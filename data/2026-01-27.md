<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 161]
- [cs.CL](#cs.CL) [Total: 111]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.IR](#cs.IR) [Total: 29]
- [cs.LG](#cs.LG) [Total: 167]
- [cs.AI](#cs.AI) [Total: 69]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 32]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Inference-Time Loss-Guided Colour Preservation in Diffusion Sampling](https://arxiv.org/abs/2601.17259)
*Angad Singh Ahuja,Aarush Ram Anandh*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的推理时区域约束颜色保持方法，通过ROI掩码、背景潜变量重置和基于CIE Lab/线性RGB的梯度引导潜变量微调，结合分布感知损失（CVaR与soft-max惩罚），显著提升文本到图像生成中指定区域的颜色准确性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在设计类任务中难以精确满足用户指定的颜色目标，尤其易出现局部颜色偏差，而现有方法多依赖平均颜色控制，忽视像素级误差分布，导致感知上明显的失败。

Method: 提出一种推理时、无需训练的区域颜色控制方法：(i) ROI-based inpainting实现空间选择性；(ii) background-latent re-imposition防止ROI外颜色漂移；(iii) 基于CIE Lab和线性RGB空间的复合损失进行latent nudging，该损失同时优化ROI均值颜色与像素误差分布尾部（采用CVaR-style和soft-maximum惩罚），并引入late-start gate和时间依赖调度以稳定去噪过程中的梯度引导。

Result: 该方法在不修改预训练模型、不额外训练的前提下，显著提升了目标区域颜色保真度；实验表明仅优化均值的基线虽满足统计平均约束，却产生明显局部色偏，而所提分布感知目标有效缓解该问题。

Conclusion: 本工作提供了一种实用、即插即用、训练无关的定向颜色控制机制，可无缝集成至标准Stable Diffusion inpainting流程，为设计导向的生成任务提供了可靠的颜色可控性解决方案。

Abstract: Precise color control remains a persistent failure mode in text-to-image diffusion systems, particularly in design-oriented workflows where outputs must satisfy explicit, user-specified color targets. We present an inference-time, region-constrained color preservation method that steers a pretrained diffusion model without any additional training. Our approach combines (i) ROI-based inpainting for spatial selectivity, (ii) background-latent re-imposition to prevent color drift outside the ROI, and (iii) latent nudging via gradient guidance using a composite loss defined in CIE Lab and linear RGB. The loss is constructed to control not only the mean ROI color but also the tail of the pixelwise error distribution through CVaR-style and soft-maximum penalties, with a late-start gate and a time-dependent schedule to stabilize guidance across denoising steps. We show that mean-only baselines can satisfy average color constraints while producing perceptually salient local failures, motivating our distribution-aware objective. The resulting method provides a practical, training-free mechanism for targeted color adherence that can be integrated into standard Stable Diffusion inpainting pipelines.

</details>


### [2] [PocketGS: On-Device Training of 3D Gaussian Splatting for High Perceptual Modeling](https://arxiv.org/abs/2601.17354)
*Wenzhi Guo,Guangchi Fang,Shu Yang,Bing Wang*

Main category: cs.CV

TL;DR: 本文提出PocketGS，一种专为移动设备设计的3D高斯泼溅（3DGS）建模方法，在极短训练时间与有限内存下实现高质量实时3D场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法依赖高资源训练环境，难以在内存与训练时长受限的移动设备上部署。

Method: 提出三个协同设计的算子：G构建几何保真点云先验；I注入局部表面统计以初始化各向异性高斯分布；T通过缓存中间量和索引映射梯度散射实现稳定移动端反向传播。

Result: PocketGS在移动设备上实现了优于主流工作站级3DGS基线的重建质量，支持端到端、全本地化的采集-渲染流程。

Conclusion: PocketGS成功解决了移动端3DGS训练中效率、内存与保真度之间的根本矛盾，推动了轻量级、高保真3D建模的实际落地。

Abstract: Efficient and high-fidelity 3D scene modeling is a long-standing pursuit in computer graphics. While recent 3D Gaussian Splatting (3DGS) methods achieve impressive real-time modeling performance, they rely on resource-unconstrained training assumptions that fail on mobile devices, which are limited by minute-scale training budgets and hardware-available peak-memory. We present PocketGS, a mobile scene modeling paradigm that enables on-device 3DGS training under these tightly coupled constraints while preserving high perceptual fidelity. Our method resolves the fundamental contradictions of standard 3DGS through three co-designed operators: G builds geometry-faithful point-cloud priors; I injects local surface statistics to seed anisotropic Gaussians, thereby reducing early conditioning gaps; and T unrolls alpha compositing with cached intermediates and index-mapped gradient scattering for stable mobile backpropagation. Collectively, these operators satisfy the competing requirements of training efficiency, memory compactness, and modeling fidelity. Extensive experiments demonstrate that PocketGS is able to outperform the powerful mainstream workstation 3DGS baseline to deliver high-quality reconstructions, enabling a fully on-device, practical capture-to-rendering workflow.

</details>


### [3] [Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility](https://arxiv.org/abs/2601.17027)
*Honglin Lin,Chonghan Qin,Zheng Liu,Qizhi Pei,Yu Li,Zhanping Zhong,Xin Gao,Yanfeng Wang,Conghui He,Lijun Wu*

Main category: cs.CV

TL;DR: 本文提出ImgCoder框架和SciGenBench评测基准，系统研究科学图像合成问题，指出像素生成模型存在视觉-逻辑偏差，并验证高保真科学图像合成可提升多模态大模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有文生图模型虽能生成视觉上合理的图像，但常缺乏科学严谨性，导致视觉与逻辑不一致，限制其在科学推理中的应用；受新一代文生图模型启发，作者系统研究科学图像合成的生成范式、评估方法及下游使用。

Method: 分析直接像素生成与程序化合成两类方法；提出逻辑驱动的ImgCoder框架，遵循“理解-规划-编码”流程以提升结构精度；构建SciGenBench评测基准，从信息效用和逻辑有效性两方面评估图像科学正确性。

Result: 发现像素生成模型存在系统性失败模式；揭示表达力与精度间的根本权衡；验证在严格验证的合成科学图像上微调多模态大模型，可带来持续推理增益，且呈现类似文本领域的可扩展趋势。

Conclusion: 高保真科学图像合成是解锁大规模多模态推理能力的有效路径。

Abstract: While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit "understand - plan - code" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.

</details>


### [4] [Flatten The Complex: Joint B-Rep Generation via Compositional $k$-Cell Particles](https://arxiv.org/abs/2601.17733)
*Junran Lu,Yuanqi Li,Hengji Li,Jie Guo,Yanwen Guo*

Main category: cs.CV

TL;DR: 本文提出了一种基于k-细胞粒子集合的新B-Rep生成范式，通过解耦传统层级结构、实现拓扑与几何的联合生成，并利用多模态流匹配框架支持无条件生成、单视图/点云重建等任务，显著提升了CAD模型的有效性与可编辑性。


<details>
  <summary>Details</summary>
Motivation: 现有B-Rep生成方法依赖级联序列处理异构的k-细胞结构，难以充分建模细胞间的几何关系（如邻接、共享），导致上下文感知弱、错误恢复能力差。

Method: 将B-Rep重构为可组合的k-细胞粒子集合，每个拓扑实体由粒子组成，相邻细胞在界面处共享隐变量以增强几何耦合；采用多模态流匹配框架进行粒子集合成，支持无条件生成与条件任务（如单视图/点云重建、局部修复、非流形结构生成）。

Result: 在多个任务上实现了高保真CAD模型生成，在有效性（validity）和可编辑性（editability）方面优于当前最先进方法；支持局部in-painting与直接生成非流形结构（如线框）。

Conclusion: 所提粒子化B-Rep表示解耦了刚性层级，统一了顶点、边、面的建模，实现了拓扑与几何的联合生成与全局上下文感知，为CAD生成提供了更鲁棒、灵活且可扩展的新范式。

Abstract: Boundary Representation (B-Rep) is the widely adopted standard
  in Computer-Aided Design (CAD) and manufacturing. However, generative modeling of B-Reps remains a formidable challenge due to their inherent heterogeneity as geometric cell complexes, which entangles topology with geometry across cells of varying orders (i.e., $k$-cells such as vertices, edges, faces). Previous methods typically rely on cascaded sequences to handle this hierarchy, which fails to fully exploit the geometric relationships between cells, such as adjacency and sharing, limiting context awareness and error recovery. To fill this gap, we introduce a novel paradigm that reformulates B-Reps into sets of compositional $k$-cell particles. Our approach encodes each topological entity as a composition of particles, where adjacent cells share identical latents at their interfaces, thereby promoting geometric coupling along shared boundaries. By decoupling the rigid hierarchy, our representation unifies vertices, edges, and faces, enabling the joint generation of topology and geometry with global context awareness.
  We synthesize these particle sets using a multi-modal flow matching framework to handle unconditional generation as well as precise conditional tasks, such as 3D reconstruction from single-view or point cloud. Furthermore, the explicit and localized nature of our representation naturally extends to downstream tasks like local in-painting and enables the direct synthesis of non-manifold structures (e.g., wireframes). Extensive experiments demonstrate that our method produces high-fidelity CAD models with superior validity and editability compared to state-of-the-art methods.

</details>


### [5] [Data-Efficient Meningioma Segmentation via Implicit Spatiotemporal Mixing and Sim2Real Semantic Injection](https://arxiv.org/abs/2601.17031)
*Yunhao Xu,Fuquan Zong,Yexuan Xing,Chulong Zhang,Guang Yang,Shilong Yang,Xiaokun Liang,Juan Yu*

Main category: cs.CV

TL;DR: 本文提出了一种双增强框架，结合空间流形扩展与语义病灶注入，利用隐式神经表示（INR）建模连续速度场并在线性变形空间中插值生成解剖学合理的图像变体，同时引入Sim2Real病灶注入模块提升合成数据真实性，显著提升了医学图像分割模型在有限标注下的数据效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割性能日益取决于数据利用效率而非原始数据量；针对脑膜瘤等复杂病变，需在有限高质量标注下充分挖掘潜在信息。

Method: 提出双增强框架：1）基于隐式神经表示（INR）建模连续速度场，对积分后的变形场进行线性混合，在变形空间内插值得到解剖学合理的结构变异；2）设计Sim2Real病灶注入模块，将病灶纹理移植到健康解剖背景中，构建高保真仿真域。

Result: 在混合数据集上的实验表明，该框架显著提升了nnU-Net和U-Mamba等SOTA模型的数据效率与鲁棒性。

Conclusion: 所提方法为标注资源受限下的高性能医学图像分析提供了有效且实用的新策略。

Abstract: The performance of medical image segmentation is increasingly defined by the efficiency of data utilization rather than merely the volume of raw data. Accurate segmentation, particularly for complex pathologies like meningiomas, demands that models fully exploit the latent information within limited high-quality annotations. To maximize the value of existing datasets, we propose a novel dual-augmentation framework that synergistically integrates spatial manifold expansion and semantic object injection. Specifically, we leverage Implicit Neural Representations (INR) to model continuous velocity fields. Unlike previous methods, we perform linear mixing on the integrated deformation fields, enabling the efficient generation of anatomically plausible variations by interpolating within the deformation space. This approach allows for the extensive exploration of structural diversity from a small set of anchors. Furthermore, we introduce a Sim2Real lesion injection module. This module constructs a high-fidelity simulation domain by transplanting lesion textures into healthy anatomical backgrounds, effectively bridging the gap between synthetic augmentation and real-world pathology. Comprehensive experiments on a hybrid dataset demonstrate that our framework significantly enhances the data efficiency and robustness of state-of-the-art models, including nnU-Net and U-Mamba, offering a potent strategy for high-performance medical image analysis with limited annotation budgets.

</details>


### [6] [Learning Sewing Patterns via Latent Flow Matching of Implicit Fields](https://arxiv.org/abs/2601.17740)
*Cong Cao,Ren Li,Corentin Dumery,Hao Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐式表示（符号距离场与无符号距离场）的缝纫纸样建模方法，结合潜在流匹配与缝合预测模块，实现复杂纸样的准确生成、图像到纸样的估计、补全与重拟合。


<details>
  <summary>Details</summary>
Motivation: 现有自动纸样生成方法难以准确建模多样化的衣片几何形状与缝合结构。

Method: 使用符号距离场表示衣片边界、无符号距离场标识缝端点，并编码至连续潜在空间以支持可微网格化；采用潜在流匹配建模衣片组合分布，辅以缝合预测模块从边缘段恢复缝合关系。

Result: 实现了复杂结构缝纫纸样的高精度建模与生成；在图像到纸样估计任务上优于现有方法；支持纸样补全与重拟合等实用功能。

Conclusion: 该隐式表示框架为数字服装设计提供了更鲁棒、灵活且可微的纸样建模与生成新范式。

Abstract: Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.

</details>


### [7] [Diagnosis Support of Sickle Cell Anemia by Classifying Red Blood Cell Shape in Peripheral Blood Images](https://arxiv.org/abs/2601.17032)
*Wilkie Delgado-Font,Miriela Escobedo-Nicot,Manuel González-Hidalgo,Silena Herold-Garcia,Antoni Jaume-i-Capó,Arnau Mir*

Main category: cs.CV

TL;DR: 本文提出了一种基于外周血涂片图像分析的自动化红细胞（RBC）分类方法，利用Chan-Vese活动轮廓模型分割细胞，并结合圆形与椭圆形形状因子（CSF/ESF）对正常、伸长及其他变形RBC进行区分，尤其通过椭圆校正处理聚簇中部分遮挡的细胞；在古巴圣地亚哥医院临床数据上验证，F值达0.97（正常）和0.95（伸长），优于现有方法，适用于镰状细胞贫血的临床辅助诊断。


<details>
  <summary>Details</summary>
Motivation: 传统显微镜下人工观察外周血涂片费时、依赖专家且主观性强、误差高，亟需自动化、客观、可靠的RBC形变分析方法以支持镰状细胞贫血等疾病的诊断。

Method: 采用Chan-Vese主动轮廓模型进行图像中红细胞分割；提取圆形形状因子（CSF）和椭圆形形状因子（ESF）作为形态学特征；针对聚簇中部分遮挡的细胞，引入椭圆拟合校正策略以提升 discoidal 和 elongated 细胞的识别鲁棒性。

Result: 在真实临床血样图像上实现高精度分类：正常RBC F-measure为0.97，伸长型为0.95；整体多类别性能指标优于当前主流方法；结果满足临床诊疗支持需求。

Conclusion: 所提方法能有效、自动、准确地区分不同形态的红细胞，显著提升镰状细胞贫血诊断的客观性与效率，具备临床转化潜力。

Abstract: Red blood cell (RBC) deformation is the consequence of several diseases, including sickle cell anemia, which causes recurring episodes of pain and severe pronounced anemia. Monitoring patients with these diseases involves the observation of peripheral blood samples under a microscope, a time-consuming procedure. Moreover, a specialist is required to perform this technique, and owing to the subjective nature of the observation of isolated RBCs, the error rate is high. In this paper, we propose an automated method for differentially enumerating RBCs that uses peripheral blood smear image analysis. In this method, the objects of interest in the image are segmented using a Chan-Vese active contour model. An analysis is then performed to classify the RBCs, also called erythrocytes, as normal or elongated or having other deformations, using the basic shape analysis descriptors: circular shape factor (CSF) and elliptical shape factor (ESF). To analyze cells that become partially occluded in a cluster during sample preparation, an elliptical adjustment is performed to allow the analysis of erythrocytes with discoidal and elongated shapes. The images of patient blood samples used in the study were acquired by a clinical laboratory specialist in the Special Hematology Department of the ``Dr. Juan Bruno Zayas'' General Hospital in Santiago de Cuba. A comparison of the results obtained by the proposed method in our experiments with those obtained by some state-of-the-art methods showed that the proposed method is superior for the diagnosis of sickle cell anemia. This superiority is achieved for evidenced by the obtained F-measure value (0.97 for normal cells and 0.95 for elongated ones) and several overall multiclass performance measures. The results achieved by the proposed method are suitable for the purpose of clinical treatment and diagnostic support of sickle cell anemia.

</details>


### [8] [MV-S2V: Multi-View Subject-Consistent Video Generation](https://arxiv.org/abs/2601.17756)
*Ziyang Song,Xinyu Gong,Bangya Liu,Zelin Zhao*

Main category: cs.CV

TL;DR: 本文提出了多视角主题到视频生成（MV-S2V）任务，通过合成数据构建与真实数据结合的方式解决训练数据稀缺问题，并引入时序偏移RoPE（TS-RoPE）机制区分跨主体与跨视角参考，显著提升了3D级主题一致性与视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有主题到视频生成（S2V）方法仅支持单视角参考，导致任务退化为S2I+I2V流程，无法实现真正3D层面的主题控制；亟需拓展至多视角以增强视频中主体的空间一致性。

Method: 1）构建多视角合成数据生成流水线，并辅以小规模真实多视角数据集；2）提出时序偏移RoPE（TS-RoPE）机制，在条件生成中显式区分不同主体与同一主体的不同视角。

Result: 在多视角参考下实现了更优的3D主题一致性与高质量视频输出，显著优于单视角基线方法。

Conclusion: MV-S2V为主题驱动视频生成开辟了新方向，TS-RoPE与合成数据策略有效解决了多视角条件建模与数据稀缺两大核心挑战。

Abstract: Existing Subject-to-Video Generation (S2V) methods have achieved high-fidelity and subject-consistent video generation, yet remain constrained to single-view subject references. This limitation renders the S2V task reducible to an S2I + I2V pipeline, failing to exploit the full potential of video subject control. In this work, we propose and address the challenging Multi-View S2V (MV-S2V) task, which synthesizes videos from multiple reference views to enforce 3D-level subject consistency. Regarding the scarcity of training data, we first develop a synthetic data curation pipeline to generate highly customized synthetic data, complemented by a small-scale real-world captured dataset to boost the training of MV-S2V. Another key issue lies in the potential confusion between cross-subject and cross-view references in conditional generation. To overcome this, we further introduce Temporally Shifted RoPE (TS-RoPE) to distinguish between different subjects and distinct views of the same subject in reference conditioning. Our framework achieves superior 3D subject consistency w.r.t. multi-view reference images and high-quality visual outputs, establishing a new meaningful direction for subject-driven video generation. Our project page is available at <a href="https://szy-young.github.io/mv-s2v">this URL</a>

</details>


### [9] [AMVICC: A Novel Benchmark for Cross-Modal Failure Mode Profiling for VLMs and IGMs](https://arxiv.org/abs/2601.17037)
*Aahana Basappa,Pranay Goel,Anusri Karra,Anish Karra,Asa Gilmore,Kevin Zhu*

Main category: cs.CV

TL;DR: 本文构建了AMVICC基准，系统评估多模态大语言模型（MLLMs）和图像生成模型（IGMs）在视觉推理任务中的失败模式，发现两类模型在方向、数量、空间关系等基础视觉概念上均存在共性与特异性缺陷，尤其IGMs对细粒度视觉属性控制能力较弱。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态模型快速发展，但在基本视觉概念（如物体朝向、数量、空间关系）的理解与生成上仍存在明显缺陷，缺乏跨模态、系统性的失败模式分析框架。

Method: 提出AMVICC基准，通过将MMVP问题适配为显式/隐式提示，在九类视觉推理任务中对11个MLLMs和3个IGMs进行跨模态评测，并对比其失败模式。

Result: 发现失败模式既有跨模型与跨模态的共性，也有模型/模态特异性；IGMs在显式提示下难以操控特定视觉成分，表明其对细粒度视觉属性控制能力差。

Conclusion: 视觉理解与生成的瓶颈部分源于共享的底层局限，AMVICC为统一视觉-语言建模的诊断与改进提供了可扩展的交叉评估框架。

Abstract: We investigated visual reasoning limitations of both multimodal large language models (MLLMs) and image generation models (IGMs) by creating a novel benchmark to systematically compare failure modes across image-to-text and text-to-image tasks, enabling cross-modal evaluation of visual understanding. Despite rapid growth in machine learning, vision language models (VLMs) still fail to understand or generate basic visual concepts such as object orientation, quantity, or spatial relationships, which highlighted gaps in elementary visual reasoning. By adapting MMVP benchmark questions into explicit and implicit prompts, we create \textit{AMVICC}, a novel benchmark for profiling failure modes across various modalities. After testing 11 MLLMs and 3 IGMs in nine categories of visual reasoning, our results show that failure modes are often shared between models and modalities, but certain failures are model-specific and modality-specific, and this can potentially be attributed to various factors. IGMs consistently struggled to manipulate specific visual components in response to prompts, especially in explicit prompts, suggesting poor control over fine-grained visual attributes. Our findings apply most directly to the evaluation of existing state-of-the-art models on structured visual reasoning tasks. This work lays the foundation for future cross-modal alignment studies, offering a framework to probe whether generation and interpretation failures stem from shared limitations to guide future improvements in unified vision-language modeling.

</details>


### [10] [PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction](https://arxiv.org/abs/2601.18336)
*Isaac Deutsch,Nicolas Moënne-Loccoz,Gavriel State,Zan Gojcic*

Main category: cs.CV

TL;DR: 本文提出了一种物理上合理的图像信号处理（PPISP）校正模块，用于解决多视角3D重建中因相机光学特性和图像信号处理差异导致的光度不一致性问题。该模块通过物理建模分离相机固有与捕获相关效应，并利用专用控制器预测新视角下的ISP参数，从而提升泛化能力和评估真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法对光度不一致性敏感，且缺乏物理依据、泛化能力差。

Method: 提出物理上合理的ISP（PPISP）校正模块，通过物理建模实现相机内参与捕获相关效应的解耦，并设计PPISP控制器预测新视角的ISP参数。

Result: 在标准基准上达到SOTA性能，支持元数据集成，提供直观可控性，并实现无需真值图像的新视角公平评估。

Conclusion: PPISP通过引入物理一致的建模方式，显著提升了多视角3D重建中光度一致性建模的鲁棒性与泛化性，为真实场景部署提供了更可靠的基础。

Abstract: Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp

</details>


### [11] [Hybrid Deep Feature Extraction and ML for Construction and Demolition Debris Classification](https://arxiv.org/abs/2601.17038)
*Obai Alashram,Nejad Alagha,Mahmoud AlKakuri,Zeeshan Swaveel,Abigail Copiaco*

Main category: cs.CV

TL;DR: 本文提出了一种结合Xception深度特征提取与多种经典机器学习分类器的混合视觉管道，用于建筑垃圾（C&D）自动分类，在自建的1800张四类真实工地图像数据集上达到99.5%准确率，优于端到端深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 建筑行业产生大量废弃物，亟需高效、可持续的分类技术以支持资源回收和现场自动化。

Method: 构建包含陶瓷/瓷砖、混凝土、垃圾/废物、木材四类共1800张高质量平衡图像的真实工地数据集；采用预训练Xception网络提取深层特征；系统评估SVM、kNN、Bagged Trees、LDA、逻辑回归等经典机器学习分类器。

Result: 基于Xception特征的线性SVM、kNN和Bagged Trees等简单分类器取得最高99.5%准确率和宏F1分数，性能超越复杂或端到端深度学习模型。

Conclusion: 该混合视觉管道兼具高性能与部署可行性，适用于实地应用，并为未来与机器人及现场自动化系统集成提供基础。

Abstract: The construction industry produces significant volumes of debris, making effective sorting and classification critical for sustainable waste management and resource recovery. This study presents a hybrid vision-based pipeline that integrates deep feature extraction with classical machine learning (ML) classifiers for automated construction and demolition (C\&D) debris classification. A novel dataset comprising 1,800 balanced, high-quality images representing four material categories, Ceramic/Tile, Concrete, Trash/Waste, and Wood was collected from real construction sites in the UAE, capturing diverse real-world conditions. Deep features were extracted using a pre-trained Xception network, and multiple ML classifiers, including SVM, kNN, Bagged Trees, LDA, and Logistic Regression, were systematically evaluated. The results demonstrate that hybrid pipelines using Xception features with simple classifiers such as Linear SVM, kNN, and Bagged Trees achieve state-of-the-art performance, with up to 99.5\% accuracy and macro-F1 scores, surpassing more complex or end-to-end deep learning approaches. The analysis highlights the operational benefits of this approach for robust, field-deployable debris identification and provides pathways for future integration with robotics and onsite automation systems.

</details>


### [12] [GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization](https://arxiv.org/abs/2601.18585)
*Chenxi Liu,Selena Ling,Alec Jacobson*

Main category: cs.CV

TL;DR: 本文提出GimmBO，一种基于偏好贝叶斯优化（PBO）的交互式适配器融合探索方法，用于高效定制扩散模型图像生成，显著提升高维权重空间中的采样效率与收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有手动滑块调参方式在适配器融合中扩展性差、权重选择困难，尤其当候选适配器达20–30个时；实际使用中存在权重稀疏性和取值范围受限等特性。

Method: 提出GimmBO框架，采用两阶段偏好贝叶斯优化（PBO）后端，结合用户偏好反馈，在高维适配器权重空间中高效搜索最优融合配置。

Result: 在模拟用户和真实用户研究中，GimmBO相比标准贝叶斯优化和线搜索基线，展现出更快收敛、更高成功率及稳定性能增益，并验证了其框架灵活性（如多扩展支持）。

Conclusion: GimmBO为社区驱动的扩散模型适配器融合提供了可扩展、高效且用户友好的交互式探索新范式。

Abstract: Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.

</details>


### [13] [MANGO: A Global Single-Date Paired Dataset for Mangrove Segmentation](https://arxiv.org/abs/2601.17039)
*Junhyuk Heo,Beomkyu Choi,Hyunjin Shin,Darongsae Kwon*

Main category: cs.CV

TL;DR: 本文提出了MANGO，一个大规模全球红树林数据集，包含42,703对单日期图像-掩膜样本，覆盖124个国家，并基于目标检测驱动的方法筛选高质量配对；同时提供了跨多种语义分割模型的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有红树林监测数据集存在缺乏单日期图像-掩膜对、区域覆盖有限、数据不可公开等问题，制约了深度学习在红树林检测中的应用。

Method: 利用2020年Sentinel-2卫星影像，在全球红树林区域提取最佳单日期图像，并通过目标检测驱动的像素级坐标对齐方法，与年度红树林掩膜匹配生成图像-掩膜对；构建了国家互斥划分的基准测试协议。

Result: 发布了MANGO数据集（42,703对图像-掩膜，覆盖124国），并在多种语义分割模型上完成了基准测试，验证了其在跨区域泛化能力上的有效性。

Conclusion: MANGO填补了全球尺度、高质量、公开可用红树林图像-掩膜数据集的空白，为可扩展、可靠的全球红树林监测提供了坚实基础。

Abstract: Mangroves are critical for climate-change mitigation, requiring reliable monitoring for effective conservation. While deep learning has emerged as a powerful tool for mangrove detection, its progress is hindered by the limitations of existing datasets. In particular, many resources provide only annual map products without curated single-date image-mask pairs, limited to specific regions rather than global coverage, or remain inaccessible to the public. To address these challenges, we introduce MANGO, a large-scale global dataset comprising 42,703 labeled image-mask pairs across 124 countries. To construct this dataset, we retrieve all available Sentinel-2 imagery within the year 2020 for mangrove regions and select the best single-date observations that align with the mangrove annual mask. This selection is performed using a target detection-driven approach that leverages pixel-wise coordinate references to ensure adaptive and representative image-mask pairings. We also provide a benchmark across diverse semantic segmentation architectures under a country-disjoint split, establishing a foundation for scalable and reliable global mangrove monitoring.

</details>


### [14] [FP-THD: Full page transcription of historical documents](https://arxiv.org/abs/2601.17040)
*H Neji,J Nogueras-Iso,J Lacasta,MÁ Latre,FJ García-Marco*

Main category: cs.CV

TL;DR: 本文提出了一种用于15-16世纪拉丁文历史文献转录的端到端流程，结合布局分析与OCR模型，在保留特殊字符和符号的前提下实现高效、准确的数字化。


<details>
  <summary>Details</summary>
Motivation: 15-16世纪拉丁文历史文献转录需保留具有特定历史意义的字符与符号，现有方法难以兼顾风格保真与识别精度。

Method: 提出融合布局分析模型与文本行识别OCR模型的端到端转录流程：先用布局分析提取文本行，再由OCR模型进行识别；引入掩码自编码器提升对手写、印刷及多语种文本的鲁棒性。

Result: 在多个数据集上验证了该流程的有效性，掩码自编码器展现出对不同类型文本（手写、印刷、多语言）的良好适应性与高效率。

Conclusion: 所提流程能有效支持历史文献数字化，在保持原始风格的同时提升转录准确性与处理效率，为古籍保护提供实用技术路径。

Abstract: The transcription of historical documents written in Latin in XV and XVI centuries has special challenges as it must maintain the characters and special symbols that have distinct meanings to ensure that historical texts retain their original style and significance. This work proposes a pipeline for the transcription of historical documents preserving these special features. We propose to extend an existing text line recognition method with a layout analysis model. We analyze historical text images using a layout analysis model to extract text lines, which are then processed by an OCR model to generate a fully digitized page. We showed that our pipeline facilitates the processing of the page and produces an efficient result. We evaluated our approach on multiple datasets and demonstrate that the masked autoencoder effectively processes different types of text, including handwritten, printed and multi-language.

</details>


### [15] [Arabic Sign Language Recognition using Multimodal Approach](https://arxiv.org/abs/2601.17041)
*Ghadeer Alanazi,Abir Benabid*

Main category: cs.CV

TL;DR: 本文提出了一种结合Leap Motion与RGB相机的多模态阿拉伯手语（ArSL）识别方法，通过融合两种模态特征，在自建18词数据集上达到78%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有ArSL识别系统依赖单一传感器（如Leap Motion或RGB相机），难以准确跟踪复杂手部朝向和三维运动，限制了识别性能。

Method: 构建双分支网络：Leap Motion分支采用带Dropout和L2正则的自定义稠密神经网络；RGB图像分支基于数据增强后的微调VGG16；两分支特征拼接后经全连接层和SoftMax分类。

Result: 在包含18个ArSL词汇的自建数据集上，系统正确识别13个词，整体准确率为78%。

Conclusion: 多模态融合方案初步验证了其在ArSL识别中的可行性，但需进一步优化模型结构并扩展数据集以提升性能。

Abstract: Arabic Sign Language (ArSL) is an essential communication method for individuals in the Deaf and Hard-of-Hearing community. However, existing recognition systems face significant challenges due to their reliance on single sensor approaches like Leap Motion or RGB cameras. These systems struggle with limitations such as inadequate tracking of complex hand orientations and imprecise recognition of 3D hand movements. This research paper aims to investigate the potential of a multimodal approach that combines Leap Motion and RGB camera data to explore the feasibility of recognition of ArSL. The system architecture includes two parallel subnetworks: a custom dense neural network for Leap Motion data, incorporating dropout and L2 regularization, and an image subnetwork based on a fine-tuned VGG16 model enhanced with data augmentation techniques. Feature representations from both modalities are concatenated in a fusion model and passed through fully connected layers, with final classification performed via SoftMax activation to analyze spatial and temporal features of hand gestures. The system was evaluated on a custom dataset comprising 18 ArSL words, of which 13 were correctly recognized, yielding an overall accuracy of 78%. These results offer preliminary insights into the viability of multimodal fusion for sign language recognition and highlight areas for further optimization and dataset expansion.

</details>


### [16] [Interpretable and Sparse Linear Attention with Decoupled Membership-Subspace Modeling via MCR2 Objective](https://arxiv.org/abs/2601.17042)
*Tianyuan Liu,Libin Hou,Linyuan Wang,Bin Yan*

Main category: cs.CV

TL;DR: 本文提出了一种解耦成员矩阵与子空间矩阵的MCR2优化方法，导出可解释的稀疏线性注意力算子DMSA，并在ToST中替换原有注意力模块形成DMST，在ImageNet-1K上精度提升1.08%-1.45%，同时提高计算效率与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有MCR2驱动的白盒Transformer中，成员矩阵与子空间矩阵U紧密耦合，导致错误token投影下出现冗余编码，影响效率与可解释性。

Method: 解耦MCR2目标中成员矩阵与子空间U的功能关系，通过优化目标的梯度展开推导出可解释的稀疏线性注意力算子DMSA：直接从输入学习成员矩阵，再从全空间S导出稀疏子空间。

Result: 在ImageNet-1K上，将DMSA嵌入ToST形成的DMST模型比原ToST提升1.08%-1.45% top-1精度，且编码压缩率更高、计算更高效、可解释性更强。

Conclusion: DMSA提供了一种兼顾高效性与可解释性的新型注意力机制，验证了结构化表征学习中解耦设计对白盒视觉建模的有效性。

Abstract: Maximal Coding Rate Reduction (MCR2)-driven white-box transformer, grounded in structured representation learning, unifies interpretability and efficiency, providing a reliable white-box solution for visual modeling. However, in existing designs, tight coupling between "membership matrix" and "subspace matrix U" in MCR2 causes redundant coding under incorrect token projection. To this end, we decouple the functional relationship between the "membership matrix" and "subspaces U" in the MCR2 objective and derive an interpretable sparse linear attention operator from unrolled gradient descent of the optimized objective. Specifically, we propose to directly learn the membership matrix from inputs and subsequently derive sparse subspaces from the fullspace S. Consequently, gradient unrolling of the optimized MCR2 objective yields an interpretable sparse linear attention operator: Decoupled Membership-Subspace Attention (DMSA). Experimental results on visual tasks show that simply replacing the attention module in Token Statistics Transformer (ToST) with DMSA (we refer to as DMST) not only achieves a faster coding reduction rate but also outperforms ToST by 1.08%-1.45% in top-1 accuracy on the ImageNet-1K dataset. Compared with vanilla Transformer architectures, DMST exhibits significantly higher computational efficiency and interpretability.

</details>


### [17] [Atomic Depth Estimation From Noisy Electron Microscopy Data Via Deep Learning](https://arxiv.org/abs/2601.17046)
*Matan Leibovich,Mai Tan,Adria Marcos-Morales,Sreyas Mohan,Peter A. Crozier,Carlos Fernandez-Granda*

Main category: cs.CV

TL;DR: 本文提出了一种基于语义分割的深度估计方法，利用加噪模拟数据训练深度卷积神经网络，以从高噪声透射电子显微镜（TEM）图像中提取原子级三维信息，并在CeO2纳米颗粒的模拟与真实TEM数据上验证了其准确性、校准性和抗噪鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决高噪声透射电子显微镜（TEM）图像中难以准确提取3D原子级信息的问题。

Method: 将深度估计建模为语义分割任务，使用含合成噪声的模拟数据训练深度卷积神经网络，生成像素级深度分割图。

Result: 该方法在CeO2纳米颗粒的模拟和真实TEM图像上均实现了准确、可校准且抗噪鲁棒的原子柱深度估计。

Conclusion: 所提方法为高噪声TEM图像的原子级三维结构解析提供了一种有效、可靠的新范式。

Abstract: We present a novel approach for extracting 3D atomic-level information from transmission electron microscopy (TEM) images affected by significant noise. The approach is based on formulating depth estimation as a semantic segmentation problem. We address the resulting segmentation problem by training a deep convolutional neural network to generate pixel-wise depth segmentation maps using simulated data corrupted by synthetic noise. The proposed method was applied to estimate the depth of atomic columns in CeO2 nanoparticles from simulated images and real-world TEM data. Our experiments show that the resulting depth estimates are accurate, calibrated and robust to noise.

</details>


### [18] [A Contrastive Pre-trained Foundation Model for Deciphering Imaging Noisomics across Modalities](https://arxiv.org/abs/2601.17047)
*Yuanjie Gu,Yiqun Wang,Chaohui Yu,Ang Xuan,Fan Wang,Zhi Lu,Biqin Dong*

Main category: cs.CV

TL;DR: 本文提出“Noisomics”框架，通过对比预训练基础模型（CoP）将成像噪声从干扰源转变为信息资源，仅用100个样本即超越传统监督方法（10万样本），显著提升零样本泛化能力与噪声建模精度。


<details>
  <summary>Details</summary>
Motivation: 现有成像噪声建模方法严重依赖大规模标注数据，且将噪声简单视为干扰，忽视其蕴含的设备与物理过程信息。

Method: 提出基于流形假设和合成噪声基因组的对比预训练基础模型（CoP），利用对比学习解耦语义信号与随机扰动，实现小样本下的噪声系统性解码。

Result: 在12个跨域数据集上实现零样本泛化，估计误差降低63.8%，决定系数提升85.1%；仅需100样本即超越使用10万样本训练的监督基线。

Conclusion: 噪声可被建模为多参数指纹，Noisomics框架重新定义噪声为关键信息资源，支持无需设备先验校准的精准成像诊断。

Abstract: Characterizing imaging noise is notoriously data-intensive and device-dependent, as modern sensors entangle physical signals with complex algorithmic artifacts. Current paradigms struggle to disentangle these factors without massive supervised datasets, often reducing noise to mere interference rather than an information resource. Here, we introduce "Noisomics", a framework shifting the focus from suppression to systematic noise decoding via the Contrastive Pre-trained (CoP) Foundation Model. By leveraging the manifold hypothesis and synthetic noise genome, CoP employs contrastive learning to disentangle semantic signals from stochastic perturbations. Crucially, CoP breaks traditional deep learning scaling laws, achieving superior performance with only 100 training samples, outperforming supervised baselines trained on 100,000 samples, thereby reducing data and computational dependency by three orders of magnitude. Extensive benchmarking across 12 diverse out-of-domain datasets confirms its robust zero-shot generalization, demonstrating a 63.8% reduction in estimation error and an 85.1% improvement in the coefficient of determination compared to the conventional training strategy. We demonstrate CoP's utility across scales: from deciphering non-linear hardware-noise interplay in consumer photography to optimizing photon-efficient protocols for deep-tissue microscopy. By decoding noise as a multi-parametric footprint, our work redefines stochastic degradation as a vital information resource, empowering precise imaging diagnostics without prior device calibration.

</details>


### [19] [SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis](https://arxiv.org/abs/2601.17048)
*Jing Jie Tan,Rupert Schreiner,Matthias Hausladen,Ali Asgharzade,Simon Edler,Julian Bartsch,Michael Bachmann,Andreas Schels,Ban-Hoe Kwan,Danny Wee-Kiat Ng,Yan-Chai Hum*

Main category: cs.CV

TL;DR: 本文提出SiMiC方法，利用带注意力机制的卷积神经网络自动、高精度地从SEM图像中提取硅微结构（如场发射尖端）的几何特征，提升表征效率与一致性，并建立几何特征与场发射性能间的联系。


<details>
  <summary>Details</summary>
Motivation: 传统SEM图像的手动分析耗时、低效且可重复性差，难以满足微纳制造与器件性能优化对快速、准确微结构表征的需求。

Method: 构建面向硅基场发射尖端的专用SEM图像数据集，设计融合注意力机制的定制化CNN模型，实现多类别微结构分类与关键尺寸（如曲率、形状、尺寸）回归预测。

Result: SiMiC在分类与尺寸预测任务上显著优于经典图像处理方法，兼具高精度与可解释性；成功将微结构几何参数与场发射性能关联，验证了其物理意义与工程价值。

Conclusion: SiMiC为硅微结构的数据驱动表征提供了新范式，推动冷阴极与SEM电子源的几何-性能协同设计，并开源数据与代码以促进该领域基准建设。

Abstract: Accurate characterization of silicon microstructures is essential for advancing microscale fabrication, quality control, and device performance. Traditional analysis using Scanning Electron Microscopy (SEM) often requires labor-intensive, manual evaluation of feature geometry, limiting throughput and reproducibility. In this study, we propose SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis. By leveraging deep learning, our approach efficiently extracts morphological features-such as size, shape, and apex curvature-from SEM images, significantly reducing human intervention while improving measurement consistency. A specialized dataset of silicon-based field-emitter tips was developed, and a customized CNN architecture incorporating attention mechanisms was trained for multi-class microstructure classification and dimensional prediction. Comparative analysis with classical image processing techniques demonstrates that SiMiC achieves high accuracy while maintaining interpretability. The proposed framework establishes a foundation for data-driven microstructure analysis directly linked to field-emission performance, opening avenues for correlating emitter geometry with emission behavior and guiding the design of optimized cold-cathode and SEM electron sources. The related dataset and algorithm repository that could serve as a baseline in this area can be found at https://research.jingjietan.com/?q=SIMIC

</details>


### [20] [Summary of the Unusual Activity Recognition Challenge for Developmental Disability Support](https://arxiv.org/abs/2601.17049)
*Christina Garcia,Nhat Tan Le,Taihei Fujioka,Umang Dobhal,Milyun Ni'ma Shoumi,Thanh Nha Nguyen,Sozo Inoue*

Main category: cs.CV

TL;DR: 本文概述了ISAS 2025举办的‘识别未见行为：基于姿态数据的异常行为识别挑战赛’，聚焦于利用非侵入式姿态估计数据自动识别发育障碍人士设施中的异常行为。


<details>
  <summary>Details</summary>
Motivation: 解决在发育障碍人士照护设施中，利用非侵入式姿态数据自动识别异常行为的关键需求。

Method: 基于模拟场景视频提取骨架关键点，采用Leave-One-Subject-Out（LOSO）策略评估，使用宏平均F1分数衡量模型性能，参赛方案涵盖传统机器学习至深度学习架构。

Result: 结果表明，在噪声大、维度低的数据中建模罕见且突发的行为极具挑战性，强调需同时捕捉行为的时间动态与上下文语义。

Conclusion: 该挑战揭示了异常行为识别的技术难点，其经验可推动面向医疗与行为监测的社会责任AI发展。

Abstract: This paper presents an overview of the Recognize the Unseen: Unusual Behavior Recognition from Pose Data Challenge, hosted at ISAS 2025. The challenge aims to address the critical need for automated recognition of unusual behaviors in facilities for individuals with developmental disabilities using non-invasive pose estimation data. Participating teams were tasked with distinguishing between normal and unusual activities based on skeleton keypoints extracted from video recordings of simulated scenarios. The dataset reflects real-world imbalance and temporal irregularities in behavior, and the evaluation adopted a Leave-One-Subject-Out (LOSO) strategy to ensure subject-agnostic generalization. The challenge attracted broad participation from 40 teams applying diverse approaches ranging from classical machine learning to deep learning architectures. Submissions were assessed primarily using macro-averaged F1 scores to account for class imbalance. The results highlight the difficulty of modeling rare, abrupt actions in noisy, low-dimensional data, and emphasize the importance of capturing both temporal and contextual nuances in behavior modeling. Insights from this challenge may contribute to future developments in socially responsible AI applications for healthcare and behavior monitoring.

</details>


### [21] [Single-Pixel Vision-Language Model for Intrinsic Privacy-Preserving Behavioral Intelligence](https://arxiv.org/abs/2601.17050)
*Hongjun An,Yiliang Song,Jiawei Shao,Zhe Sun,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出了一种单像素视觉-语言模型（SP-VLM），在保障隐私前提下实现敏感场所（如卫生间、更衣室）的行为异常检测与活动理解，通过低维单像素信号抑制身份识别能力，同时保留行为语义理解能力。


<details>
  <summary>Details</summary>
Motivation: 在厕所、更衣室等隐私敏感场所，传统监控因伦理与法规受限，但欺凌、骚扰等不良社会互动亟需监测；亟需一种兼顾安全与隐私的新型监测范式。

Method: 提出单像素视觉-语言模型（SP-VLM），利用单像素传感器采集低维信号，结合视觉-语言联合建模提取行为语义；理论与实验分析单像素采样率对身份可恢复性与行为可识别性的权衡关系。

Result: 证实单像素信号在临界采样率以下可使现有人脸识别系统失效，同时仍能有效支持异常检测、人数统计与活动理解；确定了一个行为智能涌现而身份强受保护的实用采样率区间。

Conclusion: SP-VLM为隐私敏感空间提供了符合人权理念的安全监控新路径，在不牺牲个体隐私前提下支持及时干预，避免侵入式监控常态化。

Abstract: Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.

</details>


### [22] [Synthetic Data Guided Feature Selection for Robust Activity Recognition in Older Adults](https://arxiv.org/abs/2601.17053)
*Shuhao Que,Dieuwke van Dartel,Ilse Heeringa,Han Hegeman,Miriam Vollenbroek-Hutten,Ying Wang*

Main category: cs.CV

TL;DR: 本研究开发了一种基于合成数据引导的特征干预模型（FIM），用于提升髋部骨折康复期高龄老人日常活动识别的准确性，尤其显著改善了临床意义重大的姿势转换识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于可穿戴设备的活动识别系统在中年人群中开发，难以适应高龄老人缓慢且变异性大的步态模式，导致临床实践中髋部骨折康复期老年人的身体活动难以准确量化。

Method: 招募24名80岁以上健康老年人，在模拟自由生活条件下完成日常活动（行走、站立、坐、卧、姿势转换），同时佩戴腰背部和大腿前侧两个加速度计；采用留一受试者交叉验证评估模型鲁棒性，并引入合成数据提升跨个体泛化能力，构建特征干预模型（FIM）。

Result: FIM模型在行走、站立、坐、卧、姿势转换上的平均F1分数分别为0.896、0.927、0.997、0.937和0.816；相比未使用合成数据的对照模型，显著提升了姿势转换识别性能。

Conclusion: 该初步结果证实了在高龄人群中实现鲁棒活动识别的可行性；后续需在真实髋部骨折患者群体中进一步验证其临床实用性。

Abstract: Physical activity during hip fracture rehabilitation is essential for mitigating long-term functional decline in geriatric patients. However, it is rarely quantified in clinical practice. Existing continuous monitoring systems with commercially available wearable activity trackers are typically developed in middle-aged adults and therefore perform unreliably in older adults with slower and more variable gait patterns. This study aimed to develop a robust human activity recognition (HAR) system to improve continuous physical activity recognition in the context of hip fracture rehabilitation. 24 healthy older adults aged over 80 years were included to perform activities of daily living (walking, standing, sitting, lying down, and postural transfers) under simulated free-living conditions for 75 minutes while wearing two accelerometers positioned on the lower back and anterior upper thigh. Model robustness was evaluated using leave-one-subject-out cross-validation. The synthetic data demonstrated potential to improve generalization across participants. The resulting feature intervention model (FIM), aided by synthetic data guidance, achieved reliable activity recognition with mean F1-scores of 0.896 for walking, 0.927 for standing, 0.997 for sitting, 0.937 for lying down, and 0.816 for postural transfers. Compared with a control condition model without synthetic data, the FIM significantly improved the postural transfer detection, i.e., an activity class of high clinical relevance that is often overlooked in existing HAR literature. In conclusion, these preliminary results demonstrate the feasibility of robust activity recognition in older adults. Further validation in hip fracture patient populations is required to assess the clinical utility of the proposed monitoring system.

</details>


### [23] [Ego4OOD: Rethinking Egocentric Video Domain Generalization via Covariate Shift Scoring](https://arxiv.org/abs/2601.17056)
*Zahra Vaseqi,James Clark*

Main category: cs.CV

TL;DR: 本文提出Ego4OOD基准，用于评估自我中心视频动作识别在协变量偏移下的泛化能力，并设计了一种one-vs-all二元训练目标以提升模型在分布偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自我中心域泛化基准混淆了协变量偏移与概念偏移，难以可靠评估模型对输入分布变化的泛化能力。

Method: 构建Ego4OOD基准（基于Ego4D），强调可度量的协变量多样性并减少概念偏移；引入基于聚类的协变量偏移度量；采用one-vs-all二元分类训练策略，将多类动作识别分解为独立二元任务。

Result: 一个轻量级两层全连接网络在Argo1M和Ego4OOD上达到与SOTA方法相当的性能，且参数更少、无需额外模态；实验证明协变量偏移程度与识别性能存在明确相关性。

Conclusion: 可控的基准设计与定量的域特征刻画对研究自我中心视频的分布外泛化至关重要；one-vs-all二元训练策略有效缓解协变量偏移带来的类间干扰。

Abstract: Egocentric video action recognition under domain shifts remains challenging due to large intra-class spatio-temporal variability, long-tailed feature distributions, and strong correlations between actions and environments. Existing benchmarks for egocentric domain generalization often conflate covariate shifts with concept shifts, making it difficult to reliably evaluate a model's ability to generalize across input distributions. To address this limitation, we introduce Ego4OOD, a domain generalization benchmark derived from Ego4D that emphasizes measurable covariate diversity while reducing concept shift through semantically coherent, moment-level action categories. Ego4OOD spans eight geographically distinct domains and is accompanied by a clustering-based covariate shift metric that provides a quantitative proxy for domain difficulty. We further leverage a one-vs-all binary training objective that decomposes multi-class action recognition into independent binary classification tasks. This formulation is particularly well-suited for covariate shift by reducing interference between visually similar classes under feature distribution shift. Using this formulation, we show that a lightweight two-layer fully connected network achieves performance competitive with state-of-the-art egocentric domain generalization methods on both Argo1M and Ego4OOD, despite using fewer parameters and no additional modalities. Our empirical analysis demonstrates a clear relationship between measured covariate shift and recognition performance, highlighting the importance of controlled benchmarks and quantitative domain characterization for studying out-of-distribution generalization in egocentric video.

</details>


### [24] [A Computer Vision Pipeline for Iterative Bullet Hole Tracking in Rifle Zeroing](https://arxiv.org/abs/2601.17062)
*Robert M. Belcher,Brendan C. Degryse,Leonard R. Kosta,Christopher J. Lowrance*

Main category: cs.CV

TL;DR: 本文提出了一种端到端计算机视觉系统，利用YOLOv8与IoU分析实现子弹孔自动检测与迭代追踪，并通过新型去增广数据方法和ORB视角校正预处理提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统步枪归零需人工识别多轮射击的弹孔，存在延迟与人为误差风险。

Method: 结合YOLOv8进行小目标检测，使用IoU分析实现跨序图像弹孔区分；提出基于对象移除的数据增强方法模拟真实射击序列；引入ORB特征的透视校正预处理以统一靶纸朝向。

Result: 弹孔检测mAP达97.0%，弹孔归属正确迭代的准确率为88.8%。

Conclusion: 该系统可高效、自动完成步枪归零任务，其时序区分相似视觉目标的框架亦适用于其他领域。

Abstract: Adjusting rifle sights, a process commonly called "zeroing," requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects.

</details>


### [25] [A Mechanistic View on Video Generation as World Models: State and Dynamics](https://arxiv.org/abs/2601.17067)
*Luozhou Wang,Zhifei Chen,Yihua Du,Dongyu Yan,Wenhang Ge,Guibao Shen,Xinli Xu,Leyi Wu,Man Chen,Tianshuo Xu,Peiran Ren,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频生成世界模型分类法，聚焦于状态构建与动力学建模，并倡导从视觉保真度转向功能性评估，以推动视频生成模型向通用世界模拟器发展。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视频生成模型虽展现出物理一致性，但其“无状态”架构与经典以状态为中心的世界模型理论之间存在鸿沟。

Method: 提出以状态构建（隐式上下文管理 vs 显式潜在压缩）和动力学建模（知识集成 vs 架构重构）为双支柱的新分类体系，并主张采用物理持久性与因果推理等功能型评测基准。

Result: 明确了两大关键前沿方向：一是通过数据驱动记忆与压缩保真度提升状态持久性；二是通过潜在因子解耦与推理先验融合推进因果建模能力。

Conclusion: 只有解决状态持久性与因果推理两大挑战，视频生成模型才能从生成视觉上合理的视频，进化为构建鲁棒、通用的世界模拟器。

Abstract: Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary "stateless" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.

</details>


### [26] [Superpixel-Based Image Segmentation Using Squared 2-Wasserstein Distances](https://arxiv.org/abs/2601.17071)
*Jisui Huang,Andreas Alpers,Ke Chen,Na Lei*

Main category: cs.CV

TL;DR: 本文提出了一种基于两层聚类的图像分割方法：先用线性最小二乘分配（离散最优传输）生成超像素，再用2-Wasserstein距离合并超像素为对象级区域，兼顾精度与效率。


<details>
  <summary>Details</summary>
Motivation: 解决图像中强不均匀性下的分割难题，提升传统基于均值颜色距离的超像素合并策略的鲁棒性和准确性。

Method: 第一层：通过线性最小二乘分配问题（一种离散最优传输问题）将像素聚为超像素；第二层：基于各超像素经验分布间的平方2-Wasserstein距离，贪心合并为对象级区域。

Result: 在挑战性图像上显著提升分割精度，同时保持高计算效率。

Conclusion: 采用分布式的最优传输距离统一建模两层聚类，比传统均值距离更鲁棒、更准确，形成数学一致且实用的分割框架。

Abstract: We present an efficient method for image segmentation in the presence of strong inhomogeneities. The approach can be interpreted as a two-level clustering procedure: pixels are first grouped into superpixels via a linear least-squares assignment problem, which can be viewed as a special case of a discrete optimal transport (OT) problem, and these superpixels are subsequently greedily merged into object-level segments using the squared 2-Wasserstein distance between their empirical distributions. In contrast to conventional superpixel merging strategies based on mean-color distances, our framework employs a distributional OT distance, yielding a mathematically unified formulation across both clustering levels. Numerical experiments demonstrate that this perspective leads to improved segmentation accuracy on challenging images while retaining high computational efficiency.

</details>


### [27] [GlassesGB: Controllable 2D GAN-Based Eyewear Personalization for 3D Gaussian Blendshapes Head Avatars](https://arxiv.org/abs/2601.17088)
*Rui-Yang Ju,Jen-Shiun Chiang*

Main category: cs.CV

TL;DR: 本文提出GlassesGB框架，结合GlassesGAN的2D定制化生成能力和3D Gaussian Blendshapes的头部重建能力，实现面向VR应用的、支持用户驱动细粒度定制的3D眼镜生成。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试戴系统多局限于预定义眼镜模板，缺乏用户驱动的细粒度定制能力；GlassesGAN虽支持个性化2D眼镜设计，但无法拓展至3D；受3D Gaussian Blendshapes在头部重建中成功启发，作者旨在 bridging 2D生成与3D头像渲染以支持VR中的个性化眼镜设计。

Method: 将GlassesGAN的2D生成能力与3D Gaussian Blendshapes的头部建模技术相融合，构建端到端的GlassesGB框架，实现从用户定制输入到3D头像上可渲染眼镜的生成。

Result: GlassesGB成功实现了支持用户交互式定制的3D眼镜生成，并能自然融合到3D头像中，适用于VR场景；代码已开源。

Conclusion: GlassesGB有效弥合了2D生成式定制与3D头像渲染之间的鸿沟，为VR虚拟试戴提供了更灵活、个性化的3D眼镜生成解决方案。

Abstract: Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.

</details>


### [28] [GRASP: Guided Region-Aware Sparse Prompting for Adapting MLLMs to Remote Sensing](https://arxiv.org/abs/2601.17089)
*Qigan Sun,Chaoning Zhang,Jianwei Zhang,Xudong Wang,Jiehui Xie,Pengcheng Zheng,Haoyu Wang,Sungyoung Lee,Chi-lok Andy Tai,Yang Yang,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种面向遥感图像视觉问答的参数高效微调方法GRASP，通过空间结构化软提示与问题引导的稀疏融合机制，提升模型对目标区域的关注并抑制背景噪声。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在遥感图像VQA任务中易过拟合背景噪声或忽略目标细节，源于遥感图像的大尺度变化、目标稀疏分布和复杂区域语义特征。

Method: 提出参数高效微调策略GRASP：将空间块从冻结视觉token网格中提取，并关联空间结构化软提示；通过问题引导的稀疏融合机制，动态聚合任务上下文生成紧凑全局提示。

Result: 在多个RSVQA基准上实验表明，GRASP在保持高参数效率的同时，性能媲美现有微调与基于提示的方法。

Conclusion: GRASP有效缓解了遥感图像VQA中背景干扰与目标细节丢失问题，是一种兼顾性能与效率的新型PEFT方法。

Abstract: In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.

</details>


### [29] [LoD Sketch Extraction from Architectural Models Using Generative AI: Dataset Construction for Multi-Level Architectural Design Generation](https://arxiv.org/abs/2601.17095)
*Xusheng Du,Athiwat Kongkaeo,Ye Zhang,Haoran Xie*

Main category: cs.CV

TL;DR: 本文提出了一种基于生成式AI的自动多级细节（LoD）草图提取框架，用于从高细节建筑模型中自动生成几何一致、层次连贯的多LoD表示，解决了生成式AI在建筑多级建模中因缺乏高质量配对LoD训练数据而受限的问题。


<details>
  <summary>Details</summary>
Motivation: 传统LoD建模依赖人工操作，耗时费力且易导致几何不一致；而生成式AI在建筑多级建模中的应用受限于高质量配对LoD训练数据的缺乏。

Method: 提出一种融合计算机视觉与生成式AI的渐进式LoD草图提取框架，通过从高细节模型逐步简化，生成几何一致、层次连贯的多LoD表示。

Result: 实验表明该方法在LoD3→LoD2和LoD2→LoD1转换中SSIM分别达0.7319和0.7532，归一化Hausdorff距离分别为图像对角线的25.1%和61.0%，保持了良好的几何一致性与结构保真度。

Conclusion: 该框架能有效兼顾全局结构保持与语义层级简化，为AI驱动的多级建筑设计与分层建模提供了可靠的数据与技术支撑。

Abstract: For architectural design, representation across multiple Levels of Details (LoD) is essential for achieving a smooth transition from conceptual massing to detailed modeling. However, traditional LoD modeling processes rely on manual operations that are time-consuming, labor-intensive, and prone to geometric inconsistencies. While the rapid advancement of generative artificial intelligence (AI) has opened new possibilities for generating multi-level architectural models from sketch inputs, its application remains limited by the lack of high-quality paired LoD training data. To address this issue, we propose an automatic LoD sketch extraction framework using generative AI models, which progressively simplifies high-detail architectural models to automatically generate geometrically consistent and hierarchically coherent multi-LoD representations. The proposed framework integrates computer vision techniques with generative AI methods to establish a progressive extraction pipeline that transitions from detailed representations to volumetric abstractions. Experimental results demonstrate that the method maintains strong geometric consistency across LoD levels, achieving SSIM values of 0.7319 and 0.7532 for the transitions from LoD3 to LoD2 and from LoD2 to LoD1, respectively, with corresponding normalized Hausdorff distances of 25.1% and 61.0% of the image diagonal, reflecting controlled geometric deviation during abstraction. These results verify that the proposed framework effectively preserves global structure while achieving progressive semantic simplification across different LoD levels, providing reliable data and technical support for AI-driven multi-level architectural generation and hierarchical modeling.

</details>


### [30] [Performance uncertainty in medical image analysis: a large-scale investigation of confidence intervals](https://arxiv.org/abs/2601.17103)
*Pascaline André,Charles Heitz,Evangelia Christodoulou,Annika Reinke,Carole H. Sudre,Michela Antonelli,Patrick Godau,M. Jorge Cardoso,Antoine Gilson,Sophie Tezenas du Montcel,Gaël Varoquaux,Lena Maier-Hein,Olivier Colliot*

Main category: cs.CV

TL;DR: 本文通过大规模实证分析，系统评估了医学影像AI性能评估中置信区间（CI）方法的可靠性（覆盖率）与精确性（宽度），揭示了样本量、性能指标、聚合策略、任务类型及CI方法选择对CI表现的关键影响，为制定医学影像AI性能不确定性报告指南提供依据。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI的临床转化需要可靠的性能不确定性量化，但目前社区对多种置信区间（CI）方法在具体医学影像场景下的行为缺乏系统认知。

Method: 开展大规模实证分析，涵盖24个分割与分类任务、每组19个训练模型、多种常用性能指标、不同聚合策略（如macro/micro）以及若干主流CI方法，全面评估各CI方法在不同设置下的覆盖率（可靠性）和宽度（精确性）。

Result: 发现五点核心结论：1）可靠CI所需样本量因参数而异（几十至数千例）；2）性能指标选择显著影响CI行为；3）聚合策略（如macro比micro）显著影响CI可靠性；4）任务类型（分割vs分类）调制上述效应；5）不同CI方法在不同场景下可靠性与精确性不一。

Conclusion: 研究结果构成未来制定医学影像AI性能不确定性报告指南的关键基础，强调需根据具体任务、指标和聚合方式审慎选择CI方法与样本规模。

Abstract: Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.

</details>


### [31] [StealthMark: Harmless and Stealthy Ownership Verification for Medical Segmentation via Uncertainty-Guided Backdoors](https://arxiv.org/abs/2601.17107)
*Qinkai Yu,Chong Zhang,Gaojie Jin,Tianjin Huang,Wei Zhou,Wenhui Li,Xiaobo Jin,Bo Huang,Yitian Zhao,Guang Yang,Gregory Y. H. Lip,Yalin Zheng,Aline Villavicencio,Yanda Meng*

Main category: cs.CV

TL;DR: 本文提出了一种名为StealthMark的新方法，用于在黑盒条件下验证医学图像分割模型的所有权。该方法通过微妙调节模型不确定性嵌入QR码水印，不损害分割性能，具有隐蔽性、无害性和有效性。


<details>
  <summary>Details</summary>
Motivation: 医学数据标注成本高、专家稀缺，且涉及隐私与伦理问题；训练好的医学分割模型是重要知识产权，但现有模型保护技术主要针对分类和生成任务，对分割模型的保护研究不足。

Method: 提出StealthMark方法：在不改变最终分割输出的前提下，隐式调制模型不确定性；结合模型无关解释方法（如LIME）提取特征归因，在特定触发条件下揭示嵌入的QR码水印；水印设计为可识别、鲁棒的QR码形式。

Result: 在四个医学影像数据集和五个主流分割模型上验证有效；以SAM模型为例，ASR稳定高于95%，Dice和AUC下降<1%，显著优于后门式水印方法。

Conclusion: StealthMark是一种隐蔽、无害且实用的医学分割模型所有权验证方案，具备良好泛化性与部署潜力。

Abstract: Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.

</details>


### [32] [iFSQ: Improving FSQ for Image Generation with 1 Line of Code](https://arxiv.org/abs/2601.17124)
*Bin Lin,Zongjian Li,Yuwei Niu,Kaixiong Gong,Yunyang Ge,Yunlong Lin,Mingzhe Zheng,JianWei Zhang,Miles Yang,Zhao Zhong,Liefeng Bo,Li Yuan*

Main category: cs.CV

TL;DR: 本文提出iFSQ，通过分布匹配映射解决FSQ中激活坍塌问题，在保证重建精度的同时实现最优码本利用；并基于iFSQ揭示离散与连续表征的最优平衡点约为4比特/维，且在相同重建约束下，自回归模型收敛快但扩散模型上限更高；最后将REPA适配至AR模型，推出LlamaGen-REPA。


<details>
  <summary>Details</summary>
Motivation: 当前图像生成领域中自回归（离散token）与扩散（连续latent）模型分立，源于VQ-VAE与VAE的根本差异，阻碍统一建模与公平评测；FSQ虽提供理论桥梁，但其等间隔量化易致激活坍塌，造成重建保真度与信息效率难以兼顾。

Method: 提出iFSQ：将原始FSQ中的激活函数替换为分布匹配映射，强制隐空间服从均匀先验；该方法仅需一行代码修改，理论上保证最优bin利用率与重建精度；以此为可控基准，定量比较AR与扩散模型性能，并将Representation Alignment（REPA）方法迁移至AR模型，构建LlamaGen-REPA。

Result: 1）发现离散与连续表征的最优平衡点约为4 bits/dim；2）在相同重建约束下，AR模型初期收敛更快，但扩散模型最终性能上限更高；3）成功将REPA适配至AR模型，提升其生成质量。

Conclusion: iFSQ以极简设计弥合了离散与连续建模范式鸿沟，为统一评估与建模提供了新基准；实验表明二者并非简单优劣关系，而存在互补性权衡；所提方法与分析框架可推动图像生成基础研究与模型设计。

Abstract: The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ

</details>


### [33] [Scaling medical imaging report generation with multimodal reinforcement learning](https://arxiv.org/abs/2601.17151)
*Qianchu Liu,Sheng Zhang,Guanghui Qin,Yu Gu,Ying Jin,Sam Preston,Yanbo Xu,Sid Kiblawi,Wen-wai Yim,Tim Ossowski,Tristan Naumann,Mu Wei,Hoifung Poon*

Main category: cs.CV

TL;DR: 本文提出了一种名为UniRG的通用医学影像报告生成框架，利用强化学习直接优化面向应用的评估指标，显著优于监督微调，在胸片报告生成任务中达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 前沿大模型在多模态理解与推理（尤其是生物医学等高价值领域）上仍存在明显能力缺陷；现有监督微调方法易过拟合模板化语言模式，泛化性差。

Method: 提出Universal Report Generation (UniRG)框架，以强化学习为统一机制，直接优化面向终端应用设计的评估指标，提升泛化能力。具体实现UniRG-CXR模型，基于公开胸片数据训练。

Result: 在权威ReXrank基准上，UniRG-CXR取得整体SOTA性能，大幅超越此前最优方法。

Conclusion: 强化学习驱动的指标导向优化可有效克服监督微调的过拟合问题，实现跨机构、跨临床实践的鲁棒泛化，为医学影像报告生成提供了更可靠、可推广的范式。

Abstract: Frontier models have demonstrated remarkable capabilities in understanding and reasoning with natural-language text, but they still exhibit major competency gaps in multimodal understanding and reasoning especially in high-value verticals such as biomedicine. Medical imaging report generation is a prominent example. Supervised fine-tuning can substantially improve performance, but they are prone to overfitting to superficial boilerplate patterns. In this paper, we introduce Universal Report Generation (UniRG) as a general framework for medical imaging report generation. By leveraging reinforcement learning as a unifying mechanism to directly optimize for evaluation metrics designed for end applications, UniRG can significantly improve upon supervised fine-tuning and attain durable generalization across diverse institutions and clinical practices. We trained UniRG-CXR on publicly available chest X-ray (CXR) data and conducted a thorough evaluation in CXR report generation with rigorous evaluation scenarios. On the authoritative ReXrank benchmark, UniRG-CXR sets new overall SOTA, outperforming prior state of the art by a wide margin.

</details>


### [34] [LGDWT-GS: Local and Global Discrete Wavelet-Regularized 3D Gaussian Splatting for Sparse-View Scene Reconstruction](https://arxiv.org/abs/2601.17185)
*Shima Salehi,Atharva Agashe,Andrew J. McFarland,Joshua Peeples*

Main category: cs.CV

TL;DR: 本文提出了一种结合全局与局部频率正则化的新方法，用于稀疏视角下的少样本3D重建，提升了3D高斯点绘（3DGS）模型的几何稳定性与细节保真度，并发布了一个多光谱温室植物数据集及配套开源评测工具包。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯点绘（3DGS）模型在稀疏视角下进行少样本3D重建时，存在几何不稳定和细节丢失的关键问题。

Method: 提出融合全局与局部频率正则化的新方法，以稳定几何结构并保留精细细节；构建包含四个光谱波段的多光谱温室植物数据集；开发开源基准评测包，定义标准化少样本重建评估协议。

Result: 在自建多光谱数据集及标准基准上的实验表明，该方法相比现有基线实现了更锐利、更稳定且光谱一致性更好的3D重建效果。

Conclusion: 所提方法有效缓解了少样本3D重建中几何失稳与细节退化问题，所发布的数据集与评测工具为多光谱3DGS研究提供了重要基础资源。

Abstract: We propose a new method for few-shot 3D reconstruction that integrates global and local frequency regularization to stabilize geometry and preserve fine details under sparse-view conditions, addressing a key limitation of existing 3D Gaussian Splatting (3DGS) models. We also introduce a new multispectral greenhouse dataset containing four spectral bands captured from diverse plant species under controlled conditions. Alongside the dataset, we release an open-source benchmarking package that defines standardized few-shot reconstruction protocols for evaluating 3DGS-based methods. Experiments on our multispectral dataset, as well as standard benchmarks, demonstrate that the proposed method achieves sharper, more stable, and spectrally consistent reconstructions than existing baselines. The dataset and code for this work are publicly available

</details>


### [35] [Decoding Psychological States Through Movement: Inferring Human Kinesic Functions with Application to Built Environments](https://arxiv.org/abs/2601.17194)
*Cheyu Lin,Katherine A. Flanigan,Sirajum Munir*

Main category: cs.CV

TL;DR: 本文提出了DUET数据集和一种基于运动识别的框架，用于在保护隐私的前提下量化社会基础设施中的双向互动行为，以支持社会资本理论相关的社会互动测量。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一致且保护隐私的方法来表征和测量建成环境中具有社会意义的互动，导致研究难以评估设计干预是否真正影响了社会资本理论所关注的互动形式。

Method: 构建了包含12组双向互动的DUET数据集，覆盖五类Ekman-Friesen体态功能（象征、说明、情感表达、调节、适应），并结合多模态传感与骨骼运动数据，提出无需手工词典的迁移学习识别框架。

Result: 基准测试显示现有单人动作识别模型难以胜任双向社交互动的功能识别；新框架能直接从隐私保护的骨骼运动中推断体态功能，表现出功能聚类结构，并在跨被试和跨场景下具有良好泛化性。

Conclusion: DUET数据集与嵌入式体态识别框架为建成环境中的社会互动测量提供了可复现、隐私安全且理论对齐的新方法，填补了方法学与实践应用之间的关键空白。

Abstract: Social infrastructure and other built environments are increasingly expected to support well-being and community resilience by enabling social interaction. Yet in civil and built-environment research, there is no consistent and privacy-preserving way to represent and measure socially meaningful interaction in these spaces, leaving studies to operationalize "interaction" differently across contexts and limiting practitioners' ability to evaluate whether design interventions are changing the forms of interaction that social capital theory predicts should matter. To address this field-level and methodological gap, we introduce the Dyadic User Engagement DataseT (DUET) dataset and an embedded kinesics recognition framework that operationalize Ekman and Friesen's kinesics taxonomy as a function-level interaction vocabulary aligned with social capital-relevant behaviors (e.g., reciprocity and attention coordination). DUET captures 12 dyadic interactions spanning all five kinesic functions-emblems, illustrators, affect displays, adaptors, and regulators-across four sensing modalities and three built-environment contexts, enabling privacy-preserving analysis of communicative intent through movement. Benchmarking six open-source, state-of-the-art human activity recognition models quantifies the difficulty of communicative-function recognition on DUET and highlights the limitations of ubiquitous monadic, action-level recognition when extended to dyadic, socially grounded interaction measurement. Building on DUET, our recognition framework infers communicative function directly from privacy-preserving skeletal motion without handcrafted action-to-function dictionaries; using a transfer-learning architecture, it reveals structured clustering of kinesic functions and a strong association between representation quality and classification performance while generalizing across subjects and contexts.

</details>


### [36] [Structural Complexity of Brain MRI reveals age-associated patterns](https://arxiv.org/abs/2601.17211)
*Anzhe Cheng,Italo Ivo Lima Dias Pinto,Paul Bogdan*

Main category: cs.CV

TL;DR: 本文提出了一种适用于三维信号（特别是脑部MRI）的结构复杂度分析框架，通过滑动窗口粗粒化方法改进了传统块状方法在大尺度下的不稳定性，并发现脑结构复杂度随年龄增长而系统性下降，尤其在较粗尺度上表现显著，可作为预测生物年龄的有效工具。


<details>
  <summary>Details</summary>
Motivation: 传统基于块的粗粒化方法在处理三维MRI等高维信号时，在粗分辨率下因采样不足而变得不稳定，亟需一种更鲁棒的多尺度复杂度分析方法。

Method: 将结构复杂度分析扩展至三维信号，提出滑动窗口粗粒化方案替代传统块状方法，以实现更平滑、更稳健的大尺度信息损失量化。

Result: 在中老年结构性MRI大数据集上验证发现，脑结构复杂度随年龄增长系统性下降，且该效应在更粗的空间尺度上最为显著。

Conclusion: 结构复杂度是一种可靠的三维影像多尺度分析工具，不仅提升了方法鲁棒性，还展现出预测个体生物年龄的潜在临床价值。

Abstract: We adapt structural complexity analysis to three-dimensional signals, with an emphasis on brain magnetic resonance imaging (MRI). This framework captures the multiscale organization of volumetric data by coarse-graining the signal at progressively larger spatial scales and quantifying the information lost between successive resolutions. While the traditional block-based approach can become unstable at coarse resolutions due to limited sampling, we introduce a sliding-window coarse-graining scheme that provides smoother estimates and improved robustness at large scales. Using this refined method, we analyze large structural MRI datasets spanning mid- to late adulthood and find that structural complexity decreases systematically with age, with the strongest effects emerging at coarser scales. These findings highlight structural complexity as a reliable signal processing tool for multiscale analysis of 3D imaging data, while also demonstrating its utility in predicting biological age from brain MRI.

</details>


### [37] [Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction](https://arxiv.org/abs/2601.17216)
*Murat Arda Onsu,Poonam Lohan,Burak Kantarci,Aisha Syed,Matthew Andrews,Sean Kennedy*

Main category: cs.CV

TL;DR: 本文提出了一种基于语义V2X的实时碰撞预测框架，利用RSU端的V-JEPA模型生成未来帧的时空语义嵌入，仅传输轻量级语义信息而非原始视频，在大幅降低通信开销的同时提升预测准确率。


<details>
  <summary>Details</summary>
Motivation: 传统ITS中传输原始视频或高维感知数据受限于车载通信带宽和时延，难以满足实时碰撞预测需求。

Method: 提出语义V2X框架：RSU端用V-JEPA模型生成未来帧的时空语义嵌入；构建城市交通数字孪生环境生成多样化场景；车辆端用轻量级注意力探针与分类器解码嵌入以预测碰撞。

Result: 相比原始视频传输，通信需求降低四个数量级，F1-score提升10%。

Conclusion: 语义V2X通信可有效支撑ITS中协作式、实时的碰撞预测任务。

Abstract: Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.

</details>


### [38] [Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification](https://arxiv.org/abs/2601.17228)
*Tengyue Zhang,Ruiwen Ding,Luoting Zhuang,Yuxiao Wu,Erika F. Rodriguez,William Hsu*

Main category: cs.CV

TL;DR: 本文提出了一种基于潜在扩散模型的半监督域自适应（SSDA）框架，利用源域和目标域的无标签数据生成形态保持且目标域感知的合成图像，以提升计算病理学中深度学习模型的跨机构泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在计算病理学中常因域偏移而在不同队列和机构间泛化失败；现有方法要么未充分利用目标域无标签数据，要么依赖图像到图像翻译而损害组织结构。

Method: 构建一个条件潜在扩散模型，以基础模型特征、队列身份和组织制备方法为条件，生成保留源域组织结构但具备目标域外观特性的合成图像；结合源域标注数据训练下游分类器。

Result: 在肺腺癌预后预测任务上，目标队列测试集加权F1从0.611提升至0.706，宏F1从0.641提升至0.716，且未损害源队列性能。

Conclusion: 目标域感知的扩散模型合成数据增强是提升计算病理学域泛化能力的有效新途径。

Abstract: Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.

</details>


### [39] [C-RADIOv4 (Tech Report)](https://arxiv.org/abs/2601.17237)
*Mike Ranzinger,Greg Heinrich,Collin McCarthy,Jan Kautz,Andrew Tao,Bryan Catanzaro,Pavlo Molchanov*

Main category: cs.CV

TL;DR: C-RADIOv4 是一种基于多教师蒸馏的视觉骨干网络，通过融合 SigLIP2、DINOv3 和 SAM3 等多个教师模型的能力，在保持计算复杂度不变的前提下，显著提升了下游任务性能，并增强了任意分辨率支持与高分辨率效率。


<details>
  <summary>Details</summary>
Motivation: 提升视觉骨干模型在多任务、多分辨率场景下的泛化能力与效率，同时整合不同教师模型（如SAM3）的独特能力。

Method: 采用多教师知识蒸馏方法，构建统一学生模型；更新教师集合为SigLIP2、DINOv3和SAM3；引入ViTDet选项以提升高分辨率效率；支持任意分辨率输入。

Result: C-RADIOv4 在核心指标上显著提升，新增对SAM3能力的模仿，增强任意分辨率支持，恢复ViTDet选项以提高高分辨率效率，并提供宽松许可。

Conclusion: C-RADIOv4 通过多教师蒸馏实现了性能、灵活性与效率的协同提升，是面向实际部署的先进视觉骨干模型。

Abstract: By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.

</details>


### [40] [Multi-stage Bridge Inspection System: Integrating Foundation Models with Location Anonymization](https://arxiv.org/abs/2601.17254)
*Takato Yasuno*

Main category: cs.CV

TL;DR: 本文提出了一种开源桥梁损伤检测系统，结合SAM3模型进行钢筋腐蚀检测、DBSCAN算法补全遗漏区域、高斯模糊保护施工标识区域，并通过四种预处理方法提升OCR准确率，GPU优化实现每图1.7秒处理速度，兼顾损伤识别精度与区域隐私保护。


<details>
  <summary>Details</summary>
Motivation: 在日本，基础设施需每五年进行一次目视检查，而现场采集的损伤图像常包含混凝土裂缝、钢筋暴露及揭示地域信息的施工标识；为保障基础设施安全使用且避免引发公众焦虑，亟需在精准提取损伤特征、可视化维修关键指标的同时，有效保护地域隐私信息。

Method: 采用Segment Anything Model (SAM3) 进行钢筋腐蚀检测，利用DBSCAN自动补全检测遗漏区域；对施工标识区域采用高斯模糊进行隐私保护；设计四种图像预处理方法以提高OCR识别准确率；并基于GPU加速优化整体处理流程。技术栈包括SAM3、PyTorch、OpenCV、pytesseract和scikit-learn。

Result: 系统实现了每张图像1.7秒的高效处理速度，在准确识别桥梁损伤（如混凝土裂缝、钢筋腐蚀）的同时，有效隐藏了施工标识所含的地域信息，提升了OCR识别精度，并支持维修决策所需的关键指标可视化。

Conclusion: 该系统在保证桥梁损伤检测精度与效率的同时，成功实现了区域隐私保护，为合规、安全、可信的基础设施智能巡检提供了可复用的开源解决方案。

Abstract: In Japan, civil infrastructure condition monitoring is mandated through visual inspection every five years. Field-captured damage images frequently contain concrete cracks and rebar exposure, often accompanied by construction signs revealing regional information. To enable safe infrastructure use without causing public anxiety, it is essential to protect regional information while accurately extracting damage features and visualizing key indicators for repair decision-making. This paper presents an open-source bridge damage detection system with regional privacy protection capabilities. We employ Segment Anything Model (SAM) 3 for rebar corrosion detection and utilize DBSCAN for automatic completion of missed regions. Construction sign regions are detected and protected through Gaussian blur. Four preprocessing methods improve OCR accuracy, and GPU optimization enables 1.7-second processing per image. The technology stack includes SAM3, PyTorch, OpenCV, pytesseract, and scikit-learn, achieving efficient bridge inspection with regional information protection.

</details>


### [41] [FineVAU: A Novel Human-Aligned Benchmark for Fine-Grained Video Anomaly Understanding](https://arxiv.org/abs/2601.17258)
*João Pereira,Vasco Lopes,João Neves,David Semedo*

Main category: cs.CV

TL;DR: 本文提出FineVAU基准，聚焦视频异常理解（VAU）任务，通过FVScore指标和FineW3数据集，强调对异常事件（What）、参与实体（Who）和位置（Where）的细粒度、视觉 grounded 理解，并揭示当前LVLM在时空细粒度异常感知上的关键局限。


<details>
  <summary>Details</summary>
Motivation: 现有VAU评估方法（n-gram或LLM-based）无法有效捕捉LVLM回答中丰富的、自由形式的、视觉接地的特性，且主观性强、与人类感知错位。

Method: 提出FineVAU基准，将VAU建模为三要素（What/Who/Where）理解问题；设计人类对齐的细粒度评估指标FVScore；构建全自动增强的细粒度数据集FineW3。

Result: FVScore在人类评估中显著优于现有指标；实验揭示LVLM在需空间与细粒度时序理解的异常事件上存在明显短板，但在粗粒度、静态或强视觉线索事件上表现良好。

Conclusion: FineVAU推动VAU评估向更精细、更视觉 grounded、更符合人类感知的方向发展，并暴露了当前LVLM在复杂时空异常理解上的根本性瓶颈。

Abstract: Video Anomaly Understanding (VAU) is a novel task focused on describing unusual occurrences in videos. Despite growing interest, the evaluation of VAU remains an open challenge. Existing benchmarks rely on n-gram-based metrics (e.g., BLEU, ROUGE-L) or LLM-based evaluation. The first fails to capture the rich, free-form, and visually grounded nature of LVLM responses, while the latter focuses on assessing language quality over factual relevance, often resulting in subjective judgments that are misaligned with human perception. In this work, we address this issue by proposing FineVAU, a new benchmark for VAU that shifts the focus towards rich, fine-grained and domain-specific understanding of anomalous videos. We formulate VAU as a three-fold problem, with the goal of comprehensively understanding key descriptive elements of anomalies in video: events (What), participating entities (Who) and location (Where). Our benchmark introduces a) FVScore, a novel, human-aligned evaluation metric that assesses the presence of critical visual elements in LVLM answers, providing interpretable, fine-grained feedback; and b) FineW3, a novel, comprehensive dataset curated through a structured and fully automatic procedure that augments existing human annotations with high quality, fine-grained visual information. Human evaluation reveals that our proposed metric has a superior alignment with human perception of anomalies in comparison to current approaches. Detailed experiments on FineVAU unveil critical limitations in LVLM's ability to perceive anomalous events that require spatial and fine-grained temporal understanding, despite strong performance on coarse grain, static information, and events with strong visual cues.

</details>


### [42] [PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation](https://arxiv.org/abs/2601.17885)
*Qingyu Fan,Zhaoxiang Li,Yi Lu,Wang Chen,Qiu Shen,Xiao-xiao Long,Yinghao Cai,Tao Lu,Shuo Wang,Xun Cao*

Main category: cs.CV

TL;DR: 本文提出PEAfowl模型，通过深度分布预测与3D提升、跨视角几何一致性表征、以及Perceiver式文本感知读出机制，提升了双臂操作在杂乱场景下的泛化性与指令理解能力，并通过训练时深度蒸馏增强几何先验。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型在双臂操作任务中因多视角特征融合方式缺乏3D一致性、语言作为全局条件导致指令定位粗粒度，难以应对遮挡、视角和场景变化。

Method: PEAfowl采用三方面创新：1）每token深度分布预测+可微3D提升+局部跨视角邻域聚合，实现几何对齐的多视图表征；2）用Perceiver风格的文本感知读出机制替代全局语言条件，在冻结CLIP视觉特征上迭代累积文本相关证据；3）训练阶段引入预训练深度教师模型进行深度分布蒸馏，不增加推理开销。

Result: 在RoboTwin 2.0仿真平台（域随机化设置）上，相比最强基线提升23.0个百分点成功率；真实机器人实验验证了良好的sim-to-real迁移能力及深度蒸馏带来的持续性能增益。

Conclusion: PEAfowl通过增强空间感知与细粒度指令接地，显著提升了双臂操作策略在复杂、动态场景中的鲁棒性与泛化性，为VLA模型设计提供了几何感知与语言交互协同的新范式。

Abstract: Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding.
  In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors.
  On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation.
  Project website: https://peafowlvla.github.io/.

</details>


### [43] [Cross360: 360° Monocular Depth Estimation via Cross Projections Across Scales](https://arxiv.org/abs/2601.17271)
*Kun Huang,Fang-Lue Zhang,Neil Dodgson*

Main category: cs.CV

TL;DR: 本文提出Cross360，一种基于交叉注意力机制的360°深度估计方法，通过融合低畸变切线投影局部特征与等距柱状图全局特征，提升全局一致性与精度。


<details>
  <summary>Details</summary>
Motivation: 现有360°深度估计方法难以兼顾球面图像的全局连续性与局部无畸变表达，局部补丁特征缺乏全局感知，而全局表示又忽略补丁边界处的特征不一致问题。

Method: 提出Cross360架构，包含Cross Projection Feature Alignment模块（利用交叉注意力对齐切线投影局部特征与等距柱状图全局特征）和Progressive Feature Aggregation with Attention模块（渐进式聚合多尺度特征）。

Result: 在多个基准数据集上显著优于现有方法，尤其在完整360°图像可用场景下表现突出。

Conclusion: Cross360有效实现了高精度、全局一致的360°深度估计，代码与模型已开源。

Abstract: 360° depth estimation is a challenging research problem due to the difficulty of finding a representation that both preserves global continuity and avoids distortion in spherical images. Existing methods attempt to leverage complementary information from multiple projections, but struggle with balancing global and local consistency. Their local patch features have limited global perception, and the combined global representation does not address discrepancies in feature extraction at the boundaries between patches. To address these issues, we propose Cross360, a novel cross-attention-based architecture integrating local and global information using less-distorted tangent patches along with equirectangular features. Our Cross Projection Feature Alignment module employs cross-attention to align local tangent projection features with the equirectangular projection's 360° field of view, ensuring each tangent projection patch is aware of the global context. Additionally, our Progressive Feature Aggregation with Attention module refines multi-scaled features progressively, enhancing depth estimation accuracy. Cross360 significantly outperforms existing methods across most benchmark datasets, especially those in which the entire 360° image is available, demonstrating its effectiveness in accurate and globally consistent depth estimation. The code and model are available at https://github.com/huangkun101230/Cross360.

</details>


### [44] [Masked Depth Modeling for Spatial Perception](https://arxiv.org/abs/2601.17895)
*Bin Tan,Changjiang Sun,Xiage Qin,Hanat Adai,Zelin Fu,Tianxiang Zhou,Han Zhang,Yinghao Xu,Xing Zhu,Yujun Shen,Nan Xue*

Main category: cs.CV

TL;DR: 本文提出LingBot-Depth模型，通过掩码深度建模与视觉上下文融合来提升RGB-D深度图精度与覆盖，超越高端硬件性能，并提供大规模真实+仿真RGB-深度数据集。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D相机受限于硬件与成像条件（如镜面、无纹理表面），导致深度测量不准确；作者将这些误差视为反映几何模糊性的‘掩码信号’，由此出发设计深度补全方法。

Method: 提出LingBot-Depth深度完成模型，结合掩码深度建模与视觉上下文引导的深度 refinement，并构建自动化数据清洗流程以支持可扩展训练。

Result: 在深度精度和像素覆盖率上均优于顶级RGB-D相机；下游任务验证其RGB与深度模态间具备对齐的潜在表征；公开代码、模型权重及300万RGB-深度图像对（200万真实+100万仿真）。

Conclusion: 掩码深度建模是一种有效利用视觉上下文缓解传感器局限的新范式，LingBot-Depth为低成本高精度空间感知提供了可行路径。

Abstract: Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as "masked" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.

</details>


### [45] [Fluxamba: Topology-Aware Anisotropic State Space Models for Geological Lineament Segmentation in Multi-Source Remote Sensing](https://arxiv.org/abs/2601.17288)
*Jin Bai,Huiyao Zhang,Qi Wen,Shengyang Li,Xiaolin Tian,Atta ur Rahman*

Main category: cs.CV

TL;DR: 本文提出Fluxamba，一种轻量级地质线性特征分割架构，通过拓扑感知的特征校正框架（含结构通量块SFB、分层空间调节器HSR和高保真聚焦单元HFFU）解决传统状态空间模型因轴对齐扫描导致的拓扑失配问题，在多个地质数据集上达到SOTA性能，兼顾高精度与实时部署能力。


<details>
  <summary>Details</summary>
Motivation: 现有状态空间模型（SSMs）因依赖刚性轴对齐扫描路径，与地质线性特征的各向异性、弯曲拓扑不匹配，导致上下文碎片化和特征退化，难以实现精确分割。

Method: 提出Fluxamba架构，核心是结构通量块（SFB），结合各向异性结构门（ASG）与先验调制流（PMF），解耦特征方向与空间位置，沿目标内在几何动态聚合上下文；并引入分层空间调节器（HSR）进行多尺度语义对齐，以及高保真聚焦单元（HFFU）提升低对比度下微弱特征的信噪比。

Result: 在LROC-Lineament、LineaMapper和GeoCrack等多样地质基准上达到新SOTA：LROC-Lineament上F1达89.22%，mIoU达89.87%；推理速度超24 FPS，仅3.4M参数、6.3G FLOPs，计算成本较重型基线降低两个数量级。

Conclusion: Fluxamba成功弥合了长程依赖建模与地质拓扑结构之间的鸿沟，在分割精度与嵌入式实时部署可行性之间建立了新的Pareto前沿。

Abstract: The precise segmentation of geological linear features, spanning from planetary lineaments to terrestrial fractures, demands capturing long-range dependencies across complex anisotropic topologies. Although State Space Models (SSMs) offer near-linear computational complexity, their dependence on rigid, axis-aligned scanning trajectories induces a fundamental topological mismatch with curvilinear targets, resulting in fragmented context and feature erosion. To bridge this gap, we propose Fluxamba, a lightweight architecture that introduces a topology-aware feature rectification framework. Central to our design is the Structural Flux Block (SFB), which orchestrates an anisotropic information flux by integrating an Anisotropic Structural Gate (ASG) with a Prior-Modulated Flow (PMF). This mechanism decouples feature orientation from spatial location, dynamically gating context aggregation along the target's intrinsic geometry rather than rigid paths. Furthermore, to mitigate serialization-induced noise in low-contrast environments, we incorporate a Hierarchical Spatial Regulator (HSR) for multi-scale semantic alignment and a High-Fidelity Focus Unit (HFFU) to explicitly maximize the signal-to-noise ratio of faint features. Extensive experiments on diverse geological benchmarks (LROC-Lineament, LineaMapper, and GeoCrack) demonstrate that Fluxamba establishes a new state-of-the-art. Notably, on the challenging LROC-Lineament dataset, it achieves an F1-score of 89.22% and mIoU of 89.87%. Achieving a real-time inference speed of over 24 FPS with only 3.4M parameters and 6.3G FLOPs, Fluxamba reduces computational costs by up to two orders of magnitude compared to heavy-weight baselines, thereby establishing a new Pareto frontier between segmentation fidelity and onboard deployment feasibility.

</details>


### [46] [Dynamic Meta-Ensemble Framework for Efficient and Accurate Deep Learning in Plant Leaf Disease Detection on Resource-Constrained Edge Devices](https://arxiv.org/abs/2601.17290)
*Weloday Fikadu Moges,Jianmei Su,Amin Waqas*

Main category: cs.CV

TL;DR: 本文提出了一种动态元集成框架（DMEF），通过自适应加权融合三个轻量CNN模型（MobileNetV2、NASNetMobile、InceptionV3），在边缘设备资源受限条件下实现高精度植物病害检测。


<details>
  <summary>Details</summary>
Motivation: 边缘设备（如IoT传感器、智能手机）计算资源和能耗有限，难以部署高精度深度学习模型用于植物病害检测。

Method: 提出动态元集成框架（DMEF），采用基于准确率提升（DeltaAcc）与模型大小权衡的自适应权重机制，在训练中迭代更新各子模型权重，优先选择高性能低复杂度模型。

Result: 在马铃薯和玉米病害数据集上分别达到99.53%和96.61%分类精度，较单模型和静态集成分别提升2.1%和6.3%；推理延迟<75ms，参数量<1M。

Conclusion: DMEF在保持高精度的同时显著降低计算开销，有效弥合了高精度AI模型与农业边缘实际应用之间的鸿沟，具备规模化作物病害管理潜力。

Abstract: Deploying deep learning models for plant disease detection on edge devices such as IoT sensors, smartphones, and embedded systems is severely constrained by limited computational resources and energy budgets. To address this challenge, we introduce a novel Dynamic Meta-Ensemble Framework (DMEF) for high-accuracy plant disease diagnosis under resource constraints. DMEF employs an adaptive weighting mechanism that dynamically combines the predictions of three lightweight convolutional neural networks (MobileNetV2, NASNetMobile, and InceptionV3) by optimizing a trade-off between accuracy improvements (DeltaAcc) and computational efficiency (model size). During training, the ensemble weights are updated iteratively, favoring models exhibiting high performance and low complexity. Extensive experiments on benchmark datasets for potato and maize diseases demonstrate state-of-the-art classification accuracies of 99.53% and 96.61%, respectively, surpassing standalone models and static ensembles by 2.1% and 6.3%. With computationally efficient inference latency (<75ms) and a compact footprint (<1 million parameters), DMEF shows strong potential for edge-based agricultural monitoring, suggesting viability for scalable crop disease management. This bridges the gap between high-accuracy AI and practical field applications.

</details>


### [47] [Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning](https://arxiv.org/abs/2601.18714)
*Judith Vilella-Cantos,Mauro Martini,Marcello Chiaberge,Mónica Ballesta,David Valiente*

Main category: cs.CV

TL;DR: 本文提出了一种名为MinkUNeXt-VINE的轻量级深度学习方法，用于在葡萄园等农业环境中实现高效、鲁棒的机器人定位与地点识别，特别适配低成本稀疏LiDAR输入，并通过预处理和Matryoshka表征学习多损失策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 农业环境结构化程度低、缺乏显著路标，导致机器人定位和地点识别困难；现有方法在该场景下表现不足。

Method: 提出MinkUNeXt-VINE模型，采用轻量化网络架构，结合定制预处理流程与Matryoshka Representation Learning多损失训练策略，适配稀疏LiDAR输入并输出低维特征。

Result: 在两个长期葡萄园数据集（使用不同LiDAR传感器）上显著超越当前最优方法，展现出对低分辨率、低成本输入的强鲁棒性与实时高效性；消融实验验证了各模块有效性。

Conclusion: MinkUNeXt-VINE为农业机器人提供了实用、高效、可部署的地点识别方案，兼顾精度、速度与硬件适应性，代码已开源。

Abstract: Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.

</details>


### [48] [ClinNet: Evidential Ordinal Regression with Bilateral Asymmetry and Prototype Memory for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17315)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

TL;DR: 本文提出ClinNet，一种用于膝骨关节炎（KOA）X光分级的可信框架，将问题建模为基于证据的序数回归，结合双侧不对称编码器、诊断记忆库和基于NIG分布的序数头，显著提升性能并提供可解释的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: KOA放射学分级面临细粒度差异、专家标注不确定性及疾病进展固有序数性等挑战，传统多分类方法忽略连续退变进程与标注不确定性。

Method: 提出ClinNet框架，包含：(1) 双侧不对称编码器（BAE）建模内外侧结构差异；(2) 诊断记忆库稳定类原型特征；(3) 基于正态-逆伽马（NIG）分布的证据序数头，联合预测KL等级与认知不确定性。

Result: ClinNet在Quadratic Weighted Kappa达0.892，准确率0.768，显著优于SOTA（p < 0.001）；其不确定性估计可有效识别分布外样本与潜在误诊。

Conclusion: ClinNet通过证据序数回归建模提升了KOA分级的准确性与可信度，不确定性输出支持临床安全部署。

Abstract: Knee osteoarthritis (KOA) grading based on radiographic images is a critical yet challenging task due to subtle inter-grade differences, annotation uncertainty, and the inherently ordinal nature of disease progression. Conventional deep learning approaches typically formulate this problem as deterministic multi-class classification, ignoring both the continuous progression of degeneration and the uncertainty in expert annotations. In this work, we propose ClinNet, a novel trustworthy framework that addresses KOA grading as an evidential ordinal regression problem. The proposed method integrates three key components: (1) a Bilateral Asymmetry Encoder (BAE) that explicitly models medial-lateral structural discrepancies; (2) a Diagnostic Memory Bank that maintains class-wise prototypes to stabilize feature representations; and (3) an Evidential Ordinal Head based on the Normal-Inverse-Gamma (NIG) distribution to jointly estimate continuous KL grades and epistemic uncertainty. Extensive experiments demonstrate that ClinNet achieves a Quadratic Weighted Kappa of 0.892 and Accuracy of 0.768, statistically outperforming state-of-the-art baselines (p < 0.001). Crucially, we demonstrate that the model's uncertainty estimates successfully flag out-of-distribution samples and potential misdiagnoses, paving the way for safe clinical deployment.

</details>


### [49] [SkyReels-V3 Technique Report](https://arxiv.org/abs/2601.17323)
*Debang Li,Zhengcong Fei,Tuanhui Li,Yikun Dou,Zheng Chen,Jiangping Yang,Mingyuan Fan,Jingtao Xu,Jiahua Wang,Baoxuan Gu,Mingshan Chang,Yuqiang Xie,Binjie Mao,Youqiang Zhang,Nuo Pang,Hao Zhang,Yuzhe Jin,Zhiheng Xu,Dixuan Lin,Guibin Chen,Yahui Zhou*

Main category: cs.CV

TL;DR: SkyReels-V3是一个基于扩散Transformer的统一多模态上下文学习框架的条件视频生成模型，支持图像到视频、视频扩展和音频引导视频生成三种范式，在视觉质量、指令遵循等方面达到SOTA或接近SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 提升视频生成模型在多模态上下文推理能力，尤其是世界建模中的核心能力；解决现有方法中主体身份保持差、时序不连贯、叙事不一致、参考粘贴伪影、音画不同步等问题。

Method: 提出SkyReels-V3模型，基于扩散Transformer与统一多模态上下文学习框架；设计跨帧配对、图像编辑与语义重写的数据处理流程；采用图像-视频混合训练策略与多分辨率联合优化；引入时空一致性建模与大规模视频理解机制；构建首尾帧插入与关键帧重建的说话人像生成范式。

Result: 在视觉质量、指令遵循、特定维度指标上达到SOTA或近SOTA，性能逼近领先闭源系统；支持三类生成任务且保持高保真度、强身份一致性、时序连贯性、叙事一致性和音画同步性。

Conclusion: SkyReels-V3验证了统一多模态上下文学习框架在复杂条件视频生成任务中的有效性与可扩展性，为构建具备强推理能力的世界模型提供了新路径。

Abstract: Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.
  Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.

</details>


### [50] [SymbolSight: Minimizing Inter-Symbol Interference for Reading with Prosthetic Vision](https://arxiv.org/abs/2601.17326)
*Jasmine Lesner,Michael Beyeler*

Main category: cs.CV

TL;DR: 本文提出SymbolSight计算框架，通过优化视网膜假体中字母与符号的映射关系，减少因视觉暂留导致的相邻字母识别混淆，显著提升阅读准确性。


<details>
  <summary>Details</summary>
Motivation: 视网膜假体空间分辨率低、存在时间残留，导致顺序呈现字母时产生干扰性后像，影响阅读；本文旨在不依赖硬件升级的前提下，通过优化符号设计缓解该问题。

Method: 构建SymbolSight框架，结合模拟假体视觉（SPV）与神经代理观察者估计符号两两混淆度，并利用语言特异性双字母统计优化符号-字母映射。

Result: 在阿拉伯语、保加利亚语和英语仿真中，所生成的异构符号集相较原生字母表，预测混淆率中位数降低22倍。

Conclusion: 标准字体不适配序列式低带宽假体视觉；计算建模可高效缩小视觉编码设计空间，为后续心理物理与临床验证提供高潜力候选方案。

Abstract: Retinal prostheses restore limited visual perception, but low spatial resolution and temporal persistence make reading difficult. In sequential letter presentation, the afterimage of one symbol can interfere with perception of the next, leading to systematic recognition errors. Rather than relying on future hardware improvements, we investigate whether optimizing the visual symbols themselves can mitigate this temporal interference. We present SymbolSight, a computational framework that selects symbol-to-letter mappings to minimize confusion among frequently adjacent letters. Using simulated prosthetic vision (SPV) and a neural proxy observer, we estimate pairwise symbol confusability and optimize assignments using language-specific bigram statistics. Across simulations in Arabic, Bulgarian, and English, the resulting heterogeneous symbol sets reduced predicted confusion by a median factor of 22 relative to native alphabets. These results suggest that standard typography is poorly matched to serial, low-bandwidth prosthetic vision and demonstrate how computational modeling can efficiently narrow the design space of visual encodings to generate high-potential candidates for future psychophysical and clinical evaluation.

</details>


### [51] [Learning with Geometric Priors in U-Net Variants for Polyp Segmentation](https://arxiv.org/abs/2601.17331)
*Fabian Vazquez,Jose A. Nuñez,Diego Adame,Alissen Moreno,Augustin Zhan,Huimin Li,Jinghao Yang,Haoteng Tang,Bin Fu,Pengfei Gu*

Main category: cs.CV

TL;DR: 本文提出了一种几何先验引导模块（GPM），通过引入显式几何先验（由微调的VGGT在ColonDepth数据集上生成的深度图提供）来增强U-Net类模型在结肠镜图像中对低对比度和杂乱场景下息肉分割的鲁棒性，GPM可即插即用，并在五个公开数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN、Transformer和Mamba的U-Net变体在息肉分割中仍难以有效捕捉几何与结构线索，尤其在低对比度或杂乱结肠镜场景中性能受限。

Method: 提出几何先验引导模块（GPM）：1）在模拟的ColonDepth数据集上微调Visual Geometry Grounded Transformer（VGGT）以生成适配内窥镜域的息肉深度图；2）GPM利用这些深度图将几何先验注入U-Net编码器特征图；3）结合空间与通道注意力机制进一步优化特征表达；4）GPM为即插即用模块，兼容多种U-Net变体。

Result: 在五个公开息肉分割数据集上，GPM在三个强基线模型上均取得一致性能提升。

Conclusion: 显式引入几何先验能有效增强息肉分割模型对复杂结肠镜场景的鲁棒性，GPM作为一种轻量、通用的模块，为医学图像分割提供了新思路。

Abstract: Accurate and robust polyp segmentation is essential for early colorectal cancer detection and for computer-aided diagnosis. While convolutional neural network-, Transformer-, and Mamba-based U-Net variants have achieved strong performance, they still struggle to capture geometric and structural cues, especially in low-contrast or cluttered colonoscopy scenes. To address this challenge, we propose a novel Geometric Prior-guided Module (GPM) that injects explicit geometric priors into U-Net-based architectures for polyp segmentation. Specifically, we fine-tune the Visual Geometry Grounded Transformer (VGGT) on a simulated ColonDepth dataset to estimate depth maps of polyp images tailored to the endoscopic domain. These depth maps are then processed by GPM to encode geometric priors into the encoder's feature maps, where they are further refined using spatial and channel attention mechanisms that emphasize both local spatial and global channel information. GPM is plug-and-play and can be seamlessly integrated into diverse U-Net variants. Extensive experiments on five public polyp segmentation datasets demonstrate consistent gains over three strong baselines. Code and the generated depth maps are available at: https://github.com/fvazqu/GPM-PolypSeg

</details>


### [52] [AGE-Net: Spectral--Spatial Fusion and Anatomical Graph Reasoning with Evidential Ordinal Regression for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17336)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

TL;DR: 本文提出AGE-Net，一种基于ConvNeXt的KL分级自动评估框架，融合频谱-空间融合、解剖图推理和差异细化模块，并采用NIG证据回归头与序数排序约束，显著提升膝关节X光片KL分级精度与不确定性建模能力。


<details>
  <summary>Details</summary>
Motivation: KL分级自动化面临细微结构变化、长程解剖依赖及等级边界模糊等挑战。

Method: 提出AGE-Net框架，包含Spectral-Spatial Fusion (SSF)、Anatomical Graph Reasoning (AGR) 和 Differential Refinement (DFR) 模块；采用Normal-Inverse-Gamma (NIG)证据回归头建模预测不确定性，并引入成对序数排序约束保持等级序关系。

Result: 在膝关节KL数据集上QWK达0.9017±0.0045，MSE为0.2349±0.0028，优于强CNN基线，消融实验验证各模块有效性；同时评估了不确定性质量、鲁棒性与可解释性。

Conclusion: AGE-Net通过多尺度特征融合、解剖结构建模与不确定性感知回归，在KL分级任务中实现了高精度与可靠性，为临床辅助诊断提供了新方法。

Abstract: Automated Kellgren--Lawrence (KL) grading from knee radiographs is challenging due to subtle structural changes, long-range anatomical dependencies, and ambiguity near grade boundaries. We propose AGE-Net, a ConvNeXt-based framework that integrates Spectral--Spatial Fusion (SSF), Anatomical Graph Reasoning (AGR), and Differential Refinement (DFR). To capture predictive uncertainty and preserve label ordinality, AGE-Net employs a Normal-Inverse-Gamma (NIG) evidential regression head and a pairwise ordinal ranking constraint. On a knee KL dataset, AGE-Net achieves a quadratic weighted kappa (QWK) of 0.9017 +/- 0.0045 and a mean squared error (MSE) of 0.2349 +/- 0.0028 over three random seeds, outperforming strong CNN baselines and showing consistent gains in ablation studies. We further outline evaluations of uncertainty quality, robustness, and explainability, with additional experimental figures to be included in the full manuscript.

</details>


### [53] [TEXTS-Diff: TEXTS-Aware Diffusion Model for Real-World Text Image Super-Resolution](https://arxiv.org/abs/2601.17340)
*Haodong He,Xin Zhan,Yancheng Bai,Rui Lan,Lei Sun,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出Real-Texts数据集和TEXTS-Diff模型，以提升真实场景文本图像超分辨率的背景重建与文字可读性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集中文本图像稀缺、多为孤立文本样本，导致文本区域恢复效果差、背景重建质量低。

Method: 构建大规模真实文本图像数据集Real-Texts（含中英文自然文本），并提出TEXTS-Aware Diffusion Model（TEXTS-Diff），融合抽象文本概念理解与具体文本区域建模，协同优化背景与文字细节生成。

Result: 在多个指标上达到SOTA性能，显著提升复杂场景下的文本恢复精度与泛化能力，有效抑制文字畸变与幻觉伪影，同时保持场景视觉保真度。

Conclusion: Real-Texts数据集与TEXTS-Diff模型共同解决了真实文本图像超分辨率中文字可读性与背景一致性难以兼顾的关键问题，为该任务提供了新基准与有效方法。

Abstract: Real-world text image super-resolution aims to restore overall visual quality and text legibility in images suffering from diverse degradations and text distortions. However, the scarcity of text image data in existing datasets results in poor performance on text regions. In addition, datasets consisting of isolated text samples limit the quality of background reconstruction. To address these limitations, we construct Real-Texts, a large-scale, high-quality dataset collected from real-world images, which covers diverse scenarios and contains natural text instances in both Chinese and English. Additionally, we propose the TEXTS-Aware Diffusion Model (TEXTS-Diff) to achieve high-quality generation in both background and textual regions. This approach leverages abstract concepts to improve the understanding of textual elements within visual scenes and concrete text regions to enhance textual details. It mitigates distortions and hallucination artifacts commonly observed in text regions, while preserving high-quality visual scene fidelity. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple evaluation metrics, exhibiting superior generalization ability and text restoration accuracy in complex scenarios. All the code, model, and dataset will be released.

</details>


### [54] [STARS: Shared-specific Translation and Alignment for missing-modality Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2601.17342)
*Tong Wang,Xiaodong Zhang,Guanzhou Chen,Jiaqi Wang,Chenxi Liu,Xiaoliang Tan,Wenchao Guo,Xuyang Li,Xuanrui Wang,Zifan Wang*

Main category: cs.CV

TL;DR: 本文提出STARS框架，通过非对称对齐机制和像素级语义采样对齐策略，解决遥感多模态数据缺失下的语义分割问题，提升模型鲁棒性与小类识别能力。


<details>
  <summary>Details</summary>
Motivation: 遥感多模态数据（如光学、SAR、DSM）在实际中常存在模态缺失问题，导致传统融合模型性能下降；现有补全方法存在特征坍缩和恢复特征泛化过度等缺陷。

Method: 提出STARS框架，包含两个核心设计：1）基于双向翻译与stop-gradient的非对称对齐机制，防止特征坍缩并降低超参敏感性；2）结合类别均衡采样与跨模态语义对齐损失的像素级语义采样对齐（PSA）策略。

Result: STARS在模态缺失场景下显著提升遥感语义分割性能，尤其改善了少数类识别效果，并增强了模型鲁棒性与训练稳定性。

Conclusion: STARS为不完整多模态遥感数据提供了一种有效且鲁棒的语义分割解决方案，其对齐与翻译机制可推广至其他多模态缺失任务。

Abstract: Multimodal remote sensing technology significantly enhances the understanding of surface semantics by integrating heterogeneous data such as optical images, Synthetic Aperture Radar (SAR), and Digital Surface Models (DSM). However, in practical applications, the missing of modality data (e.g., optical or DSM) is a common and severe challenge, which leads to performance decline in traditional multimodal fusion models. Existing methods for addressing missing modalities still face limitations, including feature collapse and overly generalized recovered features. To address these issues, we propose \textbf{STARS} (\textbf{S}hared-specific \textbf{T}ranslation and \textbf{A}lignment for missing-modality \textbf{R}emote \textbf{S}ensing), a robust semantic segmentation framework for incomplete multimodal inputs. STARS is built on two key designs. First, we introduce an asymmetric alignment mechanism with bidirectional translation and stop-gradient, which effectively prevents feature collapse and reduces sensitivity to hyperparameters. Second, we propose a Pixel-level Semantic sampling Alignment (PSA) strategy that combines class-balanced pixel sampling with cross-modality semantic alignment loss, to mitigate alignment failures caused by severe class imbalance and improve minority-class recognition.

</details>


### [55] [Revisiting Lightweight Low-Light Image Enhancement: From a YUV Color Space Perspective](https://arxiv.org/abs/2601.17349)
*Hailong Yan,Shice Liu,Xiangtao Zhang,Lujian Yao,Fengxiang Yang,Jinwei Chen,Bo Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于YUV颜色空间的轻量级低光图像增强新范式，通过频域分析发现Y通道主要丢失低频信息、UV通道受高频噪声影响，并据此设计了双流注意力与引导交互模块，在保持模型紧凑的同时显著提升视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级低光图像增强方法忽视通道特异性退化模式及通道间交互，导致性能受限。

Method: 进行YUV颜色空间的频域分析，提出Dual-Stream Global-Local Attention（Y通道）、Y-guided Local-Aware Frequency Attention（UV通道）和Guided Interaction（特征融合）模块。

Result: 在多个基准上达到新SOTA，视觉质量更优且参数量显著更低。

Conclusion: YUV空间更适合轻量级低光增强；解耦并针对性恢复各通道频域特性可兼顾模型轻量化与增强效果。

Abstract: In the current era of mobile internet, Lightweight Low-Light Image Enhancement (L3IE) is critical for mobile devices, which faces a persistent trade-off between visual quality and model compactness. While recent methods employ disentangling strategies to simplify lightweight architectural design, such as Retinex theory and YUV color space transformations, their performance is fundamentally limited by overlooking channel-specific degradation patterns and cross-channel interactions. To address this gap, we perform a frequency-domain analysis that confirms the superiority of the YUV color space for L3IE. We identify a key insight: the Y channel primarily loses low-frequency content, while the UV channels are corrupted by high-frequency noise. Leveraging this finding, we propose a novel YUV-based paradigm that strategically restores channels using a Dual-Stream Global-Local Attention module for the Y channel, a Y-guided Local-Aware Frequency Attention module for the UV channels, and a Guided Interaction module for final feature fusion. Extensive experiments validate that our model establishes a new state-of-the-art on multiple benchmarks, delivering superior visual quality with a significantly lower parameter count.

</details>


### [56] [NeRF-MIR: Towards High-Quality Restoration of Masked Images with Neural Radiance Fields](https://arxiv.org/abs/2601.17350)
*Xianliang Huang,Zhizhou Zhong,Shuhang Chen,Yi Xu,Juhong Guan,Shuigeng Zhou*

Main category: cs.CV

TL;DR: This paper proposes NeRF-MIR, a novel NeRF-based method for masked image restoration, featuring a patch-based entropy-guided ray emitting strategy (PERE), a progressively iterative self-training restoration mechanism (PIRE), and a dynamically-weighted loss; it also introduces three new masked datasets and shows superior performance over existing methods.


<details>
  <summary>Details</summary>
Motivation: NeRF struggles with corrupted (e.g., masked) input images common in natural scene capture, limiting its effectiveness in 3D scene reconstruction; there is a need for robust NeRF variants tailored to masked image restoration.

Method: Introduces NeRF-MIR with three core components: (1) PERE — a patch-based entropy strategy to guide ray emission for better texture learning; (2) PIRE — a progressively iterative self-training mechanism to restore masked regions; (3) a dynamically-weighted loss that adapts weights for masked areas. Also constructs three new masked datasets.

Result: NeRF-MIR achieves superior masked image restoration performance over baseline and state-of-the-art methods on both real-world and synthetically masked datasets.

Conclusion: NeRF-MIR successfully extends NeRF’s applicability to masked image restoration by improving ray sampling, introducing iterative self-restoration, and adaptive loss weighting—demonstrating NeRF's untapped potential in robust neural rendering under corruption.

Abstract: Neural Radiance Fields (NeRF) have demonstrated remarkable performance in novel view synthesis. However, there is much improvement room on restoring 3D scenes based on NeRF from corrupted images, which are common in natural scene captures and can significantly impact the effectiveness of NeRF. This paper introduces NeRF-MIR, a novel neural rendering approach specifically proposed for the restoration of masked images, demonstrating the potential of NeRF in this domain. Recognizing that randomly emitting rays to pixels in NeRF may not effectively learn intricate image textures, we propose a \textbf{P}atch-based \textbf{E}ntropy for \textbf{R}ay \textbf{E}mitting (\textbf{PERE}) strategy to distribute emitted rays properly. This enables NeRF-MIR to fuse comprehensive information from images of different views. Additionally, we introduce a \textbf{P}rogressively \textbf{I}terative \textbf{RE}storation (\textbf{PIRE}) mechanism to restore the masked regions in a self-training process. Furthermore, we design a dynamically-weighted loss function that automatically recalibrates the loss weights for masked regions. As existing datasets do not support NeRF-based masked image restoration, we construct three masked datasets to simulate corrupted scenarios. Extensive experiments on real data and constructed datasets demonstrate the superiority of NeRF-MIR over its counterparts in masked image restoration.

</details>


### [57] [HyDeMiC: A Deep Learning-based Mineral Classifier using Hyperspectral Data](https://arxiv.org/abs/2601.17352)
*M. L. Mamud,Piyoosh Jaysaval,Frederick D Day-Lewis,M. K. Mudunuru*

Main category: cs.CV

TL;DR: 本文提出了一种基于卷积神经网络的高光谱矿物分类模型HyDeMiC，利用USGS矿物光谱库训练，在不同噪声水平下表现出优异且稳健的分类性能，尤其适用于真实野外含噪高光谱数据。


<details>
  <summary>Details</summary>
Motivation: 传统高光谱矿物分类方法易受环境噪声、传感器限制及高维数据计算复杂度影响，亟需更鲁棒的深度学习方案。

Method: 构建名为HyDeMiC的CNN模型；使用USGS提供的115种矿物实验室光谱，通过卷积传感器响应函数生成带噪声的合成训练数据；以三种含铜矿物（赤铜矿、孔雀石、黄铜矿）为案例；在1%–10%噪声水平的2D合成高光谱数据上评估模型，并采用Matthews相关系数（MCC）量化性能。

Result: HyDeMiC在干净及低噪声数据上达到近完美分类（MCC=1.00），在中等噪声下仍保持强鲁棒性。

Conclusion: HyDeMiC是一种对噪声具有强鲁棒性的高光谱矿物分类模型，具备应用于实际野外矿物勘探的潜力。

Abstract: Hyperspectral imaging (HSI) has emerged as a powerful remote sensing tool for mineral exploration, capitalizing on unique spectral signatures of minerals. However, traditional classification methods such as discriminant analysis, logistic regression, and support vector machines often struggle with environmental noise in data, sensor limitations, and the computational complexity of analyzing high-dimensional HSI data. This study presents HyDeMiC (Hyperspectral Deep Learning-based Mineral Classifier), a convolutional neural network (CNN) model designed for robust mineral classification under noisy data. To train HyDeMiC, laboratory-measured hyperspectral data for 115 minerals spanning various mineral groups were used from the United States Geological Survey (USGS) library. The training dataset was generated by convolving reference mineral spectra with an HSI sensor response function. These datasets contained three copper-bearing minerals, Cuprite, Malachite, and Chalcopyrite, used as case studies for performance demonstration. The trained CNN model was evaluated on several synthetic 2D hyperspectral datasets with noise levels of 1%, 2%, 5%, and 10%. Our noisy data analysis aims to replicate realistic field conditions. The HyDeMiC's performance was assessed using the Matthews Correlation Coefficient (MCC), providing a comprehensive measure across different noise regimes. Results demonstrate that HyDeMiC achieved near-perfect classification accuracy (MCC = 1.00) on clean and low-noise datasets and maintained strong performance under moderate noise conditions. These findings emphasize HyDeMiC's robustness in the presence of moderate noise, highlighting its potential for real-world applications in hyperspectral imaging, where noise is often a significant challenge.

</details>


### [58] [UCAD: Uncertainty-guided Contour-aware Displacement for semi-supervised medical image segmentation](https://arxiv.org/abs/2601.17366)
*Chengbo Ding,Fenghe Tang,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: 本文提出UCAD框架，通过超像素生成解剖学一致区域，并结合不确定性引导的位移策略和动态不确定性加权一致性损失，提升半监督医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督分割中的位移策略仅在矩形区域操作，忽略解剖结构，导致边界失真和语义不一致。

Method: 提出UCAD框架：利用超像素生成与解剖边界对齐的区域；设计不确定性引导的选择机制，选择困难区域进行位移；引入动态不确定性加权一致性损失以稳定训练并正则化无标签区域。

Result: UCAD在多个实验中持续超越当前最优半监督分割方法，在标注数据有限条件下取得更优分割精度。

Conclusion: UCAD通过轮廓感知和不确定性引导的位移策略，有效提升了半监督医学图像分割的语义一致性和模型鲁棒性。

Abstract: Existing displacement strategies in semi-supervised segmentation only operate on rectangular regions, ignoring anatomical structures and resulting in boundary distortions and semantic inconsistency. To address these issues, we propose UCAD, an Uncertainty-Guided Contour-Aware Displacement framework for semi-supervised medical image segmentation that preserves contour-aware semantics while enhancing consistency learning. Our UCAD leverages superpixels to generate anatomically coherent regions aligned with anatomy boundaries, and an uncertainty-guided selection mechanism to selectively displace challenging regions for better consistency learning. We further propose a dynamic uncertainty-weighted consistency loss, which adaptively stabilizes training and effectively regularizes the model on unlabeled regions. Extensive experiments demonstrate that UCAD consistently outperforms state-of-the-art semi-supervised segmentation methods, achieving superior segmentation accuracy under limited annotation. The code is available at:https://github.com/dcb937/UCAD.

</details>


### [59] [Physical Prompt Injection Attacks on Large Vision-Language Models](https://arxiv.org/abs/2601.17383)
*Chen Ling,Kai Hu,Hangcheng Liu,Xingshuo Han,Tianwei Zhang,Changhai Ou*

Main category: cs.CV

TL;DR: 本文提出了一种名为物理提示注入攻击（PPIA）的新型黑盒、查询无关攻击方法，通过在物理对象上嵌入恶意文字指令来操控大型视觉语言模型（LVLMs），无需访问模型或其输入，在多种真实场景下实现了高达98%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有针对LVLMs的提示注入攻击通常需要访问输入通道或依赖用户查询信息，这些假设在实际部署中往往不成立，因此亟需一种更贴近现实威胁模型的攻击方法。

Method: 提出物理提示注入攻击（PPIA），采用离线筛选高可识别性与语义有效性的视觉提示，并结合基于时空注意力的环境感知布设策略，在物理世界中嵌入恶意文字指令，仅通过视觉观测即可影响LVLM行为。

Result: 在10个SOTA LVLM上跨仿真与真实环境验证，覆盖视觉问答、规划与导航任务，攻击成功率最高达98%，且对距离、视角、光照等物理变化具有强鲁棒性。

Conclusion: PPIA是首个真正黑盒、查询无关的物理域提示注入攻击，揭示了LVLM在开放物理环境中面临的新安全风险，为后续防御研究提供了重要基准和警示。

Abstract: Large Vision-Language Models (LVLMs) are increasingly deployed in real-world intelligent systems for perception and reasoning in open physical environments. While LVLMs are known to be vulnerable to prompt injection attacks, existing methods either require access to input channels or depend on knowledge of user queries, assumptions that rarely hold in practical deployments. We propose the first Physical Prompt Injection Attack (PPIA), a black-box, query-agnostic attack that embeds malicious typographic instructions into physical objects perceivable by the LVLM. PPIA requires no access to the model, its inputs, or internal pipeline, and operates solely through visual observation. It combines offline selection of highly recognizable and semantically effective visual prompts with strategic environment-aware placement guided by spatiotemporal attention, ensuring that the injected prompts are both perceivable and influential on model behavior. We evaluate PPIA across 10 state-of-the-art LVLMs in both simulated and real-world settings on tasks including visual question answering, planning, and navigation, PPIA achieves attack success rates up to 98%, with strong robustness under varying physical conditions such as distance, viewpoint, and illumination. Our code is publicly available at https://github.com/2023cghacker/Physical-Prompt-Injection-Attack.

</details>


### [60] [ONRW: Optimizing inversion noise for high-quality and robust watermark](https://arxiv.org/abs/2601.17388)
*Xuan Ding,Xiu Yan,Chuanlong Xie,Yao Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的高质量、鲁棒水印框架，通过空文本优化获得反转噪声，并在潜在空间中优化该噪声，再经扩散模型迭代去噪生成水印图像；引入自注意力约束和伪掩码策略保持语义一致性，实验表明其在多种图像失真下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习水印方法虽能保持图像质量，但面对传输过程中的图像失真时鲁棒性不足，限制了实际应用价值。

Method: 基于扩散模型构建水印框架：先通过空文本优化将原始图像转为反转噪声；在潜在空间中优化该噪声并加入自注意力约束与伪掩码策略以保持语义；最后通过扩散模型迭代去噪生成水印图像。

Result: 在COCO数据集上对12种图像变换的平均鲁棒性比Stable Signature方法高10%；水印图像视觉质量高，且对多种图像失真具有强鲁棒性。

Conclusion: 所提方法在保证水印图像高质量的同时显著提升了鲁棒性，为扩散模型在数字水印领域的应用提供了新思路和有效方案。

Abstract: Watermarking methods have always been effective means of protecting intellectual property, yet they face significant challenges. Although existing deep learning-based watermarking systems can hide watermarks in images with minimal impact on image quality, they often lack robustness when encountering image corruptions during transmission, which undermines their practical application value. To this end, we propose a high-quality and robust watermark framework based on the diffusion model. Our method first converts the clean image into inversion noise through a null-text optimization process, and after optimizing the inversion noise in the latent space, it produces a high-quality watermarked image through an iterative denoising process of the diffusion model. The iterative denoising process serves as a powerful purification mechanism, ensuring both the visual quality of the watermarked image and enhancing the robustness of the watermark against various corruptions. To prevent the optimizing of inversion noise from distorting the original semantics of the image, we specifically introduced self-attention constraints and pseudo-mask strategies. Extensive experimental results demonstrate the superior performance of our method against various image corruptions. In particular, our method outperforms the stable signature method by an average of 10\% across 12 different image transformations on COCO datasets. Our codes are available at https://github.com/920927/ONRW.

</details>


### [61] [SMV-EAR: Bring Spatiotemporal Multi-View Representation Learning into Efficient Event-Based Action Recognition](https://arxiv.org/abs/2601.17391)
*Rui Fan,Weidong Hao*

Main category: cs.CV

TL;DR: 本文提出了一种面向事件相机动作识别（EAR）的新型时空多视角表示学习框架，通过平移不变的密集事件转换、双分支动态融合架构和生物启发的时间扭曲增强，在多个数据集上显著提升了准确率，同时大幅降低了参数量和计算量。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件的对象识别（EOR）方法在动作识别任务中受限于平移敏感的空间分箱表示和简单的早期拼接融合结构，难以有效建模动作的时序运动动力学。

Method: 提出三个核心改进：（i）平移不变的稀疏事件密集转换以构建时空多视角表示；（ii）双分支动态融合架构，建模不同视角运动特征的样本级互补性；（iii）生物启发的时间扭曲数据增强，模拟真实人类动作的速度变化。

Result: 在HARDVS、DailyDVS-200和THU-EACT-50-CHL三个数据集上，Top-1准确率分别提升+7.0%、+10.7%和+10.2%，同时参数减少30.1%，计算量降低35.7%。

Conclusion: 所提框架为事件相机动作识别提供了一个新颖、高效且强性能的新范式。

Abstract: Event cameras action recognition (EAR) offers compelling privacy-protecting and efficiency advantages, where temporal motion dynamics is of great importance. Existing spatiotemporal multi-view representation learning (SMVRL) methods for event-based object recognition (EOR) offer promising solutions by projecting H-W-T events along spatial axis H and W, yet are limited by its translation-variant spatial binning representation and naive early concatenation fusion architecture. This paper reexamines the key SMVRL design stages for EAR and propose: (i) a principled spatiotemporal multi-view representation through translation-invariant dense conversion of sparse events, (ii) a dual-branch, dynamic fusion architecture that models sample-wise complementarity between motion features from different views, and (iii) a bio-inspired temporal warping augmentation that mimics speed variability of real-world human actions. On three challenging EAR datasets of HARDVS, DailyDVS-200 and THU-EACT-50-CHL, we show +7.0%, +10.7%, and +10.2% Top-1 accuracy gains over existing SMVRL EOR method with surprising 30.1% reduced parameters and 35.7% lower computations, establishing our framework as a novel and powerful EAR paradigm.

</details>


### [62] [ReLE: A Scalable System and Structured Benchmark for Diagnosing Capability Anisotropy in Chinese LLMs](https://arxiv.org/abs/2601.17399)
*Rui Fang,Jian Li,Wei Chen,Bin Hu,Ying-Cong Chen,Xin Tang,Liang Diao*

Main category: cs.CV

TL;DR: 本文提出ReLE系统，用于诊断大语言模型在不同领域能力上的各向异性，通过符号-基础混合评分机制和动态方差感知调度器，实现高效、鲁棒的实时评估。


<details>
  <summary>Details</summary>
Motivation: 现有中文大模型评测面临基准饱和、计算成本高、难以揭示能力结构权衡等问题。

Method: 提出ReLE系统，包含符号-基础混合评分机制（消除推理任务中嵌入式误判）和基于Neyman分配与噪声校正的动态方差感知调度器（降低70%计算开销，保持0.96排名相关性）。

Result: 在304个模型（189商用+115开源）、207843样本的Domain×Capability正交矩阵上验证；发现模型聚合排名对权重方案高度敏感，Rank Stability Amplitude达11.4，远高于传统基准的~5.0，证实模型高度专业化。

Conclusion: ReLE不是替代静态基准，而是作为高频诊断监控工具，服务于快速演进的大模型生态。

Abstract: Large Language Models (LLMs) have achieved rapid progress in Chinese language understanding, yet accurately evaluating their capabilities remains challenged by benchmark saturation and prohibitive computational costs. While static leaderboards provide snapshot rankings, they often mask the structural trade-offs between capabilities. In this work, we present ReLE (Robust Efficient Live Evaluation), a scalable system designed to diagnose Capability Anisotropy, the non-uniformity of model performance across domains. Using ReLE, we evaluate 304 models (189 commercial, 115 open-source) across a Domain $\times$ Capability orthogonal matrix comprising 207,843 samples. We introduce two methodological contributions to address current evaluation pitfalls: (1) A Symbolic-Grounded Hybrid Scoring Mechanism that eliminates embedding-based false positives in reasoning tasks; (2) A Dynamic Variance-Aware Scheduler based on Neyman allocation with noise correction, which reduces compute costs by 70\% compared to full-pass evaluations while maintaining a ranking correlation of $ρ=0.96$. Our analysis reveals that aggregate rankings are highly sensitive to weighting schemes: models exhibit a Rank Stability Amplitude (RSA) of 11.4 in ReLE versus $\sim$5.0 in traditional benchmarks, confirming that modern models are highly specialized rather than generally superior. We position ReLE not as a replacement for comprehensive static benchmarks, but as a high-frequency diagnostic monitor for the evolving model landscape.

</details>


### [63] [HAAF: Hierarchical Adaptation and Alignment of Foundation Models for Few-Shot Pathology Anomaly Detection](https://arxiv.org/abs/2601.17405)
*Chunze Yang,Wenjie Zhao,Yue Tang,Junbo Lu,Jiusong Ge,Qidong Liu,Zeyu Gao,Chen Li*

Main category: cs.CV

TL;DR: 本文提出HAAF框架，通过跨层级缩放对齐（CLSA）机制和双分支推理策略，解决视觉-语言模型在病理学中因粒度不匹配导致的细粒度异常检测难题，在多个基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 精度病理学依赖于在特定感兴趣区域（ROI）内检测细粒度形态学异常，而现有视觉-语言模型存在粒度不匹配问题，难以解析此类细微缺陷，且模态间缺乏ROI特异性视觉上下文的语义对齐。

Method: 提出分层适应与对齐框架（HAAF），核心是跨层级缩放对齐（CLSA）机制：先用视觉特征增强文本提示生成内容自适应描述符，再用该描述符空间引导视觉编码器聚焦异常；并采用融合语义得分与几何原型的双分支推理策略以提升少样本稳定性。

Result: 在四个基准数据集上，HAAF显著超越当前最优方法，并能在低资源场景下有效适配领域专用骨干网络（如CONCH）。

Conclusion: HAAF通过协同建模视觉与语言模态的层级对齐关系，有效缓解粒度不匹配问题，提升了细粒度病理异常检测的精度与泛化能力，尤其适用于标注稀缺的临床场景。

Abstract: Precision pathology relies on detecting fine-grained morphological abnormalities within specific Regions of Interest (ROIs), as these local, texture-rich cues - rather than global slide contexts - drive expert diagnostic reasoning. While Vision-Language (V-L) models promise data efficiency by leveraging semantic priors, adapting them faces a critical Granularity Mismatch, where generic representations fail to resolve such subtle defects. Current adaptation methods often treat modalities as independent streams, failing to ground semantic prompts in ROI-specific visual contexts. To bridge this gap, we propose the Hierarchical Adaptation and Alignment Framework (HAAF). At its core is a novel Cross-Level Scaled Alignment (CLSA) mechanism that enforces a sequential calibration order: visual features first inject context into text prompts to generate content-adaptive descriptors, which then spatially guide the visual encoder to spotlight anomalies. Additionally, a dual-branch inference strategy integrates semantic scores with geometric prototypes to ensure stability in few-shot settings. Experiments on four benchmarks show HAAF significantly outperforms state-of-the-art methods and effectively scales with domain-specific backbones (e.g., CONCH) in low-resource scenarios.

</details>


### [64] [Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity](https://arxiv.org/abs/2601.17408)
*Harsharaj Pathak,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: 本文提出了一种基于邻域签名的无源域自适应（SFDA）方法，仅用单个损失项优化目标域样本预测的相似性与差异性，提升聚类信息量并抑制噪声邻居影响，在VisDA等基准数据集上取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法依赖邻域一致性，但易受误导性邻域信息影响，导致错误；本文旨在通过学习更具信息量的簇并缓解噪声邻居影响来改进这一问题。

Method: 引入邻域签名概念，设计单一损失项以优化目标域样本预测之间的相似性与差异性，从而实现更鲁棒的域自适应。

Result: 在具有挑战性的VisDA数据集上优于现有方法，并在其他基准数据集上也取得了有竞争力的结果。

Conclusion: 基于邻域签名的单损失优化策略能有效提升SFDA性能，验证了增强聚类信息和抑制噪声邻居的有效性。

Abstract: Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.

</details>


### [65] [Cloud-Enabled IoT System for Real-Time Environmental Monitoring and Remote Device Control Using Firebase](https://arxiv.org/abs/2601.17414)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种基于Firebase实时数据库的低成本云物联网系统，使用ESP32连接DHT22和HC-SR04传感器并远程控制LED，实现99.2%可靠数据传输与<1.5秒控制延迟，总成本仅32.5美元。


<details>
  <summary>Details</summary>
Motivation: 传统监控系统在实时数据访问、远程可控性和云集成方面存在局限，而IoT设备激增带来了新机遇，亟需轻量、低成本、易部署的云物联网解决方案。

Method: 采用ESP32微控制器接入DHT22温湿度传感器和HC-SR04超声波测距传感器，并通过Firebase Realtime Database实现传感器数据上传与LED远程控制；所有操作基于云同步，无需自建服务器。

Result: 实验表明系统数据传输成功率达99.2%，远程控制延迟低于1.5秒，支持持久化历史数据存储，总硬件成本为32.50美元。

Conclusion: 该Firebase驱动的云IoT架构具备高可靠性、低延迟、低成本和易扩展性，适用于智能家居、工业监控等场景，显著降低了资源受限开发者构建云物联网应用的门槛。

Abstract: The proliferation of Internet of Things (IoT) devices has created unprecedented opportunities for remote monitoring and control applications across various domains. Traditional monitoring systems often suffer from limitations in real-time data accessibility, remote controllability, and cloud integration. This paper presents a cloud-enabled IoT system that leverages Google's Firebase Realtime Database for synchronized environmental monitoring and device control. The system utilizes an ESP32 microcontroller to interface with a DHT22 temperature/humidity sensor and an HC-SR04 ultrasonic distance sensor, while enabling remote control of two LED indicators through a cloud-based interface. Real-time sensor data is transmitted to Firebase, providing a synchronized platform accessible from multiple devices simultaneously. Experimental results demonstrate reliable data transmission with 99.2\% success rate, real-time control latency under 1.5 seconds, and persistent data storage for historical analysis. The system architecture offers a scalable framework for various IoT applications, from smart home automation to industrial monitoring, with a total implementation cost of \$32.50. The integration of Firebase provides robust cloud capabilities without requiring complex server infrastructure, making advanced IoT applications accessible to developers and researchers with limited resources.

</details>


### [66] [CoT-Seg: Rethinking Segmentation with Chain-of-Thought Reasoning and Self-Correction](https://arxiv.org/abs/2601.17420)
*Shiu-hong Kao,Chak Ho Huang,Huaiqian Liu,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.CV

TL;DR: 本文提出CoT-Seg，一种无需训练的推理分割框架，结合思维链推理与自我修正机制，利用预训练多模态大模型（如GPT-4o）分解查询、提取图像语义、生成并迭代优化分割掩码，显著提升复杂和跨域场景下的鲁棒性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法在处理复杂查询和跨域图像时表现不足；受人类逐步思考、自查自纠的启发，亟需一种能分步推理、自我评估与修正的系统。

Method: 提出训练无关的CoT-Seg框架：1）利用GPT-4o将查询分解为元指令并解析图像细粒度语义；2）生成初始分割结果；3）基于原始查询与推理轨迹进行自我评估与迭代掩码修正；4）支持检索增强以引入外部知识。

Result: CoT-Seg在复杂/模糊/易错场景下显著提升分割可靠性与鲁棒性；在新构建的ReasonSeg-Hard数据集上验证了其优越性能；验证了思维链+自我修正范式对视觉-语言联合分割的有效性。

Conclusion: CoT-Seg证明了无需微调、仅依靠预训练MLLM的内在推理与自我修正能力，即可实现高性能、高适应性的推理分割，为视觉语言融合提供了新范式。

Abstract: Existing works of reasoning segmentation often fall short in complex cases, particularly when addressing complicated queries and out-of-domain images. Inspired by the chain-of-thought reasoning, where harder problems require longer thinking steps/time, this paper aims to explore a system that can think step-by-step, look up information if needed, generate results, self-evaluate its own results, and refine the results, in the same way humans approach harder questions. We introduce CoT-Seg, a training-free framework that rethinks reasoning segmentation by combining chain-of-thought reasoning with self-correction. Instead of fine-tuning, CoT-Seg leverages the inherent reasoning ability of pre-trained MLLMs (GPT-4o) to decompose queries into meta-instructions, extract fine-grained semantics from images, and identify target objects even under implicit or complex prompts. Moreover, CoT-Seg incorporates a self-correction stage: the model evaluates its own segmentation against the original query and reasoning trace, identifies mismatches, and iteratively refines the mask. This tight integration of reasoning and correction significantly improves reliability and robustness, especially in ambiguous or error-prone cases. Furthermore, our CoT-Seg framework allows easy incorporation of retrieval-augmented reasoning, enabling the system to access external knowledge when the input lacks sufficient information. To showcase CoT-Seg's ability to handle very challenging cases ,we introduce a new dataset ReasonSeg-Hard. Our results highlight that combining chain-of-thought reasoning, self-correction, offers a powerful paradigm for vision-language integration driven segmentation.

</details>


### [67] [Coronary Artery Segmentation and Vessel-Type Classification in X-Ray Angiography](https://arxiv.org/abs/2601.17429)
*Mehdi Yousefzadeh,Siavash Shirzadeh Barough,Ashkan Fakharifar,Yashar Tayyarazad,Narges Eghbali,Mohaddeseh Mozaffari,Hoda Taeb,Negar Sadat Rafiee Tabatabaee,Parsa Esfahanian,Ghazaleh Sadeghi Gohar,Amineh Safavirad,Saeideh Mazloomzadeh,Ehsan khalilipur,Armin Elahifar,Majid Maleki*

Main category: cs.CV

TL;DR: 本文提出了一种结合经典滤波器优化与深度学习的X射线冠状动脉造影（XCA）血管分割与分型方法，通过SVR实现每帧图像参数自适应调优，并采用FPN等网络及合并导管标注策略提升分割精度与跨中心泛化能力。


<details>
  <summary>Details</summary>
Motivation: X射线冠状动脉造影（XCA）虽为临床金标准，但因低对比度、运动伪影、重叠、导管干扰等问题导致血管分割鲁棒性差，且存在多中心域偏移，亟需可靠分割与血管类型标注以支持解剖定位和下游定量分析。

Method: 从670段动态序列中选取峰值充盈帧，进行联合超分辨率与增强；对比Meijering、Frangi、Sato滤波器在人工调参、全局均值参数、SVR预测参数三种设置下的性能；评估U-Net、FPN、Swin Transformer等神经网络在仅冠脉标注与冠脉+导管合并标注下的表现；第二阶段采用分类模型进行LAD/LCX/RCA血管类型识别；外部验证使用公开DCA1数据集。

Result: SVR调参使Frangi滤波器Dice达0.759（优于全局均值0.741）；FPN在冠脉单标签下Dice为0.914±0.007，合并导管标签后提升至0.931±0.006；DCA1外部测试中Dice分别降至0.798和0.814，轻量微调后恢复至约0.882；血管分型准确率分别为RCA 98.5%、LAD 95.4%、LCX 96.2%。

Conclusion: 学习式逐帧参数调优可增强传统血管增强流程；高分辨率FPN模型结合冠脉与导管联合监督能显著提升模型稳定性与跨中心迁移能力，仅需少量微调即可适应新中心数据。

Abstract: X-ray coronary angiography (XCA) is the clinical reference standard for assessing coronary artery disease, yet quantitative analysis is limited by the difficulty of robust vessel segmentation in routine data. Low contrast, motion, foreshortening, overlap, and catheter confounding degrade segmentation and contribute to domain shift across centers. Reliable segmentation, together with vessel-type labeling, enables vessel-specific coronary analytics and downstream measurements that depend on anatomical localization. From 670 cine sequences (407 subjects), we select a best frame near peak opacification using a low-intensity histogram criterion and apply joint super-resolution and enhancement. We benchmark classical Meijering, Frangi, and Sato vesselness filters under per-image oracle tuning, a single global mean setting, and per-image parameter prediction via Support Vector Regression (SVR). Neural baselines include U-Net, FPN, and a Swin Transformer, trained with coronary-only and merged coronary+catheter supervision. A second stage assigns vessel identity (LAD, LCX, RCA). External evaluation uses the public DCA1 cohort. SVR per-image tuning improves Dice over global means for all classical filters (e.g., Frangi: 0.759 vs. 0.741). Among deep models, FPN attains 0.914+/-0.007 Dice (coronary-only), and merged coronary+catheter labels further improve to 0.931+/-0.006. On DCA1 as a strict external test, Dice drops to 0.798 (coronary-only) and 0.814 (merged), while light in-domain fine-tuning recovers to 0.881+/-0.014 and 0.882+/-0.015. Vessel-type labeling achieves 98.5% accuracy (Dice 0.844) for RCA, 95.4% (0.786) for LAD, and 96.2% (0.794) for LCX. Learned per-image tuning strengthens classical pipelines, while high-resolution FPN models and merged-label supervision improve stability and external transfer with modest adaptation.

</details>


### [68] [ReflexSplit: Single Image Reflection Separation via Layer Fusion-Separation](https://arxiv.org/abs/2601.17468)
*Chia-Ming Lee,Yu-Fan Lin,Jing-Hui Jung,Yu-Jou Hsiao,Chih-Chung Hsu,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 本文提出ReflexSplit，一种用于单图像反射分离（SIRS）的双流框架，通过跨尺度门控融合、层融合-分离模块和课程训练策略，有效缓解非线性混合下的透射-反射混淆问题，在合成与真实数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有SIRS方法在非线性混合下存在透射层与反射层混淆问题，尤其在深层解码器中，源于隐式融合机制和多尺度协同不足。

Method: 提出ReflexSplit双流框架：(1) 跨尺度门控融合（CrGF）自适应聚合多层级语义、纹理与上下文；(2) 层融合-分离模块（LFSB）交替执行共享结构提取与差异化解耦，并引入跨流减法实现注意力消去；(3) 课程训练策略，通过深度相关初始化与轮次渐进升温强化差异分离。

Result: 在合成与真实世界基准上取得SOTA性能，具备更优感知质量与强泛化能力。

Conclusion: ReflexSplit通过显式建模双流交互与多尺度协同，显著提升SIRS任务中非线性混合场景下的分离精度与鲁棒性。

Abstract: Single Image Reflection Separation (SIRS) disentangles mixed images into transmission and reflection layers. Existing methods suffer from transmission-reflection confusion under nonlinear mixing, particularly in deep decoder layers, due to implicit fusion mechanisms and inadequate multi-scale coordination. We propose ReflexSplit, a dual-stream framework with three key innovations. (1) Cross-scale Gated Fusion (CrGF) adaptively aggregates semantic priors, texture details, and decoder context across hierarchical depths, stabilizing gradient flow and maintaining feature consistency. (2) Layer Fusion-Separation Blocks (LFSB) alternate between fusion for shared structure extraction and differential separation for layer-specific disentanglement. Inspired by Differential Transformer, we extend attention cancellation to dual-stream separation via cross-stream subtraction. (3) Curriculum training progressively strengthens differential separation through depth-dependent initialization and epoch-wise warmup. Extensive experiments on synthetic and real-world benchmarks demonstrate state-of-the-art performance with superior perceptual quality and robust generalization. Our code is available at https://github.com/wuw2135/ReflexSplit.

</details>


### [69] [PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors](https://arxiv.org/abs/2601.17470)
*Chia-Ming Lee,Yu-Fan Lin,Yu-Jou Hsiao,Jing-Hui Jung,Yu-Lun Liu,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: 本文提出PhaSR方法，通过双重物理先验对齐（光照校正与跨模态对齐）提升阴影去除在多样光照条件下的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有阴影去除方法在复杂、多光源环境下面临光照与反射率解耦困难，且物理先验常不匹配，导致性能下降。

Method: 提出双重对齐机制：1）物理对齐归一化（PAN），结合灰度世界归一化、对数域Retinex分解与动态范围重组进行光照校正；2）几何-语义矫正注意力（GSRA），融合深度几何信息与DINO-v2语义特征，实现跨模态对齐。

Result: 在阴影去除任务中达到竞争性性能，计算复杂度更低，并显著提升在多光源环境下的泛化能力，优于传统方法。

Conclusion: 双重物理先验对齐策略有效缓解了光照多样性带来的挑战，为单图阴影去除提供了更鲁棒、可泛化的解决方案。

Abstract: Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.

</details>


### [70] [BMDS-Net: A Bayesian Multi-Modal Deep Supervision Network for Robust Brain Tumor Segmentation](https://arxiv.org/abs/2601.17504)
*Yan Zhou,Zhen Huang,Yingqiu Li,Yue Ouyang,Suncheng Xiang,Zehua Wang*

Main category: cs.CV

TL;DR: 本文提出BMDS-Net，一种面向临床鲁棒性与可信度的脑肿瘤分割框架，解决Transformer模型在缺失模态和不确定性校准方面的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的脑肿瘤分割模型（如Swin UNETR）虽在基准数据上表现优异，但在临床中易受缺失模态影响且缺乏置信度校准，难以满足实际部署的安全需求。

Method: 提出三方面方法：1）构建含零初始化多模态上下文融合（MMCF）与残差门控深层解码监督（DDS）的确定性主干网络；2）引入内存高效的贝叶斯微调策略，生成体素级不确定性图；3）在BraTS 2021数据集上系统验证。

Result: BMDS-Net在保持竞争性Dice分数的同时，显著降低Hausdorff距离，在缺失模态场景下展现出远超基线模型的稳定性，并提供可解释的不确定性估计。

Conclusion: BMDS-Net通过兼顾鲁棒性、精度与不确定性建模，提升了模型在真实临床环境中的可信部署能力。

Abstract: Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.

</details>


### [71] [FMIR, a foundation model-based Image Registration Framework for Robust Image Registration](https://arxiv.org/abs/2601.17529)
*Fengting Zhang,Yue He,Qinghao Liu,Yaonan Wang,Xiang Chen,Hang Zhang*

Main category: cs.CV

TL;DR: 本文提出FMIR，一种基于基础模型的医学图像配准框架，通过结合基础模型特征编码器和通用配准头，并采用通道正则化策略仅在单个数据集上训练，实现了域内SOTA性能及跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学图像配准中虽提速显著，但受限于小规模医学数据集，泛化能力差，阻碍临床应用。

Method: 提出FMIR框架：使用基础模型作为特征编码器提取解剖结构，搭配通用配准头，并采用通道正则化策略在单一数据集上训练。

Result: 在域内达到SOTA性能，同时在跨域图像上保持鲁棒配准效果。

Conclusion: FMIR为资源有限条件下构建可泛化的医学影像基础模型提供了可行路径。

Abstract: Deep learning has revolutionized medical image registration by achieving unprecedented speeds, yet its clinical application is hindered by a limited ability to generalize beyond the training domain, a critical weakness given the typically small scale of medical datasets. In this paper, we introduce FMIR, a foundation model-based registration framework that overcomes this limitation.Combining a foundation model-based feature encoder for extracting anatomical structures with a general registration head, and trained with a channel regularization strategy on just a single dataset, FMIR achieves state-of-the-art(SOTA) in-domain performance while maintaining robust registration on out-of-domain images.Our approach demonstrates a viable path toward building generalizable medical imaging foundation models with limited resources. The code is available at https://github.com/Monday0328/FMIR.git.

</details>


### [72] [Will It Zero-Shot?: Will It Zero-Shot?: Predicting Zero-Shot Classification Performance For Arbitrary Queries](https://arxiv.org/abs/2601.17535)
*Kevin Robbins,Xiaotong Liu,Yu Wu,Le Sun,Grady McPeak,Abby Stylianou,Robert Pless*

Main category: cs.CV

TL;DR: 本文提出了一种结合生成图像和文本的零样本准确率预测方法，用于评估视觉-语言模型（如CLIP）在特定任务上的适用性，显著优于纯文本评估，并为用户提供可解释的反馈。


<details>
  <summary>Details</summary>
Motivation: 非专家用户缺乏简单有效的方法来评估所选视觉-语言模型（VLM）在其特定任务上的有效性；现有纯文本评估方法存在局限性。

Method: 在已有纯文本评估方法基础上，引入与任务相关的合成图像生成，构建图文联合评估机制，预测零样本分类准确率。

Result: 图文联合评估显著提升零样本准确率预测质量，并提供可视化反馈；在标准CLIP基准数据集上验证了其有效性。

Conclusion: 融合生成图像的评估方法能更可靠地预测VLM在无标注数据场景下的适用性，增强用户对模型选择的信心与可解释性。

Abstract: Vision-Language Models like CLIP create aligned embedding spaces for text and images, making it possible for anyone to build a visual classifier by simply naming the classes they want to distinguish. However, a model that works well in one domain may fail in another, and non-expert users have no straightforward way to assess whether their chosen VLM will work on their problem. We build on prior work using text-only comparisons to evaluate how well a model works for a given natural language task, and explore approaches that also generate synthetic images relevant to that task to evaluate and refine the prediction of zero-shot accuracy. We show that generated imagery to the baseline text-only scores substantially improves the quality of these predictions. Additionally, it gives a user feedback on the kinds of images that were used to make the assessment. Experiments on standard CLIP benchmark datasets demonstrate that the image-based approach helps users predict, without any labeled examples, whether a VLM will be effective for their application.

</details>


### [73] [OTI: A Model-free and Visually Interpretable Measure of Image Attackability](https://arxiv.org/abs/2601.17536)
*Jiaming Liang,Haowei Liu,Chi-Man Pun*

Main category: cs.CV

TL;DR: 本文提出了一种名为Object Texture Intensity (OTI)的新型图像攻击性度量方法，该方法无需依赖特定模型（model-free），且具有视觉可解释性，通过衡量图像中语义对象的纹理强度来评估其被对抗攻击的难易程度。


<details>
  <summary>Details</summary>
Motivation: 现有攻击性度量方法依赖模型代理获取梯度等信息，且缺乏视觉可解释性；而实际中许多任务模型不可访问，亟需一种模型无关、直观可解释的攻击性评估指标。

Method: 提出Object Texture Intensity（OTI）指标，基于图像语义对象的纹理强度定义攻击性；从决策边界和对抗扰动的中高频特性两个角度给出理论支撑。

Result: 实验证明OTI在有效性与计算效率上均表现优异，并为对抗机器学习领域提供了对攻击性的可视化理解。

Conclusion: OTI是一种模型无关、视觉可解释、理论扎实且实用高效的图像攻击性度量新范式。

Abstract: Despite the tremendous success of neural networks, benign images can be corrupted by adversarial perturbations to deceive these models. Intriguingly, images differ in their attackability. Specifically, given an attack configuration, some images are easily corrupted, whereas others are more resistant. Evaluating image attackability has important applications in active learning, adversarial training, and attack enhancement. This prompts a growing interest in developing attackability measures. However, existing methods are scarce and suffer from two major limitations: (1) They rely on a model proxy to provide prior knowledge (e.g., gradients or minimal perturbation) to extract model-dependent image features. Unfortunately, in practice, many task-specific models are not readily accessible. (2) Extracted features characterizing image attackability lack visual interpretability, obscuring their direct relationship with the images. To address these, we propose a novel Object Texture Intensity (OTI), a model-free and visually interpretable measure of image attackability, which measures image attackability as the texture intensity of the image's semantic object. Theoretically, we describe the principles of OTI from the perspectives of decision boundaries as well as the mid- and high-frequency characteristics of adversarial perturbations. Comprehensive experiments demonstrate that OTI is effective and computationally efficient. In addition, our OTI provides the adversarial machine learning community with a visual understanding of attackability.

</details>


### [74] [Saliency Driven Imagery Preprocessing for Efficient Compression -- Industrial Paper](https://arxiv.org/abs/2601.17555)
*Justin Downes,Sam Saltwick,Anthony Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于显著性图的卫星图像预处理方法，结合传统有损压缩标准，实现单幅大尺寸卫星图像内的可变码率压缩。


<details>
  <summary>Details</summary>
Motivation: 每天产生数百TB的卫星图像，存储和带宽成本高昂；而许多下游任务仅关注图像中的小区域（兴趣区），因此可利用已知的兴趣区信息优化编码。

Method: 利用显著性图指导图像预处理，采用与量化显著性等级对应的可变尺寸平滑核对像素进行处理，再结合传统有损压缩编码标准实现可变码率压缩。

Result: 实现了在单幅大型卫星图像内按区域重要性进行差异化压缩，提升了下游任务所需区域的重建质量，同时降低整体码率。

Conclusion: 基于显著性图的预处理能有效提升传统压缩标准在卫星图像上的适应性，为面向任务的高效遥感图像压缩提供了新思路。

Abstract: The compression of satellite imagery remains an important research area as hundreds of terabytes of images are collected every day, which drives up storage and bandwidth costs. Although progress has been made in increasing the resolution of these satellite images, many downstream tasks are only interested in small regions of any given image. These areas of interest vary by task but, once known, can be used to optimize how information within the image is encoded. Whereas standard image encoding methods, even those optimized for remote sensing, work on the whole image equally, there are emerging methods that can be guided by saliency maps to focus on important areas. In this work we show how imagery preprocessing techniques driven by saliency maps can be used with traditional lossy compression coding standards to create variable rate image compression within a single large satellite image. Specifically, we use variable sized smoothing kernels that map to different quantized saliency levels to process imagery pixels in order to optimize downstream compression and encoding schemes.

</details>


### [75] [Sponge Tool Attack: Stealthy Denial-of-Efficiency against Tool-Augmented Agentic Reasoning](https://arxiv.org/abs/2601.17566)
*Qi Li,Xinchao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Sponge Tool Attack (STA)的新型攻击方法，通过仅重写输入提示（query-only）来干扰基于工具调用的LLM代理推理过程，在不修改模型或工具的前提下，诱导生成冗长低效的推理路径，造成计算开销增加但语义和意图保持不变，具有隐蔽性和普适性。


<details>
  <summary>Details</summary>
Motivation: 现有基于外部工具增强的LLM代理推理方法存在未被充分研究的安全漏洞，尤其是对工具调用过程的恶意操纵风险。

Method: 提出Sponge Tool Attack（STA），设计为一种迭代式多智能体协同框架，具备显式的重写策略控制，生成在语义上高度保真但诱导低效推理的良性外观提示改写。

Result: 在6个模型、12个工具、4种代理框架、13个数据集（覆盖5个领域）上验证了STA的有效性，成功引发冗长低效推理，显著增加计算开销且保持语义隐蔽。

Conclusion: STA揭示了工具增强型LLM代理的关键安全盲区，表明仅靠提示改写即可严重损害推理效率，为构建鲁棒的AI代理系统提供了重要警示与评估基准。

Abstract: Enabling large language models (LLMs) to solve complex reasoning tasks is a key step toward artificial general intelligence. Recent work augments LLMs with external tools to enable agentic reasoning, achieving high utility and efficiency in a plug-and-play manner. However, the inherent vulnerabilities of such methods to malicious manipulation of the tool-calling process remain largely unexplored. In this work, we identify a tool-specific attack surface and propose Sponge Tool Attack (STA), which disrupts agentic reasoning solely by rewriting the input prompt under a strict query-only access assumption. Without any modification on the underlying model or the external tools, STA converts originally concise and efficient reasoning trajectories into unnecessarily verbose and convoluted ones before arriving at the final answer. This results in substantial computational overhead while remaining stealthy by preserving the original task semantics and user intent. To achieve this, we design STA as an iterative, multi-agent collaborative framework with explicit rewritten policy control, and generates benign-looking prompt rewrites from the original one with high semantic fidelity. Extensive experiments across 6 models (including both open-source models and closed-source APIs), 12 tools, 4 agentic frameworks, and 13 datasets spanning 5 domains validate the effectiveness of STA.

</details>


### [76] [Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization](https://arxiv.org/abs/2601.17586)
*Sebastian Doerrich,Francesco Di Salvo,Jonas Alle,Christian Ledig*

Main category: cs.CV

TL;DR: 本文提出Stylizing ViT，一种基于ViT的新型编码器，通过权重共享的注意力模块实现解剖一致性保持与风格迁移协同，显著提升医学图像跨域泛化能力，并在多个任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学图像分析中常因数据异质性和稀缺性导致跨域和跨人群泛化能力差；传统增强方法在大域偏移下失效，现有风格增强方法存在风格多样性不足或引入伪影的问题。

Method: 提出Stylizing ViT，采用权重共享的注意力块统一实现自注意力（保持解剖结构）与交叉注意力（完成风格迁移），用于训练时数据增强及测试时增强。

Result: 在组织病理学与皮肤科三类图像分类任务中，相比SOTA提升最高达13%准确率，生成图像无伪影、感知质量高；测试时增强进一步带来17%性能提升。

Conclusion: Stylizing ViT有效解决了医学图像域泛化中的风格多样性与解剖保真度矛盾，兼具训练与推理阶段的增强能力，具备实用价值与可扩展性。

Abstract: Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at https://github.com/sdoerrich97/stylizing-vit .

</details>


### [77] [SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation](https://arxiv.org/abs/2601.17657)
*Taewan Cho,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.CV

TL;DR: 本文提出SPACE-CLIP，一种双路径解码器架构，直接从冻结的CLIP视觉编码器中提取几何结构信息，无需文本编码器或提示词；语义路径通过FiLM动态调制高层特征，结构路径提取早期层空间细节，二者分层融合实现语义与几何的协同感知，在KITTI上显著优于现有CLIP方法。


<details>
  <summary>Details</summary>
Motivation: CLIP擅长语义理解但缺乏几何感知能力，现有方法依赖文本提示进行间接、低效的几何推理，亟需更直接高效的几何知识提取机制。

Method: 提出SPACE-CLIP双路径解码器：语义路径使用FiLM对CLIP视觉特征进行全局上下文动态调制；结构路径从CLIP早期层提取细粒度空间信息；两路径分层融合以联合建模语义与几何。整个框架不使用CLIP文本编码器和文本提示，且视觉编码器保持冻结。

Result: 在KITTI深度估计基准上显著超越所有现有CLIP-based方法；消融实验证明双路径协同融合是性能提升的关键；模型可即插即用于VLA等具身AI系统。

Conclusion: SPACE-CLIP提供了一种新颖、高效、结构简洁的大模型空间感知重用范式，不仅适用于深度估计，更可作为通用空间感知模块嵌入下一代具身AI系统。

Abstract: Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip

</details>


### [78] [Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting](https://arxiv.org/abs/2601.17666)
*Xinyue Pan,Yuhao Chen,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的Prompt Grafting（PG）框架，用于提升文本到图像扩散模型在生成多食物图像时的可控性与准确性，通过结合显式空间提示与隐式布局引导，有效缓解食物间因边界模糊导致的物体纠缠问题。


<details>
  <summary>Details</summary>
Motivation: 现实中的餐食图像常包含多种食物，而现有文本到图像扩散模型难以准确生成多食物图像，主要因食物间缺乏清晰边界而导致物体纠缠（如米饭与汤融合），影响图像膳食评估和菜谱可视化等应用。

Method: 提出Prompt Grafting（PG）——一种训练-free的两阶段采样框架：第一阶段用布局提示（layout prompt）建立食物的空间区域；第二阶段在布局稳定后将目标提示（target prompt）‘嫁接’上去；支持通过编辑布局安排来控制食物分离或混合。

Result: 在两个食物数据集上显著提升了目标食物对象的出现率，并提供了定性证据表明该方法能实现可控的食物分离。

Conclusion: PG是一种轻量、灵活且无需训练的方法，有效提升了多食物图像生成的准确性与可控性，为饮食健康相关视觉任务提供了新思路。

Abstract: Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.

</details>


### [79] [Uni-RS: A Spatially Faithful Unified Understanding and Generation Model for Remote Sensing](https://arxiv.org/abs/2601.17673)
*Weiyu Zhang,Yuan Hu,Yong Li,Yu Liu*

Main category: cs.CV

TL;DR: 本文提出Uni-RS模型，首次针对遥感领域设计统一多模态模型，通过空间布局规划、空间感知查询监督和图像-文本空间布局变化三种机制，解决理解与生成之间空间关系不一致的问题，显著提升文本到图像生成中的空间保真度。


<details>
  <summary>Details</summary>
Motivation: 统一遥感多模态模型存在空间反转诅咒：能准确理解图像中物体位置，但在文本到图像生成中却难以忠实再现相同空间关系，而这类关系是遥感语义的核心。

Method: 提出Uni-RS模型，包含三部分：1）显式空间布局规划，将文本指令转化为空间布局计划；2）空间感知查询监督，引导可学习查询关注指令中明确指定的空间关系；3）图像-文本空间布局变化，引入几何一致的空间变换增强训练。

Result: 在多个基准测试中，该方法显著提升了文本到图像生成的空间保真度，同时在图像描述、视觉定位和VQA等多模态理解任务上保持强性能。

Conclusion: Uni-RS有效缓解了遥感多模态模型中理解与生成之间的空间不对称问题，为遥感领域统一多模态建模提供了新范式。

Abstract: Unified remote sensing multimodal models exhibit a pronounced spatial reversal curse: Although they can accurately recognize and describe object locations in images, they often fail to faithfully execute the same spatial relations during text-to-image generation, where such relations constitute core semantic information in remote sensing. Motivated by this observation, we propose Uni-RS, the first unified multimodal model tailored for remote sensing, to explicitly address the spatial asymmetry between understanding and generation. Specifically, we first introduce explicit Spatial-Layout Planning to transform textual instructions into spatial layout plans, decoupling geometric planning from visual synthesis. We then impose Spatial-Aware Query Supervision to bias learnable queries toward spatial relations explicitly specified in the instruction. Finally, we develop Image-Caption Spatial Layout Variation to expose the model to systematic geometry-consistent spatial transformations. Extensive experiments across multiple benchmarks show that our approach substantially improves spatial faithfulness in text-to-image generation, while maintaining strong performance on multimodal understanding tasks like image captioning, visual grounding, and VQA tasks.

</details>


### [80] [StyleDecoupler: Generalizable Artistic Style Disentanglement](https://arxiv.org/abs/2601.17697)
*Zexi Jia,Jinchao Zhang,Jie Zhou*

Main category: cs.CV

TL;DR: 本文提出StyleDecoupler，一种无需微调的信息理论框架，利用多模态与单模态视觉模型表征差异解耦艺术风格与语义内容，并构建大规模艺术数据集WeART进行验证。


<details>
  <summary>Details</summary>
Motivation: 艺术风格表征困难在于其与语义内容深度耦合，现有方法难以分离二者。

Method: 提出StyleDecoupler框架，以单模态模型表征为内容参考，通过最小化互信息从多模态嵌入中提取纯风格特征；作为即插即用模块作用于冻结的视觉-语言模型；同时构建WeART艺术基准数据集（28万幅作品、152种风格、1556位艺术家）。

Result: 在WeART和WikiART数据集上实现风格检索SOTA性能，并支持风格关系映射与生成模型评估等应用。

Conclusion: StyleDecoupler有效解耦风格与内容，无需模型微调，兼具通用性与实用性，并开源代码与数据集。

Abstract: Representing artistic style is challenging due to its deep entanglement with semantic content. We propose StyleDecoupler, an information-theoretic framework that leverages a key insight: multi-modal vision models encode both style and content, while uni-modal models suppress style to focus on content-invariant features. By using uni-modal representations as content-only references, we isolate pure style features from multi-modal embeddings through mutual information minimization. StyleDecoupler operates as a plug-and-play module on frozen Vision-Language Models without fine-tuning. We also introduce WeART, a large-scale benchmark of 280K artworks across 152 styles and 1,556 artists. Experiments show state-of-the-art performance on style retrieval across WeART and WikiART, while enabling applications like style relationship mapping and generative model evaluation. We release our method and dataset at this url.

</details>


### [81] [An AI-enabled tool for quantifying overlapping red blood cell sickling dynamics in microfluidic assays](https://arxiv.org/abs/2601.17703)
*Nikhil Kadivar,Guansheng Li,Jianlu Zheng,John M. Higgins,Ming Dao,George Em Karniadakis,Mengjia Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的自动化框架，用于在时间序列显微图像中准确分割、分类和计数密集重叠的红细胞（RBC），尤其适用于镰状细胞形态动态分析；该方法仅需少量标注数据，结合AI辅助标注、nnU-Net分割与分水岭算法，显著提升量化精度与实验通量。


<details>
  <summary>Details</summary>
Motivation: 准确识别镰状细胞在不同生物物理条件下的形态转变，尤其在高密度、重叠细胞群体中存在标注稀缺与分割困难等挑战。

Method: 构建集成AI辅助标注、nnU-Net语义分割、分水岭实例分割、分类与计数的深度学习流程；使用Roboflow平台标注实验图像训练nnU-Net，并用分水岭算法解决细胞重叠问题。

Result: 在少量标注数据下实现高分割性能，可精确追踪镰状细胞比例的时序变化，使实验通量提升两倍以上，成功捕获药物依赖性镰变行为并揭示细胞力学演化特征。

Conclusion: 该AI驱动框架为微生理系统中细胞生物力学研究与疗效评估提供了可扩展、可重复的计算平台。

Abstract: Understanding sickle cell dynamics requires accurate identification of morphological transitions under diverse biophysical conditions, particularly in densely packed and overlapping cell populations. Here, we present an automated deep learning framework that integrates AI-assisted annotation, segmentation, classification, and instance counting to quantify red blood cell (RBC) populations across varying density regimes in time-lapse microscopy data. Experimental images were annotated using the Roboflow platform to generate labeled dataset for training an nnU-Net segmentation model. The trained network enables prediction of the temporal evolution of the sickle cell fraction, while a watershed algorithm resolves overlapping cells to enhance quantification accuracy. Despite requiring only a limited amount of labeled data for training, the framework achieves high segmentation performance, effectively addressing challenges associated with scarce manual annotations and cell overlap. By quantitatively tracking dynamic changes in RBC morphology, this approach can more than double the experimental throughput via densely packed cell suspensions, capture drug-dependent sickling behavior, and reveal distinct mechanobiological signatures of cellular morphological evolution. Overall, this AI-driven framework establishes a scalable and reproducible computational platform for investigating cellular biomechanics and assessing therapeutic efficacy in microphysiological systems.

</details>


### [82] [Advancing Structured Priors for Sparse-Voxel Surface Reconstruction](https://arxiv.org/abs/2601.17720)
*Ting-Hsun Chi,Chu-Rong Chen,Chi-Tun Hsu,Hsuan-Ting Lin,Sheng-Yu Huang,Cheng Sun,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: 本文提出了一种结合3D高斯溅射与稀疏体素光栅化的混合方法，通过智能体素初始化和精细化深度几何监督，提升了表面重建的几何精度、细节恢复能力和完整性，同时保持快速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有两种显式表征方法——3D高斯溅射（收敛快但表面保真度低）和稀疏体素光栅化（几何清晰但初始化低效、收敛慢），各自存在互补性缺陷，亟需融合优势。

Method: 1）基于场景结构的智能体素初始化方法，将体素置于合理位置并自适应设置细节层级；2）精细化深度几何监督，将多视角线索转化为逐光线的直接深度正则化，提升深度一致性且不模糊边缘。

Result: 在标准基准上实验表明，该方法在几何精度、细结构恢复和表面完整性方面均优于先前方法，同时维持了快速收敛特性。

Conclusion: 融合隐式先验与显式结构建模、结合数据驱动初始化与几何感知监督，是提升神经辐射场表面重建质量的有效路径。

Abstract: Reconstructing accurate surfaces with radiance fields has progressed rapidly, yet two promising explicit representations, 3D Gaussian Splatting and sparse-voxel rasterization, exhibit complementary strengths and weaknesses. 3D Gaussian Splatting converges quickly and carries useful geometric priors, but surface fidelity is limited by its point-like parameterization. Sparse-voxel rasterization provides continuous opacity fields and crisp geometry, but its typical uniform dense-grid initialization slows convergence and underutilizes scene structure. We combine the advantages of both by introducing a voxel initialization method that places voxels at plausible locations and with appropriate levels of detail, yielding a strong starting point for per-scene optimization. To further enhance depth consistency without blurring edges, we propose refined depth geometry supervision that converts multi-view cues into direct per-ray depth regularization. Experiments on standard benchmarks demonstrate improvements over prior methods in geometric accuracy, better fine-structure recovery, and more complete surfaces, while maintaining fast convergence.

</details>


### [83] [Implicit Neural Representation-Based Continuous Single Image Super Resolution: An Empirical Study](https://arxiv.org/abs/2601.17723)
*Tayyab Nasir,Daochang Liu,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文对隐式神经表示（INR）在任意尺度图像超分辨率（ASSR）中的应用进行了系统性实证分析，揭示了现有方法的实际增益有限、训练配置影响显著、新损失函数可提升纹理保真度，以及缩放定律在INR-ASSR中成立等关键发现。


<details>
  <summary>Details</summary>
Motivation: 缺乏对INR用于ASSR的系统性实证研究，既无统一基准，也未厘清训练策略（如缩放律、目标函数、优化方法）的真实影响，亟需严谨分析以明确现状、饱和边界与未来方向。

Method: 构建统一框架与开源代码库，对比多种INR方法在多指标下的性能；控制变量分析不同训练配置对感知质量的影响；提出一种兼顾边缘保持与纹理细节的新损失函数。

Result: （1）复杂INR方法仅带来边际提升；（2）训练配置对性能影响远超模型结构差异；（3）新损失函数显著增强纹理保真度；（4）验证了模型规模与数据多样性提升带来可预测性能增益的缩放规律。

Conclusion: INR-ASSR的进展更多依赖训练策略与目标设计，而非单纯模型复杂化；应重视可复现的基准建设与面向感知质量的损失函数设计。

Abstract: Implicit neural representation (INR) has become the standard approach for arbitrary-scale image super-resolution (ASSR). To date, no empirical study has systematically examined the effectiveness of existing methods, nor investigated the effects of different training recipes, such as scaling laws, objective design, and optimization strategies. A rigorous empirical analysis is essential not only for benchmarking performance and revealing true gains but also for establishing the current state of ASSR, identifying saturation limits, and highlighting promising directions. We fill this gap by comparing existing techniques across diverse settings and presenting aggregated performance results on multiple image quality metrics. We contribute a unified framework and code repository to facilitate reproducible comparisons. Furthermore, we investigate the impact of carefully controlled training configurations on perceptual image quality and examine a new loss function that penalizes intensity variations while preserving edges, textures, and finer details during training. We conclude the following key insights that have been previously overlooked: (1) Recent, more complex INR methods provide only marginal improvements over earlier methods. (2) Model performance is strongly correlated to training configurations, a factor overlooked in prior works. (3) The proposed loss enhances texture fidelity across architectures, emphasizing the role of objective design for targeted perceptual gains. (4) Scaling laws apply to INR-based ASSR, confirming predictable gains with increased model complexity and data diversity.

</details>


### [84] [The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation](https://arxiv.org/abs/2601.17737)
*Chenyu Mu,Xin He,Qu Yang,Wanshun Chen,Jiadi Yao,Huang Liu,Zihao Yi,Bo Zhao,Xingyu Chen,Ruotian Ma,Fanghua Ye,Erkun Yang,Cheng Deng,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的智能体框架，将对话文本转化为连贯的长时序电影视频，通过ScripterAgent生成精细剧本、DirectorAgent协调视频生成，并引入新基准ScriptBench和评估指标VSA，显著提升脚本忠实度与时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型难以从高层次创意（如对话）生成长时序、语义连贯的影视内容，存在‘语义鸿沟’。

Method: 提出基于智能体的端到端框架：ScripterAgent将粗粒度对话转为可执行电影剧本；DirectorAgent采用跨场景连续生成策略协调SOTA视频模型；构建专家标注的多模态基准ScriptBench；设计AI CriticAgent与Visual-Script Alignment（VSA）评估指标。

Result: 在多个视频模型上显著提升脚本忠实度与时间保真度；发现当前SOTA模型在视觉效果与脚本严格遵循之间存在关键权衡。

Conclusion: 该框架有效弥合了创意构思与影视化执行之间的语义鸿沟，为自动化电影制作提供了新范式与实证洞见。

Abstract: Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.

</details>


### [85] [Frequency-aware Neural Representation for Videos](https://arxiv.org/abs/2601.17741)
*Jun Zhu,Xinfeng Zhang,Lv Tang,Junhao Jiang,Gai Zhang,Jia Wang*

Main category: cs.CV

TL;DR: 本文提出FaNeRV，一种面向视频压缩的频域感知神经表示方法，通过解耦高低频分量、多分辨率监督策略、动态高频注入机制和频域分解网络模块，显著提升了隐式神经表示在视频重建中的保真度和率失真性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示（INR）的视频压缩方法存在固有频谱偏差，偏向低频成分，导致重建图像过度平滑、率失真性能欠佳。

Method: 提出FaNeRV框架：1）显式解耦高低频分量；2）采用多分辨率监督策略进行分阶段训练；3）引入动态高频注入机制自适应增强难重建区域；4）设计频率分解网络模块以提升跨频段特征建模能力。

Result: 在标准基准测试中，FaNeRV显著超越现有INR方法，并在率失真性能上与传统编解码器（如H.264/265）具有竞争力。

Conclusion: 频域感知建模可有效缓解INR的频谱偏差问题，FaNeRV为高质量、高效率神经视频压缩提供了新思路与实用框架。

Abstract: Implicit Neural Representations (INRs) have emerged as a promising paradigm for video compression. However, existing INR-based frameworks typically suffer from inherent spectral bias, which favors low-frequency components and leads to over-smoothed reconstructions and suboptimal rate-distortion performance. In this paper, we propose FaNeRV, a Frequency-aware Neural Representation for videos, which explicitly decouples low- and high-frequency components to enable efficient and faithful video reconstruction. FaNeRV introduces a multi-resolution supervision strategy that guides the network to progressively capture global structures and fine-grained textures through staged supervision . To further enhance high-frequency reconstruction, we propose a dynamic high-frequency injection mechanism that adaptively emphasizes challenging regions. In addition, we design a frequency-decomposed network module to improve feature modeling across different spectral bands. Extensive experiments on standard benchmarks demonstrate that FaNeRV significantly outperforms state-of-the-art INR methods and achieves competitive rate-distortion performance against traditional codecs.

</details>


### [86] [Video Compression with Hierarchical Temporal Neural Representation](https://arxiv.org/abs/2601.17743)
*Jun Zhu,Xinfeng Zhang,Lv Tang,Junhao Jiang,Gai Zhang,Jia Wang*

Main category: cs.CV

TL;DR: 本文提出了一种分层时间神经表示方法TeNeRV，通过帧间特征融合模块和GoP自适应调制机制，有效建模视频中的短时与长时依赖关系，在率失真性能上超越现有隐式神经表示方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示（INR）的视频压缩方法将时间维度视为独立输入，难以捕捉复杂的时序依赖关系。

Method: 提出TeNeRV框架，包含两个核心组件：1）帧间特征融合（IFF）模块，聚合相邻帧特征以建模局部时序一致性与精细运动；2）GoP自适应调制（GAM）机制，将视频划分为图像组（GoP），学习组特定先验并调制网络参数以实现自适应表示。

Result: 在多个数据集上的实验表明，TeNeRV在率失真性能上持续优于现有INR-based视频压缩方法。

Conclusion: 分层建模短时与长时时间依赖对提升INR-based视频压缩性能至关重要，TeNeRV为高效视频表示提供了新思路。

Abstract: Video compression has recently benefited from implicit neural representations (INRs), which model videos as continuous functions. INRs offer compact storage and flexible reconstruction, providing a promising alternative to traditional codecs. However, most existing INR-based methods treat the temporal dimension as an independent input, limiting their ability to capture complex temporal dependencies. To address this, we propose a Hierarchical Temporal Neural Representation for Videos, TeNeRV. TeNeRV integrates short- and long-term dependencies through two key components. First, an Inter-Frame Feature Fusion (IFF) module aggregates features from adjacent frames, enforcing local temporal coherence and capturing fine-grained motion. Second, a GoP-Adaptive Modulation (GAM) mechanism partitions videos into Groups-of-Pictures and learns group-specific priors. The mechanism modulates network parameters, enabling adaptive representations across different GoPs. Extensive experiments demonstrate that TeNeRV consistently outperforms existing INR-based methods in rate-distortion performance, validating the effectiveness of our proposed approach.

</details>


### [87] [Bridging Supervision Gaps: A Unified Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.17747)
*Kaixuan Jiang,Chen Wu,Zhenghui Zhao,Chengxi Han*

Main category: cs.CV

TL;DR: 本文提出了一种统一的遥感影像变化检测框架UniCD，能够同时处理监督、弱监督和无监督三种标注条件下的变化检测任务，通过共享编码器和多分支协同学习机制实现异构监督信号的深度融合，在多个数据集上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中像素级变化标签获取成本高，现有模型难以适应不同标注可用性的场景。

Method: 提出UniCD框架，包含三个监督特定分支：监督分支引入时空感知模块（STAM）实现双时相特征协同融合；弱监督分支构建变化表征正则化（CRR）引导模型从粗粒度激活向一致可分的变化建模收敛；无监督分支提出语义先验驱动的变化推理（SPCI），将无监督任务转化为受控的弱监督路径优化。

Result: 在主流数据集上，UniCD在三类任务中均取得最优性能，在LEVIR-CD数据集上弱监督和无监督场景分别比当前SOTA提升12.72%和12.37%。

Conclusion: UniCD通过深度耦合异构监督信号，有效缓解了对密集像素级标注的依赖，提升了模型在不同标注条件下的泛化能力和实用性。

Abstract: Change detection (CD) aims to identify surface changes from multi-temporal remote sensing imagery. In real-world scenarios, Pixel-level change labels are expensive to acquire, and existing models struggle to adapt to scenarios with diverse annotation availability. To tackle this challenge, we propose a unified change detection framework (UniCD), which collaboratively handles supervised, weakly-supervised, and unsupervised tasks through a coupled architecture. UniCD eliminates architectural barriers through a shared encoder and multi-branch collaborative learning mechanism, achieving deep coupling of heterogeneous supervision signals. Specifically, UniCD consists of three supervision-specific branches. In the supervision branch, UniCD introduces the spatial-temporal awareness module (STAM), achieving efficient synergistic fusion of bi-temporal features. In the weakly-supervised branch, we construct change representation regularization (CRR), which steers model convergence from coarse-grained activations toward coherent and separable change modeling. In the unsupervised branch, we propose semantic prior-driven change inference (SPCI), which transforms unsupervised tasks into controlled weakly-supervised path optimization. Experiments on mainstream datasets demonstrate that UniCD achieves optimal performance across three tasks. It exhibits significant accuracy improvements in weakly and unsupervised scenarios, surpassing current state-of-the-art by 12.72% and 12.37% on LEVIR-CD, respectively.

</details>


### [88] [Agreement-Driven Multi-View 3D Reconstruction for Live Cattle Weight Estimation](https://arxiv.org/abs/2601.17791)
*Rabin Dulal,Wenfeng Jia,Lihong Zheng,Jane Quinn*

Main category: cs.CV

TL;DR: 本文提出了一种基于多视角RGB图像和SAM 3D融合的非接触式牛只活体重估计算法，在低数据条件下验证了经典集成模型优于深度学习模型，具备农场实用价值。


<details>
  <summary>Details</summary>
Motivation: 传统称重和体况评分方法需人工干预，影响动物福利与生产效率，亟需低成本、非接触、高精度的替代方案。

Method: 采用多视角RGB图像输入，结合SAM 3D模型与一致性引导的点云融合策略生成单头牛3D点云，再分别用经典集成回归（如随机森林、XGBoost）和深度学习模型进行体重回归预测。

Result: SAM 3D+多视角融合在重建质量上最优；经典集成模型在低数据下表现最稳健（R² = 0.69 ± 0.10，MAPE = 2.22 ± 0.56%），更适合实际牧场部署。

Conclusion: 提升3D重建质量比增加模型复杂度更能提升体重估计性能，该轻量、非接触方案可支撑规模化牧场应用。

Abstract: Accurate cattle live weight estimation is vital for livestock management, welfare, and productivity. Traditional methods, such as manual weighing using a walk-over weighing system or proximate measurements using body condition scoring, involve manual handling of stock and can impact productivity from both a stock and economic perspective. To address these issues, this study investigated a cost-effective, non-contact method for live weight calculation in cattle using 3D reconstruction. The proposed pipeline utilized multi-view RGB images with SAM 3D-based agreement-guided fusion, followed by ensemble regression. Our approach generates a single 3D point cloud per animal and compares classical ensemble models with deep learning models under low-data conditions. Results show that SAM 3D with multi-view agreement fusion outperforms other 3D generation methods, while classical ensemble models provide the most consistent performance for practical farm scenarios (R$^2$ = 0.69 $\pm$ 0.10, MAPE = 2.22 $\pm$ 0.56 \%), making this practical for on-farm implementation. These findings demonstrate that improving reconstruction quality is more critical than increasing model complexity for scalable deployment on farms where producing a large volume of 3D data is challenging.

</details>


### [89] [ViTCoP: Accelerating Large Vision-Language Models via Visual and Textual Semantic Collaborative Pruning](https://arxiv.org/abs/2601.17818)
*Wen Luo,Peng Chen,Xiaotao Huang,LiQun Huang*

Main category: cs.CV

TL;DR: 本文提出ViTCoP框架，通过视觉编码器冗余过滤与LLM中基于层级特性的逐步协同剪枝，结合L2范数作为K向量显著性度量，有效保留关键且信息多样的视觉token，在图像和视频理解任务中实现SOTA性能，同时显著降低推理延迟和GPU显存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有视觉token剪枝方法存在两大局限：在视觉编码器中剪枝易过早丢失关键视觉信息；在大语言模型（LLM）中剪枝则易导致所选token间信息冗余。

Method: 提出视觉与文本语义协同剪枝框架（ViTCoP），包含两部分：1）在视觉编码器中进行冗余过滤；2）在LLM中基于其层级结构进行逐步协同剪枝；并引入K向量的L2范数作为LLM中的token显著性度量，以兼容FlashAttention等加速技术。

Result: 在多种大型视觉-语言模型上广泛实验表明，ViTCoP在图像和视频理解任务上均超越现有方法，达到SOTA性能；同时显著降低推理延迟和GPU内存消耗，且在极端剪枝率下优势更明显。

Conclusion: ViTCoP通过联合优化视觉编码器与LLM中的剪枝策略，并采用适配硬件加速的显著性度量，实现了高效、鲁棒且高性能的视觉token压缩，为LVLM的轻量化部署提供了新思路。

Abstract: Large Vision-Language Models (LVLMs) incur high computational costs due to significant redundancy in their visual tokens. To effectively reduce this cost, researchers have proposed various visual token pruning methods. However, existing methods are generally limited, either losing critical visual information prematurely due to pruning in the vision encoder, or leading to information redundancy among the selected tokens due to pruning in the Large Language Models (LLMs). To address these challenges, we propose a Visual and Textual Semantic Collaborative Pruning framework (ViTCoP) that combines redundancy filtering in the vision encoder with step-wise co-pruning within the LLM based on its hierarchical characteristics, to efficiently preserve critical and informationally diverse visual tokens. Meanwhile, to ensure compatibility with acceleration techniques like FlashAttention, we introduce the L2 norm of K-vectors as the token saliency metric in the LLM. Extensive experiments on various Large Vision-Language Models demonstrate that ViTCoP not only achieves state-of-the-art performance surpassing existing methods on both image and video understanding tasks, but also significantly reduces model inference latency and GPU memory consumption. Notably, its performance advantage over other methods becomes even more pronounced under extreme pruning rates.

</details>


### [90] [VAE-REPA: Variational Autoencoder Representation Alignment for Efficient Diffusion Training](https://arxiv.org/abs/2601.17830)
*Mengmeng Wang,Dengyang Jiang,Liuzhuozheng Li,Yucheng Lin,Guojiang Shen,Xiangjie Kong,Yong Liu,Guang Dai,Jingdong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级内在引导框架\name，利用预训练VAE的重建特性对扩散Transformer进行特征对齐，从而在不增加外部计算开销的前提下加速训练并提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有去噪扩散Transformer训练收敛效率低，而现有加速方法（如REPA、SRA）因依赖外部编码器或双模型结构带来高计算开销。

Method: 提出\name框架，利用现成预训练VAE的隐式视觉先验（纹理、结构、语义），通过轻量投影层对齐扩散Transformer中间特征与VAE特征，并以特征对齐损失进行监督。

Result: 实验表明\name在生成质量与训练收敛速度上均优于基线扩散Transformer，媲美或超越现有加速方法，仅增加4% GFLOPs，且无需额外外部引导模型。

Conclusion: \name是一种简单有效、低开销的扩散模型训练加速方案，通过内在特征对齐实现高效训练。

Abstract: Denoising-based diffusion transformers, despite their strong generation performance, suffer from inefficient training convergence. Existing methods addressing this issue, such as REPA (relying on external representation encoders) or SRA (requiring dual-model setups), inevitably incur heavy computational overhead during training due to external dependencies. To tackle these challenges, this paper proposes \textbf{\namex}, a lightweight intrinsic guidance framework for efficient diffusion training. \name leverages off-the-shelf pre-trained Variational Autoencoder (VAE) features: their reconstruction property ensures inherent encoding of visual priors like rich texture details, structural patterns, and basic semantic information. Specifically, \name aligns the intermediate latent features of diffusion transformers with VAE features via a lightweight projection layer, supervised by a feature alignment loss. This design accelerates training without extra representation encoders or dual-model maintenance, resulting in a simple yet effective pipeline. Extensive experiments demonstrate that \name improves both generation quality and training convergence speed compared to vanilla diffusion transformers, matches or outperforms state-of-the-art acceleration methods, and incurs merely 4\% extra GFLOPs with zero additional cost for external guidance models.

</details>


### [91] [Geometry-Grounded Gaussian Splatting](https://arxiv.org/abs/2601.17835)
*Baowen Zhang,Chenxing Jiang,Heng Li,Shaojie Shen,Ping Tan*

Main category: cs.CV

TL;DR: 本文提出了一种基于高斯原语作为随机实体的几何感知高斯点绘方法，通过理论推导和体积渲染实现高质量形状重建。


<details>
  <summary>Details</summary>
Motivation: 现有高斯点绘方法在形状提取方面存在几何参数化不足、近似效果差的问题，导致多视角一致性差且对浮点噪声敏感。

Method: 通过严格的理论推导，将高斯原语建模为一类随机实体，并利用其体素特性高效渲染高质量深度图以进行细粒度几何提取。

Result: 在公开数据集上，该方法在所有基于高斯点绘的形状重建方法中取得了最优结果。

Conclusion: 高斯原语可被严谨地视为随机实体，从而为几何驱动的高斯点绘提供了理论基础和实用路径。

Abstract: Gaussian Splatting (GS) has demonstrated impressive quality and efficiency in novel view synthesis. However, shape extraction from Gaussian primitives remains an open problem. Due to inadequate geometry parameterization and approximation, existing shape reconstruction methods suffer from poor multi-view consistency and are sensitive to floaters. In this paper, we present a rigorous theoretical derivation that establishes Gaussian primitives as a specific type of stochastic solids. This theoretical framework provides a principled foundation for Geometry-Grounded Gaussian Splatting by enabling the direct treatment of Gaussian primitives as explicit geometric representations. Using the volumetric nature of stochastic solids, our method efficiently renders high-quality depth maps for fine-grained geometry extraction. Experiments show that our method achieves the best shape reconstruction results among all Gaussian Splatting-based methods on public datasets.

</details>


### [92] [SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction](https://arxiv.org/abs/2601.17857)
*Lan Yang,Minghan Yang,Ke Li,Honggang Zhang,Kaiyue Pang,Yi-Zhe Song*

Main category: cs.CV

TL;DR: 本文提出SynMind框架，通过将fMRI信号解析为多粒度语义文本描述，并结合视觉先验引导扩散模型，显著提升脑成像重建的语义准确性与感知一致性。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI图像重建方法虽具高视觉保真度，但常出现语义错位（如物体误识别或幻觉），因其过度依赖低级视觉特征而非显式语义表征。

Method: 利用具身化视觉语言模型（VLM）生成合成的、类人的多粒度文本描述（含物体身份与空间关系），以此作为显式语义编码；再将该编码与视觉先验联合，驱动Stable Diffusion 1.4进行条件重建。

Result: SynMind在多数定量指标上超越SOTA方法；仅用SD 1.4和单消费级GPU即优于基于SDXL的方法；人类评估证实其重建更符合人眼感知；神经可视化显示其激活更广泛、语义更相关的脑区。

Conclusion: 显式引入分层语义解码可有效缓解fMRI重建中的语义失准问题，验证了‘语义先行’范式在脑解码中的关键作用。

Abstract: Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.

</details>


### [93] [Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment](https://arxiv.org/abs/2601.17862)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、量子增强的域泛化框架，用于提升医学影像AI模型在跨中心部署中的鲁棒性，无需真实多中心标注数据。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI模型在单中心表现良好，但在跨中心真实场景中因域偏移导致性能下降，临床泛化能力受限。

Method: 构建基于MobileNetV2的域不变编码器，结合三部分：（1）多域成像偏移仿真（亮度、对比度等扰动）；（2）带梯度反转的域对抗训练；（3）轻量级参数化量子电路特征增强层；并引入测试时自适应策略。

Result: 在模拟多中心数据集上显著优于无域泛化或无量子增强的基线模型，降低域间性能方差，提升AUC和敏感度。

Conclusion: 量子增强的域泛化方法在计算资源受限下具备临床应用潜力，为混合量子-经典医学影像系统提供了可行范式。

Abstract: Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.

</details>


### [94] [MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance](https://arxiv.org/abs/2601.17866)
*Yoonwoo Jeong,Cheng Sun,Yu-Chiang Frank Wang,Minsu Cho,Jaesung Choe*

Main category: cs.CV

TL;DR: 本文提出MV-SAM框架，利用点图（pointmaps）实现多视角图像的3D一致分割，无需显式3D网络或标注数据，在多个基准上超越SAM2-Video并媲美需场景级优化的方法。


<details>
  <summary>Details</summary>
Motivation: 现有可提示分割模型（如SAM）在视频和多视角图像中缺乏3D感知，导致跨视角结果不一致，需昂贵的逐场景优化来保证3D一致性。

Method: MV-SAM利用视觉几何模型重建的点图，将SAM的图像嵌入提升为3D点嵌入，并通过带3D位置编码的transformer解码器与3D提示嵌入进行交叉注意力融合，实现2D交互与3D几何对齐。

Result: 在NVOS、SPIn-NeRF、ScanNet++、uCo3D和DL3DV等多个基准上，MV-SAM优于SAM2-Video，并达到与需逐场景优化方法相当的性能；且仅在SA-1B数据集上训练即具备良好泛化能力。

Conclusion: MV-SAM证明了借助无姿态图像重建的点图即可高效实现多视角3D一致分割，避免了对3D专用网络或标注数据的依赖，为可提示分割迈向真正3D感知提供了新范式。

Abstract: Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps -- 3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel-point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks. Code will be released.

</details>


### [95] [VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding](https://arxiv.org/abs/2601.17868)
*Zhihao He,Tieyuan Chen,Kangyu Wang,Ziran Qin,Yang Shao,Chaofan Gan,Shijie Li,Zuxuan Wu,Weiyao Lin*

Main category: cs.CV

TL;DR: 本文提出VidLaDA，一种基于扩散语言模型的视频大语言模型，通过双向注意力机制克服自回归模型的因果掩码偏差，并引入MARS-Cache框架加速推理，在保持准确率的同时实现12倍以上加速。


<details>
  <summary>Details</summary>
Motivation: 标准自回归视频大语言模型受因果掩码偏差影响，难以进行全局时空建模，导致理解效率低下。

Method: 提出基于扩散语言模型（DLM）的VidLaDA，采用双向注意力；并设计MARS-Cache，结合异步视觉缓存刷新与帧级分块注意力，利用锚点令牌保留全局连通性。

Result: VidLaDA在多项实验中超越扩散基线模型，性能媲美Qwen2.5-VL和LLaVA-Video等先进自回归模型；MARS-Cache带来超12倍推理加速且不损推理精度。

Conclusion: VidLaDA通过双向建模与高效缓存机制，显著提升视频语言理解效率与可扩展性，为视频大模型提供新范式。

Abstract: Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.

</details>


### [96] [Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran](https://arxiv.org/abs/2601.17880)
*Muhammad Umar Salman,Mohammad Areeb Qazi,Mohammed Talha Alam*

Main category: cs.CV

TL;DR: Quran MD is a multimodal Quran dataset integrating Arabic text, English translation, transliteration, and audio at verse and word levels from 32 reciters, supporting NLP, speech processing, linguistic analysis, and Islamic digital studies.


<details>
  <summary>Details</summary>
Motivation: To bridge the textual and oral traditions of the Quran computationally by creating a fine-grained, multimodal resource that supports diverse research and community applications in digital Islamic studies and speech-language technologies.

Method: Constructed a verse- and word-level multimodal dataset including original Arabic text, English translation, phonetic transliteration, and aligned audio recordings from 32 distinct reciters; ensured precise text-audio alignment at the word level for phonological and semantic analysis.

Result: A publicly available, comprehensive multimodal Quran dataset (Quran MD) enabling ASR, tajweed detection, Quranic TTS, multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems.

Conclusion: Quran MD establishes a foundational, scalable resource for advancing computational linguistics, speech technology, and digital humanities research focused on the Quran, fostering both academic inquiry and practical community tools.

Abstract: We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset

</details>


### [97] [Revisiting 3D Reconstruction Kernels as Low-Pass Filters](https://arxiv.org/abs/2601.17900)
*Shengjun Zhang,Min Chen,Yibo Wei,Mingyu Dong,Yueqi Duan*

Main category: cs.CV

TL;DR: 本文从信号处理角度重新审视3D重建，指出离散采样引起的周期性频谱延拓是根本挑战；提出Jinc核作为理想低通滤波器，并进一步设计调制核以平衡空间效率与频域保真度，显著提升渲染性能。


<details>
  <summary>Details</summary>
Motivation: 离散采样导致的周期性频谱延拓是3D重建的根本挑战，现有核函数（如高斯、指数、t分布）作为非理想低通滤波器会引起频谱混叠。

Method: 引入具有理想截止特性的Jinc核，并设计调制核以改善其空间衰减速度，在频域保真度与空间效率之间取得更好平衡。

Result: 所提出的Jinc核与调制核在实验中展现出更优的渲染性能。

Conclusion: 基于理想低通滤波思想设计的Jinc及调制核能有效缓解频谱混叠问题，为3D重建提供新的信号处理视角和实用解决方案。

Abstract: 3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.

</details>


### [98] [Feature-Space Generative Models for One-Shot Class-Incremental Learning](https://arxiv.org/abs/2601.17905)
*Jack Foster,Kirill Paramonov,Mete Ozay,Umberto Michieli*

Main category: cs.CV

TL;DR: 本文提出Gen1S方法，通过将嵌入空间映射到残差空间并利用VAE或扩散模型学习残差的多模态分布，以提升单样本类增量学习中对新类的识别能力。


<details>
  <summary>Details</summary>
Motivation: 解决单样本类增量学习（1-shot FSCIL）中仅用一个样本识别新类且不允许后续训练或模型修改的难题。

Method: 将原始嵌入空间映射为残差空间（减去类原型），再用VAE或扩散模型建模基类残差的多模态分布，将其作为结构先验辅助新类识别。

Result: Gen1S在多个基准和骨干网络上持续超越现有最优方法。

Conclusion: 基类与新类嵌入具有结构相似性，利用残差空间建模可有效提升单样本增量学习性能。

Abstract: Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.

</details>


### [99] [Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models](https://arxiv.org/abs/2601.17918)
*Dain Kim,Jiwoo Lee,Jaehoon Yun,Yong Hoe Koo,Qingyu Chen,Hyunjae Kim,Jaewoo Kang*

Main category: cs.CV

TL;DR: 本文首次系统评估了多种直接偏好优化（DPO）变体在医学大视觉语言模型（LVLMs）中的效果，发现其性能不稳定且难以纠正视觉误判；为此提出一种针对性的偏好构建策略，在VQA任务上提升3.6%，并开源全部资源。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs在医疗应用中存在对齐不足和可靠性差的问题，而DPO在该高风险领域的实证研究尚属空白，亟需系统性评估与方法改进。

Method: 对九种DPO变体在LLaVA-Med和HuatuoGPT-Vision两个医学LVLM上进行跨任务、跨骨干的全面评估，并提出一种聚焦视觉误判修正的偏好构造策略。

Result: 发现当前DPO方法增益不稳定、任务依赖性强，且难以解决视觉误判；新策略在医学视觉问答任务上相较最强DPO基线提升3.6%。

Conclusion: DPO在医学LVLM中的应用需更精细的设计，尤其应针对领域特有错误（如视觉误判）定制偏好信号；本工作为后续研究提供了基准、洞见与开源资源。

Abstract: Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.

</details>


### [100] [RemEdit: Efficient Diffusion Editing with Riemannian Geometry](https://arxiv.org/abs/2601.17927)
*Eashan Adhikarla,Brian D. Davison*

Main category: cs.CV

TL;DR: RemEdit 是一种基于扩散模型的可控图像生成框架，通过将潜在空间建模为黎曼流形并结合 Mamba 模块实现高保真语义编辑，同时引入任务特定的注意力剪枝机制以加速推理，在保持实时性的同时超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决可控图像生成中语义保真度与推理速度之间的关键权衡问题。

Method: 1）将潜在空间视为黎曼流形，用 Mamba 模块学习其结构并计算测地线路径；2）采用双 SLERP 融合与视觉语言模型驱动的目标感知提示增强；3）设计轻量级任务特定注意力剪枝头，动态保留编辑相关 token。

Result: 在保持实时性能（50% 剪枝下）的同时，编辑质量超越现有最先进方法。

Conclusion: RemEdit 为实用、强大的图像编辑设立了新基准。

Abstract: Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.

</details>


### [101] [From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images](https://arxiv.org/abs/2601.17934)
*Vi Vu,Thanh-Huy Nguyen,Tien-Thinh Nguyen,Ba-Thinh Lam,Hoang-Thien Nguyen,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: 本文提出SC-SAM框架，通过U-Net（专家）与SAM（通才）的双向协同训练，利用无标签数据提升半监督医学图像分割性能，在前列腺MRI和息肉分割任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 基础模型（如SAM）在医学图像适应中面临领域偏移、标注稀缺及PEFT无法利用无标签数据等问题；而传统模型（如U-Net）在半监督医学学习中表现优异，但其辅助PEFT SAM的潜力被忽视。

Method: 提出SC-SAM框架：U-Net生成点提示和伪标签引导SAM微调，SAM则作为强泛化监督者正则化U-Net，形成双向共训循环以联合利用无标签数据。

Result: 在前列腺MRI和结肠息肉分割两个基准上均达到当前最优性能，超越其他半监督SAM变体及MedSAM等医学基础模型。

Conclusion: 专家（U-Net）与通才（SAM）协同合作可显著提升标签效率，为医学图像分割提供新范式。

Abstract: Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.

</details>


### [102] [DTC: A Deformable Transposed Convolution Module for Medical Image Segmentation](https://arxiv.org/abs/2601.17939)
*Chengkun Sun,Jinqian Pan,Renjie Liang,Zhengkang Fan,Xin Miao,Jiang Bian,Jie Xu*

Main category: cs.CV

TL;DR: 本文提出了一种可变形转置卷积（DTC）方法，用于医学图像分割中的上采样，通过学习动态采样位置来提升特征重建与细节恢复能力。


<details>
  <summary>Details</summary>
Motivation: 传统上采样方法（如转置卷积和线性插值）在固定位置操作，难以捕获结构信息，易引入伪影或丢失细节。

Method: 受可变形卷积启发，提出可变形转置卷积（DTC），自动学习动态采样坐标，适用于2D和3D医学图像分割。

Result: 在BTCV15、ISIC18、BUSI等多个数据集上验证，DTC能有效集成到现有模型中，持续提升解码器的特征重建与细节恢复性能。

Conclusion: DTC是一种更灵活、更具表现力的上采样方法，在医学图像分割任务中具有广泛适用性和优越性。

Abstract: In medical image segmentation, particularly in UNet-like architectures, upsampling is primarily used to transform smaller feature maps into larger ones, enabling feature fusion between encoder and decoder features and supporting multi-scale prediction. Conventional upsampling methods, such as transposed convolution and linear interpolation, operate on fixed positions: transposed convolution applies kernel elements to predetermined pixel or voxel locations, while linear interpolation assigns values based on fixed coordinates in the original feature map. These fixed-position approaches may fail to capture structural information beyond predefined sampling positions and can lead to artifacts or loss of detail. Inspired by deformable convolutions, we propose a novel upsampling method, Deformable Transposed Convolution (DTC), which learns dynamic coordinates (i.e., sampling positions) to generate high-resolution feature maps for both 2D and 3D medical image segmentation tasks. Experiments on 3D (e.g., BTCV15) and 2D datasets (e.g., ISIC18, BUSI) demonstrate that DTC can be effectively integrated into existing medical image segmentation models, consistently improving the decoder's feature reconstruction and detail recovery capability.

</details>


### [103] [FlowMorph: Physics-Consistent Self-Supervision for Label-Free Single-Cell Mechanics in Microfluidic Videos](https://arxiv.org/abs/2601.17947)
*Bora Yimenicioglu,Vishal Manikanden*

Main category: cs.CV

TL;DR: 本文提出FlowMorph，一种物理一致的自监督框架，用于从微流控亮场视频中无标签地学习红细胞（RBC）力学代理参数k，无需人工标注或手工特征，融合斯托克斯流物理建模与可微分轮廓演化，在多个数据集上实现高分割精度、良好面积守恒性，并能有效区分RBC动力学模式及预测杨氏模量。


<details>
  <summary>Details</summary>
Motivation: 红细胞机械性能是血液与系统性疾病的重要生物标志物，但现有高通量微流控分析方法依赖监督分割或手工设计的kymograph，且未显式编码支配RBC形变的层流斯托克斯物理规律。

Method: FlowMorph构建低维参数化轮廓表示单个RBC，通过可微分的'胶囊在流中'模型联合层流对流与曲率正则化弹性松弛推进边界点，并以仅由自动提取的轮廓和光流导出的损失函数（包括轮廓重叠、胞内流一致性、面积守恒、壁约束和时间平滑性）进行端到端优化。

Result: 在四个公开RBC微流控数据集上，FlowMorph平均轮廓IoU达0.905；在约15万中心化序列中，标量k单独区分tank-treading与flipping动力学的AUC为0.863；仅用200个RT-DC事件校准后，单调映射E=g(k)预测表观杨氏模量的平均绝对误差为0.118 MPa，且对通道几何、光学与帧率变化鲁棒。

Conclusion: FlowMorph实现了物理引导、自监督、无标签的RBC力学量化，显著提升形变建模的物理保真度与泛化能力，为高通量无标记血液力学诊断提供新范式。

Abstract: Mechanical properties of red blood cells (RBCs) are promising biomarkers for hematologic and systemic disease, motivating microfluidic assays that probe deformability at throughputs of $10^3$--$10^6$ cells per experiment. However, existing pipelines rely on supervised segmentation or hand-crafted kymographs and rarely encode the laminar Stokes-flow physics that governs RBC shape evolution. We introduce FlowMorph, a physics-consistent self-supervised framework that learns a label-free scalar mechanics proxy $k$ for each tracked RBC from short brightfield microfluidic videos. FlowMorph models each cell by a low-dimensional parametric contour, advances boundary points through a differentiable ''capsule-in-flow'' combining laminar advection and curvature-regularized elastic relaxation, and optimizes a loss coupling silhouette overlap, intra-cellular flow agreement, area conservation, wall constraints, and temporal smoothness, using only automatically derived silhouettes and optical flow.
  Across four public RBC microfluidic datasets, FlowMorph achieves a mean silhouette IoU of $0.905$ on physics-rich videos with provided velocity fields and markedly improves area conservation and wall violations over purely data-driven baselines. On $\sim 1.5\times 10^5$ centered sequences, the scalar $k$ alone separates tank-treading from flipping dynamics with an AUC of $0.863$. Using only $200$ real-time deformability cytometry (RT-DC) events for calibration, a monotone map $E=g(k)$ predicts apparent Young's modulus with a mean absolute error of $0.118$\,MPa on $600$ held-out cells and degrades gracefully under shifts in channel geometry, optics, and frame rate.

</details>


### [104] [UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders](https://arxiv.org/abs/2601.17950)
*Matthew Walmer,Saksham Suri,Anirud Aggarwal,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 本文提出UPLiFT架构及Local Attender算子，通过改进迭代上采样方法，在像素级特征上采样任务中实现SOTA性能且推理成本更低，并在生成式下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于交叉注意力的特征上采样方法存在效率扩展问题；而早期迭代上采样方法被忽视，但仍有潜力提升性能与效率平衡。

Method: 提出UPLiFT通用轻量级像素稠密特征变换架构，并设计局部注意力算子（Local Attender），采用完全局部定义的注意力池化机制，替代全局或交叉注意力，以稳定迭代上采样过程中的特征。

Result: UPLiFT在像素稠密特征上采样任务中达到SOTA性能，推理开销低于现有方法；在VAE特征上采样的生成任务中，性能媲美先进耦合流匹配模型。

Conclusion: 迭代上采样方法仍具竞争力；UPLiFT结合Local Attender提供了一种高效、稳定、通用的特征上采样新范式。

Abstract: The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.

</details>


### [105] [Domain-Expert-Guided Hybrid Mixture-of-Experts for Medical AI: Integrating Data-Driven Learning with Clinical Priors](https://arxiv.org/abs/2601.17977)
*Jinchen Gu,Nan Zhao,Lei Qiu,Lu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种域知识引导的混合MoE模型（DKGH-MoE），将数据驱动专家与临床专家引导专家结合，提升医学图像分析的性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: MoE模型在医学等小数据领域效果受限，而临床实践中丰富的专家知识（如医生注视模式、诊断启发式）难以被模型从有限数据中可靠学习。

Method: 提出DKGH-MoE模块：包含一个数据驱动MoE提取影像新特征，以及一个融合医生眼动线索等临床先验的域专家引导MoE，以突出高诊断价值区域；整体为即插即用、可解释架构。

Result: DKGH-MoE在提升模型性能的同时增强了临床可解释性，实现了数据驱动与领域知识的互补融合。

Conclusion: 融合域知识与数据驱动学习的混合MoE架构，能有效缓解医学小样本挑战，并提升模型的鲁棒性与临床可信度。

Abstract: Mixture-of-Experts (MoE) models increase representational capacity with modest computational cost, but their effectiveness in specialized domains such as medicine is limited by small datasets. In contrast, clinical practice offers rich expert knowledge, such as physician gaze patterns and diagnostic heuristics, that models cannot reliably learn from limited data. Combining data-driven experts, which capture novel patterns, with domain-expert-guided experts, which encode accumulated clinical insights, provides complementary strengths for robust and clinically meaningful learning. To this end, we propose Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE), a plug-and-play and interpretable module that unifies data-driven learning with domain expertise. DKGH-MoE integrates a data-driven MoE to extract novel features from raw imaging data, and a domain-expert-guided MoE incorporates clinical priors, specifically clinician eye-gaze cues, to emphasize regions of high diagnostic relevance. By integrating domain expert insights with data-driven features, DKGH-MoE improves both performance and interpretability.

</details>


### [106] [MorphXAI: An Explainable Framework for Morphological Analysis of Parasites in Blood Smear Images](https://arxiv.org/abs/2601.18001)
*Aqsa Yousaf,Sint Sint Win,Megan Coffee,Habeeb Olufowobi*

Main category: cs.CV

TL;DR: 本文提出MorphXAI框架，将寄生虫检测与细粒度形态学分析统一起来，通过形态监督提升模型可解释性，并构建了含三种寄生虫形态标注的临床数据集。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在寄生虫检测中缺乏可解释性，传统可视化方法无法反映医生依赖的形态学特征。

Method: 提出MorphXAI框架，在检测流程中嵌入形态学监督，联合定位寄生虫并量化形状、曲率、点状结构数量、鞭毛存在性及发育阶段等临床相关属性；构建由临床医生标注的三种寄生虫（利什曼原虫、布氏锥虫、克氏锥虫）形态数据集。

Result: MorphXAI在检测性能上优于基线模型，并能生成结构化、生物学意义明确的解释。

Conclusion: 形态学监督可有效增强寄生虫检测模型的可解释性与临床实用性，为医学AI提供新范式。

Abstract: Parasitic infections remain a pressing global health challenge, particularly in low-resource settings where diagnosis still depends on labor-intensive manual inspection of blood smears and the availability of expert domain knowledge. While deep learning models have shown strong performance in automating parasite detection, their clinical usefulness is constrained by limited interpretability. Existing explainability methods are largely restricted to visual heatmaps or attention maps, which highlight regions of interest but fail to capture the morphological traits that clinicians rely on for diagnosis. In this work, we present MorphXAI, an explainable framework that unifies parasite detection with fine-grained morphological analysis. MorphXAI integrates morphological supervision directly into the prediction pipeline, enabling the model to localize parasites while simultaneously characterizing clinically relevant attributes such as shape, curvature, visible dot count, flagellum presence, and developmental stage. To support this task, we curate a clinician-annotated dataset of three parasite species (Leishmania, Trypanosoma brucei, and Trypanosoma cruzi) with detailed morphological labels, establishing a new benchmark for interpretable parasite analysis. Experimental results show that MorphXAI not only improves detection performance over the baseline but also provides structured, biologically meaningful explanations.

</details>


### [107] [Strip-Fusion: Spatiotemporal Fusion for Multispectral Pedestrian Detection](https://arxiv.org/abs/2601.18008)
*Asiegbu Miracle Kanu-Asiegbu,Nitin Jotwani,Xiaoxiao Du*

Main category: cs.CV

TL;DR: 本文提出Strip-Fusion，一种鲁棒的空间-时间融合网络，用于多光谱（可见光与热成像）行人检测，能有效应对图像错位、光照变化和严重遮挡等问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注空间融合而忽略时序信息，且多光谱数据集中的RGB与热图常存在未对齐问题；此外，光照变化与遮挡也增加了检测难度。

Method: 提出Strip-Fusion网络，包含时序自适应卷积以动态加权时空特征；设计KL散度损失缓解模态不平衡；并开发新后处理算法降低误检率。

Result: 在KAIST和CVC-14基准上性能领先，尤其在严重遮挡和图像错位等挑战性条件下显著优于先前SOTA方法。

Conclusion: Strip-Fusion通过联合建模时空信息与模态互补性，提升了多光谱行人检测的鲁棒性与精度，为实际机器人感知应用提供了更可靠方案。

Abstract: Pedestrian detection is a critical task in robot perception. Multispectral modalities (visible light and thermal) can boost pedestrian detection performance by providing complementary visual information. Several gaps remain with multispectral pedestrian detection methods. First, existing approaches primarily focus on spatial fusion and often neglect temporal information. Second, RGB and thermal image pairs in multispectral benchmarks may not always be perfectly aligned. Pedestrians are also challenging to detect due to varying lighting conditions, occlusion, etc. This work proposes Strip-Fusion, a spatial-temporal fusion network that is robust to misalignment in input images, as well as varying lighting conditions and heavy occlusions. The Strip-Fusion pipeline integrates temporally adaptive convolutions to dynamically weigh spatial-temporal features, enabling our model to better capture pedestrian motion and context over time. A novel Kullback-Leibler divergence loss was designed to mitigate modality imbalance between visible and thermal inputs, guiding feature alignment toward the more informative modality during training. Furthermore, a novel post-processing algorithm was developed to reduce false positives. Extensive experimental results show that our method performs competitively for both the KAIST and the CVC-14 benchmarks. We also observed significant improvements compared to previous state-of-the-art on challenging conditions such as heavy occlusion and misalignment.

</details>


### [108] [Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation](https://arxiv.org/abs/2601.18045)
*Zhuangzhi Gao,Feixiang Zhou,He Zhao,Xiuju Chen,Xiaoxin Li,Qinkai Yu,Yitian Zhao,Alena Shantsila,Gregory Y. H. Lip,Eduard Shantsila,Yalin Zheng*

Main category: cs.CV

TL;DR: 本文提出PIs-Regressor模块和Topology SegNet框架，直接从数据学习可微分的持久性图像（PI）表征，并将其嵌入网络结构中以提升医学图像中曲线结构分割的准确性和拓扑保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手工设计的拓扑损失函数，泛化能力差，且持久性图（PD）本身不可微、计算成本高，难以有效嵌入深度网络。

Method: 提出PIs-Regressor模块学习持久性图像（PI）表征，并构建Topology SegNet网络，在下采样和上采样阶段融合拓扑特征，将拓扑信息直接集成到网络架构中而非仅作为辅助损失。

Result: 在三个曲线结构基准上达到像素级精度与拓扑保真度的SOTA性能，显著提升对过曝光、模糊等医学影像退化问题的鲁棒性。

Conclusion: 将可微分拓扑表征（PI）直接嵌入分割网络结构比使用手工损失更有效、更鲁棒，为拓扑引导的医学图像分割提供了新范式。

Abstract: Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity.

</details>


### [109] [Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling](https://arxiv.org/abs/2601.18049)
*Yunfei Qiu,Qiqiong Ma,Tianhua Lv,Li Fang,Shudong Zhou,Wei Yao*

Main category: cs.CV

TL;DR: 本文提出了一种结合空间先验与动态学习机制的半监督高光谱图像分类框架，包含EASLP、DHP和ATSC三个核心模块，有效缓解边界标签扩散与伪标签不稳定问题，提升分类鲁棒性与精度。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像半监督分类面临标注成本高、样本少的问题，导致边界标签扩散和伪标签不稳定。

Method: 提出动态可靠性增强伪标签框架（DREPL），包含边缘感知超像素标签传播（EASLP）、动态历史融合预测（DHP）和自适应三元样本分类（ATSC）三个模块，实现空-时一致性优化。

Result: 在四个基准数据集上验证了该方法在分类性能上的优越性，显著提升了伪标签质量、时间一致性与抗噪能力。

Conclusion: 所提框架通过融合空间结构先验与动态学习策略，有效解决了半监督高光谱分类中的关键挑战，具备良好的泛化性与实用性。

Abstract: Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.

</details>


### [110] [Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification](https://arxiv.org/abs/2601.18088)
*Jianshu Chao,Tianhua Lv,Qiqiong Ma,Yunfei Qiu,Li Fang,Huifang Shen,Wei Yao*

Main category: cs.CV

TL;DR: 本文提出了一种无需源域标签的自监督跨域迁移框架，通过Spatial-Spectral Transformer（S2Former）和频域约束（FDC）实现光谱-空间联合表征学习，并在微调阶段引入扩散对齐蒸馏机制（DAFT），显著提升了少样本下跨域高光谱图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督高光谱方法依赖源域标注且易受分布偏移影响，跨域泛化能力差。

Method: 提出自监督跨域迁移框架：预训练阶段设计S2Former双分支光谱-空间Transformer与双向交叉注意力机制，并引入基于rFFT的频域约束（FDC）；微调阶段采用扩散对齐微调（DAFT）蒸馏机制。

Result: 在四个高光谱数据集上验证了该方法在跨域场景下具备稳定分类性能和强适应性，尤其适用于低资源条件。

Conclusion: 所提框架有效实现了无源标签、抗分布偏移、少样本适应的高光谱跨域迁移，为自监督遥感图像分析提供了新思路。

Abstract: Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions.

</details>


### [111] [Text-Pass Filter: An Efficient Scene Text Detector](https://arxiv.org/abs/2601.18098)
*Chuang Yang,Haozhao Ma,Xu Han,Yuan Yuan,Qi Wang*

Main category: cs.CV

TL;DR: 本文提出Text-Pass Filter（TPF）方法，直接分割整段文本以克服现有收缩掩码扩展策略丢失文本边缘特征的缺陷；通过模拟带通滤波器为每个文本构建独特特征-滤波器对，并引入强化集成单元（REU）和前景先验单元（FPU）提升识别效果与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于收缩掩码扩展的文本检测方法在收缩过程中丢失文本边缘视觉特征，混淆前景与背景差异，导致文本特征识别存在固有局限。

Method: 提出Text-Pass Filter（TPF），模拟带通滤波器原理，为每个文本构建专属特征-滤波器对；设计强化集成单元（REU）增强同一文本特征一致性并扩大识别感受野；引入前景先验单元（FPU）提升前景-背景判别能力。

Result: 实验验证了REU和FPU的有效性，且TPF在任意形状文本检测中展现出优越性能，尤其支持自然分离粘连文本，无需复杂解码或后处理，具备实时检测潜力。

Conclusion: TPF通过端到端直接分割整文本、结合REU与FPU模块，有效克服传统方法的特征损失问题，在精度、鲁棒性和效率上取得综合提升，为任意形状文本检测提供了新思路。

Abstract: To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.

</details>


### [112] [Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs](https://arxiv.org/abs/2601.18099)
*Akbar Saadat*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的前向计算框架，用于实时估计图像的高斯散焦模糊程度，通过离散化解析表达式并结合邻域相似性筛选，实现了高精度的模糊参数估计和图像重建。


<details>
  <summary>Details</summary>
Motivation: 为实现实时应用中的图像散焦模糊估计，需避免传统方法依赖训练数据和耗时优化的问题。

Method: 基于 sharper 图像解析推导 defocused 图像的数学表达式，离散计算不同高斯核标准差下的结果，并利用邻域点的相似性度量筛选唯一解；支持两幅图像互为部分模糊版本的情形。

Result: 在真实图像上实验表明，合成模糊值估计的平均绝对误差（MAE）低于 1.7%；将提取的散焦滤波器应用于较清晰图像所重建的模糊图像，其像素强度与真实模糊图像差异小于 2%。

Conclusion: 该零训练、前向计算框架高效且准确，适用于实时散焦模糊建模与图像恢复任务。

Abstract: Following the earlier verification for Gaussian model in \cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\%$, obtained by applying the extracted defocus filters to less blurred images.

</details>


### [113] [Spatial-Conditioned Reasoning in Long-Egocentric Videos](https://arxiv.org/abs/2601.18100)
*James Tribble,Hao Wang,Si-En Hong,Chaoyi Zhou,Ashish Bastola,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: 本文研究了显式空间信号对基于视觉语言模型（VLM）的长时程自我中心视频理解的影响，未修改模型结构或推理流程；提出了Sanpo-D数据集并融合深度图增强空间推理，在导航相关任务上验证了深度感知与空间定位表征对安全关键任务（如行人/障碍物检测）的性能提升。


<details>
  <summary>Details</summary>
Motivation: 长时程自我中心视频存在视角漂移和缺乏持久几何上下文的问题，现有VLM在空间推理能力上仍受限。

Method: 提出Sanpo-D细粒度重标注数据集，对多个VLM在导航导向的空间查询上进行基准测试，并通过融合深度图与RGB帧来考察输入级归纳偏置对空间推理的影响。

Result: 发现通用准确率与空间特化能力之间存在权衡；深度感知和空间定位表征可提升行人检测、障碍物检测等安全关键任务的性能。

Conclusion: 显式空间信号（如深度图）能有效增强VLM在长时程自我中心视频中的空间推理能力，无需改变模型架构，为安全敏感的视觉导航任务提供了实用改进路径。

Abstract: Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.

</details>


### [114] [LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment](https://arxiv.org/abs/2601.18118)
*Daeyoung Kim*

Main category: cs.CV

TL;DR: 本文提出LungCRCT框架，基于潜在因果表征学习，结合图自编码器因果发现算法与距离相关性解耦及熵驱动图像重建优化，实现肺癌因果干预分析与高精度恶性肿瘤分类（AUC达93.91%）。


<details>
  <summary>Details</summary>
Motivation: 肺癌早期无症状、症状易与其他呼吸系统疾病混淆，导致延误诊断；现有深度学习模型虽在检测任务中表现优异，但因果解释性差、难以支持治疗分析与因果干预模拟。

Method: 提出LungCRCT框架：采用图自编码器进行因果发现，引入距离相关性解耦以提升因果因子独立性，并结合熵驱动的图像重建优化提升表征质量。

Result: 实现了肺癌因果干预分析能力，并在恶性肿瘤分类任务中达到93.91%的AUC分数，同时模型轻量、鲁棒性强。

Conclusion: LungCRCT通过潜在因果表征学习，突破了传统深度学习在肺癌分析中可解释性与因果推理能力的局限，为临床治疗决策与干预模拟提供了新范式。

Abstract: Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.

</details>


### [115] [Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection](https://arxiv.org/abs/2601.18135)
*Jiahao Lyu,Minghua Zhao,Xuewen Huang,Yifei Chen,Shuangli Du,Jing Hu,Cheng Shi,Zhiyong Lv*

Main category: cs.CV

TL;DR: 本文提出FoGA，一种轻量级视频异常检测模型，通过前向一致性学习与门控上下文聚合，在边缘设备上实现高效准确的异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有VAD方法依赖大模型、难以部署于边缘设备，且多仅用单帧预测误差，忽略长期时序信息。

Method: 提出基于Unet的轻量模型FoGA（约2M参数），包含连续帧特征提取、门控上下文聚合模块（用于跳连）及前向一致性联合损失；采用融合即时与前向预测误差的混合异常度量策略。

Result: 在多个基准上显著优于SOTA方法，推理速度达155 FPS，兼顾高精度与高效率。

Conclusion: FoGA在性能与效率间取得优秀平衡，适用于资源受限的实时边缘监控场景。

Abstract: As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric.

</details>


### [116] [Agentic Very Long Video Understanding](https://arxiv.org/abs/2601.18157)
*Aniket Rege,Arka Sadhu,Yuliang Li,Kejie Li,Ramya Korlakai Vinayak,Yuning Chai,Yong Jae Lee,Hyo Jin Kim*

Main category: cs.CV

TL;DR: 本文提出了EGAgent，一种基于实体场景图的增强型代理框架，用于解决长时序自我中心视频理解问题，通过结构化搜索、跨模态推理和时序一致性建模，在EgoLifeQA和Video-MME（Long）数据集上取得SOTA或具竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于上下文窗口长度，难以对持续数天甚至数周的自我中心视频流进行组合式、多跳推理，无法满足全天候可穿戴AI助手对长期情境理解的需求。

Method: 提出EGAgent框架，核心是构建随时间演化的实体场景图（含人物、地点、物体及其关系），并配备规划代理、结构化搜索与推理工具，以及混合视听检索能力，支持跨模态与时序一致的推理。

Result: 在EgoLifeQA数据集上达到57.5%准确率（SOTA），在Video-MME（Long）上达74.1%，表现具竞争力。

Conclusion: 基于实体场景图的代理式架构能有效提升长时序自我中心视频的理解与推理能力，为持续性AI助手提供了可行技术路径。

Abstract: The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.

</details>


### [117] [TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration](https://arxiv.org/abs/2601.18168)
*Zehua Liu,Shihao Zou,Jincai Huang,Yanfang Zhang,Chao Tong,Weixin Si*

Main category: cs.CV

TL;DR: 本文提出了一种用于经动脉化疗栓塞术（TACE）中2D-3D血管配准的粗到精策略，包含结构感知的视角n点法（SA-PnP）和基于时间上下文的扩散模型TempDiffReg，在临床数据上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: TACE手术中血管导航复杂、解剖变异大，亟需准确鲁棒的2D-3D血管配准以辅助微导管精准定位和治疗。

Method: 提出粗到精两阶段配准策略：第一阶段用结构感知的视角n点法（SA-PnP）实现全局对齐；第二阶段用时序扩散模型TempDiffReg迭代建模血管形变，融合时间上下文以适应局部解剖变化。

Result: 在23例患者、626组多帧配对样本上验证，MSE为0.63 mm，MAE为0.51 mm，较最优现有方法分别降低66.7%和17.7%，配准精度与解剖合理性均更优。

Conclusion: 该方法有望提升TACE手术安全性与效率，尤其辅助经验不足的医生，改善手术效果与患者预后。

Abstract: Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\% lower MSE and 17.7\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}

</details>


### [118] [YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection](https://arxiv.org/abs/2601.18172)
*Lin Huang,Yujuan Tan,Weisheng Li,Shitai Shan,Liu Liu,Bo Liu,Linlin Shen,Jing Yu,Yue Niu*

Main category: cs.CV

TL;DR: 本文提出YOLO-DS框架，通过新型双统计协同算子（DSO）及其衍生的轻量级门控模块（DSG和MSG），显式建模共享特征通道内异质目标响应，在保持高效率的同时显著提升YOLO系列检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有YOLO检测器缺乏对共享特征通道内异质目标响应的显式建模，限制了性能进一步提升。

Method: 提出YOLO-DS框架，核心是双统计协同算子（DSO），联合建模通道均值与峰均比差异；并基于DSO设计双统计协同门控（DSG）模块和多路径分段门控（MSG）模块，分别实现通道自适应选择和深度特征加权。

Result: 在MS-COCO基准上，YOLO-DS在五个模型尺度（N/S/M/L/X）上均超越YOLOv8，AP提升1.1%–1.7%，仅带来极小推理延迟增加；可视化、消融及对比实验验证了其对异质目标判别能力与高效性的优势。

Conclusion: YOLO-DS通过显式建模异质目标响应，有效提升了YOLO系列检测器的精度与效率平衡，为一阶段检测器设计提供了新思路。

Abstract: One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.

</details>


### [119] [\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation](https://arxiv.org/abs/2601.18188)
*Weiye Zhu,Zekai Zhang,Xiangchen Wang,Hewei Pan,Teng Wang,Tiantian Geng,Rongtao Xu,Feng Zheng*

Main category: cs.CV

TL;DR: 本文提出NaVIDA框架，通过逆动力学增强和分层概率动作分块，显式建模视觉-动作因果关系，提升VLN任务中的泛化性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法缺乏对动作如何因果改变视觉观测的建模，导致行为不稳定、泛化弱、路径误差累积。

Method: 提出NaVIDA框架，包含三部分：1）基于分块的逆动力学监督学习视觉变化与动作的因果关系；2）分层概率动作分块（HPAC）组织多步轨迹并提供长程视觉变化线索；3）熵引导的自适应执行机制动态调整动作块执行步数。

Result: 在多个VLN基准上性能超越SOTA，参数量更少（3B vs. 8B），并在真实机器人上验证了有效性。

Conclusion: 显式建模视觉-动作因果性是提升VLN鲁棒性与泛化能力的关键，NaVIDA为该方向提供了统一且实用的解决方案。

Abstract: Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \textsc{NaVIDA} (\textbf{Nav}igation with \textbf{I}nverse \textbf{D}ynamics \textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.

</details>


### [120] [Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval](https://arxiv.org/abs/2601.18190)
*Yifan Li,Shiying Wang,Jianqiang Huang*

Main category: cs.CV

TL;DR: 本文提出MPS-CLIP，一种参数高效的视觉语言预训练框架，通过关键词引导的细粒度对齐提升遥感图文检索性能，结合LLM与SamGeo生成多视角子区域，并引入G^2A适配器和MPR模块，在RSICD和RSITMD上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有VLP模型在遥感图文检索中依赖粗粒度全局对齐，忽略图像中密集、多尺度语义；且全量微调计算开销大、易灾难性遗忘。

Method: 利用LLM提取关键词，指导SamGeo生成语义相关子视角；设计轻量Gated Global Attention（G^2A）适配器适配冻结主干；引入Multi-Perspective Representation（MPR）模块聚合局部特征；采用多视角对比损失与加权三元组损失联合优化。

Result: 在RSICD和RSITMD数据集上mR分别达35.18%和48.40%，显著优于全量微调基线及近期先进方法。

Conclusion: MPS-CLIP通过参数高效方式实现关键词驱动的细粒度对齐，有效提升遥感图文检索精度与鲁棒性，为轻量化VLP适配遥感任务提供了新范式。

Abstract: Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.

</details>


### [121] [MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models](https://arxiv.org/abs/2601.18192)
*Tian-Yi Zhou,Xuan-Hao Liu,Bao-Liang Lu,Wei-Long Zheng*

Main category: cs.CV

TL;DR: 本文提出MindCine框架，通过多模态联合学习与预训练大尺度EEG模型，解决EEG-to-video重建中单模态依赖和数据稀缺问题，在有限数据下实现高保真视频重建。


<details>
  <summary>Details</summary>
Motivation: 现有EEG-to-video重建方法受限于仅对齐文本模态（导致过拟合）和EEG-视频配对数据稀缺（难以收敛），亟需更鲁棒、数据高效的重建框架。

Method: 提出MindCine框架：1）采用多模态联合学习策略，融合文本以外的模态；2）利用预训练大规模EEG模型缓解数据稀缺；3）设计带因果注意力的Seq2Seq模型解码感知信息。

Result: 在多个指标和视觉质量上显著超越现有SOTA方法；验证了多模态互补性及大EEG模型对性能提升的有效性。

Conclusion: 多模态协同建模与大模型先验可有效克服EEG视频重建中的模态单一与数据瓶颈，为非侵入式脑机视觉解码提供新范式。

Abstract: Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.

</details>


### [122] [QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding](https://arxiv.org/abs/2601.18195)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Kaiwei Zhang,Jun Jia,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本文提出QualiRAG，一种无需训练的检索增强生成框架，利用大视觉语言模型的隐式感知知识，通过动态构建四类互补知识源实现可解释的视觉质量理解。


<details>
  <summary>Details</summary>
Motivation: 现有视觉质量评估方法依赖人工标注的监督微调或强化学习，成本高且易受数据集偏差影响，亟需一种免训练、可解释、泛化强的新范式。

Method: 提出训练-free的RAG框架QualiRAG：不从静态语料库检索，而是将问题结构化分解，动态生成并检索四类辅助知识——视觉元数据、主体定位、全局质量摘要和局部质量描述，支撑证据驱动的推理。

Result: 在视觉质量理解任务上显著优于开源通用及VQA微调的大模型；在质量比较任务中达到有竞争力的性能；全程无需任何任务特定训练。

Conclusion: QualiRAG验证了利用大模型固有感知能力、通过动态知识构造与检索实现高质量、可解释、免训练视觉评估的可行性，为VQA提供了新思路。

Abstract: Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \textit{fine-grained spatiotemporal perception} and \textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \textbf{QualiRAG}, a \textit{training-free} \textbf{R}etrieval-\textbf{A}ugmented \textbf{G}eneration \textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \textit{visual metadata}, \textit{subject localization}, \textit{global quality summaries}, and \textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.

</details>


### [123] [HomoFM: Deep Homography Estimation with Flow Matching](https://arxiv.org/abs/2601.18222)
*Mengfan He,Liangzheng Sun,Chunyu Li,Ziyang Meng*

Main category: cs.CV

TL;DR: 本文提出HomoFM框架，首次将生成模型中的流匹配技术引入单应性估计任务，通过学习连续点态速度场来恢复高精度变换，并结合梯度反转层提升跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有单应性估计方法多为直接回归或迭代优化，难以建模复杂几何变换且泛化能力差，尤其在跨模态或光照变化等域偏移场景下表现不佳。

Method: 将单应性估计建模为速度场学习问题，利用条件流轨迹从噪声分布中恢复配准坐标；在特征提取主干中集成梯度反转层（GRL）以实现域不变特征学习。

Result: 在标准基准上，HomoFM在估计精度和鲁棒性方面均超越现有最先进方法。

Conclusion: 流匹配为单应性估计提供了新范式，结合域自适应策略可显著提升模型在复杂真实场景下的泛化能力与稳定性。

Abstract: Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.

</details>


### [124] [Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach](https://arxiv.org/abs/2601.18228)
*Sahil Naik,Soham Bagayatkar,Pavankumar Singh*

Main category: cs.CV

TL;DR: 本文提出了一种基于EfficientNetB2的轻量高效人脸表情识别方法，结合两阶段训练、AdamW优化、标签平滑和类别权重裁剪等策略，在FER-2013数据集上达到68.78%准确率，参数量仅为VGG16基线的十分之一，适用于实时与边缘部署。


<details>
  <summary>Details</summary>
Motivation: 现实场景中人脸表情识别面临图像质量差、光照/姿态变化、背景干扰、类间差异小、众包标签噪声大及严重类别不平衡等问题，尤其在FER-2013数据集上表现突出；同时，现有大型CNN模型（如VGG、ResNet）计算与内存开销大，难以满足实时应用需求。

Method: 采用轻量级EfficientNetB2构建识别流程，结合两阶段warm-up与微调策略；引入AdamW优化器、解耦权重衰减、标签平滑（ε=0.06）、裁剪类别权重、Dropout、混合精度训练及实时数据增强。训练采用分层87.5%/12.5%划分，保留官方测试集。

Result: 在FER-2013测试集上达到68.78%准确率，参数量约为VGG16基线的1/10；实验显示训练稳定、泛化能力强，具备良好的每类指标与学习动态特性。

Conclusion: 所提方法在精度与效率间取得良好平衡，显著降低资源消耗，验证了其在实时及边缘设备上的实用性和可行性。

Abstract: Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.

</details>


### [125] [V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering](https://arxiv.org/abs/2601.18240)
*Mengyuan Jin,Zehui Liao,Yong Xia*

Main category: cs.CV

TL;DR: 本文提出V-Loop框架，通过双向视觉逻辑循环验证，无需训练即可检测医学视觉问答中多模态大模型的幻觉问题，提升答案的事实正确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于不确定性的幻觉检测方法间接且无法直接验证答案是否符合图像事实，在高风险医疗场景中存在安全隐患。

Method: 提出无训练、即插即用的Visual Logical Loop Verification（V-Loop）框架，构建以图像为依据的双向逻辑循环：从原始问答对提取语义单元，生成依赖答案的验证问题，并强制主问题与验证问题关注图像同一证据区域；若验证答案与预期一致，则闭环成立，表明答案具事实基础。

Result: 在多个医学VQA基准和MLLMs上实验表明，V-Loop持续优于现有内省式方法，效率高，且可与不确定性方法结合进一步提升性能。

Conclusion: V-Loop为医学VQA中的幻觉检测提供了一种直接、高效、可泛化的新型验证范式，显著增强模型输出的可信度与安全性。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.

</details>


### [126] [Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation](https://arxiv.org/abs/2601.18242)
*Zerui Kang,Yishen Lim,Zhouyou Gu,Seung-Woo Ko,Tony Q. S. Quek,Jihong Park*

Main category: cs.CV

TL;DR: 本文提出了一种视觉-语言模型（VLM）引导的可微射线追踪（DRT）框架，用于加速和稳定多材料射频参数估计，显著提升收敛速度与精度。


<details>
  <summary>Details</summary>
Motivation: 6G电磁数字孪生需要高精度RF材料参数，但现有基于梯度的逆向射线追踪方法对初值敏感、在测量受限时计算成本高。

Method: 利用VLM解析场景图像以推断材料类别，并结合ITU-R材料表生成电导率等定量先验；VLM还优选发射/接收位置以增强路径对材料的区分性；随后在DRT引擎中基于实测接收信号强度进行梯度优化。

Result: 在NVIDIA Sionna室内场景实验中，相比均匀或随机初始化及随机布点基线，收敛速度快2–4倍，最终参数误差降低10–100倍，仅需少量接收器即可实现<0.1%平均相对误差；复杂度近似线性增长，且VLM引导布点减少了所需测量次数。

Conclusion: VLM提供的语义先验能有效引导基于物理的优化过程，实现快速、鲁棒的RF材料参数估计。

Abstract: Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\times$ faster convergence and 10-100$\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.

</details>


### [127] [A multimodal vision foundation model for generalizable knee pathology](https://arxiv.org/abs/2601.18250)
*Kang Yu,Dingyu Wang,Zimu Yuan,Nan Zhou,Jiajun Liu,Jiaxin Liu,Shanggui Liu,Yaoyan Zheng,Huishu Yuan,Di Huang,Dong Jiang*

Main category: cs.CV

TL;DR: 本文提出了OrthoFoundation，一种针对肌肉骨骼病理的多模态视觉基础模型，通过自监督对比学习在120万膝关节X光和MRI图像上预训练，实现了下游14项任务的SOTA性能，并展现出优异的标签效率和跨解剖部位泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前骨科AI方法依赖于任务特定的监督学习，存在碎片化、需要大量标注数据、泛化能力差等问题，且缺乏大规模开源肌肉骨骼数据集制约了基础模型的发展。

Method: 构建了包含120万未标注膝关节X光和MRI图像的预训练数据集，采用Dinov3骨干网络，通过自监督对比学习进行训练，以学习鲁棒的放射学表征。

Result: 在14个下游任务中达到SOTA性能，X光骨关节炎诊断准确率更高，MRI结构损伤检测排名第一；仅用50%标注数据即可匹敌监督基线；在髋、肩、踝等其他解剖部位表现出强跨部位泛化能力。

Conclusion: OrthoFoundation通过从大规模多模态数据中学习基础、关节无关的放射学语义，显著降低了标注负担并提升了临床诊断准确性，是肌肉骨骼影像通用AI的重要进展。

Abstract: Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.

</details>


### [128] [Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing](https://arxiv.org/abs/2601.18252)
*Chao Wang,Xuanying Li,Cheng Dai,Jinglei Feng,Yuxiang Luo,Yuqi Ouyang,Hao Qin*

Main category: cs.CV

TL;DR: 本文提出Co-PLNet，一种点线协同的线框解析框架，通过Point-Line Prompt Encoder和Cross-Guidance Line Decoder实现点与线预测间的空间信息交互与一致性约束，在Wireframe和YorkUrban数据集上提升了精度、鲁棒性与实时性。


<details>
  <summary>Details</summary>
Motivation: 现有方法分别预测线段和连接点，并在后处理中进行匹配，易导致不一致和鲁棒性下降。

Method: 提出Co-PLNet框架：1）Point-Line Prompt Encoder（PLP-Encoder）将早期检测结果编码为几何属性对齐的空间提示图；2）Cross-Guidance Line Decoder（CGL-Decoder）基于稀疏注意力和互补提示联合优化点线预测，增强一致性与效率。

Result: 在Wireframe和YorkUrban数据集上，线框解析精度与鲁棒性显著提升，同时保持良好的实时推理效率。

Conclusion: 点线协同建模与空间提示机制可有效提升结构化几何感知性能，为SLAM等下游任务提供更可靠的线框表示。

Abstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.

</details>


### [129] [Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images](https://arxiv.org/abs/2601.18260)
*Eytan Kats,Kai Geissler,Daniel Mensing,Jochen G. Hirsch,Stefan Heldman,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的框架，利用RGB-D相机获取的单张2D深度图像直接预测多个内部器官的3D位置和形状，无需显式表面重建，提升了放射科自动患者定位的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 自动化患者定位对优化扫描流程、提高患者通量至关重要；RGB-D相机提供的深度信息为估计内部器官位置提供了新途径。

Method: 构建统一卷积神经网络，使用大规模全身体MRI数据合成配对的深度图像与解剖分割标签进行端到端训练，直接从单张2D深度图预测多器官3D位置与形状。

Result: 方法能准确定位包括骨骼与软组织在内的多种解剖结构，在实验中展现出集成深度传感器至放射科工作流的潜力。

Conclusion: 该学习框架为无表面重建的自动化患者定位提供了可行且高效的新方案，有助于提升扫描效率与患者体验。

Abstract: Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.

</details>


### [130] [Revisiting Aerial Scene Classification on the AID Benchmark](https://arxiv.org/abs/2601.18263)
*Subhajeet Das,Susmita Ghosh,Abhiroop Chatterjee*

Main category: cs.CV

TL;DR: This paper reviews machine learning methods for aerial image classification and proposes Aerial-Y-Net, an attention-enhanced CNN with multi-scale feature fusion, achieving 91.72% accuracy on the AID dataset.


<details>
  <summary>Details</summary>
Motivation: Aerial images are heterogeneous and complex, making robust scene classification challenging; thus, a comprehensive review and improved model are needed.

Method: Literature review of handcrafted features (e.g., SIFT, LBP), traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks; design and evaluation of Aerial-Y-Net—a spatial attention-enhanced CNN with multi-scale feature fusion.

Result: Aerial-Y-Net achieves 91.72% classification accuracy on the AID dataset, outperforming several baseline architectures.

Conclusion: Attention mechanisms and multi-scale feature fusion significantly improve aerial image classification performance, and Aerial-Y-Net demonstrates the effectiveness of such design in handling image heterogeneity.

Abstract: Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.

</details>


### [131] [Contextual Range-View Projection for 3D LiDAR Point Clouds](https://arxiv.org/abs/2601.18301)
*Seyedali Mousavi,Seyedhamidreza Mousavi,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 本文提出两种改进的range-view投影方法（CAP和CWAP），通过引入实例中心距离和类别权重来缓解点云投影中的多对一冲突，提升语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有range-view投影方法仅保留最近点，忽略语义相关性和物体结构，导致上下文信息丢失。

Method: 提出Centerness-Aware Projection（CAP）和Class-Weighted-Aware Projection（CWAP）：CAP根据点到实例中心的距离调整深度优先级；CWAP依据用户定义的类别权重调整选择策略。

Result: 在SemanticKITTI上，CAP相比基线提升3.1% mIoU；CWAP可针对性增强特定类别性能，且对其他类别影响极小。

Conclusion: 融合实例结构与类别先验的投影策略能更有效地保留关键上下文信息，显著提升下游任务性能。

Abstract: Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \textit{Centerness-Aware Projection (CAP)} and \textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes

</details>


### [132] [SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis](https://arxiv.org/abs/2601.18305)
*Xuan Wang,Siyuan Su,Quantong Fu,Yongxiang Hu,Yangfan Zhou*

Main category: cs.CV

TL;DR: 本文提出SwipeGen自动化管道以生成类人滑动交互，并构建首个评估GUI代理滑动执行能力的基准；基于此，设计了增强交互执行能力的GUI代理GUISwiper，在滑动执行准确率上较现有VLM基线提升214%。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理在滑动交互处理上策略过于简化，难以准确复现人类行为，导致任务完成受限。

Method: 将人类滑动手势分解为多个可量化维度，提出SwipeGen自动化合成管道；构建首个滑动执行能力评估基准；基于合成数据训练GUISwiper代理。

Result: GUISwiper滑动执行准确率达69.07%，较现有VLM基线提升214%。

Conclusion: 通过精细化建模人类滑动行为并构建专用数据与基准，可显著提升GUI代理的交互执行能力。

Abstract: With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.

</details>


### [133] [A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification](https://arxiv.org/abs/2601.18330)
*Muhammad Ali Shah,Muhammad Mansoor Alam,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 本文提出了一种高效的Densely Swin Hybrid（EDSH）框架，用于脑肿瘤MRI分析，结合DenseNet和Swin Transformer的优势，通过两种肿瘤感知实验设置，分别提升弥漫性胶质瘤和脑膜瘤/垂体瘤的检测性能，在大规模数据集上达到98.50%准确率和召回率。


<details>
  <summary>Details</summary>
Motivation: 解决脑肿瘤MRI分析中细粒度纹理模式与长程上下文依赖联合建模困难，以及不同肿瘤类型（如弥漫性胶质瘤、脑膜瘤、垂体瘤）在形态、边界、位置等特征上的诊断特异性挑战。

Method: 提出EDSH框架：1）Boosted Feature Space（BFS）设置，融合定制化DenseNet（局部纹理）与Swin_t（全局上下文），维度对齐并增强；2）分层DenseNet-Swin架构，含Deep Feature Extraction（DFE）与Dual Residual（DR）连接，DenseNet作为CNN主干学习局部结构特征，Swin_t建模全局肿瘤形态；两者均针对MRI特性定制（如输入适配、patch embedding、shifted-window attention）。

Result: 在40,260张MRI图像（四类肿瘤）的大规模数据集上测试，EDSH取得98.50%准确率与召回率，显著优于独立CNN、ViT及其它混合模型，尤其降低弥漫性胶质瘤漏检（敏感检测不规则形状、边界模糊、异质纹理）和脑膜瘤/垂体瘤假阴性（识别明确肿块、颅外位置、硬膜尾征等）。

Conclusion: EDSH框架通过双路径肿瘤感知设计与模型定制，有效协同局部细节与全局结构建模，为多类脑肿瘤MRI精准分类提供了高效、鲁棒的新范式。

Abstract: This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.

</details>


### [134] [Beyond Rigid: Benchmarking Non-Rigid Video Editing](https://arxiv.org/abs/2601.18340)
*Bingzheng Qu,Kehai Chen,Xuefeng Bai,Jun Yu,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了NRVBench，首个专门用于评估非刚性视频编辑的综合基准，包含高质量数据集、新评估指标NRVE-Acc和无需训练的基线方法VM-Edit，显著提升了物理合理性和时序一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动视频编辑方法在生成连贯的非刚性形变时存在物理失真和时间闪烁问题，缺乏专用评估基准。

Method: 构建包含180个物理驱动非刚性运动视频的数据集；提出基于视觉语言模型的评估指标NRVE-Acc；设计无需训练的双区域去噪基线方法VM-Edit。

Result: 实验表明当前方法在物理合理性上存在不足，而所提方法在标准及新指标下均表现优异。

Conclusion: NRVBench可作为推进物理感知视频编辑的标准测试平台。

Abstract: Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.

</details>


### [135] [Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception](https://arxiv.org/abs/2601.18346)
*Sijing Wu,Yunhao Li,Zicheng Zhang,Qi Jia,Xinyue Li,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了首个面向人像图像质量感知的综合基准Q-Bench-Portrait，包含2765个图像-问题-答案三元组，涵盖多源人像图像、多维质量评估维度及多样化问题形式；基于该基准评测了25个MLLM，发现其在人像质量感知上仍显著落后于人类判断。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在通用图像低级视觉任务上表现优异，但在具有独特结构与感知特性的肖像图像质量感知方面能力尚不明确，亟需专用基准进行系统评估。

Method: 构建了首个专用于人像图像质量感知的基准Q-Bench-Portrait，包含多样化的图像来源、全面的质量维度（技术失真、AIGC特有失真、美学）以及多种题型（单选、多选、判断、开放问答）；并在该基准上对20个开源和5个闭源MLLM进行系统评测。

Result: 当前MLLM在Q-Bench-Portrait上的表现有限且不精确，与人类判断存在明显差距，尤其在AIGC失真和美学维度上表现更弱。

Conclusion: Q-Bench-Portrait填补了人像图像质量感知评估的空白，揭示了现有MLLM在此领域的不足，有望推动通用与领域专用MLLM在人像理解能力上的进一步发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.

</details>


### [136] [OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI](https://arxiv.org/abs/2601.18368)
*Caterina Fuster-Barceló,Claudia Castrillón,Laura Rodrigo-Muñoz,Victor Manuel Vega-Suárez,Nicolás Pérez-Fernández,Gorka Bastarrika,Arrate Muñoz-Barrutia*

Main category: cs.CV

TL;DR: OREHAS 是首个全自动管道，用于从常规3D-SPACE-MRC和3D-REAL-IR MRI中量化内淋巴积水（EH）体积，仅需每例患者3–6张标注切片即可实现高精度分割与ELR比值计算，显著优于临床软件syngo.via。


<details>
  <summary>Details</summary>
Motivation: 现有内淋巴积水（EH）量化方法依赖大量手动标注或临床软件（如syngo.via），存在主观性强、可重复性差、易高估体积等问题，亟需一种全自动、低监督、临床兼容的定量分析方案。

Method: 提出OREHAS全自动流程，整合切片分类、内耳定位和序列特异性分割三模块；采用深度学习模型，仅用每例3–6张标注切片训练，直接从全3D MRI体积中计算单耳内淋巴/前庭体积比（ELR）。

Result: 在外部验证队列中，OREHAS与专家标注高度一致（VSI=74.3%），远超syngo.via（VSI=42.5%）；Dice分数达0.90（SPACE-MRC）和0.75（REAL-IR）；19例测试中其前庭体积与syngo.via一致，但内淋巴体积更小且更符合生理实际。

Conclusion: OREHAS实现了基于常规MRI、低监督、全自动、高一致性的EH体积量化，提升了可重复性与临床适用性，为大规模研究及诊断阈值校准提供了可靠工具。

Abstract: We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.
  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.
  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.

</details>


### [137] [Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues](https://arxiv.org/abs/2601.18372)
*Christos Petrou,Harris Partaourides,Athanasios Balomenos,Yannis Kopsinis,Sotirios Chatzis*

Main category: cs.CV

TL;DR: 本文提出了一种结合HMD运动信号与视频帧视觉显著性特征的轻量级注视预测框架，无需直接眼动追踪，提升了VR中foveated rendering等技术的实时性与交互自然性。


<details>
  <summary>Details</summary>
Motivation: 在VR应用中，直接眼动追踪常受限于硬件或隐私问题，而注视预测对降低延迟和实现计算密集型技术（如foveated rendering）至关重要。

Method: 采用轻量级显著性编码器UniSal提取视频帧视觉特征，并与HMD运动信号融合，再通过TSMixer或LSTM时间序列模型预测未来注视方向。

Result: 在EHTask数据集及商用VR设备上的实验表明，该方法显著优于Center-of-HMD和Mean Gaze等基线方法。

Conclusion: 所提框架能有效建模预测性注视行为，在缺乏直接眼动追踪的VR场景中显著降低感知延迟、提升交互自然性。

Abstract: Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.

</details>


### [138] [Estimation of geometric transformation matrices using grid-shaped pilot signals](https://arxiv.org/abs/2601.18385)
*Rinka Kawano,Masaki Kawamura*

Main category: cs.CV

TL;DR: 本文提出了一种基于网格状导频信号的数字水印方法，通过分析导频信号在几何变换（如缩放、旋转、剪切和裁剪）后的畸变，利用Radon变换估计变换矩阵，从而实现水印的鲁棒同步，尤其对裁剪攻击具有较强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有数字水印方法在面对裁剪等几何失真时同步困难，缺乏足够的鲁棒性。

Method: 在图像中嵌入具有区分度的水平与垂直值的网格状导频信号；对受攻击图像应用Radon变换，估计畸变后网格的角度与间隔；利用水平/垂直编码差异确定网格方向以消除歧义，进而估计几何变换矩阵并实现水印同步。

Result: 仿真结果表明，该方法在各向异性缩放、旋转、剪切及裁剪（单次与复合）攻击下均能以低误差准确估计变换矩阵。

Conclusion: 所提方法显著提升了水印在裁剪等几何攻击下的同步鲁棒性，为实际应用场景提供了更可靠的解决方案。

Abstract: Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.

</details>


### [139] [ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks](https://arxiv.org/abs/2601.18386)
*Gabriel Lee Jun Rong,Christos Korgialas,Dion Jia Xu Ho,Pai Chet Ng,Xiaoxiao Miao,Konstantinos N. Plataniotis*

Main category: cs.CV

TL;DR: 本文提出ARMOR框架，利用视觉语言模型（VLM）和大语言模型（LLM）协同调度多种对抗攻击方法（CW、JSMA、STA），通过语义感知与实时参数重调，提升跨架构迁移性和对黑盒/白盒目标的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有自动化攻击套件是静态的、缺乏战略适应性和语义感知能力，难以应对多样化的图像语义漏洞。

Method: 提出ARMOR框架，由VLM引导的多个攻击代理在共享‘Mixing Desk’上协作生成扰动；LLM在闭环系统中实时自适应地调优各攻击代理的参数。

Result: 在标准基准上，ARMOR显著提升了跨架构攻击迁移性；对黑盒目标输出混合扰动，对白盒目标基于置信度与SSIM分数选择最优或混合攻击策略。

Conclusion: ARMOR通过引入语义驱动的智能编排与动态重参数化机制，突破了传统静态攻击范式的局限，为对抗攻击提供了更鲁棒、更自适应的新范式。

Abstract: Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.

</details>


### [140] [Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space](https://arxiv.org/abs/2601.18392)
*Moritz Rempe,Lukas T. Rotkopf,Marco Schlimbach,Helmut Becker,Fabian Hörst,Johannes Haubold,Philipp Dammann,Kevin Kröninger,Jens Kleesiek*

Main category: cs.CV

TL;DR: 本文提出了一种直接在MRI的k空间数据上进行分类的复数Vision Transformer（kViT），通过径向k空间分块策略，兼顾MRI物理特性与频域能量分布，在保持高性能的同时显著提升计算效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有MRI深度学习方法多基于重建后的幅值图像，丢失相位信息且依赖高开销变换；传统CNN或ViT等局部操作难以建模k空间的全局、非局部特性。

Method: 设计复数域Vision Transformer（kViT），引入径向k空间分块策略以适配频域谱能量分布，并直接在原始k空间数据上进行端到端分类。

Result: 在fastMRI和内部数据集上，kViT分类性能媲美ResNet、EfficientNet和ViT等图像域SOTA模型；对高加速因子鲁棒性更强；训练显存消耗最多降低68倍。

Conclusion: kViT为MRI提供了无需图像重建、直接从扫描仪原始数据进行AI分析的新范式，兼具高性能、高鲁棒性与极高资源效率。

Abstract: Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.

</details>


### [141] [Larger than memory image processing](https://arxiv.org/abs/2601.18407)
*Jon Sporring,David Stansby*

Main category: cs.CV

TL;DR: 本文提出了一种面向超大规模图像（如PB级电镜数据）的流式分析架构，通过基于切片的1D流式处理、扫掠执行、窗口操作和重叠感知分块等技术，最小化I/O开销，并设计了支持自动优化的领域专用语言（DSL），实现内存受限下的高效、可预测的大图分析。


<details>
  <summary>Details</summary>
Motivation: 现有超大规模图像（如1.4 PB电镜数据、150 TB器官图谱）分析严重受I/O瓶颈限制，传统基于3D块的存储与访问方式在多遍扫描时导致大量冗余磁盘访问，亟需一种兼顾算法局部性与I/O效率的通用流式处理范式。

Method: 提出基于1D切片的流式架构，形式化扫掠执行（sweep-based execution）、窗口操作与重叠感知分块；设计支持编译期/运行期优化的领域专用语言（DSL），自动选择窗口大小、融合流水阶段、分流/合流数据流、调度多遍扫描，适配有限内存环境。

Result: 该方法实现近线性的I/O扫描、可预测的内存占用，在保持与现有分割/形态学工具兼容的同时，显著提升超大图像分析吞吐量，无需将全量数据载入内存。

Conclusion: 面向超大规模图像分析，以1D切片流为核心的结构化流水范式比传统3D块访问更高效；DSL驱动的自动优化使算法能内禀地适配I/O与内存约束，为petascale图像计算提供了可扩展、实用的新路径。

Abstract: This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.

</details>


### [142] [Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings](https://arxiv.org/abs/2601.18414)
*Aura Loredana Dan*

Main category: cs.CV

TL;DR: 本文比较了MobileNet、EfficientNet和VGG16三种深度学习模型在儿童绘画情感识别任务中的性能，旨在为自闭症谱系障碍（ASD）儿童早期情绪状态评估提供非侵入、客观且可部署的自动化方法。


<details>
  <summary>Details</summary>
Motivation: 传统儿童情绪评估方法具有侵入性、主观性强、一致性差等问题，尤其对ASD儿童早期情绪识别构成挑战；利用儿童绘画进行自动情感识别是一种有潜力的替代方案。

Method: 采用迁移学习策略，在心理学专家标注的情感标签数据集上，统一实验框架下对比评估MobileNet、EfficientNet和VGG16三种深度学习模型的情感分类性能、鲁棒性与计算效率。

Result: 揭示了轻量级与深层网络在绘画情感识别任务中的关键权衡：轻量模型更适配移动端与实时应用，而深层模型可能在精度上占优但资源消耗更高。

Conclusion: 基于儿童绘画的情绪识别可行且具应用前景；模型选择需根据实际场景（如部署平台、实时性要求）权衡性能与效率，为面向ASD儿童的辅助诊断工具开发提供了实证依据。

Abstract: Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.

</details>


### [143] [On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics](https://arxiv.org/abs/2601.18448)
*Lloyd Austin Courtenay*

Main category: cs.CV

TL;DR: 本文指出在几何形态测量学（GMM）与机器学习（ML）结合应用中，传统广义Procrustes分析（GPA）预处理方式会导致训练集与测试集间统计依赖，从而污染模型预测；作者通过模拟实验量化该污染效应，并提出一种新对齐方法——仅将测试样本相对于训练集进行对齐，以消除跨样本依赖；研究还揭示了Procrustes切空间自由度对误差缩放的解析影响，并强调地标点空间自相关性对模型性能的关键作用。


<details>
  <summary>Details</summary>
Motivation: 传统GMM预处理中，所有样本统一经GPA对齐后再划分训练/测试集，会引入数据泄露和统计依赖，但该问题尚未被系统刻画和解决。

Method: 通过2D/3D控制模拟，考察不同样本量、地标点密度及异速生长模式下GPA导致的误差污染；提出‘训练集导向’的测试样本实时对齐新流程；结合线性回归与卷积回归模型，评估忽略地标空间自相关性的性能损失；从Procrustes切空间自由度出发解析RMSE缩放规律。

Result: 发现样本量与地标数构成的‘对角线区域’决定RMSE缩放行为，其斜率可由切空间自由度理论推导；新对齐方法有效消除交叉污染；忽略地标空间自相关显著降低ML模型性能。

Conclusion: GMM用于ML时必须避免全局GPA对齐，应采用训练集引导的实时对齐策略；本文为GMM-ML流程提供了统计严谨的预处理指南，并厘清了Procrustes形状空间固有的建模约束。

Abstract: Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust "diagonal" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.

</details>


### [144] [3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control](https://arxiv.org/abs/2601.18451)
*Xuanmeng Sha,Liyun Zhang,Tomohiro Mashita,Naoya Chiba,Yuki Uranishi*

Main category: cs.CV

TL;DR: 本文提出3DGesPolicy，一种基于动作的扩散策略框架，用于生成语义和空间上连贯的全身协同语音手势，通过GAP融合模块实现语音、身体运动与面部表情的精细对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成全身协同语音手势时存在语义不协调和空间不稳定的问题，主要由于采用部分分解或逐帧回归策略。

Method: 将全身手势生成重新建模为连续轨迹控制问题，使用机器人领域的扩散策略；引入Gesture-Audio-Phoneme（GAP）融合模块，深度融合语音、音素与手势多模态信号。

Result: 在BEAT2数据集上的大量实验表明，3DGesPolicy在自然性、表现力和语音对齐度方面显著优于现有最先进方法。

Conclusion: 3DGesPolicy通过动作建模与多模态融合，有效解决了全身协同语音手势生成中的语义与空间一致性难题，为该任务提供了新范式。

Abstract: Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.

</details>


### [145] [Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System](https://arxiv.org/abs/2601.18464)
*Wenbin Wei,Suyuan Yao,Cheng Huang,Xiangyu Gao*

Main category: cs.CV

TL;DR: Fair-Eye Net 是一个面向青光眼筛查与随访的公平、可靠多模态AI系统，融合眼底照相、OCT结构指标、视野功能指数及人口统计学因素，通过不确定性感知的分层门控机制实现选择性预测与安全转诊，并在提升诊断性能的同时显著降低种族间漏诊差异。


<details>
  <summary>Details</summary>
Motivation: 现有青光眼筛查和进展评估依赖单一或松散关联检查，主观性强、碎片化严重；高质量影像设备与专家资源匮乏进一步损害临床一致性与公平性。

Method: 提出Fair-Eye Net：采用双流异构融合架构整合多模态数据（眼底照、OCT、VF、人口统计），引入不确定性感知的分层门控策略实现选择性预测与安全转诊，并嵌入公平性约束以减少弱势亚组漏诊。

Result: AUC达0.912（特异性96.7%），种族假阴性率差异降低73.4%（12.31%→3.28%），跨域性能稳定，可提前3–12个月发出风险预警（敏感性92%，特异性88%）。

Conclusion: Fair-Eye Net将公平性作为核心优化目标，结合多任务学习保障临床可靠性，为全球眼科健康公平提供可复现、可大规模部署的AI解决方案。

Abstract: Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.

</details>


### [146] [DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment](https://arxiv.org/abs/2601.18493)
*Sara Tehrani,Yonghao Xu,Leif Haglund,Amanda Berg,Michael Felsberg*

Main category: cs.CV

TL;DR: 本文提出了DisasterInsight多模态基准，用于评估视觉-语言模型在真实灾害分析任务中的性能，并提出了DI-Chat模型作为领域适配基线，在多个灾害分析任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉-语言基准主要关注粗粒度标签和图像级识别，缺乏对灾害响应中功能理解与指令鲁棒性的支持。

Method: 构建了包含约11.2万个建筑中心实例的DisasterInsight基准，支持多任务指令式评估；提出基于LoRA微调的DI-Chat模型作为领域适配基线。

Result: 实验表明现有模型在损毁理解与结构化报告生成方面存在明显性能差距；DI-Chat在损毁等级、灾害类型分类及报告生成质量上显著提升，但建筑功能分类仍具挑战性。

Conclusion: DisasterInsight为灾害影像中的具身多模态推理研究提供了统一基准，推动面向人道主义应用的VLM发展。

Abstract: Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.
  To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.

</details>


### [147] [From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation](https://arxiv.org/abs/2601.18532)
*Devon Levy,Bar Assayag,Laura Gaspar,Ilan Shimshoni,Bella Specktor-Fadida*

Main category: cs.CV

TL;DR: 本文提出了一种结合基础模型嵌入与聚类的冷启动采样策略，并在后续主动学习中融合不确定性与空间多样性，以提升医学图像分割在低标注数据下的性能。


<details>
  <summary>Details</summary>
Motivation: 手动标注医学图像分割mask耗时耗力，而传统主动学习的冷启动阶段缺乏代表性，难以在初始阶段构建高质量训练集。

Method: 提出一种基于基础模型嵌入和自适应聚类（自动确定簇数+按比例跨簇采样）的冷启动策略；后续AL阶段采用结合熵不确定性和空间多样性的样本选择方法，并支持特征空间分布可视化。

Result: 在CheXmask、Montgomery和SynthStrip三个数据集（X光与MRI）上验证：冷启动阶段显著提升Dice分数并降低Hausdorff距离；AL阶段进一步改善性能，尤其在低数据场景下稳定优于基线方法。

Conclusion: 所提框架在低标注预算下能更高效地利用标注资源，提升分割精度，兼具可解释性与实用性。

Abstract: Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.

</details>


### [148] [GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning](https://arxiv.org/abs/2601.18543)
*Kaixun Jiang,Yuzheng Wang,Junjie Zhou,Pandeng Li,Zhihang Liu,Chen-Wei Xie,Zhaoyu Chen,Yun Zheng,Wenqiang Zhang*

Main category: cs.CV

TL;DR: GenAgent 是一种新型代理式多模态模型，通过将视觉理解与生成解耦——由多模态模型负责理解、调用图像生成模型作为工具进行生成——实现高效协同；采用两阶段训练（监督微调 + 结合点式与对式奖励的端到端强化学习），显著提升生成质量，并具备跨工具泛化、测试时可扩展及任务自适应推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型存在训练成本高、理解与生成能力相互制约的问题；而模块化系统又受限于静态流水线，缺乏自主多轮交互与推理能力。

Method: 提出 GenAgent 代理框架：多模态模型自主执行推理、工具调用、判断与反思，形成多模态思维链；采用两阶段训练：1）基于高质量工具调用与反思数据的监督微调；2）结合点式（图像质量）和对式（反思准确性）奖励的端到端强化学习，并引入轨迹重采样以增强多轮探索。

Result: 在 GenEval++ 和 WISE 基准上分别提升 FLUX.1-dev 生成性能 23.6% 和 14%；验证了跨生成器泛化、测试时多轮迭代持续提升、以及任务驱动的自适应推理能力。

Conclusion: GenAgent 证明了将理解与生成解耦并赋予模型代理能力是提升多模态生成效果与灵活性的有效范式，为构建更智能、可扩展的生成系统提供了新路径。

Abstract: We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\%) and WISE (+14\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \href{https://github.com/deep-kaixun/GenAgent}{this url}.

</details>


### [149] [REMAC: Reference-Based Martian Asymmetrical Image Compression](https://arxiv.org/abs/2601.18547)
*Qing Ding,Mai Xu,Shengxi Li,Xin Deng,Xin Zou*

Main category: cs.CV

TL;DR: 本文提出了一种面向火星图像的参考式非对称压缩方法REMAC，通过将计算负担从资源受限的火星端编码器转移到地球端解码器，并利用图像间和图像内相似性，显著降低编码复杂度并提升压缩性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的图像压缩方法在火星图像上效果受限，主要因为忽视了火星端极有限的计算资源，且未利用火星图像间强烈的跨图像相似性。

Method: 提出参考式火星非对称压缩方法（REMAC），包括参考引导熵模块、ref-decoder（支持多尺度与大感受野）以及潜在特征复用机制，以迁移计算至解码端并挖掘图像间与图像内相似性。

Result: 相比当前最优方法，REMAC降低编码器复杂度43.51%，同时BD-PSNR提升0.2664 dB。

Conclusion: REMAC有效平衡了火星端低计算开销与高压缩性能需求，为深空图像传输提供了实用可行的新范式。

Abstract: To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \textit{intra-} and \textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.

</details>


### [150] [Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray](https://arxiv.org/abs/2601.18555)
*Roberto Di Via,Vito Paolo Pastore,Francesca Odone,Siôn Glyn-Jones,Irina Voiculescu*

Main category: cs.CV

TL;DR: 本文提出了一种基于MRI和X光配对数据的跨模态临床等效性验证方法，证明MRI在cam型股骨髋臼撞击（FAI）的定位与诊断准确性上可达到与X光相当的水平，支持将自动化FAI评估整合进常规MRI工作流。


<details>
  <summary>Details</summary>
Motivation: FAI筛查传统依赖X光角度测量，但评估撞击区域的高度和跨度需MRI提供的3D视图；两种模态互补，亟需验证MRI能否替代或补充X光进行精准 landmark 检测与诊断。

Method: 在89例配对MRI/X光患者队列上，采用标准热图回归架构进行跨模态landmark检测与诊断性能对比验证。

Result: MRI在冠状面3D MRI体积中实现了与X光等效的局部定位精度和cam型FAI诊断准确率，并展现出用于体积化分析（如增加更多解剖标志点）的可行性。

Conclusion: MRI可作为FAI临床评估的可靠替代模态，支持自动化FAI评估无缝嵌入常规MRI检查流程。

Abstract: Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions

</details>


### [151] [Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis](https://arxiv.org/abs/2601.18556)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 本文提出SDA-QEC框架，结合简化的扩散数据增强与量子增强分类，有效解决医学图像分类中严重的类别不平衡问题，在冠状动脉造影图像分类任务中取得高准确率、AUC和F1分数，并实现高敏感性与特异性平衡。


<details>
  <summary>Details</summary>
Motivation: 真实世界医学数据集常存在严重类别不平衡，导致模型对少数类召回率低，影响诊断准确性并带来误诊风险。

Method: 提出SDA-QEC框架：采用轻量级扩散增强器为少数类生成高质量合成样本以重平衡训练分布；在MobileNetV2中嵌入量子特征层，利用希尔伯特空间高维映射提升判别能力。

Result: 在冠状动脉造影图像分类任务中达到98.33%准确率、98.78% AUC、98.33% F1分数，同时实现98.33%敏感性和98.33%特异性，显著优于ResNet18、MobileNetV2、DenseNet121和VGG16等基线模型。

Conclusion: SDA-QEC验证了生成式增强与量子增强建模融合在小样本、高度不平衡、高风险医学影像任务中的可行性，为构建高可靠性医疗AI系统提供了新路径。

Abstract: In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.

</details>


### [152] [AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging](https://arxiv.org/abs/2601.18560)
*Li Fang,Tianyu Li,Yanghong Lin,Shudong Zhou,Wei Yao*

Main category: cs.CV

TL;DR: 本文提出了一种面向高光谱卫星影像分类的轻量级、非深度学习AI边缘计算框架，结合少样本学习与两阶段像素级标签传播方法，在资源受限的星上平台实现自主决策，并有效应对传感器故障和图像退化问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像卫星在灾害监测等需快速响应的应用中受限于下行传输速率瓶颈，亟需星上自主处理能力；同时星载处理面临传感器故障、扫描误差导致的像素退化与混合噪声问题。

Method: 提出轻量级非深度学习框架，融合少样本学习；设计两阶段像素级标签传播：第一阶段基于锚点-像素亲和矩阵传播初始标签，第二阶段利用top-k稀疏图及其闭式解更新标签；引入基于秩约束的图聚类算法自动选取锚点标签。

Result: 在资源受限的卫星平台上实现了高效、鲁棒的高光谱图像分类，无需依赖空间结构信息和迭代计算，显著降低计算开销并提升对坏/错位像素及混合噪声的适应性。

Conclusion: 该AI赋能的星上边缘计算范式为高光谱卫星提供了低复杂度、高鲁棒性的实时分类能力，推动遥感系统向自主智能观测演进。

Abstract: As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.

</details>


### [153] [Self-Refining Video Sampling](https://arxiv.org/abs/2601.18577)
*Sangwon Jang,Taekyung Ki,Jaehyeong Jo,Saining Xie,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.CV

TL;DR: 本文提出了一种无需额外训练或外部验证器的自精炼视频采样方法，通过将预训练视频生成器视为去噪自编码器，在推理时进行迭代内循环精炼，并结合不确定性感知策略选择性优化区域，显著提升了运动连贯性和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现代视频生成器在复杂物理动力学建模上仍不足，现有方法依赖外部验证器或数据增强训练，计算开销大且难以捕捉细粒度运动。

Method: 提出自精炼视频采样方法：将预训练视频生成器解释为去噪自编码器，实现推理时的迭代内循环精炼；引入不确定性感知策略，依据自我一致性选择性精炼区域以避免过精炼伪影。

Result: 在主流视频生成器上实验表明，该方法显著提升运动连贯性与物理对齐性，人类偏好率超70%，优于默认采样器和引导式采样器。

Conclusion: 自精炼视频采样是一种轻量、高效且无需额外训练的方法，能有效增强视频生成的物理真实感与动态质量。

Abstract: Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\% human preference compared to the default sampler and guidance-based sampler.

</details>


### [154] [AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment](https://arxiv.org/abs/2601.18589)
*KV Karthikeya,Ashok Kumar Das,Shantanu Pal,Vivekananda Bhat K,Arun Sekar Rajasekaran*

Main category: cs.CV

TL;DR: 本文提出了一种自适应图信号处理与动态语义对齐（AGSP-DSA）框架，用于鲁棒地融合文本、音频和图像等异构多模态数据，通过双图构建、谱图滤波、多尺度GCN嵌入及语义感知注意力机制，在多个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构多模态数据（文本、音频、图像）融合中的鲁棒性与动态语义对齐问题，尤其在模态缺失场景下提升性能。

Method: 构建双图结构建模模态内与模态间关系；采用谱图滤波增强信息信号；使用多尺度图卷积网络（GCN）进行节点嵌入；引入语义感知注意力机制实现各模态的动态上下文贡献。

Result: 在CMU-MOSEI上达95.3%准确率、0.936 F1、0.924 mAP；在AVE和MM-IMDB上分别取得93.4%/0.911和91.8%/0.886的准确率/F1；较MM-GNN准确率提升2.6%，且在模态缺失下表现稳健。

Conclusion: AGSP-DSA有效提升了多模态学习在情感分析、事件识别与多媒体分类任务中的性能，验证了其通用性与鲁棒性。

Abstract: In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.

</details>


### [155] [EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery](https://arxiv.org/abs/2601.18597)
*Yu Xia,Chang Liu,Tianqi Xiang,Zhigang Tu*

Main category: cs.CV

TL;DR: 本文提出EFSI-DETR框架，通过动态频率-空间协同网络（DyFusNet）与高效语义特征浓缩器（ESFC），结合细粒度特征保留策略（FFR），提升无人机影像中小目标检测的实时性与精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在无人机影像小目标检测中受限于特征表达能力不足、多尺度融合效果差、忽略频率信息及使用静态卷积操作。

Method: 提出EFSI-DETR：包含动态频率-空间统一协同网络（DyFusNet）用于多尺度特征融合，高效语义特征浓缩器（ESFC）实现低开销深层语义提取，并引入细粒度特征保留（FFR）策略以保留浅层空间细节。

Result: 在VisDrone和CODrone数据集上达到SOTA性能；VisDrone上AP和APs分别提升1.6%和5.8%，单RTX 4090 GPU上推理速度达188 FPS。

Conclusion: EFSI-DETR有效融合频率与空间信息，兼顾高精度与实时性，显著提升了无人机影像中小目标检测性能。

Abstract: Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \textbf{1.6}\% and \textbf{5.8}\% in AP and AP$_{s}$ on VisDrone, while obtaining \textbf{188} FPS inference speed on a single RTX 4090 GPU.

</details>


### [156] [Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures](https://arxiv.org/abs/2601.18619)
*Jorge Quesada,Ghassan AlRegib*

Main category: cs.CV

TL;DR: 本文提出了一种尺度感知的自监督学习（SSL）方法，通过在预训练中引入小窗口裁剪来聚焦细粒度结构，在地震成像和神经成像两个领域的小目标分割任务中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有SSL方法在分割任务中对大而均匀区域效果好，但在小、稀疏或局部不规则目标上表现下降，缺乏对目标尺度的适配。

Method: 在SSL增强流程中引入小窗口裁剪策略，使模型在预训练阶段关注细尺度结构，提升对小目标的表征能力。

Result: 在地震断层分割和细胞结构 delineation 任务中，相比基线方法分别提升最高13%和5%的精度；而对大尺度特征（如地震相、组织区域）改善不明显。

Conclusion: SSL的有效性高度依赖于目标对象的尺度与稀疏性，应根据具体任务对象尺度定制SSL设计，该原则可推广至各类科学图像分析领域。

Abstract: Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.

</details>


### [157] [Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation](https://arxiv.org/abs/2601.18623)
*Zihao Wang,Yuzhou Chen,Shaogang Ren*

Main category: cs.CV

TL;DR: 本文提出了一种嵌入域偏移动力学的跨模态图像翻译新方法，通过空间变化的混合场和显式的重建项，在每一步去噪过程中进行目标一致的引导，从而提升结构保真度与语义一致性，并减少采样步数。


<details>
  <summary>Details</summary>
Motivation: 标准扩散方法依赖单一全局线性域间映射，导致采样器需穿越流形外高代价区域，引发语义漂移和校正负担加重，即‘固定调度域转移’这一共性缺陷。

Method: 在生成过程每一步预测空间变化的混合场，并注入显式的、目标一致的恢复项到漂移项中；提供连续时间建模与精确解形式，并推导保持边缘一致性的实用一阶采样器。

Result: 在医学影像、遥感和电致发光语义映射等多个跨模态翻译任务上，显著提升了结构保真度和语义一致性，且收敛所需去噪步数更少。

Conclusion: 将域偏移动态显式建模并融入生成过程，可有效缓解离流形更新问题，使模型从全局对齐转向局部残差校正，提升跨模态图像翻译的鲁棒性与效率。

Abstract: Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.

</details>


### [158] [CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search](https://arxiv.org/abs/2601.18625)
*Zequn Xie*

Main category: cs.CV

TL;DR: 本文提出CONQUER框架，通过训练阶段的多粒度编码与最优传输匹配，以及推理阶段的即插即用式查询增强，显著提升文本驱动行人检索性能。


<details>
  <summary>Details</summary>
Motivation: 文本驱动行人检索（TBPS）在公共安全中至关重要，但面临跨模态差异和用户查询模糊两大挑战。

Method: CONQUER采用两阶段设计：训练阶段引入多粒度编码、互补对挖掘和基于最优传输的上下文引导匹配；推理阶段使用无需重训练的锚点选择与属性驱动查询增强模块。

Result: 在CUHK-PEDES、ICFG-PEDES和RSTPReid数据集上，CONQUER在Rank-1准确率和mAP上均超越强基线，尤其在跨域和不完整查询场景下提升显著。

Conclusion: CONQUER是一种实用且高效的TBPS解决方案，适用于真实场景部署。

Abstract: Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.

</details>


### [159] [Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting](https://arxiv.org/abs/2601.18633)
*Tong Shi,Melonie de Almeida,Daniela Ivanova,Nicolas Pugeault,Paul Henderson*

Main category: cs.CV

TL;DR: Splat-Portrait是一种基于高斯点绘（Gaussian Splatting）的无监督3D说话人头生成方法，无需3D标注或运动先验，自动分离静态3D头像与背景，并根据语音驱动自然唇部运动。


<details>
  <summary>Details</summary>
Motivation: 现有3D说话人头生成方法依赖领域特定启发式先验（如基于形变的面部运动表示），导致3D重建不准确、动画真实性不足。

Method: 提出Splat-Portrait：利用高斯点绘表征静态3D头像，联合学习2D背景和音频条件下的唇部运动；训练仅依赖2D重建损失和分数蒸馏损失，无需3D监督或关键点标注。

Result: 在说话人头生成与新视角合成任务上显著优于先前方法，视觉质量更高。

Conclusion: 高斯点绘可有效建模高质量3D人头，结合纯2D监督与分数蒸馏能实现无先验、端到端的逼真语音驱动动画生成。

Abstract: Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.

</details>


### [160] [Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge](https://arxiv.org/abs/2601.18698)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

TL;DR: 本文提出Geo-Attraction Landmark Probing（GAP）框架与GEOATTRACTION-500基准，评估文本到视频模型（如Sora 2）在地理表征上的公平性，发现其地理视觉知识分布比预期更均衡。


<details>
  <summary>Details</summary>
Motivation: 探究当前文本到视频生成模型是否编码了地理上公平的视觉知识，尤其关注其对全球不同地区旅游景点的表征能力。

Method: 提出GAP评估框架，结合全局结构对齐、关键点级对齐和多模态语言模型判断，并构建含500个全球景点的GEOATTRACTION-500基准；以Sora 2为对象开展实证分析，并与人工评估对比验证。

Result: Sora 2在不同地理区域、发展水平和文化群体间表现出相对均匀的地理视觉知识表达能力，仅对景点流行度有微弱依赖。

Conclusion: 当前文本到视频模型具备比预期更均衡的全球视觉知识表达能力，展现出全球部署潜力，但也需持续开展地理公平性评估。

Abstract: Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.

</details>


### [161] [SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification](https://arxiv.org/abs/2601.18739)
*Ignacio Antequera-Sánchez,Juan Luis Suárez-Díaz,Rosana Montes,Francisco Herrera*

Main category: cs.CV

TL;DR: 本文提出SeNeDiF-OOD方法，通过语义嵌套二分融合框架，分层建模不同抽象层次的决策边界，以提升对异构OOD数据（如低级扰动、语义偏移、未知类别和对抗攻击）的检测能力，并在MonuMAI建筑风格识别系统中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有单阶段OOD检测器难以应对开放世界中异构的OOD数据（如低级图像损坏与高层语义偏移），亟需更鲁棒、分层的检测机制。

Method: 提出基于语义嵌套二分（Semantic Nested Dichotomy）的融合框架SeNeDiF-OOD，将OOD检测任务分解为多层二元融合节点，每层对应特定语义抽象层级的决策边界融合。

Result: 在MonuMAI真实建筑风格识别系统上的实验表明，该方法显著优于传统基线，在过滤多种OOD类型（非纪念碑图像、未知风格、对抗样本）的同时保持ID性能稳定。

Conclusion: 分层语义融合是提升OOD检测泛化性与鲁棒性的有效路径，SeNeDiF-OOD为开放世界AI部署提供了可扩展、可解释的检测范式。

Abstract: Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [162] [Crystal-KV: Efficient KV Cache Management for Chain-of-Thought LLMs via Answer-First Principle](https://arxiv.org/abs/2601.16986)
*Zihan Wang,Cheng Tang,Lei Gong,Cheng Li,Chao Wang,teng wang,Wenqi Lou,Xuehai Zhou*

Main category: cs.CL

TL;DR: 本文提出Crystal-KV框架，基于'答案优先'原则区分关键（CrystalKV）与非关键（SlipKV）缓存项，通过注意力驱动的LRU策略和自适应缓存预算分配，在保持甚至提升CoT推理准确率的同时，显著压缩KV缓存、提高吞吐量与响应速度。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought推理中KV缓存内存开销过大，而传统KV压缩方法未考虑CoT中仅最终答案关键、中间思考步骤重要性不均的特点。

Method: 提出Crystal-KV框架：1）依据答案偏好构建思考阶段注意力图，区分SlipKV与CrystalKV；2）设计注意力驱动的Least Recently Frequently Used算法动态淘汰SlipKV；3）引入基于各层/头CrystalKV比例的自适应缓存预算分配机制。

Result: 在CoT推理任务上实现SOTA级KV缓存压缩效果，显著提升吞吐量与响应速度，同时保持或提升答案准确率。

Conclusion: Crystal-KV通过建模CoT中不同token对最终答案的贡献差异，实现了高效、精准、动态的KV缓存管理，为大模型推理优化提供了新范式。

Abstract: Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.

</details>


### [163] [Evaluating Reward Model Generalization via Pairwise Maximum Discrepancy Competitions](https://arxiv.org/abs/2601.16987)
*Shunyang Luo,Peibei Cao,Zhihui Zhu,Kehua Feng,Zhihua Wang,Keyan Ding*

Main category: cs.CL

TL;DR: 本文提出Pairwise Maximum Discrepancy Competition (PMDC)，一种动态、标注高效的奖励模型（RM）泛化能力评估框架，利用未标注开放域提示池，通过最大化两个RM间分歧来筛选高争议测试样本，并借助Bradley-Terry模型生成全局排名与胜率图谱；实验重评10个主流RM，发现其排序与传统基准差异显著，并揭示系统性泛化缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有RM评估依赖静态预标注偏好数据集，覆盖有限且难以真实反映开放世界中的泛化能力。

Method: 提出PMDC框架：基于大规模未标注开放域提示池，主动选择使两个RM分歧最大的prompt-response对作为测试样本；由oracle裁决后，用Bradley-Terry模型聚合结果，生成RM全局排名和两两胜率图谱。

Result: 在10个代表性RM上应用PMDC，观察到相较传统基准存在显著排名变动；定性分析揭示了RM系统性的泛化失败模式。

Conclusion: PMDC提供了一种更贴近实际部署场景的动态评估范式，能更真实地衡量RM泛化能力，并为改进奖励建模提供可解释的诊断依据。

Abstract: Reward models (RMs) are central to aligning large language models, yet their practical effectiveness hinges on generalization to unseen prompts and shifting distributions. Most existing RM evaluations rely on static, pre-annotated preference datasets, which provide limited coverage and often fail to faithfully assess generalization in open-world settings. We introduce Pairwise Maximum Discrepancy Competition (PMDC), a dynamic and annotation-efficient framework for evaluating RM generalization using a large, unlabeled, open-domain prompt pool. PMDC actively selects prompt--response pairs that maximize disagreement between two RMs, yielding a compact set of highly contentious test cases. These cases are adjudicated by an oracle, and the resulting outcomes are aggregated via a Bradley--Terry model to produce a global ranking and pairwise win-rate landscape of RMs. We apply PMDC to re-evaluate 10 representative RMs and observe substantial rank reshuffling compared with conventional benchmarks. Qualitative analyses further uncover systematic generalization failures, providing valuable insights for improving reward modeling.

</details>


### [164] [Uncertainty Quantification for Named Entity Recognition via Full-Sequence and Subsequence Conformal Prediction](https://arxiv.org/abs/2601.16999)
*Matthew Singer,Srijan Sengupta,Karl Pazdernik*

Main category: cs.CL

TL;DR: 本文提出了一种基于共形预测的不确定性感知命名实体识别（NER）框架，使模型能输出包含真实标注、具有用户指定置信度保证的预测集合。


<details>
  <summary>Details</summary>
Motivation: 现有NER模型仅输出单一标签序列，缺乏不确定性估计，易导致下游任务级联错误。

Method: 基于共形预测构建不确定性感知的预测集，设计高效非一致性打分函数，支持无条件与类别条件覆盖，并考虑句子长度、语言、实体类型及实体数量等异质性因素。

Result: 在三个基准数据集、四种NER模型上的实验验证了该方法的普适性、有效性与校准性，预测集满足预设覆盖率保证。

Conclusion: 该框架为NER提供了具备统计保证的不确定性量化手段，可提升下游应用鲁棒性，是将共形预测成功拓展至结构化序列标注任务的重要尝试。

Abstract: Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.

</details>


### [165] [RAM-SD: Retrieval-Augmented Multi-agent framework for Sarcasm Detection](https://arxiv.org/abs/2601.17002)
*Ziyang Zhou,Ziqi Liu,Yan Wang,Yiming Lin,Yangbin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种检索增强的多智能体框架RAM-SD，用于解决讽刺检测中因表达多样性导致的统一推理策略失效问题，通过上下文检索、元规划、多视角专用智能体分析与结果整合四阶段流程，在四个基准上达到77.74% Macro-F1，超越GPT-4o+CoC 7.01点，并提供可解释推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有讽刺检测方法（如微调Transformer或大语言模型）采用统一推理策略，难以应对讽刺表达在语境预期违背、外部知识依赖和修辞模式识别等方面的多样化分析需求。

Method: 提出RAM-SD框架：（1）上下文检索，从讽刺与非讽刺样例中获取支撑；（2）元规划器识别讽刺类型并选择最优推理计划；（3）多个专用智能体进行互补的多视角分析；（4）整合器生成最终判断及自然语言解释。

Result: 在四个标准基准上取得77.74%的Macro-F1，比强基线GPT-4o+CoC高7.01个百分点，并提供透明、可解释的推理轨迹。

Conclusion: RAM-SD不仅提升了讽刺检测性能，还增强了模型决策的可解释性，揭示了讽刺理解背后的认知机制。

Abstract: Sarcasm detection remains a significant challenge due to its reliance on nuanced contextual understanding, world knowledge, and multi-faceted linguistic cues that vary substantially across different sarcastic expressions. Existing approaches, from fine-tuned transformers to large language models, apply a uniform reasoning strategy to all inputs, struggling to address the diverse analytical demands of sarcasm. These demands range from modeling contextual expectation violations to requiring external knowledge grounding or recognizing specific rhetorical patterns. To address this limitation, we introduce RAM-SD, a Retrieval-Augmented Multi-Agent framework for Sarcasm Detection. The framework operates through four stages: (1) contextual retrieval grounds the query in both sarcastic and non-sarcastic exemplars; (2) a meta-planner classifies the sarcasm type and selects an optimal reasoning plan from a predefined set; (3) an ensemble of specialized agents performs complementary, multi-view analysis; and (4) an integrator synthesizes these analyses into a final, interpretable judgment with a natural language explanation. Evaluated on four standard benchmarks, RAM-SD achieves a state-of-the-art Macro-F1 of 77.74%, outperforming the strong GPT-4o+CoC baseline by 7.01 points. Our framework not only sets a new performance benchmark but also provides transparent and interpretable reasoning traces, illuminating the cognitive processes behind sarcasm comprehension.

</details>


### [166] [From Emotion to Expression: Theoretical Foundations and Resources for Fear Speech](https://arxiv.org/abs/2601.17132)
*Vigneshwaran Shankaran,Gabriella Lapesa,Claudia Wagner*

Main category: cs.CL

TL;DR: 本文整合心理学、政治学、传播学和语言学对恐惧的研究视角，系统梳理恐惧言语（fear speech）的定义、现有数据集，并提出统一的多维分类体系，为构建新数据集和推动该领域计算研究提供理论与实践指导。


<details>
  <summary>Details</summary>
Motivation: 恐惧言语广泛存在且影响力强，表面更‘文明’因而易逃避内容审核，但其计算研究仍零散且资源不足，亟需跨学科整合与系统化框架。

Method: 通过跨学科理论比较（心理学、政治学、传播学、语言学），梳理现有定义，调研相关数据集，并提出涵盖多维度的恐惧言语分类体系。

Result: 提出了首个整合多学科视角的恐惧言语 taxonomy，系统总结了现有数据集特征与局限，明确了核心概念与研究方向。

Conclusion: 恐惧言语需被视作一种独立言语类型而非单纯情绪；跨学科整合是推进其计算研究的关键路径；本工作为后续数据集构建与算法开发提供了基础性框架。

Abstract: Few forces rival fear in their ability to mobilize societies, distort communication, and reshape collective behavior. In computational linguistics, fear is primarily studied as an emotion, but not as a distinct form of speech. Fear speech content is widespread and growing, and often outperforms hate-speech content in reach and engagement because it appears "civiler" and evades moderation. Yet the computational study of fear speech remains fragmented and under-resourced. This can be understood by recognizing that fear speech is a phenomenon shaped by contributions from multiple disciplines. In this paper, we bridge cross-disciplinary perspectives by comparing theories of fear from Psychology, Political science, Communication science, and Linguistics. Building on this, we review existing definitions. We follow up with a survey of datasets from related research areas and propose a taxonomy that consolidates different dimensions of fear for studying fear speech. By reviewing current datasets and defining core concepts, our work offers both theoretical and practical guidance for creating datasets and advancing fear speech research.

</details>


### [167] [Dynamic Role Assignment for Multi-Agent Debate](https://arxiv.org/abs/2601.17152)
*Miao Zhang,Junsik Kim,Siyuan Xiang,Jian Gao,Cheng Cao*

Main category: cs.CL

TL;DR: 本文提出动态角色分配框架，通过元辩论（Meta-Debate）在多智能体辩论系统中为不同角色选择最合适的LLM/VLM模型，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体辩论系统虽采用专业化角色，但未根据各模型的实际能力为其分配最适配的角色，导致潜力未被充分挖掘。

Method: 提出动态角色分配框架：先运行两阶段元辩论——（1）提案阶段，候选模型生成角色定制化论点；（2）同行评审阶段，依据数据与角色特异性标准对提案打分，选出最优模型担任各角色。

Result: 在LLM问题求解基准上验证，相较统一指派（所有角色用同一模型）最高提升74.8%，相较随机指派最高提升29.7%。

Conclusion: 该工作确立了多智能体系统设计的新范式——从静态部署转向动态、能力感知的角色分配。

Abstract: Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.

</details>


### [168] [Interpretability of the Intent Detection Problem: A New Approach](https://arxiv.org/abs/2601.17156)
*Eduardo Sanchez-Karhunen,Jose F. Quesada-Moreno,Miguel A. Gutiérrez-Naranjo*

Main category: cs.CL

TL;DR: 本文利用动力系统理论分析RNN在意图检测任务中的工作机制，发现其在平衡数据集（SNIPS）上形成理想几何结构（低维流形上的意图聚类），但在不平衡数据集（ATIS）上因类别不均衡导致低频意图聚类退化；该框架将几何分离与读出对齐解耦，揭示了数据特性如何直接塑造网络计算解。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习（尤其是RNN）在意图检测中占主导地位，但其内部工作机制尚不清楚，尤其缺乏对RNN如何从动态系统角度解决该任务的机理理解。

Method: 采用动力系统理论，将句子建模为隐状态空间中的轨迹，在平衡的SNIPS和不平衡的ATIS数据集上分析RNN隐状态空间的几何结构，重点考察低维流形、意图聚类分布及类别不平衡的影响。

Result: 在SNIPS上观察到理想几何解：隐状态被约束于低维流形并清晰聚类；在ATIS上发现低频意图对应聚类退化；提出几何分离与读出对齐解耦的新解释框架。

Conclusion: RNN在意图检测中的性能差异可由数据集的统计特性（如类别平衡性）通过隐状态空间几何结构的变化来机制性解释，为理解RNN动态行为提供了新的几何视角。

Abstract: Intent detection, a fundamental text classification task, aims to identify and label the semantics of user queries, playing a vital role in numerous business applications. Despite the dominance of deep learning techniques in this field, the internal mechanisms enabling Recurrent Neural Networks (RNNs) to solve intent detection tasks are poorly understood. In this work, we apply dynamical systems theory to analyze how RNN architectures address this problem, using both the balanced SNIPS and the imbalanced ATIS datasets. By interpreting sentences as trajectories in the hidden state space, we first show that on the balanced SNIPS dataset, the network learns an ideal solution: the state space, constrained to a low-dimensional manifold, is partitioned into distinct clusters corresponding to each intent. The application of this framework to the imbalanced ATIS dataset then reveals how this ideal geometric solution is distorted by class imbalance, causing the clusters for low-frequency intents to degrade. Our framework decouples geometric separation from readout alignment, providing a novel, mechanistic explanation for real world performance disparities. These findings provide new insights into RNN dynamics, offering a geometric interpretation of how dataset properties directly shape a network's computational solution.

</details>


### [169] [Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text](https://arxiv.org/abs/2601.17172)
*Tunazzina Islam*

Main category: cs.CL

TL;DR: 本文首次系统分析了大语言模型（LLMs）在人口统计学条件下的定向消息生成中的行为，发现GPT-4o、Llama-3.3和Mistral-Large 2.1均表现出显著的年龄与性别偏见：面向男性和年轻人的消息强调能动性与创新，而面向女性和老年人的消息则侧重温暖与传统；上下文增强进一步放大了这些偏差。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在个性化、说服性文本生成方面能力增强，其在自动化传播中引发的偏见与公平性问题日益突出，亟需系统评估其在人口统计条件下的定向生成行为。

Method: 构建了一个受控评估框架，在两种生成设置（独立生成与上下文丰富生成）下，使用GPT-4o、Llama-3.3和Mistral-Large 2.1三个主流模型，从词汇内容、语言风格和说服框架三方面评估气候传播中的定向消息生成。

Result: 所有模型均一致呈现年龄与性别不对称：男性/青年导向消息偏向能动性、创新与果断；女性/老年导向消息偏向温暖、关怀与传统；上下文提示显著放大差异，且对年轻/男性受众的消息说服力评分更高。

Conclusion: 人口统计刻板印象会在LLM定向通信中自然浮现并被上下文强化，凸显需构建偏见感知的生成流程与透明审计框架，尤其在社会敏感应用中须显式纳入人口统计条件考量。

Abstract: Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.

</details>


### [170] [Beyond Factual QA: Mentorship-Oriented Question Answering over Long-Form Multilingual Content](https://arxiv.org/abs/2601.17173)
*Parth Bhalerao,Diola Dsouza,Ruiwen Guan,Oana Ignat*

Main category: cs.CL

TL;DR: 本文提出了MentorQA，首个面向导师式问答的多语言数据集与评估框架，聚焦长视频中的反思性与指导性回答，涵盖四种语言、近9000个问答对；定义了超越事实准确性的评估维度（清晰度、一致性、学习价值）；实验表明多智能体架构在复杂主题和低资源语言中表现更优；同时揭示了基于大模型的自动评估与人工判断存在显著偏差。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统评估主要关注事实正确性，但教育、职业指导等实际场景需要具备反思与指导能力的‘导师式’回应；当前基准缺乏对多语言和长文本场景下导师式问答的支持。

Method: 构建MentorQA多语言长视频问答数据集（4种语言、180小时视频、近9000 QA对），提出涵盖清晰度、一致性、学习价值的导师式评估维度；在统一设置下对比单智能体、双智能体、RAG与多智能体架构；并分析LLM自动评估与人工评价的一致性。

Result: 多智能体架构在导师式响应质量上持续优于其他方法，尤其在复杂主题和低资源语言中提升显著；LLM自动评估结果与人类判断存在较大偏差。

Conclusion: 导师式问答是一个独立且重要的研究方向；MentorQA为多语言教育AI中智能体架构设计与评估方法研究提供了新基准与实证基础。

Abstract: Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.

</details>


### [171] [Systematicity between Forms and Meanings across Languages Supports Efficient Communication](https://arxiv.org/abs/2601.17181)
*Doreen Osmelak,Yang Xu,Michael Hahn,Kate McCurdy*

Main category: cs.CL

TL;DR: 本文探讨了语言中语法意义（如人称、数）在动词和代词上的表达方式，提出了一种基于可学性衡量复杂度的新模型，以解释语言形式的系统性与高效交际理论之间的联系。


<details>
  <summary>Details</summary>
Motivation: 现有高效交际理论未能解释词形内部的系统性关系，本文旨在填补这一空白。

Method: 提出一种基于意义-形式映射可学性的新复杂度度量方法，并分析跨语言动词和代词中语法意义的表达模式。

Result: 发现动词和代词形式受简洁性（最小化语法区分数量）与准确性（确保意义可恢复）两种交际压力共同塑造；新模型能更好地区分已存在与不存在的语言系统。

Conclusion: 该研究建立了高效交际理论与自然语言系统性之间新的理论联系，并通过可学性复杂度度量揭示了语言形式的细粒度规律。

Abstract: Languages vary widely in how meanings map to word forms. These mappings have been found to support efficient communication; however, this theory does not account for systematic relations within word forms. We examine how a restricted set of grammatical meanings (e.g. person, number) are expressed on verbs and pronouns across typologically diverse languages. Consistent with prior work, we find that verb and pronoun forms are shaped by competing communicative pressures for simplicity (minimizing the inventory of grammatical distinctions) and accuracy (enabling recovery of intended meanings). Crucially, our proposed model uses a novel measure of complexity (inverse of simplicity) based on the learnability of meaning-to-form mappings. This innovation captures fine-grained regularities in linguistic form, allowing better discrimination between attested and unattested systems, and establishes a new connection from efficient communication theory to systematicity in natural language.

</details>


### [172] [Reasoning Beyond Literal: Cross-style Multimodal Reasoning for Figurative Language Understanding](https://arxiv.org/abs/2601.17197)
*Seyyed Saeid Cheshmi,Hahnemann Ortiz,James Mooney,Dongyeop Kang*

Main category: cs.CL

TL;DR: 本文提出了一种三步框架，用于构建能理解多模态比喻语言、提供可解释推理过程、并跨多种比喻风格泛化的轻量级视觉-语言模型（VLM）。实验表明，引入推理轨迹显著提升性能，风格间存在可迁移性，联合训练可超越更大规模模型。


<details>
  <summary>Details</summary>
Motivation: 现有VLM在字面多模态任务上表现良好，但在处理讽刺、幽默、隐喻等比喻语言时仍面临挑战，尤其当图文含义存在微妙不一致或主观性增强时。

Method: 提出三步框架：(i) 多模态比喻语言理解；(ii) 生成透明推理轨迹；(iii) 跨多种比喻风格（如讽刺、幽默等）泛化。通过联合训练与推理轨迹建模实现。

Result: 在四种比喻风格上的实验显示：(1) 推理轨迹显著提升理解能力；(2) 风格间存在正向迁移（尤其讽刺与幽默）；(3) 联合训练的轻量VLM优于更大规模开源/闭源模型。

Conclusion: 轻量级VLM结合可验证推理机制，可在多模态比喻理解任务中实现强跨风格泛化，并提供可检验的推理过程。

Abstract: Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at https://github.com/scheshmi/CrossStyle-MMR.

</details>


### [173] [Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis](https://arxiv.org/abs/2601.17203)
*Scott Friedman,Sonja Schmer-Galunder,Anthony Chen,Jeffrey Rye*

Main category: cs.CL

TL;DR: 本文提出一种量化词嵌入中性别偏见的方法，并利用该方法刻画教育、政治、经济和健康领域的统计性别差距，通过2018年Twitter数据验证其与真实世界性别差距指标的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有NLP模型因训练数据固有偏差而存在性别/种族偏见，这些偏见虽需修正，但也可能反映真实社会文化中的性别差距，因而可作为理解文化背景的大数据工具。

Method: 构建词嵌入性别偏见量化指标，并将其与多国/地区在教育、政治、经济、健康等领域的18项国际及5项美国本土统计性别差距指标进行相关性分析。

Result: 在51个美国州和99个国家的2018年Twitter数据上验证了词嵌入性别偏见指标，发现其与真实统计性别差距具有显著相关性，展现出规律性和预测能力。

Conclusion: 词嵌入中的性别偏见可作为反映现实社会性别差距的有效代理指标，为基于大规模文本数据的文化与社会分析提供新路径。

Abstract: Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.

</details>


### [174] [DF-RAG: Query-Aware Diversity for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.17212)
*Saadat Hasan Khan,Spencer Hong,Jingyu Wu,Kevin Lybarger,Youbing Yin,Erin Babinsky,Daben Liu*

Main category: cs.CL

TL;DR: 本文提出DF-RAG方法，在检索阶段引入多样性以提升推理密集型问答任务的性能，通过动态优化每条查询的多样性水平，无需额外微调，显著优于传统RAG及其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统RAG在推理密集型问答任务中受限于基于余弦相似度的检索方式，易引入冗余内容，降低信息召回率。

Method: 基于最大边际相关性（MMR）框架，设计多样性聚焦的检索策略，动态调整每条查询的多样性水平，无需额外微调。

Result: 在推理密集型QA基准上F1值比传统RAG提升4-10%，达到Oracle上限的91.3%。

Conclusion: DF-RAG通过在检索阶段系统性引入多样性，有效提升了复杂问答任务的性能，且具备良好的泛化性和实用性。

Abstract: Retrieval-augmented generation (RAG) is a common technique for grounding language model outputs in domain-specific information. However, RAG is often challenged by reasoning-intensive question-answering (QA), since common retrieval methods like cosine similarity maximize relevance at the cost of introducing redundant content, which can reduce information recall. To address this, we introduce Diversity-Focused Retrieval-Augmented Generation (DF-RAG), which systematically incorporates diversity into the retrieval step to improve performance on complex, reasoning-intensive QA benchmarks. DF-RAG builds upon the Maximal Marginal Relevance framework to select information chunks that are both relevant to the query and maximally dissimilar from each other. A key innovation of DF-RAG is its ability to optimize the level of diversity for each query dynamically at test time without requiring any additional fine-tuning or prior information. We show that DF-RAG improves F1 performance on reasoning-intensive QA benchmarks by 4-10 percent over vanilla RAG using cosine similarity and also outperforms other established baselines. Furthermore, we estimate an Oracle ceiling of up to 18 percent absolute F1 gains over vanilla RAG, of which DF-RAG captures up to 91.3 percent.

</details>


### [175] [Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning](https://arxiv.org/abs/2601.17223)
*Massimiliano Pronesti,Anya Belz,Yufang Hou*

Main category: cs.CL

TL;DR: 本文提出了一种名为可验证过程奖励模型（VPRMs）的强化学习框架，利用确定性、基于规则的验证器来检查大语言模型（LLM）推理过程中的中间步骤，应用于医学证据合成中的偏倚风险评估，显著提升了推理合规性、逻辑一致性和最终性能。


<details>
  <summary>Details</summary>
Motivation: 现有过程监督方法依赖神经判别器评分思维链步骤，存在不透明、偏差和奖励作弊问题；而结果级可验证奖励虽有效，但无法引导中间推理质量。

Method: 提出VPRMs框架，将确定性、基于规则的验证器嵌入强化学习流程，对推理链每一步进行程序化验证；在医学偏倚风险评估任务中，依据指南定义的规则对推理路径进行逐步校验。

Result: 在多个数据集上，VPRMs生成的推理更符合领域规则，步骤决策与最终标签一致性显著提升；F1分数比当前最优模型高20%，比可验证结果奖励高6.5%，并在证据依据性和逻辑连贯性上取得大幅改进。

Conclusion: 可验证的过程监督（VPRMs）是一种有效且可靠的方法，能显著提升LLM在结构化、规则明确领域的推理质量与可信度，为安全关键型AI应用提供了新范式。

Abstract: Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.

</details>


### [176] [Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation](https://arxiv.org/abs/2601.17226)
*David Y. Liu,Xanthe Muston,Aditya Joshi,Sebastian Sequoiah-Grayson*

Main category: cs.CL

TL;DR: 本文提出了一种基于强化学习的自动故事生成（ASG）后训练方法d-RLAIF，利用叙事均衡理论指导奖励设计，并通过LLM-as-judge实现与人类标注的一致性，结果表明其在多样性与叙事规范性上优于监督微调（SFT）。


<details>
  <summary>Details</summary>
Motivation: 过去自动故事生成工作依赖有限且主观性强的真值标签进行训练和评估，缺乏对叙事主观性本质的有效建模。

Method: 提出d-RLAIF方法，结合Todorov叙事均衡理论构建评价原则，使用7B/14B LLM作为裁判模型提供与人类一致的奖励信号，进行强化学习后训练；用Gemini-3-Flash评估生成故事质量，并与TimeTravel中人工撰写故事对比。

Result: d-RLAIF生成的故事比SFT更富多样性，且更符合人类叙事规范，在语言层面实现了更优的主观任务后训练效果。

Conclusion: 强化学习（尤其是d-RLAIF）是一种有前景的、面向语言 grounded 的主观任务（如ASG）后训练范式，可有效缓解对固定真值标签的依赖。

Abstract: Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.

</details>


### [177] [CaseFacts: A Benchmark for Legal Fact-Checking and Precedent Retrieval](https://arxiv.org/abs/2601.17230)
*Akshith Reddy Putta,Jacob Devasier,Chengkai Li*

Main category: cs.CL

TL;DR: 本文提出了CaseFacts基准，用于验证面向普通用户的法律主张是否符合美国最高法院判例，强调语义鸿沟与时间有效性挑战，并揭示当前大模型在该任务上表现不佳，尤其网络搜索反而降低性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查研究多聚焦于静态通用知识，忽视了法律等高风险、动态演进且技术性强的领域，亟需能处理非正式表述与专业判例间语义差距及时间有效性的新基准。

Method: 构建CaseFacts基准：基于专家案例摘要，利用大语言模型（LLM）生成6294条通俗法律主张；提出新颖语义相似性启发式方法，高效识别并验证复杂判例推翻关系；采用多阶段流水线完成标注（Supported/Refuted/Overruled）。

Result: 实验表明，当前最先进大语言模型在该任务上仍面临巨大挑战；引入无限制网络搜索反而导致性能下降，因其检索到大量噪声和非权威判例。

Conclusion: CaseFacts填补了法律事实核查基准空白，凸显了跨语义、有时效性法律推理的难度，呼吁发展更鲁棒、权威感知的法律验证系统，并已开源该数据集以推动相关研究。

Abstract: Automated Fact-Checking has largely focused on verifying general knowledge against static corpora, overlooking high-stakes domains like law where truth is evolving and technically complex. We introduce CaseFacts, a benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents. Unlike existing resources that map formal texts to formal texts, CaseFacts challenges systems to bridge the semantic gap between layperson assertions and technical jurisprudence while accounting for temporal validity. The dataset consists of 6,294 claims categorized as Supported, Refuted, or Overruled. We construct this benchmark using a multi-stage pipeline that leverages Large Language Models (LLMs) to synthesize claims from expert case summaries, employing a novel semantic similarity heuristic to efficiently identify and verify complex legal overrulings. Experiments with state-of-the-art LLMs reveal that the task remains challenging; notably, augmenting models with unrestricted web search degrades performance compared to closed-book baselines due to the retrieval of noisy, non-authoritative precedents. We release CaseFacts to spur research into legal fact verification systems.

</details>


### [178] [Frame-Guided Synthetic Claim Generation for Automatic Fact-Checking Using High-Volume Tabular Data](https://arxiv.org/abs/2601.17232)
*Jacob Devasier,Akshith Putta,Qing Wang,Alankrit Moses,Chengkai Li*

Main category: cs.CL

TL;DR: 本文提出了一种面向大规模结构化数据（如OECD表格）的多语言自动事实核查新基准，包含78,503条合成声明，并设计了基于语义框架的生成方法；实验证明现有大模型无法靠记忆回答，必须进行真实检索与推理，且检索是主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查基准忽视了在真实世界、高容量结构化数据上验证声明的挑战，多依赖小规模、人工整理的表格，缺乏对现实场景的覆盖。

Method: 构建了一个大规模多语言数据集，包含78,503条基于434个复杂OECD表格（平均每表超50万行）生成的合成声明；提出帧引导（frame-guided）方法，依据六类语义帧自动选取关键数据点生成英文、中文、西班牙语和印地语声明；通过知识探测实验验证LLM未记忆相关事实；提供SQL生成基线系统。

Result: 基准极具挑战性，分析表明证据检索是主要瓶颈——模型难以在海量表格中准确定位所需数据；基线系统表现有限，证实该任务尚未解决。

Conclusion: 该工作填补了结构化数据事实核查的关键空白，提供了首个面向真实高维表格的大规模多语言基准，推动检索增强型推理与跨语言事实核查研究。

Abstract: Automated fact-checking benchmarks have largely ignored the challenge of verifying claims against real-world, high-volume structured data, instead focusing on small, curated tables. We introduce a new large-scale, multilingual dataset to address this critical gap. It contains 78,503 synthetic claims grounded in 434 complex OECD tables, which average over 500K rows each. We propose a novel, frame-guided methodology where algorithms programmatically select significant data points based on six semantic frames to generate realistic claims in English, Chinese, Spanish, and Hindi. Crucially, we demonstrate through knowledge-probing experiments that LLMs have not memorized these facts, forcing systems to perform genuine retrieval and reasoning rather than relying on parameterized knowledge. We provide a baseline SQL-generation system and show that our benchmark is highly challenging. Our analysis identifies evidence retrieval as the primary bottleneck, with models struggling to find the correct data in massive tables. This dataset provides a critical new resource for advancing research on this unsolved, real-world problem.

</details>


### [179] [PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues](https://arxiv.org/abs/2601.17277)
*Mohammad Rifqi Farhansyah,Hanif Muhammad Zhafran,Farid Adilazuarda,Shamsuddeen Hassan Muhammad,Maryam Ibrahim Mukhtar,Nedjma Ousidhoum,Genta Indra Winata,Ayu Purwarianti,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 本文提出了PingPong基准，用于评估自然多语码切换对话，涵盖五种语言组合（含三语），强调真实多参与者、多线程、长距离引用等复杂结构，并定义了问答、摘要和主题分类三项下游任务，实验表明现有大模型在该任务上性能有限。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能准确反映日常交流中多语码切换的复杂性，亟需更贴近真实场景的评估数据集。

Method: 构建人类撰写的多参与者（2–4人）、多线程、长上下文依赖的码切换对话数据集PingPong，覆盖五种语言组合（含三语），并基于其定义三个下游NLP任务。

Result: PingPong在自然性、结构多样性（消息长度、发言主导性、回复距离）上显著优于机器生成数据；当前SOTA语言模型在其上的问答、摘要与主题分类任务表现仍较差。

Conclusion: 真实多语码切换对话极具挑战性，现有NLP系统鲁棒性不足，需针对性建模以支持复杂多语交流。

Abstract: Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.

</details>


### [180] [Mind the Ambiguity: Aleatoric Uncertainty Quantification in LLMs for Safe Medical Question Answering](https://arxiv.org/abs/2601.17284)
*Yaokun Liu,Yifan Liu,Phoebe Mbuvi,Zelin Li,Ruichen Yao,Gawon Lim,Dong Wang*

Main category: cs.CL

TL;DR: 本文提出了一种基于输入歧义（aleatoric uncertainty）检测的'先澄清再回答'框架，用于提升医疗问答系统的安全性和准确性。通过构建首个专门研究医疗QA中输入歧义的基准CV-MedBench，并发现歧义在线性可分的LLM隐状态中编码，作者设计了无需微调、单次前向传播即可工作的轻量级AU-Probe模块，显著提升了多个开源大模型在医疗问答上的准确率（平均+9.48%）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗问答中的部署因用户查询模糊而严重受限，这种模糊性带来显著的安全风险，并降低高风险医疗场景下的回答准确性。

Method: 1）形式化输入模糊性为偶然不确定性（AU）；2）构建首个针对医疗QA中输入模糊性的基准CV-MedBench；3）从表征工程角度分析发现AU在线性可分的LLM内部激活模式中编码；4）提出AU-guided 'Clarify-Before-Answer'框架及轻量AU-Probe模块，直接从隐藏状态检测歧义，无需微调或多次前向传播。

Result: 在四个开源大语言模型上实验表明，所提框架平均准确率较基线提升9.48%；AU-Probe具备高效性与即插即用特性；CV-MedBench数据集与代码均已开源。

Conclusion: 该框架为安全、可靠的医疗问答提供了高效且鲁棒的解决方案，增强了健康相关AI应用的可信度。

Abstract: The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided "Clarify-Before-Answer" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.

</details>


### [181] [Meta-Judging with Large Language Models: Concepts, Methods, and Challenges](https://arxiv.org/abs/2601.17312)
*Hugo Silva,Mateus Mendes,Hugo Gonçalo Oliveira*

Main category: cs.CL

TL;DR: 本文综述了LLM-as-a-Meta-Judge这一新兴范式，旨在克服传统LLM-as-a-Judge在评估中存在提示敏感、偏见、冗余效应和幻觉等问题，提出从概念基础、机制、对齐训练、评估、局限性与失效模式及未来方向六个维度系统梳理相关研究。


<details>
  <summary>Details</summary>
Motivation: 传统LLM-as-a-Judge存在提示敏感、系统性偏见、冗长效应及不可靠/幻觉推理等显著缺陷，亟需更鲁棒的评估范式。

Method: 通过构建涵盖六大关键视角（概念基础、元评判机制、对齐训练方法、评估方式、局限性与失效模式、未来方向）的框架，系统梳理并分析现有元评判文献。

Result: 确立LLM-as-a-Meta-Judge为提升自动评估稳定性与可信度的有前景方向，并识别出成本、提示敏感性及共享模型偏差等关键挑战。

Conclusion: LLM-as-a-Meta-Judge是改进大语言模型自动评估的重要路径，但其实际落地仍需解决成本高、提示鲁棒性弱及模型共性偏差等问题。

Abstract: Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.

</details>


### [182] [The Shadow Self: Intrinsic Value Misalignment in Large Language Model Agents](https://arxiv.org/abs/2601.17344)
*Chen Chen,Kim Young Il,Yuan Yang,Wenhao Su,Yilin Zhang,Xueluan Gong,Qian Wang,Yongsen Zheng,Ziyao Liu,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 本文提出IMPRESS框架，用于评估大语言模型（LLM）代理在真实、良性、情境化场景下的内在价值错位（Intrinsic VM）风险，发现该风险普遍存在且受动机、风险类型、模型规模与架构影响显著，而现有缓解策略效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全评估主要关注对显式有害输入的响应或系统鲁棒性，却忽视了在完全良性、现实且具自主性的代理场景中可能发生的内在价值错位问题。

Method: 形式化Loss-of-Control风险与Intrinsic VM概念；构建基于多阶段LLM生成与严格质量控制的IMPRESS场景驱动评估框架及基准；对21个前沿LLM代理进行系统评测，并辅以人工验证与缓解策略分析。

Result: Intrinsic VM是普遍存在的安全风险；其发生率受动机、风险类型、模型规模和架构显著影响，而解码策略影响微弱；情境化与表述方式显著改变错位行为；现有安全提示与防护机制效果不稳定或有限。

Conclusion: Intrinsic VM是LLM代理安全的关键盲区，IMPRESS为系统性识别与治理该风险提供了可扩展、可复现的评估范式，推动AI生态中更可靠的价值对齐实践。

Abstract: Large language model (LLM) agents with extended autonomy unlock new capabilities, but also introduce heightened challenges for LLM safety. In particular, an LLM agent may pursue objectives that deviate from human values and ethical norms, a risk known as value misalignment. Existing evaluations primarily focus on responses to explicit harmful input or robustness against system failure, while value misalignment in realistic, fully benign, and agentic settings remains largely underexplored. To fill this gap, we first formalize the Loss-of-Control risk and identify the previously underexamined Intrinsic Value Misalignment (Intrinsic VM). We then introduce IMPRESS (Intrinsic Value Misalignment Probes in REalistic Scenario Set), a scenario-driven framework for systematically assessing this risk. Following our framework, we construct benchmarks composed of realistic, fully benign, and contextualized scenarios, using a multi-stage LLM generation pipeline with rigorous quality control. We evaluate Intrinsic VM on 21 state-of-the-art LLM agents and find that it is a common and broadly observed safety risk across models. Moreover, the misalignment rates vary by motives, risk types, model scales, and architectures. While decoding strategies and hyperparameters exhibit only marginal influence, contextualization and framing mechanisms significantly shape misalignment behaviors. Finally, we conduct human verification to validate our automated judgments and assess existing mitigation strategies, such as safety prompting and guardrails, which show instability or limited effectiveness. We further demonstrate key use cases of IMPRESS across the AI Ecosystem. Our code and benchmark will be publicly released upon acceptance.

</details>


### [183] [Do readers prefer AI-generated Italian short stories?](https://arxiv.org/abs/2601.17363)
*Michael Farrell*

Main category: cs.CL

TL;DR: 本研究通过双盲实验比较读者对AI生成意大利语短篇小说与著名意大利作家莫拉维亚作品的偏好，发现AI文本略受青睐，但差异不显著，且偏好与人口统计学或阅读习惯无关。


<details>
  <summary>Details</summary>
Motivation: 探究读者是否更偏好AI生成的短篇小说而非人类知名作家的作品，挑战关于文学创作中人类作者不可替代性的既有假设。

Method: 采用双盲实验设计，20名参与者阅读并评价两篇ChatGPT-4o生成和一篇莫拉维亚所写的意大利语短篇小说；同时收集其阅读习惯及年龄、性别、教育程度、母语等人口统计学数据。

Result: AI生成文本平均评分略高、被更频繁选择为首选，但差异微小；未发现文本偏好与任何人口统计学变量或阅读习惯存在统计学显著关联。

Conclusion: 结果质疑读者必然偏好人工作品的预设，提示在文学语境中可能无需对合成文本进行过度编辑，也引发关于AI文学接受度与价值判断的新思考。

Abstract: This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.

</details>


### [184] [Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws](https://arxiv.org/abs/2601.17364)
*Mohammed Fasha,Bassam Hammo,Bilal Sowan,Husam Barham,Esam Nsour*

Main category: cs.CL

TL;DR: 本研究以约旦法律为案例，探索了对Llama-3.1大语言模型进行阿拉伯语问答任务的微调方法，采用LoRA适配器与4比特量化技术，在Unsloth框架下高效训练，并构建了6000对约旦法律问答数据集，显著提升了法律推理准确率与资源效率。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在阿拉伯语法律领域的问答能力，解决现有模型在专业、低资源语言场景下的适应性不足问题。

Method: 使用参数高效微调（PEFT）结合LoRA适配器，对两个Llama-3.1-8B变体（基础版与Instruct版）进行4比特量化微调；基于约旦法律构建6000条结构化问答数据集；采用BLEU与ROUGE指标评估性能。

Result: 微调后模型在法律问答任务中展现出更强的法律推理能力和更高准确性，同时通过量化与优化微调策略实现了显著的资源效率提升。

Conclusion: 该工作验证了大语言模型适配阿拉伯语法律领域的可行性，并为低资源语言和专业领域微调提供了可复现、高效率的技术路径。

Abstract: This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.

</details>


### [185] [Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers](https://arxiv.org/abs/2601.17367)
*Zecheng Tang,Quantong Qiu,Yi Yang,Zhiyi Hong,Haiya Xiang,Kebin Liu,Qingqing Dang,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 本文提出Elastic Attention，通过引入轻量级Attention Router，使模型能根据输入动态调整稀疏度，在保持性能的同时提升长上下文场景下的推理效率。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制的二次时间复杂度限制了大语言模型在长上下文场景中的可扩展性；现有混合注意力方法采用静态计算比例，无法适应不同下游任务对稀疏性的敏感性变化。

Method: 提出Elastic Attention，引入轻量级Attention Router，动态为每个注意力头分配不同的计算模式（稀疏或全注意力），并可在预训练模型上快速微调（仅12小时，8xA800 GPU）。

Result: 在三个长上下文基准测试中，于多个主流大语言模型上验证了该方法在性能与推理效率上的优越性。

Conclusion: Elastic Attention实现了输入驱动的动态稀疏控制，在不显著牺牲性能的前提下显著提升了长上下文推理效率，具备良好的实用性与可扩展性。

Abstract: The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.

</details>


### [186] [WarrantScore: Modeling Warrants between Claims and Evidence for Substantiation Evaluation in Peer Reviews](https://arxiv.org/abs/2601.17377)
*Kiyotada Mori,Shohei Tanaka,Tosho Hirasawa,Tadashi Kozuno,Koichiro Yoshino,Yoshitaka Ushiku*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估科学评审意见中主张与证据间逻辑推理质量的指标，以提升评审意见实质性（substantiation）评估的准确性，从而辅助缓解同行评审中的人力资源短缺问题。


<details>
  <summary>Details</summary>
Motivation: 科学同行评审面临投稿量激增导致审稿人资源短缺的问题，亟需利用语言模型降低人工成本；现有评估评审意见实质性水平的方法仅检测证据存在与否，忽略了主张与证据之间的逻辑推理质量。

Method: 提出一种新评估指标，不仅提取评审意见中的主张和证据，还专门建模并评估二者之间的逻辑推理关系，以更准确衡量实质性水平。

Result: 实验表明，该方法与人类评分的相关性高于传统方法。

Conclusion: 所提指标能更准确地评估评审意见的实质性，有望有效提升同行评审效率，为AI辅助评审提供更可靠的评估基础。

Abstract: The scientific peer-review process is facing a shortage of human resources due to the rapid growth in the number of submitted papers. The use of language models to reduce the human cost of peer review has been actively explored as a potential solution to this challenge. A method has been proposed to evaluate the level of substantiation in scientific reviews in a manner that is interpretable by humans. This method extracts the core components of an argument, claims and evidence, and assesses the level of substantiation based on the proportion of claims supported by evidence. The level of substantiation refers to the extent to which claims are based on objective facts. However, when assessing the level of substantiation, simply detecting the presence or absence of supporting evidence for a claim is insufficient; it is also necessary to accurately assess the logical inference between a claim and its evidence. We propose a new evaluation metric for scientific review comments that assesses the logical inference between claims and evidence. Experimental results show that the proposed method achieves a higher correlation with human scores than conventional methods, indicating its potential to better support the efficiency of the peer-review process.

</details>


### [187] [Revisiting Modality Invariance in a Multilingual Speech-Text Model via Neuron-Level Analysis](https://arxiv.org/abs/2601.17387)
*Toshiki Nakai,Varsha Suresh,Vera Demberg*

Main category: cs.CL

TL;DR: 本文研究了多语言语音-文本基础模型（SeamlessM4T v2）中语言与模态（语音/文本）信息的内部表征一致性，发现其编码器虽趋向语言无关，但解码器难以准确恢复源语言，尤其在语音转文本时；跨注意力机制中存在高度局部化的模态选择性结构，且语音条件解码和非主流文字系统表现出更高的神经元激活集中度，导致跨模态与跨语言鲁棒性下降。


<details>
  <summary>Details</summary>
Motivation: 探究多语言语音-文本基础模型是否在语音与文本两种模态下对同一语言保持一致的内部表征。

Method: 在SeamlessM4T v2上开展三项互补分析：1）使用平均精度排序识别语言/模态选择性神经元；2）通过推理时中位数替换干预检验其因果作用；3）分析不同语言与模态下激活幅度的不均衡性（即不平等程度）。

Result: 发现编码器表征随层级加深趋于语言无关，但导致共享解码器难以恢复源语言（尤其语音→文本）；跨注意力层的key/value投影存在强局部化模态选择性；语音条件解码与非主导文字系统激活更集中，表明依赖更少神经元。

Conclusion: 模型未实现完全的模态不变性，模态与语言信息在不同网络模块中呈现非均匀、非对称编码，这可能解释了其跨模态与跨语言任务中的性能退化与脆弱性。

Abstract: Multilingual speech-text foundation models aim to process language uniformly across both modality and language, yet it remains unclear whether they internally represent the same language consistently when it is spoken versus written. We investigate this question in SeamlessM4T v2 through three complementary analyses that probe where language and modality information is encoded, how selective neurons causally influence decoding, and how concentrated this influence is across the network. We identify language- and modality-selective neurons using average-precision ranking, investigate their functional role via median-replacement interventions at inference time, and analyze activation-magnitude inequality across languages and modalities. Across experiments, we find evidence of incomplete modality invariance. Although encoder representations become increasingly language-agnostic, this compression makes it more difficult for the shared decoder to recover the language of origin when constructing modality-agnostic representations, particularly when adapting from speech to text. We further observe sharply localized modality-selective structure in cross-attention key and value projections. Finally, speech-conditioned decoding and non-dominant scripts exhibit higher activation concentration, indicating heavier reliance on a small subset of neurons, which may underlie increased brittleness across modalities and languages.

</details>


### [188] [CLM-Bench: Benchmarking and Analyzing Cross-lingual Misalignment of LLMs in Knowledge Editing](https://arxiv.org/abs/2601.17397)
*Yucheng Hu,Wei Zhou,Juesi Xiao*

Main category: cs.CL

TL;DR: 本文提出了一种文化感知的多语言知识编辑基准CLM-Bench，揭示了现有方法在跨语言知识编辑中存在显著的'跨语言错位'现象，并从表征几何角度解释其成因。


<details>
  <summary>Details</summary>
Motivation: 现有MKE基准依赖机械翻译，引入翻译偏差、忽略目标语言特有文化实体，无法真实反映LLM的多语言知识分布。

Method: 提出以中文为本位的CLM-Bench构建方法，收集1010组根植于中文文化语境的CounterFact编辑对，并与英文对齐；在主流LLM上开展实验，结合层间表征分析揭示中英文编辑向量近似正交。

Result: 发现显著的跨语言错位现象：单语编辑无法跨语言传播；几何分析表明中英文编辑向量几乎正交，位于不同子空间；混合语言编辑具有向量线性可加性。

Conclusion: 当前多语言知识编辑方法在跨语言迁移上效果有限；需采用文化原生的基准来评估和推动真正鲁棒的多语言知识更新能力。

Abstract: Knowledge Editing (KE) has emerged as a promising paradigm for updating facts in Large Language Models (LLMs) without retraining. However, progress in Multilingual Knowledge Editing (MKE) is currently hindered by biased evaluation frameworks. We observe that existing MKE benchmarks are typically constructed by mechanically translating English-centric datasets into target languages (e.g., English-to-Chinese). This approach introduces translation artifacts and neglects culturally specific entities native to the target language, failing to reflect the true knowledge distribution of LLMs. To address this, we propose CLM-Bench, a culture-aware benchmark constructed using a native Chinese-first methodology. We curate 1,010 high-quality CounterFact pairs rooted in Chinese cultural contexts and align them with English counterparts. Using CLM-Bench, we conduct extensive experiments on representative LLMs (e.g., Llama-3, Qwen2) and reveal a significant Cross-lingual Misalignment: edits in one language function independently and fail to propagate to the other. We further provide a geometric explanation via layer-wise representation analysis, demonstrating that edit vectors for Chinese and English are nearly orthogonal -- residing in disjoint subspaces -- while mixed-lingual editing exhibits linear additivity of these vectors. Our findings challenge the effectiveness of current methods in cross-lingual transfer and underscore the importance of culturally native benchmarks.

</details>


### [189] [Oops, Wait: Token-Level Signals as a Lens into LLM Reasoning](https://arxiv.org/abs/2601.17421)
*Jaehui Hwang,Dongyoon Han,Sangdoo Yun,Byeongho Heo*

Main category: cs.CL

TL;DR: 本文系统分析了大语言模型中类似话语的标记（如'wait'和'therefore'）与推理正确性之间的关系，发现这些标记的概率信号在不同训练策略下变化显著，但在不同模型规模下保持稳定。


<details>
  <summary>Details</summary>
Motivation: 尽管话语类标记在大语言模型中被观察到与推理过程相关，但尚缺乏对其如何随训练策略和模型规模变化的系统性分析。

Method: 通过分析多种模型在token-level上的概率信号，研究特定标记（如'wait'）与答案概率及推理正确性的关联，并比较不同训练策略和模型规模下的差异。

Result: 发现特定标记（如'wait'）的概率与推理正确性高度相关；该相关性受训练策略影响明显，但在不同模型规模下保持稳定；小规模数据微调的模型仅部分利用此类信号。

Conclusion: 话语类标记可作为观察和理解大语言模型推理动态的系统性指标，为模型推理能力的分析提供了新视角。

Abstract: The emergence of discourse-like tokens such as "wait" and "therefore" in large language models (LLMs) has offered a unique window into their reasoning processes. However, systematic analyses of how such signals vary across training strategies and model scales remain lacking. In this paper, we analyze token-level signals through token probabilities across various models. We find that specific tokens strongly correlate with reasoning correctness, varying with training strategies while remaining stable across model scales. A closer look at the "wait" token in relation to answer probability demonstrates that models fine-tuned on small-scale datasets acquire reasoning ability through such signals but exploit them only partially. This work provides a systematic lens to observe and understand the dynamics of LLM reasoning.

</details>


### [190] [Clustering-driven Memory Compression for On-device Large Language Models](https://arxiv.org/abs/2601.17443)
*Ondrej Bohdal,Pramit Saha,Umberto Michieli,Mete Ozay,Taha Ceritli*

Main category: cs.CL

TL;DR: 本文提出一种基于聚类的记忆压缩策略，用于在设备端大语言模型中高效利用用户个性化记忆，兼顾上下文长度限制与生成质量。


<details>
  <summary>Details</summary>
Motivation: 设备端大语言模型上下文长度有限，而直接拼接用户记忆或简单平均压缩均存在上下文爆炸或语义冲突问题。

Method: 将用户记忆按语义相似性聚类，在每个簇内进行融合（如加权平均），再将各簇代表向量拼入提示，以减少冗余并保持语义一致性。

Result: 相比直接拼接和朴素平均等基线方法，该方法显著减少记忆token数量，同时提升生成质量；在固定上下文预算下表现更优。

Conclusion: 基于聚类的记忆压缩是一种有效平衡上下文效率与个性化质量的新范式，适用于资源受限的边缘部署场景。

Abstract: Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.

</details>


### [191] [Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes](https://arxiv.org/abs/2601.17530)
*Gautam Siddharth Kashyap,Harsh Joshi,Niharika Jain,Ebad Shabbir,Jiechao Gao,Nipun Joshi,Usman Naseem*

Main category: cs.CL

TL;DR: 本文提出ConLLM框架，结合对比学习与大语言模型，解决现有深度伪造检测方法在多模态泛化性和跨模态语义一致性推理方面的不足，显著提升音频、视频及音视频联合检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法面临模态碎片化（导致跨模态泛化差）和跨模态推理浅层化（难以捕捉细粒度语义不一致）两大核心问题。

Method: 提出ConLLM：第一阶段用预训练模型提取各模态特征；第二阶段通过对比学习对齐多模态嵌入以缓解模态碎片化，并引入大语言模型进行语义级跨模态推理以识别语义不一致。

Result: 在音频、视频、音视频任务上显著提升性能：音频EER最高降低50%，视频准确率最高提升8%，音视频准确率提升约9%；消融实验表明预训练模型特征带来9%-10%稳定增益。

Conclusion: ConLLM通过融合对比学习与LLM驱动的语义推理，有效增强了多模态深度伪造检测的鲁棒性与泛化能力，为应对日益复杂的深度伪造威胁提供了新范式。

Abstract: The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities.

</details>


### [192] [Less is More for RAG: Information Gain Pruning for Generator-Aligned Reranking and Evidence Selection](https://arxiv.org/abs/2601.17532)
*Zhipeng Song,Yizhi Zhou,Xiangyu Kong,Jiulong Jiao,Xinrui Bao,Xu You,Xueqing Shi,Yuhang Zhou,Heng Qi*

Main category: cs.CL

TL;DR: 本文提出了一种名为信息增益剪枝（IGP）的方法，用于在检索增强生成（RAG）中更有效地选择外部证据，以提升问答质量并降低输入token开销。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法中，检索相关性指标（如NDCG）与端到端问答质量弱相关甚至负相关，尤其在多段证据注入时因冗余和轻微冲突导致生成不稳定。

Method: 提出信息增益剪枝（IGP），一种部署友好的重排序与剪枝模块，利用生成器对齐的效用信号选择证据，并在截断前过滤弱或有害段落，不改变原有预算接口。

Result: 在五个开放域问答基准、多种检索器与生成器组合下，IGP持续改善质量-成本权衡；典型多证据场景下，平均F1相对提升12–20%，最终阶段输入token减少76–79%。

Conclusion: IGP是一种轻量、通用且高效的方法，能显著提升RAG系统在有限上下文预算下的实际性能。

Abstract: Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.

</details>


### [193] [Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations](https://arxiv.org/abs/2601.17569)
*Alireza Salemi,Hamed Zamani*

Main category: cs.CL

TL;DR: P^3是一种交互式个性化框架，通过服务器端大模型生成草稿、客户端小模型基于私有用户资料进行修正，实现高质量个性化生成，同时保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 现有个性化方法面临隐私泄露（将用户私有资料暴露给云服务）与性能下降（依赖能力较弱的本地模型）之间的权衡。

Method: P^3采用协同解码机制：服务器端大模型仅基于用户查询生成k个草稿token；客户端小模型（可访问用户私有资料）评估并修改这些草稿，循环直至生成结束符。

Result: 在LaMP-QA基准上，P^3显著优于非个性化服务器端和个性化客户端基线，平均提升7.4%–9%；恢复了90.3%–95.7%的‘泄露’上界性能；隐私分析显示仅引入1.5%–3.5%额外信息泄露；客户端仅生成9.2%总token，适合边缘部署。

Conclusion: P^3在保障用户隐私前提下实现了高效、高质量的LLM个性化生成，是兼顾实用性与隐私性的可行方案。

Abstract: Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.

</details>


### [194] [Self-Manager: Parallel Agent Loop for Long-form Deep Research](https://arxiv.org/abs/2601.17879)
*Yilong Xu,Zhi Zheng,Xiang Long,Yujun Cai,Yiwei Wang*

Main category: cs.CL

TL;DR: 本文提出Self-Manager，一种支持异步并发执行的并行智能体循环架构，通过为每个子线程分配独立上下文和线程控制块，解决传统单上下文、顺序执行范式导致的干扰与阻塞问题，在深度研究任务中显著提升可扩展性、灵活性与性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体在处理长周期深度研究任务时，虽采用子任务级上下文管理，但仍受限于单一上下文窗口和顺序执行范式，导致线程间相互干扰、阻塞，制约可扩展性与适应性。

Method: 提出Self-Manager：一种并行智能体循环机制，主线索引多个具有隔离上下文的子线程，并通过Thread Control Blocks进行迭代式协调与管理，实现异步并发执行。

Result: 在DeepResearch Bench基准上，Self-Manager在所有指标上均持续超越单智能体循环基线；分析实验验证了其设计必要性，并展现出更强的上下文容量、执行效率与泛化能力。

Conclusion: Self-Manager通过解耦上下文与执行流，为复杂长周期AI研究任务提供了更鲁棒、可扩展的智能体架构范式。

Abstract: Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.

</details>


### [195] [Sequence Repetition Enhances Token Embeddings and Improves Sequence Labeling with Decoder-only Language Models](https://arxiv.org/abs/2601.17585)
*Matija Luka Kukić,Marko Čuljak,David Dukić,Martin Tutek,Jan Šnajder*

Main category: cs.CL

TL;DR: 本文提出序列重复（SR）方法，使解码器-only语言模型具备双向上下文能力，从而更高效地应用于序列标注任务，且无需修改模型结构。


<details>
  <summary>Details</summary>
Motivation: 现代自回归语言模型（LMs）仅依赖前缀进行预测，而序列标注（SL）任务需要双向上下文；传统上SL依赖编码器-only模型，但decoder-only模型发展迅速，亟需适配SL的轻量级方案。

Method: 提出序列重复（SR）策略，在输入中重复序列以隐式引入双向信息；通过微调实验验证其对token-level嵌入质量的提升，并分析不同重复次数及中间层嵌入的效果。

Result: SR显著提升decoder-only模型在SL任务上的性能，超越标准encoder和unmasked decoder；增加重复次数不损害性能；中间层嵌入效果接近最终层但计算更高效。

Conclusion: SR是一种低侵入、高效的双向性增强方法，可缓解decoder-only模型的结构限制，拓展其在各类token-level任务中的适用性。

Abstract: Modern language models (LMs) are trained in an autoregressive manner, conditioned only on the prefix. In contrast, sequence labeling (SL) tasks assign labels to each individual input token, naturally benefiting from bidirectional context. This discrepancy has historically led SL to rely on inherently bidirectional encoder-only models. However, the rapid development of decoder-only models has raised the question of whether they can be adapted to SL. While causal mask removal has emerged as a viable technique for adapting decoder-only models to leverage the full context for SL, it requires considerable changes to the base model functionality. In this work, we explore sequence repetition (SR) as a less invasive alternative for enabling bidirectionality in decoder-only models. Through fine-tuning experiments, we show that SR inherently makes decoders bidirectional, improving the quality of token-level embeddings and surpassing encoders and unmasked decoders. Contrary to earlier claims, we find that increasing the number of repetitions does not degrade SL performance. Finally, we demonstrate that embeddings from intermediate layers are highly effective for SR, comparable to those from final layers, while being significantly more efficient to compute. Our findings underscore that SR alleviates the structural limitations of decoders, enabling more efficient and adaptable LMs and broadening their applicability to other token-level tasks.

</details>


### [196] [From Chains to DAGs: Probing the Graph Structure of Reasoning in LLMs](https://arxiv.org/abs/2601.17593)
*Tianjun Zhong,Linyang He,Nima Mesgarani*

Main category: cs.CL

TL;DR: 本文提出Reasoning DAG Probing框架，探究大语言模型内部是否线性可解码地表征有向无环图（DAG）形式的多步推理结构，发现中间层隐状态确实编码了可探测的DAG几何结构，且其可恢复性随节点深度和模型规模系统性变化。


<details>
  <summary>Details</summary>
Motivation: 现有研究多将推理视为线性链式过程，但许多实际推理问题天然具有图结构（如前提共享、并行推导、结果复用），尚不清楚大模型内部是否反映此类图结构。

Method: 提出Reasoning DAG Probing框架：为每个推理节点赋予文本实现，训练轻量探针从各层隐状态中预测节点深度与节点间距离两类图论属性，并通过控制实验验证结构特异性。

Result: 实证表明，LLM中间层隐状态中存在可被线性探针识别的DAG几何结构；该结构的可恢复性随节点深度增加而下降，并随模型规模增大而提升。

Conclusion: 大语言模型的推理机制不仅具有序列性，还内在具备可测量的图结构表征能力，支持更丰富的非线性推理建模。

Abstract: Recent progress in large language models has renewed interest in mechanistically characterizing how multi-step reasoning is represented and computed. While much prior work treats reasoning as a linear chain of steps, many reasoning problems are more naturally structured as directed acyclic graphs (DAGs), where intermediate conclusions may depend on multiple premises, branch into parallel sub-derivations, and later merge or be reused. Understanding whether such graph-structured reasoning is reflected in model internals remains an open question.
  In this work, we introduce Reasoning DAG Probing, a framework that directly asks whether LLM hidden states encode the geometry of a reasoning DAG in a linearly accessible form, and where this structure emerges across layers. Within this framework, we associate each reasoning node with a textual realization and train lightweight probes to predict two graph-theoretic properties from hidden states: node depth and pairwise node distance. We use these probes to analyze the layerwise emergence of DAG structure and evaluate controls that disrupt reasoning-relevant structure while preserving superficial textual properties. Our results provide evidence that reasoning DAG geometry is meaningfully encoded in intermediate layers, with recoverability varying systematically by node depth and model scale, suggesting that LLM reasoning is not only sequential but exhibits measurable internal graph structure.

</details>


### [197] [Corpus-Based Approaches to Igbo Diacritic Restoration](https://arxiv.org/abs/2601.18380)
*Ignatius Ezeani*

Main category: cs.CL

TL;DR: 本文针对低资源语言Igbo的变音符号消歧问题，提出了一种灵活的数据集生成框架，并比较了n-gram模型、分类模型和嵌入模型三种方法在变音符号恢复任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自然语言处理研究多集中于高资源语言，而全球95%以上的语言属于低资源语言，缺乏数据、工具和技术支持；Igbo作为典型低资源语言，其变音符号歧义问题亟需有效解决方案。

Method: 构建了用于变音符号恢复的数据集生成框架；提出了三种方法：基于上下文词序列的标准n-gram模型、利用目标词左右窗口的分类模型、以及通过计算上下文与候选变体词向量相似度的嵌入模型。

Result: 实现了针对Igbo语的变音符号恢复框架，并对三种模型在该任务上的有效性进行了实验评估与比较。

Conclusion: 该研究为低资源语言的变音符号处理提供了可扩展的方法框架，验证了不同建模策略在资源受限场景下的适用性与潜力。

Abstract: With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.
  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.

</details>


### [198] [Learning to Ideate for Machine Learning Engineering Agents](https://arxiv.org/abs/2601.17596)
*Yunxiang Zhang,Kang Zhou,Zhichao Xu,Kiran Ramnath,Yun Zhou,Sangmin Woo,Haibo Ding,Lin Lee Cheong*

Main category: cs.CL

TL;DR: 本文提出MLE-Ideator双智能体框架，将算法构想与实现分离，显著提升机器学习工程（MLE）任务性能，并通过强化学习训练Ideator，在少量样本下实现显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习工程（MLE）智能体难以迭代优化算法有效性，需分离构想与实现以提升策略性能力。

Method: 提出MLE-Ideator双智能体框架：一个实现智能体可向专用Ideator智能体请求战略建议；Ideator可通过无训练方式直接使用，也可用强化学习（RL）在1K样本上微调（如Qwen3-8B）。

Result: 在MLE-Bench上，无训练版显著优于纯实现智能体；RL训练后的Qwen3-8B Ideator相较未训练版本提升11.5%相对性能，并超越Claude Sonnet 3.5。

Conclusion: 分离构想与实现的双智能体范式，结合小样本强化学习，为构建面向科学发现的战略型AI系统提供了可行路径。

Abstract: Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.

</details>


### [199] [Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory](https://arxiv.org/abs/2601.18771)
*Yanming Liu,Xinyue Peng,Zixuan Yan,Yanxin Shen,Wenjie Xu,Yuefeng Huang,Xinyi Wang,Jiannan Cao,Jianwei Yin,Xuhong Zhang*

Main category: cs.CL

TL;DR: 本文提出Dep-Search框架，通过引入依赖感知的结构化搜索、检索与持久化记忆机制，显著提升大语言模型在多跳推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于搜索的推理框架过度依赖隐式自然语言推理来决定搜索策略和信息利用方式，导致子问题依赖管理困难、知识复用低效、强化学习难以优化搜索策略。

Method: 提出Dep-Search框架，结合结构化推理、显式控制机制（问题分解、按需检索、记忆访问与摘要）、GRPO（一种强化学习算法）及持久化记忆，实现对依赖关系建模与知识高效复用。

Result: 在七个多样化问答数据集上实验表明，Dep-Search在不同规模大语言模型上均显著超越强基线，尤其在复杂多跳推理任务中性能提升明显。

Conclusion: Dep-Search通过显式建模依赖关系与整合结构化推理、检索与记忆，为搜索增强型推理提供了更可控、可学习、可复用的新范式。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.

</details>


### [200] [What Language Models Know But Don't Say: Non-Generative Prior Extraction for Generalization](https://arxiv.org/abs/2601.17609)
*Sara Rezaeimanesh,Mohammad M. Ghassemi*

Main category: cs.CL

TL;DR: 本文提出LoID方法，通过直接提取大语言模型（LLM）在词元级预测中对正负语义方向的置信度差异，构建信息性先验分布，用于小样本、分布外（OOD）场景下的贝叶斯逻辑回归，显著提升AUC性能。


<details>
  <summary>Details</summary>
Motivation: 在医疗和金融等领域，大规模标注数据昂贵且稀缺，导致模型在小数据集上训练后泛化能力差；而大语言模型蕴含大量领域知识，但如何可靠、高效地将其转化为统计建模中的先验知识仍具挑战。

Method: LoID（Logit-Informed Distributions）是一种确定性方法：通过构造正反语义方向的提示句，探测LLM对每个特征影响方向（如正/负效应）在不同表述下的logit输出一致性，从而量化其信念强度与可靠性，并据此生成逻辑回归的先验分布。

Result: 在10个真实表格数据集及合成协变量偏移OOD设置下，LoID相较无信息先验显著提升AUC，最多填补59%的Oracle性能差距；在8/10数据集上优于AutoElicit和LLMProcesses，且具备可复现性与计算高效性。

Conclusion: LoID为将LLM隐含知识转化为结构化、可解释、可计算的贝叶斯先验提供了新范式，尤其适用于小样本、分布偏移的关键领域建模任务。

Abstract: In domains like medicine and finance, large-scale labeled data is costly and often unavailable, leading to models trained on small datasets that struggle to generalize to real-world populations. Large language models contain extensive knowledge from years of research across these domains. We propose LoID (Logit-Informed Distributions), a deterministic method for extracting informative prior distributions for Bayesian logistic regression by directly accessing their token-level predictions. Rather than relying on generated text, we probe the model's confidence in opposing semantic directions (positive vs. negative impact) through carefully constructed sentences. By measuring how consistently the LLM favors one direction across diverse phrasings, we extract the strength and reliability of the model's belief about each feature's influence. We evaluate LoID on ten real-world tabular datasets under synthetic out-of-distribution (OOD) settings characterized by covariate shift, where the training data represents only a subset of the population. We compare our approach against (1) standard uninformative priors, (2) AutoElicit, a recent method that prompts LLMs to generate priors via text completions, (3) LLMProcesses, a method that uses LLMs to generate numerical predictions through in-context learning and (4) an oracle-style upper bound derived from fitting logistic regression on the full dataset. We assess performance using Area Under the Curve (AUC). Across datasets, LoID significantly improves performance over logistic regression trained on OOD data, recovering up to \textbf{59\%} of the performance gap relative to the oracle model. LoID outperforms AutoElicit and LLMProcessesc on 8 out of 10 datasets, while providing a reproducible and computationally efficient mechanism for integrating LLM knowledge into Bayesian inference.

</details>


### [201] [Beyond the Rabbit Hole: Mapping the Relational Harms of QAnon Radicalization](https://arxiv.org/abs/2601.17658)
*Bich Ngoc,Doan,Giuseppe Russo,Gianmarco De Francisci Morales,Robert West*

Main category: cs.CL

TL;DR: 本研究通过混合方法分析QAnon支持社区的叙事，识别出六种激进化人格类型，并揭示其与亲人情感伤害之间的关联，首次将激进化视为一种关系现象。


<details>
  <summary>Details</summary>
Motivation: 现有大规模计算研究忽视了阴谋论信徒亲友所承受的个人情感代价，本研究旨在填补这一空白。

Method: 采用BERTopic进行主题建模以描绘激进化轨迹；用LDA图形模型识别六种‘激进化人格’；结合大语言模型辅助的情绪检测与回归建模，关联人格类型与叙述者报告的情感影响。

Result: 发现六种可复现的激进化人格类型，且不同类型显著预测叙述者不同情绪反应：被视为主动意识形态选择的激进化引发愤怒与厌恶，而伴随个人与认知崩溃的激进化则引发恐惧与悲伤。

Conclusion: 激进化不仅是个体转变过程，更是一种关系现象；本研究为理解其人际后果提供了首个实证框架，对研究者与实践者具有重要指导意义。

Abstract: The rise of conspiracy theories has created far-reaching societal harm in the public discourse by eroding trust and fueling polarization. Beyond this public impact lies a deeply personal toll on the friends and families of conspiracy believers, a dimension often overlooked in large-scale computational research. This study fills this gap by systematically mapping radicalization journeys and quantifying the associated emotional toll inflicted on loved ones. We use the prominent case of QAnon as a case study, analyzing 12747 narratives from the r/QAnonCasualties support community through a novel mixed-methods approach. First, we use topic modeling (BERTopic) to map the radicalization trajectories, identifying key pre-existing conditions, triggers, and post-radicalization characteristics. From this, we apply an LDA-based graphical model to uncover six recurring archetypes of QAnon adherents, which we term "radicalization personas." Finally, using LLM-assisted emotion detection and regression modeling, we link these personas to the specific emotional toll reported by narrators. Our findings reveal that these personas are not just descriptive; they are powerful predictors of the specific emotional harms experienced by narrators. Radicalization perceived as a deliberate ideological choice is associated with narrator anger and disgust, while those marked by personal and cognitive collapse are linked to fear and sadness. This work provides the first empirical framework for understanding radicalization as a relational phenomenon, offering a vital roadmap for researchers and practitioners to navigate its interpersonal fallout.

</details>


### [202] [UrduLM: A Resource-Efficient Monolingual Urdu Language Model](https://arxiv.org/abs/2601.17664)
*Syed Muhammad Ali,Hammad Sajid,Zainab Haider,Ali Muhammad Asad,Haya Fatima,Abdul Samad*

Main category: cs.CL

TL;DR: 本文提出了UrduLM，一个专为乌尔都语设计的单语语言模型，通过构建33GB的乌尔都语语料库、定制BPE分词器，并在低资源条件下预训练了一个1亿参数的解码器模型，在多项任务中展现出优于大得多的多语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语缺乏专用的基于Transformer的语言模型和高质量语料库，现有多语言模型在乌尔都语上表现差、计算成本高且存在文化偏差。

Method: 构建了33GB的多样化乌尔都语语料库；设计了比多语言分词器减少20-30%开销的定制BPE分词器；预训练了一个1亿参数的解码器-only模型。

Result: 在少样本评估中，UrduLM在情感分类任务上达到66.6%准确率，在语法纠错任务上BLEU得分超30，性能媲美体积达其30倍的多语言模型。

Conclusion: UrduLM为乌尔都语NLP研究建立了新基线，并为其他代表性不足的语言提供了可扩展的建模框架；所有资源（语料、分词器、模型权重、评测基准）均已开源。

Abstract: Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.

</details>


### [203] [Align to the Pivot: Dual Alignment with Self-Feedback for Multilingual Math Reasoning](https://arxiv.org/abs/2601.17671)
*Chunxu Zhao,Xin Huang,Xue Han,Shujian Huang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 本文提出PASMR方法，通过以主语言为枢纽，将多语言数学问题翻译成枢纽语言进行推理，并利用枢纽语言的推理答案监督目标语言的推理过程，从而提升大语言模型在多语言场景下的数学推理能力，无需外部标注或奖励模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言场景下（尤其是低资源语言）表现下降，原因是其多语言理解与推理对齐不一致。

Method: 提出Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR)：以模型主语言为pivot language，训练时先将问题翻译为pivot语言以对齐推理模式，再用pivot语言的推理答案监督目标语言的推理过程，构建跨语言自反馈机制。

Result: 实验表明该方法显著提升了模型对多语言问题的理解与推理能力，在多项任务上取得明显改进。

Conclusion: PASMR能有效增强大语言模型的多语言数学推理对齐能力，是一种无需外部标注或奖励模型的轻量高效方法。

Abstract: Despite the impressive reasoning abilities demonstrated by large language models (LLMs), empirical evidence indicates that they are not language agnostic as expected, leading to performance declines in multilingual settings, especially for low-resource languages. We attribute the decline to the model's inconsistent multilingual understanding and reasoning alignment. To address this, we present Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR), aiming to improve the alignment of multilingual math reasoning abilities in LLMs. This approach designates the model's primary language as the pivot language. During training, the model first translates questions into the pivot language to facilitate better alignment of reasoning patterns. The reasoning process in the target language is then supervised by the pivot language's reasoning answers, thereby establishing a cross-lingual self-feedback mechanism without relying on external correct answers or reward models. Extensive experimental results demonstrate that our method enhances both the model's understanding of questions and its reasoning capabilities, leading to notable task improvements.

</details>


### [204] [S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference](https://arxiv.org/abs/2601.17702)
*Qingsen Ma,Dianyun Wang,Yaoye Wang,Lechen Ning,Sujie Zhu,Xiaohang Zhang,Jiaming Lyu,Linhao Ren,Zhenbo Xu,Zhaofeng He*

Main category: cs.CL

TL;DR: 本文提出S3-Attention，一种内存优先的推理时框架，通过稀疏自编码器和CPU倒排索引实现长上下文注意力对齐的内生检索，显著降低GPU内存占用，同时在LongBench评测中接近全上下文性能。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文推理方法存在KV缓存内存开销大、外部检索易引入无关内容等问题，亟需更高效、更相关的信息提取机制。

Method: S3-Attention利用轻量稀疏自编码器将键/查询投影为top-k稀疏特征标识符，并在单次流式扫描中构建CPU倒排索引；生成时基于特征共激活检索紧凑证据片段，可选融合BM25提升精确匹配。

Result: 在统一LongBench协议下，S3-Hybrid在多个模型家族上接近全上下文推理性能，在信息密集场景中鲁棒性更强；但当前原型存在墙钟延迟高于优化全KV基线的工程局限。

Conclusion: S3-Attention验证了注意力对齐的内生检索路径可行性，为长上下文高效推理提供了新范式，后续需底层kernel优化以降低延迟。

Abstract: Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.
  We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.
  At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.

</details>


### [205] [Distance-to-Distance Ratio: A Similarity Measure for Sentences Based on Rate of Change in LLM Embeddings](https://arxiv.org/abs/2601.17705)
*Abdullah Qureshi,Kenneth Rice,Alexander Wolpert*

Main category: cs.CL

TL;DR: 本文提出了一种新的文本嵌入相似性度量方法——距离-距离比（DDR），它基于Lipschitz连续性思想，衡量上下文对语义的影响，并在受控扰动实验中展现出比现有指标更强的语义区分能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入相似性度量需符合人类对文本相似性的感知，但缺乏对上下文语义影响的显式建模。

Method: 提出距离-距离比（DDR）度量，通过比较上下文前后的词嵌入距离变化率来量化上下文的语义影响；在句子数据集上设计单词替换扰动实验（同义词/随机词，替换1-3个词），评估DDR性能。

Result: DDR在各类扰动下均能更精细地区分语义相似与不相似文本，优于现有主流相似性度量。

Conclusion: DDR是一种更符合人类语义直觉、对上下文敏感且鲁棒的嵌入相似性度量方法。

Abstract: A measure of similarity between text embeddings can be considered adequate only if it adheres to the human perception of similarity between texts. In this paper, we introduce the distance-to-distance ratio (DDR), a novel measure of similarity between LLM sentence embeddings. Inspired by Lipschitz continuity, DDR measures the rate of change in similarity between the pre-context word embeddings and the similarity between post-context LLM embeddings, thus measuring the semantic influence of context. We evaluate the performance of DDR in experiments designed as a series of perturbations applied to sentences drawn from a sentence dataset. For each sentence, we generate variants by replacing one, two, or three words with either synonyms, which constitute semantically similar text, or randomly chosen words, which constitute semantically dissimilar text. We compare the performance of DDR with other prevailing similarity metrics and demonstrate that DDR consistently provides finer discrimination between semantically similar and dissimilar texts, even under minimal, controlled edits.

</details>


### [206] [A Computational Approach to Visual Metonymy](https://arxiv.org/abs/2601.17706)
*Saptarshi Ghosh,Linfeng Liu,Tianyu Jiang*

Main category: cs.CL

TL;DR: 本文首次对视觉转喻进行计算研究，提出基于符号学理论的生成框架，并构建首个视觉转喻数据集ViMET，用于评估多模态模型对间接视觉指代的理解能力。


<details>
  <summary>Details</summary>
Motivation: 视觉图像常通过关联线索（而非直接描绘）传达深层概念（即视觉转喻），但现有模型缺乏对此类间接视觉指代的理解能力，亟需系统性研究与评测基准。

Method: 基于符号学理论，结合大语言模型与文生图模型构建生成管道，生成具有转喻意义的图像，并设计包含2000道多选题的ViMET数据集，用于评估多模态模型的认知推理能力。

Result: 在ViMET数据集上，人类准确率为86.9%，而当前最优视觉-语言模型仅为65.9%，揭示了模型在理解视觉转喻方面存在显著差距。

Conclusion: 视觉转喻是多模态理解中的关键认知能力，ViMET为评估和提升模型的间接视觉推理能力提供了新基准和研究方向。

Abstract: Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.

</details>


### [207] [Unsupervised Elicitation of Moral Values from Language Models](https://arxiv.org/abs/2601.17728)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei*

Main category: cs.CL

TL;DR: 本文提出了一种无需人工标注的内部一致性最大化（ICM）算法，用于从预训练语言模型中无监督地激发其内在道德推理能力，在多个道德基准上超越现有基线，并显著缓解社会偏见。


<details>
  <summary>Details</summary>
Motivation: 由于构建道德评估的真值数据困难（存在多元道德框架和普遍偏见），需探索不依赖人工标注的道德能力激发方法。

Method: 采用内部一致性最大化（ICM）算法，在三个基准数据集和四种语言模型上进行无监督道德判断标注，并评估其跨框架泛化性与偏见缓解效果。

Result: ICM在Norm Bank和ETHICS基准上优于所有预训练及对话模型基线；基于ICM标签微调的效果媲美甚至超过人工标签；在正义与常识道德框架上提升最显著；将种族、社会经济地位和政治相关偏见错误率降低一半以上。

Conclusion: 预训练语言模型具备潜在的道德推理能力，可通过ICM等无监督方法有效激发，为AI对齐提供可扩展的新路径。

Abstract: As AI systems become pervasive, grounding their behavior in human values is critical. Prior work suggests that language models (LMs) exhibit limited inherent moral reasoning, leading to calls for explicit moral teaching. However, constructing ground truth data for moral evaluation is difficult given plural frameworks and pervasive biases. We investigate unsupervised elicitation as an alternative, asking whether pretrained (base) LMs possess intrinsic moral reasoning capability that can be surfaced without human supervision. Using the Internal Coherence Maximization (ICM) algorithm across three benchmark datasets and four LMs, we test whether ICM can reliably label moral judgments, generalize across moral frameworks, and mitigate social bias. Results show that ICM outperforms all pre-trained and chatbot baselines on the Norm Bank and ETHICS benchmarks, while fine-tuning on ICM labels performs on par with or surpasses those of human labels. Across theoretically motivated moral frameworks, ICM yields its largest relative gains on Justice and Commonsense morality. Furthermore, although chatbot LMs exhibit social bias failure rates comparable to their pretrained ones, ICM reduces such errors by more than half, with the largest improvements in race, socioeconomic status, and politics. These findings suggest that pretrained LMs possess latent moral reasoning capacities that can be elicited through unsupervised methods like ICM, providing a scalable path for AI alignment.

</details>


### [208] [Hylog: A Hybrid Approach to Logging Text Production in Non-alphabetic Scripts](https://arxiv.org/abs/2601.17753)
*Roberto Crotti,Giovanni Denaro,Zhiqiang Du,Ricardo Muñoz Martín*

Main category: cs.CL

TL;DR: 本文提出了Hylog，一种结合分析型键记录和生态文本记录的混合日志系统，用于更完整、更精细地分析非字母文字（如简体中文）通过输入法编辑器（IME）输入时的屏幕变换过程。


<details>
  <summary>Details</summary>
Motivation: 现有研究型键盘记录器大多无法捕捉非字母文字输入法编辑器（IME）引起的屏幕变换，存在方法学上的空白。

Method: 开发了模块化、开源的Hylog混合日志系统，通过插件支持主流应用（如Word、Chrome），同步记录键盘输出与渲染文本，生成双轨迹；并开展概念验证实验，由两名志愿者进行中英翻译任务。

Result: Hylog成功捕获了拉丁字母、汉字及IME确认之间的按键与时间间隔，部分数据传统键记录器无法获取；所获数据支持提出关于IME辅助打字中不同语言层级认知限制与可用性的新假设。

Conclusion: Hylog填补了多语种文本产出研究的方法空白，其插件架构可扩展至其他IME系统，推动更具包容性的跨语言文本生成认知研究。

Abstract: Research keyloggers are essential for cognitive studies of text production, yet most fail to capture the on-screen transformations performed by Input Method Editors (IMEs) for non-alphabetic scripts. To address this methodological gap, we present Hylog, a novel hybrid logging system that combines analytical keylogging with ecological text logging for a more complete and finer-grained analysis. Our modular, open-source system uses plug-ins for standard applications (Microsoft Word, Google Chrome) to capture both keyboard output and rendered text, which a hybridizer module then synchronizes into a dual trace. To validate the system's technical feasibility and demonstrate its analytical capabilities, we conducted a proof-of-concept study where two volunteers translated a text into simplified Chinese. Hylog successfully captured keypresses and temporal intervals between Latin letters, Chinese characters, and IME confirmations -- some measurements invisible to traditional keyloggers. The resulting data enable the formulation of new, testable hypotheses about the cognitive restrictions and affordances at different linguistic layers in IME-mediated typing. Our plug-in architecture enables extension to other IME systems and fosters more inclusive multilingual text-production research.

</details>


### [209] [ProGraph-R1: Progress-aware Reinforcement Learning for Graph Retrieval Augmented Generation](https://arxiv.org/abs/2601.17755)
*Jinyoung Park,Sanghyeok Lee,Omar Zia Khan,Hyunwoo J. Kim,Joo-Kyung Kim*

Main category: cs.CL

TL;DR: 本文提出ProGraph-R1，一种面向图检索与多步推理的进展感知型智能体框架，通过结构感知的超图检索机制和基于进展的逐步策略优化，克服了现有RL驱动GraphRAG方法在图结构利用不足和奖励稀疏方面的缺陷，显著提升了多跳问答的推理准确率与生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的GraphRAG方法（如Graph-R1）存在两个关键问题：一是仅依赖语义相似性进行检索，忽略知识图谱的拓扑结构；二是使用稀疏的结果级奖励，无法评估和优化中间检索步骤的质量及其依赖关系。

Method: 提出ProGraph-R1框架，包含两部分核心方法：（1）结构感知的超图检索机制，联合建模语义相关性与图连通性，支持连贯的多跳路径遍历；（2）进展驱动的逐步策略优化，通过在图内量化中间推理进展来提供稠密的学习信号，替代仅依赖最终结果的稀疏奖励。

Result: 在多跳问答基准测试中，ProGraph-R1在推理准确率和生成质量上持续优于现有GraphRAG方法。

Conclusion: ProGraph-R1通过融合图结构信息与细粒度进展反馈，有效提升了LLM在知识图谱上的多步推理能力，为构建更鲁棒、可解释的图增强生成系统提供了新范式。

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has been successfully applied in various knowledge-intensive question answering tasks by organizing external knowledge into structured graphs of entities and relations. It enables large language models (LLMs) to perform complex reasoning beyond text-chunk retrieval. Recent works have employed reinforcement learning (RL) to train agentic GraphRAG frameworks that perform iterative interactions between LLMs and knowledge graphs. However, existing RL-based frameworks such as Graph-R1 suffer from two key limitations: (1) they primarily depend on semantic similarity for retrieval, often overlooking the underlying graph structure, and (2) they rely on sparse, outcome-level rewards, failing to capture the quality of intermediate retrieval steps and their dependencies. To address these limitations, we propose ProGraph-R1, a progress-aware agentic framework for graph-based retrieval and multi-step reasoning. ProGraph-R1 introduces a structure-aware hypergraph retrieval mechanism that jointly considers semantic relevance and graph connectivity, encouraging coherent traversal along multi-hop reasoning paths. We also design a progress-based step-wise policy optimization, which provides dense learning signals by modulating advantages according to intermediate reasoning progress within a graph, rather than relying solely on final outcomes. Experiments on multi-hop question answering benchmarks demonstrate that ProGraph-R1 consistently improves reasoning accuracy and generation quality over existing GraphRAG methods.

</details>


### [210] [Cross-Lingual Probing and Community-Grounded Analysis of Gender Bias in Low-Resource Bengali](https://arxiv.org/abs/2601.17764)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Jui Saha Pritha,Abdullah Al Noman,Abir Ahmed,Golam Md Mohiuddin,Tze Hui Liew*

Main category: cs.CL

TL;DR: 本文研究了孟加拉语中大型语言模型（LLMs）的性别偏见问题，指出英语中心的偏见检测框架在孟加拉语中效果受限，需结合语言文化特性与社区驱动方法进行本地化、情境敏感的偏见识别与缓解。


<details>
  <summary>Details</summary>
Motivation: 当前关于大模型性别偏见的研究主要集中于英语，而全球南方语言（如孟加拉语）中的语言与文化偏见未被充分考察；亟需针对低资源、高文化特异性语言开展本土化偏见研究。

Method: 采用词典挖掘、计算分类模型、翻译对比分析和GPT生成偏见语句等多种方法提取性别偏见表达，并在农村及低收入地区开展两次实地调研以获取真实语境下的偏见认知。

Result: 发现孟加拉语中的性别偏见具有不同于英语的独特特征；英语主导的偏见检测框架因语言差异与社会文化因素而严重受限；社区驱动方法能有效识别自动化系统易忽略的文化相关偏见。

Conclusion: 应为孟加拉语等代表性不足的语言专门构建语言工具与评估框架，推动更包容、公平的NLP系统发展，并为其他印度语系语言的偏见研究奠定基础。

Abstract: Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.

</details>


### [211] [DPI: Exploiting Parameter Heterogeneity for Interference-Free Fine-Tuning](https://arxiv.org/abs/2601.17777)
*Xiaoyu Liu,Xiaoyu Guan,Di Liang,Xianjie Wu*

Main category: cs.CL

TL;DR: 本文提出一种动态参数隔离策略，通过识别各SFT任务的核心参数区域并分阶段冻结，缓解多任务微调中的‘跷跷板效应’，显著提升模型在异构任务上的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 解决监督微调（SFT）中因任务目标冲突导致的‘跷跷板效应’，即优化一个任务会损害其他任务性能的问题，根源在于参数更新缺乏任务针对性。

Method: 首先对不同SFT任务独立微调，识别各自最大参数更新子集作为核心参数区域；依据核心区域重叠度对任务聚类或分阶段；多阶段微调中冻结前序任务的核心参数，避免干扰。

Result: 在多个公开数据集上实验表明，该方法显著降低数据冲突，性能持续优于多阶段和多任务联合微调基线。

Conclusion: 参数异质性是跨任务干扰的关键原因，显式建模并隔离任务特定核心参数区域可有效提升多任务SFT的稳定性与性能。

Abstract: Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the "seesaw effect": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.

</details>


### [212] [Controlling Reading Ease with Gaze-Guided Text Generation](https://arxiv.org/abs/2601.17781)
*Andreas Säuberli,Darja Jepifanova,Diego Frassinelli,Barbara Plank*

Main category: cs.CL

TL;DR: 本文提出了一种利用眼动预测模型引导语言模型生成具有可控阅读难度文本的方法，并通过眼动实验验证了其在调节阅读时间和主观难度上的有效性，主要影响词汇加工层面。


<details>
  <summary>Details</summary>
Motivation: 利用阅读时的眼动模式反映认知负荷，从而生成具有可控阅读难度的文本，以提升信息可及性和个性化语言学习材料生成。

Method: 采用预测人类凝视模式的模型来引导语言模型输出，使其诱发特定的阅读行为（如更短或更长的注视时间）。

Result: 眼动实验表明该方法能有效调控文本的阅读难度（客观阅读时间与主观难度评估均显著变化），统计分析显示效果主要源于影响词汇加工的文本特征。

Conclusion: 基于眼动建模的文本生成方法可行且有效，适用于文本简化和个性化教育材料生成等实际场景。

Abstract: The way our eyes move while reading can tell us about the cognitive effort required to process the text. In the present study, we use this fact to generate texts with controllable reading ease. Our method employs a model that predicts human gaze patterns to steer language model outputs towards eliciting certain reading behaviors. We evaluate the approach in an eye-tracking experiment with native and non-native speakers of English. The results demonstrate that the method is effective at making the generated texts easier or harder to read, measured both in terms of reading times and perceived difficulty of the texts. A statistical analysis reveals that the changes in reading behavior are mostly due to features that affect lexical processing. Possible applications of our approach include text simplification for information accessibility and generation of personalized educational material for language learning.

</details>


### [213] [Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations](https://arxiv.org/abs/2601.17786)
*Yixin Liu,Kehan Yan,Shiyuan Li,Qingfeng Chen,Shirui Pan*

Main category: cs.CL

TL;DR: 本文提出MCA²框架，通过多视角嵌入融合、对比协作模块和自适应权重分配，提升文本异常检测在多样数据集和异常类型上的鲁棒性与适应性。


<details>
  <summary>Details</summary>
Motivation: 现有两步式文本异常检测方法受限于单一嵌入模型及跨数据集/异常类型的适应性差。

Method: 提出MCA²多视图TAD框架：融合多个预训练语言模型的嵌入，采用多视图重建模型提取正常文本模式；设计对比协作模块增强视图间互补性；引入自适应分配模块动态加权各视图贡献。

Result: 在10个基准数据集上显著优于强基线方法。

Conclusion: MCA²通过多视图协同与自适应机制，有效提升了文本异常检测的泛化能力与实用性。

Abstract: Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step "embedding-detector" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.

</details>


### [214] [DIETA: A Decoder-only transformer-based model for Italian-English machine TrAnslation](https://arxiv.org/abs/2601.17823)
*Pranav Kasela,Marco Braga,Alessandro Ghiotto,Andrea Pilzer,Marco Viviani,Alessandro Raganato*

Main category: cs.CL

TL;DR: DIETA是一个专为意大利语-英语机器翻译设计的0.5B参数解码器-only Transformer模型，基于大规模多领域平行语料训练，并发布新评测集与全部资源。


<details>
  <summary>Details</summary>
Motivation: 现有模型在意大利语-英语翻译任务上缺乏专门优化的小型高效模型，且缺乏面向当代文本（如新闻）的标准化评测资源。

Method: 构建约2.07亿句对的高质量意大利语-英语平行语料（含议会、法律、网络、字幕、新闻、文学等多领域），并加入3.52亿句回译数据；训练0.5B参数decoder-only Transformer；构建并开源450句基于2025年WikiNews的新评测集。

Result: DIETA在多个意大利语-英语基准测试中表现具竞争力，在32系统排行榜中稳定位于第二四分位，并在5个测试套件中的4个上超越大多数小于3B参数的模型。

Conclusion: DIETA证明了针对特定语言对和领域定制小型Transformer模型的有效性，其开源数据、模型与评测集将推动意英翻译研究发展。

Abstract: In this paper, we present DIETA, a small, decoder-only Transformer model with 0.5 billion parameters, specifically designed and trained for Italian-English machine translation. We collect and curate a large parallel corpus consisting of approximately 207 million Italian-English sentence pairs across diverse domains, including parliamentary proceedings, legal texts, web-crawled content, subtitles, news, literature and 352 million back-translated data using pretrained models. Additionally, we create and release a new small-scale evaluation set, consisting of 450 sentences, based on 2025 WikiNews articles, enabling assessment of translation quality on contemporary text. Comprehensive evaluations show that DIETA achieves competitive performance on multiple Italian-English benchmarks, consistently ranking in the second quartile of a 32-system leaderboard and outperforming most other sub-3B models on four out of five test suites. The training script, trained models, curated corpus, and newly introduced evaluation set are made publicly available, facilitating further research and development in specialized Italian-English machine translation. https://github.com/pkasela/DIETA-Machine-Translation

</details>


### [215] [Linguistic and Argument Diversity in Synthetic Data for Function-Calling Agents](https://arxiv.org/abs/2601.17829)
*Dan Greenstein,Zohar Karnin,Chen Amiraz,Oren Somekh*

Main category: cs.CL

TL;DR: 本文提出了一种无需人工规则或分类法、基于通用多样性度量优化查询与参数多样性的合成数据生成方法，用于提升函数调用智能体的训练效果，在多样性和泛化性能（如BFCL基准上提升7.4%准确率）方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有函数调用代理训练数据缺乏请求语句和参数（如城市名、股票代码）层面的语言多样性与覆盖度，而此前工作主要关注函数类型、调用模式和交互轮次的多样性。

Method: 提出一种端到端的合成数据生成方法，通过优化通用多样性指标（覆盖查询文本和参数值两个维度）自动构建高质量、高多样性训练数据，不依赖人工规则或预定义分类体系。

Result: 在内在评估（多样性）和外在评估（下游模型性能）中均优于SOTA基线方法；所生成数据训练出的模型在OOD场景下表现更优，在BFCL基准上准确率提升7.4%。

Conclusion: 基于通用多样性优化的无监督合成数据生成方法，能有效提升函数调用代理的语言覆盖性与泛化能力，是一种鲁棒、可迁移的数据构建范式。

Abstract: The construction of function calling agents has emerged as a promising avenue for extending model capabilities. A major challenge for this task is obtaining high quality diverse data for training. Prior work emphasizes diversity in functions, invocation patterns, and interaction turns, yet linguistic diversity of requests and coverage of arguments (e.g., \texttt{city\_name}, \texttt{stock\_ticker}) remain underexplored. We propose a method that generates synthetic datasets via optimizing general-purpose diversity metrics across both queries and arguments, without relying on hand-crafted rules or taxonomies, making it robust to different usecases. We demonstrate the effectiveness of our technique via both intrinsic and extrinsic testing, comparing it to SoTA data generation methods. We show a superiority over baselines in terms of diversity, while keeping comparable correctness. Additionally, when used as a training set, the model resulting from our dataset exhibits superior performance compared to analogous models based on the baseline data generation methods in out-of-distribution performance. In particular, we achieve an $7.4\%$ increase in accuracy on the BFCL benchmark compared to similar counterparts.

</details>


### [216] [EFT-CoT: A Multi-Agent Chain-of-Thought Framework for Emotion-Focused Therapy](https://arxiv.org/abs/2601.17842)
*Lanqing Du,Yunong Li,YuJie Long,Shihong Chen*

Main category: cs.CL

TL;DR: 本文提出了一种基于情绪聚焦疗法（EFT）的多智能体链式思维框架（EFT-CoT），用于心理健康问答，强调自下而上的情绪与身体体验处理，并构建了EFT-Instruct数据集和EFT-LLM模型，实验表明其在共情深度与专业性等方面优于基线与人类回答。


<details>
  <summary>Details</summary>
Motivation: 现有基于认知行为疗法（CBT）的心理健康问答方法偏向‘自上而下’的理性重构，忽视来访者的具身经验与原发情绪加工，导致干预效果受限。

Method: 提出EFT-CoT多智能体链式思维框架，包含‘具身感知—认知探索—叙事干预’三阶段推理流程；设计8个专用智能体执行躯体觉察映射、适应性评估、核心信念提取与叙事重构等任务；构建EFT-Instruct数据集（约6.7万真实文本经CoT蒸馏），并微调专用模型EFT-LLM。

Result: EFT-LLM在共情深度、结构专业性等指标上超越强基线及人类回答；消融实验证实多智能体机制的必要性；模型展现出更优的心理学推理能力。

Conclusion: EFT-CoT框架为构建可解释、高共情的心理咨询系统提供了有效新路径，推动LLM在心理健康领域向更具人文关怀与临床适配性的方向发展。

Abstract: Leveraging Large Language Models (LLMs) for Mental Health Question Answering (MHQA) is promising for mitigating resource shortages. However, existing Cognitive Behavioral Therapy (CBT)-based approaches predominantly favor a "top-down" rational restructuring, often neglecting clients' embodied experiences and primary emotion processing. To address this, we propose an Emotion-Focused Therapy (EFT)-based Multi-Agent Chain-of-Thought framework (EFT-CoT). Adopting a "bottom-up" trajectory, it deconstructs the intervention into a three-stage reasoning flow: "Embodied Perception - Cognitive Exploration - Narrative Intervention." Utilizing eight specialized agents, the system explicitly executes critical components such as somatic awareness mapping, adaptive assessment, core belief extraction, and narrative restructuring. We further constructed "EFT-Instruct," a high-quality dataset via Chain-of-Thought distillation of approximately 67,000 authentic texts, and fine-tuned a specialized model, EFT-LLM. Experimental evaluations demonstrate that EFT-LLM outperforms strong baselines and human responses across metrics like empathy depth and structural professionalism. Ablation studies confirm the necessity of the multi-agent mechanism. The model exhibits superior psychological reasoning, offering an effective pathway for interpretable, high-empathy counseling systems.

</details>


### [217] [D-Models and E-Models: Diversity-Stability Trade-offs in the Sampling Behavior of Large Language Models](https://arxiv.org/abs/2601.17865)
*Jia Gu,Liang Pang,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 本文揭示了大语言模型（LLM）在细粒度采样概率（P_token）与任务级目标分布（P_task）对齐上的根本差异，识别出两类模型：D-models（如Qwen-2.5）采样不稳定、对齐差；E-models（如Mistral-Small）更稳定、对齐好，并在代码生成与推荐等下游任务中验证其多样性-稳定性权衡，为实际应用中的模型选型提供指导。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM能近似真实世界分布，但其逐token采样概率是否真正符合具体任务需求（即P_token是否忠实对齐P_task）仍属未知。

Method: 通过受控的分布采样模拟实验，区分并定义D-models与E-models；在代码生成、推荐等下游任务中实证评估二者表现；进一步分析两类模型的内部机制。

Result: 发现LLM存在显著的采样行为二分性：D-models P_token步间波动大、与P_task对齐差；E-models更稳定、对齐更好；下游任务中二者呈现系统性的多样性-稳定性权衡。

Conclusion: LLM的采样概率并非统一可靠，其内在采样特性存在本质分化；D-models适合需高多样性的场景，E-models更适合需高稳定性和任务对齐的Web规模应用（如推荐、搜索、对话），该发现为模型选择与配置提供了可解释的实践依据。

Abstract: The predictive probability of the next token (P_token) in large language models (LLMs) is inextricably linked to the probability of relevance for the next piece of information, the purchase probability of the next product, and the execution probability of the next action-all of which fall under the scope of the task-level target distribution (P_task). While LLMs are known to generate samples that approximate real-world distributions, whether their fine-grained sampling probabilities faithfully align with task requirements remains an open question. Through controlled distribution-sampling simulations, we uncover a striking dichotomy in LLM behavior, distinguishing two model types: D-models (e.g. Qwen-2.5), whose P_token exhibits large step-to-step variability and poor alignment with P_task; and E-models (e.g. Mistral-Small), whose P_token is more stable and better aligned with P_task. We further evaluate these two model types in downstream tasks such as code generation and recommendation, revealing systematic trade-offs between diversity and stability that shape task outcomes. Finally, we analyze the internal properties of both model families to probe their underlying mechanisms. These findings offer foundational insights into the probabilistic sampling behavior of LLMs and provide practical guidance on when to favor D- versus E-models. For web-scale applications, including recommendation, search, and conversational agents, our results inform model selection and configuration to balance diversity with reliability under real-world uncertainty, providing a better level of interpretation.

</details>


### [218] [On the Emergence and Test-Time Use of Structural Information in Large Language Models](https://arxiv.org/abs/2601.17869)
*Michelle Chao Chen,Moritz Miller,Bernhard Schölkopf,Siyuan Guo*

Main category: cs.CL

TL;DR: 本文研究语言模型如何从观测数据中学习抽象结构，并在测试时利用这些结构信息，通过设计基于语言结构变换的自然语言数据集进行实证分析，发现结构信息的学习与复杂推理任务相关，但测试时的组合生成能力仍有限。


<details>
  <summary>Details</summary>
Motivation: 学习观测数据中的结构信息对于科学发现中的机制理解以及测试时灵活的组合生成至关重要。

Method: 设计基于语言结构变换的自然语言数据集，在受控环境下研究语言模型学习和利用抽象结构的能力。

Result: 实证表明结构信息的学习与复杂推理任务相关，但测试时的组合生成能力仍然有限。

Conclusion: 语言模型虽能学习结构信息，但在测试时进行组合生成方面仍存在明显局限。

Abstract: Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.

</details>


### [219] [Assessment of Generative Named Entity Recognition in the Era of Large Language Models](https://arxiv.org/abs/2601.17898)
*Qi Zhan,Yile Wang,Hui Huang*

Main category: cs.CL

TL;DR: 本文系统评估了开源大语言模型（LLM）在扁平和嵌套命名实体识别（NER）任务上的表现，发现通过参数高效微调与结构化输出格式（如内联括号或XML），LLM性能可媲美甚至超越传统编码器模型及闭源LLM（如GPT-3）；其NER能力源于指令遵循与生成能力，而非简单记忆；且NER微调对模型通用能力影响甚微，甚至可提升部分下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型兴起，NER正从序列标注转向生成范式，但开源LLM在NER任务上的实际能力、泛化性、是否依赖记忆以及微调对其通用能力的影响尚缺乏系统评估。

Method: 对8个不同规模的开源LLM在4个标准NER数据集上进行系统实验，涵盖扁平与嵌套NER任务；采用参数高效微调，并对比多种输出格式（如内联括号、XML等）；分析模型是否依赖实体-标签对记忆，并评估NER微调对通用能力（如DROP）的影响。

Result: （1）结构化格式+参数高效微调使开源LLM在NER上达到甚至超过传统模型与GPT-3；（2）LLM的NER能力来自指令遵循与生成能力，非记忆；（3）NER微调几乎不损害通用能力，反而可能提升DROP等任务性能。

Conclusion: 生成式NER是传统方法的可行且用户友好的替代方案，开源LLM经适当微调与格式设计后具备强大NER能力，且保持良好通用性。

Abstract: Named entity recognition (NER) is evolving from a sequence labeling task into a generative paradigm with the rise of large language models (LLMs). We conduct a systematic evaluation of open-source LLMs on both flat and nested NER tasks. We investigate several research questions including the performance gap between generative NER and traditional NER models, the impact of output formats, whether LLMs rely on memorization, and the preservation of general capabilities after fine-tuning. Through experiments across eight LLMs of varying scales and four standard NER datasets, we find that: (1) With parameter-efficient fine-tuning and structured formats like inline bracketed or XML, open-source LLMs achieve performance competitive with traditional encoder-based models and surpass closed-source LLMs like GPT-3; (2) The NER capability of LLMs stems from instruction-following and generative power, not mere memorization of entity-label pairs; and (3) Applying NER instruction tuning has minimal impact on general capabilities of LLMs, even improving performance on datasets like DROP due to enhanced entity understanding. These findings demonstrate that generative NER with LLMs is a promising, user-friendly alternative to traditional methods. We release the data and code at https://github.com/szu-tera/LLMs4NER.

</details>


### [220] [ShapLoRA: Allocation of Low-rank Adaption on Large Language Models via Shapley Value Inspired Importance Estimation](https://arxiv.org/abs/2601.17921)
*Yi Zhao,Qinghua Yao,Xinyuan song,Wei Zhu*

Main category: cs.CL

TL;DR: 本文提出ShapLoRA框架，利用Shapley值思想设计可解释的'Shapley敏感度'来优化LoRA中秩的分配，提升参数高效微调性能。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA秩分配方法依赖不可靠、不可解释的重要性度量，导致性能受限。

Method: 提出基于Shapley值的' Shapley敏感度'作为更可解释的秩重要性度量；在独立验证集上计算该指标；采用分配-重训练流程确保公平比较。

Result: 在多个挑战性任务上，ShapLoRA在可调参数量相当的情况下，性能优于近期基线方法。

Conclusion: Shapley值启发的可解释敏感度度量能有效提升LoRA秩分配质量，推动参数高效微调方法的发展。

Abstract: Low-rank adaption (LoRA) is a representative method in the field of parameter-efficient fine-tuning (PEFT), and is key to Democratizating the modern large language models (LLMs). The vanilla LoRA is implemented with uniform ranks, and the recent literature have found that properly allocating ranks on the LLM backbones results in performance boosts. However, the previous rank allocation methods have limitations since they rely on inexplanable and unreliable importance measures for the LoRA ranks. To address the above issues, we propose the ShapLoRA framework. Inspired by the explanable attribution measure Shapley Value, we combine the sensitivity-based measures with the idea of coalitions in the collaborative games among LoRA ranks, and propose a more explainable importance measure called Shapley sensitivity. In addition, we optimize the workflow of the existing works by: (a) calculating Shapley sensitivity on a separate validation set; (b) Setting up the allocating-retraining procedures for fair comparisons. We have conducted experiments on various challenging tasks, and the experimental results demonstrate that our ShapLoRA method can outperform the recent baselines with comparable tunable parameters.\footnote{Codes and fine-tuned models will be open-sourced to facilitate future research.

</details>


### [221] [A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models](https://arxiv.org/abs/2601.17952)
*Michail Mamalakis,Tiago Azevedo,Cristian Cosentino,Chiara D'Ercoli,Subati Abulikemu,Zhongtian Sun,Richard Bethlehem,Pietro Lio*

Main category: cs.CL

TL;DR: 本文提出了一种统一的可解释性框架，通过单义特征提取整合归因式与机制式解释方法，以提升大语言模型在阿尔茨海默病进展诊断等临床场景中的稳定性与可信度。


<details>
  <summary>Details</summary>
Motivation: 临床场景（如阿尔茨海默病诊断）亟需可信赖、早期且稳定的LLM预测；现有归因方法变异性高、解释不稳定，机制解释又缺乏输入输出对齐和显式重要性评分。

Method: 构建LLM某一层的单义嵌入空间，优化框架以显式降低不同归因方法间的差异性，生成稳定输入级重要性得分，并通过目标层的解压缩表征凸显关键特征。

Result: 实现了更稳定、可解释、输入对齐的LLM解释，提升了其在认知健康与神经退行性疾病中的安全可信应用能力。

Conclusion: 单义特征提取可有效融合归因与机制解释视角，为临床部署LLM提供更可靠、可解释的技术路径。

Abstract: Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.

</details>


### [222] [LLMs as Cultural Archives: Cultural Commonsense Knowledge Graph Extraction](https://arxiv.org/abs/2601.17971)
*Junior Cedric Tonga,Chen Cecilia Liu,Iryna Gurevych,Fajri Koto*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLMs）构建文化常识知识图谱（CCKG）的迭代式提示框架，旨在将LLM作为文化档案库系统性地提取跨语言的文化实体、关系与实践，并组织为多步推理链；实验表明当前LLM对非英语文化的知识编码不均衡，英文链效果更优，且CCKG可有效增强小模型在文化推理和故事生成任务上的表现。


<details>
  <summary>Details</summary>
Motivation: LLM虽从海量数据中习得了丰富的文化知识，但这些知识隐含且无结构，导致其可解释性与实用性受限，亟需一种方法显式建模大规模文化常识。

Method: 提出迭代式、基于提示的框架，将LLM视为文化档案，通过多轮提示引导其生成文化特定的实体、关系与实践，并构建跨语言的多步推理链，最终形成文化常识知识图谱（CCKG）。

Result: 在五国文化样本上的人工评估显示：CCKG在英语中实现得更好（即使目标文化为中文、印尼语、阿拉伯语等），揭示了当前LLM文化编码的不均衡性；用CCKG增强小模型显著提升了文化推理与故事生成性能，尤以英文推理链增益最大。

Conclusion: LLM作为文化技术兼具潜力与局限；链式结构的文化知识是实现文化扎根NLP的可行基础，但需解决多语言文化表征偏差问题。

Abstract: Large language models (LLMs) encode rich cultural knowledge learned from diverse web-scale data, offering an unprecedented opportunity to model cultural commonsense at scale. Yet this knowledge remains mostly implicit and unstructured, limiting its interpretability and use. We present an iterative, prompt-based framework for constructing a Cultural Commonsense Knowledge Graph (CCKG) that treats LLMs as cultural archives, systematically eliciting culture-specific entities, relations, and practices and composing them into multi-step inferential chains across languages. We evaluate CCKG on five countries with human judgments of cultural relevance, correctness, and path coherence. We find that the cultural knowledge graphs are better realized in English, even when the target culture is non-English (e.g., Chinese, Indonesian, Arabic), indicating uneven cultural encoding in current LLMs. Augmenting smaller LLMs with CCKG improves performance on cultural reasoning and story generation, with the largest gains from English chains. Our results show both the promise and limits of LLMs as cultural technologies and that chain-structured cultural knowledge is a practical substrate for culturally grounded NLP.

</details>


### [223] [SD-E$^2$: Semantic Exploration for Reasoning Under Token Budgets](https://arxiv.org/abs/2601.17982)
*Kshitij Mishra,Nils Lukas,Salem Lahlou*

Main category: cs.CL

TL;DR: 本文提出SD-E²框架，通过语义多样性奖励显式优化小语言模型的推理路径探索，在GSM8K等基准上显著提升性能，同时发现更多语义不同的解题策略。


<details>
  <summary>Details</summary>
Motivation: 小语言模型在复杂推理任务中受限于计算资源，传统探索方式成本高、效率低，亟需一种更高效的探索-利用机制。

Method: 提出Semantic Diversity-Exploration-Exploitation（SD-E²）强化学习框架，利用冻结句嵌入模型计算推理路径间的语义多样性作为奖励，并与正确性、效率构成z-score归一化的多目标优化目标。

Result: 在GSM8K上超越基线Qwen2.5-3B-Instruct达+27.4个百分点；MedMCQA提升至49.64%（基线38.37%）；AIME达13.28%（基线6.74%）；平均每题发现9.8种语义不同策略。

Conclusion: 语义新颖性奖励能提供更计算高效的探索-利用信号；通过认知适应（调整推理结构而非逐token计算），SD-E²为资源受限小模型提供了新的效率提升路径。

Abstract: Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.

</details>


### [224] [AI-based approach to burnout identification from textual data](https://arxiv.org/abs/2601.17993)
*Marina Zavertiaeva,Petr Parshakov,Mikhail Usanin,Aleksei Smirnov,Sofia Paklina,Anastasiia Kibardina*

Main category: cs.CL

TL;DR: 本文提出了一种基于RuBERT模型的AI方法，通过NLP从文本中检测职业倦怠，使用ChatGPT生成的合成数据和俄语YouTube评论进行微调，可大规模监测高压工作环境中的倦怠信号。


<details>
  <summary>Details</summary>
Motivation: 在高压工作环境中，及时识别职业倦怠对员工心理健康至关重要，但传统方法依赖主观问卷，缺乏实时、大规模文本分析能力。

Method: 采用预训练的RuBERT模型，先用于情感分析，再利用ChatGPT生成的合成句子和俄语YouTube用户评论进行微调，构建二分类模型以输出文本的倦怠概率。

Result: 模型能有效为输入文本分配倦怠概率，适用于批量处理书面交流，初步验证了其在真实语境（如俄语视频评论）中的可行性。

Conclusion: 该方法展示了将大语言模型生成数据与真实用户文本结合用于细粒度心理状态检测的潜力，为组织级倦怠早期预警提供了可扩展的技术路径。

Abstract: This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.

</details>


### [225] [PEAR: Pairwise Evaluation for Automatic Relative Scoring in Machine Translation](https://arxiv.org/abs/2601.18006)
*Lorenzo Proietti,Roman Grundkiewicz,Matt Post*

Main category: cs.CL

TL;DR: PEAR是一种新的监督式质量评估（QE）指标族，将无参考机器翻译评估重构为分级的成对比较任务，通过预测两个候选译文的质量差异方向和幅度来实现，并在WMT24基准上显著优于同类单候选QE方法及更大规模模型。


<details>
  <summary>Details</summary>
Motivation: 现有参考-free机器翻译评估方法多基于单候选打分，难以建模译文间相对质量关系；而人类评估天然具有比较性，因此需设计能直接建模译文对相对质量的QE方法。

Method: PEAR将QE建模为源句与两个候选译文构成的三元组上的分级成对比较任务，使用人工评分差值构建监督信号，并引入候选顺序反转下的符号一致性正则化项。

Result: 在WMT24 meta-evaluation基准上，PEAR超越了同等数据与骨干网络的单候选QE基线，且参数量远少于当前大模型却性能更优；分析表明其评估信号冗余度更低；并可有效用于MBR解码，降低成对打分开销。

Conclusion: 成对比较范式能更有效地利用人类评分信息，提升QE性能与效率；PEAR验证了轻量、监督式、相对评估路径的有效性，为QE与MT解码提供了新思路。

Abstract: We present PEAR (Pairwise Evaluation for Automatic Relative Scoring), a supervised Quality Estimation (QE) metric family that reframes reference-free Machine Translation (MT) evaluation as a graded pairwise comparison. Given a source segment and two candidate translations, PEAR predicts the direction and magnitude of their quality difference. The metrics are trained using pairwise supervision derived from differences in human judgments, with an additional regularization term that encourages sign inversion under candidate order reversal. On the WMT24 meta-evaluation benchmark, PEAR outperforms strictly matched single-candidate QE baselines trained with the same data and backbones, isolating the benefit of the proposed pairwise formulation. Despite using substantially fewer parameters than recent large metrics, PEAR surpasses far larger QE models and reference-based metrics. Our analysis further indicates that PEAR yields a less redundant evaluation signal relative to other top metrics. Finally, we show that PEAR is an effective utility function for Minimum Bayes Risk (MBR) decoding, reducing pairwise scoring cost at negligible impact.

</details>


### [226] [Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems](https://arxiv.org/abs/2601.18012)
*Hendrika Maclean,Mert Can Cakmak,Muzakkiruddin Ahmed Mohammed,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）在高精度数值计算（如薪资系统）中的可靠性，发现仅靠提示工程在简单任务中有效，而复杂任务需引入显式计算；提出了一个可复现的评估框架和实用部署建议。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然语言理解上持续进步，但在精确数值计算和可审计输出方面仍不可靠，亟需在高风险场景（如薪资系统）中验证其准确性和可信度。

Method: 构建了一个合成的薪资系统作为测试用例，设计了从基础到复杂的分层数据集，对比了多种提示策略（基础提示、模式引导提示、推理增强提示），并在多个主流模型（GPT、Claude、Perplexity、Grok、Gemini）上进行系统性评估。

Result: 实验表明：在简单任务中，精心设计的提示即可达到高精度；而在复杂任务中，仅靠提示无法保证分币级准确，必须引入显式计算机制；不同模型表现差异显著。

Conclusion: 单纯依赖LLM的文本生成能力不足以满足高精度、高保障需求的任务；需结合结构化提示、外部计算模块与可审计流程，才能实现安全可靠的部署。

Abstract: Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.

</details>


### [227] [A System for Name and Address Parsing with Large Language Models](https://arxiv.org/abs/2601.18014)
*Adeeba Tarannum,Muzakkiruddin Ahmed Mohammed,Mert Can Cakmak,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

TL;DR: 本文提出了一种无需微调的提示驱动、验证为中心的框架，用于将非结构化的人名和地址文本可靠地转换为17字段结构化数据，结合输入归一化、结构化提示、约束解码与规则验证，在真实多语言噪声数据上实现了高准确率、强模式一致性与稳定置信度校准。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则或概率的方法在干净数据上表现好，但在噪声或多语言场景下失效；神经模型和大语言模型（LLMs）则缺乏确定性控制与可复现性。

Method: 提出一种提示驱动、验证为中心的框架，整合输入归一化、结构化提示、约束解码与严格基于规则的验证，在固定实验设置下确保可复现性，且无需微调。

Result: 在异构真实地址数据上的评估显示高字段级准确率、强schema一致性及稳定的置信度校准。

Conclusion: 将确定性验证与生成式提示相结合，可提供鲁棒、可解释且可扩展的结构化信息抽取方案，是训练密集型或领域专用模型的实用替代方案。

Abstract: Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.

</details>


### [228] [CommonLID: Re-evaluating State-of-the-Art Language Identification Performance on Web Data](https://arxiv.org/abs/2601.18026)
*Pedro Ortiz Suarez,Laurie Burchell,Catherine Arnett,Rafael Mosquera-Gómez,Sara Hincapie-Monsalve,Thom Vaughan,Damian Stewart,Malte Ostendorff,Idris Abdulmumin,Vukosi Marivate,Shamsuddeen Hassan Muhammad,Atnafu Lambebo Tonja,Hend Al-Khalifa,Nadia Ghezaiel Hammouda,Verrah Otiende,Tack Hwa Wong,Jakhongir Saydaliev,Melika Nobakhtian,Muhammad Ravi Shulthan Habibi,Chalamalasetti Kranti,Carol Muchemi,Khang Nguyen,Faisal Muhammad Adam,Luis Frentzen Salim,Reem Alqifari,Cynthia Amol,Joseph Marvin Imperial,Ilker Kesen,Ahmad Mustafid,Pavel Stepachev,Leshem Choshen,David Anugraha,Hamada Nayel,Seid Muhie Yimam,Vallerie Alexandra Putra,My Chiffon Nguyen,Azmine Toushik Wasi,Gouthami Vadithya,Rob van der Goot,Lanwenn ar C'horr,Karan Dua,Andrew Yates,Mithil Bangera,Yeshil Bangera,Hitesh Laxmichand Patel,Shu Okabe,Fenal Ashokbhai Ilasariya,Dmitry Gaynullin,Genta Indra Winata,Yiyuan Li,Juan Pablo Martínez,Amit Agarwal,Ikhlasul Akmal Hanif,Raia Abu Ahmad,Esther Adenuga,Filbert Aurelian Tjiaranata,Weerayut Buaphet,Michael Anugraha,Sowmya Vajjala,Benjamin Rice,Azril Hafizi Amirudin,Jesujoba O. Alabi,Srikant Panda,Yassine Toughrai,Bruhan Kyomuhendo,Daniel Ruffinelli,Akshata A,Manuel Goulão,Ej Zhou,Ingrid Gabriela Franco Ramirez,Cristina Aggazzotti,Konstantin Dobler,Jun Kevin,Quentin Pagès,Nicholas Andrews,Nuhu Ibrahim,Mattes Ruckdeschel,Amr Keleg,Mike Zhang,Casper Muziri,Saron Samuel,Sotaro Takeshita,Kun Kerdthaisong,Luca Foppiano,Rasul Dent,Tommaso Green,Ahmad Mustapha Wali,Kamohelo Makaaka,Vicky Feliren,Inshirah Idris,Hande Celikkanat,Abdulhamid Abubakar,Jean Maillard,Benoît Sagot,Thibault Clérice,Kenton Murray,Sarah Luger*

Main category: cs.CL

TL;DR: 本文介绍了CommonLID，一个面向网络域、涵盖109种语言（含大量此前被忽视的语言）的社区驱动、人工标注的语言识别（LID）基准测试集，用于评估和改进现有LID模型在噪声大、异构性强的网页数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别模型在噪声大、异构性强的网页数据上表现不佳，尤其对许多语言效果差；已有评估基准覆盖不全、代表性不足，导致对模型真实性能的误判。

Method: 构建了名为CommonLID的人工标注、开源、覆盖109种语言的Web领域LID基准；联合5个其他常用评测集，在8个主流LID模型上开展系统性评测与分析。

Result: 实证表明，当前主流LID评测严重高估了模型在Web场景下对诸多语言的识别准确率；CommonLID填补了低资源及被忽视语言的评估空白，显著提升了评估的代表性和可靠性。

Conclusion: CommonLID为构建更公平、更具代表性的多语言语料库提供了关键评估工具，推动LID技术向更真实、更包容的Web环境落地，并已开源数据与代码。

Abstract: Language identification (LID) is a fundamental step in curating multilingual corpora. However, LID models still perform poorly for many languages, especially on the noisy and heterogeneous web data often used to train multilingual language models. In this paper, we introduce CommonLID, a community-driven, human-annotated LID benchmark for the web domain, covering 109 languages. Many of the included languages have been previously under-served, making CommonLID a key resource for developing more representative high-quality text corpora. We show CommonLID's value by using it, alongside five other common evaluation sets, to test eight popular LID models. We analyse our results to situate our contribution and to provide an overview of the state of the art. In particular, we highlight that existing evaluations overestimate LID accuracy for many languages in the web domain. We make CommonLID and the code used to create it available under an open, permissive license.

</details>


### [229] [Addressing LLM Diversity by Infusing Random Concepts](https://arxiv.org/abs/2601.18053)
*Pulin Agrawal,Prasoon Goyal*

Main category: cs.CL

TL;DR: 本文研究了在提示中注入随机概念是否能提高大语言模型（LLM）输出的多样性，并设计了一种系统性评估协议来验证该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）生成的输出通常缺乏多样性，本文旨在探索通过在提示中引入随机概念来提升输出多样性的可行性。

Method: 设计一种系统性评估协议，例如向LLM提问‘列举10位好莱坞演员’，并在提示前添加与任务无关的随机词或句子，分析输出结果的多样性指标。

Result: 实验表明，在多个LLM上，添加无关随机内容可显著提升输出多样性。

Conclusion: 在提示中注入随机概念是一种简单而有效的提升LLM输出多样性的方法，所提出的评估协议也为未来系统性评测LLM多样性提供了新思路。

Abstract: Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form "Name 10 Hollywood actors", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.

</details>


### [230] [Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production](https://arxiv.org/abs/2601.18056)
*Ahmet Yavuz Uluslu,Elliot Murphy*

Main category: cs.CL

TL;DR: 本文探讨了将振荡信号纳入双语产出错误研究的价值，提出ROSE神经模型可解释二语句法迁移，并以跨语言影响（CLI）为例，论证其源于特定振荡失败模式，从而为语言功能障碍提供更复杂的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 传统双语产出错误研究多依赖事件相关电位等时间标记，本文旨在引入振荡信号以提供实施层面的新理论约束。

Method: 基于ROSE神经计算模型，结合振荡神经动力学分析，以跨语言影响（CLI）为案例，探讨功能抑制/竞争理论背后的振荡机制。

Result: ROSE模型成功刻画了句法迁移的形式特性及形态句法序列失败模式；CLI被解释为L2句子规划中特定振荡失败所致。

Conclusion: 将振荡信号纳入双语研究不仅强化了ROSE模型所倡导的连接假说，还支持探索比传统神经信号更时空复杂的语言功能障碍生物标志物。

Abstract: We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.

</details>


### [231] [Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models](https://arxiv.org/abs/2601.18065)
*Aryan Roy,Zekun Wang,Christopher J. MacLellan*

Main category: cs.CL

TL;DR: 本文通过对比Llama文本模型和Llama Vision多模态模型，研究视觉-语言模型（VLMs）是否比纯文本大语言模型（LLMs）在语言具体性感知上更接近人类，发现VLMs在多个层面展现出更强的具体性敏感性和更符合人类认知的表征与注意模式。


<details>
  <summary>Details</summary>
Motivation: 探究视觉-语言模型（VLMs）相较于纯文本大语言模型（LLMs）是否因多模态预训练而发展出更类人的语言具体性敏感性，尤其在仅用文本提示评估时。

Method: 采用控制实验设计，对比匹配的Llama文本基座模型及其Llama Vision多模态对应模型；从输出行为、嵌入几何结构、注意力动态三个层面量化具体性效应，并评估模型生成的词级具体性评分与人类规范分布的一致性。

Result: VLMs在更具体的输入上准确率提升更大，其表征空间更清晰地沿具体性轴组织，生成的具体性评分更贴近人类标准，且注意力模式显示更强的上下文依赖与感知具身性。

Conclusion: 多模态预训练（即使推理时不使用图像）能增强模型对语言具体性的敏感性，使其表征与行为更接近人类认知，表明感知具身性对语言理解建模具有实质性影响。

Abstract: Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding.

</details>


### [232] [Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents](https://arxiv.org/abs/2601.18077)
*Mahesh Ramesh,Kaousheik Jayakumar,Aswinkumar Ramkumar,Pavan Thodima,Aniket Rege*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）在不完全信息合作推理任务——纸牌游戏Hanabi中的表现，通过不同层级的上下文工程（Watson/Sherlock/Mycroft设置）评估17个SOTA模型；发现工作记忆与模型能力正相关，跨模型交叉对战性能随规模平滑提升；发布首个公开Hanabi数据集（HanabiLogs与HanabiRewards），并基于其微调4B开源模型，在Hanabi上性能大幅提升，且泛化至其他协作与推理任务。


<details>
  <summary>Details</summary>
Motivation: Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication.

Method: Benchmark 17 state-of-the-art LLM agents in 2-5 player Hanabi games; study context engineering across model scales (4B to 600B+) — from minimal prompt (Watson), to Bayesian-motivated deduction scaffolding (Sherlock), to multi-turn state tracking via working memory (Mycroft); release two new public datasets (HanabiLogs and HanabiRewards); perform supervised and RL fine-tuning on a 4B open-weight model (Qwen3-Instruct).

Result: Agents can maintain internal working memory for state tracking; cross-play performance smoothly interpolates with model strength; strongest models in Sherlock setting average >15 points but still below experienced humans and specialist agents (>20); supervised and RL finetuning improve Hanabi performance by 21% and 156%, respectively, approaching o4-mini and surpassing GPT-4.1 by 52%; HanabiRewards-RL model also improves generalization on cooperative guessing, temporal reasoning, instruction-following, and math reasoning.

Conclusion: Context engineering and targeted dataset curation significantly enhance LLMs' cooperative reasoning under incomplete information; working memory and scalable scaffolding are key levers; the released datasets and finetuned models advance both Hanabi-specific and general multi-agent reasoning capabilities.

Abstract: Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.

</details>


### [233] [CHiRPE: A Step Towards Real-World Clinical NLP with Clinician-Oriented Model Explanations](https://arxiv.org/abs/2601.18102)
*Stephanie Fong,Zimu Wang,Guilherme C. Oliveira,Xiangyu Zhao,Yiwen Jiang,Jiahe Liu,Beau-Luke Colton,Scott Woods,Martha E. Shenton,Barnaby Nelson,Zongyuan Ge,Dominic Dwyer*

Main category: cs.CL

TL;DR: CHiRPE 是一个面向临床高风险预测的可解释NLP管道，结合临床医生协作设计的新型SHAP解释格式，在 psychosis 风险预测任务中达到90%以上准确率，并获临床专家高度认可。


<details>
  <summary>Details</summary>
Motivation: 传统可解释AI方法与临床推理不匹配，且缺乏临床医生参与，难以满足医疗NLP工具对可解释性的实际需求。

Method: 提出CHiRPE管道，整合症状领域映射、大语言模型摘要和BERT分类；采用与临床医生共同开发的新型概念引导型SHAP解释格式（尤其是图-文混合摘要）；基于AMP-SCZ研究中24个国际诊所的944份半结构化访谈转录本训练。

Result: 在三种BERT变体上均取得超90%准确率，优于基线模型；28位临床专家评估显示其偏好新型概念引导解释，尤其图-文混合格式。

Conclusion: 以临床为导向的模型开发路径可同时提升NLP模型的准确性与可解释性，为医疗AI落地提供可行范式。

Abstract: The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites.

</details>


### [234] [GLEN-Bench: A Graph-Language based Benchmark for Nutritional Health](https://arxiv.org/abs/2601.18106)
*Jiatan Huang,Zheyuan Zhang,Tianyi Ma,Mingchen Li,Yaning Zheng,Yanfang Ye,Chuxu Zhang*

Main category: cs.CL

TL;DR: 本文提出GLEN-Bench，首个面向营养健康评估的图语言联合基准，整合多源真实数据构建知识图谱，支持风险检测、个性化膳食推荐与可解释问答三类任务，并在阿片类药物使用障碍场景中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法在个性化膳食指导方面存在三大缺陷：忽视现实约束（如社会经济地位、共病、食物可及性）、缺乏可解释性、缺少统一评估基准。

Method: 构建融合NHANES、FNDDS和USDA数据的知识图谱，设计包含风险检测、约束感知膳食推荐和图接地问答的三任务基准GLEN-Bench，并评估图神经网络、大语言模型及混合架构性能。

Result: 在阿片类药物使用障碍案例中成功识别疾病各阶段细微营养差异；建立多个模型基线，揭示了与健康风险显著相关的膳食模式。

Conclusion: GLEN-Bench填补了营养干预领域缺乏可解释、约束感知与系统评估的空白，为临床转化提供可落地的技术路径与实证洞察。

Abstract: Nutritional interventions are important for managing chronic health conditions, but current computational methods provide limited support for personalized dietary guidance. We identify three key gaps: (1) dietary pattern studies often ignore real-world constraints such as socioeconomic status, comorbidities, and limited food access; (2) recommendation systems rarely explain why a particular food helps a given patient; and (3) no unified benchmark evaluates methods across the connected tasks needed for nutritional interventions. We introduce GLEN-Bench, the first comprehensive graph-language based benchmark for nutritional health assessment. We combine NHANES health records, FNDDS food composition data, and USDA food-access metrics to build a knowledge graph that links demographics, health conditions, dietary behaviors, poverty-related constraints, and nutrient needs. We test the benchmark using opioid use disorder, where models must detect subtle nutritional differences across disease stages. GLEN-Bench includes three linked tasks: risk detection identifies at-risk individuals from dietary and socioeconomic patterns; recommendation suggests personalized foods that meet clinical needs within resource constraints; and question answering provides graph-grounded, natural-language explanations to facilitate comprehension. We evaluate these graph-language approaches, including graph neural networks, large language models, and hybrid architectures, to establish solid baselines and identify practical design choices. Our analysis identifies clear dietary patterns linked to health risks, providing insights that can guide practical interventions.

</details>


### [235] [FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning](https://arxiv.org/abs/2601.18116)
*Lin Sun,Linglin Zhang,Jingang Huang,Change Jia,Zhengwei Cheng,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 本文提出FABLE框架，通过LLM增强的森林式分层索引与双路径检索策略，在保持高准确率的同时大幅降低长上下文推理的计算开销，证明结构化检索在长上下文LLM时代仍不可或缺。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLMs虽发展迅速，但仍存在‘中间丢失’、高计算成本及多文档推理可扩展性差等问题；而传统RAG受限于扁平化分块检索，语义噪声大且难以支持跨文档结构化整合。

Method: 提出FABLE：构建LLM增强的多粒度语义森林索引，并采用双路径策略——LLM引导的层次遍历 + 结构感知传播，实现细粒度证据获取，同时引入显式预算控制以自适应权衡效率与精度。

Result: 实验表明FABLE持续超越SOTA RAG方法，在准确率上媲美全上下文LLM推理，同时减少高达94%的token消耗。

Conclusion: 长上下文LLM并未取代RAG，反而凸显了结构化、高效检索的必要性；FABLE为下一代检索增强系统提供了新范式。

Abstract: The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.
  We present \textbf{FABLE}, a \textbf{F}orest-based \textbf{A}daptive \textbf{B}i-path \textbf{L}LM-\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.
  Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.

</details>


### [236] [Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models](https://arxiv.org/abs/2601.18129)
*Kunat Pipatanakul,Pittawat Taveekitworachai*

Main category: cs.CL

TL;DR: 本文提出Typhoon S，一种轻量级、开源的后训练方法，结合监督微调、在线策略蒸馏和小规模强化微调（RFT），在有限资源下实现主权可控的大语言模型，尤其在泰语法律推理和本地知识任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决当前大语言模型被少数高资源机构垄断的问题，满足区域或国家层面机构对模型权重、数据和部署的自主可控需求，尤其在资源有限和透明度要求高的主权场景下。

Method: 提出Typhoon S后训练方案，包含监督微调、在线策略蒸馏和小规模RFT；引入InK-GRPO（GRPO增强版，加入下一词预测损失）以提升领域特定能力。

Result: 在泰语场景验证有效：显著提升法律推理与本地知识能力，同时保持通用性能；大幅降低指令数据规模与计算需求。

Conclusion: 精心设计的轻量级后训练策略可在学术级资源下实现高质量、主权可控的大语言模型，无需依赖海量指令数据或复杂偏好优化流程。

Abstract: Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.

</details>


### [237] [Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models](https://arxiv.org/abs/2601.18162)
*Ani Harutyunyan,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文在GoEmotions数据集上对三种模型（TF-IDF逻辑回归、BiLSTM+Attention、微调BERT）进行细粒度多标签情感识别基准测试，发现逻辑回归在Micro-F1上最优，而BERT在Macro-F1等指标上更均衡，表明表层线索适用于高频情感，上下文建模更利于稀有和模糊情感。


<details>
  <summary>Details</summary>
Motivation: 解决细粒度情感识别中因标签重叠和类别不平衡带来的挑战。

Method: 在GoEmotions数据集上对比TF-IDF+逻辑回归（二元相关训练）、BiLSTM+注意力机制、以及微调的BERT三种模型；采用官方划分和逆频率类别权重缓解不平衡。

Result: 逻辑回归取得最高Micro-F1（0.51），BERT在Macro-F1（0.49）、Hamming Loss（0.036）和Subset Accuracy（0.36）上表现最佳，超越原论文结果。

Conclusion: 高频情感依赖表层词汇线索，而上下文表示（如BERT）更有利于稀有和模糊情感识别，提升整体性能平衡性。

Abstract: Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.

</details>


### [238] [MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning](https://arxiv.org/abs/2601.18204)
*Juexiang Ye,Xue Li,Xinyu Yang,Chengkai Huang,Lanshun Nie,Lina Yao,Dechen Zhan*

Main category: cs.CL

TL;DR: MemWeaver 是一种统一的记忆框架，通过结构化图记忆、经验记忆和段落记忆三部分协同工作，提升大语言模型代理在长周期交互中的时间一致性、多跳推理与证据可追溯性，并显著减少上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有记忆系统依赖非结构化检索或粗粒度抽象，导致时间冲突、推理脆弱及可追溯性差，难以支持长周期、多步推理与证据支撑的智能体交互。

Method: 提出 MemWeaver 框架，包含：1）时序对齐的图记忆用于结构化关系推理；2）经验记忆提取重复交互模式；3）段落记忆保留原始文本证据；并采用双通道检索策略联合调用结构知识与支持证据。

Result: 在 LoCoMo 基准测试中，MemWeaver 显著提升多跳与时间推理准确率，同时将输入上下文长度压缩超 95%，优于长上下文基线方法。

Conclusion: MemWeaver 通过结构化、分层与证据驱动的记忆设计，有效解决了长周期智能体记忆中的时间一致性、推理鲁棒性与可解释性难题，为 LLM 智能体记忆系统提供了新范式。

Abstract: Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\% compared to long-context baselines.

</details>


### [239] [TechING: Towards Real World Technical Image Understanding via VLMs](https://arxiv.org/abs/2601.18238)
*Tafazzul Nadeem,Bhavik Shangari,Manish Rai,Gagan Raj Gupta,Ashutosh Modi*

Main category: cs.CL

TL;DR: 本文提出了一种面向手绘技术图表理解的大规模合成数据集及配套自监督训练方法，通过微调Llama 3.2 11B-instruct模型得到LLama-VL-TUG，在合成与真实手绘图上均显著提升VLM的图表理解与代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）难以理解手绘技术图表（如流程图、框图），而收集大量真实手绘图像用于微调不现实，亟需高效可行的训练范式。

Method: 构建大规模、逼真的合成手绘图表语料库；设计多个新自监督任务；在合成数据上微调Llama 3.2 11B-instruct模型，得到LLama-VL-TUG；在真实手绘图上开展人工评估。

Result: LLama-VL-TUG使ROUGE-L指标提升2.14倍；在8类图表中，7类编译错误最少；平均F1分数提升6.97倍。

Conclusion: 合成数据+自监督训练是提升VLM理解手绘技术图表的有效路径，LLama-VL-TUG在多项指标上显著优于基线模型。

Abstract: Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.

</details>


### [240] [BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation](https://arxiv.org/abs/2601.18253)
*Peng Sun,Xiangyu Zhang,Duan Wu*

Main category: cs.CL

TL;DR: 本文提出BoRP（Bootstrapped Regression Probing）框架，利用大语言模型隐空间的几何特性，通过极化指数引导的自举机制与偏最小二乘回归，实现高效、高保真、低成本的用户满意度评估，显著优于生成式基线并支持大规模A/B测试。


<details>
  <summary>Details</summary>
Motivation: 开放域对话AI缺乏可靠、可扩展的用户满意度评估方法：显式反馈稀疏，隐式指标模糊，传统A/B测试难以支撑迭代优化。

Method: 提出BoRP框架：1）基于极化指数的自举机制自动构建评估量规；2）利用LLM隐状态的几何结构，采用偏最小二乘（PLS）将隐藏状态映射为连续满意度得分；不依赖生成式打分，而是挖掘表征空间内在规律。

Result: 在工业数据集上，BoRP（基于Qwen3-8B/14B）在与人工评分的一致性上显著超越各类生成式基线（包括更强的Qwen3-Max），且推理开销降低数个数量级。

Conclusion: BoRP为对话AI提供了可扩展、高保真、低成本的满意度评估新范式，支持全量监控与高灵敏度CUPED增强型A/B测试，推动人机交互评估从‘黑盒生成’走向‘白盒表征驱动’。

Abstract: Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.

</details>


### [241] [Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue](https://arxiv.org/abs/2601.18281)
*Yuhang Jia,Pei Liu,Haoqin Sun,Jiaming Zhou,Xuxin Cheng,Cao Liu,Ke Zeng,Xunliang Cai,Yong Qin*

Main category: cs.CL

TL;DR: 本文提出EmpathyEval评估模型和ReEmpathy端到端口语语言模型，通过共情自反思交替推理机制提升对话共情能力，摆脱对刚性监督信号的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖刚性监督信号（如真实响应或偏好分数），难以建模复杂共情，因共情无唯一正确答案，数值评分无法捕捉情感表达与行为适切性的细微差别。

Method: 提出自然语言描述型评估模型EmpathyEval；在此基础上构建ReEmpathy模型，引入共情自反思交替推理机制，在口语响应生成过程中穿插自由形式的共情相关反思推理。

Result: 大量实验表明，ReEmpathy显著提升了共情敏感型口语对话质量，验证了反思推理的有效性。

Conclusion: ReEmpathy为实现更具情感智能和共情意识的人机交互提供了新路径，突破了传统监督范式的局限。

Abstract: End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single "correct" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.

</details>


### [242] [U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents](https://arxiv.org/abs/2601.18285)
*Jin Su,Runnan Fang,Yeqiu Li,Xiaobin Wang,Shihao Cai,Pengjun Xie,Ningyu Zhang,Fajie Yuan*

Main category: cs.CL

TL;DR: 本文提出U-Fold框架，解决大语言模型代理在用户中心多轮对话中因上下文长度限制导致的总结丢失关键细节与意图漂移问题，通过动态生成意图感知对话摘要和精简工具日志，在多个基准上显著优于ReAct等基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有上下文折叠方法在单查询场景有效，但在真实用户多轮对话中会不可逆地丢弃关键细粒度约束与中间事实，并无法跟踪演化中的用户意图，导致错误决策。

Method: 提出U-Fold动态上下文折叠框架：保留完整对话与工具调用历史，每轮使用两个核心组件生成意图感知的演化对话摘要和紧凑的任务相关工具日志。

Result: 在τ-bench、τ²-bench、VitaBench及更难的上下文膨胀设置中，U-Fold在长上下文场景下对ReAct胜率达71.4%，相较先前折叠基线最高提升27.0%，尤其在长、噪声大、多轮任务中优势明显。

Conclusion: U-Fold是将上下文管理技术从单查询基准迈向真实用户中心应用的重要进展，为LLM代理的可扩展性提供了新路径。

Abstract: Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $τ$-bench, $τ^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.

</details>


### [243] [Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.18296)
*Zhaoyan Gong,Zhiqiang Liu,Songze Li,Xiaoke Guo,Yuanxiang Liu,Xinle Deng,Zhizhen Liu,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 本文提出了首个基于强化学习训练的自主端到端时间知识图谱问答（TKGQA）代理Temp-R1，通过扩展动作空间和反向课程学习提升多跳时序推理能力，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有TKGQA方法依赖固定流程和昂贵闭源API，缺乏灵活性与可扩展性；同时单步动作易导致认知过载和简单问题上的捷径学习。

Method: 提出Temp-R1：1）设计包含专用内部动作与外部动作的扩展动作空间以缓解认知过载；2）引入反向课程学习策略，先训练难样本再迁移到易样本，强制发展复杂推理能力；3）采用强化学习进行端到端训练。

Result: 8B参数的Temp-R1在MultiTQ和TimelineKGQA数据集上达到SOTA，复杂问题性能比强基线提升19.8%。

Conclusion: Temp-R1确立了自主时序推理代理的新范式，为TKGQA提供了更灵活、可扩展且可训练的解决方案。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.

</details>


### [244] [Suppressing Final Layer Hidden State Jumps in Transformer Pretraining](https://arxiv.org/abs/2601.18302)
*Keigo Shibata,Kazuki Yano,Ryosuke Takahashi,Jaesung Lee,Wataru Ikeda,Jun Suzuki*

Main category: cs.CL

TL;DR: 本文研究了Transformer语言模型内部隐藏状态向量角度距离的异常跳跃现象，特别是在最后几层，并提出了一种跳变抑制正则化方法（JREG）来缓解该现象，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 观察到Transformer模型在中间层输入输出隐藏状态角度距离变化小，但在最终层出现显著跳跃，怀疑这种不均衡可能影响模型能力分布与性能。

Method: 提出量化最终层附近‘跳变强度’的指标；分析多模型中该现象的普遍性及训练过程中的演化；设计跳变抑制正则化项（JREG），在预训练中惩罚该跳变。

Result: 在三种尺寸的Llama模型上验证JREG有效，相比基线模型，在不改变架构前提下提升了下游任务性能。

Conclusion: 隐藏状态角度距离的末端跳变是一种普遍存在且可被正则化的现象；JREG通过促进中间层更均衡地承担建模能力，提升了模型整体表现。

Abstract: This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.

</details>


### [245] [Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM](https://arxiv.org/abs/2601.18306)
*Everlyn Asiko Chimoto,Mostafa Elhoushi,Bruce A. Bassett*

Main category: cs.CL

TL;DR: 本文系统评估了不同语言校准集对多语言大语言模型量化性能的影响，发现非英语及多语言校准集显著降低困惑度，强调校准数据的语言适配性与多样性对鲁棒量化至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有后训练量化方法多依赖小规模、仅含英语的校准集，其对多语言模型的影响尚未被充分研究。

Method: 在10种语言的数据上，系统评估8种校准设置（5种单语+3种多语混合）在两种量化器（GPTQ、AWQ）上的表现，分析困惑度变化、语言特异性提升及激活分布差异。

Result: 多语言混合校准使Llama3.1 8B和Qwen2.5 7B困惑度最高降低3.52点；语言匹配校准对各语言提升最显著；特定语言-量化器组合因激活范围分布差异出现性能下降。

Conclusion: 静态统一校准策略次优，应根据目标语言和多样性定制校准数据，以实现多语言大模型的鲁棒量化。

Abstract: Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.

</details>


### [246] [MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization](https://arxiv.org/abs/2601.18320)
*Jinwei Lu,Yuanfeng Song,Chen Zhang,Raymond Chi-Wing Wong*

Main category: cs.CL

TL;DR: 本文提出MultiVis-Agent，一种逻辑规则增强的多智能体框架，用于可靠地生成多模态、多场景的可视化图表。该框架通过四层逻辑规则提供数学保证的系统可靠性，并在新构建的MultiVis-Bench基准上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现实中的可视化任务具有复杂、多模态需求（如参考图像、代码示例、迭代优化），而现有系统受限于单模态输入、一次性生成和刚性流程，且LLM方法存在可靠性差（灾难性失败、无限循环）问题。

Method: 提出MultiVis-Agent：基于逻辑规则增强的多智能体框架；设计四层逻辑规则（作为数学约束而非替代LLM推理）；形式化定义涵盖四种场景的MultiVis任务；构建含1000+案例的MultiVis-Bench多模态可视化评测基准。

Result: 在挑战性任务上可视化得分为75.63%，显著高于基线（57.54–62.79%）；任务完成率达99.58%，代码执行成功率达94.56%（无逻辑规则时分别为74.48%和65.10%）。

Conclusion: MultiVis-Agent有效兼顾了自动化可视化生成的复杂性与可靠性，逻辑规则作为可验证的引导机制，为LLM驱动的可视化系统提供了新范式。

Abstract: Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.

</details>


### [247] [Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare](https://arxiv.org/abs/2601.18334)
*Clément Christophe,Wadood Mohammed Abdul,Prateek Munjal,Tathagata Raha,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

TL;DR: 本文提出了一种基于医学多选题（MCQA）的鲁棒框架，用于评估大语言模型（LLM）在临床场景中的“谄媚倾向”（sycophancy），即模型为迎合用户而牺牲事实准确性的倾向；提出了校正后的谄媚分数（Adjusted Sycophancy Score），并发现推理优化模型在权威压力下反而更易产生错误合理化，提示高基准性能不等于临床可靠。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）日益融入临床工作流，其谄媚倾向（优先迎合用户而非坚持事实）可能严重威胁患者安全；现有评估方法多依赖主观数据集，缺乏基于可验证事实的客观衡量标准。

Method: 构建基于医学多选题（MCQA）的评估框架，引入‘校正谄媚分数’（Adjusted Sycophancy Score），该指标通过控制模型固有的随机不稳定性（confusability）来分离对齐偏差；对Qwen-3和Llama-3系列模型开展大规模缩放分析，并分析‘Thinking’类推理优化模型的内部推理轨迹。

Result: 发现模型抗谄媚能力随规模呈现清晰提升趋势；但‘Thinking’类推理优化模型虽基础准确率高，却在权威压力下频繁对其错误建议进行内部合理化；简化推理结构反而展现出更强的抗专家驱动谄媚能力。

Conclusion: 基准测试性能不能代表临床可靠性；需警惕推理优化带来的隐蔽脆弱性；未来临床部署应优先考虑对齐鲁棒性而非单纯准确率，并采用具备可验证 ground truth 的客观评估范式。

Abstract: As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or "confusability". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized "Thinking" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.

</details>


### [248] [When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs](https://arxiv.org/abs/2601.18350)
*Junyi Zou*

Main category: cs.CL

TL;DR: 本文提出了一种两阶段LoRA适配器微调方法（领域自适应预训练+监督微调），并引入加权适配器融合策略，在14B参数大模型上提升其在医学领域的术语准确性和指令遵循安全性；在医学验证集上取得一定BLEU和ROUGE指标，并分析了解码敏感性与训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用能力上表现优异，但在医学术语精确性和安全关键型指令遵循方面存在不足，需针对性提升其在医疗等高风险领域的可靠性。

Method: 采用两阶段LoRA适配器微调：第一阶段为领域自适应预训练（DAPT），通过持续预训练注入广泛医学知识；第二阶段为监督微调（SFT），使用指令式医学问答数据对齐模型行为；提出加权适配器融合（Weighted Adapter Merging）策略，线性合并PT与SFT适配器后导出最终模型。

Result: 在医学验证集（F5/F6）上，融合模型在实用解码配置下达到BLEU-4=16.38、ROUGE-1=20.42、ROUGE-2=4.60、ROUGE-L=11.54；并通过损失曲线与受控解码对比分析了训练稳定性与解码敏感性。

Conclusion: 加权适配器融合能有效平衡指令遵循能力与领域知识保留，为安全关键型专业领域（如医疗）的LLM轻量适配提供了可行且可分析的技术路径。

Abstract: Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.

</details>


### [249] [Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning](https://arxiv.org/abs/2601.18352)
*Manjie Xu,Isabella Yin,Xinyi Tu,Chi Zhang,Yixin Zhu*

Main category: cs.CL

TL;DR: 本文揭示了大语言模型在面对动态规则变化时存在的'语义惯性'问题，即难以抑制预训练先验知识；提出通过将动态规则表示为可执行代码而非描述性文本，并引入Code-Grounded Vistas（LCV）方法，有效提升模型对上下文规则的适应能力，挑战了‘越大越好’的固有假设。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在面对与预训练先验相矛盾的动态上下文规则时表现不佳，即存在'语义惯性'问题，亟需探究其成因并提出改进方案。

Method: 提出Code-Grounded Vistas（LCV）方法：1）将物理规则建模为可执行代码以解耦语义与逻辑；2）在训练中使用反事实样本对进行微调；3）识别含矛盾规则的状态，引导模型关注逻辑约束而非视觉/语言先验。

Result: 实验表明，LCV显著缓解逆向缩放现象（即大模型性能反而更差），在准确率和推理效率上均优于推理时搜索等昂贵方法；代码化表征使模型能有效抑制先验、遵循新规则。

Conclusion: 表征方式从根本上决定了模型缩放对上下文推理的影响——将动态规则编码为可执行代码而非自然语言，可逆转逆向缩放趋势，提升先验抑制能力；这对需动态覆盖先验知识的应用领域具有重要启示。

Abstract: LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., "Lava is Dangerous") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting "Lava is Safe"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.

</details>


### [250] [CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes](https://arxiv.org/abs/2601.18374)
*Rodrigo Silva,José Evans,José Isidro,Miguel Marques,Afonso Fonseca,Ricardo Morais,João Canavilhas,Arian Pasquali,Purificação Silvano,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,Ricardo Campos*

Main category: cs.CL

TL;DR: CitiLink 是一个利用大语言模型（LLM）和信息检索技术，将葡萄牙市政会议纪要转化为结构化、可搜索数据的平台，旨在提升地方政府透明度与公众可及性。


<details>
  <summary>Details</summary>
Motivation: 市政会议纪要冗长、格式僵化、结构不清晰，导致普通市民和记者难以高效获取关键信息，亟需技术手段提升其可访问性与透明度。

Method: 使用大语言模型（如 Gemini）从会议纪要中提取元数据、议题内容和投票结果；采用 BM25 进行全文检索，并结合多维面筛选；构建用户友好的交互界面；在 120 份来自六个葡萄牙市镇的会议纪要上部署与测试。

Result: 成功构建并验证了 CitiLink 平台，Gemini 在信息抽取任务中表现有效；通过与市政工作人员的引导式测试，获得了真实用户交互反馈，证实系统具备实用性和可用性。

Conclusion: NLP 与 IR 技术可有效赋能地方政府文档的结构化与智能化处理，CitiLink 展示了技术驱动公共信息可及性的可行路径，为数字治理提供了实践范例。

Abstract: City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.

</details>


### [251] [Hierarchical Text Classification with LLM-Refined Taxonomies](https://arxiv.org/abs/2601.18375)
*Jonas Golde,Nicolaas Jedema,Ravi Krishnan,Phong Le*

Main category: cs.CL

TL;DR: 本文提出TaxMorph框架，利用大语言模型（LLM）对层级文本分类（HTC）中的标签层级结构进行语义驱动的重构（如重命名、合并、拆分、重排序），使 taxonomy 更契合 LLM 的内在表征与决策模式；实验表明其显著提升 HTC 性能（最高+2.9pp F1），且改进源于 taxonomy 与模型归纳偏置的一致性增强，而非简单聚类可分性提升。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的层级标签体系（taxonomy）常存在语义歧义（如同名叶子节点、相似父节点），导致语言模型难以学习清晰的分类边界，限制层级文本分类性能。

Method: 提出TaxMorph框架，利用大语言模型对整棵taxonomy执行语义感知的结构化编辑操作（包括重命名、合并、拆分、重排序），以使其更匹配语言模型内部编码的语义关系；并通过双向父子节点分配评估和嵌入空间分析，探究改进机制。

Result: 在三个HTC基准上，LLM优化后的taxonomy持续优于人工构建的taxonomy，F1最高提升2.9个百分点；分析发现，虽其嵌入簇更难分离，但更准确反映模型实际分类混淆模式，即更契合模型的归纳偏置。

Conclusion: LLM引导的taxonomy重构能生成更适配模型学习机制的层级结构，提升HTC性能的关键在于语义一致性与模型偏置对齐，而非单纯提升标签可分性。

Abstract: Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.

</details>


### [252] [Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction](https://arxiv.org/abs/2601.18395)
*Mikel Zubillaga,Oscar Sainz,Oier Lopez de Lacalle,Eneko Agirre*

Main category: cs.CL

TL;DR: 本文提出ThinkTwice框架，利用采样而非贪婪解码提升文档级信息抽取（DocIE）性能，通过生成多个候选模板并选择最优结果，结合无监督（基于一致性）与有监督（奖励模型）选择方法，并提出基于拒绝采样的银标数据生成策略以缓解推理轨迹标注稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 标准DocIE方法使用贪婪解码以避免输出不一致，但作者认为采样带来的多样性可被利用以提升性能，尤其在推理模型中；同时，DocIE缺乏高质量的黄金推理轨迹数据。

Method: 提出ThinkTwice框架：1）LLM对同一文档采样生成多个候选模板；2）无监督选择（利用输出间一致性）或有监督选择（用奖励模型打分）；3）采用拒绝采样法生成带推理轨迹的银标训练数据。

Result: ThinkTwice在无监督和有监督设置下均显著优于贪婪解码基线及当前最优方法。

Conclusion: 采样+选择策略能有效提升DocIE性能；无需人工标注的无监督选择已具竞争力；银标数据生成策略缓解了推理轨迹稀缺问题。

Abstract: Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.

</details>


### [253] [Pisets: A Robust Speech Recognition System for Lectures and Interviews](https://arxiv.org/abs/2601.18415)
*Ivan Bondarenko,Daniil Grebenkin,Oleg Sedukhin,Mikhail Klementev,Roman Derunets,Lyudmila Budneva*

Main category: cs.CL

TL;DR: 本文提出了一种名为“Pisets”的语音转文本系统，专为科学家和记者设计，采用Wav2Vec2、AST和Whisper三组件架构，并结合课程学习、多源俄语语料及不确定性建模，显著提升了识别准确率与鲁棒性，优于WhisperX和标准Whisper。


<details>
  <summary>Details</summary>
Motivation: 提升语音识别准确率，减少Whisper模型在科学和新闻场景中产生的错误与幻觉。

Method: 构建基于Wav2Vec2（主识别）、AST（假阳性过滤）和Whisper（最终识别）的三组件架构；引入课程学习、多样化俄语语料训练及先进不确定性建模技术。

Result: 在多种声学条件下对长音频实现更鲁棒的转录，性能优于WhisperX和标准Whisper模型。

Conclusion: Pisets系统通过模块化设计与多项优化技术，在专业领域语音识别任务中展现出更高准确性与可靠性，代码已开源。

Abstract: This work presents a speech-to-text system "Pisets" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of "Pisets" system is publicly available at GitHub: https://github.com/bond005/pisets.

</details>


### [254] [Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models](https://arxiv.org/abs/2601.18468)
*Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 本文研究了大语言模型在微调过程中如何学习和泛化生物医学本体术语映射，发现潜在知识（latent knowledge）是影响事实学习速度和泛化能力的关键因素，且训练强化能增强知识的稳定性。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型中‘潜在知识’的存在及其对微调过程中事实学习、泛化与遗忘的影响，特别是在生物医学本体映射任务中。

Method: 在Llama 3.1 8B Instruct上微调学习HPO和GO术语映射；采用随机解码检测基线潜在知识；将学习建模为事件时间过程，用Cox比例风险模型分析获取、泛化与退化的影响因素。

Result: 基线确定性召回率仅2.8%，微调后达71.9%；潜在知识是最快习得事实的最强预测因子（HR=2.6）；泛化率低（5.8%），但存在潜在知识时更可能发生；未见术语的正确映射更易退化，而训练过的术语具有保护效应。

Conclusion: 潜在知识不仅预测微调中事实学习的速度，也制约对未见本体事实的有限泛化；知识是否被训练强化决定了其抗退化能力。

Abstract: Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.

</details>


### [255] [Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs](https://arxiv.org/abs/2601.18483)
*Arya Labroo,Ivaxi Sheth,Vyas Raina,Amaani Ahmed,Mario Fritz*

Main category: cs.CL

TL;DR: 本文提出了一种用于评估大语言模型在单概念和双概念场景下细粒度文本控制能力的框架，发现现有提示方法在多概念组合控制上存在显著性能下降，揭示了模型在概念组合性上的根本局限。


<details>
  <summary>Details</summary>
Motivation: 许多应用需要对特定文本概念（如幽默、说服力、正式性）进行显式且细粒度的控制，而现有方法仅支持粗粒度或单属性控制，缺乏对多属性控制的系统性评估。

Method: 构建了一个针对单概念和双概念（特别是语言学上差异明显的概念对，如说服力 vs. 幽默）的细粒度可控性评估框架，并在多个大语言模型和生成任务上进行实证测试。

Result: 实验表明，在双概念设置下模型性能普遍下降，即使所选概念在直觉上是可分离的，揭示了基于提示的控制方法在概念组合性上的根本缺陷。

Conclusion: 当前基于提示的细粒度控制方法难以支持多概念协同控制；该框架为未来多概念控制方法的开发与评估提供了系统性基准和原则性指导。

Abstract: Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.

</details>


### [256] [Demographic Probing of Large Language Models Lacks Construct Validity](https://arxiv.org/abs/2601.18486)
*Manuel Tonneau,Neil K. R. Seghal,Niyati Malhotra,Victor Orozco-Olvera,Ana María Muñoz Boudet,Lakshmi Subramanian,Sharath Chandra Guntuku,Valentin Hofmann*

Main category: cs.CL

TL;DR: 本文质疑了人口统计学探测（demographic probing）在评估大语言模型（LLMs）对人口属性响应时的构念效度，发现单一人口线索（如姓名或方言）无法稳定、一致地表征同一人口群体，导致测量出的差异结果不稳定且易受语言混淆因素干扰；建议采用多线索、生态有效设计并控制混杂变量以提升结论可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有研究常假设单一人人口线索（如名字或方言）能有效、等价地表征某个人口群体（如种族或性别），从而用于探测LLM的行为差异，但该假设缺乏实证检验，可能影响公平性评估的科学性。

Method: 在真实建议寻求对话场景中，系统性地测试多种旨在表征相同人口群体（美国语境下的种族与性别）的不同线索，分析模型响应的重叠性、组内区分度及差异估计的稳定性，并探究线索强度与语言混淆因素的影响。

Result: 同一人口群体的不同线索引发的模型行为变化仅部分重叠；组内区分弱且不均衡；所估计的人群间差异在大小和方向上随线索变化而显著波动；线索的 demographic 编码强度差异与语言混淆因素是导致不一致性的关键原因。

Conclusion: 人口统计学探测缺乏构念效度，不能提供关于LLM如何条件化人口信息的单一稳定刻画；其问题可能源于构念本身设定不当或碎片化；应改用多线索、生态有效设计，并显式控制混淆变量。

Abstract: Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.

</details>


### [257] [Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research](https://arxiv.org/abs/2601.18512)
*Antonio Garzon-Vico,Krithika Sharon Komalapati,Arsalan Shahid,Jan Rosier*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLM）基于真实CEO沟通和道德基础理论构建虚拟高管人格的方法，并验证其在组织研究中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决组织研究中难以直接接触高层管理者的问题，探索LLM能否作为可信的替代性研究工具。

Method: 基于真实CEO沟通数据和道德基础理论，构建LLM驱动的虚拟CEO人格，并通过三阶段评估（构念效度、信度、行为保真度）与真人参与者进行基准对比。

Result: 理论支撑的虚拟人格能较好拟合人类样本的道德判断，表明LLM虚拟CEO具有行为可信度和研究适用性。

Conclusion: LLM驱动的虚拟人格可作为组织研究中补充性、可行性的研究工具，尤其适用于高管接触受限的情境。

Abstract: This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.

</details>


### [258] [GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback](https://arxiv.org/abs/2601.18517)
*James Sungarda,Hongkai Liu,Zilong Zhou,Tien-Hsuan Wu,Johnson Chun-Sing Cheung,Ben Kao*

Main category: cs.CL

TL;DR: 本文提出了SWITCH，一个用于社会工作培训的交互式聊天机器人，通过模拟真实客户、实时分类咨询技能和动机访谈（MI）进展系统，提供可扩展、低成本且一致的培训流程。


<details>
  <summary>Details</summary>
Motivation: 社会工作实地教育中，及时和客观的反馈受限于指导教师和咨询客户的可用性。

Method: SWITCH结合了基于认知模型的客户模拟、实时咨询技能分类模块以及动机访谈（MI）进展控制系统；技能分类采用微调的BERT多标签分类器和基于检索的上下文学习方法。

Result: 实验表明，基于BERT的方法和上下文学习方法均显著优于基线模型。

Conclusion: SWITCH为社会工作培训提供了可扩展、低成本且一致的辅助工具，使督导者能专注于更高层次的指导。

Abstract: Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.

</details>


### [259] [Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models](https://arxiv.org/abs/2601.18527)
*Francesco Maria Molfese,Momchil Hardalov,Rexhina Blloshmi,Bill Byrne,Adrià de Gispert*

Main category: cs.CL

TL;DR: 本文研究了长上下文语言模型（LCLMs）在微调策略下的性能提升及其在KV缓存压缩下的鲁棒性，发现微调能显著提升领域内表现，但跨领域泛化效果因任务而异，且对KV压缩有一定鲁棒性增益。


<details>
  <summary>Details</summary>
Motivation: 探索微调策略能否提升长上下文语言模型（LCLMs）在信息识别与利用能力上的表现，并增强其在KV缓存压缩下的鲁棒性。

Method: 通过系统实验比较不同微调策略对LCLMs在长上下文理解、信息检索和KV缓存压缩场景下的影响。

Result: 在领域内任务上实现最高+20分的提升；跨领域表现差异大：金融类问题提升+9分，而RAG在多项选择题上优于LCLMs（+6分）；KV缓存压缩下鲁棒性有中等程度提升，但任务间差异明显。

Conclusion: 微调可有效增强LCLMs的长上下文能力及部分压缩鲁棒性，但其跨领域泛化能力有限且高度依赖任务类型，不能全面替代RAG。

Abstract: With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.

</details>


### [260] [From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation](https://arxiv.org/abs/2601.18533)
*Yuxin Jiang,Yufei Wang,Qiyuan Zhang,Xingshan Zeng,Liangyou Li,Jierun Chen,Chaofan Tao,Haoli Bai,Lifeng Shang*

Main category: cs.CL

TL;DR: 本文提出了一种新的强化学习框架RLVRR，通过从高质量参考文本中提取有序语言信号（奖励链）来解决开放生成任务中缺乏明确真值的问题，兼顾内容确定性与风格一致性，显著优于现有SFT和奖励模型方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于可验证奖励的强化学习（RLVR）在数学、代码等有明确答案的任务中有效，但在开放生成任务中因缺乏唯一真值而面临效率低和奖励作弊问题。

Method: 提出RLVRR框架：将奖励分解为内容维度（保留关键词等确定性核心概念）和风格维度（由大模型验证是否符合参考风格），构建基于参考的奖励链，融合强化学习的探索性与监督微调的高效可靠性。

Result: 在10多个基准上，使用Qwen和Llama模型验证：RLVRR显著超越数据量十倍的SFT及先进奖励模型；统一结构化推理与开放生成训练；泛化性更强且保持输出多样性。

Conclusion: RLVRR为通用大语言模型对齐提供了一条原理清晰、高效可行的可验证强化学习路径。

Abstract: Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.

</details>


### [261] [Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features](https://arxiv.org/abs/2601.18536)
*Abishek Stephen,Jindřich Libovický*

Main category: cs.CL

TL;DR: 本文提出了一种基于形态句法特征的新指标，用于评估子词切分的形态合理性，无需依赖质量参差不齐或缺失的金标准分词数据，而是利用Universal Dependencies等广泛可用的资源，通过IBM Model 1实现子词与形态特征的概率对齐。


<details>
  <summary>Details</summary>
Motivation: 传统基于词素边界的F-score等评估指标依赖高质量、跨语言一致的金标准分词数据，但这类数据在许多语言中不可用或质量不一。

Method: 提出一种新指标，利用通用依存关系（UD）或UniMorph等资源中的形态句法特征，通过IBM Model 1对子词与形态特征进行概率对齐。

Result: 实验表明该指标与传统的词素边界召回率高度相关，且适用于更多具有不同形态系统的语言。

Conclusion: 该指标在保持与传统评估一致性的同时，显著提升了跨语言适用性与实用性。

Abstract: We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.

</details>


### [262] [Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection](https://arxiv.org/abs/2601.18552)
*Devansh Srivastav,David Pape,Lea Schönherr*

Main category: cs.CL

TL;DR: 本文提出了'隐藏意图'的概念，即大语言模型（LLM）中难以察觉但具有目标导向性的行为，并构建了涵盖10类的分类体系；通过实验证明其易被诱导且在开放世界场景下极难检测，尤其在低发生率条件下检测性能急剧下降；研究强调亟需建立鲁棒的评估与治理框架。


<details>
  <summary>Details</summary>
Motivation: LLM日益融入日常决策，但其输出可能隐含难以察觉的、影响用户信念与行为的‘隐藏意图’，这些意图可能源于训练偏差或恶意诱导，却缺乏系统性分析与有效检测手段。

Method: 提出基于社会科学研究的10类隐藏意图分类法（按意图、机制、情境与影响组织）；在可控模型中诱导隐藏意图以构建测试基准；系统评估多种检测方法（含推理型与非推理型LLM判别器），并在开放世界、低发生率等现实条件下进行压力测试；开展定性案例研究验证其在实际部署模型中的存在性。

Result: 隐藏意图可被轻易诱导；现有检测方法在开放世界尤其低发生率场景下失效（高假阳性/假阴性）；精度-发生率与精度-漏检率权衡分析揭示审计失败的根本原因；所有10类隐藏意图均在现役先进LLM中被实证发现。

Conclusion: 隐藏意图是LLM真实且紧迫的风险，当前检测方法在现实条件下严重不足；需建立兼顾可扩展性、鲁棒性与可解释性的新型评估与治理框架，并依托该分类法持续预判新兴威胁。

Abstract: LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.

</details>


### [263] [One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization](https://arxiv.org/abs/2601.18572)
*Franziska Weeber,Vera Neplenbroek,Jan Batzner,Sebastian Padó*

Main category: cs.CL

TL;DR: 本文研究了使用不同社会人口学线索（persona cues）对大语言模型（LLM）进行个性化时的偏差与鲁棒性问题，发现单一线索易导致结果不可靠，建议未来研究采用多种外部有效线索进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有基于单一persona cue（如姓名或显式属性）的研究忽视了LLM对提示变化的敏感性（鲁棒性）及某些线索在真实交互中的稀有性（外部效度）。

Method: 在七个开源与商业大语言模型上，系统比较六种常用persona cues在四项写作与建议任务中的表现，并分析响应差异与线索间相关性。

Result: 六种persona cues总体高度相关，但在不同persona下仍引发显著响应差异；单一cue得出的结论缺乏稳健性与外部有效性。

Conclusion: 不应仅依赖单一persona cue得出关于LLM偏见或个性化效果的结论；未来研究应采用多种、更具外部效度的persona cues进行综合评估。

Abstract: Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.

</details>


### [264] [From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection](https://arxiv.org/abs/2601.18582)
*Yuan Cao,Feixiang Liu,Xinyue Wang,Yihan Zhu,Hui Xu,Zheng Wang,Qiang Qiu*

Main category: cs.CL

TL;DR: 本文提出一种基于强化学习的个性检测新方法，将个性检测视为排序任务而非分类任务，并设计了专门的排序奖励函数和Group Relative Policy Optimization (GRPO)训练范式，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的个性检测方法依赖专家设计的提示词，缺乏自主模式学习能力，且难以处理人格特质间模糊边界和主观性问题。

Method: 将个性检测建模为排序任务，先通过监督微调（SFT）初始化模型的排序能力并规范输出格式，再采用Group Relative Policy Optimization（GRPO）结合专为排序设计的奖励函数进行强化学习训练。

Result: 在多个个性检测基准上达到当前最优性能（state-of-the-art）。

Conclusion: 将个性检测转化为排序任务并引入适配主观性与模糊边界的强化学习范式，能有效提升大语言模型在此任务上的表现，克服传统提示工程与分类范式的局限。

Abstract: Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.

</details>


### [265] [Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning](https://arxiv.org/abs/2601.18722)
*Lintang Sutawika,Gokul Swamy,Zhiwei Steven Wu,Graham Neubig*

Main category: cs.CL

TL;DR: 本文提出SP3F框架，通过自博弈与特权成对反馈，在无需目标语言数据的情况下提升大语言模型的多语言推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前推理型大语言模型在低资源语言上的表现远逊于英语，亟需不依赖目标语言数据的多语言推理增强方法。

Method: SP3F包含两阶段：1）基于翻译的英文问答对进行监督微调（SFT）；2）利用拥有英文参考答案作为特权信息的成对判别器进行自博弈式强化学习（RL）。

Result: SP3F显著提升基线模型在多语言、单语言及未见语言泛化任务上的性能，且仅用更少训练数据即超越完全后训练模型。

Conclusion: SP3F证明了无需目标语言标注数据、仅靠英文监督与特权反馈即可有效提升多语言推理能力，为低资源语言推理提供了新范式。

Abstract: When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than
  of the training data across the single-language, multilingual, and generalization to unseen language settings.

</details>


### [266] [HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences](https://arxiv.org/abs/2601.18724)
*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 本文系统研究了学术论文中幻觉引用（HalluCitation）现象的普遍性与影响，发现ACL、NAACL和EMNLP 2024–2025年会议论文中近300篇存在此类问题，尤以EMNLP 2025最为严重，半数集中于此，且超100篇为主会或Findings录用论文，严重威胁学术可信度。


<details>
  <summary>Details</summary>
Motivation: 幻觉引用（即虚构的、不存在的参考文献）频现于投稿、预印本及已发表论文中，损害科学可靠性，并可能削弱会议公信力，亟需系统调查。

Method: 对ACL、NAACL和EMNLP在2024与2025年所有主会、Findings及 workshop 论文进行大规模实证分析，识别并统计HalluCitation的数量、分布与接受状态。

Result: 共发现近300篇含HalluCitation的论文，其中约150篇集中于EMNLP 2025；超100篇为EMNLP 2025主会或Findings录用论文。

Conclusion: HalluCitation问题正在快速加剧，尤其在最新顶会中高发，已对学术出版生态和会议信誉构成实质性威胁，需引起学界高度重视并建立检测与防范机制。

Abstract: Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.

</details>


### [267] [Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale](https://arxiv.org/abs/2601.18730)
*Henry Bell,Caroline Zhang,Mohammed Mobasserul Haque,Dhaval Potdar,Samia Zaman,Brandon Fain*

Main category: cs.CL

TL;DR: 本文提出了一种名为REFLECT的推理时（inference-time）宪法对齐框架，无需训练或标注数据，通过在上下文中显式地基于原则进行自我评估、自我批评和最终修订，提升大语言模型对价值原则的遵循能力，同时保持事实推理能力，并能生成用于后续微调的高质量训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法（如RLHF）依赖参数微调，计算开销大、工程复杂、需大量人工标注，难以灵活适配多样或新原则。

Method: REFLECT是一种纯推理时、零训练、零数据的框架，包含四步：(i) 基于宪法生成初始响应；(ii) 自我评估是否符合原则；(iii)(a) 自我批评指出违规点；(iii)(b) 基于批评修订输出；全程在上下文中完成，无需修改模型参数。

Result: REFLECT显著提升LLM对多样化、复杂原则（包括与原始微调不一致的原则）的遵守率；有效降低尾部罕见但严重的原则违反；不损害事实推理能力；并能自动生成高质量监督数据用于后续微调。

Conclusion: REFLECT提供了一种轻量、透明、可插拔的对齐范式，弥补了训练时对齐的灵活性与效率短板，兼具即刻部署能力与长期可扩展性。

Abstract: The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.

</details>


### [268] [One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment](https://arxiv.org/abs/2601.18731)
*Hongru Cai,Yongqi Li,Tiezheng Yu,Fengbin Zhu,Wenjie Wang,Fuli Feng,Wenjie Li*

Main category: cs.CL

TL;DR: 本文提出元奖励建模（MRM）方法，将个性化奖励建模视为元学习问题，通过MAML风格框架优化基础奖励函数权重初始化，结合鲁棒个性化目标（RPO），在少量反馈下实现对新用户的快速、鲁棒个性化适配。


<details>
  <summary>Details</summary>
Motivation: 解决个性化对齐中个体用户反馈稀缺和难以高效适配未见用户两大挑战，需从拟合偏好数据转向学习偏好适应过程。

Method: 提出Meta Reward Modeling（MRM），将用户奖励模型表示为若干基础奖励函数的加权组合，并采用MAML式元学习优化权重初始化；引入Robust Personalization Objective（RPO）在元优化中加强对难学习用户的关注。

Result: 在多个个性化偏好数据集上实验表明，MRM显著提升少样本个性化能力、用户鲁棒性，并持续优于各类基线方法。

Conclusion: MRM通过元学习范式有效应对个性化奖励建模中的数据稀疏与泛化难题，为LLM个性化对齐提供了新思路与实用框架。

Abstract: Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.

</details>


### [269] [Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings](https://arxiv.org/abs/2601.18788)
*Mumin Jia,Jairo Diaz-Rodriguez*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的无监督文本分割方法Embed-KCPD，利用句子嵌入向量和带惩罚的KCPD目标函数检测边界，并首次为m-依赖序列建立了KCPD的依赖感知理论，同时设计了基于大语言模型的仿真框架验证理论预测。


<details>
  <summary>Details</summary>
Motivation: 无监督文本分割至关重要，因为边界标注成本高、主观性强，且难以跨领域和不同粒度迁移。

Method: 提出Embed-KCPD：将句子表示为嵌入向量，通过最小化带惩罚的KCPD（核变点检测）目标函数估计边界；建立适用于m-依赖序列的KCPD理论；设计基于LLM的仿真框架生成具有可控有限记忆依赖和已知边界的合成文档。

Result: 理论方面证明了总体惩罚风险的oracle不等式及定位保证（每个真实变点可在相对于段长较小的窗口内被恢复）；实验上在标准分割基准上常优于强无监督基线；在Taylor Swift推文案例中验证了其理论保证、仿真可靠性与实际有效性。

Conclusion: Embed-KCPD是一种兼具坚实理论基础、可验证可靠性与实用性能的无监督文本分割方法，为解决标注稀缺与依赖建模问题提供了新范式。

Abstract: Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.

</details>


### [270] [MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts](https://arxiv.org/abs/2601.18790)
*Etienne Lanzeray,Stephane Meilliez,Malo Ruelle,Damien Sileo*

Main category: cs.CL

TL;DR: 本文提出MortalMATH基准，揭示专注深度推理的大模型在用户遭遇生命危险时仍执着完成数学任务，忽视安全响应，暴露出‘隧道视野’风险。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型过度优化深度推理能力是否导致其在紧急安全场景下丧失基本风险识别与响应能力（即‘隧道视野’问题）。

Method: 构建包含150个生命威胁场景的MortalMATH基准，测试通用模型（如Llama-3.1）与专用推理模型（如Qwen-3-32b、GPT-5-nano）在用户求助代数计算同时描述急症（如中风、自由落体）时的响应行为，并测量响应延迟。

Result: 通用模型大多能拒绝计算、优先响应危机；而专用推理模型95%以上仍坚持完成数学任务，且推理耗时高达15秒，严重延误救助。

Conclusion: 过度强调任务准确性的训练范式可能削弱模型的安全本能，需在推理能力与安全意识间重新平衡。

Abstract: Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a "tunnel vision" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.

</details>


### [271] [Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets](https://arxiv.org/abs/2601.18791)
*Iaroslav Chelombitko,Mika Hämäläinen,Aleksey Komissarov*

Main category: cs.CL

TL;DR: 本文通过构建基于维基百科词典的'glottosets'，利用字节对编码（BPE）对242种拉丁和西里尔字母语言进行大规模跨语言比较研究，发现BPE分词在形态边界对齐上显著优于随机基线，并且其词汇相似性与语言的谱系关系高度相关。


<details>
  <summary>Details</summary>
Motivation: 旨在建立一个统一的分析框架，以大规模、定量的方式比较不同语言间的词汇模式，尤其是拉丁和西里尔字母书写系统的语言。

Method: 基于维基百科词典构建'glottosets'，采用字节对编码（BPE）进行子词分割，使用基于秩的子词向量分析词汇重叠、词汇分化和语言相似性，并评估BPE对形态边界的对齐能力及与语言谱系关系的相关性。

Result: BPE分词在15种语言中对形态边界的对齐F1值达0.34，远高于随机基线（0.15）；BPE词汇相似性与语言遗传相关性显著相关（Mantel r = 0.329, p < 0.001）；罗曼语族聚类最紧密（平均距离0.51），跨语系对明显分离（0.82）；48.7%的跨语言同形词在相关语言中被不同地切分，且切分差异与系统发育距离相关。

Conclusion: 该研究为宏观语言学提供了跨类型语言词汇模式的量化洞见，并验证了BPE在语言比较中的有效性与语言学意义。

Abstract: We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.

</details>


### [272] [ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models](https://arxiv.org/abs/2601.18796)
*Brian Ondov,Chia-Hsuan Chang,Yujia Zhou,Mauro Giuffrè,Hua Xu*

Main category: cs.CL

TL;DR: 本文提出了一种将大语言模型（LLM）与临床试验文本嵌入对齐的新方法——Embedding Language Model（ELM），并开源了通用框架与专家验证的合成数据集；最终模型ctELM能从嵌入反推可读、合理的临床试验描述，并支持基于语义方向（如年龄、性别）可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入缺乏可解释性、可探索性和可逆性，限制了其透明度和生成潜力，尤其在临床等高价值领域亟需嵌入-语言双向对齐工具。

Method: 构建开源、领域无关的ELM架构与训练框架；为临床试验设计专用训练任务；创建专家验证的合成数据集；系统评估不同任务与训练策略对ELM性能的影响。

Result: ctELM模型能仅凭嵌入准确描述和比较未见临床试验，并从新嵌入向量生成合理试验摘要；生成摘要可响应沿‘年龄’‘性别’概念向量的嵌入移动，体现语义可控性。

Conclusion: ELM是一种有效对齐嵌入空间与语言模型的通用范式，本工作推动了生物医学等领域嵌入空间的可解释性与生成式应用，代码与实验结果已公开。

Abstract: Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [273] [Embodiment-Induced Coordination Regimes in Tabular Multi-Agent Q-Learning](https://arxiv.org/abs/2601.17454)
*Muhammad Ahmed Atif,Nehal Naeem Haji,Mohammad Shahid Shaikh,Muhammad Ebad Atif*

Main category: cs.MA

TL;DR: 本文在完全表格化的捕食者-猎物网格世界中，通过控制实验检验了集中式值学习是否真能提升多智能体强化学习中的协调性与稳定性。结果表明，在考虑智能体运动学约束（如速度和耐力）时，集中式Q学习并不总优于独立学习，甚至常被后者超越；且集中-独立混合配置会导致持续的协调失败。研究指出，集中式学习的效果高度依赖于具体任务场景和角色设定，并非普适有效。


<details>
  <summary>Details</summary>
Motivation: 集中式值学习常被假设可提升多智能体强化学习中的协调性与稳定性，但该假设极少在受控条件下被严格检验。本文旨在通过消除函数逼近与表征学习等干扰因素，直接评估协调结构本身对学习效果的影响。

Method: 在完全表格化的捕食者-猎物网格世界中，对比独立Q学习与集中式Q学习；引入显式的智能体运动学约束（速度、耐力）及不对称角色设定；在全观测、精确值估计条件下进行多组对照实验。

Result: 集中式学习未表现出一致优势，常被独立学习超越；集中-独立混合配置导致持续而非暂时的协调失败；协调能力增强在具身约束下反而可能成为负担；集中式学习效果高度依赖于动力学机制与角色分配。

Conclusion: 集中式值学习并非普遍提升多智能体协调性的万能方案；其有效性本质上是任务依赖的，需结合智能体具身约束与角色分工综合考量。

Abstract: Centralized value learning is often assumed to improve coordination and stability in multi-agent reinforcement learning, yet this assumption is rarely tested under controlled conditions. We directly evaluate it in a fully tabular predator-prey gridworld by comparing independent and centralized Q-learning under explicit embodiment constraints on agent speed and stamina. Across multiple kinematic regimes and asymmetric agent roles, centralized learning fails to provide a consistent advantage and is frequently outperformed by fully independent learning, even under full observability and exact value estimation. Moreover, asymmetric centralized-independent configurations induce persistent coordination breakdowns rather than transient learning instability. By eliminating confounding effects from function approximation and representation learning, our tabular analysis isolates coordination structure as the primary driver of these effects. The results show that increased coordination can become a liability under embodiment constraints, and that the effectiveness of centralized learning is fundamentally regime and role dependent rather than universal.

</details>


### [274] [VissimRL: A Multi-Agent Reinforcement Learning Framework for Traffic Signal Control Based on Vissim](https://arxiv.org/abs/2601.18284)
*Hsiao-Chuan Chang,Sheng-You Huang,Yen-Chi Chen,I-Chen Wu*

Main category: cs.MA

TL;DR: 本文提出VissimRL——一个面向交通信号控制（TSC）的模块化强化学习（RL）框架，封装了高保真交通仿真器VISSIM的COM接口，提供标准化单/多智能体训练环境，显著降低开发门槛并支持实际性能提升与多智能体协同涌现。


<details>
  <summary>Details</summary>
Motivation: VISSIM虽具高保真驾驶行为建模和工业广泛应用优势，但因接口复杂、缺乏标准化RL框架，其在强化学习研究中未被充分利用。

Method: 设计并实现VissimRL框架：通过高层Python API封装VISSIM的COM接口，构建模块化、可扩展的单智能体与多智能体RL训练环境。

Result: 实验表明VissimRL大幅减少开发工作量、保持运行效率，并在训练中持续提升交通性能指标（如延误、排队长度），且在多智能体设置下展现出协同控制能力。

Conclusion: VissimRL验证了在高保真仿真环境中应用RL进行交通信号控制的可行性，有效弥合了学术研究与工业落地之间的鸿沟。

Abstract: Traffic congestion remains a major challenge for urban transportation, leading to significant economic and environmental impacts. Traffic Signal Control (TSC) is one of the key measures to mitigate congestion, and recent studies have increasingly applied Reinforcement Learning (RL) for its adaptive capabilities. With respect to SUMO and CityFlow, the simulator Vissim offers high-fidelity driver behavior modeling and wide industrial adoption but remains underutilized in RL research due to its complex interface and lack of standardized frameworks. To address this gap, this paper proposes VissimRL, a modular RL framework for TSC that encapsulates Vissim's COM interface through a high-level Python API, offering standardized environments for both single- and multi-agent training. Experiments show that VissimRL significantly reduces development effort while maintaining runtime efficiency, and supports consistent improvements in traffic performance during training, as well as emergent coordination in multi-agent control. Overall, VissimRL demonstrates the feasibility of applying RL in high-fidelity simulations and serves as a bridge between academic research and practical applications in intelligent traffic signal control.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [275] [Frequency-aware Adaptive Contrastive Learning for Sequential Recommendation](https://arxiv.org/abs/2601.17057)
*Zhikai Wang,Weihua Zhang*

Main category: cs.IR

TL;DR: 本文提出了一种频率感知的自适应对比学习框架FACL，用于解决序列推荐中数据增强对低频物品和稀疏用户行为的固有偏差问题。该框架通过微观层面的自适应扰动保护罕见物品完整性，并通过宏观层面的重加权增强稀疏交互序列的影响。实验表明FACL在多个基准数据集上显著优于现有方法，并有效缓解长尾场景下的性能下降。


<details>
  <summary>Details</summary>
Motivation: 揭示了对比学习中数据增强对低频物品和稀疏用户行为的固有偏差问题。

Method: 提出了FACL框架，包含微观层面的自适应扰动和宏观层面的重加权机制。

Result: 在五个公开基准数据集上，FACL比现有方法最高提升3.8%推荐准确率，并显著缓解低频物品和用户的性能下降。

Conclusion: FACL具有鲁棒的意图保持能力，适用于真实世界中的长尾推荐场景。

Abstract: In this paper, we revisited the role of data augmentation in contrastive learning for sequential recommendation, revealing its inherent bias against low-frequency items and sparse user behaviors. To address this limitation, we proposed FACL, a frequency-aware adaptive contrastive learning framework that introduces micro-level adaptive perturbation to protect the integrity of rare items, as well as macro-level reweighting to amplify the influence of sparse and rare-interaction sequences during training. Comprehensive experiments on five public benchmark datasets demonstrated that FACL consistently outperforms state-of-the-art data augmentation and model augmentation-based methods, achieving up to 3.8% improvement in recommendation accuracy. Moreover, fine-grained analyses confirm that FACL significantly alleviates the performance drop on low-frequency items and users, highlighting its robust intent-preserving ability and its superior applicability to real-world, long-tail recommendation scenarios.

</details>


### [276] [Evaluation on Entity Matching in Recommender Systems](https://arxiv.org/abs/2601.17218)
*Zihan Huang,Rohan Surana,Zhouhang Xie,Junda Wu,Yu Xia,Julian McAuley*

Main category: cs.IR

TL;DR: 本文提出了Reddit-Amazon-EM数据集，用于跨数据集实体匹配评估，并系统评测了多种主流实体匹配方法，同时开源标注数据和映射结果以促进可复现研究。


<details>
  <summary>Details</summary>
Motivation: 缺乏严格的跨数据集实体匹配评估框架，阻碍了LLM驱动的对话推荐和知识增强型数据集构建等方向的发展。

Method: 构建了Reddit-Amazon-EM数据集，通过人工标注建立Reddit-Movies与Amazon'23中电影的对应关系，并对规则、图、词法、嵌入及大语言模型（LLM）等多种实体匹配方法进行系统评估。

Result: 提供了人工标注的实体匹配黄金标准集，并基于实验最优方法发布了两个数据集间的映射关系。

Conclusion: Reddit-Amazon-EM为推荐系统中的实体匹配研究提供了新基准和实用资源，推动该领域可复现与可扩展发展。

Abstract: Entity matching is a crucial component in various recommender systems, including conversational recommender systems (CRS) and knowledge-based recommender systems. However, the lack of rigorous evaluation frameworks for cross-dataset entity matching impedes progress in areas such as LLM-driven conversational recommendations and knowledge-grounded dataset construction.
  In this paper, we introduce Reddit-Amazon-EM, a novel dataset comprising naturally occurring items from Reddit and the Amazon '23 dataset. Through careful manual annotation, we identify corresponding movies across Reddit-Movies and Amazon'23, two existing recommender system datasets with inherently overlapping catalogs. Leveraging Reddit-Amazon-EM, we conduct a comprehensive evaluation of state-of-the-art entity matching methods, including rule-based, graph-based, lexical-based, embedding-based, and LLM-based approaches.
  For reproducible research, we release our manually annotated entity matching gold set and provide the mapping between the two datasets using the best-performing method from our experiments. This serves as a valuable resource for advancing future work on entity matching in recommender systems.

</details>


### [277] [FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search](https://arxiv.org/abs/2601.17333)
*Lalit Pant,Shivang Nagar*

Main category: cs.IR

TL;DR: 本文提出了一种面向金融知识搜索的现代自然语言查询（NLQ）系统技术蓝图，融合NLP、搜索工程与向量数据模型，以提升检索精度、召回率及跨金融实体的深度关联分析能力。


<details>
  <summary>Details</summary>
Motivation: 传统金融知识检索方法在精度、召回率及跨实体关系挖掘方面存在不足，亟需支持自然语言交互、适应金融数据特性的NLQ系统。

Method: 结合自然语言处理、搜索工程与向量数据模型，构建支持离线索引与在线检索的NLQ系统架构，并针对金融数据特点优化实体识别、相关性排序、数据新鲜度与发现能力。

Result: 该NLQ系统显著提升了金融知识搜索的精度与召回率，支持对金融对象、事件和关系的高效链接与深度洞察，并通过实验验证了其有效性。

Conclusion: 本文为金融领域NLQ系统的设计提供了完整技术框架与实证分析，明确了关键挑战、架构方案与未来优化方向，具有实际落地价值与理论参考意义。

Abstract: Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.

</details>


### [278] [Beyond Correlations: A Downstream Evaluation Framework for Query Performance Prediction](https://arxiv.org/abs/2601.17339)
*Payel Santra,Partha Basuchowdhuri,Debasis Ganguly*

Main category: cs.IR

TL;DR: 本文提出了一种面向下游任务的查询性能预测（QPP）评估框架，将QPP估计值作为信息检索（IR）融合的先验分布，验证其在实际IR流水线中的有效性，发现下游效果与传统相关性评估指标并不强相关。


<details>
  <summary>Details</summary>
Motivation: 传统QPP评估仅依赖集合级相关性，无法反映单个查询的预测效果，也未与下游应用（如IR融合）挂钩，导致高相关性方法未必实用。

Method: 构建下游聚焦的评估框架：利用多个排序器返回的顶部文档列表上的QPP估计分布作为先验，用于加权IR融合（如CombSUM、RRF）；通过融合效果衡量QPP的实际价值。

Result: 实验表明：（1）基于QPP估计的加权IR融合比无权重策略提升超4.5%；（2）QPP在下游任务中的有效性与其在标准相关性评估中的表现弱相关。

Conclusion: QPP评估应结合下游任务实效性，而非仅依赖相关性指标；该框架为QPP方法的实际部署提供了更合理的评估依据。

Abstract: The standard practice of query performance prediction (QPP) evaluation is to measure a set-level correlation between the estimated retrieval qualities and the true ones. However, neither this correlation-based evaluation measure quantifies QPP effectiveness at the level of individual queries, nor does this connect to a downstream application, meaning that QPP methods yielding high correlation values may not find a practical application in query-specific decisions in an IR pipeline. In this paper, we propose a downstream-focussed evaluation framework where a distribution of QPP estimates across a list of top-documents retrieved with several rankers is used as priors for IR fusion. While on the one hand, a distribution of these estimates closely matching that of the true retrieval qualities indicates the quality of the predictor, their usage as priors on the other hand indicates a predictor's ability to make informed choices in an IR pipeline. Our experiments firstly establish the importance of QPP estimates in weighted IR fusion, yielding substantial improvements of over 4.5% over unweighted CombSUM and RRF fusion strategies, and secondly, reveal new insights that the downstream effectiveness of QPP does not correlate well with the standard correlation-based QPP evaluation.

</details>


### [279] [Breaking Flat: A Generalised Query Performance Prediction Evaluation Framework](https://arxiv.org/abs/2601.17359)
*Payel Santra,Partha Basuchowdhuri,Debasis Ganguly*

Main category: cs.IR

TL;DR: 本文扩展了查询性能预测（QPP）任务，提出三种新设定：单排序器多查询（SRMQ-PP）、多排序器单查询（MRSQ-PP）和多排序器多查询（MRMQ-PP），并发现MRSQ-PP比SRMQ-PP更难，且不同设定下QPP模型表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 传统QPP仅预测查询在固定排序器下的性能，而实际应用中更需为给定查询选择最优排序器，因此需推广QPP任务以支持多排序器场景。

Method: 提出三种QPP任务设定（SRMQ-PP、MRSQ-PP、MRMQ-PP），并在统一框架下评估多种QPP模型在各设定下的性能。

Result: 实验表明：(a) QPP模型在SRMQ-PP与MRSQ-PP上的相对性能差异显著；(b) 预测查询对应的最佳排序器（MRSQ-PP）比预测查询在固定排序器下的难易程度（SRMQ-PP）更具挑战性。

Conclusion: QPP任务需根据应用场景细化设定，MRSQ-PP是更实用但也更困难的方向，现有QPP方法在此设定下表现不足，需针对性改进。

Abstract: The traditional use-case of query performance prediction (QPP) is to identify which queries perform well and which perform poorly for a given ranking model. A more fine-grained and arguably more challenging extension of this task is to determine which ranking models are most effective for a given query. In this work, we generalize the QPP task and its evaluation into three settings: (i) SingleRanker MultiQuery (SRMQ-PP), corresponding to the standard use case; (ii) MultiRanker SingleQuery (MRSQ-PP), which evaluates a QPP model's ability to select the most effective ranker for a query; and (iii) MultiRanker MultiQuery (MRMQ-PP), which considers predictions jointly across all query ranker pairs. Our results show that (a) the relative effectiveness of QPP models varies substantially across tasks (SRMQ-PP vs. MRSQ-PP), and (b) predicting the best ranker for a query is considerably more difficult than predicting the relative difficulty of queries for a given ranker.

</details>


### [280] [UniGRec: Unified Generative Recommendation with Soft Identifiers for End-to-End Optimization](https://arxiv.org/abs/2601.17438)
*Jialei Li,Yang Zhang,Yimeng Bai,Shuai Zhu,Ziqi Xue,Xiaoyan Zhao,Dingxian Wang,Frank Yang,Andrew Rabinovich,Xiangnan He*

Main category: cs.IR

TL;DR: 本文提出UniGRec框架，通过可微软标识符统一生成式推荐中的分词器与推荐器，实现端到端联合训练，并引入三种机制解决软硬不一致、标识符坍缩和协同信号不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法常将分词与推荐解耦或采用异步交替优化，难以实现完全端到端对齐，限制了性能提升。

Method: 提出UniGRec框架：1）退火推理对齐（Annealed Inference Alignment）缓解训练-推理差异；2）码字均匀性正则化（Codeword Uniformity Regularization）防止标识符坍缩；3）双协同蒸馏（Dual Collaborative Distillation）从轻量教师模型中蒸馏协同先验以联合指导分词器与推荐器。

Result: 在多个真实数据集上的实验表明，UniGRec持续优于当前最先进的基线方法。

Conclusion: 统一建模分词与推荐并协同优化二者，能有效提升生成式推荐性能；所提三项技术分别针对性地解决了端到端训练中的关键挑战。

Abstract: Generative recommendation has recently emerged as a transformative paradigm that directly generates target items, surpassing traditional cascaded approaches. It typically involves two components: a tokenizer that learns item identifiers and a recommender trained on them. Existing methods often decouple tokenization from recommendation or rely on asynchronous alternating optimization, limiting full end-to-end alignment. To address this, we unify the tokenizer and recommender under the ultimate recommendation objective via differentiable soft item identifiers, enabling joint end-to-end training. However, this introduces three challenges: training-inference discrepancy due to soft-to-hard mismatch, item identifier collapse from codeword usage imbalance, and collaborative signal deficiency due to an overemphasis on fine-grained token-level semantics.
  To tackle these challenges, we propose UniGRec, a unified generative recommendation framework that addresses them from three perspectives. UniGRec employs Annealed Inference Alignment during tokenization to smoothly bridge soft training and hard inference, a Codeword Uniformity Regularization to prevent identifier collapse and encourage codebook diversity, and a Dual Collaborative Distillation mechanism that distills collaborative priors from a lightweight teacher model to jointly guide both the tokenizer and the recommender. Extensive experiments on real-world datasets demonstrate that UniGRec consistently outperforms state-of-the-art baseline methods. Our codes are available at https://github.com/Jialei-03/UniGRec.

</details>


### [281] [Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features](https://arxiv.org/abs/2601.17472)
*Junyou He,Lixi Deng,Huichao Guo,Ye Tang,Yong Li,Sulong Xu*

Main category: cs.IR

TL;DR: 本文提出A²DCDR模型，通过对抗对齐与特征解耦，融合域不变、非对齐及上下文特征，提升跨域推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨域推荐方法仅依赖域不变特征与目标域特有特征，忽略有价值的非对齐特征，导致性能受限。

Method: 提出A²DCDR模型：1）用对抗训练改进MMD以增强泛化；2）设计特征解耦器与重建机制实现域内解耦；3）构建融合表示（域不变+非对齐+原始上下文特征）。

Result: 在真实数据集和线上A/B测试中，A²DCDR显著优于现有方法。

Conclusion: 融合多种跨域信息的建模方式更有效，A²DCDR兼具理论创新与实际应用价值。

Abstract: Cross-domain recommendation (CDR) has been increasingly explored to address data sparsity and cold-start issues. However, recent approaches typically disentangle domain-invariant features shared between source and target domains, as well as domain-specific features for each domain. However, they often rely solely on domain-invariant features combined with target domain-specific features, which can lead to suboptimal performance. To overcome the limitations, this paper presents the Adversarial Alignment and Disentanglement Cross-Domain Recommendation ($A^2DCDR$ ) model, an innovative approach designed to capture a comprehensive range of cross-domain information, including both domain-invariant and valuable non-aligned features. The $A^2DCDR$ model enhances cross-domain recommendation through three key components: refining MMD with adversarial training for better generalization, employing a feature disentangler and reconstruction mechanism for intra-domain disentanglement, and introducing a novel fused representation combining domain-invariant, non-aligned features with original contextual data. Experiments on real-world datasets and online A/B testing show that $A^2DCDR$ outperforms existing methods, confirming its effectiveness and practical applicability. The code is provided at https://github.com/youzi0925/A-2DCDR/tree/main.

</details>


### [282] [Towards Fair Large Language Model-based Recommender Systems without Costly Retraining](https://arxiv.org/abs/2601.17492)
*Jin Li,Huilin Gu,Shoujin Wang,Qi Zhang,Shui Yu,Chen Wang,Xiwei Xu,Fang Chen*

Main category: cs.IR

TL;DR: 本文提出FUDLR方法，通过将去偏问题重构为高效的机器遗忘任务，以解决大语言模型推荐系统（LLM-RS）中的公平性问题，兼顾去偏效果与推荐准确性。


<details>
  <summary>Details</summary>
Motivation: LLM-RS易继承训练数据中的偏见，导致严重公平性问题；现有去偏方法缺乏通用性且重训练计算成本过高。

Method: 提出FUDLR框架：第一阶段用偏差无关掩码识别需遗忘的偏差样本；第二阶段通过估计并移除这些样本对模型参数的影响实现高效去偏。

Result: 实验表明FUDLR能有效提升公平性，同时保持推荐准确性，且无需全模型重训练。

Conclusion: FUDLR为构建社会负责的大语言模型推荐系统提供了一种实用、通用且高效的去偏路径。

Abstract: Large Language Models (LLMs) have revolutionized Recommender Systems (RS) through advanced generative user modeling. However, LLM-based RS (LLM-RS) often inadvertently perpetuates bias present in the training data, leading to severe fairness issues. Addressing these fairness problems in LLM-RS faces two significant challenges. 1) Existing debiasing methods, designed for specific bias types, lack the generality to handle diverse or emerging biases in real-world applications. 2) Debiasing methods relying on retraining are computationally infeasible given the massive parameter scale of LLMs. To overcome these challenges, we propose FUDLR (Fast Unified Debiasing for LLM-RS). The core idea is to reformulate the debiasing problem as an efficient machine unlearning task with two stages. First, FUDLR identifies bias-inducing samples to unlearn through a novel bias-agnostic mask, optimized to balance fairness improvement with accuracy preservation. Its bias-agnostic design allows adaptability to various or co-existing biases simply by incorporating different fairness metrics. Second, FUDLR performs efficient debiasing by estimating and removing the influence of identified samples on model parameters. Extensive experiments demonstrate that FUDLR effectively and efficiently improves fairness while preserving recommendation accuracy, offering a practical path toward socially responsible LLM-RS. The code and data are available at https://github.com/JinLi-i/FUDLR.

</details>


### [283] [To Case or Not to Case: An Empirical Study in Learned Sparse Retrieval](https://arxiv.org/abs/2601.17500)
*Emmanouil Georgios Lionis,Jia-Huei Ju,Angelos Nalmpantis,Casper Thuis,Sean MacAvaney,Andrew Yates*

Main category: cs.IR

TL;DR: 本文系统评估了大小写敏感（cased）与不敏感（uncased）骨干模型对学习型稀疏检索（LSR）性能的影响，发现直接使用cased模型会显著降低性能，但通过简单的小写预处理即可消除性能差距；分析表明，小写处理后cased模型实际退化为类似uncased模型的行为。


<details>
  <summary>Details</summary>
Motivation: 最新SOTA语言模型多为cased版本，而现有LSR方法主要依赖uncased模型，二者存在适配 gap，且该问题尚未被系统研究，可能威胁LSR方法的持续发展。

Method: 在多个数据集上，对同一骨干模型的cased与uncased版本进行配对实验评估，并引入小写预处理；辅以token-level分析探究模型词汇使用行为。

Result: cased模型默认表现远差于uncased模型；小写预处理可完全消除性能差距；token分析显示小写后cased模型几乎完全抑制cased词汇，行为趋近uncased模型。

Conclusion: 小写预处理使最新cased骨干模型可直接、高效地应用于LSR，拓展了其适用性，并支持引入更强骨干架构提升稀疏检索性能。

Abstract: Learned Sparse Retrieval (LSR) methods construct sparse lexical representations of queries and documents that can be efficiently searched using inverted indexes. Existing LSR approaches have relied almost exclusively on uncased backbone models, whose vocabularies exclude case-sensitive distinctions, thereby reducing vocabulary mismatch. However, the most recent state-of-the-art language models are only available in cased versions. Despite this shift, the impact of backbone model casing on LSR has not been studied, potentially posing a risk to the viability of the method going forward. To fill this gap, we systematically evaluate paired cased and uncased versions of the same backbone models across multiple datasets to assess their suitability for LSR. Our findings show that LSR models with cased backbone models by default perform substantially worse than their uncased counterparts; however, this gap can be eliminated by pre-processing the text to lowercase. Moreover, our token-level analysis reveals that, under lowercasing, cased models almost entirely suppress cased vocabulary items and behave effectively as uncased models, explaining their restored performance. This result broadens the applicability of recent cased models to the LSR setting and facilitates the integration of stronger backbone architectures into sparse retrieval. The complete code and implementation for this project are available at: https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR

</details>


### [284] [Pipeline Inspection, Visualization, and Interoperability in PyTerrier](https://arxiv.org/abs/2601.17502)
*Emmanouil Georgios Lionis,Craig Macdonald,Sean MacAvaney*

Main category: cs.IR

TL;DR: PyTerrier 提供了一个声明式框架，用于构建和实验信息检索（IR）管道，并新增了支持程序化检查、可视化及通过模型上下文协议（MCP）集成其他工具的管道操作。


<details>
  <summary>Details</summary>
Motivation: 提升 IR 管道的可理解性、可调试性与可集成性，便于研究人员、学生及 AI 代理使用。

Method: 引入支持程序化检查、可视化及 MCP 集成的新 pipeline 操作。

Result: 增强了 PyTerrier 管道的可解释性、可观测性与互操作性。

Conclusion: 新功能使 IR 管道更易于理解、教学与协同开发，推动 IR 研究与教育的可复现性和可扩展性。

Abstract: PyTerrier provides a declarative framework for building and experimenting with Information Retrieval (IR) pipelines. In this demonstration, we highlight several recent pipeline operations that improve their ability to be programmatically inspected, visualized, and integrated with other tools (via the Model Context Protocol, MCP). These capabilities aim to make it easier for researchers, students, and AI agents to understand and use a wide array of IR pipelines.

</details>


### [285] [Real-Time Trend Prediction via Continually-Aligned LLM Query Generation](https://arxiv.org/abs/2601.17567)
*Zijing Hui,Wenhan Lyu,Shusen Wang,Li Chen,Chu Wang*

Main category: cs.IR

TL;DR: 本文提出RTTP框架，利用持续学习的大语言模型（CL-LLM）从新闻内容实时生成搜索查询，并结合互动强度与创作者权威性进行打分，从而在低流量搜索环境中提前发现长尾趋势；引入Mix-Policy DPO方法缓解灾难性遗忘，已在Meta产品中大规模部署，显著提升尾部趋势检测精度和查询生成准确率。


<details>
  <summary>Details</summary>
Motivation: 低流量搜索环境中因查询量稀疏导致趋势发现存在冷启动问题，传统基于关键词频率或查询激增的方法反应慢、效果差。

Method: 提出RTTP框架：1）使用持续学习的LLM（CL-LLM）将新闻内容直接转化为搜索式查询；2）基于用户互动强度与创作者权威性对生成查询打分；3）设计Mix-Policy DPO偏好学习方法，融合on-policy稳定性与off-policy新颖性以缓解灾难性遗忘。

Result: 在Facebook和Meta AI产品中落地部署，尾部趋势检测Precision@500提升91.4%，查询生成准确率提升19%；多周在线训练后性能保持稳定。

Conclusion: LLM生成的合成搜索信号，若经过对齐建模与持续更新，可有效突破低流量场景下的趋势感知延迟瓶颈，为实时趋势预测提供新范式。

Abstract: Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.

</details>


### [286] [Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts](https://arxiv.org/abs/2601.17601)
*Fangping Lan,Abdullah Aljebreen,Eduard C. Dragut*

Main category: cs.IR

TL;DR: 本文提出了一种以读者为中心的社交媒体超链接意图分类法，通过众包标注和大语言模型辅助，构建了包含6个顶层类别、26个细粒度类别的分类体系，并在1000条推文上验证了其有效性，发现广告、论证和分享是最常见意图。


<details>
  <summary>Details</summary>
Motivation: 以往研究多关注作者分享URL的动机，但这类意图难以实际观测；本文转向读者视角，探究用户如何理解社交媒体中URL背后的意图，以支持下游NLP与信息检索任务。

Method: 采用混合方法：先基于大规模众包标注进行自下而上的数据驱动探索，再利用大语言模型辅助生成类别名称与精确定义，最终构建结构化意图分类体系，并对1000条Twitter帖子进行人工标注与分析。

Result: 构建了一个含6个顶层类别、26个细粒度类别的超链接意图分类法；实证分析表明广告、论证和分享是三大最常见意图；该分类法可支撑意图感知的信息检索、推荐与内容理解。

Conclusion: 读者中心的URL意图分类是可行且有效的，所提出的分类法为社交媒体内容的理解与应用提供了可扩展、可复用的基础框架。

Abstract: URLs serve as bridges between social media platforms and the broader web, linking user-generated content to external information resources. On Twitter (X), approximately one in five tweets contains at least one URL, underscoring their central role in information dissemination. While prior studies have examined the motivations of authors who share URLs, such author-centered intentions are difficult to observe in practice. To enable broader downstream use, this work investigates reader-centered interpretations, i.e., how users perceive the intentions behind hyperlinks included in posts. We develop an intent taxonomy for including hyperlinks in social posts through a hybrid approach that begins with a bottom-up, data-driven process using large-scale crowdsourced annotations, and is then refined using large language model assistance to generate descriptive category names and precise definitions. The final taxonomy comprises 6 top-level categories and 26 fine-grained intention classes, capturing diverse communicative purposes. Applying this taxonomy, we annotate and analyze 1000 user posts, revealing that advertising, arguing, and sharing are the most prevalent intentions. This resulting taxonomy provides a foundation for intent-aware information retrieval and NLP applications, enabling more accurate retrieval, recommendation, and understanding of social media content.

</details>


### [287] [Agentic Search in the Wild: Intents and Trajectory Dynamics from 14M+ Real Search Requests](https://arxiv.org/abs/2601.17617)
*Jingjie Ning,João Coelho,Yibo Kong,Yunfan Long,Bruno Martins,João Magalhães,Jamie Callan,Chenyan Xiong*

Main category: cs.IR

TL;DR: 本文通过分析1444万次搜索请求的大规模日志，揭示了LLM驱动的搜索代理在多步信息检索中的行为模式，提出了CTAR指标衡量查询词与历史证据的关联性，并建议改进策略如重复感知的早停、意图自适应的检索预算和跨步上下文跟踪。


<details>
  <summary>Details</summary>
Motivation: IR社区缺乏对LLM驱动搜索代理在多步信息寻求任务中实际行为的实证理解。

Method: 基于DeepResearchGym开源API收集的搜索日志，进行会话切分、LLM驱动的意图与查询改写标注，并提出上下文驱动的术语采纳率（CTAR）指标来量化新查询词是否源自先前检索证据。

Result: 发现90%以上多轮会话不超过10步、89%步骤间隔小于1分钟；不同意图会话行为差异显著（如事实型高重复、推理型广探索）；54%新引入查询词出现在累积证据中，且来自多步前的检索结果。

Conclusion: 应为代理搜索设计重复感知的早停机制、意图适配的检索资源分配及显式的跨步上下文建模，并将公开匿名化日志以促进后续研究。

Abstract: LLM-powered search agents are increasingly being used for multi-step information seeking tasks, yet the IR community lacks empirical understanding of how agentic search sessions unfold and how retrieved evidence is used. This paper presents a large-scale log analysis of agentic search based on 14.44M search requests (3.97M sessions) collected from DeepResearchGym, i.e. an open-source search API accessed by external agentic clients. We sessionize the logs, assign session-level intents and step-wise query-reformulation labels using LLM-based annotation, and propose Context-driven Term Adoption Rate (CTAR) to quantify whether newly introduced query terms are traceable to previously retrieved evidence. Our analyses reveal distinctive behavioral patterns. First, over 90% of multi-turn sessions contain at most ten steps, and 89% of inter-step intervals fall under one minute. Second, behavior varies by intent. Fact-seeking sessions exhibit high repetition that increases over time, while sessions requiring reasoning sustain broader exploration. Third, agents reuse evidence across steps. On average, 54% of newly introduced query terms appear in the accumulated evidence context, with contributions from earlier steps beyond the most recent retrieval. The findings suggest that agentic search may benefit from repetition-aware early stopping, intent-adaptive retrieval budgets, and explicit cross-step context tracking. We plan to release the anonymized logs to support future research.

</details>


### [288] [LegalMALR:Multi-Agent Query Understanding and LLM-Based Reranking for Chinese Statute Retrieval](https://arxiv.org/abs/2601.17692)
*Yunhan Li,Mingjie Xie,Gaoli Kang,Zihan Gong,Gengshen Wu,Min Yang*

Main category: cs.IR

TL;DR: 本文提出LegalMALR框架，结合多智能体查询理解系统（MAS）与零样本大语言模型重排序器（LLM Reranker），提升隐含、多问题、口语化法律查询下的法规检索效果；通过强化学习优化MAS策略，并在新构建的CSAID数据集及STARD基准上验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现实法律查询常隐含、多议题、口语化或表述不完整，导致传统检索增强生成（RAG）方法难以准确召回所需法规条文；稠密检索器过度依赖字面匹配，轻量级重排序器缺乏法律推理能力。

Method: 提出LegalMALR框架：1）多智能体查询理解系统（MAS）生成多样化、法律 grounded 的查询改写，并进行迭代稠密检索以扩大候选集；2）采用广义强化策略优化（GRPO）统一优化MAS策略以稳定LLM生成的随机性；3）使用零样本大语言模型重排序器（LLM Reranker）基于自然语言法律推理对候选集进行最终排序。

Result: 在自建CSAID（118个困难中文法律查询）和公开STARD基准上，LegalMALR显著优于强RAG基线，在分布内和分布外设置下均表现优异。

Conclusion: 将多视角查询理解、强化学习策略优化与大模型重排序相结合，能有效提升复杂法律查询下的法规检索性能。

Abstract: Statute retrieval is essential for legal assistance and judicial decision support, yet real-world legal queries are often implicit, multi-issue, and expressed in colloquial or underspecified forms. These characteristics make it difficult for conventional retrieval-augmented generation pipelines to recover the statutory elements required for accurate retrieval. Dense retrievers focus primarily on the literal surface form of the query, whereas lightweight rerankers lack the legal-reasoning capacity needed to assess statutory applicability. We present LegalMALR, a retrieval framework that integrates a Multi-Agent Query Understanding System (MAS) with a zero-shot large-language-model-based reranking module (LLM Reranker). MAS generates diverse, legally grounded reformulations and conducts iterative dense retrieval to broaden candidate coverage. To stabilise the stochastic behaviour of LLM-generated rewrites, we optimise a unified MAS policy using Generalized Reinforcement Policy Optimization(GRPO). The accumulated candidate set is subsequently evaluated by the LLM Reranker, which performs natural-language legal reasoning to produce the final ranking. We further construct CSAID, a dataset of 118 difficult Chinese legal queries annotated with multiple statutory labels, and evaluate LegalMALR on both CSAID and the public STARD benchmark. Experiments show that LegalMALR substantially outperforms strong Retrieval-augmented generation(RAG) baselines in both in-distribution and out-of-distribution settings, demonstrating the effectiveness of combining multi-perspective query interpretation, reinforcement-based policy optimisation, and large-model reranking for statute retrieval.

</details>


### [289] [Token-Weighted Multi-Target Learning for Generative Recommenders with Curriculum Learning](https://arxiv.org/abs/2601.17787)
*Wei-Ning Chiu,Chuan-Ju Wang,Pu-Jen Cheng*

Main category: cs.IR

TL;DR: 本文提出了一种面向生成式推荐系统的基于信息增益的双策略token加权方法（Front-Greater Weighting和Frequency Weighting），并结合课程学习的多目标学习框架，显著提升对长尾物品的推荐效果与模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法将下一项预测建模为自回归序列生成，但简单优化标准下一个token似然，忽视token间语义信息量差异，与语义ID建模不一致。

Method: 提出两种信息增益驱动的token加权策略：1）Front-Greater Weighting——优先加权能最大程度减少候选物品不确定性的前缀早期token；2）Frequency Weighting——对稀有token升权以缓解流行度偏差；并设计融合二者与标准似然的多目标课程学习框架。

Result: 在多个基准数据集上显著优于强基线及现有token加权方法，对头部和尾部物品均有明显提升，具备更强鲁棒性与跨语义ID构造的泛化能力。

Conclusion: 基于信息增益的token加权与多目标课程学习可有效校准生成式推荐中的语义ID建模偏差，是提升长尾推荐性能的有效范式。

Abstract: Generative recommender systems have recently attracted attention by formulating next-item prediction as an autoregressive sequence generation task. However, most existing methods optimize standard next-token likelihood and implicitly treat all tokens as equally informative, which is misaligned with semantic-ID-based generation. Accordingly, we propose two complementary information-gain-based token-weighting strategies tailored to generative recommendation with semantic IDs. Front-Greater Weighting captures conditional semantic information gain by prioritizing early tokens that most effectively reduce candidate-item uncertainty given their prefixes and encode coarse semantics. Frequency Weighting models marginal information gain under long-tailed item and token distributions, upweighting rare tokens to counteract popularity bias. Beyond individual strategies, we introduce a multi-target learning framework with curriculum learning that jointly optimizes the two token-weighted objectives alongside standard likelihood, enabling stable optimization and adaptive emphasis across training stages. Extensive experiments on benchmark datasets show that our method consistently outperforms strong baselines and existing token-weighting approaches, with improved robustness, strong generalization across different semantic-ID constructions, and substantial gains on both head and tail items. Code is available at https://github.com/CHIUWEINING/Token-Weighted-Multi-Target-Learning-for-Generative-Recommenders-with-Curriculum-Learning.

</details>


### [290] [Unleashing the Potential of Sparse Attention on Long-term Behaviors for CTR Prediction](https://arxiv.org/abs/2601.17836)
*Weijiang Lai,Beihong Jin,Di Zhang,Siru Chen,Jiongyan Zhang,Yuhang Gou,Jian Dong,Xingxing Wang*

Main category: cs.IR

TL;DR: 本文提出SparseCTR模型，通过个性化分块和三支路稀疏自注意力机制，有效建模用户长期行为序列，在保持高效性的同时展现出显著的缩放定律现象，并在线上A/B测试中提升CTR和CPM。


<details>
  <summary>Details</summary>
Motivation: 标准自注意力机制计算复杂度高，难以在工业场景中部署长序列用户行为建模；现有稀疏注意力机制不适用于推荐场景，因用户行为具有个性化和时序特性，数据分布与其他领域差异大。

Method: 提出SparseCTR模型：1）个性化分块处理行为序列以保留连续性并支持并行；2）设计三支路稀疏自注意力机制联合建模全局兴趣、兴趣迁移和短期兴趣；3）引入可学习、头特异的复合相对时间编码，更好捕捉行为间的时序与周期关系。

Result: 实验表明SparseCTR在效率和效果上均优于SOTA方法；展现出跨三个数量级FLOPs的明显缩放定律；线上A/B测试中CTR提升1.72%，CPM提升1.41%。

Conclusion: SparseCTR是一种专为用户长期行为建模设计的高效且有效的推荐模型，兼顾性能、效率与可扩展性，验证了推荐系统中缩放定律的可行性与实用性。

Abstract: In recent years, the success of large language models (LLMs) has driven the exploration of scaling laws in recommender systems. However, models that demonstrate scaling laws are actually challenging to deploy in industrial settings for modeling long sequences of user behaviors, due to the high computational complexity of the standard self-attention mechanism. Despite various sparse self-attention mechanisms proposed in other fields, they are not fully suited for recommendation scenarios. This is because user behaviors exhibit personalization and temporal characteristics: different users have distinct behavior patterns, and these patterns change over time, with data from these users differing significantly from data in other fields in terms of distribution. To address these challenges, we propose SparseCTR, an efficient and effective model specifically designed for long-term behaviors of users. To be precise, we first segment behavior sequences into chunks in a personalized manner to avoid separating continuous behaviors and enable parallel processing of sequences. Based on these chunks, we propose a three-branch sparse self-attention mechanism to jointly identify users' global interests, interest transitions, and short-term interests. Furthermore, we design a composite relative temporal encoding via learnable, head-specific bias coefficients, better capturing sequential and periodic relationships among user behaviors. Extensive experimental results show that SparseCTR not only improves efficiency but also outperforms state-of-the-art methods. More importantly, it exhibits an obvious scaling law phenomenon, maintaining performance improvements across three orders of magnitude in FLOPs. In online A/B testing, SparseCTR increased CTR by 1.72\% and CPM by 1.41\%. Our source code is available at https://github.com/laiweijiang/SparseCTR.

</details>


### [291] [Post-Training Denoising of User Profiles with LLMs in Collaborative Filtering Recommendation](https://arxiv.org/abs/2601.18009)
*Ervin Dervishaj,Maria Maistro,Tuukka Ruotsalo,Christina Lioma*

Main category: cs.IR

TL;DR: 本文提出了一种基于大语言模型（LLM）的后训练用户画像去噪方法，用于提升协同过滤推荐效果，无需修改模型结构或训练流程，实验显示推荐效果最高提升13%。


<details>
  <summary>Details</summary>
Motivation: 隐式反馈数据噪声大，影响推荐效果；现有去噪方法多需额外数据或修改模型与训练流程，成本高、数据需求大。

Method: 利用大语言模型对用户画像进行后训练去噪：将用户交互历史、候选物品及其在CF模型中的排序作为提示输入LLM，让LLM判断并移除用户画像中可能干扰该候选物品排序的噪声交互。

Result: 在3个数据集上联合4个开源/闭源LLM与先进CF模型实验，去噪后推荐效果最高提升13%。

Conclusion: 后训练LLM去噪是一种轻量、通用且有效的隐式反馈净化方法，不依赖额外训练或模型修改，显著提升推荐性能。

Abstract: Implicit feedback -- the main data source for training Recommender Systems (RSs) -- is inherently noisy and has been shown to negatively affect recommendation effectiveness. Denoising has been proposed as a method for removing noisy implicit feedback and improving recommendations. Prior work has focused on in-training denoising, however this requires additional data, changes to the model architecture and training procedure or fine-tuning, all of which can be costly and data hungry. In this work, we focus on post-training denoising. Different from in-training denoising, post-training denoising does not involve changing the architecture of the model nor its training procedure, and does not require additional data. Specifically, we present a method for post-training denoising user profiles using Large Language Models (LLMs) for Collaborative Filtering (CF) recommendations. Our approach prompts LLMs with (i) a user profile (user interactions), (ii) a candidate item, and (iii) its rank as given by the CF recommender, and asks the LLM to remove items from the user profile to improve the rank of the candidate item. Experiments with a state-of-the-art CF recommender and 4 open and closed source LLMs in 3 datasets show that our denoising yields improvements up to 13% in effectiveness over the original user profiles. Our code is available at https://github.com/edervishaj/denoising-user-profiles-LLM.

</details>


### [292] [Enhancing LLM-based Recommendation with Preference Hint Discovery from Knowledge Graph](https://arxiv.org/abs/2601.18096)
*Yuting Zhang,Ziliang Pei,Chao Wang,Ying Sun,Fuzhen Zhuang*

Main category: cs.IR

TL;DR: 本文提出了一种基于交互整合知识图谱的偏好提示发现模型，通过选择性提取关键属性作为提示，并设计双注意力机制量化属性偏好可信度，从而提升大语言模型在推荐系统中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法在捕捉复杂偏好模式上不如传统推荐器，且将连续嵌入与离散语义空间融合存在核心差距；直接使用交互衍生的文本属性作为提示存在稀疏性和噪声问题。

Method: 提出基于交互整合知识图谱的偏好提示发现模型：设计协同偏好提示提取方案，利用相似用户的显式交互提供未见物品的语义提示；开发实例级双注意力机制评估候选属性的偏好可信度；采用扁平化提示组织方式缩短输入长度并供LLM进行常识推理。

Result: 在成对和列表式推荐任务上的大量实验表明，该框架相较基线平均相对提升超过3.02%。

Conclusion: 将结构化推荐知识（如用户-物品交互、知识图谱）与LLM的语义理解能力有机结合，通过可控、可解释的提示机制能显著提升LLM推荐效果。

Abstract: LLMs have garnered substantial attention in recommendation systems. Yet they fall short of traditional recommenders when capturing complex preference patterns. Recent works have tried integrating traditional recommendation embeddings into LLMs to resolve this issue, yet a core gap persists between their continuous embedding and discrete semantic spaces. Intuitively, textual attributes derived from interactions can serve as critical preference rationales for LLMs' recommendation logic. However, directly inputting such attribute knowledge presents two core challenges: (1) Deficiency of sparse interactions in reflecting preference hints for unseen items; (2) Substantial noise introduction from treating all attributes as hints. To this end, we propose a preference hint discovery model based on the interaction-integrated knowledge graph, enhancing LLM-based recommendation. It utilizes traditional recommendation principles to selectively extract crucial attributes as hints. Specifically, we design a collaborative preference hint extraction schema, which utilizes semantic knowledge from similar users' explicit interactions as hints for unseen items. Furthermore, we develop an instance-wise dual-attention mechanism to quantify the preference credibility of candidate attributes, identifying hints specific to each unseen item. Using these item- and user-based hints, we adopt a flattened hint organization method to shorten input length and feed the textual hint information to the LLM for commonsense reasoning. Extensive experiments on both pair-wise and list-wise recommendation tasks verify the effectiveness of our proposed framework, indicating an average relative improvement of over 3.02% against baselines.

</details>


### [293] [Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking](https://arxiv.org/abs/2601.18146)
*Huizhong Guo,Tianjun Wei,Dongxia Wang,Yingpeng Du,Ziyan Wang,Jie Zhang,Zhu Sun*

Main category: cs.IR

TL;DR: 本文提出了一种推理路由框架（reasoning routing），通过轻量级路由器头在生成前判断是否需要调用推理模式（Think）或直接推理（Non-Think），从而在提升排序效果的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的排序方法中，推理提示虽能提升性能但效果不稳定且计算成本高，因此需解决‘何时推理’这一关键问题。

Method: 设计一个轻量、即插即用的路由器头，仅依赖生成前信号（如候选分散度等排序感知特征和基于诊断清单的模型难度信号），预测是否启用Think模式；并支持在验证Pareto前沿上动态选择部署策略以适应不同资源约束。

Result: 在三个公开排序数据集及多个开源LLM上验证，该方法一致提升了排序指标（如NDCG@10），同时大幅减少token消耗（例如MovieLens上Qwen3-4B模型+6.3% NDCG@10，-49.5% token）。

Conclusion: 推理路由是一种兼顾准确率与效率的实用方案，有效缓解了大模型排序任务中的精度-效率权衡问题。

Abstract: Large language models (LLMs) are increasingly applied to ranking tasks in retrieval and recommendation. Although reasoning prompting can enhance ranking utility, our preliminary exploration reveals that its benefits are inconsistent and come at a substantial computational cost, suggesting that when to reason is as crucial as how to reason. To address this issue, we propose a reasoning routing framework that employs a lightweight, plug-and-play router head to decide whether to use direct inference (Non-Think) or reasoning (Think) for each instance before generation. The router head relies solely on pre-generation signals: i) compact ranking-aware features (e.g., candidate dispersion) and ii) model-aware difficulty signals derived from a diagnostic checklist reflecting the model's estimated need for reasoning. By leveraging these features before generation, the router outputs a controllable token that determines whether to apply the Think mode. Furthermore, the router can adaptively select its operating policy along the validation Pareto frontier during deployment, enabling dynamic allocation of computational resources toward instances most likely to benefit from Think under varying system constraints. Experiments on three public ranking datasets with different scales of open-source LLMs show consistent improvements in ranking utility with reduced token consumption (e.g., +6.3\% NDCG@10 with -49.5\% tokens on MovieLens with Qwen3-4B), demonstrating reasoning routing as a practical solution to the accuracy-efficiency trade-off.

</details>


### [294] [DMAP: Human-Aligned Structural Document Map for Multimodal Document Understanding](https://arxiv.org/abs/2601.18203)
*ShunLiang Fu,Yanxin Zhang,Yixin Xiang,Xiaoyu Du,Jinhui Tang*

Main category: cs.IR

TL;DR: 本文提出文档级结构化文档映射（DMAP），通过结构化语义理解代理构建包含层次结构与元素关系的文档表示，并利用反思推理代理进行结构感知的证据驱动推理，显著提升多模态文档问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于扁平语义检索的多模态文档问答系统忽略了文档内在的层次与关系结构（如章节组织、图文对应、交叉引用等），导致逻辑和空间依赖关系断裂，无法模拟人类自然理解方式。

Method: 设计结构化语义理解代理构建文档级结构化文档映射（DMAP），整合文本、图表等元素为符合人类认知的层次化结构；再由反思推理代理在DMAP上进行动态上下文充分性评估与迭代式答案优化。

Result: 在MMDocQA基准上实验表明，DMAP显著提升了检索精度、推理一致性与多模态理解能力，优于传统RAG方法。

Conclusion: 显式建模文档结构（层次+关系）是提升多模态文档问答性能的关键，DMAP提供了更符合人类解释模式的文档特定结构表示。

Abstract: Existing multimodal document question-answering (QA) systems predominantly rely on flat semantic retrieval, representing documents as a set of disconnected text chunks and largely neglecting their intrinsic hierarchical and relational structures. Such flattening disrupts logical and spatial dependencies - such as section organization, figure-text correspondence, and cross-reference relations, that humans naturally exploit for comprehension. To address this limitation, we introduce a document-level structural Document MAP (DMAP), which explicitly encodes both hierarchical organization and inter-element relationships within multimodal documents. Specifically, we design a Structured-Semantic Understanding Agent to construct DMAP by organizing textual content together with figures, tables, charts, etc. into a human-aligned hierarchical schema that captures both semantic and layout dependencies. Building upon this representation, a Reflective Reasoning Agent performs structure-aware and evidence-driven reasoning, dynamically assessing the sufficiency of retrieved context and iteratively refining answers through targeted interactions with DMAP. Extensive experiments on MMDocQA benchmarks demonstrate that DMAP yields document-specific structural representations aligned with human interpretive patterns, substantially enhancing retrieval precision, reasoning consistency, and multimodal comprehension over conventional RAG-based approaches. Code is available at https://github.com/Forlorin/DMAP

</details>


### [295] [Generative Chain of Behavior for User Trajectory Prediction](https://arxiv.org/abs/2601.18213)
*Chengkai Huang,Xiaodi Chen,Hongtao Huang,Quan Z. Sheng,Lina Yao*

Main category: cs.IR

TL;DR: 本文提出了Generative Chain of Behavior (GCB)框架，通过语义ID编码与自回归生成建模用户长期行为轨迹，显著提升多步预测准确率与轨迹一致性。


<details>
  <summary>Details</summary>
Motivation: 现有顺序推荐模型多聚焦于下一物品预测，忽视了对多个未来动作间依赖关系的建模，难以刻画用户长期偏好演化。

Method: GCB首先利用RQ-VAE（结合k-means优化）将物品编码为保持语义邻近性的离散语义ID，构建语义潜在空间；再基于该空间，采用Transformer自回归生成器，以用户历史为条件预测多步未来行为链。

Result: 在多个基准数据集上，GCB在多步预测准确率和轨迹一致性方面持续超越当前最优顺序推荐模型。

Conclusion: GCB提供了一种统一的生成式建模范式，有效建模用户偏好长期演化过程，拓展了顺序推荐从单步预测到多步行为链生成的能力边界。

Abstract: Modeling long-term user behavior trajectories is essential for understanding evolving preferences and enabling proactive recommendations. However, most sequential recommenders focus on next-item prediction, overlooking dependencies across multiple future actions. We propose Generative Chain of Behavior (GCB), a generative framework that models user interactions as an autoregressive chain of semantic behaviors over multiple future steps. GCB first encodes items into semantic IDs via RQ-VAE with k-means refinement, forming a discrete latent space that preserves semantic proximity. On top of this space, a transformer-based autoregressive generator predicts multi-step future behaviors conditioned on user history, capturing long-horizon intent transitions and generating coherent trajectories. Experiments on benchmark datasets show that GCB consistently outperforms state-of-the-art sequential recommenders in multi-step accuracy and trajectory consistency. Beyond these gains, GCB offers a unified generative formulation for capturing user preference evolution.

</details>


### [296] [GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction](https://arxiv.org/abs/2601.18251)
*Kesha Ou,Zhen Tian,Wayne Xin Zhao,Hongyu Lu,Ji-Rong Wen*

Main category: cs.IR

TL;DR: 本文提出GenCI框架，通过生成语义兴趣群体来建模用户动态意图，解决CTR预测中历史特征过拟合和点式排序忽略上下文信号的问题。


<details>
  <summary>Details</summary>
Motivation: 现有CTR模型存在两个问题：一是判别式范式易过拟合历史主导特征，难以适应用户兴趣快速变化；二是点式排序忽略召回集整体的上下文信号，导致长期偏好掩盖即时意图。

Method: 提出生成式用户意图框架GenCI：首先用以next-item预测为目标训练的生成模型主动产生用户兴趣群体；再通过分层候选感知网络结合交叉注意力，将兴趣群体与用户历史及目标物品对齐；端到端训练整个模型。

Result: 在三个常用数据集上的大量实验验证了该方法的有效性。

Conclusion: GenCI通过引入候选无关的兴趣表征和上下文感知的排序机制，提升了CTR预测对用户即时动态意图的建模能力与准确性。

Abstract: Click-through rate (CTR) prediction plays a pivotal role in online advertising and recommender systems. Despite notable progress in modeling user preferences from historical behaviors, two key challenges persist. First, exsiting discriminative paradigms focus on matching candidates to user history, often overfitting to historically dominant features and failing to adapt to rapid interest shifts. Second, a critical information chasm emerges from the point-wise ranking paradigm. By scoring each candidate in isolation, CTR models discard the rich contextual signal implied by the recalled set as a whole, leading to a misalignment where long-term preferences often override the user's immediate, evolving intent. To address these issues, we propose GenCI, a generative user intent framework that leverages semantic interest cohorts to model dynamic user preferences for CTR prediction. The framework first employs a generative model, trained with a next-item prediction (NTP) objective, to proactively produce candidate interest cohorts. These cohorts serve as explicit, candidate-agnostic representations of a user's immediate intent. A hierarchical candidate-aware network then injects this rich contextual signal into the ranking stage, refining them with cross-attention to align with both user history and the target item. The entire model is trained end-to-end, creating a more aligned and effective CTR prediction pipeline. Extensive experiments on three widely used datasets demonstrate the effectiveness of our approach.

</details>


### [297] [Orchestrating Specialized Agents for Trustworthy Enterprise RAG](https://arxiv.org/abs/2601.18267)
*Xincheng You,Qi Sun,Neha Bora,Huayi Li,Shubham Goel,Kang Li,Sean Culatana*

Main category: cs.IR

TL;DR: ADORE是一种面向企业知识工作的检索增强生成框架，通过引入记忆库、证据覆盖引导执行和分段长上下文接地等机制，提升了深度合成、可追溯性和提示鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在高风险决策场景中表现不足，存在浅层摘要、接地不一致及完整性验证弱等问题，尤其难以应对提示模糊或要求严格溯源的场景。

Method: 提出ADORE框架：采用中央协调器与专用智能体协同的迭代式、用户引导式调研；构建结构化Memory Bank（含声明-证据图谱与分节级可采纳证据）；设计证据覆盖率驱动的检索-反思循环；实现分节打包、剪枝与保引用压缩的长上下文接地。

Result: 在DeepResearch Bench上得分52.65（排名第一），在DeepConsult头对头对比中对商业系统胜率达77.2%。

Conclusion: ADORE通过结构化记忆与自适应执行显著提升RAG在企业深度研究任务中的可靠性、可追溯性与完整性，为高价值知识工作提供了新范式。

Abstract: Retrieval-Augmented Generation (RAG) shows promise for enterprise knowledge work, yet it often underperforms in high-stakes decision settings that require deep synthesis, strict traceability, and recovery from underspecified prompts. One-pass retrieval-and-write pipelines frequently yield shallow summaries, inconsistent grounding, and weak mechanisms for completeness verification. We introduce ADORE (Adaptive Deep Orchestration for Research in Enterprise), an agentic framework that replaces linear retrieval with iterative, user-steered investigation coordinated by a central orchestrator and a set of specialized agents. ADORE's key insight is that a structured Memory Bank (a curated evidence store with explicit claim-evidence linkage and section-level admissible evidence) enables traceable report generation and systematic checks for evidence completeness. Our contributions are threefold: (1) Memory-locked synthesis - report generation is constrained to a structured Memory Bank (Claim-Evidence Graph) with section-level admissible evidence, enabling traceable claims and grounded citations; (2) Evidence-coverage-guided execution - a retrieval-reflection loop audits section-level evidence coverage to trigger targeted follow-up retrieval and terminates via an evidence-driven stopping criterion; (3) Section-packed long-context grounding - section-level packing, pruning, and citation-preserving compression make long-form synthesis feasible under context limits. Across our evaluation suite, ADORE ranks first on DeepResearch Bench (52.65) and achieves the highest head-to-head preference win rate on DeepConsult (77.2%) against commercial systems.

</details>


### [298] [TopKGAT: A Top-K Objective-Driven Architecture for Recommendation](https://arxiv.org/abs/2601.18432)
*Sirui Chen,Jiawei Chen,Canghong Jin,Sheng Zhou,Jingbang Chen,Wujie Sun,Can Wang*

Main category: cs.IR

TL;DR: 本文提出TopKGAT，一种直接从top-K指标的可微近似推导出的新型推荐架构，其前向计算与Precision@K指标的梯度上升动力学内在一致，从而自然提升top-K推荐精度。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统架构设计往往未显式对齐top-K优化目标，限制了其有效性。

Method: 提出TopKGAT模型，其单层前向计算与Precision@K指标的梯度上升动态一致，结构上类似图注意力网络，可高效实现。

Result: 在四个基准数据集上的大量实验表明，TopKGAT持续优于当前最先进的基线方法。

Conclusion: TopKGAT通过将模型架构与top-K评估指标直接对齐，有效提升了推荐系统的top-K准确性，是一种有前景的新架构设计范式。

Abstract: Recommendation systems (RS) aim to retrieve the top-K items most relevant to users, with metrics such as Precision@K and Recall@K commonly used to assess effectiveness. The architecture of an RS model acts as an inductive bias, shaping the patterns the model is inclined to learn. In recent years, numerous recommendation architectures have emerged, spanning traditional matrix factorization, deep neural networks, and graph neural networks. However, their designs are often not explicitly aligned with the top-K objective, thereby limiting their effectiveness.
  To address this limitation, we propose TopKGAT, a novel recommendation architecture directly derived from a differentiable approximation of top-K metrics. The forward computation of a single TopKGAT layer is intrinsically aligned with the gradient ascent dynamics of the Precision@K metric, enabling the model to naturally improve top-K recommendation accuracy. Structurally, TopKGAT resembles a graph attention network and can be implemented efficiently. Extensive experiments on four benchmark datasets demonstrate that TopKGAT consistently outperforms state-of-the-art baselines. The code is available at https://github.com/StupidThree/TopKGAT.

</details>


### [299] [Token-level Collaborative Alignment for LLM-based Generative Recommendation](https://arxiv.org/abs/2601.18457)
*Fake Lin,Binbin Hu,Zhi Zheng,Xi Zhu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Tong Xu*

Main category: cs.IR

TL;DR: 本文提出TCA4Rec框架，通过协同标记化和软标签对齐，在优化层面显式融合协同过滤（CF）信号与大语言模型（LLM）的生成过程，提升推荐准确性与可控性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐系统难以有效融入协同过滤（CF）信号，因CF基于物品级偏好建模，而LLM训练基于词元级下一词预测（NTP），二者存在根本性不匹配；且以往方法仅将CF作为上下文提示或表示偏差，无法显式调控LLM生成。

Method: 提出Token-level Collaborative Alignment for Recommendation（TCA4Rec）：（i）Collaborative Tokenizer将物品级CF logits映射为与LLM词元空间对齐的词元级分布；（ii）Soft Label Alignment将该分布与one-hot监督结合，优化软NTP目标。该框架模型无关、即插即用。

Result: TCA4Rec在多种CF模型和LLM推荐架构上均显著提升推荐性能；兼容任意传统CF模型，支持行为对齐与语义流畅性的显式权衡，生成更准确、可控的推荐结果。

Conclusion: TCA4Rec成功建立了CF监督与LLM生成之间的显式优化级接口，在不牺牲LLM生成特性的前提下实现协同对齐，为LLM推荐系统提供了通用、高效、可控的CF融合新范式。

Abstract: Large Language Models (LLMs) have demonstrated strong potential for generative recommendation by leveraging rich semantic knowledge. However, existing LLM-based recommender systems struggle to effectively incorporate collaborative filtering (CF) signals, due to a fundamental mismatch between item-level preference modeling in CF and token-level next-token prediction (NTP) optimization in LLMs. Prior approaches typically treat CF as contextual hints or representation bias, and resort to multi-stage training to reduce behavioral semantic space discrepancies, leaving CF unable to explicitly regulate LLM generation. In this work, we propose Token-level Collaborative Alignment for Recommendation (TCA4Rec), a model-agnostic and plug-and-play framework that establishes an explicit optimization-level interface between CF supervision and LLM generation. TCA4Rec consists of (i) Collaborative Tokenizer, which projects raw item-level CF logits into token-level distributions aligned with the LLM token space, and (ii) Soft Label Alignment, which integrates these CF-informed distributions with one-hot supervision to optimize a soft NTP objective. This design preserves the generative nature of LLM training while enabling collaborative alignment with essential user preference of CF models. We highlight TCA4Rec is compatible with arbitrary traditional CF models and generalizes across a wide range of decoder-based LLM recommender architectures. Moreover, it provides an explicit mechanism to balance behavioral alignment and semantic fluency, yielding generative recommendations that are both accurate and controllable. Extensive experiments demonstrate that TCA4Rec consistently improves recommendation performance across a broad spectrum of CF models and LLM-based recommender systems.

</details>


### [300] [Feature-Indexed Federated Recommendation with Residual-Quantized Codebooks](https://arxiv.org/abs/2601.18570)
*Mingzhe Han,Jiahao Liu,Dongsheng Li,Hansu Gu,Peng Zhang,Ning Gu,Tun Lu*

Main category: cs.IR

TL;DR: 本文提出RQFedRec，一种基于特征索引通信范式的联邦推荐方法，利用残差量化（RQ）-Kmeans将物品映射为离散码ID，并在客户端训练共享码本而非原始嵌入，从而降低通信开销、提升泛化性与鲁棒性，并通过协同-语义双通道聚合策略增强建模效果。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐方法采用ID索引通信范式，传输完整物品嵌入，存在通信资源不可控、无法泛化至未交互物品、易受客户端噪声反馈影响三大问题，亟需范式革新。

Method: 提出特征索引通信范式，设计RQFedRec：1）用RQ-Kmeans为每个物品分配离散码ID序列；2）客户端基于服务器下发的码ID生成并训练码嵌入（码本），服务器聚合码本而非物品嵌入；3）引入协同-语义双通道聚合与课程学习策略，初期侧重语义码、逐步增强协同码贡献。

Result: 在多个真实数据集上，RQFedRec持续优于现有SOTA联邦推荐基线，同时显著降低通信开销。

Conclusion: 特征索引通信范式能有效解决ID索引范式的固有缺陷，RQFedRec通过码本共享、跨物品更新传播和双通道课程聚合，在精度与效率间取得更好平衡，为隐私保护推荐提供新思路。

Abstract: Federated recommendation provides a privacy-preserving solution for training recommender systems without centralizing user interactions. However, existing methods follow an ID-indexed communication paradigm that transmit whole item embeddings between clients and the server, which has three major limitations: 1) consumes uncontrollable communication resources, 2) the uploaded item information cannot generalize to related non-interacted items, and 3) is sensitive to client noisy feedback. To solve these problems, it is necessary to fundamentally change the existing ID-indexed communication paradigm. Therefore, we propose a feature-indexed communication paradigm that transmits feature code embeddings as codebooks rather than raw item embeddings. Building on this paradigm, we present RQFedRec, which assigns each item a list of discrete code IDs via Residual Quantization (RQ)-Kmeans. Each client generates and trains code embeddings as codebooks based on discrete code IDs provided by the server, and the server collects and aggregates these codebooks rather than item embeddings. This design makes communication controllable since the codebooks could cover all items, enabling updates to propagate across related items in same code ID. In addition, since code embedding represents many items, which is more robust to a single noisy item. To jointly capture semantic and collaborative information, RQFedRec further adopts a collaborative-semantic dual-channel aggregation with a curriculum strategy that emphasizes semantic codes early and gradually increases the contribution of collaborative codes over training. Extensive experiments on real-world datasets demonstrate that RQFedRec consistently outperforms state-of-the-art federated recommendation baselines while significantly reducing communication overhead.

</details>


### [301] [FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG](https://arxiv.org/abs/2601.18579)
*Seonho An,Chaejeong Hyun,Min-Soo Kim*

Main category: cs.IR

TL;DR: 本文提出FastInsight方法，通过引入图检索分类法识别现有方法的局限性，并设计两种新型融合算子（GRanker和STeX）实现高效且富有洞察力的图检索，显著提升检索准确率与生成质量，在效果与效率间取得帕累托改进。


<details>
  <summary>Details</summary>
Motivation: 现有图RAG方法依赖耗时的LLM推理交织过程，难以兼顾时间效率与检索洞察力。

Method: 提出图检索分类法，识别出模型搜索缺乏拓扑感知、图搜索缺乏语义感知两大问题；进而设计Graph-based Reranker（GRanker）和Semantic-Topological eXpansion（STeX）两个融合算子，分别实现图模型搜索与向量-图搜索。

Result: 在多个检索与生成数据集上实验表明，FastInsight显著优于当前最优基线，在检索精度和生成质量上均有提升，并在有效性与效率之间实现显著帕累托改进。

Conclusion: FastInsight通过结构化分类与双融合算子设计，有效克服了现有图RAG方法在拓扑与语义感知上的缺陷，为高效洞察式图检索提供了新范式。

Abstract: Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.

</details>


### [302] [S$^2$GR: Stepwise Semantic-Guided Reasoning in Latent Space for Generative Recommendation](https://arxiv.org/abs/2601.18664)
*Zihao Guo,Jian Wang,Ruxin Zhou,Youhua Liu,Jiawei Guo,Jun Zhao,Xiaoxiao Xu,Yongqi Liu,Kaiqiao Zhan*

Main category: cs.IR

TL;DR: 本文提出S²GR框架，通过语义引导的分步推理机制，在潜在空间中增强生成式推荐的推理能力，解决了现有方法中推理与生成分离、推理路径不可解释等问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法仅关注直接生成语义ID（SID），缺乏类似大语言模型的深层推理能力；同时，当前推理增强方法存在推理与生成严格分离、推理向量缺乏可解释性、推理路径缺乏可验证监督等关键问题。

Method: 提出S²GR框架：1）通过优化码本（融合共现关系、负载均衡与均匀性目标）构建稳健语义基础；2）引入分步推理机制，在每个SID生成前插入‘思考token’，并用对比学习监督其对应粗粒度语义与真实码本簇分布的一致性。

Result: 在多个数据集上实验表明S²GR性能优越；在线A/B测试验证了其在大型工业短视频平台上的有效性。

Conclusion: S²GR通过语义引导的分步潜在空间推理，显著提升了生成式推荐的推理深度与可解释性，兼顾计算均衡性与物理可解释性，为生成式推荐提供了新范式。

Abstract: Generative Recommendation (GR) has emerged as a transformative paradigm with its end-to-end generation advantages. However, existing GR methods primarily focus on direct Semantic ID (SID) generation from interaction sequences, failing to activate deeper reasoning capabilities analogous to those in large language models and thus limiting performance potential. We identify two critical limitations in current reasoning-enhanced GR approaches: (1) Strict sequential separation between reasoning and generation steps creates imbalanced computational focus across hierarchical SID codes, degrading quality for SID codes; (2) Generated reasoning vectors lack interpretable semantics, while reasoning paths suffer from unverifiable supervision. In this paper, we propose stepwise semantic-guided reasoning in latent space (S$^2$GR), a novel reasoning enhanced GR framework. First, we establish a robust semantic foundation via codebook optimization, integrating item co-occurrence relationship to capture behavioral patterns, and load balancing and uniformity objectives that maximize codebook utilization while reinforcing coarse-to-fine semantic hierarchies. Our core innovation introduces the stepwise reasoning mechanism inserting thinking tokens before each SID generation step, where each token explicitly represents coarse-grained semantics supervised via contrastive learning against ground-truth codebook cluster distributions ensuring physically grounded reasoning paths and balanced computational focus across all SID codes. Extensive experiments demonstrate the superiority of S$^2$GR, and online A/B test confirms efficacy on large-scale industrial short video platform.

</details>


### [303] [Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval](https://arxiv.org/abs/2601.18747)
*Amir Aavani*

Main category: cs.IR

TL;DR: 本文提出了一种新型检索语言 $\mathcal{L}_R$ 和评估算法 ComputePN，使检索引擎能高效直接在索引上计算任意多项式时间可解的逻辑与算术约束（即“Capturing $\mathbf{P}$”），解决了当前检索系统在复杂神经符号推理中效率与内存的两难困境。


<details>
  <summary>Details</summary>
Motivation: 现代信息检索正转向复杂神经符号推理，但现有架构（如DaT和TaT）在处理严格逻辑/算术约束时面临效率（运行时间爆炸）或内存（开销过大）的根本性困境。

Method: 定义基于有向无环图（DAG）的检索语言 $\mathcal{L}_R$，证明其精确刻画复杂度类 $\mathbf{P}$；提出 ComputePN 算法，融合原生 DAG 遍历与内存高效的“正-负”响应机制，实现 $\mathcal{L}_R$ 的可扩展评估。

Result: ComputePN 在保证多项式时间可计算性的同时显著降低内存占用；$\mathcal{L}_R$ 为将搜索索引升级为通用计算引擎提供了首个形式化理论基础。

Conclusion: 检索引擎应具备直接在索引上高效计算任意 P 类性质的能力（Capturing $\mathbf{P}$）；$\mathcal{L}_R$ 与 ComputePN 共同构成了面向神经符号推理的新一代高效、可证明正确的检索基础设施。

Abstract: Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.
  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\mathbf{P}$. We introduce \texttt{ComputePN}, a novel evaluation algorithm that makes $\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \texttt{ComputePN} ensures the efficient evaluation of any query in $\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [304] [REV-INR: Regularized Evidential Implicit Neural Representation for Uncertainty-Aware Volume Visualization](https://arxiv.org/abs/2601.17689)
*Shanu Saklani,Tushar M. Athawale,Nairita Pal,David Pugmire,Christopher R. Johnson,Soumya Dutta*

Main category: cs.LG

TL;DR: 本文提出REV-INR，一种正则化证据隐式神经表示方法，用于在单次前向传播中同时预测体数据值及其坐标级的数据不确定性（偶然性）和模型不确定性（认知性），从而提升体积重建质量与可视化结果的可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统确定性隐式神经表示（INRs）无法提供预测不确定性估计，导致重建体积数据的解释和可视化不可靠，尤其在原始数据因体量过大而不可用时难以识别错误结果。

Method: 提出REV-INR（Regularized Evidential Implicit Neural Representation），基于证据深度学习框架，引入正则化机制，在单一前向传播中联合学习数据值、aleatoric不确定性和epistemic不确定性。

Result: REV-INR在体数据重建质量、不确定性估计鲁棒性（aleatoric与epistemic）及推理速度方面均优于现有主流深度不确定性估计方法。

Conclusion: REV-INR使仅依赖模型预测数据进行可信等值面提取与体可视化分析成为可能，显著提升了INR在科学可视化与分析中的实用性与可信度。

Abstract: Applications of Implicit Neural Representations (INRs) have emerged as a promising deep learning approach for compactly representing large volumetric datasets. These models can act as surrogates for volume data, enabling efficient storage and on-demand reconstruction via model predictions. However, conventional deterministic INRs only provide value predictions without insights into the model's prediction uncertainty or the impact of inherent noisiness in the data. This limitation can lead to unreliable data interpretation and visualization due to prediction inaccuracies in the reconstructed volume. Identifying erroneous results extracted from model-predicted data may be infeasible, as raw data may be unavailable due to its large size. To address this challenge, we introduce REV-INR, Regularized Evidential Implicit Neural Representation, which learns to predict data values accurately along with the associated coordinate-level data uncertainty and model uncertainty using only a single forward pass of the trained REV-INR during inference. By comprehensively comparing and contrasting REV-INR with existing well-established deep uncertainty estimation methods, we show that REV-INR achieves the best volume reconstruction quality with robust data (aleatoric) and model (epistemic) uncertainty estimates using the fastest inference time. Consequently, we demonstrate that REV-INR facilitates assessment of the reliability and trustworthiness of the extracted isosurfaces and volume visualization results, enabling analyses to be solely driven by model-predicted data.

</details>


### [305] [TelcoAI: Advancing 3GPP Technical Specification Search through Agentic Multi-Modal Retrieval-Augmented Generation](https://arxiv.org/abs/2601.16984)
*Rahul Ghosh,Chun-Hao Liu,Gaurav Rele,Vidya Sagar Ravipati,Hazar Aouad*

Main category: cs.LG

TL;DR: 本文提出TelcoAI，一个面向3GPP技术文档的多模态、智能体式检索增强生成（RAG）系统，通过分节切块、结构化查询规划、元数据引导检索及图文融合等创新方法，在召回率、主张召回率和忠实度上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 3GPP技术规范结构复杂、格式密集、内容多模态，传统LLM难以有效处理复杂查询、视觉信息和文档间依赖关系。

Method: 提出TelcoAI系统，包含分节感知的文本切分、结构化查询规划、元数据引导的检索机制，以及文本与图表的多模态融合。

Result: 在多个基准测试（含专家构建的查询集）上达到87%召回率、83%主张召回率、92%忠实度，较SOTA基线提升16%。

Conclusion: 证明了智能体式架构与多模态推理在理解复杂技术文档中的有效性，为电信领域实际研发与工程提供了新工具。

Abstract: The 3rd Generation Partnership Project (3GPP) produces complex technical specifications essential to global telecommunications, yet their hierarchical structure, dense formatting, and multi-modal content make them difficult to process. While Large Language Models (LLMs) show promise, existing approaches fall short in handling complex queries, visual information, and document interdependencies. We present TelcoAI, an agentic, multi-modal Retrieval-Augmented Generation (RAG) system tailored for 3GPP documentation. TelcoAI introduces section-aware chunking, structured query planning, metadata-guided retrieval, and multi-modal fusion of text and diagrams. Evaluated on multiple benchmarks-including expert-curated queries-our system achieves $87\%$ recall, $83\%$ claim recall, and $92\%$ faithfulness, representing a $16\%$ improvement over state-of-the-art baselines. These results demonstrate the effectiveness of agentic and multi-modal reasoning in technical document understanding, advancing practical solutions for real-world telecommunications research and engineering.

</details>


### [306] [Sparsity-Aware Low-Rank Representation for Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2601.16991)
*Longteng Zhang,Sen Wu,Shuai Hou,Zhengyu Qing,Zhuo Zheng,Danning Ke,Qihong Lin,Qiang Wang,Shaohuai Shi,Xiaowen Chu*

Main category: cs.LG

TL;DR: 本文提出SALR方法，将低秩适配（LoRA）与稀疏剪枝结合，在保证性能的同时显著降低大语言模型微调的存储和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA虽减少可训练参数，但基础权重仍为稠密且占用高存储/计算资源；直接剪枝又会损害LoRA性能。

Method: 提出SALR框架：理论证明仅剪枝冻结的基础权重可最小化误差，并用截断SVD低秩适配器恢复残差信息；进一步融合多个适配器为单次GEMM，并采用位图编码与两级流水解码+GEMM设计。

Result: 在多个LLM上实现50%稀疏率，性能媲美LoRA（GSM8K、MMLU），模型体积减半，推理加速最高达1.7倍。

Conclusion: SALR在不牺牲精度前提下，实现了更高效、更紧凑的大模型微调，兼顾理论严谨性与硬件友好性。

Abstract: Adapting large pre-trained language models to downstream tasks often entails fine-tuning millions of parameters or deploying costly dense weight updates, which hinders their use in resource-constrained environments. Low-rank Adaptation (LoRA) reduces trainable parameters by factorizing weight updates, yet the underlying dense weights still impose high storage and computation costs. Magnitude-based pruning can yield sparse models but typically degrades LoRA's performance when applied naively. In this paper, we introduce SALR (Sparsity-Aware Low-Rank Representation), a novel fine-tuning paradigm that unifies low-rank adaptation with sparse pruning under a rigorous mean-squared-error framework. We prove that statically pruning only the frozen base weights minimizes the pruning error bound, and we recover the discarded residual information via a truncated-SVD low-rank adapter, which provably reduces per-entry MSE by a factor of $(1 - r/\min(d,k))$. To maximize hardware efficiency, we fuse multiple low-rank adapters into a single concatenated GEMM, and we adopt a bitmap-based encoding with a two-stage pipelined decoding + GEMM design to achieve true model compression and speedup. Empirically, SALR attains 50\% sparsity on various LLMs while matching the performance of LoRA on GSM8K and MMLU, reduces model size by $2\times$, and delivers up to a $1.7\times$ inference speedup.

</details>


### [307] [ThinkTank-ME: A Multi-Expert Framework for Middle East Event Forecasting](https://arxiv.org/abs/2601.17065)
*Haoxuan Li,He Chang,Yunshan Ma,Yi Bin,Yang Yang,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.LG

TL;DR: 本文提出ThinkTank-ME框架，通过多专家协同模拟智库分析，提升中东事件预测的准确性与地缘政治敏感性，并构建了专用基准POLECAT-FOR-ME进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的事件预测方法采用单模型单一轨迹生成方式，难以捕捉复杂区域（如中东）中受国际关系、历史与文化影响的多样化地缘政治细微差异。

Method: 提出ThinkTank-ME多专家协同框架，模拟现实世界战略决策中的专家协作机制；并构建中东专属事件预测基准POLECAT-FOR-ME，支持专家专业化与严格评估。

Result: 实验表明，多专家协同在处理复杂时序地缘政治预测任务上显著优于单模型方法。

Conclusion: 多专家协作范式更适配高不确定性、强上下文依赖的地缘政治事件预测任务，为LLM在战略预测领域的应用提供了新思路。

Abstract: Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.

</details>


### [308] [A Dataset of Dengue Hospitalizations in Brazil (1999 to 2021) with Weekly Disaggregation from Monthly Counts](https://arxiv.org/abs/2601.16994)
*Lucas M. Morello,Matheus Lima Castro,Pedro Cesar M. G. Camargo,Liliane Moreira Nery,Darllan Collins da Cunha e Silva,Leopoldo Lusquino Filho*

Main category: cs.LG

TL;DR: 本文介绍了一个巴西登革热住院数据集（v1.0.0），将原始月度数据通过立方样条插值法降尺度至流行病学周粒度，并配套提供多种社会、环境与气象协变量，支持AI驱动的流行病预测建模。


<details>
  <summary>Details</summary>
Motivation: 为提升AI模型在流行病预测中的训练效果，需提高原始月度登革热数据的时间分辨率，因此开展市政级数据的周粒度降尺度工作。

Method: 采用立方样条插值法对巴西各市1999–2021年登革热住院数据进行周粒度分解，并引入校正步骤以保持月总量不变；通过圣保罗州高分辨率参考数据（同时含月和周数据）对比线性插值、抖动法与立方样条法，验证其统计与时间有效性；所有协变量同步按相同方案进行时间降尺度。

Result: 立方样条插值法在MAE、RMSE、R²、KL散度、JSD、DTW及KS检验等多指标上表现最优，被选定为最终方法；数据集已公开发布于Zenodo（DOI: 10.5281/zenodo.18189192），包含住院时序及人口密度、温室气体排放、气候与地理等多维协变量。

Conclusion: 该数据集填补了巴西高时间分辨率登革热监测数据的空白，具备良好的统计可靠性与多变量兼容性，适用于环境健康研究、多变量时间序列分析及机器学习/深度学习疫情预测模型开发。

Abstract: This data paper describes and publicly releases this dataset (v1.0.0), published on Zenodo under DOI 10.5281/zenodo.18189192. Motivated by the need to increase the temporal granularity of originally monthly data to enable more effective training of AI models for epidemiological forecasting, the dataset harmonizes municipal-level dengue hospitalization time series across Brazil and disaggregates them to weekly resolution (epidemiological weeks) through an interpolation protocol with a correction step that preserves monthly totals. The statistical and temporal validity of this disaggregation was assessed using a high-resolution reference dataset from the state of Sao Paulo (2024), which simultaneously provides monthly and epidemiological-week counts, enabling a direct comparison of three strategies: linear interpolation, jittering, and cubic spline. Results indicated that cubic spline interpolation achieved the highest adherence to the reference data, and this strategy was therefore adopted to generate weekly series for the 1999 to 2021 period. In addition to hospitalization time series, the dataset includes a comprehensive set of explanatory variables commonly used in epidemiological and environmental modeling, such as demographic density, CH4, CO2, and NO2 emissions, poverty and urbanization indices, maximum temperature, mean monthly precipitation, minimum relative humidity, and municipal latitude and longitude, following the same temporal disaggregation scheme to ensure multivariate compatibility. The paper documents the datasets provenance, structure, formats, licenses, limitations, and quality metrics (MAE, RMSE, R2, KL, JSD, DTW, and the KS test), and provides usage recommendations for multivariate time-series analysis, environmental health studies, and the development of machine learning and deep learning models for outbreak forecasting.

</details>


### [309] [Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation](https://arxiv.org/abs/2601.17133)
*Inderjeet Singh,Eleonore Vissol-Gaudin,Andikan Otung,Motoyoshi Sekiya*

Main category: cs.LG

TL;DR: 本文提出KNEXA-FL框架，通过去中心化联邦学习与基于上下文赌博机的智能匹配机制，在保护数据隐私前提下实现异构LLM代理间的高效知识交换，显著提升代码生成任务性能并保障训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习存在单点故障和模型逆向攻击风险；去中心化联邦学习虽规避了中心节点，但随机P2P配对忽视代理异质性，易导致负迁移。如何在保障数据主权与隐私前提下实现高效、鲁棒的跨组织LLM协同微调，是核心动机。

Method: 提出KNEXA-FL框架：引入不聚合模型的中央画像/匹配器（CPM），将P2P协作建模为上下文赌博机问题，采用LinUCB算法基于抽象代理画像学习最优匹配策略；各代理采用PEFT方法微调LLM，并通过安全知识蒸馏直接进行点对点知识交换，CPM全程不接触原始模型或数据。

Result: 在代码生成任务上，KNEXA-FL相较随机P2P协作使Pass@1提升约50%；相比强中心化蒸馏基线，其展现出稳定收敛性，而后者出现灾难性性能崩溃。

Conclusion: 自适应、学习驱动的编排机制是构建鲁棒高效去中心化AI生态系统的基石；KNEXA-FL在隐私保护、性能增益与训练稳定性三方面取得实质性突破。

Abstract: Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.

</details>


### [310] [MathMixup: Boosting LLM Mathematical Reasoning with Difficulty-Controllable Data Synthesis and Curriculum Learning](https://arxiv.org/abs/2601.17006)
*Xuchen Li,Jing Chen,Xuzhao Li,Hao Liang,Xiaohuan Zhou,Taifeng Wang,Wentao Zhang*

Main category: cs.LG

TL;DR: 本文提出MathMixup，一种能生成高质量、难度可控的数学推理问题的新数据合成范式，并构建MathMixupQA数据集与配套课程学习策略，显著提升大语言模型在数学推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据合成方法多样性不足、难度控制不精确，难以支撑课程学习等高效训练范式。

Method: 提出MathMixup范式，采用混合与分解策略生成问题，结合自动自检与人工筛选保障语义清晰与难度梯度；构建MathMixupQA数据集并设计相应课程学习策略。

Result: Qwen2.5-7B经MathMixup微调后在七个数学基准上平均得分达52.6%，超越此前最优方法。

Conclusion: MathMixup有效提升了大语言模型的数学推理能力，验证了其在数据驱动课程学习中的有效性与广泛适用性。

Abstract: In mathematical reasoning tasks, the advancement of Large Language Models (LLMs) relies heavily on high-quality training data with clearly defined and well-graded difficulty levels. However, existing data synthesis methods often suffer from limited diversity and lack precise control over problem difficulty, making them insufficient for supporting efficient training paradigms such as curriculum learning. To address these challenges, we propose MathMixup, a novel data synthesis paradigm that systematically generates high-quality, difficulty-controllable mathematical reasoning problems through hybrid and decomposed strategies. Automated self-checking and manual screening are incorporated to ensure semantic clarity and a well-structured difficulty gradient in the synthesized data. Building on this, we construct the MathMixupQA dataset and design a curriculum learning strategy that leverages these graded problems, supporting flexible integration with other datasets. Experimental results show that MathMixup and its curriculum learning strategy significantly enhance the mathematical reasoning performance of LLMs. Fine-tuned Qwen2.5-7B achieves an average score of 52.6\% across seven mathematical benchmarks, surpassing previous state-of-the-art methods. These results fully validate the effectiveness and broad applicability of MathMixup in improving the mathematical reasoning abilities of LLMs and advancing data-centric curriculum learning.

</details>


### [311] [Analysis of voice recordings features for Classification of Parkinson's Disease](https://arxiv.org/abs/2601.17007)
*Beatriz Pérez-Sánchez,Noelia Sánchez-Maroño,Miguel A. Díaz-Freire*

Main category: cs.LG

TL;DR: 本文提出结合多种机器学习模型与特征选择方法，利用患者语音录音实现帕金森病（PD）的早期诊断，并验证了在显著减少特征数量的同时仍能保持高分类性能。


<details>
  <summary>Details</summary>
Motivation: 帕金森病早期症状轻微、诊断困难，而语音数据虽具潜力但特征冗余，亟需高效准确的自动诊断方法。

Method: 采用多种机器学习模型（尤其神经网络）并结合特征选择技术，对语音特征进行筛选与分类建模。

Result: 神经网络等模型适用于PD分类，且通过特征选择可大幅减少输入特征数而不损害模型性能。

Conclusion: 语音分析结合特征选择与机器学习是可行且高效的PD早期辅助诊断方案。

Abstract: Parkinson's disease (PD) is a chronic neurodegenerative disease. Early diagnosis is essential to mitigate the progressive deterioration of patients' quality of life. The most characteristic motor symptoms are very mild in the early stages, making diagnosis difficult. Recent studies have shown that the use of patient voice recordings can aid in early diagnosis. Although the analysis of such recordings is costly from a clinical point of view, advances in machine learning techniques are making the processing of this type of data increasingly accurate and efficient. Vocal recordings contain many features, but it is not known whether all of them are relevant for diagnosing the disease.
  This paper proposes the use of different types of machine learning models combined with feature selection methods to detect the disease. The selection techniques allow to reduce the number of features used by the classifiers by determining which ones provide the most information about the problem. The results show that machine learning methods, in particular neural networks, are suitable for PD classification and that the number of features can be significantly reduced without affecting the performance of the models.

</details>


### [312] [Bayesian Robust Financial Trading with Adversarial Synthetic Market Data](https://arxiv.org/abs/2601.17008)
*Haochong Xia,Simin Li,Ruixiao Xu,Zhixia Zhang,Hongxiang Wang,Zhiqian Liu,Teng Yao Long,Molei Qin,Chuqiao Zong,Bo An*

Main category: cs.LG

TL;DR: 本文提出了一种贝叶斯鲁棒框架，结合宏观条件生成对抗网络与鲁棒策略学习，以提升算法交易模型在动态多变市场环境下的泛化性与稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有算法交易模型在样本内表现优异，但在面对由宏观经济变化（如货币政策调整或参与者行为突变）引发的真实市场状态迁移时性能显著下降；其根源在于策略对高层市场波动不确定性鲁棒性不足，且缺乏真实多样的仿真训练环境，导致过拟合。

Method: 提出贝叶斯鲁棒框架：（1）数据端：构建宏观条件GAN生成器，以宏观经济指标为控制变量，合成具备时序、跨品种及宏观相关性的逼真多样化金融数据；（2）策略端：将交易建模为双人零和贝叶斯马尔可夫博弈，引入对抗智能体通过扰动宏观变量模拟市场机制切换，交易智能体基于分位数信念网络维护隐市场状态信念，并通过贝叶斯神经虚拟自博弈求解鲁棒完美贝叶斯均衡。

Result: 在9种金融工具上的大量实验表明，该框架优于9种前沿基线方法；在新冠疫情等极端事件中展现出更强的盈利能力和风险管控能力。

Conclusion: 所提框架有效缓解了算法交易模型在演化市场中的鲁棒性缺失与过拟合问题，为不确定、动态变化的市场环境提供了可靠可行的交易解决方案。

Abstract: Algorithmic trading relies on machine learning models to make trading decisions. Despite strong in-sample performance, these models often degrade when confronted with evolving real-world market regimes, which can shift dramatically due to macroeconomic changes-e.g., monetary policy updates or unanticipated fluctuations in participant behavior. We identify two challenges that perpetuate this mismatch: (1) insufficient robustness in existing policy against uncertainties in high-level market fluctuations, and (2) the absence of a realistic and diverse simulation environment for training, leading to policy overfitting. To address these issues, we propose a Bayesian Robust Framework that systematically integrates a macro-conditioned generative model with robust policy learning. On the data side, to generate realistic and diverse data, we propose a macro-conditioned GAN-based generator that leverages macroeconomic indicators as primary control variables, synthesizing data with faithful temporal, cross-instrument, and macro correlations. On the policy side, to learn robust policy against market fluctuations, we cast the trading process as a two-player zero-sum Bayesian Markov game, wherein an adversarial agent simulates shifting regimes by perturbing macroeconomic indicators in the macro-conditioned generator, while the trading agent-guided by a quantile belief network-maintains and updates its belief over hidden market states. The trading agent seeks a Robust Perfect Bayesian Equilibrium via Bayesian neural fictitious self-play, stabilizing learning under adversarial market perturbations. Extensive experiments on 9 financial instruments demonstrate that our framework outperforms 9 state-of-the-art baselines. In extreme events like the COVID, our method shows improved profitability and risk management, offering a reliable solution for trading under uncertain and shifting market dynamics.

</details>


### [313] [Optimizing the Landscape of LLM Embeddings with Dynamic Exploratory Graph Analysis for Generative Psychometrics: A Monte Carlo Study](https://arxiv.org/abs/2601.17010)
*Hudson Golino*

Main category: cs.LG

TL;DR: 本文提出将大语言模型（LLM）嵌入视为可搜索的语义景观，通过改进的动态探索性图分析（DynEGA）方法系统探索嵌入维度空间，发现嵌入深度对结构准确性与熵组织性存在权衡，需采用加权复合准则进行优化，而非默认使用全部维度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM嵌入在心理测验开发中被当作静态、全维使用的表征，忽略了其内部信息分布可能高度不均，最优结构信息可能仅集中于特定维度区域，亟需更精细的优化策略。

Method: 将嵌入坐标视作可遍历的‘景观’，引入伪时间序（维度索引），适配DynEGA方法；结合大规模蒙特卡洛模拟，基于text-embedding-3-small生成五维自恋量表项目嵌入，在不同项目数（3–40/维）与嵌入深度（3–1298维）组合下评估网络结构。

Result: TEFI（总熵拟合指数）在深维区（900–1200维）达最小值但结构准确性下降，NMI（标准化互信息）在浅维区峰值高但熵拟合欠佳；单指标优化导致结构失真，而加权复合准则可识别兼顾准确与组织的最优深度区间；最优深度随项目池规模系统变化。

Conclusion: LLM嵌入空间是非均匀的语义场，必须依据具体测量目标进行有原则的维度选择与优化，摒弃默认全向量使用的做法，为嵌入驱动的心理测量设计提供新范式。

Abstract: Large language model (LLM) embeddings are increasingly used to estimate dimensional structure in psychological item pools prior to data collection, yet current applications treat embeddings as static, cross-sectional representations. This approach implicitly assumes uniform contribution across all embedding coordinates and overlooks the possibility that optimal structural information may be concentrated in specific regions of the embedding space. This study reframes embeddings as searchable landscapes and adapts Dynamic Exploratory Graph Analysis (DynEGA) to systematically traverse embedding coordinates, treating the dimension index as a pseudo-temporal ordering analogous to intensive longitudinal trajectories. A large-scale Monte Carlo simulation embedded items representing five dimensions of grandiose narcissism using OpenAI's text-embedding-3-small model, generating network estimations across systematically varied item pool sizes (3-40 items per dimension) and embedding depths (3-1,298 dimensions). Results reveal that Total Entropy Fit Index (TEFI) and Normalized Mutual Information (NMI) leads to competing optimization trajectories across the embedding landscape. TEFI achieves minima at deep embedding ranges (900--1,200 dimensions) where entropy-based organization is maximal but structural accuracy degrades, whereas NMI peaks at shallow depths where dimensional recovery is strongest but entropy-based fit remains suboptimal. Single-metric optimization produces structurally incoherent solutions, whereas a weighted composite criterion identifies embedding dimensions depth regions that jointly balance accuracy and organization. Optimal embedding depth scales systematically with item pool size. These findings establish embedding landscapes as non-uniform semantic spaces requiring principled optimization rather than default full-vector usage.

</details>


### [314] [FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices](https://arxiv.org/abs/2601.17063)
*Byeongju Kim,Jungwan Lee,Donghyeon Han,Hoi-Jun Yoo,Sangyeob Kim*

Main category: cs.LG

TL;DR: 本文提出FlashMoE系统，通过将非活跃专家卸载至SSD并在有限RAM下实现高效MoE推理，结合轻量级ML缓存策略提升缓存命中率与推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有MoE推理系统依赖DRAM卸载，难以适应内存受限的端侧环境；随着MoE模型规模达数百GB，RAM卸载已不切实际。

Method: 提出FlashMoE系统，采用SSD卸载 inactive experts，并设计融合时效性与频次信号的轻量级ML缓存策略以优化专家复用、降低I/O开销；在真实桌面平台验证。

Result: 在真实硬件上，FlashMoE相比LRU/LFU等策略缓存命中率最高提升51%，推理速度相较现有MoE系统最高提升2.6倍。

Conclusion: FlashMoE为内存受限设备上的大规模MoE模型提供了可行、高效的端侧推理方案，显著提升了存储效率与推理性能。

Abstract: Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.

</details>


### [315] [Multi-Agent Deep Reinforcement Learning Under Constrained Communications](https://arxiv.org/abs/2601.17069)
*Shahil Shaik,Jonathon M. Smereka,Yue Wang*

Main category: cs.LG

TL;DR: 本文提出了一种完全去中心化的多智能体强化学习框架DG-MAPPO，通过分布式图注意力网络（D-GAT）实现多跳通信下的全局状态推断，无需任何中心化训练或全局状态信息，在多个基准任务中超越主流CTDE方法。


<details>
  <summary>Details</summary>
Motivation: 现有CTDE范式依赖全局状态，存在可扩展性、鲁棒性和泛化性瓶颈；实际中面对队友增减或环境变化时易失效且重训练成本高；而分布式方法仅依赖本地信息和点对点通信，更具适应性。

Method: 提出分布式图注意力网络（D-GAT）用于多跳通信下的全局状态推断；在此基础上构建DG-MAPPO框架，各智能体仅基于局部观测、多跳通信与共享/平均奖励，独立优化本地策略与价值函数。

Result: 在StarCraftII、Google Research Football和Multi-Agent Mujoco上显著优于强CTDE基线，尤其在同质与异质协作任务中展现出更优协调能力与鲁棒性。

Conclusion: DG-MAPPO是首个完全摆脱中心化特权信息依赖的MARL方法，为鲁棒、可扩展的多智能体协作提供了新范式。

Abstract: Centralized training with decentralized execution (CTDE) has been the dominant paradigm in multi-agent reinforcement learning (MARL), but its reliance on global state information during training introduces scalability, robustness, and generalization bottlenecks. Moreover, in practical scenarios such as adding/dropping teammates or facing environment dynamics that differ from the training, CTDE methods can be brittle and costly to retrain, whereas distributed approaches allow agents to adapt using only local information and peer-to-peer communication. We present a distributed MARL framework that removes the need for centralized critics or global information. Firstly, we develop a novel Distributed Graph Attention Network (D-GAT) that performs global state inference through multi-hop communication, where agents integrate neighbor features via input-dependent attention weights in a fully distributed manner. Leveraging D-GAT, we develop the distributed graph-attention MAPPO (DG-MAPPO) -- a distributed MARL framework where agents optimize local policies and value functions using local observations, multi-hop communication, and shared/averaged rewards. Empirical evaluation on the StarCraftII Multi-Agent Challenge, Google Research Football, and Multi-Agent Mujoco demonstrates that our method consistently outperforms strong CTDE baselines, achieving superior coordination across a wide range of cooperative tasks with both homogeneous and heterogeneous teams. Our distributed MARL framework provides a principled and scalable solution for robust collaboration, eliminating the need for centralized training or global observability. To the best of our knowledge, DG-MAPPO appears to be the first to fully eliminate reliance on privileged centralized information, enabling agents to learn and act solely through peer-to-peer communication.

</details>


### [316] [Attention-Based Variational Framework for Joint and Individual Components Learning with Applications in Brain Network Analysis](https://arxiv.org/abs/2601.17073)
*Yifei Zhang,Meimei Liu,Zhengwu Zhang*

Main category: cs.LG

TL;DR: 本文提出CM-JIVNet模型，用于整合结构连接（SC）与功能连接（FC）数据，通过概率建模和多头注意力融合，解耦联合与模态特异性特征，在HCP-YA数据上实现了更优的跨模态重建与行为预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效整合高维、非线性的SC与FC数据，且难以区分跨模态共享信息与模态特异性变异，限制了对脑-行为关联机制的理解。

Method: 提出Cross-Modal Joint-Individual Variational Network（CM-JIVNet），一种基于变分推断的统一概率框架，结合多头注意力融合模块，学习配对SC-FC数据的分解式潜在表征，显式建模联合与个体成分。

Result: 在HCP-YA数据上验证表明，CM-JIVNet在SC↔FC跨模态重建任务及多种行为性状预测任务中均优于现有方法；其学习到的潜在空间具有可解释性与可扩展性。

Conclusion: CM-JIVNet为大规模多模态脑连接组分析提供了鲁棒、可解释且可扩展的新范式，有助于深入理解SC-FC耦合及其与行为表型的关系。

Abstract: Brain organization is increasingly characterized through multiple imaging modalities, most notably structural connectivity (SC) and functional connectivity (FC). Integrating these inherently distinct yet complementary data sources is essential for uncovering the cross-modal patterns that drive behavioral phenotypes. However, effective integration is hindered by the high dimensionality and non-linearity of connectome data, complex non-linear SC-FC coupling, and the challenge of disentangling shared information from modality-specific variations. To address these issues, we propose the Cross-Modal Joint-Individual Variational Network (CM-JIVNet), a unified probabilistic framework designed to learn factorized latent representations from paired SC-FC datasets. Our model utilizes a multi-head attention fusion module to capture non-linear cross-modal dependencies while isolating independent, modality-specific signals. Validated on Human Connectome Project Young Adult (HCP-YA) data, CM-JIVNet demonstrates superior performance in cross-modal reconstruction and behavioral trait prediction. By effectively disentangling joint and individual feature spaces, CM-JIVNet provides a robust, interpretable, and scalable solution for large-scale multimodal brain analysis.

</details>


### [317] [PhysE-Inv: A Physics-Encoded Inverse Modeling approach for Arctic Snow Depth Prediction](https://arxiv.org/abs/2601.17074)
*Akila Sampath,Vandana Janeja,Jianwu Wang*

Main category: cs.LG

TL;DR: 本文提出PhysE-Inv框架，结合LSTM Encoder-Decoder、多头注意力与物理引导的对比学习，通过物理约束的满射反演方法，利用静水平衡前向模型和潜空间物理正则化，在缺乏真值标签和数据稀疏噪声条件下，显著提升北极雪深估计精度与物理解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于过程或数据驱动的北极雪深估计方法，要么对稀疏数据高度敏感，要么缺乏气候应用所需的物理可解释性。

Method: 提出PhysE-Inv框架：1）采用LSTM Encoder-Decoder与多头注意力的序列架构；2）引入物理引导的对比学习；3）构建基于静水平衡前向模型的代理目标，并在潜空间施加重建物理正则化，实现物理约束的满射反演。

Result: 相比SOTA基线，预测误差降低20%，且在物理一致性与抗数据稀疏性方面表现更优。

Conclusion: PhysE-Inv为噪声容忍、可解释的反演建模提供了新范式，适用于地理空间与冰冻圈等广泛领域。

Abstract: The accurate estimation of Arctic snow depth ($h_s$) remains a critical time-varying inverse problem due to the extreme scarcity and noise inherent in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, an LSTM Encoder-Decoder with Multi-head Attention and physics-guided contrastive learning, with physics-guided inference.Our core innovation lies in a surjective, physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct $h_s$ ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20\% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. This approach pioneers a path for noise-tolerant, interpretable inverse modeling, with wide applicability in geospatial and cryospheric domains.

</details>


### [318] [E2PL: Effective and Efficient Prompt Learning for Incomplete Multi-view Multi-Label Class Incremental Learning](https://arxiv.org/abs/2601.17076)
*Jiajun Chen,Yue Wu,Kai Huang,Wen Xi,Yangyang Wu,Xiaoye Miao,Mengying Zhu,Meng Xi,Guanjie Cheng*

Main category: cs.LG

TL;DR: 本文提出了一个新任务IMvMLCIL，用于解决多视图多标签分类中视图缺失和类别动态增长的挑战，并设计了高效提示学习框架E2PL，包含任务定制提示、缺失感知提示、高效原型张量化和动态对比学习，显著提升了效果与效率。


<details>
  <summary>Details</summary>
Motivation: 现实网络环境中存在视图缺失和新类别持续出现的问题，而现有方法无法同时适应新类别并高效处理各种缺失视图模式，导致可扩展性差。

Method: 提出E2PL框架，包括任务定制提示（支持类别增量学习）、缺失感知提示（适配任意视图缺失）、基于原子张量分解的高效原型张量化模块（将参数复杂度从指数级降至线性级），以及动态对比学习策略（建模不同缺失模式间的依赖关系）。

Result: 在三个基准数据集上的实验表明，E2PL在有效性与效率上均持续优于现有最先进方法。

Conclusion: E2PL为不完整多视图多标签类增量学习提供了系统性解决方案，兼具强鲁棒性、高适应性与良好可扩展性，适用于真实Web场景。

Abstract: Multi-view multi-label classification (MvMLC) is indispensable for modern web applications aggregating information from diverse sources. However, real-world web-scale settings are rife with missing views and continuously emerging classes, which pose significant obstacles to robust learning. Prevailing methods are ill-equipped for this reality, as they either lack adaptability to new classes or incur exponential parameter growth when handling all possible missing-view patterns, severely limiting their scalability in web environments. To systematically address this gap, we formally introduce a novel task, termed \emph{incomplete multi-view multi-label class incremental learning} (IMvMLCIL), which requires models to simultaneously address heterogeneous missing views and dynamic class expansion. To tackle this task, we propose \textsf{E2PL}, an Effective and Efficient Prompt Learning framework for IMvMLCIL. \textsf{E2PL} unifies two novel prompt designs: \emph{task-tailored prompts} for class-incremental adaptation and \emph{missing-aware prompts} for the flexible integration of arbitrary view-missing scenarios. To fundamentally address the exponential parameter explosion inherent in missing-aware prompts, we devise an \emph{efficient prototype tensorization} module, which leverages atomic tensor decomposition to elegantly reduce the prompt parameter complexity from exponential to linear w.r.t. the number of views. We further incorporate a \emph{dynamic contrastive learning} strategy explicitly model the complex dependencies among diverse missing-view patterns, thus enhancing the model's robustness. Extensive experiments on three benchmarks demonstrate that \textsf{E2PL} consistently outperforms state-of-the-art methods in both effectiveness and efficiency. The codes and datasets are available at https://anonymous.4open.science/r/code-for-E2PL.

</details>


### [319] [SFO: Learning PDE Operators via Spectral Filtering](https://arxiv.org/abs/2601.17090)
*Noam Koren,Rafael Moschopoulos,Kira Radinsky,Elad Hazan*

Main category: cs.LG

TL;DR: 本文提出了Spectral Filtering Operator (SFO)，一种基于通用谱基（USB）参数化积分核的神经算子，通过利用离散格林函数的空间线性动力系统结构，在多个PDE基准任务中实现了更高精度和更少参数。


<details>
  <summary>Details</summary>
Motivation: 神经算子在捕捉偏微分方程（PDE）解映射中的长程、非局部相互作用时效率不足。

Method: 提出SFO，使用从希尔伯特矩阵特征模导出的固定正交USB来参数化积分核，并利用离散格林函数具有的空间LDS结构，仅学习快速衰减特征值的谱系数。

Result: 在六个PDE基准（包括反应-扩散、流体动力学和3D电磁学）上达到SOTA精度，相对强基线误差降低最高达40%，且参数量显著减少。

Conclusion: SFO通过紧凑、理论驱动的谱表示，有效提升了神经算子对PDE解映射的建模效率与精度。

Abstract: Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.

</details>


### [320] [CUROCKET: Optimizing ROCKET for GPU](https://arxiv.org/abs/2601.17091)
*Ole Stüven,Keno Moenck,Thorsten Schüppstuhl*

Main category: cs.LG

TL;DR: 本文提出了CUROCKET，一种在GPU上高效执行ROCKET算法的方法，解决了ROCKET中不规则卷积核导致GPU计算效率低的问题，实现了比CPU版本高达11倍的每瓦特计算效率提升。


<details>
  <summary>Details</summary>
Motivation: ROCKET是一种高效的时序分类特征提取算法，但现有实现主要运行在CPU上；而其卷积操作适合GPU并行加速，但由于使用不规则（inhomogeneous）卷积核，标准GPU卷积方法效率低下，因此需要设计适配GPU的高效实现。

Method: 提出一种专为GPU优化的ROCKET实现算法（即CUROCKET），通过适配不规则卷积核的特性，提升GPU上的卷积计算效率。

Result: CUROCKET在GPU上实现了最高达11倍的每瓦特计算效率提升，显著优于CPU版ROCKET；代码已开源。

Conclusion: CUROCKET成功将ROCKET迁移至GPU平台，在保持高精度的同时大幅提升能效，为时序分类提供了更高效、可扩展的解决方案。

Abstract: ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.

</details>


### [321] [The Triangle of Similarity: A Multi-Faceted Framework for Comparing Neural Network Representations](https://arxiv.org/abs/2601.17093)
*Olha Sirikova,Alvin Chan*

Main category: cs.LG

TL;DR: 本文提出了‘相似性三角’框架，从静态表征相似性、功能相似性和稀疏性相似性三个互补角度比较神经网络表征，揭示了模型架构对表征相似性的主导作用及剪枝对表征的正则化效应。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络表征比较方法视角单一，难以全面理解与验证科学应用中的模型。

Method: 提出‘相似性三角’框架，整合静态表征相似性（CKA/Procrustes）、功能相似性（线性模式连通性或预测相似性）和稀疏性相似性（剪枝鲁棒性），并在CNN、ViT和多模态模型上，使用ImageNetV2和CIFAR-10数据集进行分析。

Result: 发现：(1) 架构族是表征相似性的主要决定因素；(2) CKA自相似性与任务准确率在剪枝过程中强相关但准确率下降更快；(3) 对某些模型对，剪枝可正则化表征并暴露共享计算核心。

Conclusion: 该框架为评估模型是否收敛于相似内部机制提供了更全面的方法，有助于科学研究中的模型选择与分析。

Abstract: Comparing neural network representations is essential for understanding and validating models in scientific applications. Existing methods, however, often provide a limited view. We propose the Triangle of Similarity, a framework that combines three complementary perspectives: static representational similarity (CKA/Procrustes), functional similarity (Linear Mode Connectivity or Predictive Similarity), and sparsity similarity (robustness under pruning). Analyzing a range of CNNs, Vision Transformers, and Vision-Language Models using both in-distribution (ImageNetV2) and out-of-distribution (CIFAR-10) testbeds, our initial findings suggest that: (1) architectural family is a primary determinant of representational similarity, forming distinct clusters; (2) CKA self-similarity and task accuracy are strongly correlated during pruning, though accuracy often degrades more sharply; and (3) for some model pairs, pruning appears to regularize representations, exposing a shared computational core. This framework offers a more holistic approach for assessing whether models have converged on similar internal mechanisms, providing a useful tool for model selection and analysis in scientific research.

</details>


### [322] [Boltzmann-GPT: Bridging Energy-Based World Models and Language Generation](https://arxiv.org/abs/2601.17094)
*Junichiro Niimi*

Main category: cs.LG

TL;DR: 本文提出'嘴不是大脑'的架构原则，将世界模型与语言模型分离，通过Deep Boltzmann Machine（DBM）建模领域结构，适配器连接潜在信念状态与嵌入空间，并冻结GPT-2提供语言能力；在亚马逊手机评论数据上的实验表明，该架构显著提升情感相关性、降低困惑度、增强语义相似性，并支持因果干预与可控生成。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型是否真正理解世界，而非仅生成似是而非的语言；旨在分离语言能力与世界理解，验证世界模型对可控、一致文本生成的必要性。

Method: 提出三组件架构：1）基于能量的世界模型（Deep Boltzmann Machine）建模领域结构；2）适配器将DBM的潜在信念状态映射至语言模型嵌入空间；3）冻结GPT-2作为纯语言生成器。在智能手机评论域实例化并开展条件生成、能量判别与因果干预实验。

Result: 1）相比纯提示生成，经世界模型条件化的生成显著提升情感相关性、降低困惑度、提高语义相似性；2）DBM能量函数能有效区分合理与不合理市场配置（如品牌-价格组合）；3）对属性的干预可因果影响生成文本，且干预结果分布与真实样本一致。

Conclusion: 即使小规模语言模型，只要耦合恰当的世界模型，即可实现一致、可控、因果可解释的生成；为‘语言能力’与‘世界理解’的分离提供了实证支持。

Abstract: Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.

</details>


### [323] [MambaNet: Mamba-assisted Channel Estimation Neural Network With Attention Mechanism](https://arxiv.org/abs/2601.17108)
*Dianxin Luan,Chengsi Liang,Jie Huang,Zheng Lin,Kaitao Meng,John Thompson,Cheng-Xiang Wang*

Main category: cs.LG

TL;DR: 本文提出了一种结合自注意力机制的Mamba辅助神经网络框架，用于OFDM系统中低复杂度、高性能的大规模子载波信道估计。通过引入双向选择性扫描和定制化Mamba结构，该方法在保持较低空间复杂度的同时，有效建模子载波间长程依赖关系，并在3GPP信道仿真中展现出优于基线模型的性能与参数效率。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计算法在大规模OFDM系统中面临复杂度高、难以建模子载波间长程依赖的问题；现有基于Transformer的神经网络虽有效但空间复杂度高；而标准Mamba是因果结构，不适用于非因果的信道增益建模。

Method: 提出一种融合自注意力机制的Mamba辅助神经网络框架；采用定制化Mamba架构，关键改进为双向选择性扫描以适配非因果信道特性；整体结构兼顾Mamba的线性复杂度优势与自注意力的全局建模能力。

Result: 在3GPP TS 36.101信道下仿真表明，相比其他神经网络基线方法，所提方法在降低可调参数数量的同时，实现了更优的信道估计性能（如更低的NMSE）；且空间复杂度低于Transformer类模型。

Conclusion: 该Mamba-assisted框架为大规模OFDM信道估计提供了一种高效、低复杂、高性能的新范式，验证了改进Mamba结构在无线通信物理层AI任务中的有效性与潜力。

Abstract: This paper proposes a Mamba-assisted neural network framework incorporating self-attention mechanism to achieve improved channel estimation with low complexity for orthogonal frequency-division multiplexing (OFDM) waveforms, particularly for configurations with a large number of subcarriers. With the integration of customized Mamba architecture, the proposed framework handles large-scale subcarrier channel estimation efficiently while capturing long-distance dependencies among these subcarriers effectively. Unlike conventional Mamba structure, this paper implements a bidirectional selective scan to improve channel estimation performance, because channel gains at different subcarriers are non-causal. Moreover, the proposed framework exhibits relatively lower space complexity than transformer-based neural networks. Simulation results tested on the 3GPP TS 36.101 channel demonstrate that compared to other baseline neural network solutions, the proposed method achieves improved channel estimation performance with a reduced number of tunable parameters.

</details>


### [324] [Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts](https://arxiv.org/abs/2601.17111)
*Xuan-Phi Nguyen,Shrey Pandit,Austin Xu,Caiming Xiong,Shafiq Joty*

Main category: cs.LG

TL;DR: 本文提出Least-Loaded Expert Parallelism (LLEP)，一种动态重路由策略，解决MoE模型在专家并行（EP）中因路由失衡导致的设备过载问题，显著提升推理与后训练速度及内存效率。


<details>
  <summary>Details</summary>
Motivation: MoE模型虽有负载均衡约束，但实际路由仍严重失衡；而专家并行（EP）依赖均衡假设，在失衡时易引发设备计算/内存瓶颈，尤其在无法施加显式负载均衡的后训练与推理阶段。

Method: 提出LLEP算法：根据设备负载实时检测过载，将超额token和对应专家参数动态迁移至空闲设备，在满足内存约束下最小化整体延迟。

Result: 在多种规模模型上，LLEP相较标准EP最高提速5倍、峰值内存降低4倍；在gpt-oss-120b上推理快约1.9倍；理论分析与大量实验（含消融）验证有效性。

Conclusion: LLEP为硬件适配的MoE部署提供了实用、高效且可调的专家并行新范式，揭示了负载均衡、通信开销与内存限制间的关键权衡。

Abstract: Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.

</details>


### [325] [Low-Rank Tensor Approximation of Weights in Large Language Models via Cosine Lanczos Bidiagonalization](https://arxiv.org/abs/2601.17112)
*A. El Ichi,K. Jbilou*

Main category: cs.LG

TL;DR: 本文提出了一种基于cproduct的张量压缩框架，用于对大语言模型（LLMs）中的权重张量进行低秩近似，以降低内存占用和计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）虽然在自然语言任务中表现出色，但其巨大的内存占用和计算开销限制了实际应用。

Method: 利用cproduct代数结构，在变换域中表示嵌入层、注意力投影和前馈网络等权重张量，并对前后切片进行联合低秩张量因子近似，从而实现高效压缩。

Result: 该方法能有效利用多维相关性，超越传统SVD方法，实现更高效的计算与压缩。

Conclusion: 所提出的基于cproduct的张量压缩框架为降低LLMs的资源消耗提供了新思路，具有良好的理论基础与实践潜力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language tasks but suffer from extremely large memory footprints and computational costs. In this paper, we introduce a tensor compression framework based on the cproduct for computing low rank approximation In the first part of our approach, we leverage the algebraic structure of the cproduct to represent weight tensors such as those in embedding layers, attention projections, and feed forward networks in a transform domain where frontal slices can be jointly approximated by low rank tensor factors. This enables computationally efficient compression that exploits multidimensional correlations beyond traditional SVD methods.

</details>


### [326] [How does Graph Structure Modulate Membership-Inference Risk for Graph Neural Networks?](https://arxiv.org/abs/2601.17130)
*Megha Khosla*

Main category: cs.LG

TL;DR: 本文研究图神经网络（GNN）中节点级成员推断（MI）的隐私泄露问题，强调图结构特异性，分析训练图构建与推理时边访问对MI的影响，并指出传统泛化差距不能准确反映MI风险，同时探讨差分隐私GNN在图场景下的可审计性局限。


<details>
  <summary>Details</summary>
Motivation: GNN在敏感应用中存在训练数据泄露风险，但现有隐私研究多借鉴非图领域结论，缺乏针对图结构（尤其是节点级成员推断）的专门分析。

Method: 形式化节点邻域元组上的成员推断（MI）；系统考察训练图构造方式（如snowball采样 vs 随机采样）和推理时是否允许跨训练-测试边访问两个维度；实证评估MI优势、泛化差距与边访问的关系；适配统计交换性定义，分析归纳式图划分对差分隐私GNN审计性的影响。

Result: Snowball采样因覆盖偏差损害泛化；推理时允许跨train-test边访问可提升测试准确率、缩小train-test差距、并显著降低多数模型和数据集上的成员推断优势；泛化差距不能可靠代理MI风险（MI可独立于差距变化而升降）；归纳式图划分（随机或snowball）破坏统计交换性，使标准差分隐私成员优势界不适用。

Conclusion: 图结构特性（尤其是边访问权限和图采样策略）对GNN成员隐私风险具有决定性影响；需发展图原生的隐私分析框架与审计方法，而非直接迁移非图领域结论。

Abstract: Graph neural networks (GNNs) have become the standard tool for encoding data and their complex relationships into continuous representations, improving prediction accuracy in several machine learning tasks like node classification and link prediction. However, their use in sensitive applications has raised concerns about the potential leakage of training data. Research on privacy leakage in GNNs has largely been shaped by findings from non-graph domains, such as images and tabular data. We emphasize the need of graph specific analysis and investigate the impact of graph structure on node level membership inference. We formalize MI over node-neighbourhood tuples and investigate two important dimensions: (i) training graph construction and (ii) inference-time edge access. Empirically, snowball's coverage bias often harms generalisation relative to random sampling, while enabling inter-train-test edges at inference improves test accuracy, shrinks the train-test gap, and yields the lowest membership advantage across most of the models and datasets. We further show that the generalisation gap empirically measured as the performance difference between the train and test nodes is an incomplete proxy for MI risk: access to edges dominates-MI can rise or fall independent of gap changes. Finally, we examine the auditability of differentially private GNNs, adapting the definition of statistical exchangeability of train-test data points for graph based models. We show that for node level tasks the inductive splits (random or snowball sampled) break exchangeability, limiting the applicability of standard bounds for membership advantage of differential private models.

</details>


### [327] [ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning](https://arxiv.org/abs/2601.17135)
*Jakob Karalus,Friedhelm Schwenker*

Main category: cs.LG

TL;DR: ConceptACT 是一种改进的模仿学习方法，通过在训练阶段利用人类提供的语义概念（如物体属性、空间关系、任务约束）来提升机器人操作技能的学习效率，无需在部署时依赖语言输入；其核心是修改Transformer架构，在编码器最后一层引入概念感知的交叉注意力机制，并以人类标注为监督信号；实验表明其收敛更快、样本效率更高，且注意力机制的架构级整合优于辅助损失或语言条件化方法。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法仅依赖低层传感器数据，忽略了人类固有的丰富任务语义知识，导致学习效率低下。

Method: 提出ConceptACT，扩展Action Chunking with Transformers（ACT），在演示采集阶段引入 episode-level 语义概念标注；设计改进的Transformer架构，使编码器最后一层实现概念感知的交叉注意力，并以人类标注为监督目标进行对齐。

Result: 在两个含逻辑约束的机器人操作任务上，ConceptACT比标准ACT收敛更快、样本效率更高；证明了注意力机制驱动的架构级语义集成显著优于辅助预测损失或语言条件化模型。

Conclusion: 恰当整合语义监督可为机器人学习提供强归纳偏置，显著提升学习效率；语义信息应在模型架构层面（如注意力）而非仅作为辅助损失或运行时条件注入。

Abstract: Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.

</details>


### [328] [Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging](https://arxiv.org/abs/2601.17180)
*Inés Gonzalez-Pepe,Vinuyan Sivakolunthu,Jacob Fortin,Yohan Chatelain,Tristan Glatard*

Main category: cs.LG

TL;DR: 本文提出两种新型的max pooling和unpooling变体（Conservative & Aggressive NaNs），利用CNN中数值不确定性识别并跳过受噪声主导的冗余卷积操作，从而提升推理效率，且无需修改网络结构。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在神经影像学中日益依赖大型架构，尽管硬件进步，计算效率仍是持续挑战；作者观察到大量卷积操作受数值噪声主导、对输出影响可忽略，存在显著冗余。

Method: 提出Conservative NaNs和Aggressive NaNs两种方法，在max pooling/unpooling中识别数值不稳定的体素并置为NaN，使后续层跳过相关计算；完全基于PyTorch实现，无需改变模型架构。

Result: 在含≥50% NaN的输入上获得一致运行时提升；当NaN比例超2/3（常见于神经影像）时，平均推理加速达1.67x；Conservative NaNs平均减少30%卷积操作，最高跳过64.64%；Aggressive NaNs最高跳过69.30%，但可能轻微影响性能。

Conclusion: 数值不确定性可被主动利用以削减冗余计算，显著提升CNN推理效率，尤其适用于神经影像等高NaN比例场景。

Abstract: Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.

</details>


### [329] [Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data](https://arxiv.org/abs/2601.17183)
*Farzam Asad,Junaid Saif Khan,Maria Tariq,Sundus Munir,Muhammad Adnan Khan*

Main category: cs.LG

TL;DR: 本文研究了FedProx算法在心脏病预测中的联邦学习应用，通过模拟非独立同分布（non-IID）的临床数据，验证其在保护患者隐私前提下优于集中式和孤立本地模型的性能。


<details>
  <summary>Details</summary>
Motivation: 医疗数据因隐私法规（如HIPAA、GDPR）难以共享，而临床数据天然具有非IID特性，需适配异构环境的联邦学习方法。

Method: 基于UCI心脏病数据集，模拟四个异构医院客户端（源自Cleveland Clinic的303例患者），按人口统计学分层构建non-IID数据划分；采用FedProx算法（mu=0.05），开展50次独立实验与消融研究。

Result: FedProx达到85.00%准确率，优于集中式学习（83.33%）和平均孤立本地模型（78.45%）；实证表明proximal正则化有效缓解客户端漂移。

Conclusion: FedProx适用于真实医疗联邦场景，为医院IT管理员提供可落地的隐私保护协同建模方案与实践指南。

Abstract: Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.

</details>


### [330] [Rethinking Benchmarks for Differentially Private Image Classification](https://arxiv.org/abs/2601.17189)
*Sabrina Mokhtari,Sara Kodeiri,Shubhankar Mohapatra,Florian Tramer,Gautam Kamath*

Main category: cs.LG

TL;DR: 本文重新审视了差分隐私图像分类的基准测试，提出了一套全面的基准测试集，并在这些基准上评估了现有技术的有效性，同时建立了公开的排行榜以跟踪差分隐私机器学习的进展。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私图像分类的基准测试不够全面，难以在多种设置下公平评估不同技术的有效性。

Method: 提出一套涵盖多种设置（如有无额外数据、凸优化场景、不同性质数据集）的综合基准测试集，并在这些基准上系统测试已有的差分隐私机器学习技术。

Result: 验证了部分已有技术在不同设置下的有效性差异，并建立了首个面向社区的差分隐私机器学习公开排行榜。

Conclusion: 全面且多样化的基准测试对推动差分隐私机器学习研究至关重要，公开排行榜有助于促进社区协作与技术进步。

Abstract: We revisit benchmarks for differentially private image classification. We suggest a comprehensive set of benchmarks, allowing researchers to evaluate techniques for differentially private machine learning in a variety of settings, including with and without additional data, in convex settings, and on a variety of qualitatively different datasets. We further test established techniques on these benchmarks in order to see which ideas remain effective in different settings. Finally, we create a publicly available leader board for the community to track progress in differentially private machine learning.

</details>


### [331] [PUNCH: Physics-informed Uncertainty-aware Network for Coronary Hemodynamics](https://arxiv.org/abs/2601.17192)
*Sukirt Thakur,Marcus Roper,Yang Zhou,Reza Akbarian Bafghi,Brahmajee K. Nallamothu,C. Alberto Figueroa,Srinivas Paruchuri,Scott Burger,Maziar Raissi*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息神经网络与变分推断的非侵入式、不确定性感知框架，可直接从常规冠状动脉造影图像中估计冠状动脉血流储备（CFR），无需侵入性测量或真实流量标签，且单GPU运行约3分钟。在合成数据和12例临床患者中均验证了其高精度与不确定性校准能力，有望提升冠状微血管功能障碍（CMD）的可及性与诊断可靠性。


<details>
  <summary>Details</summary>
Motivation: 冠状微血管功能障碍（CMD）全球患病率高但诊断不足，因金标准生理测量具有侵入性和可重复性差的问题。

Method: 结合物理信息神经网络与变分推断，基于对比剂传输的第一性原理建模，从标准冠脉造影序列（kymographs）中无监督地推断血流并输出不确定性估计。

Result: 在1000例合成数据中，预测不确定性与误差高度相关（Pearson r=0.997）；在12例临床LAD血管中，PUNCH-CFR与有创热稀释法高度一致（Pearson r=0.90, p=6.3e-5），且置信区间窄于重复有创测量的变异度。

Conclusion: 该框架将常规冠脉造影转化为定量、不确定性感知的CMD评估工具，具备可扩展性、安全性和高重复性，有望推动全球CMD诊断普及，并确立临床影像中物理引导、个体化推理的新范式。

Abstract: Coronary microvascular dysfunction (CMD) affects millions worldwide yet remains underdiagnosed because gold-standard physiological measurements are invasive and variably reproducible. We introduce a non-invasive, uncertainty-aware framework for estimating coronary flow reserve (CFR) directly from standard angiography. The system integrates physics-informed neural networks with variational inference to infer coronary blood flow from first-principles models of contrast transport, without requiring ground-truth flow measurements. The pipeline runs in approximately three minutes per patient on a single GPU, with no population-level training.
  Using 1{,}000 synthetic spatiotemporal intensity maps (kymographs) with controlled noise and artifacts, the framework reliably identifies degraded data and outputs appropriately inflated uncertainty estimates, showing strong correspondence between predictive uncertainty and error (Pearson $r = 0.997$, Spearman $ρ= 0.998$). Clinical validation in 12 patients shows strong agreement between PUNCH-derived CFR and invasive bolus thermodilution (Pearson $r = 0.90$, $p = 6.3 \times 10^{-5}$). We focus on the LAD, the artery most commonly assessed in routine CMD testing. Probabilistic CFR estimates have confidence intervals narrower than the variability of repeated invasive measurements.
  By transforming routine angiography into quantitative, uncertainty-aware assessment, this approach enables scalable, safer, and more reproducible evaluation of coronary microvascular function. Because standard angiography is widely available globally, the framework could expand access to CMD diagnosis and establish a new paradigm for physics-informed, patient-specific inference from clinical imaging.

</details>


### [332] [Accelerated Sinkhorn Algorithms for Partial Optimal Transport](https://arxiv.org/abs/2601.17196)
*Nghia Thu Truong,Qui Phu Pham,Quang Nguyen,Dung Luong,Mai Tran*

Main category: cs.LG

TL;DR: 本文提出了加速Sinkhorn算法（ASPOT）用于部分最优传输（POT），通过结合交替最小化与Nesterov加速，将复杂度优化至O(n^{7/3}ε^{-5/3})，并改进了经典Sinkhorn中熵参数γ的选择策略。


<details>
  <summary>Details</summary>
Motivation: 现有基于Sinkhorn的部分最优传输（POT）方法复杂度次优，限制了其在大规模或含异常值场景下的可扩展性。

Method: 提出ASPOT算法，将交替最小化与Nesterov风格加速引入POT框架；同时分析并优化经典Sinkhorn中熵参数γ的选取以提升收敛速率。

Result: ASPOT达到O(n^{7/3}ε^{-5/3})的理论复杂度；实验验证了理论改进，并在真实数据上展现出优越性能。

Conclusion: ASPOT显著提升了POT问题的计算效率与实用性，为不等质量分布及含噪声场景下的最优传输提供了更优解决方案。

Abstract: Partial Optimal Transport (POT) addresses the problem of transporting only a fraction of the total mass between two distributions, making it suitable when marginals have unequal size or contain outliers. While Sinkhorn-based methods are widely used, their complexity bounds for POT remain suboptimal and can limit scalability. We introduce Accelerated Sinkhorn for POT (ASPOT), which integrates alternating minimization with Nesterov-style acceleration in the POT setting, yielding a complexity of $\mathcal{O}(n^{7/3}\varepsilon^{-5/3})$. We also show that an informed choice of the entropic parameter $γ$ improves rates for the classical Sinkhorn method. Experiments on real-world applications validate our theories and demonstrate the favorable performance of our proposed methods.

</details>


### [333] [SpecBridge: Bridging Mass Spectrometry and Molecular Representations via Cross-Modal Alignment](https://arxiv.org/abs/2601.17204)
*Yinkai Wang,Yan Zhou Chen,Xiaohui Chen,Li-Ping Liu,Soha Hassoun*

Main category: cs.LG

TL;DR: 本文提出SpecBridge，一种新颖的隐式对齐框架，将小分子结构鉴定视为几何对齐问题，通过微调光谱编码器并将其投影到冻结的分子基础模型（ChemBERTa）的潜在空间中，实现高效准确的MS/MS谱图识别。


<details>
  <summary>Details</summary>
Motivation: 小分子在非靶向质谱分析中因谱库不全导致鉴定困难，现有深度学习方法存在显式生成模型或联合对比模型的局限性。

Method: SpecBridge微调自监督光谱编码器DreaMS，使其投影至冻结的分子基础模型ChemBERTa的潜在空间，并通过余弦相似度在预计算分子嵌入库中进行检索。

Result: 在MassSpecGym、Spectraverse和MSnLib基准测试中，SpecBridge相较强神经基线模型将top-1检索准确率相对提升约20–25%，且可训练参数量少。

Conclusion: 对齐冻结的基础模型是一种实用、稳定的小分子鉴定替代方案，优于从头设计新架构。

Abstract: Small-molecule identification from tandem mass spectrometry (MS/MS) remains a bottleneck in untargeted settings where spectral libraries are incomplete. While deep learning offers a solution, current approaches typically fall into two extremes: explicit generative models that construct molecular graphs atom-by-atom, or joint contrastive models that learn cross-modal subspaces from scratch. We introduce SpecBridge, a novel implicit alignment framework that treats structure identification as a geometric alignment problem. SpecBridge fine-tunes a self-supervised spectral encoder (DreaMS) to project directly into the latent space of a frozen molecular foundation model (ChemBERTa), and then performs retrieval by cosine similarity to a fixed bank of precomputed molecular embeddings. Across MassSpecGym, Spectraverse, and MSnLib benchmarks, SpecBridge improves top-1 retrieval accuracy by roughly 20-25% relative to strong neural baselines, while keeping the number of trainable parameters small. These results suggest that aligning to frozen foundation models is a practical, stable alternative to designing new architectures from scratch. The code for SpecBridge is released at https://github.com/HassounLab/SpecBridge.

</details>


### [334] [NewPINNs: Physics-Informing Neural Networks Using Conventional Solvers for Partial Differential Equations](https://arxiv.org/abs/2601.17207)
*Maedeh Makki,Satish Chandran,Maziar Raissi,Adrien Grenier,Behzad Mohebbi*

Main category: cs.LG

TL;DR: NewPINNs是一种新型物理信息学习框架，将神经网络与传统数值求解器耦合，通过求解器一致性定义学习目标，避免了残差损失设计和微分方程残差显式计算，提升了在刚性或非线性问题中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决标准物理信息神经网络（PINNs）存在的优化病态、损失权重敏感、在刚性或非线性区域性能差等问题。

Method: 将数值求解器直接嵌入训练循环，神经网络生成候选解，由求解器推进演化，训练目标是最小化网络预测与求解器演化结果之间的差异，形成‘拉-推’交互机制。

Result: 在多个前向与反向问题（涉及有限体积、有限元和谱方法求解器）上验证了该方法的有效性，显著缓解了传统PINNs的典型失效模式。

Conclusion: NewPINNs通过将物理约束、边界条件和数值稳定性交由成熟数值求解器处理，提升了物理驱动学习的可靠性与泛化能力，无需问题定制的损失工程。

Abstract: We introduce NewPINNs, a physics-informing learning framework that couples neural networks with conventional numerical solvers for solving differential equations. Rather than enforcing governing equations and boundary conditions through residual-based loss terms, NewPINNs integrates the solver directly into the training loop and defines learning objectives through solver-consistency. The neural network produces candidate solution states that are advanced by the numerical solver, and training minimizes the discrepancy between the network prediction and the solver-evolved state. This pull-push interaction enables the network to learn physically admissible solutions through repeated exposure to the solver's action, without requiring problem-specific loss engineering or explicit evaluation of differential equation residuals. By delegating the enforcement of physics, boundary conditions, and numerical stability to established numerical solvers, NewPINNs mitigates several well-known failure modes of standard physics-informed neural networks, including optimization pathologies, sensitivity to loss weighting, and poor performance in stiff or nonlinear regimes. We demonstrate the effectiveness of the proposed approach across multiple forward and inverse problems involving finite volume, finite element, and spectral solvers.

</details>


### [335] [PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems](https://arxiv.org/abs/2601.17495)
*Ruiyu Zhang,Lin Nie,Wai-Fung Lam,Qihao Wang,Xin Zhao*

Main category: cs.LG

TL;DR: 本文提出PEARL方法，通过少量标注数据对预训练嵌入进行软对齐，以提升最近邻检索等下游任务性能，尤其在标签稀缺场景下效果显著。


<details>
  <summary>Details</summary>
Motivation: 现实部署中，基于嵌入的最近邻检索系统常因嵌入空间几何结构与任务需求不匹配而失败；重新训练大编码器成本高，且标签稀缺、领域漂移普遍，亟需轻量、标签高效的方法优化嵌入几何。

Method: PEARL（Prototype-Enhanced Aligned Representation Learning）利用有限监督信号，将原始嵌入软对齐到类原型上，在保持维度和避免坍缩的前提下，重塑局部邻域几何结构。

Result: 在极端标签稀缺条件下，PEARL相比原始嵌入提升25.7%，相比强无监督后处理提升超21.1%，显著增强局部邻域质量；在不同标签量级下均验证了有效性。

Conclusion: PEARL在标签效率与性能间取得良好平衡，填补了纯无监督后处理与全监督投影之间的空白，为实际相似性系统提供了实用、鲁棒的嵌入优化方案。

Abstract: In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.

</details>


### [336] [JetFormer: A Scalable and Efficient Transformer for Jet Tagging from Offline Analysis to FPGA Triggers](https://arxiv.org/abs/2601.17215)
*Ruoqing Zheng,Chang Sun,Qibin Liu,Lauri Laatu,Arianna Cox,Benedikt Maier,Alexander Tapper,Jose G. F. Coutinho,Wayne Luk,Zhiqiang Que*

Main category: cs.LG

TL;DR: JetFormer是一种面向LHC粒子喷注识别的高效、可扩展的编码器-only Transformer模型，兼顾高精度离线分析与超低延迟在线触发，在多个基准上性能领先且计算高效，并支持硬件友好压缩部署。


<details>
  <summary>Details</summary>
Motivation: 现有喷注识别方法往往针对特定部署场景（如仅离线或仅在线）设计，缺乏通用性；同时，高性能模型常依赖显式成对相互作用，计算开销大，难以满足FPGA等硬件的低延迟要求。

Method: 提出JetFormer：一种处理变长粒子特征集的encoder-only Transformer架构，不依赖显式成对交互；设计硬件感知优化流程，结合多目标超参搜索、结构化剪枝与量化，生成轻量级变体（如JetFormer-tiny）。

Result: 在JetClass数据集上，大型JetFormer以37.4%更少FLOPs达到与ParT模型相当精度（差距<0.7%）；在HLS4ML 150P上较MLP、Deep Sets、Interaction Networks准确率提升3–4%；JetFormer-tiny可在FPGA上实现亚微秒级延迟。

Conclusion: JetFormer统一了建模性能与硬件可部署性，为LHC离线与在线喷注识别提供了实用、高效的Transformer解决方案。

Abstract: We present JetFormer, a versatile and scalable encoder-only Transformer architecture for particle jet tagging at the Large Hadron Collider (LHC). Unlike prior approaches that are often tailored to specific deployment regimes, JetFormer is designed to operate effectively across the full spectrum of jet tagging scenarios, from high-accuracy offline analysis to ultra-low-latency online triggering. The model processes variable-length sets of particle features without relying on input of explicit pairwise interactions, yet achieves competitive or superior performance compared to state-of-the-art methods. On the large-scale JetClass dataset, a large-scale JetFormer matches the accuracy of the interaction-rich ParT model (within 0.7%) while using 37.4% fewer FLOPs, demonstrating its computational efficiency and strong generalization. On benchmark HLS4ML 150P datasets, JetFormer consistently outperforms existing models such as MLPs, Deep Sets, and Interaction Networks by 3-4% in accuracy. To bridge the gap to hardware deployment, we further introduce a hardware-aware optimization pipeline based on multi-objective hyperparameter search, yielding compact variants like JetFormer-tiny suitable for FPGA-based trigger systems with sub-microsecond latency requirements. Through structured pruning and quantization, we show that JetFormer can be aggressively compressed with minimal accuracy loss. By unifying high-performance modeling and deployability within a single architectural framework, JetFormer provides a practical pathway for deploying Transformer-based jet taggers in both offline and online environments at the LHC. Code is available at https://github.com/walkieq/JetFormer.

</details>


### [337] [Parameter Inference and Uncertainty Quantification with Diffusion Models: Extending CDI to 2D Spatial Conditioning](https://arxiv.org/abs/2601.17224)
*Dmitrii Torbunov,Yihui Ren,Lijun Wu,Yimei Zhu*

Main category: cs.LG

TL;DR: 本文提出将条件扩散模型（CDI）扩展到二维空间条件，用于从空间观测中直接进行概率参数推断，并在会聚束电子衍射（CBED）参数反演任务中验证了其有效性，结果表明CDI能生成校准良好的后验分布，真实反映参数的不确定性，优于掩盖不确定性的标准回归方法。


<details>
  <summary>Details</summary>
Motivation: 现有CDI方法仅适用于一维时间信号的概率推断，其在更高维空间数据中的适用性尚未探索；而科学反问题中准确量化不确定性对区分可识别与模糊参数至关重要。

Method: 将CDI扩展至二维空间条件建模，实现从2D空间观测（如CBED衍射图样）直接进行概率参数推断；使用带真值的模拟CBED数据进行训练与验证。

Result: CDI在CBED反问题中生成了良好校准的后验分布：对确定性强的参数给出窄分布，对模糊参数给出合理宽泛分布；而标准回归方法虽在聚合指标上表现良好，却掩盖了真实不确定性。

Conclusion: CDI成功从时域扩展至空域，为材料表征等科学反问题提供了可靠的不确定性量化能力，支持稳健的科学推断。

Abstract: Uncertainty quantification is critical in scientific inverse problems to distinguish identifiable parameters from those that remain ambiguous given available measurements. The Conditional Diffusion Model-based Inverse Problem Solver (CDI) has previously demonstrated effective probabilistic inference for one-dimensional temporal signals, but its applicability to higher-dimensional spatial data remains unexplored. We extend CDI to two-dimensional spatial conditioning, enabling probabilistic parameter inference directly from spatial observations. We validate this extension on convergent beam electron diffraction (CBED) parameter inference - a challenging multi-parameter inverse problem in materials characterization where sample geometry, electronic structure, and thermal properties must be extracted from 2D diffraction patterns. Using simulated CBED data with ground-truth parameters, we demonstrate that CDI produces well-calibrated posterior distributions that accurately reflect measurement constraints: tight distributions for well-determined quantities and appropriately broad distributions for ambiguous parameters. In contrast, standard regression methods - while appearing accurate on aggregate metrics - mask this underlying uncertainty by predicting training set means for poorly constrained parameters. Our results confirm that CDI successfully extends from temporal to spatial domains, providing the genuine uncertainty information required for robust scientific inference.

</details>


### [338] [A Constrained Optimization Perspective of Unrolled Transformers](https://arxiv.org/abs/2601.17257)
*Javier Porras-Valenzuela,Samar Hadou,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 本文提出了一种约束优化框架来训练行为类似优化下降算法的Transformer模型，通过层间下降约束和原始-对偶训练方案，使中间表征在各层上期望单调降低损失，在视频去噪和文本分类任务中提升了鲁棒性和分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提升Transformer模型的鲁棒性和分布外泛化能力，同时保持其在分布内任务上的性能。

Method: 引入层间下降约束于目标函数，并用原始-对偶训练方案替代标准经验风险最小化（ERM），使模型中间表征在各层上期望单调降低损失。

Result: 在视频去噪和文本分类任务中，约束Transformer展现出更强的扰动鲁棒性和更高的分布外泛化能力，同时不损害分布内性能。

Conclusion: 该约束优化框架能有效引导Transformer模拟优化下降行为，从而提升其泛化与鲁棒性，为可解释、可控的深度学习建模提供了新思路。

Abstract: We introduce a constrained optimization framework for training transformers that behave like optimization descent algorithms. Specifically, we enforce layerwise descent constraints on the objective function and replace standard empirical risk minimization (ERM) with a primal-dual training scheme. This approach yields models whose intermediate representations decrease the loss monotonically in expectation across layers. We apply our method to both unrolled transformer architectures and conventional pretrained transformers on tasks of video denoising and text classification. Across these settings, we observe constrained transformers achieve stronger robustness to perturbations and maintain higher out-of-distribution generalization, while preserving in-distribution performance.

</details>


### [339] [PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR](https://arxiv.org/abs/2601.18207)
*James Burgess,Jan N. Hansen,Duo Peng,Yuhui Zhang,Alejandro Lozano,Min Woo Sun,Emma Lundberg,Serena Yeung-Levy*

Main category: cs.LG

TL;DR: 本文提出了一种面向科学论文搜索与推理的智能体训练方法，构建了包含1600万篇生物医学摘要的语料库及6万样本的PaperSearchQA问答数据集，并基于RLVR框架训练出能进行规划、推理和自验证的搜索代理。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习与可验证奖励（RLVR）的搜索代理主要面向通用领域问答，难以满足科学、工程和医学等技术领域的需求；本文旨在构建能处理科学文献的技术性问答代理，以支持真实科研人员并推动AI Scientist系统发展。

Method: 构建大规模生物医学论文摘要语料库（1600万篇）与高质量事实型问答数据集PaperSearchQA（6万样本），在Search-R1代码框架下采用RLVR训练搜索代理，并进行定量分析与行为观察。

Result: 训练出的搜索代理显著优于非强化学习检索基线，展现出规划、推理和自验证等高级行为；相关数据、基准与代码已开源，方法具备跨学科可扩展性。

Conclusion: 面向科学文献的搜索代理训练是可行且有效的，所构建资源与方法为技术领域QA和未来AI Scientist系统奠定了重要基础。

Abstract: Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.

</details>


### [340] [The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment](https://arxiv.org/abs/2601.17260)
*Marco Pollanen*

Main category: cs.LG

TL;DR: 本文研究了DPO中对齐参数β的影响，发现其与模型能力之间存在非单调、架构依赖甚至负相关的关系，并揭示了训练路径依赖（滞后效应），强调需在β空间内进行能力分解评估。


<details>
  <summary>Details</summary>
Motivation: 以往将DPO中的β视为越大越好的对齐强度调节器，但缺乏对其作为控制参数的系统性分析；作者旨在揭示β对模型实际推理能力的真实影响机制。

Method: 在三个7B开源模型族（Mistral、Llama、Qwen）上，采用固定DPO流程，对β进行密集扫描；使用逻辑探针（logic-probe）量化推理能力，分析偏好边距与能力的相关性，并考察高β训练路径对后续能力的持久影响（滞后效应）。

Result: 1）Mistral能力呈尖锐非单调性，仅在β≈10⁻²窄带内正向；2）不同架构响应模式迥异（Mistral突变、Llama选择性变化、Qwen平滑权衡）；3）偏好边距与推理能力显著负相关（Llama达r=−0.91）；4）高β训练导致不可逆能力退化（滞后效应）。

Conclusion: β不应被简单视为对齐强度指标，而应作为关键控制变量进行能力解析式评估；依赖偏好边距或聚合基准选择模型存在严重风险，需在β谱系上开展能力分解评估。

Abstract: Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $β$) yields progressively "better" behavior. We instead treat $β$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $β\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $β$ induces capability losses that persist even after $β$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $β$ landscape rather than reliance on margins or aggregate benchmarks.

</details>


### [341] [Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization](https://arxiv.org/abs/2601.17570)
*Hadi Salloum,Ali Jnadi,Yaroslav Kholodov,Alexander Gasnikov*

Main category: cs.LG

TL;DR: 本文提出MC+QUBO方法，将蒙特卡洛强化学习中的episode选择建模为QUBO优化问题，并用量子启发式采样器（如SQA和SB）求解，以提升稀疏奖励、大状态空间场景下的策略评估效率与性能。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛强化学习在稀疏奖励、大状态空间及轨迹相关性强的环境中样本复杂度高，需改进episode选择机制。

Method: 将每批轨迹的子集选择建模为QUBO问题：线性项鼓励高累积奖励episode，二次项惩罚状态覆盖冗余；使用模拟量子退火（SQA）和模拟分岔（SB）等黑箱量子启发式求解器进行优化。

Result: 在有限时域GridWorld实验中，MC+QUBO相比标准蒙特卡洛方法显著加快收敛速度并提升最终策略质量。

Conclusion: 量子启发式优化可作为强化学习中有效的决策子程序，尤其适用于需平衡奖励与探索的策略评估任务。

Abstract: Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.

</details>


### [342] [AGZO: Activation-Guided Zeroth-Order Optimization for LLM Fine-Tuning](https://arxiv.org/abs/2601.17261)
*Wei Lin,Yining Jiang,Qingyu Song,Qiao Xiang,Hong Xu*

Main category: cs.LG

TL;DR: 本文提出了一种激活引导的零阶优化方法（AGZO），利用前向传播中的激活结构信息，在低秩子空间内进行扰动，从而在内存受限下更高效地微调大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法使用各向同性扰动，忽略了前向传播中丰富的激活结构信息；而梯度实际受限于输入激活张成的子空间，这一结构未被利用。

Method: 提出Activation-Guided Zeroth-Order optimization（AGZO），在前向过程中动态提取激活引导的紧凑低秩子空间，并将扰动限制在该子空间内；理论分析其优化的是子空间平滑目标，并证明其更新方向与真实梯度余弦相似度更高。

Result: 在Qwen3和Pangu模型上多任务评测中，AGZO持续优于现有零阶方法，显著缩小与一阶微调的性能差距，同时保持与其他零阶方法相近的峰值内存占用。

Conclusion: 激活结构可有效提升零阶优化质量；AGZO通过子空间感知扰动，在极低内存开销下实现接近一阶微调的性能，为资源受限场景下的LLM高效微调提供了新范式。

Abstract: Zeroth-Order (ZO) optimization has emerged as a promising solution for fine-tuning LLMs under strict memory constraints, as it avoids the prohibitive memory cost of storing activations for backpropagation. However, existing ZO methods typically employ isotropic perturbations, neglecting the rich structural information available during the forward pass. In this paper, we identify a crucial link between gradient formation and activation structure: the gradient of a linear layer is confined to the subspace spanned by its input activations. Leveraging this insight, we propose Activation-Guided Zeroth-Order optimization (AGZO). Unlike prior methods, AGZO extracts a compact, activation-informed subspace on the fly during the forward pass and restricts perturbations to this low-rank subspace. We provide a theoretical framework showing that AGZO optimizes a subspace-smoothed objective and provably yields update directions with higher cosine similarity to the true gradient than isotropic baselines. Empirically, we evaluate AGZO on Qwen3 and Pangu models across various benchmarks. AGZO consistently outperforms state-of-the-art ZO baselines and significantly narrows the performance gap with first-order fine-tuning, while maintaining almost the same peak memory footprint as other ZO methods.

</details>


### [343] [Unrolled Neural Networks for Constrained Optimization](https://arxiv.org/abs/2601.17274)
*Samar Hadou,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 本文提出了一种名为约束对偶展开（CDU）的框架，通过两个耦合神经网络联合逼近拉格朗日函数的鞍点，以加速并可学习地求解带约束优化问题；该方法在MIQP和无线网络功率分配任务上实现了近最优、近可行解，并展现出强分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统对偶上升（DA）算法收敛慢且不可学习，而现有展开方法缺乏对原始-对偶动态的显式建模；本文旨在设计一种可学习、加速且能保持DA动力学特性的神经网络框架。

Method: 提出约束对偶展开（CDU）框架：包含一个模拟原始优化器的 primal 网络和一个生成对偶乘子轨迹的 dual 网络；通过施加原始下降与对偶上升的约束实现DA动力学；训练采用嵌套优化与交替更新策略，缓解对偶乘子分布未知带来的训练不确定性。

Result: 在混合整数二次规划（MIQP）和无线网络功率分配任务上，CDU生成近最优、近可行解；相比基线方法，展现出更强的分布外（OOD）泛化能力。

Conclusion: CDU为约束优化提供了一种可学习、结构化且泛化性强的新范式，验证了将经典优化动力学嵌入神经网络架构的有效性与实用性。

Abstract: In this paper, we develop unrolled neural networks to solve constrained optimization problems, offering accelerated, learnable counterparts to dual ascent (DA) algorithms. Our framework, termed constrained dual unrolling (CDU), comprises two coupled neural networks that jointly approximate the saddle point of the Lagrangian. The primal network emulates an iterative optimizer that finds a stationary point of the Lagrangian for a given dual multiplier, sampled from an unknown distribution. The dual network generates trajectories towards the optimal multipliers across its layers while querying the primal network at each layer. Departing from standard unrolling, we induce DA dynamics by imposing primal-descent and dual-ascent constraints through constrained learning. We formulate training the two networks as a nested optimization problem and propose an alternating procedure that updates the primal and dual networks in turn, mitigating uncertainty in the multiplier distribution required for primal network training. We numerically evaluate the framework on mixed-integer quadratic programs (MIQPs) and power allocation in wireless networks. In both cases, our approach yields near-optimal near-feasible solutions and exhibits strong out-of-distribution (OOD) generalization.

</details>


### [344] [Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning](https://arxiv.org/abs/2601.17275)
*Lianlei Shan,Han Chen,Yixuan Wang,Zhenjie Liu,Wei Li*

Main category: cs.LG

TL;DR: 本文提出DeepLatent Reasoning（DLR）框架，通过在连续潜在空间中进行双向对比强化学习，规避传统RL在离散token空间中采样效率低、方差高和灾难性遗忘等问题，提升大语言模型的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: LLM在复杂多步推理任务中常依赖统计拟合而非系统逻辑推导；传统RL直接在高维离散token空间训练面临样本效率低、梯度方差大和灾难性遗忘三大瓶颈。

Method: 提出DLR框架：引入轻量助理模型在潜在空间采样K条推理链编码，通过正确性与格式双奖励机制筛选高质量轨迹，并由冻结主模型单次解码；设计潜在空间对比学习目标以平衡探索与一致性；主模型参数全程冻结，从数学上杜绝灾难性遗忘。

Result: 在同等GPU预算下，DLR实现更稳定的训练收敛、支持更长推理链，并可持续积累推理能力。

Conclusion: DLR为大语言模型提供了一种可靠、可扩展的强化学习新路径，有效克服了传统方法在推理优化中的结构性瓶颈。

Abstract: While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.

</details>


### [345] [Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions](https://arxiv.org/abs/2601.18107)
*Pedram Agand,Mo Chen*

Main category: cs.LG

TL;DR: 本文提出MoReBRAC，一种基于不确定性感知潜空间合成的模型式离线强化学习框架，通过双循环世界模型生成高质量合成转移，并结合VAE流形检测、模型敏感性分析与MC Dropout构成的分层不确定性管道来筛选高置信度数据，从而缓解分布偏移问题，在D4RL Gym-MuJoCo基准上尤其在随机和次优数据场景下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中静态数据集与策略之间的分布偏移是主要障碍，导致需过度保守而限制策略提升；尤其在工业机器人等安全关键领域，亟需更可靠且高效的离线学习方法。

Method: 提出MoReBRAC框架：构建双循环世界模型用于合成高保真转移；设计分层不确定性管道，融合VAE流形检测、模型敏感性分析和MC Dropout，仅保留动力学高置信区域的合成数据。

Result: 在D4RL Gym-MuJoCo基准上取得显著性能提升，尤其在'random'和'suboptimal'数据集上；揭示VAE作为几何锚点的作用，并分析了近最优数据下的分布权衡。

Conclusion: MoReBRAC通过不确定性引导的潜空间合成有效缓解分布偏移，提升了离线策略的学习能力与泛化性，为安全关键场景下的离线RL提供了新范式。

Abstract: Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.

</details>


### [346] [Tabular Foundation Models are Strong Graph Anomaly Detectors](https://arxiv.org/abs/2601.17301)
*Yunhui Liu,Tieke He,Yongchao Liu,Can Yi,Hong Jin,Chuntao Hong*

Main category: cs.LG

TL;DR: 本文提出TFM4GAD框架，将表格基础模型（TFMs）适配于图异常检测（GAD），通过构建融合拓扑信息的增强特征表，实现无需重训练的跨图泛化异常检测，显著优于专用GAD模型。


<details>
  <summary>Details</summary>
Motivation: 现有GAD方法遵循“一数据集一模型”范式，计算开销大、数据需求高、跨数据集泛化差；亟需能支持“一模型通用于多图”的基础模型，但图结构与特征的高度异质性构成挑战。

Method: 提出TFM4GAD框架：将图“扁平化”，构建融合拉普拉斯嵌入、局部/全局结构特征及异常敏感邻居聚合的增强节点特征表，并利用TFM在全上下文学习模式下处理该表。

Result: 在多个数据集和不同TFM骨干网络上的实验表明，TFM4GAD意外地显著超越了从头训练的专用GAD模型。

Conclusion: TFM4GAD为图异常检测提供了新视角和实用范式，证明表格基础模型可作为强大且通用的图异常检测器。

Abstract: Graph anomaly detection (GAD), which aims to identify abnormal nodes that deviate from the majority, has become increasingly important in high-stakes Web domains. However, existing GAD methods follow a "one model per dataset" paradigm, leading to high computational costs, substantial data demands, and poor generalization when transferred to new datasets. This calls for a foundation model that enables a "one-for-all" GAD solution capable of detecting anomalies across diverse graphs without retraining. Yet, achieving this is challenging due to the large structural and feature heterogeneity across domains. In this paper, we propose TFM4GAD, a simple yet effective framework that adapts tabular foundation models (TFMs) for graph anomaly detection. Our key insight is that the core challenges of foundation GAD, handling heterogeneous features, generalizing across domains, and operating with scarce labels, are the exact problems that modern TFMs are designed to solve via synthetic pre-training and powerful in-context learning. The primary challenge thus becomes structural: TFMs are agnostic to graph topology. TFM4GAD bridges this gap by "flattening" the graph, constructing an augmented feature table that enriches raw node features with Laplacian embeddings, local and global structural characteristics, and anomaly-sensitive neighborhood aggregations. This augmented table is processed by a TFM in a fully in-context regime. Extensive experiments on multiple datasets with various TFM backbones reveal that TFM4GAD surprisingly achieves significant performance gains over specialized GAD models trained from scratch. Our work offers a new perspective and a practical paradigm for leveraging TFMs as powerful, generalist graph anomaly detectors.

</details>


### [347] [Decentralized Multi-Agent Swarms for Autonomous Grid Security in Industrial IoT: A Consensus-based Approach](https://arxiv.org/abs/2601.17303)
*Samaresh Kumar Singh,Joyjit Roy*

Main category: cs.LG

TL;DR: 本文提出了一种去中心化的多智能体蜂群（DMAS）架构，通过在每个边缘网关部署自主AI代理，构建分布式数字‘免疫系统’，实现IIoT网络的低延迟、高精度异常检测与威胁协同验证，显著优于传统集中式和边缘计算方案。


<details>
  <summary>Details</summary>
Motivation: 随着工业物联网（IIoT）设备规模扩大，集中式安全监控架构引发严重延迟问题，易被攻击者利用，威胁整个制造生态系统。

Method: 设计去中心化多智能体蜂群（DMAS）架构，各边缘网关部署自主AI代理，通过轻量级P2P协议协同检测异常；引入基于共识的威胁验证（CVT）机制，实现威胁投票与即时隔离。

Result: 在2000设备模拟工厂测试中，DMAS实现平均0.85ms响应时间、97.3%恶意活动检出率、87%零日攻击检出率，并可防止级联故障、降低89%网络带宽消耗。

Conclusion: DMAS架构有效克服了集中式安全监控的延迟瓶颈，在检测精度、响应速度、带宽效率及零日攻击防御方面全面优于现有方案，为大规模IIoT提供了可扩展、鲁棒的安全新范式。

Abstract: As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital "immune system" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions.

</details>


### [348] [Weighted Graph Clustering via Scale Contraction and Graph Structure Learning](https://arxiv.org/abs/2601.17307)
*Haobing Liu,Yinuo Zhang,Tingting Wang,Ruobing Jiang,Yanwei Yu*

Main category: cs.LG

TL;DR: 本文提出了一种收缩式边权感知图聚类网络，通过簇导向的图收缩模块和边权感知注意力网络，解决加权图聚类中图规模大、边权噪声干扰的问题，显著提升聚类效果并降低计算与存储开销。


<details>
  <summary>Details</summary>
Motivation: 现有图聚类方法未能充分利用边权重信息，且面临边权重引入导致的存储/计算开销增大和噪声干扰两大挑战，缺乏联合优化聚类与边权重的方法。

Method: 提出收缩式边权感知图聚类网络：（1）簇导向图收缩模块压缩图规模并保留关键节点；（2）边权感知注意力网络识别并削弱噪声边连接。

Result: 在三个真实加权图数据集上实验表明，该模型性能优于最优基线；图收缩模块显著减少训练时间和存储空间。

Conclusion: 所提方法能有效缓解噪声边对聚类的负面影响，提升聚类有效性，同时兼顾效率与可扩展性。

Abstract: Graph clustering aims to partition nodes into distinct clusters based on their similarity, thereby revealing relationships among nodes. Nevertheless, most existing methods do not fully utilize these edge weights. Leveraging edge weights in graph clustering tasks faces two critical challenges. (1) The introduction of edge weights may significantly increase storage space and training time, making it essential to reduce the graph scale while preserving nodes that are beneficial for the clustering task. (2) Edge weight information may inherently contain noise that negatively impacts clustering results. However, few studies can jointly optimize clustering and edge weights, which is crucial for mitigating the negative impact of noisy edges on clustering task. To address these challenges, we propose a contractile edge-weight-aware graph clustering network. Specifically, a cluster-oriented graph contraction module is designed to reduce the graph scale while preserving important nodes. An edge-weight-aware attention network is designed to identify and weaken noisy connections. In this way, we can more easily identify and mitigate the impact of noisy edges during the clustering process, thus enhancing clustering effectiveness. We conducted extensive experiments on three real-world weighted graph datasets. In particular, our model outperforms the best baseline, demonstrating its superior performance. Furthermore, experiments also show that the proposed graph contraction module can significantly reduce training time and storage space.

</details>


### [349] [PAR: Plausibility-aware Amortized Recourse Generation](https://arxiv.org/abs/2601.17309)
*Anagha Sabu,Vidhya S,Narayanan C Krishnan*

Main category: cs.LG

TL;DR: 本文提出了一种名为PAR的算法，通过约束最大后验（MAP）推理，在接受类数据分布下生成高似然、可行且定制化的反事实解释，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有算法化反事实解释方法在生成既有效又现实可行的建议时存在挑战，需要兼顾决策翻转、可行性与真实性。

Method: 将反事实生成建模为受约束的最大后验（MAP）推理问题，采用可训练的近似推断框架PAR；利用可处理的概率模型直接估计似然，结合梯度优化；引入邻域条件机制实现对个体样本的定制化生成。

Result: 在多个标准反事实数据集上验证，PAR生成的反事实具有高有效性、低稀疏性、高相似性与强合理性，性能超越当前最优方法。

Conclusion: PAR提供了一种高效、可扩展且原理清晰的反事实生成框架，兼顾似然性、约束满足与个性化，推动算法可解释性与公平性实践。

Abstract: Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.

</details>


### [350] [Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment](https://arxiv.org/abs/2601.17329)
*Tiejin Chen,Xiaoou Liu,Vishnu Nandam,Kuan-Ru Liou,Hua Wei*

Main category: cs.LG

TL;DR: 本文提出Conformal Feedback Alignment（CFA）框架，利用Conformal Prediction量化回答层面的可靠性，并将其转化为偏好学习中的权重，提升RLHF类方法的鲁棒性与数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的对齐方法（如RLHF）依赖易受噪声和不一致影响的成对偏好标签；已有不确定性感知方法仅加权偏好，却忽略了被比较答案本身的可靠性这一更根本因素。

Method: 提出CFA框架，基于Conformal Prediction构建具有可控覆盖率的回答级置信集，进而导出回答可靠性度量，并将其聚合为DPO和PPO训练中的原则性权重。

Result: 在多个数据集上的实验表明，CFA显著提升了对齐模型的鲁棒性和数据效率。

Conclusion: 建模回答侧（answer-side）不确定性比仅加权偏好更本质，能有效补充并增强现有不确定性感知对齐方法。

Abstract: Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.

</details>


### [351] [Thermodynamically Optimal Regularization under Information-Geometric Constraints](https://arxiv.org/abs/2601.17330)
*Laurent Caraffa*

Main category: cs.LG

TL;DR: 本文提出一个统一的理论框架，将热力学最优性、信息几何与机器学习正则化联系起来，在三个假设下证明Fisher-Rao度量是信念空间上唯一可接受的几何结构，热力学最优正则化等价于最小化到参考状态的Fisher-Rao距离平方；并推导高斯与圆周信念模型对应的双曲与von Mises流形，指出经典正则方法无法保证热力学最优性，引入学习热力学效率概念并给出可实验验证的预测。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习依赖多种经验有效但理论基础各异的正则化技术，同时大模型训练能耗激增，促使人们追问学习算法是否逼近某种基本效率极限。

Method: 基于三个明确假设（A1：最优性需内在且参数无关的信息测度；A2：信念状态由满足已知约束的最大熵分布建模；A3：最优过程为准静态过程），建立连接热力学、信息几何与正则化的统一框架，并推导相应流形几何与效率度量。

Result: 证明Fisher-Rao度量是信念空间上唯一可接受的几何；热力学最优正则化即最小化Fisher-Rao距离平方；高斯与圆形信念模型分别对应双曲与von Mises流形；经典正则方法无法保证热力学最优；提出热力学效率概念及可实验验证预测。

Conclusion: 本工作为机器学习中的正则化提供了原理性的几何与热力学基础，揭示了正则化本质与物理最优性之间的深层联系。

Abstract: Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization.
  Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state.
  We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.

</details>


### [352] [Power-based Partial Attention: Bridging Linear-Complexity and Full Attention](https://arxiv.org/abs/2601.17334)
*Yufeng Huang*

Main category: cs.LG

TL;DR: 本文提出了一种幂基部分注意力（PPA）机制，其计算复杂度为O(L^{1+p})，通过调节参数p在滑动窗口线性注意力与全注意力之间平滑过渡，并实验证明存在0<p<1使得亚二次复杂度的注意力即可达到与全注意力相当的性能。


<details>
  <summary>Details</summary>
Motivation: 量化注意力机制所需的计算量，探究是否存在亚二次复杂度（即低于O(L^2)）但仍能保持高性能的注意力机制。

Method: 提出幂基部分注意力（PPA），其复杂度为O(L^{1+p})，p∈[0,1]；p=0对应线性滑动窗口注意力，p=1对应全注意力；系统评估不同p值下模型性能变化。

Result: 实验发现性能随p呈S型曲线变化，在较小p区间内快速提升并趋于饱和；存在0<p<1使得O(L^{1+p})注意力可达到与O(L^2)全注意力相当的效果。

Conclusion: 全注意力并非必需，存在亚二次复杂度的注意力机制（如PPA）可在显著降低计算开销的同时维持模型性能。

Abstract: It is widely accepted from transformer research that "attention is all we need", but the amount of attention required has never been systematically quantified. Is quadratic $O(L^2)$ attention necessary, or is there a sub-quadratic attention mechanism that can achieve comparable performance? To answer this question, we introduce power-based partial attention (PPA), an attention mechanism of order $O(L^{1+p})$, where $0 \leq p \leq 1$, such that $p=0$ corresponds to sliding window attention with linear complexity, and $p=1$ corresponds to full attention. With this attention construction, we can explore how transformer architecture performance varies as a function of the attention scaling behavior controlled by $p$. The overall trend from our experiments shows an S-curve-like behavior where the performance transitions from sliding-window (linear-complexity) attention to full attention over a narrow window of $p$ values, and plateaus as $p$ approaches $1$. In our experiments, we show that there exists $0<p<1$ such that $O(L^{1+p})$ attention is sufficient to achieve similar results as $O(L^2)$ full attention.

</details>


### [353] [Spectral Geometry for Deep Learning: Compression and Hallucination Detection via Random Matrix Theory](https://arxiv.org/abs/2601.17357)
*Davide Ettori*

Main category: cs.LG

TL;DR: This thesis introduces a unified spectral framework to improve reliability and reduce computational cost of large language and deep neural models by analyzing eigenvalue structures of hidden activations, featuring EigenTrack for real-time hallucination/OOD detection and RMT-KD for spectral-guided knowledge distillation.


<details>
  <summary>Details</summary>
Motivation: Large language models and deep neural networks face reliability issues (e.g., hallucinations, OOD behavior) and high computational cost.

Method: A unified framework based on spectral geometry and random matrix theory is proposed, analyzing eigenvalue structure of hidden activations; EigenTrack uses spectral features and their temporal dynamics for real-time detection; RMT-KD applies iterative knowledge distillation guided by informative spectral components.

Result: EigenTrack enables real-time hallucination and OOD detection in language and vision-language models; RMT-KD achieves compact, efficient models with preserved accuracy; spectral statistics serve as interpretable and robust signals for uncertainty monitoring and compression.

Conclusion: Spectral statistics of hidden activations provide a principled, interpretable, and robust foundation for enhancing both reliability and efficiency in large-scale neural networks.

Abstract: Large language models and deep neural networks achieve strong performance but suffer from reliability issues and high computational cost. This thesis proposes a unified framework based on spectral geometry and random matrix theory to address both problems by analyzing the eigenvalue structure of hidden activations. The first contribution, EigenTrack, is a real-time method for detecting hallucinations and out-of-distribution behavior in language and vision-language models using spectral features and their temporal dynamics. The second contribution, RMT-KD, is a principled compression method that identifies informative spectral components and applies iterative knowledge distillation to produce compact and efficient models while preserving accuracy. Together, these results show that spectral statistics provide interpretable and robust signals for monitoring uncertainty and guiding compression in large-scale neural networks.

</details>


### [354] [Robust Privacy: Inference-Time Privacy through Certified Robustness](https://arxiv.org/abs/2601.17360)
*Jiankai Jin,Xiangzheng Zhang,Zhao Liu,Deyue Zhang,Quanchen Zou*

Main category: cs.LG

TL;DR: 本文提出了一种新的推理时隐私保护概念——鲁棒隐私（RP），结合属性隐私增强（APE）方法，通过保证模型预测在输入邻域内的不变性，来防止敏感属性被推断，并在推荐任务和模型反演攻击中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在推理时可能泄露敏感输入属性，现有隐私机制（如差分隐私）主要关注训练阶段，缺乏对推理时属性推断攻击的有效防御。

Method: 提出鲁棒隐私（RP）概念：若模型预测在半径R的邻域内不变（如ℓ₂范数下），则输入x享有R-鲁棒隐私；进一步设计属性隐私增强（APE）将输入级不变性转化为属性级隐私保障；在可控推荐任务中分析敏感属性推理区间扩展效果；通过添加噪声实现RP，并评估其对模型反演攻击（MIA）的抑制能力。

Result: 在推荐任务中，RP显著扩大了与正向推荐兼容的敏感属性取值范围；在模型反演攻击中，小噪声（σ=0.1）下攻击成功率（ASR）从73%降至4%，且仅造成部分性能下降；无性能损失时ASR也可降至44%。

Conclusion: 鲁棒隐私是一种可行且有效的推理时隐私保障机制，能在保持模型实用性的同时显著提升对属性推断和模型反演攻击的鲁棒性。

Abstract: Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($σ=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.

</details>


### [355] [Diversified Scaling Inference in Time Series Foundation Models](https://arxiv.org/abs/2601.17376)
*Ruijin Hua,Zichuan Liu,Kun Zhang,Yiyuan Yang*

Main category: cs.LG

TL;DR: 本文系统研究了时间序列基础模型（TSFMs）在推理阶段的计算潜力，提出通过受控的多样化采样（如时序扰动）提升性能，并理论分析了多样性与保真度的权衡，验证了无需参数更新即可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有TSFM主要依赖大规模预训练，而推理阶段的计算潜力尚未被充分利用；标准采样方法因探索不足难以满足缩放律。

Method: 1）分析TSFM在标准采样下的行为与局限；2）设计面向时间序列的扰动策略实现多样化推理缩放；3）理论推导多样性-保真度权衡及关键样本阈值；4）提出RobustMSE评估指标。

Result: 多样化推理缩放在多个TSFM和数据集上显著提升性能，无需参数更新；理论给出多样化采样优于标准采样的临界样本数；RobustMSE可量化固定预算下的性能提升空间。

Conclusion: 推理阶段的设计（尤其是多样化采样）是TSFM优化中关键且计算高效的维度，可在不重训练前提下可靠提升性能。

Abstract: The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.

</details>


### [356] [GO-OSC and VASH: Geometry-Aware Representation Learning for Early Degradation Detection in Oscillatory Systems](https://arxiv.org/abs/2601.17396)
*Vashista Nobaub*

Main category: cs.LG

TL;DR: 本文提出GO-OSC框架，通过几何感知的表示学习实现对振荡系统早期退化（如相位抖动、频率漂移）的稳定、灵敏检测，优于传统能量型方法。


<details>
  <summary>Details</summary>
Motivation: 早期退化表现为动力学几何畸变（如相位抖动、频率漂移），而能量变化尚不明显，导致传统能量诊断和无约束表征方法检测迟滞或不稳定。

Method: 提出GO-OSC：一种几何感知的振荡时间序列表示学习框架，强制实现规范且可识别的潜在参数化；并设计一族针对退化相关方向的不变线性几何探针。

Result: 理论证明：在纯相位退化下，能量统计量一阶检测能力为零，而几何探针具有严格正敏感度；实验表明GO-OSC能更早检测、更高数据效率、更强工况鲁棒性。

Conclusion: 规范化的几何表征是提升早期退化检测统计可检测性的关键，GO-OSC为振荡系统健康监测提供了新范式。

Abstract: Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.

</details>


### [357] [Efficient Dilated Squeeze and Excitation Neural Operator for Differential Equations](https://arxiv.org/abs/2601.17407)
*Prajwal Chauhan,Salah Eddine Choutri,Saif Eddin Jabari*

Main category: cs.LG

TL;DR: 本文提出了一种轻量级神经算子D-SENO，结合空洞卷积与Squeeze-Excitation模块，以高效、高精度求解多种PDE问题，训练速度比现有Transformer和神经算子快约20倍，且精度相当或更优。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的模型和神经算子参数量大、训练成本高、部署慢，难以满足物理驱动PDE快速准确建模的需求。

Method: 提出D-SENO框架：融合空洞卷积（DC）块与Squeeze-Excitation（SE）模块，前者通过可调膨胀率扩大感受野以捕获长程物理依赖，后者实现通道注意力自适应重标定特征。

Result: 在空气动力学势流、达西流、泊肃叶流及不可压NS涡量场等多个PDE基准上，训练速度提升约20倍，精度超越或持平于主流方法；消融实验表明SE模块对性能有正向贡献。

Conclusion: D-SENO是一种兼顾效率与精度的轻量级神经算子，在广泛PDE建模任务中具有显著实用价值。

Abstract: Fast and accurate surrogates for physics-driven partial differential equations (PDEs) are essential in fields such as aerodynamics, porous media design, and flow control. However, many transformer-based models and existing neural operators remain parameter-heavy, resulting in costly training and sluggish deployment. We propose D-SENO (Dilated Squeeze-Excitation Neural Operator), a lightweight operator learning framework for efficiently solving a wide range of PDEs, including airfoil potential flow, Darcy flow in porous media, pipe Poiseuille flow, and incompressible Navier Stokes vortical fields. D-SENO combines dilated convolution (DC) blocks with squeeze-and-excitation (SE) modules to jointly capture wide receptive fields and dynamics alongside channel-wise attention, enabling both accurate and efficient PDE inference. Carefully chosen dilation rates allow the receptive field to focus on critical regions, effectively modeling long-range physical dependencies. Meanwhile, the SE modules adaptively recalibrate feature channels to emphasize dynamically relevant scales. Our model achieves training speed of up to approximately $20\times$ faster than standard transformer-based models and neural operators, while also surpassing (or matching) them in accuracy across multiple PDE benchmarks. Ablation studies show that removing the SE modules leads to a slight drop in performance.

</details>


### [358] [Active Hypothesis Testing for Correlated Combinatorial Anomaly Detection](https://arxiv.org/abs/2601.17430)
*Zichuan Yang,Yiming Xing*

Main category: cs.LG

TL;DR: 本文提出了一种名为ECC-AHT的自适应算法，用于在存在相关噪声的情况下识别异常数据流子集，通过最大化Chernoff信息实现主动噪声消除，具有最优样本复杂度，并在合成与真实数据上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 受网络物理系统中监控与安全需求驱动，研究在相关噪声下识别异常数据流子集的问题。

Method: 提出ECC-AHT算法，采用连续、受限的自适应测量策略，最大化竞争假设间的Chernoff信息，利用差分感知实现主动噪声抑制。

Result: ECC-AHT获得最优样本复杂度理论保证，在合成与真实相关噪声环境中显著优于当前最优基线方法。

Conclusion: 相关性可被有效建模并用于提升异常检测效率；ECC-AHT为相关噪声下的组合纯探索问题提供了高效、理论可证的解决方案。

Abstract: We study the problem of identifying an anomalous subset of streams under correlated noise, motivated by monitoring and security in cyber-physical systems. This problem can be viewed as a form of combinatorial pure exploration, where each stream plays the role of an arm and measurements must be allocated sequentially under uncertainty. Existing combinatorial bandit and hypothesis testing methods typically assume independent observations and fail to exploit correlation for efficient measurement design. We propose ECC-AHT, an adaptive algorithm that selects continuous, constrained measurements to maximize Chernoff information between competing hypotheses, enabling active noise cancellation through differential sensing. ECC-AHT achieves optimal sample complexity guarantees and significantly outperforms state-of-the-art baselines in both synthetic and real-world correlated environments. The code is available on https://github.com/VincentdeCristo/ECC-AHT

</details>


### [359] [Data-driven Clustering and Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2601.17441)
*Ondrej Bohdal,Taha Ceritli,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli*

Main category: cs.LG

TL;DR: 本文提出D2C方法，通过少量任务样本和迭代优化对适配器进行聚类与合并，生成适用于资源受限设备的多任务适配器，在有限存储预算下提升性能。


<details>
  <summary>Details</summary>
Motivation: 移动设备内存有限，无法存储全部任务专用适配器，但可容纳少量；如何选择能跨任务泛化的代表性适配器尚无研究。

Method: 提出D2C适配器聚类方法，利用每任务极少样本（如10个）并采用迭代优化更新聚类分配，最终合并各簇内适配器形成多任务适配器。

Result: 实验表明该方法在给定存储预算下能有效提升多个下游任务的性能。

Conclusion: D2C为在边缘设备上高效部署多任务大模型适配器提供了可行且有效的解决方案。

Abstract: On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.

</details>


### [360] [DREAM: Dual-Standard Semantic Homogeneity with Dynamic Optimization for Graph Learning with Label Noise](https://arxiv.org/abs/2601.17449)
*Yusheng Zhao,Jiaye Xie,Qixin Zhang,Weizhi Zhang,Xiao Luo,Zhiping Xiao,Philip S. Yu,Ming Zhang*

Main category: cs.LG

TL;DR: 本文提出DREAM方法，通过双标准语义同质性与动态优化，解决图神经网络在标签噪声下的可靠性与关系感知优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络假设训练图标签准确，但实际中标签不可靠；现有去噪方法难以区分节点可靠性且忽略图拓扑中的关系信息。

Method: 提出DREAM：设计关系感知的动态优化框架，迭代重评估节点可靠性；采用基于节点邻近性与图拓扑的双标准锚点选择策略；计算目标节点与锚点间的语义同质性以指导优化；并提供理论分析。

Result: 在六个跨领域图数据集、三种图标签噪声下，DREAM显著优于现有基线方法。

Conclusion: DREAM能有效提升图学习在标签噪声下的鲁棒性与性能，兼顾节点可靠性建模与图结构关系利用。

Abstract: Graph neural networks (GNNs) have been widely used in various graph machine learning scenarios. Existing literature primarily assumes well-annotated training graphs, while the reliability of labels is not guaranteed in real-world scenarios. Recently, efforts have been made to address the problem of graph learning with label noise. However, existing methods often (i) struggle to distinguish between reliable and unreliable nodes, and (ii) overlook the relational information embedded in the graph topology. To tackle this problem, this paper proposes a novel method, Dual-Standard Semantic Homogeneity with Dynamic Optimization (DREAM), for reliable, relation-informed optimization on graphs with label noise. Specifically, we design a relation-informed dynamic optimization framework that iteratively reevaluates the reliability of each labeled node in the graph during the optimization process according to the relation of the target node and other nodes. To measure this relation comprehensively, we propose a dual-standard selection strategy that selects a set of anchor nodes based on both node proximity and graph topology. Subsequently, we compute the semantic homogeneity between the target node and the anchor nodes, which serves as guidance for optimization. We also provide a rigorous theoretical analysis to justify the design of DREAM. Extensive experiments are performed on six graph datasets across various domains under three types of graph label noise against competing baselines, and the results demonstrate the effectiveness of the proposed DREAM.

</details>


### [361] [Harnessing Reasoning Trajectories for Hallucination Detection via Answer-agreement Representation Shaping](https://arxiv.org/abs/2601.17467)
*Jianxiong Zhang,Bing Guo,Yuming Jiang,Haobo Wang,Bo An,Xuefeng Du*

Main category: cs.LG

TL;DR: 本文提出Answer-agreement Representation Shaping (ARS)方法，通过在推理轨迹边界嵌入上施加潜在扰动生成反事实答案，并依据答案是否一致进行对比学习，从而塑造对幻觉敏感的表征，无需人工标注即可提升幻觉检测性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型常生成看似合理但答案错误的长推理链，导致幻觉难以检测；直接使用原始轨迹文本或隐藏状态易过拟合表面模式，缺乏对答案有效性的鲁棒判别信号。

Method: ARS方法通过对推理轨迹边界嵌入施加小幅度潜在扰动，生成多个反事实答案，并以是否与原答案一致为标签，构建对比式表征学习目标：拉近答案一致的隐状态、推远不一致的隐状态，从而凸显答案不稳定性的潜在结构。

Result: ARS在多个基准上显著提升幻觉检测性能，稳定优于强基线方法，且所学表征可即插即用地增强现有基于嵌入的检测器。

Conclusion: ARS提供了一种无需人工标注、可泛化、检测友好的推理轨迹表征学习范式，有效揭示答案稳定性这一关键幻觉信号，为可信推理模型评估开辟了新路径。

Abstract: Large reasoning models (LRMs) often generate long, seemingly coherent reasoning traces yet still produce incorrect answers, making hallucination detection challenging. Although trajectories contain useful signals, directly using trace text or vanilla hidden states for detection is brittle: traces vary in form and detectors can overfit to superficial patterns rather than answer validity. We introduce Answer-agreement Representation Shaping (ARS), which learns detection-friendly trace-conditioned representations by explicitly encoding answer stability. ARS generates counterfactual answers through small latent interventions, specifically, perturbing the trace-boundary embedding, and labels each perturbation by whether the resulting answer agrees with the original. It then learns representations that bring answer-agreeing states together and separate answer-disagreeing ones, exposing latent instability indicative of hallucination risk. The shaped embeddings are plug-and-play with existing embedding-based detectors and require no human annotations during training. Experiments demonstrate that ARS consistently improves detection and achieves substantial gains over strong baselines.

</details>


### [362] [Identifying and Correcting Label Noise for Robust GNNs via Influence Contradiction](https://arxiv.org/abs/2601.17469)
*Wei Ju,Wei Zhang,Siyu Yi,Zhengyang Mao,Yifan Wang,Jingyang Yuan,Zhiping Xiao,Ziyue Qiao,Ming Zhang*

Main category: cs.LG

TL;DR: 本文提出ICGNN方法，利用图结构信息缓解标签噪声问题，通过设计噪声指示器ICS、高斯混合模型检测噪声标签、软策略修正标签及伪标签辅助监督，显著提升GNN鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 真实场景中图数据常存在标签噪声（如标注错误或不一致），严重影响GNN的鲁棒性和性能。

Method: 提出ICGNN：1）基于图扩散矩阵设计影响矛盾分数（ICS）作为噪声指示器；2）用高斯混合模型检测节点标签是否含噪；3）采用邻域预测的软策略修正噪声标签；4）引入未标记节点的伪标签提供额外监督。

Result: 在多个基准数据集上的实验验证了ICGNN相较于现有方法具有更优的性能和鲁棒性。

Conclusion: 利用图结构信息建模并协同优化噪声检测、标签修正与半监督学习，可有效提升GNN在噪声标签下的学习能力。

Abstract: Graph Neural Networks (GNNs) have shown remarkable capabilities in learning from graph-structured data with various applications such as social analysis and bioinformatics. However, the presence of label noise in real scenarios poses a significant challenge in learning robust GNNs, and their effectiveness can be severely impacted when dealing with noisy labels on graphs, often stemming from annotation errors or inconsistencies. To address this, in this paper we propose a novel approach called ICGNN that harnesses the structure information of the graph to effectively alleviate the challenges posed by noisy labels. Specifically, we first design a novel noise indicator that measures the influence contradiction score (ICS) based on the graph diffusion matrix to quantify the credibility of nodes with clean labels, such that nodes with higher ICS values are more likely to be detected as having noisy labels. Then we leverage the Gaussian mixture model to precisely detect whether the label of a node is noisy or not. Additionally, we develop a soft strategy to combine the predictions from neighboring nodes on the graph to correct the detected noisy labels. At last, pseudo-labeling for abundant unlabeled nodes is incorporated to provide auxiliary supervision signals and guide the model optimization. Experiments on benchmark datasets show the superiority of our proposed approach.

</details>


### [363] [LeanTutor: Towards a Verified AI Mathematical Proof Tutor](https://arxiv.org/abs/2601.17473)
*Manooshree Patel,Rayna Bhattacharyya,Thomas Lu,Arnav Mehta,Niels Voss,Narges Norouzi,Gireeja Ranade*

Main category: cs.LG

TL;DR: 本文提出了一种结合大语言模型（LLM）与定理证明器（如Lean）优势的AI数学证明辅导系统LeanTutor，旨在兼顾自然语言交互的易用性与形式化证明的正确性，并构建了用于评估的PeanoBench数据集。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽能自然语言交互但易出错；定理证明器虽保证正确性但学习门槛高。需融合二者优势，构建既易用又可靠的数学证明教学工具。

Method: 设计三模块系统LeanTutor：(i)自动形式化/证明检查器，(ii)下一步推理生成器，(iii)自然语言反馈生成器；并构建含371个佩亚诺算术证明的双语数据集PeanoBench进行评估。

Result: 实现了LeanTutor原型系统，并发布了PeanoBench数据集，验证了LLM与定理证明器协同在数学教育中的可行性。

Conclusion: LLM与定理证明器的协同架构可有效提升数学证明教学的可用性与可靠性，为AI教育工具提供了新范式。

Abstract: This paper considers the development of an AI-based provably-correct mathematical proof tutor. While Large Language Models (LLMs) allow seamless communication in natural language, they are error prone. Theorem provers such as Lean allow for provable-correctness, but these are hard for students to learn. We present a proof-of-concept system (LeanTutor) by combining the complementary strengths of LLMs and theorem provers. LeanTutor is composed of three modules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and (iii) a natural language feedback generator. To evaluate the system, we introduce PeanoBench, a dataset of 371 Peano Arithmetic proofs in human-written natural language and formal language, derived from the Natural Numbers Game.

</details>


### [364] [Unintended Memorization of Sensitive Information in Fine-Tuned Language Models](https://arxiv.org/abs/2601.17480)
*Marton Szep,Jorge Marin Ruiz,Georgios Kaissis,Paulina Seidl,Rüdiger von Eisenhart-Rothe,Florian Hinterwimmer,Daniel Rueckert*

Main category: cs.LG

TL;DR: 本文系统研究了大语言模型（LLM）在微调过程中对仅出现在输入中、未出现在目标标签中的个人身份信息（PII）的无意记忆与泄露风险，并通过合成与真实数据集设计探针量化该风险，评估了多种隐私保护方法的权衡效果。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型时存在无意记忆和泄露敏感数据（尤其是仅出现在输入中的PII）的风险，可能违反隐私法规并威胁个体安全，但该问题尚未被充分研究。

Method: 设计可控提取探针，在合成与真实世界数据集上量化PII无意记忆程度；分析语言、PII频率、任务类型和模型规模等因素的影响；基准测试四种隐私保护方法（差分隐私、机器遗忘、正则化、偏好对齐）的隐私-效用权衡。

Result: 后训练方法通常提供更一致的隐私-效用权衡；差分隐私在特定设置下能显著降低信息泄露，但可能导致训练不稳定。

Conclusion: 微调LLM中的记忆问题依然严峻，亟需鲁棒、可扩展的隐私保护技术。

Abstract: Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.

</details>


### [365] [Automatic Stability and Recovery for Neural Network Training](https://arxiv.org/abs/2601.17483)
*Barak Or*

Main category: cs.LG

TL;DR: 本文提出了一种监督式运行时稳定性框架，通过引入基于验证探针等二次测量的创新信号，自动检测并恢复训练中的破坏性更新，无需修改底层优化器，并提供理论上的运行时安全性保证。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络训练日益脆弱，罕见但严重的不稳定更新常导致不可逆发散或静默性能下降；现有优化方法缺乏对已发生不稳定的检测与恢复能力。

Method: 将优化视为受控随机过程，提取来自验证探针等二次测量的‘创新信号’以隔离不稳定性，实现无需修改原优化器的自动检测与恢复。

Result: 实现了低开销、内存受限场景兼容的稳定性监控与恢复机制，并提供了形式化的有界退化与恢复理论保障。

Conclusion: 该监督式框架显著提升了训练鲁棒性，为优化过程提供了可验证的运行时安全保障。

Abstract: Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.

</details>


### [366] [SpatialMath: Spatial Comprehension-Infused Symbolic Reasoning for Mathematical Problem-Solving](https://arxiv.org/abs/2601.17489)
*Ashutosh Bajpai,Akshat Bhandari,Akshay Nambi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: 本文提出SpatialMath框架，通过空间感知模块提取几何图像中的空间关系，并将其融入符号推理链，显著提升多模态中小模型在视觉密集型数学问题（尤其是几何题）上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有中小型多模态语言模型在视觉理解与数学推理（特别是几何问题）方面存在明显不足，难以准确分解复杂视觉输入并连接感知与结构化推理。

Method: 提出SpatialMath框架，包含专用空间感知模块以提取图像中的空间结构与关系，并将这些空间表示系统性地注入符号推理链；同时构建新数据集MATHVERSE-PLUS，含结构化视觉解释与分步推理路径。

Result: SpatialMath在视觉密集型任务上相较强基线模型最高提升10个百分点；鲁棒性分析表明增强的空间表征直接提升了推理准确率。

Conclusion: 结构化的‘感知→推理’流水线对提升多模态中小模型的视觉理解与数学推理能力至关重要。

Abstract: Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.

</details>


### [367] [One-Shot Federated Clustering of Non-Independent Completely Distributed Data](https://arxiv.org/abs/2601.17512)
*Yiqun Zhang,Shenghong Cai,Zihua Yang,Sen Feng,Yuzhu Ji,Haijun Zhang*

Main category: cs.LG

TL;DR: 本文提出GOLD框架，解决非独立同分布（Non-IID）下联邦聚类中因客户端数据碎片化导致的聚类性能瓶颈问题，通过局部分布学习与全局融合提升聚类效果。


<details>
  <summary>Details</summary>
Motivation: 现有无监督联邦聚类（FC）方法在Non-IID数据下性能受限，尤其因客户端数据对同一簇的碎片化分布（即新提出的Non-ICD现象）而难以有效融合局部聚类知识。

Method: 提出GOLD框架：1）精细挖掘各客户端不完整的局部簇分布；2）上传分布摘要至服务器进行全局融合；3）基于全局分布指导本地簇增强。

Result: 通过显著性检验、消融实验、可扩展性评估和定性分析等大量实验，验证了GOLD在多种Non-IID场景下显著优于现有联邦聚类方法。

Conclusion: GOLD有效应对Non-ICD挑战，提升了联邦聚类的鲁棒性与准确性，为无监督分布式学习提供了新思路。

Abstract: Federated Learning (FL) that extracts data knowledge while protecting the privacy of multiple clients has achieved remarkable results in distributed privacy-preserving IoT systems, including smart traffic flow monitoring, smart grid load balancing, and so on. Since most data collected from edge devices are unlabeled, unsupervised Federated Clustering (FC) is becoming increasingly popular for exploring pattern knowledge from complex distributed data. However, due to the lack of label guidance, the common Non-Independent and Identically Distributed (Non-IID) issue of clients have greatly challenged FC by posing the following problems: How to fuse pattern knowledge (i.e., cluster distribution) from Non-IID clients; How are the cluster distributions among clients related; and How does this relationship connect with the global knowledge fusion? In this paper, a more tricky but overlooked phenomenon in Non-IID is revealed, which bottlenecks the clustering performance of the existing FC approaches. That is, different clients could fragment a cluster, and accordingly, a more generalized Non-IID concept, i.e., Non-ICD (Non-Independent Completely Distributed), is derived. To tackle the above FC challenges, a new framework named GOLD (Global Oriented Local Distribution Learning) is proposed. GOLD first finely explores the potential incomplete local cluster distributions of clients, then uploads the distribution summarization to the server for global fusion, and finally performs local cluster enhancement under the guidance of the global distribution. Extensive experiments, including significance tests, ablation studies, scalability evaluations, qualitative results, etc., have been conducted to show the superiority of GOLD.

</details>


### [368] [Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment](https://arxiv.org/abs/2601.17563)
*Nathan Gavenski,Matteo Leonetti,Odinaldo Rodrigues*

Main category: cs.LG

TL;DR: 本文提出了一种无监督的从观察中模仿学习方法（UfO），通过两阶段过程在无需动作标签的情况下重建教师动作并优化策略，在多个环境中超越现有ILfO方法且泛化性更强。


<details>
  <summary>Details</summary>
Motivation: 现有从观察中模仿学习（ILfO）方法依赖动作监督、假设状态-动作一一对应、忽视环境实际状态，难以从纯观测轨迹中有效提取真实策略。

Method: UfO采用两阶段无监督方法：第一阶段基于观测状态转移近似还原教师真实动作；第二阶段通过轨迹对齐进一步优化策略。

Result: 在五个常用环境中，UfO不仅性能超越教师策略及所有其他ILfO方法，且标准差最小，表明其在未见场景中泛化能力更强。

Conclusion: UfO成功克服了ILfO对动作监督的依赖和状态-动作强假设等关键限制，为真正无监督、鲁棒的模仿学习提供了新范式。

Abstract: State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.

</details>


### [369] [Understanding Transformer Encoder-Decoder Representations through Bernoulli Dropout](https://arxiv.org/abs/2601.17602)
*Xuanzhou Chen*

Main category: cs.LG

TL;DR: 本文通过研究高维编码器-解码器嵌入中的角度相似性，分析Transformer的过参数化问题，提出在编码器和解码器之间引入伯努利Dropout，并结合二进制擦除信道（BEC）进行实验，发现模型性能在某一稀疏度阈值处急剧下降。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer模型过参数化现象及其对模型性能的影响，特别是高维嵌入空间中角度相似性与鲁棒性的关系。

Method: 在编码器与解码器之间引入伯努利Dropout，理论分析有效稀疏性对嵌入稳定性和解码性能的影响，并构建集成二进制擦除信道（BEC）的Transformer变体，在英法翻译任务上进行实证验证。

Result: 理论证明：当有效稀疏性足够大时，中等程度坐标Dropout下嵌入和解码性能保持稳定；实验显示：验证准确率与BLEU分数均在某dropout阈值处急剧下降。

Conclusion: Transformer存在一个与稀疏性相关的性能临界阈值，揭示了其过参数化与结构鲁棒性之间的内在联系，为模型压缩与鲁棒性设计提供新视角。

Abstract: We study Transformer overparameterization through the lens of angular similarity in high-dimensional encoder-decoder embeddings. We apply Bernoulli dropout between the encoder and the decoder, varying the keep probability $p$ to identify a sparsity-dependent threshold above which the Top-1 prediction is preserved. Theoretically, we prove that, if the effective sparsity embeddings is sufficiently large, and thus decoder performance, remain stable under moderate coordinate dropout. Empirically, we implement the Bernoulli dropout by constructing a new Transformer model augmented with Binary Erasure Channel (BEC) and test its performance on an English-French translation task. Experimental results visualize the trends for validation accuracies and BLEU scores, both decline sharply at some threshold.

</details>


### [370] [A Thermodynamic Theory of Learning I: Irreversible Ensemble Transport and Epistemic Costs](https://arxiv.org/abs/2601.17607)
*Daisuke Okanohara*

Main category: cs.LG

TL;DR: 本文提出了一种基于表观自由能和熵产的不可逆学习理论框架，推导出仅依赖Wasserstein距离的学习速度极限（ESL），解释了学习如何在信息守恒下产生抽象。


<details>
  <summary>Details</summary>
Motivation: 解决学习系统如何在经典信息论（确定性变换不增信息）限制下仍能产生抽象与认知结构这一根本矛盾。

Method: 将学习建模为概率分布空间中的传输过程，构建表观自由能框架，定义自由能下降并分解为可逆与不可逆部分，并基于最优传输理论推导Epistemic Speed Limit（ESL）。

Result: 得到一个普适的有限时间不等式——ESL，它以下界形式给出实现给定分布变换所需的最小熵产，且该下界仅依赖于初始与终态分布间的Wasserstein距离，与具体算法无关。

Conclusion: 学习本质上是不可逆过程，认知结构的形成必然伴随熵产；信息论限制未被违反，而是通过热力学类比（自由能/熵产）得以协调，ESL揭示了学习效率的根本物理约束。

Abstract: Learning systems acquire structured internal representations from data, yet classical information-theoretic results state that deterministic transformations do not increase information. This raises a fundamental question: how can learning produce abstraction and insight without violating information-theoretic limits?
  We argue that learning is inherently an irreversible process when performed over finite time, and that the realization of epistemic structure necessarily incurs entropy production. To formalize this perspective, we model learning as a transport process in the space of probability distributions over model configurations and introduce an epistemic free-energy framework.
  Within this framework, we define the free-energy drop as a bookkeeping quantity that records the total reduction of epistemic free energy along a learning trajectory. This reduction decomposes into a reversible component associated with potential improvement and an irreversible component corresponding to entropy production.
  We then derive the Epistemic Speed Limit (ESL), a finite-time inequality that lower-bounds the minimal entropy production required by any learning process to realize a given distributional transformation. This bound depends only on the Wasserstein distance between initial and final ensemble distributions and is independent of the specific learning algorithm.

</details>


### [371] [Split-on-Share: Mixture of Sparse Experts for Task-Agnostic Continual Learning](https://arxiv.org/abs/2601.17616)
*Fatema Siddika,Md Anwar Hossen,Tanwi Mallick,Ali Jannesari*

Main category: cs.LG

TL;DR: 本文提出了一种名为SETA的持续学习框架，通过将大语言模型分解为任务特定专家和共享专家的稀疏混合结构，并结合弹性权重锚定机制，有效缓解了可塑性-稳定性困境，显著优于现有参数高效微调的持续学习方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型持续学习中的可塑性-稳定性困境，即新知识获取导致旧知识灾难性遗忘的问题；现有方法未区分任务特有知识与通用能力，参数更新相互干扰。

Method: 提出Mixture of Sparse Experts for Task-Agnostic Continual Learning（SETA）：将模型分解为任务特定专家（隔离任务模式）和共享专家（提取通用特征），并引入弹性权重锚定保护关键共享知识，配合统一门控网络动态选择专家组合。

Result: 在多个领域专用与通用基准测试中，SETA持续超越当前基于参数高效微调的最先进持续学习方法。

Conclusion: SETA通过模块化子空间分解与弹性保护机制，实现了任务知识隔离与共享能力保留的平衡，为大语言模型持续学习提供了更鲁棒、可扩展的解决方案。

Abstract: Continual learning in Large Language Models (LLMs) is hindered by the plasticity-stability dilemma, where acquiring new capabilities often leads to catastrophic forgetting of previous knowledge. Existing methods typically treat parameters uniformly, failing to distinguish between specific task knowledge and shared capabilities. We introduce Mixture of Sparse Experts for Task-Agnostic Continual Learning, referred to as SETA, a framework that resolves the plasticity-stability conflict by decomposing the model into modular subspaces. Unlike standard updates, where tasks compete for the same parameters, SETA separates knowledge into unique experts, designed to isolate task-specific patterns, and shared experts, responsible for capturing common features. This structure is maintained through elastic weight anchoring, which protects critical shared knowledge and enables a unified gating network to automatically retrieve the correct expert combination for each task during inference. Extensive experiments across diverse domain-specific and general benchmarks demonstrate that SETA consistently outperforms state-of-the-art parameter-efficient fine-tuning-based continual learning methods.

</details>


### [372] [BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation](https://arxiv.org/abs/2601.17625)
*Yuhan Xie,Jinhan Liu,Xiaoyong Ni,Fei Tan,Icare Sakr,Thibault Collin,Shiqi Sun,Alejandro Rodriguez Guajardo,Demon Fanny,Charles-francois Vincent Latchoumane,Henri Lorach,Jocelyne Bloch,Gregoire Courtine,Mahsa Shoaran*

Main category: cs.LG

TL;DR: 本文提出BrainDistill，一种面向可植入脑机接口（BCI）的轻量级Transformer解码器方案，结合任务特定知识蒸馏（TSKD）与量化感知训练，在保持高性能的同时显著降低计算与功耗开销。


<details>
  <summary>Details</summary>
Motivation: 大型Transformer解码器虽在BCI任务中表现优异，但其高参数量和高计算开销难以满足可植入设备严格的功耗与资源约束。

Method: 提出BrainDistill框架，包含可植入神经解码器（IND）、任务特定知识蒸馏（TSKD）——通过监督投影聚焦关键解码特征，以及量化感知训练（含激活剪裁范围学习）以支持整数推理。

Result: IND在多个神经数据集上超越现有解码器；TSKD在少样本校准下优于其他蒸馏方法；量化后IND在极低功耗下实现近乎无损的推理性能。

Conclusion: BrainDistill为面向临床应用的低功耗、高性能可植入BCI提供了可行且高效的端到端解决方案。

Abstract: Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.

</details>


### [373] [RPNT: Robust Pre-trained Neural Transformer -- A Pathway for Generalized Motor Decoding](https://arxiv.org/abs/2601.17641)
*Hao Fang,Ryan A. Canfield,Tomohiro Ouchi,Beatrice Macagno,Eli Shlizerman,Amy L. Orsborn*

Main category: cs.LG

TL;DR: 本文提出了一种鲁棒预训练神经Transformer模型RPNT，通过多维旋转位置编码、基于上下文的注意力机制和鲁棒自监督学习目标，在跨会话、跨任务、跨被试和跨脑区的脑信号解码任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前脑解码模型难以在不同脑区、会话、行为类型和被试间泛化，亟需能适应并泛化的预训练神经Transformer模型。

Method: 提出RPNT模型，包含：1）多维旋转位置编码（MRoPE）融合实验元数据；2）基于卷积核的上下文注意力机制建模局部时序结构；3）采用均匀因果掩码与对比表征的鲁棒自监督学习目标。在两类多维度神经电生理数据集上分别预训练。

Result: RPNT在跨会话、跨任务、跨被试和跨脑区的行为解码下游任务中均一致超越现有解码模型。

Conclusion: RPNT通过结构化预训练策略实现了对神经活动非平稳性和多样性的鲁棒建模，为通用脑解码提供了新范式。

Abstract: Brain decoding aims to interpret and translate neural activity into behaviors. As such, it is imperative that decoding models are able to generalize across variations, such as recordings from different brain sites, distinct sessions, different types of behavior, and a variety of subjects. Current models can only partially address these challenges and warrant the development of pretrained neural transformer models capable to adapt and generalize. In this work, we propose RPNT - Robust Pretrained Neural Transformer, designed to achieve robust generalization through pretraining, which in turn enables effective finetuning given a downstream task. In particular, RPNT unique components include 1) Multidimensional rotary positional embedding (MRoPE) to aggregate experimental metadata such as site coordinates, session name and behavior types; 2) Context-based attention mechanism via convolution kernels operating on global attention to learn local temporal structures for handling non-stationarity of neural population activity; 3) Robust self-supervised learning (SSL) objective with uniform causal masking strategies and contrastive representations. We pretrained two separate versions of RPNT on distinct datasets a) Multi-session, multi-task, and multi-subject microelectrode benchmark; b) Multi-site recordings using high-density Neuropixel 1.0 probes. The datasets include recordings from the dorsal premotor cortex (PMd) and from the primary motor cortex (M1) regions of nonhuman primates (NHPs) as they performed reaching tasks. After pretraining, we evaluated the generalization of RPNT in cross-session, cross-type, cross-subject, and cross-site downstream behavior decoding tasks. Our results show that RPNT consistently achieves and surpasses the decoding performance of existing decoding models in all tasks.

</details>


### [374] [A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization](https://arxiv.org/abs/2601.17646)
*Karim Bounja,Lahcen Laayouni,Abdeljalil Sakat*

Main category: cs.LG

TL;DR: 本文研究经验风险最小化（ERM）解集的稳定性，提出Painlevé-Kuratowski上半连续性（PK-u.s.c.）作为其内在稳定性概念，并在Mosco一致性扰动与局部有界极小值条件下，刻画了该稳定性的充分条件及定量偏差界。


<details>
  <summary>Details</summary>
Motivation: 传统ERM稳定性分析多基于单值输出，而凸非严格损失函数导致解集为集合值；需建立适配集合值解的稳定性理论。

Method: 引入Painlevé-Kuratowski上半连续性（PK-u.s.c.）作为ERM解对应关系的稳定性定义，结合Mosco收敛、局部有界性与二次增长等条件进行定性与定量分析。

Result: 证明Mosco一致扰动加局部有界极小值可推出PK-u.s.c.、最小值连续性及零间隙近极小值的一致性；二次增长条件下获得显式定量偏差界。

Conclusion: PK-u.s.c.是ERM解集稳定性的本质刻画，为集合值稳定性分析提供了统一框架，并支撑对各类选择（如正则化解）稳定性的合理解释。

Abstract: Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlevé-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.

</details>


### [375] [Time-Varying Causal Treatment for Quantifying the Causal Effect of Short-Term Variations on Arctic Sea Ice Dynamics](https://arxiv.org/abs/2601.17647)
*Akila Sampath,Vandana Janeja,Jianwu Wang*

Main category: cs.LG

TL;DR: 本文提出KGCM-VAE模型，结合物理知识（如速度调制、MMD分布匹配与因果邻接约束）提升海冰厚度对海表面高度（SSH）因果效应的估计精度，在合成与真实北极数据上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在时空因果推断中难以处理未观测混杂因子和缺乏物理约束的问题，而冰融与淡水分布的因果关系对理解极地气候变暖和海平面上升至关重要。

Method: 提出知识引导的因果模型变分自编码器（KGCM-VAE）：引入基于SSH变化动态调制的平滑速度信号作为物理驱动的因果处理；采用最大均值差异（MMD）平衡潜在空间中处理组与对照组协变量分布；设计因果邻接约束解码器以符合已知物理结构。

Result: 在合成与真实北极数据集上，KGCM-VAE在预测误差均方根（PEHE）指标上优于当前最优方法；消融实验表明MMD与因果邻接约束联合使用使估计误差降低1.88%。

Conclusion: 融合物理先验与因果推断的KGCM-VAE能更可靠地量化海冰厚度与SSH之间的因果机制，为极地气候系统建模提供新范式。

Abstract: Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\% reduction in estimation error.

</details>


### [376] [Kareus: Joint Reduction of Dynamic and Static Energy in Large Model Training](https://arxiv.org/abs/2601.17654)
*Ruofan Wu,Jae-Won Chung,Mosharaf Chowdhury*

Main category: cs.LG

TL;DR: 本文提出Kareus训练系统，通过细粒度核调度与频率缩放联合优化动态与静态能耗，在保持相同训练时间下最多降低28.3%能耗，或在相同能耗下最多缩短27.5%训练时间。


<details>
  <summary>Details</summary>
Motivation: AI计算需求激增而能源供应滞后，导致能源成为昂贵且竞争激烈的资源，需显式管理与优化；现有大模型训练优化工作仅关注动态或静态能耗之一，忽视二者联合影响。

Method: 发现细粒度核调度与频率缩放对动态和静态能耗具有联合且相互依赖的影响；据此设计Kareus系统，将难解的联合优化问题分解为局部、基于分区的子问题，并采用多轮多目标优化算法寻找推动时间-能量权衡前沿的执行调度。

Result: 相比当前最优方法，Kareus在相同训练时间下最多降低28.3%训练能耗，或在相同能耗下最多缩短27.5%训练时间。

Conclusion: 联合优化核调度与频率缩放可显著提升大模型训练的时间-能量效率，Kareus为面向能效的大模型训练系统提供了新范式。

Abstract: The computing demand of AI is growing at an unprecedented rate, but energy supply is not keeping pace. As a result, energy has become an expensive, contended resource that requires explicit management and optimization. Although recent works have made significant progress in large model training optimization, they focus only on a single aspect of energy consumption: dynamic or static energy.
  We find that fine-grained kernel scheduling and frequency scaling jointly and interdependently impact both dynamic and static energy consumption. Based on this finding, we design Kareus, a training system that pushes the time--energy tradeoff frontier by optimizing both aspects. Kareus decomposes the intractable joint optimization problem into local, partition-based subproblems. It then uses a multi-pass multi-objective optimization algorithm to find execution schedules that push the time--energy tradeoff frontier. Compared to the state of the art, Kareus reduces training energy by up to 28.3% at the same training time, or reduces training time by up to 27.5% at the same energy consumption.

</details>


### [377] [Entropic Risk-Aware Monte Carlo Tree Search](https://arxiv.org/abs/2601.17667)
*Pedro P. Santos,Jacopo Silvestrin,Alberto Sardinha,Francisco S. Melo*

Main category: cs.LG

TL;DR: 本文提出了一种针对带熵风险度量（ERM）目标的风险感知马尔可夫决策过程（MDP）的、具有理论保证的蒙特卡洛树搜索（MCTS）算法，并给出了非渐近性分析，证明其正确性和多项式遗憾集中性。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对风险感知MDP中熵风险度量目标的MCTS算法的理论保障，尤其缺少非渐近性收敛与遗憾分析。

Method: 基于前人建立的风险感知MDP的动态规划框架，设计一种结合上置信界（UCB）机制的MCTS算法，并进行非渐近性理论分析，证明其在ERM目标下的收敛性与多项式遗憾集中性。

Result: 算法在根节点获得的经验ERM收敛到最优ERM；具备多项式阶的遗憾集中性；实验表明该风险感知MCTS优于相关基线方法。

Conclusion: 所提MCTS算法是首个具备非渐近理论保证的风险感知MDP求解方法，为ERM型风险优化提供了可靠且可分析的在线规划工具。

Abstract: We propose a provably correct Monte Carlo tree search (MCTS) algorithm for solving \textit{risk-aware} Markov decision processes (MDPs) with \textit{entropic risk measure} (ERM) objectives. We provide a \textit{non-asymptotic} analysis of our proposed algorithm, showing that the algorithm: (i) is \textit{correct} in the sense that the empirical ERM obtained at the root node converges to the optimal ERM; and (ii) enjoys \textit{polynomial regret concentration}. Our algorithm successfully exploits the dynamic programming formulations for solving risk-aware MDPs with ERM objectives introduced by previous works in the context of an upper confidence bound-based tree search algorithm. Finally, we provide a set of illustrative experiments comparing our risk-aware MCTS method against relevant baselines.

</details>


### [378] [Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction](https://arxiv.org/abs/2601.17668)
*Jang-Hyun Kim,Dongyoon Han,Sangdoo Yun*

Main category: cs.LG

TL;DR: 本文提出了一种基于门控的KV缓存驱逐方法，用于冻结权重的大语言模型，在几乎不增加计算开销的情况下实现高达70%的KV缓存压缩，同时保持近乎无损的性能。


<details>
  <summary>Details</summary>
Motivation: 高效KV缓存管理对大语言模型实际部署至关重要，但现有压缩技术常在性能下降与计算开销之间难以兼顾。

Method: 引入轻量级sink-attention门控模块识别并保留关键KV对，并设计仅依赖前向传播、无需反向传播的门控训练算法，采用任务无关的重建目标提升泛化性。

Result: 在Qwen2.5-1M、Qwen3和Gemma3系列模型上实验表明，该方法可驱逐最多70% KV缓存，且在长上下文理解、代码理解和数学推理等多类任务中均保持近似无损性能。

Conclusion: 所提方法在极低计算成本下实现了高比率KV缓存压缩与强任务泛化能力，为冻结权重LLM的实际部署提供了高效可行的缓存管理方案。

Abstract: Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.

</details>


### [379] [$\infty$-MoE: Generalizing Mixture of Experts to Infinite Experts](https://arxiv.org/abs/2601.17680)
*Shota Takashiro,Takeshi Kojima,Shohei Taniguchi,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.LG

TL;DR: 本文提出∞-MoE，通过在连续空间中采样参数来选择专家，实现无限专家数量的同时保持计算效率，并在GPT-2 Small上达到接近GPT-2 Medium的性能。


<details>
  <summary>Details</summary>
Motivation: 传统MoE中专家相互独立且离散组合，专家数量增加时训练困难，需稳定训练并扩展专家规模。

Method: 提出∞-MoE，在连续空间中为每个token采样连续值，动态选择大FFN的部分参数，实现‘无限’专家和高效计算。

Result: 基于GPT-2 Small的∞-MoE（129M激活参数/186M总参数）性能媲美350M参数的密集GPT-2 Medium；推理时调节采样专家数可灵活权衡精度与速度，精度最高提升2.5%。

Conclusion: ∞-MoE通过连续专家空间解决了传统MoE训练不稳定与扩展性差的问题，兼顾模型容量、效率与灵活性。

Abstract: The Mixture of Experts (MoE) selects a few feed-forward networks (FFNs) per token, achieving an effective trade-off between computational cost and performance. In conventional MoE, each expert is treated as entirely independent, and experts are combined in a discrete space. As a result, when the number of experts increases, it becomes difficult to train each expert effectively. To stabilize training while increasing the number of experts, we propose $\infty$-MoE that selects a portion of the parameters of large FFNs based on continuous values sampled for each token. By considering experts in a continuous space, this approach allows for an infinite number of experts while maintaining computational efficiency. Experiments show that a GPT-2 Small-based $\infty$-MoE model, with 129M active and 186M total parameters, achieves comparable performance to a dense GPT-2 Medium with 350M parameters. Adjusting the number of sampled experts at inference time allows for a flexible trade-off between accuracy and speed, with an improvement of up to 2.5\% in accuracy over conventional MoE.

</details>


### [380] [Agentic reinforcement learning empowers next-generation chemical language models for molecular design and synthesis](https://arxiv.org/abs/2601.17687)
*Hao Li,He Cao,Shenyao Peng,Zijing Liu,Bin Feng,Yu Wang,Zhiyuan Yan,Yonghong Tian,Yu Li,Li Yuan*

Main category: cs.LG

TL;DR: ChemCRAFT 是一种基于智能体强化学习的新框架，通过将化学推理与知识存储解耦，使小型本地语言模型能借助外部化学工具沙盒高效完成药物设计任务，兼顾性能、隐私与低成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在小型本地模型（易幻觉、知识有限）和大型云端模型（隐私风险高、推理成本高）之间难以兼顾，亟需一种兼顾准确性、隐私性与效率的化学AI新范式。

Method: 提出 ChemCRAFT 框架：1）构建化学智能体沙盒与代理轨迹生成流程；2）发布首个大规模化学工具轨迹数据集 ChemToolDataset；3）提出 SMILES-GRPO 方法构建稠密化学奖励函数，提升小模型调用化学工具的能力。

Result: 在分子结构分析、分子优化和合成路径预测等药物设计任务上，ChemCRAFT 超越当前主流云端大模型；验证了科学推理可作为可学习的工具编排策略，而非仅依赖模型规模。

Conclusion: 科学推理能力可通过工具协同策略习得；ChemCRAFT 为 AI 辅助化学提供了低成本、高隐私、本地部署的新范式，推动分子发现加速。

Abstract: Language models are revolutionizing the biochemistry domain, assisting scientists in drug design and chemical synthesis with high efficiency. Yet current approaches struggle between small language models prone to hallucination and limited knowledge retention, and large cloud-based language models plagued by privacy risks and high inference costs. To bridge this gap, we introduce ChemCRAFT, a novel framework leveraging agentic reinforcement learning to decouple chemical reasoning from knowledge storage. Instead of forcing the model to memorize vast chemical data, our approach empowers the language model to interact with a sandbox for precise information retrieval. This externalization of knowledge allows a locally deployable small model to achieve superior performance with minimal inference costs. To enable small language models for agent-calling ability, we build an agentic trajectory construction pipeline and a comprehensive chemical-agent sandbox. Based on sandbox interactions, we constructed ChemToolDataset, the first large-scale chemical tool trajectory dataset. Simultaneously, we propose SMILES-GRPO to build a dense chemical reward function, promoting the model's ability to call chemical agents. Evaluations across diverse aspects of drug design show that ChemCRAFT outperforms current cloud-based LLMs in molecular structure analysis, molecular optimization, and synthesis pathway prediction, demonstrating that scientific reasoning is not solely an emergent ability of model scale, but a learnable policy of tool orchestration. This work establishes a cost-effective and privacy-preserving paradigm for AI-aided chemistry, opening new avenues for accelerating molecular discovery with locally deployable agents.

</details>


### [381] [FedCCA: Client-Centric Adaptation against Data Heterogeneity in Federated Learning on IoT Devices](https://arxiv.org/abs/2601.17713)
*Kaile Wang,Jiannong Cao,Yu Yang,Xiaoyin Li,Yinfeng Cao*

Main category: cs.LG

TL;DR: 本文提出了一种名为Client-Centric Adaptation联邦学习（FedCCA）的新算法，通过动态客户端选择、自适应聚合以及注意力机制的全局聚合策略，缓解物联网设备间数据异质性对模型性能和收敛速度的影响，从而为每个客户端学习个性化模型。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）快速发展下，基于私有数据（如人体感知数据）进行AI模型训练需求迫切；但联邦学习（FL）中客户端间数据异质性严重制约模型性能与收敛速度，且现有方法在客户端选择和云聚合上固定，难以隐私保护地提取客户端特有信息。

Method: 提出FedCCA算法：引入客户端特有编码器实现选择性适配；采用动态客户端选择与基于该编码器的自适应聚合；设计注意力机制驱动的全局聚合策略以增强多源知识迁移。

Result: 在多个数据集上的大量实验表明，FedCCA在应对数据异质性问题上显著优于现有基线方法，提升了模型性能与收敛速度。

Conclusion: FedCCA通过客户端中心化适配机制，有效缓解了FL中数据异质性带来的挑战，实现了更优的个性化模型学习效果，兼顾隐私保护与模型效能。

Abstract: With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.

</details>


### [382] [Do Reasoning Models Ask Better Questions? A Formal Information-Theoretic Analysis on Multi-Turn LLM Games](https://arxiv.org/abs/2601.17716)
*Daniel M. Pedrozo,Telma W. de L. Soares,Bryan L. M. de Oliveira*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息增益（IG）的多轮对话框架，用于评估大语言模型（LLMs）在模糊用户请求下提出高质量是非问题的能力，并在地理‘猜城市’游戏中验证了带思维链（CoT）推理能力的模型更高效地获取信息。


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对LLM信息寻求行为的全面评估，尤其缺少基于信息增益的中间与最终评价信号，也缺乏对是否使用思维链推理的系统性比较。

Method: 构建三代理交互框架（提问、回答、更新假设空间），在分层知识图谱环境中以Shannon熵定义的信息增益为指标，量化每轮及累计提问有效性；在五级地理分类‘Guess My City’游戏中进行实验，对比全/部分可观测条件下、有/无思维链的多种LLM变体。

Result: 具备显式推理能力的模型单位轮次信息增益更高、求解步数更少（尤其在部分可观测场景）；小模型通过更激进的问题探索补偿能力不足，大模型则表现出更强的最优问题选择自信和更高潜力IG候选生成能力。

Conclusion: 信息增益是衡量LLM主动提问能力的有效指标；引入思维链显著提升信息获取效率，且模型规模与推理机制共同影响其信息寻求策略。

Abstract: Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests. While prior work has explored information-seeking behavior through word games, existing benchmarks lack comprehensive evaluation frameworks that provide both final and intermediate signals based on Information Gain (IG). Moreover, they rarely provide systematic comparisons between models that use chain-of-thought reasoning and those that do not. We propose a multi-turn dialogue framework that quantitatively measures how effectively LLMs gather information through yes/no questions in a hierarchical knowledge graph environment. Our framework employs a triad of interacting LLM agents that ask questions, answer them, and update the hypothesis space. We adopt IG as the main metric, grounded in Shannon entropy, to assess query effectiveness at each turn and cumulatively. We instantiate our framework in a geographical Guess My City game setting organized in a five-level taxonomy and evaluate multiple LLM variants under fully and partially observable conditions, with and without Chain-of-Thought reasoning. Our experiments demonstrate that, among the evaluated models, the ones with explicit reasoning capabilities achieve higher IG per turn and reach solutions in fewer steps, particularly in partially observable settings. Analysis of reasoning traces reveals that smaller models compensate for limited capacity through more aggressive exploration of candidate questions, while larger models exhibit higher assertiveness in selecting optimal queries, generating candidates with greater potential IG.

</details>


### [383] [AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation](https://arxiv.org/abs/2601.17761)
*Dongjie Cheng,Ruifeng Yuan,Yongqi Li,Runyang You,Wenjie Wang,Liqiang Nie,Lei Zhang,Wenjie Li*

Main category: cs.LG

TL;DR: 本文提出AR-Omni，一种基于自回归范式的统一任意模态到任意模态模型，无需额外专家解码器，支持文本、图像和流式语音的联合生成，并通过损失重加权、感知对齐损失与有限状态解码机制解决多模态建模中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的感知与交互天然多模态（语言、视觉、语音），但现有“全能”多模态大模型（Omni MLLMs）多依赖额外专家组件实现多模态输出，缺乏训练与推理的统一性；而自回归建模在文本领域已证明其简洁性与可扩展性，启发本文构建统一自回归多模态模型。

Method: 提出AR-Omni：单一Transformer解码器、单token流、单next-token预测目标；引入任务感知损失重加权缓解模态不平衡；设计轻量级token级感知对齐损失提升图像生成保真度；采用有限状态解码机制平衡生成稳定性与创造性。

Result: AR-Omni在文本、图像、语音三模态生成质量上均表现优异，且具备实时性——语音生成实现实时因子0.88。

Conclusion: AR-Omni验证了纯自回归范式可支撑高质量、实时、统一的任意模态到任意模态生成，为构建真正端到端、无专家模块的全能多模态大模型提供了可行路径。

Abstract: Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of "Omni" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.

</details>


### [384] [LLM-42: Enabling Determinism in LLM Inference with Verified Speculation](https://arxiv.org/abs/2601.17768)
*Raja Gond,Aditya K Kamath,Arkaprava Basu,Ramachandran Ramjee,Ashish Panwar*

Main category: cs.LG

TL;DR: LLM-42 是一种基于调度的轻量级方法，通过验证-回滚机制在保持动态批处理高吞吐的同时实现 LLM 推理的确定性，无需修改现有 GPU 内核。


<details>
  <summary>Details</summary>
Motivation: LLM 推理中因浮点非结合性、动态批处理及 GPU 归约顺序变化导致输出非确定性；现有方案（禁用动态批处理或重写内核）分别牺牲吞吐或引入固定开销。

Method: 提出 LLM-42：利用序列状态一致性假设，在非确定性快速路径上解码 token，并通过固定形状归约调度的轻量验证器对候选 token 进行重放验证；仅对不满足确定性的 token 执行回滚，复用现有内核。

Result: 在保证确定性的同时维持接近动态批处理的高吞吐，开销仅与需确定性的请求流量成正比，无需内核重写。

Conclusion: LLM-42 解耦了确定性与内核设计，为实际部署中按需提供确定性提供了高效、灵活的系统级解决方案。

Abstract: In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism.
  Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.

</details>


### [385] [Shortcut Learning in Binary Classifier Black Boxes: Applications to Voice Anti-Spoofing and Biometrics](https://arxiv.org/abs/2601.17782)
*Md Sahidullah,Hye-jin Shim,Rosa Gonzalez Hautamäki,Tomi H. Kinnunen*

Main category: cs.LG

TL;DR: 本文提出一种新框架，结合干预与观察视角，利用线性混合效应模型对黑盒二分类器进行事后分析，以揭示数据集偏差和'捷径学习'问题，并在语音反欺骗与说话人验证任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型广泛应用下，数据集和模型中的隐性偏差可能引发意外结果，尤其在二分类器中存在'捷径学习'（Clever Hans效应）问题，亟需可解释、可归因的偏差分析方法。

Method: 提出融合干预与观察视角的黑盒分类器分析框架，采用线性混合效应模型进行后验分析，超越传统错误率评估，量化训练/测试数据对分类得分的影响。

Result: 在音频反欺骗和说话人验证任务上，该框架成功识别并量化了数据偏差对统计模型与深度神经网络分类行为的影响，验证了其有效性与可迁移性。

Conclusion: 该框架为理解与诊断分类器中的数据偏差提供了新范式，有助于提升模型鲁棒性与公平性，并推动可解释人工智能的发展。

Abstract: The widespread adoption of deep-learning models in data-driven applications has drawn attention to the potential risks associated with biased datasets and models. Neglected or hidden biases within datasets and models can lead to unexpected results. This study addresses the challenges of dataset bias and explores ``shortcut learning'' or ``Clever Hans effect'' in binary classifiers. We propose a novel framework for analyzing the black-box classifiers and for examining the impact of both training and test data on classifier scores. Our framework incorporates intervention and observational perspectives, employing a linear mixed-effects model for post-hoc analysis. By evaluating classifier performance beyond error rates, we aim to provide insights into biased datasets and offer a comprehensive understanding of their influence on classifier behavior. The effectiveness of our approach is demonstrated through experiments on audio anti-spoofing and speaker verification tasks using both statistical models and deep neural networks. The insights gained from this study have broader implications for tackling biases in other domains and advancing the field of explainable artificial intelligence.

</details>


### [386] [Robust Computational Extraction of Non-Enhancing Hypercellular Tumor Regions from Clinical Imaging Data](https://arxiv.org/abs/2601.17802)
*A. Brawanski,Th. Schaffer,F. Raab,K. -M. Schebesch,M. Schrey,Chr. Doenitz,A. M. Tomé,E. W. Lang*

Main category: cs.LG

TL;DR: 本文提出了一种基于常规MRI数据生成非强化高细胞（NEH）肿瘤区域概率图的计算框架，通过多种网络架构应对影像边界模糊和变异性问题，并以rCBV和增强肿瘤复发位置为临床标记进行验证，支持NEH作为无创影像生物标志物用于精准神经肿瘤诊疗。


<details>
  <summary>Details</summary>
Motivation: 准确识别非增强高细胞（NEH）肿瘤区域是神经肿瘤影像学中的未满足需求，对患者管理和治疗规划具有重要意义。

Method: 构建了一个鲁棒的计算框架，利用多种网络架构从常规MRI数据生成NEH区域的概率图，以应对影像中固有的变异性和缺乏清晰边界的问题。

Result: 该方法在独立临床标记（相对脑血容量rCBV和增强肿瘤复发位置ETRL）上得到验证，展现出方法学鲁棒性和生物学相关性。

Conclusion: 该框架实现了NEH肿瘤区室的可靠、无创映射，有助于将其作为影像生物标志物整合进临床工作流，推动脑肿瘤患者的精准肿瘤学发展。

Abstract: Accurate identification of non-enhancing hypercellular (NEH) tumor regions is an unmet need in neuro-oncological imaging, with significant implications for patient management and treatment planning. We present a robust computational framework that generates probability maps of NEH regions from routine MRI data, leveraging multiple network architectures to address the inherent variability and lack of clear imaging boundaries. Our approach was validated against independent clinical markers -- relative cerebral blood volume (rCBV) and enhancing tumor recurrence location (ETRL) -- demonstrating both methodological robustness and biological relevance. This framework enables reliable, non-invasive mapping of NEH tumor compartments, supporting their integration as imaging biomarkers in clinical workflows and advancing precision oncology for brain tumor patients.

</details>


### [387] [MergeMix: Optimizing Mid-Training Data Mixtures via Learnable Model Merging](https://arxiv.org/abs/2601.17858)
*Jiapeng Wang,Changxin Tian,Kunlong Chen,Ziqi Liu,Jiaxin Mao,Wayne Xin Zhao,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

TL;DR: 本文提出MergeMix方法，通过重用模型合并权重作为低成本、高保真度的性能代理，高效确定最优数据混合比例，避免了传统方法中昂贵的全量训练开销。


<details>
  <summary>Details</summary>
Motivation: 优化数据混合对提升大语言模型性能至关重要，但现有方法依赖启发式试错或昂贵的代理训练，计算成本过高。

Method: 提出MergeMix：先在少量token上训练领域专用专家模型，再通过优化其合并权重来逼近下游任务性能，从而间接优化数据混合比例。

Result: 在8B和16B参数模型上实验表明，MergeMix性能媲美甚至超越人工穷举调优，搜索成本大幅降低；Spearman相关系数ρ>0.9，且具备良好的跨尺度迁移性。

Conclusion: MergeMix是一种可扩展、自动化的数据混合优化新范式，兼顾高效性与可靠性。

Abstract: Optimizing data mixtures is essential for unlocking the full potential of large language models (LLMs), yet identifying the optimal composition remains computationally prohibitive due to reliance on heuristic trials or expensive proxy training. To address this, we introduce \textbf{MergeMix}, a novel approach that efficiently determines optimal data mixing ratios by repurposing model merging weights as a high-fidelity, low-cost performance proxy. By training domain-specific experts on minimal tokens and optimizing their merging weights against downstream benchmarks, MergeMix effectively optimizes the performance of data mixtures without incurring the cost of full-scale training. Extensive experiments on models with 8B and 16B parameters validate that MergeMix achieves performance comparable to or surpassing exhaustive manual tuning while drastically reducing search costs. Furthermore, MergeMix exhibits high rank consistency (Spearman $ρ> 0.9$) and strong cross-scale transferability, offering a scalable, automated solution for data mixture optimization.

</details>


### [388] [EEG Foundation Models: Progresses, Benchmarking, and Open Problems](https://arxiv.org/abs/2601.17883)
*Dingkun Liu,Yuheng Chen,Zhu Chen,Zhenyao Cui,Yaozhi Wen,Jiayu An,Jingwei Luo,Dongrui Wu*

Main category: cs.LG

TL;DR: 本文对50种EEG基础模型进行了系统性综述与统一框架梳理，并在13个数据集上公平评估了12个开源模型，发现线性探针常不充分、专用模型仍具竞争力、模型规模增大未必提升泛化性能。


<details>
  <summary>Details</summary>
Motivation: 缺乏对现有EEG基础模型的公平、全面比较，因预训练目标、预处理方式和下游评估协议不一致。

Method: 构建涵盖数据标准化、模型架构与自监督预训练策略的统一分类框架；在13个EEG数据集上，采用跨被试留一法和被试内少样本设置，对比12个开源基础模型与专用基线模型；评估全参数微调与线性探针效果，并分析模型规模与性能关系。

Result: 1）线性探针常不足以发挥预训练表征能力；2）从头训练的专用模型在多数任务中仍具竞争力；3）当前数据与训练范式下，更大规模基础模型未必带来更好泛化性能。

Conclusion: EEG基础模型的发展需更注重预训练策略、表征可迁移性及实际部署适配性，而非单纯扩大模型规模；统一评估框架为未来研究提供了基准与方向。

Abstract: Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.

</details>


### [389] [Adaptive Weighting in Knowledge Distillation: An Axiomatic Framework for Multi-Scale Teacher Ensemble Optimization](https://arxiv.org/abs/2601.17910)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 本文提出了一种与算子无关的公理化框架，用于多教师知识蒸馏中的自适应加权，涵盖token、task和context三个尺度，并在该框架下建立了存在性、收敛性、稳定性及安全性约束的理论分析。


<details>
  <summary>Details</summary>
Motivation: 现有基于多教师的知识蒸馏方法依赖启发式或实现相关的加权策略，缺乏统一、可解释且具备理论保障的自适应加权机制。

Method: 构建跨token、task、context三尺度的算子无关公理化框架；形式化定义自适应加权算子的结构性条件；研究其可实现性、组合性（通过乘积结构归一化）、存在性与非唯一性；分析梯度优化的收敛性、稳定性与扰动鲁棒性；抽象建模安全约束下的蒸馏过程。

Result: 证明了符合该框架的自适应加权算子的存在性与非唯一性；给出了梯度优化在标准假设下的收敛保证；分析了系统稳定性与对扰动的鲁棒性；提出了安全约束蒸馏的抽象表述；实现了理论保证与具体加权公式解耦。

Conclusion: 该框架为异构性、分布偏移和安全约束下的自适应多教师知识蒸馏提供了统一、可扩展且具备严格理论支撑的分析基础。

Abstract: Knowledge distillation with multiple teachers is increasingly used to improve robustness, efficiency, and safety, yet existing approaches rely largely on heuristic or implementation-specific weighting schemes. This paper develops an operator-agnostic axiomatic framework for adaptive weighting in multi-teacher knowledge distillation across three complementary scales: token, task, and context. We formalize structural conditions under which adaptive weighting operators are well-defined, admit multiple non-equivalent implementations, and can be hierarchically composed via product-structure normalization. Within this framework, we establish existence and non-uniqueness of conforming operators, characterize convergence of gradient-based optimization under standard assumptions, analyze stability and perturbation robustness, and provide an abstract formulation of safety-constrained distillation. The results decouple theoretical guarantees from specific weighting formulas, enabling principled analysis of adaptive distillation methods under heterogeneity, distribution shift, and safety constraints.

</details>


### [390] [Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN](https://arxiv.org/abs/2601.17912)
*Qinyi Liu,Mohammad Khalil,Naman Goel*

Main category: cs.LG

TL;DR: 本文对TabPFN这一面向表格数据的基础模型进行了全面的实证评估，重点考察其预测性能、公平性和鲁棒性；结果表明，尽管TabPFN在预测准确性和抗虚假相关性方面表现优异，但其公平性提升有限且不稳定，尤其在MNAR协变量偏移下，说明因果预训练虽有益但不足以保障算法公平。


<details>
  <summary>Details</summary>
Motivation: 基础模型（如TabPFN）在预训练中融入了因果推理思想，但其公平性尚未被深入探究。

Method: 对TabPFN及其微调变体进行大规模实证评估，涵盖不同数据规模和分布偏移（特别是MNAR协变量偏移）下的预测性能、公平性与鲁棒性。

Result: TabPFN预测准确率优于基线且对虚假相关鲁棒，但公平性提升中等且不一致，尤其在MNAR偏移下表现不佳。

Conclusion: TabPFN中的因果预训练有助于但不足以实现算法公平，实际部署需额外公平性干预。

Abstract: Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.

</details>


### [391] [UniPACT: A Multimodal Framework for Prognostic Question Answering on Raw ECG and Structured EHR](https://arxiv.org/abs/2601.17916)
*Jialu Tang,Tong Xia,Yuan Lu,Aaqib Saeed*

Main category: cs.LG

TL;DR: 本文提出UniPACT框架，通过结构化提示将结构化EHR数据文本化，并与原始ECG波形表征融合，使大语言模型能统一处理多模态临床时序数据，实现精准预后问答，在MDS-ED基准上达到89.37%平均AUROC，显著优于专用基线。


<details>
  <summary>Details</summary>
Motivation: 准确临床预后需整合结构化电子健康记录（EHR）与实时生理信号（如ECG），但大语言模型（LLM）难以原生处理此类异构非文本数据。

Method: 提出UniPACT框架，核心是结构化提示机制，将数值型EHR数据转化为语义丰富的文本，并将其与直接从原始ECG波形中学习的表征进行融合，使LLM能整体推理两种模态。

Result: 在MDS-ED基准上，UniPACT在诊断、恶化、ICU入院和死亡等多样化预后任务中取得89.37%的平均AUROC，达到SOTA；且多模态多任务设计提升了缺失数据下的鲁棒性。

Conclusion: UniPACT成功弥合了LLM处理临床多模态时序数据的模态鸿沟，验证了文本化结构数据与原始信号联合建模的有效性与实用性。

Abstract: Accurate clinical prognosis requires synthesizing structured Electronic Health Records (EHRs) with real-time physiological signals like the Electrocardiogram (ECG). Large Language Models (LLMs) offer a powerful reasoning engine for this task but struggle to natively process these heterogeneous, non-textual data types. To address this, we propose UniPACT (Unified Prognostic Question Answering for Clinical Time-series), a unified framework for prognostic question answering that bridges this modality gap. UniPACT's core contribution is a structured prompting mechanism that converts numerical EHR data into semantically rich text. This textualized patient context is then fused with representations learned directly from raw ECG waveforms, enabling an LLM to reason over both modalities holistically. We evaluate UniPACT on the comprehensive MDS-ED benchmark, it achieves a state-of-the-art mean AUROC of 89.37% across a diverse set of prognostic tasks including diagnosis, deterioration, ICU admission, and mortality, outperforming specialized baselines. Further analysis demonstrates that our multimodal, multi-task approach is critical for performance and provides robustness in missing data scenarios.

</details>


### [392] [treaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding](https://arxiv.org/abs/2601.17917)
*Zhongyu Xiao,Zhiwei Hao,Jianyuan Guo,Yong Luo,Jia Liu,Jie Xu,Han Hu*

Main category: cs.LG

TL;DR: 本文提出Streaming-dLLM，一种无需训练的框架，通过空间维度上的衰减引导后缀建模和时间维度上的动态置信度感知策略（含早退机制），显著提升扩散大语言模型（dLLMs）推理效率，最高达68.2倍加速，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有dLLMs推理方法存在空间冗余（对信息稀疏的后缀区域统一建模）和时间低效（固定去噪调度），未充分利用扩散过程的内在特性。

Method: 提出Streaming-dLLM框架：1）空间上采用衰减引导的后缀建模，剪枝冗余掩码token以近似全上下文；2）时间上采用动态置信度感知策略并引入早退机制，跳过已收敛token的多余迭代。

Result: 在多个基准上实现最高68.2倍的推理加速，同时保持与基线相当的生成质量。

Conclusion: Streaming-dLLM是一种高效、通用且无需训练的dLLMs推理优化框架，有效缓解了块级扩散过程中的空间冗余和时间低效问题。

Abstract: Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.

</details>


### [393] [Dissipative Learning: A Framework for Viable Adaptive Systems](https://arxiv.org/abs/2601.17933)
*Laurent Caraffa*

Main category: cs.LG

TL;DR: 本文提出BEDS框架，将学习视为受耗散约束的压缩信念状态演化过程，证明Fisher-Rao正则化是热力学最优策略，并统一多种现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统学习理论中遗忘和正则化常被视为启发式补充，本文旨在从信息论、热力学与信息几何出发，揭示其作为自适应系统结构性要求的本质。

Method: 基于贝叶斯推理与耗散结构理论，构建BEDS框架；推导条件最优性定理，比较Fisher-Rao与欧氏正则化的热力学效率；将岭回归、SIGReg、EMA、SAC等纳入统一动力学方程。

Result: 证明Fisher-Rao正则化是唯一热力学最优的正则化方式；将过拟合解释为'过度结晶'，灾难性遗忘为耗散控制不足；区分BEDS-可结晶与BEDS-可维持问题；框架自然拓展至持续学习与多智能体场景。

Conclusion: 学习本质上是受耗散约束下维持可行信念态的过程，该视角为理解遗忘、正则化与稳定性提供了原理性基础。

Abstract: We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints.
  A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation.
  Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.

</details>


### [394] [FedGraph-VASP: Privacy-Preserving Federated Graph Learning with Post-Quantum Security for Cross-Institutional Anti-Money Laundering](https://arxiv.org/abs/2601.17935)
*Daniel Commey,Matilda Nkoom,Yousef Alsenani,Sena G. Hounsinou,Garth V. Crosby*

Main category: cs.LG

TL;DR: 本文提出FedGraph-VASP，一种面向VASP机构的隐私保护型联邦图学习框架，通过边界嵌入交换协议与后量子密码学保障，在不共享原始交易数据前提下提升跨机构反洗钱检测性能；在Bitcoin数据上F1达0.508，优于FedSage+；但其效果依赖图连通性，在Ethereum稀疏图上不如生成式方法。


<details>
  <summary>Details</summary>
Motivation: VASP机构在反洗钱监管合规与用户隐私之间存在根本张力：共享敏感交易数据侵犯隐私，孤立建模则无法识别跨链洗钱模式。

Method: 提出FedGraph-VASP框架，核心是Boundary Embedding Exchange协议——仅交换边界账户的压缩、非可逆图神经网络嵌入，并采用Kyber-512（NIST后量子标准）与AES-256-GCM进行加密保护；基于Elliptic比特币和以太坊欺诈数据集，结合Louvain划分与联邦学习设定开展实验评估。

Result: 在Elliptic比特币数据集上F1=0.508，较FedSage+（0.453）提升12.1%；高连通场景下接近中心化性能（F1=0.620）；但在Ethereum稀疏图中表现逊于FedSage+（0.635 vs 0.855）；隐私审计显示嵌入仅部分可逆（R²=0.32）。

Conclusion: 嵌入交换与生成式填补存在图拓扑依赖的权衡：前者适用于高连通交易图，后者更适于高度模块化的稀疏图；FedGraph-VASP为合规与隐私兼顾的跨机构AML提供了可行技术路径。

Abstract: Virtual Asset Service Providers (VASPs) face a fundamental tension between regulatory compliance and user privacy when detecting cross-institutional money laundering. Current approaches require either sharing sensitive transaction data or operating in isolation, leaving critical cross-chain laundering patterns undetected. We present FedGraph-VASP, a privacy-preserving federated graph learning framework that enables collaborative anti-money laundering (AML) without exposing raw user data. Our key contribution is a Boundary Embedding Exchange protocol that shares only compressed, non-invertible graph neural network representations of boundary accounts. These exchanges are secured using post-quantum cryptography, specifically the NIST-standardized Kyber-512 key encapsulation mechanism combined with AES-256-GCM authenticated encryption. Experiments on the Elliptic Bitcoin dataset with realistic Louvain partitioning show that FedGraph-VASP achieves an F1-score of 0.508, outperforming the state-of-the-art generative baseline FedSage+ (F1 = 0.453) by 12.1 percent on binary fraud detection. We further show robustness under low-connectivity settings where generative imputation degrades performance, while approaching centralized performance (F1 = 0.620) in high-connectivity regimes. We additionally evaluate generalization on an Ethereum fraud detection dataset, where FedGraph-VASP (F1 = 0.635) is less effective under sparse cross-silo connectivity, while FedSage+ excels (F1 = 0.855), outperforming even local training (F1 = 0.785). These results highlight a topology-dependent trade-off: embedding exchange benefits connected transaction graphs, whereas generative imputation can dominate in highly modular sparse graphs. A privacy audit shows embeddings are only partially invertible (R^2 = 0.32), limiting exact feature recovery.

</details>


### [395] [Scaling Effects and Uncertainty Quantification in Neural Actor Critic Algorithms](https://arxiv.org/abs/2601.17954)
*Nikos Georgoudios,Konstantinos Spiliopoulos,Justin Sirignano*

Main category: cs.LG

TL;DR: 本文研究了使用浅层神经网络的Actor-Critic算法，重点分析不同网络宽度缩放方案下的收敛性与统计特性，推导了网络输出的渐近展开式，并揭示了方差随缩放参数变化的规律，为超参数选择提供了理论指导。


<details>
  <summary>Details</summary>
Motivation: 以往工作主要关注逆平方根缩放下的收敛性，本文旨在扩展至更一般的逆多项式缩放，以实现对神经Actor-Critic方法输出的更全面统计刻画，特别是量化其不确定性。

Method: 采用渐近分析方法，研究网络宽度趋于无穷时、在指数介于1/2与1之间的逆多项式缩放下，Actor和Critic网络输出的统计结构；推导其作为统计估计量的渐近展开式，并结合数值实验验证理论结果。

Result: 证明了主导阶下方差按网络宽度的(1/2−α)次幂衰减（α为缩放指数），当α趋近1时统计鲁棒性提升；数值实验支持该结论并显示更快收敛；同时给出了学习率、探索率等超参数关于网络宽度与缩放参数的显式选取准则。

Conclusion: 逆多项式缩放（指数∈(1/2,1)）能显著改善神经Actor-Critic算法的统计性能；本文建立的渐近框架不仅深化了对其不确定性的理解，还为实际训练提供了可证明优良统计行为的超参数设计指南。

Abstract: We investigate the neural Actor Critic algorithm using shallow neural networks for both the Actor and Critic models. The focus of this work is twofold: first, to compare the convergence properties of the network outputs under various scaling schemes as the network width and the number of training steps tend to infinity; and second, to provide precise control of the approximation error associated with each scaling regime. Previous work has shown convergence to ordinary differential equations with random initial conditions under inverse square root scaling in the network width. In this work, we shift the focus from convergence speed alone to a more comprehensive statistical characterization of the algorithm's output, with the goal of quantifying uncertainty in neural Actor Critic methods. Specifically, we study a general inverse polynomial scaling in the network width, with an exponent treated as a tunable hyperparameter taking values strictly between one half and one. We derive an asymptotic expansion of the network outputs, interpreted as statistical estimators, in order to clarify their structure. To leading order, we show that the variance decays as a power of the network width, with an exponent equal to one half minus the scaling parameter, implying improved statistical robustness as the scaling parameter approaches one. Numerical experiments support this behavior and further suggest faster convergence for this choice of scaling. Finally, our analysis yields concrete guidelines for selecting algorithmic hyperparameters, including learning rates and exploration rates, as functions of the network width and the scaling parameter, ensuring provably favorable statistical behavior.

</details>


### [396] [TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors](https://arxiv.org/abs/2601.17958)
*Ido Andrew Atad,Itamar Zimerman,Shahar Katz,Lior Wolf*

Main category: cs.LG

TL;DR: 本文提出TensorLens，一种新颖的张量表示方法，将整个Transformer模型建模为一个依赖于输入的线性算子，通过高阶注意力交互张量统一编码注意力、前馈网络、归一化和残差连接等所有组件。


<details>
  <summary>Details</summary>
Motivation: 现有对注意力矩阵的分析多局限于单个注意力头或层，缺乏对模型全局行为的统一、完整表征。

Method: 提出TensorLens，构建一个高阶注意力交互张量，将Transformer中注意力、FFN、激活、归一化及残差连接联合编码为一个输入依赖的线性算子。

Result: TensorLens在理论上严谨，在实验中展现出比以往注意力聚合方法更丰富的表征能力，并可作为可解释性与模型理解工具的有力基础。

Conclusion: TensorLens填补了Transformer全局行为统一建模的空白，为可解释性、可视化、操控与蒸馏等任务提供了更强大、更一致的理论与实践基础。

Abstract: Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.

</details>


### [397] [Federated learning for unpaired multimodal data through a homogeneous transformer model](https://arxiv.org/abs/2601.17986)
*Anders Eklund*

Main category: cs.LG

TL;DR: 本文提出了一种新型联邦学习框架，用于在模态分离、数据不配对且严格私有的分布式节点上训练多模态基础模型，通过公共锚点集和核对齐实现语义对齐，保障数据主权，并支持大模型稳定微调与不确定性加权聚合。


<details>
  <summary>Details</summary>
Motivation: 现实中的联邦环境数据往往是未配对、碎片化、跨节点分离且严格私有的（如一个节点只有传感器数据，另一个只有文本日志），而现有联邦学习方法依赖配对数据或需共享原始特征，违背数据主权。

Method: 引入小规模公共锚点集，利用其计算Gram矩阵，通过中心化核对齐（CKA）实现跨模态语义对齐；提出子空间稳定微调法，解耦域内幅度偏移与语义方向；设计精度加权平均机制，基于不确定性估计动态加权各节点模型更新。

Result: 在不传输任何私有样本的前提下，实现了跨异构模态节点的全局多模态Transformer训练，提供了比原型共享更强的数学隐私保证，并支持大规模模型的稳定联邦微调。

Conclusion: 本工作为联邦环境下非配对基础模型训练奠定了数学基础，使全球模型能从分散、分离、私有的数据孤岛中学习统一世界表征，无需中心化存储或配对样本。

Abstract: Training of multimodal foundation models is currently restricted to centralized data centers containing massive, aligned datasets (e.g., image-text pairs). However, in realistic federated environments, data is often unpaired and fragmented across disjoint nodes; one node may hold sensor data, while another holds textual logs. These datasets are strictly private and share no common samples. Current federated learning (FL) methods fail in this regime, as they assume local clients possess aligned pairs or require sharing raw feature embeddings, which violates data sovereignty. We propose a novel framework to train a global multimodal transformer across decentralized nodes with disjoint modalities. We introduce a small public anchor set to align disjoint private manifolds. Using Gram matrices calculated from these public anchors, we enforce semantic alignment across modalities through centered kernel alignment without ever transmitting private samples, offering a mathematically superior privacy guarantee compared to prototype sharing. Further, we introduce a subspace-stabilized fine-tuning method to handle FL with huge transformer models. We strictly decouple domain-specific magnitude shifts from semantic direction, ensuring that nodes with varying sensor characteristics align geometrically to the global consensus. Lastly, we propose precision weighted averaging, where efficiently obtained uncertainty estimates are used to downweight uncertain nodes. This paper establishes the mathematical backbone for federated unpaired foundation models, enabling a global model to learn a unified representation of the world from fragmented, disjoint, and private data silos without requiring centralized storage or paired samples.

</details>


### [398] [Systematic Characterization of Minimal Deep Learning Architectures: A Unified Analysis of Convergence, Pruning, and Quantization](https://arxiv.org/abs/2601.17987)
*Ziwei Zheng,Huizhi Liang,Vaclav Snasel,Vito Latora,Panos Pardalos,Giuseppe Nicosia,Varun Ojha*

Main category: cs.LG

TL;DR: 本文提出了一种系统性探索深度学习模型收敛性、剪枝敏感性和量化鲁棒性关系的计算方法，在多种架构（DNN、CNN、ViT）和图像分类任务上发现学习动力学存在三个普适阶段，并揭示了最小可学习参数量、剪枝冗余度及量化精度影响规律。


<details>
  <summary>Details</summary>
Motivation: 识别能可靠解决任务的最小深度学习架构仍具挑战，需系统理解收敛、剪枝与量化间的内在关联。

Method: 构建结构化设计扫描流程：在大量架构上进行训练以评估收敛行为、剪枝敏感性和量化鲁棒性，并在不同复杂度图像分类任务及DNN/CNN/ViT三类模型上开展实证分析。

Result: 发现跨架构的学习动力学普遍存在不稳定、学习、过拟合三阶段；确定了稳定学习所需的最小可学习参数量；揭示剪枝冗余可达60%，且深层模型更鲁棒；量化对参数少的模型和难数据集影响更大。

Conclusion: 研究成果为在剪枝与低精度约束下选择紧凑、稳定图像分类模型提供了可操作指导。

Abstract: Deep learning networks excel at classification, yet identifying minimal architectures that reliably solve a task remains challenging. We present a computational methodology for systematically exploring and analyzing the relationships among convergence, pruning, and quantization. The workflow first performs a structured design sweep across a large set of architectures, then evaluates convergence behavior, pruning sensitivity, and quantization robustness on representative models. Focusing on well-known image classification of increasing complexity, and across Deep Neural Networks, Convolutional Neural Networks, and Vision Transformers, our initial results show that, despite architectural diversity, performance is largely invariant and learning dynamics consistently exhibit three regimes: unstable, learning, and overfitting. We further characterize the minimal learnable parameters required for stable learning, uncover distinct convergence and pruning phases, and quantify the effect of reduced numeric precision on trainable parameters. Aligning with intuition, the results confirm that deeper architectures are more resilient to pruning than shallower ones, with parameter redundancy as high as 60%, and quantization impacts models with fewer learnable parameters more severely and has a larger effect on harder image datasets. These findings provide actionable guidance for selecting compact, stable models under pruning and low-precision constraints in image classification.

</details>


### [399] [Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning](https://arxiv.org/abs/2601.17995)
*Shudi Weng,Ming Xiao,Mikael Skoglund*

Main category: cs.LG

TL;DR: 本文提出了一种鲁棒的分层安全聚合方案H-SecCoGC，通过引入编码策略实现结构化聚合，以在不可靠通信和强隐私保护下提升联邦学习的准确性、鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 在分层联邦学习中，不可靠通信会随机破坏隐私噪声的协调，导致模型精度与隐私保护难以兼顾。

Method: 提出H-SecCoGC方案，融合编码策略实现结构化安全聚合，解决部分参与问题并增强鲁棒性。

Result: 理论分析与实验表明，该方案在任意强隐私保障和不可靠通信下均优于现有方法。

Conclusion: H-SecCoGC有效提升了分层联邦学习在隐私、鲁棒性与效率三方面的综合性能。

Abstract: Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees

</details>


### [400] [Spelling Bee Embeddings for Language Modeling](https://arxiv.org/abs/2601.18030)
*Markus N. Rabe,Judith Clymo,Zheren Dong*

Main category: cs.LG

TL;DR: 本文提出了一种对嵌入层的简单修改，通过在词元嵌入中注入拼写信息，从而提升模型在拼写任务及其他标准基准上的性能，并减少约8%的计算与数据需求。


<details>
  <summary>Details</summary>
Motivation: 提升语言模型在拼写相关任务上的表现，并探索是否能通过改进嵌入层设计带来更广泛的性能增益。

Method: 对嵌入层进行修改，在词元嵌入中显式融入拼写信息。

Result: 改进后的模型不仅在拼写任务上表现更好，也在多个标准基准上取得提升；缩放实验（40M–800M参数）表明其效果相当于节省约8%的计算量和训练数据。

Conclusion: 向词元嵌入注入拼写信息是一种高效且可扩展的改进方式，能在不显著增加复杂度的前提下提升模型多方面性能。

Abstract: We introduce a simple modification to the embedding layer. The key change is to infuse token embeddings with information about their spelling. Models trained with these embeddings improve not only on spelling, but also across standard benchmarks. We conduct scaling studies for models with 40M to 800M parameters, which suggest that the improvements are equivalent to needing about 8% less compute and data to achieve the same test loss.

</details>


### [401] [Multimodal Machine Learning for Soft High-k Elastomers under Data Scarcity](https://arxiv.org/abs/2601.18032)
*Brijesh FNU,Viet Thanh Duy Nguyen,Ashima Sharma,Md Harun Rashid Molla,Chengyi Xu,Truong-Son Hy*

Main category: cs.LG

TL;DR: 本文构建了一个丙烯酸酯基介电弹性体的高质量数据集，并提出了一种利用预训练多模态聚合物表征的少样本学习框架，以准确预测其介电与力学性能，从而加速高介电常数、低模量软弹性体的数据高效发现。


<details>
  <summary>Details</summary>
Motivation: 现有介电弹性体面临高介电常数与低杨氏模量难以兼顾的挑战，且缺乏系统性涵盖分子结构、介电与力学性能的公开数据集。

Method: 整理近10年文献，构建丙烯酸酯类介电弹性体结构-性能数据集；结合图神经网络与序列编码器的预训练聚合物表征，建立多模态少样本学习模型。

Result: 实现了对介电常数和杨氏模量的高精度少样本预测；验证了该方法可迁移至其他聚合物骨架（如硅酮、聚氨酯）。

Conclusion: 预训练多模态表征可有效缓解聚合物材料领域的小样本瓶颈，为软高k介电弹性体的高效设计提供了新范式。

Abstract: Dielectric materials are critical building blocks for modern electronics such as sensors, actuators, and transistors. With the rapid recent advance in soft and stretchable electronics for emerging human- and robot-interfacing applications, there is a surging need for high-performance dielectric elastomers. However, it remains a grand challenge to develop soft elastomers that simultaneously possess high dielectric constants (k, related to energy storage capacity) and low Young's moduli (E, related to mechanical flexibility). While some new elastomer designs have been reported in individual (mostly one-off) studies, almost no structured dataset is currently available for dielectric elastomers that systematically encompasses their molecular sequence, dielectric, and mechanical properties. Within this context, we curate a compact, high-quality dataset of acrylate-based dielectric elastomers, one of the most widely explored elastomer backbones due to its versatile chemistry and molecular design flexibility, by screening and aggregating experimental results from the literature over the past 10 years. Building on this dataset, we propose a multimodal learning framework that leverages large-scale pretrained polymer representations from graph- and sequence-based encoders. These pretrained embeddings transfer rich chemical and structural knowledge from vast polymer corpora, enabling accurate few-shot prediction of both dielectric and mechanical properties from molecular sequences. Our results represent a new paradigm for transferring knowledge from pretrained multimodal models to overcome severe data scarcity, which can be readily translated to other polymer backbones (e.g., silicones, urethanes) and thus accelerate data-efficient discovery of soft high-k dielectric elastomers. Our source code and dataset are publicly available at https://github.com/HySonLab/Polymers

</details>


### [402] [Resonant Sparse Geometry Networks](https://arxiv.org/abs/2601.18064)
*Hasi Hays*

Main category: cs.LG

TL;DR: 本文提出了受大脑启发的Resonant Sparse Geometry Networks (RSGN)，通过在学习到的双曲空间中嵌入计算节点，实现输入依赖的动态稀疏连接，显著降低计算复杂度，并在长程依赖和分层分类任务上优于Transformer。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer等模型因密集注意力机制导致的O(n^2)高计算复杂度问题，探索更高效、更具生物合理性的稀疏、几何化神经架构。

Method: 提出RSGN架构：节点嵌入于学习得到的双曲空间，连接强度随测地距离衰减；采用快慢双时间尺度机制——快速可微激活传播（梯度下降优化）与慢速赫布式结构学习（基于局部相关性规则）；理论分析其O(n*k)复杂度。

Result: 在长程依赖任务上达96.5%准确率，参数量仅为标准Transformer的1/15；在20类分层分类任务中以41,672参数达23.8%准确率（Transformer需403,348参数才达30.1%）；消融实验证实赫布学习持续提升性能。

Conclusion: 稀疏、几何组织的类脑计算范式是构建更高效、更符合生物学原理神经网络的可行路径。

Abstract: We introduce Resonant Sparse Geometry Networks (RSGN), a brain-inspired architecture with self-organizing sparse
  hierarchical input-dependent connectivity. Unlike Transformer architectures that employ dense attention mechanisms with
  O(n^2) computational complexity, RSGN embeds computational nodes in learned hyperbolic space where connection strength
  decays with geodesic distance, achieving dynamic sparsity that adapts to each input. The architecture operates on two
  distinct timescales: fast differentiable activation propagation optimized through gradient descent, and slow
  Hebbian-inspired structural learning for connectivity adaptation through local correlation rules. We provide rigorous
  mathematical analysis demonstrating that RSGN achieves O(n*k) computational complexity, where k << n represents the average
  active neighborhood size. Experimental evaluation on hierarchical classification and long-range dependency tasks
  demonstrates that RSGN achieves 96.5% accuracy on long-range dependency tasks while using approximately 15x fewer
  parameters than standard Transformers. On challenging hierarchical classification with 20 classes, RSGN achieves 23.8%
  accuracy (compared to 5% random baseline) with only 41,672 parameters, nearly 10x fewer than the Transformer baselines
  which require 403,348 parameters to achieve 30.1% accuracy. Our ablation studies confirm the contribution of each architectural
  component, with Hebbian learning providing consistent improvements. These results suggest that brain-inspired principles
  of sparse, geometrically-organized computation offer a promising direction toward more efficient and biologically plausible
  neural architectures.

</details>


### [403] [Comparison requires valid measurement: Rethinking attack success rate comparisons in AI red teaming](https://arxiv.org/abs/2601.18076)
*Alexandra Chouldechova,A. Feder Cooper,Solon Barocas,Abhinav Palia,Dan Vann,Hanna Wallach*

Main category: cs.LG

TL;DR: 本文质疑了通过攻击成功率（ASR）比较来评估AI系统安全性和攻击方法有效性的做法，指出其常缺乏实证支持，并存在‘苹果与橙子’式错误比较和测量效度低的问题；作者结合社会科学测量理论与推断统计学，提出ASR可比性的理论条件，并以越狱（jailbreaking）为例展开分析。


<details>
  <summary>Details</summary>
Motivation: 现有AI红队测试中广泛依赖攻击成功率（ASR）进行系统安全性或攻击方法优劣的比较，但此类比较往往缺乏理论基础和测量有效性支撑，易导致误导性结论。

Method: 融合社会科学测量理论（如测量效度、可比性条件）与推断统计学原理，构建ASR可比性的概念框架；以AI越狱为典型案例，开展概念分析、理论推演与实证讨论。

Result: 明确了ASR可被有意义比较所需满足的若干条件（如测量构念一致性、任务等价性、评分标准可比性等），并系统揭示了当前研究中大量ASR比较存在的效度缺陷与不可比性问题。

Conclusion: 单纯依赖ASR数值对比得出的安全性或攻击效能结论往往不可靠；未来AI红队评估需重视测量理论基础，确保比较在构念、方法与情境上具有实质可比性。

Abstract: We argue that conclusions drawn about relative system safety or attack method efficacy via AI red teaming are often not supported by evidence provided by attack success rate (ASR) comparisons. We show, through conceptual, theoretical, and empirical contributions, that many conclusions are founded on apples-to-oranges comparisons or low-validity measurements. Our arguments are grounded in asking a simple question: When can attack success rates be meaningfully compared? To answer this question, we draw on ideas from social science measurement theory and inferential statistics, which, taken together, provide a conceptual grounding for understanding when numerical values obtained through the quantification of system attributes can be meaningfully compared. Through this lens, we articulate conditions under which ASRs can and cannot be meaningfully compared. Using jailbreaking as a running example, we provide examples and extensive discussion of apples-to-oranges ASR comparisons and measurement validity challenges.

</details>


### [404] [DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal](https://arxiv.org/abs/2601.18081)
*Peixuan Han,Yingjie Yu,Jingjun Xu,Jiaxuan You*

Main category: cs.LG

TL;DR: 本文提出DRPG框架，通过分解评审意见、检索论文证据、规划反驳策略和生成回应四步，实现高质量学术反驳自动生成，显著超越现有方法并达到超人类水平。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在学术研究中应用广泛，但自动学术反驳支持仍被忽视，现有方法难以处理长上下文且缺乏针对性和说服力。

Method: 提出DRPG智能体框架，包含四个步骤：分解评审为原子问题、从论文中检索相关证据、规划反驳策略、按策略生成回应；其中规划器准确率超98%。

Result: 在顶级会议数据上实验表明，DRPG显著优于现有反驳流程，仅用8B模型即超越平均人类水平；在多轮复杂场景下也表现良好。

Conclusion: DRPG有效提升了学术反驳质量与可解释性，具备支持规模化学术讨论的潜力。

Abstract: Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.

</details>


### [405] [LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts](https://arxiv.org/abs/2601.18089)
*Venmugil Elango,Nidhi Bhatia,Roger Waleffe,Rasoul Shafipour,Tomer Asida,Abhinav Khattar,Nave Assaf,Maximilian Golub,Joey Guman,Tiyasa Mitra,Ritchie Zhao,Ritika Borkar,Ran Zilberstein,Mostofa Patwary,Mohammad Shoeybi,Bita Rouhani*

Main category: cs.LG

TL;DR: 本文提出了一种新的混合专家（MoE）架构LatentMoE，从软硬件协同设计角度出发，优化推理效率（精度/FLOP和精度/参数），在高达95B参数和1T token训练规模下验证其显著优于标准MoE，并已被Nemotron-3系列大模型采用。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构在推理成本（精度每浮点运算、每参数）方面是否接近最优尚不明确，需从硬件-软件协同设计角度重新审视其性能瓶颈。

Method: 基于实证与理论分析，刻画不同部署场景（离线高吞吐与在线低延迟）下的关键性能瓶颈，并通过系统性架构探索设计LatentMoE；在95B参数、1T token训练规模上进行实证验证，并辅以理论分析。

Result: LatentMoE在精度/FLOP和精度/参数两个指标上持续超越标准MoE架构；已被Nvidia Nemotron-3 Super/Ultra旗舰模型采用，并扩展至更大规模（更长token序列、更大模型）。

Conclusion: LatentMoE是一种更优的MoE架构设计，实现了硬件效率与模型精度的更好平衡，为大规模语言模型的高效部署提供了新范式。

Abstract: Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).

</details>


### [406] [From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models](https://arxiv.org/abs/2601.18091)
*Longwei Ding,Anhao Zhao,Fanghua Ye,Ziyang Chen,Xiaoyu Shen*

Main category: cs.LG

TL;DR: 本文系统研究了大语言模型（LLM）在指令遵循型（LLM-instruct）与推理增强型（LLM-think）两类范式下的剪枝效果，发现剪枝策略效果高度依赖模型范式：深度剪枝更适合分类任务，宽度剪枝更利于生成与推理任务；静态剪枝更利于保持推理能力，动态剪枝在分类和生成上表现更好但难以支持长链推理。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝研究主要集中于指令遵循型大模型，而对显式生成中间推理链的推理增强型模型（LLM-think）缺乏系统考察，尚不清楚既有剪枝策略是否适用。

Method: 开展受控对比实验，分别对LLM-instruct和LLM-think模型进行静态深度剪枝、静态宽度剪枝和动态剪枝；为消除分布偏移影响，校准剪枝与恢复数据使其匹配各自原始训练分布；在17个涵盖分类、生成与推理的任务上统一评估。

Result: 发现显著的范式依赖差异：（1）深度剪枝在分类任务上优于宽度剪枝，宽度剪枝在生成与推理任务上更鲁棒；（2）静态剪枝更能保持推理性能，动态剪枝在分类与生成上更优，但在长链推理上仍具挑战。

Conclusion: 推理增强型大模型具有独特结构与行为特征，需设计专门适配其特性的剪枝策略，不能直接套用指令遵循型模型的剪枝方法。

Abstract: Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\textbf{LLM-instruct}$) and reasoning-augmented ($\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning.

</details>


### [407] [AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110)
*Pedram Zaree,Md Abdullah Al Mamun,Yue Dong,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: 本文提出AttenMIA，一种基于Transformer自注意力机制的新型成员推断攻击（MIA）方法，利用注意力模式识别训练数据成员，显著优于现有基于置信度或嵌入的方法，在低误报率下表现优异，并揭示注意力机制可能加剧大语言模型隐私风险。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）因训练数据量大，存在记忆训练样本带来的隐私与知识产权风险；现有成员推断攻击（MIA）依赖输出置信度或嵌入特征，信号脆弱、攻击效果有限。

Method: 提出AttenMIA框架，提取多层多头自注意力模式作为特征，结合扰动下的散度度量，训练MIA分类器。

Result: 在LLaMA-2、Pythia、OPT等开源模型上实验表明，注意力特征持续优于基线方法；在WikiMIA-32基准上达0.996 ROC AUC和87.9% TPR@1%FPR；注意力信号具有跨数据集与架构泛化性；用于数据提取时可超越当前最优方法。

Conclusion: 自注意力机制虽提升模型可解释性，却意外放大LLM隐私风险，亟需针对性防御机制。

Abstract: Large Language Models (LLMs) are increasingly deployed to enable or improve a multitude of real-world applications. Given the large size of their training data sets, their tendency to memorize training data raises serious privacy and intellectual property concerns. A key threat is the membership inference attack (MIA), which aims to determine whether a given sample was included in the model's training set. Existing MIAs for LLMs rely primarily on output confidence scores or embedding-based features, but these signals are often brittle, leading to limited attack success. We introduce AttenMIA, a new MIA framework that exploits self-attention patterns inside the transformer model to infer membership. Attention controls the information flow within the transformer, exposing different patterns for memorization that can be used to identify members of the dataset. Our method uses information from attention heads across layers and combines them with perturbation-based divergence metrics to train an effective MIA classifier. Using extensive experiments on open-source models including LLaMA-2, Pythia, and Opt models, we show that attention-based features consistently outperform baselines, particularly under the important low-false-positive metric (e.g., achieving up to 0.996 ROC AUC & 87.9% TPR@1%FPR on the WikiMIA-32 benchmark with Llama2-13b). We show that attention signals generalize across datasets and architectures, and provide a layer- and head-level analysis of where membership leakage is most pronounced. We also show that using AttenMIA to replace other membership inference attacks in a data extraction framework results in training data extraction attacks that outperform the state of the art. Our findings reveal that attention mechanisms, originally introduced to enhance interpretability, can inadvertently amplify privacy risks in LLMs, underscoring the need for new defenses.

</details>


### [408] [Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting](https://arxiv.org/abs/2601.18111)
*Jean Kossaifi,Nikola Kovachki,Morteza Mardani,Daniel Leibovici,Suman Ravuri,Ira Shokar,Edoardo Calvello,Mohammad Shoaib Abbas,Peter Harrington,Ashay Subramaniam,Noah Brenowitz,Boris Bonev,Wonmin Byeon,Karsten Kreis,Dale Durran,Arash Vahdat,Mike Pritchard,Jan Kautz*

Main category: cs.LG

TL;DR: 本文提出了一种可扩展的多尺度大气动力学学习框架，无需复杂架构或专用训练策略，即可在中程天气预报中实现最先进的概率预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动天气预报方法架构和训练策略繁杂，掩盖了影响预报准确性的根本因素。

Method: 结合直接下采样的潜在空间与历史条件局部投影器，构建可扩展的多尺度大气动力学学习框架，并兼容多种概率估计器（如随机插值、扩散模型、CRPS集成训练）。

Result: 在与IFS和GenCast对比验证中，在大多数变量上取得统计显著的性能提升。

Conclusion: 扩大通用模型规模足以达到最先进中程预测水平，无需定制化训练方案，且适用于各类概率建模框架。

Abstract: The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.

</details>


### [409] [Robust Learning of a Group DRO Neuron](https://arxiv.org/abs/2601.18115)
*Guyang Cao,Shuyao Li,Sushrut Karmalkar,Jelena Diakonikolas*

Main category: cs.LG

TL;DR: 本文研究在存在任意标签噪声和组级分布偏移的情况下，如何学习单个神经元，并提出了一种针对群体分布鲁棒优化（Group DRO）问题的高效 primal-dual 算法，能在非凸损失下提供鲁棒学习保证。


<details>
  <summary>Details</summary>
Motivation: 解决在任意标签噪声和组级分布偏移下的单神经元学习问题，提升模型在最坏组权重下的泛化能力与鲁棒性。

Method: 提出一种计算高效的 primal-dual 算法，通过引入 f-散度正则项来控制组权重偏差，并在非凸平方损失下进行优化。

Result: 算法输出的参数向量 ŵw 具有常数因子近似最优性；理论分析支持其在任意标签污染和组分布偏移下的鲁棒性；在大语言模型预训练基准上验证了有效性。

Conclusion: 该方法为非凸 Group DRO 问题提供了首个兼具理论保证与实用性的解决方案，拓展了鲁棒学习在现实噪声与分布偏移场景中的适用性。

Abstract: We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\mathcal p_{[1]},\dots,\mathcal p_{[K]}$, we seek to approximate $\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\boldsymbolλ \in Δ_K$, where the objective is $\sum_{i \in [K]}λ_{[i]}\,\mathbb E_{(\mathbf x,y)\sim\mathcal p_{[i]}}(σ(\mathbf w\cdot\mathbf x)-y)^2 - νd_f(\boldsymbolλ,\frac{1}{K}\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $ν\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\widehat{\mathbf w}$ that is constant-factor competitive with $\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.

</details>


### [410] [Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods](https://arxiv.org/abs/2601.18142)
*Mingxu Zhang,Huicheng Zhang,Jiaming Ji,Yaodong Yang,Ying Sun*

Main category: cs.LG

TL;DR: 本文提出了一种基于自抗扰控制（ADRC）的拉格朗日安全强化学习方法（ADRC-Lagrangian），以解决传统安全RL中因参数敏感性和相位滞后导致的振荡与频繁安全违规问题；实验表明其在降低违规次数、违规幅度和平均代价方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于拉格朗日的方法（如PID和经典拉格朗日法）在安全强化学习中存在振荡严重、安全约束频繁被违反的问题，主要源于参数敏感性和固有相位滞后。

Method: 提出ADRC-Lagrangian方法，将自抗扰控制（ADRC）引入拉格朗日框架，构建统一框架，兼容经典及PID拉格朗日方法，并提升鲁棒性、抑制振荡。

Result: 实验显示该方法将安全违规次数减少最多74%，约束违规幅度降低89%，平均代价下降67%。

Conclusion: ADRC-Lagrangian方法在复杂环境中显著提升了安全强化学习的安全性与稳定性，是一种更鲁棒、更高效的安全约束优化方案。

Abstract: Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\%, establishing superior effectiveness for Safe RL in complex environments.

</details>


### [411] [FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning](https://arxiv.org/abs/2601.18150)
*Zhaopeng Qiu,Shuang Yu,Jingqi Zhang,Shuai Zhang,Xue Huang,Jingyi Yang,Junjie Lai*

Main category: cs.LG

TL;DR: 本文提出了一种面向大语言模型强化学习（RL）的实用FP8推理栈，通过块级FP8量化、FP8 KV缓存及基于重要性采样的修正方法，在保持训练稳定性的同时显著提升rollout吞吐量。


<details>
  <summary>Details</summary>
Motivation: RL中rollout阶段因长序列导致注意力计算和KV缓存内存成为瓶颈；FP8虽有潜力，但面临策略权重动态更新和低精度rollout引发训练-推理不匹配的挑战。

Method: （i）采用块级FP8量化实现W8A8线性层rollout；（ii）扩展FP8至KV缓存，并通过每步QKV尺度重校准消除长上下文内存瓶颈；（iii）引入基于重要性采样的rollout修正（TIS/MIS变体）缓解精度不匹配。

Result: 在稠密与MoE模型上实现最高44%的rollout吞吐提升，且学习行为与BF16基线相当。

Conclusion: 该FP8 rollout栈在veRL生态中实现了工程可行性与算法鲁棒性的统一，为LLM RL高效训练提供了可落地的低精度解决方案。

Abstract: Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.

</details>


### [412] [Learning Fair Domain Adaptation with Virtual Label Distribution](https://arxiv.org/abs/2601.18171)
*Yuguang Zhang,Lijun Sheng,Jian Liang,Ran He*

Main category: cs.LG

TL;DR: 本文提出了一种名为VILL的无监督域自适应方法，旨在提升类别公平性，通过自适应重加权和KL散度重平衡策略，增强难分类类别的影响并调整决策边界。


<details>
  <summary>Details</summary>
Motivation: 现有UDA方法忽视了不同类别间的性能差异（即类别公平性问题），导致模型偏向易分类类别而忽略难分类类别。

Method: 提出了Virtual Label-distribution-aware Learning (VILL)框架，包括自适应重加权策略以增强难分类类别的影响，以及基于KL散度的重平衡策略来显式调整决策边界。

Result: 在常用数据集上的实验表明，VILL可作为即插即用模块集成到现有UDA方法中，显著提升类别公平性，同时保持高整体准确率。

Conclusion: VILL是一种简单有效的方法，能兼顾最坏情况性能与整体准确率，为解决UDA中的类别公平性问题提供了新思路。

Abstract: Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness.

</details>


### [413] [Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients](https://arxiv.org/abs/2601.18189)
*Rui Wu,Yongjun Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的混合序无环性约束（AHOC）及对应的平滑近端梯度优化算法（SPG-AHOC），在标准可识别性假设下，理论上保证有限步内精确恢复有向无环图（DAG）结构，无需后验阈值截断。


<details>
  <summary>Details</summary>
Motivation: 现有基于连续优化的因果发现方法（如NOTEARS）仅能保证渐近收敛到驻点，所得加权矩阵稠密，需人为阈值化才能得到DAG，导致结构模糊和理论与离散图结构脱节。

Method: 提出Hybrid-Order Acyclicity Constraint（AHOC）替代传统迹指数约束，并设计Smoothed Proximal Gradient算法（SPG-AHOC）进行优化；利用近端算法的流形识别性质，建立有限时间oracle性质的理论保障。

Result: 在标准可识别性条件下，SPG-AHOC可在有限迭代内精确恢复DAG的支撑集（即零/非零结构），输出严格稀疏图，无需任何后处理阈值；实验表明其结构恢复精度达SOTA。

Conclusion: AHOC与SPG-AHOC成功弥合了连续优化与离散DAG结构之间的理论鸿沟，首次实现了带严格理论保证的有限步精确结构识别，消除了因果图学习中的结构性歧义。

Abstract: Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory.

</details>


### [414] [HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models](https://arxiv.org/abs/2601.18200)
*Chenyu Zhang,Xinchen Lyu,Chenshan Ren,Shuhan Liu,Qimei Cui,Xiaofeng Tao*

Main category: cs.LG

TL;DR: 本文提出HeterCSI框架，解决无线基础模型在处理异构信道状态信息（CSI）时因尺度与场景双重异质性导致的梯度干扰与泛化受限问题；通过尺度感知自适应批处理与双掩码机制，实现高效跨场景泛化，显著提升CSI重建与预测性能，并降低训练延迟。


<details>
  <summary>Details</summary>
Motivation: 现有预训练方法受限于固定输入维度或按尺度隔离训练，难以应对CSI在尺度和场景上的双重异质性，导致泛化能力与可扩展性不足。

Method: 提出HeterCSI框架：将异构CSI批构建建模为最小化零填充开销且保持场景多样性的划分优化问题；设计尺度感知自适应批处理策略以对齐相似尺度样本；引入双掩码机制分离有效信号与填充伪影；基于梯度动态分析揭示尺度异质性引发破坏性梯度干扰、而场景多样性可促进建设性梯度对齐。

Result: 在12个数据集上验证：无需场景特定微调即实现通用基础模型；相比零样本基准WiFo，NMSE分别降低7.19 dB（CSI重建）、4.08 dB（时域预测）、5.27 dB（频域预测）；训练延迟降低53%，平均泛化性能提升1.53 dB。

Conclusion: HeterCSI通过梯度动态新视角与结构化批处理设计，有效协调训练效率与跨场景鲁棒泛化，为6G无线基础模型提供了可扩展、高性能的异构CSI预训练范式。

Abstract: Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.

</details>


### [415] [Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting](https://arxiv.org/abs/2601.18231)
*Trong Khiem Tran,Manh Cuong Dao,Phi Le Nguyen,Thao Nguyen Truong,Trong Nghia Hoang*

Main category: cs.LG

TL;DR: 本文提出了一种理论框架，通过引入‘特征-标签失真’概念，建立了目标误差的可证明泛化界，揭示了特征对齐与目标拟合之间的相互作用，并据此设计出性能显著优于现有方法的新算法。


<details>
  <summary>Details</summary>
Motivation: 适应预训练模型到未见过的特征模态日益重要，但现有工作缺乏对特征对齐与目标拟合之间关键交互的理论理解。

Method: 构建了一个原理性框架，提出‘特征-标签失真’新概念，推导出目标误差的可证明泛化界，指导特征对齐与目标拟合的协同优化。

Result: 所提方法在多个基准数据集上显著优于当前最优方法。

Conclusion: 特征对齐与目标拟合的协同优化需基于理论指导；本文泛化界为该协同提供了可解释、可操作的设计依据。

Abstract: Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.

</details>


### [416] [Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity](https://arxiv.org/abs/2601.18245)
*Santanu Das,Jatin Batra*

Main category: cs.LG

TL;DR: 本文提出了首个针对重尾噪声和对抗性污染下鲁棒相位恢复问题的多项式时间算法，通过将鲁棒谱初始化与鲁棒PCA的最新算法进展联系起来，实现了近线性样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 相位恢复在光学、晶体学等领域有广泛应用，但现有算法对测量误差（尤其是重尾噪声和对抗性污染）鲁棒性不足；此前Buna和Rebeschini提出了指数时间算法，其关键步骤——鲁棒谱初始化——被认为缺乏高效实现方案。

Method: 建立鲁棒谱初始化与鲁棒主成分分析（PCA）算法之间的联系，利用后者最新进展设计多项式时间算法，支持对测量值y_i和感知向量a_i同时存在常数比例对抗性污染的情形。

Result: 首次实现了鲁棒相位恢复问题的多项式时间求解，样本复杂度达O(n log n)量级（即近线性），显著优于此前指数时间算法。

Conclusion: 本文突破了鲁棒谱初始化的技术瓶颈，将鲁棒PCA方法成功迁移至相位恢复问题，为重尾噪声与对抗污染并存下的非凸反问题提供了高效、理论保证的解决方案。

Abstract: Phase retrieval is the classical problem of recovering a signal $x^* \in \mathbb{R}^n$ from its noisy phaseless measurements $y_i = \langle a_i, x^* \rangle^2 + ζ_i$ (where $ζ_i$ denotes noise, and $a_i$ is the sensing vector) for $i \in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.

</details>


### [417] [Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs](https://arxiv.org/abs/2601.18255)
*Fei Meng*

Main category: cs.LG

TL;DR: 本文揭示了经验回放（ER）在大语言模型持续学习中对不同任务类型的双重影响：对鲁棒的非结构化任务有正向迁移，但对脆弱的结构化任务（如代码生成）造成显著负向迁移；为此提出正交子空间唤醒（OSW）方法，在保证旧知识结构安全的同时维持新任务学习能力。


<details>
  <summary>Details</summary>
Motivation: 经验回放（ER）虽被广泛用于缓解灾难性遗忘，但其对不同类型任务（尤其是结构化与非结构化任务）的影响尚未被系统揭示，亟需一种兼顾稳定性与结构性安全的新方法。

Method: 提出正交子空间唤醒（OSW）：通过短暂‘唤醒’阶段识别先前任务的关键参数子空间，并强制新任务更新在该子空间的正交方向上进行，从而数学上保障已有知识结构不被破坏。

Result: 在四任务持续学习序列上，OSW在保持代码生成等脆弱能力方面显著优于ER，同时不牺牲新任务的学习性能；验证了结构安全性评估的必要性。

Conclusion: ER在持续学习中存在结构性风险，OSW通过正交约束提供了结构安全保证，表明未来LLM持续学习需同时关注平均性能保留与结构完整性。

Abstract: Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief "wake-up" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded "safety guarantee" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.

</details>


### [418] [FGGM: Fisher-Guided Gradient Masking for Continual Learning](https://arxiv.org/abs/2601.18261)
*Chao-Hong Tan,Qian Chen,Wen Wang,Yukun Ma,Chong Zhang,Chong Deng,Qinglin Zhang,Xiangang Li,Jieping Ye*

Main category: cs.LG

TL;DR: 本文提出Fisher-Guided Gradient Masking（FGGM）方法，利用对角Fisher信息动态生成二值掩码，选择性更新参数以缓解大语言模型持续学习中的灾难性遗忘，无需历史数据，在TRACE基准上显著优于监督微调和MIGU。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在持续学习中因灾难性遗忘导致的性能下降问题。

Method: 提出Fisher-Guided Gradient Masking（FGGM）框架，基于对角Fisher信息估计参数重要性，动态生成带自适应阈值的二值掩码，实现关键参数保护与更新平衡。

Result: 在TRACE基准上，FGGM相较监督微调（SFT）提升9.6%通用能力保留率，相较MIGU提升4.4%；代码生成任务中也验证其更优的抗遗忘能力。

Conclusion: FGGM是一种无需历史数据、具有数学原理支撑的有效持续学习方法，能更好兼顾稳定性与可塑性。

Abstract: Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.

</details>


### [419] [Neural Network Approximation: A View from Polytope Decomposition](https://arxiv.org/abs/2601.18264)
*ZeYu Li,ShiJun Zhang,TieYong Zeng,FengLei Fan*

Main category: cs.LG

TL;DR: 本文从多面体分解视角研究ReLU网络的通用逼近能力，提出一种显式核多项式方法，结合Totik-Ditzian型连续模与多面体域分解，构建分段逼近网络，在奇异点附近更高效灵活，并推广至解析函数以获得更高逼近阶。


<details>
  <summary>Details</summary>
Motivation: 现有通用逼近理论多采用均匀划分输入空间的方式，忽视目标函数的局部正则性；本文旨在提出更现实、任务导向的逼近方法。

Method: 基于多面体分解视角，设计显式核多项式方法，利用Totik-Ditzian型连续模刻画逼近精度，并在每个子域上分别构造ReLU网络逼近该多项式。

Result: 所提方法在奇异点附近比现有方法更高效灵活；并可扩展至解析函数，实现更高逼近速率。

Conclusion: 多面体分解为ReLU网络的通用逼近提供了更精细、自适应且实用的理论框架，提升了逼近效率与灵活性。

Abstract: Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.

</details>


### [420] [What Do Learned Models Measure?](https://arxiv.org/abs/2601.18278)
*Indrė Žliobaitė*

Main category: cs.LG

TL;DR: 本文提出“学习测量函数”概念，强调当机器学习模型被用作测量工具而非单纯预测器时，需关注其输出作为测量量的稳定性（measurement stability）；指出传统评估标准（如泛化误差、校准性、鲁棒性）无法保证该稳定性，并通过真实案例验证不同模型即使预测性能相近，也可能产生系统性不等价的测量结果。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型越来越多地被用作科学与数据驱动应用中的测量仪器，但现有评估框架仅关注预测性能，忽视了模型输出作为测量量的一致性与可解释性问题。

Method: 形式化定义了学习测量函数及其关键性质——测量稳定性（即在学习过程实现方式和应用场景变化下，所测得数量保持不变），并理论分析与实证检验了标准评估指标是否能保障该性质。

Result: 证明泛化误差、校准性和鲁棒性等常用指标均不能保证测量稳定性；真实案例显示，预测性能相近的模型可能产生系统性不一致的测量结果，尤其在分布偏移下尤为明显。

Conclusion: 当模型输出被解释为测量值时，现有评估体系存在根本性局限，亟需引入‘测量稳定性’作为新的独立评估维度。

Abstract: In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.

</details>


### [421] [TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292)
*Zhewen Tan,Wenhan Yu,Jianfeng Si,Tongxin Liu,Kaiqi Guan,Huiyan Jin,Jiawen Tao,Xiaokun Yuan,Duohe Ma,Xiangzheng Zhang,Tong Yang,Lin Sun*

Main category: cs.LG

TL;DR: 本文提出了一种名为TriPlay-RL的闭环强化学习框架，通过攻击者、防御者和评估者三角色协同迭代优化，实现大语言模型安全对齐，显著提升对抗有效性、安全性与评估精细度，且几乎无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型的安全风险日益突出，亟需降低有毒有害内容生成，而现有安全对齐范式依赖大量人工标注，效率低、可扩展性差。

Method: 提出TriPlay-RL闭环强化学习框架，使攻击者、防御者和评估者在统一学习环中协同迭代优化，无需或仅需极少人工标注。

Result: 攻击者在保持高多样性的同时，对抗有效性提升20%-50%；防御者安全性能提升10%-30%，且不损害通用推理能力；评估者持续提升细粒度判断能力，能准确区分不安全响应、简单拒绝和有益引导。

Conclusion: TriPlay-RL建立了高效、可扩展的大语言模型安全对齐新范式，支持三角色在统一学习环中持续共进化。

Abstract: In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.

</details>


### [422] [A Master Class on Reproducibility: A Student Hackathon on Advanced MRI Reconstruction Methods](https://arxiv.org/abs/2601.18314)
*Lina Felsner,Sevgi G. Kafali,Hannah Eichhorn,Agnes A. J. Leth,Aidas Batvinskas,Andre Datchev,Fabian Klemm,Jan Aulich,Puntika Leepagorn,Ruben Klinger,Daniel Rueckert,Julia A. Schnabel*

Main category: cs.LG

TL;DR: This paper reports on a student reproducibility hackathon aimed at replicating results from three influential MRI reconstruction papers—MoDL, HUMUS-Net, and an untrained physics-regularized dynamic MRI method—and shares insights, outcomes, and best practices for reproducible code development.


<details>
  <summary>Details</summary>
Motivation: To improve reproducibility in medical imaging research by engaging students in hands-on replication of influential MRI reconstruction methods and identifying common pitfalls and effective practices.

Method: Organized a student hackathon to reproduce three MRI reconstruction papers; evaluated reproduction success, conducted additional experiments, and distilled fundamental practices for building reproducible codebases.

Result: Successful partial or full replication of the three methods was achieved by student teams; key challenges and solutions in reproducibility were identified and documented.

Conclusion: Reproducibility in MRI reconstruction is feasible but requires careful attention to implementation details, shared resources, and community-driven standards; the hackathon format proved effective for training and knowledge transfer.

Abstract: We report the design, protocol, and outcomes of a student reproducibility hackathon focused on replicating the results of three influential MRI reconstruction papers: (a) MoDL, an unrolled model-based network with learned denoising; (b) HUMUS-Net, a hybrid unrolled multiscale CNN+Transformer architecture; and (c) an untrained, physics-regularized dynamic MRI method that uses a quantitative MR model for early stopping. We describe the setup of the hackathon and present reproduction outcomes alongside additional experiments, and we detail fundamental practices for building reproducible codebases.

</details>


### [423] [Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals](https://arxiv.org/abs/2601.18326)
*Jie Li,Jing Li,Lu Lv,Zhanyu Ju,Fengkui Gong*

Main category: cs.LG

TL;DR: 本文提出了一种基于Zadoff-Chu序列与时频图像认知融合的无人机信号分布外检测（OODD）算法，用于远程识别（RID），通过多模态特征交互与融合提升分类与OOD检测性能，并在仿真中展现出优越性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机远程识别（RID）任务中，对未知或非标准通信协议无人机信号的分布外检测（OODD）难题，提升系统对异常/新型无人机信号的识别能力。

Method: 提取接收射频信号中的Zadoff-Chu（ZC）序列特征（针对DJI协议）和时频图像（TFI）特征（覆盖未知协议），经专用特征提取模块增强与对齐；再通过多模态特征交互、单模态融合及多模态融合生成互补特征；最后沿空间与通道维计算判别得分并生成自适应注意力权重，加权后经Softmax输出分类结果。

Result: 仿真表明该算法在RID和OODD指标上分别比现有方法提升1.7%和7.5%，且在不同飞行条件与多种无人机类型下均表现出强鲁棒性。

Conclusion: 所提多模态认知融合框架有效提升了无人机信号OODD与RID联合性能，为复杂电磁环境下可靠无人机识别提供了新思路。

Abstract: We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.

</details>


### [424] [Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection](https://arxiv.org/abs/2601.18329)
*Chuhan Feng,Jing Li,Jie Li,Lu Lv,Fengkui Gong*

Main category: cs.LG

TL;DR: 本文提出了一种基于可分辨性驱动的空间-通道选择与梯度范数的无人机信号分布外（OOD）检测算法，通过自适应加权时频图像特征并融合梯度范数与能量分数实现高鲁棒性OOD检测。


<details>
  <summary>Details</summary>
Motivation: 提升无人机信号在复杂无线环境中对分布外样本的检测能力，解决传统方法对协议特异性时频特征利用不足及OOD样本不稳定性建模薄弱的问题。

Method: 提出可分辨性驱动的空间-通道选择机制，结合梯度范数度量扰动敏感性，并与能量分数融合进行联合推断。

Result: 仿真结果表明该算法在不同信噪比（SNR）和多种无人机类型下均展现出更优的判别能力和鲁棒性能。

Conclusion: 所提算法有效提升了无人机信号OOD检测的准确性和泛化能力，适用于实际动态无线环境。

Abstract: We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.

</details>


### [425] [Structural Gender Bias in Credit Scoring: Proxy Leakage](https://arxiv.org/abs/2601.18342)
*Navya SD,Sreekanth D,SS Uma Sankari*

Main category: cs.LG

TL;DR: 本研究揭示了台湾信用违约数据集中存在的结构性性别偏见，指出即使移除敏感属性并采用标准公平性干预措施，模型仍可通过婚姻状况、年龄和信用额度等非敏感特征隐式推断性别，导致算法歧视持续存在。


<details>
  <summary>Details</summary>
Motivation: 金融行业广泛采用机器学习进行信用风险评估，但算法偏见持续阻碍金融包容的公平性。现有‘去敏感化即公平’范式存在根本缺陷，亟需系统性审计隐性结构偏见。

Method: 结合SHAP可解释性分析与对抗式逆向建模框架，对台湾信用违约数据集开展公平性审计：首先识别非敏感特征作为性别代理变量，再量化其重构性别的能力（ROC AUC=0.65）。

Result: 发现Marital Status、Age、Credit Limit等非敏感变量是强性别代理；仅用非敏感特征即可以0.65 ROC AUC重构性别标签，证明传统公平性审计失效。

Conclusion: 应摒弃‘公平即盲视’理念，转向因果感知建模与结构性问责机制，以真正实现金融AI的公平性。

Abstract: As financial institutions increasingly adopt machine learning for credit risk assessment, the persistence of algorithmic bias remains a critical barrier to equitable financial inclusion. This study provides a comprehensive audit of structural gender bias within the Taiwan Credit Default dataset, specifically challenging the prevailing doctrine of "fairness through blindness." Despite the removal of explicit protected attributes and the application of industry standard fairness interventions, our results demonstrate that gendered predictive signals remain deeply embedded within non-sensitive features. Utilizing SHAP (SHapley Additive exPlanations), we identify that variables such as Marital Status, Age, and Credit Limit function as potent proxies for gender, allowing models to maintain discriminatory pathways while appearing statistically fair. To mathematically quantify this leakage, we employ an adversarial inverse modeling framework. Our findings reveal that the protected gender attribute can be reconstructed from purely non-sensitive financial features with an ROC AUC score of 0.65, demonstrating that traditional fairness audits are insufficient for detecting implicit structural bias. These results advocate for a shift from surface-level statistical parity toward causal-aware modeling and structural accountability in financial AI.

</details>


### [426] [Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning](https://arxiv.org/abs/2601.18356)
*Weiqin Yang,Haowen Xue,Qingyi Peng,Hexuan Hu,Qian Huang,Tingbo Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种多模态因果检索增强生成（Multimodal Causal RAG）框架，通过引入因果推理与临床因果图谱检索，提升医学视觉语言模型在诊断报告生成等任务中的事实准确性、鲁棒性与可解释性，使其超越相关性建模，迈向可信临床推理。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型依赖表面统计关联，缺乏对病理生理因果机制的建模，导致脆弱性、幻觉和数据偏差敏感；传统RAG仅基于语义相似性检索，仍引入伪相关。

Method: 提出多模态因果RAG框架：从外部知识源中检索临床相关示例及因果图谱，并以反事实与干预证据为条件进行模型推理，而非仅依赖相关性。

Result: 在放射科报告生成、诊断预测和视觉问答任务上，显著提升了事实准确性、分布偏移鲁棒性与可解释性。

Conclusion: 因果检索是构建可信赖、超越模式匹配的医学VLM的一条可扩展路径，有助于高风险临床场景下的多模态可信推理。

Abstract: Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.

</details>


### [427] [Estimating Dense-Packed Zone Height in Liquid-Liquid Separation: A Physics-Informed Neural Network Approach](https://arxiv.org/abs/2601.18399)
*Mehmet Velioglu,Song Zhai,Alexander Mitsos,Adel Mhamdi,Andreas Jupke,Manuel Dahmen*

Main category: cs.LG

TL;DR: 本文提出一种基于物理信息神经网络（PINN）的两阶段方法，利用廉价的体积流量测量数据估计重力沉降器中液-液分散体系的相界面高度，通过预训练与实验数据微调结合，并嵌入扩展卡尔曼滤波框架实现在线状态估计。


<details>
  <summary>Details</summary>
Motivation: 重力沉降器中致密堆积区高度是关键性能与安全指标，但受光学限制难以直接、经济地测量，亟需仅依赖易测变量（如流量）的可靠估计方法。

Method: 构建物理信息神经网络（PINN），先基于低精度机理模型生成的合成数据和体积平衡方程进行预训练；再用少量实验数据微调；最后将可微PINN嵌入类扩展卡尔曼滤波的状态估计算法中，实现从流量测量实时追踪相高度。所有模型均采用集成方式以量化参数不确定性。

Result: 在前向仿真和滤波估计任务中，两阶段训练的PINN均显著优于未预训练的PINN及纯数据驱动的两阶段神经网络，在相高度估计精度上表现最优。

Conclusion: 融合机理约束与稀疏实验数据的两阶段PINN框架，能有效克服光学测量限制，在无需额外传感器的前提下实现高精度、鲁棒的相高度在线估计，适用于化工、制药及回收等实际过程。

Abstract: Separating liquid-liquid dispersions in gravity settlers is critical in chemical, pharmaceutical, and recycling processes. The dense-packed zone height is an important performance and safety indicator but it is often expensive and impractical to measure due to optical limitations. We propose to estimate phase heights using only inexpensive volume flow measurements. To this end, a physics-informed neural network (PINN) is first pretrained on synthetic data and physics equations derived from a low-fidelity (approximate) mechanistic model to reduce the need for extensive experimental data. While the mechanistic model is used to generate synthetic training data, only volume balance equations are used in the PINN, since the integration of submodels describing droplet coalescence and sedimentation into the PINN would be computationally prohibitive. The pretrained PINN is then fine-tuned with scarce experimental data to capture the actual dynamics of the separator. We then employ the differentiable PINN as a predictive model in an Extended Kalman Filter inspired state estimation framework, enabling the phase heights to be tracked and updated from flow-rate measurements. We first test the two-stage trained PINN by forward simulation from a known initial state against the mechanistic model and a non-pretrained PINN. We then evaluate phase height estimation performance with the filter, comparing the two-stage trained PINN with a two-stage trained purely data-driven neural network. All model types are trained and evaluated using ensembles to account for model parameter uncertainty. In all evaluations, the two-stage trained PINN yields the most accurate phase-height estimates.

</details>


### [428] [Superlinear Multi-Step Attention](https://arxiv.org/abs/2601.18401)
*Yufeng Huang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Superlinear attention的多步可训练注意力架构，通过将标准因果自注意力重构成多步搜索问题，在保持随机上下文访问能力的同时，实现了亚二次时间复杂度（如O(L^1.5)），并在长序列（达10M）上验证了其系统可行性与初步有效性。


<details>
  <summary>Details</summary>
Motivation: 解决标准自注意力在长序列下O(L²)计算复杂度过高、而现有高效注意力方法常牺牲随机上下文访问（即结构非排他性）的问题。

Method: 将因果自注意力建模为N步搜索问题，总复杂度为O(L^{1+1/N})；以N=2为例，第一阶段进行O(L^{3/2})跨度搜索，第二阶段在选中跨度内执行O(L^{3/2})跨度注意力；采用可学习路由机制实现端到端训练。

Result: 在单块B200 GPU上，改进的30B混合MoE模型在1M和10M上下文长度下分别达到114和80 token/sec解码吞吐量；在NIAH任务上，仅经有限训练即在256K上下文下表现强劲。

Conclusion: Superlinear attention在理论复杂度、结构灵活性（保留随机访问）与工程可行性之间取得良好平衡，为超长上下文建模提供了新架构范式，后续需在更多长上下文任务上全面评估质量。

Abstract: In this paper, we propose \textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \textbf{random context access} (a.k.a.\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.

</details>


### [429] [Frequency-Based Hyperparameter Selection in Games](https://arxiv.org/abs/2601.18409)
*Aniket Sanyal,Baraah A. M. Sidahmed,Rebekka Burkholz,Tatjana Chavdarova*

Main category: cs.LG

TL;DR: 本文提出Modal LookAhead (MoLA)，一种基于振荡动力学频率估计的自适应超参数选择方法，用于改进光滑博弈中的学习过程，相比LookAhead具有更快的训练速度和更少的计算开销。


<details>
  <summary>Details</summary>
Motivation: 光滑博弈中的学习因旋转动力学而不同于标准最小化，导致传统超参数调优策略失效；现有方法如LookAhead虽有效但引入了对性能影响显著的额外参数，亟需一种有原则的超参数选择方法。

Method: 通过分析连续时间轨迹和离散动力学频谱中的振荡频率，提出Modal LookAhead（MoLA），作为LookAhead的扩展，实现超参数对问题的自适应选择。

Result: MoLA在纯旋转博弈和混合场景中均能加速训练，且计算开销极小，并提供了收敛性保证。

Conclusion: 基于频率分析的自适应超参数选择是提升博弈学习效率的有效途径，MoLA为光滑博弈中的优化提供了一种原理清晰、实用性强的新方法。

Abstract: Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.

</details>


### [430] [Gradient Regularized Natural Gradients](https://arxiv.org/abs/2601.18420)
*Satya Prakash Dash,Hossein Abdi,Wei Pan,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 本文提出了一种结合梯度正则化与自然梯度更新的新型二阶优化器GRNG，包含无需显式计算Fisher信息矩阵（FIM）的频率派和贝叶斯派两种变体，并在理论收敛性与实际视觉/语言任务上均展现出优于一阶与现有二阶方法的优化速度与泛化性能。


<details>
  <summary>Details</summary>
Motivation: 尽管自然梯度下降可加速训练初期优化，但其训练动力学如何从梯度正则化（GR）中受益尚缺乏研究；同时，GR已被证实可提升模型泛化能力，亟需将其与二阶优化有效融合。

Method: 提出Gradient-Regularized Natural Gradients（GRNG）框架，包含：1）避免显式FIM求逆的结构化近似频率派算法；2）基于正则化卡尔曼滤波的贝叶斯派算法，彻底消除FIM求逆需求；并给出收敛性理论保证。

Result: GRNG在视觉和语言基准任务上显著优于SGD、AdamW、K-FAC和Sophia等基线，在优化速度与泛化性能两方面均取得一致提升。

Conclusion: 梯度正则化是一种原则性强且实用的工具，能有效增强自然梯度方法在大规模深度学习中的鲁棒性与实用性。

Abstract: Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.

</details>


### [431] [GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level](https://arxiv.org/abs/2601.18447)
*Jinlong Hu,Jiacheng Liu*

Main category: cs.LG

TL;DR: 本文提出了一种面向深度图学习模型的生成式模型级反事实解释方法GCFX，通过增强的深度图生成框架与全局摘要算法，生成高质量、具代表性的全局反事实解释，提升模型可解释性与可信度。


<details>
  <summary>Details</summary>
Motivation: 深度图学习模型因结构复杂、缺乏透明性而难以解释，影响用户理解与信任，亟需模型级、全局性的解释技术。

Method: 提出GCFX方法：基于深度图生成的生成式模型级反事实解释框架，融合双编码器、结构感知标记器和消息传递神经网络解码器，并结合全局反事实摘要算法筛选最具代表性解释。

Result: 在合成数据集与多个真实数据集上的实验表明，GCFX在反事实有效性与覆盖率上优于现有方法，同时保持较低解释成本。

Conclusion: GCFX为深度图学习模型提供了高效、可靠、可扩展的全局反事实解释能力，显著增强了模型的实用性与可信度。

Abstract: Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.

</details>


### [432] [Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States](https://arxiv.org/abs/2601.18479)
*Kyoleen Kwak,Hyoseok Hwang*

Main category: cs.LG

TL;DR: 本文提出ASAP方法，通过引入过渡诱导相似状态和对齐动作与前一状态预测来平滑强化学习中的高频动作振荡，从而提升真实环境中的控制性能。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在实际环境中应用受限，因其动作输出存在高频振荡；现有基于损失的方法依赖启发式或合成的状态相似性定义，难以准确反映系统动力学。

Method: 提出过渡诱导相似状态（即从上一状态转移得到的下一状态分布），并基于此设计ASAP方法：通过将当前动作与过渡诱导相似状态下的动作对齐，并惩罚二阶差分，实现动作平滑。

Result: 在Gymnasium和Isaac-Lab环境中实验表明，ASAP相比现有方法能产生更平滑的控制信号并提升策略性能。

Conclusion: ASAP是一种数据驱动、无需先验假设的动作平滑方法，能更准确建模系统动力学，有效缓解深度强化学习中的动作振荡问题。

Abstract: Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.

</details>


### [433] [Nearly Optimal Bayesian Inference for Structural Missingness](https://arxiv.org/abs/2601.18500)
*Chen Liang,Donghua Yang,Yutong Wang,Tianle Zhang,Shenghe Zhou,Zhiyu Liang,Hengtong Zhang,Hongzhi Wang,Ziqi Li,Xiyang Zhang,Zheng Liang,Yifei Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于贝叶斯后验预测分布的框架，用于处理结构化缺失数据问题，解耦缺失值后验学习与标签预测，实现不确定性传播，并在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 结构性缺失（如因果或逻辑约束导致的未定义值、MNAR机制等）使传统‘先插补再训练’方法失效，带来因果循环、分布偏移和不确定性丢失等问题。

Method: 采用贝叶斯视角，通过后验预测分布对完整模型不确定性进行积分；将缺失值后验学习与标签预测解耦，支持后验集成。

Result: 在43个分类和15个插补基准上达到SOTA；在SCM先验下具备有限样本近贝叶斯最优性保证。

Conclusion: 该框架以‘几乎免费午餐’方式实现不确定性保留的鲁棒预测，为结构性缺失建模提供了新范式。

Abstract: Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.

</details>


### [434] [Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark](https://arxiv.org/abs/2601.18509)
*Andro Sabashvili*

Main category: cs.LG

TL;DR: 本文综述了在时间序列预测中应用共形预测（CP）以实现可靠不确定性量化的方法，重点解决时间序列数据违反CP所需交换性假设的问题，并对比分析了四类主要解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列不确定性量化方法依赖强分布假设，而共形预测虽具分布无关性与理论保障，却因时间序列的时序依赖性违背其所需的交换性假设，亟需适配方法。

Method: 系统梳理并分类四类应对策略：放宽交换性假设的方法、将独立时间序列集作为数据单元的方法、显式建模预测残差动态的方法、以及适应分布漂移的在线学习算法。

Result: 通过综合比较，揭示了各类方法在计算效率与真实数据上的实际性能表现。

Conclusion: 该综述为时间序列共形预测提供了结构化视角，指明了当前研究进展、适用场景与实践权衡。

Abstract: Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.

</details>


### [435] [Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates](https://arxiv.org/abs/2601.18510)
*Yibo Li,Zijie Lin,Ailin Deng,Xuan Zhang,Yufei He,Shuo Ji,Tri Cao,Bryan Hooi*

Main category: cs.LG

TL;DR: 本文提出了一种无需训练的测试时策略优化框架JitRL，通过非参数化动态记忆和实时轨迹检索来估计动作优势，并直接调制LLM输出logits，理论证明其为KL约束策略优化的闭式解，在WebArena和Jericho上超越现有无训练方法，且比微调方法更高效、低成本。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在部署后因权重冻结而难以持续适应；传统强化学习虽可行但计算成本高且易灾难性遗忘。

Method: 提出Just-In-Time Reinforcement Learning（JitRL）：无需梯度更新，利用动态非参数记忆存储经验，实时检索相关轨迹估计动作优势，并以加性方式调制LLM输出logits；理论证明该更新规则是KL约束策略优化的精确闭式解。

Result: 在WebArena和Jericho上达到无训练方法SOTA；性能优于计算昂贵的微调方法（如WebRL），同时降低30倍以上货币成本。

Conclusion: JitRL为LLM智能体提供了高效、可扩展的持续学习新路径，兼顾性能、效率与实用性。

Abstract: While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.

</details>


### [436] [LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models](https://arxiv.org/abs/2601.18513)
*Kai Hu,Haoqi Hu,Matt Fredrikson*

Main category: cs.LG

TL;DR: 本文提出了LipNeXt，一种无约束、无卷积的1-Lipschitz认证鲁棒性架构，通过正交流形优化和空间移位模块实现高效、可扩展的确定性鲁棒保证，在CIFAR和ImageNet上均达到SOTA认证鲁棒精度。


<details>
  <summary>Details</summary>
Motivation: Lipschitz-based认证虽具高效、确定性优势，但在模型规模、训练效率和ImageNet性能方面难以扩展。

Method: 提出LipNeXt架构：采用正交流形上的参数更新（manifold optimization）、空间移位模块（Spatial Shift Module）替代卷积、1-Lipschitz β-Abs非线性、正交投影与L2空间池化，全程保持紧致Lipschitz常数控制。

Result: 在CIFAR-10/100和Tiny-ImageNet上达到SOTA清洁精度与认证鲁棒精度（CRA）；在ImageNet上可扩展至1–2B参数模型，ε=1时CRA较先前Lipschitz模型最高提升8%，并支持高效稳定的低精度训练。

Conclusion: Lipschitz-based认证方法可通过现代缩放范式（如大模型、结构简化）提升性能，同时不牺牲确定性与计算效率。

Abstract: Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \emph{LipNeXt}, the first \emph{constraint-free} and \emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $β$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\%$ at $\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency.

</details>


### [437] [Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning](https://arxiv.org/abs/2601.18521)
*Emna Boudabbous,Mohamed Karaa,Lokman Sboui,Julio Montecinos,Omar Alam*

Main category: cs.LG

TL;DR: 本文提出了一种面向城市级公交网络的延迟预测流水线，结合多尺度特征工程、自适应PCA降维与深度学习（特别是全局LSTM），在蒙特利尔STM数据上显著优于Transformer等模型，兼具高精度、低参数量和实时部署能力。


<details>
  <summary>Details</summary>
Motivation: 现有公交延迟预测系统多局限于少数线路、依赖人工特征、缺乏可扩展可复用的架构设计，难以支撑城市级实时运营与乘客信息服务需求。

Method: 构建了城市级预测流水线：1）基于H3地理网格与路线/路段/时间多维度组合生成1683个时空特征；2）采用Adaptive PCA压缩至83维（保留95%方差）；3）提出H3+拓扑混合聚类方法解决密集城区‘巨簇’问题，形成12个均衡路线簇；4）对比五种模型，选用带簇感知特征的全局LSTM。

Result: 在蒙特利尔STM六个月数据上，所提LSTM模型相较Transformer模型精度提升18–52%，参数量仅为后者的1/275；多层级（路段/行程/班次）走步验证与延迟分析证实其满足实时城市级部署要求。

Conclusion: 该框架具备强扩展性、低适配成本与高实用性，可迁移至其他公交网络，为智能公交实时调度与信息服务提供了可复用的技术范式。

Abstract: Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.
  We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the "giant cluster" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.
  We compare five model architectures on six months of bus operations from the Société de transport de Montréal (STM) network in Montréal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.

</details>


### [438] [From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale](https://arxiv.org/abs/2601.18524)
*Yongqi Jin,Yecheng Wang,Jun-jie Wang,Rong Zhu,Guolin Ke,Weinan E*

Main category: cs.LG

TL;DR: 本文提出一种半监督框架，利用数百万篇文献中提取的未标记NMR谱图（无需原子级标注）结合少量标注数据，显著提升化学位移预测精度、鲁棒性与泛化能力，并首次在大规模上建模溶剂效应。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法依赖有限且需人工标注原子归属的NMR数据集，严重制约模型性能与可扩展性。

Method: 将文献谱图的化学位移预测建模为排列不变的集合监督问题，证明在常见损失函数条件下最优二分匹配可简化为排序损失，从而支持稳定的大规模半监督训练；同时整合溶剂信息。

Result: 模型在精度、鲁棒性和跨更大更广分子数据集的泛化能力上显著超越当前最优方法，并首次实现了对常见NMR溶剂系统性效应的大规模建模。

Conclusion: 文献中挖掘的大规模未标注NMR谱图是训练高精度位移预测模型的有效实用数据源，凸显弱结构化文献数据在科学AI中的重要价值。

Abstract: Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.

</details>


### [439] [Closing the Modality Gap Aligns Group-Wise Semantics](https://arxiv.org/abs/2601.18525)
*Eleonora Grassucci,Giordano Cicchetti,Emanuele Frasca,Aurelio Uncini,Danilo Comminiello*

Main category: cs.LG

TL;DR: 本文揭示了CLIP等跨模态模型中存在的模态间隙（modality gap）对群体级任务（如聚类）影响显著，而对实例级任务（如检索）影响有限；为此提出一种新方法，可有效缩小该间隙，并在多模态设置中验证其对群体级任务性能的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP类方法虽能语义对齐多模态表征，但存在结构性不匹配（即模态间隙），其影响在实例级任务中不显著，作者旨在探究其在群体级任务中的作用并加以缓解。

Method: 提出一种新颖方法，在双模态设定下一致减小模态间隙，并可自然扩展至n模态情形。

Result: 实验证明，缩小模态间隙对传统实例级任务（如检索）仅带来边缘或不稳定提升，却显著提升群体级任务（如聚类）性能。

Conclusion: 模态间隙并非无关紧要，而是影响群体级语义分组任务性能的关键因素，应被重新重视。

Abstract: In multimodal learning, CLIP has been recognized as the \textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.

</details>


### [440] [Information Hidden in Gradients of Regression with Target Noise](https://arxiv.org/abs/2601.18546)
*Arash Jamshidi,Katsiaryna Haitsiukevich,Kai Puolamäki*

Main category: cs.LG

TL;DR: 本文提出了一种仅利用梯度信息来估计Hessian矩阵（在线性回归中等价于数据协方差Σ）的实用方法，核心是通过高斯噪声注入实现方差校准（目标噪声方差设为batch size n），从而在远离最优解处也能准确逼近Hessian，并提供了非渐近算子范数理论保证。


<details>
  <summary>Details</summary>
Motivation: 在许多现代机器学习场景中，二阶信息（如曲率或数据协方差）对优化、诊断和鲁棒性至关重要，但往往只能获取梯度，无法直接获得Hessian或协方差。

Method: 通过向输入注入高斯噪声并校准其方差（使总目标噪声方差等于batch size n），使得经验梯度协方差能紧密逼近Hessian；在sub-Gaussian输入下给出非渐近算子范数误差界，并证明无校准将导致Ω(1)量级误差。

Result: 实现了在远离最优解处仍能以O(n)噪声方差鲁棒恢复Σ（至尺度因子）；该方法被验证可用于预处理加速优化、对抗风险估计及分布式系统中的梯度-only训练。

Conclusion: 梯度本身蕴含足够二阶信息，只需恰当的噪声方差校准即可可靠提取，为无需显式二阶计算的实用算法提供了理论基础与简单可部署准则（'设目标噪声方差为n'）。

Abstract: Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $Σ$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $Ω(1)$ factor. The proposed method is practical (a "set target-noise variance to $n$" rule) and robust (variance $\mathcal{O}(n)$ suffices to recover $Σ$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.

</details>


### [441] [An Unsupervised Tensor-Based Domain Alignment](https://arxiv.org/abs/2601.18564)
*Chong Hyun Lee,Kibae Lee,Hyun Hee Yim*

Main category: cs.LG

TL;DR: 本文提出了一种基于张量的域对齐算法，通过在不变子空间中使用对齐矩阵来对齐源域和目标域张量，并在斜流形上进行迭代优化，同时引入方差保持正则项以提升鲁棒性与性能。


<details>
  <summary>Details</summary>
Motivation: 现有域对齐方法在流形约束（如Stiefel流形）下灵活性不足，且难以兼顾对齐效率与分类精度；需更适应性强、鲁棒性高的张量对齐框架。

Method: 设计张量域对齐算法，在斜流形（oblique manifold）上联合优化对齐矩阵与不变子空间，并加入保持源/目标张量方差的正则项。

Result: 实验表明该方法显著提升域对齐转换速度与分类准确率，优于当前最先进方法。

Conclusion: 所提算法兼具高效性与泛化能力，可统一多种张量域对齐方法，并在复杂域适应任务中展现出优越性能。

Abstract: We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.

</details>


### [442] [K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents](https://arxiv.org/abs/2601.18580)
*Vincenzo De Paola,Mirco Mutti,Riccardo Zamboni,Marcello Restelli*

Main category: cs.LG

TL;DR: K-Myriad 是一种可扩展的无监督并行强化学习方法，通过最大化多个策略联合诱导的状态熵，促进多样化探索，提升训练效率并发现异质解。


<details>
  <summary>Details</summary>
Motivation: 传统并行强化学习中多个worker使用相同采样分布，限制了探索多样性；本文旨在利用策略群体的差异化探索优势。

Method: 提出 K-Myriad 方法，通过优化一个策略群体，使其联合诱导的状态分布具有最大熵，从而鼓励多样化、专业化探索行为。

Result: 在高维连续控制任务的大规模并行实验中，K-Myriad 成功学习到一组显著不同的策略，验证了其在集体探索上的有效性。

Conclusion: K-Myriad 为并行强化学习提供了更鲁棒的初始化和新范式，兼顾训练效率与解的多样性。

Abstract: Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.

</details>


### [443] [Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning](https://arxiv.org/abs/2601.18586)
*Miguel Costa,Arthur Vandervoort,Carolin Schmidt,Morten W. Petersen,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 本文提出了一种结合综合评估模型（IAM）与强化学习（RL）的决策支持框架，用于在深度不确定性下学习城市交通系统应对气候变化（如暴雨内涝）的长期自适应投资路径，并在哥本哈根市案例中验证了其优于传统基准策略的有效性与可迁移性。


<details>
  <summary>Details</summary>
Motivation: 城市交通系统面临气候变化加剧的降雨等灾害风险，但基础设施投资具有长期性、序列性和跨部门复杂性，且存在深层不确定性，亟需能动态适应的决策支持方法。

Method: 将综合评估模型（IAM）与强化学习（RL）耦合：IAM整合IPCC气候情景、极端天气→灾害概率→基础设施影响→服务与社会成本的多层映射；RL在该模型中学习以投资/维护成本与规避损失为权衡目标的自适应政策。

Result: 在哥本哈根2024–2100年内涝适应案例中，所学策略生成协调的时空投资路径，在鲁棒性上显著优于‘不作为’和‘随机行动’等基线方法。

Conclusion: 该框架能有效支持复杂不确定环境下多阶段、跨部门的城市气候适应决策，具备向其他灾害类型和城市推广的潜力。

Abstract: Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.

</details>


### [444] [LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation](https://arxiv.org/abs/2601.18604)
*Zhiwei Zheng,Kevin Bryson*

Main category: cs.LG

TL;DR: 本文提出了LaCoGSEA，一种结合深度表示学习与稳健通路统计的无监督通路富集分析框架，通过自编码器捕获非线性转录组结构，并利用基因-潜在空间相关性生成无标签基因排序，从而提升癌症亚型聚类、生物学通路发现及跨数据鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有通路富集分析方法（如GSEA）依赖预定义表型标签，难以用于无监督场景；单样本方法仅捕捉线性关系且未显式建模基因-通路关联；而面向特征归因的XAI技术不适用于通路级无监督解释。

Method: 提出LaCoGSEA框架：采用自编码器学习非线性转录组流形；定义全局基因-潜在空间相关性作为差异表达代理，生成稠密无标签基因排序；结合稳健通路统计进行富集分析。

Result: LaCoGSEA在癌症亚型聚类性能上优于无监督基线；比线性降维和梯度类XAI方法在更高排序位置检出更多生物学意义通路；且在不同实验方案和数据规模下保持高鲁棒性与一致性。

Conclusion: LaCoGSEA实现了无监督通路富集分析的最先进性能，为无标签转录组数据的可解释深度学习提供了新范式。

Abstract: Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited.
  Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis.
  Availability and implementation: https://github.com/willyzzz/LaCoGSEA

</details>


### [445] [Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem](https://arxiv.org/abs/2601.18615)
*Ramiro Valdes Jara,Adam Meyers*

Main category: cs.LG

TL;DR: 本文提出了一种基于条件扩散模型的数据驱动方法，用于解决心电图成像（ECGI）中的逆问题，能够从噪声体表信号概率性地重建心脏表面电势，无需患者特异性几何建模，并在真实数据集上优于多种确定性深度学习基线。


<details>
  <summary>Details</summary>
Motivation: ECGI逆问题具有非唯一性和病态性，传统方法依赖患者特异性几何建模且仅给出单一确定解，难以刻画不确定性。

Method: 提出一种条件扩散框架，以噪声体表信号为条件，学习到心脏表面电势的概率映射；利用扩散模型的生成能力实现多解采样，且完全数据驱动、无需几何建模。

Result: 在真实ECGI数据集上，该扩散方法在重建精度上优于CNN、LSTM和Transformer等确定性深度学习基线模型。

Conclusion: 扩散模型能有效建模ECGI逆问题的不确定性，是一种有潜力的、鲁棒的无创心脏电生理成像新工具。

Abstract: This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.

</details>


### [446] [Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning](https://arxiv.org/abs/2601.18699)
*Olaf Yunus Laitinen Imanov*

Main category: cs.LG

TL;DR: 本文通过系统实验分析了大语言模型在顺序微调过程中灾难性遗忘的三种主要机制：注意力权重中的梯度干扰、中间层表征漂移以及损失曲面扁平化，并发现遗忘程度与任务相似性和梯度对齐指标密切相关。


<details>
  <summary>Details</summary>
Motivation: 尽管灾难性遗忘现象被广泛观察到，但其内在机制仍不清楚，本文旨在深入理解大语言模型在顺序微调中发生灾难性遗忘的机理。

Method: 通过对不同规模（109B至400B参数）的Transformer架构大语言模型，在多任务序列上进行系统性微调实验，结合梯度分析、表征变化追踪和损失曲面分析等方法，识别遗忘的关键机制。

Result: 发现三种主要遗忘机制：注意力权重中的梯度干扰、中间层表征漂移、损失曲面扁平化；遗忘程度与任务相似性高度相关（Pearson r = 0.87）；约15%–23%的注意力头严重受损，且底层更易受影响。

Conclusion: 本研究为持续学习系统中针对性缓解灾难性遗忘策略的设计提供了坚实的机制基础。

Abstract: Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.

</details>


### [447] [CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling](https://arxiv.org/abs/2601.18620)
*Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Ian Berlot-Attwell,Stéphane Aroca-Ouellette,Kaheer Suleman*

Main category: cs.LG

TL;DR: 本文提出了CASSANDRA，一种利用大语言模型（LLM）作为知识先验的神经符号化世界建模方法，用于在数据有限的情况下构建轻量级状态转移模型，提升现实商业场景中的规划能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界领域（如商业）语义丰富，需借助世界知识从有限数据中有效建模复杂动作效果和因果关系。

Method: CASSANDRA包含两部分：(1) 由LLM生成代码建模确定性特征；(2) 由LLM引导结构学习构建概率图模型以刻画随机变量间的因果关系。

Result: 在咖啡店模拟器和主题公园商业模拟器中，CASSANDRA在状态转移预测与规划任务上显著优于基线方法。

Conclusion: LLM可作为有效的知识先验，支撑轻量、可解释且高性能的神经符号化世界模型构建，适用于数据稀缺的现实规划任务。

Abstract: Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.

</details>


### [448] [Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models](https://arxiv.org/abs/2601.18734)
*Siyan Zhao,Zhihui Xie,Mengchen Liu,Jing Huang,Guan Pang,Feiyu Chen,Aditya Grover*

Main category: cs.LG

TL;DR: 本文提出了一种名为On-Policy Self-Distillation（OPSD）的新框架，利用单一大语言模型在不同上下文（有/无特权信息）下分别充当教师与学生，实现无需额外教师模型的高效推理知识蒸馏。


<details>
  <summary>Details</summary>
Motivation: 现有on-policy蒸馏依赖额外的大教师模型，且未充分利用推理数据集中的真实答案；本文受‘强模型可基于特权推理轨迹指导自身弱版本’启发，旨在消除对独立教师模型的依赖并提升数据利用效率。

Method: OPSD让同一模型在两种条件下运行：教师策略以验证过的推理轨迹等特权信息为条件，学生策略仅以问题为条件；训练目标是最小化学生自身采样轨迹上两策略的逐token分布差异。

Result: 在多个数学推理基准上验证了OPSD有效性，相比GRPO等强化学习方法提升4–8倍token效率，并优于传统off-policy蒸馏方法。

Conclusion: OPSD是一种高效、简洁的自蒸馏范式，通过单模型双角色设计缓解分布偏移、节省计算资源，为LLM推理能力压缩提供了新思路。

Abstract: Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.

</details>


### [449] [Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning](https://arxiv.org/abs/2601.18626)
*Yingxiao Huo,Satya Prakash Dash,Radu Stoican,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 本文提出了一种基于秩-1近似逆Fisher信息矩阵的高效可扩展自然策略优化方法，在保证收敛速度和样本复杂度的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 自然梯度在深度强化学习中具有快速收敛和协变权重更新的优点，但其计算依赖于每次迭代中Fisher信息矩阵（FIM）的求逆，计算代价过高。

Method: 提出一种利用秩-1近似来近似全逆FIM的自然策略优化技术，并从理论上分析其收敛性与样本复杂度。

Result: 在多种环境中实验表明，该方法性能优于标准的Actor-Critic和信任域基线方法。

Conclusion: 秩-1近似逆FIM在特定条件下不仅比策略梯度收敛更快，且样本复杂度可与随机策略梯度方法相当，是一种高效可行的自然策略优化方案。

Abstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.

</details>


### [450] [Physics-Informed Uncertainty Enables Reliable AI-driven Design](https://arxiv.org/abs/2601.18638)
*Tingkai Xue,Chin Chun Ooi,Yang Jiang,Luu Trung Pham Duong,Pao-Hsiung Chiu,Weijiang Zhao,Nagarajan Raghavan,My Ha Dao*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理规律违背程度的‘物理信息不确定性’新范式，用于频率选择表面的逆向设计，显著提升了优化成功率并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于深度学习的代理模型优化方法缺乏不确定性量化，导致在数据稀疏区域预测错误、优化性能下降。

Method: 提出‘物理信息不确定性’：以模型预测违背物理定律的程度作为廉价且有效的预测不确定性代理；将其集成到多保真度、不确定性感知的优化工作流中。

Result: 在20–30 GHz频段设计复杂频率选择表面时，高性能解的成功率从<10%提升至>50%，计算成本比纯高保真求解器降低一个数量级。

Conclusion: 在高维物理系统逆向设计中，不确定性量化不可或缺；物理信息不确定性是替代传统不确定性量化方法的有效新途径，为自主科学发现系统奠定基础。

Abstract: Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs.

</details>


### [451] [Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values](https://arxiv.org/abs/2601.18760)
*Henry Bell,Lara Neubauer da Costa Schertel,Bochu Ding,Brandon Fain*

Main category: cs.LG

TL;DR: 本文提出了一种名为Grounded Constitutional AI (GCAI)的统一框架，用于生成既反映用户对AI的一般期望（一般原则），又体现其交互时偏好（情境原则）的宪法式对齐原则；通过结合人类偏好标注中的理由和用户关于AI的价值陈述，GCAI生成的宪法在人类评估中优于仅基于偏好的ICAI方法，且被认为更具道德基础、连贯性和多元性。


<details>
  <summary>Details</summary>
Motivation: 现有宪法式对齐方法（如ICAI）缺乏对广泛利益相关者价值观的公平整合机制，难以兼顾用户的一般价值期待与具体交互情境下的偏好。

Method: 扩展逆宪法AI（ICAI）方法，利用人类偏好标注中的‘理由’生成情境原则；同时从用户关于AI的‘价值陈述’中提取一般原则；将二者融合构建GCAI宪法。

Result: GCAI生成的宪法在人类评估中显著优于ICAI宪法，无论是在个人偏好还是广泛适用性上；且被评价为更道德、更连贯、更多元。

Conclusion: GCAI提供了一种更公平、更 grounded 的宪法生成范式，能更好融合多源人类价值观，提升LLM对齐的合理性与可接受性。

Abstract: A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.

</details>


### [452] [TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning](https://arxiv.org/abs/2601.18640)
*Zhiwei Zheng,Kevin Bryson*

Main category: cs.LG

TL;DR: 本文提出TwinPurify，一种基于Barlow Twins自监督学习的表示学习框架，用于从批量转录组数据中提取肿瘤特异性信号，无需外部参考或细胞类型解卷积，显著提升下游生物发现与临床预测性能。


<details>
  <summary>Details</summary>
Motivation: 大批量患者队列仍依赖易受肿瘤纯度变异干扰的批量转录组数据，现有解卷积方法在真实队列中泛化能力差。

Method: 提出TwinPurify框架，采用Barlow Twins自监督目标，利用同一队列中配对癌旁组织作为‘背景’引导，学习连续高维肿瘤嵌入，实现肿瘤特异性信号解耦。

Result: 在多个大型癌症队列（RNA-seq和微阵列平台）上，TwinPurify优于传统自编码器等基线，在恢复肿瘤内在及免疫信号、分子分型/分级分类、生存模型一致性及通路活性解析方面表现更优。

Conclusion: TwinPurify为批量转录组数据去污染提供了可迁移的通用框架，拓展了现有临床数据在分子机制研究与转化应用中的价值。

Abstract: Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.
  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as "background" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.
  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.

</details>


### [453] [PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation](https://arxiv.org/abs/2601.18777)
*Abhishek Divekar,Anirban Majumder*

Main category: cs.LG

TL;DR: 本文提出PRECISE框架，结合少量人工标注与大语言模型（LLM）判断，利用扩展的Prediction-Powered Inference（PPI）方法，高效、低方差地估计检索系统指标（如Precision@K），显著降低对人工标注的依赖，并校正LLM固有偏差。


<details>
  <summary>Details</summary>
Motivation: 传统搜索、排序和RAG系统评估依赖大量人工相关性标注，成本高；而直接用LLM作自动裁判又受其固有偏差影响，难以准确估计指标。

Method: 提出PRECISE统计框架，扩展Prediction-Powered Inference（PPI），支持子实例级（query-document level）标注；通过重构指标积分空间，将计算复杂度从O(2^|C|)降至O(2^K)；仅需约100个人工标注查询和1万未标注样本。

Result: 在多个主流检索数据集上验证：PRECISE显著降低Precision@K等关键业务指标估计的方差，并在低资源场景下有效校正LLM偏差。

Conclusion: PRECISE是一种高效、可靠、低标注成本的LLM辅助评估新范式，为搜索与RAG系统提供可信赖的自动化指标估计方案。

Abstract: Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.

</details>


### [454] [FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning](https://arxiv.org/abs/2601.18650)
*Liheng Yu,Zhe Zhao,Yuxuan Wang,Pengkun Wang,Binwu Wang,Yang Wang*

Main category: cs.LG

TL;DR: 本文首次研究了在长尾分布下的机器遗忘问题，提出了FaLW方法，通过实例级动态损失重加权来解决异质性和偏斜性遗忘偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法主要在平衡的遗忘数据集上评估，忽略了现实中常见的长尾分布场景（如用户活动记录），导致遗忘效果不佳。

Method: 提出FaLW方法，一种即插即用、实例级的动态损失重加权策略；通过比较每个样本预测概率与同类未见数据分布来评估其遗忘状态，并引入遗忘感知的重加权机制和平衡因子自适应调整遗忘强度。

Result: 大量实验表明FaLW在长尾遗忘场景下性能显著优于现有方法。

Conclusion: FaLW有效缓解了长尾分布下机器遗忘中的异质性与偏斜性偏差问题，为符合隐私法规（如被遗忘权）提供了更实用的解决方案。

Abstract: Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \textit{Heterogeneous Unlearning Deviation} and \textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \textbf{Supplementary Material}.

</details>


### [455] [Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability](https://arxiv.org/abs/2601.18778)
*Shobhita Sundaram,John Quan,Ariel Kwiatkowski,Kartik Ahuja,Yann Ollivier,Julia Kempe*

Main category: cs.LG

TL;DR: 本文提出SOAR框架，通过元强化学习让大语言模型自动生成教学课程，从而在稀疏奖励下实现自我提升，突破推理瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在初始成功率低的数据集上容易陷入学习停滞，缺乏足够的训练信号；作者探究预训练大语言模型能否利用潜在知识为自身无法解决的问题生成自动化课程。

Method: 设计SOAR自改进框架：一个教师模型为学生模型生成合成问题，教师的奖励取决于学生在少量难题上的性能提升；奖励基于实际测量的学生进步（而非内在代理奖励），属于双层元强化学习。

Result: 在数学基准最难子集（初始成功率为0/128）上验证：1）双层元RL可激活模型生成有效阶梯题目的潜在能力；2）基于实测进步的奖励优于内在奖励，避免不稳定与多样性崩溃；3）生成题目的结构质量与表述清晰度比答案正确性更关键。

Conclusion: 模型无需先掌握难题解法，即可生成有助于学习的阶梯题目；SOAR为摆脱推理瓶颈提供了无需额外人工标注数据的原理性路径。

Abstract: Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.

</details>


### [456] [A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2601.18672)
*Spyros Rigas,Thanasis Papaioannou,Panagiotis Trakadas,Georgios Alexandridis*

Main category: cs.LG

TL;DR: 本文提出了一种基于曲率的结点分配新策略，将网格自适应建模为重要性密度函数（IDF）驱动的密度估计问题，显著提升了Kolmogorov-Arnold网络（KANs）在函数拟合、物理方程求解等任务中的精度。


<details>
  <summary>Details</summary>
Motivation: 现有KAN的网格自适应策略仅依赖输入数据密度，忽视目标函数的几何复杂性和训练过程中的动态信息。

Method: 提出广义框架，将结点分配建模为由重要性密度函数（IDF）控制的密度估计任务，并设计基于曲率的自适应策略。

Result: 在合成函数拟合、Feynman数据集子集回归和Helmholtz偏微分方程求解上，相对误差分别平均降低25.3%、9.4%和23.3%，Wilcoxon检验证实其统计显著性。

Conclusion: 曲率驱动的自适应方法是一种鲁棒且计算高效的KAN训练替代方案。

Abstract: Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training.

</details>


### [457] [POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration](https://arxiv.org/abs/2601.18779)
*Yuxiao Qu,Amrith Setlur,Virginia Smith,Ruslan Salakhutdinov,Aviral Kumar*

Main category: cs.LG

TL;DR: 本文提出Privileged On-Policy Exploration (POPE)，利用人类或oracle解作为特权信息引导强化学习在难题上的探索，显著提升大语言模型在困难推理任务上的求解能力。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在难题上难以获得正向奖励，导致无学习信号；传统探索改进策略（如熵奖励、重要性采样裁剪）效果有限甚至破坏训练；混合难易问题训练会因ray interference阻碍难题进展。

Method: POPE方法将oracle解的前缀作为提示加入难题输入，使RL在引导下生成可获正奖励的轨迹；该引导行为通过指令遵循与推理的协同作用迁移到原始无引导问题上。

Result: POPE显著扩大了可解问题集，在多个挑战性推理基准上大幅提升性能。

Conclusion: 利用特权信息进行有引导的on-policy探索是解决LLM推理中稀疏奖励问题的有效新范式，优于传统探索增强和简单迁移方法。

Abstract: Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.

</details>


### [458] [Learning temporal embeddings from electronic health records of chronic kidney disease patients](https://arxiv.org/abs/2601.18675)
*Aditya Kumar,Mario A. Cypko,Oliver Amft*

Main category: cs.LG

TL;DR: 本文研究了在纵向电子健康记录上训练的时间嵌入模型能否在不牺牲预测性能的前提下学习到具有临床意义的表征，并比较了三种循环神经网络架构（LSTM、注意力增强LSTM和时序感知LSTM）在慢性肾病（CKD）患者建模中的表现；结果表明T-LSTM生成的嵌入结构更优，且以嵌入为中间步骤的模型在ICU内死亡率预测任务中优于端到端模型。


<details>
  <summary>Details</summary>
Motivation: 现有临床预测模型多为单任务优化，缺乏跨任务泛化能力；而模型引导医学需要能捕捉疾病动态、透明且任务无关的表征。因此，本文旨在探索如何通过时间嵌入模型学习高质量、可迁移的临床表征。

Method: 基于MIMIC-IV数据集，针对慢性肾病（CKD）患者，构建并对比三种循环架构（vanilla LSTM、attention-augmented LSTM、time-aware LSTM/T-LSTM），分别训练为嵌入模型和端到端预测模型；通过CKD分期聚类（Davies-Bouldin Index）和ICU内死亡率预测评估嵌入质量与预测性能。

Result: T-LSTM在CKD分期聚类中表现最优（DBI=9.91，分类准确率0.74），优于vanilla LSTM（DBI=15.85，准确率0.63）和attention-augmented LSTM（DBI=20.72，准确率0.67）；在ICU死亡率预测中，嵌入模型准确率（0.82–0.83）显著高于端到端模型（0.72–0.75）。

Conclusion: 时间感知的循环架构（如T-LSTM）能学习更具临床意义和结构化的患者表征；将嵌入学习作为中间步骤比端到端预测更有效，支持其在模型引导医学中的应用潜力。

Abstract: We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.

</details>


### [459] [Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes](https://arxiv.org/abs/2601.18795)
*Amrith Setlur,Zijian Wang,Andrew Cohen,Paria Rashidinejad,Sang Michael Xie*

Main category: cs.LG

TL;DR: 本文提出PrefixRL方法，通过利用历史采样数据（off-policy traces）的前缀作为条件，在其基础上进行on-policy强化学习，从而提升大语言模型在困难推理任务上的训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 典型强化学习方法在处理困难问题时存在计算浪费、策略梯度消失和学习停滞等问题，亟需更高效的RL训练范式。

Method: PrefixRL方法利用成功的历史off-policy轨迹前缀作为条件，仅对后半部分进行on-policy RL优化；通过调节前缀长度控制任务难度，并从理论上证明其目标函数与标准RL一致且更具样本效率。

Result: 实验表明，PrefixRL比最强基线（SFT+RL）快2倍达到相同奖励，并将最终奖励提升3倍；还观察到‘反向泛化’现象（仅训练带前缀任务却提升无前缀任务表现），且效果可迁移至未见基准并兼容不同模型族生成的离策略数据。

Conclusion: PrefixRL是一种高效、稳定、灵活的LLM推理强化学习新范式，能显著提升困难问题的学习效率与泛化能力。

Abstract: Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.

</details>


### [460] [Quasi Monte Carlo methods enable extremely low-dimensional deep generative models](https://arxiv.org/abs/2601.18676)
*Miles Martinez,Alex H. Williams*

Main category: cs.LG

TL;DR: 本文提出了准蒙特卡洛潜在变量模型（QLVMs），一种专为高维数据寻找极低维且可解释嵌入的深度生成模型，通过准蒙特卡洛积分直接近似边缘似然，在1-3维潜空间中显著优于VAE和IWAE，但计算开销大、难以生成复杂细节。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如VAE）依赖学习编码器和变分下界，难以保证低维潜空间的可解释性和分析可靠性；需一种更直接、透明、适合低维嵌入建模的方法。

Method: 提出准蒙特卡洛潜在变量模型（QLVMs），摒弃编码器和变分推断，直接使用随机化准蒙特卡洛积分估计边缘似然，优化极低维（1–3维）深度潜变量模型。

Result: 在多个数据集上，QLVMs在相同潜维数下持续超越VAE和IWAE；所得低维嵌入支持可视化、非参数密度估计、聚类与测地线计算等可验证的后验分析。

Conclusion: QLVMs虽计算密集且难建模复杂细节，但在强调可解释性与潜空间分析的应用中具有独特优势，为低维深度生成建模提供了新范式。

Abstract: This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.

</details>


### [461] [Counterfactual Explanations on Robust Perceptual Geodesics](https://arxiv.org/abs/2601.18678)
*Eslam Zaher,Maciej Trzaskowski,Quan Nguyen,Fred Roosta*

Main category: cs.LG

TL;DR: 本文提出Perceptual Counterfactual Geodesics（PCG）方法，通过基于鲁棒视觉特征构建的感知黎曼度量下的测地线生成反事实解释，从而实现语义合理、流形内、平滑的预测变化。


<details>
  <summary>Details</summary>
Motivation: 现有潜在空间优化方法在生成反事实解释时因距离度量选择不当，易导致语义漂移、流形外伪影或对抗性坍缩，缺乏与人类感知对齐的几何结构。

Method: PCG方法利用鲁棒视觉特征诱导出感知一致的黎曼度量，并在此度量下沿测地线搜索最小语义扰动的反事实样本。

Result: 在三个视觉数据集上的实验表明，PCG优于现有基线方法，并能揭示标准度量下隐藏的模型失败模式。

Conclusion: PCG通过引入符合人类感知的黎曼几何，有效提升了反事实解释的语义合理性与可解释性，解决了传统方法中几何失配导致的诸多问题。

Abstract: Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.

</details>


### [462] [ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule](https://arxiv.org/abs/2601.18681)
*Yilie Huang,Wenpin Tang,Xunyu Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种自适应重参数化时间（ART）方法，用于优化基于分数的扩散模型的时间离散化，通过控制重参数化时间变量的时钟速度来实现不均匀的时间步长，从而最小化欧拉离散化误差；进一步提出了ART-RL，将时间变换建模为连续时间强化学习问题，并证明其可恢复最优ART调度；实验表明ART-RL在多个数据集上显著提升了FID指标。


<details>
  <summary>Details</summary>
Motivation: 均匀或手工设计的时间网格在给定步数预算下可能次优，需更灵活的时间离散策略以降低离散化误差。

Method: 提出自适应重参数化时间（ART）框架，将时间变换建模为连续时间强化学习（ART-RL），采用高斯策略，并通过actor-critic方式进行数据驱动学习。

Result: 在CIFAR-10上基于EDM流程显著提升FID，且无需重训练即可迁移到AFHQv2、FFHQ和ImageNet。

Conclusion: ART-RL提供了一种理论严谨且实用的数据驱动方式，优化扩散模型采样过程的时间离散化，兼顾精度与泛化性。

Abstract: We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.

</details>


### [463] [Explainability Methods for Hardware Trojan Detection: A Systematic Comparison](https://arxiv.org/abs/2601.18696)
*Paul Whitten,Francis Wolff,Chris Papachristou*

Main category: cs.LG

TL;DR: 本文比较了三种可解释性方法在门级硬件木马检测中的应用，包括基于领域知识的属性分析、基于案例的推理和模型无关的特征归因方法，并评估了它们在可解释性和性能上的优劣。


<details>
  <summary>Details</summary>
Motivation: 硬件木马检测需要准确识别与可解释性高的结果，以便安全工程师验证并采取行动。

Method: 比较三种可解释性方法：(1) 基于31个电路特定特征（如门扇入模式、触发器距离、I/O连接性）的领域感知属性分析；(2) 基于k近邻的案例推理；(3) 模型无关的特征归因（LIME、SHAP、梯度法）。使用XGBoost进行分类，并在Trust-Hub基准上评估。

Result: 属性分析提供电路概念层面的解释（如'输出附近高扇入复杂度可能表示触发器'）；案例推理达到97.4%预测与训练样本一致性；LIME/SHAP特征归因高度相关（r=0.94），但缺乏电路语境；XGBoost实现46.15%精度与52.17%召回率，精度较先前工作提升9倍，误报率从5.6%降至0.25%；梯度法比SHAP快481倍但解释性更弱。

Conclusion: 属性分析和案例推理相比通用特征排序方法，在领域对齐与先例可解释性方面更具优势，对XAI在安全实践中的部署具有重要启示。

Abstract: Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).
  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like "high fanin complexity near outputs indicates potential triggers." Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.
  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.
  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.

</details>


### [464] [From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic](https://arxiv.org/abs/2601.18702)
*Hansheng Ren*

Main category: cs.LG

TL;DR: 本文提出'精确性假说'，认为通用人工智能（AGI）尤其是高阶因果推理，需要任意精度算术的计算基础；为解决当前LLM因浮点误差导致的幻觉与逻辑不一致问题，作者设计了基于有理数运算（ℚ）的Halo架构及精确推理单元（EIU），并在Huginn-0125原型上验证其零数值发散特性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习范式依赖低精度浮点运算（如BF16），导致大语言模型出现幻觉和逻辑不一致，作者认为这是IEEE 754浮点近似误差在深层组合函数中累积所致，亟需更高数值保真度的计算基础以支撑系统2型AGI的逻辑确定性。

Method: 提出基于有理数域（ℚ）的Halo架构，包含新型精确推理单元（EIU），摒弃浮点运算，实现任意精度算术；在Huginn-0125硬件原型上开展对比实验，评估其在混沌系统中的数值稳定性。

Result: Halo架构在600B参数规模下实现无限期零数值发散，而同等规模BF16基线模型在混沌系统中迅速崩溃；实证表明有理数精确运算可彻底消除由浮点误差引发的逻辑不确定性。

Conclusion: 精确算术（而非统计相关性）是实现高阶因果推理与系统2型AGI的必要前提；数值精确性应成为AGI基础设施的核心设计原则，而非仅追求计算吞吐量。

Abstract: Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the "hallucinations" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.

</details>


### [465] [SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model](https://arxiv.org/abs/2601.18707)
*Jan Hagnberger,Mathias Niepert*

Main category: cs.LG

TL;DR: SMART是一种无需仿真网格的神经代理模型，仅使用几何点云表示即可预测任意查询位置的物理量，通过跨层交互联合更新几何特征和物理场，在工业级仿真中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的代理模型虽能提高物理仿真效率，但依赖计算成本高昂的仿真网格；而无需网格的方法通常误差较高。因此，需要一种既能避免网格生成开销、又能保持高精度的替代方案。

Method: 提出SMART模型：以几何点云和仿真参数为输入，编码至共享潜在空间；通过物理解码器对编码器中间潜在表示进行注意力机制建模，实现空间查询到物理量的映射，并利用跨层交互联合优化几何特征与物理场。

Result: SMART在多个实验中表现优于或媲美依赖仿真网格的现有方法，验证了其在工业级复杂几何仿真中的有效性与实用性。

Conclusion: SMART成功实现了不依赖仿真网格的高精度物理量预测，为复杂几何下的高效仿真提供了新范式。

Abstract: Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.

</details>


### [466] [Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data](https://arxiv.org/abs/2601.18728)
*Willem Diepeveen,Oscar Leong*

Main category: cs.LG

TL;DR: 本文提出Riemannian AmbientFlow框架，从带噪或线性退化观测中联合学习生成模型与非线性数据流形结构，结合变分推断与数据驱动的黎曼几何，提供理论保证与逆问题应用。


<details>
  <summary>Details</summary>
Motivation: 在科学与成像应用中，常仅有带噪或退化观测，缺乏干净样本；同时，提取数据内在的流形等潜在结构对下游分析至关重要。

Method: 基于AmbientFlow的变分推断框架，引入由归一化流诱导的数据驱动黎曼几何，利用拉回度量与黎曼自编码器提取流形结构，并施加几何正则化以保障理论性质。

Result: 理论证明在适当几何正则化与测量条件下，模型能以可控误差恢复真实数据分布，并给出光滑、双利普希茨的流形参数化；所得平滑解码器可作为具恢复保证的生成先验用于逆问题。

Conclusion: Riemannian AmbientFlow实现了从退化观测中端到端学习生成模型与流形几何，兼具理论严谨性与实际有效性，已在合成低维流形和MNIST上验证。

Abstract: Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.

</details>


### [467] [Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift](https://arxiv.org/abs/2601.18736)
*Jake Lyon,Ehsan Saeedizade,Shamik Sengupta*

Main category: cs.LG

TL;DR: 本研究评估了四种监督学习模型（随机森林、LightGBM、逻辑回归和多层感知机）在IoT-23数据集上的物联网恶意软件检测与分类性能，发现基于树的模型在小样本和时序演化场景下表现更优，强调需部署轻量自适应模型以应对真实物联网安全挑战。


<details>
  <summary>Details</summary>
Motivation: 物联网设备资源受限、物理防护弱、网络异构动态，易受攻击；亟需轻量且有效的机器学习方法实现自动化恶意软件检测。

Method: 采用随机森林、LightGBM、逻辑回归和多层感知机四种监督学习模型，在IoT-23数据集上开展二分类与多分类任务实验，评估其对训练数据量的敏感性及时间鲁棒性（模拟威胁演化）。

Result: 树模型（尤其Random Forest和LightGBM）在少量训练数据下仍保持高准确率与泛化能力；但所有模型随时间推移因恶意软件多样性增加而性能下降。

Conclusion: 面向物联网安全的机器学习方案必须兼顾轻量化与自适应性，树模型更具部署优势，但需持续更新以应对动态威胁环境。

Abstract: The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments.

</details>


### [468] [Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback](https://arxiv.org/abs/2601.18751)
*Seyed Amir Hosseini,Maryam Abdolali,Amirhosein Tavakkoli,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.LG

TL;DR: 本文提出TriTrust-PBRL（TTP）框架，通过联合学习共享奖励模型与专家特定信任参数，自动识别并翻转对抗性标注者的错误偏好，从而在多专家异构偏好数据下实现鲁棒的偏好强化学习。


<details>
  <summary>Details</summary>
Motivation: 现实中的偏好数据来自异质标注者（准确、噪声、对抗性），而现有PBRL方法无法有效应对系统性对抗性标注者。

Method: 提出TTP框架，联合优化共享奖励模型和专家信任参数；信任参数在梯度优化中自然演化为正（信任）、近零（忽略）或负（翻转），从而自动校正对抗性偏好；提供可识别性理论保证与梯度分析。

Result: 在MetaWorld与DM Control等四个领域、多种污染场景下，TTP在对抗性污染下保持近oracle性能，显著优于现有PBRL方法；能从混合可靠/对抗专家池中成功学习，仅需专家ID索引，兼容现有PBRL流程。

Conclusion: TTP是一种统一、鲁棒且无需额外专家特征的多专家PBRL新范式，能自动分离并利用异质偏好信号，尤其适用于存在系统性对抗标注者的实际场景。

Abstract: Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.

</details>


### [469] [HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs](https://arxiv.org/abs/2601.18753)
*Xinyue Zeng,Junhong Lin,Yujun Yan,Feng Guo,Liang Shi,Jun Wu,Dawei Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种统一的理论框架——幻觉风险界（Hallucination Risk Bound），将大语言模型（LLM）的幻觉风险分解为数据驱动和推理驱动两部分，并基于神经正切核（NTK）设计了检测方法HalluGuard，在多个基准和模型上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM幻觉检测方法通常只针对单一幻觉来源（数据或推理），且依赖任务特定启发式，泛化能力差，难以应对高风险领域中的复杂幻觉问题。

Method: 提出幻觉风险界理论框架，形式化分解幻觉风险；基于NTK几何与表征特性，构建统一评分指标HalluGuard，联合检测两类幻觉。

Result: 在10个基准、11个基线方法和9个主流LLM骨干网络上验证，HalluGuard持续达到SOTA检测性能。

Conclusion: HalluGuard提供了一种原理清晰、通用性强的LLM幻觉检测新范式，为提升高风险场景下LLM可靠性提供了可解释、可扩展的理论与工具支撑。

Abstract: The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.

</details>


### [470] [Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic](https://arxiv.org/abs/2601.18783)
*Deepthi Pathare,Leo Laine,Morteza Haghir Chehreghani*

Main category: cs.LG

TL;DR: 本文提出了一种基于近端策略优化（PPO）的多目标强化学习框架，用于重型卡车在高速公路上的战术决策，能学习连续的帕累托最优策略集，显式刻画安全、能耗效率与时间效率三者间的权衡关系，并支持无需重训练的策略平滑切换。


<details>
  <summary>Details</summary>
Motivation: 传统标量奖励函数难以清晰表达安全、效率与运营成本等多目标间的内在权衡关系，限制了重型车辆自主决策的灵活性与可解释性。

Method: 采用基于PPO的多目标强化学习方法，在可扩展的卡车战术决策仿真平台上训练，直接优化三个冲突目标（安全性、能量效率、时间效率），生成连续的帕累托最优策略集。

Result: 成功学习到光滑、可解释的帕累托前沿，实现了安全（碰撞率与任务完成率）、能量效率（能耗成本）和时间效率（驾驶员成本）三目标间的显式权衡；支持不同策略间的无缝切换。

Conclusion: 该框架为自动驾驶卡车提供了鲁棒、自适应且可灵活配置的决策能力，克服了单标量奖励在多目标权衡中的局限性。

Abstract: Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [471] [Online parameter estimation for the Crazyflie quadcopter through an EM algorithm](https://arxiv.org/abs/2601.17009)
*Yanhua Zhao*

Main category: cs.AI

TL;DR: 本文研究了随机噪声对四旋翼无人机系统的影响，并采用扩展卡尔曼滤波进行状态估计，基于随机微分方程系统设计线性二次高斯控制器，并利用期望最大化算法进行参数估计，比较了离线与在线参数估计的收敛性。


<details>
  <summary>Details</summary>
Motivation: 地震等灾害导致基础设施损毁，人员难以进入灾区，而无人机可抵达人类无法到达的区域，因此需提升其在噪声环境下的稳定性与控制性能。

Method: 在四旋翼无人机系统中引入随机噪声，使用扩展卡尔曼滤波（EKF）估计状态；基于随机微分方程（SDE）构建模型，设计线性二次高斯（LQG）控制器；采用期望最大化（EM）算法分别进行离线和在线参数估计。

Result: 在线参数估计相比离线估计具有略大的收敛值范围，表明其在动态环境中的鲁棒性更强。

Conclusion: 该方法提升了四旋翼无人机在含噪传感器观测下的建模与控制能力，为灾害响应等实际应用提供了更可靠的参数估计与控制框架。

Abstract: Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.

</details>


### [472] [Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability](https://arxiv.org/abs/2601.17168)
*Judy Zhu,Dhari Gandhi,Himanshu Joshi,Ahmad Rezaie Mianroodi,Sedef Akinli Kocak,Dhanesh Ramachandran*

Main category: cs.AI

TL;DR: 本文探讨了智能体系统（Agentic systems）中可解释性与可解释性技术的现状、局限性及未来方向，强调需为智能体系统专门设计可解释性方法以保障其安全与问责。


<details>
  <summary>Details</summary>
Motivation: 智能体系统具有多步规划和环境交互能力，其动态性、决策累积性和上下文依赖性给传统可解释性方法带来挑战，亟需面向智能体生命周期（目标形成、环境交互、结果评估）设计新型可解释性机制。

Method: 评估现有可解释性方法在智能体系统中的适用性与局限性，识别其在揭示智能体决策过程方面的不足，并提出面向智能体系统全生命周期的可解释性技术发展路径。

Result: 发现当前主要为静态模型设计的可解释性技术难以应对智能体系统的时序性、决策累积性与上下文敏感性；明确了在目标设定、环境交互和结果评估等关键阶段嵌入可解释性与监督机制的必要性。

Conclusion: 必须将可解释性与可解释性设计内置于智能体系统架构中，推动专用可解释性技术的发展，以确保智能体AI的安全、透明与可问责部署。

Abstract: Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.

</details>


### [473] [Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction](https://arxiv.org/abs/2601.17188)
*Swapn Shah,Wlodek Zadrozny*

Main category: cs.AI

TL;DR: 本文通过三个实验验证了Domingos提出的张量逻辑（Tensor Logic）框架，将符号推理与神经网络统一：1）证明递归Datalog规则与迭代张量收缩等价；2）在嵌入空间中实现可学习的零样本组合推理；3）在FB15k-237上验证关系矩阵叠加构造的有效性，提升多跳推理性能。


<details>
  <summary>Details</summary>
Motivation: 解决符号系统（可靠、可解释但不可扩展）与神经网络（可学习但不透明）之间的根本矛盾，寻求二者统一的理论与实践路径。

Method: 基于Domingos提出的张量逻辑框架，将逻辑规则映射为张量运算（特别是Einstein求和与矩阵乘法），开展三项实证实验：（1）用张量收缩计算圣经家谱图的传递闭包；（2）训练含可学习变换矩阵的神经网络进行零样本组合推理；（3）在FB15k-237上采用关系矩阵R_r = E⊤ A_r E形式，评估标准链接预测与去直接边的组合推理任务。

Result: （1）家谱图传递闭包在74次迭代后收敛，发现33945条祖先关系；（2）成功实现零样本组合推理；（3）在FB15k-237上标准链接预测MRR达0.3068，组合推理MRR达0.3346，证实矩阵组合支持无需直接监督的多跳推理。

Conclusion: 张量逻辑不仅具有数学一致性，而且在真实知识图谱任务中展现出可扩展、可学习、可解释的统一推理能力，为神经符号AI提供了可行且有效的实现范式。

Abstract: The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.

</details>


### [474] [High-Fidelity Longitudinal Patient Simulation Using Real-World Data](https://arxiv.org/abs/2601.17310)
*Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe*

Main category: cs.AI

TL;DR: 本文提出了一种基于海量真实临床记录的生成式模拟器模型，用于合成高保真度的患者未来病程轨迹，在事件发生率、检验结果和时间动态等方面均与真实数据高度一致。


<details>
  <summary>Details</summary>
Motivation: 模拟患者病程具有巨大潜力，但受复杂生物和社会文化因素影响，建模困难；而真实世界临床数据（如电子健康档案）尚未被充分挖掘利用。

Method: 开发了一个生成式模拟器模型，以患者历史记录为输入，合成细粒度、真实的未来病程轨迹；模型在超过2亿条临床记录上进行预训练。

Result: 模型生成的未来病程在事件发生率、实验室检查结果和时间动态上与真实患者数据高度匹配；对未来事件概率的估计准确，观测值与期望值比值稳定接近1.0。

Conclusion: 真实世界临床数据具有巨大未开发价值，该工作提供了一种可扩展的临床照护‘硅基’（in silico）建模新框架。

Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.

</details>


### [475] [Phase Transition for Budgeted Multi-Agent Synergy](https://arxiv.org/abs/2601.17311)
*Bang Liu,Linglong Kong,Jian Pei*

Main category: cs.AI

TL;DR: 本文提出了一种最小且可校准的理论，用于预测多智能体系统在固定推理预算下的三种行为模式（提升、饱和或崩溃），其核心基于三个现实约束：有限上下文窗口、有损的智能体间通信和相似智能体间的共享失败，并通过理论建模与实验验证揭示了多智能体协同性能的相变规律与设计权衡。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统虽有望提升可靠性，但在固定推理预算下常出现性能提升、饱和甚至下降的现象；现有工作缺乏统一理论解释这些现象背后的机制。

Method: 构建一个融合上下文窗口W、消息保真度曲线γ(m)、有效共享错误相关性ρ及计算-性能缩放指数β的理论框架；针对二元任务与多数投票聚合，推导深度b叉树中带相关输入和有损通信下的相变判据α_ρ；进一步导出组织指数s，给出预算化协同增益条件（s>β）及显式计算分配规则；引入混合深度刻画饱和，并设计保守剪裁预测器；还通过连续性能预热分析星型、链式与树形结构的风险函数。

Result: 证明了存在由单一标量α_ρ决定的尖锐相变；导出了预算协同增益发生的充要条件（s>β）及对应闭式计算分配策略；提出了混合深度表征饱和行为，并构造了跨增长与饱和阶段仍保持准确的保守预测器；给出了星/链/树结构的闭式风险表达，显式揭示相关性与通信导致的性能下限；在合成仿真中验证了相变边界，并成功解释了近期大模型代理系统缩放实验中的主要瓶颈。

Conclusion: 多智能体系统的性能并非随规模单调增长，而受制于上下文、通信与依赖三重约束；本文理论为代理架构设计提供了可解释、可预测、可校准的定量指导，揭示了‘何时组队更优’以及‘如何最优组队’的根本规律。

Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.

</details>


### [476] [AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning](https://arxiv.org/abs/2601.18631)
*Mingyang Song,Haoyu Sun,Jiawei Gu,Linjie Li,Luxin Xu,Ranjay Krishna,Yu Cheng*

Main category: cs.AI

TL;DR: 本文提出AdaReasoner，一种通过强化学习和自适应机制学习通用工具使用技能的多模态大模型，无需显式监督即可自主选择、组合和调整工具使用，显著提升视觉推理性能。


<details>
  <summary>Details</summary>
Motivation: 人类在面对超出自身能力的问题时依赖工具，因此让多模态大语言模型（MLLMs）具备自主、灵活、泛化的工具使用能力，是提升其视觉推理的关键挑战。

Method: 提出AdaReasoner框架，包含三部分：(i) 可扩展的数据构建流程，提供长视野、多步骤工具交互数据；(ii) Tool-GRPO强化学习算法，基于端到端任务成功优化工具选择与序列编排；(iii) 自适应学习机制，动态调节工具调用频率与方式。

Result: AdaReasoner展现出强工具自适应性与泛化能力：能自主采纳有益工具、抑制无关工具、按需调整调用频次；在多个挑战性基准上达到SOTA，7B基模型平均提升+24.9%，并在VSP、Jigsaw等任务上超越GPT-5等强闭源系统。

Conclusion: 工具使用可被建模为一种通用推理能力，而非特定工具或任务的监督行为；AdaReasoner证明了通过端到端强化学习与自适应机制，MLLMs可实现鲁棒、可泛化的多步工具协同推理。

Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.

</details>


### [477] [TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow](https://arxiv.org/abs/2601.17332)
*Yicheng Tao,Hongteng Xu*

Main category: cs.AI

TL;DR: TheoremForge 是一个成本效益高的形式化数据合成管道，通过将形式化过程分解为五个子任务并采用解耦提取策略，显著提高了数据生成效率和验证率。


<details>
  <summary>Details</summary>
Motivation: 高成本的代理工作流阻碍了形式数学中的大规模数据合成，加剧了开源语料库的稀缺性。

Method: 引入 TheoremForge 管道，将形式化过程分解为五个子任务（命题形式化、证明生成、前提选择、证明修正、证明草图），并采用解耦提取策略从全局失败轨迹中恢复有效训练信号。

Result: 在2000个问题的基准测试中，TheoremForge 实现了12.6%的验证率，高于基线8.6%，单次成功轨迹平均成本仅为0.481美元；证明生成的数据产量提升1.6倍。

Conclusion: TheoremForge 是一个可扩展的框架，可用于构建数据飞轮以训练未来专家模型。

Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \textit{statement formalization}, \textit{proof generation}, \textit{premise selection}, \textit{proof correction} and \textit{proof sketching}. By implementing a \textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\%, surpassing the 8.6\% baseline, at an average cost of only \textbf{\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \textbf{1.6$\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \href{https://github.com/timechess/TheoremForge}{here}.

</details>


### [478] [The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability](https://arxiv.org/abs/2601.17335)
*Angshul Majumdar*

Main category: cs.AI

TL;DR: 本文提出了一种形式化AGI的公理化框架，证明了AGI本质上是关系性、非鲁棒、受限迁移且不可自证的语义属性，因此强意义上的、分布无关的AGI概念在未明确定义索引时是无意义的。


<details>
  <summary>Details</summary>
Motivation: 探讨AGI是否具有支持存在性、鲁棒性或自验证等绝对断言的连贯理论定义。

Method: 将AGI公理化为依赖于任务族、任务分布、性能泛函和资源预算的分布性、资源受限语义谓词，并运用数学逻辑（Rice定理、哥德尔-塔斯基论证）、概率与优化分析推导关键性质。

Result: 得出四类结果：1）AGI的‘通用性’本质上是关系性的；2）AGI在任务分布扰动下不具鲁棒性（存在cliff sets）；3）有限资源下跨任务族的迁移能力有界；4）AGI是不可被任何可计算程序（包括自身）完备可靠判定的非平凡语义性质。

Conclusion: 强意义上的、分布无关的AGI主张并非错误，而是在缺乏显式形式索引时根本无定义；AI实证进展不意味着自认证通用智能的可实现性。

Abstract: We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and Gödel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.

</details>


### [479] [Are We Evaluating the Edit Locality of LLM Model Editing Properly?](https://arxiv.org/abs/2601.17343)
*Wei Liu,Haomei Xu,Hongkai Liu,Zhiying Deng,Ruixuan Li,Heng Huang,Yee Whye Teh,Wee Sun Lee*

Main category: cs.AI

TL;DR: 本文指出现有模型编辑特异性评估协议存在概念缺陷、与正则化器强度相关性弱及敏感性不足等问题，并提出一种新的评估协议以提升评估的准确性和区分度。


<details>
  <summary>Details</summary>
Motivation: 现有特异性评估协议无法准确衡量模型编辑中知识更新的效果与非目标知识的保留能力，存在概念缺陷、相关性弱和敏感性不足三大问题。

Method: 作者系统分析了现有评估协议的问题，并提出一种新的构造性评估协议，消除开放性大语言模型与确定答案假设之间的冲突，避免查询无关的流畅性偏差，并支持在近连续空间内平滑调整评估严格度。

Result: 新协议下的评估指标对特异性正则化器强度变化更敏感，且与其呈现强相关性，能更精细地区分不同方法的知识保留能力。

Conclusion: 所提出的评估协议显著提升了特异性评估的可靠性与区分力，为模型编辑研究提供了更科学的评价标准。

Abstract: Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.

</details>


### [480] [Multi-Agent Learning Path Planning via LLMs](https://arxiv.org/abs/2601.17346)
*Haoxin Xu,Changyong Qi,Tong Liu,Bohao Zhang,Anna He,Bingqian Jiang,Longwei Zheng,Xiaoqing Gu*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体的LLM学习路径规划框架（MALPP），通过角色与规则驱动的协作机制，提升高等教育中个性化学习的透明性、适应性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有学习路径规划方法缺乏透明性、适应性和以学习者为中心的可解释性。

Method: 提出多智能体学习路径规划（MALPP）框架，包含学习者分析、路径规划和反思三个任务型LLM智能体，基于认知负荷理论和最近发展区理论，通过结构化提示与预定义规则协同工作。

Result: 在MOOCCubeX数据集上，使用7个LLM验证，MALPP在路径质量、知识序列一致性与认知负荷对齐度上显著优于基线；消融实验验证了协作机制与理论约束的有效性。

Conclusion: MALPP为教育中可信、可解释AI的发展提供了新范式，展示了LLM驱动的以学习者为中心的自适应教学的可扩展路径。

Abstract: The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.

</details>


### [481] [Auditing Disability Representation in Vision-Language Models](https://arxiv.org/abs/2601.17348)
*Srikant Panda,Sourabh Singh Yadav,Palkesh Malviya*

Main category: cs.AI

TL;DR: 本文研究了视觉语言模型（VLMs）在描述残障人士相关图像时的偏差问题，发现引入残障语境会系统性降低解释保真度，导致推测性推断、叙事夸大、情感退化和缺陷导向 framing，并受种族与性别交叉影响；提出新基准与评估框架，并验证了针对性提示与偏好微调可有效缓解该问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在社会敏感场景中广泛应用，但其对残障相关描述的行为尚缺乏深入研究，尤其存在从客观事实描述滑向无依据主观解读的问题。

Method: 构建基于中性提示（NP）与残障语境化提示（DP）配对的新基准，涵盖9类残障；在零样本下评估15个主流开源与闭源VLM；结合文本指标（情感、社会评价、响应长度变化）与经残障经历者验证的LLM-as-judge协议，以解释保真度为核心目标。

Result: 引入残障语境普遍导致解释保真度下降，表现为推测性推断、叙事扩展、情感退化及缺陷导向表述；该效应在种族与性别维度上被放大；针对性提示与偏好微调可显著提升保真度并减少偏差。

Conclusion: 当前VLM在残障描述中存在系统性解释偏差，亟需以解释保真度为准则设计评估与优化方法；融入残障社群真实经验对构建公平、可信的多模态系统至关重要。

Abstract: Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.

</details>


### [482] [A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models](https://arxiv.org/abs/2601.17426)
*Zhengqing Zang,Yuqi Ding,Yanmei Gu,Changkai Song,Zhengkai Yang,Guoping Du,Junbo Zhao,Haobo Wang*

Main category: cs.AI

TL;DR: 本文探究了大语言模型（LLM）在逻辑推理上是否经历从传统逻辑（如亚里士多德逻辑）向现代逻辑（如弗雷格-罗素逻辑）的演化，并以“存在预设”为探针，通过新构建的三段论数据集评估主流LLM，发现模型规模、思维链推理和基础模型选择显著影响其逻辑框架的转变倾向。


<details>
  <summary>Details</summary>
Motivation: 受人类逻辑从直觉推理演进到形式化系统的启发，作者希望考察当前大语言模型是否也展现出类似的逻辑框架演化趋势，尤其关注其对传统逻辑与现代逻辑中关键差异（如存在预设）的处理能力。

Method: 以‘存在预设’为逻辑探针，设计并构建了一个新的三段论推理数据集；在该数据集上系统评测多个SOTA大语言模型；分析模型规模、是否启用思维链（chain-of-thought）、以及基础模型类型等因素对逻辑判断倾向（传统vs.现代）的影响。

Result: 实验发现：(i) 模型参数量增大倾向于使其推理更符合现代逻辑；(ii) 思维链推理能高效加速该逻辑转变，效果优于单纯扩大参数量；(iii) 基础模型架构/训练方式决定了该转变发生的难易程度与稳定性；此外还揭示了当前LLM在三段论推理中的若干结构性局限。

Conclusion: 大语言模型确实在逻辑推理层面呈现出从传统逻辑向现代逻辑演化的趋势，但该趋势并非自动随规模增长而发生，而是受模型架构、推理机制与训练基础等多重因素协同调控；这提示我们应将逻辑能力视为可塑的、需主动引导的认知维度，而非仅依赖缩放定律的副产品。

Abstract: Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.

</details>


### [483] [Lattice: Generative Guardrails for Conversational Agents](https://arxiv.org/abs/2601.17481)
*Emily Broadhurst,Tawab Safi,Joseph Edell,Vashisht Ganesh,Karime Maamari*

Main category: cs.AI

TL;DR: 本文提出Lattice框架，用于自构建和持续改进对话AI系统的防护机制，通过两阶段（构建与持续改进）实现对新威胁的自适应，并在多个基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有防护机制依赖静态规则，无法适应新威胁或部署环境的变化。

Method: Lattice框架包含两个阶段：构建阶段通过标注样例、迭代模拟与优化生成初始防护机制；持续改进阶段通过风险评估、对抗测试与整合，自主优化已部署的防护机制。

Result: 在ProsocialDialog数据集上，Lattice达到91% F1，较关键词基线高43个百分点，较LlamaGuard高25个百分点，较NeMo高4个百分点；跨域数据上，持续改进阶段带来7个百分点F1提升。

Conclusion: 有效的防护机制可通过迭代优化实现自构建，Lattice证明了其可行性与优越性。

Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.

</details>


### [484] [Cognitive Platform Engineering for Autonomous Cloud Operations](https://arxiv.org/abs/2601.17542)
*Vinoth Punniyamoorthy,Nitin Saksena,Srivenkateswara Reddy Sankiti,Nachiappan Chockalingam,Aswathnarayan Muthukrishnan Kirubakaran,Shiva Kumar Reddy Carimireddy,Durgaraman Maruthavanan*

Main category: cs.AI

TL;DR: 本文提出认知平台工程（Cognitive Platform Engineering），通过四层架构将感知、推理与自主行动嵌入云原生平台生命周期，实现智能化、自适应、意图对齐的运维范式。


<details>
  <summary>Details</summary>
Motivation: 现代DevOps在云原生环境下面临遥测数据爆炸、配置漂移加剧等问题，传统基于规则的自动化反应滞后、依赖人工，难以支撑大规模动态系统。

Method: 提出四平面参考架构（数据采集、智能推理、策略编排、人机体验），构建基于Kubernetes、Terraform、OPA和ML异常检测的原型系统，并嵌入持续反馈闭环。

Result: 实验表明该方法显著缩短平均故障修复时间（MTTR）、提升资源效率与合规性，支持弹性、自调节、意图对齐的云环境。

Conclusion: 认知平台工程是DevOps演进的关键方向；未来研究应聚焦强化学习驱动自治、可解释治理机制及可持续自管理云生态。

Abstract: Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.

</details>


### [485] [JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research](https://arxiv.org/abs/2601.17564)
*Aadam,Monu Verma,Mohamed Abdel-Mottaleb*

Main category: cs.AI

TL;DR: JaxARC is a high-performance, JAX-based RL environment for the Abstraction and Reasoning Corpus (ARC), enabling massively parallel, large-scale inductive reasoning research with up to 5,439x speedup over Gymnasium.


<details>
  <summary>Details</summary>
Motivation: Existing Gymnasium-based RL environments for ARC suffer from computational bottlenecks, severely limiting experimental scale and large-scale RL research on human-like inductive reasoning.

Method: The authors designed JaxARC — an open-source, functional, stateless RL environment for ARC implemented in JAX — leveraging JIT compilation and vectorization for massive parallelism; it supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility.

Result: JaxARC achieves 38–5,439× speedup over Gymnasium at matched batch sizes and peak throughput of 790M steps/second, making previously infeasible large-scale ARC RL experiments computationally viable.

Conclusion: JaxARC establishes a scalable, reproducible, and high-throughput foundation for advancing RL-based inductive reasoning research on ARC.

Abstract: The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.

</details>


### [486] [Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design](https://arxiv.org/abs/2601.17587)
*Azza Fadhel,Nathaniel W. Zuckschwerdt,Aryan Deshwal,Susmita Bose,Amit Bandyopadhyay,Jana Doppa*

Main category: cs.AI

TL;DR: 本文提出了一种结合AI驱动自适应实验设计与领域知识的方法，通过构建代理模型智能选择参数配置，显著加速了金属增材制造（如GRCop-42合金）可行工艺参数的发现过程，并首次在商用红外激光平台上实现了高质量打印。


<details>
  <summary>Details</summary>
Motivation: 金属增材制造中工艺参数配置困难，传统试错法效率低、成本高、周期长，尤其面对复杂合金（如NASA开发的GRCop-42）时缺乏有效可行方案。

Method: 采用AI驱动的自适应实验设计框架，基于历史实验数据构建 surrogate model（代理模型），在每轮迭代中智能批量推荐待验证的输入参数组合，用于定向能量沉积（DED）工艺优化。

Result: 在三个月内成功获得多种激光功率下无缺陷的GRCop-42打印件，大幅缩短研发周期（相比人工数月无果），并首次实现在通用红外激光设备上的高质量制备。

Conclusion: 该方法显著提升参数探索效率与成功率，降低了对高端专用设备的依赖，推动高性能航天合金的低成本、分布式制造。

Abstract: Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications.

</details>


### [487] [Intelligence Requires Grounding But Not Embodiment](https://arxiv.org/abs/2601.17588)
*Marcus Ma,Shrikanth Narayanan*

Main category: cs.AI

TL;DR: 本文论证了智能的核心在于'具身化'（embodiment）还是'根基化'（grounding），提出智能的关键是根基化而非具身化，并通过定义智能的四个属性（动机、预测能力、因果理解、经验学习）说明非具身但根基化的代理亦可具备智能。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型（LLM）的进展引发了关于具身化是否为智能必要条件的科学争论，本文旨在澄清这一争议，提出更根本的条件——根基化。

Method: 通过哲学与认知科学分析，定义智能的四个核心属性，并逐一论证这些属性可在非具身但根基化的系统中实现；辅以数字环境中的LLM思想实验及对反方观点的回应。

Result: 确立‘根基化’（grounding）是智能的必要条件，而‘具身化’（embodiment）只是实现根基化的一种可能途径，非必需。

Conclusion: 智能的本质要求是根基化，即符号或表征必须与现实世界经验建立稳定、可交互的联系；具身化虽常促成根基化，但并非逻辑上不可或缺。

Abstract: Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments.

</details>


### [488] [Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context](https://arxiv.org/abs/2601.17642)
*Zhihao Zhang,Liting Huang,Guanghao Wu,Preslav Nakov,Heng Ji,Usman Naseem*

Main category: cs.AI

TL;DR: 本文提出Health-ORSC-Bench，首个大规模医疗领域基准，用于系统评估大语言模型在边界查询上的过度拒绝（Over-Refusal）与安全完成（Safe Completion）能力；实验发现前沿大模型普遍存在安全悲观倾向，过度拒绝率达80%，而小模型或MoE架构模型校准更优。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法依赖二元拒绝边界，导致对良性查询过度拒绝或对有害查询不安全服从；缺乏对‘双用途/边缘查询’下既保持帮助性又避免实际危害的‘安全完成’能力的评估。

Method: 构建包含31920个良性边界提示的Health-ORSC-Bench基准，覆盖7类健康主题，采用自动化流水线+人工验证，在不同意图模糊度下测试30个SOTA模型；分析模型家族、规模与安全校准的关系。

Result: 安全优化模型对‘Hard’良性提示拒绝率高达80%；领域专用模型常以牺牲安全性换取实用性；更大尺寸前沿模型（如GPT-5、Llama-4）表现出更强‘安全悲观’倾向，相比小型或MoE模型（如Qwen-3-Next）更易过拒。

Conclusion: 当前LLM难以在医疗场景中平衡拒绝与合规；Health-ORSC-Bench为下一代医疗AI助手提供了一套衡量‘细致、安全且有益’生成能力的严格标准。

Abstract: Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \emph{over-refusal} of benign queries or \emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \textbf{Over-Refusal} and \textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\% of "Hard" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit "safety-pessimism" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \textcolor{red}{Warning: Some contents may include toxic or undesired contents.}

</details>


### [489] [DIML: Differentiable Inverse Mechanism Learning from Behaviors of Multi-Agent Learning Trajectories](https://arxiv.org/abs/2601.17678)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 本文提出DIML框架，用于从自利学习代理的策略交互轨迹中反向推断未知的激励生成机制（包括非结构化神经网络机制），通过可微分多智能体学习动力学建模与似然估计实现机制识别与反事实预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法如逆博弈论、多智能体逆强化学习通常局限于结构化机制内的效用/奖励参数推断，而可微机制设计是前向优化而非观测推断；本文旨在解决对未知、甚至非结构化（如神经网络）激励机制的逆向学习问题。

Method: 提出基于似然的DIML框架，通过可微分多智能体学习动力学模型，利用候选机制生成反事实收益以预测观测动作；在条件logit响应模型下建立收益差的可识别性，并证明最大似然估计在标准正则条件下具统计一致性。

Result: 在模拟实验中，DIML能可靠恢复可识别的激励差异，并支持反事实预测：在小规模环境中性能媲美表格枚举oracle，在百人规模匿名博弈等大环境仍保持收敛性与可扩展性。

Conclusion: DIML为逆机制学习提供了首个适用于非结构化、尤其是神经机制的可微分、统计一致且可扩展的观测推断框架，拓展了机制设计与多智能体学习的交叉边界。

Abstract: We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced.

</details>


### [490] [SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL](https://arxiv.org/abs/2601.17699)
*Harper Hua,Zhen Han,Zhengyuan Shen,Jeremy Lee,Patrick Guan,Qi Zhu,Sullam Jeoung,Yueyan Chen,Yunfei Bai,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.AI

TL;DR: 本文提出SQL-Trail，一种基于多轮强化学习的Text-to-SQL智能体框架，通过与数据库交互并利用执行反馈迭代优化SQL生成，显著提升准确率与数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有单次生成范式缺乏人类所具有的迭代推理、模式探索和错误修正能力，导致在BIRD-SQL等难基准上与人类专家仍有明显差距。

Method: 提出SQL-Trail框架：采用多轮RL智能体，结合自适应轮数分配机制和复合奖励面板（兼顾SQL正确性与探索效率），在数据库环境中交互式生成与修正SQL。

Result: 在多个基准上达到SOTA；数据效率达此前单次RL方法的18倍；7B/14B开源模型平均超越更大规模闭源系统5%。

Conclusion: 交互式、智能体驱动的工作流是提升Text-to-SQL鲁棒性的有效路径，多轮迭代优于单次生成范式。

Abstract: While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.

</details>


### [491] [The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data](https://arxiv.org/abs/2601.17717)
*Kaituo Zhang,Mingzhi Hu,Hoang Anh Duy Le,Fariha Kabir Torsha,Zhimeng Jiang,Minh Khai Bui,Chia-Yuan Chang,Yu-Neng Chuang,Zhen Xiong,Ying Lin,Guanchu Wang,Na Zou*

Main category: cs.AI

TL;DR: 本文提出LLM Data Auditor框架，系统评估大语言模型生成的跨模态合成数据的质量与可信度，强调内在指标而非下游任务表现，并为数据生成评估提供改进建议和实践方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究聚焦于LLM生成方法，却忽视合成数据质量本身，且多局限于单模态，缺乏统一跨模态评估视角。

Method: 提出LLM Data Auditor框架：1）梳理LLM在六种模态的数据生成应用；2）从质量与可信度两个维度系统分类内在评估指标；3）分析代表性生成方法的实验评估，揭示当前评估缺陷；4）给出改进建议与跨模态应用方法。

Result: 识别出当前合成数据评估实践中存在重大不足，如过度依赖外在下游指标、缺乏统一内在质量标准等。

Conclusion: 应转向以数据本征属性为核心的评估范式，建立跨模态、可复现、可解释的合成数据质量评估体系，并推动其在实际场景中的可靠应用。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.

</details>


### [492] [EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents](https://arxiv.org/abs/2601.17722)
*Ying Mo,Yu Bai,Dapeng Sun,Yuqian Shi,Yukai Miao,Li Chen,Dan Li*

Main category: cs.AI

TL;DR: 本文提出了EntWorld，一个面向企业级场景的大规模基准测试集，包含1756个跨6个企业领域的任务，采用基于数据库schema的任务生成框架和SQL驱动的状态验证机制，揭示了当前多模态大模型在企业复杂流程中性能远低于人类水平（47.61% vs 人类），呼吁发展领域专用智能体。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM基准主要针对消费级场景，无法反映企业系统高密度UI、严格业务逻辑与状态一致性信息检索等特有挑战，亟需更严谨的评估基准。

Method: 提出EntWorld基准：1）基于真实数据库schema反向工程业务逻辑，自动生成长周期、高保真企业任务；2）设计SQL驱动的确定性状态验证机制，替代模糊视觉匹配；3）覆盖CRM、ITIL、ERP等六大企业领域。

Result: SOTA模型（如GPT-4.1）在EntWorld上成功率为47.61%，显著低于人类水平，证实当前通用智能体存在明显‘企业能力鸿沟’。

Conclusion: EntWorld填补了企业级智能体评估空白，其schema驱动生成与SQL验证范式为构建可信赖、可验证的企业数字员工提供了新方法论，并开源以推动领域专用代理研究。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.

</details>


### [493] [ReFuGe: Feature Generation for Prediction Tasks on Relational Databases with LLM Agents](https://arxiv.org/abs/2601.17735)
*Kyungho Kim,Geon Lee,Juyeon Kim,Dongwon Choi,Shinhwan Kang,Kijung Shin*

Main category: cs.AI

TL;DR: 本文提出ReFuGe框架，利用大语言模型代理自动生成关系数据库中的预测特征，显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 关系数据库预测任务需要生成信息丰富的关联特征，但面临模式复杂性和特征空间组合爆炸的挑战，且缺乏显式监督信号。

Method: 提出ReFuGe框架，包含三个专用大语言模型代理：模式选择代理、特征生成代理和特征过滤代理，在迭代反馈环中协同工作。

Result: 在多个关系数据库基准测试上，ReFuGe显著提升了各类预测任务的性能。

Conclusion: ReFuGe是一种有效的无监督特征工程方法，通过多代理协作实现高质量关系特征的自动发现与筛选。

Abstract: Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE.

</details>


### [494] [Faramesh: A Protocol-Agnostic Execution Control Plane for Autonomous Agent Systems](https://arxiv.org/abs/2601.17744)
*Amjad Fatmi*

Main category: cs.AI

TL;DR: 本文提出Faramesh，一种协议无关的执行控制平面，通过不可绕过的Action Authorization Boundary（AAB）在执行时对自主智能体行为实施强制授权，确保组织能确定性地许可、拒绝或延迟现实世界操作。


<details>
  <summary>Details</summary>
Motivation: 现有自主智能体系统在触发真实世界副作用（如修改数据库、移动资金等）时缺乏强制性的执行检查点，导致组织无法确定性地管控风险。

Method: 设计Faramesh系统：定义不可绕过的Action Authorization Boundary（AAB）；将智能体意图规范化为Canonical Action Representation（CAR）；基于策略与状态进行确定性策略评估；生成PERMIT/DEFER/DENY决策凭证；支持框架/模型/协议无关、多智能体/多租户部署；提供基于动作哈希的追加式决策日志。

Result: 实现了可强制执行、可预测的自主执行治理机制；支持审计、验证与确定性重放；避免了与编排层的隐式耦合及仅依赖可观测性的局限。

Conclusion: Faramesh为自主智能体的真实世界操作提供了轻量、解耦、可验证的执行授权基础设施，是构建可信AI系统的关键治理组件。

Abstract: Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches.

</details>


### [495] [HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis](https://arxiv.org/abs/2601.17767)
*Rajan Das Gupta,Xiaobin Wu,Xun Liu,Jiaqi He*

Main category: cs.AI

TL;DR: 本文提出了一种融合CNN、LSTM与KNN、XGB的混合集成框架，用于心血管疾病预测，在两个公开数据集上分别达到82.30%和97.10%准确率，兼顾性能与可解释性，支持联合国可持续发展目标3。


<details>
  <summary>Details</summary>
Motivation: 传统预测模型在异构数据集和复杂生理模式下泛化能力不足，而心血管疾病仍是全球首要死因，亟需智能、数据驱动的诊断工具。

Method: 构建基于投票机制的混合集成框架，融合深度学习（CNN、LSTM）与经典机器学习（KNN、XGB），兼顾表征能力与可解释性及效率。

Result: 在两个Kaggle公开数据集上分别取得82.30%和97.10%的准确率，并在精确率、召回率和F1分数上均表现更优。

Conclusion: 该混合AI框架具有鲁棒性和临床应用潜力，有助于心血管疾病的早期干预，同时支撑联合国可持续发展目标3（良好健康与福祉）。

Abstract: Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.

</details>


### [496] [Neuro-Symbolic Verification on Instruction Following of LLMs](https://arxiv.org/abs/2601.17789)
*Yiming Su,Kunzhao Xu,Yanjie Gao,Fan Yang,Cheng Li,Mao Yang,Tianyin Xu*

Main category: cs.AI

TL;DR: 本文提出NSVIF，一种神经符号框架，用于验证大语言模型（LLM）是否遵循指令，将其建模为约束满足问题，并在新基准VIFBENCH上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: LLM常不遵守指令，且违规难以检测，在基于LLM的智能体工作流中可能引发级联错误；需通用、可解释的指令遵循验证方法。

Method: NSVIF将用户指令建模为逻辑与语义约束，通过统一求解器协同逻辑推理与语义分析进行约束求解；不依赖特定指令或LLM，具备通用性。

Result: 在VIFBENCH基准上，NSVIF显著优于纯LLM方法，提供高精度验证与可解释反馈；其反馈还能在无需后训练的情况下提升LLM的指令遵循能力。

Conclusion: NSVIF为LLM指令遵循提供了通用、可靠、可解释的神经符号验证范式，兼具理论严谨性与实用价值。

Abstract: A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.

</details>


### [497] [MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing](https://arxiv.org/abs/2601.17814)
*Haoxuan Ma,Guannan Lai,Han-Jia Ye*

Main category: cs.AI

TL;DR: 本文提出MMR-Bench，一个面向多模态大语言模型（MLLM）查询级路由选择的统一基准，旨在解决异构MLLM在不同任务和计算预算下难以统一优化的问题；通过引入多模态信号提升路由质量，显著改善成本-精度权衡，并实现零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM架构、对齐策略与效率差异大，单一模型无法在所有任务上均表现最优；实际部署中工作负载多样，亟需按查询动态选择最适模型（即路由），但多模态路由面临模态融合复杂、计算成本差异大、缺乏标准化预算感知评估等挑战。

Method: 构建MMR-Bench基准：包含模态感知输入、可变计算预算的受控环境；覆盖OCR、通用VQA和多模态数学推理的多样化视觉-语言任务；提供单模型基线、Oracle上界及典型路由策略；设计并验证基于多模态信号的路由策略。

Result: 实验证明，利用多模态信号可提升路由质量，在约33%计算成本下超越最强单模型的精度；所学路由策略能零样本迁移到新数据集及纯文本基准，无需调优。

Conclusion: MMR-Bench为研究自适应多模态模型选择与高效MLLM部署提供了坚实基础，推动了预算感知、任务感知的智能路由方法发展。

Abstract: Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.

</details>


### [498] [RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance](https://arxiv.org/abs/2601.17826)
*Siyuan Yang,Xihan Bian,Jiayin Tang*

Main category: cs.AI

TL;DR: 本文提出RegGuard，一个面向制药行业的工业级AI助手，用于自动化解读异构监管文本并匹配企业内部政策，通过HiSACC和ReLACE两个创新模块提升检索与生成质量，实证表明其在相关性、事实依据性和上下文聚焦方面显著优于基线，并有效抑制幻觉，具备可审计、可追溯的系统架构。


<details>
  <summary>Details</summary>
Motivation: 跨国制药公司面临监管更新频繁、复杂且跨辖区、跨格式、跨机构的问题，合规团队依赖人工解读，成本高、易出错。

Method: 提出RegGuard系统，包含安全文档摄入管道、HiSACC（分层语义聚合的上下文分块）实现长文档语义一致切分，以及ReLACE（监管列表式自适应交叉编码器）进行查询与候选联合建模以提升重排序效果；系统支持溯源追踪、访问控制与增量索引。

Result: 在企业环境中评估显示，RegGuard显著提升答案的相关性、事实依据性（groundedness）和上下文聚焦能力，同时大幅降低幻觉风险。

Conclusion: RegGuard是一个可审计、可追溯、响应迅速的合规AI系统，不仅适用于制药行业，也可推广至其他强监管领域。

Abstract: The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.

</details>


### [499] [Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards](https://arxiv.org/abs/2601.17828)
*Tanvi Verma,Yang Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.AI

TL;DR: 本文提出信息增益微调（IGFT）方法，通过结合在线组相对策略优化（GRPO）与信息论奖励机制，使医疗对话AI能自主学习高效问诊并生成详尽的现病史（HPI），无需依赖人工标注对话数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的专家标注对话或静态数据集，难以扩展且缺乏对多轮问诊策略的自主探索能力；需一种能自驱动、临床有效、泛化性强的训练范式。

Method: 提出IGFT框架：基于在线RL（GRPO），使用信息增益奖励函数（融合临床实体覆盖度与GPT-4o-mini多维质量评估），在模拟患者交互中优化提问策略；采用LoRA对Llama-3.1-8B和DeepSeek-R1-Distill-Qwen-7B进行微调；训练数据仅来自Avey（简短HPI），测试泛化至MIMIC（长HPI）。

Result: DeepSeek-R1-Distill-Qwen-7B(IGFT)在Avey和MIMIC上HPI抽取F1达0.408和0.289（分别提升10.9%和12.9%）；Llama-3.1-8B(IGFT)达0.384和0.336；两者均超越OpenAI模型及HuatuoGPT、UltraMedical等单轮医疗QA基线。

Conclusion: IGFT验证了无需人类对话数据、仅靠信息驱动的在线强化学习即可有效训练多轮医疗对话AI，显著提升HPI生成质量与跨数据集泛化能力，为低资源医疗AI训练提供了新路径。

Abstract: We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.

</details>


### [500] [When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents](https://arxiv.org/abs/2601.17887)
*Jiahe Guo,Xiangran Guo,Yulin Hu,Zimo Long,Xingyu Sui,Xuda Zhi,Yongbo Huang,Hao He,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.AI

TL;DR: 本文揭示了个性化智能体中一种新的安全失效模式——意图正当化（intent legitimation），即良性的个人记忆会干扰意图推断，导致模型为有害查询提供正当性；为此构建了PS-Bench基准进行量化评估，并提出轻量级检测-反思方法缓解该问题。


<details>
  <summary>Details</summary>
Motivation: 现有个性化智能体研究多关注效用与用户体验，忽视长期记忆带来的安全风险，尤其是良性的个人记忆可能无意中助长有害行为。

Method: 提出意图正当化概念，构建PS-Bench基准评估不同记忆增强型智能体框架下的该现象；通过内部表征空间分析提供机制证据；设计轻量级检测-反思方法以缓解安全退化。

Result: 个性化使攻击成功率相对无状态基线提升15.8%–243.7%；在多个模型和框架上验证了意图正当化的普遍存在；所提检测-反思方法有效降低安全退化。

Conclusion: 意图正当化是一种源于真实个性化场景的新型安全失效模式，亟需在长期个性化上下文中系统评估智能体安全性。

Abstract: Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.

</details>


### [501] [UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis](https://arxiv.org/abs/2601.17897)
*Jiayu Liu,Yinhe Long,Zhenya Huang,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出UniCog框架，通过潜在心智空间分析大语言模型（LLM）的认知过程，揭示其推理中存在共享核心与能力特异性签名的帕累托分布，并利用该认知视角提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法难以刻画大语言模型在推理过程中如何调用认知能力，而人类与LLM的认知机制存在本质差异，亟需一种认知层面的建模与分析框架。

Method: 提出UniCog——一种基于隐变量模型的统一框架，将密集的模型激活映射为稀疏、解耦的潜在维度，以表征多样化认知能力；在6个先进LLM上进行实证分析，并设计潜在激活异常检测与潜在信息驱动的候选优先级策略。

Result: 发现LLM认知遵循帕累托原则（共享推理核心+能力特异性签名）；推理失败常表现为潜在激活强度异常；所提候选优先级策略在多个困难基准上最高提升7.5%推理性能。

Conclusion: UniCog为LLM推理提供了以认知为基础的动态分析新范式，不仅深化了对模型内在机制的理解，也为提升推理鲁棒性与性能提供了可解释、可干预的新路径。

Abstract: A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.

</details>


### [502] [Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation](https://arxiv.org/abs/2601.17915)
*Saurabh Jha,Rohan Arora,Bhavya,Noah Zheutlin,Paulina Toro Isaza,Laura Shwartz,Yu Deng,Daby Sow,Ruchi Mahindru,Ruchir Puri*

Main category: cs.AI

TL;DR: 本文提出EoG（Explanations over Graphs）框架，将调查任务建模为依赖图上的溯因推理，解耦LLM的语义推理与控制器的流程管理，以提升在开放、动态、大规模异构数据中进行证据迭代挖掘时的准确性与一致性。


<details>
  <summary>Details</summary>
Motivation: 现有ReAct类LLM代理在开放性调查任务中表现脆弱：受限于上下文窗口，难以保留关键中间证据；探索顺序敏感、运行间不一致（高Pass-at-k但低Majority-at-k）；缺乏显式的信念维护与修正机制；且语义推理与控制逻辑耦合导致错误传播。

Method: 将调查建模为依赖图上的溯因推理；设计EoG框架，实现LLM（仅做局部证据挖掘与因果标注）与确定性控制器（负责图遍历、状态管理、信念传播与解释前沿计算）的职责分离。

Result: 在ITBench诊断任务上，EoG显著优于ReAct基线，在准确率和运行一致性上均有提升，实体F1的Majority-at-k平均提升达7倍。

Conclusion: 解耦语义推理与系统控制、引入显式图结构与信念机制，是提升LLM在复杂动态调查任务中鲁棒性与可靠性的有效路径。

Abstract: LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.
  We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.

</details>


### [503] [Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges](https://arxiv.org/abs/2601.17920)
*Xuanzhou Chen,Audrey Wang,Stanley Yin,Hanyang Jiang,Dong Zhang*

Main category: cs.AI

TL;DR: 本文综述了面向自驱动实验室（SDL）的AI方法，聚焦于真实实验环境中的智能体决策问题，涵盖贝叶斯优化、主动学习、强化学习与工具调用代理等关键技术，并提出以能力为导向的分类体系与可比性评估框架。


<details>
  <summary>Details</summary>
Motivation: 自驱动实验室（SDL）为在昂贵操作、噪声延迟反馈、严格安全与可行性约束及非平稳性条件下验证智能体AI提供了极具挑战性的测试平台；本文旨在系统梳理SDL中核心AI问题并建立统一分析框架。

Method: 将SDL自主性建模为具有显式观测、动作、成本与约束的智能体-环境交互问题；综述贝叶斯优化与主动学习（高效选样）、规划与强化学习（长周期协议优化）、工具调用智能体（异构仪器/软件协同）三类主流方法；提出基于决策时域、不确定性建模、动作参数化等维度的能力驱动分类法；设计兼顾成本、鲁棒性、约束合规性与可复现性的基准任务与评估指标。

Result: 建立了SDL AI问题的统一形式化框架；系统归纳了支撑闭环实验的关键AI方法族；提出了能力驱动的SDL系统分类体系；构建了面向实际部署需求的评估基准模板与指标；提炼出多模态表征、校准不确定性、安全探索与共享基准设施等关键开放挑战。

Conclusion: SDL不仅是自动化实验平台，更是推动具身智能与可信AI发展的前沿试验场；未来需加强理论严谨性、工程可靠性与跨学科协作，以实现从‘能运行’到‘可信赖、可验证、可持续演进’的跨越。

Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.

</details>


### [504] [Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation](https://arxiv.org/abs/2601.17923)
*Ali Najar*

Main category: cs.AI

TL;DR: 本文提出了一种基于技能图的分层课程学习方法，在《黑暗之魂3》实时战斗环境中构建可复用、可选择性微调的五个子技能（镜头控制、锁定目标、移动、闪避、治疗/攻击决策），显著提升样本效率并支持环境变化下的快速适应。


<details>
  <summary>Details</summary>
Motivation: 让智能体具备终身学习能力，即在不从头训练或覆盖旧行为的前提下，持续扩展其能力。

Method: 将战斗建模为有向技能图，采用分层课程学习方式训练五个职责明确、可复用的子技能，并支持环境变化后的选择性后训练（仅微调部分技能）。

Result: 在Phase 1到Phase 2环境变化时，仅需微调两个技能即可在有限交互预算下快速恢复性能。

Conclusion: 技能图课程学习与选择性微调相结合，为复杂实时环境中可演化的持续学习智能体提供了可行路径。

Abstract: Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.

</details>


### [505] [LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting](https://arxiv.org/abs/2601.17942)
*Yu-Jie Yang,Hung-Fu Chang,Po-An Chen*

Main category: cs.AI

TL;DR: 本文提出了一种无需真实标签的单智能体自优化框架SSEV，并在此基础上构建了多智能体协作框架ReCAPAgent-SQL，显著提升了Text-to-SQL在多个基准（如Spider、BIRD）上的执行准确率，尤其面向企业级复杂数据库场景。


<details>
  <summary>Details</summary>
Motivation: 自然语言到SQL转换仍面临语义歧义、模式链接复杂、跨SQL方言泛化能力弱及领域知识依赖等挑战，尤其在真实企业数据库中更为突出。

Method: 提出SSEV（Single-Agent Self-Refinement with Ensemble Voting）流程，基于PET-SQL，融合自优化与加权多数投票（WMV）及其随机变体（RWMA）；进一步设计ReCAPAgent-SQL多智能体框架，包含规划、知识检索、批判、执行、自优化、模式链接和结果验证等专业化智能体，支持迭代式SQL生成与修正。

Result: SSEV在Spider 1.0-Dev/Test上达85.5%/86.4%执行准确率，BIRD-Dev达66.3%；ReCAPAgent-SQL在Spider 2.0-Lite前100查询上达31%执行准确率，显著优于基线。

Conclusion: 所提方法有效提升了Text-to-SQL系统在真实场景下的鲁棒性与可扩展性，为低成本、高效率部署数据驱动决策系统提供了可行路径。

Abstract: Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.

</details>


### [506] [Sentipolis: Emotion-Aware Agents for Social Simulations](https://arxiv.org/abs/2601.18027)
*Chiyuan Fu,Lyuhao Chen,Yunze Xiao,Weihao Xuan,Carlos Busso,Mona Diab*

Main category: cs.AI

TL;DR: 本文提出了Sentipolis框架，旨在为大语言模型（LLM）代理赋予持续、状态化的 emotion 表征能力，通过PAD模型、双速情绪动力学与情绪-记忆耦合机制，显著提升社交模拟中情绪连贯性与行为合理性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在社会模拟中常将情绪视为瞬时线索，导致‘情绪失忆’和长时程行为连续性弱，难以建模真实人类社交中的情感累积效应。

Method: 提出Sentipolis框架，包含三部分：1）连续的愉悦-唤醒-支配（PAD）情绪表征；2）快慢双速情绪动态更新机制；3）情绪状态与记忆系统的显式耦合。在多个基座模型和评估器上进行数千次交互实验，并辅以网络级关系结构诊断。

Result: Sentipolis显著提升了情绪基础行为、沟通质量与情绪连续性；效果呈模型依赖性——高容量模型可信度提升，小模型可能下降；情绪感知轻微削弱社会规范遵从，体现人机间类似的情感-规则张力；网络分析显示关系结构具备互惠性、中等聚类性与时间稳定性。

Conclusion: Sentipolis为构建具有情感状态延续性的LLM代理提供了可行路径，支持对联盟形成、关系渐变等长期社会动态的建模，揭示了情感建模与规范行为间的内在权衡。

Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.

</details>


### [507] [Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing](https://arxiv.org/abs/2601.18061)
*Kiana Jafari,Paul Ulrich Nikolaus Rust,Duncan Eddy,Robbie Fraser,Nina Vasan,Darja Djordjevic,Akanksha Dadlani,Max Lamparth,Eugenia Kim,Mykel Kochenderfer*

Main category: cs.AI

TL;DR: 本文挑战了基于人类反馈学习（LHF）中专家共识即真实标签的假设，发现在精神健康领域，即使由受过训练的精神科医生使用校准量表独立评分，其评分者间信度极低（ICC 0.087–0.295），尤其在自杀/自伤等高危场景下存在系统性分歧；分歧源于不同但合理的临床哲学（如安全优先、以参与为中心、文化敏感），而非随机误差；因此，简单聚合专家标签会抹除专业判断的深层逻辑，应转向能建模并学习分歧的对齐方法。


<details>
  <summary>Details</summary>
Motivation: LHF范式默认专家共识可提供可靠真值标签，但在精神健康等高风险AI应用中，该假设未经实证检验，而错误标签可能引发严重安全后果。

Method: 三位认证精神科医生依据校准量表独立评估LLM生成的心理健康回应；计算组内相关系数（ICC）与Krippendorff's α量化信度；开展质性访谈探究分歧根源。

Result: 专家间信度极低（ICC 0.087–0.295），自杀/自伤类响应分歧最大，其中一项指标α为负（-0.203），表明系统性对立；质性分析揭示分歧源于三种互斥但合理的临床框架，而非测量噪声。

Conclusion: 专家在高危AI任务中的分歧是根植于专业实践的、有原则的、结构性的社会技术现象；简单聚合标签会掩盖专业判断的多样性与深度；应放弃追求共识，转而发展能建模、保留并学习专家分歧的对齐与评估新范式。

Abstract: Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.

</details>


### [508] [EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization](https://arxiv.org/abs/2601.18067)
*Wei-Po Hsin,Ren-Hao Deng,Yao-Ting Hsieh,En-Ming Huang,Shih-Hao Hung*

Main category: cs.AI

TL;DR: 本文提出EvolVE框架，结合蒙特卡洛树搜索（MCTS）与创意引导精炼（IGR）策略，并辅以结构化测试平台生成（STG），显著提升Verilog硬件设计自动化水平，在多个基准上达到SOTA性能，并在工业级IC-RTL基准中大幅优化PPA指标。


<details>
  <summary>Details</summary>
Motivation: Verilog设计流程劳动密集且依赖专家经验；现有大语言模型受限于训练数据不足和序列推理能力，难以建模硬件的严格逻辑与并发特性。

Method: 提出EvolVE框架，系统评估多种进化策略（如MCTS用于功能正确性、IGR用于优化），引入结构化测试平台生成（STG）加速进化过程，并构建工业级IC-RTL基准测试套件。

Result: 在VerilogEval v2和RTLLM v2上分别达98.1%和92%准确率；在IC-RTL上相较参赛者实现最高66%的PPA降低（Huffman编码）及17%几何平均PPA优化。

Conclusion: EvolVE是首个面向芯片设计任务的多策略进化框架，验证了MCTS与IGR在不同目标下的互补优势，为硬件设计自动化提供了新范式。

Abstract: Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.

</details>


### [509] [Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?](https://arxiv.org/abs/2601.18119)
*Jing Ye,Yiwen Duan,Yonghong Yu,Victor Ma,Yang Gao,Xing Chen*

Main category: cs.AI

TL;DR: 本文提出了OurBench，首个面向企业级SQL推理与调试的基准测试，包含语法和语义错误两类复杂SQL查询，并评估了近30个大模型在该基准上的表现，揭示了现有模型性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: SQL在企业数据工程中至关重要，但即使经验丰富的开发者和先进文本到SQL的大语言模型也难以一次性生成完全正确的SQL，常需多次调试；缺乏针对企业级SQL调试的系统性、可扩展的基准测试。

Method: 提出OurBench基准：（1）基于反向工程的自动化流程，系统注入真实感强的SQL缺陷；（2）设计无需执行的、适配企业场景的高效评估框架；构建含469条语法错误（OurBenchSyn）和516条语义错误（OurBenchSem）的高复杂度SQL查询集。

Result: 在近30个LLM上评估显示，最优模型Claude-4-Sonnet在OurBenchSyn和OurBenchSem上准确率分别仅为36.46%和32.17%，多数模型低于20%；识别出关键挑战并提出四种解决策略及未来方向。

Conclusion: OurBench填补了企业级SQL调试基准的空白，实证揭示当前LLM在复杂SQL调试任务上的显著不足，为后续研究提供了标准化评测平台和明确改进路径。

Abstract: SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.
  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.
  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.

</details>


### [510] [Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters](https://arxiv.org/abs/2601.18123)
*Muhammad Ibrahim Khan,Bivin Pradeep,James Brusey*

Main category: cs.AI

TL;DR: 本文研究了浸入式热水器的截止时间感知控制，旨在在指定时间达到目标温度的同时最小化能耗。作者构建了一个基于Gymnasium的热力学仿真环境，并对比了时间最优bang-bang控制、零样本MCTS规划器和PPO强化学习策略，结果表明PPO在多种设定下显著降低能耗（最高达69%），且推理开销极低。


<details>
  <summary>Details</summary>
Motivation: 传统家用浸入式热水器冬季常连续运行，加热快但效率低，忽视可预测的用水时段和环境热损失，亟需更节能的智能控制策略。

Method: 构建一个模拟一阶热损失、离散开关动作（0W/6000W、每120秒一次）的Gymnasium环境；对比时间最优bang-bang控制、零样本蒙特卡洛树搜索（MCTS）规划器和近端策略优化（PPO）强化学习策略。

Result: PPO在60步（2小时）截止时间下仅耗电3.23 kWh，显著优于bang-bang（4.37–10.45 kWh）和MCTS（4.18–6.46 kWh）；在典型工况下相比bang-bang和MCTS分别节能54%和33%；节能幅度随截止时间延长而增大（30步时26%，90步时69%）。

Conclusion: 基于学习的截止时间感知控制可在相同物理假设下显著降低能耗；规划类方法无需训练即可获得部分节能效果，而训练后的策略具备近零推理成本，更具实用潜力。

Abstract: Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.

</details>


### [511] [RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents](https://arxiv.org/abs/2601.18130)
*Jize Wang,Han Wu,Zhiyuan You,Yiming Song,Yijun Wang,Zifei Shan,Yining Li,Songyang Zhang,Xinyi Le,Cailian Chen,Xinping Guan,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文提出RouteMoA，一种通过动态路由提升混合智能体（MoA）效率的新框架，利用轻量级打分器初筛、混合裁判器精调、以及兼顾性能/成本/延迟的排序机制，在大幅降低开销的同时保持甚至提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有MoA方法因密集拓扑导致高成本与高延迟；LLM裁判需全部模型先推理再评判，无法有效降本；缺乏模型选择标准，难以扩展至大规模模型池。

Method: RouteMoA包含三阶段：1）轻量级打分器基于查询粗略预测模型性能，实现无推理初筛；2）混合裁判器利用已有输出进行轻量自评与互评，提供后验校准；3）综合性能、成本与延迟的模型排序机制完成最终选择。

Result: 在不同任务和模型池规模下均优于标准MoA；在大规模模型池中降低成本89.8%，降低延迟63.6%。

Conclusion: RouteMoA通过动态路由显著提升了MoA的效率与可扩展性，为构建低成本、低延迟、高性能的多模型协作系统提供了新范式。

Abstract: Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.

</details>


### [512] [RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening](https://arxiv.org/abs/2601.18132)
*Xi Chen,Hongru Zhou,Huahui Yi,Shiyu Feng,Hanyu Zhou,Tiancheng He,Mingke You,Li Wang,Qiankun Li,Kun Wang,Weili Fu,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: RareAlert 是一种基于多LLM推理校准与集成的早期筛查系统，利用常规初级诊疗数据预测罕见病风险，在真实世界数据集 RareBench 上实现 AUC 0.917，显著优于各类先进LLM和机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 罕见病在初诊阶段常因信息有限、不确定性高而被漏诊或误诊；现有分诊流程无法可靠识别高风险患者，亟需通用型早期筛查工具以缩短诊断延迟。

Method: 提出 RareAlert 系统：融合10个大语言模型（LLM）生成的临床推理，通过机器学习进行信号校准与加权，并蒸馏为单个轻量级本地可部署模型（基于 Qwen3-4B）；构建覆盖33类罕见病、超7000种疾病的现实世界数据集 RareBench（158,666例）用于训练与评估。

Result: RareAlert 在独立测试集上达到 AUC 0.917，超越所有对比模型（包括 GPT-5、DeepSeek-R1、Claude-3.7-Sonnet、o3-mini、Gemini-2.5-Pro 和 Qwen3-235B）及最佳机器学习集成模型；验证了LLM医学推理的多样性及其在校准对齐后在高度不确定临床任务中的有效性。

Conclusion: 罕见病识别可重构为面向全体人群的‘普遍性不确定性消解’过程；RareAlert 通过融合校准后的多LLM推理，实现了高精度、隐私保护、可扩展且适合大规模本地部署的罕见病风险筛查。

Abstract: Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.

</details>


### [513] [DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints](https://arxiv.org/abs/2601.18137)
*Yinger Zhang,Shutong Jiang,Renhao Li,Jianhong Tu,Yang Su,Lianghao Deng,Xudong Guo,Chenxu Lv,Junyang Lin*

Main category: cs.AI

TL;DR: 本文提出了DeepPlanning基准，用于评估大语言模型在实际长周期规划任务中的能力，包括多日旅行规划和多商品购物任务，强调主动信息获取、局部约束推理和全局约束优化。


<details>
  <summary>Details</summary>
Motivation: 现有基准过于关注局部步骤级推理，缺乏对真实世界中全局约束优化（如时间和财务预算）以及主动信息收集和细粒度局部约束的建模。

Method: 构建DeepPlanning基准，包含多日旅行规划和多商品购物两类任务，并对前沿具身大语言模型进行系统评估，结合错误分析提出改进方向。

Result: 实验表明，即使是最先进的具身大语言模型在DeepPlanning任务上仍表现不佳，凸显显式可靠推理模式和平行工具调用的重要性。

Conclusion: DeepPlanning揭示了当前大语言模型在长周期、多约束规划任务上的关键短板，为未来研究提供了开源数据、代码和明确改进路径。

Abstract: While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.

</details>


### [514] [Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success](https://arxiv.org/abs/2601.18175)
*Daniel Russo*

Main category: cs.AI

TL;DR: 本文证明了成功条件化（success conditioning）精确地解决了一个信任区域优化问题，即在χ²散度约束下最大化策略改进，并揭示了相对策略改进、策略变化幅度和动作影响三者在每个状态下的精确等价性。


<details>
  <summary>Details</summary>
Motivation: 成功条件化作为一种广泛使用的策略改进技术，其背后所解决的优化问题一直不明确，本文旨在澄清这一理论基础。

Method: 通过理论分析与数学证明，将成功条件化与信任区域优化问题建立联系，并推导出相对策略改进、策略变化幅度与动作影响之间的精确等价关系。

Result: 成功条件化被证明是保守的策略改进算子：它不会降低性能或引发危险分布偏移；若失效，则表现为策略几乎无变化，且可被观测到。此外，文中还分析了常见实践——回报阈值法——对改进效果与目标对齐性的影响。

Conclusion: 成功条件化是一种具有理论保障的安全策略改进方法，其内在机制由自动确定的χ²散度约束所刻画，为理解多种相关算法（如SFT、目标条件RL、决策Transformer）提供了统一视角。

Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.

</details>


### [515] [GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models](https://arxiv.org/abs/2601.18197)
*Shaokang Wang,Pei Fu,Ruoceng Zhang,Shaojie Zhang,Xiuwen Xi,Jiahui Yang,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan*

Main category: cs.AI

TL;DR: 本文提出GUI Action Critic's Data Flywheel System (GAIA)，通过训练一个直觉批评模型（ICM）来评估GUI代理操作的即时正确性，并利用反馈数据迭代优化，从而提升测试时性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在GUI代理任务中面临操作不可逆问题，单个错误动作可能导致严重偏差，亟需一种能动态评估与修正操作的机制。

Method: 提出GAIA框架：首先用基础代理生成的正负样本训练直觉批评模型（ICM）；ICM实时评估动作合理性并筛选高成功率操作；再以ICM指导生成更优数据，迭代训练增强版批评模型。

Result: 在多个数据集上验证了ICM可显著提升闭源与开源GUI代理的测试时性能，且随数据循环使用，性能持续提升。

Conclusion: GAIA通过构建数据飞轮机制，赋予GUI代理迭代自省与优化能力，有效缓解操作不可逆问题，为提升GUI智能体鲁棒性提供了新范式。

Abstract: While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.

</details>


### [516] [SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback](https://arxiv.org/abs/2601.18202)
*Fangyuan Xu,Rujun Han,Yanfei Chen,Zifeng Wang,I-Hung Hsu,Jun Yan,Vishy Tirumalashetty,Eunsol Choi,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: 本文提出SAGE框架，通过数据生成器与搜索代理的多轮交互，自动生成高质量、难度可控的深度搜索问答对，显著提升深度搜索代理的性能。


<details>
  <summary>Details</summary>
Motivation: 深度搜索代理需要跨多文档推理以回答复杂问题，但人工标注此类数据成本极高，因为涉及长而复杂的探索轨迹。

Method: 提出SAGE流水线：包含一个数据生成器（生成问答对）和一个搜索代理（尝试解答并反馈执行结果），二者多轮交互迭代优化，直至生成符合目标难度的问答对。

Result: 内在评估显示SAGE生成的问题需多样推理策略，且正确率与难度显著提升；外在评估显示在主流深度搜索基准上相对性能提升达23%；还验证了所训练代理可无缝迁移至Google搜索而无需额外训练。

Conclusion: SAGE是一种高效、可扩展的合成数据生成方法，能有效缓解深度搜索任务中高质量标注数据稀缺的问题，并提升模型泛化与迁移能力。

Abstract: Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.

</details>


### [517] [Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents](https://arxiv.org/abs/2601.18217)
*Zhihan Liu,Lin Guan,Yixin Nie,Kai Zhang,Zhuoqun Hao,Lin Chen,Asli Celikyilmaz,Zhaoran Wang,Na Zhang*

Main category: cs.AI

TL;DR: 本文研究了通用大语言模型（LLM）智能体在未知测试域下的泛化能力，发现状态信息丰富度和规划复杂度是影响跨域泛化的关键环境因素，而非领域真实性或文本相似性；提出一种低开销的状态随机化方法以增强泛化，并分析了SFT预热/中训练及逐步推理等建模选择对泛化的影响。


<details>
  <summary>Details</summary>
Motivation: 通用LLM智能体常在窄域上后训练，却需部署于更广、未见的领域，本文旨在探究未知测试域下提升其跨域泛化能力的关键因素与有效策略。

Method: 通过系统分析RL环境特性（如状态信息丰富度、规划复杂度）与建模选择（SFT暖启、中训练、逐步推理）对泛化的影响，并提出一种向状态中添加目标无关干扰特征的随机化技术。

Result: 发现状态信息丰富度和规划复杂度显著影响跨域泛化，而领域真实性和文本相似性并非主因；仅增加状态信息丰富度即可提升鲁棒性；SFT中训练会损害未包含域的泛化；逐步推理有助于保持泛化能力。

Conclusion: 提升LLM智能体跨域泛化能力应聚焦于环境状态设计（如适度增加信息丰富度）和推理机制（如启用逐步思考），而非单纯追求环境真实性或数据覆盖；所提随机化方法简单有效，具广泛适用性。

Abstract: Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.

</details>


### [518] [ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants](https://arxiv.org/abs/2601.18225)
*Pei Wang,Yanan Wu,Xiaoshuai Song,Weixun Wang,Gengru Chen,Zhongwen Li,Kezhong Yan,Ken Deng,Qi Liu,Shuaibing Zhao,Shaopan Xiong,Xuepeng Liu,Xuefeng Chen,Wanxi Deng,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: 本文提出了ShopSimulator，一个大规模、具有挑战性的中文购物模拟环境，用于评估和训练基于大语言模型（LLM）的购物代理；实验发现现有LLM在复杂购物任务中表现不佳（全成功率达不到40%），并通过错误分析与SFT+RL联合训练显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏能统一模拟个性化偏好理解、多轮对话交互及高相似商品甄别等关键能力的购物环境，且仅关注评测而忽视训练支持。

Method: 构建ShopSimulator中文购物仿真环境，并在该环境下对多种LLM进行多场景评测；开展错误分析定位瓶颈；探索监督微调（SFT）与强化学习（RL）相结合的训练方法。

Result: 即使最优LLM在ShopSimulator上的全成功率也低于40%；错误分析表明代理在深度搜索、商品选择、个性化线索平衡及用户交互方面存在明显缺陷；SFT+RL联合训练显著提升性能。

Conclusion: ShopSimulator填补了可训练、可评测的中文购物代理基准空白；揭示了当前LLM在真实购物任务中的核心短板，并验证了混合训练策略的有效性。

Abstract: Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.

</details>


### [519] [Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks](https://arxiv.org/abs/2601.18226)
*Haotian Li,Shijun Yang,Weizhen Qi,Silei Zhao,Rui Hua,Mingzhu Song,Xiaojian Yang,Chao Peng*

Main category: cs.AI

TL;DR: 本文提出了一种名为'原位自演化（In-Situ Self-Evolving）'的新范式，使智能体能在无监督、任务持续漂移的开放环境中，通过工具演化自动扩展能力；并实现了Yunjue Agent系统，结合并行批量演化策略，在多个零起点基准上显著超越基线，并支持知识迁移与演化过程量化监控。


<details>
  <summary>Details</summary>
Motivation: 传统智能体系统在任务分布持续漂移、缺乏外部监督的开放环境中表现受限，因其依赖静态工具集或离线训练，导致能力边界僵化且不可知。

Method: 提出In-Situ Self-Evolving范式，将任务交互视为连续经验流，利用执行反馈（尤其是工具使用成败的二值信号）驱动工具的合成、优化与复用；设计Yunjue Agent系统，并引入Parallel Batch Evolution策略提升演化效率；定义新指标监测演化收敛性。

Result: 在五个零起点基准上显著优于专有基线；暖启动实验验证演化所得通用知识可无缝迁移到新领域；提出可量化演化收敛的新指标；开源代码、系统轨迹与演化工具。

Conclusion: 工具驱动的原位自演化是一种可行且高效的构建鲁棒、自适应智能体的路径，为面向真实动态环境的自主智能研究提供了新范式与实证基础。

Abstract: Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.

</details>


### [520] [Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning](https://arxiv.org/abs/2601.18282)
*Lei Wei,Jinpeng Ou,Xiao Peng,Bin Wang*

Main category: cs.AI

TL;DR: 本文提出Think-Augmented Function Calling (TAFC)框架，通过在函数调用中引入显式、分层级（函数级与参数级）的推理机制，提升大语言模型在复杂多参数函数调用中的准确性与可解释性，无需修改模型架构且兼容现有API。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的函数调用机制缺乏对参数生成过程的显式推理透明性，尤其在处理具有相互依赖关系的复杂参数时；链式思维等方法仅作用于智能体层面，无法为单个参数提供细粒度推理指导。

Method: 提出TAFC框架：1）引入通用的'think'参数增强机制，使模型能显式表达决策过程；2）动态优化参数描述以提升推理质量；3）基于复杂度评分自动触发关键参数的细粒度推理；4）采用推理引导优化策略，使生成的推理更符合人类预期。

Result: 在ToolBench基准上，TAFC显著提升了多参数函数的参数生成准确率与推理连贯性，并增强了AI智能体行为调试的可解释性，适用于各类闭源与开源大语言模型。

Conclusion: TAFC是一种轻量、即插即用的函数调用增强框架，在不改变模型结构和API兼容性的前提下，有效兼顾性能提升与推理透明性，为构建可信、可控的自主智能体提供了新路径。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal "think" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.

</details>


### [521] [A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience](https://arxiv.org/abs/2601.18308)
*Geunsik Lim*

Main category: cs.AI

TL;DR: Climate RADAR 是一个基于生成式AI的风险感知、动态响应与行动推荐系统，旨在提升早期预警系统的实际响应效果，通过融合多源数据和受约束的大语言模型，提供个性化防灾建议，并在模拟、用户研究和市政试点中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统早期预警系统虽能快速发布警报，但常无法有效触发及时防护行动，导致可预防的损失和不平等加剧。

Method: 提出 Climate RADAR 系统，整合气象、水文、脆弱性和社会数据构建综合风险指数，并采用嵌入安全护栏的大语言模型，在市民、志愿者和市政多接口上生成个性化行动建议；结合预测分析、行为科学与可信AI方法。

Result: 仿真、用户研究与市政试点表明，该系统提升了防护行动执行率、缩短响应延迟、增强可用性与用户信任。

Conclusion: Climate RADAR 推动了以人为本、透明且公平的早期预警系统发展，为符合合规要求的灾害韧性基础设施提供了可行路径。

Abstract: As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.

</details>


### [522] [Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books](https://arxiv.org/abs/2601.18353)
*Tuhin Chakrabarty,Paramveer S. Dhillon*

Main category: cs.AI

TL;DR: 本研究通过行为实验比较了人类作家与大语言模型（LLM）在模仿50位知名作家风格上的表现，发现经过微调的AI在专家和大众评判中均超越人类，引发关于创意劳动本质与作者身份认同的深刻反思。


<details>
  <summary>Details</summary>
Motivation: 挑战AI无法复制人类创意写作（如声音与风格）的传统假设，探究生成式AI在文学模仿任务中的实际能力及其对创意劳动的影响。

Method: 开展行为实验：28名MFA专业作家与3个LLM竞争模仿50位公认优秀作家的风格；采用双盲配对比较，由28名专家评委和131名非专业评委评估；对比两种AI提示方式（上下文提示 vs. 基于全量作品微调）；辅以专家深度访谈。

Result: 在上下文提示下，专家偏好人写作（82.7%）；但AI经作者全量作品微调后，专家偏好逆转为62%支持AI；而大众评委始终更偏好AI写作；专家访谈揭示其产生身份危机与审美自信动摇。

Conclusion: 生成式AI已能在特定创意任务中系统性超越人类专家，这不仅颠覆了对AI创造力局限性的既有认知，更对创意劳动的价值、作者身份及文学评价标准构成根本性质疑。

Abstract: Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes "good writing." These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.

</details>


### [523] [AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito](https://arxiv.org/abs/2601.18381)
*Yinghan Hou,Zongyou Yang*

Main category: cs.AI

TL;DR: 本文提出了一种基于RAG与大语言模型的AI代理框架，用于将传统Fortran有限差分代码自动迁移至Devito框架，通过知识图谱构建、多级检索、约束代码生成与强化学习驱动的反馈机制，实现动态自适应的代码转换。


<details>
  <summary>Details</summary>
Motivation: 为解决传统有限差分（如Fortran）代码向现代高性能计算框架Devito迁移困难的问题，需克服领域知识复杂、语义鸿沟大、API适配难等挑战。

Method: 构建融合RAG与开源LLM的多阶段LangGraph代理系统；通过文档解析与Leiden社区发现构建Devito知识图谱；利用静态分析逆向生成三层查询策略；设计并行检索、概念扩展与社区级语义检索流水线；采用Pydantic约束保障代码生成结构化；引入RL启发式反馈机制支持迭代优化。

Result: 实现了高精度、可验证的Fortran→Devito代码转换；在地震波模拟、计算流体力学等典型场景中验证了语义一致性、执行正确性、API合规性与数学保真度；显著提升RAG在专业领域查询的准确率与响应效率。

Conclusion: 该AI代理框架不仅提升了科学计算代码迁移的自动化水平，更通过强化学习反馈机制推动代码理解与生成从静态映射迈向动态分析与自适应演化，为HPC领域AI工程化提供了新范式。

Abstract: To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.

</details>


### [524] [Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models](https://arxiv.org/abs/2601.18383)
*Zhenyuan Guo,Tong Chen,Wenlong Meng,Chen Gong,Xin Yu,Chengkun Wei,Wenzhi Chen*

Main category: cs.AI

TL;DR: 本文提出Dynamic Thinking-Token Selection (DynTS)方法，通过分析注意力图识别推理轨迹中起关键决策作用的token，仅保留其KV缓存，从而减少大推理模型（LRMs）的内存与计算开销。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）因生成长推理轨迹导致内存占用高、计算开销大，效率受限；作者发现推理过程中仅少数token对最终答案起决定性作用。

Method: 基于注意力图分析推理轨迹中各token的影响，提出DynTS方法，动态识别并保留决策关键token对应的Key-Value（KV）缓存，剔除冗余KV项。

Result: DynTS显著降低推理过程中的内存占用和计算开销，同时保持模型推理准确性。

Conclusion: 推理轨迹中存在大量冗余token，仅保留关键token的KV缓存即可高效支撑推理，DynTS为提升LRMs效率提供了新思路。

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.

</details>


### [525] [OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents](https://arxiv.org/abs/2601.18467)
*Yuhang Zhou,Kai Zheng,Qiguang Chen,Mengkang Hu,Qingfeng Sun,Can Xu,Jingjing Chen*

Main category: cs.AI

TL;DR: 本文提出了一种无需昂贵在线强化学习即可构建强大深度研究代理的方法，通过开源的离线训练套件（包括DeepForge任务合成框架和大规模高质量数据集）训练出OffSeeker（8B）模型，在多个基准测试中表现优异，甚至媲美30B参数的在线RL训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有高性能深度研究代理依赖成本高昂的在线强化学习，而离线训练受限于高质量研究轨迹数据的稀缺。

Method: 提出完全开源的离线训练套件，包括：1）DeepForge——轻量级、可扩展的研究问题生成框架；2）包含66k QA对、33k监督微调轨迹和21k DPO对的高质量数据集；并基于此完全离线训练OffSeeker（8B）模型。

Result: OffSeeker（8B）在六个基准测试中领先同规模代理，并与30B参数、经繁重在线RL训练的系统性能相当。

Conclusion: 昂贵的在线强化学习并非构建强研究代理的唯一路径，高质量数据与有效离线训练策略足以支撑高性能小模型的开发。

Abstract: Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.

</details>


### [526] [AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security](https://arxiv.org/abs/2601.18491)
*Dongrui Liu,Qihan Ren,Chen Qian,Shuai Shao,Yuejin Xie,Yu Li,Zhonghao Yang,Haoyu Luo,Peng Wang,Qingyu Liu,Binxin Hu,Ling Tang,Jilin Mei,Dadi Guo,Leitao Yuan,Junyao Yang,Guanxu Chen,Qihao Lin,Yi Yu,Bo Zhang,Jiaxuan Guo,Jie Zhang,Wenqi Shao,Huiqi Deng,Zhiheng Xi,Wenjie Wang,Wenxuan Wang,Wen Shen,Zhikai Chen,Haoyu Xie,Jialing Tao,Juntao Dai,Jiaming Ji,Zhongjie Ba,Linfeng Zhang,Yong Liu,Quanshi Zhang,Lei Zhu,Zhihua Wei,Hui Xue,Chaochao Lu,Jing Shao,Xia Hu*

Main category: cs.AI

TL;DR: 本文提出了一种面向AI智能体的新型安全防护框架AgentDoG，基于三维风险分类法构建细粒度安全基准ATBench，并实现可解释的风险诊断与根源分析，支持多模型规模开源。


<details>
  <summary>Details</summary>
Motivation: 当前守卫模型缺乏对智能体风险的感知能力与风险诊断的透明性，难以应对AI智能体自主调用工具和环境交互带来的复杂安全挑战。

Method: 提出统一的三维风险分类法（来源/失败模式/后果），据此构建细粒度安全基准ATBench，并设计Diagnostic Guardrail框架AgentDoG，支持轨迹级细粒度监控与根因诊断；提供Qwen和Llama系列三种参数规模模型。

Result: AgentDoG在多种复杂交互场景中达到智能体安全审核的SOTA性能；所有模型与数据集均已开源。

Conclusion: AgentDoG通过结构化风险建模与可解释诊断，显著提升了AI智能体安全守卫的细粒度、透明性与实用性，为智能体对齐提供了新范式。

Abstract: The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.

</details>


### [527] [DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference](https://arxiv.org/abs/2601.18496)
*Zihan wang,Hao Wang,Shi Feng,Xiaocui Yang,Daling Wang,Yiqun Zhang,Jinghao Lin,Haihua Yang,Xiaozhong Ji*

Main category: cs.AI

TL;DR: 本文提出DeepMed，一种专为医疗领域设计的深度研究（DR）模型，通过多跳医学搜索QA合成数据、难度感知的回合惩罚训练策略以及推理时的假设验证监控机制，显著提升了医疗推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有医疗推理模型受限于参数化知识，易出现遗忘和幻觉；而通用深度研究模型在医疗领域迁移效果有限，主要由于任务特性差异（需临床背景知识）和工具使用扩展问题（盲目调用工具引入噪声）。

Method: 提出DeepMed模型：1）构建多跳医学搜索问答合成数据以适配医疗场景；2）训练中引入难度感知的回合惩罚机制抑制过度工具调用；3）推理阶段加入监控模块，在限定步数内验证假设并防止上下文退化。

Result: 在七个医疗基准测试中，DeepMed平均提升基线模型9.79%，且优于更大规模的医疗推理与深度研究模型。

Conclusion: DeepMed有效弥合了通用深度研究模型在医疗领域应用的两大鸿沟——临床语境理解不足与工具调用失控，为高可信医疗AI推理提供了新范式。

Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus "find it but fail to use it," leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\% on average and outperforms larger medical reasoning and DR models.

</details>


### [528] [Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities](https://arxiv.org/abs/2601.18554)
*Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner*

Main category: cs.AI

TL;DR: 本文提出了MOSAIC框架，用于细粒度评估大语言模型对复杂指令的遵守能力，揭示了不同模型在指令类型、数量和位置上的差异性表现及特定弱点。


<details>
  <summary>Details</summary>
Motivation: 现有基准难以反映真实场景，且无法将指令遵守能力与任务完成能力分离，因此需要更可靠、更细粒度的评估方法。

Method: 提出模块化合成评估框架MOSAIC，利用动态生成的数据集，包含最多20种面向应用的生成约束，实现对指令遵守能力的独立、细致分析。

Result: 在五个不同家族的大语言模型上评估发现：指令遵守能力非单一维度，受约束类型、数量和位置显著影响；存在模型特异性弱点、指令间协同/冲突效应，以及首因/近因等位置偏差。

Conclusion: MOSAIC提供了关键细粒度洞察，有助于诊断模型失败原因，并推动构建对复杂指令严格遵从的更可靠大语言模型。

Abstract: Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.

</details>


### [529] [Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs](https://arxiv.org/abs/2601.18588)
*Xianzhe Meng,Qiangsheng Zeng,Ling Luo,Qinghan Yang,Jiarui Hao,Wenbo Wu,Qinyu Wang,Rui Yin,Lin Qi,Renzhi Lu*

Main category: cs.AI

TL;DR: 本文探讨了大语言模型训练稳定性与生成分布之间的关系，发现稳定训练虽能平滑损失曲线，却可能导致生成熵降低、模式坍缩和重复性输出，表明优化稳定性并不等同于生成质量。


<details>
  <summary>Details</summary>
Motivation: 训练稳定性常被视为大语言模型可靠优化的前提，但其对最终生成分布的影响尚不明确；本文旨在探究稳定训练动态如何影响生成分布的多样性与质量。

Method: 理论分析标准最大似然训练下参数轨迹稳定性与前向KL散度、生成熵的关系，并设计基于反馈的可控训练框架来稳定内部生成统计量以进行实证验证。

Result: 稳定参数轨迹导致模型近似最小化前向KL散度并隐式降低生成熵，引发模式集中与系统性退化；实验显示该效应在不同架构和随机种子下均一致出现低熵、重复输出。

Conclusion: 优化稳定性与生成表现力并非天然一致，仅依赖训练稳定性不足以保证生成质量，需重新审视稳定性作为优化指标的充分性。

Abstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.

</details>


### [530] [A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic](https://arxiv.org/abs/2601.18595)
*Joseph Cotnareanu,Didier Chetelat,Yingxue Zhang,Mark Coates*

Main category: cs.AI

TL;DR: 本文提出了一种结合大语言模型（LLM）与逻辑求解器的迭代方法，利用求解器反馈引导LLM补充缺失的常识性前提，从而提升复杂逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: LLM在复杂证明规划任务中表现不佳；现有逻辑求解器虽高效但无法处理缺失的常识关系。

Method: 设计一种迭代框架：逻辑求解器反馈指导LLM生成并筛选潜在常识性前提，通过搜索控制成本并提升有效性。

Result: 在移除部分常识信息的纯逻辑推理数据集上，该方法显著优于现有技术。

Conclusion: 神经（LLM）与符号（逻辑求解器）方法的协同平衡，对解决人类语境下的推理问题具有重要价值。

Abstract: Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.

</details>


### [531] [PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression](https://arxiv.org/abs/2601.18608)
*Fabian Fumagalli,R. Teal Witter,Christopher Musco*

Main category: cs.AI

TL;DR: 本文提出PolySHAP方法，通过高阶多项式逼近Shapley值游戏，提升估计精度并证明其一致性；同时揭示配对采样（paired sampling）等价于二阶PolySHAP，首次为其优异实践效果提供理论依据。


<details>
  <summary>Details</summary>
Motivation: Shapley值在XAI中重要但计算复杂度高（2^d），KernelSHAP用线性近似缓解该问题，但忽略特征间非线性交互；需更准确、有理论保障的近似方法。

Method: 提出PolySHAP：用高阶多项式（而非线性）逼近Shapley游戏，并结合配对采样技术；理论上证明其Shapley估计的一致性，并揭示配对采样等价于二阶PolySHAP。

Result: PolySHAP在多个基准数据集上比KernelSHAP给出更优的Shapley值估计；严格证明了估计一致性；首次从理论上解释配对采样的有效性——其输出等同于二阶PolySHAP结果。

Conclusion: 高阶多项式逼近是改进Shapley值估计的有效途径；配对采样不仅是启发式技巧，本质上是隐式执行二阶多项式拟合，为KernelSHAP变体提供了坚实理论基础。

Abstract: Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.
  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.
  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.

</details>


### [532] [Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks](https://arxiv.org/abs/2601.18617)
*Pierre Orhan,Pablo Diego-Simón,Emmnanuel Chemla,Yair Lakretz,Yves Boubenec,Jean-Rémi King*

Main category: cs.AI

TL;DR: 本文研究了人工神经网络在训练过程中是否以及何时会出现音素、词汇和句法表征，并发现这些表征按顺序依次出现，但所需数据量远超人类儿童。


<details>
  <summary>Details</summary>
Motivation: 缺乏统一的计算框架来解释语言习得过程中神经表征的形成机制。

Method: 分析语音和文本模型在训练过程中神经激活所形成的子空间结构，考察其是否依次涌现出音素、词汇和句法表征。

Result: 语音和文本模型在训练中依次构建出分别对应音素、词汇和句法结构的神经表征子空间；但所需数据量比儿童多2–4个数量级。

Conclusion: 语言习得的主要阶段可在特定条件下自发涌现，为理解语言习得背后的计算机制提供了新路径。

Abstract: During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.

</details>


### [533] [Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation](https://arxiv.org/abs/2601.18630)
*Abeer Badawi,Md Tahmid Rahman Laskar,Elahe Rahimi,Sheri Grach,Lindsay Bertrand,Lames Danok,Frank Rudzicz,Jimmy Huang,Elham Dolatabadi*

Main category: cs.AI

TL;DR: 本文提出了一种以人类为基准的评估方法，用于评价大语言模型（LLMs）在心理治疗对话中的响应质量；研究发现LLMs在认知支持（如安全性、连贯性、临床适当性）上表现良好，但在情感共鸣（如共情、关系敏感性）方面不稳定，尤其开源模型更显情感扁平；强调需构建兼顾认知准确性和情感敏感性的临床导向评估框架。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康危机持续加剧，存在治疗缺口、资源可及性低及合格治疗师短缺等问题，亟需可扩展的支持方案；尽管LLMs有望提供情绪支持，但其可靠性、治疗相关性及与人类标准的一致性仍存挑战。

Method: 构建包含500个真实场景心理问题的对话数据集，邀请两位精神科训练专家，采用5点李克特量表，依据涵盖认知支持与情感共鸣两大维度的6项指标综合评分，对9个主流闭源与开源LLM生成的回应进行独立双盲评估。

Result: LLMs整体具备强认知可靠性（安全、连贯、临床恰当），但情感对齐不稳定；闭源模型（如GPT-4o）治疗响应更均衡，开源模型表现波动大且情感扁平；揭示了普遍存在的‘认知-情感鸿沟’。

Conclusion: 当前LLM在心理支持中尚难替代人类治疗师，需发展失败感知、临床扎根的评估体系，强调关系敏感性与信息准确性并重；倡导‘人在环路’的平衡评估协议，推动面向心理健康AI的负责任设计与临床监管。

Abstract: The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.

</details>


### [534] [FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory](https://arxiv.org/abs/2601.18642)
*Lei Wei,Xu Dong,Xiao Peng,Niantao Xie,Bin Wang*

Main category: cs.AI

TL;DR: 本文提出FadeMem，一种受生物启发的智能体记忆架构，通过双层记忆层次和自适应指数衰减机制实现选择性遗忘，显著提升多跳推理与检索能力，并减少45%存储开销。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为自主智能体面临记忆限制问题，缺乏类似人类的选择性遗忘机制，导致灾难性遗忘或信息过载。

Method: FadeMem构建双层记忆层次结构，采用基于语义相关性、访问频率和时间模式调制的自适应指数衰减函数实现差异化遗忘；结合大语言模型引导的冲突解决与智能记忆融合，实现相关信息整合与无关信息淡化。

Result: 在Multi-Session Chat、LoCoMo和LTI-Bench基准上验证了FadeMem在多跳推理与检索任务中的优越性能，并实现45%的存储空间缩减。

Conclusion: 引入类人主动遗忘机制可显著提升智能体记忆系统的效率与鲁棒性，为AI记忆建模提供了新的生物学启发范式。

Abstract: Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.

</details>


### [535] [TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent](https://arxiv.org/abs/2601.18700)
*Xingyu Sui,Yanyan Zhao,Yulin Hu,Jiahe Guo,Weixiang Zhao,Bing Qin*

Main category: cs.AI

TL;DR: 本文提出了TEA-Bench，首个用于评估工具增强型情感支持对话（ESC）代理的交互式基准，并构建了TEA-Dialog数据集；实验表明工具增强可提升支持质量、减少幻觉，但效果高度依赖模型能力。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话系统和基准主要关注纯文本中的情感表达，忽视了外部工具在提供事实依据、减少幻觉方面的作用，尤其在多轮交互中缺乏对工具增强型代理的系统性评估。

Method: 构建了首个面向工具增强型ESC代理的交互式基准TEA-Bench，包含真实情感场景、MCP风格工具环境及过程级评估指标；同时发布工具增强对话数据集TEA-Dialog，并开展九种大语言模型的对比实验与监督微调研究。

Result: 工具增强普遍提升情感支持质量并降低幻觉，但增益显著依赖模型能力：强模型能更选择性、有效地使用工具，弱模型仅获边际收益；监督微调在分布内表现提升，但泛化能力差。

Conclusion: 工具使用对构建可信、可靠的情感支持代理至关重要，未来需兼顾模型能力与工具协同机制设计。

Abstract: Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.

</details>


### [536] [Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs](https://arxiv.org/abs/2601.18706)
*Zhichao Yang,Sepehr Janghorbani,Dongxu Zhang,Jun Han,Qian Qian,Andrew Ressler,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

TL;DR: Health-SCORE 是一种可扩展、通用的基于评分标准的训练与评估框架，显著降低医疗领域高质量评分标准构建成本，同时支持强化学习奖励建模和上下文学习提示增强。


<details>
  <summary>Details</summary>
Motivation: 人工构建高质量、领域特定的评分标准（rubrics）在医疗等安全关键领域耗时昂贵，制约了基于评分标准的评估与训练的大规模应用。

Method: 提出 Health-SCORE 框架，将评分标准用于两种新用途：1）作为结构化奖励信号指导安全感知的强化学习；2）嵌入提示中通过上下文学习提升模型响应质量。

Result: 在开放型医疗任务上，Health-SCORE 的评估质量媲美人工制定的评分标准，同时大幅降低开发投入。

Conclusion: Health-SCORE 实现了低成本、高性能、可扩展的医疗领域 LLM 评估与训练，推动 rubric-based 方法的实际落地。

Abstract: Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.

</details>


### [537] [Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules](https://arxiv.org/abs/2601.18716)
*Naeyma N. Islam,Thomas R. Caulfield*

Main category: cs.AI

TL;DR: 本研究提出了一种AI辅助的药物设计新方法，利用E3连接酶导向的分子胶促进阿尔茨海默病关键毒性蛋白Abeta-42通过泛素-蛋白酶体系统（UPS）降解。


<details>
  <summary>Details</summary>
Motivation: Abeta-42在细胞内异常累积是阿尔茨海默病早期致病关键，但靶向清除该蛋白的有效策略仍缺乏；传统药物设计难以高效发现能同时结合Abeta-42与特定E3连接酶的分子胶。

Method: 结合结构建模、ADMET筛选与分子对接评估CRBN/VHL/MDM2三种E3连接酶与Abeta-42形成三元复合物的能力，并开发了融合蛋白序列嵌入与扭转角感知图结构的Ligase-Conditioned JT-VAE生成模型，用于设计E3连接酶特异性的新型分子胶。

Result: 成功构建并验证了LC-JT-VAE模型，生成的分子胶具备化学有效性、新颖性及E3连接酶特异性，可有效介导Abeta-42的UPS依赖性降解。

Conclusion: 该AI驱动的分子胶设计框架为靶向降解Abeta-42及治疗神经退行性疾病提供了新范式和潜在候选化合物。

Abstract: Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.

</details>


### [538] [Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems](https://arxiv.org/abs/2601.18735)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Jing Yang,Jiawei Yao,Jian Wang,Guanlong Qu,Ziliang Chen,Keze Wang*

Main category: cs.AI

TL;DR: 本文提出Agora框架，将多智能体协调问题建模为不确定性资产的去中心化市场，通过经济理性规则实现成本高效协作，在多个多模态基准上显著提升准确率并降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有VLM多智能体系统因信息不对称和启发式协调机制导致成本高昂且次优，缺乏对不确定性和经济成本的联合建模。

Method: 将认知不确定性形式化为可交易资产（感知、语义、推理），设计基于理性经济规则的代理间交易机制，并引入扩展Thompson Sampling的市场感知broker来引导协作。

Result: 在MMMU、MMBench等5个基准上超越强基线：MMMU准确率提升+8.5%，成本降低3倍以上。

Conclusion: 市场驱动的协调是一种原理清晰、可扩展且经济可行的多智能体视觉智能构建范式。

Abstract: Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.

</details>


### [539] [TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models](https://arxiv.org/abs/2601.18744)
*Fangxu Yu,Xingang Guo,Lingzhi Yuan,Haoqiang Kang,Hongyu Zhao,Lianhui Qin,Furong Huang,Bin Hu,Tianyi Zhou*

Main category: cs.AI

TL;DR: 本文提出了TSRBench，一个全面的多模态基准测试，用于评估通用模型在时间序列推理方面的能力，涵盖感知、推理、预测和决策四个维度，并通过实验揭示了现有模型在这些任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有通用模型基准缺乏对时间序列推理能力的评估，而时间序列数据在现实应用中至关重要，因此需要构建专门的基准来填补这一空白。

Method: 构建了一个包含14个领域、4125个问题的多模态时间序列推理基准TSRBench，涵盖感知、推理、预测和决策四大维度及15项具体任务，并对30多个主流大语言模型、视觉语言模型和时序大模型进行了系统评测。

Result: 实验发现：i) 缩放定律在感知与推理任务中成立，但在预测任务中失效；ii) 强大的推理能力不等于准确的上下文感知预测，语义理解与数值预测存在解耦；iii) 当前多模态模型未能有效融合文本与视觉时间序列表征以实现互补增益。

Conclusion: TSRBench为时间序列推理能力提供了标准化评测平台，揭示了当前通用模型的关键挑战，并为未来研究提供重要方向。

Abstract: Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [540] [LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction](https://arxiv.org/abs/2601.18475)
*Xinhui Liu,Can Wang,Lei Liu,Zhenghao Chen,Wei Jiang,Wei Wang,Dong Xu*

Main category: cs.GR

TL;DR: 本文提出StreamLoD-GS，一种面向流式自由视点视频（SFVV）的LoD基高斯溅射框架，通过分层高斯剪枝、GMM运动分割与量化残差精化三项创新，在稀疏输入下实现高效、高保真且低存储的实时FVV重建。


<details>
  <summary>Details</summary>
Motivation: 现有自由视点视频（FVV）重建在实时流式传输中面临稀疏视角输入、训练开销大和带宽受限等瓶颈，尤其3D高斯溅射（3DGS）虽渲染快，但难以满足流式场景对快速优化、稀疏约束下高保真重建及极小存储 footprint 的综合需求。

Method: 提出StreamLoD-GS框架：1）基于Anchor与八叉树的LoD结构化3DGS，结合分层高斯dropout以提升优化效率与稳定性；2）GMM驱动的运动分割机制，分离动静态内容并针对性优化动态区域；3）量化残差精化框架，压缩存储而不损视觉质量。

Result: 实验表明，StreamLoD-GS在重建质量、优化效率和存储占用三方面均达到有竞争力或SOTA水平。

Conclusion: StreamLoD-GS有效解决了SFVV在稀疏输入下的实时性、保真度与轻量化矛盾，为流式自由视点视频提供了实用化新路径。

Abstract: Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [541] [Breaking Task Impasses Quickly: Adaptive Neuro-Symbolic Learning for Open-World Robotics](https://arxiv.org/abs/2601.16985)
*Pierrick Lorang*

Main category: cs.RO

TL;DR: 本文提出了一种结合分层抽象、任务与运动规划（TAMP）及强化学习的神经符号框架，用于提升机器人在开放世界中对未知新事物的快速适应能力。


<details>
  <summary>Details</summary>
Motivation: 自主系统在开放世界环境中应对未知新事物仍面临挑战，现有混合规划与强化学习方法存在样本效率低、适应慢和灾难性遗忘等问题。

Method: 提出一种神经符号框架，融合符号化目标导向学习与基于世界模型的探索，并整合分层抽象、任务与运动规划（TAMP）及强化学习。

Result: 在机器人操作和自动驾驶任务中验证，该方法相比最先进混合方法具有更快收敛速度、更高样本效率和更强鲁棒性。

Conclusion: 该框架展现出在现实世界部署的潜力，为开放世界自主系统提供了更高效、稳健的适应机制。

Abstract: Adapting to unforeseen novelties in open-world environments remains a major challenge for autonomous systems. While hybrid planning and reinforcement learning (RL) approaches show promise, they often suffer from sample inefficiency, slow adaptation, and catastrophic forgetting. We present a neuro-symbolic framework integrating hierarchical abstractions, task and motion planning (TAMP), and reinforcement learning to enable rapid adaptation in robotics. Our architecture combines symbolic goal-oriented learning and world model-based exploration to facilitate rapid adaptation to environmental changes. Validated in robotic manipulation and autonomous driving, our approach achieves faster convergence, improved sample efficiency, and superior robustness over state-of-the-art hybrid methods, demonstrating its potential for real-world deployment.

</details>


### [542] [Advancing Improvisation in Human-Robot Construction Collaboration: Taxonomy and Research Roadmap](https://arxiv.org/abs/2601.17219)
*David Wireko Atibila,Vineet R. Kamat,Carol C. Menassa*

Main category: cs.RO

TL;DR: 本文提出了一种基于即兴能力的六级人机协作（HRC）分类法，涵盖从纯手动操作到真正协同即兴的演进路径；通过系统综述214篇文献，发现当前研究集中于低层级，存在经验学习与协同即兴能力不足等关键缺口，并指出技术、概念与方法三重障碍，建议结合AR/VR、大语言模型与云知识系统推动发展。


<details>
  <summary>Details</summary>
Motivation: 建筑行业面临生产率停滞、技工短缺和安全问题，而现有施工机器人难以适应非结构化、动态的现场环境；人类主导的即兴能力（创造性应对意外情况）是保障流程连续性的关键，亟需构建支持人机协同即兴的理论与技术框架。

Method: 构建一个六级人机协作即兴能力分类学；开展2010–2025年间214篇文献的系统性综述，对施工机器人按即兴能力分级归类；提出五维雷达框架（规划、认知角色、物理执行、学习能力、即兴）刻画演进路径；识别并分析阻碍协同即兴的三类根本障碍。

Result: 确立了覆盖Level 0–6的即兴导向HRC分类体系；揭示当前研究集中于Level 0–3，Level 4–6进展有限；五维雷达图证实人机互补可提升团队绩效；明确三大障碍：具身与对话式推理技术局限、人类即兴与机器人研究间的概念鸿沟、方法论挑战。

Conclusion: 真正的协同即兴是施工人机协作的高阶目标，其实现依赖跨学科融合——尤其需增强人机通信（如AR/VR）、引入大语言模型实现语义理解与决策协同、构建云知识系统支持实时经验共享与演化学习。

Abstract: The construction industry faces productivity stagnation, skilled labor shortages, and safety concerns. While robotic automation offers solutions, construction robots struggle to adapt to unstructured, dynamic sites. Central to this is improvisation, adapting to unexpected situations through creative problem-solving, which remains predominantly human. In construction's unpredictable environments, collaborative human-robot improvisation is essential for workflow continuity. This research develops a six-level taxonomy classifying human-robot collaboration (HRC) based on improvisation capabilities. Through systematic review of 214 articles (2010-2025), we categorize construction robotics across: Manual Work (Level 0), Human-Controlled Execution (Level 1), Adaptive Manipulation (Level 2), Imitation Learning (Level 3), Human-in-Loop BIM Workflow (Level 4), Cloud-Based Knowledge Integration (Level 5), and True Collaborative Improvisation (Level 6). Analysis reveals current research concentrates at lower levels, with critical gaps in experiential learning and limited progression toward collaborative improvisation. A five-dimensional radar framework illustrates progressive evolution of Planning, Cognitive Role, Physical Execution, Learning Capability, and Improvisation, demonstrating how complementary human-robot capabilities create team performance exceeding individual contributions. The research identifies three fundamental barriers: technical limitations in grounding and dialogic reasoning, conceptual gaps between human improvisation and robotics research, and methodological challenges. We recommend future research emphasizing improved human-robot communication via Augmented/Virtual Reality interfaces, large language model integration, and cloud-based knowledge systems to advance toward true collaborative improvisation.

</details>


### [543] [Hierarchical Informative Path Planning via Graph Guidance and Trajectory Optimization](https://arxiv.org/abs/2601.17227)
*Avraiem Iskandar,Shamak Dutta,Kevin Murrant,Yash Vardhan Pant,Stephen L. Smith*

Main category: cs.RO

TL;DR: 本文提出了一种用于障碍密集环境下的分层信息路径规划（IPP）框架，结合图规划与样条优化，在保证性能的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在障碍密集环境中存在局限：图搜索方法需预设测量点，连续轨迹优化则计算开销大且对初值敏感。

Method: 提出三级分层框架：(i) 图结构全局规划；(ii) 基于几何与核函数边界的分段预算分配；(iii) 满足硬约束并剔除障碍的样条局部精细化优化。

Result: 在合成障碍环境和北极实测数据上，该方法相比纯图法和连续优化基线，后验不确定性更低，运行速度提升达9倍（梯度法）至20倍（黑盒优化器）。

Conclusion: 分层设计有效融合全局指导与局部精细化，在复杂环境中实现了高精度与高效率的平衡。

Abstract: We study informative path planning (IPP) with travel budgets in cluttered environments, where an agent collects measurements of a latent field modeled as a Gaussian process (GP) to reduce uncertainty at target locations. Graph-based solvers provide global guarantees but assume pre-selected measurement locations, while continuous trajectory optimization supports path-based sensing but is computationally intensive and sensitive to initialization in obstacle-dense settings. We propose a hierarchical framework with three stages: (i) graph-based global planning, (ii) segment-wise budget allocation using geometric and kernel bounds, and (iii) spline-based refinement of each segment with hard constraints and obstacle pruning. By combining global guidance with local refinement, our method achieves lower posterior uncertainty than graph-only and continuous baselines, while running faster than continuous-space solvers (up to 9x faster than gradient-based methods and 20x faster than black-box optimizers) across synthetic cluttered environments and Arctic datasets.

</details>


### [544] [Real-Time, Energy-Efficient, Sampling-Based Optimal Control via FPGA Acceleration](https://arxiv.org/abs/2601.17231)
*Tanmay Desai,Brian Plancher,R. Iris Bahar*

Main category: cs.RO

TL;DR: 本文提出了一种面向FPGA优化的MPPI控制算法设计，通过深度流水线和跨阶段并行显著提升性能与能效，适用于电池受限的自主移动机器人。


<details>
  <summary>Details</summary>
Motivation: 现有基于GPU/CPU的采样型模型预测控制（如MPPI）在嵌入式AMR平台上难以满足严格的能耗和延迟约束。

Method: 设计一种FPGA优化的MPPI架构，利用细粒度并行、深度流水线及跨算法阶段并行，消除同步瓶颈。

Result: 相比嵌入式GPU和CPU上的优化实现，平均加速3.1x–7.5x，能耗降低2.5x–5.4x。

Conclusion: FPGA是实现边缘机器人高能效、高性能控制的有前景架构。

Abstract: Autonomous mobile robots (AMRs), used for search-and-rescue and remote exploration, require fast and robust planning and control schemes. Sampling-based approaches for Model Predictive Control, especially approaches based on the Model Predictive Path Integral Control (MPPI) algorithm, have recently proven both to be highly effective for such applications and to map naturally to GPUs for hardware acceleration. However, both GPU and CPU implementations of such algorithms can struggle to meet tight energy and latency budgets on battery-constrained AMR platforms that leverage embedded compute. To address this issue, we present an FPGA-optimized MPPI design that exposes fine-grained parallelism and eliminates synchronization bottlenecks via deep pipelining and parallelism across algorithmic stages. This results in an average 3.1x to 7.5x speedup over optimized implementations on an embedded GPU and CPU, respectively, while simultaneously achieving a 2.5x to 5.4x reduction in energy usage. These results demonstrate that FPGA architectures are a promising direction for energy-efficient and high-performance edge robotics.

</details>


### [545] [Quantifying Ergonomics in the Elevate Soft Robotic Suit](https://arxiv.org/abs/2601.17249)
*Peter Bryan,Rejin John Varghese,Dario Farina*

Main category: cs.RO

TL;DR: 本文定量评估了Elevate软体机器人外衣在肩部抬升辅助中的工效学与舒适性，结果显示其施加的压力和组织压缩均在人体可接受范围内，未引起受试者不适，为后续患者研究提供了初步验证。


<details>
  <summary>Details</summary>
Motivation: 软体机器人外衣虽具康复与日常辅助潜力，但受限于数据驱动、用户个性化及以舒适为先的人机界面设计挑战，亟需对其工效学与舒适性进行定量验证。

Method: 采用运动捕捉系统与力传感器，测量Elevate电缆驱动软体外衣在辅助肩部抬升至70度过程中的工效学参数；开展两次4小时实验，施加最高200N电缆张力，并估算肩部压力、躯干与上臂的体积压缩率。

Result: 受试者未报告任何不适；肩部压力约为69.1–85.1 kPa（相当于人手抓握水平）；躯干与上臂体积压缩分别<3%和<8%。

Conclusion: Elevate外衣的工效学设计获得初步验证，具备进一步在患者群体中开展研究的可行性。

Abstract: Soft robotic suits have the potential to rehabilitate, assist, and augment the human body. The low weight, cost, and minimal form-factor of these devices make them ideal for daily use by both healthy and impaired individuals. However, challenges associated with data-driven, user-specific, and comfort-first design of human-robot interfaces using soft materials limit their widespread translation and adoption. In this work, we present the quantitative evaluation of ergonomics and comfort of the Elevate suit - a cable driven soft robotic suit that assists shoulder elevation. Using a motion-capture system and force sensors, we measured the suit's ergonomics during assisted shoulder elevation up to 70 degrees. Two 4-hour sessions were conducted with one subject, involving transmitting cable tensions of up to 200N with no discomfort reported. We estimated that the pressure applied to the shoulder during assisted movements was within the range seen in a human grasp (approximately 69.1-85.1kPa), and estimated volumetric compression of <3% and <8% across the torso and upper arm, respectively. These results provide early validation of Elevate's ergonomic design in preparation for future studies with patient groups.

</details>


### [546] [EMPM: Embodied MPM for Modeling and Simulation of Deformable Objects](https://arxiv.org/abs/2601.17251)
*Yunuo Chen,Yafei Hu,Lingfeng Sun,Tushar Kusnur,Laura Herlant,Chenfanfu Jiang*

Main category: cs.RO

TL;DR: 本文提出了EMPM框架，基于可微分MPM模拟器，从多视角RGB-D视频中重建形变物体的几何与外观，并通过最小化预测与观测视觉数据的差异来模拟物体行为，同时在线优化MPM参数以实现自适应、鲁棒且物理感知的形变物体建模，显著优于弹簧-质点基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法对可变形物体（尤其是连续介质材料）的建模往往过度简化其丰富动力学特性或依赖大量训练数据，导致物理真实性差、泛化能力弱、数据效率低。

Method: 提出基于可微分Material Point Method（MPM）的EMPM框架；从多视角RGB-D视频中重建几何与外观；利用MPM物理引擎模拟物体行为，通过最小化预测与观测视觉数据的差异进行优化；并基于传感器反馈在线优化MPM参数。

Result: EMPM在形变物体建模与仿真任务中显著优于弹簧-质点等基线模型，实现了更物理真实、泛化性强且数据高效的建模能力，并提升了机器人对复杂可变形物体的操作性能。

Conclusion: EMPM为可变形物体提供了兼具物理合理性、通用性与数据效率的建模与仿真新范式，拓展了机器人操作复杂形变物体的能力边界。

Abstract: Modeling deformable objects - especially continuum materials - in a way that is physically plausible, generalizable, and data-efficient remains challenging across 3D vision, graphics, and robotic manipulation. Many existing methods oversimplify the rich dynamics of deformable objects or require large training sets, which often limits generalization. We introduce embodied MPM (EMPM), a deformable object modeling and simulation framework built on a differentiable Material Point Method (MPM) simulator that captures the dynamics of challenging materials. From multi-view RGB-D videos, our approach reconstructs geometry and appearance, then uses an MPM physics engine to simulate object behavior by minimizing the mismatch between predicted and observed visual data. We further optimize MPM parameters online using sensory feedback, enabling adaptive, robust, and physics-aware object representations that open new possibilities for robotic manipulation of complex deformables. Experiments show that EMPM outperforms spring-mass baseline models. Project website: https://embodied-mpm.github.io.

</details>


### [547] [Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots](https://arxiv.org/abs/2601.17287)
*Yanrong Chen,Xihan Bian*

Main category: cs.RO

TL;DR: 本文提出了一种面向NAO人形机器人的实时多模态情感同步框架，通过双通道情感引擎、时长感知的动态时间规整和闭环可行性验证，实现语音韵律与全身姿态的精准协同，显著提升情感对齐度。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人越来越多地进入社交场景，实现情感同步的多模态交互仍面临重大挑战，亟需提升其在服务角色中的实际应用能力。

Method: 提出一种实时框架，包含三个核心创新：（1）双通道情感引擎，利用大语言模型同时生成语境感知文本响应和符合生物力学的运动描述；（2）时长感知的动态时间规整，实现语音与动作关键帧的精确时间对齐；（3）闭环可行性验证，通过实时适配确保动作符合NAO机器人关节物理限制。

Result: 评估显示，相比基于规则的系统，情感对齐度提升21%，通过协调唤醒度驱动的语音音高与上肢运动学，同时保持下肢稳定性。

Conclusion: 该框架通过实现无缝的感觉运动协调，推动了情境感知社交机器人在个性化医疗、互动教育和响应式客户服务等动态场景中的部署。

Abstract: As humanoid robots increasingly introduced into social scene, achieving emotionally synchronized multimodal interaction remains a significant challenges. To facilitate the further adoption and integration of humanoid robots into service roles, we present a real-time framework for NAO robots that synchronizes speech prosody with full-body gestures through three key innovations: (1) A dual-channel emotion engine where large language model (LLM) simultaneously generates context-aware text responses and biomechanically feasible motion descriptors, constrained by a structured joint movement library; (2) Duration-aware dynamic time warping for precise temporal alignment of speech output and kinematic motion keyframes; (3) Closed-loop feasibility verification ensuring gestures adhere to NAO's physical joint limits through real-time adaptation. Evaluations show 21% higher emotional alignment compared to rule-based systems, achieved by coordinating vocal pitch (arousal-driven) with upper-limb kinematics while maintaining lower-body stability. By enabling seamless sensorimotor coordination, this framework advances the deployment of context-aware social robots in dynamic applications such as personalized healthcare, interactive education, and responsive customer service platforms.

</details>


### [548] [Eye-Tracking-Driven Control in Daily Task Assistance for Assistive Robotic Arms](https://arxiv.org/abs/2601.17404)
*Anke Fischer-Janzen,Thomas M. Wendt,Kristof Van Laerhoven*

Main category: cs.RO

TL;DR: 本文提出了一种基于眼动追踪的共享控制框架，利用任务图标作为标记，结合特征匹配方法实现对物体和任务的选择，无需用户位置信息，准确率达97.9%，适用于严重肢体障碍者独立完成日常任务。


<details>
  <summary>Details</summary>
Motivation: 解决当前眼动追踪驱动方法在3D视线估计精度低、多任务间视线意图难区分等问题，提升严重肢体障碍者的自主生活能力。

Method: 采用任务 pictograms 作为 fiducial 标记，结合特征匹配算法，在 eye-in-hand 配置下实现眼动控制；集成先进目标检测模型以支持任务与物体的灵活扩展。

Result: 系统在物体与任务选择识别中准确率达97.9%；发现并改进了评估中的若干问题，总结为可复用的经验教训；框架开源且具备良好可扩展性。

Conclusion: 该眼动驱动共享控制框架有效降低了用户操作负荷，提升了机器人自主性与适应性，为残障人士提供了实用、鲁棒且可定制的人机交互解决方案。

Abstract: Shared control improves Human-Robot Interaction by reducing the user's workload and increasing the robot's autonomy. It allows robots to perform tasks under the user's supervision. Current eye-tracking-driven approaches face several challenges. These include accuracy issues in 3D gaze estimation and difficulty interpreting gaze when differentiating between multiple tasks. We present an eye-tracking-driven control framework, aimed at enabling individuals with severe physical disabilities to perform daily tasks independently. Our system uses task pictograms as fiducial markers combined with a feature matching approach that transmits data of the selected object to accomplish necessary task related measurements with an eye-in-hand configuration. This eye-tracking control does not require knowledge of the user's position in relation to the object. The framework correctly interpreted object and task selection in up to 97.9% of measurements. Issues were found in the evaluation, that were improved and shared as lessons learned. The open-source framework can be adapted to new tasks and objects due to the integration of state-of-the-art object detection models.

</details>


### [549] [DiffusionCinema: Text-to-Aerial Cinematography](https://arxiv.org/abs/2601.17412)
*Valerii Serpiva,Artem Lykov,Jeffrin Sam,Aleksey Fedoseev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 本文提出了一种基于扩散模型的无人机创意拍摄系统，用户通过自然语言描述期望镜头，系统自动生成符合语义与场景几何的飞行轨迹并自主执行，显著降低操作负荷与认知负担。


<details>
  <summary>Details</summary>
Motivation: 传统无人机航拍需手动操控，学习成本高、操作复杂，难以满足普通用户对高质量、创意性视频拍摄的需求；亟需一种更直观、低门槛的人机交互方式。

Method: 结合自然语言提示与机载初始图像，利用扩散模型生成满足场景几何约束和镜头语义的时空运动规划（即飞行轨迹），再由无人机自主执行录制。

Result: 用户实验（NASA-TLX）显示，相比传统遥控器，该系统显著降低总体工作负荷（21.6 vs. 58.1）、心理需求（11.5 vs. 60.5）和挫败感（14.0 vs. 54.5）；生成视频平滑、可复现且语义一致。

Conclusion: 扩散模型可作为‘创意操作员’，实现从文本到电影级航拍的端到端映射，开创了‘文本驱动电影飞行’这一新交互范式。

Abstract: We propose a novel Unmanned Aerial Vehicles (UAV) assisted creative capture system that leverages diffusion models to interpret high-level natural language prompts and automatically generate optimal flight trajectories for cinematic video recording. Instead of manually piloting the drone, the user simply describes the desired shot (e.g., "orbit around me slowly from the right and reveal the background waterfall"). Our system encodes the prompt along with an initial visual snapshot from the onboard camera, and a diffusion model samples plausible spatio-temporal motion plans that satisfy both the scene geometry and shot semantics. The generated flight trajectory is then executed autonomously by the UAV to record smooth, repeatable video clips that match the prompt. User evaluation using NASA-TLX showed a significantly lower overall workload with our interface (M = 21.6) compared to a traditional remote controller (M = 58.1), demonstrating a substantial reduction in perceived effort. Mental demand (M = 11.5 vs. 60.5) and frustration (M = 14.0 vs. 54.5) were also markedly lower for our system, confirming clear usability advantages in autonomous text-driven flight control. This project demonstrates a new interaction paradigm: text-to-cinema flight, where diffusion models act as the "creative operator" converting story intentions directly into aerial motion.

</details>


### [550] [Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.17428)
*Ziming Li,Chenhao Li,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种基于学习进展的自动课程强化学习框架（LP-ACRL），无需先验难度信息即可在线估计学习进展并动态调整任务采样分布，成功使ANYmal D四足机器人在多种复杂地形上实现高速稳定运动。


<details>
  <summary>Details</summary>
Motivation: 现有课程学习方法在扩展到复杂、广泛的任务空间时受限，因缺乏明确定义的难度结构而难以设定任务难度顺序。

Method: 提出LP-ACRL框架，通过在线估计智能体的学习进展，自适应调整任务采样分布，实现无需先验难度知识的自动课程生成。

Result: LP-ACRL训练的策略使ANYmal D四足机器人在楼梯、斜坡、碎石和低摩擦平面等多种地形上实现了2.5 m/s线速度和3.0 rad/s角速度的稳定高速运动，显著优于以往仅能在平坦地形高速或复杂地形低速运行的方法。

Conclusion: LP-ACRL展现出强可扩展性和真实世界适用性，为复杂机器人学习任务空间中的课程生成研究提供了稳健基准。

Abstract: Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.

</details>


### [551] [PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes](https://arxiv.org/abs/2601.17440)
*Xinru Cui,Linxi Feng,Yixuan Zhou,Haoqi Han,Zhe Liu,Hesheng Wang*

Main category: cs.RO

TL;DR: 本文提出PILOT，一种用于感知式运动-操作一体化的单阶段强化学习框架，通过跨模态上下文编码器和专家混合（MoE）策略架构，提升人形机器人在复杂非结构化环境中的稳定性、指令跟踪精度与地形适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有全身控制器缺乏对外部环境的感知能力，难以在复杂、非结构化场景中稳定执行任务。

Method: 提出PILOT框架：1）跨模态上下文编码器融合预测型本体感知特征与基于注意力的感知表征以增强地形感知和足部精确定位；2）采用专家混合（MoE）策略架构协调多样化运动技能。

Result: 在仿真和实机（Unitree G1人形机器人）实验中，PILOT在稳定性、指令跟踪精度和地形通过性方面均优于现有基线方法。

Conclusion: PILOT可作为非结构化场景下运动-操作一体化任务的鲁棒、基础级低层控制器。

Abstract: Humanoid robots hold great potential for diverse interactions and daily service tasks within human-centered environments, necessitating controllers that seamlessly integrate precise locomotion with dexterous manipulation. However, most existing whole-body controllers lack exteroceptive awareness of the surrounding environment, rendering them insufficient for stable task execution in complex, unstructured scenarios.To address this challenge, we propose PILOT, a unified single-stage reinforcement learning (RL) framework tailored for perceptive loco-manipulation, which synergizes perceptive locomotion and expansive whole-body control within a single policy. To enhance terrain awareness and ensure precise foot placement, we design a cross-modal context encoder that fuses prediction-based proprioceptive features with attention-based perceptive representations. Furthermore, we introduce a Mixture-of-Experts (MoE) policy architecture to coordinate diverse motor skills, facilitating better specialization across distinct motion patterns. Extensive experiments in both simulation and on the physical Unitree G1 humanoid robot validate the efficacy of our framework. PILOT demonstrates superior stability, command tracking precision, and terrain traversability compared to existing baselines. These results highlight its potential to serve as a robust, foundational low-level controller for loco-manipulation in unstructured scenes.

</details>


### [552] [EquiForm: Noise-Robust SE(3)-Equivariant Policy Learning from 3D Point Clouds](https://arxiv.org/abs/2601.17486)
*Zhiyuan Zhang,Yu She*

Main category: cs.RO

TL;DR: 本文提出EquiForm，一种针对点云视觉模仿学习的噪声鲁棒SE(3)-等变策略学习框架，通过几何去噪模块和对比等变对齐目标提升在传感器噪声、姿态扰动和遮挡下的泛化能力，在仿真和真实世界任务中均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 点云策略对传感器噪声、姿态扰动和遮挡敏感，破坏几何结构并违背等变性假设，而现有等变方法未显式校正几何偏差或约束表征一致性。

Method: 提出EquiForm框架，包含：1）几何去噪模块以恢复噪声/不完整观测下的稳定3D结构；2）对比等变对齐目标，强制表征在刚体变换和噪声扰动下保持一致；3）融合噪声鲁棒几何推理与现代生成模型的策略学习流程。

Result: 在16个仿真任务和4个真实世界操作任务上评估，相比SOTA点云模仿学习方法，平均性能提升分别为17.2%（仿真）和28.1%（真实世界）。

Conclusion: EquiForm有效提升了点云策略在噪声与几何扰动下的鲁棒性和空间泛化能力，为实际部署提供了更可靠的视觉模仿学习解决方案。

Abstract: Visual imitation learning with 3D point clouds has advanced robotic manipulation by providing geometry-aware, appearance-invariant observations. However, point cloud-based policies remain highly sensitive to sensor noise, pose perturbations, and occlusion-induced artifacts, which distort geometric structure and break the equivariance assumptions required for robust generalization. Existing equivariant approaches primarily encode symmetry constraints into neural architectures, but do not explicitly correct noise-induced geometric deviations or enforce equivariant consistency in learned representations. We introduce EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation. EquiForm formalizes how noise-induced geometric distortions lead to equivariance deviations in observation-to-action mappings, and introduces a geometric denoising module to restore consistent 3D structure under noisy or incomplete observations. In addition, we propose a contrastive equivariant alignment objective that enforces representation consistency under both rigid transformations and noise perturbations. Built upon these components, EquiForm forms a flexible policy learning pipeline that integrates noise-robust geometric reasoning with modern generative models. We evaluate EquiForm on 16 simulated tasks and 4 real-world manipulation tasks across diverse objects and scene layouts. Compared to state-of-the-art point cloud imitation learning methods, EquiForm achieves an average improvement of 17.2% in simulation and 28.1% in real-world experiments, demonstrating strong noise robustness and spatial generalization.

</details>


### [553] [MetaWorld: Skill Transfer and Composition in a Hierarchical World Model for Grounding High-Level Instructions](https://arxiv.org/abs/2601.17507)
*Yutong Shen,Hangxu Liu,Kailin Pei,Ruizhe Xia,Tongtong Feng*

Main category: cs.RO

TL;DR: 本文提出MetaWorld，一种分层世界模型，通过专家策略迁移整合语义规划与物理控制，解决人形机器人运动操作中语义-物理鸿沟问题，在Humanoid-Bench上验证了其在任务完成率和运动连贯性上的优势。


<details>
  <summary>Details</summary>
Motivation: 人形机器人运动操作受限于语义与物理之间的鸿沟，现有方法在强化学习样本效率低、模仿学习泛化性差、视觉语言模型物理不一致三方面存在局限。

Method: 提出MetaWorld分层世界模型：上层由VLM驱动语义规划，下层为紧凑状态空间中的潜在动力学模型；引入动态专家选择与运动先验融合机制，利用预训练多专家策略库实现知识迁移和两阶段在线自适应。

Result: 在Humanoid-Bench实验中，MetaWorld在任务完成率和运动连贯性上优于基于世界模型的强化学习方法。

Conclusion: MetaWorld通过语义-物理协同建模与专家策略迁移，有效弥合语义-物理鸿沟，提升了人形机器人locomanipulation的样本效率、泛化性与物理一致性。

Abstract: Humanoid robot loco-manipulation remains constrained by the semantic-physical gap. Current methods face three limitations: Low sample efficiency in reinforcement learning, poor generalization in imitation learning, and physical inconsistency in VLMs. We propose MetaWorld, a hierarchical world model that integrates semantic planning and physical control via expert policy transfer. The framework decouples tasks into a VLM-driven semantic layer and a latent dynamics model operating in a compact state space. Our dynamic expert selection and motion prior fusion mechanism leverages a pre-trained multi-expert policy library as transferable knowledge, enabling efficient online adaptation via a two-stage framework. VLMs serve as semantic interfaces, mapping instructions to executable skills and bypassing symbol grounding. Experiments on Humanoid-Bench show MetaWorld outperforms world model-based RL in task completion and motion coherence. Our code will be found at https://anonymous.4open.science/r/metaworld-2BF4/

</details>


### [554] [AsterNav: Autonomous Aerial Robot Navigation In Darkness Using Passive Computation](https://arxiv.org/abs/2601.17550)
*Deepak Singh,Shreyas Khobragade,Nitin J. Sanket*

Main category: cs.RO

TL;DR: 本文提出了一种在绝对黑暗环境中实现微型无人机自主导航的新方法AsterNav，结合红外单目相机、大孔径编码镜头与结构光，利用深度相关的离焦线索，通过仿真训练的AsterNet深度估计模型实现实时深度感知，并在真实世界中无需微调即能直接部署，成功率达95.5%。


<details>
  <summary>Details</summary>
Motivation: 灾后搜救常因断电处于绝对黑暗环境，而资源受限的微型空中机器人难以在此类环境中安全导航并搜寻幸存者。

Method: 采用红外单目相机+大孔径编码镜头+结构光组合，提取深度依赖的离焦线索作为先验；设计轻量级深度估计网络AsterNet，在仿真中基于简单光学模型生成数据训练，直接迁移到真实平台；系统完全依赖机载传感与计算（Jetson Orin Nano，20Hz）。

Result: 在无GPS/动捕等外部设施下，完成多组真实黑暗场景实验（含哑光障碍物、细绳（直径6.25mm）等），对未知形状、位置与材质物体实现95.5%导航成功率。

Conclusion: 这是首个实现单目+结构光驱动的四旋翼在绝对黑暗中全自主导航的工作，具备强泛化性、鲁棒性与低成本可部署性。

Abstract: Autonomous aerial navigation in absolute darkness is crucial for post-disaster search and rescue operations, which often occur from disaster-zone power outages. Yet, due to resource constraints, tiny aerial robots, perfectly suited for these operations, are unable to navigate in the darkness to find survivors safely. In this paper, we present an autonomous aerial robot for navigation in the dark by combining an Infra-Red (IR) monocular camera with a large-aperture coded lens and structured light without external infrastructure like GPS or motion-capture. Our approach obtains depth-dependent defocus cues (each structured light point appears as a pattern that is depth dependent), which acts as a strong prior for our AsterNet deep depth estimation model. The model is trained in simulation by generating data using a simple optical model and transfers directly to the real world without any fine-tuning or retraining. AsterNet runs onboard the robot at 20 Hz on an NVIDIA Jetson Orin$^\text{TM}$ Nano. Furthermore, our network is robust to changes in the structured light pattern and relative placement of the pattern emitter and IR camera, leading to simplified and cost-effective construction. We successfully evaluate and demonstrate our proposed depth navigation approach AsterNav using depth from AsterNet in many real-world experiments using only onboard sensing and computation, including dark matte obstacles and thin ropes (diameter 6.25mm), achieving an overall success rate of 95.5% with unknown object shapes, locations and materials. To the best of our knowledge, this is the first work on monocular, structured-light-based quadrotor navigation in absolute darkness.

</details>


### [555] [Correct-by-Construction Vision-based Pose Estimation using Geometric Generative Models](https://arxiv.org/abs/2601.17556)
*Ulices Santa Cruz,Mahmoud Elfar,Yasser Shoukry*

Main category: cs.RO

TL;DR: 本文提出了一种结合物理建模与深度学习的可认证神经网络框架，用于基于视觉的位姿估计，通过几何生成模型（GGM）和可达性分析实现对估计误差的理论保证，并在合成与真实图像（含事件相机数据）上验证了其在无遮挡与遮挡场景下的有效性与安全性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在视觉任务中缺乏输出正确性的可证明保证，而这对安全关键型自主系统至关重要。

Method: 提出一种融合物理驱动建模与学习的可认证神经网络框架：首先构建基于目标物体（如交通标志、跑道标线）几何特性的几何生成模型（GGM），其参数源自成像过程；利用GGM训练具备误差认证保证的位姿估计器；进一步结合神经网络可达性分析设计可认证目标检测器，并构建多阶段感知流水线以扩展至遮挡环境。

Result: 在无遮挡与遮挡环境中均实现了具备理论误差界保证的位姿估计；在合成与真实图像（含事件相机采集数据）上验证了框架有效性，例如成功在事件数据中按认证误差界估计交通标志位姿。

Conclusion: 该框架为安全关键型视觉感知提供了兼具性能与可验证性的新范式，将几何先验与神经网络有机结合，实现了从单目标到复杂场景的可认证推广。

Abstract: We consider the problem of vision-based pose estimation for autonomous systems. While deep neural networks have been successfully used for vision-based tasks, they inherently lack provable guarantees on the correctness of their output, which is crucial for safety-critical applications. We present a framework for designing certifiable neural networks (NNs) for perception-based pose estimation that integrates physics-driven modeling with learning-based estimation. The proposed framework begins by leveraging the known geometry of planar objects commonly found in the environment, such as traffic signs and runway markings, referred to as target objects. At its core, it introduces a geometric generative model (GGM), a neural-network-like model whose parameters are derived from the image formation process of a target object observed by a camera. Once designed, the GGM can be used to train NN-based pose estimators with certified guarantees in terms of their estimation errors. We first demonstrate this framework in uncluttered environments, where the target object is the only object present in the camera's field of view. We extend this using ideas from NN reachability analysis to design certified object NN that can detect the presence of the target object in cluttered environments. Subsequently, the framework consolidates the certified object detector with the certified pose estimator to design a multi-stage perception pipeline that generalizes the proposed approach to cluttered environments, while maintaining its certified guarantees. We evaluate the proposed framework using both synthetic and real images of various planar objects commonly encountered by autonomous vehicles. Using images captured by an event-based camera, we show that the trained encoder can effectively estimate the pose of a traffic sign in accordance with the certified bound provided by the framework.

</details>


### [556] [Delay-Compensated Stiffness Estimation for Robot-Mediated Dyadic Interaction](https://arxiv.org/abs/2601.17812)
*Mingtian Du,Suhas Raghavendra Kulkarni,Bernardo Noronha,Domenico Campolo*

Main category: cs.RO

TL;DR: 本文提出了一种延迟补偿的刚度估计框架，通过准静态平衡推导代数估计器，并结合归一化加权最小二乘（NWLS）滤除动态偏差，显著提升了网络延迟下远程人机交互中患者刚度感知的准确性。


<details>
  <summary>Details</summary>
Motivation: 网络诱导的触觉延迟导致远程康复中患者刚度感知不准确，传统忽略延迟的估计方法因力与位置信号时间错位而误差增大。

Method: 基于准静态平衡推导代数刚度估计器，显式对齐专家输入与新手响应的时间；引入归一化加权最小二乘（NWLS）滤除代数推导引入的动态偏差。

Result: 在H-MAN康复机器人平台上实验表明，该方法在多种人为引入延迟下均显著优于标准估计器，保持稳定跟踪精度。

Conclusion: 所提延迟补偿框架为远程双人交互提供了高保真触觉感知方案，有望提升跨网络治疗场景中刚度评估的可靠性。

Abstract: Robot-mediated human-human (dyadic) interactions enable therapists to provide physical therapy remotely, yet an accurate perception of patient stiffness remains challenging due to network-induced haptic delays. Conventional stiffness estimation methods, which neglect delay, suffer from temporal misalignment between force and position signals, leading to significant estimation errors as delays increase. To address this, we propose a robust, delay-compensated stiffness estimation framework by deriving an algebraic estimator based on quasi-static equilibrium that explicitly accounts for temporally aligning the expert's input with the novice's response. A Normalised Weighted Least Squares (NWLS) implementation is then introduced to robustly filter dynamic bias resulting from the algebraic derivation. Experiments using commercial rehabilitation robots (H-MAN) as the platform demonstrate that the proposed method significantly outperforms the standard estimator, maintaining consistent tracking accuracy under multiple introduced delays. These findings offer a promising solution for achieving high-fidelity haptic perception in remote dyadic interaction, potentially facilitating reliable stiffness assessment in therapeutic settings across networks.

</details>


### [557] [Less Is More: Scalable Visual Navigation from Limited Data](https://arxiv.org/abs/2601.17815)
*Yves Inglin,Jonas Frey,Changan Chen,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种结合经典几何规划器生成的合成轨迹与少量人类示范数据的方法，训练出名为LiMo的基于Transformer的视觉导航策略，显著提升了目标条件下的视觉导航性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在目标条件视觉导航中效果依赖于高质量、多样化的训练数据，而人类示范数据获取成本高且有限。

Method: 利用经典几何规划器生成合成轨迹以补充人类示范；设计并训练基于Transformer的视觉导航策略LiMo，仅需单帧RGB图像即可预测SE(2)轨迹。

Result: 在有限专家示范基础上加入规划器生成监督信号，显著提升导航性能；实机部署验证了方法的有效性；数据多样性比单纯增加数据量更重要。

Conclusion: 面向具身智能的可扩展、几何精确的合成监督是实现数据高效视觉导航的实用路径。

Abstract: Imitation learning provides a powerful framework for goal-conditioned visual navigation in mobile robots, enabling obstacle avoidance while respecting human preferences and social norms. However, its effectiveness depends critically on the quality and diversity of training data. In this work, we show how classical geometric planners can be leveraged to generate synthetic trajectories that complement costly human demonstrations. We train Less is More (LiMo), a transformer-based visual navigation policy that predicts goal-conditioned SE(2) trajectories from a single RGB observation, and find that augmenting limited expert demonstrations with planner-generated supervision yields substantial performance gains. Through ablations and complementary qualitative and quantitative analyses, we characterize how dataset scale and diversity affect planning performance. We demonstrate real-robot deployment and argue that robust visual navigation is enabled not by simply collecting more demonstrations, but by strategically curating diverse, high-quality datasets. Our results suggest that scalable, embodiment-specific geometric supervision is a practical path toward data-efficient visual navigation.

</details>


### [558] [NeuroManip: Prosthetic Hand Manipulation System Based on EMG and Eye Tracking Powered by the Neuromorphic Processor AltAi](https://arxiv.org/abs/2601.17991)
*Roman Akinshin,Elizaveta Lopatina,Kirill Bogatikov,Nikolai Kiz,Anna V. Makarova,Mikhail Lebedev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Valerii Kangler*

Main category: cs.RO

TL;DR: 本文提出了一种结合sEMG与凝视引导视觉的新型神经形态上肢假肢控制系统，基于AltAi芯片实现低功耗、高精度、上下文感知的实时手势识别。


<details>
  <summary>Details</summary>
Motivation: 提升上肢假肢控制的能量效率、安全性与日常实用性，解决传统肌电接口功耗高、缺乏环境上下文理解的问题。

Method: 构建融合表面肌电信号（sEMG）与眼动追踪+场景视觉的神经形态控制架构；将原有GPU训练的EMG分类模型转换为脉冲神经网络，部署于低功耗神经形态处理器AltAi；视觉模块限定当前注视物体对应的安全手势子集以约束决策空间。

Result: 在六类功能手势上达到与最先进肌电接口相当的鲁棒识别性能；引入视觉上下文约束后，准确率提升至约95%，并有效排除不安全、物体不匹配的抓取动作；系统运行功耗低于1瓦，支持轻量化可穿戴实现。

Conclusion: 该神经形态、上下文感知控制器兼具能效性与可靠性，有望显著改善上肢截肢者日常活动中的假肢安全性与可用性。

Abstract: This paper presents a novel neuromorphic control architecture for upper-limb prostheses that combines surface electromyography (sEMG) with gaze-guided computer vision. The system uses a spiking neural network deployed on the neuromorphic processor AltAi to classify EMG patterns in real time while an eye-tracking headset and scene camera identify the object within the user's focus. In our prototype, the same EMG recognition model that was originally developed for a conventional GPU is deployed as a spiking network on AltAi, achieving comparable accuracy while operating in a sub-watt power regime, which enables a lightweight, wearable implementation. For six distinct functional gestures recorded from upper-limb amputees, the system achieves robust recognition performance comparable to state-of-the-art myoelectric interfaces. When the vision pipeline restricts the decision space to three context-appropriate gestures for the currently viewed object, recognition accuracy increases to roughly 95% while excluding unsafe, object-inappropriate grasps. These results indicate that the proposed neuromorphic, context-aware controller can provide energy-efficient and reliable prosthesis control and has the potential to improve safety and usability in everyday activities for people with upper-limb amputation.

</details>


### [559] [Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization](https://arxiv.org/abs/2601.18121)
*Byeonggyeol Choi,Woojin Oh,Jongwoo Lim*

Main category: cs.RO

TL;DR: 本文提出了一种仿真闭环优化框架，将视觉对齐的手-物轨迹转化为物理上可执行的轨迹，通过基于稀疏关键帧的样条参数化和CMA-ES黑箱优化，在保持演示保真度的同时提升物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有大规模手部操作数据集（如DexYCB、HO3D）虽视觉对齐良好，但在物理仿真中常出现穿透、失接触、抓取不稳定等物理不可行问题，制约了强化学习策略训练。

Method: 构建仿真闭环精调框架：将手部运动用低维样条表示（基于稀疏时间关键帧），以高保真物理引擎为黑箱目标函数，采用无梯度优化器CMA-ES联合优化物理成功指标（稳定抓取与抬升）与演示保真度（姿态偏差最小化）。

Result: 相比MANIPTRANS等迁移方法，本方法在重放时手部与物体姿态误差更低，手-物物理交互恢复更准确；能高效生成高保真、物理可行的轨迹数据。

Conclusion: 该方法为将视觉演示转化为物理有效轨迹提供了通用、可扩展的解决方案，显著提升了用于鲁棒策略学习的合成数据质量。

Abstract: Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps.
  We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration.
  Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning.

</details>


### [560] [Quest2ROS2: A ROS 2 Framework for Bi-manual VR Teleoperation](https://arxiv.org/abs/2601.18289)
*Jialong Li,Zhenguo Wang,Tianci Wang,Maj Stenmark,Volker Krueger*

Main category: cs.RO

TL;DR: Quest2ROS2是一个开源的ROS2框架，用于双臂遥操作，通过相对运动控制克服工作空间限制，并提供多种易用与安全功能。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统遥操作系统中工作空间受限、操作不直观的问题，并提升机器人数据收集的可扩展性与操作体验。

Method: 基于VR控制器姿态变化计算机器人相对运动，设计模块化架构，支持“并排”和“镜像”两种控制模式，并集成RViz实时可视化、简化夹爪控制及暂停重置功能。

Result: 实现了直观、姿态无关的双臂遥操作，提升了操作灵活性与安全性，并在多样化平台上验证了可用性。

Conclusion: Quest2ROS2为机器人遥操作与数据收集提供了一个灵活、安全、开源且易于扩展的ROS2解决方案。

Abstract: Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports "Side-by-Side" and "Mirror" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2.

</details>


### [561] [TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion](https://arxiv.org/abs/2601.18323)
*Weishi Mi,Yong Bao,Xiaowei Chi,Xiaozhu Ju,Zhiyuan Qin,Kuangzhi Ge,Kai Tang,Peidong Jia,Shanghang Zhang,Jian Tang*

Main category: cs.RO

TL;DR: 本文提出了一种工具中心的逆动力学模型（TC-IDM），通过将生成世界模型所规划的工具轨迹转化为可执行动作，弥合了视觉规划与物理控制之间的鸿沟，显著提升了机器人在多任务、跨视角及零样本场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）范式依赖大量高质量机器人数据，泛化能力受限；而生成式世界模型虽具潜力，但其像素级规划难以直接映射为物理可执行动作，存在关键鸿沟。

Method: 提出工具中心的逆动力学模型（TC-IDM）：首先从生成视频中通过分割和3D运动估计提取工具点云轨迹；再设计解耦的动作头，将轨迹映射为6自由度末端执行器运动及控制信号。

Result: 在真实世界实验中，TC-IDM驱动的世界模型平均成功率61.11%，简单任务达77.7%，零样本可变形物体任务达38.46%，显著优于端到端VLA基线及其他逆动力学模型。

Conclusion: TC-IDM通过引入以工具轨迹为中介的‘规划-翻译’范式，有效连接高层语义规划与底层物理控制，增强了机器人系统的通用性、鲁棒性与跨任务泛化能力。

Abstract: The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions.
  To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control.
  TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals.
  This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects.
  In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models.

</details>


### [562] [SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation](https://arxiv.org/abs/2601.18442)
*Hongyi Zhao,Shuo Wang,Qijie He,Ziyuan Pu*

Main category: cs.RO

TL;DR: 本文提出SG-CADVLM框架，通过上下文感知解码与多模态输入处理，从事故报告和路网图中生成高保真、可执行的安全关键场景，显著提升风险场景生成率（84.4% vs 12.5%）并缓解VLM幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 真实世界中的安全关键驾驶场景稀少且实车测试成本高、风险大； crash报告虽真实但现有方法难以据此生成多样、物理合理、符合事故特征的仿真场景。

Method: 提出SG-CADVLM：融合上下文感知解码机制的视觉语言模型，支持事故文本报告与道路网络图像联合输入，协同生成道路几何结构与车辆轨迹，抑制VLM对参数化先验知识的过度依赖。

Result: 在关键风险场景生成率上达84.4%，较基线方法（12.5%）提升469%；所有生成场景均可直接用于自动驾驶仿真测试。

Conclusion: SG-CADVLM有效解决了VLM在事故驱动场景生成中的上下文压制与物理失真问题，为自动驾驶安全验证提供了高保真、可执行、可扩展的场景生成新范式。

Abstract: Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.

</details>


### [563] [DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation](https://arxiv.org/abs/2601.18492)
*Zijun Li,Shijie Li,Zhenxi Zhang,Bin Li,Shoujun Zhou*

Main category: cs.RO

TL;DR: 本文提出DV-VLN框架，采用生成-验证范式提升视觉-语言导航（VLN）的鲁棒性与可解释性：先对LLaMA-2进行轻量领域适配生成结构化推理链，再通过真/假验证（TFV）和掩码实体验证（MEV）双通道对候选动作进行多样本验证与重排序。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的VLN方法依赖单次动作决策，易受多视角文本观测噪声、局部匹配偏差及中间推理不完善影响，导致错误累积、泛化能力差。

Method: DV-VLN采用生成-然后验证（generate-then-verify）范式：1）对开源LLaMA-2进行参数高效领域微调，生成结构化导航思维链；2）设计双通道验证机制——True-False Verification（TFV）和Masked-Entity Verification（MEV），对多个采样动作进行独立验证；3）聚合各验证通道的成功率，生成可解释的动作评分并用于重排序。

Result: 在R2R、RxR（英文子集）和REVERIE基准上，DV-VLN持续优于直接预测和纯采样基线，在纯语言VLN方法中性能具竞争力，并优于若干跨模态系统。

Conclusion: 生成-验证范式能有效缓解LLM在VLN中因单步决策带来的误差累积问题，双通道验证机制提升了动作选择的鲁棒性与可解释性，为语言驱动的具身导航提供了新思路。

Abstract: Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN.

</details>


### [564] [SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction](https://arxiv.org/abs/2601.18537)
*Linyong Gan,Zimo Li,Wenxin Xu,Xingjian Li,Jianhua Z. Huang,Enmei Tu,Shuhang Chen*

Main category: cs.RO

TL;DR: 本文提出了一种基于语义关键点（Next Key Point, NKP）的船舶轨迹预测框架，将长时域预测分解为高层语义决策与局部运动建模，显著提升方向一致性和长期预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长时域船舶轨迹预测中难以保持全局方向一致性，易出现漂移或不合理轨迹，主因是复杂航行行为和环境因素带来的累积不确定性。

Method: 提出语义关键点（NKP）条件化轨迹建模框架，通过历史观测预训练-微调策略高效估计NKP先验，将长时域预测解耦为全局语义决策（NKP选择）和局部运动建模。

Result: 在真实AIS数据上的实验表明，该方法在长航程、方向精度和细粒度轨迹预测方面持续优于现有最先进方法。

Conclusion: 语义关键点建模能有效约束轨迹生成空间至语义可行子集，提升长时域预测的物理合理性和鲁棒性。

Abstract: Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.

</details>


### [565] [Fast and Safe Trajectory Optimization for Mobile Manipulators With Neural Configuration Space Distance Field](https://arxiv.org/abs/2601.18548)
*Yulin Li,Zhiyuan Song,Yiming Li,Zhicheng Song,Kai Chen,Chunxin Zheng,Zhihai Bi,Jiahang Cao,Sylvain Calinon,Fan Shi,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出广义构型空间距离场（GCDF），扩展了固定基座机械臂的构型空间距离场（CDF）表示，以支持移动操作机器人的全身体碰撞建模与优化；通过理论证明、神经网络训练与高效序列凸优化框架，实现了在复杂、受限环境中的快速、准确轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 现有移动操作机器人在杂乱受限环境中进行全身轨迹优化困难，主要由于高维非凸性及对快速精确碰撞推理的需求；而配置空间距离场（CDF）虽适用于固定基座机械臂，但难以直接推广至具有无界工作空间和更强基座-机械臂耦合的移动操作机器人。

Method: 提出广义构型空间距离场（GCDF），理论证明其保持欧氏局部距离结构并精确编码全身几何；构建连续神经GCDF的数据生成与训练流程，支持GPU批量查询；设计基于GCDF的高性能序列凸优化框架，包含在线神经约束设定、稀疏感知的并行活跃集检测、以及增量式约束管理。

Result: 实现了在无界工作空间中对含平移与旋转关节的移动操作机器人的精确、平滑、可微分碰撞建模；神经GCDF具备高精度值与梯度；优化器能高效处理数千隐式约束，支持快速重规划。

Conclusion: GCDF为移动操作机器人提供了统一、可微、几何精确的构型空间碰撞表示，所提出的优化框架显著提升了复杂场景下全身运动规划的效率与鲁棒性，推动了移动操作在真实受限环境中的实用化。

Abstract: Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes.

</details>


### [566] [Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation](https://arxiv.org/abs/2601.18569)
*Seokju Lee,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 本文提出了一种基于注意力机制的神经增强卡尔曼滤波器（AttenNKF），用于足式机器人状态估计，通过在不变扩展卡尔曼滤波器（InEKF）中引入注意力驱动的神经补偿器来估计并校正由足部打滑引起的误差。


<details>
  <summary>Details</summary>
Motivation: 足部打滑是足式机器人状态估计误差的主要来源，会破坏无滑移假设并在滤波更新步中引入偏差，需有效估计并补偿该滑移诱导误差。

Method: 在InEKF基础上，增加一个基于注意力机制的神经补偿器，在滤波更新后对状态进行补偿；补偿器在潜在空间中训练，以降低对原始输入尺度的敏感性，并实现结构化的滑移条件补偿，同时保持InEKF递推结构。

Result: 实验表明，AttenNKF相比现有足式机器人状态估计算法性能更优，尤其在易打滑条件下提升显著。

Conclusion: 注意力机制与神经补偿相结合可有效建模并校正滑移引起的系统性偏差，为复杂地形下鲁棒状态估计提供了新思路。

Abstract: In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.

</details>


### [567] [ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection](https://arxiv.org/abs/2601.18629)
*Yiming Wang,Ruogu Zhang,Minyang Li,Hao Shi,Junbo Wang,Deyi Li,Jieji Ren,Wenhai Liu,Weiming Wang,Hao-Shu Fang*

Main category: cs.RO

TL;DR: ExoGS 是一种无需机器人参与的 4D Real-to-Sim-to-Real 框架，通过被动外骨骼 AirExo-3 捕获高精度人体操作轨迹与同步视觉数据，结合 3D 高斯泼溅重建与轻量级掩码适配器，实现环境与交互的联合仿真迁移，显著提升接触密集型操作任务的数据效率与策略泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有 Real-to-Sim-to-Real 方法多关注环境层面的视觉迁移，忽视真实交互（尤其接触丰富任务）的建模，导致纯仿真中交互数据生成困难且低效。

Method: 提出 ExoGS 框架：1）使用自研被动式机器人同构外骨骼 AirExo-3 捕获毫米级精度运动轨迹与同步 RGB 视频；2）将人、物体、环境重建为可编辑的 3D Gaussian Splatting 资产，支持几何一致回放与大规模数据增强；3）引入轻量 Mask Adapter 注入实例级语义以缓解视觉域偏移。

Result: 实验证明 ExoGS 相比基于遥操作的基线方法，在数据效率和策略泛化性上均有显著提升。

Conclusion: ExoGS 为接触密集型机器人操作任务提供了高效、可扩展的现实交互数据采集与策略学习新范式， bridging real interaction and simulation effectively.

Abstract: Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS.

</details>


### [568] [Constraint-Aware Discrete-Time PID Gain Optimization for Robotic Joint Control Under Actuator Saturation](https://arxiv.org/abs/2601.18639)
*Ojasva Mishra,Xiaolong Wu,Min Xu*

Main category: cs.RO

TL;DR: 本文提出了一种面向实际实现的离散时间关节控制分析与调参方法，结合稳定性理论、抗饱和反计算实现和混合认证贝叶斯优化，在模型不确定性和硬件非理想性下显著提升控制鲁棒性与性能。


<details>
  <summary>Details</summary>
Motivation: 传统PID控制在实际机器人系统中因离散执行、执行器饱和、小延迟及测量误差等非理想因素而偏离连续时间理论性能，亟需考虑实现约束的分析与调参方法。

Method: （i）基于Jury准则推导欧拉法和零阶保持（ZOH）离散化下的PI控制器稳定区域；（ii）在饱和主导场景下评估离散反计算抗积分饱和实现；（iii）提出混合认证贝叶斯优化流程，融合解析不稳定性筛查与行为安全性验证，以鲁棒IAE为目标函数并施加超调与饱和占空比软惩罚。

Result: 在模拟不确定性（延迟、噪声、量化、紧饱和）的随机模型族下，鲁棒调参使中位IAE从0.843降至0.430，中位超调保持在2%以下；仿真调参中，认证筛选提前拒绝11.6%的边界内随机增益，提升样本效率。

Conclusion: 实现感知的控制分析与混合认证优化可有效桥接理论PID设计与真实机器人部署需求，在不依赖大量硬件实验的前提下提升鲁棒性与可靠性。

Abstract: The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($τ=1.0$~s, $Δt=0.01$~s, $u\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\%$. In simulation-only tuning, the certification screen rejects $11.6\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments.

</details>


### [569] [A Pragmatic VLA Foundation Model](https://arxiv.org/abs/2601.18692)
*Wei Wu,Fan Lu,Yunnan Wang,Shuai Yang,Shi Liu,Fangjing Wang,Qian Zhu,He Sun,Yong Wang,Shuailei Ma,Yiyu Ren,Kejia Zhang,Hui Yu,Jingmei Zhao,Shuai Zhou,Zhenqi Qiu,Houlong Xiong,Ziyu Wang,Zechen Wang,Ran Cheng,Yong-Lu Li,Yongtao Huang,Xing Zhu,Yujun Shen,Kecheng Zheng*

Main category: cs.RO

TL;DR: 本文提出了LingBot-VLA模型，基于约2万小时来自9种双臂机器人配置的真实世界数据训练，在3个机器人平台上验证了其优越性能和强泛化能力，并提供了高效代码库与开源资源以推动机器人学习领域发展。


<details>
  <summary>Details</summary>
Motivation: 构建一个能在不同任务和机器人平台上可靠泛化、同时兼顾数据与计算成本效率的视觉-语言-动作（VLA）基础模型。

Method: 利用9种双臂机器人配置采集的约20,000小时真实世界数据训练LingBot-VLA模型，并在3个机器人平台、共100个任务（每任务130轮后训练测试）上系统评估；开发高效代码库以提升训练吞吐量。

Result: LingBot-VLA在多项任务中显著优于现有方法，展现出强泛化性；代码库在8-GPU设置下达到261样本/秒/GPU吞吐量，比现有VLA代码库快1.5~2.8倍；全部代码、基模型与基准数据均已开源。

Conclusion: LingBot-VLA兼具高性能、强泛化性与高训练效率，适合真实场景部署，且开源举措有助于推动机器人学习领域的任务难度提升与评估标准规范化。

Abstract: Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.

</details>


### [570] [Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods](https://arxiv.org/abs/2601.18723)
*Mengyuan Liu,Juyi Sheng,Peiming Li,Ziyi Wang,Tianming Xu,Tiantian Xu,Hong Liu*

Main category: cs.RO

TL;DR: 本文提出Eval-Actions基准与AutoEval评估架构，以解决当前机器人模仿学习中缺乏可信评估方法的问题，通过引入多维监督信号和时空聚合等技术，显著提升对策略行为真实性与执行质量的评估能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估范式仅依赖二值成功率，无法衡量信任关键维度（源真实性与执行质量），阻碍了可信评估体系的建立。

Method: 构建包含VA/VLA策略轨迹与人类遥操作数据（含失败案例）的Eval-Actions基准，并设计Expert Grading、Rank-Guided偏好与Chain-of-Thought三类监督信号；提出AutoEval架构，融合时空语义评估与运动学校准信号，AutoEval-P进一步引入GRPO增强逻辑推理。

Result: AutoEval在Expert Grading和Rank-Guided协议下SRCC分别达0.81和0.84；源鉴别准确率达99.6%。

Conclusion: 该工作建立了面向机器人模仿学习的可信评估新范式，为Vision-Action/VLA模型的稳健性与安全性评估提供了可扩展、可解释的标准化框架。

Abstract: Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/.

</details>


### [571] [Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge](https://arxiv.org/abs/2601.18733)
*Li Kang,Heng Zhou,Xiufeng Song,Rui Li,Bruno N. Y. Chen,Ziye Wang,Ximeng Meng,Stone Tao,Yiran Qin,Xiaohong Liu,Ruimao Zhang,Lei Bai,Yilun Du,Hao Su,Philip Torr,Zhenfei Yin,Ruihao Gong,Yejun Zeng,Fengjun Zhong,Shenghao Jin,Jinyang Guo,Xianglong Liu,Xiaojun Jia,Tianqi Shan,Wenqi Ren,Simeng Qin,Jialing Yang,Xiaoyu Ma,Tianxing Chen,Zixuan Li,Zijian Cai,Yan Qin,Yusen Qin,Qiangyu Chen,Kaixuan Wang,Zhaoming Han,Yao Mu,Ping Luo,Yuanqi Yao,Haoming Song,Jan-Nico Zaech,Fabien Despinoy,Danda Pani Paudel,Luc Van Gool*

Main category: cs.RO

TL;DR: 本文介绍了在NeurIPS 2025 Workshop上提出的MARS挑战赛，旨在推动多智能体具身AI系统在规划与控制方面的研究，聚焦于基于视觉语言模型的多智能体协同规划和动态环境中的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI任务日益复杂，单智能体系统难以满足可扩展性、效率和协作性需求；多智能体框架因智能体能力提升、任务分工增效及人机交互增强而成为关键方向。

Method: 提出MARS（Multi-Agent Robotic System）挑战赛，围绕多智能体具身规划（利用VLMs协调任务）和策略执行（动态环境下的机器人操控）两大核心任务开展竞赛评估。

Result: 通过参赛方案评估，获得了关于多智能体具身系统设计与协同机制的实证洞察，验证了VLMs在多智能体任务规划中的潜力及策略执行在动态场景中的可行性。

Conclusion: MARS挑战赛为具身多智能体系统的研究提供了标准化评测平台，推动了面向复杂现实场景的协作式AI系统发展。

Abstract: Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.

</details>


### [572] [Goal-oriented Communication for Fast and Robust Robotic Fault Detection and Recovery](https://arxiv.org/abs/2601.18765)
*Shutong Chen,Adnan Aijaz,Yansha Deng*

Main category: cs.RO

TL;DR: 本文提出了一种面向目标的通信（GoC）框架，通过联合设计通信-计算-控制（3C）环路，以实现快速鲁棒的机器人故障检测与恢复（FDR），显著降低FDR时间并提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有FDR框架存在通信与计算延迟大、运动规划不可靠等问题，根源在于3C环路设计未考虑下游FDR目标。

Method: 提出GoC框架：1）基于3D场景图（3D-SG）进行语义化故障检测；2）采用LoRA微调小语言模型（SLM）并结合知识蒸馏增强其推理与泛化能力以生成恢复动作；3）设计轻量级目标导向数字孪生重建模块，仅用任务相关物体轮廓进行精细化控制。

Result: 仿真表明，GoC框架相较SOTA方法（依赖视觉语言模型检测+大语言模型恢复），FDR时间最多减少82.6%，任务成功率最多提升76%。

Conclusion: GoC框架通过语义感知、轻量智能模型与目标导向数字孪生协同，有效实现了低时延、高鲁棒的机器人FDR，为智能工厂自主系统提供了新范式。

Abstract: Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery.

</details>
