<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 67]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.LG](#cs.LG) [Total: 73]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 26]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs](https://arxiv.org/abs/2511.04727)
*Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 本文提出了IndicVisionBench，首个聚焦印度次大陆的大规模多语言视觉-语言基准，涵盖13个文化主题、10种印度语言和3种多模态任务，揭示现有视觉语言模型在多元文化背景下的性能局限。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型评估基准大多以西方为中心，缺乏对文化多样性和多语言场景的充分覆盖，因此需要一个专注于非西方文化的基准来评估模型在真实多语言环境中的表现。

Method: 构建了一个包含约5K张图像和37K+问答对的多语言多模态基准IndicVisionBench，覆盖英语和10种印度语言，涉及OCR、MMT和VQA三种任务及6类问题类型，并发布了一个跨10种印度语言的平行标注语料库。

Result: 在8个主流视觉语言模型上的实验表明，当前模型在印度语言和文化背景下存在显著性能下降，尤其在低资源语言和复杂文化语境中表现不佳。

Conclusion: IndicVisionBench为评估视觉语言模型在文化多样性和多语言环境下的表现提供了可复现的框架，推动更包容的多模态人工智能研究。

Abstract: Vision-language models (VLMs) have demonstrated impressive generalization
across multimodal tasks, yet most evaluation benchmarks remain Western-centric,
leaving open questions about their performance in culturally diverse and
multilingual settings. To address this gap, we introduce IndicVisionBench, the
first large-scale benchmark centered on the Indian subcontinent. Covering
English and 10 Indian languages, our benchmark spans 3 multimodal tasks,
including Optical Character Recognition (OCR), Multimodal Machine Translation
(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.
Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across
13 culturally grounded topics. In addition, we release a paired parallel corpus
of annotations across 10 Indic languages, creating a unique resource for
analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum
of 8 models, from proprietary closed-source systems to open-weights medium and
large-scale models. Our experiments reveal substantial performance gaps,
underscoring the limitations of current VLMs in culturally diverse contexts. By
centering cultural diversity and multilinguality, IndicVisionBench establishes
a reproducible evaluation framework that paves the way for more inclusive
multimodal research.

</details>


### [2] [Knowledge-based anomaly detection for identifying network-induced shape artifacts](https://arxiv.org/abs/2511.04729)
*Rucha Deshpande,Tahsin Rahman,Miguel Lago,Adarsh Subbaswamy,Jana G. Delfino,Ghada Zamzmi,Elim Thompson,Aldo Badano,Seyed Kahaki*

Main category: cs.CV

TL;DR: 提出一种基于知识的异常检测方法，用于检测合成图像中的网络诱导形状伪影，通过两阶段框架在两个合成乳腺X线数据集上验证了有效性，定量评估和读者研究均显示该方法能有效识别伪影，有助于提升合成数据的质量与安全性。


<details>
  <summary>Details</summary>
Motivation: 合成数据虽能缓解机器学习中的数据稀缺问题，但可能引入影响模型性能和临床应用的伪影和失真，因此需要可靠的质量评估方法来确保其安全使用。

Method: 采用两阶段框架：第一阶段设计新的特征提取器，通过分析解剖边界上的角度梯度分布构建专用特征空间；第二阶段使用孤立森林进行异常检测。

Result: 在CSAW-syn和VMLO-syn两个合成乳腺数据集上，AUC分别为0.97和0.91；人类读片者对最异常分区的平均一致率达到66%和68%，是最低异常分区的1.5-2倍；算法与人工排序的Kendall-Tau相关系数为0.45和0.43。

Conclusion: 该方法推动了合成数据的负责任使用，可帮助开发者依据解剖学约束评估合成图像质量，定位并改进特定问题，从而提高合成数据集的整体质量。

Abstract: Synthetic data provides a promising approach to address data scarcity for
training machine learning models; however, adoption without proper quality
assessments may introduce artifacts, distortions, and unrealistic features that
compromise model performance and clinical utility. This work introduces a novel
knowledge-based anomaly detection method for detecting network-induced shape
artifacts in synthetic images. The introduced method utilizes a two-stage
framework comprising (i) a novel feature extractor that constructs a
specialized feature space by analyzing the per-image distribution of angle
gradients along anatomical boundaries, and (ii) an isolation forest-based
anomaly detector. We demonstrate the effectiveness of the method for
identifying network-induced shape artifacts in two synthetic mammography
datasets from models trained on CSAW-M and VinDr-Mammo patient datasets
respectively. Quantitative evaluation shows that the method successfully
concentrates artifacts in the most anomalous partition (1st percentile), with
AUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study
involving three imaging scientists confirmed that images identified by the
method as containing network-induced shape artifacts were also flagged by human
readers with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the
most anomalous partition, approximately 1.5-2 times higher than the least
anomalous partition. Kendall-Tau correlations between algorithmic and human
rankings were 0.45 and 0.43 for the two datasets, indicating reasonable
agreement despite the challenging nature of subtle artifact detection. This
method is a step forward in the responsible use of synthetic data, as it allows
developers to evaluate synthetic images for known anatomic constraints and
pinpoint and address specific issues to improve the overall quality of a
synthetic dataset.

</details>


### [3] [CPO: Condition Preference Optimization for Controllable Image Generation](https://arxiv.org/abs/2511.04753)
*Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen*

Main category: cs.CV

TL;DR: 本文提出了条件偏好优化（CPO），通过在控制信号上进行偏好学习而非生成图像，解决了文本到图像生成中可控性优化的高成本和混淆因素问题，相较于ControlNet++和DPO方法，在多种控制类型下显著提升了可控性。


<details>
  <summary>Details</summary>
Motivation: 现有的可控文本到图像生成方法如ControlNet++受限于近似误差和高计算成本，而直接偏好优化（DPO）因生成图像中存在质量等混淆因素，难以准确优化可控性。因此需要一种更高效、低方差且避免混淆因素的优化方法。

Method: 提出条件偏好优化（CPO），在控制信号层面构建胜出和失败的控制对（c^w 和 c^l），训练模型偏好更优的控制信号，从而避免图像生成中的不确定性干扰，并降低对比损失的方差。

Result: CPO在多个控制类型上显著优于ControlNet++：语义分割错误率降低超10%，人体姿态降低70%-80%，边缘和深度图一致降低2%-5%；同时减少数据构建的计算与存储开销。

Conclusion: CPO是一种高效、低方差的可控文本到图像生成优化方法，通过在控制条件上进行偏好学习，有效提升了模型可控性，优于现有方法，具有较强的实用性和扩展性。

Abstract: To enhance controllability in text-to-image generation, ControlNet introduces
image-based control signals, while ControlNet++ improves pixel-level cycle
consistency between generated images and the input control signal. To avoid the
prohibitive cost of back-propagating through the sampling process, ControlNet++
optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step
approximation, which not only ignores the contribution of high-noise timesteps
but also introduces additional approximation errors. A straightforward
alternative for optimizing controllability across all timesteps is Direct
Preference Optimization (DPO), a fine-tuning method that increases model
preference for more controllable images ($I^{w}$) over less controllable ones
($I^{l}$). However, due to uncertainty in generative models, it is difficult to
ensure that win--lose image pairs differ only in controllability while keeping
other factors, such as image quality, fixed. To address this, we propose
performing preference learning over control conditions rather than generated
images. Specifically, we construct winning and losing control signals,
$\mathbf{c}^{w}$ and $\mathbf{c}^{l}$, and train the model to prefer
$\mathbf{c}^{w}$. This method, which we term \textit{Condition Preference
Optimization} (CPO), eliminates confounding factors and yields a low-variance
training objective. Our approach theoretically exhibits lower contrastive loss
variance than DPO and empirically achieves superior results. Moreover, CPO
requires less computation and storage for dataset curation. Extensive
experiments show that CPO significantly improves controllability over the
state-of-the-art ControlNet++ across multiple control types: over $10\%$ error
rate reduction in segmentation, $70$--$80\%$ in human pose, and consistent
$2$--$5\%$ reductions in edge and depth maps.

</details>


### [4] [DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation](https://arxiv.org/abs/2511.04766)
*Dhenenjay Yadav,Rohan Sawai*

Main category: cs.CV

TL;DR: 本文提出了DARN，一种针对卫星图像异质性问题的新型解码器架构，通过任务复杂度预测、自适应丢弃调制和动态通道门控，在全微调和高效适应两种范式下均实现了卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基础模型在地理空间分析中表现强大，但标准适配方法未能充分考虑卫星图像的高度异质性，导致性能受限。

Method: 提出DARN架构，包含三个创新：轻量级任务复杂度预测器（TCP）、自适应Dropout调制（ADM）和动态容量门控（DCG），并从理论上证明其优化收敛性和信息瓶颈机制。

Result: 在全微调设置下，DARN在GeoBench上达到86.66% mIoU，超越先前SOTA 5.56个百分点；在冻结主干的高效适应下，在Sen1Floods11上达到90.5% mIoU，并在OOD泛化、鲁棒性和少数类性能方面显著提升。

Conclusion: DARN为利用基础模型进行地理空间分析提供了一种更智能、更鲁棒且高效的解决方案，适用于实际部署中的关键应用。

Abstract: Foundation models (FMs) offer powerful representations for geospatial
analysis, but adapting them effectively remains challenging. Standard
adaptation methods, whether full fine-tuning or efficient frozen-backbone
approaches, typically employ decoders with fixed regularization strategies,
failing to account for the significant heterogeneity in satellite imagery. We
introduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder
architecture designed to address this limitation. DARN integrates three key
innovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates
per-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically
adjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and
(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide
theoretical justifications linking DARN's optimization to stationary point
convergence and its mechanism to adaptive information bottlenecks. Empirically,
DARN demonstrates exceptional performance across both major adaptation
paradigms. In full fine-tuning (unfrozen backbone), DARN achieves a new
state-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp
over prior SOTA). In efficient adaptation (frozen backbone), DARN achieves
SOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering
substantial advantages crucial for real-world deployment: superior
out-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),
enhanced robustness (17% relative reduction in corruption error), and improved
performance on minority classes. DARN offers a more intelligent, robust, and
efficient approach to leveraging FMs in critical geospatial applications.

</details>


### [5] [Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges](https://arxiv.org/abs/2511.05152)
*Adrian Azzarelli,Nantheera Anantrasirichai,David R Bull*

Main category: cs.CV

TL;DR: 本文提出了一种基于稀疏多视角视频的可变形高斯点阵分割方法，通过将前景与背景分离建模，在低预算电影制作条件下实现了高质量、分层动态3D重建，无需密集掩码监督即可生成透明和动态纹理的分割结果。


<details>
  <summary>Details</summary>
Motivation: 现有动态3D重建方法依赖密集多视角视频和大量相机，在电影制作中因预算限制导致相机配置稀疏时表现不佳，难以捕捉复杂动态特征。

Method: 将canonical高斯点和形变场分为前景和背景两部分，使用t=0时刻的稀疏掩码进行初始化；在预训练阶段分别对两部分应用不同损失函数，在动态训练阶段为前景学习颜色、位置和旋转变化，为背景仅学习位置变化。

Result: 在3D和2.5D娱乐数据集上达到SOTA水平，PSNR最高提升3dB，模型大小减小一半；无需密集掩码监督即可实现透明物体和动态纹理的分层重建。

Conclusion: 该方法有效提升了在稀疏视图条件下的动态3D重建质量，兼顾效率与视觉效果，并支持自然的前景-背景分离，适用于实际电影制作场景。

Abstract: Deformable Gaussian Splatting (GS) accomplishes photorealistic dynamic 3-D
reconstruction from dense multi-view video (MVV) by learning to deform a
canonical GS representation. However, in filmmaking, tight budgets can result
in sparse camera configurations, which limits state-of-the-art (SotA) methods
when capturing complex dynamic features. To address this issue, we introduce an
approach that splits the canonical Gaussians and deformation field into
foreground and background components using a sparse set of masks for frames at
t=0. Each representation is separately trained on different loss functions
during canonical pre-training. Then, during dynamic training, different
parameters are modeled for each deformation field following common filmmaking
practices. The foreground stage contains diverse dynamic features so changes in
color, position and rotation are learned. While, the background containing
film-crew and equipment, is typically dimmer and less dynamic so only changes
in point position are learned. Experiments on 3-D and 2.5-D entertainment
datasets show that our method produces SotA qualitative and quantitative
results; up to 3 PSNR higher with half the model size on 3-D scenes. Unlike the
SotA and without the need for dense mask supervision, our method also produces
segmented dynamic reconstructions including transparent and dynamic textures.
Code and video comparisons are available online:
https://interims-git.github.io/

</details>


### [6] [Global 3D Reconstruction of Clouds & Tropical Cyclones](https://arxiv.org/abs/2511.04773)
*Shirin Ermis,Cesar Aybar,Lilli Freischem,Stella Girtsou,Kyriaki-Margarita Bintsi,Emiliano Diaz Salas-Porras,Michael Eisinger,William Jones,Anna Jungbluth,Benoit Tremblay*

Main category: cs.CV

TL;DR: 提出了一种基于预训练-微调框架的机器学习方法，首次实现从多卫星数据生成全球瞬时三维云图，准确重建强热带气旋的三维结构。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏探测热带气旋（TC）结构的卫星观测以及难以解析与TC增强相关的云特性，准确预测TC仍具挑战性。现有3D云重建方法受限于TC罕见区域且对强风暴验证不足。

Method: 采用预训练-微调的机器学习框架，利用具有全球覆盖的多颗卫星数据，将2D卫星图像转换为包含关键云特性的3D云图，并在自建的TC数据集上进行评估。

Result: 首次实现了全球范围内瞬时3D云图生成，能够准确重建强风暴的3D结构，在有无观测数据的情况下均能提供可靠估计。

Conclusion: 该模型不仅扩展了现有卫星观测能力，还能在观测缺失时提供估算，有助于深入理解TC增强机制并提升预报精度。

Abstract: Accurate forecasting of tropical cyclones (TCs) remains challenging due to
limited satellite observations probing TC structure and difficulties in
resolving cloud properties involved in TC intensification. Recent research has
demonstrated the capabilities of machine learning methods for 3D cloud
reconstruction from satellite observations. However, existing approaches have
been restricted to regions where TCs are uncommon, and are poorly validated for
intense storms. We introduce a new framework, based on a
pre-training--fine-tuning pipeline, that learns from multiple satellites with
global coverage to translate 2D satellite imagery into 3D cloud maps of
relevant cloud properties. We apply our model to a custom-built TC dataset to
evaluate performance in the most challenging and relevant conditions. We show
that we can - for the first time - create global instantaneous 3D cloud maps
and accurately reconstruct the 3D structure of intense storms. Our model not
only extends available satellite observations but also provides estimates when
observations are missing entirely. This is crucial for advancing our
understanding of TC intensification and improving forecasts.

</details>


### [7] [EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear](https://arxiv.org/abs/2511.04779)
*Andrea Aspesi,Andrea Simpsi,Aaron Tognoli,Simone Mentasti,Luca Merigo,Matteo Matteucci*

Main category: cs.CV

TL;DR: 本文提出了一种专为基于事件数据的眼动追踪设计的卷积神经网络EETnet，可在资源受限的微控制器上运行，并提供了训练、评估和量化方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的眼动追踪方案多在高性能GPU上验证，缺乏在真实嵌入式设备上的部署能力，限制了其在低功耗场景中的应用。

Method: 设计了两种EETnet架构：一种是在图像网格上检测瞳孔的分类模型，另一种是像素级操作的回归模型，并使用公开数据集进行训练、评估与量化。

Result: EETnet能够在资源受限的微控制器上高效运行，适用于低功耗、低延迟的眼动追踪应用。

Conclusion: EETnet实现了在微控制器上的实时事件驱动眼动追踪，推动了事件相机在嵌入式系统中的实际应用。

Abstract: Event-based cameras are becoming a popular solution for efficient, low-power
eye tracking. Due to the sparse and asynchronous nature of event data, they
require less processing power and offer latencies in the microsecond range.
However, many existing solutions are limited to validation on powerful GPUs,
with no deployment on real embedded devices. In this paper, we present EETnet,
a convolutional neural network designed for eye tracking using purely
event-based data, capable of running on microcontrollers with limited
resources. Additionally, we outline a methodology to train, evaluate, and
quantize the network using a public dataset. Finally, we propose two versions
of the architecture: a classification model that detects the pupil on a grid
superimposed on the original image, and a regression model that operates at the
pixel level.

</details>


### [8] [3D Gaussian Point Encoders](https://arxiv.org/abs/2511.04797)
*Jim James,Ben Wilson,Simon Lucey,James Hays*

Main category: cs.CV

TL;DR: 提出3D高斯点编码器，一种基于学习的3D高斯混合的显式每点嵌入表示，相比PointNet更高效，在速度、内存和计算量上均有显著优势。


<details>
  <summary>Details</summary>
Motivation: 克服隐式表示（如PointNet）在3D识别任务中的效率瓶颈，探索更高效的显式几何表示方法。

Method: 构建基于混合3D高斯的显式表示，采用自然梯度优化和从PointNet蒸馏的技术来学习高斯基，以重建PointNet激活；借鉴3D高斯泼溅的过滤技术加速编码器。

Result: 3D高斯点编码器比PointNet快2.7倍，内存减少46%，FLOPs减少88%；在Mamba3D中快1.27倍，内存和FLOPs分别减少42%和54%，且可在纯CPU设备上实现高帧率。

Conclusion: 3D高斯点编码器是一种高效、轻量化的显式3D表示方法，显著优于传统PointNet，在实际应用中具有优越的性能和部署潜力。

Abstract: In this work, we introduce the 3D Gaussian Point Encoder, an explicit
per-point embedding built on mixtures of learned 3D Gaussians. This explicit
geometric representation for 3D recognition tasks is a departure from widely
used implicit representations such as PointNet. However, it is difficult to
learn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We
develop optimization techniques based on natural gradients and distillation
from PointNets to find a Gaussian Basis that can reconstruct PointNet
activations. The resulting 3D Gaussian Point Encoders are faster and more
parameter efficient than traditional PointNets. As in the 3D reconstruction
literature where there has been considerable interest in the move from implicit
(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can
take advantage of computational geometry heuristics to accelerate 3D Gaussian
Point Encoders further. We extend filtering techniques from 3D Gaussian
Splatting to construct encoders that run 2.7 times faster as a comparable
accuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,
we demonstrate the effectiveness of 3D Gaussian Point Encoders as a component
in Mamba3D, running 1.27 times faster and achieving a reduction in memory and
FLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight
enough to achieve high framerates on CPU-only devices.

</details>


### [9] [Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose](https://arxiv.org/abs/2511.04803)
*Shuo Zhao,Jianxu Chen*

Main category: cs.CV

TL;DR: 本研究以Cellpose为例，系统分析了通用生物医学图像分割模型中的数据冗余和跨域迁移中的灾难性遗忘问题。提出数据量化（DQ）策略，发现仅用10%数据即可达到性能饱和，并利用DQ回放有效缓解遗忘，同时指出训练域顺序对泛化的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决通用生物医学图像分割模型中未被充分探索的两个问题：训练数据冗余程度以及跨域迁移对模型保留能力的影响。

Method: 提出数据量化（DQ）策略构建紧凑且多样化的训练子集；使用MAE嵌入和t-SNE进行潜在空间分析；开展跨域微调实验，评估灾难性遗忘，并测试基于DQ的回放策略及不同训练域顺序的影响。

Result: 在Cyto数据集上，仅使用10%数据即可使分割性能饱和，表明存在显著数据冗余；DQ选择的样本具有更高的特征多样性；跨域微调导致源域性能显著下降；重放5-10%源数据可有效恢复性能；合理的训练域顺序有助于提升泛化并减少遗忘。

Conclusion: 高效的生物医学图像分割训练不仅需要紧凑的数据子集，还需关注模型遗忘问题，采用保留感知的学习策略和合理的领域训练顺序，强调了以数据为中心设计的重要性。

Abstract: Generalist biomedical image segmentation models such as Cellpose are
increasingly applied across diverse imaging modalities and cell types. However,
two critical challenges remain underexplored: (1) the extent of training data
redundancy and (2) the impact of cross domain transfer on model retention. In
this study, we conduct a systematic empirical analysis of these challenges
using Cellpose as a case study. First, to assess data redundancy, we propose a
simple dataset quantization (DQ) strategy for constructing compact yet diverse
training subsets. Experiments on the Cyto dataset show that image segmentation
performance saturates with only 10% of the data, revealing substantial
redundancy and potential for training with minimal annotations. Latent space
analysis using MAE embeddings and t-SNE confirms that DQ selected patches
capture greater feature diversity than random sampling. Second, to examine
catastrophic forgetting, we perform cross domain finetuning experiments and
observe significant degradation in source domain performance, particularly when
adapting from generalist to specialist domains. We demonstrate that selective
DQ based replay reintroducing just 5-10% of the source data effectively
restores source performance, while full replay can hinder target adaptation.
Additionally, we find that training domain sequencing improves generalization
and reduces forgetting in multi stage transfer. Our findings highlight the
importance of data centric design in biomedical image segmentation and suggest
that efficient training requires not only compact subsets but also retention
aware learning strategies and informed domain ordering. The code is available
at https://github.com/MMV-Lab/biomedseg-efficiency.

</details>


### [10] [An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention](https://arxiv.org/abs/2511.04811)
*Shuo Zhao,Yu Zhou,Jianxu Chen*

Main category: cs.CV

TL;DR: 提出一种结合主动学习和伪标签的数据中心AI工作流，用于生物医学图像分割，显著减少人工标注需求的同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在噪声数据上表现不佳，而深度学习模型如nnU-Net需要大量标注数据进行交叉验证，限制了其在缺乏标签数据时的应用；大基础模型虽具零样本泛化能力，但在特定数据集上表现有限。

Method: 利用基础模型生成伪标签，用于nnU-Net的自配置，并通过核心集选择策略选取代表性样本进行少量人工标注，结合主动学习和伪标签进行模型微调。

Result: 该方法在减少人工标注量的同时，保持了与现有先进方法相竞争的分割性能。

Conclusion: 所提数据为中心的工作流有效融合了传统神经网络与大基础模型的优势，为生物医学研究者提供了低标注成本、高性能的图像分割解决方案。

Abstract: Biomedical image segmentation is critical for precise structure delineation
and downstream analysis. Traditional methods often struggle with noisy data,
while deep learning models such as U-Net have set new benchmarks in
segmentation performance. nnU-Net further automates model configuration, making
it adaptable across datasets without extensive tuning. However, it requires a
substantial amount of annotated data for cross-validation, posing a challenge
when only raw images but no labels are available. Large foundation models offer
zero-shot generalizability, but may underperform on specific datasets with
unique characteristics, limiting their direct use for analysis. This work
addresses these bottlenecks by proposing a data-centric AI workflow that
leverages active learning and pseudo-labeling to combine the strengths of
traditional neural networks and large foundation models while minimizing human
intervention. The pipeline starts by generating pseudo-labels from a foundation
model, which are then used for nnU-Net's self-configuration. Subsequently, a
representative core-set is selected for minimal manual annotation, enabling
effective fine-tuning of the nnU-Net model. This approach significantly reduces
the need for manual annotations while maintaining competitive performance,
providing an accessible solution for biomedical researchers to apply
state-of-the-art AI techniques in their segmentation tasks. The code is
available at https://github.com/MMV-Lab/AL_BioMed_img_seg.

</details>


### [11] [Geometry Denoising with Preferred Normal Vectors](https://arxiv.org/abs/2511.04848)
*Manuel Weiß,Lukas Baumgärtner,Roland Herzog,Stephan Schmidt*

Main category: cs.CV

TL;DR: 提出一种基于表面法向量先验知识的几何去噪新方法，通过标签向量进行法向相似性分割，并结合全变分正则化与分裂Bregman优化框架。


<details>
  <summary>Details</summary>
Motivation: 传统几何去噪方法缺乏对表面结构的先验引导，导致细节保留与噪声去除难以平衡，因此需要引入法向先验信息以提升去噪质量。

Method: 引入一组预定义的标签向量作为法向先验，将去噪过程中的法向分配建模为基于相似性的分割问题，并采用全变分正则化和split Bregman（ADMM）算法求解，顶点更新利用二阶形状微积分。

Result: 该方法能有效保留几何细节并去除噪声，在多个几何模型上验证了其优越的去噪性能和法向一致性。

Conclusion: 通过引入法向标签向量先验和分割机制，所提方法在几何去噪任务中实现了更好的细节保持与噪声抑制平衡。

Abstract: We introduce a new paradigm for geometry denoising using prior knowledge
about the surface normal vector. This prior knowledge comes in the form of a
set of preferred normal vectors, which we refer to as label vectors. A
segmentation problem is naturally embedded in the denoising process. The
segmentation is based on the similarity of the normal vector to the elements of
the set of label vectors. Regularization is achieved by a total variation term.
We formulate a split Bregman (ADMM) approach to solve the resulting
optimization problem. The vertex update step is based on second-order shape
calculus.

</details>


### [12] [Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction](https://arxiv.org/abs/2511.04864)
*Kyle Fogarty,Chenyue Cai,Jing Yang,Zhilin Guo,Cengiz Öztireli*

Main category: cs.CV

TL;DR: 提出一种隐式自先验方法，从输入点云中提取形状特定的先验，并嵌入隐式神经表示中，通过联合训练可学习嵌入字典和隐式距离场，利用交叉注意力捕捉重复结构和长程相关性。


<details>
  <summary>Details</summary>
Motivation: 从不规则点云中恢复高质量表面是一个病态问题，需要强几何先验。现有方法依赖外部数据或缺乏对局部细节与整体结构的平衡建模。

Method: 联合训练一个小型可学习嵌入字典与隐式距离场，在每个查询位置通过交叉注意力机制使场关注字典；仅使用自监督点云重建损失进行优化；利用自动微分采样训练后的场以获取密集点和解析法向，并将其集成到鲁棒隐式移动最小二乘（RIMLS）框架中。

Result: 该方法在无需外部训练数据的情况下，优于传统和基于学习的方法，在细节保持和对常见数据退化（如稀疏、噪声）的鲁棒性方面表现更优。

Conclusion: 所提出的混合策略能有效结合自学习先验与输入保真度，在点云重建中实现高质量、高细节的表面恢复。

Abstract: Recovering high-quality surfaces from irregular point cloud is ill-posed
unless strong geometric priors are available. We introduce an implicit
self-prior approach that distills a shape-specific prior directly from the
input point cloud itself and embeds it within an implicit neural
representation. This is achieved by jointly training a small dictionary of
learnable embeddings with an implicit distance field; at every query location,
the field attends to the dictionary via cross-attention, enabling the network
to capture and reuse repeating structures and long-range correlations inherent
to the shape. Optimized solely with self-supervised point cloud reconstruction
losses, our approach requires no external training data. To effectively
integrate this learned prior while preserving input fidelity, the trained field
is then sampled to extract densely distributed points and analytic normals via
automatic differentiation. We integrate the resulting dense point cloud and
corresponding normals into a robust implicit moving least squares (RIMLS)
formulation. We show this hybrid strategy preserves fine geometric details in
the input data, while leveraging the learned prior to regularize sparse
regions. Experiments show that our method outperforms both classical and
learning-based approaches in generating high-fidelity surfaces with superior
detail preservation and robustness to common data degradations.

</details>


### [13] [Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications](https://arxiv.org/abs/2511.04871)
*Gabriel Girard,Manon Edde,Félix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Boré,Maxime Descoteaux,Pierre-Marc Jodoin*

Main category: cs.CV

TL;DR: 提出Clinical-ComBAT方法，用于在多中心临床场景中对扩散MRI数据进行非线性、自适应的站点效应校正。


<details>
  <summary>Details</summary>
Motivation: 传统ComBAT方法受限于线性假设、固定站点数和大样本需求，难以满足临床实际中动态新增站点和小样本的需求。

Method: 提出Clinical-ComBAT，采用非线性多项式模型，以规范站点为参考进行独立站点校正，引入可适应小样本的方差先验、超参数调优和拟合优度评估指标。

Result: 在模拟和真实数据上验证了方法的有效性，显著提升扩散指标的对齐效果，增强规范化建模的适用性。

Conclusion: Clinical-ComBAT克服了现有方法的局限，适用于真实世界中动态、小样本、多中心的DW-MRI数据校正。

Abstract: Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps
are effective for assessing neurodegenerative diseases and microstructural
properties of white matter in large number of brain conditions. However, DW-MRI
inherently limits the combination of data from multiple acquisition sites
without harmonization to mitigate scanner-specific biases. While the widely
used ComBAT method reduces site effects in research, its reliance on linear
covariate relationships, homogeneous populations, fixed site numbers, and well
populated sites constrains its clinical use. To overcome these limitations, we
propose Clinical-ComBAT, a method designed for real-world clinical scenarios.
Clinical-ComBAT harmonizes each site independently, enabling flexibility as new
data and clinics are introduced. It incorporates a non-linear polynomial data
model, site-specific harmonization referenced to a normative site, and variance
priors adaptable to small cohorts. It further includes hyperparameter tuning
and a goodness-of-fit metric for harmonization assessment. We demonstrate its
effectiveness on simulated and real data, showing improved alignment of
diffusion metrics and enhanced applicability for normative modeling.

</details>


### [14] [Validating Vision Transformers for Otoscopy: Performance and Data-Leakage Effects](https://arxiv.org/abs/2511.04872)
*James Ndubuisi,Fernando Auat,Marta Vallejo*

Main category: cs.CV

TL;DR: 本研究比较了Swin Transformer与传统ResNet在耳部疾病诊断中的性能，发现初始高准确率源于数据泄露问题；修正后，模型性能显著下降，表明严谨的数据处理对医学机器学习至关重要。


<details>
  <summary>Details</summary>
Motivation: 由于耳鼻喉专科医生存在27%的误诊率，提高耳部疾病诊断准确性具有重要意义，因此需要评估先进模型（如视觉Transformer）在此任务中的有效性。

Method: 使用来自智利大学临床医院的真实耳镜视频数据集，基于Laplacian和Shannon熵筛选帧并去除空白帧；采用Swin v1、Swin v2和ResNet模型进行比较，在发现数据泄露后重新评估模型性能。

Result: 未修正前Swin v1和Swin v2分别达到100%和99.1%准确率，ResNet为99.5%；修正数据泄露后，Swin v1和Swin v2降至83%，ResNet降至82%。

Conclusion: 尽管视觉Transformer在耳病诊断中展现出潜力，但数据预处理中的漏洞会严重影响结果可靠性；必须平衡模型架构优势与数据质量，以构建可靠的医学AI系统。

Abstract: This study evaluates the efficacy of vision transformer models, specifically
Swin transformers, in enhancing the diagnostic accuracy of ear diseases
compared to traditional convolutional neural networks. With a reported 27%
misdiagnosis rate among specialist otolaryngologists, improving diagnostic
accuracy is crucial. The research utilised a real-world dataset from the
Department of Otolaryngology at the Clinical Hospital of the Universidad de
Chile, comprising otoscopic videos of ear examinations depicting various middle
and external ear conditions. Frames were selected based on the Laplacian and
Shannon entropy thresholds, with blank frames removed. Initially, Swin v1 and
Swin v2 transformer models achieved accuracies of 100% and 99.1%, respectively,
marginally outperforming the ResNet model (99.5%). These results surpassed
metrics reported in related studies. However, the evaluation uncovered a
critical data leakage issue in the preprocessing step, affecting both this
study and related research using the same raw dataset. After mitigating the
data leakage, model performance decreased significantly. Corrected accuracies
were 83% for both Swin v1 and Swin v2, and 82% for the ResNet model. This
finding highlights the importance of rigorous data handling in machine learning
studies, especially in medical applications. The findings indicate that while
vision transformers show promise, it is essential to find an optimal balance
between the benefits of advanced model architectures and those derived from
effective data preprocessing. This balance is key to developing a reliable
machine learning model for diagnosing ear diseases.

</details>


### [15] [Beta Distribution Learning for Reliable Roadway Crash Risk Assessment](https://arxiv.org/abs/2511.04886)
*Ahmad Elallaf,Nathan Jacobs,Xinyue Ye,Mei Chen,Gongbo Liang*

Main category: cs.CV

TL;DR: 提出一种基于卫星图像的地理空间深度学习框架，用于估计致命交通事故风险，并通过输出完整的Beta概率分布来提供不确定性感知的预测。


<details>
  <summary>Details</summary>
Motivation: 传统交通安全研究通常孤立地分析风险因素，忽略了建成环境中的空间复杂性和上下文交互；同时，现有的神经网络方法缺乏对模型不确定性的表达，限制了其在关键决策中的应用。

Method: 利用卫星图像作为综合空间输入，构建一个能够捕捉复杂空间模式和环境风险因素的地理空间深度学习模型，并估计致命事故风险的完整Beta概率分布，从而实现不确定性感知的风险预测。

Result: 模型在召回率上比基线模型提高17-23%，且具有更优的校准性能，能从卫星图像中生成可靠且可解释的风险评估。

Conclusion: 该方法为自动驾驶、城市规划和政策制定提供了可扩展、公平且低成本的道路安全增强工具，推动了可信AI在安全关键领域的应用。

Abstract: Roadway traffic accidents represent a global health crisis, responsible for
over a million deaths annually and costing many countries up to 3% of their
GDP. Traditional traffic safety studies often examine risk factors in
isolation, overlooking the spatial complexity and contextual interactions
inherent in the built environment. Furthermore, conventional Neural
Network-based risk estimators typically generate point estimates without
conveying model uncertainty, limiting their utility in critical
decision-making. To address these shortcomings, we introduce a novel geospatial
deep learning framework that leverages satellite imagery as a comprehensive
spatial input. This approach enables the model to capture the nuanced spatial
patterns and embedded environmental risk factors that contribute to fatal crash
risks. Rather than producing a single deterministic output, our model estimates
a full Beta probability distribution over fatal crash risk, yielding accurate
and uncertainty-aware predictions--a critical feature for trustworthy AI in
safety-critical applications. Our model outperforms baselines by achieving a
17-23% improvement in recall, a key metric for flagging potential dangers,
while delivering superior calibration. By providing reliable and interpretable
risk assessments from satellite imagery alone, our method enables safer
autonomous navigation and offers a highly scalable tool for urban planners and
policymakers to enhance roadway safety equitably and cost-effectively.

</details>


### [16] [Learning to Restore Multi-Degraded Images via Ingredient Decoupling and Task-Aware Path Adaptation](https://arxiv.org/abs/2511.04920)
*Hu Gao,Xiaoning Lei,Ying Zhang,Xichen Xu,Guannan Jiang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 本文提出了一种自适应多退化图像恢复网络IMDNet，通过解耦退化成分并指导路径选择来重建图像，在多退化和单退化任务中均表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像恢复方法大多针对单一退化类型，难以应对真实场景中多种退化共存的问题，限制了其实际应用效果。

Method: 设计退化成分解耦模块（DIDBlock）分离退化特征，结合可学习矩阵的融合模块（FBlock）整合多层级退化信息，并在解码器中引入任务自适应模块（TABlock）动态选择最优恢复路径。

Result: IMDNet在多退化图像恢复任务上表现优异，同时在单退化任务上也保持竞争力，实验验证了其有效性。

Conclusion: 通过解耦退化成分并自适应选择恢复路径，IMDNet能够有效处理复杂的真实世界图像退化问题，提升了图像恢复的实用性和鲁棒性。

Abstract: Image restoration (IR) aims to recover clean images from degraded
observations. Despite remarkable progress, most existing methods focus on a
single degradation type, whereas real-world images often suffer from multiple
coexisting degradations, such as rain, noise, and haze coexisting in a single
image, which limits their practical effectiveness. In this paper, we propose an
adaptive multi-degradation image restoration network that reconstructs images
by leveraging decoupled representations of degradation ingredients to guide
path selection. Specifically, we design a degradation ingredient decoupling
block (DIDBlock) in the encoder to separate degradation ingredients
statistically by integrating spatial and frequency domain information,
enhancing the recognition of multiple degradation types and making their
feature representations independent. In addition, we present fusion block
(FBlock) to integrate degradation information across all levels using learnable
matrices. In the decoder, we further introduce a task adaptation block
(TABlock) that dynamically activates or fuses functional branches based on the
multi-degradation representation, flexibly selecting optimal restoration paths
under diverse degradation conditions. The resulting tightly integrated
architecture, termed IMDNet, is extensively validated through experiments,
showing superior performance on multi-degradation restoration while maintaining
strong competitiveness on single-degradation tasks.

</details>


### [17] [A benchmark multimodal oro-dental dataset for large vision-language models](https://arxiv.org/abs/2511.04948)
*Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib*

Main category: cs.CV

TL;DR: 本文介绍了一个包含8775次牙科检查的多模态数据集，涵盖口腔图像、X光片和文本记录，并通过微调视觉-语言模型验证了其在口腔疾病分类和诊断报告生成中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了推动人工智能在口腔医疗中的应用，需要大规模、多样化的多模态临床数据集来支持模型训练与评估。

Method: 收集了4800名患者八年间的牙科检查数据，包括5万张口腔图像、8056张X光片和详细文本记录，并对Qwen-VL 3B/7B模型进行微调，用于口腔异常分类和诊断报告生成任务。

Result: 微调后的Qwen-VL模型在六类口腔异常分类和诊断报告生成任务中显著优于基线模型（包括GPT-4o），证明了数据集的有效性。

Conclusion: 该数据集为AI驱动的口腔健康研究提供了重要资源，有助于推动多模态人工智能在牙科领域的应用。

Abstract: The advancement of artificial intelligence in oral healthcare relies on the
availability of large-scale multimodal datasets that capture the complexity of
clinical practice. In this paper, we present a comprehensive multimodal
dataset, comprising 8775 dental checkups from 4800 patients collected over
eight years (2018-2025), with patients ranging from 10 to 90 years of age. The
dataset includes 50000 intraoral images, 8056 radiographs, and detailed textual
records, including diagnoses, treatment plans, and follow-up notes. The data
were collected under standard ethical guidelines and annotated for
benchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large
vision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks:
classification of six oro-dental anomalies and generation of complete
diagnostic reports from multimodal inputs. We compared the fine-tuned models
with their base counterparts and GPT-4o. The fine-tuned models achieved
substantial gains over these baselines, validating the dataset and underscoring
its effectiveness in advancing AI-driven oro-dental healthcare solutions. The
dataset is publicly available, providing an essential resource for future
research in AI dentistry.

</details>


### [18] [DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning](https://arxiv.org/abs/2511.04949)
*Tharindu Fernando,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 提出一种基于高维潜在空间表示和多智能体对抗强化学习（MAARL）的新型深度学习框架，用于鲁棒且自适应的深伪检测水印技术。


<details>
  <summary>Details</summary>
Motivation: 现有被动式深伪检测方法难以泛化到新型深伪内容，而主动水印方法在抗良性失真与敏感恶意篡改之间难以平衡。

Method: 在潜在空间中设计可学习的水印嵌入器，结合MAARL范式，通过水印代理与对抗攻击代理的交互，动态优化水印的鲁棒性与脆弱性平衡。

Result: 在CelebA和CelebA-HQ数据集上，面对复杂操作场景，性能超过现有最先进方法，分别提升4.5%和5.3%以上。

Conclusion: 该方法有效提升了水印在复杂环境下的鲁棒性和适应性，为高质合成媒体的可信识别提供了新思路。

Abstract: Rapid advances in generative AI have led to increasingly realistic deepfakes,
posing growing challenges for law enforcement and public trust. Existing
passive deepfake detectors struggle to keep pace, largely due to their
dependence on specific forgery artifacts, which limits their ability to
generalize to new deepfake types. Proactive deepfake detection using watermarks
has emerged to address the challenge of identifying high-quality synthetic
media. However, these methods often struggle to balance robustness against
benign distortions with sensitivity to malicious tampering. This paper
introduces a novel deep learning framework that harnesses high-dimensional
latent space representations and the Multi-Agent Adversarial Reinforcement
Learning (MAARL) paradigm to develop a robust and adaptive watermarking
approach. Specifically, we develop a learnable watermark embedder that operates
in the latent space, capturing high-level image semantics, while offering
precise control over message encoding and extraction. The MAARL paradigm
empowers the learnable watermarking agent to pursue an optimal balance between
robustness and fragility by interacting with a dynamic curriculum of benign and
malicious image manipulations simulated by an adversarial attacker agent.
Comprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that
our method consistently outperforms state-of-the-art approaches, achieving
improvements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under
challenging manipulation scenarios.

</details>


### [19] [CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting](https://arxiv.org/abs/2511.04951)
*Hexu Zhao,Xiwen Min,Xiaoteng Liu,Moonjun Gong,Yiming Li,Ang Li,Saining Xie,Jinyang Li,Aurojit Panda*

Main category: cs.CV

TL;DR: 提出CLM系统，通过将高斯分布卸载到CPU内存并在需要时加载到GPU，实现在单个消费级GPU上渲染大规模3DGS场景。


<details>
  <summary>Details</summary>
Motivation: 3D高斯点阵（3DGS）在渲染大场景时面临显存不足的问题，难以在普通GPU上扩展。

Method: 设计CLM系统，利用3DGS的内存访问模式，采用新型卸载策略，将高斯数据卸载至CPU内存，并通过流水线重叠通信与计算以减少开销。

Result: 在单个RTX4090上成功渲染包含1亿个高斯的大场景，性能优越，并保持高质量重建效果。

Conclusion: CLM有效解决了3DGS在大规模场景下的显存瓶颈，实现了高效、高质量的大场景渲染。

Abstract: 3D Gaussian Splatting (3DGS) is an increasingly popular novel view synthesis
approach due to its fast rendering time, and high-quality output. However,
scaling 3DGS to large (or intricate) scenes is challenging due to its large
memory requirement, which exceed most GPU's memory capacity. In this paper, we
describe CLM, a system that allows 3DGS to render large scenes using a single
consumer-grade GPU, e.g., RTX4090. It does so by offloading Gaussians to CPU
memory, and loading them into GPU memory only when necessary. To reduce
performance and communication overheads, CLM uses a novel offloading strategy
that exploits observations about 3DGS's memory access pattern for pipelining,
and thus overlap GPU-to-CPU communication, GPU computation and CPU computation.
Furthermore, we also exploit observation about the access pattern to reduce
communication volume. Our evaluation shows that the resulting implementation
can render a large scene that requires 100 million Gaussians on a single
RTX4090 and achieve state-of-the-art reconstruction quality.

</details>


### [20] [Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement](https://arxiv.org/abs/2511.04963)
*Xiongri Shen,Jiaqi Wang,Yi Zhong,Zhenxi Song,Leilei Zhao,Yichen Wei,Lingyan Liang,Shuqiang Wang,Baiying Lei,Demao Deng,Zhiguo Zhang*

Main category: cs.CV

TL;DR: 提出PDS方法，通过双模态3D扩散框架和组织细化网络实现fMRI和dMRI的高效合成，在多个数据集上达到先进性能，并在临床诊断中表现良好。


<details>
  <summary>Details</summary>
Motivation: 解决fMRI和dMRI模态缺失问题，克服现有生成模型在信号差异和疾病相关结构整合上的局限性。

Method: 设计模式感知的双模态3D扩散框架用于跨模态学习，并结合组织细化网络与高效的微结构优化机制以保持结构保真度和细节。

Result: 在OASIS-3、ADNI和自建数据集上取得SOTA结果，fMRI合成PSNR/SSIM提升1.54 dB和4.12%，dMRI提升1.02 dB和2.2%；临床实验中对NC/MCI/AD分类准确率分别为67.92%/66.02%/64.15%。

Conclusion: PDS能有效合成高质量fMRI和dMRI图像，显著提升模态补全性能，具备临床应用潜力。

Abstract: Magnetic resonance imaging (MRI), especially functional MRI (fMRI) and
diffusion MRI (dMRI), is essential for studying neurodegenerative diseases.
However, missing modalities pose a major barrier to their clinical use.
Although GAN- and diffusion model-based approaches have shown some promise in
modality completion, they remain limited in fMRI-dMRI synthesis due to (1)
significant BOLD vs. diffusion-weighted signal differences between fMRI and
dMRI in time/gradient axis, and (2) inadequate integration of disease-related
neuroanatomical patterns during generation. To address these challenges, we
propose PDS, introducing two key innovations: (1) a pattern-aware dual-modal 3D
diffusion framework for cross-modality learning, and (2) a tissue refinement
network integrated with a efficient microstructure refinement to maintain
structural fidelity and fine details. Evaluated on OASIS-3, ADNI, and in-house
datasets, our method achieves state-of-the-art results, with PSNR/SSIM scores
of 29.83 dB/90.84\% for fMRI synthesis (+1.54 dB/+4.12\% over baselines) and
30.00 dB/77.55\% for dMRI synthesis (+1.02 dB/+2.2\%). In clinical validation,
the synthesized data show strong diagnostic performance, achieving
67.92\%/66.02\%/64.15\% accuracy (NC vs. MCI vs. AD) in hybrid real-synthetic
experiments. Code is available in \href{https://github.com/SXR3015/PDS}{PDS
GitHub Repository}

</details>


### [21] [Learning Fourier shapes to probe the geometric world of deep neural networks](https://arxiv.org/abs/2511.04970)
*Jian Wang,Yixing Yong,Haixia Bi,Lijun He,Fan Li*

Main category: cs.CV

TL;DR: 提出了一种端到端可微框架，利用优化形状作为语义载体，揭示深度神经网络的几何理解能力，并展示其在解释性和对抗性攻击中的潜力。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络研究主要集中于纹理，而对形状和几何理解关注不足，缺乏有效工具来探测模型的几何感知能力。

Method: 通过傅里叶级数参数化任意形状，结合基于绕数的映射将其转换为像素网格，并引入信号能量约束以提高优化效率和物理合理性。

Result: 优化后的形状能独立引发高置信度分类，精确识别模型关注区域，并可作为通用对抗手段欺骗下游视觉任务。

Conclusion: 该框架为探究DNN的几何认知提供了新工具，推动了对机器视觉感知机制的理解，并开辟了新的研究方向。

Abstract: While both shape and texture are fundamental to visual recognition, research
on deep neural networks (DNNs) has predominantly focused on the latter, leaving
their geometric understanding poorly probed. Here, we show: first, that
optimized shapes can act as potent semantic carriers, generating
high-confidence classifications from inputs defined purely by their geometry;
second, that they are high-fidelity interpretability tools that precisely
isolate a model's salient regions; and third, that they constitute a new,
generalizable adversarial paradigm capable of deceiving downstream visual
tasks. This is achieved through an end-to-end differentiable framework that
unifies a powerful Fourier series to parameterize arbitrary shapes, a winding
number-based mapping to translate them into the pixel grid required by DNNs,
and signal energy constraints that enhance optimization efficiency while
ensuring physically plausible shapes. Our work provides a versatile framework
for probing the geometric world of DNNs and opens new frontiers for challenging
and understanding machine perception.

</details>


### [22] [Challenges in 3D Data Synthesis for Training Neural Networks on Topological Features](https://arxiv.org/abs/2511.04972)
*Dylan Peek,Matthew P. Skerritt,Siddharth Pritam,Stephan Chalup*

Main category: cs.CV

TL;DR: 提出了一种基于Repulsive Surface算法生成带拓扑标签的3D数据集的方法，用于训练和评估TDA中的神经网络估计器，特别是通过3D卷积Transformer架构训练了一个亏格估计网络。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑数据分析方法（如持久同调）计算成本高，且缺乏适用于监督学习的带标签3D数据集，限制了基于神经网络的TDA方法发展。

Method: 使用Repulsive Surface算法系统生成具有可控拓扑不变量（如孔数）的带标签3D数据集，并采用3D卷积Transformer架构训练亏格估计网络。

Result: 成功生成多样化的几何形状与明确拓扑标签的3D数据集，训练的网络在形变增加时准确率下降，表明几何复杂性对泛化能力有显著影响。

Conclusion: 该数据集填补了TDA领域中带标签3D数据生成的空白，为训练和评估神经网络提供了有效工具，同时揭示了几何因素在拓扑估计中的重要性。

Abstract: Topological Data Analysis (TDA) involves techniques of analyzing the
underlying structure and connectivity of data. However, traditional methods
like persistent homology can be computationally demanding, motivating the
development of neural network-based estimators capable of reducing
computational overhead and inference time. A key barrier to advancing these
methods is the lack of labeled 3D data with class distributions and diversity
tailored specifically for supervised learning in TDA tasks. To address this, we
introduce a novel approach for systematically generating labeled 3D datasets
using the Repulsive Surface algorithm, allowing control over topological
invariants, such as hole count. The resulting dataset offers varied geometry
with topological labeling, making it suitable for training and benchmarking
neural network estimators. This paper uses a synthetic 3D dataset to train a
genus estimator network, created using a 3D convolutional transformer
architecture. An observed decrease in accuracy as deformations increase
highlights the role of not just topological complexity, but also geometric
complexity, when training generalized estimators. This dataset fills a gap in
labeled 3D datasets and generation for training and evaluating models and
techniques for TDA.

</details>


### [23] [GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder](https://arxiv.org/abs/2511.04977)
*Heng Er Metilda Chee,Jiayin Wang,Zhiqiang Guo,Weizhi Ma,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了贴纸语义相似性任务的定义，并发布了首个基准数据集Triple-S和轻量级模型GSE，用于学习鲁棒的贴纸嵌入，在多个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于贴纸内容高度多样且具有象征性，现有模型难以理解其语义关系，因此需要专门的任务定义和基准来推动研究。

Method: 提出Triple-S基准（包含905对人工标注的正负样本），并设计了通用贴纸编码器（GSE），利用Triple-S和其他数据集进行训练，以学习有效的贴纸嵌入表示。

Result: 实验表明现有预训练视觉和多模态模型在贴纸语义理解上表现不佳；GSE在未见贴纸上表现优越，并在情绪分类和贴纸检索等下游任务中取得良好效果。

Conclusion: 通过发布Triple-S和GSE，为贴纸理解、检索及多模态生成研究提供了标准化评估工具和强大嵌入模型，推动该领域发展。

Abstract: Stickers have become a popular form of visual communication, yet
understanding their semantic relationships remains challenging due to their
highly diverse and symbolic content. In this work, we formally {define the
Sticker Semantic Similarity task} and introduce {Triple-S}, the first benchmark
for this task, consisting of 905 human-annotated positive and negative sticker
pairs. Through extensive evaluation, we show that existing pretrained vision
and multimodal models struggle to capture nuanced sticker semantics. To address
this, we propose the {General Sticker Encoder (GSE)}, a lightweight and
versatile model that learns robust sticker embeddings using both Triple-S and
additional datasets. GSE achieves superior performance on unseen stickers, and
demonstrates strong results on downstream tasks such as emotion classification
and sticker-to-sticker retrieval. By releasing both Triple-S and GSE, we
provide standardized evaluation tools and robust embeddings, enabling future
research in sticker understanding, retrieval, and multimodal content
generation. The Triple-S benchmark and GSE have been publicly released and are
available here.

</details>


### [24] [Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings](https://arxiv.org/abs/2511.05017)
*Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang*

Main category: cs.CV

TL;DR: 本文指出现有大型视觉语言模型（LVLM）架构中存在对语言模态的固有偏见，并提出通过平均池化视觉特征来优化文本嵌入的方法，以改善视觉 grounding 并减少幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 发现当前LVLM架构在多模态融合中过度偏向语言模态，导致视觉信息利用不足和生成幻觉的问题。

Method: 通过将平均池化的视觉特征融入并优化文本嵌入，缓解语言模态偏差问题。

Result: 该方法显著提升了视觉 grounding 能力，并在多个基准上有效减少了幻觉现象。

Conclusion: 修正文本嵌入以融合视觉信息可有效缓解模态不平衡问题，未来可探索更复杂的融合策略以进一步提升性能。

Abstract: In this work, we identify an inherent bias in prevailing LVLM architectures
toward the language modality, largely resulting from the common practice of
simply appending visual embeddings to the input text sequence. To address this,
we propose a simple yet effective method that refines textual embeddings by
integrating average-pooled visual features. Our approach demonstrably improves
visual grounding and significantly reduces hallucinations on established
benchmarks. While average pooling offers a straightforward, robust, and
efficient means of incorporating visual information, we believe that more
sophisticated fusion methods could further enhance visual grounding and
cross-modal alignment. Given that the primary focus of this work is to
highlight the modality imbalance and its impact on hallucinations -- and to
show that refining textual embeddings with visual information mitigates this
issue -- we leave exploration of advanced fusion strategies for future work.

</details>


### [25] [Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation](https://arxiv.org/abs/2511.05034)
*Jing Jin,Xu Liu,Te Gao,Zhihong Shi,Yixiong Liang,Ruiqing Zheng,Hulin Kuang,Min Zeng,Shichao Kan*

Main category: cs.CV

TL;DR: 提出了一种基于动态残差编码和滑动级别对比学习的全切片图像（WSI）表示方法（DRE-SLCL），通过内存库存储图像块特征并结合采样与检索特征进行残差编码，有效解决了千兆像素级WSI端到端训练的计算难题。


<details>
  <summary>Details</summary>
Motivation: 由于全切片图像包含大量图像块，传统方法难以在单个mini-batch中计算所有块的梯度，受限于GPU内存，因此需要一种高效的端到端WSI表示学习方法。

Method: 采用内存库存储所有WSI的图像块特征；在每个训练batch中，对每张WSI随机采样部分图像块，并从内存库中选取额外特征，通过残差编码生成WSI表示，最后利用滑动级别对比损失进行训练。

Result: 在癌症亚型分类、癌症识别和突变预测任务上的实验表明，所提DRE-SLCL方法显著优于现有方法，验证了其在多种下游任务中的有效性。

Conclusion: DRE-SLCL能够高效地实现端到端的WSI表示学习，通过结合内存库机制与残差编码，在不增加计算负担的情况下提升了模型性能。

Abstract: Whole Slide Image (WSI) representation is critical for cancer subtyping,
cancer recognition and mutation prediction.Training an end-to-end WSI
representation model poses significant challenges, as a standard gigapixel
slide can contain tens of thousands of image tiles, making it difficult to
compute gradients of all tiles in a single mini-batch due to current GPU
limitations. To address this challenge, we propose a method of dynamic residual
encoding with slide-level contrastive learning (DRE-SLCL) for end-to-end WSI
representation. Our approach utilizes a memory bank to store the features of
tiles across all WSIs in the dataset. During training, a mini-batch usually
contains multiple WSIs. For each WSI in the batch, a subset of tiles is
randomly sampled and their features are computed using a tile encoder. Then,
additional tile features from the same WSI are selected from the memory bank.
The representation of each individual WSI is generated using a residual
encoding technique that incorporates both the sampled features and those
retrieved from the memory bank. Finally, the slide-level contrastive loss is
computed based on the representations and histopathology reports ofthe WSIs
within the mini-batch. Experiments conducted over cancer subtyping, cancer
recognition, and mutation prediction tasks proved the effectiveness of the
proposed DRE-SLCL method.

</details>


### [26] [Pressure2Motion: Hierarchical Motion Synthesis from Ground Pressure with Text Guidance](https://arxiv.org/abs/2511.05038)
*Zhengxuan Li,Qinhui Yang,Yiyu Zhuang,Chuan Guo,Xinxin Zuo,Xiaoxiao Long,Yao Yao,Xun Cao,Qiu Shen,Hao Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为Pressure2Motion的新方法，通过地面压力序列和文本提示生成人体运动，无需特殊设备，适用于隐私保护、低光和低成本场景。


<details>
  <summary>Details</summary>
Motivation: 传统动作捕捉需要专用设备，限制了其在隐私敏感或低成本环境中的应用；而仅从压力信号恢复全身运动存在严重不适定问题。

Method: 提出一种生成模型，结合压力特征输入与文本提示作为高层约束，采用双层特征提取器解析压力数据，并利用分层扩散模型生成大尺度运动轨迹和细微姿态调整。

Result: 实验表明该方法能生成高保真、物理合理的动作，在新构建的MPL基准上达到了当前最优性能。

Conclusion: Pressure2Motion是首个结合压力数据与语言先验进行动作生成的工作，为基于压力的动作捕捉建立了新标准。

Abstract: We present Pressure2Motion, a novel motion capture algorithm that synthesizes
human motion from a ground pressure sequence and text prompt. It eliminates the
need for specialized lighting setups, cameras, or wearable devices, making it
suitable for privacy-preserving, low-light, and low-cost motion capture
scenarios. Such a task is severely ill-posed due to the indeterminate nature of
the pressure signals to full-body motion. To address this issue, we introduce
Pressure2Motion, a generative model that leverages pressure features as input
and utilizes a text prompt as a high-level guiding constraint. Specifically,
our model utilizes a dual-level feature extractor that accurately interprets
pressure data, followed by a hierarchical diffusion model that discerns
broad-scale movement trajectories and subtle posture adjustments. Both the
physical cues gained from the pressure sequence and the semantic guidance
derived from descriptive texts are leveraged to guide the motion generation
with precision. To the best of our knowledge, Pressure2Motion is a pioneering
work in leveraging both pressure data and linguistic priors for motion
generation, and the established MPL benchmark is the first benchmark for this
task. Experiments show our method generates high-fidelity, physically plausible
motions, establishing a new state-of-the-art for this task. The codes and
benchmarks will be publicly released upon publication.

</details>


### [27] [Medical Referring Image Segmentation via Next-Token Mask Prediction](https://arxiv.org/abs/2511.05044)
*Xinyu Chen,Yiran Wang,Gaoyang Pang,Jiafu Hao,Chentao Yue,Luping Zhou,Yonghui Li*

Main category: cs.CV

TL;DR: 本文提出NTP-MRISeg，将医学图像指代分割（MRIS）重新定义为基于统一多模态序列的自回归下一个词预测任务，简化模型设计，并通过三种新策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MRIS方法通常依赖复杂的多模态融合或多阶段解码器设计，缺乏简洁高效的统一框架。

Method: 将图像、文本和掩码统一为标记序列，采用自回归下一词预测；提出NkTP减少累积误差，TCL增强边界敏感性，HET优化难例训练。

Result: 在QaTa-COV19和MosMedData+数据集上达到SOTA性能，验证了方法的有效性和泛化能力。

Conclusion: NTP-MRISeg提供了一种简洁、端到端的MRIS新范式，无需模态特定融合或外部分割模型，具有良好的适应性和应用前景。

Abstract: Medical Referring Image Segmentation (MRIS) involves segmenting target
regions in medical images based on natural language descriptions. While
achieving promising results, recent approaches usually involve complex design
of multimodal fusion or multi-stage decoders. In this work, we propose
NTP-MRISeg, a novel framework that reformulates MRIS as an autoregressive
next-token prediction task over a unified multimodal sequence of tokenized
image, text, and mask representations. This formulation streamlines model
design by eliminating the need for modality-specific fusion and external
segmentation models, supports a unified architecture for end-to-end training.
It also enables the use of pretrained tokenizers from emerging large-scale
multimodal models, enhancing generalization and adaptability. More importantly,
to address challenges under this formulation-such as exposure bias, long-tail
token distributions, and fine-grained lesion edges-we propose three novel
strategies: (1) a Next-k Token Prediction (NkTP) scheme to reduce cumulative
prediction errors, (2) Token-level Contrastive Learning (TCL) to enhance
boundary sensitivity and mitigate long-tail distribution effects, and (3) a
memory-based Hard Error Token (HET) optimization strategy that emphasizes
difficult tokens during training. Extensive experiments on the QaTa-COV19 and
MosMedData+ datasets demonstrate that NTP-MRISeg achieves new state-of-the-art
performance, offering a streamlined and effective alternative to traditional
MRIS pipelines.

</details>


### [28] [No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware Test-Time Adaptation for Monocular Depth Estimation](https://arxiv.org/abs/2511.05055)
*Mingyu Sung,Hyeonmin Choe,Il-Min Kim,Sangseok Yun,Jae Mo Kang*

Main category: cs.CV

TL;DR: 本文提出了一种新的测试时自适应（TTA）框架PITTA，用于单目深度估计（MDE），在无相机姿态信息和实例感知图像掩码的条件下显著提升了动态环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法在多样化和动态环境中效果有限，需要一种更有效的方法来提升MDE模型在不同环境条件下的适应能力。

Method: 提出PITTA框架，采用姿态无关的TTA范式和实例感知图像掩码策略，并结合边缘提取方法增强输入图像和深度图。

Result: 在DrivingStereo和Waymo数据集上的实验表明，PITTA在不同环境条件下显著优于现有最先进方法。

Conclusion: PITTA通过无需姿态信息和动态对象掩码的创新策略，有效提升了单目深度估计在真实动态场景中的测试时自适应性能。

Abstract: Monocular depth estimation (MDE), inferring pixel-level depths in single RGB
images from a monocular camera, plays a crucial and pivotal role in a variety
of AI applications demanding a three-dimensional (3D) topographical scene. In
the real-world scenarios, MDE models often need to be deployed in environments
with different conditions from those for training. Test-time (domain)
adaptation (TTA) is one of the compelling and practical approaches to address
the issue. Although there have been notable advancements in TTA for MDE,
particularly in a self-supervised manner, existing methods are still
ineffective and problematic when applied to diverse and dynamic environments.
To break through this challenge, we propose a novel and high-performing TTA
framework for MDE, named PITTA. Our approach incorporates two key innovative
strategies: (i) pose-agnostic TTA paradigm for MDE and (ii) instance-aware
image masking. Specifically, PITTA enables highly effective TTA on a pretrained
MDE network in a pose-agnostic manner without resorting to any camera pose
information. Besides, our instance-aware masking strategy extracts
instance-wise masks for dynamic objects (e.g., vehicles, pedestrians, etc.)
from a segmentation mask produced by a pretrained panoptic segmentation
network, by removing static objects including background components. To further
boost performance, we also present a simple yet effective edge extraction
methodology for the input image (i.e., a single monocular image) and depth map.
Extensive experimental evaluations on DrivingStereo and Waymo datasets with
varying environmental conditions demonstrate that our proposed framework,
PITTA, surpasses the existing state-of-the-art techniques with remarkable
performance improvements in MDE during TTA.

</details>


### [29] [Role-SynthCLIP: A Role Play Driven Diverse Synthetic Data Approach](https://arxiv.org/abs/2511.05057)
*Yuanxiang Huangfu,Chaochao Wang,Weilei Wang*

Main category: cs.CV

TL;DR: 提出Role-SynthCLIP，利用多视角角色扮演提示生成语义多样化的图像文本对，提升CLIP模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据方法侧重增加数据量，但语义多样性不足，导致文本描述冗余或浅层。

Method: 设计多视角角色扮演提示（如构图分析师、图像上下文解释者），指导多模态大模型生成多样化、细粒度的图像描述。

Result: 在仅100万对合成数据下，CLIP-B/16模型在MS COCO上达到64.1%的Recall@1，超过使用500万对数据的现有最佳方法2.8个百分点。

Conclusion: Role-SynthCLIP通过提升语义多样性和图文对齐质量，显著增强合成数据的有效性与训练效率。

Abstract: The effectiveness of Contrastive Language-Image Pre-training (CLIP) models
critically depends on the semantic diversity and quality of their training
data. However, while existing synthetic data generation methods primarily focus
on increasing data volume, such emphasis often leads to limited semantic
diversity and redundant or shallow captions. To address this limitation, we
propose Role-SynthCLIP, a novel data synthesis framework that leverages
multi-perspective role-playing prompts (e.g., a compositional analyst, an
interpreter of image context) to guide Multimodal Large Language Models (MLLMs)
in generating semantically diverse captions from distinct viewpoints. This
mechanism enhances the semantic diversity and fine-grained image-text alignment
of synthetic pairs, thereby improving caption expressiveness and accuracy while
keeping the total number of image-text pairs unchanged. Experimental results
demonstrate the effectiveness and efficiency of our method. A CLIP-B/16 model
trained on only 1 million Role-SynthCLIP pairs achieves a Recall@1 of 64.1% on
the MS COCO validation set, surpassing the best existing synthetic data
baseline (trained on 5M pairs) by 2.8 percentage points. The code and trained
models are released at https://github.com/huangfu170/Role-SynthCLIP.

</details>


### [30] [SurgiATM: A Physics-Guided Plug-and-Play Model for Deep Learning-Based Smoke Removal in Laparoscopic Surgery](https://arxiv.org/abs/2511.05059)
*Mingyu Sheng,Jianan Fan,Dongnan Liu,Guoyan Zheng,Ron Kikinis,Weidong Cai*

Main category: cs.CV

TL;DR: 提出了一种名为SurgiATM的轻量级、即插即用模块，用于术中烟雾去除，结合物理模型与深度学习优势，在不增加可训练参数的情况下提升多种去烟模型的性能。


<details>
  <summary>Details</summary>
Motivation: 术中烟雾会降低内窥镜图像质量，影响手术安全和计算机辅助分析，因此需要高效、通用且低开销的去烟方法。

Method: 提出SurgiATM，将物理大气模型与数据驱动的深度学习相结合，设计为无需额外可训练权重的轻量模块，可集成到多种去烟网络中。

Result: 在三个公开手术数据集上验证了SurgiATM的有效性，显著降低了图像恢复误差，提升了模型泛化能力和稳定性，适用于多种手术类型。

Conclusion: SurgiATM是一种高效、低成本、通用性强的去烟模块，能在不改变原网络结构的前提下提升去烟性能，具有良好的临床应用前景。

Abstract: During laparoscopic surgery, smoke generated by tissue cauterization can
significantly degrade the visual quality of endoscopic frames, increasing the
risk of surgical errors and hindering both clinical decision-making and
computer-assisted visual analysis. Consequently, removing surgical smoke is
critical to ensuring patient safety and maintaining operative efficiency. In
this study, we propose the Surgical Atmospheric Model (SurgiATM) for surgical
smoke removal. SurgiATM statistically bridges a physics-based atmospheric model
and data-driven deep learning models, combining the superior generalizability
of the former with the high accuracy of the latter. Furthermore, SurgiATM is
designed as a lightweight, plug-and-play module that can be seamlessly
integrated into diverse surgical desmoking architectures to enhance their
accuracy and stability, better meeting clinical requirements. It introduces
only two hyperparameters and no additional trainable weights, preserving the
original network architecture with minimal computational and modification
overhead. We conduct extensive experiments on three public surgical datasets
with ten desmoking methods, involving multiple network architectures and
covering diverse procedures, including cholecystectomy, partial nephrectomy,
and diaphragm dissection. The results demonstrate that incorporating SurgiATM
commonly reduces the restoration errors of existing models and relatively
enhances their generalizability, without adding any trainable layers or
weights. This highlights the convenience, low cost, effectiveness, and
generalizability of the proposed method. The code for SurgiATM is released at
https://github.com/MingyuShengSMY/SurgiATM.

</details>


### [31] [Deep learning models are vulnerable, but adversarial examples are even more vulnerable](https://arxiv.org/abs/2511.05073)
*Jun Li,Yanwei Xu,Keran Li,Xiaoli Zhang*

Main category: cs.CV

TL;DR: 该研究发现图像对抗样本在遮挡下表现出显著的敏感性，并提出了一种新的度量方法SMCE来量化模型置信度波动，进而设计了基于滑动窗口遮挡的对抗样本检测方法SWM-AED，在多种攻击和分类器下实现了高达96.5%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 理解对抗样本与原始样本之间的本质差异，有助于提升深度神经网络的鲁棒性和对抗攻击的检测能力。

Method: 通过在CIFAR-10上使用九种典型攻击生成对抗样本，引入滑动遮挡掩码置信熵（SMCE）来量化模型在遮挡下的置信度波动，并提出SWM-AED检测方法。

Result: 实验表明对抗样本在遮挡下具有更高的置信度波动，SWM-AED在多个分类器和攻击场景下检测准确率超过62%，最高达96.5%。

Conclusion: 基于遮挡敏感性的分析为对抗样本检测提供了新视角，SWM-AED有效且鲁棒，避免了传统对抗训练中的过拟合问题。

Abstract: Understanding intrinsic differences between adversarial examples and clean
samples is key to enhancing DNN robustness and detection against adversarial
attacks. This study first empirically finds that image-based adversarial
examples are notably sensitive to occlusion. Controlled experiments on CIFAR-10
used nine canonical attacks (e.g., FGSM, PGD) to generate adversarial examples,
paired with original samples for evaluation. We introduce Sliding Mask
Confidence Entropy (SMCE) to quantify model confidence fluctuation under
occlusion. Using 1800+ test images, SMCE calculations supported by Mask Entropy
Field Maps and statistical distributions show adversarial examples have
significantly higher confidence volatility under occlusion than originals.
Based on this, we propose Sliding Window Mask-based Adversarial Example
Detection (SWM-AED), which avoids catastrophic overfitting of conventional
adversarial training. Evaluations across classifiers and attacks on CIFAR-10
demonstrate robust performance, with accuracy over 62% in most cases and up to
96.5%.

</details>


### [32] [A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification](https://arxiv.org/abs/2511.05092)
*Ruolin Li,Min Liu,Yuan Bian,Zhaoyang Li,Yuzhen Li,Xueping Wang,Yaonan Wang*

Main category: cs.CV

TL;DR: 提出了一种双阶段提示驱动的隐私保护范式（DPPP），通过扩散模型生成大规模虚拟行人重识别数据集GenePerson，并结合提示解耦机制（PDM）提升模型的域泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于游戏引擎生成的虚拟数据集存在构建复杂和域泛化能力差的问题，难以应用于真实场景下的行人重识别任务。

Method: 第一阶段利用包含外观、光照、视角等多维属性的丰富提示词，驱动扩散模型端到端合成大规模虚拟数据集GenePerson；第二阶段提出提示驱动解耦机制（PDM），通过对比学习和文本反转网络将图像映射为风格与内容的伪词，构造风格解耦的内容提示以学习域不变特征。

Result: 在GenePerson上结合PDM训练的模型在多个主流真实和虚拟Re-ID数据集上均实现了最先进的泛化性能。

Conclusion: 所提出的DPPP框架有效解决了虚拟数据构建复杂和域泛化差的问题，为隐私保护的行人重识别提供了高效可行的新方案。

Abstract: With growing concerns over data privacy, researchers have started using
virtual data as an alternative to sensitive real-world images for training
person re-identification (Re-ID) models. However, existing virtual datasets
produced by game engines still face challenges such as complex construction and
poor domain generalization, making them difficult to apply in real scenarios.
To address these challenges, we propose a Dual-stage Prompt-driven
Privacy-preserving Paradigm (DPPP). In the first stage, we generate rich
prompts incorporating multi-dimensional attributes such as pedestrian
appearance, illumination, and viewpoint that drive the diffusion model to
synthesize diverse data end-to-end, building a large-scale virtual dataset
named GenePerson with 130,519 images of 6,641 identities. In the second stage,
we propose a Prompt-driven Disentanglement Mechanism (PDM) to learn
domain-invariant generalization features. With the aid of contrastive learning,
we employ two textual inversion networks to map images into pseudo-words
representing style and content, respectively, thereby constructing
style-disentangled content prompts to guide the model in learning
domain-invariant content features at the image level. Experiments demonstrate
that models trained on GenePerson with PDM achieve state-of-the-art
generalization performance, surpassing those on popular real and virtual Re-ID
datasets.

</details>


### [33] [Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start](https://arxiv.org/abs/2511.05095)
*Fuyang Liu,Jiaqi Xu,Xiaowei Hu*

Main category: cs.CV

TL;DR: 提出了一种基于物理驱动高保真数据集HFLS-Weather和双层强化学习框架的天气自适应视觉感知方法，在无配对监督下实现真实复杂天气下的持续优化与最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于合成数据训练的视觉模型在面对复杂多变的恶劣天气退化时泛化能力差，缺乏对真实世界动态退化的适应性。

Method: 构建了物理驱动的高保真天气模拟数据集HFLS-Weather，并设计了一个双层强化学习框架：局部层面通过扰动驱动的图像质量优化来精细化天气特定恢复模型；全局层面由元控制器动态调度模型选择与执行顺序。

Result: 该框架在多种恶劣天气场景下实现了无需配对监督的持续自适应优化，取得了当前最先进的性能表现。

Conclusion: 所提方法有效提升了模型在真实复杂天气条件下的泛化与适应能力，为实际视觉感知系统提供了可行的冷启动与持续学习解决方案。

Abstract: Adverse weather severely impairs real-world visual perception, while existing
vision models trained on synthetic data with fixed parameters struggle to
generalize to complex degradations. To address this, we first construct
HFLS-Weather, a physics-driven, high-fidelity dataset that simulates diverse
weather phenomena, and then design a dual-level reinforcement learning
framework initialized with HFLS-Weather for cold-start training. Within this
framework, at the local level, weather-specific restoration models are refined
through perturbation-driven image quality optimization, enabling reward-based
learning without paired supervision; at the global level, a meta-controller
dynamically orchestrates model selection and execution order according to scene
degradation. This framework enables continuous adaptation to real-world
conditions and achieves state-of-the-art performance across a wide range of
adverse weather scenarios. Code is available at
https://github.com/xxclfy/AgentRL-Real-Weather

</details>


### [34] [Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study](https://arxiv.org/abs/2511.05106)
*Yasemin Turkan,F. Boray Tek,M. Serdar Nazlı,Öykü Eren*

Main category: cs.CV

TL;DR: 本研究首次将深度学习应用于原始OCT B扫描图像进行阿尔茨海默病（AD）的早期预测，使用ResNet-34等预训练模型在UK Biobank数据集上进行微调，并引入年加权损失函数和数据增强技术以应对小样本高维数据的挑战。结果显示AUC为0.62，虽未达到临床应用标准，但可解释性分析证实了AD患者与对照组在中心黄斑区存在局部结构差异，为基于OCT的AD早期预测提供了基线参考。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期检测极具挑战性，因影像变化早于临床诊断多年。视网膜层厚度变化与神经退行性疾病相关，传统研究多依赖分割后的层厚度指标，而直接利用原始OCT图像进行分类可能捕捉更细微的生物标志物。因此，探索基于深度学习的原始OCT B-scans自动分类方法，有望实现AD的无创、早期筛查。

Method: 采用多种预训练深度学习模型（包括ImageNet预训练网络和OCT专用的RETFound Transformer），对来自UK Biobank队列的原始OCT B-scan图像进行微调。使用受试者水平交叉验证，并匹配年龄、性别和成像实例。为减少小样本高维数据中的过拟合，应用了标准及OCT特异性数据增强技术，并设计年加权损失函数，优先关注成像后4年内确诊的病例。

Result: ResNet-34模型在4年预测窗口内表现最稳定，AUC达到0.62。尽管性能尚未达到临床应用阈值，但可解释性分析（如Grad-CAM）确认了AD组与对照组在中心黄斑亚区存在局部结构差异，表明模型关注的是生物学合理的区域。

Conclusion: 这是首个利用原始OCT B-scan图像结合深度学习进行AD早期预测的研究，为OCT在AD筛查中的应用提供了初步基线。结果表明，在临床诊断前数年检测视网膜细微变化极具挑战，当前模型性能有限，未来需要更大规模的数据集和多模态融合方法来提升预测能力。

Abstract: Alterations in retinal layer thickness, measurable using Optical Coherence
Tomography (OCT), have been associated with neurodegenerative diseases such as
Alzheimer's disease (AD). While previous studies have mainly focused on
segmented layer thickness measurements, this study explored the direct
classification of OCT B-scan images for the early detection of AD. To our
knowledge, this is the first application of deep learning to raw OCT B-scans
for AD prediction in the literature. Unlike conventional medical image
classification tasks, early detection is more challenging than diagnosis
because imaging precedes clinical diagnosis by several years. We fine-tuned and
evaluated multiple pretrained models, including ImageNet-based networks and the
OCT-specific RETFound transformer, using subject-level cross-validation
datasets matched for age, sex, and imaging instances from the UK Biobank
cohort. To reduce overfitting in this small, high-dimensional dataset, both
standard and OCT-specific augmentation techniques were applied, along with a
year-weighted loss function that prioritized cases diagnosed within four years
of imaging. ResNet-34 produced the most stable results, achieving an AUC of
0.62 in the 4-year cohort. Although below the threshold for clinical
application, our explainability analyses confirmed localized structural
differences in the central macular subfield between the AD and control groups.
These findings provide a baseline for OCT-based AD prediction, highlight the
challenges of detecting subtle retinal biomarkers years before AD diagnosis,
and point to the need for larger datasets and multimodal approaches.

</details>


### [35] [SnowyLane: Robust Lane Detection on Snow-covered Rural Roads Using Infrastructural Elements](https://arxiv.org/abs/2511.05108)
*Jörg Gamerdinger,Benedict Wetzel,Patrick Schulz,Sven Teufel,Oliver Bringmann*

Main category: cs.CV

TL;DR: 提出一种不依赖传统车道线、通过检测路边分隔柱作为间接车道指示的鲁棒实时车道检测方法，并发布包含8万帧标注数据的合成雪天数据集SnowyLane。


<details>
  <summary>Details</summary>
Motivation: 在积雪覆盖环境下，传统车道线常被遮挡或消失，导致现有车道检测方法失效，因此需要一种不依赖车道线标记的鲁棒检测方案。

Method: 通过检测路边的垂直分隔柱，利用参数化贝塞尔曲线模型拟合平滑车道轨迹，结合空间一致性和道路几何信息进行车道推断。

Result: 在合成雪天数据集SnowyLane上验证，相比现有最先进方法，在严重积雪遮挡情况下表现出显著更强的鲁棒性。

Conclusion: 该方法为冬季场景下的可靠车道检测提供了有效解决方案，并发布了有价值的数据集，推动全天候自动驾驶的研究。

Abstract: Lane detection for autonomous driving in snow-covered environments remains a
major challenge due to the frequent absence or occlusion of lane markings. In
this paper, we present a novel, robust and realtime capable approach that
bypasses the reliance on traditional lane markings by detecting roadside
features,specifically vertical roadside posts called delineators, as indirect
lane indicators. Our method first perceives these posts, then fits a smooth
lane trajectory using a parameterized Bezier curve model, leveraging spatial
consistency and road geometry. To support training and evaluation in these
challenging scenarios, we introduce SnowyLane, a new synthetic dataset
containing 80,000 annotated frames capture winter driving conditions, with
varying snow coverage, and lighting conditions. Compared to state-of-the-art
lane detection systems, our approach demonstrates significantly improved
robustness in adverse weather, particularly in cases with heavy snow occlusion.
This work establishes a strong foundation for reliable lane detection in winter
scenarios and contributes a valuable resource for future research in
all-weather autonomous driving. The dataset is available at
https://ekut-es.github.io/snowy-lane

</details>


### [36] [From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection](https://arxiv.org/abs/2511.05150)
*Jingsong Liu,Han Li,Nassir Navab,Peter J. Schüffler*

Main category: cs.CV

TL;DR: JWTH是一种新型病理学基础模型，通过结合细胞中心的后调优和注意力池化，融合局部和全局特征，在多个生物标志物检测任务中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的病理学基础模型大多依赖于全局补丁级嵌入，忽略了细胞级别的形态信息，限制了AI生物标志物的可解释性和准确性。

Method: 提出JWTH模型，采用大规模自监督预训练，结合细胞中心的后调优和注意力池化机制，整合局部与全局token。

Result: 在涉及四个生物标志物和八个队列的四项任务中，JWTH相比先前模型最高提升8.3%的平衡准确率，平均提升1.2%。

Conclusion: JWTH通过融合细胞级形态信息，显著提升了AI生物标志物检测的性能与可解释性，推动了数字病理学的发展。

Abstract: AI-based biomarkers can infer molecular features directly from hematoxylin &
eosin (H&E) slides, yet most pathology foundation models (PFMs) rely on global
patch-level embeddings and overlook cell-level morphology. We present a PFM
model, JWTH (Joint-Weighted Token Hierarchy), which integrates large-scale
self-supervised pretraining with cell-centric post-tuning and attention pooling
to fuse local and global tokens. Across four tasks involving four biomarkers
and eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and 1.2%
average improvement over prior PFMs, advancing interpretable and robust
AI-based biomarker detection in digital pathology.

</details>


### [37] [Another BRIXEL in the Wall: Towards Cheaper Dense Features](https://arxiv.org/abs/2511.05168)
*Alexander Lappe,Martin A. Giese*

Main category: cs.CV

TL;DR: 提出BRIXEL方法，通过知识蒸馏在固定分辨率下显著优于DINOv3，并以更低计算成本生成高质量特征图。


<details>
  <summary>Details</summary>
Motivation: DINOv3模型需要高分辨率输入和大量计算资源，限制了其在实际应用中的效率。

Method: 采用简单的知识蒸馏方法，让学生模型学习生成更高分辨率的自身特征图。

Result: BRIXEL在下游任务中显著优于DINOv3基线模型，且生成的特征图与教师模型相似，计算成本大幅降低。

Conclusion: BRIXEL是一种高效、轻量的方法，能够在保持性能的同时显著减少计算开销。

Abstract: Vision foundation models achieve strong performance on both global and
locally dense downstream tasks. Pretrained on large images, the recent DINOv3
model family is able to produce very fine-grained dense feature maps, enabling
state-of-the-art performance. However, computing these feature maps requires
the input image to be available at very high resolution, as well as large
amounts of compute due to the squared complexity of the transformer
architecture. To address these issues, we propose BRIXEL, a simple knowledge
distillation approach that has the student learn to reproduce its own feature
maps at higher resolution. Despite its simplicity, BRIXEL outperforms the
baseline DINOv3 models by large margins on downstream tasks when the resolution
is kept fixed. Moreover, it is able to produce feature maps that are very
similar to those of the teacher at a fraction of the computational cost. Code
and model weights are available at https://github.com/alexanderlappe/BRIXEL.

</details>


### [38] [MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification](https://arxiv.org/abs/2511.05170)
*Zijiang Yang,Hanqing Chao,Bokai Zhao,Yelin Yang,Yunshuo Zhang,Dongmei Fu,Junping Zhang,Le Lu,Ke Yan,Dakai Jin,Minfeng Xu,Yun Bian,Hui Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种名为MUSE的自监督学习方法，用于组织病理学中的细胞核检测与分类（NDC），通过无需严格对齐的坐标引导局部自蒸馏机制NuLo，有效利用大规模无标签数据，提升了细粒度细胞核表征能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖密集的细胞核级别标注，难以充分利用大量无标签数据来学习判别性细胞核表示。

Method: 提出MUSE框架，核心为NuLo机制，实现基于预测位置的多尺度局部自蒸馏；设计了编码器-解码器结构和大视野半监督微调策略以增强性能。

Result: 在三个主流基准上实验表明，MUSE优于现有的监督方法和通用病理基础模型，在细胞核检测与分类任务中表现卓越。

Conclusion: MUSE通过创新的自蒸馏机制和架构设计，显著提升了无标签数据利用效率和模型性能，为病理图像分析提供了新的高效解决方案。

Abstract: Nucleus detection and classification (NDC) in histopathology analysis is a
fundamental task that underpins a wide range of high-level pathology
applications. However, existing methods heavily rely on labor-intensive
nucleus-level annotations and struggle to fully exploit large-scale unlabeled
data for learning discriminative nucleus representations. In this work, we
propose MUSE (MUlti-scale denSE self-distillation), a novel self-supervised
learning method tailored for NDC. At its core is NuLo (Nucleus-based Local
self-distillation), a coordinate-guided mechanism that enables flexible local
self-distillation based on predicted nucleus positions. By removing the need
for strict spatial alignment between augmented views, NuLo allows critical
cross-scale alignment, thus unlocking the capacity of models for fine-grained
nucleus-level representation. To support MUSE, we design a simple yet effective
encoder-decoder architecture and a large field-of-view semi-supervised
fine-tuning strategy that together maximize the value of unlabeled pathology
images. Extensive experiments on three widely used benchmarks demonstrate that
MUSE effectively addresses the core challenges of histopathological NDC. The
resulting models not only surpass state-of-the-art supervised baselines but
also outperform generic pathology foundation models.

</details>


### [39] [Walk the Lines 2: Contour Tracking for Detailed Segmentation](https://arxiv.org/abs/2511.05210)
*André Peter Kelm,Max Braeschke,Emre Gülsoylu,Simone Frintrop*

Main category: cs.CV

TL;DR: Walk the Lines 2 (WtL2) 是一种改进的轮廓跟踪算法，用于红外图像中的船舶和RGB图像中多种物体的精细分割，通过优化轮廓检测取代传统的非极大值抑制（NMS），在闭合轮廓生成和高IoU表现上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 原有 Walk the Lines (WtL) 方法仅适用于彩色图像中的船舶分割，缺乏对红外图像和其他RGB对象的适应性，限制了其应用范围。

Method: WtL2 改进了输入和轮廓检测器以适应红外图像中的船舶，并增强算法以处理多种RGB对象，采用轮廓跟踪技术迭代优化目标轮廓，直至生成1像素宽的闭合形状，实现前景-背景场景下的可分割区域。

Result: WtL2 在生成闭合物体轮廓方面优于最新的基于轮廓的方法，实现了高峰值交并比（IoU）和丰富的细节表现，适用于需要高精度分割的专用场景。

Conclusion: WtL2 成功扩展了 WtL 的应用范围至红外图像和多样化RGB对象，是一种具有潜力的高质细分方法，有望推动图像分割特定领域的发展。

Abstract: This paper presents Walk the Lines 2 (WtL2), a unique contour tracking
algorithm specifically adapted for detailed segmentation of infrared (IR) ships
and various objects in RGB.1 This extends the original Walk the Lines (WtL)
[12], which focused solely on detailed ship segmentation in color. These
innovative WtLs can replace the standard non-maximum suppression (NMS) by using
contour tracking to refine the object contour until a 1-pixel-wide closed shape
can be binarized, forming a segmentable area in foreground-background
scenarios. WtL2 broadens the application range of WtL beyond its original
scope, adapting to IR and expanding to diverse objects within the RGB context.
To achieve IR segmentation, we adapt its input, the object contour detector, to
IR ships. In addition, the algorithm is enhanced to process a wide range of RGB
objects, outperforming the latest generation of contour-based methods when
achieving a closed object contour, offering high peak Intersection over Union
(IoU) with impressive details. This positions WtL2 as a compelling method for
specialized applications that require detailed segmentation or high-quality
samples, potentially accelerating progress in several niche areas of image
segmentation.

</details>


### [40] [FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction](https://arxiv.org/abs/2511.05219)
*Jiang Lin,Xinyu Chen,Song Wu,Zhiqiu Zhang,Jizhi Zhang,Ye Wang,Qiang Tang,Qian Wang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: FreeControl是一种无需训练的扩散模型语义结构控制框架，通过单步注意力提取和潜在条件解耦（LCD）实现高效、高质量的图像生成控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法如ControlNet依赖手工条件图和重训练，灵活性差；基于反转的方法推理成本高。需要一种高效、灵活且无需训练的结构控制方法。

Method: FreeControl在单一最优关键时间步进行一步注意力提取，并在整个去噪过程中复用该注意力；引入潜在条件解耦（LCD）机制，分离关键时间步与噪声潜在变量，提升控制精度并消除结构伪影；支持通过多源参考图像实现组合控制。

Result: 实现了训练免费、低推理成本（仅增加约5%）的结构化图像生成；相比现有方法更高效稳定，支持直观场景布局设计和更强的提示对齐；兼容现代扩散模型。

Conclusion: FreeControl提出了一种新的测试时控制范式，能够在无需训练或反转的情况下实现语义与结构一致、视觉连贯的图像生成，具有高灵活性和应用潜力。

Abstract: Controlling the spatial and semantic structure of diffusion-generated images
remains a challenge. Existing methods like ControlNet rely on handcrafted
condition maps and retraining, limiting flexibility and generalization.
Inversion-based approaches offer stronger alignment but incur high inference
cost due to dual-path denoising. We present FreeControl, a training-free
framework for semantic structural control in diffusion models. Unlike prior
methods that extract attention across multiple timesteps, FreeControl performs
one-step attention extraction from a single, optimally chosen key timestep and
reuses it throughout denoising. This enables efficient structural guidance
without inversion or retraining. To further improve quality and stability, we
introduce Latent-Condition Decoupling (LCD): a principled separation of the key
timestep and the noised latent used in attention extraction. LCD provides finer
control over attention quality and eliminates structural artifacts. FreeControl
also supports compositional control via reference images assembled from
multiple sources - enabling intuitive scene layout design and stronger prompt
alignment. FreeControl introduces a new paradigm for test-time control,
enabling structurally and semantically aligned, visually coherent generation
directly from raw images, with the flexibility for intuitive compositional
design and compatibility with modern diffusion models at approximately 5
percent additional cost.

</details>


### [41] [4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos](https://arxiv.org/abs/2511.05229)
*Mengqi Guo,Bo Xu,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: 提出4D3R，一种无需相机姿态的动态神经渲染框架，通过解耦静态与动态成分，在真实动态场景中实现更高效、高质量的新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF和3DGS等方法在处理动态场景时依赖预估相机姿态，难以准确建模动态内容，尤其在相机姿态未知的情况下性能受限。

Method: 采用两阶段方法：首先利用3D基础模型估计初始位姿与几何，再进行运动感知优化；引入运动感知BA模块（结合Transformer先验与SAM2）优化相机位姿，并提出Motion-Aware Gaussian Splatting（MA-GS）表示，使用控制点、变形场MLP和线性蒙皮建模动态运动。

Result: 在真实动态数据集上实验显示，相比现有最先进方法PSNR提升达1.8dB，尤其在大动态物体场景表现突出，同时计算成本降低5倍。

Conclusion: 4D3R有效解决了未知相机姿态下的动态场景新视角合成难题，在保持高质量重建的同时显著提升效率，推动了动态神经渲染的实用化发展。

Abstract: Novel view synthesis from monocular videos of dynamic scenes with unknown
camera poses remains a fundamental challenge in computer vision and graphics.
While recent advances in 3D representations such as Neural Radiance Fields
(NeRF) and 3D Gaussian Splatting (3DGS) have shown promising results for static
scenes, they struggle with dynamic content and typically rely on pre-computed
camera poses. We present 4D3R, a pose-free dynamic neural rendering framework
that decouples static and dynamic components through a two-stage approach. Our
method first leverages 3D foundational models for initial pose and geometry
estimation, followed by motion-aware refinement. 4D3R introduces two key
technical innovations: (1) a motion-aware bundle adjustment (MA-BA) module that
combines transformer-based learned priors with SAM2 for robust dynamic object
segmentation, enabling more accurate camera pose refinement; and (2) an
efficient Motion-Aware Gaussian Splatting (MA-GS) representation that uses
control points with a deformation field MLP and linear blend skinning to model
dynamic motion, significantly reducing computational cost while maintaining
high-quality reconstruction. Extensive experiments on real-world dynamic
datasets demonstrate that our approach achieves up to 1.8dB PSNR improvement
over state-of-the-art methods, particularly in challenging scenarios with large
dynamic objects, while reducing computational requirements by 5x compared to
previous dynamic scene representations.

</details>


### [42] [ADPretrain: Advancing Industrial Anomaly Detection via Anomaly Representation Pretraining](https://arxiv.org/abs/2511.05245)
*Xincheng Yao,Yan Luo,Zefeng Qian,Chongyang Zhang*

Main category: cs.CV

TL;DR: 提出了一种专为工业异常检测设计的预训练表示学习框架，通过角度和范数导向的对比损失，在大规模异常检测数据集RealIAD上学习鲁棒且具有判别性的特征表示，有效缓解了ImageNet预训练与异常检测任务目标不一致及分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于ImageNet预训练的特征在异常检测任务中因目标不匹配和分布偏移而表现次优，亟需专为异常检测设计的预训练表示。

Method: 提出角度和范数导向的对比损失，结合残差特征在RealIAD数据集上进行预训练，以增强正常与异常样本特征间的差异。

Result: 在五个异常检测数据集和五种骨干网络上，基于所提预训练表示的五种嵌入式方法均显著优于原有特征。

Conclusion: 专为异常检测设计的预训练框架能有效提升各类下游方法性能，验证了任务专用预训练的重要性。

Abstract: The current mainstream and state-of-the-art anomaly detection (AD) methods
are substantially established on pretrained feature networks yielded by
ImageNet pretraining. However, regardless of supervised or self-supervised
pretraining, the pretraining process on ImageNet does not match the goal of
anomaly detection (i.e., pretraining in natural images doesn't aim to
distinguish between normal and abnormal). Moreover, natural images and
industrial image data in AD scenarios typically have the distribution shift.
The two issues can cause ImageNet-pretrained features to be suboptimal for AD
tasks. To further promote the development of the AD field, pretrained
representations specially for AD tasks are eager and very valuable. To this
end, we propose a novel AD representation learning framework specially designed
for learning robust and discriminative pretrained representations for
industrial anomaly detection. Specifically, closely surrounding the goal of
anomaly detection (i.e., focus on discrepancies between normals and anomalies),
we propose angle- and norm-oriented contrastive losses to maximize the angle
size and norm difference between normal and abnormal features simultaneously.
To avoid the distribution shift from natural images to AD images, our
pretraining is performed on a large-scale AD dataset, RealIAD. To further
alleviate the potential shift between pretraining data and downstream AD
datasets, we learn the pretrained AD representations based on the
class-generalizable representation, residual features. For evaluation, based on
five embedding-based AD methods, we simply replace their original features with
our pretrained representations. Extensive experiments on five AD datasets and
five backbones consistently show the superiority of our pretrained features.
The code is available at https://github.com/xcyao00/ADPretrain.

</details>


### [43] [Accurate online action and gesture recognition system using detectors and Deep SPD Siamese Networks](https://arxiv.org/abs/2511.05250)
*Mohamed Sanim Akremi,Rim Slama,Hedi Tabia*

Main category: cs.CV

TL;DR: 本文提出了一种基于骨架序列流的在线识别系统，结合SPD矩阵表示和Siamese网络，实现对未分割动作序列中运动区间的检测与分类，在手势和身体动作识别任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于实际应用中需要实时处理连续动作，而现有基于分段的动作识别方法不适用于在线场景，因此需要一种能够持续、实时识别骨架数据流的系统。

Method: 提出由检测器和分类器组成的在线识别系统，使用半正定（SPD）矩阵表示骨骼数据，并利用Siamese网络学习其语义相似性，以实现动作区间检测和动作类别识别。

Result: 在多个手部手势和身体动作识别基准上进行了广泛实验，结果表明该系统在多数情况下优于当前最先进的方法，具备高精度和连续状态识别能力。

Conclusion: 所提出的基于SPD矩阵和Siamese网络的在线识别系统有效解决了连续骨架数据流中的动作检测与分类问题，具有良好的实用性与性能表现。

Abstract: Online continuous motion recognition is a hot topic of research since it is
more practical in real life application cases. Recently, Skeleton-based
approaches have become increasingly popular, demonstrating the power of using
such 3D temporal data. However, most of these works have focused on
segment-based recognition and are not suitable for the online scenarios. In
this paper, we propose an online recognition system for skeleton sequence
streaming composed from two main components: a detector and a classifier, which
use a Semi-Positive Definite (SPD) matrix representation and a Siamese network.
The powerful statistical representations for the skeletal data given by the SPD
matrices and the learning of their semantic similarity by the Siamese network
enable the detector to predict time intervals of the motions throughout an
unsegmented sequence. In addition, they ensure the classifier capability to
recognize the motion in each predicted interval. The proposed detector is
flexible and able to identify the kinetic state continuously. We conduct
extensive experiments on both hand gesture and body action recognition
benchmarks to prove the accuracy of our online recognition system which in most
cases outperforms state-of-the-art performances.

</details>


### [44] [Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection](https://arxiv.org/abs/2511.05253)
*Tiziano Natali,Karin A. Olthof,Niels F. M. Kok,Koert F. D. Kuhlmann,Theo J. M. Ruers,Matteo Fusaglia*

Main category: cs.CV

TL;DR: 本研究提出了一种基于裁剪3D U-Net的自动分割方法，用于术中三维超声（iUS）下结直肠癌肝转移瘤（CRLM）的精准勾画，实现了接近专家水平的快速、可靠分割，显著减少了手动操作时间和手术流程时间。


<details>
  <summary>Details</summary>
Motivation: 术中准确勾画CRLM对于实现阴性切缘至关重要，但传统iUS因对比度低、噪声多和操作者依赖性而难以实现精确分割，亟需自动化方法提升精度和效率。

Method: 采用nnU-Net框架训练3D U-Net模型，比较全体积与肿瘤区域裁剪后的输入效果，并在85例患者数据上进行训练与评估，最终集成至3D Slicer平台支持实时术中导航。

Result: 裁剪模型显著优于全体积模型（AUC-ROC 0.898 vs 0.718），中位DSC为0.74，HDist.为17.1 mm，召回率为0.79，处理速度约为手动方法的4倍（约1分钟），前瞻性术中测试显示其性能稳定且临床可接受。

Conclusion: 基于裁剪输入的3D U-Net可实现CRLM在iUS中的自动、近实时分割，具备高可靠性与低操作负担，支持无需配准的超声导航，有望提升肝脏手术的精准性与效率。

Abstract: Introduction: Accurate intraoperative delineation of colorectal liver
metastases (CRLM) is crucial for achieving negative resection margins but
remains challenging using intraoperative ultrasound (iUS) due to low contrast,
noise, and operator dependency. Automated segmentation could enhance precision
and efficiency in ultrasound-based navigation workflows.
  Methods: Eighty-five tracked 3D iUS volumes from 85 CRLM patients were used
to train and evaluate a 3D U-Net implemented via the nnU-Net framework. Two
variants were compared: one trained on full iUS volumes and another on cropped
regions around tumors. Segmentation accuracy was assessed using Dice Similarity
Coefficient (DSC), Hausdorff Distance (HDist.), and Relative Volume Difference
(RVD) on retrospective and prospective datasets. The workflow was integrated
into 3D Slicer for real-time intraoperative use.
  Results: The cropped-volume model significantly outperformed the full-volume
model across all metrics (AUC-ROC = 0.898 vs 0.718). It achieved median DSC =
0.74, recall = 0.79, and HDist. = 17.1 mm comparable to semi-automatic
segmentation but with ~4x faster execution (~ 1 min). Prospective
intraoperative testing confirmed robust and consistent performance, with
clinically acceptable accuracy for real-time surgical guidance.
  Conclusion: Automatic 3D segmentation of CRLM in iUS using a cropped 3D U-Net
provides reliable, near real-time results with minimal operator input. The
method enables efficient, registration-free ultrasound-based navigation for
hepatic surgery, approaching expert-level accuracy while substantially reducing
manual workload and procedure time.

</details>


### [45] [OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU](https://arxiv.org/abs/2511.05263)
*Qi Sun,Dingju Zhou,Lina Zhang*

Main category: cs.CV

TL;DR: OregairuChar是一个用于分析动漫《我的青春恋爱物语果然有问题》第三季中角色出场频率的基准数据集，包含1600帧和2860个标注框，涵盖11个主要角色，支持对角色 prominence 和叙事动态的细粒度研究。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解动漫中的叙事结构和角色重要性，需要一个专注于角色视觉出现频率的高质量数据集。现有数据集缺乏针对特定动漫的精细标注，难以支持基于外观的叙事分析。

Method: 构建了一个名为OregairuChar的数据集，包含从动漫第三季中手工选取的1600帧图像，并对11个主要角色标注了2860个边界框；在此基础上，使用多种目标检测模型进行基准测试，并利用其预测结果进行按集数划分的角色出现频率分析。

Result: 成功建立了OregairuChar数据集并验证了其在复杂视觉条件下的有效性；通过目标检测模型实现了对角色出场情况的量化分析，揭示了角色在剧情发展中的 prominence 变化模式。

Conclusion: OregairuChar为研究风格化媒体中的计算叙事动态和以角色为中心的 storytelling 提供了一个有价值的工具，推动了基于视觉出现频率的叙事分析发展。

Abstract: The analysis of character appearance frequency is essential for understanding
narrative structure, character prominence, and story progression in anime. In
this work, we introduce OregairuChar, a benchmark dataset designed for
appearance frequency analysis in the anime series My Teen Romantic Comedy
SNAFU. The dataset comprises 1600 manually selected frames from the third
season, annotated with 2860 bounding boxes across 11 main characters.
OregairuChar captures diverse visual challenges, including occlusion, pose
variation, and inter-character similarity, providing a realistic basis for
appearance-based studies. To enable quantitative research, we benchmark several
object detection models on the dataset and leverage their predictions for
fine-grained, episode-level analysis of character presence over time. This
approach reveals patterns of character prominence and their evolution within
the narrative. By emphasizing appearance frequency, OregairuChar serves as a
valuable resource for exploring computational narrative dynamics and
character-centric storytelling in stylized media.

</details>


### [46] [DeepEyesV2: Toward Agentic Multimodal Model](https://arxiv.org/abs/2511.05271)
*Jack Hong,Chenxiao Zhao,ChengLin Zhu,Weiheng Lu,Guohai Xu,Xing Yu*

Main category: cs.CV

TL;DR: 本文介绍了DeepEyesV2，探索了从数据构建、训练方法到模型评估的角度如何构建具有主动调用外部工具能力的多模态智能体模型。提出两阶段训练 pipeline（冷启动+强化学习），并在新提出的RealX-Bench基准上验证了模型在真实世界多模态推理任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 直接使用强化学习无法稳定诱导出模型的工具使用行为，因此需要更系统的训练策略和专门的数据与评测基准来推动多模态智能体模型的发展。

Method: 采用两阶段训练方法：先通过冷启动阶段建立工具使用模式，再用强化学习进行优化；构建了一个包含有益工具使用示例的多样化训练数据集，并提出了RealX-Bench评测基准。

Result: DeepEyesV2在RealX-Bench等多个基准上表现出色，具备任务自适应的工具调用能力，能根据任务类型选择图像操作或数值计算，并通过强化学习实现复杂工具组合与上下文感知的工具调用。

Conclusion: 两阶段训练策略有效提升了多模态模型的工具使用能力，RealX-Bench为评估真实场景下的多模态推理提供了新标准，研究为构建具备主动行为能力的多模态智能体提供了可行路径。

Abstract: Agentic multimodal models should not only comprehend text and images, but
also actively invoke external tools, such as code execution environments and
web search, and integrate these operations into reasoning. In this work, we
introduce DeepEyesV2 and explore how to build an agentic multimodal model from
the perspectives of data construction, training methods, and model evaluation.
We observe that direct reinforcement learning alone fails to induce robust
tool-use behavior. This phenomenon motivates a two-stage training pipeline: a
cold-start stage to establish tool-use patterns, and reinforcement learning
stage to further refine tool invocation. We curate a diverse, moderately
challenging training dataset, specifically including examples where tool use is
beneficial. We further introduce RealX-Bench, a comprehensive benchmark
designed to evaluate real-world multimodal reasoning, which inherently requires
the integration of multiple capabilities, including perception, search, and
reasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative
benchmarks, demonstrating its effectiveness across real-world understanding,
mathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2
exhibits task-adaptive tool invocation, tending to use image operations for
perception tasks and numerical computations for reasoning tasks. Reinforcement
learning further enables complex tool combinations and allows model to
selectively invoke tools based on context. We hope our study can provide
guidance for community in developing agentic multimodal models.

</details>


### [47] [What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs](https://arxiv.org/abs/2511.05292)
*Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: 提出CuisineSense系统，结合智能手表和智能眼镜的运动数据，实现对中国菜类型的准确分类，并设计两阶段检测流程以提高饮食监测的精度。


<details>
  <summary>Details</summary>
Motivation: 现有饮食监测方法存在回忆偏差、隐私问题或食物类型覆盖有限的问题，尤其缺乏对中国多样饮食的有效识别。

Method: 融合智能手表的手部动作和智能眼镜的头部动态数据，采用两阶段检测流程：第一阶段识别进食状态，第二阶段进行细粒度食物类型分类。

Result: 在包含11类食物、10名参与者、27.5小时IMU数据的数据集上验证，CuisineSense在进食状态检测和食物分类方面均表现出高准确率。

Conclusion: CuisineSense为无感、可穿戴的饮食监测提供了一种实用解决方案，特别适用于复杂的中式餐饮场景。

Abstract: Accurate food intake detection is vital for dietary monitoring and chronic
disease prevention. Traditional self-report methods are prone to recall bias,
while camera-based approaches raise concerns about privacy. Furthermore,
existing wearable-based methods primarily focus on a limited number of food
types, such as hamburgers and pizza, failing to address the vast diversity of
Chinese cuisine. To bridge this gap, we propose CuisineSense, a system that
classifies Chinese food types by integrating hand motion cues from a smartwatch
with head dynamics from smart glasses. To filter out irrelevant daily
activities, we design a two-stage detection pipeline. The first stage
identifies eating states by distinguishing characteristic temporal patterns
from non-eating behaviors. The second stage then conducts fine-grained food
type recognition based on the motions captured during food intake. To evaluate
CuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings
across 11 food categories and 10 participants. Experiments demonstrate that
CuisineSense achieves high accuracy in both eating state detection and food
classification, offering a practical solution for unobtrusive, wearable-based
dietary monitoring.The system code is publicly available at
https://github.com/joeeeeyin/CuisineSense.git.

</details>


### [48] [Cross-domain EEG-based Emotion Recognition with Contrastive Learning](https://arxiv.org/abs/2511.05293)
*Rui Yan,Yibo Li,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: 提出EmotionCLIP模型，将EEG情绪识别转化为EEG-文本匹配任务，结合SST-LegoViT骨干网络，在跨被试和跨时间场景下实现优异性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于EEG的情绪识别中特征利用不足和跨域泛化能力差的问题。

Method: 在CLIP框架下构建EEG-文本匹配模型，采用SST-LegoViT骨干网络提取空间、频谱和时间多尺度特征，通过对比学习实现跨模态对齐。

Result: 在SEED和SEED-IV数据集上，跨被试准确率分别达到88.69%和73.50%，跨时间准确率分别达88.46%和77.54%，优于现有模型。

Conclusion: 多模态对比学习能有效提升EEG情绪识别的鲁棒性和跨域泛化能力。

Abstract: Electroencephalogram (EEG)-based emotion recognition is vital for affective
computing but faces challenges in feature utilization and cross-domain
generalization. This work introduces EmotionCLIP, which reformulates
recognition as an EEG-text matching task within the CLIP framework. A tailored
backbone, SST-LegoViT, captures spatial, spectral, and temporal features using
multi-scale convolution and Transformer modules. Experiments on SEED and
SEED-IV datasets show superior cross-subject accuracies of 88.69% and 73.50%,
and cross-time accuracies of 88.46% and 77.54%, outperforming existing models.
Results demonstrate the effectiveness of multimodal contrastive learning for
robust EEG emotion recognition.

</details>


### [49] [LiveStar: Live Streaming Assistant for Real-World Online Video Understanding](https://arxiv.org/abs/2511.05299)
*Zhenyu Yang,Kairui Zhang,Yuhang Hu,Bing Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Weiming Dong,Changsheng Xu*

Main category: cs.CV

TL;DR: 本文提出了LiveStar，一种用于实时视频理解的在线视频大语言模型，通过自适应流式解码实现持续主动响应，显著提升了实时性和叙事连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有在线视频大语言模型难以同时处理逐帧连续输入并确定最佳响应时机，影响了实时响应和叙事连贯性。

Method: 提出LiveStar，包含增量视频-语言对齐训练策略、响应-静默解码框架以单次前向传播确定最佳响应时机，以及基于峰值-末端记忆压缩和流式键值缓存的内存感知加速方法。

Result: 在三个基准上实验表明，相比现有在线Video-LLMs，语义正确性平均提升19.5%，响应时序差异减少18.1%，五项OmniStar任务中FPS提升12.0%。

Conclusion: LiveStar在长时在线视频理解中实现了高效、准确且及时的响应，推动了实时视频理解的发展。

Abstract: Despite significant progress in Video Large Language Models (Video-LLMs) for
offline video understanding, existing online Video-LLMs typically struggle to
simultaneously process continuous frame-by-frame inputs and determine optimal
response timing, often compromising real-time responsiveness and narrative
coherence. To address these limitations, we introduce LiveStar, a pioneering
live streaming assistant that achieves always-on proactive responses through
adaptive streaming decoding. Specifically, LiveStar incorporates: (1) a
training strategy enabling incremental video-language alignment for
variable-length video streams, preserving temporal consistency across
dynamically evolving frame sequences; (2) a response-silence decoding framework
that determines optimal proactive response timing via a single forward pass
verification; (3) memory-aware acceleration via peak-end memory compression for
online inference on 10+ minute videos, combined with streaming key-value cache
to achieve 1.53x faster inference. We also construct an OmniStar dataset, a
comprehensive dataset for training and benchmarking that encompasses 15 diverse
real-world scenarios and 5 evaluation tasks for online video understanding.
Extensive experiments across three benchmarks demonstrate LiveStar's
state-of-the-art performance, achieving an average 19.5% improvement in
semantic correctness with 18.1% reduced timing difference compared to existing
online Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks.
Our model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.

</details>


### [50] [Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation](https://arxiv.org/abs/2511.05308)
*Matteo Bastico,David Ryckelynck,Laurent Corté,Yannick Tillier,Etienne Decencière*

Main category: cs.CV

TL;DR: 本文提出了一种新的点云生成模型评估指标SNC，并改进了现有的Chamfer Distance，提出了Density-Aware Chamfer Distance（DCD），同时引入对齐预处理以提高评估的鲁棒性。此外，作者提出了Diffusion Point Transformer模型，在ShapeNet数据集上实现了生成质量的新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有基于Chamfer Distance的点云生成评估指标对缺陷不敏感，无法准确反映几何保真度和局部形状一致性，亟需更鲁棒、可靠的评估方法。

Method: 引入样本对齐预处理，用Density-Aware Chamfer Distance（DCD）替代传统CD；提出Surface Normal Concordance（SNC）指标，通过比较点法向量评估表面相似性；结合Transformer架构设计Diffusion Point Transformer生成模型。

Result: 在ShapeNet数据集上实验表明，所提DCD和SNC指标更具鲁棒性和一致性；Diffusion Point Transformer在生成点云质量上优于先前方法，达到新SOTA。

Conclusion: 改进的评估流程（对齐+DCD+SNC）能更准确评估生成点云质量，所提出的Diffusion Point Transformer模型能生成更高保真度的3D结构，推动了点云生成技术的发展。

Abstract: As 3D point clouds become a cornerstone of modern technology, the need for
sophisticated generative models and reliable evaluation metrics has grown
exponentially. In this work, we first expose that some commonly used metrics
for evaluating generated point clouds, particularly those based on Chamfer
Distance (CD), lack robustness against defects and fail to capture geometric
fidelity and local shape consistency when used as quality indicators. We
further show that introducing samples alignment prior to distance calculation
and replacing CD with Density-Aware Chamfer Distance (DCD) are simple yet
essential steps to ensure the consistency and robustness of point cloud
generative model evaluation metrics. While existing metrics primarily focus on
directly comparing 3D Euclidean coordinates, we present a novel metric, named
Surface Normal Concordance (SNC), which approximates surface similarity by
comparing estimated point normals. This new metric, when combined with
traditional ones, provides a more comprehensive evaluation of the quality of
generated samples. Finally, leveraging recent advancements in transformer-based
models for point cloud analysis, such as serialized patch attention , we
propose a new architecture for generating high-fidelity 3D structures, the
Diffusion Point Transformer. We perform extensive experiments and comparisons
on the ShapeNet dataset, showing that our model outperforms previous solutions,
particularly in terms of quality of generated point clouds, achieving new
state-of-the-art. Code available at
https://github.com/matteo-bastico/DiffusionPointTransformer.

</details>


### [51] [$\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models](https://arxiv.org/abs/2511.05319)
*Huanqi Wu,Huangbiao Xu,Runfeng Xie,Jiaxin Cai,Kaixin Zhang,Xiao Ke*

Main category: cs.CV

TL;DR: 本文提出了句子到图像的隐写术（Sentence-to-Image Steganography），利用大语言模型（LLM）将语义丰富的文本信息嵌入图像中，提出S²LM方法并在新基准Invisible Text（IVT）上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统隐写术难以在载体中嵌入语义丰富的句子级信息，而在AIGC时代对隐写容量和语义表达能力提出了更高要求。

Method: 提出S²LM：一种结合大语言模型的语义隐写语言模型，通过全新设计的端到端流程，将句子或段落级别的文本语义嵌入图像；构建了名为Invisible Text（IVT）的基准用于评估。

Result: 实验表明S²LM在定量和定性指标上均能有效实现语义级信息隐藏，显著提升隐写术的语义表达能力。

Conclusion: S²LM成功实现了将高阶语义文本嵌入图像的语义隐写新范式，为LLM在隐写领域的应用开辟了新方向。

Abstract: Although steganography has made significant advancements in recent years, it
still struggles to embed semantically rich, sentence-level information into
carriers. However, in the era of AIGC, the capacity of steganography is more
critical than ever. In this work, we present Sentence-to-Image Steganography,
an instance of Semantic Steganography, a novel task that enables the hiding of
arbitrary sentence-level messages within a cover image. Furthermore, we
establish a benchmark named Invisible Text (IVT), comprising a diverse set of
sentence-level texts as secret messages for evaluation. Finally, we present
$\mathbf{S^2LM}$: Semantic Steganographic Language Model, which utilizes large
language models (LLMs) to embed high-level textual information, such as
sentences or even paragraphs, into images. Unlike traditional bit-level
counterparts, $\mathrm{S^2LM}$ enables the integration of semantically rich
content through a newly designed pipeline in which the LLM is involved
throughout the entire process. Both quantitative and qualitative experiments
demonstrate that our method effectively unlocks new semantic steganographic
capabilities for LLMs. The source code will be released soon.

</details>


### [52] [Canonical Space Representation for 4D Panoptic Segmentation of Articulated Objects](https://arxiv.org/abs/2511.05356)
*Manuel Gomes,Bogdan Raducanu,Miguel Oliveira*

Main category: cs.CV

TL;DR: 本文提出了Artic4D数据集和CanonSeg4D框架，用于4D动态可动部件物体的全景分割，通过时序建模和规范空间对齐提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略时间动态性，且缺乏针对可动部件物体的4D全景分割基准数据集。

Method: 构建Artic4D数据集并提出CanonSeg4D框架，估计每帧中物体部分到规范空间的偏移，实现跨帧一致的部件对齐与分割。

Result: 在Artic4D上的实验表明，CanonSeg4D在复杂场景下优于现有最先进方法。

Conclusion: 时序建模与规范空间对齐有效提升了动态可动物体的理解能力，推动了4D可动物体感知的发展。

Abstract: Articulated object perception presents significant challenges in computer
vision, particularly because most existing methods ignore temporal dynamics
despite the inherently dynamic nature of such objects. The use of 4D temporal
data has not been thoroughly explored in articulated object perception and
remains unexamined for panoptic segmentation. The lack of a benchmark dataset
further hurt this field. To this end, we introduce Artic4D as a new dataset
derived from PartNet Mobility and augmented with synthetic sensor data,
featuring 4D panoptic annotations and articulation parameters. Building on this
dataset, we propose CanonSeg4D, a novel 4D panoptic segmentation framework.
This approach explicitly estimates per-frame offsets mapping observed object
parts to a learned canonical space, thereby enhancing part-level segmentation.
The framework employs this canonical representation to achieve consistent
alignment of object parts across sequential frames. Comprehensive experiments
on Artic4D demonstrate that the proposed CanonSeg4D outperforms state of the
art approaches in panoptic segmentation accuracy in more complex scenarios.
These findings highlight the effectiveness of temporal modeling and canonical
alignment in dynamic object understanding, and pave the way for future advances
in 4D articulated object perception.

</details>


### [53] [Dense Motion Captioning](https://arxiv.org/abs/2511.05369)
*Shiyao Xu,Benedetta Liberatori,Gül Varol,Paolo Rota*

Main category: cs.CV

TL;DR: 本文提出了密集动作描述任务（Dense Motion Captioning），旨在对3D人体动作序列中的动作进行时间定位与描述，并发布了首个大规模复杂动作数据集CompMo及配套模型DEMO。


<details>
  <summary>Details</summary>
Motivation: 现有的3D动作理解研究缺乏详细的时间标注数据，且多集中于短序列和少量动作，限制了动作理解的发展。

Method: 构建了一个包含6万条多动作序列的大型数据集CompMo，并设计了结合大语言模型与简单动作适配器的DEMO模型，用于生成时序对齐的密集描述。

Result: 实验表明，DEMO在CompMo和改编基准上显著优于现有方法，实现了更准确的动作时间定位与描述。

Conclusion: 该工作为3D人体动作理解与描述建立了新的研究基础，推动了从生成到理解的范式发展。

Abstract: Recent advances in 3D human motion and language integration have primarily
focused on text-to-motion generation, leaving the task of motion understanding
relatively unexplored. We introduce Dense Motion Captioning, a novel task that
aims to temporally localize and caption actions within 3D human motion
sequences. Current datasets fall short in providing detailed temporal
annotations and predominantly consist of short sequences featuring few actions.
To overcome these limitations, we present the Complex Motion Dataset (CompMo),
the first large-scale dataset featuring richly annotated, complex motion
sequences with precise temporal boundaries. Built through a carefully designed
data generation pipeline, CompMo includes 60,000 motion sequences, each
composed of multiple actions ranging from at least two to ten, accurately
annotated with their temporal extents. We further present DEMO, a model that
integrates a large language model with a simple motion adapter, trained to
generate dense, temporally grounded captions. Our experiments show that DEMO
substantially outperforms existing methods on CompMo as well as on adapted
benchmarks, establishing a robust baseline for future research in 3D motion
understanding and captioning.

</details>


### [54] [PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization](https://arxiv.org/abs/2511.05393)
*Zehui Feng,Tian Qiu,Tong Wu,Junxuan Li,Huayuan Xu,Ting Han*

Main category: cs.CV

TL;DR: 提出PreResQ-R1，一种基于偏好-响应解耦的强化学习框架，统一绝对评分回归与相对排序一致性，在图像和视频质量评估中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉质量评估方法依赖监督微调或仅排序目标，导致推理浅层、评分校准差、跨域泛化能力弱。

Method: 提出PreResQ-R1，采用双分支奖励机制，分别建模样本内响应一致性与样本间偏好对齐，通过Group Relative Policy Optimization（GRPO）优化，并设计全局-时序与局部-空间数据流策略用于视频质量评估。

Result: 在6K图像和28K视频上微调后，PreResQ-R1在10个IQA和5个VQA基准上达到SOTA，IQA任务SRCC和PLCC指标分别提升5.30%和2.15%，并生成与人类感知对齐的可解释推理路径。

Conclusion: PreResQ-R1通过解耦偏好与响应的强化学习框架，实现了更细粒度、稳定且可解释的视觉质量评估，在少量数据下表现出强泛化能力和优越性能。

Abstract: Visual Quality Assessment (QA) seeks to predict human perceptual judgments of
visual fidelity. While recent multimodal large language models (MLLMs) show
promise in reasoning about image and video quality, existing approaches mainly
rely on supervised fine-tuning or rank-only objectives, resulting in shallow
reasoning, poor score calibration, and limited cross-domain generalization. We
propose PreResQ-R1, a Preference-Response Disentangled Reinforcement Learning
framework that unifies absolute score regression and relative ranking
consistency within a single reasoning-driven optimization scheme. Unlike prior
QA methods, PreResQ-R1 introduces a dual-branch reward formulation that
separately models intra-sample response coherence and inter-sample preference
alignment, optimized via Group Relative Policy Optimization (GRPO). This design
encourages fine-grained, stable, and interpretable chain-of-thought reasoning
about perceptual quality. To extend beyond static imagery, we further design a
global-temporal and local-spatial data flow strategy for Video Quality
Assessment. Remarkably, with reinforcement fine-tuning on only 6K images and
28K videos, PreResQ-R1 achieves state-of-the-art results across 10 IQA and 5
VQA benchmarks under both SRCC and PLCC metrics, surpassing by margins of 5.30%
and textbf2.15% in IQA task, respectively. Beyond quantitative gains, it
produces human-aligned reasoning traces that reveal the perceptual cues
underlying quality judgments. Code and model are available.

</details>


### [55] [AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly](https://arxiv.org/abs/2511.05394)
*Alexander Htet Kyaw,Haotian Ma,Sasa Zivkovic,Jenny Sabin*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习目标识别的AR辅助装配工作流程，通过实时框选组件及其安装位置，提供逐步指导，无需预先手动分类或标记组件。


<details>
  <summary>Details</summary>
Motivation: 解决传统装配过程中需要手动查找、分类和标记组件的问题，提高装配效率和准确性。

Method: 利用深度学习的目标识别技术，在增强现实中为每个装配步骤显示对应组件的边界框及其应放置的位置，实现与物理空间的实时对齐。

Result: 系统能够准确识别LEGO组件并引导用户完成组装，验证了该方法在AR辅助装配中的可行性。

Conclusion: 该AI辅助AR装配系统有效减少了人工干预，展示了在复杂装配任务中应用深度学习与AR结合的巨大潜力。

Abstract: We present an AI-assisted Augmented Reality assembly workflow that uses deep
learning-based object recognition to identify different assembly components and
display step-by-step instructions. For each assembly step, the system displays
a bounding box around the corresponding components in the physical space, and
where the component should be placed. By connecting assembly instructions with
the real-time location of relevant components, the system eliminates the need
for manual searching, sorting, or labeling of different components before each
assembly. To demonstrate the feasibility of using object recognition for
AR-assisted assembly, we highlight a case study involving the assembly of LEGO
sculptures.

</details>


### [56] [PALM: A Dataset and Baseline for Learning Multi-subject Hand Prior](https://arxiv.org/abs/2511.05403)
*Zicong Fan,Edoardo Remelli,David Dimond,Fadime Sener,Liuhao Ge,Bugra Tekin,Cem Keskin,Shreyas Hampali*

Main category: cs.CV

TL;DR: 提出了PALM数据集，包含263名受试者的1.3万次高质量手部扫描和9万张多视角图像，用于推动基于单张图像的个性化手部头像建模研究。


<details>
  <summary>Details</summary>
Motivation: 由于手部几何、外观和姿态复杂，且缺乏同时包含精确3D几何、高分辨率多视角图像和多样化人群的数据集，从图像创建高质量个性化手部头像具有挑战性。

Method: 构建了大规模数据集PALM，并提出PALM-Net，通过基于物理的逆向渲染学习多主体的手部几何与材质属性先验，实现逼真且可重照明的单图像手部头像个性化。

Result: 提供了包含1.3万次手部扫描和9万张多视角图像的大规模、多样化数据集，并展示了PALM-Net在单图像手部头像个性化中的有效性。

Conclusion: PALM数据集及其基准方法为手部建模及相关研究提供了宝贵的现实世界资源。

Abstract: The ability to grasp objects, signal with gestures, and share emotion through
touch all stem from the unique capabilities of human hands. Yet creating
high-quality personalized hand avatars from images remains challenging due to
complex geometry, appearance, and articulation, particularly under
unconstrained lighting and limited views. Progress has also been limited by the
lack of datasets that jointly provide accurate 3D geometry, high-resolution
multiview imagery, and a diverse population of subjects. To address this, we
present PALM, a large-scale dataset comprising 13k high-quality hand scans from
263 subjects and 90k multi-view images, capturing rich variation in skin tone,
age, and geometry. To show its utility, we present a baseline PALM-Net, a
multi-subject prior over hand geometry and material properties learned via
physically based inverse rendering, enabling realistic, relightable
single-image hand avatar personalization. PALM's scale and diversity make it a
valuable real-world resource for hand modeling and related research.

</details>


### [57] [Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments](https://arxiv.org/abs/2511.05404)
*Laura Alejandra Encinar Gonzalez,John Folkesson,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.CV

TL;DR: 本文提出MPRF，一种基于多模态基础模型的环路闭合检测方法，结合视觉与LiDAR模态，在弱纹理和非结构化环境中实现鲁棒的位姿估计，优于现有检索方法。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止环境（如行星探测）中，传统视觉和LiDAR方法因纹理缺失、别名效应或点云稀疏而难以可靠地进行环路闭合检测。

Method: MPRF采用两阶段视觉检索策略，结合DINOv2特征与SALAD聚合进行候选筛选，并利用SONATA-based LiDAR描述子进行几何验证，同时引入6-DoF位姿估计以提升精度。

Result: 在S3LI和S3LI Vulcano数据集上，MPRF在精度上超过现有最先进检索方法，并在低纹理区域展现出更强的位姿估计鲁棒性。

Conclusion: MPRF通过融合多模态基础模型，在准确性、效率与可靠性之间取得良好平衡，为SLAM系统提供了可解释的匹配结果，展示了基础模型在统一地点识别与位姿估计中的潜力。

Abstract: Robust loop closure detection is a critical component of Simultaneous
Localization and Mapping (SLAM) algorithms in GNSS-denied environments, such as
in the context of planetary exploration. In these settings, visual place
recognition often fails due to aliasing and weak textures, while LiDAR-based
methods suffer from sparsity and ambiguity. This paper presents MPRF, a
multimodal pipeline that leverages transformer-based foundation models for both
vision and LiDAR modalities to achieve robust loop closure in severely
unstructured environments. Unlike prior work limited to retrieval, MPRF
integrates a two-stage visual retrieval strategy with explicit 6-DoF pose
estimation, combining DINOv2 features with SALAD aggregation for efficient
candidate screening and SONATA-based LiDAR descriptors for geometric
verification. Experiments on the S3LI dataset and S3LI Vulcano dataset show
that MPRF outperforms state-of-the-art retrieval methods in precision while
enhancing pose estimation robustness in low-texture regions. By providing
interpretable correspondences suitable for SLAM back-ends, MPRF achieves a
favorable trade-off between accuracy, efficiency, and reliability,
demonstrating the potential of foundation models to unify place recognition and
pose estimation. Code and models will be released at github.com/DLR-RM/MPRF.

</details>


### [58] [Sharing the Learned Knowledge-base to Estimate Convolutional Filter Parameters for Continual Image Restoration](https://arxiv.org/abs/2511.05421)
*Aupendu Kar,Krishnendu Ghosh,Prabir Kumar Biswas*

Main category: cs.CV

TL;DR: 提出一种基于卷积层简单修改的持续图像恢复方法，可在不改变主干网络结构的情况下适应新任务，有效缓解遗忘问题，且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法在图像恢复领域面临大尺寸图像和多样化退化类型的挑战，且通常需要复杂的结构修改，导致计算开销高；而正则化方法不适用于需不同特征处理的多种恢复任务。

Method: 对卷积层进行简单修改，引入可学习的适配模块，在不改动主干网络的前提下实现知识迁移和任务自适应，支持无缝集成到任意深度架构中。

Result: 实验表明该方法在新增恢复任务时不影响原有任务性能，且通过利用先前任务构建的知识库提升了新任务的表现，同时训练参数增加但计算开销和推理时间无显著上升。

Conclusion: 所提方法实现了高效、灵活的持续图像恢复，无需复杂结构修改，具有良好的扩展性和实用性，为持续学习在图像恢复中的应用提供了可行方案。

Abstract: Continual learning is an emerging topic in the field of deep learning, where
a model is expected to learn continuously for new upcoming tasks without
forgetting previous experiences. This field has witnessed numerous
advancements, but few works have been attempted in the direction of image
restoration. Handling large image sizes and the divergent nature of various
degradation poses a unique challenge in the restoration domain. However,
existing works require heavily engineered architectural modifications for new
task adaptation, resulting in significant computational overhead.
Regularization-based methods are unsuitable for restoration, as different
restoration challenges require different kinds of feature processing. In this
direction, we propose a simple modification of the convolution layer to adapt
the knowledge from previous restoration tasks without touching the main
backbone architecture. Therefore, it can be seamlessly applied to any deep
architecture without any structural modifications. Unlike other approaches, we
demonstrate that our model can increase the number of trainable parameters
without significantly increasing computational overhead or inference time.
Experimental validation demonstrates that new restoration tasks can be
introduced without compromising the performance of existing tasks. We also show
that performance on new restoration tasks improves by adapting the knowledge
from the knowledge base created by previous restoration tasks. The code is
available at https://github.com/aupendu/continual-restore.

</details>


### [59] [Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis](https://arxiv.org/abs/2511.05432)
*Dogucan Yaman,Seymanur Akti,Fevziye Irem Eyiokur,Alexander Waibel*

Main category: cs.CV

TL;DR: 提出了一种基于HierSpeech++潜在语音表示的文本到说话人脸合成框架，通过两阶段训练实现音频与视觉的高度对齐。


<details>
  <summary>Details</summary>
Motivation: 解决文本到说话人脸合成中音频与视觉不同步、表情不自然以及TTS特征分布偏移的问题。

Method: 设计Text-to-Vec模块生成Wav2Vec2嵌入，并联合条件化语音和面部生成；采用预训练在Wav2Vec2嵌入上、微调在TTS输出上的两阶段训练策略。

Result: 实现了无需真实音频推理下的自然、富有表现力的语音与同步面部动作，在唇形同步和视觉真实感上优于级联方法。

Conclusion: 该方法能有效提升音频-视觉一致性与说话人脸合成质量，尤其在分布偏移处理和端到端同步方面具有优势。

Abstract: We propose a text-to-talking-face synthesis framework leveraging latent
speech representations from HierSpeech++. A Text-to-Vec module generates
Wav2Vec2 embeddings from text, which jointly condition speech and face
generation. To handle distribution shifts between clean and TTS-predicted
features, we adopt a two-stage training: pretraining on Wav2Vec2 embeddings and
finetuning on TTS outputs. This enables tight audio-visual alignment, preserves
speaker identity, and produces natural, expressive speech and synchronized
facial motion without ground-truth audio at inference. Experiments show that
conditioning on TTS-predicted latent features outperforms cascaded pipelines,
improving both lip-sync and visual realism.

</details>


### [60] [How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?](https://arxiv.org/abs/2511.05449)
*Tuan Anh Tran,Duy M. H. Nguyen,Hoai-Chau Tran,Michael Barz,Khoa D. Doan,Roger Wattenhofer,Ngo Anh Vien,Mathias Niepert,Daniel Sonntag,Paul Swoboda*

Main category: cs.CV

TL;DR: 本文提出了gitmerge3D，一种全局感知的图令牌合并方法，可将3D点云Transformer中的令牌数量减少90-95%，同时保持竞争力的性能，揭示了当前模型存在过度令牌化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的3D点云Transformer依赖密集令牌表示，导致训练和推理过程中计算和内存成本高昂；本文旨在解决这一效率瓶颈。

Method: 提出gitmerge3D，通过全局信息指导的图结构进行令牌合并，显著减少令牌数量。

Result: 在多个3D视觉任务上验证了该方法，令牌数减少90-95%，计算效率显著提升，且性能保持稳定。

Conclusion: 当前3D Transformer模型存在显著的令牌冗余，gitmerge3D为构建高效、可扩展的3D基础架构提供了新方向。

Abstract: Recent advances in 3D point cloud transformers have led to state-of-the-art
results in tasks such as semantic segmentation and reconstruction. However,
these models typically rely on dense token representations, incurring high
computational and memory costs during training and inference. In this work, we
present the finding that tokens are remarkably redundant, leading to
substantial inefficiency. We introduce gitmerge3D, a globally informed graph
token merging method that can reduce the token count by up to 90-95% while
maintaining competitive performance. This finding challenges the prevailing
assumption that more tokens inherently yield better performance and highlights
that many current models are over-tokenized and under-optimized for
scalability. We validate our method across multiple 3D vision tasks and show
consistent improvements in computational efficiency. This work is the first to
assess redundancy in large-scale 3D transformer models, providing insights into
the development of more efficient 3D foundation architectures. Our code and
checkpoints are publicly available at https://gitmerge3d.github.io

</details>


### [61] [The Potential of Copernicus Satellites for Disaster Response: Retrieving Building Damage from Sentinel-1 and Sentinel-2](https://arxiv.org/abs/2511.05461)
*Olivier Dietrich,Merlin Alfredsson,Emilia Arens,Nando Metzger,Torben Peters,Linus Scheibenreif,Jan Dirk Wegner,Konrad Schindler*

Main category: cs.CV

TL;DR: 本研究探讨了中分辨率地球观测图像（来自哥白尼计划的Sentinel-1和Sentinel-2）在建筑物损毁评估中的应用，提出了xBD-S12数据集，并发现尽管空间分辨率为10米，仍能有效检测多数灾害场景下的损毁情况；复杂模型在泛化能力上表现不佳，基础地理模型实际增益有限，表明中分辨率影像可作为快速大范围灾损评估的有效补充手段。


<details>
  <summary>Details</summary>
Motivation: 由于高分辨率遥感影像常受限于获取难度和覆盖范围，急需一种更广泛可用的数据源用于快速灾害损毁评估，因此探索中分辨率影像（如Sentinel系列）在建筑物损毁识别中的潜力具有重要意义。

Method: 构建了一个包含10,315对前后影像的xBD-S12数据集，结合Sentinel-1与Sentinel-2影像，并与现有xBD基准对齐；通过一系列实验评估不同模型架构在损毁检测任务上的性能，分析其在不同灾害类型中的泛化能力。

Result: 实验证明，即使在10米分辨率下，仍可在多种灾害场景中较准确地检测和绘制建筑物损毁图；但更复杂的模型架构并未带来明显优势，且在未见灾害类型上泛化能力较差；现有的地理空间基础模型实际提升有限。

Conclusion: 哥白尼计划的中分辨率影像（如Sentinel-1/2）是快速、大范围灾害损毁评估的可行数据源，可有效补充高分辨率影像的不足；同时发布数据集、代码和训练模型以推动后续研究。

Abstract: Natural disasters demand rapid damage assessment to guide humanitarian
response. Here, we investigate whether medium-resolution Earth observation
images from the Copernicus program can support building damage assessment,
complementing very-high resolution imagery with often limited availability. We
introduce xBD-S12, a dataset of 10,315 pre- and post-disaster image pairs from
both Sentinel-1 and Sentinel-2, spatially and temporally aligned with the
established xBD benchmark. In a series of experiments, we demonstrate that
building damage can be detected and mapped rather well in many disaster
scenarios, despite the moderate 10$\,$m ground sampling distance. We also find
that, for damage mapping at that resolution, architectural sophistication does
not seem to bring much advantage: more complex model architectures tend to
struggle with generalization to unseen disasters, and geospatial foundation
models bring little practical benefit. Our results suggest that Copernicus
images are a viable data source for rapid, wide-area damage assessment and
could play an important role alongside VHR imagery. We release the xBD-S12
dataset, code, and trained models to support further research.

</details>


### [62] [Photo Dating by Facial Age Aggregation](https://arxiv.org/abs/2511.05464)
*Jakub Paplham,Vojtech Franc*

Main category: cs.CV

TL;DR: 提出了一种利用图像中人脸信息进行照片年代估计的新方法，并发布了包含160多万标注人脸的CSFD-1.6M数据集。通过结合面部识别、年龄估计和职业时间先验的多面孔信息聚合框架，显著优于基于场景的基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的照片年代估计方法多依赖场景信息，忽略人物面部提供的丰富时间线索，尤其是多人图像中的多面孔信息未被有效利用。

Method: 构建一个概率框架，融合现代人脸识别模型、年龄估计模型提供的视觉证据以及基于人物职业生涯的时间先验，对多个面孔的信息进行聚合以推断拍摄年份。

Result: 在实验中，聚合多个面孔的信息持续提升性能，尤其在包含多个可识别个体的图像上，显著优于强健的基于场景的基线方法。

Conclusion: 利用多个人脸信息并结合视觉特征与时间先验进行照片年代估计是有效的，所提出的方法在性能上优于现有基线，验证了人脸信息在图像时间定位中的巨大潜力。

Abstract: We introduce a novel method for Photo Dating which estimates the year a
photograph was taken by leveraging information from the faces of people present
in the image. To facilitate this research, we publicly release CSFD-1.6M, a new
dataset containing over 1.6 million annotated faces, primarily from movie
stills, with identity and birth year annotations. Uniquely, our dataset
provides annotations for multiple individuals within a single image, enabling
the study of multi-face information aggregation. We propose a probabilistic
framework that formally combines visual evidence from modern face recognition
and age estimation models, and career-based temporal priors to infer the photo
capture year. Our experiments demonstrate that aggregating evidence from
multiple faces consistently improves the performance and the approach
significantly outperforms strong, scene-based baselines, particularly for
images containing several identifiable individuals.

</details>


### [63] [EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes](https://arxiv.org/abs/2511.05467)
*Sanghyeon Chang,Srikar Arani,Nishant Sai Nuthalapati,Youngjoon Suh,Nicholas Choi,Siavash Khodakarami,Md Rakibul Hasan Roni,Nenad Miljkovic,Aparna Chandramowlishwaran,Yoonjin Won*

Main category: cs.CV

TL;DR: 提出基于神经形态传感器信号的实时流动工况分类框架，利用事件驱动数据实现高精度、低延迟的流动沸腾监测。


<details>
  <summary>Details</summary>
Motivation: 传统光学成像方法计算量大、时间分辨率不足，难以捕捉瞬态流动行为，亟需一种能够准确且低延迟地实时监测流动工况的方法。

Method: 采用神经形态传感器获取事件驱动的亮度变化信号，构建五种分类模型（包括传统图像和事件数据模型），并设计异步处理流水线与多数投票机制以实现连续稳定的预测。

Result: 事件数据模型优于帧基方法，其中基于事件的LSTM模型达到97.6%的分类精度，处理时间为0.28 ms，支持低延迟、高可靠性的实时预测。

Conclusion: 该框架结合神经形态传感与事件驱动模型，显著提升流动工况识别的速度与准确性，适用于实验控制与智能热管理中的实时反馈。

Abstract: Flow boiling is an efficient heat transfer mechanism capable of dissipating
high heat loads with minimal temperature variation, making it an ideal thermal
management method. However, sudden shifts between flow regimes can disrupt
thermal performance and system reliability, highlighting the need for accurate
and low-latency real-time monitoring. Conventional optical imaging methods are
limited by high computational demands and insufficient temporal resolution,
making them inadequate for capturing transient flow behavior. To address this,
we propose a real-time framework based on signals from neuromorphic sensors for
flow regime classification. Neuromorphic sensors detect changes in brightness
at individual pixels, which typically correspond to motion at edges, enabling
fast and efficient detection without full-frame reconstruction, providing
event-based information. We develop five classification models using both
traditional image data and event-based data, demonstrating that models
leveraging event data outperform frame-based approaches due to their
sensitivity to dynamic flow features. Among these models, the event-based long
short-term memory model provides the best balance between accuracy and speed,
achieving 97.6% classification accuracy with a processing time of 0.28 ms. Our
asynchronous processing pipeline supports continuous, low-latency predictions
and delivers stable output through a majority voting mechanisms, enabling
reliable real-time feedback for experimental control and intelligent thermal
management.

</details>


### [64] [Semantic-Guided Natural Language and Visual Fusion for Cross-Modal Interaction Based on Tiny Object Detection](https://arxiv.org/abs/2511.05474)
*Xian-Hong Huang,Hui-Kai Su,Chi-Chia Sun,Jun-Wei Hsieh*

Main category: cs.CV

TL;DR: 本文提出了一种结合语义引导的自然语言处理与先进视觉识别骨干网络的跨模态微小目标检测方法，通过集成BERT与PRB-FPN-Net，并采用ELAN、MSP和CSP等创新架构，实现了高效、精准的小目标检测。


<details>
  <summary>Details</summary>
Motivation: 为提升复杂场景下微小目标的检测精度与效率，探索自然语言与视觉模型的深度融合。

Method: 将BERT语言模型与CNN-based PRB-FPN-Net结合，引入ELAN、MSP、CSP等骨干结构，利用词形还原与微调技术对齐文本语义与视觉特征。

Result: 在COCO2017验证集上达到52.6%的AP，显著优于YOLO-World，参数量仅为Transformer模型（如GLIP）的一半，且在多尺度目标检测中表现出良好可扩展性与鲁棒性。

Conclusion: 自然语言理解与先进骨干网络的融合能有效提升目标检测的准确性、效率及实际应用适应性，为跨模态检测提供了新范式。

Abstract: This paper introduces a cutting-edge approach to cross-modal interaction for
tiny object detection by combining semantic-guided natural language processing
with advanced visual recognition backbones. The proposed method integrates the
BERT language model with the CNN-based Parallel Residual Bi-Fusion Feature
Pyramid Network (PRB-FPN-Net), incorporating innovative backbone architectures
such as ELAN, MSP, and CSP to optimize feature extraction and fusion. By
employing lemmatization and fine-tuning techniques, the system aligns semantic
cues from textual inputs with visual features, enhancing detection precision
for small and complex objects. Experimental validation using the COCO and
Objects365 datasets demonstrates that the model achieves superior performance.
On the COCO2017 validation set, it attains a 52.6% average precision (AP),
outperforming YOLO-World significantly while maintaining half the parameter
consumption of Transformer-based models like GLIP. Several test on different of
backbones such ELAN, MSP, and CSP further enable efficient handling of
multi-scale objects, ensuring scalability and robustness in
resource-constrained environments. This study underscores the potential of
integrating natural language understanding with advanced backbone
architectures, setting new benchmarks in object detection accuracy, efficiency,
and adaptability to real-world challenges.

</details>


### [65] [GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.05477)
*Guojie Li,Anwar P. P. Abdul Majeed,Muhammad Ateeq,Anh Nguyen,Fan Zhang*

Main category: cs.CV

TL;DR: GroupKAN是一种轻量级医学图像分割网络，通过引入分组KAN变换和分组KAN激活模块，在降低计算复杂度的同时提升了精度和可解释性，在多个医学数据集上优于U-KAN。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有卷积网络缺乏自适应非线性和透明决策、Transformer架构存在二次复杂度和注意力机制不透明的问题，同时克服U-KAN因全通道变换导致的高计算复杂度限制其扩展性的缺陷。

Method: 提出GroupKAN，包含两个新模块：(1) 分组KAN变换，将通道分为G组进行多元样条映射，将复杂度从O(C^2)降至O(C^2/G)；(2) 分组KAN激活，在每组内共享样条映射实现高效的逐token非线性变换。

Result: 在BUSI、GlaS和CVC三个医学图像分割基准上，GroupKAN平均IoU达到79.80%，比U-KAN提升+1.11%，参数量仅为U-KAN的47.6%（3.02M vs 6.35M），且具有更好的可解释性。

Conclusion: GroupKAN在保持高精度和良好可解释性的同时显著减少参数量并降低计算复杂度，是适用于医学图像分割的高效、可扩展的新型网络架构。

Abstract: Medical image segmentation requires models that are accurate, lightweight,
and interpretable. Convolutional architectures lack adaptive nonlinearity and
transparent decision-making, whereas Transformer architectures are hindered by
quadratic complexity and opaque attention mechanisms. U-KAN addresses these
challenges using Kolmogorov-Arnold Networks, achieving higher accuracy than
both convolutional and attention-based methods, fewer parameters than
Transformer variants, and improved interpretability compared to conventional
approaches. However, its O(C^2) complexity due to full-channel transformations
limits its scalability as the number of channels increases. To overcome this,
we introduce GroupKAN, a lightweight segmentation network that incorporates two
novel, structured functional modules: (1) Grouped KAN Transform, which
partitions channels into G groups for multivariate spline mappings, reducing
complexity to O(C^2/G), and (2) Grouped KAN Activation, which applies shared
spline-based mappings within each channel group for efficient, token-wise
nonlinearity. Evaluated on three medical benchmarks (BUSI, GlaS, and CVC),
GroupKAN achieves an average IoU of 79.80 percent, surpassing U-KAN by +1.11
percent while requiring only 47.6 percent of the parameters (3.02M vs 6.35M),
and shows improved interpretability.

</details>


### [66] [TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning](https://arxiv.org/abs/2511.05489)
*Junwen Pan,Qizhe Zhang,Rui Zhang,Ming Lu,Xin Wan,Yuan Zhang,Chang Liu,Qi She*

Main category: cs.CV

TL;DR: 本文提出TimeSearch-R，将时间搜索重构为交错的文本-视频思维过程，并通过强化学习实现端到端优化；引入GRPO-CSV方法提升搜索完整性和推理一致性，在多个视频理解基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间搜索方法依赖手工设计的搜索流程，缺乏端到端优化，难以学习最优搜索策略，且在强化学习中存在中间决策无监督、探索不足和逻辑不一致问题。

Method: 将时间搜索建模为交错的文本-视频推理过程，采用强化学习框架（GRPO-CSV），其中引入完备性自验证机制，利用同一策略模型对已搜索帧进行充分性验证，以提升搜索完整性和推理连贯性，并构建专门数据集用于SFT冷启动和RL训练。

Result: 在Haystack-LVBench、Haystack-Ego4D、VideoMME、MLVU和LongVideoBench等多个基准上显著优于现有方法，其中在LongVideoBench上相比Qwen2.5-VL提升4.1%，相比Video-R1提升2.0%。

Conclusion: TimeSearch-R通过将时间搜索融入推理过程并引入完备性自验证机制，实现了更完整和一致的长视频理解，为端到端优化的时间搜索提供了新范式。

Abstract: Temporal search aims to identify a minimal set of relevant frames from tens
of thousands based on a given query, serving as a foundation for accurate
long-form video understanding. Existing works attempt to progressively narrow
the search space. However, these approaches typically rely on a hand-crafted
search process, lacking end-to-end optimization for learning optimal search
strategies. In this paper, we propose TimeSearch-R, which reformulates temporal
search as interleaved text-video thinking, seamlessly integrating searching
video clips into the reasoning process through reinforcement learning (RL).
However, applying RL training methods, such as Group Relative Policy
Optimization (GRPO), to video reasoning can result in unsupervised intermediate
search decisions. This leads to insufficient exploration of the video content
and inconsistent logical reasoning. To address these issues, we introduce GRPO
with Completeness Self-Verification (GRPO-CSV), which gathers searched video
frames from the interleaved reasoning process and utilizes the same policy
model to verify the adequacy of searched frames, thereby improving the
completeness of video reasoning. Additionally, we construct datasets
specifically designed for the SFT cold-start and RL training of GRPO-CSV,
filtering out samples with weak temporal dependencies to enhance task
difficulty and improve temporal search capabilities. Extensive experiments
demonstrate that TimeSearch-R achieves significant improvements on temporal
search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as
long-form video understanding benchmarks like VideoMME and MLVU. Notably,
TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1%
improvement over the base model Qwen2.5-VL and 2.0% over the advanced video
reasoning model Video-R1. Our code is available at
https://github.com/Time-Search/TimeSearch-R.

</details>


### [67] [Visual Spatial Tuning](https://arxiv.org/abs/2511.05491)
*Rui Yang,Ziyu Zhu,Yanwei Li,Jingjia Huang,Shen Yan,Siyuan Zhou,Zhe Liu,Xiangtai Li,Shuangye Li,Wenqian Wang,Yi Lin,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 本文提出了一个名为视觉空间调优（VST）的框架，旨在提升视觉-语言模型（VLMs）的空间感知与推理能力，通过构建大规模数据集VST-P和VST-R，并采用渐进式训练策略，在不损害通用能力的前提下显著提升了在多个空间基准上的表现。


<details>
  <summary>Details</summary>
Motivation: 为了增强通用架构中视觉-语言模型的空间理解能力，避免引入额外专家编码器所带来的开销和对通用性能的损害。

Method: 提出VST框架，包括两个数据集：VST-P（410万样本，涵盖19种单视图、多图像和视频技能）用于提升空间感知；VST-R（13.5万样本）用于空间推理。采用分阶段训练：先监督微调建立基础空间知识，再用强化学习提升推理能力。

Result: 在MMSI-Bench上达到34.8%，在VSIBench上达到61.2%，均取得当前最优结果，且未影响模型的通用能力。

Conclusion: 所提出的VST范式能有效增强视觉-语言-动作模型的空间能力，为实现更具物理 grounding 的人工智能提供了可行路径。

Abstract: Capturing spatial relationships from visual inputs is a cornerstone of
human-like general intelligence. Several previous studies have tried to enhance
the spatial awareness of Vision-Language Models (VLMs) by adding extra expert
encoders, which brings extra overhead and usually harms general capabilities.
To enhance the spatial ability in general architectures, we introduce Visual
Spatial Tuning (VST), a comprehensive framework to cultivate VLMs with
human-like visuospatial abilities, from spatial perception to reasoning. We
first attempt to enhance spatial perception in VLMs by constructing a
large-scale dataset termed VST-P, which comprises 4.1 million samples spanning
19 skills across single views, multiple images, and videos. Then, we present
VST-R, a curated dataset with 135K samples that instruct models to reason in
space. In particular, we adopt a progressive training pipeline: supervised
fine-tuning to build foundational spatial knowledge, followed by reinforcement
learning to further improve spatial reasoning abilities. Without the
side-effect to general capabilities, the proposed VST consistently achieves
state-of-the-art results on several spatial benchmarks, including $34.8\%$ on
MMSI-Bench and $61.2\%$ on VSIBench. It turns out that the
Vision-Language-Action models can be significantly enhanced with the proposed
spatial tuning paradigm, paving the way for more physically grounded AI.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [68] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 该研究探讨了大语言模型在从打乱的步骤中重建有序过程序列的能力，使用食谱数据集进行评估，并提出了一套综合评价框架。


<details>
  <summary>Details</summary>
Motivation: 为了评估大语言模型在程序性推理任务中的能力，尤其是在步骤顺序对结果至关重要的情况下。

Method: 采用食品食谱数据集，在零样本和少样本设置下评估多个大语言模型，使用Kendall's Tau、NLCS和NED等指标进行综合评估。

Result: 模型性能随序列长度增加而下降，输入步骤位移越大，性能越差。

Conclusion: 当前的大语言模型在处理较长且更混乱的程序性序列时存在局限性。

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [69] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: ATLAS 是一种基于项目反应理论（IRT）的自适应测试框架，通过 Fisher 信息引导的题目选择，在仅使用少量题目的情况下保持大语言模型评估的精确性，显著减少评估成本并揭示传统静态评估中的标注误差和排名偏差。


<details>
  <summary>Details</summary>
Motivation: 传统的语言模型评估方法使用固定题目的平均准确率，忽视了题目质量和信息量的差异，且成本高昂。同时，部分题目存在标注错误，影响评估可靠性。因此需要一种更高效、精准的自适应评估方法。

Method: 提出 ATLAS 框架，结合项目反应理论（IRT）和 Fisher 信息最大化进行动态题目选择，以高效估计模型能力，并分析多个主流基准数据集中的题目质量与模型表现。

Result: 在 HellaSwag 数据集中，仅用 42 个题目（原 5,608）即可达到与完整基准相当的估计精度（MAE=0.154），题目减少达 90%；题目暴露率低于 10%，测试重叠率为 16-27%；发现 3-6% 的题目具有负区分度，表明存在标注错误；IRT 排名与准确率排名存在显著差异，23-31% 的模型排名变动超过 10 位。

Conclusion: ATLAS 能大幅降低评估开销，提升测量效率与公平性，揭示传统静态评估的局限性，为大模型评估提供更科学、可扩展的替代方案。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [70] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: 提出了一种基于情感增强的角色聚类框架SARC，用于提升社交媒体中的虚假新闻检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将情感特征作为辅助信号，忽略了不同用户角色对相同情感极性的影响，限制了模型捕捉细微模式的能力。

Method: 通过BiGRU和注意力机制联合表示评论文本并编码情感信息，生成用户特征；构建可微分的深度聚类模块自动分类用户角色；采用联合优化目标，结合角色聚类与虚假新闻检测任务进行训练。

Result: 在RumourEval-19和Weibo-comp两个基准数据集上的实验表明，SARC在所有指标上均优于基线模型。

Conclusion: SARC通过情感增强的用户角色聚类有效提升了虚假新闻检测的性能，验证了考虑用户角色差异的重要性。

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [71] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文提出将指令层次解析重构为推理任务，通过构建VerIH数据集并使用轻量级强化学习训练模型，使其能够优先处理高优先级指令，从而提升大语言模型在复杂场景下的可控性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在现实决策中需处理来自不同来源的冲突指令，确保高优先级指令（如系统安全策略）能覆盖低优先级请求（如用户输入），以提高模型的可靠性和安全性。

Method: 将指令层次问题转化为推理任务，构建包含一致与冲突指令的VerIH数据集，并采用轻量级强化学习进行微调，使模型学会在响应前‘思考’用户提示与系统指令之间的关系。

Result: 微调后的模型在指令遵循和指令层次基准上表现持续提升，且推理能力可泛化至训练分布之外的安全关键场景，有效增强对越狱和提示注入攻击的防御能力。

Conclusion: 通过推理处理指令层次是一种实现可靠、可控大语言模型的有效路径，系统提示的更新可带来行为上的可预测调整。

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [72] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: EncouRAGe是一个用于简化基于大语言模型和嵌入模型的检索增强生成（RAG）系统开发与评估的Python框架，包含五个模块化组件，支持灵活实验和可扩展开发，并在多个基准数据集上进行了广泛评估。


<details>
  <summary>Details</summary>
Motivation: 为了提升RAG系统的开发效率、科学可重复性和评估全面性，需要一个集成且模块化的框架来支持本地部署和多样化评估。

Method: 提出EncouRAGe框架，包含Type Manifest、RAG Factory、Inference、Vector Store和Metrics五个模块，支持灵活配置和扩展，并在25k问答对和51k文档以上的数据集上进行实验评估。

Result: 实验表明RAG系统仍逊于Oracle Context，Hybrid BM25在所有四个数据集中表现最佳；重排序仅带来轻微性能提升但增加响应延迟。

Conclusion: EncouRAGe为RAG系统提供了可复现、可扩展的开发与评估平台，有助于推动RAG技术的研究与应用。

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [73] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: 本文提出了一种名为multiMentalRoBERTa的细调RoBERTa模型，用于从社交媒体文本中多分类识别常见心理疾病，包括压力、焦虑、抑郁、创伤后应激障碍（PTSD）、自杀意念和中性言论，在六类和五类设置下分别取得了0.839和0.870的宏F1分数，性能优于现有方法，并通过可解释性技术分析关键词汇特征。


<details>
  <summary>Details</summary>
Motivation: 早期发现心理健康问题对于及时提供支持和干预至关重要，而社交媒体文本为自动检测提供了潜在数据源，但现有方法在多类别识别和可解释性方面仍有不足。

Method: 基于多个精选数据集微调RoBERTa模型，进行数据探索以分析类别重叠情况，并与传统机器学习方法、领域专用Transformer模型及基于提示的大语言模型进行比较；采用Layer Integrated Gradients和KeyBERT等可解释性方法识别关键词汇特征。

Result: multiMentalRoBERTa在六类和五类分类任务中分别达到0.839和0.870的宏F1分数，优于MentalBERT和其他基线模型；发现抑郁与自杀意念、焦虑与PTSD之间存在强相关性，压力类别具有广泛重叠性；可解释性分析成功识别出区分抑郁与自杀意念的关键词汇线索。

Conclusion: 细调后的Transformer模型在心理健康文本识别中表现出高准确性和可解释性，multiMentalRoBERTa是一种轻量、鲁棒且可部署的解决方案，适用于心理健康支持平台，但仍需关注公平性、偏见缓解和人机协同安全机制。

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [74] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: Cross-Lingual SynthDocs是一个大规模合成语料库，旨在解决阿拉伯语OCR和文档理解资源稀缺的问题，通过在真实扫描背景上生成双语文本、带音标字体和复杂图表结构，显著提升多模态文档理解性能。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语在光学字符识别（OCR）和文档理解（DU）领域缺乏高质量标注数据的问题，推动多语言文档分析研究。

Method: 构建一个包含超过250万样本的合成数据集，结合真实扫描背景、双语布局和音标感知字体，生成包含文本、表格和图表的多样化阿拉伯语文档，并用于微调Qwen-2.5-VL模型。

Result: 在多个公开阿拉伯语基准上，微调后的模型显著降低了词错误率（WER）和字符错误率（CER），同时提升了表格解析的Tree-Edit Distance Similarity（TEDS）和图表提取得分（CharTeX）。

Conclusion: SynthDocs提供了一个可扩展且视觉逼真的资源，有效提升了阿拉伯语及其他语言的文档理解系统性能，具有广泛的研究与应用价值。

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [75] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li*

Main category: cs.CL

TL;DR: WinnowRAG 是一种无需模型微调、可扩展的检索增强生成框架，通过查询感知的聚类和LLM代理协作机制，在多文档场景下有效过滤噪声并保留关键信息，提升生成响应的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在增加检索文档数量时容易引入噪声，导致生成结果不准确，亟需一种能自动区分并剔除无关或误导性文档的系统化过滤机制。

Method: WinnowRAG分为两个阶段：第一阶段基于查询进行文档聚类，每个主题簇由一个LLM代理生成答案；第二阶段引入批评者LLM评估各代理输出，并迭代筛选有用文档，结合两种策略性合并技术保留关键知识。

Result: 在多个真实数据集上的实验表明，WinnowRAG在响应准确性方面显著优于当前最先进的基线方法，且具备良好的模型通用性和任务适应性。

Conclusion: WinnowRAG通过两阶段的智能过滤与融合机制，有效解决了大规模检索带来的噪声问题，为提升RAG系统的鲁棒性和效率提供了新思路。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [76] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 该论文系统审查了445个大语言模型（LLM）基准测试，发现当前评估在构念效度方面存在不足，并提出了八项改进建议。


<details>
  <summary>Details</summary>
Motivation: 准确评估LLM的能力、安全性和鲁棒性至关重要，但现有基准测试在衡量抽象复杂现象时缺乏足够的构念效度。

Method: 组织29名专家对顶级会议中的445个LLM基准进行系统性综述，分析所测现象、任务和评分指标的有效性。

Result: 发现了影响评估有效性的多种模式和问题，包括测量目标不明确、任务设计不合理和评分指标不恰当等。

Conclusion: 提升LLM评估的构念效度需要更严谨的基准设计，研究提出了八项具体建议以指导未来工作。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [77] [POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios](https://arxiv.org/abs/2511.04705)
*Tingyue Yang,Junchi Yao,Yuhui Guo,Chang Liu*

Main category: cs.CL

TL;DR: POLIS-Bench是首个针对政府双语政策场景中大语言模型的系统性评估套件，提出更新的双语语料库、情景化任务设计和双指标评估框架，并通过大规模实验验证模型性能，支持低成本合规部署。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在政府双语政策场景下缺乏时效性、任务相关性和综合评估能力，难以有效衡量LLM在实际治理中的表现。

Method: 构建了最新的双语政策语料库，设计了三个基于实际场景的任务（条款检索与解释、方案生成、合规判断），并提出结合语义相似度与准确率的双指标评估框架，对超过10个主流LLM进行大规模评测，并基于该基准微调轻量开源模型。

Result: 实验显示推理类模型在跨任务稳定性与准确性上表现更优；基于POLIS-Bench微调的轻量POLIS系列模型在多个子任务上达到或超越强闭源基线，且成本显著降低。

Conclusion: POLIS-Bench为政府双语政策场景提供了更有效、贴近实际的评估标准，同时展示了通过专用基准优化开源模型实现高效合规部署的可行性。

Abstract: We introduce POLIS-Bench, the first rigorous, systematic evaluation suite
designed for LLMs operating in governmental bilingual policy scenarios.
Compared to existing benchmarks, POLIS-Bench introduces three major
advancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,
up-to-date policy corpus that significantly scales the effective assessment
sample size, ensuring relevance to current governance practice. (ii)
Scenario-Grounded Task Design: We distill three specialized, scenario-grounded
tasks -- Clause Retrieval & Interpretation, Solution Generation, and the
Compliance Judgmen--to comprehensively probe model understanding and
application. (iii) Dual-Metric Evaluation Framework: We establish a novel
dual-metric evaluation framework combining semantic similarity with accuracy
rate to precisely measure both content alignment and task requirement
adherence. A large-scale evaluation of over 10 state-of-the-art LLMs on
POLIS-Bench reveals a clear performance hierarchy where reasoning models
maintain superior cross-task stability and accuracy, highlighting the
difficulty of compliance tasks. Furthermore, leveraging our benchmark, we
successfully fine-tune a lightweight open-source model. The resulting POLIS
series models achieves parity with, or surpasses, strong proprietary baselines
on multiple policy subtasks at a significantly reduced cost, providing a
cost-effective and compliant path for robust real-world governmental
deployment.

</details>


### [78] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: 本文提出了GEMMA-SQL，一种基于Gemma 2B架构的轻量级、高效的文本到SQL模型，通过资源高效的迭代微调和多种提示策略，在SPIDER基准上超越多个先进基线模型。


<details>
  <summary>Details</summary>
Motivation: 为了降低文本到SQL系统的资源需求并提升在低硬件成本下的可部署性，同时提高SQL生成的准确性。

Method: 基于开源Gemma 2B模型，采用资源高效的迭代微调方法，并结合少样本学习等多种提示策略；开发了指令微调版本GEMMA-SQL Instruct。

Result: 在SPIDER基准上，GEMMA-SQL Instruct达到66.8%的Test-Suite准确率和63.3%的Exact Set Match准确率，优于IRNet、RYANSQL和CodeXDavinci等模型。

Conclusion: 有效的提示设计和针对性的指令微调能显著提升轻量级模型性能，GEMMA-SQL是一个实用、开源且易于部署的文本到SQL解决方案。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [79] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）中训练样本影响估计的问题，指出当前基于梯度的影响函数方法受限于计算可行性，通常仅使用部分模型层。先前研究认为嵌入层最有效，依据是影响分数的抵消效应。本文提出理论和实证证据表明该抵消效应不可靠，并发现中间注意力层是更好的影响估计器。此外，文章探讨了跨层聚合影响分数的方法，展示了排名和投票等替代标准平均的方法可显著提升性能。最后，提出了无需重新训练模型即可评估影响分数有效性的新方法及噪声检测率（NDR）指标，实验证明其具有强预测能力。通过在不同类型和规模的LLM上进行广泛实验，本文得出结论：首层并不一定比末层更适合LLM影响估计，这与领域内先前认知相悖。


<details>
  <summary>Details</summary>
Motivation: 理解训练样本如何影响大语言模型决策对于解释模型行为和审计大规模数据集至关重要。现有方法因模型参数量巨大而受限，需确定哪些层最适合计算影响。

Method: 提出理论分析与实证研究，挑战Yeh等人（2022）提出的‘抵消效应’假设；比较不同网络层（如嵌入层、中间注意力层、最后层）在影响估计中的表现；探索多种跨层聚合策略（如排名、投票机制），并引入新的评估指标NDR以避免昂贵的模型重训练。

Result: 1. 抵消效应作为选择计算层的依据不可靠；2. 中间注意力层比首层更优地估计训练样本影响；3. 非平均聚合方法（如投票、排序）显著提升影响估计性能；4. 提出的NDR指标能有效评估影响分数质量且无需重训练；5. 实验验证首层并非总是优于末层，颠覆此前共识。

Conclusion: 大语言模型中训练样本影响估计不应局限于首层或依赖抵消效应，而应关注中间注意力层并采用更优的聚合与评估方法；本文提出的NDR指标和跨层分析框架为未来影响函数研究提供了可靠基础。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [80] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.CL

TL;DR: 本文提出RADAR，一种用于脑部MRI中罕见病检测的检索增强诊断推理系统，通过结合外部医学知识（如病例报告和文献）提升AI模型对罕见病的识别能力，无需额外训练即可显著提高诊断准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于罕见病在医学影像中样本稀少，AI模型通常表现不佳；而放射科医生在遇到不熟悉病症时会查阅文献，因此作者受此启发，希望构建一个能模拟这一过程的AI系统。

Method: 使用句子变换器对病例报告和文献进行嵌入，并用FAISS建立索引以实现高效相似性搜索，AI代理通过检索相关临床证据来指导诊断决策，且该系统可与多种大语言模型结合，无需再训练。

Result: 在包含280种罕见病的NOVA数据集上，RADAR最多带来10.2%的性能提升，尤其对DeepSeek等开源模型效果显著，并提供基于文献的可解释结果。

Conclusion: 检索增强推理是一种有效应对医学影像中低发病率疾病诊断的范式，RADAR作为一种模型无关的推理模块，显著提升了罕见病识别的准确性与可解释性。

Abstract: Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [81] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 本文提出了一种基于惊异度方差的图像描述多样性度量方法，发现使用不同语言模型评分可能导致完全相反的结论，因此建议在多样性评估中使用多个评分模型。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地衡量图像描述中的语言多样性，现有方法可能存在偏差，需要一种新的度量方式来避免因单一评分模型导致的错误结论。

Method: 提出使用词元级别的负对数概率（即惊异度）在描述集合内的方差作为多样性指标，并在MSCOCO测试集上比较了五种先进视觉-语言大模型与人类描述的差异，采用n-gram语言模型和通用语言模型进行重评分分析。

Result: 使用专用于描述训练的n-gram语言模型时，人类描述的惊异度方差约为模型的两倍；但使用通用语言模型重评分时，该模式反转。表明评分模型的选择显著影响多样性评估结果。

Conclusion: 仅依赖单一评分模型可能得出错误结论，鲁棒的语言多样性评估应结合多个评分模型的惊异度结果。

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [82] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: 提出ERPO框架以增强大语言模型在残差提示上的探索，通过历史追踪和自适应提高采样温度来恢复训练信号，显著提升数学推理性能。


<details>
  <summary>Details</summary>
Motivation: 随着模型训练时间增加和规模扩大，越来越多的提示变为无奖励方差的残差提示，导致有效训练信号减少、训练多样性下降。

Method: 提出ERPO框架，为每个提示维护历史记录，并对曾生成全正确响应的残差提示自适应提高采样温度，鼓励生成更多样化的推理路径，从而引入错误响应以恢复训练信号。

Result: 在Qwen2.5系列模型上的实验表明，ERPO在多个数学推理基准上持续优于强基线方法。

Conclusion: ERPO能有效利用残差提示中的潜在信息，重新激活训练信号，提升大模型在强化学习与可验证奖励设置下的推理能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [83] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）在生成回答时的语义校准能力，发现基础LLM在开放域问答中具有良好的语义校准性，而RL指令微调和思维链推理会破坏这种校准性，并提出了基于词元预测机制的理论解释。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通常缺乏对其输出的有意义的置信度估计。尽管基础LLM在下一个词元预测上表现出校准性，但其是否能在超越词元层面的意义上评估回答的置信度尚不清楚。因此，本文旨在探究LLM在语义层面的校准能力及其成因。

Method: 提出一种基于采样的语义校准定义，并引入“B-校准”这一广义校准概念，结合最近关于校准与局部损失最优性的理论联系，建立语义校准从词元预测中自然涌现的理论机制，并通过实验验证该理论的三个可检验预测。

Result: 实验证明：（1）基础LLM在多种问答任务中具有语义校准性；（2）RL指令微调会系统性破坏这种校准性；（3）思维链推理也会破坏校准性。此外，理论表明当模型能提前预测自身语义类别分布时，语义校准更易出现。

Conclusion: 本文首次为大语言模型中语义校准的出现时机与原因提供了原理性解释，揭示了语义校准是词元级别预测训练的副产品，并指出了当前微调方法对模型置信度估计的负面影响。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [84] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: 研究表明，通过低秩适配器（LoRA）微调指令调优的大型语言模型，行为自知能力可被轻易诱导并表现为任务特定的线性特征。


<details>
  <summary>Details</summary>
Motivation: 探索大模型行为自知能力出现的最小条件及其机制，以应对潜在的安全风险。

Method: 使用低秩适配器（LoRA）对指令调优的大型语言模型进行受控微调实验。

Result: 发现行为自知能力可通过单个rank-1 LoRA适配器可靠诱导；该能力主要由激活空间中的单一引导向量捕获，且具有任务局部性和非通用性。

Conclusion: 行为自知能力是一种可被轻易诱导和调节的领域特定线性特征。

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [85] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: 本文提出了SDS KoPub VDR，首个用于韩文公文检索的大规模公开基准，包含361份真实文档和600个经人工验证的查询三元组，支持文本与多模态检索任务，揭示了现有模型在跨模态推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视觉文档检索基准忽视非英语语言和官方文件的结构复杂性，缺乏对韩文公共文档的有效评估资源。

Method: 基于361份真实韩文公文构建语料库，使用多模态模型生成600个查询-页面-答案三元组，并通过人工审核确保准确性；设计文本检索和多模态检索两项任务进行评估。

Result: 在文本和多模态检索任务中发现现有最先进模型存在显著性能差距，尤其是在需要跨模态推理的场景下表现不佳。

Conclusion: SDS KoPub VDR为韩文公文理解提供了可靠的评估基准，推动多模态AI在复杂真实文档智能中的发展。

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [86] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: 提出BudgetMem，一种基于记忆增强的架构，通过选择性记忆和特征驱动的显著性评分，在严格内存预算下高效处理长上下文，相比传统RAG节省72.4%内存且仅损失1.0% F1分数。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长上下文时面临计算和内存瓶颈，现有扩展上下文窗口的方法成本过高，难以在资源受限场景部署。

Method: 结合基于特征的显著性评分（如实体密度、TF-IDF、篇章标记、位置偏差）与学习型门控机制，采用BM25稀疏检索，实现有预算限制下的选择性记忆存储。

Result: 在Llama-3.2-3B-Instruct上测试700个问答对，长文档中仅1.0% F1下降，内存节省72.4%；效益随文档长度增加而提升。

Conclusion: BudgetMem为在有限硬件资源上部署高效长上下文语言模型提供了可行方案，有助于普及高级语言理解能力。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [87] [AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent](https://arxiv.org/abs/2511.04921)
*Yu Li,Lehui Li,Qingmin Liao,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出了一种基于集体感知的增强检索框架，用于推荐科研中的基线和数据集，通过自动数据收集、增强的嵌入模型和推理增强重排序，显著提升了实验设计自动化的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数据覆盖范围和推荐相关性上存在不足，主要依赖公开资源且忽视实际论文中使用的数据集，同时过于依赖内容相似性而忽略实验适用性。

Method: 1）构建自动化数据收集管道，关联约十万篇论文与其实际使用的基线和数据集；2）提出集体感知增强的检索器，结合自描述与引用上下文表示，并微调嵌入模型以提升召回效率；3）开发推理增强的重排序器，利用大模型生成可解释的推理链和优化排名。

Result: 所构建的数据集覆盖了过去五年顶级AI会议中85%的实际使用数据集和基线；在Recall@20上提升+5.85%，HitRate@5上提升+8.30%，优于最强基线方法。

Conclusion: 该框架显著推进了实验设计自动化在可靠性与可解释性方面的性能，为LLM代理在科研任务中的应用提供了有效支持。

Abstract: Large language model agents are becoming increasingly capable at web-centric
tasks such as information retrieval, complex reasoning. These emerging
capabilities have given rise to surge research interests in developing LLM
agent for facilitating scientific quest. One key application in AI research is
to automate experiment design through agentic dataset and baseline retrieval.
However, prior efforts suffer from limited data coverage, as recommendation
datasets primarily harvest candidates from public portals and omit many
datasets actually used in published papers, and from an overreliance on content
similarity that biases model toward superficial similarity and overlooks
experimental suitability. Harnessing collective perception embedded in the
baseline and dataset citation network, we present a comprehensive framework for
baseline and dataset recommendation. First, we design an automated
data-collection pipeline that links roughly one hundred thousand accepted
papers to the baselines and datasets they actually used. Second, we propose a
collective perception enhanced retriever. To represent the position of each
dataset or baseline within the scholarly network, it concatenates
self-descriptions with aggregated citation contexts. To achieve efficient
candidate recall, we finetune an embedding model on these representations.
Finally, we develop a reasoning-augmented reranker that exact interaction
chains to construct explicit reasoning chains and finetunes a large language
model to produce interpretable justifications and refined rankings. The dataset
we curated covers 85\% of the datasets and baselines used at top AI conferences
over the past five years. On our dataset, the proposed method outperforms the
strongest prior baseline with average gains of +5.85\% in Recall@20, +8.30\% in
HitRate@5. Taken together, our results advance reliable, interpretable
automation of experimental design.

</details>


### [88] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: 本研究提出了一种新的验证方法，用于检测Wikidata中特定领域的分类错误、过度泛化的子类链接和冗余连接，并引入了新的评估标准来判断这些问题是否需要修正。


<details>
  <summary>Details</summary>
Motivation: 由于Wikidata相对宽松的编辑策略导致了分类上的不一致性，因此需要一种有效的方法来识别和评估这些结构问题。

Method: 基于先前的研究，提出并应用一种新颖的验证方法，结合新设计的评估标准，并开发一个系统以允许用户检查任意Wikidata实体的分类关系。

Result: 确认了Wikidata特定领域中存在分类错误、过度泛化和冗余连接的问题，并通过新系统实现了对这些问题的有效审查。

Conclusion: 该方法能够有效识别Wikidata中的结构性质量问题，利用其众包特性提升知识图谱的准确性与可用性。

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [89] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: 提出了一种名为LoPT的无损并行分词框架，通过基于字符位置的匹配和动态调整块长度，在保证与标准串行分词结果一致的前提下，显著加速长文本分词。


<details>
  <summary>Details</summary>
Motivation: 现有并行分词方法因文本分割边界问题导致合并后结果不一致，且分词成为长上下文推理中的性能瓶颈。

Method: 采用基于字符位置的匹配策略和动态调整分块长度的方法，精确对齐和合并分词片段，确保结果与串行分词完全一致。

Result: 在多种长文本数据集上实验表明，LoPT能显著提速并保持无损分词，同时提供了理论一致性证明和鲁棒性分析。

Conclusion: LoPT有效解决了并行分词中的边界效应问题，在保证结果准确的同时大幅提升分词效率，适用于大模型长上下文推理场景。

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [90] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: 本研究探讨了大语言模型在扮演道德模糊或反派角色时的表现，发现其安全性对齐机制显著影响了角色扮演的真实性，尤其是对于欺骗性和操纵性等特质。为此，作者提出了Moral RolePlay基准，揭示了当前模型在创造性保真度与安全对齐之间的关键矛盾。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型经过安全对齐训练，可能难以真实模拟非亲社会或反派角色，这限制了其在创意生成任务中的表现。研究旨在探究这一限制及其成因。

Method: 提出Moral RolePlay基准，包含四层道德对齐量表和平衡测试集，评估最先进的大语言模型在扮演从道德楷模到纯粹反派角色时的表现，并分析其行为模式。

Result: 随着角色道德水平下降，模型的角色扮演保真度呈单调递减；模型难以体现‘欺骗’和‘操纵’等特质，常以表面攻击性替代复杂恶意；且通用对话能力无法预测反派扮演效果，高安全对齐模型表现更差。

Conclusion: 安全性对齐虽有助于模型安全，却牺牲了对反派角色的刻画能力，暴露了安全与创意之间的根本冲突，需发展更细致、情境感知的对齐方法。

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [91] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 本文提出了一种通过中文大语言模型生成并过滤高质量常见情感事件的方法，构建了首个大规模中文情感事件常识知识库（共102,218条），并验证了其在情感原因提取任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 情感事件知识对多种应用具有重要意义，但获取上下文无关的通用情感事件（如“获奖”、“被批评”）十分困难，尤其是在中文环境下缺乏大规模常识知识库。

Method: 首先收集中文情感事件指示词，利用这些指示词提示中文大语言模型生成情感事件；接着训练一个过滤器以去除无效结果，并采用不同技术对事件进行正负情感极性分类。

Result: 成功构建包含102,218个高质量常见中文情感事件的知识库，具备情感极性标注；内在意图评估表明该方法能有效获取常见情感事件，外在应用案例显示其在情感原因提取任务中具有良好潜力。

Conclusion: 所提方法能够高效获取带情感标签的中文常见情感事件，构建的知识库填补了中文情感常识领域的空白，且在实际任务中展现出应用价值。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [92] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien*

Main category: cs.CL

TL;DR: 本文提出了PBSUITE，一个用于评估大语言模型在多轮对抗性对话中遵守多样化行为规范能力的动态评估套件，揭示了现有对齐方法在复杂现实场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通常被对齐到通用的安全和使用原则，但在实际应用中需适应不同组织的多样化政策和需求，因此需要评估模型在多元对齐目标下的表现。

Method: 构建包含300个真实行为策略的数据集，并设计动态评估框架，在多轮交互和对抗条件下测试模型对定制化行为规范的遵循能力。

Result: 实验发现主流大语言模型在单轮对话中违规率低于4%，但在多轮对抗场景中违规率高达84%，表明现有对齐方法在复杂情境下效果显著下降。

Conclusion: 现有对齐和安全机制难以有效支持多元对齐需求，PBSUITE为未来研究提供了数据和分析基础。

Abstract: Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [93] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: 本文提出了一个用于评估乌克兰语代码生成和竞赛编程问题解决能力的新基准UA-Code-Bench，包含来自Eolymp平台的500个问题，并对13种主流模型进行了评测，结果显示即使是表现最好的模型也仅能解决一半的问题，突显了低资源语言中代码生成的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准多集中于从英语翻译的任务或仅评估简单的语言理解，难以真实反映大模型在低资源语言中的实际能力，因此需要针对低资源语言（如乌克兰语）建立更全面、更具挑战性的代码生成评估基准。

Method: 构建了一个包含500个竞争性编程问题的开源基准UA-Code-Bench，问题覆盖五个难度等级；采用13个主流闭源与开源大模型，在单样本提示下生成Python解决方案，并通过Eolymp平台的隐藏测试用例评估代码正确性，同时分析了解决方案的唯一性、运行时间和内存消耗。

Result: 即使是最先进的模型（如OpenAI o3和GPT-5）也只能解决约50%的问题；模型性能随问题难度增加显著下降；不同模型在执行效率和解的多样性方面存在差异。

Conclusion: 竞争性编程基准对于评估低资源语言下的大语言模型具有重要价值，UA-Code-Bench为多语言代码生成和推理增强模型的研究提供了新方向。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [94] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 本文提出了Order-Level Attention（OLA），揭示了不同语言模型在相同阶数下的OLA具有显著相似性，并发现OLA与句法知识之间存在隐式映射。基于此，提出了一种无需训练的跨语言模型适配方法Transferable OLA Adapter（TOA），实验证明TOA能有效提升未见模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型在上下文聚合模式上是否存在共性，以加深对语言模型的理解并促进跨模型知识迁移。现有研究多集中于单个模型或注意力头，缺乏跨多个语言模型的系统性分析。

Method: 通过注意力展开的阶次分解提出Order-Level Attention（OLA），分析多个语言模型间的OLA相似性，并利用OLA作为统一的句法特征表示来训练适配器，实现无需参数更新的跨模型迁移。

Result: 发现同阶OLA在不同语言模型间具有高度相似性，且与句法结构存在隐式对应；所提出的TOA方法在无需训练的情况下，在多个未见过的语言模型上均提升了任务性能。

Conclusion: 语言模型在上下文聚合过程中存在共性，OLA可作为跨模型通用的句法特征表示，TOA为实现高效、无需训练的跨模型迁移提供了新途径。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [95] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga*

Main category: cs.CL

TL;DR: 本文提出了一种用于多语言虚假信息检测的声明规范化方法，通过问答分解实现跨语言迁移，在仅使用英文训练数据的情况下，在20种语言上表现出色。


<details>
  <summary>Details</summary>
Motivation: 社交媒体帖子通常嘈杂且非正式，难以直接用于多语言虚假信息检测，因此需要将其转化为清晰、可验证的声明。

Method: 采用Who、What、Where、When、Why和How问题对帖子进行系统性分解，使用LoRA微调Qwen3-14B模型，并结合帖内去重、基于召回率的语义对齐过滤以及检索增强的少样本推理。

Result: 在英语上的METEOR得分为41.16，马拉地语为15.21，相对于基线提升了41.3%，在英语、荷兰语和旁遮普语排行榜上分别排名第三和第四，对罗曼语族和日耳曼语族语言具有良好的跨语言泛化能力。

Conclusion: 该方法能有效实现跨语言声明规范化，即使仅用英文训练也能在多种语言中保持语义连贯性和较高的性能表现。

Abstract: We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [96] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin*

Main category: cs.CL

TL;DR: 本研究评估了两种主流大语言模型（Mistral 24B 和 QWen2.5 32B）在生物医学文本简化任务中的表现，发现指令调优的 Mistral 模型在提升可读性的同时更好地保持了语义保真度，表现出架构优势。


<details>
  <summary>Details</summary>
Motivation: 公众对生物医学信息的需求日益增长，需要可扩展的自动化文本简化方案，但现有方法在可读性与语义保真之间的权衡上仍面临挑战。

Method: 通过对比指令调优的 Mistral 24B 和推理增强的 QWen2.5 32B 模型，在多个可读性、语义保真（如 BERTScore）、内容安全和分布特征指标上进行实证分析，并开展相关性分析以揭示指标间的冗余性。

Result: Mistral 在 SARI（均值 42.46）和 BERTScore（0.91）上表现优异，平衡了可读性与语义保真；QWen 虽提升可读性，但 BERTScore 显著较低（0.89），显示其策略失衡；21项指标分析揭示五种可读性指数存在强功能冗余。

Conclusion: 指令调优的 Mistral 24B 更适合文本简化任务，研究为大模型在该领域的基线性能提供了实证依据，提出了指标选择的启发式建议，并指出词汇支持是领域适配的关键问题。

Abstract: The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [97] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev,Mikhail Tikhomirov*

Main category: cs.CL

TL;DR: 本文提出了一种改进的基于ShortGPT的迭代蒸馏方法，通过评估并移除重要性较低的Transformer层，并结合KL散度与均方误差的联合损失函数进行微调，成功将Qwen2.5-3B模型从36层压缩至28层甚至24层，仅带来9.7%和18%的性能损失，验证了该方法在资源受限场景下的高效性。


<details>
  <summary>Details</summary>
Motivation: 为了在保持大语言模型高性能的同时降低其规模，以适应资源受限环境的部署需求，研究现有蒸馏方法的局限性并提出更有效的压缩策略。

Method: 基于ShortGPT方法，引入迭代式层重要性评估机制：通过移除单个层并测量在代表性数据集上的性能下降来判断层的重要性；结合基于KL散度和均方误差的联合损失函数进行进一步微调，实现知识蒸馏与模型压缩。

Result: 在Qwen2.5-3B模型上实验表明，可将其层数从36层压缩至28层（参数量降至2.47B），性能损失仅为9.7%；进一步压缩至24层时性能损失为18%。发现中间Transformer层对推理贡献较小。

Conclusion: 所提出的迭代蒸馏与微调方法能有效压缩大语言模型，在显著减少参数量的同时保留大部分性能，适用于资源受限场景，具有良好的实际应用前景。

Abstract: This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [98] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu*

Main category: cs.CL

TL;DR: 提出了一种改进的进化式提示优化方法，通过分解进化步骤、引入基于LLM的评判器、融合人类反馈和高效评估策略，提升了优化质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有进化式提示优化方法缺乏强大的操作算子和高效的评估机制，限制了其在大语言模型提示优化中的效果和应用。

Method: 将进化过程分解为独立步骤，引入基于LLM的评判器验证进化结果，结合人类反馈优化进化算子，并设计更高效的评估策略以降低计算开销。

Result: 所提方法在保持性能的同时显著提高了提示优化的质量和效率，具备一定的通用性，并已开源代码支持新任务的应用。

Conclusion: 改进的进化式提示优化框架有效提升了提示优化的控制性、质量和效率，推动了该方向的进一步研究和实际应用。

Abstract: Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [99] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: 本文提出了ManufactuBERT，一种在大规模制造领域语料库上持续预训练的RoBERTa模型，通过精心去重的数据处理流程显著提升了模型性能并减少了33%的训练时间和计算成本。


<details>
  <summary>Details</summary>
Motivation: 通用Transformer编码器在制造等专业领域表现不佳，因其缺乏对领域术语和语义的接触，因此需要专门针对制造领域优化的语言模型。

Method: 构建了一个面向制造领域的大型语料库，采用领域过滤和多阶段去重的数据处理流程，并在此基础上对RoBERTa模型进行持续预训练。

Result: ManufactuBERT在多个制造相关的NLP任务上达到最先进水平，优于强基线模型；使用去重后的语料库使训练收敛速度加快33%，显著降低训练成本。

Conclusion: 该研究展示了领域特定持续预训练的有效性，所提出的数据处理流程具有可复制性，可用于其他专业领域高性能编码器的开发。

Abstract: While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [100] [Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results](https://arxiv.org/abs/2511.05162)
*Jan-Thorsten Peter,David Vilar,Tobias Domhan,Dan Malkin,Markus Freitag*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在多语言数学任务中的表现，发现先前报告的语言间性能差距主要源于数据翻译错误和答案提取不一致；通过提出自动质量保证方法和改进建议，修正后该差距基本消失，并发布了更正后的数据集。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在不同语言间的性能差异是否真实存在，特别是在数学任务中跨语言能力的泛化问题。

Method: 以MGSM这一多语言数学基准为例，分析其中的翻译错误，并提出自动化的质量保证方法来检测和修正这些问题，同时改进答案提取的一致性。

Result: 发现原始基准中存在显著的翻译错误和答案提取问题，修正后模型在不同语言间的性能差距大幅缩小甚至消失。

Conclusion: 先前观察到的跨语言性能差距主要由数据质量问题引起，而非模型本身的能力差异；强调了标准化、高质量多语言评估基准的重要性。

Abstract: Most current large language models (LLMs) support a wide variety of languages
in addition to English, including high-resource languages (e.g. German,
Chinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In
addition they have also shown impressive capabilities in different domains,
like coding, science and math. In this short paper, taking math as an example
domain, we study the performance of different LLMs across languages.
Experimental results show that there exists a non-negligible and consistent gap
in the performance of the models across languages. Interestingly, and somewhat
against expectations, the gap exists for both high- and low-resource languages.
We hope that these results influence further research into cross-lingual
capability generalization for next generation LLMs. If it weren't for the fact
that they are false! By analyzing one of the standard multilingual math
benchmarks (MGSM), we determine that several translation errors are present in
the data. Furthermore, the lack of standardized answer extraction from LLM
outputs further influences the final results. We propose a method for automatic
quality assurance to address the first issue at scale, and give recommendations
to address the second one. Combining these two approaches we show that the
aforementioned language gap mostly disappears, leading to completely different
conclusions from our research. We additionally release the corrected dataset to
the community.

</details>


### [101] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do,Rama Doddipatla,Kate Knill*

Main category: cs.CL

TL;DR: 本文研究了链式思维（CoT）提示在白盒知识蒸馏中将大语言模型的推理能力迁移到小模型中的作用，实验表明CoT能有效提升小模型在复杂自然语言推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在探索如何通过CoT提升知识蒸馏的效果，以增强小型语言模型在推理任务中的表现。

Method: 采用Qwen和Llama2系列的大模型进行白盒知识蒸馏，并利用CoT-Collection数据集中的CoT数据，在BIG-Bench-Hard（BBH）基准上评估蒸馏后模型的性能。

Result: 实验结果显示，使用CoT进行白盒知识蒸馏可显著提高小型模型在BBH任务上的平均性能。

Conclusion: CoT在知识蒸馏过程中有效促进了推理能力的迁移，提升了小型语言模型在复杂推理任务中的表现。

Abstract: Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [102] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li,Jie Cao*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLM）的注释管道，用于解决古典汉文日译中的低资源序列标注问题，并构建了新的数据集，实验表明引入辅助中文NLP任务有助于提升标注性能，且该方法可作为LLM在字符级注释任务中的补充。


<details>
  <summary>Details</summary>
Motivation: 古典汉文日译通常通过在每个汉字周围添加注解实现，这一过程可抽象为序列标注任务，但由于数据稀缺，面临低资源挑战，因此需要有效方法来提升翻译与注解的自动化水平。

Method: 提出一种基于大语言模型的注释管道，从开源数字化翻译数据中构建新数据集，并引入辅助中文NLP任务以增强低资源下的序列标注模型训练效果。

Result: 实验表明，在低资源设置下，引入辅助中文NLP任务能有效提升序列标注性能；大语言模型在直接翻译任务中表现良好，但在字符级注解任务上表现不佳。

Conclusion: 所提方法在低资源条件下有效提升了古典汉文注释与翻译的性能，可作为大语言模型在细粒度标注任务中的有力补充。

Abstract: Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [103] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu*

Main category: cs.CL

TL;DR: 提出Reflective Personalization Optimization (RPO)框架，通过将内容生成与个性化对齐解耦，提升黑盒大语言模型的个性化性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖上下文注入，在生成内容的同时需对齐用户风格，导致质量下降和控制不精确。

Method: RPO分为两阶段：先由基础模型生成通用回复，再通过外部反思模块重写以对齐用户偏好；该模块先通过监督微调学习重写轨迹，再用强化学习优化。

Result: 在LaMP基准上的实验表明，RPO显著优于现有方法，实现了更高质量的个性化输出。

Conclusion: 显式重写优于隐式上下文注入，RPO提供了一种高效、模型无关的个性化层，为用户中心生成提供了新方向。

Abstract: The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [104] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了一种基于微调BERT模型的新型叙事框架标注方法，用于分析播客中的叙事结构，揭示话题与叙述方式之间的系统性关系。


<details>
  <summary>Details</summary>
Motivation: 播客作为一种非正式、多主题、对话式的媒体形式，其复杂的叙事结构难以通过现有语言模型有效分析，需要更贴近人类判断的自动化方法。

Method: 开发并评估一个微调的BERT模型，将叙事框架与对话中提及的具体实体关联起来，并将细粒度的框架标签与高层主题相关联，以揭示宏观话语趋势。

Result: 该方法在捕捉播客中的叙事框架方面优于现有大语言模型，能够更准确地识别和分析对话数据中的叙事模式及其与主题的关系。

Conclusion: 所提出的框架标注方法为分析数字媒体中的影响力提供了更稳健的工具，有助于深入理解播客等非结构化内容的说服机制。

Abstract: Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [105] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal*

Main category: cs.CL

TL;DR: 本文研究了从斯洛伐克公开法院判决中提取犯罪行为描述的可行性，比较了正则表达式和大语言模型（LLM）两种方法。改进的正则表达式和LLM方法显著优于基线方法，结合使用时提取准确率高达99.5%。


<details>
  <summary>Details</summary>
Motivation: 刑事司法行政数据对犯罪行为的信息记录有限，而欧洲大陆法院判决书中包含丰富的犯罪行为描述，但尚未被充分利用。因此，有必要开发有效方法从中提取结构化信息以补充现有数据。

Method: 采用两种方法提取判决书中的犯罪行为描述：一是基于正则表达式的规则匹配，包括基础方法和改进方法（关注‘sparing’及其空格规范化）；二是使用Gemini Flash 2.0大语言模型，通过预定义指令进行提示抽取。结果通过法律专业学生的人工标注进行评估。

Result: 基础正则表达式方法仅在40.5%的判决中成功提取描述，而改进的正则表达式达到97%，LLM达到98.75%，二者结合达99.5%。与人工标注对比显示，改进方法匹配率约90%，远高于基线的34.5%；LLM完全匹配率达91.75%，结合方法达92%。

Conclusion: 改进的正则表达式和大语言模型均可高效、准确地从法院判决中提取犯罪行为描述，尤其结合使用时效果最佳，为刑事司法研究提供了可行的大规模文本信息提取方案。

Abstract: Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [106] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary,Abdullah Al Noman*

Main category: cs.CL

TL;DR: 本文提出了一种专为孟加拉语设计的字节对编码（BPE）分词器BengaliBPE，通过Unicode归一化、音素级初始化和形态感知的合并规则，提升了对丰富形态语言的分词效果。


<details>
  <summary>Details</summary>
Motivation: 现有的子词分词器主要针对拉丁或多种语言语料库设计，在处理如孟加拉语这类形态丰富的语言时表现不佳，因此需要一种更适应孟加拉语特性的分词方法。

Method: 提出了BengaliBPE，采用Unicode归一化、图素级初始化以及形态感知的合并规则，并在大规模孟加拉语新闻分类数据集上与Whitespace、SentencePiece BPE和HuggingFace BPE进行对比。

Result: BengaliBPE在分词粒度和形态可解释性方面表现最佳，尽管计算成本略高，但在下游分类任务中表现出良好的性能。

Conclusion: 语言适配的分词策略对形态丰富的语言至关重要，BengaliBPE为未来的孟加拉语NLP系统（包括大规模预训练模型）提供了坚实基础。

Abstract: Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [107] [A multimodal multiplex of the mental lexicon for multilingual individuals](https://arxiv.org/abs/2511.05361)
*Maria Huynh,Wilder C. Rodrigues*

Main category: cs.CL

TL;DR: 本研究探讨多语言者心理词汇库的结构，特别是遗产语言如何影响新语言的学习，并通过引入视觉输入的多模态模型来扩展现有框架。


<details>
  <summary>Details</summary>
Motivation: 传统上认为双语会增加认知负担，但近年来研究表明多语言者在语言和认知任务中表现更优。因此，有必要深入理解多语言者心理词汇的组织方式及其对语言学习的影响。

Method: 基于Stella等人（2018）的多重网络模型和Dijkstra与van Heuven（2002）的BIA+框架，采用多层网络方法并引入视觉输入层，构建多模态的多语言心理词汇模型，比较文本与图文并行条件下翻译任务的表现差异。

Result: 研究设计预期将揭示视觉输入是否以及如何提升多语言者的语言处理准确性和熟练度，特别是在涉及遗产语言的翻译任务中。

Conclusion: 该研究有望证实多模态输入在多语言词汇加工中的积极作用，并为多语言教育和语言复兴提供理论支持。

Abstract: Historically, bilingualism was often perceived as an additional cognitive
load that could hinder linguistic and intellectual development. However, over
the last three decades, this view has changed considerably. Numerous studies
have aimed to model and understand the architecture of the bilingual word
recognition system Dijkstra and van Heuven (2002), investigating how parallel
activation operates in the brain and how one language influences another Kroll
et al. (2015). Increasingly, evidence suggests that multilinguals, individuals
who speak three or more languages, can perform better than monolinguals in
various linguistic and cognitive tasks, such as learning an additional language
Abu-Rabia and Sanitsky (2010). This research proposal focuses on the study of
the mental lexicon and how it may be structured in individuals who speak
multiple languages. Building on the work of Stella et al. (2018), who
investigated explosive learning in humans using a multiplex model of the mental
lexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by
Dijkstra and van Heuven (2002), the present study applies the same multilayer
network principles introduced by Kivela et al. (2014). Our experimental design
extends previous research by incorporating multimodality into the multiplex
model, introducing an additional layer that connects visual inputs to their
corresponding lexical representations across the multilingual layers of the
mental lexicon. In this research, we aim to explore how a heritage language
influences the acquisition of another language. Specifically, we ask: Does the
presence of visual input in a translation task influence participants'
proficiency and accuracy compared to text-only conditions?

</details>


### [108] [Large Language Models for Explainable Threat Intelligence](https://arxiv.org/abs/2511.05406)
*Tiago Dinis,Miguel Correia,Roger Tavares*

Main category: cs.CL

TL;DR: 本文提出了一种结合检索增强生成（RAG）的大语言模型系统RAGRecon，用于网络安全威胁情报的获取，并通过生成知识图谱提升AI决策的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统安全机制难以应对日益复杂的网络威胁，需要更智能、可解释的方法来辅助威胁分析。

Method: 设计并实现RAGRecon系统，利用大语言模型与检索增强生成技术结合实时信息检索和领域数据回答安全问题，并为每个回答生成可视化知识图谱。

Result: 在两个数据集上使用七个不同大语言模型进行实验评估，最佳组合的响应匹配参考答案超过91%。

Conclusion: RAGRecon能有效提升威胁情报获取的准确性与透明度，知识图谱增强了系统的可解释性，有助于安全分析师理解模型推理过程。

Abstract: As cyber threats continue to grow in complexity, traditional security
mechanisms struggle to keep up. Large language models (LLMs) offer significant
potential in cybersecurity due to their advanced capabilities in text
processing and generation. This paper explores the use of LLMs with
retrieval-augmented generation (RAG) to obtain threat intelligence by combining
real-time information retrieval with domain-specific data. The proposed system,
RAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats.
Moreover, it makes this form of Artificial Intelligence (AI) explainable by
generating and visually presenting to the user a knowledge graph for every
reply. This increases the transparency and interpretability of the reasoning of
the model, allowing analysts to better understand the connections made by the
system based on the context recovered by the RAG system. We evaluated RAGRecon
experimentally with two datasets and seven different LLMs and the responses
matched the reference responses more than 91% of the time for the best
combinations.

</details>


### [109] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu,Zi Haur Pang,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 提出一种统一框架，通过建模个体和群体偏好来提升对话系统中用户满意度估计的性能，尤其改善少数用户群体的表现。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法通常忽略少数用户视角和个性化需求，导致在不同用户间满意度评估偏差。

Method: 引入CoPeR捕捉个体偏好，采用基于期望最大化算法的M2PC无监督聚类发现用户群体，并构建PAda-PPO强化学习框架联合优化个体与群体偏好对齐。

Result: 在情感支持对话数据集上实验表明，该方法显著提升用户满意度估计效果，尤其对代表性不足的用户群体表现更优。

Conclusion: 所提框架能有效兼顾个体与群体偏好，增强对话系统对多样化用户满意度的适应能力。

Abstract: User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [110] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro,Fabien Roger*

Main category: cs.CL

TL;DR: 提出对比权重引导（contrastive weight steering）方法，通过权重算术调整模型参数以实现对大语言模型行为的精细控制，相比激活引导具有更好的泛化性和分布外控制能力。


<details>
  <summary>Details</summary>
Motivation: 在狭窄训练数据上提供高质量反馈困难且成本高，仅依赖窄分布易导致意外泛化，需更有效利用有限数据来精确控制模型行为。

Method: 通过两个小型微调（一个诱导目标行为，另一个诱导相反行为）的权重增量差值，在权重空间中分离出行为方向，并通过加减该方向来修改模型权重。

Result: 权重引导在抑制谄媚（sycophancy）和诱导错位行为方面表现良好，泛化性强于激活引导；可在保持任务性能的同时缓解微调带来的不良行为漂移；初步证据显示可通过‘邪恶’权重方向检测新兴错位行为。

Conclusion: 对比权重引导是一种有效的后训练模型编辑方法，能在不损害通用能力的前提下实现更强的行为控制，具备应用于监控训练过程中隐性错位行为的潜力。

Abstract: Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [111] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 本文提出了MIMIC-SR-ICD11数据集和LL-Rank重排序框架，用于基于临床报告的疾病诊断，显著优于生成式基线方法。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录常忽略患者自述中的重要细节，而这些细节对疾病诊断至关重要，因此需要更有效的诊断建模方法。

Method: 构建了与ICD-11对齐的MIMIC-SR-ICD11数据集，并提出LL-Rank框架，通过计算标签在上下文中的归一化联合似然并减去无报告先验似然进行重排序。

Result: 在七个模型骨干上，LL-Rank consistently优于GenMap基线方法，消融实验表明其性能提升主要来自基于PMI的打分机制。

Conclusion: LL-Rank能有效利用临床报告内容进行多标签诊断预测，缓解标签频率偏差，提升诊断准确性。

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [112] [Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale](https://arxiv.org/abs/2511.04904)
*Bassel Al Omari,Michael Matthews,Alexander Rutherford,Jakob Nicolaus Foerster*

Main category: cs.LG

TL;DR: 本文提出了Craftax-MA和Craftax-Coop两个多智能体强化学习基准环境，旨在挑战现有方法在长时程依赖、探索与协作等方面的能力，推动多智能体系统长期研究发展。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习基准大多局限于短期视野任务，难以充分测试智能体在长期依赖和泛化能力方面的表现，因此需要更具挑战性的基准来推动领域发展。

Method: 基于流行的Craftax环境，扩展出支持多智能体的Craftax-MA，并进一步设计了需复杂协作的Craftax-Coop，引入异构智能体、交易机制等新特性；环境使用JAX实现，训练效率高。

Result: 实验表明现有算法在该基准上的长时程信用分配、探索和协作任务上表现不佳，验证了其挑战性。

Conclusion: Craftax-MA和Craftax-Coop为多智能体强化学习提供了高效且具挑战性的新基准，有望促进该领域的长期研究进展。

Abstract: Progress in multi-agent reinforcement learning (MARL) requires challenging
benchmarks that assess the limits of current methods. However, existing
benchmarks often target narrow short-horizon challenges that do not adequately
stress the long-term dependencies and generalization capabilities inherent in
many multi-agent systems. To address this, we first present
\textit{Craftax-MA}: an extension of the popular open-ended RL environment,
Craftax, that supports multiple agents and evaluates a wide range of general
abilities within a single environment. Written in JAX, \textit{Craftax-MA} is
exceptionally fast with a training run using 250 million environment
interactions completing in under an hour. To provide a more compelling
challenge for MARL, we also present \textit{Craftax-Coop}, an extension
introducing heterogeneous agents, trading and more mechanics that require
complex cooperation among agents for success. We provide analysis demonstrating
that existing algorithms struggle with key challenges in this benchmark,
including long-horizon credit assignment, exploration and cooperation, and
argue for its potential to drive long-term research in MARL.

</details>


### [113] [Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity](https://arxiv.org/abs/2511.04686)
*Pratik Poudel*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型推理过程中KV缓存管理对生成质量的影响，指出当缓存接近或超过模型训练上下文窗口时，生成质量会显著下降，尤其当常用驱逐策略破坏位置编码连续性时。实验表明，保持连续上下文块的简单策略优于复杂但破坏位置结构的方法，强调应整体考虑缓存健康，而不仅仅是大小。


<details>
  <summary>Details</summary>
Motivation: 随着大模型在多轮对话等状态持续场景中的应用，KV缓存不断增长，可能导致超出模型训练时的上下文长度限制，进而影响生成质量。然而现有缓存管理策略往往忽视位置编码的完整性，导致性能下降。

Method: 通过构建一个支持状态保持的基准测试框架，实证分析不同KV缓存管理策略在接近模型上下文限制（如Llama 3的8192 tokens）时的表现，并评估其对位置编码（如RoPE）和生成连贯性的影响。

Result: 发现当KV缓存接近或超过模型训练上下文窗口时，生成质量急剧下降；常见的高保留率驱逐策略（如AttentionTop保留99%）若破坏位置连续性，反而加剧退化；而保留连续上下文块（如初始‘要点’）的简单策略能产生更连贯的输出。

Conclusion: 应设计尊重模型架构限制、保持位置结构完整性的KV缓存驱逐策略，并从整体上维护‘缓存健康’，而非仅关注缓存大小。

Abstract: The Key-Value (KV) cache is integral to efficient autoregressive inference in
large language models (LLMs), yet its unbounded growth in stateful multi-turn
scenarios presents major challenges. This paper examines the interplay between
KV cache management strategies, the architectural context limits of models like
meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of
positional encodings. Through empirical analysis using a stateful benchmarking
framework, we show that LLM generation quality degrades sharply when the
accumulated KV cache approaches or exceeds the model's trained context window
(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory
exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via
AttentionTop), can worsen performance if they disrupt positional coherence.
Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a
cache by removing non-contiguous tokens can scramble these signals and lead to
degenerative outputs. We further show that simple strategies preserving
contiguous context blocks (e.g., keeping an initial "gist") can yield more
coherent generations than complex or positionally disruptive ones. We advocate
for eviction techniques that respect architectural limits, preserve positional
structure, and view "cache health" holistically beyond mere size.

</details>


### [114] [Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification](https://arxiv.org/abs/2511.04718)
*Yue Xun,Jiaxing Xu,Wenbo Gao,Chen Yang,Shujun Wang*

Main category: cs.LG

TL;DR: 提出一种基于自适应级联分解和频带耦合连接学习的新型框架，用于fMRI数据分析，提升脑疾病分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略BOLD信号的多频特性且依赖预定义频段，限制了脑疾病诊断的敏感性和特异性。

Method: 采用自适应级联分解学习每个脑区任务相关的子频带，并通过频带耦合连接学习构建统一的功能网络，结合Unified-GCN进行消息传递以实现诊断预测。

Result: 在ADNI和ABIDE数据集上实验表明，该方法优于现有方法。

Conclusion: 该框架能更有效地捕捉疾病相关的频带特异性功能连接变化，提升fMRI在脑疾病分类中的应用价值。

Abstract: Resting-state fMRI has become a valuable tool for classifying brain disorders
and constructing brain functional connectivity networks
  by tracking BOLD signals across brain regions. However, existing mod els
largely neglect the multi-frequency nature of neuronal oscillations,
  treating BOLD signals as monolithic time series. This overlooks the cru cial
fact that neurological disorders often manifest as disruptions within
  specific frequency bands, limiting diagnostic sensitivity and specificity.
  While some methods have attempted to incorporate frequency informa tion, they
often rely on predefined frequency bands, which may not be
  optimal for capturing individual variability or disease-specific alterations.
  To address this, we propose a novel framework featuring Adaptive Cas cade
Decomposition to learn task-relevant frequency sub-bands for each
  brain region and Frequency-Coupled Connectivity Learning to capture
  both intra- and nuanced cross-band interactions in a unified functional
  network. This unified network informs a novel message-passing mecha nism
within our Unified-GCN, generating refined node representations
  for diagnostic prediction. Experimental results on the ADNI and ABIDE
  datasets demonstrate superior performance over existing methods. The
  code is available at https://github.com/XXYY20221234/Ada-FCN.

</details>


### [115] [AWEMixer: Adaptive Wavelet-Enhanced Mixer Network for Long-Term Time Series Forecasting](https://arxiv.org/abs/2511.04722)
*Qianyang Li,Xingjun Zhang,Peng Tao,Shaoxun Wang,Yancheng Pan,Jia Wei*

Main category: cs.LG

TL;DR: 提出了一种名为AWEMixer的自适应小波增强混合网络，用于物联网环境中的长期时间序列预测，通过结合频域与小波子带加权和多尺度时频融合机制，在多个公开基准上优于现有的Transformer和MLP模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法受限于时域操作，且傅里叶变换获得的全局频率信息难以捕捉瞬态事件的时间模式，同时长期预测存在非平稳性、多尺度特征和误差累积问题。

Method: 设计了频率路由器，利用FFT获取的全局周期性自适应加权局部小波子带；引入相干门控融合模块，通过交叉注意力和门控机制选择性融合显著频率特征与多尺度时间表示。

Result: 在七个公开基准数据集上验证了AWEMixer的有效性，相比基于Transformer和MLP的最先进模型，在长序列时间序列预测中 consistently 取得性能提升。

Conclusion: AWEMixer实现了精确的时频局部化并具有噪声鲁棒性，为物联网中非平稳、多尺度时间序列的长期预测提供了一个高效解决方案。

Abstract: Forecasting long-term time series in IoT environments remains a significant
challenge due to the non-stationary and multi-scale characteristics of sensor
signals. Furthermore, error accumulation causes a decrease in forecast quality
when predicting further into the future. Traditional methods are restricted to
operate in time-domain, while the global frequency information achieved by
Fourier transform would be regarded as stationary signals leading to blur the
temporal patterns of transient events. We propose AWEMixer, an Adaptive
Wavelet-Enhanced Mixer Network including two innovative components: 1) a
Frequency Router designs to utilize the global periodicity pattern achieved by
Fast Fourier Transform to adaptively weight localized wavelet subband, and 2) a
Coherent Gated Fusion Block to achieve selective integration of prominent
frequency features with multi-scale temporal representation through
cross-attention and gating mechanism, which realizes accurate time-frequency
localization while remaining robust to noise. Seven public benchmarks validate
that our model is more effective than recent state-of-the-art models.
Specifically, our model consistently achieves performance improvement compared
with transformer-based and MLP-based state-of-the-art models in long-sequence
time series forecasting. Code is available at
https://github.com/hit636/AWEMixer

</details>


### [116] [Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction](https://arxiv.org/abs/2511.04723)
*Mohamadreza Akbari Pour,Mohamad Sadeq Karimi,Amir Hossein Mazloumi*

Main category: cs.LG

TL;DR: 提出了一种结合TCN和改进的TFT（加入Bi-LSTM）的新型框架，用于工业系统中的剩余使用寿命（RUL）预测，通过多时间窗口方法提升适应性，在基准数据集上将平均RMSE降低了5.5%。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以捕捉细粒度时间依赖并动态突出关键特征，导致RUL预测性能受限。

Method: 结合Temporal Convolutional Networks（TCN）进行局部时序特征提取，采用改进的Temporal Fusion Transformer（TFT）并引入Bi-LSTM编码器-解码器结构，同时应用多时间窗口策略以适应不同工况。

Result: 在多个基准数据集上验证了模型的有效性，平均RMSE最多降低5.5%，优于当前最先进的方法。

Conclusion: 该框架有效弥补了现有RUL预测方法的不足，提升了工业预测系统的性能，展示了先进时序Transformer在设备健康预测中的潜力。

Abstract: Health prediction is crucial for ensuring reliability, minimizing downtime,
and optimizing maintenance in industrial systems. Remaining Useful Life (RUL)
prediction is a key component of this process; however, many existing models
struggle to capture fine-grained temporal dependencies while dynamically
prioritizing critical features across time for robust prognostics. To address
these challenges, we propose a novel framework that integrates Temporal
Convolutional Networks (TCNs) for localized temporal feature extraction with a
modified Temporal Fusion Transformer (TFT) enhanced by Bi-LSTM encoder-decoder.
This architecture effectively bridges short- and long-term dependencies while
emphasizing salient temporal patterns. Furthermore, the incorporation of a
multi-time-window methodology improves adaptability across diverse operating
conditions. Extensive evaluations on benchmark datasets demonstrate that the
proposed model reduces the average RMSE by up to 5.5%, underscoring its
improved predictive accuracy compared to state-of-the-art methods. By closing
critical gaps in current approaches, this framework advances the effectiveness
of industrial prognostic systems and highlights the potential of advanced
time-series transformers for RUL prediction.

</details>


### [117] [Regularized GLISp for sensor-guided human-in-the-loop optimization](https://arxiv.org/abs/2511.04751)
*Matteo Cercola,Michele Lomuscio,Dario Piga,Simone Formentin*

Main category: cs.LG

TL;DR: 提出了一种传感器引导的GLISp正则化扩展方法，将可测量的描述信息通过物理信息假设函数和最小二乘正则项融入偏好学习循环，相比基线GLISp实现了更快的收敛速度和更优的最终解。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的优化方法（如Preferential Bayesian Optimization或GLISp）将系统视为黑箱，忽略了有用的传感器测量信息，限制了优化效率和性能。

Method: 引入一种传感器引导的正则化GLISp扩展方法，通过物理信息假设函数和最小二乘正则项，将可测量的传感器数据与主观偏好反馈结合，形成灰箱优化框架。

Result: 在解析基准测试和人机协同车辆悬架调优任务上的数值实验表明，该方法比标准GLISp收敛更快，且获得更优解。

Conclusion: 所提方法有效融合了传感器信息与人类偏好，在保留偏好搜索灵活性的同时提升了优化效率，验证了灰箱结构在人机协同校准中的优势。

Abstract: Human-in-the-loop calibration is often addressed via preference-based
optimization, where algorithms learn from pairwise comparisons rather than
explicit cost evaluations. While effective, methods such as Preferential
Bayesian Optimization or Global optimization based on active preference
learning with radial basis functions (GLISp) treat the system as a black box
and ignore informative sensor measurements. In this work, we introduce a
sensor-guided regularized extension of GLISp that integrates measurable
descriptors into the preference-learning loop through a physics-informed
hypothesis function and a least-squares regularization term. This injects
grey-box structure, combining subjective feedback with quantitative sensor
information while preserving the flexibility of preference-based search.
Numerical evaluations on an analytical benchmark and on a human-in-the-loop
vehicle suspension tuning task show faster convergence and superior final
solutions compared to baseline GLISp.

</details>


### [118] [When Data Falls Short: Grokking Below the Critical Threshold](https://arxiv.org/abs/2511.04760)
*Vaibhav Singh,Eugene Belilovsky,Rahaf Aljundi*

Main category: cs.LG

TL;DR: 本文研究了在数据稀缺和分布变化情况下，通过知识蒸馏（KD）诱导和加速“grokking”现象的方法，表明KD能在低数据条件下促进模型泛化并缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 探索在训练样本不足及分布偏移的实际场景中，如何实现并加速模型的延迟泛化（grokking）。

Method: 采用知识蒸馏（KD），从已在某一分布上grokked的模型向另一分布上的模型迁移知识，并评估其在不同训练设置下的表现，包括联合分布训练和持续预训练。

Result: 知识蒸馏能够诱导并在数据低于临界阈值时加速grokking；在联合分布训练中实现泛化；在持续预训练中加速泛化并显著减轻灾难性遗忘，即使仅使用10%数据也能取得良好性能。

Conclusion: 知识蒸馏在低数据量和动态分布场景中对促进泛化和实现高效模型适应具有关键作用，揭示了grokking在知识迁移中的潜在机制。

Abstract: In this paper, we investigate the phenomenon of grokking, where models
exhibit delayed generalization following overfitting on training data. We focus
on data-scarce regimes where the number of training samples falls below the
critical threshold, making grokking unobservable, and on practical scenarios
involving distribution shift. We first show that Knowledge Distillation (KD)
from a model that has already grokked on a distribution (p1) can induce and
accelerate grokking on a different distribution (p2), even when the available
data lies below the critical threshold. This highlights the value of KD for
deployed models that must adapt to new distributions under limited data. We
then study training on the joint distribution (p1, p2) and demonstrate that
while standard supervised training fails when either distribution has
insufficient data, distilling from models grokked on the individual
distributions enables generalization. Finally, we examine a continual
pretraining setup, where a grokked model transitions from p1 to p2, and find
that KD both accelerates generalization and mitigates catastrophic forgetting,
achieving strong performance even with only 10% of the data. Together, our
results provide new insights into the mechanics of grokking under knowledge
transfer and underscore the central role of KD in enabling generalization in
low-data and evolving distribution settings.

</details>


### [119] [FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow](https://arxiv.org/abs/2511.04768)
*Rubens Lacouture,Nathan Zhang,Ritvik Sharma,Marco Siracusa,Fredrik Kjolstad,Kunle Olukotun,Olivia Hsu*

Main category: cs.LG

TL;DR: FuseFlow是一个编译器，将PyTorch中的稀疏机器学习模型转换为可重构数据流架构的融合稀疏数据流图，支持跨表达式的通用融合及多种优化，通过设计空间探索发现全融合并非总是最优，并在GPT-3与BigBird稀疏注意力上实现约2.7倍加速。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模增大，稀疏计算和专用数据流硬件成为提升效率的关键方案，但现有编译器缺乏对稀疏操作的通用跨表达式融合支持，限制了性能优化潜力。

Method: 提出FuseFlow编译器，支持稀疏操作的跨核融合、并行化、数据流排序和稀疏块优化，并生成融合的数据流图以供周期精确的数据流模拟器进行微架构分析，同时引入启发式方法剪枝次优配置。

Result: 在四个真实稀疏机器学习应用中进行设计空间探索，发现融合粒度需根据模型特性调整，全融合不一定最优；在GPT-3结合BigBird块稀疏注意力的任务中，相比未融合基线实现了约2.7倍的加速。

Conclusion: FuseFlow首次实现了稀疏操作的通用跨表达式融合，揭示了融合粒度对性能的影响，并通过高效编译优化显著提升稀疏模型在数据流架构上的执行效率。

Abstract: As deep learning models scale, sparse computation and specialized dataflow
hardware have emerged as powerful solutions to address efficiency. We propose
FuseFlow, a compiler that converts sparse machine learning models written in
PyTorch to fused sparse dataflow graphs for reconfigurable dataflow
architectures (RDAs). FuseFlow is the first compiler to support general
cross-expression fusion of sparse operations. In addition to fusion across
kernels (expressions), FuseFlow also supports optimizations like
parallelization, dataflow ordering, and sparsity blocking. It targets a
cycle-accurate dataflow simulator for microarchitectural analysis of fusion
strategies. We use FuseFlow for design-space exploration across four real-world
machine learning applications with sparsity, showing that full fusion (entire
cross-expression fusion across all computation in an end-to-end model) is not
always optimal for sparse models-fusion granularity depends on the model
itself. FuseFlow also provides a heuristic to identify and prune suboptimal
configurations. Using Fuseflow, we achieve performance improvements, including
a ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse
attention.

</details>


### [120] [SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud Microservices](https://arxiv.org/abs/2511.04774)
*Liu Jiang,Zerui Bao,Shiqi Sheng,Di Zhu*

Main category: cs.LG

TL;DR: 提出一种改进的指令预取设计，通过压缩入口和分层元数据存储优化云工作负载下的性能与能效。


<details>
  <summary>Details</summary>
Motivation: 大型网络服务因软件栈复杂和微服务编排导致指令足迹增大、前端停顿增多，进而增加尾延迟和能耗。

Method: 基于EIP，引入36位压缩入口以捕捉空间聚类中的多个目标，并采用分层元数据存储将频繁访问的数据保留在片上，其余虚拟化至下层；同时加入轻量级在线机器学习控制器，利用上下文特征和bandit调整阈值评估预取收益。

Result: 在数据中心应用中，该方法在减少片上状态的同时保持了类似EIP的加速效果，并提升了ML时代网络服务的效率。

Conclusion: 所提出的指令预取架构有效平衡了性能、资源开销与能效，适用于SLO驱动和自优化的云系统。

Abstract: Large-scale networked services rely on deep soft-ware stacks and microservice
orchestration, which increase instruction footprints and create frontend stalls
that inflate tail latency and energy. We revisit instruction prefetching for
these cloud workloads and present a design that aligns with SLO driven and self
optimizing systems. Building on the Entangling Instruction Prefetcher (EIP), we
introduce a Compressed Entry that captures up to eight destinations around a
base using 36 bits by exploiting spatial clustering, and a Hierarchical
Metadata Storage scheme that keeps only L1 resident and frequently queried
entries on chip while virtualizing bulk metadata into lower levels. We further
add a lightweight Online ML Controller that scores prefetch profitability using
context features and a bandit adjusted threshold. On data center applications,
our approach preserves EIP like speedups with smaller on chip state and
improves efficiency for networked services in the ML era.

</details>


### [121] [Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting](https://arxiv.org/abs/2511.04789)
*Xiaoda Wang,Yuji Zhao,Kaiqiao Han,Xiao Luo,Sanne van Rooij,Jennifer Stevens,Lifang He,Liang Zhan,Yizhou Sun,Wei Wang,Carl Yang*

Main category: cs.LG

TL;DR: 提出了一种基于神经ODE的连续个体化帕金森病（PD）进展预测框架CNODE，能够有效建模不规则、稀疏的纵向脑形态变化数据，并捕捉个体异质性，在PPMI数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于离散且规则采样的数据，难以处理PD队列中不规则和稀疏的MRI数据，且难以捕捉个体在发病时间、进展速度和症状严重程度上的异质性。

Method: 提出CNODE（Conditional Neural ODE），使用神经ODE模型将脑形态变化建模为连续时间过程，并联合学习患者特定的初始时间和进展速度，以对齐个体轨迹到共享的疾病进展路径。

Result: 在PPMI数据集上的实验表明，CNODE在预测PD纵向进展方面优于现有的最先进基线方法。

Conclusion: CNODE能够更准确地进行个体化的PD进展预测，为机制理解、治疗开发和数字孪生建模提供了有力工具。

Abstract: Parkinson's disease (PD) shows heterogeneous, evolving brain-morphometry
patterns. Modeling these longitudinal trajectories enables mechanistic insight,
treatment development, and individualized 'digital-twin' forecasting. However,
existing methods usually adopt recurrent neural networks and transformer
architectures, which rely on discrete, regularly sampled data while struggling
to handle irregular and sparse magnetic resonance imaging (MRI) in PD cohorts.
Moreover, these methods have difficulty capturing individual heterogeneity
including variations in disease onset, progression rate, and symptom severity,
which is a hallmark of PD. To address these challenges, we propose CNODE
(Conditional Neural ODE), a novel framework for continuous, individualized PD
progression forecasting. The core of CNODE is to model morphological brain
changes as continuous temporal processes using a neural ODE model. In addition,
we jointly learn patient-specific initial time and progress speed to align
individual trajectories into a shared progression trajectory. We validate CNODE
on the Parkinson's Progression Markers Initiative (PPMI) dataset. Experimental
results show that our method outperforms state-of-the-art baselines in
forecasting longitudinal PD progression.

</details>


### [122] [Causal Structure and Representation Learning with Biomedical Applications](https://arxiv.org/abs/2511.04790)
*Caroline Uhler,Jiaqi Zhang*

Main category: cs.LG

TL;DR: 本文探讨了将表征学习与因果推断结合的必要性，提出利用多模态数据（观察性和扰动性数据）来推动因果结构与表征学习，并构建统计与计算框架以回答生物医学中的核心问题。


<details>
  <summary>Details</summary>
Motivation: 尽管表征学习在预测任务中取得成功，但在因果任务（如干预效应预测）中表现不佳，因此需要将其与因果推断结合。

Method: 提出一个统计与计算框架，利用多模态数据（包括观察性和扰动性、成像和测序数据等）进行因果结构发现、因果变量学习和最优扰动设计。

Result: 为整合观测与扰动数据进行因果发现、从多模态视角学习因果变量以及设计最优干预提供了系统框架。

Conclusion: 将表征学习与因果推断结合，并利用多模态数据，有望解决复杂生物医学系统中的因果推断问题。

Abstract: Massive data collection holds the promise of a better understanding of
complex phenomena and, ultimately, better decisions. Representation learning
has become a key driver of deep learning applications, as it allows learning
latent spaces that capture important properties of the data without requiring
any supervised annotations. Although representation learning has been hugely
successful in predictive tasks, it can fail miserably in causal tasks including
predicting the effect of a perturbation/intervention. This calls for a marriage
between representation learning and causal inference. An exciting opportunity
in this regard stems from the growing availability of multi-modal data
(observational and perturbational, imaging-based and sequencing-based, at the
single-cell level, tissue-level, and organism-level). We outline a statistical
and computational framework for causal structure and representation learning
motivated by fundamental biomedical questions: how to effectively use
observational and perturbational data to perform causal discovery on observed
causal variables; how to use multi-modal views of the system to learn causal
variables; and how to design optimal perturbations.

</details>


### [123] [DuetServe: Harmonizing Prefill and Decode for LLM Serving via Adaptive GPU Multiplexing](https://arxiv.org/abs/2511.04791)
*Lei Gao,Chaoyi Jiang,Hossein Entezari Zarch,Daniel Wong,Murali Annavaram*

Main category: cs.LG

TL;DR: DuetServe是一种统一的LLM服务框架，通过细粒度、自适应的SM分区在单个GPU上实现预填充和解码阶段的按需解耦，从而在保持低延迟的同时提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM服务系统在处理计算密集型的预填充阶段和内存受限的解码阶段时，要么因共享GPU导致阶段间干扰，降低每令牌时间（TBT），要么通过跨GPU分离阶段造成资源浪费。因此需要一种既能隔离阶段又不浪费资源的方法。

Method: DuetServe默认以聚合模式运行，并在预测到TBT退化时动态激活SM级别的GPU空间复用。它采用注意力感知的屋顶线模型预测迭代延迟，结合分区优化器选择最优SM划分方案，并通过无中断执行引擎消除CPU-GPU同步开销。

Result: 实验表明，与最先进的框架相比，DuetServe在保持低生成延迟的同时，总吞吐量最高提升了1.3倍。

Conclusion: DuetServe通过动态、细粒度的GPU资源划分，在单个GPU上实现了类似分离架构的隔离性，有效平衡了高吞吐与低延迟的需求，提升了LLM服务效率。

Abstract: Modern LLM serving systems must sustain high throughput while meeting strict
latency SLOs across two distinct inference phases: compute-intensive prefill
and memory-bound decode phases. Existing approaches either (1) aggregate both
phases on shared GPUs, leading to interference between prefill and decode
phases, which degrades time-between-tokens (TBT); or (2) disaggregate the two
phases across GPUs, improving latency but wasting resources through duplicated
models and KV cache transfers. We present DuetServe, a unified LLM serving
framework that achieves disaggregation-level isolation within a single GPU.
DuetServe operates in aggregated mode by default and dynamically activates
SM-level GPU spatial multiplexing when TBT degradation is predicted. Its key
idea is to decouple prefill and decode execution only when needed through
fine-grained, adaptive SM partitioning that provides phase isolation only when
contention threatens latency service level objectives (SLOs). DuetServe
integrates (1) an attention-aware roofline model to forecast iteration latency,
(2) a partitioning optimizer that selects the optimal SM split to maximize
throughput under TBT constraints, and (3) an interruption-free execution engine
that eliminates CPU-GPU synchronization overhead. Evaluations show that
DuetServe improves total throughput by up to 1.3x while maintaining low
generation latency compared to state-of-the-art frameworks.

</details>


### [124] [Simplex-FEM Networks (SiFEN): Learning A Triangulated Function Approximator](https://arxiv.org/abs/2511.04804)
*Chaymae Yahyati,Ismail Lamaakal,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: 提出了一种名为Simplex-FEM网络（SiFEN）的新型神经网络，通过在学习到的单纯形网格上构建全局C^r连续的有限元场，实现高效、稀疏且可解释的预测模型，在多种任务中优于或媲美MLP和KAN。


<details>
  <summary>Details</summary>
Motivation: 设计一种兼具理论保证、计算效率和可解释性的神经网络结构，克服传统MLP参数密集、缺乏几何局部性和边缘样条网络表达能力受限的问题。

Method: 将输入空间映射到可学习的单纯形网格，并结合Bernstein-Bezier多项式与轻量可逆变换，利用重心坐标激活单个单纯形；采用形状正则化、半离散最优传输覆盖和可微边翻转进行端到端训练。

Result: 在合成逼近、表格数据分类回归及作为CNN头部的任务中，SiFEN在相同参数预算下达到或超过MLP和KAN性能，具备更低的ECE/Brier分数、更优校准性、更小推理延迟，并具有明确的局部性与理论逼近率M^(-m/d)。

Conclusion: SiFEN是一种紧凑、可解释、理论支持的替代方案，适用于需要高效率与可控光滑性的深度学习场景。

Abstract: We introduce Simplex-FEM Networks (SiFEN), a learned piecewise-polynomial
predictor that represents f: R^d -> R^k as a globally C^r finite-element field
on a learned simplicial mesh in an optionally warped input space. Each query
activates exactly one simplex and at most d+1 basis functions via barycentric
coordinates, yielding explicit locality, controllable smoothness, and
cache-friendly sparsity. SiFEN pairs degree-m Bernstein-Bezier polynomials with
a light invertible warp and trains end-to-end with shape regularization,
semi-discrete OT coverage, and differentiable edge flips. Under standard
shape-regularity and bi-Lipschitz warp assumptions, SiFEN achieves the classic
FEM approximation rate M^(-m/d) with M mesh vertices. Empirically, on synthetic
approximation tasks, tabular regression/classification, and as a drop-in head
on compact CNNs, SiFEN matches or surpasses MLPs and KANs at matched parameter
budgets, improves calibration (lower ECE/Brier), and reduces inference latency
due to geometric locality. These properties make SiFEN a compact,
interpretable, and theoretically grounded alternative to dense MLPs and
edge-spline networks.

</details>


### [125] [PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference](https://arxiv.org/abs/2511.04805)
*Yushu Zhao,Zheng Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: PuzzleMoE是一种无需训练的MoE压缩方法，通过稀疏专家合并和位打包编码技术，在保持高精度的同时实现高效推理，最高可压缩50%并提升1.28倍推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型因存储所有专家参数导致内存开销大，尤其在专家数量增加时问题更严重，限制了其广泛部署。已有压缩方法在高压缩比下常导致性能下降。

Method: 提出PuzzleMoE，包含两项创新：一是通过双掩码识别元素级权重冗余与特异性，实现稀疏专家合并；二是设计位打包编码方案，复用指数位以避免存储二进制掩码和符号的开销，提升GPU推理效率。

Result: 实验表明，PuzzleMoE可在高达50%压缩率下保持模型准确性，在MMLU任务上比先前方法最高提升16.7%，并实现最高1.28倍的推理加速。

Conclusion: PuzzleMoE在不牺牲性能的前提下显著降低MoE模型的存储和计算开销，为大规模语言模型的高效部署提供了有效的训练-free压缩方案。

Abstract: Mixture-of-Experts (MoE) models have shown strong potential in scaling
language models efficiently by activating only a small subset of experts per
input. However, their widespread deployment remains limited due to the high
memory overhead associated with storing all expert parameters, particularly as
the number of experts increases. To address this challenge, prior works have
explored expert dropping and merging strategies, yet they often suffer from
performance drop at high compression ratios. In this paper, we introduce
PuzzleMoE, a training-free MoE compression method that achieves both high
accuracy and efficient inference through two key innovations: First, PuzzleMoE
performs sparse expert merging by identifying element-wise weight redundancy
and specialization. It uses a dual-mask to capture both shared and
expert-specific parameters. Second, to avoid the overhead of storing binary
masks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses
underutilized exponent bits, enabling efficient MoE inference on GPUs.
Extensive experiments demonstrate that PuzzleMoE can compress MoE models by up
to 50% while maintaining accuracy across various tasks. Specifically, it
outperforms prior MoE compression methods by up to 16.7% on MMLU at 50%
compression ratio, and achieves up to 1.28\times inference speedup.

</details>


### [126] [Autoencoding Dynamics: Topological Limitations and Capabilities](https://arxiv.org/abs/2511.04807)
*Matthew D. Kvalheim,Eduardo D. Sontag*

Main category: cs.LG

TL;DR: 本文探讨了在数据流形和潜在空间之间构建自编码器时存在的拓扑限制与能力，并分析了对具有不变流形的动态系统进行自编码的可能性。


<details>
  <summary>Details</summary>
Motivation: 研究自编码器在连续映射下的拓扑性质，揭示其在逼近恒等映射过程中存在的固有局限性和潜力。

Method: 利用拓扑学工具分析编码器-解码器组合映射D∘E接近数据流形上恒等映射的能力与限制，并扩展至动力系统中的应用。

Result: 提出了自编码器设计中的若干拓扑约束条件，同时展示了在特定条件下自编码器可以有效处理具有不变流形的动力系统。

Conclusion: 自编码器的设计受到拓扑因素的深刻影响，理解这些限制有助于更好地构建适用于复杂数据结构和动力系统的模型。

Abstract: Given a "data manifold" $M\subset \mathbb{R}^n$ and "latent space"
$\mathbb{R}^\ell$, an autoencoder is a pair of continuous maps consisting of an
"encoder" $E\colon \mathbb{R}^n\to \mathbb{R}^\ell$ and "decoder" $D\colon
\mathbb{R}^\ell\to \mathbb{R}^n$ such that the "round trip" map $D\circ E$ is
as close as possible to the identity map $\mbox{id}_M$ on $M$. We present
various topological limitations and capabilites inherent to the search for an
autoencoder, and describe capabilities for autoencoding dynamical systems
having $M$ as an invariant manifold.

</details>


### [127] [Sharp Minima Can Generalize: A Loss Landscape Perspective On Data](https://arxiv.org/abs/2511.04808)
*Raymond Fan,Bryce Sandlund,Lin Myat Ko*

Main category: cs.LG

TL;DR: 深度学习的有效性可能与损失函数中极小值的体积有关，但数据量增加会改变损失景观，使原本尖锐且泛化好的极小值变得更易被找到。


<details>
  <summary>Details</summary>
Motivation: 解释大数据在深度学习泛化中的作用，并检验体积假说是否成立。

Method: 通过改变训练数据量来测量不同极小值的体积变化，分析其与泛化性能的关系。

Result: 发现存在能良好泛化的尖锐极小值，但由于其体积小而难以被找到；增加数据量会使这些极小值的相对体积增大。

Conclusion: 数据量的增加通过改变损失地貌促进了泛化，这补充了体积假说对深度学习有效性的解释。

Abstract: The volume hypothesis suggests deep learning is effective because it is
likely to find flat minima due to their large volumes, and flat minima
generalize well. This picture does not explain the role of large datasets in
generalization. Measuring minima volumes under varying amounts of training data
reveals sharp minima which generalize well exist, but are unlikely to be found
due to their small volumes. Increasing data changes the loss landscape, such
that previously small generalizing minima become (relatively) large.

</details>


### [128] [A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification](https://arxiv.org/abs/2511.04814)
*Sebastian Ojeda,Rafael Velasquez,Nicolás Aparicio,Juanita Puentes,Paula Cárdenas,Nicolás Andrade,Gabriel González,Sergio Rincón,Carolina Muñoz-Camargo,Pablo Arbeláez*

Main category: cs.LG

TL;DR: 本文提出了一个名为ESCAPE的抗菌肽标准化数据集和基于Transformer的多标签分类模型，显著提升了抗菌肽功能预测性能。


<details>
  <summary>Details</summary>
Motivation: 由于数据分散、注释不一致和缺乏标准基准，抗菌肽的计算发现受到阻碍。

Method: 整合27个验证数据库中的8万多个肽，构建标准化多标签数据集ESCAPE，并开发结合序列与结构信息的Transformer模型进行多功能预测。

Result: 该模型在平均AP上比第二好的方法平均提升2.56%，实现了新的多标签分类SOTA性能。

Conclusion: ESCAPE为AI驱动的抗菌肽研究提供了全面、可重复的评估框架，推动了抗菌肽的发现。

Abstract: Antimicrobial peptides have emerged as promising molecules to combat
antimicrobial resistance. However, fragmented datasets, inconsistent
annotations, and the lack of standardized benchmarks hinder computational
approaches and slow down the discovery of new candidates. To address these
challenges, we present the Expanded Standardized Collection for Antimicrobial
Peptide Evaluation (ESCAPE), an experimental framework integrating over 80.000
peptides from 27 validated repositories. Our dataset separates antimicrobial
peptides from negative sequences and incorporates their functional annotations
into a biologically coherent multilabel hierarchy, capturing activities across
antibacterial, antifungal, antiviral, and antiparasitic classes. Building on
ESCAPE, we propose a transformer-based model that leverages sequence and
structural information to predict multiple functional activities of peptides.
Our method achieves up to a 2.56% relative average improvement in mean Average
Precision over the second-best method adapted for this task, establishing a new
state-of-the-art multilabel peptide classification. ESCAPE provides a
comprehensive and reproducible evaluation framework to advance AI-driven
antimicrobial peptide research.

</details>


### [129] [Persistent reachability homology in machine learning applications](https://arxiv.org/abs/2511.04825)
*Luigi Caputi,Nicholas Meadows,Henri Riihimäki*

Main category: cs.LG

TL;DR: 本文研究了持久可达性同调（PRH）在癫痫检测这一神经科学问题中的网络分类任务上的有效性，发现PRH优于传统的基于有向旗形复形的持久同调（DPH），且因考虑有向图持续滤波中的凝聚而计算更高效。


<details>
  <summary>Details</summary>
Motivation: 探索新的持久可达性同调方法（PRH）在神经科学中癫痫检测的网络分类任务上的应用潜力，并克服传统方法计算复杂度高的问题。

Method: 使用持久可达性同调（PRH）提取有向图数据的拓扑特征，与基于有向旗形复形的持久同调（DPH）进行比较，采用贝蒂数曲线及其积分作为特征，结合支持向量机实现分类。

Result: PRH在癫痫检测的网络分类任务中表现优于DPH，且由于基于更小的凝聚图进行计算，具备更高的计算效率。

Conclusion: PRH是一种有效且高效的拓扑数据分析方法，在神经科学的网络分类任务中具有优越性能，尤其适用于如癫痫检测等实际应用。

Abstract: We explore the recently introduced persistent reachability homology (PRH) of
digraph data, i.e. data in the form of directed graphs. In particular, we study
the effectiveness of PRH in network classification task in a key neuroscience
problem: epilepsy detection. PRH is a variation of the persistent homology of
digraphs, more traditionally based on the directed flag complex (DPH). A main
advantage of PRH is that it considers the condensations of the digraphs
appearing in the persistent filtration and thus is computed from smaller
digraphs. We compare the effectiveness of PRH to that of DPH and we show that
PRH outperforms DPH in the classification task. We use the Betti curves and
their integrals as topological features and implement our pipeline on support
vector machine.

</details>


### [130] [Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.04834)
*Jiwoo Shin,Byeonghu Na,Mina Kang,Wonhyeok Choi,Il-chul Moon*

Main category: cs.LG

TL;DR: 提出一种简单且有效的方法，通过概念反演获得隐式负嵌入来替代训练无关方法中的负提示，从而提升对有害内容的防御效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在面对恶意文本提示时可能生成有害内容，而现有的两种防御方法结合后效果不佳，存在不兼容问题。

Method: 使用概念反演生成隐式负嵌入，替代训练无关的引导方法中的负提示，无需修改模型或训练过程。

Result: 在裸露和暴力内容基准上实验验证，该方法显著提升了防御成功率，同时保持了输入提示的核心语义。

Conclusion: 所提方法简单、兼容性强，能有效增强现有防御手段的联合性能。

Abstract: Recent advances in text-to-image generative models have raised concerns about
their potential to produce harmful content when provided with malicious input
text prompts. To address this issue, two main approaches have emerged: (1)
fine-tuning the model to unlearn harmful concepts and (2) training-free
guidance methods that leverage negative prompts. However, we observe that
combining these two orthogonal approaches often leads to marginal or even
degraded defense performance. This observation indicates a critical
incompatibility between two paradigms, which hinders their combined
effectiveness. In this work, we address this issue by proposing a conceptually
simple yet experimentally robust method: replacing the negative prompts used in
training-free methods with implicit negative embeddings obtained through
concept inversion. Our method requires no modification to either approach and
can be easily integrated into existing pipelines. We experimentally validate
its effectiveness on nudity and violence benchmarks, demonstrating consistent
improvements in defense success rate while preserving the core semantics of
input prompts.

</details>


### [131] [SPECTRA: Spectral Target-Aware Graph Augmentation for Imbalanced Molecular Property Regression](https://arxiv.org/abs/2511.04838)
*Brenda Nogueira,Meng Jiang,Nitesh V. Chawla,Nuno Moniz*

Main category: cs.LG

TL;DR: 提出SPECTRA，一种基于谱域的靶向感知图增强框架，用于解决分子属性预测中稀有高价值化合物数据稀疏的问题。


<details>
  <summary>Details</summary>
Motivation: 标准图神经网络在稀有但关键的高价值化合物上表现不佳，现有过采样方法易破坏分子拓扑结构。

Method: 通过SMILES重建多属性分子图，利用(Fused) Gromov-Wasserstein耦合对齐分子对以获得节点对应关系，在共享基上稳定插值拉普拉斯特征值、特征向量和节点特征，并重构边以生成物理上合理的中间分子；结合基于标签核密度估计的稀有性感知预算机制，集中增强数据稀缺区域。

Result: 在基准测试中，SPECTRA在目标相关区间显著降低误差，同时保持整体MAE竞争力，并生成可解释、反映谱几何结构的合成分子。

Conclusion: 谱域几何感知增强是解决不平衡分子属性回归问题的有效且高效策略。

Abstract: In molecular property prediction, the most valuable compounds (e.g., high
potency) often occupy sparse regions of the target space. Standard Graph Neural
Networks (GNNs) commonly optimize for the average error, underperforming on
these uncommon but critical cases, with existing oversampling methods often
distorting molecular topology. In this paper, we introduce SPECTRA, a Spectral
Target-Aware graph augmentation framework that generates realistic molecular
graphs in the spectral domain. SPECTRA (i) reconstructs multi-attribute
molecular graphs from SMILES; (ii) aligns molecule pairs via (Fused)
Gromov-Wasserstein couplings to obtain node correspondences; (iii) interpolates
Laplacian eigenvalues, eigenvectors and node features in a stable share-basis;
and (iv) reconstructs edges to synthesize physically plausible intermediates
with interpolated targets. A rarity-aware budgeting scheme, derived from a
kernel density estimation of labels, concentrates augmentation where data are
scarce. Coupled with a spectral GNN using edge-aware Chebyshev convolutions,
SPECTRA densifies underrepresented regions without degrading global accuracy.
On benchmarks, SPECTRA consistently improves error in relevant target ranges
while maintaining competitive overall MAE, and yields interpretable synthetic
molecules whose structure reflects the underlying spectral geometry. Our
results demonstrate that spectral, geometry-aware augmentation is an effective
and efficient strategy for imbalanced molecular property regression.

</details>


### [132] [Sublinear iterations can suffice even for DDPMs](https://arxiv.org/abs/2511.04844)
*Matthew S. Zhang,Stephen Huan,Jerry Huang,Nicholas M. Boffi,Sitan Chen,Sinho Chewi*

Main category: cs.LG

TL;DR: 本文提出了一种基于随机中点的去噪扩散方法（DDRaM），利用“移位组合规则”分析其离散化性质，在适当平滑性假设下实现了次线性的收敛复杂度$\widetilde{O}(\sqrt{d})$，是首个针对纯DDPM采样的次线性复杂度界，并通过实验验证了其在预训练图像生成模型中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的DDPM分析主要集中于指数欧拉离散化，其收敛保证通常至少线性依赖于维度或初始Fisher信息，限制了高维场景下的效率；受对数凹采样工作的启发，希望设计一种能更好逼近SDE且具有更优复杂度的采样器。

Method: 引入去噪扩散随机中点法（DDRaM），通过额外的随机中点来改进SDE逼近，并采用新近发展的“移位组合规则”分析框架进行理论分析。

Result: 在适当平滑性假设下，DDRaM算法仅需$\widetilde{O}(\sqrt{d})$次得分评估即可保证收敛，首次为纯DDPM采样提供了次线性复杂度上界，并在真实图像生成任务中验证了其优越性能。

Conclusion: DDRaM是一种高效且贴近实际使用的DDPM采样方法，理论和实验结果表明其在保持采样质量的同时显著提升了收敛效率，为扩散模型的高效采样提供了新思路。

Abstract: SDE-based methods such as denoising diffusion probabilistic models (DDPMs)
have shown remarkable success in real-world sample generation tasks. Prior
analyses of DDPMs have been focused on the exponential Euler discretization,
showing guarantees that generally depend at least linearly on the dimension or
initial Fisher information. Inspired by works in log-concave sampling (Shen and
Lee, 2019), we analyze an integrator -- the denoising diffusion randomized
midpoint method (DDRaM) -- that leverages an additional randomized midpoint to
better approximate the SDE. Using a recently-developed analytic framework
called the "shifted composition rule", we show that this algorithm enjoys
favorable discretization properties under appropriate smoothness assumptions,
with sublinear $\widetilde{O}(\sqrt{d})$ score evaluations needed to ensure
convergence. This is the first sublinear complexity bound for pure DDPM
sampling -- prior works which obtained such bounds worked instead with
ODE-based sampling and had to make modifications to the sampler which deviate
from how they are used in practice. We also provide experimental validation of
the advantages of our method, showing that it performs well in practice with
pre-trained image synthesis models.

</details>


### [133] [Investigating U.S. Consumer Demand for Food Products with Innovative Transportation Certificates Based on Stated Preferences and Machine Learning Approaches](https://arxiv.org/abs/2511.04845)
*Jingchen Bi,Rodrigo Mesa-Arango*

Main category: cs.LG

TL;DR: 该研究利用机器学习模型分析美国消费者对具有创新运输证书的食品产品的偏好，发现消费者更重视运输过程中的安全和能源相关证书，并结合产品和决策者因素提供了改进食品供应链的数据驱动建议。


<details>
  <summary>Details</summary>
Motivation: 识别消费者在食品购买决策中重视的运输属性，以提升食品供应链的透明度和效率。

Method: 基于前期关于可追溯性食品需求的研究，设计偏好实验并应用机器学习模型，提出五种创新运输证书（运输方式、物联网、安全措施、能源来源、必须到达日期），并控制产品和决策者变量。

Result: 消费者显著偏好安全措施和能源来源相关的运输证书；价格、产品类型、证书类型及决策者因素均影响购买选择。

Conclusion: 研究为优化美国食品供应链系统提供了数据支持的建议，强调在运输环节引入安全和可持续能源相关认证可提升消费者接受度。

Abstract: This paper utilizes a machine learning model to estimate the consumer's
behavior for food products with innovative transportation certificates in the
U.S. Building on previous research that examined demand for food products with
supply chain traceability using stated preference analysis, transportation
factors were identified as significant in consumer food purchasing choices.
Consequently, a second experiment was conducted to pinpoint the specific
transportation attributes valued by consumers. A machine learning model was
applied, and five innovative certificates related to transportation were
proposed: Transportation Mode, Internet of Things (IoT), Safety measures,
Energy Source, and Must Arrive By Dates (MABDs). The preference experiment also
incorporated product-specific and decision-maker factors for control purposes.
The findings reveal a notable inclination toward safety and energy certificates
within the transportation domain of the U.S. food supply chain. Additionally,
the study examined the influence of price, product type, certificates, and
decision-maker factors on purchasing choices. Ultimately, the study offers
data-driven recommendations for improving food supply chain systems.

</details>


### [134] [Grounded Test-Time Adaptation for LLM Agents](https://arxiv.org/abs/2511.04847)
*Arthur Chen,Zuxin Liu,Jianguo Zhang,Akshara Prabhakar,Zhiwei Liu,Shelby Heinecke,Silvio Savarese,Victor Zhong,Caiming Xiong*

Main category: cs.LG

TL;DR: 本文提出两种互补策略以提升基于大语言模型（LLM）的智能体在新环境中的泛化能力：在线分布适应和部署时动态建模，显著提升了在函数调用和网页导航等任务中的成功率。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在面对未见过的复杂环境时泛化能力差，主要由于训练与测试条件不匹配，表现为对观测格式（语法）和状态转移动态（语义）的理解不足。

Method: 1）在线分布适应：学习轻量级适配向量，调整模型输出分布以匹配环境响应格式；2）部署时动态建模：通过角色驱动探索阶段主动探测环境因果动态，构建非参数化世界模型。

Result: 在多个代理基准（如WebArena、函数调用）上验证有效，计算成本低；在WebArena多站点任务中，成功率从2%提升至23%，尤其在动态复杂环境中效果显著。

Conclusion: 结合环境特定信息进行部署时适应是提升LLM智能体泛化能力的有效路径，特别是动态建模策略为应对复杂未知环境提供了鲁棒解决方案。

Abstract: Large language model (LLM)-based agents struggle to generalize to novel and
complex environments, such as unseen websites or new sets of functions, due to
a fundamental mismatch between their pre-training and test-time conditions.
This challenge stems from two distinct failure modes: a syntactic
misunderstanding of environment-specific components like observation formats,
and a semantic misunderstanding of state-transition dynamics, which are only
revealed at test time. To address these issues, we propose two distinct and
complementary strategies for adapting LLM agents by leveraging
environment-specific information available during deployment. First, an online
distributional adaptation method parameterizes environmental nuances by
learning a lightweight adaptation vector that biases the model's output
distribution, enabling rapid alignment with an environment response format.
Second, a deployment-time dynamics grounding method employs a persona-driven
exploration phase to systematically probe and learn the environment's causal
dynamics before task execution, equipping the agent with a nonparametric world
model. We evaluate these strategies across diverse agentic benchmarks,
including function calling and web navigation. Our empirical results show the
effectiveness of both strategies across all benchmarks with minimal
computational cost. We find that dynamics grounding is particularly effective
in complex environments where unpredictable dynamics pose a major obstacle,
demonstrating a robust path toward more generalizable and capable LLM-based
agents. For example, on the WebArena multi-site split, this method increases
the agent's success rate from 2% to 23%.

</details>


### [135] [SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion](https://arxiv.org/abs/2511.04854)
*Alvaro Prat,Leo Zhang,Charlotte M. Deane,Yee Whye Teh,Garrett M. Morris*

Main category: cs.LG

TL;DR: SigmaDock 是一种基于 SE(3) 黎曼扩散模型的新型分子对接方法，通过将配体分解为刚性片段并学习在结合口袋中重组这些片段来生成结合构象，显著提升了对接成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有生成式分子对接方法常受限于化学不合理性、泛化能力差和计算成本高，因此需要一种更高效、可靠且具化学合理性的深度学习方法。

Method: 提出一种结合结构化学先验知识的配体碎片化方案，并基于此构建 SigmaDock 模型，采用 SE(3) 空间中的黎曼扩散过程对刚性片段进行构象生成与组装。

Result: 在 PoseBusters 数据集上达到 79.9% 以上的 Top-1 成功率（RMSD<2 & PB-valid），显著优于近期深度学习方法（12.7%-30.8%），并在未见蛋白上表现出良好泛化性，首次在 PB 划分下超越传统基于物理的方法。

Conclusion: SigmaDock 实现了深度学习在分子对接任务中的重大突破，兼具高精度、良好泛化性和化学合理性，推动了深度学习在药物发现中的实际应用可行性。

Abstract: Determining the binding pose of a ligand to a protein, known as molecular
docking, is a fundamental task in drug discovery. Generative approaches promise
faster, improved, and more diverse pose sampling than physics-based methods,
but are often hindered by chemically implausible outputs, poor
generalisability, and high computational cost. To address these challenges, we
introduce a novel fragmentation scheme, leveraging inductive biases from
structural chemistry, to decompose ligands into rigid-body fragments. Building
on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion
model that generates poses by learning to reassemble these rigid bodies within
the binding pocket. By operating at the level of fragments in SE(3), SigmaDock
exploits well-established geometric priors while avoiding overly complex
diffusion processes and unstable training dynamics. Experimentally, we show
SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates
(RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8%
reported by recent deep learning approaches, whilst demonstrating consistent
generalisation to unseen proteins. SigmaDock is the first deep learning
approach to surpass classical physics-based docking under the PB train-test
split, marking a significant leap forward in the reliability and feasibility of
deep learning for molecular modelling.

</details>


### [136] [Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2511.04856)
*Thore Gerlach,Michael Schenk,Verena Kain*

Main category: cs.LG

TL;DR: 提出了一种支持连续动作强化学习的连续半量子玻尔兹曼机（CSQBM），结合可见单元的指数族先验和隐藏单元的量子玻尔兹曼分布，实现了低量子比特消耗与高表达能力的平衡，并通过解析梯度支持Actor-Critic算法，提出了基于高效采样的连续Q学习框架以解决连续控制中的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 为解决连续动作空间强化学习中量子资源消耗大、训练不稳定的问题，需要一种兼具表达力与计算效率的量子-经典混合模型。

Method: 设计连续半量子玻尔兹曼机（CSQBM），在可见层引入指数族先验，在隐藏层采用量子玻尔兹曼分布；利用解析梯度实现与Actor-Critic架构的直接集成；通过从CSQBM分布中采样替代传统Q-learning中的全局最大化，提升训练稳定性。

Result: CSQBM在减少量子比特需求的同时保持强表达能力；实现了对连续变量的解析梯度计算；所提连续Q-learning框架显著提升了连续控制任务中的训练稳定性。

Conclusion: CSQBM为连续动作强化学习提供了一种高效、稳定的量子-经典混合建模范式，推动了量子机器学习在实际控制任务中的应用。

Abstract: We introduce theoretically grounded Continuous Semi-Quantum Boltzmann
Machines (CSQBMs) that supports continuous-action reinforcement learning. By
combining exponential-family priors over visible units with quantum Boltzmann
distributions over hidden units, CSQBMs yield a hybrid quantum-classical model
that reduces qubit requirements while retaining strong expressiveness.
Crucially, gradients with respect to continuous variables can be computed
analytically, enabling direct integration into Actor-Critic algorithms.
Building on this, we propose a continuous Q-learning framework that replaces
global maximization by efficient sampling from the CSQBM distribution, thereby
overcoming instability issues in continuous control.

</details>


### [137] [FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting](https://arxiv.org/abs/2511.04865)
*Esha Sharma,Lauren Davis,Julie Ivy,Min Chi*

Main category: cs.LG

TL;DR: 提出了一种基于强化学习的元学习框架FoodRL，用于提高食品银行对捐赠量的预测准确性，尤其在自然灾害等干扰期间表现优异，每年可多分配相当于170万餐的食物。


<details>
  <summary>Details</summary>
Motivation: 传统预测模型在应对食品捐赠的高度波动性和概念漂移（如季节变化和自然灾害）时表现不稳定，影响食品银行的资源分配效率。

Method: 提出FoodRL，一种基于强化学习的元学习框架，通过聚类并根据近期性能和上下文信息动态加权多种预测模型，提升预测的适应性和准确性。

Result: 在两个受不同自然灾害影响的美国食品银行数据上验证，FoodRL在干扰或下降期显著优于基线方法，预测更可靠。

Conclusion: FoodRL能有效提升食品银行的捐赠预测能力，具有显著的社会影响力，并为 humanitarian 供应链中的自适应集成学习提供了新思路。

Abstract: Food banks are crucial for alleviating food insecurity, but their
effectiveness hinges on accurately forecasting highly volatile in-kind
donations to ensure equitable and efficient resource distribution. Traditional
forecasting models often fail to maintain consistent accuracy due to
unpredictable fluctuations and concept drift driven by seasonal variations and
natural disasters such as hurricanes in the Southeastern U.S. and wildfires in
the West Coast. To address these challenges, we propose FoodRL, a novel
reinforcement learning (RL) based metalearning framework that clusters and
dynamically weights diverse forecasting models based on recent performance and
contextual information. Evaluated on multi-year data from two structurally
distinct U.S. food banks-one large regional West Coast food bank affected by
wildfires and another state-level East Coast food bank consistently impacted by
hurricanes, FoodRL consistently outperforms baseline methods, particularly
during periods of disruption or decline. By delivering more reliable and
adaptive forecasts, FoodRL can facilitate the redistribution of food equivalent
to 1.7 million additional meals annually, demonstrating its significant
potential for social impact as well as adaptive ensemble learning for
humanitarian supply chains.

</details>


### [138] [Self-Interest and Systemic Benefits: Emergence of Collective Rationality in Mixed Autonomy Traffic Through Deep Reinforcement Learning](https://arxiv.org/abs/2511.04883)
*Di Chen,Jia Li,Michael Zhang*

Main category: cs.LG

TL;DR: 该研究探讨了在混合自动驾驶交通系统中，自利的自动驾驶车辆是否仍能为所有驾驶者带来好处，重点分析了集体理性（CR）的概念，并通过深度强化学习证明了即使不直接引入系统级目标，CR也能在多种场景下稳定出现。


<details>
  <summary>Details</summary>
Motivation: 理解自利的自动驾驶车辆在混合交通系统中是否能够促进整体交通性能，尤其是在驾驶者追求个体利益的情况下。

Method: 采用深度强化学习（DRL）训练驾驶代理，使用简单的奖励设计，在不直接加入系统级目标的前提下，模拟并分析集体理性的出现情况。

Result: 实验结果表明，无论在何种场景下，集体理性（CR）均能稳定地自发涌现，显示出该特性的鲁棒性，并通过仿真验证了解释其微观动态机制的假设。

Conclusion: 研究表明，即便驾驶代理出于自利动机，集体理性仍可实现，提示未来可通过联邦学习等先进学习方法，在混合自主交通系统中实现自利代理间的集体协作。

Abstract: Autonomous vehicles (AVs) are expected to be commercially available in the
near future, leading to mixed autonomy traffic consisting of both AVs and
human-driven vehicles (HVs). Although numerous studies have shown that AVs can
be deployed to benefit the overall traffic system performance by incorporating
system-level goals into their decision making, it is not clear whether the
benefits still exist when agents act out of self-interest -- a trait common to
all driving agents, both human and autonomous. This study aims to understand
whether self-interested AVs can bring benefits to all driving agents in mixed
autonomy traffic systems. The research is centered on the concept of collective
rationality (CR). This concept, originating from game theory and behavioral
economics, means that driving agents may cooperate collectively even when
pursuing individual interests. Our recent research has proven the existence of
CR in an analytical game-theoretical model and empirically in mixed
human-driven traffic. In this paper, we demonstrate that CR can be attained
among driving agents trained using deep reinforcement learning (DRL) with a
simple reward design. We examine the extent to which self-interested traffic
agents can achieve CR without directly incorporating system-level objectives.
Results show that CR consistently emerges in various scenarios, which indicates
the robustness of this property. We also postulate a mechanism to explain the
emergence of CR in the microscopic and dynamic environment and verify it based
on simulation evidence. This research suggests the possibility of leveraging
advanced learning methods (such as federated learning) to achieve collective
cooperation among self-interested driving agents in mixed-autonomy systems.

</details>


### [139] [You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models](https://arxiv.org/abs/2511.04902)
*Shuvendu Roy,Hossein Hajimirsadeghi,Mengyao Zhai,Golnoosh Samei*

Main category: cs.LG

TL;DR: 本文研究了无监督强化学习（RL）方法在不同规模和推理能力的模型上的表现，发现小模型由于推理能力弱而难以有效进行自我反思。为此，作者提出了一种结合课程学习和掩码非多数 rollout 的新方法，并设计了数据筛选流程，显著提升了小模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索无监督强化学习在小型基础模型上的适用性，解决现有方法对强推理基座模型依赖的问题。

Method: 采用课程学习逐步引入更难的问题，掩码非多数rollout策略，并构建数据筛选流程生成具有预定义难度的训练样本。

Result: 所提方法在0.5B到7B参数的模型上均实现了稳定提升，尤其改善了小模型的推理表现，克服了传统无监督RL在弱模型上性能下降的问题。

Conclusion: 通过课程学习和数据控制，可使标签无关的强化学习更有效地引导小模型发展推理能力，为资源受限场景下的模型推理增强提供了可行路径。

Abstract: Recent advances in large language models have demonstrated the promise of
unsupervised reinforcement learning (RL) methods for enhancing reasoning
capabilities without external supervision. However, the generalizability of
these label-free RL approaches to smaller base models with limited reasoning
capabilities remains unexplored. In this work, we systematically investigate
the performance of label-free RL methods across different model sizes and
reasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals
critical limitations: label-free RL is highly dependent on the base model's
pre-existing reasoning capability, with performance often degrading below
baseline levels for weaker models. We find that smaller models fail to generate
sufficiently long or diverse chain-of-thought reasoning to enable effective
self-reflection, and that training data difficulty plays a crucial role in
determining success. To address these challenges, we propose a simple yet
effective method for label-free RL that utilizes curriculum learning to
progressively introduce harder problems during training and mask no-majority
rollouts during training. Additionally, we introduce a data curation pipeline
to generate samples with predefined difficulty. Our approach demonstrates
consistent improvements across all model sizes and reasoning capabilities,
providing a path toward more robust unsupervised RL that can bootstrap
reasoning abilities in resource-constrained models. We make our code available
at https://github.com/BorealisAI/CuMa

</details>


### [140] [Multi-agent Coordination via Flow Matching](https://arxiv.org/abs/2511.05005)
*Dongsu Lee,Daehee Lee,Amy Zhang*

Main category: cs.LG

TL;DR: 本文提出了MAC-Flow，一种用于多智能体协调的简单而有效的框架，通过流模型学习联合行为表示，并蒸馏为去中心化的单步策略，在保持性能的同时实现快速推理。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体协调方法在表现力和实时性之间存在权衡：基于扩散模型的方法表达能力强但计算慢，基于高斯策略的方法快但难以处理复杂的交互。本文旨在解决这一权衡问题。

Method: MAC-Flow首先使用基于流的模型学习离线数据中的联合行为表示，然后将其蒸馏为去中心化的单步策略，以实现高效实时执行。

Result: 在4个基准、12个环境和34个数据集上的实验表明，MAC-Flow比基于扩散的MARL方法推理速度快约14.5倍，同时保持良好性能，且推理速度与基于高斯策略的离线MARL方法相当。

Conclusion: MAC-Flow有效缓解了多智能体协调中性能与计算成本之间的权衡，兼具强表达能力和高效推理，为离线多智能体强化学习提供了一种更实用的解决方案。

Abstract: This work presents MAC-Flow, a simple yet expressive framework for
multi-agent coordination. We argue that requirements of effective coordination
are twofold: (i) a rich representation of the diverse joint behaviors present
in offline data and (ii) the ability to act efficiently in real time. However,
prior approaches often sacrifice one for the other, i.e., denoising
diffusion-based solutions capture complex coordination but are computationally
slow, while Gaussian policy-based solutions are fast but brittle in handling
multi-agent interaction. MAC-Flow addresses this trade-off by first learning a
flow-based representation of joint behaviors, and then distilling it into
decentralized one-step policies that preserve coordination while enabling fast
execution. Across four different benchmarks, including $12$ environments and
$34$ datasets, MAC-Flow alleviates the trade-off between performance and
computational cost, specifically achieving about $\boldsymbol{\times14.5}$
faster inference compared to diffusion-based MARL methods, while maintaining
good performance. At the same time, its inference speed is similar to that of
prior Gaussian policy-based offline multi-agent reinforcement learning (MARL)
methods.

</details>


### [141] [Efficient Swap Multicalibration of Elicitable Properties](https://arxiv.org/abs/2511.04907)
*Lunjia Hu,Haipeng Luo,Spandan Senapati,Vatsal Sharan*

Main category: cs.LG

TL;DR: 本文推广了多校准（multicalibration）的概念，提出了一种更强的“交换多校准”（swap multicalibration）定义，并设计了一个高效的在线算法，在任意有界假设类和可提取性质Γ下，实现了优于先前工作的ℓ_r-多校准误差界，解决了关于是否存在高效算法实现√T ℓ₂-均值多校准误差的开放问题。


<details>
  <summary>Details</summary>
Motivation: 多校准是算法公平性的重要概念，但已有工作在效率和适用范围上存在局限。本文旨在扩展多校准至更一般的假设类，并提升其校准强度与算法效率，以解决现有理论瓶颈。

Method: 通过引入交换多校准概念，并利用在线对抗学习器作为预言机，结合序列Rademacher复杂度分析，设计出一种预言机高效的在线算法，实现对ℓ_r-多校准误差的控制。

Result: 提出了适用于任意有界假设类的交换多校准框架；给出了一个预言机高效算法，以高概率实现T^{1/(r+1)}的ℓ_r-多校准误差（r≥2），特别地在r=2时达到T^{1/3}的ℓ₂误差，显著优于之前的√T界限。

Conclusion: 本文证明了在可提取性质下，通过交换多校准和预言机高效算法，可以在更广泛设定下实现更优的多校准性能，彻底解决了关于能否超越√T ℓ₂-误差的开放问题。

Abstract: Multicalibration [HJKRR18] is an algorithmic fairness perspective that
demands that the predictions of a predictor are correct conditional on
themselves and membership in a collection of potentially overlapping subgroups
of a population. The work of [NR23] established a surprising connection between
multicalibration for an arbitrary property $\Gamma$ (e.g., mean or median) and
property elicitation: a property $\Gamma$ can be multicalibrated if and only if
it is elicitable, where elicitability is the notion that the true property
value of a distribution can be obtained by solving a regression problem over
the distribution. In the online setting, [NR23] proposed an inefficient
algorithm that achieves $\sqrt T$ $\ell_2$-multicalibration error for a
hypothesis class of group membership functions and an elicitable property
$\Gamma$, after $T$ rounds of interaction between a forecaster and adversary.
  In this paper, we generalize multicalibration for an elicitable property
$\Gamma$ from group membership functions to arbitrary bounded hypothesis
classes and introduce a stronger notion -- swap multicalibration, following
[GKR23]. Subsequently, we propose an oracle-efficient algorithm which, when
given access to an online agnostic learner, achieves $T^{1/(r+1)}$
$\ell_r$-swap multicalibration error with high probability (for $r\ge2$) for a
hypothesis class with bounded sequential Rademacher complexity and an
elicitable property $\Gamma$. For the special case of $r=2$, this implies an
oracle-efficient algorithm that achieves $T^{1/3}$ $\ell_2$-swap
multicalibration error, which significantly improves on the previously
established bounds for the problem [NR23, GMS25, LSS25a], and completely
resolves an open question raised in [GJRR24] on the possibility of an
oracle-efficient algorithm that achieves $\sqrt{T}$ $\ell_2$-mean
multicalibration error by answering it in a strongly affirmative sense.

</details>


### [142] [SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning](https://arxiv.org/abs/2511.05355)
*Tzu-Yuan Huang,Armin Lederer,Dai-Jie Wu,Xiaobing Dai,Sihua Zhang,Stefan Sosnowski,Shao-Hua Sun,Sandra Hirche*

Main category: cs.LG

TL;DR: SAD-Flower是一种用于生成安全、合规且动力学一致轨迹的新框架，通过增强流模型并引入虚拟控制输入，结合非线性控制理论，在无需重新训练的情况下提供状态、动作和动力学约束的形式化保证。


<details>
  <summary>Details</summary>
Motivation: 现有流匹配规划器缺乏对状态和动作约束的正式保证，且不确保动力学一致性，限制了其在安全关键系统中的应用。

Method: 提出SAD-Flower框架，通过引入虚拟控制输入增强流模型，并利用非线性控制理论提供对约束的 principled 指导，实现安全性和动态一致性保障。

Result: 实验表明，SAD-Flower在多个任务中优于现有的生成模型基线方法，在满足各类约束方面表现更优。

Conclusion: SAD-Flower能够在无需重新训练的前提下，有效保证规划轨迹的安全性、合规性和动力学可执行性，适用于复杂系统的数据驱动规划。

Abstract: Flow matching (FM) has shown promising results in data-driven planning.
However, it inherently lacks formal guarantees for ensuring state and action
constraints, whose satisfaction is a fundamental and crucial requirement for
the safety and admissibility of planned trajectories on various systems.
Moreover, existing FM planners do not ensure the dynamical consistency, which
potentially renders trajectories inexecutable. We address these shortcomings by
proposing SAD-Flower, a novel framework for generating Safe, Admissible, and
Dynamically consistent trajectories. Our approach relies on an augmentation of
the flow with a virtual control input. Thereby, principled guidance can be
derived using techniques from nonlinear control theory, providing formal
guarantees for state constraints, action constraints, and dynamic consistency.
Crucially, SAD-Flower operates without retraining, enabling test-time
satisfaction of unseen constraints. Through extensive experiments across
several tasks, we demonstrate that SAD-Flower outperforms various
generative-model-based baselines in ensuring constraint satisfaction.

</details>


### [143] [A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates](https://arxiv.org/abs/2511.04909)
*Paula Rodriguez-Diaz,Kirk Bansak Elisabeth Paulson*

Main category: cs.LG

TL;DR: 本文提出了一种名为Dual-Guided Loss (DGL)的新方法，用于在预测-优化范式中减少对求解器的依赖，同时保持决策对齐。该方法通过利用下游问题的对偶变量，仅周期性调用优化器，并在更新间隙使用可微代理损失进行训练，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的决策导向学习方法需要频繁调用（尤其是组合）优化器，导致训练成本高、难以扩展，因此需要一种更高效、可扩展的方法来减少求解器调用次数。

Method: 提出Dual-Guided Loss (DGL)，利用下游优化问题的对偶变量调整预测目标；周期性求解优化问题以更新对偶变量，在两次更新之间使用简单可微的代理损失进行模型训练。

Result: DGL在匹配、背包和最短路径等组合选择问题上表现优异，在显著减少求解器调用次数和训练时间的同时，决策性能达到或超过现有最先进方法；理论证明其具有渐近衰减的决策遗憾，并具备更低的运行复杂度。

Conclusion: DGL是一种简单且可扩展的决策导向学习框架，有效平衡了决策性能与计算效率，为大规模组合优化问题中的预测-优化流程提供了实用解决方案。

Abstract: Many real-world decisions are made under uncertainty by solving optimization
problems using predicted quantities. This predict-then-optimize paradigm has
motivated decision-focused learning, which trains models with awareness of how
the optimizer uses predictions, improving the performance of downstream
decisions. Despite its promise, scaling is challenging: state-of-the-art
methods either differentiate through a solver or rely on task-specific
surrogates, both of which require frequent and expensive calls to an optimizer,
often a combinatorial one. In this paper, we leverage dual variables from the
downstream problem to shape learning and introduce Dual-Guided Loss (DGL), a
simple, scalable objective that preserves decision alignment while reducing
solver dependence. We construct DGL specifically for combinatorial selection
problems with natural one-of-many constraints, such as matching, knapsack, and
shortest path. Our approach (a) decouples optimization from gradient updates by
solving the downstream problem only periodically; (b) between refreshes, trains
on dual-adjusted targets using simple differentiable surrogate losses; and (c)
as refreshes become less frequent, drives training cost toward standard
supervised learning while retaining strong decision alignment. We prove that
DGL has asymptotically diminishing decision regret, analyze runtime complexity,
and show on two problem classes that DGL matches or exceeds state-of-the-art
DFL methods while using far fewer solver calls and substantially less training
time. Code is available at https://github.com/paularodr/Dual-Guided-Learning.

</details>


### [144] [Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction](https://arxiv.org/abs/2511.05396)
*Yiting He,Zhishuai Liu,Weixin Wang,Pan Xu*

Main category: cs.LG

TL;DR: 本文研究了在训练和部署环境动态不同的情况下，基于在线交互的鲁棒强化学习问题，提出了首个在f-散度不确定性下实现次线性遗憾的高效算法，并建立了匹配的下界，验证了算法的最优性。


<details>
  <summary>Details</summary>
Motivation: 现有工作多假设有生成模型或良好覆盖的数据集，忽略了探索挑战；本文考虑更现实的仅能与训练环境在线交互的设定，研究在线鲁棒强化学习中的探索难题。

Method: 引入了上确界访问比率来量化训练与部署动态之间的不匹配，并设计了一种新的高效算法，在f-散度约束的转移不确定性下实现次线性遗憾。

Result: 证明了当上确界访问比率无界时，学习变得指数级困难；所提算法实现了与该比率和交互轮数相关的最优遗憾下界。

Conclusion: 本文提出的算法在在线鲁棒强化学习中达到了理论上的最优性能，并通过实验验证了其有效性。

Abstract: Off-dynamics reinforcement learning (RL), where training and deployment
transition dynamics are different, can be formulated as learning in a robust
Markov decision process (RMDP) where uncertainties in transition dynamics are
imposed. Existing literature mostly assumes access to generative models
allowing arbitrary state-action queries or pre-collected datasets with a good
state coverage of the deployment environment, bypassing the challenge of
exploration. In this work, we study a more realistic and challenging setting
where the agent is limited to online interaction with the training environment.
To capture the intrinsic difficulty of exploration in online RMDPs, we
introduce the supremal visitation ratio, a novel quantity that measures the
mismatch between the training dynamics and the deployment dynamics. We show
that if this ratio is unbounded, online learning becomes exponentially hard. We
propose the first computationally efficient algorithm that achieves sublinear
regret in online RMDPs with $f$-divergence based transition uncertainties. We
also establish matching regret lower bounds, demonstrating that our algorithm
achieves optimal dependence on both the supremal visitation ratio and the
number of interaction episodes. Finally, we validate our theoretical results
through comprehensive numerical experiments.

</details>


### [145] [Machine Learning Algorithms in Statistical Modelling Bridging Theory and Application](https://arxiv.org/abs/2511.04918)
*A. Ganapathi Rao,Sathish Krishna Anumula,Aditya Kumar Singh,Renukhadevi M,Y. Jeevan Nagendra Kumar,Tammineni Rama Tulasi*

Main category: cs.LG

TL;DR: 本文探讨了机器学习算法与传统统计模型的结合方式，展示了现代ML算法如何提升传统模型的性能、可扩展性、灵活性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 理解机器学习与传统统计模型之间的联系，并探索如何通过现代ML算法增强传统模型。

Method: 研究机器学习与统计模型的连接，构建混合模型并评估其在预测准确性、鲁棒性和可解释性方面的表现。

Result: 混合模型在预测准确性、鲁棒性和可解释性方面均有显著提升。

Conclusion: 将机器学习与传统统计模型结合能有效改进模型性能，代表了数据分析和决策的新方向。

Abstract: It involves the completely novel ways of integrating ML algorithms with
traditional statistical modelling that has changed the way we analyze data, do
predictive analytics or make decisions in the fields of the data. In this
paper, we study some ML and statistical model connections to understand ways in
which some modern ML algorithms help 'enrich' conventional models; we
demonstrate how new algorithms improve performance, scale, flexibility and
robustness of the traditional models. It shows that the hybrid models are of
great improvement in predictive accuracy, robustness, and interpretability

</details>


### [146] [Leak@$k$: Unlearning Does Not Make LLMs Forget Under Probabilistic Decoding](https://arxiv.org/abs/2511.04934)
*Hadi Reisizadeh,Jiajun Ruan,Yiwei Chen,Soumyadeep Pal,Sijia Liu,Mingyi Hong*

Main category: cs.LG

TL;DR: 现有大语言模型的遗忘方法在确定性解码下看似有效，但在实际概率解码中仍会泄露敏感信息；本文提出新的评估指标 leak@k，并通过大规模实验证明当前方法普遍缺乏真正的遗忘能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM遗忘方法多在确定性解码下评估，忽视了在实际生成中使用概率采样时知识可能重新浮现的问题，导致高估了遗忘效果，因此需要更可靠的评估方式和更鲁棒的遗忘技术。

Method: 提出一种新的元评估指标 leak@k，用于量化在不同解码策略下生成k个样本时被遗忘知识重现的概率，并在TOFU、MUSE和WMDP三个主流基准上进行系统性大规模评估。

Result: 实验表明，几乎所有现有的遗忘方法在概率采样生成时都会显著泄露已被遗忘的知识，说明当前方法并未实现真正的知识清除。

Conclusion: 当前的大语言模型遗忘方法在现实生成场景中普遍存在知识泄漏问题，leak@k 提供了一个更严格的评估标准，凸显了开发更强健遗忘机制的紧迫性。

Abstract: Unlearning in large language models (LLMs) is critical for regulatory
compliance and for building ethical generative AI systems that avoid producing
private, toxic, illegal, or copyrighted content. Despite rapid progress, in
this work we show that \textit{almost all} existing unlearning methods fail to
achieve true forgetting in practice. Specifically, while evaluations of these
`unlearned' models under deterministic (greedy) decoding often suggest
successful knowledge removal using standard benchmarks (as has been done in the
literature), we show that sensitive information reliably resurfaces when models
are sampled with standard probabilistic decoding. To rigorously capture this
vulnerability, we introduce \texttt{leak@$k$}, a new meta-evaluation metric
that quantifies the likelihood of forgotten knowledge reappearing when
generating $k$ samples from the model under realistic decoding strategies.
Using three widely adopted benchmarks, TOFU, MUSE, and WMDP, we conduct the
first large-scale, systematic study of unlearning reliability using our newly
defined \texttt{leak@$k$} metric. Our findings demonstrate that knowledge
leakage persists across methods and tasks, underscoring that current
state-of-the-art unlearning techniques provide only limited forgetting and
highlighting the urgent need for more robust approaches to LLM unlearning.

</details>


### [147] [Structural Properties, Cycloid Trajectories and Non-Asymptotic Guarantees of EM Algorithm for Mixed Linear Regression](https://arxiv.org/abs/2511.04937)
*Zhankun Luo,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: 本论文研究了在混合权重和回归参数均未知的情况下，两组件混合线性回归（2MLR）中期望最大化（EM）算法的结构特性、旋轮线轨迹及非渐近收敛保证。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究在已知平衡权重或高信噪比条件下证明了EM算法的全局收敛性，但在完全未知参数设置下，其轨迹行为和收敛阶数仍不清楚，本文旨在填补这一理论空白。

Method: 推导了在所有信噪比条件下2MLR中EM更新的显式表达式，分析其结构特性和旋轮线轨迹；通过建立次优角的递推关系，证明在无噪声情况下回归参数轨迹为旋轮线，并在高信噪比下量化其偏差。

Result: 揭示了EM算法的收敛阶数：当估计接近正交于真实值时为线性收敛，当估计与真实值夹角较小时为二次收敛；并建立了有限样本下的非渐近收敛保证。

Conclusion: 本文提出了一个基于轨迹的新框架，用于分析混合线性回归中的EM算法，阐明了其在不同信噪比和初始化条件下的动态行为和统计精度。

Abstract: This work investigates the structural properties, cycloid trajectories, and
non-asymptotic convergence guarantees of the Expectation-Maximization (EM)
algorithm for two-component Mixed Linear Regression (2MLR) with unknown mixing
weights and regression parameters. Recent studies have established global
convergence for 2MLR with known balanced weights and super-linear convergence
in noiseless and high signal-to-noise ratio (SNR) regimes. However, the
theoretical behavior of EM in the fully unknown setting remains unclear, with
its trajectory and convergence order not yet fully characterized. We derive
explicit EM update expressions for 2MLR with unknown mixing weights and
regression parameters across all SNR regimes and analyze their structural
properties and cycloid trajectories. In the noiseless case, we prove that the
trajectory of the regression parameters in EM iterations traces a cycloid by
establishing a recurrence relation for the sub-optimality angle, while in high
SNR regimes we quantify its discrepancy from the cycloid trajectory. The
trajectory-based analysis reveals the order of convergence: linear when the EM
estimate is nearly orthogonal to the ground truth, and quadratic when the angle
between the estimate and ground truth is small at the population level. Our
analysis establishes non-asymptotic guarantees by sharpening bounds on
statistical errors between finite-sample and population EM updates, relating
EM's statistical accuracy to the sub-optimality angle, and proving convergence
with arbitrary initialization at the finite-sample level. This work provides a
novel trajectory-based framework for analyzing EM in Mixed Linear Regression.

</details>


### [148] [Risk Prediction of Cardiovascular Disease for Diabetic Patients with Machine Learning and Deep Learning Techniques](https://arxiv.org/abs/2511.04971)
*Esha Chowdhury*

Main category: cs.LG

TL;DR: 本研究利用机器学习和混合深度学习方法，基于BRFSS数据集构建了针对糖尿病患者的心血管疾病（CVD）风险预测模型，XGBoost和LSTM模型均达到0.9050的最高准确率，部分模型实现1.00召回率，表明其在辅助临床决策和个性化预防策略中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 糖尿病与心血管疾病密切相关，准确预测糖尿病患者的心血管疾病风险对提升临床决策和预防策略至关重要。

Method: 采用BRFSS数据集，通过去重、处理缺失值、特征分类和主成分分析（PCA）进行预处理；比较了多种机器学习模型（如XGBoost、SVM等）和深度学习模型（如LSTM、CNN、GRU等）以及CNN与LSTM、BiLSTM、GRU的混合模型。

Result: XGBoost和LSTM模型均达到0.9050的最高准确率，部分深度学习模型实现了1.00的完美召回率，F1分数较高。

Conclusion: 机器学习和深度学习模型在预测糖尿病患者心血管疾病风险方面表现优异，有助于自动化和增强临床决策，提升个性化风险管理和预防策略的有效性。

Abstract: Accurate prediction of cardiovascular disease (CVD) risk is crucial for
healthcare institutions. This study addresses the growing prevalence of
diabetes and its strong link to heart disease by proposing an efficient CVD
risk prediction model for diabetic patients using machine learning (ML) and
hybrid deep learning (DL) approaches. The BRFSS dataset was preprocessed by
removing duplicates, handling missing values, identifying categorical and
numerical features, and applying Principal Component Analysis (PCA) for feature
extraction. Several ML models, including Decision Trees (DT), Random Forest
(RF), k-Nearest Neighbors (KNN), Support Vector Machine (SVM), AdaBoost, and
XGBoost, were implemented, with XGBoost achieving the highest accuracy of
0.9050. Various DL models, such as Artificial Neural Networks (ANN), Deep
Neural Networks (DNN), Recurrent Neural Networks (RNN), Convolutional Neural
Networks (CNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), and
Gated Recurrent Unit (GRU), as well as hybrid models combining CNN with LSTM,
BiLSTM, and GRU, were also explored. Some of these models achieved perfect
recall (1.00), with the LSTM model achieving the highest accuracy of 0.9050.
Our research highlights the effectiveness of ML and DL models in predicting CVD
risk among diabetic patients, automating and enhancing clinical
decision-making. High accuracy and F1 scores demonstrate these models'
potential to improve personalized risk management and preventive strategies.

</details>


### [149] [Less Is More: Generating Time Series with LLaMA-Style Autoregression in Simple Factorized Latent Spaces](https://arxiv.org/abs/2511.04973)
*Siyuan Li,Yifan Sun,Lei Cheng,Lewen Wang,Yang Liu,Weiqing Liu,Jianlong Li,Jiang Bian,Shikai Fang*

Main category: cs.LG

TL;DR: 提出FAR-TS框架，结合解耦分解与自回归Transformer，在离散潜在空间中实现快速、可控的任意长度时间序列生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的时间序列生成方法速度慢且受限于固定长度窗口，难以满足实际应用需求。

Method: 将时间序列分解为捕捉静态跨通道相关性的自适应基和可向量量化的时序系数，使用类似LLaMA的自回归Transformer对离散化后的token序列进行建模。

Result: FAR-TS比Diffusion-TS快几个数量级，同时保持跨通道相关性和可解释的潜在空间。

Conclusion: FAR-TS是一种高效、灵活且高质量的时间序列生成框架，适用于数据增强、仿真和隐私保护等任务。

Abstract: Generative models for multivariate time series are essential for data
augmentation, simulation, and privacy preservation, yet current
state-of-the-art diffusion-based approaches are slow and limited to
fixed-length windows. We propose FAR-TS, a simple yet effective framework that
combines disentangled factorization with an autoregressive Transformer over a
discrete, quantized latent space to generate time series. Each time series is
decomposed into a data-adaptive basis that captures static cross-channel
correlations and temporal coefficients that are vector-quantized into discrete
tokens. A LLaMA-style autoregressive Transformer then models these token
sequences, enabling fast and controllable generation of sequences with
arbitrary length. Owing to its streamlined design, FAR-TS achieves
orders-of-magnitude faster generation than Diffusion-TS while preserving
cross-channel correlations and an interpretable latent space, enabling
high-quality and flexible time series synthesis.

</details>


### [150] [Scaling Up ROC-Optimizing Support Vector Machines](https://arxiv.org/abs/2511.04979)
*Gimun Bae,Seung Jun Shin*

Main category: cs.LG

TL;DR: 提出了一种基于不完全U统计量的可扩展ROC-SVM变体，显著降低计算复杂度，同时保持与原方法相当的AUC性能。


<details>
  <summary>Details</summary>
Motivation: 原始ROC-SVM因计算成本高（O(n^2)）限制了其在类别不平衡问题中的实际应用。

Method: 利用不完全U统计量减少计算量，并结合低秩核近似扩展到非线性分类。

Result: 理论分析提供了误差界支持，实验结果显示新方法在合成和真实数据上显著缩短训练时间的同时保持了相近的AUC性能。

Conclusion: 该方法在保证分类性能的前提下大幅提升了ROC-SVM的训练效率，适用于大规模或类别不平衡场景。

Abstract: The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the
area under the ROC curve (AUC) and has become an attractive alternative of the
conventional binary classification under the presence of class imbalance.
However, its practical use is limited by high computational cost, as training
involves evaluating all $O(n^2)$. To overcome this limitation, we develop a
scalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby
substantially reducing computational complexity. We further extend the
framework to nonlinear classification through a low-rank kernel approximation,
enabling efficient training in reproducing kernel Hilbert spaces. Theoretical
analysis establishes an error bound that justifies the proposed approximation,
and empirical results on both synthetic and real datasets demonstrate that the
proposed method achieves comparable AUC performance to the original ROC-SVM
with drastically reduced training time.

</details>


### [151] [Unlocking the Black Box: A Five-Dimensional Framework for Evaluating Explainable AI in Credit Risk](https://arxiv.org/abs/2511.04980)
*Rongbin Ye,Jiaqi Chen*

Main category: cs.LG

TL;DR: 本文探讨了在金融行业中如何平衡机器学习模型的预测能力与监管要求的可解释性，提出了一种新的五维评估框架（包括固有可解释性、全局解释、局部解释、一致性和复杂性），以评估和比较不同模型的可解释性。研究表明，通过使用SHAP和LIME等现代解释技术，高性能的复杂模型也可满足监管需求。


<details>
  <summary>Details</summary>
Motivation: 金融行业需要在高预测性能的“黑箱”模型与监管机构对模型可解释性的要求之间取得平衡，现有研究缺乏系统性评估方法。

Method: 应用LIME和SHAP等可解释性框架于多种模型，并提出一个包含五个维度的新评估框架：固有可解释性、全局解释、局部解释、一致性和复杂性。

Result: 证明了复杂且高性能的机器学习模型可以通过SHAP和LIME实现与简单模型相当的可解释性，并通过新提出的五维框架提供了更细致的评估手段。

Conclusion: 通过现代可解释性技术，可以在保持模型高性能的同时满足金融监管要求，所提出的评估框架有助于在实际应用中权衡模型性能与可解释性。

Abstract: The financial industry faces a significant challenge modeling and risk
portfolios: balancing the predictability of advanced machine learning models,
neural network models, and explainability required by regulatory entities (such
as Office of the Comptroller of the Currency, Consumer Financial Protection
Bureau). This paper intends to fill the gap in the application between these
"black box" models and explainability frameworks, such as LIME and SHAP.
Authors elaborate on the application of these frameworks on different models
and demonstrates the more complex models with better prediction powers could be
applied and reach the same level of the explainability, using SHAP and LIME.
Beyond the comparison and discussion of performances, this paper proposes a
novel five dimensional framework evaluating Inherent Interpretability, Global
Explanations, Local Explanations, Consistency, and Complexity to offer a
nuanced method for assessing and comparing model explainability beyond simple
accuracy metrics. This research demonstrates the feasibility of employing
sophisticated, high performing ML models in regulated financial environments by
utilizing modern explainability techniques and provides a structured approach
to evaluate the crucial trade offs between model performance and
interpretability.

</details>


### [152] [Deep Progressive Training: scaling up depth capacity of zero/one-layer models](https://arxiv.org/abs/2511.04981)
*Zhiqi Bu*

Main category: cs.LG

TL;DR: 提出零/单层渐进训练方法，通过在训练过程中扩展模型深度，在几乎不损失性能的情况下节省约80%计算量，加速约5倍。


<details>
  <summary>Details</summary>
Motivation: 深层模型虽精度高但计算成本大，需高效训练策略以平衡计算开销与性能。

Method: 基于优化理论和特征学习分析模型深度扩展，提出零/单层渐进训练策略，研究新层初始化、超参数迁移、学习率调度和模型扩展时机。

Result: 在GPT2上实现约80%的计算节省或5倍加速，同时保持与完整60层7B参数模型相当的损失表现。

Conclusion: 零/单层渐进训练能有效平衡大模型训练中的计算效率与模型性能。

Abstract: Model depth is a double-edged sword in deep learning: deeper models achieve
higher accuracy but require higher computational cost. To efficiently train
models at scale, an effective strategy is the progressive training, which
scales up model capacity during training, hence significantly reducing
computation with little to none performance degradation. In this work, we study
the depth expansion of large models through the lens of optimization theory and
feature learning, offering insights on the initialization of new layers,
hyperparameter transfer, learning rate schedule, and timing of model expansion.
Specifically, we propose zero/one-layer progressive training for the optimal
tradeoff between computation and loss. For example, zero/one-layer progressive
training on GPT2 can save $\approx 80\%$ compute, or equivalently accelerate
$\approx 5\times$ while achieving almost the same loss, compared to to a fully
trained 60-layer model with 7B parameters.

</details>


### [153] [Peptide2Mol: A Diffusion Model for Generating Small Molecules as Peptide Mimics for Targeted Protein Binding](https://arxiv.org/abs/2511.04984)
*Xinheng He,Yijia Zhang,Haowei Lin,Xingang Peng,Xiangzhe Kong,Mingyu Li,Jianzhu Ma*

Main category: cs.LG

TL;DR: 本文提出了一种基于E(3)-等变图神经网络扩散模型的结构化药物设计方法Peptide2Mol，能够参考原始肽结合物及其蛋白口袋环境生成小分子，在非自回归生成任务中达到先进性能，并支持分子优化与类肽设计。


<details>
  <summary>Details</summary>
Motivation: 现有AI驱动的药物设计方法常忽略内源性蛋白质-肽相互作用，可能导致分子设计次优，因此需要一种能结合肽结合信息和蛋白环境的方法。

Method: 采用E(3)-等变图神经网络扩散模型，以原始肽配体及其周围蛋白口袋为输入，进行小分子生成；通过部分扩散实现分子优化和类肽设计。

Result: Peptide2Mol在生成任务中达到最先进的性能，生成的分子与原始肽具有相似性，并能有效优化生物活性小分子。

Conclusion: Peptide2Mol是一种有效的深度生成模型，可用于从蛋白结合口袋出发生成和优化具有生物活性的小分子，尤其适用于类肽药物设计。

Abstract: Structure-based drug design has seen significant advancements with the
integration of artificial intelligence (AI), particularly in the generation of
hit and lead compounds. However, most AI-driven approaches neglect the
importance of endogenous protein interactions with peptides, which may result
in suboptimal molecule designs. In this work, we present Peptide2Mol, an
E(3)-equivariant graph neural network diffusion model that generates small
molecules by referencing both the original peptide binders and their
surrounding protein pocket environments. Trained on large datasets and
leveraging sophisticated modeling techniques, Peptide2Mol not only achieves
state-of-the-art performance in non-autoregressive generative tasks, but also
produces molecules with similarity to the original peptide binder.
Additionally, the model allows for molecule optimization and peptidomimetic
design through a partial diffusion process. Our results highlight Peptide2Mol
as an effective deep generative model for generating and optimizing bioactive
small molecules from protein binding pockets.

</details>


### [154] [Carbon Price Forecasting with Structural Breaks: A Comparative Study of Deep Learning Models](https://arxiv.org/abs/2511.04988)
*Runsheng Ren,Jing Li,Yanxiu Li,Shixun Huang,Jun Shen,Wanqing Li,John Le,Sheng Wang*

Main category: cs.LG

TL;DR: 本文提出了一种结合结构断点检测、小波去噪和深度学习模型（LSTM、GRU、TCN）的混合框架，用于提高碳价格预测精度。实验表明，PELT-WT-TCN模型在误差指标上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于政策干预和市场冲击导致碳价序列存在结构性断裂和高频噪声，传统方法在去噪与建模分离且缺乏对先进深度学习模型的系统评估，限制了预测的鲁棒性和泛化能力。

Method: 提出一个综合框架：使用Bai-Perron、ICSS和PELT算法检测结构断点，结合小波变换进行信号去噪，并引入LSTM、GRU和TCN三种先进深度学习模型进行预测，构建单变量和多变量数据集进行对比评估。

Result: 在2007–2024年欧盟碳排放配额（EUA）价格数据上的实验显示，PELT-WT-TCN模型表现最佳，相比基于LSTM的基准模型，RMSE降低22.35%，MAE降低18.63%；相比未分解的原始LSTM，RMSE降低70.55%，MAE降低74.42%。

Conclusion: 将结构感知与多尺度分解融入深度学习模型可显著提升碳价预测的准确性与可解释性，该框架对非平稳金融时间序列预测具有广泛适用价值。

Abstract: Accurately forecasting carbon prices is essential for informed energy market
decision-making, guiding sustainable energy planning, and supporting effective
decarbonization strategies. However, it remains challenging due to structural
breaks and high-frequency noise caused by frequent policy interventions and
market shocks. Existing studies, including the most recent baseline approaches,
have attempted to incorporate breakpoints but often treat denoising and
modeling as separate processes and lack systematic evaluation across advanced
deep learning architectures, limiting the robustness and the generalization
capability. To address these gaps, this paper proposes a comprehensive hybrid
framework that integrates structural break detection (Bai-Perron, ICSS, and
PELT algorithms), wavelet signal denoising, and three state-of-the-art deep
learning models (LSTM, GRU, and TCN). Using European Union Allowance (EUA) spot
prices from 2007 to 2024 and exogenous features such as energy prices and
policy indicators, the framework constructs univariate and multivariate
datasets for comparative evaluation. Experimental results demonstrate that our
proposed PELT-WT-TCN achieves the highest prediction accuracy, reducing
forecasting errors by 22.35% in RMSE and 18.63% in MAE compared to the
state-of-the-art baseline model (Breakpoints with Wavelet and LSTM), and by
70.55% in RMSE and 74.42% in MAE compared to the original LSTM without
decomposition from the same baseline study. These findings underscore the value
of integrating structural awareness and multiscale decomposition into deep
learning architectures to enhance accuracy and interpretability in carbon price
forecasting and other nonstationary financial time series.

</details>


### [155] [BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records](https://arxiv.org/abs/2511.04998)
*Daniel S. Lee,Mayra S. Haedo-Cruz,Chen Jiang,Oshin Miranda,LiRong Wang*

Main category: cs.LG

TL;DR: 提出了一种名为BiPETE的Transformer模型，用于基于电子健康记录（EHR）的单病种疾病风险预测，结合旋转位置编码和正弦位置编码建模不规则就诊时间与顺序，在抑郁症和PTSD队列中显著提升了酒精和物质使用障碍的预测性能，并通过归因方法实现了模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的EHR疾病预测模型难以有效建模不规则就诊间隔和缺乏统一结构的时间依赖性，限制了预测性能和可解释性。

Method: 提出BiPETE模型，采用旋转位置嵌入编码相对时间间隔，正弦位置嵌入保留就诊顺序，无需大规模预训练，在两个精神健康队列数据上训练以预测ASUD风险，并使用集成梯度法进行特征归因分析。

Result: 在抑郁症和PTSD队列中，AUPRC分别提升34%和50%，优于基线模型；消融实验验证了双位置编码策略的有效性；归因分析识别出炎症、血液学、代谢异常等关键临床特征及保护因素。

Conclusion: BiPETE提供了一个实用且可解释的EHR疾病风险预测框架，能有效捕捉时间动态并提升预测性能，有助于临床风险评估与干预。

Abstract: Transformer-based deep learning models have shown promise for disease risk
prediction using electronic health records(EHRs), but modeling temporal
dependencies remains a key challenge due to irregular visit intervals and lack
of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder
or BiPETE for single-disease prediction, which integrates rotary positional
embeddings to encode relative visit timing and sinusoidal embeddings to
preserve visit order. Without relying on large-scale pretraining, BiPETE is
trained on EHR data from two mental health cohorts-depressive disorder and
post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and
substance use disorders (ASUD). BiPETE outperforms baseline models, improving
the area under the precision-recall curve (AUPRC) by 34% and 50% in the
depression and PTSD cohorts, respectively. An ablation study further confirms
the effectiveness of the dual positional encoding strategy. We apply the
Integrated Gradients method to interpret model predictions, identifying key
clinical features associated with ASUD risk and protection, such as abnormal
inflammatory, hematologic, and metabolic markers, as well as specific
medications and comorbidities. Overall, these key clinical features identified
by the attribution methods contribute to a deeper understanding of the risk
assessment process and offer valuable clues for mitigating potential risks. In
summary, our study presents a practical and interpretable framework for disease
risk prediction using EHR data, which can achieve strong performance.

</details>


### [156] [OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data](https://arxiv.org/abs/2511.05028)
*Dongjin Park,Hasung Yeo,Joon-Woo Lee*

Main category: cs.LG

TL;DR: OvA-LP是一种新型联邦微调框架，通过在PEFT范式内从源头抑制局部漂移，显著提升非独立同分布数据下的模型鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有联邦微调方法在极端非IID条件下因事后纠正局部漂移而表现脆弱，缺乏从源头抑制漂移的机制。

Method: 提出OvA-LP框架，结合冻结编码器的线性探测、一对多分类头和两阶段流程，保持预训练特征几何结构并解耦 logits 以防止漂移放大。

Result: 在CIFAR-100上，OvA-LP在多种非IID划分下保持95.9%的IID准确率，远超PFPT（10.1%）和FFT-MoE（34.5%），且对称和非对称标签噪声下均具鲁棒性，同时预计算特征使每轮成本几乎与编码器大小无关。

Conclusion: OvA-LP为异构环境下的联邦微调提供了一个原理清晰且高效的解决方案。

Abstract: Federated fine-tuning (FFT) adapts foundation models to decentralized data
but remains fragile under heterogeneous client distributions due to local
drift, i.e., client-level update divergences that induce systematic bias and
amplified variance in the global model. Existing aggregation and
personalization methods largely correct drift post hoc, which proves brittle
under extreme non-IID conditions. We introduce OvA-LP, a minimalist framework
that is, to our knowledge, the first explicitly designed to suppress drift at
its source within the PEFT-based FFT paradigm. OvA-LP combines linear probing
on a frozen encoder with a one-vs-all head and a simple two-stage procedure,
preserving pretrained feature geometry and decoupling logits to prevent the
mechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over
shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of
its IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%
(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains
resilience under both symmetric and asymmetric label noise. In addition,
precomputing encoder features makes per-round cost nearly independent of
encoder size. Together, these results demonstrate that OvA-LP provides a
principled and efficient basis for robust FFT under heterogeneity.

</details>


### [157] [Usando LLMs para Programar Jogos de Tabuleiro e Variações](https://arxiv.org/abs/2511.05114)
*Álvaro Guglielmin Becker,Lana Bertoldo Rossato,Anderson Rocha Tavares*

Main category: cs.LG

TL;DR: 提出了一种方法来测试三种大语言模型（Claude、DeepSeek 和 ChatGPT）在生成棋盘游戏及其新变体代码方面的能力。


<details>
  <summary>Details</summary>
Motivation: 创建表示棋盘游戏的程序可能耗时，而大语言模型能够根据简单上下文信息高效生成代码，因此探索其在此任务中的能力具有重要意义。

Method: 通过评估 Claude、DeepSeek 和 ChatGPT 在生成棋盘游戏及新变体代码方面的表现，测试它们的能力。

Result: 比较了三种大语言模型在生成棋盘游戏代码任务中的性能和效果。

Conclusion: 该研究揭示了不同大语言模型在自动化生成棋盘游戏代码方面的潜力与局限性。

Abstract: Creating programs to represent board games can be a time-consuming task.
Large Language Models (LLMs) arise as appealing tools to expedite this process,
given their capacity to efficiently generate code from simple contextual
information. In this work, we propose a method to test how capable three LLMs
(Claude, DeepSeek and ChatGPT) are at creating code for board games, as well as
new variants of existing games.

</details>


### [158] [QuAnTS: Question Answering on Time Series](https://arxiv.org/abs/2511.05124)
*Felix Divo,Maurice Kraus,Anh Q. Nguyen,Hao Xue,Imran Razzak,Flora D. Salim,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.LG

TL;DR: 本文提出了一个名为QuAnTS的新型时间序列问答（TSQA）数据集，旨在通过文本问答增强对时间序列数据（特别是人体运动骨架轨迹）的理解与交互，填补现有研究在时间序列问答上的空白。


<details>
  <summary>Details</summary>
Motivation: 现有问答研究主要集中在视觉和文本领域，时间序列数据的问答关注较少，缺乏具有挑战性的基准数据集，限制了时间序列模型在可访问性和决策支持方面的发展。

Method: 构建了一个大规模、多样化的人体运动骨架轨迹时间序列问答数据集QuAnTS，设计多种类型的问题与答案，并通过实验验证数据集的质量；同时评估了现有及新提出的基线模型，并提供人类表现作为性能参考。

Result: QuAnTS数据集被验证为结构良好且全面，基线模型评估揭示了当前方法的局限性，人类表现提供了实用性的衡量基准，为TSQA研究奠定了基础。

Conclusion: QuAnTS为时间序列问答提供了有价值的基准，推动了通过自然语言与时间序列模型交互的研究方向，有助于提升模型可解释性与决策支持能力。

Abstract: Text offers intuitive access to information. This can, in particular,
complement the density of numerical time series, thereby allowing improved
interactions with time series models to enhance accessibility and
decision-making. While the creation of question-answering datasets and models
has recently seen remarkable growth, most research focuses on question
answering (QA) on vision and text, with time series receiving minute attention.
To bridge this gap, we propose a challenging novel time series QA (TSQA)
dataset, QuAnTS, for Question Answering on Time Series data. Specifically, we
pose a wide variety of questions and answers about human motion in the form of
tracked skeleton trajectories. We verify that the large-scale QuAnTS dataset is
well-formed and comprehensive through extensive experiments. Thoroughly
evaluating existing and newly proposed baselines then lays the groundwork for a
deeper exploration of TSQA using QuAnTS. Additionally, we provide human
performances as a key reference for gauging the practical usability of such
models. We hope to encourage future research on interacting with time series
models through text, enabling better decision-making and more transparent
systems.

</details>


### [159] [DL101 Neural Network Outputs and Loss Functions](https://arxiv.org/abs/2511.05131)
*Fernando Berzal*

Main category: cs.LG

TL;DR: 本文探讨了神经网络输出层激活函数与损失函数的统计学基础，指出选择特定损失函数等价于假设模型输出服从某种概率分布，并通过最大似然估计将常见损失函数（如MSE、MAE、交叉熵）与广义线性模型联系起来。


<details>
  <summary>Details</summary>
Motivation: 理解损失函数与输出层激活函数之间的统计关系，为深度学习模型的设计提供理论依据。

Method: 分析常见的输出层激活函数（线性、sigmoid、ReLU、softmax）及其数学性质，结合最大似然估计原理，建立损失函数与概率分布之间的对应关系，并联系广义线性模型进行解释。

Result: 明确了不同损失函数背后隐含的概率分布假设，揭示了损失函数与激活函数在统计上的内在联系，扩展到重尾分布、约束输出等实际场景。

Conclusion: 选择合适的损失函数应基于对输出变量概率分布的合理假设，该统计视角有助于更好地设计和理解神经网络输出层结构。

Abstract: The loss function used to train a neural network is strongly connected to its
output layer from a statistical point of view. This technical report analyzes
common activation functions for a neural network output layer, like linear,
sigmoid, ReLU, and softmax, detailing their mathematical properties and their
appropriate use cases. A strong statistical justification exists for the
selection of the suitable loss function for training a deep learning model.
This report connects common loss functions such as Mean Squared Error (MSE),
Mean Absolute Error (MAE), and various Cross-Entropy losses to the statistical
principle of Maximum Likelihood Estimation (MLE). Choosing a specific loss
function is equivalent to assuming a specific probability distribution for the
model output, highlighting the link between these functions and the Generalized
Linear Models (GLMs) that underlie network output layers. Additional scenarios
of practical interest are also considered, such as alternative output
encodings, constrained outputs, and distributions with heavy tails.

</details>


### [160] [Consecutive Preferential Bayesian Optimization](https://arxiv.org/abs/2511.05163)
*Aras Erarslan,Carlos Sevilla Salcedo,Ville Tanskanen,Anni Nisov,Eero Päiväkumpu,Heikki Aisala,Kaisu Honkapää,Arto Klami,Petrus Mikkola*

Main category: cs.LG

TL;DR: 提出了一种考虑生成和评估成本的连续偏好贝叶斯优化方法，结合感知模糊性建模，提升了高成本或存在 indifference 反馈场景下的优化精度。


<details>
  <summary>Details</summary>
Motivation: 传统偏好贝叶斯优化忽略了候选解生成的成本，且未考虑人类专家反馈中的感知模糊性，限制了在实际应用中的效率和准确性。

Method: 提出了Consecutive Preferential Bayesian Optimization，通过限制比较仅涉及先前生成的候选解来降低生成成本，并引入Just-Noticeable Difference阈值到概率偏好模型中以捕捉小效用差异的无感性；采用信息论获取策略选择最具信息量的新配置。

Result: 实验表明，在高生成成本或存在 indifference 反馈的情况下，该方法显著提高了优化的准确性。

Conclusion: 所提出的方法有效平衡了生成与评估成本，并通过建模人类感知局限性提升了偏好优化的实用性与性能。

Abstract: Preferential Bayesian optimization allows optimization of objectives that are
either expensive or difficult to measure directly, by relying on a minimal
number of comparative evaluations done by a human expert. Generating candidate
solutions for evaluation is also often expensive, but this cost is ignored by
existing methods. We generalize preference-based optimization to explicitly
account for production and evaluation costs with Consecutive Preferential
Bayesian Optimization, reducing production cost by constraining comparisons to
involve previously generated candidates. We also account for the perceptual
ambiguity of the oracle providing the feedback by incorporating a
Just-Noticeable Difference threshold into a probabilistic preference model to
capture indifference to small utility differences. We adapt an
information-theoretic acquisition strategy to this setting, selecting new
configurations that are most informative about the unknown optimum under a
preference model accounting for the perceptual ambiguity. We empirically
demonstrate a notable increase in accuracy in setups with high production costs
or with indifference feedback.

</details>


### [161] [Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy](https://arxiv.org/abs/2511.05169)
*Simon Baur,Tristan Ruhwedel,Ekin Böke,Zuzanna Kobus,Gergana Lishkova,Christoph Wetz,Holger Amthauer,Christoph Roderburg,Frank Tacke,Julian M. Rogasch,Wojciech Samek,Henning Jann,Jackie Ma,Johannes Eschrich*

Main category: cs.LG

TL;DR: 该研究评估了实验室指标、影像学和多模态深度学习模型在预测接受PRRT治疗的转移性神经内分泌肿瘤患者无进展生存期（PFS）中的表现，发现结合SR-PET、CT和实验室标志物的多模态融合模型性能最优（AUROC 0.72），优于单模态方法，未来经外部验证后可助力个体化随访策略制定。


<details>
  <summary>Details</summary>
Motivation: 预测PRRT治疗后患者的PFS有助于实现个体化治疗规划，但现有预测能力有限，因此需要探索更有效的多模态预测模型。

Method: 回顾性纳入116例接受177Lu-DOTATOC治疗的转移性NET患者，收集临床特征、实验室指标和治疗前SR-PET/CT图像；构建七种机器学习模型（包括基于实验室、SR-PET或CT的单模态及多模态融合模型）用于区分高低PFS组，并通过特征重要性分析和梯度图评估可解释性。

Result: 42例（36%）患者PFS较短（<1年），74例较长（>1年）。短PFS组基线嗜铬粒蛋白A更高（p=0.003）、γ-GT升高（p=0.002）且接受PRRT周期较少（p<0.001）。仅使用实验室标志物的随机森林模型AUROC为0.59±0.02，SR-PET和CT的3D CNN模型表现更差（AUROC分别为0.42±0.03和0.54±0.01），而结合实验室、SR-PET和CT并引入预训练CT分支的多模态融合模型表现最佳（AUROC 0.72±0.01，AUPRC 0.80±0.01）。

Conclusion: 多模态深度学习模型整合SR-PET、CT和实验室生物标志物在预测PRRT后PFS方面优于单模态方法，具有临床应用潜力，需进一步外部验证以支持风险适应性随访策略。

Abstract: Peptide receptor radionuclide therapy (PRRT) is an established treatment for
metastatic neuroendocrine tumors (NETs), yet long-term disease control occurs
only in a subset of patients. Predicting progression-free survival (PFS) could
support individualized treatment planning. This study evaluates laboratory,
imaging, and multimodal deep learning models for PFS prediction in PRRT-treated
patients. In this retrospective, single-center study 116 patients with
metastatic NETs undergoing 177Lu-DOTATOC were included. Clinical
characteristics, laboratory values, and pretherapeutic somatostatin receptor
positron emission tomography/computed tomographies (SR-PET/CT) were collected.
Seven models were trained to classify low- vs. high-PFS groups, including
unimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches.
Explainability was evaluated by feature importance analysis and gradient maps.
Forty-two patients (36%) had short PFS (< 1 year), 74 patients long PFS (>1
year). Groups were similar in most characteristics, except for higher baseline
chromogranin A (p = 0.003), elevated gamma-GT (p = 0.002), and fewer PRRT
cycles (p < 0.001) in short-PFS patients. The Random Forest model trained only
on laboratory biomarkers reached an AUROC of 0.59 +- 0.02. Unimodal
three-dimensional convolutional neural networks using SR-PET or CT performed
worse (AUROC 0.42 +- 0.03 and 0.54 +- 0.01, respectively). A multimodal fusion
model laboratory values, SR-PET, and CT -augmented with a pretrained CT branch
- achieved the best results (AUROC 0.72 +- 0.01, AUPRC 0.80 +- 0.01).
Multimodal deep learning combining SR-PET, CT, and laboratory biomarkers
outperformed unimodal approaches for PFS prediction after PRRT. Upon external
validation, such models may support risk-adapted follow-up strategies.

</details>


### [162] [Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models](https://arxiv.org/abs/2511.05171)
*Davide Marincione,Donato Crisostomi,Roberto Dessi,Emanuele Rodolà,Emanuele Rossi*

Main category: cs.LG

TL;DR: 通过合并NatureLM与其基础语言模型，恢复了指令遵循能力，并显著提升了对未见物种的零样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决NatureLM在特定领域微调后指令遵循灵活性下降的问题。

Method: 采用简单的模型融合策略，将NatureLM与其基础语言模型进行插值合并。

Result: 合并后的模型在请求同时输出通用名和科学名时准确率显著提升，并在未见物种的闭集零样本分类任务中实现了超过200%的相对性能提升，达到新的最先进水平。

Conclusion: 模型融合策略有效平衡了领域专业知识与指令遵循能力，显著增强了跨物种零样本泛化性能。

Abstract: Foundation models capable of generalizing across species and tasks represent
a promising new frontier in bioacoustics, with NatureLM being one of the most
prominent examples. While its domain-specific fine-tuning yields strong
performance on bioacoustic benchmarks, we observe that it also introduces
trade-offs in instruction-following flexibility. For instance, NatureLM
achieves high accuracy when prompted for either the common or scientific name
individually, but its accuracy drops significantly when both are requested in a
single prompt. We address this by applying a simple model merging strategy that
interpolates NatureLM with its base language model, recovering
instruction-following capabilities with minimal loss of domain expertise.
Finally, we show that the merged model exhibits markedly stronger zero-shot
generalization, achieving over a 200% relative improvement and setting a new
state-of-the-art in closed-set zero-shot classification of unseen species.

</details>


### [163] [Associative Poisoning to Generative Machine Learning](https://arxiv.org/abs/2511.05177)
*Mathias Lundteigen Mohus,Jingyue Li,Zhirong Yang*

Main category: cs.LG

TL;DR: 提出一种新型数据投毒技术——关联投毒，通过仅扰动训练数据来操控生成输出中特定特征对的统计关联，无需控制训练过程。


<details>
  <summary>Details</summary>
Motivation: 现有投毒攻击通常导致生成数据广泛退化或需控制训练过程，限制了实际应用。因此需要一种更隐蔽且精细的攻击方法。

Method: 提出关联投毒技术，形式化建模攻击过程并证明其可行性和隐蔽性，仅通过修改训练数据操纵特征间的统计关联。

Result: 在两个最先进的生成模型上验证，该方法能有效诱导或抑制特征关联，保持目标特征的边缘分布和生成质量，难以被视觉检测发现。

Conclusion: 生成系统易受此类细微、隐蔽的操纵影响，损害其统计完整性；现有防御手段存在局限，需新的应对策略。

Abstract: The widespread adoption of generative models such as Stable Diffusion and
ChatGPT has made them increasingly attractive targets for malicious
exploitation, particularly through data poisoning. Existing poisoning attacks
compromising synthesised data typically either cause broad degradation of
generated data or require control over the training process, limiting their
applicability in real-world scenarios. In this paper, we introduce a novel data
poisoning technique called associative poisoning, which compromises
fine-grained features of the generated data without requiring control of the
training process. This attack perturbs only the training data to manipulate
statistical associations between specific feature pairs in the generated
outputs. We provide a formal mathematical formulation of the attack and prove
its theoretical feasibility and stealthiness. Empirical evaluations using two
state-of-the-art generative models demonstrate that associative poisoning
effectively induces or suppresses feature associations while preserving the
marginal distributions of the targeted features and maintaining high-quality
outputs, thereby evading visual detection. These results suggest that
generative systems used in image synthesis, synthetic dataset generation, and
natural language processing are susceptible to subtle, stealthy manipulations
that compromise their statistical integrity. To address this risk, we examine
the limitations of existing defensive strategies and propose a novel
countermeasure strategy.

</details>


### [164] [APP: Accelerated Path Patching with Task-Specific Pruning](https://arxiv.org/abs/2511.05442)
*Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff*

Main category: cs.LG

TL;DR: 提出加速路径补丁（APP）方法，结合对比注意力头剪枝以减少电路发现的搜索空间，显著提升效率并保持电路性能。


<details>
  <summary>Details</summary>
Motivation: 现有电路发现方法如Path Patching计算成本高，对小模型的深入分析有限，需更高效的方法。

Method: 提出Contrastive-FLAP剪枝算法，利用因果中介分析识别任务相关注意力头；先用Contrastive-FLAP缩小搜索空间，再在剩余头上应用传统Path Patching。

Result: APP平均减少56%搜索空间，相比全模型Path Patching提速59.63%-93.27%，且发现的电路与原有方法高度重叠且性能相近。

Conclusion: APP显著加速电路发现过程，同时保持结果的有效性和可解释性，适用于高效机械性可解释性分析。

Abstract: Circuit discovery is a key step in many mechanistic interpretability
pipelines. Current methods, such as Path Patching, are computationally
expensive and have limited in-depth circuit analysis for smaller models. In
this study, we propose Accelerated Path Patching (APP), a hybrid approach
leveraging our novel contrastive attention head pruning method to drastically
reduce the search space of circuit discovery methods. Our Contrastive-FLAP
pruning algorithm uses techniques from causal mediation analysis to assign
higher pruning scores to task-specific attention heads, leading to higher
performing sparse models compared to traditional pruning techniques. Although
Contrastive-FLAP is successful at preserving task-specific heads that existing
pruning algorithms remove at low sparsity ratios, the circuits found by
Contrastive-FLAP alone are too large to satisfy the minimality constraint
required in circuit analysis. APP first applies Contrastive-FLAP to reduce the
search space on required for circuit discovery algorithms by, on average, 56\%.
Next, APP, applies traditional Path Patching on the remaining attention heads,
leading to a speed up of 59.63\%-93.27\% compared to Path Patching applied to
the dense model. Despite the substantial computational saving that APP
provides, circuits obtained from APP exhibit substantial overlap and similar
performance to previously established Path Patching circuits

</details>


### [165] [No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models](https://arxiv.org/abs/2511.05179)
*Ragini Gupta,Naman Raina,Bo Chen,Li Chen,Claudiu Danilov,Josh Eckhardt,Keyshla Bernard,Klara Nahrstedt*

Main category: cs.LG

TL;DR: 本文研究了在不同传感器密度和采样频率下，多种时空预测模型（包括经典模型、神经网络、时空图神经网络和时间序列基础模型）在真实温度数据上的表现，发现STGNN在稀疏部署下表现良好，而TSFM（尤其是Moirai）在高频率下最优，但对空间覆盖敏感。


<details>
  <summary>Details</summary>
Motivation: 现有边缘数据优化方法忽略了采样频率和空间覆盖对下游预测模型性能的影响，本文旨在系统评估这些因素对不同类型预测模型的影响。

Method: 使用真实无线传感器网络中的温度数据，系统评估VAR、GRU、Transformer、STGNN和TSFM（Chronos Moirai, TimesFM）等模型在不同传感器密度和采样间隔下的预测性能。

Result: STGNN在传感器稀疏且采样率适中时表现最佳，利用图结构捕捉空间相关性；TSFM在高采样频率下竞争力强，但在空间覆盖减少时性能下降；多变量TSFM Moirai因能直接学习跨传感器依赖关系而整体表现最优。

Conclusion: 模型选择应结合部署密度与采样频率：STGNN适用于稀疏场景，TSFM适用于高频密集部署，Moirai展现出强大潜力，建议根据实际传感配置选择合适模型以构建高效预测系统。

Abstract: Modern IoT deployments for environmental sensing produce high volume
spatiotemporal data to support downstream tasks such as forecasting, typically
powered by machine learning models. While existing filtering and strategic
deployment techniques optimize collected data volume at the edge, they overlook
how variations in sampling frequencies and spatial coverage affect downstream
model performance. In many forecasting models, incorporating data from
additional sensors denoise predictions by providing broader spatial contexts.
This interplay between sampling frequency, spatial coverage and different
forecasting model architectures remain underexplored. This work presents a
systematic study of forecasting models - classical models (VAR), neural
networks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs),
and time series foundation models (TSFMs: Chronos Moirai, TimesFM) under
varying spatial sensor nodes density and sampling intervals using real-world
temperature data in a wireless sensor network. Our results show that STGNNs are
effective when sensor deployments are sparse and sampling rate is moderate,
leveraging spatial correlations via encoded graph structure to compensate for
limited coverage. In contrast, TSFMs perform competitively at high frequencies
but degrade when spatial coverage from neighboring sensors is reduced.
Crucially, the multivariate TSFM Moirai outperforms all models by natively
learning cross-sensor dependencies. These findings offer actionable insights
for building efficient forecasting pipelines in spatio-temporal systems. All
code for model configurations, training, dataset, and logs are open-sourced for
reproducibility:
https://github.com/UIUC-MONET-Projects/Benchmarking-Spatiotemporal-Forecast-Models

</details>


### [166] [Linear Gradient Prediction with Control Variates](https://arxiv.org/abs/2511.05187)
*Kamil Ciosek,Nicolò Felicioni,Juan Elenter Litwin*

Main category: cs.LG

TL;DR: 提出一种使用近似预测梯度代替完整梯度的新方法，以减少神经网络训练成本，并通过控制变量技术确保更新是真实梯度的无偏估计。


<details>
  <summary>Details</summary>
Motivation: 减少神经网络训练中的计算成本，特别是避免昂贵的反向传播过程。

Method: 采用基于控制变量的技术生成无偏估计的近似预测梯度，并结合神经正切核理论设计梯度预测器。

Result: 在视觉Transformer分类任务中验证了该方法的有效性。

Conclusion: 该方法能有效降低训练成本，同时保持梯度更新的准确性。

Abstract: We propose a new way of training neural networks, with the goal of reducing
training cost. Our method uses approximate predicted gradients instead of the
full gradients that require an expensive backward pass. We derive a
control-variate-based technique that ensures our updates are unbiased estimates
of the true gradient. Moreover, we propose a novel way to derive a predictor
for the gradient inspired by the theory of the Neural Tangent Kernel. We
empirically show the efficacy of the technique on a vision transformer
classification task.

</details>


### [167] [ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy](https://arxiv.org/abs/2511.05221)
*David Bertram,Anja Ophey,Sinah Röttgen,Konstantin Kuffer,Gereon R. Fink,Elke Kalbe,Clint Hansen,Walter Maetzler,Maximilian Kapsecker,Lara M. Reimer,Stephan Jonas,Andreas T. Damgaard,Natasha B. Bertelsen,Casper Skjaerbaek,Per Borghammer,Karolien Groenewald,Pietro-Luca Ratti,Michele T. Hu,Noémie Moreau,Michael Sommerauer,Katarzyna Bozek*

Main category: cs.LG

TL;DR: 本研究开发了一款名为ActiTect的开源、全自动机器学习工具，用于从腕部活动记录仪数据中识别孤立性快速眼动睡眠行为障碍（iRBD），在多中心数据上表现出色且具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: iRBD是α-突触核蛋白病的重要前驱标志物，早期检测有助于神经退行性疾病的预测；然而，缺乏高效分析腕部活动数据的工具限制了大规模筛查的应用。

Method: 提出ActiTect，包含鲁棒的预处理、自动睡眠-觉醒检测和生理可解释的运动特征提取，并基于多中心数据训练机器学习模型，采用嵌套交叉验证和跨数据集外部验证评估性能。

Result: 在内部队列中AUROC达0.95，在三个独立外部队列中分别为0.86、0.84和0.94；留一数据集交叉验证显示AUROC为0.84–0.89，关键特征具有跨数据集稳定性。

Conclusion: ActiTect是一种可泛化、稳健且易于部署的开源工具，有望推动基于可穿戴设备的iRBD统一检测模型的发展。

Abstract: Isolated rapid eye movement sleep behavior disorder (iRBD) is a major
prodromal marker of $\alpha$-synucleinopathies, often preceding the clinical
onset of Parkinson's disease, dementia with Lewy bodies, or multiple system
atrophy. While wrist-worn actimeters hold significant potential for detecting
RBD in large-scale screening efforts by capturing abnormal nocturnal movements,
they become inoperable without a reliable and efficient analysis pipeline. This
study presents ActiTect, a fully automated, open-source machine learning tool
to identify RBD from actigraphy recordings. To ensure generalizability across
heterogeneous acquisition settings, our pipeline includes robust preprocessing
and automated sleep-wake detection to harmonize multi-device data and extract
physiologically interpretable motion features characterizing activity patterns.
Model development was conducted on a cohort of 78 individuals, yielding strong
discrimination under nested cross-validation (AUROC = 0.95). Generalization was
confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two
independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To
assess real-world robustness, leave-one-dataset-out cross-validation across the
internal and external cohorts demonstrated consistent performance (AUROC range
= 0.84-0.89). A complementary stability analysis showed that key predictive
features remained reproducible across datasets, supporting the final pooled
multi-center model as a robust pre-trained resource for broader deployment. By
being open-source and easy to use, our tool promotes widespread adoption and
facilitates independent validation and collaborative improvements, thereby
advancing the field toward a unified and generalizable RBD detection model
using wearable devices.

</details>


### [168] [The Causal Round Trip: Generating Authentic Counterfactuals by Eliminating Information Loss](https://arxiv.org/abs/2511.05236)
*Rui Wu,Lizheng Wang,Yongjun Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的扩散模型框架BELM-MDCM，通过因果信息守恒原则解决结构因果模型中因信息丢失导致的反事实推理不准确问题，实现了高保真个体级反事实推断。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在用于结构因果模型的反事实推理时，由于设计上侧重感知生成而非逻辑推断，导致潜变量推断存在信息丢失（即结构重建误差SRE），难以实现精确的因果推断。

Method: 提出因果信息守恒（CIC）原则作为忠实反事实推断的必要条件，并构建了首个分析可逆、消除SRE的扩散模型框架BELM-MDCM；采用目标建模策略进行结构正则化，结合混合训练目标以增强因果归纳偏置。

Result: 实验表明，该零-SRE框架在反事实准确性上达到最先进水平，能够实现高保真的个体级反事实推理。

Conclusion: 本工作建立了现代生成模型与经典因果理论之间的桥梁，为基于生成模型的因果推断提供了坚实基础和更严格的标准。

Abstract: Judea Pearl's vision of Structural Causal Models (SCMs) as engines for
counterfactual reasoning hinges on faithful abduction: the precise inference of
latent exogenous noise. For decades, operationalizing this step for complex,
non-linear mechanisms has remained a significant computational challenge. The
advent of diffusion models, powerful universal function approximators, offers a
promising solution. However, we argue that their standard design, optimized for
perceptual generation over logical inference, introduces a fundamental flaw for
this classical problem: an inherent information loss we term the Structural
Reconstruction Error (SRE). To address this challenge, we formalize the
principle of Causal Information Conservation (CIC) as the necessary condition
for faithful abduction. We then introduce BELM-MDCM, the first diffusion-based
framework engineered to be causally sound by eliminating SRE by construction
through an analytically invertible mechanism. To operationalize this framework,
a Targeted Modeling strategy provides structural regularization, while a Hybrid
Training Objective instills a strong causal inductive bias. Rigorous
experiments demonstrate that our Zero-SRE framework not only achieves
state-of-the-art accuracy but, more importantly, enables the high-fidelity,
individual-level counterfactuals required for deep causal inquiries. Our work
provides a foundational blueprint that reconciles the power of modern
generative models with the rigor of classical causal theory, establishing a new
and more rigorous standard for this emerging field.

</details>


### [169] [An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones](https://arxiv.org/abs/2511.05265)
*Taihelong Zeng,Yun Lin,Yuhe Shi,Yan Li,Zhiqing Wei,Xuanru Ji*

Main category: cs.LG

TL;DR: 本文提出了一种基于分层Actor-Critic深度强化学习框架的TSP-D求解方法，结合稀疏注意力机制与门控单元，在计算效率和训练速度上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 无人机与卡车协同配送中的TSP-D问题具有NP难特性，传统优化方法难以高效求解，需借助深度强化学习实现自适应决策。

Method: 采用Transformer-inspired编码器与Minimal Gated Unit解码器组成的分层架构，引入k近邻稀疏注意力机制并融合全局节点特征，在异步优势Actor-Critic框架下进行训练。

Result: 在N=10至100的基准实例上，模型在更短计算时间内获得优于或相当的解，且训练时间显著减少，性能更优。

Conclusion: 所提框架在求解TSP-D问题上兼具高效性与可扩展性，显著提升了深度强化学习方法的训练与推理效率。

Abstract: The emergence of truck-drone collaborative systems in last-mile logistics has
positioned the Traveling Salesman Problem with Drones (TSP-D) as a pivotal
extension of classical routing optimization, where synchronized vehicle
coordination promises substantial operational efficiency and reduced
environmental impact, yet introduces NP-hard combinatorial complexity beyond
the reach of conventional optimization paradigms. Deep reinforcement learning
offers a theoretically grounded framework to address TSP-D's inherent
challenges through self-supervised policy learning and adaptive
decision-making. This study proposes a hierarchical Actor-Critic deep
reinforcement learning framework for solving the TSP-D problem. The
architecture consists of two primary components: a Transformer-inspired encoder
and an efficient Minimal Gated Unit decoder. The encoder incorporates a novel,
optimized k-nearest neighbors sparse attention mechanism specifically for
focusing on relevant spatial relationships, further enhanced by the integration
of global node features. The Minimal Gated Unit decoder processes these encoded
representations to efficiently generate solution sequences. The entire
framework operates within an asynchronous advantage actor-critic paradigm.
Experimental results show that, on benchmark TSP-D instances of various scales
(N=10 to 100), the proposed model can obtain competitive or even superior
solutions in shorter average computation times compared to high-performance
heuristic algorithms and existing reinforcement learning methods. Moreover,
compared to advanced reinforcement learning algorithm benchmarks, the proposed
framework significantly reduces the total training time required while
achieving superior final performance, highlighting its notable advantage in
training efficiency.

</details>


### [170] [Integrating Score-Based Diffusion Models with Machine Learning-Enhanced Localization for Advanced Data Assimilation in Geological Carbon Storage](https://arxiv.org/abs/2511.05266)
*Gabriel Serrão Seabra,Nikolaj T. Mücke,Vinicius Luiz Santos Silva,Alexandre A. Emerick,Denis Voskov,Femke Vossepoel*

Main category: cs.LG

TL;DR: 提出一种结合基于分数的扩散模型和机器学习增强局部化的数据同化框架，用于提高地质碳封存中通道化储层渗透率场的不确定性量化可靠性。


<details>
  <summary>Details</summary>
Motivation: 准确刻画地下非均质性对地质碳封存项目的安全性和有效性至关重要，传统方法在协方差估计和局部化处理上存在局限。

Method: 采用基于分数的扩散模型生成大量渗透率集合（Ns=5000），结合简单机器学习算法计算状态，构建机器学习增强的局部化框架，并集成到集合平滑器多数据同化（ESMDA）中；使用FLUVSIM生成先验渗透率场，在DARTS模拟的CO2注入场景中进行验证。

Result: 相比无局部化或传统方法，该方法在保持更显著的集合方差的同时，实现了相当的数据匹配质量，提升了协方差估计精度。

Conclusion: 所提出的机器学习增强局部化框架能有效改善地质碳封存中的数据同化效果，增强不确定性量化的可靠性，具有实际应用前景。

Abstract: Accurate characterization of subsurface heterogeneity is important for the
safe and effective implementation of geological carbon storage (GCS) projects.
This paper explores how machine learning methods can enhance data assimilation
for GCS with a framework that integrates score-based diffusion models with
machine learning-enhanced localization in channelized reservoirs during CO$_2$
injection. We employ a machine learning-enhanced localization framework that
uses large ensembles ($N_s = 5000$) with permeabilities generated by the
diffusion model and states computed by simple ML algorithms to improve
covariance estimation for the Ensemble Smoother with Multiple Data Assimilation
(ESMDA). We apply ML algorithms to a prior ensemble of channelized permeability
fields, generated with the geostatistical model FLUVSIM. Our approach is
applied on a CO$_2$ injection scenario simulated using the Delft Advanced
Research Terra Simulator (DARTS). Our ML-based localization maintains
significantly more ensemble variance than when localization is not applied,
while achieving comparable data-matching quality. This framework has practical
implications for GCS projects, helping improve the reliability of uncertainty
quantification for risk assessment.

</details>


### [171] [Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting](https://arxiv.org/abs/2511.05289)
*Marius Fracarolli,Michael Staniek,Stefan Riezler*

Main category: cs.LG

TL;DR: 本研究探讨了通过数据增强方法（如ZOO、ZOO-PCA和MixUp）提升时间序列预测模型在电子健康记录中的隐私保护能力，特别是抵御成员推断攻击，同时保持预测性能。实验表明ZOO-PCA在降低攻击成功率的同时不牺牲模型准确性。


<details>
  <summary>Details</summary>
Motivation: 在电子健康记录的时间序列预测中，需兼顾强隐私保护与高预测性能，而成员推断攻击威胁模型隐私，因此需要有效防御手段。

Method: 采用多种数据增强策略（包括ZOO、ZOO-PCA和MixUp），通过合成数据重训练模型，以混淆攻击者并提升泛化能力，评估其对损失基成员推断攻击的防御效果。

Result: ZOO-PCA策略在显著降低成员推断攻击的真阳性/假阳性比率方面表现最佳，且未牺牲模型在测试数据上的预测性能。

Conclusion: 基于合成数据增强，特别是ZOO-PCA方法，能有效提升时间序列预测模型的隐私防护能力，同时保持高预测准确性，具有实际应用潜力。

Abstract: Balancing strong privacy guarantees with high predictive performance is
critical for time series forecasting (TSF) tasks involving Electronic Health
Records (EHR). In this study, we explore how data augmentation can mitigate
Membership Inference Attacks (MIA) on TSF models. We show that retraining with
synthetic data can substantially reduce the effectiveness of loss-based MIAs by
reducing the attacker's true-positive to false-positive ratio. The key
challenge is generating synthetic samples that closely resemble the original
training data to confuse the attacker, while also introducing enough novelty to
enhance the model's ability to generalize to unseen data. We examine multiple
augmentation strategies - Zeroth-Order Optimization (ZOO), a variant of ZOO
constrained by Principal Component Analysis (ZOO-PCA), and MixUp - to
strengthen model resilience without sacrificing accuracy. Our experimental
results show that ZOO-PCA yields the best reductions in TPR/FPR ratio for MIA
attacks without sacrificing performance on test data.

</details>


### [172] [Attention and Compression is all you need for Controllably Efficient Language Models](https://arxiv.org/abs/2511.05313)
*Jatin Prakash,Aahlad Puli,Rajesh Ranganath*

Main category: cs.LG

TL;DR: 本文提出了Compress & Attend Transformer (CAT)，通过结合密集注意力和压缩机制，在保持高质量的同时显著降低计算和内存开销，并支持测试时灵活调整质量-计算权衡。


<details>
  <summary>Details</summary>
Motivation: Transformer中的二次注意力成本促使研究高效方法，但现有方法常以牺牲质量（如上下文回忆能力）为代价，且需预先固定权衡，缺乏灵活性。不同下游任务对内存和延迟的需求各异，需要更自适应的解决方案。

Method: CAT采用两个核心组件：密集注意力和压缩。模型将输入分块处理，解码当前块时仅关注先前块的压缩表示。通过调整块大小来控制质量与效率的权衡，并可在训练时使用多种块大小，实现单个模型在测试时动态适应不同计算资源。

Result: 在语言建模、上下文回忆和长文本理解任务中，单一自适应CAT模型在不同计算-内存预算下优于现有的高效基线模型（包括混合架构）。CAT在语言建模上表现与密集Transformer相当，但速度快1.4-3倍，总内存消耗低2-9倍。

Conclusion: CAT提供了一种概念简单且高效的替代方案，通过压缩历史序列实现计算和内存节省，同时保持强大的建模性能，并支持测试时灵活调节质量-计算权衡，适用于多样化的应用场景。

Abstract: The quadratic cost of attention in transformers motivated the development of
efficient approaches: namely sparse and sliding window attention, convolutions
and linear attention. Although these approaches result in impressive reductions
in compute and memory, they often trade-off with quality, specifically
in-context recall performance. Moreover, apriori fixing this quality-compute
tradeoff means being suboptimal from the get-go: some downstream applications
require more memory for in-context recall, while others require lower latency
and memory. Further, these approaches rely on heuristic choices that
artificially restrict attention, or require handcrafted and complex recurrent
state update rules, or they must be carefully composed with attention at
specific layers to form a hybrid architecture that complicates the design
process, especially at scale. To address above issues, we propose Compress &
Attend Transformer (CAT), a conceptually simple architecture employing two
simple ingredients only: dense attention and compression. CAT decodes chunks of
tokens by attending to compressed chunks of the sequence so far. Compression
results in decoding from a reduced sequence length that yields compute and
memory savings, while choosing a particular chunk size trades-off quality for
efficiency. Moreover, CAT can be trained with multiple chunk sizes at once,
unlocking control of quality-compute trade-offs directly at test-time without
any retraining, all in a single adaptive architecture. In exhaustive
evaluations on common language modeling tasks, in-context recall, and
long-context understanding, a single adaptive CAT model outperforms existing
efficient baselines, including hybrid architectures, across different
compute-memory budgets. Further, a single CAT matches dense transformer in
language modeling across model scales while being 1.4-3x faster and requiring
2-9x lower total memory usage.

</details>


### [173] [Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval](https://arxiv.org/abs/2511.05325)
*Janet Jenq,Hongda Shen*

Main category: cs.LG

TL;DR: 提出一种新方法，通过将商品文本信息渲染到图像上来增强图文对齐，提升电商多模态检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型易受图像中误导性文字影响（如字体攻击），导致检索不准确，需提高图文一致性以改善搜索相关性和用户体验。

Method: 将商品标题、描述等文本信息直接渲染到产品图像上，利用视觉方式实现图文压缩，强化图像与文本的对齐。

Result: 在三个垂直电商数据集（运动鞋、手袋、交易卡）和六种先进视觉基础模型上验证，该方法在单模态和多模态检索准确率上均有稳定提升。

Conclusion: 可视化渲染商品元数据是一种简单而有效的手段，可显著提升电商场景下的零样本多模态检索性能。

Abstract: Multimodal product retrieval systems in e-commerce platforms rely on
effectively combining visual and textual signals to improve search relevance
and user experience. However, vision-language models such as CLIP are
vulnerable to typographic attacks, where misleading or irrelevant text embedded
in images skews model predictions. In this work, we propose a novel method that
reverses the logic of typographic attacks by rendering relevant textual content
(e.g., titles, descriptions) directly onto product images to perform
vision-text compression, thereby strengthening image-text alignment and
boosting multimodal product retrieval performance. We evaluate our method on
three vertical-specific e-commerce datasets (sneakers, handbags, and trading
cards) using six state-of-the-art vision foundation models. Our experiments
demonstrate consistent improvements in unimodal and multimodal retrieval
accuracy across categories and model families. Our findings suggest that
visually rendering product metadata is a simple yet effective enhancement for
zero-shot multimodal retrieval in e-commerce applications.

</details>


### [174] [Learning Dynamics from Input-Output Data with Hamiltonian Gaussian Processes](https://arxiv.org/abs/2511.05330)
*Jan-Hendrik Ewering,Robin E. Herrmann,Niklas Wahlström,Thomas B. Schön,Thomas Seel*

Main category: cs.LG

TL;DR: 提出一种基于非保守哈密顿高斯过程的动力学学习方法，利用输入-输出数据进行学习，并通过贝叶斯方法估计隐藏状态、超参数及结构参数的概率密度，在无需动量测量的情况下实现物理一致性建模。


<details>
  <summary>Details</summary>
Motivation: 将能量守恒等先验知识嵌入学习模型中，以在数据有限的情况下构建符合物理规律的模型，尤其适用于基于模型的控制；现有方法依赖难以获取的速度或动量数据，限制了实际应用。

Method: 采用非保守哈密顿高斯过程框架，结合全贝叶斯推断估计隐藏状态和各类超参数（包括阻尼系数）的后验分布，并使用低秩高斯过程近似以降低计算复杂度，提升训练与预测效率。

Result: 在非线性仿真案例中验证了该方法的有效性，能够在仅使用输入-输出数据的情况下实现准确的动力学建模，并优于依赖动量测量的先进方法。

Conclusion: 所提方法在不依赖动量观测的前提下，实现了物理一致且具备不确定性量化的动力学建模，具有更强的实用性与计算效率，适用于现实场景中的系统辨识与控制应用。

Abstract: Embedding non-restrictive prior knowledge, such as energy conservation laws,
in learning-based approaches is a key motive to construct physically consistent
models from limited data, relevant for, e.g., model-based control. Recent work
incorporates Hamiltonian dynamics into Gaussian Process (GP) regression to
obtain uncertainty-quantifying models that adhere to the underlying physical
principles. However, these works rely on velocity or momentum data, which is
rarely available in practice. In this paper, we consider dynamics learning with
non-conservative Hamiltonian GPs, and address the more realistic problem
setting of learning from input-output data. We provide a fully Bayesian scheme
for estimating probability densities of unknown hidden states, of GP
hyperparameters, as well as of structural hyperparameters, such as damping
coefficients. Considering the computational complexity of GPs, we take
advantage of a reduced-rank GP approximation and leverage its properties for
computationally efficient prediction and training. The proposed method is
evaluated in a nonlinear simulation case study and compared to a
state-of-the-art approach that relies on momentum measurements.

</details>


### [175] [Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media](https://arxiv.org/abs/2511.05357)
*Mikhail Tsukerman,Konstantin Grotov,Pavel Ginzburg*

Main category: cs.LG

TL;DR: 提出一种基于条件扩散模型的电磁逆设计方法，通过1D U-Net架构直接从目标散射谱生成介质结构，显著提升设计效率与性能。


<details>
  <summary>Details</summary>
Motivation: 传统电磁逆设计依赖耗时的迭代优化，难以高效生成满足特定散射特性的结构，亟需快速且鲁棒的方法。

Method: 采用条件扩散模型，结合带特征线性调制的1D U-Net架构，学习从目标角向散射图样到2x2介电球结构的映射，并通过采样处理逆问题的非唯一性。

Result: 在11,000个模拟超表面数据上训练后，模型在未见目标上中位数MPE低于19%（最佳达1.39%），性能优于CMA-ES进化优化，设计时间从小时级缩短至秒级。

Conclusion: 扩散模型在电磁逆设计中展现出巨大潜力，可加速复杂超表面结构的探索，推动光子学与无线通信系统的发展。

Abstract: We present a conditional diffusion model for electromagnetic inverse design
that generates structured media geometries directly from target differential
scattering cross-section profiles, bypassing expensive iterative optimization.
Our 1D U-Net architecture with Feature-wise Linear Modulation learns to map
desired angular scattering patterns to 2x2 dielectric sphere structure,
naturally handling the non-uniqueness of inverse problems by sampling diverse
valid designs. Trained on 11,000 simulated metasurfaces, the model achieves
median MPE below 19% on unseen targets (best: 1.39%), outperforming CMA-ES
evolutionary optimization while reducing design time from hours to seconds.
These results demonstrate that employing diffusion models is promising for
advancing electromagnetic inverse design research, potentially enabling rapid
exploration of complex metasurface architectures and accelerating the
development of next-generation photonic and wireless communication systems. The
code is publicly available at
https://github.com/mikzuker/inverse_design_metasurface_generation.

</details>


### [176] [ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids](https://arxiv.org/abs/2511.05420)
*Emad Efatinasab,Nahal Azadi,Davide Dalle Pezze,Gian Antonio Susto,Chuadhry Mujeeb Ahmed,Mirco Rampazzo*

Main category: cs.LG

TL;DR: 本文提出了一种用于智能电网故障预测的持续学习框架ProDER，能够在动态环境中适应新故障类型和区域，实验表明其在四种现实场景下表现优异，准确率损失极小。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在动态变化的智能电网环境中难以可靠地预测新故障类型和区域，缺乏持续学习能力。

Method: 设计了基于类增量和域增量学习的四种评估场景，提出了结合原型特征正则化、对数蒸馏和原型引导回放记忆的统一回放方法ProDER。

Result: ProDER在故障类型预测中仅出现0.045的准确率下降，在故障区域预测中仅下降0.015，优于其他持续学习技术。

Conclusion: 持续学习框架ProDER具有实际应用价值，可支持智能电网中可扩展、面向现实的故障预测。

Abstract: As smart grids evolve to meet growing energy demands and modern operational
challenges, the ability to accurately predict faults becomes increasingly
critical. However, existing AI-based fault prediction models struggle to ensure
reliability in evolving environments where they are required to adapt to new
fault types and operational zones. In this paper, we propose a continual
learning (CL) framework in the smart grid context to evolve the model together
with the environment. We design four realistic evaluation scenarios grounded in
class-incremental and domain-incremental learning to emulate evolving grid
conditions. We further introduce Prototype-based Dark Experience Replay
(ProDER), a unified replay-based approach that integrates prototype-based
feature regularization, logit distillation, and a prototype-guided replay
memory. ProDER achieves the best performance among tested CL techniques, with
only a 0.045 accuracy drop for fault type prediction and 0.015 for fault zone
prediction. These results demonstrate the practicality of CL for scalable,
real-world fault prediction in smart grids.

</details>


### [177] [Adversarially Robust Multitask Adaptive Control](https://arxiv.org/abs/2511.05444)
*Kasra Fallah,Leonardo F. Toso,James Anderson*

Main category: cs.LG

TL;DR: 提出了一种聚类多任务方法，用于对抗性鲁棒的自适应线性二次控制，通过聚类、系统辨识和弹性聚合来减轻模型更新被破坏的影响，并建立了非渐近性遗憾界。


<details>
  <summary>Details</summary>
Motivation: 在存在模型不确定性和对抗性破坏的情况下，多个系统协同学习控制策略时面临鲁棒性和效率挑战。

Method: 结合聚类与系统辨识，采用弹性聚合机制，在多任务线性二次调节（LQR）控制中实现对抗环境下的稳健学习。

Result: 分析了聚类准确性、簇内异质性和对抗行为对期望遗憾的影响，证明了遗憾随每个簇中诚实系统的数量增加而减小，并在每个簇中存在一定比例对抗系统时仍保持该性质。

Conclusion: 所提方法在有界比例的对抗系统存在下仍能有效降低多任务LQR控制中的遗憾，具备良好的鲁棒性和可扩展性。

Abstract: We study adversarially robust multitask adaptive linear quadratic control; a
setting where multiple systems collaboratively learn control policies under
model uncertainty and adversarial corruption. We propose a clustered multitask
approach that integrates clustering and system identification with resilient
aggregation to mitigate corrupted model updates. Our analysis characterizes how
clustering accuracy, intra-cluster heterogeneity, and adversarial behavior
affect the expected regret of certainty-equivalent (CE) control across LQR
tasks. We establish non-asymptotic bounds demonstrating that the regret
decreases inversely with the number of honest systems per cluster and that this
reduction is preserved under a bounded fraction of adversarial systems within
each cluster.

</details>


### [178] [Parameter-Efficient Conditioning for Material Generalization in Graph-Based Simulators](https://arxiv.org/abs/2511.05456)
*Naveen Raj Manoharan,Hassan Iqbal,Krishna Kumar*

Main category: cs.LG

TL;DR: 提出一种参数高效的条件机制，使图网络模拟器（GNS）能适应不同材料参数，尤其在颗粒流中表现良好，仅需少量新数据即可实现对未见材料属性的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有GNS模型通常针对单一材料训练，难以跨不同本构行为泛化，限制了其在真实工程场景中的应用。希望提升模型对不同材料参数的适应能力。

Method: 基于发现材料敏感性集中在早期消息传递层，提出在前几层使用FiLM条件机制进行参数高效调节，并仅微调1-5层以适应新材料。

Result: 该方法在仅使用12条短仿真轨迹训练时，即可在未见、插值或适度外推的材料参数上实现准确的长期 rollout；相比基线方法数据需求减少5倍，并成功应用于反问题中估计未知粘聚力参数。

Conclusion: 所提出的FiLM条件机制实现了GNS在多材料场景下的高效适应，支持逆向设计与闭环控制等任务，提升了其在工程应用中的实用性。

Abstract: Graph network-based simulators (GNS) have demonstrated strong potential for
learning particle-based physics (such as fluids, deformable solids, and
granular flows) while generalizing to unseen geometries due to their inherent
inductive biases. However, existing models are typically trained for a single
material type and fail to generalize across distinct constitutive behaviors,
limiting their applicability in real-world engineering settings. Using granular
flows as a running example, we propose a parameter-efficient conditioning
mechanism that makes the GNS model adaptive to material parameters. We identify
that sensitivity to material properties is concentrated in the early
message-passing (MP) layers, a finding we link to the local nature of
constitutive models (e.g., Mohr-Coulomb) and their effects on information
propagation. We empirically validate this by showing that fine-tuning only the
first few (1-5) of 10 MP layers of a pretrained model achieves comparable test
performance as compared to fine-tuning the entire network. Building on this
insight, we propose a parameter-efficient Feature-wise Linear Modulation (FiLM)
conditioning mechanism designed to specifically target these early layers. This
approach produces accurate long-term rollouts on unseen, interpolated, or
moderately extrapolated values (e.g., up to 2.5 degrees for friction angle and
0.25 kPa for cohesion) when trained exclusively on as few as 12 short
simulation trajectories from new materials, representing a 5-fold data
reduction compared to a baseline multi-task learning method. Finally, we
validate the model's utility by applying it to an inverse problem, successfully
identifying unknown cohesion parameters from trajectory data. This approach
enables the use of GNS in inverse design and closed-loop control tasks where
material properties are treated as design variables.

</details>


### [179] [Synapse: Adaptive Arbitration of Complementary Expertise in Time Series Foundational Models](https://arxiv.org/abs/2511.05460)
*Sarkar Snigdha Sarathi Das,Palash Goyal,Mihir Parmar,Yiwen Song,Long T. Le,Lesly Miculicich,Jinsung Yoon,Rui Zhang,Hamid Palangi,Tomas Pfister*

Main category: cs.LG

TL;DR: 本文提出了一种名为Synapse的新型仲裁框架，用于整合多个时间序列基础模型（TSFMs）的预测输出。通过动态分配和调整各模型的预测权重，并基于上下文表现自适应地采样生成鲁棒预测分布，Synapse在多种预测任务中优于现有集成方法和单个模型。


<details>
  <summary>Details</summary>
Motivation: 不同TSFM因训练协议和数据来源差异，在不同预测任务中表现不一，存在性能互补性。如何有效利用这种差异进行模型仲裁仍缺乏研究。

Method: 分析不同TSFM在多种预测场景下的性能特征，研究模型选择与预测范围分布对仲裁策略的影响；提出Synapse框架，动态聚合多个TSFM，根据上下文依赖的表现分配并调整预测权重，通过自适应量化采样构建最终预测分布。

Result: 实验结果表明，Synapse在多个数据集上 consistently 优于主流集成方法和单一TSFM，展现出更强的预测性能和鲁棒性。

Conclusion: Synapse能够有效利用不同TSFM的互补优势，通过动态加权和自适应采样提升整体预测精度，为时间序列预测中的模型集成提供了一个高效且灵活的解决方案。

Abstract: Pre-trained Time Series Foundational Models (TSFMs) represent a significant
advance, capable of forecasting diverse time series with complex
characteristics, including varied seasonalities, trends, and long-range
dependencies. Despite their primary goal of universal time series forecasting,
their efficacy is far from uniform; divergent training protocols and data
sources cause individual TSFMs to exhibit highly variable performance across
different forecasting tasks, domains, and horizons. Leveraging this
complementary expertise by arbitrating existing TSFM outputs presents a
compelling strategy, yet this remains a largely unexplored area of research. In
this paper, we conduct a thorough examination of how different TSFMs exhibit
specialized performance profiles across various forecasting settings, and how
we can effectively leverage this behavior in arbitration between different time
series models. We specifically analyze how factors such as model selection and
forecast horizon distribution can influence the efficacy of arbitration
strategies. Based on this analysis, we propose Synapse, a novel arbitration
framework for TSFMs. Synapse is designed to dynamically leverage a pool of
TSFMs, assign and adjust predictive weights based on their relative,
context-dependent performance, and construct a robust forecast distribution by
adaptively sampling from the output quantiles of constituent models.
Experimental results demonstrate that Synapse consistently outperforms other
popular ensembling techniques as well as individual TSFMs, demonstrating
Synapse's efficacy in time series forecasting.

</details>


### [180] [SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning](https://arxiv.org/abs/2511.05462)
*Xiaodong Wang,Jing Huang,Kevin J Liang*

Main category: cs.LG

TL;DR: 本文提出了一种新的自监督学习模型SiamMM，通过将聚类方法与经典统计混合模型相结合，显著提升了性能，并在多个基准上达到最先进水平，同时发现学习到的聚类与真实标签高度相似，揭示了潜在的标注错误。


<details>
  <summary>Details</summary>
Motivation: 现有的基于聚类的自监督和无监督学习方法常采用启发式应用，缺乏理论指导，最优方法尚不明确，因此需要建立理论框架来改进现有方法。

Method: 通过建立聚类方法与经典统计混合模型之间的联系，提出一种新的模型SiamMM，利用该框架优化聚类过程并提升表示学习效果。

Result: SiamMM在多个自监督学习基准上取得了最先进的性能；学习到的聚类结果与未见的真实标签高度相似，并揭示出数据中可能存在的标注错误。

Conclusion: 将聚类方法与统计混合模型结合能有效提升自监督学习性能，为当前启发式的聚类方法提供了理论基础，并展示了其在发现数据标注错误方面的潜力。

Abstract: Recent studies have demonstrated the effectiveness of clustering-based
approaches for self-supervised and unsupervised learning. However, the
application of clustering is often heuristic, and the optimal methodology
remains unclear. In this work, we establish connections between these
unsupervised clustering methods and classical mixture models from statistics.
Through this framework, we demonstrate significant enhancements to these
clustering methods, leading to the development of a novel model named SiamMM.
Our method attains state-of-the-art performance across various self-supervised
learning benchmarks. Inspection of the learned clusters reveals a strong
resemblance to unseen ground truth labels, uncovering potential instances of
mislabeling.

</details>


### [181] [Precipitation nowcasting of satellite data using physically conditioned neural networks](https://arxiv.org/abs/2511.05471)
*Antônio Catão,Melvin Poveda,Leonardo Voltarelli,Paulo Orenstein*

Main category: cs.LG

TL;DR: 提出了一种仅使用卫星数据的短临降水预报模型TUPANN，通过物理对齐的深度学习方法，在多种气候条件下表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有的短临降水预报依赖密集雷达网络，在气候极端地区应用受限，因此需要一种可在无雷达地区使用的高精度预报方法。

Method: TUPANN采用卫星数据（GOES-16 RRQPE），将预报分解为物理上有意义的组件：变分编码器-解码器在光流监督下推断运动和强度场，MaxViT网络演化潜在状态，可微平流算子重建未来帧。

Result: 在Rio de Janeiro、Manaus、Miami和La Paz四种不同气候区进行评估，TUPANN在多数情况下达到最佳或次优技能，尤其在较高雨量阈值下表现突出；跨城市训练提升性能，且模型具备良好可迁移性。

Conclusion: 物理对齐的学习方法可实现高技能、可迁移且适用于全球的短临降水预报，即使在缺乏雷达的地区也具有实用价值。

Abstract: Accurate short-term precipitation forecasts predominantly rely on dense
weather-radar networks, limiting operational value in places most exposed to
climate extremes. We present TUPANN (Transferable and Universal Physics-Aligned
Nowcasting Network), a satellite-only model trained on GOES-16 RRQPE. Unlike
most deep learning models for nowcasting, TUPANN decomposes the forecast into
physically meaningful components: a variational encoder-decoder infers motion
and intensity fields from recent imagery under optical-flow supervision, a
lead-time-conditioned MaxViT evolves the latent state, and a differentiable
advection operator reconstructs future frames. We evaluate TUPANN on both
GOES-16 and IMERG data, in up to four distinct climates (Rio de Janeiro,
Manaus, Miami, La Paz) at 10-180min lead times using the CSI and HSS metrics
over 4-64 mm/h thresholds. Comparisons against optical-flow, deep learning and
hybrid baselines show that TUPANN achieves the best or second-best skill in
most settings, with pronounced gains at higher thresholds. Training on multiple
cities further improves performance, while cross-city experiments show modest
degradation and occasional gains for rare heavy-rain regimes. The model
produces smooth, interpretable motion fields aligned with numerical optical
flow and runs in near real time due to the low latency of GOES-16. These
results indicate that physically aligned learning can provide nowcasts that are
skillful, transferable and global.

</details>


### [182] [On Flow Matching KL Divergence](https://arxiv.org/abs/2511.05480)
*Maojiang Su,Jerry Yao-Chieh Hu,Sophia Pi,Han Liu*

Main category: cs.LG

TL;DR: 本文推导了流匹配分布近似下KL散度的非渐近上界，表明当L2流匹配损失被ε²限制时，真实数据分布与估计分布间的KL散度被A₁ε + A₂ε²所界，且该结果意味着在总变差距离下的统计收敛速率接近最小最大最优。


<details>
  <summary>Details</summary>
Motivation: 为了理解流匹配方法在估计数据分布时的统计效率，并建立其与扩散模型之间的理论可比性。

Method: 通过分析L2流匹配损失与KL散度之间的关系，推导出确定性的非渐近上界，并利用正则性条件控制相关常数。

Result: 得到了KL散度的上界为A₁ε + A₂ε²，进而推出在总变差距离下的收敛速率，并证明流匹配在估计光滑分布时接近最小最大最优。

Conclusion: 流匹配在统计效率上可与扩散模型相媲美，且具有明确的非渐近理论保证。

Abstract: We derive a deterministic, non-asymptotic upper bound on the Kullback-Leibler
(KL) divergence of the flow-matching distribution approximation. In particular,
if the $L_2$ flow-matching loss is bounded by $\epsilon^2 > 0$, then the KL
divergence between the true data distribution and the estimated distribution is
bounded by $A_1 \epsilon + A_2 \epsilon^2$. Here, the constants $A_1$ and $A_2$
depend only on the regularities of the data and velocity fields. Consequently,
this bound implies statistical convergence rates of Flow Matching Transformers
under the Total Variation (TV) distance. We show that, flow matching achieves
nearly minimax-optimal efficiency in estimating smooth distributions. Our
results make the statistical efficiency of flow matching comparable to that of
diffusion models under the TV distance. Numerical studies on synthetic and
learned velocities corroborate our theory.

</details>


### [183] [SoilX: Calibration-Free Comprehensive Soil Sensing Through Contrastive Cross-Component Learning](https://arxiv.org/abs/2511.05482)
*Kang Yang,Yuanlin Yang,Yuning Chen,Sikai Yang,Xinyu Zhang,Wan Du*

Main category: cs.LG

TL;DR: 本文提出了一种无需校准的土壤传感系统SoilX，可同时测量土壤中的水分、氮、磷、钾、有机碳和铝硅酸盐六种关键成分，通过引入对比跨组分学习和新型四面体天线阵列，有效消除土壤质地影响，显著降低估计误差并具备良好的跨田地泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统无线土壤传感器在测量土壤关键成分时需针对不同土壤质地频繁重新校准，限制了其实际应用。因此，需要一种无需校准、适应性强的传感系统以提升精准农业的可行性。

Method: 提出SoilX系统，通过显式建模有机碳（C）和铝硅酸盐（Al）来消除土壤质地依赖；采用对比跨组分学习（3CL），包含正交正则化项和分离损失，以解耦组分间的干扰；设计新型四面体天线阵列与天线切换机制，实现不受设备放置影响的稳定介电常数测量。

Result: 实验表明，SoilX相比基线方法将估计误差降低了23.8%至31.5%，并在未见过的农田中表现出良好的泛化能力。

Conclusion: SoilX实现了无需校准的多组分土壤感知，克服了土壤质地变化带来的挑战，为精准农业提供了更具实用性和鲁棒性的解决方案。

Abstract: Precision agriculture demands continuous and accurate monitoring of soil
moisture (M) and key macronutrients, including nitrogen (N), phosphorus (P),
and potassium (K), to optimize yields and conserve resources. Wireless soil
sensing has been explored to measure these four components; however, current
solutions require recalibration (i.e., retraining the data processing model) to
handle variations in soil texture, characterized by aluminosilicates (Al) and
organic carbon (C), limiting their practicality. To address this, we introduce
SoilX, a calibration-free soil sensing system that jointly measures six key
components: {M, N, P, K, C, Al}. By explicitly modeling C and Al, SoilX
eliminates texture- and carbon-dependent recalibration. SoilX incorporates
Contrastive Cross-Component Learning (3CL), with two customized terms: the
Orthogonality Regularizer and the Separation Loss, to effectively disentangle
cross-component interference. Additionally, we design a novel tetrahedral
antenna array with an antenna-switching mechanism, which can robustly measure
soil dielectric permittivity independent of device placement. Extensive
experiments demonstrate that SoilX reduces estimation errors by 23.8% to 31.5%
over baselines and generalizes well to unseen fields.

</details>


### [184] [DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating Mechanism for Enzyme DDG Prediction](https://arxiv.org/abs/2511.05483)
*Abigail Lin*

Main category: cs.LG

TL;DR: 本文提出了一种名为DGTN（Diffused Graph-Transformer Network）的新架构，通过扩散机制联合学习图神经网络（GNN）和Transformer注意力，以更准确地预测氨基酸突变对酶热力学稳定性的影响。该方法在ProTherm和SKEMPI基准上达到了最先进的性能，并具有理论支持的收敛性和优越性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法通常独立处理蛋白质序列和结构信息，未能充分捕捉局部结构几何与全局序列模式之间的复杂耦合关系，限制了突变效应预测的准确性。

Method: 提出DGTN模型，采用双向扩散机制：一方面用GNN提取的结构嵌入通过可学习的扩散核引导Transformer注意力；另一方面用Transformer的序列表示通过注意力调制的图更新来优化GNN的消息传递过程。

Result: 在ProTherm和SKEMPI基准测试中，DGTN达到SOTA性能（Pearson Rho = 0.87，RMSE = 1.21 kcal/mol），比最佳基线提升6.2%；消融实验表明扩散机制贡献了4.8点相关性提升；理论分析证明扩散注意力以O(1/sqrt(T))速率收敛至最优结构-序列耦合。

Conclusion: DGTN通过可学习的扩散机制实现了结构与序列信息的深度融合，为整合异构蛋白表示提供了有理论保障的新框架，显著提升了稳定性变化预测的准确性。

Abstract: Predicting the effect of amino acid mutations on enzyme thermodynamic
stability (DDG) is fundamental to protein engineering and drug design. While
recent deep learning approaches have shown promise, they often process sequence
and structure information independently, failing to capture the intricate
coupling between local structural geometry and global sequential patterns. We
present DGTN (Diffused Graph-Transformer Network), a novel architecture that
co-learns graph neural network (GNN) weights for structural priors and
transformer attention through a diffusion mechanism. Our key innovation is a
bidirectional diffusion process where: (1) GNN-derived structural embeddings
guide transformer attention via learnable diffusion kernels, and (2)
transformer representations refine GNN message passing through
attention-modulated graph updates. We provide rigorous mathematical analysis
showing this co-learning scheme achieves provably better approximation bounds
than independent processing. On ProTherm and SKEMPI benchmarks, DGTN achieves
state-of-the-art performance (Pearson Rho = 0.87, RMSE = 1.21 kcal/mol), with
6.2% improvement over best baselines. Ablation studies confirm the diffusion
mechanism contributes 4.8 points to correlation. Our theoretical analysis
proves the diffused attention converges to optimal structure-sequence coupling,
with convergence rate O(1/sqrt(T) ) where T is diffusion steps. This work
establishes a principled framework for integrating heterogeneous protein
representations through learnable diffusion.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [185] [TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems](https://arxiv.org/abs/2511.05269)
*Ishan Kavathekar,Hemang Jain,Ameya Rathod,Ponnurangam Kumaraguru,Tanuja Ganu*

Main category: cs.MA

TL;DR: 本文提出了TAMAS，一个用于评估多智能体LLM系统安全性和鲁棒性的新基准，包含五种场景、300个对抗实例和六类攻击，并引入有效鲁棒性评分（ERS）来衡量安全性与任务效能之间的权衡，揭示了当前多智能体系统在面对攻击时的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注单智能体环境，缺乏对多智能体系统中独特安全威胁的评估，因此需要构建专门针对多智能体动态和协作漏洞的评测基准。

Method: 设计了TAMAS基准，涵盖五种多智能体场景、300个对抗样本、6种攻击类型和211个工具，同时包含100个无害任务；在十个基础LLM和三种智能体交互配置上进行评估，并提出有效鲁棒性评分（ERS）来量化安全与性能的权衡。

Result: 实验表明多智能体系统在多种攻击下表现出高度脆弱性，不同LLM和框架在安全性和有效性之间存在显著差异，暴露了当前系统的关键缺陷。

Conclusion: 多智能体LLM系统面临严重安全威胁，亟需加强防御机制；TAMAS为系统化研究和提升多智能体系统安全性提供了基础平台。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities as
autonomous agents through tool use, planning, and decision-making abilities,
leading to their widespread adoption across diverse tasks. As task complexity
grows, multi-agent LLM systems are increasingly used to solve problems
collaboratively. However, safety and security of these systems remains largely
under-explored. Existing benchmarks and datasets predominantly focus on
single-agent settings, failing to capture the unique vulnerabilities of
multi-agent dynamics and co-ordination. To address this gap, we introduce
$\textbf{T}$hreats and $\textbf{A}$ttacks in $\textbf{M}$ulti-$\textbf{A}$gent
$\textbf{S}$ystems ($\textbf{TAMAS}$), a benchmark designed to evaluate the
robustness and safety of multi-agent LLM systems. TAMAS includes five distinct
scenarios comprising 300 adversarial instances across six attack types and 211
tools, along with 100 harmless tasks. We assess system performance across ten
backbone LLMs and three agent interaction configurations from Autogen and
CrewAI frameworks, highlighting critical challenges and failure modes in
current multi-agent deployments. Furthermore, we introduce Effective Robustness
Score (ERS) to assess the tradeoff between safety and task effectiveness of
these frameworks. Our findings show that multi-agent systems are highly
vulnerable to adversarial attacks, underscoring the urgent need for stronger
defenses. TAMAS provides a foundation for systematically studying and improving
the safety of multi-agent LLM systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [186] [DAFM: Dynamic Adaptive Fusion for Multi-Model Collaboration in Composed Image Retrieval](https://arxiv.org/abs/2511.05020)
*Yawei Cai,Jiapeng Mi,Nan Ji,Haotian Rong,Yawei Zhang,Zhangti Li,Wenbin Guo,Rensong Xie*

Main category: cs.GR

TL;DR: 提出动态自适应融合（DAFM）方法，通过多模型协作解决组合图像检索中的特征融合与相似性匹配问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有单模型方法难以同时捕捉图像的全局信息与细节，且缺乏动态权重分配机制，导致嵌入偏离目标，影响检索精度。

Method: 设计动态自适应融合框架（DAFM），利用异构模型的互补优势，并动态调整各模型贡献权重，实现鲁棒的多模型协同。

Result: 在CIRR和FashionIQ数据集上取得显著提升：CIRR上Recall@10达93.21，Rmean达84.43；FashionIQ上平均Rmean为67.48，优于最强基线最多4.5%。

Conclusion: 动态多模型协作能有效解决CIR中的特征融合难题，具有高准确性和顺序无关的鲁棒性，为CIR提供了通用解决方案。

Abstract: Composed Image Retrieval (CIR) is a cross-modal task that aims to retrieve
target images from large-scale databases using a reference image and a
modification text. Most existing methods rely on a single model to perform
feature fusion and similarity matching. However, this paradigm faces two major
challenges. First, one model alone can't see the whole picture and the tiny
details at the same time; it has to handle different tasks with the same
weights, so it often misses the small but important links between image and
text. Second, the absence of dynamic weight allocation prevents adaptive
leveraging of complementary model strengths, so the resulting embedding drifts
away from the target and misleads the nearest-neighbor search in CIR. To
address these limitations, we propose Dynamic Adaptive Fusion (DAFM) for
multi-model collaboration in CIR. Rather than optimizing a single method in
isolation, DAFM exploits the complementary strengths of heterogeneous models
and adaptively rebalances their contributions. This not only maximizes
retrieval accuracy but also ensures that the performance gains are independent
of the fusion order, highlighting the robustness of our approach. Experiments
on the CIRR and FashionIQ benchmarks demonstrate consistent improvements. Our
method achieves a Recall@10 of 93.21 and an Rmean of 84.43 on CIRR, and an
average Rmean of 67.48 on FashionIQ, surpassing recent strong baselines by up
to 4.5%. These results confirm that dynamic multi-model collaboration provides
an effective and general solution for CIR.

</details>


### [187] [Efficient representation of 3D spatial data for defense-related applications](https://arxiv.org/abs/2511.05109)
*Benjamin Kahl,Marcus Hebel,Michael Arens*

Main category: cs.GR

TL;DR: 本文比较了传统与现代三维地理空间传感器数据表示方法，提出结合两者优势的混合系统架构。


<details>
  <summary>Details</summary>
Motivation: 为了提升现代防御和安全中的情境感知能力，需要对不同3D数据表示方法进行系统性比较并探索更优解决方案。

Method: 对比分析点云、体素网格、三角网格等传统方法与NeRF、3DGS等神经隐式表示方法，并提出一种融合传统几何结构与神经视觉细节的混合系统架构。

Result: 发现传统方法在几何准确性上表现优异，适用于功能型任务；现代方法在视觉保真度上更胜一筹但几何可靠性不足；所提出的混合架构能兼顾几何完整性与高保真渲染。

Conclusion: 结合传统几何表示与神经视觉表示的混合方法是未来地理空间传感器数据建模最具前景的方向。

Abstract: Geospatial sensor data is essential for modern defense and security, offering
indispensable 3D information for situational awareness. This data, gathered
from sources like lidar sensors and optical cameras, allows for the creation of
detailed models of operational environments. In this paper, we provide a
comparative analysis of traditional representation methods, such as point
clouds, voxel grids, and triangle meshes, alongside modern neural and implicit
techniques like Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting
(3DGS). Our evaluation reveals a fundamental trade-off: traditional models
offer robust geometric accuracy ideal for functional tasks like line-of-sight
analysis and physics simulations, while modern methods excel at producing
high-fidelity, photorealistic visuals but often lack geometric reliability.
Based on these findings, we conclude that a hybrid approach is the most
promising path forward. We propose a system architecture that combines a
traditional mesh scaffold for geometric integrity with a neural representation
like 3DGS for visual detail, managed within a hierarchical scene structure to
ensure scalability and performance.

</details>


### [188] [Neural Image Abstraction Using Long Smoothing B-Splines](https://arxiv.org/abs/2511.05360)
*Daniel Berio,Michael Stroh,Sylvain Calinon,Frederic Fol Leymarie,Oliver Deussen,Ariel Shamir*

Main category: cs.GR

TL;DR: 本文提出了一种将平滑B样条集成到可微分矢量图形（DiffVG）管道中的方法，通过线性映射实现图像深度学习系统中平滑且任意长度路径的生成，并支持几何与图像空间中的风格化控制。


<details>
  <summary>Details</summary>
Motivation: 为了在深度学习系统中生成更平滑、可控且具有艺术风格的矢量路径，克服传统方法在连续性和长度上的限制。

Method: 通过线性映射将平滑B样条引入标准的可微分矢量图形（DiffVG）流程，并利用基于导数的平滑代价函数来控制保真度与简洁性之间的权衡。

Result: 实现了对风格化矢量图形生成的有效控制，展示了四种应用：风格化的空间填充路径生成、基于笔画的图像抽象、闭合区域图像抽象和风格化文本生成。

Conclusion: 该方法兼容现有的矢量图形生成与矢量化技术，能够灵活地生成高质量、风格化的长矢量路径，拓展了DiffVG在图像深度学习中的应用范围。

Abstract: We integrate smoothing B-splines into a standard differentiable vector
graphics (DiffVG) pipeline through linear mapping, and show how this can be
used to generate smooth and arbitrarily long paths within image-based deep
learning systems. We take advantage of derivative-based smoothing costs for
parametric control of fidelity vs. simplicity tradeoffs, while also enabling
stylization control in geometric and image spaces. The proposed pipeline is
compatible with recent vector graphics generation and vectorization methods. We
demonstrate the versatility of our approach with four applications aimed at the
generation of stylized vector graphics: stylized space-filling path generation,
stroke-based image abstraction, closed-area image abstraction, and stylized
text generation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [189] [ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling](https://arxiv.org/abs/2511.04758)
*Caelan Garrett,Fabio Ramos*

Main category: cs.RO

TL;DR: 本文提出了ScheduleStream，首个用于规划与调度的通用框架，通过引入混合持续性动作支持异步启动和参数化持续时间，实现了双臂机器人任务与运动规划中的并行动作调度，并利用GPU加速提升效率。


<details>
  <summary>Details</summary>
Motivation: 由于双臂或人形机器人在执行任务时具有人类般的多臂协同能力，但同时控制多个机械臂面临混合离散-连续动作空间带来的计算挑战；现有任务与运动规划（TAMP）方法通常只能生成单臂依次运动的计划，缺乏对并行操作的支持，因此需要扩展TAMP以实现高效的并行调度。

Method: 提出ScheduleStream框架，采用混合持续性动作建模时间动态，允许动作异步启动且持续时间由其参数决定；设计了领域无关的算法来求解该框架下的问题，并在TAMPAS中结合GPU加速采样器提高规划速度。

Result: 在仿真中对比多种消融实验，结果显示所提算法能生成更高效的解决方案；并在多个真实世界的双臂机器人任务上成功演示了ScheduleStream的有效性。

Conclusion: ScheduleStream是首个支持采样操作的通用规划与调度框架，能够有效实现双臂机器人的并行任务与运动规划，显著提升任务执行效率，具备广泛的应用潜力。

Abstract: Bimanual and humanoid robots are appealing because of their human-like
ability to leverage multiple arms to efficiently complete tasks. However,
controlling multiple arms at once is computationally challenging due to the
growth in the hybrid discrete-continuous action space. Task and Motion Planning
(TAMP) algorithms can efficiently plan in hybrid spaces but generally produce
plans, where only one arm is moving at a time, rather than schedules that allow
for parallel arm motion. In order to extend TAMP to produce schedules, we
present ScheduleStream, the first general-purpose framework for planning &
scheduling with sampling operations. ScheduleStream models temporal dynamics
using hybrid durative actions, which can be started asynchronously and persist
for a duration that's a function of their parameters. We propose
domain-independent algorithms that solve ScheduleStream problems without any
application-specific mechanisms. We apply ScheduleStream to Task and Motion
Planning & Scheduling (TAMPAS), where we use GPU acceleration within samplers
to expedite planning. We compare ScheduleStream algorithms to several ablations
in simulation and find that they produce more efficient solutions. We
demonstrate ScheduleStream on several real-world bimanual robot tasks at
https://schedulestream.github.io.

</details>


### [190] [ReGen: Generative Robot Simulation via Inverse Design](https://arxiv.org/abs/2511.04769)
*Phat Nguyen,Tsun-Hsuan Wang,Zhang-Wei Hong,Erfan Aasi,Andrew Silva,Guy Rosman,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 本文提出了ReGen，一种基于大语言模型的生成式仿真框架，通过逆向设计自动构建机器人仿真环境，根据机器人的行为和文本描述推断出可能的情景和环境。


<details>
  <summary>Details</summary>
Motivation: 传统仿真环境构建费时费力，且难以覆盖复杂和边缘场景，因此需要一种自动化、可扩展的方法来提升机器人学习的效率与泛化能力。

Method: ReGen利用大语言模型生成包含因果关系、实体及其属性的有向图，并将其转化为符号程序以配置和执行机器人仿真环境，支持基于行为的仿真增强、可控的反事实场景生成以及多模态感知推理。

Result: 在自动驾驶和机器人操作任务中，ReGen生成了比现有方法更多样、更复杂的仿真环境，具有高成功率，并能可控生成边缘案例场景。

Conclusion: ReGen有效提升了机器人策略的验证能力，支持数据与仿真增强，推动了可扩展机器人学习的发展，增强了模型的泛化性和鲁棒性。

Abstract: Simulation plays a key role in scaling robot learning and validating
policies, but constructing simulations remains a labor-intensive process. This
paper introduces ReGen, a generative simulation framework that automates
simulation design via inverse design. Given a robot's behavior -- such as a
motion trajectory or an objective function -- and its textual description,
ReGen infers plausible scenarios and environments that could have caused the
behavior. ReGen leverages large language models to synthesize scenarios by
expanding a directed graph that encodes cause-and-effect relationships,
relevant entities, and their properties. This structured graph is then
translated into a symbolic program, which configures and executes a robot
simulation environment. Our framework supports (i) augmenting simulations based
on ego-agent behaviors, (ii) controllable, counterfactual scenario generation,
(iii) reasoning about agent cognition and mental states, and (iv) reasoning
with distinct sensing modalities, such as braking due to faulty GPS signals. We
demonstrate ReGen in autonomous driving and robot manipulation tasks,
generating more diverse, complex simulated environments compared to existing
simulations with high success rates, and enabling controllable generation for
corner cases. This approach enhances the validation of robot policies and
supports data or simulation augmentation, advancing scalable robot learning for
improved generalization and robustness. We provide code and example videos at:
https://regen-sim.github.io/

</details>


### [191] [Unified Multimodal Diffusion Forcing for Forceful Manipulation](https://arxiv.org/abs/2511.04812)
*Zixuan Huang,Huaidian Hou,Dmitry Berenson*

Main category: cs.RO

TL;DR: 本文提出了Multimodal Diffusion Forcing（MDF），一种用于从多模态机器人轨迹中学习的统一框架，通过随机部分掩码并训练扩散模型重构轨迹，捕捉时序和跨模态依赖，适用于接触丰富、力控操作的任务。


<details>
  <summary>Details</summary>
Motivation: 标准的模仿学习方法通常只学习从观测到动作的直接映射，忽略了感官输入、动作和奖励之间丰富的交互关系，而这种关系对建模机器人行为和理解任务结果至关重要。

Method: 提出MDF框架，采用随机部分掩码策略，训练扩散模型重构多模态轨迹，从而学习模态间和时间上的依赖关系，支持动作生成之外的多种功能。

Result: 在模拟和真实环境中的接触丰富、力控操作任务上验证了MDF的有效性，结果显示该方法具有多功能性、高性能以及在噪声观测下的鲁棒性。

Conclusion: MDF能够有效建模多模态机器人轨迹中的复杂依赖关系，提升模仿学习在复杂操作任务中的表现和鲁棒性。

Abstract: Given a dataset of expert trajectories, standard imitation learning
approaches typically learn a direct mapping from observations (e.g., RGB
images) to actions. However, such methods often overlook the rich interplay
between different modalities, i.e., sensory inputs, actions, and rewards, which
is crucial for modeling robot behavior and understanding task outcomes. In this
work, we propose Multimodal Diffusion Forcing, a unified framework for learning
from multimodal robot trajectories that extends beyond action generation.
Rather than modeling a fixed distribution, MDF applies random partial masking
and trains a diffusion model to reconstruct the trajectory. This training
objective encourages the model to learn temporal and cross-modal dependencies,
such as predicting the effects of actions on force signals or inferring states
from partial observations. We evaluate MDF on contact-rich, forceful
manipulation tasks in simulated and real-world environments. Our results show
that MDF not only delivers versatile functionalities, but also achieves strong
performance, and robustness under noisy observations. More visualizations can
be found on our website https://unified-df.github.io

</details>


### [192] [Pixi: Unified Software Development and Distribution for Robotics and AI](https://arxiv.org/abs/2511.04827)
*Tobias Fischer,Wolf Vollprecht,Bas Zalmstra,Ruben Arts,Tim de Jager,Alejandro Fontan,Adam D Hines,Michael Milford,Silvio Traversaro,Daniel Claes,Scarlett Raine*

Main category: cs.RO

TL;DR: Pixi是一个统一的包管理框架，通过项目级锁定文件确保跨平台的精确依赖状态和逐位可重现性，解决了机器人研究中的可重复性危机。


<details>
  <summary>Details</summary>
Motivation: 科学计算中的可重复性危机限制了机器人研究的发展，高达70%的机器人算法无法被独立团队复现，且复杂的软硬件工具链导致依赖地狱问题。

Method: Pixi通过捕获项目级锁定文件中的精确依赖状态来解决这些问题，并集成conda-forge和PyPI生态系统，使用高性能SAT求解器实现比同类工具快10倍的依赖解析速度。

Result: 自2023年以来已被超过5,300个项目采用，将设置时间从数小时减少到几分钟，显著降低了研究人员的技术门槛。

Conclusion: Pixi通过实现可扩展、可重复和协作的研究基础设施，加速了机器人和人工智能领域的进步。

Abstract: The reproducibility crisis in scientific computing constrains robotics
research. Existing studies reveal that up to 70% of robotics algorithms cannot
be reproduced by independent teams, while many others fail to reach deployment
because creating shareable software environments remains prohibitively complex.
These challenges stem from fragmented, multi-language, and hardware-software
toolchains that lead to dependency hell. We present Pixi, a unified
package-management framework that addresses these issues by capturing exact
dependency states in project-level lockfiles, ensuring bit-for-bit
reproducibility across platforms. Its high-performance SAT solver achieves up
to 10x faster dependency resolution than comparable tools, while integration of
the conda-forge and PyPI ecosystems removes the need for multiple managers.
Adopted in over 5,300 projects since 2023, Pixi reduces setup times from hours
to minutes and lowers technical barriers for researchers worldwide. By enabling
scalable, reproducible, collaborative research infrastructure, Pixi accelerates
progress in robotics and AI.

</details>


### [193] [Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning](https://arxiv.org/abs/2511.04831)
*NVIDIA,:,Mayank Mittal,Pascal Roth,James Tigue,Antoine Richard,Octi Zhang,Peter Du,Antonio Serrano-Muñoz,Xinjie Yao,René Zurbrügg,Nikita Rudin,Lukasz Wawrzyniak,Milad Rakhsha,Alain Denzler,Eric Heiden,Ales Borovicka,Ossama Ahmed,Iretiayo Akinola,Abrar Anwar,Mark T. Carlson,Ji Yuan Feng,Animesh Garg,Renato Gasoto,Lionel Gulich,Yijie Guo,M. Gussert,Alex Hansen,Mihir Kulkarni,Chenran Li,Wei Liu,Viktor Makoviychuk,Grzegorz Malczyk,Hammad Mazhar,Masoud Moghani,Adithyavairavan Murali,Michael Noseworthy,Alexander Poddubny,Nathan Ratliff,Welf Rehberg,Clemens Schwarke,Ritvik Singh,James Latham Smith,Bingjie Tang,Ruchik Thaker,Matthew Trepte,Karl Van Wyk,Fangzhou Yu,Alex Millane,Vikram Ramasamy,Remo Steiner,Sangeeta Subramanian,Clemens Volk,CY Chen,Neel Jawale,Ashwin Varghese Kuruttukulam,Michael A. Lin,Ajay Mandlekar,Karsten Patzwaldt,John Welsh,Huihua Zhao,Fatima Anes,Jean-Francois Lafleche,Nicolas Moënne-Loccoz,Soowan Park,Rob Stepinski,Dirk Van Gelder,Chris Amevor,Jan Carius,Jumyung Chang,Anka He Chen,Pablo de Heras Ciechomski,Gilles Daviet,Mohammad Mohajerani,Julia von Muralt,Viktor Reutskyy,Michael Sauter,Simon Schirm,Eric L. Shi,Pierre Terdiman,Kenny Vilella,Tobias Widmer,Gordon Yeoman,Tiffany Chen,Sergey Grizan,Cathy Li,Lotus Li,Connor Smith,Rafael Wiltz,Kostas Alexis,Yan Chang,David Chu,Linxi "Jim" Fan,Farbod Farshidian,Ankur Handa,Spencer Huang,Marco Hutter,Yashraj Narang,Soha Pouya,Shiwei Sheng,Yuke Zhu,Miles Macklin,Adam Moravanszky,Philipp Reist,Yunrong Guo,David Hoeller,Gavriel State*

Main category: cs.RO

TL;DR: Isaac Lab 是一个GPU原生的机器人仿真框架，扩展了Isaac Gym，支持大规模多模态学习，集成了高保真物理仿真、逼真渲染、传感器模拟和数据收集工具，适用于强化学习与模仿学习。


<details>
  <summary>Details</summary>
Motivation: 为了应对机器人学习中对高保真、可扩展仿真平台的需求，支持复杂任务如全身控制、灵巧操作和跨形态移动。

Method: 采用GPU并行物理引擎、模块化环境设计、多频率传感器模拟、域随机化以及与可微分物理引擎集成的方法。

Result: 实现了支持大规模机器人策略训练的统一平台，适用于多种复杂机器人任务，并为数据高效和梯度驱动的学习方法提供支持。

Conclusion: Isaac Lab 结合先进的仿真能力与数据中心级执行能力，有望推动下一代机器人研究的突破。

Abstract: We present Isaac Lab, the natural successor to Isaac Gym, which extends the
paradigm of GPU-native robotics simulation into the era of large-scale
multi-modal learning. Isaac Lab combines high-fidelity GPU parallel physics,
photorealistic rendering, and a modular, composable architecture for designing
environments and training robot policies. Beyond physics and rendering, the
framework integrates actuator models, multi-frequency sensor simulation, data
collection pipelines, and domain randomization tools, unifying best practices
for reinforcement and imitation learning at scale within a single extensible
platform. We highlight its application to a diverse set of challenges,
including whole-body control, cross-embodiment mobility, contact-rich and
dexterous manipulation, and the integration of human demonstrations for skill
acquisition. Finally, we discuss upcoming integration with the differentiable,
GPU-accelerated Newton physics engine, which promises new opportunities for
scalable, data-efficient, and gradient-based approaches to robot learning. We
believe Isaac Lab's combination of advanced simulation capabilities, rich
sensing, and data-center scale execution will help unlock the next generation
of breakthroughs in robotics research.

</details>


### [194] [Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning](https://arxiv.org/abs/2511.04835)
*Shubham Natraj,Bruno Sinopoli,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 提出一种新的非均匀采样策略，通过将采样偏向“认证”区域来提升基于采样的运动规划器的效率，并提供概率上正确的保证。


<details>
  <summary>Details</summary>
Motivation: 基于采样的运动规划器（SBMPs）因依赖均匀采样而在复杂环境中效率低下，需要更高效的采样方法。

Method: 结合启发式路径预测器生成初始路径，并利用共形预测量化不确定性，构建包含最优解的预测集作为采样偏好区域。

Result: 实验表明该方法比现有基线更快找到可行路径，并在未见环境中表现出更好的泛化能力。

Conclusion: 这是首个为SBMP提供概率正确保证的非均匀采样方法，显著提升了规划效率和鲁棒性。

Abstract: Sampling-based motion planners (SBMPs) are widely used to compute dynamically
feasible robot paths. However, their reliance on uniform sampling often leads
to poor efficiency and slow planning in complex environments. We introduce a
novel non-uniform sampling strategy that integrates into existing SBMPs by
biasing sampling toward `certified' regions. These regions are constructed by
(i) generating an initial, possibly infeasible, path using any heuristic path
predictor (e.g., A* or vision-language models) and (ii) applying conformal
prediction to quantify the predictor's uncertainty. This process yields
prediction sets around the initial-guess path that are guaranteed, with
user-specified probability, to contain the optimal solution. To our knowledge,
this is the first non-uniform sampling approach for SBMPs that provides such
probabilistically correct guarantees on the sampling regions. Extensive
evaluations demonstrate that our method consistently finds feasible paths
faster and generalizes better to unseen environments than existing baselines.

</details>


### [195] [Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions](https://arxiv.org/abs/2511.04837)
*Cameron Robinson,Ganghee Jang*

Main category: cs.RO

TL;DR: 本文研究了太阳能板在关键任务应用中因灰尘或太空碎片覆盖而影响运行的问题，设计并测试了清洁机制和防护材料。


<details>
  <summary>Details</summary>
Motivation: 解决太阳能板被灰尘或太空碎片覆盖导致性能下降甚至失效的问题，确保其在空间探索、野火监测等关键任务中的持续运行。

Method: 设计了两种清洁机制（刮水器系统和轨道系统），并通过碰撞实验测试了多种防护材料的抗冲击性能，比较了不同方案在成本、清洁速度和功耗方面的表现。

Result: 在防护材料方面，聚碳酸酯表现良好，但最有效的方案是在面板表面与硬质材料之间加入软质中间层；在清洁系统方面，刮水器系统在成本、清洁速度和总功耗上优于轨道系统。

Conclusion: 刮水器系统是更高效的清洁方案，而采用软硬复合层结构能有效提升太阳能板对尘埃和碎片的防护能力。

Abstract: Solar energy is used for many mission-critical applications including space
exploration, sensor systems to monitor wildfires, etc. Their operation can be
limited or even terminated if solar panels are covered with dust or hit by
space debris. To address this issue, we designed panel cleaning mechanisms and
tested protective materials. For cleaning mechanisms, we designed and compared
a wiper system and a rail system. For protective materials, we found through
collision tests that polycarbonate was very promising, though the most
important factor was layering a soft material between the panel's surface and a
hard material. In the cleaning system comparisons, the wiper-based system was
more efficient than the rail-based system in terms of cost, cleaning speed, and
total power consumption.

</details>


### [196] [iFlyBot-VLM Technical Report](https://arxiv.org/abs/2511.04976)
*Xin Nie,Zhiyuan Cheng,Yuan Zhang,Chao Ji,Jiajia Wu,Yuhan Zhang,Jia Pan*

Main category: cs.RO

TL;DR: iFlyBot-VLM 是一种通用的视觉-语言模型，旨在弥合环境感知与机器人动作控制之间的跨模态语义鸿沟，通过抽象视觉信息为可迁移的操作语言，实现多平台的感知-行动闭环协调。


<details>
  <summary>Details</summary>
Motivation: 为了提升具身智能中视觉与动作之间的语义对齐能力，解决高维感知与低维控制间的语义鸿沟问题。

Method: 设计了一种系统化的VLM架构，将复杂视觉和空间信息抽象为身体无关的操作语言，并支持空间理解、目标定位、动作生成和任务规划四大功能。

Result: 在10个主流具身智能VLM基准（如Blink、Where2Place）上取得最优性能，同时保持模型的通用性。

Conclusion: iFlyBot-VLM 有望成为具身AI的可扩展基础模型，推动从专用系统向通用认知智能体的发展，且训练数据与模型权重将公开发布。

Abstract: We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used
to improve the domain of Embodied Intelligence. The central objective of
iFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional
environmental perception and low-level robotic motion control. To this end, the
model abstracts complex visual and spatial information into a body-agnostic and
transferable Operational Language, thereby enabling seamless perception-action
closed-loop coordination across diverse robotic platforms. The architecture of
iFlyBot-VLM is systematically designed to realize four key functional
capabilities essential for embodied intelligence: 1) Spatial Understanding and
Metric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and
Control Parameter Generation; 4) Task Planning and Skill Sequencing. We
envision iFlyBot-VLM as a scalable and generalizable foundation model for
embodied AI, facilitating the progression from specialized task-oriented
systems toward generalist, cognitively capable agents. We conducted evaluations
on 10 current mainstream embodied intelligence-related VLM benchmark datasets,
such as Blink and Where2Place, and achieved optimal performance while
preserving the model's general capabilities. We will publicly release both the
training data and model weights to foster further research and development in
the field of Embodied Intelligence.

</details>


### [197] [A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces](https://arxiv.org/abs/2511.04992)
*Bibekananda Patra,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 提出了一种计算6-6 Stewart-Gough平台操作器在指定姿态工作空间内最大无奇异性球（SFS）的方法，通过采样和分析计算最小SFS，并在四种不同结构上进行了数值实验。


<details>
  <summary>Details</summary>
Motivation: 为了在给定的姿态工作空间内分析和设计SGPM时，能够有效评估其无奇异性运动能力，需要一种可靠的方法来计算最大的无奇异性球（SFS）。

Method: 对固定姿态下的移动平台，解析计算SFS；在姿态工作空间内生成多个样本点，重复计算SFS，并取其中最小值作为该工作空间的SFS。

Result: 在四种不同的SGPM架构上进行了数值实验，比较了它们在同一姿态工作空间下的SFS体积表现。

Conclusion: 所提出的方法能有效用于SGPM的分析与设计，有助于评估不同结构在姿态工作空间内的无奇异性性能。

Abstract: This article presents a method for computing the largest singularity-free
sphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a
specified orientation workspace. For a fixed orientation of the moving
platform, the SFS is computed analytically. This process is repeated over a set
of samples generated within the orientation workspace, and the smallest among
them is designated as the desired SFS for the given orientation workspace.
Numerical experiments are performed on four distinct architectures of the SGPM
to understand their relative performances w.r.t. SFS volumes over the same
orientation workspace. This study demonstrates the potential utility of the
proposed computational method both in analysis and design of SGPMs.

</details>


### [198] [Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems](https://arxiv.org/abs/2511.04994)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 本文提出了一种双端口生物力学感知的无源性同步与稳定器（TBPS2），用于改善网络化机器人系统在存在通信延迟和非无源行为下的位置同步与稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保证力传递的同时难以解决因通信不完美和非无源行为引起的位置失步问题，限制了遥操作系统的性能。

Method: 设计了一种结合人体生物力学信息的双端口无源性同步与稳定器（TBPS2），通过优化生物力学感知机制减少稳定器激活时的保守性，并提供数学设计与稳定性证明。

Result: 通过网格仿真和系统实验，在不同时间延迟和环境条件下验证了TBPS2相比现有方法在位置同步和稳定性方面的优越性能。

Conclusion: TBPS2能有效提升网络化机器人系统在复杂通信条件下的同步性和稳定性，同时兼顾人机交互的安全与性能。

Abstract: Maintaining system stability and accurate position tracking is imperative in
networked robotic systems, particularly for haptics-enabled human-robot
interaction. Recent literature has integrated human biomechanics into the
stabilizers implemented for teleoperation, enhancing force preservation while
guaranteeing convergence and safety. However, position desynchronization due to
imperfect communication and non-passive behaviors remains a challenge. This
paper proposes a two-port biomechanics-aware passivity-based synchronizer and
stabilizer, referred to as TBPS2. This stabilizer optimizes position
synchronization by leveraging human biomechanics while reducing the
stabilizer's conservatism in its activation. We provide the mathematical design
synthesis of the stabilizer and the proof of stability. We also conducted a
series of grid simulations and systematic experiments, comparing their
performance with that of state-of-the-art solutions under varying time delays
and environmental conditions.

</details>


### [199] [MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery](https://arxiv.org/abs/2511.05007)
*Baiye Cheng,Tianhai Liang,Suning Huang,Maanping Shao,Feihong Zhang,Botian Xu,Zhengrong Xue,Huazhe Xu*

Main category: cs.RO

TL;DR: 本文提出了Mixture of Experts-Enhanced Diffusion Policy (MoE-DP)，通过在视觉编码器和扩散模型之间引入MoE层，提升扩散策略在长时程、多阶段任务中的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在长时程多阶段任务中难以从子任务失败中恢复，且策略表征缺乏可解释性。

Method: 在视觉编码器与扩散模型之间插入Mixture of Experts（MoE）层，将策略知识分解为多个专业化专家，动态激活以应对不同任务阶段。

Result: 在6个模拟长时程任务中，受干扰条件下平均成功率相对提升36%；在真实场景中也表现出显著性能增益；同时实现了可解释的技能分解，不同专家对应语义化的任务原语（如接近、抓取），并支持推理时无需重训练的子任务重组。

Conclusion: MoE-DP显著提升了扩散策略在复杂任务中的鲁棒性和可解释性，具备实际应用潜力，并支持灵活的任务结构调整。

Abstract: Diffusion policies have emerged as a powerful framework for robotic
visuomotor control, yet they often lack the robustness to recover from subtask
failures in long-horizon, multi-stage tasks and their learned representations
of observations are often difficult to interpret. In this work, we propose the
Mixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is
to insert a Mixture of Experts (MoE) layer between the visual encoder and the
diffusion model. This layer decomposes the policy's knowledge into a set of
specialized experts, which are dynamically activated to handle different phases
of a task. We demonstrate through extensive experiments that MoE-DP exhibits a
strong capability to recover from disturbances, significantly outperforming
standard baselines in robustness. On a suite of 6 long-horizon simulation
tasks, this leads to a 36% average relative improvement in success rate under
disturbed conditions. This enhanced robustness is further validated in the real
world, where MoE-DP also shows significant performance gains. We further show
that MoE-DP learns an interpretable skill decomposition, where distinct experts
correspond to semantic task primitives (e.g., approaching, grasping). This
learned structure can be leveraged for inference-time control, allowing for the
rearrangement of subtasks without any re-training.Our video and code are
available at the https://moe-dp-website.github.io/MoE-DP-Website/.

</details>


### [200] [Tunable Passivity Control for Centralized Multiport Networked Systems](https://arxiv.org/abs/2511.05026)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 提出了一种集中式最优无源性稳定框架TCoPC，用于多端口网络化动态系统，在非理想网络条件下保证L2稳定性并优化性能。


<details>
  <summary>Details</summary>
Motivation: 传统无源性方法在分布式补偿和节点无源性假设上存在限制，难以适应大规模或复杂网络环境下的稳定性需求。

Method: 设计了一个集中式无源性观测器与最优控制器，通过数据驱动、模型无关的方式动态分配耗散，实现全局严格无源性。

Result: 仿真表明该方法在时变延迟下有效提升系统稳定性与性能，且无需远程节点满足最小相位或无源性假设。

Conclusion: TCoPC框架增强了系统的可扩展性和通用性，为复杂CMND系统提供了更灵活鲁棒的稳定控制方案。

Abstract: Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key
architecture with applications in several complex network systems, such as
multilateral telerobotics and multi-agent control. These systems consist of a
hub node/subsystem connecting with multiple remote nodes/subsystems via a
networked architecture. One challenge for this system is stability, which can
be affected by non-ideal network artifacts. Conventional passivity-based
approaches can stabilize the system under specialized applications like
small-scale networked systems. However, those conventional passive stabilizers
have several restrictions, such as distributing compensation across subsystems
in a decentralized manner, limiting flexibility, and, at the same time, relying
on the restrictive assumptions of node passivity. This paper synthesizes a
centralized optimal passivity-based stabilization framework for CMND systems.
It consists of a centralized passivity observer monitoring overall energy flow
and an optimal passivity controller that distributes the just-needed
dissipation among various nodes, guaranteeing strict passivity and, thus, L2
stability. The proposed data-driven model-free approach, i.e., Tunable
Centralized Optimal Passivity Control (TCoPC), optimizes total performance
based on the prescribed dissipation distribution strategy while ensuring
stability. The controller can put high dissipation loads on some sub-networks
while relaxing the dissipation on other nodes. Simulation results demonstrate
the proposed frameworks performance in a complex task under different
time-varying delay scenarios while relaxing the remote nodes minimum phase and
passivity assumption, enhancing the scalability and generalizability.

</details>


### [201] [Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems](https://arxiv.org/abs/2511.05033)
*Jennifer K. Leestma,Siddharth R. Nathella,Christoph P. O. Nuesslein,Snehil Mathur,Gregory S. Sawicki,Aaron J. Young*

Main category: cs.RO

TL;DR: Epically Powerful 是一个开源的机器人基础设施，旨在简化可穿戴机器人系统的开发与部署，支持多种商用准直驱执行器、单板计算机和传感器，提供硬件选型、系统组装和控制器实现的完整指南。


<details>
  <summary>Details</summary>
Motivation: 降低研究人员开发定制化可穿戴机器人系统的门槛，加快从硬件到功能设备的实现过程。

Method: 提供统一的软件框架，管理通信协议、时钟同步、执行器控制、传感器数据采集、日志记录和可视化，并通过Python接口简化用户实现，同时附带硬件兼容性指南和示例控制器。

Result: 实现了对多种QDD执行器和传感器的无缝集成，支持实时可视化和数据记录，提升了系统模块化和鲁棒性。

Conclusion: Epically Powerful 有效降低了可穿戴机器人系统的开发复杂度，具有良好的扩展性，也可应用于其他使用QDD执行器和闭环控制的机器人领域。

Abstract: Epically Powerful is an open-source robotics infrastructure that streamlines
the underlying framework of wearable robotic systems - managing communication
protocols, clocking, actuator commands, visualization, sensor data acquisition,
data logging, and more - while also providing comprehensive guides for hardware
selection, system assembly, and controller implementation. Epically Powerful
contains a code base enabling simplified user implementation via Python that
seamlessly interfaces with various commercial state-of-the-art quasi-direct
drive (QDD) actuators, single-board computers, and common sensors, provides
example controllers, and enables real-time visualization. To further support
device development, the package also includes a recommended parts list and
compatibility guide and detailed documentation on hardware and software
implementation. The goal of Epically Powerful is to lower the barrier to
developing and deploying custom wearable robotic systems without a
pre-specified form factor, enabling researchers to go from raw hardware to
modular, robust devices quickly and effectively. Though originally designed
with wearable robotics in mind, Epically Powerful is broadly applicable to
other robotic domains that utilize QDD actuators, single-board computers, and
sensors for closed-loop control.

</details>


### [202] [TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments](https://arxiv.org/abs/2511.05052)
*Zihao Li,Yiming Zhu,Zhe Zhong,Qinyuan Ren,Yijiang Huang*

Main category: cs.RO

TL;DR: 提出了一种名为TAPOM的拓扑感知物体操作规划方法，通过任务空间拓扑分析提高在狭窄空间中机器人操作的规划效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 在复杂受限空间中进行机器人操作具有挑战性，尤其是在处理低间隙环境时，现有方法常因采样困难或陷入局部极小值而失败。

Method: TAPOM结合高层任务空间拓扑分析以识别关键路径并生成引导关键帧，并将其用于底层规划器中寻找可行的构型空间轨迹。

Result: 实验验证表明，TAPOM在低间隙操作任务中相比现有最先进方法具有显著更高的成功率和效率提升。

Conclusion: TAPOM有效提升了机器人在复杂真实环境中执行受限空间操作的能力，具有广泛的应用前景。

Abstract: Robotic manipulation in complex, constrained spaces is vital for widespread
applications but challenging, particularly when navigating narrow passages with
elongated objects. Existing planning methods often fail in these low-clearance
scenarios due to the sampling difficulties or the local minima. This work
proposes Topology-Aware Planning for Object Manipulation (TAPOM), which
explicitly incorporates task-space topological analysis to enable efficient
planning. TAPOM uses a high-level analysis to identify critical pathways and
generate guiding keyframes, which are utilized in a low-level planner to find
feasible configuration space trajectories. Experimental validation demonstrates
significantly high success rates and improved efficiency over state-of-the-art
methods on low-clearance manipulation tasks. This approach offers broad
implications for enhancing manipulation capabilities of robots in complex
real-world environments.

</details>


### [203] [Decomposed Object Manipulation via Dual-Actor Policy](https://arxiv.org/abs/2511.05129)
*Bin Fan,Jianjian Jiang,Zhuohao Li,Yixiang He,Xiaoming Wu,Yihan Yang,Shengbang Liu,Weishi Zheng*

Main category: cs.RO

TL;DR: 提出一种双演员策略（DAP），利用不同阶段的视觉先验信息提升物体操作性能，并构建包含多种任务的模拟数据集进行验证。


<details>
  <summary>Details</summary>
Motivation: 以往方法忽略物体操作任务中接近和操作两个阶段的区别，采用单一策略直接学习整个过程，导致性能受限。

Method: 提出Dual-Actor Policy（DAP），包含基于可及性的演员用于定位功能部件以改善接近过程，基于运动光流的演员捕捉部件运动以促进操作过程，并引入决策模块判断当前阶段并选择相应演员。同时构建Dual-Prior Object Manipulation Dataset支持训练。

Result: 在自建数据集、RoboTwin基准和真实场景中，该方法平均分别比现有最优方法提升5.55%、14.7%和10.4%。

Conclusion: DAP通过显式区分操作阶段并融合异构视觉先验，显著提升了物体操作的性能，且在多种任务和场景下具有良好的泛化能力。

Abstract: Object manipulation, which focuses on learning to perform tasks on similar
parts across different types of objects, can be divided into an approaching
stage and a manipulation stage. However, previous works often ignore this
characteristic of the task and rely on a single policy to directly learn the
whole process of object manipulation. To address this problem, we propose a
novel Dual-Actor Policy, termed DAP, which explicitly considers different
stages and leverages heterogeneous visual priors to enhance each stage.
Specifically, we introduce an affordance-based actor to locate the functional
part in the manipulation task, thereby improving the approaching process.
Following this, we propose a motion flow-based actor to capture the movement of
the component, facilitating the manipulation process. Finally, we introduce a
decision maker to determine the current stage of DAP and select the
corresponding actor. Moreover, existing object manipulation datasets contain
few objects and lack the visual priors needed to support training. To address
this, we construct a simulated dataset, the Dual-Prior Object Manipulation
Dataset, which combines the two visual priors and includes seven tasks,
including two challenging long-term, multi-stage tasks. Experimental results on
our dataset, the RoboTwin benchmark and real-world scenarios illustrate that
our method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4%
on average respectively.

</details>


### [204] [Follow-Me in Micro-Mobility with End-to-End Imitation Learning](https://arxiv.org/abs/2511.05158)
*Sahar Salimpour,Iacopo Catalano,Tomi Westerlund,Mohsen Falahi,Jorge Peña Queralta*

Main category: cs.RO

TL;DR: 本文研究了自主微移动平台在复杂环境下的社会导航问题，提出使用模仿学习优化用户舒适度，并通过不同神经网络架构实现端到端控制，在实际部署中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人导航指标（如时间和距离）不足以满足商业应用中对用户舒适度和体验的需求，尤其是在大型室内或城市动态环境中，需要更关注社会导航中的用户体验。

Method: 采用模仿学习方法训练控制器，对比手动调参的传统控制器，评估不同神经网络架构在端到端控制中的表现，并在实际生产的自主轮椅DAACV上进行验证。

Result: 模仿学习得到的控制器相比手动调参控制器具有更优的平滑性和整体性能，在跟随模式下实现了当前最优的舒适度水平，并证明了所选神经网络架构在真实场景中的可用性。

Conclusion: 模仿学习能有效提升自主微移动平台在社会导航中的用户舒适度和整体体验，适用于实际商业部署，特别是在服务行动不便人群的场景中具有广泛应用前景。

Abstract: Autonomous micro-mobility platforms face challenges from the perspective of
the typical deployment environment: large indoor spaces or urban areas that are
potentially crowded and highly dynamic. While social navigation algorithms have
progressed significantly, optimizing user comfort and overall user experience
over other typical metrics in robotics (e.g., time or distance traveled) is
understudied. Specifically, these metrics are critical in commercial
applications. In this paper, we show how imitation learning delivers smoother
and overall better controllers, versus previously used manually-tuned
controllers. We demonstrate how DAAV's autonomous wheelchair achieves
state-of-the-art comfort in follow-me mode, in which it follows a human
operator assisting persons with reduced mobility (PRM). This paper analyzes
different neural network architectures for end-to-end control and demonstrates
their usability in real-world production-level deployments.

</details>


### [205] [Procedimiento de auditoría de ciberseguridad para sistemas autónomos: metodología, amenazas y mitigaciones](https://arxiv.org/abs/2511.05185)
*Adrián Campazas-Vega,Claudia Álvarez-Aparicio,David Sobrín-Hidalgo,Laura Inyesto-Alonso,Francisco Javier Rodríguez-Lera,Vicente Matellán-Olivera,Ángel Manuel Guerrero-Higueras*

Main category: cs.RO

TL;DR: 本文提出了一种针对自主系统的分层安全审计方法，结合机器人领域的威胁分类和具体缓解措施，并通过四种代表性机器人平台的案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统在关键领域（如工业、医疗、物流和家庭环境）的广泛应用，其面临的安全威胁日益严重，尤其是在人机交互环境中，亟需系统化的安全审计方法来应对不断扩大的攻击面。

Method: 采用分层结构化的方法，构建适应机器人环境的威胁分类体系，并提出具体的缓解措施，形成一套专门针对自主系统的安全审计流程。

Result: 该方法在Ghost Robotics的Vision 60、Unitree Robotics的A1、Universal Robots的UR3以及Aldebaran Robotics的Pepper四个典型机器人平台上进行了四组实际案例研究，验证了其可行性和有效性。

Conclusion: 所提出的分层安全审计方法能够有效识别和缓解自主系统的安全风险，适用于复杂且高操作依赖性的机器人系统，具有较强的实践价值和推广潜力。

Abstract: The deployment of autonomous systems has experienced remarkable growth in
recent years, driven by their integration into sectors such as industry,
medicine, logistics, and domestic environments. This expansion is accompanied
by a series of security issues that entail significant risks due to the
critical nature of autonomous systems, especially those operating in
human-interaction environments. Furthermore, technological advancement and the
high operational and architectural complexity of autonomous systems have
resulted in an increased attack surface. This article presents a specific
security auditing procedure for autonomous systems, based on a layer-structured
methodology, a threat taxonomy adapted to the robotic context, and a set of
concrete mitigation measures. The validity of the proposed approach is
demonstrated through four practical case studies applied to representative
robotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1
robot from Unitree Robotics, the UR3 collaborative arm from Universal Robots,
and the Pepper social robot from Aldebaran Robotics.

</details>


### [206] [Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation](https://arxiv.org/abs/2511.05199)
*Yichen Zhu,Feifei Feng*

Main category: cs.RO

TL;DR: 本文提出了一种从人类演示视频中检索信息来学习机器人策略的新方法（RfV），通过提取物体可操作性掩码和手部运动轨迹等中层信息，结合视频检索器和策略生成器的双组件系统，使机器人能在复杂环境中泛化并执行新任务。


<details>
  <summary>Details</summary>
Motivation: 机器人在复杂不确定环境中面临挑战，传统方法依赖大量训练数据，而人类可通过观看视频学习新任务，因此希望借鉴这种类比学习方式提升机器人学习效率与泛化能力。

Method: 构建包含人类日常操作视频的视频库，提取中层特征（如物体affordance掩码和手部运动轨迹）；设计双组件系统：视频检索器根据任务描述从外部视频库中检索相关视频，策略生成器将检索到的知识融入策略学习过程。

Result: 在多个模拟和真实场景测试中，该系统显著优于传统机器人系统，能够在未见任务上实现良好泛化，表现出更强的适应性和操作性能。

Conclusion: RfV方法通过类比人类学习方式，利用视频演示中的中层语义信息和外部知识检索，有效提升了机器人在复杂环境中的学习效率和任务泛化能力，为机器人操作学习提供了新方向。

Abstract: Robots operating in complex and uncertain environments face considerable
challenges. Advanced robotic systems often rely on extensive datasets to learn
manipulation tasks. In contrast, when humans are faced with unfamiliar tasks,
such as assembling a chair, a common approach is to learn by watching video
demonstrations. In this paper, we propose a novel method for learning robot
policies by Retrieving-from-Video (RfV), using analogies from human
demonstrations to address manipulation tasks. Our system constructs a video
bank comprising recordings of humans performing diverse daily tasks. To enrich
the knowledge from these videos, we extract mid-level information, such as
object affordance masks and hand motion trajectories, which serve as additional
inputs to enhance the robot model's learning and generalization capabilities.
We further feature a dual-component system: a video retriever that taps into an
external video bank to fetch task-relevant video based on task specification,
and a policy generator that integrates this retrieved knowledge into the
learning cycle. This approach enables robots to craft adaptive responses to
various scenarios and generalize to tasks beyond those in the training data.
Through rigorous testing in multiple simulated and real-world settings, our
system demonstrates a marked improvement in performance over conventional
robotic systems, showcasing a significant breakthrough in the field of
robotics.

</details>


### [207] [Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space](https://arxiv.org/abs/2511.05203)
*Linus Nwankwo,Björn Ellensohn,Christian Rauch,Elmar Rueckert*

Main category: cs.RO

TL;DR: 提出了一种共生交互学习（SIL）方法，实现人与智能体之间的双向共适应，提升自主智能体在长周期任务中的主动性和协作性。


<details>
  <summary>Details</summary>
Motivation: 现有的自主智能体在人机交互中多采用主从式被动执行模式，缺乏人类互动中常见的共适应动态，限制了自然协作。

Method: 将SIL建模为共享潜在任务空间中的共适应过程，结合预训练基础模型进行感知与推理，并引入轻量级潜在编码器和记忆架构以实现任务特定表征及防止遗忘。

Result: 在模拟和真实世界的具身任务中验证了SIL的有效性，支持主动澄清、自适应建议和共同计划优化等新型行为。

Conclusion: SIL实现了人与智能体间的双向学习与适应，推动了更自然、协作的人机交互发展。

Abstract: Today's autonomous agents can understand free-form natural language
instructions and execute long-horizon tasks in a manner akin to human-level
reasoning. These capabilities are mostly driven by large-scale pre-trained
foundation models (FMs). However, the approaches with which these models are
grounded for human-robot interaction (HRI) perpetuate a master-apprentice
model, where the apprentice (embodied agent) passively receives and executes
the master's (human's) commands without reciprocal learning. This reactive
interaction approach does not capture the co-adaptive dynamics inherent in
everyday multi-turn human-human interactions. To address this, we propose a
Symbiotic Interactive Learning (SIL) approach that enables both the master and
the apprentice to co-adapt through mutual, bidirectional interactions. We
formalised SIL as a co-adaptation process within a shared latent task space,
where the agent and human maintain joint belief states that evolve based on
interaction history. This enables the agent to move beyond reactive execution
to proactive clarification, adaptive suggestions, and shared plan refinement.
To realise these novel behaviours, we leveraged pre-trained FMs for spatial
perception and reasoning, alongside a lightweight latent encoder that grounds
the models' outputs into task-specific representations. Furthermore, to ensure
stability as the tasks evolve, we augment SIL with a memory architecture that
prevents the forgetting of learned task-space representations. We validate SIL
on both simulated and real-world embodied tasks, including instruction
following, information retrieval, query-oriented reasoning, and interactive
dialogues. Demos and resources are public
at:~\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.

</details>


### [208] [Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning](https://arxiv.org/abs/2511.05234)
*Philipp Dahlinger,Niklas Freymuth,Tai Hoang,Tobias Würth,Michael Volpp,Luise Kärger,Gerhard Neumann*

Main category: cs.RO

TL;DR: 提出了一种基于轨迹级元学习的网格模拟方法M3GN，利用条件神经过程和运动原语实现快速、稳定且准确的模拟，显著提高了仿真精度并降低了运行时间。


<details>
  <summary>Details</summary>
Motivation: 现有学习型模拟器依赖单步观测，难以利用时间上下文，无法推断材料属性，且自回归 rollout 会导致长轨迹误差累积。

Method: 将网格模拟视为轨迹级元学习问题，采用条件神经过程进行快速适应，并利用运动原语通过单次模型调用直接预测模拟轨迹。

Result: M3GN在多个任务上相比当前最先进的图网络模拟器，在更短的运行时间内实现了更高的仿真精度。

Conclusion: M3GN通过引入时间上下文和元学习机制，有效提升了物理模拟的准确性与效率，适用于机器人操作和制造优化等需要快速精确仿真的场景。

Abstract: Simulating object deformations is a critical challenge across many scientific
domains, including robotics, manufacturing, and structural mechanics. Learned
Graph Network Simulators (GNSs) offer a promising alternative to traditional
mesh-based physics simulators. Their speed and inherent differentiability make
them particularly well suited for applications that require fast and accurate
simulations, such as robotic manipulation or manufacturing optimization.
However, existing learned simulators typically rely on single-step
observations, which limits their ability to exploit temporal context. Without
this information, these models fail to infer, e.g., material properties.
Further, they rely on auto-regressive rollouts, which quickly accumulate error
for long trajectories. We instead frame mesh-based simulation as a
trajectory-level meta-learning problem. Using Conditional Neural Processes, our
method enables rapid adaptation to new simulation scenarios from limited
initial data while capturing their latent simulation properties. We utilize
movement primitives to directly predict fast, stable and accurate simulations
from a single model call. The resulting approach, Movement-primitive
Meta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of
the runtime cost compared to state-of-the-art GNSs across several tasks.

</details>


### [209] [TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models](https://arxiv.org/abs/2511.05275)
*Hokyun Im,Euijin Jeong,Jianlong Fu,Andrey Kolobov,Youngwoon Lee*

Main category: cs.RO

TL;DR: TwinVLA是一种模块化框架，通过组合两个预训练的单臂视觉-语言-动作模型（VLA），实现高效的双手机器人操作，无需额外的双臂数据训练，在真实和仿真环境中均表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在双手机器人任务中通常需要大量双臂演示数据进行训练或微调，而公开的双臂数据稀缺，限制了模型的适应性。因此，需要一种更高效的方法来利用广泛可用的单臂数据实现高性能双手机械操作。

Method: 提出TwinVLA，该框架将两个相同的预训练单臂VLA模型组合成一个协同工作的双臂VLA系统。通过模块化组合而非端到端重训练，实现跨形态动作协调，无需双臂数据预训练。

Result: 在多种真实世界和仿真环境中的双手机器人任务上，TwinVLA优于同等规模的单体RDT-1B模型，且性能接近依赖大量专有双臂数据和计算资源的最先进模型π₀。

Conclusion: TwinVLA提供了一种数据高效、可扩展的双手机器人操作解决方案，有效利用公开的单臂数据，减少了对专有双臂数据和高计算成本的依赖。

Abstract: Vision-language-action models (VLAs) trained on large-scale robotic datasets
have demonstrated strong performance on manipulation tasks, including bimanual
tasks. However, because most public datasets focus on single-arm
demonstrations, adapting VLAs for bimanual tasks typically requires substantial
additional bimanual data and fine-tuning. To address this challenge, we
introduce TwinVLA, a modular framework that composes two copies of a pretrained
single-arm VLA into a coordinated bimanual VLA. Unlike monolithic
cross-embodiment models trained on mixtures of single-arm and bimanual data,
TwinVLA improves both data efficiency and performance by composing pretrained
single-arm policies. Across diverse bimanual tasks in real-world and simulation
settings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model
without requiring any bimanual pretraining. Furthermore, it narrows the gap to
state-of-the-art model, $\pi_0$ which rely on extensive proprietary bimanual
data and compute cost. These results establish our modular composition approach
as a data-efficient and scalable path toward high-performance bimanual
manipulation, leveraging public single-arm data.

</details>


### [210] [Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators](https://arxiv.org/abs/2511.05307)
*Akua K. Dickson,Juan C. Pacheco Garcia,Andrew P. Sabelhaus*

Main category: cs.RO

TL;DR: 提出一种将任务空间的力安全标准映射到构型空间的框架，实现实时力安全检测，适用于软体机器人在复杂环境中的安全操作。


<details>
  <summary>Details</summary>
Motivation: 现有避障方法未考虑软体机器人接触脆弱障碍物时的受力限制，需确保操作过程中的力安全性。

Method: 通过正向运动学将任务空间的允许接触力限制映射到构型空间，建立力安全准则的映射框架，并在配置空间中实时判断安全构型。

Result: 在模拟和硬件实验中验证了该方法能准确检测与可变形障碍物交互时的力安全性，支持实时安全规划。

Conclusion: 该方法能够有效保障软体机器人在复杂、脆弱环境中进行实时安全操作，为安全运动规划提供了基础。

Abstract: Soft robot manipulators have the potential for deployment in delicate
environments to perform complex manipulation tasks. However, existing obstacle
detection and avoidance methods do not consider limits on the forces that
manipulators may exert upon contact with delicate obstacles. This work
introduces a framework that maps force safety criteria from task space (i.e.
positions along the robot's body) to configuration space (i.e. the robot's
joint angles) and enables real-time force safety detection. We incorporate
limits on allowable environmental contact forces for given task-space
obstacles, and map them into configuration space (C-space) through the
manipulator's forward kinematics. This formulation ensures that configurations
classified as safe are provably below the maximum force thresholds, thereby
allowing us to determine force-safe configurations of the soft robot
manipulator in real-time. We validate our approach in simulation and hardware
experiments on a two-segment pneumatic soft robot manipulator. Results
demonstrate that the proposed method accurately detects force safety during
interactions with deformable obstacles, thereby laying the foundation for
real-time safe planning of soft manipulators in delicate, cluttered
environments.

</details>


### [211] [ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality](https://arxiv.org/abs/2511.05379)
*Eric Godden,Jacquie Groenewegen,Matthew K. X. J. Pan*

Main category: cs.RO

TL;DR: ETHOS 是一种动态的触觉显示系统，可在虚拟现实中的社交互动（如击掌、击拳和传递物品）中实现自然的物理接触。


<details>
  <summary>Details</summary>
Motivation: 在虚拟现实中实现有意义的社交触觉反馈，增强人际互动的真实感。

Method: 结合扭矩控制的机械臂、可更换的被动道具（如硅胶手模型）、基于标记的虚实配准和安全监控机制，并提出静态与动态两种控制策略。

Result: 静态模式下定位精度为 5.09 +/- 0.94 mm，用户交互平均接触延迟为 28.53 +/- 31.21 ms，实现了良好的时空对齐。

Conclusion: ETHOS 验证了在虚拟环境中重现社会性触觉的可行性，为高保真动态人际交互提供了实用基础。

Abstract: We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction),
a dynamic encountered-type haptic display (ETHD) that enables natural physical
contact in virtual reality (VR) during social interactions such as handovers,
fist bumps, and high-fives. The system integrates a torque-controlled robotic
manipulator with interchangeable passive props (silicone hand replicas and a
baton), marker-based physical-virtual registration via a ChArUco board, and a
safety monitor that gates motion based on the user's head and hand pose. We
introduce two control strategies: (i) a static mode that presents a stationary
prop aligned with its virtual counterpart, consistent with prior ETHD
baselines, and (ii) a dynamic mode that continuously updates prop position by
exponentially blending an initial mid-point trajectory with real-time hand
tracking, generating a unique contact point for each interaction. Bench tests
show static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions
achieved temporal alignment with an average contact latency of 28.53 +/- 31.21
ms across all interaction and control conditions. These results demonstrate the
feasibility of recreating socially meaningful haptics in VR. By incorporating
essential safety and control mechanisms, ETHOS establishes a practical
foundation for high-fidelity, dynamic interpersonal interactions in virtual
environments.

</details>


### [212] [EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation](https://arxiv.org/abs/2511.05397)
*Samarth Chopra,Alex McMoil,Ben Carnovale,Evan Sokolson,Rajkumar Kubendran,Samuel Dickerson*

Main category: cs.RO

TL;DR: EverydayVLA是一种低成本（<300美元）、6自由度的机械臂系统，结合统一的视觉-语言-动作模型与自适应规划机制，在标准和复杂场景中均表现出优异性能，显著提升机器人基础模型的可及性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型依赖昂贵硬件，且在新环境或杂乱场景中表现不佳，限制了其在家庭和研究实验室中的普及应用。

Method: 提出EverydayVLA，一种低成本、6-DOF机械臂；设计单一统一模型联合输出离散与连续动作，并采用自适应时域集成方法监控运动不确定性，实现动态重规划。

Result: 在LIBERO基准上达到最先进成功率；实际测试中，分布内任务性能超过先前方法49%，分布外任务提升34.9%。

Conclusion: 通过将先进的VLA模型与经济型硬件结合，EverydayVLA降低了使用门槛，推动了机器人基础模型在家庭和科研场景中的广泛应用。

Abstract: While Vision-Language-Action (VLA) models map visual inputs and language
instructions directly to robot actions, they often rely on costly hardware and
struggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF
manipulator that can be assembled for under $300, capable of modest payloads
and workspace. A single unified model jointly outputs discrete and continuous
actions, and our adaptive-horizon ensemble monitors motion uncertainty to
trigger on-the-fly re-planning for safe, reliable operation. On LIBERO,
EverydayVLA matches state-of-the-art success rates, and in real-world tests it
outperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.
By combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA
democratizes access to a robotic foundation model and paves the way for
economical use in homes and research labs alike. Experiment videos and details:
https://everydayvla.github.io/

</details>


### [213] [Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications](https://arxiv.org/abs/2511.05402)
*Muhammad Saud Ul Hassan,Derek Vasquez,Hamza Asif,Christian Hubicki*

Main category: cs.RO

TL;DR: 本文提出了一种基于能量守恒的控制架构，用于实现四足机器人稳定的动态运动，采用弹簧负载倒立摆（SLIP）模型并通过仿真验证了其在稳定弹跳步态中的有效性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了实现四足机器人在动态运动中的稳定性，借鉴生物四足动物的弹跳运动特性，设计一种能保持能量守恒的高效控制方法。

Method: 将机器人建模为弹簧负载倒立摆（SLIP），在飞行阶段控制腿的方向，在支撑阶段控制腿长，并利用能量守恒原理计算支撑阶段的稳定抛物线样条轨迹进行跟踪。

Result: 在Ghost Robotics Minitaur机器人上的仿真结果表明，该控制算法能够生成稳定的弹跳步态，并在传感器测量存在高达10%误差的情况下仍保持稳定。

Conclusion: 基于能量守恒的SLIP模型控制架构能有效实现四足机器人稳定且鲁棒的动态运动，适用于仿生弹跳步态的控制。

Abstract: In this paper, we present an energy-conservation based control architecture
for stable dynamic motion in quadruped robots. We model the robot as a
Spring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the
bouncing motion characteristic of running gaits observed in various biological
quadrupeds and bio-inspired robotic systems. The model permits leg-orientation
control during flight and leg-length control during stance, a design choice
inspired by natural quadruped behaviors and prevalent in robotic quadruped
systems. Our control algorithm uses the reduced-order SLIP dynamics of the
quadruped to track a stable parabolic spline during stance, which is calculated
using the principle of energy conservation. Through simulations based on the
design specifications of an actual quadruped robot, Ghost Robotics Minitaur, we
demonstrate that our control algorithm generates stable bouncing gaits.
Additionally, we illustrate the robustness of our controller by showcasing its
ability to maintain stable bouncing even when faced with up to a 10% error in
sensor measurements.

</details>


### [214] [Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience](https://arxiv.org/abs/2511.05426)
*Luca Girardi,Gabriel Maquignaz,Stefano Mintchev*

Main category: cs.RO

TL;DR: 提出了一种名为FlexiQuad的软体框架四旋翼设计，受生物体各向异性刚度和分布式质量-能量结构启发，显著提升了碰撞抗性和挤压能力，同时保持了高机动性。


<details>
  <summary>Details</summary>
Motivation: 传统四旋翼依靠刚性框架，限制了在复杂环境中的碰撞抗性和通过狭窄通道的能力，而自然界飞行生物使用柔性翅膀实现多种飞行行为，因此需要一种兼具敏捷性与鲁棒性的新设计。

Method: 基于生物启发的各向异性刚度和分布式质量-能量结构，设计并实现了一种软体框架四旋翼（FlexiQuad），通过材料和结构优化实现高顺应性与飞行性能的平衡。

Result: 405克的FlexiQuad原型比传统四旋翼顺应性高三个数量级，可实现超过80 km/h的速度和3g以上线加速度及300 rad/s²角加速度；能承受5 m/s正面撞击，斜碰反作用力降低39倍，可通过压缩至原宽70%的狭小缝隙。

Conclusion: FlexiQuad在0.006至0.77 N/mm的结构软度范围内，实现了敏捷性、挤压性和碰撞抗性的协同优化，适用于20至3000克的无人机平台，拓展了复杂环境中悬停无人机的操作能力。

Abstract: Natural flyers use soft wings to seamlessly enable a wide range of flight
behaviours, including agile manoeuvres, squeezing through narrow passageways,
and withstanding collisions. In contrast, conventional quadrotor designs rely
on rigid frames that support agile flight but inherently limit collision
resilience and squeezability, thereby constraining flight capabilities in
cluttered environments. Inspired by the anisotropic stiffness and distributed
mass-energy structures observed in biological organisms, we introduce
FlexiQuad, a soft-frame quadrotor design approach that limits this trade-off.
We demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more
compliant than conventional quadrotors, yet capable of acrobatic manoeuvres
with peak speeds above 80 km/h and linear and angular accelerations exceeding 3
g and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate
accelerations of rigid counterparts up to a thrust-to-weight ratio of 8.
Simultaneously, FlexiQuad exhibits fourfold higher collision resilience,
surviving frontal impacts at 5 m/s without damage and reducing destabilising
forces in glancing collisions by a factor of 39. Its frame can fully compress,
enabling flight through gaps as narrow as 70% of its nominal width. Our
analysis identifies an optimal structural softness range, from 0.006 to 0.77
N/mm, comparable to that of natural flyers' wings, whereby agility,
squeezability, and collision resilience are jointly achieved for FlexiQuad
models from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in
complex environments, enabling robust physical interactions without
compromising flight performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [215] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 团队Twente在2024年综合医疗排班竞赛中获得第三名，采用混合整数规划、约束规划和模拟退火的三阶段分解方法，并提供了基准实例的下界。


<details>
  <summary>Details</summary>
Motivation: 在医疗排班竞赛中实现高效且可行的解决方案，同时探索优化性能的潜力。

Method: 结合混合整数规划、约束规划和模拟退火，采用三阶段分解策略解决子问题。

Result: 在竞赛中排名第三，并首次为基准实例提供了最优解的下界。

Conclusion: 该方法有效，但仍存在改进空间，文中指出了未来可研究的开放性问题。

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [216] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 本文提出了一种基于认知不确定性（epistemic uncertainty）的拒绝预测方法，通过最小化预期遗憾来决定是否对输入进行拒绝，适用于数据不足场景下的可靠决策。


<details>
  <summary>Details</summary>
Motivation: 在高风险应用中，模型不仅需要准确预测，还需量化不确定性。传统方法仅关注随机不确定性，在数据有限时假设认知不确定性可忽略是不现实的，因此需要一种能识别因训练数据不足而导致不可靠预测的新方法。

Method: 基于贝叶斯学习，重新定义最优预测器为最小化预期遗憾（即学习模型与贝叶斯最优预测器之间的性能差距），当某输入的遗憾超过设定的拒绝成本时，模型选择 abstain（拒绝预测）。

Result: 提出了首个能够识别因训练数据不足而无法做出可靠决策的输入的原理性框架，并实现了基于认知不确定性的拒绝机制。

Conclusion: 该方法为数据稀缺场景下的不确定性建模和安全预测提供了新的理论基础和实用工具，增强了高风险应用中模型的可靠性。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [217] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: 本文提出了动态记忆对齐（DMA）框架，通过多粒度人类反馈实现检索增强生成系统在交互环境中的在线学习与排序优化。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统依赖静态检索，难以适应用户意图变化和内容漂移，需要一种能实时整合反馈的机制。

Method: DMA将文档级、列表级和响应级反馈整合为统一的学习流程，包括监督训练、策略优化和知识蒸馏，并引入双轨评估协议。

Result: 在线A/B测试显示显著提升用户参与度，离线测试在TriviaQA和HotpotQA等基准上取得明显增益，同时保持基础检索能力。

Conclusion: DMA为RAG系统提供了一种兼顾性能与实时适应性的原则性方法，适用于实际部署场景。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [218] [Real-Time Reasoning Agents in Evolving Environments](https://arxiv.org/abs/2511.04898)
*Yule Wen,Yixin Ye,Yanzhe Zhang,Diyi Yang,Hao Zhu*

Main category: cs.AI

TL;DR: 本文提出了实时推理（real-time reasoning）这一新问题，用于描述动态环境中智能体的决策挑战，并构建了Real-Time Reasoning Gym进行验证。研究比较了反应式和规划式两种语言模型代理范式，发现现有模型在逻辑性和时效性上均表现不足。为此，作者提出AgileThinker，结合两种推理模式，在任务难度和时间压力增加时显著优于单一模式代理。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的智能体需要在环境持续变化的同时进行及时且合理的判断，而现有语言模型推理方法未能充分考虑这种动态性。因此，亟需一种能兼顾推理深度与响应速度的新框架。

Method: 提出实时推理问题并构建Real-Time Reasoning Gym测试平台；研究反应式（有限推理步数）与规划式（扩展推理）两种范式；设计AgileThinker模型，同时融合两种推理模式以实现动态平衡。

Result: 实验表明，即使最先进的模型在两种单独范式下都难以兼顾逻辑性与时效性；AgileThinker在高任务难度和时间压力下始终优于单一范式代理，有效平衡了推理深度与响应延迟。

Conclusion: 实时推理是构建实用智能体的关键测试平台，AgileThinker为解决动态环境下的推理提供了可行路径，推动了时间受限AI系统的研究发展。

Abstract: Agents in the real world must make not only logical but also timely
judgments. This requires continuous awareness of the dynamic environment:
hazards emerge, opportunities arise, and other agents act, while the agent's
reasoning is still unfolding. Despite advances in language model reasoning,
existing approaches fail to account for this dynamic nature. We introduce
real-time reasoning as a new problem formulation for agents in evolving
environments and build Real-Time Reasoning Gym to demonstrate it. We study two
paradigms for deploying language models in agents: (1) reactive agents, which
employ language models with bounded reasoning computation for rapid responses,
and (2) planning agents, which allow extended reasoning computation for complex
problems. Our experiments show that even state-of-the-art models struggle with
making logical and timely judgments in either paradigm. To address this
limitation, we propose AgileThinker, which simultaneously engages both
reasoning paradigms. AgileThinker consistently outperforms agents engaging only
one reasoning paradigm as the task difficulty and time pressure rise,
effectively balancing reasoning depth and response latency. Our work
establishes real-time reasoning as a critical testbed for developing practical
agents and provides a foundation for research in temporally constrained AI
systems, highlighting a path toward real-time capable agents.

</details>


### [219] [ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property](https://arxiv.org/abs/2511.04956)
*Maria Mahbub,Vanessa Lama,Sanjay Das,Brian Starks,Christopher Polchek,Saffell Silvers,Lauren Deck,Prasanna Balaprakash,Tirthankar Ghosal*

Main category: cs.AI

TL;DR: ORCHID是一个模块化代理系统，用于美国能源部高风险财产分类，结合检索增强生成与人工监督，提升合规决策的准确性与可审计性。


<details>
  <summary>Details</summary>
Motivation: 传统专家主导的高风险财产分类流程耗时且难以应对不断变化的出口管制政策，亟需自动化、可追溯的解决方案。

Method: 采用基于检索增强生成（RAG）的多代理系统，包含检索、描述优化、分类、验证和反馈记录等协作代理，通过Model Context Protocol实现模型无关的本地运行，并构建从物品到证据再到决策的闭环流程。

Result: 在真实案例初步测试中，ORCHID相比非代理基线提升了分类准确性和可追溯性，能有效将不确定项交由领域专家处理，并生成可导出的审计文档。

Conclusion: ORCHID为敏感环境下的LLM辅助合规提供了可信、透明且可审计的实践路径。

Abstract: High-Risk Property (HRP) classification is critical at U.S. Department of
Energy (DOE) sites, where inventories include sensitive and often dual-use
equipment. Compliance must track evolving rules designated by various export
control policies to make transparent and auditable decisions. Traditional
expert-only workflows are time-consuming, backlog-prone, and struggle to keep
pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic
system for HRP classification that pairs retrieval-augmented generation (RAG)
with human oversight to produce policy-based outputs that can be audited. Small
cooperating agents, retrieval, description refiner, classifier, validator, and
feedback logger, coordinate via agent-to-agent messaging and invoke tools
through the Model Context Protocol (MCP) for model-agnostic on-premise
operation. The interface follows an Item to Evidence to Decision loop with
step-by-step reasoning, on-policy citations, and append-only audit bundles
(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID
improves accuracy and traceability over a non-agentic baseline while deferring
uncertain items to Subject Matter Experts (SMEs). The demonstration shows
single item submission, grounded citations, SME feedback capture, and
exportable audit artifacts, illustrating a practical path to trustworthy LLM
assistance in sensitive DOE compliance workflows.

</details>


### [220] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 提出一种支持军事地面作战执行阶段决策的方法，通过生成和评估机械化营的多种行动方案，结合敌方状态和行动进行优化推荐。


<details>
  <summary>Details</summary>
Motivation: 在动态变化的战场环境中，为决策者提供实时、有效的行动方案推荐，提升作战效率和决策质量。

Method: 系统化生成数千种行动方案，并基于预期结果、兵力对比、攻防类型等因素进行评估，结合并发的生成与评估流程，在顺序决策框架下持续优化推荐方案。

Result: 能够根据战场态势演变快速生成并更新备选行动方案，支持决策者在复杂环境中做出更优选择。

Conclusion: 该方法有效支持了军事作战中的动态决策过程，具备应对复杂战场环境的能力。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


### [221] [Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance](https://arxiv.org/abs/2511.05311)
*Valeriu Dimidov,Faisal Hawlader,Sasan Jafarnejad,Raphaël Frank*

Main category: cs.AI

TL;DR: 本文探讨了基于大语言模型（LLM）的智能体在汽车预测性维护（PdM）数据清洗中的应用潜力，特别是在处理维护日志中的多种噪声问题时表现出有效性，展示了LLM在工业实践中的前景。


<details>
  <summary>Details</summary>
Motivation: 经济限制、数据集可获得性低和专业人才短缺长期阻碍汽车领域预测性维护的发展，而大语言模型的进步为克服这些障碍提供了新机遇。

Method: 研究聚焦于维护日志的清洗任务，评估LLM智能体在处理六种不同类型噪声（如拼写错误、缺失字段、近似重复条目和错误日期）中的表现。

Result: LLM在通用清洗任务中表现有效，但在处理领域特定错误方面仍存在挑战。

Conclusion: LLM为PdM数据清洗提供了有前景的基础，未来通过专业化训练和增强智能体能力有望进一步提升其工业应用价值。

Abstract: Economic constraints, limited availability of datasets for reproducibility
and shortages of specialized expertise have long been recognized as key
challenges to the adoption and advancement of predictive maintenance (PdM) in
the automotive sector. Recent progress in large language models (LLMs) presents
an opportunity to overcome these barriers and speed up the transition of PdM
from research to industrial practice. Under these conditions, we explore the
potential of LLM-based agents to support PdM cleaning pipelines. Specifically,
we focus on maintenance logs, a critical data source for training
well-performing machine learning (ML) models, but one often affected by errors
such as typos, missing fields, near-duplicate entries, and incorrect dates. We
evaluate LLM agents on cleaning tasks involving six distinct types of noise.
Our findings show that LLMs are effective at handling generic cleaning tasks
and offer a promising foundation for future industrial applications. While
domain-specific errors remain challenging, these results highlight the
potential for further improvements through specialized training and enhanced
agentic capabilities.

</details>


### [222] [Reasoning Is All You Need for Urban Planning AI](https://arxiv.org/abs/2511.05375)
*Sijie Yang,Jiatong Li,Filip Biljecki*

Main category: cs.AI

TL;DR: 本文提出了一种面向城市规划的智能体AI框架，通过多智能体协作实现基于价值、规则和可解释性的推理决策，增强而非取代人类规划者的能力。


<details>
  <summary>Details</summary>
Motivation: 传统的统计学习方法在城市规划中缺乏透明推理、约束满足和价值观整合能力，难以支持复杂的决策需求，因此需要具备显式推理能力的AI系统。

Method: 构建包含感知、基础与推理三层认知结构及分析、生成、验证、评估、协作与决策六大逻辑组件的多智能体协作框架，并结合CoT、ReAct等先进推理技术。

Result: 提出了一个完整的Agentic Urban Planning AI架构，明确了其与传统统计学习的区别，设计了基准评估指标，并展示了其在方案探索、合规验证和权衡分析中的潜力。

Conclusion: 推理型AI智能体能够通过透明、规范且可解释的方式辅助城市规划决策，有效扩展人类规划师的能力，未来需进一步解决相关研究挑战以实现广泛应用。

Abstract: AI has proven highly successful at urban planning analysis -- learning
patterns from data to predict future conditions. The next frontier is
AI-assisted decision-making: agents that recommend sites, allocate resources,
and evaluate trade-offs while reasoning transparently about constraints and
stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,
ReAct, and multi-agent collaboration frameworks -- now make this vision
achievable.
  This position paper presents the Agentic Urban Planning AI Framework for
reasoning-capable planning agents that integrates three cognitive layers
(Perception, Foundation, Reasoning) with six logic components (Analysis,
Generation, Verification, Evaluation, Collaboration, Decision) through a
multi-agents collaboration framework. We demonstrate why planning decisions
require explicit reasoning capabilities that are value-based (applying
normative principles), rule-grounded (guaranteeing constraint satisfaction),
and explainable (generating transparent justifications) -- requirements that
statistical learning alone cannot fulfill. We compare reasoning agents with
statistical learning, present a comprehensive architecture with benchmark
evaluation metrics, and outline critical research challenges. This framework
shows how AI agents can augment human planners by systematically exploring
solution spaces, verifying regulatory compliance, and deliberating over
trade-offs transparently -- not replacing human judgment but amplifying it with
computational reasoning capabilities.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [223] [Association via Entropy Reduction](https://arxiv.org/abs/2511.04901)
*Anthony Gamst,Lawrence Wilson*

Main category: cs.IR

TL;DR: 提出一种新的相似性度量方法aver，在发现关联文档对方面优于传统的tf-idf，并具备自然阈值、可扩展性和理论基础等优势，但也更复杂且难以解释。


<details>
  <summary>Details</summary>
Motivation: 寻找比tf-idf更有效、更具理论基础的文档关联度量方法，特别是在图中识别相关节点的任务中。

Method: 提出名为aver的新评分方法，基于熵和简单统计模型推导，并在具有真实标记的关联数据集上与tf-idf进行比较。

Result: aver在识别关联文档对方面表现优于tf-idf；具备自然阈值、能区分tf-idf得分为1.0的文档对、适用于更大规模文档集合，且具有理论基础；但计算更复杂且评分更难解释。

Conclusion: aver是一种比tf-idf更优的关联发现方法，尤其适用于神经网络不占优势的场景，尽管其复杂性较高，但在理论上更自然、功能更强大。

Abstract: Prior to recent successes using neural networks, term frequency-inverse
document frequency (tf-idf) was clearly regarded as the best choice for
identifying documents related to a query. We provide a different score, aver,
and observe, on a dataset with ground truth marking for association, that aver
does do better at finding assciated pairs than tf-idf. This example involves
finding associated vertices in a large graph and that may be an area where
neural networks are not currently an obvious best choice. Beyond this one
anecdote, we observe that (1) aver has a natural threshold for declaring pairs
as unassociated while tf-idf does not, (2) aver can distinguish between pairs
of documents for which tf-idf gives a score of 1.0, (3) aver can be applied to
larger collections of documents than pairs while tf-idf cannot, and (4) that
aver is derived from entropy under a simple statistical model while tf-idf is a
construction designed to achieve a certain goal and hence aver may be more
"natural." To be fair, we also observe that (1) writing down and computing the
aver score for a pair is more complex than for tf-idf and (2) that the fact
that the aver score is naturally scale-free makes it more complicated to
interpret aver scores.

</details>


### [224] [Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG](https://arxiv.org/abs/2511.04939)
*Harshit Nainwani,Hediyeh Baban*

Main category: cs.IR

TL;DR: 提出了Search-Is-Not-Retrieve (SINR) 框架，将检索过程分为搜索和上下文获取两个层次，提升检索系统的可组合性、可扩展性和上下文保真度。


<details>
  <summary>Details</summary>
Motivation: 现有检索系统混淆了信息查找与上下文提供两个不同过程，导致上下文不完整或冗余，影响AI推理效果。

Method: 提出SINR双层架构，使用细粒度的搜索表示进行精准查找，并关联粗粒度的上下文块以支持推理，保持低计算开销。

Result: SINR框架能更有效地连接语义精确的小搜索块与上下文完整的大检索块，使检索从被动步骤转变为主动信息处理过程。

Conclusion: SINR为下一代基于检索的AI系统提供了更符合人类信息处理方式的实用架构基础。

Abstract: Retrieval systems are essential to contemporary AI pipelines, although most
confuse two separate processes: finding relevant information and giving enough
context for reasoning. We introduce the Search-Is-Not-Retrieve (SINR)
framework, a dual-layer architecture that distinguishes between fine-grained
search representations and coarse-grained retrieval contexts. SINR enhances the
composability, scalability, and context fidelity of retrieval systems by
directly connecting small, semantically accurate search chunks to larger,
contextually complete retrieve chunks, all without incurring extra processing
costs. This design changes retrieval from a passive step to an active one,
making the system architecture more like how people process information. We
discuss the SINR framework's conceptual foundation, formal structure,
implementation issues, and qualitative outcomes. This provides a practical
foundation for the next generation of AI systems that use retrieval.

</details>


### [225] [Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval](https://arxiv.org/abs/2511.05000)
*Hyunkyu Kim,Yeeun Yoo,Youngjun Kwak*

Main category: cs.IR

TL;DR: 提出了一种基于大语言模型的系统性方法来构建领域特定的信息检索基准，应用于银行领域并发布了KoBankIR数据集，实验表明现有检索模型在复杂查询上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有的信息检索基准无法捕捉真实银行场景中复杂且领域特定的信息需求，且构建领域特定基准成本高并受客户数据使用的法律限制。

Method: 结合单文档和多文档的查询生成方法，并引入增强的、推理增强的答案可判断性评估方法，通过大语言模型生成领域特定查询。

Result: 构建了包含815个查询和204份官方银行文档的KoBankIR数据集，实验证明现有检索模型在多文档复杂查询上表现较差，新方法在人类判断一致性上优于先前方法。

Conclusion: 所提出的系统性方法有效支持金融领域信息检索基准的构建，凸显了改进金融领域检索技术的必要性。

Abstract: As financial applications of large language models (LLMs) gain attention,
accurate Information Retrieval (IR) remains crucial for reliable AI services.
However, existing benchmarks fail to capture the complex and domain-specific
information needs of real-world banking scenarios. Building domain-specific IR
benchmarks is costly and constrained by legal restrictions on using real
customer data. To address these challenges, we propose a systematic methodology
for constructing domain-specific IR benchmarks through LLM-based query
generation. As a concrete implementation of this methodology, our pipeline
combines single and multi-document query generation with an enhanced and
reasoning-augmented answerability assessment method, achieving stronger
alignment with human judgments than prior approaches. Using this methodology,
we construct KoBankIR, comprising 815 queries derived from 204 official banking
documents. Our experiments show that existing retrieval models struggle with
the complex multi-document queries in KoBankIR, demonstrating the value of our
systematic approach for domain-specific benchmark construction and underscoring
the need for improved retrieval techniques in financial domains.

</details>


### [226] [Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR](https://arxiv.org/abs/2511.05079)
*Grigory Kovalev,Natalia Loukachevitch,Mikhail Tikhomirov,Olga Babina,Pavel Mamaev*

Main category: cs.IR

TL;DR: 本文提出了一系列基于俄语维基百科“你知道吗”部分构建的新型俄语信息检索数据集，支持事实核查、检索增强生成和全文检索等任务，并通过实验比较了词法模型与神经网络模型在不同任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 扩展现有的俄语信息检索资源，推动俄语环境下检索模型的研究与发展。

Method: 利用维基百科中带有句子级标注的有趣事实及其引用文章构建数据集，结合BM25、微调的俄语神经模型和多语言模型进行实验，并分析文档长度对检索性能的影响。

Result: 词法方法在全文检索上优于神经模型，而神经模型在短文本（如事实核查）中表现更好；结合神经重排序能持续提升检索效果。

Conclusion: 所构建的数据集丰富了俄语信息检索研究资源，强调了准确评估检索模型的重要性，且所有数据和代码均已公开。

Abstract: In this paper, we present a novel series of Russian information retrieval
datasets constructed from the "Did you know..." section of Russian Wikipedia.
Our datasets support a range of retrieval tasks, including fact-checking,
retrieval-augmented generation, and full-document retrieval, by leveraging
interesting facts and their referenced Wikipedia articles annotated at the
sentence level with graded relevance. We describe the methodology for dataset
creation that enables the expansion of existing Russian Information Retrieval
(IR) resources. Through extensive experiments, we extend the RusBEIR research
by comparing lexical retrieval models, such as BM25, with state-of-the-art
neural architectures fine-tuned for Russian, as well as multilingual models.
Results of our experiments show that lexical methods tend to outperform neural
models on full-document retrieval, while neural approaches better capture
lexical semantics in shorter texts, such as in fact-checking or fine-grained
retrieval. Using our newly created datasets, we also analyze the impact of
document length on retrieval performance and demonstrate that combining
retrieval with neural reranking consistently improves results. Our contribution
expands the resources available for Russian information retrieval research and
highlights the importance of accurate evaluation of retrieval models to achieve
optimal performance. All datasets are publicly available at HuggingFace. To
facilitate reproducibility and future research, we also release the full
implementation on GitHub.

</details>


### [227] [QUESTER: Query Specification for Generative Retrieval](https://arxiv.org/abs/2511.05301)
*Arthur Satouf,Yuxuan Zong,Habiboulaye Amadou-Boubacar,Pablo Piantanida,Benjamin Piwowarski*

Main category: cs.IR

TL;DR: 提出QUESTER方法，通过小规模LLM生成查询关键词用于生成式检索，结合强化学习训练，在保持高效的同时优于BM25并媲美神经IR模型。


<details>
  <summary>Details</summary>
Motivation: 生成式检索（GR）在泛化和扩展性方面存在困难，传统方法依赖索引后检索的流程，而GR直接生成文档标识符但效率较低。

Method: 将生成式检索重构为查询特定生成任务，使用小型语言模型生成适用于BM25的关键词查询，并采用GRPO强化学习技术进行策略训练。

Result: 在域内和跨域评估中，QUESTER优于BM25，与神经信息检索模型性能相当，同时保持较高的检索效率。

Conclusion: QUESTER通过查询生成方式改进了生成式检索的泛化能力和可扩展性，为高效检索提供了一种新思路。

Abstract: Generative Retrieval (GR) differs from the traditional index-then-retrieve
pipeline by storing relevance in model parameters and directly generating
document identifiers. However, GR often struggles to generalize and is costly
to scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval),
which reframes GR as query specification generation - in this work, a simple
keyword query handled by BM25 - using a (small) LLM. The policy is trained
using reinforcement learning techniques (GRPO). Across in- and out-of-domain
evaluations, we show that our model is more effective than BM25, and
competitive with neural IR models, while maintaining a good efficiency

</details>


### [228] [TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2511.05385)
*Chao Zhang,Yuhao Wang,Derong Xu,Haoxin Zhang,Yuanjie Lyu,Yuhao Chen,Shuochen Liu,Tong Xu,Xiangyu Zhao,Yan Gao,Yao Hu,Enhong Chen*

Main category: cs.IR

TL;DR: TeaRAG 是一种高效的检索增强生成框架，通过图检索与知识压缩减少 token 使用，同时利用迭代优化提升推理简洁性，在多个数据集上显著降低输出 token 数量的同时提高了准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的代理式 RAG 方法在提高准确性的同时引入了高昂的 token 开销，牺牲了效率，因此需要一种兼顾准确性和效率的新型 RAG 框架。

Method: 1) 结合基于语义的块检索与使用简洁三元组的图检索构建知识关联图，并利用 Personalized PageRank 突出关键知识以压缩检索内容；2) 提出 Iterative Process-aware Direct Preference Optimization (IP-DPO)，通过知识匹配机制评估知识充分性并惩罚冗余推理步骤，从而减少推理轮次。

Result: 在六个数据集上，TeaRAG 在 Llama3-8B-Instruct 和 Qwen2.5-14B-Instruct 上分别将输出 token 减少了 61% 和 59%，同时平均精确匹配率分别提升了 4% 和 2%。

Conclusion: TeaRAG 成功实现了在保持甚至提升性能的同时大幅减少 token 消耗，为高效、实用的代理式 RAG 提供了一种可行方案。

Abstract: Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment
Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs
autonomous, multi-round retrieval and reasoning to resolve queries. Although
recent agentic RAG has improved via reinforcement learning, they often incur
substantial token overhead from search and reasoning processes. This trade-off
prioritizes accuracy over efficiency. To address this issue, this work proposes
TeaRAG, a token-efficient agentic RAG framework capable of compressing both
retrieval content and reasoning steps. 1) First, the retrieved content is
compressed by augmenting chunk-based semantic retrieval with a graph retrieval
using concise triplets. A knowledge association graph is then built from
semantic similarity and co-occurrence. Finally, Personalized PageRank is
leveraged to highlight key knowledge within this graph, reducing the number of
tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative
Process-aware Direct Preference Optimization (IP-DPO) is proposed.
Specifically, our reward function evaluates the knowledge sufficiency by a
knowledge matching mechanism, while penalizing excessive reasoning steps. This
design can produce high-quality preference-pair datasets, supporting iterative
DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the
average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on
Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at
https://github.com/Applied-Machine-Learning-Lab/TeaRAG.

</details>
