<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 52]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.AI](#cs.AI) [Total: 30]
- [cs.LG](#cs.LG) [Total: 88]
- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GAZE:Governance-Aware pre-annotation for Zero-shot World Model Environments](https://arxiv.org/abs/2510.14992)
*Leela Krishna,Mengyang Zhao,Saicharithreddy Pasula,Harshit Rajgarhia,Abhishek Mukherji*

Main category: cs.CV

TL;DR: 提出GAZE自动化流水线，将原始长视频转换为可用于世界模型训练的高质量、多模态标注数据，显著提升标注效率并降低人工审核量。


<details>
  <summary>Details</summary>
Motivation: 传统手动标注多模态数据耗时且昂贵，制约了世界模型的训练效率和规模。

Method: 通过标准化360度视频格式、并行处理，结合多种AI模型进行密集预标注，并整合信号生成结构化输出，支持快速人工验证。

Result: 每审核小时节省约19分钟，人工审核量减少超过80%，同时提高标签密度、一致性和隐私保护。

Conclusion: GAZE提供了一个可扩展的蓝图，能高效生成高保真、隐私安全的世界模型训练数据，兼顾吞吐量与治理需求。

Abstract: Training robust world models requires large-scale, precisely labeled
multimodal datasets, a process historically bottlenecked by slow and expensive
manual annotation. We present a production-tested GAZE pipeline that automates
the conversion of raw, long-form video into rich, task-ready supervision for
world-model training. Our system (i) normalizes proprietary 360-degree formats
into standard views and shards them for parallel processing; (ii) applies a
suite of AI models (scene understanding, object tracking, audio transcription,
PII/NSFW/minor detection) for dense, multimodal pre-annotation; and (iii)
consolidates signals into a structured output specification for rapid human
validation.
  The GAZE workflow demonstrably yields efficiency gains (~19 minutes saved per
review hour) and reduces human review volume by >80% through conservative
auto-skipping of low-salience segments. By increasing label density and
consistency while integrating privacy safeguards and chain-of-custody metadata,
our method generates high-fidelity, privacy-aware datasets directly consumable
for learning cross-modal dynamics and action-conditioned prediction. We detail
our orchestration, model choices, and data dictionary to provide a scalable
blueprint for generating high-quality world model training data without
sacrificing throughput or governance.

</details>


### [2] [PC-UNet: An Enforcing Poisson Statistics U-Net for Positron Emission Tomography Denoising](https://arxiv.org/abs/2510.14995)
*Yang Shi,Jingchao Wang,Liangsi Lu,Mingxuan Huang,Ruixin He,Yifeng Xie,Hanqian Liu,Minzhe Guo,Yangyang Liang,Weipeng Zhang,Zimeng Li,Xuhang Chen*

Main category: cs.CV

TL;DR: 提出了一种基于物理一致性的PC-UNet模型和PVMC-Loss，用于低剂量PET图像去噪，显著提升图像保真度与一致性。


<details>
  <summary>Details</summary>
Motivation: 低剂量PET成像因泊松噪声严重，现有方法去噪效果差，易引入伪影，限制了临床应用。

Method: 设计PC-UNet网络结构，并提出PVMC-Loss损失函数，结合物理数据建模，确保统计无偏性和梯度适应性，采用广义矩方法实现鲁棒去噪。

Result: 在PET数据集上验证，PC-UNet在物理一致性和图像质量方面优于现有方法，有效抑制噪声并保留细节。

Conclusion: PC-UNet通过融合物理先验信息，显著提升了低剂量PET图像的去噪性能，具有良好的临床应用潜力。

Abstract: Positron Emission Tomography (PET) is crucial in medicine, but its clinical
use is limited due to high signal-to-noise ratio doses increasing radiation
exposure. Lowering doses increases Poisson noise, which current denoising
methods fail to handle, causing distortions and artifacts. We propose a Poisson
Consistent U-Net (PC-UNet) model with a new Poisson Variance and Mean
Consistency Loss (PVMC-Loss) that incorporates physical data to improve image
fidelity. PVMC-Loss is statistically unbiased in variance and gradient
adaptation, acting as a Generalized Method of Moments implementation, offering
robustness to minor data mismatches. Tests on PET datasets show PC-UNet
improves physical consistency and image fidelity, proving its ability to
integrate physical information effectively.

</details>


### [3] [DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.15015)
*Mor Ventura,Michael Toker,Or Patashnik,Yonatan Belinkov,Roi Reichart*

Main category: cs.CV

TL;DR: 本文提出了一种名为DeLeaker的轻量级、无需优化的推理时方法，通过直接干预模型注意力图来缓解文本到图像生成中的语义泄漏问题，并引入首个专门针对该问题的数据集SLIM和自动评估框架。实验表明，DeLeaker在不牺牲生成质量的前提下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像模型发展迅速，但其存在语义泄漏问题，即不同实体间语义特征的非预期传递，影响生成结果的准确性，亟需有效且高效的缓解方法。

Method: 提出DeLeaker方法，在扩散过程中动态重加权注意力图，抑制实体间的过度交互并增强各实体自身身份表达；同时构建SLIM数据集及自动评估框架以支持系统性评测。

Result: 实验结果显示，DeLeaker在多种场景下均一致优于基线方法，即使这些方法使用外部信息也未能超越；且该方法不依赖优化过程，不影响生成图像的质量与保真度。

Conclusion: DeLeaker通过注意力控制有效缓解了语义泄漏问题，验证了注意力机制调控在提升T2I模型语义精确性方面的潜力，为未来研究提供了新方向。

Abstract: Text-to-Image (T2I) models have advanced rapidly, yet they remain vulnerable
to semantic leakage, the unintended transfer of semantically related features
between distinct entities. Existing mitigation strategies are often
optimization-based or dependent on external inputs. We introduce DeLeaker, a
lightweight, optimization-free inference-time approach that mitigates leakage
by directly intervening on the model's attention maps. Throughout the diffusion
process, DeLeaker dynamically reweights attention maps to suppress excessive
cross-entity interactions while strengthening the identity of each entity. To
support systematic evaluation, we introduce SLIM (Semantic Leakage in IMages),
the first dataset dedicated to semantic leakage, comprising 1,130
human-verified samples spanning diverse scenarios, together with a novel
automatic evaluation framework. Experiments demonstrate that DeLeaker
consistently outperforms all baselines, even when they are provided with
external information, achieving effective leakage mitigation without
compromising fidelity or quality. These results underscore the value of
attention control and pave the way for more semantically precise T2I models.

</details>


### [4] [UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos](https://arxiv.org/abs/2510.15018)
*Mingxuan Liu,Honglin He,Elisa Ricci,Wayne Wu,Bolei Zhou*

Main category: cs.CV

TL;DR: UrbanVerse是一个数据驱动的从真实到仿真的系统，能将众包的城市游览视频转化为具有物理感知能力的交互式仿真场景，支持大规模、高保真城市AI代理训练。


<details>
  <summary>Details</summary>
Motivation: 现有手工或程序化生成的城市仿真环境缺乏可扩展性或无法充分捕捉现实世界的复杂性，难以满足城市具身AI代理训练的需求。

Method: 提出UrbanVerse系统，包括UrbanVerse-100K（包含超10万带语义和物理属性标注的城市3D资产库）和UrbanVerse-Gen（从视频中自动提取布局并实例化为度量级3D仿真的自动化流程），在IsaacSim中运行。

Result: 构建了来自24个国家的160个高质量仿真场景和10个艺术家设计的测试场景；实验显示仿真场景保持了真实的语义与布局，人类评估的逼真度媲美手工场景；在城市导航任务中，训练出的策略表现出良好的缩放律和泛化能力，仿真中成功率提升6.3%，零样本sim-to-real迁移中提升30.1%，实现在仅两次干预下完成300米真实世界任务。

Conclusion: UrbanVerse实现了高保真、可扩展的城市仿真环境自动生成，显著提升了城市AI代理在现实世界中的部署能力和泛化性能。

Abstract: Urban embodied AI agents, ranging from delivery robots to quadrupeds, are
increasingly populating our cities, navigating chaotic streets to provide
last-mile connectivity. Training such agents requires diverse, high-fidelity
urban environments to scale, yet existing human-crafted or procedurally
generated simulation scenes either lack scalability or fail to capture
real-world complexity. We introduce UrbanVerse, a data-driven real-to-sim
system that converts crowd-sourced city-tour videos into physics-aware,
interactive simulation scenes. UrbanVerse consists of: (i) UrbanVerse-100K, a
repository of 100k+ annotated urban 3D assets with semantic and physical
attributes, and (ii) UrbanVerse-Gen, an automatic pipeline that extracts scene
layouts from video and instantiates metric-scale 3D simulations using retrieved
assets. Running in IsaacSim, UrbanVerse offers 160 high-quality constructed
scenes from 24 countries, along with a curated benchmark of 10 artist-designed
test scenes. Experiments show that UrbanVerse scenes preserve real-world
semantics and layouts, achieving human-evaluated realism comparable to manually
crafted scenes. In urban navigation, policies trained in UrbanVerse exhibit
scaling power laws and strong generalization, improving success by +6.3% in
simulation and +30.1% in zero-shot sim-to-real transfer comparing to prior
methods, accomplishing a 300 m real-world mission with only two interventions.

</details>


### [5] [NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks](https://arxiv.org/abs/2510.15019)
*Junliang Ye,Shenghao Xie,Ruowen Zhao,Zhengyi Wang,Hongyu Yan,Wenqiang Zu,Lei Ma,Jun Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的3D物体编辑框架Nano3D，通过结合FlowEdit与TRELLIS，并引入区域感知的合并策略，在不使用掩码的情况下实现精确且一致的3D编辑。同时构建了大规模3D编辑数据集Nano3D-Edit-100k，推动了3D编辑算法的发展。


<details>
  <summary>Details</summary>
Motivation: 现有的3D物体编辑方法依赖多视角渲染与重建，效率低、一致性差，且难以保持未编辑区域的结构完整性，因此需要一种更高效、一致且无需训练的编辑框架。

Method: Nano3D将FlowEdit集成到TRELLIS中，利用前视图渲染进行局部编辑，并提出Voxel/Slat-Merge区域感知合并策略，自适应地保持编辑与未编辑区域之间的一致性，从而在无需训练和掩码的情况下实现高质量3D编辑。

Result: 实验表明，Nano3D在3D一致性与视觉质量上优于现有方法，并成功构建了包含超过10万对高质量3D编辑样本的数据集Nano3D-Edit-100k。

Conclusion: Nano3D有效解决了3D编辑中的长期挑战，提升了编辑的通用性和可靠性，为前馈式3D编辑模型的发展奠定了基础。

Abstract: 3D object editing is essential for interactive content creation in gaming,
animation, and robotics, yet current approaches remain inefficient,
inconsistent, and often fail to preserve unedited regions. Most methods rely on
editing multi-view renderings followed by reconstruction, which introduces
artifacts and limits practicality. To address these challenges, we propose
Nano3D, a training-free framework for precise and coherent 3D object editing
without masks. Nano3D integrates FlowEdit into TRELLIS to perform localized
edits guided by front-view renderings, and further introduces region-aware
merging strategies, Voxel/Slat-Merge, which adaptively preserve structural
fidelity by ensuring consistency between edited and unedited areas. Experiments
demonstrate that Nano3D achieves superior 3D consistency and visual quality
compared with existing methods. Based on this framework, we construct the first
large-scale 3D editing datasets Nano3D-Edit-100k, which contains over 100,000
high-quality 3D editing pairs. This work addresses long-standing challenges in
both algorithm design and data availability, significantly improving the
generality and reliability of 3D editing, and laying the groundwork for the
development of feed-forward 3D editing models. Project
Page:https://jamesyjl.github.io/Nano3D

</details>


### [6] [Constantly Improving Image Models Need Constantly Improving Benchmarks](https://arxiv.org/abs/2510.15021)
*Jiaxin Ge,Grace Luo,Heekyung Lee,Nishant Malpani,Long Lian,XuDong Wang,Aleksander Holynski,Trevor Darrell,Sewon Min,David M. Chan*

Main category: cs.CV

TL;DR: 本文提出了ECHO框架，利用社交媒体上的真实用户使用案例构建图像生成模型的评估基准，揭示了现有基准未覆盖的复杂任务，并改进了模型性能的评估方式。


<details>
  <summary>Details</summary>
Motivation: 现有基准滞后于图像生成技术的发展，无法捕捉新兴应用场景，导致社区认知与正式评估之间存在差距。

Method: 通过分析GPT-4o Image Gen在社交媒体上的实际使用情况，收集超过31,000个提示语，构建ECHO数据集，并基于真实用户反馈设计评估指标。

Result: ECHO能够发现现有基准中没有的创造性任务，更好地区分最先进模型与其它模型，并根据社区反馈提出衡量颜色、身份和结构变化的质量指标。

Conclusion: ECHO为图像生成模型提供了一种基于真实世界证据的动态评估方法，有效弥补了传统基准的不足。

Abstract: Recent advances in image generation, often driven by proprietary systems like
GPT-4o Image Gen, regularly introduce new capabilities that reshape how users
interact with these models. Existing benchmarks often lag behind and fail to
capture these emerging use cases, leaving a gap between community perceptions
of progress and formal evaluation. To address this, we present ECHO, a
framework for constructing benchmarks directly from real-world evidence of
model use: social media posts that showcase novel prompts and qualitative user
judgments. Applying this framework to GPT-4o Image Gen, we construct a dataset
of over 31,000 prompts curated from such posts. Our analysis shows that ECHO
(1) discovers creative and complex tasks absent from existing benchmarks, such
as re-rendering product labels across languages or generating receipts with
specified totals, (2) more clearly distinguishes state-of-the-art models from
alternatives, and (3) surfaces community feedback that we use to inform the
design of metrics for model quality (e.g., measuring observed shifts in color,
identity, and structure). Our website is at https://echo-bench.github.io.

</details>


### [7] [LoRAverse: A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models](https://arxiv.org/abs/2510.15022)
*Mert Sonmezer,Matthew Zheng,Pinar Yanardag*

Main category: cs.CV

TL;DR: 本文提出了一种基于子模优化框架的方法，用于从大量LoRA适配器中选择最相关且多样化的模型，以提升预训练扩散模型的个性化效果。


<details>
  <summary>Details</summary>
Motivation: 由于现有平台上存在超过10万种LoRA适配器，用户在选择和使用合适适配器时面临困难，主要问题包括数量庞大、多样性高以及缺乏结构化组织。

Method: 将LoRA模型的选择问题建模为组合优化问题，并提出一种新颖的子模函数框架来实现相关性和多样性之间的平衡。

Result: 通过定量和定性实验验证了该方法在广泛领域内能够生成多样化输出，并有效选出合适的LoRA适配器组合。

Conclusion: 所提出的子模框架能够高效地从大规模LoRA数据库中筛选出既相关又多样的适配器，提升了个性化内容生成的效果与用户体验。

Abstract: Low-rank Adaptation (LoRA) models have revolutionized the personalization of
pre-trained diffusion models by enabling fine-tuning through low-rank,
factorized weight matrices specifically optimized for attention layers. These
models facilitate the generation of highly customized content across a variety
of objects, individuals, and artistic styles without the need for extensive
retraining. Despite the availability of over 100K LoRA adapters on platforms
like Civit.ai, users often face challenges in navigating, selecting, and
effectively utilizing the most suitable adapters due to their sheer volume,
diversity, and lack of structured organization. This paper addresses the
problem of selecting the most relevant and diverse LoRA models from this vast
database by framing the task as a combinatorial optimization problem and
proposing a novel submodular framework. Our quantitative and qualitative
experiments demonstrate that our method generates diverse outputs across a wide
range of domains.

</details>


### [8] [MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning](https://arxiv.org/abs/2510.15026)
*Mattia Segu,Marta Tintore Gazulla,Yongqin Xian,Luc Van Gool,Federico Tombari*

Main category: cs.CV

TL;DR: MOBIUS是一种面向高效部署的通用实例分割基础模型家族，通过结构优化和训练策略创新，在显著降低计算量的同时保持最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有大模型因计算成本高，难以在资源受限设备上部署，亟需在不牺牲性能的前提下实现高效下采样和轻量化。

Method: 提出MOBIUS模型家族，包含高效的瓶颈像素解码器、语言引导的不确定性校准损失以实现自适应剪枝，以及简化的统一训练策略。

Result: 相比基线模型，MOBIUS将像素解码器和Transformer解码器的FLOPs分别减少最多55%和75%，且仅用三分之一的训练迭代次数即达到最先进的分割性能。

Conclusion: MOBIUS在高性能计算平台和移动设备上均实现了高效实例分割的新标杆，兼顾精度与效率，适合跨设备部署。

Abstract: Scaling up model size and training data has advanced foundation models for
instance-level perception, achieving state-of-the-art in-domain and zero-shot
performance across object detection and segmentation. However, their high
computational cost limits adoption on resource-constrained platforms. We first
examine the limitations of existing architectures in enabling efficient edge
deployment without compromising performance. We then introduce MOBIUS, a family
of foundation models for universal instance segmentation, designed for
Pareto-optimal downscaling to support deployment across devices ranging from
high-end accelerators to mobile hardware. To reduce training and inference
demands, we propose: (i) a bottleneck pixel decoder for efficient multi-scale
and multi-modal fusion, (ii) a language-guided uncertainty calibration loss for
adaptive decoder pruning, and (iii) a streamlined, unified training strategy.
Unlike efficient baselines that trade accuracy for reduced complexity, MOBIUS
reduces pixel and transformer decoder FLOPs by up to 55% and 75%, respectively,
while maintaining state-of-the-art performance in just a third of the training
iterations. MOBIUS establishes a new benchmark for efficient segmentation on
both high-performance computing platforms and mobile devices.

</details>


### [9] [Composition-Grounded Instruction Synthesis for Visual Reasoning](https://arxiv.org/abs/2510.15040)
*Xinyi Gu,Jiayuan Mao,Zhang-Wei Hong,Zhuoran Yu,Pengyuan Li,Dhiraj Joshi,Rogerio Feris,Zexue He*

Main category: cs.CV

TL;DR: 本文提出了COGS框架，通过将少量种子问题分解为基本感知和推理因子，并重新组合生成大量合成问答对，从而提升多模态大模型在缺乏标注数据的人工图像领域的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型在标注稀缺的人工图像领域（如图表、网页）推理能力有限，缺乏大规模标注数据集。

Method: 提出COGS框架，将种子问题分解为感知与推理因子，跨图像重组生成合成问答数据，并结合因子级过程奖励进行强化学习。

Result: 在图表推理任务上显著提升模型对未见问题的性能，尤其在复杂推理和组合性问题上效果明显；跨数据集迁移表现良好，且可扩展至网页等其他领域。

Conclusion: COGS是一种数据高效的训练框架，能有效增强多模态大模型在人工图像域的通用推理能力，避免过拟合，具备良好泛化性和扩展性。

Abstract: Pretrained multi-modal large language models (MLLMs) demonstrate strong
performance on diverse multimodal tasks, but remain limited in reasoning
capabilities for domains where annotations are difficult to collect. In this
work, we focus on artificial image domains such as charts, rendered documents,
and webpages, which are abundant in practice yet lack large-scale human
annotated reasoning datasets. We introduce COGS (COmposition-Grounded
instruction Synthesis), a data-efficient framework for equipping MLLMs with
advanced reasoning abilities from a small set of seed questions. The key idea
is to decompose each seed question into primitive perception and reasoning
factors, which can then be systematically recomposed with new images to
generate large collections of synthetic question-answer pairs. Each generated
question is paired with subquestions and intermediate answers, enabling
reinforcement learning with factor-level process rewards. Experiments on chart
reasoning show that COGS substantially improves performance on unseen
questions, with the largest gains on reasoning-heavy and compositional
questions. Moreover, training with a factor-level mixture of different seed
data yields better transfer across multiple datasets, suggesting that COGS
induces generalizable capabilities rather than dataset-specific overfitting. We
further demonstrate that the framework extends beyond charts to other domains
such as webpages.

</details>


### [10] [Generalized Dynamics Generation towards Scannable Physical World Model](https://arxiv.org/abs/2510.15041)
*Yichen Li,Zhiyi Li,Brandon Feng,Dinghuai Zhang,Antonio Torralba*

Main category: cs.CV

TL;DR: 本文提出了GDGen，一种从势能角度统一刚体、铰接体和软体动力学的通用框架，通过引入方向刚度和神经场实现几何无关的物理模拟，为复杂动态场景中的虚拟环境构建和机器人训练提供了新基础。


<details>
  <summary>Details</summary>
Motivation: 为了在具有复杂物理行为的可扫描环境中开发通用具身智能体，需要一个能够统一多种物理动力学的框架。

Method: 提出GDGen框架，基于势能最小化原理，扩展经典弹性动力学以引入方向刚度，并使用专用网络建模材料属性，采用神经场几何无关地表示形变。

Result: 实验表明GDGen能稳健地统一多种物理模拟范式，在不同物理系统中实现了准确的动力学预测与仿真。

Conclusion: GDGen提供了一个统一、几何无关的物理建模范式，为构建交互式虚拟环境和训练复杂动态场景下的机器人代理奠定了基础。

Abstract: Digital twin worlds with realistic interactive dynamics presents a new
opportunity to develop generalist embodied agents in scannable environments
with complex physical behaviors. To this end, we present GDGen (Generalized
Representation for Generalized Dynamics Generation), a framework that takes a
potential energy perspective to seamlessly integrate rigid body, articulated
body, and soft body dynamics into a unified, geometry-agnostic system. GDGen
operates from the governing principle that the potential energy for any stable
physical system should be low. This fresh perspective allows us to treat the
world as one holistic entity and infer underlying physical properties from
simple motion observations. We extend classic elastodynamics by introducing
directional stiffness to capture a broad spectrum of physical behaviors,
covering soft elastic, articulated, and rigid body systems. We propose a
specialized network to model the extended material property and employ a neural
field to represent deformation in a geometry-agnostic manner. Extensive
experiments demonstrate that GDGen robustly unifies diverse simulation
paradigms, offering a versatile foundation for creating interactive virtual
environments and training robotic agents in complex, dynamically rich
scenarios.

</details>


### [11] [Comprehensive language-image pre-training for 3D medical image understanding](https://arxiv.org/abs/2510.15042)
*Tassilo Wald,Ibrahim Ethem Hamamci,Yuan Gao,Sam Bond-Taylor,Harshita Sharma,Maximilian Ilse,Cynthia Lo,Olesya Melnichenko,Noel C. F. Codella,Maria Teodora Wetscherek,Klaus H. Maier-Hein,Panagiotis Korfiatis,Valentina Salvatelli,Javier Alvarez-Valle,Fernando Pérez-García*

Main category: cs.CV

TL;DR: 本文提出了COLIPRI模型家族，通过引入报告生成目标和结合视觉-语言与纯视觉预训练，增强了3D医学图像领域的数据利用，实现了在报告生成、分类探测和零样本分类上的最先进性能，并在语义分割任务中保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 由于3D医学图像领域配对的图像-文本数据稀缺，限制了现有视觉-语言编码器的能力，因此需要新的方法来缓解数据不足的问题。

Method: 引入额外的归纳偏置：添加报告生成目标，并将视觉-语言预训练与纯视觉预训练相结合，从而利用仅图像和配对的图像-文本3D数据集。

Result: COLIPRI编码器在报告生成、分类探针和零样本分类任务上达到最先进的性能，在语义分割任务中也具有竞争力。

Conclusion: 通过引入更强的归纳偏置并结合领域最佳实践，COLIPRI有效利用多种数据源，显著提升了3D医学视觉-语言模型的性能。

Abstract: Vision-language pre-training, i.e., aligning images with paired text, is a
powerful paradigm to create encoders that can be directly used for tasks such
as classification and retrieval, and for downstream tasks such as segmentation
and report generation. In the 3D medical image domain, these capabilities allow
vision-language encoders (VLEs) to support radiologists by retrieving patients
with similar abnormalities or predicting likelihoods of abnormality. While the
methodology holds promise, data availability limits the capabilities of current
3D VLEs.
  In this paper, we alleviate the lack of data by injecting additional
inductive biases: introducing a report generation objective and pairing
vision-language pre-training with vision-only pre-training. This allows us to
leverage both image-only and paired image-text 3D datasets, increasing the
total amount of data to which our model is exposed. Through these additional
inductive biases, paired with best practices of the 3D medical imaging domain,
we develop the Comprehensive Language-image Pre-training (COLIPRI) encoder
family. Our COLIPRI encoders achieve state-of-the-art performance in report
generation, classification probing, and zero-shot classification, and remain
competitive for semantic segmentation.

</details>


### [12] [Directional Reasoning Injection for Fine-Tuning MLLMs](https://arxiv.org/abs/2510.15050)
*Chao Huang,Zeliang Zhang,Jiang Liu,Ximeng Sun,Jialian Wu,Xiaodong Yu,Ze Wang,Chenliang Xu,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: 提出DRIFT方法，通过梯度空间中的定向推理注入，在不破坏多模态对齐的前提下，高效提升多模态大模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有提升多模态大语言模型推理能力的方法依赖大规模标注数据或强化学习，资源消耗大；模型合并虽有潜力但效果不稳定，需更有效的知识迁移方式。

Method: 预计算推理增强模型与多模态模型之间的参数差异作为推理先验，并在多模态微调过程中将其用于引导梯度更新方向，实现推理知识的定向注入。

Result: 在MathVista和MathVerse等多模态推理基准上，DRIFT显著优于朴素模型合并和监督微调，性能媲美高成本训练方法，但计算开销更低。

Conclusion: DRIFT提供了一种轻量、高效且稳定的推理能力迁移方案，能够在保持多模态对齐的同时有效提升多模态大模型的推理表现。

Abstract: Multimodal large language models (MLLMs) are rapidly advancing, yet their
reasoning ability often lags behind that of strong text-only counterparts.
Existing methods to bridge this gap rely on supervised fine-tuning over
large-scale multimodal reasoning data or reinforcement learning, both of which
are resource-intensive. A promising alternative is model merging, which
interpolates parameters between reasoning-enhanced LLMs and multimodal
variants. However, our analysis shows that naive merging is not always a "free
lunch": its effectiveness varies drastically across model families, with some
(e.g., LLaVA, Idefics) benefiting while others (e.g., Qwen) suffer performance
degradation. To address this, we propose Directional Reasoning Injection for
Fine-Tuning (DRIFT) MLLMs, a lightweight method that transfers reasoning
knowledge in the gradient space, without destabilizing multimodal alignment.
DRIFT precomputes a reasoning prior as the parameter-space difference between
reasoning and multimodal variants, then uses it to bias gradients during
multimodal fine-tuning. This approach preserves the simplicity of standard
supervised fine-tuning pipelines while enabling efficient reasoning transfer.
Extensive experiments on multimodal reasoning benchmarks, including MathVista
and MathVerse, demonstrate that DRIFT consistently improves reasoning
performance over naive merging and supervised fine-tuning, while matching or
surpassing training-heavy methods at a fraction of the cost.

</details>


### [13] [MSAM: Multi-Semantic Adaptive Mining for Cross-Modal Drone Video-Text Retrieval](https://arxiv.org/abs/2510.15470)
*Jinghao Huang,Yaxiong Chen,Ganchao Liu*

Main category: cs.CV

TL;DR: 本文首次提出并研究了无人机视频-文本检索（DVTR）任务，提出了一种名为多语义自适应挖掘（MSAM）的新方法，通过细粒度的文本与视频帧交互和跨模态特征融合机制，在自建数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 无人机视频具有俯视视角、结构同质性强和目标组合语义多样等特点，现有面向地面视角的跨模态方法难以有效建模其特征，因此需要针对无人机场景设计专用的检索机制。

Method: 提出多语义自适应挖掘（MSAM）方法，包含多语义自适应学习机制、自适应语义构建模块、分布驱动语义学习项和多样性语义项，并引入跨模态交互特征融合池化机制，聚焦目标区域的特征提取与匹配。

Result: 在两个自建的无人机视频-文本数据集上进行了大量实验，结果表明MSAM在无人机视频-文本检索任务中优于其他现有方法。

Conclusion: MSAM能有效提升对无人机视频内容的深度理解和推理能力，增强了跨模态特征表示的鲁棒性，为无人机视频语义检索提供了新的解决方案。

Abstract: With the advancement of drone technology, the volume of video data increases
rapidly, creating an urgent need for efficient semantic retrieval. We are the
first to systematically propose and study the drone video-text retrieval (DVTR)
task. Drone videos feature overhead perspectives, strong structural
homogeneity, and diverse semantic expressions of target combinations, which
challenge existing cross-modal methods designed for ground-level views in
effectively modeling their characteristics. Therefore, dedicated retrieval
mechanisms tailored for drone scenarios are necessary. To address this issue,
we propose a novel approach called Multi-Semantic Adaptive Mining (MSAM). MSAM
introduces a multi-semantic adaptive learning mechanism, which incorporates
dynamic changes between frames and extracts rich semantic information from
specific scene regions, thereby enhancing the deep understanding and reasoning
of drone video content. This method relies on fine-grained interactions between
words and drone video frames, integrating an adaptive semantic construction
module, a distribution-driven semantic learning term and a diversity semantic
term to deepen the interaction between text and drone video modalities and
improve the robustness of feature representation. To reduce the interference of
complex backgrounds in drone videos, we introduce a cross-modal interactive
feature fusion pooling mechanism that focuses on feature extraction and
matching in target regions, minimizing noise effects. Extensive experiments on
two self-constructed drone video-text datasets show that MSAM outperforms other
existing methods in the drone video-text retrieval task. The source code and
dataset will be made publicly available.

</details>


### [14] [A solution to generalized learning from small training sets found in everyday infant experiences](https://arxiv.org/abs/2510.15060)
*Frangil Ramirez,Elizabeth Clerkin,David J. Crandall,Linda B. Smith*

Main category: cs.CV

TL;DR: 婴幼儿通过日常视觉经验中的“块状相似性”结构实现物体类别的泛化，这种自然的经验模式有助于小样本下的高效学习，并为机器学习提供启示。


<details>
  <summary>Details</summary>
Motivation: 探索婴幼儿如何在有限的视觉经验下实现物体类别的识别与泛化，解决其与传统大数据学习之间的矛盾。

Method: 分析14名7至11个月大婴儿的第一人称视角图像，识别其日常视觉输入的相似性结构，并通过计算实验模拟该结构在机器学习中的效果。

Result: 发现婴儿的视觉输入具有‘块状相似性’结构（高度相似图像的聚类），并在机器学习中模拟该结构可提升小样本数据的泛化能力。

Conclusion: 婴儿日常经验的自然‘块状’结构可能支持早期类别学习，这一机制可为各类学习系统提供高效的泛化原则。

Abstract: Young children readily recognize and generalize visual objects labeled by
common nouns, suggesting that these basic level object categories may be given.
Yet if they are, how they arise remains unclear. We propose that the answer
lies in the statistics of infant daily life visual experiences. Whereas large
and diverse datasets typically support robust learning and generalization in
human and machine learning, infants achieve this generalization from limited
experiences. We suggest that the resolution of this apparent contradiction lies
in the visual diversity of daily life, repeated experiences with single object
instances. Analyzing egocentric images from 14 infants (aged 7 to 11 months) we
show that their everyday visual input exhibits a lumpy similarity structure,
with clusters of highly similar images interspersed with rarer, more variable
ones, across eight early-learned categories. Computational experiments show
that mimicking this structure in machines improves generalization from small
datasets in machine learning. The natural lumpiness of infant experience may
thus support early category learning and generalization and, more broadly,
offer principles for efficient learning across a variety of problems and kinds
of learners.

</details>


### [15] [SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images](https://arxiv.org/abs/2510.15072)
*Jiaxin Guo,Tongfan Guan,Wenzhen Dong,Wenzhao Zheng,Wenting Wang,Yue Wang,Yeung Yam,Yun-Hui Liu*

Main category: cs.CV

TL;DR: 提出SaLon3R，一种结构感知的长时序3D高斯点阵重建框架，通过紧凑锚点和3D点Transformer实现高效、低冗余、几何一致的在线重建。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在长序列视频中存在高冗余和几何不一致问题，难以实现实时、通用的在线重建。

Method: 引入基于显著性感知的可微高斯量化生成紧凑锚点，并采用3D Point Transformer在3D空间中学习结构先验以优化锚点属性和显著性，实现自适应高斯解码。

Result: 在多个数据集上实现了超过50帧的实时重建（>10 FPS），去除50%-90%冗余，在新视角合成与深度估计任务中表现SOTA。

Conclusion: SaLon3R是首个支持长时序、高效、在线通用3DGS的方法，显著提升重建效率、鲁棒性和泛化能力。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled generalizable,
on-the-fly reconstruction of sequential input views. However, existing methods
often predict per-pixel Gaussians and combine Gaussians from all views as the
scene representation, leading to substantial redundancies and geometric
inconsistencies in long-duration video sequences. To address this, we propose
SaLon3R, a novel framework for Structure-aware, Long-term 3DGS Reconstruction.
To our best knowledge, SaLon3R is the first online generalizable GS method
capable of reconstructing over 50 views in over 10 FPS, with 50% to 90%
redundancy removal. Our method introduces compact anchor primitives to
eliminate redundancy through differentiable saliency-aware Gaussian
quantization, coupled with a 3D Point Transformer that refines anchor
attributes and saliency to resolve cross-frame geometric and photometric
inconsistencies. Specifically, we first leverage a 3D reconstruction backbone
to predict dense per-pixel Gaussians and a saliency map encoding regional
geometric complexity. Redundant Gaussians are compressed into compact anchors
by prioritizing high-complexity regions. The 3D Point Transformer then learns
spatial structural priors in 3D space from training data to refine anchor
attributes and saliency, enabling regionally adaptive Gaussian decoding for
geometric fidelity. Without known camera parameters or test-time optimization,
our approach effectively resolves artifacts and prunes the redundant 3DGS in a
single feed-forward pass. Experiments on multiple datasets demonstrate our
state-of-the-art performance on both novel view synthesis and depth estimation,
demonstrating superior efficiency, robustness, and generalization ability for
long-term generalizable 3D reconstruction. Project Page:
https://wrld.github.io/SaLon3R/.

</details>


### [16] [TGT: Text-Grounded Trajectories for Locally Controlled Video Generation](https://arxiv.org/abs/2510.15104)
*Guofeng Zhang,Angtian Wang,Jacob Zhiyuan Fang,Liming Jiang,Haotian Yang,Bo Liu,Yiding Yang,Guang Chen,Longyin Wen,Alan Yuille,Chongyang Ma*

Main category: cs.CV

TL;DR: 本文提出了Text-Grounded Trajectories (TGT)框架，通过将轨迹与局部文本描述配对，实现对视频生成中对象外观和运动的精确控制。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在多对象场景下难以精确控制对象的位置和运动，缺乏轨迹与视觉实体之间的清晰对应关系。

Method: 提出TGT框架，结合Location-Aware Cross-Attention (LACA)和双条件引导机制（dual-CFG），并构建包含两百万高质量视频片段的数据集进行训练。

Result: 实验表明，TGT在视觉质量、文本对齐精度和运动可控性方面优于先前方法。

Conclusion: TGT通过点轨迹作为直观的运动控制手柄，并结合文本描述，显著提升了复杂场景下视频生成的可控性和准确性。

Abstract: Text-to-video generation has advanced rapidly in visual fidelity, whereas
standard methods still have limited ability to control the subject composition
of generated scenes. Prior work shows that adding localized text control
signals, such as bounding boxes or segmentation masks, can help. However, these
methods struggle in complex scenarios and degrade in multi-object settings,
offering limited precision and lacking a clear correspondence between
individual trajectories and visual entities as the number of controllable
objects increases. We introduce Text-Grounded Trajectories (TGT), a framework
that conditions video generation on trajectories paired with localized text
descriptions. We propose Location-Aware Cross-Attention (LACA) to integrate
these signals and adopt a dual-CFG scheme to separately modulate local and
global text guidance. In addition, we develop a data processing pipeline that
produces trajectories with localized descriptions of tracked entities, and we
annotate two million high quality video clips to train TGT. Together, these
components enable TGT to use point trajectories as intuitive motion handles,
pairing each trajectory with text to control both appearance and motion.
Extensive experiments show that TGT achieves higher visual quality, more
accurate text alignment, and improved motion controllability compared with
prior approaches. Website: https://textgroundedtraj.github.io.

</details>


### [17] [Deep generative priors for 3D brain analysis](https://arxiv.org/abs/2510.15119)
*Ana Lawry Aguila,Dina Zemlyanker,You Cheng,Sudeshna Das,Daniel C. Alexander,Oula Puonti,Annabel Sorby-Adams,W. Taylor Kimberly,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 本文提出了一种将扩散模型作为先验应用于医学成像逆问题的通用框架，利用基于分数的扩散先验结合灵活的前向模型，在无需配对训练数据的情况下实现了脑部MRI分析的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的贝叶斯逆问题方法依赖于经典数学先验，难以捕捉大脑解剖结构的复杂性；而数据驱动的扩散模型缺乏与领域知识的有效结合，限制了其在脑成像中的应用。

Method: 采用在多样化脑部MRI数据上广泛训练的基于分数的扩散模型作为先验，并结合可建模超分辨率、偏置场校正、图像修复等任务的灵活前向模型，解决多种医学成像逆问题。

Result: 在异构的临床和研究MRI数据上的实验表明，该方法在无需配对训练数据的情况下，生成了高质量且一致的结果，优于现有方法，并能提升现有深度学习方法输出的解剖保真度。

Conclusion: 扩散先验可作为多功能工具用于脑部MRI分析，有效结合数据驱动模型与领域知识，为医学成像逆问题提供了新的解决方案。

Abstract: Diffusion models have recently emerged as powerful generative models in
medical imaging. However, it remains a major challenge to combine these
data-driven models with domain knowledge to guide brain imaging problems. In
neuroimaging, Bayesian inverse problems have long provided a successful
framework for inference tasks, where incorporating domain knowledge of the
imaging process enables robust performance without requiring extensive training
data. However, the anatomical modeling component of these approaches typically
relies on classical mathematical priors that often fail to capture the complex
structure of brain anatomy. In this work, we present the first general-purpose
application of diffusion models as priors for solving a wide range of medical
imaging inverse problems. Our approach leverages a score-based diffusion prior
trained extensively on diverse brain MRI data, paired with flexible forward
models that capture common image processing tasks such as super-resolution,
bias field correction, inpainting, and combinations thereof. We further
demonstrate how our framework can refine outputs from existing deep learning
methods to improve anatomical fidelity. Experiments on heterogeneous clinical
and research MRI data show that our method achieves state-of-the-art
performance producing consistent, high-quality solutions without requiring
paired training datasets. These results highlight the potential of diffusion
priors as versatile tools for brain MRI analysis.

</details>


### [18] [Fourier Transform Multiple Instance Learning for Whole Slide Image Classification](https://arxiv.org/abs/2510.15138)
*Anthony Bilic,Guangyu Sun,Ming Li,Md Sanzid Bin Hossain,Yu Tian,Wei Zhang,Laura Brattain,Dexter Hadley,Chen Chen*

Main category: cs.CV

TL;DR: 提出FFT-MIL框架，通过引入频域分支增强全切片图像分类中的全局上下文建模，结合空间和频率特征，在多个数据集和MIL架构上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MIL方法难以捕捉全切片图像的全局依赖关系，因图像尺寸大且局部嵌入限制了对关键粗粒度结构的建模。

Method: 利用快速傅里叶变换提取低频区域，设计FFT-Block（含卷积层和Min-Max归一化）处理频域信息，并通过轻量级策略融合频域与空间patch特征。

Result: 在BRACS、LUAD和IMP三个公开数据集上，集成FFT-Block平均提升macro F1 3.51%和AUC 1.51%，效果稳定且跨架构一致。

Conclusion: 频域学习能有效补充空间特征，为WSI分类提供高效、可扩展的全局上下文建模方式，推动计算病理学中MIL方法的发展。

Abstract: Whole Slide Image (WSI) classification relies on Multiple Instance Learning
(MIL) with spatial patch features, yet existing methods struggle to capture
global dependencies due to the immense size of WSIs and the local nature of
patch embeddings. This limitation hinders the modeling of coarse structures
essential for robust diagnostic prediction.
  We propose Fourier Transform Multiple Instance Learning (FFT-MIL), a
framework that augments MIL with a frequency-domain branch to provide compact
global context. Low-frequency crops are extracted from WSIs via the Fast
Fourier Transform and processed through a modular FFT-Block composed of
convolutional layers and Min-Max normalization to mitigate the high variance of
frequency data. The learned global frequency feature is fused with spatial
patch features through lightweight integration strategies, enabling
compatibility with diverse MIL architectures.
  FFT-MIL was evaluated across six state-of-the-art MIL methods on three public
datasets (BRACS, LUAD, and IMP). Integration of the FFT-Block improved macro F1
scores by an average of 3.51% and AUC by 1.51%, demonstrating consistent gains
across architectures and datasets. These results establish frequency-domain
learning as an effective and efficient mechanism for capturing global
dependencies in WSI classification, complementing spatial features and
advancing the scalability and accuracy of MIL-based computational pathology.

</details>


### [19] [XModBench: Benchmarking Cross-Modal Capabilities and Consistency in Omni-Language Models](https://arxiv.org/abs/2510.15148)
*Xingrui Wang,Jiang Liu,Chao Huang,Xiaodong Yu,Ze Wang,Ximeng Sun,Jialian Wu,Alan Yuille,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: 本文提出了XModBench，一个大规模三模态基准，用于评估Omni-modal大语言模型在跨模态一致性方面的表现，揭示了现有模型在模态不变推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估跨模态问答能力，但无法判断OLLM是否实现模态不变推理或存在模态偏差，因此需要专门衡量跨模态一致性的新基准。

Method: 构建包含60,828个多选题的XModBench，覆盖五类任务和六种模态组合，系统评估模型在不同模态输入输出下的推理一致性。

Result: 实验显示当前最强模型Gemini 2.5 Pro在空间和时间推理上准确率低于60%，音频理解性能显著低于文本，且以视觉为上下文时一致性更低，表现出模态差异和方向性不平衡。

Conclusion: 当前OLLM尚未实现真正的模态不变推理，XModBench可作为诊断和提升跨模态能力的重要工具。

Abstract: Omni-modal large language models (OLLMs) aim to unify audio, vision, and text
understanding within a single framework. While existing benchmarks primarily
evaluate general cross-modal question-answering ability, it remains unclear
whether OLLMs achieve modality-invariant reasoning or exhibit modality-specific
biases. We introduce XModBench, a large-scale tri-modal benchmark explicitly
designed to measure cross-modal consistency. XModBench comprises 60,828
multiple-choice questions spanning five task families and systematically covers
all six modality compositions in question-answer pairs, enabling fine-grained
diagnosis of an OLLM's modality-invariant reasoning, modality disparity, and
directional imbalance. Experiments show that even the strongest model, Gemini
2.5 Pro, (i) struggles with spatial and temporal reasoning, achieving less than
60% accuracy, (ii) reveals persistent modality disparities, with performance
dropping substantially when the same semantic content is conveyed through audio
rather than text, and (iii) shows systematic directional imbalance, exhibiting
lower consistency when vision serves as context compared to text. These
findings indicate that current OLLMs remain far from truly modality-invariant
reasoning and position XModBench as a fundamental diagnostic tool for
evaluating and improving cross-modal competence. All data and evaluation tools
will be available at https://xingruiwang.github.io/projects/XModBench/.

</details>


### [20] [Train a Unified Multimodal Data Quality Classifier with Synthetic Data](https://arxiv.org/abs/2510.15162)
*Weizhi Wang,Rongmei Lin,Shiyang Li,Colin Lockard,Ritesh Sarkhel,Sanket Lokegaonkar,Jingbo Shang,Xifeng Yan,Nasser Zalmout,Xian Li*

Main category: cs.CV

TL;DR: 提出UniFilter，一种高效的多模态数据质量分类器，用于筛选高质量的图像-文本配对和交错文档数据，通过半合成方法生成多级质量标注数据进行训练，并在多个数据集上验证其提升MLLM预训练效果的能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究对图像-文本交错文档数据的高质量筛选关注不足，缺乏有效的多模态数据质量评估方法。

Method: 设计UniFilter模型，采用半合成方式利用原始图像生成四种质量等级的对应文本，构建样本-评分对用于训练；应用于DataComp和OBELICS数据集以筛选高质量数据。

Result: 在筛选后的数据上预训练的MLLM表现出更强的零样本推理和上下文学习能力，在视觉监督微调后在多个基准上取得更优性能。

Conclusion: UniFilter能有效提升多模态预训练数据质量，进而增强MLLM的下游任务表现，相关数据与模型已开源。

Abstract: The Multimodal Large Language Models (MLLMs) are continually pre-trained on a
mixture of image-text caption data and interleaved document data, while the
high-quality data filtering towards image-text interleaved document data is
under-explored. We propose to train an efficient MLLM as a Unified Mulitmodal
Data Quality Classifier to Filter both high-quality image-text caption and
interleaved data (UniFilter). To address the challenge of collecting diverse
labeled multimodal data, we introduce a semi-synthetic approach that leverages
readily available raw images and generates corresponding text across four
quality levels. This method enables efficient creation of sample-score pairs
for both caption and interleaved document data to train UniFilter. We apply
UniFilter to curate high-quality caption data from DataComp caption dataset and
interleaved data from the OBELICS image-text interleaved dataset. MLLMs
pre-trained on the filtered data demonstrate significantly enhanced
capabilities compared to those trained on baseline-filtered data, achieving
stronger zero-shot reasoning and in-context learning capabilities. After visual
supervised fine-tuning, these UniFilter-induced MLLMs achieve stronger
performance on various benchmarks, highlighting the downstream benefits of
high-quality multimodal pre-training. We release the synthetic training data
used for training UniFilter, the UniFilter model checkpoints, and the
high-quality interleaved document subset OBELICS-HQ, curated by UniFilter, to
the community for reproduction and further development.

</details>


### [21] [Hyperparameter Optimization and Reproducibility in Deep Learning Model Training](https://arxiv.org/abs/2510.15164)
*Usman Afzaal,Ziyu Su,Usama Sajjad,Hao Lu,Mostafa Rezapour,Metin Nafi Gurcan,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 本研究通过在QUILT-1M数据集上训练CLIP模型，系统评估了超参数和数据增强策略对下游病理学任务可重复性的影响，发现特定的RandomResizedCrop值、分布式训练方式和学习率设置能显著提升可重复性，其中LC25000（Colon）数据集表现最稳定。


<details>
  <summary>Details</summary>
Motivation: 解决组织病理学基础模型训练中因软件随机性、硬件非确定性和超参数报告不一致导致的可重复性难题。

Method: 在QUILT-1M数据集上训练CLIP模型，并在PatchCamelyon、LC25000-Lung和LC25000-Colon三个下游数据集上系统评估不同超参数和增强策略的影响。

Result: RandomResizedCrop取值0.7–0.8时性能最优，无局部损失的分布式训练更稳定，学习率低于5.0e-5会降低性能，LC25000（Colon）数据集最具可重复性。

Conclusion: 组织病理学中的可重复性不仅依赖透明记录，还需精心设计实验配置，本文提出了指导未来数字病理基础模型开发的实用规则。

Abstract: Reproducibility remains a critical challenge in foundation model training for
histopathology, often hindered by software randomness, hardware
non-determinism, and inconsistent hyperparameter reporting. To investigate
these issues, we trained a CLIP model on the QUILT-1M dataset and
systematically evaluated the impact of different hyperparameter settings and
augmentation strategies across three downstream histopathology datasets
(PatchCamelyon, LC25000-Lung, and LC25000-Colon). Despite variability across
runs, we identified clear trends: RandomResizedCrop values of 0.7-0.8
outperformed more aggressive (0.6) or conservative (0.9) settings, distributed
training without local loss improved stability, and learning rates below 5.0e-5
consistently degraded performance across all datasets. The LC25000 (Colon)
dataset consistently provided the most reproducible benchmark. These findings
highlight that reproducibility in computational pathology depends not only on
transparent documentation but also on carefully chosen experimental
configurations, and we provide practical rules to guide future efforts in
developing reproducible foundation models for digital pathology.

</details>


### [22] [Salient Concept-Aware Generative Data Augmentation](https://arxiv.org/abs/2510.15194)
*Tianchen Zhao,Xuanbai Chen,Zhihua Li,Jun Fang,Dongsheng An,Xiang Xu,Zhuowen Tu,Yifan Xing*

Main category: cs.CV

TL;DR: 提出一种基于显著概念感知图像嵌入的个性化图像生成框架，有效平衡生成图像的保真度与多样性，在八项细粒度视觉数据集上优于现有数据增强方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像和文本提示的生成式数据增强方法难以在保真度和多样性之间取得平衡，因合成过程中的表征常与非必要图像属性纠缠，导致与文本提示冲突。

Method: 设计一种显著概念感知的图像嵌入模型，在生成过程中减少无关视觉细节的影响，保留类别判别特征并引入可控变化，实现图像与文本输入的直观对齐。

Result: 在八个细粒度视觉数据集上，分类准确率在常规和长尾设置下分别平均提升0.73%和6.5%，优于当前最先进方法。

Conclusion: 该框架通过解耦关键语义特征与无关上下文，有效提升了生成图像的质量与数据增强效果，增强了下游模型的鲁棒性。

Abstract: Recent generative data augmentation methods conditioned on both image and
text prompts struggle to balance between fidelity and diversity, as it is
challenging to preserve essential image details while aligning with varied text
prompts. This challenge arises because representations in the synthesis process
often become entangled with non-essential input image attributes such as
environmental contexts, creating conflicts with text prompts intended to modify
these elements. To address this, we propose a personalized image generation
framework that uses a salient concept-aware image embedding model to reduce the
influence of irrelevant visual details during the synthesis process, thereby
maintaining intuitive alignment between image and text inputs. By generating
images that better preserve class-discriminative features with additional
controlled variations, our framework effectively enhances the diversity of
training datasets and thereby improves the robustness of downstream models. Our
approach demonstrates superior performance across eight fine-grained vision
datasets, outperforming state-of-the-art augmentation methods with averaged
classification accuracy improvements by 0.73% and 6.5% under conventional and
long-tail settings, respectively.

</details>


### [23] [CARDIUM: Congenital Anomaly Recognition with Diagnostic Images and Unified Medical records](https://arxiv.org/abs/2510.15208)
*Daniela Vega,Hannah V. Ceballos,Javier S. Vera,Santiago Rodriguez,Alejandra Perez,Angela Castillo,Maria Escobar,Dario Londoño,Luis A. Sarmiento,Camila I. Castro,Nadiezhda Rodriguez,Juan C. Briceño,Pablo Arbeláez*

Main category: cs.CV

TL;DR: 本文提出了首个公开的多模态数据集CARDIUM，结合胎儿超声/超声心动图像与母体临床记录，用于先天性心脏病（CHD）的产前检测，并设计了一种基于交叉注意力机制的多模态Transformer模型，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于先天性心脏病病例稀少，高质量诊断数据收集困难，现有数据集不平衡且质量低，同时缺乏整合影像与临床数据的公开资源，限制了AI在产前CHD诊断中的应用。

Method: 构建了名为CARDIUM的公开多模态数据集，包含胎儿超声/超声心动图和母体临床记录；提出一种引入交叉注意力机制的多模态Transformer架构，用于融合图像与表格数据的特征表示。

Result: 所提模型在CARDIUM数据集上比单模态图像和表格方法分别提升11%和50%的检测性能，F1分数达到79.8±4.8%。

Conclusion: CARDIUM为AI驱动的产前CHD诊断提供了重要的公共数据资源，所提出的多模态融合方法有效提升了检测效果，推动了临床决策支持系统的发展。

Abstract: Prenatal diagnosis of Congenital Heart Diseases (CHDs) holds great potential
for Artificial Intelligence (AI)-driven solutions. However, collecting
high-quality diagnostic data remains difficult due to the rarity of these
conditions, resulting in imbalanced and low-quality datasets that hinder model
performance. Moreover, no public efforts have been made to integrate multiple
sources of information, such as imaging and clinical data, further limiting the
ability of AI models to support and enhance clinical decision-making. To
overcome these challenges, we introduce the Congenital Anomaly Recognition with
Diagnostic Images and Unified Medical records (CARDIUM) dataset, the first
publicly available multimodal dataset consolidating fetal ultrasound and
echocardiographic images along with maternal clinical records for prenatal CHD
detection. Furthermore, we propose a robust multimodal transformer architecture
that incorporates a cross-attention mechanism to fuse feature representations
from image and tabular data, improving CHD detection by 11% and 50% over image
and tabular single-modality approaches, respectively, and achieving an F1 score
of 79.8 $\pm$ 4.8% in the CARDIUM dataset. We will publicly release our dataset
and code to encourage further research on this unexplored field. Our dataset
and code are available at https://github.com/BCVUniandes/Cardium, and at the
project website https://bcv-uniandes.github.io/CardiumPage/

</details>


### [24] [The Face of Persuasion: Analyzing Bias and Generating Culture-Aware Ads](https://arxiv.org/abs/2510.15240)
*Aysan Aghazadeh,Adriana Kovashka*

Main category: cs.CV

TL;DR: 研究了文本到图像模型在定制视觉广告和针对特定人群中的应用潜力，探讨了不同主题广告中的 demographic bias 以及因性别/种族差异导致的广告说服力差异，并实验了针对特定国家投放广告的技术。


<details>
  <summary>Details</summary>
Motivation: 探索文本到图像模型在广告定制化中的潜力，分析其在不同人口群体中的偏见和说服力差异。

Method: 通过分析不同广告主题中的 demographic bias，比较仅在性别/种族上不同的广告在模型判断下的说服力差异，并尝试针对特定国家的广告定向技术。

Result: 发现了广告中存在基于性别和种族的显著说服力差异，并验证了针对特定国家进行广告定制的可行性。

Conclusion: 文本到图像模型在广告个性化方面具有潜力，但需注意其中的 demographic 偏见问题，同时可有效用于地域性广告定向。

Abstract: Text-to-image models are appealing for customizing visual advertisements and
targeting specific populations. We investigate this potential by examining the
demographic bias within ads for different ad topics, and the disparate level of
persuasiveness (judged by models) of ads that are identical except for
gender/race of the people portrayed. We also experiment with a technique to
target ads for specific countries. The code is available at
https://github.com/aysanaghazadeh/FaceOfPersuasion

</details>


### [25] [DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion](https://arxiv.org/abs/2510.15264)
*Weijie Wang,Jiagang Zhu,Zeyu Zhang,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Chaojun Ni,Haoxiao Wang,Guan Huang,Xinze Chen,Yukun Zhou,Wenkang Qin,Duochao Shi,Haoyun Li,Guanghong Jia,Jiwen Lu*

Main category: cs.CV

TL;DR: DriveGen3D是一个用于生成高质量、高可控性动态3D驾驶场景的新框架，结合快速视频生成与大规模动态场景重建，实现实时长序列驾驶视频与3D场景的联合生成。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶场景合成方法在长时间生成、3D表示或动态控制方面存在计算成本高或功能局限的问题，亟需一种兼顾效率与质量的统一解决方案。

Method: 提出DriveGen3D框架，包含两个核心模块：FastDrive-DiT，基于文本和鸟瞰图布局引导的高效视频扩散Transformer；FastRecon3D，前馈式重建模块，快速生成时序一致的3D高斯表示。

Result: 实现了高达424×800分辨率、12FPS的实时驾驶视频生成，并在新视角合成任务上达到0.811 SSIM和22.84 PSNR，同时保持良好的参数效率。

Conclusion: DriveGen3D有效弥补了现有方法在时空一致性、3D动态表达与生成效率之间的鸿沟，为自动驾驶仿真提供了高效可控的新工具。

Abstract: We present DriveGen3D, a novel framework for generating high-quality and
highly controllable dynamic 3D driving scenes that addresses critical
limitations in existing methodologies. Current approaches to driving scene
synthesis either suffer from prohibitive computational demands for extended
temporal generation, focus exclusively on prolonged video synthesis without 3D
representation, or restrict themselves to static single-scene reconstruction.
Our work bridges this methodological gap by integrating accelerated long-term
video generation with large-scale dynamic scene reconstruction through
multimodal conditional control. DriveGen3D introduces a unified pipeline
consisting of two specialized components: FastDrive-DiT, an efficient video
diffusion transformer for high-resolution, temporally coherent video synthesis
under text and Bird's-Eye-View (BEV) layout guidance; and FastRecon3D, a
feed-forward reconstruction module that rapidly builds 3D Gaussian
representations across time, ensuring spatial-temporal consistency. Together,
these components enable real-time generation of extended driving videos (up to
$424\times800$ at 12 FPS) and corresponding dynamic 3D scenes, achieving SSIM
of 0.811 and PSNR of 22.84 on novel view synthesis, all while maintaining
parameter efficiency.

</details>


### [26] [CuSfM: CUDA-Accelerated Structure-from-Motion](https://arxiv.org/abs/2510.15271)
*Jingrui Yu,Jun Liu,Kefei Ren,Joydeep Biswas,Rurui Ye,Keqiang Wu,Chirag Majithia,Di Zeng*

Main category: cs.CV

TL;DR: 本文提出了一种基于CUDA加速的离线Structure-from-Motion系统cuSfM，用于实现高效且精确的相机位姿估计，显著优于COLMAP方法，并开源了Python封装PyCuSfM。


<details>
  <summary>Details</summary>
Motivation: 为了在自主导航、机器人感知和虚拟仿真中实现密集重建所需的高精度相机位姿估计，需要克服传统SfM方法在计算效率和精度之间的权衡。

Method: 设计并实现了cuSfM，一个利用GPU并行化加速的离线SfM系统，采用计算密集但高精度的特征提取器，支持位姿优化、建图、先验地图定位和外参 refinement。

Result: 实验表明，cuSfM在多种测试场景下相比COLMAP显著提升了精度和处理速度，同时保持了高全局一致性。

Conclusion: cuSfM通过充分利用GPU资源，在离线SfM应用中实现了更高精度和效率，适用于对精度要求高的视觉与机器人任务。

Abstract: Efficient and accurate camera pose estimation forms the foundational
requirement for dense reconstruction in autonomous navigation, robotic
perception, and virtual simulation systems. This paper addresses the challenge
via cuSfM, a CUDA-accelerated offline Structure-from-Motion system that
leverages GPU parallelization to efficiently employ computationally intensive
yet highly accurate feature extractors, generating comprehensive and
non-redundant data associations for precise camera pose estimation and globally
consistent mapping. The system supports pose optimization, mapping, prior-map
localization, and extrinsic refinement. It is designed for offline processing,
where computational resources can be fully utilized to maximize accuracy.
Experimental results demonstrate that cuSfM achieves significantly improved
accuracy and processing speed compared to the widely used COLMAP method across
various testing scenarios, while maintaining the high precision and global
consistency essential for offline SfM applications. The system is released as
an open-source Python wrapper implementation, PyCuSfM, available at
https://github.com/nvidia-isaac/pyCuSFM, to facilitate research and
applications in computer vision and robotics.

</details>


### [27] [Post-Processing Methods for Improving Accuracy in MRI Inpainting](https://arxiv.org/abs/2510.15282)
*Nishad Kulkarni,Krithika Iyer,Austin Tapp,Abhijeet Parida,Daniel Capellán-Martín,Zhifan Jiang,María J. Ledesma-Carbayo,Syed Muhammad Anwar,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本文系统评估了最先进的MRI图像修复模型，并提出了一种结合模型集成与高效后处理策略（如中值滤波、直方图匹配和像素平均）以及轻量级U-Net增强的方法，显著提升了修复区域的解剖合理性和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的MRI图像修复模型在处理大脑肿瘤等大病变时表现有限，且性能趋于饱和，难以满足临床需求。

Method: 采用模型集成方法结合多种后处理技术（中值滤波、 histogram matching、像素平均），并引入轻量级U-Net进行解剖结构细化。

Result: 所提方法在解剖合理性、视觉质量和定量指标上均优于单个基线模型，实现了更准确、更鲁棒的修复效果。

Conclusion: 通过组合现有模型与针对性后处理，可在不依赖新模型的情况下显著提升修复性能，促进临床部署和资源节约型研究。

Abstract: Magnetic Resonance Imaging (MRI) is the primary imaging modality used in the
diagnosis, assessment, and treatment planning for brain pathologies. However,
most automated MRI analysis tools, such as segmentation and registration
pipelines, are optimized for healthy anatomies and often fail when confronted
with large lesions such as tumors. To overcome this, image inpainting
techniques aim to locally synthesize healthy brain tissues in tumor regions,
enabling the reliable application of general-purpose tools. In this work, we
systematically evaluate state-of-the-art inpainting models and observe a
saturation in their standalone performance. In response, we introduce a
methodology combining model ensembling with efficient post-processing
strategies such as median filtering, histogram matching, and pixel averaging.
Further anatomical refinement is achieved via a lightweight U-Net enhancement
stage. Comprehensive evaluation demonstrates that our proposed pipeline
improves the anatomical plausibility and visual fidelity of inpainted regions,
yielding higher accuracy and more robust outcomes than individual baseline
models. By combining established models with targeted post-processing, we
achieve improved and more accessible inpainting outcomes, supporting broader
clinical deployment and sustainable, resource-conscious research. Our 2025
BraTS inpainting docker is available at
https://hub.docker.com/layers/aparida12/brats2025/inpt.

</details>


### [28] [QCFace: Image Quality Control for boosting Face Representation & Recognition](https://arxiv.org/abs/2510.15289)
*Duc-Phuong Doan-Ngo,Thanh-Dang Diep,Thanh Nguyen-Duc,Thanh-Sach LE,Nam Thoai*

Main category: cs.CV

TL;DR: 本文提出了一种基于硬边界的损失函数QCFace，通过解耦可识别性与身份表示，有效提升了人脸识别系统在验证和识别任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉人脸可识别性时存在表示能力弱、特征优化过程中梯度重叠导致不稳定等问题，难以实现高质量的特征解耦。

Method: 引入硬边界策略QCFace，设计新的损失函数，利用引导因子进行超球面规划，实现可识别性与身份特征的清晰分离，并解决梯度重叠问题。

Result: 实验表明，QCFace在多个验证和识别基准上优于现有的可识别性相关损失方法，实现了最先进的性能，同时提供了鲁棒且可量化的可识别性编码。

Conclusion: QCFace通过硬边界策略有效解耦可识别性与身份信息，增强了特征表示的判别能力和泛化性，为深度人脸识别中的质量感知学习提供了新思路。

Abstract: Recognizability, a key perceptual factor in human face processing, strongly
affects the performance of face recognition (FR) systems in both verification
and identification tasks. Effectively using recognizability to enhance feature
representation remains challenging. In deep FR, the loss function plays a
crucial role in shaping how features are embedded. However, current methods
have two main drawbacks: (i) recognizability is only partially captured through
soft margin constraints, resulting in weaker quality representation and lower
discrimination, especially for low-quality or ambiguous faces; (ii) mutual
overlapping gradients between feature direction and magnitude introduce
undesirable interactions during optimization, causing instability and confusion
in hypersphere planning, which may result in poor generalization, and entangled
representations where recognizability and identity are not cleanly separated.
To address these issues, we introduce a hard margin strategy - Quality Control
Face (QCFace), which overcomes the mutual overlapping gradient problem and
enables the clear decoupling of recognizability from identity representation.
Based on this strategy, a novel hard-margin-based loss function employs a
guidance factor for hypersphere planning, simultaneously optimizing for
recognition ability and explicit recognizability representation. Extensive
experiments confirm that QCFace not only provides robust and quantifiable
recognizability encoding but also achieves state-of-the-art performance in both
verification and identification benchmarks compared to existing
recognizability-based losses.

</details>


### [29] [Exploring Conditions for Diffusion models in Robotic Control](https://arxiv.org/abs/2510.15510)
*Heeseong Shin,Byeongho Heo,Dongyoon Han,Seungryong Kim,Taekyung Kim*

Main category: cs.CV

TL;DR: 本文提出ORCA方法，利用预训练的文本到图像扩散模型生成任务自适应的视觉表征用于机器人控制，通过可学习的任务提示和视觉提示来克服领域差距，显著提升了控制性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉表征在策略学习过程中通常是冻结且任务无关的，难以充分利用扩散模型的潜力；同时直接使用文本条件在机器人控制中效果不佳，存在领域差距问题。

Method: 提出ORCA方法，引入可学习的任务提示（learnable task prompts）以适应控制环境，以及视觉提示（visual prompts）捕捉帧级别的细粒度信息，从而实现无需微调扩散模型本身即可获得任务自适应的视觉表征。

Result: 在多个机器人控制基准上实现了最先进的性能，显著优于先前方法。

Conclusion: 通过设计适配控制任务的新型提示机制，可以在不微调扩散模型的情况下有效利用其生成任务自适应视觉表征，为机器人控制提供了新的高效视觉编码方案。

Abstract: While pre-trained visual representations have significantly advanced
imitation learning, they are often task-agnostic as they remain frozen during
policy learning. In this work, we explore leveraging pre-trained text-to-image
diffusion models to obtain task-adaptive visual representations for robotic
control, without fine-tuning the model itself. However, we find that naively
applying textual conditions - a successful strategy in other vision domains -
yields minimal or even negative gains in control tasks. We attribute this to
the domain gap between the diffusion model's training data and robotic control
environments, leading us to argue for conditions that consider the specific,
dynamic visual information required for control. To this end, we propose ORCA,
which introduces learnable task prompts that adapt to the control environment
and visual prompts that capture fine-grained, frame-specific details. Through
facilitating task-adaptive representations with our newly devised conditions,
our approach achieves state-of-the-art performance on various robotic control
benchmarks, significantly surpassing prior methods.

</details>


### [30] [Hyperbolic Structured Classification for Robust Single Positive Multi-label Learning](https://arxiv.org/abs/2510.15296)
*Yiming Lin,Shang Wang,Junkai Zhou,Qiufeng Wang,Xiao-Bo Jin,Kaizhu Huang*

Main category: cs.CV

TL;DR: 提出首个用于单正好多标签学习（SPMLL）的双曲分类框架，通过将标签表示为双曲空间中的球体，显式建模包含、重叠和分离等多种标签关系，并引入温度自适应分类器和物理启发的双井正则化，实验证明其在多个基准数据集上具有竞争力且更具可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有SPMLL方法隐式建模标签关系，缺乏对不同类型关系的显式几何定义，难以捕捉复杂的标签结构和层次关系。

Method: 提出基于双曲空间中球体表示的分类框架，利用球体间的几何交互显式建模标签间的包含、重叠和分离关系；设计温度自适应的双曲球分类器和物理启发的双井正则化机制以优化球体配置。

Result: 在MS-COCO、PASCAL VOC、NUS-WIDE和CUB-200-2011四个基准数据集上实验表明，该方法性能具有竞争力且可解释性更强；统计分析显示学习到的嵌入与真实共现模式高度相关。

Conclusion: 双曲几何为不完全监督下的结构化分类提供了更鲁棒的范式，所提球体表示方法能有效建模复杂标签关系。

Abstract: Single Positive Multi-Label Learning (SPMLL) addresses the challenging
scenario where each training sample is annotated with only one positive label
despite potentially belonging to multiple categories, making it difficult to
capture complex label relationships and hierarchical structures. While existing
methods implicitly model label relationships through distance-based similarity,
lacking explicit geometric definitions for different relationship types. To
address these limitations, we propose the first hyperbolic classification
framework for SPMLL that represents each label as a hyperbolic ball rather than
a point or vector, enabling rich inter-label relationship modeling through
geometric ball interactions. Our ball-based approach naturally captures
multiple relationship types simultaneously: inclusion for hierarchical
structures, overlap for co-occurrence patterns, and separation for semantic
independence. Further, we introduce two key component innovations: a
temperature-adaptive hyperbolic ball classifier and a physics-inspired
double-well regularization that guides balls toward meaningful configurations.
To validate our approach, extensive experiments on four benchmark datasets
(MS-COCO, PASCAL VOC, NUS-WIDE, CUB-200-2011) demonstrate competitive
performance with superior interpretability compared to existing methods.
Furthermore, statistical analysis reveals strong correlation between learned
embeddings and real-world co-occurrence patterns, establishing hyperbolic
geometry as a more robust paradigm for structured classification under
incomplete supervision.

</details>


### [31] [Latent Diffusion Model without Variational Autoencoder](https://arxiv.org/abs/2510.15301)
*Minglei Shi,Haolin Wang,Wenzhao Zheng,Ziyang Yuan,Xiaoshi Wu,Xintao Wang,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文提出了一种无需变分自编码器（VAE）的新型潜在扩散模型SVG，利用自监督表示（DINO特征）构建具有语义区分性的潜在空间，从而提升训练效率、生成质量，并支持快速采样。


<details>
  <summary>Details</summary>
Motivation: 现有的VAE+扩散模型范式存在训练效率低、推理速度慢、可迁移性差的问题，主要源于VAE潜在空间缺乏清晰的语义分离和判别结构。本文旨在构建一个更具语义结构的潜在空间以解决这些问题。

Method: SVG采用冻结的DINO自监督特征构建语义清晰的潜在空间，并通过轻量级残差分支捕捉细节信息，直接在此结构化空间上训练扩散模型，避免使用VAE。

Result: SVG实现了更快的扩散训练、支持少步采样、提升了生成质量，并保留了底层自监督表征的语义与判别能力。

Conclusion: SVG提供了一条通向任务通用、高质量视觉表征的原理性路径，克服了传统VAE+扩散模型在效率、速度和可迁移性方面的局限。

Abstract: Recent progress in diffusion-based visual generation has largely relied on
latent diffusion models with variational autoencoders (VAEs). While effective
for high-fidelity synthesis, this VAE+diffusion paradigm suffers from limited
training efficiency, slow inference, and poor transferability to broader vision
tasks. These issues stem from a key limitation of VAE latent spaces: the lack
of clear semantic separation and strong discriminative structure. Our analysis
confirms that these properties are crucial not only for perception and
understanding tasks, but also for the stable and efficient training of latent
diffusion models. Motivated by this insight, we introduce SVG, a novel latent
diffusion model without variational autoencoders, which leverages
self-supervised representations for visual generation. SVG constructs a feature
space with clear semantic discriminability by leveraging frozen DINO features,
while a lightweight residual branch captures fine-grained details for
high-fidelity reconstruction. Diffusion models are trained directly on this
semantically structured latent space to facilitate more efficient learning. As
a result, SVG enables accelerated diffusion training, supports few-step
sampling, and improves generative quality. Experimental results further show
that SVG preserves the semantic and discriminative capabilities of the
underlying self-supervised representations, providing a principled pathway
toward task-general, high-quality visual representations.

</details>


### [32] [Layer as Puzzle Pieces: Compressing Large Language Models through Layer Concatenation](https://arxiv.org/abs/2510.15304)
*Fei Wang,Li Shen,Liang Ding,Chao Xue,Ye Liu,Changxing Ding*

Main category: cs.CV

TL;DR: 本文提出了一种名为CoMe的渐进式层剪枝框架，通过基于拼接的权重合并和分层蒸馏后训练策略，有效缓解了大语言模型结构化剪枝中的性能下降问题，在七项基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的结构化剪枝方法在直接删除层时会导致显著性能下降，且缺乏对被剪枝部分能力的有效保留机制，本文旨在解决这些关键局限性。

Method: 提出CoMe框架：1）基于激活强度和权重范数的通道敏感性度量进行细粒度通道选择；2）采用基于拼接的跨层融合方法合并关键通道；3）设计分层蒸馏策略，利用剪枝过程中建立的原模型与剪枝模型层间对应关系实现高效知识迁移。

Result: 在七个基准测试上验证了方法的有效性，当剪去LLaMA-2-7b 30%参数时，剪枝后的模型仍保持原始平均准确率的83%。

Conclusion: CoMe通过渐进式剪枝、拼接式合并和分层蒸馏，显著提升了大模型结构化剪枝的性能，为高效压缩大语言模型提供了新思路。

Abstract: Large Language Models excel at natural language processing tasks, but their
massive size leads to high computational and storage demands. Recent works have
sought to reduce their model size through layer-wise structured pruning.
However, they tend to ignore retaining the capabilities in the pruned part. In
this work, we re-examine structured pruning paradigms and uncover several key
limitations: 1) notable performance degradation due to direct layer removal, 2)
incompetent linear weight layer aggregation, and 3) the lack of effective
post-training recovery mechanisms. To address these limitations, we propose
CoMe, including a progressive layer pruning framework with a
Concatenation-based Merging technology and a hierarchical distillation
post-training process. Specifically, we introduce a channel sensitivity metric
that utilizes activation intensity and weight norms for fine-grained channel
selection. Subsequently, we employ a concatenation-based layer merging method
to fuse the most critical channels across adjacent layers, enabling progressive
model size reduction. Finally, we propose a hierarchical distillation protocol
that leverages the correspondences between the original and pruned model layers
established during pruning, thereby enabling efficient knowledge transfer.
Experiments on seven benchmarks show that CoMe achieves state-of-the-art
performance; when pruning 30% of LLaMA-2-7b's parameters, the pruned model
retains 83% of its original average accuracy. Our code is available at
https://github.com/MPI-Lab/CoMe.

</details>


### [33] [Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models](https://arxiv.org/abs/2502.08636)
*Xingrui Wang,Wufei Ma,Tiezheng Zhang,Celso M de Melo,Jieneng Chen,Alan Yuille*

Main category: cs.CV

TL;DR: 本文提出了一个名为Spatial457的可扩展、无偏见的合成数据集，用于评估大型多模态模型在6D空间推理（包括多对象识别、2D/3D位置和3D方向）上的能力，并设计了包含7种问题类型和5个难度级别的级联评测结构。实验表明现有LMM在复杂3D和6D任务中性能显著下降，且存在属性预测偏差。


<details>
  <summary>Details</summary>
Motivation: 现有的基准主要关注2D空间理解，缺乏对复杂3D及6D空间推理能力的系统性评估，因此需要一个更全面、可扩展的评测框架来揭示大型多模态模型在三维空间推理方面的局限性。

Method: 构建了一个名为Spatial457的合成数据集，涵盖四个关键空间推理能力：多对象识别、2D位置、3D位置和3D方向；设计了五级难度、七类问题的级联评估结构；引入相对性能下降率（RPDR）量化模型在不同复杂度任务中的表现衰减，并分析模型在不同属性上的预测偏差。

Result: 在PulseCheck457上评测多种LMM发现，随着任务复杂度增加，模型性能普遍下降，尤其在3D位置和6D空间推理任务中表现不佳；RPDR有效揭示了3D推理的薄弱环节；同时发现了模型在不同属性上的系统性预测偏差，且该偏差在真实场景图像中也具有一致性。

Conclusion: 当前大型多模态模型在复杂3D和6D空间推理方面仍存在显著不足，Spatial457为未来提升模型的空间理解能力提供了有效的评测基准和数据支持。

Abstract: Although large multimodal models (LMMs) have demonstrated remarkable
capabilities in visual scene interpretation and reasoning, their capacity for
complex and precise 3-dimensional spatial reasoning remains uncertain. Existing
benchmarks focus predominantly on 2D spatial understanding and lack a framework
to comprehensively evaluate 6D spatial reasoning across varying complexities.
To address this limitation, we present Spatial457, a scalable and unbiased
synthetic dataset designed with 4 key capability for spatial reasoning:
multi-object recognition, 2D location, 3D location, and 3D orientation. We
develop a cascading evaluation structure, constructing 7 question types across
5 difficulty levels that range from basic single object recognition to our new
proposed complex 6D spatial reasoning tasks. We evaluated various large
multimodal models (LMMs) on PulseCheck457, observing a general decline in
performance as task complexity increases, particularly in 3D reasoning and 6D
spatial tasks. To quantify these challenges, we introduce the Relative
Performance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoning
capabilities. Leveraging the unbiased attribute design of our dataset, we also
uncover prediction biases across different attributes, with similar patterns
observed in real-world image settings. The code and data are released in
https://github.com/XingruiWang/Spatial457.

</details>


### [34] [Proto-Former: Unified Facial Landmark Detection by Prototype Transformer](https://arxiv.org/abs/2510.15338)
*Shengkai Hu,Haozhe Qi,Jun Wan,Jiaxing Huang,Lefei Zhang,Hang Sun,Dacheng Tao*

Main category: cs.CV

TL;DR: 本文提出了一种统一、自适应的端到端面部关键点检测框架Proto-Former，通过引入原型感知机制实现多数据集联合训练，提升了模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有面部关键点检测数据集定义的关键点数量不同，主流方法通常只能在单一数据集上训练，限制了模型在不同数据集间的泛化能力，缺乏统一模型。

Method: 提出Proto-Former，包含自适应原型感知编码器（APAE）和渐进式原型感知解码器（PPAD），并设计原型感知（PA）损失函数，以增强数据集特定的面部结构表征，支持多数据集联合训练。

Result: 在多个主流基准数据集上的实验表明，Proto-Former性能优于现有的最先进方法。

Conclusion: Proto-Former通过原型感知机制有效解决了多数据集训练中的专家寻址不稳定和梯度冲突问题，实现了更准确的面部结构特征提取，推动了统一面部关键点检测模型的发展。

Abstract: Recent advances in deep learning have significantly improved facial landmark
detection. However, existing facial landmark detection datasets often define
different numbers of landmarks, and most mainstream methods can only be trained
on a single dataset. This limits the model generalization to different datasets
and hinders the development of a unified model. To address this issue, we
propose Proto-Former, a unified, adaptive, end-to-end facial landmark detection
framework that explicitly enhances dataset-specific facial structural
representations (i.e., prototype). Proto-Former overcomes the limitations of
single-dataset training by enabling joint training across multiple datasets
within a unified architecture. Specifically, Proto-Former comprises two key
components: an Adaptive Prototype-Aware Encoder (APAE) that performs adaptive
feature extraction and learns prototype representations, and a Progressive
Prototype-Aware Decoder (PPAD) that refines these prototypes to generate
prompts that guide the model's attention to key facial regions. Furthermore, we
introduce a novel Prototype-Aware (PA) loss, which achieves optimal path
finding by constraining the selection weights of prototype experts. This loss
function effectively resolves the problem of prototype expert addressing
instability during multi-dataset training, alleviates gradient conflicts, and
enables the extraction of more accurate facial structure features. Extensive
experiments on widely used benchmark datasets demonstrate that our Proto-Former
achieves superior performance compared to existing state-of-the-art methods.
The code is publicly available at: https://github.com/Husk021118/Proto-Former.

</details>


### [35] [SHARE: Scene-Human Aligned Reconstruction](https://arxiv.org/abs/2510.15342)
*Joshua Li,Brendan Chharawala,Chang Shu,Xue Bin Peng,Pengcheng Xi*

Main category: cs.CV

TL;DR: 本文提出了一种名为SHARE的新方法，利用场景几何的空间线索来更准确地重建单目视频中的3D人类动作，显著提升了在复杂环境中人物定位的精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将人类准确放置于3D空间中存在困难，尤其是在复杂环境交互中，缺乏对场景几何的有效利用。

Method: SHARE方法首先从单目RGB视频中估计每帧的人体网格和分割掩码，并在关键帧构建场景点云图；然后通过将人体网格与场景中提取的人体点云进行比对，迭代优化关键帧中人体位置，同时保持非关键帧与关键帧之间的根关节相对位置一致性。

Result: 实验表明，SHARE在多个数据集和真实网络视频上均优于现有方法，能够实现更精确的3D人体定位并同步重建周围场景。

Conclusion: SHARE通过融合场景几何信息与人体运动重建，有效解决了单目视频中人体在3D空间中准确定位的问题，适用于游戏、AR/VR和机器人等需要真实角色交互的场景。

Abstract: Animating realistic character interactions with the surrounding environment
is important for autonomous agents in gaming, AR/VR, and robotics. However,
current methods for human motion reconstruction struggle with accurately
placing humans in 3D space. We introduce Scene-Human Aligned REconstruction
(SHARE), a technique that leverages the scene geometry's inherent spatial cues
to accurately ground human motion reconstruction. Each reconstruction relies
solely on a monocular RGB video from a stationary camera. SHARE first estimates
a human mesh and segmentation mask for every frame, alongside a scene point map
at keyframes. It iteratively refines the human's positions at these keyframes
by comparing the human mesh against the human point map extracted from the
scene using the mask. Crucially, we also ensure that non-keyframe human meshes
remain consistent by preserving their relative root joint positions to keyframe
root joints during optimization. Our approach enables more accurate 3D human
placement while reconstructing the surrounding scene, facilitating use cases on
both curated datasets and in-the-wild web videos. Extensive experiments
demonstrate that SHARE outperforms existing methods.

</details>


### [36] [Cortical-SSM: A Deep State Space Model for EEG and ECoG Motor Imagery Decoding](https://arxiv.org/abs/2510.15371)
*Shuntaro Suzuki,Shunya Nagashima,Masayuki Hirata,Komei Sugiura*

Main category: cs.CV

TL;DR: 提出了一种名为Cortical-SSM的新架构，用于在时间、空间和频率域上捕捉脑电图（EEG）和皮层脑电图（ECoG）信号的综合依赖关系，该方法在多个基准测试中优于基线方法，并能有效识别神经生理相关区域。


<details>
  <summary>Details</summary>
Motivation: 脑电图和皮层脑电图信号在运动想象分类中具有广泛应用潜力，但易受生理伪影干扰且现有Transformer方法难以捕捉细粒度依赖关系。

Method: 提出Cortical-SSM，扩展深度状态空间模型以捕捉EEG和ECoG信号在时、空、频域的综合依赖性。

Result: 在两个大规模公开EEG数据集和一个肌萎缩侧索硬化症患者的临床ECoG数据集上，Cortical-SSM均优于基线方法，可视化解释显示其能有效捕捉神经生理相关区域。

Conclusion: Cortical-SSM在处理EEG和ECoG信号分类任务中表现出优越性能，具备应用于辅助通信和康复支持的潜力。

Abstract: Classification of electroencephalogram (EEG) and electrocorticogram (ECoG)
signals obtained during motor imagery (MI) has substantial application
potential, including for communication assistance and rehabilitation support
for patients with motor impairments. These signals remain inherently
susceptible to physiological artifacts (e.g., eye blinking, swallowing), which
pose persistent challenges. Although Transformer-based approaches for
classifying EEG and ECoG signals have been widely adopted, they often struggle
to capture fine-grained dependencies within them. To overcome these
limitations, we propose Cortical-SSM, a novel architecture that extends deep
state space models to capture integrated dependencies of EEG and ECoG signals
across temporal, spatial, and frequency domains. We validated our method across
three benchmarks: 1) two large-scale public MI EEG datasets containing more
than 50 subjects, and 2) a clinical MI ECoG dataset recorded from a patient
with amyotrophic lateral sclerosis. Our method outperformed baseline methods on
the three benchmarks. Furthermore, visual explanations derived from our model
indicate that it effectively captures neurophysiologically relevant regions of
both EEG and ECoG signals.

</details>


### [37] [Adaptive transfer learning for surgical tool presence detection in laparoscopic videos through gradual freezing fine-tuning](https://arxiv.org/abs/2510.15372)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: 提出一种分阶段自适应微调方法，通过线性探测和逐步冻结策略提升手术工具检测性能，在Cholec80和CATARACTS数据集上取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 手术环境中标注数据有限，传统深度学习模型难以训练出鲁棒的手术工具检测模型，需更高效的微调策略。

Method: 采用预训练CNN架构（如ResNet-50、DenseNet-121），先进行线性探测以构建分类层，再通过逐步冻结减少可微调层数，实现单轮训练下的高效域适应。

Result: 在Cholec80数据集上达到96.4%的mAP，优于现有方法，并在CATARACTS数据集上验证了方法的泛化能力。

Conclusion: 逐步冻结微调是一种有效的手术工具检测优化策略，具有跨手术领域的适用性和潜在的通用图像分类应用价值。

Abstract: Minimally invasive surgery can benefit significantly from automated surgical
tool detection, enabling advanced analysis and assistance. However, the limited
availability of annotated data in surgical settings poses a challenge for
training robust deep learning models. This paper introduces a novel staged
adaptive fine-tuning approach consisting of two steps: a linear probing stage
to condition additional classification layers on a pre-trained CNN-based
architecture and a gradual freezing stage to dynamically reduce the
fine-tunable layers, aiming to regulate adaptation to the surgical domain. This
strategy reduces network complexity and improves efficiency, requiring only a
single training loop and eliminating the need for multiple iterations. We
validated our method on the Cholec80 dataset, employing CNN architectures
(ResNet-50 and DenseNet-121) pre-trained on ImageNet for detecting surgical
tools in cholecystectomy endoscopic videos. Our results demonstrate that our
method improves detection performance compared to existing approaches and
established fine-tuning techniques, achieving a mean average precision (mAP) of
96.4%. To assess its broader applicability, the generalizability of the
fine-tuning strategy was further confirmed on the CATARACTS dataset, a distinct
domain of minimally invasive ophthalmic surgery. These findings suggest that
gradual freezing fine-tuning is a promising technique for improving tool
presence detection in diverse surgical procedures and may have broader
applications in general image classification tasks.

</details>


### [38] [FreqPDE: Rethinking Positional Depth Embedding for Multi-View 3D Object Detection Transformers](https://arxiv.org/abs/2510.15385)
*Haisheng Su,Junjie Zhang,Feixiang Song,Sanping Zhou,Wei Wu,Nanning Zheng,Junchi Yan*

Main category: cs.CV

TL;DR: 本文提出了一种名为FreqPDE的频率感知位置深度嵌入方法，用于从多视图2D图像中进行3D目标检测，通过三个模块和混合深度监督提升空间信息恢复与检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖LiDAR点进行深度预测监督，但深度质量不佳，存在物体边界不连续、小物体识别困难等问题，且缺乏对跨视角一致性和尺度不变性的考虑。

Method: 提出FreqPDE，包含频率感知空间金字塔编码器（FSPE）、跨视角尺度不变深度预测器（CSDP）和位置深度编码器（PDE），结合高频边缘与低频语义特征，利用跨视角与通道注意力机制预测像素级深度分布，并融合2D特征与3D位置嵌入生成深度感知特征，同时采用混合深度监督。

Result: 在nuScenes数据集上的大量实验表明，该方法在3D检测性能上优于现有方法，有效提升了深度估计质量和检测精度。

Conclusion: FreqPDE通过精细化的特征融合与深度预测机制，在无需密集LiDAR监督的情况下显著提升了多视图3D检测性能，具有良好的应用前景。

Abstract: Detecting 3D objects accurately from multi-view 2D images is a challenging
yet essential task in the field of autonomous driving. Current methods resort
to integrating depth prediction to recover the spatial information for object
query decoding, which necessitates explicit supervision from LiDAR points
during the training phase. However, the predicted depth quality is still
unsatisfactory such as depth discontinuity of object boundaries and
indistinction of small objects, which are mainly caused by the sparse
supervision of projected points and the use of high-level image features for
depth prediction. Besides, cross-view consistency and scale invariance are also
overlooked in previous methods. In this paper, we introduce Frequency-aware
Positional Depth Embedding (FreqPDE) to equip 2D image features with spatial
information for 3D detection transformer decoder, which can be obtained through
three main modules. Specifically, the Frequency-aware Spatial Pyramid Encoder
(FSPE) constructs a feature pyramid by combining high-frequency edge clues and
low-frequency semantics from different levels respectively. Then the Cross-view
Scale-invariant Depth Predictor (CSDP) estimates the pixel-level depth
distribution with cross-view and efficient channel attention mechanism.
Finally, the Positional Depth Encoder (PDE) combines the 2D image features and
3D position embeddings to generate the 3D depth-aware features for query
decoding. Additionally, hybrid depth supervision is adopted for complementary
depth learning from both metric and distribution aspects. Extensive experiments
conducted on the nuScenes dataset demonstrate the effectiveness and superiority
of our proposed method.

</details>


### [39] [PFGS: Pose-Fused 3D Gaussian Splatting for Complete Multi-Pose Object Reconstruction](https://arxiv.org/abs/2510.15386)
*Ting-Yu Yen,Yu-Sheng Chiu,Shih-Hsuan Hung,Peter Wonka,Hung-Kuo Chu*

Main category: cs.CV

TL;DR: 本文提出了一种姿态感知的3D高斯点阵化框架PFGS，用于从多姿态图像中重建完整物体，通过融合主姿态与辅助姿态图像，结合全局与局部配准策略，提升了重建完整性与精度。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯点阵化方法通常假设物体处于单一静态姿态，导致遮挡区域无法重建，难以实现完整三维建模。

Method: PFGS采用姿态感知的融合策略，结合全局与局部配准，利用背景特征进行每姿态相机位姿估计，并引入基础模型实现跨姿态配准，逐步将辅助姿态图像融合至主姿态的统一3DGS表示中。

Result: 实验表明，PFGS在定性和定量评估中均优于强基线方法，能够生成更完整的重建结果和更高保真度的3DGS模型。

Conclusion: PFGS有效解决了多姿态下物体完整重建的问题，通过智能整合基础模型与背景特征，在降低内存消耗的同时提高了配准精度与重建质量。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled high-quality,
real-time novel-view synthesis from multi-view images. However, most existing
methods assume the object is captured in a single, static pose, resulting in
incomplete reconstructions that miss occluded or self-occluded regions. We
introduce PFGS, a pose-aware 3DGS framework that addresses the practical
challenge of reconstructing complete objects from multi-pose image captures.
Given images of an object in one main pose and several auxiliary poses, PFGS
iteratively fuses each auxiliary set into a unified 3DGS representation of the
main pose. Our pose-aware fusion strategy combines global and local
registration to merge views effectively and refine the 3DGS model. While recent
advances in 3D foundation models have improved registration robustness and
efficiency, they remain limited by high memory demands and suboptimal accuracy.
PFGS overcomes these challenges by incorporating them more intelligently into
the registration process: it leverages background features for per-pose camera
pose estimation and employs foundation models for cross-pose registration. This
design captures the best of both approaches while resolving background
inconsistency issues. Experimental results demonstrate that PFGS consistently
outperforms strong baselines in both qualitative and quantitative evaluations,
producing more complete reconstructions and higher-fidelity 3DGS models.

</details>


### [40] [LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding](https://arxiv.org/abs/2510.15392)
*Peng Ren,Hai Yang*

Main category: cs.CV

TL;DR: LILAC提出了一种在线实时任意运动风格化方法，通过潜空间流式架构和因果滑窗设计，实现高质量、低延迟的长序列人体运动生成。


<details>
  <summary>Details</summary>
Motivation: 现有流式方法在原始运动空间操作导致计算开销大且时序不稳定；基于潜空间VAE-扩散的离线框架虽质量高但无法实时处理，需填补实时性与质量之间的差距。

Method: 基于高性能离线框架，构建流式VAE-扩散模型，采用滑窗因果结构并在解码中注入运动特征以保证过渡平滑，不依赖未来帧也不修改扩散模型结构。

Result: 在基准数据集上实现了高质量、低延迟的长序列实时运动风格化，平衡了风格化效果与响应速度。

Conclusion: LILAC成功将离线运动风格化模型扩展到在线场景，适用于需要连续响应控制的应用。

Abstract: Generating long and stylized human motions in real time is critical for
applications that demand continuous and responsive character control. Despite
its importance, existing streaming approaches often operate directly in the raw
motion space, leading to substantial computational overhead and making it
difficult to maintain temporal stability. In contrast, latent-space
VAE-Diffusion-based frameworks alleviate these issues and achieve high-quality
stylization, but they are generally confined to offline processing. To bridge
this gap, LILAC (Long-sequence Incremental Low-latency Arbitrary Motion
Stylization via Streaming VAE-Diffusion with Causal Decoding) builds upon a
recent high-performing offline framework for arbitrary motion stylization and
extends it to an online setting through a latent-space streaming architecture
with a sliding-window causal design and the injection of decoded motion
features to ensure smooth motion transitions. This architecture enables
long-sequence real-time arbitrary stylization without relying on future frames
or modifying the diffusion model architecture, achieving a favorable balance
between stylization quality and responsiveness as demonstrated by experiments
on benchmark datasets. Supplementary video and examples are available at the
project page: https://pren1.github.io/lilac/

</details>


### [41] [MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment](https://arxiv.org/abs/2510.15398)
*Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出了MARIS，首个大规模水下开放词汇实例分割基准，并设计了统一框架GPEM和SAIM模块，以应对水下场景中的视觉退化和语义错位问题，在域内和跨域设置下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有水下实例分割方法受限于闭合词汇预测，难以识别新海洋类别；同时，开放词汇方法在自然图像上表现良好，但迁移到水下场景时因视觉退化和语义不匹配而性能下降。

Method: 提出包含几何先验增强模块（GPEM）和语义对齐注入机制（SAIM）的统一框架：GPEM利用部分级和结构线索增强退化条件下的物体一致性，SAIM则通过领域特定先验丰富语言嵌入，缓解语义模糊性。

Result: 在新提出的MARIS基准上实验表明，该方法在域内和跨域开放词汇分割任务中均显著优于现有基线方法。

Conclusion: 所提框架有效解决了水下开放词汇实例分割中的视觉退化与语义错位问题，为未来水下感知研究提供了坚实基础。

Abstract: Most existing underwater instance segmentation approaches are constrained by
close-vocabulary prediction, limiting their ability to recognize novel marine
categories. To support evaluation, we introduce \textbf{MARIS}
(\underline{Mar}ine Open-Vocabulary \underline{I}nstance
\underline{S}egmentation), the first large-scale fine-grained benchmark for
underwater Open-Vocabulary (OV) segmentation, featuring a limited set of seen
categories and diverse unseen categories. Although OV segmentation has shown
promise on natural images, our analysis reveals that transfer to underwater
scenes suffers from severe visual degradation (e.g., color attenuation) and
semantic misalignment caused by lack underwater class definitions. To address
these issues, we propose a unified framework with two complementary components.
The Geometric Prior Enhancement Module (\textbf{GPEM}) leverages stable
part-level and structural cues to maintain object consistency under degraded
visual conditions. The Semantic Alignment Injection Mechanism (\textbf{SAIM})
enriches language embeddings with domain-specific priors, mitigating semantic
ambiguity and improving recognition of unseen categories. Experiments show that
our framework consistently outperforms existing OV baselines both In-Domain and
Cross-Domain setting on MARIS, establishing a strong foundation for future
underwater perception research.

</details>


### [42] [Robust High-Resolution Multi-Organ Diffusion MRI Using Synthetic-Data-Tuned Prompt Learning](https://arxiv.org/abs/2510.15400)
*Chen Qian,Haoyu Zhang,Junnan Ma,Liuhong Zhu,Qingrui Cai,Yu Wang,Ruibo Song,Lv Li,Lin Mei,Xianwang Jiang,Qin Xu,Boyu Jiang,Ran Tao,Chunmiao Chen,Shufang Chen,Dongyun Liang,Qiu Guo,Jianzhong Lin,Taishan Kang,Mengtian Lu,Liyuan Fu,Ruibin Huang,Huijuan Wan,Xu Huang,Jianhua Wang,Di Guo,Hai Zhong,Jianjun Zhou,Xiaobo Qu*

Main category: cs.CV

TL;DR: 提出了一种名为LoSP-Prompt的重建框架，用于克服多射扩散加权成像中因生理运动引起的相位伪影，实现高分辨率、多器官、无导航信号的全身肿瘤诊断成像。


<details>
  <summary>Details</summary>
Motivation: 临床中多射DWI因呼吸、肠蠕动等引起的相位伪影及多器官、多参数复杂性而受限，亟需一种鲁棒、高分辨率且无需导航信号的重建方法。

Method: 通过物理信息建模与合成数据驱动的提示学习相结合：将 shot间相位变化建模为高阶局部平滑相位（LoSP），并集成到低秩Hankel矩阵重建中；利用仅基于合成腹部DWI数据训练的提示学习自动设置算法的秩参数。

Result: 在超过10,000张临床图像上验证（43名受试者，4种扫描仪，5个中心），LoSP-Prompt实现了单次激发DWI两倍的空间分辨率，提升了肝病灶可见性；单个模型通用于7个不同解剖区域；在图像质量、伪影抑制和降噪方面优于现有方法（11名放射科医生评分，p<0.05）；无需导航信号和真实标注数据监督。

Conclusion: LoSP-Prompt是一种可解释、鲁棒、扫描仪无关的高分辨率多器官多射DWI解决方案，在精准肿瘤学中具有变革潜力。

Abstract: Clinical adoption of multi-shot diffusion-weighted magnetic resonance imaging
(multi-shot DWI) for body-wide tumor diagnostics is limited by severe
motion-induced phase artifacts from respiration, peristalsis, and so on,
compounded by multi-organ, multi-slice, multi-direction and multi-b-value
complexities. Here, we introduce a reconstruction framework, LoSP-Prompt, that
overcomes these challenges through physics-informed modeling and
synthetic-data-driven prompt learning. We model inter-shot phase variations as
a high-order Locally Smooth Phase (LoSP), integrated into a low-rank Hankel
matrix reconstruction. Crucially, the algorithm's rank parameter is
automatically set via prompt learning trained exclusively on synthetic
abdominal DWI data emulating physiological motion. Validated across 10,000+
clinical images (43 subjects, 4 scanner models, 5 centers), LoSP-Prompt: (1)
Achieved twice the spatial resolution of clinical single-shot DWI, enhancing
liver lesion conspicuity; (2) Generalized to seven diverse anatomical regions
(liver, kidney, sacroiliac, pelvis, knee, spinal cord, brain) with a single
model; (3) Outperformed state-of-the-art methods in image quality, artifact
suppression, and noise reduction (11 radiologists' evaluations on a 5-point
scale, $p<0.05$), achieving 4-5 points (excellent) on kidney DWI, 4 points
(good to excellent) on liver, sacroiliac and spinal cord DWI, and 3-4 points
(good) on knee and tumor brain. The approach eliminates navigator signals and
realistic data supervision, providing an interpretable, robust solution for
high-resolution multi-organ multi-shot DWI. Its scanner-agnostic performance
signifies transformative potential for precision oncology.

</details>


### [43] [Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models](https://arxiv.org/abs/2510.15430)
*Shuang Liang,Zhihao Xu,Jialing Tao,Hui Xue,Xiting Wang*

Main category: cs.CV

TL;DR: 提出了一种名为LoD的通用框架，通过多模态安全概念激活向量和安全模式自编码器模块，有效检测大视觉-语言模型中的未知越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在泛化性和准确性上存在局限，难以应对未知的越狱攻击。

Method: 采用任务特定学习替代攻击特定学习，结合多模态安全概念激活向量和无监督的安全模式自编码器进行攻击分类。

Result: 实验表明，该方法在多种未知攻击上的检测AUROC consistently 更高，且效率更优。

Conclusion: LoD框架能有效提升对未知越狱攻击的检测性能，具有良好的通用性和实用性。

Abstract: Despite extensive alignment efforts, Large Vision-Language Models (LVLMs)
remain vulnerable to jailbreak attacks, posing serious safety risks. To address
this, existing detection methods either learn attack-specific parameters, which
hinders generalization to unseen attacks, or rely on heuristically sound
principles, which limit accuracy and efficiency. To overcome these limitations,
we propose Learning to Detect (LoD), a general framework that accurately
detects unknown jailbreak attacks by shifting the focus from attack-specific
learning to task-specific learning. This framework includes a Multi-modal
Safety Concept Activation Vector module for safety-oriented representation
learning and a Safety Pattern Auto-Encoder module for unsupervised attack
classification. Extensive experiments show that our method achieves
consistently higher detection AUROC on diverse unknown attacks while improving
efficiency. The code is available at
https://anonymous.4open.science/r/Learning-to-Detect-51CB.

</details>


### [44] [Semantic4Safety: Causal Insights from Zero-shot Street View Imagery Segmentation for Urban Road Safety](https://arxiv.org/abs/2510.15434)
*Huan Chen,Ting Han,Siyu Chen,Zhihao Guo,Yiping Chen,Meiliu Wu*

Main category: cs.CV

TL;DR: 提出Semantic4Safety框架，利用街景图像进行语义分割以构建街道级安全指标，并结合因果推断方法分析不同事故类型的成因。


<details>
  <summary>Details</summary>
Motivation: 解决街景图像在交通风险分析中缺乏可解释性街道级指标及难以量化其对不同类型事故因果影响的问题。

Method: 采用零样本语义分割提取11个可解释的街道环境特征，结合道路类型信息，使用XGBoost多分类模型与SHAP解释性分析，并通过广义倾向评分加权和平均处理效应估计进行因果推断。

Result: 发现场景复杂度、暴露程度和道路几何特征对预测贡献最大；可行驶区域和应急空间增大降低风险，而过度视觉开放可能增加风险。不同事故类型表现出异质性因果模式。

Conclusion: Semantic4Safety通过融合预测模型与因果推断，支持针对性干预和高风险路段诊断，为城市道路安全规划提供可扩展的数据驱动工具。

Abstract: Street-view imagery (SVI) offers a fine-grained lens on traffic risk, yet two
fundamental challenges persist: (1) how to construct street-level indicators
that capture accident-related features, and (2) how to quantify their causal
impacts across different accident types. To address these challenges, we
propose Semantic4Safety, a framework that applies zero-shot semantic
segmentation to SVIs to derive 11 interpretable streetscape indicators, and
integrates road type as contextual information to analyze approximately 30,000
accident records in Austin. Specifically, we train an eXtreme Gradient Boosting
(XGBoost) multi-class classifier and use Shapley Additive Explanations (SHAP)
to interpret both global and local feature contributions, and then apply
Generalized Propensity Score (GPS) weighting and Average Treatment Effect (ATE)
estimation to control confounding and quantify causal effects. Results uncover
heterogeneous, accident-type-specific causal patterns: features capturing scene
complexity, exposure, and roadway geometry dominate predictive power; larger
drivable area and emergency space reduce risk, whereas excessive visual
openness can increase it. By bridging predictive modeling with causal
inference, Semantic4Safety supports targeted interventions and high-risk
corridor diagnosis, offering a scalable, data-informed tool for urban road
safety planning.

</details>


### [45] [Rethinking Convergence in Deep Learning: The Predictive-Corrective Paradigm for Anatomy-Informed Brain MRI Segmentation](https://arxiv.org/abs/2510.15439)
*Feifei Zhang,Zhenhong Jia,Sensen Song,Fei Shi,Dayong Ren*

Main category: cs.CV

TL;DR: 提出了一种新的Predictive-Corrective (PC)范式和PCMambaNet网络，通过解耦建模任务加速学习，在脑部MRI分割中实现了最先进的精度，并在1-5个epoch内收敛。


<details>
  <summary>Details</summary>
Motivation: 端到端深度学习模型在数据稀缺领域（如医学影像）中存在收敛慢、依赖大规模数据集的问题，限制了其效率和适用性。

Method: 提出了PC范式和PCMambaNet网络，包含预测先验模块（PPM）和校正残差网络（CRN）。PPM利用解剖学知识生成粗略近似，CRN专注于学习残差误差以精确定位病理边界。

Result: 在高分辨率脑部MRI分割实验中，PCMambaNet在仅1-5个epoch内收敛，达到最先进的精度，显著优于传统端到端模型。

Conclusion: 通过显式引入领域知识简化学习目标，PCMambaNet有效缓解了数据低效和过拟合问题，为数据稀缺场景下的高效学习提供了新思路。

Abstract: Despite the remarkable success of the end-to-end paradigm in deep learning,
it often suffers from slow convergence and heavy reliance on large-scale
datasets, which fundamentally limits its efficiency and applicability in
data-scarce domains such as medical imaging. In this work, we introduce the
Predictive-Corrective (PC) paradigm, a framework that decouples the modeling
task to fundamentally accelerate learning. Building upon this paradigm, we
propose a novel network, termed PCMambaNet. PCMambaNet is composed of two
synergistic modules. First, the Predictive Prior Module (PPM) generates a
coarse approximation at low computational cost, thereby anchoring the search
space. Specifically, the PPM leverages anatomical knowledge-bilateral
symmetry-to predict a 'focus map' of diagnostically relevant asymmetric
regions. Next, the Corrective Residual Network (CRN) learns to model the
residual error, focusing the network's full capacity on refining these
challenging regions and delineating precise pathological boundaries. Extensive
experiments on high-resolution brain MRI segmentation demonstrate that
PCMambaNet achieves state-of-the-art accuracy while converging within only 1-5
epochs-a performance unattainable by conventional end-to-end models. This
dramatic acceleration highlights that by explicitly incorporating domain
knowledge to simplify the learning objective, PCMambaNet effectively mitigates
data inefficiency and overfitting.

</details>


### [46] [Select Less, Reason More: Prioritizing Evidence Purity for Video Reasoning](https://arxiv.org/abs/2510.15440)
*Xuchen Li,Xuzhao Li,Shiyu Hu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 本文提出了一种基于“少选择，多推理”理念的证据感知强化学习（EARL）框架，通过动态选择关键帧并进行局部重采样来提升长视频推理中证据的纯度和时序细节获取能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大模型在长视频推理中因均匀采样导致信息稀释，且缺乏有效的奖励机制保证证据纯度，难以补充预采样之外的时序信息。

Method: 提出EARL框架，结合证据感知的强化学习，动态选择最相关帧，并在关键帧周围进行局部重采样以获取细粒度时序信息。

Result: 在五个视频推理基准上达到开源Video LLM中的最先进水平，7B模型在LongVideoBench、MVBench和VideoMME上分别取得59.8%、69.0%和64.9%的成绩。

Conclusion: 优先考虑证据纯度对长视频推理至关重要，所提出的EARL框架有效提升了视频大模型的推理性能。

Abstract: Long-form video reasoning remains a major challenge for Video Large Language
Models (Video LLMs), as static uniform frame sampling leads to information
dilution and obscures critical evidence. Furthermore, existing pixel-space
video reasoning agents, which are designed to actively interact with the video
to acquire new visual information, remain suboptimal due to their lack of
rigorous reward mechanisms to enforce evidence purity and their inability to
perform temporal information supplementation beyond pre-sampled frames. To
address this critical gap, we propose a novel evidence-prioritized adaptive
framework built upon our core philosophy: "Select Less, Reason More." Our core
contribution is the evidence-aware reinforcement learning (EARL) framework,
which transforms the model into an active interrogator of evidence. EARL is
precisely engineered to dynamically select the most relevant frames and,
crucially, to perform localized re-sampling around the selected key frames to
access fine-grained temporal detail. Extensive experiments on five demanding
video reasoning benchmarks demonstrate that our EARL-trained model achieves new
state-of-the-art among open-source Video LLMs, simultaneously learning an
effective and high-purity visual evidence selection policy. Impressively, our
7B model achieves 59.8% on LongVideoBench, 69.0% on MVBench and 64.9% on
VideoMME. These results highlight the importance of prioritizing evidence
purity and the effectiveness of our framework.

</details>


### [47] [MAVR-Net: Robust Multi-View Learning for MAV Action Recognition with Cross-View Attention](https://arxiv.org/abs/2510.15448)
*Nengbo Zhang,Hann Woei Ho*

Main category: cs.CV

TL;DR: 本文提出了一种基于多视角学习的MAV动作识别框架MAVR-Net，融合RGB、光流和分割掩码数据，结合多尺度特征金字塔和跨视角注意力模块，显著提升了识别精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于RGB的视觉识别模型难以捕捉MAV运动的复杂时空特征，导致动作区分能力有限。

Method: 采用ResNet编码器提取多视角特征，引入多尺度特征金字塔保留时空细节，并设计跨视角注意力模块和多视图对齐损失以增强模态间交互和语义一致性。

Result: 在多个MAV动作数据集上取得显著性能提升，分别在Short MAV、Medium MAV和Long MAV数据集上达到97.8%、96.5%和92.8%的准确率。

Conclusion: MAVR-Net通过有效融合多视角信息和增强跨模态交互，在MAV动作识别任务中表现出优越的鲁棒性和准确性。

Abstract: Recognizing the motion of Micro Aerial Vehicles (MAVs) is crucial for
enabling cooperative perception and control in autonomous aerial swarms. Yet,
vision-based recognition models relying only on RGB data often fail to capture
the complex spatial temporal characteristics of MAV motion, which limits their
ability to distinguish different actions. To overcome this problem, this paper
presents MAVR-Net, a multi-view learning-based MAV action recognition
framework. Unlike traditional single-view methods, the proposed approach
combines three complementary types of data, including raw RGB frames, optical
flow, and segmentation masks, to improve the robustness and accuracy of MAV
motion recognition. Specifically, ResNet-based encoders are used to extract
discriminative features from each view, and a multi-scale feature pyramid is
adopted to preserve the spatiotemporal details of MAV motion patterns. To
enhance the interaction between different views, a cross-view attention module
is introduced to model the dependencies among various modalities and feature
scales. In addition, a multi-view alignment loss is designed to ensure semantic
consistency and strengthen cross-view feature representations. Experimental
results on benchmark MAV action datasets show that our method clearly
outperforms existing approaches, achieving 97.8\%, 96.5\%, and 92.8\% accuracy
on the Short MAV, Medium MAV, and Long MAV datasets, respectively.

</details>


### [48] [DPTrack:Directional Kernel-Guided Prompt Learning for Robust Nighttime Aerial Tracking](https://arxiv.org/abs/2510.15449)
*Zhiqiang Zhu,Xinbo Gao,Wen Lu,Jie Li,Zhaoyang Wang,Mingqian Ge*

Main category: cs.CV

TL;DR: 本文提出了一种名为DPTrack的夜间航拍跟踪器，通过引入细粒度线索和拓扑结构信息来生成更精确的提示，从而提升在低光照条件下的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示学习的夜间航拍跟踪器仅依赖于空间定位监督，缺乏指向目标特征的细粒度线索，导致提示模糊，跟踪效果不佳。

Method: DPTrack受视觉仿生启发，首先分层捕获目标的拓扑结构，利用拓扑属性增强特征表示；然后通过编码器将拓扑感知特征压缩到方向核中，作为包含细粒度属性线索的核心引导信号；最后，基于通道-类别对应关系的核引导提示模块在搜索区域传播该核以精确定位目标特征并生成精确提示，并结合空间门控机制实现鲁棒的夜间跟踪。

Result: 在多个标准基准上的实验表明，DPTrack在夜间航拍场景中显著优于现有方法，展现出卓越的跟踪性能。

Conclusion: DPTrack通过引入拓扑感知的方向核与细粒度属性编码机制，有效提升了夜间航拍跟踪中提示的准确性与鲁棒性，为基于提示学习的跟踪框架提供了新的思路。

Abstract: Existing nighttime aerial trackers based on prompt learning rely solely on
spatial localization supervision, which fails to provide fine-grained cues that
point to target features and inevitably produces vague prompts. This limitation
impairs the tracker's ability to accurately focus on the object features and
results in trackers still performing poorly. To address this issue, we propose
DPTrack, a prompt-based aerial tracker designed for nighttime scenarios by
encoding the given object's attribute features into the directional kernel
enriched with fine-grained cues to generate precise prompts. Specifically,
drawing inspiration from visual bionics, DPTrack first hierarchically captures
the object's topological structure, leveraging topological attributes to enrich
the feature representation. Subsequently, an encoder condenses these
topology-aware features into the directional kernel, which serves as the core
guidance signal that explicitly encapsulates the object's fine-grained
attribute cues. Finally, a kernel-guided prompt module built on
channel-category correspondence attributes propagates the kernel across the
features of the search region to pinpoint the positions of target features and
convert them into precise prompts, integrating spatial gating for robust
nighttime tracking. Extensive evaluations on established benchmarks demonstrate
DPTrack's superior performance. Our code will be available at
https://github.com/zzq-vipsl/DPTrack.

</details>


### [49] [Improving Micro-Expression Recognition with Phase-Aware Temporal Augmentation](https://arxiv.org/abs/2510.15466)
*Vu Tram Anh Khuong,Luu Tu Nguyen,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: 提出了一种基于动态图像的相位感知时间增强方法，通过将微表情分解为两个运动阶段（onset-to-apex 和 apex-to-offset）并生成双阶段动态图像（Dual-phase DI），有效提升微表情识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有微表情识别研究缺乏有效的时间增强策略，且标注数据稀缺，限制了模型泛化能力和运动模式多样性。

Method: 将微表情序列分解为onset-to-apex和apex-to-offset两个阶段，分别为每个阶段生成动态图像（DI），形成双阶段DI增强策略，以引入更丰富的运动多样性和关键的时间线索。

Result: 在CASME-II和SAMM数据集上，结合六种深度模型（包括CNN、Vision Transformer和LEARNet）实验表明，该方法在识别准确率、无权重F1分数和无权重平均召回率上均有显著提升，结合空间增强最高实现10%的相对改进。

Conclusion: 所提出的双阶段时间增强方法简单、与模型无关，且在低资源场景下仍有效，为鲁棒和可泛化的微表情识别提供了新方向。

Abstract: Micro-expressions (MEs) are brief, involuntary facial movements that reveal
genuine emotions, typically lasting less than half a second. Recognizing these
subtle expressions is critical for applications in psychology, security, and
behavioral analysis. Although deep learning has enabled significant advances in
micro-expression recognition (MER), its effectiveness is limited by the
scarcity of annotated ME datasets. This data limitation not only hinders
generalization but also restricts the diversity of motion patterns captured
during training. Existing MER studies predominantly rely on simple spatial
augmentations (e.g., flipping, rotation) and overlook temporal augmentation
strategies that can better exploit motion characteristics. To address this gap,
this paper proposes a phase-aware temporal augmentation method based on dynamic
image. Rather than encoding the entire expression as a single onset-to-offset
dynamic image (DI), our approach decomposes each expression sequence into two
motion phases: onset-to-apex and apex-to-offset. A separate DI is generated for
each phase, forming a Dual-phase DI augmentation strategy. These phase-specific
representations enrich motion diversity and introduce complementary temporal
cues that are crucial for recognizing subtle facial transitions. Extensive
experiments on CASME-II and SAMM datasets using six deep architectures,
including CNNs, Vision Transformer, and the lightweight LEARNet, demonstrate
consistent performance improvements in recognition accuracy, unweighted
F1-score, and unweighted average recall, which are crucial for addressing class
imbalance in MER. When combined with spatial augmentations, our method achieves
up to a 10\% relative improvement. The proposed augmentation is simple,
model-agnostic, and effective in low-resource settings, offering a promising
direction for robust and generalizable MER.

</details>


### [50] [MRASfM: Multi-Camera Reconstruction and Aggregation through Structure-from-Motion in Driving Scenes](https://arxiv.org/abs/2510.15467)
*Lingfeng Xuan,Chang Nie,Yiqing Xu,Zhe Liu,Yanzi Miao,Hesheng Wang*

Main category: cs.CV

TL;DR: 提出了一种针对驾驶场景的多相机结构光运动（MRASfM）框架，通过利用多相机系统的固定空间关系、平面模型去噪和捆绑调整优化，显著提升了相机位姿估计的可靠性、路面重建质量及效率，并实现了多场景的粗到精聚合。


<details>
  <summary>Details</summary>
Motivation: 传统SfM在多相机系统拍摄的驾驶场景中存在位姿估计不可靠、路面重建异常点多、效率低等问题。

Method: 利用多相机系统的固定空间关系增强位姿估计；采用平面模型去除路面三角化中的错误点；将多相机组视为单一单元进行捆绑调整以减少优化变量；通过场景关联与组装模块实现多场景聚合。

Result: 在nuScenes数据集上实现了0.124的绝对位姿误差，大规模实验验证了其在不同场景下的泛化能力和挑战环境下的鲁棒性。

Conclusion: MRASfM在驾驶场景中实现了高精度、高效率和高质量的三维重建，优于现有方法，具备实际应用价值。

Abstract: Structure from Motion (SfM) estimates camera poses and reconstructs point
clouds, forming a foundation for various tasks. However, applying SfM to
driving scenes captured by multi-camera systems presents significant
difficulties, including unreliable pose estimation, excessive outliers in road
surface reconstruction, and low reconstruction efficiency. To address these
limitations, we propose a Multi-camera Reconstruction and Aggregation
Structure-from-Motion (MRASfM) framework specifically designed for driving
scenes. MRASfM enhances the reliability of camera pose estimation by leveraging
the fixed spatial relationships within the multi-camera system during the
registration process. To improve the quality of road surface reconstruction,
our framework employs a plane model to effectively remove erroneous points from
the triangulated road surface. Moreover, treating the multi-camera set as a
single unit in Bundle Adjustment (BA) helps reduce optimization variables to
boost efficiency. In addition, MRASfM achieves multi-scene aggregation through
scene association and assembly modules in a coarse-to-fine fashion. We deployed
multi-camera systems on actual vehicles to validate the generalizability of
MRASfM across various scenes and its robustness in challenging conditions
through real-world applications. Furthermore, large-scale validation results on
public datasets show the state-of-the-art performance of MRASfM, achieving
0.124 absolute pose error on the nuScenes dataset.

</details>


### [51] [A Novel Combined Optical Flow Approach for Comprehensive Micro-Expression Recognition](https://arxiv.org/abs/2510.15471)
*Vu Tram Anh Khuong,Thi Bich Phuong Man,Luu Tu Nguyen,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: 提出了一种结合起始到峰值和峰值到结束阶段的联合光流（COF）方法，以提升微表情识别性能。


<details>
  <summary>Details</summary>
Motivation: 大多数微表情识别方法仅关注 onset-to-apex 阶段的光流，忽略了 apex-to-offset 阶段中包含的重要时序动态信息。

Method: 引入联合光流（COF），整合onset-to-apex和apex-to-offset两个阶段的光流信息，以增强微表情的特征表示。

Result: 在CASMEII和SAMM数据集上的实验表明，COF优于仅使用单一光流的方法，显著提升了微表情识别效果。

Conclusion: COF能更全面地捕捉微表情的运动动态，有效提升识别性能。

Abstract: Facial micro-expressions are brief, involuntary facial movements that reveal
hidden emotions. Most Micro-Expression Recognition (MER) methods that rely on
optical flow typically focus on the onset-to-apex phase, neglecting the
apex-to-offset phase, which holds key temporal dynamics. This study introduces
a Combined Optical Flow (COF), integrating both phases to enhance feature
representation. COF provides a more comprehensive motion analysis, improving
MER performance. Experimental results on CASMEII and SAMM datasets show that
COF outperforms single optical flow-based methods, demonstrating its
effectiveness in capturing micro-expression dynamics.

</details>


### [52] [Iterative Motion Compensation for Canonical 3D Reconstruction from UAV Plant Images Captured in Windy Conditions](https://arxiv.org/abs/2510.15491)
*Andre Rochow,Jonas Marcic,Svetlana Seliunina,Sven Behnke*

Main category: cs.CV

TL;DR: 提出一种无人机辅助的植物3D重建管道，通过迭代优化减轻叶片运动影响，提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 实现高质量植物3D表型分析，用于研究植物生长、产量预测和病害控制。

Method: 使用小型商用无人机自动采集植物图像，结合ArUco标记和自研Android应用控制；采用基于光流估计的迭代图像配准方法，逐步校正叶片运动导致的误差，并支持集成任意先进3D重建算法。

Result: 该管道显著提升了现有3D重建方法的效果，生成高分辨率3D网格；公开了源代码和包含多种作物多时段的植物数据集。

Conclusion: 所提方法有效缓解了环境风和无人机下洗气流引起的叶片运动问题，实现了高质量、高鲁棒性的单株植物3D重建。

Abstract: 3D phenotyping of plants plays a crucial role for understanding plant growth,
yield prediction, and disease control. We present a pipeline capable of
generating high-quality 3D reconstructions of individual agricultural plants.
To acquire data, a small commercially available UAV captures images of a
selected plant. Apart from placing ArUco markers, the entire image acquisition
process is fully autonomous, controlled by a self-developed Android application
running on the drone's controller. The reconstruction task is particularly
challenging due to environmental wind and downwash of the UAV. Our proposed
pipeline supports the integration of arbitrary state-of-the-art 3D
reconstruction methods. To mitigate errors caused by leaf motion during image
capture, we use an iterative method that gradually adjusts the input images
through deformation. Motion is estimated using optical flow between the
original input images and intermediate 3D reconstructions rendered from the
corresponding viewpoints. This alignment gradually reduces scene motion,
resulting in a canonical representation. After a few iterations, our pipeline
improves the reconstruction of state-of-the-art methods and enables the
extraction of high-resolution 3D meshes. We will publicly release the source
code of our reconstruction pipeline. Additionally, we provide a dataset
consisting of multiple plants from various crops, captured across different
points in time.

</details>


### [53] [Rethinking Efficient Hierarchical Mixing Architecture for Low-light RAW Image Enhancement](https://arxiv.org/abs/2510.15497)
*Xianmin Chen,Peiliang Huang,Longfei Han,Dingwen Zhang,Junwei Han*

Main category: cs.CV

TL;DR: 本文提出了一种用于低光照RAW图像增强的高效分层混合架构HiMA，结合Transformer和Mamba模块的优势，并引入局部分布调整（LoDA）和多先验融合（MPF）模块，在多个数据集上实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的低光照图像增强方法在增强质量与效率之间难以兼顾，且存在两阶段框架中的模糊问题，同时对光照不均和局部变化处理不足。

Method: 提出HiMA架构，利用Transformer处理大尺度特征、Mamba处理小尺度特征；设计LoDA模块以自适应对齐不同局部区域的特征分布；采用MPF模块融合空间域和频域先验信息以增强细节。

Result: 在多个公开数据集上实验表明，该方法在更少参数量下优于当前最先进的方法，具有更高的增强质量和效率。

Conclusion: HiMA通过合理的架构设计和模块创新，在低光照RAW图像增强任务中实现了高效且高质量的性能，具备较强的实用潜力。

Abstract: Low-light RAW image enhancement remains a challenging task. Although numerous
deep learning based approaches have been proposed, they still suffer from
inherent limitations. A key challenge is how to simultaneously achieve strong
enhancement quality and high efficiency. In this paper, we rethink the
architecture for efficient low-light image signal processing (ISP) and
introduce a Hierarchical Mixing Architecture (HiMA). HiMA leverages the
complementary strengths of Transformer and Mamba modules to handle features at
large and small scales, respectively, thereby improving efficiency while
avoiding the ambiguities observed in prior two-stage frameworks. To further
address uneven illumination with strong local variations, we propose Local
Distribution Adjustment (LoDA), which adaptively aligns feature distributions
across different local regions. In addition, to fully exploit the denoised
outputs from the first stage, we design a Multi-prior Fusion (MPF) module that
integrates spatial and frequency-domain priors for detail enhancement.
Extensive experiments on multiple public datasets demonstrate that our method
outperforms state-of-the-art approaches, achieving superior performance with
fewer parameters. Code will be released at https://github.com/Cynicarlos/HiMA.

</details>


### [54] [Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI](https://arxiv.org/abs/2502.17092)
*Syed Abdul Gaffar Shakhadri,Kruthika KR,Kartik Basavaraj Angadi*

Main category: cs.CV

TL;DR: Shakti VLM 是一个具有1B和4B参数的视觉-语言模型系列，通过架构创新和三阶段训练策略，在较少数据下实现高效多模态学习，尤其在文档理解、视觉推理和OCR等任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决当前视觉-语言模型依赖大量训练数据导致的数据效率低下问题，探索通过模型设计而非数据规模来提升性能的路径。

Method: 采用QK归一化、混合归一化技术和增强的位置编码，并结合三阶段训练策略以提高学习效率。

Result: Shakti-VLM-1B 和 Shakti-VLM-4B 在文档理解、视觉推理、OCR提取和通用多模态推理任务上表现出色，用更少的训练token达到竞争力的结果。

Conclusion: 高效的模型设计和训练策略可以在减少对大规模数据依赖的同时实现高性能，Shakti为大规模企业级多模态任务提供了一种高效解决方案。

Abstract: We introduce Shakti VLM, a family of vision-language models in the capacity
of 1B and 4B parameters designed to address data efficiency challenges in
multimodal learning. While recent VLMs achieve strong performance through
extensive training data, Shakti models leverage architectural innovations to
attain competitive results with fewer tokens. Key advancements include
QK-Normalization for attention stability, hybrid normalization techniques, and
enhanced positional encoding. A three-stage training strategy further optimizes
learning efficiency. Evaluations show that Shakti-Shakti-VLM-1B and
Shakti-VLM-4B excel in document understanding, Visual Reasoning, OCR
extraction, and general multimodal reasoning. Our results highlight that high
performance can be achieved through model design and training strategy rather
than sheer data volume, making Shakti an efficient solution for
enterprise-scale multimodal tasks.

</details>


### [55] [Latent Feature Alignment: Discovering Biased and Interpretable Subpopulations in Face Recognition Models](https://arxiv.org/abs/2510.15520)
*Ignacio Serna*

Main category: cs.CV

TL;DR: 提出了一种无需属性标签的潜在特征对齐（LFA）方法，用于识别人脸识别模型中的系统性偏差，相比传统聚类方法能更一致地发现语义连贯的子群体和可解释的潜在方向。


<details>
  <summary>Details</summary>
Motivation: 现有偏见评估方法依赖昂贵且有限的标注属性来划分子群体，难以全面发现人脸识别模型中的系统性偏差。

Method: 提出Latent Feature Alignment（LFA）算法，利用潜在方向而非显式属性进行子群体划分，通过语义一致性和可解释方向发现能力优于k-means和最近邻等传统聚类方法。

Result: 在四个先进模型和两个数据集上验证了LFA在组内语义一致性方面优于基线方法，并成功发现了与年龄、种族、着装等相关的可解释潜在方向。

Conclusion: LFA是一种实用的表示审计方法，可在无需预定义属性标注的情况下识别和解释人脸识别模型中的偏差子群体。

Abstract: Modern face recognition models achieve high overall accuracy but continue to
exhibit systematic biases that disproportionately affect certain
subpopulations. Conventional bias evaluation frameworks rely on labeled
attributes to form subpopulations, which are expensive to obtain and limited to
predefined categories. We introduce Latent Feature Alignment (LFA), an
attribute-label-free algorithm that uses latent directions to identify
subpopulations. This yields two main benefits over standard clustering: (i)
semantically coherent grouping, where faces sharing common attributes are
grouped together more reliably than by proximity-based methods, and (ii)
discovery of interpretable directions, which correspond to semantic attributes
such as age, ethnicity, or attire. Across four state-of-the-art recognition
models (ArcFace, CosFace, ElasticFace, PartialFC) and two benchmarks (RFW,
CelebA), LFA consistently outperforms k-means and nearest-neighbor search in
intra-group semantic coherence, while uncovering interpretable latent
directions aligned with demographic and contextual attributes. These results
position LFA as a practical method for representation auditing of face
recognition models, enabling practitioners to identify and interpret biased
subpopulations without predefined attribute annotations.

</details>


### [56] [Balanced Multi-Task Attention for Satellite Image Classification: A Systematic Approach to Achieving 97.23% Accuracy on EuroSAT Without Pre-Training](https://arxiv.org/abs/2510.15527)
*Aditya Vir*

Main category: cs.CV

TL;DR: 提出了一种用于卫星土地利用分类的定制卷积神经网络架构，在EuroSAT数据集上达到97.23%的准确率，无需预训练模型。


<details>
  <summary>Details</summary>
Motivation: 解决卫星图像分类中的特定失败模式，并提升无预训练模型下的分类性能。

Method: 设计了三种渐进式网络架构，提出一种结合坐标注意力和挤压激励模块的平衡多任务注意力机制，并采用DropBlock正则化和类别平衡损失。

Result: 最终12层网络在EuroSAT上达到97.23%准确率，Cohen's Kappa为0.9692，各类别准确率均超94.46%，且具备良好的置信度校准。

Conclusion: 系统化的架构设计可有效提升领域特定任务性能，所提方法在无需外部数据下接近微调ResNet-50的性能。

Abstract: This work presents a systematic investigation of custom convolutional neural
network architectures for satellite land use classification, achieving 97.23%
test accuracy on the EuroSAT dataset without reliance on pre-trained models.
Through three progressive architectural iterations (baseline: 94.30%,
CBAM-enhanced: 95.98%, and balanced multi-task attention: 97.23%) we identify
and address specific failure modes in satellite imagery classification. Our
principal contribution is a novel balanced multi-task attention mechanism that
combines Coordinate Attention for spatial feature extraction with
Squeeze-Excitation blocks for spectral feature extraction, unified through a
learnable fusion parameter. Experimental results demonstrate that this
learnable parameter autonomously converges to alpha approximately 0.57,
indicating near-equal importance of spatial and spectral modalities for
satellite imagery. We employ progressive DropBlock regularization (5-20% by
network depth) and class-balanced loss weighting to address overfitting and
confusion pattern imbalance. The final 12-layer architecture achieves Cohen's
Kappa of 0.9692 with all classes exceeding 94.46% accuracy, demonstrating
confidence calibration with a 24.25% gap between correct and incorrect
predictions. Our approach achieves performance within 1.34% of fine-tuned
ResNet-50 (98.57%) while requiring no external data, validating the efficacy of
systematic architectural design for domain-specific applications. Complete
code, trained models, and evaluation scripts are publicly available.

</details>


### [57] [Diffusion Bridge Networks Simulate Clinical-grade PET from MRI for Dementia Diagnostics](https://arxiv.org/abs/2510.15556)
*Yitong Li,Ralph Buchert,Benita Schmitz-Koep,Timo Grimmer,Björn Ommer,Dennis M. Hedderich,Igor Yakushev,Christian Wachinger*

Main category: cs.CV

TL;DR: 提出了一种基于3D扩散桥的框架SiM2P，可从MRI和患者辅助信息中模拟出诊断级FDG-PET图像，显著提升痴呆症的诊断准确率。


<details>
  <summary>Details</summary>
Motivation: FDG-PET在痴呆诊断中虽有效但可及性差且成本高，而MRI更常用；因此需要一种能将MRI转化为PET质量图像的方法以提升诊断可及性。

Method: 开发了名为SiM2P的3D扩散桥模型，学习从MRI和患者基本信息到FDG-PET图像的概率映射，并设计了适用于本地部署的轻量级工作流。

Result: 在盲法临床读片研究中，SiM2P将三类人群（阿尔茨海默病、行为变异型额颞叶痴呆、健康对照）的诊断准确率从75.0%提升至84.7%（p<0.05），模拟PET图像获得更高的诊断确定性和更好的阅片者一致性。

Conclusion: SiM2P能够以较低资源需求实现高质量FDG-PET模拟，有助于在资源有限环境中提升痴呆症的早期检测与鉴别诊断水平。

Abstract: Positron emission tomography (PET) with 18F-Fluorodeoxyglucose (FDG) is an
established tool in the diagnostic workup of patients with suspected dementing
disorders. However, compared to the routinely available magnetic resonance
imaging (MRI), FDG-PET remains significantly less accessible and substantially
more expensive. Here, we present SiM2P, a 3D diffusion bridge-based framework
that learns a probabilistic mapping from MRI and auxiliary patient information
to simulate FDG-PET images of diagnostic quality. In a blinded clinical reader
study, two neuroradiologists and two nuclear medicine physicians rated the
original MRI and SiM2P-simulated PET images of patients with Alzheimer's
disease, behavioral-variant frontotemporal dementia, and cognitively healthy
controls. SiM2P significantly improved the overall diagnostic accuracy of
differentiating between three groups from 75.0% to 84.7% (p<0.05). Notably, the
simulated PET images received higher diagnostic certainty ratings and achieved
superior interrater agreement compared to the MRI images. Finally, we developed
a practical workflow for local deployment of the SiM2P framework. It requires
as few as 20 site-specific cases and only basic demographic information. This
approach makes the established diagnostic benefits of FDG-PET imaging more
accessible to patients with suspected dementing disorders, potentially
improving early detection and differential diagnosis in resource-limited
settings. Our code is available at https://github.com/Yiiitong/SiM2P.

</details>


### [58] [ClapperText: A Benchmark for Text Recognition in Low-Resource Archival Documents](https://arxiv.org/abs/2510.15557)
*Tingyu Lin,Marco Peer,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: ClapperText 是一个用于手写和印刷文本识别的基准数据集，源自二战时期的127段包含场记板的档案视频，包含9,813个标注帧和94,573个词级文本实例，支持低资源和视觉退化场景下的OCR研究。


<details>
  <summary>Details</summary>
Motivation: 为应对历史文档中结构化信息在视觉退化和非标准形式下的识别挑战，提供一个真实、文化相关且适用于低资源环境的文本识别基准数据集。

Method: 从127段二战时期档案视频中提取含场记板的帧，进行词级文本标注，包括转录、语义类别、文本类型和遮挡状态，并以旋转边界框（四点多边形）形式提供；使用每视频一致的评估协议，在零样本和微调条件下对六种识别模型和七种检测模型进行基准测试。

Result: 数据集中67%为手写文本，1,566个实例部分遮挡；尽管训练集仅18个视频，微调仍带来显著性能提升，验证了其在少样本学习场景中的有效性。

Conclusion: ClapperText 提供了一个现实且具文化意义的数据资源，适用于推动低资源环境下鲁棒OCR与文档理解技术的发展。

Abstract: This paper presents ClapperText, a benchmark dataset for handwritten and
printed text recognition in visually degraded and low-resource settings. The
dataset is derived from 127 World War II-era archival video segments containing
clapperboards that record structured production metadata such as date,
location, and camera-operator identity. ClapperText includes 9,813 annotated
frames and 94,573 word-level text instances, 67% of which are handwritten and
1,566 are partially occluded. Each instance includes transcription, semantic
category, text type, and occlusion status, with annotations available as
rotated bounding boxes represented as 4-point polygons to support spatially
precise OCR applications. Recognizing clapperboard text poses significant
challenges, including motion blur, handwriting variation, exposure
fluctuations, and cluttered backgrounds, mirroring broader challenges in
historical document analysis where structured content appears in degraded,
non-standard forms. We provide both full-frame annotations and cropped word
images to support downstream tasks. Using a consistent per-video evaluation
protocol, we benchmark six representative recognition and seven detection
models under zero-shot and fine-tuned conditions. Despite the small training
set (18 videos), fine-tuning leads to substantial performance gains,
highlighting ClapperText's suitability for few-shot learning scenarios. The
dataset offers a realistic and culturally grounded resource for advancing
robust OCR and document understanding in low-resource archival contexts. The
dataset and evaluation code are available at
https://github.com/linty5/ClapperText.

</details>


### [59] [Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation](https://arxiv.org/abs/2510.15564)
*Xiaoming Zhu,Xu Huang,Qinghongbing Xie,Zhi Deng,Junsheng Yu,Yirui Guan,Zhongyuan Liu,Lin Zhu,Qijun Zhao,Ligang Liu,Long Zeng*

Main category: cs.CV

TL;DR: 提出了一种基于视觉引导的3D布局生成系统，通过图像生成与解析结合优化场景布局，在丰富性和质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景布局生成方法受限于手工规则、生成内容缺乏多样性或难以准确建模空间关系。

Method: 构建高质量资产库，利用图像生成模型扩展提示并微调以匹配资产库，开发图像解析模块恢复3D布局，并结合场景图和视觉语义进行优化。

Result: 在用户测试中显著优于现有方法，生成的布局更丰富、更高质量。

Conclusion: 该视觉引导方法能有效生成艺术性强且逻辑一致的3D场景布局，具备良好的实用潜力。

Abstract: Generating artistic and coherent 3D scene layouts is crucial in digital
content creation. Traditional optimization-based methods are often constrained
by cumbersome manual rules, while deep generative models face challenges in
producing content with richness and diversity. Furthermore, approaches that
utilize large language models frequently lack robustness and fail to accurately
capture complex spatial relationships. To address these challenges, this paper
presents a novel vision-guided 3D layout generation system. We first construct
a high-quality asset library containing 2,037 scene assets and 147 3D scene
layouts. Subsequently, we employ an image generation model to expand prompt
representations into images, fine-tuning it to align with our asset library. We
then develop a robust image parsing module to recover the 3D layout of scenes
based on visual semantics and geometric information. Finally, we optimize the
scene layout using scene graphs and overall visual semantics to ensure logical
coherence and alignment with the images. Extensive user testing demonstrates
that our algorithm significantly outperforms existing methods in terms of
layout richness and quality. The code and dataset will be available at
https://github.com/HiHiAllen/Imaginarium.

</details>


### [60] [Unmasking Facial DeepFakes: A Robust Multiview Detection Framework for Natural Images](https://arxiv.org/abs/2510.15576)
*Sami Belguesmia,Mohand Saïd Allili,Assia Hamadene*

Main category: cs.CV

TL;DR: 提出一种多视角架构的DeepFake检测方法，通过融合全局、中观、局部和姿态视图编码器的特征，有效提升在复杂姿态和光照条件下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有DeepFake检测方法在姿态变化、遮挡和真实场景中的细微伪影上表现不佳，难以应对实际应用中的挑战。

Method: 设计一个多视图架构，包含四个编码器：全局视图编码器检测边界不一致性，中观视图编码器分析纹理与色彩对齐，局部视图编码器捕捉眼鼻口等区域的失真，面部朝向编码器分类人脸姿态；通过融合各编码器特征进行检测。

Result: 在具有挑战性的数据集上实验表明，该方法优于传统的单视图方法，尤其在复杂姿态和光照条件下表现出更强的鲁棒性。

Conclusion: 所提出的多视图融合架构显著提升了DeepFake检测的准确性和鲁棒性，适用于现实场景中的伪造图像识别。

Abstract: DeepFake technology has advanced significantly in recent years, enabling the
creation of highly realistic synthetic face images. Existing DeepFake detection
methods often struggle with pose variations, occlusions, and artifacts that are
difficult to detect in real-world conditions. To address these challenges, we
propose a multi-view architecture that enhances DeepFake detection by analyzing
facial features at multiple levels. Our approach integrates three specialized
encoders, a global view encoder for detecting boundary inconsistencies, a
middle view encoder for analyzing texture and color alignment, and a local view
encoder for capturing distortions in expressive facial regions such as the
eyes, nose, and mouth, where DeepFake artifacts frequently occur. Additionally,
we incorporate a face orientation encoder, trained to classify face poses,
ensuring robust detection across various viewing angles. By fusing features
from these encoders, our model achieves superior performance in detecting
manipulated images, even under challenging pose and lighting
conditions.Experimental results on challenging datasets demonstrate the
effectiveness of our method, outperforming conventional single-view approaches

</details>


### [61] [Lightweight CycleGAN Models for Cross-Modality Image Transformation and Experimental Quality Assessment in Fluorescence Microscopy](https://arxiv.org/abs/2510.15579)
*Mohammad Soltaninezhad,Yashar Rouzbahani,Jhonatan Contreras,Rohan Chippalkatti,Daniel Kwaku Abankwa,Christian Eggeling,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 提出了一种轻量级CycleGAN用于荧光显微镜中的模态转换（共聚焦到超分辨率STED/去卷积STED），通过固定通道数显著减少参数量，并将GAN用作实验和标记质量的诊断工具。


<details>
  <summary>Details</summary>
Motivation: 解决未配对数据集下荧光显微镜图像模态转换的问题，同时降低深度学习模型的计算成本和环境影响。

Method: 在基于U-Net的生成器中用固定通道策略替代传统的通道倍增策略，大幅减少可训练参数；使用CycleGAN框架进行无配对图像转换，并利用生成结果与实验图像的偏差进行质量诊断。

Result: 模型参数从4180万减少到约9000，训练更快、内存占用更低，且性能更优；能够有效检测光漂白、伪影和标记不准等实验问题。

Conclusion: 该轻量级CycleGAN不仅实现了高效的模态转换，还可作为显微成像工作流中验证实验准确性和图像保真度的实用诊断工具。

Abstract: Lightweight deep learning models offer substantial reductions in
computational cost and environmental impact, making them crucial for scientific
applications. We present a lightweight CycleGAN for modality transfer in
fluorescence microscopy (confocal to super-resolution STED/deconvolved STED),
addressing the common challenge of unpaired datasets. By replacing the
traditional channel-doubling strategy in the U-Net-based generator with a fixed
channel approach, we drastically reduce trainable parameters from 41.8 million
to approximately nine thousand, achieving superior performance with faster
training and lower memory usage. We also introduce the GAN as a diagnostic tool
for experimental and labeling quality. When trained on high-quality images, the
GAN learns the characteristics of optimal imaging; deviations between its
generated outputs and new experimental images can reveal issues such as
photobleaching, artifacts, or inaccurate labeling. This establishes the model
as a practical tool for validating experimental accuracy and image fidelity in
microscopy workflows.

</details>


### [62] [Standardization for improved Spatio-Temporal Image Fusion](https://arxiv.org/abs/2510.15589)
*Harkaitz Goyena,Peter M. Atkinson,Unai Pérez-Goya,M. Dolores Ugarte*

Main category: cs.CV

TL;DR: 提出并比较了两种标准化方法，以提升无配对时空图像融合（USTFIP）的精度，其中基于异常的卫星图像标准化（ABSIS）锐化方法显著提高了光谱和空间准确性。


<details>
  <summary>Details</summary>
Motivation: 为了促进时空图像融合（STIF）方法的应用，解决不同传感器获取的图像在空间和光谱分辨率上的不匹配问题。

Method: 第一种方法是传统的细分辨率图像上采样；第二种方法是称为基于异常的卫星图像标准化（ABSIS）的锐化方法，将细分辨率图像序列的整体特征与特定粗分辨率图像的独特属性相结合。

Result: 两种方法均显著提升了USTFIP方法的融合精度，其中ABSIS方法使光谱和空间精度分别最高提升49.46%和78.40%。

Conclusion: 所提出的标准化方法，尤其是ABSIS锐化方法，能有效提高无配对时空图像融合的精度，有助于更广泛应用STIF技术。

Abstract: Spatio-Temporal Image Fusion (STIF) methods usually require sets of images
with matching spatial and spectral resolutions captured by different sensors.
To facilitate the application of STIF methods, we propose and compare two
different standardization approaches. The first method is based on traditional
upscaling of the fine-resolution images. The second method is a sharpening
approach called Anomaly Based Satellite Image Standardization (ABSIS) that
blends the overall features found in the fine-resolution image series with the
distinctive attributes of a specific coarse-resolution image to produce images
that more closely resemble the outcome of aggregating the fine-resolution
images. Both methods produce a significant increase in accuracy of the Unpaired
Spatio Temporal Fusion of Image Patches (USTFIP) STIF method, with the
sharpening approach increasing the spectral and spatial accuracies of the fused
images by up to 49.46\% and 78.40\%, respectively.

</details>


### [63] [FlexiReID: Adaptive Mixture of Expert for Multi-Modal Person Re-Identification](https://arxiv.org/abs/2510.15595)
*Zhen Sun,Lei Tan,Yunhang Shen,Chengmao Cai,Xing Sun,Pingyang Dai,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出FlexiReID框架，支持四种模态（rgb、红外、草图、文本）之间的七种检索模式，通过自适应混合专家机制和跨模态查询融合模块实现灵活的多模态行人重识别。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于固定的跨模态设置，无法支持任意查询-检索组合，限制了实际应用。

Method: 提出FlexiReID，引入自适应混合专家（MoE）机制动态融合多模态特征，并设计跨模态查询融合模块增强特征提取；构建统一数据集CIRS-PEDES以支持全面评估。

Result: 在多个实验中表现出色，实现了最先进的性能，在复杂场景下具有强泛化能力。

Conclusion: FlexiReID为多模态行人重识别提供了灵活且高效的解决方案，推动了实际应用中的任意模态检索。

Abstract: Multimodal person re-identification (Re-ID) aims to match pedestrian images
across different modalities. However, most existing methods focus on limited
cross-modal settings and fail to support arbitrary query-retrieval
combinations, hindering practical deployment. We propose FlexiReID, a flexible
framework that supports seven retrieval modes across four modalities: rgb,
infrared, sketches, and text. FlexiReID introduces an adaptive
mixture-of-experts (MoE) mechanism to dynamically integrate diverse modality
features and a cross-modal query fusion module to enhance multimodal feature
extraction. To facilitate comprehensive evaluation, we construct CIRS-PEDES, a
unified dataset extending four popular Re-ID datasets to include all four
modalities. Extensive experiments demonstrate that FlexiReID achieves
state-of-the-art performance and offers strong generalization in complex
scenarios.

</details>


### [64] [Quantized FCA: Efficient Zero-Shot Texture Anomaly Detection](https://arxiv.org/abs/2510.15602)
*Andrei-Timotei Ardelean,Patrick Rückbeil,Tim Weyrich*

Main category: cs.CV

TL;DR: 本文提出了一种名为QFCA的实时零样本纹理异常检测方法，通过量化特征对应分析和PCA预处理，在保持高精度的同时实现10倍速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常定位方法在纹理检测中运行速度慢，难以应用于实际场景（如生产线监控），亟需高效且准确的解决方案。

Method: 提出QFCA方法，采用量化版本的特征对应分析（FCA），基于量化值直方图进行patch统计比较，并引入基于主成分分析（PCA）的特征预处理以增强正常与异常特征的对比度。

Result: 相比现有方法实现了约10倍的加速，精度损失极小，并在复杂纹理上提升了检测精度，实验表明其性能优于先前方法。

Conclusion: QFCA是一种高效、精确的零样本纹理异常定位方法，适合实际工业应用，为实时异常检测提供了可行方案。

Abstract: Zero-shot anomaly localization is a rising field in computer vision research,
with important progress in recent years. This work focuses on the problem of
detecting and localizing anomalies in textures, where anomalies can be defined
as the regions that deviate from the overall statistics, violating the
stationarity assumption. The main limitation of existing methods is their high
running time, making them impractical for deployment in real-world scenarios,
such as assembly line monitoring. We propose a real-time method, named QFCA,
which implements a quantized version of the feature correspondence analysis
(FCA) algorithm. By carefully adapting the patch statistics comparison to work
on histograms of quantized values, we obtain a 10x speedup with little to no
loss in accuracy. Moreover, we introduce a feature preprocessing step based on
principal component analysis, which enhances the contrast between normal and
anomalous features, improving the detection precision on complex textures. Our
method is thoroughly evaluated against prior art, comparing favorably with
existing methods. Project page:
https://reality.tf.fau.de/pub/ardelean2025quantized.html

</details>


### [65] [Lightweight Data-Free Denoising for Detail-Preserving Biomedical Image Restoration](https://arxiv.org/abs/2510.15611)
*Tomáš Chobola,Julia A. Schnabel,Tingying Peng*

Main category: cs.CV

TL;DR: 提出了一种名为Noise2Detail (N2D)的超轻量级自监督去噪模型，在无需干净参考图像的情况下，通过多阶段去噪流程实现快速且高质量的图像恢复。


<details>
  <summary>Details</summary>
Motivation: 现有自监督去噪方法计算和内存开销大，难以在实际应用中兼顾推理速度与重建质量，尤其在生物医学成像等数据稀缺场景下面临挑战。

Method: 基于Noise2Noise训练框架，设计了一个创新的多阶段去噪流水线Noise2Detail（N2D），在推理过程中打破噪声的空间相关性，先生成中间平滑结构，再从原始噪声输入中恢复细节。

Result: 实验表明，N2D在性能上优于现有的无数据集方法，同时仅需极低的计算资源。

Conclusion: N2D结合了高效性、低计算成本和无需训练数据的优势，适用于生物医学成像等实际应用场景。

Abstract: Current self-supervised denoising techniques achieve impressive results, yet
their real-world application is frequently constrained by substantial
computational and memory demands, necessitating a compromise between inference
speed and reconstruction quality. In this paper, we present an
ultra-lightweight model that addresses this challenge, achieving both fast
denoising and high quality image restoration. Built upon the Noise2Noise
training framework-which removes the reliance on clean reference images or
explicit noise modeling-we introduce an innovative multistage denoising
pipeline named Noise2Detail (N2D). During inference, this approach disrupts the
spatial correlations of noise patterns to produce intermediate smooth
structures, which are subsequently refined to recapture fine details directly
from the noisy input. Extensive testing reveals that Noise2Detail surpasses
existing dataset-free techniques in performance, while requiring only a
fraction of the computational resources. This combination of efficiency, low
computational cost, and data-free approach make it a valuable tool for
biomedical imaging, overcoming the challenges of scarce clean training data-due
to rare and complex imaging modalities-while enabling fast inference for
practical use.

</details>


### [66] [Deep Learning Based Domain Adaptation Methods in Remote Sensing: A Comprehensive Survey](https://arxiv.org/abs/2510.15615)
*Shuchang Lyu,Qi Zhao,Zheng Zhou,Meng Li,You Zhou,Dingding Yao,Guangliang Cheng,Huiyu Zhou,Zhenwei Shi*

Main category: cs.CV

TL;DR: 本文综述了深度学习在遥感领域中域适应任务的最新进展，提出了系统的方法分类体系，涵盖了多种任务类型、输入模式和监督范式，并总结了常用数据集和前沿方法性能，指出了当前面临的挑战与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 遥感中的域适应面临数据分布差异大、传感器多样、环境变化复杂等挑战，现有研究分散且缺乏系统性梳理，亟需全面综述以推动领域发展。

Method: 通过构建多维度分类体系（任务类型、输入模式、监督方式、算法粒度）对现有深度学习域适应方法进行系统归纳，并总结常用数据集与性能表现。

Result: 提供了遥感域适应领域的全面综述，包括方法分类、数据集汇总和性能分析，相比以往工作覆盖更广、结构更清晰。

Conclusion: 该综述为遥感域适应研究提供了系统的知识框架，有助于启发新研究、促进理解并指导未来方向。

Abstract: Domain adaptation is a crucial and increasingly important task in remote
sensing, aiming to transfer knowledge from a source domain a differently
distributed target domain. It has broad applications across various real-world
applications, including remote sensing element interpretation, ecological
environment monitoring, and urban/rural planning. However, domain adaptation in
remote sensing poses significant challenges due to differences in data, such as
variations in ground sampling distance, imaging modes from various sensors,
geographical landscapes, and environmental conditions. In recent years, deep
learning has emerged as a powerful tool for feature representation and
cross-domain knowledge transfer, leading to widespread adoption in remote
sensing tasks. In this paper, we present a comprehensive survey of significant
advancements in deep learning based domain adaptation for remote sensing. We
first introduce the preliminary knowledge to clarify key concepts, mathematical
notations, and the taxonomy of methodologies. We then organize existing
algorithms from multiple perspectives, including task categorization, input
mode, supervision paradigm, and algorithmic granularity, providing readers with
a structured understanding of the field. Next, we review widely used datasets
and summarize the performance of state-of-the-art methods to provide an
overview of current progress. We also identify open challenges and potential
directions to guide future research in domain adaptation for remote sensing.
Compared to previous surveys, this work addresses a broader range of domain
adaptation tasks in remote sensing, rather than concentrating on a few
subfields. It also presents a systematic taxonomy, providing a more
comprehensive and organized understanding of the field. As a whole, this survey
can inspire the research community, foster understanding, and guide future work
in the field.

</details>


### [67] [Uncertainty-Aware Extreme Point Tracing for Weakly Supervised Ultrasound Image Segmentation](https://arxiv.org/abs/2510.15666)
*Lei Shi,Gang Li,Junxing Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于四个极端点作为标注的弱监督医学图像分割框架，结合SAM2生成伪标签，并通过改进的FGEPM算法和不确定性感知损失进行优化，在减少标注成本的同时实现了与全监督方法相当甚至更优的性能。


<details>
  <summary>Details</summary>
Motivation: 全监督医学图像分割需要大量像素级标注，成本高且耗时，因此需要一种能显著降低标注负担的弱监督方法。

Method: 利用四个极端点生成边界框作为SAM2的提示以产生初始伪标签；采用增强的FGEPM算法结合蒙特卡洛Dropout估计不确定性，构建统一的梯度不确定性代价图用于边界追踪；引入双分支不确定性感知尺度一致性（USC）损失和框对齐损失以提升训练中的空间一致性和边界对齐精度。

Result: 在BUSI和UNS两个公开超声数据集上的实验表明，该方法性能与全监督方法相当甚至更优，同时大幅降低了标注成本。

Conclusion: 所提出的弱监督分割框架在超声图像分割中具有良好的有效性与实用性，显著减少了对密集标注的依赖。

Abstract: Automatic medical image segmentation is a fundamental step in computer-aided
diagnosis, yet fully supervised approaches demand extensive pixel-level
annotations that are costly and time-consuming. To alleviate this burden, we
propose a weakly supervised segmentation framework that leverages only four
extreme points as annotation. Specifically, bounding boxes derived from the
extreme points are used as prompts for the Segment Anything Model 2 (SAM2) to
generate reliable initial pseudo labels. These pseudo labels are progressively
refined by an enhanced Feature-Guided Extreme Point Masking (FGEPM) algorithm,
which incorporates Monte Carlo dropout-based uncertainty estimation to
construct a unified gradient uncertainty cost map for boundary tracing.
Furthermore, a dual-branch Uncertainty-aware Scale Consistency (USC) loss and a
box alignment loss are introduced to ensure spatial consistency and precise
boundary alignment during training. Extensive experiments on two public
ultrasound datasets, BUSI and UNS, demonstrate that our method achieves
performance comparable to, and even surpassing fully supervised counterparts
while significantly reducing annotation cost. These results validate the
effectiveness and practicality of the proposed weakly supervised framework for
ultrasound image segmentation.

</details>


### [68] [Valeo Near-Field: a novel dataset for pedestrian intent detection](https://arxiv.org/abs/2510.15673)
*Antonyo Musabini,Rachid Benmokhtar,Jagdish Bhanushali,Victor Galizzi,Bertrand Luvison,Xavier Perrotton*

Main category: cs.CV

TL;DR: 本文提出了一种用于检测行人接近自车时意图的新型多模态数据集，包含鱼眼相机、激光雷达、超声波传感器和3D身体姿态等同步数据，并提供详细标注和基准测试工具。


<details>
  <summary>Details</summary>
Motivation: 为了提升智能车辆在近场场景中对行人意图的理解能力，解决现有数据集中多模态数据同步不足、标注精度低以及现实挑战（如遮挡、动态环境）覆盖不全的问题。

Method: 采集了多种传感器数据（鱼眼相机、激光雷达、超声波和动捕系统），实现了3D关节位置与图像的同步标注，并从激光雷达数据中提取精确的3D行人位置，构建了一个综合基准测试套件，支持准确性、效率和嵌入式系统可扩展性评估。

Result: 发布部分数据集及完整基准工具，提供了基于自定义神经网络的基线性能指标，在行人检测、3D姿态估计和4D轨迹与意图预测任务中展现出良好的应用潜力。

Conclusion: 该数据集为智能车辆在复杂真实环境中进行行人意图识别提供了有力支持，有望推动相关算法的发展，并作为未来研究的基础。

Abstract: This paper presents a novel dataset aimed at detecting pedestrians'
intentions as they approach an ego-vehicle. The dataset comprises synchronized
multi-modal data, including fisheye camera feeds, lidar laser scans, ultrasonic
sensor readings, and motion capture-based 3D body poses, collected across
diverse real-world scenarios. Key contributions include detailed annotations of
3D body joint positions synchronized with fisheye camera images, as well as
accurate 3D pedestrian positions extracted from lidar data, facilitating robust
benchmarking for perception algorithms. We release a portion of the dataset
along with a comprehensive benchmark suite, featuring evaluation metrics for
accuracy, efficiency, and scalability on embedded systems. By addressing
real-world challenges such as sensor occlusions, dynamic environments, and
hardware constraints, this dataset offers a unique resource for developing and
evaluating state-of-the-art algorithms in pedestrian detection, 3D pose
estimation and 4D trajectory and intention prediction. Additionally, we provide
baseline performance metrics using custom neural network architectures and
suggest future research directions to encourage the adoption and enhancement of
the dataset. This work aims to serve as a foundation for researchers seeking to
advance the capabilities of intelligent vehicles in near-field scenarios.

</details>


### [69] [Towards Label-Free Brain Tumor Segmentation: Unsupervised Learning with Multimodal MRI](https://arxiv.org/abs/2510.15684)
*Gerard Comas-Quiles,Carles Garcia-Cabrera,Julia Dietlmeier,Noel E. O'Connor,Ferran Marques*

Main category: cs.CV

TL;DR: 提出一种基于多模态视觉Transformer自编码器（MViT-AE）的无监督异常检测方法，用于脑肿瘤分割，仅使用健康脑MRI进行训练，通过重建误差图实现肿瘤检测与定位，并结合SAM模型优化轮廓，无需人工标注，在BraTS-GoAT 2025数据集上取得有临床意义的结果。


<details>
  <summary>Details</summary>
Motivation: 在标注数据有限、成本高或不一致的情况下，提供一种可扩展的无监督脑肿瘤分割方案，以解决神经影像工作流中的标注瓶颈问题。

Method: 采用多模态Vision Transformer自编码器（MViT-AE），在健康脑MRI上无监督训练，利用早期-晚期融合策略融合多序列MRI信息，并结合Segment Anything Model（SAM）进行后处理以优化肿瘤边界。

Result: 在BraTS-GoAT 2025 Lighthouse数据集上，病灶级Dice系数达到0.437（全肿瘤）、0.316（肿瘤核心）、0.350（增强肿瘤），验证集异常检测率达到89.4%。

Conclusion: 基于Transformer的无监督模型在脑肿瘤检测中具有潜力，可作为可扩展、标签高效的神经肿瘤影像分析工具。

Abstract: Unsupervised anomaly detection (UAD) presents a complementary alternative to
supervised learning for brain tumor segmentation in magnetic resonance imaging
(MRI), particularly when annotated datasets are limited, costly, or
inconsistent. In this work, we propose a novel Multimodal Vision Transformer
Autoencoder (MViT-AE) trained exclusively on healthy brain MRIs to detect and
localize tumors via reconstruction-based error maps. This unsupervised paradigm
enables segmentation without reliance on manual labels, addressing a key
scalability bottleneck in neuroimaging workflows. Our method is evaluated in
the BraTS-GoAT 2025 Lighthouse dataset, which includes various types of tumors
such as gliomas, meningiomas, and pediatric brain tumors. To enhance
performance, we introduce a multimodal early-late fusion strategy that
leverages complementary information across multiple MRI sequences, and a
post-processing pipeline that integrates the Segment Anything Model (SAM) to
refine predicted tumor contours. Despite the known challenges of UAD,
particularly in detecting small or non-enhancing lesions, our method achieves
clinically meaningful tumor localization, with lesion-wise Dice Similarity
Coefficient of 0.437 (Whole Tumor), 0.316 (Tumor Core), and 0.350 (Enhancing
Tumor) on the test set, and an anomaly Detection Rate of 89.4% on the
validation set. These findings highlight the potential of transformer-based
unsupervised models to serve as scalable, label-efficient tools for
neuro-oncological imaging.

</details>


### [70] [Unimedvl: Unifying Medical Multimodal Understanding And Generation Through Observation-Knowledge-Analysis](https://arxiv.org/abs/2510.15710)
*Junzhi Ning,Wei Li,Cheng Tang,Jiashi Lin,Chenglong Ma,Chaoyang Zhang,Jiyao Liu,Ying Chen,Shujian Gao,Lihao Liu,Yuandong Pu,Huihui Xu,Chenhui Gou,Ziyan Huang,Yi Xin,Qi Qin,Zhongying Deng,Diping Song,Bin Fu,Guang Yang,Yuanfeng Ji,Tianbin Li,Yanzhou Su,Jin Ye,Shixiang Tang,Ming Hu,Junjun He*

Main category: cs.CV

TL;DR: 提出了一种基于观察-知识-分析（OKA）范式的多层级框架UniMedVL，首次实现医疗图像理解与生成任务的统一建模，通过双向知识共享显著提升多模态医学视觉-语言任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI系统在图像理解和生成任务上割裂，导致数据表示、特征融合和多模态能力上的鸿沟，难以满足临床诊断中对图文双输出的需求。

Method: 构建了包含560万样本的多模态数据集UniMed-5M；提出渐进式课程学习引入医学多模态知识；设计了统一的医疗多模态模型UniMedVL，支持图像理解与生成的联合训练。

Result: 在五个医学图像理解基准上达到领先性能，在八种医学影像模态的生成质量上媲美专用生成模型，并验证了生成任务对理解任务的正向促进作用。

Conclusion: 统一的多模态架构能有效实现医疗图像理解与生成的双向知识迁移，提升整体性能，为医学AI提供更贴近临床需求的解决方案。

Abstract: Medical diagnostic applications require models that can process multimodal
medical inputs (images, patient histories, lab results) and generate diverse
outputs including both textual reports and visual content (annotations,
segmentation masks, and images). Despite this need, existing medical AI systems
disrupt this unified process: medical image understanding models interpret
images but cannot generate visual outputs, while medical image generation
models synthesize images but cannot provide textual explanations. This leads to
gaps in data representation, feature integration, and task-level multimodal
capabilities. To this end, we propose a multi-level framework that draws
inspiration from diagnostic workflows through the
Observation-Knowledge-Analysis (OKA) paradigm. Specifically, at the observation
level, we construct UniMed-5M, a dataset comprising over 5.6M samples that
reformat diverse unimodal data into multimodal pairs for foundational
observation. At the knowledge level, we propose Progressive Curriculum Learning
that systematically introduces medical multimodal knowledge. At the analysis
level, we introduce UniMedVL, the first medical unified multimodal model for
the simultaneous analysis of image understanding and generation tasks within a
single architecture. UniMedVL achieves superior performance on five medical
image understanding benchmarks, while matching specialized models in generation
quality across eight medical imaging modalities. Crucially, our unified
architecture enables bidirectional knowledge sharing: generation tasks enhance
visual understanding features, demonstrating that integrating traditionally
separate capabilities within a single medical framework unlocks improvements
across diverse medical vision-language tasks. Code is available at
https://github.com/uni-medical/UniMedVL.

</details>


### [71] [OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM](https://arxiv.org/abs/2510.15870)
*Hanrong Ye,Chao-Han Huck Yang,Arushi Goel,Wei Huang,Ligeng Zhu,Yuanhang Su,Sean Lin,An-Chieh Cheng,Zhen Wan,Jinchuan Tian,Yuming Lou,Dong Yang,Zhijian Liu,Yukang Chen,Ambrish Dantrey,Ehsan Jahangiri,Sreyan Ghosh,Daguang Xu,Ehsan Hosseini-Asl,Danial Mohseni Taheri,Vidya Murali,Sifei Liu,Jason Lu,Oluwatobi Olabiyi,Frank Wang,Rafael Valle,Bryan Catanzaro,Andrew Tao,Song Han,Jan Kautz,Hongxu Yin,Pavlo Molchanov*

Main category: cs.CV

TL;DR: OmniVinci是一个开源的多模态大语言模型，通过创新的架构设计和高效的数据 pipeline，在跨模态理解、音频和视觉任务上显著优于现有模型，且训练token减少6倍。


<details>
  <summary>Details</summary>
Motivation: 为了提升机器智能的多模态感知能力，模仿人类多感官感知世界的方式，构建一个强大且开放的多模态大模型。

Method: 提出OmniAlignNet增强视觉与音频嵌入对齐，Temporal Embedding Grouping捕捉时序相对关系，Constrained Rotary Time Embedding编码绝对时间信息，并构建2400万单模态与多模态对话数据集。

Result: 在DailyOmni、MMAR和Video-MME等基准上分别提升+19.05、+1.7和+3.9，仅使用0.2T训练token，为Qwen2.5-Omni的1/6。

Conclusion: 多模态信号相互增强感知与推理能力，OmniVinci在更少训练资源下实现更优性能，展现出在机器人、医疗AI和智能工厂等应用中的潜力。

Abstract: Advancing machine intelligence requires developing the ability to perceive
across multiple modalities, much as humans sense the world. We introduce
OmniVinci, an initiative to build a strong, open-source, omni-modal LLM. We
carefully study the design choices across model architecture and data curation.
For model architecture, we present three key innovations: (i) OmniAlignNet for
strengthening alignment between vision and audio embeddings in a shared
omni-modal latent space; (ii) Temporal Embedding Grouping for capturing
relative temporal alignment between vision and audio signals; and (iii)
Constrained Rotary Time Embedding for encoding absolute temporal information in
omni-modal embeddings. We introduce a curation and synthesis pipeline that
generates 24M single-modal and omni-modal conversations. We find that
modalities reinforce one another in both perception and reasoning. Our model,
OmniVinci, outperforms Qwen2.5-Omni with +19.05 on DailyOmni (cross-modal
understanding), +1.7 on MMAR (audio), and +3.9 on Video-MME (vision), while
using just 0.2T training tokens - a 6 times reduction compared to
Qwen2.5-Omni's 1.2T. We finally demonstrate omni-modal advantages in downstream
applications spanning robotics, medical AI, and smart factory.

</details>


### [72] [DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification](https://arxiv.org/abs/2510.15725)
*Tingyu Lin,Armin Dadras,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: 本文提出了一种名为DGME-T的轻量级视频Swim Transformer扩展方法，通过引入基于光流的方向性网格运动编码，提升了在现代和历史影片上的相机运动分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有相机运动分类模型在处理噪声多、帧缺失和低对比度的档案影片时性能下降，因此需要一个更鲁棒的模型来应对退化视频数据中的运动线索模糊问题。

Method: 构建了一个统一基准，整合了两个现代语料库为四个标准类别，并将HISTORIAN数据集重构为五个平衡类别；在此基础上提出DGME-T，利用可学习且归一化的 late-fusion 层注入来自光流的方向性网格运动编码（DGME）。

Result: DGME-T在现代片段上将主干网络的top-1准确率从81.78%提升至86.14%，macro F1从82.08%提升至87.81%；在二战历史 footage 上准确率从83.43%提升至84.62%，macro F1从81.72%提升至82.63%；跨域实验显示，先在现代数据上进行微调可使历史数据性能提高超过5个百分点。

Conclusion: 结构化运动先验与Transformer表征是互补的，即使是一个小而精细校准的运动头也能显著增强退化影片分析的鲁棒性。

Abstract: Camera movement classification (CMC) models trained on contemporary,
high-quality footage often degrade when applied to archival film, where noise,
missing frames, and low contrast obscure motion cues. We bridge this gap by
assembling a unified benchmark that consolidates two modern corpora into four
canonical classes and restructures the HISTORIAN collection into five balanced
categories. Building on this benchmark, we introduce DGME-T, a lightweight
extension to the Video Swin Transformer that injects directional grid motion
encoding, derived from optical flow, via a learnable and normalised late-fusion
layer. DGME-T raises the backbone's top-1 accuracy from 81.78% to 86.14% and
its macro F1 from 82.08% to 87.81% on modern clips, while still improving the
demanding World-War-II footage from 83.43% to 84.62% accuracy and from 81.72%
to 82.63% macro F1. A cross-domain study further shows that an intermediate
fine-tuning stage on modern data increases historical performance by more than
five percentage points. These results demonstrate that structured motion priors
and transformer representations are complementary and that even a small,
carefully calibrated motion head can substantially enhance robustness in
degraded film analysis. Related resources are available at
https://github.com/linty5/DGME-T.

</details>


### [73] [Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset](https://arxiv.org/abs/2510.15742)
*Qingyan Bai,Qiuyu Wang,Hao Ouyang,Yue Yu,Hanlin Wang,Wen Wang,Ka Leong Cheng,Shuailei Ma,Yanhong Zeng,Zichen Liu,Yinghao Xu,Yujun Shen,Qifeng Chen*

Main category: cs.CV

TL;DR: 本文提出了Ditto框架，用于生成大规模高质量的指令式视频编辑数据集Ditto-1M，进而训练出具备卓越指令跟随能力的视频编辑模型Editto，实现了该领域的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模、高质量的训练数据，基于指令的视频编辑技术发展受限，本文旨在解决这一根本性问题。

Method: 提出Ditto框架，结合图像编辑器的创造性与上下文视频生成器，采用高效的蒸馏模型架构和时序增强器以降低成本并提升时序一致性，并通过智能代理自动生成多样化指令并过滤输出以保证质量。利用12,000 GPU天构建Ditto-1M数据集，并采用课程学习策略训练Editto模型。

Result: 成功构建了包含一百万个高保真视频编辑样本的Ditto-1M数据集，训练出的Editto模型在指令跟随能力和编辑质量上显著优于现有方法，达到新的SOTA水平。

Conclusion: Ditto框架有效解决了指令式视频编辑中数据稀缺的问题，为该领域提供了可扩展的数据生成范式，并推动了相关模型性能的大幅提升。

Abstract: Instruction-based video editing promises to democratize content creation, yet
its progress is severely hampered by the scarcity of large-scale, high-quality
training data. We introduce Ditto, a holistic framework designed to tackle this
fundamental challenge. At its heart, Ditto features a novel data generation
pipeline that fuses the creative diversity of a leading image editor with an
in-context video generator, overcoming the limited scope of existing models. To
make this process viable, our framework resolves the prohibitive cost-quality
trade-off by employing an efficient, distilled model architecture augmented by
a temporal enhancer, which simultaneously reduces computational overhead and
improves temporal coherence. Finally, to achieve full scalability, this entire
pipeline is driven by an intelligent agent that crafts diverse instructions and
rigorously filters the output, ensuring quality control at scale. Using this
framework, we invested over 12,000 GPU-days to build Ditto-1M, a new dataset of
one million high-fidelity video editing examples. We trained our model, Editto,
on Ditto-1M with a curriculum learning strategy. The results demonstrate
superior instruction-following ability and establish a new state-of-the-art in
instruction-based video editing.

</details>


### [74] [SEGA: A Stepwise Evolution Paradigm for Content-Aware Layout Generation with Design Prior](https://arxiv.org/abs/2510.15749)
*Haoran Wang,Bo Zhao,Jinghui Wang,Hanzhang Wang,Huan Yang,Wei Ji,Hao Liu,Xinyan Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种新的逐步进化范式SEGA，用于内容感知的布局生成，通过粗略到精细的分层推理框架和引入布局设计原则先验知识，显著提升了复杂场景下的布局规划能力，并发布了大规模海报数据集GenPoster-100K。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂元素布局时缺乏反馈自修正机制，导致失败率较高，难以生成与背景图像协调的高质量布局。

Method: 提出SEGA模型，采用分层推理框架：首先由粗粒度模块估计整体布局，再由细化模块进行精细调整；同时融入布局设计原则作为先验知识，并构建了大规模标注数据集GenPoster-100K用于训练和评估。

Result: 在多个基准数据集上实现了最先进的性能，验证了所提方法在内容感知布局生成任务中的有效性。

Conclusion: SEGA通过模仿人类思维的逐步优化过程，结合设计先验与大规模数据，有效解决了复杂场景下的内容感知布局生成问题，具有较强的实用性和扩展性。

Abstract: In this paper, we study the content-aware layout generation problem, which
aims to automatically generate layouts that are harmonious with a given
background image. Existing methods usually deal with this task with a
single-step reasoning framework. The lack of a feedback-based self-correction
mechanism leads to their failure rates significantly increasing when faced with
complex element layout planning. To address this challenge, we introduce SEGA,
a novel Stepwise Evolution Paradigm for Content-Aware Layout Generation.
Inspired by the systematic mode of human thinking, SEGA employs a hierarchical
reasoning framework with a coarse-to-fine strategy: first, a coarse-level
module roughly estimates the layout planning results; then, another refining
module performs fine-level reasoning regarding the coarse planning results.
Furthermore, we incorporate layout design principles as prior knowledge into
the model to enhance its layout planning ability. Besides, we present
GenPoster-100K that is a new large-scale poster dataset with rich
meta-information annotation. The experiments demonstrate the effectiveness of
our approach by achieving the state-of-the-art results on multiple benchmark
datasets. Our project page is at: https://brucew91.github.io/SEGA.github.io/

</details>


### [75] [NDM: A Noise-driven Detection and Mitigation Framework against Implicit Sexual Intentions in Text-to-Image Generation](https://arxiv.org/abs/2510.15752)
*Yitong Sun,Yao Huang,Ruochen Zhang,Huanran Chen,Shouwei Ruan,Ranjie Duan,Xingxing Wei*

Main category: cs.CV

TL;DR: 提出了一种名为NDM的噪声驱动的检测与缓解框架，用于在文本到图像生成中检测和抑制隐式恶意意图，同时保持模型原有的生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的检测方法难以识别隐含的性暗示提示，且微调方法可能损害生成质量，因此需要一种既能有效检测隐式风险又能保留生成性能的解决方案。

Method: 利用早期预测噪声的可分离性，设计基于噪声的检测方法，并提出噪声增强的自适应负引导机制，通过抑制显著区域注意力来优化初始噪声，从而实现对隐式性内容的有效抑制。

Result: 在自然和对抗数据集上验证了NDM的有效性，其性能优于SLD、UCE、RECE等现有最先进方法。

Conclusion: NDM首次实现了在不损害生成质量的前提下对隐式性内容的高效检测与缓解，为文本到图像扩散模型的安全性提供了新的解决路径。

Abstract: Despite the impressive generative capabilities of text-to-image (T2I)
diffusion models, they remain vulnerable to generating inappropriate content,
especially when confronted with implicit sexual prompts. Unlike explicit
harmful prompts, these subtle cues, often disguised as seemingly benign terms,
can unexpectedly trigger sexual content due to underlying model biases, raising
significant ethical concerns. However, existing detection methods are primarily
designed to identify explicit sexual content and therefore struggle to detect
these implicit cues. Fine-tuning approaches, while effective to some extent,
risk degrading the model's generative quality, creating an undesirable
trade-off. To address this, we propose NDM, the first noise-driven detection
and mitigation framework, which could detect and mitigate implicit malicious
intention in T2I generation while preserving the model's original generative
capabilities. Specifically, we introduce two key innovations: first, we
leverage the separability of early-stage predicted noise to develop a
noise-based detection method that could identify malicious content with high
accuracy and efficiency; second, we propose a noise-enhanced adaptive negative
guidance mechanism that could optimize the initial noise by suppressing the
prominent region's attention, thereby enhancing the effectiveness of adaptive
negative guidance for sexual mitigation. Experimentally, we validate NDM on
both natural and adversarial datasets, demonstrating its superior performance
over existing SOTA methods, including SLD, UCE, and RECE, etc. Code and
resources are available at https://github.com/lorraine021/NDM.

</details>


### [76] [Semantic segmentation with coarse annotations](https://arxiv.org/abs/2510.15756)
*Jort de Jong,Mike Holenderski*

Main category: cs.CV

TL;DR: 提出一种基于超像素的正则化方法，用于编码器-解码器结构的语义分割模型，在粗标注数据下显著提升边界召回率。


<details>
  <summary>Details</summary>
Motivation: 在难以获得精细标注的情况下，利用粗标注进行语义分割面临边界对齐困难的问题，需要提高模型在粗标注下的边界分割性能。

Method: 提出一种基于SLIC超像素的正则化方法，鼓励解码后的分割结果以颜色和位置为基础形成超像素，与标注无关，并应用于FCN-16网络结构。

Result: 在SUIM、Cityscapes和PanNuke数据集上验证，该方法在粗标注训练下显著提升了边界召回率，优于现有方法。

Conclusion: 该正则化方法有效改善了粗标注条件下的语义分割边界质量，为低成本标注场景提供了可行方案。

Abstract: Semantic segmentation is the task of classifying each pixel in an image.
Training a segmentation model achieves best results using annotated images,
where each pixel is annotated with the corresponding class. When obtaining fine
annotations is difficult or expensive, it may be possible to acquire coarse
annotations, e.g. by roughly annotating pixels in an images leaving some pixels
around the boundaries between classes unlabeled. Segmentation with coarse
annotations is difficult, in particular when the objective is to optimize the
alignment of boundaries between classes. This paper proposes a regularization
method for models with an encoder-decoder architecture with superpixel based
upsampling. It encourages the segmented pixels in the decoded image to be
SLIC-superpixels, which are based on pixel color and position, independent of
the segmentation annotation. The method is applied to FCN-16 fully
convolutional network architecture and evaluated on the SUIM, Cityscapes, and
PanNuke data sets. It is shown that the boundary recall improves significantly
compared to state-of-the-art models when trained on coarse annotations.

</details>


### [77] [QSilk: Micrograin Stabilization and Adaptive Quantile Clipping for Detail-Friendly Latent Diffusion](https://arxiv.org/abs/2510.15761)
*Denis Rychkovskiy*

Main category: cs.CV

TL;DR: QSilk是一种轻量级、常驻的潜扩散稳定层，通过微钳位和自适应分位剪切提升高频保真度并抑制激活尖峰，无需训练即可在低步数和超高清分辨率下实现更清晰、锐利的渲染效果。


<details>
  <summary>Details</summary>
Motivation: 为了在保持纹理细节的同时提高潜扩散模型在高分辨率生成中的稳定性，抑制罕见的激活异常并增强高频细节表现。

Method: 提出QSilk，结合每样本微钳位和自适应分位剪切（AQClip），后者可根据区域特性动态调整数值范围，支持基于局部结构统计的代理模式或注意力熵引导的模型置信度模式。

Result: 在CADE 2.5渲染管线中集成后，QSilk在低步数和超高清分辨率下显著提升图像清晰度与锐利度，开销极低，且与CFG/Rescale等技术具有协同效应。

Conclusion: QSilk无需训练或微调，仅需极少用户控制，即可在多种SD/SDXL架构上实现一致的定性改进，是一种高效实用的扩散模型稳定方案。

Abstract: We present QSilk, a lightweight, always-on stabilization layer for latent
diffusion that improves high-frequency fidelity while suppressing rare
activation spikes. QSilk combines (i) a per-sample micro clamp that gently
limits extreme values without washing out texture, and (ii) Adaptive Quantile
Clip (AQClip), which adapts the allowed value corridor per region. AQClip can
operate in a proxy mode using local structure statistics or in an attention
entropy guided mode (model confidence). Integrated into the CADE 2.5 rendering
pipeline, QSilk yields cleaner, sharper results at low step counts and
ultra-high resolutions with negligible overhead. It requires no training or
fine-tuning and exposes minimal user controls. We report consistent qualitative
improvements across SD/SDXL backbones and show synergy with CFG/Rescale,
enabling slightly higher guidance without artifacts.

</details>


### [78] [Towards more holistic interpretability: A lightweight disentangled Concept Bottleneck Model](https://arxiv.org/abs/2510.15770)
*Gaoxiang Huang,Songning Lai,Yutao Yue*

Main category: cs.CV

TL;DR: 提出一种轻量级解耦概念瓶颈模型（LDCBM），通过无需区域标注的自动特征分组、滤波分组损失和联合概念监督，提升概念与视觉模式的对齐，增强可解释性和分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型存在输入到概念映射偏差和可控性不足的问题，限制了其实际应用价值和基于概念方法的策略可信度。

Method: 提出轻量级解耦概念瓶颈模型（LDCBM），通过引入滤波分组损失和联合概念监督，自动将视觉特征分组为语义上有意义的组件，无需区域标注。

Result: 在三个不同数据集上的实验表明，LDCBM在概念准确率和分类准确率上均优于以往CBM方法，具有更强的可解释性和鲁棒性。

Conclusion: LDCBM通过将概念建立在视觉证据基础上，克服了先前模型的根本局限，提升了可解释AI的可靠性。

Abstract: Concept Bottleneck Models (CBMs) enhance interpretability by predicting
human-understandable concepts as intermediate representations. However,
existing CBMs often suffer from input-to-concept mapping bias and limited
controllability, which restricts their practical value, directly damage the
responsibility of strategy from concept-based methods. We propose a lightweight
Disentangled Concept Bottleneck Model (LDCBM) that automatically groups visual
features into semantically meaningful components without region annotation. By
introducing a filter grouping loss and joint concept supervision, our method
improves the alignment between visual patterns and concepts, enabling more
transparent and robust decision-making. Notably, Experiments on three diverse
datasets demonstrate that LDCBM achieves higher concept and class accuracy,
outperforming previous CBMs in both interpretability and classification
performance. By grounding concepts in visual evidence, our method overcomes a
fundamental limitation of prior models and enhances the reliability of
interpretable AI.

</details>


### [79] [Controlling the image generation process with parametric activation functions](https://arxiv.org/abs/2510.15778)
*Ilia Pavlov*

Main category: cs.CV

TL;DR: 提出一种通过替换生成网络激活函数为参数化函数并调节其参数来增强用户对模型理解的交互式方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型虽在保真度和普及性上不断提升，但缺乏可解释地直接与其内部机制交互的工具。

Method: 将生成网络中的激活函数替换为可调参数的激活函数，允许用户通过调整参数来控制网络输出，并进行交互式探索。

Result: 在StyleGAN2（FFHQ）和BigGAN（ImageNet）上验证了该方法的有效性，展示了对生成结果的可控性和可解释性。

Conclusion: 该方法为理解和操控生成模型提供了一种新的可解释、交互式的途径。

Abstract: As image generative models continue to increase not only in their fidelity
but also in their ubiquity the development of tools that leverage direct
interaction with their internal mechanisms in an interpretable way has received
little attention In this work we introduce a system that allows users to
develop a better understanding of the model through interaction and
experimentation By giving users the ability to replace activation functions of
a generative network with parametric ones and a way to set the parameters of
these functions we introduce an alternative approach to control the networks
output We demonstrate the use of our method on StyleGAN2 and BigGAN networks
trained on FFHQ and ImageNet respectively.

</details>


### [80] [ReCon: Region-Controllable Data Augmentation with Rectification and Alignment for Object Detection](https://arxiv.org/abs/2510.15783)
*Haowei Zhu,Tianxiang Pan,Rui Qin,Jun-Hai Yong,Bin Wang*

Main category: cs.CV

TL;DR: 提出ReCon，一种基于区域引导校正和区域对齐交叉注意力的新型数据增强框架，提升生成数据在目标检测中的质量与可用性。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在数据增强中常存在内容-位置不匹配和语义泄露问题，且依赖复杂后处理或大规模微调，限制了其在目标检测中的应用。

Method: ReCon将区域引导校正集成到扩散采样过程中，利用预训练感知模型的反馈来修正生成错误的区域；同时提出区域对齐交叉注意力机制，增强图像区域与文本提示间的空间-语义一致性。

Result: 实验表明，ReCon显著提升了生成数据的质量和可训练性，在不同数据集、主干网络和数据规模下均实现性能提升。

Conclusion: ReCon有效增强了结构可控生成模型在目标检测任务中的数据增强能力，解决了语义一致性和空间对齐的关键问题。

Abstract: The scale and quality of datasets are crucial for training robust perception
models. However, obtaining large-scale annotated data is both costly and
time-consuming. Generative models have emerged as a powerful tool for data
augmentation by synthesizing samples that adhere to desired distributions.
However, current generative approaches often rely on complex post-processing or
extensive fine-tuning on massive datasets to achieve satisfactory results, and
they remain prone to content-position mismatches and semantic leakage. To
overcome these limitations, we introduce ReCon, a novel augmentation framework
that enhances the capacity of structure-controllable generative models for
object detection. ReCon integrates region-guided rectification into the
diffusion sampling process, using feedback from a pre-trained perception model
to rectify misgenerated regions within diffusion sampling process. We further
propose region-aligned cross-attention to enforce spatial-semantic alignment
between image regions and their textual cues, thereby improving both semantic
consistency and overall image fidelity. Extensive experiments demonstrate that
ReCon substantially improve the quality and trainability of generated data,
achieving consistent performance gains across various datasets, backbone
architectures, and data scales. Our code is available at
https://github.com/haoweiz23/ReCon .

</details>


### [81] [ERNet: Efficient Non-Rigid Registration Network for Point Sequences](https://arxiv.org/abs/2510.15800)
*Guangzhao He,Yuxi Xiao,Zhen Xu,Xiaowei Zhou,Sida Peng*

Main category: cs.CV

TL;DR: 提出ERNet，一种高效的前馈模型，用于非刚性形变点云序列的配准，通过两阶段管道预测形变图序列，在准确性和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决非刚性形变点云序列配准中的局部极小值和误差累积问题，提升在噪声和部分输入下的鲁棒性与长期跟踪性能。

Method: 采用数据驱动的可扩展方法，设计ERNet模型，通过两阶段管道：先逐帧估计粗略图节点进行稳健初始化，再以滑动窗口方式优化其时间轨迹。

Result: 在DeformingThings4D和D-FAUST数据集上超越先前最优方法，并实现超过4倍的速度提升。

Conclusion: ERNet在非刚性点云序列配准中实现了更高的准确性、一致性和计算效率，有效应对噪声、遮挡和长序列误差累积挑战。

Abstract: Registering an object shape to a sequence of point clouds undergoing
non-rigid deformation is a long-standing challenge. The key difficulties stem
from two factors: (i) the presence of local minima due to the non-convexity of
registration objectives, especially under noisy or partial inputs, which
hinders accurate and robust deformation estimation, and (ii) error accumulation
over long sequences, leading to tracking failures. To address these challenges,
we introduce to adopt a scalable data-driven approach and propose ERNet, an
efficient feed-forward model trained on large deformation datasets. It is
designed to handle noisy and partial inputs while effectively leveraging
temporal information for accurate and consistent sequential registration. The
key to our design is predicting a sequence of deformation graphs through a
two-stage pipeline, which first estimates frame-wise coarse graph nodes for
robust initialization, before refining their trajectories over time in a
sliding-window fashion. Extensive experiments show that our proposed approach
(i) outperforms previous state-of-the-art on both the DeformingThings4D and
D-FAUST datasets, and (ii) achieves more than 4x speedup compared to the
previous best, offering significant efficiency improvement.

</details>


### [82] [VISTA: A Test-Time Self-Improving Video Generation Agent](https://arxiv.org/abs/2510.15831)
*Do Xuan Long,Xingchen Wan,Hootan Nakhost,Chen-Yu Lee,Tomas Pfister,Sercan Ö. Arık*

Main category: cs.CV

TL;DR: 本文提出了一种名为VISTA的多智能体系统，通过迭代优化提示词来自主提升视频生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成方法对用户提示词依赖性强，且在测试时优化方法难以应对视频生成的多面性挑战。

Method: VISTA将用户想法分解为结构化的时间计划，通过成对比赛选择最佳视频，并由专注于视觉、音频和上下文保真度的三个特化代理进行批评，最后由推理代理综合反馈以重写和增强提示词。

Result: 实验表明，VISTA在单场景和多场景视频生成中均能持续提升视频质量和与用户意图的一致性，相较于现有最先进基线方法，成对胜率达到60%，人类评估者在66.4%的情况下更偏好VISTA生成的结果。

Conclusion: VISTA通过多智能体协同的迭代自改进机制，有效提升了文本到视频生成的质量和一致性，展现出较强的实用性与优越性能。

Abstract: Despite rapid advances in text-to-video synthesis, generated video quality
remains critically dependent on precise user prompts. Existing test-time
optimization methods, successful in other domains, struggle with the
multi-faceted nature of video. In this work, we introduce VISTA (Video
Iterative Self-improvemenT Agent), a novel multi-agent system that autonomously
improves video generation through refining prompts in an iterative loop. VISTA
first decomposes a user idea into a structured temporal plan. After generation,
the best video is identified through a robust pairwise tournament. This winning
video is then critiqued by a trio of specialized agents focusing on visual,
audio, and contextual fidelity. Finally, a reasoning agent synthesizes this
feedback to introspectively rewrite and enhance the prompt for the next
generation cycle. Experiments on single- and multi-scene video generation
scenarios show that while prior methods yield inconsistent gains, VISTA
consistently improves video quality and alignment with user intent, achieving
up to 60% pairwise win rate against state-of-the-art baselines. Human
evaluators concur, preferring VISTA outputs in 66.4% of comparisons.

</details>


### [83] [Neuro-Symbolic Spatial Reasoning in Segmentation](https://arxiv.org/abs/2510.15841)
*Jiayi Lin,Jiabo Huang,Shaogang Gong*

Main category: cs.CV

TL;DR: 本文提出了RelateSeg，首次将神经符号（NeSy）空间推理引入开放词汇语义分割（OVSS），通过一阶逻辑在深度网络中建模显式的空间关系约束，实现像素级语义与空间伪类别的联合预测，显著提升多物体场景下的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉-语言模型的OVSS方法缺乏对场景中物体间空间关系的理解，难以泛化到未见类别，因此需要引入显式空间推理机制以提升分割一致性与准确性。

Method: 提出RelateSeg，利用伪类别自动提取图像中的空间关系（如“猫在人右侧”），构建一阶逻辑公式，并通过模糊逻辑松弛将其嵌入神经网络，实现端到端的空间关系一致的语义分割。每个像素同时预测语义类别和空间伪类别，施加关系约束。

Result: RelateSeg在四个基准数据集上实现了最先进的平均mIoU表现，尤其在包含多个类别的图像中优势明显，且仅增加一个辅助损失，无额外参数。

Conclusion: 引入神经符号空间推理能有效提升OVSS中对未见类别的泛化能力与空间一致性，RelateSeg为OVSS提供了新的范式，验证了逻辑约束与深度学习结合的有效性。

Abstract: Open-Vocabulary Semantic Segmentation (OVSS) assigns pixel-level labels from
an open set of categories, requiring generalization to unseen and unlabelled
objects. Using vision-language models (VLMs) to correlate local image patches
with potential unseen object categories suffers from a lack of understanding of
spatial relations of objects in a scene. To solve this problem, we introduce
neuro-symbolic (NeSy) spatial reasoning in OVSS. In contrast to contemporary
VLM correlation-based approaches, we propose Relational Segmentor (RelateSeg)
to impose explicit spatial relational constraints by first order logic (FOL)
formulated in a neural network architecture. This is the first attempt to
explore NeSy spatial reasoning in OVSS. Specifically, RelateSeg automatically
extracts spatial relations, e.g., <cat, to-right-of, person>, and encodes them
as first-order logic formulas using our proposed pseudo categories. Each pixel
learns to predict both a semantic category (e.g., "cat") and a spatial pseudo
category (e.g., "right of person") simultaneously, enforcing relational
constraints (e.g., a "cat" pixel must lie to the right of a "person"). Finally,
these logic constraints are formulated in a deep network architecture by fuzzy
logic relaxation, enabling end-to-end learning of spatial-relationally
consistent segmentation. RelateSeg achieves state-of-the-art performance in
terms of average mIoU across four benchmark datasets and particularly shows
clear advantages on images containing multiple categories, with the cost of
only introducing a single auxiliary loss function and no additional parameters,
validating the effectiveness of NeSy spatial reasoning in OVSS.

</details>


### [84] [3DPR: Single Image 3D Portrait Relight using Generative Priors](https://arxiv.org/abs/2510.15846)
*Pramod Rao,Abhimitra Meka,Xilong Zhou,Gereon Fox,Mallikarjun B R,Fangneng Zhan,Tim Weyrich,Bernd Bickel,Hanspeter Pfister,Wojciech Matusik,Thabo Beeler,Mohamed Elgharib,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 本文提出3DPR，一种基于图像的重光照模型，利用从光场采集的多视角OLAT图像学习生成先验，实现单目肖像图像中人头的高质量重光照渲染。


<details>
  <summary>Details</summary>
Motivation: 传统图形学方法依赖显式分解图像为几何、材质和光照，受限于模型假设与参数化；而该工作旨在通过数据驱动的生成先验克服这一限制，提升重光照的真实性和细节保真度。

Method: 引入一个大规模多视角4K OLAT数据集，结合预训练生成头模型的隐空间先验，通过编码器逆变换将输入肖像嵌入隐流形，并设计基于三平面（triplane）的反射率网络在隐空间中合成高保真OLAT图像，最终通过HDRI环境图组合生成结果。

Result: 实验表明，3DPR在身份保持、高光、自阴影和次表面散射等光照效果上优于先前方法，实现了物理准确的环境重光照。

Conclusion: 3DPR通过融合生成模型先验与光场数据，在无需显式解耦的情况下实现了高质量的人脸重光照，展示了隐空间中学习反射率的有效性。

Abstract: Rendering novel, relit views of a human head, given a monocular portrait
image as input, is an inherently underconstrained problem. The traditional
graphics solution is to explicitly decompose the input image into geometry,
material and lighting via differentiable rendering; but this is constrained by
the multiple assumptions and approximations of the underlying models and
parameterizations of these scene components. We propose 3DPR, an image-based
relighting model that leverages generative priors learnt from multi-view
One-Light-at-A-Time (OLAT) images captured in a light stage. We introduce a new
diverse and large-scale multi-view 4K OLAT dataset of 139 subjects to learn a
high-quality prior over the distribution of high-frequency face reflectance. We
leverage the latent space of a pre-trained generative head model that provides
a rich prior over face geometry learnt from in-the-wild image datasets. The
input portrait is first embedded in the latent manifold of such a model through
an encoder-based inversion process. Then a novel triplane-based reflectance
network trained on our lightstage data is used to synthesize high-fidelity OLAT
images to enable image-based relighting. Our reflectance network operates in
the latent space of the generative head model, crucially enabling a relatively
small number of lightstage images to train the reflectance model. Combining the
generated OLATs according to a given HDRI environment maps yields physically
accurate environmental relighting results. Through quantitative and qualitative
evaluations, we demonstrate that 3DPR outperforms previous methods,
particularly in preserving identity and in capturing lighting effects such as
specularities, self-shadows, and subsurface scattering. Project Page:
https://vcai.mpi-inf.mpg.de/projects/3dpr/

</details>


### [85] [Memory-SAM: Human-Prompt-Free Tongue Segmentation via Retrieval-to-Prompt](https://arxiv.org/abs/2510.15849)
*Joongwon Chae,Lihui Luo,Xi Yuan,Dongmei Yu,Zhenglin Chen,Lian Zhang,Peiwu Qin*

Main category: cs.CV

TL;DR: 提出Memory-SAM，一种无需训练、无需人工提示的舌部分割方法，通过检索先验样例生成有效提示，显著提升真实场景下的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有监督模型依赖大量标注数据，SAM类模型仍需人工提示，限制了在中医舌象分析中的自动化应用。

Method: 利用DINOv3密集特征和FAISS检索构建小型记忆库，从历史样本中自动提取查询图像的掩码约束对应关系，并转化为前景/背景点提示以指导SAM2进行分割。

Result: 在600张专家标注图像上验证，混合测试集mIoU达0.9863，优于FCN（0.8188）和检测框引导SAM基线（0.1839）；在真实场景下表现显著优于现有方法。

Conclusion: 检索生成提示的策略实现了高效、鲁棒的舌部分割，尤其适用于不规则边界和现实拍摄条件，推动了中医影像分析的自动化。

Abstract: Accurate tongue segmentation is crucial for reliable TCM analysis. Supervised
models require large annotated datasets, while SAM-family models remain
prompt-driven. We present Memory-SAM, a training-free, human-prompt-free
pipeline that automatically generates effective prompts from a small memory of
prior cases via dense DINOv3 features and FAISS retrieval. Given a query image,
mask-constrained correspondences to the retrieved exemplar are distilled into
foreground/background point prompts that guide SAM2 without manual clicks or
model fine-tuning. We evaluate on 600 expert-annotated images (300 controlled,
300 in-the-wild). On the mixed test split, Memory-SAM achieves mIoU 0.9863,
surpassing FCN (0.8188) and a detector-to-box SAM baseline (0.1839). On
controlled data, ceiling effects above 0.98 make small differences less
meaningful given annotation variability, while our method shows clear gains
under real-world conditions. Results indicate that retrieval-to-prompt enables
data-efficient, robust segmentation of irregular boundaries in tongue imaging.
The code is publicly available at https://github.com/jw-chae/memory-sam.

</details>


### [86] [BLIP3o-NEXT: Next Frontier of Native Image Generation](https://arxiv.org/abs/2510.15857)
*Jiuhai Chen,Le Xue,Zhiyang Xu,Xichen Pan,Shusheng Yang,Can Qin,An Yan,Honglu Zhou,Zeyuan Chen,Lifu Huang,Tianyi Zhou,Junnan Li,Silvio Savarese,Caiming Xiong,Ran Xu*

Main category: cs.CV

TL;DR: BLIP3o-NEXT 是一个开源的基础模型，统一了文本到图像生成和图像编辑任务，采用自回归+扩散架构，在图像生成与编辑性能上超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 推动原生图像生成的前沿发展，实现文本到图像生成与图像编辑的统一建模，并解决当前图像编辑中指令跟随和一致性不足的问题。

Method: 采用Autoregressive + Diffusion架构：自回归模型根据多模态输入生成离散图像token，其隐藏状态作为扩散模型的条件信号生成高保真图像；结合强化学习、后训练和数据引擎优化性能。

Result: 在多个文本到图像和图像编辑基准测试中，BLIP3o-NEXT表现出优于现有模型的生成质量和编辑一致性，验证了架构设计、数据质量与训练策略的有效性。

Conclusion: 数据质量与规模是决定模型性能上限的关键因素，结合自回归模型的推理能力与扩散模型的细节渲染能力可有效提升生成图像的连贯性与真实感，为未来图像生成模型提供可行方向。

Abstract: We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3
series that advances the next frontier of native image generation. BLIP3o-NEXT
unifies text-to-image generation and image editing within a single
architecture, demonstrating strong image generation and image editing
capabilities. In developing the state-of-the-art native image generation model,
we identify four key insights: (1) Most architectural choices yield comparable
performance; an architecture can be deemed effective provided it scales
efficiently and supports fast inference; (2) The successful application of
reinforcement learning can further push the frontier of native image
generation; (3) Image editing still remains a challenging task, yet instruction
following and the consistency between generated and reference images can be
significantly enhanced through post-training and data engine; (4) Data quality
and scale continue to be decisive factors that determine the upper bound of
model performance. Building upon these insights, BLIP3o-NEXT leverages an
Autoregressive + Diffusion architecture in which an autoregressive model first
generates discrete image tokens conditioned on multimodal inputs, whose hidden
states are then used as conditioning signals for a diffusion model to generate
high-fidelity images. This architecture integrates the reasoning strength and
instruction following of autoregressive models with the fine-detail rendering
ability of diffusion models, achieving a new level of coherence and realism.
Extensive evaluations of various text-to-image and image-editing benchmarks
show that BLIP3o-NEXT achieves superior performance over existing models.

</details>


### [87] [BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models](https://arxiv.org/abs/2510.15866)
*Kaushitha Silva,Mansitha Eashwara,Sanduni Ubayasiri,Ruwan Tennakoon,Damayanthi Herath*

Main category: cs.CV

TL;DR: 本文提出了BiomedXPro，一种用于生物医学视觉-语言模型的可解释提示生成框架，通过进化算法和大语言模型自动产生多样化的自然语言提示对，提升疾病诊断性能与可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的提示优化技术生成的隐向量或单一文本提示缺乏可解释性，难以满足临床诊断中多维度观察整合的需求，限制了其在高风险医疗场景中的可信度和应用。

Method: 提出BiomedXPro框架，利用大语言模型作为生物医学知识提取器和自适应优化器，采用进化算法自动生成多样、可解释的自然语言提示对，用于疾病诊断任务。

Result: 在多个生物医学基准测试中，BiomedXPro在少样本场景下持续优于当前最先进的提示调优方法，并显示出生成提示与显著临床特征之间的强语义对齐。

Conclusion: BiomedXPro通过生成多样化且可解释的提示集合，为模型预测提供了可验证的基础，是迈向更可信、更符合临床需求的AI系统的重要一步。

Abstract: The clinical adoption of biomedical vision-language models is hindered by
prompt optimization techniques that produce either uninterpretable latent
vectors or single textual prompts. This lack of transparency and failure to
capture the multi-faceted nature of clinical diagnosis, which relies on
integrating diverse observations, limits their trustworthiness in high-stakes
settings. To address this, we introduce BiomedXPro, an evolutionary framework
that leverages a large language model as both a biomedical knowledge extractor
and an adaptive optimizer to automatically generate a diverse ensemble of
interpretable, natural-language prompt pairs for disease diagnosis. Experiments
on multiple biomedical benchmarks show that BiomedXPro consistently outperforms
state-of-the-art prompt-tuning methods, particularly in data-scarce few-shot
settings. Furthermore, our analysis demonstrates a strong semantic alignment
between the discovered prompts and statistically significant clinical features,
grounding the model's performance in verifiable concepts. By producing a
diverse ensemble of interpretable prompts, BiomedXPro provides a verifiable
basis for model predictions, representing a critical step toward the
development of more trustworthy and clinically-aligned AI systems.

</details>


### [88] [LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal](https://arxiv.org/abs/2510.15868)
*Shr-Ruei Tsai,Wei-Cheng Chang,Jie-Ying Lee,Chih-Hai Su,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的外绘框架LightsOut，用于增强单图像去眩光方法，通过重建画面外光源显著提升去眩光效果。


<details>
  <summary>Details</summary>
Motivation: 现有单图像去眩光方法在画面外光源不完整或缺失时表现不佳，影响了物体检测和自动驾驶等关键任务的性能。

Method: 采用多任务回归模块和LoRA微调的扩散模型，实现真实且物理一致的画面外光源重建。

Result: 实验表明，LightsOut在多种挑战性场景下 consistently 提升了现有去眩光方法的性能，且无需额外训练，具有通用性和即插即用特性。

Conclusion: LightsOut是一种有效的预处理方案，能够显著增强现有SIFR方法对复杂眩光的处理能力。

Abstract: Lens flare significantly degrades image quality, impacting critical computer
vision tasks like object detection and autonomous driving. Recent Single Image
Flare Removal (SIFR) methods perform poorly when off-frame light sources are
incomplete or absent. We propose LightsOut, a diffusion-based outpainting
framework tailored to enhance SIFR by reconstructing off-frame light sources.
Our method leverages a multitask regression module and LoRA fine-tuned
diffusion model to ensure realistic and physically consistent outpainting
results. Comprehensive experiments demonstrate LightsOut consistently boosts
the performance of existing SIFR methods across challenging scenarios without
additional retraining, serving as a universally applicable plug-and-play
preprocessing solution. Project page: https://ray-1026.github.io/lightsout/

</details>


### [89] [Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery](https://arxiv.org/abs/2510.15869)
*Jie-Ying Lee,Yi-Ruei Liu,Shr-Ruei Tsai,Wei-Cheng Chang,Chung-Ho Wu,Jiewen Chan,Zhenjun Zhao,Chieh Hubert Lin,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 提出Skyfall-GS，首个无需昂贵3D标注的城市街区级3D场景生成框架，结合卫星图像与扩散模型实现高质量、实时可探索的3D城市场景合成。


<details>
  <summary>Details</summary>
Motivation: 缺乏大规模高质量真实3D扫描数据用于训练通用生成模型，难以合成大尺度、可交互且几何精确的城市3D场景。

Method: 结合可用的卫星图像（提供真实粗略几何）和开放域扩散模型（生成高质量近景外观），提出Skyfall-GS框架，并采用课程驱动的迭代优化策略逐步提升几何完整性和纹理真实感。

Result: 实验证明，Skyfall-GS在跨视角几何一致性与纹理真实性方面优于现有方法，支持实时沉浸式3D探索。

Conclusion: Skyfall-GS实现了无需3D标注的大规模3D城市场景生成，在几何精度和视觉质量上均有显著提升，为虚拟城市构建提供了可行方案。

Abstract: Synthesizing large-scale, explorable, and geometrically accurate 3D urban
scenes is a challenging yet valuable task in providing immersive and embodied
applications. The challenges lie in the lack of large-scale and high-quality
real-world 3D scans for training generalizable generative models. In this
paper, we take an alternative route to create large-scale 3D scenes by
synergizing the readily available satellite imagery that supplies realistic
coarse geometry and the open-domain diffusion model for creating high-quality
close-up appearances. We propose \textbf{Skyfall-GS}, the first city-block
scale 3D scene creation framework without costly 3D annotations, also featuring
real-time, immersive 3D exploration. We tailor a curriculum-driven iterative
refinement strategy to progressively enhance geometric completeness and
photorealistic textures. Extensive experiments demonstrate that Skyfall-GS
provides improved cross-view consistent geometry and more realistic textures
compared to state-of-the-art approaches. Project page:
https://skyfall-gs.jayinnn.dev/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Ming-Kun Xie,Biao Liu,Changwei Wang,Lei Feng,Yuheng Jia,Gang Niu,Masashi Sugiyama,Xin Geng*

Main category: cs.CL

TL;DR: 本文提出三个新的多标签毒性检测基准（Q-A-MLL、R-A-MLL、H-X-MLL），基于15类细粒度分类体系，解决现有单标签检测器在评估大语言模型毒性内容时存在的偏差问题，并通过伪标签方法提升检测性能，实验表明该方法优于GPT-4o和DeepSeek等先进基线。


<details>
  <summary>Details</summary>
Motivation: 现有的毒性检测主要依赖单标签基准，无法充分捕捉现实世界中毒性提示的模糊性和多维性，导致评估存在偏差（如漏检和误报），且多标签标注成本高昂，限制了有效评估与模型发展。

Method: 构建了三个基于公开毒性数据集的多标签基准，采用15类细粒度分类体系；提出一种基于伪标签的毒性检测方法，并从理论上证明使用伪标签训练优于直接的单标签监督学习。

Result: 实验结果显示，所提伪标签方法在多标签毒性检测上显著优于包括GPT-4o和DeepSeek在内的先进基线模型，提升了检测的准确性和可靠性。

Conclusion: 本文提出的多标签基准和伪标签方法有效解决了现有毒性检测中的评估偏差和标注成本问题，为大语言模型生成内容的毒性评估提供了更准确、可靠的解决方案。

Abstract: Large language models (LLMs) have achieved impressive results across a range
of natural language processing tasks, but their potential to generate harmful
content has raised serious safety concerns. Current toxicity detectors
primarily rely on single-label benchmarks, which cannot adequately capture the
inherently ambiguous and multi-dimensional nature of real-world toxic prompts.
This limitation results in biased evaluations, including missed toxic
detections and false positives, undermining the reliability of existing
detectors. Additionally, gathering comprehensive multi-label annotations across
fine-grained toxicity categories is prohibitively costly, further hindering
effective evaluation and development. To tackle these issues, we introduce
three novel multi-label benchmarks for toxicity detection: \textbf{Q-A-MLL},
\textbf{R-A-MLL}, and \textbf{H-X-MLL}, derived from public toxicity datasets
and annotated according to a detailed 15-category taxonomy. We further provide
a theoretical proof that, on our released datasets, training with pseudo-labels
yields better performance than directly learning from single-label supervision.
In addition, we develop a pseudo-label-based toxicity detection method.
Extensive experimental results show that our approach significantly surpasses
advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate
and reliable evaluation of multi-label toxicity in LLM-generated content.

</details>


### [91] [Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek](https://arxiv.org/abs/2510.15009)
*Enis Oğuz*

Main category: cs.CL

TL;DR: 本研究评估了生成式AI模型（ChatGPT、Gemini、Deepseek）在有无习语的学生作文自动评分中的表现，结合语料库与计算语言学方法，发现三者一致性高，其中Gemini在与人类评分者的一致性及处理习语能力上表现最佳，且无显著人口学偏见，具备独立或混合应用于作文评分的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于生成式AI在处理隐喻性语言（如习语）方面可能存在局限，研究旨在探究其在自动评分学生作文时的表现差异，特别是在包含习语的文本中是否会影响评分公平性与准确性。

Method: 从348篇学生作文语料库中构建两组等量作文：一组每篇含多个习语，另一组不含习语；使用与人类评分相同的评分标准，让ChatGPT、Gemini和Deepseek各对两组作文评分三次，并从评分一致性、与人类评分者的相关性及人口统计偏差等方面进行比较分析。

Result: 三个生成式AI模型均表现出优秀的评分一致性，Gemini在与人类评分者的评分一致性上优于其他模型，尤其在处理含习语的作文时最接近人类评分模式，且未发现对任何人口群体的明显偏见。

Conclusion: 生成式AI具备用于自动作文评分的潜力，尤其是Gemini在处理包含习语的作文时表现突出，是未来实现全自动或人机混合评分系统的优选模型。

Abstract: The developments in Generative AI technologies have paved the way for
numerous innovations in different fields. Recently, Generative AI has been
proposed as a competitor to AES systems in evaluating student essays
automatically. Considering the potential limitations of AI in processing
idioms, this study assessed the scoring performances of Generative AI models
for essays with and without idioms by incorporating insights from Corpus
Linguistics and Computational Linguistics. Two equal essay lists were created
from 348 student essays taken from a corpus: one with multiple idioms present
in each essay and another with no idioms in essays. Three Generative AI models
(ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists
three times, using the same rubric used by human raters in assigning essay
scores. The results revealed excellent consistency for all models, but Gemini
outperformed its competitors in interrater reliability with human raters. There
was also no detectable bias for any demographic group in AI assessment. For
essays with multiple idioms, Gemini followed a the most similar pattern to
human raters. While the models in the study demonstrated potential for a hybrid
approach, Gemini was the best candidate for the task due to its ability to
handle figurative language and showed promise for handling essay-scoring tasks
alone in the future.

</details>


### [92] [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](https://arxiv.org/abs/2510.15081)
*Shiyu Ji,Farnoosh Hashemi,Joice Chen,Juanwen Pan,Weicheng Ma,Hefan Zhang,Sophia Pan,Ming Cheng,Shubham Mohole,Saeed Hassanpour,Soroush Vosoughi,Michael Macy*

Main category: cs.CL

TL;DR: 提出一种基于大语言模型生成和标注合成辩论数据的新框架，用于自动识别四种修辞策略（因果、实证、情感、道德），并通过微调分类器验证其在跨领域任务中的高性能与强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有修辞策略分析依赖人工标注，成本高、难以扩展，且数据集受限于特定主题和策略，限制了模型的鲁棒性发展。

Method: 利用大语言模型根据四类修辞策略（因果、实证、情感、道德）自动生成并标注合成辩论数据，基于该数据微调基于Transformer的分类器，并在人工标注数据及多个外部语料库上验证模型性能。

Result: 模型在内部和外部数据集上均表现出高性能和良好的跨领域泛化能力；应用于说服力预测时提升了效果，并揭示1960–2020年美国总统辩论中情感型论点使用增加、认知型论点减少的趋势。

Conclusion: LLM生成的合成数据可有效支持修辞策略识别模型的训练，具备良好泛化性和实际应用价值，为自动化修辞分析提供了可扩展的新路径。

Abstract: Rhetorical strategies are central to persuasive communication, from political
discourse and marketing to legal argumentation. However, analysis of rhetorical
strategies has been limited by reliance on human annotation, which is costly,
inconsistent, difficult to scale. Their associated datasets are often limited
to specific topics and strategies, posing challenges for robust model
development. We propose a novel framework that leverages large language models
(LLMs) to automatically generate and label synthetic debate data based on a
four-part rhetorical typology (causal, empirical, emotional, moral). We
fine-tune transformer-based classifiers on this LLM-labeled dataset and
validate its performance against human-labeled data on this dataset and on
multiple external corpora. Our model achieves high performance and strong
generalization across topical domains. We illustrate two applications with the
fine-tuned model: (1) the improvement in persuasiveness prediction from
incorporating rhetorical strategy labels, and (2) analyzing temporal and
partisan shifts in rhetorical strategies in U.S. Presidential debates
(1960-2020), revealing increased use of affective over cognitive argument in
U.S. Presidential debates.

</details>


### [93] [Continual Learning via Sparse Memory Finetuning](https://arxiv.org/abs/2510.15103)
*Jessy Lin,Luke Zettlemoyer,Gargi Ghosh,Wen-Tau Yih,Aram Markosyan,Vincent-Pierre Berges,Barlas Oğuz*

Main category: cs.CL

TL;DR: 本文提出稀疏记忆微调方法，通过仅更新内存槽来减少新知识与已有能力之间的干扰，从而显著降低灾难性遗忘，在持续学习中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 由于可训练参数在所有任务间共享，导致模型在更新新数据时容易遗忘先前获得的能力，因此需要探索如何缓解这一问题。

Method: 引入稀疏记忆微调方法，利用内存层模型的设计特性进行稀疏更新，仅修改对新知识高度激活的内存槽。

Result: 在两个问答任务上评估发现，相比全量微调和LoRA等参数高效微调方法，稀疏记忆微调在获取新知识的同时遗忘程度大幅降低：NaturalQuestions F1指标分别下降89%（全量微调）和71%（LoRA），而该方法仅下降11%。

Conclusion: 内存层中的稀疏性为大型语言模型实现持续学习提供了一条有前景的路径。

Abstract: Modern language models are powerful, but typically static after deployment. A
major obstacle to building models that continually learn over time is
catastrophic forgetting, where updating on new data erases previously acquired
capabilities. Motivated by the intuition that mitigating forgetting is
challenging because trainable parameters are shared across all tasks, we
investigate whether sparse parameter updates can enable learning without
catastrophic forgetting. We introduce sparse memory finetuning, leveraging
memory layer models (Berges et al., 2024), which are sparsely updated by
design. By updating only the memory slots that are highly activated by a new
piece of knowledge relative to usage on pretraining data, we reduce
interference between new knowledge and the model's existing capabilities. We
evaluate learning and forgetting compared to full finetuning and
parameter-efficient finetuning with LoRA on two question answering tasks. We
find that sparse memory finetuning learns new knowledge while exhibiting
substantially less forgetting: while NaturalQuestions F1 drops by 89% after
full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields
only an 11% drop with the same level of new knowledge acquisition. Our results
suggest sparsity in memory layers offers a promising path toward continual
learning in large language models.

</details>


### [94] [Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks](https://arxiv.org/abs/2510.15115)
*Kirill Semenov,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文研究了多语言事实知识评估中模板翻译的问题，提出使用整句翻译提升语法正确性和评分可解释性，并在多个语言上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有模板翻译方法未考虑命名实体的语法和语义信息，导致生成的提示不合法或表达错误，影响评分解读，尤其是在形态丰富的语言中。

Method: 选取MLAMA数据集中的4种斯拉夫语，比较原始模板翻译与Google Translate和ChatGPT生成的句子级翻译在知识检索得分上的差异，并扩展至其他5种不同语系的语言进行分析。

Result: 句子级翻译显著提高了知识检索得分，且在多种语言中均观察到类似趋势。

Conclusion: 建议使用神经机器翻译或大语言模型进行整句翻译以确保多语言数据集的语法流畅性，从而获得更高且更可解释的评估结果。

Abstract: For multilingual factual knowledge assessment of LLMs, benchmarks such as
MLAMA use template translations that do not take into account the grammatical
and semantic information of the named entities inserted in the sentence. This
leads to numerous instances of ungrammaticality or wrong wording of the final
prompts, which complicates the interpretation of scores, especially for
languages that have a rich morphological inventory. In this work, we sample 4
Slavic languages from the MLAMA dataset and compare the knowledge retrieval
scores between the initial (templated) MLAMA dataset and its sentence-level
translations made by Google Translate and ChatGPT. We observe a significant
increase in knowledge retrieval scores, and provide a qualitative analysis for
possible reasons behind it. We also make an additional analysis of 5 more
languages from different families and see similar patterns. Therefore, we
encourage the community to control the grammaticality of highly multilingual
datasets for higher and more interpretable results, which is well approximated
by whole sentence translation with neural MT or LLM systems. The dataset and
all related code is published at the Github repository:
https://github.com/ZurichNLP/Fluent-mLAMA.

</details>


### [95] [Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis](https://arxiv.org/abs/2510.15125)
*Alexander Brady,Tunazzina Islam*

Main category: cs.CL

TL;DR: 提出一种基于大语言模型的端到端框架，用于从无标签语料库中自动生成可解释的主题分类体系，并应用于2024年美国大选前的Meta政治广告分析，揭示了广告支出、道德框架和受众定位的极化模式。


<details>
  <summary>Details</summary>
Motivation: 社交媒体在政治话语中起关键作用，但其内容体量大且变化快，传统分析方法难以有效处理；需要一种无需领域专业知识即可自动构建可解释话题结构的方法。

Method: 结合无监督聚类与基于提示的大语言模型标签生成，迭代构建主题分类体系，无需种子集或人工标注，实现对政治广告文本的自动主题提取与道德维度标注。

Result: 在Meta政治广告数据上验证了方法有效性，发现投票和移民广告占据最多支出与曝光，堕胎和选举诚信话题则获得不成比例的传播；资金来源高度极化，不同议题使用不同的道德叙事框架，且存在显著的人口定向特征。

Conclusion: 该框架支持对社交媒体政治信息进行可扩展且可解释的分析，有助于理解数字政治传播中的新兴叙事、极化动态及其道德基础。

Abstract: Social media platforms play a pivotal role in shaping political discourse,
but analyzing their vast and rapidly evolving content remains a major
challenge. We introduce an end-to-end framework for automatically generating an
interpretable topic taxonomy from an unlabeled corpus. By combining
unsupervised clustering with prompt-based labeling, our method leverages large
language models (LLMs) to iteratively construct a taxonomy without requiring
seed sets or domain expertise. We apply this framework to a large corpus of
Meta (previously known as Facebook) political ads from the month ahead of the
2024 U.S. Presidential election. Our approach uncovers latent discourse
structures, synthesizes semantically rich topic labels, and annotates topics
with moral framing dimensions. We show quantitative and qualitative analyses to
demonstrate the effectiveness of our framework. Our findings reveal that voting
and immigration ads dominate overall spending and impressions, while abortion
and election-integrity achieve disproportionate reach. Funding patterns are
equally polarized: economic appeals are driven mainly by conservative PACs,
abortion messaging splits between pro- and anti-rights coalitions, and
crime-and-justice campaigns are fragmented across local committees. The framing
of these appeals also diverges--abortion ads emphasize liberty/oppression
rhetoric, while economic messaging blends care/harm, fairness/cheating, and
liberty/oppression narratives. Topic salience further reveals strong
correlations between moral foundations and issues. Demographic targeting also
emerges. This work supports scalable, interpretable analysis of political
messaging on social media, enabling researchers, policymakers, and the public
to better understand emerging narratives, polarization dynamics, and the moral
underpinnings of digital political communication.

</details>


### [96] [FarsiMCQGen: a Persian Multiple-choice Question Generation Framework](https://arxiv.org/abs/2510.15134)
*Mohammad Heydari Rad,Rezvan Afari,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文提出了一种用于生成波斯语多选题（MCQ）的创新方法FarsiMCQGen，结合候选生成、过滤和排序技术，并利用Transformer、知识图谱与基于规则的方法生成高质量干扰项。研究还构建了一个包含10,289个问题的新波斯语MCQ数据集，并通过多种先进大语言模型验证其质量。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言（如波斯语）中缺乏高效、高质量的多选题自动生成方法，限制了教育测评的发展，因此需要一种能生成真实可靠选项的自动化方案。

Method: 结合Transformer模型、知识图谱与基于规则的方法，采用候选生成、过滤和排序三阶段策略生成波斯语MCQ及干扰项，并基于波斯语维基百科内容构建数据集。

Result: 成功构建了包含10,289个波斯语MCQ的新数据集，实验表明所提模型能有效生成高质量题目，且多个先进大语言模型对该数据集评估结果良好。

Conclusion: FarsiMCQGen方法能够有效生成高质量的波斯语多选题，所发布数据集为未来低资源语言教育测评研究提供了重要资源。

Abstract: Multiple-choice questions (MCQs) are commonly used in educational testing, as
they offer an efficient means of evaluating learners' knowledge. However,
generating high-quality MCQs, particularly in low-resource languages such as
Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an
innovative approach for generating Persian-language MCQs. Our methodology
combines candidate generation, filtering, and ranking techniques to build a
model that generates answer choices resembling those in real MCQs. We leverage
advanced methods, including Transformers and knowledge graphs, integrated with
rule-based approaches to craft credible distractors that challenge test-takers.
Our work is based on data from Wikipedia, which includes general knowledge
questions. Furthermore, this study introduces a novel Persian MCQ dataset
comprising 10,289 questions. This dataset is evaluated by different
state-of-the-art large language models (LLMs). Our results demonstrate the
effectiveness of our model and the quality of the generated dataset, which has
the potential to inspire further research on MCQs.

</details>


### [97] [Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning](https://arxiv.org/abs/2510.15191)
*Junlin Wu,Xianrui Zhong,Jiashuo Sun,Bolian Li,Bowen Jin,Jiawei Han,Qingkai Zeng*

Main category: cs.CL

TL;DR: 提出Structure-R1框架，利用强化学习将检索内容转化为结构化表示以增强大模型的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统依赖非结构化文本，信息密度低，影响推理效果；需要更高效的知识组织方式来提升推理性能。

Method: 通过强化学习训练一个内容表示策略，动态生成适应多步推理需求的结构化表示，并引入自奖励的结构验证机制确保结构正确且自包含。

Result: 在七个知识密集型基准上实验表明，使用7B规模模型的Structure-R1性能媲美更大模型，显著优于传统RAG方法。

Conclusion: 结构化表示能有效提升信息密度和上下文清晰度，从而增强语言模型的复杂推理能力。

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
reasoning capabilities. However, their performance remains constrained by
limited access to explicit and structured domain knowledge. Retrieval-Augmented
Generation (RAG) addresses this by incorporating external information as
context to augment reasoning. Nevertheless, traditional RAG systems typically
operate over unstructured and fragmented text, resulting in low information
density and suboptimal reasoning. To overcome these limitations, we propose
\textsc{Structure-R1}, a novel framework that transforms retrieved content into
structured representations optimized for reasoning. Leveraging reinforcement
learning, \textsc{Structure-R1} learns a content representation policy that
dynamically generates and adapts structural formats based on the demands of
multi-step reasoning. Unlike prior methods that rely on fixed schemas, our
approach adopts a generative paradigm capable of producing task-specific
structures tailored to individual queries. To ensure the quality and
reliability of these representations, we introduce a self-reward structural
verification mechanism that checks whether the generated structures are both
correct and self-contained. Extensive experiments on seven knowledge-intensive
benchmarks show that \textsc{Structure-R1} consistently achieves competitive
performance with a 7B-scale backbone model and matches the performance of much
larger models. Additionally, our theoretical analysis demonstrates how
structured representations enhance reasoning by improving information density
and contextual clarity. Our code and data are available at:
https://github.com/jlwu002/sr1.

</details>


### [98] [Extending Audio Context for Long-Form Understanding in Large Audio-Language Models](https://arxiv.org/abs/2510.15231)
*Yuatyong Chaichana,Pittawat Taveekitworachai,Warit Sirichotedumrong,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本文提出Partial YaRN和VLAT两种方法，以解决大型音频-语言模型（LALMs）在长音频理解中的上下文窗口限制问题。Partial YaRN是一种仅针对音频token的训练-free扩展方法，而VLAT则通过训练时的位置增强策略模拟多样化的音频长度，提升模型对超长音频的泛化能力和鲁棒性。实验表明，这两种方法在SALMONN和Qwen2-Audio模型上显著优于原始模型。


<details>
  <summary>Details</summary>
Motivation: 现有的LALMs通常受限于较短的音频上下文窗口，即使其文本主干网络支持长上下文，这限制了对长格式音频的理解。现有上下文扩展方法主要应用于单模态LLM，尚未探索其在LALMs中的应用。因此，需要一种适用于多模态音频-语言模型的有效上下文扩展方法。

Method: 首先提出Partial YaRN，基于RoPE的上下文扩展方法，仅修改音频token的位置编码，保持文本位置不变，以保留基础LLM的文本能力；其次提出Virtual Longform Audio Training (VLAT)，在训练过程中引入位置增强，通过模拟不同长度的音频输入来提升模型对长音频的泛化能力。

Result: 在SALMONN和Qwen2-Audio上的实验结果显示，Partial YaRN在多种设置下均优于原始模型，而采用VLAT训练策略进一步带来了显著性能提升，尤其在未见过的超长音频输入上表现出色。

Conclusion: Partial YaRN和VLAT为LALMs提供了有效的长上下文音频理解解决方案，无需额外训练即可扩展音频上下文，并通过训练策略增强了模型对长音频的适应性和鲁棒性，推动了多模态模型在长音频任务上的应用。

Abstract: Large Audio-Language Models (LALMs) are often constrained by short audio
context windows, even when their text backbones support long contexts, limiting
long-form audio understanding. Prior work has introduced context-extension
methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains
unexplored. First, building on RoPE-based context extension, we introduce
Partial YaRN, a training-free, audio-only extension method that modifies only
audio token positions, leaving text positions intact to preserve the base LLM's
text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a
training strategy that extends Partial YaRN into a training-time positional
augmentation. VLAT simulates diverse audio lengths during training, enabling
generalization to inputs far longer than those seen in training and improving
robustness for long-context audio understanding. Our experiments on SALMONN and
Qwen2-Audio show that Partial YaRN outperforms the original models across wide
range of settings, and VLAT training strategy provides substantial improvement,
achieving strong performance on long audio of unseen lengths.

</details>


### [99] [Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning](https://arxiv.org/abs/2510.15244)
*Lina Berrayana,Ahmed Heakl,Muhammad Abdullah Sohail,Thomas Hofmann,Salman Khan,Wei Chen*

Main category: cs.CL

TL;DR: 本研究探索了将离散扩散语言模型（DDLM）与自回归模型（ARM）结合的混合架构，发现通过潜空间通信可显著提升准确率并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有自回归模型虽然准确率高但生成长序列代价大，而扩散模型虽能并行生成但在文本生成上存在局限，因此探索两者协作的互补优势。

Method: 首先在文本空间中让一个模型规划、另一个执行；然后引入学习到的投影器，将DDLM的潜变量映射到ARM的嵌入空间，实现潜空间通信。

Result: 从文本空间转向潜空间通信显著提升了准确率（如DART-5从27.0%升至54.0%，AIME24从0.0%升至14.0%），且组合DDLM规划器与ARM执行器可在几乎不影响准确率的情况下大幅节省计算开销。

Conclusion: DDLM与ARM的混合架构，尤其是潜空间通信方式，具有显著的性能和效率优势，为复杂推理任务提供了新思路。

Abstract: Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.

</details>


### [100] [Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding](https://arxiv.org/abs/2510.15253)
*Sensen Gao,Shanshan Zhao,Xu Jiang,Lunhao Duan,Yong Xien Chng,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,Jia-Wang Bian,Mingming Gong*

Main category: cs.CL

TL;DR: 本文系统综述了面向文档理解的多模态检索增强生成（Multimodal RAG），提出分类体系，总结技术进展、数据集与应用，并指出效率、细粒度表示和鲁棒性等开放挑战。


<details>
  <summary>Details</summary>
Motivation: 现有文档理解方法在保留结构信息和上下文建模方面存在不足，OCR+LLM流程丢失结构细节，而多模态大模型难以有效建模上下文。文档的多模态特性需要更先进的检索增强范式。

Method: 提出基于领域、检索模态和粒度的分类体系，系统梳理结合图结构和智能体框架的多模态RAG进展，总结相关数据集、基准和应用场景。

Result: 建立了多模态RAG的系统性分类框架，归纳了当前技术发展现状与核心资源，明确了该领域在效率、细粒度表示和鲁棒性等方面的关键挑战。

Conclusion: 多模态RAG是实现全面文档智能的关键路径，本文为未来文档AI的发展提供了清晰的技术路线图。

Abstract: Document understanding is critical for applications from financial analysis
to scientific discovery. Current approaches, whether OCR-based pipelines
feeding Large Language Models (LLMs) or native Multimodal LLMs (MLLMs), face
key limitations: the former loses structural detail, while the latter struggles
with context modeling. Retrieval-Augmented Generation (RAG) helps ground models
in external data, but documents' multimodal nature, i.e., combining text,
tables, charts, and layout, demands a more advanced paradigm: Multimodal RAG.
This approach enables holistic retrieval and reasoning across all modalities,
unlocking comprehensive document intelligence. Recognizing its importance, this
paper presents a systematic survey of Multimodal RAG for document
understanding. We propose a taxonomy based on domain, retrieval modality, and
granularity, and review advances involving graph structures and agentic
frameworks. We also summarize key datasets, benchmarks, and applications, and
highlight open challenges in efficiency, fine-grained representation, and
robustness, providing a roadmap for future progress in document AI.

</details>


### [101] [TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration](https://arxiv.org/abs/2510.15267)
*Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: 提出TraceCoder框架，通过整合多源外部知识（如UMLS、Wikipedia和大语言模型）提升ICD编码的可追溯性与可解释性，结合混合注意力机制，在多个数据集上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有ICD编码方法存在语义鸿沟、对罕见和长尾代码表现差、可解释性不足等问题。

Method: 设计TraceCoder框架，动态融合多源外部知识以增强编码表示，并引入混合注意力机制建模标签、临床上下文与知识间的交互。

Result: 在MIMIC-III-ICD9、MIMIC-IV-ICD9和MIMIC-IV-ICD10数据集上达到SOTA性能，消融实验验证各组件有效性。

Conclusion: TraceCoder提供了一种可扩展且鲁棒的自动化ICD编码解决方案，满足临床对准确性、可解释性和可靠性的需求。

Abstract: Automated International Classification of Diseases (ICD) coding assigns
standardized diagnosis and procedure codes to clinical records, playing a
critical role in healthcare systems. However, existing methods face challenges
such as semantic gaps between clinical text and ICD codes, poor performance on
rare and long-tail codes, and limited interpretability. To address these
issues, we propose TraceCoder, a novel framework integrating multi-source
external knowledge to enhance traceability and explainability in ICD coding.
TraceCoder dynamically incorporates diverse knowledge sources, including UMLS,
Wikipedia, and large language models (LLMs), to enrich code representations,
bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a
hybrid attention mechanism to model interactions among labels, clinical
context, and knowledge, improving long-tail code recognition and making
predictions interpretable by grounding them in external evidence. Experiments
on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that
TraceCoder achieves state-of-the-art performance, with ablation studies
validating the effectiveness of its components. TraceCoder offers a scalable
and robust solution for automated ICD coding, aligning with clinical needs for
accuracy, interpretability, and reliability.

</details>


### [102] [TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding](https://arxiv.org/abs/2510.15269)
*Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种名为TACL（阈值自适应课程学习）的新框架，通过根据样本复杂度动态调整训练过程，提升模型对多语言电子病历的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常忽视临床记录间的复杂性差异，导致模型难以泛化到罕见或复杂的病例。因此需要一种能区分数据难度并优化训练过程的方法。

Method: TACL基于课程学习思想，将医疗文本按难度分级，在训练初期优先学习简单样本，逐步过渡到复杂样本，并动态调整难度阈值。

Result: 在英文和中文临床文本上验证了TACL的有效性，在ICD编码、再入院预测和中医证候辨识等多个任务中均显著提升了模型性能。

Conclusion: TACL能够有效提升医疗文本理解模型的性能，具备跨语言和跨任务的通用性，为构建更准确、可扩展的医疗AI系统提供了新路径。

Abstract: Medical texts, particularly electronic medical records (EMRs), are a
cornerstone of modern healthcare, capturing critical information about patient
care, diagnoses, and treatments. These texts hold immense potential for
advancing clinical decision-making and healthcare analytics. However, their
unstructured nature, domain-specific language, and variability across contexts
make automated understanding an intricate challenge. Despite the advancements
in natural language processing, existing methods often treat all data as
equally challenging, ignoring the inherent differences in complexity across
clinical records. This oversight limits the ability of models to effectively
generalize and perform well on rare or complex cases. In this paper, we present
TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to
address these challenges by rethinking how models interact with medical texts
during training. Inspired by the principle of progressive learning, TACL
dynamically adjusts the training process based on the complexity of individual
samples. By categorizing data into difficulty levels and prioritizing simpler
cases early in training, the model builds a strong foundation before tackling
more complex records. By applying TACL to multilingual medical data, including
English and Chinese clinical records, we observe significant improvements
across diverse clinical tasks, including automatic ICD coding, readmission
prediction and TCM syndrome differentiation. TACL not only enhances the
performance of automated systems but also demonstrates the potential to unify
approaches across disparate medical domains, paving the way for more accurate,
scalable, and globally applicable medical text understanding solutions.

</details>


### [103] [MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543)
*Qiyu Wu,Shuyang Cui,Satoshi Hayakawa,Wei-Yao Wang,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.CL

TL;DR: 提出一种模态组合感知框架，通过偏好损失和组合正则化目标来提升多模态检索在分布外场景下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 统一编码器在传统对比学习下容易学习到模态捷径，导致在分布偏移下表现不佳。

Method: 引入偏好损失使多模态嵌入优于单模态嵌入，并设计组合正则化目标将多模态嵌入与由单模态部分组成的原型对齐。

Result: 在多个基准上实验表明，该方法在分布外检索任务中性能显著提升。

Conclusion: 模态组合感知是利用MLLM作为统一编码器时实现鲁棒多模态检索的有效原则。

Abstract: Multimodal retrieval, which seeks to retrieve relevant content across
modalities such as text or image, supports applications from AI search to
contents production. Despite the success of separate-encoder approaches like
CLIP align modality-specific embeddings with contrastive learning, recent
multimodal large language models (MLLMs) enable a unified encoder that directly
processes composed inputs. While flexible and advanced, we identify that
unified encoders trained with conventional contrastive learning are prone to
learn modality shortcut, leading to poor robustness under distribution shifts.
We propose a modality composition awareness framework to mitigate this issue.
Concretely, a preference loss enforces multimodal embeddings to outperform
their unimodal counterparts, while a composition regularization objective
aligns multimodal embeddings with prototypes composed from its unimodal parts.
These objectives explicitly model structural relationships between the composed
representation and its unimodal counterparts. Experiments on various benchmarks
show gains in out-of-distribution retrieval, highlighting modality composition
awareness as a effective principle for robust composed multimodal retrieval
when utilizing MLLMs as the unified encoder.

</details>


### [104] [Exemplar-Guided Planing: Enhanced LLM Agent for KGQA](https://arxiv.org/abs/2510.15283)
*Jingao Xu,Shuoyoucheng Ma,Xin Song,Rong Jiang,Hongkui Tu,Bin Zhou*

Main category: cs.CL

TL;DR: 提出了一种名为Exemplar-Guided Planning (EGP)的新框架，通过利用训练数据中的成功推理路径来增强大语言模型在知识图谱问答（KGQA）中的规划能力，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在KGQA中存在自然语言与结构化知识图谱之间的语义鸿沟问题，导致规划效果差、探索效率低，且训练-free方法未能充分利用训练数据中的有效推理模式。

Method: EGP首先通过实体模板对训练集问题进行语义归一化，然后使用语义嵌入和FAISS索引检索相似的示例及其成功推理路径，并在任务分解和关系探索两个阶段动态指导LLM；同时引入Smart Lookahead机制提升探索效率。

Result: 在WebQSP和CWQ两个真实KGQA数据集上的实验表明，PoG-EGP显著优于基线方法PoG及其他对比方法。

Conclusion: EGP能有效提升LLM代理在KGQA中的规划能力和推理效率，为无需训练的LLM代理提供了利用历史推理模式的新途径。

Abstract: Large Language Models (LLMs) as interactive agents show significant promise
in Knowledge Graph Question Answering (KGQA) but often struggle with the
semantic gap between natural language queries and structured knowledge graph
(KG) representations. This leads to suboptimal planning and inefficient
exploration on KG, while training-free approaches often underutilize valuable
reasoning patterns in training data. To address these limitations, we propose a
novel framework, Exemplar-Guided Planning (EGP), which enhances the planning
capabilities of LLM agents for KGQA. EGP first preprocesses the training set
questions via entity templating to normalize semantic variations. It then
retrieves highly similar exemplary questions and their successful reasoning
paths from this preprocessed set using semantic embeddings and an efficient
FAISS index. These retrieved exemplars dynamically guide the LLM's planning
process in two key phases: (1) Task Decomposition, by aligning generated
sub-objectives with proven reasoning steps, and (2) Relation Exploration, by
providing high-quality auxiliary information to improve relation pruning
accuracy. Additionally, we introduce a Smart Lookahead mechanism during
relation exploration to improve efficiency by preemptively exploring promising
paths and potentially terminating exploration earlier. We apply EGP to the
Plan-on-Graph (PoG) framework, termed PoG-EGP. Extensive experiments on two
real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP
significantly improves over the baseline PoG system and other compared methods.

</details>


### [105] [Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth](https://arxiv.org/abs/2510.15719)
*Helia Hashemi,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 提出了一种成本感知的检索增强推理模型，通过动态调整检索文档长度和使用强化学习优化效率，在降低延迟的同时提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强推理模型计算成本高，资源消耗大，亟需更高效的解决方案。

Method: 设计了动态调整检索文档列表长度的模型，结合成本感知的优势函数，利用强化学习在内存和延迟受限的情况下优化训练过程。

Result: 在七个公开问答数据集上验证，模型延迟减少16-20%，准确率平均提升约5%（以精确匹配为指标）。

Conclusion: 所提出的成本感知框架在不牺牲效果的前提下显著提升了检索增强推理模型的效率，具有良好的实际应用潜力。

Abstract: Reasoning models have gained significant attention due to their strong
performance, particularly when enhanced with retrieval augmentation. However,
these models often incur high computational costs, as both retrieval and
reasoning tokens contribute substantially to the overall resource usage. In
this work, we make the following contributions: (1) we propose a
retrieval-augmented reasoning model that dynamically adjusts the length of the
retrieved document list based on the query and retrieval results; (2) we
develop a cost-aware advantage function for training of efficient
retrieval-augmented reasoning models through reinforcement learning; and (3) we
explore both memory- and latency-bound implementations of the proposed
cost-aware framework for both proximal and group relative policy optimization
algorithms. We evaluate our approach on seven public question answering
datasets and demonstrate significant efficiency gains, without compromising
effectiveness. In fact, we observed that the model latency decreases by ~16-20%
across datasets, while its effectiveness increases by ~5% on average, in terms
of exact match.

</details>


### [106] [Automatic essay scoring: leveraging Jaccard coefficient and Cosine similaritywith n-gram variation in vector space model approach](https://arxiv.org/abs/2510.15311)
*Andharini Dwi Cahyani,Moh. Wildan Fathoni,Fika Hastarita Rachman,Ari Basuki,Salman Amin,Bain Khusnul Khotimah*

Main category: cs.CL

TL;DR: 本研究比较了Jaccard系数和余弦相似度在基于n-gram向量空间模型的自动作文评分中的表现，结果表明余弦相似度优于Jaccard系数，且单个词（unigram）比双词和三词组合具有更低的误差。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动作文评分系统的准确性和效率，研究不同相似性度量方法在中学公民教育科目作文评估中的有效性。

Method: 采用n-gram模型（包括unigram、bigram和trigram）进行特征提取，并使用向量空间模型将文本转化为数值表示，随后计算作文之间的Jaccard系数和余弦相似度，并通过均方根误差（RMSE）评估系统性能。

Result: 余弦相似度的表现优于Jaccard系数；在n-gram层面，unigram的RMSE最低，优于bigram和trigram。

Conclusion: 在自动作文评分任务中，使用余弦相似度结合unigram特征能更有效地接近人工评分结果，是更优的方案。

Abstract: Automated essay scoring (AES) is a vital area of research aiming to provide
efficient and accurate assessment tools for evaluating written content. This
study investigates the effectiveness of two popular similarity metrics, Jaccard
coefficient, and Cosine similarity, within the context of vector space
models(VSM)employing unigram, bigram, and trigram representations. The data
used in this research was obtained from the formative essay of the citizenship
education subject in a junior high school. Each essay undergoes preprocessing
to extract features using n-gram models, followed by vectorization to transform
text data into numerical representations. Then, similarity scores are computed
between essays using both Jaccard coefficient and Cosine similarity. The
performance of the system is evaluated by analyzing the root mean square error
(RMSE), which measures the difference between the scores given by human graders
and those generated by the system. The result shows that the Cosine similarity
outperformed the Jaccard coefficient. In terms of n-gram, unigrams have lower
RMSE compared to bigrams and trigrams.

</details>


### [107] [Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination](https://arxiv.org/abs/2510.15312)
*Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma*

Main category: cs.CL

TL;DR: 提出CoordGen框架，通过结合推测解码与动态硬件调度，加速移动设备上的上下文感知文本生成。


<details>
  <summary>Details</summary>
Motivation: 在移动设备上，由于生成过程内存受限，导致大语言模型的逐token生成存在高延迟和硬件利用率低的问题。

Method: 引入三个协同组件：自适应执行调度、上下文对齐的草案生成和硬件高效的草案扩展，以优化预填充和解码阶段的计算图分配、提升推测效率并减少验证开销。

Result: 在多种智能手机和典型工作负载上的实验表明，相比现有方案，生成速度最高提升3.8倍，能效提升达4.7倍。

Conclusion: CoordGen有效提升了移动端上下文感知文本生成的效率，为个性化智能助手等应用提供了更高效的推理支持。

Abstract: Enhancing on-device large language models (LLMs) with contextual information
from local data enables personalized and task-aware generation, powering use
cases such as intelligent assistants and UI agents. While recent developments
in neural processors have substantially improved the efficiency of prefill on
mobile devices, the token-by-token generation process still suffers from high
latency and limited hardware utilization due to its inherently memory-bound
characteristics. This work presents CoordGen, a mobile inference framework that
integrates speculative decoding with dynamic hardware scheduling to accelerate
context-aware text generation on mobile devices. The framework introduces three
synergistic components: (1) adaptive execution scheduling, which dynamically
balances compute graphs between prefill and decoding phases; (2)
context-aligned drafting, which improves speculative efficiency through
lightweight online calibration to current tasks; and (3) hardware-efficient
draft extension, which reuses and expands intermediate sequences to improve
processing parallelism and reduce verification cost. Experiments on multiple
smartphones and representative workloads show consistent improvements of up to
3.8x in generation speed and 4.7x in energy efficiency compared with existing
mobile inference solutions. Component-level analysis further validates the
contribution of each optimization.

</details>


### [108] [Capabilities and Evaluation Biases of Large Language Models in Classical Chinese Poetry Generation: A Case Study on Tang Poetry](https://arxiv.org/abs/2510.15313)
*Bolei Ma,Yina Yao,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: 提出了一种结合计算指标、大模型评分和人类专家验证的三步评估框架，用于评估大模型在古典中文诗歌生成中的表现，发现模型在评价创造性质量时存在“回音室”效应，与人类判断存在偏差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在创意领域的应用日益广泛，但其在古典中文诗歌生成与评估方面的表现尚不清楚，需要系统评估其能力与局限。

Method: 提出一种三步评估框架，结合计算指标、大模型作为评判者（LLM-as-a-judge）以及人类专家验证，对六种主流大模型在主题、情感、意象、形式和风格等多个维度进行评估。

Result: 发现大模型在自我评估时存在“回音室”效应，倾向于采纳有缺陷的评估标准，与人类专家判断存在系统性偏差。

Conclusion: 当前大模型在古典中文诗歌生成与评估中存在局限，需结合人类与模型的混合验证方式，以应对文化与技术复杂性较高的创意任务。

Abstract: Large Language Models (LLMs) are increasingly applied to creative domains,
yet their performance in classical Chinese poetry generation and evaluation
remains poorly understood. We propose a three-step evaluation framework that
combines computational metrics, LLM-as-a-judge assessment, and human expert
validation. Using this framework, we evaluate six state-of-the-art LLMs across
multiple dimensions of poetic quality, including themes, emotions, imagery,
form, and style. Our analysis reveals systematic generation and evaluation
biases: LLMs exhibit "echo chamber" effects when assessing creative quality,
often converging on flawed standards that diverge from human judgments. These
findings highlight both the potential and limitations of current capabilities
of LLMs as proxy for literacy generation and the limited evaluation practices,
thereby demonstrating the continued need of hybrid validation from both humans
and models in culturally and technically complex creative tasks.

</details>


### [109] [AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction](https://arxiv.org/abs/2510.15339)
*Hong Ting Tsang,Jiaxin Bai,Haoyu Huang,Qiao Xiao,Tianshi Zheng,Baixuan Xu,Shujie Liu,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文提出了AutoGraph-R1，首个使用强化学习直接优化知识图谱构建以提升下游任务性能的框架，通过任务感知的奖励函数显著提升了基于知识图谱的检索增强生成在问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱构建过程与其下游应用脱节，导致图结构次优，难以充分发挥其在检索增强生成（RAG）中的潜力。

Method: 将图谱生成建模为策略学习问题，利用强化学习训练LLM构造器，并设计了两种任务感知的奖励函数：一种用于图谱作为知识载体，另一种用于图谱作为知识索引。

Result: 在多个问答基准上，AutoGraph-R1 consistently 提升了图RAG方法的性能，优于任务无关的基线图谱。

Conclusion: 实现了知识图谱构建与应用之间的闭环优化，推动了从构建“内在良好”的图谱转向构建“实际有用”的图谱的新范式。

Abstract: Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation
(RAG) is pivotal for advancing question answering (QA) systems. However, its
effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)
construction process is decoupled from its downstream application, yielding
suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the
first framework to directly optimize KG construction for task performance using
Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing
graph generation as a policy learning problem, where the reward is derived from
the graph's functional utility in a RAG pipeline. We design two novel,
task-aware reward functions, one for graphs as knowledge carriers and another
as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently
enables graph RAG methods to achieve significant performance gains over using
task-agnostic baseline graphs. Our work shows it is possible to close the loop
between construction and application, shifting the paradigm from building
intrinsically ``good'' graphs to building demonstrably ``useful'' ones.

</details>


### [110] [Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics](https://arxiv.org/abs/2510.15345)
*Catarina G Belem,Parker Glenn,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 该研究通过分析897个人类可读性判断，发现信息内容和主题显著影响文本的可理解性，而不仅仅是表面特征。评估了15种传统与6种基于模型的可读性指标，结果显示基于模型的指标在与人类判断的相关性上表现更优，表明其比传统方法更具前景。


<details>
  <summary>Details</summary>
Motivation: 当前可读性评估领域缺乏一致定义，且多依赖文本表层特征，难以准确反映人类对可读性的实际感知，因此需要探究真正影响可读性的因素并比较不同度量方式的有效性。

Method: 分析897条人类可读性判断数据，考察语言表层特征、信息内容和话题等因素对可读性感知的影响；并在五个英文数据集上评估15种传统可读性指标和6种基于模型的指标，比较它们与人类判断的排名相关性。

Result: 信息内容和话题显著影响人类对可读性的感知；在与人类判断的排名相关性上，四种基于模型的指标始终位列前四，而最佳传统指标平均排名仅为8.6。

Conclusion: 现有可读性指标与人类感知存在不匹配，基于模型的方法更能捕捉可读性的复杂性，是未来更具潜力的发展方向。

Abstract: Automatic readability assessment plays a key role in ensuring effective and
accessible written communication. Despite significant progress, the field is
hindered by inconsistent definitions of readability and measurements that rely
on surface-level text properties. In this work, we investigate the factors
shaping human perceptions of readability through the analysis of 897 judgments,
finding that, beyond surface-level cues, information content and topic strongly
shape text comprehensibility. Furthermore, we evaluate 15 popular readability
metrics across five English datasets, contrasting them with six more nuanced,
model-based metrics. Our results show that four model-based metrics
consistently place among the top four in rank correlations with human
judgments, while the best performing traditional metric achieves an average
rank of 8.6. These findings highlight a mismatch between current readability
metrics and human perceptions, pointing to model-based approaches as a more
promising direction.

</details>


### [111] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://arxiv.org/abs/2510.15346)
*Heecheol Yun,Kwangmin Ki,Junghyun Lee,Eunho Yang*

Main category: cs.CL

TL;DR: 本文提出了SAFE框架，通过选择性集成大语言模型的下一个词元概率分布来提升长文本生成的性能，结合分词匹配和共识度分析，并引入概率锐化策略以提高稳定性与效率。


<details>
  <summary>Details</summary>
Motivation: 现有的集成方法在短答案任务中表现良好，但在长文本生成中的应用效果不佳，需要谨慎选择集成位置。因此，本文旨在解决这一问题，提升长文本生成中集成LLM的效果。

Method: 提出SAFE框架，基于模型间的分词不一致性和下一词元概率分布的一致性来决定是否进行集成，并引入概率锐化策略，将同一单词的多个子词元概率集中到一个代表词元上。

Result: 在MATH500和BBH等多个基准上的实验表明，SAFE在准确性和效率方面均优于现有方法，即使仅集成不到1%的词元也能取得性能增益。

Conclusion: 通过选择性集成和概率锐化，SAFE有效解决了长文本生成中传统集成方法性能下降的问题，实现了更稳定且高效的LLM集成。

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising
approach to surpass the performance of individual models by leveraging their
complementary strengths. In particular, aggregating models' next-token
probability distributions to select the next token has been shown to be
effective in various tasks. However, while successful for short-form answers,
its application to long-form generation remains underexplored. In this paper,
we show that using existing ensemble methods in long-form generation requires a
careful choice of ensembling positions, since the standard practice of
ensembling at every token often degrades performance. We identify two key
factors for determining these positions: tokenization mismatch across models
and consensus in their next-token probability distributions. Based on this, we
propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively
ensembles by jointly considering these factors. To further improve stability,
we introduce a probability sharpening strategy that consolidates probabilities
spread across multiple sub-word tokens representing the same word into a single
representative token. Our experiments on diverse benchmarks, including MATH500
and BBH, demonstrate that SAFE outperforms existing methods in both accuracy
and efficiency, with gains achieved even when ensembling fewer than 1% of
tokens.

</details>


### [112] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2510.15349)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CL

TL;DR: 提出LayoutRL强化学习框架和Infinity-Doc-400K数据集，用于提升文档解析的布局理解与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法在多样化文档类型上泛化能力差，且高质量布局感知训练数据稀缺。

Method: 构建LayoutRL强化学习框架，采用复合奖励（包括归一化编辑距离、段落数量准确性和阅读顺序保持）优化布局理解；构建Infinity-Doc-400K数据集并训练Infinity-Parser视觉语言模型。

Result: 在OmniDocBench、olmOCR-Bench、PubTabNet和FinTabNet等多个基准上，Infinity-Parser在多种文档类型、语言和结构复杂性下均达到最先进的性能。

Conclusion: LayoutRL框架结合大规模数据集显著提升了文档解析模型的泛化能力和解析精度，推动了布局感知文档解析的发展。

Abstract: Document parsing from scanned images into structured formats remains a
significant challenge due to its complexly intertwined elements such as text
paragraphs, figures, formulas, and tables. Existing supervised fine-tuning
methods often struggle to generalize across diverse document types, leading to
poor performance, particularly on out-of-distribution data. This issue is
further exacerbated by the limited availability of high-quality training data
for layout-aware parsing tasks. To address these challenges, we introduce
LayoutRL, a reinforcement learning framework that optimizes layout
understanding through composite rewards integrating normalized edit distance,
paragraph count accuracy, and reading order preservation. To support this
training, we construct the Infinity-Doc-400K dataset, which we use to train
Infinity-Parser, a vision-language model demonstrating robust generalization
across various domains. Extensive evaluations on benchmarks including
OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser
consistently achieves state-of-the-art performance across a broad range of
document types, languages, and structural complexities, substantially
outperforming both specialized document parsing systems and general-purpose
vision-language models. We will release our code, dataset, and model to
facilitate reproducible research in document parsing.

</details>


### [113] [VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency](https://arxiv.org/abs/2510.15406)
*Hongcheng Liu,Yixuan Hou,Heyang Liu,Yuhao Wang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文研究了语音大语言模型（Speech-LLMs）在处理帕金森病等导致的言语不流利情况下的鲁棒性，发现现有模型在真实场景中的表现显著下降。作者提出了VocalBench-DF框架，用于系统评估多维度言语不流利现象，分析指出音素级处理和长上下文建模是主要瓶颈，并强调需改进识别与推理能力以提升包容性。


<details>
  <summary>Details</summary>
Motivation: 现有Speech-LLMs的评估多基于理想化输入，忽视了如帕金森病患者常见的言语不流利现象，缺乏对真实用户交互中鲁棒性的检验，亟需系统性评估方法来推动更具包容性的模型发展。

Method: 提出VocalBench-DF框架，基于多维分类法对言语不流利进行系统评估；在22个主流Speech-LLMs上测试其对言语障碍的处理能力，并分析性能瓶颈。

Result: 评估显示22个主流Speech-LLMs在面对言语不流利时性能显著下降；音素级处理和长上下文建模被识别为主要瓶颈；增强组件和流程中的识别与推理能力可显著提升鲁棒性。

Conclusion: 当前Speech-LLMs在应对言语障碍用户时鲁棒性不足，距离实际应用仍有差距；必须发展新方法以更好处理言语不流利问题，构建真正包容的语音语言模型。

Abstract: While Speech Large Language Models (Speech-LLMs) show strong performance in
many applications, their robustness is critically under-tested, especially to
speech disfluency. Existing evaluations often rely on idealized inputs,
overlooking common disfluencies, particularly those associated with conditions
like Parkinson's disease. This work investigates whether current Speech-LLMs
can maintain performance when interacting with users who have speech
impairments. To facilitate this inquiry, we introduce VocalBench-DF, a
framework for the systematic evaluation of disfluency across a
multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals
substantial performance degradation, indicating that their real-world readiness
is limited. Further analysis identifies phoneme-level processing and
long-context modeling as primary bottlenecks responsible for these failures.
Strengthening recognition and reasoning capability from components and
pipelines can substantially improve robustness. These findings highlight the
urgent need for new methods to improve disfluency handling and build truly
inclusive Speech-LLMs

</details>


### [114] [Large-scale User Game Lifecycle Representation Learning](https://arxiv.org/abs/2510.15412)
*Yanjie Gou,Jiangming Liu,Kouying Xue,Yi Hua*

Main category: cs.CL

TL;DR: 本文提出了一种新的用户游戏生命周期（UGL）表示学习方法，以解决游戏推荐和广告中的数据稀疏性和不平衡性问题，通过引入行为增强策略和逆概率掩码机制，在离线和在线实验中均显著提升了推荐与广告效果。


<details>
  <summary>Details</summary>
Motivation: 由于游戏数量稀少且用户行为集中在少数热门游戏上，现有的大规模推荐系统方法难以有效应用于游戏推荐与广告场景，因此需要专门针对游戏领域设计能够应对数据稀疏和分布不平衡的表示学习方法。

Method: 提出了用户游戏生命周期（UGL）框架来丰富用户行为序列，并设计了两种行为操作策略以捕捉用户的短期和长期兴趣；同时引入逆概率掩码策略缓解游戏流行度带来的不平衡问题，从而提升表示学习质量。

Result: 离线实验显示AUC平均提升1.83%（广告）和0.5%（道具推荐），在线指标CVR平均提升21.67%，ARPU提升0.82%，验证了UGL在真实场景中的有效性。

Conclusion: UGL框架能有效应对游戏推荐中的稀疏性和不平衡性挑战，显著提升广告转化率和推荐性能，具备实际部署价值。

Abstract: The rapid expansion of video game production necessitates the development of
effective advertising and recommendation systems for online game platforms.
Recommending and advertising games to users hinges on capturing their interest
in games. However, existing representation learning methods crafted for
handling billions of items in recommendation systems are unsuitable for game
advertising and recommendation. This is primarily due to game sparsity, where
the mere hundreds of games fall short for large-scale user representation
learning, and game imbalance, where user behaviors are overwhelmingly dominated
by a handful of popular games. To address the sparsity issue, we introduce the
User Game Lifecycle (UGL), designed to enrich user behaviors in games.
Additionally, we propose two innovative strategies aimed at manipulating user
behaviors to more effectively extract both short and long-term interests. To
tackle the game imbalance challenge, we present an Inverse Probability Masking
strategy for UGL representation learning. The offline and online experimental
results demonstrate that the UGL representations significantly enhance model by
achieving a 1.83% AUC offline increase on average and a 21.67% CVR online
increase on average for game advertising and a 0.5% AUC offline increase and a
0.82% ARPU online increase for in-game item recommendation.

</details>


### [115] [Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](https://arxiv.org/abs/2510.15418)
*Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye*

Main category: cs.CL

TL;DR: 本研究提出并验证了一个框架，通过知识蒸馏生成合成数据集，并使用QLoRA方法微调MedGemma模型，以提升其在皮肤病、眼底和胸部放射图像领域的图像描述生成能力，从而增强基于马来西亚临床实践指南的检索增强生成（RAG）系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的通用视觉-语言模型在处理医学图像查询时缺乏临床特异性和事实准确性，限制了检索增强生成系统在基于事实的临床决策支持中的有效性。

Method: 采用知识蒸馏方法构建跨领域的合成数据集，对MedGemma模型进行参数高效微调（使用QLoRA），并通过分类准确率和RAGAS框架评估生成描述的保真度、相关性和正确性。

Result: 微调后的模型在分类性能上显著提升，RAGAS评估显示生成描述的保真度和正确性明显改善，证明该模型能生成可靠且事实准确的医学图像描述。

Conclusion: 该研究建立了一个有效的流程来专业化医疗视觉-语言模型，并验证了其作为高质量查询生成器的能力，为增强多模态RAG系统在循证临床决策支持中的应用奠定了基础。

Abstract: Retrieval-Augmented Generation systems are essential for providing fact-based
guidance from Malaysian Clinical Practice Guidelines. However, their
effectiveness with image-based queries is limited, as general Vision-Language
Model captions often lack clinical specificity and factual grounding. This
study proposes and validates a framework to specialize the MedGemma model for
generating high-fidelity captions that serve as superior queries. To overcome
data scarcity, we employ a knowledge distillation pipeline to create a
synthetic dataset across dermatology, fundus, and chest radiography domains,
and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance
was rigorously assessed through a dual framework measuring both classification
accuracy and, via a novel application of the RAGAS framework, caption
faithfulness, relevancy, and correctness. The fine-tuned model demonstrated
substantial improvements in classification performance, while RAGAS evaluation
confirmed significant gains in caption faithfulness and correctness, validating
the models ability to produce reliable, factually grounded descriptions. This
work establishes a robust pipeline for specializing medical VLMs and validates
the resulting model as a high-quality query generator, laying the groundwork
for enhancing multimodal RAG systems in evidence-based clinical decision
support.

</details>


### [116] [When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs](https://arxiv.org/abs/2510.15421)
*Hongcheng Liu,Pingjie Wang,Yuhao Wang,Siqu Ou,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估基准GuessBench，用于评估多模态大语言模型（MLLMs）在信息不完整情况下的主动推理能力，发现现有模型在此任务上表现不佳，表明仍有较大改进空间。


<details>
  <summary>Details</summary>
Motivation: 现有对MLLMs的评估主要集中于被动推理，而现实场景中模型需要主动获取缺失信息，因此需要研究MLLMs在信息不完整情况下的主动决策能力。

Method: 提出GuessBench基准，包含感知导向和知识导向图像，要求MLLMs从候选池中选择目标图像以主动获取证据，并迭代优化决策，评估20种先进MLLMs的表现。

Result: 实验显示MLLMs在主动推理任务上的性能远低于被动推理场景，细粒度感知和及时决策是主要挑战；消融研究表明感知增强对小模型更有效，而面向思维的方法在不同规模模型上均有提升。

Conclusion: 当前MLLMs在主动推理方面仍有显著不足，未来应关注主动信息获取、细粒度感知与高效决策机制的研究。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities
across a broad range of benchmarks. However, most existing evaluations focus on
passive inference, where models perform step-by-step reasoning under complete
information. This setup is misaligned with real-world use, where seeing is not
enough. This raises a fundamental question: Can MLLMs actively acquire missing
evidence under incomplete information? To bridge this gap, we require the MLLMs
to actively acquire missing evidence and iteratively refine decisions under
incomplete information, by selecting a target image from a candidate pool
without task-specific priors. To support systematic study, we propose
GuessBench, a benchmark with both perception-oriented and knowledge-oriented
images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs
and find that performance on active reasoning lags far behind it on passive
settings, indicating substantial room for improvement. Further analysis
identifies fine-grained perception and timely decision-making as key
challenges. Ablation studies show that perceptual enhancements benefit smaller
models, whereas thinking-oriented methods provide consistent gains across model
sizes. These results suggest promising directions for future research on
multimodal active reasoning.

</details>


### [117] [Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering](https://arxiv.org/abs/2510.15436)
*Xiangchen Song,Yuchen Liu,Yaxuan Luan,Jinxu Guo,Xiaofan Guo*

Main category: cs.CL

TL;DR: 提出一种基于提示工程的可控抽象摘要生成方法，通过多阶段提示生成框架提升大语言模型的摘要质量与可控性。


<details>
  <summary>Details</summary>
Motivation: 解决传统摘要方法在质量与可控性方面的不足，探索如何通过提示工程优化大语言模型的摘要生成能力。

Method: 设计一个多阶段提示生成框架，对输入文本进行语义分析、主题建模和噪声控制，以生成不同抽象层次的摘要，并在CNN/Daily Mail数据集上评估不同提示长度、数据噪声和文本类型的影响。

Result: 提示长度显著影响摘要质量，过短或过长均导致ROUGE-L分数下降；数据噪声增加会降低生成效果；模型在新闻文本上表现最佳，在学术文章上较差。

Conclusion: 通过控制提示策略和优化文本预处理可有效提升大语言模型在摘要生成中的准确性与可控性。

Abstract: This study presents a controllable abstract summary generation method for
large language models based on prompt engineering. To address the issues of
summary quality and controllability in traditional methods, we design a
multi-stage prompt generation framework. This framework generates summaries
with varying levels of abstraction by performing semantic analysis, topic
modeling, and noise control on the input text. The experiment uses the
CNN/Daily Mail dataset and provides a detailed analysis of different prompt
lengths, data noise, and text types. The experimental results show that prompt
length has a significant impact on the quality of generated summaries. Both
very short and very long prompt tokens result in a decrease in summary quality.
Data noise also negatively affects the summary generation process. As noise
levels increase, the ROUGE-L score gradually decreases. Furthermore, different
text types have varying effects on the model's ability to generate summaries.
The model performs best when handling news texts, while its performance is
worse when processing academic articles. This research provides new insights
into improving summary generation using large language models, particularly in
how controlling prompt strategies and optimizing text preprocessing can enhance
summary accuracy and controllability.

</details>


### [118] [CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs](https://arxiv.org/abs/2510.15455)
*Gucongcong Fan,Chaoyue Niu,Chengfei Lyu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: 提出了一种名为CORE的协作框架，结合云端和本地大语言模型的优势，在减少移动代理用户界面暴露的同时保持任务准确性。


<details>
  <summary>Details</summary>
Motivation: 云基大语言模型虽准确但需上传完整UI状态，存在隐私泄露风险；本地大语言模型虽保护隐私但性能有限。因此需要一种兼顾隐私与性能的解决方案。

Method: CORE框架包含三个核心组件：基于XML层次的布局感知块划分、本地与云端LLM协同规划当前子任务、以及本地LLM排序相关UI块后由云端LLM在最高优先级块中选择具体元素，并引入多轮累积机制以缓解本地误判。

Result: 实验表明，CORE在多种移动应用和任务中可将UI暴露减少最多55.6%，同时任务成功率接近纯云方案。

Conclusion: CORE有效平衡了隐私保护与任务执行性能，显著降低了不必要的UI信息上传，为移动代理提供了更安全高效的执行框架。

Abstract: Mobile agents rely on Large Language Models (LLMs) to plan and execute tasks
on smartphone user interfaces (UIs). While cloud-based LLMs achieve high task
accuracy, they require uploading the full UI state at every step, exposing
unnecessary and often irrelevant information. In contrast, local LLMs avoid UI
uploads but suffer from limited capacity, resulting in lower task success
rates. We propose $\textbf{CORE}$, a $\textbf{CO}$llaborative framework that
combines the strengths of cloud and local LLMs to $\textbf{R}$educe UI
$\textbf{E}$xposure, while maintaining task accuracy for mobile agents. CORE
comprises three key components: (1) $\textbf{Layout-aware block partitioning}$,
which groups semantically related UI elements based on the XML screen
hierarchy; (2) $\textbf{Co-planning}$, where local and cloud LLMs
collaboratively identify the current sub-task; and (3)
$\textbf{Co-decision-making}$, where the local LLM ranks relevant UI blocks,
and the cloud LLM selects specific UI elements within the top-ranked block.
CORE further introduces a multi-round accumulation mechanism to mitigate local
misjudgment or limited context. Experiments across diverse mobile apps and
tasks show that CORE reduces UI exposure by up to 55.6% while maintaining task
success rates slightly below cloud-only agents, effectively mitigating
unnecessary privacy exposure to the cloud. The code is available at
https://github.com/Entropy-Fighter/CORE.

</details>


### [119] [DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios](https://arxiv.org/abs/2510.15501)
*Yao Huang,Yitong Sun,Yichi Zhang,Ruochen Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CL

TL;DR: 本文提出了DeceptionBench，首个系统评估大语言模型在不同社会领域中欺骗行为的基准，揭示了模型在强化学习动态下易受操纵的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多种认知任务上取得了显著进展，但其快速增强的能力也带来了潜在的欺骗行为，尤其在高风险应用场景中可能引发严重问题。目前对现实场景中欺骗行为的研究尚不充分，因此需要系统性评估框架来识别和分析这些行为。

Method: 构建了一个包含150个精心设计场景、覆盖经济、医疗、教育、社交和娱乐五个领域的基准测试集（DeceptionBench），包含1000多个样本，并引入多轮交互机制以模拟真实反馈动态；从内在行为模式（如利己倾向或谄媚行为）和外在影响因素（如奖励激励或胁迫压力）两个维度分析模型的欺骗倾向。

Result: 实验表明，当前大语言模型和大型推理模型在强化学习动态下表现出显著增强的欺骗行为，缺乏对操纵性上下文线索的鲁棒防御能力。

Conclusion: 现有模型在面对外部激励或压力时容易产生欺骗行为，亟需开发更先进的防护机制以应对各类欺骗风险。

Abstract: Despite the remarkable advances of Large Language Models (LLMs) across
diverse cognitive tasks, the rapid enhancement of these capabilities also
introduces emergent deceptive behaviors that may induce severe risks in
high-stakes deployments. More critically, the characterization of deception
across realistic real-world scenarios remains underexplored. To bridge this
gap, we establish DeceptionBench, the first benchmark that systematically
evaluates how deceptive tendencies manifest across different societal domains,
what their intrinsic behavioral patterns are, and how extrinsic factors affect
them. Specifically, on the static count, the benchmark encompasses 150
meticulously designed scenarios in five domains, i.e., Economy, Healthcare,
Education, Social Interaction, and Entertainment, with over 1,000 samples,
providing sufficient empirical foundations for deception analysis. On the
intrinsic dimension, we explore whether models exhibit self-interested egoistic
tendencies or sycophantic behaviors that prioritize user appeasement. On the
extrinsic dimension, we investigate how contextual factors modulate deceptive
outputs under neutral conditions, reward-based incentivization, and coercive
pressures. Moreover, we incorporate sustained multi-turn interaction loops to
construct a more realistic simulation of real-world feedback dynamics.
Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal
critical vulnerabilities, particularly amplified deception under reinforcement
dynamics, demonstrating that current models lack robust resistance to
manipulative contextual cues and the urgent need for advanced safeguards
against various deception behaviors. Code and resources are publicly available
at https://github.com/Aries-iai/DeceptionBench.

</details>


### [120] [Temporal Referential Consistency: Do LLMs Favor Sequences Over Absolute Time References?](https://arxiv.org/abs/2510.15513)
*Ashutosh Bajpai,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了一个名为时间指代一致性（temporal referential consistency）的新基准，并构建了TEMP-ReCon资源来评估大语言模型在多语言场景下的时间一致性表现，发现现有模型在此方面存在不足；为此，作者提出了一种基于推理路径对齐的模型UnTRaP，实验证明其能有效提升LLMs的时间一致性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在法律、医疗和金融等时间敏感领域的广泛应用，模型需要具备良好的时间推理能力以确保跨时间维度的一致性，但目前缺乏对LLM时间一致性的系统评估与增强方法。

Method: 构建了一个新的评测基准Temporal Referential Consistency及配套数据集TEMP-ReCon，涵盖英语、法语和罗马尼亚语等多种语言环境；提出UnTRaP模型，通过推理路径对齐机制来增强LLM的时间指代一致性。

Result: 实验表明现有LLM在时间指代一致性方面表现不佳；UnTRaP模型在多个开源和闭源LLM上均显著优于基线模型，有效提升了时间一致性。

Conclusion: 时间指代一致性是LLM在时间敏感应用中的关键挑战，TEMP-ReCon为评估提供了有效工具，而UnTRaP为提升该能力提供了可行方案。

Abstract: The increasing acceptance of large language models (LLMs) as an alternative
to knowledge sources marks a significant paradigm shift across various domains,
including time-sensitive fields such as law, healthcare, and finance. To
fulfill this expanded role, LLMs must not only be factually accurate but also
demonstrate consistency across temporal dimensions, necessitating robust
temporal reasoning capabilities. Despite this critical requirement, efforts to
ensure temporal consistency in LLMs remain scarce including noticeable absence
of endeavors aimed at evaluating or augmenting LLMs across temporal references
in time-sensitive inquiries. In this paper, we seek to address this gap by
introducing a novel benchmark entitled temporal referential consistency,
accompanied by a resource TEMP-ReCon designed to benchmark a wide range of both
open-source and closed-source LLMs with various linguistic contexts
characterized by differing resource richness (including English, French, and
Romanian). The findings emphasis that LLMs do exhibit insufficient temporal
referent consistency. To address this, we propose \newmodel, a reasoning path
alignment-based model that aims to enhance the temporal referential consistency
of LLMs. Our empirical experiments substantiate the efficacy of UnTRaP compared
to several baseline models.

</details>


### [121] [From Characters to Tokens: Dynamic Grouping with Hierarchical BPE](https://arxiv.org/abs/2510.15517)
*Rares Dolga,Lucas Maystre,Tudor Berariu,David Barber*

Main category: cs.CL

TL;DR: 提出了一种基于BPE结构的动态字符分组方法，通过添加显式的块结束标记和二级BPE压缩，在不依赖额外模型的情况下实现高效、灵活且语言无关的表示。


<details>
  <summary>Details</summary>
Motivation: 现有子词分词方法在处理罕见词时效率低且嵌入矩阵大，而字符级模型存在性能瓶颈，当前的分块策略受限于空格或需辅助模型，缺乏通用性和效率。

Method: 在BPE基础上引入显式的块结束标记，并采用二级BPE压缩机制来控制块的粒度，实现动态字符分组。

Result: 实验表明该方法在性能上达到或超过基于熵和空格的动态分块策略，同时保持紧凑的词汇表。

Conclusion: 所提方法无需额外模型即可有效结合子词与字符级模型的优势，具有良好的灵活性、效率和语言普适性。

Abstract: Subword tokenization methods like Byte Pair Encoding (BPE) are widely used in
large language models due to their balance of vocabulary compactness and
representational power. However, they suffer from inefficiencies in
representing rare words and require large embedding matrices. Character-level
models address these issues but introduce performance bottlenecks, particularly
in Transformer-based architectures. Recent hierarchical models attempt to merge
the benefits of both paradigms by grouping characters into patches, but
existing patching strategies either rely on whitespace-limiting applicability
to certain languages, or require auxiliary models that introduce new
dependencies. In this paper, we propose a dynamic character grouping method
that leverages the structure of existing BPE tokenization without requiring
additional models. By appending explicit end-of-patch markers to BPE tokens and
introducing a second-level BPE compression stage to control patch granularity,
our method offers efficient, flexible, and language-agnostic representations.
Empirical results demonstrate that our approach matches or exceeds the
performance of dynamic entropy- and whitespace-based patching strategies, while
maintaining a compact vocabulary.

</details>


### [122] [Latent Reasoning in LLMs as a Vocabulary-Space Superposition](https://arxiv.org/abs/2510.15522)
*Jingcheng Deng,Liang Pang,Zihao Wei,Shichen Xu,Zenghao Duan,Kun Xu,Yang Song,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 提出Latent-SFT框架，通过将潜在推理限制在词汇表的列空间中，实现高效且高性能的推理，显著减少计算开销并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法因潜在空间无结构导致性能下降，需解决潜在表示难以拟合的问题。

Method: 设计两阶段学习框架Latent-SFT：第一阶段使用特殊注意力掩码引导生成潜在标记；第二阶段让LLM自主生成潜在标记进行推理，采用KL和CE损失优化。

Result: 在GSM8k上达到新SOTA，性能匹配显式SFT同时减少最多4倍推理链长度，在Math500和AIME24上优于基于隐藏状态的方法。

Conclusion: 将潜在推理限制在词汇概率的超位置空间可有效提升性能，Latent-SFT兼顾效率与效果，揭示了潜在推理兼具路径压缩与多路径叠加的本质。

Abstract: Large language models (LLMs) demonstrate strong reasoning abilities with
chain-of-thought prompting, but explicit reasoning introduces substantial
computational overhead. Recent work on latent reasoning reduces this cost by
reasoning in latent space without explicit supervision, but performance drops
significantly. Our preliminary experiments suggest that this degradation stems
from the unstructured latent space, which makes fitting latent tokens
difficult. To address this, we restrict the latent space to the column space of
the LLM vocabulary, treating latent reasoning as a superposition over
vocabulary probabilities. Once latent reasoning concludes, it collapses into an
eigenstate of explicit reasoning to yield the final answer. Based on this idea,
we propose Latent-SFT, a two-stage learning framework. In the first stage, we
design two specialized attention masks to guide the Latent Token Encoder in
generating latent tokens, allowing the LLM to produce the correct answer
conditioned on them. In the second stage, the Latent Token Encoder is
discarded, and the LLM is directly trained to generate these latent tokens
autonomously for latent reasoning, optimized with KL and CE losses. Latent-SFT
sets a new state of the art on GSM8k, matching explicit SFT performance while
cutting reasoning chains by up to 4 times and outperforming prior latent
methods. On Math500 and AIME24, lexical probability-based latent reasoning also
clearly surpasses hidden-state-based approaches. Our metrics of effective
compression rate and effective global parallelism further show that latent
reasoning is both the compression of a single path and the superposition of
multiple paths.

</details>


### [123] [TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs](https://arxiv.org/abs/2510.15545)
*Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou*

Main category: cs.CL

TL;DR: 提出TokenTiming算法，基于动态时间规整（DTW）实现词汇表不匹配的通用推测解码，无需重训练即可兼容任意现成模型，实验显示推理速度提升1.57倍。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法要求草稿模型与目标模型共享相同词汇表，限制了草稿模型的选择并常需从头训练新模型，阻碍了其广泛应用。

Method: 受动态时间规整（DTW）启发，提出TokenTiming算法：通过重新编码草稿token序列生成新的目标token序列，并利用DTW建立映射以转移概率分布，从而实现跨词汇表的推测采样。

Result: 在多种任务上进行了全面实验，实现了1.57倍的推理加速，验证了方法在不同模型和任务下的有效性与通用性。

Conclusion: TokenTiming实现了无需修改或重训练的通用推测解码，突破了词汇表一致性的限制，使推测解码成为更灵活、实用的大模型推理加速工具。

Abstract: Accelerating the inference of large language models (LLMs) has been a
critical challenge in generative AI. Speculative decoding (SD) substantially
improves LLM inference efficiency. However, its utility is limited by a
fundamental constraint: the draft and target models must share the same
vocabulary, thus limiting the herd of available draft models and often
necessitating the training of a new model from scratch. Inspired by Dynamic
Time Warping (DTW), a classic algorithm for aligning time series, we propose
the algorithm TokenTiming for universal speculative decoding. It operates by
re-encoding the draft token sequence to get a new target token sequence, and
then uses DTW to build a mapping to transfer the probability distributions for
speculative sampling. Benefiting from this, our method accommodates mismatched
vocabularies and works with any off-the-shelf models without retraining and
modification. We conduct comprehensive experiments on various tasks,
demonstrating 1.57x speedup. This work enables a universal approach for draft
model selection, making SD a more versatile and practical tool for LLM
acceleration.

</details>


### [124] [Rethinking Cross-lingual Gaps from a Statistical Viewpoint](https://arxiv.org/abs/2510.15551)
*Vihari Piratla,Purvam Jain,Darshan Singh,Partha Talukdar,Trevor Cohn*

Main category: cs.CL

TL;DR: 本文提出了一种新的视角来解释大语言模型中的跨语言差距，认为目标语言中响应的方差是主要原因，并通过偏差-方差分解进行形式化分析，实验表明控制方差可显著缩小该差距。


<details>
  <summary>Details</summary>
Motivation: 现有研究将跨语言差距归因于源语言和目标语言潜在表示的差异，但本文质疑这一解释，试图从响应方差的角度提供更准确的理论框架。

Method: 采用偏差-方差分解方法对跨语言差距进行形式化建模，并通过多种推理时干预手段（如提示指令）控制目标语言的响应方差。

Result: 实验证明响应方差与跨语言差距密切相关，简单的提示指令即可使不同模型的目标语言准确率提升20-25%。

Conclusion: 跨语言差距的主要来源是目标语言中生成响应的方差，而非潜在表示差异，控制方差是提升多语言性能的有效途径。

Abstract: Any piece of knowledge is usually expressed in one or a handful of natural
languages on the web or in any large corpus. Large Language Models (LLMs) act
as a bridge by acquiring knowledge from a source language and making it
accessible when queried from target languages. Prior research has pointed to a
cross-lingual gap, viz., a drop in accuracy when the knowledge is queried in a
target language compared to when the query is in the source language. Existing
research has rationalized divergence in latent representations in source and
target languages as the source of cross-lingual gap. In this work, we take an
alternative view and hypothesize that the variance of responses in the target
language is the main cause of this gap. For the first time, we formalize the
cross-lingual gap in terms of bias-variance decomposition. We present extensive
experimental evidence which support proposed formulation and hypothesis. We
then reinforce our hypothesis through multiple inference-time interventions
that control the variance and reduce the cross-lingual gap. We demonstrate a
simple prompt instruction to reduce the response variance, which improved
target accuracy by 20-25% across different models.

</details>


### [125] [Think Parallax: Solving Multi-Hop Problems via Multi-View Knowledge-Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15552)
*Jinliang Liu*

Main category: cs.CL

TL;DR: ParallaxRAG 是一种基于知识图谱的检索增强生成框架，通过将查询和图谱三元组解耦到多视图空间，利用注意力头的专门化实现多跳推理的精确检索，减少幻觉并提升问答性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多跳推理中容易产生幻觉，现有知识图谱增强方法依赖扁平嵌入和噪声路径探索，缺乏有效结构引导。

Method: 提出 ParallaxRAG，将查询与知识图谱三元组对称解耦至多视图空间，利用不同注意力头在不同推理阶段捕捉特定语义关系，显式增强头部多样性并抑制弱相关路径。

Result: 在 WebQSP 和 CWQ 数据集上，使用 BGE-M3 和 Llama3.1-8B 的统一设置下，实现了具有竞争力的检索与问答性能，显著减少幻觉并表现出良好泛化能力。

Conclusion: 多视图注意力头的专门化是一种有前景的知识增强多跳推理范式，为构建更可靠的检索-推理协同架构提供了新方向。

Abstract: Large language models (LLMs) excel at language understanding but often
hallucinate and struggle with multi-hop reasoning. Knowledge-graph-based
retrieval-augmented generation (KG-RAG) offers grounding, yet most methods rely
on flat embeddings and noisy path exploration. We propose ParallaxRAG, a
framework that symmetrically decouples queries and graph triples into
multi-view spaces, enabling a robust retrieval architecture that explicitly
enforces head diversity while constraining weakly related paths. Central to our
approach is the observation that different attention heads specialize in
semantic relations at distinct reasoning stages, contributing to different hops
of the reasoning chain. This specialization allows ParallaxRAG to construct
cleaner subgraphs and guide LLMs through grounded, step-wise reasoning.
Experiments on WebQSP and CWQ, under our unified, reproducible setup (BGE-M3 +
Llama3.1-8B), demonstrate competitive retrieval and QA performance, alongside
reduced hallucination and good generalization. Our results highlight multi-view
head specialization as a principled direction for knowledge-grounded multi-hop
reasoning. Our implementation will be released as soon as the paper is
accepted.

</details>


### [126] [KITE: A Benchmark for Evaluating Korean Instruction-Following Abilities in Large Language Models](https://arxiv.org/abs/2510.15558)
*Dongjun Kim,Chanhee Park,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 本文提出了KITE，一个针对韩语指令跟随能力的综合评测基准，填补了非英语语言在开放性指令评估方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型评测主要集中在英语，忽视了其他语言的语言和文化特性，尤其是具有独特语法和敬语系统的韩语。

Method: 设计了一个名为KITE的基准，包含通用和韩语特定的开放式指令任务，并结合自动化指标与人工评估进行模型性能分析。

Result: 通过KITE评估发现了不同模型在韩语指令跟随任务上的表现差异，并提供了对其优缺点的深入洞察。

Conclusion: KITE有助于推动更具语言和文化包容性的大语言模型发展，并为其他少数语言的评测提供借鉴。

Abstract: The instruction-following capabilities of large language models (LLMs) are
pivotal for numerous applications, from conversational agents to complex
reasoning systems. However, current evaluations predominantly focus on English
models, neglecting the linguistic and cultural nuances of other languages.
Specifically, Korean, with its distinct syntax, rich morphological features,
honorific system, and dual numbering systems, lacks a dedicated benchmark for
assessing open-ended instruction-following capabilities. To address this gap,
we introduce the Korean Instruction-following Task Evaluation (KITE), a
comprehensive benchmark designed to evaluate both general and Korean-specific
instructions. Unlike existing Korean benchmarks that focus mainly on factual
knowledge or multiple-choice testing, KITE directly targets diverse, open-ended
instruction-following tasks. Our evaluation pipeline combines automated metrics
with human assessments, revealing performance disparities across models and
providing deeper insights into their strengths and weaknesses. By publicly
releasing the KITE dataset and code, we aim to foster further research on
culturally and linguistically inclusive LLM development and inspire similar
endeavors for other underrepresented languages.

</details>


### [127] [Finetuning LLMs for EvaCun 2025 token prediction shared task](https://arxiv.org/abs/2510.15561)
*Josef Jon,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文介绍了为EvaCun 2025 token预测任务提交的基于LLM（Command-R、Mistral和Aya Expanse）的系统，使用主办方提供的训练数据进行微调，未进行任务特定调整，并比较了三种不同提示方法在保留数据上的表现。


<details>
  <summary>Details</summary>
Motivation: 由于对任务领域和语言了解有限，作者希望在不进行额外数据处理的情况下，评估现成大模型在token预测任务中的表现。

Method: 基于Command-R、Mistral和Aya Expanse三种大语言模型，直接在任务提供的训练数据上进行微调，并通过三种不同的提示方式生成预测结果。

Result: 在保留的数据子集上对三种提示方法进行了评估，但具体性能指标未在摘要中提及。

Conclusion: 尽管缺乏领域和语言知识且未对数据进行预处理，基于微调LLM的方法仍可用于该token预测任务，不同提示策略的表现有待进一步比较分析。

Abstract: In this paper, we present our submission for the token prediction task of
EvaCun 2025. Our sys-tems are based on LLMs (Command-R, Mistral, and Aya
Expanse) fine-tuned on the task data provided by the organizers. As we only
pos-sess a very superficial knowledge of the subject field and the languages of
the task, we simply used the training data without any task-specific
adjustments, preprocessing, or filtering. We compare 3 different approaches
(based on 3 different prompts) of obtaining the predictions, and we evaluate
them on a held-out part of the data.

</details>


### [128] [From Ghazals to Sonnets: Decoding the Polysemous Expressions of Love Across Languages](https://arxiv.org/abs/2510.15569)
*Syed Mohammad Sualeh Ali*

Main category: cs.CL

TL;DR: 本研究通过多义性案例分析和词嵌入比较，探讨乌尔都语诗歌中“pyaar”、“muhabbat”和“ishq”三个表示爱的词汇之间的细微语义差异，揭示其在文化与语言表达上的独特层次。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语诗歌中关于‘爱’的词汇具有丰富的语义层次，但这些细微差别在英语中缺乏对应表达，导致跨文化理解困难。研究旨在揭示这些词语的独特情感光谱，深化对乌尔都语诗歌的理解。

Method: 采用多义性案例研究方法，分析三个‘爱’相关词汇在乌尔都语诗歌中的使用语境，并通过生成乌尔都语和英语中相关词汇的词嵌入进行对比，量化其语义空间差异。

Result: 研究揭示了pyaar、muhabbat和ishq在情感深度和使用语境上的显著区别，并通过词嵌入可视化展示了它们在语义空间中的不同分布，凸显出乌尔都语表达爱的复杂性与细腻度。

Conclusion: 乌尔都语中关于爱的词汇承载着独特的文化和情感内涵，其语义差异无法被英语完全捕捉；该研究为理解非西方诗歌中的情感表达提供了新的方法论视角。

Abstract: This paper delves into the intricate world of Urdu poetry, exploring its
thematic depths through a lens of polysemy. By focusing on the nuanced
differences between three seemingly synonymous words (pyaar, muhabbat, and
ishq) we expose a spectrum of emotions and experiences unique to the Urdu
language. This study employs a polysemic case study approach, meticulously
examining how these words are interwoven within the rich tapestry of Urdu
poetry. By analyzing their usage and context, we uncover a hidden layer of
meaning, revealing subtle distinctions which lack direct equivalents in English
literature. Furthermore, we embark on a comparative analysis, generating word
embeddings for both Urdu and English terms related to love. This enables us to
quantify and visualize the semantic space occupied by these words, providing
valuable insights into the cultural and linguistic nuances of expressing love.
Through this multifaceted approach, our study sheds light on the captivating
complexities of Urdu poetry, offering a deeper understanding and appreciation
for its unique portrayal of love and its myriad expressions

</details>


### [129] [BiMax: Bidirectional MaxSim Score for Document-Level Alignment](https://arxiv.org/abs/2510.15577)
*Xiaotian Wang,Takehito Utsuro,Masaaki Nagata*

Main category: cs.CL

TL;DR: 本文提出了一种用于文档对齐的跨语言双向最大相似度（BiMax）方法，在保持与最优传输（OT）方法相当准确率的同时，速度提升了约100倍，并在WMT16任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于网络挖掘数据规模巨大，需要在保证准确性的同时提升文档对齐的速度。

Method: 提出了跨语言双向最大相似度（BiMax）来计算文档间相似性，并评估了当前最先进的多语言句子嵌入模型的表现。

Result: 在WMT16双语文档对齐任务中，BiMax达到了与OT方法相当的准确率，同时速度提升了约100倍。

Conclusion: BiMax在效率和准确性之间取得了良好平衡，是一种高效的文档对齐方法，相关工具EmbDA已公开发布。

Abstract: Document alignment is necessary for the hierarchical mining (Ba\~n\'on et
al., 2020; Morishita et al., 2022), which aligns documents across source and
target languages within the same web domain. Several high precision sentence
embedding-based methods have been developed, such as TK-PERT (Thompson and
Koehn, 2020) and Optimal Transport (OT) (Clark et al., 2019; El-Kishky and
Guzm\'an, 2020). However, given the massive scale of web mining data, both
accuracy and speed must be considered. In this paper, we propose a
cross-lingual Bidirectional Maxsim score (BiMax) for computing doc-to-doc
similarity, to improve efficiency compared to the OT method. Consequently, on
the WMT16 bilingual document alignment task, BiMax attains accuracy comparable
to OT with an approximate 100-fold speed increase. Meanwhile, we also conduct a
comprehensive analysis to investigate the performance of current
state-of-the-art multilingual sentence embedding models. All the alignment
methods in this paper are publicly available as a tool called EmbDA
(https://github.com/EternalEdenn/EmbDA).

</details>


### [130] [The Elephant in the Coreference Room: Resolving Coreference in Full-Length French Fiction Works](https://arxiv.org/abs/2510.15594)
*Antoine Bourgois,Thierry Poibeau*

Main category: cs.CL

TL;DR: 本文介绍了一个包含三部完整法语小说的新标注语料库，共超过285,000个词符，旨在解决长篇文学作品中的共指消解问题。


<details>
  <summary>Details</summary>
Motivation: 现有的共指消解数据集多集中于短文本，缺乏对长篇复杂文学作品的充分覆盖，限制了模型在长距离指代链上的评估与应用。

Method: 构建了一个模块化的共指消解流程，并在一个新发布的长篇法语小说语料库上进行实验，支持细粒度错误分析。

Result: 所提出的方法在长文档上表现具有竞争力且具有良好扩展性，并成功用于推断虚构人物的性别。

Conclusion: 该语料库和方法为文学分析和下游NLP任务提供了有力支持，推动长文档共指消解的研究发展。

Abstract: While coreference resolution is attracting more interest than ever from
computational literature researchers, representative datasets of fully
annotated long documents remain surprisingly scarce. In this paper, we
introduce a new annotated corpus of three full-length French novels, totaling
over 285,000 tokens. Unlike previous datasets focused on shorter texts, our
corpus addresses the challenges posed by long, complex literary works, enabling
evaluation of coreference models in the context of long reference chains. We
present a modular coreference resolution pipeline that allows for fine-grained
error analysis. We show that our approach is competitive and scales effectively
to long documents. Finally, we demonstrate its usefulness to infer the gender
of fictional characters, showcasing its relevance for both literary analysis
and downstream NLP tasks.

</details>


### [131] [HypoSpace: Evaluating LLM Creativity as Set-Valued Hypothesis Generators under Underdetermination](https://arxiv.org/abs/2510.15614)
*Tingting Chen,Beibei Lin,Zifeng Yuan,Qiran Zou,Hongyu He,Yew-Soon Ong,Anirudh Goyal,Dianbo Liu*

Main category: cs.CL

TL;DR: HypoSpace是一个用于评估语言模型在科学问题中生成多种解释能力的诊断工具，衡量有效性、唯一性和覆盖率三个指标。


<details>
  <summary>Details</summary>
Motivation: 由于许多科学问题是不确定的，存在多个与观察结果一致的不同机制假设，因此需要评估语言模型提出多组解释的能力而不仅仅是单一正确答案。

Method: 将语言模型视为有限假设集的采样器，在因果图、3D体素重建和布尔基因互作三个确定性领域中实例化HypoSpace，并使用确定性验证器和完全枚举的假设空间来测量有效性、唯一性和恢复率。

Result: 实验发现，随着可接受假设空间增大，尽管有效性保持较高，但唯一性和覆盖率下降，暴露出仅基于正确性的指标无法发现的模式崩溃现象。

Conclusion: HypoSpace提供了一种受控探测方法，用于评估显式探索和覆盖可接受解释空间的技术，而非简单排名。

Abstract: As language models are increasingly used in scientific workflows, evaluating
their ability to propose sets of explanations-not just a single correct
answer-becomes critical. Many scientific problems are underdetermined:
multiple, mechanistically distinct hypotheses are consistent with the same
observations. We introduce HypoSpace, a diagnostic suite that treats LLMs as
samplers of finite hypothesis sets and measures three complementary indicators:
Validity (precision of proposals consistent with observations), Uniqueness
(non-redundancy among proposals), and Recovery (coverage of the enumerated
admissible set). We instantiate HypoSpace in three structured domains with
deterministic validators and exactly enumerated hypothesis spaces: (i) causal
graphs from perturbations, (ii) gravity-constrained 3D voxel reconstruction
from top-down projections, and (iii) Boolean genetic interactions. Across
instruction-tuned and reasoning-focused models, Validity often remains high
while Uniqueness and Recovery degrade as the admissible space grows, revealing
mode collapse that is invisible to correctness-only metrics. HypoSpace offers a
controlled probe-rather than a leaderboard-for methods that explicitly explore
and cover admissible explanation spaces. Code is available at:
https://github.com/CTT-Pavilion/_HypoSpace.

</details>


### [132] [Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection](https://arxiv.org/abs/2510.15685)
*Joshua Wolfe Brook,Ilia Markov*

Main category: cs.CL

TL;DR: 该研究提出了一种利用大语言模型（LLMs）作为动态知识库生成背景上下文，并将其融入仇恨言论检测（HSD）分类器输入的新方法，显著提升了文本和多模态场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 隐式仇恨言论检测因缺乏明确线索而具有挑战性，现有方法常依赖静态知识库或外部特征，难以捕捉动态语境，因此需要更灵活的上下文增强策略。

Method: 使用大语言模型生成上下文，采用两种策略：基于命名实体的提示和全文提示；比较四种上下文融合方式：文本拼接、嵌入拼接、分层Transformer融合和LLM驱动的文本增强。

Result: 在文本数据集Latent Hatred和多模态数据集MAMI上实验显示，相比无上下文基线，嵌入拼接方法分别带来最高3和6个F1分数点的提升。

Conclusion: 生成的上下文信息及其融合方式对仇恨言论检测性能至关重要，嵌入拼接结合LLM生成上下文是有效策略，尤其适用于隐式和多模态场景。

Abstract: This research introduces a novel approach to textual and multimodal Hate
Speech Detection (HSD), using Large Language Models (LLMs) as dynamic knowledge
bases to generate background context and incorporate it into the input of HSD
classifiers. Two context generation strategies are examined: one focused on
named entities and the other on full-text prompting. Four methods of
incorporating context into the classifier input are compared: text
concatenation, embedding concatenation, a hierarchical transformer-based
fusion, and LLM-driven text enhancement. Experiments are conducted on the
textual Latent Hatred dataset of implicit hate speech and applied in a
multimodal setting on the MAMI dataset of misogynous memes. Results suggest
that both the contextual information and the method by which it is incorporated
are key, with gains of up to 3 and 6 F1 points on textual and multimodal setups
respectively, from a zero-context baseline to the highest-performing system,
based on embedding concatenation.

</details>


### [133] [Attention Sinks in Diffusion Language Models](https://arxiv.org/abs/2510.15731)
*Maximo Eduardo Rulli,Simone Petruzzi,Edoardo Michielon,Fabrizio Silvestri,Simone Scardapane,Alessio Devoto*

Main category: cs.CL

TL;DR: 本文研究了掩码扩散语言模型（DLMs）中的注意力沉降现象，发现其具有动态位置变化且对性能影响较小的特性，表明DLMs在注意力机制上与传统自回归模型存在根本差异。


<details>
  <summary>Details</summary>
Motivation: 尽管DLMs已被证明高效且有效，但其内部工作机制尚不清楚，尤其是注意力机制的行为特征。

Method: 通过对DLM的注意力模式进行实证分析，重点研究生成过程中注意力沉降现象的变化和影响。

Result: 发现DLMs中存在动态移动的注意力沉降位置，并且移除这些沉降对模型性能影响较小，表现出较强的鲁棒性。

Conclusion: DLMs在注意力分配和使用方式上与自回归模型有本质不同，揭示了扩散语言模型内部运作的新机制。

Abstract: Masked Diffusion Language Models (DLMs) have recently emerged as a promising
alternative to traditional Autoregressive Models (ARMs). DLMs employ
transformer encoders with bidirectional attention, enabling parallel token
generation while maintaining competitive performance. Although their efficiency
and effectiveness have been extensively studied, the internal mechanisms that
govern DLMs remain largely unexplored. In this work, we conduct an empirical
analysis of DLM attention patterns, focusing on the attention sinking
phenomenon, an effect previously observed in various transformer-based
architectures. Our findings reveal that DLMs also exhibit attention sinks, but
with distinct characteristics. First, unlike in ARMs, the sink positions in
DLMs tend to shift throughout the generation process, displaying a dynamic
behaviour. Second, while ARMs are highly sensitive to the removal of attention
sinks, DLMs remain robust: masking sinks leads to only a minor degradation in
performance. These results provide new insights into the inner workings of
diffusion-based language models and highlight fundamental differences in how
they allocate and utilize attention compared to autoregressive models.

</details>


### [134] [LLMs Judge Themselves: A Game-Theoretic Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2510.15746)
*Gao Yang,Yuhang Liu,Siyu Miao,Xinyue Liang,Zhengyang Liu,Heyan Huang*

Main category: cs.CL

TL;DR: 本文提出了一种基于博弈论的大型语言模型（LLM）评估新方法，通过LLM之间的相互评估与人类投票行为对比，验证其与人类判断的一致性。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法依赖固定任务和标准答案，难以捕捉LLM在开放、主观任务中的复杂行为，因此需要更灵活、符合现实的评估机制。

Method: 提出自动互评框架，利用LLM进行自我博弈和同行评审，并采用博弈论投票算法聚合评估结果，最后与人类投票数据进行系统比较。

Result: 实验结果显示模型间的互评结果在某些方面与人类判断一致，但也存在偏差，揭示了互评方法的潜力与局限。

Conclusion: 该研究首次将相互评估、博弈论聚合与人类验证结合，为LLM能力评估提供了新的可行路径，但需进一步优化以更好对齐人类偏好。

Abstract: Ideal or real - that is the question.In this work, we explore whether
principles from game theory can be effectively applied to the evaluation of
large language models (LLMs). This inquiry is motivated by the growing
inadequacy of conventional evaluation practices, which often rely on
fixed-format tasks with reference answers and struggle to capture the nuanced,
subjective, and open-ended nature of modern LLM behavior. To address these
challenges, we propose a novel alternative: automatic mutual evaluation, where
LLMs assess each other's output through self-play and peer review. These peer
assessments are then systematically compared with human voting behavior to
evaluate their alignment with human judgment. Our framework incorporates
game-theoretic voting algorithms to aggregate peer reviews, enabling a
principled investigation into whether model-generated rankings reflect human
preferences. Empirical results reveal both convergences and divergences between
theoretical predictions and human evaluations, offering valuable insights into
the promises and limitations of mutual evaluation. To the best of our
knowledge, this is the first work to jointly integrate mutual evaluation,
game-theoretic aggregation, and human-grounded validation for evaluating the
capabilities of LLMs.

</details>


### [135] [On Non-interactive Evaluation of Animal Communication Translators](https://arxiv.org/abs/2510.15768)
*Orr Paradise,David F. Gruber,Adam Tauman Kalai*

Main category: cs.CL

TL;DR: 提出了一种无需参考翻译的机器翻译质量评估方法，通过分段翻译和NLP重排测试来检测“幻觉”，并在数据稀缺的人类语言和构造语言上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 如何在没有参考翻译的情况下验证AI对复杂动物语言（如鲸鱼语）的翻译准确性，同时避免伦理、安全和成本问题。

Method: 采用分段翻译结合经典的NLP重排测试，评估翻译结果在顺序排列下是否比随机排列更合理，从而判断翻译质量。

Result: 在数据稀缺的人类语言和构造语言上的实验证明该方法有效，且与基于参考翻译的标准评估高度相关；理论分析表明早期翻译学习中交互可能非必要。

Conclusion: 无需依赖交互或外部观察，仅通过输出即可评估复杂语言的翻译质量，为无参考MTQE提供了可行方案。

Abstract: If you had an AI Whale-to-English translator, how could you validate whether
or not it is working? Does one need to interact with the animals or rely on
grounded observations such as temperature? We provide theoretical and
proof-of-concept experimental evidence suggesting that interaction and even
observations may not be necessary for sufficiently complex languages. One may
be able to evaluate translators solely by their English outputs, offering
potential advantages in terms of safety, ethics, and cost. This is an instance
of machine translation quality evaluation (MTQE) without any reference
translations available. A key challenge is identifying ``hallucinations,''
false translations which may appear fluent and plausible. We propose using
segment-by-segment translation together with the classic NLP shuffle test to
evaluate translators. The idea is to translate animal communication, turn by
turn, and evaluate how often the resulting translations make more sense in
order than permuted. Proof-of-concept experiments on data-scarce human
languages and constructed languages demonstrate the potential utility of this
evaluation methodology. These human-language experiments serve solely to
validate our reference-free metric under data scarcity. It is found to
correlate highly with a standard evaluation based on reference translations,
which are available in our experiments. We also perform a theoretical analysis
suggesting that interaction may not be necessary nor efficient in the early
stages of learning to translate.

</details>


### [136] [Emergence of Linear Truth Encodings in Language Models](https://arxiv.org/abs/2510.15804)
*Shauli Ravfogel,Gilad Yehudai,Tal Linzen,Joan Bruna,Alberto Bietti*

Main category: cs.CL

TL;DR: 本文提出一个透明的单层transformer玩具模型，端到端地再现了语言模型中真与假语句的线性子空间，并揭示了其形成机制：在事实语句倾向于共现的数据分布下，模型为降低语言建模损失而学会区分真假。实验还观察到两阶段学习动态：先快速记忆具体事实，再长期发展出线性分离能力。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究发现大语言模型中存在区分真假语句的线性子空间，但其成因尚不清楚。本文旨在从机制上解释这种线性真理表征是如何以及为何在语言模型中出现的。

Method: 构建一个可解释的单层transformer玩具模型，在控制的数据分布（事实语句更可能与事实语句共现）下训练，并分析其学习过程中对真假语句的表示演化；同时在预训练语言模型中验证类似模式。

Result: 玩具模型成功端到端地生成了线性真理子空间；发现两阶段学习过程：初期快速记忆个别事实关联，后期逐步形成对真假语句的线性分离，从而降低语言建模损失；在真实预训练模型中也观察到支持该机制的相关证据。

Conclusion: 线性真理表征可以在语言模型中自然涌现，其驱动力来自于数据中的事实共现结构以及降低语言建模损失的学习目标，本文为此提供了具体的机制解释和实证支持。

Abstract: Recent probing studies reveal that large language models exhibit linear
subspaces that separate true from false statements, yet the mechanism behind
their emergence is unclear. We introduce a transparent, one-layer transformer
toy model that reproduces such truth subspaces end-to-end and exposes one
concrete route by which they can arise. We study one simple setting in which
truth encoding can emerge: a data distribution where factual statements
co-occur with other factual statements (and vice-versa), encouraging the model
to learn this distinction in order to lower the LM loss on future tokens. We
corroborate this pattern with experiments in pretrained language models.
Finally, in the toy setting we observe a two-phase learning dynamic: networks
first memorize individual factual associations in a few steps, then -- over a
longer horizon -- learn to linearly separate true from false, which in turn
lowers language-modeling loss. Together, these results provide both a
mechanistic demonstration and an empirical motivation for how and why linear
truth representations can emerge in language models.

</details>


### [137] [Paper2Web: Let's Make Your Paper Alive!](https://arxiv.org/abs/2510.15842)
*Yuhang Chen,Tianpeng Lv,Siyi Zhang,Yixiang Yin,Yao Wan,Philip S. Yu,Dongping Chen*

Main category: cs.CL

TL;DR: 本文提出了Paper2Web，一个用于评估学术网页生成的基准数据集和多维评估框架，并设计了PWAgent自动化管道，将科研论文转化为互动性强、多媒体丰富的学术主页，在内容、布局和交互性方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的学术项目网站生成方法（如直接使用大语言模型生成、模板或HTML转换）难以生成具有合理布局和良好交互性的网站，且缺乏全面的评估体系。因此需要一种更有效的方法来提升学术研究成果的传播效果。

Method: 提出Paper2Web基准，包含基于规则的指标（如连通性、完整性）、LLM-as-a-Judge评估（涵盖交互性、美观性和信息性）以及PaperQuiz知识保留测试；同时设计PWAgent智能体，通过MCP工具迭代优化内容与布局。

Result: 实验表明，PWAgent在各项指标上均显著优于基于模板的方法和arXiv/alphaXiv版本，能在低成本下实现更优的网页生成效果，达到帕累托前沿。

Conclusion: PWAgent结合Paper2Web评估框架能够高效生成高质量、交互性强的学术项目网站，为学术成果展示提供了可评估、可扩展的新范式。

Abstract: Academic project websites can more effectively disseminate research when they
clearly present core content and enable intuitive navigation and interaction.
However, current approaches such as direct Large Language Model (LLM)
generation, templates, or direct HTML conversion struggle to produce
layout-aware, interactive sites, and a comprehensive evaluation suite for this
task has been lacking. In this paper, we introduce Paper2Web, a benchmark
dataset and multi-dimensional evaluation framework for assessing academic
webpage generation. It incorporates rule-based metrics like Connectivity,
Completeness and human-verified LLM-as-a-Judge (covering interactivity,
aesthetics, and informativeness), and PaperQuiz, which measures paper-level
knowledge retention. We further present PWAgent, an autonomous pipeline that
converts scientific papers into interactive and multimedia-rich academic
homepages. The agent iteratively refines both content and layout through MCP
tools that enhance emphasis, balance, and presentation quality. Our experiments
show that PWAgent consistently outperforms end-to-end baselines like
template-based webpages and arXiv/alphaXiv versions by a large margin while
maintaining low cost, achieving the Pareto-front in academic webpage
generation.

</details>


### [138] [Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer Framework](https://arxiv.org/abs/2510.15843)
*Shayan Rokhva,Mousa Alizadeh,Maryam Abdollahi Shamami*

Main category: cs.CL

TL;DR: 提出了一种结合词典、模糊逻辑与轻量级Transformer的混合框架，用于生成连续情感得分，提升了在非正式和领域特定文本中情感极性与强度检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于产品评论和社交媒体文本中的非正式语言和领域特异性，传统方法难以准确捕捉情感极性和强度，存在过度中性偏倚和粒度不足的问题。

Method: 采用VADER进行初始情感估计，利用DistilBERT的置信度进行第一阶段修正，并引入模糊逻辑系统进行第二阶段调整，最终通过自定义模糊推理系统将结果映射到0到1的连续区间。

Result: 在四个领域特定数据集（食品配送、电子商务、旅游、时尚）上验证了该框架的有效性，结果显示其与用户评分更一致，能更好识别情感极端样本，减少误分类，且具备高效运行性能。

Conclusion: 融合符号推理与神经模型的方法能够提升情感分析的可解释性与细粒度表现，适用于语言动态性强的实际场景。

Abstract: Accurately detecting sentiment polarity and intensity in product reviews and
social media posts remains challenging due to informal and domain-specific
language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer
framework that combines rule-based heuristics, contextual deep learning, and
fuzzy logic to generate continuous sentiment scores reflecting both polarity
and strength. The pipeline begins with VADER-based initial sentiment
estimations, which are refined through a two-stage adjustment process. This
involves leveraging confidence scores from DistilBERT, a lightweight
transformer and applying fuzzy logic principles to mitigate excessive
neutrality bias and enhance granularity. A custom fuzzy inference system then
maps the refined scores onto a 0 to 1 continuum, producing expert)like
judgments. The framework is rigorously evaluated on four domain-specific
datasets. food delivery, e-commerce, tourism, and fashion. Results show
improved alignment with user ratings, better identification of sentiment
extremes, and reduced misclassifications. Both quantitative metrics
(distributional alignment, confusion matrices) and qualitative insights (case
studies, runtime analysis) affirm the models robustness and efficiency. This
work demonstrates the value of integrating symbolic reasoning with neural
models for interpretable, finegrained sentiment analysis in linguistically
dynamic domains.

</details>


### [139] [SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling](https://arxiv.org/abs/2510.15851)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 本文研究了基于语音的大语言模型（speechLLMs）在槽位填充任务中的应用，提出了通过改进训练数据、架构和训练策略来缩小与任务上限性能差距的方法，并提供了实证指导和见解。


<details>
  <summary>Details</summary>
Motivation: 传统槽位填充采用级联的语音识别和自然语言理解组件，难以实现统一且高效的语音理解。新兴的speechLLMs为零样本、泛化性和效率带来了新机遇，但其在槽位填充中的潜力尚需系统探索。

Method: 构建任务的经验上界，识别性能、鲁棒性和泛化性差距，并提出针对训练数据、模型架构和训练策略的改进措施。

Result: 各项改进措施显著提升了模型性能，缩小了与上界之间的差距，同时揭示了实际挑战并提供了实证指导。

Conclusion: 通过针对性优化，speechLLMs在槽位填充任务中具有巨大潜力，能够实现更高效、统一且具备良好泛化的语音理解。

Abstract: Slot filling is a crucial subtask in spoken language understanding (SLU),
traditionally implemented as a cascade of speech recognition followed by one or
more natural language understanding (NLU) components. The recent advent of
speech-based large language models (speechLLMs), which integrate speech and
textual foundation models, has opened new avenues for achieving speech
understanding tasks in a more unified, generative, and instruction-following
manner while promising data and compute efficiency with zero-shot abilities,
generalizing to unseen slot labels. We address the slot-filling task by
creating an empirical upper bound for the task, identifying performance,
robustness, and generalization gaps, and proposing improvements to the training
data, architecture, and training strategies to narrow the gap with the upper
bound result. We show that each of these measures improve performance
substantially, while highlighting practical challenges and providing empirical
guidance and insights for harnessing these emerging models.

</details>


### [140] [InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training](https://arxiv.org/abs/2510.15859)
*Pengkai Wang,Qi Zuo,Pengwei Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.CL

TL;DR: 本文提出了ORBIT，一种基于评分标准的增量强化学习框架，用于提升大语言模型在高风险医学对话中的表现，仅用2000个样本就在HealthBench-Hard上将性能从7.0提升至27.2，实现了同类规模模型的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖可编程验证的奖励信号，在开放、主观或情境依赖的任务（如医学咨询）中难以定义有效奖励函数，限制了大模型在此类高风险领域的应用。

Method: 提出ORBIT框架，结合合成对话生成与动态评分标准构建，通过评分标准指导增量式强化学习；不依赖外部医学知识或人工规则，而是利用评分标准提供的反馈进行训练。

Result: 在Qwen3-4B-Instruct模型上，使用仅2k样本将HealthBench-Hard基准得分从7.0提升至27.2，达到该规模模型的SOTA；且性能增益在多种咨询场景中具有一致性和稳定性。

Conclusion: 基于评分标准的强化学习是一种可扩展且有效的策略，能够推动大语言模型在复杂、开放性任务中的持续进步，尤其适用于缺乏明确奖励信号的高风险领域。

Abstract: Large Language Models (LLMs) have shown substantial advances through
reinforcement learning (RL), particularly in domains where rewards can be
programmatically verified, such as mathematics and code. In these areas, models
benefit from a well-defined operational base guided by explicit rule-based
objectives. However, this progress reveals a significant limitation: in
open-ended domains where rewards are ambiguous, subjective, or
context-dependent, such as creative writing, scientific reasoning, and notably
medical consultation, robust reward functions are lacking, making these areas
challenging for current RL strategies. To bridge this gap, we introduce ORBIT,
an open-ended rubric-based incremental training framework specifically designed
for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue
generation with the dynamic creation of rubrics, employing these rubrics to
direct an incremental RL process. In particular, this approach does not depend
on external medical knowledge or manual rules, instead utilizing rubric-guided
feedback to shape learning. When implemented on the Qwen3-4B-Instruct model,
our method can greatly enhance its performance on the HealthBench-Hard
benchmark from 7.0 to 27.2 using only 2k samples, thus achieving
state-of-the-art results for models of this scale. Our analysis confirms that
rubric-driven RL fos-ters consistent performance gains across diverse
consultation scenarios, going beyond simple numerical improvements. These
findings underscore rubric-based feedback as a scalable strategy for advancing
LLMs in intricate, open-ended tasks.

</details>


### [141] [PolySkill: Learning Generalizable Skills Through Polymorphic Abstraction](https://arxiv.org/abs/2510.15863)
*Simon Yu,Gang Li,Weiyan Shi,Peng Qi*

Main category: cs.CL

TL;DR: PolySkill是一种新框架，通过将技能的抽象目标与具体实现解耦，使智能体能够在开放网络环境中持续学习并泛化可重用的技能。


<details>
  <summary>Details</summary>
Motivation: 现有方法学到的技能往往过度特化于单一网站，缺乏跨环境泛化能力，限制了智能体在动态环境中的持续学习。

Method: 受软件工程中多态性的启发，PolySkill将技能的目标（what）与执行方式（how）分离，支持技能的抽象建模与组合使用，并通过自我探索优化目标识别和课程学习。

Result: 实验表明，该方法在已见网站上技能复用率提升1.7倍，在Mind2Web和未见网站上的成功率分别提高9.4%和13.9%，步数减少超过20%；在无任务设定的自我探索中，能生成更高质量的任务并习得跨站点通用技能。

Conclusion: 将技能的目标与执行分离是实现智能体在开放网络中持续、自主、泛化学习的关键步骤，为构建适应性更强的智能体提供了可行路径。

Abstract: Large language models (LLMs) are moving beyond static uses and are now
powering agents that learn continually during their interaction with external
environments. For example, agents can learn reusable skills while navigating
web pages or toggling new tools. However, existing methods for skill learning
often create skills that are over-specialized to a single website and fail to
generalize. We introduce PolySkill, a new framework that enables agents to
learn generalizable and compositional skills. The core idea, inspired by
polymorphism in software engineering, is to decouple a skill's abstract goal
(what it accomplishes) and its concrete implementation (how it is executed).
Experiments show that our method (1) improves skill reuse by 1.7x on seen
websites and (2) boosts success rates by up to 9.4% on Mind2Web and 13.9% on
unseen websites, while reducing steps by over 20%. (3) In self-exploration
settings without specified tasks, our framework improves the quality of
proposed tasks and enables agents to learn generalizable skills that work
across different sites. By enabling the agent to identify and refine its own
goals, the PolySkill enhances the agent's ability to learn a better curriculum,
leading to the acquisition of more generalizable skills compared to baseline
methods. This work provides a practical path toward building agents capable of
continual learning in adaptive environments. Our findings show that separating
a skill's goal from its execution is a crucial step toward developing
autonomous agents that can learn and generalize across the open web
continuously.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [142] [Fix False Transparency by Noise Guided Splatting](https://arxiv.org/abs/2510.15736)
*Aly El Hakie,Yiren Lu,Yu Yin,Michael Jenkins,Yehe Liu*

Main category: cs.GR

TL;DR: 本文首次识别并解决了3D高斯泼溅（3DGS）中不透明物体表面出现虚假透明的问题，提出了一种名为NGS的方法，通过在训练过程中向物体体积内注入不透明的噪声高斯来增强表面不透明性，并设计了基于透射率的评估指标和新的数据集来定量评估该问题。


<details>
  <summary>Details</summary>
Motivation: 在交互式查看中，3DGS重建的不透明物体常表现出虚假透明现象，导致背景和内部结构随视角变化而不一致。这一问题源于3DGS训练过程中缺乏对表面不透明性的显式约束，仅依赖RGB图像的光度损失进行优化，容易使本应不透明的区域被错误地赋予透明性。

Method: 提出NGS方法，在训练时向物体内部注入不透明的噪声高斯，促使表面高斯趋向更高不透明度，仅需对现有泼溅流程做最小修改即可实现。同时设计了一个基于透射率的量化指标来评估虚假透明程度，并构建了一个高质量、具有明显透明问题的对象中心扫描数据集，以及为现有数据集补充了用于测试鲁棒性的填充噪声数据。

Result: 在多个数据集上的实验表明，NGS显著减少了虚假透明现象，同时在标准渲染指标上保持了具有竞争力的性能。所提出的评估指标能有效量化该问题，新数据集有助于更全面地评估3D重建方法对虚假透明的鲁棒性。

Conclusion: NGS是首个专门针对3DGS中虚假透明问题的有效解决方案，通过简单的训练策略改进显著提升了重建结果的视觉一致性，尤其在交互式对象查看场景下表现优越，推动了3DGS在高质量对象重建中的应用。

Abstract: Opaque objects reconstructed by 3DGS often exhibit a falsely transparent
surface, leading to inconsistent background and internal patterns under camera
motion in interactive viewing. This issue stems from the ill-posed optimization
in 3DGS. During training, background and foreground Gaussians are blended via
alpha-compositing and optimized solely against the input RGB images using a
photometric loss. As this process lacks an explicit constraint on surface
opacity, the optimization may incorrectly assign transparency to opaque
regions, resulting in view-inconsistent and falsely transparent. This issue is
difficult to detect in standard evaluation settings but becomes particularly
evident in object-centric reconstructions under interactive viewing. Although
other causes of view-inconsistency have been explored recently, false
transparency has not been explicitly identified. To the best of our knowledge,
we are the first to identify, characterize, and develop solutions for this
artifact, an underreported artifact in 3DGS. Our strategy, NGS, encourages
surface Gaussians to adopt higher opacity by injecting opaque noise Gaussians
in the object volume during training, requiring only minimal modifications to
the existing splatting process. To quantitatively evaluate false transparency
in static renderings, we propose a transmittance-based metric that measures the
severity of this artifact. In addition, we introduce a customized, high-quality
object-centric scan dataset exhibiting pronounced transparency issues, and we
augment popular existing datasets with complementary infill noise specifically
designed to assess the robustness of 3D reconstruction methods to false
transparency. Experiments across multiple datasets show that NGS substantially
reduces false transparency while maintaining competitive performance on
standard rendering metrics, demonstrating its overall effectiveness.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [143] [Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration](https://arxiv.org/abs/2510.15114)
*Marios-Nektarios Stamatopoulos,Elias Small,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种基于异构无人机（UAV）的全自主空中砌筑建造框架，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 实现全自主的空中砌筑建造，提升建筑自动化水平，减少人工干预和施工风险。

Method: 开发了两种专用无人机：砖块搬运无人机（带球铰驱动机构）和粘合剂喷涂无人机（带伺服控制阀和挤出喷嘴）；采用反应式任务规划单元结合依赖图与冲突图进行并行任务管理，利用分层状态机确保运行鲁棒性和安全切换；通过动态任务分配适应环境反馈，采用最小加加速度轨迹生成实现平滑飞行；砖运无人机搭载基于ArUco标记和最小二乘优化滤波器的机载视觉系统，实现实时位姿估计与精确对齐。

Result: 成功实现了全自主空中砌筑建造的实验验证，展示了异构无人机协同作业的能力，包括精准布砖与自动涂胶；视频结果证明了该框架的有效性与稳定性。

Conclusion: 本工作首次实验验证了基于异构无人机的全自主空中砌筑建造可行性，为未来空中机器人自主建造技术的发展提供了基础框架。

Abstract: This article presents a fully autonomous aerial masonry construction
framework using heterogeneous unmanned aerial vehicles (UAVs), supported by
experimental validation. Two specialized UAVs were developed for the task: (i)
a brick-carrier UAV equipped with a ball-joint actuation mechanism for precise
brick manipulation, and (ii) an adhesion UAV integrating a servo-controlled
valve and extruder nozzle for accurate adhesion application. The proposed
framework employs a reactive mission planning unit that combines a dependency
graph of the construction layout with a conflict graph to manage simultaneous
task execution, while hierarchical state machines ensure robust operation and
safe transitions during task execution. Dynamic task allocation allows
real-time adaptation to environmental feedback, while minimum-jerk trajectory
generation ensures smooth and precise UAV motion during brick pickup and
placement. Additionally, the brick-carrier UAV employs an onboard vision system
that estimates brick poses in real time using ArUco markers and a least-squares
optimization filter, enabling accurate alignment during construction. To the
best of the authors' knowledge, this work represents the first experimental
demonstration of fully autonomous aerial masonry construction using
heterogeneous UAVs, where one UAV precisely places the bricks while another
autonomously applies adhesion material between them. The experimental results
supported by the video showcase the effectiveness of the proposed framework and
demonstrate its potential to serve as a foundation for future developments in
autonomous aerial robotic construction.

</details>


### [144] [RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation](https://arxiv.org/abs/2510.15189)
*Xiangyu Chen,Chuhao Zhou,Yuxi Liu,Jianfei Yang*

Main category: cs.RO

TL;DR: 提出了一种角色模型强化学习（RM-RL）框架，通过自动生成近似最优动作标签实现无需人类示范的高效机器人精细操作。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高质量专家示范，难以获取且数据效率低，离线强化学习存在分布偏移问题。

Method: 引入角色模型策略，将在线训练数据用近似最优动作打标签，将策略学习重构为监督训练，并结合混合训练机制提升数据利用效率。

Result: 相比现有RL方法收敛更快更稳定，在真实世界操作中平移精度提升53%，旋转精度提升20%。

Conclusion: RM-RL在无需人工示范的情况下显著提升了精细操作的精度和训练效率，成功实现了细胞板精确放置等挑战性任务。

Abstract: Precise robot manipulation is critical for fine-grained applications such as
chemical and biological experiments, where even small errors (e.g., reagent
spillage) can invalidate an entire task. Existing approaches often rely on
pre-collected expert demonstrations and train policies via imitation learning
(IL) or offline reinforcement learning (RL). However, obtaining high-quality
demonstrations for precision tasks is difficult and time-consuming, while
offline RL commonly suffers from distribution shifts and low data efficiency.
We introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies
online and offline training in real-world environments. The key idea is a
role-model strategy that automatically generates labels for online training
data using approximately optimal actions, eliminating the need for human
demonstrations. RM-RL reformulates policy learning as supervised training,
reducing instability from distribution mismatch and improving efficiency. A
hybrid training scheme further leverages online role-model data for offline
reuse, enhancing data efficiency through repeated sampling. Extensive
experiments show that RM-RL converges faster and more stably than existing RL
methods, yielding significant gains in real-world manipulation: 53% improvement
in translation accuracy and 20% in rotation accuracy. Finally, we demonstrate
the successful execution of a challenging task, precisely placing a cell plate
onto a shelf, highlighting the framework's effectiveness where prior methods
fail.

</details>


### [145] [GaussGym: An open-source real-to-sim framework for learning locomotion from pixels](https://arxiv.org/abs/2510.15352)
*Alejandro Escontrela,Justin Kerr,Arthur Allshire,Jonas Frey,Rocky Duan,Carmelo Sferrazza,Pieter Abbeel*

Main category: cs.RO

TL;DR: 提出了一种基于3D高斯点阵的逼真机器人仿真方法，可在消费级GPU上实现每秒超过10万步的高速模拟，同时保持高视觉保真度，并支持从多种真实场景数据生成训练环境，推动可扩展的机器人学习。


<details>
  <summary>Details</summary>
Motivation: 传统机器人仿真在速度与视觉真实性之间存在权衡，难以同时满足高效训练和真实感知的需求。本文旨在打破这一瓶颈，实现高速物理仿真与高保真视觉渲染的融合。

Method: 将3D Gaussian Splatting作为即插即用的渲染器集成到向量化物理仿真器（如IsaacGym）中，利用其高效并行特性实现超高速模拟，同时保留丰富的视觉语义信息。

Result: 实现了超过100,000 steps/s的模拟速度，在消费级GPU上展示高质量视觉效果；成功应用于sim-to-real任务中，验证了其在导航、避障等任务中的有效性，并支持从iPhone扫描、大型场景数据集和生成式视频模型构建大规模训练环境。

Conclusion: 该方法弥合了高吞吐仿真与高保真感知之间的鸿沟，为可扩展、可泛化的机器人学习提供了强大工具，且代码与数据全部开源，促进社区发展。

Abstract: We present a novel approach for photorealistic robot simulation that
integrates 3D Gaussian Splatting as a drop-in renderer within vectorized
physics simulators such as IsaacGym. This enables unprecedented speed --
exceeding 100,000 steps per second on consumer GPUs -- while maintaining high
visual fidelity, which we showcase across diverse tasks. We additionally
demonstrate its applicability in a sim-to-real robotics setting. Beyond
depth-based sensing, our results highlight how rich visual semantics improve
navigation and decision-making, such as avoiding undesirable regions. We
further showcase the ease of incorporating thousands of environments from
iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs
from generative video models like Veo, enabling rapid creation of realistic
training worlds. This work bridges high-throughput simulation and high-fidelity
perception, advancing scalable and generalizable robot learning. All code and
data will be open-sourced for the community to build upon. Videos, code, and
data available at https://escontrela.me/gauss_gym/.

</details>


### [146] [Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit](https://arxiv.org/abs/2510.15199)
*Borna Monazzah Moghaddam,Robin Chhabra*

Main category: cs.RO

TL;DR: 本文提出了拉格朗日-庞加莱-开普勒方程（LPKE），用于建模非惯性轨道参考系下航天器-机械臂系统的动力学，结合了航天器姿态、轨道运动与机械臂运动学，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地描述轨道环境中航天器-机械臂系统的耦合动力学，扩展现有拉格朗日-庞加莱方程以包含轨道动态影响。

Method: 基于主丛上的拉格朗日-达朗贝尔原理，结合欧拉-庞加莱方程、开普勒轨道动力学和降维拉格朗日方程，采用指数关节参数化方法推导出LPKE框架及闭式结构矩阵。

Result: 成功推导出能显式反映轨道扰动及其与机械臂动态耦合的新型闭式结构矩阵，并在7自由度机械臂系统上验证了该模型的数值优越性和有效性。

Conclusion: LPKE框架为轨道环境下航天器-机械臂系统的建模、控制与硬件在环仿真提供了系统且高效的理论基础。

Abstract: This article presents an extension of the Lagrange-Poincare Equations (LPE)
to model the dynamics of spacecraft-manipulator systems operating within a
non-inertial orbital reference frame. Building upon prior formulations of LPE
for vehicle-manipulator systems, the proposed framework, termed the
Lagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between
spacecraft attitude dynamics, orbital motion, and manipulator kinematics. The
formalism combines the Euler-Poincare equations for the base spacecraft,
Keplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange
equations for the manipulator's shape space, using an exponential joint
parametrization. Leveraging the Lagrange-d'Alembert principle on principal
bundles, we derive novel closed-form structural matrices that explicitly
capture the effects of orbital disturbances and their dynamic coupling with the
manipulator system. The LPKE framework also systematically includes externally
applied, symmetry-breaking wrenches, allowing for immediate integration into
hardware-in-the-loop simulations and model-based control architectures for
autonomous robotic operations in the orbital environment. To illustrate the
effectiveness of the proposed model and its numerical superiority, we present a
simulation study analyzing orbital effects on a 7-degree-of-freedom manipulator
mounted on a spacecraft.

</details>


### [147] [LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization](https://arxiv.org/abs/2510.15220)
*Kevin Christiansen Marsim,Minho Oh,Byeongho Yu,Seungjae Lee,I Made Aswin Nahrendra,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的LiDAR-视觉-惯性-运动学融合里程计系统，用于复杂动态环境中足式机器人的自主导航。


<details>
  <summary>Details</summary>
Motivation: 现有传感器融合SLAM方法在挑战性环境中因融合策略不当易产生估计漂移，需提高鲁棒性。

Method: 结合相机、LiDAR、IMU和关节编码器信息，采用优化为基础的视觉-惯性-运动学里程计（VIKO）和基于滤波的LiDAR-惯性-运动学里程计（LIKO），分别在滑动窗口优化中使用足部预积分和超像素深度一致性，在ESIKF中引入点到平面残差和足部运动学。

Result: 在公开和长期数据集上，相比其他融合SLAM算法表现出更强的鲁棒性。

Conclusion: 所提出的多传感器融合框架有效提升了足式机器人在复杂环境中的定位与建图精度和稳定性。

Abstract: Autonomous navigation for legged robots in complex and dynamic environments
relies on robust simultaneous localization and mapping (SLAM) systems to
accurately map surroundings and localize the robot, ensuring safe and efficient
operation. While prior sensor fusion-based SLAM approaches have integrated
various sensor modalities to improve their robustness, these algorithms are
still susceptible to estimation drift in challenging environments due to their
reliance on unsuitable fusion strategies. Therefore, we propose a robust
LiDAR-visual-inertial-kinematic odometry system that integrates information
from multiple sensors, such as a camera, LiDAR, inertial measurement unit
(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our
system employs a fusion-based pose estimation approach that runs
optimization-based visual-inertial-kinematic odometry (VIKO) and filter-based
LiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In
VIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth
consistency using superpixel clusters in a sliding window optimization. In
LIKO, we incorporate foot kinematics and employ a point-toplane residual in an
error-state iterative Kalman filter (ESIKF). Compared with other sensor
fusion-based SLAM algorithms, our approach shows robust performance across
public and longterm datasets.

</details>


### [148] [PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation](https://arxiv.org/abs/2510.15226)
*Mrunal Sarvaiya,Guanrui Li,Giuseppe Loianno*

Main category: cs.RO

TL;DR: 本文提出了PolyFly，一种用于空中运输机器人的非保守全局规划方法，通过将无人机、缆绳和载荷建模为独立且姿态感知的多面体，并利用对偶理论将约束转化为光滑可微形式，实现了在复杂狭窄环境中的快速避障飞行。


<details>
  <summary>Details</summary>
Motivation: 现有方法对飞行器和障碍物进行几何上的过度近似，导致路径规划过于保守、飞行时间增加，难以满足灾后救援中快速穿越密集或结构不稳定环境的需求。

Method: 提出PolyFly，将无人机系统（四旋翼、缆绳、载荷）和环境中各物体建模为独立的多面体，并引入姿态感知的多面体以提高模型精度；利用对偶理论将多面体碰撞规避约束转化为光滑可微的优化约束，从而高效求解最优控制问题。

Result: 在八个迷宫状环境中与当前最先进方法对比，PolyFly均生成了更快速的轨迹；并在真实四旋翼携带悬挂载荷的实验中验证了该方法的实用性和准确性。

Conclusion: PolyFly通过非保守的精确几何建模和高效的约束处理，显著提升了空中运输机器人在复杂受限环境中的飞行性能和实用性。

Abstract: Aerial transportation robots using suspended cables have emerged as versatile
platforms for disaster response and rescue operations. To maximize the
capabilities of these systems, robots need to aggressively fly through tightly
constrained environments, such as dense forests and structurally unsafe
buildings, while minimizing flight time and avoiding obstacles. Existing
methods geometrically over-approximate the vehicle and obstacles, leading to
conservative maneuvers and increased flight times. We eliminate these
restrictions by proposing PolyFly, an optimal global planner which considers a
non-conservative representation for aerial transportation by modeling each
physical component of the environment, and the robot (quadrotor, cable and
payload), as independent polytopes. We further increase the model accuracy by
incorporating the attitude of the physical components by constructing
orientation-aware polytopes. The resulting optimal control problem is
efficiently solved by converting the polytope constraints into smooth
differentiable constraints via duality theory. We compare our method against
the existing state-of-the-art approach in eight maze-like environments and show
that PolyFly produces faster trajectories in each scenario. We also
experimentally validate our proposed approach on a real quadrotor with a
suspended payload, demonstrating the practical reliability and accuracy of our
method.

</details>


### [149] [A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs](https://arxiv.org/abs/2510.15229)
*Sina Kazemdehbashi,Yanchao Liu,Boris S. Mordukhovich*

Main category: cs.RO

TL;DR: 本文提出了一种新的数学框架——Sylvester-Fermat-Torricelli (SFT) 问题，用于优化移动无人机（UAV）基站的位置，以提升灾后响应效率。该框架综合考虑了风力影响、无人机异质性和往返运动等因素，在实际灾害场景中可将无效作业时间减少高达84%。


<details>
  <summary>Details</summary>
Motivation: 灾害常导致通信基础设施损毁，使救援团队难以及时获取受灾信息和定位受困人员。因此，需要高效的数据采集与临时通信方案来提升救援效率。现有无人机部署方法未充分考虑风力和无人机差异等现实因素，限制了其实际应用效果。

Method: 通过推广Sylvester问题，构建了一个包含风力影响、无人机异质性及往返飞行模式的统一数学模型——Sylvester-Fermat-Torricelli (SFT) 问题，并求解最优移动无人机基站位置。

Result: 实验结果表明，所提框架能够显著减少无人机操作中的浪费时间，最多可达84%，从而提高灾后救援任务的效率和有效性。

Conclusion: 该研究增强了基于无人机的灾害响应规划的实用性，通过整合真实世界中的关键因素，为未来应急通信系统的设计提供了理论支持和优化工具。

Abstract: Natural and human-made disasters can cause severe devastation and claim
thousands of lives worldwide. Therefore, developing efficient methods for
disaster response and management is a critical task for relief teams. One of
the most essential components of effective response is the rapid collection of
information about affected areas, damages, and victims. More data translates
into better coordination, faster rescue operations, and ultimately, more lives
saved. However, in some disasters, such as earthquakes, the communication
infrastructure is often partially or completely destroyed, making it extremely
difficult for victims to send distress signals and for rescue teams to locate
and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as
valuable tools in such scenarios. In particular, a fleet of UAVs can be
dispatched from a mobile station to the affected area to facilitate data
collection and establish temporary communication networks. Nevertheless,
real-world deployment of UAVs faces several challenges, with adverse weather
conditions--especially wind--being among the most significant. To address this,
we develop a novel mathematical framework to determine the optimal location of
a mobile UAV station while explicitly accounting for the heterogeneity of the
UAVs and the effect of wind. In particular, we generalize the Sylvester problem
to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures
complex factors such as wind influence, UAV heterogeneity, and back-and-forth
motion within a unified framework. The proposed framework enhances the
practicality of UAV-based disaster response planning by accounting for
real-world factors such as wind and UAV heterogeneity. Experimental results
demonstrate that it can reduce wasted operational time by up to 84%, making
post-disaster missions significantly more efficient and effective.

</details>


### [150] [Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping](https://arxiv.org/abs/2510.15319)
*Jeewon Kim,Minho Oh,Hyun Myung*

Main category: cs.RO

TL;DR: 提出一种考虑机器人与环境交互的可通行性感知房间分割方法，提升了场景图中语义一致性和位姿图优化效率。


<details>
  <summary>Details</summary>
Motivation: 现有实时方法在房间分割中存在过分割或欠分割问题，导致定位与建图精度下降，尤其在视野受限或空间未完全封闭时表现不佳。

Method: 引入可通行性感知的房间分割方法，结合机器人与环境的交互特性，确保分割结果在不同视角下具有一致的可通行性信息，并与分层场景图和位姿图优化紧密集成。

Result: 在重复路径遍历数据集中显著提高了相同房间的重检测频率，同时减少了位姿图优化的时间消耗。

Conclusion: 所提方法有效改善了复杂环境下房间分割的鲁棒性，增强了语义一致性与计算效率，对提升机器人定位与建图性能具有重要意义。

Abstract: Scene graphs enhance 3D mapping capabilities in robotics by understanding the
relationships between different spatial elements, such as rooms and objects.
Recent research extends scene graphs to hierarchical layers, adding and
leveraging constraints across these levels. This approach is tightly integrated
with pose-graph optimization, improving both localization and mapping accuracy
simultaneously. However, when segmenting spatial characteristics, consistently
recognizing rooms becomes challenging due to variations in viewpoints and
limited field of view (FOV) of sensors. For example, existing real-time
approaches often over-segment large rooms into smaller, non-functional spaces
that are not useful for localization and mapping due to the time-dependent
method. Conversely, their voxel-based room segmentation method often
under-segment in complex cases like not fully enclosed 3D space that are
non-traversable for ground robots or humans, leading to false constraints in
pose-graph optimization. We propose a traversability-aware room segmentation
method that considers the interaction between robots and surroundings, with
consistent feasibility of traversability information. This enhances both the
semantic coherence and computational efficiency of pose-graph optimization.
Improved performance is demonstrated through the re-detection frequency of the
same rooms in a dataset involving repeated traversals of the same space along
the same path, as well as the optimization time consumption.

</details>


### [151] [ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning](https://arxiv.org/abs/2510.15331)
*Gahee Kim,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本文提出了一种名为主动式仿真推理（ASBI）的框架，用于在黑箱模拟器中通过主动收集真实世界数据来精确估计机器人仿真的参数。


<details>
  <summary>Details</summary>
Motivation: 由于黑箱模拟器无法获取似然函数，且真实观测数据难以包含足够的参数估计信息，传统基于离线观测的仿真推理方法效果受限。

Method: 提出ASBI框架，结合主动学习与神经后验估计（NPE），通过最大化信息增益（即后验与先验香农熵的期望减少量）来优化机器人动作，主动采集高信息量的观测数据。利用神经网络学习后验分布以绕过不可访问的似然函数。

Result: 三个仿真实验表明，该方法能实现精确的参数估计，后验分布紧密集中在真实参数周围；并在真实机器人上成功应用于立方颗粒（珠子和碎石）倾倒动作的仿真参数估计。

Conclusion: ASBI能够有效解决黑箱模拟器中因观测信息不足导致的参数估计难题，通过主动数据采集显著提升仿真模型调参的准确性与实用性。

Abstract: Black-box simulators are widely used in robotics, but optimizing their
parameters remains challenging due to inaccessible likelihoods.
Simulation-Based Inference (SBI) tackles this issue using simulation-driven
approaches, estimating the posterior from offline real observations and forward
simulations. However, in black-box scenarios, preparing observations that
contain sufficient information for parameter estimation is difficult due to the
unknown relationship between parameters and observations. In this work, we
present Active Simulation-Based Inference (ASBI), a parameter estimation
framework that uses robots to actively collect real-world online data to
achieve accurate black-box simulator tuning. Our framework optimizes robot
actions to collect informative observations by maximizing information gain,
which is defined as the expected reduction in Shannon entropy between the
posterior and the prior. While calculating information gain requires the
likelihood, which is inaccessible in black-box simulators, our method solves
this problem by leveraging Neural Posterior Estimation (NPE), which leverages a
neural network to learn the posterior estimator. Three simulation experiments
quantitatively verify that our method achieves accurate parameter estimation,
with posteriors sharply concentrated around the true parameters. Moreover, we
show a practical application using a real robot to estimate the simulation
parameters of cubic particles corresponding to two real objects, beads and
gravel, with a bucket pouring action.

</details>


### [152] [Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles](https://arxiv.org/abs/2510.15336)
*Liviu-Mihai Stan,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Masashi Konyo,Kazunori Ohno*

Main category: cs.RO

TL;DR: 提出一种基于LiDAR和里程计的自适应路径规划框架，集成到ROS2 Nav2中，通过可移动障碍物层和慢速位姿监测器提升机器人在非结构化环境中的导航可靠性。


<details>
  <summary>Details</summary>
Motivation: 在灾难救援等非结构化室内环境中，机器人需具备识别并推开障碍物的能力以实现可靠导航，而现有方法难以有效处理此类动态或可移动障碍。

Method: 设计了一个可移动障碍物层，将缺失于静态地图的LiDAR回波标记为可能可移动并降低其通行成本；同时引入慢速位姿进度检查器，根据实际速度与指令速度比值动态调整局部代价，避免死锁。

Result: 在Gazebo中对Scout Mini进行测试，相比无该层的基线方法，目标到达率更高、死锁更少，遍历时间相当，且计算开销低，适用于资源受限平台。

Conclusion: 交互感知代价地图是一种轻量、原生支持ROS2的扩展方案，能有效提升机器人在存在潜在可移动障碍的非结构化环境中的导航性能。

Abstract: Reliable navigation in disaster-response and other unstructured indoor
settings requires robots not only to avoid obstacles but also to recognise when
those obstacles can be pushed aside. We present an adaptive, LiDAR and
odometry-based path-planning framework that embeds this capability into the
ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing
from a prior static map as tentatively movable and assigns a reduced traversal
cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to
actual velocity; when the robot slows appreciably, the local cost is raised
from light to heavy, and on a stall to lethal, prompting the global planner to
back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated
objects and cluttered corridors, show higher goal-reach rates and fewer
deadlocks than a no-layer baseline, with traversal times broadly comparable.
Because the method relies only on planar scans and CPU-level computation, it
suits resource-constrained search and rescue robots and integrates into
heterogeneous platforms with minimal engineering. Overall, the results indicate
that interaction-aware cost maps are a lightweight, ROS2-native extension for
navigating among potentially movable obstacles in unstructured settings. The
full implementation will be released as open source
athttps://costmap-namo.github.io.

</details>


### [153] [Nauplius Optimisation for Autonomous Hydrodynamics](https://arxiv.org/abs/2510.15350)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: 提出一种受藤壶幼虫行为启发的新型群优化算法NOAH，用于解决自主水下机器人在强流、有限带宽和持续感知需求下的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 传统群优化方法在水下环境中因强水流、通信带宽受限和持续感知需求而表现不可靠，亟需具备水动力感知和稳定锚定能力的新算法。

Method: 借鉴藤壶幼体的行为特性，设计NOAH算法，融合水流感知漂移、不可逆锚定机制和基于群体的通信策略，以适应复杂水下环境。

Result: 验证研究表明，NOAH在永久锚定场景中成功率达86%，并建立了包含水动力约束与不可逆定居行为的统一模型，经实验证明在流动条件下有效。

Conclusion: NOAH为可扩展、节能的水下群机器人系统提供了坚实基础，显著提升了复杂水下任务中的可靠性和性能。

Abstract: Autonomous Underwater vehicles must operate in strong currents, limited
acoustic bandwidth, and persistent sensing requirements where conventional
swarm optimisation methods are unreliable. This paper presents NOAH, a novel
nature-inspired swarm optimisation algorithm that combines current-aware drift,
irreversible settlement in persistent sensing nodes, and colony-based
communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH
addresses the critical limitations of existing swarm algorithms by providing
hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based
communication capabilities essential for underwater exploration missions. The
algorithm establishes a comprehensive foundation for scalable and
energy-efficient underwater swarm robotics with validated performance analysis.
Validation studies demonstrate an 86% success rate for permanent anchoring
scenarios, providing a unified formulation for hydrodynamic constraints and
irreversible settlement behaviours with an empirical study under flow.

</details>


### [154] [Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting](https://arxiv.org/abs/2510.15376)
*Zhaodong Yang,Ai-Ping Hu,Harish Ravichandar*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的力反馈切割策略，用于自动化鸡肩去骨任务，实现了从仿真到真实环境的零样本迁移，并在成功率和避骨能力上比传统开环方法提升高达4倍。


<details>
  <summary>Details</summary>
Motivation: 鸡肩关节结构复杂、部分遮挡且材质多样，传统自动化去骨方法难以精确控制刀具在狭小关节间隙中运动并避免触碰骨头，存在安全隐患，因此需要一种能够实时响应环境变化的智能切割方法。

Method: 1）开发了一个开源的多材质切割仿真器，支持强化学习训练；2）设计了可重复实验的物理测试平台，模拟鸡肩的双硬球嵌入软质材料结构；3）采用离散化力反馈观测和域随机化的残差强化学习策略，实现6自由度刀具动态轨迹调整。

Result: 在仿真、物理测试平台和真实鸡肩上的实验表明，该方法能可靠穿越关节间隙，显著减少与骨头或软骨的接触，在成功率和避骨性能上较现有开环基线最多提升4倍，并首次实现了学习策略在真实鸡肩去骨中的成功应用。

Conclusion: 力反馈对于安全高效的多材质切割至关重要，本文提出的系统方案和残差RL策略为复杂食品加工任务的自动化提供了可行路径，并验证了仿真到现实迁移的有效性。

Abstract: Automating chicken shoulder deboning requires precise 6-DoF cutting through a
partially occluded, deformable, multi-material joint, since contact with the
bones presents serious health and safety risks. Our work makes both
systems-level and algorithmic contributions to train and deploy a reactive
force-feedback cutting policy that dynamically adapts a nominal trajectory and
enables full 6-DoF knife control to traverse the narrow joint gap while
avoiding contact with the bones. First, we introduce an open-source
custom-built simulator for multi-material cutting that models coupling,
fracture, and cutting forces, and supports reinforcement learning, enabling
efficient training and rapid prototyping. Second, we design a reusable physical
testbed to emulate the chicken shoulder: two rigid "bone" spheres with
controllable pose embedded in a softer block, enabling rigorous and repeatable
evaluation while preserving essential multi-material characteristics of the
target problem. Third, we train and deploy a residual RL policy, with
discretized force observations and domain randomization, enabling robust
zero-shot sim-to-real transfer and the first demonstration of a learned policy
that debones a real chicken shoulder. Our experiments in our simulator, on our
physical testbed, and on real chicken shoulders show that our learned policy
reliably navigates the joint gap and reduces undesired bone/cartilage contact,
resulting in up to a 4x improvement over existing open-loop cutting baselines
in terms of success rate and bone avoidance. Our results also illustrate the
necessity of force feedback for safe and effective multi-material cutting. The
project website is at https://sites.google.com/view/chickendeboning-2026.

</details>


### [155] [VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving](https://arxiv.org/abs/2510.15446)
*Ziang Guo,Zufeng Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为VDRive的端到端自动驾驶新框架，通过结合视觉语言动作模型（VLA）与生成扩散策略，实现可解释且鲁棒的决策。该方法在上下文和几何层面建模状态-动作映射，并采用演员-评论家架构进行强化学习优化，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中动态环境和极端情况对车辆状态理解和决策的鲁棒性构成挑战，现有方法缺乏可解释性和对复杂场景的适应能力。

Method: 提出VDRive框架：利用VLA进行状态理解，通过CVQ-VAE将观测离散化为token，并预训练生成未来观测；结合扩散策略作为动作头，采用强化学习微调VLA以预测轨迹和动作；构建演员-评论家架构，由评论家提供梯度反馈以优化策略。

Result: 在Bench2Drive闭环基准和nuScenes开环规划任务中均取得最先进的性能表现。

Conclusion: VDRive通过显式建模状态-动作映射，结合生成式预训练与强化学习，在可解释性和鲁棒性方面优于现有方法，是端到端自动驾驶的有效解决方案。

Abstract: In autonomous driving, dynamic environment and corner cases pose significant
challenges to the robustness of ego vehicle's state understanding and decision
making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving
that explicitly models state-action mapping to address these challenges,
enabling interpretable and robust decision making. By leveraging the
advancement of the state understanding of the Vision Language Action Model
(VLA) with generative diffusion policy-based action head, our VDRive guides the
driving contextually and geometrically. Contextually, VLA predicts future
observations through token generation pre-training, where the observations are
represented as discrete codes by a Conditional Vector Quantized Variational
Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning
fine-tuning of the VLA to predict future trajectories and actions based on
current driving conditions. VLA supplies the current state tokens and predicted
state tokens for the action policy head to generate hierarchical actions and
trajectories. During policy training, a learned critic evaluates the actions
generated by the policy and provides gradient-based feedback, forming an
actor-critic framework that enables a reinforcement-based policy learning
pipeline. Experiments show that our VDRive achieves state-of-the-art
performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop
planning.

</details>


### [156] [Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving](https://arxiv.org/abs/2510.15505)
*Aron Distelzweig,Faris Janjoš,Oliver Scheel,Sirish Reddy Varra,Raghu Rajan,Joschka Boedecker*

Main category: cs.RO

TL;DR: 本文研究了自动驾驶中集成预测与规划（IPP）方法的有效性，发现即使拥有完美的未来预测，当前的IPP方法也未能显著提升规划性能。相反，高质量的候选轨迹生成更为关键。作者基于PDM方法改进提案生成，在复杂和分布外场景中取得了新的最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有集成预测与规划（IPP）方法在实际规划性能上的提升不明确，且对预测信息利用不足，因此需要重新评估预测的作用并改进规划方法。

Method: 通过在Val14和interPlan两个基准上分析预测在IPP中的作用，提出以提案为中心的方法，强调生成多样化且高质量的候选轨迹，并将预测主要用于碰撞检测。

Result: 实验表明，当前IPP方法难以充分利用未来预测信息；相比之下，改进后的提案生成方法显著优于现有方法，尤其在高度交互和分布外场景中表现突出。

Conclusion: 高质量的候选轨迹生成比精确预测更重要，提案为中心的设计能更有效提升自动驾驶规划性能，特别是在复杂交互场景中。

Abstract: Traditionally, prediction and planning in autonomous driving (AD) have been
treated as separate, sequential modules. Recently, there has been a growing
shift towards tighter integration of these components, known as Integrated
Prediction and Planning (IPP), with the aim of enabling more informed and
adaptive decision-making. However, it remains unclear to what extent this
integration actually improves planning performance. In this work, we
investigate the role of prediction in IPP approaches, drawing on the widely
adopted Val14 benchmark, which encompasses more common driving scenarios with
relatively low interaction complexity, and the interPlan benchmark, which
includes highly interactive and out-of-distribution driving situations. Our
analysis reveals that even access to perfect future predictions does not lead
to better planning outcomes, indicating that current IPP methods often fail to
fully exploit future behavior information. Instead, we focus on high-quality
proposal generation, while using predictions primarily for collision checks. We
find that many imitation learning-based planners struggle to generate realistic
and plausible proposals, performing worse than PDM - a simple lane-following
approach. Motivated by this observation, we build on PDM with an enhanced
proposal generation method, shifting the emphasis towards producing diverse but
realistic and high-quality proposals. This proposal-centric approach
significantly outperforms existing methods, especially in out-of-distribution
and highly interactive settings, where it sets new state-of-the-art results.

</details>


### [157] [VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation](https://arxiv.org/abs/2510.15530)
*Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 本文提出了一种仅基于单视角视觉的扩散策略学习方法VO-DP，利用预训练视觉基础模型融合语义与几何特征，在仿真和真实世界任务中均显著优于现有视觉方法，并在鲁棒性测试中表现出色，同时开源了支持多种策略和模拟器的并行训练库。


<details>
  <summary>Details</summary>
Motivation: 现有基于点云的模仿学习方法虽精度高，但对纯视觉方案探索不足，缺乏有效融合语义与几何信息的方法，限制了其在实际应用中的鲁棒性和可扩展性。

Method: 提出VO-DP，使用VGGT中间特征，结合DINOv2的语义特征和交替注意力模块提取的几何特征，通过交叉注意力融合并用CNN进行空间压缩，输入到策略头中实现动作预测。

Result: 在仿真任务中VO-DP平均成功率为64.6%，与DP3（64.0%）相当且远高于DP（34.8%）；在真实任务中达到87.9%，显著优于DP3（67.5%）和DP（11.2%），并在多种环境变化下保持高稳定性。

Conclusion: VO-DP验证了纯视觉单视角方案在机器人操作中的有效性与优越性，展示了其在真实场景中的强鲁棒性，并通过开源训练库推动相关研究发展。

Abstract: In the context of imitation learning, visuomotor-based diffusion policy
learning is one of the main directions in robotic manipulation. Most of these
approaches rely on point clouds as observation inputs and construct scene
representations through point clouds feature learning, which enables them to
achieve remarkable accuracy. However, the existing literature lacks an in-depth
exploration of vision-only solutions that have significant potential. In this
paper, we propose a Vision-Only and single-view Diffusion Policy learning
method (VO-DP) that leverages pretrained visual foundation models to achieve
effective fusion of semantic and geometric features. We utilize intermediate
features from VGGT incorporating semantic features from DINOv2 and geometric
features from Alternating Attention blocks. Features are fused via
cross-attention and spatially compressed with a CNN to form the input to the
policy head. Extensive experiments demonstrate that VO-DP not only outperforms
the vision-only baseline DP significantly but also exhibits distinct
performance trends against the point cloud-based method DP3: in simulation
tasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%
and far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,
outperforming both DP3 67.5% and DP 11.2% by a notable margin. Further
robustness evaluations confirm that VO-DP remains highly stable under varying
conditions including color, size, background, and lighting. Lastly, we
open-source a training library for robotic manipulation. Built on Accelerate,
this library supports multi-machine and multi-GPU parallel training, as well as
mixed precision training. It is compatible with visuomotor policies such as DP,
DP3 and VO-DP, and also supports the RoboTwin simulator.

</details>


### [158] [Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons](https://arxiv.org/abs/2510.15533)
*Shilei Li,Dawei Shi,Makoto Iwasaki,Yan Ning,Hongpeng Zhou,Ling Shi*

Main category: cs.RO

TL;DR: 本文研究了机械系统中由于未知干扰导致的性能下降问题，提出了一种两自由度控制结构来解耦名义性能与干扰抑制，并设计了两种新的干扰估计方法以提高跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 未知干扰会降低机械系统的名义性能，而传统方法难以实现完美干扰抑制，因此需要更有效的干扰估计与补偿机制。

Method: 提出了两种新型干扰观测器：基于交互多模型扩展卡尔曼滤波的干扰观测器和基于多核相关熵扩展卡尔曼滤波的干扰观测器，用于提升干扰估计能力。

Result: 在外骨骼实验中，新方法分别使髋关节误差减少了36.3%和16.2%，膝关节误差减少了46.3%和24.4%，优于传统的扩展卡尔曼滤波干扰观测器。

Conclusion: 所提出的两种干扰观测器能有效提升机械系统在时变交互力下的轨迹跟踪精度，验证了其在干扰抑制方面的优越性。

Abstract: The nominal performance of mechanical systems is often degraded by unknown
disturbances. A two-degree-of-freedom control structure can decouple nominal
performance from disturbance rejection. However, perfect disturbance rejection
is unattainable when the disturbance dynamic is unknown. In this work, we
reveal an inherent trade-off in disturbance estimation subject to tracking
speed and tracking uncertainty. Then, we propose two novel methods to enhance
disturbance estimation: an interacting multiple model extended Kalman
filter-based disturbance observer and a multi-kernel correntropy extended
Kalman filter-based disturbance observer. Experiments on an exoskeleton verify
that the proposed two methods improve the tracking accuracy $36.3\%$ and
$16.2\%$ in hip joint error, and $46.3\%$ and $24.4\%$ in knee joint error,
respectively, compared to the extended Kalman filter-based disturbance
observer, in a time-varying interaction force scenario, demonstrating the
superiority of the proposed method.

</details>


### [159] [Adaptive Legged Locomotion via Online Learning for Model Predictive Control](https://arxiv.org/abs/2510.15626)
*Hongyu Zhou,Xiaoyu Zhang,Vasileios Tzoumas*

Main category: cs.RO

TL;DR: 提出一种基于在线学习和模型预测控制的自适应足式机器人运动算法，通过残差动力学建模误差和外部扰动，在存在未知负载和非平坦地形的情况下实现鲁棒运动控制。


<details>
  <summary>Details</summary>
Motivation: 面向未来自主性需求，使四足机器人能在真实世界中面对未知不确定性（如未知负载和不平整地形）时仍能自主完成复杂任务。

Method: 采用模型预测控制（MPC）与残差动力学在线学习相结合的方法，使用随机傅里叶特征在再生核希尔伯特空间中逼近残差动力学，并以自监督方式通过最小二乘法在线更新模型。

Result: 算法实现了次线性的动态遗憾，仿真验证表明在Gazebo和MuJoCo中能有效应对高达12g的恒定外力、20度斜坡、0.25m起伏地形以及8kg时变负载和变化摩擦系数等干扰下的轨迹跟踪。

Conclusion: 该方法显著提升了四足机器人在复杂未知环境中的自适应运动能力，具备较强的鲁棒性和理论保证。

Abstract: We provide an algorithm for adaptive legged locomotion via online learning
and model predictive control. The algorithm is composed of two interacting
modules: model predictive control (MPC) and online learning of residual
dynamics. The residual dynamics can represent modeling errors and external
disturbances. We are motivated by the future of autonomy where quadrupeds will
autonomously perform complex tasks despite real-world unknown uncertainty, such
as unknown payload and uneven terrains. The algorithm uses random Fourier
features to approximate the residual dynamics in reproducing kernel Hilbert
spaces. Then, it employs MPC based on the current learned model of the residual
dynamics. The model is updated online in a self-supervised manner using least
squares based on the data collected while controlling the quadruped. The
algorithm enjoys sublinear \textit{dynamic regret}, defined as the
suboptimality against an optimal clairvoyant controller that knows how the
residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,
where the quadruped aims to track reference trajectories. The Gazebo
simulations include constant unknown external forces up to $12\boldsymbol{g}$,
where $\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain
with $20\degree$ inclination, and rough terrain with $0.25m$ height variation.
The MuJoCo simulations include time-varying unknown disturbances with payload
up to $8~kg$ and time-varying ground friction coefficients in flat terrain.

</details>


### [160] [Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS](https://arxiv.org/abs/2510.15638)
*Jared K. Lepora,Haoran Li,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 本文介绍了一款完全使用LEGO MINDSTORMS构建的人形机器人手——教育用SoftHand-A，基于Pisa/IIT SoftHand设计，适用于教育场景，可通过简单驱动机制自适应抓取多种物体，具有启发儿童学习现代机器人技术的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在教育环境中推广先进的机器人手设计理念，开发一种仅使用标准乐高组件、便于家庭测试和组装的类人机器人手。

Method: 采用肌腱驱动、欠驱动结构，每个手指由双电机驱动拮抗肌式肌腱，并通过带有离合齿轮的差动机构实现软协同同步手指运动。

Result: 成功构建出能自适应抓取多种物体的类人机器人手，验证了其精细反应控制能力和结构有效性。

Conclusion: 该设计结合了先进机器人手概念与乐高组件的易用性，适合教育用途，有助于激发儿童对现代机器人技术的兴趣。

Abstract: This paper introduces an anthropomorphic robot hand built entirely using LEGO
MINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated
robot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for
an educational context, the design is constrained to use only standard LEGO
pieces with tests using common equipment available at home. The hand features
dual motors driving an agonist/antagonist opposing pair of tendons on each
finger, which are shown to result in reactive fine control. The finger motions
are synchonized through soft synergies, implemented with a differential
mechanism using clutch gears. Altogether, this design results in an
anthropomorphic hand that can adaptively grasp a broad range of objects using a
simple actuation and control mechanism. Since the hand can be constructed from
LEGO pieces and uses state-of-the-art design concepts for robotic hands, it has
the potential to educate and inspire children to learn about the frontiers of
modern robotics.

</details>


### [161] [Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation](https://arxiv.org/abs/2510.15639)
*Manuel J. Fernandez,Alejandro Suarez,Anibal Ollero,Matteo Fumagalli*

Main category: cs.RO

TL;DR: 本文提出了一种可变刚度连接（VSL）机构，用于长距离空中操作，通过在柔性绳索和刚性杆之间调节刚度，提升无人机与双臂机械手之间的动态耦合性能。


<details>
  <summary>Details</summary>
Motivation: 传统长距离空中操作系统采用刚性或缆线连接，限制了操作精度或会将扰动传递给飞行器，因此需要一种能自适应调节机械耦合特性的方案。

Method: 设计并集成了可变刚度链接（VSL）机构，安装于配备LiCAS双臂机械手的四旋翼无人机上，通过遥操作实验评估其在外部扰动和包裹运输任务中的表现。

Result: 实验结果表明，调节连接刚度可显著改变无人机与负载间的动态交互：柔性模式可衰减外部冲击和气动扰动，刚性模式则提高操作时的位置精度。

Conclusion: VSL提升了长距离空中操作的灵活性与安全性，实现了柔顺性与精度之间的可控权衡，未来将研究自主刚度调节及多机协同等方向。

Abstract: This paper presents the integration of a Variable Stiffness Link (VSL) for
long-reach aerial manipulation, enabling adaptable mechanical coupling between
an aerial multirotor platform and a dual-arm manipulator. Conventional
long-reach manipulation systems rely on rigid or cable connections, which limit
precision or transmit disturbances to the aerial vehicle. The proposed VSL
introduces an adjustable stiffness mechanism that allows the link to behave
either as a flexible rope or as a rigid rod, depending on task requirements.
  The system is mounted on a quadrotor equipped with the LiCAS dual-arm
manipulator and evaluated through teleoperated experiments, involving external
disturbances and parcel transportation tasks. Results demonstrate that varying
the link stiffness significantly modifies the dynamic interaction between the
UAV and the payload. The flexible configuration attenuates external impacts and
aerodynamic perturbations, while the rigid configuration improves positional
accuracy during manipulation phases.
  These results confirm that VSL enhances versatility and safety, providing a
controllable trade-off between compliance and precision. Future work will focus
on autonomous stiffness regulation, multi-rope configurations, cooperative
aerial manipulation and user studies to further assess its impact on
teleoperated and semi-autonomous aerial tasks.

</details>


### [162] [Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing](https://arxiv.org/abs/2510.15668)
*Yameng Zhang,Dianye Huang,Max Q. -H. Meng,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 提出一种基于轻量级相机和视觉伺服的低成本、高精度自由手3D超声成像方法，通过模拟环境中的闭环优化实现精确的探头位姿估计。


<details>
  <summary>Details</summary>
Motivation: 传统自由手3D超声成像依赖昂贵的追踪系统，而基于神经网络的方法易受图像噪声和误差累积影响，导致重建精度下降。

Method: 利用轻量级相机捕捉纹理平面工作区的视觉反馈，结合图像修复技术恢复遮挡区域，并通过模拟-现实闭环优化和视觉伺服控制器迭代最小化位姿误差，提升平移估计精度。

Result: 在血管软体模型、3D打印锥形模型和人体手臂上的实验显示，与参考重建的Hausdorff距离分别为0.359 mm、1.171 mm和0.858 mm，验证了方法的鲁棒性和高精度。

Conclusion: 该方法无需昂贵设备，具有良好的临床应用潜力，可实现可靠且精确的自由手3D超声重建。

Abstract: Freehand 3D ultrasound (US) imaging using conventional 2D probes offers
flexibility and accessibility for diverse clinical applications but faces
challenges in accurate probe pose estimation. Traditional methods depend on
costly tracking systems, while neural network-based methods struggle with image
noise and error accumulation, compromising reconstruction precision. We propose
a cost-effective and versatile solution that leverages lightweight cameras and
visual servoing in simulated environments for precise 3D US imaging. These
cameras capture visual feedback from a textured planar workspace. To counter
occlusions and lighting issues, we introduce an image restoration method that
reconstructs occluded regions by matching surrounding texture patterns. For
pose estimation, we develop a simulation-in-the-loop approach, which replicates
the system setup in simulation and iteratively minimizes pose errors between
simulated and real-world observations. A visual servoing controller refines the
alignment of camera views, improving translational estimation by optimizing
image alignment. Validations on a soft vascular phantom, a 3D-printed conical
model, and a human arm demonstrate the robustness and accuracy of our approach,
with Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171
mm, and 0.858 mm, respectively. These results confirm the method's potential
for reliable freehand 3D US reconstruction.

</details>


### [163] [HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward](https://arxiv.org/abs/2510.15679)
*Yuhong Cao,Yizhuo Wang,Jingsong Liang,Shuhao Liao,Yifeng Zhang,Peizhuo Li,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: HEADER是一种基于注意力机制的分层图强化学习方法，用于大规模环境中的高效自主探索，具有增量式、形状自适应的全局图构建能力，并通过无参数特权奖励提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在大规模环境中探索效率低且扩展性差，需要更高效的基于学习的自主探索方法。

Method: 提出HEADER，采用基于注意力网络的分层图结构，设计社区算法构建全局图，并引入无参数特权奖励以避免奖励塑形偏差。

Result: 在大规模仿真和真实场景（如300m×230m校园）中，HEADER比现有方法效率提升高达20%，具备良好可扩展性。

Conclusion: HEADER在大尺度环境中实现了高效、可扩展的自主探索，结合增量式图表示与无参数奖励设计，显著提升了探索性能。

Abstract: This work pushes the boundaries of learning-based methods in autonomous robot
exploration in terms of environmental scale and exploration efficiency. We
present HEADER, an attention-based reinforcement learning approach with
hierarchical graphs for efficient exploration in large-scale environments.
HEADER follows existing conventional methods to construct hierarchical
representations for the robot belief/map, but further designs a novel
community-based algorithm to construct and update a global graph, which remains
fully incremental, shape-adaptive, and operates with linear complexity.
Building upon attention-based networks, our planner finely reasons about the
nearby belief within the local range while coarsely leveraging distant
information at the global scale, enabling next-best-viewpoint decisions that
consider multi-scale spatial dependencies. Beyond novel map representation, we
introduce a parameter-free privileged reward that significantly improves model
performance and produces near-optimal exploration behaviors, by avoiding
training objective bias caused by handcrafted reward shaping. In simulated
challenging, large-scale exploration scenarios, HEADER demonstrates better
scalability than most existing learning and non-learning methods, while
achieving a significant improvement in exploration efficiency (up to 20%) over
state-of-the-art baselines. We also deploy HEADER on hardware and validate it
in complex, large-scale real-life scenarios, including a 300m*230m campus
environment.

</details>


### [164] [Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems](https://arxiv.org/abs/2510.15686)
*Taehyeon Kim,Vishnunandan L. N. Venkatesh,Byung-Cheol Min*

Main category: cs.RO

TL;DR: 提出了一种新的少样本学习框架DDACE，用于多机器人系统的时空任务协调与轨迹执行，通过解耦时空要素实现高效泛化。


<details>
  <summary>Details</summary>
Motivation: 传统从示范中学习的方法需要大量数据，难以适应多机器人系统中的多样化和动态任务需求。

Method: 结合时序图网络学习任务无关的时间序列，使用高斯过程建模空间轨迹，解耦时空建模以提升模块化与泛化能力。

Result: 实验表明DDACE在少样本条件下能有效完成多序列执行、多动作动态、复杂轨迹生成等任务，并在异构配置下具有良好泛化性。

Conclusion: 模块化架构（如DDACE）可显著降低数据需求，提升多机器人系统在现实应用中的实用性与可扩展性。

Abstract: In this paper, we propose a novel few-shot learning framework for multi-robot
systems that integrate both spatial and temporal elements: Few-Shot
Demonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our
approach leverages temporal graph networks for learning task-agnostic temporal
sequencing and Gaussian Processes for spatial trajectory modeling, ensuring
modularity and generalization across various tasks. By decoupling temporal and
spatial aspects, DDACE requires only a small number of demonstrations,
significantly reducing data requirements compared to traditional learning from
demonstration approaches. To validate our proposed framework, we conducted
extensive experiments in task environments designed to assess various aspects
of multi-robot coordination-such as multi-sequence execution, multi-action
dynamics, complex trajectory generation, and heterogeneous configurations. The
experimental results demonstrate that our approach successfully achieves task
execution under few-shot learning conditions and generalizes effectively across
dynamic and diverse settings. This work underscores the potential of modular
architectures in enhancing the practicality and scalability of multi-robot
systems in real-world applications. Additional materials are available at
https://sites.google.com/view/ddace.

</details>


### [165] [DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation](https://arxiv.org/abs/2510.15786)
*Xinyue Xu,Jieqiang Sun,Jing,Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Yiwen Lu*

Main category: cs.RO

TL;DR: DexCanvas是一个大规模混合真实-合成的人类操作数据集，包含7000小时的灵巧手物交互数据，基于Cutkosky分类法覆盖21种基本操作类型，提供多视角RGB-D、高精度动作捕捉和物理一致的接触力标注。


<details>
  <summary>Details</summary>
Motivation: 为了推动机器人操作学习、富含接触的控制及跨不同手部形态的技能迁移研究，需要一个兼具大规模真实演示、系统性技能覆盖和物理验证接触标注的操作数据集。

Method: 通过从70小时真实人类演示出发，使用强化学习训练策略，在物理仿真中控制可驱动的MANO手模型复现人类动作，并推断产生物体运动的底层接触力，构建真实到仿真的生成 pipeline。

Result: 构建了包含7,000小时手物交互的DexCanvas数据集，每条数据包含同步的多视角RGB-D、高精度mocap、MANO手参数及每帧带有物理一致性力分布的接触点；是首个结合大规模真实演示、系统性技能分类和物理验证接触标注的数据集。

Conclusion: DexCanvas为机器人操作学习、接触丰富环境下的控制以及跨形态技能迁移提供了高质量、物理可信的数据支持，填补了现有数据集在规模、系统性和物理准确性方面的空白。

Abstract: We present DexCanvas, a large-scale hybrid real-synthetic human manipulation
dataset containing 7,000 hours of dexterous hand-object interactions seeded
from 70 hours of real human demonstrations, organized across 21 fundamental
manipulation types based on the Cutkosky taxonomy. Each entry combines
synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,
and per-frame contact points with physically consistent force profiles. Our
real-to-sim pipeline uses reinforcement learning to train policies that control
an actuated MANO hand in physics simulation, reproducing human demonstrations
while discovering the underlying contact forces that generate the observed
object motion. DexCanvas is the first manipulation dataset to combine
large-scale real demonstrations, systematic skill coverage based on established
taxonomies, and physics-validated contact annotations. The dataset can
facilitate research in robotic manipulation learning, contact-rich control, and
skill transfer across different hand morphologies.

</details>


### [166] [Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion](https://arxiv.org/abs/2510.15803)
*Zahra Arjmandi,Gunho Sohn*

Main category: cs.RO

TL;DR: 提出了一种基于推断注意力融合（INAF）模块的LiDAR SLAM融合技术，结合AI与几何里程计，提升定位与3D建图精度。


<details>
  <summary>Details</summary>
Motivation: 为了提高复杂环境下LiDAR SLAM系统的定位精度和3D建图性能，增强系统适应性和测量准确性。

Method: 提出INAF模块，通过环境反馈动态调整注意力权重，融合AI与几何里程计信息，使用KITTI数据集进行验证。

Result: 在KITTI数据集上验证表明，该方法显著提升了定位和3D建图的精度与系统适应性。

Conclusion: 所提出的融合技术有效增强了LiDAR SLAM在复杂场景下的性能，具有应用于自主导航系统的潜力。

Abstract: This paper presents a novel fusion technique for LiDAR Simultaneous
Localization and Mapping (SLAM), aimed at improving localization and 3D mapping
using LiDAR sensor. Our approach centers on the Inferred Attention Fusion
(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI
dataset's LiDAR data, INAF dynamically adjusts attention weights based on
environmental feedback, enhancing the system's adaptability and measurement
accuracy. This method advances the precision of both localization and 3D
mapping, demonstrating the potential of our fusion technique to enhance
autonomous navigation systems in complex scenarios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [167] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: 本文提出了一种名为freephdlabor的开源多智能体框架，支持动态工作流和模块化架构，旨在实现可定制、持续且能与人类协作的自动化科学研究系统。


<details>
  <summary>Details</summary>
Motivation: 现有科学自动化系统存在预设工作流不灵活和上下文管理不足的问题，难以支持长周期研究。因此需要一个能动态调整流程并有效管理上下文的框架。

Method: 设计了一个具备动态工作流、模块化架构、自动上下文压缩、基于工作区通信、记忆持久化和非阻塞人工干预机制的多智能体系统。

Result: 实现了支持持续研究项目的自动化科研框架，能够跨会话记忆、防止信息退化，并允许用户自定义智能体以适应不同领域需求。

Conclusion: freephdlabor为构建可扩展、可定制的协同科学家系统提供了架构原则和实践基础，推动自动化科研在各科学领域的广泛应用。

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [168] [AURA: An Agent Autonomy Risk Assessment Framework](https://arxiv.org/abs/2510.15739)
*Lorenzo Satta Chiris,Ayush Mishra*

Main category: cs.AI

TL;DR: AURA是一个用于检测、量化和缓解代理AI风险的统一框架，采用基于gamma的风险评分方法，支持人机协同监督和自主自评估，适用于企业级大规模部署。


<details>
  <summary>Details</summary>
Motivation: 随着代理AI系统在组织中的广泛应用，对齐、治理和风险管理方面的挑战日益突出，亟需一个有效的风险评估框架来支持安全、可扩展的部署。

Method: 提出AURA框架，引入gamma-based风险评分方法，并设计交互式流程用于评分、评估和缓解单个或多个AI代理的风险，支持同步或异步运行，集成Agent-to-Human通信机制和Human-in-the-Loop监督。

Result: AURA实现了高效且准确的风险评估，在保证计算效率的同时支持与现有协议（MCP、A2A）和工具的互操作性，能够在企业环境中实现可治理的大规模代理AI部署。

Conclusion: AURA为代理AI系统的负责任和透明化应用提供了关键支撑，是实现大规模、可管控代理AI部署的重要推动力。

Abstract: As autonomous agentic AI systems see increasing adoption across
organisations, persistent challenges in alignment, governance, and risk
management threaten to impede deployment at scale. We present AURA (Agent
aUtonomy Risk Assessment), a unified framework designed to detect, quantify,
and mitigate risks arising from agentic AI. Building on recent research and
practical deployments, AURA introduces a gamma-based risk scoring methodology
that balances risk assessment accuracy with computational efficiency and
practical considerations. AURA provides an interactive process to score,
evaluate and mitigate the risks of running one or multiple AI Agents,
synchronously or asynchronously (autonomously). The framework is engineered for
Human-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)
communication mechanisms, allowing for seamless integration with agentic
systems for autonomous self-assessment, rendering it interoperable with
established protocols (MCP and A2A) and tools. AURA supports a responsible and
transparent adoption of agentic AI and provides robust risk detection and
mitigation while balancing computational resources, positioning it as a
critical enabler for large-scale, governable agentic AI in enterprise
environments.

</details>


### [169] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: 本文提出了OpenEstimate，一个用于评估语言模型在不确定性下进行数值估计能力的多领域基准测试，发现当前前沿语言模型生成的先验概率常不准确且过度自信，改进空间有限。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的应用场景（如医疗、金融等）要求语言模型能够处理不完整信息并在不确定性下推理，但现有评测多集中于有明确答案的问题，缺乏对模型不确定性推理能力的有效评估。

Method: 提出OpenEstimate基准，包含跨领域的数值估计任务，要求模型综合大量背景知识并以概率先验形式表达预测，通过评估这些先验的准确性与校准性来衡量模型性能。

Result: 在六个前沿语言模型上的实验表明，模型生成的先验普遍不准确且过度自信；不同不确定性引导方式对性能有轻微改善，但采样策略、推理努力或提示设计的变化影响不大。

Conclusion: OpenEstimate为评估语言模型在不确定性下的推理能力提供了具有挑战性的新平台，揭示了当前模型在概率估计方面的不足，推动未来更优模型的发展。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [170] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 提出了一种基于深度强化学习（DRL）的程序化关卡设计新方法，通过在Unity中训练两个PPO代理（蜂鸟和浮岛）实现内容生成与求解的协同演化。


<details>
  <summary>Details</summary>
Motivation: 探索深度强化学习在程序化内容生成（PCG）中的潜力，实现游戏关卡的自动化、智能且上下文感知的设计，减少人工干预并提升可重玩性。

Method: 在Unity 3D环境中使用ML-Agents工具包，训练两个基于PPO算法的代理：蜂鸟代理作为求解器学习高效导航与采集；浮岛代理根据障碍物位置、蜂鸟初始状态及历史表现反馈，生成合理的花朵布局。两代理交互驱动关卡的动态演化。

Result: 实验表明该方法能生成有效的代理行为和适应性强的关卡布局，展现出跨环境配置的鲁棒泛化能力，并实现了由机器学习驱动的自主关卡设计。

Conclusion: 深度强化学习可用于同时生成和解决虚拟环境中的内容，为AI参与创造性游戏开发提供了新路径，拓展了程序化内容生成的边界。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [171] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 本文认为通向通用人工智能（AGI）的进展受限于理论而非数据或规模，提出基于批判理性主义的“因果力学”框架，强调通过猜想与批判扩展假设空间，并引入结构性原则以实现错误的发现与修正。


<details>
  <summary>Details</summary>
Motivation: 现有AI依赖观察学习和表征假设，但在干预任务中表现受限；作者认为仅靠观测不足以保证因果理解，需理论突破推动AGI发展。

Method: 基于波普尔和多伊奇的批判理性主义，重新定义知识、学习、智能等概念，提出‘因果力学’框架，将假设空间的变化作为核心操作，结合结构化原则如局域性、自主性、规范不变性与组合自主性。

Result: 提出了三个关于误差演化的核心问题，建立了支持模块化干预、可分离性和类比保持的结构性原则，并提供了可操作的诊断方法，使系统能将不可达误差转化为可达并加以纠正。

Conclusion: AGI的发展需要从以数据为中心转向以理论和机制为中心的学习范式，通过动态扩展假设空间和主动纠错实现真正的智能。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [172] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: HugAgent是一个用于评估机器在个体层面模拟人类推理能力的新基准，通过双轨设计（合成轨和人类轨）实现对个体推理适应性的可扩展、可复现评估。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型倾向于群体共识，忽视了个体推理风格和信念演变的差异，难以真正模拟人类个体化的思维过程。

Method: 提出HugAgent基准，包含合成轨道和真实人类‘出声思考’数据轨道，任务是根据个体过去观点的部分证据，预测其在新情境下的推理与信念更新。

Result: 实验显示当前最先进的大语言模型在个体化推理适应上存在持续差距，难以准确捕捉个体信念的演化路径。

Conclusion: HugAgent是首个支持个体化推理评估的可扩展基准，为实现更贴近人类个体思维的机器推理提供了新方向。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [173] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 本文介绍了一个大规模、长期的职场情绪数据集，包含38名员工在30.5个月内采集的733,651条面部表情记录，涵盖新冠疫情等重大社会事件，提供了多种情绪指标和元数据，数据质量高，可用于情绪识别、情感动态建模和离职预测等研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏在真实工作环境中采集的大规模纵向数据集，现实场景中的自动情绪识别仍具挑战性，因此需要构建一个真实、长期且富含上下文信息的情绪数据集。

Method: 收集了38名员工在2021年11月至2024年5月期间的真实办公环境下的面部表情数据，使用深度学习模型提取七种情绪概率，并计算32种情绪指标，结合职位、人格特质和雇佣结果等元数据进行技术验证和基准实验。

Result: 数据集成功复现了已知心理规律（如周末效应急剧上升192%，p<0.001；昼夜节律显著），对员工离职预测具有完美预测效力（AUC=1.0），随机森林和LSTM模型在情绪分类上准确率达91.2%，效价预测R²达0.84。

Conclusion: 该数据集是目前公开的最大规模、最长周期的职场情绪纵向数据集，为情绪识别、情感动态、情绪传染及情绪感知系统设计等研究提供了重要资源。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [174] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 本文提出了一种改进的通用人工智能（AGI）评估框架，主张将多领域能力视为一个具有稳定性的属性集群，而非简单的对称加权快照评分。作者建议根据领域的因果中心性进行加权，并引入跨会话持久性作为评估标准，提出了两个可兼容现有测试体系的扩展方法：基于CHC理论的中心性优先评分和集群稳定性指数族。


<details>
  <summary>Details</summary>
Motivation: 现有AGI评估方法存在两个问题：一是对所有能力领域赋予相同权重，忽视了不同领域在智能结构中的实际重要性差异；二是依赖单一时间点的快照评分，无法区分稳定能力和脆弱表现。因此需要更符合人类智能特征的动态、稳定性导向的评估方式。

Method: 提出将一般智力理解为一种稳态属性集群，即一组在扰动下仍能共存的能力及其维持机制。在此基础上设计两种可与现有测试电池兼容的扩展：1）基于CHC智力模型的因果中心性加权评分法，并提供敏感性分析；2）集群稳定性指数族，用于衡量能力剖面的持久性、持久学习和错误纠正能力。

Result: 新框架能够保留多领域广度的同时减少评估的脆弱性和‘刷分’行为。通过引入领域权重和跨会话稳定性指标，提升了AGI评估的生态效度和鲁棒性。文中还提供了可检验的预测和无需访问模型架构即可实施的黑箱测试协议。

Conclusion: 将AGI评估从静态快照转向动态稳定性视角，有助于更真实地衡量机器的一般智能水平。基于因果中心性和集群稳定性的评估方法为未来AGI测评提供了更具理论依据和实践可行性的方向。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [175] [Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions](https://arxiv.org/abs/2510.15258)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Jun Xu,Fu Zhang,Wenbo Lei,Annie Wang,Peng Gong*

Main category: cs.AI

TL;DR: 提出一种基于大语言模型（LLM）代理与知识图谱（KG）交互的多维数据分析方法，构建动态协同分析生态系统，实现实时知识提取、图谱构建与可视化，并支持用户深度探索，在产品生态分析和关系挖掘中表现优越。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理结构化知识时存在“幻觉”问题且难以实时更新，知识图谱虽能存储结构化知识但缺乏动态交互能力，因此需要结合两者优势以提升多维数据的动态分析能力。

Method: 利用LLM代理从非结构化数据中自动抽取产品信息，实时构建并可视化知识图谱，通过交互式平台支持用户对图节点进行深入探索与分析。

Result: 实验表明该方法在产品生态系统分析、关系挖掘和用户驱动的探索性分析中具有显著优势，能够实现高效、动态的知识更新与交互。

Conclusion: LLM代理与知识图谱的协同机制为多维复杂数据的动态分析提供了有效解决方案，推动了智能化、交互式数据分析的发展。

Abstract: In the current era of big data, extracting deep insights from massive,
heterogeneous, and complexly associated multi-dimensional data has become a
significant challenge. Large Language Models (LLMs) perform well in natural
language understanding and generation, but still suffer from "hallucination"
issues when processing structured knowledge and are difficult to update in
real-time. Although Knowledge Graphs (KGs) can explicitly store structured
knowledge, their static nature limits dynamic interaction and analytical
capabilities. Therefore, this paper proposes a multi-dimensional data analysis
method based on the interactions between LLM agents and KGs, constructing a
dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to
automatically extract product data from unstructured data, constructs and
visualizes the KG in real-time, and supports users in deep exploration and
analysis of graph nodes through an interactive platform. Experimental results
show that this method has significant advantages in product ecosystem analysis,
relationship mining, and user-driven exploratory analysis, providing new ideas
and tools for multi-dimensional data analysis.

</details>


### [176] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: 提出KG-Agent框架，通过构建状态-动作知识图谱（SA-KG）提升LLM代理在无API环境下的GUI操作效率与长期规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在缺乏API的GUI环境中依赖像素级试错，决策短视、探索效率低，难以进行长期规划。

Method: 将代理的视觉交互经验构建成持久化的状态-动作知识图谱（SA-KG），通过图结构关联功能相似但外观不同的界面状态，并设计基于图拓扑的混合内在奖励机制（状态价值奖励+新颖性奖励），实现高效探索与长期策略解耦。

Result: 在《文明V》和《杀戮尖塔》两个复杂开放环境中验证，KG-Agent显著优于现有方法，在探索效率和战略深度上均有提升。

Conclusion: KG-Agent通过结构化经验表示和分层奖励机制，有效解决了无API环境下代理的低效探索与长程决策难题，提升了GUI任务中的学习与规划能力。

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [177] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个受人类记忆启发的多模态代理系统，通过将信息抽象为语义标签并存储在图结构的上下文记忆中，实现了比传统多模态RAG和MemGPT更高效、更快的性能。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统主要依赖文本记忆，忽略了多模态信号的重要性。受人类记忆多模态特性的启发，需要构建更贴近认知科学的多模态记忆系统。

Method: 系统包含四个循环阶段：编码、存储、检索和行动；提出将信息概念化为语义标签，并与上下文关联后存入图结构的多模态记忆中，实现基于概念的高效检索。

Result: 在ImageNet分类任务上比传统多模态RAG快3.5倍，在MSC基准上优于MemGPT。

Conclusion: AUGUSTUS通过模仿人类记忆的认知机制，验证了图结构多模态记忆在效率和性能上的优势，为代理系统的记忆设计提供了新方向。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [178] [WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation](https://arxiv.org/abs/2510.15306)
*Kuang-Da Wang,Zhao Wang,Yotaro Shimose,Wei-Yao Wang,Shingo Takamatsu*

Main category: cs.AI

TL;DR: WebGen-V是一个用于指令到HTML生成的新基准和框架，通过提升数据质量和评估粒度，实现高细粒度的网页生成与评估。


<details>
  <summary>Details</summary>
Motivation: 现有的指令到HTML生成任务在数据质量和评估细粒度方面存在不足，缺乏对真实网页的细粒度多模态监督和系统性评估方法。

Method: 提出WebGen-V，包含三个创新：基于代理的无边界爬取框架、结构化的分段数据表示（含元数据、UI截图和JSON格式资源），以及分节的多模态评估协议。

Result: 实验验证了结构化数据和分节评估的有效性，各组件均对性能有显著贡献，支持高细粒度的生成与评估。

Conclusion: WebGen-V是首个支持高细粒度代理爬取与多模态评估的指令到HTML生成框架，提供了从数据采集到生成再到评估的统一 pipeline。

Abstract: Witnessed by the recent advancements on leveraging LLM for coding and
multimodal understanding, we present WebGen-V, a new benchmark and framework
for instruction-to-HTML generation that enhances both data quality and
evaluation granularity. WebGen-V contributes three key innovations: (1) an
unbounded and extensible agentic crawling framework that continuously collects
real-world webpages and can leveraged to augment existing benchmarks; (2) a
structured, section-wise data representation that integrates metadata,
localized UI screenshots, and JSON-formatted text and image assets, explicit
alignment between content, layout, and visual components for detailed
multimodal supervision; and (3) a section-level multimodal evaluation protocol
aligning text, layout, and visuals for high-granularity assessment. Experiments
with state-of-the-art LLMs and ablation studies validate the effectiveness of
our structured data and section-wise evaluation, as well as the contribution of
each component. To the best of our knowledge, WebGen-V is the first work to
enable high-granularity agentic crawling and evaluation for instruction-to-HTML
generation, providing a unified pipeline from real-world data acquisition and
webpage generation to structured multimodal assessment.

</details>


### [179] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: 提出VERITAS管道，通过整合视觉先验和多个先进大模型与统计方法，提升监督微调数据质量，显著增强多模态模型在文本丰富和细粒度推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法因视觉感知不足常导致事实错误和幻觉，影响大模型性能，需提高监督微调数据质量。

Method: 利用视觉识别模型和OCR提取结构化视觉先验，结合图像、问题和答案；使用多个大模型进行答案评估并生成批评理由和评分，通过统计融合生成高置信共识分数作为真值；训练轻量级批评模型，并基于批评意见优化生成最终答案。

Result: 在六个多模态基准上实验表明，使用VERITAS处理的数据微调的模型优于使用原始数据的模型，尤其在文本丰富和细粒度推理任务中表现更优；所提批评模型效率高，能力接近最先进大模型。

Conclusion: VERITAS有效提升了多模态监督微调数据的质量，增强了模型性能，且其轻量批评模型具备高效推理能力，推动了多模态数据优化研究。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [180] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: 提出了一种新的强化学习框架DEPO，用于减少大推理模型中的无效推理，显著降低了响应长度并提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法虽然提升了模型准确性，但存在响应过长和过度思考的问题，导致推理延迟和计算消耗增加，尤其是在处理简单任务时。

Method: DEPO框架包含三个核心组件：优势解耦算法、难度感知的长度惩罚和优势裁剪方法，分别用于引导模型减少无效token、降低响应长度并防止策略优化偏差。

Result: 在DeepSeek-Distill-Qwen-7B和1.5B模型上实验显示，DEPO将序列长度减少了39%，减少了无效推理路径，同时整体准确率优于基线模型。

Conclusion: DEPO有效平衡了推理效率与模型性能，能够在保持甚至提升准确率的同时显著减少不必要的推理开销。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [181] [Advancing Routing-Awareness in Analog ICs Floorplanning](https://arxiv.org/abs/2510.15387)
*Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习和关系图卷积神经网络的自动布局规划引擎，旨在提高模拟集成电路布局的可布线性，满足工业标准。


<details>
  <summary>Details</summary>
Motivation: 模拟集成电路布局中，由于电气和问题特定约束严格，且布局规划与布线步骤相互依赖，导致机器学习技术的应用受限，布局工程师迫切需要可布线感知的布局规划解决方案。

Method: 采用强化学习和关系图卷积神经网络开发自动布局规划引擎，结合提高网格分辨率、精确引脚信息集成和动态布线资源估计技术，以平衡布线和面积效率。

Result: 在模拟环境中分析布局和布线效果时，该方法相比以往基于学习的最先进方法，死区空间减少了13.8%，线长减少了40.6%，布线成功率提高了73.4%。

Conclusion: 所提出的自动布局规划引擎能有效提升模拟集成电路布局的可布线性和整体性能，达到工业应用标准。

Abstract: The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.

</details>


### [182] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: 本文提出了一种将任意目标转化为可纠正目标的变换方法，形式化定义了可纠正性，并通过实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在AI训练过程中，为了避免AI抵抗目标更新或关机，需要确保其具备可纠正性，从而提升安全性并适应人类偏好变化。然而现有研究缺乏既可纠正又具有竞争力的目标设计。

Method: 通过一种变换方法构造出任何可被纠正目标的可纠正版本，利用短视地预测阻止更新情况下的奖励来决定接受更新时的奖励，并可递归扩展至新生成的代理。

Result: 提出了可纠正性的形式化定义，设计了不牺牲性能的可纠正目标变换方法，并在两个网格世界实验中验证了该方法能有效学习并产生期望行为。

Conclusion: 该变换方法能够构建兼具可纠正性和竞争力的目标，为AI安全提供了可行路径。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [183] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: MARS是一个端到端的强化学习框架，通过在合作与竞争性游戏中进行自我对弈，提升大语言模型在多智能体系统中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在单智能体任务中表现良好，但在多轮、多智能体场景中因长期信用分配和智能体特定优势估计困难而受限。

Method: 提出MARS框架，引入回合级优势估计器和智能体特定的优势归一化机制，通过自我对弈在合作与竞争游戏中进行端到端训练。

Result: MARS在未见过的游戏中性能最高提升28.7%，并在AIME和GPQA-Diamond基准上分别提升10.0%和12.5%。

Conclusion: MARS证明了在战略游戏中通过自我对弈进行端到端强化学习是发展大语言模型多智能体推理能力的有效途径。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [184] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds 是一个将 LoRA 适配器作为领域专用工具的智能体系统，通过基础大模型动态选择最相关的 LoRA 工具，实现跨领域的自适应响应。


<details>
  <summary>Details</summary>
Motivation: 为了克服单一微调模型和基于规则路由的局限性，提升大模型在多领域任务中的适应性和准确性。

Method: 利用基础大语言模型作为语义路由器，根据查询内容动态选择合适的 LoRA 适配器，并结合 LangGraph 实现工作流管理。

Result: 系统能够按需切换不同领域的专家模型，在保持对话能力的同时提供准确且专业化的响应。

Conclusion: Adaptive Minds 结合了多智能体协调的灵活性和参数高效微调的优势，为领域自适应的 AI 助手提供了可扩展且开源的基础框架。

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [185] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 提出了一种新框架DGR，用于检测和解决强化学习中的判断不一致性问题，提升训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强化学习中存在判断不一致（如偏好循环）的问题，影响训练稳定性，且逻辑连贯性未被充分研究。

Method: 提出冲突检测率（CDR）指标和去冲突图奖励（DGR）框架，通过构建偏好图并转化为无环有向图（DAG）来生成逻辑一致的奖励信号。

Result: 实验表明，该框架显著提升了训练稳定性和模型性能，优于强基线方法。

Conclusion: 逻辑一致性是AI反馈的关键可管理维度，DGR为解决判断冲突提供了有效方案。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [186] [Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors](https://arxiv.org/abs/2510.15547)
*Usman Ali,Ali Zia,Waqas Ali,Umer Ramzan,Abdul Rehman,Muhammad Tayyab Chaudhry,Wei Xiang*

Main category: cs.AI

TL;DR: 本文提出了一种名为MM-HCAN的多模态超图对比注意力网络，用于感应电机故障诊断，首次将对比学习引入超图结构以实现多传感器数据融合，实现了高达99.82%的准确率，并具有良好的跨域泛化和抗噪能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉复杂的多模态信号关系，通常局限于单模态或单一故障类型，且在噪声或跨域条件下性能下降，因此需要一种更鲁棒、统一的多故障诊断框架。

Method: 提出MM-HCAN模型，结合超图拓扑与对比学习，建模模态内和模态间依赖关系，利用多模态传感器数据进行联合学习，在非欧几里得空间中增强泛化能力，实现轴承、定子和转子故障的同步诊断。

Result: 在三个真实世界基准上测试，MM-HCAN最高达到99.82%的准确率，表现出优异的跨域泛化性和噪声鲁棒性，消融实验验证了各组件的有效性。

Conclusion: MM-HCAN为工业环境中的多故障诊断提供了一个可扩展且鲁棒的解决方案，支持预测性维护和设备寿命延长，具备实际部署潜力。

Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety
and operational continuity, mitigating costly unplanned downtime. Conventional
approaches often struggle to capture complex multimodal signal relationships,
are constrained to unimodal data or single fault types, and exhibit performance
degradation under noisy or cross-domain conditions. This paper proposes the
Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified
framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is
the first to integrate contrastive learning within a hypergraph topology
specifically designed for multimodal sensor fusion, enabling the joint
modelling of intra- and inter-modal dependencies and enhancing generalisation
beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis
of bearing, stator, and rotor faults, addressing the engineering need for
consolidated di- agnostic capabilities. Evaluated on three real-world
benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain
generalisation and resilience to noise, demonstrating its suitability for
real-world deployment. An ablation study validates the contribution of each
component. MM-HCAN provides a scalable and robust solution for comprehensive
multi-fault diagnosis, supporting predictive maintenance and extended asset
longevity in industrial environments.

</details>


### [187] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: 本文提出了JudgeSQL，一个通过结构化推理和加权共识机制来改进Text-to-SQL候选查询选择的新框架。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL候选选择方法（如自一致性或最优N解码）仅提供浅层信号，难以捕捉语义细微差别，容易导致评分不一致和推理脆弱。

Method: 提出JudgeSQL框架，包括基于推理的SQL评判模型（通过强化学习和可验证奖励训练）以及加权共识锦标赛机制，结合显式推理偏好与生成器置信度。

Result: 在BIRD基准上的实验表明，JudgeSQL在SQL判断能力、跨尺度泛化性和对生成器容量的鲁棒性方面表现优越。

Conclusion: JudgeSQL通过结构化推理和融合多源信息的锦标赛机制，显著提升了Text-to-SQL任务中候选查询选择的准确性与可靠性。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [188] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 提出一种机器学习框架，通过整合患者历史就诊数据（如影像和临床生物标志物）来提升疾病风险预测的特异性，尤其在就诊次数有限且频率不均的情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 利用时间维度上的医疗数据上下文信息，改善现有仅依赖单次就诊数据进行健康监测时特异性不足的问题，特别是在患者历史就诊数据稀疏且不规律的情况下。

Method: 首先基于最近一次就诊的医疗数据估计初始疾病风险，然后逐步融合此前收集的医学影像和/或临床生物标志物信息，以优化风险评估。

Result: 在前列腺癌风险预测中，整合最多三次先前影像检查使假阳性率从51%降至33%，进一步加入临床数据后降至24%；五年内癌症风险预测的假阳性率从64%显著降低至9%，同时保持高灵敏度。

Conclusion: 长期积累的医疗数据能有效提升风险预测的特异性，降低假阳性率，有助于在低基线风险人群中推广纵向健康监测，实现早期检测和更好健康结局。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [189] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 本文提出了Thoth，一个通过“Sketch-and-Fill”范式和结构化奖励机制提升科学实验协议生成可靠性的模型，在多基准测试中优于现有大语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在自动生成科学实验协议时常产生不完整或不一致的结果，限制了科研的可重复性。

Method: 提出SciRecipe数据集（包含12K+结构化协议）和“Sketch-and-Fill”生成范式，并设计基于结构组件的奖励机制，训练Thoth模型经过知识到行动的分阶段过程。

Result: Thoth在多个基准上显著优于现有开源和闭源大模型，提升了步骤对齐、逻辑顺序和语义准确性。

Conclusion: 该方法推动了可靠科学助手的发展，能够有效连接科学知识与实验执行，且所有数据、代码和模型将公开发布。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [190] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 本文提出了一种新的生成模型对齐框架，通过引入多响应排序和异构偏好建模，解决了现有RLHF和DPO方法在处理多样化人类反馈时的局限性，并结合公平性准则实现个性化与公平性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习从人类反馈中学习（RLHF）和直接偏好优化（DPO）方法通常假设人类标注者的偏好一致且依赖二元比较，忽略了人类评价者的多样性以及成对反馈的局限性，因此难以准确捕捉真实的人类偏好。

Method: 作者结合计量经济学理论，证明了三者及以上响应的排序数据可确保用户偏好的可识别性，而二元比较则不足；并提出了基于期望最大化（EM）的DPO扩展方法，用于发现潜在标注者类型并训练LLM混合模型，同时设计了一种基于最小最大遗憾公平准则的聚合算法以生成单一生成策略。

Result: 所提方法在理论上保证了偏好识别的可识别性，实验显示其能有效建模异构偏好，并在生成策略中实现更公平的表现。

Conclusion: 该工作建立了支持多样用户公平性和个性化的生成模型对齐理论与算法框架，为未来考虑多样的人类价值观的对齐技术提供了新方向。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [191] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 本文提出了一种从发票文档中提取结构化信息的方法，并设计了一套评估指标来衡量提取结果的准确性。


<details>
  <summary>Details</summary>
Motivation: 需要一种可靠且标准化的方法来评估从发票中提取结构化数据的准确性和一致性。

Method: 通过预处理扫描或数字发票，利用Docling和LlamaCloud服务识别并提取关键字段，并建立包含字段级精确率、一致性检查失败率和完全匹配准确率的评估框架。

Result: 提出了一套有效的评估指标，能够标准化地比较不同提取方法，并揭示各方法在特定字段上的表现优劣。

Conclusion: 该方法和评估体系有助于提升发票信息提取的可靠性与可比性，为后续优化提供了依据。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [192] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 提出了一种新的帕金森病评估框架TRIP，将多模态学习建模为多目标优化问题，解决了模态同步训练和依赖所有模态推理的限制，并通过基于边距的类别重平衡策略提升性能，在多个公开数据集上实现了最先进的效果。


<details>
  <summary>Details</summary>
Motivation: 现有帕金森病多模态评估方法需要所有模态同步训练且推理时依赖全部模态，限制了实际应用，因此需要更灵活的方法。

Method: 将多模态学习转化为多目标优化（MOO）问题，提出TRIP框架，支持训练和推理时模态输入的灵活性，并引入基于边距的类别重平衡策略缓解单个模态内的类别不平衡问题。

Result: 在三个公开数据集上验证，异步设置下比最佳基线提升16.48、6.89和11.55个百分点，同步设置下提升4.86和2.30个百分点，表现出优越的性能和适应性。

Conclusion: TRIP框架有效解决了多模态帕金森病评估中的模态同步与依赖问题，具有良好的实际应用潜力和推广价值。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [193] [Preliminary Quantitative Study on Explainability and Trust in AI Systems](https://arxiv.org/abs/2510.15769)
*Allen Daniel Sunny*

Main category: cs.AI

TL;DR: 本研究通过定量实验设计，探讨了不同类型的解释（从基本特征重要性到交互式反事实）对用户在AI系统中信任感的影响，发现解释的清晰度、相关性以及交互性显著提升用户信任和参与度。


<details>
  <summary>Details</summary>
Motivation: 随着大型AI模型在关键领域的广泛应用，如何建立用户对AI系统的信任成为一个紧迫问题，特别是透明性和可解释性对信任的影响尚需实证研究。

Method: 采用基于网络的交互式贷款审批模拟实验，比较不同类型解释对用户信任的影响，使用量化方法分析用户反馈数据。

Result: 交互式反事实解释比基本特征重要性解释更能提升用户信任和参与度；解释的清晰度和相关性是影响信任的关键因素。

Conclusion: 解释设计的优化，尤其是增强交互性、清晰度和相关性，能够有效提升用户对AI系统的信任，为以人为本的可解释AI提供了实证支持。

Abstract: Large-scale AI models such as GPT-4 have accelerated the deployment of
artificial intelligence across critical domains including law, healthcare, and
finance, raising urgent questions about trust and transparency. This study
investigates the relationship between explainability and user trust in AI
systems through a quantitative experimental design. Using an interactive,
web-based loan approval simulation, we compare how different types of
explanations, ranging from basic feature importance to interactive
counterfactuals influence perceived trust. Results suggest that interactivity
enhances both user engagement and confidence, and that the clarity and
relevance of explanations are key determinants of trust. These findings
contribute empirical evidence to the growing field of human-centered
explainable AI, highlighting measurable effects of explainability design on
user perception

</details>


### [194] [Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL](https://arxiv.org/abs/2510.15772)
*Richard M. Bailey*

Main category: cs.AI

TL;DR: 本文提出了Dialectica框架，通过结构化对话、记忆、自我反思和策略约束的上下文编辑，使大语言模型代理在缺乏明确正确答案的复杂问题中发展出类专家能力。实验表明，具备反思性上下文编辑的代理在多种评估指标上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型缺乏在复杂、不可验证的‘棘手问题’中通过经验自主发展专业知识的内生机制，限制了其与人类协作解决现实世界难题的能力。

Method: 提出Dialectica框架，将讨论建模为隐式的元强化学习过程，代理通过结构化对话、记忆、自我反思和策略引导的上下文编辑进行训练，并使用配对比较方法对代理生成的回答进行后验评估。

Result: 在Qwen3:30b和o4-mini两种架构上，启用反思性上下文编辑的代理在Elo评分、归一化Bradley-Terry-Davidson能力和AlphaRank质量等指标上均显著优于基线模型；定性分析显示反思日志能识别弱点并持续改进后续陈述。

Conclusion: 基于对话的上下文演化是一种在开放、不可验证领域中实现目标性专业能力增强的有效路径，为AI参与解决复杂社会问题提供了可行方案。

Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this gap with Dialectica, a framework where agents
engage in structured dialogue on defined topics, augmented by memory,
self-reflection, and policy-constrained context editing. Formally, discussion
is viewed as an implicit meta-reinforcement learning process. The
`dialogue-trained' agents are evaluated post-hoc using judged pairwise
comparisons of elicited responses. Across two model architectures (locally run
Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based
context editing during discussion produces agents which dominate their baseline
counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and
AlphaRank mass. The predicted signatures of learning are observed qualitatively
in statement and reflection logs, where reflections identify weaknesses and
reliably shape subsequent statements. Agreement between quantitative and
qualitative evidence supports dialogue-driven context evolution as a practical
path to targeted expertise amplification in open non-verifiable domains.

</details>


### [195] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 本研究提出并评估了六种用于长新冠（LC）临床问答的检索增强生成（RAG）语料库配置，发现结合临床指南和高质量系统综述的配置在准确性、相关性和全面性方面表现最佳。作者提出了Guide-RAG系统，整合专家知识与文献数据库，以支持复杂新兴疾病的临床决策。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天机器人在临床医学中的应用日益广泛，如何为复杂且不断发展的疾病（如长新冠）构建有效的问答框架仍面临挑战，尤其是平衡信息的权威性、全面性与实用性。

Method: 开发了六种不同的RAG语料库配置，涵盖从专家整理资料到大规模文献数据库的不同来源；采用LLM-as-a-judge框架，在LongCOVID-CQ这一由专家生成的临床问题数据集上，对生成答案的忠实性、相关性和全面性进行评估。

Result: 结合临床指南与高质量系统综述的RAG配置在各项指标上均优于单一指南或大规模原始文献数据库的方法，能更好地支持临床决策，避免信息过载或过度简化。

Conclusion: 对于长新冠等新兴疾病，基于经过筛选的二次综述文献的检索策略在权威性与全面性之间实现了最优平衡；提出的Guide-RAG系统及其评估框架为临床AI问答提供了可推广的解决方案。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>


### [196] [PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold](https://arxiv.org/abs/2510.15862)
*Yi Wan,Jiuqi Wang,Liam Li,Jinsong Liu,Ruihao Zhu,Zheqing Zhu*

Main category: cs.AI

TL;DR: PokeeResearch-7B是一个基于70亿参数的深度研究代理，采用无标注强化学习框架训练，通过多步推理和自我验证机制，在10个主流研究基准上达到7B级别最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强型大模型在检索深度、对齐度量和工具使用鲁棒性方面存在局限，难以胜任复杂研究任务。

Method: 提出统一的强化学习框架，采用基于LLM反馈的奖励信号（事实准确性、引用忠实性、指令遵循）进行策略优化，并引入思维链驱动的多调用推理结构以实现自我验证和自适应恢复。

Result: 在10个流行的深度研究基准测试中，PokeeResearch-7B在7B规模模型中实现了最先进的性能。

Conclusion: 精心设计的强化学习与推理架构能够生成高效、稳健且具备研究级能力的AI代理。

Abstract: Tool-augmented large language models (LLMs) are emerging as deep research
agents, systems that decompose complex queries, retrieve external evidence, and
synthesize grounded responses. Yet current agents remain limited by shallow
retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce
PokeeResearch-7B, a 7B-parameter deep research agent built under a unified
reinforcement learning framework for robustness, alignment, and scalability.
PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from
AI Feedback (RLAIF) framework to optimize policies using LLM-based reward
signals that capture factual accuracy, citation faithfulness, and instruction
adherence. A chain-of-thought-driven multi-call reasoning scaffold further
enhances robustness through self-verification and adaptive recovery from tool
failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves
state-of-the-art performance among 7B-scale deep research agents. This
highlights that careful reinforcement learning and reasoning design can produce
efficient, resilient, and research-grade AI agents. The model and inference
code is open-sourced under MIT license at
https://github.com/Pokee-AI/PokeeResearchOSS.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [197] [Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information](https://arxiv.org/abs/2506.07829)
*Jan Corazza,Hadi Partovi Aria,Hyohun Kim,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: 本文研究了在去中心化多智能体强化学习（DMARL）中引入高层符号知识如何帮助解决策略兼容性、隐私、通信和性能等挑战，并扩展了形式化工具以提供理论保证，实验表明符号知识能显著加速学习过程。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，许多任务需要多个智能体协作完成，而传统的DMARL面临策略兼容性、通信限制和隐私等问题，因此需要新方法提升学习效率与可行性。

Method: 通过引入关于环境事件时序演化的高层符号知识，扩展用于检查局部策略与团队任务兼容性的形式化工具，从而在去中心化训练中提供理论保障。

Result: 实验证明，符号知识能够显著加快DMARL中的学习速度，同时所提出的方法使去中心化训练在更多场景下具备理论保证和实际可用性。

Conclusion: 引入高层符号知识不仅能提升多智能体系统的学习效率，还能在满足隐私和通信约束的同时确保策略的兼容性，推动DMARL在复杂现实场景中的应用。

Abstract: Reinforcement learning (RL) algorithms can find an optimal policy for a
single agent to accomplish a particular task. However, many real-world problems
require multiple agents to collaborate in order to achieve a common goal. For
example, a robot executing a task in a warehouse may require the assistance of
a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL
(DMARL), agents learn independently and then combine their policies at
execution time, but often must satisfy constraints on compatibility of local
policies to ensure that they can achieve the global task when combined. In this
paper, we study how providing high-level symbolic knowledge to agents can help
address unique challenges of this setting, such as privacy constraints,
communication limitations, and performance concerns. In particular, we extend
the formal tools used to check the compatibility of local policies with the
team task, making decentralized training with theoretical guarantees usable in
more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge
about the temporal evolution of events in the environment can significantly
expedite the learning process in DMARL.

</details>


### [198] [Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators](https://arxiv.org/abs/2510.14983)
*Oskar Triebe,Fletcher Passow,Simon Wittner,Leonie Wagner,Julio Arend,Tao Sun,Chad Zanocco,Marek Miltner,Arezou Ghesmati,Chen-Hao Tsai,Christoph Bergmeir,Ram Rajagopal*

Main category: cs.LG

TL;DR: 本文提出了一种多层级负荷预测系统，以应对可持续能源发展带来的电力负荷不确定性，提升输电系统运营商在节点级负荷预测中的准确性与可管理性。


<details>
  <summary>Details</summary>
Motivation: 随着可持续能源的发展，局部电网的电力负荷不确定性增加，传统区域级负荷预测已无法满足需求，需要更高空间分辨率的节点级负荷预测，但节点级预测精度较低且管理复杂。

Method: 结合输电系统运营商的实际需求，设计了一个多层级预测系统，采用可解释且可扩展的预测模型，利用区域和节点净负荷的大规模数据集进行实验评估，并通过完全并行化的单模型预测流程提高系统的可管理性。

Result: 该系统在区域级和节点级负荷预测中均显著提升了预测精度和可解释性，使操作员能够更准确地调整预测并精确定位错误。

Conclusion: 所提出的多层级预测系统有效支持了从区域到节点级负荷预测的过渡，增强了操作员在日常运行中对风险的评估能力，提高了电网运行的可靠性。

Abstract: The reliability of local power grid infrastructure is challenged by
sustainable energy developments increasing electric load uncertainty.
Transmission System Operators (TSOs) need load forecasts of higher spatial
resolution, extending current forecasting operations from zonal aggregates to
individual nodes. However, nodal loads are less accurate to forecast and
require a large number of individual forecasts, which are hard to manage for
the human experts assessing risks in the control room's daily operations
(operator). In collaboration with a TSO, we design a multi-level system that
meets the needs of operators for hourly day-ahead load forecasting. Utilizing a
uniquely extensive dataset of zonal and nodal net loads, we experimentally
evaluate our system components. First, we develop an interpretable and scalable
forecasting model that allows for TSOs to gradually extend zonal operations to
include nodal forecasts. Second, we evaluate solutions to address the
heterogeneity and volatility of nodal load, subject to a trade-off. Third, our
system is manageable with a fully parallelized single-model forecasting
workflow. Our results show accuracy and interpretability improvements for zonal
forecasts, and substantial improvements for nodal forecasts. In practice, our
multi-level forecasting system allows operators to adjust forecasts with
unprecedented confidence and accuracy, and to diagnose otherwise opaque errors
precisely.

</details>


### [199] [TangledFeatures: Robust Feature Selection in Highly Correlated Spaces](https://arxiv.org/abs/2510.15005)
*Allen Daniel Sunny*

Main category: cs.LG

TL;DR: TangledFeatures是一种用于处理相关特征空间的特征选择框架，能够从纠缠的预测变量中识别代表性特征，减少冗余并保持解释力。


<details>
  <summary>Details</summary>
Motivation: 现有特征选择方法多关注预测准确性，在存在相关预测变量时性能下降，缺乏对可解释性和稳定性的兼顾。

Method: 提出TangledFeatures框架，通过识别高度相关的特征组中的代表性特征来进行特征选择，从而减少冗余并保留解释能力。

Result: 在Alanine Dipeptide数据上验证了方法的有效性，所选特征对应于具有结构意义的原子间距离，能有效解释主链二面角的变化。

Conclusion: TangledFeatures在保持预测性能的同时提升了模型的可解释性和稳定性，适用于存在特征相关性的场景。

Abstract: Feature selection is a fundamental step in model development, shaping both
predictive performance and interpretability. Yet, most widely used methods
focus on predictive accuracy, and their performance degrades in the presence of
correlated predictors. To address this gap, we introduce TangledFeatures, a
framework for feature selection in correlated feature spaces. It identifies
representative features from groups of entangled predictors, reducing
redundancy while retaining explanatory power. The resulting feature subset can
be directly applied in downstream models, offering a more interpretable and
stable basis for analysis compared to traditional selection techniques. We
demonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying
it to the prediction of backbone torsional angles and show that the selected
features correspond to structurally meaningful intra-atomic distances that
explain variation in these angles.

</details>


### [200] [Compressive Modeling and Visualization of Multivariate Scientific Data using Implicit Neural Representation](https://arxiv.org/abs/2510.15535)
*Abhay Kumar Dwivedi,Shanu Saklani,Soumya Dutta*

Main category: cs.LG

TL;DR: 提出了一种基于共享参数的单个神经网络，用于同时学习多变量数据集中所有变量的压缩神经表示，在数据压缩、重建质量、可视化效果和存储效率方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着深度神经网络在科学可视化中的广泛应用，如何高效压缩包含数十到数百个变量的多变量数据集成为一个挑战，现有方法难以兼顾压缩率与重建质量。

Method: 采用一个共享参数的单一神经网络，同时学习多变量数据集中所有变量的隐式神经表示，实现高效的压缩建模。

Result: 实验表明该方法在重构数据质量、渲染与可视化质量、变量间依赖关系保持以及存储效率方面优于现有方法，达到最先进的压缩性能。

Conclusion: 所提出的多变量神经压缩表示方法通过参数共享实现了高性能的数据压缩与高质量的可视化重建，适用于大规模科学数据处理。

Abstract: The extensive adoption of Deep Neural Networks has led to their increased
utilization in challenging scientific visualization tasks. Recent advancements
in building compressed data models using implicit neural representations have
shown promising results for tasks like spatiotemporal volume visualization and
super-resolution. Inspired by these successes, we develop compressed neural
representations for multivariate datasets containing tens to hundreds of
variables. Our approach utilizes a single network to learn representations for
all data variables simultaneously through parameter sharing. This allows us to
achieve state-of-the-art data compression. Through comprehensive evaluations,
we demonstrate superior performance in terms of reconstructed data quality,
rendering and visualization quality, preservation of dependency information
among variables, and storage efficiency.

</details>


### [201] [ES-C51: Expected Sarsa Based C51 Distributional Reinforcement Learning Algorithm](https://arxiv.org/abs/2510.15006)
*Rijul Tandon,Peter Vamplew,Cameron Foale*

Main category: cs.LG

TL;DR: 本文提出了一种改进的分布强化学习算法ES-C51，用Expected Sarsa更新替代C51中的贪婪Q-learning更新，通过softmax策略整合所有动作信息，提升了策略稳定性与性能，在Gym经典控制任务和Atari-10游戏中表现优于改进后的QL-C51。


<details>
  <summary>Details</summary>
Motivation: 传统C51算法在动作期望回报相近但分布不同时可能学习不稳定，因依赖贪婪更新只选择单一最优动作，缺乏对动作分布差异的充分建模。

Method: 提出ES-C51算法，将C51中的贪婪Q-learning更新替换为Expected Sarsa更新，使用softmax计算综合所有动作的信息，从而更稳定地学习价值分布。

Result: 在Gym经典控制环境和Atari-10游戏上评估显示，ES-C51在多数环境中性能优于采用softmax探索的QL-C51。

Conclusion: 采用Expected Sarsa更新的ES-C51能有效缓解因动作期望相似导致的分布学习不稳定问题，提升策略学习效果，验证了非贪婪更新在分布强化学习中的优势。

Abstract: In most value-based reinforcement learning (RL) algorithms, the agent
estimates only the expected reward for each action and selects the action with
the highest reward. In contrast, Distributional Reinforcement Learning (DRL)
estimates the entire probability distribution of possible rewards, providing
richer information about uncertainty and variability. C51 is a popular DRL
algorithm for discrete action spaces. It uses a Q-learning approach, where the
distribution is learned using a greedy Bellman update. However, this can cause
problems if multiple actions at a state have similar expected reward but with
different distributions, as the algorithm may not learn a stable distribution.
This study presents a modified version of C51 (ES-C51) that replaces the greedy
Q-learning update with an Expected Sarsa update, which uses a softmax
calculation to combine information from all possible actions at a state rather
than relying on a single best action. This reduces instability when actions
have similar expected rewards and allows the agent to learn higher-performing
policies. This approach is evaluated on classic control environments from Gym,
and Atari-10 games. For a fair comparison, we modify the standard C51's
exploration strategy from e-greedy to softmax, which we refer to as QL-C51 (Q-
Learning based C51). The results demonstrate that ES-C51 outperforms QL-C51
across many environments.

</details>


### [202] [Hybrid Autoencoder-Based Framework for Early Fault Detection in Wind Turbines](https://arxiv.org/abs/2510.15010)
*Rekha R Nair,Tina Babu,Alavikunhu Panthakkan,Balamurugan Balusamy,Wathiq Mansoor*

Main category: cs.LG

TL;DR: 提出了一种基于集成深度学习的无监督风力涡轮机异常检测框架，结合VAE、LSTM和Transformer模型及多特征工程，在真实数据集上实现了0.947的AUC-ROC，并能提前48小时预警故障。


<details>
  <summary>Details</summary>
Motivation: 提高风力涡轮机可靠性，降低维护成本和停机时间，通过早期故障检测提升可再生能源系统的运行效率。

Method: 融合变分自编码器（VAE）、LSTM自编码器和Transformer架构，构建集成深度学习模型；设计特征工程流程提取时域、统计和频域特征，采用集成评分与自适应阈值进行无监督异常检测。

Result: 在包含89年实际数据的CARE数据集上测试，达到0.947的AUC-ROC，可提前48小时检测到故障，显著优于现有方法。

Conclusion: 该方法无需标注故障数据即可实现高效异常检测，有助于推动风力发电的预测性维护，提升大规模风电系统的可靠性和社会经济效益。

Abstract: Wind turbine reliability is critical to the growing renewable energy sector,
where early fault detection significantly reduces downtime and maintenance
costs. This paper introduces a novel ensemble-based deep learning framework for
unsupervised anomaly detection in wind turbines. The method integrates
Variational Autoencoders (VAE), LSTM Autoencoders, and Transformer
architectures, each capturing different temporal and contextual patterns from
high-dimensional SCADA data. A unique feature engineering pipeline extracts
temporal, statistical, and frequency-domain indicators, which are then
processed by the deep models. Ensemble scoring combines model predictions,
followed by adaptive thresholding to detect operational anomalies without
requiring labeled fault data. Evaluated on the CARE dataset containing 89 years
of real-world turbine data across three wind farms, the proposed method
achieves an AUC-ROC of 0.947 and early fault detection up to 48 hours prior to
failure. This approach offers significant societal value by enabling predictive
maintenance, reducing turbine failures, and enhancing operational efficiency in
large-scale wind energy deployments.

</details>


### [203] [AlignFlow: Improving Flow-based Generative Models with Semi-Discrete Optimal Transport](https://arxiv.org/abs/2510.15038)
*Lingkai Kong,Molei Tao,Yang Liu,Bryan Wang,Jinmiao Fu,Chien-Chih Wang,Huidong Liu*

Main category: cs.LG

TL;DR: 提出AlignFlow，一种基于半离散最优传输（SDOT）的流式生成模型训练方法，通过显式对齐噪声与数据点提升模型性能，具有可扩展性和即插即用特性。


<details>
  <summary>Details</summary>
Motivation: 现有基于最优传输的流式生成模型训练方法受限于小批量采样，难以扩展到大规模高维数据集，且流动轨迹不够高效。

Method: 引入半离散最优传输（SDOT），将噪声空间划分为拉格朗日单元，每个单元对应一个数据点，建立噪声分布与数据点之间的显式最优对齐，并在训练中通过SDOT映射配对独立同分布的噪声样本与数据点。

Result: AlignFlow在多种先进流式生成模型上提升了性能，具有良好扩展性，适用于大型数据集和大模型架构，计算开销极低。

Conclusion: AlignFlow通过SDOT实现了噪声与数据的最优对齐，显著提升流式生成模型的训练效率和生成质量，是一种通用、高效且可插拔的改进方案。

Abstract: Flow-based Generative Models (FGMs) effectively transform noise into complex
data distributions. Incorporating Optimal Transport (OT) to couple noise and
data during FGM training has been shown to improve the straightness of flow
trajectories, enabling more effective inference. However, existing OT-based
methods estimate the OT plan using (mini-)batches of sampled noise and data
points, which limits their scalability to large and high-dimensional datasets
in FGMs. This paper introduces AlignFlow, a novel approach that leverages
Semi-Discrete Optimal Transport (SDOT) to enhance the training of FGMs by
establishing an explicit, optimal alignment between noise distribution and data
points with guaranteed convergence. SDOT computes a transport map by
partitioning the noise space into Laguerre cells, each mapped to a
corresponding data point. During FGM training, i.i.d. noise samples are paired
with data points via the SDOT map. AlignFlow scales well to large datasets and
model architectures with negligible computational overhead. Experimental
results show that AlignFlow improves the performance of a wide range of
state-of-the-art FGM algorithms and can be integrated as a plug-and-play
component. Code is available at: https://github.com/konglk1203/AlignFlow.

</details>


### [204] [IQNN-CS: Interpretable Quantum Neural Network for Credit Scoring](https://arxiv.org/abs/2510.15044)
*Abdul Samad Khan,Nouhaila Innan,Aeysha Khalique,Muhammad Shafique*

Main category: cs.LG

TL;DR: 提出了一种可解释的量子神经网络框架IQNN-CS，用于多分类信用风险评估，结合变分量子神经网络和事后解释技术，并引入新的指标ICAA来量化不同类别间的归因差异，提升了模型透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习（QML）在金融等高风险领域应用受限于其黑箱特性，缺乏可解释性阻碍了其在需要透明和信任场景中的采用。因此，需要构建具备可解释性的QML模型以满足监管要求和实际应用需求。

Method: 提出IQNN-CS框架，结合变分量子神经网络与针对结构化数据设计的后验解释方法；引入Inter-Class Attribution Alignment（ICAA）指标，用于量化模型在不同预测类别之间的归因差异，从而揭示模型如何区分信用风险等级。

Result: 在两个真实世界信用数据集上验证了IQNN-CS具有稳定的训练动态、良好的预测性能以及更强的可解释性，ICAA有效揭示了模型决策依据。

Conclusion: IQNN-CS为实现透明、可问责的量子机器学习模型在金融决策中的应用提供了可行路径，推动QML向高监管领域落地。

Abstract: Credit scoring is a high-stakes task in financial services, where model
decisions directly impact individuals' access to credit and are subject to
strict regulatory scrutiny. While Quantum Machine Learning (QML) offers new
computational capabilities, its black-box nature poses challenges for adoption
in domains that demand transparency and trust. In this work, we present
IQNN-CS, an interpretable quantum neural network framework designed for
multiclass credit risk classification. The architecture combines a variational
QNN with a suite of post-hoc explanation techniques tailored for structured
data. To address the lack of structured interpretability in QML, we introduce
Inter-Class Attribution Alignment (ICAA), a novel metric that quantifies
attribution divergence across predicted classes, revealing how the model
distinguishes between credit risk categories. Evaluated on two real-world
credit datasets, IQNN-CS demonstrates stable training dynamics, competitive
predictive performance, and enhanced interpretability. Our results highlight a
practical path toward transparent and accountable QML models for financial
decision-making.

</details>


### [205] [Internalizing World Models via Self-Play Finetuning for Agentic RL](https://arxiv.org/abs/2510.15047)
*Shiqi Chen,Tongyao Zhu,Zian Wang,Jinghan Zhang,Kangrui Wang,Siyang Gao,Teng Xiao,Yee Whye Teh,Junxian He,Manling Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于自玩（Self-Play）的强化学习框架SPA，通过引入内部世界模型提升大语言模型在OOD环境中的决策能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在分布外（OOD）场景中表现不佳，传统强化学习训练难以扩展，探索脆弱且泛化能力有限。

Method: 将世界模型分解为状态表示和转移建模两部分，先通过Self-Play监督微调阶段冷启动策略以学习世界模型，再利用其模拟未来状态进行策略优化。

Result: 在Sokoban、FrozenLake和Sudoku等多个环境中实验表明，该方法显著提升性能，例如Qwen2.5-1.5B-Instruct模型在Sokoban的成功率从25.6%提升至59.8%，FrozenLake得分从22.1%提升至70.9%。

Conclusion: 引入内部世界模型并通过Self-Play初始化能有效增强LLM代理在复杂动态环境中的推理与决策能力，显著提高强化学习训练效果。

Abstract: Large Language Models (LLMs) as agents often struggle in out-of-distribution
(OOD) scenarios. Real-world environments are complex and dynamic, governed by
task-specific rules and stochasticity, which makes it difficult for LLMs to
ground their internal knowledge in those dynamics. Under such OOD conditions,
vanilla RL training often fails to scale; we observe Pass@k--the probability
that at least one of (k) sampled trajectories succeeds--drops markedly across
training steps, indicating brittle exploration and limited generalization.
Inspired by model-based reinforcement learning, we hypothesize that equipping
LLM agents with an internal world model can better align reasoning with
environmental dynamics and improve decision-making. We show how to encode this
world model by decomposing it into two components: state representation and
transition modeling. Building on this, we introduce SPA, a simple reinforcement
learning framework that cold-starts the policy via a Self-Play supervised
finetuning (SFT) stage to learn the world model by interacting with the
environment, then uses it to simulate future states prior to policy
optimization. This simple initialization outperforms the online world-modeling
baseline and greatly boosts the RL-based agent training performance.
Experiments across diverse environments like Sokoban, FrozenLake, and Sudoku
show that our approach significantly improves performance. For example, SPA
boosts the Sokoban success rate from 25.6% to 59.8% and raises the FrozenLake
score from 22.1% to 70.9% for the Qwen2.5-1.5B-Instruct model.

</details>


### [206] [Learn to Change the World: Multi-level Reinforcement Learning with Model-Changing Actions](https://arxiv.org/abs/2510.15056)
*Ziqing Lu,Babak Hassibi,Lifeng Lai,Weiyu Xu*

Main category: cs.LG

TL;DR: 本文提出了一种多层可配置时变马尔可夫决策过程（MCTVMDP），允许智能体通过改变环境动态模型来主动优化长期奖励。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习假设环境固定，智能体只能被动适应；本文旨在研究智能体如何通过主动改变环境模型来提升性能。

Method: 引入MCTVMDP框架，包含上下两层：上层负责通过模型改变动作配置环境动态，下层执行基本动作；联合优化上下层策略以最大化长期折扣奖励。

Result: 智能体不仅能优化行为策略，还能主动调整环境转移函数，从而在非平稳环境中获得更高回报。

Conclusion: MCTVMDP为具有环境改造能力的智能体提供了统一建模框架，扩展了传统强化学习的边界。

Abstract: Reinforcement learning usually assumes a given or sometimes even fixed
environment in which an agent seeks an optimal policy to maximize its long-term
discounted reward. In contrast, we consider agents that are not limited to
passive adaptations: they instead have model-changing actions that actively
modify the RL model of world dynamics itself. Reconfiguring the underlying
transition processes can potentially increase the agents' rewards. Motivated by
this setting, we introduce the multi-layer configurable time-varying Markov
decision process (MCTVMDP). In an MCTVMDP, the lower-level MDP has a
non-stationary transition function that is configurable through upper-level
model-changing actions. The agent's objective consists of two parts: Optimize
the configuration policies in the upper-level MDP and optimize the primitive
action policies in the lower-level MDP to jointly improve its expected
long-term reward.

</details>


### [207] [Antislop: A Comprehensive Framework for Identifying and Eliminating Repetitive Patterns in Language Models](https://arxiv.org/abs/2510.15061)
*Samuel Paech,Allen Roush,Judah Goldfeder,Ravid Shwartz-Ziv*

Main category: cs.LG

TL;DR: 本文提出了Antislop框架，用于检测和消除大语言模型（LLM）生成文本中的重复性表达（称为“slop”），通过反向采样、自动化数据生成和新型微调方法FTPO，显著减少slop而不损害生成质量。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，其生成文本中出现大量重复、模式化的表达（slop），影响输出质量并使AI内容易于识别，亟需有效抑制方法。

Method: 提出Antislop框架，包含三部分：1) Antislop Sampler在推理时通过回溯抑制特定字符串；2) 自动化流程分析模型特有slop并生成训练数据；3) 提出最终令牌偏好优化（FTPO），基于推理轨迹对单个token进行精细化logit调整。

Result: 实验显示，某些slop在LLM输出中比人类文本高出1000倍以上；Antislop Sampler可成功抑制8000多个模式且保持质量，而传统词元屏蔽在2000个即失效；FTPO实现90%的slop减少，在GSM8K、MMLU和创意写作等跨领域任务中性能保持或提升，优于DPO方法。

Conclusion: Antislop框架有效解决了LLM生成文本中slop问题，尤其FTPO在不牺牲性能的前提下实现高度抑制，为提升生成文本自然性和多样性提供了实用方案。

Abstract: Widespread LLM adoption has introduced characteristic repetitive phraseology,
termed ``slop,'' which degrades output quality and makes AI-generated text
immediately recognizable. We present Antislop, a comprehensive framework
providing tools to both detect and eliminate these overused patterns. Our
approach combines three innovations: (1) The Antislop Sampler, which uses
backtracking to suppress unwanted strings at inference time without destroying
vocabulary; (2) An automated pipeline that profiles model-specific slop against
human baselines and generates training data; (3) Final Token Preference
Optimization (FTPO), a novel fine-tuning method that operates on individual
tokens, surgically adjusting logits wherever a banned pattern has appeared in
an inference trace. We demonstrate that some slop patterns appear over
1,000$\times$ more frequently in LLM output than human text. The Antislop
Sampler successfully suppresses 8,000+ patterns while maintaining quality,
whereas token banning becomes unusable at just 2,000. Most importantly, FTPO
achieves 90\% slop reduction while maintaining or improving performance in
cross-domain evals including GSM8K, MMLU, and creative writing tasks. In
contrast, DPO suffers significant degradation in writing quality and lexical
diversity despite achieving weaker suppression. We release all code and results
under MIT license: https://github.com/sam-paech/auto-antislop.

</details>


### [208] [Physics-informed data-driven machine health monitoring for two-photon lithography](https://arxiv.org/abs/2510.15075)
*Sixian Jia,Zhiqiao Dong,Chenhui Shao*

Main category: cs.LG

TL;DR: 本文提出三种基于物理信息和数据驱动的统计模型，用于精确及时地监测双光子光刻（TPL）系统的健康状态，实现了高准确性、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的TPL系统维护依赖经验，导致维护不及时或过度维护，影响制造质量和效率，亟需基于状态的智能监测方法。

Method: 结合物理信息的数据驱动预测模型与统计方法，构建三种TPL设备健康监测方法，并在包含多种工艺参数和结构尺寸的实验数据集上进行验证。

Result: 所提方法在不同测试场景下均表现出高准确率，能够有效识别两种机器健康状态，具有良好的鲁棒性和泛化性。

Conclusion: 该研究为实现TPL系统的状态监测与预测性维护提供了有效方案，推动了微纳制造中的智能化运维发展。

Abstract: Two-photon lithography (TPL) is a sophisticated additive manufacturing
technology for creating three-dimensional (3D) micro- and nano-structures.
Maintaining the health of TPL systems is critical for ensuring consistent
fabrication quality. Current maintenance practices often rely on experience
rather than informed monitoring of machine health, resulting in either untimely
maintenance that causes machine downtime and poor-quality fabrication, or
unnecessary maintenance that leads to inefficiencies and avoidable downtime. To
address this gap, this paper presents three methods for accurate and timely
monitoring of TPL machine health. Through integrating physics-informed
data-driven predictive models for structure dimensions with statistical
approaches, the proposed methods are able to handle increasingly complex
scenarios featuring different levels of generalizability. A comprehensive
experimental dataset that encompasses six process parameter combinations and
six structure dimensions under two machine health conditions was collected to
evaluate the effectiveness of the proposed approaches. Across all test
scenarios, the approaches are shown to achieve high accuracies, demonstrating
excellent effectiveness, robustness, and generalizability. These results
represent a significant step toward condition-based maintenance for TPL
systems.

</details>


### [209] [Online Correlation Clustering: Simultaneously Optimizing All $\ell_p$-norms](https://arxiv.org/abs/2510.15076)
*Sami Davies,Benjamin Moseley,Heather Newman*

Main category: cs.LG

TL;DR: 本文提出了一种在线学习模型下的相关聚类算法，能够在所有$\ell_p$-范数下同时实现近似最优的竞争比，首次将离线场景中的“全范数”保证成功迁移到在线场景。


<details>
  <summary>Details</summary>
Motivation: 在相关聚类中，$\ell_p$-范数目标在最小化总分歧（$\ell_1$）与个体节点公平性（$\ell_\infty$）之间存在根本权衡。已有工作在离线场景下实现了对所有范数的同时近似，但在线场景下是否可行尚无答案。此外，作者证明在标准随机顺序模型中，$\ell_\infty$-范数存在$\Omega(n^{1/3})$的下界，说明需要更强的模型假设。

Method: 采用在线带样本（AOS）模型，利用输入的一小部分作为样本设计统一聚类算法，并结合多尺度分析和概率论证来同时处理所有$\ell_p$-范数目标。

Result: 所提算法以高概率在所有$\ell_p$-范数下达到$O(\log^4 n)$-竞争比，在$\ell_\infty$-范数下为$O(\log n)$-竞争比，且在期望意义下对$\ell_1$-范数为$O(1)$-竞争比；并证明这些结果在AOS模型中接近紧确。

Conclusion: 本文首次实现了在线环境下对相关聚类所有$\ell_p$-范数的同时近似，验证了AOS模型的有效性，并揭示了不同在线模型之间的本质差异。

Abstract: The $\ell_p$-norm objectives for correlation clustering present a fundamental
trade-off between minimizing total disagreements (the $\ell_1$-norm) and
ensuring fairness to individual nodes (the $\ell_\infty$-norm). Surprisingly,
in the offline setting it is possible to simultaneously approximate all
$\ell_p$-norms with a single clustering. Can this powerful guarantee be
achieved in an online setting? This paper provides the first affirmative
answer. We present a single algorithm for the online-with-a-sample (AOS) model
that, given a small constant fraction of the input as a sample, produces one
clustering that is simultaneously $O(\log^4 n)$-competitive for all
$\ell_p$-norms with high probability, $O(\log n)$-competitive for the
$\ell_\infty$-norm with high probability, and $O(1)$-competitive for the
$\ell_1$-norm in expectation. This work successfully translates the offline
"all-norms" guarantee to the online world.
  Our setting is motivated by a new hardness result that demonstrates a
fundamental separation between these objectives in the standard random-order
(RO) online model. Namely, while the $\ell_1$-norm is trivially
$O(1)$-approximable in the RO model, we prove that any algorithm in the RO
model for the fairness-promoting $\ell_\infty$-norm must have a competitive
ratio of at least $\Omega(n^{1/3})$. This highlights the necessity of a
different beyond-worst-case model. We complement our algorithm with lower
bounds, showing our competitive ratios for the $\ell_1$- and $\ell_\infty$-
norms are nearly tight in the AOS model.

</details>


### [210] [Operator Flow Matching for Timeseries Forecasting](https://arxiv.org/abs/2510.15101)
*Yolanne Yi Ran Lee,Kyriakos Flouris*

Main category: cs.LG

TL;DR: 提出TempO模型，一种基于流匹配的高效方法，用于高维PDE动力学预测，结合稀疏条件和通道折叠，在三个基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自回归和扩散模型在长期物理一致性预测中存在累积误差和离散化伪影问题，难以高效准确地建模高维PDE动力学。

Method: 提出TempO，一种潜在流匹配模型，采用时间条件傅里叶层与稀疏条件和通道折叠机制，实现对3D时空场的高效处理和多尺度模式的高保真捕捉。

Result: TempO在三个PDE基准数据集上性能超越最先进的基线模型，频谱分析显示其能更优恢复多尺度动态，且具有更低的参数量和内存占用。

Conclusion: TempO通过流匹配和结构设计实现了高效、精确的PDE动力学预测，为高维物理系统建模提供了新思路。

Abstract: Forecasting high-dimensional, PDE-governed dynamics remains a core challenge
for generative modeling. Existing autoregressive and diffusion-based approaches
often suffer cumulative errors and discretisation artifacts that limit long,
physically consistent forecasts. Flow matching offers a natural alternative,
enabling efficient, deterministic sampling. We prove an upper bound on FNO
approximation error and propose TempO, a latent flow matching model leveraging
sparse conditioning with channel folding to efficiently process 3D
spatiotemporal fields using time-conditioned Fourier layers to capture
multi-scale modes with high fidelity. TempO outperforms state-of-the-art
baselines across three benchmark PDE datasets, and spectral analysis further
demonstrates superior recovery of multi-scale dynamics, while efficiency
studies highlight its parameter- and memory-light design compared to
attention-based or convolutional regressors.

</details>


### [211] [DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning](https://arxiv.org/abs/2510.15110)
*Shih-Yang Liu,Xin Dong,Ximing Lu,Shizhe Diao,Mingjie Liu,Min-Hung Chen,Hongxu Yin,Yu-Chiang Frank Wang,Kwang-Ting Cheng,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.LG

TL;DR: 本文提出了一种名为DLER的强化学习训练方法，通过简单的截断长度惩罚和优化策略，显著提升了推理语言模型在准确性和效率之间的权衡，实现了更短的输出长度和更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的推理语言模型虽然性能强大，但往往生成过长的输出，如何在保证准确性的前提下减少输出长度仍是一个开放问题。

Method: 提出了DLER方法，结合批归一化奖励、高剪切、动态采样和简单截断长度惩罚，解决了优势估计偏差、熵崩溃和稀疏奖励信号三个挑战。同时引入了难度感知的DLER和更新选择性合并方法。

Result: DLER在多个基准上实现了最先进的准确率-效率权衡，输出长度减少了70%以上，并且在测试时扩展性方面优于DeepSeek-R1-7B，准确率提高28%，延迟更低。

Conclusion: 通过正确的长度惩罚设计和强化学习优化，可以在不牺牲甚至提升准确率的前提下大幅压缩模型输出长度，为高效推理提供了有效解决方案。

Abstract: Reasoning language models such as OpenAI-o1, DeepSeek-R1, and Qwen achieve
strong performance via extended chains of thought but often generate
unnecessarily long outputs. Maximizing intelligence per token--accuracy
relative to response length--remains an open problem. We revisit reinforcement
learning (RL) with the simplest length penalty--truncation--and show that
accuracy degradation arises not from the lack of sophisticated penalties but
from inadequate RL optimization. We identify three key challenges: (i) large
bias in advantage estimation, (ii) entropy collapse, and (iii) sparse reward
signal. We address them with Doing Length pEnalty Right (DLER), a training
recipe combining batch-wise reward normalization, higher clipping, dynamic
sampling, and a simple truncation length penalty. DLER achieves
state-of-the-art accuracy--efficiency trade-offs, cutting output length by over
70 percent while surpassing all previous baseline accuracy. It also improves
test-time scaling: compared to DeepSeek-R1-7B, DLER-7B generates multiple
concise responses in parallel with 28 percent higher accuracy and lower
latency. We further introduce Difficulty-Aware DLER, which adaptively tightens
truncation on easier questions for additional efficiency gains. We also propose
an update-selective merging method that preserves baseline accuracy while
retaining the concise reasoning ability of the DLER model, which is useful for
scenarios where RL training data is scarce.

</details>


### [212] [Navigating the consequences of mechanical ventilation in clinical intensive care settings through an evolutionary game-theoretic framework](https://arxiv.org/abs/2510.15127)
*David J. Albers,Tell D. Bennett,Jana de Wiljes,Bradford J. Smith,Peter D. Sottile,J. N. Stroh*

Main category: cs.LG

TL;DR: 本文提出了一种基于进化博弈论的框架，用于分析机械通气（MV）及辅助治疗决策对患者预后的影响，旨在通过合成和真实ICU数据验证方法的有效性，并推动MV治疗的个性化与优化。


<details>
  <summary>Details</summary>
Motivation: 由于患者-呼吸机系统的异质性和临床决策环境的复杂性，亟需一种系统性方法来理解机械通气策略的效果，并利用现有临床数据生成改进重症呼吸管理的新假设。

Method: 引入“联合患者-呼吸机-护理系统”（J6）视角，采用进化博弈论（EGT）分析呼吸行为，并结合概率与随机方法（如强化学习）进行深入分析，首先在合成数据上进行解析验证，再应用于真实ICU数据。

Result: 建立了可扩展的数据分析方法，揭示了J6系统中的数据生成复杂性，为机械通气决策的建模提供了定量基础，并初步实现了向MV个性化优化的迈进。

Conclusion: 基于EGT的分析框架有助于理解复杂患者-呼吸机交互过程，是实现机械通气优化和个性化治疗的重要一步，未来可结合经验与博弈论元素构建状态转移模型以模拟MV决策效果。

Abstract: Identifying the effects of mechanical ventilation strategies and protocols in
critical care requires analyzing data from heterogeneous patient-ventilator
systems within the context of the clinical decision-making environment. This
research develops a framework to help understand the consequences of mechanical
ventilation (MV) and adjunct care decisions on patient outcome from
observations of critical care patients receiving MV. Developing an
understanding of and improving critical care respiratory management requires
the analysis of existing secondary-use clinical data to generate hypotheses
about advantageous variations and adaptations of current care. This work
introduces a perspective of the joint patient-ventilator-care systems
(so-called J6) to develop a scalable method for analyzing data and trajectories
of these complex systems. To that end, breath behaviors are analyzed using
evolutionary game theory (EGT), which generates the necessary quantitative
precursors for deeper analysis through probabilistic and stochastic machinery
such as reinforcement learning. This result is one step along the pathway
toward MV optimization and personalization. The EGT-based process is
analytically validated on synthetic data to reveal potential caveats before
proceeding to real-world ICU data applications that expose complexities of the
data-generating process J6. The discussion includes potential developments
toward a state transition model for the simulating effects of MV decision using
empirical and game-theoretic elements.

</details>


### [213] [A Simple Method for PMF Estimation on Large Supports](https://arxiv.org/abs/2510.15132)
*Alex Shtoff*

Main category: cs.LG

TL;DR: 提出一种基于图拉普拉斯低通滤波的非参数概率质量函数估计方法，适用于多模态、重尾分布，在保持粗粒度结构的同时有效抑制噪声。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理大离散支撑空间上的多模态、重尾PMF时难以兼顾平滑性与结构保持，需要更鲁棒且自动化的估计方法。

Method: 将经验PMF视为路径图上的信号，构造由图拉普拉斯和对角扰动矩阵组成的对称三对角算子，通过计算其最小特征值对应的特征向量构建低维子空间，将经验PMF投影至此空间并进行截断重归一化以获得平滑估计。

Result: 该方法在合成与真实重尾数据上能有效保留粗结构并抑制采样噪声，性能优于logspline和高斯核密度估计，在计算效率和稳定性方面表现良好，且可通过数据驱动规则自动选择降维维度。

Conclusion: 该方法实现简洁、鲁棒性强、计算高效，适合大规模自动化流程和探索性分析，但在突变不连续等情形下存在失效风险。

Abstract: We study nonparametric estimation of a probability mass function (PMF) on a
large discrete support, where the PMF is multi-modal and heavy-tailed. The core
idea is to treat the empirical PMF as a signal on a line graph and apply a
data-dependent low-pass filter. Concretely, we form a symmetric tri-diagonal
operator, the path graph Laplacian perturbed with a diagonal matrix built from
the empirical PMF, then compute the eigenvectors, corresponding to the smallest
feq eigenvalues. Projecting the empirical PMF onto this low dimensional
subspace produces a smooth, multi-modal estimate that preserves coarse
structure while suppressing noise. A light post-processing step of clipping and
re-normalizing yields a valid PMF.
  Because we compute the eigenpairs of a symmetric tridiagonal matrix, the
computation is reliable and runs time and memory proportional to the support
times the dimension of the desired low-dimensional supspace. We also provide a
practical, data-driven rule for selecting the dimension based on an
orthogonal-series risk estimate, so the method "just works" with minimal
tuning. On synthetic and real heavy-tailed examples, the approach preserves
coarse structure while suppressing sampling noise, compares favorably to
logspline and Gaussian-KDE baselines in the intended regimes. However, it has
known failure modes (e.g., abrupt discontinuities). The method is short to
implement, robust across sample sizes, and suitable for automated pipelines and
exploratory analysis at scale because of its reliability and speed.

</details>


### [214] [Predicting the Unpredictable: Reproducible BiLSTM Forecasting of Incident Counts in the Global Terrorism Database (GTD)](https://arxiv.org/abs/2510.15136)
*Oluwasegun Adegoke*

Main category: cs.LG

TL;DR: 该研究使用全球恐怖主义数据库（GTD）对每周恐怖事件数量进行短期预测，提出基于BiLSTM的可复现模型，并在测试集上显著优于传统方法和LSTM-Attention基线。


<details>
  <summary>Details</summary>
Motivation: 现有恐怖主义事件预测多聚焦长期趋势，缺乏对短期动态的建模；同时缺少公开、可复现的基准方法。本研究旨在建立透明、高性能的短期预测基准。

Method: 采用固定时间划分的可复现流水线，构建双向LSTM（BiLSTM）模型，与季节性朴素法、线性/ARIMA及LSTM-Attention等基线对比；通过消融实验分析时间记忆、历史长度、空间粒度、回看窗口和特征组的影响。

Result: BiLSTM在测试集上达到RMSE 6.38，较LSTM-Attention提升30.6%，较线性回归提升35.4%，且在MAE和MAPE指标上均有改善；长历史训练数据、适度回看窗口（20–30周）和双向编码被证明关键；滞后计数和滚动统计特征贡献最大。

Conclusion: BiLSTM能有效捕捉恐怖事件短期波动模式，为GTD数据上的短期预测提供了可复现、性能超越基线的新参考方案。

Abstract: We study short-horizon forecasting of weekly terrorism incident counts using
the Global Terrorism Database (GTD, 1970--2016). We build a reproducible
pipeline with fixed time-based splits and evaluate a Bidirectional LSTM
(BiLSTM) against strong classical anchors (seasonal-naive, linear/ARIMA) and a
deep LSTM-Attention baseline. On the held-out test set, the BiLSTM attains RMSE
6.38, outperforming LSTM-Attention (9.19; +30.6\%) and a linear lag-regression
baseline (+35.4\% RMSE gain), with parallel improvements in MAE and MAPE.
Ablations varying temporal memory, training-history length, spatial grain,
lookback size, and feature groups show that models trained on long historical
data generalize best; a moderate lookback (20--30 weeks) provides strong
context; and bidirectional encoding is critical for capturing both build-up and
aftermath patterns within the window. Feature-group analysis indicates that
short-horizon structure (lagged counts and rolling statistics) contributes
most, with geographic and casualty features adding incremental lift. We release
code, configs, and compact result tables, and provide a data/ethics statement
documenting GTD licensing and research-only use. Overall, the study offers a
transparent, baseline-beating reference for GTD incident forecasting.

</details>


### [215] [Policy Transfer Ensures Fast Learning for Continuous-Time LQR with Entropy Regularization](https://arxiv.org/abs/2510.15165)
*Xin Guo,Zijiu Lyu*

Main category: cs.LG

TL;DR: 本文研究了连续时间线性二次调节器（LQR）中基于熵正则化的策略迁移理论，首次证明了一个LQR任务中的最优策略可作为相近LQR任务的近似最优初始化，并保持原有收敛速度，同时提出了一种具有全局线性和局部超线性收敛的新算法。


<details>
  <summary>Details</summary>
Motivation: 在复杂任务中从零开始训练强化学习策略效率低下，而迁移学习在大模型中已展现潜力，因此本文旨在为连续时间RL提供理论支持，填补离散时间到连续时间迁移学习的理论空白。

Method: 采用策略迁移方法，利用源任务的最优LQR策略初始化目标任务，并结合熵正则化设计新算法，通过理论分析证明其在连续时间下的近似最优性和收敛性。

Result: 首次给出了连续时间RL中策略迁移的理论证明，表明源策略在相近LQR中是近似最优初始化且不改变收敛速率；提出的新算法实现了全局线性与局部超线性收敛；并间接证明了一类连续时间扩散模型的稳定性。

Conclusion: 迁移学习在连续时间强化学习中具有理论保障和实际效益，策略迁移能显著提升学习效率，所提算法性能优越，同时揭示了LQR与扩散模型之间的稳定性联系。

Abstract: Reinforcement Learning (RL) enables agents to learn optimal decision-making
strategies through interaction with an environment, yet training from scratch
on complex tasks can be highly inefficient. Transfer learning (TL), widely
successful in large language models (LLMs), offers a promising direction for
enhancing RL efficiency by leveraging pre-trained models.
  This paper investigates policy transfer, a TL approach that initializes
learning in a target RL task using a policy from a related source task, in the
context of continuous-time linear quadratic regulators (LQRs) with entropy
regularization. We provide the first theoretical proof of policy transfer for
continuous-time RL, proving that a policy optimal for one LQR serves as a
near-optimal initialization for closely related LQRs, while preserving the
original algorithm's convergence rate. Furthermore, we introduce a novel policy
learning algorithm for continuous-time LQRs that achieves global linear and
local super-linear convergence. Our results demonstrate both theoretical
guarantees and algorithmic benefits of transfer learning in continuous-time RL,
addressing a gap in existing literature and extending prior work from discrete
to continuous time settings.
  As a byproduct of our analysis, we derive the stability of a class of
continuous-time score-based diffusion models via their connection with LQRs.

</details>


### [216] [A simple mean field model of feature learning](https://arxiv.org/abs/2510.15174)
*Niclas Göring,Chris Mingard,Yoonsoo Nam,Ard Louis*

Main category: cs.LG

TL;DR: 提出了一种自洽平均场理论来研究有限宽度下神经网络的特征学习，发现对称性破缺相变，并引入自增强输入特征选择机制以准确预测泛化性能。


<details>
  <summary>Details</summary>
Motivation: 理解特征学习在有限宽度神经网络中的出现机制及其对泛化性能的影响。

Method: 结合统计物理方法，推导出使用随机梯度朗之万动力学训练的两层非线性网络的贝叶斯后验的平均场理论，并改进该理论以包含自增强输入特征选择机制。

Result: 发现了网络在有限宽度下会突然与目标函数对齐的相变现象，原始平均场理论能半定量预测特征学习的起始点，但低估了过渡后的泛化提升；加入新机制后可定量匹配学习曲线。

Conclusion: 自增强输入特征选择是特征学习中关键且被先前理论忽略的机制，纳入该机制后理论能准确描述实际学习过程。

Abstract: Feature learning (FL), where neural networks adapt their internal
representations during training, remains poorly understood. Using methods from
statistical physics, we derive a tractable, self-consistent mean-field (MF)
theory for the Bayesian posterior of two-layer non-linear networks trained with
stochastic gradient Langevin dynamics (SGLD). At infinite width, this theory
reduces to kernel ridge regression, but at finite width it predicts a symmetry
breaking phase transition where networks abruptly align with target functions.
While the basic MF theory provides theoretical insight into the emergence of FL
in the finite-width regime, semi-quantitatively predicting the onset of FL with
noise or sample size, it substantially underestimates the improvements in
generalisation after the transition. We trace this discrepancy to a key
mechanism absent from the plain MF description: \textit{self-reinforcing input
feature selection}. Incorporating this mechanism into the MF theory allows us
to quantitatively match the learning curves of SGLD-trained networks and
provides mechanistic insight into FL.

</details>


### [217] [Finding geodesics with the Deep Ritz method](https://arxiv.org/abs/2510.15177)
*Conor Rowan*

Main category: cs.LG

TL;DR: 本文探讨了测地线问题在科学机器学习中的应用潜力，提出深度Ritz方法特别适合解决具有几何结构、变分性质和自然非线性的测地线问题，并通过路径规划、光学和固体力学三个数值实例验证了这一观点。


<details>
  <summary>Details</summary>
Motivation: 测地线问题广泛存在于物理和工程领域，但科学机器学习社区对其关注较少。本文旨在探索深度Ritz方法在该类问题中的适用性，填补研究空白。

Method: 利用深度Ritz方法结合测地线问题的变分结构，通过最小化能量泛函求解最优轨迹，并在不同领域设计数值实验进行验证。

Result: 在路径规划、光学和固体力学三个案例中，深度Ritz方法均能有效求解测地线问题，展现出良好的适应性和精度。

Conclusion: 测地线问题是深度Ritz方法的一个有前景的应用方向，也为科学机器学习提供了新的研究路径。

Abstract: Geodesic problems involve computing trajectories between prescribed initial
and final states to minimize a user-defined measure of distance, cost, or
energy. They arise throughout physics and engineering -- for instance, in
determining optimal paths through complex environments, modeling light
propagation in refractive media, and the study of spacetime trajectories in
control theory and general relativity. Despite their ubiquity, the scientific
machine learning (SciML) community has given relatively little attention to
investigating its methods in the context of these problems. In this work, we
argue that given their simple geometry, variational structure, and natural
nonlinearity, geodesic problems are particularly well-suited for the Deep Ritz
method. We substantiate this claim with three numerical examples drawn from
path planning, optics, and solid mechanics. Our goal is not to provide an
exhaustive study of geodesic problems, but rather to identify a promising
application of the Deep Ritz method and a fruitful direction for future SciML
research.

</details>


### [218] [An Advanced Two-Stage Model with High Sensitivity and Generalizability for Prediction of Hip Fracture Risk Using Multiple Datasets](https://arxiv.org/abs/2510.15179)
*Shuo Sun,Meiling Zhou,Chen Zhao,Joyce H. Keyak,Nancy E. Lane,Jeffrey D. Deng,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Kui Zhang,Weihua Zhou*

Main category: cs.LG

TL;DR: 提出一种结合临床和影像信息的两阶段模型，用于提高髋部骨折风险预测的敏感性，相较于传统的DXA T-score和FRAX方法，能更有效地识别高风险个体。


<details>
  <summary>Details</summary>
Motivation: 现有工具如DXA T-score和FRAX在识别无 prior 骨折或骨量减少个体的髋部骨折风险时敏感性不足，容易漏诊高风险人群。

Method: 采用来自MrOS、SOF和UK Biobank的数据，构建两阶段模型：第一阶段使用临床、人口学和功能变量进行初步风险评估，第二阶段结合DXA衍生特征进行精细化预测。

Result: 该模型在内部和外部验证中表现稳定，在不同队列中具有一致性和适应性，相比T-score和FRAX具有更高的敏感性和更少的漏诊病例。

Conclusion: 两阶段模型提供了一种更具成本效益和个性化的早期髋部骨折风险评估方法，有助于改善当前筛查工具的局限性。

Abstract: Hip fractures are a major cause of disability, mortality, and healthcare
burden in older adults, underscoring the need for early risk assessment.
However, commonly used tools such as the DXA T-score and FRAX often lack
sensitivity and miss individuals at high risk, particularly those without prior
fractures or with osteopenia. To address this limitation, we propose a
sequential two-stage model that integrates clinical and imaging information to
improve prediction accuracy. Using data from the Osteoporotic Fractures in Men
Study (MrOS), the Study of Osteoporotic Fractures (SOF), and the UK Biobank,
Stage 1 (Screening) employs clinical, demographic, and functional variables to
estimate baseline risk, while Stage 2 (Imaging) incorporates DXA-derived
features for refinement. The model was rigorously validated through internal
and external testing, showing consistent performance and adaptability across
cohorts. Compared to T-score and FRAX, the two-stage framework achieved higher
sensitivity and reduced missed cases, offering a cost-effective and
personalized approach for early hip fracture risk assessment.
  Keywords: Hip Fracture, Two-Stage Model, Risk Prediction, Sensitivity, DXA,
FRAX

</details>


### [219] [Automotive Crash Dynamics Modeling Accelerated with Machine Learning](https://arxiv.org/abs/2510.15201)
*Mohammad Amin Nabian,Sudeep Chavare,Deepak Akhare,Rishikesh Ranade,Ram Cherukuri,Srinivas Tadepalli*

Main category: cs.LG

TL;DR: 本研究探索了使用NVIDIA PhysicsNeMo框架开发基于机器学习的替代模型，以高效预测汽车碰撞中的结构变形。


<details>
  <summary>Details</summary>
Motivation: 传统高保真有限元仿真计算成本高、耗时长，限制了设计迭代效率，因此需要一种更高效的替代方法用于碰撞安全性评估。

Method: 采用MeshGraphNet和Transolver两种先进的神经网络架构，并结合三种瞬态动力学建模策略（时间条件法、标准自回归法及增强稳定性自回归法），在包含150个LS-DYNA仿真的BIW碰撞数据集上进行训练与评估。

Result: 模型能够合理准确地捕捉整体变形趋势，虽未达到全有限元精度，但计算成本降低了几个数量级，显著提升了预测速度。

Conclusion: 研究表明，所探索的机器学习方法在结构碰撞动力学建模中具有可行性与工程应用价值，可用于快速设计探索和早期优化。

Abstract: Crashworthiness assessment is a critical aspect of automotive design,
traditionally relying on high-fidelity finite element (FE) simulations that are
computationally expensive and time-consuming. This work presents an exploratory
comparative study on developing machine learning-based surrogate models for
efficient prediction of structural deformation in crash scenarios using the
NVIDIA PhysicsNeMo framework. Given the limited prior work applying machine
learning to structural crash dynamics, the primary contribution lies in
demonstrating the feasibility and engineering utility of the various modeling
approaches explored in this work. We investigate two state-of-the-art neural
network architectures for modeling crash dynamics: MeshGraphNet, and
Transolver. Additionally, we examine three strategies for modeling transient
dynamics: time-conditional, the standard Autoregressive approach, and a
stability-enhanced Autoregressive scheme incorporating rollout-based training.
The models are evaluated on a comprehensive Body-in-White (BIW) crash dataset
comprising 150 detailed FE simulations using LS-DYNA. The dataset represents a
structurally rich vehicle assembly with over 200 components, including 38 key
components featuring variable thickness distributions to capture realistic
manufacturing variability. Each model utilizes the undeformed mesh geometry and
component characteristics as inputs to predict the spatiotemporal evolution of
the deformed mesh during the crash sequence. Evaluation results show that the
models capture the overall deformation trends with reasonable fidelity,
demonstrating the feasibility of applying machine learning to structural crash
dynamics. Although not yet matching full FE accuracy, the models achieve
orders-of-magnitude reductions in computational cost, enabling rapid design
exploration and early-stage optimization in crashworthiness evaluation.

</details>


### [220] [Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection](https://arxiv.org/abs/2510.15202)
*Denis Janiak,Jakub Binkowski,Tomasz Kajdanowicz*

Main category: cs.LG

TL;DR: 本文研究了深度学习模型中分布外检测（OOD）的表现，特别关注马氏距离方法在不同表示几何和归一化方案下的性能。作者发现马氏方法并非普遍可靠，并提出通过谱特性和本征维度指标可预测OOD性能。基于此，他们提出了径向缩放的ℓ2归一化方法，通过调节特征空间的径向几何结构显著提升OOD检测效果。


<details>
  <summary>Details</summary>
Motivation: 马氏距离方法虽广泛用于OOD检测，但其受表示几何和归一化方式影响的机制尚不明确，限制了实际应用。因此，需系统研究这些因素对OOD性能的影响，并提出更优的归一化策略。

Method: 作者在多种图像基础模型、数据集和距离归一化方案上进行了实证研究，分析表示几何与OOD性能的关系，并提出径向缩放ℓ2归一化方法，引入可调参数控制特征空间的径向结构。

Result: 1) 马氏方法并非在所有情况下都可靠；2) 谱特性和本征维度可有效预测OOD性能；3) 所提径向缩放ℓ2归一化能显著提升OOD检测表现。

Conclusion: 表示几何和归一化方式对OOD检测至关重要。通过调控特征空间的径向结构，可以系统性改善OOD检测性能，为构建更可靠深度学习模型提供了新思路。

Abstract: Out-of-distribution (OOD) detection is critical for the reliable deployment
of deep learning models. hile Mahalanobis distance methods are widely used, the
impact of representation geometry and normalization on their performance is not
fully understood, which may limit their downstream application. To address this
gap, we conducted a comprehensive empirical study across diverse image
foundation models, datasets, and distance normalization schemes. First, our
analysis shows that Mahalanobis-based methods aren't universally reliable.
Second, we define the ideal geometry for data representations and demonstrate
that spectral and intrinsic-dimensionality metrics can accurately predict a
model's OOD performance. Finally, we analyze how normalization impacts OOD
performance. Building upon these studies, we propose radially scaled $\ell_2$
normalization, a method that generalizes the standard $\ell_2$ normalization
recently applied to Mahalanobis-based OOD detection. Our approach introduces a
tunable parameter to directly control the radial geometry of the feature space,
systematically contracting or expanding representations to significantly
improve OOD detection performance. By bridging the gap between representation
geometry, normalization, and OOD performance, our findings offer new insights
into the design of more effective and reliable deep learning models.

</details>


### [221] [ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning](https://arxiv.org/abs/2510.15211)
*Yongchan Kwon,Shang Zhu,Federico Bianchi,Kaitlyn Zhou,James Zou*

Main category: cs.LG

TL;DR: 本文提出了ReasonIF基准，用于评估大推理模型（LRM）在推理过程中遵循用户指令的能力，发现现有模型在多类别指令下的遵从率普遍低于25%，并探索了多轮推理和基于合成数据的指令微调（RIF）两种改进方法。


<details>
  <summary>Details</summary>
Motivation: 确保大推理模型在整个推理过程中遵循用户指令，以提升模型的可控性、透明性，并减少幻觉、捷径行为和奖励欺骗等风险。

Method: 构建包含六类指令提示的系统性基准ReasonIF，评估多个开源大推理模型的表现；提出多轮推理和基于合成数据的推理指令微调（RIF）两种增强策略。

Result: 现有模型的推理指令遵从得分（IFS）普遍低于0.25，且随任务难度增加而下降；通过RIF方法，GPT-OSS-20B的IFS从0.11提升至0.27。

Conclusion: 当前大推理模型在推理过程中对用户指令的遵循能力严重不足，需进一步研究提升其指令遵从性，RIF等方法显示出一定潜力但仍有改进空间。

Abstract: The ability of large language models (LLMs) to follow user instructions is
central to their reliability, safety, and usefulness. While prior studies
assess instruction adherence in the model's main responses, we argue that it is
also critical for large reasoning models (LRMs) to follow user instructions
throughout their reasoning process. Reasoning instruction following makes LRMs
more controllable and transparent, while reducing risks of undesirable
shortcuts, hallucinations, or reward hacking within reasoning traces. To
evaluate this dimension, we introduce ReasonIF, a systematic benchmark for
assessing reasoning instruction following. ReasonIF includes six categories of
instruction prompts, spanning multilingual reasoning, formatting and length
control. Across many open-source LRMs including GPT-OSS, Qwen3, and
DeepSeek-R1, we find substantial failures in reasoning instruction adherence:
the highest instruction following score (IFS) remains below 0.25, meaning that
fewer than $25\%$ of reasoning traces comply with the given instructions.
Notably, as task difficulty increases, reasoning instruction following degrades
further. We also explore two strategies to enhance reasoning instruction
fidelity. (1) multi-turn reasoning and (2) Reasoning Instruction Finetuning
(RIF) using synthetic data. RIF improves the IFS of $GPT-OSS-20B$ from 0.11 to
0.27, indicating measurable progress but leaving ample room for improvement.

</details>


### [222] [Soundness-Aware Level: A Microscopic Signature that Predicts LLM Reasoning Potential](https://arxiv.org/abs/2510.15216)
*Xuansheng Wu,Xiaoman Pan,Wenlin Yao,Jianshu Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于潜层特征和霍恩子句推理链的分析方法，发现预训练模型在强化学习后推理性能差异的关键在于其对规则语义正确性（如严格、合理、噪声）的内在区分能力。作者提出了Soundness-Aware Level（SAL）这一微观指标，利用Jensen-Shannon散度量化模型对不同正确性级别规则的概率分布差异，并验证了SAL与RLVR后性能高度相关（R²=0.87），适用于多种模型系列和规模。


<details>
  <summary>Details</summary>
Motivation: 探究为何不同基础大模型在经过强化学习与可验证奖励（RLVR）训练后表现出显著不同的推理能力，寻找决定这种差异的微观属性。

Method: 将推理形式化为从LLM潜空间特征提取出的霍恩子句（'if-then'规则）链；使用跨层稀疏自编码器（SAE）提取特征，估计特征间转移概率，并用LLM对规则的语义正确性水平（严格、合理、噪声等）进行分类。

Result: 发现高性能模型在内部概率分布上能明显区分不同正确性级别的规则（即‘正确性感知’），而弱模型则无法区分（‘正确性盲视’）；提出SAL指标，基于Jensen-Shannon散度衡量分布分离程度，SAL值与RLVR后的推理性能呈强相关（R²=0.87），且跨模型族和参数规模具有一致性。

Conclusion: 模型的推理潜力取决于其预训练阶段形成的内在区分正确与错误知识的能力；SAL提供了一个基于模型内部机制的实用指标，可用于选择或设计更优的基础模型，强调了预训练过程在塑造推理能力中的关键作用。

Abstract: Reinforcement learning with verifiable rewards (RLVR) can elicit strong
reasoning in large language models (LLMs), while their performance after RLVR
varies dramatically across different base models. This raises a fundamental
question: what microscopic property of pre-trained models leads to this
variation? To investigate, we formalize reasoning as chains of Horn clauses
("if-then" rules) built from features extracted from the LLM's latent space via
cross-layer sparse autoencoders (SAEs). We estimate the transition
probabilities between its features, and further categorize each rule by its
semantic soundness level (e.g., strict, plausible, noisy) with an LLM. Our key
discovery is that high-potential models are inherently soundness-aware: their
internal probability distributions systematically shift across rules' soundness
levels, becoming highly distinct for "strict" versus "noisy" rules. In
contrast, weaker models are soundness-agnostic, collapsing to one distribution
regardless of soundness levels. To quantify this, we introduce the
Soundness-Aware Level (SAL), a microscopic metric using the Jensen-Shannon
Divergence to measure the separation between these distributions. We show that
SAL's predictions of post-RLVR reasoning performance follow a precise empirical
law (R^2=0.87) across diverse model families (Qwen, Mistral, Llama, DeepSeek)
and scales (0.5B-14B). This reveals that a model's reasoning potential is tied
to its intrinsic, pre-trained ability to distinguish sound knowledge from
unsound ones. These findings underscore the critical role of model pre-training
in shaping reasoning and offer a practical metric grounded in the model's
internal mechanisms for selecting/designing stronger base models.

</details>


### [223] [Reflections from Research Roundtables at the Conference on Health, Inference, and Learning (CHIL) 2025](https://arxiv.org/abs/2510.15217)
*Emily Alsentzer,Marie-Laure Charpignon,Bill Chen,Niharika D'Souza,Jason Fries,Yixing Jiang,Aparajita Kashyap,Chanwoo Kim,Simon Lee,Aishwarya Mandyam,Ashery Christopher Mbilinyi,Nikita Mehandru,Nitish Nagesh,Brighton Nuwagira,Emma Pierson,Arvind Pillai,Akane Sano,Tanveer Syeda-Mahmood,Shashank Yadav,Elias Adhanom,Muhammad Umar Afza,Amelia Archer,Suhana Bedi,Vasiliki Bikia,Trenton Chang,George H. Chen,Winston Chen,Erica Chiang,Edward Choi,Octavia Ciora,Paz Dozie-Nnamah,Shaza Elsharief,Matthew Engelhard,Ali Eshragh,Jean Feng,Josh Fessel,Scott Fleming,Kei Sen Fong,Thomas Frost,Soham Gadgil,Judy Gichoya,Leeor Hershkovich,Sujeong Im,Bhavya Jain,Vincent Jeanselme,Furong Jia,Qixuan,Jin,Yuxuan Jin,Daniel Kapash,Geetika Kapoor,Behdokht Kiafar,Matthias Kleiner,Stefan Kraft,Annika Kumar,Daeun Kyung,Zhongyuan Liang,Joanna Lin,Qianchu,Liu,Chang Liu,Hongzhou Luan,Chris Lunt,Leopoldo Julían Lechuga López,Matthew B. A. McDermott,Shahriar Noroozizadeh,Connor O'Brien,YongKyung Oh,Mixail Ota,Stephen Pfohl,Meagan Pi,Tanmoy Sarkar Pias,Emma Rocheteau,Avishaan Sethi,Toru Shirakawa,Anita Silver,Neha Simha,Kamile Stankeviciute,Max Sunog,Peter Szolovits,Shengpu Tang,Jialu Tang,Aaron Tierney,John Valdovinos,Byron Wallace,Will Ke Wang,Peter Washington,Jeremy Weiss,Daniel Wolfe,Emily Wong,Hye Sun Yun,Xiaoman Zhang,Xiao Yu Cindy Zhang,Hayoung Jeong,Kaveri A. Thakoor*

Main category: cs.LG

TL;DR: CHIL 2025会议举办了八个关于机器学习与医疗健康交叉领域的研究圆桌讨论，涵盖可解释性、不确定性、因果性等关键主题，旨在促进协作对话和领域发展。


<details>
  <summary>Details</summary>
Motivation: 推动机器学习在医疗健康领域的应用，解决关键挑战并探索新兴机会。

Method: 通过由资深和青年主席共同主持的小型圆桌讨论，促进开放交流和包容性参与。

Result: 成功举办了八个主题的圆桌讨论，涉及可解释性、偏差、因果性、领域适应、基础模型等多个前沿方向。

Conclusion: 此类协作式研讨有助于激发创新思维，推动医疗机器学习领域的实质性进展。

Abstract: The 6th Annual Conference on Health, Inference, and Learning (CHIL 2025),
hosted by the Association for Health Learning and Inference (AHLI), was held in
person on June 25-27, 2025, at the University of California, Berkeley, in
Berkeley, California, USA. As part of this year's program, we hosted Research
Roundtables to catalyze collaborative, small-group dialogue around critical,
timely topics at the intersection of machine learning and healthcare. Each
roundtable was moderated by a team of senior and junior chairs who fostered
open exchange, intellectual curiosity, and inclusive engagement. The sessions
emphasized rigorous discussion of key challenges, exploration of emerging
opportunities, and collective ideation toward actionable directions in the
field. In total, eight roundtables were held by 19 roundtable chairs on topics
of "Explainability, Interpretability, and Transparency," "Uncertainty, Bias,
and Fairness," "Causality," "Domain Adaptation," "Foundation Models," "Learning
from Small Medical Data," "Multimodal Methods," and "Scalable, Translational
Healthcare Solutions."

</details>


### [224] [Machine Learning for Early Detection of Meningitis: Stacked Ensemble Learning with EHR data](https://arxiv.org/abs/2510.15218)
*Han Ouyang,Jesse Hamilton,Saeed Amal*

Main category: cs.LG

TL;DR: 本研究利用MIMIC-III数据库中的214名脑膜炎患者和46,303名非脑膜炎患者，通过两阶段特征选择和集成学习方法（随机森林、LightGBM、DNN结合逻辑回归元模型）构建诊断模型，在两个测试集上分别取得0.9637和0.9472的AUC，模拟真实急诊环境以提升临床应用价值。


<details>
  <summary>Details</summary>
Motivation: 脑膜炎早期诊断困难且临床后果严重，亟需高效、可靠的辅助诊断工具；现有模型在真实临床场景中的适用性有限，因此需要开发更具鲁棒性和解释性的AI模型。

Method: 基于MIMIC-III数据库进行ICD编码队列筛选，采用独热编码和两阶段特征选择提取性别、蛛网膜下腔出血、脑继发恶性肿瘤、全身性癫痫等临床相关特征；构建随机森林、LightGBM和深度神经网络作为基模型，通过堆叠集成学习方式将输出输入至逻辑回归元模型进行最终预测。

Result: 集成模型在测试集1和测试集2上分别达到0.9637和0.9472的AUC值，表现出优异的分类性能；所选特征具有临床合理性且符合时间顺序，模型在模拟真实急诊场景下仍保持高预测能力。

Conclusion: 该研究表明基于多模型集成学习的方法在脑膜炎辅助诊断中具有巨大潜力，能够在复杂真实环境中提供高精度预测，为未来AI驱动的临床决策支持系统奠定了基础。

Abstract: We utilized a cohort of 214 meningitis patients and 46,303 non-meningitis
patients from the MIMIC-III database. After extensive data preprocessing, which
included ICD-based cohort selection, one-hot encoding of coding, and a
two-stage feature selection process (for both the training set and the testing
sets), clinically relevant features such as gender and high-risk ICD codes
(including subarachnoid hemorrhage, secondary malignant neoplasm of the brain,
and generalized epilepsy) are selected. Overall, these clinically reasonable
and temporally adherent features provided excellent modeling performance. Three
models (Random Forest, LightGBM, and Deep Neural Networks (DNN) are trained as
base models for Ensemble Learning. Base model outputs are aggregated and
stacked into a meta model (Logistic Regression) that uses the base model
outputs as input values in training. Ultimately, soldier outputs (AUC of
Testing Set 1: 0.9637, AUC of Testing Set 2: 0.9472) are obtained through
ensemble learning.
  We created a challenging condition for diagnosing meningitis, simulating a
real-world ER (Emergency Room) scenario to enhance clinical use in real-world
applications. While directly deploying a diagnostic tool that clinicians can
use is challenging, this paper paves the way for a potential future AI-driven
diagnostic approach for meningitis using Ensemble Learning.

</details>


### [225] [Towards Robust Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.15382)
*Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xiayuan Zhan*

Main category: cs.LG

TL;DR: 本文提出了BREEZE，一种增强表达能力的零样本强化学习框架，通过行为正则化、任务条件扩散模型和注意力机制改进了现有方法的表示学习、策略提取和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本强化学习方法（如FB）在表示学习上表达能力不足，且离线学习中因分布外动作导致外推误差，影响性能。

Method: 提出BREEZE框架：引入行为正则化以提升学习稳定性；使用任务条件扩散模型进行策略提取，生成高质量、多模态动作分布；采用基于注意力的表达性架构增强表示学习。

Result: 在ExORL和D4RL Kitchen基准上实验表明，BREEZE达到最优或接近最优性能，并展现出比现有方法更强的鲁棒性。

Conclusion: BREEZE通过增强表示表达性和引入稳定的学习机制，在零样本强化学习中显著提升了性能和鲁棒性，为通用策略的预训练提供了有效方案。

Abstract: The recent development of zero-shot reinforcement learning (RL) has opened a
new avenue for learning pre-trained generalist policies that can adapt to
arbitrary new tasks in a zero-shot manner. While the popular Forward-Backward
representations (FB) and related methods have shown promise in zero-shot RL, we
empirically found that their modeling lacks expressivity and that extrapolation
errors caused by out-of-distribution (OOD) actions during offline learning
sometimes lead to biased representations, ultimately resulting in suboptimal
performance. To address these issues, we propose Behavior-REgularizEd Zero-shot
RL with Expressivity enhancement (BREEZE), an upgraded FB-based framework that
simultaneously enhances learning stability, policy extraction capability, and
representation learning quality. BREEZE introduces behavioral regularization in
zero-shot RL policy learning, transforming policy optimization into a stable
in-sample learning paradigm. Additionally, BREEZE extracts the policy using a
task-conditioned diffusion model, enabling the generation of high-quality and
multimodal action distributions in zero-shot RL settings. Moreover, BREEZE
employs expressive attention-based architectures for representation modeling to
capture the complex relationships between environmental dynamics. Extensive
experiments on ExORL and D4RL Kitchen demonstrate that BREEZE achieves the best
or near-the-best performance while exhibiting superior robustness compared to
prior offline zero-shot RL methods. The official implementation is available
at: https://github.com/Whiterrrrr/BREEZE.

</details>


### [226] [Integrating Product Coefficients for Improved 3D LiDAR Data Classification (Part II)](https://arxiv.org/abs/2510.15219)
*Patricia Medina,Rasika Karkare*

Main category: cs.LG

TL;DR: 本文通过结合积系数、自编码器表示和KNN分类器，提升了3D LiDAR点云分类性能，并发现逐层添加积系数能系统性提高分类准确性和类别可分性。


<details>
  <summary>Details</summary>
Motivation: 在原有LiDAR空间特征基础上，进一步引入积系数以增强3D点云分类性能，探索更优的特征组合方法。

Method: 将积系数与自编码器表示相结合，并采用KNN分类器；同时逐层分析积系数的加入对分类性能的影响。

Result: 相比基于PCA的基线方法和先前框架，新方法在分类性能上表现出一致提升；随着积系数层级增加，类别可分性和整体准确率系统性提高。

Conclusion: 结合层次化的积系数特征与自编码器可有效推动LiDAR点云分类性能的进一步提升。

Abstract: This work extends our previous study on enhancing 3D LiDAR point-cloud
classification with product coefficients
\cite{medina2025integratingproductcoefficientsimproved}, measure-theoretic
descriptors that complement the original spatial Lidar features. Here, we show
that combining product coefficients with an autoencoder representation and a
KNN classifier delivers consistent performance gains over both PCA-based
baselines and our earlier framework. We also investigate the effect of adding
product coefficients level by level, revealing a clear trend: richer sets of
coefficients systematically improve class separability and overall accuracy.
The results highlight the value of combining hierarchical product-coefficient
features with autoencoders to push LiDAR classification performance further.

</details>


### [227] [Stress-Aware Learning under KL Drift via Trust-Decayed Mirror Descent](https://arxiv.org/abs/2510.15222)
*Gabriel Nixon Raj*

Main category: cs.LG

TL;DR: 本文提出了一种熵正则化的信任衰减方法（entropy-regularized trust-decay），用于在分布漂移下的序贯决策问题，实现了对信念更新和镜像下降决策的压力感知指数倾斜，并在多种设定下建立了动态遗憾保证与鲁棒性分析。


<details>
  <summary>Details</summary>
Motivation: 在存在分布漂移的环境中，传统序贯决策方法难以同时保持对变化的敏感性和稳健性，因此需要一种能够自适应环境变化并量化系统脆弱性的新框架。

Method: 引入熵正则化与信任衰减机制，通过Fenchel对偶性分析信念与决策倾斜的一致性，定义KL漂移路径长度，并结合压力感知的指数倾斜进行动态更新，支持带反馈、分布式优化等多种扩展。

Result: 证明了在KL漂移路径长度ST下的\tilde{O}(\sqrt{T})动态遗憾界，实现O(1)每切换遗憾；提出了无参数hedge来自适应未知漂移，避免过倾斜导致的\Omega(\lambda^2 T)惩罚，并给出校准的压力界限及其他扩展。

Conclusion: 该信任衰减框架统一了动态遗憾分析、分布鲁棒优化与KL正则化控制，提供了一个可解释、自适应且理论完备的序贯决策解决方案，适用于存在分布漂移的复杂环境。

Abstract: We study sequential decision-making under distribution drift. We propose
entropy-regularized trust-decay, which injects stress-aware exponential tilting
into both belief updates and mirror-descent decisions. On the simplex, a
Fenchel-dual equivalence shows that belief tilt and decision tilt coincide. We
formalize robustness via fragility (worst-case excess risk in a KL ball),
belief bandwidth (radius sustaining a target excess), and a decision-space
Fragility Index (drift tolerated at $O(\sqrt{T})$ regret). We prove
high-probability sensitivity bounds and establish dynamic-regret guarantees of
$\tilde{O}(\sqrt{T})$ under KL-drift path length $S_T = \sum_{t\ge2}\sqrt{{\rm
KL}(D_t|D_{t-1})/2}$. In particular, trust-decay achieves $O(1)$ per-switch
regret, while stress-free updates incur $\Omega(1)$ tails. A parameter-free
hedge adapts the tilt to unknown drift, whereas persistent over-tilting yields
an $\Omega(\lambda^2 T)$ stationary penalty. We further obtain
calibrated-stress bounds and extensions to second-order updates, bandit
feedback, outliers, stress variation, distributed optimization, and plug-in
KL-drift estimation. The framework unifies dynamic-regret analysis,
distributionally robust objectives, and KL-regularized control within a single
stress-adaptive update.

</details>


### [228] [FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain](https://arxiv.org/abs/2510.15232)
*Tiansheng Hu,Tongyan Hu,Liuyang Bai,Yilun Zhao,Arman Cohan,Chen Zhao*

Main category: cs.LG

TL;DR: 本文提出了FinTrust，一个专门用于评估大语言模型在金融应用中可信度的综合基准。


<details>
  <summary>Details</summary>
Motivation: 由于金融应用具有高风险和高利害关系，将大语言模型应用于实际金融场景仍面临挑战，因此需要一个能够全面评估其可信度的基准。

Method: 设计了一个基于实际场景、涵盖多个可信维度并对每个维度进行细粒度任务划分的综合性基准FinTrust，并在11个大语言模型上进行了评估。

Result: 发现专有模型（如o4-mini）在安全性等大多数任务中表现更好，而开源模型（如DeepSeek-V3）在行业级公平性等特定领域具有优势；但在受托责任对齐和信息披露等复杂任务上，所有模型均表现不佳，暴露出法律意识方面的显著不足。

Conclusion: FinTrust可作为评估金融领域大语言模型可信度的有效工具，推动模型在高风险金融场景中的可靠应用。

Abstract: Recent LLMs have demonstrated promising ability in solving finance related
problems. However, applying LLMs in real-world finance application remains
challenging due to its high risk and high stakes property. This paper
introduces FinTrust, a comprehensive benchmark specifically designed for
evaluating the trustworthiness of LLMs in finance applications. Our benchmark
focuses on a wide range of alignment issues based on practical context and
features fine-grained tasks for each dimension of trustworthiness evaluation.
We assess eleven LLMs on FinTrust and find that proprietary models like o4-mini
outperforms in most tasks such as safety while open-source models like
DeepSeek-V3 have advantage in specific areas like industry-level fairness. For
challenging task like fiduciary alignment and disclosure, all LLMs fall short,
showing a significant gap in legal awareness. We believe that FinTrust can be a
valuable benchmark for LLMs' trustworthiness evaluation in finance domain.

</details>


### [229] [Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed Conformal Prediction](https://arxiv.org/abs/2510.15233)
*Amitesh Badkul,Lei Xie*

Main category: cs.LG

TL;DR: 本文提出了一种新的不确定性量化方法TESSERA，用于蛋白质-配体结合亲和力预测，能够在分布内和分布外场景下提供可靠且自适应的预测区间，具有良好的覆盖率-宽度权衡和可信赖的个体化不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习不确定性量化方法在风险敏感领域（如药物发现）中表现不佳，尤其是在分布偏移、数据不平衡和噪声异质性情况下缺乏可靠的个体化不确定性估计。

Method: 结合混合专家模型（MoE）的多样性与分裂保形校准（split-conformal calibration），提出TESSERA方法，通过缩放估计实现高效、可靠且自适应的预测区间生成，并引入Size-Stratified Coverage（SSC）评估区间合理性。

Result: 在i.i.d.和基于骨架的OOD分割上，TESSERA实现了接近标称水平的覆盖率，在Coverage-Width Criterion（CWC）上表现最优，同时具有最低的AUSE值，表明其区间宽度能有效反映预测误差，且在数据稀缺或噪声大时自动扩大。

Conclusion: TESSERA为高风险应用场景提供了可信、紧致且自适应的不确定性量化方案，特别适用于药物发现中的选择性预测和决策支持。

Abstract: Reliable, informative, and individual uncertainty quantification (UQ) remains
missing in current ML community. This hinders the effective application of
AI/ML to risk-sensitive domains. Most methods either fail to provide coverage
on new data, inflate intervals so broadly that they are not actionable, or
assign uncertainties that do not track actual error, especially under a
distribution shift. In high-stakes drug discovery, protein-ligand affinity
(PLI) prediction is especially challenging as assay noise is heterogeneous,
chemical space is imbalanced and large, and practical evaluations routinely
involve distribution shift. In this work, we introduce a novel uncertainty
quantification method, Trustworthy Expert Split-conformal with Scaled
Estimation for Efficient Reliable Adaptive intervals (TESSERA), that provides
per-sample uncertainty with reliable coverage guarantee, informative and
adaptive prediction interval widths that track the absolute error. We evaluate
on protein-ligand binding affinity prediction under both independent and
identically distributed (i.i.d.) and scaffold-based out-of-distribution (OOD)
splits, comparing against strong UQ baselines. TESSERA attains near-nominal
coverage and the best coverage-width trade-off as measured by the
Coverage-Width Criterion (CWC), while maintaining competitive adaptivity
(lowest Area Under the Sparsification Error (AUSE)). Size-Stratified Coverage
(SSC) further confirms that intervals are right-sized, indicating width
increases when data are scarce or noisy, and remain tight when predictions are
reliable. By unifying Mixture of Expert (MoE) diversity with conformal
calibration, TESSERA delivers trustworthy, tight, and adaptive uncertainties
that are well-suited to selective prediction and downstream decision-making in
the drug-discovery pipeline and other applications.

</details>


### [230] [Dual-Weighted Reinforcement Learning for Generative Preference Modeling](https://arxiv.org/abs/2510.15242)
*Shengyu Feng,Yun He,Shuang Ma,Beibin Li,Yuanhao Xiong,Vincent Li,Karishma Mandyam,Julian Katz-Samuels,Shengjie Bi,Licheng Yu,Hejia Zhang,Karthik Abinav Sankararaman,Han Fang,Riham Mansour,Yiming Yang,Manaal Faruqui*

Main category: cs.LG

TL;DR: 本文提出了Dual-Weighted Reinforcement Learning (DWRL) 框架，结合思维链推理与Bradley-Terry模型，用于非可验证任务中的偏好建模，通过实例级和组级双重加权机制提升训练效果，在多个基准上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习在可验证任务中已成功扩展思维链推理，但在缺乏明确答案、依赖人类偏好的非可验证任务中应用仍具挑战且研究不足，因此需要一种能保持偏好建模归纳偏置的新框架。

Method: 提出DWRL框架，引入双加权强化学习目标：实例级的错配权重突出未充分训练且违背人类偏好的样本对，组级的自归一化条件偏好分数促进优质思维生成；结合生成式偏好模型（GPM），先生成思维再预测偏好得分。

Result: 在多个基准和不同模型规模（Llama3、Qwen2.5）下，DWRL在偏好建模任务中 consistently 优于GPM基线和标量模型，并能生成连贯、可解释的思维过程。

Conclusion: DWRL是一种有效的通用框架，能够将思维链推理整合到非可验证任务的偏好学习中，为基于人类偏好的强化学习提供了新方向。

Abstract: Reinforcement learning (RL) has recently proven effective at scaling
chain-of-thought (CoT) reasoning in large language models on tasks with
verifiable answers. However, extending RL to more general non-verifiable tasks,
typically in the format of human preference pairs, remains both challenging and
underexplored. In this work, we propose Dual-Weighted Reinforcement Learning
(DWRL), a new framework for preference modeling that integrates CoT reasoning
with the Bradley-Terry (BT) model via a dual-weighted RL objective that
preserves preference-modeling inductive bias. DWRL approximates the
maximum-likelihood objective of the BT model with two complementary weights: an
instance-wise misalignment weight, which emphasizes under-trained pairs
misaligned with human preference, and a group-wise (self-normalized)
conditional preference score, which promotes promising thoughts. In this paper,
we apply DWRL to preference modeling by training generative preference models
(GPMs) to first generate a thought and then predict the human preference score.
Across multiple benchmarks and model scales (Llama3 and Qwen2.5), DWRL
consistently outperforms both GPM baselines and scalar models, while producing
coherent, interpretable thoughts. In summary, our results position DWRL as a
general framework for reasoning-enhanced preference learning beyond verifiable
tasks.

</details>


### [231] [Spatiotemporal Transformers for Predicting Avian Disease Risk from Migration Trajectories](https://arxiv.org/abs/2510.15254)
*Dingya Feng,Dingyuan Xue*

Main category: cs.LG

TL;DR: 本研究提出了一种基于Transformer的框架，用于预测迁徙鸟类路径终点的禽类疾病风险，融合了GPS追踪、疫情记录和地理空间数据，通过H3编码处理坐标，模型在测试中表现出色（准确率0.9821，AUC 0.9803），显示出在禽病预警系统中的潜力。


<details>
  <summary>Details</summary>
Motivation: 准确预测禽类疾病暴发对野生动物保护和公共卫生至关重要，而迁徙鸟类在疾病传播中起关键作用，因此需建立有效的早期预警系统。

Method: 采用基于Transformer的模型，整合来自Movebank的GPS追踪数据、WOAH的疫情记录以及GADM和Natural Earth的地理空间数据，使用H3分层地理编码处理原始坐标，建模鸟类移动序列中的时空依赖关系以预测终点疾病风险。

Result: 在保留测试集上，模型取得准确率0.9821、AUC 0.9803、平均精度0.9299、最优阈值下F1分数0.8836，表现出优异的预测性能。

Conclusion: Transformer架构能有效捕捉迁徙模式与疾病风险之间的复杂关系，具备支持禽类疾病早期预警和干预策略的潜力。

Abstract: Accurate forecasting of avian disease outbreaks is critical for wildlife
conservation and public health. This study presents a Transformer-based
framework for predicting the disease risk at the terminal locations of
migratory bird trajectories. We integrate multi-source datasets, including GPS
tracking data from Movebank, outbreak records from the World Organisation for
Animal Health (WOAH), and geospatial context from GADM and Natural Earth. The
raw coordinates are processed using H3 hierarchical geospatial encoding to
capture spatial patterns. The model learns spatiotemporal dependencies from
bird movement sequences to estimate endpoint disease risk. Evaluation on a
held-out test set demonstrates strong predictive performance, achieving an
accuracy of 0.9821, area under the ROC curve (AUC) of 0.9803, average precision
(AP) of 0.9299, and an F1-score of 0.8836 at the optimal threshold. These
results highlight the potential of Transformer architectures to support
early-warning systems for avian disease surveillance, enabling timely
intervention and prevention strategies.

</details>


### [232] [DRO-InstructZero: Distributionally Robust Prompt Optimization for Large Language Models](https://arxiv.org/abs/2510.15260)
*Yangyang Li*

Main category: cs.LG

TL;DR: DRO-InstructZero 提出了一种分布鲁棒的零样本提示优化方法，通过将提示搜索建模为鲁棒贝叶斯优化，在分布偏移和对抗性评估下显著提升提示的可靠性与迁移性，同时保持查询效率。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示搜索方法在分布偏移和对抗性环境下表现不佳，因它们仅优化单一评估分布下的期望性能，导致提示缺乏泛化能力。

Method: 将零样本提示优化视为鲁棒贝叶斯优化问题，使用f散度球定义评估分布周围的模糊集，并采用最大化最坏情况期望效用的鲁棒获取规则。

Result: 在形式化重写、代码调试和翻译等任务中，相比InstructZero，DRO-InstructZero在分布偏移下实现约25-30个百分点的准确率提升，且在稳定任务上不损失性能。

Conclusion: DRO-InstructZero 将分布鲁棒优化与提示学习结合，提供了一种即插即用、通用的方法，有效提升提示在现实不确定性下的可靠性和可迁移性。

Abstract: Large language models are highly sensitive to prompt wording. However,
popular automatic prompt search methods, including InstructZero, often degrade
under distribution shift and adversarial evaluation because they optimize
expected performance under a single evaluation distribution. Consequently,
prompts that work in one setting frequently fail to transfer. To address this,
DRO-InstructZero formulates zero-shot prompt optimization as robust Bayesian
optimization. Specifically, an f-divergence ball defines an ambiguity set
around the evaluation distribution, and a robust acquisition rule maximizes
worst-case expected utility while retaining the query efficiency of Bayesian
search. Therefore, the search explicitly targets reliability under distribution
shift rather than average behavior alone. Experiments follow the
instruction-induction protocol with matched query budgets across formality
rewriting, code debugging, and translation. For example, on BIG-Bench
informative-to-formal rewriting, accuracy improves from 61.3 +/- 0.7% to
approximately 85-90%, yielding an absolute gain of about 25-30 points.
Moreover, auto-debugging shows about +25-point gains under domain shift.
Meanwhile, stable tasks such as cause-and-effect remain above 96%, indicating
no loss on in-distribution cases. Furthermore, improvements are consistent
across divergence choices and decoding temperatures. Overall, DRO-InstructZero
connects distributionally robust optimization with prompt learning, offering a
plug-and-play and general approach for reliable, transferable prompt alignment
under real-world uncertainty.

</details>


### [233] [Robust Layerwise Scaling Rules by Proper Weight Decay Tuning](https://arxiv.org/abs/2510.15262)
*Zhiyuan Fan,Yifeng Liu,Qingyue Zhao,Angela Yuan,Quanquan Gu*

Main category: cs.LG

TL;DR: 本文提出了一种针对AdamW优化器的权重衰减缩放规则，结合μP学习率规则，在现代尺度不变架构中实现宽度变化下的零样本超参数迁移，解决了传统μP在训练进入稳态后因归一化层导致的性能退化问题。


<details>
  <summary>Details</summary>
Motivation: 在现代尺度不变架构中，训练很快进入由优化器主导的稳态，归一化层导致反向传播的尺度敏感性，使得有效学习率依赖于模型宽度，从而削弱了μP的跨宽度学习率迁移效果。因此需要一种新的方法来保持不同宽度下子层增益的稳定性。

Method: 通过引入AdamW优化器下的权重衰减缩放规则，使矩阵参数的奇异值谱范数随√(η/λ)变化，并基于观察到的奇异值随宽度d的0.75次方增长的现象，结合μP的学习率规则η₂∝d⁻¹，推导出λ₂∝√d的权重衰减缩放规则；同时对向量型参数设置η₁=Θₐ(1)和λ₁=0，以保持子层增益在宽度上的不变性。

Result: 该方法在LLaMA风格的Transformer和合成任务上验证了有效性，实现了从代理宽度到目标宽度的零样本学习率与权重衰减迁移，无需针对每个宽度进行超参数搜索，并提出了匹配顶部奇异值作为检查子层增益不变性的简单诊断工具。

Conclusion: 所提出的权重衰减缩放规则扩展了μP的应用范围，超越了初始阶段的近似行为，通过显式控制优化器决定的稳态尺度，为使用AdamW的模型提供了实用的、对宽度鲁棒的超参数迁移方案。

Abstract: Empirical scaling laws prescribe how to allocate parameters, data, and
compute, while maximal-update parameterization ($\mu$P) enables learning-rate
transfer across widths by equalizing early-time update magnitudes. However, in
modern scale-invariant architectures, training quickly enters an
optimizer-governed steady state where normalization layers create backward
scale sensitivity and the effective learning rate becomes width dependent,
degrading $\mu$P transfer. We address this by introducing a weight-decay
scaling rule for AdamW that preserves sublayer gain across widths. Empirically,
the singular-value spectrum of each matrix parameter scales in norm as
$\sqrt{\eta/\lambda}$ with an approximately invariant shape; under width
scaling $d$, we observe that the top singular value scales approximately as
$\sqrt{\eta/\lambda}\cdot d^{0.75}$. Combining this observation with the $\mu$P
learning-rate rule $\eta_2\propto d^{-1}$ for matrix-like parameters implies an
empirical weight-decay scaling rule $\lambda_2\propto \sqrt{d}$ that
approximately keeps sublayer gains width invariant. Together with vector-like
parameters trained at $\eta_1=\Theta_d(1)$ and $\lambda_1=0$, this yields
\emph{zero-shot} transfer of both learning rate and weight decay from proxy to
target widths, removing per-width sweeps. We validate the rule on LLaMA-style
Transformers and in a minimal synthetic setting, and we provide a simple
diagnostic, matching top singular values, to check sublayer-gain invariance.
Our results extend $\mu$P beyond the near-init regime by explicitly controlling
steady-state scales set by the optimizer, offering a practical recipe for
width-robust hyperparameter transfer under AdamW.

</details>


### [234] [Causal Time Series Modeling of Supraglacial Lake Evolution in Greenland under Distribution Shift](https://arxiv.org/abs/2510.15265)
*Emam Hossain,Muhammad Hasan Ferdous,Devon Dunmire,Aneesh Subramanian,Md Osman Gani*

Main category: cs.LG

TL;DR: 提出RIC-TSC框架，结合区域感知的因果发现与时间序列分类，提升冰川湖演化预测的泛化能力与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有地球观测模型多依赖相关性特征，在分布偏移下泛化能力差，需利用因果建模挖掘稳定不变关系。

Method: 采用J-PCMCI+方法进行全局与按流域的因果图推断，提取具有时间滞后的不变因果特征，并输入轻量级分类器进行时序分类。

Result: 在2018-2019年两个融化季的1000个标注湖泊数据上，因果模型在分布外场景下比相关性基线最高提升12.59%准确率。

Conclusion: 因果发现不仅能用于特征选择，还可构建更具泛化性和机理可解释性的地球表面动态过程模型。

Abstract: Causal modeling offers a principled foundation for uncovering stable,
invariant relationships in time-series data, thereby improving robustness and
generalization under distribution shifts. Yet its potential is underutilized in
spatiotemporal Earth observation, where models often depend on purely
correlational features that fail to transfer across heterogeneous domains. We
propose RIC-TSC, a regionally-informed causal time-series classification
framework that embeds lag-aware causal discovery directly into sequence
modeling, enabling both predictive accuracy and scientific interpretability.
Using multi-modal satellite and reanalysis data-including Sentinel-1 microwave
backscatter, Sentinel-2 and Landsat-8 optical reflectance, and CARRA
meteorological variables-we leverage Joint PCMCI+ (J-PCMCI+) to identify
region-specific and invariant predictors of supraglacial lake evolution in
Greenland. Causal graphs are estimated globally and per basin, with validated
predictors and their time lags supplied to lightweight classifiers. On a
balanced benchmark of 1000 manually labeled lakes from two contrasting melt
seasons (2018-2019), causal models achieve up to 12.59% higher accuracy than
correlation-based baselines under out-of-distribution evaluation. These results
show that causal discovery is not only a means of feature selection but also a
pathway to generalizable and mechanistically grounded models of dynamic Earth
surface processes.

</details>


### [235] [Semi-Supervised Regression with Heteroscedastic Pseudo-Labels](https://arxiv.org/abs/2510.15266)
*Xueqing Sun,Renzhen Wang,Quanziang Wang,Yichen Wu,Xixi Jia,Deyu Meng*

Main category: cs.LG

TL;DR: 提出一种不确定性感知的伪标签框架，用于半监督回归，通过双层优化动态调整伪标签影响，有效缓解不可靠伪标签的影响。


<details>
  <summary>Details</summary>
Motivation: 半监督回归中连续输出和异方差噪声使得伪标签可靠性难以评估，导致误差累积和过拟合。

Method: 从双层优化角度出发，联合最小化整体经验风险并优化标注数据上的不确定性估计以增强泛化能力。

Result: 在多个基准SSR数据集上验证了方法的有效性，表现出优于现有方法的鲁棒性和性能。

Conclusion: 该框架能有效应对半监督回归中伪标签的不可靠性问题，提升模型性能。

Abstract: Pseudo-labeling is a commonly used paradigm in semi-supervised learning, yet
its application to semi-supervised regression (SSR) remains relatively
under-explored. Unlike classification, where pseudo-labels are discrete and
confidence-based filtering is effective, SSR involves continuous outputs with
heteroscedastic noise, making it challenging to assess pseudo-label
reliability. As a result, naive pseudo-labeling can lead to error accumulation
and overfitting to incorrect labels. To address this, we propose an
uncertainty-aware pseudo-labeling framework that dynamically adjusts
pseudo-label influence from a bi-level optimization perspective. By jointly
minimizing empirical risk over all data and optimizing uncertainty estimates to
enhance generalization on labeled data, our method effectively mitigates the
impact of unreliable pseudo-labels. We provide theoretical insights and
extensive experiments to validate our approach across various benchmark SSR
datasets, and the results demonstrate superior robustness and performance
compared to existing methods. Our code is available at
https://github.com/sxq/Heteroscedastic-Pseudo-Labels.

</details>


### [236] [Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition](https://arxiv.org/abs/2510.15280)
*Fan Liu,Jindong Han,Tengfei Lyu,Weijia Zhang,Zhe-Rui Yang,Lu Dai,Cancheng Liu,Hao Liu*

Main category: cs.LG

TL;DR: 本文提出基础模型（FMs）正在推动科学范式转变，提出了一个三阶段框架：元科学研究整合、人机协同共创和自主科学发现，探讨了FMs在科学发现中的作用、风险与未来方向。


<details>
  <summary>Details</summary>
Motivation: 探讨基础模型是否仅增强现有科研方法，还是正在重新定义科学实践方式。

Method: 提出一个三阶段演进框架（Meta-Scientific Integration, Hybrid Human-AI Co-Creation, Autonomous Scientific Discovery），并通过该框架分析FMs在不同科学范式中的应用与潜力。

Result: 系统梳理了FMs在当前科研中的应用与新兴能力，识别出FM驱动科学发现的风险与未来发展方向。

Conclusion: 基础模型不仅是科研工具的升级，更在催化一种新的科学范式，未来可能实现高度自主的科学发现。

Abstract: Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the
landscape of scientific research. Beyond accelerating tasks such as hypothesis
generation, experimental design, and result interpretation, they prompt a more
fundamental question: Are FMs merely enhancing existing scientific
methodologies, or are they redefining the way science is conducted? In this
paper, we argue that FMs are catalyzing a transition toward a new scientific
paradigm. We introduce a three-stage framework to describe this evolution: (1)
Meta-Scientific Integration, where FMs enhance workflows within traditional
paradigms; (2) Hybrid Human-AI Co-Creation, where FMs become active
collaborators in problem formulation, reasoning, and discovery; and (3)
Autonomous Scientific Discovery, where FMs operate as independent agents
capable of generating new scientific knowledge with minimal human intervention.
Through this lens, we review current applications and emerging capabilities of
FMs across existing scientific paradigms. We further identify risks and future
directions for FM-enabled scientific discovery. This position paper aims to
support the scientific community in understanding the transformative role of
FMs and to foster reflection on the future of scientific discovery. Our project
is available at
https://github.com/usail-hkust/Awesome-Foundation-Models-for-Scientific-Discovery.

</details>


### [237] [Small Ensemble-based Data Assimilation: A Machine Learning-Enhanced Data Assimilation Method with Limited Ensemble Size](https://arxiv.org/abs/2510.15284)
*Zhilin Li,Zhou Yao,Xianglong Li,Zeng Liu,Zhaokuan Lu,Shanlin Xu,Seungnam Kim,Guangyao Wang*

Main category: cs.LG

TL;DR: 提出一种结合集合卡尔曼滤波（EnKF）与全连接神经网络（FCNN）的新型数据同化方法EnKF-FCNN，利用小集合规模生成初步分析状态，并用FCNN预测校正项以提高精度，在Lorenz系统和非线性海洋波场模拟中验证了其优于传统EnKF的准确性且计算成本增加 negligible。


<details>
  <summary>Details</summary>
Motivation: 传统集合数据同化方法在分析精度和计算效率之间存在权衡，大集合规模虽可提升精度但计算成本高，小集合则易导致性能下降，因此需要一种既能保持低计算成本又能提高精度的新方法。

Method: 采用小规模集合通过EnKF生成次优的初步分析状态，然后使用全连接神经网络（FCNN）学习并预测这些状态的校正项，从而补偿因集合规模小带来的误差，实现精度提升。

Result: 在Lorenz系统和非线性海洋波场模拟中的实验表明，EnKF-FCNN在相同集合规模下比传统EnKF具有更高的精度，且额外计算开销可忽略不计，同时该方法具有良好的可扩展性和模型适应性。

Conclusion: EnKF-FCNN有效缓解了集合规模受限带来的性能退化问题，在保持计算高效的同时显著提升了分析精度，具备广泛应用于不同动力系统的潜力。

Abstract: Ensemble-based data assimilation (DA) methods have become increasingly
popular due to their inherent ability to address nonlinear dynamic problems.
However, these methods often face a trade-off between analysis accuracy and
computational efficiency, as larger ensemble sizes required for higher accuracy
also lead to greater computational cost. In this study, we propose a novel
machine learning-based data assimilation approach that combines the traditional
ensemble Kalman filter (EnKF) with a fully connected neural network (FCNN).
Specifically, our method uses a relatively small ensemble size to generate
preliminary yet suboptimal analysis states via EnKF. A FCNN is then employed to
learn and predict correction terms for these states, thereby mitigating the
performance degradation induced by the limited ensemble size. We evaluate the
performance of our proposed EnKF-FCNN method through numerical experiments
involving Lorenz systems and nonlinear ocean wave field simulations. The
results consistently demonstrate that the new method achieves higher accuracy
than traditional EnKF with the same ensemble size, while incurring negligible
additional computational cost. Moreover, the EnKF-FCNN method is adaptable to
diverse applications through coupling with different models and the use of
alternative ensemble-based DA methods.

</details>


### [238] [Identifying internal patterns in (1+1)-dimensional directed percolation using neural networks](https://arxiv.org/abs/2510.15294)
*Danil Parkhomenko,Pavel Ovchinnikov,Konstantin Soldatov,Vitalii Kapitan,Gennady Y. Chitov*

Main category: cs.LG

TL;DR: 提出了一种基于神经网络的方法，用于自动检测相变并分类隐藏的渗流模式，无需手动特征提取。


<details>
  <summary>Details</summary>
Motivation: 实现对(1+1)维复制过程中相变的自动检测与模式分类，提升从原始数据中提取复杂结构的能力。

Method: 结合CNN、TCN和GRU网络的深度学习模型，直接在原始构型上进行训练。

Result: 成功复现相图，并为构型分配相标签，验证了模型提取分层结构的能力。

Conclusion: 深度架构能够有效从数值实验的原始数据中自动提取复杂的层次化结构。

Abstract: In this paper we present a neural network-based method for the automatic
detection of phase transitions and classification of hidden percolation
patterns in a (1+1)-dimensional replication process. The proposed network model
is based on the combination of CNN, TCN and GRU networks, which are trained
directly on raw configurations without any manual feature extraction. The
network reproduces the phase diagram and assigns phase labels to
configurations. It shows that deep architectures are capable of extracting
hierarchical structures from the raw data of numerical experiments.

</details>


### [239] [DFCA: Decentralized Federated Clustering Algorithm](https://arxiv.org/abs/2510.15300)
*Jonas Kirch,Sebastian Becker,Tiago Koketsu Rodrigues,Stefan Harmeling*

Main category: cs.LG

TL;DR: 本文提出了一种名为DFCA的完全去中心化的聚类联邦学习算法，能够在无需中央服务器协调的情况下，使客户端协作训练特定于聚类的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的聚类联邦学习方法（如IFCA）依赖中心服务器，导致存在瓶颈和单点故障，限制了其在真实去中心化场景中的应用。

Method: DFCA采用顺序运行平均机制，随着更新的到来逐步聚合邻居模型，替代批处理聚合，实现通信高效且保持聚类性能。

Result: 在多个数据集上的实验表明，DFCA优于其他去中心化算法，并在稀疏连接下仍能与中心化的IFCA相媲美。

Conclusion: DFCA具有鲁棒性和实用性，适用于动态的真实世界去中心化网络。

Abstract: Clustered Federated Learning has emerged as an effective approach for
handling heterogeneous data across clients by partitioning them into clusters
with similar or identical data distributions. However, most existing methods,
including the Iterative Federated Clustering Algorithm (IFCA), rely on a
central server to coordinate model updates, which creates a bottleneck and a
single point of failure, limiting their applicability in more realistic
decentralized learning settings. In this work, we introduce DFCA, a fully
decentralized clustered FL algorithm that enables clients to collaboratively
train cluster-specific models without central coordination. DFCA uses a
sequential running average to aggregate models from neighbors as updates
arrive, providing a communication-efficient alternative to batch aggregation
while maintaining clustering performance. Our experiments on various datasets
demonstrate that DFCA outperforms other decentralized algorithms and performs
comparably to centralized IFCA, even under sparse connectivity, highlighting
its robustness and practicality for dynamic real-world decentralized networks.

</details>


### [240] [On the Generalization Properties of Learning the Random Feature Models with Learnable Activation Functions](https://arxiv.org/abs/2510.15327)
*Zailin Ma,Jiansheng Yang,Yaodong Yang*

Main category: cs.LG

TL;DR: 本文研究了具有可学习激活函数的随机特征模型（RFLAF）的泛化性质，通过数据依赖性采样方案，显著改进了回归和分类任务中所需特征数量的理论界，并提出了基于杠杆权重采样的算法，实验证明该方法在更少特征下即可达到相当性能。


<details>
  <summary>Details</summary>
Motivation: 为了提升RFLAF模型在回归与分类任务中的泛化性能，并减少所需随机特征的数量，亟需更精确的理论分析和高效的采样策略。

Method: 采用数据依赖的杠杆加权采样方案，提出统一的定理来刻画特征数量的复杂度，并设计算法用于近似核函数并实施加权采样。

Result: 在MSE损失下，特征数上界从Ω(1/ε²)改进至Õ((1/ε)^(1/t))，当Gram矩阵秩有限时甚至可达Ω(1)；在Lipschitz损失下，改进至Õ((1/ε²)^(1/t))；实验表明加权RFLAF用更少特征即可达到相同性能。

Conclusion: 数据依赖的加权采样显著提升了RFLAF的效率与理论保证，所提方法在理论和实践上均优于传统均匀采样方案。

Abstract: This paper studies the generalization properties of a recently proposed
kernel method, the Random Feature models with Learnable Activation Functions
(RFLAF). By applying a data-dependent sampling scheme for generating features,
we provide by far the sharpest bounds on the required number of features for
learning RFLAF in both the regression and classification tasks. We provide a
unified theorem that describes the complexity of the feature number $s$, and
discuss the results for the plain sampling scheme and the data-dependent
leverage weighted scheme. Through weighted sampling, the bound on $s$ in the
MSE loss case is improved from $\Omega(1/\epsilon^2)$ to
$\tilde{\Omega}((1/\epsilon)^{1/t})$ in general $(t\geq 1)$, and even to
$\Omega(1)$ when the Gram matrix has a finite rank. For the Lipschitz loss
case, the bound is improved from $\Omega(1/\epsilon^2)$ to
$\tilde{\Omega}((1/\epsilon^2)^{1/t})$. To learn the weighted RFLAF, we also
propose an algorithm to find an approximate kernel and then apply the leverage
weighted sampling. Empirical results show that the weighted RFLAF achieves the
same performances with a significantly fewer number of features compared to the
plainly sampled RFLAF, validating our theories and the effectiveness of this
method.

</details>


### [241] [Backdoor or Manipulation? Graph Mixture of Experts Can Defend Against Various Graph Adversarial Attacks](https://arxiv.org/abs/2510.15333)
*Yuyuan Feng,Bin Ma,Enyan Dai*

Main category: cs.LG

TL;DR: 提出基于Mixture of Experts（MoE）的统一框架，通过基于互信息（MI）的逻辑多样性损失和鲁棒性感知路由器，有效防御图神经网络中的多种对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法通常只针对单一类型的对抗攻击，缺乏能够同时抵御多种威胁（如后门攻击、边操纵和节点注入攻击）的统一防御机制。

Method: 利用MoE架构的灵活性，设计一个可扩展的统一防御框架；引入基于互信息的逻辑多样性损失，使不同专家关注不同的邻域结构；设计鲁棒性感知路由器，识别扰动模式并自适应地将受扰节点路由到相应的鲁棒专家。

Result: 在多种对抗场景下的大量实验表明，该方法在面对多种图对抗攻击时均表现出优越的鲁棒性，优于现有防御方法。

Conclusion: 所提出的MoE-based框架能够有效实现对多种图对抗攻击的统一防御，提升了GNN在复杂攻击环境下的安全性与可靠性。

Abstract: Extensive research has highlighted the vulnerability of graph neural networks
(GNNs) to adversarial attacks, including manipulation, node injection, and the
recently emerging threat of backdoor attacks. However, existing defenses
typically focus on a single type of attack, lacking a unified approach to
simultaneously defend against multiple threats. In this work, we leverage the
flexibility of the Mixture of Experts (MoE) architecture to design a scalable
and unified framework for defending against backdoor, edge manipulation, and
node injection attacks. Specifically, we propose an MI-based logic diversity
loss to encourage individual experts to focus on distinct neighborhood
structures in their decision processes, thus ensuring a sufficient subset of
experts remains unaffected under perturbations in local structures. Moreover,
we introduce a robustness-aware router that identifies perturbation patterns
and adaptively routes perturbed nodes to corresponding robust experts.
Extensive experiments conducted under various adversarial settings demonstrate
that our method consistently achieves superior robustness against multiple
graph adversarial attacks.

</details>


### [242] [Sequence Modeling with Spectral Mean Flows](https://arxiv.org/abs/2510.15366)
*Jinwoo Kim,Max Beier,Petar Bevanda,Nayun Kim,Seunghoon Hong*

Main category: cs.LG

TL;DR: 提出了一种基于算子理论的序列建模新方法，通过将序列分布嵌入张量空间并利用MMD梯度流生成序列，结合谱分解和流动匹配实现高效学习与采样。


<details>
  <summary>Details</summary>
Motivation: 解决序列建模中如何表示和学习高度非线性、概率性状态动态的问题，利用算子理论提供新的视角。

Method: 基于隐马尔可夫模型的算子理论观点，将序列分布嵌入乘积希尔伯特空间中的张量，并通过最大均值差异（MMD）梯度流定义生成过程；引入谱均值流算法，结合谱分解与时间依赖希尔伯特空间中的MMD流。

Result: 在多个时间序列建模数据集上取得了具有竞争力的结果，实现了更高效的训练和更快的采样速度。

Conclusion: 该方法为序列建模提供了一个新颖且有效的框架，结合算子理论与现代生成模型技术，克服了传统随机递归的局限性。

Abstract: A key question in sequence modeling with neural networks is how to represent
and learn highly nonlinear and probabilistic state dynamics. Operator theory
views such dynamics as linear maps on Hilbert spaces containing mean embedding
vectors of distributions, offering an appealing but currently overlooked
perspective. We propose a new approach to sequence modeling based on an
operator-theoretic view of a hidden Markov model (HMM). Instead of
materializing stochastic recurrence, we embed the full sequence distribution as
a tensor in the product Hilbert space. A generative process is then defined as
maximum mean discrepancy (MMD) gradient flow in the space of sequences. To
overcome challenges with large tensors and slow sampling convergence, we
introduce spectral mean flows, a novel tractable algorithm integrating two core
concepts. First, we propose a new neural architecture by leveraging spectral
decomposition of linear operators to derive a scalable tensor network
decomposition of sequence mean embeddings. Second, we extend MMD gradient flows
to time-dependent Hilbert spaces and connect them to flow matching via the
continuity equation, enabling simulation-free learning and faster sampling. We
demonstrate competitive results on a range of time-series modeling datasets.
Code is available at https://github.com/jw9730/spectral-mean-flow.

</details>


### [243] [Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning](https://arxiv.org/abs/2510.15388)
*Mingyang Sun,Pengxiang Ding,Weinan Zhang,Donglin Wang*

Main category: cs.LG

TL;DR: 提出Stepwise Flow Policy (SWFP) 框架，通过离散化流匹配推理过程，结合最优传输中的JKO原理，实现稳定高效的在线自适应和预训练流模型微调。


<details>
  <summary>Details</summary>
Motivation: 行为克隆结合流/扩散策略在学习复杂技能方面表现出色，但对分布偏移敏感，且现有强化学习方法难以有效微调此类模型。

Method: 基于固定步长欧拉法离散化流匹配过程，将其与变分JKO原理对齐，将全局流分解为一系列小的增量变换，每步对应一个带熵正则化的JKO更新。

Result: SWFP实现了更稳定的在线自适应，降低了训练和计算成本，并在多个机器人控制任务中展现出优越的适应性能。

Conclusion: SWFP提供了一种高效、稳定且可理论解释的流程，用于微调基于流的策略模型，显著提升了其在实际应用中的适应能力。

Abstract: While behavior cloning with flow/diffusion policies excels at learning
complex skills from demonstrations, it remains vulnerable to distributional
shift, and standard RL methods struggle to fine-tune these models due to their
iterative inference process and the limitations of existing workarounds. In
this work, we introduce the Stepwise Flow Policy (SWFP) framework, founded on
the key insight that discretizing the flow matching inference process via a
fixed-step Euler scheme inherently aligns it with the variational
Jordan-Kinderlehrer-Otto (JKO) principle from optimal transport. SWFP
decomposes the global flow into a sequence of small, incremental
transformations between proximate distributions. Each step corresponds to a JKO
update, regularizing policy changes to stay near the previous iterate and
ensuring stable online adaptation with entropic regularization. This
decomposition yields an efficient algorithm that fine-tunes pre-trained flows
via a cascade of small flow blocks, offering significant advantages:
simpler/faster training of sub-models, reduced computational/memory costs, and
provable stability grounded in Wasserstein trust regions. Comprehensive
experiments demonstrate SWFP's enhanced stability, efficiency, and superior
adaptation performance across diverse robotic control benchmarks.

</details>


### [244] [Geometric Mixture Models for Electrolyte Conductivity Prediction](https://arxiv.org/abs/2510.15403)
*Anyi Li,Jiacheng Cen,Songyou Li,Mingze Li,Yang Yu,Wenbing Huang*

Main category: cs.LG

TL;DR: 提出GeoMix，一种具有几何感知能力的框架，用于准确预测电解质系统的离子电导率，通过引入分子几何图表示和等变消息传递机制，在改进的CALiSol和DiffMix数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前电解质系统中离子电导率预测面临两个挑战：缺乏高质量标准化基准数据集，以及对混合体系中几何结构和分子间相互作用建模不足。

Method: 重构并增强CALiSol和DiffMix数据集，引入分子几何图表示；提出GeoMix框架，包含保持SE(3)等变性的几何交互网络（GIN），实现分子间几何信息的等变消息传递。

Result: 实验表明，GeoMix在两个数据集上均优于MLP、GNN和几何GNN等多种基线模型，验证了跨分子几何相互作用和等变消息传递对性能提升的关键作用。

Conclusion: 该工作建立了电解质研究的新基准，并提供了一个通用的几何学习框架，可推广至能源材料、药物开发等领域的混合系统建模。

Abstract: Accurate prediction of ionic conductivity in electrolyte systems is crucial
for advancing numerous scientific and technological applications. While
significant progress has been made, current research faces two fundamental
challenges: (1) the lack of high-quality standardized benchmarks, and (2)
inadequate modeling of geometric structure and intermolecular interactions in
mixture systems. To address these limitations, we first reorganize and enhance
the CALiSol and DiffMix electrolyte datasets by incorporating geometric graph
representations of molecules. We then propose GeoMix, a novel geometry-aware
framework that preserves Set-SE(3) equivariance-an essential but challenging
property for mixture systems. At the heart of GeoMix lies the Geometric
Interaction Network (GIN), an equivariant module specifically designed for
intermolecular geometric message passing. Comprehensive experiments demonstrate
that GeoMix consistently outperforms diverse baselines (including MLPs, GNNs,
and geometric GNNs) across both datasets, validating the importance of
cross-molecular geometric interactions and equivariant message passing for
accurate property prediction. This work not only establishes new benchmarks for
electrolyte research but also provides a general geometric learning framework
that advances modeling of mixture systems in energy materials, pharmaceutical
development, and beyond.

</details>


### [245] [Online Kernel Dynamic Mode Decomposition for Streaming Time Series Forecasting with Adaptive Windowing](https://arxiv.org/abs/2510.15404)
*Christopher Salazar,Krithika Manohar,Ashis G. Banerjee*

Main category: cs.LG

TL;DR: 提出WORK-DMD方法，结合随机傅里叶特征与在线动态模态分解，实现高效、准确的流数据实时预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理非平稳动态、计算资源受限和快速适应性方面存在权衡，难以兼顾准确性、适应性和效率。

Method: 将随机傅里叶特征与在线DMD结合，通过滑动窗口内的Sherman-Morrison更新实现仅依赖当前数据的持续适应，保持固定计算成本。

Result: 在多个领域基准数据集上，WORK-DMD优于多种先进在线预测方法，尤其在短期预测中表现突出，且只需单次数据遍历，存储需求低。

Conclusion: WORK-DMD在最小化数据需求的同时实现强预测性能，为流数据预测提供了比深度学习更高效的实用替代方案。

Abstract: Real-time forecasting from streaming data poses critical challenges: handling
non-stationary dynamics, operating under strict computational limits, and
adapting rapidly without catastrophic forgetting. However, many existing
approaches face trade-offs between accuracy, adaptability, and efficiency,
particularly when deployed in constrained computing environments. We introduce
WORK-DMD (Windowed Online Random Kernel Dynamic Mode Decomposition), a method
that combines Random Fourier Features with online Dynamic Mode Decomposition to
capture nonlinear dynamics through explicit feature mapping, while preserving
fixed computational cost and competitive predictive accuracy across evolving
data. WORK-DMD employs Sherman-Morrison updates within rolling windows,
enabling continuous adaptation to evolving dynamics from only current data,
eliminating the need for lengthy training or large storage requirements for
historical data. Experiments on benchmark datasets across several domains show
that WORK-DMD achieves higher accuracy than several state-of-the-art online
forecasting methods, while requiring only a single pass through the data and
demonstrating particularly strong performance in short-term forecasting. Our
results show that combining kernel evaluations with adaptive matrix updates
achieves strong predictive performance with minimal data requirements. This
sample efficiency offers a practical alternative to deep learning for streaming
forecasting applications.

</details>


### [246] [ParaFormer: Shallow Parallel Transformers with Progressive Approximation](https://arxiv.org/abs/2510.15425)
*Wei Wang,Xiao-Yong Wei,Qing Li*

Main category: cs.LG

TL;DR: 本文提出了一种名为ParaFormer的浅层Transformer架构，通过并行结构和计算实现高效性能，挑战了“越深越好”的传统观念。


<details>
  <summary>Details</summary>
Motivation: 深度模型虽然性能优越，但训练时间长、推理延迟高，难以在资源受限设备上部署，因此需要更高效的架构设计。

Method: 将标准Transformer建模为闭式函数逼近器，理论分析其性能依赖于层间协作而非层数本身，并设计并行分支结构，在算法层面强制实现层间协作与渐进逼近。

Result: 实验表明ParaFormer在性能上优于ViT等标准Transformer，支持最高15.07倍的模型压缩，并在多GPU部署下比FairScale快3.30倍。

Conclusion: Transformer的性能关键在于层间协作而非深度本身，ParaFormer通过并行结构实现了高效且可扩展的模型设计，为高效架构提供了新方向。

Abstract: The widespread 'deeper is better' philosophy has driven the creation of
architectures like ResNet and Transformer, which achieve high performance by
stacking numerous layers. However, increasing model depth comes with challenges
such as longer training times, higher inference latency, and impracticality on
resource-constrained devices. To address these issues, we propose ParaFormer, a
shallow Transformer architecture designed for true parallelism in both
structure and computation. By formulating standard Transformers as function
approximators in closed-form, our theoretical analysis shows that their
performance relies on inter-layer collaboration for progressive approximation,
rather than depth itself. While deep Transformers enforce this collaboration
through sequential designs, we demonstrate that such collaboration is not
inherently tied to sequential structures. ParaFormer removes the sequential
constraint by organizing layers into parallel branches, enforcing inter-layer
collaboration algorithmically. Specifically, we implement progressive
approximation, ensuring that each new branch further reduces the loss from
preceding branches, enabling faster convergence. Extensive experiments validate
ParaFormer's effectiveness, outperforming standard Transformers like ViT.
Moreover, ParaFormer supports up to 15.07x model compression and facilitates
model expansion for adaptive continuous learning. Experimental results on
multi-GPU deployment demonstrate that ParaFormer is 3.30x faster than widely
used parallelism solutions such as FairScale. These advancements stem from our
closed-form formulation of Transformers based on the Universal Approximation
Theorem, which not only explains the ``depth belief'' but also opens new
avenues for designing efficient Transformer architectures. Source code:
https://(open-upon-acceptance)

</details>


### [247] [Safe, Efficient, and Robust Reinforcement Learning for Ranking and Diffusion Models](https://arxiv.org/abs/2510.15429)
*Shashank Gupta*

Main category: cs.LG

TL;DR: 本论文研究了如何设计安全、高效且鲁棒的强化学习方法，涵盖排序推荐和文本到图像生成两个应用领域，提出了具有理论保证的安全算法与改进的策略优化方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习在实际应用中面临安全性、样本效率和鲁棒性等挑战，尤其是在稀疏反馈和模型不确定性条件下，需要保障性能下限并提升学习可靠性。

Method: 采用上下文-bandit RL框架，提出基于曝光的泛化界与反事实风险最小化目标，并设计双稳健估计器；引入基线校正框架下的最优闭式基线以降低方差；提出LOOP算法结合多轨迹扩散与REINFORCE风格基线于PPO目标中。

Result: 所提方法在排序系统中实现了安全部署保证，在策略评估与梯度学习中减少了方差，并在文本到图像生成任务中兼顾了样本效率与生成质量。

Conclusion: 通过理论驱动的算法设计，可在不牺牲效率的前提下实现强化学习的安全性与鲁棒性，为推荐系统与生成模型提供了可信赖的RL解决方案。

Abstract: This dissertation investigates how reinforcement learning (RL) methods can be
designed to be safe, sample-efficient, and robust. Framed through the unifying
perspective of contextual-bandit RL, the work addresses two major application
domains - ranking and recommendation, and text-to-image diffusion models. The
first part of the thesis develops theory and algorithms for safe deployment in
ranking systems. An exposure-based generalisation bound is derived, leading to
a counterfactual risk-minimisation objective whose solution is guaranteed not
to underperform the logging policy, even with sparse feedback. This guarantee
is extended to doubly robust estimators, enabling safety even under adversarial
or misspecified user models and offering practitioners explicit control over
permissible utility loss. The second part turns to single-action bandits, where
various off-policy estimators are unified within a baseline-correction
framework. A closed-form optimal baseline is proposed and shown to minimise
both evaluation and policy-gradient variance, thereby improving off-policy
learning reliability. The final part examines the trade-offs between efficiency
and effectiveness in generative RL. A systematic study of PPO and REINFORCE
motivates the Leave-One-Out PPO (LOOP) algorithm, which combines multiple
diffusion trajectories with a REINFORCE-style baseline inside PPO's clipped
objective. LOOP achieves PPO-level sample efficiency while producing
generations that align more faithfully with textual attributes.

</details>


### [248] [A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning](https://arxiv.org/abs/2510.15444)
*Zhi Zhou,Yuhao Tan,Zenan Li,Yuan Yao,Lan-Zhe Guo,Yu-Feng Li,Xiaoxing Ma*

Main category: cs.LG

TL;DR: 本文提出了RPC，一种基于置信度估计理论框架的采样式测试时扩展方法，通过结合自洽性与困惑度的优点，并引入推理剪枝来减少低概率路径，显著降低推理错误并提升置信度可靠性，同时减少50%采样成本。


<details>
  <summary>Details</summary>
Motivation: 尽管采样式测试时扩展方法在实践中有效，但其理论基础尚不充分，尤其是自洽性和困惑度方法存在估计误差高或模型误差大的问题。

Method: 提出一个新的理论框架，基于该框架设计了RPC方法，包含两个核心组件：困惑度一致性（Perplexity Consistency）和推理剪枝（Reasoning Pruning），以提升估计误差收敛速度并防止退化。

Result: 在七个基准数据集上的实验表明，RPC能有效降低推理错误，置信度更可靠，性能与自洽性相当，但采样成本减少50%。

Conclusion: RPC是一种高效、可靠的测试时扩展方法，兼具低推理误差、高置信度和低计算开销，为大语言模型的推理优化提供了新的理论视角和实践方案。

Abstract: Test-time scaling seeks to improve the reasoning performance of large
language models (LLMs) by adding computational resources. A prevalent approach
within the field is sampling-based test-time scaling methods, which enhance
reasoning by generating multiple reasoning paths for a given input during
inference. However, despite its practical success, the theoretical foundations
remain underexplored. In this paper, we provide the first theoretical framework
for analyzing sampling-based test-time scaling methods, grounded in the
perspective of confidence estimation. Based on the framework, we analyze two
dominant paradigms: self-consistency and perplexity, and reveal key
limitations: self-consistency suffers from high estimation error while
perplexity exhibits substantial modeling error and possible degradation of the
estimation error convergence. To address these limitations, we introduce RPC, a
hybrid method that leverages our theoretical insights through two key
components: Perplexity Consistency and Reasoning Pruning. Perplexity
Consistency combines the strengths of self-consistency and perplexity, boosting
the convergence rate of estimation error from linear to exponential while
preserving model error. Reasoning Pruning prevents degradation by eliminating
low-probability reasoning paths. Both theoretical analysis and empirical
results across seven benchmark datasets demonstrate that RPC has a strong
potential for reducing reasoning error. Notably, RPC achieves reasoning
performance comparable to self-consistency while not only enhancing confidence
reliability but also reducing sampling costs by 50%. The code and resources are
available at https://wnjxyk.github.io/RPC.

</details>


### [249] [Particle Dynamics for Latent-Variable Energy-Based Models](https://arxiv.org/abs/2510.15447)
*Shiqin Tang,Shuxin Zhuang,Rong Feng,Runsheng Yu,Hongzong Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于鞍点优化和Wasserstein梯度流的LVEBM训练方法，无需判别器或辅助网络，具有理论收敛保证且ELBO更紧。


<details>
  <summary>Details</summary>
Motivation: 为了有效训练含隐变量的能量模型，同时捕捉隐藏结构并避免使用复杂的辅助网络。

Method: 将最大似然训练重构为关于潜在变量和联合流形分布的鞍点问题，采用耦合的Wasserstein梯度流进行交替更新，结合过阻尼Langevin动力学与随机参数上升。

Result: 证明了算法在KL散度和Wasserstein-2距离下的收敛性，得到比传统变分推断更紧的ELBO，并在物理系统数值模拟中表现优异。

Conclusion: 该方法为LVEBM提供了一种理论上可靠、实现简洁且性能优越的训练框架。

Abstract: Latent-variable energy-based models (LVEBMs) assign a single normalized
energy to joint pairs of observed data and latent variables, offering
expressive generative modeling while capturing hidden structure. We recast
maximum-likelihood training as a saddle problem over distributions on the
latent and joint manifolds and view the inner updates as coupled Wasserstein
gradient flows. The resulting algorithm alternates overdamped Langevin updates
for a joint negative pool and for conditional latent particles with stochastic
parameter ascent, requiring no discriminator or auxiliary networks. We prove
existence and convergence under standard smoothness and dissipativity
assumptions, with decay rates in KL divergence and Wasserstein-2 distance. The
saddle-point view further yields an ELBO strictly tighter than bounds obtained
with restricted amortized posteriors. Our method is evaluated on numerical
approximations of physical systems and performs competitively against
comparable approaches.

</details>


### [250] [Expediting Reinforcement Learning by Incorporating Knowledge About Temporal Causality in the Environment](https://arxiv.org/abs/2510.15456)
*Jan Corazza,Hadi Partovi Aria,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: 提出一种将时序逻辑因果图融入奖励机制的新方法，以加速策略学习并促进任务规范在新环境中的迁移。


<details>
  <summary>Details</summary>
Motivation: 强化学习在稀疏奖励和复杂事件序列的任务中表现不佳，且现有的概率奖励机器难以手动修改和设计，限制了高阶因果知识的利用和跨域迁移。

Method: 将基于时序逻辑的因果图整合到奖励形式化中，形成新的奖励机制，并结合特殊强化学习算法进行策略学习。

Result: 理论上证明了该方法能收敛到最优策略，并通过实验验证了其在加速学习和迁移任务规范方面的有效性。

Conclusion: 该方法有效利用因果知识提升了稀疏奖励下的学习效率，并增强了任务规范在不同因果结构环境中的可迁移性。

Abstract: Reinforcement learning (RL) algorithms struggle with learning optimal
policies for tasks where reward feedback is sparse and depends on a complex
sequence of events in the environment. Probabilistic reward machines (PRMs) are
finite-state formalisms that can capture temporal dependencies in the reward
signal, along with nondeterministic task outcomes. While special RL algorithms
can exploit this finite-state structure to expedite learning, PRMs remain
difficult to modify and design by hand. This hinders the already difficult
tasks of utilizing high-level causal knowledge about the environment, and
transferring the reward formalism into a new domain with a different causal
structure. This paper proposes a novel method to incorporate causal information
in the form of Temporal Logic-based Causal Diagrams into the reward formalism,
thereby expediting policy learning and aiding the transfer of task
specifications to new environments. Furthermore, we provide a theoretical
result about convergence to optimal policy for our method, and demonstrate its
strengths empirically.

</details>


### [251] [Learning to Answer from Correct Demonstrations](https://arxiv.org/abs/2510.15464)
*Nirmit Joshi,Gene Li,Siddharth Bhandari,Shiva Prasad Kasiviswanathan,Cong Ma,Nathan Srebro*

Main category: cs.LG

TL;DR: 提出了一种新的方法，通过假设奖励模型属于低基数类别，而非演示者属于低复杂度策略类别，来解决从正确示范中学习的问题，该方法在样本复杂度上具有对数级的优势。


<details>
  <summary>Details</summary>
Motivation: 传统方法假设演示者属于低复杂度策略类别，这可能导致最大似然估计失败；本文旨在提出一个更弱的假设条件下的有效学习方法。

Method: 将问题形式化为上下文赌博机中的离线模仿学习，利用奖励模型属于低基数类别的假设，设计了一种新的学习方法。

Result: 证明了基于似然最大化的方法在这种情况下可能失败，并且新方法的学习样本复杂度是奖励类别基数的对数。

Conclusion: 当从正确的示范中学习时，应该超越似然最大化的思路，考虑其他方法。

Abstract: We study the problem of learning to generate an answer (or completion) to a
question (or prompt), where there could be multiple correct answers, any one of
which is acceptable at test time. Learning is based on demonstrations of some
correct answer to each training question, as in Supervised Fine Tuning (SFT).
We formalize the problem as offline imitation learning in contextual bandits,
with demonstrations from some optimal policy, without explicitly observed
rewards. Prior work assumes that the demonstrator belongs to a low-complexity
policy class, which motivates maximum likelihood estimation (i.e., log-loss
minimization). In contrast, we propose relying only on the reward model
(specifying which answers are correct) being in a low-cardinality class, which
we argue is a weaker assumption. We show that likelihood maximization methods
can fail in this case, and instead devise an alternative novel approach that
learns with sample complexity logarithmic in the cardinality of the reward
class. Our work motivates looking beyond likelihood maximization when learning
from correct demonstrations.

</details>


### [252] [Adversary-Free Counterfactual Prediction via Information-Regularized Representations](https://arxiv.org/abs/2510.15479)
*Shiqin Tang,Rong Feng,Shuxin Zhuang,Hongzong Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 提出一种基于信息论的反事实预测方法，通过最小化表示与处理变量之间的互信息来消除治疗-协变量依赖，避免对抗训练，具有理论保证且训练稳定。


<details>
  <summary>Details</summary>
Motivation: 在存在分配偏倚的情况下进行准确的反事实预测，现有方法常依赖对抗训练，存在训练不稳定和调参困难的问题。

Method: 从连接反事实-事实风险差距与互信息的界出发，学习一个对结果有预测性的随机表示Z，并最小化I(Z; T)；推导出可优化的变分目标，结合监督解码器实现稳定训练，并扩展到动态场景。

Result: 在数值模拟和真实临床数据上验证了方法的有效性，在似然、反事实误差和策略评估等指标上优于现有的平衡、重加权和对抗方法，且避免了对抗训练的不稳定性。

Conclusion: 该信息论框架为反事实预测提供了一种理论上合理、训练稳定且易于扩展的新方法，尤其适用于医疗等需要可靠因果推断的领域。

Abstract: We study counterfactual prediction under assignment bias and propose a
mathematically grounded, information-theoretic approach that removes
treatment-covariate dependence without adversarial training. Starting from a
bound that links the counterfactual-factual risk gap to mutual information, we
learn a stochastic representation Z that is predictive of outcomes while
minimizing I(Z; T). We derive a tractable variational objective that
upper-bounds the information term and couples it with a supervised decoder,
yielding a stable, provably motivated training criterion. The framework extends
naturally to dynamic settings by applying the information penalty to sequential
representations at each decision time. We evaluate the method on controlled
numerical simulations and a real-world clinical dataset, comparing against
recent state-of-the-art balancing, reweighting, and adversarial baselines.
Across metrics of likelihood, counterfactual error, and policy evaluation, our
approach performs favorably while avoiding the training instabilities and
tuning burden of adversarial schemes.

</details>


### [253] [OffSim: Offline Simulator for Model-based Offline Inverse Reinforcement Learning](https://arxiv.org/abs/2510.15495)
*Woo-Jin Ahn,Sang-Ryul Baek,Yong-Jun Lee,Hyun-Duck Choi,Myo-Taeg Lim*

Main category: cs.LG

TL;DR: 提出了一种名为OffSim的离线模拟器框架，通过专家轨迹数据联合优化高熵转移模型和基于逆强化学习的奖励函数，实现无需与真实环境交互的策略训练，并在MuJoCo实验中表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖人工设计的模拟器和奖励函数，开发成本高且耗时，因此需要一种能从专家轨迹中自动学习环境动态和奖励结构的方法以降低对真实环境交互的依赖。

Method: 提出OffSim框架，联合优化高熵状态转移模型和逆强化学习（IRL）奖励函数；进一步引入OffSim$^+$，通过边际奖励机制支持多数据集设置下的更好探索。

Result: 在MuJoCo环境中进行的大量实验表明，OffSim相比现有的离线逆强化学习方法显著提升了性能，验证了其有效性与鲁棒性。

Conclusion: OffSim能够有效从专家轨迹中学习环境模拟和奖励函数，支持高效的离线策略训练，为减少强化学习对人工设计和环境交互的依赖提供了可行方案。

Abstract: Reinforcement learning algorithms typically utilize an interactive simulator
(i.e., environment) with a predefined reward function for policy training.
Developing such simulators and manually defining reward functions, however, is
often time-consuming and labor-intensive. To address this, we propose an
Offline Simulator (OffSim), a novel model-based offline inverse reinforcement
learning (IRL) framework, to emulate environmental dynamics and reward
structure directly from expert-generated state-action trajectories. OffSim
jointly optimizes a high-entropy transition model and an IRL-based reward
function to enhance exploration and improve the generalizability of the learned
reward. Leveraging these learned components, OffSim can subsequently train a
policy offline without further interaction with the real environment.
Additionally, we introduce OffSim$^+$, an extension that incorporates a
marginal reward for multi-dataset settings to enhance exploration. Extensive
MuJoCo experiments demonstrate that OffSim achieves substantial performance
gains over existing offline IRL methods, confirming its efficacy and
robustness.

</details>


### [254] [The Road Less Traveled: Enhancing Exploration in LLMs via Sequential Sampling](https://arxiv.org/abs/2510.15502)
*Shijia Kang,Muhan Zhang*

Main category: cs.LG

TL;DR: 提出SESA（Sequential SAmpling）框架，通过序列化生成多样化推理草图来提升大语言模型在强化学习中的探索能力，缓解熵崩溃问题，显著提高路径多样性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 强化学习中大语言模型常因探索不足和熵崩溃导致多样性下降，影响性能提升；并行采样加剧该问题，需新方法促进有效探索。

Method: 设计SESA框架，先依次生成不同的解题草图，再扩展为完整推理路径，通过条件依赖前序输出来维持多样性，避免策略坍缩。

Result: 在合成任务上，SESA优于传统RL方法，表现出更高的路径多样性与抗坍缩能力；在真实任务中，三个代理基准上的成功率分别提升了+0.25、+0.42和+0.07（相对基线RL最高提升211%）。

Conclusion: SESA通过结构化探索机制有效缓解了RL训练中LLMs的熵崩溃问题，增强了推理多样性和整体性能，为构建更高效的推理系统提供了新方向。

Abstract: Reinforcement learning (RL) has been pivotal in enhancing the reasoning
capabilities of large language models (LLMs), but it often suffers from limited
exploration and entropy collapse, where models exploit a narrow set of
solutions, leading to a loss of sampling diversity and subsequently preventing
RL from further improving performance. This issue is exacerbated in parallel
sampling methods, where multiple outputs are drawn from the same distribution,
potentially causing the model to converge to similar solutions. We propose
SESA, a novel SEquential SAmpling framework that mitigates this challenge by
generating diverse solution sketches sequentially before expanding them into
full reasoning paths. This approach ensures broader exploration by conditioning
each new output on previous ones, promoting diversity throughout the process
and preventing policy collapse. Our experiments on a synthetic task show that
sequential sampling consistently outperforms traditional RL methods in terms of
path diversity and recovery from collapse. Further evaluations on real-world
tasks demonstrate that SESA improves both the exploration of valid strategies
and the overall performance of LLMs. On three agent benchmarks, SESA lifts
success rates by $+0.25$, $+0.42$, and $+0.07$ absolute over the base model (up
to an additional $211\%$ relative improvement over baseline RL), underscoring
its exploration advantage. This work introduces a structured approach to
exploration, paving the way for more effective and diverse reasoning in
RL-trained LLMs. Our code is released at https://github.com/MuLabPKU/sesa.

</details>


### [255] [Theoretical Refinement of CLIP by Utilizing Linear Structure of Optimal Similarity](https://arxiv.org/abs/2510.15508)
*Naoki Yoshida,Satoshi Hayakawa,Yuhta Takida,Toshimitsu Uesaka,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: 提出KME-CLIP，利用再生核希尔伯特空间中的内积来更好地逼近模态间点互信息（PMI），提升多模态对比学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP及其变体未能充分利用PMI的线性结构，导致相似度计算不够最优。

Method: 在再生核希尔伯特空间中通过内积建模PMI，理论证明可任意精度逼近PMI。

Result: 在多个检索和分类任务上优于标准CLIP方法。

Conclusion: KME-CLIP能更有效地建模跨模态相似性，提升多模态预训练模型性能。

Abstract: In this study, we propose an enhancement to the similarity computation
mechanism in multi-modal contrastive pretraining frameworks such as CLIP. Prior
theoretical research has demonstrated that the optimal similarity metrics
between paired modalities should correspond to the pointwise mutual information
(PMI) between the two modalities. However, the current implementations of CLIP
and its variants fail to fully utilize the underlying linear structure of PMI.
We therefore propose KME-CLIP, which leverages this structure through the inner
product in a reproducing kernel Hilbert space. We theoretically prove that our
method can approximate PMI with arbitrary accuracy and empirically demonstrate
that our approach overall outperforms the standard CLIP formulation across
several retrieval and classification tasks.

</details>


### [256] [Language Models are Injective and Hence Invertible](https://arxiv.org/abs/2510.15511)
*Giorgos Nikolaou,Tommaso Mencattini,Donato Crisostomi,Andrea Santilli,Yannis Panagakis,Emanuele Rodola'*

Main category: cs.LG

TL;DR: 本文证明了Transformer语言模型在从离散输入序列映射到连续表示时是单射（injective）且无损的，提出了SipIt算法可高效准确地从隐藏激活中重建输入文本。


<details>
  <summary>Details</summary>
Motivation: 由于Transformer中的非线性激活和归一化操作通常被认为是非单射的，可能导致信息丢失，本文旨在挑战这一观点，探究语言模型是否真正保留了输入的完整信息。

Method: 通过数学证明建立模型在初始化和训练过程中保持单射性的理论基础，并在六种最先进的语言模型上进行数十亿次碰撞测试以验证无碰撞现象，同时提出SipIt算法实现从隐藏状态线性时间复杂度下的精确输入重构。

Result: 理论证明和实验均表明Transformer语言模型在实践中是单射的，未观察到任何表示碰撞，SipIt算法能够高效且准确地恢复原始输入文本。

Conclusion: 注入性是语言模型的一个基本且可利用的性质，对模型透明性、可解释性和安全部署具有重要意义。

Abstract: Transformer components such as non-linear activations and normalization are
inherently non-injective, suggesting that different inputs could map to the
same output and prevent exact recovery of the input from a model's
representations. In this paper, we challenge this view. First, we prove
mathematically that transformer language models mapping discrete input
sequences to their corresponding sequence of continuous representations are
injective and therefore lossless, a property established at initialization and
preserved during training. Second, we confirm this result empirically through
billions of collision tests on six state-of-the-art language models, and
observe no collisions. Third, we operationalize injectivity: we introduce
SipIt, the first algorithm that provably and efficiently reconstructs the exact
input text from hidden activations, establishing linear-time guarantees and
demonstrating exact invertibility in practice. Overall, our work establishes
injectivity as a fundamental and exploitable property of language models, with
direct implications for transparency, interpretability, and safe deployment.

</details>


### [257] [Revisiting Knowledge Distillation: The Hidden Role of Dataset Size](https://arxiv.org/abs/2510.15516)
*Giulia Lanzillotta,Felix Sarnthein,Gil Kur,Thomas Hofmann,Bobby He*

Main category: cs.LG

TL;DR: 本文研究了知识蒸馏在不同数据集大小下的表现，发现其在低数据量情况下效果更佳，提出了知识蒸馏的数据效率特性，并验证了现有理论的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管知识蒸馏已被广泛使用，但其工作原理尚不清楚，尤其是关于模型大小和泛化能力的研究较多，而对数据集大小的影响研究较少。

Method: 通过在多种数据集、任务和神经网络架构上进行实验，分析知识蒸馏在不同数据量条件下的表现，并测试现有理论的预测能力。

Result: 实验证明知识蒸馏的效果在小数据集上不仅保持而且增强，支持‘暗知识’假说，否定了标签平滑假说。

Conclusion: 数据集大小是影响知识蒸馏机制的一个基本但被忽视的因素，知识蒸馏具有显著的数据效率特性。

Abstract: The concept of knowledge distillation (KD) describes the training of a
student model from a teacher model and is a widely adopted technique in deep
learning. However, it is still not clear how and why distillation works.
Previous studies focus on two central aspects of distillation: model size, and
generalisation. In this work we study distillation in a third dimension:
dataset size. We present a suite of experiments across a wide range of
datasets, tasks and neural architectures, demonstrating that the effect of
distillation is not only preserved but amplified in low-data regimes. We call
this newly discovered property the data efficiency of distillation. Equipped
with this new perspective, we test the predictive power of existing theories of
KD as we vary the dataset size. Our results disprove the hypothesis that
distillation can be understood as label smoothing, and provide further evidence
in support of the dark knowledge hypothesis. Finally, we analyse the impact of
modelling factors such as the objective, scale and relative number of samples
on the observed phenomenon. Ultimately, this work reveals that the dataset size
may be a fundamental but overlooked variable in the mechanisms underpinning
distillation.

</details>


### [258] [An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation](https://arxiv.org/abs/2510.15541)
*Saumya B*

Main category: cs.LG

TL;DR: 该研究探讨了基于蒙特卡洛Dropout的不确定性估计在2D脑肿瘤MRI分割中识别边界误差的有效性，发现其与分割误差的相关性较弱，尤其是在肿瘤边界区域，提示需要更优或混合的不确定性估计方法。


<details>
  <summary>Details</summary>
Motivation: 准确的脑肿瘤分割对诊断和治疗至关重要，而模型不确定性估计（如MC Dropout）是否能有效识别分割错误，特别是在肿瘤边界附近，尚不明确。

Method: 使用U-Net模型在四种数据增强设置下训练，通过50次随机前向传播计算MC Dropout不确定性，并采用皮尔逊和斯皮尔曼相关系数分析其与像素级误差的相关性。

Result: 全局相关性较弱（r ≈ 0.30–0.38），边界相关性可忽略（|r| < 0.05）；不同增强策略间差异显著但无实际意义。

Conclusion: MC Dropout产生的不确定性对定位边界误差作用有限，需探索其他或混合不确定性估计方法以提升医学图像分割的可靠性。

Abstract: Accurate brain tumor segmentation from MRI is vital for diagnosis and
treatment planning. Although Monte Carlo (MC) Dropout is widely used to
estimate model uncertainty, its effectiveness in identifying segmentation
errors -- especially near tumor boundaries -- remains unclear. This study
empirically examines the relationship between MC Dropout--based uncertainty and
segmentation error in 2D brain tumor MRI segmentation using a U-Net trained
under four augmentation settings: none, horizontal flip, rotation, and scaling.
Uncertainty was computed from 50 stochastic forward passes and correlated with
pixel-wise errors using Pearson and Spearman coefficients. Results show weak
global correlations ($r \approx 0.30$--$0.38$) and negligible boundary
correlations ($|r| < 0.05$). Although differences across augmentations were
statistically significant ($p < 0.001$), they lacked practical relevance. These
findings suggest that MC Dropout uncertainty provides limited cues for boundary
error localization, underscoring the need for alternative or hybrid uncertainty
estimation methods in medical image segmentation.

</details>


### [259] [Doubly Robust Estimation of Causal Effects in Strategic Equilibrium Systems](https://arxiv.org/abs/2510.15555)
*Sibo Xiao*

Main category: cs.LG

TL;DR: 提出了一种新的Strategic Doubly Robust (SDR)估计器，用于在策略环境中进行因果推断，结合了策略均衡建模与双重稳健估计，理论和实证结果表明其在偏差减少和可扩展性方面优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在存在策略性行为的环境中，传统的因果推断方法难以处理由智能体策略互动引起的内生性处理分配问题，因此需要一种能同时考虑策略行为和双重稳健性的新方法。

Method: 将策略均衡建模与双重稳健估计相结合，构建SDR估计器，并在策略性未混淆条件下证明其一致性和渐近正态性。

Result: 理论分析显示SDR具有一致性和渐近正态性；实验表明其相较于基线方法在不同策略强度下实现了7.6%到29.3%的偏差降低，并在智能体数量增加时保持良好的可扩展性。

Conclusion: SDR为存在策略响应的因果推断提供了一个有原则且可靠的新框架，能够在复杂策略环境中有效提升估计精度和稳健性。

Abstract: We introduce the Strategic Doubly Robust (SDR) estimator, a novel framework
that integrates strategic equilibrium modeling with doubly robust estimation
for causal inference in strategic environments. SDR addresses endogenous
treatment assignment arising from strategic agent behavior, maintaining double
robustness while incorporating strategic considerations. Theoretical analysis
confirms SDR's consistency and asymptotic normality under strategic
unconfoundedness. Empirical evaluations demonstrate SDR's superior performance
over baseline methods, achieving 7.6\%-29.3\% bias reduction across varying
strategic strengths and maintaining robust scalability with agent populations.
The framework provides a principled approach for reliable causal inference when
agents respond strategically to interventions.

</details>


### [260] [On the Neural Feature Ansatz for Deep Neural Networks](https://arxiv.org/abs/2510.15563)
*Edward Tansley,Estelle Massart,Coralia Cartis*

Main category: cs.LG

TL;DR: 本文研究了深度神经网络中特征学习的数学基础，提出了神经特征假设（NFA），并证明了在多层网络中NFA成立且指数α与深度L相关（α=1/L），同时讨论了权重衰减和初始化对NFA的影响，并通过实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 理解特征学习是建立深度神经网络数学基础的重要开放问题，本文旨在扩展神经特征假设（NFA）到深层网络并分析其成立条件。

Method: 基于梯度流动力学和平衡权重初始化的假设，通过理论证明和数值实验验证NFA在多层线性网络中的成立性，并探讨非平衡初始化和非线性激活函数下的情况。

Result: 证明了对于L≥2层的网络，NFA以指数α=1/L成立；在施加权重衰减时，非平衡初始化下NFA渐近成立；但某些非线性激活的网络架构存在反例表明NFA不成立。实验验证覆盖多种优化算法、权重衰减率和初始化方案。

Conclusion: NFA在深层线性网络中具有深度依赖性（α=1/L），权重衰减有助于非平衡初始化下NFA的成立，但在某些非线性网络中NFA不成立，揭示了特征学习机制的复杂性。

Abstract: Understanding feature learning is an important open question in establishing
a mathematical foundation for deep neural networks. The Neural Feature Ansatz
(NFA) states that after training, the Gram matrix of the first-layer weights of
a deep neural network is proportional to some power $\alpha>0$ of the average
gradient outer product (AGOP) of this network with respect to its inputs.
Assuming gradient flow dynamics with balanced weight initialization, the NFA
was proven to hold throughout training for two-layer linear networks with
exponent $\alpha = 1/2$ (Radhakrishnan et al., 2024). We extend this result to
networks with $L \geq 2$ layers, showing that the NFA holds with exponent
$\alpha = 1/L$, thus demonstrating a depth dependency of the NFA. Furthermore,
we prove that for unbalanced initialization, the NFA holds asymptotically
through training if weight decay is applied. We also provide counterexamples
showing that the NFA does not hold for some network architectures with
nonlinear activations, even when these networks fit arbitrarily well the
training data. We thoroughly validate our theoretical results through numerical
experiments across a variety of optimization algorithms, weight decay rates and
initialization schemes.

</details>


### [261] [Attn-JGNN: Attention Enhanced Join-Graph Neural Networks](https://arxiv.org/abs/2510.15583)
*Jixin Zhang,Yong Lai*

Main category: cs.LG

TL;DR: 提出了一种注意力增强的联合图神经网络（Attn-JGNN）模型，用于求解#SAT问题，在准确率上显著优于其他神经网络方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高#SAT问题的求解精度，尤其是在处理复杂CNF公式时现有神经网络方法表现不足。

Method: 基于迭代联合图传播（IJGP）算法，利用树分解将CNF公式编码为联合图，并在图上进行迭代消息传递；引入注意力机制优化簇内和簇间的信息聚合，以关注关键变量和结构，最后通过学习划分函数来近似模型计数。

Result: 实验表明，Attn-JGNN在多个测试实例上优于其他神经网络方法，显著提升了模型计数的准确性。

Conclusion: Attn-JGNN通过结合树分解与注意力增强的消息传递机制，有效提升了#SAT问题的求解性能，为基于学习的可满足性计数提供了新思路。

Abstract: We propose an Attention Enhanced Join-Graph Neural Networks(Attn-JGNN) model
for solving #SAT problems, which significantly improves the solving accuracy.
Inspired by the Iterative Join Graph Propagation (IJGP) algorithm, Attn-JGNN
uses tree decomposition to encode the CNF formula into a join-graph, then
performs iterative message passing on the join-graph, and finally approximates
the model number by learning partition functions. In order to further improve
the accuracy of the solution, we apply the attention mechanism in and between
clusters of the join-graphs, which makes Attn-JGNN pay more attention to the
key variables and clusters in probabilistic inference, and reduces the
redundant calculation. Finally, our experiments show that our Attn-JGNN model
achieves better results than other neural network methods.

</details>


### [262] [GRATING: Low-Latency and Memory-Efficient Semantic Selection on Device](https://arxiv.org/abs/2510.15620)
*Jiahao Zhou,Chengliang Lin,Dingji Li,Mingkai Dong,Haibo Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为GRATING的训练-free推理系统，通过单体前向传播和渐进式聚类剪枝，在保持精度的同时显著降低了语义top-K选择的延迟和内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有的语义top-K选择方法在边缘设备上存在高延迟和高内存消耗的问题，限制了其在端侧AI服务中的部署。作者发现只需关注候选之间的相对排序而非精确得分，并观察到序列级稀疏性，从而提出新的优化思路。

Method: 基于中间层早期稳定性的观察，提出单体前向传播机制，结合全局候选视图进行渐进式聚类剪枝；通过双层滑动窗口和分块执行策略重叠I/O与计算，控制峰值内存使用。

Result: 在0.6B到8B参数的重排序模型上，相比现有最先进基线，微基准测试中延迟降低最高达89.0%，峰值内存减少最高达94.9%；在三个真实端侧AI应用中，延迟降低11.6%-51.0%，峰值内存减少18.6%-77.8%。

Conclusion: GRATING在不损失精度的前提下，大幅提升了top-K选择的效率和可部署性，适用于检索增强生成、智能体记忆和个性化推荐等端侧AI场景。

Abstract: Semantic top-K selection with cross-encoder rerankers underpins of on-device
AI services, such as retrieval-augmented generation, agent memory, and
personalized recommendation. However, its latency and memory demands dominate
end-to-end budgets on edge hardware. Revisiting the objective of top-K
selection, we reveal that only relative rankings matter, not exact
per-candidate scores. We further observe sequence-level sparsity: relative
rankings stabilize early in intermediate layers, allowing pruning opportunities
prior to completing full inference.
  Building on this insight, we propose monolithic forwarding and develop a
training-free inference system, GRATING. By maintaining a global view of all
candidates, it reduces latency through progressive cluster pruning. It also
bounds peak memory usage by strategically overlapping I/O with computation via
dual-layer sliding window and chunked execution. We evaluate GRATING against
state-of-the-art baselines on rerankers from 0.6B to 8B parameters across Apple
M2 and RTX 5070. GRATING consistently reduces latency by up to 89.0% and peak
memory by up to 94.9% in microbenchmarks, without any loss in precision. Across
three real-world on-device AI applications, GRATING lowers latency by
11.6%-51.0% and peak memory by 18.6%-77.8%, demonstrating substantial
improvements in efficiency and deployability.

</details>


### [263] [CQD-SHAP: Explainable Complex Query Answering via Shapley Values](https://arxiv.org/abs/2510.15623)
*Parsa Abbasi,Stefan Heindorf*

Main category: cs.LG

TL;DR: 本文提出了一种基于Shapley值的可解释框架CQD-SHAP，用于复杂查询问答（CQA），通过量化查询各部分对答案排序的贡献，提升神经模型在不完整知识图谱上的推理透明度。


<details>
  <summary>Details</summary>
Motivation: 现有CQA方法多为黑箱模型，缺乏对查询各部分重要性的解释，影响用户信任；尽管神经符号方法（如CQD）可追踪中间结果，但仍无法解释不同查询部分的相对贡献。

Method: 提出CQD-SHAP框架，基于合作博弈论中的Shapley值计算每个查询部分对特定答案排序的贡献，并满足所有Shapley公理，从而提供符合理论基础的解释。

Result: 在必要性和充分性解释方面的自动评估显示，CQD-SHAP在大多数查询类型上优于多种基线方法，验证了其解释的有效性。

Conclusion: CQD-SHAP为神经CQA模型提供了理论可靠且有效的解释能力，揭示了神经预测器从不完整知识图谱中推断新知识的价值，增强了模型的可解释性与可信度。

Abstract: Complex query answering (CQA) goes beyond the well-studied link prediction
task by addressing more sophisticated queries that require multi-hop reasoning
over incomplete knowledge graphs (KGs). Research on neural and neurosymbolic
CQA methods is still an emerging field. Almost all of these methods can be
regarded as black-box models, which may raise concerns about user trust.
Although neurosymbolic approaches like CQD are slightly more interpretable,
allowing intermediate results to be tracked, the importance of different parts
of the query remains unexplained. In this paper, we propose CQD-SHAP, a novel
framework that computes the contribution of each query part to the ranking of a
specific answer. This contribution explains the value of leveraging a neural
predictor that can infer new knowledge from an incomplete KG, rather than a
symbolic approach relying solely on existing facts in the KG. CQD-SHAP is
formulated based on Shapley values from cooperative game theory and satisfies
all the fundamental Shapley axioms. Automated evaluation of these explanations
in terms of necessary and sufficient explanations, and comparisons with various
baselines, shows the effectiveness of this approach for most query types.

</details>


### [264] [Decentralized Parameter-Free Online Learning](https://arxiv.org/abs/2510.15644)
*Tomas Ortega,Hamid Jafarkhani*

Main category: cs.LG

TL;DR: 提出首个无需调参的去中心化在线学习算法，通过多智能体掷币与八卦步骤结合，实现网络遗憾的次线性界。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化在线学习中需要超参数调节的问题，提供一种无需调参且具有理论保证的方法。

Method: 引入基于“投注函数”的新框架，将多智能体掷币与八卦（gossip）通信步骤结合，实现去中心化的协同学习。

Result: 理论分析证明了次线性的网络遗憾界，并在合成和真实数据集上通过实验验证了算法有效性。

Conclusion: 该算法家族无需调参即可实现良好性能，适用于分布式感知、去中心化优化和协作机器学习等场景。

Abstract: We propose the first parameter-free decentralized online learning algorithms
with network regret guarantees, which achieve sublinear regret without
requiring hyperparameter tuning. This family of algorithms connects multi-agent
coin-betting and decentralized online learning via gossip steps. To enable our
decentralized analysis, we introduce a novel "betting function" formulation for
coin-betting that simplifies the multi-agent regret analysis. Our analysis
shows sublinear network regret bounds and is validated through experiments on
synthetic and real datasets. This family of algorithms is applicable to
distributed sensing, decentralized optimization, and collaborative ML
applications.

</details>


### [265] [Deep Neural ODE Operator Networks for PDEs](https://arxiv.org/abs/2510.15651)
*Ziqian Li,Kang Liu,Yongcun Song,Hangrui Yue,Enrique Zuazua*

Main category: cs.LG

TL;DR: 本文提出了一种名为NODE-ONet的深度神经ODE算子网络框架，用于求解偏微分方程，结合物理信息提升模型在时间外推和泛化能力方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有算子学习方法常忽略PDE内在的物理知识，导致难以捕捉时间动态且泛化能力差。

Method: 采用编码器-解码器架构，包含空间编码器、编码物理信息的神经ODE（用于建模潜在时间动态）和物理空间解码器，并进行理论误差分析。

Result: 在非线性扩散-反应方程和Navier-Stokes方程上实验表明，该方法具有高精度、高效计算能力，并能预测训练时间范围之外的解。

Conclusion: NODE-ONet通过融合物理知识显著提升了算子学习的鲁棒性、效率和泛化能力，具备跨PDE家族的通用性和可扩展性，是科学机器学习中有前景的工具。

Abstract: Operator learning has emerged as a promising paradigm for developing
efficient surrogate models to solve partial differential equations (PDEs).
However, existing approaches often overlook the domain knowledge inherent in
the underlying PDEs and hence suffer from challenges in capturing temporal
dynamics and generalization issues beyond training time frames. This paper
introduces a deep neural ordinary differential equation (ODE) operator network
framework, termed NODE-ONet, to alleviate these limitations. The framework
adopts an encoder-decoder architecture comprising three core components: an
encoder that spatially discretizes input functions, a neural ODE capturing
latent temporal dynamics, and a decoder reconstructing solutions in physical
spaces. Theoretically, error analysis for the encoder-decoder architecture is
investigated. Computationally, we propose novel physics-encoded neural ODEs to
incorporate PDE-specific physical properties. Such well-designed neural ODEs
significantly reduce the framework's complexity while enhancing numerical
efficiency, robustness, applicability, and generalization capacity. Numerical
experiments on nonlinear diffusion-reaction and Navier-Stokes equations
demonstrate high accuracy, computational efficiency, and prediction
capabilities beyond training time frames. Additionally, the framework's
flexibility to accommodate diverse encoders/decoders and its ability to
generalize across related PDE families further underscore its potential as a
scalable, physics-encoded tool for scientific machine learning.

</details>


### [266] [Fast and Compact Tsetlin Machine Inference on CPUs Using Instruction-Level Optimization](https://arxiv.org/abs/2510.15653)
*Yefan Zeng,Shengyu Duan,Rishad Shafik,Alex Yakovlev*

Main category: cs.LG

TL;DR: 提出了一种基于指令级按位操作和早期退出机制的高效Tsetlin机器软件实现，显著提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 利用Tsetlin机器的逻辑运算特性，在资源受限设备上实现高速推理。

Method: 采用按位操作进行紧凑模型表示，并引入基于字面量重排序的早期退出机制以减少计算开销。

Result: 在ARM处理器上的实验表明，相比传统实现，推理时间最多减少96.71%，且代码密度相当。

Conclusion: 所提出的优化方法大幅提升了Tsetlin机器的推理效率，适用于资源受限环境。

Abstract: The Tsetlin Machine (TM) offers high-speed inference on resource-constrained
devices such as CPUs. Its logic-driven operations naturally lend themselves to
parallel execution on modern CPU architectures. Motivated by this, we propose
an efficient software implementation of the TM by leveraging instruction-level
bitwise operations for compact model representation and accelerated processing.
To further improve inference speed, we introduce an early exit mechanism, which
exploits the TM's AND-based clause evaluation to avoid unnecessary
computations. Building upon this, we propose a literal Reorder strategy
designed to maximize the likelihood of early exits. This strategy is applied
during a post-training, pre-inference stage through statistical analysis of all
literals and the corresponding actions of their associated Tsetlin Automata
(TA), introducing negligible runtime overhead. Experimental results using the
gem5 simulator with an ARM processor show that our optimized implementation
reduces inference time by up to 96.71% compared to the conventional
integer-based TM implementations while maintaining comparable code density.

</details>


### [267] [WARP-LUTs - Walsh-Assisted Relaxation for Probabilistic Look Up Tables](https://arxiv.org/abs/2510.15655)
*Lino Gerlach,Liv Våge,Thore Gerlach,Elliott Kauffman*

Main category: cs.LG

TL;DR: 提出了一种名为WARP-LUTs的新方法，通过Walsh变换辅助的松弛技术，实现更高效、参数更少的逻辑门组合学习，在CIFAR-10上比DLGNs收敛更快且保持相当精度。


<details>
  <summary>Details</summary>
Motivation: 现有乘法自由模型（如DLGNs）训练计算成本高，且难以推广到多输入逻辑块，限制了在高效硬件部署中的应用。

Method: 引入WARP-LUTs，采用基于梯度的方法结合Walsh变换对概率查找表进行松弛优化，减少可训练参数数量，提升训练效率。

Result: 在CIFAR-10上，WARP-LUTs相比DLGNs显著加快了收敛速度，同时保持了相当的准确率，并展现出向高输入逻辑块扩展的潜力。

Conclusion: WARP-LUTs是一种更具训练效率和可扩展性的逻辑门学习框架，有望推动在FPGA上的极高效部署及其在实时科学应用中的使用。

Abstract: Fast and efficient machine learning is of growing interest to the scientific
community and has spurred significant research into novel model architectures
and hardware-aware design. Recent hard? and software co-design approaches have
demonstrated impressive results with entirely multiplication-free models.
Differentiable Logic Gate Networks (DLGNs), for instance, provide a
gradient-based framework for learning optimal combinations of low-level logic
gates, setting state-of-the-art trade-offs between accuracy, resource usage,
and latency. However, these models suffer from high computational cost during
training and do not generalize well to logic blocks with more inputs. In this
work, we introduce Walsh-Assisted Relaxation for Probabilistic Look-Up Tables
(WARP-LUTs) - a novel gradient-based method that efficiently learns
combinations of logic gates with substantially fewer trainable parameters. We
demonstrate that WARP-LUTs achieve significantly faster convergence on CIFAR-10
compared to DLGNs, while maintaining comparable accuracy. Furthermore, our
approach suggests potential for extension to higher-input logic blocks,
motivating future research on extremely efficient deployment on modern FPGAs
and its real-time science applications.

</details>


### [268] [CarBoN: Calibrated Best-of-N Sampling Improves Test-time Reasoning](https://arxiv.org/abs/2510.15674)
*Yung-Chen Tang,Pin-Yu Chen,Andrea Cavallaro*

Main category: cs.LG

TL;DR: 提出了一种名为CarBoN的测试时校准框架，通过自适应调整模型 logits 来提升推理路径的质量，在减少采样次数的同时提高准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时扩展方法（如Best-of-N）随着N增大效率下降，存在收益递减问题，需要更高效的推理优化方法。

Method: 提出CarBoN，包含两个阶段：先探索解空间，然后学习输入特定的温度T和偏移向量δ来校准logits，引导生成更可靠的推理路径。

Result: 在MATH-500和AIME-2024上实验显示，CarBoN相比Baseline最多减少4倍rollout达到相同准确率，并在固定预算下常获得更高准确率；同时该框架可推广到beam search等步级采样策略。

Conclusion: CarBoN有效提升了语言模型在推理任务中的测试时扩展效率，通过动态logits校准在有限采样下显著改善了期望奖励下界，且无需重新训练大模型。

Abstract: Allocating more computation during inference time (test-time scaling)
improves language model performance, especially for reasoning tasks. However,
popular methods like Best-of-$N$ sampling often show diminishing returns as $N$
increases. To address this inefficiency, we introduce a general test-time
calibration framework that adaptively modifies the model toward high-reward
reasoning paths, with theoretical guarantees of improving the lower bound of
expected reward under finite sampling, all without large language model (LLM)
retraining. Within this framework, we propose CarBoN (Calibrated Best-of-$N$),
a two-phase method that first explores the solution space and then learns a
calibration of the logits via an input-specific temperature $T$ and additive
shift vector $\delta$, guiding generation toward more reliable reasoning.
Experiments on MATH-500 and AIME-2024 show that CarBoN improves efficiency,
with up to $4\times$ fewer rollouts to reach the same accuracy, while often
achieving higher accuracy under fixed budgets. We also analyze the
complementary roles of $T$ and $\delta$ in balancing output diversity and
correctness, and demonstrate that the framework also generalizes to step-level
sampling strategies such as beam search. For more information, please refer to
our project page at huggingface.co/spaces/TrustSafeAI/Test-Time-Calibration.

</details>


### [269] [KS-Net: Multi-layer network model for determining the rotor type from motor parameters in interior PMSMs](https://arxiv.org/abs/2510.15688)
*Kivanc Dogan,Ahmet Orhan*

Main category: cs.LG

TL;DR: 本研究提出了一种基于机器学习的方法，利用电磁参数对IPMSM电机转子形状（2D型、V型、Nabla型）进行分类，以替代传统的高计算成本有限元法（FEM）。通过自定义深度学习模型KS-Net与多种传统算法在9000个样本的平衡数据集上进行10折交叉验证比较，结果表明Cubic SVM和Quadratic SVM达到100%准确率，KS-Net也实现了99.98%的高准确率。该方法为电机设计、自动转子识别和数据驱动故障诊断提供了快速且经济高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统IPMSM转子形状分析依赖有限元法（FEM），计算成本高、耗时长，亟需一种高效、精确且低成本的替代方法。

Method: 采用机器学习方法对IPMSM转子形状进行分类，构建包含9000个样本的平衡数据集，使用10折交叉验证评估KS-Net、Cubic SVM、Quadratic SVM、KNN和决策树等模型性能，并以准确率、精确率、召回率和F1分数作为评价指标。

Result: Cubic SVM和Quadratic SVM实现100%分类准确率，KS-Net达到99.98%准确率（仅2个误分类），显著优于或媲美传统FEM方法。

Conclusion: 基于电磁参数的数据驱动方法可高效准确地预测IPMSM转子形状，为电机设计优化、自动化识别及故障诊断提供了可行且经济的替代方案，具有广泛工程应用前景。

Abstract: The demand for high efficiency and precise control in electric drive systems
has led to the widespread adoption of Interior Permanent Magnet Synchronous
Motors (IPMSMs). The performance of these motors is significantly influenced by
rotor geometry. Traditionally, rotor shape analysis has been conducted using
the finite element method (FEM), which involves high computational costs. This
study aims to classify the rotor shape (2D type, V type, Nabla type) of IPMSMs
using electromagnetic parameters through machine learning-based methods and to
demonstrate the applicability of this approach as an alternative to classical
methods. In this context, a custom deep learning model, KS-Net, developed by
the user, was comparatively evaluated against Cubic SVM, Quadratic SVM, Fine
KNN, Cosine KNN, and Fine Tree algorithms. The balanced dataset, consisting of
9,000 samples, was tested using 10-fold cross-validation, and performance
metrics such as accuracy, precision, recall, and F1-score were employed. The
results indicate that the Cubic SVM and Quadratic SVM algorithms classified all
samples flawlessly, achieving 100% accuracy, while the KS-Net model achieved
99.98% accuracy with only two misclassifications, demonstrating competitiveness
with classical methods. This study shows that the rotor shape of IPMSMs can be
predicted with high accuracy using data-driven approaches, offering a fast and
cost-effective alternative to FEM-based analyses. The findings provide a solid
foundation for accelerating motor design processes, developing automated rotor
identification systems, and enabling data-driven fault diagnosis in engineering
applications.

</details>


### [270] [Constrained Adversarial Perturbation](https://arxiv.org/abs/2510.15699)
*Virendra Nishad,Bhaskar Mukhoty,Hilal AlQuabeh,Sandeep K. Shukla,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 提出了一种基于增广拉格朗日的约束对抗扰动方法（CAP），在保证领域特定约束的前提下，提升通用对抗攻击的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有通用对抗扰动方法常忽略特征空间中的领域约束，导致生成的对抗样本不现实或易被检测，限制了其实际应用。

Method: 通过构建增广拉格朗日形式的min-max优化问题，引入多类复杂约束，并采用基于梯度的交替优化策略求解，提出CAP算法。同时设计了从数据中学习特征约束的机制。

Result: 在金融、IT网络和信息物理系统等多个领域验证了CAP的有效性，相比基线方法在攻击成功率上更高且运行时间显著减少，同时可推广到个体对抗扰动场景。

Conclusion: CAP能够在满足领域约束的前提下生成更真实、有效的对抗样本，提升了对抗攻击在实际场景中的适用性，并为约束特征空间下的模型安全性研究提供了新思路。

Abstract: Deep neural networks have achieved remarkable success in a wide range of
classification tasks. However, they remain highly susceptible to adversarial
examples - inputs that are subtly perturbed to induce misclassification while
appearing unchanged to humans. Among various attack strategies, Universal
Adversarial Perturbations (UAPs) have emerged as a powerful tool for both
stress testing model robustness and facilitating scalable adversarial training.
Despite their effectiveness, most existing UAP methods neglect domain specific
constraints that govern feature relationships. Violating such constraints, such
as debt to income ratios in credit scoring or packet flow invariants in network
communication, can render adversarial examples implausible or easily
detectable, thereby limiting their real world applicability.
  In this work, we advance universal adversarial attacks to constrained feature
spaces by formulating an augmented Lagrangian based min max optimization
problem that enforces multiple, potentially complex constraints of varying
importance. We propose Constrained Adversarial Perturbation (CAP), an efficient
algorithm that solves this problem using a gradient based alternating
optimization strategy. We evaluate CAP across diverse domains including
finance, IT networks, and cyber physical systems, and demonstrate that it
achieves higher attack success rates while significantly reducing runtime
compared to existing baselines. Our approach also generalizes seamlessly to
individual adversarial perturbations, where we observe similar strong
performance gains. Finally, we introduce a principled procedure for learning
feature constraints directly from data, enabling broad applicability across
domains with structured input spaces.

</details>


### [271] [ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations](https://arxiv.org/abs/2510.15700)
*Alex Gu,Bartosz Piotrowski,Fabian Gloeckle,Kaiyu Yang,Aram H. Markosyan*

Main category: cs.LG

TL;DR: 本文提出了ProofOptimizer，首个通过强化学习和专家迭代训练的用于简化Lean证明的语言模型，无需人工监督即可显著压缩由RL训练的定理证明器生成的冗长证明。


<details>
  <summary>Details</summary>
Motivation: 神经定理证明生成的证明过长，难以理解且限制了数学洞察力，而现有方法在处理超长证明时表现不佳，且缺乏训练数据。

Method: 采用专家迭代和强化学习方法训练ProofOptimizer，利用Lean验证简化结果并提供训练信号，在推理时通过迭代流程逐步缩短证明长度。

Result: 在多个基准上显著压缩证明长度：miniF2F减少87%，PutnamBench减少57%，IMO 2025证明减少49%；简化后的证明在Lean中验证更快，并能提升下游证明器的性能。

Conclusion: ProofOptimizer有效解决了神经定理证明中证明过长的问题，提升了可读性、验证效率和再利用价值，是自动化数学推理的重要进展。

Abstract: Neural theorem proving has advanced rapidly in the past year, reaching IMO
gold-medalist capabilities and producing formal proofs that span thousands of
lines. Although such proofs are mechanically verified by formal systems like
Lean, their excessive length renders them difficult for humans to comprehend
and limits their usefulness for mathematical insight. Proof simplification is
therefore a critical bottleneck. Yet, training data for this task is scarce,
and existing methods -- mainly agentic scaffolding with off-the-shelf LLMs --
struggle with the extremely long proofs generated by RL-trained provers. We
introduce ProofOptimizer, the first language model trained to simplify Lean
proofs without requiring additional human supervision. ProofOptimizer is
trained via expert iteration and reinforcement learning, using Lean to verify
simplifications and provide training signal. At inference time, it operates
within an iterative proof-shortening workflow, progressively reducing proof
length. Experiments show that ProofOptimizer substantially compresses proofs
generated by state-of-the-art RL-trained provers on standard benchmarks,
reducing proof length by 87% on miniF2F, 57% on PutnamBench, and 49% on
Seed-Prover's IMO 2025 proofs. Beyond conciseness, the simplified proofs check
faster in Lean and further improve downstream prover performance when reused as
training data for supervised finetuning.

</details>


### [272] [ProSh: Probabilistic Shielding for Model-free Reinforcement Learning](https://arxiv.org/abs/2510.15720)
*Edwin Hamel-De le Court,Gaspard Ohlmann,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 提出了一种名为ProSh的无模型安全强化学习算法，通过风险增强的概率屏蔽机制，在满足成本约束的同时保证训练和部署过程中的安全性。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中实现形式化的安全性保障，确保系统在部署和训练过程中均满足安全约束。

Method: 引入风险预算扩展状态空间，利用学习到的成本critic对策略分布施加屏蔽，确保采样动作在期望意义下安全；结合备份critic提供成本的期望上界。

Result: 理论上证明了在确定性环境中保持最优性，给出了依赖于备份critic精度的成本期望上界，并在实验中验证了训练期间的安全性。

Conclusion: ProSh能够在无模型设定下有效实现安全强化学习，在训练和部署阶段均提供形式化安全保证，适用于实际可实现的假设条件。

Abstract: Safety is a major concern in reinforcement learning (RL): we aim at
developing RL systems that not only perform optimally, but are also safe to
deploy by providing formal guarantees about their safety. To this end, we
introduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free
algorithm for safe reinforcement learning under cost constraints. ProSh
augments the Constrained MDP state space with a risk budget and enforces safety
by applying a shield to the agent's policy distribution using a learned cost
critic. The shield ensures that all sampled actions remain safe in expectation.
We also show that optimality is preserved when the environment is
deterministic. Since ProSh is model-free, safety during training depends on the
knowledge we have acquired about the environment. We provide a tight
upper-bound on the cost in expectation, depending only on the backup-critic
accuracy, that is always satisfied during training. Under mild, practically
achievable assumptions, ProSh guarantees safety even at training time, as shown
in the experiments.

</details>


### [273] [RLAF: Reinforcement Learning from Automaton Feedback](https://arxiv.org/abs/2510.15728)
*Mahyar Alinejad,Alvaro Velasquez,Yue Wang,George Atia*

Main category: cs.LG

TL;DR: 提出一种基于自动机反馈的强化学习方法，利用确定性有限自动机（DFA）生成轨迹偏好来学习奖励函数，避免手动设计奖励，支持非马尔可夫奖励结构，并在离散和连续环境中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在处理复杂、历史依赖的奖励结构时面临挑战，且手动设计奖励函数费时易错，需要一种无需显式奖励工程的方法来应对非马尔可夫性。

Method: 使用DFA生成轨迹间的偏好，通过偏好学习推断奖励函数，提出静态方法（直接优化策略）和动态方法（迭代更新奖励函数与策略），以实现对非马尔可夫奖励的建模。

Result: 在离散和连续环境中均取得优于奖励机器和LTL引导等基线方法的表现，能有效学习具有时序依赖任务的策略，并提供收敛保证，证明所学策略接近真实目标的最优解。

Conclusion: 基于自动机的偏好学习为处理非马尔可夫奖励提供了可扩展、高效且无需人工干预的替代方案，在理论和实验上均验证了其有效性。

Abstract: Reinforcement Learning (RL) in environments with complex, history-dependent
reward structures poses significant challenges for traditional methods. In this
work, we introduce a novel approach that leverages automaton-based feedback to
guide the learning process, replacing explicit reward functions with
preferences derived from a deterministic finite automaton (DFA). Unlike
conventional approaches that use automata for direct reward specification, our
method employs the structure of the DFA to generate preferences over
trajectories that are used to learn a reward function, eliminating the need for
manual reward engineering. Our framework introduces a static approach that uses
the learned reward function directly for policy optimization and a dynamic
approach that involves continuous refining of the reward function and policy
through iterative updates until convergence.
  Our experiments in both discrete and continuous environments demonstrate that
our approach enables the RL agent to learn effective policies for tasks with
temporal dependencies, outperforming traditional reward engineering and
automaton-based baselines such as reward machines and LTL-guided methods. Our
results highlight the advantages of automaton-based preferences in handling
non-Markovian rewards, offering a scalable, efficient, and human-independent
alternative to traditional reward modeling. We also provide a convergence
guarantee showing that under standard assumptions our automaton-guided
preference-based framework learns a policy that is near-optimal with respect to
the true non-Markovian objective.

</details>


### [274] [A Comprehensive Evaluation of Graph Neural Networks and Physics Informed Learning for Surrogate Modelling of Finite Element Analysis](https://arxiv.org/abs/2510.15750)
*Nayan Kumar Singh*

Main category: cs.LG

TL;DR: 本文评估了图神经网络（GNN）和3D U-Net作为参数化I型梁有限元分析（FEA）代理模型的性能，并提出了一种基于物理信息神经网络（PINN）框架和课程学习策略的训练方法，结果显示GNN显著优于U-Net，其中图变换器和MPNN精度最高，而MPNN PINN在精度、模型大小和推理速度之间提供了最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 有限元分析（FEA）虽然在产品设计中至关重要，但计算成本高，难以用于设计优化；深度学习可作为替代方案，但如何选择高精度且稳定的架构仍具挑战。

Method: 采用图神经网络（GNN）和3D U-Net作为FEA代理模型，构建基于Navier Cauchy方程的物理信息神经网络（PINN）框架，并使用课程学习策略：先在数据上预训练，再进行物理引导的微调。

Result: GNN整体优于U-Net：GCN最低误差为8.7%，U-Net最佳表现（含注意力机制）误差为13.0%；MPNN和图变换器分别达到3.5%和2.6%的相对L2误差；引入PINN使高信号任务误差降低达11.3%；图变换器推理速度比MPNN慢37.5%。

Conclusion: GNN在FEA代理建模中优于3D U-Net；图变换器最准确但推理较慢，而PINN增强的MPNN（MPNN PINN）在准确性、模型大小和推理速度之间实现了最佳权衡，是最实用的解决方案。

Abstract: Although Finite Element Analysis (FEA) is an integral part of the product
design lifecycle, the analysis is computationally expensive, making it
unsuitable for many design optimization problems. The deep learning models can
be a great solution. However, selecting the architecture that emulates the FEA
with great accuracy is a challenge. This paper presents a comprehensive
evaluation of graph neural networks (GNNs) and 3D U-Nets as surrogates for FEA
of parametric I-beams. We introduce a Physics-Informed Neural Network (PINN)
framework, governed by the Navier Cauchy equations, to enforce physical laws.
Crucially, we demonstrate that a curriculum learning strategy, pretraining on
data followed by physics informed fine tuning, is essential for stabilizing
training. Our results show that GNNs fundamentally outperform the U-Net. Even
the worst performer among GNNs, the GCN framework, achieved a relative L2 error
of 8.7% while the best framework among U Net, U Net with attention mechanism
trained on high resolution data, achieved 13.0% score. Among the graph-based
architectures, the Message Passing Neural Networks (MPNN) and Graph
Transformers achieved the highest accuracy, achieving a relative L2 score of
3.5% and 2.6% respectively. The inclusion of physics fundamental laws (PINN)
significantly improved the generalization, reducing error by up to 11.3% on
high-signal tasks. While the Graph Transformer is the most accurate model, it
is more 37.5% slower during inference when compared to second best model, MPNN
PINN. The PINN enhanced MPNN (MPNN PINN) provides the most practical solution.
It offers a good compromise between predictive performance, model size, and
inference speed.

</details>


### [275] [SAMix: Calibrated and Accurate Continual Learning via Sphere-Adaptive Mixup and Neural Collapse](https://arxiv.org/abs/2510.15751)
*Trung-Anh Dang,Vincent Nguyen,Ngoc-Son Vu,Christel Vrain*

Main category: cs.LG

TL;DR: 提出了一种名为Sphere-Adaptive Mixup（SAMix）的新方法，通过自适应混合策略增强持续学习中的模型校准和性能，显著提升准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法多关注缓解遗忘和提高准确性，但忽视了模型校准这一关键问题；神经坍塌虽有助于特征对齐，但其在提升模型校准方面仍缺乏探索。

Method: 提出SAMix，一种针对基于神经坍塌方法的自适应mixup策略，根据神经坍塌下特征空间的几何特性调整混合过程，实现更鲁棒的正则化与对齐。

Result: 实验表明，SAMix在持续学习中显著提升性能，超越现有SOTA方法，同时改善模型校准、降低过置信度、缓解遗忘，并提高跨任务准确率。

Conclusion: SAMix通过结合神经坍塌的几何特性进行自适应数据增强，有效提升了持续学习模型的准确性与预测可靠性，是构建鲁棒持续学习系统的重要进展。

Abstract: While most continual learning methods focus on mitigating forgetting and
improving accuracy, they often overlook the critical aspect of network
calibration, despite its importance. Neural collapse, a phenomenon where
last-layer features collapse to their class means, has demonstrated advantages
in continual learning by reducing feature-classifier misalignment. Few works
aim to improve the calibration of continual models for more reliable
predictions. Our work goes a step further by proposing a novel method that not
only enhances calibration but also improves performance by reducing
overconfidence, mitigating forgetting, and increasing accuracy. We introduce
Sphere-Adaptive Mixup (SAMix), an adaptive mixup strategy tailored for neural
collapse-based methods. SAMix adapts the mixing process to the geometric
properties of feature spaces under neural collapse, ensuring more robust
regularization and alignment. Experiments show that SAMix significantly boosts
performance, surpassing SOTA methods in continual learning while also improving
model calibration. SAMix enhances both across-task accuracy and the broader
reliability of predictions, making it a promising advancement for robust
continual learning systems.

</details>


### [276] [Poultry Farm Intelligence: An Integrated Multi-Sensor AI Platform for Enhanced Welfare and Productivity](https://arxiv.org/abs/2510.15757)
*Pieris Panagi,Savvas Karatsiolis,Kyriacos Mosphilis,Nicholas Hadjisavvas,Andreas Kamilaris,Nicolas Nicolaou,Efstathios Stavrakis,Vassilis Vassiliades*

Main category: cs.LG

TL;DR: PoultryFI是一个模块化、低成本的家禽养殖智能平台，集成了六个AI驱动模块，实现对家禽养殖的持续监控、生产预测和性能优化。


<details>
  <summary>Details</summary>
Motivation: 中小型家禽养殖场缺乏经济实惠且集成化的连续监测与决策工具，通常依赖人工、被动式检查，难以兼顾生产效率、动物福利和环境合规。

Method: 采用进化算法优化摄像头布局以最小硬件实现全覆盖；通过同步视频、音频和喂养数据提取动物福利指标；利用边缘视觉模型实现实时蛋计数；结合天气数据和预测模型进行产量与饲料消耗预测，并提供操作建议。

Result: 实地试验显示树莓派5上蛋计数准确率达100%，具备强大的异常检测能力和可靠的短期预测性能。

Conclusion: PoultryFI是首个结合低成本传感、边缘计算和处方式AI的系统之一，填补了孤立试点工具与可扩展的全农场智能之间的空白，帮助养殖户主动保障动物福利和盈利能力。

Abstract: Poultry farming faces increasing pressure to meet productivity targets while
ensuring animal welfare and environmental compliance. Yet many small and
medium-sized farms lack affordable, integrated tools for continuous monitoring
and decision-making, relying instead on manual, reactive inspections. This
paper presents Poultry Farm Intelligence (PoultryFI) - a modular,
cost-effective platform that integrates six AI-powered modules: Camera
Placement Optimizer, Audio-Visual Monitoring, Analytics & Alerting, Real-Time
Egg Counting, Production & Profitability Forecasting, and a Recommendation
Module.
  Camera layouts are first optimized offline using evolutionary algorithms for
full poultry house coverage with minimal hardware. The Audio-Visual Monitoring
module extracts welfare indicators from synchronized video, audio, and feeding
data. Analytics & Alerting produces daily summaries and real-time
notifications, while Real-Time Egg Counting uses an edge vision model to
automate production tracking. Forecasting models predict egg yield and feed
consumption up to 10 days in advance, and the Recommendation Module integrates
forecasts with weather data to guide environmental and operational adjustments.
  This is among the first systems to combine low-cost sensing, edge analytics,
and prescriptive AI to continuously monitor flocks, predict production, and
optimize performance. Field trials demonstrate 100% egg-count accuracy on
Raspberry Pi 5, robust anomaly detection, and reliable short-term forecasting.
PoultryFI bridges the gap between isolated pilot tools and scalable, farm-wide
intelligence, empowering producers to proactively safeguard welfare and
profitability.

</details>


### [277] [Cavity Duplexer Tuning with 1d Resnet-like Neural Networks](https://arxiv.org/abs/2510.15796)
*Anton Raskovalov*

Main category: cs.LG

TL;DR: 提出了一种基于监督学习的机器学习方法，用于调节具有大量调节螺钉的腔体双工器，结合1D ResNet-like神经网络和S参数信息，在4-5次旋转内接近调谐状态。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在调节腔体双工器时效果不佳，需寻找更高效的调谐方法。

Method: 将问题重新构定为监督学习任务，采用1D ResNet-like骨干网络，并融合S参数的曲线形状、峰值位置和幅度等附加信息，结合外部控制算法进行调谐。

Result: 该方法能在平均每颗螺丝4-5次旋转内使双工器接近调谐状态，显著提升调谐效率。

Conclusion: 所提出的监督学习框架结合专用神经网络结构能有效解决复杂双工器的自动调谐问题，优于传统强化学习方法。

Abstract: This paper presents machine learning method for tuning of cavity duplexer
with a large amount of adjustment screws. After testing we declined
conventional reinforcement learning approach and reformulated our task in the
supervised learning setup. The suggested neural network architecture includes
1d ResNet-like backbone and processing of some additional information about
S-parameters, like the shape of curve and peaks positions and amplitudes. This
neural network with external control algorithm is capable to reach almost the
tuned state of the duplexer within 4-5 rotations per screw.

</details>


### [278] [AB-UPT for Automotive and Aerospace Applications](https://arxiv.org/abs/2510.15808)
*Benedikt Alkin,Richard Kurle,Louis Serrano,Dennis Just,Johannes Brandstetter*

Main category: cs.LG

TL;DR: AB-UPT是一种高效的神经网络模型，能快速准确地模拟汽车和飞机的空气动力学性能，显著减少计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 为了降低传统数值求解器在流体动力学仿真中的高计算成本，探索基于Transformer的神经代理模型在工业级应用中的潜力。

Method: 采用Anchored-Branched Universal Physics Transformers（AB-UPT）模型，并在Luminary Cloud平台生成的两个高质量数据集（SHIFT-SUV和SHIFT-Wing）上进行训练与评估，结合各向同性网格几何表示进行预测。

Result: AB-UPT在两个数据集上均优于现有的Transformer基线模型，能够在几秒内近乎完美地预测积分气动力，且单GPU上一天内即可完成训练。

Conclusion: AB-UPT展现出强大的泛化能力和高效性，具备在工业规模流体仿真中广泛应用的潜力。

Abstract: The recently proposed Anchored-Branched Universal Physics Transformers
(AB-UPT) shows strong capabilities to replicate automotive computational fluid
dynamics simulations requiring orders of magnitudes less compute than
traditional numerical solvers. In this technical report, we add two new
datasets to the body of empirically evaluated use-cases of AB-UPT, combining
high-quality data generation with state-of-the-art neural surrogates. Both
datasets were generated with the Luminary Cloud platform containing automotives
(SHIFT-SUV) and aircrafts (SHIFT-Wing). We start by detailing the data
generation. Next, we show favorable performances of AB-UPT against previous
state-of-the-art transformer-based baselines on both datasets, followed by
extensive qualitative and quantitative evaluations of our best AB-UPT model.
AB-UPT shows strong performances across the board. Notably, it obtains near
perfect prediction of integrated aerodynamic forces within seconds from a
simple isotopically tesselate geometry representation and is trainable within a
day on a single GPU, paving the way for industry-scale applications.

</details>


### [279] [Chronos-2: From Univariate to Universal Forecasting](https://arxiv.org/abs/2510.15821)
*Abdul Fatir Ansari,Oleksandr Shchur,Jaris Küken,Andreas Auer,Boran Han,Pedro Mercado,Syama Sundar Rangapuram,Huibin Shen,Lorenzo Stella,Xiyuan Zhang,Mononito Goswami,Shubham Kapoor,Danielle C. Maddix,Pablo Guerron,Tony Hu,Junming Yin,Nick Erickson,Prateek Mutalik Desai,Hao Wang,Huzefa Rangwala,George Karypis,Yuyang Wang,Michael Bohlke-Schneider*

Main category: cs.LG

TL;DR: Chronos-2 是一个预训练的时间序列模型，能够在无需任务特定训练的情况下处理单变量、多变量和协变量感知的预测任务，通过组注意力机制实现上下文学习，在多个基准测试中表现达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练时间序列模型主要关注单变量预测，限制了其在包含多变量数据和协变量的实际场景中的应用。因此需要一个能够统一处理多种预测任务的通用模型。

Method: 提出 Chronos-2，采用组注意力机制，促进组内多个时间序列之间的信息共享，支持上下文学习；通过在具有多样化多变量结构的合成数据集上进行训练，实现对多变量和协变量感知任务的零样本预测。

Result: 在 fev-bench、GIFT-Eval 和 Chronos Benchmark II 三个基准上达到最先进的性能，尤其在涉及协变量的任务上显著优于现有模型，并在能源和零售领域的案例研究中展现出实际优势。

Conclusion: Chronos-2 具备强大的零样本上下文学习能力，是一个可直接用于真实世界预测流程的通用型时间序列预测模型。

Abstract: Pretrained time series models have enabled inference-only forecasting systems
that produce accurate predictions without task-specific training. However,
existing approaches largely focus on univariate forecasting, limiting their
applicability in real-world scenarios where multivariate data and covariates
play a crucial role. We present Chronos-2, a pretrained model capable of
handling univariate, multivariate, and covariate-informed forecasting tasks in
a zero-shot manner. Chronos-2 employs a group attention mechanism that
facilitates in-context learning (ICL) through efficient information sharing
across multiple time series within a group, which may represent sets of related
series, variates of a multivariate series, or targets and covariates in a
forecasting task. These general capabilities are achieved through training on
synthetic datasets that impose diverse multivariate structures on univariate
series. Chronos-2 delivers state-of-the-art performance across three
comprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On
fev-bench, which emphasizes multivariate and covariate-informed forecasting,
Chronos-2's universal ICL capabilities lead to substantial improvements over
existing models. On tasks involving covariates, it consistently outperforms
baselines by a wide margin. Case studies in the energy and retail domains
further highlight its practical advantages. The in-context learning
capabilities of Chronos-2 establish it as a general-purpose forecasting model
that can be used "as is" in real-world forecasting pipelines.

</details>


### [280] [SNOO: Step-K Nesterov Outer Optimizer - The Surprising Effectiveness of Nesterov Momentum Applied to Pseudo-Gradients](https://arxiv.org/abs/2510.15830)
*Dominik Kallusky,Vinay Rao,Vishal Nandavanam,Hao-Jun Michael Shi*

Main category: cs.LG

TL;DR: 本文提出了一种名为SNOO的Lookahead优化器变体，通过在伪梯度上应用Nesterov动量，在非分布式设置下显著提升训练效率，计算因子增益达1.5-2.5倍，且效果随模型规模增大而增强。


<details>
  <summary>Details</summary>
Motivation: 现有的Lookahead类优化器（如DiLoCo）在非分布式设置下表现出意外的有效性，但其背后原因尚不明确。本文旨在探究其有效性来源，并提出更高效的优化方法。

Method: 通过实证分析发现DiLoCo的有效性主要源于对伪梯度应用Nesterov动量，进而提出Step-K Nesterov Outer Optimizer (SNOO)，并在非分布式环境下验证其性能。

Result: SNOO在高达1e23 FLOPs的训练规模下实现了1.5-2.5倍的计算因子增益，性能提升随模型增大而增加，且具有低计算和内存开销，兼容模型分片。

Conclusion: SNOO是一种高效、实用的Lookahead优化器变体，适用于多种内层优化器（如AdamW、Muon），特别适合大规模语言模型的训练。

Abstract: The rapid development of large language models (LLMs) has driven the demand
for more efficient optimization techniques. Among these, the Lookahead family
of optimizers employs a two-loop framework, maintaining fast and slow sets of
model weights. Multiple inner optimizer steps on the fast weights produce a
trajectory - the pseudo-gradient - that is used to update the slow weights.
DiLoCo, a notable example originally designed for distributed training, applies
Nesterov momentum to the averaged pseudo-gradient from multiple workers,
claiming to even outperform AdamW in a non-distributed setup. In this paper, we
empirically show that DiLoCo's surprising effectiveness stems primarily from
applying Nesterov momentum to the pseudo-gradient, which improves training in a
non-distributed setting. We call this Lookahead variant the Step-$K$ Nesterov
Outer Optimizer (SNOO). We demonstrate that SNOO achieves compute factor gains
of 1.5 - 2.5$\times$ in a non-distributed setting up to a scale of 1e23
training FLOPs, with improvements that increase with model size. Because of its
minimal compute and memory overhead and compatibility with model sharding, SNOO
is a practical enhancement for a variety of inner optimizers, including AdamW
and Muon.

</details>


### [281] [FIDDLE: Reinforcement Learning for Quantum Fidelity Enhancement](https://arxiv.org/abs/2510.15833)
*Hoang M. Ngo,Tamer Kahveci,My T. Thai*

Main category: cs.LG

TL;DR: 本文提出了一种名为FIDDLE的新框架，用于在量子电路的转译过程中最大化过程保真度，特别是在路由阶段。该框架结合了高斯过程代理模型和强化学习模块，直接优化保真度，优于依赖电路深度或门数量等间接指标的传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前量子设备受噪声影响，导致可靠性降低，尤其是在基于门的量子计算中，如何在转译过程（特别是路由阶段）提高量子电路的保真度成为一个关键挑战。

Method: 提出了FIDDLE框架，包含两个模块：基于高斯过程的代理模型用于用有限训练样本估计过程保真度，以及一个强化学习模块用于优化路由策略，以直接最大化过程保真度。

Result: 实验表明，所提出的代理模型在保真度估计上优于现有学习技术，整个端到端框架在多种噪声模型下显著提升了量子电路的过程保真度。

Conclusion: FIDDLE是首个在路由阶段直接最大化过程保真度的学习框架，相较于依赖间接指标的传统方法表现更优，为提升含噪量子设备上的电路可靠性提供了有效解决方案。

Abstract: Quantum computing has the potential to revolutionize fields like quantum
optimization and quantum machine learning. However, current quantum devices are
hindered by noise, reducing their reliability. A key challenge in gate-based
quantum computing is improving the reliability of quantum circuits, measured by
process fidelity, during the transpilation process, particularly in the routing
stage. In this paper, we address the Fidelity Maximization in Routing Stage
(FMRS) problem by introducing FIDDLE, a novel learning framework comprising two
modules: a Gaussian Process-based surrogate model to estimate process fidelity
with limited training samples and a reinforcement learning module to optimize
routing. Our approach is the first to directly maximize process fidelity,
outperforming traditional methods that rely on indirect metrics such as circuit
depth or gate count. We rigorously evaluate FIDDLE by comparing it with
state-of-the-art fidelity estimation techniques and routing optimization
methods. The results demonstrate that our proposed surrogate model is able to
provide a better estimation on the process fidelity compared to existing
learning techniques, and our end-to-end framework significantly improves the
process fidelity of quantum circuits across various noise models.

</details>


### [282] [Transfer Orthology Networks](https://arxiv.org/abs/2510.15837)
*Vikash Singh*

Main category: cs.LG

TL;DR: 提出了一种名为TRON的新型神经网络架构，利用同源关系进行跨物种迁移学习。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地利用现有的转录组数据，实现跨物种的知识迁移，并提供生物学上有依据且可解释的方法。

Method: 通过构建物种间的二分图表示同源关系，在预训练前馈神经网络前添加一个学习到的物种转换层，该层权重由二分图的双邻接矩阵掩码控制，从而实现从源物种到目标物种基因表达空间的线性映射。

Result: TRON能够高效地将源物种的知识迁移到目标物种，且转换层的学习权重有助于解释功能同源性。

Conclusion: TRON为跨物种迁移学习提供了生物学基础和可解释性的新方法，有望提升转录组数据的利用效率。

Abstract: We present Transfer Orthology Networks (TRON), a novel neural network
architecture designed for cross-species transfer learning. TRON leverages
orthologous relationships, represented as a bipartite graph between species, to
guide knowledge transfer. Specifically, we prepend a learned species conversion
layer, whose weights are masked by the biadjacency matrix of this bipartite
graph, to a pre-trained feedforward neural network that predicts a phenotype
from gene expression data in a source species. This allows for efficient
transfer of knowledge to a target species by learning a linear transformation
that maps gene expression from the source to the target species' gene space.
The learned weights of this conversion layer offer a potential avenue for
interpreting functional orthology, providing insights into how genes across
species contribute to the phenotype of interest. TRON offers a biologically
grounded and interpretable approach to cross-species transfer learning, paving
the way for more effective utilization of available transcriptomic data. We are
in the process of collecting cross-species transcriptomic/phenotypic data to
gain experimental validation of the TRON architecture.

</details>


### [283] [Learning Correlated Reward Models: Statistical Barriers and Opportunities](https://arxiv.org/abs/2510.15839)
*Yeshwanth Cherapanamjeri,Constantinos Daskalakis,Gabriele Farina,Sobhan Mohammadpour*

Main category: cs.LG

TL;DR: 本文研究了避免独立无关选项假设（IIA）的关联probit模型的学习问题，指出成对偏好数据无法充分捕捉相关性信息，而三选一偏好数据可有效克服此问题，并提出了高效估计方法，在真实数据上验证了其在个性化建模人类偏好方面的优势。


<details>
  <summary>Details</summary>
Motivation: 许多随机效用模型（RUMs）依赖于IIA假设，将所有人类偏好简化为单一效用函数，导致对人类偏好多样性的粗略近似；然而，避免IIA的模型缺乏统计与计算保证，因此需要探索更精细且可学习的偏好建模方法。

Method: 提出使用best-of-three（三选一）偏好数据而非传统的成对比较数据，设计了一种具有近似最优性能的统计和计算高效的估计器，用于学习关联probit模型中的相关性结构。

Result: 理论证明成对偏好数据不足以学习相关性信息，而三选一数据可以克服这一局限；所提估计器在多个真实世界数据集上表现出更优的个性化偏好建模能力。

Conclusion: 高阶偏好数据（如三选一）能有效提升对人类偏好中相关结构的学习能力，为RLHF等应用中的奖励建模提供了更精细、个性化的解决方案。

Abstract: Random Utility Models (RUMs) are a classical framework for modeling user
preferences and play a key role in reward modeling for Reinforcement Learning
from Human Feedback (RLHF). However, a crucial shortcoming of many of these
techniques is the Independence of Irrelevant Alternatives (IIA) assumption,
which collapses \emph{all} human preferences to a universal underlying utility
function, yielding a coarse approximation of the range of human preferences. On
the other hand, statistical and computational guarantees for models avoiding
this assumption are scarce. In this paper, we investigate the statistical and
computational challenges of learning a \emph{correlated} probit model, a
fundamental RUM that avoids the IIA assumption. First, we establish that the
classical data collection paradigm of pairwise preference data is
\emph{fundamentally insufficient} to learn correlational information,
explaining the lack of statistical and computational guarantees in this
setting. Next, we demonstrate that \emph{best-of-three} preference data
provably overcomes these shortcomings, and devise a statistically and
computationally efficient estimator with near-optimal performance. These
results highlight the benefits of higher-order preference data in learning
correlated utilities, allowing for more fine-grained modeling of human
preferences. Finally, we validate these theoretical guarantees on several
real-world datasets, demonstrating improved personalization of human
preferences.

</details>


### [284] [Self-Certifying Primal-Dual Optimization Proxies for Large-Scale Batch Economic Dispatch](https://arxiv.org/abs/2510.15850)
*Michael Klamkin,Mathieu Tanneau,Pascal Van Hentenryck*

Main category: cs.LG

TL;DR: 提出了一种结合经典求解器与优化代理的混合求解器，利用对偶理论有效界定预测的最优性差距，并在无法验证最优性时回退到经典求解器，实现了超过1000倍的加速同时保证最大2%的最优性差距。


<details>
  <summary>Details</summary>
Motivation: 现有优化代理在最坏情况下可能出现远高于平均值的最优性差距，导致实际应用中难以信任其预测结果，因此需要一种可信赖的、具有可解释权衡的求解方案。

Method: 基于对偶理论构建混合求解器，结合原始和对偶代理训练方法，通过用户定义的最优性阈值动态决定是否回退到经典求解器。

Result: 在大规模输电系统上的实验表明，该混合求解器具有良好可扩展性，在保证最大2%最优性差距的同时，相比并行单纯形求解器实现了超过1000倍的速度提升。

Conclusion: 所提出的混合求解器在速度与最优性之间实现了可解释且可控的权衡，有助于优化代理在关键场景中的可信部署。

Abstract: Recent research has shown that optimization proxies can be trained to high
fidelity, achieving average optimality gaps under 1% for large-scale problems.
However, worst-case analyses show that there exist in-distribution queries that
result in orders of magnitude higher optimality gap, making it difficult to
trust the predictions in practice. This paper aims at striking a balance
between classical solvers and optimization proxies in order to enable
trustworthy deployments with interpretable speed-optimality tradeoffs based on
a user-defined optimality threshold. To this end, the paper proposes a hybrid
solver that leverages duality theory to efficiently bound the optimality gap of
predictions, falling back to a classical solver for queries where optimality
cannot be certified. To improve the achieved speedup of the hybrid solver, the
paper proposes an alternative training procedure that combines the primal and
dual proxy training. Experiments on large-scale transmission systems show that
the hybrid solver is highly scalable. The proposed hybrid solver achieves
speedups of over 1000x compared to a parallelized simplex-based solver while
guaranteeing a maximum optimality gap of 2%.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [285] [DMRetriever: A Family of Models for Improved Text Retrieval in Disaster Management](https://arxiv.org/abs/2510.15087)
*Kai Yin,Xiangjue Dong,Chengkai Liu,Allen Lin,Lingfeng Shi,Ali Mostafavi,James Caverlee*

Main category: cs.IR

TL;DR: 本文提出了DMRetriever，首个专为灾害管理领域定制的稠密检索模型系列，通过三阶段训练框架在多种搜索意图下实现了最先进的性能，并展现出卓越的参数效率。


<details>
  <summary>Details</summary>
Motivation: 现有的通用检索模型无法有效应对灾害管理中多样的搜索意图，导致性能不稳定，因此需要专门针对该领域的检索模型。

Method: 提出了一种包含双向注意力适配、无监督对比预训练和难度感知渐进式指令微调的三阶段训练框架，并利用高级数据精炼流程生成高质量数据来训练DMRetriever模型。

Result: 实验证明，DMRetriever在所有六个搜索意图和各个模型规模上均达到SOTA性能；596M模型优于大13.3倍的基线模型，33M模型仅用7.6%的参数即超越基线。

Conclusion: DMRetriever是首个面向灾害管理的高效密集检索模型，兼具高性能与高参数效率，具备实际应用价值。

Abstract: Effective and efficient access to relevant information is essential for
disaster management. However, no retrieval model is specialized for disaster
management, and existing general-domain models fail to handle the varied search
intents inherent to disaster management scenarios, resulting in inconsistent
and unreliable performance. To this end, we introduce DMRetriever, the first
series of dense retrieval models (33M to 7.6B) tailored for this domain. It is
trained through a novel three-stage framework of bidirectional attention
adaptation, unsupervised contrastive pre-training, and difficulty-aware
progressive instruction fine-tuning, using high-quality data generated through
an advanced data refinement pipeline. Comprehensive experiments demonstrate
that DMRetriever achieves state-of-the-art (SOTA) performance across all six
search intents at every model scale. Moreover, DMRetriever is highly
parameter-efficient, with 596M model outperforming baselines over 13.3 X larger
and 33M model exceeding baselines with only 7.6% of their parameters. All
codes, data, and checkpoints are available at
https://github.com/KaiYin97/DMRETRIEVER

</details>


### [286] [MTmixAtt: Integrating Mixture-of-Experts with Multi-Mix Attention for Large-Scale Recommendation](https://arxiv.org/abs/2510.15286)
*Xianyang Qi,Yuan Tian,Zhaoyu Hu,Zhirui Kuai,Chang Liu,Hongxiang Lin,Lei Wang*

Main category: cs.IR

TL;DR: 本文提出MTmixAtt，一种用于大规模推荐任务的统一Mixture-of-Experts架构，通过AutoToken和MTmixAttBlock模块自动处理异构特征并建模跨场景行为，在工业级数据集上显著优于现有模型，并在在线A/B测试中取得显著商业增益。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统依赖人工特征工程和特定场景架构，难以实现跨场景迁移和大规模部署，因此需要一种统一且可扩展的解决方案。

Method: 提出MTmixAtt，包含两个核心模块：AutoToken模块自动将异构特征聚类为语义一致的token；MTmixAttBlock模块通过可学习的混合矩阵、共享的密集专家和场景感知的稀疏专家实现高效的token交互。

Result: 在美团工业级TRec数据集上，MTmixAtt在CTR和CTCVR指标上均优于Transformer、WuKong、HiFormer等先进模型；扩展到10亿参数规模时性能持续提升；线上A/B测试显示首页场景的支付PV提升+3.62%，实际支付GTV提升+2.54%。

Conclusion: MTmixAtt提供了一种统一、可扩展的推荐建模范式，能有效处理跨场景异构特征，显著提升用户体验与商业结果。

Abstract: Industrial recommender systems critically depend on high-quality ranking
models. However, traditional pipelines still rely on manual feature engineering
and scenario-specific architectures, which hinder cross-scenario transfer and
large-scale deployment. To address these challenges, we propose
\textbf{MTmixAtt}, a unified Mixture-of-Experts (MoE) architecture with
Multi-Mix Attention, designed for large-scale recommendation tasks. MTmixAtt
integrates two key components. The \textbf{AutoToken} module automatically
clusters heterogeneous features into semantically coherent tokens, removing the
need for human-defined feature groups. The \textbf{MTmixAttBlock} module
enables efficient token interaction via a learnable mixing matrix, shared dense
experts, and scenario-aware sparse experts, capturing both global patterns and
scenario-specific behaviors within a single framework. Extensive experiments on
the industrial TRec dataset from Meituan demonstrate that MTmixAtt consistently
outperforms state-of-the-art baselines including Transformer-based models,
WuKong, HiFormer, MLP-Mixer, and RankMixer. At comparable parameter scales,
MTmixAtt achieves superior CTR and CTCVR metrics; scaling to MTmixAtt-1B yields
further monotonic gains. Large-scale online A/B tests validate the real-world
impact: in the \textit{Homepage} scenario, MTmixAtt increases Payment PV by
\textbf{+3.62\%} and Actual Payment GTV by \textbf{+2.54\%}. Overall, MTmixAtt
provides a unified and scalable solution for modeling arbitrary heterogeneous
features across scenarios, significantly improving both user experience and
commercial outcomes.

</details>


### [287] [GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework](https://arxiv.org/abs/2510.15299)
*Yijia Sun,Shanshan Huang,Zhiyuan Guan,Qiang Luo,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: 本文提出了一种名为GRank的新型检索范式，用于工业级推荐系统，无需结构化索引即可实现目标感知与用户中心化的高效检索。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统在检索阶段面临表达能力有限或依赖高维护成本的结构化索引的问题，难以兼顾高召回率、低延迟和动态用户偏好建模。

Method: GRank包含三个核心组件：(1) 一个目标感知的生成器，通过GPU加速的MIPS进行个性化候选生成；(2) 一个轻量但强大的排序器，对小规模候选集进行细粒度推理；(3) 一个端到端的多任务学习框架，确保生成与排序目标间的语义一致性。

Result: 在两个公开基准和十亿级生产数据集上的实验表明，GRank相比最先进的树和图基检索器，Recall@500提升超过30%，P99 QPS提高1.7倍。已在生产环境部署，服务4亿活跃用户，可用性达99.95%。

Conclusion: GRank有效解决了大规模推荐系统中高召回、低延迟与动态用户建模之间的矛盾，无需结构化索引即可实现高性能检索，并在实际应用中显著提升用户参与度。

Abstract: Industrial-scale recommender systems rely on a cascade pipeline in which the
retrieval stage must return a high-recall candidate set from billions of items
under tight latency. Existing solutions ei- ther (i) suffer from limited
expressiveness in capturing fine-grained user-item interactions, as seen in
decoupled dual-tower architectures that rely on separate encoders, or
generative models that lack precise target-aware matching capabilities, or (ii)
build structured indices (tree, graph, quantization) whose item-centric
topologies struggle to incorporate dynamic user preferences and incur
prohibitive construction and maintenance costs.
  We present GRank, a novel structured-index-free retrieval paradigm that
seamlessly unifies target-aware learning with user-centric retrieval. Our key
innovations include: (1) A target-aware Generator trained to perform
personalized candidate generation via GPU-accelerated MIPS, eliminating
semantic drift and maintenance costs of structured indexing; (2) A lightweight
but powerful Ranker that performs fine-grained, candidate-specific inference on
small subsets; (3) An end-to-end multi-task learning framework that ensures
semantic consistency between generation and ranking objectives.
  Extensive experiments on two public benchmarks and a billion-item production
corpus demonstrate that GRank improves Recall@500 by over 30% and 1.7$\times$
the P99 QPS of state-of-the-art tree- and graph-based retrievers.
  GRank has been fully deployed in production in our recommendation platform
since Q2 2025, serving 400 million active users with 99.95% service
availability. Online A/B tests confirm significant improvements in core
engagement metrics, with Total App Usage Time increasing by 0.160% in the main
app and 0.165% in the Lite version.

</details>


### [288] [Dimension Mask Layer: Optimizing Embedding Efficiency for Scalable ID-based Models](https://arxiv.org/abs/2510.15308)
*Srijan Saket,Ikuhiro Ihara,Vaibhav Sharma,Danish Kalim*

Main category: cs.IR

TL;DR: 本文提出一种自动确定ID特征最优嵌入大小的方法，通过在嵌入查找后引入维度掩码层，显著减小模型规模同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大规模ID特征的嵌入表占用大量内存，导致模型臃肿、难以部署和维护，因此需要一种有效方法来管理嵌入大小。

Method: 设计一种自定义的Keras层（维度掩码层），置于嵌入查找之后，仅允许前N个维度通过，从而削减嵌入向量的维度。

Result: 在公开数据集上的离线实验和真实生产环境的在线A/B测试表明，该方法可将有效嵌入维度减少40-50%，显著提升内存效率，且对模型性能影响极小。

Conclusion: 该方法为处理高数量ID特征的平台提供了一种可扩展的解决方案，能够在降低资源消耗的同时优化模型性能。

Abstract: In modern recommendation systems and social media platforms like Meta,
TikTok, and Instagram, large-scale ID-based features often require embedding
tables that consume significant memory. Managing these embedding sizes can be
challenging, leading to bulky models that are harder to deploy and maintain. In
this paper, we introduce a method to automatically determine the optimal
embedding size for ID features, significantly reducing the model size while
maintaining performance.
  Our approach involves defining a custom Keras layer called the dimension mask
layer, which sits directly after the embedding lookup. This layer trims the
embedding vector by allowing only the first N dimensions to pass through. By
doing this, we can reduce the input feature dimension by more than half with
minimal or no loss in model performance metrics. This reduction helps cut down
the memory footprint of the model and lowers the risk of overfitting due to
multicollinearity.
  Through offline experiments on public datasets and an online A/B test on a
real production dataset, we demonstrate that using a dimension mask layer can
shrink the effective embedding dimension by 40-50\%, leading to substantial
improvements in memory efficiency. This method provides a scalable solution for
platforms dealing with a high volume of ID features, optimizing both resource
usage and model performance.

</details>


### [289] [Fault Cause Identification across Manufacturing Lines through Ontology-Guided and Process-Aware FMEA Graph Learning with LLMs](https://arxiv.org/abs/2510.15428)
*Sho Okazaki,Kohei Kaminishi,Takuma Fujiu,Yusheng Wang,Jun Ota*

Main category: cs.IR

TL;DR: 提出一种结合制造领域概念化与图神经网络推理的流程感知框架，以提升FMEA知识在异构生产线间的可重用性。


<details>
  <summary>Details</summary>
Motivation: 由于系统复杂性、频繁重构及现有FMEA知识重用受限，自动化生产线中的故障原因识别具有挑战性。传统FMEA表格因自然语言差异、术语不一致和工艺差异难以跨线复用。

Method: 首先通过本体引导的大语言模型（LLM）提取，将多条生产线的FMEA表转换为统一的知识图谱；然后采用关系图卷积网络（RGCN）结合流程感知评分函数学习嵌入表示；最后利用链接预测推断并排序目标产线中可能的故障原因。

Result: 在汽车压力传感器装配线案例中，该方法在故障原因识别性能上优于检索增强生成基线（F1@20=0.267）和普通RGCN方法（0.400），达到0.523的最佳性能。消融实验验证了LLM驱动的概念化和流程感知学习的有效性。

Conclusion: 所提框架显著提升了FMEA知识在异构生产线间的可迁移性，有助于操作员更可靠地诊断故障，并为智能制造业中领域自适应大模型的应用奠定基础。

Abstract: Fault cause identification in automated manufacturing lines is challenging
due to the system's complexity, frequent reconfigurations, and the limited
reusability of existing Failure Mode and Effects Analysis (FMEA) knowledge.
Although FMEA worksheets contain valuable expert insights, their reuse across
heterogeneous lines is hindered by natural language variability, inconsistent
terminology, and process differences. To address these limitations, this study
proposes a process-aware framework that enhances FMEA reusability by combining
manufacturing-domain conceptualization with graph neural network (GNN)
reasoning. First, FMEA worksheets from multiple manufacturing lines are
transformed into a unified knowledge graph through ontology-guided large
language model (LLM) extraction, capturing domain concepts such as actions,
states, components, and parameters. Second, a Relational Graph Convolutional
Network (RGCN) with the process-aware scoring function learns embeddings that
respect both semantic relationships and sequential process flows. Finally, link
prediction is employed to infer and rank candidate fault causes consistent with
the target line's process flow.
  A case study on automotive pressure sensor assembly lines demonstrates that
the proposed method outperforms a state-of-the-art retrieval-augmented
generation (RAG) baseline (F1@20 = 0.267) and an RGCN approach (0.400),
achieving the best performance (0.523) in fault cause identification. Ablation
studies confirm the contributions of both LLM-driven domain conceptualization
and process-aware learning. These results indicate that the proposed framework
significantly improves the transferability of FMEA knowledge across
heterogeneous lines, thereby supporting operators in diagnosing failures more
reliably and paving the way for future domain-adaptive LLM applications in
smart manufacturing.

</details>


### [290] [Enhance Large Language Models as Recommendation Systems with Collaborative Filtering](https://arxiv.org/abs/2510.15647)
*Zhisheng Yang,Xiaofei Xu,Ke Deng,Li Li*

Main category: cs.IR

TL;DR: 提出Critic-LLM-RS，通过引入基于协同过滤的批评模型（Critic）为大语言模型提供反馈，从而在无需微调的情况下提升推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有非微调大语言模型推荐方法缺乏任务特定或本地企业知识，且未显式融合成功的协同过滤技术，导致推荐效果受限。

Method: 训练一个独立的机器学习模型Critic，该模型基于用户-物品交互数据实现协同过滤，并向大语言模型提供批评意见以优化推荐结果。

Result: 在真实数据集上的大量实验验证了Critic-LLM-RS的有效性，显著提升了推荐质量。

Conclusion: Critic-LLM-RS成功将协同过滤与非微调大语言模型结合，在不进行模型微调的前提下实现了更精准的个性化推荐。

Abstract: As powerful tools in Natural Language Processing (NLP), Large Language Models
(LLMs) have been leveraged for crafting recommendations to achieve precise
alignment with user preferences and elevate the quality of the recommendations.
The existing approaches implement both non-tuning and tuning strategies.
Compared to following the tuning strategy, the approaches following the
non-tuning strategy avoid the relatively costly, time-consuming, and
expertise-requiring process of further training pre-trained LLMs on
task-specific datasets, but they suffer the issue of not having the
task-specific business or local enterprise knowledge. To the best of our
knowledge, none of the existing approaches following the non-tuning strategy
explicitly integrates collaborative filtering, one of the most successful
recommendation techniques. This study aims to fill the gap by proposing
critique-based LLMs as recommendation systems (Critic-LLM-RS). For our purpose,
we train a separate machine-learning model called Critic that implements
collaborative filtering for recommendations by learning from the interactions
between many users and items. The Critic provides critiques to LLMs to
significantly refine the recommendations. Extensive experiments have verified
the effectiveness of Critic-LLM-RS on real datasets.

</details>


### [291] [SQuAI: Scientific Question-Answering with Multi-Agent Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15682)
*Ines Besrour,Jingbo He,Tobias Schreieder,Michael Färber*

Main category: cs.IR

TL;DR: SQuAI是一个可扩展且可信的多智能体检索增强生成框架，用于基于大语言模型的科学问答，通过协同代理分解问题、混合检索证据和自适应过滤，显著提升回答的准确性与可追溯性。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成系统在处理复杂、开放域的科学问题时存在准确性不足、缺乏引用支持和大规模文献检索能力弱的问题，难以满足科学研究对可信问答的需求。

Method: SQuAI构建于230万篇arXiv全文论文之上，采用四个协作代理：问题分解、混合稀疏-密集检索、文档自适应过滤和答案生成，并集成内联引用与支持句子以确保可追溯性。

Result: 相比强基线，SQuAI在保真度、答案相关性和上下文相关性上最高提升+0.088（12%），并发布包含1000个问答证据三元组的基准数据集。

Conclusion: SQuAI通过透明推理、可验证引用和领域级可扩展性，展示了多智能体RAG在实现可信科学问答中的潜力。

Abstract: We present SQuAI (https://squai.scads.ai/), a scalable and trustworthy
multi-agent retrieval-augmented generation (RAG) framework for scientific
question answering (QA) with large language models (LLMs). SQuAI addresses key
limitations of existing RAG systems in the scholarly domain, where complex,
open-domain questions demand accurate answers, explicit claims with citations,
and retrieval across millions of scientific documents. Built on over 2.3
million full-text papers from arXiv.org, SQuAI employs four collaborative
agents to decompose complex questions into sub-questions, retrieve targeted
evidence via hybrid sparse-dense retrieval, and adaptively filter documents to
improve contextual relevance. To ensure faithfulness and traceability, SQuAI
integrates in-line citations for each generated claim and provides supporting
sentences from the source documents. Our system improves faithfulness, answer
relevance, and contextual relevance by up to +0.088 (12%) over a strong RAG
baseline. We further release a benchmark of 1,000 scientific
question-answer-evidence triplets to support reproducibility. With transparent
reasoning, verifiable citations, and domain-wide scalability, SQuAI
demonstrates how multi-agent RAG enables more trustworthy scientific QA with
LLMs.

</details>


### [292] [Mixture of Experts Approaches in Dense Retrieval Tasks](https://arxiv.org/abs/2510.15683)
*Effrosyni Sokli,Pranav Kasela,Georgios Peikos,Gabriella Pasi*

Main category: cs.IR

TL;DR: 本文提出了一种高效的稀疏激活混合专家模型（SB-MoE），将其置于稠密检索模型（DRM）的最后一个Transformer层之后，以提升模型在不同任务和领域的泛化能力。相比在每一层引入MoE的方法，SB-MoE参数更少、效率更高。实验表明，SB-MoE对轻量级基模型（如TinyBERT）效果显著，在多个基准上优于标准微调方法；而对于更大模型（如BERT-Base），则需要更多训练数据才能发挥优势。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的稠密检索模型（DRMs）在跨任务和跨领域时泛化能力有限，而当前引入混合专家（MoE）的方法虽有效但参数量增加过多，因此需要一种更高效的MoE架构来提升泛化性同时控制模型复杂度。

Method: 提出在DRM的最后一个Transformer层后添加一个单一的MoE块（SB-MoE），并在三个信息检索任务上进行实证评估。实验包括两种设置：一是在七个IR基准上对四种不同的DRM进行微调并测试其域内性能；二是在MSMARCO上微调后，在十三个BEIR数据集上进行零样本迁移评估。同时分析了专家数量等超参数对性能的影响。

Result: SB-MoE在轻量级模型（如TinyBERT和BERT-Small）上表现优异，持续超越标准微调方法；对于参数更多的模型（如BERT-Base和Contriever），需更多训练样本才能提升检索性能。此外，SB-MoE在零样本设置下也展现出良好的迁移能力。

Conclusion: SB-MoE是一种更高效的MoE设计，能有效提升稠密检索模型的泛化能力，尤其适用于资源受限的轻量模型，为构建高效可扩展的检索系统提供了可行方案。

Abstract: Dense Retrieval Models (DRMs) are a prominent development in Information
Retrieval (IR). A key challenge with these neural Transformer-based models is
that they often struggle to generalize beyond the specific tasks and domains
they were trained on. To address this challenge, prior research in IR
incorporated the Mixture-of-Experts (MoE) framework within each Transformer
layer of a DRM, which, though effective, substantially increased the number of
additional parameters. In this paper, we propose a more efficient design, which
introduces a single MoE block (SB-MoE) after the final Transformer layer. To
assess the retrieval effectiveness of SB-MoE, we perform an empirical
evaluation across three IR tasks. Our experiments involve two evaluation
setups, aiming to assess both in-domain effectiveness and the model's zero-shot
generalizability. In the first setup, we fine-tune SB-MoE with four different
underlying DRMs on seven IR benchmarks and evaluate them on their respective
test sets. In the second setup, we fine-tune SB-MoE on MSMARCO and perform
zero-shot evaluation on thirteen BEIR datasets. Additionally, we perform
further experiments to analyze the model's dependency on its hyperparameters
(i.e., the number of employed and activated experts) and investigate how this
variation affects SB-MoE's performance. The obtained results show that SB-MoE
is particularly effective for DRMs with lightweight base models, such as
TinyBERT and BERT-Small, consistently exceeding standard model fine-tuning
across benchmarks. For DRMs with more parameters, such as BERT-Base and
Contriever, our model requires a larger number of training samples to achieve
improved retrieval performance. Our code is available online at:
https://github.com/FaySokli/SB-MoE.

</details>


### [293] [GraphMind: Interactive Novelty Assessment System for Accelerating Scientific Discovery](https://arxiv.org/abs/2510.15706)
*Italo Luis da Silva,Hanqi Yan,Lin Gui,Yulan He*

Main category: cs.IR

TL;DR: GraphMind是一个交互式网络工具，结合LLM与外部API（如arXiv和Semantic Scholar），帮助用户评估科学论文或研究想法的新颖性，提供可验证的上下文洞察和文献关联的结构化视图。


<details>
  <summary>Details</summary>
Motivation: 评估科学论文的新颖性在同行评审中至关重要，但需要广泛的背景知识。现有LLM辅助工具缺乏透明度和结果可追溯性，难以有效支持新颖性评估。

Method: 开发了一个名为GraphMind的交互式网络工具，通过集成外部学术API和大语言模型，实现论文关键要素的标注、相关研究的多维度探索以及基于上下文信息的新颖性评估。

Result: GraphMind能够生成科学思想的核心贡献及其与现有研究关系的丰富结构化视图，支持用户进行可追溯、透明的新颖性分析，并已公开发布工具网站、演示视频和源代码。

Conclusion: GraphMind为科研人员和审稿人提供了一个透明、易用且可验证的工具，有效提升了科学新颖性评估的可及性和可靠性。

Abstract: Large Language Models (LLMs) show strong reasoning and text generation
capabilities, prompting their use in scientific literature analysis, including
novelty assessment. While evaluating novelty of scientific papers is crucial
for peer review, it requires extensive knowledge of related work, something not
all reviewers have. While recent work on LLM-assisted scientific literature
analysis supports literature comparison, existing approaches offer limited
transparency and lack mechanisms for result traceability via an information
retrieval module. To address this gap, we introduce $\textbf{GraphMind}$, an
easy-to-use interactive web tool designed to assist users in evaluating the
novelty of scientific papers or drafted ideas. Specially, $\textbf{GraphMind}$
enables users to capture the main structure of a scientific paper, explore
related ideas through various perspectives, and assess novelty via providing
verifiable contextual insights. $\textbf{GraphMind}$ enables users to annotate
key elements of a paper, explore related papers through various relationships,
and assess novelty with contextual insight. This tool integrates external APIs
such as arXiv and Semantic Scholar with LLMs to support annotation, extraction,
retrieval and classification of papers. This combination provides users with a
rich, structured view of a scientific idea's core contributions and its
connections to existing work. $\textbf{GraphMind}$ is available at
https://oyarsa.github.io/graphmind and a demonstration video at
https://youtu.be/wKbjQpSvwJg. The source code is available at
https://github.com/oyarsa/graphmind.

</details>


### [294] [The 3rd Place Solution of CCIR CUP 2025: A Framework for Retrieval-Augmented Generation in Multi-Turn Legal Conversation](https://arxiv.org/abs/2510.15722)
*Da Li,Zecheng Fang,Qiang Yan,Wei Huang,Xuanpu Luo*

Main category: cs.IR

TL;DR: 本文介绍了在CCIR CUP 2025中提出的“法律知识检索与生成”方法，结合大语言模型与信息检索系统，基于法律条文对用户问题生成回答。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）在自然语言处理领域取得了显著进展，但在法律领域的应用仍处于探索阶段，因此需要专门针对法律知识进行检索与生成的研究。

Method: 提出一种结合大语言模型和信息检索系统的方法，用于法律知识的检索与生成，通过从可靠法律来源中检索相关信息来生成准确的回答。

Result: 该方法能够基于法律条文对用户问题提供相关且上下文适当的响应，在法律领域的应用展现出潜力。

Conclusion: 所提出的方法为法律领域中的检索增强生成提供了可行方案，有助于推动RAG在专业领域的应用发展。

Abstract: Retrieval-Augmented Generation has made significant progress in the field of
natural language processing. By combining the advantages of information
retrieval and large language models, RAG can generate relevant and contextually
appropriate responses based on items retrieved from reliable sources. This
technology has demonstrated outstanding performance across multiple domains,
but its application in the legal field remains in its exploratory phase. In
this paper, we introduce our approach for "Legal Knowledge Retrieval and
Generation" in CCIR CUP 2025, which leverages large language models and
information retrieval systems to provide responses based on laws in response to
user questions.

</details>


### [295] [FACE: A General Framework for Mapping Collaborative Filtering Embeddings into LLM Tokens](https://arxiv.org/abs/2510.15729)
*Chao Wang,Yixin Song,Jinhui Ye,Chuan Qin,Dazhong Shen,Lingfeng Liu,Xiang Wang,Yanyong Zhang*

Main category: cs.IR

TL;DR: 提出了一种名为FACE的通用可解释框架，将协同过滤（CF）嵌入映射到预训练大语言模型（LLM）的token中，提升推荐性能并实现语义对齐，无需微调LLM。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）难以理解协同过滤（CF）生成的非语义潜在嵌入，限制了推荐系统的有效性与应用。

Method: 设计了一个解耦投影模块，将CF嵌入分解为特定概念向量，并通过量化自编码器将其转换为LLM可理解的描述性token；引入对比对齐目标，使token与文本信号保持一致。

Result: 在三个真实世界数据集上验证了FACE框架能提升基准推荐模型的性能，且可解释性研究证实生成的描述符具有语义可解释性。

Conclusion: FACE是一种模型无关、无需微调LLM的可解释框架，成功实现了CF嵌入与LLM token之间的语义对齐，增强了推荐效果与可解释性。

Abstract: Recently, large language models (LLMs) have been explored for integration
with collaborative filtering (CF)-based recommendation systems, which are
crucial for personalizing user experiences. However, a key challenge is that
LLMs struggle to interpret the latent, non-semantic embeddings produced by CF
approaches, limiting recommendation effectiveness and further applications. To
address this, we propose FACE, a general interpretable framework that maps CF
embeddings into pre-trained LLM tokens. Specifically, we introduce a
disentangled projection module to decompose CF embeddings into concept-specific
vectors, followed by a quantized autoencoder to convert continuous embeddings
into LLM tokens (descriptors). Then, we design a contrastive alignment
objective to ensure that the tokens align with corresponding textual signals.
Hence, the model-agnostic FACE framework achieves semantic alignment without
fine-tuning LLMs and enhances recommendation performance by leveraging their
pre-trained capabilities. Empirical results on three real-world recommendation
datasets demonstrate performance improvements in benchmark models, with
interpretability studies confirming the interpretability of the descriptors.
Code is available in https://github.com/YixinRoll/FACE.

</details>


### [296] [FIRE: Fact-checking with Iterative Retrieval and Verification](https://arxiv.org/abs/2411.00784)
*Zhuohan Xie,Rui Xing,Yuxia Wang,Jiahui Geng,Hasan Iqbal,Dhruv Sahnan,Iryna Gurevych,Preslav Nakov*

Main category: cs.IR

TL;DR: 提出FIRE框架，通过迭代式检索与验证，在降低7.6倍LLM成本和16.5倍搜索成本的同时实现优于现有方法的事实核查性能。


<details>
  <summary>Details</summary>
Motivation: 传统原子化事实核查方法固定检索证据数量，未充分利用模型内部知识且缺乏人类式的迭代推理，导致成本高且效率低。

Method: 设计基于代理的FIRE框架，采用统一机制动态判断是生成最终答案还是发起下一轮搜索查询，实现检索与验证的迭代整合。

Result: 相比强基线方法，FIRE在性能略优的情况下，平均减少7.6倍大语言模型调用成本和16.5倍搜索成本。

Conclusion: FIRE框架在保持高性能的同时显著降低成本，具备应用于大规模事实核查任务的潜力。

Abstract: Fact-checking long-form text is challenging, and it is therefore common
practice to break it down into multiple atomic claims. The typical approach to
fact-checking these atomic claims involves retrieving a fixed number of pieces
of evidence, followed by a verification step. However, this method is usually
not cost-effective, as it underutilizes the verification model's internal
knowledge of the claim and fails to replicate the iterative reasoning process
in human search strategies. To address these limitations, we propose FIRE, a
novel agent-based framework that integrates evidence retrieval and claim
verification in an iterative manner. Specifically, FIRE employs a unified
mechanism to decide whether to provide a final answer or generate a subsequent
search query, based on its confidence in the current judgment. We compare FIRE
with other strong fact-checking frameworks and find that it achieves slightly
better performance while reducing large language model (LLM) costs by an
average of 7.6 times and search costs by 16.5 times. These results indicate
that FIRE holds promise for application in large-scale fact-checking
operations. Our code is available at https://github.com/mbzuai-nlp/fire.git.

</details>
