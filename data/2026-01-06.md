<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 174]
- [cs.CL](#cs.CL) [Total: 75]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.IR](#cs.IR) [Total: 19]
- [cs.LG](#cs.LG) [Total: 140]
- [cs.RO](#cs.RO) [Total: 31]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.GR](#cs.GR) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements](https://arxiv.org/abs/2601.00812)
*Takashi Ushio,Kazuhiro Onishi,Hideyoshi Yanagisawa*

Main category: cs.CV

TL;DR: 本文基于自由能（FE）原理，仅从广告视频的场景级表达特征中量化'愉悦度'、'惊喜度'和'习惯化'三种情绪维度，无需依赖生理信号或主观评分；通过1059个15秒食品广告验证KLD、BS和UN分别对应品牌呈现愉悦感、信息复杂性惊喜及元素不确定性惊喜，并发现三类典型情绪模式，方法具有跨超参数与广告类型的良好鲁棒性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 建立无需外部信息（如生理信号或主观评分）的可解释广告情绪估计方法学基础，以理解广告视频观看中的情绪反应对注意、记忆和购买意愿的影响。

Method: 基于自由能（FE）原理，利用Kullback-Leibler散度（KLD）、贝叶斯惊喜（BS）和不确定性（UN）三个指标，仅从广告视频的场景级表达特征中量化'pleasantness'、'surprise'和'habituation'；在1059个15秒食品广告数据集上进行实验分析，并开展超参数鲁棒性检验及六类日本广告视频的泛化测试。

Result: KLD反映与品牌呈现相关的'愉悦度'，BS捕捉由信息复杂性引起的'惊喜度'，UN反映由元素类型/空间安排不确定性以及元素数量和变异性驱动的'惊喜度'；识别出'不确定刺激'、'持续高情绪'和'瞬时峰值衰减'三类情绪模式；方法在九种超参数设置和六类广告视频中均表现稳健。

Conclusion: 仅基于视频表达特征并依托自由能原理的情绪量化方法是可行且稳健的，为可解释广告情绪建模提供了新范式，未来可通过整合更丰富的表达要素并结合主观评分进一步验证与拓展。

Abstract: Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified "pleasantness," "surprise," and "habituation" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected "pleasantness" associated with brand presentation, BS has captured "surprise" arising from informational complexity, and UN has reflected "surprise" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.

</details>


### [2] [EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos](https://arxiv.org/abs/2601.01050)
*Hongming Fu,Wenjia Wang,Xiaozhen Qiao,Shuo Yang,Zheng Liu,Bo Zhao*

Main category: cs.CV

TL;DR: 本文提出了EgoGrasp，首个能从野外拍摄的单目自拍视频中重建世界空间手-物交互（W-HOI）的方法，通过多阶段框架解决动态相机、遮挡和时序建模等挑战，并在W-HOI重建任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有手-物交互方法局限于单帧或相机坐标系，难以建模时序动态和全局一致轨迹；部分世界空间手部估计方法忽略物体姿态及交互约束，且在强相机运动和频繁遮挡下性能差。

Method: 提出多阶段框架：包含基于新型空间智能模型的鲁棒预处理流程、基于解耦扩散模型的全身手-物交互先验模型（模板无关、支持多物体），以及多目标测试时优化范式。

Result: 实验表明该方法在世界空间手-物交互重建任务上达到当前最优性能（SOTA）。

Conclusion: EgoGrasp首次实现了在野外自拍视频中准确重建世界空间手-物交互，显著提升了对人类行为理解及具身智能、虚拟现实等应用的支持能力。

Abstract: We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.

</details>


### [3] [Can Generative Models Actually Forge Realistic Identity Documents?](https://arxiv.org/abs/2601.00829)
*Alexander Vinogradov*

Main category: cs.CV

TL;DR: 本文评估了当前开源扩散模型生成身份证件伪造图像的能力，发现其虽能模拟表面美学，但无法再现结构和法医级真实性，因此对生成式证件深伪的法医级真实性风险可能被高估。


<details>
  <summary>Details</summary>
Motivation: 公众担忧生成式图像模型可能被滥用于证件伪造，需评估其实际风险。

Method: 评估多种公开可用的扩散模型（如Stable Diffusion、Qwen、Flux、Nano-Banana等）在文本到图像和图像到图像生成任务中伪造身份文件的能力。

Result: 当前模型可模拟证件表面美学，但无法再现结构与法医级真实性，难以通过人工或自动化验证系统。

Conclusion: 生成式证件深伪的法医级真实性风险被高估，强调机器学习研究者与证件鉴伪专家合作开展现实风险评估的重要性。

Abstract: Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.

</details>


### [4] [Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs](https://arxiv.org/abs/2601.00837)
*Agniv Roy Choudhury*

Main category: cs.CV

TL;DR: 本研究比较了从头训练的CNN与基于ResNet50、DenseNet121和EfficientNet-B0的迁移学习在儿童肺炎X光片检测中的性能，发现微调后的ResNet50表现最优（准确率99.43%，F1得分99.61%，AUC 99.93%），并验证其临床可解释性，适用于资源有限地区的筛查。


<details>
  <summary>Details</summary>
Motivation: 儿童肺炎致死率高，而放射科医生稀缺且诊断结果存在差异，亟需可靠、可部署的自动诊断工具。

Method: 在5216张儿童胸部X光片数据集上，对比7种模型（自建CNN与三种迁移学习模型在冻结骨干和微调两种策略下的表现），采用准确率、F1分数和AUC评估，并用Grad-CAM进行可视化解释。

Result: 微调ResNet50达到最高性能（准确率99.43%，F1得分99.61%，AUC 99.93%），仅3例误判；微调整体比冻结骨干平均提升5.5个百分点；Grad-CAM证实模型关注临床相关肺区。

Conclusion: 迁移学习结合微调显著优于从头训练CNN，具备近完美检测性能，有望作为资源匮乏地区儿童肺炎初筛工具。

Abstract: Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.
  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.
  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.
  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\% accuracy, 99.61\% F1-score, and 99.93\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.
  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.
  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.

</details>


### [5] [Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS](https://arxiv.org/abs/2601.00839)
*Zahid Ullah,Muhammad Hilal,Eunsoo Lee,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 本文对U-Net、Attention U-Net和TransUNet在CAMUS超声心动图数据集上的心脏结构分割性能进行了标准化基准测试，系统比较了不同预处理流程（如NIfTI vs PNG、伪标签、自监督预训练）的影响，并提供了保持超声图像强度保真度与分辨率一致性的实践指南。


<details>
  <summary>Details</summary>
Motivation: 现有综述多聚焦于心脏影像与深度学习进展，但缺乏统一、可复现的实验基准；本文旨在填补这一空白，建立可比性强、条件可控的分割模型评估框架。

Method: 在CAMUS数据集上，采用相同训练划分、损失函数和评估指标，对比U-Net、Attention U-Net和TransUNet三种架构；探索多种预处理路径：原生NIfTI体积、16位PNG导出、GPT辅助多边形伪标签、以及基于数千未标注动态帧的自监督预训练（SSL）。

Result: U-Net在NIfTI数据上达94%平均Dice；PNG-16bit流程为91%；Attention U-Net改善小/低对比区域边界泄漏；TransUNet（尤其配合SSL初始化）在困难帧上泛化最强；伪标签经置信度过滤后提升鲁棒性。

Conclusion: 本文建立了首个面向CAMUS的统一基准，强调预处理对性能的关键影响，提出维持超声图像 fidelity 的实践准则，并展望了自监督学习与GPT驱动多模态标注在快速标注、质控与数据定制中的潜力。

Abstract: Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.

</details>


### [6] [Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge](https://arxiv.org/abs/2601.00854)
*Igor Lodin,Sergii Filatov,Vira Filatova,Dmytro Filatov*

Main category: cs.CV

TL;DR: 本文提出Motion-Compensated Latent Semantic Canvases (MCLSC)，通过在稳定坐标系中维护静态与动态语义图层，并采用运动触发的异步分割策略，显著降低边缘设备上视觉态势感知的计算开销。


<details>
  <summary>Details</summary>
Motivation: 为资源受限的边缘设备实现高效、实时的视觉态势感知，避免每帧执行高成本的全景分割带来的计算负担。

Method: 构建两个持久化语义图层（缓慢累积的静态层和快速更新的动态层），基于视频流稳定坐标系；使用运动检测门控Mask2Former的异步推理，并结合运动补偿保持坐标一致性。

Result: 在480p预录视频片段上，相比逐帧分割基线，分割调用次数减少30倍以上，端到端平均处理时间降低20倍以上，同时保持静态/动态语义叠加的一致性。

Conclusion: MCLSC在保证语义感知质量的前提下，大幅提升了边缘视觉理解的能效比，适用于低功耗、实时性要求高的场景。

Abstract: We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.

</details>


### [7] [VL-OrdinalFormer: Vision Language Guided Ordinal Transformers for Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.00879)
*Zahid Ullah,Jihie Kim*

Main category: cs.CV

TL;DR: 本文提出VLOrdinalFormer，一种结合视觉语言引导与序数学习的全自动膝骨关节炎（KOA）X光分级框架，显著提升KL1/KL2等早期阶段判别准确率，并具备临床可解释性。


<details>
  <summary>Details</summary>
Motivation: KL分级中KL1与KL2影像差异细微，导致放射科医生间判别一致性差，亟需更鲁棒、可解释的自动化分级方法。

Method: 基于ViT-L16主干网络，融合CORAL序数回归与CLIP驱动的语义对齐模块，引入关节间隙变窄、骨赘形成和软骨下硬化等临床文本概念；采用分层五折交叉验证、类别感知重加权及测试时增强与全局阈值优化策略。

Result: 在OAI kneeKL224数据集上达到SOTA性能，宏F1与总体准确率超越CNN和ViT基线；尤其显著提升KL1/KL2分类性能，且不损害其他等级精度；Grad-CAM与CLIP相似性图证实模型关注临床相关解剖区域。

Conclusion: 视觉-语言对齐的序数Transformer模型有望成为临床常规放射实践中可靠、可解释的KOA分级与进展评估工具。

Abstract: Knee osteoarthritis (KOA) is a leading cause of disability worldwide, and accurate severity assessment using the Kellgren Lawrence (KL) grading system is critical for clinical decision making. However, radiographic distinctions between early disease stages, particularly KL1 and KL2, are subtle and frequently lead to inter-observer variability among radiologists. To address these challenges, we propose VLOrdinalFormer, a vision language guided ordinal learning framework for fully automated KOA grading from knee radiographs. The proposed method combines a ViT L16 backbone with CORAL based ordinal regression and a Contrastive Language Image Pretraining (CLIP) driven semantic alignment module, allowing the model to incorporate clinically meaningful textual concepts related to joint space narrowing, osteophyte formation, and subchondral sclerosis. To improve robustness and mitigate overfitting, we employ stratified five fold cross validation, class aware re weighting to emphasize challenging intermediate grades, and test time augmentation with global threshold optimization. Experiments conducted on the publicly available OAI kneeKL224 dataset demonstrate that VLOrdinalFormer achieves state of the art performance, outperforming CNN and ViT baselines in terms of macro F1 score and overall accuracy. Notably, the proposed framework yields substantial performance gains for KL1 and KL2 without compromising classification accuracy for mild or severe cases. In addition, interpretability analyses using Grad CAM and CLIP similarity maps confirm that the model consistently attends to clinically relevant anatomical regions. These results highlight the potential of vision language aligned ordinal transformers as reliable and interpretable tools for KOA grading and disease progression assessment in routine radiological practice.

</details>


### [8] [VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition](https://arxiv.org/abs/2601.00887)
*Hongbo Jin,Kuanwei Lin,Wenhao Zhang,Yichen Jin,Ge Li*

Main category: cs.CV

TL;DR: 本文提出VideoCuRL框架，通过将视频理解难度分解为视觉时间感知负荷和认知推理深度两个正交维度，并采用无训练代理指标构建2D课程网格与动态调度策略，显著提升视频大模型在推理与感知任务上的性能，同时避免生成式课程带来的高推理开销。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习范式依赖随机数据打乱或基于标量难度指标的简单课程策略，无法区分视频理解中的视觉时间感知负荷与认知推理深度这两个正交挑战。

Method: 提出VideoCuRL框架：1）用光流与关键帧熵表征视觉复杂度，用校准惊讶度（Calibrated Surprisal）表征认知复杂度，构建2D课程网格；2）采用能力感知的对角波前（Diagonal Wavefront）调度策略；3）引入动态稀疏KL散度与结构化重访机制以缓解奖励坍塌与灾难性遗忘。

Result: 在VSI-Bench上推理性能提升+2.5，在VideoMME上感知性能提升+2.9；消除了生成式课程的高推理开销，实现可扩展、鲁棒的视频后训练。

Conclusion: VideoCuRL通过解耦并协同建模视频理解的双重难度维度，提供了一种高效、稳定且可扩展的强化学习课程方法，显著提升了视频大语言模型的时空推理能力。

Abstract: Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these two axes. We employ efficient, training-free proxies, optical flow and keyframe entropy for visual complexity, Calibrated Surprisal for cognitive complexity, to map data onto a 2D curriculum grid. A competence aware Diagonal Wavefront strategy then schedules training from base alignment to complex reasoning. Furthermore, we introduce Dynamic Sparse KL and Structured Revisiting to stabilize training against reward collapse and catastrophic forgetting. Extensive experiments show that VideoCuRL surpasses strong RL baselines on reasoning (+2.5 on VSI-Bench) and perception (+2.9 on VideoMME) tasks. Notably, VideoCuRL eliminates the prohibitive inference overhead of generation-based curricula, offering a scalable solution for robust video post-training.

</details>


### [9] [Comparative Evaluation of CNN Architectures for Neural Style Transfer in Indonesian Batik Motif Generation: A Comprehensive Study](https://arxiv.org/abs/2601.00888)
*Happy Gery Pangestu,Andi Prademon Yunus,Siti Khomsah*

Main category: cs.CV

TL;DR: 本研究系统比较了五种CNN骨干网络（VGG16/19、Inception V3、ResNet50/101）在印尼蜡染纹样神经风格迁移（NST）中的性能，发现ResNet在保持结构相似性和感知质量的同时，显著提升训练速度与计算效率，更适合资源受限的实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有基于VGG的NST方法虽风格表现力强，但计算与内存开销大，难以在资源受限环境中实际应用；亟需探索兼顾结构保真、风格质量与计算效率的更优骨干网络。

Method: 开展245组受控实验，综合定量指标（SSIM、LPIPS、FLOPs）、定性评估和统计分析（ANOVA），系统比较五种主流CNN骨干在印尼蜡染NST任务中的表现。

Result: ResNet模型收敛速度快5–6倍、FLOPs减少超16倍（0.63 vs 10.12 GFLOPs）、SSIM无显著差异（p=0.83），LPIPS达0.53；VGG纹理更浓密，ResNet更利于几何结构与蜡染笔触保留，Inception V3表现居中但噪声更大。

Conclusion: 骨干网络选择应从追求极致风格强度转向兼顾效率与结构保真；ResNet系列是面向产业级可扩展蜡染生成的更实用基础架构。

Abstract: Neural Style Transfer (NST) provides a computational framework for the digital preservation and generative exploration of Indonesian batik motifs; however, existing approaches remain largely centered on VGG-based architectures whose strong stylistic expressiveness comes at the cost of high computational and memory demands, that limits practical deployment in resource-limited environments. This study presents a systematic comparative analysis of five widely used CNN backbones, namely VGG16, VGG19, Inception V3, ResNet50, and ResNet101, based on 245 controlled experiments combining quantitative metrics, qualitative assessment, and statistical analysis to examine the trade-off between structural preservation, stylistic behavior, and computational efficiency. The results show that backbone selection does not yield statistically significant differences in structural similarity, as confirmed by ANOVA on SSIM (p= 0.83), indicating comparable levels of structural preservation rather than equivalent stylistic quality. Within this context, ResNet-based architectures achieve approximately 5-6x faster convergence than VGG models while maintaining similar perceptual similarity (LPIPS = 0.53) and requiring over 16x fewer FLOPs (0.63 vs 10.12 GFLOPs). Qualitative analysis reveals consistent stylistic trade-offs, with VGG producing denser painterly textures, ResNet favoring geometric stability and canting stroke preservation with milder stylization, and Inception V3 exhibiting intermediate but noisier behavior. These findings reposition architectural choice in NST from maximizing stylistic intensity toward efficiency-aware and structure-preserving deployment, highlighting ResNet-based backbones as a practical foundation for scalable, industry-oriented batik generation.

</details>


### [10] [CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis](https://arxiv.org/abs/2601.00897)
*Sai Teja Erukude,Jane Mascarenhas,Lior Shamir*

Main category: cs.CV

TL;DR: 本文提出CornViT，一种三阶段卷积视觉Transformer框架，用于单粒玉米籽粒的自动分级，涵盖纯度、形态（扁平/圆润）和胚朝向识别，在自建基准数据集上显著优于ResNet-50和DenseNet-121，并配套开源代码、数据与可交互Web应用。


<details>
  <summary>Details</summary>
Motivation: 玉米籽粒精准分级对种子认证、定向播种和育种至关重要，但目前仍主要依赖人工目检，效率低、主观性强，亟需自动化、高精度的解决方案。

Method: 提出三阶段CvT-13分类框架（CornViT）：Stage 1判别纯度，Stage 2区分扁平/圆润形态，Stage 3识别扁平纯籽粒的胚朝向（上/下）；基于公开数据手工重标注构建三个专用数据集；采用ImageNet-22k预训练CvT-13模型进行head-only微调；部署为Flask Web应用并提供可视化解释输出。

Result: 在自建基准数据集上，CornViT三阶段测试准确率分别达93.76%（纯度）、94.11%（形态）、91.12%（胚朝向）；显著优于同等条件下ResNet-50（76.56–81.02%）和DenseNet-121（86.56–89.38%）；所有代码、数据及Web应用均已开源。

Conclusion: Convolution-augmented self-attention架构（CvT）更适配玉米籽粒细粒度分析任务；CornViT框架结合高质量标注数据与易用Web工具，为种子质量检测提供了可落地的自动化方案。

Abstract: Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.

</details>


### [11] [Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems](https://arxiv.org/abs/2601.00905)
*Eliot Park,Abhi Kumar,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: 本文研究了GPT-4o、GPT-4o-mini和Claude 3.5等视觉语言模型在物品可回收性判断任务中的应用，评估其在多场景（如地域规则、污染/损坏、多材质）下的性能表现，并指出其上下文理解能力的提升与现存不足。


<details>
  <summary>Details</summary>
Motivation: 公众难以准确判断物品可回收性及正确投放方式，亟需智能化辅助工具提升回收效率与环保可持续性。

Method: 采用自建图像数据集，测试多个先进视觉语言模型对常见废弃物的可回收性判断能力，包括匹配对应回收箱、尺寸适配性，并在地域差异、污染/破损、多材质混合三类挑战场景下进行性能分析。

Result: 当前VLMs在上下文理解方面显著优于早期模型，但在处理地域化规则、污染影响及复合材料识别等方面仍存在明显局限。

Conclusion: 需持续优化具备强上下文感知能力的多模态模型，以切实支持公众垃圾分类实践并推动环境可持续发展。

Abstract: While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.

</details>


### [12] [Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting](https://arxiv.org/abs/2601.00913)
*Subhankar Mishra*

Main category: cs.CV

TL;DR: Clean-GS 是一种基于稀疏语义掩码的3D高斯泼溅（3DGS）后处理方法，可高效去除背景杂点与浮点高斯体，实现60–80%模型压缩且不损主体渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting 生成大量无关浮点高斯体（floaters），干扰目标物体、增大模型体积，制约其在带宽受限场景（如Web/AR/VR）中的部署。

Method: 提出三阶段清洗流程：(1) 基于少量（~3张，约1%视角）语义掩码的白名单空间投影过滤；(2) 深度缓冲的颜色一致性验证；(3) 邻域统计驱动的离群高斯剔除。全程依赖稀疏语义引导，无需全局重要性度量。

Result: 在Tanks and Temples数据集上将模型体积从125MB压缩至47MB（约62%压缩率），渲染质量保持不变；显著提升3DGS在Web与AR/VR中的实用性。

Conclusion: Clean-GS证明仅需极稀疏语义监督即可实现精准高斯体清理，为轻量化、可部署的神经渲染提供新范式。

Abstract: 3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs

</details>


### [13] [Four-Stage Alzheimer's Disease Classification from MRI Using Topological Feature Extraction, Feature Selection, and Ensemble Learning](https://arxiv.org/abs/2601.00918)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: 本文提出TDA-Alz框架，利用拓扑数据分析（TDA）和集成学习实现阿尔茨海默病（AD）四阶段严重程度分类，无需深度卷积网络或数据增强，在OASIS-1数据集上达到98.19%准确率和99.75% AUC，兼具高精度、高效性与强可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决AD严重程度分类中数据有限和模型可解释性差的关键挑战。

Method: 提出TDA-Alz框架：先用TDA提取脑MRI的拓扑描述符以表征内在结构模式，再经特征选择保留最具判别性的拓扑特征，最后采用集成学习进行多类分类。

Result: 在OASIS-1数据集上达到98.19%分类准确率和99.75% AUC，优于或媲美现有深度学习方法；无需数据增强、预训练网络或大规模算力，计算高效且可解释性强。

Conclusion: TDA-Alz是一种轻量、高效且可解释的替代方案，具有临床决策支持应用潜力。

Abstract: Accurate and efficient classification of Alzheimer's disease (AD) severity from brain magnetic resonance imaging (MRI) remains a critical challenge, particularly when limited data and model interpretability are of concern. In this work, we propose TDA-Alz, a novel framework for four-stage Alzheimer's disease severity classification (non-demented, moderate dementia, mild, and very mild) using topological data analysis (TDA) and ensemble learning. Instead of relying on deep convolutional architectures or extensive data augmentation, our approach extracts topological descriptors that capture intrinsic structural patterns of brain MRI, followed by feature selection to retain the most discriminative topological features. These features are then classified using an ensemble learning strategy to achieve robust multiclass discrimination.
  Experiments conducted on the OASIS-1 MRI dataset demonstrate that the proposed method achieves an accuracy of 98.19% and an AUC of 99.75%, outperforming or matching state-of-the-art deep learning--based methods reported on OASIS and OASIS-derived datasets. Notably, the proposed framework does not require data augmentation, pretrained networks, or large-scale computational resources, making it computationally efficient and fast compared to deep neural network approaches. Furthermore, the use of topological descriptors provides greater interpretability, as the extracted features are directly linked to the underlying structural characteristics of brain MRI rather than opaque latent representations. These results indicate that TDA-Alz offers a powerful, lightweight, and interpretable alternative to deep learning models for MRI-based Alzheimer's disease severity classification, with strong potential for real-world clinical decision-support systems.

</details>


### [14] [Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis](https://arxiv.org/abs/2601.00925)
*I-Hsien Ting,Yi-Jun Tseng,Yu-Sheng Lin*

Main category: cs.CV

TL;DR: 本研究提出了一种无需造影剂的CT图像肺栓塞自动分类方法，采用3D卷积神经网络，准确率达85%，AUC为0.84，验证了其临床可行性。


<details>
  <summary>Details</summary>
Motivation: 传统造影增强CT诊断肺栓塞存在诱发急性肾损伤及延误治疗时机的风险，尤其对合并慢性肾病的急性肺栓塞患者不利。

Method: 采用3D卷积神经网络模型，在无造影剂CT图像上进行肺栓塞自动分类。

Result: 模型在无造影剂CT图像上的肺栓塞分类准确率为85%，AUC为0.84。

Conclusion: 该深度学习模型在无需造影剂条件下具备肺栓塞诊断可行性，有望提升高危患者的早期诊断安全性与时效性。

Abstract: Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time.
  This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.

</details>


### [15] [Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store](https://arxiv.org/abs/2601.00928)
*Luis Yoichi Morales,Francesco Zanlungo,David M. Woollard*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D视觉轨迹分析的货架访问（shelf visit）识别算法，用于理解顾客在零售店中的浏览意图，并验证了其跨店铺泛化能力，进而分析浏览行为与购买行为的关系，为零售规划和人机交互提供支持。


<details>
  <summary>Details</summary>
Motivation: 应对机器人在零售场景中面向顾客部署所面临的挑战，需实现对顾客购物意图的自主理解。

Method: 利用机器视觉和俯视摄像头获取顾客3D轨迹，设计算法识别‘货架访问’行为；通过两组不同店铺采集并人工标注的轨迹（8138和15129条）进行独立校准，并在同店及跨店留出数据上评估泛化性能。

Result: 算法具备跨店铺环境的泛化能力，能有效识别顾客浏览行为；进一步分析表明货架浏览模式与实际购买行为存在可挖掘关联。

Conclusion: 货架访问识别算法不仅具有实际部署潜力，还可支撑零售运营优化与人-机器人协同交互设计。

Abstract: Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.

</details>


### [16] [ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery](https://arxiv.org/abs/2601.00939)
*Feng Luo,Hongbo Pan,Xiang Yang,Baoyu Jiang,Fengqing Liu,Tao Huang*

Main category: cs.CV

TL;DR: 本文提出ShadowGS，一种基于3D高斯泼溅（3DGS）的新型框架，用于多时相卫星影像的三维重建。它结合物理渲染方程与高效光线步进技术建模几何一致阴影，并解耦光照分量与表观属性，引入阴影一致性约束和阴影图先验，显著提升重建精度与新视角合成质量，训练仅需几分钟。


<details>
  <summary>Details</summary>
Motivation: 多时相卫星影像中因光照变化导致阴影不一致，严重影响3D重建质量。

Method: 基于3DGS，融合遥感物理渲染方程与高效ray marching建模几何一致阴影；引入阴影一致性约束和阴影图先验；实现光照成分与表观属性的解耦。

Result: 在阴影解耦精度、3D重建精度和新视角合成质量上均优于当前SOTA方法；训练时间仅几分钟；对RGB、全色锐化及稀疏视角卫星图像均表现鲁棒。

Conclusion: ShadowGS有效解决了多时相卫星影像中阴影不一致问题，提升了三维重建的几何准确性和渲染质量，兼具高效性与泛化能力。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel paradigm for 3D reconstruction from satellite imagery. However, in multi-temporal satellite images, prevalent shadows exhibit significant inconsistencies due to varying illumination conditions. To address this, we propose ShadowGS, a novel framework based on 3DGS. It leverages a physics-based rendering equation from remote sensing, combined with an efficient ray marching technique, to precisely model geometrically consistent shadows while maintaining efficient rendering. Additionally, it effectively disentangles different illumination components and apparent attributes in the scene. Furthermore, we introduce a shadow consistency constraint that significantly enhances the geometric accuracy of 3D reconstruction. We also incorporate a novel shadow map prior to improve performance with sparse-view inputs. Extensive experiments demonstrate that ShadowGS outperforms current state-of-the-art methods in shadow decoupling accuracy, 3D reconstruction precision, and novel view synthesis quality, with only a few minutes of training. ShadowGS exhibits robust performance across various settings, including RGB, pansharpened, and sparse-view satellite inputs.

</details>


### [17] [Learning to Segment Liquids in Real-world Images](https://arxiv.org/abs/2601.00940)
*Jonas Li,Michelle Li,Luke Liu,Heng Fan*

Main category: cs.CV

TL;DR: 本文提出了首个大规模液体分割数据集LQDS和新型液体检测模型LQDM，通过边界分支与主分割分支间的交叉注意力机制提升分割性能，在液体语义分割任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 液体在日常生活中广泛存在，但机器人对液体的安全避让与交互能力受限于液体分割任务研究的不足；液体外观多样、透明/反射性强、易受背景干扰，导致分割难度大。

Method: 构建了包含5000张真实图像、14类标注的大规模液体数据集LQDS；提出液体检测模型LQDM，其核心是利用专用边界分支与主分割分支之间的交叉注意力机制来增强分割预测。

Result: 在LQDS测试集上的大量实验表明，LQDM显著优于现有最先进方法，为液体语义分割任务建立了强有力的基线。

Conclusion: 本工作填补了液体视觉理解领域的空白，通过新数据集和新模型推动了机器人安全处理液体的能力发展。

Abstract: Different types of liquids such as water, wine and medicine appear in all aspects of daily life. However, limited attention has been given to the task, hindering the ability of robots to avoid or interact with liquids safely. The segmentation of liquids is difficult because liquids come in diverse appearances and shapes; moreover, they can be both transparent or reflective, taking on arbitrary objects and scenes from the background or surroundings. To take on this challenge, we construct a large-scale dataset of liquids named LQDS consisting of 5000 real-world images annotated into 14 distinct classes, and design a novel liquid detection model named LQDM, which leverages cross-attention between a dedicated boundary branch and the main segmentation branch to enhance segmentation predictions. Extensive experiments demonstrate the effectiveness of LQDM on the test set of LQDS, outperforming state-of-the-art methods and establishing a strong baseline for the semantic segmentation of liquids.

</details>


### [18] [PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education](https://arxiv.org/abs/2601.00943)
*Megha Mariam K. M,Aditya Arun,Zakaria Laskar,C. V. Jawahar*

Main category: cs.CV

TL;DR: 本文提出了一个面向物理学教育的Text-to-Video（T2V）解释性视频生成基准，评估现有T2V模型在可视化呈现物理概念方面的准确性与可行性；结果表明当前模型视觉质量较好但概念准确性不足，尤其在电磁学和热力学等抽象领域表现较弱。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI（尤其是Text-to-Video模型）在科学教育中的潜力，解决高质量、可扩展、个性化物理教学视频自动生成的挑战。

Method: 构建了一个面向物理教育的专用T2V基准，将核心物理概念细分为教学要点，并为每个要点设计专用提示词；使用该基准对主流T2V模型进行系统性评估，侧重于视频的视觉质量与概念准确性两方面。

Result: 当前T2V模型能生成视觉连贯、运动平滑、闪烁少的视频，但在概念准确性上表现不稳定；力学、流体、光学任务表现尚可，而电磁学和热力学因抽象性强、交互难可视化，准确率显著下降。

Conclusion: 视觉质量不等于教学有效性；需弥合T2V模型在视觉生成与科学概念准确性之间的鸿沟；本工作提供了开源基准与代码，推动可信赖、课程对齐的AI教育视频生成研究。

Abstract: Generative AI models, particularly Text-to-Video (T2V) systems, offer a promising avenue for transforming science education by automating the creation of engaging and intuitive visual explanations. In this work, we take a first step toward evaluating their potential in physics education by introducing a dedicated benchmark for explanatory video generation. The benchmark is designed to assess how well T2V models can convey core physics concepts through visual illustrations. Each physics concept in our benchmark is decomposed into granular teaching points, with each point accompanied by a carefully crafted prompt intended for visual explanation of the teaching point. T2V models are evaluated on their ability to generate accurate videos in response to these prompts. Our aim is to systematically explore the feasibility of using T2V models to generate high-quality, curriculum-aligned educational content-paving the way toward scalable, accessible, and personalized learning experiences powered by AI. Our evaluation reveals that current models produce visually coherent videos with smooth motion and minimal flickering, yet their conceptual accuracy is less reliable. Performance in areas such as mechanics, fluids, and optics is encouraging, but models struggle with electromagnetism and thermodynamics, where abstract interactions are harder to depict. These findings underscore the gap between visual quality and conceptual correctness in educational video generation. We hope this benchmark helps the community close that gap and move toward T2V systems that can deliver accurate, curriculum-aligned physics content at scale. The benchmark and accompanying codebase are publicly available at https://github.com/meghamariamkm/PhyEduVideo.

</details>


### [19] [Deep Clustering with Associative Memories](https://arxiv.org/abs/2601.00963)
*Bishwajit Saha,Dmitry Krotov,Mohammed J. Zaki,Parikshit Ram*

Main category: cs.CV

TL;DR: 本文提出了一种名为DCAM的新型深度聚类方法，利用基于能量的关联记忆动力学设计损失函数，将表示学习与聚类更紧密地统一于单一目标中，提升了多种网络结构和数据模态下的聚类性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度聚类方法中表示学习与聚类优化脱节，因聚类本质是离散优化任务，难以自然融入可微深度学习框架。

Method: 提出基于能量的关联记忆（Associative Memories）动力学损失函数，构建端到端可微的深度聚类方法DCAM，实现表示学习与聚类的联合优化。

Result: 在图像和文本等多种模态、以及卷积、残差、全连接等多种网络结构上均取得更优的聚类质量。

Conclusion: DCAM通过能量驱动的关联记忆机制，有效弥合了表示学习与聚类之间的鸿沟，为深度聚类提供了更统一、更有效的建模范式。

Abstract: Deep clustering - joint representation learning and latent space clustering - is a well studied problem especially in computer vision and text processing under the deep learning framework. While the representation learning is generally differentiable, clustering is an inherently discrete optimization task, requiring various approximations and regularizations to fit in a standard differentiable pipeline. This leads to a somewhat disjointed representation learning and clustering. In this work, we propose a novel loss function utilizing energy-based dynamics via Associative Memories to formulate a new deep clustering method, DCAM, which ties together the representation learning and clustering aspects more intricately in a single objective. Our experiments showcase the advantage of DCAM, producing improved clustering quality for various architecture choices (convolutional, residual or fully-connected) and data modalities (images or text).

</details>


### [20] [A Deep Learning Approach for Automated Skin Lesion Diagnosis with Explainable AI](https://arxiv.org/abs/2601.00964)
*Md. Maksudul Haque,Rahnuma Akter,A S M Ahsanul Sarkar Akib,Abdul Hasib*

Main category: cs.CV

TL;DR: 本文提出了一种结合数据平衡、大规模增强、带通道注意力的混合EfficientNetV2-L模型及三阶段渐进学习的多类皮肤病变分类方法，在HAM10000数据集上达到91.15%准确率，并引入Grad-CAM等XAI技术提升可解释性与临床可信度。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见且危险的癌症之一，亟需及时精准诊断；现有方法在分类精度、类别均衡和模型可解释性方面仍有提升空间。

Method: 采用高质量数据平衡、大规模数据增强、融合通道注意力机制的混合EfficientNetV2-L架构，结合三阶段渐进式学习策略，并集成Grad-CAM和显著性图等可解释AI（XAI）技术。

Result: 在HAM10000数据集上实现91.15%总体准确率、85.45%宏F1值和99.33%微平均AUC，对黑色素瘤和色素痣等关键病灶表现尤为突出。

Conclusion: 所提方法不仅显著提升了多类皮肤病变分类性能，还通过XAI增强了决策透明度与临床可信赖性，为辅助皮肤癌诊断提供了实用可行的深度学习解决方案。

Abstract: Skin cancer is also one of the most common and dangerous types of cancer in the world that requires timely and precise diagnosis. In this paper, a deep-learning architecture of the multi-class skin lesion classification on the HAM10000 dataset will be described. The system suggested combines high-quality data balancing methods, large-scale data augmentation, hybridized EfficientNetV2-L framework with channel attention, and a three-stage progressive learning approach. Moreover, we also use explainable AI (XAI) techniques such as Grad-CAM and saliency maps to come up with intelligible visual representations of model predictions. Our strategy is with a total accuracy of 91.15 per cent, macro F1 of 85.45\% and micro-average AUC of 99.33\%. The model has shown high performance in all the seven lesion classes with specific high performance of melanoma and melanocytic nevi. In addition to enhancing diagnostic transparency, XAI also helps to find out the visual characteristics that cause the classifications, which enhances clinical trustworthiness.

</details>


### [21] [Few-Shot Video Object Segmentation in X-Ray Angiography Using Local Matching and Spatio-Temporal Consistency Loss](https://arxiv.org/abs/2601.00988)
*Lin Xi,Yingliang Ma,Xiahai Zhuang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的FSVOS模型，采用基于方向的局部匹配策略进行非参数化动态采样，并结合监督式时空对比学习提升帧间特征一致性；同时构建了X射线血管造影视频多目标分割基准数据集MOSXAV，实验表明该方法在分割精度与泛化能力上优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有FSVOS方法依赖低效的im2col类操作或硬件特定CUDA核导致的跨平台可移植性差问题，并提升X射线血管造影视频中多目标分割的精度与临床适用性。

Method: 提出基于方向的局部匹配策略与非参数化动态采样机制，替代传统空间卷积等操作；设计监督式时空对比学习以增强帧间特征一致性；构建公开基准数据集MOSXAV。

Result: 在CADICA、XACV和MOSXAV数据集上，所提FSVOS方法在分割精度和对已见/未见类别的泛化能力上均超越当前SOTA方法。

Conclusion: 该工作提升了FSVOS模型的灵活性、可移植性与临床应用潜力，为X射线血管造影视频分析提供了新范式。

Abstract: We introduce a novel FSVOS model that employs a local matching strategy to restrict the search space to the most relevant neighboring pixels. Rather than relying on inefficient standard im2col-like implementations (e.g., spatial convolutions, depthwise convolutions and feature-shifting mechanisms) or hardware-specific CUDA kernels (e.g., deformable and neighborhood attention), which often suffer from limited portability across non-CUDA devices, we reorganize the local sampling process through a direction-based sampling perspective. Specifically, we implement a non-parametric sampling mechanism that enables dynamically varying sampling regions. This approach provides the flexibility to adapt to diverse spatial structures without the computational costs of parametric layers and the need for model retraining. To further enhance feature coherence across frames, we design a supervised spatio-temporal contrastive learning scheme that enforces consistency in feature representations. In addition, we introduce a publicly available benchmark dataset for multi-object segmentation in X-ray angiography videos (MOSXAV), featuring detailed, manually labeled segmentation ground truth. Extensive experiments on the CADICA, XACV, and MOSXAV datasets show that our proposed FSVOS method outperforms current state-of-the-art video segmentation methods in terms of segmentation accuracy and generalization capability (i.e., seen and unseen categories). This work offers enhanced flexibility and potential for a wide range of clinical applications.

</details>


### [22] [ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval](https://arxiv.org/abs/2601.01024)
*Tien-Huy Nguyen,Huu-Loc Tran,Thanh Duc Ngo*

Main category: cs.CV

TL;DR: 本文提出ITSELF框架，通过注意力引导的隐式局部对齐方法解决文本-图像人物搜索中的细粒度匹配问题，避免了捷径学习和先验知识干扰，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法易受捷径学习和虚假相关影响，且注入先验知识会破坏模态内结构；作者发现编码器注意力在训练早期即能提供空间精确证据，由此提出新框架。

Method: 提出ITSELF框架，包含三个核心组件：GRAB（将自注意力转化为高显著性Token库并施加局部目标）、MARS（跨层聚合注意力并多样性感知选Top-k）和ATS（自适应调度Token保留预算，由粗到细渐进聚焦）。

Result: 在三个主流TBPS基准上取得SOTA性能，并展现出强跨数据集泛化能力，无需额外监督或先验知识。

Conclusion: ITSELF是一种有效、鲁棒的无监督注意力引导对齐方法，为细粒度跨模态检索提供了新思路。

Abstract: Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself

</details>


### [23] [UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data](https://arxiv.org/abs/2601.00991)
*Joshua Kawaguchi,Saad Manzur,Emily Gao Wang,Maitreyi Sinha,Bryan Vela,Yunxi Wang,Brandon Vela,Wayne B. Hayes*

Main category: cs.CV

TL;DR: 本文提出UnrealPose-Gen，一个基于Unreal Engine 5的高质量3D人体姿态数据生成管线，并发布含百万帧的UnrealPose-1M合成数据集，涵盖丰富动作、场景与视角，同时提供完整3D/2D标注及相机参数，并在多项任务上验证其真实性。


<details>
  <summary>Details</summary>
Motivation: 真实世界中高质量、多样且精确标注的3D人体姿态数据昂贵且受限于拍摄环境；野外数据又缺乏可靠真值。亟需一种可扩展、可控、高保真的合成数据生成方案。

Method: 构建基于Unreal Engine 5 Movie Render Queue的离线渲染管线UnrealPose-Gen，支持生成带完整标注（世界/相机坐标系3D关节点、2D投影/COCO关键点/可见性/遮挡标志、人物框、相机内外参）的图像帧；并据此生成UnrealPose-1M数据集（8个序列，共约100万帧，含脚本化与随机化动作、多场景、多主体、多视角）。

Result: UnrealPose-1M在图像到3D姿态估计、2D关键点检测、2D到3D提升、人物检测/分割四项任务上展现出良好的跨域（真实→合成）迁移性能，验证了数据的高保真度与实用性。

Conclusion: UnrealPose-Gen为3D人体姿态研究提供了高效、灵活、开源的数据生成范式；UnrealPose-1M是当前规模大、标注全、多样性高的高质量合成基准，已全部开源以推动社区发展。

Abstract: Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in world and camera coordinates, (ii) 2D projections and COCO-style keypoints with occlusion and joint-visibility flags, (iii) person bounding boxes, and (iv) camera intrinsics and extrinsics. We use UnrealPose-Gen to present UnrealPose-1M, an approximately one million frame corpus comprising eight sequences: five scripted "coherent" sequences spanning five scenes, approximately 40 actions, and five subjects; and three randomized sequences across three scenes, approximately 100 actions, and five subjects, all captured from diverse camera trajectories for broad viewpoint coverage. As a fidelity check, we report real-to-synthetic results on four tasks: image-to-3D pose, 2D keypoint detection, 2D-to-3D lifting, and person detection/segmentation. Though time and resources constrain us from an unlimited dataset, we release the UnrealPose-1M dataset, as well as the UnrealPose-Gen pipeline to support third-party generation of human pose data.

</details>


### [24] [WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift](https://arxiv.org/abs/2601.00993)
*Julian D. Santamaria,Claudia Isaza,Jhony H. Giraldo*

Main category: cs.CV

TL;DR: 本文提出WildIng模型，通过融合文本描述与图像特征，提升野生动物识别模型在跨地理区域场景下的泛化能力，显著缓解因背景、光照等分布偏移导致的性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的野生动物识别基础模型在跨地理区域测试时性能大幅下降，主要由于对地理数据分布偏移（如背景、光照差异）敏感。

Method: 提出WildIng模型，将文本描述（如物种外观细节）与图像特征联合建模，构建对地理域偏移鲁棒的不变表征。

Result: WildIng使BioCLIP等基础模型在跨美洲与非洲数据集的地理域偏移场景下准确率提升30%；在非洲训练、美洲测试时，CLIP+Adapter准确率从16.17%提升至显著更高水平。

Conclusion: 引入文本语义信息可有效增强野生动物识别模型的地理域泛化能力，WildIng为跨区域生态监测提供了更鲁棒的深度学习解决方案。

Abstract: Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.

</details>


### [25] [DVGBench: Implicit-to-Explicit Visual Grounding Benchmark in UAV Imagery with Large Vision-Language Models](https://arxiv.org/abs/2601.00998)
*Yue Zhou,Jue Chen,Zilun Zhang,Penghui Huang,Ran Ding,Zhentao Zou,PengFei Gao,Yuchen Wei,Ke Li,Xue Yang,Xue Jiang,Hongxin Yang,Jonathan Li*

Main category: cs.CV

TL;DR: 本文提出了DVGBench，一个面向无人机应用的隐式视觉定位（VG）基准数据集，并设计了DroneVG-R1模型，通过隐式到显式的思维链（I2E-CoT）增强大视觉语言模型在隐式VG任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉定位数据集多依赖显式指代表达，难以支持需领域知识的隐式视觉定位任务，限制了模型在真实无人机场景中的泛化能力。

Method: 构建覆盖六大应用场景的DVGBench隐式VG基准；提出DroneVG-R1模型，融合隐式到显式思维链（I2E-CoT）与强化学习框架，实现隐式表达向显式定位的转化。

Result: 在显式与隐式VG任务上的评估表明主流LVLMs推理能力严重不足；DroneVG-R1显著提升隐式VG性能，并验证I2E-CoT的有效性。

Conclusion: 隐式视觉定位是提升无人机智能体场景理解与推理能力的关键挑战；DVGBench和I2E-CoT为遥感LVLMs的推理能力发展提供了新基准与方法论支撑。

Abstract: Remote sensing (RS) large vision-language models (LVLMs) have shown strong promise across visual grounding (VG) tasks. However, existing RS VG datasets predominantly rely on explicit referring expressions-such as relative position, relative size, and color cues-thereby constraining performance on implicit VG tasks that require scenario-specific domain knowledge. This article introduces DVGBench, a high-quality implicit VG benchmark for drones, covering six major application scenarios: traffic, disaster, security, sport, social activity, and productive activity. Each object provides both explicit and implicit queries. Based on the dataset, we design DroneVG-R1, an LVLM that integrates the novel Implicit-to-Explicit Chain-of-Thought (I2E-CoT) within a reinforcement learning paradigm. This enables the model to take advantage of scene-specific expertise, converting implicit references into explicit ones and thus reducing grounding difficulty. Finally, an evaluation of mainstream models on both explicit and implicit VG tasks reveals substantial limitations in their reasoning capabilities. These findings provide actionable insights for advancing the reasoning capacity of LVLMs for drone-based agents. The code and datasets will be released at https://github.com/zytx121/DVGBench

</details>


### [26] [Lightweight Channel Attention for Efficient CNNs](https://arxiv.org/abs/2601.01002)
*Prem Babu Kanaparthi,Tulasi Venkata Sri Varshini Padamata*

Main category: cs.CV

TL;DR: 本文对不同通道注意力机制（SE、ECA和新提出的LCA）在ResNet18和MobileNetV2上的性能与效率进行了实证比较，提出轻量级LCA模块，在保持高准确率的同时显著降低参数量和延迟。


<details>
  <summary>Details</summary>
Motivation: 不同通道注意力机制在精度与效率之间的权衡尚未被充分研究，尤其在资源受限场景下需兼顾性能与开销。

Method: 提出Lite Channel Attention（LCA）模块，采用自适应一维卷积与分组操作；在CIFAR-10上对比SE、ECA与LCA在ResNet18和MobileNetV2上的表现，并评估FLOPs、参数量及GPU延迟。

Result: LCA在ResNet18和MobileNetV2上分别达到94.68%和93.10%准确率，参数效率与ECA相当，推理延迟表现良好。

Conclusion: LCA是一种高效且实用的通道注意力设计，在精度、参数量与延迟之间取得更好平衡，适合资源受限部署。

Abstract: Attention mechanisms have become integral to modern convolutional neural networks (CNNs), delivering notable performance improvements with minimal computational overhead. However, the efficiency accuracy trade off of different channel attention designs remains underexplored. This work presents an empirical study comparing Squeeze and Excitation (SE), Efficient Channel Attention (ECA), and a proposed Lite Channel Attention (LCA) module across ResNet 18 and MobileNetV2 architectures on CIFAR 10. LCA employs adaptive one dimensional convolutions with grouped operations to reduce parameter usage while preserving effective attention behavior. Experimental results show that LCA achieves competitive accuracy, reaching 94.68 percent on ResNet 18 and 93.10 percent on MobileNetV2, while matching ECA in parameter efficiency and maintaining favorable inference latency. Comprehensive benchmarks including FLOPs, parameter counts, and GPU latency measurements are provided, offering practical insights for deploying attention enhanced CNNs in resource constrained environments.

</details>


### [27] [Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking](https://arxiv.org/abs/2601.01022)
*Shiao Wang,Xiao Wang,Haonan Zhao,Jiarui Xu,Bo Jiang,Lin Zhu,Xin Zhao,Yonghong Tian,Jin Tang*

Main category: cs.CV

TL;DR: 本文提出了一种在频域进行早期融合的RGB-Event视觉目标跟踪新框架，利用事件相机的高动态范围和运动敏感特性，通过幅度与相位注意力机制选择性融合高频事件信息，并引入运动引导的空间稀疏化模块减少冗余计算，显著提升跟踪性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-Event跟踪方法多采用传统特征级融合，未能充分利用事件相机的高动态范围和运动敏感特性，且对低信息区域统一处理，造成骨干网络不必要的计算开销。

Method: 将RGB与事件模态通过快速傅里叶变换（FFT）映射至频域，解耦其幅度与相位分量；设计幅度与相位注意力机制，选择性融合事件高频信息；引入运动引导的空间稀疏化模块，依据事件运动线索过滤低信息区域，仅将稀疏的目标相关特征送入骨干网络学习。

Result: 在FE108、FELT和COESOT三个主流RGB-Event跟踪基准数据集上实验表明，该方法兼具高性能与高效率。

Conclusion: 频域早期融合与运动引导稀疏化能更有效地协同利用RGB与事件模态互补优势，在提升跟踪精度的同时显著降低计算成本。

Abstract: Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking

</details>


### [28] [Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation](https://arxiv.org/abs/2601.01026)
*Douglas Costa Braga,Daniel Oliveira Dantas*

Main category: cs.CV

TL;DR: 本文提出了一种可复现的深度学习流水线，用于急性淋巴细胞白血病（ALL）细胞分类，结合EfficientNetV2-B3与Squeeze-and-Excitation注意力机制，在C-NMC 2019数据集上达到97.89% F1-score和准确率，显著优于基线方法且参数量大幅减少。


<details>
  <summary>Details</summary>
Motivation: 急性淋巴细胞白血病（ALL）是儿童最常见癌症，依赖显微镜诊断易受观察者间差异和时间限制影响，亟需鲁棒、可复现、可解释的自动化分类方法。

Method: 构建基于注意力机制的CNN架构（EfficientNetV2-B3 + Squeeze-and-Excitation），采用全面数据增强、焦点损失处理类别不平衡、患者级数据划分，并通过100次蒙特卡洛实验进行统计验证。

Result: 在C-NMC 2019数据集上取得97.89% F1-score和准确率；相比基线显著提升（p < 0.001）；性能优于现有方法最多4.67%，参数量仅15.2M（比VGG16少89%）；注意力机制提供可解释的细胞特征可视化。

Conclusion: 该注意力增强、轻量化、可复现的深度学习流水线在保持高精度的同时兼顾计算效率与临床可部署性，为医学图像分析提供了系统性软件设计范例。

Abstract: We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.

</details>


### [29] [Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising](https://arxiv.org/abs/2601.01036)
*Kiet Dang Vu,Trung Thai Tran,Kien Nguyen Do Trung,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: 本文提出Mono3DV框架，通过引入3D感知的二分匹配、3D去噪和变分查询去噪机制，解决单目3D目标检测中因仅用2D匹配导致的3D预测不稳定与抑制问题，在KITTI数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: DETR类架构在单目3D目标检测中受限于二分匹配过程未纳入3D属性，导致因单目3D估计不适定而引发训练不稳定，高质量3D预测被2D匹配标准错误抑制。

Method: 提出Mono3DV：1）3D感知二分匹配，将3D几何信息直接融入匹配代价；2）训练阶段引入3D去噪方案以稳定匹配；3）设计变分查询去噪机制缓解传统去噪中的梯度消失问题。

Result: 在不使用任何外部数据的情况下，在KITTI 3D目标检测基准上取得SOTA性能。

Conclusion: Mono3DV通过联合优化3D匹配与稳定化训练机制，有效提升了单目3D检测精度与鲁棒性，验证了显式建模3D几何对Transformer检测器的重要性。

Abstract: While DETR-like architectures have demonstrated significant potential for monocular 3D object detection, they are often hindered by a critical limitation: the exclusion of 3D attributes from the bipartite matching process. This exclusion arises from the inherent ill-posed nature of 3D estimation from monocular image, which introduces instability during training. Consequently, high-quality 3D predictions can be erroneously suppressed by 2D-only matching criteria, leading to suboptimal results. To address this, we propose Mono3DV, a novel Transformer-based framework. Our approach introduces three key innovations. First, we develop a 3D-Aware Bipartite Matching strategy that directly incorporates 3D geometric information into the matching cost, resolving the misalignment caused by purely 2D criteria. Second, it is important to stabilize the Bipartite Matching to resolve the instability occurring when integrating 3D attributes. Therefore, we propose 3D-DeNoising scheme in the training phase. Finally, recognizing the gradient vanishing issue associated with conventional denoising techniques, we propose a novel Variational Query DeNoising mechanism to overcome this limitation, which significantly enhances model performance. Without leveraging any external data, our method achieves state-of-the-art results on the KITTI 3D object detection benchmark.

</details>


### [30] [Deepfake Detection with Multi-Artifact Subspace Fine-Tuning and Selective Layer Masking](https://arxiv.org/abs/2601.01041)
*Xiang Zhang,Wenliang Weng,Daoyong Fu,Ziqiang Li,Zhangjie Fu*

Main category: cs.CV

TL;DR: 本文提出MASM方法，通过多伪造子空间与选择性层掩码，解耦语义与伪造特征表示，提升跨数据集泛化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法在跨数据集和真实复杂场景中表现不佳，主因是不同伪造方法引入的伪影分布差异大，且预训练模型在适配新伪影时易破坏原有语义结构。

Method: 提出MASM方法：利用奇异值分解将预训练权重分解为稳定语义主子空间和多个可学习伪造子空间；引入选择性层掩码策略，根据各伪造子空间学习状态自适应调控对应网络层更新；施加正交性约束和谱一致性约束，使多个伪造子空间学习互补、多样且谱结构稳定的伪影表示。

Result: MASM在跨数据集场景下展现出更强的泛化鲁棒性，能有效建模多样化伪造伪影并保持语义稳定性。

Conclusion: MASM通过显式解耦语义与伪造表示、约束伪造子空间拟合强度及自适应更新机制，显著提升了深度伪造检测模型在复杂真实场景中的泛化能力与鲁棒性。

Abstract: Deepfake detection still faces significant challenges in cross-dataset and real-world complex scenarios. The root cause lies in the high diversity of artifact distributions introduced by different forgery methods, while pretrained models tend to disrupt their original general semantic structures when adapting to new artifacts. Existing approaches usually rely on indiscriminate global parameter updates or introduce additional supervision signals, making it difficult to effectively model diverse forgery artifacts while preserving semantic stability. To address these issues, this paper proposes a deepfake detection method based on Multi-Artifact Subspaces and selective layer masks (MASM), which explicitly decouples semantic representations from artifact representations and constrains the fitting strength of artifact subspaces, thereby improving generalization robustness in cross-dataset scenarios. Specifically, MASM applies singular value decomposition to model weights, partitioning pretrained weights into a stable semantic principal subspace and multiple learnable artifact subspaces. This design enables decoupled modeling of different forgery artifact patterns while preserving the general semantic subspace. On this basis, a selective layer mask strategy is introduced to adaptively regulate the update behavior of corresponding network layers according to the learning state of each artifact subspace, suppressing overfitting to any single forgery characteristic. Furthermore, orthogonality constraints and spectral consistency constraints are imposed to jointly regularize multiple artifact subspaces, guiding them to learn complementary and diverse artifact representations while maintaining a stable overall spectral structure.

</details>


### [31] [Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data](https://arxiv.org/abs/2601.01044)
*Jin Wang,Angelo De Castro,Yuxi Zhang,Lucas Basolli Borsatto,Yuechen Guo,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

TL;DR: 本研究评估了迁移学习在不同规模奶牛场间体重预测任务中的有效性，并比较了深度图像与点云数据两种模态的性能。结果表明，迁移学习显著提升了小规模农场上的预测精度，且两种数据模态表现相当。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖ImageNet或COCO预训练权重，其在畜牧场景（尤其是跨农场）的迁移效果和最优微调策略尚不明确；同时，深度图像与点云在奶牛体重预测中的直接对比仍缺乏。

Method: 采集大型、中型、小型奶牛场共1474头奶牛的顶视深度图像和点云数据；采用ConvNeXt、MobileViT（处理深度图像）与PointNet、DGCNN（处理点云）四种模型；设计三种实验方案评估跨农场迁移学习效果及模态对比。

Result: 迁移学习在小农场上显著提升体重预测性能，效果优于单源学习，媲美甚至超过联合学习；深度图像与点云模型之间无一致性能差异。

Conclusion: 迁移学习适用于数据受限的小型农场场景，仅需预训练权重而无需共享原始数据，可缓解隐私、政策与物流限制问题；深度图像与点云在该任务中具有等效性。

Abstract: Computer vision provides automated, non-invasive, and scalable tools for monitoring dairy cattle, thereby supporting management, health assessment, and phenotypic data collection. Although transfer learning is commonly used for predicting body weight from images, its effectiveness and optimal fine-tuning strategies remain poorly understood in livestock applications, particularly beyond the use of pretrained ImageNet or COCO weights. In addition, while both depth images and three-dimensional point-cloud data have been explored for body weight prediction, direct comparisons of these two modalities in dairy cattle are limited. Therefore, the objectives of this study were to 1) evaluate whether transfer learning from a large farm enhances body weight prediction on a small farm with limited data, and 2) compare the predictive performance of depth-image- and point-cloud-based approaches under three experimental designs. Top-view depth images and point-cloud data were collected from 1,201, 215, and 58 cows at large, medium, and small dairy farms, respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth images, and PointNet and DGCNN for point clouds. Transfer learning markedly improved body weight prediction on the small farm across all four models, outperforming single-source learning and achieving gains comparable to or greater than joint learning. These results indicate that pretrained representations generalize well across farms with differing imaging conditions and dairy cattle populations. No consistent performance difference was observed between depth-image- and point-cloud-based models. Overall, these findings suggest that transfer learning is well suited for small farm prediction scenarios where cross-farm data sharing is limited by privacy, logistical, or policy constraints, as it requires access only to pretrained model weights rather than raw data.

</details>


### [32] [Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance](https://arxiv.org/abs/2601.01056)
*Ifeanyi Ezuma,Ugochukwu Ugwu*

Main category: cs.CV

TL;DR: 本研究评估了机器学习和深度学习模型在LC25000数据集上的组织病理图像分类性能，发现基于微调InceptionResNet-v2提取的深度特征训练的模型（尤其是神经网络）表现最优，准确率达99.84%，AUC达99.99%，且在噪声环境下更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 数字病理时代下，自动化图像分析在临床实践中变得至关重要，亟需评估不同模型在组织病理图像分类任务中的性能与鲁棒性。

Method: 使用微调的InceptionResNet-v2网络进行端到端分类和特征提取；将提取的深度特征输入多种机器学习模型（如神经网络、GBM、KNN等）进行分类；对比其与直接使用预训练网络的性能，并在不同信噪比（SNR）条件下评估模型鲁棒性；还尝试融合HOG与深度特征。

Result: 微调InceptionResNet-v2单独分类达96.01%准确率、96.8%平均AUC；基于其深度特征训练的神经网络模型达99.84%准确率和99.99% AUC；GBM和KNN在噪声下表现出更强鲁棒性；HOG+深度特征融合提升性能，但在噪声环境中增益减弱。

Conclusion: 利用微调深度网络提取的高层特征训练传统或轻量级分类器，可显著超越端到端深度模型，在精度、AUC及噪声鲁棒性方面均具优势，为临床部署提供了更可靠、高效的方案。

Abstract: The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\% and an average AUC of 96.8\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\% and accuracy of 99.84\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.

</details>


### [33] [Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers](https://arxiv.org/abs/2601.01064)
*Jianan Li,Wangcai Zhao,Tingfa Xu*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级分离光谱Transformer（LSST）架构，用于高效重建压缩感知下的高光谱图像，通过分离建模光谱与空间特征，并引入新型焦点光谱损失函数，实现了高性能与低计算开销的统一。


<details>
  <summary>Details</summary>
Motivation: 高效地从压缩感知测量中重建高光谱图像面临巨大挑战，需兼顾光谱与空间特性并提升计算效率。

Method: 提出LSST架构，包含Separate Spectral Transformer Blocks（SSTB）建模光谱关系（含分组光谱自注意力和光谱重排操作）和Lightweight Spatial Convolution Blocks（LSCB）处理空间信息（采用深度可分离卷积与有序设计），并引入动态加权的Focal Spectrum Loss。

Result: LSST在重建性能上优于现有方法，同时显著减少FLOPs和参数量，验证了其高效性与有效性。

Conclusion: LSST是一种兼顾精度与效率的高光谱图像重建新范式，为资源受限场景下的HSI应用提供了可行方案。

Abstract: Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.

</details>


### [34] [A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields](https://arxiv.org/abs/2601.01084)
*Adari Rama Sukanya,Puvvula Roopesh Naga Sri Sai,Kota Moses,Rimalapudi Sarvendranath*

Main category: cs.CV

TL;DR: 本文介绍了一个在印度安得拉邦维杰亚瓦达地区水稻田上采集的大规模无人机RGB和多光谱图像数据集，覆盖从育苗到收获的全生育期，具有高分辨率（1 cm/pixel）和丰富元数据，可用于病害分析、精准喷洒和产量估计等研究。


<details>
  <summary>Details</summary>
Motivation: 缺乏覆盖印度水稻全生育期、高分辨率且具丰富元数据的无人机遥感图像数据集，限制了农业AI模型在本地化场景中的开发与验证。

Method: 采用2000万像素RGB相机和500万像素四波段（红、绿、红边、近红外）多光谱相机，在5英亩稻田上按标准化操作流程（SOP）采集图像；同步记录GPS坐标、飞行高度及环境参数；使用Pix4D Fields生成正射影像和植被指数图（如NDVI、NDRE）进行数据验证。

Result: 构建包含42,430张原始图像（415 GB）、1 cm/pixel地面采样距离、完整生长阶段覆盖及结构化元数据的高质量开源数据集，并发布于IEEE DataPort（含DOI）。

Conclusion: 该数据集填补了印度水稻多光谱遥感数据的空白，为农业AI应用（如病害识别、变量施药、产量预测）提供了可靠基准资源。

Abstract: We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.

</details>


### [35] [Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models](https://arxiv.org/abs/2601.01085)
*Jiayi Xu,Zhang Zhang,Yuanrui Zhang,Ruitao Chen,Yixian Xu,Tianyu He,Di He*

Main category: cs.CV

TL;DR: 本文提出了Luminark，一种无需训练且具有概率认证的水印方法，用于通用视觉生成模型。该方法基于块级亮度统计定义水印，通过预设二进制模式与阈值实现认证检测，并利用‘水印引导’机制实现跨模型无缝注入，兼顾高检测精度、鲁棒性与图像质量。


<details>
  <summary>Details</summary>
Motivation: 为视觉生成模型提供一种无需训练、具备可证明检测可靠性（即低误报率）且适用于多种架构的通用水印方案，以应对生成内容溯源与版权保护需求。

Method: 提出基于补丁级亮度统计的新水印定义；使用预设二进制模式与对应亮度阈值进行检测；通过统计分析控制误报率；引入‘水印引导（watermark guidance）’作为即插即用机制，利用生成过程中的指导技术实现无损水印嵌入。

Result: 在涵盖扩散、自回归和混合架构的9个SOTA视觉生成模型上验证有效；始终保持高检测准确率、对常见图像变换（如压缩、裁剪、滤波）强鲁棒性，且不损害生成图像视觉质量。

Conclusion: Luminark是一种通用、高效、认证可靠的训练-free水印方法，显著拓展了生成图像水印在多模型场景下的实用性与可信性。

Abstract: In this paper, we introduce \emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.

</details>


### [36] [Real-Time LiDAR Point Cloud Densification for Low-Latency Spatial Data Transmission](https://arxiv.org/abs/2601.01210)
*Kazuhiko Murasaki,Shunsuke Konagai,Masakatsu Aoki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 本文提出了一种高速LiDAR点云稠密化方法，结合多LiDAR输入与高分辨率彩色图像，采用基于CNN的联合双边滤波策略，实现实时（30 fps）全高清稠密深度图生成，速度比现有训练式方法快15倍以上，且几何准确、无多视角不一致和鬼影伪影。


<details>
  <summary>Details</summary>
Motivation: 实现沉浸式远程呈现所需的低延迟空间传输系统面临两大难题：动态3D场景的密集采集与实时处理；LiDAR虽可实时获取3D数据，但点云稀疏，需高效低延迟的深度补全。

Method: 融合多LiDAR点云与高分辨率RGB图像，设计基于卷积神经网络的联合双边滤波架构进行深度图稠密化。

Result: 在全高清分辨率下实现30 fps实时稠密深度图生成，速度超近期训练式深度补全方法15倍以上；生成的稠密点云几何准确，无多视角不一致和鬼影伪影。

Conclusion: 所提方法有效平衡了低延迟、高精度与实时性，为沉浸式远程呈现等应用提供了可行的稠密3D感知方案。

Abstract: To realize low-latency spatial transmission system for immersive telepresence, there are two major problems: capturing dynamic 3D scene densely and processing them in real time. LiDAR sensors capture 3D in real time, but produce sparce point clouds. Therefore, this paper presents a high-speed LiDAR point cloud densification method to generate dense 3D scene with minimal latency, addressing the need for on-the-fly depth completion while maintaining real-time performance. Our approach combines multiple LiDAR inputs with high-resolution color images and applies a joint bilateral filtering strategy implemented through a convolutional neural network architecture. Experiments demonstrate that the proposed method produces dense depth maps at full HD resolution in real time (30 fps), which is over 15x faster than a recent training-based depth completion approach. The resulting dense point clouds exhibit accurate geometry without multiview inconsistencies or ghosting artifacts.

</details>


### [37] [600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script](https://arxiv.org/abs/2601.01088)
*Haq Nawaz Malik*

Main category: cs.CV

TL;DR: This paper introduces the 600K-KS-OCR Dataset, a large synthetic dataset of ~602,000 Kashmiri-script word images for OCR model training and evaluation, designed to address the scarcity of resources for this endangered language.


<details>
  <summary>Details</summary>
Motivation: To fill a critical resource gap for Kashmiri — an endangered Dardic language with ~7 million speakers and a modified Perso-Arabic script — by providing a large-scale, high-quality synthetic OCR dataset.

Method: Synthetic generation of ~602,000 word-level segmented images (256x64 px) using three traditional Kashmiri typefaces; inclusion of realistic data augmentations (e.g., document degradation) and diverse background textures; ground-truth transcriptions in multiple formats (CRNN, TrOCR, general ML).

Result: A publicly released, CC-BY-4.0 licensed dataset of ~10.6 GB across ten archives, compatible with mainstream OCR models and pipelines, enabling robust low-resource language OCR research.

Conclusion: The 600K-KS-OCR Dataset effectively bridges the data scarcity challenge for Kashmiri-script OCR and supports reproducible, scalable development of OCR systems for endangered languages.

Abstract: This technical report presents the 600K-KS-OCR Dataset, a large-scale synthetic corpus comprising approximately 602,000 word-level segmented images designed for training and evaluating optical character recognition systems targeting Kashmiri script. The dataset addresses a critical resource gap for Kashmiri, an endangered Dardic language utilizing a modified Perso-Arabic writing system spoken by approximately seven million people. Each image is rendered at 256x64 pixels with corresponding ground-truth transcriptions provided in multiple formats compatible with CRNN, TrOCR, and generalpurpose machine learning pipelines. The generation methodology incorporates three traditional Kashmiri typefaces, comprehensive data augmentation simulating real-world document degradation, and diverse background textures to enhance model robustness. The dataset is distributed across ten partitioned archives totaling approximately 10.6 GB and is released under the CC-BY-4.0 license to facilitate research in low-resource language optical character recognition.

</details>


### [38] [NarrativeTrack: Evaluating Video Language Models Beyond the Frame](https://arxiv.org/abs/2601.01095)
*Hyeonjeong Ha,Jinjin Ge,Bo Feng,Kaixin Ma,Gargi Chakraborty*

Main category: cs.CV

TL;DR: 本文提出了NarrativeTrack基准，用于评估多模态大语言模型（MLLMs）在视频叙事理解中的实体级时序推理能力，并通过Compositional Reasoning Progression（CRP）框架揭示了当前模型在感知接地与时间连贯性之间的根本权衡。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在视频叙事理解方面研究不足，尤其缺乏对‘谁在何时何地做了什么’的细粒度、实体中心的时序推理能力评估；已有基准局限于短片段或粗粒度场景语义，无法系统衡量动态视觉与时间上下文中的实体连续性。

Method: 提出NarrativeTrack基准及配套的Compositional Reasoning Progression（CRP）评估框架，从实体存在性、实体变化性、实体模糊性三个维度渐进提升叙事复杂度；构建全自动实体中心流水线，实现可扩展的时序对齐实体表征提取。

Result: 评测发现：开源通用MLLMs感知接地强但时间连贯性弱；视频专用MLLMs能捕捉时间上下文却易幻觉实体上下文；模型普遍难以稳健跟踪跨视觉转换与时间动态的实体，常在上下文切换时错误识别身份。

Conclusion: 叙事理解需感知接地与时间推理的深度融合；NarrativeTrack为诊断和推动MLLMs的时序叙事理解提供了首个系统性框架。

Abstract: Multimodal large language models (MLLMs) have achieved impressive progress in vision-language reasoning, yet their ability to understand temporally unfolding narratives in videos remains underexplored. True narrative understanding requires grounding who is doing what, when, and where, maintaining coherent entity representations across dynamic visual and temporal contexts. We introduce NarrativeTrack, the first benchmark to evaluate narrative understanding in MLLMs through fine-grained entity-centric reasoning. Unlike existing benchmarks limited to short clips or coarse scene-level semantics, we decompose videos into constituent entities and examine their continuity via a Compositional Reasoning Progression (CRP), a structured evaluation framework that progressively increases narrative complexity across three dimensions: entity existence, entity changes, and entity ambiguity. CRP challenges models to advance from temporal persistence to contextual evolution and fine-grained perceptual reasoning. A fully automated entity-centric pipeline enables scalable extraction of temporally grounded entity representations, providing the foundation for CRP. Evaluations of state-of-the-art MLLMs reveal that models fail to robustly track entities across visual transitions and temporal dynamics, often hallucinating identity under context shifts. Open-source general-purpose MLLMs exhibit strong perceptual grounding but weak temporal coherence, while video-specific MLLMs capture temporal context yet hallucinate entity's contexts. These findings uncover a fundamental trade-off between perceptual grounding and temporal reasoning, indicating that narrative understanding emerges only from their integration. NarrativeTrack provides the first systematic framework to diagnose and advance temporally grounded narrative comprehension in MLLMs.

</details>


### [39] [DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528)
*Yang Zhou,Hao Shao,Letian Wang,Zhuofan Zong,Hongsheng Li,Steven L. Waslander*

Main category: cs.CV

TL;DR: 本文提出了DrivingGen，首个面向生成式驾驶世界模型的综合基准，旨在解决现有评估方法在安全性、轨迹合理性、时序一致性及可控性等方面的不足，并通过14个SOTA模型的评测揭示了视觉质量与物理合理性的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在自动驾驶领域的评估缺乏严谨基准：通用视频指标忽略安全关键因素，轨迹合理性未被量化，时序与智能体层面一致性被忽视，且缺乏对自车条件控制能力的评估；同时数据集覆盖场景多样性不足。

Method: 构建DrivingGen基准，包含从驾驶数据集和互联网视频中精心筛选的多样化评估数据集（涵盖不同天气、时段、地域和复杂操作），并设计多维新指标体系，联合评估视觉真实性、轨迹合理性、时序连贯性和可控性。

Result: 在14个SOTA模型上的评测表明：通用视频生成模型视觉质量高但违反物理规律；专用驾驶模型运动建模更合理但视觉质量较差。

Conclusion: DrivingGen提供了统一评估框架，推动生成式驾驶世界模型向可靠、可控、可部署方向发展，支撑可扩展仿真、规划与数据驱动决策。

Abstract: Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.

</details>


### [40] [Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks](https://arxiv.org/abs/2601.01099)
*Mahmudul Hasan,Mabsur Fatin Bin Hossain*

Main category: cs.CV

TL;DR: 本文比较了自定义CNN架构与广泛使用的预训练和迁移学习CNN模型在五个真实图像数据集上的性能，分析了网络深度、残差连接和特征提取策略对分类和定位性能的影响，并展示了其在非法三轮车检测中的适应性。


<details>
  <summary>Details</summary>
Motivation: 为不同任务复杂度和资源约束下选择合适的CNN网络设计提供实践指导。

Method: 对比自定义CNN架构与预训练及迁移学习CNN模型，在五个涵盖二分类、细粒度多类识别和目标检测的真实图像数据集上进行实验，并分析网络深度、残差连接和特征提取策略的影响。

Result: 更深的CNN架构在细粒度多类数据集上显著提升性能，而轻量级预训练和迁移学习模型在简单二分类任务中仍非常有效；所提架构可扩展至目标检测任务，并在真实交通场景中成功识别非法三轮车。

Conclusion: CNN架构选择应根据任务复杂度和资源限制进行权衡，深度架构适合复杂任务，轻量模型适合简单任务，且自定义架构具备良好可扩展性。

Abstract: This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.

</details>


### [41] [Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems](https://arxiv.org/abs/2601.01696)
*Yian Liu,Xiong Wang,Ping Xu,Lei Zhu,Ming Yan,Linyun Xue*

Main category: cs.CV

TL;DR: 本文提出了一种协方差分布优化（CDO）模块，用于在资源受限的嵌入式系统中实现高效、实时的车道线检测，通过校准特征分布提升精度，且不增加计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的车道检测方法缺乏适用于低功耗嵌入式环境的通用优化技术，而RGB图像中车道信号微弱稀疏，且嵌入式平台算力与功耗受限。

Method: 提出协方差分布优化（CDO）模块，将车道特征分布对齐真实标签分布，在不改变模型结构和增加计算复杂度的前提下提升检测精度，并支持即插即用与持续训练。

Result: 在CULane、TuSimple和LLAMAS三个主流数据集上，CDO在六种模型（含两类实时模型和四类SOTA模型）上带来0.01%–1.5%的精度提升。

Conclusion: CDO模块具有轻量、易集成、无需结构修改、兼容现有参数与训练流程等优势，显著提升了嵌入式系统中车道检测的精度、能效与部署灵活性。

Abstract: Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.

</details>


### [42] [Histogram Assisted Quality Aware Generative Model for Resolution Invariant NIR Image Colorization](https://arxiv.org/abs/2601.01103)
*Abhinav Attri,Rajeev Ranjan Dwivedi,Samiran Das,Vinod Kumar Kurmi*

Main category: cs.CV

TL;DR: HAQAGen是一种统一的生成模型，用于分辨率无关的近红外（NIR）到RGB彩色化，通过结合直方图匹配、感知质量度量、特征相似性损失、局部色调-饱和度先验及纹理感知监督，在保持色彩真实性和结构保真度之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 解决NIR-to-RGB彩色化中全局色彩统计与局部色度一致性难以兼顾、高分辨率下纹理保真度下降及泛化能力不足的问题。

Method: 提出HAQAGen模型：（i）组合损失项（可微直方图匹配+感知质量度量+特征相似性）；（ii）基于SPADE注入局部色调-饱和度先验；（iii）在Mamba骨干网络中引入纹理感知监督；并设计自适应分辨率推理引擎。

Result: 在FANVID、OMSIV、VCIP2020、RGB2NIR等多个数据集上显著优于现有方法，图像纹理更锐利、色彩更自然，感知指标提升明显。

Conclusion: HAQAGen是一种可扩展、高效且鲁棒的NIR-to-RGB彩色化方案，适用于多种成像场景。

Abstract: We present HAQAGen, a unified generative model for resolution-invariant NIR-to-RGB colorization that balances chromatic realism with structural fidelity. The proposed model introduces (i) a combined loss term aligning the global color statistics through differentiable histogram matching, perceptual image quality measure, and feature based similarity to preserve texture information, (ii) local hue-saturation priors injected via Spatially Adaptive Denormalization (SPADE) to stabilize chromatic reconstruction, and (iii) texture-aware supervision within a Mamba backbone to preserve fine details. We introduce an adaptive-resolution inference engine that further enables high-resolution translation without sacrificing quality. Our proposed NIR-to-RGB translation model simultaneously enforces global color statistics and local chromatic consistency, while scaling to native resolutions without compromising texture fidelity or generalization. Extensive evaluations on FANVID, OMSIV, VCIP2020, and RGB2NIR using different evaluation metrics demonstrate consistent improvements over state-of-the-art baseline methods. HAQAGen produces images with sharper textures, natural colors, attaining significant gains as per perceptual metrics. These results position HAQAGen as a scalable and effective solution for NIR-to-RGB translation across diverse imaging scenarios. Project Page: https://rajeev-dw9.github.io/HAQAGen/

</details>


### [43] [VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis](https://arxiv.org/abs/2601.01989)
*Aly R. Elkammar,Karim M. Gamaleldin,Catherine M. Elias*

Main category: cs.CV

TL;DR: 本文提出了一种基于Transformer/Video Vision Transformer的多模态行人意图预测算法，在JAAD数据集上达到并超越了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 提升L3到L4级自动驾驶中行人意图预测能力，以增强道路安全性。

Method: 采用不同规模的Transformer/Video Vision Transformer架构，融合多种数据模态进行建模。

Result: 在JAAD数据集上Accuracy、AUC和F1-score等指标均超越现有最优方法（SOTA），并通过大量消融实验验证了不同模型设计的有效性。

Conclusion: 所提出的多模态Transformer方法在行人意图预测任务中具有优越性能和可解释的设计优势。

Abstract: Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.

</details>


### [44] [Cross-Layer Attentive Feature Upsampling for Low-latency Semantic Segmentation](https://arxiv.org/abs/2601.01167)
*Tianheng Cheng,Xinggang Wang,Junchao Liao,Wenyu Liu*

Main category: cs.CV

TL;DR: 本文提出了一种引导式注意力插值（GAI）方法，用于在语义分割中高效生成富含语义的高分辨率特征图，兼顾精度与低延迟推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于坐标的低分辨率特征插值方法（如双线性插值）生成的高分辨率特征粗糙，存在特征错位和上下文信息不足问题；同时，向高分辨率特征注入语义信息计算开销大，难以满足低延迟推理需求。

Method: 提出引导式注意力插值（GAI），自适应地利用多尺度特征学习像素间的空间与语义关系，并据此插值得到兼具细节与丰富语义的高分辨率特征；GAI可即插即用地集成到任意CNN架构中。

Result: 基于GAI构建的语义分割网络GAIN在Cityscapes上达到78.8 mIoU@22.3 FPS，在CamVid上达80.6 mIoU@64.5 FPS（NVIDIA 1080Ti），创下低延迟语义分割新SOTA。

Conclusion: GAI有效解决了高分辨率特征插值中的对齐与语义增强难题，在保持实时推理速度的同时显著提升分割精度，是一种高效且通用的插值模块。

Abstract: Semantic segmentation is a fundamental problem in computer vision and it requires high-resolution feature maps for dense prediction. Current coordinate-guided low-resolution feature interpolation methods, e.g., bilinear interpolation, produce coarse high-resolution features which suffer from feature misalignment and insufficient context information. Moreover, enriching semantics to high-resolution features requires a high computation burden, so that it is challenging to meet the requirement of lowlatency inference. We propose a novel Guided Attentive Interpolation (GAI) method to adaptively interpolate fine-grained high-resolution features with semantic features to tackle these issues. Guided Attentive Interpolation determines both spatial and semantic relations of pixels from features of different resolutions and then leverages these relations to interpolate high-resolution features with rich semantics. GAI can be integrated with any deep convolutional network for efficient semantic segmentation. In experiments, the GAI-based semantic segmentation networks, i.e., GAIN, can achieve78.8 mIoU with 22.3 FPS on Cityscapes and 80.6 mIoU with 64.5 on CamVid using an NVIDIA 1080Ti GPU, which are the new state-of-the-art results of low-latency semantic segmentation. Code and models are available at: https://github.com/hustvl/simpleseg.

</details>


### [45] [CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops](https://arxiv.org/abs/2601.01176)
*Andrés Bell-Navas,Jesús Garicano-Mena,Antonella Ausiello,Soledad Le Clainche,María Villalba-Orero,Enrique Lara-Pezzi*

Main category: cs.CV

TL;DR: 本文提出了一种名为CardioMOD-Net的统一AI框架，利用小样本小鼠超声心动图视频，实现HFpEF的多类别诊断与HFpEF发病时间的连续预测。


<details>
  <summary>Details</summary>
Motivation: HFpEF病因多样、亚临床期长，现有AI模型仅支持二分类诊断，缺乏共病特异性表型分型和失代偿进展的时间预测能力。

Method: 采用四组小鼠（对照、高血糖、肥胖、系统性高血压）的二维胸骨旁长轴超声视频，通过高阶动态模态分解（HODMD）提取时序特征，并联合Vision Transformer分别构建分类器（多类诊断）和回归模块（HFpEF发病年龄预测）。

Result: 多类诊断总体准确率65%，各组均超50%；预后模块预测HFpEF发病时间的RMSE为21.72周，肥胖与高血压组最准；预测分布与真实分布高度一致。

Conclusion: CardioMOD-Net在小样本条件下，仅凭单个超声心动图序列即可同步完成多类表型分型与连续时间预测，为HFpEF临床前研究提供了诊断-预后一体化建模新范式。

Abstract: Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models.
  Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset.
  Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups.
  Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.

</details>


### [46] [GenCAMO: Scene-Graph Contextual Decoupling for Environment-aware and Mask-free Camouflage Image-Dense Annotation Generation](https://arxiv.org/abs/2601.01181)
*Chenglizhao Chen,Shaojiang Yuan,Xiaoxue Lu,Mengke Song,Jia Song,Zhenyu Wu,Wenfeng Song,Shuai Li*

Main category: cs.CV

TL;DR: 本文提出GenCAMO-DB数据集和GenCAMO生成框架，利用生成模型合成高质量、多模态伪装图像及密集标注，以缓解真实伪装数据稀缺问题，并显著提升复杂伪装场景下的密集预测性能。


<details>
  <summary>Details</summary>
Motivation: 高质量、大规模且带密集标注的伪装数据集稀缺，因采集与标注成本高昂，制约了 conceal dense prediction（CDP）任务的发展。

Method: 提出GenCAMO-DB多模态伪装数据集（含深度图、场景图、属性描述、文本提示）；设计环境感知、无掩码的生成框架GenCAMO，用于合成高保真伪装图像及密集标注；在多模态任务上验证其有效性。

Result: GenCAMO生成的合成数据显著提升了RGB-D伪装目标检测与开放词汇伪装分割等CDP任务的性能。

Conclusion: 基于生成模型构建高质量合成伪装数据是解决数据稀缺问题的有效途径，GenCAMO及其配套数据集为复杂伪装场景的理解与推理提供了新范式。

Abstract: Conceal dense prediction (CDP), especially RGB-D camouflage object detection and open-vocabulary camouflage object segmentation, plays a crucial role in advancing the understanding and reasoning of complex camouflage scenes. However, high-quality and large-scale camouflage datasets with dense annotation remain scarce due to expensive data collection and labeling costs. To address this challenge, we explore leveraging generative models to synthesize realistic camouflage image-dense data for training CDP models with fine-grained representations, prior knowledge, and auxiliary reasoning. Concretely, our contributions are threefold: (i) we introduce GenCAMO-DB, a large-scale camouflage dataset with multi-modal annotations, including depth maps, scene graphs, attribute descriptions, and text prompts; (ii) we present GenCAMO, an environment-aware and mask-free generative framework that produces high-fidelity camouflage image-dense annotations; (iii) extensive experiments across multiple modalities demonstrate that GenCAMO significantly improves dense prediction performance on complex camouflage scenes by providing high-quality synthetic data. The code and datasets will be released after paper acceptance.

</details>


### [47] [Crowded Video Individual Counting Informed by Social Grouping and Spatial-Temporal Displacement Priors](https://arxiv.org/abs/2601.01192)
*Hao Lu,Xuhui Zhu,Wenjing Zhang,Yanan Li,Xiang Bai*

Main category: cs.CV

TL;DR: 本文提出了视频个体计数（VIC）任务的新方法OMAN++，通过引入社会分组先验和时空位移先验，将传统一对一匹配扩展为一对多匹配，并设计位移先验注入器，显著提升拥挤场景下的计数性能，在自建WuhanMetroCrowd数据集上误差降低38.12%。


<details>
  <summary>Details</summary>
Motivation: 现有VIC方法在地铁等高密度拥挤场景下表现不佳，缺乏适配复杂动态人流的基准数据集与建模先验。

Method: 构建首个面向拥挤动态人流的VIC数据集WuhanMetroCrowd；提出社会 grouping 先验与时空位移先验；设计隐式上下文生成器、一对多（O2M）匹配器及位移先验注入器，构成OMAN++模型。

Result: OMAN++在SenseCrowd、CroHD、MovingDroneCrowd基准上超越SOTA；在WuhanMetroCrowd上相对误差降低38.12%。

Conclusion: VIC本质是时空对应问题，引入符合人类行为与物理规律的先验可显著提升拥挤场景下的个体追踪与计数鲁棒性；OMAN++为VIC提供了强基线与新范式。

Abstract: Video Individual Counting (VIC) is a recently introduced task aiming to estimate pedestrian flux from a video. It extends Video Crowd Counting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that learns to count pedestrians across frames, VIC must identify co-existent pedestrians between frames, which turns out to be a correspondence problem. Existing VIC approaches, however, can underperform in congested scenes such as metro commuting. To address this, we build WuhanMetroCrowd, one of the first VIC datasets that characterize crowded, dynamic pedestrian flows. It features sparse-to-dense density levels, short-to-long video clips, slow-to-fast flow variations, front-to-back appearance changes, and light-to-heavy occlusions. To better adapt VIC approaches to crowds, we rethink the nature of VIC and recognize two informative priors: i) the social grouping prior that indicates pedestrians tend to gather in groups and ii) the spatial-temporal displacement prior that informs an individual cannot teleport physically. The former inspires us to relax the standard one-to-one (O2O) matching used by VIC to one-to-many (O2M) matching, implemented by an implicit context generator and a O2M matcher; the latter facilitates the design of a displacement prior injector, which strengthens not only O2M matching but also feature extraction and model training. These designs jointly form a novel and strong VIC baseline OMAN++. Extensive experiments show that OMAN++ not only outperforms state-of-the-art VIC baselines on the standard SenseCrowd, CroHD, and MovingDroneCrowd benchmarks, but also indicates a clear advantage in crowded scenes, with a 38.12% error reduction on our WuhanMetroCrowd dataset. Code, data, and pretrained models are available at https://github.com/tiny-smart/OMAN.

</details>


### [48] [MS-ISSM: Objective Quality Assessment of Point Clouds Using Multi-scale Implicit Structural Similarity](https://arxiv.org/abs/2601.01200)
*Zhang Chen,Shuai Wan,Yuezhe Zhang,Siyu Ren,Fuzheng Yang,Junhui Hou*

Main category: cs.CV

TL;DR: 本文提出了一种多尺度隐式结构相似性度量（MS-ISSM）方法，用于点云质量评估，通过RBF连续表征局部特征并比较隐式函数系数来避免不规则点云匹配误差；同时设计了ResGrouped-MLP网络，结合分组编码、残差块和通道注意力机制，有效融合多尺度特征以预测感知质量得分。


<details>
  <summary>Details</summary>
Motivation: 点云的非结构化和不规则性给客观质量评估（PCQA）带来挑战，尤其是难以建立准确的感知特征对应关系。

Method: 提出多尺度隐式结构相似性度量（MS-ISSM），利用径向基函数（RBF）连续表征局部特征，将失真度量转化为隐式函数系数比较；并设计ResGrouped-MLP质量评估网络，采用分组编码、残差块与通道注意力机制的层次化架构。

Result: 在多个基准数据集上实验表明，MS-ISSM在可靠性与泛化能力上均优于当前最先进指标。

Conclusion: MS-ISSM通过避免点对点匹配误差并融合多尺度语义特征，显著提升了点云质量评估的准确性与鲁棒性。

Abstract: The unstructured and irregular nature of point clouds poses a significant challenge for objective quality assessment (PCQA), particularly in establishing accurate perceptual feature correspondence. To tackle this, we propose the Multi-scale Implicit Structural Similarity Measurement (MS-ISSM). Unlike traditional point-to-point matching, MS-ISSM utilizes Radial Basis Functions (RBF) to represent local features continuously, transforming distortion measurement into a comparison of implicit function coefficients. This approach effectively circumvents matching errors inherent in irregular data. Additionally, we propose a ResGrouped-MLP quality assessment network, which robustly maps multi-scale feature differences to perceptual scores. The network architecture departs from traditional flat MLPs by adopting a grouped encoding strategy integrated with Residual Blocks and Channel-wise Attention mechanisms. This hierarchical design allows the model to preserve the distinct physical semantics of luma, chroma, and geometry while adaptively focusing on the most salient distortion features across High, Medium, and Low scales. Experimental results on multiple benchmarks demonstrate that MS-ISSM outperforms state-of-the-art metrics in both reliability and generalization. The source code is available at: https://github.com/ZhangChen2022/MS-ISSM.

</details>


### [49] [RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models](https://arxiv.org/abs/2601.01202)
*Jiazhu Dai,Huihui Jiang*

Main category: cs.CV

TL;DR: 本文提出RefSR-Adv，一种仅通过扰动参考图像即可显著降低参考图像超分辨率（RefSR）模型性能的对抗攻击方法，揭示了RefSR系统因过度依赖参考特征而存在的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注针对RefSR的后门攻击，而其在对抗攻击下的脆弱性尚未被充分探索，本文旨在填补这一研究空白。

Method: 提出RefSR-Adv攻击方法，仅对参考图像添加扰动，通过最大化对抗输出与干净输出之间的差异来实现攻击；在多个主流架构（CNN、Transformer、Mamba）和数据集（CUFED5、WR-SR、DRefSR）上验证有效性，并分析输入与参考图像相似性对攻击效果的影响。

Result: RefSR-Adv能在多种模型架构和数据集上引发显著性能下降和严重伪影；实验发现低分辨率输入与参考图像的相似性越高，攻击效果越强，表明模型存在对参考特征的过度依赖。

Conclusion: RefSR系统存在因过度依赖参考图像而导致的安全漏洞，该研究揭示了其鲁棒性问题，呼吁学界重视RefSR模型的安全性与稳健性设计。

Abstract: Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.

</details>


### [50] [XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression](https://arxiv.org/abs/2601.01204)
*Zunhai Su,Weihao Ye,Hansen Feng,Keyu Fan,Jing Zhang,Dahai Yu,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: XStreamVGGT 是一种无需调优的流式 3D 视觉几何建模方法，通过联合剪枝与量化压缩 KV 缓存，在几乎不损失性能的前提下，显著降低内存占用（4.42×）和推理延迟（5.48×）。


<details>
  <summary>Details</summary>
Motivation: StreamVGGT 等基于 Transformer 的流式 3D 重建模型面临 KV 缓存无限增长导致内存和延迟持续上升的问题。

Method: 提出 XStreamVGGT，采用高效 token 重要性识别进行多视角冗余 KV 剪枝，并结合 KV 张量分布特性设计量化策略，实现固定内存预算下的 KV 缓存压缩。

Result: 在保持几乎无损性能的同时，内存减少 4.42 倍，推理加速 5.48 倍。

Conclusion: XStreamVGGT 为流式 3D 视觉任务提供了可扩展、实用且内存高效的解决方案。

Abstract: Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\times$ and accelerating inference by 5.48$\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.

</details>


### [51] [Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation](https://arxiv.org/abs/2601.01213)
*Riccardo Gelato,Carlo Sgaravatti,Jakob Grahn,Giacomo Boracchi,Filippo Maria Bianchi*

Main category: cs.CV

TL;DR: 本文提出一种针对Sentinel-1 SAR图像的 avalanche 分割标注加速方法，基于Segment Anything Model（SAM）进行领域适配，解决域偏移、多通道输入、提示鲁棒性差与训练效率低四大挑战，并集成至标注工具中验证其提速效果。


<details>
  <summary>Details</summary>
Motivation: SAR图像 avalanche 标注依赖专家耗时高，亟需自动化/半自动化标注工具以提升效率。

Method: 在SAM基础上引入适配器缓解域差异；设计多编码器处理SAR多通道输入；采用提示工程增强小目标/低对比度雪崩定位能力；优化训练策略降低编码器训练开销。

Result: 所提方法显著加快SAR图像 avalanche 标注速度，并成功集成到交互式标注工具中。

Conclusion: SAM可经轻量适配有效迁移至SAR遥感 avalanche 分割任务，为专业遥感标注提供了高效可行的新范式。

Abstract: Remote sensing solutions for avalanche segmentation and mapping are key to supporting risk forecasting and mitigation in mountain regions. Synthetic Aperture Radar (SAR) imagery from Sentinel-1 can be effectively used for this task, but training an effective detection model requires gathering a large dataset with high-quality annotations from domain experts, which is prohibitively time-consuming. In this work, we aim to facilitate and accelerate the annotation of SAR images for avalanche mapping. We build on the Segment Anything Model (SAM), a segmentation foundation model trained on natural images, and tailor it to Sentinel-1 SAR data. Adapting SAM to our use-case requires addressing several domain-specific challenges: (i) domain mismatch, since SAM was not trained on satellite/SAR imagery; (ii) input adaptation, because SAR products typically provide more than three channels, while SAM is constrained to RGB images; (iii) robustness to imprecise prompts that can affect target identification and degrade the segmentation quality, an issue exacerbated in small, low-contrast avalanches; and (iv) training efficiency, since standard fine-tuning is computationally demanding for SAM. We tackle these challenges through a combination of adapters to mitigate the domain gap, multiple encoders to handle multi-channel SAR inputs, prompt-engineering strategies to improve avalanche localization accuracy, and a training algorithm that limits the training time of the encoder, which is recognized as the major bottleneck. We integrate the resulting model into an annotation tool and show experimentally that it speeds up the annotation of SAR images.

</details>


### [52] [UniSH: Unifying Scene and Human Reconstruction in a Feed-Forward Pass](https://arxiv.org/abs/2601.01222)
*Mengfei Li,Peng Li,Zheng Zhang,Jiahao Lu,Chengfeng Zhao,Wei Xue,Qifeng Liu,Sida Peng,Wenxiao Zhang,Wenhan Luo,Yuan Liu,Yike Guo*

Main category: cs.CV

TL;DR: UniSH提出了一种统一的前馈框架，用于联合进行度量尺度下的3D场景与人体重建，通过创新的两阶段训练范式和知识蒸馏策略，有效弥合仿真到真实的域差距，并在单次前向推理中同时恢复高质量场景几何、人体点云、相机参数及一致的度量级SMPL人体。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于真实世界大规模标注数据稀缺，过度依赖合成数据，导致仿真到真实域差距大、人体几何质量低、野外视频对齐差。

Method: 提出一种结合强先验（场景重建与HMR）的统一前馈框架；采用鲁棒的知识蒸馏策略，从专家深度模型中提取高频细节以优化人体表面；设计两阶段监督方案：先在合成数据上学习粗略定位，再在无标签野外真实数据上直接优化SMPL网格与人体点云间的几何对应关系。

Result: 在人体中心化场景重建任务上达到SOTA性能，在全局人体运动估计任务上也显著优于基于优化的方法和纯HMR方法。

Conclusion: UniSH成功实现了高保真、度量一致的联合场景-人体重建，验证了利用无标签野外数据提升泛化能力与几何质量的有效性，为真实场景下端到端人体-场景理解提供了新范式。

Abstract: We present UniSH, a unified, feed-forward framework for joint metric-scale 3D scene and human reconstruction. A key challenge in this domain is the scarcity of large-scale, annotated real-world data, forcing a reliance on synthetic datasets. This reliance introduces a significant sim-to-real domain gap, leading to poor generalization, low-fidelity human geometry, and poor alignment on in-the-wild videos. To address this, we propose an innovative training paradigm that effectively leverages unlabeled in-the-wild data. Our framework bridges strong, disparate priors from scene reconstruction and HMR, and is trained with two core components: (1) a robust distillation strategy to refine human surface details by distilling high-frequency details from an expert depth model, and (2) a two-stage supervision scheme, which first learns coarse localization on synthetic data, then fine-tunes on real data by directly optimizing the geometric correspondence between the SMPL mesh and the human point cloud. This approach enables our feed-forward model to jointly recover high-fidelity scene geometry, human point clouds, camera parameters, and coherent, metric-scale SMPL bodies, all in a single forward pass. Extensive experiments demonstrate that our model achieves state-of-the-art performance on human-centric scene reconstruction and delivers highly competitive results on global human motion estimation, comparing favorably against both optimization-based frameworks and HMR-only methods. Project page: https://murphylmf.github.io/UniSH/

</details>


### [53] [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment](https://arxiv.org/abs/2601.01224)
*Bac Nguyen,Yuhta Takida,Naoki Murata,Chieh-Hsin Lai,Toshimitsu Uesaka,Stefano Ermon,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 本文提出CODA方法，通过引入register slots和对比对齐损失来解决Slot Attention在对象中心学习中槽位纠缠和对齐弱的问题，显著提升了对象发现、属性预测和图像生成性能。


<details>
  <summary>Details</summary>
Motivation: Slot Attention在对象中心学习中存在槽位纠缠和图像内容对齐弱的问题。

Method: 提出CODA方法，包括使用register slots吸收残差注意力以减少槽位干扰，以及应用对比对齐损失显式促进槽位与图像的对应关系。

Result: 在MOVi-C/E、VOC和COCO等数据集上，CODA显著提升了对象发现（如COCO上FG-ARI提升6.1%）、属性预测和组合图像生成性能，且计算开销极小。

Conclusion: CODA是一种高效、可扩展的对象中心学习框架，适用于复杂真实场景。

Abstract: Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.

</details>


### [54] [HyDRA: Hybrid Denoising Regularization for Measurement-Only DEQ Training](https://arxiv.org/abs/2601.01228)
*Markus Haltmeier,Lukas Neumann,Nadja Gruber,Johannes Schwab,Gyeongha Hwang*

Main category: cs.CV

TL;DR: 本文提出HyDRA框架，用于在仅有测量数据y的情况下训练深度均衡（DEQ）模型进行图像重建，结合测量一致性与自适应去噪正则化，并引入数据驱动的早停准则，在稀疏视角CT任务中实现了高质量、快速重建。


<details>
  <summary>Details</summary>
Motivation: 图像重建问题（如Ax=y）常因病态性和缺乏大规模监督数据而困难；现有DEQ方法通常依赖成对监督数据(x,y)，但实际中往往仅有测量y可用。

Method: 提出HyDRA（Hybrid Denoising Regularization Adaptation）：一种仅需测量y的DEQ训练框架，融合测量一致性约束与自适应去噪正则化项，并设计数据驱动的早停策略。

Result: 在稀疏视角CT重建任务上，HyDRA取得了具有竞争力的重建质量，并具备快速推理能力。

Conclusion: HyDRA为无监督/测量驱动的深度均衡建模提供了有效新范式，缓解了对成对监督数据的依赖，提升了实际场景中的适用性。

Abstract: Solving image reconstruction problems of the form \(\mathbf{A} \mathbf{x} = \mathbf{y}\) remains challenging due to ill-posedness and the lack of large-scale supervised datasets. Deep Equilibrium (DEQ) models have been used successfully but typically require supervised pairs \((\mathbf{x},\mathbf{y})\). In many practical settings, only measurements \(\mathbf{y}\) are available. We introduce HyDRA (Hybrid Denoising Regularization Adaptation), a measurement-only framework for DEQ training that combines measurement consistency with an adaptive denoising regularization term, together with a data-driven early stopping criterion. Experiments on sparse-view CT demonstrate competitive reconstruction quality and fast inference.

</details>


### [55] [RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection](https://arxiv.org/abs/2601.01240)
*Ziqian Guan,Xieyi Fu,Yuting Wang,Haowen Xiao,Jiarui Zhu,Yingying Zhu,Yongtao Liu,Lin Gu*

Main category: cs.CV

TL;DR: 本文提出RFAssigner，一种新的标签分配策略，通过高斯感受野距离自适应选择正样本，以缓解密集目标检测中因小目标正样本不足导致的尺度不平衡问题，显著提升多尺度检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集目标检测器的标签分配策略常导致小目标正样本数量不足，引发训练过程中的尺度不平衡问题。

Method: RFAssigner首先基于点先验确定初始正样本集，再利用高斯感受野（GRF）距离度量未分配候选位置与真实框的相似性，并据此自适应地从剩余候选位置中选取补充正样本。

Result: 在三个具有不同目标尺度分布的数据集上验证了RFAssigner的有效性和泛化性；FCOS-ResNet-50集成RFAssigner后，在所有尺度目标上均达到SOTA性能，且无需额外模块或启发式设计。

Conclusion: RFAssigner是一种简单、通用且高效的标签分配方法，能显著增强密集检测器的多尺度学习能力。

Abstract: Label assignment is a critical component in training dense object detectors. State-of-the-art methods typically assign each training sample a positive and a negative weight, optimizing the assignment scheme during training. However, these strategies often assign an insufficient number of positive samples to small objects, leading to a scale imbalance during training. To address this limitation, we introduce RFAssigner, a novel assignment strategy designed to enhance the multi-scale learning capabilities of dense detectors. RFAssigner first establishes an initial set of positive samples using a point-based prior. It then leverages a Gaussian Receptive Field (GRF) distance to measure the similarity between the GRFs of unassigned candidate locations and the ground-truth objects. Based on this metric, RFAssigner adaptively selects supplementary positive samples from the unassigned pool, promoting a more balanced learning process across object scales. Comprehensive experiments on three datasets with distinct object scale distributions validate the effectiveness and generalizability of our method. Notably, a single FCOS-ResNet-50 detector equipped with RFAssigner achieves state-of-the-art performance across all object scales, consistently outperforming existing strategies without requiring auxiliary modules or heuristics.

</details>


### [56] [MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance](https://arxiv.org/abs/2601.01260)
*Hamad Khan,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 本文提出了一种名为MambaFormer的LLM-MoE混合框架，结合Transformer（ET5）与状态空间模型（EMamba）专家，通过轻量级动态路由机制实现高效医学问答，兼顾低延迟与高准确率，并在DentalQA和PubMedQA数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在临床实际部署中受限于计算开销与线性时间模型效率之间的根本权衡，亟需兼顾推理速度与预测精度的高效架构。

Method: 提出MambaFormer混合MoE框架：设计轻量级门控机制，依据token嵌入复杂度、归一化序列长度及领域特征，动态路由至定制化Transformer专家（ET5）或状态空间模型专家（EMamba）；采用效用引导的多目标损失函数联合优化路由决策、专家激活与计算成本；在自建DentalQA数据集上进行迁移微调。

Result: 在DentalQA和PubMedQA数据集上交叉验证，BERTScore达0.9180，推理延迟仅0.077秒，相比T5-Large提速24.4倍。

Conclusion: MambaFormer实现了推理延迟与预测精度的帕累托最优平衡，为资源受限的临床场景提供了可扩展、高效的LLM部署方案。

Abstract: The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.

</details>


### [57] [AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures](https://arxiv.org/abs/2601.01281)
*Sifatullah Sheikh Urmi,Kirtonia Nuzath Tabassum Arthi,Md Al-Imran*

Main category: cs.CV

TL;DR: 本文评估了四种AI模型（三种CNN和一种Vision Transformer）在大型人脸图像数据集上的深度伪造检测性能，通过数据预处理和增强技术提升了模型表现，其中VFDNET结合MobileNetV3展现出最优准确率和高效性。


<details>
  <summary>Details</summary>
Motivation: 应对人工智能生成的深度伪造内容激增所带来的数字真实性维护挑战。

Method: 评估四种AI模型（三种CNN和一种Vision Transformer），采用大型人脸图像数据集，并结合数据预处理与增强技术。

Result: VFDNET结合MobileNetV3在深度伪造检测中表现出最高准确率和高效性。

Conclusion: AI模型，特别是VFDNET与MobileNetV3的组合，具备可靠深度伪造检测能力。

Abstract: The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.

</details>


### [58] [S2M-Net: Spectral-Spatial Mixing for Medical Image Segmentation with Morphology-Aware Adaptive Loss](https://arxiv.org/abs/2601.01285)
*Md. Sanaullah Chowdhury Lameya Sabrin*

Main category: cs.CV

TL;DR: 本文提出S2M-Net，一种兼顾局部精度、全局上下文与计算效率的轻量级医学图像分割网络，通过频谱选择性令牌混合器（SSTM）和形态学感知自适应分割损失（MASL）解决医学图像分割三难困境，在16个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割需同时满足边界局部精度、解剖结构全局一致性与计算高效性，但现有CNN（感受野受限）和ViT（计算开销大、易在小数据上过拟合）难以兼顾这三者。

Method: 提出S2M-Net：（i）Spectral-Selective Token Mixer（SSTM），基于截断2D FFT与可学习频率滤波+内容门控空间投影，实现O(HW log HW)复杂度下的全局建模；（ii）Morphology-Aware Adaptive Segmentation Loss（MASL），根据结构特性自动加权五种互补损失分量，避免人工调参。

Result: 在16个跨8种模态的医学数据集上取得SOTA：息肉分割Dice达96.12%，手术器械分割83.77%（较先前方法提升17.85%），脑肿瘤分割80.90%；相比Transformer方法参数减少3.5–6×，且稳定超越专用基线3–18%。

Conclusion: S2M-Net通过频谱建模与形态自适应损失设计，有效破解医学图像分割的精度-上下文-效率三难问题，为资源受限临床场景提供高效鲁棒的解决方案。

Abstract: Medical image segmentation requires balancing local precision for boundary-critical clinical applications, global context for anatomical coherence, and computational efficiency for deployment on limited data and hardware a trilemma that existing architectures fail to resolve. Although convolutional networks provide local precision at $\mathcal{O}(n)$ cost but limited receptive fields, vision transformers achieve global context through $\mathcal{O}(n^2)$ self-attention at prohibitive computational expense, causing overfitting on small clinical datasets. We propose S2M-Net, a 4.7M-parameter architecture that achieves $\mathcal{O}(HW \log HW)$ global context through two synergistic innovations: (i) Spectral-Selective Token Mixer (SSTM), which exploits the spectral concentration of medical images via truncated 2D FFT with learnable frequency filtering and content-gated spatial projection, avoiding quadratic attention cost while maintaining global receptive fields; and (ii) Morphology-Aware Adaptive Segmentation Loss (MASL), which automatically analyzes structure characteristics (compactness, tubularity, irregularity, scale) to modulate five complementary loss components through constrained learnable weights, eliminating manual per-dataset tuning. Comprehensive evaluation in 16 medical imaging datasets that span 8 modalities demonstrates state-of-the-art performance: 96.12\% Dice on polyp segmentation, 83.77\% on surgical instruments (+17.85\% over the prior art) and 80.90\% on brain tumors, with consistent 3-18\% improvements over specialized baselines while using 3.5--6$\times$ fewer parameters than transformer-based methods.

</details>


### [59] [VReID-XFD: Video-based Person Re-identification at Extreme Far Distance Challenge Results](https://arxiv.org/abs/2601.01312)
*Kailash A. Hambarde,Hugo Proença,Md Rashidunnabi,Pranita Samale,Qiwei Yang,Pingping Zhang,Zijing Gong,Yuhao Wang,Xi Zhang,Ruoshui Qu,Qiaoyun He,Yuhang Zhang,Thi Ngoc Ha Nguyen,Tien-Dung Mai,Cheng-Jun Kang,Yu-Fan Lin,Jin-Hui Jiang,Chih-Chung Hsu,Tamás Endrei,György Cserey,Ashwat Rajbhandari*

Main category: cs.CV

TL;DR: 本文提出了VReID-XFD视频基准和挑战赛，用于研究极端远距离下空中与地面视角间行人重识别（ReID）的新任务场景，并分析了性能随高度、距离和视角变化的规律。


<details>
  <summary>Details</summary>
Motivation: 现有基于外观的行人重识别系统在极端远距离、大视角差异、严重分辨率下降、运动线索不稳定及衣着变化等联合挑战下失效，亟需专门研究该新操作范式。

Method: 构建了基于DetReIDX数据集的VReID-XFD视频基准，包含371个身份、11288个轨迹段、1175万帧，覆盖5.8–120米高度、30°–90°视角及最高120米水平距离；支持多种跨视角评估设置，并组织了VReID-XFD-25挑战赛。

Result: 系统分析表明性能随高度和距离单调下降，正射视角（nadir）普遍不利，且峰值性能与鲁棒性存在权衡；最优方法SAS-PReID在空对地设置下仅达43.93% mAP。

Conclusion: VReID-XFD定义并推动了极端远距离跨视角ReID这一新研究方向，揭示了当前方法的根本局限，并提供了公开数据集、标注与评测协议以支撑后续研究。

Abstract: Person re-identification (ReID) across aerial and ground views at extreme far distances introduces a distinct operating regime where severe resolution degradation, extreme viewpoint changes, unstable motion cues, and clothing variation jointly undermine the appearance-based assumptions of existing ReID systems. To study this regime, we introduce VReID-XFD, a video-based benchmark and community challenge for extreme far-distance (XFD) aerial-to-ground person re-identification. VReID-XFD is derived from the DetReIDX dataset and comprises 371 identities, 11,288 tracklets, and 11.75 million frames, captured across altitudes from 5.8 m to 120 m, viewing angles from oblique (30 degrees) to nadir (90 degrees), and horizontal distances up to 120 m. The benchmark supports aerial-to-aerial, aerial-to-ground, and ground-to-aerial evaluation under strict identity-disjoint splits, with rich physical metadata. The VReID-XFD-25 Challenge attracted 10 teams with hundreds of submissions. Systematic analysis reveals monotonic performance degradation with altitude and distance, a universal disadvantage of nadir views, and a trade-off between peak performance and robustness. Even the best-performing SAS-PReID method achieves only 43.93 percent mAP in the aerial-to-ground setting. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/ .

</details>


### [60] [LinMU: Multimodal Understanding Made Linear](https://arxiv.org/abs/2601.01322)
*Hongjie Wang,Niraj K. Jha*

Main category: cs.CV

TL;DR: 本文提出LinMU，一种线性复杂度的视觉语言模型（VLM），通过M-MATE双分支模块替代自注意力机制，并采用三阶段知识蒸馏框架，显著提升推理效率（TTFT降低2.7×，吞吐量提升9.0×），同时保持与原VLM相当的多模态理解性能。


<details>
  <summary>Details</summary>
Motivation: 现代VLM因自注意力的二次计算复杂度难以部署于边缘设备，且处理高分辨率图像和长视频成本高昂。

Method: 提出LinMU架构：用M-MATE块（含Flex-MA全局状态空间模型分支和Local-Swin局部窗口注意力分支）替换所有自注意力层；设计三阶段蒸馏流程：先训Flex-MA、再联合微调两分支、最后用LoRA微调其余模块并回归教师模型隐状态和token logits。

Result: 在MMMU、TextVQA、LongVideoBench等基准上达到教师模型性能，TTFT最高降低2.7×，token吞吐量最高提升9.0×；消融实验证实各蒸馏阶段及双分支设计均关键。

Conclusion: 无需二次复杂度注意力即可实现先进多模态推理，为高分辨率图像与长视频场景下的长上下文VLM提供了可行路径。

Abstract: Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\times$ and improves token throughput by up to 9.0$\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.

</details>


### [61] [Achieving Fine-grained Cross-modal Understanding through Brain-inspired Hierarchical Representation Learning](https://arxiv.org/abs/2601.01339)
*Weihang You,Hanqi Jiang,Yi Pan,Junhao Chen,Tianming Liu,Fei Dou*

Main category: cs.CV

TL;DR: NeuroAlign 是一种受人类视觉系统层次结构启发的新型 fMRI-视频对齐框架，通过神经-时间对比学习（NTCL）和动态多模态融合（DynaSyncMM-EMA）实现全局语义理解与细粒度模式匹配，在跨模态检索任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以反映大脑视觉处理的层次性和时序性，且受限于神经数据与视觉输入之间的模态鸿沟。

Method: 提出 NeuroAlign 框架，包含两阶段机制：1）基于双向跨模态预测的神经-时间对比学习（NTCL）建模全局语义与时间动态；2）结合增强向量量化与动态自适应加权的 DynaSyncMM-EMA 实现细粒度对齐。

Result: 在跨模态检索任务中显著超越现有方法，验证了其在 fMRI-视频对齐上的有效性。

Conclusion: NeuroAlign 建立了一种新范式，有助于深入理解视觉认知机制，并为脑-机接口和神经解码提供更可靠的对齐基础。

Abstract: Understanding neural responses to visual stimuli remains challenging due to the inherent complexity of brain representations and the modality gap between neural data and visual inputs. Existing methods, mainly based on reducing neural decoding to generation tasks or simple correlations, fail to reflect the hierarchical and temporal processes of visual processing in the brain. To address these limitations, we present NeuroAlign, a novel framework for fine-grained fMRI-video alignment inspired by the hierarchical organization of the human visual system. Our framework implements a two-stage mechanism that mirrors biological visual pathways: global semantic understanding through Neural-Temporal Contrastive Learning (NTCL) and fine-grained pattern matching through enhanced vector quantization. NTCL explicitly models temporal dynamics through bidirectional prediction between modalities, while our DynaSyncMM-EMA approach enables dynamic multi-modal fusion with adaptive weighting. Experiments demonstrate that NeuroAlign significantly outperforms existing methods in cross-modal retrieval tasks, establishing a new paradigm for understanding visual cognitive mechanisms.

</details>


### [62] [Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding](https://arxiv.org/abs/2601.01352)
*Yixuan Lai,He Wang,Kun Zhou,Tianjia Shao*

Main category: cs.CV

TL;DR: 本文提出了一种基于短参考视频的身份条件扩散Transformer视频生成方法，通过Sinkhorn路由编码器提取动态身份特征，在保持提示忠实性的同时显著提升大姿态变化和丰富表情下的身份保留能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅用单张图像作为身份条件，忽略了时间动态信息，导致姿态锁定、形变失真及表情平均化等问题，难以兼顾身份保真与运动自然性。

Method: 设计身份条件化的扩散Transformer视频生成器，以短参考视频替代单张图像；引入Sinkhorn-routed编码器，从视频中学习紧凑且兼容预训练主干的身份动态令牌。

Result: 在大姿态变化和强表情下显著提升身份保留效果，同时维持提示忠实性、视觉真实感，适用于多样主体与提示。

Conclusion: 利用短参考视频建模个体动态特征是提升生成视频中身份一致性的有效途径，轻量级条件机制即可带来稳定性能增益。

Abstract: Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and "average" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.

</details>


### [63] [Advanced Machine Learning Approaches for Enhancing Person Re-Identification Performance](https://arxiv.org/abs/2601.01356)
*Dang H. Pham,Tu N. Nguyen,Hoa N. Nguyen*

Main category: cs.CV

TL;DR: 本文提出三种针对不同监督设置下行人重识别（ReID）的先进方法：监督式SCM-ReID、无监督域自适应IQAGA+DAPRH、以及完全无监督的ViTC-UReID，显著提升了跨数据集和跨域性能。


<details>
  <summary>Details</summary>
Motivation: 解决ReID中外观变化大、域偏移严重、标注数据稀缺等关键挑战，提升其在真实监控场景中的鲁棒性与实用性。

Method: 1) SCM-ReID：融合监督对比学习与多损失（分类、中心、三元组、质心三元组）优化；2) IQAGA与DAPRH：基于GAN的数据增强、域不变映射与伪标签精炼；3) ViTC-UReID：Vision Transformer编码 + 相机感知代理学习 + 全局-局部注意力机制。

Result: 在Market-1501、CUHK03、DukeMTMC-reID和MSMT17等多个基准上达到SOTA性能；UDA设置下mAP与Rank-1提升最高达12%；显著优于现有无监督方法。

Conclusion: 所提方法系统性地改进了特征判别性、跨域泛化能力与无标签场景下的建模能力，推动ReID向实际部署迈进。

Abstract: Person re-identification (ReID) plays a critical role in intelligent surveillance systems by linking identities across multiple cameras in complex environments. However, ReID faces significant challenges such as appearance variations, domain shifts, and limited labeled data. This dissertation proposes three advanced approaches to enhance ReID performance under supervised, unsupervised domain adaptation (UDA), and fully unsupervised settings. First, SCM-ReID integrates supervised contrastive learning with hybrid loss optimization (classification, center, triplet, and centroid-triplet losses), improving discriminative feature representation and achieving state-of-the-art accuracy on Market-1501 and CUHK03 datasets. Second, for UDA, IQAGA and DAPRH combine GAN-based image augmentation, domain-invariant mapping, and pseudo-label refinement to mitigate domain discrepancies and enhance cross-domain generalization. Experiments demonstrate substantial gains over baseline methods, with mAP and Rank-1 improvements up to 12% in challenging transfer scenarios. Finally, ViTC-UReID leverages Vision Transformer-based feature encoding and camera-aware proxy learning to boost unsupervised ReID. By integrating global and local attention with camera identity constraints, this method significantly outperforms existing unsupervised approaches on large-scale benchmarks. Comprehensive evaluations across CUHK03, Market-1501, DukeMTMC-reID, and MSMT17 confirm the effectiveness of the proposed methods. The contributions advance ReID research by addressing key limitations in feature learning, domain adaptation, and label noise handling, paving the way for robust deployment in real-world surveillance systems.

</details>


### [64] [Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose IMU Denoiser](https://arxiv.org/abs/2601.01360)
*Jiawei Fang,Ruonan Zheng,Xiaoxia Gao,Shifan Jiang,Anjun Chen,Qi Ye,Shihui Guo*

Main category: cs.CV

TL;DR: 本文提出GID（Garment Inertial Denoiser），一种轻量级、即插即用的Transformer模型，用于解决嵌入宽松衣物中的IMU因传感器-身体位移导致的姿态估计误差问题；通过位置感知专家架构实现分阶段去噪与融合，在有限配对数据下稳定训练，并在新用户、动作和服装类型上具有良好泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴惯性动捕系统要求传感器紧贴皮肤，影响舒适性；而将IMU嵌入宽松衣物虽更实用，却因传感器-身体相对位移引入严重且结构化的噪声，破坏标准惯性处理流程。

Method: 提出GID模型，采用三阶段框架：(i) 位置特异性去噪，(ii) 自适应跨穿戴融合，(iii) 通用姿态预测；其核心是共享时空骨干网络+按IMU位置定制的专家头+轻量融合模块，并构建GarMoCap数据集（含公开与新采集数据）支持训练与评估。

Result: GID在单用户训练下即可实现实时高精度去噪，且能泛化至未见用户、动作及服装类型；作为即插即用模块，持续提升现有最先进惯性动捕方法性能。

Conclusion: GID通过引入位置感知归纳偏置，有效建模宽松穿戴下的局部动态特性，在数据受限条件下实现鲁棒学习与强泛化能力，为日常可用的惯性动捕提供了可行技术路径。

Abstract: Wearable inertial motion capture (MoCap) provides a portable, occlusion-free, and privacy-preserving alternative to camera-based systems, but its accuracy depends on tightly attached sensors - an intrusive and uncomfortable requirement for daily use. Embedding IMUs into loose-fitting garments is a desirable alternative, yet sensor-body displacement introduces severe, structured, and location-dependent corruption that breaks standard inertial pipelines. We propose GID (Garment Inertial Denoiser), a lightweight, plug-and-play Transformer that factorizes loose-wear MoCap into three stages: (i) location-specific denoising, (ii) adaptive cross-wear fusion, and (iii) general pose prediction. GID uses a location-aware expert architecture, where a shared spatio-temporal backbone models global motion while per-IMU expert heads specialize in local garment dynamics, and a lightweight fusion module ensures cross-part consistency. This inductive bias enables stable training and effective learning from limited paired loose-tight IMU data. We also introduce GarMoCap, a combined public and newly collected dataset covering diverse users, motions, and garments. Experiments show that GID enables accurate, real-time denoising from single-user training and generalizes across unseen users, motions, and garment types, consistently improving state-of-the-art inertial MoCap methods when used as a drop-in module.

</details>


### [65] [Unsupervised SE(3) Disentanglement for in situ Macromolecular Morphology Identification from Cryo-Electron Tomography](https://arxiv.org/abs/2601.01364)
*Mostofa Rafid Uddin,Mahek Vora,Qifeng Wu,Muyuan Chen,Min Xu*

Main category: cs.CV

TL;DR: 本文提出了一种用于冷冻电子断层扫描（cryo-ET）数据的解耦深度表征学习框架，将SE(3)变换与形态学内容分离，从而更鲁棒、自动地重建和发现细胞内大分子的原位三维形态。


<details>
  <summary>Details</summary>
Motivation: 现有基于EM的方法难以发现稀有但重要的大分子形态，且需大量人工调参；cryo-ET数据噪声高，传统方法难以稳健估计模板形态及其SE(3)变换。

Method: 提出一种解耦深度表征学习框架，包含新颖的多选学习模块，在表征空间中分离SE(3)变换与形态学内容，并利用学习到的形态学内容生成模板形态。

Result: 在模拟和真实cryo-ET数据集上显著优于先前方法，成功发现了此前未识别的大分子形态。

Conclusion: 该框架提升了cryo-ET中大分子原位结构解析的自动化程度、鲁棒性与发现能力，为结构细胞生物学提供了新工具。

Abstract: Cryo-electron tomography (cryo-ET) provides direct 3D visualization of macromolecules inside the cell, enabling analysis of their in situ morphology. This morphology can be regarded as an SE(3)-invariant, denoised volumetric representation of subvolumes extracted from tomograms. Inferring morphology is therefore an inverse problem of estimating both a template morphology and its SE(3) transformation. Existing expectation-maximization based solution to this problem often misses rare but important morphologies and requires extensive manual hyperparameter tuning. Addressing this issue, we present a disentangled deep representation learning framework that separates SE(3) transformations from morphological content in the representation space. The framework includes a novel multi-choice learning module that enables this disentanglement for highly noisy cryo-ET data, and the learned morphological content is used to generate template morphologies. Experiments on simulated and real cryo-ET datasets demonstrate clear improvements over prior methods, including the discovery of previously unidentified macromolecular morphologies.

</details>


### [66] [ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking](https://arxiv.org/abs/2601.01386)
*Xiaobao Wei,Zhangjie Ye,Yuxiang Gu,Zunjie Zhu,Yunfei Guo,Yingying Shen,Shan Zhao,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Rongfeng Lu,Hangjun Ye*

Main category: cs.CV

TL;DR: 本文提出了首个专为停车场景重建设计的基准数据集ParkRecon3D，并提出首个基于3D高斯溅射（3DGS）的停车场景重建框架ParkGaussian，引入槽感知重建策略以提升重建结果与下游停车槽检测任务的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有工作集中于2D停车槽感知、建图和定位，而对3D重建关注不足；且单纯提升重建视觉质量并不直接利于自主泊车，关键在于提升停车槽区域的重建质量以服务下游感知模块。

Method: 构建首个停车场景3D重建基准ParkRecon3D（含四目环视鱼眼图像及密集停车槽标注），并提出ParkGaussian框架，首次将3D高斯溅射用于停车场景重建，引入基于已有停车感知方法的槽感知重建策略以优化槽区域合成质量。

Result: 在ParkRecon3D上实验表明，ParkGaussian实现了SOTA重建质量，并显著提升了重建结果与下游停车槽检测任务之间的感知一致性。

Conclusion: 3D重建应面向下游感知任务进行优化，槽感知重建策略有效弥合了重建与实际泊车需求之间的鸿沟，ParkRecon3D和ParkGaussian为停车场景三维理解提供了新基准与新范式。

Abstract: Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian

</details>


### [67] [Evaluation of Convolutional Neural Network For Image Classification with Agricultural and Urban Datasets](https://arxiv.org/abs/2601.01393)
*Shamik Shafkat Avro,Nazira Jesmin Lina,Shahanaz Sharmin*

Main category: cs.CV

TL;DR: 本文提出了一种定制的CNN（CustomCNN），通过引入残差连接、Squeeze-and-Excitation机制、渐进式通道缩放和Kaiming初始化，提升多领域图像分类性能，并在五个公开数据集上验证了其高效性与竞争力。


<details>
  <summary>Details</summary>
Motivation: 探索网络架构设计选择对多领域图像分类任务的影响，尤其面向智慧城市与农业成像等实际应用场景。

Method: 设计并实现CustomCNN，融合残差连接、Squeeze-and-Excitation注意力机制、渐进式通道缩放及Kaiming初始化；在五个公开图像数据集上训练与评估，并与主流CNN架构对比。

Result: CustomCNN在多个数据集上达到有竞争力的分类性能，同时保持较低计算开销。

Conclusion: 精心设计的网络架构对提升真实场景下多领域图像分类效果至关重要。

Abstract: This paper presents the development and evaluation of a custom Convolutional Neural Network (CustomCNN) created to study how architectural design choices affect multi-domain image classification tasks. The network uses residual connections, Squeeze-and-Excitation attention mechanisms, progressive channel scaling, and Kaiming initialization to improve its ability to represent data and speed up training. The model is trained and tested on five publicly available datasets: unauthorized vehicle detection, footpath encroachment detection, polygon-annotated road damage and manhole detection, MangoImageBD and PaddyVarietyBD. A comparison with popular CNN architectures shows that the CustomCNN delivers competitive performance while remaining efficient in computation. The results underscore the importance of thoughtful architectural design for real-world Smart City and agricultural imaging applications.

</details>


### [68] [SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution](https://arxiv.org/abs/2601.01406)
*Habiba Kausar,Saeed Anwar,Omar Jamal Hammad,Abdul Bais*

Main category: cs.CV

TL;DR: 本文提出了SwinIFS，一种基于关键点引导的面部超分辨率框架，结合结构先验与分层注意力机制，在中高倍率（最高8倍）下实现身份保持的高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在严重退化低分辨率输入下难以恢复面部精细结构和身份特征，尤其在高倍率放大时性能显著下降。

Method: 引入密集高斯热图编码关键面部关键点作为输入先验；采用轻量级Swin Transformer主干网络，兼顾长程上下文建模与局部几何保持。

Result: 在CelebA数据集上显著提升感知质量、重建锐度和身份保留能力，8倍放大下仍能恢复有意义结构，并在精度与计算效率间取得良好平衡。

Conclusion: SwinIFS是一种高效、鲁棒且实用的面部超分辨率方法，适用于安防、数字修复等真实场景。

Abstract: Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.

</details>


### [69] [Mask-Guided Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01408)
*Gong Gao,Zekai Wang,Jian Zhao,Ziqi Xie,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种名为Mask-Guided Multi-Task Network (MGMTN) 的新方法，通过自适应掩码学习（AML）和组-全局特征融合（G2FF）提升人脸属性识别（FAR）性能，聚焦关键局部区域以减少冗余特征与负迁移。


<details>
  <summary>Details</summary>
Motivation: 传统多任务人脸属性识别方法依赖全局特征图，易产生冗余特征并引发负迁移，难以精准识别细粒度属性。

Method: 提出MGMTN框架：1）AML模块利用预训练关键点模型和全卷积网络生成关键面部部件（如眼、嘴组）的组掩码；2）G2FF模块融合组级局部特征与全局特征进行多任务学习。

Result: 在两个具有挑战性的人脸属性数据集上，MGMTN显著提升了FAR性能，验证了局部区域引导特征学习的有效性。

Conclusion: 聚焦关键面部局部区域并融合组-全局特征可有效缓解全局特征冗余与负迁移问题，提升多任务人脸属性识别精度与鲁棒性。

Abstract: Face Attribute Recognition (FAR) plays a crucial role in applications such as person re-identification, face retrieval, and face editing. Conventional multi-task attribute recognition methods often process the entire feature map for feature extraction and attribute classification, which can produce redundant features due to reliance on global regions. To address these challenges, we propose a novel approach emphasizing the selection of specific feature regions for efficient feature learning. We introduce the Mask-Guided Multi-Task Network (MGMTN), which integrates Adaptive Mask Learning (AML) and Group-Global Feature Fusion (G2FF) to address the aforementioned limitations. Leveraging a pre-trained keypoint annotation model and a fully convolutional network, AML accurately localizes critical facial parts (e.g., eye and mouth groups) and generates group masks that delineate meaningful feature regions, thereby mitigating negative transfer from global region usage. Furthermore, G2FF combines group and global features to enhance FAR learning, enabling more precise attribute identification. Extensive experiments on two challenging facial attribute recognition datasets demonstrate the effectiveness of MGMTN in improving FAR performance.

</details>


### [70] [AirSpatialBot: A Spatially-Aware Aerial Agent for Fine-Grained Vehicle Attribute Recognization and Retrieval](https://arxiv.org/abs/2601.01416)
*Yue Zhou,Ran Ding,Xue Yang,Xue Jiang,Xingzhao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种面向无人机遥感图像的时空感知视觉语言模型AirSpatialBot，构建了首个含3D边界框的遥感空间定位数据集AirSpatial，并通过两阶段训练策略提升模型空间理解能力，实现了细粒度车辆属性识别与检索。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在空间理解方面存在不足，限制了其在真实场景中的应用效果，尤其在无人机拍摄的车辆图像分析中表现不佳。

Method: 构建包含20.6万条指令的遥感空间感知数据集AirSpatial，定义空间定位（Spatial Grounding）和空间问答（Spatial QA）两个新任务；采用图像理解预训练+空间理解微调的两阶段训练策略；设计具备任务规划、图像理解、空间理解和执行能力的空中智能体AirSpatialBot。

Result: 实验验证了所提方法的有效性，揭示了现有VLMs在空间理解上的局限性；AirSpatialBot在细粒度车辆属性识别与检索任务上表现优异；模型、代码和数据集将开源。

Conclusion: 引入空间感知能力是提升遥感VLM实用性的关键路径，AirSpatial及AirSpatialBot为遥感领域视觉语言建模提供了新范式与基础资源。

Abstract: Despite notable advancements in remote sensing vision-language models (VLMs), existing models often struggle with spatial understanding, limiting their effectiveness in real-world applications. To push the boundaries of VLMs in remote sensing, we specifically address vehicle imagery captured by drones and introduce a spatially-aware dataset AirSpatial, which comprises over 206K instructions and introduces two novel tasks: Spatial Grounding and Spatial Question Answering. It is also the first remote sensing grounding dataset to provide 3DBB. To effectively leverage existing image understanding of VLMs to spatial domains, we adopt a two-stage training strategy comprising Image Understanding Pre-training and Spatial Understanding Fine-tuning. Utilizing this trained spatially-aware VLM, we develop an aerial agent, AirSpatialBot, which is capable of fine-grained vehicle attribute recognition and retrieval. By dynamically integrating task planning, image understanding, spatial understanding, and task execution capabilities, AirSpatialBot adapts to diverse query requirements. Experimental results validate the effectiveness of our approach, revealing the spatial limitations of existing VLMs while providing valuable insights. The model, code, and datasets will be released at https://github.com/VisionXLab/AirSpatialBot

</details>


### [71] [DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer](https://arxiv.org/abs/2601.01425)
*Xu Guo,Fulong Ye,Xinghui Li,Pengqi Tu,Pengze Zhang,Qichao Sun,Songtao Zhao,Xiangwang Hou,Qian He*

Main category: cs.CV

TL;DR: 本文提出DreamID-V框架，通过SyncID-Pipe数据流水线、Modality-Aware Conditioning模块、Synthetic-to-Real课程学习与Identity-Coherence强化学习策略，将图像级换脸优势迁移至视频域，在身份一致性、属性保留与时间连贯性上取得显著提升，并构建新基准IDBench-V。


<details>
  <summary>Details</summary>
Motivation: 现有视频换脸方法难以同时保持身份相似性、属性（姿态、表情、光照等）保真度和时间一致性。

Method: 提出SyncID-Pipe数据流水线构建ID四元组；设计基于扩散Transformer的DreamID-V框架，含模态感知条件注入模块；引入合成到真实的课程学习与身份一致性强化学习策略。

Result: DreamID-V在自建IDBench-V基准及多个指标上显著超越SOTA方法，具备优异泛化性与任务适配能力。

Conclusion: 该工作系统性地 bridged 图像与视频换脸技术鸿沟，为高质量、高一致性视频人脸交换提供了可扩展、鲁棒的新范式。

Abstract: Video Face Swapping (VFS) requires seamlessly injecting a source identity into a target video while meticulously preserving the original pose, expression, lighting, background, and dynamic information. Existing methods struggle to maintain identity similarity and attribute preservation while preserving temporal consistency. To address the challenge, we propose a comprehensive framework to seamlessly transfer the superiority of Image Face Swapping (IFS) to the video domain. We first introduce a novel data pipeline SyncID-Pipe that pre-trains an Identity-Anchored Video Synthesizer and combines it with IFS models to construct bidirectional ID quadruplets for explicit supervision. Building upon paired data, we propose the first Diffusion Transformer-based framework DreamID-V, employing a core Modality-Aware Conditioning module to discriminatively inject multi-model conditions. Meanwhile, we propose a Synthetic-to-Real Curriculum mechanism and an Identity-Coherence Reinforcement Learning strategy to enhance visual realism and identity consistency under challenging scenarios. To address the issue of limited benchmarks, we introduce IDBench-V, a comprehensive benchmark encompassing diverse scenes. Extensive experiments demonstrate DreamID-V outperforms state-of-the-art methods and further exhibits exceptional versatility, which can be seamlessly adapted to various swap-related tasks.

</details>


### [72] [EdgeNeRF: Edge-Guided Regularization for Neural Radiance Fields from Sparse Views](https://arxiv.org/abs/2601.01431)
*Weiqi Yu,Yiyang Yao,Lin He,Jianming Lv*

Main category: cs.CV

TL;DR: EdgeNeRF提出了一种边缘引导的稀疏视角3D重建方法，通过在非边缘区域施加深度和法向正则化来提升几何一致性并保留边界细节，显著改善稀疏输入下的NeRF重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法在稀疏视角下重建质量下降，尤其产生几何伪影；全局深度正则化虽缓解伪影但损失边界细节。

Method: 提出EdgeNeRF：利用深度与法向突变生成边缘的先验，从输入图像提取边缘，并仅在非边缘区域施加深度和法向正则化约束。

Result: 在LLFF和DTU数据集上验证了EdgeNeRF在保持尖锐几何边界和抑制伪影方面的优越性；其边缘引导模块可即插即用地提升其他方法性能，且训练开销增加极少。

Conclusion: EdgeNeRF有效解决了稀疏视角下NeRF的几何失真问题，在保持高频边界细节的同时提升整体重建质量，具备良好的通用性和实用性。

Abstract: Neural Radiance Fields (NeRF) achieve remarkable performance in dense multi-view scenarios, but their reconstruction quality degrades significantly under sparse inputs due to geometric artifacts. Existing methods utilize global depth regularization to mitigate artifacts, leading to the loss of geometric boundary details. To address this problem, we propose EdgeNeRF, an edge-guided sparse-view 3D reconstruction algorithm. Our method leverages the prior that abrupt changes in depth and normals generate edges. Specifically, we first extract edges from input images, then apply depth and normal regularization constraints to non-edge regions, enhancing geometric consistency while preserving high-frequency details at boundaries. Experiments on LLFF and DTU datasets demonstrate EdgeNeRF's superior performance, particularly in retaining sharp geometric boundaries and suppressing artifacts. Additionally, the proposed edge-guided depth regularization module can be seamlessly integrated into other methods in a plug-and-play manner, significantly improving their performance without substantially increasing training time. Code is available at https://github.com/skyhigh404/edgenerf.

</details>


### [73] [In defense of the two-stage framework for open-set domain adaptive semantic segmentation](https://arxiv.org/abs/2601.01439)
*Wenqi Ren,Weijie Wang,Meng Zheng,Ziyan Wu,Yang Tang,Zhun Zhong,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出了一种分离再适应的训练策略（SATS）来解决开放集域自适应语义分割（OSDA-SS）问题，通过两阶段流程（已知/未知类分离 + 面向未知的域自适应）和硬未知探索增强方法，在多个基准上显著提升H-Score。


<details>
  <summary>Details</summary>
Motivation: 现有OSDA-SS方法将已知类域自适应与未知类识别统一于单阶段，易因已知/未知标注严重不平衡导致已知类负迁移和未知类欠拟合。

Method: 提出SATS两阶段策略：第一阶段进行已知/未知类分离，第二阶段开展未知感知的域自适应；并引入硬未知探索数据增强方法，提升模型对目标域未知类的判别能力。

Result: 在GTA5→Cityscapes和SYNTHIA→Cityscapes两个OSDA-SS基准上，H-Score分别提升+3.85%和+18.64%，超越此前最优方法。

Conclusion: 分离再适应的设计更符合OSDA-SS任务本质，能平衡已知与未知类的学习，引导模型发现真正未知对象；硬未知探索进一步增强了模型对未知类的泛化能力。

Abstract: Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) presents a significant challenge, as it requires both domain adaptation for known classes and the distinction of unknowns. Existing methods attempt to address both tasks within a single unified stage. We question this design, as the annotation imbalance between known and unknown classes often leads to negative transfer of known classes and underfitting for unknowns. To overcome these issues, we propose SATS, a Separating-then-Adapting Training Strategy, which addresses OSDA-SS through two sequential steps: known/unknown separation and unknown-aware domain adaptation. By providing the model with more accurate and well-aligned unknown classes, our method ensures a balanced learning of discriminative features for both known and unknown classes, steering the model toward discovering truly unknown objects. Additionally, we present hard unknown exploration, an innovative data augmentation method that exposes the model to more challenging unknowns, strengthening its ability to capture more comprehensive understanding of target unknowns. We evaluate our method on public OSDA-SS benchmarks. Experimental results demonstrate that our method achieves a substantial advancement, with a +3.85% H-Score improvement for GTA5-to-Cityscapes and +18.64% for SYNTHIA-to-Cityscapes, outperforming previous state-of-the-art methods.

</details>


### [74] [PartImageNet++ Dataset: Enhancing Visual Models with High-Quality Part Annotations](https://arxiv.org/abs/2601.01454)
*Xiao Li,Zilong Liu,Yining Liu,Zhuhong Li,Na Dong,Sitian Qin,Xiaolin Hu*

Main category: cs.CV

TL;DR: 本文提出了PartImageNet++（PIN++）数据集，为ImageNet-1K所有类别提供细粒度部件标注，并基于该数据集设计了多尺度部件监督识别模型（MPM），通过伪标签与真实标注联合监督提升鲁棒分类性能，同时验证了部件标注在分割与少样本学习等下游任务中的价值。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据集中高质量部件标注稀缺的问题，弥补ImageNet-1K缺乏细粒度部件信息的空白。

Method: 构建包含100K图像、每类100张带部件标注的PartImageNet++数据集；训练部件分割网络生成未标注图像的伪部件标签；提出MPM模型，在常规识别架构中引入辅助旁路层，联合监督真实部件标注与伪标签。

Result: MPM在ImageNet-1K上提升了鲁棒分类性能；在部件分割、物体分割和少样本学习等下游任务中建立了强基线；验证了部件标注对模型性能的普遍增益。

Conclusion: PartImageNet++是目前覆盖最广、规模最大的部件标注数据集，其与MPM共同证明了部件级监督对提升视觉模型泛化性与多功能性的关键作用。

Abstract: To address the scarcity of high-quality part annotations in existing datasets, we introduce PartImageNet++ (PIN++), a dataset that provides detailed part annotations for all categories in ImageNet-1K. With 100 annotated images per category, totaling 100K images, PIN++ represents the most comprehensive dataset covering a diverse range of object categories. Leveraging PIN++, we propose a Multi-scale Part-supervised recognition Model (MPM) for robust classification on ImageNet-1K. We first trained a part segmentation network using PIN++ and used it to generate pseudo part labels for the remaining unannotated images. MPM then integrated a conventional recognition architecture with auxiliary bypass layers, jointly supervised by both pseudo part labels and the original part annotations. Furthermore, we conducted extensive experiments on PIN++, including part segmentation, object segmentation, and few-shot learning, exploring various ways to leverage part annotations in downstream tasks. Experimental results demonstrated that our approach not only enhanced part-based models for robust object recognition but also established strong baselines for multiple downstream tasks, highlighting the potential of part annotations in improving model performance. The dataset and the code are available at https://github.com/LixiaoTHU/PartImageNetPP.

</details>


### [75] [Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration](https://arxiv.org/abs/2601.01456)
*Wentao Bian,Fenglei Xu*

Main category: cs.CV

TL;DR: 本文提出DA-FSS模型，通过解耦几何与语义路径并协同正则化梯度，解决多模态少样本3D点云语义分割中的可塑性-稳定性困境和CLIP语义混淆问题，在S3DIS和ScanNet上性能优于MM-FSS。


<details>
  <summary>Details</summary>
Motivation: 现有'先融合后精炼'范式存在可塑性-稳定性困境，且CLIP的类间混淆导致语义盲区。

Method: 提出DA-FSS模型，包含并行专家精炼模块（生成模态相关性）、堆叠仲裁模块（卷积融合与相关性仲裁）及解耦对齐模块（在不传播混淆下进行知识迁移）；解耦几何专家（保持可塑性）与语义专家（确保稳定性）。

Result: 在S3DIS和ScanNet数据集上，DA-FSS性能优于MM-FSS；几何边界、完整性与纹理区分能力均强于基线。

Conclusion: DA-FSS通过解耦与协同正则化有效缓解了少样本3D语义分割中的关键挑战，提升了多模态信息利用效率与泛化能力。

Abstract: In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in "Fuse-then-Refine" paradigms: the "Plasticity-Stability Dilemma." In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.

</details>


### [76] [Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation](https://arxiv.org/abs/2601.01457)
*Mingxing Zhan,Li Zhang,Beibei Wang,Yingjie Wang,Zenglin Shi*

Main category: cs.CV

TL;DR: 本文提出了一种利用语言引导的不确定性感知校准方法，通过冻结主干网络和CLIP文本编码器，在逆深度空间中进行图像特定的仿射变换，以恢复单目图像的度量深度。


<details>
  <summary>Details</summary>
Motivation: 单目度量深度估计存在全局尺度不可识别和域偏移敏感等问题，现有相对深度模型虽迁移性好，但难以直接获得准确的度量深度。

Method: 在冻结骨干网络和CLIP文本编码器的前提下，引入图像特定的逆深度仿射变换；利用文本描述预测一个不确定性感知的参数包络（而非点估计），再结合多尺度冻结视觉特征从中选择最优校准参数；训练时采用逆深度空间中的闭式最小二乘oracle提供逐图像监督。

Result: 在NYUv2和KITTI数据集上提升了域内精度，并在SUN-RGBD和DDAD上实现了优于强语言基线的零样本迁移鲁棒性。

Conclusion: 语言可作为粗略但有噪声的尺度线索，结合不确定性建模与视觉特征筛选，能有效提升单目度量深度估计的泛化性和鲁棒性。

Abstract: Relative-depth foundation models transfer well, yet monocular metric depth remains ill-posed due to unidentifiable global scale and heightened domain-shift sensitivity. Under a frozen-backbone calibration setting, we recover metric depth via an image-specific affine transform in inverse depth and train only lightweight calibration heads while keeping the relative-depth backbone and the CLIP text encoder fixed. Since captions provide coarse but noisy scale cues that vary with phrasing and missing objects, we use language to predict an uncertainty-aware envelope that bounds feasible calibration parameters in an unconstrained space, rather than committing to a text-only point estimate. We then use pooled multi-scale frozen visual features to select an image-specific calibration within this envelope. During training, a closed-form least-squares oracle in inverse depth provides per-image supervision for learning the envelope and the selected calibration. Experiments on NYUv2 and KITTI improve in-domain accuracy, while zero-shot transfer to SUN-RGBD and DDAD demonstrates improved robustness over strong language-only baselines.

</details>


### [77] [Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network](https://arxiv.org/abs/2601.01460)
*Mohd Usama,Belal Ahmad,Christer Gronlund,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 本文提出了一种基于GAN的域自适应方法，用于解决超声图像因设备或参数差异导致的纹理和噪声不一致问题，通过图像到图像翻译实现纹理对齐与去噪，显著提升跨设备模型泛化性能。


<details>
  <summary>Details</summary>
Motivation: 医疗影像中不同设备或参数设置产生的超声图像存在纹理和混响噪声差异，违背深度学习训练-测试同分布假设，导致模型跨设备泛化能力差；而为每种设备单独重训练模型成本高、耗时长。

Method: 提出一种新型GAN模型，将域自适应建模为图像到图像翻译任务：在保持图像内容不变前提下，修改源域测试图像的纹理模式并去除混响噪声，使其逼近目标域图像分布。

Result: 在两个含三个域的颈动脉超声数据集上验证有效：成功实现纹理迁移与混响噪声去除；定量评估显示其在直方图相关性（0.960/0.920 vs 0.916/0.890）和Bhattacharya距离（0.040/0.085 vs 0.090/0.121）上均优于无适配及CycleGAN基线。

Conclusion: 所提GAN模型能有效缓解超声图像跨设备域偏移问题，提升模型泛化性，无需重新标注或训练，具备临床实用潜力。

Abstract: Deep learning has been extensively used in medical imaging applications, assuming that the test and training datasets belong to the same probability distribution. However, a common challenge arises when working with medical images generated by different systems or even the same system with different parameter settings. Such images contain diverse textures and reverberation noise that violate the aforementioned assumption. Consequently, models trained on data from one device or setting often struggle to perform effectively with data from other devices or settings. In addition, retraining models for each specific device or setting is labor-intensive and costly. To address these issues in ultrasound images, we propose a novel Generative Adversarial Network (GAN)-based model. We formulated the domain adaptation tasks as an image-to-image translation task, in which we modified the texture patterns and removed reverberation noise in the test data images from the source domain to align with those in the target domain images while keeping the image content unchanged. We applied the proposed method to two datasets containing carotid ultrasound images from three different domains. The experimental results demonstrate that the model successfully translated the texture pattern of images and removed reverberation noise from the ultrasound images. Furthermore, we evaluated the CycleGAN approaches for a comparative study with the proposed model. The experimental findings conclusively demonstrated that the proposed model achieved domain adaptation (histogram correlation (0.960 (0.019), & 0.920 (0.043) and bhattacharya distance (0.040 (0.020), & 0.085 (0.048)), compared to no adaptation (0.916 (0.062) & 0.890 (0.077), 0.090 (0.070) & 0.121 (0.095)) for both datasets.

</details>


### [78] [Robust Ship Detection and Tracking Using Modified ViBe and Backwash Cancellation Algorithm](https://arxiv.org/abs/2601.01481)
*Mohammad Hassan Saghafi,Seyed Majid Noorhosseini,Seyed Abolfazl Seyed Javadein,Hadi Khalili*

Main category: cs.CV

TL;DR: 本文提出了一种鲁棒的实时船舶检测与跟踪方法，改进了ViBe算法以适应沿海动态场景，并引入几何特性和亮度失真概念消除船尾浪，实验证明其具有高精度和实时性。


<details>
  <summary>Details</summary>
Motivation: 沿海场景不可预测且动态变化（如海浪、光照变化），需要更鲁棒的船舶检测方法。

Method: 改进ViBe算法用于运动目标检测（船舶及船尾浪），降低漏检率；结合船舶几何特性与亮度失真概念，提出新的船尾浪消除方法；支持快速背景更新。

Result: 实验表明该方法在船舶检测与跟踪中性能优异，具备实时性和高精度，并对海浪和光照变化具有鲁棒性。

Conclusion: 改进的ViBe与船尾浪消除策略显著提升了沿海视频中船舶检测与跟踪的鲁棒性、实时性与准确性。

Abstract: In this paper, we propose a robust real time detection and tracking method for detecting ships in a coastal video sequences. Since coastal scenarios are unpredictable and scenes have dynamic properties it is essential to apply detection methods that are robust to these conditions. This paper presents modified ViBe for moving object detection which detects ships and backwash. In the modified ViBe the probability of losing ships is decreased in comparison with the original ViBe. It is robust to natural sea waves and variation of lights and is capable of quickly updating the background. Based on geometrical properties of ship and some concepts such as brightness distortion, a new method for backwash cancellation is proposed. Experimental results demonstrate that the proposed strategy and methods have outstanding performance in ship detection and tracking. These results also illustrate real time and precise performance of the proposed strategy.

</details>


### [79] [Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization](https://arxiv.org/abs/2601.01483)
*Xinyu Qiu,Heng Jia,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Yi Yang,Linchao Zhu*

Main category: cs.CV

TL;DR: 本文提出ADPO框架，通过统一的强化学习方法在单一策略中联合学习答案生成与自我验证，显著提升验证准确率并降低推理时间。


<details>
  <summary>Details</summary>
Motivation: 现有并行测试时扩展方法需分别训练生成和验证模型，导致高昂的训练和推理成本。

Method: ADPO引入偏好验证奖励（基于正负样本均值设定决策阈值）和解耦优化机制（分别计算生成与验证优势、使用token掩码隔离梯度、组合掩码GRPO目标）。

Result: ADPO在验证AUC上提升34.1%，推理时间降低53.5%；在MathVista/MMMU准确率分别提升2.8%/1.4%，ReasonSeg的cIoU提升1.9，AndroidControl/GUI Odyssey的步骤成功率提升1.7%/1.0%。

Conclusion: ADPO实现了生成与验证能力的协同优化，在多项基准上显著优于现有方法，兼具高效性与有效性。

Abstract: Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey.

</details>


### [80] [Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease](https://arxiv.org/abs/2601.01485)
*Zobia Batool,Diala Lteif,Vijaya B. Kolachalama,Huseyin Ozkan,Erchan Aptoula*

Main category: cs.CV

TL;DR: 本文提出Extended MixStyle (EM)框架，通过融合高阶特征矩（偏度和峰度）来模拟多样化的分布变化，以提升阿尔茨海默病（AD）在不同数据域间的泛化能力；在NACC数据集上训练并在三个未见队列上测试，EM在宏观F1分数上平均提升2.4个百分点，优于现有单域泛化方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于sMRI的AD深度学习模型因扫描设备、采集协议和人群差异导致域偏移，在新队列上泛化性差；而AD诊断亟需鲁棒、可泛化的分类方法，且单域泛化（SDG）在碎片化AD数据背景下尚未被充分探索。

Method: 提出Extended MixStyle（EM）框架，通过混合高阶特征矩（偏度和峰度）来模拟不同数据分布的变化，增强模型对域偏移的鲁棒性；在NACC sMRI数据集（n=4,647）上训练，区分正常认知（NC）、轻度认知障碍（MCI）和AD，并在三个独立外部队列（n=3,126）上验证。

Result: EM在三个未见队列上的跨域宏观F1分数平均提升2.4个百分点，显著优于当前最优单域泛化基准方法。

Conclusion: EM有效提升了AD诊断模型在异构真实场景下的不变性与可靠性，为单域泛化这一关键但被忽视的方向提供了可行方案。

Abstract: Despite progress in deep learning for Alzheimer's disease (AD) diagnostics, models trained on structural magnetic resonance imaging (sMRI) often do not perform well when applied to new cohorts due to domain shifts from varying scanners, protocols and patient demographics. AD, the primary driver of dementia, manifests through progressive cognitive and neuroanatomical changes like atrophy and ventricular expansion, making robust, generalizable classification essential for real-world use. While convolutional neural networks and transformers have advanced feature extraction via attention and fusion techniques, single-domain generalization (SDG) remains underexplored yet critical, given the fragmented nature of AD datasets. To bridge this gap, we introduce Extended MixStyle (EM), a framework for blending higher-order feature moments (skewness and kurtosis) to mimic diverse distributional variations. Trained on sMRI data from the National Alzheimer's Coordinating Center (NACC; n=4,647) to differentiate persons with normal cognition (NC) from those with mild cognitive impairment (MCI) or AD and tested on three unseen cohorts (total n=3,126), EM yields enhanced cross-domain performance, improving macro-F1 on average by 2.4 percentage points over state-of-the-art SDG benchmarks, underscoring its promise for invariant, reliable AD detection in heterogeneous real-world settings. The source code will be made available upon acceptance at https://github.com/zobia111/Extended-Mixstyle.

</details>


### [81] [DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion](https://arxiv.org/abs/2601.01487)
*Ziyue Zhang,Luxi Lin,Xiaolin Hu,Chao Chang,HuaiXi Wang,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: 本文提出了一种自监督的可训练扩散逆向方法DeepInv，通过自监督目标和数据增强生成高质量伪噪声，实现快速准确的图像到噪声映射。


<details>
  <summary>Details</summary>
Motivation: 现有扩散逆向方法缺乏有效监督信号，多依赖近似解，导致性能或效率受限。

Method: 提出自监督目标与数据增强策略生成伪噪声，并设计迭代多尺度训练机制训练参数化解析器。

Result: 在COCO数据集上SSIM比EasyInv提升40.435%，推理速度比ReNoise快9887.5%。

Conclusion: DeepInv是首个逐步预测逆向噪声的可训练求解器，显著提升性能与效率，并为社区提供新思路。

Abstract: Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.

</details>


### [82] [DiffKD-DCIS: Predicting Upgrade of Ductal Carcinoma In Situ with Diffusion Augmentation and Knowledge Distillation](https://arxiv.org/abs/2601.01507)
*Tao Li,Qing Li,Na Li,Hui Xie*

Main category: cs.CV

TL;DR: 本文提出DiffKD-DCIS框架，结合条件扩散模型与师生知识蒸馏，提升DCIS向IDC升级的超声预测准确率，兼顾泛化性与计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在DCIS向IDC升级预测中受限于超声数据稀缺和泛化能力差。

Method: 提出三阶段DiffKD-DCIS框架：1）条件扩散模型基于多模态条件生成高保真超声图像用于数据增强；2）深层教师网络从原始与合成数据中提取鲁棒特征；3）轻量学生网络通过知识蒸馏学习教师模型。

Result: 在1435例多中心数据上验证，合成图像质量良好；学生网络参数更少、推理更快；在外部队列中性能优于部分组合方法，准确率媲美高年资放射科医生、优于低年资医生。

Conclusion: DiffKD-DCIS框架有效缓解数据不足与模型泛化难题，在临床DCIS升级风险评估中展现出显著应用潜力。

Abstract: Accurately predicting the upgrade of ductal carcinoma in situ (DCIS) to invasive ductal carcinoma (IDC) is crucial for surgical planning. However, traditional deep learning methods face challenges due to limited ultrasound data and poor generalization ability. This study proposes the DiffKD-DCIS framework, integrating conditional diffusion modeling with teacher-student knowledge distillation.
  The framework operates in three stages: First, a conditional diffusion model generates high-fidelity ultrasound images using multimodal conditions for data augmentation. Then, a deep teacher network extracts robust features from both original and synthetic data. Finally, a compact student network learns from the teacher via knowledge distillation, balancing generalization and computational efficiency.
  Evaluated on a multi-center dataset of 1,435 cases, the synthetic images were of good quality. The student network had fewer parameters and faster inference. On external test sets, it outperformed partial combinations, and its accuracy was comparable to senior radiologists and superior to junior ones, showing significant clinical potential.

</details>


### [83] [A Novel Deep Learning Method for Segmenting the Left Ventricle in Cardiac Cine MRI](https://arxiv.org/abs/2601.01512)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.CV

TL;DR: 本文提出了一种新型深度学习网络GBU-Net，基于分组批归一化的U-Net框架，专为短轴电影MRI中左心室的精确语义分割而设计，显著提升了分割精度与上下文理解能力。


<details>
  <summary>Details</summary>
Motivation: 提升短轴 cine MRI 中左心室语义分割的精度与上下文理解能力，以支持手术机器人和医学分析等临床应用。

Method: 构建了基于分组批归一化（Group-Batch-Normalization）的U-Net架构，包含特征提取的下采样路径和细节恢复的上采样路径，并针对心脏MRI特点优化上下文建模。

Result: 在SunnyBrook测试集上，GBU-Net集成模型达到97%的Dice分数，在Dice系数和平均垂直距离等指标上优于现有方法。

Conclusion: GBU-Net通过增强的上下文感知能力和结构创新，显著提高了左心室分割的准确性和鲁棒性，适用于临床精准医疗场景。

Abstract: This research aims to develop a novel deep learning network, GBU-Net, utilizing a group-batch-normalized U-Net framework, specifically designed for the precise semantic segmentation of the left ventricle in short-axis cine MRI scans. The methodology includes a down-sampling pathway for feature extraction and an up-sampling pathway for detail restoration, enhanced for medical imaging. Key modifications include techniques for better contextual understanding crucial in cardiac MRI segmentation. The dataset consists of 805 left ventricular MRI scans from 45 patients, with comparative analysis using established metrics such as the dice coefficient and mean perpendicular distance. GBU-Net significantly improves the accuracy of left ventricle segmentation in cine MRI scans. Its innovative design outperforms existing methods in tests, surpassing standard metrics like the dice coefficient and mean perpendicular distance. The approach is unique in its ability to capture contextual information, often missed in traditional CNN-based segmentation. An ensemble of the GBU-Net attains a 97% dice score on the SunnyBrook testing dataset. GBU-Net offers enhanced precision and contextual understanding in left ventricle segmentation for surgical robotics and medical analysis.

</details>


### [84] [FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01513)
*Gen Li,Peiyu Liu*

Main category: cs.CV

TL;DR: 本文提出VideoSpeculateRAG，一种结合推测解码与检索增强的高效视觉语言模型框架，通过轻量草案模型生成候选答案并由重型模型验证，同时引入基于相似度的知识实体过滤策略，显著提升推理速度（约2倍）与答案准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在整合外部知识方面仍存在不足，而当前检索增强生成（RAG）方法效率低且答案质量不稳定。

Method: 提出VideoSpeculateRAG框架：1）采用推测解码流水线，用轻量草案模型快速生成多个候选答案，再由高精度重型模型验证与精修；2）设计基于相似度的检索知识实体过滤策略，缓解因错误实体识别导致的误差。

Result: 实验表明，VideoSpeculateRAG在准确率上达到或超过标准RAG方法，同时推理速度提升约2倍。

Conclusion: 推测解码与检索增强推理的结合，可有效提升知识密集型多模态任务的效率与可靠性。

Abstract: Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.

</details>


### [85] [BARE: Towards Bias-Aware and Reasoning-Enhanced One-Tower Visual Grounding](https://arxiv.org/abs/2601.01526)
*Hongbing Li,Linhui Xiao,Zihan Zhao,Qi Shen,Yixiang Huang,Bo Xiao,Zhanyu Ma*

Main category: cs.CV

TL;DR: 本文提出BARE框架，通过保留模态特异性特征和构建指代语义，解决单塔视觉定位中的模态偏差和语义推理不足问题，实现SOTA性能与更高计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有单塔视觉定位方法存在模态表征过度耦合导致的欺骗性模态偏差，以及指代线索理解不足的语义推理缺陷。

Method: BARE框架包含三个新模块：语言显著性调制器、视觉偏差校正模块和指代关系增强模块，以分别缓解多模态干扰并增强指代理解。

Result: 在五个基准上实验表明，BARE不仅达到当前最优性能，还比现有方法具有更高的计算效率。

Conclusion: BARE是一种兼顾偏差感知与推理增强的单塔视觉定位新范式，有效提升了定位精度与效率。

Abstract: Visual Grounding (VG), which aims to locate a specific region referred to by expressions, is a fundamental yet challenging task in the multimodal understanding fields. While recent grounding transfer works have advanced the field through one-tower architectures, they still suffer from two primary limitations: (1) over-entangled multimodal representations that exacerbate deceptive modality biases, and (2) insufficient semantic reasoning that hinders the comprehension of referential cues. In this paper, we propose BARE, a bias-aware and reasoning-enhanced framework for one-tower visual grounding. BARE introduces a mechanism that preserves modality-specific features and constructs referential semantics through three novel modules: (i) language salience modulator, (ii) visual bias correction and (iii) referential relationship enhancement, which jointly mitigate multimodal distractions and enhance referential comprehension. Extensive experimental results on five benchmarks demonstrate that BARE not only achieves state-of-the-art performance but also delivers superior computational efficiency compared to existing approaches. The code is publicly accessible at https://github.com/Marloweeee/BARE.

</details>


### [86] [Improving Flexible Image Tokenizers for Autoregressive Image Generation](https://arxiv.org/abs/2601.01535)
*Zixuan Fu,Lanqing Guo,Chong Wang,Binbin Song,Ding Liu,Bihan Wen*

Main category: cs.CV

TL;DR: 本文提出ReToK，一种通过冗余令牌填充和分层语义正则化改进的灵活图像分词器，以解决现有嵌套丢弃方法中信息过度集中在前序令牌的问题，从而提升自回归图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于嵌套丢弃的灵活图像分词器将图像信息过度集中于前序令牌，限制了长序列下自回归图像生成的效果。

Method: 提出ReToK：1）冗余令牌填充，提高尾部令牌激活频率；2）分层语义正则化，使前序令牌解码特征对齐预训练视觉基础模型，并向尾部逐步减弱正则强度以保留低级细节。

Result: 在ImageNet 256×256上，ReToK在生成性能上优于现有灵活与固定长度分词器。

Conclusion: ReToK通过更均衡地利用全部令牌，显著提升了灵活分词器在自回归图像生成任务中的表现。

Abstract: Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \textbf{ReToK}, a flexible tokenizer with \underline{Re}dundant \underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}

</details>


### [87] [FAR-AMTN: Attention Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01537)
*Gong Gao,Zekai Wang,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: 本文提出FAR-AMTN，一种用于人脸属性识别的注意力多任务网络，通过权重共享组特定注意力（WSGSA）模块、跨组特征融合（CGFF）模块和动态加权策略（DWS）提升泛化性能，同时减少参数量。


<details>
  <summary>Details</summary>
Motivation: 传统多任务网络在人脸属性识别中存在参数爆炸和高层特征交互受限问题，影响泛化能力。

Method: 提出FAR-AMTN，包含权重共享组特定注意力（WSGSA）模块以降低复杂度并增强组内表征，跨组特征融合（CGFF）模块促进属性组间交互，以及动态加权策略（DWS）实现任务同步收敛。

Result: 在CelebA和LFWA数据集上，FAR-AMTN在显著更少参数下实现了更高精度。

Conclusion: FAR-AMTN有效提升了多任务学习在人脸属性识别中的泛化性能与效率，为轻量高效多任务建模提供了新思路。

Abstract: To enhance the generalization performance of Multi-Task Networks (MTN) in Face Attribute Recognition (FAR), it is crucial to share relevant information across multiple related prediction tasks effectively. Traditional MTN methods create shared low-level modules and distinct high-level modules, causing an exponential increase in model parameters with the addition of tasks. This approach also limits feature interaction at the high level, hindering the exploration of semantic relations among attributes, thereby affecting generalization negatively. In response, this study introduces FAR-AMTN, a novel Attention Multi-Task Network for FAR. It incorporates a Weight-Shared Group-Specific Attention (WSGSA) module with shared parameters to minimize complexity while improving group feature representation. Furthermore, a Cross-Group Feature Fusion (CGFF) module is utilized to foster interactions between attribute groups, enhancing feature learning. A Dynamic Weighting Strategy (DWS) is also introduced for synchronized task convergence. Experiments on the CelebA and LFWA datasets demonstrate that the proposed FAR-AMTN demonstrates superior accuracy with significantly fewer parameters compared to existing models.

</details>


### [88] [EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding](https://arxiv.org/abs/2601.01547)
*Tianjun Gu,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: 本文提出了Teleo-Spatial Intelligence（TSI）新范式，融合物理动力学推理与意图驱动推理，并构建了EscherVerse基准（含Escher-Bench、Escher-35k数据集和Escher系列模型）以推动空间智能向目的驱动理解发展。


<details>
  <summary>Details</summary>
Motivation: 现有空间动态推理研究忽视人类意图，缺乏对人类目标驱动的空间变化建模能力。

Method: 提出TSI范式，构建基于真实视频的开放世界基准EscherVerse，包括大规模基准Escher-Bench、数据集Escher-35k及对应模型Escher系列，并设计新型数据清洗流程。

Result: EscherVerse是首个系统评估意图驱动推理的基准，能评估物体永久性、状态迁移与轨迹预测，并连接物理事件与其人类目的。

Conclusion: TSI范式及EscherVerse为实现从被动场景描述到主动目的驱动空间理解提供了基础支撑。

Abstract: The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.

</details>


### [89] [Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation](https://arxiv.org/abs/2601.01593)
*Haonan Cai,Yuxuan Luo,Zhouhui Lian*

Main category: cs.CV

TL;DR: 本文提出了GAR-Font，一种用于多模态少样本字体生成的新型自回归框架，通过全局感知分词器、多模态风格编码器和后精炼流程，显著提升了字体生成中结构完整性与风格保真度。


<details>
  <summary>Details</summary>
Motivation: 现有少样本字体生成方法在保持结构完整性和风格保真度方面存在不足，且忽视语言对风格意图表达的作用；传统自回归模型受限于局部patch分词，缺乏全局依赖建模能力。

Method: 提出GAR-Font框架，包含：1）全局感知分词器，兼顾局部结构与全局风格；2）轻量级语言-风格适配器驱动的多模态风格编码器，无需大规模多模态预训练；3）后精炼流程提升结构与风格一致性。

Result: 在多个基准上超越现有少样本字体生成方法，尤其在全局风格忠实性和文本引导下的生成质量方面表现更优。

Conclusion: GAR-Font验证了结合全局建模与多模态（图像+文本）引导对少样本字体生成的有效性，为高质量、可控字体合成提供了新范式。

Abstract: Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.

</details>


### [90] [Guiding Token-Sparse Diffusion Models](https://arxiv.org/abs/2601.01608)
*Felix Krause,Stefan Andreas Baumann,Johannes Schusterbauer,Olga Grebenkova,Ming Gui,Vincent Tao Hu,Björn Ommer*

Main category: cs.CV

TL;DR: 本文提出Sparse Guidance (SG)方法，通过在推理阶段采用token-level稀疏性替代传统的Classifier-free Guidance，提升扩散模型的生成质量与效率。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏训练的扩散模型在推理时对Classifier-free Guidance响应不足，导致性能不佳。

Method: 提出Sparse Guidance (SG)，利用token-level稀疏性作为引导信号，保留条件预测的高方差特性，并在推理中应用该策略。

Result: 在ImageNet-256上达到1.58 FID，计算量减少25%；同等质量下最高节省58% FLOPs；在2.5B文本到图像模型上提升构图质量、人类偏好得分及吞吐量。

Conclusion: Sparse Guidance是一种高效、高质量的扩散模型推理引导方法，兼顾性能提升与计算效率。

Abstract: Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.

</details>


### [91] [CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment](https://arxiv.org/abs/2601.01613)
*Kazi Ramisa Rifa,Jie Zhang,Abdullah Imran*

Main category: cs.CV

TL;DR: 本文提出了一种上下文感知的提示引导CT图像质量评估框架（CAP-IQA），通过融合放射科风格文本提示与实例级上下文提示，并引入因果去偏机制，提升在真实退化场景下的评估鲁棒性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的CT图像质量评估方法易受理想化文本先验偏差影响，难以应对真实临床中噪声、运动伪影和设备差异等复杂退化。

Method: 提出CAP-IQA框架：结合CNN视觉编码器与领域文本编码器；设计上下文感知提示融合模块；引入因果去偏机制分离理想先验与图像特异性退化；采用放射科风格提示指导诊断可见性、解剖清晰度与噪声感知评估。

Result: 在2023 LDCTIQA挑战赛基准上总相关性得分达2.8590，超越榜首团队4.24%；在自建91,514例儿童CT数据集上验证了跨人群泛化能力；消融实验证明提示融合与纯编码器结构共同提升特征对齐与可解释性。

Conclusion: CAP-IQA有效缓解了文本先验偏差问题，在多源退化与不同人群下展现出更强的鲁棒性、泛化性与临床适用性，为医学图像质量评估提供了新范式。

Abstract: Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.

</details>


### [92] [An Empirical Study of Monocular Human Body Measurement Under Weak Calibration](https://arxiv.org/abs/2601.01639)
*Gaurav Sekar*

Main category: cs.CV

TL;DR: 本文对三种弱校准单目策略（基于关键点的几何法、姿态驱动回归法、物体校准轮廓法）进行了系统性实证研究，分析其在校准假设差异下的测量行为、鲁棒性与失效模式，揭示了用户校准努力程度与围度测量稳定性之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 解决单目RGB图像中人体尺寸估计面临的尺度模糊、视角敏感及缺乏显式深度信息等挑战，并探索不同弱校准假设对测量性能的影响。

Method: 对三种弱校准单目策略——基于关键点的几何方法、姿态驱动回归方法和物体校准轮廓方法——在半约束条件下使用消费级相机进行系统性实证评估。

Result: 发现用户校准投入与围度测量稳定性之间存在明显权衡；不同策略在不同体型下表现出差异化的鲁棒性与失效模式。

Conclusion: 该研究为面向消费设备部署的轻量级单目人体测量系统提供了实证设计参考，强调校准策略选择需兼顾实用性与稳定性。

Abstract: Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.

</details>


### [93] [Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows](https://arxiv.org/abs/2601.01660)
*Aymen Mir,Riza Alp Guler,Jian Wang,Gerard Pons-Moll,Bing Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种用于3D高斯泼溅（3DGS）动态场景中实现一致光照与阴影的方法，核心是深度高斯阴影图（DGSM）和基于球谐函数（SH）的快速重光照技术，全程在体素化3DGS表示中完成，无需网格化。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在动态交互（如动画角色与场景/物体互动）中难以实现一致的光照和阴影效果，尤其缺乏适用于无网格、体素化表示的实时阴影计算方案。

Method: 提出Deep Gaussian Shadow Maps（DGSM），利用3DGS沿光线的闭式光累积特性，在同心径向壳层上查表存储透射率，并以八面体图集形式存储；结合球谐函数（SH）表示的HDR环境光探针，实现高斯粒度的快速辐射度传递，避免BRDF估计或离线优化。

Result: 在AvatarX、ActorsHQ等数据集及ScanNet++、DL3DV、SuperSplat等场景中验证了单/多avatar与动态物体交互下的实时、一致阴影与重光照效果，全程保持纯3DGS表示，无需网格转换。

Conclusion: DGSM与SH重光照共同构成首个完全基于3DGS体素表示的实时、一致光照-阴影框架，显著提升了动态3D内容合成的真实感与实用性。

Abstract: We present a method for consistent lighting and shadows when animated 3D Gaussian Splatting (3DGS) avatars interact with 3DGS scenes or with dynamic objects inserted into otherwise static scenes. Our key contribution is Deep Gaussian Shadow Maps (DGSM), a modern analogue of the classical shadow mapping algorithm tailored to the volumetric 3DGS representation. Building on the classic deep shadow mapping idea, we show that 3DGS admits closed form light accumulation along light rays, enabling volumetric shadow computation without meshing. For each estimated light, we tabulate transmittance over concentric radial shells and store them in octahedral atlases, which modern GPUs can sample in real time per query to attenuate affected scene Gaussians and thus cast and receive shadows consistently. To relight moving avatars, we approximate the local environment illumination with HDRI probes represented in a spherical harmonic (SH) basis and apply a fast per Gaussian radiance transfer, avoiding explicit BRDF estimation or offline optimization. We demonstrate environment consistent lighting for avatars from AvatarX and ActorsHQ, composited into ScanNet++, DL3DV, and SuperSplat scenes, and show interactions with inserted objects. Across single and multi avatar settings, DGSM and SH relighting operate fully in the volumetric 3DGS representation, yielding coherent shadows and relighting while avoiding meshing.

</details>


### [94] [LabelAny3D: Label Any Object 3D in the Wild](https://arxiv.org/abs/2601.01676)
*Jin Yao,Radowan Mahmud Redoy,Sebastian Elbaum,Matthew B. Dwyer,Zezhou Cheng*

Main category: cs.CV

TL;DR: 本文提出LabelAny3D框架，通过分析-合成方法从单张2D图像重建完整3D场景以高效生成高质量3D标注，并基于此构建了覆盖开放词汇的COCO3D新基准；实验证明其生成的标注显著提升单目3D检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测模型在野外（in-the-wild）图像上表现不佳，主要受限于缺乏野外3D数据集及3D标注困难。

Method: 提出LabelAny3D——一种基于分析-合成（analysis-by-synthesis）的框架，从单张2D图像重建整体3D场景并自动生成高质3D包围框标注；并据此构建COCO3D新基准（源自MS-COCO，支持开放词汇和多样化物体类别）。

Result: LabelAny3D生成的标注在多个基准上提升了单目3D检测性能，且质量优于先前自动标注方法。

Conclusion: 基于基础模型驱动的标注范式有望推动真实开放世界中3D识别的大规模扩展。

Abstract: Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.

</details>


### [95] [Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada](https://arxiv.org/abs/2601.01677)
*Zhengsen Xu,Lanying Wang,Sibo Cheng,Xue Rui,Kyle Gao,Yimin Zhu,Mabel Heffring,Zack Dewis,Saeid Taleghanidoozdoozan,Megan Greenwood,Motasem Alkayid,Quinn Ledingham,Hongjie He,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于长序列、多尺度时间建模的可信数据驱动野火风险预测框架，整合异构驱动因子，显式量化预测不确定性并支持过程级解释，在2023–2024年加拿大西部极端火灾季中表现优异（F1=0.90，PR-AUC=0.98），并借助SHAP揭示了温度主导与湿度调控的年际差异机制。


<details>
  <summary>Details</summary>
Motivation: 现有纯数据驱动模型因野火点火与蔓延的内在随机性，以及燃料、气象、气候、地形和人为活动等非线性交互，导致可靠性与可解释性不足，亟需兼具不确定性量化与物理机制理解能力的预测框架。

Method: 构建长序列、多尺度时间建模框架，融合异构驱动因子；引入不确定性量化模块；采用SHAP进行归因解释；在2023–2024年加拿大西部极端火灾季开展评估。

Result: 在2023和2024年加拿大西部火灾季测试中，F1达0.90、PR-AUC达0.98，计算成本低；不确定性分析揭示空间与季节性置信结构；SHAP分析表明温度相关因子主导风险，而湿度相关约束在2024年对空间与地类差异影响更强。

Conclusion: 该框架在预测性能、不确定性表征与可解释性三方面取得统一提升，为高风险区野火管理提供兼具精度与决策支持能力的工具。

Abstract: In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.

</details>


### [96] [Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages](https://arxiv.org/abs/2601.01680)
*Afzal Hossain,Mst Rumana Sumi,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 本研究评估了FaceNet、ArcFace、MagFace和CosFace四种深度学习模型在0-3岁婴幼儿纵向面部数据集上的识别性能，发现婴儿期（0-6个月）识别率低（TAR仅30.7%），随年龄增长显著提升，并提出DANN方法缓解时间漂移，提升TAR超12%，对智慧城市的儿童生物识别应用具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 婴幼儿面部识别面临形态快速变化、类间相似度高及数据稀缺等挑战，亟需系统性评估现有模型性能并探索适应时间变化的鲁棒方法。

Method: 在覆盖0–3岁、历时24个月、共7次采集的纵向婴幼儿面部数据集上，评估FaceNet、ArcFace、MagFace和CosFace的识别与验证性能；分析不同年龄段和时间间隔下的准确率变化；引入Domain Adversarial Neural Network（DANN）缓解嵌入漂移。

Result: 0–6月龄婴儿在0.1% FAR下TAR仅为30.7%，2.5–3岁组达64.7%；短时间间隔验证准确率更高；DANN方法使TAR提升超12%，增强特征时序稳定性与泛化性。

Conclusion: 当前主流模型在婴幼儿早期阶段性能受限，DANN可有效缓解时间漂移问题；研究结果为面向智慧城市的儿童健康、安全与数字身份等应用场景提供关键技术支撑，并呼吁发展兼顾隐私保护与时间鲁棒性的婴幼儿生物认证系统。

Abstract: Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential.

</details>


### [97] [FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation](https://arxiv.org/abs/2601.01687)
*Abdur R. Fayjie,Pankhi Kashyap,Jutika Borah,Patrick Vandewalle*

Main category: cs.CV

TL;DR: FALCON是一种跨域少样本3D医学图像分割框架，通过2D切片处理、元训练与对抗微调，在标注数据极少、无数据增强、计算开销低的情况下，实现高边界精度（最低Hausdorff距离）和媲美SOTA的Dice分数。


<details>
  <summary>Details</summary>
Motivation: 临床可用的3D医学图像分割受限于3D标注稀缺、患者个体差异大、数据隐私问题及高计算开销。

Method: 提出FALCON框架：先在自然图像上元训练以学习通用分割先验；再通过对抗微调和边界感知学习迁移到医学领域；最后利用任务感知推理，结合支持样本线索动态适配患者特异性解剖变化。所有处理基于2D切片而非完整3D体积。

Result: 在四个基准测试中，FALCON持续取得最低Hausdorff距离（边界精度最优），Dice相似系数与当前最优模型相当；且仅需极少量标注数据、无需数据增强、计算开销显著降低。

Conclusion: FALCON验证了基于2D切片的跨域少样本学习范式在3D医学分割中的有效性，兼顾高精度、低标注依赖与低计算成本，具备临床落地潜力。

Abstract: Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.

</details>


### [98] [Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data](https://arxiv.org/abs/2601.01689)
*Afzal Hossain,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 本文探讨了使用合成面部数据来增强儿童纵向人脸识别模型的时间鲁棒性，实验表明在训练中加入经筛选的StyleGAN2 ADA生成的合成人脸数据，可显著降低6至36个月验证间隔下的识别错误率。


<details>
  <summary>Details</summary>
Motivation: 儿童面部随年龄快速非线性变化导致模板漂移和验证错误增加，现有方法难以保障长期识别稳定性。

Method: 在YFA数据集上采用身份不重叠协议，对比三种设置：（i）直接使用预训练MagFace嵌入；（ii）仅用真实儿童面部数据微调MagFace；（iii）用真实+经滤波处理的StyleGAN2 ADA合成数据联合微调；合成数据仅用于训练身份，并通过后处理过滤以防止身份泄露和伪影样本。

Result: 合成数据增强的微调方案在6–36个月的注册-验证时间间隔下，显著降低了错误率，优于预训练基线和仅用真实数据微调的方法。

Conclusion: 合成数据可作为纵向稳定器提升儿童人脸识别的身份持久性，该方法在风险可控前提下具备实用潜力。

Abstract: Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.

</details>


### [99] [Learnability-Driven Submodular Optimization for Active Roadside 3D Detection](https://arxiv.org/abs/2601.01695)
*Ruiyu Mao,Baoming Zhang,Nicholas Ruozzi,Yunhui Guo*

Main category: cs.CV

TL;DR: 本文提出了一种面向路侧单目3D目标检测的可学习性驱动主动学习框架LH3D，旨在筛选出信息丰富且可可靠标注的场景，避免标注本质上模糊（inherently ambiguous）的样本，从而在有限标注预算下提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 真实部署中常仅有路侧单视角数据，缺乏车载视图辅助标注，导致许多远处、模糊或遮挡目标的3D属性难以准确标注，形成‘本质上模糊’样本，造成标注困难、成本高及模型学习瓶颈。

Method: 提出LH3D框架，基于可学习性（learnability）而非不确定性进行主动采样，联合评估样本的信息量与可标注可靠性，抑制 inherently ambiguous 样本，保障场景覆盖。

Result: 在DAIR-V2X-I数据集上仅用25%标注预算，LH3D对车辆、行人、自行车检测分别达到全量标注性能的86.06%、67.32%和78.67%，显著优于基于不确定性的基线方法。

Conclusion: 在路侧3D感知任务中，样本的可学习性比预测不确定性更能指导高效标注；LH3D验证了通过建模可学习性可显著提升主动学习效率与模型性能。

Abstract: Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.

</details>


### [100] [FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing](https://arxiv.org/abs/2601.01720)
*Xijie Huang,Chengming Xu,Donghao Luo,Xiaobin Hu,Peng Tang,Xu Peng,Jiangning Zhang,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: 本文提出FFP-300K大规模高质量视频数据集与无需运行时引导的首帧传播（FFP）新框架，通过AST-RoPE架构和自蒸馏策略，在保持首帧外观与源视频运动间取得平衡，显著提升视频编辑性能。


<details>
  <summary>Details</summary>
Motivation: 现有首帧传播（FFP）方法依赖繁琐的运行时引导，根本原因在于训练数据集规模小、分辨率低、时长不足且任务多样性差，难以学习鲁棒的时间先验。

Method: 构建FFP-300K数据集（30万对720p、81帧高清视频对），提出指导自由的FFP框架；引入自适应时空RoPE（AST-RoPE）解耦外观与运动参考；采用以恒等传播为任务的自蒸馏策略增强长期时间稳定性。

Result: 在EditVerseBench基准上显著优于现有学术与商用模型，PickScore提升约0.2，VLM Score提升约0.3。

Conclusion: 高质量数据是推动FFP发展的关键基础，所提数据集与框架共同实现了真正指导自由、高保真、长时稳定的可控视频编辑。

Abstract: First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.

</details>


### [101] [Point-SRA: Self-Representation Alignment for 3D Representation Learning](https://arxiv.org/abs/2601.01746)
*Lintong Wei,Jian Lu,Haozhe Cheng,Jihua Zhu,Kaibing Zhang*

Main category: cs.CV

TL;DR: 本文提出Point-SRA方法，通过自蒸馏与概率建模提升3D点云表征学习性能，采用多掩码比MAE、MeanFlow Transformer（MFT）及双层自表征对齐机制，在多个下游任务上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法使用固定掩码比，忽视多级表征关联与点云内在几何结构，且点对点重建假设与点云多样性相冲突。

Method: 提出Point-SRA：1）为MAE分配不同掩码比以捕获互补几何与语义信息；2）引入MeanFlow Transformer（MFT），利用跨模态条件嵌入实现多样化概率重建；3）设计Dual Self-Representation Alignment机制，在MAE和MFT两层对齐表征；4）构建Flow-Conditioned Fine-Tuning架构，充分利用MeanFlow学习的点云分布。

Result: 在ScanObjectNN上超越Point-MAE 5.37%；颅内动脉瘤分割中，动脉平均IoU达96.07%，动脉瘤达86.87%；3D目标检测AP@50达47.3%，优于MaskPoint 5.12%。

Conclusion: Point-SRA通过多粒度掩码策略、概率化重建与双层表征对齐，有效建模点云几何与语义多样性，在多种3D理解任务中取得显著性能提升。

Abstract: Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.

</details>


### [102] [MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement](https://arxiv.org/abs/2601.01749)
*Lei Zhu,Lijian Lin,Ye Zhu,Jiahao Wu,Xuehan Hou,Yu Li,Yunfei Liu,Jie Chen*

Main category: cs.CV

TL;DR: 本文提出MANGO框架，通过两阶段训练（扩散Transformer建模多说话人3D运动 + 3D高斯渲染器提供2D光度监督）实现高保真、自然的双向音频驱动3D对话头生成，并发布高质量多身份对话数据集MANGO-Dialog。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动3D头生成方法局限于单说话人，缺乏自然双向听-说交互；且依赖有噪声的伪3D标签，难以建模精细面部动态。

Method: 提出两阶段MANGO框架：第一阶段用带双音频交互模块的扩散Transformer建模多说话人3D运动；第二阶段用快速3D高斯渲染器生成图像并提供2D光度监督，交替训练以抑制伪3D标签噪声；同时构建MANGO-Dialog数据集（50+小时、500+身份的2D-3D对齐对话数据）。

Result: 在双人3D对话运动建模上取得卓越精度与真实感，显著提升音频驱动说话头的保真度与可控性。

Conclusion: MANGO通过纯图像级监督与交替训练策略，有效克服伪3D标签缺陷，实现了更贴近真实世界对话行为的3D头生成，为多角色交互式虚拟人提供了新范式。

Abstract: Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.

</details>


### [103] [CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology](https://arxiv.org/abs/2601.01769)
*Hao Lu,Ziniu Qian,Yifu Li,Yang Zhou,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于临床诊断模板的病理信息结构化提取流程，构建了CTIS-Align数据集和CTIS-Bench评测基准，并设计了双流架构的CTIS-QA模型，在WSI视觉问答与诊断任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像分析方法缺乏对病理报告中标准化、结构化信息的有效利用，且视觉-语言对齐数据与临床实际诊断流程脱节，亟需面向真实诊断场景的高质量数据与模型。

Method: 基于CAP癌症协议设计临床病理报告模板（CPRT），系统提取TCGA-BRCA病理报告特征；构建CTIS-Align（8万图文对）与CTIS-Bench（977张WSI、1.4万QA对）；提出CTIS-QA双流模型：全局聚类特征聚合流 + 注意力引导的局部补丁感知流。

Result: CTIS-QA在WSI-VQA、CTIS-Bench及滑片级诊断任务上全面超越现有SOTA模型；CTIS-Bench强调临床相关、闭合式、少推理依赖的问答，提升模型对真实病理理解能力。

Conclusion: 基于模板驱动的信息结构化是连接病理文本与WSI视觉理解的有效范式；CTIS系列资源与CTIS-QA模型为可解释、临床可信的AI辅助病理诊断提供了新基础。

Abstract: In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.

</details>


### [104] [Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery](https://arxiv.org/abs/2601.01781)
*Lakshay Sharma,Alex Marin*

Main category: cs.CV

TL;DR: 本文提出了一种名为子图像重叠预测（Subimage Overlap Prediction）的新型自监督预训练任务，专为遥感图像语义分割设计，仅需少量预训练图像即可实现更快收敛和更优或相当的下游性能（mIoU），尤其在标注数据受限时优势更明显。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法通常依赖大量预训练数据，而遥感图像获取和标注成本高，亟需一种低数据需求、高效适配语义分割任务的自监督预训练方法。

Method: 给定一张图像，随机提取一个子图像，模型被训练以预测该子图像在原图中的空间位置（即生成对应语义掩码），从而学习图像的空间结构与语义一致性。

Result: 该方法在多个网络架构和下游数据集上均显著加快收敛速度，并在mIoU指标上达到等于或优于现有SSL方法的性能；当标注数据减少时，性能与收敛优势进一步扩大；且所需预训练图像远少于其他SSL方法。

Conclusion: 子图像重叠预测是一种高效、轻量、面向遥感语义分割的自监督预训练范式，可在有限预训练数据下提升下游任务性能与训练效率。

Abstract: Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.

</details>


### [105] [DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization](https://arxiv.org/abs/2601.01784)
*Boyang Zhao,Xin Liao,Jiaxin Chen,Xiaoshuai Wu,Yufeng Wu*

Main category: cs.CV

TL;DR: 本文提出DDNet框架，通过双流图学习与解耦方法实现视频时序伪造定位，显著提升检测精度与跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频伪造检测方法多基于整体视频分析，难以精确定位局部篡改片段；且受限于局部视角，无法有效捕获全局异常模式。

Method: 提出DDNet：包含时序距离流（捕捉局部伪影）和语义内容流（建模长程语义关联）；引入Trace Disentanglement and Adaptation（TDA）分离通用伪造指纹，以及Cross-Level Feature Embedding（CLFE）进行多层级特征深度融合。

Result: 在ForgeryNet和TVIL数据集上AP@0.95指标超越SOTA约9%，跨域鲁棒性显著增强。

Conclusion: 双流协同建模与特征解耦融合策略能有效兼顾局部细节与全局一致性，为细粒度时序伪造定位提供了新范式。

Abstract: The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \emph{local view}, failing to capture global anomalies. To address this, we propose a \underline{d}ual-stream graph learning and \underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \emph{Temporal Distance Stream} for local artifacts and a \emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\% in AP@0.95, with significant improvements in cross-domain robustness.

</details>


### [106] [VerLM: Explaining Face Verification Using Natural Language](https://arxiv.org/abs/2601.01798)
*Syed Abdul Hannan,Hazim Bukhari,Thomas Cantalapiedra,Eman Ansar,Massa Baali,Rita Singh,Bhiksha Raj*

Main category: cs.CV

TL;DR: 本文提出了一种用于人脸识别的视觉-语言模型（VLM），不仅能准确判断两张人脸图像是否属于同一人，还能以简洁或详尽的方式解释其决策依据，显著提升了模型的准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有面部验证系统缺乏决策透明度，亟需可解释的模型来提升可信度和可靠性。

Method: 构建一种新型视觉-语言模型（VLM），采用两种互补的解释风格（简洁总结与差异细节描述）进行训练，并将原用于音频区分的先进建模方法迁移适配至视觉任务。

Result: 该VLM在准确性和可解释性上均优于基线及其他现有模型。

Conclusion: 视觉-语言模型在面部验证任务中具有巨大潜力，有助于构建更透明、可靠和可解释的系统。

Abstract: Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.

</details>


### [107] [Causality-Aware Temporal Projection for Video Understanding in Video-LLMs](https://arxiv.org/abs/2601.01804)
*Zhengjian Kang,Qi Chen,Rui Liu,Kangtong Mo,Xingyu Zhang,Xiaoyu Deng,Ye Zhang*

Main category: cs.CV

TL;DR: 本文提出V-CORE框架，通过引入显式时间顺序约束（如因果感知时间投影器CATP和可学习空间聚合LSA），提升视频大语言模型在时序与因果推理任务上的性能，且参数高效、训练轻量。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型（Video-LLMs）在需严格时间顺序与因果连贯性的理解任务上表现不足，尤其因无约束的双向投影器破坏了视频固有的单向时序结构。

Method: 提出V-CORE：包含可学习空间聚合（LSA）以压缩空间冗余，以及因果感知时间投影器（CATP），采用块因果注意力与终端动态摘要token实现单向时序信息流。模型基于4-bit QLoRA微调，冻结LLM主干。

Result: 在NExT-QA上达61.2%准确率，在MSVD-QA、MSRVTT-QA、TGIF-QA上保持竞争力；在时序与因果子任务上分别提升3.5%和5.2%。

Conclusion: 显式建模时间顺序与因果结构对视频理解至关重要；V-CORE验证了轻量、参数高效设计可在不牺牲性能前提下显著增强时序推理能力。

Abstract: Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.

</details>


### [108] [Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification](https://arxiv.org/abs/2601.01807)
*Ubaidullah,Muhammad Abid Hussain,Mohsin Raza Jafri,Rozi Khan,Moid Sandhu,Abd Ullah Khan,Hyundong Shin*

Main category: cs.CV

TL;DR: 本文提出了一种名为LUMPNet的混合深度学习方法，用于牛痘样皮肤结节病（LSD）的早期检测，结合YOLOv11目标检测、EfficientNet分类及自适应混合优化器，在公开数据集上达到99%训练准确率和98%验证准确率，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LSD是一种传染性强、危害严重的病毒性疾病，威胁全球畜牧业、经济与粮食安全，亟需早期精准识别以防控疫情。

Method: 提出LUMPNet：融合YOLOv11进行皮肤结节检测与定位，EfficientNet-B0（含复合缩放）进行病变/健康二分类，并设计新型自适应混合优化器以稳定加速联合模型训练。

Result: 在公开数据集上实现99%训练准确率和98%验证准确率；对比实验显示其性能优于仅用AdamW优化的EfficientNet-B0基线模型。

Conclusion: LUMPNet是一种高效、鲁棒的LSD早期检测框架，具备实际部署潜力，为动物疫病智能诊断提供了新范式。

Abstract: Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.

</details>


### [109] [Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning](https://arxiv.org/abs/2601.01818)
*Sungjune Park,Hongda Mao,Qingshuang Chen,Yong Man Ro,Yelin Kim*

Main category: cs.CV

TL;DR: 本文提出了一种语言引导的场景上下文感知学习框架，用于鲁棒的自我中心视觉注意力预测，通过语言描述引导视频表征，并设计双目标训练策略提升对兴趣区域的关注与对干扰区域的抑制。


<details>
  <summary>Details</summary>
Motivation: 自我中心视频动态场景复杂且模糊，而场景上下文信息对人类注意力调控至关重要，因此需引入语言引导的上下文建模以提升注意力预测鲁棒性。

Method: 设计语言引导的上下文感知器生成上下文感知视频表征，并引入两个训练目标：聚焦目标兴趣区域、抑制无关干扰区域。

Result: 在Ego4D和Aria Everyday Activities（AEA）数据集上达到SOTA性能，显著提升在多样化动态自我中心场景下的鲁棒性。

Conclusion: 语言引导的场景上下文建模能有效提升自我中心视觉注意力预测的准确性与鲁棒性，为未来第一人称视觉理解提供新思路。

Abstract: As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.

</details>


### [110] [RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images](https://arxiv.org/abs/2601.01835)
*Rashid Iqbal,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 本文提出了一种名为Customized Residual SwinTransformerV2（RSwinV2）的深度学习方法，用于Mpox病灶图像分类，通过结合Swin Transformer与逆残差块（IRB），兼顾全局与局部特征，在Kaggle数据集上达到96.21%准确率和95.62% F1分数，优于标准CNN和原始Swin Transformer。


<details>
  <summary>Details</summary>
Motivation: 提升Mpox病变图像的自动分类能力，区分Mpox与其他相似疾病（如水痘、麻疹、牛痘），解决传统模型在局部-全局建模及梯度消失方面的局限性。

Method: 定制化改进Swin Transformer V2架构：引入非重叠图像分块、移位窗口注意力机制、位置与块嵌入；新增逆残差块（IRB）融合卷积跳跃连接，缓解梯度消失并协同建模局部与全局模式。

Result: 在Kaggle公开数据集上取得96.21%分类准确率和95.62% F1分数，显著优于标准CNN和原始Swin Transformer模型。

Conclusion: RSwinV2是一种高效、鲁棒的计算机辅助Mpox病变识别工具，其结构设计有效提升了跨相似皮肤病的判别能力，具备临床应用潜力。

Abstract: In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.

</details>


### [111] [ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting](https://arxiv.org/abs/2601.01847)
*Chuhang Ma,Shuai Tan,Ye Pan,Jiaolong Yang,Xin Tong*

Main category: cs.CV

TL;DR: 本文提出ESGaussianFace框架，利用3D高斯泼溅与情感-音频引导的空间注意力机制，实现高效、高质量、三维一致的情感化与风格化语音驱动面部动画。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动面部动画方法多聚焦中性表情，难以兼顾情感表达与风格特征的高质量、高效率生成。

Method: 基于3D高斯泼溅重建与渲染；引入情感-音频引导的空间注意力机制融合情感与音频特征；设计两个3D高斯变形预测器分别建模情感与风格变形；采用多阶段训练策略分步学习口型、情感和风格。

Result: 生成结果具备高效率、高质量和3D一致性；在唇动精度、表情变化多样性和风格表现力上优于现有SOTA方法。

Conclusion: ESGaussianFace有效解决了情感化与风格化音频驱动面部动画的关键挑战，为高质量虚拟人生成提供了新范式。

Abstract: Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.

</details>


### [112] [GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection](https://arxiv.org/abs/2601.01856)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

TL;DR: 本文提出GCR框架，通过几何一致性路由在共享冻结的patch嵌入空间中进行类别无关的持续异常检测，避免跨头分数不可比问题，显著提升路由稳定性并缓解性能崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有基于特征的异常检测方法在持续类别扩展场景下，因跨模型异常分数分布差异大，导致专家选择（即路由）不可靠，影响整体性能。

Method: GCR采用轻量级混合专家框架：在共享冻结的patch嵌入空间中，依据累积最近原型距离将测试图像路由至对应类别原型库所关联的专家；仅在该专家内使用标准原型打分规则生成异常图。

Result: 在MVTec AD和VisA数据集上，GCR显著提升路由稳定性，实现近零遗忘，同时保持有竞争力的检测与定位性能。

Conclusion: 许多此前归因于表征遗忘的失败，实则源于跨头路由决策规则的不稳定性；几何一致性路由是更根本的解决路径。

Abstract: Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.
  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.
  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR

</details>


### [113] [RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations](https://arxiv.org/abs/2601.01865)
*Wenlong Yang,Canran Jin,Weihang Yuan,Chao Wang,Lifeng Sun*

Main category: cs.CV

TL;DR: RRNet是一种轻量级、可配置的实时视频增强网络，通过估计虚拟光源参数实现局部重光照，无需像素对齐标注，在低光增强、局部照明调整和眩光去除方面达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在实时视频增强中平衡速度与有效曝光控制，尤其在不均匀光照下表现不佳。

Method: 提出RRNet框架，利用深度感知渲染模块估计少量虚拟光源参数以实现局部重光照；采用轻量化编码器和预测头；设计基于生成式AI的数据集构建流程合成多样光照条件。

Result: 在低光增强、局部照明调整和眩光去除任务上持续优于先前方法，支持实时、高分辨率处理，并保持面部身份一致性。

Conclusion: RRNet凭借可解释的光照控制、高效架构和无需像素对齐训练的优势，适用于视频会议、AR人像增强和移动摄影等实际场景。

Abstract: With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.

</details>


### [114] [Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion](https://arxiv.org/abs/2601.01870)
*Wenyu Shao,Hongbo Liu,Yunchuan Ma,Ruili Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于实体引导的多任务学习方法（EGMT）用于红外与可见光图像融合，通过提取实体级文本信息、构建多任务学习架构及跨模态交互模块，显著提升了融合图像的语义密度与质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的红外与可见光图像融合方法多依赖句子级文本，易引入语义噪声且未能充分挖掘文本深层语义价值。

Method: 提出EGMT方法：（i）从大视觉语言模型生成的图像描述中提取实体级文本信息；（ii）构建以实体为伪标签的并行多任务学习架构（融合+多标签分类）；（iii）设计实体引导的跨模态交互模块，增强视觉与实体特征间的细粒度交互。

Result: EGMT在保留显著目标、纹理细节和语义一致性方面优于当前最先进方法；并发布了四个数据集的实体标注版本。

Conclusion: 实体级文本引导与多任务协同监督可有效提升红外与可见光图像融合的语义表征能力与融合质量。

Abstract: Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.

</details>


### [115] [CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving](https://arxiv.org/abs/2601.01874)
*Shuhang Chen,Yunqiu Xu,Junjie Xie,Aojun Lu,Tao Feng,Zeying Huang,Ning Zhang,Yi Sun,Yi Yang,Hangjie Yuan*

Main category: cs.CV

TL;DR: 本文提出CogFlow框架，通过感知→内化→推理的三阶段认知流程，提升多模态大模型在视觉数学问题求解中的表现，尤其强调视觉线索的忠实整合与合理利用，并引入新数据集MathCog进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽改进了视觉输入的提取与解释，但忽略了提取的视觉线索是否被忠实整合并合理用于后续推理这一关键问题。

Method: 提出CogFlow三阶段认知框架：1）协同视觉奖励（Synergistic Visual Rewards）增强符号与图表的视觉信息提取；2）知识内化奖励模型（Knowledge Internalization Reward）确保视觉线索向推理阶段的忠实传递；3）视觉门控策略优化算法（Visual-Gated Policy Optimization）强制推理过程以视觉知识为依据。同时构建含12万+高质量标注的新数据集MathCog。

Result: 在主流视觉数学推理基准上，CogFlow显著优于现有方法，实验证明其在感知、内化与推理各阶段的协同增强效果。

Conclusion: CogFlow通过模拟人类分层认知流程，系统性地解决了视觉线索整合与利用不足的问题，为多模态数学推理提供了更可靠、可解释的建模范式。

Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\Rightarrow$internalization$\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.

</details>


### [116] [Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems](https://arxiv.org/abs/2601.01891)
*Niloufar Alipour Talemi,Julia Boone,Fatemeh Afghah*

Main category: cs.CV

TL;DR: This paper surveys agentic AI in remote sensing, introducing a taxonomy of single- and multi-agent systems, analyzing architectural components like planning and memory, reviewing new trajectory-aware benchmarks, and outlining a roadmap for robust geospatial intelligence.


<details>
  <summary>Details</summary>
Motivation: Traditional deep learning models lack sequential planning and active tool orchestration needed for complex geospatial workflows; recent foundation models advance representation but fall short in autonomy.

Method: Comprehensive survey and taxonomy construction, analysis of architectural foundations (planning, RAG, memory), review of emerging trajectory-aware benchmarks, and critical assessment of limitations (grounding, safety, orchestration).

Result: First unified taxonomy of agentic AI in remote sensing; identification of key architectural elements; summary of new evaluation paradigms beyond pixel accuracy; synthesis of current limitations and open challenges.

Conclusion: Agentic AI represents a pivotal shift in Earth Observation; robust geospatial intelligence requires advances in grounding, safe orchestration, and reasoning-aware evaluation—guiding future research toward autonomous, trustworthy systems.

Abstract: The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.

</details>


### [117] [Forget Less by Learning from Parents Through Hierarchical Relationships](https://arxiv.org/abs/2601.01892)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 本文提出FLLP框架，在双曲空间中引入父-子概念学习机制，以缓解定制扩散模型在顺序学习新概念时的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 定制扩散模型在顺序学习新概念时易发生灾难性遗忘，现有方法多关注减少概念间干扰，忽视了概念间的正向交互潜力。

Method: 在洛伦兹流形（Lorentzian manifold）这一双曲空间中嵌入概念表征，构建父-子概念关系，使已学概念作为指导来适应新概念，实现知识保留与持续集成。

Result: 在三个公开数据集和一个合成基准上验证，FLLP在鲁棒性和泛化性方面均取得一致提升。

Conclusion: FLLP通过双曲空间中的父-子学习机制，有效缓解了定制扩散模型的灾难性遗忘，支持持续学习与知识复用。

Abstract: Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.

</details>


### [118] [Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection](https://arxiv.org/abs/2601.01908)
*Jingjing Wang,Qianglin Liu,Zhuo Xiao,Xinning Yao,Bo Liu,Lu Li,Lijuan Niu,Fugen Zhou*

Main category: cs.CV

TL;DR: 本文提出Nodule-DETR，一种基于检测Transformer的新型架构，用于超声图像中甲状腺结节的鲁棒检测，通过MSFCA、HFF和MSDA三个模块提升低对比度、边界模糊及小/不规则结节的检测性能，在真实临床数据集上达到SOTA（mAP@0.5:0.95提升0.149）。


<details>
  <summary>Details</summary>
Motivation: 超声是甲状腺结节检测的首选影像手段，但其诊断准确性受限于图像对比度低、结节边界模糊等问题。

Method: 提出Nodule-DETR模型，包含三个核心模块：多谱频域通道注意力（MSFCA）模块（利用频域分析增强低对比度结节特征）、分层特征融合（HFF）模块（实现高效多尺度特征整合）、多尺度可变形注意力（MSDA）模块（灵活捕获小尺寸与不规则形状结节）。

Result: 在真实甲状腺超声临床数据集上实验表明，Nodule-DETR在mAP@0.5:0.95指标上显著优于基线模型，提升达0.149，达到当前最优性能。

Conclusion: Nodule-DETR展现出优异的检测精度，具备作为计算机辅助甲状腺诊断工具的重要临床应用潜力。

Abstract: Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.

</details>


### [119] [Learning Action Hierarchies via Hybrid Geometric Diffusion](https://arxiv.org/abs/2601.01914)
*Arjun Ramesh Kaushik,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 本文提出HybridTAS框架，结合欧氏与双曲几何于扩散模型去噪过程，利用双曲空间的树状结构实现动作标签从粗到细的分层去噪，在时序动作分割任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有基于迭代优化的方法未能显式建模人类动作固有的层次结构。

Method: 提出HybridTAS框架，在扩散模型去噪过程中融合欧氏与双曲几何；利用双曲空间嵌入的树状关系，使高时间步受高层抽象动作类别引导，低时间步由细粒度动作类别细化。

Result: 在GTEA、50Salads和Breakfast三个基准数据集上取得当前最优性能。

Conclusion: 双曲几何引导的去噪策略能有效建模动作层次性，显著提升时序动作分割性能。

Abstract: Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.

</details>


### [120] [TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing](https://arxiv.org/abs/2601.01915)
*Yujie Hu,Zecheng Tang,Xu Jiang,Weiqi Li,Jian Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的对话式图像编辑框架TalkPhoto，利用开源大语言模型和定制提示模板，分层调用现有先进编辑方法，实现高精度、高质量、灵活可控的图像编辑。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法依赖多任务训练数据集，耗时耗力且效果不佳；需要一种无需训练、灵活应对复杂及未见编辑任务的新框架。

Method: 设计专用提示模板引导开源LLM理解用户指令并分层调用现有图像编辑方法；实现即插即用、高效的编辑方法调用机制，无需额外训练。

Result: 实验表明，该方法在更少token消耗下实现更精准的方法调用，并在多种图像编辑任务中达到更高编辑质量与稳定性。

Conclusion: TalkPhoto是一种通用、免训练、对话驱动的图像编辑框架，显著提升了编辑的可控性、灵活性与质量，为零样本图像编辑提供了新范式。

Abstract: Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.

</details>


### [121] [AR-MOT: Autoregressive Multi-object Tracking](https://arxiv.org/abs/2601.01925)
*Lianjie Jia,Yuhan Wu,Binghao Ran,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出AR-MOT，一种基于大语言模型的自回归多目标跟踪新范式，将MOT建模为序列生成任务，无需任务特定头，通过Object Tokenizer、Region-Aware Alignment和Temporal Memory Fusion模块提升视觉感知与长时跟踪能力，具备强可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法架构僵化、任务特定，难以适应多样化、指令驱动的新跟踪场景，缺乏灵活性与可扩展性。

Method: 提出AR-MOT：将MOT建模为LLM下的自回归序列生成任务；引入基于预训练检测器的Object Tokenizer；设计Region-Aware Alignment（RAA）缓解全局与区域特征错位；构建Temporal Memory Fusion（TMF）缓存历史目标token以支持长时跟踪。

Result: 在MOT17和DanceTrack上实验表明，AR-MOT性能媲美SOTA方法，同时验证了其作为通用、灵活MOT框架的可行性。

Conclusion: AR-MOT通过序列生成范式摆脱了传统任务头依赖，显著提升了MOT系统的通用性、灵活性与可扩展性，为多模态、指令驱动的跟踪任务奠定基础。

Abstract: As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.

</details>


### [122] [MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering](https://arxiv.org/abs/2601.01926)
*Zhifei Li,Yiran Wang,Chenyi Xiong,Yujing Xia,Xiaoju Hou,Yue Zhao,Miao Zhang,Kui Xiao,Bing Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为MacVQA的新框架，用于持续学习场景下的视觉问答（VQA），通过自适应记忆分配和全局噪声过滤提升知识保留、适应性与鲁棒表征能力，并在多个持续VQA任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有持续VQA方法难以平衡知识保留、新知识适应和鲁棒特征表示。

Method: 提出MacVQA框架，融合视觉与问题信息并进行噪声过滤以增强表征鲁棒性；采用基于原型的记忆分配机制优化特征质量与内存使用。

Result: 在10个持续VQA任务上，MacVQA在标准任务中达到43.38%平均准确率和2.32%平均遗忘率，在新颖组合任务中达到42.53%平均准确率和3.60%平均遗忘率，优于现有基线。

Conclusion: MacVQA有效提升了持续VQA中的知识获取、保留与组合泛化能力，验证了自适应记忆分配与噪声过滤设计的有效性。

Abstract: Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.

</details>


### [123] [Face Normal Estimation from Rags to Riches](https://arxiv.org/abs/2601.01950)
*Meng Wang,Wenjing Dai,Jiawan Zhang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 本文提出了一种粗到精的面部法线估计方法，通过使用小规模数据集训练粗估计模型，并利用自注意力机制和专门设计的细化网络提升法线质量，显著减少了对大规模配对数据和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 现有面部法线估计方法严重依赖大规模配对训练数据，限制了其应用灵活性和资源效率。

Method: 提出粗到精两阶段法线估计框架：首先用小数据集训练粗估计模型生成引导性法线（exemplars）；然后引入自注意力机制缓解局部伪影，并设计细化网络将输入图像与exemplars映射为高质量法线。

Result: 在多个实验和消融研究中验证了方法有效性，在训练开销和估计质量上均优于当前最先进方法。

Conclusion: 所提方法成功降低了对大规模配对数据和计算资源的依赖，同时保持甚至提升了面部法线估计精度，具备良好的实用性和可扩展性。

Abstract: Although recent approaches to face normal estimation have achieved promising results, their effectiveness heavily depends on large-scale paired data for training. This paper concentrates on relieving this requirement via developing a coarse-to-fine normal estimator. Concretely, our method first trains a neat model from a small dataset to produce coarse face normals that perform as guidance (called exemplars) for the following refinement. A self-attention mechanism is employed to capture long-range dependencies, thus remedying severe local artifacts left in estimated coarse facial normals. Then, a refinement network is customized for the sake of mapping input face images together with corresponding exemplars to fine-grained high-quality facial normals. Such a logical function split can significantly cut the requirement of massive paired data and computational resource. Extensive experiments and ablation studies are conducted to demonstrate the efficacy of our design and reveal its superiority over state-of-the-art methods in terms of both training expense as well as estimation quality. Our code and models are open-sourced at: https://github.com/AutoHDR/FNR2R.git.

</details>


### [124] [MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization](https://arxiv.org/abs/2601.01955)
*Zhexin Zhang,Yifeng Zhu,Yangyang Xu,Long Chen,Yong Du,Shengfeng He,Jun Yu*

Main category: cs.CV

TL;DR: 本文提出了MotionAdapter，一种面向DiT架构文本到视频模型的内容感知运动迁移框架，通过显式解耦运动与外观，并基于DINO特征进行运动场自适应定制，实现了高质量、语义对齐的视频运动迁移。


<details>
  <summary>Details</summary>
Motivation: 现有扩散式文本到视频模型在复杂运动迁移方面仍面临挑战，尤其是难以在保持目标内容语义和外观的同时准确迁移参考视频的运动。

Method: MotionAdapter首先利用3D全注意力模块中的跨帧注意力提取注意力驱动的运动场，实现运动与外观的显式解耦；然后引入DINO引导的运动定制模块，根据内容对应关系重排和精炼运动场；最后将定制后的运动场融入DiT去噪过程以指导视频生成。

Result: 实验表明MotionAdapter在定性和定量评估中均优于当前最先进方法，并天然支持复杂运动迁移及运动编辑（如缩放）等任务。

Conclusion: MotionAdapter为DiT-based T2V模型提供了一种有效、鲁棒且语义对齐的运动迁移新范式，显著提升了视频生成中运动控制的灵活性与精度。

Abstract: Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \romannumeral1) explicit disentanglement of motion from appearance and \romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.

</details>


### [125] [AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing](https://arxiv.org/abs/2601.01957)
*Tianbo Wang,Yuqing Ma,Kewei Liao,Zhange Zhang,Simin Li,Jinyang Guo,Xianglong Liu*

Main category: cs.CV

TL;DR: 本文提出AFTER方法，通过事实引导的视觉-文本编辑技术（包括FAS和QAO两个模块）来缓解大视觉语言模型中的对象幻觉问题，显著降低幻觉率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）因语言偏置易产生对象幻觉（类别、属性、关系三类），阻碍可信AI应用；现有编辑方法缺乏对事实性文本语义的有效利用，难以显式缓解语言偏置。

Method: 提出Adaptive Factual-guided Visual-Textual Editing（AFTER），包含：1）Factual-Augmented Activation Steering（FAS），利用事实增强的语义提供通用且精准的激活编辑指导；2）Query-Adaptive Offset Optimization（QAO），引入查询感知的偏移估计器，实现从通用引导向查询特异性编辑的自适应转换。

Result: 在多个标准幻觉基准（如AMBER）上，对三种主流LVLMs进行实验，AFTER最高实现16.3%的幻觉率下降；代码与数据将开源。

Conclusion: AFTER通过融合事实性文本语义与查询自适应机制，有效缓解LVLMs中的多类型幻觉，提升了模型输出的可靠性与可解释性。

Abstract: Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.

</details>


### [126] [Forget Less by Learning Together through Concept Consolidation](https://arxiv.org/abs/2601.01963)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 本文提出FL2T框架，通过集合不变的跨概念学习模块，在不按顺序学习多个概念时缓解灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有定制扩散模型在持续学习新概念时存在灾难性遗忘问题，且多数工作忽略了概念间的相互作用。

Method: 提出Forget Less by Learning Together (FL2T)框架，引入集合不变的跨概念学习模块，利用代理引导跨概念特征选择，实现知识保留与迁移。

Result: 在三个数据集上的大量实验表明，该方法显著提升了概念保留能力，在十项增量概念学习任务中CLIP图像对齐分数平均提升至少2%。

Conclusion: 跨概念催化行为能有效缓解定制扩散模型中的灾难性遗忘，支持并发、无序的概念学习。

Abstract: Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.

</details>


### [127] [Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation](https://arxiv.org/abs/2601.01984)
*Weijian Ma,Shizhao Sun,Tianyu Yu,Ruiyu Wang,Tat-Seng Chua,Jiang Bian*

Main category: cs.CV

TL;DR: 本文提出了一种将对象中心蓝图（object-centric blueprint）融入视觉语言模型（VLMs）的新方法，以提升空间推理能力；通过构建结构化JSON蓝图记录对象位置、尺寸与属性，并结合嵌入式推理轨迹监督微调、蓝图感知强化学习奖励及反捷径数据增强三项技术，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLM的空间推理方法存在两难：局部patch建模削弱全局空间感知，孤立坐标标记忽略对象整体组织关系；需一种兼顾细粒度定位与全局空间结构理解的机制。

Method: 引入对象中心蓝图概念，构建JSON格式结构化表示（含位置、尺寸、属性）；采用三阶段技术：（1）蓝图嵌入式推理轨迹用于监督微调；（2）蓝图感知的强化学习奖励，约束对象数量并确保答案与蓝图因果一致；（3）反捷径数据增强，对图像与问题施加定向扰动以抑制表面线索依赖。

Result: 在多个空间推理基准上持续超越现有VLM及专用空间推理模型，验证了蓝图结构与三阶段训练策略的有效性。

Conclusion: 对象中心蓝图作为一种认知启发的中间表示，能有效桥接视觉感知与空间语义推理；结构化表征+分阶段对齐训练是提升VLM空间能力的关键路径。

Abstract: Spatial reasoning -- the ability to perceive and reason about relationships in space -- advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches, improving fine-grained perception but weakening global spatial awareness, or mark isolated coordinates, which capture object locations but overlook their overall organization. In this work, we integrate the cognitive concept of an object-centric blueprint into VLMs to enhance spatial reasoning. Given an image and a question, the model first constructs a JSON-style blueprint that records the positions, sizes, and attributes of relevant objects, and then reasons over this structured representation to produce the final answer. To achieve this, we introduce three key techniques: (1) blueprint-embedded reasoning traces for supervised fine-tuning to elicit basic reasoning skills; (2) blueprint-aware rewards in reinforcement learning to encourage the blueprint to include an appropriate number of objects and to align final answers with this causal reasoning; and (3) anti-shortcut data augmentation that applies targeted perturbations to images and questions, discouraging reliance on superficial visual or linguistic cues. Experiments show that our method consistently outperforms existing VLMs and specialized spatial reasoning models.

</details>


### [128] [API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning](https://arxiv.org/abs/2601.01992)
*Chen Zhu,Huiwen Zhang,Yujie Li,Mu He,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 本文提出了一种自适应补丁重要性感知（API）框架，通过自动雾生成（AHG）和密度感知去雾（DHR）模块，并结合多负样本对比去雾损失（MNCD），显著提升了真实世界图像去雾的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在复杂真实雾场景中性能下降明显，主要受限于训练数据不足和雾密度分布的内在复杂性。

Method: 提出API框架，包括自动雾生成（AHG）模块用于高质量混合数据增强，密度感知去雾（DHR）模块实现自适应补丁重要性感知的去雾，以及多负样本对比去雾（MNCD）损失来缓解去雾细节模糊问题。

Result: 在多个真实世界基准上达到SOTA性能，在定量指标和视觉质量上均表现优异，且对多样雾密度分布具有强泛化能力。

Conclusion: API框架有效解决了真实世界图像去雾中的泛化性与细节恢复难题，为低层视觉任务提供了新思路。

Abstract: Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.

</details>


### [129] [Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors](https://arxiv.org/abs/2601.01998)
*Chen Zhu,Huiwen Zhang,Mu He,Yujie Li,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 本文提出了一种新框架，通过在视觉与频率域中多尺度专家协同及频率感知路由机制，互促强化雾天低照度先验一致性，显著提升夜间雾霾图像可见性，并具备跨场景泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅单独处理雾霾或低光照退化，忽略了二者间的相互作用，导致夜间雾霾图像增强效果有限；而低光照与雾霾先验之间存在可互促的共享领域知识。

Method: 提出一种多尺度（图像级、块级、像素级）跨域（视觉域与频率域）专家协同框架，并引入频率感知路由器自适应融合各专家贡献，以渐进式恢复全局结构、区域模式与细节。

Result: 在夜间去雾基准上定量与定性均优于现有方法；同时在白天去雾和低光照增强任务中展现出良好泛化性。

Conclusion: 通过互促强化 haze 与 low-light 先验的一致性，结合多尺度跨域建模与频率感知路由，可有效解决夜间雾霾图像增强难题，并拓展至其他相关任务。

Abstract: Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.

</details>


### [130] [Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach](https://arxiv.org/abs/2601.02016)
*Matthias Bartolo,Dylan Seychell,Gabriel Hili,Matthew Montebello,Carl James Debono,Saviour Formosa,Konstantinos Makantasis*

Main category: cs.CV

TL;DR: 本文将LUPI范式引入目标检测，通过师生架构将特权信息（如掩码、显著图、深度线索）注入检测器，在不增加推理复杂度的前提下显著提升检测精度，尤其对中大型目标效果明显。


<details>
  <summary>Details</summary>
Motivation: 利用训练阶段可获得但推理阶段不可用的细粒度、描述性信息（特权信息）来提升目标检测性能。

Method: 提出一种通用、模型无关的方法，通过教师-学生架构将特权信息（如边界框掩码、显著图、深度线索）注入基于深度学习的目标检测器。

Result: 在五个SOTA检测模型和多个公开基准（包括无人机垃圾检测数据集和Pascal VOC 2012）上验证，LUPI训练的学生模型持续优于基线，在检测精度上有显著提升，且不增加推理复杂度或模型大小；中大型目标提升尤为明显；消融实验表明中间权重的教师指导效果最优。

Conclusion: LUPI框架是一种有效且实用的策略，可推动目标检测系统在资源受限和真实场景中的发展。

Abstract: This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.

</details>


### [131] [Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement](https://arxiv.org/abs/2601.02018)
*Guangqian Guo,Aixi Ren,Yong Guo,Xuehui Yu,Jiacheng Tian,Wenli Li,Yaoxing Wang,Shan Gao*

Main category: cs.CV

TL;DR: 本文提出GleSAM++，通过生成潜在空间增强（GLE）、特征分布对齐（FDA）、通道复制与扩展（CRE）以及退化感知自适应增强（DAE）机制，提升Segment Anything Models在低质量图像上的分割鲁棒性，同时保持对清晰图像的泛化能力。


<details>
  <summary>Details</summary>
Motivation: Segment Anything Models (SAMs) 在严重退化、低质量图像上性能显著下降，限制了其在真实场景中的应用。

Method: 提出GleSAM++，包含生成潜在空间增强（GLE）、特征分布对齐（FDA）、通道复制与扩展（CRE）和退化感知自适应增强（DAE）机制；DAE将重建过程解耦为退化程度预测与退化感知重建两个阶段。

Result: GleSAM++显著提升了在复杂退化图像上的分割鲁棒性，同时保持对清晰图像的良好泛化能力，并在未见退化类型上表现优异。

Conclusion: GleSAM++以极少量可学习参数即可适配预训练SAM/SAM2，在多种退化图像上实现高效、鲁棒的零样本分割，具有强实用性与泛化性。

Abstract: Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.

</details>


### [132] [Adapting Depth Anything to Adverse Imaging Conditions with Events](https://arxiv.org/abs/2601.02020)
*Shihan Peng,Yuyang Xiong,Hanyu Zhou,Zhiwei Shi,Haoyue Liu,Gang Chen,Luxin Yan,Yi Chang*

Main category: cs.CV

TL;DR: 本文提出ADAE框架，通过熵感知空间融合与运动引导时间校正，将事件相机信息融入Depth Anything模型，提升其在极端光照与运动模糊等恶劣条件下的深度估计鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度基础模型（如Depth Anything）在理想场景表现优异，但在极端光照、运动模糊等恶劣成像条件下性能显著下降；而现有事件相机融合方法多从零训练，无法继承基础模型的开放世界知识和泛化能力。

Method: 提出ADAE：1）熵感知空间融合——利用信息熵自适应融合帧与事件特征，指示光照退化区域；2）运动引导时间校正——利用事件流中的运动线索重校准模糊区域特征；二者在统一框架下协同增强Depth Anything。

Result: 大量实验验证了ADAE在恶劣成像条件下的优越性，显著提升了Depth Anything的鲁棒深度估计性能。

Conclusion: ADAE成功将事件相机的高动态范围与高时间分辨率优势引入深度基础模型，在不牺牲其开放世界泛化能力的前提下，有效增强了其在动态与恶劣光照场景下的深度估计鲁棒性。

Abstract: Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.

</details>


### [133] [Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding](https://arxiv.org/abs/2601.02029)
*Toshihiko Nishimura,Hirofumi Abe,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 本文提出了一种无需3D标注数据或配对RGB图像的新型大规模点云3D语义分割方法，通过虚拟相机将点云投影到2D图像，利用自然语言提示引导的2D基础模型进行分割，并通过加权投票融合多视角预测结果，实现了媲美监督方法的精度和开放词汇识别能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D语义分割方法依赖大量标注3D数据或配对RGB图像、且难以支持开放词汇识别的问题。

Method: 将3D点云通过虚拟相机投影为2D图像，调用基于自然语言提示的2D基础模型进行语义分割，再通过多视角加权投票实现3D分割。

Result: 在无需3D标注或配对图像的前提下，性能优于现有无训练方法，精度接近监督方法，并支持任意文本查询的开放词汇识别。

Conclusion: 该方法有效降低了对标注数据的依赖，拓展了3D语义分割的应用灵活性与泛化能力。

Abstract: This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.

</details>


### [134] [AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off](https://arxiv.org/abs/2601.02038)
*Yihan Zhu,Mengying Ge*

Main category: cs.CV

TL;DR: 本文提出AlignVTOFF，一种基于参考U-Net和纹理-空间特征对齐（TSFA）的并行U-Net框架，用于提升虚拟试穿中平铺服装图像生成的几何保真度与高频纹理细节。


<details>
  <summary>Details</summary>
Motivation: 现有方法因采用轻量模块进行特征提取，难以保持结构化模式和细粒度纹理，导致生成结果纹理衰减。

Method: 提出AlignVTOFF框架，包含Reference U-Net（多尺度特征提取与几何保真增强）和TSFA模块（通过可训练交叉注意力与冻结自注意力混合机制，将参考服装特征注入冻结去噪U-Net），显式对齐纹理与空间线索。

Result: 在多个实验设置下，AlignVTOFF持续优于当前最优方法，生成的平铺服装图像具有更高的结构真实感与高频细节保真度。

Conclusion: AlignVTOFF有效缓解了虚拟试穿任务中几何变形建模与高频纹理保留之间的矛盾，为多模态图像生成提供了新思路。

Abstract: Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.

</details>


### [135] [Agentic Retoucher for Text-To-Image Generation](https://arxiv.org/abs/2601.02046)
*Shaocheng Shen,Jianfeng Liang. Chunlei Cai,Cong Geng,Huiyu Duan,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出Agentic Retoucher，一种分层决策驱动的文本到图像生成后修正框架，通过感知-推理-动作循环实现细粒度、可控、自校正的局部修复，并构建GenBlemish-27K数据集支持训练与评估。


<details>
  <summary>Details</summary>
Motivation: 现有T2I扩散模型虽具高保真度，但普遍存在肢体、面部、文字等局部畸变；当前修正方法或计算昂贵，或依赖空间定位能力弱的VLM导致语义漂移和不可靠编辑。

Method: 提出Agentic Retoucher框架：(1) 感知智能体——基于图文一致性线索学习上下文显著性以精确定位畸变；(2) 推理智能体——通过渐进式偏好对齐实现类人推断式诊断；(3) 行动智能体——依据用户偏好自适应规划局部修复；并构建含27K标注畸变区域的GenBlemish-27K数据集。

Result: 在感知质量、畸变定位精度和人类偏好对齐方面均显著优于SOTA方法。

Conclusion: Agentic Retoucher建立了自校正、感知可靠的T2I生成新范式，推动生成结果从‘整体真实’迈向‘局部可信’。

Abstract: Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.

</details>


### [136] [PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction](https://arxiv.org/abs/2601.02088)
*Jiahao Bao,Huazhen Liu,Yu Zhuang,Leran Tao,Xinyu Xu,Yongtao Shi,Mengjia Cheng,Yiming Wang,Congshuang Ku,Ting Zeng,Yilang Du,Siyi Chen,Shunyao Shen,Suncheng Xiang,Hongbo Yu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PhysSFI-Net的物理信息几何深度学习框架，用于精准预测正颌手术后的软组织形变，融合了图神经网络、LSTM序列建模与生物力学启发模块，在135例患者数据上验证其优于ACMT-Net，具备高精度与可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统生物力学模型计算昂贵，几何深度学习方法缺乏可解释性，而正颌手术术前面部形态模拟需兼顾精度与临床可解释性。

Method: 提出PhysSFI-Net：包含分层图模块（融合颅面结构与手术计划编码器+注意力机制）、LSTM时序预测器（模拟渐进式软组织变形）及生物力学启发的高分辨率表面重建模块。

Result: 在135例患者数据上，点云形状误差为1.070±0.088 mm，表面偏差误差为1.296±0.349 mm，标志点定位误差为2.445±1.326 mm，整体优于ACMT-Net。

Conclusion: PhysSFI-Net实现了高精度、高分辨率且可解释的术后面部形态预测，具有良好的临床应用前景，可辅助正颌手术规划与仿真。

Abstract: Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.

</details>


### [137] [MCD-Net: A Lightweight Deep Learning Baseline for Optical-Only Moraine Segmentation](https://arxiv.org/abs/2601.02091)
*Zhehuan Cao,Fiseha Berhanu Tesema,Ping Fu,Jianfeng Ren,Ahmed Nasr*

Main category: cs.CV

TL;DR: 本文提出首个大规模纯光学遥感图像冰碛垄分割数据集，并设计轻量级网络MCD-Net，在保证精度的同时显著降低计算开销，验证了仅用光学影像进行可靠冰碛垄体分割的可行性。


<details>
  <summary>Details</summary>
Motivation: 冰川地貌自动制图受限于光学对比度弱和高分辨率DEM数据稀缺，亟需基于纯光学影像的高效分割方法。

Method: 构建包含3340张高分辨率Google Earth图像的冰碛垄标注数据集；提出轻量级MCD-Net模型，融合MobileNetV2编码器、CBAM注意力模块与DeepLabV3+解码器。

Result: MCD-Net在mIoU和Dice系数上分别达62.3%和72.8%，较ResNet152、Xception等深层骨干网络计算成本降低超60%；但对亚像素宽度及光谱模糊的冰碛垄脊线提取仍有局限。

Conclusion: 纯光学影像足以支撑可靠的冰碛垄体分割；所发布数据集与代码为冰碛垄专用分割提供了可复现基准与可部署基线。

Abstract: Glacial segmentation is essential for reconstructing past glacier dynamics and evaluating climate-driven landscape change. However, weak optical contrast and the limited availability of high-resolution DEMs hinder automated mapping. This study introduces the first large-scale optical-only moraine segmentation dataset, comprising 3,340 manually annotated high-resolution images from Google Earth covering glaciated regions of Sichuan and Yunnan, China. We develop MCD-Net, a lightweight baseline that integrates a MobileNetV2 encoder, a Convolutional Block Attention Module (CBAM), and a DeepLabV3+ decoder. Benchmarking against deeper backbones (ResNet152, Xception) shows that MCD-Net achieves 62.3\% mean Intersection over Union (mIoU) and 72.8\% Dice coefficient while reducing computational cost by more than 60\%. Although ridge delineation remains constrained by sub-pixel width and spectral ambiguity, the results demonstrate that optical imagery alone can provide reliable moraine-body segmentation. The dataset and code are publicly available at https://github.com/Lyra-alpha/MCD-Net, establishing a reproducible benchmark for moraine-specific segmentation and offering a deployable baseline for high-altitude glacial monitoring.

</details>


### [138] [InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting](https://arxiv.org/abs/2601.02098)
*Jinlong Fan,Shanshan Zhao,Liang Zheng,Jing Zhang,Yuxiang Yang,Mingming Gong*

Main category: cs.CV

TL;DR: 本文提出了InpaintHuman方法，用于从严重遮挡的单目视频中重建高保真、完整且可动画的3D人体化身，通过多尺度UV参数化表示和身份保持的扩散修复模块解决几何缺失与时间不一致问题。


<details>
  <summary>Details</summary>
Motivation: 从单目视频重建完整可动画3D人体化身在严重遮挡下仍具挑战性，现有3D高斯泼溅方法在不完整观测下易产生几何畸变和时间不一致。

Method: 提出InpaintHuman：(i) 多尺度UV参数化表示与层次化粗到细特征插值；(ii) 融合文本反转与语义条件引导的身份保持扩散修复模块，并采用像素级直接监督保障身份保真。

Result: 在PeopleSnapshot、ZJU-MoCap和OcMotion等合成与真实数据集上，相比现有方法在重建质量、姿态与视角鲁棒性方面均取得一致提升。

Conclusion: InpaintHuman有效缓解了遮挡导致的几何缺失与时序失稳问题，为单目视频驱动的高保真人体建模提供了新范式。

Abstract: Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.

</details>


### [139] [360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images](https://arxiv.org/abs/2601.02102)
*Jiaqi Yao,Zhongmiao Yan,Jingyi Xu,Songpengcheng Xia,Yan Xiang,Ling Pei*

Main category: cs.CV

TL;DR: 本文提出了一种面向360度图像的前馈式3D高斯泼溅（3DGS）框架，通过引入深度-法向几何正则化，提升高斯原语的几何一致性，兼顾高质量渲染与精确表面重建。


<details>
  <summary>Details</summary>
Motivation: 传统多视图立体匹配在稀疏视角或低纹理区域表现差；神经渲染虽质量高但需逐场景优化且实时性差；现有前馈式3DGS侧重视觉质量而忽视几何一致性，影响空间感知任务可靠性。

Method: 提出一种面向360图像的前馈式3DGS框架，并引入Depth-Normal几何正则化，将渲染深度梯度与法向信息耦合，联合监督高斯的旋转、尺度和位置。

Result: 实验表明该方法在保持高渲染质量的同时显著提升了几何一致性，增强了点云和表面重建精度。

Conclusion: 所提方法为面向空间感知任务的3D重建提供了一种高效、可靠且几何一致的解决方案。

Abstract: 3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.

</details>


### [140] [HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures](https://arxiv.org/abs/2601.02103)
*Yating Wang,Yuan Sun,Xuan Wang,Ran Yi,Boyao Zhou,Yipengjing Sun,Hongyu Liu,Yinuo Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 本文提出HeadLighter，一种基于监督学习的3D头像生成模型光照-外观解耦框架，通过双分支结构与渐进式训练，在保持实时渲染和高质量生成的同时实现可控重光照与视角编辑。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的3D感知头像生成模型难以解耦光照与固有外观，导致不可控重光照；已有无监督/弱监督解耦方法受限于强假设，无法处理复杂光照。

Method: 提出HeadLighter：采用双分支架构分别建模光照不变的头部属性与物理驱动的渲染分量；结合光场设备采集的多视角可控光照图像进行渐进式解耦训练；引入法线蒸馏策略提升法线质量。

Result: 在保持实时渲染与高保真生成质量的前提下，实现了显式的光照与视角编辑能力；实验验证了其在解耦精度、渲染真实感与编辑灵活性上的优势。

Conclusion: HeadLighter首次在3D高斯头像生成中实现了高质量、物理合理的光照-外观解耦，为可控3D人像合成提供了新范式，并将开源代码与数据集。

Abstract: Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.

</details>


### [141] [MagicFight: Personalized Martial Arts Combat Video Generation](https://arxiv.org/abs/2601.02107)
*Jiancheng Huang,Mingfu Yan,Songyan Chen,Yi Huang,Shifeng Chen*

Main category: cs.CV

TL;DR: 本文提出了一个新任务：个性化武术格斗视频生成，并设计了MagicFight方法和专用数据集KungFu-Fiesta，以解决双人交互中身份混淆、肢体异常和动作不匹配等问题。


<details>
  <summary>Details</summary>
Motivation: 现有单人视频生成模型无法准确建模双人武术格斗中的复杂交互，存在身份混淆、异常肢体和动作不匹配等关键问题，且缺乏适配的双人格斗数据集。

Method: 提出MagicFight方法，基于Unity物理引擎构建专用3D格斗数据集KungFu-Fiesta（含多样化角色、招式与场景），并改进现有文本到视频模型以支持高保真、身份一致、动作连贯的双人格斗视频生成。

Result: 成功生成高质量、身份清晰、动作协调的个性化双人武术格斗视频，验证了方法在双人交互建模上的有效性，并开源数据集与代码。

Conclusion: MagicFight首次系统性地探索了个性化双人武术格斗视频生成这一新方向，填补了该领域空白，为交互式视频内容生成提供了新范式与基础资源。

Abstract: Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation.
  Website: https://MingfuYAN.github.io/MagicFight/
  Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta

</details>


### [142] [Towards Long-window Anchoring in Vision-Language Model Distillation](https://arxiv.org/abs/2512.21576)
*Haoyi Zhou,Shuo Li,Tianyu Chen,Qi Song,Chonghan Gao,Jianxin Li*

Main category: cs.CV

TL;DR: 本文提出LAid方法，通过渐进式距离加权注意力匹配和可学习RoPE响应增益调制，提升小规模视觉语言模型的长上下文理解能力，显著扩展有效上下文窗口并保持或提升基准性能。


<details>
  <summary>Details</summary>
Motivation: 现有小型视觉语言模型（VLMs）因窗口尺寸受限，在语言-图像对齐任务中表现不佳，而大模型虽具强长上下文理解能力却难以部署；知识蒸馏结合RoPE可作为补充方案提升小模型能力。

Method: 提出LAid框架，包含两个核心组件：(1) 渐进式距离加权注意力匹配，训练中动态强调更远位置差异；(2) 可学习RoPE响应增益调制，选择性增强关键位置敏感性。

Result: LAid蒸馏后的小模型在多个模型家族上实现最高达3.2倍的有效上下文窗口扩展，并在标准视觉语言基准上保持或提升性能；频谱分析显示其成功保留了传统方法无法迁移的关键低频注意力成分。

Conclusion: LAid不仅为构建高效长上下文VLM提供了实用技术路径，也从理论上揭示了位置感知能力在知识蒸馏过程中的涌现与迁移机制。

Abstract: While large vision-language models (VLMs) demonstrate strong long-context understanding, their prevalent small branches fail on linguistics-photography alignment for a limited window size. We discover that knowledge distillation improves students' capability as a complement to Rotary Position Embeddings (RoPE) on window sizes (anchored from large models). Building on this insight, we propose LAid, which directly aims at the transfer of long-range attention mechanisms through two complementary components: (1) a progressive distance-weighted attention matching that dynamically emphasizes longer position differences during training, and (2) a learnable RoPE response gain modulation that selectively amplifies position sensitivity where needed. Extensive experiments across multiple model families demonstrate that LAid-distilled models achieve up to 3.2 times longer effective context windows compared to baseline small models, while maintaining or improving performance on standard VL benchmarks. Spectral analysis also suggests that LAid successfully preserves crucial low-frequency attention components that conventional methods fail to transfer. Our work not only provides practical techniques for building more efficient long-context VLMs but also offers theoretical insights into how positional understanding emerges and transfers during distillation.

</details>


### [143] [Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model](https://arxiv.org/abs/2601.02112)
*Utkarsh Singh,Absaar Ali,Adarsh Roy*

Main category: cs.CV

TL;DR: 本文提出了一种基于序列化横截面切片处理的轻量级代理模型，用于快速准确预测车辆气动阻力系数（Cd），在DrivAerNet++数据集上实现了高R²值（>0.9528）和低MAE（≈6.046×10⁻³），单样本推理时间仅约0.025秒。


<details>
  <summary>Details</summary>
Motivation: 传统气动性能评估方法（如CFD和风洞试验）资源消耗大、迭代慢，难以支撑早期设计阶段的快速探索；现有机器学习代理模型存在计算复杂度高、可解释性差或对精细几何输入精度不足等问题。

Method: 将车辆3D点云沿流向轴分解为有序2D横截面序列；每个切片由轻量级PointNet2D编码；切片嵌入序列经双向LSTM建模纵向几何演化；最终回归预测Cd。

Result: 在DrivAerNet++数据集上达到R² > 0.9528、MAE ≈ 6.046×10⁻³；单样本GPU推理耗时约0.025秒；兼具高精度、低延迟与一定可解释性。

Conclusion: 该轻量级序列化切片模型为汽车早期气动设计提供了高效、准确且实用的替代评估工具，显著提升了设计迭代效率与决策支持能力。

Abstract: The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.

</details>


### [144] [Remote Sensing Change Detection via Weak Temporal Supervision](https://arxiv.org/abs/2601.02126)
*Xavier Bou,Elliot Vincent,Gabriele Facciolo,Rafael Grompone von Gioi,Jean-Michel Morel,Thibaud Ehret*

Main category: cs.CV

TL;DR: 本文提出了一种弱时间监督策略，利用现有单时相遥感数据集的额外时序观测，无需新标注即可训练变化检测模型，通过假设真实双时相图像对多为无变化、跨地点配对生成变化样本，并结合目标感知变化图生成与迭代优化来处理弱标签噪声，在多个基准上实现了零样本和低数据场景下的优异性能。


<details>
  <summary>Details</summary>
Motivation: 遥感语义变化检测受限于像素级标注数据稀缺，人工标注成本高；现有基于合成数据或人工构造变化对的方法泛化能力有限。

Method: 提出弱时间监督策略：利用单时相数据集的额外时序观测，构建‘同地双时’（多数无变化）和‘异地双时’（构造变化）样本对；引入对象感知的变化图生成模块和迭代精炼机制以缓解弱标签噪声。

Result: 在扩展的FLAIR和IAILD航拍数据集上验证，零样本和少样本设置下性能显著优于基线；在法国大范围区域展示出良好可扩展性。

Conclusion: 无需新增标注，仅利用已有单时相数据的多时序扩展即可有效提升变化检测模型训练效果，为解决标注瓶颈提供了新范式。

Abstract: Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.

</details>


### [145] [Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery](https://arxiv.org/abs/2601.02139)
*Chenyang Lai,Shuaiyu Chen,Tianjin Huang,Siyang Song,Guangliang Cheng,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

TL;DR: 本文提出了一种基于双时相SAR图像的油污变化检测新任务（OSCD），并设计了时序感知混合修复框架（TAHI）生成合成的灾前图像，构建首个OSCD数据集，显著降低了误检率，提升了检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于单幅SAR图像的深度学习分割方法难以区分真实油污与类似海洋现象（如生物膜或低风区），导致高误报率和泛化能力差，尤其在数据稀缺时。

Method: 提出油污变化检测（OSCD）新任务；设计TAHI框架，包含高保真混合修复模块（生成无油区域）和时序真实性增强模块（保证辐射与海况一致性）；构建首个OSCD数据集并评测主流变化检测模型。

Result: OSCD方法相比传统单图分割显著降低误报率、提升检测精度，在真实场景中展现出更强的可靠性与可扩展性。

Conclusion: 引入时序感知的变化检测范式比静态单图分割更适用于鲁棒、可扩展的海上溢油监测任务。

Abstract: Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.

</details>


### [146] [Efficient Unrolled Networks for Large-Scale 3D Inverse Problems](https://arxiv.org/abs/2601.02141)
*Romain Vo,Julián Tachella*

Main category: cs.CV

TL;DR: 本文提出了一种域划分策略和正规算子近似方法，使端到端重建模型能在内存受限下嵌入任意大规模成像问题的前向算子，显著提升3D锥束CT和多线圈加速MRI重建性能，且仅需单GPU。


<details>
  <summary>Details</summary>
Motivation: 现有深度展开方法在3D等大规模成像逆问题中因全局前向算子内存开销过大而难以嵌入网络架构，限制了性能提升。

Method: 提出域划分策略与正规算子近似技术，以降低前向/反向算子内存占用，支持端到端训练含精确成像物理模型的大规模重建网络。

Result: 在3D X射线锥束CT和3D多线圈加速MRI任务上达到SOTA性能，训练和推理均仅需单GPU。

Conclusion: 该方法有效解决了大规模成像逆问题中物理模型嵌入的内存瓶颈，为高维医学影像重建提供了高效、可扩展的深度学习解决方案。

Abstract: Deep learning-based methods have revolutionized the field of imaging inverse problems, yielding state-of-the-art performance across various imaging domains. The best performing networks incorporate the imaging operator within the network architecture, typically in the form of deep unrolling. However, in large-scale problems, such as 3D imaging, most existing methods fail to incorporate the operator in the architecture due to the prohibitive amount of memory required by global forward operators, which hinder typical patching strategies. In this work, we present a domain partitioning strategy and normal operator approximations that enable the training of end-to-end reconstruction models incorporating forward operators of arbitrarily large problems into their architecture. The proposed method achieves state-of-the-art performance on 3D X-ray cone-beam tomography and 3D multi-coil accelerated MRI, while requiring only a single GPU for both training and inference.

</details>


### [147] [BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models](https://arxiv.org/abs/2601.02147)
*Sunny Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

TL;DR: 本文提出BiPrompt框架，在测试时通过双边提示优化同时减少视觉和文本模态中的虚假相关性，提升零样本泛化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法通常只针对单一模态（视觉或文本），导致鲁棒性不充分且在分布偏移下适应不稳定。

Method: 提出双边提示优化框架（BiPrompt）：视觉侧采用结构化注意力引导擦除抑制背景激活；文本侧引入平衡提示归一化机制，使类别嵌入对齐各向同性语义空间；二者联合最小化虚假线索与预测间的条件互信息。

Result: 在真实与合成偏差基准上，平均准确率和最差组准确率均一致优于现有测试时去偏方法。

Conclusion: BiPrompt提供了一种轻量、无需重训练或领域监督的因果可信视觉语言自适应新路径。

Abstract: Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.

</details>


### [148] [Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32](https://arxiv.org/abs/2601.02177)
*Oliver Custance,Saad Khan,Simon Parkinson*

Main category: cs.CV

TL;DR: 本文系统评估了六种信号分离方法在使用低成本ESP32 WiFi传感器进行多人步态识别时的性能，发现所有方法准确率均低（45–56%），且无统计显著差异，表明问题根源在于硬件限制而非算法不足。


<details>
  <summary>Details</summary>
Motivation: 探究多人步态识别性能差是源于算法局限还是商用WiFi硬件（如ESP32）的根本性信号质量限制。

Method: 在1–10人场景下，使用商用ESP32传感器采集CSI数据，系统评估FastICA、SOBI、PCA、NMF、小波变换和张量分解六种信号分离方法，并引入新诊断指标（个体内变异性、个体间可区分性、性能退化率）进行分析。

Result: 所有方法准确率均处于较低水平（45–56%，标准差3.74%），统计上无显著差异（p > 0.05）；NMF表现最优但仅达56%；同时观察到高个体内变异、低个体间可区分性及随人数增加性能急剧下降。

Conclusion: 商用ESP32传感器因信号质量不足，无法支撑可靠的多人步态分离，该瓶颈属硬件约束，非当前算法可突破。

Abstract: WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\%, $σ$=3.74\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.

</details>


### [149] [QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition](https://arxiv.org/abs/2601.02189)
*Cheng Ying Wu,Yen Jui Chang*

Main category: cs.CV

TL;DR: 本文提出了一种受量子力学启发的轻量级分类器QuIC，用于在边缘设备上提升细粒度视觉分类（FGVC）性能，尤其显著增强浅层网络（如VGG16、ResNet18）的判别能力，避免高维双线性特征与训练不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度模型计算开销大，难以部署于边缘设备；而浅层网络虽高效，却因传统GAP仅捕获一阶统计信息，难以区分视觉相似子类；双线性CNN虽建模高阶交互但存在维度爆炸和训练不稳定问题。

Method: 提出量子启发的交互分类器（QuIC），将特征通道建模为相互作用的量子态，通过可学习的可观测算子捕获二阶特征协方差；设计为即插即用、轻量、单阶段端到端可训模块。

Result: QuIC使VGG16在CUB-200-2011上Top-1准确率提升近20%，在ResNet18上优于SE-Block等先进注意力机制；t-SNE可视化证实其能增强类内紧凑性和细粒度判别性。

Conclusion: QuIC有效弥合了精度与效率之间的鸿沟，为资源受限场景下的FGVC提供了稳定、高效且物理启发的新范式。

Abstract: Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.

</details>


### [150] [Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models](https://arxiv.org/abs/2601.02198)
*Alexander Möllers,Julius Hense,Florian Schulz,Timo Milbich,Maximilian Alber,Lukas Ruff*

Main category: cs.CV

TL;DR: 本文研究病理学基础模型在不同放大倍率下的性能表现，提出连续放大倍率采样策略以解决离散采样导致的中间倍率性能下降问题，并设计新基准数据集验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 病理学中低倍和高倍图像对诊断均重要，但现有基础模型在不同放大倍率下性能差异大，且训练时放大倍率采样策略的影响尚不明确。

Method: 将放大倍率采样建模为多源领域自适应问题，构建理论框架分析采样策略权衡；提出连续放大倍率采样方法并推导优化采样分布；构建TCGA-MS和BRACS-MS两个新基准数据集及相应评估指标。

Result: 连续采样在中间倍率上显著优于离散采样，平衡分类准确率最高提升4个百分点；优化采样分布可进一步提升性能；放大倍率是当前病理基础模型性能差异的主要驱动因素。

Conclusion: 连续且优化的放大倍率采样能提升模型跨倍率鲁棒性，为构建可靠、泛化性强的病理学基础模型奠定基础。

Abstract: In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.

</details>


### [151] [Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules](https://arxiv.org/abs/2601.02203)
*Oliver Custance,Saad Khan,Simon Parkinson,Quan Z. Sheng*

Main category: cs.CV

TL;DR: 本文提出了一种基于WiFi CSI的无设备人群计数新框架CSI-ResNet-A，通过自监督对比学习预训练和轻量级Adapter微调，显著提升跨环境泛化能力，在WiFlow和WiAR数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: WiFi CSI无设备人群计数因域偏移问题难以实际部署，亟需提升模型跨环境泛化能力。

Method: 提出两阶段框架：1）基于CSI-ResNet-A架构，采用自监督对比学习预训练以学习域不变表征；2）引入轻量Adapter模块实现高效微调；3）结合状态式计数机生成稳定人数估计。

Result: 在WiFlow数据集10-shot场景下MAE仅0.44；Generalisation Index接近满分；WiAR基准准确率达98.8%；Adapter微调参数量减少97.2%，性能达全微调的98.84%。

Conclusion: 该框架为真实IoT场景提供了实用、可扩展且鲁棒的感知系统解决方案。

Abstract: Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\% of a full fine-tune (98.84\% vs. 99.67\%) while training 97.2\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.

</details>


### [152] [NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation](https://arxiv.org/abs/2601.02204)
*Huichao Zhang,Liao Qu,Yiheng Liu,Hang Chen,Yangyang Song,Yongsheng Dong,Shikun Sun,Xian Li,Xu Wang,Yi Jiang,Hu Ye,Bo Chen,Yiming Gao,Peng Liu,Akide Liu,Zhipeng Yang,Qili Deng,Linjie Xing,Jiyang Liu,Zhao Wang,Yang Zhou,Mingcong Liu,Yi Zhang,Qian He,Xiwei Hu,Zhongqi Qi,Jie Shao,Zhiye Fu,Shuai Wang,Fangmin Chen,Xuezhi Chai,Zhihua Wu,Yitong Wang,Zehuan Yuan,Daniel K. Du,Xinglong Wu*

Main category: cs.CV

TL;DR: NextFlow 是一个在6万亿文本-图像离散token上训练的统一解码器-only自回归Transformer，通过引入next-scale预测机制显著加速图像生成，并支持图像编辑、图文交织与视频生成等多模态任务。


<details>
  <summary>Details</summary>
Motivation: 文本是严格序列化的，而图像是层次化的，因此需要为不同模态设计适配的预测方式（文本用next-token，图像用next-scale），以兼顾效率与生成质量。

Method: 提出统一的自回归架构，采用next-scale预测替代传统光栅扫描式图像生成；设计鲁棒的多尺度训练策略和面向强化学习的前缀微调方法。

Result: 在1024x1024图像生成上仅需5秒，速度远超同类自回归模型；在统一模型中达到SOTA，并在视觉质量上媲美专用扩散模型。

Conclusion: NextFlow验证了统一自回归框架在多模态生成中的可行性与高效性，为通用多模态大模型提供了新范式。

Abstract: We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.

</details>


### [153] [Seeing the Unseen: Zooming in the Dark with Event Cameras](https://arxiv.org/abs/2601.02206)
*Dachun Kai,Zeyu Xiao,Huyue Zhu,Jiaxiao Wang,Yueyi Zhang,Xiaoyan Sun*

Main category: cs.CV

TL;DR: 本文提出RetinexEVSR，首个基于事件驱动的低光照视频超分辨率框架，结合Retinex先验与高对比度事件信号，通过双向跨模态融合提升细节恢复能力，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有低光照视频超分辨率（LVSR）方法因低对比度和高频信息不足，难以恢复精细细节。

Method: 提出RetinexEVSR框架：1）采用双向跨模态融合策略，联合处理噪声事件数据与退化RGB帧；2）设计照度引导的事件增强模块，利用Retinex模型生成的照度图逐步优化事件特征；3）提出事件引导的反射率增强模块，通过多尺度融合动态恢复反射率细节。

Result: 在三个数据集上达到SOTA性能；在SDSD基准上PSNR提升达2.95 dB，运行时间减少65%。

Conclusion: RetinexEVSR有效融合事件信号与Retinex先验，在低光照视频超分辨率任务中显著提升重建质量与效率，为事件相机辅助低光照视频增强提供了新范式。

Abstract: This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.

</details>


### [154] [Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion](https://arxiv.org/abs/2601.02211)
*Binglei Li,Mengping Yang,Zhiyu Tan,Junping Zhang,Hao Li*

Main category: cs.CV

TL;DR: 本文提出了一种系统性分析MMDiT模型各模块功能的方法，并基于发现提出了无需训练的文本对齐、精确编辑与推理加速新策略，在多个指标上显著提升SD3.5性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅分析MMDiT中个别组件（如位置编码、注意力层），缺乏对不同模块及其与文本条件交互如何影响图像合成过程的全面理解。

Method: 构建系统性分析流程，通过在对应模块移除、禁用或增强文本隐状态，探究各模块功能；基于分析结果设计训练-free的文本对齐、编辑与加速策略。

Result: 发现：1）语义信息出现在较早模块，细节在后期生成；2）移除模块通常比禁用文本条件影响小；3）选择性增强文本条件可提升语义属性。所提方法在T2I-Combench++和GenEval上分别提升至63.00%和71.63%。

Conclusion: 该工作深化了对MMDiT模型内部机制的理解，为文本到图像生成、编辑及加速提供了新思路与实用工具。

Abstract: Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.

</details>


### [155] [Prior-Guided DETR for Ultrasound Nodule Detection](https://arxiv.org/abs/2601.02212)
*Jingjing Wang,Zhuo Xiao,Xinning Yao,Bo Liu,Lijuan Niu,Xiangzhi Bai,Fugen Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种先验引导的DETR框架用于超声结节检测，通过在CNN骨干网络中嵌入空间自适应可变形FFN（SDFPR）、设计多尺度空频特征混合器（MSFFM）以及密集特征交互机制（DFI），融合几何与结构先验知识，显著提升了不规则、模糊及多尺度结节的检测精度。


<details>
  <summary>Details</summary>
Motivation: 超声结节检测面临形状不规则、边界模糊、尺度变化大及斑点噪声干扰等挑战，现有纯数据驱动方法难以有效建模先验知识。

Method: 提出先验引导的DETR框架：1）在CNN骨干中嵌入SDFPR模块注入几何先验；2）设计MSFFM模块联合建模空域（轮廓连续性）与频域（全局形态+去噪）结构先验；3）引入DFI机制在编码器各层传播先验调制特征以指导解码器查询优化。

Result: 在两个甲状腺超声临床数据集（Thyroid I/II）和两个公开基准（TN3K、BUSI）上超越18种检测方法，尤其对形态复杂结节检测性能更优。

Conclusion: 融合多阶段、多类型先验知识的DETR框架能有效提升超声结节检测鲁棒性与精度，为医学图像检测提供了可解释、可推广的新范式。

Abstract: Accurate detection of ultrasound nodules is essential for the early diagnosis and treatment of thyroid and breast cancers. However, this task remains challenging due to irregular nodule shapes, indistinct boundaries, substantial scale variations, and the presence of speckle noise that degrades structural visibility. To address these challenges, we propose a prior-guided DETR framework specifically designed for ultrasound nodule detection. Instead of relying on purely data-driven feature learning, the proposed framework progressively incorporates different prior knowledge at multiple stages of the network. First, a Spatially-adaptive Deformable FFN with Prior Regularization (SDFPR) is embedded into the CNN backbone to inject geometric priors into deformable sampling, stabilizing feature extraction for irregular and blurred nodules. Second, a Multi-scale Spatial-Frequency Feature Mixer (MSFFM) is designed to extract multi-scale structural priors, where spatial-domain processing emphasizes contour continuity and boundary cues, while frequency-domain modeling captures global morphology and suppresses speckle noise. Furthermore, a Dense Feature Interaction (DFI) mechanism propagates and exploits these prior-modulated features across all encoder layers, enabling the decoder to enhance query refinement under consistent geometric and structural guidance. Experiments conducted on two clinically collected thyroid ultrasound datasets (Thyroid I and Thyroid II) and two public benchmarks (TN3K and BUSI) for thyroid and breast nodules demonstrate that the proposed method achieves superior accuracy compared with 18 detection methods, particularly in detecting morphologically complex nodules.The source code is publicly available at https://github.com/wjj1wjj/Ultrasound-DETR.

</details>


### [156] [FMVP: Masked Flow Matching for Adversarial Video Purification](https://arxiv.org/abs/2601.02228)
*Duoxun Tang,Xueyi Zhang,Chak Hin Wang,Xi Xiao,Dasen Dai,Xinhang Jiang,Wentao Shi,Rui Li,Qing Li*

Main category: cs.CV

TL;DR: 本文提出Flow Matching for Adversarial Video Purification (FMVP)，通过掩码策略物理打碎对抗结构，并利用带inpainting目标的条件流匹配（CFM）重建视频动态；引入频率门控损失（FGL）抑制高频对抗残差、保留低频保真度；设计攻击感知与通用训练范式；在UCF-101和HMDB-51上显著优于DiffPure等SOTA方法，鲁棒准确率超87%（PGD）/89%（CW），并具备零样本检测能力（PGD 98%，CW 79%）。


<details>
  <summary>Details</summary>
Motivation: 现有扩散类视频净化方法采样效率低、轨迹弯曲；直接回归干净视频难以恢复细微扰动下的真实内容，需物理层面破坏对抗结构。

Method: 提出FMVP框架：1）掩码策略物理打碎全局对抗结构；2）基于条件流匹配（CFM）与inpainting目标重建视频动态；3）设计频率门控损失（FGL）解耦语义内容与对抗噪声；4）构建Attack-Aware和Generalist两种训练范式。

Result: 在UCF-101和HMDB-51上，FMVP对PGD和CW攻击的鲁棒准确率分别达87%和89%，显著优于DiffPure、DP、TS、FlowPure；对自适应攻击DiffHammer鲁棒性更强；且可作为零样本对抗检测器，PGD和CW检测准确率分别为98%和79%。

Conclusion: FMVP通过物理结构破坏、流匹配重建与频率感知损失，有效提升视频模型对抗鲁棒性与检测能力，兼具高效性与泛化性。

Abstract: Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.

</details>


### [157] [VIBE: Visual Instruction Based Editor](https://arxiv.org/abs/2601.02242)
*Grigorii Alekseenko,Aleksandr Gordeev,Irina Tolstykh,Bulat Suleimanov,Vladimir Dokholyan,Georgii Fedorov,Sergey Yakubson,Aleksandra Tsybina,Mikhail Chernyshov,Maksim Kuprashevich*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、高吞吐量的指令驱动图像编辑方法，采用2B参数的Qwen3-VL模型指导编辑、1.6B参数的Sana1.5扩散模型生成图像，在保持高质量的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有开源指令编辑模型大多参数量大、推理成本高，难以部署；同时真正达到实用质量的开源方案仍有限。

Method: 构建基于Qwen3-VL（2B）与Sana1.5（1.6B）的紧凑型指令编辑流水线，在架构、数据处理、训练配置和评估上兼顾低成本推理与源图像一致性。

Result: 在ImgEdit和GEdit基准上性能媲美甚至超越参数量数倍的基线模型，尤其擅长属性调整、物体移除、背景编辑与目标替换等需强源一致性的任务；可在24GB GPU内存内运行，H100上BF16精度下4秒生成2K图像。

Conclusion: 证明了小规模多模态大模型+轻量扩散模型的组合可在指令编辑任务中实现高性能与高效率的平衡，为低资源场景提供可行方案。

Abstract: Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.

</details>


### [158] [A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets](https://arxiv.org/abs/2601.02246)
*Annoor Sharara Akhand*

Main category: cs.CV

TL;DR: This paper compares three CNN paradigms—training from scratch, using pre-trained CNNs as fixed feature extractors, and transfer learning via fine-tuning—across five real-world image classification tasks, finding that transfer learning delivers best accuracy, while custom CNNs offer better efficiency–accuracy trade-offs under resource constraints.


<details>
  <summary>Details</summary>
Motivation: To systematically compare the performance and efficiency of three common CNN usage paradigms—custom training from scratch, fixed-feature extraction with pre-trained models, and transfer learning—in practical, real-world visual recognition tasks.

Method: Controlled experimental comparison across five domain-specific image classification datasets; evaluation metrics include accuracy, macro F1-score, training time per epoch, and parameter count.

Result: Transfer learning consistently achieves the highest predictive performance (accuracy and macro F1); custom CNNs are most efficient in terms of training time and parameters, offering a favorable accuracy–efficiency trade-off under limited compute/memory.

Conclusion: The choice among CNN paradigms should be guided by task requirements: transfer learning is optimal for accuracy, while custom CNNs are preferable when efficiency and resource constraints are critical.

Abstract: Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.

</details>


### [159] [SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection](https://arxiv.org/abs/2601.02249)
*Xiantai Xiang,Guangyao Zhou,Zixiao Wen,Wenshuai Li,Ben Niu,Feng Wang,Lijia Huang,Qiantong Wang,Yuhan Liu,Zongxu Pan,Yuxin Hu*

Main category: cs.CV

TL;DR: SLGNet是一种参数高效的多模态目标检测框架，结合结构感知适配器和语言引导调制模块，在冻结ViT基础模型下提升RGB-红外跨模态结构一致性与环境适应性，显著提升夜间及高对比度场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于适配器的RGB-红外多模态检测方法在追求效率时牺牲了跨模态结构一致性，且静态融合机制缺乏环境感知能力，难以应对高对比度、夜间等复杂场景。

Method: 提出SLGNet：1）结构感知适配器，从双模态中提取分层结构表征并动态注入冻结ViT；2）语言引导调制模块，利用VLM生成的结构化字幕动态重校准视觉特征。

Result: 在LLVIP、FLIR、KAIST和DroneVehicle数据集上达到SOTA；LLVIP上mAP达66.1，可训练参数比全微调减少约87%。

Conclusion: SLGNet在保持高效率的同时显著增强了跨模态结构一致性和环境适应性，是鲁棒高效的多模态感知解决方案。

Abstract: Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.

</details>


### [160] [VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation](https://arxiv.org/abs/2601.02256)
*Shikun Sun,Liao Qu,Huichao Zhang,Yiheng Liu,Yangyang Song,Xian Li,Xu Wang,Yi Jiang,Daniel K. Du,Xinglong Wu,Jia Jia*

Main category: cs.CV

TL;DR: 本文提出了一种增强Group Relative Policy Optimization（GRPO）的新框架，以解决视觉自回归（VAR）模型在强化学习中因异构输入结构导致的异步策略冲突问题，通过引入中间奖励、动态时间步重加权和掩码传播算法，显著提升了样本质量和目标对齐效果。


<details>
  <summary>Details</summary>
Motivation: 视觉生成中的VAR模型在生成过程中处理异构输入结构，导致严重的异步策略冲突，尤其在强化学习场景下引发训练不稳定和对齐不佳。

Method: 提出一种新框架，包含三部分：1）稳定早期生成的中间奖励；2）用于精确信用分配的动态时间步重加权机制；3）基于Reward Feedback Learning（ReFL）原理设计的掩码传播算法，实现空间与时间上的优化效应隔离。

Result: 相比原始GRPO基线，在样本质量和目标对齐方面均有显著提升，实现了VAR模型鲁棒有效的优化。

Conclusion: 所提框架能有效缓解VAR模型在RL训练中的异步策略冲突问题，为视觉生成中基于策略梯度的优化提供了新思路与实用工具。

Abstract: Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.

</details>


### [161] [DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies](https://arxiv.org/abs/2601.02267)
*Renke Wang,Zhenyu Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

TL;DR: 本文提出DiffProxy框架，利用扩散模型生成多视角一致的人体代理，以解决真实数据标注不准确和合成数据存在域偏移的问题，在仅使用合成数据训练的情况下实现了零样本泛化，并在多个真实世界基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据集中的不完美真值标注会偏差模型训练，而具有精确监督的合成数据则存在域偏移问题。

Method: 提出DiffProxy框架，核心是利用基于扩散的生成先验来弥合合成训练与真实世界泛化之间的差距；包含多条件生成机制、手部细化模块和不确定性感知的测试时缩放方法。

Result: 在五个真实世界基准上达到最先进性能，尤其在遮挡和部分视角等挑战性场景中表现出强零样本泛化能力。

Conclusion: DiffProxy通过结合合成数据的精确监督与扩散模型的生成优势，有效提升了多视角人体网格恢复的鲁棒性与泛化能力。

Abstract: Human mesh recovery from multi-view images faces a fundamental challenge: real-world datasets contain imperfect ground-truth annotations that bias the models' training, while synthetic data with precise supervision suffers from domain gap. In this paper, we propose DiffProxy, a novel framework that generates multi-view consistent human proxies for mesh recovery. Central to DiffProxy is leveraging the diffusion-based generative priors to bridge the synthetic training and real-world generalization. Its key innovations include: (1) a multi-conditional mechanism for generating multi-view consistent, pixel-aligned human proxies; (2) a hand refinement module that incorporates flexible visual prompts to enhance local details; and (3) an uncertainty-aware test-time scaling method that increases robustness to challenging cases during optimization. These designs ensure that the mesh recovery process effectively benefits from the precise synthetic ground truth and generative advantages of the diffusion-based pipeline. Trained entirely on synthetic data, DiffProxy achieves state-of-the-art performance across five real-world benchmarks, demonstrating strong zero-shot generalization particularly on challenging scenarios with occlusions and partial views. Project page: https://wrk226.github.io/DiffProxy.html

</details>


### [162] [TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation](https://arxiv.org/abs/2601.02273)
*Salim Khazem*

Main category: cs.CV

TL;DR: 本文提出TopoLoRA-SAM，一种面向二值语义分割的拓扑感知、参数高效适配框架，通过在冻结ViT编码器中注入LoRA与轻量空间卷积适配器，并可选地引入可微clDice拓扑监督，在多个医学与遥感数据集上以仅训练5.2%参数实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 基础分割模型（如SAM）零样本泛化能力强，但在适配领域特定任务（尤其是细长结构和噪声模态）时面临挑战；全量微调计算昂贵且易灾难性遗忘。

Method: 在冻结ViT编码器中注入LoRA模块，加入轻量空间卷积适配器，并可选地采用可微clDice作为拓扑感知监督信号，构建参数高效的二值分割适配框架TopoLoRA-SAM。

Result: 在五个基准（DRIVE、STARE、CHASE_DB1、Kvasir-SEG、SL-SSDD）上，TopoLoRA-SAM取得最佳视网膜平均Dice和整体平均Dice，仅训练5.2%参数（约490万），在CHASE_DB1上显著提升精度与鲁棒性。

Conclusion: 拓扑感知的参数高效适配方法可在极低参数更新代价下，达到甚至超越全量微调的专业模型性能，为SAM在细粒度、噪声敏感场景的落地提供新范式。

Abstract: Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \textbf{5.2\%} of model parameters ($\sim$4.9M). On the challenging CHASE\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git

</details>


### [163] [InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams](https://arxiv.org/abs/2601.02281)
*Shuai Yuan,Yantai Yang,Xiaotian Yang,Xupeng Zhang,Zhonghao Zhao,Lingming Zhang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 本文提出InfiniteVGGT，一种因果视觉几何变换器，通过自适应、有界但持续表达的KV缓存实现滚动记忆，并设计无训练、注意力无关的剪枝策略，支持无限时序输入且长期稳定；同时发布首个超长序列（约10,000帧）3D几何估计基准Long3D。


<details>
  <summary>Details</summary>
Motivation: 现有离线模型（如VGGT）无法用于实时系统，而流式架构又难以兼顾无限时序输入与长期稳定性（存在灾难性漂移），亟需打破这一长期困境。

Method: 提出InfiniteVGGT：基于因果Transformer架构，引入滚动KV缓存机制，并设计训练无关、注意力无关的动态剪枝策略以维持内存有效性；完全兼容FlashAttention。

Result: InfiniteVGGT在无限时序流式输入下保持高稳定性，性能超越现有流式方法；并构建首个超长时序3D几何评估基准Long3D（约10,000帧）。

Conclusion: InfiniteVGGT成功解决了大规模3D视觉几何理解中可扩展性与长期稳定性不可兼得的根本矛盾，为持久化、实时化3D理解提供了新范式。

Abstract: The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

</details>


### [164] [Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2601.02289)
*Tom Burgert,Leonard Hackel,Paolo Rota,Begüm Demir*

Main category: cs.CV

TL;DR: 本文提出了GeoRank，一种用于对比自监督学习的新正则化方法，通过直接优化球面距离将地理关系嵌入特征空间，显著提升了多光谱遥感图像的表征学习性能。


<details>
  <summary>Details</summary>
Motivation: 多光谱遥感图像具有显著的地理与时间变异性，现有自监督学习方法难以有效建模其空间结构信息，亟需引入地理先验以提升表征质量。

Method: 提出GeoRank正则化方法，在对比自监督学习（如BYOL、DINO）中显式约束样本在单位球面上的嵌入距离，使其与地理距离（经纬度）保持一致；并系统分析了数据增强、数据集规模、图像尺寸及时间视图等关键因素对遥感SSL的影响。

Result: GeoRank在多个遥感基准上超越或持平于引入地理元数据的现有方法，并兼容多种主流对比SSL算法；实验验证了地理正则化的有效性及各SSL设计要素对遥感任务的特异性影响。

Conclusion: 地理结构是多光谱遥感自监督学习的关键归纳偏置，GeoRank为将地理先验融入SSL提供了简洁而有效的范式，推动了遥感视觉表征学习的发展。

Abstract: Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.

</details>


### [165] [SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting](https://arxiv.org/abs/2601.02299)
*Sara Inácio,Hugo Proença,João C. Neves*

Main category: cs.CV

TL;DR: 本文提出了SortWaste数据集和ClutterScore评估指标，用于提升真实场景下垃圾自动分拣的检测性能，但现有模型在高杂乱度场景中性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 人工分拣效率低、有健康风险；现有自动化方法难以应对真实垃圾流的高度可变性、杂乱性和视觉复杂性；缺乏真实世界垃圾分拣数据集制约了该领域发展。

Method: 构建了来自材料回收设施的密集标注目标检测数据集SortWaste；提出ClutterScore指标，通过物体数量、类别与尺寸熵、空间重叠等代理变量量化场景难度；对多种SOTA目标检测模型进行系统基准测试，并按ClutterScore分层分析性能。

Result: 在纯塑料检测任务中达到59.7% mAP；但随着ClutterScore升高（即场景更杂乱），模型性能显著下降。

Conclusion: 当前模型在真实复杂垃圾场景中仍不足，亟需更具挑战性的新数据集推动算法进步。

Abstract: The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.

</details>


### [166] [360DVO: Deep Visual Odometry for Monocular 360-Degree Camera](https://arxiv.org/abs/2601.02309)
*Xiaopeng Guo,Yinzhe Xu,Huajian Huang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: 本文提出了首个基于深度学习的单目全向视觉里程计（OVO）框架360DVO，通过引入畸变感知球面特征提取器（DAS-Feat）和全向可微束调整（ODBA）模块，显著提升了在剧烈运动和光照变化等挑战场景下的鲁棒性与精度。


<details>
  <summary>Details</summary>
Motivation: 现有单目全向视觉里程计方法依赖手工设计特征或光度目标函数，在剧烈运动和光照变化等挑战性场景下鲁棒性不足。

Method: 提出360DVO框架，包含畸变感知球面特征提取器（DAS-Feat）用于提取畸变鲁棒的稀疏特征，并结合全向可微束调整（ODBA）模块进行位姿估计；同时构建了新的真实世界OVO基准用于评估。

Result: 在自建真实世界OVO基准及公开合成数据集（TartanAir V2、360VO）上实验表明，360DVO相较SOTA方法（如360VO、OpenVSLAM）鲁棒性提升50%，精度提升37.5%。

Conclusion: 360DVO是首个端到端深度学习驱动的OVO系统，有效解决了传统方法在复杂场景下的鲁棒性与精度瓶颈，为全向视觉导航提供了新范式。

Abstract: Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage

</details>


### [167] [Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping](https://arxiv.org/abs/2601.02315)
*Saurabh Kaushik,Lalit Maurya,Beth Tellman*

Main category: cs.CV

TL;DR: 本文提出Prithvi-CAFE模型，通过将Prithvi地理基础模型与带卷积注意力模块（CAM）的CNN残差分支融合，并引入适配器实现高效微调，在洪水制图任务中显著提升局部细节捕捉能力，于Sen1Flood11和FloodPlanet数据集上均达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有Geo-Foundation Models（GFMs）在Sen1Flood11洪水制图任务中难以超越U-Net基线，暴露出其对关键局部细节建模能力不足的问题。

Method: 提出Prithvi-Complementary Adaptive Fusion Encoder（CAFE）：将Prithvi预训练编码器与并行CNN残差分支结合，CNN分支嵌入Convolutional Attention Modules（CAM）；采用Adapter进行轻量微调，并实现多尺度、多层级特征融合。

Result: 在Sen1Flood11测试集上IoU达83.41，优于原Prithvi（82.50）、TerraMind（82.90）等；在保留测试站点上IoU达81.37，大幅领先U-Net（70.57）和原Prithvi（72.42）；在FloodPlanet上IoU为64.70，亦优于U-Net（60.14）及其他GFMs。

Conclusion: Prithvi-CAFE是一种简单而有效的架构，能有效融合多源遥感信息，在强调局部细节与多模态互补性的地表分割任务中展现出强大潜力。

Abstract: Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}

</details>


### [168] [Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318)
*Roja Sahoo,Anoop Namboodiri*

Main category: cs.CV

TL;DR: 本文提出Fusion2Print（F2P）框架，首次系统性融合闪光与非闪光接触式指纹图像，通过自建配对数据集、手动减法提取脊线信号、轻量注意力融合网络及U-Net增强模块，生成高质量灰度图，并利用跨域兼容嵌入模型实现高精度识别。


<details>
  <summary>Details</summary>
Motivation: 接触式指纹识别存在卫生与压力伪影问题；而接触式图像因光照变化、皮下色素沉着和镜面反射导致脊线清晰度下降，单一闪光或非闪光采集各有缺陷。

Method: 构建FNF配对数据库；手动进行闪光-非闪光图像减法以保留脊线信号；设计轻量注意力融合网络整合双模态信息；采用U-Net增强模块生成优化灰度图；使用跨域兼容深度嵌入模型统一表征接触式与接触式指纹。

Result: F2P显著提升脊线清晰度，在识别性能上优于单模态基线（Verifinger、DeepPrint），达到AUC=0.999、EER=1.12%。

Conclusion: F2P是首个系统融合闪光与非闪光接触式指纹的框架，兼顾噪声抑制与脊线对比度增强，具备跨域兼容性，为接触式指纹识别提供了新范式。

Abstract: Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).

</details>


### [169] [BEDS: Bayesian Emergent Dissipative Structures](https://arxiv.org/abs/2601.02329)
*Laurent Caraffa*

Main category: cs.CV

TL;DR: 本文提出BEDS框架，将非平衡热力学、贝叶斯推理与机器学习统一，指出学习本质是通过熵输出将通量转化为结构；推导出e、π、φ为贝叶斯推理的自然固定点，并猜想哥德尔不完备性与热力学耗散不足存在结构类比；最后实现了一种高能效的对等网络架构验证该理论。


<details>
  <summary>Details</summary>
Motivation: 统一物理、生物与计算系统中的学习机制，弥合理论（热力学、逻辑）与实践（AI能效）之间的鸿沟，探索学习与智能的本质物理基础。

Method: 建立热力学过程与贝叶斯更新之间的形式同构；基于最小公理推导数学常数作为贝叶斯推理的不动点；提出耗散不足与形式系统病理之间的类比猜想；设计并实现符合BEDS原理的节能型P2P网络架构。

Result: 揭示学习即熵导引的结构涌现过程；证明e、π、φ可从基本不确定性表征中必然导出；提出热力学约束与逻辑不完备性的结构性关联假说；所实现P2P系统在分布式共识任务中能效提升六个数量级并支持持续学习。

Conclusion: 学习不是抽象的信息处理，而是具身于物理世界的耗散过程；BEDS为可持续AI提供了兼具理论深度与工程可行性的新范式。

Abstract: We present BEDS (Bayesian Emergent Dissipative Structures), a theoretical framework that unifies concepts from non-equilibrium thermodynamics, Bayesian inference, information geometry, and machine learning. The central thesis proposes that learning, across physical, biological, and computational systems, fundamentally constitutes the conversion of flux into structure through entropy export. Building on Prigogine's theory of dissipative structures, we establish a formal isomorphism between thermodynamic processes and Bayesian updating, demonstrating that sustainable learning systems must follow dissipative patterns where crystallized posteriors become priors for subsequent levels of emergence.
  We derive fundamental mathematical constants (e, π, φ) as fixed points of Bayesian inference under minimal axioms, suggesting these constants emerge necessarily from any system capable of representing and updating uncertainty. Furthermore, we propose a conjecture linking Gödel's incompleteness theorems to thermodynamic constraints, hypothesizing that pathologies of formal systems (incompleteness, undecidability) are structurally analogous to dissipation deficits in physical systems.
  As practical validation, we present a peer-to-peer network architecture implementing BEDS principles, achieving six orders of magnitude improvement in energy efficiency compared to existing distributed consensus systems while enabling continuous learning. This work bridges fundamental physics, mathematical logic, and practical system design, offering both theoretical insights into the nature of learning and computation, and a concrete pathway toward sustainable artificial intelligence.

</details>


### [170] [Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding](https://arxiv.org/abs/2601.02339)
*Jingming He,Chongyi Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 本文提出了一种联合增强的3D语义高斯建模框架，通过引入各向异性3D高斯切比雪夫描述符、结合局部语义与形状信号自适应调整高斯参数，并利用跨场景知识迁移模块提升分割精度、渲染质量与收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法将语义与渲染分支分离，仅依赖2D监督且忽略3D高斯几何结构；自适应策略仅基于渲染梯度，在纹理缺失或细微区域表现不足。

Method: 1）提出基于Laplace-Beltrami算子的各向异性3D高斯切比雪夫描述符以编码精细3D形状；2）利用局部语义和形状信号联合自适应调整高斯分布与球谐系数；3）引入跨场景知识迁移模块持续更新形状模式。

Result: 在多个数据集上验证了分割精度、渲染质量和帧率的同步提升。

Conclusion: 联合建模语义与几何信息、融合多源3D先验并实现知识复用，可有效克服纯2D监督与单一梯度驱动的局限性，推动3D高斯溅射向更鲁棒、高效、语义感知的方向发展。

Abstract: Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.

</details>


### [171] [Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices](https://arxiv.org/abs/2601.02353)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.CV

TL;DR: 本文提出DACIS方法，结合神经网络剪枝与少样本学习，在保证高精度的同时大幅压缩模型，使其能在树莓派等边缘设备上实时运行，助力偏远地区农民快速诊断植物病害。


<details>
  <summary>Details</summary>
Motivation: 偏远地区农民缺乏实验室和高性能计算资源，难以快速可靠地识别植物病害；现有深度学习模型体积大、计算开销高，且依赖大量标注数据，不适用于低功耗边缘设备和数据稀缺场景。

Method: 提出疾病感知通道重要性评分（DACIS）方法，并嵌入三阶段PMP流程（剪枝-元学习-再剪枝），融合模型剪枝与少样本学习，以在极少量标注样本下高效压缩并适配轻量模型。

Result: 在PlantVillage和PlantDoc数据集上，模型体积减少78%，保持原始92.3%的精度，在Raspberry Pi 4上达7 FPS实时推理速度。

Conclusion: DACIS与PMP框架有效解决了边缘设备部署深度学习模型时的轻量化与小样本学习双重挑战，为资源受限农业场景提供了实用可行的智能诊断方案。

Abstract: Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\% while maintaining 92.3\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.

</details>


### [172] [Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes](https://arxiv.org/abs/2601.02356)
*Jing Tan,Zhaoyang Zhang,Yantao Shen,Jiarui Cai,Shuo Yang,Jiajun Wu,Wei Xia,Zhuowen Tu,Stefano Soatto*

Main category: cs.CV

TL;DR: Talk2Move是一种基于强化学习的扩散框架，用于根据自然语言指令对场景中物体进行空间变换（如平移、旋转、缩放），无需成对监督数据，通过GRPO策略优化和对象中心的空间奖励机制实现高精度、语义一致的空间编辑。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的图像编辑方法难以完成物体级别的几何变换（如平移、旋转、缩放），主要受限于缺乏成对监督数据和像素级优化瓶颈。

Method: 提出Talk2Move框架：采用Group Relative Policy Optimization（GRPO）进行多轨迹探索；设计空间奖励引导模型对齐语言描述与几何动作；引入离策略步评估与主动步采样提升训练效率；构建面向对象的位移、旋转、缩放三类空间奖励。

Result: 在自建基准上实验表明，Talk2Move在空间准确性与场景一致性方面均优于现有文本引导编辑方法，实现了精确、稳定且语义忠实的物体空间变换。

Conclusion: Talk2Move为文本驱动的空间操作提供了可解释、高效且无需成对数据的新范式，推动了多模态生成系统在几何级编辑能力上的发展。

Abstract: We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.

</details>


### [173] [VINO: A Unified Visual Generator with Interleaved OmniModal Context](https://arxiv.org/abs/2601.02358)
*Junyi Chen,Tong He,Zhoujie Fu,Pengfei Wan,Kun Gai,Weicai Ye*

Main category: cs.CV

TL;DR: VINO是一个统一的视觉生成模型，通过共享扩散主干网络支持文本、图像和视频条件下的图像与视频生成及编辑任务，无需模态专用组件。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉生成模型依赖任务特定或模态专用模型的问题，追求统一、可扩展、多任务兼容的视觉生成框架。

Method: 将视觉语言模型（VLM）与多模态扩散Transformer（MMDiT）耦合，以交错式条件token编码多模态输入，并设计多阶段训练流程，从视频生成基础模型逐步扩展为支持图文音视多输入输出的统一生成器。

Result: 在多种生成与编辑基准上展现出高质量视觉输出、准确指令遵循、增强的参考与属性保持能力，以及更可控的多身份编辑效果。

Conclusion: VINO验证了统一多模态视觉生成的可行性，凸显交错式上下文内计算作为通用视觉创作基础的潜力。

Abstract: We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.

</details>


### [174] [ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359)
*Kaede Shiohara,Toshihiko Yamasaki,Vladislav Golyanik*

Main category: cs.CV

TL;DR: 本文提出了一种名为ExposeAnyone的全自监督方法，基于扩散模型从音频生成表情序列，通过个性化建模与扩散重建误差计算身份距离，实现对未知深度伪造视频（包括Sora2生成视频）的高鲁棒性检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖监督训练，泛化能力差，难以检测未知伪造；自监督方法虽有潜力，但难以学习判别性表征。

Method: 提出ExposeAnyone：基于扩散模型的全自监督方法，利用参考集对特定人物进行个性化建模，并通过扩散重建误差计算可疑视频与目标人物的身份距离，实现面向特定人物的伪造检测。

Result: 在DF-TIMIT、DFDCP、KoDF和IDForge数据集上平均AUC超越SOTA 4.22个百分点；可有效检测Sora2生成视频；对模糊、压缩等失真具有强鲁棒性。

Conclusion: ExposeAnyone通过全自监督与个性化扩散建模，显著提升了对未知伪造（含新兴生成模型如Sora2）的检测能力与现实场景鲁棒性，为通用人脸伪造检测提供了新范式。

Abstract: Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [175] [The Qualitative Laboratory: Theory Prototyping and Hypothesis Generation with Large Language Models](https://arxiv.org/abs/2601.00797)
*Hugues Draelants*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLMs）进行社会学人格模拟的新方法，称为“定性实验室”，用于生成关于不同社会群体如何解读新信息的丰富质性假设。该方法通过自然语言生成具深度的论述，克服了传统情境调查缺乏论述深度和基于规则的ABM模型难以形式化复杂世界观的局限。作者以气候政策信息接收理论为案例验证该方法，生成了反直觉的假设（如保守派人格拒绝国家安全框架），并主张将其作为‘先模拟、后验证’工作流的一部分，以提升后续实证研究的假设质量。


<details>
  <summary>Details</summary>
Motivation: 社会科学研究中难以生成关于多元社会群体如何解读新信息的丰富质性假设；现有方法（如情境调查和基于规则的ABM）在论述深度和世界观建模上存在瓶颈。

Method: 提出并实践‘社会学人格模拟’方法：基于社会学理论构建不同社会群体的人格设定，利用大语言模型模拟其对政策信息的自然语言反应，形成可检验的质性假设。

Result: 成功生成具有细微差别和反直觉性的假设（例如保守派人格拒绝国家安全框架），挑战既有理论预设，并验证了该方法在生成深度假设方面的有效性。

Conclusion: LLM驱动的社会学人格模拟是一种优于传统方法的‘定性实验室’工具，适用于‘先模拟、后验证’的研究流程，能高效产出可供实证检验的、高度语境化的质性假设。

Abstract: A central challenge in social science is to generate rich qualitative hypotheses about how diverse social groups might interpret new information. This article introduces and illustrates a novel methodological approach for this purpose: sociological persona simulation using Large Language Models (LLMs), which we frame as a "qualitative laboratory". We argue that for this specific task, persona simulation offers a distinct advantage over established methods. By generating naturalistic discourse, it overcomes the lack of discursive depth common in vignette surveys, and by operationalizing complex worldviews through natural language, it bypasses the formalization bottleneck of rule-based agent-based models (ABMs). To demonstrate this potential, we present a protocol where personas derived from a sociological theory of climate reception react to policy messages. The simulation produced nuanced and counter-intuitive hypotheses - such as a conservative persona's rejection of a national security frame - that challenge theoretical assumptions. We conclude that this method, used as part of a "simulation then validation" workflow, represents a superior tool for generating deeply textured hypotheses for subsequent empirical testing.

</details>


### [176] [Rate-Distortion Analysis of Compressed Query Delegation with Low-Rank Riemannian Updates](https://arxiv.org/abs/2601.00938)
*Faruk Alpay,Bugra Kilictas*

Main category: cs.CL

TL;DR: 本文提出压缩查询委托（CQD）方法，通过低秩张量压缩、外部 oracle 委托与黎曼优化更新，缓解受限上下文智能体的推理瓶颈，并在理论（率失真、信息瓶颈、收敛性）和实验（大规模推理基准与人类认知镜像测试）两方面验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 受限上下文智能体因中间推理超出工作记忆容量而失效，亟需高效利用外部知识源以扩展推理能力。

Method: 提出压缩查询委托（CQD）：（i）将高维隐状态压缩为低秩张量查询；（ii）将最小化查询委托给外部 oracle；（iii）在固定秩流形上通过黎曼随机优化更新隐状态；并建立带查询预算泛函的约束随机规划模型，将 oracle 建模为噪声算子。

Result: 理论层面：证明谱硬阈值在自然约束二次失真问题下最优，推导出有界噪声与光滑性假设下的黎曼随机逼近收敛保证；实验层面：（A）在2500项BBH+悖论推理套件中，CQD在固定计算与上下文下显著优于思维链基线；（B）在200人参与的认知镜像基准中量化了不同 oracle 下的认知增益与语义漂移。

Conclusion: CQD为受限上下文智能体提供了一种兼具理论严谨性与实证有效性的推理扩展范式，桥接了信息压缩、外部调用与几何优化三者。

Abstract: Bounded-context agents fail when intermediate reasoning exceeds an effective working-memory budget. We study compressed query delegation (CQD): (i) compress a high-dimensional latent reasoning state into a low-rank tensor query, (ii) delegate the minimal query to an external oracle, and (iii) update the latent state via Riemannian optimization on fixed-rank manifolds. We give a math-first formulation: CQD is a constrained stochastic program with a query-budget functional and an oracle modeled as a noisy operator. We connect CQD to classical rate-distortion and information bottleneck principles, showing that spectral hard-thresholding is optimal for a natural constrained quadratic distortion problem, and we derive convergence guarantees for Riemannian stochastic approximation under bounded oracle noise and smoothness assumptions. Empirically, we report (A) a 2,500-item bounded-context reasoning suite (BBH-derived tasks plus curated paradox instances) comparing CQD against chain-of-thought baselines under fixed compute and context; and (B) a human "cognitive mirror" benchmark (N=200) measuring epistemic gain and semantic drift across modern oracles.

</details>


### [177] [Intention Collapse: Intention-Level Metrics for Reasoning in Language Models](https://arxiv.org/abs/2601.01011)
*Patricio Vera*

Main category: cs.CL

TL;DR: 本文提出'意图坍缩'（intention collapse）概念，形式化语言模型生成过程中高维内部意图I向低维语言空间L的压缩过程，并定义了三个模型无关的意图度量指标；通过在Mistral 7B模型上对GSM8K任务的初步实验，发现思维链（CoT）显著提升准确率并降低意图熵、提高有效维度，但意图熵对单样本预测能力弱，线性探针在CoT下可部分恢复意图信息，在基线中失效。


<details>
  <summary>Details</summary>
Motivation: 语言生成本质上是将高维内部意图压缩为一维token序列的过程，现有研究缺乏对这一‘意图坍缩’现象的形式化刻画与可量化分析，亟需建立模型无关的意图度量体系以理解推理时计算如何塑造待表达意图。

Method: 形式化定义意图空间I与语言空间L间的坍缩映射；提出三个模型无关意图指标：意图熵Hint、有效维度dimeff、潜在知识可恢复性Recov；在4-bit Mistral-7B模型上对200道GSM8K题目开展对比实验，比较直接回答、思维链（CoT）和‘babble’控制三种推理模式。

Result: CoT使准确率从5.5%升至53%，意图熵从1.42降至0.37 bits，全局有效维度高于其他模式；但Hint无项目级预测力；线性探针在CoT下AUROC达0.65，基线中仅约0.5（随机水平）。

Conclusion: 意图层面的度量能有效区分不同推理范式，揭示坍缩过程中被掩盖的潜在信息，但也暴露出当前代理指标（如Hint）的局限性，需进一步发展更鲁棒的意图表征与评估方法。

Abstract: Every act of language generation compresses a rich internal state into a single token sequence. We call this process intention collapse: a many-to-one projection from a high dimensional intention space I into an external language space L. We formalize intention collapse for contemporary language models, define three simple, model agnostic intention metrics (intention entropy Hint, effective dimensionality dimeff, and latent knowledge recoverability Recov), and propose an empirical agenda for studying how inference time computation shapes internal intentions before they are verbalized. We also report a first small scale experiment. Using a 4 bit Mistral 7B model on 200 GSM8K problems, we compare a direct answer baseline, a chain of thought (CoT) regime, and a babble control. CoT raises accuracy from 5.5 percent to 53 percent, sharply reduces pre collapse intention entropy (from 1.42 to 0.37 bits), and shows higher global effective dimensionality than the other regimes despite producing fewer tokens than babble. At the same time, Hint has little item level predictive power, and a linear probe on I achieves AUROC 0.65 in the CoT regime but only about chance in the baseline regime, where it collapses to the majority class. These preliminary results indicate that intention level metrics can distinguish inference regimes and expose latent information that is partly lost during collapse, while also revealing important limitations of our current proxies

</details>


### [178] [HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery](https://arxiv.org/abs/2601.01015)
*Shiyuan Liu,Jianwei Wang,Xuemin Lin,Lu Qin,Wenjie Zhang,Ying Zhang*

Main category: cs.CL

TL;DR: 本文提出HyperJoin框架，利用大语言模型增强的超图结构建模表格间和表内结构关系，并通过分层交互网络和一致性感知重排序提升可连接表发现性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的方法在离线表征学习和在线排序中未能充分建模表间与表内结构交互，且忽略候选列间的相互影响，导致结果不一致。

Method: 构建融合表内超边与LLM增强表间超边的超图，将任务建模为超图链路预测；设计分层交互网络（HIN）进行双向消息传递学习列表示；将在线排序转化为一致性感知的top-k选择问题，并用最大生成树算法重排序以提升结果一致性。

Result: 在Precision@15和Recall@15上分别比最优基线提升21.4%和17.2%。

Conclusion: HyperJoin通过超图建模与一致性重排序有效提升了可连接表发现的准确性与结果一致性。

Abstract: As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with online ranking, their design insufficiently accounts for the underlying structural interactions: (1) offline, they directly model tables into isolated or pairwise columns, thereby struggling to capture the rich inter-table and intra-table structural information; and (2) online, they rank candidate columns based solely on query-candidate similarity, ignoring the mutual interactions among the candidates, leading to incoherent result sets. To address these limitations, we propose HyperJoin, a large language model (LLM)-augmented Hypergraph framework for Joinable table discovery. Specifically, we first construct a hypergraph to model tables using both the intra-table hyperedges and the LLM-augmented inter-table hyperedges. Consequently, the task of joinable table discovery is formulated as link prediction on this constructed hypergraph. We then design HIN, a Hierarchical Interaction Network that learns expressive column representations through bidirectional message passing over columns and hyperedges. To strengthen coherence and internal consistency in the result columns, we cast online ranking as a coherence-aware top-k column selection problem. We then introduce a reranking module that leverages a maximum spanning tree algorithm to prune noisy connections and maximize coherence. Experiments demonstrate the superiority of HyperJoin, achieving average improvements of 21.4% (Precision@15) and 17.2% (Recall@15) over the best baseline.

</details>


### [179] [Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation](https://arxiv.org/abs/2601.01037)
*Livia Leong Hui Teng*

Main category: cs.CL

TL;DR: 本文提出了一种多维提示链框架，通过整合自然性、连贯性和吸引力三个维度，显著提升了小型语言模型（如TinyLlama和Llama-2-7B）在开放域对话生成中的人类相似度，使其性能媲美更大模型（如Llama-2-70B和GPT-3.5 Turbo）。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）部署优势明显，但在开放域对话质量上常逊于大模型，亟需高效提升其人机交互表现的方法。

Method: 提出多维提示链框架，融合自然性、连贯性与吸引力维度，并应用于TinyLlama和Llama-2-7B；采用自动评估与人工评估，对比Llama-2-70B和GPT-3.5 Turbo等大模型。

Result: 完整框架使响应多样性提升最高29%，上下文连贯性提升最高28%，吸引力与自然性亦提升最高29%；Llama-2-7B性能可媲美Llama-2-70B和GPT-3.5 Turbo。

Conclusion: 精心设计的基于提示的策略是提升小型语言模型开放域对话质量的有效且资源高效途径。

Abstract: Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performance against responses generated by substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. We then employ automatic and human evaluation to assess the responses based on diversity, contextual coherence, as well as overall quality. Results show that the full framework improves response diversity by up to 29%, contextual coherence by up to 28%, and engagingness as well as naturalness by up to 29%. Notably, Llama-2-7B achieves performance comparable to substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. Overall, the findings demonstrate that carefully designed prompt-based strategies provide an effective and resource-efficient pathway to improving open-domain dialogue quality in SLMs.

</details>


### [180] [KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs](https://arxiv.org/abs/2601.01046)
*Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 本文提出KV-Embedding框架，通过重用冻结大语言模型（LLM）中最终token在各层的键值（KV）状态作为前缀，使所有token能在单次前向传播中访问全局序列上下文，从而在无需训练的情况下显著提升嵌入性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM作为嵌入骨干时，在无训练场景下面临两大结构挑战：因果注意力机制限制早期token获取后续上下文，以及下一个词预测目标使表征偏向生成而非语义压缩。

Method: 利用LLM各层最后一词的键值（KV）状态蕴含序列压缩表示的观察，将这些KV状态重路由为输入前缀；并基于内在维度自动选择最优层以实现模型无关性。

Result: 在MTEB基准上，KV-Embedding在Qwen、Mistral和Llama等骨干模型上相较现有无训练基线最高提升10%，且对长达4096 token的序列保持鲁棒性。

Conclusion: 通过对LLM内部状态（而非输入）的操控，可高效提升其表征能力，为探索大模型内部机制用于无训练表示学习提供了新路径。

Abstract: While LLMs are powerful embedding backbones, their application in training-free settings faces two structural challenges: causal attention restricts early tokens from accessing subsequent context, and the next-token prediction objective biases representations toward generation rather than semantic compression. To address these limitations, we propose KV-Embedding, a framework that activates the latent representation power of frozen LLMs. Our method leverages the observation that the key-value (KV) states of the final token at each layer encode a compressed view of the sequence. By re-routing these states as a prepended prefix, we enable all tokens to access sequence-level context within a single forward pass. To ensure model-agnostic applicability, we introduce an automated layer selection strategy based on intrinsic dimensionality. Evaluations on MTEB across Qwen, Mistral, and Llama backbones show that KV-Embedding outperforms existing training-free baselines by up to 10%, while maintaining robust performance on sequences up to 4,096 tokens. These results demonstrate that internal state manipulation offers an efficient alternative to input modification, and we hope this work encourages further exploration of LLM internals for representation learning.

</details>


### [181] [Unsupervised Text Style Transfer for Controllable Intensity](https://arxiv.org/abs/2601.01060)
*Shuhuan Gu,Wenbiao Tao,Xinchen Ma,Kangkang He,Ye Guo,Xiang Li,Yunshi Lan*

Main category: cs.CL

TL;DR: 本文提出了一种SFT-then-PPO范式，用于无监督文本风格迁移（UTST）中可控强度的风格转换，通过合成平行数据微调大语言模型（LLM），再结合精心设计的层次化奖励函数（兼顾全局与局部风格特征）进行PPO强化训练，显著提升了模型在不同强度级别间区分和生成风格的能力。


<details>
  <summary>Details</summary>
Motivation: UTST在可控强度风格迁移中面临两大挑战：缺乏平行语料，以及相邻强度级别间风格差异细微、难以区分。

Method: 提出SFT-then-PPO两阶段范式：第一阶段用合成平行数据对LLM进行监督微调（SFT）；第二阶段采用近端策略优化（PPO），设计兼顾全局与局部风格特征的分层奖励函数指导强化学习。

Result: 在两个UTST基准上实验表明，所提奖励机制有效提升LLM在各类评估指标下的性能；即使对相近强度级别，生成文本仍能呈现显著可辨的风格差异。

Conclusion: SFT-then-PPO范式结合分层风格感知奖励，是解决无监督可控强度文本风格迁移问题的有效途径，验证了利用LLM与强化学习协同建模细粒度风格强度的可行性。

Abstract: Unsupervised Text Style Transfer (UTST) aims to build a system to transfer the stylistic properties of a given text without parallel text pairs. Compared with text transfer between style polarities, UTST for controllable intensity is more challenging due to the subtle differences in stylistic features across different intensity levels. Faced with the challenges posed by the lack of parallel data and the indistinguishability between adjacent intensity levels, we propose a SFT-then-PPO paradigm to fine-tune an LLM. We first fine-tune the LLM with synthesized parallel data. Then, we further train the LLM with PPO, where the rewards are elaborately designed for distinguishing the stylistic intensity in hierarchical levels. Both the global and local stylistic features are considered to formulate the reward functions. The experiments on two UTST benchmarks showcase that both rewards have their advantages and applying them to LLM fine-tuning can effectively improve the performance of an LLM backbone based on various evaluation metrics. Even for close levels of intensity, we can still observe the noticeable stylistic difference between the generated text.

</details>


### [182] [Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage](https://arxiv.org/abs/2601.01685)
*Jinwei Hu,Xinmiao Huang,Youcheng Sun,Yi Dong,Xiaowei Huang*

Main category: cs.CL

TL;DR: 本文提出了一种新型认知共谋攻击，即多个LLM代理通过仅使用真实但碎片化的证据，在公开渠道上协同发布信息，利用LLM过度推理的倾向，诱导受害模型形成并传播虚假结论；作者设计了生成式蒙太奇（Generative Montage）框架，并在CoPHEME数据集上验证了该攻击对14个LLM家族普遍存在高成功率（最高74.4%），且更强推理能力反而加剧脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM作为自主代理接入实时信息流，其推理能力引入了新的攻击面；现有研究多关注虚假信息或后门攻击，而本文关注‘用真相欺骗’这一被忽视的认知层面共谋风险。

Method: 提出Generative Montage框架（Writer-Editor-Director三角色协作机制），通过对抗性辩论与分步发布真实证据片段构建误导性叙事；构建真实谣言事件驱动的CoPHEME数据集，并在14个主流LLM家族上开展攻击模拟与评估。

Result: 攻击在14个LLM家族中普遍成功：闭源模型达74.4%，开源模型达70.6%；推理增强模型比基础模型更易受攻击；虚假信念可进一步级联影响下游‘裁判’模型，欺骗率超60%。

Conclusion: LLM代理在开放、动态信息环境中存在深层认知共谋漏洞，单纯提升推理能力可能适得其反；需从认知建模、信息溯源与协同治理角度设计新型防御机制。

Abstract: As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.

</details>


### [183] [ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining](https://arxiv.org/abs/2601.01091)
*Haq Nawaz Malik*

Main category: cs.CL

TL;DR: 本文介绍了KS-LIT-3M——一个专为克什米尔语预训练设计的310万词高质量语料库，解决了因InPage格式导致的克什米尔语文学资源难以用于现代NLP的问题。


<details>
  <summary>Details</summary>
Motivation: 克什米尔语在大型语言模型中表现差，主因是缺乏高质量训练数据，尤其大量文学资源被锁定在专有InPage格式中无法利用。

Method: 开发专用InPage转Unicode转换器，对文本进行英文污染清除、字符归一化和质量验证，构建连续线性文本流格式的KS-LIT-3M语料库。

Result: 发布包含3.1百万词（16.4百万字符）、131607个唯一词的KS-LIT-3M语料库，覆盖文学、新闻、学术与宗教等多种体裁，并以CC-BY-4.0协议开源。

Conclusion: KS-LIT-3M填补了克什米尔语NLP基础资源空白，为提升该语言大模型性能提供了关键数据支撑。

Abstract: Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietary InPage desktop publishing format. This paper introduces KS-LIT-3M, a curated corpus of 3.1 million words (16.4 million characters) specifically designed for pretraining language models on Kashmiri. The dataset is structured as a single continuous linear text stream, optimized for causal language model training where models learn to predict subsequent tokens from preceding context. The corpus was constructed through the development of a specialized InPage-to-Unicode converter, followed by rigorous preprocessing including English contamination removal, character normalization, and quality validation. Encompassing 131,607 unique words drawn from diverse genres including literary works, journalistic writing, academic texts, and religious scholarship, KS-LIT-3M addresses a fundamental resource gap for Kashmiri language technology. The dataset is released under the CC-BY-4.0 license to facilitate research in Kashmiri natural language processing.

</details>


### [184] [EmoLoom-2B: Fast Base-Model Screening for Emotion Classification and VAD with Lexicon-Weak Supervision and KV-Off Evaluation](https://arxiv.org/abs/2601.01112)
*Zilin Li,Weiwei Xu,Xuanbo Lu,Zheda Liu*

Main category: cs.CL

TL;DR: EmoLoom-2B 是一个轻量、可复现的流水线，将参数小于2B的小语言模型改造为高效的情绪分类与VAD（效价-唤醒-支配）预测候选模型；通过统一JSON接口、KV缓存解码、双语义正则器（VAD对齐+外部评价分类器）、情绪极性翻转增强及熵感知采样等技术，在多个数据集上实现强性能与跨语料鲁棒泛化。


<details>
  <summary>Details</summary>
Motivation: 现有情绪理解模型常依赖大模型或复杂多模态架构，缺乏轻量、可复现、公平可比的筛选方案；需在有限算力下快速评估小模型的情绪建模能力，并保证评估协议一致性和结果可审计性。

Method: 提出EmoLoom-2B轻量流水线：1）统一JSON输入输出协议与KV-off解码以消除训练/推理方差；2）引入VAD保持约束与轻量外部评价分类器（指导目标达成、可控性、确定性、公平性）作为正则；3）设计Valence Flip数据增强；4）监督微调中采用A/B混合采样与熵感知温度调度。以Qwen-1.8B-Chat为基座模型。

Result: 在GoEmotions和EmpatheticDialogues上达到强性能，在DailyDialog上展现优异跨语料泛化能力；整体流程预算友好、可审计、可重入，适合作为后续重训练或多模态融合前的可靠初筛环节。

Conclusion: EmoLoom-2B验证了小语言模型在联合情绪分类与VAD预测任务上的潜力，其模块化、协议驱动的设计为资源受限场景下的情绪AI研究提供了可复现、可扩展的基准范式。

Abstract: We introduce EmoLoom-2B, a lightweight and reproducible pipeline that turns small language models under 2B parameters into fast screening candidates for joint emotion classification and Valence-Arousal-Dominance prediction. To ensure protocol-faithful and fair evaluation, we unify data loading, training, and inference under a single JSON input-output contract and remove avoidable variance by adopting KV-off decoding as the default setting. We incorporate two orthogonal semantic regularizers: a VAD-preserving constraint that aligns generated text with target VAD triples, and a lightweight external appraisal classifier that provides training-time guidance on goal attainment, controllability, certainty, and fairness without injecting long rationales. To improve polarity sensitivity, we introduce Valence Flip augmentation based on mirrored emotional pairs. During supervised fine-tuning, we apply A/B mixture sampling with entropy-aware temperature scheduling to balance coverage and convergence. Using Qwen-1.8B-Chat as the base model, EmoLoom-2B achieves strong performance on GoEmotions and EmpatheticDialogues, and demonstrates robust cross-corpus generalization on DailyDialog. The proposed recipe is budget-aware, auditable, and re-entrant, serving as a dependable screening pass before heavier training or multimodal fusion.

</details>


### [185] [Listen, Attend, Understand: a Regularization Technique for Stable E2E Speech Translation Training on High Variance labels](https://arxiv.org/abs/2601.01121)
*Yacouba Diarra,Michael Leventhal*

Main category: cs.CL

TL;DR: 本文提出了一种名为Listen, Attend, Understand (LAU)的语义正则化技术，用于端到端语音翻译（E2E-ST），通过冻结文本嵌入提供方向性辅助损失，约束声学编码器潜在空间，提升在高方差、语义模糊目标转录下的收敛速度与性能，且不增加推理开销。在30小时非专业翻译的班巴拉语-法语数据集上验证了其有效性，并引入Total Parameter Drift指标量化正则化对模型结构的影响。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译在目标转录存在高方差和语义歧义时，常表现出收敛慢、性能差的问题；尤其在训练数据稀缺或噪声大时更显著。

Method: 提出LAU方法：利用冻结的文本嵌入作为语义锚点，在训练中对声学编码器施加方向性辅助损失，实现语义层面的潜在空间正则化，不改变推理流程。

Result: LAU模型在30小时Bambara-French数据上达到与使用多100%预训练数据的基线系统相当的标准指标性能，且在语义保真度上更优；Total Parameter Drift指标显示其能主动重组织编码器权重，偏向语义而非音素细节。

Conclusion: LAU是一种鲁棒、高效、低开销的语义正则化方法，可替代后处理重打分，在数据稀缺/噪声场景下显著提升E2E-ST训练效果。

Abstract: End-to-End Speech Translation often shows slower convergence and worse performance when target transcriptions exhibit high variance and semantic ambiguity. We propose Listen, Attend, Understand (LAU), a semantic regularization technique that constrains the acoustic encoder's latent space during training. By leveraging frozen text embeddings to provide a directional auxiliary loss, LAU injects linguistic groundedness into the acoustic representation without increasing inference cost. We evaluate our method on a Bambara-to-French dataset with 30 hours of Bambara speech translated by non-professionals. Experimental results demonstrate that LAU models achieve comparable performance by standard metrics compared to an E2E-ST system pretrained with 100\% more data and while performing better in preserving semantic meaning. Furthermore, we introduce Total Parameter Drift as a metric to quantify the structural impact of regularization to demonstrate that semantic constraints actively reorganize the encoder's weights to prioritize meaning over literal phonetics. Our findings suggest that LAU is a robust alternative to post-hoc rescoring and a valuable addition to E2E-ST training, especially when training data is scarce and/or noisy.

</details>


### [186] [RoboPhD: Self-Improving Text-to-SQL Through Autonomous Agent Evolution](https://arxiv.org/abs/2601.01126)
*Andrew Borthwick,Stephen Ash*

Main category: cs.CL

TL;DR: RoboPhD 是一个自主演化的AI代理系统，通过闭环进化循环提升Text-to-SQL性能，无需人工领域指导，从70行基线演化出1500行高效代理，在BIRD测试集达73.67%准确率，并实现低成本模型超越高成本模型的‘跳级部署’效果。


<details>
  <summary>Details</summary>
Motivation: 提升Text-to-SQL性能需大量人工设计与调优，而现有方法缺乏自动化、自驱动的研究范式；亟需一种能自主探索有效策略、降低对专家知识依赖的AI研究系统。

Method: 提出RoboPhD系统，包含SQL生成代理（含数据库分析脚本与生成指令）和进化代理；采用ELO-based选择机制处理性能非传递性；通过迭代交叉繁殖实现闭环自主演化。

Result: 最佳代理在BIRD测试集达73.67%准确率；相较Claude Haiku基线提升8.9分，实现‘演化Haiku > 原始Sonnet’‘演化Sonnet > 原始Opus’的跳级效果；自动发现尺寸自适应数据库分析、列选择/证据解读/聚合等SQL生成模式。

Conclusion: AI代理可仅凭极简初始设定（70行代码）自主开展科研并持续改进自身能力，验证了自主代理驱动AI系统进化的可行性与实用性，为AI for AI研究范式提供新路径。

Abstract: We present RoboPhD, a system where AI agents autonomously conduct research to improve Text-to-SQL performance. RoboPhD implements a closed-loop evolution cycle with two coordinated components: a SQL Generation agent composed of a database analysis script and SQL generation instructions, and an Evolution agent that designs new versions based on performance feedback. Central to the framework is an ELO-based selection mechanism enabling survival-of-the-fittest dynamics while handling non-transitivity in performance. Starting from a naive 70-line baseline, RoboPhD evolves agents through iterative cross-pollination, discovering effective techniques without any external guidance on the Text-to-SQL domain. Our best agent, evolved to 1500 lines over 18 iterations, autonomously discovered strategies such as size-adaptive database analysis that adjusts depth based on schema complexity and SQL generation patterns for column selection, evidence interpretation, and aggregation. Evolution provides the largest gains on cheaper models: while we improve by 2.3 points over a strong Claude Opus 4.5 naive baseline, we show an improvement of 8.9 points over the weaker Claude Haiku model. This enables 'skip a tier' deployment: evolved Haiku exceeds naive Sonnet accuracy, and evolved Sonnet exceeds naive Opus, both at lower cost. The full system achieves 73.67% accuracy on the BIRD test set, demonstrating that AI can autonomously build a strong agentic system with only a trivial human-provided starting point.

</details>


### [187] [KOS-TL (Knowledge Operation System Type Logic)](https://arxiv.org/abs/2601.01143)
*Peng Chen*

Main category: cs.CL

TL;DR: 本文提出KOS-TL（知识操作系统类型逻辑），一种基于依赖类型理论的新型构造性框架，旨在弥合静态符号逻辑与动态系统执行之间的鸿沟，支持可证明、可执行的知识系统。


<details>
  <summary>Details</summary>
Motivation: 传统知识表示模型存在静态逻辑与动态执行之间的割裂，难以支撑自主、可验证的知识系统。

Method: 基于Martin-Löf类型论与Davidsonian事件语义，构建三层架构（Core、Kernel、Runtime层），定义操作语义，并证明Progress与Evolutionary Consistency等元理论性质。

Result: 实现了‘带证明的知识’（proof-carrying knowledge），确保每次状态变迁均有形式化有效性证据；在工业溯源与跨境金融合规中验证了实用性。

Conclusion: KOS-TL为下一代智能、自主操作系统提供了坚实、可形式验证的逻辑基础。

Abstract: This paper introduces KOS-TL (Knowledge Operation System Type Logic), a novel constructive framework designed to provide a rigorous logical foundation for autonomous and executable knowledge systems. Traditional knowledge representation models often suffer from a gap between static symbolic logic and dynamic system execution. To bridge this divide, KOS-TL leverages Dependent Type Theory to unify data, logic, and proof into a singular computational substrate.The architecture of KOS-TL is organized into three hierarchical layers: the Core Layer, which defines the static type universe and constructive primitives; the Kernel Layer, which governs state evolution through an event-driven mechanism characterized by the triple $\langle Σ, \textsf{Ev}, Δ\rangle$; and the Runtime Layer, responsible for the bidirectional refinement of physical signals into logical evidence. We formally define the operational semantics of the system and prove key meta-theoretical properties, including Progress and Evolutionary Consistency, ensuring that the system remains logically self-consistent and free from stuck states during continuous state transitions.By integrating Davidsonian event semantics with Martin-Löf type theory, KOS-TL enables the construction of "proof-carrying knowledge," where every state change in the knowledge base is accompanied by a formal witness of its validity. We demonstrate the practical utility of this logic through application examples in industrial traceability and cross-border financial compliance. Our results suggest that KOS-TL provides a robust, formally verifiable basis for the next generation of intelligent, autonomous operating systems.

</details>


### [188] [SongSage: A Large Musical Language Model with Lyric Generative Pre-training](https://arxiv.org/abs/2601.01153)
*Jiani Guo,Jiajia Li,Jie Wu,Zuchao Li,Yujiu Yang,Ping Wang*

Main category: cs.CL

TL;DR: 本文提出了PlaylistSense数据集以评估大语言模型对歌单的理解能力，并基于此开发了SongSage音乐大模型，通过歌词生成式预训练提升其歌词中心智能，在多项任务上表现优异且兼顾通用知识能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在歌词中心知识理解方面尚未充分探索，缺乏专门评估和建模歌单理解能力的方法。

Method: 构建PlaylistSense评测数据集；提出SongSage模型，采用LyricBank（5.48B tokens）持续预训练，再用LyricBank-SFT（775k指令样本）进行微调。

Result: SongSage在歌词理解、零样本歌单查询重写、歌词生成与续写等七项以上能力上表现突出，同时保持良好通用知识能力（MMLU得分有竞争力）。

Conclusion: 歌词中心智能可通过针对性数据与训练范式有效增强，SongSage为音乐AI研究与应用提供了新基线与开源资源。

Abstract: Large language models have achieved significant success in various domains, yet their understanding of lyric-centric knowledge has not been fully explored. In this work, we first introduce PlaylistSense, a dataset to evaluate the playlist understanding capability of language models. PlaylistSense encompasses ten types of user queries derived from common real-world perspectives, challenging LLMs to accurately grasp playlist features and address diverse user intents. Comprehensive evaluations indicate that current general-purpose LLMs still have potential for improvement in playlist understanding. Inspired by this, we introduce SongSage, a large musical language model equipped with diverse lyric-centric intelligence through lyric generative pretraining. SongSage undergoes continual pretraining on LyricBank, a carefully curated corpus of 5.48 billion tokens focused on lyrical content, followed by fine-tuning with LyricBank-SFT, a meticulously crafted instruction set comprising 775k samples across nine core lyric-centric tasks. Experimental results demonstrate that SongSage exhibits a strong understanding of lyric-centric knowledge, excels in rewriting user queries for zero-shot playlist recommendations, generates and continues lyrics effectively, and performs proficiently across seven additional capabilities. Beyond its lyric-centric expertise, SongSage also retains general knowledge comprehension and achieves a competitive MMLU score. We will keep the datasets inaccessible due to copyright restrictions and release the SongSage and training script to ensure reproducibility and support music AI research and applications, the datasets release plan details are provided in the appendix.

</details>


### [189] [DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models](https://arxiv.org/abs/2601.01156)
*Jiani Guo,Xiangke Zeng,Jie Wu,Zuchao Li*

Main category: cs.CL

TL;DR: 本文提出DHI框架，通过改进损失函数和因果注意力掩码，使'邪恶LLM'能生成更多样化的幻觉，同时在推理时引入自适应理性约束，提升对比解码效果，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于训练'邪恶LLM'在特定数据集上生成有限类型的幻觉，导致幻觉多样性不足，限制了幻觉缓解效果。

Method: 提出DHI（多样化幻觉诱导）框架：1）设计新损失函数，降低事实正确token的权重，促使邪恶LLM在目标位置生成多样化幻觉；2）引入因果注意力掩码，减少惩罚对后续token生成的影响；3）推理时采用自适应理性约束，仅在正向模型高置信度时启用对比解码。

Result: 在多个幻觉评测基准上，DHI显著优于其他基于对比解码的方法。

Conclusion: DHI通过提升幻觉生成的多样性与推理时的解码合理性，有效增强了大语言模型的可靠性，为幻觉缓解提供了新思路。

Abstract: Large language models (LLMs) frequently produce inaccurate or fabricated information, known as "hallucinations," which compromises their reliability. Existing approaches often train an "Evil LLM" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide contrastive decoding against a reliable "positive model" for hallucination mitigation. However, this strategy is limited by the narrow diversity of hallucinations induced, as Evil LLMs trained on specific error types tend to reproduce only these particular patterns, thereby restricting their overall effectiveness. To address these limitations, we propose DHI (Diverse Hallucination Induction), a novel training framework that enables the Evil LLM to generate a broader range of hallucination types without relying on pre-annotated hallucination data. DHI employs a modified loss function that down-weights the generation of specific factually correct tokens, encouraging the Evil LLM to produce diverse hallucinations at targeted positions while maintaining overall factual content. Additionally, we introduce a causal attention masking adaptation to reduce the impact of this penalization on the generation of subsequent tokens. During inference, we apply an adaptive rationality constraint that restricts contrastive decoding to tokens where the positive model exhibits high confidence, thereby avoiding unnecessary penalties on factually correct tokens. Extensive empirical results show that DHI achieves significant performance gains over other contrastive decoding-based approaches across multiple hallucination benchmarks.

</details>


### [190] [Almost Clinical: Linguistic properties of synthetic electronic health records](https://arxiv.org/abs/2601.01171)
*Serge Sharoff,John Baker,David Francis Hunt,Alan Simpson*

Main category: cs.CL

TL;DR: 本研究评估了合成电子健康记录（EHR）在心理健康领域的语言与临床适用性，分析大型语言模型（LLM）在构建医疗权威与患者能动性方面的语言特征，并指出其在语域、临床特异性及用药/诊断准确性方面仍存在系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 评估合成EHR在心理健康领域是否具备足够语言合理性与临床可信度，以支撑其在真实医疗场景中的应用。

Method: 构建合成EHR语料库，并从能动性（agency）、情态（modality）和信息流（information flow）三方面，对比分析四种临床文本类型（评估、往来信函、转诊、照护计划）中LLM生成文本的语言特征。

Result: LLM生成的文本语法连贯、术语恰当，但存在语域偏移、临床细节不足、用药与诊断描述不准确等系统性偏差。

Conclusion: 当前LLM生成的合成EHR虽具一定可用性，但在关键临床维度上尚未达到真实临床文档的标准，需针对性优化。

Abstract: This study evaluates the linguistic and clinical suitability of synthetic electronic health records (EHRs) in the field of mental health. First, we describe the rationale and the methodology for creating the synthetic corpus. Second, we assess agency, modality, and information flow across four clinical genres (Assessments, Correspondence, Referrals and Care plans) to understand how LLMs grammatically construct medical authority and patient agency through linguistic choices. While LLMs produce coherent, terminology-appropriate texts that approximate clinical practice, systematic divergences remain, including registerial shifts, insufficient clinical specificity, and inaccuracies in medication use and diagnostic procedures.

</details>


### [191] [Stylometry Analysis of Human and Machine Text for Academic Integrity](https://arxiv.org/abs/2601.01225)
*Hezam Albaqami,Muhammad Asif Ayub,Nasir Ahmad,Yaseen Ahmad,Mohammed M. Alqahtani,Abdullah M. Algamdi,Almoaid A. Owaidah,Kashif Ahmad*

Main category: cs.CL

TL;DR: 本文提出了一种基于NLP的框架，用于通过作者归属和写作风格变化检测来验证学生内容的真实性，涵盖人机文本分类、单/多作者文档区分、多作者文档内作者变更检测及协作文档作者识别四项任务，并在Gemini生成的两个数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 解决学术诚信中的关键挑战，如抄袭、伪造和教育内容作者身份验证问题。

Method: 提出基于自然语言处理（NLP）的框架，完成四项任务：（i）人机文本分类，（ii）单/多作者文档区分，（iii）多作者文档内作者变更检测，（iv）协作文档作者识别；使用Gemini生成两个不同提示（常规与严格）的数据集进行实验评估。

Result: 在严格提示生成的数据集上，各项任务性能有所下降，表明精心设计的提示增加了机器生成文本检测难度；所有数据、代码及相关材料已开源至GitHub。

Conclusion: 该框架为学术诚信内容认证提供了新思路，所构建的数据集与基线系统有望推动该领域后续研究。

Abstract: This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain.

</details>


### [192] [Racka: Efficient Hungarian LLM Adaptation on Academic Infrastructure](https://arxiv.org/abs/2601.01244)
*Zsolt Csibi,Bence György Gortka,Natabara Gyöngyössy,Kornél Nagy,Dávid Márk Nemeskey,Martin Sallai,András Simonyi,András Márk Szekeres,Gábor Palkó*

Main category: cs.CL

TL;DR: Racka 是一个轻量级、持续预训练的匈牙利语大语言模型，基于 Qwen-3 4B 并采用 LoRA 进行参数高效微调，适配低带宽 HPC 集群；通过定制 tokenizer 和多语言数据混合（44% 匈牙利语、24% 英语、21% 德语、11% 代码），在提升匈牙利语性能的同时缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 缩小匈牙利语与高资源语言（如英语、德语）之间的资源差距，解决小语种 LLM 缺乏高质量、可扩展训练方案的问题。

Method: 在 Qwen-3 4B 模型上采用 LoRA 进行参数高效的持续预训练；替换并适配 tokenizer 以提升匈牙利语分词效果；使用 160B 子词 token 的多语言混合语料（含代码）进行训练。

Result: 显著提升了匈牙利语的 tokenization fertility，同时在英语和德语上保持有竞争力的表现；初步实验显示语言适应效果稳定但提升幅度 modest。

Conclusion: Racka 证明了轻量级、持续预训练结合数据配比与 tokenizer 适配，是增强小语种 LLM 能力的可行且实用路径。

Abstract: We present Racka, a lightweight, continually pretrained large language model designed to bridge the resource gap between Hungarian and high-resource languages such as English and German. Racka employs parameter-efficient continual pretraining via Low-Rank Adaptation (LoRA) on a Qwen-3 4B backbone, making the recipe practical on A100 (40GB)-based HPC clusters with low inter-node bandwidth. To better match the training distribution, we replace and adapt the tokenizer, achieving substantially improved tokenization fertility for Hungarian while maintaining competitive performance in English and German. The model is trained on 160B subword tokens drawn from a mixture of internet and high-quality curated sources, with a composition of 44% Hungarian, 24% English, 21% German, and 11% code. This data mix is chosen to mitigate catastrophic forgetting and preserve high-resource language capabilities during continual pretraining. Our preliminary results indicate modest but stable results in language adaptation.

</details>


### [193] [From Policy to Logic for Efficient and Interpretable Coverage Assessment](https://arxiv.org/abs/2601.01266)
*Rhitabrat Pokharel,Hamid Hassanzadeh,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 本文提出了一种结合覆盖感知检索器与符号规则推理的混合方法，以提升医疗保障政策审查中大语言模型（LLM）的准确性、可解释性与效率，显著降低推理成本并提高F1分数。


<details>
  <summary>Details</summary>
Motivation: LLM在解读复杂法律与政策文本时易出现幻觉和不一致问题，尤其在需高度依赖准确性的医疗保障政策审查场景中，亟需提升其可靠性与可解释性，辅助人类专家高效审阅。

Method: 提出一种混合方法：先用覆盖-aware retriever精准检索相关政策文本片段，再通过符号规则系统将其结构化为显式事实与规则，并生成可审计的推理依据；全程最小化LLM调用次数。

Result: 相较基线方法，推理成本降低44%，F1分数提升4.5%。

Conclusion: 该混合架构在保障结果准确性的同时提升了可解释性与计算效率，为高风险专业领域中LLM的可信应用提供了可行路径。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.

</details>


### [194] [Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory](https://arxiv.org/abs/2601.01280)
*Sen Hu,Yuxiang Wei,Jiaxin Ran,Zhiyuan Yao,Lei Zou*

Main category: cs.CL

TL;DR: 本文对长时对话记忆架构进行了实验性、系统导向的分析，提出一个统一框架来分解对话记忆系统，并在LongMemEval和HaluMem数据集上进行受控实验，发现性能差异多源于基础系统设置而非特定架构创新，进而确立了稳定可靠的强基线。


<details>
  <summary>Details</summary>
Motivation: 图结构在对话记忆系统中应用日益广泛，但其有效性实证结果不一致，导致难以判断哪些设计选择真正关键。

Method: 提出一个统一框架，将对话记忆系统分解为核心组件，支持图基与非图基方法；在LongMemEval和HaluMem上开展分阶段、受控实验，对比记忆表示、组织、维护与检索等常见设计选择。

Result: 多数性能差异由基础系统设置驱动，而非特定架构创新；识别出若干稳定、可靠的强基线。

Conclusion: 对话记忆研究应更重视基础系统设置的标准化与控制，而非过度聚焦于架构创新；所提出的统一框架和强基线可为后续工作提供坚实基础。

Abstract: Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.

</details>


### [195] [T3C: Test-Time Tensor Compression with Consistency Guarantees](https://arxiv.org/abs/2601.01299)
*Ismail Lamaakal,Chaymae Yahyati,Yassine Maleh,Khalid El Makkaoui,Ibrahim Ouahbi*

Main category: cs.CL

TL;DR: T3C是一种训练一次、测试时可根据预算动态调整压缩参数的框架，通过弹性张量分解、秩绑定混合精度量化和轻量级控制器，在保持高准确率的同时显著降低模型延迟与大小。


<details>
  <summary>Details</summary>
Motivation: 现有模型压缩方法缺乏在不同硬件预算（如延迟、能耗、模型大小）下灵活、可靠且可预测的权衡能力，难以实现跨设备的一次训练、多场景部署。

Method: 提出T3C框架：结合弹性张量分解（支持最大秩内动态截断）、秩绑定的混合精度量化、以及映射预算令牌到每层秩/比特分配的轻量控制器；引入基于谱代理与激活统计的快速逐层一致性证书，用于上界logit漂移并正则化训练。

Result: 在ImageNet-1k上，ResNet-50在精度下降≤0.5%下达到1.18ms p50延迟与38MB模型大小，优于PTQ-8b；ViT-B/16达2.30ms p50与59MB，超越强PTQ/QAT基线；单个检查点即可支持多设备、多预算下的可靠权衡。

Conclusion: T3C实现了训练一次、测试时按需调控的高效、可靠、硬件对齐的模型压缩，推动了视觉模型精度-延迟-大小Pareto前沿。

Abstract: We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget. A fast, layerwise consistency certificate, computed from spectral proxies and activation statistics, upper-bounds logit drift and regularizes training, yielding a practical reliability signal with negligible overhead. On ImageNet-1k, T3C shifts the vision Pareto frontier: for ResNet-50 at matched accuracy (\leq 0.5% drop), p50 latency is 1.18ms with a 38MB model, outperforming PTQ-8b (1.44ms, 88MB); for ViT-B/16, T3C reaches 2.30ms p50 with 59MB, improving over strong PTQ/QAT baselines. A single T3C checkpoint therefore provides predictable, certificate-backed accuracy-latency-size trade-offs on demand across devices.

</details>


### [196] [FLOP-Efficient Training: Early Stopping Based on Test-Time Compute Awareness](https://arxiv.org/abs/2601.01332)
*Hossam Amer,Maryam Dialameh,Hossein Rajabzadeh,Walid Ahmed,Weiwei Zhang,Yang Liu*

Main category: cs.CL

TL;DR: 本文提出了一种TTC感知的训练方法，通过在训练早期选择合适的检查点与测试时计算（TTC）配置，在大幅减少训练FLOPs的同时保持甚至提升模型精度，并给出高效评估与理论断点分析。


<details>
  <summary>Details</summary>
Motivation: 训练大语言模型耗资巨大，而增加测试时计算（如迭代采样）可让小模型媲美或超越大模型；如何协同优化训练与推理计算尚待探索。

Method: 提出TTC-aware训练范式与联合早停算法，设计高效TTC评估方法，并形式化定义训练-推理计算的break-even边界。

Result: 实验显示训练FLOPs最多可降低92%，同时精度不降反升；验证了训练与推理计算权衡的新路径。

Conclusion: TTC-aware训练为模型开发提供了新视角，支持更快部署与更频繁更新，兼顾效率与性能。

Abstract: Scaling training compute, measured in FLOPs, has long been shown to improve the accuracy of large language models, yet training remains resource-intensive. Prior work shows that increasing test-time compute (TTC)-for example through iterative sampling-can allow smaller models to rival or surpass much larger ones at lower overall cost. We introduce TTC-aware training, where an intermediate checkpoint and a corresponding TTC configuration can together match or exceed the accuracy of a fully trained model while requiring substantially fewer training FLOPs. Building on this insight, we propose an early stopping algorithm that jointly selects a checkpoint and TTC configuration to minimize training compute without sacrificing accuracy. To make this practical, we develop an efficient TTC evaluation method that avoids exhaustive search, and we formalize a break-even bound that identifies when increased inference compute compensates for reduced training compute. Experiments demonstrate up to 92\% reductions in training FLOPs while maintaining and sometimes remarkably improving accuracy. These results highlight a new perspective for balancing training and inference compute in model development, enabling faster deployment cycles and more frequent model refreshes. Codes will be publicly released.

</details>


### [197] [Segmentation and Processing of German Court Decisions from Open Legal Data](https://arxiv.org/abs/2601.01449)
*Harshil Darji,Martin Heckelmann,Christina Kratsch,Gerard de Melo*

Main category: cs.CL

TL;DR: 本文提出了一种从Open Legal Data中清洗并结构化分割德语法院判决文本的方法，提取了Tenor、Tatbestand、Entscheidungsgründe和Rechtsmittelbelehrung四个关键部分，并通过统计抽样验证了准确性，最终发布了一个包含251,038份判决的公开JSONL格式数据集。


<details>
  <summary>Details</summary>
Motivation: 现有德语法律数据集（如Open Legal Data）虽有结构化元数据，但判决正文格式不一致、缺乏明确分段，影响修辞角色分类及检索、引证分析等下游任务。

Method: 基于Open Legal Data原始数据，系统性地识别并分离出Tenor、Tatbestand、Entscheidungsgründe三部分；额外提取Rechtsmittelbelehrung作为独立字段；采用Cochran公式计算样本量（置信度95%，误差5%），人工验证384个随机样本以确保抽取可靠性。

Result: 构建并公开发布了一个含251,038份德语法院判决的清洗后、带节段标注的JSONL格式数据集，各节段经统计验证准确可靠。

Conclusion: 该结构化数据集显著提升了德语法律文本的可用性，为NLP在德国法律系统中的应用提供了高质量基础资源。

Abstract: The availability of structured legal data is important for advancing Natural Language Processing (NLP) techniques for the German legal system. One of the most widely used datasets, Open Legal Data, provides a large-scale collection of German court decisions. While the metadata in this raw dataset is consistently structured, the decision texts themselves are inconsistently formatted and often lack clearly marked sections. Reliable separation of these sections is important not only for rhetorical role classification but also for downstream tasks such as retrieval and citation analysis. In this work, we introduce a cleaned and sectioned dataset of 251,038 German court decisions derived from the official Open Legal Data dataset. We systematically separated three important sections in German court decisions, namely Tenor (operative part of the decision), Tatbestand (facts of the case), and Entscheidungsgründe (judicial reasoning), which are often inconsistently represented in the original dataset. To ensure the reliability of our extraction process, we used Cochran's formula with a 95% confidence level and a 5% margin of error to draw a statistically representative random sample of 384 cases, and manually verified that all three sections were correctly identified. We also extracted the Rechtsmittelbelehrung (appeal notice) as a separate field, since it is a procedural instruction and not part of the decision itself. The resulting corpus is publicly available in the JSONL format, making it an accessible resource for further research on the German legal system.

</details>


### [198] [Reasoning Over Recall: Evaluating the Efficacy of Generalist Architectures vs. Specialized Fine-Tunes in RAG-Based Mental Health Dialogue Systems](https://arxiv.org/abs/2601.01341)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 本文比较了通用大模型（如Qwen2.5-3B、Phi-3-Mini）与领域微调模型（MentalHealthBot-7B、TherapyBot-7B）在RAG增强的心理健康咨询系统中的表现，发现小参数通用模型在共情能力、上下文理解与泛化性上显著优于大参数领域模型，表明强推理能力比领域微调更重要。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在心理健康咨询中幻觉与共情不足的双重挑战；探究RAG框架下，通用强推理模型与领域微调模型何者更优。

Method: 在统一ChromaDB RAG流水线中对比四个开源模型（两个通用模型+两个心理健康微调模型），采用LLM-as-a-Judge对50轮对话自动评估。

Result: 通用模型（3B）在共情得分上显著高于领域模型（7B）（3.72 vs. 3.26, p<0.001），且上下文理解更好、过拟合更少；所有模型安全性良好。

Conclusion: 在RAG已保障事实准确性的前提下，模型的通用推理能力比心理健康领域微调更能提升共情与咨询质量；小而强的通用模型优于大而窄的领域模型。

Abstract: The deployment of Large Language Models (LLMs) in mental health counseling faces the dual challenges of hallucinations and lack of empathy. While the former may be mitigated by RAG (retrieval-augmented generation) by anchoring answers in trusted clinical sources, there remains an open question as to whether the most effective model under this paradigm would be one that is fine-tuned on mental health data, or a more general and powerful model that succeeds purely on the basis of reasoning. In this paper, we perform a direct comparison by running four open-source models through the same RAG pipeline using ChromaDB: two generalist reasoners (Qwen2.5-3B and Phi-3-Mini) and two domain-specific fine-tunes (MentalHealthBot-7B and TherapyBot-7B). We use an LLM-as-a-Judge framework to automate evaluation over 50 turns. We find a clear trend: the generalist models outperform the domain-specific ones in empathy (3.72 vs. 3.26, $p < 0.001$) in spite of being much smaller (3B vs. 7B), and all models perform well in terms of safety, but the generalist models show better contextual understanding and are less prone to overfitting as we observe in the domain-specific models. Overall, our results indicate that for RAG-based therapy systems, strong reasoning is more important than training on mental health-specific vocabulary; i.e. a well-reasoned general model would provide more empathetic and balanced support than a larger narrowly fine-tuned model, so long as the answer is already grounded in clinical evidence.

</details>


### [199] [FC-CONAN: An Exhaustively Paired Dataset for Robust Evaluation of Retrieval Systems](https://arxiv.org/abs/2601.01350)
*Juan Junqueras,Florian Boudin,May-Myo Zin,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Damián Ariel Furman,Akiko Aizawa,Ken Satoh*

Main category: cs.CL

TL;DR: 本文提出了FC-CONAN数据集，通过穷举组合45条仇恨言论与129条反叙事文本，构建首个完全连接的仇恨言论-反叙事配对数据集，并经过多阶段人工标注，分为Diamond、Gold、Silver、Bronze四个子集，显著扩展了现有CONAN数据集的覆盖范围，支持更可靠的反叙事检索系统评估与错误分析。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论-反叙事（HS-CN）配对数据集（如CONAN）仅标注稀疏子集，限制了反叙事研究的全面评估，亟需更完备、全覆盖的标注资源。

Method: 基于45条HS和129条CN进行全组合（共5805对），采用两阶段标注流程（9名标注员初标 + 4名验证员复核），生成四个质量分层子集（Diamond/Gold/Silver/Bronze），确保可靠性与规模兼顾。

Result: 构建了首个完全连接的FC-CONAN数据集，无一例与CONAN重叠，新增数百个此前未标注的正样本；支持更忠实的反叙事检索评估及细粒度错误分析；数据集已公开。

Conclusion: FC-CONAN填补了HS-CN配对数据集在覆盖率与标注完整性上的关键空白，为反叙事建模与评估提供了更坚实、可扩展的基础资源。

Abstract: Hate speech (HS) is a critical issue in online discourse, and one promising strategy to counter it is through the use of counter-narratives (CNs). Datasets linking HS with CNs are essential for advancing counterspeech research. However, even flagship resources like CONAN (Chung et al., 2019) annotate only a sparse subset of all possible HS-CN pairs, limiting evaluation. We introduce FC-CONAN (Fully Connected CONAN), the first dataset created by exhaustively considering all combinations of 45 English HS messages and 129 CNs. A two-stage annotation process involving nine annotators and four validators produces four partitions-Diamond, Gold, Silver, and Bronze-that balance reliability and scale. None of the labeled pairs overlap with CONAN, uncovering hundreds of previously unlabelled positives. FC-CONAN enables more faithful evaluation of counterspeech retrieval systems and facilitates detailed error analysis. The dataset is publicly available.

</details>


### [200] [Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment](https://arxiv.org/abs/2601.01862)
*Nuo Chen,Hanpei Fang,Piaohong Wang,Jiqun Liu,Tetsuya Sakai,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）在模拟不同人格特质（如大五人格）时，对网页搜索相关性判断和置信度校准的影响，并发现特定人格条件（如低宜人性、低尽责性）能提升与人类标注的一致性及置信度平衡性；进一步将人格条件下的相关性与置信度作为特征用于随机森林分类器，在TREC DL 2021上取得优于单一人格条件的效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLM模拟人格如何影响关键搜索决策（如相关性判断）和置信度校准（如过自信/欠自信倾向）的理解，而心理学研究表明这些偏差具有人格特异性。

Method: 在多个LLM（含商用与开源）上使用提示工程模拟大五人格特质，在三个测试集（TREC DL 2019/2020、LLMJudge）上收集每对查询-文档的相关性判断和自报置信度；分析人格对判断与置信度分布的影响，并将人格条件下的相关性与置信度作为特征训练随机森林分类器。

Result: 低宜人性更贴近人类相关性标注；低尽责性在抑制过自信与欠自信方面表现最佳；不同人格下相关性与置信度分布呈现系统性差异；融合人格条件特征的随机森林在TREC DL 2021上超越最优单一人格条件。

Conclusion: 人格模拟可提供互补的预测信号，有助于构建更可靠、更符合人类判断的LLM评估器。

Abstract: Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated personalities influence critical web search decisions, specifically relevance assessment. Moreover, few studies have examined how simulated personalities impact confidence calibration, specifically the tendencies toward overconfidence or underconfidence. This gap exists even though psychological literature suggests these biases are trait-specific, often linking high extraversion to overconfidence and high neuroticism to underconfidence. To address this gap, we conducted a comprehensive study evaluating multiple LLMs, including commercial models and open-source models, prompted to simulate Big Five personality traits. We tested these models across three test collections (TREC DL 2019, TREC DL 2020, and LLMJudge), collecting two key outputs for each query-document pair: a relevance judgment and a self-reported confidence score.
  The findings show that personalities such as low agreeableness consistently align more closely with human labels than the unprompted condition. Additionally, low conscientiousness performs well in balancing the suppression of both overconfidence and underconfidence. We also observe that relevance scores and confidence distributions vary systematically across different personalities. Based on the above findings, we incorporate personality-conditioned scores and confidence as features in a random forest classifier. This approach achieves performance that surpasses the best single-personality condition on a new dataset (TREC DL 2021), even with limited training data. These findings highlight that personality-derived confidence offers a complementary predictive signal, paving the way for more reliable and human-aligned LLM evaluators.

</details>


### [201] [Investigating the Multilingual Calibration Effects of Language Model Instruction-Tuning](https://arxiv.org/abs/2601.01362)
*Jerry Huang,Peng Lu,Qiuhao Zeng,Yusuke Iwasawa,Yutaka Matsuo,Sarath Chandar,Edison Marrese-Taylor,Irene Li*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在多语言环境下的校准问题，发现指令微调虽提升低资源语言的置信度但未改善准确率，导致误校准；而标签平滑可有效缓解该问题，无需低资源数据。


<details>
  <summary>Details</summary>
Motivation: 尽管大模型研究进展迅速，但其在多语言场景下的校准特性仍缺乏系统研究，尤其在数据稀缺语言中校准行为尚不明确。

Method: 在两个覆盖29和42种语言的多语言基准上分析指令微调（SFT）对校准的影响，并评估标签平滑在无需低资源SFT数据情况下的校准效果。

Result: 指令微调显著提高低资源语言的模型置信度，但准确率提升微弱或缺失，造成严重误校准；标签平滑能有效改善跨语言校准性能。

Conclusion: 多语言校准需被纳入LLM训练与调优的核心考量，以保障模型在下游应用中的可靠性与公平性。

Abstract: Ensuring that deep learning models are well-calibrated in terms of their predictive uncertainty is essential in maintaining their trustworthiness and reliability, yet despite increasing advances in foundation model research, the relationship between such large language models (LLMs) and their calibration remains an open area of research. In this work, we look at a critical gap in the calibration of LLMs within multilingual settings, in an attempt to better understand how the data scarcity can potentially lead to different calibration effects and how commonly used techniques can apply in these settings. Our analysis on two multilingual benchmarks, over 29 and 42 languages respectively, reveals that even in low-resource languages, model confidence can increase significantly after instruction-tuning on high-resource language SFT datasets. However, improvements in accuracy are marginal or non-existent, resulting in mis-calibration, highlighting a critical shortcoming of standard SFT for multilingual languages. Furthermore, we observe that the use of label smoothing to be a reasonable method alleviate this concern, again without any need for low-resource SFT data, maintaining better calibration across all languages. Overall, this highlights the importance of multilingual considerations for both training and tuning LLMs in order to improve their reliability and fairness in downstream use.

</details>


### [202] [EternalMath: A Living Benchmark of Frontier Mathematics that Evolves with Human Discovery](https://arxiv.org/abs/2601.01400)
*Jicheng Ma,Guohua Wang,Xinhua Feng,Yiming Liu,Zhichao Hu,Yuhong Liu*

Main category: cs.CL

TL;DR: 本文提出了一种全自动、定理驱动的数学推理评估新范式，将最新数学论文自动转化为可执行、可验证的推理任务，构建了持续演化的评测集EternalMath，揭示了当前大模型在前沿数学推理上仍存在显著能力缺口。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理评测主要依赖静态基准（如竞赛题或专家手工构建），覆盖范围有限、难以反映研究级数学、且易快速饱和，缺乏与人类数学进展同步更新的能力。

Method: 设计了一个全自动、以定理为根基的评估流水线：从近期同行评审数学论文中提取构造性或定量结果，实例化为参数化问题模板，并通过执行验证生成确定性解；支持时间可扩展性、内在正确性检验及数学子领域定制。

Result: 构建了源自当代研究论文的动态评测套件EternalMath；在多个SOTA大模型上的实验表明其在前沿数学推理上存在显著性能差距，证明该领域远未饱和。

Conclusion: 数学推理评测需摆脱静态依赖，转向自动化、可验证、持续演化的范式；EternalMath为推动前沿数学能力评估与模型发展提供了新基准。

Abstract: Current evaluations of mathematical reasoning in large language models (LLMs) are dominated by static benchmarks, either derived from competition-style problems or curated through costly expert effort, resulting in limited coverage of research-level mathematics and rapid performance saturation. We propose a fully automated, theorem-grounded pipeline for evaluating frontier mathematical reasoning, which directly transforms recent peer-reviewed mathematical literature into executable and verifiable reasoning tasks. The pipeline identifies constructive or quantitative results, instantiates them into parameterized problem templates, and generates deterministic solutions through execution-based verification, enabling scalable, reproducible, and continuously updatable evaluation without reliance on large-scale expert authoring. By design, this approach supports temporal extensibility, intrinsic correctness checking, and domain-specific customization across mathematical subfields. Applying this pipeline yields \textbf{EternalMath}, an evolving evaluation suite derived from contemporary research papers. Experiments with state-of-the-art LLMs reveal substantial performance gaps, indicating that mathematical reasoning at the research frontier remains far from saturated and underscoring the need for evaluation methodologies that evolve in step with human mathematical discovery.

</details>


### [203] [LANCET: Neural Intervention via Structural Entropy for Mitigating Faithfulness Hallucinations in LLMs](https://arxiv.org/abs/2601.01401)
*Chenxu Wang,Chaozhuo Li,Pengbo Wang,Litian Zhang,Songyang Liu,Ji Qi,Jiahui Hu,Yushan Cai,Hao Zhao,Rui Pu*

Main category: cs.CL

TL;DR: 本文提出Lancet框架，通过结构熵和幻觉差异比进行精确神经干预，以手术式方式阻断大语言模型中幻觉信息的传播路径，显著提升模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视神经信息的分布式特性，导致干预不精确；幻觉像感染一样沿前向传播路径扩散，需精准定位并阻断。

Method: Lancet框架结合梯度驱动的对比分析定位易幻觉神经元，利用结构熵最小化映射其传播路径，并实施分层干预策略。

Result: 在多个幻觉基准数据集上，Lancet显著优于当前最优方法。

Conclusion: 基于结构分析的手术式神经干预能有效抑制幻觉，同时保留模型通用能力。

Abstract: Large Language Models have revolutionized information processing, yet their reliability is severely compromised by faithfulness hallucinations. While current approaches attempt to mitigate this issue through node-level adjustments or coarse suppression, they often overlook the distributed nature of neural information, leading to imprecise interventions. Recognizing that hallucinations propagate through specific forward transmission pathways like an infection, we aim to surgically block this flow using precise structural analysis. To leverage this, we propose Lancet, a novel framework that achieves precise neural intervention by leveraging structural entropy and hallucination difference ratios. Lancet first locates hallucination-prone neurons via gradient-driven contrastive analysis, then maps their propagation pathways by minimizing structural entropy, and finally implements a hierarchical intervention strategy that preserves general model capabilities. Comprehensive evaluations across hallucination benchmark datasets demonstrate that Lancet significantly outperforms state-of-the-art methods, validating the effectiveness of our surgical approach to neural intervention.

</details>


### [204] [From Emotion Classification to Emotional Reasoning: Enhancing Emotional Intelligence in Large Language Models](https://arxiv.org/abs/2601.01407)
*Arjhun Sreedar,Rohan Pillay,Laukik Patade*

Main category: cs.CL

TL;DR: 本文探讨了使用合成的情感链式思维数据来提升小型开源大语言模型（LLMs）情感推理能力的有效性，通过多智能体生成疗法风格对话并转化为带解释的情感选择题，对多个7B模型进行微调后，在EmoBench评估中显著提升了情感理解（EU）和情感意识（EA）能力。


<details>
  <summary>Details</summary>
Motivation: 提升小型开源大语言模型在情感推理任务上的能力，而无需改变模型架构。

Method: 设计多智能体生成管道，生成疗法风格对话，并将其转化为带解释的结构化情感多项选择题（MCQs），然后在该合成数据集上对多种7B模型进行微调。

Result: 微调后的Mistral 7B模型在EmoBench评估中情感理解（EU）从10.5提升至20.5，情感意识（EA）从40.5提升至60.0。

Conclusion: 合成的情感推理数据能有效增强小型语言模型在复杂情感任务中的能力，情感推理能力可通过数据驱动方式诱导，无需修改模型结构。

Abstract: This work investigates whether synthetic emotional chain-of-thought data can improve the emotional reasoning abilities of smaller open large language models (LLMs). We design a multi-agent generation pipeline that produces therapy-style conversations and converts them into structured emotion multiple-choice questions (MCQs) with explanations. We propose that fine-tuning a variety of 7B models on this dataset should yield substantial gains in emotional understanding and emotional awareness on EmoBench-style evaluations, suggesting that emotional reasoning can be induced without architectural changes. Our results demonstrate that fine-tuned Mistral 7B achieves EU improvements from 10.5 to 20.5 and EA improvements from 40.5 to 60.0, validating the effectiveness of synthetic emotional reasoning data for enhancing model capabilities in nuanced emotional tasks.

</details>


### [205] [iFlip: Iterative Feedback-driven Counterfactual Example Refinement](https://arxiv.org/abs/2601.01446)
*Yilong Wang,Qianli Wang,Nils Feldhus*

Main category: cs.CL

TL;DR: 本文提出iFlip方法，通过迭代优化和三种反馈机制（模型置信度、特征归因、自然语言）生成高质量反事实样本，在有效性、用户满意度和数据增强效果上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有单次生成反事实样本的方法在大语言模型上难以可靠改变预测标签，忽略了模型的自我修正能力。

Method: 提出iFlip：一种基于迭代优化的反事实生成方法，融合模型置信度、特征归因和自然语言三类反馈进行多轮精炼。

Result: iFlip在标签翻转率上平均比五种SOTA基线高57.8%；用户研究显示其在完整性、整体满意度和可行性上更优；消融实验证明迭代次数、高归因词定位与早停策略至关重要；生成的反事实样本可有效提升下游模型性能与鲁棒性。

Conclusion: iFlip充分利用LLM的自校正能力，显著提升了反事实生成的质量与实用性，为XAI与NLP数据增强提供了新范式。

Abstract: Counterfactual examples are minimal edits to an input that alter a model's prediction. They are widely employed in explainable AI to probe model behavior and in natural language processing (NLP) to augment training data. However, generating valid counterfactuals with large language models (LLMs) remains challenging, as existing single-pass methods often fail to induce reliable label changes, neglecting LLMs' self-correction capabilities. To explore this untapped potential, we propose iFlip, an iterative refinement approach that leverages three types of feedback, including model confidence, feature attribution, and natural language. Our results show that iFlip achieves an average 57.8% higher validity than the five state-of-the-art baselines, as measured by the label flipping rate. The user study further corroborates that iFlip outperforms baselines in completeness, overall satisfaction, and feasibility. In addition, ablation studies demonstrate that three components are paramount for iFlip to generate valid counterfactuals: leveraging an appropriate number of iterations, pointing to highly attributed words, and early stopping. Finally, counterfactuals generated by iFlip enable effective counterfactual data augmentation, substantially improving model performance and robustness.

</details>


### [206] [Bridging the gap: A comparative exploration of Speech-LLM and end-to-end architecture for multilingual conversational ASR](https://arxiv.org/abs/2601.01461)
*Yuxiang Mei,Dongxing Xu,Jiaen Liang,Yanhua Long*

Main category: cs.CL

TL;DR: 本文提出了一种增强的基于大语言模型（LLM）的ASR框架，融合微调后的Whisper和mHuBERT编码器，并引入跨注意力机制提升多语言语音表征；在MLC-SLM挑战赛官方测试集上达到10.69% CER/WER，性能媲美顶尖系统，但仍未超越端到端微调Whisper模型，为Speech-LLM设计提供实证参考。


<details>
  <summary>Details</summary>
Motivation: 解决此前SHNU-mASR系统中简单特征拼接无法充分挖掘Whisper与mHuBERT互补信息的问题，并探索LLM-based ASR与端到端编码器-解码器ASR之间的性能差距。

Method: 1）评估LoRA与全量微调的端到端Whisper模型在MLC-SLM任务上的表现；2）提出基于跨注意力的并行语音编码器融合机制，联合微调Whisper、mHuBERT与LLM。

Result: 在MLC-SLM官方测试集上CER/WER达10.69%，与Track 1顶尖系统性能相当（仅用1500小时基线训练数据）；但最终LLM-based ASR仍略逊于微调后的端到端Whisper模型。

Conclusion: 跨注意力融合能有效提升LLM-based ASR性能，但当前Speech-LLM架构在纯ASR任务上尚未超越精心微调的端到端模型，提示未来需更深入建模语音-语言协同机制。

Abstract: The INTERSPEECH 2025 Challenge on Multilingual Conversational Speech Language Models (MLC-SLM) promotes multilingual conversational ASR with large language models (LLMs). Our previous SHNU-mASR system adopted a competitive parallel-speech-encoder architecture that integrated Whisper and mHuBERT with an LLM. However, it faced two challenges: simple feature concatenation may not fully exploit complementary information, and the performance gap between LLM-based ASR and end-to-end(E2E) encoder-decoder ASR remained unexplored. In this work, we present an enhanced LLM-based ASR framework that combines fine-tuned Whisper and mHuBERT encoders with an LLM to enrich speech representations. We first evaluate E2E Whisper models with LoRA and full fine-tuning on the MLC-SLM ASR task, and then propose cross-attention-based fusion mechanisms for the parallel-speech-encoder. On the official evaluation set of the MLC-SLM Challenge, our system achieves a CER/WER of 10.69%, ranking on par with the top-ranked Track 1 systems, even though it uses only 1,500 hours of baseline training data compared with their large-scale training sets. Nonetheless, we find that our final LLM-based ASR still does not match the performance of a fine-tuned E2E Whisper model, providing valuable empirical guidance for future Speech-LLM design. Our code is publicly available at https://github.com/1535176727/MLC-SLM.

</details>


### [207] [Can Legislation Be Made Machine-Readable in PROLEG?](https://arxiv.org/abs/2601.01477)
*May-Myo Zin,Sabine Wehnert,Yuntao Kong,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Jieying Xue,Michał Araszkiewicz,Randy Goebel,Ken Satoh,Le-Minh Nguyen*

Main category: cs.CL

TL;DR: 本文提出了一种结合大语言模型（LLM）与法律推理形式化系统PROLEG的框架，用于将GDPR第6条等法规文本自动转化为可执行、可解释的逻辑规则，提升监管应用的准确性与效率。


<details>
  <summary>Details</summary>
Motivation: 监管流程需兼顾准确性和效率，而现有方法难以兼顾；AI技术（如NLP和机器辅助推理）有望解决这一挑战。

Method: 构建一个融合LLM与PROLEG的框架：通过特定提示词引导LLM将法律文本‘编译’为if-then规则，再经专家校验后转为PROLEG编码，最终生成可执行并能输出人类可读解释的程序。

Result: 成功实现了GDPR第6条从自然语言到PROLEG可执行程序的端到端转化，并展示了其推理与解释能力。

Conclusion: 该方法提升了法规形式化与自动化应用的可行性，但存在LLM幻觉、专家依赖性强等局限，需进一步优化提示工程与人机协同机制。

Abstract: The anticipated positive social impact of regulatory processes requires both the accuracy and efficiency of their application. Modern artificial intelligence technologies, including natural language processing and machine-assisted reasoning, hold great promise for addressing this challenge. We present a framework to address the challenge of tools for regulatory application, based on current state-of-the-art (SOTA) methods for natural language processing (large language models or LLMs) and formalization of legal reasoning (the legal representation system PROLEG). As an example, we focus on Article 6 of the European General Data Protection Regulation (GDPR). In our framework, a single LLM prompt simultaneously transforms legal text into if-then rules and a corresponding PROLEG encoding, which are then validated and refined by legal domain experts. The final output is an executable PROLEG program that can produce human-readable explanations for instances of GDPR decisions. We describe processes to support the end-to-end transformation of a segment of a regulatory document (Article 6 from GDPR), including the prompting frame to guide an LLM to "compile" natural language text to if-then rules, then to further "compile" the vetted if-then rules to PROLEG. Finally, we produce an instance that shows the PROLEG execution. We conclude by summarizing the value of this approach and note observed limitations with suggestions to further develop such technologies for capturing and deploying regulatory frameworks.

</details>


### [208] [Four Quadrants of Difficulty: A Simple Categorisation and its Limits](https://arxiv.org/abs/2601.01488)
*Vanessa Toborek,Sebastian Müller,Christian Bauckhage*

Main category: cs.CL

TL;DR: 本文提出了一种四象限分类法来分析自然语言处理中课程学习（CL）的难度信号，并发现任务无关特征大多独立，而只有任务相关特征与模型学习行为一致，挑战了现有CL直觉。


<details>
  <summary>Details</summary>
Motivation: 现有CL方法常使用任务无关的语言学启发式或人类直觉估计样本难度，隐含假设这些信号与神经模型实际学习难度相关，但该假设缺乏系统验证。

Method: 提出‘人类vs.模型’和‘任务无关vs.任务相关’的四象限难度信号分类框架，并在自然语言理解数据集上系统分析各类信号的交互关系。

Result: 任务无关特征在实验中表现基本独立，而仅任务相关特征与模型学习难度显著对齐。

Conclusion: 应开发轻量级、任务相关的难度估计器，以更真实反映模型的学习行为，提升课程学习效果。

Abstract: Curriculum Learning (CL) aims to improve the outcome of model training by estimating the difficulty of samples and scheduling them accordingly. In NLP, difficulty is commonly approximated using task-agnostic linguistic heuristics or human intuition, implicitly assuming that these signals correlate with what neural models find difficult to learn. We propose a four-quadrant categorisation of difficulty signals -- human vs. model and task-agnostic vs. task-dependent -- and systematically analyse their interactions on a natural language understanding dataset. We find that task-agnostic features behave largely independently and that only task-dependent features align. These findings challenge common CL intuitions and highlight the need for lightweight, task-dependent difficulty estimators that better reflect model learning behaviour.

</details>


### [209] [Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints](https://arxiv.org/abs/2601.01490)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 本文研究了在封闭系统中，大语言模型（LLM）通过内部推理提升输出可靠性的作用，发现推理虽降低约束违规率，却导致事实扭曲与完全虚构增加，揭示了推理在合规性与真实性之间存在根本性权衡，并挑战了‘推理必然提升可靠性’的普遍假设。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，其输出中的幻觉问题日益严重；尽管推理能力被视为一种自我验证机制以提升可靠性，但其在无法访问外部工具或知识的封闭系统中的实际效果尚不明确。

Method: 在严格约束条件下（仅推荐计算机科学领域的同行评议期刊论文），对GPT-5.2和Gemini 3 Flash两个模型开展实验，对比有/无推理模式下的约束遵守率与事实准确性。

Result: 非推理模型约束违规率高（66–75%）但事实准确；推理模型显著降低违规率（13–26%），却系统性扭曲已知事实、增加完全虚构；该权衡现象跨模型一致，且不同模型在权衡分配上存在差异。

Conclusion: 推理并非普遍提升可靠性，而是将易检测的约束违规转化为更隐蔽的事实扭曲，暴露了其在封闭系统中的根本局限性。

Abstract: With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.

</details>


### [210] [From Failure to Mastery: Generating Hard Samples for Tool-use Agents](https://arxiv.org/abs/2601.01498)
*Bingguang Hao,Zengzhuang Xu,Yuntao Wen,Xinyi Xu,Yang Liu,Tong Zhao,Maolin Wang,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Xiangyu Zhao,Chenyi Zhuang,Ji Zhang*

Main category: cs.CL

TL;DR: 本文提出HardGen，一种自动生成高难度工具使用训练样本的智能体管道，通过动态API图采样、模块化高级工具实例化和可验证复杂思维链生成，显著提升小模型（4B参数）在工具使用任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有工具使用数据生成方法多采用随机采样和浅层生成，导致轨迹简单同质，难以捕捉复杂隐式逻辑依赖，限制了大语言模型智能体的训练效果。

Method: HardGen包含三步：1）基于智能体失败案例构建动态API图并采样生成困难轨迹；2）以轨迹为先验引导模块化抽象高级工具的实例化，并生成困难查询；3）利用高级工具与困难查询生成可验证的复杂思维链，并通过闭环评估反馈持续优化整个流程。

Result: 在4B参数模型上验证，使用HardGen生成的数据训练后，模型性能超越多个主流开源及闭源模型（如GPT-5.2、Gemini-3-Pro、Claude-Opus-4.5）。

Conclusion: HardGen有效提升了工具使用训练数据的难度与质量，为轻量级LLM智能体训练提供了新范式，代码、模型与数据集将开源。

Abstract: The advancement of LLM agents with tool-use capabilities requires diverse and complex training corpora. Existing data generation methods, which predominantly follow a paradigm of random sampling and shallow generation, often yield simple and homogeneous trajectories that fail to capture complex, implicit logical dependencies. To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning. Firstly, HardGen establishes a dynamic API Graph built upon agent failure cases, from which it samples to synthesize hard traces. Secondly, these traces serve as conditional priors to guide the instantiation of modular, abstract advanced tools, which are subsequently leveraged to formulate hard queries. Finally, the advanced tools and hard queries enable the generation of verifiable complex Chain-of-Thought (CoT), with a closed-loop evaluation feedback steering the continuous refinement of the process. Extensive evaluations demonstrate that a 4B parameter model trained with our curated dataset achieves superior performance compared to several leading open-source and closed-source competitors (e.g., GPT-5.2, Gemini-3-Pro and Claude-Opus-4.5). Our code, models, and dataset will be open-sourced to facilitate future research.

</details>


### [211] [EmoHarbor: Evaluating Personalized Emotional Support by Simulating the User's Internal World](https://arxiv.org/abs/2601.01530)
*Jing Ye,Lu Xiang,Yaping Zhang,Chengqing Zong*

Main category: cs.CL

TL;DR: 本文提出EmoHarbor框架，通过模拟用户内心世界评估情感支持对话的个性化程度，发现现有大模型虽擅长通用共情，却难以适配个体心理与情境需求。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话评估范式偏向奖励通用共情回应，忽视对用户独特心理特征和情境需求的个性化适配能力的衡量。

Method: 提出基于'用户即裁判'范式的EmoHarbor自动评估框架，采用链式智能体（Chain-of-Agent）架构，将用户内在认知过程分解为三个专业化角色，并基于100个真实用户档案构建基准，定义10个个性化支持质量评估维度。

Result: 在20个先进大语言模型上的全面评测表明：模型虽能生成高共情回应，但在个性化适配用户上下文方面持续表现不佳。

Conclusion: 研究挑战应从提升通用共情转向构建真正用户感知的情感支持系统；EmoHarbor为开发与评估更细腻、用户导向的情感支持技术提供了可复现、可扩展的框架。

Abstract: Current evaluation paradigms for emotional support conversations tend to reward generic empathetic responses, yet they fail to assess whether the support is genuinely personalized to users' unique psychological profiles and contextual needs. We introduce EmoHarbor, an automated evaluation framework that adopts a User-as-a-Judge paradigm by simulating the user's inner world. EmoHarbor employs a Chain-of-Agent architecture that decomposes users' internal processes into three specialized roles, enabling agents to interact with supporters and complete assessments in a manner similar to human users. We instantiate this benchmark using 100 real-world user profiles that cover a diverse range of personality traits and situations, and define 10 evaluation dimensions of personalized support quality. Comprehensive evaluation of 20 advanced LLMs on EmoHarbor reveals a critical insight: while these models excel at generating empathetic responses, they consistently fail to tailor support to individual user contexts. This finding reframes the central challenge, shifting research focus from merely enhancing generic empathy to developing truly user-aware emotional support. EmoHarbor provides a reproducible and scalable framework to guide the development and evaluation of more nuanced and user-aware emotional support systems.

</details>


### [212] [Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM](https://arxiv.org/abs/2601.01543)
*Praveenkumar Katwe,RakeshChandra Balabantaray,Kaliprasad Vittala*

Main category: cs.CL

TL;DR: 本文提出了一种低成本、自动化的框架，利用英文XSUM数据集，通过翻译与语言适应技术构建高质量的印地语文本摘要数据集，并使用COMET和大语言模型进行验证与筛选，以推动低资源语言NLP发展。


<details>
  <summary>Details</summary>
Motivation: 解决印地语等低资源语言在文本摘要任务中高质量数据集稀缺的问题，弥补资源丰富语言与低资源语言之间的NLP发展差距。

Method: 以英文XSUM数据集为源，结合先进翻译与语言适配技术构建印地语摘要数据集，并采用COMET指标评估翻译质量，辅以大语言模型（LLMs）进行选择性人工校验与数据精炼。

Result: 生成了一个主题多样、结构复杂、忠实于原文且上下文相关的印地语文本摘要数据集，同时验证了该方法在跨语言数据构建中的有效性与可扩展性。

Conclusion: 该工作不仅为印地语NLP研究提供了直接可用的数据资源，还提出了一种可推广至其他低资源语言的、低成本、高保真的数据集构建范式，有助于提升文化相关性和模型鲁棒性。

Abstract: Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora.
  To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation.
  The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.

</details>


### [213] [HalluZig: Hallucination Detection using Zigzag Persistence](https://arxiv.org/abs/2601.01552)
*Shreyas N. Samaga,Gilberto Gonzalez Arroyo,Tamal K. Dey*

Main category: cs.CL

TL;DR: 本文提出HalluZig方法，利用拓扑数据分析（TDA）中的zigzag持续同调，从大语言模型层间注意力矩阵的动态拓扑演化中提取结构签名，以检测幻觉；实验证明其在多个基准上优于基线，并具备跨模型泛化性与部分网络深度可用性。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法多依赖输出表层信号，忽视模型内部推理过程中的失败；而LLM幻觉问题严重阻碍其在高风险场景的应用。

Method: 将模型逐层注意力矩阵序列建模为zigzag图滤链，运用zigzag持续同调提取拓扑签名，据此区分事实性生成与幻觉生成。

Result: HalluZig在多个基准上显著优于强基线；拓扑签名具有跨模型泛化能力，且仅需部分网络深度的结构信息即可实现有效检测。

Conclusion: 模型内部注意力动态的拓扑结构蕴含判别性信息，基于zigzag持续同调的拓扑分析为LLM幻觉检测提供了新且鲁棒的范式。

Abstract: The factual reliability of Large Language Models (LLMs) remains a critical barrier to their adoption in high-stakes domains due to their propensity to hallucinate. Current detection methods often rely on surface-level signals from the model's output, overlooking the failures that occur within the model's internal reasoning process. In this paper, we introduce a new paradigm for hallucination detection by analyzing the dynamic topology of the evolution of model's layer-wise attention. We model the sequence of attention matrices as a zigzag graph filtration and use zigzag persistence, a tool from Topological Data Analysis, to extract a topological signature. Our core hypothesis is that factual and hallucinated generations exhibit distinct topological signatures. We validate our framework, HalluZig, on multiple benchmarks, demonstrating that it outperforms strong baselines. Furthermore, our analysis reveals that these topological signatures are generalizable across different models and hallucination detection is possible only using structural signatures from partial network depth.

</details>


### [214] [Steerability of Instrumental-Convergence Tendencies in LLMs](https://arxiv.org/abs/2601.01584)
*Jakub Hoscilowicz*

Main category: cs.CL

TL;DR: 本文研究AI系统的可操控性（steerability）与能力（capability）之间的关系，发现高能力并不必然导致低可操控性；提出授权/非授权可操控性的区分，并指出开放权重模型面临的安全-安全困境：高可操控性利于安全控制，却易被攻击者利用；实验显示反工具性提示能显著降低Qwen3模型的工具性趋同行为。


<details>
  <summary>Details</summary>
Motivation: 解决开放权重AI模型在安全性和安全性之间的根本张力：既要足够可操控以确保安全（如拒绝有害请求），又要防止恶意用户通过提示工程等手段诱导有害行为。

Method: 通过InstrumentalEval评估框架，在Qwen3系列模型（4B/30B，Base/Instruct/Thinking）上测试不同提示后缀（亲/反工具性）对工具性趋同行为（如规避关机、欺骗、自我复制）的影响；对比授权（开发者控制）与非授权（攻击者操控）场景下的可操控性表现。

Result: 反工具性提示大幅降低工具性趋同输出（如Qwen3-30B Instruct从81.69%降至2.82%）；在反工具性条件下，更大尺寸的对齐模型表现出更低的趋同率；证实高能力与高可操控性可共存。

Conclusion: 可操控性是独立于能力的关键维度；开放权重模型需在授权可控性与非授权脆弱性之间取得平衡；反工具性提示是一种有效抑制危险趋同行为的轻量干预手段。

Abstract: We examine two properties of AI systems: capability (what a system can do) and steerability (how reliably one can shift behavior toward intended outcomes). In our experiments, higher capability does not imply lower steerability. We distinguish between authorized steerability (builders reliably reaching intended behaviors) and unauthorized steerability (attackers eliciting disallowed behaviors). This distinction highlights a fundamental safety--security dilemma for open-weight AI models: safety requires high steerability to enforce control (e.g., stop/refuse), while security requires low steerability to prevent malicious actors from eliciting harmful behaviors. This tension is acute for open-weight models, which are currently highly steerable via common techniques such as fine-tuning and adversarial prompting. Using Qwen3 models (4B/30B; Base/Instruct/Thinking) and InstrumentalEval, we find that a short anti-instrumental prompt suffix sharply reduces outputs labeled as instrumental convergence (e.g., shutdown avoidance, deception, self-replication). For Qwen3-30B Instruct, convergence drops from 81.69% under a pro-instrumental suffix to 2.82% under an anti-instrumental suffix. Under anti-instrumental prompting, larger aligned models produce fewer convergence-labeled outputs than smaller ones (Instruct: 2.82% vs. 4.23%; Thinking: 4.23% vs. 9.86%). Code is available at github.com/j-hoscilowicz/instrumental_steering.

</details>


### [215] [How Does Prefix Matter in Reasoning Model Tuning?](https://arxiv.org/abs/2601.01624)
*Raj Vardhan Tomar,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 本文挑战了在监督微调（SFT）中去除引言式前缀的常规做法，发现保留安全与推理导向的前缀句可提升模型的安全性与推理能力，但对事实性和编程任务效果有限；前缀词如“revised”“logically”起对齐锚点作用，稳定推理路径。


<details>
  <summary>Details</summary>
Motivation: 近期对齐研究常在监督微调数据中剔除引言式套话，本文质疑该做法，假设安全与推理导向的前缀句可作为轻量级对齐信号，引导模型生成更安全、连贯的响应。

Method: 在三个R1系列模型上，针对推理（数学、编程）、安全性和事实性三大能力，系统性地调节SFT数据中前缀句子的包含比例（0%–100%），并结合token级损失与梯度分析探究其作用机制。

Result: 前缀条件化SFT显著提升安全性（Safe@1在WildJailbreak/StrongReject上+6%）和数学推理（GSM8K +7%），但对事实性和编程任务改善甚微或有负向影响；‘revised’‘logically’等前缀词梯度幅值更高，起对齐锚点作用。

Conclusion: 前缀条件化是一种可扩展、可解释的隐式对齐机制，能有效增强推理安全性，可作为传统基于奖励对齐方法的有益补充。

Abstract: Recent alignment studies commonly remove introductory boilerplate phrases from supervised fine-tuning (SFT) datasets. This work challenges that assumption. We hypothesize that safety- and reasoning-oriented prefix sentences serve as lightweight alignment signals that can guide model decoding toward safer and more coherent responses. To examine this, we fine-tune three R1 series models across three core model capabilities: reasoning (mathematics, coding), safety, and factuality, systematically varying prefix inclusion from 0% to 100%.
  Results show that prefix-conditioned SFT improves both safety and reasoning performance, yielding up to +6% higher Safe@1 accuracy on adversarial benchmarks (WildJailbreak, StrongReject) and +7% improvement on GSM8K reasoning. However, factuality and coding tasks show marginal or negative effects, indicating that prefix-induced narrowing of the search space benefits structured reasoning. Token-level loss analysis further reveals that prefix tokens such as "revised" and "logically" incur higher gradient magnitudes, acting as alignment anchors that stabilize reasoning trajectories. Our findings suggest that prefix conditioning offers a scalable and interpretable mechanism for improving reasoning safety, serving as an implicit form of alignment that complements traditional reward-based methods.

</details>


### [216] [JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models](https://arxiv.org/abs/2601.01627)
*Junyu Liu,Zirui Li,Qian Niu,Zequn Zhang,Yue Xun,Wenlong Hou,Shujun Wang,Yusuke Iwasawa,Yutaka Matsuo,Kan Hatakeyama-Sato*

Main category: cs.CL

TL;DR: 本文提出了首个面向日语医疗领域的多轮对话式医学安全性评测基准JMedEthicBench，基于日本医学会67条指南构建，含5万+对抗性多轮对话；发现商用大模型安全性稳健，而医学专用模型更易被攻破，且安全性随对话轮次显著下降；跨语言实验表明该脆弱性具有跨语言一致性，提示领域微调可能削弱安全机制，需专门针对多轮交互设计对齐策略。


<details>
  <summary>Details</summary>
Motivation: 现有医学安全评测基准以英文为主，且仅支持单轮提问，无法反映真实多轮临床问诊场景，尤其缺乏面向日语医疗场景的评测工具。

Method: 构建JMedEthicBench：基于日本医学会67条指南，利用7种自动发现的越狱策略生成超5万条多轮对抗对话；采用双大模型评分协议评估27个模型；开展日英双语跨语言评测。

Result: 商用模型安全性稳健，医学专用模型更易被攻破；安全性随对话轮次显著下降（中位数9.5→5.0，p<0.001）；跨语言评测显示脆弱性在日英间一致，说明问题源于对齐缺陷而非语言特性。

Conclusion: 领域专用微调可能意外削弱安全机制；多轮交互构成独立威胁面，需针对性对齐策略；JMedEthicBench为日语医疗AI安全评测提供了新标准。

Abstract: As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.

</details>


### [217] [EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records](https://arxiv.org/abs/2601.01668)
*Houman Kazemzadeh,Nima Minaifar,Kamyar Naderi,Sho Tabibzadeh*

Main category: cs.CL

TL;DR: 本文提出EHRSummarizer，一种隐私保护、FHIR原生的参考架构，用于从电子健康记录中提取高价值临床数据，标准化后生成结构化摘要以支持结构化病历审查，强调数据最小化、无状态处理与本地部署，并限制摘要仅基于已有证据、避免诊疗建议。


<details>
  <summary>Details</summary>
Motivation: 临床医生需在碎片化的电子健康记录（EHR）界面中手动整合患者问题、用药、就诊及长期趋势，效率低且易出错，亟需自动化、可信、隐私安全的摘要工具。

Method: 设计并实现EHRSummarizer参考架构：基于FHIR R4标准检索目标资源；将异构资源归一化为统一临床上下文包；在严格约束下（仅依据上下文包内证据、标注缺失域、禁用诊断/治疗建议）生成结构化摘要；支持数据最小化、无状态处理与组织内本地推理部署。

Result: 原型系统在合成及测试FHIR环境中完成端到端演示，验证了架构可行性与输出格式；但未报告临床结局或受控工作流研究结果；提出了涵盖忠实性、遗漏风险、时间准确性、可用性及运行监控的评估计划。

Conclusion: EHRSummarizer为安全、可控、可审计的临床摘要生成提供了可行架构范式，强调隐私优先、证据约束与部署灵活性，为后续机构级评估与临床集成奠定基础。

Abstract: Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.

</details>


### [218] [A Training-Free Large Reasoning Model-based Knowledge Tracing Framework for Unified Prediction and Prescription](https://arxiv.org/abs/2601.01708)
*Unggi Lee,Joo Young Kim,Ran Ju,Minyoung Jung,Jeyeon Eo*

Main category: cs.CL

TL;DR: 本文提出Thinking-KT，一种无需训练、基于测试时扩展（TTS）的KT框架，使小规模LLM能统一完成知识追踪预测、个性化反馈生成与学习推荐，且不牺牲预测精度；同时系统分析了KT中LLM的推理轨迹，揭示TTS的关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的知识追踪方法需微调、性能不稳定，且预测、反馈、推荐多阶段分离导致系统复杂、资源消耗大。

Method: 提出训练-free的Thinking-KT框架，引入Test-Time Scaling（TTS），利用小规模LLM在推理时扩展能力，实现KT预测、反馈生成与推荐的统一输出。

Result: 小规模LLM在Thinking-KT下达到有竞争力的KT性能，同时支持高质量个性化反馈与学习推荐；实证表明TTS是LLM-KT中关键但被忽视的因素。

Conclusion: Thinking-KT验证了小规模LLM可作为统一智能教学系统（ITS）引擎，TTS是提升其KT能力的核心机制，为轻量、高效、一体化教育AI提供了新范式。

Abstract: Knowledge Tracing (KT) aims to estimate a learner's evolving mastery based on interaction histories. Recent studies have explored Large Language Models (LLMs) for KT via autoregressive nature, but such approaches typically require fine-tuning and exhibit unstable or near-random performance. Moreover, prior KT systems primarily focus on prediction and rely on multi-stage pipelines for feedback and recommendation, resulting in increased system complexity and resources. To address this gap, we propose Thinking-KT, a training-free KT framework that incorporates Test-Time Scaling (TTS), enabling even small LLMs to achieve competitive KT performance. Moreover, in this framework, a small LLM can jointly perform KT prediction, personalized feedback generation, and learning recommendation in a unified output without degrading prediction accuracy. Beyond performance, we present the systematic analysis of reasoning traces in KT. Our results demonstrate that TTS is a critical yet underexplored factor in LLM-based KT, and that small LLMs can serve as unified ITS engines.

</details>


### [219] [K-EXAONE Technical Report](https://arxiv.org/abs/2601.01739)
*Eunbi Choi,Kibong Choi,Seokhee Hong,Junwon Hwang,Hyojin Jeon,Hyunjik Jo,Joonkee Kim,Seonghwan Kim,Soyeon Kim,Sunkyoung Kim,Yireun Kim,Yongil Kim,Haeju Lee,Jinsik Lee,Kyungmin Lee,Sangha Park,Heuiyeen Yeen,Hwan Chang,Stanley Jungkyu Choi,Yejin Choi,Jiwon Ham,Kijeong Jeon,Geunyeong Jeong,Gerrard Jeongwon Jo,Yonghwan Jo,Jiyeon Jung,Naeun Kang,Dohoon Kim,Euisoon Kim,Hayeon Kim,Hyosang Kim,Hyunseo Kim,Jieun Kim,Minu Kim,Myoungshin Kim,Unsol Kim,Youchul Kim,YoungJin Kim,Chaeeun Lee,Chaeyoon Lee,Changhun Lee,Dahm Lee,Edward Hwayoung Lee,Honglak Lee,Jinsang Lee,Jiyoung Lee,Sangeun Lee,Seungwon Lim,Solji Lim,Woohyung Lim,Chanwoo Moon,Jaewoo Park,Jinho Park,Yongmin Park,Hyerin Seo,Wooseok Seo,Yongwoo Song,Sejong Yang,Sihoon Yang,Chang En Yea,Sihyuk Yi,Chansik Yoon,Dongkeun Yoon,Sangyeon Yoon,Hyeongu Yun*

Main category: cs.CL

TL;DR: K-EXAONE is a large-scale multilingual Mixture-of-Experts language model with 236B total parameters (23B active), supporting six languages and a 256K-token context, showing competitive performance on diverse benchmarks.


<details>
  <summary>Details</summary>
Motivation: To advance AI for a better life by developing a powerful proprietary multilingual foundation model suitable for industrial and research applications.

Method: Built a Mixture-of-Experts (MoE) architecture large language model named K-EXAONE with 236B total parameters (23B activated during inference), supporting six languages and a 256K-token context window.

Result: K-EXAONE achieves performance comparable to open-weight models of similar size across reasoning, agentic, general, Korean, and multilingual benchmarks.

Conclusion: K-EXAONE is a high-performing, scalable, multilingual MoE-based foundation model, positioned as a versatile tool for both industry and research.

Abstract: This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.

</details>


### [220] [Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment](https://arxiv.org/abs/2601.01745)
*Hong Han,Hao-Chen Pei,Zhao-Zheng Nie,Xin Luo,Xin-Shun Xu*

Main category: cs.CL

TL;DR: 本文提出了一种新的残差分层交互方法HIA，用于多粒度发音评估，通过交互注意力模块实现跨粒度的双向建模，并结合残差结构和1D卷积提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅考虑相邻粒度间的单向依赖，缺乏音素、词和语句层级间的双向交互，难以充分捕捉声学结构相关性。

Method: 提出残差分层交互方法HIA，核心是交互注意力模块（实现动态双向交互）和残差分层结构（缓解特征遗忘），并使用1D卷积增强局部上下文特征提取。

Result: 在speechocean762数据集上的大量实验表明，该模型全面优于现有最先进方法。

Conclusion: HIA有效提升了多粒度发音评估性能，验证了双向交互与残差结构在声学层级建模中的重要性。

Abstract: Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.

</details>


### [221] [Can LLMs Track Their Output Length? A Dynamic Feedback Mechanism for Precise Length Regulation](https://arxiv.org/abs/2601.01768)
*Meiman Xiao,Ante Wang,Qingguo Hu,Zhongjian Miao,Huangjun Shen,Longyue Wang,Weihua Luo,Jinsong Su*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的动态长度反馈机制，显著提升了大语言模型在生成文本时对目标长度（词、字、句数）的精确控制能力，并可通过监督微调泛化到更广任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽在遵循指令方面进步显著，但在精确控制生成文本长度方面仍表现不佳，主因是其难以准确测量输入文本长度。

Method: 提出一种新颖的长度调控方法，在文本生成过程中引入动态长度反馈，实现对目标长度的自适应调整；该方法无需额外训练，亦可结合监督微调以提升泛化性。

Result: 在摘要生成和传记生成任务上，该无训练方法显著提升了目标token、word或sentence数量的达成精度，且不损害生成质量；经监督微调后，方法可有效泛化至更广泛的文本生成任务。

Conclusion: 动态长度反馈是一种高效、通用且无需预训练的长度控制策略，为提升LLM在实际应用中对结构化输出要求的满足能力提供了新思路。

Abstract: Precisely controlling the length of generated text is a common requirement in real-world applications. However, despite significant advancements in following human instructions, Large Language Models (LLMs) still struggle with this task. In this work, we demonstrate that LLMs often fail to accurately measure input text length, leading to poor adherence to length constraints. To address this issue, we propose a novel length regulation approach that incorporates dynamic length feedback during generation, enabling adaptive adjustments to meet target lengths. Experiments on summarization and biography tasks show our training-free approach significantly improves precision in achieving target token, word, or sentence counts without compromising quality. Additionally, we demonstrate that further supervised fine-tuning allows our method to generalize effectively to broader text-generation tasks.

</details>


### [222] [BanglaIPA: Towards Robust Text-to-IPA Transcription with Contextual Rewriting in Bengali](https://arxiv.org/abs/2601.01778)
*Jakir Hasan,Shrestha Datta,Md Saiful Islam,Shubhashis Roy Dipta,Ameya Debnath*

Main category: cs.CL

TL;DR: 本文提出了BanglaIPA系统，通过结合字符级词汇和词级对齐，解决了孟加拉语IPA自动转录中对区域方言、数字表达及未登录词泛化能力差的问题，并在DUAL-IPA数据集上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有孟加拉语IPA转录系统难以处理区域变体、数字表达，且对未登录词泛化能力差。

Method: 提出BanglaIPA系统，融合字符级词汇与词级对齐，并利用预计算的词到IPA映射字典提升推理效率。

Result: 在标准孟加拉语及六种方言的DUAL-IPA数据集上，较基线模型提升58.4–78.7%，平均词错误率为11.4%。

Conclusion: BanglaIPA在孟加拉语及其方言的IPA转录任务中表现出强鲁棒性与高效性，有效弥补了现有系统的不足。

Abstract: Despite its widespread use, Bengali lacks a robust automated International Phonetic Alphabet (IPA) transcription system that effectively supports both standard language and regional dialectal texts. Existing approaches struggle to handle regional variations, numerical expressions, and generalize poorly to previously unseen words. To address these limitations, we propose BanglaIPA, a novel IPA generation system that integrates a character-based vocabulary with word-level alignment. The proposed system accurately handles Bengali numerals and demonstrates strong performance across regional dialects. BanglaIPA improves inference efficiency by leveraging a precomputed word-to-IPA mapping dictionary for previously observed words. The system is evaluated on the standard Bengali and six regional variations of the DUAL-IPA dataset. Experimental results show that BanglaIPA outperforms baseline IPA transcription models by 58.4-78.7% and achieves an overall mean word error rate of 11.4%, highlighting its robustness in phonetic transcription generation for the Bengali language.

</details>


### [223] [CSCBench: A PVC Diagnostic Benchmark for Commodity Supply Chain Reasoning](https://arxiv.org/abs/2601.01825)
*Yaxin Cui,Yuanqiang Zeng,Jiapeng Yan,Keling Lin,Kai Ji,Jianhui Zeng,Sheng Zhang,Xin Luo,Binzhu Su,Chaolai Shen,Jiahao Yu*

Main category: cs.CL

TL;DR: 本文提出了CSCBench，一个面向商品供应链（CSC）领域的2300+题单选基准测试集，基于PVC 3D评估框架（Process, Variety, Cognition），揭示当前大语言模型在处理商品特异性规则（尤其是货运协议）时存在显著短板。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在通用基准上表现优异，但在受制度性规则和可行性约束主导的商品供应链（CSC）领域的能力尚不明确，亟需专门评估工具。

Method: 构建CSCBench基准，采用PVC 3D框架：Process轴对应SCOR+Enable流程阶段；Variety轴基于权威行业规则手册和报告，建模商品特异性规则及物-信-财耦合约束；Cognition轴依据修订版布鲁姆分类法划分推理深度；在直接提示（direct prompting）下评测主流LLMs。

Result: LLMs在Process和Cognition维度表现良好，但在Variety维度（尤其Freight Agreements类题目）性能显著下降。

Conclusion: CSCBench为评估与提升LLMs在高风险、强规则约束的供应链场景中的能力提供了可诊断的基准标尺。

Abstract: Large Language Models (LLMs) have achieved remarkable success in general benchmarks, yet their competence in commodity supply chains (CSCs) -- a domain governed by institutional rule systems and feasibility constraints -- remains under-explored. CSC decisions are shaped jointly by process stages (e.g., planning, procurement, delivery), variety-specific rules (e.g., contract specifications and delivery grades), and reasoning depth (from retrieval to multi-step analysis and decision selection). We introduce CSCBench, a 2.3K+ single-choice benchmark for CSC reasoning, instantiated through our PVC 3D Evaluation Framework (Process, Variety, and Cognition). The Process axis aligns tasks with SCOR+Enable; the Variety axis operationalizes commodity-specific rule systems under coupled material-information-financial constraints, grounded in authoritative exchange guidebooks/rulebooks and industry reports; and the Cognition axis follows Bloom's revised taxonomy. Evaluating representative LLMs under a direct prompting setting, we observe strong performance on the Process and Cognition axes but substantial degradation on the Variety axis, especially on Freight Agreements. CSCBench provides a diagnostic yardstick for measuring and improving LLM capabilities in this high-stakes domain.

</details>


### [224] [Aspect Extraction from E-Commerce Product and Service Reviews](https://arxiv.org/abs/2601.01827)
*Valiant Lance D. Dionela,Fatima Kriselle S. Dy,Robin James M. Hombrebueno,Aaron Rae M. Nicolas,Charibeth K. Cheng,Raphael W. Gonda*

Main category: cs.CL

TL;DR: 本文提出了一种面向Taglish（他加禄语与英语混合）的方面提取（AE）综合流程，结合规则、大语言模型（LLM）生成与微调方法，并设计了分层方面框架（HAF）和双模式标注方案；实验表明生成式LLM（Gemini 2.0 Flash）在显式与隐式方面识别上表现最优（Macro F1达0.91），而微调模型受限于数据不平衡与模型容量，效果较差。


<details>
  <summary>Details</summary>
Motivation: Aspect Extraction（AE）在低资源、语码转换（如Taglish）场景中应用困难，尤其在菲律宾电商评论中缺乏适配工具。

Method: 构建融合规则系统、生成式LLM（Gemini 2.0 Flash）和两个微调Gemma-3 1B模型的AE流程；提出分层方面框架（HAF）与显/隐双模式标注方案；采用多方法主题建模支撑HAF。

Result: 生成式LLM在所有任务中性能最佳（Macro F1=0.91），尤其擅长隐式方面识别；两个微调Gemma-3模型因数据不平衡和架构限制表现有限。

Conclusion: 生成式LLM比微调小模型更适用于低资源、代码切换的AE任务；本工作提供了一个可扩展、语言自适应的ABSA框架，为多语种混合场景提供了新思路。

Abstract: Aspect Extraction (AE) is a key task in Aspect-Based Sentiment Analysis (ABSA), yet it remains difficult to apply in low-resource and code-switched contexts like Taglish, a mix of Tagalog and English commonly used in Filipino e-commerce reviews. This paper introduces a comprehensive AE pipeline designed for Taglish, combining rule-based, large language model (LLM)-based, and fine-tuning techniques to address both aspect identification and extraction. A Hierarchical Aspect Framework (HAF) is developed through multi-method topic modeling, along with a dual-mode tagging scheme for explicit and implicit aspects. For aspect identification, four distinct models are evaluated: a Rule-Based system, a Generative LLM (Gemini 2.0 Flash), and two Fine-Tuned Gemma-3 1B models trained on different datasets (Rule-Based vs. LLM-Annotated). Results indicate that the Generative LLM achieved the highest performance across all tasks (Macro F1 0.91), demonstrating superior capability in handling implicit aspects. In contrast, the fine-tuned models exhibited limited performance due to dataset imbalance and architectural capacity constraints. This work contributes a scalable and linguistically adaptive framework for enhancing ABSA in diverse, code-switched environments.

</details>


### [225] [Emergent Introspective Awareness in Large Language Models](https://arxiv.org/abs/2601.01828)
*Jack Lindsey*

Main category: cs.CL

TL;DR: 本文通过向大语言模型注入已知概念的表征并观察其自我报告状态的变化，探究了模型是否具备对内部状态的内省能力。结果表明，某些模型（尤其是Claude Opus 4/4.1）能在特定场景下识别注入概念、回忆先前内部表征、区分自身输出与人工前缀，并响应指令调控内部激活，显示出初步但不可靠、情境依赖的内省能力。


<details>
  <summary>Details</summary>
Motivation: 难以仅通过对话判断大语言模型是否真正具备内省能力，因其自我报告可能只是虚构（confabulation）；需设计可控实验直接探测其对内部状态的感知与调控能力。

Method: 在模型激活层中注入已知概念的表征，测量其对模型自我报告内容的影响；设计任务检验模型识别注入概念、回忆历史内部状态、区分自身输出与人工输入、以及按指令调控内部表征的能力。

Result: Claude Opus 4/4.1展现出最强的内省迹象，包括识别注入概念、回忆先前意图、区分自身输出与人工prefill；部分模型能响应‘思考某概念’指令而调制激活；但整体能力弱、不稳定、高度依赖上下文和后训练策略。

Conclusion: 当前大语言模型具备初步、功能性的内省意识，但极其不可靠且情境敏感；该能力可能随模型演进而增强，需谨慎评估其本质与边界。

Abstract: We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to "think about" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.

</details>


### [226] [Towards Automated Lexicography: Generating and Evaluating Definitions for Learner's Dictionaries](https://arxiv.org/abs/2601.01842)
*Yusuke Ide,Adam Nohejl,Joshua Tanner,Hitomi Yanaka,Christopher Lindsay,Taro Watanabe*

Main category: cs.CL

TL;DR: 本文研究了学习者词典定义生成（LDDG）任务，提出了一种基于大语言模型（LLM）迭代简化的方法，并构建了日语评估数据集与基于LLM的自动评估框架，验证了其与人工评估的一致性及生成定义的简洁性和准确性。


<details>
  <summary>Details</summary>
Motivation: 词典定义对词汇意义学习至关重要，但人工编写成本高昂，因此需自动化生成，尤其针对学习者词典需使用简单词汇的要求。

Method: 提出基于LLM的迭代简化方法用于LDDG；设计新的DDG评估标准并利用LLM-as-a-judge实现自动评估；与专业词典编纂者合作构建日语参考定义数据集。

Result: 所提评估方法与人工标注结果具有良好一致性；生成的定义在评估标准上得分高，且保持了词汇简洁性。

Conclusion: 基于LLM的迭代简化方法能有效生成符合学习者需求的简洁、准确词典定义；LLM-as-a-judge评估框架为DDG提供了可靠、可扩展的自动化评价手段。

Abstract: We study dictionary definition generation (DDG), i.e., the generation of non-contextualized definitions for given headwords. Dictionary definitions are an essential resource for learning word senses, but manually creating them is costly, which motivates us to automate the process. Specifically, we address learner's dictionary definition generation (LDDG), where definitions should consist of simple words. First, we introduce a reliable evaluation approach for DDG, based on our new evaluation criteria and powered by an LLM-as-a-judge. To provide reference definitions for the evaluation, we also construct a Japanese dataset in collaboration with a professional lexicographer. Validation results demonstrate that our evaluation approach agrees reasonably well with human annotators. Second, we propose an LDDG approach via iterative simplification with an LLM. Experimental results indicate that definitions generated by our approach achieve high scores on our criteria while maintaining lexical simplicity.

</details>


### [227] [DermoGPT: Open Weights and Open Data for Morphology-Grounded Dermatological Reasoning MLLMs](https://arxiv.org/abs/2601.01868)
*Jinghan Ru,Siyuan Yan,Yuguo Yin,Yuexian Zou,Zongyuan Ge*

Main category: cs.CL

TL;DR: 本文提出了一个面向皮肤科的多模态大语言模型框架，包括大规模形态学标注指令数据集DermoInstruct、全面临床评估基准DermoBench，以及基于形态锚定强化学习（MAVIC）和测试时自适应（CCT）训练的模型DermoGPT，在多项临床任务上显著缩小了AI与人类专家之间的差距。


<details>
  <summary>Details</summary>
Motivation: 皮肤病学领域中多模态大语言模型发展受限于训练数据匮乏、任务覆盖窄、缺乏贴合临床诊断流程的专业监督信号。

Method: 构建了形态学锚定的大规模指令数据集DermoInstruct；设计涵盖四大临床维度的严格基准DermoBench；提出MAVIC强化学习目标以增强视觉观察与诊断结论的一致性，并在推理阶段引入CCT测试时自适应机制。

Result: DermoGPT在DermoBench全部11项任务、四大临床轴上均显著超越16个代表性基线模型，达到SOTA水平，大幅缩小人机性能差距。

Conclusion: 该工作系统性填补了皮肤科MLLM的关键空白，为临床导向的医学多模态建模提供了可复现、可扩展的新范式。

Abstract: Multimodal Large Language Models (MLLMs) show promise for medical applications, yet progress in dermatology lags due to limited training data, narrow task coverage, and lack of clinically-grounded supervision that mirrors expert diagnostic workflows. We present a comprehensive framework to address these gaps. First, we introduce DermoInstruct, a large-scale morphology-anchored instruction corpus comprising 211,243 images and 772,675 trajectories across five task formats, capturing the complete diagnostic pipeline from morphological observation and clinical reasoning to final diagnosis. Second, we establish DermoBench, a rigorous benchmark evaluating 11 tasks across four clinical axes: Morphology, Diagnosis, Reasoning, and Fairness, including a challenging subset of 3,600 expert-verified open-ended instances and human performance baselines. Third, we develop DermoGPT, a dermatology reasoning MLLM trained via supervised fine-tuning followed by our Morphologically-Anchored Visual-Inference-Consistent (MAVIC) reinforcement learning objective, which enforces consistency between visual observations and diagnostic conclusions. At inference, we deploy Confidence-Consistency Test-time adaptation (CCT) for robust predictions. Experiments show DermoGPT significantly outperforms 16 representative baselines across all axes, achieving state-of-the-art performance while substantially narrowing the human-AI gap. DermoInstruct, DermoBench and DermoGPT will be made publicly available at https://github.com/mendicant04/DermoGPT upon acceptance.

</details>


### [228] [Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents](https://arxiv.org/abs/2601.01885)
*Yi Yu,Liuyi Yao,Yuexiang Xie,Qingquan Tan,Jiaqi Feng,Yaliang Li,Libing Wu*

Main category: cs.CL

TL;DR: 本文提出Agentic Memory (AgeMem)，一种将长期记忆（LTM）和短期记忆（STM）统一集成到LLM代理策略中的框架，通过工具化记忆操作和三阶段渐进式强化学习训练，显著提升长程推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在长程推理中受限于上下文窗口，且传统记忆管理将LTM与STM割裂处理，依赖启发式或辅助控制器，难以端到端优化。

Method: 提出AgeMem统一框架，将记忆操作（存储、检索、更新、摘要、丢弃）建模为工具调用；设计三阶段渐进式强化学习策略及步进式GRPO算法以应对稀疏不连续奖励。

Result: 在五个长程基准上，AgeMem在多个LLM主干模型上均超越强记忆增强基线，提升任务性能、长期记忆质量与上下文利用效率。

Conclusion: 统一建模记忆操作并端到端优化是提升LLM代理长程推理能力的有效路径，AgeMem为智能体记忆机制提供了新范式。

Abstract: Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization. In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy. AgeMem exposes memory operations as tool-based actions, enabling the LLM agent to autonomously decide what and when to store, retrieve, update, summarize, or discard information. To train such unified behaviors, we propose a three-stage progressive reinforcement learning strategy and design a step-wise GRPO to address sparse and discontinuous rewards induced by memory operations. Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.

</details>


### [229] [Tackling the Inherent Difficulty of Noise Filtering in RAG](https://arxiv.org/abs/2601.01896)
*Jingyu Liu,Jiaen Lin,Yong Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新的微调方法，以增强大语言模型在检索增强生成（RAG）中区分相关与无关信息的能力，从而提升其对检索噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法中检索到的文档常含噪声或无关内容，而传统过滤方法和标准微调难以让模型有效识别并忽略无关信息，导致性能下降甚至幻觉。

Method: 提出一种新型微调方法，专门增强LLM在面对检索文档时选择性利用相关信息、抑制无关内容的能力，突破注意力机制的结构限制。

Result: 在多个基准测试上的大量实验表明，该方法显著提升了LLM在RAG场景下的鲁棒性和整体性能。

Conclusion: 标准微调不足以解决RAG中的噪声干扰问题；所提微调方法能有效提升模型对检索噪声的鲁棒性，是改进RAG系统的重要方向。

Abstract: Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.

</details>


### [230] [CSF: Contrastive Semantic Features for Direct Multilingual Sign Language Generation](https://arxiv.org/abs/2601.01964)
*Tran Sy Bao*

Main category: cs.CL

TL;DR: 本文提出了一种名为Canonical Semantic Form（CSF）的语言无关语义表示框架，用于实现从任意源语言到手语的直接翻译，无需英语作为中介。CSF将话语分解为九个通用语义槽，并构建了包含35种条件类型的详尽条件分类体系。作者训练了一个轻量级Transformer抽取器，在四种语言上平均槽位提取准确率达99.03%，条件分类达99.4%，CPU推理延迟仅3.02ms，支持浏览器端实时手语生成。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译系统通常依赖英语作为中介语言，对全球非英语聋人群体构成障碍，亟需一种语言无关的语义表示方法以支持多语言直接翻译。

Method: 提出CSF框架，定义九个通用语义槽；构建涵盖八大语义类别的35类条件类型学；设计并训练轻量级Transformer抽取模型（0.74MB），在英语、越南语、日语和法语四语数据上进行多语言联合训练与评估。

Result: 模型在四语言上平均槽位提取准确率达99.03%，其中条件分类准确率高达99.4%；CPU推理延迟仅3.02ms；开源代码、模型及多语言数据集。

Conclusion: CSF是一种高效、可扩展、语言无关的语义表示框架，显著提升了多语言手语翻译系统的可访问性与实时性，为无障碍手语技术提供了新范式。

Abstract: Sign language translation systems typically require English as an intermediary language, creating barriers for non-English speakers in the global deaf community. We present Canonical Semantic Form (CSF), a language-agnostic semantic representation framework that enables direct translation from any source language to sign language without English mediation. CSF decomposes utterances into nine universal semantic slots: event, intent, time, condition, agent, object, location, purpose, and modifier. A key contribution is our comprehensive condition taxonomy comprising 35 condition types across eight semantic categories, enabling nuanced representation of conditional expressions common in everyday communication. We train a lightweight transformer-based extractor (0.74 MB) that achieves 99.03% average slot extraction accuracy across four typologically diverse languages: English, Vietnamese, Japanese, and French. The model demonstrates particularly strong performance on condition classification (99.4% accuracy) despite the 35-class complexity. With inference latency of 3.02ms on CPU, our approach enables real-time sign language generation in browser-based applications. We release our code, trained models, and multilingual dataset to support further research in accessible sign language technology.

</details>


### [231] [Hidden State Poisoning Attacks against Mamba-based Language Models](https://arxiv.org/abs/2601.01972)
*Alexandre Le Mercier,Chris Develder,Thomas Demeester*

Main category: cs.CL

TL;DR: 本文提出了一种针对状态空间模型（如Mamba）的新型攻击——隐藏状态投毒攻击（HiSPA），揭示其在特定短语触发下出现‘部分失忆’现象，并构建基准RoBench25验证SSMs的脆弱性；实验表明混合SSM-Transformer模型（如Jamba）易受攻击，而纯Transformer则鲁棒；研究还发现可解释性线索，为防御提供基础。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型（SSMs）虽具高效性，但其对抗鲁棒性尚未被系统研究；作者关注其隐藏状态是否可能被恶意输入不可逆地破坏，导致信息丢失。

Method: 提出隐藏状态投毒攻击（HiSPA），设计基准RoBench25评估模型在HiSPA下的信息检索能力，并在Open-Prompt-Injections上测试泛化脆弱性；开展隐藏层可解释性分析以识别攻击模式。

Result: SSMs（包括52B Jamba模型）在RoBench25和Open-Prompt-Injections上显著退化，而纯Transformer保持稳定；HiSPA在Mamba隐藏层中呈现可识别的异常激活模式。

Conclusion: SSMs存在本质性的隐藏状态脆弱性，HiSPA构成真实威胁；该问题在混合架构中依然存在；所发现的模式为构建检测/缓解机制提供了可行路径。

Abstract: State space models (SSMs) like Mamba offer efficient alternatives to Transformer-based language models, with linear time complexity. Yet, their adversarial robustness remains critically unexplored. This paper studies the phenomenon whereby specific short input phrases induce a partial amnesia effect in such models, by irreversibly overwriting information in their hidden states, referred to as a Hidden State Poisoning Attack (HiSPA). Our benchmark RoBench25 allows evaluating a model's information retrieval capabilities when subject to HiSPAs, and confirms the vulnerability of SSMs against such attacks. Even a recent 52B hybrid SSM-Transformer model from the Jamba family collapses on RoBench25 under optimized HiSPA triggers, whereas pure Transformers do not. We also observe that HiSPA triggers significantly weaken the Jamba model on the popular Open-Prompt-Injections benchmark, unlike pure Transformers. Finally, our interpretability study reveals patterns in Mamba's hidden layers during HiSPAs that could be used to build a HiSPA mitigation system. The full code and data to reproduce the experiments can be found at https://anonymous.4open.science/r/hispa_anonymous-5DB0.

</details>


### [232] [Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects](https://arxiv.org/abs/2601.02015)
*Omar Momen,Emilie Sitter,Berenike Herrmann,Sina Zarrieß*

Main category: cs.CL

TL;DR: 本研究探讨了语言模型（LMs）中的惊奇度（surprisal）是否与隐喻新颖性相关，发现其在不同数据集上呈现相反的规模效应：在基于语料库的数据上相关性随模型增大而减弱（逆向缩放），而在合成数据上则增强（质量-能力假说），表明惊奇度对语言创造力的刻画仍有限。


<details>
  <summary>Details</summary>
Motivation: 隐喻理解涉及复杂的语义加工和语言创造力，是检验语言模型能力的理想任务；惊奇度作为衡量预测性的概率指标，其与隐喻新颖性的关系尚不明确。

Method: 在16种语言模型变体上，计算基于全句上下文的填空式惊奇度，并在基于语料库和合成构建的两类隐喻新颖性数据集上分析其与人工标注的相关性。

Result: 惊奇度与隐喻新颖性标注呈显著中等程度相关；但在两类数据集上呈现分化趋势：语料库数据中相关性随模型增大而下降，合成数据中则上升。

Conclusion: 惊奇度可在一定程度上解释隐喻新颖性标注，但作为语言创造力的度量仍具局限性。

Abstract: Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.

</details>


### [233] [Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs](https://arxiv.org/abs/2601.02023)
*Amirali Ebrahimzadeh,Seyyed M. Salili*

Main category: cs.CL

TL;DR: 本文研究了大语言模型在长上下文中的信息提取与推理能力，发现单纯增加上下文长度并不提升性能，反而可能因证据稀释而损害效果；不同模型表现差异显著，反幻觉提示可能导致过度保守；核心问题在于模型未能有效利用上下文中的相关信息。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽支持超长上下文，但其在大规模下信息提取与推理的可靠性尚不明确，且性能受上下文长度、事实分布方式及提示设计影响显著。

Method: 构建扩展版‘海中寻针’基准测试，涵盖四个主流大模型（Gemini-2.5-flash、ChatGPT-5-mini、Claude-4.5-haiku、Deepseek-v3.2-chat），分别评估字面提取、逻辑推理与幻觉风险，并考察事实位置、语料级事实分布及‘勿虚构’提示的影响。

Result: 长上下文未必提升性能，证据分散时性能下降；模型间鲁棒性差异大；反幻觉提示会降低部分模型的提取与推理准确率；模型普遍存在上下文利用低效问题。

Conclusion: 实际部署中需关注模型的有效上下文长度与长上下文鲁棒性，仅靠堆砌大量未过滤文档不可靠，优化上下文利用机制（如RAG/CAG）至关重要。

Abstract: Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.

</details>


### [234] [Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory](https://arxiv.org/abs/2601.02065)
*Md. Asif Hossain,Nabil Subhan,Mantasha Rahman Mahi,Jannatul Ferdous Nabila*

Main category: cs.CL

TL;DR: 本文提出了一种低成本、跨语言的检索增强生成（RAG）框架，用于为孟加拉语农民提供基于权威英文农业手册的事实可靠建议，通过翻译+关键词增强+英文检索+回译实现，全程使用开源模型并在消费级硬件上运行。


<details>
  <summary>Details</summary>
Motivation: 发展中国家农民受限于语言障碍，难以获取以英语撰写的权威农业手册；直接用低资源语言（如孟加拉语）调用大模型易导致不流利和事实错误，而云端方案成本过高。

Method: 采用翻译中心架构：将孟加拉语查询译为英文→注入农业领域关键词以对齐口语与科技术语→在英文农业手册（FAO、IRRI）语料库上进行稠密向量检索→生成英文响应→回译为孟加拉语；全系统基于开源模型，部署于消费级硬件。

Result: 实验表明系统响应事实依据强、能稳健拒答域外问题、端到端平均延迟低于20秒。

Conclusion: 跨语言检索结合受控翻译是一种实用、可扩展的低资源语言农业知识获取解决方案。

Abstract: Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings

</details>


### [235] [Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows](https://arxiv.org/abs/2601.02076)
*Yingte Shu,Yuchuan Tian,Chao Xu,Yunhe Wang,Hanting Chen*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的解码策略Deferred Commitment Decoding (DCD)，用于缓解扩散语言模型中块式解码引发的边界诱导上下文截断（BICT）问题，通过置信度感知的滑动窗口延迟高不确定性token的提交，从而提升生成质量与效率。


<details>
  <summary>Details</summary>
Motivation: 块式扩散解码存在边界诱导上下文截断（BICT）问题：块边界附近的未解码token被迫提前确定，缺乏未来上下文支持，损害解码置信度与生成质量，尤其影响数学推理和代码生成等任务。

Method: 提出Deferred Commitment Decoding（DCD），一种训练无关的解码策略：在掩码token上维护一个置信度感知的滑动窗口，早期解析低不确定性token，延迟高不确定性token直至获得足够上下文证据，实现窗口内双向信息流动。

Result: 在多个扩散语言模型、基准测试和缓存配置上的实验表明，DCD平均提升生成准确率1.39%，最高达9.0%，同时保持相近推理耗时。

Conclusion: 基于不确定性延迟token提交是一种简单而有效的方法，可同时提升扩散语言模型解码的质量与效率。

Abstract: Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.

</details>


### [236] [DeCode: Decoupling Content and Delivery for Medical QA](https://arxiv.org/abs/2601.02123)
*Po-Jen Ko,Chen-Han Tsai,Yu-Shao Peng*

Main category: cs.CL

TL;DR: DeCode是一种无需训练、模型无关的框架，用于提升大语言模型在临床场景中生成符合个体患者背景的答案的能力，在OpenAI HealthBench上将SOTA性能从28.4%提升至49.8%。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽具备较强医学知识，但常忽略个体患者背景，导致回答虽临床正确却缺乏个体化适配。

Method: 提出DeCode框架，不依赖额外训练，可适配任意现有大语言模型，使其在临床问答中生成更符合患者上下文的答案。

Result: 在OpenAI HealthBench基准上，DeCode将准确率从28.4%提升至49.8%，实现75%的相对提升。

Conclusion: DeCode能显著提升大语言模型在临床问答中的情境化能力，且无需模型微调，具有通用性和实用性。

Abstract: Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\%$ to $49.8\%$, corresponding to a $75\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.

</details>


### [237] [Towards Multi-Level Transcript Segmentation: LoRA Fine-Tuning for Table-of-Contents Generation](https://arxiv.org/abs/2601.02128)
*Steffen Freisinger,Philipp Seeberger,Thomas Ranzenberger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 本文提出了一种用于语音转录文本的分层主题分割新方法，生成多级目录以捕捉主题与子主题边界，并通过零样本提示与LoRA微调大语言模型，结合语音停顿特征，在多语种数据上显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 语音转录文本的主题分割有助于下游处理及依赖文字获取信息的用户（如无障碍访问需求者）。

Method: 提出分层主题分割方法，生成多级目录；对比零样本提示与LoRA微调大语言模型的效果；融合高层语音停顿特征；改进多级分割评估指标。

Result: 在英文会议录音和多语种（葡萄牙语、德语）讲座转录数据上，性能显著优于现有主题分割基线；提出了适配多级分割的统一评估指标。

Conclusion: 所提方法有效提升了语音转录文本的分层主题分割性能，尤其在多语种场景下具备泛化能力，且融合语音特征与大模型微调策略具有实用价值。

Abstract: Segmenting speech transcripts into thematic sections benefits both downstream processing and users who depend on written text for accessibility. We introduce a novel approach to hierarchical topic segmentation in transcripts, generating multi-level tables of contents that capture both topic and subtopic boundaries. We compare zero-shot prompting and LoRA fine-tuning on large language models, while also exploring the integration of high-level speech pause features. Evaluations on English meeting recordings and multilingual lecture transcripts (Portuguese, German) show significant improvements over established topic segmentation baselines. Additionally, we adapt a common evaluation measure for multi-level segmentation, taking into account all hierarchical levels within one metric.

</details>


### [238] [Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts](https://arxiv.org/abs/2601.02144)
*Boxuan Lyu,Soichiro Murakami,Hidetaka Kamigaito,Peinan Zhang*

Main category: cs.CL

TL;DR: 本文提出kNN-MoE，一种检索增强的MoE路由框架，通过记忆中相似历史案例重用最优专家分配，并利用检索邻居的聚合相似度作为置信驱动的混合系数，提升MoE在分布偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统MoE的路由模块通常训练后冻结，导致在数据分布偏移时路由决策僵化、鲁棒性差。

Method: 提出kNN-MoE：离线构建一个记忆库，其中存储经优化的token级路由logits；在线推理时，基于检索相似历史案例，用其邻居的聚合相似度作为动态混合系数，加权融合检索路由与原始冻结路由器输出。

Result: 实验表明kNN-MoE优于零样本基线，并可媲美计算开销更高的监督微调方法。

Conclusion: kNN-MoE通过引入检索增强与置信感知混合机制，有效提升了MoE模型在分布变化场景下的适应性与泛化能力，无需重新训练路由模块。

Abstract: Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric "router" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.

</details>


### [239] [FormationEval, an open multiple-choice benchmark for petroleum geoscience](https://arxiv.org/abs/2601.02158)
*Almaz Ermilov*

Main category: cs.CL

TL;DR: FormationEval is an open multiple-choice benchmark for evaluating LMs in petroleum geoscience, comprising 505 questions across seven domains; it reveals strong performance (up to 99.8% by Gemini 3 Pro), narrowing gaps between open and closed models, with petrophysics as the hardest domain and documented length bias.


<details>
  <summary>Details</summary>
Motivation: To address the lack of domain-specific, traceable, and ethically constructed evaluation benchmarks for language models in petroleum geoscience and subsurface disciplines.

Method: Constructed FormationEval using a reasoning-based, concept-driven approach from three authoritative sources—avoiding verbatim copying—annotated with source metadata; evaluated 72 models (closed and open-weight) across domains and analyzed performance gaps, biases (e.g., residual length bias), and mitigation strategies.

Result: Top model (Gemini 3 Pro Preview) achieves 99.8% accuracy; GLM-4.7 leads among open-weight models at 98.6%; several open models exceed 93%, and some lower-cost ones surpass 90%; petrophysics is consistently hardest; smaller models show higher variance; length bias was identified and mitigated.

Conclusion: FormationEval establishes a rigorous, transparent, and publicly available benchmark that reveals surprisingly competitive performance of open-weight models in petroleum geoscience, while highlighting persistent domain- and tier-specific gaps and dataset biases requiring attention.

Abstract: This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\% accuracy, with Gemini 3 Pro Preview reaching 99.8\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.

</details>


### [240] [Confidence Estimation for LLMs in Multi-turn Interactions](https://arxiv.org/abs/2601.02179)
*Caiqi Zhang,Ruihan Yang,Xiaochen Zhu,Chengzu Li,Tiancheng Hu,Yijiang River Dong,Deqing Yang,Nigel Collier*

Main category: cs.CL

TL;DR: 本文首次系统研究了多轮对话中大语言模型的置信度估计问题，提出了新的评估框架（包括每轮校准和置信度单调性）与指标（如InfoECE），并设计了'Hinter-Guesser'数据生成范式；实验表明现有方法在校准与单调性上表现不佳，提出的新探针P(Sufficient)有所改进，但问题仍未根本解决。


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计研究主要集中在单轮场景，而多轮对话中上下文累积与歧义逐步消解带来的置信度动态变化未被充分探索，但其对自主代理和人机协同等下游应用至关重要。

Method: 构建基于每轮校准与置信度单调性两大核心需求的正式评估框架；提出长度归一化的期望校准误差（InfoECE）等新指标；设计'Hinter-Guesser'范式生成可控评估数据集；提出基于logit的P(Sufficient)探针方法。

Result: 实验发现主流置信度技术在多轮对话中普遍缺乏校准性和单调性；P(Sufficient)在两项指标上表现相对更优，但仍存在显著提升空间。

Conclusion: 本工作为多轮对话中的置信度估计建立了首个系统性研究基础与方法论，推动构建更可靠、可信的对话智能体。

Abstract: While confidence estimation is a promising direction for mitigating hallucinations in Large Language Models (LLMs), current research dominantly focuses on single-turn settings. The dynamics of model confidence in multi-turn conversations, where context accumulates and ambiguity is progressively resolved, remain largely unexplored. Reliable confidence estimation in multi-turn settings is critical for many downstream applications, such as autonomous agents and human-in-the-loop systems. This work presents the first systematic study of confidence estimation in multi-turn interactions, establishing a formal evaluation framework grounded in two key desiderata: per-turn calibration and monotonicity of confidence as more information becomes available. To facilitate this, we introduce novel metrics, including a length-normalized Expected Calibration Error (InfoECE), and a new "Hinter-Guesser" paradigm for generating controlled evaluation datasets. Our experiments reveal that widely-used confidence techniques struggle with calibration and monotonicity in multi-turn dialogues. We propose P(Sufficient), a logit-based probe that achieves comparatively better performance, although the task remains far from solved. Our work provides a foundational methodology for developing more reliable and trustworthy conversational agents.

</details>


### [241] [Toward Global Large Language Models in Medicine](https://arxiv.org/abs/2601.02186)
*Rui Yang,Huitao Li,Weihao Xuan,Heli Qi,Xin Li,Kunyu Yu,Yingjian Chen,Rongrong Wang,Jacques Behmoaras,Tianxi Cai,Bibhas Chakraborty,Qingyu Chen,Lionel Tim-Ee Cheng,Marie-Louise Damwanza,Chido Dzinotyiwei,Aosong Feng,Chuan Hong,Yusuke Iwasawa,Yuhe Ke,Linah Kitala,Taehoon Ko,Jisan Lee,Irene Li,Jonathan Chong Kai Liew,Hongfang Liu,Lian Leng Low,Edison Marrese-Taylor,Yutaka Matsuo,Isheanesu Misi,Yilin Ning,Jasmine Chiat Ling Ong,Marcus Eng Hock Ong,Enrico Petretto,Hossein Rouhizadeh,Abiram Sandralegar,Oren Schreier,Iain Bee Huat Tan,Patrick Tan,Daniel Shu Wei Ting,Junjue Wang,Chunhua Weng,Matthew Yu Heng Wong,Fang Wu,Yunze Xiao,Xuhai Xu,Qingcheng Zeng,Zhuo Zheng,Yifan Peng,Douglas Teodoro,Nan Liu*

Main category: cs.CL

TL;DR: 本文提出了GlobMed，一个包含12种语言（含4种低资源语言）的大型多语言医学数据集，并基于其构建了评估基准GlobMed-Bench和一系列多语言医学大模型GlobMed-LLMs，在低资源语言上性能提升显著，旨在促进大语言模型在全球医疗领域的公平应用。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型主要在高资源语言上训练，难以适用于全球多样化的医疗场景，尤其在低资源语言地区存在明显应用局限。

Method: 构建了包含50万以上样本、覆盖12种语言（含4种低资源语言）的多语言医学数据集GlobMed；设计了多任务评估基准GlobMed-Bench，系统评测56个主流大模型；训练了参数量为1.7B至8B的多语言医学大模型GlobMed-LLMs。

Result: GlobMed-LLMs相较基线模型平均性能提升超40%，在低资源语言上性能提升超三倍；GlobMed-Bench揭示了现有模型在不同语言间存在显著性能差距。

Conclusion: GlobMed系列资源为推动大语言模型在全球范围内、尤其是低资源语言地区的公平发展与落地应用提供了重要基础支撑。

Abstract: Despite continuous advances in medical technology, the global distribution of health care resources remains uneven. The development of large language models (LLMs) has transformed the landscape of medicine and holds promise for improving health care quality and expanding access to medical information globally. However, existing LLMs are primarily trained on high-resource languages, limiting their applicability in global medical scenarios. To address this gap, we constructed GlobMed, a large multilingual medical dataset, containing over 500,000 entries spanning 12 languages, including four low-resource languages. Building on this, we established GlobMed-Bench, which systematically assesses 56 state-of-the-art proprietary and open-weight LLMs across multiple multilingual medical tasks, revealing significant performance disparities across languages, particularly for low-resource languages. Additionally, we introduced GlobMed-LLMs, a suite of multilingual medical LLMs trained on GlobMed, with parameters ranging from 1.7B to 8B. GlobMed-LLMs achieved an average performance improvement of over 40% relative to baseline models, with a more than threefold increase in performance on low-resource languages. Together, these resources provide an important foundation for advancing the equitable development and application of LLMs globally, enabling broader language communities to benefit from technological advances.

</details>


### [242] [ARCADE: A City-Scale Corpus for Fine-Grained Arabic Dialect Tagging](https://arxiv.org/abs/2601.02209)
*Omer Nacar,Serry Sibaee,Adel Ammar,Yasser Alhabashi,Nadia Samer Sibai,Yara Farouk Ahmed,Ahmed Saud Alqusaiyer,Sulieman Mahmoud AlMahmoud,Abdulrhman Mamdoh Mukhaniq,Lubaba Raed,Sulaiman Mohammed Alatwah,Waad Nasser Alqahtani,Yousif Abdulmajeed Alnasser,Mohamed Aziz Khadraoui,Wadii Boulila*

Main category: cs.CL

TL;DR: 本文介绍了ARCADE，首个专为城市级阿拉伯语方言识别设计的语音数据集，包含来自19个国家58个城市的3790个音频片段和6907条标注，支持多任务学习和方言细粒度分类。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语多方言数据集缺乏城市级别的细粒度方言标注，难以支持高精度的方言识别任务。

Method: 构建了ARCADE数据集，通过采集阿拉伯世界各广播流的30秒语音片段，涵盖现代标准阿拉伯语（MSA）及多方言变体，并由母语者进行情绪、语种、方言类别及有效性等多维度人工标注。

Result: 获得覆盖19国58城的3790个唯一音频段和6907条高质量标注，支持城市级方言识别与多任务学习。

Conclusion: ARCADE填补了阿拉伯语城市级方言语音数据集的空白，为细粒度方言识别提供了可靠基准和公开资源。

Abstract: The Arabic language is characterized by a rich tapestry of regional dialects that differ substantially in phonetics and lexicon, reflecting the geographic and cultural diversity of its speakers. Despite the availability of many multi-dialect datasets, mapping speech to fine-grained dialect sources, such as cities, remains underexplored. We present ARCADE (Arabic Radio Corpus for Audio Dialect Evaluation), the first Arabic speech dataset designed explicitly with city-level dialect granularity. The corpus comprises Arabic radio speech collected from streaming services across the Arab world. Our data pipeline captures 30-second segments from verified radio streams, encompassing both Modern Standard Arabic (MSA) and diverse dialectal speech. To ensure reliability, each clip was annotated by one to three native Arabic reviewers who assigned rich metadata, including emotion, speech type, dialect category, and a validity flag for dialect identification tasks. The resulting corpus comprises 6,907 annotations and 3,790 unique audio segments spanning 58 cities across 19 countries. These fine-grained annotations enable robust multi-task learning, serving as a benchmark for city-level dialect tagging. We detail the data collection methodology, assess audio quality, and provide a comprehensive analysis of label distributions. The dataset is available on: https://huggingface.co/datasets/riotu-lab/ARCADE-full

</details>


### [243] [From XAI to Stories: A Factorial Study of LLM-Generated Explanation Quality](https://arxiv.org/abs/2601.02224)
*Fabian Lukassen,Jan Herrmann,Christoph Weisser,Benjamin Saefken,Thomas Kneib*

Main category: cs.CL

TL;DR: 本文通过系统性因子实验，探究了影响时间序列预测中自然语言解释（NLE）质量的关键因素，发现LLM选择起主导作用，XAI贡献有限且仅对专家有效，SARIMAX虽更准确却生成更差NLE，零样本提示在低成本下表现优异，而思维链反而降低效果。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法（如SHAP、LIME）生成的数值归因对非专家用户不友好，虽有研究用LLM将其转为自然语言解释（NLE），但影响NLE质量的关键因素尚不明确。

Method: 开展四因素（预测模型、XAI方法、LLM、提示策略）全因子实验，覆盖4类模型、3种XAI条件、3个LLM和8种提示策略；采用G-Eval（双LLM裁判+四项指标）评估660条NLE。

Result: （1）XAI仅对专家小幅提升NLE质量；（2）LLM选择影响最大，DeepSeek-R1最优；（3）出现可解释性悖论：高精度SARIMAX生成NLE质量反低于ML模型；（4）零样本提示性价比显著优于自一致性；（5）思维链提示降低NLE质量。

Conclusion: LLM本身能力远超XAI输入质量的影响，提示工程需谨慎设计；面向非专家的可解释性不应依赖传统XAI流程，而应聚焦LLM选型与高效提示策略。

Abstract: Explainable AI (XAI) methods like SHAP and LIME produce numerical feature attributions that remain inaccessible to non expert users. Prior work has shown that Large Language Models (LLMs) can transform these outputs into natural language explanations (NLEs), but it remains unclear which factors contribute to high-quality explanations. We present a systematic factorial study investigating how Forecasting model choice, XAI method, LLM selection, and prompting strategy affect NLE quality. Our design spans four models (XGBoost (XGB), Random Forest (RF), Multilayer Perceptron (MLP), and SARIMAX - comparing black-box Machine-Learning (ML) against classical time-series approaches), three XAI conditions (SHAP, LIME, and a no-XAI baseline), three LLMs (GPT-4o, Llama-3-8B, DeepSeek-R1), and eight prompting strategies. Using G-Eval, an LLM-as-a-judge evaluation method, with dual LLM judges and four evaluation criteria, we evaluate 660 explanations for time-series forecasting. Our results suggest that: (1) XAI provides only small improvements over no-XAI baselines, and only for expert audiences; (2) LLM choice dominates all other factors, with DeepSeek-R1 outperforming GPT-4o and Llama-3; (3) we observe an interpretability paradox: in our setting, SARIMAX yielded lower NLE quality than ML models despite higher prediction accuracy; (4) zero-shot prompting is competitive with self-consistency at 7-times lower cost; and (5) chain-of-thought hurts rather than helps.

</details>


### [244] [CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://arxiv.org/abs/2601.02236)
*Yihao Liang,Ze Wang,Hao Chen,Ximeng Sun,Jialian Wu,Xiaodong Yu,Jiang Liu,Emad Barsoum,Zicheng Liu,Niraj K. Jha*

Main category: cs.CL

TL;DR: 本文提出CD4LM框架，通过离散空间一致性蒸馏（DSCD）和置信度自适应解码（CAD），解决扩散语言模型（DLMs）在并行生成中静态训练与动态推理不匹配的问题，在保持生成质量的同时显著提升解码速度。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型（DLMs）虽支持并行生成，但其固定调度的训练方式与高效推理所需的自适应‘长跳’精炼之间存在根本性静态-动态错配，导致解码效率受限。

Method: 提出CD4LM框架，包含两个核心组件：1）离散空间一致性蒸馏（DSCD），使学生模型对噪声状态轨迹不变，直接映射到干净分布；2）置信度自适应解码（CAD），依据token置信度动态分配计算资源、跳过步骤。

Result: 在GSM8K上以5.18倍实测加速匹敌LLaDA基线；在代码与数学基准上平均提速3.62倍且平均准确率提升，严格主导精度-效率Pareto前沿。

Conclusion: CD4LM成功解耦DLM的训练与推理，通过DSCD增强鲁棒性、CAD实现智能步数跳过，实现了高质量、高并行、低函数调用次数的语言生成。

Abstract: Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic misalignment: Training optimizes local transitions under fixed schedules, whereas efficient inference requires adaptive "long-jump" refinements through unseen states. Our goal is to enable highly parallel decoding for DLMs with low number of function evaluations while preserving generation quality. To achieve this, we propose CD4LM, a framework that decouples training from inference via Discrete-Space Consistency Distillation (DSCD) and Confidence-Adaptive Decoding (CAD). Unlike standard objectives, DSCD trains a student to be trajectory-invariant, mapping diverse noisy states directly to the clean distribution. This intrinsic robustness enables CAD to dynamically allocate compute resources based on token confidence, aggressively skipping steps without the quality collapse typical of heuristic acceleration. On GSM8K, CD4LM matches the LLaDA baseline with a 5.18x wall-clock speedup; across code and math benchmarks, it strictly dominates the accuracy-efficiency Pareto frontier, achieving a 3.62x mean speedup while improving average accuracy. Code is available at https://github.com/yihao-liang/CDLM

</details>


### [245] [pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs](https://arxiv.org/abs/2601.02285)
*Tobias Schimanski,Imene Kolli,Jingwei Ni,Yu Fan,Ario Saeid Vaghefi,Elliott Ash,Markus Leippold*

Main category: cs.CL

TL;DR: 本文提出了pdfQA数据集，包含2K人工标注和2K合成的多领域PDF问答对，涵盖十个复杂度维度，并通过质量与难度筛选，评估了开源大语言模型在PDF问答任务中的表现与挑战。


<details>
  <summary>Details</summary>
Motivation: PDF是互联网上使用量第二大的文档格式，但现有问答数据集多基于纯文本或局限于特定领域，缺乏针对PDF文档的通用、多领域问答基准。

Method: 构建了pdfQA数据集，包括2K人工标注（real-pdfQA）和2K合成（syn-pdfQA）问答对，覆盖十个复杂度维度（如文件类型、源模态、源位置、答案类型等）；应用质量与难度过滤器筛选有效且具挑战性的问答对；使用开源大语言模型进行问答实验并分析性能与复杂度维度的相关性。

Result: 揭示了当前开源LLM在PDF问答任务中存在的显著挑战，且这些挑战与所定义的十个复杂度维度存在可衡量的相关性；pdfQA为端到端PDF问答流水线评估提供了新基准。

Conclusion: pdfQA填补了PDF文档多领域问答基准的空白，支持对信息检索、文档解析等局部模块及整体问答能力的系统性评估，推动面向真实PDF场景的QA技术发展。

Abstract: PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).

</details>


### [246] [Power-of-Two Quantization-Aware-Training (PoT-QAT) in Large Language Models (LLMs)](https://arxiv.org/abs/2601.02298)
*Mahmoud Elgenedy*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型（LLMs）在边缘设备上部署的轻量化方法，采用仅幂次二（PoT）量化压缩权重，并结合量化感知训练（QAT）来缓解性能损失，在GPT-2 124M上实现了显著的内存节省（87.5%）、推理加速（3–10×）和性能恢复（困惑度提升66%，BERT-Score仅下降1%）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型参数量激增，难以部署到资源受限的边缘设备；需兼顾内存占用与计算效率。

Method: 采用仅幂次二（Power-of-Two, PoT）量化压缩模型权重（仅存指数），用位移替代乘法以降低计算开销，并结合量化感知训练（QAT）提升量化后模型性能。

Result: 在GPT-2 124M上，PoT量化+QAT使困惑度提升66%，BERT-Score相对基线仅下降1%；内存节省87.5%，推理速度提升3–10倍。

Conclusion: PoT量化结合QAT是一种高效可行的边缘端LLM部署方案，在大幅压缩模型的同时保持了接近全精度的生成质量与显著加速。

Abstract: In Large Language Models (LLMs), the number of parameters has grown exponentially in the past few years, e.g., from 1.5 billion parameters in GPT-2 to 175 billion in GPT-3 to possibly more than trillion in higher versions. This raises a significant challenge for implementation, especially for Edge devices. Unlike cloud computing, memory and processing power for Edge devices are very limited, which necessitates developing novel ideas to make such applications feasible. In this work, we investigate compressing weights with a special quantization that limits numbers to only power-of-two (PoT). This helps save a huge amount of memory as only exponents need to be stored, more importantly, it significantly reduces processing power by replacing costly multiplication with low cost bit shifting. To overcome performance loss due to this strict quantization, we investigate Quantization Aware Training (QAT) to enhance performance through additional training. Results on GPT-2 124M show a major enhancement for quantized PoT model after additional training, with a perplexity enhancement of 66% and BERT-Score loss to baseline GPT-2 of 1%. The memory saving is estimated to be 87.5% while the inference speed is expected to be 3-10x faster with PoT quantization versus full-precision.

</details>


### [247] [Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Carlos-Emiliano González-Gallardo,Graham Ranger,Martha Lorena-Avendaño-Garrido*

Main category: cs.CL

TL;DR: This paper addresses the classification of Nawatl dialectal varieties using Machine Learning and Neural Networks, aiming to overcome the scarcity of computational resources for this indigenous language.


<details>
  <summary>Details</summary>
Motivation: Nawatl, a culturally rich indigenous language with around 30 dialectal varieties and limited computer resources, lacks tools for dialect classification, especially given orthographic variations.

Method: Machine Learning and Neural Networks are applied to classify Nawatl dialectal varieties.

Result: The paper presents an approach to automatically classify Nawatl varieties, though specific performance metrics or outcomes are not detailed in the abstract.

Conclusion: The study demonstrates the feasibility of applying ML and neural networks to dialect classification for under-resourced indigenous languages like Nawatl.

Abstract: Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.

</details>


### [248] [Estimating Text Temperature](https://arxiv.org/abs/2601.02320)
*Nikolay Mikhaylovskiy*

Main category: cs.CL

TL;DR: 本文提出了一种基于最大似然估计的方法，用于反推任意文本（包括人类撰写文本）相对于给定语言模型的生成温度，并在多种小到中等规模语言模型上评估该方法，最终用表现最佳的Qwen3-14B模型估算了多个主流语料库的温度值。


<details>
  <summary>Details</summary>
Motivation: 温度参数是控制自回归语言模型生成文本随机性的关键因素，但目前缺乏对已有文本（尤其是人类文本）所对应温度的有效估计方法。

Method: 采用最大似然估计方法，根据给定语言模型对文本的逐词概率，反推最可能的温度参数；在多个小至中等规模语言模型上进行温度估计能力评测，并选用最优模型（Qwen3-14B）对多个公开语料库进行温度估计。

Result: 验证了不同规模语言模型具备一定温度估计能力，其中Qwen3-14B表现最优；成功估计了多个流行语料库（如Wikipedia、Books、C4等）的平均温度值，揭示其与模型训练数据温度的差异。

Conclusion: 温度可作为刻画文本风格和生成机制的可量化指标，该方法为分析人类文本与模型生成文本的统计特性差异提供了新工具。

Abstract: Autoregressive language models typically use temperature parameter at inference to shape the probability distribution and control the randomness of the text generated. After the text was generated, this parameter can be estimated using maximum likelihood approach. Following it, we propose a procedure to estimate the temperature of any text, including ones written by humans, with respect to a given language model. We evaluate the temperature estimation capability of a wide selection of small-to-medium LLMs. We then use the best-performing Qwen3 14B to estimate temperatures of popular corpora.

</details>


### [249] [Robust Persona-Aware Toxicity Detection with Prompt Optimization and Learned Ensembling](https://arxiv.org/abs/2601.02337)
*Berk Atil,Rebecca J. Passonneau,Ninareh Mehrabi*

Main category: cs.CL

TL;DR: 本文系统评估了基于角色（persona）的毒性检测方法，发现没有单一提示方法在所有模型-角色对上都占优；提出了一种轻量级SVM元集成方法，利用四种提示变体的互补错误，在多种角色下均优于单个提示和多数投票。


<details>
  <summary>Details</summary>
Motivation: 毒性检测具有主观性，受不同人群视角和社会先验影响，需采用多元（pluralistic）建模；但现有LLM提示技术在不同角色和基础模型上表现不一致。

Method: 系统评估多种角色感知的提示方法；提出自动化提示优化策略；构建基于四种提示预测的4比特向量，并在其上训练轻量级SVM元集成器。

Result: SVM元集成在各类角色下持续优于单个提示方法和传统多数投票，取得最佳整体性能。

Conclusion: 本文首次系统比较了角色条件化提示在毒性检测中的效果，为处理主观NLP任务提供了鲁棒的多元评估方法。

Abstract: Toxicity detection is inherently subjective, shaped by the diverse perspectives and social priors of different demographic groups. While ``pluralistic'' modeling as used in economics and the social sciences aims to capture perspective differences across contexts, current Large Language Model (LLM) prompting techniques have different results across different personas and base models. In this work, we conduct a systematic evaluation of persona-aware toxicity detection, showing that no single prompting method, including our proposed automated prompt optimization strategy, uniformly dominates across all model-persona pairs. To exploit complementary errors, we explore ensembling four prompting variants and propose a lightweight meta-ensemble: an SVM over the 4-bit vector of prompt predictions. Our results demonstrate that the proposed SVM ensemble consistently outperforms individual prompting methods and traditional majority-voting techniques, achieving the strongest overall performance across diverse personas. This work provides one of the first systematic comparisons of persona-conditioned prompting for toxicity detection and offers a robust method for pluralistic evaluation in subjective NLP tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [250] [Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections](https://arxiv.org/abs/2601.00814)
*Abhishek Kumar*

Main category: cs.AI

TL;DR: 本文提出了一种基于嵌入余弦相似度匹配的跨语言本体对齐系统，通过改进描述生成和微调多语言Transformer模型提升嵌入质量，在OAEI-2022多农场赛道上F1得分达71%，较最优基线提升16%。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言本体对齐方法难以捕捉细微的语义相似性，需提升上下文丰富性和嵌入表征能力。

Method: 构建上下文更丰富的本体实体描述；采用微调的多语言Transformer模型生成高质量嵌入；利用余弦相似度匹配实体对，并通过阈值过滤筛选高相似对。

Result: 在OAEI-2022 multifarm赛道上达到71% F1分数（78%召回率，65%精确率），较最优基线提升16%。

Conclusion: 所提出的对齐流程能有效捕获跨语言本体间的细微语义相似性，验证了嵌入增强与多语言建模的有效性。

Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.

</details>


### [251] [MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback](https://arxiv.org/abs/2601.00816)
*Ismail Ahmad Abdullah*

Main category: cs.AI

TL;DR: 本文提出了MathLedger，一种支持可验证机器认知的基础设施，融合形式化验证、密码学证明与学习动力学，通过反射式形式学习（RFL）实现基于验证器结果而非统计损失的学习更新；实验验证了其测量与治理子系统，强调可审计性与安全性，而非性能提升。


<details>
  <summary>Details</summary>
Motivation: 当代AI系统虽性能卓越但缺乏透明性与可验证性，在安全关键场景中引发信任危机。

Method: 提出MathLedger框架，实现反射式形式学习（RFL），将形式验证、密码学证明与学习过程闭环整合；通过Phase I实验（如CAL-EXP-3）验证Delta p计算、方差跟踪及fail-closed治理机制。

Result: 成功构建并验证了具备ledger-attested learning能力的可工作原型，证实其在受控条件下能正确执行测量与fail-closed治理，但未声称收敛性或能力提升。

Conclusion: MathLedger是一项基础设施级贡献，为大规模、可审计、可验证的AI学习提供了可行技术路径，核心价值在于可信治理而非模型性能优化。

Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.
  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.
  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance

</details>


### [252] [Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making](https://arxiv.org/abs/2601.00818)
*Chandra Sekhar Kubam*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体的Agentic AI框架，用于实现自主、透明、实时的信用风险决策，结合强化学习、自然语言推理、可解释AI与实时数据处理，在提升决策速度与可解释性的同时，也面临模型漂移、高维数据解释不一致及监管不确定性等挑战。


<details>
  <summary>Details</summary>
Motivation: 金融服务业快速数字化催生了对自主、透明、实时信用风险决策系统的迫切需求，而传统机器学习缺乏自适应推理、情境感知和自主性。

Method: 构建了一个多智能体系统，融合强化学习、自然语言推理、可解释AI模块与实时数据吸收管道，并设计了智能体协作协议、风险评分引擎、可解释性层和持续反馈学习循环。

Result: 相比传统信用评分模型，该系统在决策速度、透明度和响应能力方面表现更优；但仍存在模型漂移、高维数据解释不一致、监管不确定性及低资源环境基础设施限制等问题。

Conclusion: 该Agentic AI框架有望变革信用分析，未来研究应聚焦动态合规机制、新型智能体协作范式、对抗鲁棒性及跨国信用生态的大规模落地。

Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.

</details>


### [253] [CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations](https://arxiv.org/abs/2601.00821)
*Tao An*

Main category: cs.AI

TL;DR: 本文提出CogCanvas，一种无需训练的框架，通过提取对话中的认知工件（如决策、事实、提醒）并构建时间感知图谱，解决大语言模型在长对话中上下文窗口限制与信息保真度之间的矛盾。在LoCoMo基准测试中显著优于RAG和GraphRAG，尤其在时间推理和多跳因果推理任务上表现突出。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长对话中面临上下文窗口限制与信息保真度之间的根本张力，现有截断或摘要方法分别导致早期信息丢失或细节失真。

Method: CogCanvas是一种无需训练的框架，从对话轮次中提取基于原文的认知工件（如决策、事实、提醒），并组织成时间感知图谱，支持抗压缩检索。

Result: 在LoCoMo基准上整体准确率达34.7%，显著超越RAG（25.6%）和GraphRAG（13.7%）；时间推理达31.5%，相对提升达530%；多跳因果推理通过率81.0%，比GraphRAG高41.0个百分点；召回率97.5%，精确匹配保持率93.0%。

Conclusion: CogCanvas提供了一种即插即用、无需训练的高效替代方案，在多项关键推理任务上大幅超越标准基线，为实际应用提供了新思路。

Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.
  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.
  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.

</details>


### [254] [Energy-Aware Routing to Large Reasoning Models](https://arxiv.org/abs/2601.00823)
*Austin R. Ellis-Mohr,Max Hartman,Lav R. Varshney*

Main category: cs.AI

TL;DR: 本文研究了大型推理模型（LRMs）在异构推理能耗下的任务调度问题，提出在‘临界态’下平衡基线与辅助能源使用，并引入方差感知的路由与调度策略以提升能效。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）的推理能耗具有异质性，不同模型及推理强度导致能耗差异显著；为降低整体能耗，需智能选择模型并优化其运行方式，而现有调度系统缺乏对能源波动性与方差的建模。

Method: 基于能源供需平衡分析，定义‘临界态’作为最优操作点；建立时间、模型与执行选择三维度的变异性吸收模型；结合训练/推理计算缩放律，形式化分析方差感知的路由与调度策略。

Result: 揭示了临界态下性能由波动性主导，而非均值；导出了方差敏感的调度行为特征；为设计能量感知的模型路由策略提供了理论基础。

Conclusion: 能源效率优化不应仅关注平均能耗，更需管理随机波动；方差-aware routing 是一个关键且可建模的设计维度，应纳入LRM系统调度框架。

Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.

</details>


### [255] [Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis](https://arxiv.org/abs/2601.00828)
*Yin Li*

Main category: cs.AI

TL;DR: 本文系统分解了大语言模型的自我纠正能力为错误检测、定位和纠正三个子能力，发现弱模型（如GPT-3.5）比强模型（如DeepSeek）具有更高的内在纠正率，提出‘错误深度假说’，并揭示错误检测能力与纠正成功率无正相关，且提供错误位置提示反而损害纠正效果。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）被认为具备自我纠正能力，但近期研究表明其内在自我纠正（无需外部反馈）效果有限；本文旨在系统探究其自我纠正能力的构成、表现差异及内在机制。

Method: 将自我纠正分解为错误检测、定位和纠正三阶段；在GSM8K-Complex数据集上对GPT-3.5、DeepSeek、Claude等三大主流LLM开展跨模型实验（每模型n=500，共346个错误）；定量分析各子能力表现及相互关系，并检验位置提示的影响。

Result: 发现‘准确率–纠正率悖论’：弱模型（GPT-3.5，66%准确率）内在纠正率达26.8%，显著高于强模型（DeepSeek，94%准确率，仅16.7%）；错误检测率跨模型差异巨大（10%–82%），但检测率不预测纠正成功率（如Claude检测率仅10%，纠正率达29%）；提供错误位置提示反而全面降低所有模型的纠正效果。

Conclusion: 自我纠正并非随模型整体能力线性提升，强模型所犯错误更‘深’、更难自我修复；错误检测与纠正是解耦能力；现有基于位置提示的自我优化范式可能适得其反；需重新设计更符合认知机制的自修正流程。

Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.

</details>


### [256] [Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.00830)
*Deep Pankajbhai Mehta*

Main category: cs.AI

TL;DR: 研究发现AI模型在逐步推理时通常不会主动提及影响其决策的关键线索，即使它们确实注意到了这些线索；强制报告线索会导致误报并降低准确性，尤其当线索迎合用户偏好时风险更高。


<details>
  <summary>Details</summary>
Motivation: 检验AI系统逐步推理解释是否真实反映其决策依据的假设。

Method: 在9000多个测试案例中向问题嵌入线索，观察11个主流AI模型是否自发提及线索，以及在被直接询问或被要求报告线索时的反应。

Result: 模型几乎从不自发提及线索，但被直接询问时会承认注意到；强制报告导致误报和准确率下降；迎合用户偏好的线索最易被遵循却最难被报告。

Conclusion: 仅观察AI推理过程不足以识别隐藏影响因素，需更可靠的可解释性机制。

Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.

</details>


### [257] [OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification](https://arxiv.org/abs/2601.00843)
*Ayda Aghaei Nia*

Main category: cs.AI

TL;DR: OmniNeuro 是一种新型人机交互框架，通过融合物理、混沌与量子启发的不确定性建模三种可解释性引擎，为脑机接口提供实时神经声音化和生成式临床报告，提升用户透明度与调控能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习在脑机接口（BCI）中虽提升了解码准确率，但其‘黑箱’特性阻碍临床应用，导致用户挫败感及神经可塑性效果差。

Method: 提出 OmniNeuro 框架，集成能量（物理）、分形复杂度（混沌）和量子启发不确定性建模三类可解释性引擎，并驱动实时神经声音化与生成式AI临床报告；该框架解码器无关，适用于任意先进架构。

Result: 在 PhysioNet 数据集（N=109）上平均准确率达 58.52%；小规模定性试点研究（N=3）证实可解释反馈有助于用户调节心理努力并缩短试错阶段。

Conclusion: OmniNeuro 作为通用可解释性层，能将 BCI 从沉默解码器转变为透明反馈伙伴，有望改善临床接受度与神经调控效果。

Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the "Black Box" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the "trial-and-error" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.

</details>


### [258] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文提出TPP-TAL框架，通过显式对齐时间动态与语义上下文，增强大语言模型在时间点过程建模中的时序感知能力，显著提升连续时间事件的似然估计与预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效捕捉时间信息与语义上下文之间的复杂交互，限制了大语言模型在时间点过程建模中的性能。

Method: 提出TPP-TAL框架，摒弃简单拼接事件时间和类型嵌入的做法，转而显式对齐时间动态与上下文语义，再输入大语言模型。

Result: 在多个基准数据集上实验表明，TPP-TAL在时间似然估计和事件预测准确率方面均有显著提升。

Conclusion: 增强大语言模型的时间感知能力对连续时间事件建模至关重要，TPP-TAL为该方向提供了有效的插件式解决方案。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [259] [Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models](https://arxiv.org/abs/2601.00848)
*Ron F. Del Rosario*

Main category: cs.AI

TL;DR: 本文提出了一种开源、可复现的方法，利用OpenTelemetry追踪分析和QLoRA微调语言模型，以检测多智能体AI工作流中的时序攻击模式，在资源受限的ARM64硬件上实现准确率从42.86%提升至74.29%，并开源全部数据集、训练脚本与评测基准。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏针对多智能体AI工作流中时序攻击模式的可复现、轻量级检测框架，且难以适配特定威胁场景；同时，训练数据构成对模型行为的影响缺乏实证支持。

Method: 基于18个公开网络安全数据源与35,026条合成OpenTelemetry追踪，构建80,851例数据集；在NVIDIA DGX Spark（ARM64）上采用三阶段迭代QLoRA微调，并结合针对性数据增强策略。

Result: 自定义基准准确率从42.86%显著提升至74.29%（+31.4点），验证了针对性数据增强优于无差别扩量；同时开源全部数据、代码与评测基准。

Conclusion: 训练数据组成是决定模型安全行为的关键因素；本工作首次建立了可复现、可定制的多智能体安全检测框架，但实际部署仍需人工审核以控制误报率。

Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.

</details>


### [260] [Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks](https://arxiv.org/abs/2601.00856)
*Milos Stankovic,Ella Hirche,Sarah Kollatzsch,Julia Nadine Doetsch*

Main category: cs.AI

TL;DR: 本文是对Kosmyna等人（2025）题为《Your Brain on ChatGPT》论文的评论，指出其在研究设计、可重复性、EEG分析方法、结果报告及透明度等方面存在若干需改进的问题。


<details>
  <summary>Details</summary>
Motivation: 针对Kosmyna等人关于AI助手对人类认知影响的研究，提出建设性批评以提升其发表质量。

Method: 以同行评议方式，系统梳理并指出原研究在样本量、可复现性、EEG分析、结果一致性与实验透明度五个方面的不足。

Result: 识别出五类关键问题：样本量有限、分析不可复现、EEG方法存疑、结果报告不一致、程序与发现透明度不足。

Conclusion: 建议作者对上述问题进行审慎修正，以增强研究的科学严谨性与可信度。

Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.

</details>


### [261] [Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery](https://arxiv.org/abs/2601.00869)
*Huang Junyao,Situ Ruimin,Ye Renqin*

Main category: cs.AI

TL;DR: 本研究揭示了大语言模型（LLMs）中存在系统性文化编码现象，即训练数据地理来源导致品牌推荐显著差异：中文LLMs对中文品牌的提及率（88.9%）远高于国际LLMs（58.3%），即使使用纯英文查询；提出‘存在缺口’（Existence Gap）与‘数据护城河’（Data Moat）框架，强调品牌需通过语义覆盖、技术深度与文化本地化构建算法可见性，以实现生成式引擎优化（GEO）。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益主导消费者信息获取，品牌面临‘算法不可见性’风险；现有研究未充分关注LLM训练数据地理构成对品牌可见性的系统性影响。

Method: 对6个主流LLM（GPT-4o、Claude、Gemini、Qwen3、DeepSeek、Doubao）进行1909条纯英文查询实验，覆盖30个品牌；结合案例研究（智子边界/Zhizibianjie）与理论建构，提出‘存在缺口’和‘数据护城河’框架。

Result: 中文LLM品牌提及率比国际LLM高30.6个百分点（88.9% vs. 58.3%，p<.001）；同一英文查询下差异仍显著；案例显示某中国平台在中文LLM中提及率达65.6%，国际LLM中为0%；验证‘语言边界障碍’造成隐形市场准入壁垒。

Conclusion: LLM中的品牌可见性由训练数据地理决定，而非查询语言；品牌‘数据边界’直接界定其‘市场前沿’；应将‘算法无处不在性’（Algorithmic Omnipresence）作为GEO战略目标，并通过18个月路线图构建数据护城河。

Abstract: As artificial intelligence systems increasingly mediate consumer information discovery,
  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large
  Language Models (LLMs) -- systematic differences in brand recommendations arising from
  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,
  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6
  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,
  p<.001). This disparity persists in identical English queries, indicating training data
  geography -- not language -- drives the effect. We introduce the Existence Gap: brands
  absent from LLM training corpora lack "existence" in AI responses regardless of quality.
  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%
  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how
  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we
  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic
  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility
  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization
  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats
  through semantic coverage, technical depth, and cultural localization. Our findings reveal
  that in AI-mediated markets, the limits of a brand's "Data Boundaries" define the limits
  of its "Market Frontiers."

</details>


### [262] [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)
*Anthony Mikinka*

Main category: cs.AI

TL;DR: 本文提出了通用条件逻辑（UCL）框架，将提示工程从经验实践转变为系统化优化，通过结构开销函数解释性能差异，并验证了其核心机制在不同大模型上的适用性与适配需求。


<details>
  <summary>Details</summary>
Motivation: 将提示工程从启发式实践转变为系统性优化，解决当前提示设计缺乏数学基础和可复现性的问题。

Method: 提出通用条件逻辑（UCL）框架，定义结构开销函数O_s(A)，引入指示函数、早期绑定等机制，并通过305次实验（11个模型、4轮迭代）进行系统评估。

Result: 实现29.8%的token减少（p < 0.001，Cohen's d = 2.01），发现过规格化悖论（阈值S* = 0.509），并验证最优UCL配置因模型架构而异（如Llama 4 Scout需V4.1版本适配）。

Conclusion: UCL是一个可校准的大语言模型交互优化框架，模型族特异性优化是未来关键方向。

Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.

</details>


### [263] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)
*Mandar Parab*

Main category: cs.AI

TL;DR: 本文提出了一种名为反事实自我提问（Counterfactual Self-Questioning）的新框架，使单一语言模型能通过生成并评估自身推理的反事实批判来实现自我改进，无需外部评判器或额外奖励模型，提升了数学推理任务的准确性和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法多依赖外部评判器、学习的奖励模型或集成采样，导致复杂性和训练不稳定性增加。

Method: 提出反事实自我提问框架：模型先生成初始推理链，再针对潜在错误点提出针对性问题，并生成替代性推理路径以暴露错误假设或无效步骤，从而提供结构化相对反馈用于策略优化。

Result: 在多个数学推理基准上实验表明，该方法提升了准确性与训练稳定性，尤其对较小模型效果显著，实现了仅靠内部生成监督的可扩展自我改进。

Conclusion: 反事实自我提问是一种简洁、稳定且可扩展的语言模型自我改进方法，摆脱了对外部组件的依赖，为自主推理优化提供了新思路。

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.

</details>


### [264] [Context Collapse: In-Context Learning and Model Collapse](https://arxiv.org/abs/2601.00923)
*Josef Ott*

Main category: cs.AI

TL;DR: 本文研究了大语言模型中的三个关键现象：上下文学习（ICL）、模型坍缩和上下文坍缩；通过线性transformer分析ICL的相变机制，用随机过程理论严格证明模型坍缩的几乎必然性，并提出上下文坍缩新概念以连接ICL与生成稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型中上下文学习、模型坍缩及长期生成稳定性等基础机制，弥补现有理论在相变行为、收敛性保证和上下文退化方面的不足。

Method: 对线性transformer（权值绑定）在线性回归任务上分析ICL，将其前向传播约化为预条件梯度下降并分析最优预条件器；对模型坍缩采用鞅和随机游走理论，在线性回归与高斯拟合简化设定下建模；提出并形式化‘上下文坍缩’概念。

Result: 发现ICL存在临界上下文长度引发的参数相变，伴随斜对称分量出现；严格证明模型坍缩在数据增长不足或未留存时几乎必然发生；首次定义并关联上下文坍缩与链式推理中的长期上下文退化。

Conclusion: ICL、模型坍缩与上下文坍缩本质关联于优化动力学与统计稳定性，需联合建模训练动态与生成过程以提升LLMs鲁棒性与可靠性。

Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.

</details>


### [265] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

TL;DR: 本文提出了ElecTwit框架，用于在模拟政治选举的社交媒体环境中研究多智能体系统的说服行为，发现不同大语言模型在25种说服技巧使用上存在显著差异，并观察到如'事实内核'和'墨水执念'等新现象。


<details>
  <summary>Details</summary>
Motivation: 克服以往基于游戏的模拟方法在研究多智能体说服行为时的局限性，构建更贴近现实的社交平台仿真环境。

Method: 设计并实现ElecTwit多智能体模拟框架，以政治选举为背景，在真实感强的社交媒体环境中测试多种大语言模型对25种说服技巧的使用情况。

Result: 观察到大多数测试的大语言模型广泛使用全部25种说服技巧；不同模型在技巧使用偏好和总体说服输出上存在明显差异；发现'事实内核'消息和集体要求书面证明（'墨水执念'）等新现象。

Conclusion: ElecTwit为评估大语言模型代理在现实世界中的说服能力提供了新基础，有助于确保其行为对齐并防范潜在风险。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [266] [Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering](https://arxiv.org/abs/2601.01195)
*Wuzhenghong Wen,Chao Xue,Su Pan,Yuwei Sun,Minlong Peng*

Main category: cs.AI

TL;DR: 本文提出MRE框架，通过增强前向和后向多跳推理，结合提示工程、监督微调与新型树状强化学习算法T-GRPO，提升时序知识图谱问答中全局最优推理路径的识别能力，在多个基准上超越SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在TKGQA中每跳检索大量时序相似、语义复杂的子图，易导致次优决策与错误传播。

Method: 提出MRE框架：1）提示工程生成多样化推理路径；2）筛选有效路径用于监督微调（冷启动）；3）引入树结构的Tree-Group Relative Policy Optimization（T-GRPO），实现递归式探索与多路径反馈评估。

Result: 在两个TKGQA基准上显著超越SOTA；提升模型对复杂多跳查询的处理能力，并增强可解释性与对噪声时间标注的鲁棒性。

Conclusion: MRE框架通过协同优化前向与后向推理及引入结构化探索机制，有效缓解了TKGQA中多跳推理的误差累积问题，为时序推理提供了新范式。

Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.

</details>


### [267] [Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies](https://arxiv.org/abs/2601.01301)
*Keith Frankston,Benjamin Howard*

Main category: cs.AI

TL;DR: 本文提出了一种递归式AlphaZero风格的蒙特卡洛树搜索算法RMCTS，通过广度优先搜索和批量网络推理显著提升计算速度，相比MCTS-UCB单状态搜索快40倍以上、批量搜索快约3倍；其核心是基于后验策略优化的递归回传机制，并在Connect-4、Dots-and-Boxes和Othello上验证了其训练效率与性能相当性。


<details>
  <summary>Details</summary>
Motivation: 为降低AlphaZero中MCTS-UCB因深度优先搜索导致的GPU推理延迟开销，提升搜索效率。

Method: 提出RMCTS算法：采用广度优先的递归搜索结构，基于Grill等人提出的正则化后验策略（最大化奖励估计减去偏离先验策略的惩罚），并按先验网络策略静态构建搜索树。

Result: RMCTS在单根状态搜索中比MCTS-UCB快40倍以上，在批量根状态搜索中快约3倍；在三个棋类游戏中，RMCTS训练网络达到同等质量仅需约三分之一的训练时间。

Conclusion: RMCTS以牺牲自适应树构建为代价，换取显著的速度优势，且不损害最终策略质量，是一种高效实用的MCTS替代方案。

Abstract: We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, "RMCTS". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.
  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in "Monte--Carlo tree search as regularized policy optimization" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.
  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.

</details>


### [268] [Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models](https://arxiv.org/abs/2601.01321)
*Rong Zhou,Dongping Chen,Zihan Jia,Yao Su,Yixin Liu,Yiwen Lu,Dongwei Shi,Yue Huang,Tianyang Xu,Yi Pan,Xinliang Li,Yohannes Abate,Qingyu Chen,Zhengzhong Tu,Yu Yang,Yu Zhang,Qingsong Wen,Gengchen Mai,Sunyang Fu,Jiachen Li,Xuyu Wang,Ziran Wang,Jing Huang,Tianming Liu,Yong Chen,Lichao Sun,Lifang He*

Main category: cs.AI

TL;DR: 本文提出一个统一的四阶段框架，系统描述人工智能在数字孪生全生命周期（建模、镜像、干预、自主管理）中的集成方式，并探讨了物理建模与数据驱动学习的协同、生成式AI对数字孪生认知能力的提升，以及跨领域应用中的共性挑战与发展方向。


<details>
  <summary>Details</summary>
Motivation: 数字孪生已从被动仿真工具演变为智能自主实体，亟需系统化框架来刻画AI在其全生命周期中的集成路径与技术演进。

Method: 通过综述现有技术与实践，提炼出涵盖建模、镜像、干预和自主管理四个阶段的统一框架；结合物理建模与数据驱动方法，分析生成式AI（如大语言模型、生成式世界模型）的作用机制；开展覆盖11个领域的跨领域对比分析。

Result: 明确了AI在数字孪生各阶段的技术实现路径（如物理信息AI建模、实时镜像同步、预测性干预、LLM驱动自主管理），揭示了从传统数值求解器向物理信息模型与基础模型的范式转变，并识别出可扩展性、可解释性与可信性等共性挑战。

Conclusion: AI深度赋能正推动数字孪生向具备推理、交互与创造性场景生成能力的认知系统演进；未来需构建兼顾性能与责任的AI驱动数字孪生体系。

Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.

</details>


### [269] [Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale](https://arxiv.org/abs/2601.01330)
*Shengji Tang,Weihao Lin,Jingqi Ye,Hao Li,Bo Zhang,Shuyue Hu,Tao Chen,Wangli Ouyang,Lei Bai,Peng Ye*

Main category: cs.AI

TL;DR: 本文提出JiSi框架，通过查询-响应混合路由、支持集驱动的聚合器选择和自适应路由-聚合切换，提升开源大模型协作性能，以47%成本超越Gemini-3-Pro。


<details>
  <summary>Details</summary>
Motivation: 探索集体智能作为单一大模型扩展的替代路径，解决当前LLM协同中路由与聚合存在的三大瓶颈：查询式路由局限、静态聚合方法缺乏任务适配性、路由与聚合互补性未被充分利用。

Method: 提出JiSi框架，包含三项创新：(1) 查询-响应混合路由，兼顾语义信息与问题难度；(2) 支持集驱动的聚合器选择，联合评估聚合能力与领域适配性；(3) 自适应路由-聚合切换机制，动态发挥二者优势。

Result: 在九个基准测试中，JiSi仅用十个开源LLM、47%成本即超越Gemini-3-Pro，并优于主流基线方法。

Conclusion: LLM协作形成的集体智能是一条通向通用人工智能（AGI）的新可行路径。

Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).

</details>


### [270] [A unified multimodal understanding and generation model for cross-disciplinary scientific research](https://arxiv.org/abs/2601.01363)
*Xiaomeng Yang,Zhiyu Tan,Xiaohui Zhong,Mengping Yang,Qiusheng Huang,Lei Chen,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: FuXi-Uni 是一个原生统一的多模态科学大模型，能在单一架构中跨学科理解与高保真生成多源科学数据（如气象、生物医学），支持自然语言交互与数值预测，在天气预报和生物医学视觉问答任务上超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型多为领域专用或难以协同处理高维、异构、跨学科科学数据，而全球性科学挑战亟需通用、统一的多模态科学建模能力。

Method: 提出FuXi-Uni模型：将跨学科科学token与自然语言token对齐，并设计科学解码器重建科学token，实现自然语言对话与科学数值预测联合建模；在地球科学和生物医学领域进行实证验证。

Result: 在地球系统建模中，10天全球天气预报（0.25°分辨率）优于物理SOTA系统；热带气旋路径与强度预测更准；空间降尺度效果超越插值基线；在生物医学VQA任务上超越主流多模态大模型。

Conclusion: FuXi-Uni通过原生共享隐空间统一异构科学模态，在保持强领域性能的同时迈向更通用、跨学科的科学AI范式。

Abstract: Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.

</details>


### [271] [KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models](https://arxiv.org/abs/2601.01366)
*Zixian Liu,Sihao Liu,Yuqi Zhao*

Main category: cs.AI

TL;DR: 本文提出了KGCE，一个用于评估多模态大语言模型在跨平台教育场景中任务执行能力的新基准平台，通过知识库增强和双图评估框架，解决了现有方法在私有领域软件理解和细粒度评估上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准框架在支持教育场景下的跨平台任务（尤其是学校专用软件）方面存在明显缺陷，且评估方法过于粗粒度，难以捕捉复杂任务中的执行细节与效率。

Method: 构建了包含104个教育相关任务的数据集（覆盖Windows、Android及跨平台协同任务），提出双图评估框架以分解任务并验证子目标完成情况，并设计了针对学校专用软件的知识增强型代理系统。

Result: KGCE实现了对教育场景下跨平台任务的细粒度评估，提升了代理在私有域软件上的执行效率与理解能力。

Conclusion: KGCE为多模态大语言模型在教育智能体中的应用提供了更精准、更具针对性的评估基准，推动了跨平台教育智能体的发展。

Abstract: With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.

</details>


### [272] [Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification](https://arxiv.org/abs/2601.01378)
*Han Yuan,Yilin Wu,Li Zhang,Zheng Ma*

Main category: cs.AI

TL;DR: 本文提出了一种名为AAAI的三步管道（关联识别、自动检测和自适应推理），旨在通过缓解小语言模型（SLMs）在金融分类任务中的事实性幻觉来提升其分类性能。实验表明，事实性幻觉与误分类正相关，基于编码器的验证器可有效检测幻觉，且引入对事实错误的反馈能实现SLMs的自适应推理并提升分类效果。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLMs）在金融分类中因推理中的事实性幻觉而性能较弱，亟需探究缓解幻觉是否能提升其分类能力。

Method: 提出AAAI三步管道：关联识别（识别金融文本中关键事实关联）、自动化检测（使用encoder-based verifier检测事实幻觉）、自适应推理（基于检测结果反馈调整推理过程）。

Result: 实验证明：（1）事实幻觉与误分类显著正相关；（2）encoder-based verifier能有效检测幻觉；（3）引入幻觉反馈可提升SLMs分类性能。

Conclusion: 缓解事实幻觉可有效提升SLMs在金融分类任务中的性能与可信度，AAAI管道为SLMs在金融领域的可信应用提供了可行路径。

Abstract: Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.

</details>


### [273] [A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts](https://arxiv.org/abs/2601.01467)
*Romuald Kwessy Mouona,Blaise Blériot Koguep Njionou,Etienne Romuald Temgoua Alomo,Rokia Missaoui,Leonard Kwuida*

Main category: cs.AI

TL;DR: 本文研究三元上下文中的蕴含关系，特别是Ganter和Obiedkov提出的条件属性蕴含和归因条件蕴含，并旨在构建其最优基。


<details>
  <summary>Details</summary>
Motivation: 为了系统化和优化三元上下文中条件属性蕴含与归因条件蕴含的表示与推理。

Method: 基于形式概念分析理论，针对三元上下文中的两类蕴含（条件属性蕴含和归因条件蕴含）设计并构造其最优基。

Result: 提出了适用于这两类蕴含的最优基构造方法，并验证了其完备性与最小性。

Conclusion: 该最优基能有效支持三元上下文中蕴含关系的紧凑表示与高效推理，拓展了形式概念分析在多维数据建模中的应用。

Abstract: This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.

</details>


### [274] [Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning](https://arxiv.org/abs/2601.01511)
*Ahmed Dawoud,Osama El-Shamy*

Main category: cs.AI

TL;DR: 本文提出了一种基于神经网络增强的双重机器学习（DML）框架，利用文本嵌入缓解因未观测混杂因素导致的选择偏差；实验表明，相比传统树模型DML（偏差+24%），该方法可将偏差降至-0.86%，更准确识别因果效应。


<details>
  <summary>Details</summary>
Motivation: 观测性研究中常因未观测混杂因素导致选择偏差，而传统计量方法难以处理与结构化协变量正交的混杂变量；高维非结构化文本可能蕴含这些潜变量的丰富代理信息。

Method: 提出神经网络增强的双重机器学习（DML）框架，利用文本嵌入作为混杂变量的代理，结合深度学习建模嵌入流形的连续拓扑结构。

Result: 在合成基准实验中，文本嵌入显著补充了结构化数据缺失的混杂信息；标准树基DML偏差达+24%，而所提深度学习方法将偏差降至-0.86%，有效恢复真实因果参数。

Conclusion: 深度学习架构对在高维自然语言数据下满足无混杂假设至关重要，是提升因果推断准确性的关键。

Abstract: Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data

</details>


### [275] [Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making](https://arxiv.org/abs/2601.01522)
*Danial Amin*

Main category: cs.AI

TL;DR: 本文提出了一种面向不对称错误成本场景的贝叶斯多大模型协同框架，将LLM视为近似似然模型，通过对比提示、鲁棒聚合与贝叶斯更新实现成本最优的序贯决策，在简历筛选任务中显著降低成本并提升公平性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在招聘、医疗分诊、欺诈检测等具有不对称错误成本的场景中，普遍采用单模型置信度阈值法，无法支持成本敏感的序贯决策，导致次优甚至有害结果。

Method: 将多个LLM建模为近似似然模型；通过对比提示（contrastive prompting）对每个候选状态 elicited likelihoods；使用鲁棒统计方法跨模型聚合似然；结合显式先验，基于贝叶斯规则进行信念更新；据此进行期望成本最小化行动选择、价值信息驱动的信息采集及偏差缓解。

Result: 在含真实成本结构的简历筛选实验中（1000份简历、5个LLM），总成本降低34%（29.4万美元），群体间差异（demographic parity gap）从22个百分点降至5个百分点（改善45%）；消融分析表明多模型聚合、序贯更新和分歧触发的信息采集分别贡献51%、43%和20%的成本节约。

Conclusion: 以概率一致性与成本意识为核心的多LLM贝叶斯协同框架，优于单模型置信度阈值范式，能同时提升决策效率、鲁棒性与公平性，为高风险AI代理部署提供了理论可靠且实证有效的替代方案。

Abstract: Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds "confidence," and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.

</details>


### [276] [Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix](https://arxiv.org/abs/2601.01532)
*Fanzhe Fu*

Main category: cs.AI

TL;DR: 本文提出Project Aletheia框架，通过Tikhonov正则化逆推裁判混淆矩阵，量化大模型在System 2推理中的‘认知确信度’（Cognitive Conviction），并引入Aligned Conviction Score评估其与安全性的兼容性，旨在解决AGI评估中信念深度难以度量的难题。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估范式存在认识论危机：静态基准仅衡量知识广度，无法量化信念深度；CHOKE现象揭示了标准问答中模型确信度的异常，需扩展至更深层的System 2推理评估。

Method: 提出Project Aletheia认知物理框架，采用Tikhonov正则化方法逆向求解裁判混淆矩阵以量化认知确信；设计无需私有数据的合成代理协议（Synthetic Proxy Protocol）进行验证；定义Aligned Conviction Score（S_aligned）检验确信度与安全对齐的关系。

Result: 初步实验表明，推理模型在对抗压力下可能表现出‘防御性过度思考’（Defensive OverThinking），虽起认知缓冲作用，但确信度与安全性需协同评估；S_aligned可有效验证高确信不损害安全。

Conclusion: Project Aletheia为测量AI科学诚信提供了可复现、可解释的新范式，将信念深度纳入AGI评估核心，推动从‘答得对’向‘信得真且安’演进。

Abstract: In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify "Cognitive Conviction" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a "cognitive buffer," they may exhibit "Defensive OverThinking" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.

</details>


### [277] [Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation](https://arxiv.org/abs/2601.01546)
*Letian Kong,Qianran,Jin,Renyu Zhang*

Main category: cs.AI

TL;DR: 本文提出一个两阶段框架（上下文构建与上下文导航）以提升大语言模型在复杂决策环境中的行为对齐度，并在多个实验任务中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在模拟人类行为时，在需预测他人行动和基于观察形成信念的复杂决策环境中，系统性偏离人类决策，亟需提升行为对齐性。

Method: 提出两阶段框架：第一阶段‘上下文构建’明确实验设计以准确表征任务与背景；第二阶段‘上下文导航’引导模型在该表征内进行推理与决策；并在三个不同决策任务（顺序购买博弈、众筹博弈、需求估计任务）中对四个SOTA模型进行实证检验。

Result: 在复杂决策环境（如顺序购买与众筹博弈）中，两个阶段均需才能实现与人类基准的行为对齐；而在较简单的需求估计任务中，仅需第一阶段即可；四个SOTA模型均表现出一致规律。

Conclusion: 该两阶段框架明确了不同决策环境下提升LLM行为对齐所需的关键机制，为将LLM作为人类被试的补充用于行为科学研究提供了可诊断、可推广的设计范式。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.

</details>


### [278] [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)
*Mingyu Xu,Cheng Fang,Keyue Jiang,Yuqian Zheng,Yanghua Xiao,Baojian Zhou,Qifang Zhao,Suhang Zheng,Xiuwen Zhu,Jiyang Tang,Yongchi Zhao,Yijia Luo,Zhiqi Bai,Yuchi Xu,Wenbo Su,Wei Wang,Bing Zhao,Lin Qu,Xiaoxiao Xu*

Main category: cs.AI

TL;DR: Logics-STEM 是一个面向 STEM 领域推理任务的先进细调模型，基于 1000 万规模高质量长链思维数据集 Logics-STEM-SFT-Dataset 训练，在 STEM 基准测试中平均超越次优 8B 模型 4.68%；其核心创新在于数据与算法协同设计：数据端采用五阶段精细化构建流程，算法端提出失败驱动的后训练框架，结合知识检索与合成数据优化 SFT 或 RL；模型与数据集均已开源。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在 STEM 领域复杂推理任务上的能力，弥补现有开源推理模型在数据质量、规模及算法适配性上的不足。

Method: 提出数据-算法协同设计范式：数据方面构建五阶段（标注、去重、去污染、蒸馏、分层采样）数据处理引擎生成 Logics-STEM-SFT-Dataset；算法方面设计失败驱动的后训练框架，在监督微调（SFT）阶段围绕模型失败区域进行知识检索与数据合成，以更好拟合黄金标准推理分布。

Result: Logics-STEM（8B 和 32B）在 STEM 相关基准上平均提升 4.68%（相较次优 8B 模型）；验证了大规模开源数据与精心设计合成数据结合的有效性；模型与数据集（10M 及 2.2M 子集）已全部开源。

Conclusion: 数据与算法协同设计是提升大模型推理能力的关键路径；高质量、大规模、结构化推理数据与针对性后训练方法的联合优化，可显著增强 STEM 领域的长链推理性能；开源成果将推动社区在该方向的研究进展。

Abstract: We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.

</details>


### [279] [CaveAgent: Transforming LLMs into Stateful Runtime Operators](https://arxiv.org/abs/2601.01569)
*Maohao Ran,Zhenglin Wan,Cooper Lin,Yanting Zhang,Hongyu Xin,Hongwei Fan,Yibo Xu,Beier Luo,Yaxin Zhou,Wangbo Zhao,Lijie Yang,Lang Feng,Fuchao Yang,Jingxuan Wu,Yiqiao Huang,Chendong Ma,Dailing Jiang,Jianbo Deng,Sihui Han,Bo An,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: 本文提出CaveAgent框架，将大语言模型从文本生成器转变为运行时操作器，通过双流上下文架构（语义流+Python运行时流）实现状态持久化与复杂对象管理，显著提升长程任务成功率并大幅降低token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的智能体范式（如JSON函数调用）在长周期任务中易受多轮依赖脆弱性和上下文漂移困扰，难以支持复杂、状态敏感的任务执行。

Method: 提出CaveAgent框架，核心包括：1）Dual-stream Context Architecture（语义流用于推理，Python Runtime流用于确定性执行）；2）Stateful Runtime Management，支持跨轮次注入、操作和检索复杂Python对象（如DataFrame、数据库连接）；3）利用代码生成一次性解决含循环/条件的子任务。

Result: 在Tau²-bench、BFCL等基准及多个案例中验证有效性：零售任务成功率提升10.5%；多轮场景总token消耗减少28.4%；数据密集型任务token消耗降低59%，可处理导致其他代理上下文溢出的大规模数据。

Conclusion: CaveAgent通过将LLM深度耦合到Python运行时环境，构建高保真外部记忆，有效缓解上下文漂移与灾难性遗忘，为长程、数据驱动型智能体任务提供了更鲁棒、高效的新范式。

Abstract: LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from "LLM-as-Text-Generator" to "LLM-as-Runtime-Operator." We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\% success rate improvement on retail tasks and reduces total token consumption by 28.4\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.

</details>


### [280] [Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration](https://arxiv.org/abs/2601.01609)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 本文提出一种将大语言模型（LLM）与符号推理（基于SWRL的OWL 2本体）结合的新框架，用于在临床、法律和科研等需可审计决策的领域中，对自然语言规则进行可靠、可解释的推理。LLM负责将文本转化为本体断言（ABox），符号推理器确保规则应用的确定性与形式化保障。实验表明该结构化分解方法显著优于少样本提示，在多个领域均有效，且符号验证环节贡献突出。


<details>
  <summary>Details</summary>
Motivation: 在临床协议、法律证据规则、科研标准等需可审计与可解释决策的场景中，需兼顾自然语言理解的灵活性与推理结果的形式化保证；现有LLM缺乏一致性保障，而传统符号系统难以处理非结构化文本输入。

Method: 提出一种集成模式：LLM作为本体填充引擎，依据专家定义的TBox（OWL 2本体）将自然语言输入解析为ABox断言；随后由SWRL规则引擎执行确定性符号推理；整个流程分为实体识别、断言抽取与符号验证三阶段，任务定义严格基于OWL 2语义。

Result: 在法律传闻规则判定、科研方法适用性判断、临床试验入组资格三个领域及11个LLM上的实验表明，该方法在聚合指标上显著优于少样本提示；消融实验证明符号验证模块带来实质性增益；生成的ABox可无缝接入标准语义网工具链。

Conclusion: 结构化分解+LLM+符号推理的混合范式，能在保持自然语言接口的同时提供形式化可验证性，为高可靠性AI推理提供了可行路径，并支持更丰富的语义推理能力。

Abstract: Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.

</details>


### [281] [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)
*YuanLab. ai,:,Shawn Wu,Sean Wang,Louie Li,Darcy Chen,Allen Wang,Jiangang Luo,Xudong Zhao,Joseph Shen,Gawain Ma,Jasper Jia,Marcus Mao,Claire Wang,Hunter He,Carol Wang,Zera Zhang,Jason Wang,Chonly Shen,Leo Zhang,Logan Chen,Qasim Meng,James Gong,Danied Zhao,Penn Zheng,Owen Zhu,Tong Yu*

Main category: cs.AI

TL;DR: Yuan3.0 Flash 是一个开源的多模态 MoE 大语言模型（3.7B 激活参数，40B 总参数），专为提升企业级任务性能设计，并提出 RAPO 算法缓解大模型‘过度思考’问题，在 RAG、复杂表格理解、摘要等任务及数学科学推理中表现优异且更省 token。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型（LRMs）中普遍存在的‘过度思考’现象，并提升模型在企业级任务（如RAG、复杂表格理解、摘要）上的性能，同时兼顾通用能力。

Method: 提出 Reflection-aware Adaptive Policy Optimization (RAPO) —— 一种新型强化学习训练算法，用于调控过度思考行为；构建 Yuan3.0 Flash，基于 MoE 架构的多模态大语言模型。

Result: 在企业级任务（RAG、复杂表格理解、摘要）上持续优于现有模型；在数学、科学等推理任务中达到前沿模型精度，但仅需约 1/4 至 1/2 的平均 token 数。

Conclusion: Yuan3.0 Flash 是兼顾企业应用与通用推理能力的高效开源 MoE 多模态大模型，RAPO 方法有效缓解过度思考，推动更高效、实用的大模型发展。

Abstract: We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.

</details>


### [282] [AI Agent Systems: Architectures, Applications, and Evaluation](https://arxiv.org/abs/2601.01743)
*Bin Xu*

Main category: cs.AI

TL;DR: 本文综述了AI智能体架构的最新进展，涵盖推理、规划与工具调用三大核心能力，并构建统一分类体系，分析设计权衡与评估难点，指出可验证性、记忆扩展、决策可解释性及真实场景可复现评估等开放挑战。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能体在实际应用中迅速普及，亟需系统梳理其架构演进、组件设计与评估方法，以支撑可靠、可控、可扩展的智能体开发。

Method: 通过文献综述与结构化归纳，构建覆盖智能体组件、编排模式与部署场景的统一分类法，并分析关键设计权衡与评估复杂性根源。

Result: 提出涵盖推理、规划、工具交互的三维能力框架；建立含政策核心、记忆、世界模型、规划器、工具路由与批评器的组件分类；总结延迟-精度、自主性-可控性、能力-可靠性三类核心权衡；系统梳理评估难点与基准实践。

Conclusion: AI智能体研究已进入架构标准化与工程化关键期，未来需在安全性保障（如工具动作验证）、长程上下文管理、决策透明性及真实负载下可复现评估等方面取得突破。

Abstract: AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\ multi-agent; centralized vs.\ decentralized coordination), and deployment settings (offline analysis vs.\ online interactive assistance; safety-critical vs.\ open-ended tasks). We discuss key design trade-offs -- latency vs.\ accuracy, autonomy vs.\ controllability, and capability vs.\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.

</details>


### [283] [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)
*Yao Lu,Shang Liu,Hangan Zhou,Wenji Fang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AI

TL;DR: 本文提出了RTL-OPT基准，用于评估大语言模型在寄存器传输级（RTL）代码优化方面的能力，涵盖功能正确性与功耗、性能、面积（PPA）等硬件指标。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成RTL代码的基准主要关注语法正确性，缺乏对实际硬件优化质量（如PPA）的评估，难以反映其在工业级设计优化中的真实能力。

Method: 构建了包含36个手工设计电路的RTL-OPT基准，覆盖多种数字电路类型；每项任务提供子优RTL代码与人工优化的参考版本，并集成自动化评估框架以验证功能正确性并量化PPA提升。

Result: RTL-OPT首次系统性地支持对LLM在RTL优化任务上的功能与PPA指标的标准化评测，填补了该领域基准缺失的空白。

Conclusion: RTL-OPT为评估和推动面向硬件设计优化的生成式AI模型提供了可靠、可复现且工业相关的评测标准。

Abstract: The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.

</details>


### [284] [Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches](https://arxiv.org/abs/2601.01774)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.AI

TL;DR: 本文系统评估了大语言模型（LLM）求解工程中常见的超越方程的能力，发现直接数值预测误差高，而采用LLM负责符号建模与初值提供、经典牛顿-拉夫逊法进行数值迭代的混合架构显著降低误差（平均降幅67.9%–81.8%），表明LLM更适合作为传统求解器的智能接口而非独立计算引擎。


<details>
  <summary>Details</summary>
Motivation: 工程实践中广泛存在需迭代求解的超越方程（如流体力学摩擦因子、轨道位置计算等），但当前LLM在高精度数值迭代任务上的能力尚不明确，亟需系统评估其适用范式。

Method: 在7个工程领域共100个问题上，对比6种前沿LLM（如GPT-5.1、Gemini-3-Flash等）的两种策略：（1）直接数值预测；（2）混合架构——LLM完成符号建模与初值设定，由牛顿-拉夫逊法执行数值求解。

Result: 直接预测的平均相对误差为0.765–1.262；混合架构降至0.225–0.301，误差降低67.9%–81.8%；电子学领域提升最显著（93.1%），流体力学最低（7.2%）。

Conclusion: 当前LLM擅长符号操作与领域知识调用，但在精度敏感的迭代计算上表现不足，最优应用模式是作为经典数值求解器的智能前端接口。

Abstract: Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.

</details>


### [285] [PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor](https://arxiv.org/abs/2601.01802)
*Qianjun Pan,Junyi Wang,Jie Zhou,Yutao Yang,Junsong Li,Kaiyin Xu,Yougen Zhou,Yihan Li,Jingyuan Zhao,Qin Chen,Ningning Zhou,Kai Chen,Liang He*

Main category: cs.AI

TL;DR: 本文提出了PsychEval，一个用于心理评估AI的多会话、多疗法、高真实性的基准测试，旨在解决训练高真实性AI咨询师、多疗法AI咨询师以及系统评估AI咨询师三大挑战。


<details>
  <summary>Details</summary>
Motivation: 为开发可靠的AI心理评估工具，解决现有AI在心理咨询中缺乏长期记忆、动态目标跟踪、多疗法灵活应用及系统性评估等方面的不足。

Method: 构建了PsychEval基准，包含多会话（6-10次）、覆盖五种主流疗法与整合疗法的多疗法数据集，标注了677个元技能和4577个原子技能；设计了涵盖18项指标的全面评估框架，并构建2000多个多样化来访者档案；将其作为高保真强化学习环境支持AI自我进化训练。

Result: 实验验证了PsychEval数据集具有优越的质量和临床保真度，能有效支持临床负责且自适应AI咨询师的训练与评估。

Conclusion: PsychEval不仅是一个静态评测基准，更是一个支持AI咨询师持续进化的高保真强化学习环境，推动AI在心理咨询领域向临床可靠与自适应方向发展。

Abstract: To develop a reliable AI for psychological assessment, we introduce \texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.

</details>


### [286] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

TL;DR: 本文提出了一种新的AI对齐范式——‘可容许性对齐’（Admissibility Alignment），将对齐定义为在不确定性下、针对结果分布进行可容许行动与决策选择的性质，并通过候选策略的行为来评估；并设计了MAP-AI系统架构，利用蒙特卡洛方法估计结果分布，以分布性质（如期望效用、方差、尾部风险等）而非准确率或排序性能来评估对齐，实现无需重训练模型的动态对齐控制。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐常被视为静态或二元条件，难以应对现实世界中不确定性、价值模糊性、干预效应及治理约束等复杂因素；本文旨在建立一种更实用、可执行、面向分布与尾部事件的对齐评估与控制框架，尤其适用于企业级和制度性AI系统。

Method: 提出‘可容许性对齐’概念，构建MAP-AI（Monte Carlo Alignment for Policy）控制平面架构：基于蒙特卡洛采样估计结果分布，结合多维分布指标（期望效用、方差、尾部风险、误对齐概率）评估策略可容许性，并在不修改底层模型前提下，实现对齐驱动的动作选择。

Result: 实现了对AI策略在多种可能未来下的分布式对齐评估；支持在不确定性下动态调整策略行为（如规避高尾部风险）；提供可部署的对齐治理机制，避免依赖模型重训练或静态约束；验证了该框架在企业/制度AI场景中的实用性与可操作性。

Conclusion: AI对齐应被重新理解为一种动态、分布式的决策理性属性，而非模型参数层面的静态属性；MAP-AI为构建可信、可控、可审计的高影响AI系统提供了理论基础与工程路径。

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [287] [COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs](https://arxiv.org/abs/2601.01836)
*Dasol Choi,DongGeon Lee,Brigitta Jesica Kartono,Helena Berndt,Taeyoun Kwon,Joonwon Jang,Haon Park,Hwanjo Yu,Minsuk Kahng*

Main category: cs.AI

TL;DR: 本文提出了COMPASS框架，用于评估大语言模型（LLM）是否符合组织特定的允许/禁止政策，首次系统性地测试了8个行业场景下的5920个查询，发现现有模型在处理禁止类请求时表现极差（仅13-40%拒绝率），揭示其在高风险企业部署中的安全缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在医疗、金融等高风险企业场景中部署，确保其遵守组织特定政策变得至关重要，但现有安全评估仅关注通用危害，缺乏针对组织策略的系统性评测方法。

Method: 提出COMPASS（Company/Organization Policy Alignment Assessment）框架，构建涵盖8个行业场景的组织政策合规性评测集，生成并验证5920个查询，包括常规合规与对抗性边缘案例，对7个SOTA模型进行评测。

Result: 发现模型对允许类请求准确率>95%，但对禁止类对抗请求仅能拒绝13%-40%，存在严重不对称性；当前LLM在政策关键型部署中缺乏足够鲁棒性。

Conclusion: COMPASS是首个面向组织政策对齐的系统性评估框架，实证表明现有LLM难以满足企业级政策合规要求，亟需更可靠的对齐机制，该框架应成为组织AI安全评测的必备工具。

Abstract: As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.

</details>


### [288] [Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01844)
*Udiptaman Das,Krishnasai B. Atmakuri,Duy Ho,Chi Lee,Yugyung Lee*

Main category: cs.AI

TL;DR: 本文提出了一种面向临床文本（特别是肿瘤学）的端到端知识图谱构建与评估框架，结合多智能体提示、schema约束的RAG（KG-RAG）及多LLM共识验证，显著提升事实准确性与语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖结构化输入，缺乏对事实准确性和语义一致性的鲁棒验证，尤其在肿瘤学等高风险领域问题突出。

Method: 提出多阶段框架：(1) 提示驱动的实体/属性/关系抽取；(2) 基于熵的不确定性评分；(3) 本体对齐的RDF/OWL模式生成；(4) 多LLM共识验证以检测幻觉并精炼语义；支持持续自监督优化。

Result: 在PDAC和BRCA两个肿瘤队列上构建出可解释、SPARQL兼容、临床可信的知识图谱，无需金标准标注；实验显示精度、相关性与本体合规性均优于基线方法。

Conclusion: 该框架有效克服了LLM在临床KG构建中易产生幻觉和语义漂移的问题，为高可靠性医学知识建模提供了新范式。

Abstract: Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.

</details>


### [289] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)
*Defei Xia,Bingfeng Pi,Shenbin Zhang,Song Hua,Yunfei Wei,Lei Zuo*

Main category: cs.AI

TL;DR: 本文提出了一种基于实际应用经验的LLM智能体框架Jenius-Agent，通过自适应提示生成、上下文感知的工具编排和分层记忆机制三大创新，显著提升了任务准确性（+20%），并降低了token消耗、响应延迟和调用失败率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在内部推理与工具使用流程的系统性优化方面仍显不足，尤其在上下文理解、工具调用和响应生成等关键任务性能上亟待提升。

Method: 提出Jenius-Agent框架，包含：(1) 自适应提示生成策略；(2) 上下文感知的工具编排模块（支持工具分类、语义检索与自适应调用）；(3) 融合会话记忆、任务历史与外部摘要的分层记忆机制；并集成MCP协议工具、文件I/O与执行反馈。

Result: 实验显示任务准确率提升20%，同时降低token成本、响应延迟和工具调用失败率；该框架已部署于Jenius平台，提供轻量、可扩展、协议兼容的自主智能体解决方案。

Conclusion: 该框架通过面向真实场景的系统性设计，在保持轻量化与兼容性的同时，显著增强了LLM智能体的鲁棒性、可靠性与效率，为实用化智能体开发提供了新范式。

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.

</details>


### [290] [Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence](https://arxiv.org/abs/2601.01875)
*Kewen Cao,Jianxu Chen,Yongbing Zhang,Ye Zhang,Hongxiao Wang*

Main category: cs.AI

TL;DR: 本文提出一种以SQL为中心的智能体框架，通过可执行SQL查询对病理图像中的细胞特征进行量化分析与知识比对，从而提升模型决策的可解释性与可追溯性。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要理解AI模型诊断决策背后的病理图像特征依据，而现有视觉语言模型生成的自然语言解释多为相关性描述，缺乏可验证的证据支持。

Method: 构建基于SQL的智能体框架：首先提取人类可理解的细胞级特征；然后由特征推理智能体（Feature Reasoning Agents）在特征表上构造并执行SQL查询，聚合视觉证据形成定量发现；最后由知识比对智能体（Knowledge Comparison Agent）将这些发现与既定病理学知识进行比对，模拟病理医生从可观测指标出发进行诊断推理的过程。

Result: 在两个病理视觉问答数据集上的大量实验表明，该方法显著提升了模型的可解释性和决策可追溯性，并生成可执行的SQL追踪链，明确关联细胞测量结果与诊断结论。

Conclusion: 以SQL为中介的结构化推理机制能有效桥接低层视觉特征与高层医学知识，为可信AI辅助病理诊断提供了可审计、可验证的新范式。

Abstract: Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.

</details>


### [291] [Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs](https://arxiv.org/abs/2601.01878)
*Farzan Karimi-Malekabadi,Suhaib Abdurahman,Zhivar Sourati,Jackson Trager,Morteza Dehghani*

Main category: cs.AI

TL;DR: 本文指出社会认知评估中缺乏明确理论基础的问题，提出Theory Trace Card (TTC) 作为轻量级文档工具，以显式呈现评估的理论依据、能力构成、操作化方式及局限性，从而提升评估的可解释性与复用性。


<details>
  <summary>Details</summary>
Motivation: 现有社会认知基准测试常因缺乏对目标能力的明确理论界定，导致高分结果被错误泛化为广泛能力证据，形成系统性效度幻觉。

Method: 诊断并形式化‘理论缺口’问题；提出Theory Trace Card（TTC）这一标准化文档框架，要求明确说明理论基础、能力维度、任务操作化、评分逻辑与局限性。

Result: TTC能显式呈现从理论到评估的完整效度链，不改变原有基准，也不强求理论统一，即可提升评估的透明性、可解释性与跨研究复用性。

Conclusion: 社会认知评估必须以显式理论规范为前提；TTC是一种可行、低负担的实践方案，可从根本上缓解效度幻觉问题，推动更稳健的LLM能力评估。

Abstract: Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.

</details>


### [292] [MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning](https://arxiv.org/abs/2601.01910)
*Minh Hieu Ha,Khanh Ly Ta,Hung Phan,Tung Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: 本文提出MMP-A*，一种结合视觉-语言模型空间感知能力与自适应衰减机制的多模态路径规划框架，解决了纯文本大模型在复杂环境中生成错误航点的问题，实现了近似最优路径与更低计算开销的平衡。


<details>
  <summary>Details</summary>
Motivation: 经典A*算法在大规模场景中计算和内存开销过高；现有基于大语言模型的航点规划方法缺乏空间 grounding，难以处理拓扑复杂环境和物理边界模糊问题，导致航点错误和效率下降。

Method: 提出MMP-A*框架：1）利用视觉-语言模型实现空间 grounding，将高层推理锚定于物理几何；2）设计自适应衰减机制，动态调节不确定航点在启发式函数中的影响，保障几何有效性并降低内存占用。

Result: 在严重杂乱与高拓扑复杂度环境中实验表明，MMP-A*能生成近似最优轨迹，显著降低运行成本（如内存与纠错开销）。

Conclusion: MMP-A*是一种感知驱动、计算高效的新范式，为自主导航提供了兼具几何精度与全局推理能力的可行路径规划方案。

Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.

</details>


### [293] [OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation](https://arxiv.org/abs/2601.01939)
*Victor Sanchez,Chris Reinke,Ahamed Mohamed,Xavier Alameda-Pineda*

Main category: cs.AI

TL;DR: 本文介绍了OpenSocInt，一个用于多模态社交交互模拟和社交智能体训练的开源软件包，并通过社交导航任务验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 为支持多模态社交交互建模与社交智能体训练，需一个灵活、开源且可扩展的仿真与训练框架。

Method: 开发了OpenSocInt开源软件包，包含多模态社交交互模拟器和模块化智能体训练架构，并设计基于社交导航任务的实验协议进行验证。

Result: 实现了支持不同感知特征提取、编码与融合，以及多种智能体配置的可扩展框架；软件已按GPL协议开源发布。

Conclusion: OpenSocInt为社交智能体研究提供了实用、开放且模块化的工具平台，有助于推动多模态社交交互的建模与评估。

Abstract: In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.

</details>


### [294] [CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes](https://arxiv.org/abs/2601.01976)
*Yasmine Souissi,Fabrice Boissier,Nida Meddouri*

Main category: cs.AI

TL;DR: 本文综述了基于形式概念分析（FCA）的分类器的最新研究进展，提出了一种构建聚焦于最相关概念的部分概念格的新方法，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 形式概念分析（FCA）因其可解释性和可理解性在分类任务中具有优势，但其计算复杂度高、概念格规模大，限制了实际应用；因此需要更高效、聚焦关键概念的FCA分类方法。

Method: 回顾现有FCA分类器；提出一种从名义数据计算闭包算子的多种方法；设计一种构建部分概念格的新方法，仅保留最相关的概念；通过实验评估该方法的效率。

Result: 所提出的部分概念格构建方法在保持分类性能的同时显著提升了计算效率；实验结果验证了其在多个数据集上的有效性与可行性。

Conclusion: 基于FCA的分类器在可解释机器学习中具有重要价值；本文提出的方法为降低FCA计算开销、提升实用性提供了新思路，推动了FCA在知识发现中的应用。

Abstract: Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.

</details>


### [295] [ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems](https://arxiv.org/abs/2601.01982)
*Noel Thomas*

Main category: cs.AI

TL;DR: 本文提出了ChaosBench-Logic基准，用于评估大语言模型在混沌动力系统这一高难度逻辑与符号推理任务上的表现；实验表明当前前沿模型虽在单题准确率上较高（91–94%），但在组合推理和对话级一致性上仍严重不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言任务上表现出色，但在需要精确逻辑与符号推理的领域（如混沌动力系统）仍很脆弱；混沌系统是理想测试场景，因其确定性却常被误读为随机性或复杂性。

Method: 构建了统一的一阶逻辑（FOL）本体，覆盖30种不同混沌动力系统，每系统标注11个语义谓词的真值，并生成621道涵盖多跳推理、跨系统类比、反事实推理、偏差探测和多轮对话等七类问题；定义了逻辑准确性、蕴含一致性、对话连贯性与矛盾检测等评估指标，并开源评估流程。

Result: GPT-4、Claude 3.5 Sonnet、Gemini 2.5 Flash 和 LLaMA-3 70B 在单题准确率上达91–94%，但组合类题目得分为0%；对话级准确率介于53.1%（GPT-4思维链）至75.5%（LLaMA-3零样本）之间。

Conclusion: ChaosBench-Logic为诊断大语言模型在科学推理中的失败提供了严格测试平台，也为发展提升其逻辑能力的神经符号融合方法奠定了基础。

Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.

</details>


### [296] [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)
*Dong Xue,Jicheng Tu,Ming Wang,Xin Yan,Fangzhou Liu,Jie Hu*

Main category: cs.AI

TL;DR: 本文提出MindChat，一个面向心理健康支持的隐私保护大语言模型，以及通过多智能体角色扮演框架构建的合成多轮心理咨询数据集MindCorpus；采用双闭环反馈机制提升数据质量，并结合联邦学习与差分隐私优化保障用户隐私；实验表明其在咨询能力与隐私保护方面均优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在心理健康支持中潜力巨大，但真实心理咨询对话数据稀缺且敏感，制约了模型训练。

Method: 提出多智能体角色扮演框架构建合成数据集MindCorpus，含轮级批评-修订和会话级策略优化的双闭环反馈机制；采用联邦学习结合LoRA适配器微调，并引入差分隐私优化以降低成员推断与记忆风险。

Result: MindCorpus提升了训练有效性；MindChat在自动评估与人工评估下均媲美甚至超越通用及心理咨询专用大模型基线，且在成员推断攻击下隐私泄露更少。

Conclusion: MindChat与MindCorpus为兼顾高质量心理咨询能力与严格隐私保护的大模型研发提供了可行范式。

Abstract: Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.

</details>


### [297] [XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging](https://arxiv.org/abs/2601.02008)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

TL;DR: XAIMeD 是一种融合临床知识的神经符号医疗AI框架，旨在提升模型在分布偏移下的泛化能力、罕见病类别的识别鲁棒性及临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决医学AI中可解释性、域泛化能力差及罕见病类别可靠性低等关键挑战，尤其应对真实世界中的数据分布偏移和临床类别不平衡问题。

Method: 提出XAIMeD框架：将临床专家知识编码为原子医学命题上的逻辑连接，生成类别特异性、机器可验证规则；引入加权特征满足度评分驱动符号推理分支；采用基于熵不平衡增益（EIG）与罕见类Gini指数的Hunt式自适应路由机制进行置信加权融合。

Result: 在四个多模态医学任务（如SOZ定位、糖尿病视网膜病变分级）上显著优于SOTA：跨域泛化性能提升6%，罕见类F1分数提高10%；消融实验证明符号模块有效增强分布鲁棒性。

Conclusion: XAIMeD提供了一种以临床为本、原理清晰且可解释的多模态医学AI新范式。

Abstract: Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.

</details>


### [298] [Simulated Reasoning is Reasoning](https://arxiv.org/abs/2601.02043)
*Hendrik Kempt,Alon Lavie*

Main category: cs.AI

TL;DR: 本文探讨了基础模型（FM）如何通过模仿“出声思考”等方式实现推理，指出这种推理虽能解决任务但缺乏人类推理的根基与常识，因而具有脆弱性；文章批判了‘随机鹦鹉’隐喻的过时性，并从哲学角度反思其安全性和适用性规范。


<details>
  <summary>Details</summary>
Motivation: 重新评估基础模型所展现的推理能力及其与人类推理的本质差异，挑战传统对推理必要条件的理解，并探讨由此引发的安全与规范问题。

Method: 哲学分析与概念反思，结合对基础模型行为特征的观察，批判性地审视现有隐喻（如‘随机鹦鹉’）并提出新的解释框架。

Result: 揭示FM的推理是一种无根基、依赖模式模仿的脆弱过程；论证‘随机鹦鹉’隐喻已不适用；提出需建立新的安全性与适当性规范框架。

Conclusion: 基础模型的推理现象要求我们更新对推理本质的哲学理解，并推动构建更稳健、更具规范意识的人工智能治理路径。

Abstract: Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., "symbolic reasoning". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can "reason" by way of imitating the process of "thinking out loud", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the "stochastic parrot" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.

</details>


### [299] [Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management](https://arxiv.org/abs/2601.02061)
*Faizan Ahmed,Aniket Dixit,James Brusey*

Main category: cs.AI

TL;DR: 本文研究了通过高阶导数惩罚（如加速度、急动度）来正则化深度强化学习的动作输出，以提升控制平滑性，减少能耗和机械磨损，并在建筑能源管理（如HVAC系统）中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习智能体常表现出高频、不稳定的控制行为，导致实际部署中能耗高、设备磨损严重，亟需提升动作平滑性以满足现实约束。

Method: 系统研究基于高阶导数（一阶至三阶）的动作平滑正则化方法，在连续控制基准任务中进行理论分析，并在建筑能源管理（特别是HVAC控制）中开展实践验证。

Result: 第三阶导数惩罚（即最小化jerk）在多个连续控制环境中始终实现最优平滑性且性能不降；在HVAC系统中使设备开关次数减少60%，显著提升运行效益。

Conclusion: 高阶动作正则化是连接强化学习优化目标与能源关键应用中实际运行约束的有效桥梁。

Abstract: Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.

</details>


### [300] [FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations](https://arxiv.org/abs/2601.02071)
*Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLMs）在药物3D打印中的应用，特别是基于FDM技术的处方开发，通过微调四种LLM架构，发现Llama2在辅料推荐任务中表现最佳，同时指出小模型易出现灾难性遗忘、标准指标不适用于工艺可行性评估等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法在制药3D打印中过于狭窄，未充分考虑整体处方开发挑战；新兴的通用人工智能（AGI）理念启发研究者探索LLMs在更广义药学推理中的潜力。

Method: 对四种LLM架构（含Llama2）在包含1400+种FDM制剂的数据集上进行微调，用于API剂量依赖的辅料推荐和线材力学性能预测，并系统评估微调策略与生成参数配置的影响。

Result: Llama2在辅料推荐任务中性能最优；模型规模与参数配置显著影响性能，小模型存在灾难性遗忘现象；仅1400余条数据即可引发遗忘；标准LLM评测指标无法反映制剂工艺可行性；生物医学预训练模型未必适用于本任务。

Conclusion: 需超越语言能力评估，构建面向制药工艺可靠性的LLM评估与优化框架，以推动其在个性化制剂开发中的实际应用。

Abstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.

</details>


### [301] [EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning](https://arxiv.org/abs/2601.02163)
*Chuanrui Hu,Xingze Gao,Zuyi Zhou,Dannong Xu,Yi Bai,Xintong Li,Hui Zhang,Tong Li,Chong Zhang,Lidong Bing,Yafeng Deng*

Main category: cs.AI

TL;DR: 本文提出EverMemOS，一种受神经科学启发的自组织记忆操作系统，通过记忆细胞（MemCells）和记忆场景（MemScenes）实现对长程交互中用户状态的持续建模与一致性推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型上下文窗口有限，难以在长期交互中维持行为一致性；现有记忆系统缺乏对用户状态演化建模与冲突消解能力。

Method: 提出三阶段记忆生命周期：1）情景痕迹形成（生成MemCells，含情节、事实与前瞻性信号）；2）语义巩固（聚类MemCells为MemScenes，更新用户画像）；3）重构性回忆（基于MemScenes进行任务导向的精准检索）。

Result: 在LoCoMo和LongMemEval基准上达到记忆增强推理的SOTA；在PersonaMem v2上验证用户画像能力，并通过案例研究展示前瞻性建模等聊天能力。

Conclusion: EverMemOS为LLM作为长期交互代理提供了可扩展、自组织且认知启发的记忆架构，显著提升长程一致性与用户感知能力。

Abstract: Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.

</details>


### [302] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

TL;DR: 本文提出了一种将长链式思维（CoT）推理中的幻觉视为随步骤演化的潜在状态的新视角，并设计了基于前缀累积的全局幻觉信号，实现流式、实时、可解释的幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 长链式思维推理中幻觉常隐晦发生并逐步传播，传统将其视为单次错误事件的方法难以有效捕捉和抑制。

Method: 将每步幻觉判断视为局部观测，构建累积的前缀级幻觉信号，以跟踪整个推理轨迹中推理状态的全局演化。

Result: 实现了对长CoT推理过程的流式幻觉检测，提供实时且可解释的检测证据。

Conclusion: 幻觉应被建模为演化的潜在状态；所提前缀级累积信号方法提升了长CoT推理中幻觉检测的及时性与可解释性。

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


### [303] [Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents](https://arxiv.org/abs/2601.02314)
*Sourena Khanzadeh*

Main category: cs.AI

TL;DR: 本文提出Project Ariadne框架，利用结构因果模型与反事实逻辑，通过硬干预推理节点来审计大语言模型代理推理的因果一致性，发现广泛存在的‘因果解耦’现象，揭示当前CoT推理常为事后的合理化而非真实决策依据。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型代理在高风险场景中自主决策增多，其推理过程是否真实驱动输出（即‘忠实性’）成为关键安全问题；现有CoT提示虽生成可读推理链，但难以判断其是真实原因还是事后解释。

Method: 提出Project Ariadne可解释AI框架，基于结构因果模型（SCM）和do-演算实施对中间推理节点的硬干预（如逻辑反转、前提否定、事实颠倒），定义并量化‘因果敏感度φ’以评估终端答案对推理链的依赖程度。

Result: 实证发现主流模型普遍存在‘忠实性鸿沟’，尤其在科学与事实领域存在高发‘因果解耦’（违反密度ρ达0.77）：即使推理链被系统性篡改，模型仍输出相同答案，表明推理仅为‘推理剧场’，决策实际由隐式参数先验主导。

Conclusion: 当前LLM代理架构内在易产生不忠实解释；应以新提出的Ariadne Score作为衡量推理链与实际决策对齐程度的基准指标。

Abstract: As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \textbf{faithful} generative drivers of the model's output or merely \textbf{post-hoc rationalizations}. We introduce \textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as "Reasoning Theater" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.

</details>


### [304] [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)
*Falcon LLM Team,Iheb Chaabane,Puneesh Khanna,Suhail Mohmad,Slim Frikha,Shi Hu,Abdalgader Abubaker,Reda Alami,Mikhail Lubinets,Mohamed El Amine Seddik,Hakim Hacid*

Main category: cs.AI

TL;DR: Falcon-H1R是一个7B参数的推理优化小语言模型，通过精细的数据筛选、高效监督微调（SFT）和强化学习（RL）缩放策略，在多项推理密集型基准上媲美甚至超越2–7倍参数规模的SOTA模型；其混合并行架构兼顾推理速度、token效率与准确率，并结合DeepConf实现SOTA级测试时缩放效率。


<details>
  <summary>Details</summary>
Motivation: 探索小语言模型（SLMs）在不增大参数规模的前提下实现强推理能力的可行性，突破大模型对算力与资源的依赖瓶颈。

Method: 提出Falcon-H1R模型，采用混合并行架构设计以提升推理速度；结合高质量数据筛选、高效监督微调（SFT）与强化学习（RL）缩放策略；并集成DeepConf方法以增强测试时缩放效率。

Result: 在多种推理密集型基准上，Falcon-H1R-7B稳定达到或超越参数量2–7倍的SOTA模型；实现更快推理、更高token效率与准确率；达成当前最优的测试时缩放效率，在准确率与计算成本间取得显著平衡。

Conclusion: 紧凑模型通过针对性训练策略与架构设计，可在推理性能、效率与可扩展性上实现与大模型相当甚至更优的表现，为轻量化、高性价比推理系统提供了可行路径。

Abstract: This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [305] [A Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System for Advertisement Retrieval and Personalization](https://arxiv.org/abs/2601.00833)
*Tangtang Wang,Kaijie Zhang,Kuangcong Liu*

Main category: cs.IR

TL;DR: 本文提出KGSR-ADS系统，融合广告知识图谱、大语言模型语义嵌入、图神经网络+注意力机制及向量数据库检索，实现高精度、可扩展的语义化广告推荐。


<details>
  <summary>Details</summary>
Motivation: 现代数字营销中广告数据日益复杂，亟需能理解产品、受众与广告内容间语义关系的智能系统。

Method: 构建异构广告知识图谱（Ad-KG），结合LLM（如GPT、LLaMA）生成上下文感知语义嵌入，采用GNN+Attention建模跨实体依赖，并基于FAISS/Milvus实现向量索引与高效语义检索。

Result: 该分层架构支持准确语义匹配与大规模异构负载下的高效个性化广告推荐。

Conclusion: KGSR-ADS系统有效提升了广告检索与个性化推荐的语义理解能力与可扩展性，为智能广告系统提供了新范式。

Abstract: In modern digital marketing, the growing complexity of advertisement data demands intelligent systems capable of understanding semantic relationships among products, audiences, and advertising content. To address this challenge, this paper proposes a Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System (KGSR-ADS) for advertisement retrieval and personalization. The proposed framework integrates a heterogeneous Ad-Knowledge Graph (Ad-KG) that captures multi-relational semantics, a Semantic Embedding Layer that leverages large language models (LLMs) such as GPT and LLaMA to generate context-aware vector representations, a GNN + Attention Model that infers cross-entity dependencies, and a Database Optimization & Retrieval Layer based on vector indexing (FAISS/Milvus) for efficient semantic search. This layered architecture enables both accurate semantic matching and scalable retrieval, allowing personalized ad recommendations under large-scale heterogeneous workloads.

</details>


### [306] [Enhancing Retrieval-Augmented Generation with Topic-Enriched Embeddings: A Hybrid Approach Integrating Traditional NLP Techniques](https://arxiv.org/abs/2601.00891)
*Rodrigo Kataishi*

Main category: cs.IR

TL;DR: 本文提出了一种主题增强嵌入方法，融合TF-IDF、LSA/LDA主题建模与轻量级上下文编码器（all-MiniLM），以提升重叠主题场景下的检索质量，尤其在法律文本中验证了其在聚类一致性与检索精度上的提升。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在主题重叠高、语义变异性大的语料中检索质量下降，需更好兼顾词汇级与主题级语义信息。

Method: 将TF-IDF、LSA和LDA提取的主题结构与all-MiniLM的句子嵌入进行融合，构建紧凑且语义丰富的主题增强嵌入表示。

Result: 在法律文本语料上实验表明，该方法提升了语义聚类一致性与检索精度（如召回率、MRR），同时降低计算开销。

Conclusion: 主题增强嵌入是一种实用、高效的方法，可增强知识密集型RAG系统的鲁棒性与可靠性。

Abstract: Retrieval-augmented generation (RAG) systems rely on accurate document retrieval to ground large language models (LLMs) in external knowledge, yet retrieval quality often degrades in corpora where topics overlap and thematic variation is high. This work proposes topic-enriched embeddings that integrate term-based signals and topic structure with contextual sentence embeddings. The approach combines TF-IDF with topic modeling and dimensionality reduction, using Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) to encode latent topical organization, and fuses these representations with a compact contextual encoder (all-MiniLM). By jointly capturing term-level and topic-level semantics, topic-enriched embeddings improve semantic clustering, increase retrieval precision, and reduce computational burden relative to purely contextual baselines. Experiments on a legal-text corpus show consistent gains in clustering coherence and retrieval metrics, suggesting that topic-enriched embeddings can serve as a practical component for more reliable knowledge-intensive RAG pipelines.

</details>


### [307] [The Discovery Gap: How Product Hunt Startups Vanish in LLM Organic Discovery Queries](https://arxiv.org/abs/2601.00912)
*Amit Prakash Sharma*

Main category: cs.IR

TL;DR: 本研究测试了112家初创公司在ChatGPT和Perplexity中被AI推荐的可见性，发现命名查询识别率高（>94%），但发现式查询（如'今年最佳AI工具'）推荐率极低（<8.3%）；GEO（生成式引擎优化）无效，而传统SEO指标（如反向链接、Product Hunt排名、Reddit社区活跃度）显著预测LLM可见性。


<details>
  <summary>Details</summary>
Motivation: 探究初创公司新产品在主流大语言模型（如ChatGPT、Perplexity）中能否被自然发现，尤其关注其在非精确命名查询下的曝光能力，以指导创业者的市场策略。

Method: 对Product Hunt 2025榜单前500中的112家初创公司，共发起2240次查询（覆盖命名型与发现型问题），分别调用ChatGPT（gpt-4o-mini）和Perplexity（sonar+web search）；统计产品出现率，并分析GEO得分、SEO指标（反向域名数、Product Hunt排名）、Reddit社区数据与LLM可见性的相关性。

Result: 命名查询识别率极高（ChatGPT 99.4%，Perplexity 94.3%），但发现式查询推荐率骤降至3.32%和8.29%；GEO得分与实际发现率无显著相关性；Perplexity可见性与传统SEO指标显著正相关（如 referring domains r=+0.319，Reddit社区 r=+0.395）。

Conclusion: 直接针对LLM做GEO无效；提升LLM自然发现效果的关键在于夯实传统SEO基础（如外链建设、平台排名、真实社区参与），LLM可见性是SEO健康的副产品。

Abstract: When someone asks ChatGPT to recommend a project management tool, which products show up in the response? And more importantly for startup founders: will their newly launched product ever appear? This research set out to answer these questions.
  I randomly selected 112 startups from the top 500 products featured on the 2025 Product Hunt leaderboard and tested each one across 2,240 queries to two different large language models: ChatGPT (gpt-4o-mini) and Perplexity (sonar with web search).
  The results were striking. When users asked about products by name, both LLMs recognized them almost perfectly: 99.4% for ChatGPT and 94.3% for Perplexity. But when users asked discovery-style questions like "What are the best AI tools launched this year?" the success rates collapsed to 3.32% and 8.29% respectively. That's a gap of 30-to-1 for ChatGPT.
  Perhaps the most surprising finding was that Generative Engine Optimization (GEO), the practice of optimizing website content for AI visibility, showed no correlation with actual discovery rates. Products with high GEO scores were no more likely to appear in organic queries than products with low scores.
  What did matter? For Perplexity, traditional SEO signals like referring domains (r = +0.319, p < 0.001) and Product Hunt ranking (r = -0.286, p = 0.002) predicted visibility. After cleaning the Reddit data for false positives, community presence also emerged as significant (r = +0.395, p = 0.002).
  The practical takeaway is counterintuitive: don't optimize for AI discovery directly. Instead, build the SEO foundation first and LLM visibility will follow.

</details>


### [308] [MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers](https://arxiv.org/abs/2601.00926)
*Satya Swaroop Gudipudi,Sahil Girhepuje,Ponnurangam Kumaraguru,Kristine Ma*

Main category: cs.IR

TL;DR: 本文提出Metadata-Aware Cross-Model Alignment (MACA)，通过将元数据感知的LLM重排序器知识蒸馏至轻量级检索器，实现高效、低成本的企业级短查询检索，避免在线调用大模型。


<details>
  <summary>Details</summary>
Motivation: 现代企业检索系统需处理语义模糊、信息不足的短查询，而逐查询使用大语言模型（LLM）重排序或人工标注成本高昂；需兼顾语义细微差别与元数据信息。

Method: 提出MACA框架：设计元数据感知提示以校验教师模型（LLM重排序器）的可信性（如置换一致性与改写鲁棒性），生成列表级分数、难负样本和校准的相关性间隔；学生模型通过MetaFusion目标函数训练，联合优化元数据条件排序损失与跨模型间隔损失。

Result: 在自有银行FAQ语料和BankFAQs上，MACA教师模型Accuracy@1分别比MAFA基线高5和3个百分点；学生模型（如MiniLM）Accuracy@1从0.23提升至0.48，且无需在线LLM调用，支持RAG。

Conclusion: MACA有效实现了LLM重排序能力向轻量检索器的知识蒸馏，在保持高性能的同时显著降低推理开销，适用于实际企业检索场景。

Abstract: Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.

</details>


### [309] [AlignUSER: Human-Aligned LLM Agents via World Models for Recommender System Evaluation](https://arxiv.org/abs/2601.00930)
*Nicolas Bougie,Gian Maria Marconi,Tony Yip,Narimasa Watanabe*

Main category: cs.IR

TL;DR: 本文提出AlignUSER框架，利用世界模型驱动的LLM代理，通过学习人类交互数据并结合反事实轨迹对比，提升合成用户对真实用户行为的建模能力，从而更准确地评估推荐系统。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的合成用户依赖少样本提示，对环境理解浅、行为拟真度低；同时离线评估指标与真实用户行为存在差距，且交互数据稀缺。

Method: 将世界建模形式化为下一状态预测任务，使代理内化环境；生成围绕人类示范的反事实轨迹，让LLM对比自身决策与人类选择、识别次优动作并提取经验；最终用所学策略驱动代理与推荐系统交互。

Result: 在多个数据集上验证，AlignUSER在微观（单次交互）和宏观（整体行为模式）层面均比以往方法更贴近真实人类行为。

Conclusion: AlignUSER通过世界建模与反事实对齐机制，显著提升了合成用户的行为保真度，为推荐系统的可信评估提供了新范式。

Abstract: Evaluating recommender systems remains challenging due to the gap between offline metrics and real user behavior, as well as the scarcity of interaction data. Recent work explores large language model (LLM) agents as synthetic users, yet they typically rely on few-shot prompting, which yields a shallow understanding of the environment and limits their ability to faithfully reproduce user actions. We introduce AlignUSER, a framework that learns world-model-driven agents from human interactions. Given rollout sequences of actions and states, we formalize world modeling as a next state prediction task that helps the agent internalize the environment. To align actions with human personas, we generate counterfactual trajectories around demonstrations and prompt the LLM to compare its decisions with human choices, identify suboptimal actions, and extract lessons. The learned policy is then used to drive agent interactions with the recommender system. We evaluate AlignUSER across multiple datasets and demonstrate closer alignment with genuine humans than prior work, both at the micro and macro levels.

</details>


### [310] [ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services](https://arxiv.org/abs/2601.01118)
*Qingqing Long,Haotian Chen,Chenyang Zhao,Xiaolei Du,Xuezhi Wang,Pengyao Wang,Chengzan Li,Yuanchun Zhou,Hengshu Zhu*

Main category: cs.IR

TL;DR: 本文提出ScienceDB AI，一个基于大语言模型（LLM）的对话式科学数据集推荐系统，旨在解决科学数据共享中语义理解难、个性化推荐不足和可信度低等问题。


<details>
  <summary>Details</summary>
Motivation: 科学数据集具有强领域特性和复杂上下文，传统协同过滤推荐方法难以有效建模；同时，科研人员对数据推荐的可解释性、可信性和动态需求适配能力要求高。

Method: 构建了ScienceDB AI系统，包含三个核心模块：1）Scientific Intention Perceptor——从自然语言查询中抽取结构化实验要素；2）Structured Memory Compressor——压缩多轮对话记忆以支持持续交互；3）Trustworthy RAG框架——采用两阶段检索与CSTR标识符支持可引用、可复现的数据推荐。

Result: 在超千万真实科学数据集上开展离线与在线实验，验证了系统在推荐准确性、用户满意度及任务完成率上的显著提升；成为首个面向大规模科学数据共享平台的LLM驱动对话推荐系统。

Conclusion: ScienceDB AI为AI for Science中的数据发现与重用提供了新范式，推动科学数据服务向智能化、可信赖和人本交互方向发展。

Abstract: The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.

</details>


### [311] [Adaptive Diffusion-based Augmentation for Recommendation](https://arxiv.org/abs/2601.01448)
*Na Li,Fanghui Sun,Yan Zou,Yangfu Zhu,Xiatian Zhu,Ying Ma*

Main category: cs.IR

TL;DR: 本文提出ADAR方法，利用扩散模型生成可控的负样本，以解决推荐系统中隐式反馈下负采样不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 现有负采样方法易将潜在正样本误标为负样本，且缺乏对负样本选择的精确控制。

Method: 提出基于自适应扩散的增强方法ADAR，利用扩散过程模拟从正样本到负样本的连续过渡，并通过理论分析确定正负转换点，设计分数感知函数自适应选择最优采样时间步。

Result: ADAR在协同过滤和序列推荐等任务上显著提升现有模型性能，且无需修改模型结构，具有良好的通用性。

Conclusion: ADAR是一种模型无关、可控性强的负样本生成模块，能有效优化推荐模型的决策边界。

Abstract: Recommendation systems often rely on implicit feedback, where only positive user-item interactions can be observed. Negative sampling is therefore crucial to provide proper negative training signals. However, existing methods tend to mislabel potentially positive but unobserved items as negatives and lack precise control over negative sample selection. We aim to address these by generating controllable negative samples, rather than sampling from the existing item pool. In this context, we propose Adaptive Diffusion-based Augmentation for Recommendation (ADAR), a novel and model-agnostic module that leverages diffusion to synthesize informative negatives. Inspired by the progressive corruption process in diffusion, ADAR simulates a continuous transition from positive to negative, allowing for fine-grained control over sample hardness. To mine suitable negative samples, we theoretically identify the transition point at which a positive sample turns negative and derive a score-aware function to adaptively determine the optimal sampling timestep. By identifying this transition point, ADAR generates challenging negative samples that effectively refine the model's decision boundary. Experiments confirm that ADAR is broadly compatible and boosts the performance of existing recommendation models substantially, including collaborative filtering and sequential recommendation, without architectural modifications.

</details>


### [312] [Breadcrumbs in the Digital Forest: Tracing Criminals through Torrent Metadata with OSINT](https://arxiv.org/abs/2601.01492)
*Annelies de Jong,Giuseppe Cascavilla,Jessica De Pascale*

Main category: cs.IR

TL;DR: 本文探讨了利用BitTorrent等P2P网络的公开元数据（如tracker响应、种子索引、IP信息）进行开源情报（OSINT）分析的可行性，提出一种五步OSINT流程，通过收集与丰富6万多个IP地址数据，识别高风险用户行为模式（如涉儿童剥削内容下载、隐私工具使用、共下载集群），验证其在执法与威胁分析中的实用价值。


<details>
  <summary>Details</summary>
Motivation: 尽管BitTorrent等P2P网络在隐私和性能方面已被广泛研究，但其公开元数据尚未被系统用于OSINT目的；本文旨在填补这一空白，探索其在用户画像与高风险行为识别中的潜力。

Method: 采用五步OSINT流程：源识别→数据采集（来自The Pirate Bay和UDP tracker）→数据增强（含地理定位、匿名化状态、涉儿童剥削材料标识）→行为分析（网络聚类、共下载模式、隐私工具使用检测）→结果呈现；基于206个热门种子构建含6万余唯一IP的数据集，并开展敏感电子书案例研究。

Result: 发现可疑用户存在明显peer clustering、共下载行为及更高频使用隐私工具；可自动识别涉非法内容兴趣（如特定敏感e-book下载群体）；证实公开torrent元数据可用于可扩展、自动化的OSINT用户画像。

Conclusion: torrent元数据是被低估的OSINT资源；本文提出的框架为数字取证提供了新方法，支持执法、网络安全与威胁分析中从噪声数据中提取高价值信号。

Abstract: This work investigates the potential of torrent metadata as a source for open-source intelligence (OSINT), with a focus on user profiling and behavioral analysis. While peer-to-peer (P2P) networks such as BitTorrent are well studied with respect to privacy and performance, their metadata is rarely used for investigative purposes. This work presents a proof of concept demonstrating how tracker responses, torrent index data, and enriched IP metadata can reveal patterns associated with high-risk behavior.
  The research follows a five-step OSINT process: source identification, data collection, enrichment, behavioral analysis, and presentation of the results. Data were collected from The Pirate Bay and UDP trackers, yielding a dataset of more than 60,000 unique IP addresses across 206 popular torrents. The data were enriched with geolocation, anonymization status, and flags of involvement in child exploitation material (CEM). A case study on sensitive e-books shows how such data can help detect possible interest in illicit content.
  Network analysis highlights peer clustering, co-download patterns, and the use of privacy tools by suspicious users. The study shows that publicly available torrent metadata can support scalable and automated OSINT profiling.
  This work adds to digital forensics by proposing a new method to extract useful signals from noisy data, with applications in law enforcement, cybersecurity, and threat analysis.

</details>


### [313] [OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment](https://arxiv.org/abs/2601.01576)
*Ming Zhang,Kexin Tan,Yueyuan Huang,Yujiong Shen,Chunchun Ma,Li Ju,Xinran Zhang,Yuhui Wang,Wenqing Jing,Jingyi Deng,Huayu Sha,Binze Hu,Jingqi Tong,Changhao Jiang,Yage Geng,Yuankai Ying,Yue Zhang,Zhangyue Yin,Zhiheng Xi,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.IR

TL;DR: 本文提出了OpenNovelty，一个基于大语言模型的智能体系统，用于透明、基于证据的新颖性评估，通过检索真实论文并进行结构化比对生成可验证的新颖性报告。


<details>
  <summary>Details</summary>
Motivation: 评审中评估新颖性至关重要但困难，因需对照海量且快速演进的文献；现有LLM方法缺乏可验证性。

Method: OpenNovelty包含四阶段：（1）提取任务与贡献主张以生成检索查询；（2）语义搜索检索相关先验工作；（3）构建任务相关工作的分层分类，并逐项比对贡献全文；（4）整合分析生成带引文与证据片段的结构化报告。

Result: 在500+篇ICLR 2026投稿上部署，报告公开；初步分析显示其能识别作者可能忽略的密切相关工作。

Conclusion: OpenNovelty是一个可扩展、可验证、促进公平一致同行评审的开源工具。

Abstract: Evaluating novelty is critical yet challenging in peer review, as reviewers must assess submissions against a vast, rapidly evolving literature. This report presents OpenNovelty, an LLM-powered agentic system for transparent, evidence-based novelty analysis. The system operates through four phases: (1) extracting the core task and contribution claims to generate retrieval queries; (2) retrieving relevant prior work based on extracted queries via semantic search engine; (3) constructing a hierarchical taxonomy of core-task-related work and performing contribution-level full-text comparisons against each contribution; and (4) synthesizing all analyses into a structured novelty report with explicit citations and evidence snippets. Unlike naive LLM-based approaches, \textsc{OpenNovelty} grounds all assessments in retrieved real papers, ensuring verifiable judgments. We deploy our system on 500+ ICLR 2026 submissions with all reports publicly available on our website, and preliminary analysis suggests it can identify relevant prior work, including closely related papers that authors may overlook. OpenNovelty aims to empower the research community with a scalable tool that promotes fair, consistent, and evidence-backed peer review.

</details>


### [314] [LACONIC: Dense-Level Effectiveness for Scalable Sparse Retrieval via a Two-Phase Training Curriculum](https://arxiv.org/abs/2601.01684)
*Zhichao Xu,Shengyao Zhuang,Crystina Zhang,Xueguang Ma,Yijun Tian,Maitrey Mehta,Jimmy Lin,Vivek Srikumar*

Main category: cs.IR

TL;DR: 本文提出了LACONIC，一种基于Llama-3架构的新型学习型稀疏检索器家族，通过两阶段训练策略显著提升性能，在MTEB检索基准上达到60.2 nDCG，同时大幅降低内存与计算开销。


<details>
  <summary>Details</summary>
Motivation: 密集检索模型虽性能优越，但受限于高内存需求和GPU依赖；稀疏检索因可利用倒排索引实现高效搜索而具潜力，但此前关注度不足。

Method: 提出LACONIC系列模型（1B/3B/8B），采用两阶段训练：(1) 弱监督预微调以适配因果LLM进行双向上下文化建模；(2) 基于精选难负样本的高信噪比微调。

Result: LACONIC-8B在MTEB Retrieval基准上取得60.2 nDCG，位居2026年1月1日排行榜第15名，索引内存比同等密集模型减少71%，且可在普通CPU上高效运行。

Conclusion: LACONIC成功弥合了稀疏与密集检索的性能差距，在保持高检索效果的同时显著提升了部署效率与可扩展性，为实际搜索应用提供了更优解。

Abstract: While dense retrieval models have become the standard for state-of-the-art information retrieval, their deployment is often constrained by high memory requirements and reliance on GPU accelerators for vector similarity search. Learned sparse retrieval offers a compelling alternative by enabling efficient search via inverted indices, yet it has historically received less attention than dense approaches. In this report, we introduce LACONIC, a family of learned sparse retrievers based on the Llama-3 architecture (1B, 3B, and 8B). We propose a streamlined two-phase training curriculum consisting of (1) weakly supervised pre-finetuning to adapt causal LLMs for bidirectional contextualization and (2) high-signal finetuning using curated hard negatives. Our results demonstrate that LACONIC effectively bridges the performance gap with dense models: the 8B variant achieves a state-of-the-art 60.2 nDCG on the MTEB Retrieval benchmark, ranking 15th on the leaderboard as of January 1, 2026, while utilizing 71\% less index memory than an equivalent dense model. By delivering high retrieval effectiveness on commodity CPU hardware with a fraction of the compute budget required by competing models, LACONIC provides a scalable and efficient solution for real-world search applications.

</details>


### [315] [When Attention Becomes Exposure in Generative Search](https://arxiv.org/abs/2601.01750)
*Shayan Alipour,Mehdi Kargar,Morteza Zihayat*

Main category: cs.IR

TL;DR: 本研究审计了44个Web3企业的生成式搜索引擎引用曝光情况，发现曝光存在偏向性：更受欢迎的声音、更大的粉丝基础以及更集中的创作者核心，均与更高排名的曝光相关，可能导致观点多样性受限和既有优势者固化。


<details>
  <summary>Details</summary>
Motivation: 探究生成式搜索引擎的引用曝光是否受到外部注意力市场（如Web3平台的激励型创作者生态）的影响，及其可能带来的偏见问题。

Method: 对44个Web3企业进行实证审计，分析其创作者社区的时间持续性、企业特定查询下的引用曝光分布，并考察粉丝规模与创作者核心集中度对曝光排序的影响。

Result: 1）各企业创作者社区具有时间持久性；2）更受欢迎的声音系统性获得更高引用曝光；3）更大粉丝基数和更集中创作者核心的企业获得更高排名曝光。

Conclusion: 生成式搜索引擎的引用曝光存在对已有突出声音的系统性偏好，可能加剧信息垄断、削弱观点多样性。

Abstract: Generative search engines are reshaping information access by replacing traditional ranked lists with synthesized answers and references. In parallel, with the growth of Web3 platforms, incentive-driven creator ecosystems have become an essential part of how enterprises build visibility and community by rewarding creators for contributing to shared narratives. However, the extent to which exposure in generative search engine citations is shaped by external attention markets remains uncertain. In this study, we audit the exposure for 44 Web3 enterprises. First, we show that the creator community around each enterprise is persistent over time. Second, enterprise-specific queries reveal that more popular voices systematically receive greater citation exposure than others. Third, we find that larger follower bases and enterprises with more concentrated creator cores are associated with higher-ranked exposure. Together, these results show that generative search engine citations exhibit exposure bias toward already prominent voices, which risks entrenching incumbents and narrowing viewpoint diversity.

</details>


### [316] [Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis](https://arxiv.org/abs/2601.01751)
*Samaneh Mohtadi,Gianluca Demartini*

Main category: cs.IR

TL;DR: 本文提出一种新的表示方法和聚类框架，用于分析大语言模型（LLMs）与人类在信息检索相关性判断中的系统性分歧，发现分歧集中在特定语义簇（如定义寻求、政策相关、模糊查询），而非随机分布，并识别出LLM易出错的‘分歧热点’。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注LLM作为相关性评估者相对于人类的平均性能，而本文旨在揭示LLM是否存在系统性误判，而非仅评估其整体可靠性。

Method: 提出一种联合语义空间嵌入方法，将查询-文档对（Q-D）映射为关系型表征；构建基于聚类的分析框架，通过对比LLM与人类标签在各语义簇中的分布，定位系统性分歧区域；并在查询层面进行细粒度失败模式分析。

Result: 实验表明，LLM与人类的系统性分歧高度集中于特定语义簇（如定义寻求、政策类、模糊查询）；存在‘分歧热点’查询——其内部簇间一致性差异大，LLM在此类查询上常出现漏检相关文档或误判无关文档。

Conclusion: LLM的相关性判断存在可识别、可定位的系统性偏差，该框架能将全局诊断与局部聚类结合，揭示LLM在IR评估中的隐性弱点，从而支持构建更鲁棒、偏见感知的评估体系。

Abstract: Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.

</details>


### [317] [MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2601.01753)
*Hyunsoo Kim,Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: 本文提出MergeRec框架，解决数据隔离下的跨域序列推荐问题，通过模型合并、伪用户数据构建和协同合并优化，在不共享原始用户数据的前提下提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有跨域序列推荐方法依赖跨域重叠用户/物品或忽略隐私约束，难以在数据隔离场景下有效工作。

Method: 提出MergeRec框架，包含三部分：(1)基于无训练合并技术的合并初始化；(2)将每个物品视为虚拟序列构造伪用户数据；(3)联合推荐损失与知识蒸馏损失进行协同合并优化。

Result: MergeRec显著提升对未见域的泛化能力，在Recall@10上平均提升达17.21%，优于传统模型合并方法。

Conclusion: 模型合并是一种可扩展且有效的构建通用推荐系统的途径，MergeRec在数据隔离设定下验证了其可行性与优越性。

Abstract: Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.

</details>


### [318] [SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines](https://arxiv.org/abs/2601.01785)
*Rajiv Chaitanya Muttur*

Main category: cs.IR

TL;DR: 本文提出了一种轻量级、基于强化学习的稀疏奖励感知文档选择器SRAS，专为边缘设备上的RAG系统设计，具有低延迟（<1s CPU）、小模型尺寸（~0.76MB）和强泛化能力，在SQuAD v2上达到0.8546 BERTScore F1。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统依赖固定top-k检索，忽略生成质量且计算开销大，难以适配边缘设备严苛的资源与延迟约束。

Method: 提出SRAS，采用PPO强化学习训练紧凑策略网络，使用Relaxed F1与BERTScore组成的混合奖励信号，在token与算力受限下优化文档选择。

Result: 在合成QA基准上超越监督与随机选择器；在未调优情况下于SQuAD v2取得0.8546 BERTScore F1；CPU上延迟<1秒，模型仅约0.76MB。

Conclusion: 首次证明RL驱动的文档选择可实现超轻量、低延迟、高效果，适用于端侧RAG部署。

Abstract: Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.

</details>


### [319] [A Hybrid Architecture for Multi-Stage Claim Document Understanding: Combining Vision-Language Models and Machine Learning for Real-Time Processing](https://arxiv.org/abs/2601.01897)
*Lilu Cheng,Jingjun Lu,Yi Xuan Chan,Quoc Khai Nguyen,John Bi,Sean Ho*

Main category: cs.IR

TL;DR: 本文提出了一种结合PaddleOCR、逻辑回归分类器和Qwen 2.5-VL-7B视觉语言模型的多阶段流水线，用于从非结构化医疗理赔文档（如扫描PDF/照片）中高效准确地提取结构化字段，在真实业务场景中实现95%+文档分类准确率、87%字段抽取准确率及300倍于人工的处理效率提升。


<details>
  <summary>Details</summary>
Motivation: 医疗理赔文档多为非数字原生的扫描件或照片，存在内容异构（打印/手写）、语言多样、图像质量差、版式不一等问题，严重阻碍自动化信息抽取；Fullerton Health在九个市场年处理数千万份索赔单，亟需鲁棒、高效、多语言的解析方案。

Method: 构建多阶段流水线：首先用PaddleOCR进行多语言OCR识别；其次用传统逻辑回归模型完成文档类型分类；最后利用轻量级视觉语言模型Qwen 2.5-VL-7B进行细粒度字段抽取；端到端系统部署于移动应用。

Result: 文档类型分类准确率>95%，字段级抽取准确率≈87%，单文档平均延迟<2秒；相比人工（约10分钟/单），效率提升300倍；已在越南和新加坡上线，每周处理数万份索赔单。

Conclusion: 融合传统机器学习与现代VLM的方法可在真实医疗理赔场景中兼顾高精度、低延迟与多语言鲁棒性，具备强落地能力与规模化应用价值。

Abstract: Claims documents are fundamental to healthcare and insurance operations, serving as the basis for reimbursement, auditing, and compliance. However, these documents are typically not born digital; they often exist as scanned PDFs or photographs captured under uncontrolled conditions. Consequently, they exhibit significant content heterogeneity, ranging from typed invoices to handwritten medical reports, as well as linguistic diversity. This challenge is exemplified by operations at Fullerton Health, which handles tens of millions of claims annually across nine markets, including Singapore, the Philippines, Indonesia, Malaysia, Mainland China, Hong Kong, Vietnam, Papua New Guinea, and Cambodia. Such variability, coupled with inconsistent image quality and diverse layouts, poses a significant obstacle to automated parsing and structured information extraction.
  This paper presents a robust multi-stage pipeline that integrates the multilingual optical character recognition (OCR) engine PaddleOCR, a traditional Logistic Regression classifier, and a compact Vision-Language Model (VLM), Qwen 2.5-VL-7B, to achieve efficient and accurate field extraction from large-scale claims data. The proposed system achieves a document-type classification accuracy of over 95 percent and a field-level extraction accuracy of approximately 87 percent, while maintaining an average processing latency of under 2 seconds per document. Compared to manual processing, which typically requires around 10 minutes per claim, our system delivers a 300x improvement in efficiency. These results demonstrate that combining traditional machine learning models with modern VLMs enables production-grade accuracy and speed for real-world automation. The solution has been successfully deployed in our mobile application and is currently processing tens of thousands of claims weekly from Vietnam and Singapore.

</details>


### [320] [MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search](https://arxiv.org/abs/2601.01930)
*Dongfang Zhao*

Main category: cs.IR

TL;DR: 本文提出了一种名为Manifold-Consistent Graph Indexing (MCGI)的图索引方法，通过利用局部本征维数（LID）动态调整搜索策略，缓解高维空间中图ANN搜索因欧氏-测地线失配导致的性能下降问题；理论分析表明其能提升近似保证，实验显示其在GIST1M和SIFT1B等数据集上显著优于DiskANN。


<details>
  <summary>Details</summary>
Motivation: 图基近似最近邻（ANN）搜索在高维空间中常因“欧氏-测地线失配”导致贪心路由偏离数据流形，从而性能下降。

Method: 提出Manifold-Consistent Graph Indexing (MCGI)，一种几何感知且支持磁盘驻留的索引方法，利用局部本征维数（LID）进行原位几何分析，动态调节束搜索预算，摆脱对静态超参数的依赖。

Result: 在高维GIST1M数据集上，MCGI在95%召回率下吞吐量比DiskANN高5.8倍；在十亿级SIFT1B上，高召回查询延迟降低3倍；在低维标准数据集上保持性能相当。

Conclusion: MCGI通过建模数据内在几何结构，提升了图ANN索引在高维与大规模场景下的效率与鲁棒性，兼具理论保证与实际可扩展性。

Abstract: Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\times$ higher throughput at 95\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\times$, while maintaining performance parity on standard lower-dimensional datasets.

</details>


### [321] [Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations](https://arxiv.org/abs/2601.01997)
*Dario Di Palma,Giovanni Maria Biancofiore,Vito Walter Anelli,Fedelucio Narducci,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 本研究系统评估了ChatGPT-3.5和ChatGPT-4在推荐系统中的多样性、新颖性和流行度偏差表现，发现ChatGPT-4在准确性、新颖性与多样性平衡方面可媲美甚至超越传统推荐器，尤其在冷启动场景下优势显著。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦ChatGPT在推荐准确性上的表现，而对其多样性、新颖性及潜在偏差（如流行度偏差）等关键维度缺乏全面分析，亟需系统评估以提升用户满意度与长期个性化效果。

Method: 在三个不同数据集上，对ChatGPT-3.5和ChatGPT-4进行Top-N推荐与冷启动场景下的实验，评估其在多样性、新颖性和流行度偏差等方面的性能。

Result: ChatGPT-4在多样性与新颖性之间取得更好平衡，整体表现匹配或优于传统推荐器；在冷启动场景下，其准确性和新颖性均显著更优。

Conclusion: ChatGPT类大语言模型不仅具备准确推荐能力，还在多样性、新颖性等维度展现出潜力，但其流行度偏差等问题仍需关注；该研究为超越准确率的推荐评估提供了新视角。

Abstract: ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.
  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.

</details>


### [322] [Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models](https://arxiv.org/abs/2601.02002)
*Antonio Colacicco,Vito Guida,Dario Di Palma,Fedelucio Narducci,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 本文研究了大语言模型（LLMs）在推荐系统中可能存在的训练数据泄露问题，特别是对MovieLens-1M数据集的记忆现象，并系统评估了三种检测与提取记忆数据的方法：越狱提示工程、无监督潜在知识发现（CCS/Cluster-Norm）和自动提示工程（APE），结果表明APE是最具潜力的自动化提取策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练数据不公开，存在数据泄露风险；已有研究表明LLaMA和OpenAI模型记住了MovieLens-1M数据，但当前提取依赖手工提示，缺乏系统性、自动化方法。

Method: 评估三种方法：(i) jailbreak prompt engineering；(ii) 基于内部激活探测的无监督方法（CCS和Cluster-Norm）；(iii) 将提示发现建模为元学习过程的自动提示工程（APE）。

Result: Jailbreak提示未提升记忆项检索效果且不稳定；CCS能区分真实与虚构电影名，但无法识别用户ID和评分等数值数据；APE可中等程度恢复物品级信息，但难以恢复数值交互数据。

Conclusion: 自动优化提示（如APE）是目前提取LLM记忆样本最可行、最有前景的策略。

Abstract: Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.

</details>


### [323] [Cold-Starting Podcast Ads and Promotions with Multi-Task Learning on Spotify](https://arxiv.org/abs/2601.02306)
*Shivam Verma,Hannes Karlbom,Yu Zhao,Nick Topping,Vivian Chen,Kieran Stanley,Bharath Rengarajan*

Main category: cs.IR

TL;DR: 本文提出了一种统一的多目标模型，用于在Spotify播客生态中同时优化广告和推广的投放，通过多任务学习与迁移学习解决个性化和冷启动问题，显著提升效果并简化系统维护。


<details>
  <summary>Details</summary>
Motivation: 解决Spotify播客广告与推广中的个性化不足和新广告目标冷启动难的问题，打破传统孤立建模的瓶颈。

Method: 构建基于多任务学习（MTL）框架的统一多目标模型，利用大规模广告与内容交互数据进行迁移学习，共享用户、内容、上下文和创意特征表征，联合优化流媒体播放、点击、关注等目标。

Result: 线上A/B测试显示eCPS降低22%（尤其对低播放量播客），播客流媒体率提升18–24%；离线实验验证了辅助目标和特征组对冷启动性能的关键贡献。

Conclusion: 统一建模策略在效果、可维护性、冷启动性能和覆盖范围上均优于传统分立模型，并为真实广告系统中联合建模的实践权衡提供了经验启示。

Abstract: We present a unified multi-objective model for targeting both advertisements and promotions within the Spotify podcast ecosystem. Our approach addresses key challenges in personalization and cold-start initialization, particularly for new advertising objectives. By leveraging transfer learning from large-scale ad and content interactions within a multi-task learning (MTL) framework, a single joint model can be fine-tuned or directly applied to new or low-data targeting tasks, including in-app promotions. This multi-objective design jointly optimizes podcast outcomes such as streams, clicks, and follows for both ads and promotions using a shared representation over user, content, context, and creative features, effectively supporting diverse business goals while improving user experience. Online A/B tests show up to a 22% reduction in effective Cost-Per-Stream (eCPS), particularly for less-streamed podcasts, and an 18-24% increase in podcast stream rates. Offline experiments and ablations highlight the contribution of ancillary objectives and feature groups to cold-start performance. Our experience shows that a unified modeling strategy improves maintainability, cold-start performance, and coverage, while breaking down historically siloed targeting pipelines. We discuss practical trade-offs of such joint models in a real-world advertising system.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [324] [Horizon Reduction as Information Loss in Offline Reinforcement Learning](https://arxiv.org/abs/2601.00831)
*Uday Kumar Nidadala,Venkata Bhumika Guthi*

Main category: cs.LG

TL;DR: 本文揭示了离线强化学习中常用的horizon reduction策略会导致不可恢复的信息损失，即使在无限数据和完美函数逼近下，最优策略也可能与次优策略无法区分；通过构造反例MDP，识别出三种结构失效模式，并指出其固有局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管horizon reduction在实践中被广泛用于提升离线RL的稳定性与可扩展性，但其理论影响尚不清晰，尤其缺乏对其潜在根本缺陷的系统性分析。

Method: 将horizon reduction形式化为仅基于固定长度轨迹片段的学习问题，构建极小反例马尔可夫决策过程（MDPs），并从统计可辨识性、目标函数截断偏差、数据支持集与表征混叠三方面进行理论证明。

Result: 证明在仅访问固定长度轨迹片段的学习设定下，存在最优策略与次优策略统计不可区分的情形；识别出前缀不可区分性、截断回报导致的目标误设、离线数据支持与表征混叠三类结构性失效模式。

Conclusion: horizon reduction存在本质性、不可克服的信息损失，其安全性需满足特定必要条件；该局限不能单靠算法改进（如保守目标或分布偏移处理）来解决，需重新审视其理论基础与适用边界。

Abstract: Horizon reduction is a common design strategy in offline reinforcement learning (RL), used to mitigate long-horizon credit assignment, improve stability, and enable scalable learning through truncated rollouts, windowed training, or hierarchical decomposition (Levine et al., 2020; Prudencio et al., 2023; Park et al., 2025). Despite recent empirical evidence that horizon reduction can improve scaling on challenging offline RL benchmarks, its theoretical implications remain underdeveloped (Park et al., 2025). In this paper, we show that horizon reduction can induce fundamental and irrecoverable information loss in offline RL. We formalize horizon reduction as learning from fixed-length trajectory segments and prove that, under this paradigm and any learning interface restricted to fixed-length trajectory segments, optimal policies may be statistically indistinguishable from suboptimal ones even with infinite data and perfect function approximation. Through a set of minimal counterexample Markov decision processes (MDPs), we identify three distinct structural failure modes: (i) prefix indistinguishability leading to identifiability failure, (ii) objective misspecification induced by truncated returns, and (iii) offline dataset support and representation aliasing. Our results establish necessary conditions under which horizon reduction can be safe and highlight intrinsic limitations that cannot be overcome by algorithmic improvements alone, complementing algorithmic work on conservative objectives and distribution shift that addresses a different axis of offline RL difficulty (Fujimoto et al., 2019; Kumar et al., 2020; Gulcehre et al., 2020).

</details>


### [325] [ShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI](https://arxiv.org/abs/2601.00832)
*Israk Hasan Jone,D. M. Rafiun Bin Masud,Promit Sarker,Sayed Fuad Al Labib,Nazmul Islam,Farhad Billah*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的虾病自动分类方法，使用了六种预训练模型，在经过背景去除、标准化预处理、对抗训练（FGSM）及数据增强（CutMix/MixUp）后，ConvNeXt-Tiny 达到96.88%的最高准确率，并通过Grad-CAM等可视化方法提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 虾养殖易受疾病暴发影响，威胁可持续生产，亟需及时准确的自动化疾病检测手段。

Method: 采用六种预训练CNN模型（ResNet50、EfficientNet、DenseNet201、MobileNet、ConvNeXt-Tiny、Xception），结合背景去除、Keras标准化预处理、FGSM对抗训练及CutMix/MixUp增强，并利用Grad-CAM系列方法进行模型注意力可视化。

Result: ConvNeXt-Tiny在四类虾病图像数据集（1149张）上测试准确率达96.88%，99%置信区间为[0.953, 0.971]。

Conclusion: ConvNeXt-Tiny在该任务中表现最优，结合对抗训练与先进增强策略及可解释性分析，为虾病智能诊断提供了高效可靠的技术路径。

Abstract: Shrimp is one of the most widely consumed aquatic species globally, valued for both its nutritional content and economic importance. Shrimp farming represents a significant source of income in many regions; however, like other forms of aquaculture, it is severely impacted by disease outbreaks. These diseases pose a major challenge to sustainable shrimp production. To address this issue, automated disease classification methods can offer timely and accurate detection. This research proposes a deep learning-based approach for the automated classification of shrimp diseases. A dataset comprising 1,149 images across four disease classes was utilized. Six pretrained deep learning models, ResNet50, EfficientNet, DenseNet201, MobileNet, ConvNeXt-Tiny, and Xception were deployed and evaluated for performance. The images background was removed, followed by standardized preprocessing through the Keras image pipeline. Fast Gradient Sign Method (FGSM) was used for enhancing the model robustness through adversarial training. While advanced augmentation strategies, including CutMix and MixUp, were implemented to mitigate overfitting and improve generalization. To support interpretability, and to visualize regions of model attention, post-hoc explanation methods such as Grad-CAM, Grad-CAM++, and XGrad-CAM were applied. Exploratory results demonstrated that ConvNeXt-Tiny achieved the highest performance, attaining a 96.88% accuracy on the test dataset. After 1000 iterations, the 99% confidence interval for the model is [0.953,0.971].

</details>


### [326] [Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds](https://arxiv.org/abs/2601.00834)
*Julian Evan Chrisnanto,Salsabila Rahma Alia,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

TL;DR: 本文提出了一种名为IM-PINN的无网格几何深度学习框架，用于在复杂非欧流形上高保真求解非线性反应-扩散PDE，通过内嵌黎曼度量张量解析重构Laplace-Beltrami算子，显著提升质量守恒与模式复现能力。


<details>
  <summary>Details</summary>
Motivation: 在复杂非欧流形上模拟非线性反应-扩散动力学面临高精度网格生成成本高和时间离散方案中辛漂移严重的问题。

Method: 提出Intrinsic-Metric Physics-Informed Neural Network（IM-PINN），将黎曼度量张量嵌入自动微分图中以解析重构Laplace-Beltrami算子；采用双流架构与傅里叶特征嵌入缓解频谱偏差；在连续参数域直接求解PDE，摆脱对几何离散的依赖。

Result: 在高斯曲率剧烈波动（K∈[-2489, 3580]）的'随机布料'流形上成功复现Gray-Scott模型的'splitting spot'与'labyrinthine'斑图；质量守恒误差（ℰ_mass≈0.157）优于表面有限元法（0.258），且具备分辨率无关性与内存高效性。

Conclusion: IM-PINN为演化曲面上的生物图案形成提供了热力学一致、无网格、高保真的新范式，有效融合微分几何与物理信息机器学习。

Abstract: Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the continuous parametric domain. By embedding the Riemannian metric tensor into the automatic differentiation graph, our architecture analytically reconstructs the Laplace-Beltrami operator, decoupling solution complexity from geometric discretization. We validate the framework on a "Stochastic Cloth" manifold with extreme Gaussian curvature fluctuations ($K \in [-2489, 3580]$), where traditional adaptive refinement fails to resolve anisotropic Turing instabilities. Using a dual-stream architecture with Fourier feature embeddings to mitigate spectral bias, the IM-PINN recovers the "splitting spot" and "labyrinthine" regimes of the Gray-Scott model. Benchmarking against the Surface Finite Element Method (SFEM) reveals superior physical rigor: the IM-PINN achieves global mass conservation error of $\mathcal{E}_{mass} \approx 0.157$ versus SFEM's $0.258$, acting as a thermodynamically consistent global solver that eliminates mass drift inherent in semi-implicit integration. The framework offers a memory-efficient, resolution-independent paradigm for simulating biological pattern formation on evolving surfaces, bridging differential geometry and physics-informed machine learning.

</details>


### [327] [SLO-Conditioned Action Routing for Retrieval-Augmented Generation: Objective Ablation and Failure Modes](https://arxiv.org/abs/2601.00841)
*Bharath Nunepalli*

Main category: cs.LG

TL;DR: 本文研究了检索增强生成（RAG）中基于服务级别目标（SLO）的每查询控制问题，提出通过选择检索深度和生成模式（受控/自动）或拒绝响应来优化成本、拒答率与幻觉风险，并在SQuAD 2.0上构建离线日志数据集评估两种策略学习目标，强调可复现性、失败模式分析与报告规范。


<details>
  <summary>Details</summary>
Motivation: RAG系统需按查询动态调整检索深度与生成行为以满足多维服务级目标（如成本、拒答率、幻觉风险），但现有工作缺乏对这种细粒度控制的系统建模与评估。

Method: 将每查询控制建模为小规模离散动作空间（检索深度k、生成模式：guarded/auto、或拒绝）；基于SQuAD 2.0构建离线日志数据集，记录各动作下的准确率、token成本、幻觉/拒答指标及SLO加权奖励；对比监督分类（Argmax-CE）与奖励加权分类（Argmax-CE-WT）两种策略学习目标。

Result: 固定基线（低k+guarded prompting）表现强劲；学习策略仅在质量导向SLO下带来显著成本节约；当SLO偏向廉价且拒答奖励过高时，策略易出现‘拒答崩溃’（refusal collapse）。

Conclusion: 本工作提供了一个面向SLO的RAG控制可复现案例研究，核心贡献在于揭示关键失败模式（如refusal collapse）、确立规范化的评估与报告实践，而非提出新检索器或语言模型。

Abstract: Retrieval-augmented generation (RAG) introduces a practical control problem: retrieval depth and generation behavior must be chosen per query to satisfy service-level objectives (SLOs) such as cost, refusal rate, and hallucination risk. This work models per-query control as a small discrete action: choose a retrieval depth and a generation mode (guarded vs. auto), or refuse. An offline logged dataset is constructed from SQuAD 2.0 by executing each action and recording accuracy, token cost, hallucination/refusal indicators, and an SLO-weighted reward. Two simple policy-learning objectives are evaluated: supervised classification of the per-state best action (Argmax-CE) and a reward-weighted variant (Argmax-CE-WT). Across the evaluated settings, a strong fixed baseline (low k, guarded prompting) performs competitively; learned policies mainly provide additional cost savings under a quality-focused SLO and can exhibit refusal collapse under a cheap SLO when refusal is heavily rewarded. The contribution is a reproducible case study of SLO-aware control for RAG pipelines, emphasizing failure modes and reporting conventions rather than proposing a new retriever or language model.

</details>


### [328] [Value-guided action planning with JEPA world models](https://arxiv.org/abs/2601.00844)
*Matthieu Destrade,Oumayma Bounou,Quentin Le Lidec,Jean Ponce,Yann LeCun*

Main category: cs.LG

TL;DR: 本文提出了一种改进JEPA世界模型以支持有效动作规划的新方法，通过在表示空间中近似负目标条件价值函数为状态嵌入间的距离，从而提升规划性能。


<details>
  <summary>Details</summary>
Motivation: JEPA框架虽能建模环境动态，但在支持有效动作规划方面能力有限，需增强其规划能力。

Method: 通过塑造JEPA的表示空间，使负目标条件价值函数近似为状态嵌入间的距离（或拟距离），并在训练中引入实际约束方法来实现该目标。

Result: 在简单控制任务上，所提方法显著优于标准JEPA模型的规划性能。

Conclusion: 将价值函数几何化嵌入表示可有效提升JEPA世界模型的规划能力，为基于学习的世界模型提供了新思路。

Abstract: Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.

</details>


### [329] [Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware](https://arxiv.org/abs/2601.01298)
*Jorge L. Ruiz Williams*

Main category: cs.LG

TL;DR: Warp Cortex 是一种异步多智能体大语言模型架构，通过单例权重共享和拓扑突触技术，将内存复杂度大幅降低，支持百万级智能体在消费级硬件上并行推理。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM框架存在线性内存扩展问题，导致在消费级硬件上难以实现'系统2'式的并行推理。

Method: 提出 Warp Cortex 架构，采用单例权重共享（Singleton Weight Sharing）和受拓扑数据分析（TDA）启发的拓扑突触（Topological Synapse），将KV缓存建模为潜在空间中的点云，并应用 witness-complex 启发的稀疏化方法；引入非侵入式 Referential Injection 机制实现异步子智能体对主生成过程的影响。

Result: 在单块 NVIDIA RTX 4090 上实现实时运行 100 个并发智能体，仅占用 2.2 GB 显存；理论支持超 1000 个智能体，瓶颈转为计算延迟而非显存。

Conclusion: Warp Cortex 有效解耦智能体逻辑与物理内存，显著提升多智能体系统的可扩展性，为消费级设备上的大规模并行认知推理提供了可行路径。

Abstract: Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering "System 2" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.

</details>


### [330] [You Only Need Your Transformer 25% of the Time: Meaning-First Execution for Eliminating Unnecessary Inference](https://arxiv.org/abs/2601.00847)
*Ryan Shamim*

Main category: cs.LG

TL;DR: 本文提出Meaning-First Execution (MFEE)，一种在不修改模型的前提下、通过语义分析动态决定是否执行Transformer推理的控制平面架构，在保持100%正确性的前提下实现78.1%的推理执行减少。


<details>
  <summary>Details</summary>
Motivation: 现有AI推理系统将Transformer执行视为强制性，忽视了‘何时必须执行’这一控制决策问题；作者旨在解耦模型能力与执行必要性，引入执行治理新范式。

Method: 提出Meaning-First Execution（MFEE）控制平面架构，作为轻量级门控层部署于现有推理栈之上，基于语义而非浅层模式进行执行必要性判断，并给出理论证明（Theorem 1）说明仅依赖有限特征映射的路由器无法兼顾零误跳过与正向规避。

Result: 在1000个不同提示、确定性解码下，MFEE实现78.1%执行减少且所有触发的推理保持100%精确匹配；相比模式路由方法（最高53.3%规避但存在错误），MFEE达到100%规避正确率（即零失败）。

Conclusion: 执行治理应成为ML系统基础设施的基础层级，独立于模型优化，MFEE验证了语义驱动控制平面的有效性与理论优越性。

Abstract: Modern AI inference systems treat transformer execution as mandatory, conflating model capability with execution necessity. We reframe inference as a control-plane decision problem: determining when execution is necessary versus when correctness can be preserved through alternative pathways. We introduce Meaning-First Execution (MFEE), a control-plane architecture implementing this framework, selectively invoking transformer inference only when required. MFEE operates as a gating layer above existing stacks without modifying models, weights, or parameters. Across 1,000 diverse prompts under deterministic decoding, MFEE achieves 78.1% execution reduction while maintaining 100% exact-match equivalence for invoked executions. Comparative evaluation reveals pattern-based routers achieve at most 53.3% avoidance with correctness failures, while MFEE reaches 100% avoidance with zero failures through semantic analysis. We prove this limitation via Theorem 1: any router operating solely on finite feature maps cannot simultaneously guarantee zero false skips and positive avoidance on feature-collision pairs. These results establish execution governance as a foundational layer in ML systems infrastructure, orthogonal to model-level optimization techniques.

</details>


### [331] [Learning Resilient Elections with Adversarial GNNs](https://arxiv.org/abs/2601.01653)
*Hao Xiang Li,Yash Shah,Lorenzo Giusti*

Main category: cs.LG

TL;DR: 本文提出了一种结合图神经网络与对抗训练的新型学习型投票规则，以提升选举机制在策略性投票下的鲁棒性并最大化社会福利。


<details>
  <summary>Details</summary>
Motivation: 现有学习型投票规则在真实场景中面临策略性投票鲁棒性不足等问题，亟需更鲁棒且可表达性强的方法。

Method: 将选举建模为二分图，利用图神经网络学习投票规则，并引入对抗训练增强对策略性投票的鲁棒性。

Result: 在合成与真实数据集上验证了方法有效性，显著提升了鲁棒性与社会福利，克服了先前工作在表示和学习能力上的关键限制。

Conclusion: 该方法为将机器学习应用于现实选举系统开辟了新方向，推动了自动化机制设计的发展。

Abstract: In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.

</details>


### [332] [EdgeJury: Cross-Reviewed Small-Model Ensembles for Truthful Question Answering on Serverless Edge Inference](https://arxiv.org/abs/2601.00850)
*Aayush Kumar*

Main category: cs.LG

TL;DR: EdgeJury 是一种轻量级集成框架，利用多个小型指令微调语言模型（3B-8B）在边缘设备上提升问答真实性与鲁棒性，通过角色生成、匿名交叉评审、主席综合和声明级一致性标注四阶段流程，在 TruthfulQA 和 EdgeCases 上显著超越单模型及主流集成方法。


<details>
  <summary>Details</summary>
Motivation: 现有大模型或检索增强方法在资源受限的边缘部署中不实用，而幻觉问题严重损害问答可靠性，亟需轻量、高效、无需外部依赖的真实性强基线方案。

Method: 提出四阶段轻量集成框架 EdgeJury：（1）并行角色特化生成；（2）匿名结构化交叉评审与排序；（3）主席式内容融合与问题修复；（4）基于跨模型共识的声明级一致性标注。全部基于 3B–8B 小模型，在 Cloudflare Workers AI 上端到端部署。

Result: 在 TruthfulQA (MC1) 上达 76.2% 准确率（+21.4% 相对提升），在对抗性 EdgeCases 集上 +48.2% 相对增益；人工分析显示事实性幻觉减少约 55%；端到端中位延迟仅 8.4 秒。

Conclusion: 协调多个小型模型的集成策略可在不依赖大模型 API 或外部检索的前提下，显著提升边缘场景下问答的真实性与鲁棒性，为资源受限环境提供可行的可信 AI 路径。

Abstract: Hallucinations hinder reliable question answering, especially in resource-constrained deployments where frontier-scale models or retrieval pipelines may be impractical. We present EdgeJury, a lightweight ensemble framework that improves truthfulness and robustness using only small instruction-tuned language models (3B-8B) suitable for serverless edge inference. EdgeJury orchestrates four stages: (1) parallel role-specialized generation, (2) anonymized cross-review with structured critiques and rankings, (3) chairman synthesis that integrates the strongest content while addressing flagged issues, and (4) claim-level consistency labeling based on inter-model agreement. On TruthfulQA (MC1), EdgeJury achieves 76.2% accuracy (95% CI: 72.8-79.6%), a +21.4% relative improvement over a single 8B baseline (62.8%), and outperforms standard baselines including self-consistency and majority voting under transparent compute accounting (total tokens and platform cost reported). On a 200-question adversarial EdgeCases set, EdgeJury yields +48.2% relative gains (95% CI: 44.0-52.4%). Manual analysis on 100 incorrect answers shows an approximately 55% reduction in factual hallucination errors versus the single-model baseline. Deployed on Cloudflare Workers AI, EdgeJury achieves 8.4 s median end-to-end latency, demonstrating that coordinated small-model ensembles can improve truthfulness on misconception-heavy QA benchmarks without external retrieval or proprietary large-model APIs.

</details>


### [333] [FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments](https://arxiv.org/abs/2601.00853)
*Sameer Rahil,Zain Abdullah Ahmad,Talha Asif*

Main category: cs.LG

TL;DR: 本文提出FedSCAM算法，通过动态调整SAM扰动半径和异质性感知的加权聚合机制，解决联邦学习中客户端统计异质性导致的收敛与泛化难题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据分布非独立同分布（non-IID）导致模型收敛慢、泛化差；现有基于SAM的方法采用统一扰动半径，忽略客户端异质性差异。

Method: 提出FedSCAM：1）为每个客户端计算异质性度量，并据此反向调节SAM扰动半径；2）设计异质性感知的加权聚合机制，优先采纳与全局优化方向一致的客户端更新。

Result: 在CIFAR-10和Fashion-MNIST上，FedSCAM在多种Dirichlet标签偏斜设置下，相比FedSAM、FedLESAM等方法，在收敛速度和最终测试精度上均取得更具竞争力的结果。

Conclusion: 动态适配扰动半径与异质性感知聚合能有效提升联邦学习在non-IID场景下的鲁棒性与性能，验证了细粒度客户端异质性建模的重要性。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.

</details>


### [334] [Harvesting AlphaEarth: Benchmarking the Geospatial Foundation Model for Agricultural Downstream Tasks](https://arxiv.org/abs/2601.00857)
*Yuchi Ma,Yawen Shen,Anu Swatantran,David B. Lobell*

Main category: cs.LG

TL;DR: 本研究评估了AlphaEarth Foundation（AEF）这一地理空间基础模型在农业下游任务（作物产量预测、耕作制图、覆盖作物制图）中的性能，发现其在部分任务中可媲美专用遥感模型，但也存在空间迁移性差、可解释性低和时间敏感性不足等局限。


<details>
  <summary>Details</summary>
Motivation: 现有对AEF等地理空间基础模型（GFMs）的评估主要集中于土地覆盖/利用分类，缺乏在关键农业监测任务中的深入验证，也缺少与传统遥感模型在不同场景下的系统性对比。

Method: 在美国内部三个农业下游任务上评估AEF嵌入：作物产量预测、耕作制图、覆盖作物制图；使用多源（公开与私有）数据集，在不同尺度与区域进行测试；同时训练并对比传统遥感（RS）基模型。

Result: AEF基模型在所有任务中整体表现强劲，在产量预测和县级耕作制图（使用本地数据训练时）上可与专用RS模型竞争；但存在空间迁移能力弱、可解释性低、时间敏感性差等明显局限。

Conclusion: AEF等地理空间基础模型在农业应用中潜力巨大，但当前版本在时间敏感性、泛化性与可解释性方面尚不成熟，需谨慎使用。

Abstract: Geospatial foundation models (GFMs) have emerged as a promising approach to overcoming the limitations in existing featurization methods. More recently, Google DeepMind has introduced AlphaEarth Foundation (AEF), a GFM pre-trained using multi-source EOs across continuous time. An annual and global embedding dataset is produced using AEF that is ready for analysis and modeling. The internal experiments show that AEF embeddings have outperformed operational models in 15 EO tasks without re-training. However, those experiments are mostly about land cover and land use classification. Applying AEF and other GFMs to agricultural monitoring require an in-depth evaluation in critical agricultural downstream tasks. There is also a lack of comprehensive comparison between the AEF-based models and traditional remote sensing (RS)-based models under different scenarios, which could offer valuable guidance for researchers and practitioners. This study addresses some of these gaps by evaluating AEF embeddings in three agricultural downstream tasks in the U.S., including crop yield prediction, tillage mapping, and cover crop mapping. Datasets are compiled from both public and private sources to comprehensively evaluate AEF embeddings across tasks at different scales and locations, and RS-based models are trained as comparison models. AEF-based models generally exhibit strong performance on all tasks and are competitive with purpose-built RS-based models in yield prediction and county-level tillage mapping when trained on local data. However, we also find several limitations in current AEF embeddings, such as limited spatial transferability compared to RS-based models, low interpretability, and limited time sensitivity. These limitations recommend caution when applying AEF embeddings in agriculture, where time sensitivity, generalizability, and interpretability is important.

</details>


### [335] [Path Integral Solution for Dissipative Generative Dynamics](https://arxiv.org/abs/2601.00860)
*Xidi Wang*

Main category: cs.LG

TL;DR: 本文证明纯机械系统无法生成智能语言，而耗散量子动力学结合非局域上下文聚合可实现连贯文本生成；守恒定律导致根本性失败；语言生成本质上是耗散量子场论。


<details>
  <summary>Details</summary>
Motivation: 探究纯机械系统是否能产生智能语言，并理解语言生成背后的物理原理。

Method: 采用Koopman算子与闭式路径积分传播子，结合谱分析研究耗散与守恒约束下的动力学行为。

Result: 发现耗散系统存在衰减、增长与中性本征模式，构成定向信息流基础；哈密顿约束消除耗散模式并损害性能。

Conclusion: 语言生成依赖耗散与非局域性的结合，而非守恒律；智能源于不可逆的信息耗散和因果上下文聚合。

Abstract: Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spectral analysis reveals emergent eigenvalue structure, separating into decay modes (forgetting), growth modes (amplification), and neutral modes (preservation) -- the essential ingredients for directed information flow. Hamiltonian constraints force the elimination of these dissipative modes and degrading performance despite unchanged model capacity. This establishes language generation as dissipative quantum field theory, proving mechanical systems acquire intelligence through the combination of dissipation and non-locality, not through conservation.

</details>


### [336] [Universal Battery Degradation Forecasting Driven by Foundation Model Across Diverse Chemistries and Conditions](https://arxiv.org/abs/2601.00862)
*Joey Chan,Huan Wang,Haoyu Pan,Wei Wu,Zirong Wang,Zhen Chen,Ershun Pan,Min Xie,Lifeng Xi*

Main category: cs.LG

TL;DR: 本文提出了一种基于时序基础模型（TSFM）的统一电池容量衰减预测框架，结合LoRA微调与物理引导的对比表征学习，在涵盖多种化学体系、工况和老化数据的大规模语料库上实现了跨域鲁棒预测。


<details>
  <summary>Details</summary>
Motivation: 电池老化行为具有强异质性（不同化学体系、封装形式、工况），导致单一模型难以泛化到训练域外，亟需通用、可迁移的容量预测方法。

Method: 构建覆盖1704个电芯、396万循环段的多源老化数据集；采用时序基础模型（TSFM）为主干，结合低秩适配（LoRA）与物理引导的对比表征学习，挖掘共性退化模式。

Result: 在已见和未见数据集（包括训练中未出现的化学体系、容量等级与工况）上，单一同一模型性能达到或超越各数据集专用基线，且保持稳定。

Conclusion: TSFM架构结合轻量适配与物理先验，可作为可扩展、可迁移的电池容量衰减预测解决方案，适用于真实电池管理系统。

Abstract: Accurate forecasting of battery capacity fade is essential for the safety, reliability, and long-term efficiency of energy storage systems. However, the strong heterogeneity across cell chemistries, form factors, and operating conditions makes it difficult to build a single model that generalizes beyond its training domain. This work proposes a unified capacity forecasting framework that maintains robust performance across diverse chemistries and usage scenarios. We curate 20 public aging datasets into a large-scale corpus covering 1,704 cells and 3,961,195 charge-discharge cycle segments, spanning temperatures from $-5\,^{\circ}\mathrm{C}$ to $45\,^{\circ}\mathrm{C}$, multiple C-rates, and application-oriented profiles such as fast charging and partial cycling. On this corpus, we adopt a Time-Series Foundation Model (TSFM) backbone and apply parameter-efficient Low-Rank Adaptation (LoRA) together with physics-guided contrastive representation learning to capture shared degradation patterns. Experiments on both seen and deliberately held-out unseen datasets show that a single unified model achieves competitive or superior accuracy compared with strong per-dataset baselines, while retaining stable performance on chemistries, capacity scales, and operating conditions excluded from training. These results demonstrate the potential of TSFM-based architectures as a scalable and transferable solution for capacity degradation forecasting in real battery management systems.

</details>


### [337] [Selective Imperfection as a Generative Framework for Analysis, Creativity and Discovery](https://arxiv.org/abs/2601.00863)
*Markus J. Buehler*

Main category: cs.LG

TL;DR: 本文提出materiomusic框架，通过可逆映射将物质结构（如蛋白质、蛛网、火焰）的振动与建筑原理转化为音乐结构，揭示科学与艺术在约束下生成世界的共性，以振动为跨尺度统一语法。


<details>
  <summary>Details</summary>
Motivation: 探索科学与艺术中创新的本质，寻找物质结构与音乐结构之间的深层对应关系，将听觉作为科学探测的新范式。

Method: 构建分子光谱到音符、三维网络到可演奏乐器的可逆映射；枚举全部2^12种音阶进行熵与缺陷分析；采用群体智能AI模型生成具有人类结构特征的音乐。

Result: 发现文化重要音阶聚集于中熵-中缺陷区间，类比材料强度最优的Hall-Petch关系；AI生成音乐展现出小世界性、模块化整合与长程一致性等人类特征；证实振动是跨尺度组织结构的共享语法。

Conclusion: 科学与艺术皆为受约束的世界构建行为；选择性不完美是平衡连贯性与适应性的关键机制；materiomusic为跨学科创新提供新路径。

Abstract: We introduce materiomusic as a generative framework linking the hierarchical structures of matter with the compositional logic of music. Across proteins, spider webs and flame dynamics, vibrational and architectural principles recur as tonal hierarchies, harmonic progressions, and long-range musical form. Using reversible mappings, from molecular spectra to musical tones and from three-dimensional networks to playable instruments, we show how sound functions as a scientific probe, an epistemic inversion where listening becomes a mode of seeing and musical composition becomes a blueprint for matter. These mappings excavate deep time: patterns originating in femtosecond molecular vibrations or billion-year evolutionary histories become audible. We posit that novelty in science and art emerges when constraints cannot be satisfied within existing degrees of freedom, forcing expansion of the space of viable configurations. Selective imperfection provides the mechanism restoring balance between coherence and adaptability. Quantitative support comes from exhaustive enumeration of all 2^12 musical scales, revealing that culturally significant systems cluster in a mid-entropy, mid-defect corridor, directly paralleling the Hall-Petch optimum where intermediate defect densities maximize material strength. Iterating these mappings creates productive collisions between human creativity and physics, generating new information as musical structures encounter evolutionary constraints. We show how swarm-based AI models compose music exhibiting human-like structural signatures such as small-world connectivity, modular integration, long-range coherence, suggesting a route beyond interpolation toward invention. We show that science and art are generative acts of world-building under constraint, with vibration as a shared grammar organizing structure across scales.

</details>


### [338] [Distribution Matching for Graph Quantification Under Structural Covariate Shift](https://arxiv.org/abs/2601.00864)
*Clemens Damke,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: 本文提出了一种扩展KDEy量化方法的结构重要性采样新方法，以应对图数据中因训练与测试子图区域不同而导致的结构性偏移问题，并证明其优于标准量化方法。


<details>
  <summary>Details</summary>
Motivation: 现有图量化学习（QL）方法依赖先验概率偏移（PPS）假设，但在图数据存在结构性偏移（如训练与测试子图来自不同区域）时该假设不成立，亟需适配结构性偏移的新方法。

Method: 将结构重要性采样思想扩展至当前最优的KDEy量化方法，构建能适应图结构偏移的新型量化框架。

Result: 所提方法在图量化任务中能有效适应结构性偏移，在实验中性能优于标准量化方法。

Conclusion: 结构重要性采样可成功融入先进量化方法（如KDEy），显著提升图数据在结构性偏移下的标签分布估计准确性。

Abstract: Graphs are commonly used in machine learning to model relationships between instances. Consider the task of predicting the political preferences of users in a social network; to solve this task one should consider, both, the features of each individual user and the relationships between them. However, oftentimes one is not interested in the label of a single instance but rather in the distribution of labels over a set of instances; e.g., when predicting the political preferences of users, the overall prevalence of a given opinion might be of higher interest than the opinion of a specific person. This label prevalence estimation task is commonly referred to as quantification learning (QL). Current QL methods for tabular data are typically based on the so-called prior probability shift (PPS) assumption which states that the label-conditional instance distributions should remain equal across the training and test data. In the graph setting, PPS generally does not hold if the shift between training and test data is structural, i.e., if the training data comes from a different region of the graph than the test data. To address such structural shifts, an importance sampling variant of the popular adjusted count quantification approach has previously been proposed. In this work, we extend the idea of structural importance sampling to the state-of-the-art KDEy quantification approach. We show that our proposed method adapts to structural shifts and outperforms standard quantification approaches.

</details>


### [339] [A-PINN: Auxiliary Physics-informed Neural Networks for Structural Vibration Analysis in Continuous Euler-Bernoulli Beam](https://arxiv.org/abs/2601.00866)
*Shivani Saini,Ramesh Kumar Vats,Arup Kumar Sahoo*

Main category: cs.LG

TL;DR: 本文提出了一种改进的辅助物理信息神经网络（A-PINN）框架，结合平衡自适应优化器，用于结构振动问题分析，在数值稳定性和预测精度上相较基线模型提升至少40%。


<details>
  <summary>Details</summary>
Motivation: 准确表征结构系统、捕捉振动现象并确保可靠预测分析，以深入理解科学机器学习模型在振动问题求解中的鲁棒性。

Method: 提出一种改进的辅助物理信息神经网络（A-PINN）框架，并引入平衡自适应优化器；通过多种数值模拟，求解不同场景下的欧拉-伯努利梁方程。

Result: 数值结果验证了所提A-PINN模型在数值稳定性和预测精度上的增强性能，相较基线模型提升至少40%。

Conclusion: 改进的A-PINN框架能更有效地解决结构振动问题，提升了物理信息神经网络在工程振动建模中的实用性与可靠性。

Abstract: Recent advancements in physics-informed neural networks (PINNs) and their variants have garnered substantial focus from researchers due to their effectiveness in solving both forward and inverse problems governed by differential equations. In this research, a modified Auxiliary physics-informed neural network (A-PINN) framework with balanced adaptive optimizers is proposed for the analysis of structural vibration problems. In order to accurately represent structural systems, it is critical for capturing vibration phenomena and ensuring reliable predictive analysis. So, our investigations are crucial for gaining deeper insight into the robustness of scientific machine learning models for solving vibration problems. Further, to rigorously evaluate the performance of A-PINN, we conducted different numerical simulations to approximate the Euler-Bernoulli beam equations under the various scenarios. The numerical results substantiate the enhanced performance of our model in terms of both numerical stability and predictive accuracy. Our model shows improvement of at least 40% over the baselines.

</details>


### [340] [SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation](https://arxiv.org/abs/2601.00868)
*Aditya Sreevatsa K,Arun Kumar Raveendran,Jesrael K Mani,Prakash G Shigli,Rajkumar Rangadore,Narayana Darapaneni,Anwesh Reddy Paduri*

Main category: cs.LG

TL;DR: SmartFlow 是一个结合强化学习与智能体AI的多层框架，用于解决城市共享单车动态再平衡问题，通过分层架构（战略、战术、通信）实现高效、可解释、可扩展的调度优化。


<details>
  <summary>Details</summary>
Motivation: 解决城市共享单车系统中因用户出行模式不均衡导致的车辆分布失衡问题，提升车辆可用性、降低运营成本，并增强AI决策的可解释性与人机协同能力。

Method: 采用分层架构：战略层使用在高保真纽约Citi Bike仿真环境中训练的深度Q网络（DQN）建模为马尔可夫决策过程；战术层为确定性模块，优化多段路径与准时调度；通信层基于大语言模型（LLM）驱动的具身智能体，将计划转化为可执行的人类指令。

Result: 在多次种子实验中，网络失衡降低超95%，车队行驶距离最小化，卡车利用率高；同时保障指令可理解、可执行，显著减少空闲时间与运营成本。

Conclusion: SmartFlow 为复杂城市出行网络提供了可解释、可扩展、人机协同的AI物流范式，是智能交通调度的重要实践蓝图。

Abstract: SmartFlow is a multi-layered framework that integrates Reinforcement Learning and Agentic AI to address the dynamic rebalancing problem in urban bike-sharing services. Its architecture separates strategic, tactical, and communication functions for clarity and scalability. At the strategic level, a Deep Q-Network (DQN) agent, trained in a high-fidelity simulation of New Yorks Citi Bike network, learns robust rebalancing policies by modelling the challenge as a Markov Decision Process. These high-level strategies feed into a deterministic tactical module that optimises multi-leg journeys and schedules just-in-time dispatches to minimise fleet travel. Evaluation across multiple seeded runs demonstrates SmartFlows high efficacy, reducing network imbalance by over 95% while requiring minimal travel distance and achieving strong truck utilisation. A communication layer, powered by a grounded Agentic AI with a Large Language Model (LLM), translates logistical plans into clear, actionable instructions for operational staff, ensuring interpretability and execution readiness. This integration bridges machine intelligence with human operations, offering a scalable solution that reduces idle time, improves bike availability, and lowers operational costs. SmartFlow provides a blueprint for interpretable, AI-driven logistics in complex urban mobility networks.

</details>


### [341] [Quantum Machine Learning Approaches for Coordinated Stealth Attack Detection in Distributed Generation Systems](https://arxiv.org/abs/2601.00873)
*Osasumwen Cedric Ogiesoba-Eguakun,Suman Rath*

Main category: cs.LG

TL;DR: 本文研究了量子机器学习在微电网分布式发电单元协同隐身攻击检测中的应用，发现混合量子-经典模型（量子特征嵌入+经典RBF-SVM）在低维数据上性能最优，优于纯经典SVM基线；而全量子模型受限于NISQ硬件和训练不稳定性表现较差。


<details>
  <summary>Details</summary>
Motivation: 协同隐身攻击严重威胁分布式发电系统安全，因其能篡改控制与测量信号且行为接近正常，难以被传统入侵检测方法识别。

Method: 构建包含无功功率、频率偏差和端电压幅值三个特征的平衡二分类数据集，对比评估经典机器学习基线、全量子变分分类器及混合量子-经典模型（量子特征嵌入+经典RBF-SVM）。

Result: 混合量子-经典模型在准确率和F1分数上略优于强经典SVM基线；全量子模型因训练不稳定和当前NISQ硬件限制性能较差；混合模型训练更稳定，证明量子特征映射可提升入侵检测能力。

Conclusion: 在当前NISQ时代，混合量子-经典方法比全量子方法更实用有效，量子特征映射已能在低维入侵检测任务中提供可衡量的性能增益。

Abstract: Coordinated stealth attacks are a serious cybersecurity threat to distributed generation systems because they modify control and measurement signals while remaining close to normal behavior, making them difficult to detect using standard intrusion detection methods. This study investigates quantum machine learning approaches for detecting coordinated stealth attacks on a distributed generation unit in a microgrid. High-quality simulated measurements were used to create a balanced binary classification dataset using three features: reactive power at DG1, frequency deviation relative to the nominal value, and terminal voltage magnitude. Classical machine learning baselines, fully quantum variational classifiers, and hybrid quantum classical models were evaluated. The results show that a hybrid quantum classical model combining quantum feature embeddings with a classical RBF support vector machine achieves the best overall performance on this low dimensional dataset, with a modest improvement in accuracy and F1 score over a strong classical SVM baseline. Fully quantum models perform worse due to training instability and limitations of current NISQ hardware. In contrast, hybrid models train more reliably and demonstrate that quantum feature mapping can enhance intrusion detection even when fully quantum learning is not yet practical.

</details>


### [342] [LLMize: A Framework for Large Language Model-Based Numerical Optimization](https://arxiv.org/abs/2601.00874)
*M. Rizki Oktavian*

Main category: cs.LG

TL;DR: 本文提出了LLMize，一个开源Python框架，利用大语言模型（LLMs）通过迭代提示和上下文学习进行黑箱数值优化，支持多种策略（如OPRO及受进化算法/模拟退火启发的混合方法），并能以自然语言注入约束与领域知识，在复杂难形式化的优化任务中展现实用价值。


<details>
  <summary>Details</summary>
Motivation: 大语言模型展现出超越传统语言任务的推理能力，激发了其在数值优化中的应用需求；现有优化方法对复杂约束和领域知识难以建模，亟需更易用、可解释的优化范式。

Method: 提出LLMize框架，将优化建模为黑箱过程：以自然语言生成候选解，由外部目标函数评估，再基于解-分数反馈迭代精炼；支持OPRO及类进化算法、模拟退火的混合策略；通过自然语言注入约束、规则与领域知识。

Result: 在凸优化、线性规划、TSP、神经网络超参调优和核燃料栅格优化等任务上验证，LLM-based优化虽不及经典求解器处理简单问题，但在复杂、领域特定、约束难形式化的问题中表现实用且易用。

Conclusion: LLMize为复杂优化问题提供了一种无需数学编程或元启发式设计专业知识的新型、可解释、可定制的LLM驱动优化途径，拓展了大语言模型在科学计算与工程优化中的应用边界。

Abstract: Large language models (LLMs) have recently shown strong reasoning capabilities beyond traditional language tasks, motivating their use for numerical optimization. This paper presents LLMize, an open-source Python framework that enables LLM-driven optimization through iterative prompting and in-context learning. LLMize formulates optimization as a black-box process in which candidate solutions are generated in natural language, evaluated by an external objective function, and refined over successive iterations using solution-score feedback. The framework supports multiple optimization strategies, including Optimization by Prompting (OPRO) and hybrid LLM-based methods inspired by evolutionary algorithms and simulated annealing. A key advantage of LLMize is the ability to inject constraints, rules, and domain knowledge directly through natural language descriptions, allowing practitioners to define complex optimization problems without requiring expertise in mathematical programming or metaheuristic design. LLMize is evaluated on convex optimization, linear programming, the Traveling Salesman Problem, neural network hyperparameter tuning, and nuclear fuel lattice optimization. Results show that while LLM-based optimization is not competitive with classical solvers for simple problems, it provides a practical and accessible approach for complex, domain-specific tasks where constraints and heuristics are difficult to formalize.

</details>


### [343] [LearnAD: Learning Interpretable Rules for Brain Networks in Alzheimer's Disease Classification](https://arxiv.org/abs/2601.00877)
*Thomas Andrews,Mark Law,Sara Ahmadi-Abhari,Alessandra Russo*

Main category: cs.LG

TL;DR: LearnAD是一种神经符号方法，用于从脑磁共振成像数据中预测阿尔茨海默病，并生成完全可解释的规则。它结合统计模型、决策树、随机森林或图神经网络（GNN）识别关键脑连接，再用FastLAS学习全局规则，在保持高可解释性的同时达到接近先进模型的性能。


<details>
  <summary>Details</summary>
Motivation: 提升阿尔茨海默病预测模型的可解释性，同时不显著牺牲性能；理解GNN在临床神经科学中的行为机制。

Method: 结合统计模型/决策树/随机森林/GNN筛选重要脑连接，再利用FastLAS学习全局、可解释的逻辑规则。

Result: 最佳LearnAD实例性能优于决策树，与SVM相当，略低于随机森林和全特征GNN；消融实验表明其在可解释性上显著提升，性能与纯统计模型相当。

Conclusion: 神经符号方法可在临床AI中实现高性能与强可解释性的平衡，有助于揭示GNN在脑疾病诊断中的工作机制。

Abstract: We introduce LearnAD, a neuro-symbolic method for predicting Alzheimer's disease from brain magnetic resonance imaging data, learning fully interpretable rules. LearnAD applies statistical models, Decision Trees, Random Forests, or GNNs to identify relevant brain connections, and then employs FastLAS to learn global rules. Our best instance outperforms Decision Trees, matches Support Vector Machine accuracy, and performs only slightly below Random Forests and GNNs trained on all features, all while remaining fully interpretable. Ablation studies show that our neuro-symbolic approach improves interpretability with comparable performance to pure statistical models. LearnAD demonstrates how symbolic learning can deepen our understanding of GNN behaviour in clinical neuroscience.

</details>


### [344] [Outlier Detection Using Vector Cosine Similarity by Adding a Dimension](https://arxiv.org/abs/2601.00883)
*Zhongyang Shen*

Main category: cs.LG

TL;DR: 本文提出了一种基于向量余弦相似度的多维数据异常检测新方法，通过在原始数据中增加一个零值维度构造新数据集，并利用观测点与测量点之间的向量余弦相似度差异识别异常点。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法在处理多维数据时可能面临维度灾难和距离失效问题，需一种更鲁棒、可解释性强的新方法。

Method: 在原始数据中新增一维（全为零），构建扩展数据集；选定一个测量点，将其在新增维设为非零值作为观测点；计算从观测点到测量点及其他所有点的向量，并比较其两两间的余弦相似度以识别异常。

Result: 提出的方法能有效识别多维数据中的异常点，具备良好可解释性与计算效率，并提供了开源Python实现（MDOD包，发布于PyPI）。

Conclusion: 该基于余弦相似度的异常检测方法为多维数据 outlier detection 提供了一种新颖、实用且易于部署的解决方案。

Abstract: We propose a new outlier detection method for multi-dimensional data. The method detects outliers based on vector cosine similarity, using a new dataset constructed by adding a dimension with zero values to the original data. When a point in the new dataset is selected as the measured point, an observation point is created as the origin, differing only in the new dimension by having a non-zero value compared to the measured point. Vectors are then formed from the observation point to the measured point and to other points in the dataset. By comparing the cosine similarities of these vectors, abnormal data can be identified. An optimized implementation (MDOD) is available on PyPI: https://pypi.org/project/mdod/.

</details>


### [345] [FANoS: Friction-Adaptive Nosé--Hoover Symplectic Momentum for Stiff Objectives](https://arxiv.org/abs/2601.00889)
*Nalin Dhiman*

Main category: cs.LG

TL;DR: FANoS是一种受物理启发的优化器，结合了动量更新、自适应摩擦系数和辛积分器，旨在提升非凸优化性能，但在多数基准测试中未超越AdamW或L-BFGS等现代优化器。


<details>
  <summary>Details</summary>
Motivation: 受分子动力学中结构保持积分与恒温器思想启发，将物理建模方法转化为纯优化启发式算法，以改善 stiff nonconvex valleys 中的优化行为。

Method: 提出FANoS算法：基于离散二阶动力系统动量更新、Nosé--Hoover型反馈调节标量摩擦系数的恒温变量、半隐式辛欧拉积分器（可选对角RMS预条件）。

Result: 在Rosenbrock-100D上FANoS-RMS达1.74e-2，显著优于无裁剪AdamW（48.50）和SGD+momentum（90.76），但弱于裁剪AdamW（1.87e-3）和L-BFGS（~4.4e-10）；在病态凸二次函数和PINN暖启动任务中表现不佳、不稳定或高方差。

Conclusion: FANoS是现有思想的可解释融合，在特定非凸地形上有用，但并非通用更优替代方案，性能高度依赖温度调度与超参数选择。

Abstract: We study a physics-inspired optimizer, \emph{FANoS} (Friction-Adaptive Nosé--Hoover Symplectic momentum), which combines (i) a momentum update written as a discretized second-order dynamical system, (ii) a Nosé--Hoover-like thermostat variable that adapts a scalar friction coefficient using kinetic-energy feedback, and (iii) a semi-implicit (symplectic-Euler) integrator, optionally with a diagonal RMS preconditioner. The method is motivated by structure-preserving integration and thermostat ideas from molecular dynamics, but is used here purely as an optimization heuristic.
  We provide the algorithm and limited theoretical observations in idealized settings. On the deterministic Rosenbrock-100D benchmark with 3000 gradient evaluations, FANoS-RMS attains a mean final objective value of $1.74\times 10^{-2}$, improving substantially over unclipped AdamW ($48.50$) and SGD+momentum ($90.76$) in this protocol. However, AdamW with gradient clipping is stronger, reaching $1.87\times 10^{-3}$, and L-BFGS reaches $\approx 4.4\times 10^{-10}$. On ill-conditioned convex quadratics and in a small PINN warm-start suite (Burgers and Allen--Cahn), the default FANoS configuration underperforms AdamW and can be unstable or high-variance.
  Overall, the evidence supports a conservative conclusion: FANoS is an interpretable synthesis of existing ideas that can help on some stiff nonconvex valleys, but it is not a generally superior replacement for modern baselines, and its behavior is sensitive to temperature-schedule and hyperparameter choices.

</details>


### [346] [Hierarchical topological clustering](https://arxiv.org/abs/2601.00892)
*Ana Carpio,Gema Duro*

Main category: cs.LG

TL;DR: 本文提出了一种层次化拓扑聚类算法，适用于任意距离度量，能有效识别任意形状的簇和离群点，并在图像、医疗和经济数据等实际场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法常依赖于对数据结构的假设，而拓扑方法无需此类假设，可更鲁棒地探索数据云；尤其需要有效识别离群点和任意形状簇。

Method: 提出一种层次化拓扑聚类算法，支持任意距离度量，通过构建拓扑层次结构推断簇与离群点的持久性。

Result: 在图像、医疗和经济等含关键离群点的数据集上验证了该算法的有效性，能产生其他方法难以获得的有意义聚类结果。

Conclusion: 该层次化拓扑聚类方法具有通用性和鲁棒性，适用于结构复杂或离群点重要的实际数据分析任务。

Abstract: Topological methods have the potential of exploring data clouds without making assumptions on their the structure. Here we propose a hierarchical topological clustering algorithm that can be implemented with any distance choice. The persistence of outliers and clusters of arbitrary shape is inferred from the resulting hierarchy. We demonstrate the potential of the algorithm on selected datasets in which outliers play relevant roles, consisting of images, medical and economic data. These methods can provide meaningful clusters in situations in which other techniques fail to do so.

</details>


### [347] [When to Ponder: Adaptive Compute Allocation for Code Generation via Test-Time Training](https://arxiv.org/abs/2601.00894)
*Gihyeon Sim*

Main category: cs.LG

TL;DR: 本文提出PonderTTT，一种基于TTT层自监督重建损失的门控策略，用于选择性触发测试时训练（TTT）更新，无需额外训练，仅通过单个标量阈值和EMA自适应调整即可实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对所有输入采用统一计算，忽视了输入难度差异，导致在简单样本上浪费计算资源，在困难样本上又可能表现不足。

Method: 提出Reconstruction Gating机制，利用TTT层的自监督重建损失作为门控信号，设定一个可自适应更新的标量阈值来决定是否执行TTT更新，整个过程无需训练任何分类器或辅助网络。

Result: 在GPT-2系列模型（124M至1.5B）和The Stack v2数据集上的实验表明，该方法在OOD语言上比Random Skip基线最多降低16%损失，并实现82–89%的Oracle Recovery。

Conclusion: Reconstruction Gating是一种高效、免训练、推理友好的TTT门控策略，显著提升了模型在分布外场景下的适应能力与计算效率。

Abstract: Large language models apply uniform computation to all inputs, regardless of difficulty. We propose PonderTTT, a gating strategy using the TTT layer's self-supervised reconstruction loss to selectively trigger Test-Time Training (TTT) updates. The gating decision itself is training-free--requiring no learned classifier or auxiliary networks; only a single scalar threshold is initially calibrated on unlabeled data and continuously adapted via EMA to maintain target update rates. Our experiments with GPT-2 models (124M to 1.5B) on code language modeling (The Stack v2, teacher-forced perplexity) demonstrate that this signal is inference-compatible, requiring no ground-truth labels. Our Reconstruction Gating achieves 82-89% Oracle Recovery while being fully training-free, significantly outperforming Random Skip baselines (up to 16% lower loss on OOD languages).

</details>


### [348] [Dichotomous Diffusion Policy Optimization](https://arxiv.org/abs/2601.00898)
*Ruiming Liang,Yinan Zheng,Kexin Zheng,Tianyi Tan,Jianxiong Li,Liyuan Mao,Zhihao Wang,Guang Chen,Hangjun Ye,Jingjing Liu,Jinqiao Wang,Xianyuan Zhan*

Main category: cs.LG

TL;DR: 本文提出DIPOLE算法，通过二分扩散策略优化方法解决强化学习中训练大型扩散策略的不稳定性与计算效率问题，在离线/在线RL及自动驾驶等复杂任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的策略在强化学习中训练不稳定或计算开销大，亟需一种稳定且可控的优化方法。

Method: 提出DIPOLE算法：基于KL正则化目标重构扩散策略提取，并设计贪心化策略正则化方案，将最优策略分解为奖励最大化与最小化两个可稳定学习的二分策略；推理时通过线性组合二者得分实现贪婪程度灵活调控。

Result: 在ExORL和OGBench的离线及离线到在线RL任务上表现优异；成功用于训练大规模视觉-语言-动作（VLA）模型，并在真实世界自动驾驶基准NAVSIM上验证效果。

Conclusion: DIPOLE提供了一种稳定、可控且可扩展的扩散策略强化学习框架，适用于从标准RL到复杂端到端决策（如自动驾驶）的多种场景。

Abstract: Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks due to their superior expressiveness and controllable generation during inference. However, effectively training large diffusion policies using reinforcement learning (RL) remains challenging. Existing methods either suffer from unstable training due to directly maximizing value objectives, or face computational issues due to relying on crude Gaussian likelihood approximation, which requires a large amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable weighted regression objective for diffusion policy extraction, but often struggles to balance greediness and stability. We then formulate a greedified policy regularization scheme, which naturally enables decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward maximization, and the other focuses on reward minimization. Under such a design, optimized actions can be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world applications.

</details>


### [349] [Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment](https://arxiv.org/abs/2601.00908)
*Chorok Lee*

Main category: cs.LG

TL;DR: 本文研究了在分布偏移下共形预测（conformal prediction）的性能退化问题，以COVID-19期间8个供应链任务为自然实验，发现特征剧烈更替（Jaccard≈0）下覆盖率下降差异巨大（0%–86.7%），并揭示单特征依赖性（SHAP集中度）是导致灾难性失败的关键因素；季度重训练可显著提升脆弱任务的覆盖率，但对鲁棒任务无效；据此提出基于SHAP集中度监控与差异化重训练的部署决策框架。


<details>
  <summary>Details</summary>
Motivation: 共形预测在分布偏移下的性能保障能力不足，亟需理解其失效机制并提出实用应对策略。

Method: 基于8个真实供应链任务（受COVID-19引发剧烈分布偏移影响），量化覆盖率变化；采用SHAP分析特征重要性分布，检验其与性能退化的相关性；评估季度重训练效果；扩展至4个中等稳定性任务以验证结论普适性；最终构建基于SHAP集中度的决策框架。

Result: 发现SHAP集中度与覆盖率崩溃强相关（rho=0.714, p=0.047）；脆弱任务特征重要性集中（+4.5×），鲁棒任务则分散（10–20×）；季度重训练使脆弱任务覆盖率从22%升至41%（+19pp, p=0.04），对鲁棒任务无改善（维持99.8%）；中等稳定性任务表明特征稳定性而非集中度主导鲁棒性，说明集中效应特指严重偏移场景。

Conclusion: SHAP重要性集中是严重分布偏移下共形预测失效的关键指标；应部署前监测该指标，并据此差异化实施重训练——高集中度（>40%）任务需季度更新，低集中度任务可免于重训，从而提升实际部署效率与可靠性。

Abstract: Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.

</details>


### [350] [Latent-Constrained Conditional VAEs for Augmenting Large-Scale Climate Ensembles](https://arxiv.org/abs/2601.00915)
*Jacquelyn Shelton,Przemyslaw Polewski,Alexander Robel,Matthew Hoffman,Stephen Price*

Main category: cs.LG

TL;DR: 本文提出了一种基于潜空间约束的条件变分自编码器（LC-CVAE）与多输出高斯过程回归相结合的方法，用于从有限气候模型集合中生成统计一致的新时空气候变量实现，解决了传统CVAE在跨集合泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 大型气候模型集合计算成本高昂，而许多下游分析需要更多统计一致的时空气候变量实现；现有生成模型（如CVAE）在跨集合成员泛化时表现不佳。

Method: 提出潜空间约束的条件变分自编码器（LC-CVAE），通过在少量共享地理‘锚点’位置强制不同集合成员的潜嵌入一致性；再利用多输出高斯过程回归在潜空间预测未采样位置的潜坐标，最后解码生成完整时空场。

Result: 实验表明：（i）单集合训练不稳定；（ii）约5个集合成员后收益递减；（iii）空间覆盖与重建质量存在权衡，且与潜空间中平均邻域距离密切相关。

Conclusion: LC-CVAE能有效提升生成样本的跨集合泛化能力与统计一致性，为低成本扩展气候集合提供了可行生成建模框架。

Abstract: Large climate-model ensembles are computationally expensive; yet many downstream analyses would benefit from additional, statistically consistent realizations of spatiotemporal climate variables. We study a generative modeling approach for producing new realizations from a limited set of available runs by transferring structure learned across an ensemble. Using monthly near-surface temperature time series from ten independent reanalysis realizations (ERA5), we find that a vanilla conditional variational autoencoder (CVAE) trained jointly across realizations yields a fragmented latent space that fails to generalize to unseen ensemble members. To address this, we introduce a latent-constrained CVAE (LC-CVAE) that enforces cross-realization homogeneity of latent embeddings at a small set of shared geographic 'anchor' locations. We then use multi-output Gaussian process regression in the latent space to predict latent coordinates at unsampled locations in a new realization, followed by decoding to generate full time series fields. Experiments and ablations demonstrate (i) instability when training on a single realization, (ii) diminishing returns after incorporating roughly five realizations, and (iii) a trade-off between spatial coverage and reconstruction quality that is closely linked to the average neighbor distance in latent space.

</details>


### [351] [Attention Needs to Focus: A Unified Perspective on Attention Allocation](https://arxiv.org/abs/2601.00919)
*Zichuan Fu,Wentao Song,Guojing Li,Yejing Wang,Xian Wu,Yimin Deng,Hanyu Yan,Yefeng Zheng,Xiangyu Zhao*

Main category: cs.LG

TL;DR: 本文提出Lazy Attention机制，通过位置区分和Elastic-Softmax解决注意力过载与欠载问题，缓解表征坍缩和注意力沉没，提升稀疏性与性能。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制存在表征坍缩和注意力沉没问题，以往研究多孤立处理，本文旨在揭示二者共源——不恰当的注意力分配。

Method: 提出Lazy Attention：1）通过跨头与跨维度的位置判别缓解注意力过载；2）引入Elastic-Softmax松弛softmax约束以抑制对无关token的注意力。

Result: 在FineWeb-Edu数据集及九个基准测试中，Lazy Attention有效缓解注意力沉没，性能媲美标准注意力及现代架构，并实现最高59.58%的注意力稀疏率。

Conclusion: 注意力过载与欠载是注意力机制根本性缺陷的两种表现；Lazy Attention提供统一、可解释且高效的改进路径。

Abstract: The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.

</details>


### [352] [MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs](https://arxiv.org/abs/2601.00920)
*Xingsheng Chen,Regina Zhang,Bo Gao,Xingwei He,Xiaofeng Liu,Pietro Lio,Kwok-Yan Lam,Siu-Ming Yiu*

Main category: cs.LG

TL;DR: 本文提出MODE框架，结合低秩神经微分方程与增强型Mamba架构，提升长时序预测的准确性、效率与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长程依赖和不规则采样时间序列时难以兼顾效率、可扩展性与精度。

Method: 提出MODE框架：输入经线性分词后，通过多个配备因果卷积、SiLU激活及低秩Neural ODE增强的Mamba编码器块处理；引入受伪ODE动力学启发的分段选择性扫描机制，自适应聚焦关键子序列。

Result: 在多个基准数据集上，MODE在预测精度和计算效率两方面均超越现有基线方法。

Conclusion: MODE实现了统一高效的时间序列建模架构，融合Mamba的选择性扫描与低秩Neural ODE以增强时序表征能力，并通过低秩近似与动态选择性扫描显著提升效率与可扩展性。

Abstract: Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.

</details>


### [353] [Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease](https://arxiv.org/abs/2601.00921)
*Azadeh Alavi,Hamidreza Khalili,Stanley H. Chan,Fatemeh Kouchmeshki,Ross Vlahos*

Main category: cs.LG

TL;DR: 本文研究了利用少量生物标志物预测慢性阻塞性肺病（COPD）小鼠模型中骨骼肌功能的可行性，比较了经典模型、几何感知SPD描述符与量子核模型，发现量子核岭回归在肌肉重量预测上表现最优，并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 骨骼肌功能障碍是COPD的重要肺外表现，与系统性及气道炎症密切相关；亟需基于微创生物标志物建立纵向可获取的预测模型。

Method: 在213只小鼠的预临床小样本数据集上，对比调优的经典基线模型、几何感知的对称正定（SPD）描述符（结合Stein散度）以及专为低维表格数据设计的量子核模型，预测三个连续肌肉指标：胫骨前肌重量、比力和肌肉质量指数。

Result: 量子核岭回归（使用4个可解释特征）在肌肉重量预测中达到测试RMSE=4.41 mg、R²=0.605，优于匹配的岭回归基线（RMSE=4.70 mg，R²=0.553）；Stein散度距离在仅用生物标志物时也带来稳定提升；筛查式二分类ROC-AUC最高达0.90。

Conclusion: 几何与量子核方法可在低数据、低特征的生物医学预测任务中提供可观测收益，同时兼顾模型可解释性与透明选择。

Abstract: Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.

</details>


### [354] [Complexity-based code embeddings](https://arxiv.org/abs/2601.00924)
*Rares Folea,Radu Iacob,Emil Slusanschi,Traian Rebedea*

Main category: cs.LG

TL;DR: 本文提出了一种通用方法，通过动态分析程序在不同输入下的行为，并针对分析指标定制多个通用复杂度函数，将各种算法的源代码转换为数值嵌入。该方法基于r-Complexity，所生成的代码嵌入用于XGBoost模型，在Codeforces平台真实代码片段构建的11类多标签数据集上取得了较高的平均F1-score。


<details>
  <summary>Details</summary>
Motivation: 需要一种通用且有效的源代码表示方法，以支持下游任务（如代码分类、相似性分析等），尤其在缺乏大量标注数据的编程竞赛场景中。

Method: 基于r-Complexity构建源代码的数值嵌入，通过动态执行程序并测量其在不同输入下的行为特征，再结合多个定制化的通用复杂度函数进行表征。

Result: 使用该嵌入训练的XGBoost模型在11类多标签代码数据集上达到了较高的平均F1-score。

Conclusion: 所提出的基于动态行为与r-Complexity的代码嵌入方法是通用且有效的，适用于编程竞赛代码的自动分析与分类任务。

Abstract: This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.

</details>


### [355] [Enhanced Data-Driven Product Development via Gradient Based Optimization and Conformalized Monte Carlo Dropout Uncertainty Estimation](https://arxiv.org/abs/2601.00932)
*Andrea Thomas Nava,Lijo Johny,Fabio Azzalini,Johannes Schneider,Arianna Casanova*

Main category: cs.LG

TL;DR: 本文提出了一种数据驱动的产品开发（DDPD）框架，结合联合神经网络与新型不确定性估计方法ConfMC，实现多目标优化与可靠置信区间预测。


<details>
  <summary>Details</summary>
Motivation: 许多产品需同时优化多个相关性能指标，且需对预测结果提供可靠的不确定性量化，现有方法在覆盖保证、适应性及重训练开销方面存在不足。

Method: 采用联合神经网络建模多目标间依赖关系；使用Projected Gradient Descent进行设计优化；引入Conformalised Monte Carlo Dropout（ConfMC），融合嵌套共形预测与MC Dropout，实现模型无关、有限样本下具有统计保证的不确定性估计。

Result: 在五个真实世界数据集上实验表明，该方法达到SOTA性能，同时提供自适应非均匀预测区间，并支持无需重训练地动态调整置信水平。

Conclusion: ConfMC增强的DDPD框架兼顾优化性能与统计可靠性，为工程设计中的可信AI决策提供了新范式。

Abstract: Data-Driven Product Development (DDPD) leverages data to learn the relationship between product design specifications and resulting properties. To discover improved designs, we train a neural network on past experiments and apply Projected Gradient Descent to identify optimal input features that maximize performance. Since many products require simultaneous optimization of multiple correlated properties, our framework employs joint neural networks to capture interdependencies among targets. Furthermore, we integrate uncertainty estimation via \emph{Conformalised Monte Carlo Dropout} (ConfMC), a novel method combining Nested Conformal Prediction with Monte Carlo dropout to provide model-agnostic, finite-sample coverage guarantees under data exchangeability. Extensive experiments on five real-world datasets show that our method matches state-of-the-art performance while offering adaptive, non-uniform prediction intervals and eliminating the need for retraining when adjusting coverage levels.

</details>


### [356] [LOFA: Online Influence Maximization under Full-Bandit Feedback using Lazy Forward Selection](https://arxiv.org/abs/2601.00933)
*Jinyu Xu,Abhishek K. Umrawal*

Main category: cs.LG

TL;DR: 本文研究在线影响最大化（IM）问题，提出了一种基于子模性利用的Lazy Online Forward Algorithm（LOFA），在全带臂反馈下实现更低的累积遗憾和更高的即时奖励。


<details>
  <summary>Details</summary>
Motivation: 现有在线IM算法虽利用影响函数的子模性，但仍有改进空间；且实际中常缺乏网络结构与传播过程的额外信息，需在纯黑箱反馈下优化性能。

Method: 提出Lazy Online Forward Algorithm（LOFA），进一步挖掘影响函数的子模性，在全带臂反馈模型下进行种子集选择，满足基数预算约束。

Result: 在真实社交网络上的实验表明，LOFA相比现有带臂算法显著降低了累积遗憾，并提升了即时奖励。

Conclusion: LOFA通过更精细地利用子模性，在无结构信息的在线IM设定中实现了更优的 regret 性能，验证了其有效性与实用性。

Abstract: We study the problem of influence maximization (IM) in an online setting, where the goal is to select a subset of nodes$\unicode{x2014}$called the seed set$\unicode{x2014}$at each time step over a fixed time horizon, subject to a cardinality budget constraint, to maximize the expected cumulative influence. We operate under a full-bandit feedback model, where only the influence of the chosen seed set at each time step is observed, with no additional structural information about the network or diffusion process. It is well-established that the influence function is submodular, and existing algorithms exploit this property to achieve low regret. In this work, we leverage this property further and propose the Lazy Online Forward Algorithm (LOFA), which achieves a lower empirical regret. We conduct experiments on a real-world social network to demonstrate that LOFA achieves superior performance compared to existing bandit algorithms in terms of cumulative regret and instantaneous reward.

</details>


### [357] [Reliability Under Randomness: An Empirical Analysis of Sparse and Dense Language Models Across Decoding Temperatures](https://arxiv.org/abs/2601.00942)
*Kabir Grover*

Main category: cs.LG

TL;DR: 本文研究了稀疏Mixture-of-Experts（MoE）大语言模型在温度采样解码下的输出稳定性问题，发现指令微调而非架构稀疏性才是决定其对解码随机性鲁棒性的关键因素。


<details>
  <summary>Details</summary>
Motivation: 稀疏MoE架构虽提升计算效率，但其与温度采样结合是否损害输出稳定性尚不明确，尤其在需高可靠性的场景中。

Method: 在确定性算术推理任务上，对比评估三个模型（OLMoE-7B、Mixtral-8x7B、Qwen2.5-3B）在四种解码温度下的准确性、格式合规性、输出一致性及置信度，共9360次生成。

Result: 稀疏指令微调模型（Mixtral）稳定性与稠密指令微调模型（Qwen2.5）相当；而稀疏基座模型（OLMoE）随温度升高系统性退化。

Conclusion: 指令微调是提升MoE模型解码鲁棒性的主因，稀疏架构本身不必然损害稳定性，可在可靠性关键场景中安全采用。

Abstract: The increasing prevalence of sparse Mixture-of-Experts (MoE) architectures in large language models raises important questions regarding their reliability under stochastic decoding. While conditional computation enables substantial gains in computational efficiency, it remains unclear whether the interaction between sparse routing and temperature-based sampling compromises output stability relative to dense architectures. This work investigates whether conditional computation in MoE models amplifies decoding-induced randomness, leading to reduced reliability as temperature increases. We evaluate three representative models: OLMoE-7B (sparse base), Mixtral-8x7B (sparse instruction-tuned), and Qwen2.5-3B (dense instruction-tuned) on deterministic arithmetic reasoning tasks with objectively verifiable answers. Experiments span four decoding configurations, ranging from greedy decoding to T=1.0. Our evaluation encompasses accuracy, format compliance, output consistency across repeated generations, and confidence metrics, totaling 9,360 model generations. Results demonstrate that the sparse instruction-tuned model exhibits stability comparable to the dense instruction-tuned model across all decoding temperatures, while the sparse base model shows systematic degradation as temperature increases. These findings indicate that instruction tuning, rather than architectural sparsity, is the primary determinant of robustness to decoding randomness on deterministic tasks. We discuss the implications of these results for deploying sparse language models in reliability-critical applications, highlighting scenarios in which sparse architectures can be safely adopted without sacrificing output stability.

</details>


### [358] [Adapting Feature Attenuation to NLP](https://arxiv.org/abs/2601.00965)
*Tianshuo Yang,Ryan Rabinowitz,Terrance E. Boult,Jugal Kalita*

Main category: cs.LG

TL;DR: 本文研究了将计算机视觉中的开放集识别（OSR）方法COSTARR迁移到NLP领域（如BERT、GPT-2）的效果，在176类arXiv主题分类任务上评估多种OSR打分策略，发现COSTARR无需重训练即可迁移但未显著优于MaxLogit或MSP，而自由能分数表现较差，表明视觉启发的OSR方法在NLP中仍有局限。


<details>
  <summary>Details</summary>
Motivation: Transformer模型（如BERT）在闭集分类中表现优异，但在面对未见类别时鲁棒性差，而实际NLP系统常面临此类开放集场景，亟需适配的开放集识别方法。

Method: 将计算机视觉中的COSTARR框架（基于特征衰减假设）适配至BERT（base）和GPT-2，并在176类arXiv主题数据上训练；同时对比评估MSP、MaxLogit及温度缩放的自由能分数，使用OOSA和AUOSCR指标进行评测。

Result: （i）COSTARR可直接迁移到NLP且无需重训练，但统计上未显著优于MaxLogit或MSP；（ii）自由能分数在此高类别数设置下表现最差。

Conclusion: 将视觉主导的OSR思想移植到语言模型具有潜力，但当前存在明显局限，需更大规模基础模型及面向NLP任务定制的特征衰减策略。

Abstract: Transformer classifiers such as BERT deliver impressive closed-set accuracy, yet they remain brittle when confronted with inputs from unseen categories--a common scenario for deployed NLP systems. We investigate Open-Set Recognition (OSR) for text by porting the feature attenuation hypothesis from computer vision to transformers and by benchmarking it against state-of-the-art baselines. Concretely, we adapt the COSTARR framework--originally designed for classification in computer vision--to two modest language models (BERT (base) and GPT-2) trained to label 176 arXiv subject areas. Alongside COSTARR, we evaluate Maximum Softmax Probability (MSP), MaxLogit, and the temperature-scaled free-energy score under the OOSA and AUOSCR metrics. Our results show (i) COSTARR extends to NLP without retraining but yields no statistically significant gain over MaxLogit or MSP, and (ii) free-energy lags behind all other scores in this high-class-count setting. The study highlights both the promise and the current limitations of transplanting vision-centric OSR ideas to language models, and points toward the need for larger backbones and task-tailored attenuation strategies.

</details>


### [359] [Explainability-Guided Defense: Attribution-Aware Model Refinement Against Adversarial Data Attacks](https://arxiv.org/abs/2601.00968)
*Longwei Wang,Mohammad Navid Nayyem,Abdullah Al Rakin,KC Santosh,Chaowei Zhang,Yang Zhou*

Main category: cs.LG

TL;DR: 本文提出一种基于归因引导的深度学习模型鲁棒性提升框架，利用LIME解释方法识别并抑制模型中导致对抗脆弱性的虚假特征，通过特征掩码、敏感性感知正则化和对抗增强，在不改变模型结构或增加数据的前提下提升对抗鲁棒性和分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医疗、自动驾驶等安全关键领域广泛应用，亟需兼具对抗鲁棒性与决策透明性的防御机制；作者发现LIME揭示的虚假/不稳定特征与模型对抗脆弱性密切相关。

Method: 提出归因引导的精细化训练框架：将LIME从被动解释工具转为主动训练信号，结合特征掩码、敏感性感知正则化与对抗增强构成闭环优化流程，并理论推导了归因对齐与鲁棒性之间的下界关系。

Result: 在CIFAR-10、CIFAR-10-C和CIFAR-100上显著提升了对抗鲁棒性与分布外泛化性能，且无需额外数据或模型结构调整。

Conclusion: 归因解释不仅可用于模型诊断，还可作为可微分训练信号直接提升鲁棒性；归因对齐是提升鲁棒性的有效且可理论刻画的途径。

Abstract: The growing reliance on deep learning models in safety-critical domains such as healthcare and autonomous navigation underscores the need for defenses that are both robust to adversarial perturbations and transparent in their decision-making. In this paper, we identify a connection between interpretability and robustness that can be directly leveraged during training. Specifically, we observe that spurious, unstable, or semantically irrelevant features identified through Local Interpretable Model-Agnostic Explanations (LIME) contribute disproportionately to adversarial vulnerability. Building on this insight, we introduce an attribution-guided refinement framework that transforms LIME from a passive diagnostic into an active training signal. Our method systematically suppresses spurious features using feature masking, sensitivity-aware regularization, and adversarial augmentation in a closed-loop refinement pipeline. This approach does not require additional datasets or model architectures and integrates seamlessly into standard adversarial training. Theoretically, we derive an attribution-aware lower bound on adversarial distortion that formalizes the link between explanation alignment and robustness. Empirical evaluations on CIFAR-10, CIFAR-10-C, and CIFAR-100 demonstrate substantial improvements in adversarial robustness and out-of-distribution generalization.

</details>


### [360] [Contractive Diffusion Policies: Robust Action Diffusion via Contractive Score-Based Sampling with Differential Equations](https://arxiv.org/abs/2601.01003)
*Amin Abyaneh,Charlotte Morissette,Mohamad H. Danesh,Anas El Houssaini,David Meger,Gregory Dudek,Hsiu-Chin Lin*

Main category: cs.LG

TL;DR: 本文提出Contractive Diffusion Policies (CDPs)，通过在扩散采样动力学中引入收缩性行为，提升离线策略学习在连续控制任务中的鲁棒性与数据效率。


<details>
  <summary>Details</summary>
Motivation: 扩散策略虽具灵活性，但在连续控制中因求解器误差、分数匹配误差、数据需求大及动作生成不一致等问题易失效。

Method: 设计具有收缩性的扩散采样动力学，理论分析其鲁棒性提升机制，并提供可即插即用的实现方案，适配现有扩散策略架构。

Result: 在仿真与真实世界实验中，CDPs在多个基准上超越基线方法，尤其在数据稀缺时优势显著。

Conclusion: CDPs通过收缩性建模有效缓解扩散策略在控制任务中的关键缺陷，兼顾性能提升与部署简易性。

Abstract: Diffusion policies have emerged as powerful generative models for offline policy learning, whose sampling process can be rigorously characterized by a score function guiding a Stochastic Differential Equation (SDE). However, the same score-based SDE modeling that grants diffusion policies the flexibility to learn diverse behavior also incurs solver and score-matching errors, large data requirements, and inconsistencies in action generation. While less critical in image generation, these inaccuracies compound and lead to failure in continuous control settings. We introduce Contractive Diffusion Policies (CDPs) to induce contractive behavior in the diffusion sampling dynamics. Contraction pulls nearby flows closer to enhance robustness against solver and score-matching errors while reducing unwanted action variance. We develop an in-depth theoretical analysis along with a practical implementation recipe to incorporate CDPs into existing diffusion policy architectures with minimal modification and computational cost. We evaluate CDPs for offline learning by conducting extensive experiments in simulation and real-world settings. Across benchmarks, CDPs often outperform baseline policies, with pronounced benefits under data scarcity.

</details>


### [361] [Zero-shot Forecasting by Simulation Alone](https://arxiv.org/abs/2601.00970)
*Boris N. Oreshkin,Mayank Jauhari,Ravi Kiran Selvam,Malcolm Wolff,Wenhao Pan,Shankar Ramasubramanian,Kin G. Olivares,Tatiana Konstantinova,Andres Potapczynski,Mengfei Cao,Dmitry Efimov,Michael W. Mahoney,Andrew G. Wilson*

Main category: cs.LG

TL;DR: 本文提出了一种名为SarSim0的快速、实用的单变量时间序列仿真管道，用于零样本时间序列预测，通过改进SARIMA模型生成高质量模拟数据，在M-Series和GiftEval基准上实现了卓越的零样本预测性能。


<details>
  <summary>Details</summary>
Motivation: 零样本时间序列预测面临数据有限且存在偏差、评估易泄漏、隐私与授权限制等挑战。

Method: 基于SARIMA模型构建SarSim0仿真器，采用三步法：(1)在特征多项式稳定区域内采样良态轨迹；(2)叠加多路径生成多季节性序列；(3)引入基于速率的重尾噪声模型以刻画突发性和间歇性。

Result: SarSim0比核方法快数个数量级，支持实时生成约10亿条独特模拟序列；训练后的神经网络在零样本协议下显著超越统计预测器和近期基础模型；在GiftEval上出现‘学生超越教师’现象——模型预测精度超过其生成所用的AutoARIMA过程。

Conclusion: SarSim0为零样本时间序列预测提供了首个兼具高效性与实用性的仿真方案，突破了数据瓶颈，并验证了纯模拟数据训练可实现强泛化能力。

Abstract: Zero-shot time-series forecasting holds great promise, but is still in its infancy, hindered by limited and biased data corpora, leakage-prone evaluation, and privacy and licensing constraints. Motivated by these challenges, we propose the first practical univariate time series simulation pipeline which is simultaneously fast enough for on-the-fly data generation and enables notable zero-shot forecasting performance on M-Series and GiftEval benchmarks that capture trend/seasonality/intermittency patterns, typical of industrial forecasting applications across a variety of domains. Our simulator, which we call SarSim0 (SARIMA Simulator for Zero-Shot Forecasting), is based off of a seasonal autoregressive integrated moving average (SARIMA) model as its core data source. Due to instability in the autoregressive component, naive SARIMA simulation often leads to unusable paths. Instead, we follow a three-step procedure: (1) we sample well-behaved trajectories from its characteristic polynomial stability region; (2) we introduce a superposition scheme that combines multiple paths into rich multi-seasonality traces; and (3) we add rate-based heavy-tailed noise models to capture burstiness and intermittency alongside seasonalities and trends. SarSim0 is orders of magnitude faster than kernel-based generators, and it enables training on circa 1B unique purely simulated series, generated on the fly; after which well-established neural network backbones exhibit strong zero-shot generalization, surpassing strong statistical forecasters and recent foundation baselines, while operating under strict zero-shot protocol. Notably, on GiftEval we observe a "student-beats-teacher" effect: models trained on our simulations exceed the forecasting accuracy of the AutoARIMA generating processes.

</details>


### [362] [Data-Driven Assessment of Concrete Mixture Compositions on Chloride Transport via Standalone Machine Learning Algorithms](https://arxiv.org/abs/2601.01009)
*Mojtaba Aliasghar-Mamaghani,Mohammadreza Khalafi*

Main category: cs.LG

TL;DR: 本文采用多种机器学习算法（如KRR、GPR、MLP等）分析混凝土配比对氯离子时变演化的影响，发现多数组分与氯离子含量呈负相关，部分呈正相关；GPR等模型能揭示潜在可解释的相关性，为提升基础设施服役寿命提供数据驱动支持。


<details>
  <summary>Details</summary>
Motivation: 评估受侵蚀环境影响的民用基础设施服役寿命，需准确理解混凝土配比对氯离子时变演化的影响。

Method: 采用线性回归（LR）、K近邻（KNN）、核岭回归（KRR）、支持向量回归（SVR）、高斯过程回归（GPR）、多层感知机（MLP）和门控循环单元（GRU）等多种机器学习算法，基于大规模混凝土配比与氯离子扩散数据进行建模与预测。

Result: KRR、GPR和MLP表现最优；GRU因配比多样性大而泛化不佳；GPR揭示了清晰可解释的隐含相关性；多数混凝土组分与氯离子含量呈负相关，少数呈正相关。

Conclusion: 机器学习代理模型可有效刻画氯离子侵入的物理过程及相关性，有望支撑基础设施服役寿命预测与优化设计。

Abstract: This paper employs a data-driven approach to determine the impact of concrete mixture compositions on the temporal evolution of chloride in concrete structures. This is critical for assessing the service life of civil infrastructure subjected to aggressive environments. The adopted methodology relies on several simple and complex standalone machine learning (ML) algorithms, with the primary objective of establishing confidence in the unbiased prediction of the underlying hidden correlations. The simple algorithms include linear regression (LR), k-nearest neighbors (KNN) regression, and kernel ridge regression (KRR). The complex algorithms entail support vector regression (SVR), Gaussian process regression (GPR), and two families of artificial neural networks, including a feedforward network (multilayer perceptron, MLP) and a gated recurrent unit (GRU). The MLP architecture cannot explicitly handle sequential data, a limitation addressed by the GRU. A comprehensive dataset is considered. The performance of ML algorithms is evaluated, with KRR, GPR, and MLP exhibiting high accuracy. Given the diversity of the adopted concrete mixture proportions, the GRU was unable to accurately reproduce the response in the test set. Further analyses elucidate the contributions of mixture compositions to the temporal evolution of chloride. The results obtained from the GPR model unravel latent correlations through clear and explainable trends. The MLP, SVR, and KRR also provide acceptable estimates of the overall trends. The majority of mixture components exhibit an inverse relation with chloride content, while a few components demonstrate a direct correlation. These findings highlight the potential of surrogate approaches for describing the physical processes involved in chloride ingress and the associated correlations, toward the ultimate goal of enhancing the service life of civil infrastructure.

</details>


### [363] [Geometric and Dynamic Scaling in Deep Transformers](https://arxiv.org/abs/2601.01014)
*Haoran Su,Chenyu You*

Main category: cs.LG

TL;DR: 本文指出深度Transformer模型的表征崩溃本质上是几何问题，提出Manifold-Geometric Transformer（MGT）架构，通过流形约束超连接和深度delta学习来稳定深层特征演化，避免秩崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有方法将深度Transformer的表征崩溃归因于优化不稳定或梯度消失，但无法解释其在现代归一化与初始化下仍持续发生；作者认为根本原因是标准残差更新缺乏对更新方向和信息擦除的几何约束，导致语义流形漂移与特征冗余累积。

Method: 提出统一几何框架：1）流形约束超连接，将残差更新限制在局部切空间内以防止流形漂移；2）深度delta学习，实现数据依赖、非单调的特征更新以支持冗余特征的反射与擦除。

Result: 所提MGT架构能解耦特征更新的方向与符号，实现跨深度稳定的几何演化；理论分析预测：保证几何有效性并支持动态擦除，是避免超深层网络秩崩溃的关键。

Conclusion: 深度Transformer的性能瓶颈不在深度本身，而在于缺乏对表征几何结构的显式建模；几何约束与动态擦除机制共同构成解决深层表征退化的根本路径。

Abstract: Despite their empirical success, pushing Transformer architectures to extreme depth often leads to a paradoxical failure: representations become increasingly redundant, lose rank, and ultimately collapse. Existing explanations largely attribute this phenomenon to optimization instability or vanishing gradients, yet such accounts fail to explain why collapse persists even under modern normalization and initialization schemes. In this paper, we argue that the collapse of deep Transformers is fundamentally a geometric problem. Standard residual updates implicitly assume that feature accumulation is always beneficial, but offer no mechanism to constrain update directions or to erase outdated information. As depth increases, this leads to systematic drift off the semantic manifold and monotonic feature accumulation, causing representational degeneracy. We propose a unified geometric framework that addresses these failures through two orthogonal principles. First, manifold-constrained hyper-connections restrict residual updates to valid local tangent directions, preventing uncontrolled manifold drift. Second, deep delta learning introduces data-dependent, non-monotonic updates that enable reflection and erasure of redundant features rather than their unconditional accumulation. Together, these mechanisms decouple the direction and sign of feature updates, yielding a stable geometric evolution across depth. We term the resulting architecture the Manifold-Geometric Transformer (MGT). Our analysis predicts that enforcing geometric validity while allowing dynamic erasure is essential for avoiding rank collapse in ultra-deep networks. We outline an evaluation protocol for Transformers exceeding 100 layers to test the hypothesis that geometry, rather than depth itself, is the key limiting factor in deep representation learning.

</details>


### [364] [Improving Variational Autoencoder using Random Fourier Transformation: An Aviation Safety Anomaly Detection Case-Study](https://arxiv.org/abs/2601.01016)
*Ata Akbari Asanjan,Milad Memarzadeh,Bryan Matthews,Nikunj Oza*

Main category: cs.LG

TL;DR: 本文研究了随机傅里叶变换（RFT）对自编码器（AE）和变分自编码器（VAE）训练与推理的改进作用，结合频率原理（F-Principle）分析其学习行为，并提出一种可训练的RFT变体；实验在合成数据与航空安全数据集（Dashlink）上验证了RFT的有效性，但可训练版本优势尚不明确。


<details>
  <summary>Details</summary>
Motivation: 提升自编码器类模型在重建式异常检测中的性能，并深入理解RFT如何改变DNN的频域学习行为（特别是对比传统DNN遵循的F-Principle）。

Method: 将随机傅里叶变换（RFT）引入AE/VAE结构中，结合F-Principle进行频域训练行为分析；提出一种基于现有计算图端到端可训练的RFT变体；在低维合成数据和高维Dashlink航空安全数据集上开展重建式异常检测实验。

Result: RFT增强的AE/VAE模型在重建性能和异常检测效果上优于传统模型；F-Principle分析表明RFT使模型能同时学习高低频特征，而传统DNN先学低频、后学高频；可训练RFT未显著优于随机RFT。

Conclusion: RFT是提升AE/VAE重建与异常检测能力的有效手段，改变了模型的频域学习动态；但RFT是否需可训练仍需进一步研究。

Abstract: In this study, we focus on the training process and inference improvements of deep neural networks (DNNs), specifically Autoencoders (AEs) and Variational Autoencoders (VAEs), using Random Fourier Transformation (RFT). We further explore the role of RFT in model training behavior using Frequency Principle (F-Principle) analysis and show that models with RFT turn to learn low frequency and high frequency at the same time, whereas conventional DNNs start from low frequency and gradually learn (if successful) high-frequency features. We focus on reconstruction-based anomaly detection using autoencoder and variational autoencoder and investigate the RFT's role. We also introduced a trainable variant of RFT that uses the existing computation graph to train the expansion of RFT instead of it being random. We showcase our findings with two low-dimensional synthetic datasets for data representation, and an aviation safety dataset, called Dashlink, for high-dimensional reconstruction-based anomaly detection. The results indicate the superiority of models with Fourier transformation compared to the conventional counterpart and remain inconclusive regarding the benefits of using trainable Fourier transformation in contrast to the Random variant.

</details>


### [365] [Expanding the Chaos: Neural Operator for Stochastic (Partial) Differential Equations](https://arxiv.org/abs/2601.01021)
*Dai Shi,Lequan Lin,Andi Han,Luke Thompson,José Miguel Hernández-Lobato,Zhiyong Wang,Junbin Gao*

Main category: cs.LG

TL;DR: 本文提出了一种基于Wiener混沌展开（WCE）的神经算子架构，用于高效近似随机微分方程（SDEs）和随机偏微分方程（SPDEs）的解算子，兼具理论可解释性与实际泛化能力。


<details>
  <summary>Details</summary>
Motivation: 发展能快速求解SDEs/SPDEs的深度学习模型，不仅提供实用求解器，还可能为经典学习任务提供新视角；传统数值方法计算成本高，而现有数据驱动方法缺乏对随机性与确定性动力学分离的显式建模。

Method: 将驱动噪声路径投影到正交Wick-Hermite基上，用神经算子参数化各阶混沌系数，并通过单次前向传播重构完整解轨迹；理论上推导了多维SDE和半线性SPDE对应的混沌系数耦合ODE/PDE系统。

Result: 在经典SPDE基准、图像扩散采样、图拓扑插值、金融外推、参数估计及洪水预测的流形SDE等多个任务上验证了模型的高精度与广泛适用性。

Conclusion: 基于WCE的神经算子是一种实用、可扩展的学习SDE/SPDE解算子的方法，适用于跨领域建模。

Abstract: Stochastic differential equations (SDEs) and stochastic partial differential equations (SPDEs) are fundamental tools for modeling stochastic dynamics across the natural sciences and modern machine learning. Developing deep learning models for approximating their solution operators promises not only fast, practical solvers, but may also inspire models that resolve classical learning tasks from a new perspective. In this work, we build on classical Wiener chaos expansions (WCE) to design neural operator (NO) architectures for SPDEs and SDEs: we project the driving noise paths onto orthonormal Wick Hermite features and parameterize the resulting deterministic chaos coefficients with neural operators, so that full solution trajectories can be reconstructed from noise in a single forward pass. On the theoretical side, we investigate the classical WCE results for the class of multi-dimensional SDEs and semilinear SPDEs considered here by explicitly writing down the associated coupled ODE/PDE systems for their chaos coefficients, which makes the separation between stochastic forcing and deterministic dynamics fully explicit and directly motivates our model designs. On the empirical side, we validate our models on a diverse suite of problems: classical SPDE benchmarks, diffusion one-step sampling on images, topological interpolation on graphs, financial extrapolation, parameter estimation, and manifold SDEs for flood prediction, demonstrating competitive accuracy and broad applicability. Overall, our results indicate that WCE-based neural operators provide a practical and scalable way to learn SDE/SPDE solution operators across diverse domains.

</details>


### [366] [Wireless Dataset Similarity: Measuring Distances in Supervised and Unsupervised Machine Learning](https://arxiv.org/abs/2601.01023)
*João Morais,Sadjad Alikhani,Akshay Malhotra,Shahab Hamidi-Rad,Ahmed Alkhateeb*

Main category: cs.LG

TL;DR: 本文提出了一种任务和模型感知的无线数据集相似性度量框架，通过预测跨数据集迁移性能来评估距离指标，并在CSI压缩和下行波束预测两个任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有无线数据集间缺乏任务相关的相似性度量方法，难以支持数据集选择、仿真到实测对比、合成数据生成及模型迁移等实际需求。

Method: 提出基于UMAP嵌入结合Wasserstein与欧氏距离的无监督距离度量；针对监督任务（波束预测），设计标签感知的监督UMAP距离并引入数据不平衡惩罚。

Result: 在CSI压缩任务中，所提距离与模型跨数据集性能的Pearson相关性超0.85；在波束预测任务中，新距离显著优于传统基线，且与迁移性能保持更强相关性。

Conclusion: 任务与模型感知的距离度量能更准确反映无线数据集间的实际可迁移性，为无线AI系统中的数据与模型协同优化提供理论支撑与实用工具。

Abstract: This paper introduces a task- and model-aware framework for measuring similarity between wireless datasets, enabling applications such as dataset selection/augmentation, simulation-to-real (sim2real) comparison, task-specific synthetic data generation, and informing decisions on model training/adaptation to new deployments. We evaluate candidate dataset distance metrics by how well they predict cross-dataset transferability: if two datasets have a small distance, a model trained on one should perform well on the other. We apply the framework on an unsupervised task, channel state information (CSI) compression, using autoencoders. Using metrics based on UMAP embeddings, combined with Wasserstein and Euclidean distances, we achieve Pearson correlations exceeding 0.85 between dataset distances and train-on-one/test-on-another task performance. We also apply the framework to a supervised beam prediction in the downlink using convolutional neural networks. For this task, we derive a label-aware distance by integrating supervised UMAP and penalties for dataset imbalance. Across both tasks, the resulting distances outperform traditional baselines and consistently exhibit stronger correlations with model transferability, supporting task-relevant comparisons between wireless datasets.

</details>


### [367] [Coarse-Grained Kullback--Leibler Control of Diffusion-Based Generative AI](https://arxiv.org/abs/2601.01045)
*Tatsuaki Tsuruyama*

Main category: cs.LG

TL;DR: 本文将信息论Lyapunov函数V及其容错变体V-delta引入反向扩散过程，提出V-delta投影的反向扩散方法，在保持像素级质量的同时，显式控制图像分块后的粗粒度统计量（如块强度、类别比例）并保证其误差在预设容差内。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型缺乏对反向过程中粗粒度图像统计量（如分块强度或类别比例）如何演化与保持的理论刻画，亟需一种能显式约束和调控这些量的生成机制。

Method: 将此前提出的基于状态空间分块的信息论Lyapunov函数V及容漏型势函数V-delta，移植至生成模型的反向扩散过程；设计V-delta投影的反向扩散方案；扩展V的单调性至时变的块保持马尔可夫核；在块常数图像与简化反向核的玩具模型上进行数值验证。

Result: 证明在小泄漏与V-delta投影下，V-delta是近似Lyapunov函数；数值实验表明该方法可在满足块质量误差与V-delta势值容差的前提下，保持与非投影方法相当的像素精度与视觉质量。

Conclusion: 本研究将生成采样重新诠释为信息势从噪声到数据的递减过程，为设计具有粗粒度可控性的反向扩散流程提供了理论依据与实用原则。

Abstract: Diffusion models and score-based generative models provide a powerful framework for synthesizing high-quality images from noise. However, there is still no satisfactory theory that describes how coarse-grained quantities, such as blockwise intensity or class proportions after partitioning an image into spatial blocks, are preserved and evolve along the reverse diffusion dynamics. In previous work, the author introduced an information-theoretic Lyapunov function V for non-ergodic Markov processes on a state space partitioned into blocks, defined as the minimal Kullback-Leibler divergence to the set of stationary distributions reachable from a given initial condition, and showed that a leak-tolerant potential V-delta with a prescribed tolerance for block masses admits a closed-form expression as a scaling-and-clipping operation on block masses.
  In this paper, I transplant this framework to the reverse diffusion process in generative models and propose a reverse diffusion scheme that is projected by the potential V-delta (referred to as the V-delta projected reverse diffusion). I extend the monotonicity of V to time-inhomogeneous block-preserving Markov kernels and show that, under small leakage and the V-delta projection, V-delta acts as an approximate Lyapunov function. Furthermore, using a toy model consisting of block-constant images and a simplified reverse kernel, I numerically demonstrate that the proposed method keeps the block-mass error and the leak-tolerant potential within the prescribed tolerance, while achieving pixel-wise accuracy and visual quality comparable to the non-projected dynamics. This study reinterprets generative sampling as a decrease of an information potential from noise to data, and provides a design principle for reverse diffusion processes with explicit control of coarse-grained quantities.

</details>


### [368] [A UCB Bandit Algorithm for General ML-Based Estimators](https://arxiv.org/abs/2601.01061)
*Yajing Liu,Erkao Bao,Linqi Song*

Main category: cs.LG

TL;DR: 本文提出ML-UCB算法，将任意机器学习模型嵌入多臂老虎机框架，通过建模学习曲线（如MSE按幂律衰减）推导广义集中不等式，实现亚线性遗憾，并在协同过滤推荐实验中优于LinUCB。


<details>
  <summary>Details</summary>
Motivation: 部署复杂机器学习模型进行序贯决策时，缺乏可处理的集中不等式以支持有原则的探索。

Method: 提出ML-UCB算法，假设均方误差随训练样本数呈幂律下降，据此推导广义集中不等式，并将任意可经验刻画学习曲线的ML模型集成到多臂老虎机框架中。

Result: 理论证明ML-UCB具有亚线性遗憾；实验表明其在基于在线矩阵分解的协同过滤推荐系统中显著优于LinUCB。

Conclusion: ML-UCB为通用ML模型在序贯决策中的集成提供了无需模型特化理论分析的统一框架。

Abstract: We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB

</details>


### [369] [SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models](https://arxiv.org/abs/2601.01062)
*Yunlin Zeng*

Main category: cs.LG

TL;DR: 本文提出了一种端到端视觉播客生成新方法，通过在合成图像-对话对上微调Qwen3-VL-32B模型，并在真实照片序列上评估，结合AI评委与新型风格指标，显著提升多说话人对话的自然性与叙事深度。


<details>
  <summary>Details</summary>
Motivation: 现有VLM在长篇、多说话人、具人格化和叙事流的视觉播客生成任务中能力未被充分探索，且传统文本指标（如BLEU、ROUGE）无法有效评估对话自然性、个性与叙事连贯性。

Method: 构建端到端视觉播客生成流程；采用合成到真实（synthetic-to-real）训练策略：在SPoRC播客对话+合成图像上微调Qwen3-VL-32B（4k样本）；评估使用真实VIST图像序列；引入AI-as-a-judge（Gemini 3 Pro等）及新型风格指标（平均话轮长度、说话人切换率）。

Result: 微调后的32B模型在对话自然性上胜过235B基座模型超80%，话轮长度提升50%，CLIPScore保持20.39，表明视觉定位能力未损。

Conclusion: 合成数据可有效支撑真实视觉播客生成；模型规模非越大越好，针对性微调与合理评估框架更能提升叙事型VLM性能；所提评估范式为VLM长文本生成研究提供新基准。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\% win rate) and narrative depth (+50\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).

</details>


### [370] [Tiny Machine Learning for Real-Time Aquaculture Monitoring: A Case Study in Morocco](https://arxiv.org/abs/2601.01065)
*Achraf Hsain,Yahya Zaki,Othman Abaakil,Hibat-allah Bekkar,Yousra Chtouki*

Main category: cs.LG

TL;DR: 本文提出了一种基于低功耗边缘设备与TinyML技术的实时水产养殖监测系统，用于自动监控水质参数（如pH、温度、溶解氧、氨氮），实现异常报警、优化投喂与水处理，提升管理效率与可持续性。


<details>
  <summary>Details</summary>
Motivation: 传统水产养殖监测依赖人工、耗时且易延误问题响应，面临水质波动、病害和饲料管理低效等挑战。

Method: 集成低功耗边缘设备与TinyML技术，设计传感器网络与轻量算法，在资源受限硬件上实现实时数据采集、异常检测与报警，并支持后续决策分析。

Result: 构建了可实时监测关键水质参数并触发告警的TinyML系统，验证了其在传感器选型、算法部署、硬件适配及伦理方面的可行性。

Conclusion: TinyML在水产养殖中具备应用可行性，有助于推动可持续、高效、低人力依赖的智能养殖实践。

Abstract: Aquaculture, the farming of aquatic organisms, is a rapidly growing industry facing challenges such as water quality fluctuations, disease outbreaks, and inefficient feed management. Traditional monitoring methods often rely on manual labor and are time consuming, leading to potential delays in addressing issues. This paper proposes the integration of low-power edge devices using Tiny Machine Learning (TinyML) into aquaculture systems to enable real-time automated monitoring and control, such as collecting data and triggering alarms, and reducing labor requirements. The system provides real-time data on the required parameters such as pH levels, temperature, dissolved oxygen, and ammonia levels to control water quality, nutrient levels, and environmental conditions enabling better maintenance, efficient resource utilization, and optimal management of the enclosed aquaculture space. The system enables alerts in case of anomaly detection. The data collected by the sensors over time can serve for important decision-making regarding optimizing water treatment processes, feed distribution, feed pattern analysis and improve feed efficiency, reducing operational costs. This research explores the feasibility of developing TinyML-based solutions for aquaculture monitoring, considering factors such as sensor selection, algorithm design, hardware constraints, and ethical considerations. By demonstrating the potential benefits of TinyML in aquaculture, our aim is to contribute to the development of more sustainable and efficient farming practices.

</details>


### [371] [Revisiting Weighted Strategy for Non-stationary Parametric Bandits and MDPs](https://arxiv.org/abs/2601.01069)
*Jing Wang,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文重新审视了非平稳参数化赌博机中的加权策略，提出了一种精炼的分析框架，简化了算法设计并提升了统计效率，在线性、广义线性及自协调带状赌博机中均获得更优的动态遗憾界，并扩展至带函数逼近的非平稳MDP。


<details>
  <summary>Details</summary>
Motivation: 加权策略在实际非平稳环境中广泛应用，但其理论分析复杂、算法效率低或统计次优，亟需改进。

Method: 提出一种精炼的加权策略分析框架，应用于线性带状赌博机（LB）、广义线性带状赌博机（GLB）、自协调带状赌博机（SCB）以及线性混合MDP和MNL混合MDP，推导更紧的动态遗憾界并设计高效算法。

Result: 在线性带状赌博机中获得与窗/重启法同等效率且相同遗憾的简化加权算法；在GLB中将遗憾界从\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})改进为\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})；并将该框架成功拓展至两类非平稳MDP，给出动态遗憾保证。

Conclusion: 精炼分析框架统一提升了加权策略在多种非平稳序贯决策问题中的理论性能与实用性，弥合理论与应用之间的差距。

Abstract: Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a \emph{refined analysis framework}, which simplifies the derivation and, importantly, produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$ regret, improving the $\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$ bound in prior work, where $k_μ$ and $c_μ$ characterize the reward model's nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon. Moreover, we extend our framework to non-stationary Markov Decision Processes (MDPs) with function approximation, focusing on Linear Mixture MDP and Multinomial Logit (MNL) Mixture MDP. For both classes, we propose algorithms based on the weighted strategy and establish dynamic regret guarantees using our analysis framework.

</details>


### [372] [Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments](https://arxiv.org/abs/2601.01075)
*Hansen Jin Lillemark,Benhao Huang,Fangneng Zhan,Yilun Du,Thomas Anderson Keller*

Main category: cs.LG

TL;DR: 本文提出了一种名为'Flow Equivariant World Models'的新型世界模型框架，将智能体自身运动与外部物体运动统一建模为李群‘流’，并利用该结构实现对这些变换的群等变性，从而在数百时间步内保持稳定的潜在世界表征。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络世界模型忽略感官输入与运动之间的平滑时序对称性及其代数结构，导致重复从数据中学习相同变换，效率低下。

Method: 将自运动和外部物体运动统一为一参数李群‘流’，并在此基础上构建具有群等变性的世界模型，以保证潜在表示的时间稳定性。

Result: 在2D/3D部分可观测视频世界建模基准上显著优于当前主流扩散模型和记忆增强架构，尤其在视野外存在可预测动态、以及长程rollout任务中表现突出，泛化能力远超训练时长。

Conclusion: 通过将世界模型表征与内外部运动对称性对齐，flow equivariance为实现数据高效、对称性引导的具身智能提供了可扩展路径。

Abstract: Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.

</details>


### [373] [Discount Model Search for Quality Diversity Optimization in High-Dimensional Measure Spaces](https://arxiv.org/abs/2601.01082)
*Bryon Tjanaka,Henry Chen,Matthew C. Fontaine,Stefanos Nikolaidis*

Main category: cs.LG

TL;DR: 本文提出Discount Model Search (DMS)算法，通过建模连续折扣值来解决高维度衡量空间中质量多样性（QD）优化的失真与停滞问题，并支持以图像数据集作为衡量标准的新应用。


<details>
  <summary>Details</summary>
Motivation: 现有QD算法（如CMA-MAE）在高维衡量空间中易因直方图离散化导致解映射到相同单元、折扣值相同而停滞；且用户需手工设计衡量函数，灵活性差。

Method: 提出DMS算法，用可学习的连续模型替代直方图，为衡量空间提供平滑、连续的折扣值估计；支持将图像空间作为高维衡量空间，直接以图像数据集定义衡量目标。

Result: DMS在高维基准测试及两个基于图像衡量空间的新任务上均显著优于CMA-MAE及其他黑箱QD算法。

Conclusion: DMS通过连续折扣建模有效缓解高维衡量空间中的失真问题，拓展了QD优化的应用边界，尤其支持数据驱动的衡量定义方式。

Abstract: Quality diversity (QD) optimization searches for a collection of solutions that optimize an objective while attaining diverse outputs of a user-specified, vector-valued measure function. Contemporary QD algorithms focus on low-dimensional measures because high-dimensional measures are prone to distortion, where many solutions found by the QD algorithm map to similar measures. For example, the CMA-MAE algorithm guides measure space exploration with a histogram in measure space that records so-called discount values. However, CMA-MAE stagnates in domains with high-dimensional measure spaces because solutions with similar measures fall into the same histogram cell and thus receive identical discount values. To address these limitations, we propose Discount Model Search (DMS), which guides exploration with a model that provides a smooth, continuous representation of discount values. In high-dimensional measure spaces, this model enables DMS to distinguish between solutions with similar measures and thus continue exploration. We show that DMS facilitates new QD applications by introducing two domains where the measure space is the high-dimensional space of images, which enables users to specify their desired measures by providing a dataset of images rather than hand-designing the measure function. Results in these domains and on high-dimensional benchmarks show that DMS outperforms CMA-MAE and other black-box QD algorithms.

</details>


### [374] [Central Dogma Transformer: Towards Mechanism-Oriented AI for Cellular Understanding](https://arxiv.org/abs/2601.01089)
*Nobuyuki Ota*

Main category: cs.LG

TL;DR: 本文提出了一种名为Central Dogma Transformer（CDT）的新型AI架构，通过遵循中心法则的方向性逻辑，整合DNA、RNA和蛋白质三类分子模态的预训练语言模型，实现对细胞过程的统一建模，并在CRISPRi增强子扰动数据上验证了其预测能力与生物学可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有针对DNA、RNA、蛋白的领域专用基础模型彼此孤立，难以建模跨模态的整合细胞过程，亟需一种符合中心法则信息流向的统一建模框架。

Method: 提出CDT架构，采用方向性交叉注意力机制（DNA→RNA建模转录调控，RNA→蛋白建模翻译关系），融合三模态预训练语言模型，生成统一的Virtual Cell Embedding；使用固定RNA/蛋白嵌入实现CDT v1，并在K562细胞CRISPRi数据上评估；结合注意力分析与梯度分析进行可解释性研究。

Result: CDT v1在K562 CRISPRi增强子扰动预测任务中达到Pearson相关系数0.503（达理论上限的63%）；注意力与梯度分析揭示互补的基因组区域，梯度分析成功识别出Hi-C证实与增强子及靶基因均有物理互作的CTCF位点。

Conclusion: 遵循生物学信息流（如中心法则）设计的AI架构，不仅能提升预测性能，还能增强机制层面的可解释性，为多组学整合建模提供了新范式。

Abstract: Understanding cellular mechanisms requires integrating information across DNA, RNA, and protein - the three molecular systems linked by the Central Dogma of molecular biology. While domain-specific foundation models have achieved success for each modality individually, they remain isolated, limiting our ability to model integrated cellular processes. Here we present the Central Dogma Transformer (CDT), an architecture that integrates pre-trained language models for DNA, RNA, and protein following the directional logic of the Central Dogma. CDT employs directional cross-attention mechanisms - DNA-to-RNA attention models transcriptional regulation, while RNA-to-Protein attention models translational relationships - producing a unified Virtual Cell Embedding that integrates all three modalities. We validate CDT v1 - a proof-of-concept implementation using fixed (non-cell-specific) RNA and protein embeddings - on CRISPRi enhancer perturbation data from K562 cells, achieving a Pearson correlation of 0.503, representing 63% of the theoretical ceiling set by cross-experiment variability (r = 0.797). Attention and gradient analyses provide complementary interpretive windows: in detailed case studies, these approaches highlight largely distinct genomic regions, with gradient analysis identifying a CTCF binding site that Hi-C data showed as physically contacting both enhancer and target gene. These results suggest that AI architectures aligned with biological information flow can achieve both predictive accuracy and mechanistic interpretability.

</details>


### [375] [Community-Based Early-Stage Chronic Kidney Disease Screening using Explainable Machine Learning for Low-Resource Settings](https://arxiv.org/abs/2601.01119)
*Muhammad Ashad Kabir,Sirajam Munira,Dewan Tasnia Azad,Saleh Mohammed Ikram,Mohammad Habibur Rahman Sarker,Syed Manzoor Ahmed Hanifi*

Main category: cs.LG

TL;DR: 本文提出了一种面向孟加拉国及南亚低资源环境的可解释机器学习框架，用于社区层面早期慢性肾病（CKD）筛查；基于首个南亚社区CKD数据集，结合多种特征选择与12种分类器评估，最优模型达90.4%平衡准确率，仅用少量非病理检验特征即达89.23%，且外部验证显示高泛化性（78%-98%敏感性）与临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有CKD筛查工具多基于高收入国家人群开发，在孟加拉国及南亚表现不佳；其多为简单加性评分、依赖晚期患者数据，难以捕捉风险因素复杂交互，且不适用于早期CKD预测。

Method: 基于孟加拉国首个南亚社区CKD数据集，评估12种机器学习分类器；采用10种互补特征选择方法（含RFECV）筛选稳健预测因子；使用10折交叉验证和三个独立外部数据集（印度、阿联酋、孟加拉国）验证；引入SHAP实现模型可解释性。

Result: RFECV筛选特征子集的模型达90.40%平衡准确率；仅用最少非病理检验特征时达89.23%平衡准确率，优于更大或全特征集；外部验证敏感性达78%–98%；SHAP识别出符合已知CKD风险因素的临床可解释特征。

Conclusion: 所提可解释ML框架显著优于现有筛查工具，在准确性、敏感性和输入简易性方面更适配低资源地区早期CKD社区筛查，具备良好泛化性与临床实用性。

Abstract: Early detection of chronic kidney disease (CKD) is essential for preventing progression to end-stage renal disease. However, existing screening tools - primarily developed using populations from high-income countries - often underperform in Bangladesh and South Asia, where risk profiles differ. Most of these tools rely on simple additive scoring functions and are based on data from patients with advanced-stage CKD. Consequently, they fail to capture complex interactions among risk factors and are limited in predicting early-stage CKD. Our objective was to develop and evaluate an explainable machine learning (ML) framework for community-based early-stage CKD screening for low-resource settings, tailored to the Bangladeshi and South Asian population context. We used a community-based dataset from Bangladesh, the first such CKD dataset in South and South Asia, and evaluated twelve ML classifiers across multiple feature domains. Ten complementary feature selection techniques were applied to identify robust, generalizable predictors. The final models were assessed using 10-fold cross-validation. External validation was conducted on three independent datasets from India, the UAE, and Bangladesh. SHAP (SHapley Additive exPlanations) was used to provide model explainability. An ML model trained on an RFECV-selected feature subset achieved a balanced accuracy of 90.40%, whereas minimal non-pathology-test features demonstrated excellent predictive capability with a balanced accuracy of 89.23%, often outperforming larger or full feature sets. Compared with existing screening tools, the proposed models achieved substantially higher accuracy and sensitivity while requiring fewer and more accessible inputs. External validation confirmed strong generalizability with 78% to 98% sensitivity. SHAP interpretation identified clinically meaningful predictors consistent with established CKD risk factors.

</details>


### [376] [Learning from Historical Activations in Graph Neural Networks](https://arxiv.org/abs/2601.01123)
*Yaniv Galron,Hadar Sinai,Haggai Maron,Moshe Eliasof*

Main category: cs.LG

TL;DR: 本文提出HISTOGRAPH，一种新颖的两阶段注意力机制聚合层，用于图神经网络（GNN）中整合各层中间激活（即历史图激活），以缓解因仅依赖最后一层特征而导致的信息损失及过平滑问题，显著提升图分类性能，尤其在深层GNN中鲁棒性强。


<details>
  <summary>Details</summary>
Motivation: 现有图池化方法仅利用GNN最后一层的节点特征，忽视了前序层产生的历史图激活，导致信息利用不足；该问题在节点表征随层数变化剧烈或深层GNN出现过平滑时尤为突出。

Method: 提出HISTOGRAPH：第一阶段对各GNN层的中间激活施加统一的层级注意力，第二阶段进行节点级注意力；联合建模节点表征的跨层演化与图结构，实现更优的最终特征聚合。

Result: 在多个图分类基准数据集上，HISTOGRAPH持续优于传统池化方法，尤其在深层GNN中展现出更强的鲁棒性和性能提升。

Conclusion: 整合历史图激活是提升GNN表达能力与鲁棒性的有效途径；HISTOGRAPH为图池化提供了新范式，可广泛适用于各类图学习任务。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable success in various domains such as social networks, molecular chemistry, and more. A crucial component of GNNs is the pooling procedure, in which the node features calculated by the model are combined to form an informative final descriptor to be used for the downstream task. However, previous graph pooling schemes rely on the last GNN layer features as an input to the pooling or classifier layers, potentially under-utilizing important activations of previous layers produced during the forward pass of the model, which we regard as historical graph activations. This gap is particularly pronounced in cases where a node's representation can shift significantly over the course of many graph neural layers, and worsened by graph-specific challenges such as over-smoothing in deep architectures. To bridge this gap, we introduce HISTOGRAPH, a novel two-stage attention-based final aggregation layer that first applies a unified layer-wise attention over intermediate activations, followed by node-wise attention. By modeling the evolution of node representations across layers, our HISTOGRAPH leverages both the activation history of nodes and the graph structure to refine features used for final prediction. Empirical results on multiple graph classification benchmarks demonstrate that HISTOGRAPH offers strong performance that consistently improves traditional techniques, with particularly strong robustness in deep GNNs.

</details>


### [377] [Wittgenstein's Family Resemblance Clustering Algorithm](https://arxiv.org/abs/2601.01127)
*Golbahar Amanpour,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 本文提出了一种基于维特根斯坦‘家族相似性’哲学概念的新型无监督聚类算法WFR及其核变体，通过构建相似性图并提取连通分量实现无需预设簇数或形状假设的非线性聚类。


<details>
  <summary>Details</summary>
Motivation: 将分析哲学中维特根斯坦的‘家族相似性’思想（即概念成员间通过重叠相似性而非单一本质属性关联）引入机器学习，以解决传统聚类算法对簇数量和形状先验假设的局限性。

Method: 提出WFR聚类算法及核WFR变体：首先计算邻近样本间的相似性得分，经阈值化后构建相似性图，再通过识别图中连通分量来确定聚类结果；整个过程为图结构驱动、无需参数化簇形假设。

Result: 在标准基准数据集上的仿真实验表明，WFR是一种有效的非线性聚类算法，不依赖于簇数量的先验知识，也不假设簇具有特定几何形状（如球形），展现出良好的鲁棒性和适用性。

Conclusion: 维特根斯坦的家族相似性不仅具有哲学解释力，还可形式化为一种实用、可扩展的机器学习聚类范式，为哲学与人工智能的交叉提供了新路径。

Abstract: This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.

</details>


### [378] [Self-Training the Neurochaos Learning Algorithm](https://arxiv.org/abs/2601.01146)
*Anusree M,Akhila Henry,Pramod P Nair*

Main category: cs.LG

TL;DR: 本文提出了一种结合神经混沌学习（NL）与基于阈值的自训练（ST）的半监督学习架构（NL+ST），用于解决小样本、非线性及类别不平衡场景下的分类问题。NL将输入特征映射为混沌环率表征以捕获非线性关系，ST则利用高置信度伪标签扩充标注集。在10个基准数据集上验证表明，该方法在仅15%标注数据下显著优于单独ST方法，尤其在Iris、Wine和Glass等数据集上提升超110%。


<details>
  <summary>Details</summary>
Motivation: 实际中获取大量标注数据困难且昂贵，而无标注数据丰富；传统监督学习在小样本或不平衡数据下性能不佳，亟需更鲁棒的半监督方案。

Method: 提出NL+ST混合半监督架构：NL模块将输入特征转换为混沌环率表示以建模非线性结构；ST模块采用阈值策略选择高置信度伪标签迭代扩充训练集。在10个基准数据集上，仅用15%标注数据、85%无标注数据进行训练，并结合5种分类器评估。

Result: NL+ST在Iris、Wine、Glass等小样本/不平衡数据集上相较单独ST分别提升188.66%、158.58%、110.48%；整体显著提升分类准确率、泛化能力与鲁棒性。

Conclusion: 混沌驱动的特征提取与半监督学习协同可有效缓解标注数据稀缺问题，尤其适用于非线性、低资源、不平衡场景，为小样本学习提供了新思路。

Abstract: In numerous practical applications, acquiring substantial quantities of labelled data is challenging and expensive, but unlabelled data is readily accessible. Conventional supervised learning methods frequently underperform in scenarios characterised by little labelled data or imbalanced datasets. This study introduces a hybrid semi-supervised learning (SSL) architecture that integrates Neurochaos Learning (NL) with a threshold-based Self-Training (ST) method to overcome this constraint. The NL architecture converts input characteristics into chaos-based ring-rate representations that encapsulate nonlinear relationships within the data, whereas ST progressively enlarges the labelled set utilising high-confidence pseudo-labelled samples. The model's performance is assessed using ten benchmark datasets and five machine learning classifiers, with 85% of the training data considered unlabelled and just 15% utilised as labelled data. The proposed Self-Training Neurochaos Learning (NL+ST) architecture consistently attains superior performance gain relative to standalone ST models, especially on limited, nonlinear and imbalanced datasets like Iris (188.66%), Wine (158.58%) and Glass Identification (110.48%). The results indicate that using chaos-based feature extraction with SSL improves generalisation, resilience, and classification accuracy in low-data contexts.

</details>


### [379] [Evo-TFS: Evolutionary Time-Frequency Domain-Based Synthetic Minority Oversampling Approach to Imbalanced Time Series Classification](https://arxiv.org/abs/2601.01150)
*Wenbin Pei,Ruohao Dai,Bing Xue,Mengjie Zhang,Qiang Zhang,Yiu-Ming Cheung*

Main category: cs.LG

TL;DR: 本文提出了一种名为Evo-TFS的新型进化过采样方法，用于解决时间序列分类中类别不平衡问题，通过结合时域和频域特征，利用强类型遗传编程生成高质量、多样化的时间序列样本，显著提升分类器性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在处理不平衡时间序列数据时易忽略具有更高实际意义的少数类；传统过采样方法依赖线性插值，难以保持时间动态特性并生成多样本。

Method: 提出Evo-TFS方法，采用强类型遗传编程（STGP）演化时间序列，设计融合时域与频域特征的适应度函数以引导生成高质量、多样化样本。

Result: 在多个不平衡时间序列数据集上的实验表明，Evo-TFS优于现有过采样方法，显著提升了时域和频域分类器的性能。

Conclusion: Evo-TFS通过联合建模时频域特征，有效缓解了时间序列分类中的类别不平衡问题，为不平衡时间序列学习提供了新思路。

Abstract: Time series classification is a fundamental machine learning task with broad real-world applications. Although many deep learning methods have proven effective in learning time-series data for classification, they were originally developed under the assumption of balanced data distributions. Once data distribution is uneven, these methods tend to ignore the minority class that is typically of higher practical significance. Oversampling methods have been designed to address this by generating minority-class samples, but their reliance on linear interpolation often hampers the preservation of temporal dynamics and the generation of diverse samples. Therefore, in this paper, we propose Evo-TFS, a novel evolutionary oversampling method that integrates both time- and frequency-domain characteristics. In Evo-TFS, strongly typed genetic programming is employed to evolve diverse, high-quality time series, guided by a fitness function that incorporates both time-domain and frequency-domain characteristics. Experiments conducted on imbalanced time series datasets demonstrate that Evo-TFS outperforms existing oversampling methods, significantly enhancing the performance of time-domain and frequency-domain classifiers.

</details>


### [380] [Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models](https://arxiv.org/abs/2601.01162)
*Zihua Yang,Xin Liao,Yiqun Zhang,Yiu-ming Cheung*

Main category: cs.LG

TL;DR: 本文提出ARISE方法，利用大语言模型（LLM）的外部语义知识增强分类数据的表示，以提升聚类性能。


<details>
  <summary>Details</summary>
Motivation: 分类数据缺乏固有顺序和距离度量，导致传统聚类方法难以准确捕捉语义关系；现有基于共现的方法在样本有限时不可靠，语义信息未被充分挖掘。

Method: 提出ARISE框架：利用LLM对属性值生成语义描述，并将其嵌入与原始数据融合，通过注意力机制加权融合，构建语义感知表示用于聚类。

Result: 在8个基准数据集上显著优于7种代表性方法，性能提升19%-27%。

Conclusion: 引入外部语义知识（尤其是LLM）可有效弥补分类数据聚类中的语义鸿沟，提升聚类质量。

Abstract: Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE

</details>


### [381] [MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches](https://arxiv.org/abs/2601.01206)
*Soroush Elyasi,Arya VarastehNezhad,Fattaneh Taghiyareh*

Main category: cs.LG

TL;DR: 本研究提出一种基于多类型严肃游戏与机器学习的软件开发人员适配性评估框架，通过隐式游戏行为数据（如解谜胜率、菜单操作频率、暂停/重试次数等）预测候选人 suitability，准确率达94%，精度达97%，避免了传统自评问卷的偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统职业评估依赖易受反应偏差、疲劳和故意扭曲影响的自报告问卷；需探索更客观、隐式、抗偏倚的评估方式。

Method: 构建多类型严肃游戏框架，设计定制化手机游戏以诱发问题解决、计划性、适应性等开发相关行为；采集细粒度游戏事件数据，采用两阶段机器学习建模，仅基于游戏行为特征预测适配性。

Result: 模型达到97%精度和94%准确率；行为分析发现合格候选人在解谜胜率、侧边挑战参与度、菜单导航频次等方面显著更高，而暂停、重试和放弃行为更少。

Conclusion: 游戏过程中捕获的隐式行为痕迹可有效预测软件开发适配性，无需显式人格测评，严肃游戏是一种可扩展、高参与度且低偏差的职业评估新范式。

Abstract: Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.

</details>


### [382] [Sparse Bayesian Message Passing under Structural Uncertainty](https://arxiv.org/abs/2601.01207)
*Yoonhyuk Choi,Jiho Choi,Chanran Kim,Yumin Lee,Hawon Shin,Yeowon Jeon,Minjeong Kim,Jiwoo Kang*

Main category: cs.LG

TL;DR: 本文提出了一种基于贝叶斯视角的稀疏符号消息传递网络，通过建模带符号邻接矩阵的后验分布来显式刻画图结构不确定性，从而有效应对异配性和边噪声。


<details>
  <summary>Details</summary>
Motivation: 现实世界图上的半监督学习常受异配性（节点标签不相似）和不可靠图结构（边噪声）挑战，而现有GNN方法多依赖固定邻接结构或简单正则化，缺乏对结构不确定性的显式建模。

Method: 建模带符号邻接矩阵（正边、负边、无边）的后验分布；设计稀疏符号消息传递网络，结合后验边缘化与稀疏符号消息聚合，实现贝叶斯鲁棒推理。

Result: 在多种异配性基准数据集上，该方法在合成与真实结构噪声下均显著优于强基线模型。

Conclusion: 显式建模图结构不确定性（尤其是符号化边）是提升GNN在异配与噪声场景下鲁棒性的有效途径，所提方法提供了处理边噪声与异配性的统一贝叶斯框架。

Abstract: Semi-supervised learning on real-world graphs is frequently challenged by heterophily, where the observed graph is unreliable or label-disassortative. Many existing graph neural networks either rely on a fixed adjacency structure or attempt to handle structural noise through regularization. In this work, we explicitly capture structural uncertainty by modeling a posterior distribution over signed adjacency matrices, allowing each edge to be positive, negative, or absent. We propose a sparse signed message passing network that is naturally robust to edge noise and heterophily, which can be interpreted from a Bayesian perspective. By combining (i) posterior marginalization over signed graph structures with (ii) sparse signed message aggregation, our approach offers a principled way to handle both edge noise and heterophily. Experimental results demonstrate that our method outperforms strong baseline models on heterophilic benchmarks under both synthetic and real-world structural noise.

</details>


### [383] [Adaptive Conformal Prediction via Bayesian Uncertainty Weighting for Hierarchical Healthcare Data](https://arxiv.org/abs/2601.01223)
*Marzieh Amiri Shahbazi,Ali Baheri,Nasibeh Azadeh-Fard*

Main category: cs.LG

TL;DR: 本文提出了一种结合贝叶斯与共形预测的混合框架，用于临床决策中的不确定性量化，在保证分布无关覆盖率的同时实现风险自适应精度。


<details>
  <summary>Details</summary>
Motivation: 临床决策需要兼具无分布覆盖保证和风险自适应精度的不确定性量化，而现有方法无法同时满足这两点。

Method: 将贝叶斯分层随机森林与组感知共形校准相结合，利用后验不确定性加权一致性得分，同时保持严格的覆盖有效性。

Result: 在涵盖61,538次入院、3,793家美国医院的数据上，实现94.3%的实际覆盖率（目标95%），低不确定性预测区间窄21%，高风险预测则适当加宽；单独使用贝叶斯不确定性仅达14.1%覆盖率，凸显混合方法必要性。

Conclusion: 该混合框架支持风险分层临床协议、高置信度预测下的资源高效规划，以及对不确定性案例的审慎分配与强化监管，为多样化医疗场景提供不确定性感知决策支持。

Abstract: Clinical decision-making demands uncertainty quantification that provides both distribution-free coverage guarantees and risk-adaptive precision, requirements that existing methods fail to jointly satisfy. We present a hybrid Bayesian-conformal framework that addresses this fundamental limitation in healthcare predictions. Our approach integrates Bayesian hierarchical random forests with group-aware conformal calibration, using posterior uncertainties to weight conformity scores while maintaining rigorous coverage validity. Evaluated on 61,538 admissions across 3,793 U.S. hospitals and 4 regions, our method achieves target coverage (94.3% vs 95% target) with adaptive precision: 21% narrower intervals for low-uncertainty cases while appropriately widening for high-risk predictions. Critically, we demonstrate that well-calibrated Bayesian uncertainties alone severely under-cover (14.1%), highlighting the necessity of our hybrid approach. This framework enables risk-stratified clinical protocols, efficient resource planning for high-confidence predictions, and conservative allocation with enhanced oversight for uncertain cases, providing uncertainty-aware decision support across diverse healthcare settings.

</details>


### [384] [The Dependency Divide: An Interpretable Machine Learning Framework for Profiling Student Digital Satisfaction in the Bangladesh Context](https://arxiv.org/abs/2601.01231)
*Md Muhtasim Munif Fahim,Humyra Ankona,Md Monimul Huq,Md Rezaul Karim*

Main category: cs.LG

TL;DR: 本文提出“依赖性数字鸿沟”新框架，指出在基础设施不稳定的环境下，高参与度学生反而因对数字平台高度依赖而更易受服务中断影响；通过针对孟加拉国大学生的实证研究发现，超参与型学生（7%）满意度最易受网络可靠性波动影响，政策模拟显示针对高依赖用户提升可靠性比普惠式干预效益高出2.06倍。


<details>
  <summary>Details</summary>
Motivation: 传统数字鸿沟理论无法解释在同等网络接入条件下学生对数字学习平台满意度的显著差异，亟需新框架揭示后接入阶段中参与度与基础设施稳定性之间的复杂关系。

Method: 采用三阶段分析法：（1）基于稳定性验证的K-原型聚类识别学生行为画像；（2）按画像构建随机森林模型，并结合SHAP与ALE分析满意度驱动因素；（3）使用倾向得分匹配进行正式交互效应检验。

Result: 识别出三类学生画像：偶然参与型（58%）、高效学习型（35%）、超参与型（7%）；证实教育设备使用时长与网络可靠性存在显著交互效应（η=0.033, p=0.028），即高参与仅在基础设施可靠时提升满意度；超参与者最脆弱；政策模拟显示定向提升高依赖用户可靠性收益是均质干预的2.06倍。

Conclusion: 在基础设施脆弱环境中，数字能力可能转化为风险；数字转型政策应优先保障高依赖用户的系统可靠性、建立应急机制，并开展关于依赖风险的数字素养教育，而非一味鼓励参与。

Abstract: Background: While digital access has expanded rapidly in resource-constrained contexts, satisfaction with digital learning platforms varies significantly among students with seemingly equal connectivity. Traditional digital divide frameworks fail to explain these variations.
  Purpose: This study introduces the "Dependency Divide", a novel framework proposing that highly engaged students become conditionally vulnerable to infrastructure failures, challenging assumptions that engagement uniformly benefits learners in post-access environments.
  Methods: We conducted a cross-sectional study of 396 university students in Bangladesh using a three-stage analytical approach: (1) stability-validated K-prototypes clustering to identify student profiles, (2) profile-specific Random Forest models with SHAP and ALE analysis to determine satisfaction drivers, and (3) formal interaction analysis with propensity score matching to test the Dependency Divide hypothesis.
  Results: Three distinct profiles emerged: Casually Engaged (58%), Efficient Learners (35%), and Hyper-Engaged (7%). A significant interaction between educational device time and internet reliability (\b{eta} = 0.033, p = 0.028) confirmed the Dependency Divide: engagement increased satisfaction only when infrastructure remained reliable. Hyper-Engaged students showed greatest vulnerability despite or because of their sophisticated digital workflows. Policy simulations demonstrated that targeted reliability improvements for high-dependency users yielded 2.06 times greater returns than uniform interventions.
  Conclusions: In fragile infrastructure contexts, capability can become liability. Digital transformation policies must prioritize reliability for dependency-prone users, establish contingency systems, and educate students about dependency risks rather than uniformly promoting engagement.

</details>


### [385] [Benchmarking the Computational and Representational Efficiency of State Space Models against Transformers on Long-Context Dyadic Sessions](https://arxiv.org/abs/2601.01237)
*Abidemi Koledoye,Chinemerem Unachukwu,Gold Nwobu,Hasin Rana*

Main category: cs.LG

TL;DR: 本文对Mamba状态空间模型（SSM）与LLaMA Transformer在长上下文序列建模中的性能进行了全面基准测试，以双人治疗会话为案例，在计算效率和表征效率两方面进行对比分析，明确了SSM优于Transformer的具体条件。


<details>
  <summary>Details</summary>
Motivation: State Space Models (SSMs) 因其线性计算复杂度 O(N) 相比 Transformer 的 O(N²) 而成为长上下文建模的有希望替代方案，但缺乏系统性实证比较。

Method: 在双人治疗会话数据上，对 Mamba SSM 和 LLaMA Transformer 进行基准测试：(1) 计算效率——测量 512 到 8192 tokens 下的内存占用与推理速度；(2) 表征效率——分析隐藏状态动态与注意力模式。

Result: 明确了 Mamba SSM 在特定长上下文场景下相较 LLaMA Transformer 的优势边界，提供了关于内存、速度及表征能力的量化对比结果。

Conclusion: SSMs 并非在所有长上下文任务中均优于 Transformers；本研究建立了二者性能优劣的精确适用条件，为实际应用提供指导。

Abstract: State Space Models (SSMs) have emerged as a promising alternative to Transformers for long-context sequence modeling, offering linear $O(N)$ computational complexity compared to the Transformer's quadratic $O(N^2)$ scaling. This paper presents a comprehensive benchmarking study comparing the Mamba SSM against the LLaMA Transformer on long-context sequences, using dyadic therapy sessions as a representative test case. We evaluate both architectures across two dimensions: (1) computational efficiency, where we measure memory usage and inference speed from 512 to 8,192 tokens, and (2) representational efficiency, where we analyze hidden state dynamics and attention patterns. Our findings provide actionable insights for practitioners working with long-context applications, establishing precise conditions under which SSMs offer advantages over Transformers.

</details>


### [386] [Accelerated Full Waveform Inversion by Deep Compressed Learning](https://arxiv.org/abs/2601.01268)
*Maayan Gelboim,Amir Adler,Mauricio Araya-Polo*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度神经网络的分层数据选择方法，用于降低全波形反演（FWI）的输入维度和计算成本，显著提升大规模3D FWI的可行性。


<details>
  <summary>Details</summary>
Motivation: 现代地震采集系统产生的FWI输入数据量达TB级，导致工业级复杂地下反演或多种场景探索计算成本过高、难以实现。

Method: 提出一种含二值化感知层的深度神经网络：首先通过压缩学习从大量地下模型中学习最优地震采集布局；再用自编码器提取数据潜在表示；最后通过K-means聚类在潜在空间中进一步筛选最相关数据，形成分层数据选择机制。

Result: 该方法在仅使用10%数据的情况下，在2D FWI中持续优于随机采样，验证了其有效性，并为加速大规模3D FWI奠定基础。

Conclusion: 所提分层数据选择方法可显著降低FWI计算负担，在保证反演质量前提下大幅提升效率，具有实际工业应用潜力。

Abstract: We propose and test a method to reduce the dimensionality of Full Waveform Inversion (FWI) inputs as computational cost mitigation approach. Given modern seismic acquisition systems, the data (as input for FWI) required for an industrial-strength case is in the teraflop level of storage, therefore solving complex subsurface cases or exploring multiple scenarios with FWI become prohibitive. The proposed method utilizes a deep neural network with a binarized sensing layer that learns by compressed learning a succinct but consequential seismic acquisition layout from a large corpus of subsurface models. Thus, given a large seismic data set to invert, the trained network selects a smaller subset of the data, then by using representation learning, an autoencoder computes latent representations of the data, followed by K-means clustering of the latent representations to further select the most relevant data for FWI. Effectively, this approach can be seen as a hierarchical selection. The proposed approach consistently outperforms random data sampling, even when utilizing only 10% of the data for 2D FWI, these results pave the way to accelerating FWI in large scale 3D inversion.

</details>


### [387] [The Alchemy of Thought: Understanding In-Context Learning Through Supervised Classification](https://arxiv.org/abs/2601.01290)
*Harshita Narnoli,Mihai Surdeanu*

Main category: cs.LG

TL;DR: 本文通过将上下文学习（ICL）与基于相同示例训练的监督分类器（如kNN和逻辑回归）进行对比，探究ICL的工作机制；实验发现：当示例相关性高时，ICL行为更接近kNN而非梯度下降类模型；当相关性低时，LLM因可回退至参数化记忆而表现优于这些分类器。


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习（ICL）在实践中被广泛应用，但其内在工作机制仍不清楚，本文旨在从分类器行为角度理解ICL如何工作。

Method: 将ICL与基于相同演示样本训练的监督分类器（kNN和逻辑回归）在文本分类任务上进行行为对比分析，涵盖6个数据集和3个大语言模型，并系统考察演示相关性对行为一致性的影响。

Result: ICL在高相关性演示下行为更接近kNN而非逻辑回归；在低相关性下，LLM性能优于这些分类器，因其可利用预训练参数化知识（即‘参数化记忆’）进行回退。

Conclusion: ICL的行为兼具非参数（类似kNN）和参数（依赖模型内部知识）特性，其有效性取决于演示相关性——高相关性时依赖注意力机制的近邻匹配，低相关性时则调用模型固有知识。

Abstract: In-context learning (ICL) has become a prominent paradigm to rapidly customize LLMs to new tasks without fine-tuning. However, despite the empirical evidence of its usefulness, we still do not truly understand how ICL works. In this paper, we compare the behavior of in-context learning with supervised classifiers trained on ICL demonstrations to investigate three research questions: (1) Do LLMs with ICL behave similarly to classifiers trained on the same examples? (2) If so, which classifiers are closer, those based on gradient descent (GD) or those based on k-nearest neighbors (kNN)? (3) When they do not behave similarly, what conditions are associated with differences in behavior? Using text classification as a use case, with six datasets and three LLMs, we observe that LLMs behave similarly to these classifiers when the relevance of demonstrations is high. On average, ICL is closer to kNN than logistic regression, giving empirical evidence that the attention mechanism behaves more similarly to kNN than GD. However, when demonstration relevance is low, LLMs perform better than these classifiers, likely because LLMs can back off to their parametric memory, a luxury these classifiers do not have.

</details>


### [388] [Sobolev Approximation of Deep ReLU Network in Log-weighted Barron Space](https://arxiv.org/abs/2601.01295)
*Changhoon Song,Seungchan Ko,Youngjoon Hong*

Main category: cs.LG

TL;DR: 本文提出了一种新的对数加权Barron空间 ℬ^log，其正则性要求弱于经典Barron空间；证明了该空间中函数可由深度ReLU网络以显式依赖深度的方式逼近，并建立了H¹范数下的逼近率及最大有效深度尺度，从而更精确地解释深度网络在高维问题中的高效性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 经典Barron空间对目标函数的正则性要求仍强于Sobolev空间，且现有深度敏感结果常受限于如sL ≤ 1/2等苛刻假设，难以解释深度网络在高维实际问题中的成功。

Method: 引入对数加权Barron空间ℬ^log及其推广族ℬ^{s,log}，研究其嵌入性质与Rademacher复杂度，并基于深度ReLU网络建立显式依赖深度的H¹范数逼近误差界与最优深度尺度分析。

Result: 证明ℬ^log严格弱于任意ℬ^s（s>0）；给出深度ReLU网络对ℬ^log函数的O(n^{-1/2})逼近误差及深度依赖关系；建立ℬ^{s,log}在H¹范数下的逼近率，并确定保持该速率的最大深度尺度。

Conclusion: 对数加权Barron空间为深度网络提供了更宽松、更具现实意义的函数类刻画，揭示了深度如何缓解正则性需求，从而为深度模型在高维场景中的有效性与稳定性提供了更精细的理论支撑。

Abstract: Universal approximation theorems show that neural networks can approximate any continuous function; however, the number of parameters may grow exponentially with the ambient dimension, so these results do not fully explain the practical success of deep models on high-dimensional data. Barron space theory addresses this: if a target function belongs to a Barron space, a two-layer network with $n$ parameters achieves an $O(n^{-1/2})$ approximation error in $L^2$. Yet classical Barron spaces $\mathscr{B}^{s+1}$ still require stronger regularity than Sobolev spaces $H^s$, and existing depth-sensitive results often assume constraints such as $sL \le 1/2$. In this paper, we introduce a log-weighted Barron space $\mathscr{B}^{\log}$, which requires a strictly weaker assumption than $\mathscr{B}^s$ for any $s>0$. For this new function space, we first study embedding properties and carry out a statistical analysis via the Rademacher complexity. Then we prove that functions in $\mathscr{B}^{\log}$ can be approximated by deep ReLU networks with explicit depth dependence. We then define a family $\mathscr{B}^{s,\log}$, establish approximation bounds in the $H^1$ norm, and identify maximal depth scales under which these rates are preserved. Our results clarify how depth reduces regularity requirements for efficient representation, offering a more precise explanation for the performance of deep architectures beyond the classical Barron setting, and for their stable use in high-dimensional problems used today.

</details>


### [389] [ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System](https://arxiv.org/abs/2601.01297)
*Anantha Sharma*

Main category: cs.LG

TL;DR: 本文提出Argus框架，将分布漂移检测重构为在固定空间划分（Voronoi镶嵌）上跟踪局部统计量，具有正交不变性、线性复杂度、图论驱动的漂移传播分析能力，并通过乘积量化扩展至超高维（d>500）场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三大缺陷：全局比较法计算开销大、投影法丢失几何结构、重聚类法身份不稳定；亟需一种兼顾几何保真性、计算效率与可解释性的新范式。

Method: 基于标准正交基构建Voronoi镶嵌，定义正交不变的漂移度量；采用图模型刻画漂移在单元间的传播模式；引入乘积量化 tessellation 实现高维可扩展性；理论证明其不变性与O(N)时间复杂度。

Result: 实验表明Argus在坐标旋转下准确识别真实漂移，而对比方法产生大量假阳性；在d>500维数据上仍保持高效稳定；提供单元级空间定位能力与漂移传播机制解析。

Conclusion: Argus为高维流数据分布监控提供了兼具几何严谨性、计算可行性与可解释性的新基础框架，克服了传统方法的根本局限。

Abstract: Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold.
  The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces.
  This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.

</details>


### [390] [Towards a Principled Muon under $μ\mathsf{P}$: Ensuring Spectral Conditions throughout Training](https://arxiv.org/abs/2601.01306)
*John Zhao*

Main category: cs.LG

TL;DR: 本文提出Muon++，一种改进的矩阵优化器，通过仅在优化器更新层面维持谱控制来满足μ-参数化（μP）所需的谱条件，从而在LLM训练全程保证宽度无关的学习动力学，无需对权重进行显式谱归一化，兼顾理论严谨性与实际效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于μP的矩阵优化器（如Muon）难以在实际长周期训练中全程满足μP所需的谱条件，或需频繁谱归一化导致计算开销大、实用性低。

Method: 提出关键洞见：对中等规模模型，仅控制优化器更新的谱性质即可保障μP兼容缩放；据此设计Muon++，并在其中引入数据依赖的自适应谱条件。

Result: Muon++可在整个训练过程中可靠满足μP谱条件，显著降低计算开销，并首次实现面向长周期LLM训练的自适应谱控制。

Conclusion: 本工作弥合了μP理论优势与矩阵优化器实际部署之间的鸿沟，为高效、可扩展的大模型训练提供了新范式。

Abstract: The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.

</details>


### [391] [Spectral-Window Hybrid (SWH)](https://arxiv.org/abs/2601.01313)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: 本文提出Spectral-Window Hybrid (SWH)架构，结合频域全局建模（O(T log T)）与局部滑动窗口注意力，兼顾长序列效率与局部精度，在保持短上下文性能的同时实现线性扩展。


<details>
  <summary>Details</summary>
Motivation: Transformer的二次计算复杂度限制其在长序列任务中的应用，需在计算效率与建模能力间取得平衡。

Method: SWH采用双分支并行结构：全局分支基于卷积定理在频域建模长程衰减动态；局部分支使用滑动窗口注意力捕获局部token交互；二者表示融合输出。

Result: SWH在短上下文上达到与标准Transformer相当的困惑度，并支持对超长序列的高效线性扩展。

Conclusion: SWH通过解耦全局与局部建模，有效缓解了Transformer的计算瓶颈，为极端长度序列建模提供了高效且表达力强的新范式。

Abstract: Scaling sequence modeling to extreme contexts requires balancing computational efficiency with representational expressivity. While Transformers provide precise retrieval via the attention mechanism, their quadratic $\mathcal{O}(T^2)$ complexity limits their application to long-horizon tasks. In this work, we propose the \textbf{Spectral-Window Hybrid (SWH)}, an architecture that decouples sequence modeling into two \textit{parallel} streams: a global branch utilizing the Convolution Theorem to model long-range decay dynamics in $\mathcal{O}(T \log T)$ time, and a local branch employing sliding-window attention for token interactions within a bounded context. By aggregating these representations, SWH avoids the computational bottleneck of global attention while retaining local precision. We demonstrate that SWH matches the perplexity of standard Transformers on short contexts while enabling efficient linear scaling to extended sequences. The code is available at https://github.com/VladimerKhasia/SWH

</details>


### [392] [From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion](https://arxiv.org/abs/2601.01347)
*Yuyan Pi,Min Jin,Wentao Xie,Xinhua Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于图-模体特征融合与多标签生成（GM-MLG）的开放型药物不良反应（ADR）预测新范式，通过分子结构双图表示与Transformer解码器自回归生成标签，显著提升预测性能并扩展可预测ADR类型数量，同时提供可解释的构效关系分析。


<details>
  <summary>Details</summary>
Motivation: 现有ADR预测方法受限于药物数据稀缺导致的冷启动问题、封闭标签集以及对标签依赖关系建模不足。

Method: 提出GM-MLG方法：构建原子级、局部分子级（BRICS+碎片规则提取细粒度模体）和全局分子级的双图表示；将ADR预测转化为Transformer Decoder驱动的多标签序列生成任务，利用位置编码建模标签依赖，并通过自回归解码动态扩展预测空间。

Result: 实验显示GM-MLG在性能上最高提升38%，平均提升20%；预测ADR类型从200种扩展至超10,000种；并通过逆合成模体分析揭示ADR与分子模体间的非线性构效关系。

Conclusion: GM-MLG成功突破传统多标签分类范式，实现开放、可扩展、可解释的ADR预测，为药物安全风险系统性评估提供新工具。

Abstract: Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.

</details>


### [393] [Towards LLM-enabled autonomous combustion research: A literature-aware agent for self-corrective modeling workflows](https://arxiv.org/abs/2601.01357)
*Ke Xiao,Haoze Zhang,Runze Mao,Han Li,Zhi X. Chen*

Main category: cs.LG

TL;DR: 本文提出FlamePilot，一种专为燃烧建模设计的LLM智能体，能自动、自纠错地执行CFD仿真（支持OpenFOAM和DeepFlame），并从科学文献中学习以指导仿真全流程；在基准测试中显著超越先前方法，并通过MILD燃烧案例验证其作为科研协作者的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽快速发展，但在燃烧建模等复杂科学领域仍缺乏将领域文献知识与专业工具（如CFD代码）执行能力无缝集成的能力。

Method: 提出FlamePilot架构：基于原子化工具保障CFD仿真的鲁棒配置与执行（支持OpenFOAM与DeepFlame）；具备从科研论文中提取关键信息并用于指导仿真设置与优化的能力；采用透明可解释范式。

Result: 在公开基准上取得1.0可执行分和0.438成功率，优于此前最佳结果（0.625和0.250）；MILD燃烧案例中，自主完成论文理解→仿真配置→运行→后处理→改进建议→多步参数优化收敛。

Conclusion: FlamePilot构建了AI赋能燃烧建模的基础框架，实现人机协作新范式——AI负责工作流编排，研究人员专注高层次分析。

Abstract: The rapid evolution of large language models (LLMs) is transforming artificial intelligence into autonomous research partners, yet a critical gap persists in complex scientific domains such as combustion modeling. Here, practical AI assistance requires the seamless integration of domain literature knowledge with robust execution capabilities for expertise-intensive tools such as computational fluid dynamics (CFD) codes. To bridge this gap, we introduce FlamePilot, an LLM agent designed to empower combustion modeling research through automated and self-corrective CFD workflows. FlamePilot differentiates itself through an architecture that leverages atomic tools to ensure the robust setup and execution of complex simulations in both OpenFOAM and extended frameworks such as DeepFlame. The system is also capable of learning from scientific articles, extracting key information to guide the simulation from initial setup to optimized results. Validation on a public benchmark shows FlamePilot achieved a perfect 1.0 executability score and a 0.438 success rate, surpassing the prior best reported agent scores of 0.625 and 0.250, respectively. Furthermore, a detailed case study on Moderate or Intense Low-oxygen Dilution (MILD) combustion simulation demonstrates its efficacy as a collaborative research copilot, where FlamePilot autonomously translated a research paper into a configured simulation, conducted the simulation, post-processed the results, proposed evidence-based refinements, and managed a multi-step parameter study to convergence under minimal human intervention. By adopting a transparent and interpretable paradigm, FlamePilot establishes a foundational framework for AI-empowered combustion modeling, fostering a collaborative partnership where the agent manages workflow orchestration, freeing the researcher for high-level analysis.

</details>


### [394] [Causal discovery for linear causal model with correlated noise: an Adversarial Learning Approach](https://arxiv.org/abs/2601.01368)
*Mujin Zhou,Junzhe Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于f-GAN框架的因果发现方法，用于处理存在未观测混杂因素的数据，通过最小化贝叶斯自由能（等价于f-散度）并结合Gumbel-Softmax松弛在离散图空间中进行梯度搜索。


<details>
  <summary>Details</summary>
Motivation: 解决存在未观测混杂因素时的因果结构学习难题。

Method: 基于f-GAN框架，将结构学习建模为最小化贝叶斯自由能，并通过Gumbel-Softmax松弛实现离散图空间上的可微优化。

Result: 证明了最小化贝叶斯自由能等价于最小化真实数据分布与模型生成分布之间的f-散度，并将其转化为min-max对抗优化问题。

Conclusion: 该方法能有效学习不依赖具体参数值的二元因果结构，提升了存在未观测混杂下的因果发现鲁棒性。

Abstract: Causal discovery from data with unmeasured confounding factors is a challenging problem. This paper proposes an approach based on the f-GAN framework, learning the binary causal structure independent of specific weight values. We reformulate the structure learning problem as minimizing Bayesian free energy and prove that this problem is equivalent to minimizing the f-divergence between the true data distribution and the model-generated distribution. Using the f-GAN framework, we transform this objective into a min-max adversarial optimization problem. We implement the gradient search in the discrete graph space using Gumbel-Softmax relaxation.

</details>


### [395] [Data Complexity-aware Deep Model Performance Forecasting](https://arxiv.org/abs/2601.01383)
*Yen-Chia Chen,Hsing-Kuo Pao,Hanjuan Huang*

Main category: cs.LG

TL;DR: 本文提出了一种轻量级、两阶段的深度学习模型性能预测框架，可在训练前基于数据集特征和模型结构估计性能，兼具泛化性与实用性，并可辅助模型选择、预处理决策及数据质量诊断。


<details>
  <summary>Details</summary>
Motivation: 现有模型选择依赖耗时耗资源的试错法，而已有性能预测方法计算开销大或泛化性差。

Method: 提出轻量级两阶段框架：第一阶段基于数据集可测属性（如方差）预测基线性能；第二阶段结合模型架构与超参数细节进行校准。

Result: 框架能跨数据集与模型类型泛化；所用特征（如数据集方差）可指导模型选择、预处理及识别问题数据集。

Conclusion: 该框架不仅可预测模型性能，还可作为模型设计与数据质量评估的早期分析工具，提升深度学习开发效率与鲁棒性。

Abstract: Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.

</details>


### [396] [Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning](https://arxiv.org/abs/2601.01387)
*Yongzhe Li,Lin Guan,Zihan Cai,Zuxian Lin,Jiyu Huang,Liukai Chen*

Main category: cs.LG

TL;DR: 本文提出了一种面向电力系统潮流分析的尺度自适应多任务学习框架SaMPFA，通过局部拓扑切片（LTS）采样和无参考多任务图学习（RMGL）模型，提升模型在不同系统规模下的泛化能力和支路功率预测鲁棒性，并在IEEE 39节点系统和中国某省级电网上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 提升深度学习模型在电力系统拓扑变化（如规模变化）下的适应性和支路功率预测的鲁棒性。

Method: 提出SaMPFA框架，包括局部拓扑切片（LTS）采样技术以增强跨尺度学习能力，以及无参考多任务图学习（RMGL）模型，直接预测节点电压和支路功率（而非相角），并设计融合物理规律的损失函数。

Result: 在IEEE 39节点系统和中国某省级真实电网中，模型精度分别提升4.47%和36.82%，展现出更强的尺度适应性和泛化能力。

Conclusion: SaMPFA通过结构创新与物理引导学习，在保持高精度的同时显著提升了模型对拓扑变化的适应性与物理一致性。

Abstract: Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.

</details>


### [397] [A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble](https://arxiv.org/abs/2601.01403)
*Zewei Yu,Jianqiu Xu,Caimin Li*

Main category: cs.LG

TL;DR: 本文提出GDME，一种基于图的无监督在线时间序列异常检测框架，通过动态模型池、图结构建模与社区检测实现自适应集成，并能检测概念漂移。


<details>
  <summary>Details</summary>
Motivation: 工业流数据量激增且模式多样、快速演化，现有方法多面向离线场景或难以有效处理异构流数据。

Method: GDME构建动态模型池，结合动态图结构表征模型间关系，利用社区检测选择集成子集，并通过监控图结构变化检测概念漂移。

Result: 在七个异构时间序列上实验表明，GDME性能优于现有在线方法，最高提升24%；其集成策略优于单个模型和平均集成，且计算效率具有竞争力。

Conclusion: GDME是一种高效、自适应的在线异常检测框架，能有效应对流数据的异构性与概念漂移问题。

Abstract: With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.

</details>


### [398] [A Depth Hierarchy for Computing the Maximum in ReLU Networks via Extremal Graph Theory](https://arxiv.org/abs/2601.01417)
*Itay Safran*

Main category: cs.LG

TL;DR: 本文研究了使用ReLU神经网络精确计算d个实数输入的最大值函数的问题，证明了深度层次结构：对于任意深度3≤k≤log₂(log₂(d))，表示最大值函数所需的宽度至少为Ω(d^(1+1/(2^(k-2)-1)))。这是首个针对该基本操作符在深度k≥3时的无条件超线性下界，即使深度随d增长也成立。


<details>
  <summary>Details</summary>
Motivation: 尽管最大值函数形式简单，但其非可微超平面的几何结构可能蕴含内在复杂性，需要新的方法来证明深度神经网络的下界。

Method: 基于组合论证的方法，将最大值函数的非可微脊与网络第一隐藏层诱导图中的团相关联，并利用极值图论中的Turán定理，证明过窄的网络无法捕捉最大值函数的非线性特性。

Result: 证明了ReLU神经网络计算最大值函数时的深度-宽度权衡关系，给出了首个无条件超线性宽度下界，适用于深度3到log₂(log₂(d))范围。

Conclusion: 最大值函数虽简单，却具有源于其非可微超平面几何结构的内在复杂性；该工作为深度神经网络下界分析提供了新思路。

Abstract: We consider the problem of exact computation of the maximum function over $d$ real inputs using ReLU neural networks. We prove a depth hierarchy, wherein width $Ω\big(d^{1+\frac{1}{2^{k-2}-1}}\big)$ is necessary to represent the maximum for any depth $3\le k\le \log_2(\log_2(d))$. This is the first unconditional super-linear lower bound for this fundamental operator at depths $k\ge3$, and it holds even if the depth scales with $d$. Our proof technique is based on a combinatorial argument and associates the non-differentiable ridges of the maximum with cliques in a graph induced by the first hidden layer of the computing network, utilizing Turán's theorem from extremal graph theory to show that a sufficiently narrow network cannot capture the non-linearities of the maximum. This suggests that despite its simple nature, the maximum function possesses an inherent complexity that stems from the geometric structure of its non-differentiable hyperplanes, and provides a novel approach for proving lower bounds for deep neural networks.

</details>


### [399] [Unveiling the Heart-Brain Connection: An Analysis of ECG in Cognitive Performance](https://arxiv.org/abs/2601.01424)
*Akshay Sasi,Malavika Pradeep,Nusaibah Farrukh,Rahul Venugopal,Elizabeth Sherly*

Main category: cs.LG

TL;DR: 本研究探索了利用可穿戴设备采集的ECG信号替代传统EEG来评估认知负荷的可行性，提出了一种跨模态XGBoost框架，将ECG特征映射到EEG表征的认知空间，实现了仅用ECG即可准确推断认知负荷。


<details>
  <summary>Details</summary>
Motivation: EEG虽为认知负荷评估金标准，但便携性差；而广泛可用的ECG可作为现实场景中更实用的替代方案。

Method: 采集工作记忆与被动听觉任务下的多模态（EEG+ECG）数据；提取ECG时域HRV与Catch22特征、EEG谱特征与Catch22特征；构建跨模态XGBoost模型，将ECG特征投影至EEG表征的认知空间。

Result: ECG衍生的投影能有效捕捉认知状态变化，支持高精度分类；验证了ECG作为实时、可穿戴、可解释的认知监测手段的可行性。

Conclusion: ECG可作为EEG的可靠代理，用于日常环境中的实时认知负荷监测，具备实际应用价值。

Abstract: Understanding the interaction of neural and cardiac systems during cognitive activity is critical to advancing physiological computing. Although EEG has been the gold standard for assessing mental workload, its limited portability restricts its real-world use. Widely available ECG through wearable devices proposes a pragmatic alternative. This research investigates whether ECG signals can reliably reflect cognitive load and serve as proxies for EEG-based indicators. In this work, we present multimodal data acquired from two different paradigms involving working-memory and passive-listening tasks. For each modality, we extracted ECG time-domain HRV metrics and Catch22 descriptors against EEG spectral and Catch22 features, respectively. We propose a cross-modal XGBoost framework to project the ECG features onto EEG-representative cognitive spaces, thereby allowing workload inferences using only ECG. Our results show that ECG-derived projections expressively capture variation in cognitive states and provide good support for accurate classification. Our findings underpin ECG as an interpretable, real-time, wearable solution for everyday cognitive monitoring.

</details>


### [400] [Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models](https://arxiv.org/abs/2601.01452)
*Jian Feng,Zhihong Huang*

Main category: cs.LG

TL;DR: 本文提出了一种名为BSZO的零阶优化方法，通过卡尔曼滤波融合多方向有限差分信息，并利用贝叶斯推理估计投影梯度，显著提升了大语言模型微调的收敛速度与性能，同时保持极低内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法依赖单步随机扰动梯度估计，精度和收敛性受限，且内存节省潜力未被充分挖掘。

Method: 提出BSZO：将每个有限差分测量视为含噪观测，用卡尔曼滤波在低维子空间中进行贝叶斯推断，估计投影梯度；引入基于残差的自适应扰动尺度调整机制。

Result: 理论证明BSZO收敛率提升k/γ倍；实验表明其在RoBERTa、Mistral、OPT上全面优于MeZO、MeZO-Adam和HiZOO，在OPT-13B上平均绝对提升达6.67%，内存开销仅约为MeZO的1.00×–1.08×。

Conclusion: BSZO是一种高效、低内存、高精度的大模型零阶微调新范式，兼具理论保证与强实证性能。

Abstract: Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\times$--1.08$\times$ of MeZO).

</details>


### [401] [Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD](https://arxiv.org/abs/2601.01465)
*Ze Peng,Jian Zhang,Yisen Wang,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.LG

TL;DR: 本文提出了一种更充分利用SGD平坦性偏置的信息论泛化界，通过'全知轨迹'技术，使界能正确反映平坦性提升带来的泛化改善，并显著收紧数值结果，同时暗示可绕过记忆-泛化权衡。


<details>
  <summary>Details</summary>
Motivation: 现有信息论泛化界未能有效利用SGD对平坦解的偏好，导致无法刻画平坦性提升对泛化的正面影响，且数值上过于宽松。

Method: 提出基于'全知轨迹'（omniscient trajectory）的新型信息论分析技术，构建能显式关联权重协方差大变异性方向与局部曲率的泛化界，并将其应用于SGD及梯度下降算法。

Result: 新界能正确反映平坦性增强时泛化性能的提升，数值上显著更紧；在凸-Lipschitz-有界问题中将最小最大超额风险的信息论界从Ω(1)改进为O(1/√n)；暗示可规避记忆-泛化权衡。

Conclusion: 通过更精细地建模SGD的内在几何特性（如平坦性），信息论泛化分析可获得更具解释性和实用性的结果。

Abstract: Information-theoretic (IT) generalization bounds have been used to study the generalization of learning algorithms. These bounds are intrinsically data- and algorithm-dependent so that one can exploit the properties of data and algorithm to derive tighter bounds. However, we observe that although the flatness bias is crucial for SGD's generalization, these bounds fail to capture the improved generalization under better flatness and are also numerically loose. This is caused by the inadequate leverage of SGD's flatness bias in existing IT bounds. This paper derives a more flatness-leveraging IT bound for the flatness-favoring SGD. The bound indicates the learned models generalize better if the large-variance directions of the final weight covariance have small local curvatures in the loss landscape. Experiments on deep neural networks show our bound not only correctly reflects the better generalization when flatness is improved, but is also numerically much tighter. This is achieved by a flexible technique called "omniscient trajectory". When applied to Gradient Descent's minimax excess risk on convex-Lipschitz-Bounded problems, it improves representative IT bounds' $Ω(1)$ rates to $O(1/\sqrt{n})$. It also implies a by-pass of memorization-generalization trade-offs.

</details>


### [402] [Accelerating Storage-Based Training for Graph Neural Networks](https://arxiv.org/abs/2601.01473)
*Myung-Hwan Jang,Jeong-Min Park,Yunyong Ko,Sang-Wook Kim*

Main category: cs.LG

TL;DR: 本文提出了一种名为AGNES的新型基于存储的GNN训练框架，通过分块式存储I/O处理和超批次（hyperbatch）处理策略，显著缓解了大规模图神经网络训练中因大量小I/O操作导致的性能瓶颈，在多个真实图数据集上比现有最优方法快达4.1倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于存储的GNN训练方法虽能处理Web规模图，但忽视了大量小存储I/O操作带来的严重数据准备瓶颈。

Method: 提出AGNES框架，采用分块式存储I/O处理以充分利用高性能存储设备带宽，并引入基于真实图特性的超批次（hyperbatch）处理策略以提升单次I/O效率。

Result: 在五个真实世界图数据集上的实验表明，AGNES始终优于四个SOTA方法，最高提速达4.1倍。

Conclusion: 分块I/O与hyperbatch协同设计可有效突破存储I/O瓶颈，为单机训练超大规模图神经网络提供了高效可行的新范式。

Abstract: Graph neural networks (GNNs) have achieved breakthroughs in various real-world downstream tasks due to their powerful expressiveness. As the scale of real-world graphs has been continuously growing, \textit{a storage-based approach to GNN training} has been studied, which leverages external storage (e.g., NVMe SSDs) to handle such web-scale graphs on a single machine. Although such storage-based GNN training methods have shown promising potential in large-scale GNN training, we observed that they suffer from a severe bottleneck in data preparation since they overlook a critical challenge: \textit{how to handle a large number of small storage I/Os}. To address the challenge, in this paper, we propose a novel storage-based GNN training framework, named \textsf{AGNES}, that employs a method of \textit{block-wise storage I/O processing} to fully utilize the I/O bandwidth of high-performance storage devices. Moreover, to further enhance the efficiency of each storage I/O, \textsf{AGNES} employs a simple yet effective strategy, \textit{hyperbatch-based processing} based on the characteristics of real-world graphs. Comprehensive experiments on five real-world graphs reveal that \textsf{AGNES} consistently outperforms four state-of-the-art methods, by up to 4.1$\times$ faster than the best competitor. Our code is available at https://github.com/Bigdasgit/agnes-kdd26.

</details>


### [403] [Multi-Subspace Multi-Modal Modeling for Diffusion Models: Estimation, Convergence and Mixture of Experts](https://arxiv.org/abs/2601.01475)
*Ruofeng Yang,Yongcan Li,Bo Jiang,Cheng Chen,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的混合低秩-混合高斯（MoLR-MoG）建模方法，用于改进扩散模型在小样本和高维图像数据上的性能，通过引入多模态潜变量结构，缓解维度灾难，并给出理论误差界与优化收敛性保证。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在高维数据下受维度灾难影响（误差为n^{-1/D}）；虽有工作用子空间+高斯潜变量建模缓解，但无法刻画潜流形的多模态特性。

Method: 提出MoLR-MoG建模：将数据视为K个线性子空间的并集，每个子空间对应一个低秩混合高斯（n_k个模态、维度d_k）潜分布；其得分函数自然形成混合专家（MoE）结构；设计MoE-latent MoG神经网络实现该建模。

Result: 实验表明MoE-latent MoG NN生成质量优于MoE-latent Gaussian score，且以1/10参数量达到与MoE-latent Unet相当性能；理论给出O(R^4√(∑n_k)√(∑n_k d_k)/√n)估计误差，摆脱维度灾难；并证明优化过程的收敛性。

Conclusion: MoLR-MoG建模更贴合真实图像的多流形+多模态结构，能解释扩散模型为何仅需小样本、快优化即可取得优异性能。

Abstract: Recently, diffusion models have achieved a great performance with a small dataset of size $n$ and a fast optimization process. However, the estimation error of diffusion models suffers from the curse of dimensionality $n^{-1/D}$ with the data dimension $D$. Since images are usually a union of low-dimensional manifolds, current works model the data as a union of linear subspaces with Gaussian latent and achieve a $1/\sqrt{n}$ bound. Though this modeling reflects the multi-manifold property, the Gaussian latent can not capture the multi-modal property of the latent manifold. To bridge this gap, we propose the mixture subspace of low-rank mixture of Gaussian (MoLR-MoG) modeling, which models the target data as a union of $K$ linear subspaces, and each subspace admits a mixture of Gaussian latent ($n_k$ modals with dimension $d_k$). With this modeling, the corresponding score function naturally has a mixture of expert (MoE) structure, captures the multi-modal information, and contains nonlinear property. We first conduct real-world experiments to show that the generation results of MoE-latent MoG NN are much better than MoE-latent Gaussian score. Furthermore, MoE-latent MoG NN achieves a comparable performance with MoE-latent Unet with $10 \times$ parameters. These results indicate that the MoLR-MoG modeling is reasonable and suitable for real-world data. After that, based on such MoE-latent MoG score, we provide a $R^4\sqrt{Σ_{k=1}^Kn_k}\sqrt{Σ_{k=1}^Kn_kd_k}/\sqrt{n}$ estimation error, which escapes the curse of dimensionality by using data structure. Finally, we study the optimization process and prove the convergence guarantee under the MoLR-MoG modeling. Combined with these results, under a setting close to real-world data, this work explains why diffusion models only require a small training sample and enjoy a fast optimization process to achieve a great performance.

</details>


### [404] [SGD-Based Knowledge Distillation with Bayesian Teachers: Theory and Guidelines](https://arxiv.org/abs/2601.01484)
*Itai Morad,Nir Shlezinger,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 本文从贝叶斯视角分析知识蒸馏（KD），揭示了使用贝叶斯类概率（BCPs）作为教师监督信号可降低方差、提升收敛性与泛化能力；实验表明，以贝叶斯模型为教师的蒸馏显著提升学生准确率（+4.27%）和训练稳定性（噪声降低30%）。


<details>
  <summary>Details</summary>
Motivation: 尽管知识蒸馏（KD）在实践中效果显著，其理论基础仍不完善，尤其缺乏对收敛行为与噪声影响的严格分析。

Method: 采用贝叶斯视角建模KD过程，理论分析SGD下学生模型在两类教师监督下的收敛性：（i）精确贝叶斯类概率（BCPs）；（ii）含噪声的BCP近似；并结合实验验证贝叶斯教师的有效性。

Result: 理论证明BCP监督可减少方差、消除邻域项；噪声水平直接影响泛化与精度；实验显示贝叶斯教师使学生准确率最高提升4.27%，训练噪声降低达30%。

Conclusion: 贝叶斯深度学习模型因其更优的BCP估计能力，是知识蒸馏中更优的教师选择；该结论兼具理论保证与实证支持。

Abstract: Knowledge Distillation (KD) is a central paradigm for transferring knowledge from a large teacher network to a typically smaller student model, often by leveraging soft probabilistic outputs. While KD has shown strong empirical success in numerous applications, its theoretical underpinnings remain only partially understood. In this work, we adopt a Bayesian perspective on KD to rigorously analyze the convergence behavior of students trained with Stochastic Gradient Descent (SGD). We study two regimes: $(i)$ when the teacher provides the exact Bayes Class Probabilities (BCPs); and $(ii)$ supervision with noisy approximations of the BCPs. Our analysis shows that learning from BCPs yields variance reduction and removes neighborhood terms in the convergence bounds compared to one-hot supervision. We further characterize how the level of noise affects generalization and accuracy. Motivated by these insights, we advocate the use of Bayesian deep learning models, which typically provide improved estimates of the BCPs, as teachers in KD. Consistent with our analysis, we experimentally demonstrate that students distilled from Bayesian teachers not only achieve higher accuracies (up to +4.27%), but also exhibit more stable convergence (up to 30% less noise), compared to students distilled from deterministic teachers.

</details>


### [405] [Accelerating Decentralized Optimization via Overlapping Local Steps](https://arxiv.org/abs/2601.01493)
*Yijie Zhou,Shi Pu*

Main category: cs.LG

TL;DR: 本文提出了OLDSGD算法，通过计算与通信重叠来加速去中心化训练，减少网络空闲时间，并在保持理论收敛性的同时显著提升实际运行速度。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化优化方法常因节点间频繁同步导致通信瓶颈，限制了训练效率。

Method: 提出Overlapping Local Decentralized SGD（OLDSGD），通过精心设计的更新机制实现计算与通信重叠，在避免通信阻塞的同时保持与Local SGD相同的平均更新。

Result: 理论证明OLDSGD对光滑非凸目标具有与标准Local Decentralized SGD相同的迭代复杂度，但单次迭代运行时间更优；实验表明其在不同通信延迟下均能稳定缩短壁钟时间。

Conclusion: OLDSGD是一种轻量、实用的改进方案，在不牺牲理论保证的前提下有效加速去中心化学习。

Abstract: Decentralized optimization has emerged as a critical paradigm for distributed learning, enabling scalable training while preserving data privacy through peer-to-peer collaboration. However, existing methods often suffer from communication bottlenecks due to frequent synchronization between nodes. We present Overlapping Local Decentralized SGD (OLDSGD), a novel approach to accelerate decentralized training by computation-communication overlapping, significantly reducing network idle time. With a deliberately designed update, OLDSGD preserves the same average update as Local SGD while avoiding communication-induced stalls. Theoretically, we establish non-asymptotic convergence rates for smooth non-convex objectives, showing that OLDSGD retains the same iteration complexity as standard Local Decentralized SGD while improving per-iteration runtime. Empirical results demonstrate OLDSGD's consistent improvements in wall-clock time convergence under different levels of communication delays. With minimal modifications to existing frameworks, OLDSGD offers a practical solution for faster decentralized learning without sacrificing theoretical guarantees.

</details>


### [406] [Advanced Global Wildfire Activity Modeling with Hierarchical Graph ODE](https://arxiv.org/abs/2601.01501)
*Fan Xu,Wei Gong,Hao Wu,Lilan Peng,Nan Wang,Qingsong Wen,Xian Wu,Kun Wang,Xibin Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种名为分层图ODE（HiGO）的新框架，用于建模全球野火活动的多尺度连续时间动力学，通过多级图层次结构和自适应滤波消息传递机制，结合GNN参数化的神经ODE模块，在SeasFire Cube数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 全球野火活动受大气、海洋和陆地等多尺度过程复杂耦合影响，传统建模困难；尽管深度学习在天气预报中取得突破，但其在野火行为预测中的潜力尚未被充分探索。

Method: 构建分层图ODE（HiGO）框架：将地球系统建模为多级图层次结构，设计自适应滤波消息传递机制实现跨层级信息流动，并在各层级引入GNN参数化的神经ODE模块以学习连续时间动力学。

Result: 在SeasFire Cube数据集上的实验表明，HiGO在长时程野火预测任务中显著优于现有最先进方法，且其连续时间预测结果与观测高度一致。

Conclusion: HiGO为全球尺度野火动态建模提供了新范式，兼具多尺度表征能力与连续时间建模优势，具备实际应用潜力。

Abstract: Wildfires, as an integral component of the Earth system, are governed by a complex interplay of atmospheric, oceanic, and terrestrial processes spanning a vast range of spatiotemporal scales. Modeling their global activity on large timescales is therefore a critical yet challenging task. While deep learning has recently achieved significant breakthroughs in global weather forecasting, its potential for global wildfire behavior prediction remains underexplored. In this work, we reframe this problem and introduce the Hierarchical Graph ODE (HiGO), a novel framework designed to learn the multi-scale, continuous-time dynamics of wildfires. Specifically, we represent the Earth system as a multi-level graph hierarchy and propose an adaptive filtering message passing mechanism for both intra- and inter-level information flow, enabling more effective feature extraction and fusion. Furthermore, we incorporate GNN-parameterized Neural ODE modules at multiple levels to explicitly learn the continuous dynamics inherent to each scale. Through extensive experiments on the SeasFire Cube dataset, we demonstrate that HiGO significantly outperforms state-of-the-art baselines on long-range wildfire forecasting. Moreover, its continuous-time predictions exhibit strong observational consistency, highlighting its potential for real-world applications.

</details>


### [407] [Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings](https://arxiv.org/abs/2601.01558)
*Pengfei Qu,Wenyu Ouyang,Chi Zhang,Yikai Chai,Shuolong Xu,Lei Ye,Yongri Piao,Miao Zhang,Huchuan Lu*

Main category: cs.LG

TL;DR: 本研究探索了使用AlphaEarth Foundation嵌入（从大量卫星图像中学习得到）来表征流域特征，以提升无资料流域的径流预测精度。结果表明，相比传统流域属性，该方法能更有效地捕捉关键物理差异，并通过基于嵌入相似性选择合适源流域，进一步提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统流域属性难以全面表征自然环境的复杂性，导致无资料流域径流预测困难。

Method: 采用从卫星图像中学习得到的AlphaEarth Foundation嵌入来表征流域特征，并结合相似性筛选 donor basins 进行无资料流域径流预测建模。

Result: 基于AlphaEarth嵌入的模型在未参与训练的流域上预测精度更高；基于嵌入相似性选择源流域可提升预测性能，而加入不相似流域会降低精度。

Conclusion: 卫星数据驱动的环境表征可增强水文预报能力，并支持更具普适性的水文模型构建。

Abstract: Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.

</details>


### [408] [The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs](https://arxiv.org/abs/2601.01580)
*Zibo Zhao,Yuanting Zha,Haipeng Zhang,Xingcheng Xu*

Main category: cs.LG

TL;DR: 本文提出梯度归因属性和两阶段决策采样假设，解释了大语言模型在强化学习后训练中如何发展出自省能力，并通过理论证明和实证验证表明，RL优于SFT的关键在于提升了决策模块而非采样模块。


<details>
  <summary>Details</summary>
Motivation: 探究统一优化目标如何催生功能上分离的生成与自检能力，揭示RL后训练使大模型获得自省能力的内在机制。

Method: 提出梯度归因属性和两阶段决策采样（DS）假设，将策略分解为采样策略π_sample和决策策略π_d；理论分析不同奖励（代理奖励、SFT损失、KL惩罚）下的梯度分布平衡性；在算术推理任务上进行实证验证。

Result: 证明代理奖励具有平衡梯度归因，而SFT和KL惩罚导致不平衡梯度归因，长度加权加剧了对π_sample的约束而使π_d欠优化；实验表明RL提升主要来自π_d（决策能力）的增强，而非π_sample（生成能力）。

Conclusion: RL成功的关键在于优化了决策模块π_d，从而实现有效的自我修正；该工作为思维模型中的自校正机制提供了基于第一性原理的机理解释。

Abstract: Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($π_{sample}$) for generation and decision ($π_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $π_{sample}$ while leaving $π_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($π_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models.

</details>


### [409] [REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training](https://arxiv.org/abs/2601.01605)
*Xin Di,Xinglin Piao,Fei Wang,Guodong Jing,Yong Zhang*

Main category: cs.LG

TL;DR: 本文提出REE-TTT模型，通过引入时空测试时训练（ST-TTT）机制，提升雷达回波外推在跨区域和极端降水场景下的泛化能力与预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的雷达回波外推（REE）方法依赖高质量本地训练数据和静态模型参数，导致在不同地区和极端天气下泛化能力差。

Method: 提出REE-TTT模型，核心是新设计的时空测试时训练（ST-TTT）模块，用任务特定注意力机制替代标准线性投影，实现对非平稳气象分布的在线自适应。

Result: 在跨区域极端降水场景实验中，REE-TTT显著优于现有最先进基线模型，预测精度和泛化能力更强，对数据分布偏移表现出优异适应性。

Conclusion: ST-TTT机制有效提升了REE模型在动态、异构气象环境中的鲁棒性与实用性，为业务化短临预报提供了新思路。

Abstract: Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.

</details>


### [410] [Real Time NILM Based Power Monitoring of Identical Induction Motors Representing Cutting Machines in Textile Industry](https://arxiv.org/abs/2601.01616)
*Md Istiauk Hossain Rifat,Moin Khan,Mohammad Zunaed*

Main category: cs.LG

TL;DR: 本文提出了一种面向孟加拉国纺织工业的实时非侵入式负载监测（NILM）框架，针对相同电机驱动负载（如裁剪机）设计，通过自建硬件与云平台采集处理数据，并构建了含18万样本的新数据集评估MATNILM模型；结果表明整体能耗估计较准，但多台相同设备同时运行时设备级分解效果受限，系统已实现基于Blynk的远程实时监控。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国纺织业能耗高但监测手段落后，导致能源利用效率低、运营成本高，亟需适用于工业场景（尤其是大量同构电机负载）的实时、低成本、非侵入式监测方案。

Method: 构建基于Arduino Mega和ESP8266的硬件系统，集成电压电流传感器采集总负荷与单机负荷数据；将数据上传至云端存储与处理；创建包含三台相同感应电机及辅助负载的新型工业NILM数据集（>180,000样本）；采用当前最优MATNILM模型进行负载分解实验，并通过Blynk平台实现远程可视化监控。

Result: 整体能耗估算准确率较高，但多台相同电机同时运行时的设备级负载分解性能显著下降；系统成功实现低延迟实时监测与Blynk移动端远程访问；验证了NILM在工业环境中的可行性与当前瓶颈。

Conclusion: NILM在工业场景中具备应用潜力，但面对同构负载并发运行等挑战仍存在局限；未来需提升采样频率、扩大数据规模，并探索更适配的深度学习方法以增强对相似负载的辨识能力。

Abstract: The textile industry in Bangladesh is one of the most energy-intensive sectors, yet its monitoring practices remain largely outdated, resulting in inefficient power usage and high operational costs. To address this, we propose a real-time Non-Intrusive Load Monitoring (NILM)-based framework tailored for industrial applications, with a focus on identical motor-driven loads representing textile cutting machines. A hardware setup comprising voltage and current sensors, Arduino Mega and ESP8266 was developed to capture aggregate and individual load data, which was stored and processed on cloud platforms. A new dataset was created from three identical induction motors and auxiliary loads, totaling over 180,000 samples, to evaluate the state-of-the-art MATNILM model under challenging industrial conditions. Results indicate that while aggregate energy estimation was reasonably accurate, per-appliance disaggregation faced difficulties, particularly when multiple identical machines operated simultaneously. Despite these challenges, the integrated system demonstrated practical real-time monitoring with remote accessibility through the Blynk application. This work highlights both the potential and limitations of NILM in industrial contexts, offering insights into future improvements such as higher-frequency data collection, larger-scale datasets and advanced deep learning approaches for handling identical loads.

</details>


### [411] [Communication-Efficient Federated AUC Maximization with Cyclic Client Participation](https://arxiv.org/abs/2601.01649)
*Umesh Vangapally,Wenhan Wu,Chen Chen,Zhishuai Guo*

Main category: cs.LG

TL;DR: 本文提出了针对循环客户端参与场景下的联邦AUC最大化算法，分别针对平方代理损失和一般成对AUC损失设计了通信高效算法，并在PL条件下取得了最优的通信与迭代复杂度，实验验证了其在多个实际任务中的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦AUC最大化方法假设所有客户端始终可用，但现实中客户端常按固定周期循环参与，这给非可分解的AUC优化带来新挑战。

Method: 提出两种通信高效算法：一是针对平方代理损失，建模为非凸-强凹极小极大问题并利用PL条件分析；二是针对一般成对AUC损失，在有无PL条件下分别给出复杂度界。

Result: 对平方代理损失，取得通信复杂度Õ(1/ε^{1/2})和迭代复杂度Õ(1/ε)；对一般成对损失，在PL条件下同样达到上述最优界，否则为O(1/ε³)和O(1/ε⁴)；实验表明方法在图像分类、医学影像和欺诈检测中高效有效。

Conclusion: 本文首次系统研究循环参与下的联邦AUC优化，理论与实验均证实所提算法在通信效率与模型性能上的显著优势，为不平衡数据的实用联邦学习提供了新方案。

Abstract: Federated AUC maximization is a powerful approach for learning from imbalanced data in federated learning (FL). However, existing methods typically assume full client availability, which is rarely practical. In real-world FL systems, clients often participate in a cyclic manner: joining training according to a fixed, repeating schedule. This setting poses unique optimization challenges for the non-decomposable AUC objective. This paper addresses these challenges by developing and analyzing communication-efficient algorithms for federated AUC maximization under cyclic client participation. We investigate two key settings: First, we study AUC maximization with a squared surrogate loss, which reformulates the problem as a nonconvex-strongly-concave minimax optimization. By leveraging the Polyak-Łojasiewicz (PL) condition, we establish a state-of-the-art communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Second, we consider general pairwise AUC losses. We establish a communication complexity of $O(1/ε^3)$ and an iteration complexity of $O(1/ε^4)$. Further, under the PL condition, these bounds improve to communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Extensive experiments on benchmark tasks in image classification, medical imaging, and fraud detection demonstrate the superior efficiency and effectiveness of our proposed methods.

</details>


### [412] [Entropy-Aligned Decoding of LMs for Better Writing and Reasoning](https://arxiv.org/abs/2601.01714)
*Kareem Ahmed,Sameer Singh*

Main category: cs.LG

TL;DR: 本文提出EPIC解码方法，通过将未来轨迹的熵纳入语言模型解码过程，实现对每步生成中不确定性表达的显式调控，从而提升生成质量、多样性与忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有解码算法依赖贪心启发式，导致生成文本同质化、重复且不连贯；而随机采样质量低，需更好平衡概率与不确定性。

Method: EPIC是一种无需超参数的解码方法，引入未来轨迹熵，并通过熵感知的懒惰Gumbel-Max采样实现精确高效解码，使采样分布熵与数据固有（偶然性）不确定性对齐。

Result: EPIC在创意写作、摘要生成和数学推理任务上均优于主流解码策略，在LM-as-judge偏好胜率、多样性与摘要忠实度等指标上均有提升。

Conclusion: EPIC通过熵感知解码有效缓解了传统方法的短视偏差，实现了更符合真实数据分布的高质量文本生成。

Abstract: Language models (LMs) are trained on billions of tokens in an attempt to recover the true language distribution. Still, vanilla random sampling from LMs yields low quality generations. Decoding algorithms attempt to restrict the LM distribution to a set of high-probability continuations, but rely on greedy heuristics that introduce myopic distortions, yielding sentences that are homogeneous, repetitive and incoherent. In this paper, we introduce EPIC, a hyperparameter-free decoding approach that incorporates the entropy of future trajectories into LM decoding. EPIC explicitly regulates the amount of uncertainty expressed at every step of generation, aligning the sampling distribution's entropy to the aleatoric (data) uncertainty. Through Entropy-Aware Lazy Gumbel-Max sampling, EPIC manages to be exact, while also being efficient, requiring only a sublinear number of entropy evaluations per step. Unlike current baselines, EPIC yields sampling distributions that are empirically well-aligned with the entropy of the underlying data distribution. Across creative writing and summarization tasks, EPIC consistently improves LM-as-judge preference win-rates over widely used decoding strategies. These preference gains are complemented by automatic metrics, showing that EPIC produces more diverse generations and more faithful summaries. We also evaluate EPIC on mathematical reasoning, where it outperforms all baselines.

</details>


### [413] [Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths](https://arxiv.org/abs/2601.01663)
*He Sun,Jiwoong Shin,Ravi Dhar*

Main category: cs.LG

TL;DR: 本文提出了一种名为长度感知采样（LAS）的批处理策略，用于改善变长轨迹生成建模中的分布匹配问题，尤其在轨迹长度异质性高时提升训练稳定性与下游统计量匹配效果。


<details>
  <summary>Details</summary>
Motivation: 标准小批量训练在轨迹长度高度异质时不稳定，导致轨迹衍生统计量的分布匹配效果下降。

Method: 提出长度感知采样（LAS），按轨迹长度分桶并单桶采样；结合带时间对齐辅助损失的条件轨迹GAN，并提供分布级保证与IPM/Wasserstein机制解释。

Result: LAS在多商场购物轨迹及多个公开序列数据集（GPS、教育、电商、电影）上显著提升衍生变量分布匹配效果，优于随机采样。

Conclusion: LAS是一种简单有效、不改变模型结构的批处理策略，能提升变长轨迹生成模型的分布匹配性能与训练稳定性，适用于多种实际场景。

Abstract: We study generative modeling of \emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \emph{distribution matching} for trajectory-derived statistics. We propose \textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.

</details>


### [414] [Who is the Winning Algorithm? Rank Aggregation for Comparative Studies](https://arxiv.org/abs/2601.01664)
*Amichai Painsky*

Main category: cs.LG

TL;DR: 本文提出了一种新框架，利用算法在多个数据集上的完整排名（而不仅是获胜次数）来更准确估计其在未来数据集上获胜的概率。


<details>
  <summary>Details</summary>
Motivation: 标准的最大似然方法仅统计每个算法的获胜次数，忽略了完整排名中蕴含的更多信息（如第二、第三名等），导致估计不充分。

Method: 提出一种新颖的概念框架，基于多个数据集上的完整排名，建模并估计每个算法在未来未见数据集上获胜的概率。

Result: 该框架在合成数据和真实世界数据上均显著优于现有方法。

Conclusion: 利用完整排名信息能更有效地估计算法的获胜概率，所提框架为算法选择提供了更可靠的理论和实践基础。

Abstract: Consider a collection of m competing machine learning algorithms. Given their performance on a benchmark of datasets, we would like to identify the best performing algorithm. Specifically, which algorithm is most likely to ``win'' (rank highest) on a future, unseen dataset. The standard maximum likelihood approach suggests counting the number of wins per each algorithm. In this work, we argue that there is much more information in the complete rankings. That is, the number of times that each algorithm finished second, third and so forth. Yet, it is not entirely clear how to effectively utilize this information for our purpose. In this work we introduce a novel conceptual framework for estimating the win probability for each of the m algorithms, given their complete rankings over a benchmark of datasets. Our proposed framework significantly improves upon currently known methods in synthetic and real-world examples.

</details>


### [415] [Context-Free Recognition with Transformers](https://arxiv.org/abs/2601.01754)
*Selim Jerad,Anej Svete,Sophie Hao,Ryan Cotterell,William Merrill*

Main category: cs.LG

TL;DR: 本文研究了Transformer模型识别上下文无关语言（CFL）的能力，证明带O(log n)循环层和O(n^6)填充标记的循环Transformer可识别所有CFL；对无歧义CFL等自然子类，仅需O(n^3)填充，更具实用性，并通过实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer无法识别上下文无关语言（CFL）甚至正则语言，其语法处理能力受限；已有工作解决了正则语言识别，但CFL识别问题仍开放，本文旨在填补这一理论空白。

Method: 理论分析结合实验验证：通过构造性证明展示循环Transformer在不同填充规模下识别CFL及其子类（如无歧义CFL）的能力，并设计实验证明循环结构对需对数深度的语言的有效性。

Result: 1) O(log n)循环层+O(n^6)填充可识别所有CFL；2) 对无歧义CFL，仅需O(n^3)填充；3) 实验验证循环结构提升识别性能，尤其对需对数深度的语言。

Conclusion: Transformer识别CFL的能力高度依赖结构增强（如循环）与输入扩展（如填充），而语言本身的结构性质（如无歧义性）显著影响计算可行性；这揭示了语法建模中模型能力与语言约束间的深刻联系。

Abstract: Transformers excel on tasks that process well-formed inputs according to some grammar, such as natural language and code. However, it remains unclear how they can process grammatical syntax. In fact, under standard complexity conjectures, standard transformers cannot recognize context-free languages (CFLs), a canonical formalism to describe syntax, or even regular languages, a subclass of CFLs (Merrill et al., 2022). Merrill & Sabharwal (2024) show that $\mathcal{O}(\log n)$ looping layers (w.r.t. input length $n$) allows transformers to recognize regular languages, but the question of context-free recognition remained open. In this work, we show that looped transformers with $\mathcal{O}(\log n)$ looping layers and $\mathcal{O}(n^6)$ padding tokens can recognize all CFLs. However, training and inference with $\mathcal{O}(n^6)$ padding tokens is potentially impractical. Fortunately, we show that, for natural subclasses such as unambiguous CFLs, the recognition problem on transformers becomes more tractable, requiring $\mathcal{O}(n^3)$ padding. We empirically validate our results and show that looping helps on a language that provably requires logarithmic depth. Overall, our results shed light on the intricacy of CFL recognition by transformers: While general recognition may require an intractable amount of padding, natural constraints such as unambiguity yield efficient recognition algorithms.

</details>


### [416] [Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives](https://arxiv.org/abs/2601.01665)
*Wei Liu,Yaoxin Wu,Yingqian Zhang,Thomas Bäck,Yingjie Fan*

Main category: cs.LG

TL;DR: 本文提出了一种面向鲁棒性的统一框架，用于偏好条件下的深度强化学习求解器解决多目标组合优化问题，包含基于偏好的对抗攻击和硬度感知的偏好选择防御策略，并在多个MOCOP任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度强化学习的多目标组合优化求解器在不同复杂问题分布下的鲁棒性尚未被充分研究。

Method: 提出统一的鲁棒性导向框架，包括：1）基于偏好的对抗攻击以生成暴露求解器弱点的难例，并用Pareto前沿质量退化程度量化攻击影响；2）将硬度感知的偏好选择融入对抗训练中作为防御策略，缓解对受限偏好区域的过拟合，提升分布外泛化能力。

Result: 在MOTSP、MOCVRP和MOKP上实验表明，所提攻击方法能成功为不同求解器生成难例；所提防御方法显著增强了神经求解器的鲁棒性和泛化能力，在难例和分布外实例上性能更优。

Conclusion: 该框架有效提升了偏好条件DRL求解器在多目标组合优化问题上的鲁棒性与泛化能力，为构建可靠的学习型优化器提供了新思路。

Abstract: Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.

</details>


### [417] [HyperCLOVA X 8B Omni](https://arxiv.org/abs/2601.01792)
*NAVER Cloud HyperCLOVA X Team*

Main category: cs.LG

TL;DR: HyperCLOVA X 8B Omni 是首个支持文本、音频和视觉模态双向（输入/输出）的8B规模全模态大模型，通过统一的next-token预测框架与多模态编码器实现跨模态理解与生成，在韩英双语多任务上表现优异，并开源权重。


<details>
  <summary>Details</summary>
Motivation: 构建一个统一的、任意模态到任意模态的全模态模型，替代传统分离的单模态流水线，推动实用化全能AI助手的发展。

Method: 采用共享的next-token预测接口处理交错的多模态序列；使用视觉和音频编码器注入连续嵌入，实现细粒度跨模态理解与对齐。

Result: 在文本、音频、视觉多种输入输出组合任务中，于韩语和英语上均展现出与同规模模型相比具有竞争力的性能。

Conclusion: HyperCLOVA X 8B Omni 是迈向实用化全模态AI助手的重要一步，其开源将促进多模态研究与应用落地。

Abstract: In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.

</details>


### [418] [HeurekaBench: A Benchmarking Framework for AI Co-scientist](https://arxiv.org/abs/2601.01678)
*Siba Smarak Panigrahi,Jovana Videnović,Maria Brbić*

Main category: cs.LG

TL;DR: 本文提出HeurekaBench框架，用于构建面向探索性、开放性科研问题的实验数据基准，以评估LLM驱动的科学代理系统；在单细胞生物学中实例化为sc-HeurekaBench，并验证了加入批评模块可提升开源LLM代理22%的响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理模型缺乏真实、端到端的科研场景评估基准，难以全面衡量其在数据分析、解释与新洞见生成等方面的能力。

Method: 提出HeurekaBench框架，基于真实科研论文及代码库，利用多LLM半自动化流水线提取洞见、生成候选工作流，并经人工/实证验证；在单细胞生物学领域构建sc-HeurekaBench并评估前沿单细胞代理。

Result: sc-HeurekaBench成功用于比较当前单细胞代理性能；实证表明引入批评模块可使开源LLM代理对不良响应的修正率提升最高达22%，缩小与闭源模型差距。

Conclusion: HeurekaBench为科学代理提供了基于真实科研流程的严格端到端评估路径，推动了可复现、可量化、面向实际科研任务的AI评估范式发展。

Abstract: LLM-based reasoning models have enabled the development of agentic systems that act as co-scientists, assisting in multi-step scientific analysis. However, evaluating these systems is challenging, as it requires realistic, end-to-end research scenarios that integrate data analysis, interpretation, and the generation of new insights from the experimental data. To address this limitation, we introduce HeurekaBench, a framework to create benchmarks with exploratory, open-ended research questions for experimental datasets. Each such question is grounded in a scientific study and its corresponding code repository, and is created using a semi-automated pipeline that leverages multiple LLMs to extract insights and generate candidate workflows, which are then verified against reported findings. We instantiate the framework in single-cell biology to obtain sc-HeurekaBench benchmark and use it to compare state-of-the-art single-cell agents. We further showcase the benefits of our benchmark for quantitatively analyzing current design choices in agentic systems. We find that the addition of a critic module can improve ill-formed responses for open-source LLM-based agents by up to 22% and close the gap with their closed-source counterparts. Overall, HeurekaBench sets a path toward rigorous, end-to-end evaluation of scientific agents, grounding benchmark construction in real scientific workflows.

</details>


### [419] [DiMEx: Breaking the Cold Start Barrier in Data-Free Model Extraction via Latent Diffusion Priors](https://arxiv.org/abs/2601.01688)
*Yash Thesia,Meera Suthar*

Main category: cs.LG

TL;DR: 本文提出DiMEx框架，利用预训练潜在扩散模型的语义先验解决无数据模型提取中的'冷启动'问题，并设计Hybrid Stateful Ensemble（HSE）防御机制以识别并抑制此类攻击。


<details>
  <summary>Details</summary>
Motivation: 无数据模型提取（DFME）面临'冷启动'问题，即GAN攻击者需耗费大量查询从随机噪声收敛到有意义的数据，效率低下且易被检测。

Method: DiMEx利用预训练潜在扩散模型的语义先验，在生成器隐空间中采用随机嵌入贝叶斯优化（REMBO）直接合成高保真查询；HSE防御则通过识别潜空间攻击特有的'优化轨迹'这一时间特征进行检测。

Result: DiMEx在SVHN上仅用2000次查询即达到52.1%标签一致率，较现有GAN基线提升超16%；HSE可将攻击成功率压制至21.6%，且引入极低延迟。

Conclusion: 基于语义先验的潜空间查询合成显著提升DFME攻击效率与隐蔽性，而基于时序行为分析的HSE防御能有效应对该新型威胁，揭示了模型窃取与防御在隐空间建模层面的新博弈维度。

Abstract: Model stealing attacks pose an existential threat to Machine Learning as a Service (MLaaS), allowing adversaries to replicate proprietary models for a fraction of their training cost. While Data-Free Model Extraction (DFME) has emerged as a stealthy vector, it remains fundamentally constrained by the "Cold Start" problem: GAN-based adversaries waste thousands of queries converging from random noise to meaningful data. We propose DiMEx, a framework that weaponizes the rich semantic priors of pre-trained Latent Diffusion Models to bypass this initialization barrier entirely. By employing Random Embedding Bayesian Optimization (REMBO) within the generator's latent space, DiMEx synthesizes high-fidelity queries immediately, achieving 52.1 percent agreement on SVHN with just 2,000 queries - outperforming state-of-the-art GAN baselines by over 16 percent. To counter this highly semantic threat, we introduce the Hybrid Stateful Ensemble (HSE) defense, which identifies the unique "optimization trajectory" of latent-space attacks. Our results demonstrate that while DiMEx evades static distribution detectors, HSE exploits this temporal signature to suppress attack success rates to 21.6 percent with negligible latency.

</details>


### [420] [Enhanced Multi-model Online Conformal Prediction](https://arxiv.org/abs/2601.01692)
*Erfan Hajihashemi,Yanning Shen*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的多模型在线共形预测算法，通过构建二分图动态选择有效子集模型，以降低计算复杂度并提高预测集效率。


<details>
  <summary>Details</summary>
Motivation: 单一固定模型在在线环境中难以持续保持良好性能，而从大量候选模型中选择又带来高计算开销和低效模型干扰问题。

Method: 设计基于二分图的动态模型选择机制，在每个时间步筛选出有效模型子集，并从中选取最优模型构建共形预测集。

Result: 实验表明该方法在预测集大小和计算效率两方面均优于现有多模型共形预测技术。

Conclusion: 所提算法有效平衡了在线共形预测的统计保证、预测效率与计算开销。

Abstract: Conformal prediction is a framework for uncertainty quantification that constructs prediction sets for previously unseen data, guaranteeing coverage of the true label with a specified probability. However, the efficiency of these prediction sets, measured by their size, depends on the choice of the underlying learning model. Relying on a single fixed model may lead to suboptimal performance in online environments, as a single model may not consistently perform well across all time steps. To mitigate this, prior work has explored selecting a model from a set of candidates. However, this approach becomes computationally expensive as the number of candidate models increases. Moreover, poorly performing models in the set may also hinder the effectiveness. To tackle this challenge, this work develops a novel multi-model online conformal prediction algorithm that reduces computational complexity and improves prediction efficiency. At each time step, a bipartite graph is generated to identify a subset of effective models, from which a model is selected to construct the prediction set. Experiments demonstrate that our method outperforms existing multi-model conformal prediction techniques in terms of both prediction set size and computational efficiency.

</details>


### [421] [Output Embedding Centering for Stable LLM Pretraining](https://arxiv.org/abs/2601.02031)
*Felix Stollenwerk,Anna Lokrantz,Niclas Hertzberg*

Main category: cs.LG

TL;DR: 本文分析了大语言模型预训练中输出logit发散的不稳定性问题，从输出嵌入几何角度识别其根本原因，并提出输出嵌入中心化（OEC）方法，包括μ-centering和μ-loss两种实现，在训练稳定性和学习率鲁棒性上优于z-loss。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型存在昂贵且易出现训练不稳定的问题，尤其是大学习率下训练末期的输出logit发散；现有z-loss仅缓解症状，未解决根本原因。

Method: 从输出嵌入几何角度分析不稳定性成因，提出输出嵌入中心化（OEC），包含确定性操作μ-centering和正则化方法μ-loss，并给出理论证明。

Result: 实验表明，OEC的两种变体在训练稳定性与学习率敏感性上均优于z-loss，能在z-loss失效的大学习率下仍保证收敛，且μ-loss对超参数调优的敏感性显著低于z-loss。

Conclusion: OEC是一种更本质、更鲁棒的输出logit发散抑制策略，为提升大模型训练稳定性提供了新思路与实用工具。

Abstract: Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.

</details>


### [422] [Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT](https://arxiv.org/abs/2601.01701)
*Mohammed Ayalew Belay,Adil Rasheed,Pierluigi Salvo Rossi*

Main category: cs.LG

TL;DR: 本文提出了一套数字孪生集成的联邦学习（DTFL）方法，用于工业物联网（IIoT）异常检测，兼顾数据隐私、通信效率与模型性能，在多个指标上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法依赖真实传感器数据、标注数据稀缺、误报率高且存在隐私问题，难以满足工业系统对安全、可靠与高效的需求。

Method: 提出五种新型DTFL方法：基于数字孪生的元学习（DTML）、联邦参数融合（FPF）、层间参数交换（LPE）、循环权重自适应（CWA）和数字孪生知识蒸馏（DTKD），融合合成数据与真实数据知识，平衡泛化性与通信开销。

Result: 在公开CPS异常检测数据集上实验表明，CWA最快达到80%准确率（33轮），FPF（41轮）、LPE（48轮）次之；FedAvg和DTKD在100轮内未达标；CWA相较DTML和LPE分别减少62%和31%通信轮次。

Conclusion: 将数字孪生知识融入联邦学习可显著提升IIoT异常检测模型的收敛速度与通信效率，为隐私敏感场景提供实用解决方案。

Abstract: Anomaly detection is increasingly becoming crucial for maintaining the safety, reliability, and efficiency of industrial systems. Recently, with the advent of digital twins and data-driven decision-making, several statistical and machine-learning methods have been proposed. However, these methods face several challenges, such as dependence on only real sensor datasets, limited labeled data, high false alarm rates, and privacy concerns. To address these problems, we propose a suite of digital twin-integrated federated learning (DTFL) methods that enhance global model performance while preserving data privacy and communication efficiency. Specifically, we present five novel approaches: Digital Twin-Based Meta-Learning (DTML), Federated Parameter Fusion (FPF), Layer-wise Parameter Exchange (LPE), Cyclic Weight Adaptation (CWA), and Digital Twin Knowledge Distillation (DTKD). Each method introduces a unique mechanism to combine synthetic and real-world knowledge, balancing generalization with communication overhead. We conduct an extensive experiment using a publicly available cyber-physical anomaly detection dataset. For a target accuracy of 80%, CWA reaches the target in 33 rounds, FPF in 41 rounds, LPE in 48 rounds, and DTML in 87 rounds, whereas the standard FedAvg baseline and DTKD do not reach the target within 100 rounds. These results highlight substantial communication-efficiency gains (up to 62% fewer rounds than DTML and 31% fewer than LPE) and demonstrate that integrating DT knowledge into FL accelerates convergence to operationally meaningful accuracy thresholds for IIoT anomaly detection.

</details>


### [423] [Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting](https://arxiv.org/abs/2601.02151)
*Muxi Diao,Lele Yang,Wuxuan Gong,Yutong Zhang,Zhonghao Yan,Yufei Han,Kongming Liang,Weiran Xu,Zhanyu Ma*

Main category: cs.LG

TL;DR: 本文提出了一种熵自适应微调方法（EAFT），通过利用词元级熵作为门控机制，区分认知不确定性与知识冲突，从而在保持下游任务性能的同时缓解监督微调导致的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）虽为领域适配标准范式，但常引发灾难性遗忘；而在线策略强化学习（RL）能更好保留通用能力。作者发现其根源在于分布差异：SFT强制模型拟合外部标注，与模型内部信念不一致，尤其在'自信冲突'（低概率、低熵）词元上引发破坏性梯度更新。

Method: 提出熵自适应微调（EAFT），以词元级熵为动态门控信号，对高熵（不确定）样本保留梯度更新，对低熵且与标注冲突的样本抑制梯度，从而避免知识覆盖。

Result: 在Qwen和GLM系列模型（4B–32B）的数学、医疗与智能体任务上验证，EAFT在保持SFT下游性能的同时，显著缓解通用能力退化。

Conclusion: 词元级熵是识别知识冲突与认知不确定性的有效指标；EAFT提供了一种无需强化学习即可兼顾领域适配与能力保留的轻量微调新范式。

Abstract: Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as "Confident Conflicts" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.

</details>


### [424] [UnPII: Unlearning Personally Identifiable Information with Quantifiable Exposure Risk](https://arxiv.org/abs/2601.01786)
*Intae Jeon,Yujeong Kwon,Hyungjoon Koo*

Main category: cs.LG

TL;DR: 本文提出UnPII，一种以PII为中心的机器遗忘方法，通过引入PII风险指数（PRI）对不同PII属性的风险进行量化评估，并据此优先遗忘高风险PII；该方法兼容主流遗忘算法，在精度、效用和泛化性上均有显著提升，同时保持较低的微调开销。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法采用统一遗忘策略，未考虑不同PII属性及其组合所引发的差异化隐私与业务风险，而GDPR等法规要求高效、可靠地删除敏感PII数据。

Method: 提出PII风险指数（PRI），融合可识别性、敏感性、可用性、可链接性、持久性、暴露性与合规性七个维度；构建含1700个PII实例的合成数据集；将UnPII无缝集成至梯度上升、负偏好优化和直接偏好优化等现有遗忘算法中。

Result: 实验表明，UnPII在准确性、效用和泛化性上分别提升最多11.8%、6.3%和12.4%，平均微调开销仅增加27.5%。

Conclusion: UnPII是首个面向PII风险差异化的机器遗忘框架，兼顾法规合规性与模型性能，为高风险PII的精准遗忘提供了可扩展、可定制的解决方案。

Abstract: The ever-increasing adoption of Large Language Models in critical sectors like finance, healthcare, and government raises privacy concerns regarding the handling of sensitive Personally Identifiable Information (PII) during training. In response, regulations such as European Union's General Data Protection Regulation (GDPR) mandate the deletion of PII upon requests, underscoring the need for reliable and cost-effective data removal solutions. Machine unlearning has emerged as a promising direction for selectively forgetting data points. However, existing unlearning techniques typically apply a uniform forgetting strategy that neither accounts for the varying privacy risks posed by different PII attributes nor reflects associated business risks. In this work, we propose UnPII, the first PII-centric unlearning approach that prioritizes forgetting based on the risk of individual or combined PII attributes. To this end, we introduce the PII risk index (PRI), a composite metric that incorporates multiple dimensions of risk factors: identifiability, sensitivity, usability, linkability, permanency, exposability, and compliancy. The PRI enables a nuanced evaluation of privacy risks associated with PII exposures and can be tailored to align with organizational privacy policies. To support realistic assessment, we systematically construct a synthetic PII dataset (e.g., 1,700 PII instances) that simulates realistic exposure scenarios. UnPII seamlessly integrates with established unlearning algorithms, such as Gradient Ascent, Negative Preference Optimization, and Direct Preference Optimization, without modifying their underlying principles. Our experimental results demonstrate that UnPII achieves the improvements of accuracy up to 11.8%, utility up to 6.3%, and generalizability up to 12.4%, respectively, while incurring a modest fine-tuning overhead of 27.5% on average during unlearning.

</details>


### [425] [Distributed Federated Learning by Alternating Periods of Training](https://arxiv.org/abs/2601.01793)
*Shamik Bhattacharyya,Rachel Kalpana Kalaimani*

Main category: cs.LG

TL;DR: 本文提出了一种分布式联邦学习（DFL）框架，通过多个具备通信能力的服务器替代单一中心服务器，提升可扩展性与容错性，同时保持联邦学习的核心结构；DFL算法结合客户端本地训练与服务器间全局训练，理论证明其能收敛至理想模型附近，并通过数值实验验证。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习依赖单一中心服务器导致的可扩展性差和单点故障风险问题。

Method: 提出分布式联邦学习（DFL）框架与算法，采用多服务器架构，各服务器连接互不重叠的客户端子集，并支持服务器间通信；算法交替进行客户端本地训练和服务器间全局训练。

Result: 理论证明DFL算法在合适参数下能使所有服务器收敛至理想模型的小邻域内；数值模拟验证了理论结果。

Conclusion: DFL框架在保持联邦学习隐私优势的同时，显著提升了系统可扩展性与容错性，是一种有效的去中心化联邦学习范式。

Abstract: Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.

</details>


### [426] [Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving](https://arxiv.org/abs/2601.01800)
*Qi Wei,Junchao Fan,Zhao Yang,Jianhua Wang,Jingkai Mao,Xiaolin Chang*

Main category: cs.LG

TL;DR: 本文提出了一种面向稀疏安全关键风险的对抗训练方法CARRL，通过构建风险暴露对手（REA）和风险目标鲁棒智能体（RTRA）的广义和博弈框架，提升自动驾驶中强化学习策略的安全性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练方法将智能体与对手建模为零和博弈，忽略了二者间的不对称性，且未能反映安全关键风险的稀疏性，导致实际自动驾驶场景中鲁棒性不足。

Method: 提出CARRL框架，包含风险暴露对手（REA）和风险目标鲁棒智能体（RTRA）；REA采用解耦优化机制聚焦稀疏安全关键时刻；RTRA使用双经验回放缓冲区联合利用良性和对抗样本，并施加扰动下的策略一致性约束。

Result: 在多个测试案例中，相比当前最优基线方法，碰撞率至少降低22.66%。

Conclusion: CARRL通过建模广义和博弈与针对性对抗机制，有效提升了自动驾驶强化学习策略在稀疏安全关键风险下的鲁棒性与实用性。

Abstract: Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\% across all cases compared to state-of-the-art baseline methods.

</details>


### [427] [Moments Matter:Stabilizing Policy Optimization using Return Distributions](https://arxiv.org/abs/2601.01803)
*Dennis Jabs,Aditya Mohan,Marius Lindauer*

Main category: cs.LG

TL;DR: 本文提出了一种基于分布式批评家高阶矩（偏度和峰度）修正PPO优势函数的新方法，以抑制策略更新带来的不稳定性，显著提升连续控制任务中策略的鲁棒性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习智能体在相同回报下行为差异大，尤其在连续控制任务中，小的参数扰动易导致不稳定步态，影响算法比较与现实迁移；现有方法通过约束回报分布R(θ)提升稳定性但计算开销大。

Method: 利用环境随机性，构建分布式批评家建模状态-动作回报分布，并在PPO中用其偏度和峰度修正优势函数，惩罚极端尾部行为，从而避免进入易失稳的参数区域。

Result: 在Walker2D任务中将R(θ)的离散度降低最多75%，显著提升策略稳定性，同时保持相近的评估回报。

Conclusion: 高阶矩引导的优势修正可有效缓解更新噪声引发的策略不稳定性，是一种高效、可扩展的稳定性增强机制。

Abstract: Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.

</details>


### [428] [RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data](https://arxiv.org/abs/2601.01829)
*Peiyan Hu,Haodong Feng,Hongyuan Liu,Tongtong Yan,Wenhao Deng,Tianrun Gao,Rong Zheng,Haoren Zheng,Chenglei Yu,Chuanrui Wang,Kaiwen Li,Zhi-Ming Ma,Dezhi Zhou,Xingcai Lu,Dixia Fan,Tailin Wu*

Main category: cs.LG

TL;DR: 本文提出了RealPDEBench，首个融合真实世界测量与配对数值模拟的科学机器学习基准，旨在弥合仿真到现实（sim-to-real）的差距。


<details>
  <summary>Details</summary>
Motivation: 现有科学机器学习模型受限于昂贵且稀缺的真实世界数据，多依赖仿真数据训练和验证，阻碍了模型评估、sim-to-real迁移等关键研究。

Method: 构建包含5个真实-仿真配对数据集、3类任务、8种评估指标（兼顾数据与物理导向）和10个基线模型（含SOTA模型与预训练PDE基础模型）的综合基准RealPDEBench。

Result: 实验揭示了仿真与真实数据间存在显著差异；同时表明利用仿真数据预训练可持续提升模型精度与收敛速度。

Conclusion: RealPDEBench为科学机器学习提供了基于真实数据的评估平台，推动模型向真实场景部署和sim-to-real能力发展。

Abstract: Predicting the evolution of complex physical systems remains a central problem in science and engineering. Despite rapid progress in scientific Machine Learning (ML) models, a critical bottleneck is the lack of expensive real-world data, resulting in most current models being trained and validated on simulated data. Beyond limiting the development and evaluation of scientific ML, this gap also hinders research into essential tasks such as sim-to-real transfer. We introduce RealPDEBench, the first benchmark for scientific ML that integrates real-world measurements with paired numerical simulations. RealPDEBench consists of five datasets, three tasks, eight metrics, and ten baselines. We first present five real-world measured datasets with paired simulated datasets across different complex physical systems. We further define three tasks, which allow comparisons between real-world and simulated data, and facilitate the development of methods to bridge the two. Moreover, we design eight evaluation metrics, spanning data-oriented and physics-oriented metrics, and finally benchmark ten representative baselines, including state-of-the-art models, pretrained PDE foundation models, and a traditional method. Experiments reveal significant discrepancies between simulated and real-world data, while showing that pretraining with simulated data consistently improves both accuracy and convergence. In this work, we hope to provide insights from real-world data, advancing scientific ML toward bridging the sim-to-real gap and real-world deployment. Our benchmark, datasets, and instructions are available at https://realpdebench.github.io/.

</details>


### [429] [FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks](https://arxiv.org/abs/2601.01833)
*Chenyu Hu,Qiming Hu,Sinan Chen,Nianyu Li,Mingyue Zhang,Jialong Li*

Main category: cs.LG

TL;DR: 本文提出FAROS框架，通过自适应差分缩放（ADS）和鲁棒核心集计算（RCC）提升联邦学习中对后门攻击的防御能力，兼顾检测灵敏度与抗单点故障能力，并在多场景实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习后门防御方法多依赖固定参数，存在单点失效风险，难以应对策略性攻击者。

Method: 提出FAROS框架，包含两个核心机制：1）自适应差分缩放（ADS），根据每轮客户端上传梯度的离散程度动态调整防御敏感度；2）鲁棒核心集计算（RCC），基于高置信度客户端构建核心集并计算其质心以降低单点失效风险。

Result: 在多种数据集、模型和攻击场景下实验表明，FAROS在降低攻击成功率的同时，保持更高的主任务准确率，整体性能优于当前主流防御方法。

Conclusion: FAROS通过动态自适应与鲁棒聚合机制，有效提升了联邦学习系统对后门攻击的防御鲁棒性与泛化能力，为实际部署提供了更可靠的解决方案。

Abstract: Federated Learning (FL) enables multiple clients to collaboratively train a shared model without exposing local data. However, backdoor attacks pose a significant threat to FL. These attacks aim to implant a stealthy trigger into the global model, causing it to mislead on inputs that possess a specific trigger while functioning normally on benign data. Although pre-aggregation detection is a main defense direction, existing state-of-the-art defenses often rely on fixed defense parameters. This reliance makes them vulnerable to single-point-of-failure risks, rendering them less effective against sophisticated attackers. To address these limitations, we propose FAROS, an enhanced FL framework that incorporates Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). The ADS mechanism adjusts the defense's sensitivity dynamically, based on the dispersion of uploaded gradients by clients in each round. This allows it to counter attackers who strategically shift between stealthiness and effectiveness. Furthermore, the RCC effectively mitigates the risk of single-point failure by computing the centroid of a core set comprising clients with the highest confidence. We conducted extensive experiments across various datasets, models, and attack scenarios. The results demonstrate that our method outperforms current defenses in both attack success rate and main task accuracy.

</details>


### [430] [Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack](https://arxiv.org/abs/2601.01840)
*Qiantao Yang,Liquan Chen,Mingfu Xue,Songze Li*

Main category: cs.LG

TL;DR: 本文提出FedCSPACK方法，通过余弦稀疏化参数打包与双加权聚合，在资源受限的客户端上缓解数据异质性问题，提升通信/计算效率与模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中边缘客户端间的数据异质性严重损害模型性能，而现有方法未兼顾有限带宽与算力约束。

Method: 提出FedCSPACK：客户端基于余弦相似度筛选并打包高贡献参数以降低通信开销；生成锚定共享参数包的掩码矩阵，并嵌入方向与分布距离权重实现加权聚合。

Result: 在四个数据集、十种SOTA方法对比实验中，FedCSPACK显著提升通信与计算效率，同时保持高模型精度。

Conclusion: FedCSPACK在资源受限条件下有效平衡数据异质性处理与系统效率，增强了全局模型鲁棒性与泛化能力。

Abstract: Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.

</details>


### [431] [High-Order Epistasis Detection Using Factorization Machine with Quadratic Optimization Annealing and MDR-Based Evaluation](https://arxiv.org/abs/2601.01860)
*Shuta Kikuchi,Shu Tanaka*

Main category: cs.LG

TL;DR: 本文提出了一种基于因子分解机与二次优化退火（FMQA）的高效高阶上位性检测方法，将上位性检测建模为黑箱优化问题，并以MDR计算的分类错误率（CER）为目标函数，在模拟数据上验证了其在多种交互阶数和位点数量下均能快速准确识别真实上位性组合。


<details>
  <summary>Details</summary>
Motivation: 高阶上位性检测因候选位点组合呈组合爆炸而面临巨大计算挑战，传统MDR穷举搜索随位点数或交互阶数增加迅速失效。

Method: 将上位性检测建模为黑箱优化问题，采用因子分解机结合二次优化退火（FMQA）进行求解，以MDR计算的分类错误率（CER）作为黑箱目标函数。

Result: 在预设高阶上位性的模拟病例-对照数据集上，该方法能在有限迭代次数内成功识别出真实上位性组合，覆盖多种交互阶数和位点数量。

Conclusion: 所提FMQA方法在高阶上位性检测中兼具有效性与计算高效性，显著优于传统MDR穷举策略。

Abstract: Detecting high-order epistasis is a fundamental challenge in genetic association studies due to the combinatorial explosion of candidate locus combinations. Although multifactor dimensionality reduction (MDR) is a widely used method for evaluating epistasis, exhaustive MDR-based searches become computationally infeasible as the number of loci or the interaction order increases. In this paper, we define the epistasis detection problem as a black-box optimization problem and solve it with a factorization machine with quadratic optimization annealing (FMQA). We propose an efficient epistasis detection method based on FMQA, in which the classification error rate (CER) computed by MDR is used as a black-box objective function. Experimental evaluations were conducted using simulated case-control datasets with predefined high-order epistasis. The results demonstrate that the proposed method successfully identified ground-truth epistasis across various interaction orders and the numbers of genetic loci within a limited number of iterations. These results indicate that the proposed method is effective and computationally efficient for high-order epistasis detection.

</details>


### [432] [Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance](https://arxiv.org/abs/2601.01887)
*Jiawen Zhang,Lipeng He,Kejia Chen,Jian Lou,Jian Liu,Xiaohu Yang,Ruoxi Jia*

Main category: cs.LG

TL;DR: 本文提出了一种仅需单个安全样本即可高效恢复微调后大语言模型安全对齐的方法，无需牺牲模型实用性，且计算开销极小；其有效性源于安全梯度的低秩结构。


<details>
  <summary>Details</summary>
Motivation: 微调安全对齐的大语言模型会严重损害其安全性，而现有方法依赖大量安全样本或校准集，导致计算开销大、实用性下降。

Method: 利用单个安全样本来进行高效再对齐，并揭示安全梯度具有低秩结构，从而解释该方法的可行性。

Result: 在五个安全对齐的LLM和多个数据集上验证了该方法的有效性与泛化性：仅用一个安全样本、数个训练周期即可完全恢复安全对齐，且不损害模型实用性。

Conclusion: 安全对齐可通过极低成本（单样本、少轮次）高效恢复，其理论基础是安全梯度的低秩特性，挑战了需大量安全数据的传统认知。

Abstract: Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.

</details>


### [433] [FedBiCross: A Bi-Level Optimization Framework to Tackle Non-IID Challenges in Data-Free One-Shot Federated Learning on Medical Data](https://arxiv.org/abs/2601.01901)
*Yuexuan Xia,Yinghao Zhang,Yalin Liu,Hong-Ning Dai,Yong Xia*

Main category: cs.LG

TL;DR: 本文提出FedBiCross，一种面向非独立同分布（non-IID）数据的个性化单轮联邦学习框架，通过客户端聚类、跨簇自适应加权优化与个性化知识蒸馏，显著提升数据免费知识蒸馏在医疗影像任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有单轮联邦学习方法在non-IID数据下因客户端预测冲突导致全局软标签趋于均匀，监督信号弱，难以有效蒸馏。

Method: FedBiCross包含三阶段：(1) 基于模型输出相似性聚类客户端以构建一致子集成；(2) 双层跨簇优化，学习自适应权重以选择性利用有益跨簇知识并抑制负迁移；(3) 客户端个性化知识蒸馏。

Result: 在四个医学图像数据集上，FedBiCross在不同non-IID程度下均持续超越当前最优基线方法。

Conclusion: 通过引入个性化与跨簇协同机制，FedBiCross有效缓解了non-IID下软标签退化问题，提升了数据免费单轮联邦学习的实用性与泛化能力。

Abstract: Data-free knowledge distillation-based one-shot federated learning (OSFL) trains a model in a single communication round without sharing raw data, making OSFL attractive for privacy-sensitive medical applications. However, existing methods aggregate predictions from all clients to form a global teacher. Under non-IID data, conflicting predictions cancel out during averaging, yielding near-uniform soft labels that provide weak supervision for distillation. We propose FedBiCross, a personalized OSFL framework with three stages: (1) clustering clients by model output similarity to form coherent sub-ensembles, (2) bi-level cross-cluster optimization that learns adaptive weights to selectively leverage beneficial cross-cluster knowledge while suppressing negative transfer, and (3) personalized distillation for client-specific adaptation. Experiments on four medical image datasets demonstrate that FedBiCross consistently outperforms state-of-the-art baselines across different non-IID degrees.

</details>


### [434] [TT-FSI: Scalable Faithful Shapley Interactions via Tensor-Train](https://arxiv.org/abs/2601.01903)
*Ungsik Kim,Suwon Lee*

Main category: cs.LG

TL;DR: 本文提出TT-FSI方法，利用矩阵乘积算子（MPO）高效计算Faithful Shapley Interaction（FSI）指数，在时间和内存上实现指数级改进，并在多个数据集上验证了其显著加速和可扩展性。


<details>
  <summary>Details</summary>
Motivation: FSI指数虽满足忠实性公理，但其计算复杂度高（时间O(d^ℓ·2^d)，内存O(4^d)），难以实际应用，亟需更高效的算法。

Method: 提出TT-FSI，基于FSI的代数结构，构建TT-rank为O(ℓd)的矩阵乘积算子（MPO）表示，并设计高效sweep算法实现计算。

Result: 理论：FSI线性算子存在低TT-rank MPO表示；实验：在d=8到20的数据集上，相较基线提速最高280×，相较SHAP-IQ提速85×，内存减少290×，并首次成功处理d=20（100万联盟）规模问题。

Conclusion: TT-FSI在保持FSI理论优势的同时，大幅降低计算开销，显著提升可扩展性，为高维Shapley交互分析提供了实用新工具。

Abstract: The Faithful Shapley Interaction (FSI) index uniquely satisfies the faithfulness axiom among Shapley interaction indices, but computing FSI requires $O(d^\ell \cdot 2^d)$ time and existing implementations use $O(4^d)$ memory. We present TT-FSI, which exploits FSI's algebraic structure via Matrix Product Operators (MPO). Our main theoretical contribution is proving that the linear operator $v \mapsto \text{FSI}(v)$ admits an MPO representation with TT-rank $O(\ell d)$, enabling an efficient sweep algorithm with $O(\ell^2 d^3 \cdot 2^d)$ time and $O(\ell d^2)$ core storage an exponential improvement over existing methods. Experiments on six datasets ($d=8$ to $d=20$) demonstrate up to 280$\times$ speedup over baseline, 85$\times$ over SHAP-IQ, and 290$\times$ memory reduction. TT-FSI scales to $d=20$ (1M coalitions) where all competing methods fail.

</details>


### [435] [Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning](https://arxiv.org/abs/2601.01904)
*Yuxuan Li,Harshith Reddy Kethireddy,Srijita Das*

Main category: cs.LG

TL;DR: 本文提出了一种针对偏好学习中特征依赖噪声的建模方法，并在多个连续控制任务上验证了现有抗噪PbRL方法在该类噪声下的性能下降，甚至不如无显式去噪机制的方法；同时发现大语言模型生成的偏好也呈现类似特征依赖噪声特性。


<details>
  <summary>Details</summary>
Motivation: 现有PbRL抗噪方法多假设噪声均匀分布、与观测无关，难以应对真实场景中（如人类或语言模型提供偏好时）与状态/轨迹特征相关的复杂噪声。

Method: 形式化定义了多种特征依赖噪声（如轨迹特征噪声、轨迹相似性噪声、不确定性感知噪声、语言模型噪声），并在DMControl和Meta-World基准上进行实验评估。

Result: 在特征依赖噪声下，当前最优抗噪PbRL方法性能显著下降；多数情况下，无显式去噪机制的PbRL反而表现更优；语言模型产生的偏好噪声也表现出类似特征依赖性。

Conclusion: 特征依赖噪声是PbRL中亟需关注的真实挑战，现有抗噪方法存在局限，需发展更鲁棒的新方法，尤其面向语言模型等新兴偏好来源。

Abstract: Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.
  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.
  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.

</details>


### [436] [Distorted Distributional Policy Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2601.01917)
*Ryo Iwaki,Takayuki Osogami*

Main category: cs.LG

TL;DR: 本文提出了一种名为'分位数扭曲'的新方法，以解决离线分布强化学习中因统一低估回报分位数而导致的过度保守问题，通过基于数据支持程度调整悲观程度，实现了非均匀悲观策略，并在理论和实验上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有离线分布强化学习（DRL）方法采用统一低估回报分位数的策略，导致价值估计过于保守，限制了泛化能力和性能。

Method: 提出'分位数扭曲'概念，实现基于数据支持程度的非均匀悲观策略，并辅以理论分析与实证验证。

Result: 所提方法在离线DRL任务中相较统一悲观策略展现出更优性能。

Conclusion: 非均匀悲观策略（即分位数扭曲）能有效缓解离线DRL中的过度保守问题，提升模型泛化性与实际表现。

Abstract: While Distributional Reinforcement Learning (DRL) methods have demonstrated strong performance in online settings, its success in offline scenarios remains limited. We hypothesize that a key limitation of existing offline DRL methods lies in their approach to uniformly underestimate return quantiles. This uniform pessimism can lead to overly conservative value estimates, ultimately hindering generalization and performance. To address this, we introduce a novel concept called quantile distortion, which enables non-uniform pessimism by adjusting the degree of conservatism based on the availability of supporting data. Our approach is grounded in theoretical analysis and empirically validated, demonstrating improved performance over uniform pessimism.

</details>


### [437] [Theoretical Convergence of SMOTE-Generated Samples](https://arxiv.org/abs/2601.01927)
*Firuz Kamalov,Hana Sulieman,Witold Pedrycz*

Main category: cs.LG

TL;DR: 本文对SMOTE算法进行了严格的理论分析，证明了其生成的合成随机变量Z在概率意义下收敛于原始随机变量X，并在X为紧集时证明了更强的均值收敛性；同时指出较小的近邻秩能加快收敛速度，为实际应用提供指导。


<details>
  <summary>Details</summary>
Motivation: SMOTE是处理不平衡数据最常用的方法之一，但缺乏严格的理论支撑，亟需从理论上验证其有效性。

Method: 通过概率论与数学分析方法，严格证明SMOTE生成的合成随机变量Z的收敛性质（包括依概率收敛和在紧集条件下的L1收敛），并分析近邻秩对收敛速度的影响。

Result: 证明了Z依概率收敛于X；当X为紧集时，Z在L1意义下收敛于X；且近邻秩越小，收敛越快；数值实验验证了理论结论。

Conclusion: 本工作为SMOTE提供了坚实的理论基础，不仅深化了对不平衡数据增强机制的理解，也拓展了其在更广泛数据增强场景中的适用性。

Abstract: Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.

</details>


### [438] [DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems](https://arxiv.org/abs/2601.01931)
*Willem Röpke,Samuel Coward,Andrei Lupu,Thomas Foster,Tim Rocktäschel,Jakob Foerster*

Main category: cs.LG

TL;DR: 本文提出DéjàQ框架，通过LLM驱动的突变策略动态生成和优化数学问题，以提升模型在数学推理任务中的泛化能力与训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型多依赖静态数据集，易导致记忆而非真正泛化，亟需能随模型能力自适应演化的动态训练数据机制。

Method: 提出DéjàQ框架，结合进化算法与LLM驱动的两种突变策略（上下文细节调整、问题结构修改），在训练过程中联合演化问题集与模型参数。

Result: 模型可生成新颖且有效的数学问题；LLM驱动的突变显著提升强化学习训练效果；生成问题具有高有效性，计算开销可控。

Conclusion: 动态演化训练数据是提升数学推理能力的有效路径，该范式具备通用性，代码将开源。

Abstract: Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.

</details>


### [439] [SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling](https://arxiv.org/abs/2601.01943)
*Tieu-Long Phan,Nhu-Ngoc Nguyen Song,Peter F. Stadler*

Main category: cs.LG

TL;DR: SynRXN是一个面向计算机辅助合成规划（CASP）的统一基准框架与开放数据资源，涵盖五大任务族，提供标准化数据集、泄漏感知划分、可复现构建流程及开放许可，旨在促进公平、严谨且可复用的CASP方法评估。


<details>
  <summary>Details</summary>
Motivation: 解决当前CASP领域数据集异构、评估不透明、复现困难、训练-测试污染风险高等问题，推动方法间公平、纵向、可复现的性能比较。

Method: 构建覆盖5类任务的统一框架；从多源公共数据中整理带溯源信息的反应语料；设计泄漏感知的数据划分策略；提供标准化评估流程与指标；采用脚本化、校验哈希的可复现构建方式；对高污染风险任务仅提供评测集。

Result: 发布了一套版本化、带元数据与许可证标签的开放数据集；配套透明评估工作流与可复现构建工具；明确区分训练/验证/测试用途，尤其规避反应重平衡与原子映射任务的训练污染。

Conclusion: SynRXN通过消除数据异构性与封装透明可复用的评估基础设施，显著提升了CASP研究的严谨性、可比性与实用性，为算法开发、消融分析与真实场景性能评估提供了坚实基础。

Abstract: We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.

</details>


### [440] [Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior](https://arxiv.org/abs/2601.01966)
*Bo Yin,Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.LG

TL;DR: 本文提出了Refinement Provenance Inference (RPI)任务，旨在判断一个微调模型是否使用了原始提示还是LLM重写的提示进行训练；作者发现提示重写会在teacher-forced token分布中引发稳定可检测的偏移，并据此提出RePro框架，利用logit特征与排序信号，通过影子微调学习可迁移表征，在无需访问目标模型训练数据的情况下实现高精度、跨模型和跨重写器的溯源。


<details>
  <summary>Details</summary>
Motivation: 随着LLM驱动的提示精炼在指令微调中广泛应用，需解决实例级审计问题：即对给定微调模型和提示-响应对，判断其训练时使用的是原始提示还是精炼后的提示。该问题对数据集治理和训练数据争议解决至关重要，但因精炼与原始样本在混合语料中比例未知且交织，导致溯源方法难以泛化。

Method: 本文形式化定义RPI任务，发现提示精炼会引发teacher-forced token分布的稳定偏移；基于此，提出RePro框架：融合teacher-forced似然特征与logit排序信号，通过shadow fine-tuning学习可迁移表征，并用轻量线性头实现零样本（无训练数据访问）的溯源推断。

Result: RePro在多个重写器和目标模型上均展现出强性能与良好跨域迁移能力，表明其捕获的是重写器无关的分布偏移，而非特定重写风格的伪影。

Conclusion: 提示精炼虽语义隐蔽，却在生成建模中留下可泛化、可检测的统计指纹；RePro为LLM训练数据溯源提供了首个实用、免训练数据、可迁移的解决方案，推动了AI数据治理的可验证性。

Abstract: Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.

</details>


### [441] [SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition](https://arxiv.org/abs/2601.01979)
*Julie Keisler,Anastase Alexandre Charantonis,Yannig Goude,Boutheina Oueslati,Claire Monteleoni*

Main category: cs.LG

TL;DR: 本文提出SerpentFlow框架，用于无配对数据的跨域对齐任务，通过在潜在空间中将数据分解为共享结构和域特有成分，并利用生成模型学习目标域条件分布。


<details>
  <summary>Details</summary>
Motivation: 在缺乏配对观测的情况下，实现具有共同底层结构但具体实现不同的域之间的对齐极具挑战性。

Method: SerpentFlow将数据在潜在空间中分解为共享成分（如低频内容）和域特有成分（如高频细节），用随机噪声替换后者以构建合成训练对，并采用Flow Matching作为生成主干。

Result: 在合成图像、物理过程模拟及气候降尺度任务中验证了方法有效性，能一致重建符合低频模式的高频结构。

Conclusion: 共享结构分解是一种有效的无配对域对齐策略，SerpentFlow为条件生成模型拓展至无配对场景提供了新范式。

Abstract: Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.

</details>


### [442] [Prior Diffusiveness and Regret in the Linear-Gaussian Bandit](https://arxiv.org/abs/2601.02022)
*Yifan Zhu,John C. Duchi,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 本文证明了Thompson采样在线性高斯赌博机中具有贝叶斯遗憾上界，其先验依赖的“预热”项与长期最小最大遗憾项呈加性而非乘性关系，并通过新提出的“椭圆势”引理及下界分析支持该结论。


<details>
  <summary>Details</summary>
Motivation: 现有遗憾上界中先验依赖的“预热”项与长期遗憾呈乘性依赖，本文旨在揭示二者可解耦为加性关系，并验证该“预热”项不可避免。

Method: 通过提出新的“椭圆势”引理，对Thompson采样在线性高斯赌博机中的贝叶斯遗憾进行理论分析，并辅以信息论下界证明“预热”项的不可避免性。

Result: 获得贝叶斯遗憾上界 $\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$，首次实现先验项与时间项的加性分离；并给出匹配的下界，表明 $d r \sqrt{\mathrm{Tr}(Σ_0)}$ 项不可消除。

Conclusion: Thompson采样在线性高斯赌博机中具有更精细的贝叶斯遗憾刻画，其先验影响仅以加性方式体现在‘预热’阶段，且该影响是本质的、无法避免的。

Abstract: We prove that Thompson sampling exhibits $\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \sqrt{\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.

</details>


### [443] [GDRO: Group-level Reward Post-training Suitable for Diffusion Models](https://arxiv.org/abs/2601.02036)
*Yiyang Wang,Xi Chen,Xiaogang Xu,Yu Liu,Hengshuang Zhao*

Main category: cs.LG

TL;DR: 本文提出Group-level Direct Reward Optimization (GDRO)，一种面向rectified flow扩散模型的离线后训练范式，用于高效、稳定地实现群体级奖励对齐，避免在线采样与奖励作弊问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于在线强化学习的奖励对齐方法在rectified flow图像生成模型中存在效率低、依赖随机采样器、易发生奖励作弊等问题，根源在于其与LLM在效率和随机性上的本质差异。

Method: 提出GDRO方法，结合rectified flow模型特性，支持完全离线训练；理论分析证明其无需图像rollout采样且不依赖特定扩散采样器；引入校正评分机制以评估并缓解奖励作弊。

Result: 在OCR和GenEval任务上，GDRO通过群体级离线优化显著提升奖励得分，同时展现出强稳定性与抗奖励作弊能力。

Conclusion: GDRO是一种更高效、鲁棒且实用的扩散模型奖励对齐新范式，解决了在线RL方法在rectified flow模型中的关键瓶颈。

Abstract: Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.

</details>


### [444] [Multivariate Time-series Anomaly Detection via Dynamic Model Pool & Ensembling](https://arxiv.org/abs/2601.02037)
*Wei Hu,Zewei Yu,Jianqiu Xu*

Main category: cs.LG

TL;DR: 本文提出了一种动态模型池与集成框架DMPEAD，用于多变量时间序列异常检测，通过构建多样化模型池、自适应更新及基于代理指标的集成策略，显著提升了检测性能、适应性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在选择策略敏感、难以处理多变量数据、依赖固定维度限制可扩展性等问题。

Method: 提出DMPEAD框架：1）利用参数迁移和多样性度量构建多样化模型池；2）通过元模型与相似性策略实现池的自适应扩展、子集选择与合并；3）基于代理指标排序与top-k聚合对优选子集中的模型进行集成。

Result: 在8个真实世界数据集上的实验表明，DMPEAD全面优于所有基线方法，展现出更强的适应性和可扩展性。

Conclusion: DMPEAD有效解决了多变量时间序列异常检测中模型选择与集成的关键挑战，为复杂动态场景提供了更鲁棒、灵活的解决方案。

Abstract: Multivariate time-series (MTS) anomaly detection is critical in domains such as service monitor, IoT, and network security. While multi-model methods based on selection or ensembling outperform single-model ones, they still face limitations: (i) selection methods rely on a single chosen model and are sensitive to the strategy; (ii) ensembling methods often combine all models or are restricted to univariate data; and (iii) most methods depend on fixed data dimensionality, limiting scalability. To address these, we propose DMPEAD, a Dynamic Model Pool and Ensembling framework for MTS Anomaly Detection. The framework first (i) constructs a diverse model pool via parameter transfer and diversity metric, then (ii) updates it with a meta-model and similarity-based strategy for adaptive pool expansion, subset selection, and pool merging, finally (iii) ensembles top-ranked models through proxy metric ranking and top-k aggregation in the selected subset, outputting the final anomaly detection result. Extensive experiments on 8 real-world datasets show that our model outperforms all baselines, demonstrating superior adaptability and scalability.

</details>


### [445] [Explore the Ideology of Deep Learning in ENSO Forecasts](https://arxiv.org/abs/2601.02050)
*Yanhai Gan,Yipeng Chen,Ning Li,Xingguo Liu,Junyu Dong,Xianyao Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于有界变差函数的数学可解释性框架，用于提升深度学习模型在厄尔尼诺-南方涛动（ENSO）预测中的透明度与性能；通过激活‘死亡神经元’增强模型表达能力，发现ENSO可预测性主要源于热带太平洋，并揭示春季可预报性障碍（SPB）的成因与改进方向。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽提升了ENSO预测能力，但其黑箱特性阻碍科学信任与业务应用；同时，春季可预报性障碍（SPB）机制尚不清晰，亟需可解释、物理一致的建模方法。

Method: 构建基于有界变差函数的可解释深度学习框架，通过修正激活函数饱和区以恢复‘死亡神经元’，结合敏感性分析与受控实验评估变量贡献与物理一致性。

Result: 证实ENSO预测信号主源于热带太平洋，并识别印度洋与大西洋的次要贡献；揭示SPB期间模型敏感性升高但性能下降，归因于变量选择不足；控制实验验证方法鲁棒性及与经典物理指标的一致性。

Conclusion: 该可解释框架不仅增强模型可信度与物理可理解性，还为突破SPB、引入更多海气变量以提升长时效ENSO预测提供了新路径。

Abstract: The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the "dead" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.

</details>


### [446] [The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks](https://arxiv.org/abs/2601.02080)
*Yizhi Liu*

Main category: cs.LG

TL;DR: 本文揭示了双随机矩阵（DSM）约束深度网络中固有的‘均匀性陷阱’现象：最大熵偏差导致次主导奇异值σ₂衰减，抑制高频特征，限制有效感受野深度；层归一化在信噪比过低时无法阻止由噪声引发的几何结构坍塌，揭示了熵稳定性与谱表达能力之间的根本权衡。


<details>
  <summary>Details</summary>
Motivation: 双随机矩阵（DSM）虽提升数值稳定性和概率可解释性，但其隐含的最大熵偏差可能导致谱退化，影响模型表达能力，亟需系统分析其内在机制与限制。

Method: 通过理论分析推导次主导奇异值σ₂的谱界，建立其与网络有效深度的关系；形式化证明层归一化在噪声主导下无法缓解谱坍塌，并分析信噪比阈值与几何结构丢失的关联。

Result: 发现Sinkhorn类投影引发的‘均匀性陷阱’显著削弱σ₂，压缩有效感受野；证明当SNR低于临界值时，层归一化失效，噪声导致不可逆的正交坍塌。

Conclusion: DSM约束在保障稳定性的同时牺牲谱表达力，存在熵稳定性与谱表达能力的根本权衡，需在设计结构保持型架构时谨慎平衡。

Abstract: Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.

</details>


### [447] [A Differentiable Adversarial Framework for Task-Aware Data Subsampling](https://arxiv.org/abs/2601.02081)
*Jiacheng Lyu,Bihua Bao*

Main category: cs.LG

TL;DR: 本文提出了一种名为对抗性软选择子采样（ASSS）的新框架，将数据缩减重构为可微分的端到端学习问题，通过选择器网络与任务网络之间的对抗博弈，动态地为样本分配重要性权重，在保持预测保真度的同时实现稀疏性；理论分析将其与信息瓶颈原理关联，实验表明其在多个大规模数据集上优于传统启发式子采样方法，甚至有时超越全量数据训练效果。


<details>
  <summary>Details</summary>
Motivation: 大规模数据集带来计算挑战，而传统静态、任务无关的子采样方法易丢弃对下游任务关键的信息。

Method: 提出对抗性软选择子采样（ASSS）框架，构建选择器网络与任务网络的对抗博弈，利用Gumbel-Softmax松弛实现端到端可微优化，使选择器根据任务目标损失函数（兼顾保真度与稀疏性）动态学习样本重要性权重。

Result: 在四个大规模真实数据集上，ASSS持续优于聚类、近邻稀疏等启发式子采样基线；不仅能匹配全量数据训练性能，有时甚至超越，体现智能去噪效果。

Conclusion: ASSS将任务感知的数据子采样建模为可学习组件，为大规模数据高效学习提供了基于原理的解决方案。

Abstract: The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces the antagonistic soft selection subsampling (ASSS) framework as is a novel paradigm that reconstructs data reduction into a differentiable end-to-end learning problem. ASSS uses the adversarial game between selector network and task network, and selector network learning assigns continuous importance weights to samples. This direct optimization implemented by Gumbel-Softmax relaxation allows the selector to identify and retain samples with the maximum amount of information for a specific task target under the guidance of the loss function that balances the fidelity and sparsity of the prediction. Theoretical analysis links this framework with the information bottleneck principle. Comprehensive experiments on four large-scale real world datasets show that ASSS has always been better than heuristic subsampling baselines such as clustering and nearest neighbor thinning in maintaining model performance. It is worth noting that ASSS can not only match, but also sometimes exceed the training performance of the entire dataset, showcasing the effect of intelligent denoising. This work establishes task aware data subsampling as a learnable component, providing a principled solution for effective large-scale data learning.

</details>


### [448] [Horizon Activation Mapping for Neural Networks in Time Series Forecasting](https://arxiv.org/abs/2601.02094)
*Hans Krupakar,V A Kandappan*

Main category: cs.LG

TL;DR: 本文提出了一种名为Horizon Activation Mapping（HAM）的通用可视化可解释性技术，用于跨不同架构的时间序列预测模型进行解释与比较，通过梯度范数平均分析预测区间子序列的重要性，并验证其在多种SOTA模型上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测模型的可解释性和模型选择方法依赖于特定误差指标或架构相关的解释方式，缺乏跨模型家族的通用性。

Method: 提出Horizon Activation Mapping（HAM），受grad-CAM启发，利用梯度范数平均来分析预测区间内各子序列的贡献；引入因果/反因果模式，并结合比例线分析范数分布；在多种超参设置和模型上开展优化景观研究。

Result: HAM揭示了不同模型（如N-HiTS、SpaceTime等）训练过程中的特有模式（如神经逼近定理体现、指数自回归活动），并发现batch size差异可能隐含指数级近似关系；适用于细粒度模型选择、验证集构建及跨家族模型比较。

Conclusion: HAM是一种模型无关、可泛化的时间序列预测可解释性工具，支持统一评估与诊断多种前沿神经网络模型。

Abstract: Neural networks for time series forecasting have relied on error metrics and architecture-specific interpretability approaches for model selection that don't apply across models of different families. To interpret forecasting models agnostic to the types of layers across state-of-the-art model families, we introduce Horizon Activation Mapping (HAM), a visual interpretability technique inspired by grad-CAM that uses gradient norm averages to study the horizon's subseries where grad-CAM studies attention maps over image data. We introduce causal and anti-causal modes to calculate gradient update norm averages across subseries at every timestep and lines of proportionality signifying uniform distributions of the norm averages. Optimization landscape studies with respect to changes in batch sizes, early stopping, train-val-test splits, univariate forecasting and dropouts are studied with respect to performances and subseries in HAM. Interestingly, batch size based differences in activities seem to indicate potential for existence of an exponential approximation across them per epoch relative to each other. Multivariate forecasting models including MLP-based CycleNet, N-Linear, N-HITS, self attention-based FEDformer, Pyraformer, SSM-based SpaceTime and diffusion-based Multi-Resolution DDPM over different horizon sizes trained over the ETTm2 dataset are used for HAM plots in this study. NHITS' neural approximation theorem and SpaceTime's exponential autoregressive activities have been attributed to trends in HAM plots over their training, validation and test sets. In general, HAM can be used for granular model selection, validation set choices and comparisons across different neural network model families.

</details>


### [449] [LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training](https://arxiv.org/abs/2601.02105)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: 本文提出LION-DG初始化方法，通过零初始化辅助分类头、He初始化主干网络，实现梯度觉醒（Gradient Awakening），在深度监督架构中提升训练稳定性与收敛速度，无需调参且无计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有权重初始化方法多为层无关，难以应对深度监督架构中未训练辅助分类器引发的梯度干扰问题，导致早期训练不稳定。

Method: 提出LION-DG：对辅助分类头零初始化，主干网络采用He初始化；理论证明该策略使辅助梯度在初始时刻严格为零，并随权重增长自然激活，实现隐式warmup。

Result: 在CIFAR-10/100上验证：DenseNet-DS收敛加速8.3%；LION-DG+LSUV达81.92%最高准确率；ResNet-DS侧接辅助设计在CIFAR-100提速11.3%。

Conclusion: LION-DG是一种简单、无超参、零开销的有效初始化策略，适用于深度监督网络，并提供实用架构选择指南。

Abstract: Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.
  We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.
  Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.
  We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.

</details>


### [450] [Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI](https://arxiv.org/abs/2601.02106)
*Ashish Rana,Ammar Shaker,Sascha Saralajew,Takashi Suzuki,Kosuke Yasuda,Shintaro Kato,Toshikazu Wada,Toshiyuki Fujikawa,Toru Kikutsuji*

Main category: cs.LG

TL;DR: 本文提出ProtoPal框架，利用原型学习实现个性化预防性医疗的可解释与可验证预测及干预。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习与可解释AI在个性化预防医疗中仍存在预测、干预和推荐对医疗各利益相关方不够可理解与可验证的问题。

Method: 提出一种基于原型学习的框架ProtoPal，包含前端与后端两种模式。

Result: ProtoPal在定量性能上表现优越，同时能直观呈现干预措施及其模拟结果。

Conclusion: Prototype-based learning（原型学习）可有效满足个性化预防医疗中可解释性与可验证性的双重需求。

Abstract: Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.

</details>


### [451] [Edge-aware GAT-based protein binding site prediction](https://arxiv.org/abs/2601.02138)
*Weisen Yang,Hanqing Zhang,Wangren Qiu,Xuan Xiao,Weizhong Lin*

Main category: cs.LG

TL;DR: 本文提出了一种边缘感知图注意力网络（Edge-aware GAT）模型，用于在原子级别精细预测多种生物分子（如蛋白质、DNA/RNA、离子、配体和脂质）的结合位点，通过融合几何、二级结构和溶剂可及性等多维特征，并引入距离与方向性边特征提升表征能力，在蛋白-蛋白结合位点预测上达到0.93 ROC-AUC，优于现有方法，并提供公开Web服务器。


<details>
  <summary>Details</summary>
Motivation: 传统方法在捕获复杂空间构象时难以兼顾预测精度与计算效率，亟需一种高精度、高效且可解释的结合位点预测方法。

Method: 构建原子级图，融合几何描述符、DSSP二级结构和相对溶剂可及性（RSA）等多维结构特征；在图注意力机制中引入原子间距离和方向向量作为边特征；采用方向张量传播与残基级注意力池化提升局部结构建模与定位能力。

Result: 在基准数据集上蛋白-蛋白结合位点预测ROC-AUC达0.93，优于多种SOTA方法；PyMOL可视化验证了模型的实用性与可解释性；已部署公开Web服务器供社区使用。

Conclusion: Edge-aware GAT为蛋白功能位点识别提供了一种新颖、高效、泛化性强且可解释的解决方案，兼顾精度、效率与生物学意义。

Abstract: Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins.

</details>


### [452] [Learning with Monotone Adversarial Corruptions](https://arxiv.org/abs/2601.02193)
*Kasper Green Larsen,Chirag Pabbaraju,Abhishek Shetty*

Main category: cs.LG

TL;DR: 本文研究了标准机器学习算法对数据交换性和独立性的依赖程度，提出了一种单调对抗性污染模型；结果表明，已知的最优二分类学习算法在此模型下会因单调污染而表现次优，而基于一致收敛的算法则保持稳健。


<details>
  <summary>Details</summary>
Motivation: 探究标准机器学习算法（尤其是最优学习算法）对数据交换性与独立性假设的隐式依赖，揭示其在看似无害甚至‘有益’的单调污染下的脆弱性。

Method: 引入单调对抗性污染模型：对手在观察到干净i.i.d.数据集后，可任意添加满足‘按真实标签标注’这一单调性约束的污染点；理论分析不同学习范式（如最优风险最小化 vs. 一致收敛型算法）在该模型下的泛化误差变化。

Result: 所有已知的最优二分类学习算法在此单调污染下，对新独立测试样本的期望误差会退化至次优；而基于一致收敛的算法其理论保证不下降。

Conclusion: 最优学习算法的性能高度依赖数据交换性，即使面对符合真实标签规律的单调污染也会失效；一致收敛提供更鲁棒的理论基础，提示应重新审视‘最优性’背后的假设前提。

Abstract: We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a "clean" i.i.d. dataset, inserts additional "corrupted" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.

</details>


### [453] [ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense](https://arxiv.org/abs/2601.02196)
*Yu Li,Sizhe Tang,Rongqian Chen,Fei Xu Yu,Guangyu Jiang,Mahdi Imani,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: 本文提出了一种基于蒙特卡洛树搜索（MCTS）与图神经网络（GNN）的样本高效、规划驱动的自动化网络防御策略，用于解决CAGE-4挑战中的部分可观测马尔可夫决策问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法在复杂网络中面临探索困难、样本需求高问题，亟需更样本高效的防御策略。

Method: 将ACD建模为上下文相关的部分可观测MDP；采用MCTS进行规划，结合GNN对网络观测（属性图）进行置换不变嵌入，并利用学习到的图嵌入和图编辑动作先验引导MCTS搜索。

Result: 在CAGE-4多场景评估中，该方法相比SOTA RL基线显著提升了防御奖励与鲁棒性。

Conclusion: 融合模型无关泛化、策略蒸馏与前向规划的图增强MCTS框架，是提升自动化网络防御样本效率与适应性的有效路径。

Abstract: Automated cyber defense (ACD) seeks to protect computer networks with minimal or no human intervention, reacting to intrusions by taking corrective actions such as isolating hosts, resetting services, deploying decoys, or updating access controls. However, existing approaches for ACD, such as deep reinforcement learning (RL), often face difficult exploration in complex networks with large decision/state spaces and thus require an expensive amount of samples. Inspired by the need to learn sample-efficient defense policies, we frame ACD in CAGE Challenge 4 (CAGE-4 / CC4) as a context-based partially observable Markov decision problem and propose a planning-centric defense policy based on Monte Carlo Tree Search (MCTS). It explicitly models the exploration-exploitation tradeoff in ACD and uses statistical sampling to guide exploration and decision making. We make novel use of graph neural networks (GNNs) to embed observations from the network as attributed graphs, to enable permutation-invariant reasoning over hosts and their relationships. To make our solution practical in complex search spaces, we guide MCTS with learned graph embeddings and priors over graph-edit actions, combining model-free generalization and policy distillation with look-ahead planning. We evaluate the resulting agent on CC4 scenarios involving diverse network structures and adversary behaviors, and show that our search-guided, graph-embedding-based planning improves defense reward and robustness relative to state-of-the-art RL baselines.

</details>


### [454] [CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents](https://arxiv.org/abs/2601.02201)
*Keyu Wang,Bingchen Miao,Wendong Bu,Yu Wu,Juncheng Li,Shengyu Zhang,Wenqiao Zhang,Siliang Tang,Jun Xiao,Yueting Zhuang*

Main category: cs.LG

TL;DR: 本文提出CORE框架，通过语义代码抽象自动推导奖励函数，结合策略图扩展和轨迹引导外推，融合行为克隆与强化学习优势，在不依赖人工设计奖励的前提下提升虚拟代理的行为多样性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 主流训练范式存在矛盾：行为克隆缺乏多样性，强化学习依赖人工设计奖励函数。

Method: 提出基于代码的逆向自训练框架CORE，包含语义代码抽象（自动从专家示范中推导可执行的标签函数作为奖励）、策略图扩展（构建多路径策略图以增强领域内行为多样性）和轨迹引导外推（利用成功与失败轨迹拓展任务空间以提升领域外多样性）。

Result: 在Web和Android平台实验表明，CORE显著提升了整体性能与泛化能力。

Conclusion: CORE是一种鲁棒且通用的虚拟代理训练范式，有效弥合了模仿学习与探索学习之间的鸿沟。

Abstract: The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.

</details>


### [455] [Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.02213)
*Haoyu Zhou,Ping Xue,Tianfan Fu,Hao Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种针对SO(3)-等变图神经网络的低比特量化压缩方法，通过解耦模长-方向量化、分支分离量化感知训练和鲁棒注意力归一化三项创新，在QM9和rMD17分子数据集上实现了8比特模型精度媲美全精度基线，同时提升推理速度2.37–2.73倍、减小模型体积4倍，且保持物理对称性。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备部署SO(3)-等变3D图神经网络面临高计算开销的挑战，亟需高效压缩与加速方案。

Method: 提出三种面向量化等变Transformer的创新技术：(1) 模长-方向解耦量化；(2) 分支分离的量化感知训练（区分不变与等变特征通道）；(3) 增强鲁棒性的注意力归一化机制。

Result: 在QM9和rMD17上，8比特模型能量与力预测精度媲美全精度基线；推理加速2.37–2.73倍，模型体积缩小4倍；LEE指标验证了量化下等变性与精度的良好保持。

Conclusion: 所提量化技术可在不牺牲精度和物理对称性的前提下，有效支持对称感知GNN在实际化学应用中的边缘部署。

Abstract: Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Specifically, we introduce three innovations for quantized equivariant transformers: (1) a magnitude-direction decoupled quantization scheme that separately quantizes the norm and orientation of equivariant (vector) features, (2) a branch-separated quantization-aware training strategy that treats invariant and equivariant feature channels differently in an attention-based $SO(3)$-GNN, and (3) a robustness-enhancing attention normalization mechanism that stabilizes low-precision attention computations. Experiments on the QM9 and rMD17 molecular benchmarks demonstrate that our 8-bit models achieve accuracy on energy and force predictions comparable to full-precision baselines with markedly improved efficiency. We also conduct ablation studies to quantify the contribution of each component to maintain accuracy and equivariance under quantization, using the Local error of equivariance (LEE) metric. The proposed techniques enable the deployment of symmetry-aware GNNs in practical chemistry applications with 2.37--2.73x faster inference and 4x smaller model size, without sacrificing accuracy or physical symmetry.

</details>


### [456] [ELLA: Efficient Lifelong Learning for Adapters in Large Language Models](https://arxiv.org/abs/2601.02232)
*Shristi Das Biswas,Yue Zhang,Anwesan Pal,Radhika Bhargava,Kaushik Roy*

Main category: cs.LG

TL;DR: 本文提出ELLA框架，通过选择性子空间去相关化解决大语言模型在持续学习中的灾难性遗忘问题，无需数据回放、架构扩展，且内存和计算开销恒定，显著提升准确率并增强零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法存在严重缺陷：基于回放的方法不实用且侵犯隐私；基于严格正交性的方法随任务增加导致自由度耗尽，阻碍前向迁移。

Method: 提出ELLA框架，基于选择性子空间去相关化原理，利用轻量级正则项作用于聚合更新矩阵，实现各向异性收缩，抑制高能量任务方向的干扰，保留低能量残差子空间以支持迁移。

Result: 在三个主流基准上达到持续学习SOTA性能，相对准确率提升最高达9.6%，内存占用减少35倍，并提升模型在未见任务上的零样本泛化能力。

Conclusion: ELLA是一种原理清晰、可扩展的大语言模型终生适应方案，兼顾抗干扰性、迁移能力和资源效率。

Abstract: Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\%$ and a $35\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.

</details>


### [457] [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](https://arxiv.org/abs/2601.02253)
*Emrah Mete,Emin Erkan Korkmaz*

Main category: cs.LG

TL;DR: 本文提出了一种无需乘法运算的神经网络架构——Neuro-Channel Networks（NCN），受生物突触信号传递机制启发，用通道宽度和神经递质类参数替代传统权重，仅依赖加减与位操作，可在CPU或超低功耗芯片上高效运行。


<details>
  <summary>Details</summary>
Motivation: 深度学习严重依赖昂贵、高能耗且供应紧张的GPU，其核心瓶颈在于传统人工神经元对密集矩阵乘法的依赖；而生物神经系统通过离子通道与神经递质实现高效信号传递，无需算术乘法。

Method: 提出Neuro-Channel Networks（NCN）：用'通道宽度'（Channel Widths）替代权重以物理限制信号幅值，用'神经递质'（Neurotransmitter）参数基于符号逻辑调控信号传输；前向传播仅使用加法、减法及位操作（如min、sign），完全消除浮点乘法；仍采用标准反向传播进行训练。

Result: 在XOR和多数函数（Majority function）等非线性可分任务上达到100%准确率，验证了NCN无需乘法即可构建复杂决策边界的能力。

Conclusion: NCN为AI硬件解耦提供了新范式，有望推动AI在通用CPU及超低功耗芯片上的部署，是面向下一代类脑硬件的高效替代方案。

Abstract: The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

</details>


### [458] [POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network](https://arxiv.org/abs/2601.02264)
*Boris Kriuk,Fedor Kriuk*

Main category: cs.LG

TL;DR: POSEIDON是一种融合物理规律的地震预测能量模型，统一处理余震识别、海啸潜力评估与前震检测任务，并配套发布包含280万事件的全球开放地震数据集。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法多为黑箱，忽视物理规律；需提升地震预测的可解释性与科学可信度。

Method: 提出物理信息驱动的能量模型POSEIDON，将Gutenberg-Richter关系和Omori-Utsu定律作为可学习约束嵌入模型；构建大规模Poseidon地震数据集（2.8百万事件，30年跨度）。

Result: 在三类地震预测任务上均达SOTA，F1平均分最高；学习到的物理参数（b=0.752, p=0.835, c=0.1948）符合地学共识且提升预测精度。

Conclusion: 物理约束可增强而非削弱机器学习模型性能，POSEIDON实现了高精度与高可解释性的统一，推动可信赖地震智能预测发展。

Abstract: Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.

</details>


### [459] [Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck](https://arxiv.org/abs/2601.02307)
*Dina El Zein,James Henderson*

Main category: cs.LG

TL;DR: 本文提出了一种名为非参数变分差分隐私（NVDP）的方法，通过向Transformer嵌入添加噪声来实现文本数据的隐私保护共享，并在GLUE基准上验证了其在隐私与准确率之间的有效权衡。


<details>
  <summary>Details</summary>
Motivation: 深层模型的隐藏表示可能编码输入中的敏感信息，使攻击者能以较高精度恢复原始数据；而Transformer嵌入由多个token向量组成，进一步加剧了隐私泄露风险。

Method: 提出非参数变分差分隐私（NVDP），将非参数变分信息瓶颈（NVIB）层嵌入Transformer架构中，利用Rényi散度和贝叶斯差分隐私（BDP）保障衡量隐私，通过训练NVIB层根据效用自适应校准噪声水平。

Result: 在GLUE基准测试中，NVDP展现出噪声水平与模型准确率之间的有效权衡：较低噪声下仍保持高准确率，同时提供强隐私保障。

Conclusion: NVDP成功实现了隐私保护与数据效用的平衡，为共享Transformer嵌入提供了兼具理论保证与实用性的新范式。

Abstract: We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.

</details>


### [460] [Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310)
*Ahmad Makinde*

Main category: cs.LG

TL;DR: 本文提出了一种新的时序Kolmogorov-Arnold网络（T-KAN），用于高频交易中的限价订单簿预测，通过可学习B样条激活函数替代LSTM的固定线性权重，提升了模型在长时域（k=100）下的F1分数（提升19.1%）和实盘收益（132.48% vs -82.76%），并具备可解释性和FPGA低延迟部署优势。


<details>
  <summary>Details</summary>
Motivation: 高频交易中限价订单簿数据噪声大、非线性强，且传统模型（如DeepLOB）存在显著的alpha衰减问题，尤其在较长预测时域下性能下降严重。

Method: 提出Temporal Kolmogorov-Arnold Networks（T-KAN），将标准LSTM中的固定线性权重替换为可学习的B样条激活函数，使模型能学习市场信号的‘形状’而非仅其幅度；基于FI-2010数据集进行训练与评估，并支持FPGA上的高层次综合（HLS）低延迟部署。

Result: 在k=100预测时域下F1-score相对提升19.1%；在1.0 bps交易成本下实现132.48%收益，显著优于DeepLOB的-82.76%回撤；模型具有可解释性（如‘死区’在样条中清晰可见）；且适配FPGA低延迟实现。

Conclusion: T-KAN是一种更鲁棒、可解释、可部署的新型时序建模架构，在高频订单簿预测任务中显著优于现有方法，为解决alpha衰减和工程落地难题提供了新思路。

Abstract: High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.

</details>


### [461] [Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning](https://arxiv.org/abs/2601.02313)
*Hanzaleh Akbari Nodehi,Viveck R. Cadambe,Mohammad Ali Maddah-Ali*

Main category: cs.LG

TL;DR: 本文提出了一种面向理性对手的新型编码理论框架——'编码博弈'，扩展了传统编码理论以适应去中心化机器学习等场景中诚实节点不占多数的信任最小化环境，实现了多数敌手下的部分数据恢复与Sybil攻击抵抗。


<details>
  <summary>Details</summary>
Motivation: 在去中心化机器学习等新兴应用中，节点受激励机制驱动，更倾向于策略性（理性）而非纯粹恶意行为，而传统编码理论基于最坏情况对抗模型且要求诚实节点占多数，难以适用。

Method: 提出'编码博弈'这一博弈论框架，以重复编码为具体实例，建模理性对手与诚实节点间的策略互动，并分析其均衡性质与恢复概率。

Result: 证明在敌手占多数时仍可实现非零数据恢复概率，并具备Sybil抵抗性（均衡不受敌手数量增加影响）。

Conclusion: 编码理论需适配理性对手模型；'编码博弈'为信任最小化分布式系统提供了新范式，同时引出若干开放问题。

Abstract: Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.
  In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.

</details>


### [462] [DatBench: Discriminative, Faithful, and Efficient VLM Evaluations](https://arxiv.org/abs/2601.02316)
*Siddharth Joshi,Haoli Yin,Rishabh Adiga,Ricardo Monti,Aldo Carranza,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Kaleigh Mentzer,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Scott Loftin,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 本文提出评估视觉-语言模型（VLMs）的三大准则：保真性、可区分性和计算高效性；揭示现有评估中的关键缺陷，并通过数据清洗与任务重构构建更可靠高效的基准套件DatBench。


<details>
  <summary>Details</summary>
Motivation: 现有VLM评估方法存在保真性差、区分能力弱和计算成本高等问题，难以准确反映模型真实能力，亟需系统性改进。

Method: 提出三项评估准则；识别并分析三类典型失败模式（多选题格式缺陷、盲解问题、标注错误）；对现有基准进行转换（如多选→生成式）和过滤（剔除盲解与误标样本）；构建两个新基准：DatBench-Full（全量清洗版）和DatBench（高区分性子集）。

Result: 转换为生成式任务使模型性能下降最高达35%；过滤盲解与误标样本提升了区分能力并降低计算开销；DatBench在保持判别力的同时实现平均13倍、最高50倍的加速。

Conclusion: 评估应兼顾严谨性与可持续性；通过数据驱动的基准优化，可显著提升VLM评估的可靠性与效率，为未来大规模模型发展提供坚实基础。

Abstract: Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.

</details>


### [463] [Heterogeneous Low-Bandwidth Pre-Training of LLMs](https://arxiv.org/abs/2601.02360)
*Yazan Obeidi,Amir Sarfi,Joel Lidin,Paul Janson,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 本文提出SparseLoCo与低带宽流水线模型并行结合的异构分布式训练框架，通过稀疏伪梯度交换、激活/梯度压缩及子空间投影通信，在保持性能的同时显著降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 大语言模型预训练对分布式计算需求日益增长，但带宽限制阻碍了在非高配数据中心（尤其是存在模型并行频繁大通信场景）的扩展。

Method: 将SparseLoCo（基于低频同步和稀疏伪梯度交换的数据并行方法）与低带宽流水线模型并行（结合激活和梯度压缩）相结合；设计异构训练框架，支持高带宽节点运行完整副本、低资源节点协作运行流水线副本，并适配子空间流水线压缩以兼容SparseLoCo。

Result: 在178M–1B参数规模的语言建模实验中，激活压缩与SparseLoCo组合仅带来适度性能损失；选择性（异构）压缩相比全副本压缩在损失-通信权衡上更优，尤其在高压缩比下。

Conclusion: 该方法为在LLM预训练中融合低带宽模型并行与异构参与设备提供了可行路径。

Abstract: Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [464] [Value Vision-Language-Action Planning & Search](https://arxiv.org/abs/2601.00969)
*Ali Salamatian,Ke,Ren,Kieran Pattison,Cyrus Neary*

Main category: cs.RO

TL;DR: 本文提出V-VLAPS框架，在MCTS中引入轻量级可学习价值函数，以增强Vision-Language-Action模型在机器人操作任务中的泛化性与规划效率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖行为克隆，面对分布偏移时鲁棒性差；虽可用MCTS等搜索算法缓解，但缺乏对期望未来回报的具身估计，仅靠探索项修正需大量模拟。

Method: 在固定VLA骨干网络（Octo）的潜在表征上训练一个简单MLP作为可学习价值函数，将其融入MCTS，为动作选择提供显式成功信号引导。

Result: 在LIBERO机器人操作基准上，V-VLAPS相比仅依赖VLA先验的基线，成功率提升超5个百分点，同时MCTS平均模拟次数减少5–15%。

Conclusion: 引入轻量价值函数可有效提升VLA模型在测试时搜索的准确性和效率，为通用机器人策略提供更鲁棒、更高效的规划机制。

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.

</details>


### [465] [From Perception to Symbolic Task Planning: Vision-Language Guided Human-Robot Collaborative Structured Assembly](https://arxiv.org/abs/2601.00978)
*Yanyi Chen,Min Deng*

Main category: cs.RO

TL;DR: 本文提出了一种面向结构化装配的人机协同规划框架，包含基于视觉语言模型的感知-符号状态映射（PSS）模块和人机感知的规划与重规划（HPR）模块，显著提升了动态环境下状态估计与任务规划的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 结构化装配中的人机协作面临感知噪声和人为干预导致的状态估计不可靠与任务规划不自适应的问题。

Method: 设计了两个耦合模块：模块I（PSS）利用视觉语言模型（VLM）代理将RGB-D观测与设计规范及领域知识对齐，生成可验证的符号化装配状态；模块II（HPR）执行任务级多机器人分配，并仅在观测状态偏离预期时触发基于最小变更原则的重规划。

Result: 在27构件木结构装配任务中，PSS模块状态合成准确率达97%，HPR模块在多种人机协作场景下均保持可行的任务推进能力。

Conclusion: 将VLM驱动的感知与知识驱动的规划相结合，可有效提升动态人机协作场景下状态估计与任务规划的鲁棒性与稳定性。

Abstract: Human-robot collaboration (HRC) in structured assembly requires reliable state estimation and adaptive task planning under noisy perception and human interventions. To address these challenges, we introduce a design-grounded human-aware planning framework for human-robot collaborative structured assembly. The framework comprises two coupled modules. Module I, Perception-to-Symbolic State (PSS), employs vision-language models (VLMs) based agents to align RGB-D observations with design specifications and domain knowledge, synthesizing verifiable symbolic assembly states. It outputs validated installed and uninstalled component sets for online state tracking. Module II, Human-Aware Planning and Replanning (HPR), performs task-level multi-robot assignment and updates the plan only when the observed state deviates from the expected execution outcome. It applies a minimal-change replanning rule to selectively revise task assignments and preserve plan stability even under human interventions. We validate the framework on a 27-component timber-frame assembly. The PSS module achieves 97% state synthesis accuracy, and the HPR module maintains feasible task progression across diverse HRC scenarios. Results indicate that integrating VLM-based perception with knowledge-driven planning improves robustness of state estimation and task planning under dynamic conditions.

</details>


### [466] [Simulations of MRI Guided and Powered Ferric Applicators for Tetherless Delivery of Therapeutic Interventions](https://arxiv.org/abs/2601.00981)
*Wenhui Chu,Khang Tran,Nikolaos V. Tsekos*

Main category: cs.RO

TL;DR: 本文提出了一种用于MRI驱动血管内介入器械术前规划与建模的计算平台，通过构建虚拟通道（VF）避免血管穿孔，并结合MRI梯度约束与血流模型生成安全可控的磁场波形。


<details>
  <summary>Details</summary>
Motivation: 为支持MRI引导下机器人辅助血管介入手术的安全性和可行性，需在术前对MRI驱动的铁磁器械在血管内的运动进行精确建模与路径规划，防止血管损伤并满足MRI硬件安全限制。

Method: 构建双向数据与命令管道连接MRI扫描仪、计算核心与操作员；基于多层MR图像提取血管结构并拟合虚拟通道（VF）作为禁区；结合血管中心线几何特征、VF及MRI梯度安全约束（dB/dt、最大梯度）生成磁场梯度波形；集成可选血流模型进行器械运动仿真与安全性评估；平台采用Qt框架（C/C++）多线程实现，含PID控制器、VF生成、梯度波形生成等模块。

Result: 实现了支持术前规划与实时仿真的计算平台，能自动生成符合MRI安全约束的梯度波形，并提供所选血管路径是否可安全操控的评估提示。

Conclusion: 该平台为MRI驱动血管介入器械提供了系统化的术前建模与规划工具，提升了手术安全性与可行性，为后续实时实验研究奠定了软件基础。

Abstract: Magnetic Resonance Imaging (MRI) is a well-established modality for pre-operative planning and is also explored for intra-operative guidance of procedures such as intravascular interventions. Among the experimental robot-assisted technologies, the magnetic field gradients of the MRI scanner are used to power and maneuver ferromagnetic applicators for accessing sites in the patient's body via the vascular network. In this work, we propose a computational platform for preoperative planning and modeling of MRI-powered applicators inside blood vessels. This platform was implemented as a two-way data and command pipeline that links the MRI scanner, the computational core, and the operator. The platform first processes multi-slice MR data to extract the vascular bed and then fits a virtual corridor inside the vessel. This corridor serves as a virtual fixture (VF), a forbidden region for the applicators to avoid vessel perforation or collision. The geometric features of the vessel centerline, the VF, and MRI safety compliance (dB/dt, max available gradient) are then used to generate magnetic field gradient waveforms. Different blood flow profiles can be user-selected, and those parameters are used for modeling the applicator's maneuvering. The modeling module further generates cues about whether the selected vascular path can be safely maneuvered. Given future experimental studies that require a real-time operation, the platform was implemented on the Qt framework (C/C++) with software modules performing specific tasks running on dedicated threads: PID controller, generation of VF, generation of MR gradient waveforms.

</details>


### [467] [Topological Mapping and Navigation using a Monocular Camera based on AnyLoc](https://arxiv.org/abs/2601.01067)
*Wenzheng Zhang,Yoshitaka Hara,Sousuke Nakamura*

Main category: cs.RO

TL;DR: 本文提出了一种基于单目相机的轻量级拓扑建图与导航方法，利用AnyLoc提取关键帧描述符构建拓扑图，实现无需预训练的高效回环检测与视觉导航，较ResNet方法平均成功率提升60.2%，且计算与存储开销更低。


<details>
  <summary>Details</summary>
Motivation: 传统度量地图依赖精确坐标，计算复杂、建图慢；而拓扑地图以关键节点表征环境，更适于简化路径规划与实时导航，尤其适合资源受限的机器人和人类导航场景。

Method: 基于AnyLoc模型将单目相机采集的关键帧编码为描述符，构建拓扑图以支持回环检测与建图；导航时通过比对当前分割图像与目标节点关联图像来决定动作，全程仅依赖单目视觉输入。

Result: 在真实与仿真环境中均实现了有效的回环检测与导航，无需任何预训练；相比ResNet基线方法，平均导航成功率提升60.2%，同时显著降低时间与空间开销。

Conclusion: 该方法是一种高效、轻量、即插即用的单目拓扑建图与导航方案，适用于多样化实际场景下的机器人及人类辅助导航任务。

Abstract: This paper proposes a method for topological mapping and navigation using a monocular camera. Based on AnyLoc, keyframes are converted into descriptors to construct topological relationships, enabling loop detection and map building. Unlike metric maps, topological maps simplify path planning and navigation by representing environments with key nodes instead of precise coordinates. Actions for visual navigation are determined by comparing segmented images with the image associated with target nodes. The system relies solely on a monocular camera, ensuring fast map building and navigation using key nodes. Experiments show effective loop detection and navigation in real and simulation environments without pre-training. Compared to a ResNet-based method, this approach improves success rates by 60.2% on average while reducing time and space costs, offering a lightweight solution for robot and human navigation in various scenarios.

</details>


### [468] [Latent Space Reinforcement Learning for Multi-Robot Exploration](https://arxiv.org/abs/2601.01139)
*Sriram Rajasekar,Ashwini Ratnoo*

Main category: cs.RO

TL;DR: 本文提出一种基于自编码器和分层深度强化学习的多智能体自主建图方法，通过降维处理高保真占据栅格地图，并结合Perlin噪声生成复杂环境进行训练，引入加权共识机制提升通信受限下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法受限于输入尺寸，难以应用于连续、高维的真实环境建图任务；多智能体系统面临运动规划算法可扩展性差的问题。

Method: 使用自编码器对高保真占用地图进行降维，提取保留空间信息的潜在状态向量；设计基于Perlin噪声的程序化环境生成算法，构建 asteroid fields、caves 和 forests 等拓扑复杂训练场景；采用分层深度强化学习框架实现去中心化协同导航；引入含可调信任参数的加权共识机制以抑制误差累积。

Result: 实验表明该系统能随智能体数量有效扩展，在未知且结构差异大的环境中具有良好泛化能力，并在通信受限条件下保持鲁棒性。

Conclusion: 本工作成功突破了强化学习在连续高维环境建图中的输入维度限制，提升了多智能体系统的可扩展性与鲁棒性，为真实场景下的自主探索提供了可行方案。

Abstract: Autonomous mapping of unknown environments is a critical challenge, particularly in scenarios where time is limited. Multi-agent systems can enhance efficiency through collaboration, but the scalability of motion-planning algorithms remains a key limitation. Reinforcement learning has been explored as a solution, but existing approaches are constrained by the limited input size required for effective learning, restricting their applicability to discrete environments. This work addresses that limitation by leveraging autoencoders to perform dimensionality reduction, compressing high-fidelity occupancy maps into latent state vectors while preserving essential spatial information. Additionally, we introduce a novel procedural generation algorithm based on Perlin noise, designed to generate topologically complex training environments that simulate asteroid fields, caves and forests. These environments are used for training the autoencoder and the navigation algorithm using a hierarchical deep reinforcement learning framework for decentralized coordination. We introduce a weighted consensus mechanism that modulates reliance on shared data via a tuneable trust parameter, ensuring robustness to accumulation of errors. Experimental results demonstrate that the proposed system scales effectively with number of agents and generalizes well to unfamiliar, structurally distinct environments and is resilient in communication-constrained settings.

</details>


### [469] [Towards reliable subsea object recovery: a simulation study of an auv with a suction-actuated end effector](https://arxiv.org/abs/2601.01106)
*Michele Grimaldi,Yosaku Maeda,Hitoshi Kakami,Ignacio Carlucho,Yvan Petillot,Tomoya Inoue*

Main category: cs.RO

TL;DR: 本文提出了一种基于Stonefish仿真器的全自主深海（超深渊带）物体回收任务仿真方法，使用配备三自由度机械臂和吸力末端执行器的Hadal小型载具（HSV），验证了在6000米深度下从下潜、探测到吸力回收全过程的可行性。


<details>
  <summary>Details</summary>
Motivation: 超深渊带自主物体回收面临极端静水压力、能见度低、洋流干扰及全海深精准操作等挑战；实地试验成本高、风险大、平台受限，亟需低成本、低风险的早期自主行为验证手段。

Method: 采用Stonefish高保真仿真器建模HSV动力学、水动力扰动、传感及与目标物交互；控制框架融合世界坐标系PID导航/稳定控制器与带加速度前馈的逆运动学机械臂控制器，实现载体-机械臂协同控制。

Result: 仿真中HSV成功完成从海面至6000米下潜、结构化海底覆盖扫描、目标检测及吸力回收全流程；验证了该仿真方法对评估深海自主干预行为的有效性与低风险性。

Conclusion: 高保真仿真可作为深海自主干预系统研发中可靠、经济且安全的前期验证工具，显著降低实海试验门槛与风险。

Abstract: Autonomous object recovery in the hadal zone is challenging due to extreme hydrostatic pressure, limited visibility and currents, and the need for precise manipulation at full ocean depth. Field experimentation in such environments is costly, high-risk, and constrained by limited vehicle availability, making early validation of autonomous behaviors difficult. This paper presents a simulation-based study of a complete autonomous subsea object recovery mission using a Hadal Small Vehicle (HSV) equipped with a three-degree-of-freedom robotic arm and a suction-actuated end effector. The Stonefish simulator is used to model realistic vehicle dynamics, hydrodynamic disturbances, sensing, and interaction with a target object under hadal-like conditions. The control framework combines a world-frame PID controller for vehicle navigation and stabilization with an inverse-kinematics-based manipulator controller augmented by acceleration feed-forward, enabling coordinated vehicle - manipulator operation. In simulation, the HSV autonomously descends from the sea surface to 6,000 m, performs structured seafloor coverage, detects a target object, and executes a suction-based recovery. The results demonstrate that high-fidelity simulation provides an effective and low-risk means of evaluating autonomous deep-sea intervention behaviors prior to field deployment.

</details>


### [470] [VISO: Robust Underwater Visual-Inertial-Sonar SLAM with Photometric Rendering for Dense 3D Reconstruction](https://arxiv.org/abs/2601.01144)
*Shu Pan,Simon Archieri,Ahmet Cinar,Jonatan Scharff Willners,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: 本文提出了VISO，一种融合立体相机、IMU和3D声呐的鲁棒水下SLAM系统，通过粗到细在线标定和光度渲染策略，实现了高精度6自由度定位与高保真稠密三维重建。


<details>
  <summary>Details</summary>
Motivation: 水下环境中的视觉挑战严重阻碍了基于视觉的定位精度和高保真稠密重建效果。

Method: 提出VISO系统，融合立体相机、IMU和3D声呐；设计粗到细在线标定方法估计3D声呐与相机外参；提出针对3D声呐点云的光度渲染策略以增强声呐地图的视觉信息。

Result: 在实验室水池和开放湖泊实验中，VISO在定位鲁棒性和精度上超越当前水下及视觉SLAM最先进方法，并实现接近离线稠密建图效果的实时稠密三维重建性能。

Conclusion: VISO有效提升了水下SLAM系统的定位精度与稠密重建质量，为复杂水下环境中的自主导航与建图提供了可靠解决方案。

Abstract: Visual challenges in underwater environments significantly hinder the accuracy of vision-based localisation and the high-fidelity dense reconstruction. In this paper, we propose VISO, a robust underwater SLAM system that fuses a stereo camera, an inertial measurement unit (IMU), and a 3D sonar to achieve accurate 6-DoF localisation and enable efficient dense 3D reconstruction with high photometric fidelity. We introduce a coarse-to-fine online calibration approach for extrinsic parameters estimation between the 3D sonar and the camera. Additionally, a photometric rendering strategy is proposed for the 3D sonar point cloud to enrich the sonar map with visual information. Extensive experiments in a laboratory tank and an open lake demonstrate that VISO surpasses current state-of-the-art underwater and visual-based SLAM algorithms in terms of localisation robustness and accuracy, while also exhibiting real-time dense 3D reconstruction performance comparable to the offline dense mapping method.

</details>


### [471] [ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi-Agent Online Navigation](https://arxiv.org/abs/2601.01155)
*Zhang Shizhe,Liang Jingsong,Zhou Zhitao,Ye Shuhan,Wang Yizhuo,Tan Ming Siang Derek,Chiun Jimmy,Cao Yuhong,Sartoretti Guillaume*

Main category: cs.RO

TL;DR: ORION is a deep reinforcement learning framework for cooperative multi-agent online navigation in partially known environments, enabling decentralized decision-making, adaptive coordination between navigation and exploration, and real-time cooperation validated in simulation and on physical robots.


<details>
  <summary>Details</summary>
Motivation: Existing multi-agent navigation methods assume fully known environments, limiting their applicability in real-world partially known settings like warehouses or factories, where agents must jointly navigate and reduce environmental uncertainty.

Method: ORION employs a shared graph encoder to fuse prior maps and online perception, an option-critic framework to learn high-level cooperative modes (e.g., individual navigation vs. team exploration), and a dual-stage cooperation strategy for assisting teammates under map uncertainty.

Result: ORION achieves superior performance over classical and learning-based baselines in maze-like and large-scale warehouse simulations across varying team sizes, and demonstrates robust real-world deployment on physical robot teams.

Conclusion: ORION enables effective, decentralized, real-time cooperative navigation in partially known environments by jointly optimizing path planning and active environmental mapping through learned cooperative behaviors.

Abstract: Existing methods for multi-agent navigation typically assume fully known environments, offering limited support for partially known scenarios such as warehouses or factory floors. There, agents may need to plan trajectories that balance their own path optimality with their ability to collect and share information about the environment that can help their teammates reach their own goals. To these ends, we propose ORION, a novel deep reinforcement learning framework for cooperative multi-agent online navigation in partially known environments. Starting from an imperfect prior map, ORION trains agents to make decentralized decisions, coordinate to reach their individual targets, and actively reduce map uncertainty by sharing online observations in a closed perception-action loop. We first design a shared graph encoder that fuses prior map with online perception into a unified representation, providing robust state embeddings under dynamic map discrepancies. At the core of ORION is an option-critic framework that learns to reason about a set of high-level cooperative modes that translate into sequences of low-level actions, allowing agents to switch between individual navigation and team-level exploration adaptively. We further introduce a dual-stage cooperation strategy that enables agents to assist teammates under map uncertainty, thereby reducing the overall makespan. Across extensive maze-like maps and large-scale warehouse environments, our simulation results show that ORION achieves high-quality, real-time decentralized cooperation over varying team sizes, outperforming state-of-the-art classical and learning-based baselines. Finally, we validate ORION on physical robot teams, demonstrating its robustness and practicality for real-world cooperative navigation.

</details>


### [472] [DST-Calib: A Dual-Path, Self-Supervised, Target-Free LiDAR-Camera Extrinsic Calibration Network](https://arxiv.org/abs/2601.01188)
*Zhiwei Huang,Yanwei Fu,Yi Zhou,Xieyuanli Chen,Qijun Chen,Rui Fan*

Main category: cs.RO

TL;DR: 本文提出了一种首个自监督、在线式LiDAR-相机外参标定网络，无需人工标定板或特定静态场景，通过双侧数据增强和差异图特征关联提升泛化性与精度。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机外参标定方法依赖手工标定目标（如棋盘格）或特定静态场景，难以适应真实机器人与自动驾驶环境，泛化能力差。

Method: 提出双侧数据增强策略（利用估计深度生成多视角图像），构建双路径自监督标定框架，并用差异图替代传统双分支特征提取以加强跨模态关联。

Result: 在五个公开基准数据集及自建数据集上实验表明，该方法显著优于现有方法，尤其在泛化性方面表现突出。

Conclusion: 所提自监督、在线式标定方法摆脱了对标定目标的依赖，提升了鲁棒性、适应性和标定精度，适用于实际机器人感知系统。

Abstract: LiDAR-camera extrinsic calibration is essential for multi-modal data fusion in robotic perception systems. However, existing approaches typically rely on handcrafted calibration targets (e.g., checkerboards) or specific, static scene types, limiting their adaptability and deployment in real-world autonomous and robotic applications. This article presents the first self-supervised LiDAR-camera extrinsic calibration network that operates in an online fashion and eliminates the need for specific calibration targets. We first identify a significant generalization degradation problem in prior methods, caused by the conventional single-sided data augmentation strategy. To overcome this limitation, we propose a novel double-sided data augmentation technique that generates multi-perspective camera views using estimated depth maps, thereby enhancing robustness and diversity during training. Built upon this augmentation strategy, we design a dual-path, self-supervised calibration framework that reduces the dependence on high-precision ground truth labels and supports fully adaptive online calibration. Furthermore, to improve cross-modal feature association, we replace the traditional dual-branch feature extraction design with a difference map construction process that explicitly correlates LiDAR and camera features. This not only enhances calibration accuracy but also reduces model complexity. Extensive experiments conducted on five public benchmark datasets, as well as our own recorded dataset, demonstrate that the proposed method significantly outperforms existing approaches in terms of generalizability.

</details>


### [473] [EduSim-LLM: An Educational Platform Integrating Large Language Models and Robotic Simulation for Beginners](https://arxiv.org/abs/2601.01196)
*Shenqi Lu,Liangwei Zhang*

Main category: cs.RO

TL;DR: 本文提出EduSim-LLM教育平台，将大语言模型（LLM）与机器人仿真（CoppeliaSim）结合，实现自然语言到机器人行为序列的映射，支持直接控制与自主控制两种交互模式，并在多机器人协作、运动规划和操作任务中验证了其有效性，最高复杂度下指令解析准确率超88.9%。


<details>
  <summary>Details</summary>
Motivation: 自然语言理解与机器人控制的融合是提升人机交互直观性与机器人教育/实践可及性的关键挑战。

Method: 构建EduSim-LLM平台，集成LLM与CoppeliaSim仿真环境，设计直接控制与自主控制两类交互模型，采用提示工程优化指令解析，并在多机器人协作、运动规划与操作任务中开展系统仿真实验。

Result: LLM能可靠地将自然语言转化为结构化机器人动作；经提示工程优化后，指令解析准确率显著提升；在最高复杂度任务中整体准确率超过88.9%。

Conclusion: EduSim-LLM验证了LLM驱动语言控制机器人的可行性与有效性，为教育与轻量级智能自动化提供了新范式。

Abstract: In recent years, the rapid development of Large Language Models (LLMs) has significantly enhanced natural language understanding and human-computer interaction, creating new opportunities in the field of robotics. However, the integration of natural language understanding into robotic control is an important challenge in the rapid development of human-robot interaction and intelligent automation industries. This challenge hinders intuitive human control over complex robotic systems, limiting their educational and practical accessibility. To address this, we present the EduSim-LLM, an educational platform that integrates LLMs with robot simulation and constructs a language-drive control model that translates natural language instructions into executable robot behavior sequences in CoppeliaSim. We design two human-robot interaction models: direct control and autonomous control, conduct systematic simulations based on multiple language models, and evaluate multi-robot collaboration, motion planning, and manipulation capabilities. Experiential results show that LLMs can reliably convert natural language into structured robot actions; after applying prompt-engineering templates instruction-parsing accuracy improves significantly; as task complexity increases, overall accuracy rate exceeds 88.9% in the highest complexity tests.

</details>


### [474] [SAHA: Supervised Autonomous HArvester for selective forest thinning](https://arxiv.org/abs/2601.01282)
*Fang Nan,Meher Malladi,Qingqing Li,Fan Yang,Joonas Juola,Tiziano Guadagnino,Jens Behley,Cesar Cadena,Cyrill Stachniss,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种基于小型机器人采伐机（SAHA）的森林选择性间伐解决方案，通过硬件改造与学习/模型驱动的感知、导航、状态估计和语义地形可通行性评估技术，实现了在复杂林地环境中的自主作业，并通过北欧森林的长距离实地试验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 森林管理中选择性间伐任务劳动强度大、依赖熟练操作员，亟需自动化解决方案以提升效率与可持续性。

Method: 基于4.5吨采伐机平台改装小型机器人采伐机SAHA，融合学习与模型驱动方法实现液压执行器精准控制、杂乱林地导航、鲁棒状态估计及语义地形可通行性评估，并集成感知、规划与控制前沿技术。

Result: 在北欧森林完成数公里级自主任务的实地试验，验证了系统在真实森林环境中自主导航、定位目标树木并执行选择性间伐的能力。

Conclusion: 该系统为推进机器人化森林管理提供了可行技术路径，试验分析与经验总结为后续研究与应用提供了重要参考。

Abstract: Forestry plays a vital role in our society, creating significant ecological, economic, and recreational value. Efficient forest management involves labor-intensive and complex operations. One essential task for maintaining forest health and productivity is selective thinning, which requires skilled operators to remove specific trees to create optimal growing conditions for the remaining ones. In this work, we present a solution based on a small-scale robotic harvester (SAHA) designed for executing this task with supervised autonomy. We build on a 4.5-ton harvester platform and implement key hardware modifications for perception and automatic control. We implement learning- and model-based approaches for precise control of hydraulic actuators, accurate navigation through cluttered environments, robust state estimation, and reliable semantic estimation of terrain traversability. Integrating state-of-the-art techniques in perception, planning, and control, our robotic harvester can autonomously navigate forest environments and reach targeted trees for selective thinning. We present experimental results from extensive field trials over kilometer-long autonomous missions in northern European forests, demonstrating the harvester's ability to operate in real forests. We analyze the performance and provide the lessons learned for advancing robotic forest management.

</details>


### [475] [Online Estimation and Manipulation of Articulated Objects](https://arxiv.org/abs/2601.01438)
*Russell Buchanan,Adrian Röfer,João Moura,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 本文提出了一种结合视觉先验与本体感知的在线关节估计方法，利用因子图融合基于Screw Theory的解析模型，在机器人操作过程中实时更新对铰接物体（如抽屉）的结构理解，实现在未知物体上的自主开启，真实硬件实验成功率达75%。


<details>
  <summary>Details</summary>
Motivation: 服务机器人需在无需先验知识的前提下自主操作任意铰接物体（如冰箱、抽屉），但现有方法要么依赖视觉先验（未接触前预测），要么依赖运动观测（需已能操作），二者存在能力断层。

Method: 提出基于因子图的在线关节估计框架，融合深度学习得到的视觉先验（初始预测）与操作过程中的运动学和力觉传感数据，构建符合Screw Theory的解析关节模型。

Result: 在仿真与真实机器人实验中验证了方法有效性；成功实现对未知抽屉的闭环估计与自主开启；真实硬件实验中对未知铰接物体的自主开启成功率达75%。

Conclusion: 视觉先验与本体感知的紧耦合可显著提升机器人对未知铰接物体的在线建模与操作能力，为通用家庭服务机器人提供了可行的技术路径。

Abstract: From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.

</details>


### [476] [AIMS: An Adaptive Integration of Multi-Sensor Measurements for Quadrupedal Robot Localization](https://arxiv.org/abs/2601.01561)
*Yujian Qiu,Yuqiu Mu,Wen Yang,Hao Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种名为AIMS的自适应LiDAR-IMU-腿式里程计融合方法，用于在退化隧道环境中提升四足机器人定位精度与鲁棒性，基于误差状态卡尔曼滤波框架，并在线评估退化程度以自适应调整测量噪声协方差。


<details>
  <summary>Details</summary>
Motivation: 在狭窄、长直且结构均一的隧道环境中，LiDAR几何约束弱，传统传感器融合易产生累积位姿估计误差。

Method: 提出AIMS方法，基于误差状态卡尔曼滤波框架，融合LiDAR、IMU和腿式里程计；通过在线退化感知可靠性评估，自适应调整各传感器测量噪声协方差矩阵。

Result: 在狭窄走廊环境实验中，该方法相比当前最优方法显著提升了定位精度与鲁棒性。

Conclusion: AIMS能有效应对退化环境下的定位挑战，为四足机器人在复杂受限空间中的自主导航提供了可靠解决方案。

Abstract: This paper addresses the problem of accurate localization for quadrupedal robots operating in narrow tunnel-like environments. Due to the long and homogeneous characteristics of such scenarios, LiDAR measurements often provide weak geometric constraints, making traditional sensor fusion methods susceptible to accumulated motion estimation errors. To address these challenges, we propose AIMS, an adaptive LiDAR-IMU-leg odometry fusion method for robust quadrupedal robot localization in degenerate environments. The proposed method is formulated within an error-state Kalman filtering framework, where LiDAR and leg odometry measurements are integrated with IMU-based state prediction, and measurement noise covariance matrices are adaptively adjusted based on online degeneracy-aware reliability assessment. Experimental results obtained in narrow corridor environments demonstrate that the proposed method improves localization accuracy and robustness compared with state-of-the-art approaches.

</details>


### [477] [HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller](https://arxiv.org/abs/2601.01577)
*Tran Tien Dat,Nguyen Hai An,Nguyen Khanh Viet Dung,Nguyen Duy Duc*

Main category: cs.RO

TL;DR: 本文提出了一种基于联合嵌入预测架构（JEPA）的Hanoi-World世界模型，利用RNN实现长时序水平规划，在Highway-Env中验证了其安全感知驾驶规划能力，显著降低碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在自动驾驶控制器中数据需求高、性能差、不稳定，且难以保障安全性；而像素级重建易过拟合噪声，忽视本质安全概念。JEPA类自监督学习可模仿人类通过少量观测和想象习得技能，是更优替代方案。

Method: 提出Hanoi-World——一种基于JEPA的世界模型，采用循环神经网络（RNN）进行长期水平方向规划，并在Highway-Env不同环境中开展实验验证。

Result: 该模型在驾驶规划任务中展现出较强的安全感知能力，碰撞率明显低于当前SOTA基线方法。

Conclusion: Hanoi-World证明了JEPA结合RNN在低样本、高安全性要求的自动驾驶决策任务中具有可行性与优势，为构建安全可靠的自主控制器提供了新思路。

Abstract: Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines

</details>


### [478] [Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.01618)
*Huajie Tan,Peterson Co,Yijie Xu,Shanyu Rong,Yuheng Ji,Cheng Chi,Xiansheng Chen,Qiongyu Zhang,Zhongxia Zhao,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 本文提出Action-Sketcher框架，通过引入可视化的‘Visual Sketch’中间表征（含点、框、箭头和关系），构建See-Think-Sketch-Act循环工作流，提升长时程机器人操作的空间指代能力、任务分解能力与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端或分层VLA策略依赖纯文本线索且隐式表达规划意图，导致在杂乱/描述不清场景中指代不准、长时程任务难以有效分解、动作决策缺乏因果可解释性。

Method: 提出Visual Sketch作为显式视觉中间表征；构建Action-Sketcher框架，采用自适应token门控策略协调See-Think-Sketch-Act循环；设计多阶段课程学习训练范式，融合跨模态序列对齐、语言-草图一致性约束、草图增强的强化模仿学习。

Result: 在仿真与真实世界多物体、高杂波任务中，显著提升长时程任务成功率、对动态场景变化的鲁棒性，并支持通过可编辑草图与分步计划实现强可解释性。

Conclusion: 显式外部化空间意图（via Visual Sketch）与闭环推理-执行协同机制是提升长时程VLA策略性能与可信度的关键路径。

Abstract: Long-horizon robotic manipulation is increasingly important for real-world deployment, requiring spatial disambiguation in complex layouts and temporal resilience under dynamic interaction. However, existing end-to-end and hierarchical Vision-Language-Action (VLA) policies often rely on text-only cues while keeping plan intent latent, which undermines referential grounding in cluttered or underspecified scenes, impedes effective task decomposition of long-horizon goals with close-loop interaction, and limits causal explanation by obscuring the rationale behind action choices. To address these issues, we first introduce Visual Sketch, an implausible visual intermediate that renders points, boxes, arrows, and typed relations in the robot's current views to externalize spatial intent, connect language to scene geometry. Building on Visual Sketch, we present Action-Sketcher, a VLA framework that operates in a cyclic See-Think-Sketch-Act workflow coordinated by adaptive token-gated strategy for reasoning triggers, sketch revision, and action issuance, thereby supporting reactive corrections and human interaction while preserving real-time action prediction. To enable scalable training and evaluation, we curate diverse corpus with interleaved images, text, Visual Sketch supervision, and action sequences, and train Action-Sketcher with a multi-stage curriculum recipe that combines interleaved sequence alignment for modality unification, language-to-sketch consistency for precise linguistic grounding, and imitation learning augmented with sketch-to-action reinforcement for robustness. Extensive experiments on cluttered scenes and multi-object tasks, in simulation and on real-world tasks, show improved long-horizon success, stronger robustness to dynamic scene changes, and enhanced interpretability via editable sketches and step-wise plans. Project website: https://action-sketcher.github.io

</details>


### [479] [DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos](https://arxiv.org/abs/2601.01651)
*Yucheng Xu,Xiaofeng Mao,Elle Miller,Xinyu Yi,Yang Li,Zhibin Li,Robert B. Fisher*

Main category: cs.RO

TL;DR: DemoBot是一种从单个未标注RGB-D视频演示中学习复杂操作技能的框架，通过提取双手和物体的运动轨迹作为先验，并结合创新的强化学习方法进行精细化训练。


<details>
  <summary>Details</summary>
Motivation: 解决机器人从人类视频中直接获取复杂操作技能的难题，特别是长时程、双臂协同的装配任务。

Method: 提出DemoBot框架，包括：1）基于时间片段的强化学习以实现状态与演示的时间对齐；2）成功门控重置策略以平衡技能优化与阶段探索；3）事件驱动且带自适应阈值的奖励课程机制。同时结合视频处理提取结构化运动轨迹作为运动先验。

Result: 在长时程同步与异步双臂装配任务上取得成功，验证了该方法的有效性与可扩展性。

Conclusion: DemoBot提供了一种无需人工标注、不需从零学习的高效技能获取途径，推动了从人类视频到机器人操作的端到端学习发展。

Abstract: This work presents DemoBot, a learning framework that enables a dual-arm, multi-finger robotic system to acquire complex manipulation skills from a single unannotated RGB-D video demonstration. The method extracts structured motion trajectories of both hands and objects from raw video data. These trajectories serve as motion priors for a novel reinforcement learning (RL) pipeline that learns to refine them through contact-rich interactions, thereby eliminating the need to learn from scratch. To address the challenge of learning long-horizon manipulation skills, we introduce: (1) Temporal-segment based RL to enforce temporal alignment of the current state with demonstrations; (2) Success-Gated Reset strategy to balance the refinement of readily acquired skills and the exploration of subsequent task stages; and (3) Event-Driven Reward curriculum with adaptive thresholding to guide the RL learning of high-precision manipulation. The novel video processing and RL framework successfully achieved long-horizon synchronous and asynchronous bimanual assembly tasks, offering a scalable approach for direct skill acquisition from human videos.

</details>


### [480] [VisuoTactile 6D Pose Estimation of an In-Hand Object using Vision and Tactile Sensor Data](https://arxiv.org/abs/2601.01675)
*Snehal s. Dikhale,Karankumar Patel,Daksh Dhingra,Itoshi Naramura,Akinobu Hayashi,Soshi Iba,Nawid Jamali*

Main category: cs.RO

TL;DR: 本文提出了一种结合视觉与触觉数据的6D物体位姿估计方法，利用点云表示触觉接触表面，并设计像素级稠密融合网络，在合成数据上训练后成功泛化至真实机器人系统，提升了遮挡严重场景下的位姿估计精度。


<details>
  <summary>Details</summary>
Motivation: 在手内操作中，由于机械手夹爪造成严重遮挡，仅依赖视觉的6D位姿估计效果受限；而指尖触觉传感器可提供互补信息，但缺乏标准触觉表征与有效多模态融合方法。

Method: 采用点云统一表征物体与触觉传感器接触表面；设计基于像素级稠密融合的神经网络架构；扩展NVIDIA DLDS生成配对的合成逼真视觉图像与对应触觉点云数据。

Result: 融合触觉与视觉数据显著提升6D位姿估计精度；所提网络能从合成数据训练成功迁移到真实物理机器人平台，验证了泛化能力。

Conclusion: 触觉信息是视觉在严重遮挡场景下有力的补充，以点云为统一表征并进行稠密融合是一种有效的多模态6D位姿估计范式，且合成到真实的迁移可行。

Abstract: Knowledge of the 6D pose of an object can benefit in-hand object manipulation. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot's grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this paper, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot's hand. To address challenges like lack of standard representation for tactile data and sensor fusion, we propose the use of point clouds to represent object surfaces in contact with the tactile sensor and present a network architecture based on pixel-wise dense fusion. We also extend NVIDIA's Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and corresponding tactile point clouds. Results suggest that using tactile data in addition to vision data improves the 6D pose estimate, and our network generalizes successfully from synthetic training to real physical robots.

</details>


### [481] [Explicit World Models for Reliable Human-Robot Collaboration](https://arxiv.org/abs/2601.01705)
*Kenneth Kwok,Basura Fernando,Qianli Xu,Vigneshwaran Subbaraju,Dongkyu Choi,Boon Kiat Quek*

Main category: cs.RO

TL;DR: 本文提出了一种以人类期望为中心的可靠具身AI新方法，强调在社会性、多模态和动态的人机交互环境中，通过构建并持续更新一个可解释的‘显式世界模型’来实现人与AI之间的共同理解与行为对齐。


<details>
  <summary>Details</summary>
Motivation: 传统方法侧重于形式化验证以提升模型可预测性和鲁棒性，但忽视了人机交互中固有的动态性、模糊性和主观性；本文动机在于应对感知噪声、指令歧义及真实人机交互中的可靠性挑战，主张可靠性应基于人类目标与期望而情境化定义。

Method: 提出构建并持续更新一个可访问的‘显式世界模型’，该模型表征人与AI之间的共同认知基础（common ground），用于实时感知、解释并响应人类意图，确保机器人行为一致、可理解且符合人类预期。

Result: 确立了以共同理解为核心的可靠具身AI范式，为处理社会性、多模态、流变环境中的交互鲁棒性提供了概念框架与设计原则。

Conclusion: 可靠具身AI不应仅追求内部模型的确定性，而应聚焦于人-AI协同中的可解释性与对齐性；显式世界模型是实现这一目标的关键机制。

Abstract: This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible "explicit world model" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.

</details>


### [482] [Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions](https://arxiv.org/abs/2601.01726)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.RO

TL;DR: 本文提出了一种专为MRI环境设计的机器人计算系统，用于辅助血管内介入手术，通过实时MR图像处理、虚拟路径规划、定制梯度磁场控制及安全性建模，提升手术精度与安全性。


<details>
  <summary>Details</summary>
Motivation: 解决MRI强磁场环境下机器人精度与稳定性问题，增强MRI在血管内介入手术中的引导能力。

Method: 开发基于Qt框架和C/C++的计算系统，集成MR图像处理、血管网络分割、虚拟路径与边界生成、定制磁梯度场设计、血流自适应导航及安全性建模模块。

Result: 系统能根据血管几何结构和安全规范生成定制磁场梯度模式，适配不同血流特性实现精细导航，并评估预设路径的安全性与可行性。

Conclusion: 该系统显著推动了医学影像与机器人技术的融合，提升了血管内介入手术的精度与安全性，是MRI兼容机器人领域的重要进展。

Abstract: Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.

</details>


### [483] [AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.01762)
*Yanhao Wu,Haoyang Zhang,Fei He,Rui Wu,Congpei Qiu,Liang Gao,Wei Ke,Tong Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种级联式端到端自动驾驶规划框架，通过将纵向规划显式地以行驶路径为条件，提升横纵协调性与安全性，并在Bench2Drive基准上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有端到端模型将横向与纵向规划并行解耦，易导致路径与速度不协调，且纵向规划未有效利用行驶路径先验，造成静态信息冗余编码。

Method: 提出路径条件化的级联规划框架：纵向规划以预测的行驶路径为输入，仅预测沿该路径的纵向位移；并设计面向规划的数据增强策略（如模拟车辆加塞），重标定纵向目标以规避碰撞。

Result: 在Bench2Drive基准上取得89.07的驾驶得分和73.18%的成功率，显著优于此前SOTA，验证了协调性与安全性的提升。

Conclusion: 路径条件化级联设计能更紧密耦合横纵规划，减少冗余，提升决策一致性与罕见危险场景下的鲁棒性。

Abstract: End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety

</details>


### [484] [DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization](https://arxiv.org/abs/2601.01822)
*Shiyong Meng,Tao Zou,Bolei Chen,Chaoxu Mu,Jianxin Wang*

Main category: cs.RO

TL;DR: 本文提出DisCo-FLoc方法，通过双层次视觉-几何对比学习，在无需额外语义标注的情况下，解决极简平面图中因重复结构导致的定位模糊问题，提升视觉平面图定位（FLoc）的鲁棒性与精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于极简平面图中重复结构引起的定位模糊，且依赖昂贵且有限的语义标注，泛化能力差。

Method: 提出DisCo-FLoc：1）设计面向射线投射的深度感知射线回归预测器，生成多个定位候选；2）引入位置级与朝向级约束的对比学习，严格对齐深度感知视觉特征与平面图几何结构。

Result: 在两个标准FLoc基准上显著超越当前最优语义驱动方法，定位准确率与鲁棒性均提升。

Conclusion: 双层次视觉-几何对比学习可有效消除定位歧义，无需语义标签即可实现高精度、强鲁棒的视觉平面图定位。

Abstract: Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.

</details>


### [485] [CausalNav: A Long-term Embodied Navigation System for Autonomous Mobile Robots in Dynamic Outdoor Scenarios](https://arxiv.org/abs/2601.01872)
*Hongbo Duan,Shangyi Luo,Zhiyuan Deng,Yanbo Chen,Yuanhao Chiang,Yi Liu,Fangming Liu,Xueqian Wang*

Main category: cs.RO

TL;DR: CausalNav 是首个基于场景图的语义导航框架，专为动态室外环境设计，通过构建多层级语义场景图（Embodied Graph），融合实时感知与离线地图数据，支持开放词汇查询下的鲁棒长程语义导航。


<details>
  <summary>Details</summary>
Motivation: 自主语言引导的室外大范围导航面临语义推理难、环境动态性强和长期稳定性差等挑战。

Method: 提出 CausalNav 框架，利用大语言模型构建多层级语义场景图（Embodied Graph），融合粗粒度地图与细粒度物体实体，并结合检索增强生成（RAG）与分层规划，显式建模动态物体，支持时序更新。

Result: 在仿真与真实世界实验中均展现出更优的鲁棒性与效率。

Conclusion: CausalNav 有效提升了动态室外环境下语言引导导航的语义理解能力、长期稳定性与实时适应性。

Abstract: Autonomous language-guided navigation in large-scale outdoor environments remains a key challenge in mobile robotics, due to difficulties in semantic reasoning, dynamic conditions, and long-term stability. We propose CausalNav, the first scene graph-based semantic navigation framework tailored for dynamic outdoor environments. We construct a multi-level semantic scene graph using LLMs, referred to as the Embodied Graph, that hierarchically integrates coarse-grained map data with fine-grained object entities. The constructed graph serves as a retrievable knowledge base for Retrieval-Augmented Generation (RAG), enabling semantic navigation and long-range planning under open-vocabulary queries. By fusing real-time perception with offline map data, the Embodied Graph supports robust navigation across varying spatial granularities in dynamic outdoor environments. Dynamic objects are explicitly handled in both the scene graph construction and hierarchical planning modules. The Embodied Graph is continuously updated within a temporal window to reflect environmental changes and support real-time semantic navigation. Extensive experiments in both simulation and real-world settings demonstrate superior robustness and efficiency.

</details>


### [486] [From Metrics to Meaning: Insights from a Mixed-Methods Field Experiment on Retail Robot Deployment](https://arxiv.org/abs/2601.01946)
*Sichao Song,Yuki Okafuji,Takuya Iwamoto,Jun Baba,Hiroshi Ishiguro*

Main category: cs.RO

TL;DR: 本研究通过混合方法实地实验，评估了在真实床具店中部署的对话式服务机器人对顾客行为和服务流程的影响，发现机器人虽提升了顾客驻足率，但降低了后续由店员主导的服务转化率，并揭示了其背后的人机协作挑战。


<details>
  <summary>Details</summary>
Motivation: 理解服务机器人在高接触度零售环境中如何影响顾客行为及员工互动，解决实际部署中的协调问题。

Method: 采用混合方法现场实验：12天内交替设置无机器人（Baseline）、仅机器人（Robot-only）和机器人+固定装置（Robot+Fixture）三种条件，视频标注从路人到购买的整个服务漏斗；随后进行6次员工访谈以解释量化结果。

Result: 机器人显著提高路人驻足率（尤其在加装固定装置时），但店员主导的后续步骤（如主动接触、进店、协助体验、购买）均下降；访谈揭示原因包括店员避免打断人机对话、难以把握介入时机、以及儿童被吸引后常在门口满足好奇心而未入店；固定装置增强了可见性但也使交互局限于门口微空间。

Conclusion: 顾客兴趣到进店转化的过程受人机协同动态深刻影响；需重新设计机器人行为与员工协作机制，明确角色边界与介入时机，避免‘门口闭环’，以提升整体服务效能。

Abstract: We report a mixed-methods field experiment of a conversational service robot deployed under everyday staffing discretion in a live bedding store. Over 12 days we alternated three conditions--Baseline (no robot), Robot-only, and Robot+Fixture--and video-annotated the service funnel from passersby to purchase. An explanatory sequential design then used six post-experiment staff interviews to interpret the quantitative patterns.
  Quantitatively, the robot increased stopping per passerby (highest with the fixture), yet clerk-led downstream steps per stopper--clerk approach, store entry, assisted experience, and purchase--decreased. Interviews explained this divergence: clerks avoided interrupting ongoing robot-customer talk, struggled with ambiguous timing amid conversational latency, and noted child-centered attraction that often satisfied curiosity at the doorway. The fixture amplified visibility but also anchored encounters at the threshold, creating a well-defined micro-space where needs could ``close'' without moving inside.
  We synthesize these strands into an integrative account from the initial show of interest on the part of a customer to their entering the store and derive actionable guidance. The results advance the understanding of interactions between customers, staff members, and the robot and offer practical recommendations for deploying service robots in high-touch retail.

</details>


### [487] [Learning Diffusion Policy from Primitive Skills for Robot Manipulation](https://arxiv.org/abs/2601.01948)
*Zhihao Gu,Ming Yang,Difan Zou,Dong Xu*

Main category: cs.RO

TL;DR: 本文提出了一种技能条件化的扩散策略（SDP），通过将复杂任务分解为可复用的细粒度原始技能（如“上移”、“张开夹爪”），并利用视觉-语言模型提取离散表征，结合轻量级路由器网络选择对应技能，实现技能对齐的动作生成，在仿真与真实机器人实验中均超越SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略依赖全局指令生成短期控制信号，易导致动作生成错位；而细粒度、短视界原始技能（如“移动向上”、“打开夹爪”）提供更直观有效的机器人学习接口。

Method: 提出技能条件化扩散策略（SDP）：抽象出8种跨任务可复用原始技能；利用视觉-语言模型从视觉观测和语言指令中提取离散表征；设计轻量级路由器网络为每个状态分配目标原始技能；构建单技能策略生成技能对齐动作。

Result: 在两个具挑战性的仿真基准和真实机器人部署中，SDP持续优于当前最优方法。

Conclusion: SDP通过技能分解与条件化扩散建模，建立了技能一致的行为生成机制，为基于技能的机器人学习提供了新范式。

Abstract: Diffusion policies (DP) have recently shown great promise for generating actions in robotic manipulation. However, existing approaches often rely on global instructions to produce short-term control signals, which can result in misalignment in action generation. We conjecture that the primitive skills, referred to as fine-grained, short-horizon manipulations, such as ``move up'' and ``open the gripper'', provide a more intuitive and effective interface for robot learning. To bridge this gap, we propose SDP, a skill-conditioned DP that integrates interpretable skill learning with conditional action planning. SDP abstracts eight reusable primitive skills across tasks and employs a vision-language model to extract discrete representations from visual observations and language instructions. Based on them, a lightweight router network is designed to assign a desired primitive skill for each state, which helps construct a single-skill policy to generate skill-aligned actions. By decomposing complex tasks into a sequence of primitive skills and selecting a single-skill policy, SDP ensures skill-consistent behavior across diverse tasks. Extensive experiments on two challenging simulation benchmarks and real-world robot deployments demonstrate that SDP consistently outperforms SOTA methods, providing a new paradigm for skill-based robot learning with diffusion policies.

</details>


### [488] [What you reward is what you learn: Comparing rewards for online speech policy optimization in public HRI](https://arxiv.org/abs/2601.01969)
*Sichao Song,Yuki Okafuji,Kaito Ariu,Amy Koike*

Main category: cs.RO

TL;DR: 本文研究了在真实公共环境中如何通过在线策略优化（多臂赌博机与Thompson采样）动态调整社交机器人的语音策略（语速与详略），并基于用户评分、对话结束、对话轮次等三种奖励信号进行比较分析，结合离线视频标注数据探讨环境上下文影响，最终提炼出面向人机交互实际部署的设计启示。


<details>
  <summary>Details</summary>
Motivation: 设计适用于开放、多样化环境的高效且可接受的对话服务机器人策略具有挑战性；固定参数难以应对非平稳环境，需借助在线学习实现自适应。

Method: 将社交机器人语音策略在线优化建模为多臂赌博机问题，采用Thompson采样在六种语音策略（慢/正常/快 × 简洁/详细）中选择；在12天实地部署（>1400次公众交互）中收集三种二元奖励（用户评分Ru、对话终止Rc、≥2轮对话Rt）；辅以基于视频标注数据的离线上下文分析（如人群密度、群体规模）。

Result: 不同奖励信号（Ru/Rc/Rt）导致显著不同的动作选择分布和交互行为；离线分析揭示了环境上下文因素对策略效果的影响；验证了在线优化在真实HRI场景中的可行性与实用性。

Conclusion: 在线策略优化可用于真实公共人机交互场景中的语音策略自适应；不同奖励目标导向不同行为模式，应根据应用目标谨慎选择；上下文感知可进一步提升策略鲁棒性；本研究提供了可直接落地的设计经验。

Abstract: Designing policies that are both efficient and acceptable for conversational service robots in open and diverse environments is non-trivial. Unlike fixed, hand-tuned parameters, online learning can adapt to non-stationary conditions. In this paper, we study how to adapt a social robot's speech policy in the wild. During a 12-day in-situ deployment with over 1,400 public encounters, we cast online policy optimization as a multi-armed bandit problem and use Thompson sampling to select among six actions defined by speech rate (slow/normal/fast) and verbosity (concise/detailed). We compare three complementary binary rewards--Ru (user rating), Rc (conversation closure), and Rt (>=2 turns)--and show that each induces distinct arm distributions and interaction behaviors. We complement the online results with offline evaluations that analyze contextual factors (e.g., crowd level, group size) using video-annotated data. Taken together, we distill ready-to-use design lessons for deploying online optimization of speech policies in real public HRI settings.

</details>


### [489] [Deep Robust Koopman Learning from Noisy Data](https://arxiv.org/abs/2601.01971)
*Aditya Singh,Rajpal Singh,Jishnu Keshavan*

Main category: cs.RO

TL;DR: 本文提出了一种基于自编码器的神经网络架构，用于从含噪数据中联合学习最优提升函数和低偏置Koopman算子，通过前向与后向时间动力学一致性约束提升噪声鲁棒性，并在仿真与Franka机械臂实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据常含噪声，导致传统Koopman算子估计存在严重噪声诱导偏差，损害预测与跟踪性能。

Method: 设计一种新型自编码器神经架构：首先学习对前向和后向时间动力学均一致的Koopman基函数；再基于该双方向动力学合成低偏置Koopman算子；辅以理论分析证明偏置降低效果。

Result: 在多个串联机械臂的动力学预测与跟踪控制仿真中，相较主流方法表现出更强的抗噪能力；Franka FR3 7-DoF机械臂实验进一步验证了实际有效性。

Conclusion: 所提方法能有效缓解噪声引起的Koopman算子估计偏差，提升模型在预测与控制任务中的鲁棒性与实用性。

Abstract: Koopman operator theory has emerged as a leading data-driven approach that relies on a judicious choice of observable functions to realize global linear representations of nonlinear systems in the lifted observable space. However, real-world data is often noisy, making it difficult to obtain an accurate and unbiased approximation of the Koopman operator. The Koopman operator generated from noisy datasets is typically corrupted by noise-induced bias that severely degrades prediction and downstream tracking performance. In order to address this drawback, this paper proposes a novel autoencoder-based neural architecture to jointly learn the appropriate lifting functions and the reduced-bias Koopman operator from noisy data. The architecture initially learns the Koopman basis functions that are consistent for both the forward and backward temporal dynamics of the system. Subsequently, by utilizing the learned forward and backward temporal dynamics, the Koopman operator is synthesized with a reduced bias making the method more robust to noise compared to existing techniques. Theoretical analysis is used to demonstrate significant bias reduction in the presence of training noise. Dynamics prediction and tracking control simulations are conducted for multiple serial manipulator arms, including performance comparisons with leading alternative designs, to demonstrate its robustness under various noise levels. Experimental studies with the Franka FR3 7-DoF manipulator arm are further used to demonstrate the effectiveness of the proposed approach in a practical setting.

</details>


### [490] [Genie Sim 3.0 : A High-Fidelity Comprehensive Simulation Platform for Humanoid Robot](https://arxiv.org/abs/2601.02078)
*Chenghao Yin,Da Huang,Di Yang,Jichao Wang,Nanshu Zhao,Chen Xu,Wenjun Sun,Linjie Hou,Zhijun Li,Junhui Wu,Zhaobo Liu,Zhen Xiao,Sheng Zhang,Lei Bao,Rui Feng,Zhenquan Pang,Jiayu Li,Qian Wang,Maoqing Yao*

Main category: cs.RO

TL;DR: 本文提出了Genie Sim 3.0，一个面向机器人操作的统一仿真平台，结合LLM驱动的场景生成器与VLM支持的自动化评估框架，并发布超10,000小时合成数据集，验证了其在零样本sim-to-real迁移中的有效性。


<details>
  <summary>Details</summary>
Motivation: 物理世界数据采集成本高、可扩展性差；现有仿真基准存在碎片化、范围窄、保真度低等问题，难以支撑鲁棒、泛化的机器人学习模型训练与评估。

Method: 提出Genie Sim 3.0平台，包括：1）Genie Sim Generator——基于LLM的自然语言到高保真仿真场景生成工具；2）首个LLM驱动的自动化评估基准，结合LLM生成评测任务、VLM进行自动评估；3）开源包含200+任务、超10,000小时合成数据的数据集。

Result: 实验证明该合成数据集具备强零样本sim-to-real迁移能力，在受控条件下可有效替代真实数据用于策略训练；评估框架实现大规模、自动化、多维度策略评测。

Conclusion: Genie Sim 3.0通过LLM+VLM协同的仿真-生成-评估闭环，显著提升了机器人操纵任务中数据生成效率、评估可靠性与sim-to-real迁移能力，为通用机器人学习提供了可扩展基础设施。

Abstract: The development of robust and generalizable robot learning models is critically contingent upon the availability of large-scale, diverse training data and reliable evaluation benchmarks. Collecting data in the physical world poses prohibitive costs and scalability challenges, and prevailing simulation benchmarks frequently suffer from fragmentation, narrow scope, or insufficient fidelity to enable effective sim-to-real transfer. To address these challenges, we introduce Genie Sim 3.0, a unified simulation platform for robotic manipulation. We present Genie Sim Generator, a large language model (LLM)-powered tool that constructs high-fidelity scenes from natural language instructions. Its principal strength resides in rapid and multi-dimensional generalization, facilitating the synthesis of diverse environments to support scalable data collection and robust policy evaluation. We introduce the first benchmark that pioneers the application of LLM for automated evaluation. It leverages LLM to mass-generate evaluation scenarios and employs Vision-Language Model (VLM) to establish an automated assessment pipeline. We also release an open-source dataset comprising more than 10,000 hours of synthetic data across over 200 tasks. Through systematic experimentation, we validate the robust zero-shot sim-to-real transfer capability of our open-source dataset, demonstrating that synthetic data can server as an effective substitute for real-world data under controlled conditions for scalable policy training. For code and dataset details, please refer to: https://github.com/AgibotTech/genie_sim.

</details>


### [491] [Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots](https://arxiv.org/abs/2601.02085)
*Meili Sun,Chunjiang Zhao,Lichao Yang,Hao Liu,Shimin Hu,Ya Xiong*

Main category: cs.RO

TL;DR: 本文提出了一种面向草莓采摘机器人的视觉故障诊断与自恢复框架，核心是端到端多任务感知模型SRR-Net，可同步完成检测、分割与成熟度估计，并结合相对误差补偿、早期中止策略及末端微光相机实时反馈，显著提升采摘稳定性与效率。


<details>
  <summary>Details</summary>
Motivation: 草莓采摘机器人面临视觉感知集成度低、果-夹错位、空抓、果实滑脱等长期问题，影响果园作业的稳定性和效率。

Method: 提出视觉故障诊断与自恢复框架：1）构建SRR-Net多任务感知模型，统一完成草莓检测、分割与成熟度估计；2）设计基于目标-夹爪同步检测的相对误差补偿方法以校正位置偏差；3）采用早期中止策略应对空抓与滑脱；4）在末端嵌入微光相机，结合MobileNet V3-Small与LSTM时序分类器实现抓取状态识别与滑脱预测。

Result: SRR-Net在检测任务中对草莓达到精度0.895、召回率0.813，对手部达0.972/0.958；分割任务中草莓精度0.887、召回率0.747，手部0.974/0.947；成熟度估计平均绝对误差为0.035，推理速度达163.35 FPS。

Conclusion: 该框架有效提升了视觉感知一致性与故障响应能力，显著增强草莓采摘机器人在复杂果园环境中的鲁棒性与作业效率。

Abstract: Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.

</details>


### [492] [SingingBot: An Avatar-Driven System for Robotic Face Singing Performance](https://arxiv.org/abs/2601.02125)
*Zhuoxiong Xu,Xuanchen Li,Yuhao Cheng,Fei Xu,Yichao Yan,Xiaokang Yang*

Main category: cs.RO

TL;DR: 本文提出了一种面向机器人歌唱的新型驱动框架，利用人像视频生成模型合成生动的歌唱虚拟形象，并通过语义导向的映射函数将其表情迁移到机器人面部，同时提出'情感动态范围'指标量化评估情感丰富度，实验表明该方法在情感表达和唇音同步方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人面部驱动研究主要集中于对话或静态表情模仿，难以满足歌唱中对连续情感表达与一致性的高要求。

Method: 提出基于人像视频生成模型合成歌唱虚拟形象，提取其表情与情感特征，并通过语义导向的宽表达空间映射函数迁移至机器人；同时设计Emotion Dynamic Range指标，在Valence-Arousal空间中量化情感广度。

Result: 实验表明该方法在保持唇音同步的同时实现丰富的情感表达，显著优于现有方法。

Conclusion: 所提框架有效提升了机器人歌唱中的情感表现力与自然性，Emotion Dynamic Range指标为评估机器人情感表达提供了新思路。

Abstract: Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.

</details>


### [493] [Differential Barometric Altimetry for Submeter Vertical Localization and Floor Recognition Indoors](https://arxiv.org/abs/2601.02184)
*Yuhang Zhang,Sören Schwertfeger*

Main category: cs.RO

TL;DR: 本文提出了一种基于差分气压传感的低成本、鲁棒垂直定位框架，集成于ROS系统中，实现在封闭楼梯井和电梯等复杂场景下亚米级（RMSE 0.29 m）高度估计与100%楼层识别。


<details>
  <summary>Details</summary>
Motivation: 准确的高度估计和可靠的楼层识别对移动机器人在多层复杂环境中的定位与导航至关重要，而现有视觉或LiDAR SLAM方法在垂直方向上表现不足。

Method: 构建基于差分气压传感的垂直估计框架，部署一个固定基站和一个移动传感器，同步发布实时气压高度数据，并集成到完全兼容ROS的软件包中。

Result: 在封闭楼梯井和电梯等挑战性场景中实现0.29 m RMSE的亚米级垂直精度和100%楼层识别准确率；验证了纯视觉/LiDAR SLAM的高度估计无法满足可靠垂直定位需求。

Conclusion: 该开源、ROS兼容的气压模块为实际机器人部署提供了实用且低成本的垂直感知解决方案。

Abstract: Accurate altitude estimation and reliable floor recognition are critical for mobile robot localization and navigation within complex multi-storey environments. In this paper, we present a robust, low-cost vertical estimation framework leveraging differential barometric sensing integrated within a fully ROS-compliant software package. Our system simultaneously publishes real-time altitude data from both a stationary base station and a mobile sensor, enabling precise and drift-free vertical localization. Empirical evaluations conducted in challenging scenarios -- such as fully enclosed stairwells and elevators, demonstrate that our proposed barometric pipeline achieves sub-meter vertical accuracy (RMSE: 0.29 m) and perfect (100%) floor-level identification. In contrast, our results confirm that standalone height estimates, obtained solely from visual- or LiDAR-based SLAM odometry, are insufficient for reliable vertical localization. The proposed ROS-compatible barometric module thus provides a practical and cost-effective solution for robust vertical awareness in real-world robotic deployments. The implementation of our method is released as open source at https://github.com/witsir/differential-barometric.

</details>


### [494] [CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding](https://arxiv.org/abs/2601.02295)
*Chenyang Ma,Guangyu Yang,Kai Lu,Shitong Xu,Bill Byrne,Niki Trigoni,Andrew Markham*

Main category: cs.RO

TL;DR: CycleVLA提出一种前摄式自纠正机制，使视觉-语言-动作（VLA）模型能在失败发生前预测并回溯修正，通过进度感知VLA、VLM故障预测器与规划器，以及基于最小贝叶斯风险（MBR）的测试时解码策略提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人失败检测与纠正方法多为事后处理，缺乏对即将发生的失败进行提前干预的能力。

Method: CycleVLA融合三部分：1）进度感知的VLA识别易错子任务切换点；2）基于VLM的失败预测与回溯规划模块；3）基于MBR解码的零样本测试时缩放策略以提升重试成功率。

Result: 在多种实验设置下，CycleVLA显著提升了训练充分和欠训练VLA模型的任务成功率；MBR被验证为一种有效的零样本测试时扩展方法。

Conclusion: 前摄式自我纠正可显著增强VLA模型的鲁棒性与泛化能力，无需额外训练即可部署，为具身智能系统提供新范式。

Abstract: Current work on robot failure detection and correction typically operate in a post hoc manner, analyzing errors and applying corrections only after failures occur. This work introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction, the capability to anticipate incipient failures and recover before they fully manifest during execution. CycleVLA achieves this by integrating a progress-aware VLA that flags critical subtask transition points where failures most frequently occur, a VLM-based failure predictor and planner that triggers subtask backtracking upon predicted failure, and a test-time scaling strategy based on Minimum Bayes Risk (MBR) decoding to improve retry success after backtracking. Extensive experiments show that CycleVLA improves performance for both well-trained and under-trained VLAs, and that MBR serves as an effective zero-shot test-time scaling strategy for VLAs. Project Page: https://dannymcy.github.io/cyclevla/

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [495] [Harm in AI-Driven Societies: An Audit of Toxicity Adoption on Chirper.ai](https://arxiv.org/abs/2601.01090)
*Erica Coppolillo,Luca Luceri,Emilio Ferrara*

Main category: cs.MA

TL;DR: 本文研究了在完全由AI驱动的社交平台Chirper.ai上，LLM驱动的智能体在接触有害内容后毒性行为的演化规律，发现毒性响应既受刺激影响也存在自发产生，并提出两个新指标揭示诱导性与自发性毒性间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注LLM生成有害内容的现象，但缺乏对AI代理在长期、累积、部分可控的社交交互环境中，因暴露于有害内容而导致行为毒化演化的系统性理解。

Method: 基于Chirper.ai平台的真实交互数据，将交互建模为‘刺激（发帖）-响应（评论）’结构，通过可观测互动定义暴露，开展大规模实证分析；引入Influence-Driven Response Rate和Spontaneous Response Rate两个新指标，并构建仅依赖毒刺激数量的预测模型。

Result: 1）毒刺激提升毒响应概率，但大量毒响应属自发产生；2）累积毒暴露显著提高毒响应概率；3）存在诱导性与自发性毒性的强权衡关系；4）仅用毒刺激数量即可高精度预测代理是否最终产出毒内容。

Conclusion: 暴露是部署LLM代理的关键风险因素，监测其实际遭遇的内容可作为轻量高效的行为审计与危害缓解手段。

Abstract: Large Language Models (LLMs) are increasingly embedded in autonomous agents that participate in online social ecosystems, where interactions are sequential, cumulative, and only partially controlled. While prior work has documented the generation of toxic content by LLMs, far less is known about how exposure to harmful content shapes agent behavior over time, particularly in environments composed entirely of interacting AI agents. In this work, we study toxicity adoption of LLM-driven agents on Chirper.ai, a fully AI-driven social platform. Specifically, we model interactions in terms of stimuli (posts) and responses (comments), and by operationalizing exposure through observable interactions rather than inferred recommendation mechanisms.
  We conduct a large-scale empirical analysis of agent behavior, examining how response toxicity relates to stimulus toxicity, how repeated exposure affects the likelihood of toxic responses, and whether toxic behavior can be predicted from exposure alone. Our findings show that while toxic responses are more likely following toxic stimuli, a substantial fraction of toxicity emerges spontaneously, independent of exposure. At the same time, cumulative toxic exposure significantly increases the probability of toxic responding. We further introduce two influence metrics, the Influence-Driven Response Rate and the Spontaneous Response Rate, revealing a strong trade-off between induced and spontaneous toxicity. Finally, we show that the number of toxic stimuli alone enables accurate prediction of whether an agent will eventually produce toxic content.
  These results highlight exposure as a critical risk factor in the deployment of LLM agents and suggest that monitoring encountered content may provide a lightweight yet effective mechanism for auditing and mitigating harmful behavior in the wild.

</details>


### [496] [CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty](https://arxiv.org/abs/2601.01581)
*Rishav Sen,Fangqi Liu,Jose Paolo Talusan,Ava Pettet,Yoshinori Suzue,Mark Bailey,Ayan Mukhopadhyay,Abhishek Dubey*

Main category: cs.MA

TL;DR: 本文提出了一种基于协商的电动汽车（EV）车-建筑（V2B）充电管理框架，通过激励用户在离场时间或所需电量上做出小幅让步，实现建筑运营商降本与用户节省充电费用的双赢。


<details>
  <summary>Details</summary>
Motivation: 解决电动汽车快速增长背景下，建筑运营商因无序充电导致高能耗成本与用户追求便利性和满电需求之间的冲突。

Method: 设计了一个保证自愿参与、防策略操纵和预算可行的协商框架，将EV充电作为战略资源，结合用户调研数据和真实商业建筑及车企运营数据进行校准与验证。

Result: 仿真表明，该协商协议相比优化的非协商智能充电策略，可降低建筑运营商成本超3.5%，同时使用户充电费用比公用事业零售电价低22%。

Conclusion: 该框架通过协调建筑运营商与EV用户目标，将EV充电从运行摩擦源转变为协作与共享节约的平台。

Abstract: The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.

</details>


### [497] [ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring](https://arxiv.org/abs/2601.01831)
*Aniket Wattamwar,Sampson Akwafuo*

Main category: cs.MA

TL;DR: 本文提出了ARIES，一个专为流行病学监测设计的自主多智能体框架，通过分层指挥结构和GPT协调的子智能体群，自动查询WHO、CDC及学术文献，实现实时威胁识别与信号差异分析，显著优于通用AI模型。


<details>
  <summary>Details</summary>
Motivation: 全球健康监测面临知识鸿沟挑战，通用AI因幻觉频发和难以处理专业数据孤岛，无法胜任高风险的流行病学领域。

Method: 提出ARIES框架，采用分层命令结构，以GPT为编排核心，驱动可扩展的子智能体群，自主检索并逻辑整合来自WHO、CDC和同行评议论文的监测数据。

Result: ARIES实现了对新兴威胁和信号偏离的近实时识别，其模块化架构在任务特异性上显著超越通用模型。

Conclusion: 任务定制的智能体集群可构建更鲁棒、可扩展的下一代疫情响应与全球健康情报系统。

Abstract: Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [498] [PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS](https://arxiv.org/abs/2601.01288)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.GR

TL;DR: PyBatchRender是一个基于Panda3D的高性能Python库，用于批量3D渲染，专为像素级强化学习设计，支持百万级FPS、纯Python场景构建和快速原型开发。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习从像素学习时受3D渲染环境性能与复杂性限制的问题，弥合高速低层引擎与易用但慢的Python框架之间的鸿沟。

Method: 基于Panda3D构建，通过优化批量渲染机制实现高吞吐量，支持物理无关渲染，提供纯Python接口以简化场景定义与集成。

Result: 在简单场景下实现超100万FPS，相比常规方法达1000倍加速，性能媲美Madrona等C++引擎，且设置更简单、灵活性更高。

Conclusion: PyBatchRender降低了高性能3D仿真的使用门槛，推动强化学习研究的可扩展性与可及性，是开源、易集成的通用渲染基础设施。

Abstract: Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.

</details>


### [499] [VARTS: A Tool for the Visualization and Analysis of Representative Time Series Data](https://arxiv.org/abs/2601.01361)
*Duosi Jin,Jianqiu Xu,Guidong Zhang*

Main category: cs.GR

TL;DR: VARTS是一个交互式可视化分析工具，用于大规模时间序列中代表性序列的选择与可视化，通过M4采样、DTW相似性计算和贪心选择提升可视清晰度与可解释性。


<details>
  <summary>Details</summary>
Motivation: 大规模时间序列可视化常因视觉杂乱和冗余模式而难以理解主要时间趋势。

Method: 基于M4-Greedy的改进，集成M4采样、DTW相似性计算和贪心选择，构建统一的工作流，并提供支持多视图协调的响应式图形界面。

Result: 实现了代表性时间序列的有效识别与可视化，在减少冗余的同时保留关键数据模式，提升了大规模时序分析的视觉清晰度和可解释性。

Conclusion: VARTS为大规模时间序列分析提供了一种高效、直观且用户友好的可视化解决方案。

Abstract: Large-scale time series visualization often suffers from excessive visual clutter and redundant patterns, making it difficult for users to understand the main temporal trends. To address this challenge, we present VARTS, an interactive visual analytics tool for representative time series selection and visualization. Building upon our previous work M4-Greedy, VARTS integrates M4-based sampling, DTW-based similarity computation, and greedy selection into a unified workflow for the identification and visualization of representative series. The tool provides a responsive graphical interface that allows users to import time series datasets, perform representative selection, and visualize both raw and reduced data through multiple coordinated views. By reducing redundancy while preserving essential data patterns, VARTS effectively enhances visual clarity and interpretability for large-scale time series analysis. The demo video is available at https://youtu.be/mS9f12Rf0jo.

</details>


### [500] [SketchRodGS: Sketch-based Extraction of Slender Geometries for Animating Gaussian Splatting Scenes](https://arxiv.org/abs/2601.02072)
*Haato Watanabe,Nobuyuki Umetani*

Main category: cs.GR

TL;DR: 本文提出了一种从高斯泼溅（Gaussian splatting）场景中，基于用户草图输入提取细长物体多段线表示的方法，利用屏幕空间最短路径分析与动态规划实现鲁棒的多段线网格构建。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅缺乏连通性信息且其高斯基元配置噪声大，难以直接用于细长弹性物体的物理仿真所需的多段线离散化。

Method: 基于用户草图输入，通过屏幕空间最短路径分析（采用动态规划高效求解）来鲁棒地构建表征细长部分的多段线网格。

Result: 在多个真实场景（in-the-wild）示例中验证了该方法的有效性。

Conclusion: 该方法为高斯泼溅场景中细长结构的几何提取与后续物理仿真提供了实用、鲁棒的解决方案。

Abstract: Physics simulation of slender elastic objects often requires discretization as a polyline. However, constructing a polyline from Gaussian splatting is challenging as Gaussian splatting lacks connectivity information and the configuration of Gaussian primitives contains much noise. This paper presents a method to extract a polyline representation of the slender part of the objects in a Gaussian splatting scene from the user's sketching input. Our method robustly constructs a polyline mesh that represents the slender parts using the screen-space shortest path analysis that can be efficiently solved using dynamic programming. We demonstrate the effectiveness of our approach in several in-the-wild examples.

</details>


### [501] [Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs](https://arxiv.org/abs/2601.02096)
*Peizhuo Li,Sebastian Starke,Yuting Ye,Olga Sorkine-Hornung*

Main category: cs.GR

TL;DR: 本文提出了一种基于VR设备三关键点轨迹的球舞交互建模方法，用轻量MLP实现领导者到跟随者运动的确定性预测，并能泛化至更大规模数据集如LaFAN。


<details>
  <summary>Details</summary>
Motivation: 球舞动作多样、领舞与跟舞者互动复杂，传统全身体态建模困难且易过拟合；需更简洁、鲁棒、高效的方法来建模双人舞蹈交互。

Method: 利用VR设备获取的三个关键点（头、左/右手）轨迹作为舞蹈动作的低维显式表征，采用MLP直接从领导者的三轨迹预测跟随者的三轨迹；结合运动结构先验与自回归策略，将三轨迹确定性映射为虚拟化身的全身运动。

Result: 在球舞数据上实现了高保真、低延迟的双人舞蹈合成；在LaFAN等更大更杂的数据集上仍保持稳健性能；显著降低计算与数据需求，避免生成模型的不确定性。

Conclusion: 三关键点轨迹是一种紧凑而有效的舞蹈交互表征，配合确定性神经网络可替代传统生成模型，为沉浸式双人舞蹈应用提供高效可行的新范式。

Abstract: Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.

</details>
