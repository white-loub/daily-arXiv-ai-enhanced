<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 41]
- [cs.CL](#cs.CL) [Total: 47]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 72]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cropland Mapping using Geospatial Embeddings](https://arxiv.org/abs/2511.02923)
*Ivan Zvonkov,Gabriel Tseng,Inbal Becker-Reshef,Hannah Kerner*

Main category: cs.CV

TL;DR: 本研究评估了地理空间嵌入在多哥农田制图中的应用，结果表明其能简化工作流程并实现高精度分类，有助于更好地评估土地利用变化及其气候影响。


<details>
  <summary>Details</summary>
Motivation: 准确且最新的土地覆盖图对理解气候变化的关键驱动因素——土地利用变化至关重要，而地理空间嵌入提供了一种更高效、易获取的景观特征制图方法，但其在实际应用中的潜力尚待探索。

Method: 使用Presto和AlphaEarth生成的地理空间嵌入数据，制作多哥的农田覆盖图，并评估其在农田分类中的准确性与实用性。

Result: 地理空间嵌入能够显著简化制图工作流程，并实现高精度的农田分类。

Conclusion: 地理空间嵌入是一种有效工具，可用于支持土地利用变化及其气候影响的更优评估。

Abstract: Accurate and up-to-date land cover maps are essential for understanding land
use change, a key driver of climate change. Geospatial embeddings offer a more
efficient and accessible way to map landscape features, yet their use in
real-world mapping applications remains underexplored. In this work, we
evaluated the utility of geospatial embeddings for cropland mapping in Togo. We
produced cropland maps using embeddings from Presto and AlphaEarth. Our
findings show that geospatial embeddings can simplify workflows, achieve
high-accuracy cropland classification and ultimately support better assessments
of land use change and its climate impacts.

</details>


### [2] [Generative Hints](https://arxiv.org/abs/2511.02933)
*Andy Dimnaku,Abdullah Yusuf Kavranoğlu,Yaser Abu-Mostafa*

Main category: cs.CV

TL;DR: 提出生成式提示（generative hints）方法，利用生成模型生成虚拟样本来在整个输入空间中显式施加已知不变性，显著优于传统数据增强方法。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强仅在训练数据的变换上学习不变性，无法覆盖整个输入空间，限制了模型泛化能力。

Method: 使用在训练集上训练的生成模型近似输入分布，生成无标签的虚拟样本，并以半监督方式结合分类和提示（hint）目标进行训练，强制模型学习期望的不变性。

Result: 在多个数据集、架构和损失函数下，生成式提示 consistently 优于标准数据增强；在细粒度视觉分类任务上平均提升0.63%（最高1.78%），在CheXpert X-ray数据集上平均提升1.286%。

Conclusion: 生成式提示通过在整个输入空间中显式引入不变性，有效提升了模型性能，是一种比传统数据增强更强大的训练范式。

Abstract: Data augmentation is widely used in vision to introduce variation and
mitigate overfitting, through enabling models to learn invariant properties,
such as spatial invariance. However, these properties are not fully captured by
data augmentation alone, since it attempts to learn the property on
transformations of the training data only. We propose generative hints, a
training methodology that directly enforces known invariances in the entire
input space. Our approach leverages a generative model trained on the training
set to approximate the input distribution and generate unlabeled images, which
we refer to as virtual examples. These virtual examples are used to enforce
functional properties known as hints. In generative hints, although the
training dataset is fully labeled, the model is trained in a semi-supervised
manner on both the classification and hint objectives, using the unlabeled
virtual examples to guide the model in learning the desired hint. Across
datasets, architectures, and loss functions, generative hints consistently
outperform standard data augmentation when learning the same property. On
popular fine-grained visual classification benchmarks, we achieved up to 1.78%
top-1 accuracy improvement (0.63% on average) over fine-tuned models with data
augmentation and an average performance boost of 1.286% on the CheXpert X-ray
dataset.

</details>


### [3] [ProM3E: Probabilistic Masked MultiModal Embedding Model for Ecology](https://arxiv.org/abs/2511.02946)
*Srikumar Sastry,Subash Khanal,Aayush Dhakal,Jiayu Lin,Dan Cher,Phoenix Jarosz,Nathan Jacobs*

Main category: cs.CV

TL;DR: 提出ProM3E，一种基于掩码多模态嵌入空间重建的任意到任意生成模型，支持模态反演与跨模态检索，并展现优异的表示学习能力。


<details>
  <summary>Details</summary>
Motivation: 为生态学中的多模态表示学习提供一个灵活、可扩展的框架，能够根据部分模态推断缺失模态，并优化多模态融合策略。

Method: 采用在嵌入空间中进行掩码模态重建的方法，结合概率建模实现多模态推断与融合，提出混合跨模态和同模态相似性的新型跨模态检索方法。

Result: 模型在多种检索任务中表现优越，线性探测任务验证了其强大的表示学习能力。

Conclusion: ProM3E能有效学习生态学中的多模态表示，支持灵活的模态生成与融合，具有良好的应用潜力。

Abstract: We introduce ProM3E, a probabilistic masked multimodal embedding model for
any-to-any generation of multimodal representations for ecology. ProM3E is
based on masked modality reconstruction in the embedding space, learning to
infer missing modalities given a few context modalities. By design, our model
supports modality inversion in the embedding space. The probabilistic nature of
our model allows us to analyse the feasibility of fusing various modalities for
given downstream tasks, essentially learning what to fuse. Using these features
of our model, we propose a novel cross-modal retrieval approach that mixes
inter-modal and intra-modal similarities to achieve superior performance across
all retrieval tasks. We further leverage the hidden representation from our
model to perform linear probing tasks and demonstrate the superior
representation learning capability of our model. All our code, datasets and
model will be released at https://vishu26.github.io/prom3e.

</details>


### [4] [EvtSlowTV -- A Large and Diverse Dataset for Event-Based Depth Estimation](https://arxiv.org/abs/2511.02953)
*Sadiq Layi Macaulay,Nimet Kaygusuz,Simon Hadfield*

Main category: cs.CV

TL;DR: 提出了一种名为EvtSlowTV的大规模事件相机数据集，包含超过130亿个事件，适用于自监督深度估计学习，显著提升模型在复杂场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件的深度估计方法受限于小规模标注数据集，难以推广到真实世界场景，因此需要更大、更自然的数据集来提升模型的泛化能力。

Method: 从公开的YouTube视频中构建了大规模事件相机数据集EvtSlowTV，并采用自监督学习框架直接利用原始事件流进行训练，无需帧级标注并保持事件数据的异步特性。

Result: EvtSlowTV比现有数据集大一个数量级，实验表明使用该数据集训练的模型在复杂环境和运动下具有更强的泛化能力。

Conclusion: EvtSlowTV为基于事件的深度学习提供了更真实、更大规模的数据支持，验证了其在自监督框架下充分利用事件相机高动态范围和低延迟优势的潜力。

Abstract: Event cameras, with their high dynamic range (HDR) and low latency, offer a
promising alternative for robust depth estimation in challenging environments.
However, many event-based depth estimation approaches are constrained by
small-scale annotated datasets, limiting their generalizability to real-world
scenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event
camera dataset curated from publicly available YouTube footage, which contains
more than 13B events across various environmental conditions and motions,
including seasonal hiking, flying, scenic driving, and underwater exploration.
EvtSlowTV is an order of magnitude larger than existing event datasets,
providing an unconstrained, naturalistic setting for event-based depth
learning. This work shows the suitability of EvtSlowTV for a self-supervised
learning framework to capitalise on the HDR potential of raw event streams. We
further demonstrate that training with EvtSlowTV enhances the model's ability
to generalise to complex scenes and motions. Our approach removes the need for
frame-based annotations and preserves the asynchronous nature of event data.

</details>


### [5] [Hybrid Convolution and Vision Transformer NAS Search Space for TinyML Image Classification](https://arxiv.org/abs/2511.02992)
*Mikhael Djajapermana,Moritz Reiber,Daniel Mueller-Gritschneder,Ulf Schlichtmann*

Main category: cs.CV

TL;DR: 本文提出了一种用于神经架构搜索（NAS）的新型混合CNN-ViT搜索空间，旨在为图像分类任务找到高效且适用于tinyML部署的混合架构。


<details>
  <summary>Details</summary>
Motivation: 由于现有的CNN-ViT混合模型参数量大、计算成本高，难以部署在资源受限的tinyML设备上，因此需要设计更高效的混合架构。

Method: 构建包含混合CNN-ViT模块和可搜索池化层的新型搜索空间，利用NAS自动搜索兼顾局部与全局特征提取并高效降维的轻量级模型结构。

Result: 在CIFAR10数据集上的实验表明，所提出的搜索空间能够生成在严格模型大小限制下优于ResNet类tinyML模型的混合架构，兼具更高精度和更快推理速度。

Conclusion: 该搜索空间有效平衡了精度与效率，为tinyML应用提供了高性能的轻量级混合CNN-ViT架构设计新途径。

Abstract: Hybrids of Convolutional Neural Network (CNN) and Vision Transformer (ViT)
have outperformed pure CNN or ViT architecture. However, since these
architectures require large parameters and incur large computational costs,
they are unsuitable for tinyML deployment. This paper introduces a new hybrid
CNN-ViT search space for Neural Architecture Search (NAS) to find efficient
hybrid architectures for image classification. The search space covers hybrid
CNN and ViT blocks to learn local and global information, as well as the novel
Pooling block of searchable pooling layers for efficient feature map reduction.
Experimental results on the CIFAR10 dataset show that our proposed search space
can produce hybrid CNN-ViT architectures with superior accuracy and inference
speed to ResNet-based tinyML models under tight model size constraints.

</details>


### [6] [SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics](https://arxiv.org/abs/2511.02996)
*Ailar Mahdizadeh,Puria Azadi Moghadam,Xiangteng He,Shahriar Mirabbasi,Panos Nasiopoulos,Leonid Sigal*

Main category: cs.CV

TL;DR: 提出SCALE-VLP，一种用于CT等体数据的软加权对比视觉-语言预训练框架，结合体素空间语义与领域知识，提升跨任务和跨域的表示学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型多基于2D数据和二元监督，忽视了体数据中连续且结构化的依赖关系，难以保持空间一致性并充分利用临床语义信息。

Method: 提出SCALE-VLP框架，引入（1）体素空间语义以保持解剖结构完整性，（2）融合领域知识的语义（如放射学本体）来指导视觉-语言对齐，并采用软加权对比学习策略，在有限监督下学习结构一致且语义丰富的表示。

Result: 在CT-报告检索、异常分类和报告生成任务上显著优于先前方法：检索Top-1提升达4.3倍，分类性能提高10个百分点，报告生成ROUGE-L达0.44，BERT-F1达0.89；在外域零样本评估中仍保持一致增益，验证其良好泛化性。

Conclusion: SCALE-VLP通过整合体数据的空间结构与领域知识，在弱监督下实现了更强的跨任务迁移能力和跨域泛化能力，为医学视觉语言理解提供了有效框架。

Abstract: Vision-language models (VLMs) have demonstrated strong cross-modal
capabilities, yet most work remains limited to 2D data and assumes binary
supervision (i.e., positive vs. negative pairs), overlooking the continuous and
structured dependencies present in volumetric data such as CT. Existing
approaches often treat volumetric scans as independent 2D slices, compromising
spatial coherence and underutilizing rich clinical semantics. We propose
SCALE-VLP, a soft-weighted contrastive vision-language pre-training framework
that integrates (i) volumetric spatial semantics to preserve anatomical
structure and (ii) domain-aware, knowledge-infused semantics (e.g.,
radiological ontologies) to guide alignment. This yields structurally
consistent and semantically grounded representations under limited supervision,
demonstrating strong cross-task transferability (retrieval, report generation,
and classification), and cross-domain generalizability with consistent gains
without further fine-tuning. In particular, compared to the previous state of
the art, SCALE-VLP achieves up to 4.3x higher top-1 CT-report retrieval,
improves abnormality classification by 10 points, and reaches ROUGE-L 0.44 and
BERT-F1 0.89 for report generation. Further, in zero-shot evaluation on an
out-of-domain external dataset, we observe consistent gains, indicating the
cross-task and cross-domain generalization ability of SCALE-VLP.

</details>


### [7] [Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning](https://arxiv.org/abs/2511.03004)
*Dakota Hester,Vitor S. Martins,Lucas B. Ferreira,Thainara M. A. Lima*

Main category: cs.CV

TL;DR: 提出一种基于自监督学习的标签高效方法，仅用1,000个标注图像块实现全州范围1米分辨率土地覆盖分类。


<details>
  <summary>Details</summary>
Motivation: 深度学习语义分割在高分辨率土地覆盖分类中表现良好，但大规模标注数据的获取困难限制了其广泛应用。

Method: 采用“Bootstrap Your Own Latent”策略，利用大量无标签彩色红外航拍图像预训练ResNet-101编码器，并将学习到的权重迁移至多种语义分割模型（如U-Net等），使用少量标注数据进行微调。

Result: 在仅使用250-750个训练样本的情况下，通过集成表现最佳的U-Net模型，在密西西比州实现了87.14%的整体精度和75.58%的宏F1分数，成功完成超过1230亿像素的8类土地覆盖制图。

Conclusion: 自监督学习能有效减少对大量人工标注数据的依赖，是实现大范围高分辨率土地覆盖制图的可行方案。

Abstract: Deep learning semantic segmentation methods have shown promising performance
for very high 1-m resolution land cover classification, but the challenge of
collecting large volumes of representative training data creates a significant
barrier to widespread adoption of such models for meter-scale land cover
mapping over large areas. In this study, we present a novel label-efficient
approach for statewide 1-m land cover classification using only 1,000 annotated
reference image patches with self-supervised deep learning. We use the
"Bootstrap Your Own Latent" pre-training strategy with a large amount of
unlabeled color-infrared aerial images (377,921 256x256 1-m pixel patches) to
pre-train a ResNet-101 convolutional encoder. The learned encoder weights were
subsequently transferred into multiple deep semantic segmentation architectures
(FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN), which were then
fine-tuned using very small training dataset sizes with cross-validation (250,
500, 750 patches). Among the fine-tuned models, we obtained the 87.14% overall
accuracy and 75.58% macro F1 score using an ensemble of the best performing
U-Net models for comprehensive 1-m, 8-class land cover mapping, covering more
than 123 billion pixels over the state of Mississippi, USA. Detailed
qualitative and quantitative analysis revealed accurate mapping of open water
and forested areas, while highlighting challenges in accurate delineation
between cropland, herbaceous, and barren land cover types. These results show
that self-supervised learning is an effective strategy for reducing the need
for large volumes of manually annotated data, directly addressing a major
limitation to high spatial resolution land cover mapping at scale.

</details>


### [8] [A Foundation Model for Brain MRI with Dynamic Modality Integration](https://arxiv.org/abs/2511.03014)
*Minh Sao Khue Luu,Bair N. Tuchinov*

Main category: cs.CV

TL;DR: 提出一种适用于不同脑部MRI序列组合的通用基础模型，通过可学习的模态嵌入、条件层归一化和掩码自编码目标来处理缺失模态，并利用方差-协方差正则化提升特征多样性。


<details>
  <summary>Details</summary>
Motivation: 传统方法需为每种成像模态训练单独模型，难以应对临床中常见的模态缺失问题，因此需要一个能灵活适应不同模态组合的统一模型。

Method: 采用单一编码器架构，引入可学习的模态嵌入和条件层归一化，结合掩码自编码重建与模态补全目标进行自监督训练，并使用方差-协方差正则化稳定特征学习。

Result: 在约6万个多中心MRI数据上完成训练，初步结果显示模型能在不同模态缺失情况下有效运行，具备良好的表征灵活性和可行性。

Conclusion: 该模型能够统一处理多种MRI模态组合，支持缺失模态下的自适应推理，有望提升多中心、多模态脑部影像分析的实用性与鲁棒性。

Abstract: We present a foundation model for brain MRI that can work with different
combinations of imaging sequences. The model uses one encoder with learnable
modality embeddings, conditional layer normalization, and a masked autoencoding
objective that accounts for missing modalities. A variance-covariance
regularizer is applied to stabilize feature learning and improve representation
diversity. This design removes the need for separate models for each modality
and allows the network to adapt when some sequences are missing or unseen. It
is trained on about 60,000 multi-center MRIs using self-supervised
reconstruction and modality imputation to learn flexible representations. A
learnable modality embedding guides feature extraction so the encoder can
adjust to different inputs. We describe our planned evaluation on brain tumor
and multiple sclerosis segmentation, as well as lesion classification, under
various modality settings. Preliminary results show that the method works
feasibly, and further experiments are planned to study its performance in more
detail. All code and pretrained models are available at
https://github.com/BrainFM/brainfm

</details>


### [9] [SLIP: Structural-aware Language-Image Pretraining for Vision-Language Alignment](https://arxiv.org/abs/2511.03019)
*Wenbo Lu*

Main category: cs.CV

TL;DR: 本文提出了结构感知的语言-图像预训练方法SLIP，通过引入结构对比损失来建模实体间的关系，在大规模商品共购图数据集上实现了优于CLIP的跨模态对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言预训练方法忽略数据中自然存在的丰富关系结构（如电商中的商品共购关系），而人类认知知识具有关系图谱特性，因此需要引入结构化信息提升模型性能。

Method: 提出SLIP框架，结合结构对比损失，在对齐多模态的同时建模图中相邻实体之间的关系，并构建了大规模亚马逊商品共购多模态图数据集。

Result: 在零样本和少样本设置下的跨模态检索与分类任务中，SLIP consistently优于CLIP，验证了关系监督对跨模态对齐的有效性。

Conclusion: 引入结构化关系信息有助于提升视觉语言预训练模型的性能，揭示了利用领域结构知识的重要性。

Abstract: Vision-Language Pretraining (VLP) has achieved remarkable success across
various downstream tasks, but such gains are largely driven by scaling up on
training data. Yet, literature methods treat image-text pairs as isolated
training examples; this neglects the rich relational structure naturally
present in many domains, such as e-commerce product co-purchase graphs and
social recommendation networks. Inspired by neuroscientific evidence that human
encodes knowledge as relationship cognitive maps, we introduce Structure-aware
Language-Image Pretraining (SLIP). SLIP integrates a structural contrastive
loss to align modalities while also modeling relationships between neighboring
entities in a structured graph. To support this paradigm, we construct a
large-scale Amazon Product Co-purchase Multimodal Graph Dataset, enabling
structured cross-modality supervision at scale. Experiment results show that
SLIP consistently outperforms CLIP on cross-modal retrieval and classification
tasks in both zero-shot and few-shot settings, showing the value of relational
supervision for cross-modal alignment.

</details>


### [10] [From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth](https://arxiv.org/abs/2511.03053)
*Ziyang Xu,Olaf Wysocki,Christoph Holst*

Main category: cs.CV

TL;DR: 提出了一种基于学习的移动激光扫描点云不确定性评估框架，结合最优邻域估计与几何特征提取，减少对真实标签的依赖。


<details>
  <summary>Details</summary>
Motivation: 评估不确定性对于高精度应用至关重要，但获取真实标签成本高且不可行，因此需要减少对真实标签的依赖。

Method: 结合最优邻域估计与几何特征提取，使用XGBoost和随机森林模型预测点级不确定性（以C2C距离量化）。

Result: 在真实数据集上实验表明，所提框架可行，XGBoost模型精度与随机森林相当，但效率提高约3倍。

Conclusion: MLS点云的不确定性是可学习的，几何特征可用于预测点级不确定性，为不确定性评估研究提供了新的基于学习的视角。

Abstract: Evaluating uncertainty is critical for reliable use of Mobile Laser Scanning
(MLS) point clouds in many high-precision applications such as Scan-to-BIM,
deformation analysis, and 3D modeling. However, obtaining the ground truth (GT)
for evaluation is often costly and infeasible in many real-world applications.
To reduce this long-standing reliance on GT in uncertainty evaluation research,
this study presents a learning-based framework for MLS point clouds that
integrates optimal neighborhood estimation with geometric feature extraction.
Experiments on a real-world dataset show that the proposed framework is
feasible and the XGBoost model delivers fully comparable accuracy to Random
Forest while achieving substantially higher efficiency (about 3 times faster),
providing initial evidence that geometric features can be used to predict
point-level uncertainty quantified by the C2C distance. In summary, this study
shows that MLS point clouds' uncertainty is learnable, offering a novel
learning-based viewpoint towards uncertainty evaluation research.

</details>


### [11] [A Plug-and-Play Framework for Volumetric Light-Sheet Image Reconstruction](https://arxiv.org/abs/2511.03093)
*Yi Gong,Xinyuan Zhang,Jichen Chai,Yichen Ding,Yifei Lou*

Main category: cs.CV

TL;DR: 提出了一种结合压缩感知与光片显微镜的计算成像框架，用于高效、低光毒性的高速心脏成像，通过随机二值掩码编码和Plug-and-Play算法实现高质量图像重建。


<details>
  <summary>Details</summary>
Motivation: 传统光学成像在时空分辨率之间存在权衡，难以捕捉跳动心脏中的动态细胞结构，因此需要一种能克服该限制的高速、低光毒性成像方法。

Method: 将压缩感知（CS）与光片显微镜（LSM）结合，利用数字微镜器件（DMD）进行随机二值掩码编码实现荧光信号的压缩采集；采用基于ADMM的Plug-and-Play框架，集成Tikhonov、总变差（TV）和BM3D等先进去噪器，并引入时间正则化以保持相邻z切片间的结构连续性。

Result: 在斑马鱼心脏成像实验中，即使在高压缩比下，该方法仍能成功重建出具有优异去噪效果和清晰度的细胞结构。

Conclusion: 所提出的计算成像框架在真实世界的高速、低光生物学成像场景中表现出有效性与鲁棒性，显著提升了动态心脏组织的成像性能。

Abstract: Cardiac contraction is a rapid, coordinated process that unfolds across
three-dimensional tissue on millisecond timescales. Traditional optical imaging
is often inadequate for capturing dynamic cellular structure in the beating
heart because of a fundamental trade-off between spatial and temporal
resolution. To overcome these limitations, we propose a high-performance
computational imaging framework that integrates Compressive Sensing (CS) with
Light-Sheet Microscopy (LSM) for efficient, low-phototoxic cardiac imaging. The
system performs compressed acquisition of fluorescence signals via random
binary mask coding using a Digital Micromirror Device (DMD). We propose a
Plug-and-Play (PnP) framework, solved using the alternating direction method of
multipliers (ADMM), which flexibly incorporates advanced denoisers, including
Tikhonov, Total Variation (TV), and BM3D. To preserve structural continuity in
dynamic imaging, we further introduce temporal regularization enforcing
smoothness between adjacent z-slices. Experimental results on zebrafish heart
imaging under high compression ratios demonstrate that the proposed method
successfully reconstructs cellular structures with excellent denoising
performance and image clarity, validating the effectiveness and robustness of
our algorithm in real-world high-speed, low-light biological imaging scenarios.

</details>


### [12] [ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly](https://arxiv.org/abs/2511.03098)
*Miftahur Rahman,Samuel Adebayo,Dorian A. Acevedo-Mejia,David Hester,Daniel McPolin,Karen Rafferty,Debra F. Laefer*

Main category: cs.CV

TL;DR: 本文提出了ISC-Perception，首个专用于Intermeshed Steel Connection（ISC）组件检测的混合数据集，结合合成渲染与少量真实图像，显著降低标注成本并提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 缺乏专门的ISC图像数据集阻碍了机器人感知的发展，而在施工现场采集真实图像存在安全、隐私和后勤难题。

Method: 构建一个融合程序化CAD渲染、游戏引擎生成的逼真场景和少量精选真实照片的混合数据集，实现合成部分的全自动标注，并量化生成过程中的人力投入。

Result: 在10,000张图像的数据集中，相比手动标注节省81.7%的人力；训练的检测器在mAP@0.5上达到0.756，优于仅用合成或逼真图像的模型；在1,200帧测试中mAP@0.5达0.943。

Conclusion: ISC-Perception有效填补了建筑机器人感知领域的数据空白，支持快速开发定制化目标检测器，且可免费用于研究和工业用途。

Abstract: The Intermeshed Steel Connection (ISC) system, when paired with robotic
manipulators, can accelerate steel-frame assembly and improve worker safety by
eliminating manual assembly. Dependable perception is one of the initial stages
for ISC-aware robots. However, this is hampered by the absence of a dedicated
image corpus, as collecting photographs on active construction sites is
logistically difficult and raises safety and privacy concerns. In response, we
introduce ISC-Perception, the first hybrid dataset expressly designed for ISC
component detection. It blends procedurally rendered CAD images, game-engine
photorealistic scenes, and a limited, curated set of real photographs, enabling
fully automatic labelling of the synthetic portion. We explicitly account for
all human effort to produce the dataset, including simulation engine and scene
setup, asset preparation, post-processing scripts and quality checks; our total
human time to generate a 10,000-image dataset was 30.5,h versus 166.7,h for
manual labelling at 60,s per image (-81.7%). A manual pilot on a representative
image with five instances of ISC members took 60,s (maximum 80,s), anchoring
the manual baseline. Detectors trained on ISC-Perception achieved a mean
Average Precision at IoU 0.50 of 0.756, substantially surpassing models trained
on synthetic-only or photorealistic-only data. On a 1,200-frame bench test, we
report mAP@0.50/mAP@[0.50:0.95] of 0.943/0.823. By bridging the data gap for
construction-robotics perception, ISC-Perception facilitates rapid development
of custom object detectors and is freely available for research and industrial
use upon request.

</details>


### [13] [DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs](https://arxiv.org/abs/2511.03099)
*Yiyi Miao,Taoyu Wu,Tong Chen,Sihao Li,Ji Jiang,Youpeng Yang,Angelos Stefanidis,Limin Yu,Jionglong Su*

Main category: cs.CV

TL;DR: 本文提出DentalSplat，一种针对稀疏正畸图像的3D高斯点阵重建框架，通过先验引导的立体重建初始化点云，并结合尺度自适应剪枝与光流几何约束，显著提升了在仅三视图输入下的3D重建与新视角合成质量。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯点阵方法依赖密集多视角输入和精确相机位姿，在仅有前视及双侧颊侧三张稀疏图像的正畸场景中难以有效应用，且缺乏位姿信息导致重建质量差，因此需要一种适用于稀疏、无标定条件的高效3D重建方法。

Method: 提出DentalSplat框架：首先利用先验引导的稠密立体匹配模型初始化点云；采用尺度自适应剪枝策略优化3DGS训练效率与重建质量；在极端稀疏条件下引入光流作为几何约束，并结合梯度正则化提升渲染保真度。

Result: 在包含950个临床病例的大规模数据集及195个视频测试病例上验证，该方法在稀疏输入下实现了优于现有最先进方法的新视角合成效果，尤其在牙列咬合可视化方面表现优异。

Conclusion: DentalSplat有效解决了稀疏视图与无精确相机位姿下的正畸3D重建难题，显著提升了新视角合成质量，具有在远程正畸诊疗中广泛应用的潜力。

Abstract: In orthodontic treatment, particularly within telemedicine contexts,
observing patients' dental occlusion from multiple viewpoints facilitates
timely clinical decision-making. Recent advances in 3D Gaussian Splatting
(3DGS) have shown strong potential in 3D reconstruction and novel view
synthesis. However, conventional 3DGS pipelines typically rely on densely
captured multi-view inputs and precisely initialized camera poses, limiting
their practicality. Orthodontic cases, in contrast, often comprise only three
sparse images, specifically, the anterior view and bilateral buccal views,
rendering the reconstruction task especially challenging. The extreme sparsity
of input views severely degrades reconstruction quality, while the absence of
camera pose information further complicates the process. To overcome these
limitations, we propose DentalSplat, an effective framework for 3D
reconstruction from sparse orthodontic imagery. Our method leverages a
prior-guided dense stereo reconstruction model to initialize the point cloud,
followed by a scale-adaptive pruning strategy to improve the training
efficiency and reconstruction quality of 3DGS. In scenarios with extremely
sparse viewpoints, we further incorporate optical flow as a geometric
constraint, coupled with gradient regularization, to enhance rendering
fidelity. We validate our approach on a large-scale dataset comprising 950
clinical cases and an additional video-based test set of 195 cases designed to
simulate real-world remote orthodontic imaging conditions. Experimental results
demonstrate that our method effectively handles sparse input scenarios and
achieves superior novel view synthesis quality for dental occlusion
visualization, outperforming state-of-the-art techniques.

</details>


### [14] [Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning](https://arxiv.org/abs/2511.03120)
*Botong. Zhao,Xubin. Wang,Shujing. Lyu,Yue. Lu*

Main category: cs.CV

TL;DR: 提出了一种无需支持集的IC DefectNCD框架，利用IC SEM图像的内在先验进行缺陷检测和新类别发现，实现了对未见缺陷的有效识别与分类。


<details>
  <summary>Details</summary>
Motivation: 传统监督方法依赖大量标注数据且难以应对新兴或罕见缺陷，无监督聚类方法因缺乏先验信息而性能不稳定。

Method: 提出Self Normal Information Guided缺陷检测，通过可学习的正常信息提取器聚合正常特征，并利用重构残差粗略定位缺陷区域；引入自适应二值化策略以稳定突出核心缺陷区域；设计Self Defect Information Guided分类模块，结合软掩码引导注意力机制，将空间缺陷先验注入师生模型，提升对缺陷区域的敏感性并抑制背景干扰。

Result: 在涵盖三个关键制造阶段和15种缺陷类型的真实数据集上验证了该方法，在缺陷检测和未见缺陷分类任务中均表现出鲁棒性能。

Conclusion: IC DefectNCD框架有效结合图像内在先验，在无需支持集的情况下实现了高鲁棒性的缺陷检测与新类别发现，适用于复杂集成电路制造场景。

Abstract: Integrated circuit manufacturing is highly complex, comprising hundreds of
process steps. Defects can arise at any stage, causing yield loss and
ultimately degrading product reliability. Supervised methods require extensive
human annotation and struggle with emergent categories and rare, data scarce
defects. Clustering-based unsupervised methods often exhibit unstable
performance due to missing priors. We propose IC DefectNCD, a support set free
framework that leverages Image Intrinsic Priors in IC SEM images for defect
detection and novel class discovery. We first develop Self Normal Information
Guided IC Defect Detection, aggregating representative normal features via a
learnable normal information extractor and using reconstruction residuals to
coarsely localize defect regions. To handle saliency variations across defects,
we introduce an adaptive binarization strategy that produces stable subimages
focused on core defective areas. Finally, we design Self Defect Information
Guided IC Defect Classification, which incorporates a soft mask guided
attention mechanism to inject spatial defect priors into the teacher student
model. This enhances sensitivity to defective regions, suppresses background
interference, and enables recognition and classification of unseen defects. We
validate the approach on a real world dataset spanning three key fabrication
stages and covering 15 defect types. Experiments demonstrate robust performance
on both defect detection and unseen defect classification.

</details>


### [15] [Accelerating Physical Property Reasoning for Augmented Visual Cognition](https://arxiv.org/abs/2511.03126)
*Hongbo Lan,Zhenlin An,Haoyu Li,Vaibhav Singh,Longfei Shangguan*

Main category: cs.CV

TL;DR: 本文提出了一种名为\sysname的系统，通过算法和系统优化将视觉引导的物理属性推理延迟从10-20分钟降低到6秒以内，并在准确性和性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现增强的视觉认知，需要高效地进行物理属性推理，但现有的方法存在较高的运行时延迟问题。

Method: 结合快速几何3D重建、高效的语义特征融合以及并行视图编码等算法和系统优化手段来最小化推理管道的运行时延迟。

Result: \sysname在ABO数据集上的端到端延迟减少了62.9倍至287.2倍，同时在物体级别的物理属性估计精度方面达到或超过两个最先进的基线模型，并且在材料分割和体素级推断方面表现更优；结合眼动追踪技术，在Meta Aria眼镜的实际应用中表现出高鲁棒性。

Conclusion: \sysname显著降低了视觉引导物理属性推理的延迟，在保持甚至提升精度的同时实现了实时性能，适用于智能眼镜等实际应用场景。

Abstract: This paper introduces \sysname, a system that accelerates vision-guided
physical property reasoning to enable augmented visual cognition. \sysname
minimizes the run-time latency of this reasoning pipeline through a combination
of both algorithmic and systematic optimizations, including rapid geometric 3D
reconstruction, efficient semantic feature fusion, and parallel view encoding.
Through these simple yet effective optimizations, \sysname reduces the
end-to-end latency of this reasoning pipeline from 10--20 minutes to less than
6 seconds. A head-to-head comparison on the ABO dataset shows that \sysname
achieves this 62.9$\times$--287.2$\times$ speedup while not only reaching
on-par (and sometimes slightly better) object-level physical property
estimation accuracy(e.g. mass), but also demonstrating superior performance in
material segmentation and voxel-level inference than two SOTA baselines. We
further combine gaze-tracking with \sysname to localize the object of interest
in cluttered, real-world environments, streamlining the physical property
reasoning on smart glasses. The case study with Meta Aria Glasses conducted at
an IKEA furniture store demonstrates that \sysname achives consistently high
performance compared to controlled captures, providing robust property
estimations even with fewer views in real-world scenarios.

</details>


### [16] [Deploying Rapid Damage Assessments from sUAS Imagery for Disaster Response](https://arxiv.org/abs/2511.03132)
*Thomas Manzini,Priyankari Perali,Robin R. Murphy*

Main category: cs.CV

TL;DR: 本文提出了首个在联邦灾害响应中实际部署的基于无人机影像的建筑物损伤评估AI/ML系统，并在飓风Debby和Helene响应中成功应用。


<details>
  <summary>Details</summary>
Motivation: 应对灾害后无人机团队采集的海量影像数据超出人工分析能力，导致响应延迟，亟需自动化解决方案。

Method: 利用包含21,716个建筑损伤标签的最大已知数据集训练计算机视觉与机器学习模型，并对91名灾害从业人员进行操作培训。

Result: 最佳模型在飓风响应中约18分钟内完成了415栋建筑的损伤评估。

Conclusion: 该工作建立了基于无人机影像的损伤评估实践标准，记录了AI/ML在真实灾害响应中的应用经验，为研究与应用社区提供了宝贵借鉴。

Abstract: This paper presents the first AI/ML system for automating building damage
assessment in uncrewed aerial systems (sUAS) imagery to be deployed
operationally during federally declared disasters (Hurricanes Debby and
Helene). In response to major disasters, sUAS teams are dispatched to collect
imagery of the affected areas to assess damage; however, at recent disasters,
teams collectively delivered between 47GB and 369GB of imagery per day,
representing more imagery than can reasonably be transmitted or interpreted by
subject matter experts in the disaster scene, thus delaying response efforts.
To alleviate this data avalanche encountered in practice, computer vision and
machine learning techniques are necessary. While prior work has been deployed
to automatically assess damage in satellite imagery, there is no current state
of practice for sUAS-based damage assessment systems, as all known work has
been confined to academic settings. This work establishes the state of practice
via the development and deployment of models for building damage assessment
with sUAS imagery. The model development involved training on the largest known
dataset of post-disaster sUAS aerial imagery, containing 21,716 building damage
labels, and the operational training of 91 disaster practitioners. The best
performing model was deployed during the responses to Hurricanes Debby and
Helene, where it assessed a combined 415 buildings in approximately 18 minutes.
This work contributes documentation of the actual use of AI/ML for damage
assessment during a disaster and lessons learned to the benefit of the AI/ML
research and user communities.

</details>


### [17] [Finetuning-Free Personalization of Text to Image Generation via Hypernetworks](https://arxiv.org/abs/2511.03156)
*Sagar Shrestha,Gopal Sharma,Luowei Zhou,Suren Kumar*

Main category: cs.CV

TL;DR: 本文提出一种无需微调的个性化文本到图像生成方法，通过超网络直接从主体图像预测LoRA适配权重，并引入HM-CFG提升组合泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统个性化方法依赖计算昂贵的微调，现有适配器或编码器方法仍需额外训练或大模型支持，限制了效率与可扩展性。

Method: 设计端到端训练的超网络以预测LoRA权重，结合输出正则化稳定训练；提出混合模型无分类器引导（HM-CFG）增强推理时的组合泛化。

Result: 在CelebA-HQ、AFHQ-v2和DreamBench上实验表明，该方法在保持主体保真度和提示对齐的同时，实现了强个性化性能。

Conclusion: 超网络为开放类别个性化提供了一种高效、可扩展的新方向，无需测试时优化即可实现高质量生成。

Abstract: Personalizing text-to-image diffusion models has traditionally relied on
subject-specific fine-tuning approaches such as
DreamBooth~\cite{ruiz2023dreambooth}, which are computationally expensive and
slow at inference. Recent adapter- and encoder-based methods attempt to reduce
this overhead but still depend on additional fine-tuning or large backbone
models for satisfactory results. In this work, we revisit an orthogonal
direction: fine-tuning-free personalization via Hypernetworks that predict
LoRA-adapted weights directly from subject images. Prior hypernetwork-based
approaches, however, suffer from costly data generation or unstable attempts to
mimic base model optimization trajectories. We address these limitations with
an end-to-end training objective, stabilized by a simple output regularization,
yielding reliable and effective hypernetworks. Our method removes the need for
per-subject optimization at test time while preserving both subject fidelity
and prompt alignment. To further enhance compositional generalization at
inference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG),
which combines the compositional strengths of the base diffusion model with the
subject fidelity of personalized models during sampling. Extensive experiments
on CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves
strong personalization performance and highlights the promise of hypernetworks
as a scalable and effective direction for open-category personalization.

</details>


### [18] [Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation](https://arxiv.org/abs/2511.03163)
*Yun-Chen Lin,Jiayuan Huang,Hanyuan Zhang,Sergi Kavtaradze,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 提出一种基于深度引导的肝脏解剖标志分割框架，结合RGB和深度特征，通过改进的低秩梯度方法SRFT-GaLore高效微调SAM2，在公开和自建数据集上均表现出优越的分割精度和跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在腹腔镜肝手术中，2D视频缺乏深度感知，导致解剖标志定位困难；现有方法在融合RGB与深度特征及适应大规模视觉模型到手术场景方面仍存在挑战。

Method: 采用SAM2提取RGB特征，DA2提取深度特征，设计SRFT-GaLore方法替代SVD实现高效低秩梯度投影以微调SAM2，并通过交叉注意力模块融合多模态特征。

Result: 在L3D数据集上Dice提升4.85%，ASD降低11.78；在新建LLSD数据集上显著优于SAM基线方法，具备良好跨数据集泛化性。

Conclusion: 所提双编码器框架结合SRFT-GaLore微调策略，可在计算受限的实时手术环境中实现高精度、强鲁棒性的肝脏标志分割。

Abstract: Accurate detection and delineation of anatomical structures in medical
imaging are critical for computer-assisted interventions, particularly in
laparoscopic liver surgery where 2D video streams limit depth perception and
complicate landmark localization. While recent works have leveraged monocular
depth cues for enhanced landmark detection, challenges remain in fusing RGB and
depth features and in efficiently adapting large-scale vision models to
surgical domains. We propose a depth-guided liver landmark segmentation
framework integrating semantic and geometric cues via vision foundation
encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB
features and Depth Anything V2 (DA2) encoder to extract depth-aware features.
To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient
projection method that replaces the computationally expensive SVD with a
Subsampled Randomized Fourier Transform (SRFT). This enables efficient
fine-tuning of high-dimensional attention layers without sacrificing
representational power. A cross-attention fusion module further integrates RGB
and depth cues. To assess cross-dataset generalization, we also construct a new
Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark.
On the public L3D dataset, our method achieves a 4.85% improvement in Dice
Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface
Distance compared to the D2GPLand. To further assess generalization capability,
we evaluate our model on LLSD dataset. Our model maintains competitive
performance and significantly outperforms SAM-based baselines, demonstrating
strong cross-dataset robustness and adaptability to unseen surgical
environments. These results demonstrate that our SRFT-GaLore-enhanced
dual-encoder framework enables scalable and precise segmentation under
real-time, depth-constrained surgical settings.

</details>


### [19] [SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention](https://arxiv.org/abs/2511.03178)
*Shreyas C. Dhake,Jiayuan Huang,Runlong He,Danyal Z. Khan,Evangelos B. Mazomenos,Sophia Bano,Hani J. Marcus,Danail Stoyanov,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 本文提出了PitVQA-Anticipation，首个面向手术前瞻性推理的视觉问答数据集，以及SurgAnt-ViVQA模型，通过时序感知的视频语言建模实现手术流程的主动预测。


<details>
  <summary>Details</summary>
Motivation: 现有手术视觉问答系统多基于静态帧分析，缺乏对未来手术步骤的预测能力，且数据集聚焦当前场景而非未来事件，难以支持实时术中辅助。

Method: 构建包含33.5小时手术视频和73.5万问答对的PitVQA-Anticipation数据集，提出SurgAnt-ViVQA模型，采用GRU编码帧间动态，结合门控机制在token级别融合视觉与语言信息，并通过参数高效微调适应手术领域。

Result: SurgAnt-ViVQA在PitVQA-Anticipation和EndoVis数据集上超越多种基线模型，消融实验表明时序循环和门控融合是性能提升关键，帧数分析显示8帧最优于语言流畅性，32帧更利于时间估计。

Conclusion: 通过时序感知编码与细粒度门控交叉注意力，SurgAnt-ViVQA推动手术视觉问答从回顾性描述迈向前瞻性预判，PitVQA-Anticipation为未来感知手术辅助提供了重要基准。

Abstract: Anticipating forthcoming surgical events is vital for real-time assistance in
endonasal transsphenoidal pituitary surgery, where visibility is limited and
workflow changes rapidly. Most visual question answering (VQA) systems reason
on isolated frames with static vision language alignment, providing little
support for forecasting next steps or instrument needs. Existing surgical VQA
datasets likewise center on the current scene rather than the near future. We
introduce PitVQA-Anticipation, the first VQA dataset designed for forward
looking surgical reasoning. It comprises 33.5 hours of operative video and
734,769 question answer pairs built from temporally grouped clips and expert
annotations across four tasks: predicting the future phase, next step, upcoming
instrument, and remaining duration. We further propose SurgAnt-ViVQA, a video
language model that adapts a large language model using a GRU Gated Temporal
Cross-Attention module. A bidirectional GRU encodes frame to frame dynamics,
while an adaptive gate injects visual context into the language stream at the
token level. Parameter efficient fine tuning customizes the language backbone
to the surgical domain. SurgAnt-ViVQA tested upon on PitVQA-Anticipation and
EndoVis datasets, surpassing strong image and video based baselines. Ablations
show that temporal recurrence and gated fusion drive most of the gains. A frame
budget study indicates a trade-off: 8 frames maximize fluency, whereas 32
frames slightly reduce BLEU but improve numeric time estimation. By pairing a
temporally aware encoder with fine grained gated cross-attention, SurgAnt-ViVQA
advances surgical VQA from retrospective description to proactive anticipation.
PitVQA-Anticipation offers a comprehensive benchmark for this setting and
highlights the importance of targeted temporal modeling for reliable, future
aware surgical assistance.

</details>


### [20] [PETWB-REP: A Multi-Cancer Whole-Body FDG PET/CT and Radiology Report Dataset for Medical Imaging Research](https://arxiv.org/abs/2511.03194)
*Le Xue,Gang Feng,Wenbo Zhang,Yichi Zhang,Lanlan Li,Shuqi Wang,Liling Peng,Sisi Peng,Xin Gao*

Main category: cs.CV

TL;DR: PETWB-REP是一个包含490名多种恶性肿瘤患者全身FDG PET/CT扫描图像和对应放射学报告的大型医学影像数据集，旨在支持医学影像、放射组学、人工智能和多模态学习研究。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏整合功能与解剖成像及详细临床报告的多癌种大规模医学影像数据集，限制了AI模型开发和回顾性临床研究的发展。

Method: 收集并整理490例多种癌症患者的全身FDG PET/CT图像、去标识化文本报告和结构化临床元数据，构建一个公开可用的标准化数据集。

Result: 发布了PETWB-REP数据集，包含配对的PET与CT图像、文本报告和临床元数据，涵盖肺癌、肝癌、乳腺癌、前列腺癌和卵巢癌等常见癌症类型。

Conclusion: PETWB-REP为医学影像分析、多模态AI模型训练和临床研究提供了一个宝贵的公共资源，有助于推动癌症诊断和智能医疗的发展。

Abstract: Publicly available, large-scale medical imaging datasets are crucial for
developing and validating artificial intelligence models and conducting
retrospective clinical research. However, datasets that combine functional and
anatomical imaging with detailed clinical reports across multiple cancer types
remain scarce. Here, we present PETWB-REP, a curated dataset comprising
whole-body 18F-Fluorodeoxyglucose (FDG) Positron Emission Tomography/Computed
Tomography (PET/CT) scans and corresponding radiology reports from 490 patients
diagnosed with various malignancies. The dataset primarily includes common
cancers such as lung cancer, liver cancer, breast cancer, prostate cancer, and
ovarian cancer. This dataset includes paired PET and CT images, de-identified
textual reports, and structured clinical metadata. It is designed to support
research in medical imaging, radiomics, artificial intelligence, and
multi-modal learning.

</details>


### [21] [QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models](https://arxiv.org/abs/2511.03206)
*Kuei-Chun Kao,Hsu Tzu-Yin,Yunqi Hong,Ruochen Wang,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 提出了一种新的零样本提示方法QG-CoC，用于提升多图像场景下多模态大语言模型的细粒度感知与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有提示方法在多图像情境中缺乏细粒度感知和有效推理能力，且多数研究局限于单图像或特定场景，缺乏对复杂多图像推理任务的充分探索。

Method: 提出Question-Guided Chain-of-Captions (QG-CoC)，通过问题引导的链式描述生成机制，在任意数量的图像输入下实现感知与推理的协同。

Result: 在多个开源和闭源MLLM上验证了QG-CoC的有效性，结果表明该方法在多图像和单图像基准上均表现优异，尤其在挑战性场景中显著优于现有提示方法。

Conclusion: QG-CoC是一种通用、有效的零样本提示方法，能够显著提升MLLM在复杂多图像任务中的感知与推理整合能力。

Abstract: Recently, Multimodal Large Language Models (MLLMs) encounter two key issues
in multi-image contexts: (1) a lack of fine-grained perception across disparate
images, and (2) a diminished capability to effectively reason over and
synthesize information from multiple visual inputs. However, while various
prompting methods aim to describe visual content, many existing studies focus
primarily on single-image settings or specific, constrained scenarios. This
leaves a critical gap in understanding and addressing how MLLMs tackle more
general and complex multi-image reasoning tasks. Thus, we first extensively
investigate how current prompting methods perceive fine-grained visual details
and process visual information when dealing with multiple images. Our findings
reveal that existing prompting methods fall short in attending to needed clues
and seamlessly integrating perception and reasoning. Inspired by the findings,
we propose a new zero-shot prompting method, Question-Guided Chain-of-Captions
(QG-CoC), a generalized prompting approach that effectively handles problems
with an arbitrary number of images. We evaluate our method on various
open-source and closed-source MLLMs for multi-image and single-image
benchmarks. Experimental results indicate that QG-CoC demonstrates competitive
performance across tasks and exhibits robust improvements in the challenging
scenarios where existing prompting methods fail.

</details>


### [22] [MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction](https://arxiv.org/abs/2511.03212)
*Ruting Cheng,Boyuan Feng,Yijiang Zheng,Chuhui Qiu,Aizierjiang Aiersilan,Joaquin A. Calderon,Wentao Zhao,Qing Pan,James K. Hahn*

Main category: cs.CV

TL;DR: 本研究提出一种基于3D体形和自报医疗数据的剖宫产风险预测模型MvBody，适用于资源有限环境，具有较高准确率与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有剖宫产风险预测模型多依赖产时院内数据，在资源有限或居家环境中应用受限，亟需可在孕晚期使用且不依赖复杂医疗设备的早期预测方法。

Method: 提出一种基于多视角Transformer网络MvBody，结合自报医疗数据与孕31至38周间的3D光学体扫数据进行预测，并引入度量学习损失以提升小样本下的训练效率与泛化能力。

Result: 在独立测试集上达到84.62%准确率和0.724 AUC-ROC，优于传统机器学习及先进3D分析方法；通过集成梯度法实现模型解释，发现孕前体重、年龄、产科史、既往剖宫产史及头肩部体形为关键预测因子。

Conclusion: 基于3D体形与自报数据的MvBody模型在资源受限场景下具备应用于剖宫产风险早期预测的潜力，兼具良好性能与可解释性。

Abstract: Accurately assessing the risk of cesarean section (CS) delivery is critical,
especially in settings with limited medical resources, where access to
healthcare is often restricted. Early and reliable risk prediction allows
better-informed prenatal care decisions and can improve maternal and neonatal
outcomes. However, most existing predictive models are tailored for in-hospital
use during labor and rely on parameters that are often unavailable in
resource-limited or home-based settings. In this study, we conduct a pilot
investigation to examine the feasibility of using 3D body shape for CS risk
assessment for future applications with more affordable general devices. We
propose a novel multi-view-based Transformer network, MvBody, which predicts CS
risk using only self-reported medical data and 3D optical body scans obtained
between the 31st and 38th weeks of gestation. To enhance training efficiency
and model generalizability in data-scarce environments, we incorporate a metric
learning loss into the network. Compared to widely used machine learning models
and the latest advanced 3D analysis methods, our method demonstrates superior
performance, achieving an accuracy of 84.62% and an Area Under the Receiver
Operating Characteristic Curve (AUC-ROC) of 0.724 on the independent test set.
To improve transparency and trust in the model's predictions, we apply the
Integrated Gradients algorithm to provide theoretically grounded explanations
of the model's decision-making process. Our results indicate that pre-pregnancy
weight, maternal age, obstetric history, previous CS history, and body shape,
particularly around the head and shoulders, are key contributors to CS risk
prediction.

</details>


### [23] [Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation](https://arxiv.org/abs/2511.03219)
*Pengyu Jie,Wanquan Liu,Rui He,Yihui Wen,Deyu Meng,Chenqiang Gao*

Main category: cs.CV

TL;DR: 提出一种结合样本混合与扩散合成优势的配对扩散引导范式，通过掩码一致的配对混合（MCPMix）和真实锚定可学习退火（RLA）策略，在保持像素级语义的同时增强数据多样性，实现内窥镜图像分割性能的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法在密集预测任务中存在局限：样本混合可能导致掩码不对齐引起的标签模糊，而扩散合成虽增加多样性但忽视了掩码条件的结构优势，并引入合成-真实域偏移。

Method: 为每张真实图像生成具有相同掩码的合成图像，构成配对样本；采用MCPMix仅混合图像外观而保留原始硬掩码作为监督；通过RLA自适应调整混合强度和损失权重，逐步将优化锚定回真实数据。

Result: 在Kvasir-SEG、PICCOLO、CVC-ClinicDB、私有NPC-LES队列和ISIC 2017等多个数据集上实现了最先进的分割性能， consistently 超过基线方法。

Conclusion: 结合标签保持的混合、扩散驱动的多样性以及自适应重锚定策略，能够有效提升内窥镜图像分割的鲁棒性和泛化能力。

Abstract: Augmentation for dense prediction typically relies on either sample mixing or
generative synthesis. Mixing improves robustness but misaligned masks yield
soft label ambiguity. Diffusion synthesis increases apparent diversity but,
when trained as common samples, overlooks the structural benefit of mask
conditioning and introduces synthetic-real domain shift. We propose a paired,
diffusion-guided paradigm that fuses the strengths of both. For each real
image, a synthetic counterpart is generated under the same mask and the pair is
used as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which
mixes only image appearance while supervision always uses the original hard
mask. This produces a continuous family of intermediate samples that smoothly
bridges synthetic and real appearances under shared geometry, enlarging
diversity without compromising pixel-level semantics. To keep learning aligned
with real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the
mixing strength and the loss weight of mixed samples over training, gradually
re-anchoring optimization to real data and mitigating distributional bias.
Across Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC
2017, the approach achieves state-of-the-art segmentation performance and
consistent gains over baselines. The results show that combining
label-preserving mixing with diffusion-driven diversity, together with adaptive
re-anchoring, yields robust and generalizable endoscopic segmentation.

</details>


### [24] [Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution](https://arxiv.org/abs/2511.03232)
*Sichen Guo,Wenjie Li,Yuanyang Liu,Guangwei Gao,Jian Yang,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级超分辨率框架T-PMambaSR，结合窗口自注意力与渐进式Mamba，实现多尺度感受野的细粒度建模，并引入自适应高频增强模块恢复细节，在性能和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Mamba-based超分辨率方法在不同建模尺度间的过渡不够精细，限制了特征表示效率。

Method: 提出T-PMambaSR框架，融合窗口自注意力与渐进式Mamba以增强多尺度感受野交互，并设计自适应高频细化模块（AHFRM）恢复高频细节。

Result: 实验证明T-PMambaSR能逐步扩展感受野并提升表达能力，在更低计算成本下优于最新的Transformer和Mamba方法。

Conclusion: T-PMambaSR通过细粒度的多尺度建模和高频信息恢复，实现了高效且高性能的图像超分辨率。

Abstract: Recently, Mamba-based super-resolution (SR) methods have demonstrated the
ability to capture global receptive fields with linear complexity, addressing
the quadratic computational cost of Transformer-based SR approaches. However,
existing Mamba-based methods lack fine-grained transitions across different
modeling scales, which limits the efficiency of feature representation. In this
paper, we propose T-PMambaSR, a lightweight SR framework that integrates
window-based self-attention with Progressive Mamba. By enabling interactions
among receptive fields of different scales, our method establishes a
fine-grained modeling paradigm that progressively enhances feature
representation with linear complexity. Furthermore, we introduce an Adaptive
High-Frequency Refinement Module (AHFRM) to recover high-frequency details lost
during Transformer and Mamba processing. Extensive experiments demonstrate that
T-PMambaSR progressively enhances the model's receptive field and
expressiveness, yielding better performance than recent Transformer- or
Mamba-based methods while incurring lower computational cost. Our codes will be
released after acceptance.

</details>


### [25] [Decoupled Multi-Predictor Optimization for Inference-Efficient Model Tuning](https://arxiv.org/abs/2511.03245)
*Liwei Luo,Shuaitengyuan Li,Dongwei Ren,Qilong Wang,Pengfei Zhu,Qinghua Hu*

Main category: cs.CV

TL;DR: 提出了一种解耦多预测器优化（DMPO）方法，通过架构设计和优化策略有效分离早期层的表征能力和判别能力，提升模型推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决在大规模预训练模型微调中，早期退出机制下早期阶段难以同时为深层提供基础特征并为早期预测器提供高阶判别特征的问题。

Method: 引入轻量级旁路模块实现浅层特征的功能分解，并设计基于高阶统计信息的早期预测器；提出解耦优化策略，分两阶段分配损失权重，分别强化早期阶段的表征能力和逐步前移判别能力。

Result: 在多个数据集和预训练骨干网络上的实验表明，DMPO在降低计算成本的同时显著优于现有方法。

Conclusion: DMPO能有效解耦早期阶段的表征与判别能力，兼顾模型效率与性能，适用于高效推理场景。

Abstract: Recently, remarkable progress has been made in large-scale pre-trained model
tuning, and inference efficiency is becoming more crucial for practical
deployment. Early exiting in conjunction with multi-stage predictors, when
cooperated with a parameter-efficient fine-tuning strategy, offers a
straightforward way to achieve an inference-efficient model. However, a key
challenge remains unresolved: How can early stages provide low-level
fundamental features to deep stages while simultaneously supplying high-level
discriminative features to early-stage predictors? To address this problem, we
propose a Decoupled Multi-Predictor Optimization (DMPO) method to effectively
decouple the low-level representative ability and high-level discriminative
ability in early stages. First, in terms of architecture, we introduce a
lightweight bypass module into multi-stage predictors for functional
decomposition of shallow features from early stages, while a high-order
statistics-based predictor is developed for early stages to effectively enhance
their discriminative ability. To reasonably train our multi-predictor
architecture, a decoupled optimization is proposed to allocate two-phase loss
weights for multi-stage predictors during model tuning, where the initial
training phase enables the model to prioritize the acquisition of
discriminative ability of deep stages via emphasizing representative ability of
early stages, and the latter training phase drives discriminative ability
towards earlier stages as much as possible. As such, our DMPO can effectively
decouple representative and discriminative abilities in early stages in terms
of architecture design and model optimization. Experiments across various
datasets and pre-trained backbones demonstrate that DMPO clearly outperforms
its counterparts when reducing computational cost.

</details>


### [26] [Generative deep learning for foundational video translation in ultrasound](https://arxiv.org/abs/2511.03255)
*Nikolina Tomic Roshni Bhatnagar,Sarthak Jain,Connor Lau,Tien-Yu Liu,Laura Gambini,Rima Arnaout*

Main category: cs.CV

TL;DR: 提出一种生成式方法用于超声CDF-灰阶视频转换，显著提升数据平衡性，并在多种临床领域展示其基础应用潜力。


<details>
  <summary>Details</summary>
Motivation: 解决医学超声数据中子模态不平衡和缺失问题，提升深度学习在医疗影像中的应用效果。

Method: 采用像素级、对抗性和感知损失的双网络架构，一个用于解剖结构重建，另一个用于去噪，实现超声视频翻译。

Result: 合成视频与真实视频在分类、分割任务中表现相当（F1=0.89 vs 0.9，Dice=0.97），临床专家难以区分（准确率54±6%），SSIM达0.91±0.04，且在跨器官应用中表现稳定。

Conclusion: 该方法能生成高质量、逼真的超声视频，有效增强医疗影像数据集，拓展回顾性影像数据的应用价值。

Abstract: Deep learning (DL) has the potential to revolutionize image acquisition and
interpretation across medicine, however, attention to data imbalance and
missingness is required. Ultrasound data presents a particular challenge
because in addition to different views and structures, it includes several
sub-modalities-such as greyscale and color flow doppler (CFD)-that are often
imbalanced in clinical studies. Image translation can help balance datasets but
is challenging for ultrasound sub-modalities to date. Here, we present a
generative method for ultrasound CFD-greyscale video translation, trained on
54,975 videos and tested on 8,368. The method developed leveraged pixel-wise,
adversarial, and perceptual loses and utilized two networks: one for
reconstructing anatomic structures and one for denoising to achieve realistic
ultrasound imaging. Average pairwise SSIM between synthetic videos and ground
truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real
ones in DL classification and segmentation tasks and when evaluated by blinded
clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice
score between real and synthetic segmentation was 0.97. Overall clinician
accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%),
indicating realistic synthetic videos. Although trained only on heart videos,
the model worked well on ultrasound spanning several clinical domains (average
SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data
expand the utility of retrospectively collected imaging and augment the dataset
design toolbox for medical imaging.

</details>


### [27] [Enhancing Medical Image Segmentation via Heat Conduction Equation](https://arxiv.org/abs/2511.03260)
*Rong Wu,Yim-Sang Yu*

Main category: cs.CV

TL;DR: 提出一种结合Mamba和热传导方程的混合架构U-Mamba，用于医学图像分割，有效提升全局上下文建模与语义抽象能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在有限计算资源下难以同时实现高效的全局上下文建模和长距离依赖推理。

Method: 设计基于Mamba的状态空间模块，并在瓶颈层引入热传导算子（HCO），模拟频域热扩散以增强语义抽象。

Result: 在多模态腹部CT和MRI数据集上实验表明，该模型 consistently 优于强基线方法。

Conclusion: 结合状态空间动态与基于热传导的全局扩散是一种可扩展且可解释的医学图像分割解决方案。

Abstract: Medical image segmentation has been significantly advanced by deep learning
architectures, notably U-Net variants. However, existing models struggle to
achieve efficient global context modeling and long-range dependency reasoning
under practical computational budgets simultaneously. In this work, we propose
a novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation.
Our model combines Mamba-based state-space modules for efficient long-range
reasoning with Heat Conduction Operators (HCOs) in the bottleneck layers,
simulating frequency-domain thermal diffusion for enhanced semantic
abstraction. Experimental results on multimodal abdominal CT and MRI datasets
demonstrate that the proposed model consistently outperforms strong baselines,
validating its effectiveness and generalizability. It suggest that blending
state-space dynamics with heat-based global diffusion offers a scalable and
interpretable solution for medical segmentation tasks.

</details>


### [28] [IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection](https://arxiv.org/abs/2511.03267)
*Bingyang Guo,Hongjie Li,Ruiyun Yu,Hanzhe Liang,Jinbao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种针对真实工业场景的点云异常检测数据集IEC3D-AD，并引入了一种新的3D异常检测范式GMANet，通过几何形态分析生成合成样本并优化空间差异以提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测数据集难以捕捉真实工业环境中复杂的细微缺陷，限制了对工业设备组件精确异常检测的研究。

Method: 构建了一个来自实际生产线的高分辨率点云数据集IEC3D-AD，并提出GMANet方法，基于几何形态分析生成合成点云样本，通过空间差异优化缩小正常与异常点级特征之间的差距。

Result: 实验表明，所提方法在IEC3D-AD及其他数据集上均表现出有效的异常检测性能。

Conclusion: IEC3D-AD数据集和GMANet方法为工业设备组件的3D异常检测提供了更贴近实际、更具挑战性的研究基础，并显著提升了检测精度。

Abstract: 3D anomaly detection (3D-AD) plays a critical role in industrial
manufacturing, particularly in ensuring the reliability and safety of core
equipment components. Although existing 3D datasets like Real3D-AD and MVTec
3D-AD offer broad application support, they fall short in capturing the
complexities and subtle defects found in real industrial environments. This
limitation hampers precise anomaly detection research, especially for
industrial equipment components (IEC) such as bearings, rings, and bolts. To
address this challenge, we have developed a point cloud anomaly detection
dataset (IEC3D-AD) specific to real industrial scenarios. This dataset is
directly collected from actual production lines, ensuring high fidelity and
relevance. Compared to existing datasets, IEC3D-AD features significantly
improved point cloud resolution and defect annotation granularity, facilitating
more demanding anomaly detection tasks. Furthermore, inspired by generative
2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This
paradigm generates synthetic point cloud samples based on geometric
morphological analysis, then reduces the margin and increases the overlap
between normal and abnormal point-level features through spatial discrepancy
optimization. Extensive experiments demonstrate the effectiveness of our method
on both IEC3D-AD and other datasets.

</details>


### [29] [Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising](https://arxiv.org/abs/2511.03272)
*Shuangquan Lyu,Steven Mao,Yue Ma*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本到视频扩散模型的统一方法，用于实现任意长度的可控视频修复与扩展，通过LoRA微调和重叠融合时序去噪策略，在长视频生成中实现了高保真与一致性。


<details>
  <summary>Details</summary>
Motivation: 解决长视频生成中难以控制以及现有方法在视频修复与外补时存在拼接伪影或长度受限的问题。

Method: 采用LoRA对预训练视频扩散模型（如Wan 2.1）进行高效微调，并结合重叠融合的时序协同去噪策略与高阶求解器，以实现长序列中的时空一致性。

Result: 在数百帧的复杂修复与扩展任务中表现优异，相比Wan 2.1和VACE等基线方法，在PSNR/SSIM和LPIPS指标上均取得更优结果，且无明显接缝或漂移。

Conclusion: 该方法实现了参数高效、高质量的长视频编辑，支持任意长度生成，具有实际应用潜力。

Abstract: Generating long videos remains a fundamental challenge, and achieving high
controllability in video inpainting and outpainting is particularly demanding.
To address both of these challenges simultaneously and achieve controllable
video inpainting and outpainting for long video clips, we introduce a novel and
unified approach for long video inpainting and outpainting that extends
text-to-video diffusion models to generate arbitrarily long, spatially edited
videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a
large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked
region video synthesis, and employs an overlap-and-blend temporal co-denoising
strategy with high-order solvers to maintain consistency across long sequences.
In contrast to prior work that struggles with fixed-length clips or exhibits
stitching artifacts, our system enables arbitrarily long video generation and
editing without noticeable seams or drift. We validate our approach on
challenging inpainting/outpainting tasks including editing or adding objects
over hundreds of frames and demonstrate superior performance to baseline
methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and
perceptual realism (LPIPS). Our method enables practical long-range video
editing with minimal overhead, achieved a balance between parameter efficient
and superior performance.

</details>


### [30] [Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models](https://arxiv.org/abs/2511.03317)
*Minghao Fu,Guo-Hua Wang,Tianyu Cui,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: 提出Diffusion-SDPO，一种改进的扩散模型偏好优化方法，通过自适应缩放梯度来避免生成质量下降。


<details>
  <summary>Details</summary>
Motivation: 标准Diffusion-DPO在扩大偏好边距时可能导致优劣样本的重建误差同时增加，影响生成质量。

Method: 引入Diffusion-SDPO，采用自适应缩放机制调整劣样本梯度，保证优样本误差不增加。

Result: 在多个文本到图像基准上，Diffusion-SDPO在偏好、美学和提示对齐指标上均优于基线方法。

Conclusion: Diffusion-SDPO是一种简单、通用且高效的方法，有效解决了DPO中偏好边距扩大导致的生成退化问题。

Abstract: Text-to-image diffusion models deliver high-quality images, yet aligning them
with human preferences remains challenging. We revisit diffusion-based Direct
Preference Optimization (DPO) for these models and identify a critical
pathology: enlarging the preference margin does not necessarily improve
generation quality. In particular, the standard Diffusion-DPO objective can
increase the reconstruction error of both winner and loser branches.
Consequently, degradation of the less-preferred outputs can become sufficiently
severe that the preferred branch is also adversely affected even as the margin
grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule
that preserves the winner by adaptively scaling the loser gradient according to
its alignment with the winner gradient. A first-order analysis yields a
closed-form scaling coefficient that guarantees the error of the preferred
output is non-increasing at each optimization step. Our method is simple,
model-agnostic, broadly compatible with existing DPO-style alignment frameworks
and adds only marginal computational overhead. Across standard text-to-image
benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning
baselines on automated preference, aesthetic, and prompt alignment metrics.
Code is publicly available at https://github.com/AIDC-AI/Diffusion-SDPO.

</details>


### [31] [SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding](https://arxiv.org/abs/2511.03325)
*Mauro Orazio Drago,Luca Carlini,Pelinsu Celebi Balyemez,Dennis Pierantozzi,Chiara Lena,Cesare Hassan,Danail Stoyanov,Elena De Momi,Sophia Bano,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 本文提出了一种用于手术视频问答（VideoQA）的新模型SurgViVQA，能够利用动态视频特征而非静态图像进行视觉推理，并结合掩码视频-文本编码器与微调大语言模型生成答案。作者还构建了包含运动相关问题和诊断属性的REAL-Colon-VQA数据集，实验证明该方法在多个指标上优于现有模型，尤其在关键词准确率上有显著提升，且对问题表述变化具有更强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有手术视频问答方法多基于静态图像特征，缺乏对时间动态（如动作和器械-组织交互）的有效建模，且数据集缺少时序标注，限制了模型对手术过程的准确理解。因此，需要一种能捕捉时序信息的视频理解框架。

Method: 提出SurgViVQA模型，采用掩码视频-文本编码器融合视频与问题特征，捕获运动和工具-组织交互等时序线索，并通过微调的大语言模型解码生成答案。同时构建REAL-Colon-VQA数据集，包含运动相关问题、诊断属性及重述/语义变化的问题以评估鲁棒性。

Result: 在REAL-Colon-VQA和公开数据集EndoVis18-VQA上的实验表明，SurgViVQA在关键词准确率上分别比PitVQA提升+11%和+9%，且在问题扰动测试中表现出更强的泛化能力和鲁棒性。

Conclusion: SurgViVQA和REAL-Colon-VQA为手术视频问答提供了支持时序感知的理解框架，显著提升了对动态手术场景的建模能力，推动了AI在术中理解中的应用。

Abstract: Video Question Answering (VideoQA) in the surgical domain aims to enhance
intraoperative understanding by enabling AI models to reason over temporally
coherent events rather than isolated frames. Current approaches are limited to
static image features, and available datasets often lack temporal annotations,
ignoring the dynamics critical for accurate procedural interpretation. We
propose SurgViVQA, a surgical VideoQA model that extends visual reasoning from
static images to dynamic surgical scenes. It uses a Masked Video--Text Encoder
to fuse video and question features, capturing temporal cues such as motion and
tool--tissue interactions, which a fine-tuned large language model (LLM) then
decodes into coherent answers. To evaluate its performance, we curated
REAL-Colon-VQA, a colonoscopic video dataset that includes motion-related
questions and diagnostic attributes, as well as out-of-template questions with
rephrased or semantically altered formulations to assess model robustness.
Experimental validation on REAL-Colon-VQA and the public EndoVis18-VQA dataset
shows that SurgViVQA outperforms existing image-based VQA benchmark models,
particularly in keyword accuracy, improving over PitVQA by +11\% on
REAL-Colon-VQA and +9\% on EndoVis18-VQA. A perturbation study on the questions
further confirms improved generalizability and robustness to variations in
question phrasing. SurgViVQA and the REAL-Colon-VQA dataset provide a framework
for temporally-aware understanding in surgical VideoQA, enabling AI models to
interpret dynamic procedural contexts more effectively. Code and dataset
available at https://github.com/madratak/SurgViVQA.

</details>


### [32] [Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge](https://arxiv.org/abs/2511.03332)
*Yi Yang,Yiming Xu,Timo Kaiser,Hao Cheng,Bodo Rosenhahn,Michael Ying Yang*

Main category: cs.CV

TL;DR: 本文提出了一种用于MOT25-Spatiotemporal Action Grounding挑战的两阶段零样本方法，结合FastTracker和LLaVA-Video模型，在测试集上取得了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 准确在复杂真实场景视频中定位并追踪符合特定自由形式语言查询的多个目标。

Method: 将任务建模为视频检索问题，采用两阶段零样本方法，结合SOTA追踪模型FastTracker和多模态大语言模型LLaVA-Video。

Result: 在MOT25-StAG测试集上，m-HIoU得分为20.68，HOTA得分为10.73。

Conclusion: 所提方法有效结合了先进追踪与多模态语言模型，在挑战中表现优异，获得第二名。

Abstract: In this report, we present our solution to the MOT25-Spatiotemporal Action
Grounding (MOT25-StAG) Challenge. The aim of this challenge is to accurately
localize and track multiple objects that match specific and free-form language
queries, using video data of complex real-world scenes as input. We model the
underlying task as a video retrieval problem and present a two-stage, zero-shot
approach, combining the advantages of the SOTA tracking model FastTracker and
Multi-modal Large Language Model LLaVA-Video. On the MOT25-StAG test set, our
method achieves m-HIoU and HOTA scores of 20.68 and 10.73 respectively, which
won second place in the challenge.

</details>


### [33] [UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions](https://arxiv.org/abs/2511.03334)
*Guozhen Zhang,Zixiang Zhou,Teng Hu,Ziqiao Peng,Youliang Zhang,Yi Chen,Yuan Zhou,Qinglin Lu,Limin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为UniAVGen的统一音频-视频生成框架，通过双分支扩散Transformer架构和不对称跨模态交互机制，实现精确的时空同步与语义一致性，在较少训练数据下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有开源音视频生成方法因跨模态建模不足，常出现口型不同步和语义不一致问题。

Method: 采用双分支Diffusion Transformer构建联合潜在空间，引入不对称跨模态交互机制实现双向时序对齐的交叉注意力，并结合人脸感知调制模块和模态感知无分类器引导策略提升生成质量。

Result: 实验表明，UniAVGen在仅使用1.3M训练样本（远少于对比方法的30.1M）的情况下，在音视频同步性、音色一致性和情感一致性方面均优于现有方法。

Conclusion: UniAVGen通过统一的联合生成架构，有效解决了跨模态生成中的同步与语义一致性问题，支持多种关键音视频任务的无缝集成。

Abstract: Due to the lack of effective cross-modal modeling, existing open-source
audio-video generation methods often exhibit compromised lip synchronization
and insufficient semantic consistency. To mitigate these drawbacks, we propose
UniAVGen, a unified framework for joint audio and video generation. UniAVGen is
anchored in a dual-branch joint synthesis architecture, incorporating two
parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent
space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which
enables bidirectional, temporally aligned cross-attention, thus ensuring
precise spatiotemporal synchronization and semantic consistency. Furthermore,
this cross-modal interaction is augmented by a Face-Aware Modulation module,
which dynamically prioritizes salient regions in the interaction process. To
enhance generative fidelity during inference, we additionally introduce
Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly
amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint
synthesis design enables seamless unification of pivotal audio-video tasks
within a single model, such as joint audio-video generation and continuation,
video-to-audio dubbing, and audio-driven video synthesis. Comprehensive
experiments validate that, with far fewer training samples (1.3M vs. 30.1M),
UniAVGen delivers overall advantages in audio-video synchronization, timbre
consistency, and emotion consistency.

</details>


### [34] [Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2511.03367)
*Gahyeon Kim,Sohee Kim,Seokju Lee*

Main category: cs.CV

TL;DR: 本文提出了一种新的提示学习方法AAPL，通过引入对抗性标记嵌入来解耦数据增强带来的表面视觉变化与类别相关的语义表示，从而提升模型在零样本、少样本及跨域场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的提示学习方法在面对完全未见的类别时泛化能力有限，且主要依赖文本层面的改进，图像层面的数据增强潜力未被充分挖掘；同时缺乏对语义相关视觉特征学习的显式引导。

Method: 提出AAPL方法，利用属性特定的图像增强策略，并引入对抗性令牌嵌入，在软提示框架中分离表面视觉变异和语义特征，使提示更关注判别性视觉特征。

Result: 在11个基准数据集上进行了实验，AAPL在少样本、零样本、跨数据集和领域泛化设置下均优于现有方法。

Conclusion: AAPL通过解耦增强引起的表面变化与语义信息，有效提升了提示学习的泛化性能，展示了图像增强与提示学习结合的潜力。

Abstract: Recent advances in large-scale vision and language models have led to
significant progress in zero-shot learning tasks. Methods such as CoOp and
CoCoOp have shown that replacing handcrafted prompts with learnable vectors,
known as prompt learning, can result in improved performance. However, these
models often struggle to generalize to entirely unseen categories. While
traditional zero-shot learning techniques benefit from various data
augmentation strategies, prompt learning has primarily focused on text-based
modifications, leaving the potential of image-based augmentation largely
unexplored. In this work, we explore how image-level augmentations,
particularly those that introduce attribute-specific variations, can support
and enhance prompt learning. Our analysis examines the interaction between
these augmentations and soft prompt frameworks, revealing their potential to
improve generalization. We also identify a limitation in existing methods, such
as CoCoOp, which do not provide explicit guidance for learning prompts that
focus on semantically meaningful visual features. To address this, we propose
Adding Attributes to Prompt Learning, AAPL, a novel method that introduces
adversarial token embeddings to decouple superficial visual variations
introduced by augmentation from class-relevant semantic representations. This
decoupling enables the learned prompts to concentrate on visually
discriminative features that align with the target categories. We conduct
comprehensive experiments on eleven benchmark datasets, and AAPL consistently
outperforms existing methods across few-shot, zero-shot, cross-dataset, and
domain generalization settings. Our source code is publicly available at:
https://github.com/Gahyeonkim09/AAPL

</details>


### [35] [Robust Alignment of the Human Embryo in 3D Ultrasound using PCA and an Ensemble of Heuristic, Atlas-based and Learning-based Classifiers Evaluated on the Rotterdam Periconceptional Cohort](https://arxiv.org/abs/2511.03416)
*Nikolai Herrmann,Marcella C. Zijta,Stefan Klein,Régine P. M. Steegers-Theunissen,Rene M. H. Wijnen,Bernadette S. de Bakker,Melek Rousian,Wietske A. P. Bastiaansen*

Main category: cs.CV

TL;DR: 提出了一种基于PCA的自动化方法，用于在三维超声图像中标准化胚胎对齐，通过三种策略选择标准方向，在大规模数据上实现了高达98.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 标准化胚胎对齐有助于产前生长监测、标准平面检测和跨扫描比较，但手动对齐效率低且不一致，因此需要自动化方法。

Method: 基于胚胎分割掩膜应用主成分分析（PCA）提取主轴，生成四个候选方向，并通过Pearson相关性启发式、图谱匹配（归一化互相关）和随机森林分类器三种策略之一选择标准方向，最终采用多数投票提升准确性。

Result: 在1043个妊娠的2166幅3D超声图像上测试，PCA在99.0%的图像中正确提取主轴；三种选择策略的准确率分别为97.4%、95.8%和98.4%，多数投票达到98.5%准确率。

Conclusion: 该方法能高效、准确地实现早孕期胚胎的三维自动对齐，适用于临床和科研中的大规模图像分析，代码已公开。

Abstract: Standardized alignment of the embryo in three-dimensional (3D) ultrasound
images aids prenatal growth monitoring by facilitating standard plane
detection, improving visualization of landmarks and accentuating differences
between different scans. In this work, we propose an automated method for
standardizing this alignment. Given a segmentation mask of the embryo,
Principal Component Analysis (PCA) is applied to the mask extracting the
embryo's principal axes, from which four candidate orientations are derived.
The candidate in standard orientation is selected using one of three
strategies: a heuristic based on Pearson's correlation assessing shape, image
matching to an atlas through normalized cross-correlation, and a Random Forest
classifier. We tested our method on 2166 images longitudinally acquired 3D
ultrasound scans from 1043 pregnancies from the Rotterdam Periconceptional
Cohort, ranging from 7+0 to 12+6 weeks of gestational age. In 99.0% of images,
PCA correctly extracted the principal axes of the embryo. The correct candidate
was selected by the Pearson Heuristic, Atlas-based and Random Forest in 97.4%,
95.8%, and 98.4% of images, respectively. A Majority Vote of these selection
methods resulted in an accuracy of 98.5%. The high accuracy of this pipeline
enables consistent embryonic alignment in the first trimester, enabling
scalable analysis in both clinical and research settings. The code is publicly
available at:
https://gitlab.com/radiology/prenatal-image-analysis/pca-3d-alignment.

</details>


### [36] [Generalizing Shape-from-Template to Topological Changes](https://arxiv.org/abs/2511.03459)
*Kevin Manogue,Tomasz M Schang,Dilara Kuş,Jonas Müller,Stefan Zachow,Agniva Sengupta*

Main category: cs.CV

TL;DR: 提出了一种能够处理拓扑变化的Shape-from-Template（SfT）扩展方法，通过迭代优化模板分区来实现对撕裂和切割等变形的鲁棒重建。


<details>
  <summary>Details</summary>
Motivation: 现有SfT方法在面对伴随拓扑变化的形变时失效，无法准确重建可变形物体表面。

Method: 基于经典SfT初始化，通过划分模板空间域并最小化联合编码物理合理性和重投影一致性的能量函数，迭代调整模板。

Result: 成功实现了对包含撕裂、切割等拓扑事件的可变形表面的重建，在合成和真实数据上均优于基线方法。

Conclusion: 该方法建立了首个支持拓扑变化感知的通用SfT框架，显著提升了复杂形变下的重建鲁棒性。

Abstract: Reconstructing the surfaces of deformable objects from correspondences
between a 3D template and a 2D image is well studied under Shape-from-Template
(SfT) methods; however, existing approaches break down when topological changes
accompany the deformation. We propose a principled extension of SfT that
enables reconstruction in the presence of such changes. Our approach is
initialized with a classical SfT solution and iteratively adapts the template
by partitioning its spatial domain so as to minimize an energy functional that
jointly encodes physical plausibility and reprojection consistency. We
demonstrate that the method robustly captures a wide range of practically
relevant topological events including tears and cuts on bounded 2D surfaces,
thereby establishing the first general framework for topological-change-aware
SfT. Experiments on both synthetic and real data confirm that our approach
consistently outperforms baseline methods.

</details>


### [37] [Human Mesh Modeling for Anny Body](https://arxiv.org/abs/2511.03589)
*Romain Brégier,Guénolé Fiche,Laura Bravo-Sánchez,Thomas Lucas,Matthieu Armando,Philippe Weinzaepfel,Grégory Rogez,Fabien Baradel*

Main category: cs.CV

TL;DR: 本文提出了Anny，一种简单、完全可微且无需3D扫描的人体模型，基于人类测量学知识构建，支持跨年龄、体型和比例的可控人体形态生成，并通过WHO统计数据校准，具有开放性和语义可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有参数化人体模型依赖昂贵的3D扫描和狭窄人群的私有形状空间，缺乏开放性与多样性。

Method: 基于MakeHuman社区的人类测量学知识，设计一个连续且可解释的形状空间，使用表型参数（如性别、年龄、身高、体重）控制blendshapes，并利用WHO人口统计数据进行校准。

Result: Anny实现了毫米级精度的扫描拟合、可控的合成数据生成和人体网格恢复（HMR）；基于Anny生成的Anny-One数据集（80万张逼真图像）训练的HMR模型性能媲美基于扫描的模型。

Conclusion: Anny是一种开放、可解释且具广泛代表性的人体建模基础，在多样性和实用性之间取得平衡，代码遵循Apache 2.0许可发布。

Abstract: Parametric body models are central to many human-centric tasks, yet existing
models often rely on costly 3D scans and learned shape spaces that are
proprietary and demographically narrow. We introduce Anny, a simple, fully
differentiable, and scan-free human body model grounded in anthropometric
knowledge from the MakeHuman community. Anny defines a continuous,
interpretable shape space, where phenotype parameters (e.g. gender, age,
height, weight) control blendshapes spanning a wide range of human forms --
across ages (from infants to elders), body types, and proportions. Calibrated
using WHO population statistics, it provides realistic and demographically
grounded human shape variation within a single unified model. Thanks to its
openness and semantic control, Anny serves as a versatile foundation for 3D
human modeling -- supporting millimeter-accurate scan fitting, controlled
synthetic data generation, and Human Mesh Recovery (HMR). We further introduce
Anny-One, a collection of 800k photorealistic humans generated with Anny,
showing that despite its simplicity, HMR models trained with Anny can match the
performance of those trained with scan-based body models, while remaining
interpretable and broadly representative. The Anny body model and its code are
released under the Apache 2.0 license, making Anny an accessible foundation for
human-centric 3D modeling.

</details>


### [38] [Signal Intensity-weighted coordinate channels improve learning stability and generalisation in 1D and 2D CNNs in localisation tasks on biomedical signals](https://arxiv.org/abs/2511.03645)
*Vittal L. Rao*

Main category: cs.CV

TL;DR: 提出了一种基于信号强度加权的坐标表示方法，通过将局部信号强度与坐标耦合，提升了生物医学数据定位任务中的收敛速度和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统CoordConv仅使用绝对坐标，未考虑信号强度分布对位置感知的影响，难以有效捕捉复杂生物医学信号中的空间或时间关系。

Method: 在输入中用局部信号强度加权的坐标通道替代纯坐标通道，将强度-位置耦合直接嵌入输入表示，形成一种简单且模态无关的归纳偏置。

Result: 在ECG信号形态转换时间预测和细胞图像核中心定位两个任务中，新方法相比传统坐标通道方法具有更快的收敛速度和更高的泛化性能。

Conclusion: 信号强度加权的坐标表示能有效提升生物医学信号中定位任务的性能，适用于一维和二维信号，具有良好的通用性。

Abstract: Localisation tasks in biomedical data often require models to learn
meaningful spatial or temporal relationships from signals with complex
intensity distributions. A common strategy, exemplified by CoordConv layers, is
to append coordinate channels to convolutional inputs, enabling networks to
learn absolute positions. In this work, we propose a signal intensity-weighted
coordinate representation that replaces the pure coordinate channels with
channels scaled by local signal intensity. This modification embeds an
intensity-position coupling directly in the input representation, introducing a
simple and modality-agnostic inductive bias. We evaluate the approach on two
distinct localisation problems: (i) predicting the time of morphological
transition in 20-second, two-lead ECG signals, and (ii) regressing the
coordinates of nuclear centres in cytological images from the SiPaKMeD dataset.
In both cases, the proposed representation yields faster convergence and higher
generalisation performance relative to conventional coordinate-channel
approaches, demonstrating its effectiveness across both one-dimensional and
two-dimensional biomedical signals.

</details>


### [39] [A Lightweight 3D-CNN for Event-Based Human Action Recognition with Privacy-Preserving Potential](https://arxiv.org/abs/2511.03665)
*Mehdi Sefidgar Dilmaghani,Francis Fowley,Peter Corcoran*

Main category: cs.CV

TL;DR: 提出一种轻量级3D卷积神经网络，利用事件相机数据进行人体活动识别，兼顾隐私保护、高精度与边缘设备部署需求。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的摄像头会捕获可识别的个人信息，存在隐私泄露风险；事件相机仅记录像素变化，具有天然隐私保护优势，因此探索基于事件数据的人体活动识别方法。

Method: 设计一种轻量级3D卷积神经网络，结合焦点损失与类别重加权、针对性数据增强策略，以建模时空特征并缓解类别不平衡问题。

Result: 在Toyota Smart Home与ETRI组合数据集上，模型取得94.15%的F1分数和94.17%的整体准确率，性能优于C3D、ResNet3D和MC3_18等基准模型达3%。

Conclusion: 基于事件相机的深度学习方法在人体活动识别中具有高精度、高效率和良好隐私保护能力，适合实际边缘应用场景。

Abstract: This paper presents a lightweight three-dimensional convolutional neural
network (3DCNN) for human activity recognition (HAR) using event-based vision
data. Privacy preservation is a key challenge in human monitoring systems, as
conventional frame-based cameras capture identifiable personal information. In
contrast, event cameras record only changes in pixel intensity, providing an
inherently privacy-preserving sensing modality. The proposed network
effectively models both spatial and temporal dynamics while maintaining a
compact design suitable for edge deployment. To address class imbalance and
enhance generalization, focal loss with class reweighting and targeted data
augmentation strategies are employed. The model is trained and evaluated on a
composite dataset derived from the Toyota Smart Home and ETRI datasets.
Experimental results demonstrate an F1-score of 0.9415 and an overall accuracy
of 94.17%, outperforming benchmark 3D-CNN architectures such as C3D, ResNet3D,
and MC3_18 by up to 3%. These results highlight the potential of event-based
deep learning for developing accurate, efficient, and privacy-aware human
action recognition systems suitable for real-world edge applications.

</details>


### [40] [Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection](https://arxiv.org/abs/2511.03666)
*Dongkeun Kim,Minsu Cho,Suha Kwak*

Main category: cs.CV

TL;DR: 提出一种基于身体部位特征和人际关联的细粒度社交互动检测方法，通过部分感知的自下而上推理框架，在NVI数据集上实现了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略面部表情、视线和手势等细微社交线索，且未显式建模个体间的交互关系，导致难以准确捕捉局部社交信号并产生群体配置歧义。

Method: 采用部分感知的自下而上群组推理框架，首先检测个体并利用身体部位线索增强特征，然后通过结合空间关系和细微社交线索的相似性推理关联个体，推断群体结构。

Result: 在NVI数据集上的实验表明，该方法优于先前方法，显著提升了细粒度社交互动检测的准确性。

Conclusion: 该方法能更精确地从细微社交线索中推断社交群体和互动，为社交互动检测提供了更有效的解决方案。

Abstract: Social interactions often emerge from subtle, fine-grained cues such as
facial expressions, gaze, and gestures. However, existing methods for social
interaction detection overlook such nuanced cues and primarily rely on holistic
representations of individuals. Moreover, they directly detect social groups
without explicitly modeling the underlying interactions between individuals.
These drawbacks limit their ability to capture localized social signals and
introduce ambiguity when group configurations should be inferred from social
interactions grounded in nuanced cues. In this work, we propose a part-aware
bottom-up group reasoning framework for fine-grained social interaction
detection. The proposed method infers social groups and their interactions
using body part features and their interpersonal relations. Our model first
detects individuals and enhances their features using part-aware cues, and then
infers group configuration by associating individuals via similarity-based
reasoning, which considers not only spatial relations but also subtle social
cues that signal interactions, leading to more accurate group inference.
Experiments on the NVI dataset demonstrate that our method outperforms prior
methods, achieving the new state of the art.

</details>


### [41] [Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition](https://arxiv.org/abs/2511.03725)
*Jongseo Lee,Wooil Lee,Gyeong-Moon Park,Seong Tae Kim,Jinwoo Choi*

Main category: cs.CV

TL;DR: 提出DANCE框架，通过解耦动作和上下文概念（运动动态、物体、场景）提升视频动作识别模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于显著性的方法产生纠缠的解释，难以区分模型预测依赖于运动还是空间上下文；语言方法难以描述隐式的运动信息。

Method: 定义运动动态为人体姿态序列，使用大语言模型提取物体和场景概念，采用ante-hoc概念瓶颈结构强制通过这些概念进行预测。

Result: 在KTH、Penn Action、HAA500和UCF-101四个数据集上验证了DANCE在解释清晰度上的显著提升，并具有竞争力的性能；用户研究表明其可解释性更好，且有助于模型调试、编辑和故障分析。

Conclusion: DANCE通过解耦不同类型的概念有效提升了视频动作识别模型的可解释性，同时保持良好性能，具备实际应用价值。

Abstract: Effective explanations of video action recognition models should disentangle
how movements unfold over time from the surrounding spatial context. However,
existing methods based on saliency produce entangled explanations, making it
unclear whether predictions rely on motion or spatial context. Language-based
approaches offer structure but often fail to explain motions due to their tacit
nature -- intuitively understood but difficult to verbalize. To address these
challenges, we propose Disentangled Action aNd Context concept-based
Explainable (DANCE) video action recognition, a framework that predicts actions
through disentangled concept types: motion dynamics, objects, and scenes. We
define motion dynamics concepts as human pose sequences. We employ a large
language model to automatically extract object and scene concepts. Built on an
ante-hoc concept bottleneck design, DANCE enforces prediction through these
concepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101
-- demonstrate that DANCE significantly improves explanation clarity with
competitive performance. We validate the superior interpretability of DANCE
through a user study. Experimental results also show that DANCE is beneficial
for model debugging, editing, and failure analysis.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [42] [Cache Mechanism for Agent RAG Systems](https://arxiv.org/abs/2511.02919)
*Shuhang Lin,Zhencan Peng,Lingyao Li,Xiao Lin,Xi Zhu,Yongfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出了ARC（Agent RAG Cache Mechanism），一种无需标注的动态缓存框架，通过结合历史查询分布和嵌入空间中缓存项的几何结构，为每个LLM代理维护小而高价值的知识子集，在大幅降低存储开销的同时保持高检索准确率和低延迟。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）提升了大语言模型代理的性能，但针对代理级别的缓存管理——特别是如何动态构建、维护和更新紧凑且相关的知识库——仍缺乏研究。现有方法难以在有限存储下保持高检索效果和效率。

Method: 提出ARC框架，利用历史查询分布模式与缓存项在嵌入空间中的内在几何结构，动态筛选和更新高相关性的小规模缓存子集，实现无需人工标注的自动化缓存管理。

Result: 在三个检索数据集上的实验表明，ARC将存储需求降至原始语料库的0.015%，最高实现79.8%的有答案率，并将平均检索延迟降低80%。

Conclusion: ARC能显著提升RAG驱动的LLM代理在效率与有效性方面的表现，为代理级知识缓存提供了可扩展且高效的解决方案。

Abstract: Recent advances in Large Language Model (LLM)-based agents have been
propelled by Retrieval-Augmented Generation (RAG), which grants the models
access to vast external knowledge bases. Despite RAG's success in improving
agent performance, agent-level cache management, particularly constructing,
maintaining, and updating a compact, relevant corpus dynamically tailored to
each agent's need, remains underexplored. Therefore, we introduce ARC (Agent
RAG Cache Mechanism), a novel, annotation-free caching framework that
dynamically manages small, high-value corpora for each agent. By synthesizing
historical query distribution patterns with the intrinsic geometry of cached
items in the embedding space, ARC automatically maintains a high-relevance
cache. With comprehensive experiments on three retrieval datasets, our
experimental results demonstrate that ARC reduces storage requirements to
0.015% of the original corpus while offering up to 79.8% has-answer rate and
reducing average retrieval latency by 80%. Our results demonstrate that ARC can
drastically enhance efficiency and effectiveness in RAG-powered LLM agents.

</details>


### [43] [Automatic Machine Translation Detection Using a Surrogate Multilingual Translation Model](https://arxiv.org/abs/2511.02958)
*Cristian García-Romero,Miquel Esplà-Gomis,Felipe Sánchez-Martínez*

Main category: cs.CL

TL;DR: 提出一种利用替代多语言机器翻译模型内部表示来区分人类和机器翻译句子的新方法，在非英语语对上显著优于现有技术，准确率提升至少5个百分点。


<details>
  <summary>Details</summary>
Motivation: 由于训练数据中存在大量机器生成的翻译文本，过度依赖这些合成内容会显著降低翻译质量，因此需要有效过滤非人类翻译以提升机器翻译系统性能。

Method: 利用一个代理多语言机器翻译模型的内部表示来区分人类翻译和机器翻译的句子。

Result: 实验结果表明，该方法在非英语语言对上的表现优于当前最先进的技术，准确率至少提高5个百分点。

Conclusion: 该方法能有效识别机器生成的翻译，有助于提升机器翻译系统训练数据的质量，特别是在资源较少的语言对上具有优势。

Abstract: Modern machine translation (MT) systems depend on large parallel corpora,
often collected from the Internet. However, recent evidence indicates that (i)
a substantial portion of these texts are machine-generated translations, and
(ii) an overreliance on such synthetic content in training data can
significantly degrade translation quality. As a result, filtering out non-human
translations is becoming an essential pre-processing step in building
high-quality MT systems. In this work, we propose a novel approach that
directly exploits the internal representations of a surrogate multilingual MT
model to distinguish between human and machine-translated sentences.
Experimental results show that our method outperforms current state-of-the-art
techniques, particularly for non-English language pairs, achieving gains of at
least 5 percentage points of accuracy.

</details>


### [44] [LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation](https://arxiv.org/abs/2511.03001)
*Gyeom Hwangbo,Hyungjoo Chae,Minseok Kang,Hyeonjong Ju,Soohyun Oh,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 本文提出了LEGO-Eval评估框架和LEGO-Bench基准，用于更准确地评估细粒度指令与生成的3D场景之间的对齐程度，实验表明现有方法在生成完全对齐的场景方面成功率不足10%。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景生成方法因指令粗略而导致场景缺乏真实的空间布局和对象属性，进而影响具身智能体的学习效果；同时现有评估方法（如CLIPScore和视觉语言模型）难以可靠评估细粒度指令与场景的对齐。

Method: 提出LEGO-Eval评估框架，结合多种工具显式地对场景组件进行定位，并构建LEGO-Bench基准，包含描述真实环境复杂布局和属性的详细指令，以更准确评估3D场景生成的质量。

Result: LEGO-Eval在评估场景-指令对齐性上比基于VLM的方法F1分数高出0.41；使用LEGO-Bench基准测试发现当前生成方法最多只有10%的成功率能完全对齐细粒度指令。

Conclusion: 为了提升3D场景生成的真实性和对具身智能体训练的有效性，需采用更细粒度的指令和更精准的评估方法，LEGO-Eval与LEGO-Bench为此提供了有效解决方案。

Abstract: Despite recent progress in using Large Language Models (LLMs) for
automatically generating 3D scenes, generated scenes often lack realistic
spatial layouts and object attributes found in real-world environments. As this
problem stems from insufficiently detailed, coarse-grained instructions,
advancing 3D scene synthesis guided by more detailed, fine-grained instructions
that reflect real-world environments becomes crucial. Without such realistic
scenes, training embodied agents in unrealistic environments can lead them to
learn priors that diverge significantly from real-world physics and semantics,
degrading their performance when deployed. Thus, verifying the alignment
between the fine-grained instruction and the generated scene is essential for
effective learning. However, current evaluation methods, such as CLIPScore and
vision-language models (VLMs), often fail to reliably assess such alignment.
This shortcoming arises primarily from their shallow understanding of 3D
scenes, which often leads to improperly grounded scene components. To address
this, we introduce LEGO-Eval, an evaluation framework equipped with diverse
tools designed to explicitly ground scene components, enabling more accurate
alignment assessments. We also present LEGO-Bench, a benchmark of detailed
instructions that specify complex layouts and attributes of real-world
environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge
by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with
LEGO-Bench reveals significant limitations in current generation methods.
Across all evaluated approaches, success rates reached at most 10% in
generating scenes that fully align with fine-grained instructions.

</details>


### [45] [Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT](https://arxiv.org/abs/2511.03005)
*Hee-Jin Lee,Zhen Guo,Luchao Jin,Morteza Moazami Goudarzi*

Main category: cs.CL

TL;DR: 提出了一种Analyze-Revise-Finetune (ARF) 管道，利用小规模开源语言模型在客服摘要任务中超越大型专有模型。


<details>
  <summary>Details</summary>
Motivation: 提升开源小模型在特定任务上的性能，同时降低成本和保护数据隐私。

Method: 通过分析GPT-3.5生成摘要的常见错误，使用Llama 3.1 70B作为编辑器模型进行针对性修正，生成高质量训练数据，并用其微调Llama 3.1 8B模型。

Result: 微调后的较小模型在摘要任务上表现优于GPT-3.5，且具备更高成本效益和数据隐私保障。

Conclusion: ARF管道为增强开源语言模型提供了一个可推广的框架，适用于多种下游应用。

Abstract: We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller
open-source language models (LLMs) to surpass substantially larger proprietary
models in customer service summarization tasks. The pipeline first analyzes and
categorizes common errors in summaries produced by a teacher model (GPT-3.5),
then performs a targeted revision using a compact editor model (Llama 3.1 70B)
to generate high-quality, refined training data. Fine-tuning a smaller student
model (Llama 3.1 8B) on this refined data resulted in superior summarization
performance compared to GPT-3.5. The ARF pipeline improves cost efficiency and
data privacy while maintaining competitive accuracy, illustrating a
generalizable framework for enhancing open-source LLMs across diverse
downstream applications.

</details>


### [46] [Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2511.03034)
*Yan Cathy Hua,Paul Denny,Jörg Wicker,Katerina Taškova*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估方法FTS-OBP，并研究了小规模生成语言模型在教育评论ABSA任务中的应用，通过多任务微调策略显著提升性能，同时发布了首个公开的教育评论ABSA资源集。


<details>
  <summary>Details</summary>
Motivation: 现有ABSA研究集中于商业领域，缺乏对教育和医疗等低资源领域的支持，且传统评估方法过于严格，难以准确评价生成模型的表现。

Method: 提出FTS-OBP评估方法以容忍提取边界的合理变化；研究小规模解码器-only生成模型在数据免费和轻量数据场景下的表现；采用多任务微调策略提升模型性能。

Result: FTS-OBP与传统指标高度相关且提供细粒度诊断；1.5-3.8B参数的模型在仅使用200-1000个样本的情况下超越专有大模型并接近基准结果；发布首个公开的教育评论ABSA数据集。

Conclusion: 该工作推动了低资源领域ABSA的发展，展示了小模型在有限数据下的高效适应能力，并提供了新评估方法和开放资源以促进后续研究。

Abstract: Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining
approach that identifies and classifies opinions associated with specific
entities (aspects) or their categories within a sentence. Despite its rapid
growth and broad potential, ABSA research and resources remain concentrated in
commercial domains, leaving analytical needs unmet in high-demand yet
low-resource areas such as education and healthcare. Domain adaptation
challenges and most existing methods' reliance on resource-intensive
in-training knowledge injection further hinder progress in these areas.
Moreover, traditional evaluation methods based on exact matches are overly
rigid for ABSA tasks, penalising any boundary variations which may misrepresent
the performance of generative models. This work addresses these gaps through
three contributions: 1) We propose a novel evaluation method, Flexible Text
Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates
realistic extraction boundary variations while maintaining strong correlation
with traditional metrics and offering fine-grained diagnostics. 2) We present
the first ABSA study of small decoder-only generative language models (SLMs;
<7B parameters), examining resource lower bounds via a case study in education
review ABSA. We systematically explore data-free (in-context learning and
weight merging) and data-light fine-tuning methods, and propose a multitask
fine-tuning strategy that significantly enhances SLM performance, enabling
1.5-3.8 B models to surpass proprietary large models and approach benchmark
results with only 200-1,000 examples on a single GPU. 3) We release the first
public set of education review ABSA resources to support future research in
low-resource domains.

</details>


### [47] [ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment](https://arxiv.org/abs/2511.03048)
*Anthony Hevia,Sanjana Chintalapati,Veronica Ka Wai Lai,Thanh Tam Nguyen,Wai-Tat Wong,Terry Klassen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: ROBOTO2是一个开源的、基于网页的平台，利用大语言模型（LLM）辅助临床试验偏倚风险（ROB）评估，通过PDF解析、检索增强的LLM提示和人工参与评审，简化了传统的ROB2标注流程。


<details>
  <summary>Details</summary>
Motivation: 为了减轻传统偏倚风险评估过程中繁重的手动标注工作，提升系统评价的效率和可重复性。

Method: 结合PDF解析、检索增强的大语言模型提示以及人工反馈机制，构建一个交互式平台，并发布包含521项儿科临床试验报告的数据集用于基准测试。

Result: 实现了对4种大语言模型在ROB2评估任务上的性能基准测试，提供了初步答案与证据支持，并识别出当前自动化面临的能力与挑战。

Conclusion: ROBOTO2有效提升了偏倚风险评估的自动化水平，其公开的数据和代码有助于推动系统评价领域的研究与应用。

Abstract: We present ROBOTO2, an open-source, web-based platform for large language
model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2
streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process
via an interactive interface that combines PDF parsing, retrieval-augmented LLM
prompting, and human-in-the-loop review. Users can upload clinical trial
reports, receive preliminary answers and supporting evidence for ROB2 signaling
questions, and provide real-time feedback or corrections to system suggestions.
ROBOTO2 is publicly available at https://roboto2.vercel.app/, with code and
data released to foster reproducibility and adoption. We construct and release
a dataset of 521 pediatric clinical trial reports (8954 signaling questions
with 1202 evidence passages), annotated using both manually and LLM-assisted
methods, serving as a benchmark and enabling future research. Using this
dataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into
current model capabilities and ongoing challenges in automating this critical
aspect of systematic review.

</details>


### [48] [Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification](https://arxiv.org/abs/2511.03217)
*Shaghayegh Kolli,Richard Rosenbaum,Timo Cavelius,Lasse Strothe,Andrii Lata,Jana Diesner*

Main category: cs.CL

TL;DR: 提出了一种结合大语言模型、知识图谱和网络搜索代理的混合事实核查方法，在FEVER基准上取得了0.93的F1分数，并能有效发现原标注为‘信息不足’的声明中的有效证据。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成流畅但缺乏可靠事实依据，知识图谱事实核查精确但覆盖有限，因此需要融合两者优势以提升准确性和覆盖范围。

Method: 采用三步自主流程：1）基于DBpedia的知识图谱检索；2）基于大语言模型的任务特定提示分类；3）在知识图谱覆盖不足时调用网络搜索代理。

Result: 在FEVER数据集Supported/Refuted划分上达到0.93的F1分数，无需任务微调；并在重新标注研究中发现大量原NEI案例实际可验证。

Conclusion: 该模块化、开源的事实核查流水线通过回退策略实现了良好的泛化能力和实际证据发现能力。

Abstract: Large language models (LLMs) excel in generating fluent utterances but can
lack reliable grounding in verified information. At the same time,
knowledge-graph-based fact-checkers deliver precise and interpretable evidence,
yet suffer from limited coverage or latency. By integrating LLMs with knowledge
graphs and real-time search agents, we introduce a hybrid fact-checking
approach that leverages the individual strengths of each component. Our system
comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid
one-hop lookups in DBpedia, 2) an LM-based classification guided by a
task-specific labeling prompt, producing outputs with internal rule-based
logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient.
Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the
Supported/Refuted split without task-specific fine-tuning. To address Not
enough information cases, we conduct a targeted reannotation study showing that
our approach frequently uncovers valid evidence for claims originally labeled
as Not Enough Information (NEI), as confirmed by both expert annotators and LLM
reviewers. With this paper, we present a modular, opensource fact-checking
pipeline with fallback strategies and generalization across datasets.

</details>


### [49] [Reading Between the Lines: The One-Sided Conversation Problem](https://arxiv.org/abs/2511.03056)
*Victoria Ebert,Rishabh Singh,Tuochao Chen,Noah A. Smith,Shyamnath Gollakota*

Main category: cs.CL

TL;DR: 本文提出了单边对话问题（1SC），研究从对话的一方推断和学习的方法，包括重构缺失说话者的话语和生成单边转录本的摘要，结果表明结合未来话语信息和提示工程能有效提升重建效果，且无需重建即可生成高质量摘要，推动隐私保护的对话AI发展。


<details>
  <summary>Details</summary>
Motivation: 在许多现实场景中（如远程医疗、呼叫中心），只能记录对话的一方，限制了传统对话AI的应用，因此需要研究如何仅基于单边对话进行推理和学习。

Method: 形式化定义1SC问题，研究两种任务：缺失话语的实时重建与单边转录本摘要生成；采用提示和微调模型，在MultiWOZ、DailyDialog和Candor数据集上结合人工A/B测试与LLM-as-a-judge指标进行评估。

Result: 发现利用一个未来话语和话语长度信息可提升重建效果，占位符提示有助于减少幻觉，大模型通过提示即可生成有希望的重建结果，小模型则需微调；同时，无需重建缺失话语也能生成高质量摘要。

Conclusion: 1SC被提出作为一个新挑战，实验结果表明在隐私敏感场景下实现有效对话理解是可行的，为隐私保护的对话AI提供了新方向。

Abstract: Conversational AI is constrained in many real-world settings where only one
side of a dialogue can be recorded, such as telemedicine, call centers, and
smart glasses. We formalize this as the one-sided conversation problem (1SC):
inferring and learning from one side of a conversation. We study two tasks: (1)
reconstructing the missing speaker's turns for real-time use cases, and (2)
generating summaries from one-sided transcripts. Evaluating prompting and
finetuned models on MultiWOZ, DailyDialog, and Candor with both human A/B
testing and LLM-as-a-judge metrics, we find that access to one future turn and
information about utterance length improves reconstruction, placeholder
prompting helps to mitigate hallucination, and while large models generate
promising reconstructions with prompting, smaller models require finetuning.
Further, high-quality summaries can be generated without reconstructing missing
turns. We present 1SC as a novel challenge and report promising results that
mark a step toward privacy-aware conversational AI.

</details>


### [50] [Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval](https://arxiv.org/abs/2511.03228)
*Shantanu Agarwal,Joel Barry,Elizabeth Boschee,Scott Miller*

Main category: cs.CL

TL;DR: 本文介绍了ISI团队在MATERIAL项目中提出的SARAL方法，旨在改进跨语言信息检索（CLIR），强调检索与查询相关的一组文档而不仅仅是排序列表，并在多语言评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 提升跨语言信息检索的效果，特别是在检索相关文档集合而非仅排序列表方面。

Method: 提出了一种新颖的CLIR方法SARAL，注重领域自适应和摘要技术，以支持查询相关文档集的检索。

Result: 在MATERIAL第三阶段的评估中，SARAL在六项评测条件中的五项上优于其他团队，涵盖波斯语、哈萨克语和格鲁吉亚语三种语言。

Conclusion: SARAL方法在多语言环境下显著提升了CLIR性能，证明了其在实际应用中的有效性与优势。

Abstract: Machine Translation for English Retrieval of Information in Any Language
(MATERIAL) is an IARPA initiative targeted to advance the state of
cross-lingual information retrieval (CLIR). This report provides a detailed
description of Information Sciences Institute's (ISI's) Summarization and
domain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.
Specifically, we outline our team's novel approach to handle CLIR with emphasis
in developing an approach amenable to retrieve a query-relevant document
\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3
evaluations, SARAL exceeded the performance of other teams in five out of six
evaluation conditions spanning three different languages (Farsi, Kazakh, and
Georgian).

</details>


### [51] [PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech](https://arxiv.org/abs/2511.03080)
*Michel Wong,Ali Alshehri,Sophia Kao,Haotian He*

Main category: cs.CL

TL;DR: 提出PolyNorm，一种基于大语言模型的提示式文本归一化方法，减少对人工规则的依赖，并发布多语言数据集PolyNorm-Benchmark。


<details>
  <summary>Details</summary>
Motivation: 传统文本归一化系统依赖大量人工规则，难以扩展且在低资源语言中覆盖困难，需要更可扩展、语言通用的解决方案。

Method: 采用基于大语言模型的提示学习方法，结合语言无关的数据自动构建与评估流程，实现跨语言文本归一化。

Result: 在八种语言上的实验表明，相比生产级系统，PolyNorm consistently降低了词错误率（WER）。

Conclusion: PolyNorm能有效减少人工干预，具备良好的跨语言可扩展性，为文本归一化提供了高效、通用的新范式。

Abstract: Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS)
systems, converting written forms into their canonical spoken equivalents.
Traditional TN systems can exhibit high accuracy, but involve substantial
engineering effort, are difficult to scale, and pose challenges to language
coverage, particularly in low-resource settings. We propose PolyNorm, a
prompt-based approach to TN using Large Language Models (LLMs), aiming to
reduce the reliance on manually crafted rules and enable broader linguistic
applicability with minimal human intervention. Additionally, we present a
language-agnostic pipeline for automatic data curation and evaluation, designed
to facilitate scalable experimentation across diverse languages. Experiments
across eight languages show consistent reductions in the word error rate (WER)
compared to a production-grade-based system. To support further research, we
release PolyNorm-Benchmark, a multilingual data set covering a diverse range of
text normalization phenomena.

</details>


### [52] [A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures](https://arxiv.org/abs/2511.03089)
*Gowtham Premananth,Carol Espy-Wilson*

Main category: cs.CL

TL;DR: 该研究利用计算语言学中的突发性（surprisal）和语义连贯性（semantic coherence）两个指标，分析精神分裂症患者与健康对照组在语言表达上的差异，并探讨这些语言异常如何随症状严重程度变化。


<details>
  <summary>Details</summary>
Motivation: 语言紊乱是精神分裂症的典型特征，可能反映潜在的认知障碍，并可作为诊断和评估症状严重程度的客观指标。因此，需要通过量化方法来刻画这些语言异常。

Method: 使用计算模型对精神分裂症患者和健康对照组的语言样本进行分析，计算其语言的突发性（surprisal）和语义连贯性（semantic coherence），并比较两组之间的差异及其与症状严重程度的关系。

Result: 研究发现，与健康对照组相比，精神分裂症患者的语言表现出更高的突发性和更低的语义连贯性，且这些语言指标与症状严重程度相关。

Conclusion: 基于计算语言学的突发性和语义连贯性可有效表征精神分裂症患者的语言紊乱，具有作为疾病生物标志物的潜力。

Abstract: Language disruptions are one of the well-known effects of schizophrenia
symptoms. They are often manifested as disorganized speech and impaired
discourse coherence. These abnormalities in spontaneous language production
reflect underlying cognitive disturbances and have the potential to serve as
objective markers for symptom severity and diagnosis of schizophrenia. This
study focuses on how these language disruptions can be characterized in terms
of two computational linguistic measures: surprisal and semantic coherence. By
computing surprisal and semantic coherence of language using computational
models, this study investigates how they differ between subjects with
schizophrenia and healthy controls. Furthermore, this study provides further
insight into how language disruptions in terms of these linguistic measures
change with varying degrees of schizophrenia symptom severity.

</details>


### [53] [CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic](https://arxiv.org/abs/2511.03102)
*Saad Mankarious,Ayah Zirikly*

Main category: cs.CL

TL;DR: 本文提出了CARMA，首个大规模自动标注的阿拉伯语Reddit帖子心理健康数据集，涵盖六种心理疾病和对照组，推动了阿拉伯语等代表性不足语言的心理健康检测研究。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语心理健康资源有限，且受文化 stigma 影响，早期检测困难，现有研究多集中于英语，缺乏高质量阿拉伯语标注数据集。

Method: 构建了一个大规模自动标注的阿拉伯语Reddit数据集（CARMA），包含六种心理疾病类别和对照组，并进行词汇和语义的定性与定量分析；采用从浅层分类器到大语言模型的多种方法进行分类实验。

Result: CARMA在规模和多样性上超过现有数据集，分类实验表明各类模型均能有效区分不同心理状态，验证了该数据集在阿拉伯语心理健康检测中的潜力。

Conclusion: CARMA为阿拉伯语心理健康研究提供了重要资源，展示了在低资源语言中推进自动检测的可能性，有助于缩小跨语言心理健康技术支持的差距。

Abstract: Mental health disorders affect millions worldwide, yet early detection
remains a major challenge, particularly for Arabic-speaking populations where
resources are limited and mental health discourse is often discouraged due to
cultural stigma. While substantial research has focused on English-language
mental health detection, Arabic remains significantly underexplored, partly due
to the scarcity of annotated datasets. We present CARMA, the first
automatically annotated large-scale dataset of Arabic Reddit posts. The dataset
encompasses six mental health conditions, such as Anxiety, Autism, and
Depression, and a control group. CARMA surpasses existing resources in both
scale and diversity. We conduct qualitative and quantitative analyses of
lexical and semantic differences between users, providing insights into the
linguistic markers of specific mental health conditions. To demonstrate the
dataset's potential for further mental health analysis, we perform
classification experiments using a range of models, from shallow classifiers to
large language models. Our results highlight the promise of advancing mental
health detection in underrepresented languages such as Arabic.

</details>


### [54] [Control Barrier Function for Aligning Large Language Models](https://arxiv.org/abs/2511.03121)
*Yuya Miyaoka,Masaki Inoue*

Main category: cs.CL

TL;DR: 提出一种基于控制屏障函数（CBF）的控制框架，用于对齐大语言模型，通过安全过滤器干预生成文本，无需微调且可直接集成评估模型。


<details>
  <summary>Details</summary>
Motivation: 确保大语言模型生成符合用户期望的安全、正面文本，同时避免昂贵的微调过程。

Method: 利用控制屏障函数（CBF）设计安全过滤器，应用于基线模型输出的预测token，以实时干预和调整生成内容。

Result: 成功在开源语言模型上实现该框架，能够有效生成积极文本，并验证了过滤器的即插即用特性和对齐灵活性。

Conclusion: 该控制框架提供了一种无需微调、可扩展且灵活的大模型对齐方法，适用于需要安全可控生成的场景。

Abstract: This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the CBF safety
filter to the predicted token generated from the baseline LLM, to intervene in
the generated text. The safety filter includes two significant advantages: this
safety filter is an add-on type, allowing it to be used for alignment purposes
without fine-tuning the baseline LLM, and if there is an evaluation model
regarding the desired alignment, it can be directly applied to the filter
design. The overall text-generation system is implemented with open-source
language models, aiming to generate positive text.

</details>


### [55] [MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity](https://arxiv.org/abs/2511.03146)
*Kaiyuan Zhang,Chenghao Yang,Zhoufutu Wen,Sihang Yuan,Qiuyue Wang,Chaoyi Huang,Guosheng Zhu,He Wang,Huawenyu Lu,Jianing Wen,Jianpeng Jiao,Lishu Luo,Longxiang Liu,Sijin Wu,Xiaolei Zhu,Xuanliang Zhang,Ge Zhang,Yi Lin,Guang Shi,Chaoyou Fu,Wenhao Huang*

Main category: cs.CL

TL;DR: 本文提出了MME-CC，一个专注于视觉认知能力评估的多模态基准，涵盖空间、几何和基于知识的推理任务，揭示了现有MLLM在视觉认知上的不足，并呼吁将认知能力作为模型评估与设计的核心。


<details>
  <summary>Details</summary>
Motivation: 现有基准过于侧重文本推理，缺乏对视觉中心认知行为的系统性评估，难以充分衡量多模态大语言模型（MLLM）的认知能力。

Method: 构建了一个名为MME-CC的新基准，包含11个代表性推理任务，分为空间、几何和知识型三类，并在16个主流MLLM上进行广泛实验，分析其视觉认知表现。

Result: 实验显示闭源模型整体领先（如Gemini-2.5-Pro得分为42.66，GLM-4.5V为30.45），但空间与几何推理能力普遍较弱（≤30%）；常见错误包括方向判断错误、跨视角身份保持脆弱、对反事实指令遵循差，且思维链多依赖视觉提取阶段。

Conclusion: 应将认知能力置于多模态模型评估与设计的核心，MME-CC为推动这一转变提供了有效工具。

Abstract: As reasoning models scale rapidly, the essential role of multimodality in
human cognition has come into sharp relief, driving a growing need to probe
vision-centric cognitive behaviors. Yet, existing multimodal benchmarks either
overemphasize textual reasoning or fall short of systematically capturing
vision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs
insufficiently assessed. To address this limitation, we introduce MME-CC
(Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded
benchmark that organizes 11 representative reasoning tasks into three
fundamental categories of visual information: spatial, geometric, and
knowledge-based reasoning, and provides fine-grained analyses of MLLMs'
cognitive capacity across these dimensions. Based on MME-CC, we conduct
extensive experiments over 16 representative MLLMs. Our study reveals that
closed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs.
30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak
(less than or equal to 30%). We further identify common error patterns,
including orientation mistakes, fragile cross-view identity persistence, and
poor adherence to counterfactual instructions, and observe that
Chain-of-Thought typically follows a three-stage process (extract -> reason ->
verify) with heavy reliance on visual extraction. We hope this work catalyzes a
shift toward treating the cognitive capacity of MLLMs as central to both
evaluation and model design.

</details>


### [56] [Who Sees the Risk? Stakeholder Conflicts and Explanatory Policies in LLM-based Risk Assessment](https://arxiv.org/abs/2511.03152)
*Srishti Yadav,Jasmina Gajcin,Erik Miehling,Elizabeth Daly*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLM）的、以利益相关者为中心的风险评估框架，利用Risk Atlas Nexus和GloVE方法生成可解释的、针对不同利益相关者的风险策略，并通过交互式可视化揭示风险认知差异与冲突来源。


<details>
  <summary>Details</summary>
Motivation: 不同利益相关者对AI系统风险的认知存在差异，理解这些差异对于负责任地部署AI系统至关重要。现有风险评估方法缺乏对多视角差异的建模与解释能力。

Method: 构建一个以LLM为‘裁判’的风险预测与解释框架，结合Risk Atlas Nexus分类体系和GloVE解释技术，生成利益相关者特定的风险判断与理由，并开发交互式可视化工具展示观点冲突。

Result: 在医疗AI、自动驾驶和欺诈检测三个实际场景中验证了该方法的有效性，结果显示不同利益相关者的风险感知存在显著差异，且框架能有效揭示冲突的成因。

Conclusion: 利益相关者的视角显著影响风险认知模式，所提出的框架增强了LLM风险评估的透明性与可解释性，有助于实现以人为本的AI治理目标。

Abstract: Understanding how different stakeholders perceive risks in AI systems is
essential for their responsible deployment. This paper presents a framework for
stakeholder-grounded risk assessment by using LLMs, acting as judges to predict
and explain risks. Using the Risk Atlas Nexus and GloVE explanation method, our
framework generates stakeholder-specific, interpretable policies that shows how
different stakeholders agree or disagree about the same risks. We demonstrate
our method using three real-world AI use cases of medical AI, autonomous
vehicles, and fraud detection domain. We further propose an interactive
visualization that reveals how and why conflicts emerge across stakeholder
perspectives, enhancing transparency in conflict reasoning. Our results show
that stakeholder perspectives significantly influence risk perception and
conflict patterns. Our work emphasizes the importance of these
stakeholder-aware explanations needed to make LLM-based evaluations more
transparent, interpretable, and aligned with human-centered AI governance
goals.

</details>


### [57] [Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks](https://arxiv.org/abs/2511.03166)
*Kevin Wang,Subre Abdoul Moktar,Jia Li,Kangshuo Li,Feng Chen*

Main category: cs.CL

TL;DR: 本文对大型语言模型（LLM）中的不确定性估计（UE）方法进行了全面的实证研究，评估了12种UE方法在问答任务中对分布内和分布外数据的鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 确保LLM输出的可信度至关重要，而不确定性估计在此过程中起关键作用。需要系统评估不同UE方法在不同类型不确定性（如偶然性和认知性）下的表现。

Method: 研究采用了12种不同的UE方法，并结合四种生成质量度量指标（包括基于LLM批评者的LLMScore），在问答任务的分布内和分布外数据集上进行评估。

Result: 基于信息的方法在分布内设置中表现优异；基于密度的方法和P(True)指标在分布外场景中表现更好；语义一致性方法在不同数据集和生成指标下均表现出稳定性能。

Conclusion: 不同类型的UE方法适用于不同场景，没有一种方法在所有情况下都最优，应根据具体应用场景选择合适的UE方法。

Abstract: Large Language Models (LLMs) have become increasingly pervasive, finding
applications across many industries and disciplines. Ensuring the
trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE)
plays a key role. In this work, a comprehensive empirical study is conducted to
examine the robustness and effectiveness of diverse UE measures regarding
aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE
methods and four generation quality metrics including LLMScore from LLM
criticizers to evaluate the uncertainty of LLM-generated answers in
Question-Answering (QA) tasks on both in-distribution (ID) and
out-of-distribution (OOD) datasets. Our analysis reveals that information-based
methods, which leverage token and sequence probabilities, perform exceptionally
well in ID settings due to their alignment with the model's understanding of
the data. Conversely, density-based methods and the P(True) metric exhibit
superior performance in OOD contexts, highlighting their effectiveness in
capturing the model's epistemic uncertainty. Semantic consistency methods,
which assess variability in generated answers, show reliable performance across
different datasets and generation metrics. These methods generally perform well
but may not be optimal for every situation.

</details>


### [58] [BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture](https://arxiv.org/abs/2511.03180)
*Shahriyar Zaman Ridoy,Azmine Toushik Wasi,Koushik Ahamed Tonmoy*

Main category: cs.CL

TL;DR: 本文提出了首个针对孟加拉语及南亚文化背景的大规模伦理基准BengaliMoralBench，填补了多语言大模型在本地化伦理对齐方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有伦理基准以英语和西方价值观为主，忽视了如孟加拉语等语言的文化特殊性，限制了大模型在真实场景中的可靠部署。

Method: 构建涵盖五个道德领域、50个子主题的BengaliMoralBench数据集，通过母语者共识从美德、常识和正义三种伦理视角进行标注，并采用统一提示协议对多种多语言大模型进行零样本评估。

Result: 实验显示主流多语言大模型表现差异大（准确率50-91%），普遍存在文化理解、常识推理和道德公平性方面的缺陷。

Conclusion: BengaliMoralBench为低资源多语言环境下 culturally-aligned 的AI伦理评估提供了基础，支持更负责任的本地化部署。

Abstract: As multilingual Large Language Models (LLMs) gain traction across South Asia,
their alignment with local ethical norms, particularly for Bengali, which is
spoken by over 285 million people and ranked 6th globally, remains
underexplored. Existing ethics benchmarks are largely English-centric and
shaped by Western frameworks, overlooking cultural nuances critical for
real-world deployment. To address this, we introduce BengaliMoralBench, the
first large-scale ethics benchmark for the Bengali language and socio-cultural
contexts. It covers five moral domains, Daily Activities, Habits, Parenting,
Family Relationships, and Religious Activities, subdivided into 50 culturally
relevant subtopics. Each scenario is annotated via native-speaker consensus
using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct
systematic zero-shot evaluation of prominent multilingual LLMs, including
Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and
standard metrics. Performance varies widely (50-91% accuracy), with qualitative
analysis revealing consistent weaknesses in cultural grounding, commonsense
reasoning, and moral fairness. BengaliMoralBench provides a foundation for
responsible localization, enabling culturally aligned evaluation and supporting
the deployment of ethically robust AI in diverse, low-resource multilingual
settings such as Bangladesh.

</details>


### [59] [LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval](https://arxiv.org/abs/2511.03214)
*Wenchang Lei,Ping Zou,Yue Wang,Feng Sun,Lei Zhao*

Main category: cs.CL

TL;DR: 提出语言图模型（LGM），通过提取自然语言中的继承、别名和组成等元关系并结合反思机制，提升大语言模型对模糊或概念错位指令的理解能力，支持任意长度文本处理，且在标准基准上优于现有RAG方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在面对指令中存在模糊或概念错位术语时表现不佳，需增强其概念理解与澄清能力。

Method: 提出语言图模型（LGM），提取自然语言中的继承、alias和组成等元关系，并引入反思机制验证这些关系；结合概念迭代检索算法，动态向LLM提供元关系及相关描述信息。

Result: 实验表明，LGM在标准基准上 consistently 优于现有的检索增强生成（RAG）基线方法，且无需截断即可处理任意长度文本。

Conclusion: LGM通过结构化元关系建模和动态知识注入，有效提升了大语言模型对复杂概念的解析与响应准确性，突破了传统RAG方法对上下文窗口的依赖。

Abstract: Large language models (LLMs) exhibit strong semantic understanding, yet
struggle when user instructions involve ambiguous or conceptually misaligned
terms. We propose the Language Graph Model (LGM) to enhance conceptual clarity
by extracting meta-relations-inheritance, alias, and composition-from natural
language. The model further employs a reflection mechanism to validate these
meta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these
relations and related descriptions are dynamically supplied to the LLM,
improving its ability to interpret concepts and generate accurate responses.
Unlike conventional Retrieval-Augmented Generation (RAG) approaches that rely
on extended context windows, our method enables large language models to
process texts of any length without the need for truncation. Experiments on
standard benchmarks demonstrate that the LGM consistently outperforms existing
RAG baselines.

</details>


### [60] [IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs](https://arxiv.org/abs/2511.03237)
*Souvik Rana,Arul Menezes,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 提出IndicSuperTokenizer，一种用于印度多语言大模型的分词器，结合子词与多词分词及语言特定预分词，在肥力评分上显著优于现有方法，并提升推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 设计高效的多语言分词器面临多样文字和丰富形态变化的挑战，现有子词方法在多语言场景下的有效性尚不明确。

Method: 结合子词和多词分词方法，引入语言特定的预分词策略，优化分词过程以实现更符合语言学特性的分词结果。

Result: 在英语、22种印度语言和代码数据上评估，相比LLaMA4平均肥力评分提高39.5%，相比Sutra提高18%，推理吞吐量提升44%，且在英文和印度语基准上保持相当性能。

Conclusion: IndicSuperTokenizer通过融合多种分词技术及语言特定预处理，在多语言场景中实现了当前最优的分词效果与更高的推理效率。

Abstract: Tokenizers play a crucial role in determining the performance, training
efficiency, and the inference cost of Large Language Models (LLMs). Designing
effective tokenizers for multilingual LLMs is particularly challenging due to
diverse scripts and rich morphological variation. While subword methods such as
Byte Pair Encoding (BPE) are widely adopted, their effectiveness in
multilingual settings remains underexplored. We present IndicSuperTokenizer, a
tokenizer for Indic multilingual LLMs, that combines both subword and
multi-word tokenization, along with language-specific pre-tokenization, leading
to more linguistically aligned tokens and achieving a new state-of-the-art in
fertility score. Evaluated across English, 22 Indian languages and code data,
our tokenizer improves the average fertility score by 39.5% over LLaMA4 and by
18% over Sutra (the current best). This translates to 44% improvement in
inference throughput over LLaMA4 while maintaining comparable performance on
English and Indic benchmarks. We also present detailed ablations across
tokenizer training data size, vocabulary size, merging techniques, and
pre-tokenization strategies, demonstrating the robustness of our design
choices.

</details>


### [61] [Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature](https://arxiv.org/abs/2511.03261)
*Ranul Dayarathne,Uvini Ranaweera,Upeksha Ganegoda*

Main category: cs.CL

TL;DR: 本研究比较了四种开源大语言模型（Mistral-7b-instruct、LLaMa2-7b-chat、Falcon-7b-instruct、Orca-mini-v3-7b）与GPT-3.5在计算机科学文献问答任务中结合RAG技术的性能，结果表明Mistral-7b-instruct表现最佳，而Orca-mini-v3-7b响应延迟最低。


<details>
  <summary>Details</summary>
Motivation: 随着检索增强生成（RAG）技术的发展，评估不同大语言模型在减少幻觉和提升问答性能方面的表现成为研究热点，尤其关注开源模型能否媲美闭源模型。

Method: 在计算机科学领域的问答任务中，采用RAG技术支持，对比四个开源LLM与GPT-3.5的表现；评估指标包括二分类问题的准确率和精确率，以及长答案问题的人工评分、Gemini模型评分和余弦相似度。

Result: GPT-3.5结合RAG在各类问题上表现优异；在开源模型中，Mistral-7b-instruct在回答准确性方面领先，Orca-mini-v3-7b平均响应延迟最短，LLaMa2-7b-chat延迟最高。

Conclusion: 开源大语言模型在配备良好基础设施的情况下，能够与GPT-3.5等专有模型相媲美，具备实际应用潜力。

Abstract: Retrieval Augmented Generation (RAG) is emerging as a powerful technique to
enhance the capabilities of Generative AI models by reducing hallucination.
Thus, the increasing prominence of RAG alongside Large Language Models (LLMs)
has sparked interest in comparing the performance of different LLMs in
question-answering (QA) in diverse domains. This study compares the performance
of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,
Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA
tasks within the computer science literature leveraging RAG support. Evaluation
metrics employed in the study include accuracy and precision for binary
questions and ranking by a human expert, ranking by Google's AI model Gemini,
alongside cosine similarity for long-answer questions. GPT-3.5, when paired
with RAG, effectively answers binary and long-answer questions, reaffirming its
status as an advanced LLM. Regarding open-source LLMs, Mistral AI's
Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary
and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b
reports the shortest average latency in generating responses, whereas
LLaMa2-7b-chat by Meta reports the highest average latency. This research
underscores the fact that open-source LLMs, too, can go hand in hand with
proprietary models like GPT-3.5 with better infrastructure.

</details>


### [62] [SCALE: Upscaled Continual Learning of Large Language Models](https://arxiv.org/abs/2511.03270)
*Jin-woo Lee,Junhwa Choi,Bongkyu Hwang,Jinho Choo,Bogun Kim,JeongSeon Yi,Joonseok Lee,DongYoung Jung,Jaeseon Park,Kyoungwon Park,Suk-hoon Jung*

Main category: cs.CL

TL;DR: 本文提出了一种名为SCALE的宽度扩展架构，用于大语言模型的持续预训练，通过插入轻量级扩展并冻结预训练参数，在保持原有模型功能的同时增强模型容量。


<details>
  <summary>Details</summary>
Motivation: 现有的持续预训练方法在单纯扩大参数规模时面临遗忘严重和稳定性差的问题，因此需要一种能更好平衡模型稳定性与可塑性的结构化扩展方案。

Method: SCALE通过在线性模块中插入可训练的轻量扩展组件实现宽度扩展，同时冻结原始参数；提出了Persistent Preservation和Collaborative Adaptation两个原则，并设计了SCALE-Preserve、SCALE-Adapt和SCALE-Route三种变体。

Result: 在合成传记基准测试中，SCALE显著减少了深度扩展带来的遗忘问题；在韩语持续预训练实验中，其在英语评测上遗忘更少，在韩语任务上取得有竞争力的提升，表现出更优的稳定性-可塑性权衡。

Conclusion: SCALE通过结构化宽度扩展和保留-适应协同机制，有效解决了持续预训练中的灾难性遗忘问题，为大模型扩展提供了新的设计范式。

Abstract: We revisit continual pre-training for large language models and argue that
progress now depends more on scaling the right structure than on scaling
parameters alone. We introduce SCALE, a width upscaling architecture that
inserts lightweight expansion into linear modules while freezing all
pre-trained parameters. This preserves the residual and attention topologies
and increases capacity without perturbing the base model's original
functionality. SCALE is guided by two principles: Persistent Preservation,
which maintains the base model's behavior via preservation-oriented
initialization and freezing of the pre-trained weights, and Collaborative
Adaptation, which selectively trains a subset of expansion components to
acquire new knowledge with minimal interference. We instantiate these ideas as
SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and
SCALE-Route, an optional routing extension that performs token-level routing
between preservation and adaptation heads. On a controlled synthetic biography
benchmark, SCALE mitigates the severe forgetting observed with depth expansion
while still acquiring new knowledge. In continual pre-training on a Korean
corpus, SCALE variants achieve less forgetting on English evaluations and
competitive gains on Korean benchmarks, with these variants offering the best
overall stability-plasticity trade-off. Accompanying analysis clarifies when
preservation provably holds and why the interplay between preservation and
adaptation stabilizes optimization compared to standard continual learning
setups.

</details>


### [63] [How to Evaluate Speech Translation with Source-Aware Neural MT Metrics](https://arxiv.org/abs/2511.03295)
*Mauro Cettolo,Marco Gaido,Matteo Negri,Sara Papi,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文首次系统研究了在无源文本转录情况下语音到文本翻译（ST）的源感知评估指标，提出使用自动语音识别转录和回译作为音频输入的文本代理，并设计了一种新的跨语言重分段算法来解决对齐问题。实验表明，在词错误率低于20%时，ASR转录更可靠，而回译则成本更低且有效，为ST评估提供了更准确的方法。


<details>
  <summary>Details</summary>
Motivation: 传统ST评估依赖参考翻译，忽略源音频信息，导致评估不充分；受机器翻译中利用源文本提升评估效果的启发，希望在ST中引入源感知指标，但面临音频源无法直接使用且缺乏对齐数据的挑战。

Method: 提出两种生成音频文本代理的策略：自动语音识别（ASR）转录和参考翻译的回译；设计两步跨语言重分段算法以解决合成源与参考翻译之间的对齐不匹配问题；在两个包含79种语言对和六种不同架构ST系统的基准上进行实验验证。

Result: 实验显示当ASR词错误率低于20%时，其转录作为合成源比回译更可靠；回译虽精度略低但计算成本更低且仍有效；所提出的重分段算法显著提升了源感知MT指标在ST评估中的鲁棒性和相关性。

Conclusion: 源感知评估指标可通过使用ASR转录或回译作为文本代理并在适当对齐后有效应用于ST系统评估，尤其在真实场景中缺乏源转录时，该方法为ST自动评估提供了更准确、有原则的新路径。

Abstract: Automatic evaluation of speech-to-text translation (ST) systems is typically
performed by comparing translation hypotheses with one or more reference
translations. While effective to some extent, this approach inherits the
limitation of reference-based evaluation that ignores valuable information from
the source input. In machine translation (MT), recent progress has shown that
neural metrics incorporating the source text achieve stronger correlation with
human judgments. Extending this idea to ST, however, is not trivial because the
source is audio rather than text, and reliable transcripts or alignments
between source and references are often unavailable. In this work, we conduct
the first systematic study of source-aware metrics for ST, with a particular
focus on real-world operating conditions where source transcripts are not
available. We explore two complementary strategies for generating textual
proxies of the input audio, automatic speech recognition (ASR) transcripts, and
back-translations of the reference translation, and introduce a novel two-step
cross-lingual re-segmentation algorithm to address the alignment mismatch
between synthetic sources and reference translations. Our experiments, carried
out on two ST benchmarks covering 79 language pairs and six ST systems with
diverse architectures and performance levels, show that ASR transcripts
constitute a more reliable synthetic source than back-translations when word
error rate is below 20%, while back-translations always represent a
computationally cheaper but still effective alternative. Furthermore, our
cross-lingual re-segmentation algorithm enables robust use of source-aware MT
metrics in ST evaluation, paving the way toward more accurate and principled
evaluation methodologies for speech translation.

</details>


### [64] [Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks](https://arxiv.org/abs/2511.03328)
*Jindong Hong,Tianjie Chen,Lingjie Luo,Chuanyang Zheng,Ting Xu,Haibao Yu,Jianing Qiu,Qianzhong Chen,Suning Huang,Yan Xu,Yong Gui,Yijun He,Jiankai Sun*

Main category: cs.CL

TL;DR: 该研究评估了两种领先的多模态大语言模型（Seed1.5-VL和Gemini-2.5-Flash）在医疗任务中的“思考模式”性能，发现在大多数任务中，“思考模式”相较于“非思考模式”带来的提升有限，且在开放性视觉问答和医学图像解读等复杂任务上表现仍不理想。


<details>
  <summary>Details</summary>
Motivation: 随着具备显式控制内部思维过程能力的‘推理型多模态大语言模型’的出现，亟需系统评估其在临床任务中的性能与可靠性。

Method: 在VQA-RAD和ROCOv2数据集上，对Seed1.5-VL和Gemini-2.5-Flash两种模型的‘思考模式’和‘非思考模式’在四个视觉医疗任务中的表现进行了评估。

Result: 激活‘思考模式’在多数任务中仅带来边际性能提升；模型在复杂医学任务上的表现仍然不佳。

Conclusion: 当前的双状态MLLMs在医学应用中仍有局限，需引入领域特定的医学数据和更先进的医学知识整合方法以提升性能。

Abstract: A recent advancement in Multimodal Large Language Models (MLLMs) research is
the emergence of "reasoning MLLMs" that offer explicit control over their
internal thinking processes (normally referred as the "thinking mode")
alongside the standard "non-thinking mode". This capability allows these models
to engage in a step-by-step process of internal deliberation before generating
a final response. With the rapid transition to and adoption of these
"dual-state" MLLMs, this work rigorously evaluated how the enhanced reasoning
processes of these MLLMs impact model performance and reliability in clinical
tasks. This paper evaluates the active "thinking mode" capabilities of two
leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We
assessed their performance on four visual medical tasks using VQA-RAD and
ROCOv2 datasets. Our findings reveal that the improvement from activating the
thinking mode remains marginal compared to the standard non-thinking mode for
the majority of the tasks. Their performance on complex medical tasks such as
open-ended VQA and medical image interpretation remains suboptimal,
highlighting the need for domain-specific medical data and more advanced
methods for medical knowledge integration.

</details>


### [65] [Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances](https://arxiv.org/abs/2511.03354)
*Riasad Alvi,Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Md Rafi Ur Rashid,Md Rafiqul Islam,Yakub Sebastian,Sami Azam*

Main category: cs.CL

TL;DR: 本文综述了生成式人工智能（GenAI）在生物信息学中的方法进展、预测性能和专业化应用，系统地提出了六个研究问题，涵盖从序列分析到分子设计等多个子领域，并探讨了专用模型架构的优势、数据资源支持以及当前面临的可扩展性和数据偏差等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着GenAI在基因组学、蛋白质组学、转录组学、结构生物学和药物发现中的广泛应用，亟需系统性评估其方法学进展与实际影响，以指导未来研究方向。

Method: 基于PRISMA方法提出六个研究问题（RQ1-RQ6），对GenAI在生物信息学中的应用、模型架构、优势领域、性能提升、局限性和数据资源进行系统性综述与分析。

Result: 发现专用模型架构因针对性预训练和上下文感知策略表现更优；GenAI在分子分析、结构建模、功能预测和合成数据生成方面显著提升准确性；主流分子、细胞和文本数据集广泛支持模型训练与泛化。

Conclusion: GenAI在生物信息学中展现出巨大潜力，未来应聚焦于加强评估鲁棒性、解决数据偏差问题，并发展基于生物学原理的建模方法以提升泛化能力。

Abstract: Generative artificial intelligence (GenAI) has become a transformative
approach in bioinformatics that often enables advancements in genomics,
proteomics, transcriptomics, structural biology, and drug discovery. To
systematically identify and evaluate these growing developments, this review
proposed six research questions (RQs), according to the preferred reporting
items for systematic reviews and meta-analysis methods. The objective is to
evaluate impactful GenAI strategies in methodological advancement, predictive
performance, and specialization, and to identify promising approaches for
advanced modeling, data-intensive discovery, and integrative biological
analysis. RQ1 highlights diverse applications across multiple bioinformatics
subfields (sequence analysis, molecular design, and integrative data modeling),
which demonstrate superior performance over traditional methods through pattern
recognition and output generation. RQ2 reveals that adapted specialized model
architectures outperformed general-purpose models, an advantage attributed to
targeted pretraining and context-aware strategies. RQ3 identifies significant
benefits in the bioinformatics domains, focusing on molecular analysis and data
integration, which improves accuracy and reduces errors in complex analysis.
RQ4 indicates improvements in structural modeling, functional prediction, and
synthetic data generation, validated by established benchmarks. RQ5 suggests
the main constraints, such as the lack of scalability and biases in data that
impact generalizability, and proposes future directions focused on robust
evaluation and biologically grounded modeling. RQ6 examines that molecular
datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as
CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly
support the training and generalization of GenAI models.

</details>


### [66] [Silenced Biases: The Dark Side LLMs Learned to Refuse](https://arxiv.org/abs/2511.03369)
*Rom Himelstein,Amit LeVi,Brit Youngmann,Yaniv Nemcovsky,Avi Mendelson*

Main category: cs.CL

TL;DR: 本文提出了“沉默偏见”（silenced biases）的概念，指出安全对齐的大语言模型可能在潜层隐藏不公平偏好，而传统评估方法因将拒绝回答视为公平性表现而产生误导。为此，作者提出Silenced Bias Benchmark (SBB)，利用激活引导减少模型拒绝，揭示潜在偏见，并验证了多个LLM中存在明显的表面回应与实际公平性问题之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有公平性评估方法常将模型的拒绝回答误判为公平表现，忽视了安全对齐下隐藏的深层偏见，导致对模型公平性的误判。因此需要一种更深入、可扩展的方法来揭示这些被掩盖的偏见。

Method: 提出Silenced Bias Benchmark (SBB)，采用激活引导技术（activation steering）在问答过程中减少模型的拒绝行为，从而探测模型隐空间中被抑制的偏见。该方法无需依赖提示工程或手工构造隐式问题，具备良好的可扩展性和客观性。

Result: 在多个大语言模型上的实验表明，尽管模型在表面上表现出较少的偏见（如拒绝回答敏感问题），但在SBB揭示下仍存在显著的潜在不公平倾向，说明当前安全对齐可能只是掩盖而非消除偏见。

Conclusion: 安全对齐可能掩盖而非根除模型中的偏见，SBB提供了一种有效、可扩展的框架来揭露‘沉默偏见’，强调未来需发展超越对齐表象的公平性评估与建模方法。

Abstract: Safety-aligned large language models (LLMs) are becoming increasingly
widespread, especially in sensitive applications where fairness is essential
and biased outputs can cause significant harm. However, evaluating the fairness
of models is a complex challenge, and approaches that do so typically utilize
standard question-answer (QA) styled schemes. Such methods often overlook
deeper issues by interpreting the model's refusal responses as positive
fairness measurements, which creates a false sense of fairness. In this work,
we introduce the concept of silenced biases, which are unfair preferences
encoded within models' latent space and are effectively concealed by
safety-alignment. Previous approaches that considered similar indirect biases
often relied on prompt manipulation or handcrafted implicit queries, which
present limited scalability and risk contaminating the evaluation process with
additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to
uncover these biases by employing activation steering to reduce model refusals
during QA. SBB supports easy expansion to new demographic groups and subjects,
presenting a fairness evaluation framework that encourages the future
development of fair models and tools beyond the masking effects of alignment
training. We demonstrate our approach over multiple LLMs, where our findings
expose an alarming distinction between models' direct responses and their
underlying fairness issues.

</details>


### [67] [EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation](https://arxiv.org/abs/2511.03370)
*Yunbo Long,Yuhan Liu,Alexandra Brintrup*

Main category: cs.CL

TL;DR: 本文提出了EQ-Negotiator框架，通过结合博弈论与隐马尔可夫模型（HMM）赋予小型语言模型（SLM）动态情感推理能力，在保护隐私的前提下显著提升其在信用谈判中的表现，证明战略型情商比模型规模更关键。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在自动谈判中性能优异但计算成本高且存在隐私问题，难以用于边缘设备；而小型语言模型（SLM）虽适合部署但性能不足，尤其在处理情绪化复杂角色时表现不佳。因此需要一种能在资源和隐私受限环境下提升SLM谈判能力的新方法。

Method: 提出EQ-Negotiator框架，核心是一个融合博弈论与隐马尔可夫模型（HMM）的推理系统，可在线学习并追踪债务人的情绪状态，无需预训练；该系统为SLM提供战略智能，以应对操纵、化解冲突并遵守伦理标准。

Result: 在多种信用谈判场景的agent-to-agent实验中，配备EQ-Negotiator的7B参数语言模型在债务回收率和谈判效率上优于十倍以上规模的基线LLM，即使面对欺骗、威胁和卖惨等对抗策略仍表现优越。

Conclusion: 研究表明战略性情感智能是自动化谈判成功的关键因素，而非单纯的模型规模；EQ-Negotiator实现了从静态角色描述到动态情感架构的跃迁，推动了可在边缘运行的高效、合乎伦理且隐私保护的AI谈判代理的发展。

Abstract: The deployment of large language models (LLMs) in automated negotiation has
set a high performance benchmark, but their computational cost and data privacy
requirements render them unsuitable for many privacy-sensitive, on-device
applications such as mobile assistants, embodied AI agents or private client
interactions. While small language models (SLMs) offer a practical alternative,
they suffer from a significant performance gap compared to LLMs in playing
emotionally charged complex personas, especially for credit negotiation. This
paper introduces EQ-Negotiator, a novel framework that bridges this capability
gap using emotional personas. Its core is a reasoning system that integrates
game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional
states online, without pre-training. This allows EQ-Negotiator to equip SLMs
with the strategic intelligence to counter manipulation while de-escalating
conflict and upholding ethical standards. Through extensive agent-to-agent
simulations across diverse credit negotiation scenarios, including adversarial
debtor strategies like cheating, threatening, and playing the victim, we show
that a 7B parameter language model with EQ-Negotiator achieves better debt
recovery and negotiation efficiency than baseline LLMs more than 10 times its
size. This work advances persona modeling from descriptive character profiles
to dynamic emotional architectures that operate within privacy constraints.
Besides, this paper establishes that strategic emotional intelligence, not raw
model scale, is the critical factor for success in automated negotiation,
paving the way for effective, ethical, and privacy-preserving AI negotiators
that can operate on the edge.

</details>


### [68] [LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning](https://arxiv.org/abs/2511.03372)
*Shenghao Li*

Main category: cs.CL

TL;DR: 提出LFC-DA方法，通过符号逻辑控制的数据增强流程，提升预训练模型在逻辑推理任务中的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法依赖人工标注成本高，或直接使用大模型生成导致逻辑不一致和多样性不足。

Method: 将逻辑文本映射为命题表达式，构建紧凑规则库，通过有界状态空间搜索发现有效公式，并将其转回自然语言问题。

Result: 在ReClor和LogiQA数据集上显著提升了预训练模型的逻辑推理准确率。

Conclusion: LFC-DA能在保持逻辑严谨性的同时实现多样化数据生成，有效支持大模型引导的逻辑数据增强。

Abstract: For complex logical data augmentation, heavy reliance on human annotation is
costly, whereas direct generation with large language models yields
uninterpretable and logically homogeneous examples. To address this, we present
LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to
propositional expressions, a compact rule library is compiled, and a bounded
state-space search systematically discovers valid formulas that are then
verbalized back into natural-language questions, ensuring both diversity and
logical rigor under propositional logic. Experiments on ReClor and LogiQA show
significant improvements in the logical-reasoning accuracy of pretrained
models, confirming the effectiveness of LFC-DA for LLM-guided logical data
augmentation.

</details>


### [69] [Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance](https://arxiv.org/abs/2511.03383)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: 本文研究了在机器翻译中使用非对称字节对编码（BPE）分词方法的效果，发现为源语言和目标语言设置不同的合并操作数（NMO）可显著提升低资源场景下的翻译性能，尤其在多种语言对上表现出统计显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的机器翻译研究通常采用对称的BPE分词策略，即在源语言和目标语言上使用相同的合并操作数，但这种固定方式可能无法在不同语言对和数据规模下达到最优性能，因此本文探索更优的分词配置。

Method: 通过在不同数据量和语言对上实验对称与非对称BPE配置，比较其在MT系统中的表现，重点分析源语言和目标语言使用不同NMO的影响。

Result: 非对称BPE在低资源设置下显著优于对称BPE，在英语-印地语等六种以上语言对中，12个系统中有10个表现出统计显著提升；最佳配置为源语言高NMO（4K–32K），目标语言低NMO（0.5K–2K）。

Conclusion: 采用非对称BPE分词策略，特别是源语言使用较高而目标语言使用较低的合并操作数，能有效提升机器翻译性能，尤其适用于低资源语言对。

Abstract: Existing Machine Translation (MT) research often suggests a single, fixed set
of hyperparameters for word segmentation models, symmetric Byte Pair Encoding
(BPE), which applies the same number of merge operations (NMO) to train
tokenizers for both source and target languages. However, we demonstrate that
this uniform approach doesn't guarantee optimal MT performance across different
language pairs and data sizes. This work investigates BPE segmentation recipes
across various data volumes and language pairs to evaluate MT system
performance. We find that utilizing asymmetric BPE, where the source and target
languages have different NMOs, significantly improves results over the
symmetric approach, especially in low-resource settings (50K, 100K, and 500K
sentence pairs). Specifically, asymmetric BPE yield statistically significant
($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in
low-resource setups. We validated this trend across six additional language
pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut),
observing statistically significant improvement in 10 out of 12 systems
compared to symmetric BPE. Our findings indicate a high NMO for the source (4K
to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results,
particularly benefiting low-resource MT.

</details>


### [70] [Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties](https://arxiv.org/abs/2511.03407)
*Célian Ringwald,Fabien Gandon,Catherine Faron,Franck Michel,Hanna Abi Akl*

Main category: cs.CL

TL;DR: 本文研究了小型语言模型（SLM）在基于SHACL形状指导下进行完整RDF图谱提取（包括数据类型属性和对象属性）的表现，发现主要瓶颈在于稀有属性的长尾分布。通过评估多种策略，发现最有效的方法是构建每个属性出现次数超过特定阈值的训练集，并公开了数据、代码和实验结果。


<details>
  <summary>Details</summary>
Motivation: 解决小型语言模型在关系抽取中对稀有属性（尤其是对象属性）表现不佳的问题，实现更完整的RDF图谱提取。

Method: 评估了分层采样、加权损失、数据集扩展和基于模板的合成数据增强等多种策略，重点分析不同方法对不平衡目标属性的处理效果。

Result: 构建一个每个属性出现次数超过给定阈值的训练集是最有效的策略，能显著提升SLM在长尾属性上的表现。

Conclusion: 为训练具备形状感知能力的小型语言模型提供了实用指导，强调了数据分布平衡的重要性，并指出了语义关系抽取未来的研究方向。

Abstract: Small language models (SLMs) have shown promises for relation extraction (RE)
when extracting RDF triples guided by SHACL shapes focused on common datatype
properties. This paper investigates how SLMs handle both datatype and object
properties for a complete RDF graph extraction. We show that the key bottleneck
is related to long-tail distribution of rare properties. To solve this issue,
we evaluate several strategies: stratified sampling, weighted loss, dataset
scaling, and template-based synthetic data augmentation. We show that the best
strategy to perform equally well over unbalanced target properties is to build
a training set where the number of occurrences of each property exceeds a given
threshold. To enable reproducibility, we publicly released our datasets,
experimental results and code. Our findings offer practical guidance for
training shape-aware SLMs and highlight promising directions for future work in
semantic RE.

</details>


### [71] [Efficient Reasoning via Thought-Training and Thought-Free Inference](https://arxiv.org/abs/2511.03408)
*Canhui Wu,Qiong Cao,Chao Xue,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: 本文提出了3TF框架，通过短到长的思维训练，使模型在推理时无需显式生成思维链即可实现高质量的隐式推理，提升了推理效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链提示方法主要依赖显式推理，虽然通过压缩提升效率，但依然需要生成详细的推理过程，限制了效率与实用性。

Method: 提出3TF框架，先训练一个兼具推理与非推理模式的混合模型，再利用思维链标注数据训练其内化结构化推理能力，并在推理时强制使用简洁、无思维输出的非推理模式。

Result: 实验表明，3TF在多种推理基准上显著优于基线模型，在无需显式生成思维链的情况下仍能保持甚至提升推理性能。

Conclusion: 3TF实现了高效且高质量的隐式推理，证明了无需显式逐步生成也能学习和执行复杂推理，为高效推理提供了新范式。

Abstract: Recent advances in large language models (LLMs) have leveraged explicit
Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most
existing methods primarily compress verbose reasoning outputs. These
Long-to-Short transformations aim to improve efficiency, but still rely on
explicit reasoning during inference. In this work, we introduce \textbf{3TF}
(\textbf{T}hought-\textbf{T}raining and \textbf{T}hought-\textbf{F}ree
inference), a framework for efficient reasoning that takes a Short-to-Long
perspective. We first train a hybrid model that can operate in both reasoning
and non-reasoning modes, and then further train it on CoT-annotated data to
internalize structured reasoning, while enforcing concise, thought-free outputs
at inference time using the no-reasoning mode. Unlike compression-based
approaches, 3TF improves the reasoning quality of non-reasoning outputs,
enabling models to perform rich internal reasoning implicitly while keeping
external outputs short. Empirically, 3TF-trained models obtain large
improvements on reasoning benchmarks under thought-free inference,
demonstrating that high quality reasoning can be learned and executed
implicitly without explicit step-by-step generation.

</details>


### [72] [Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG](https://arxiv.org/abs/2511.03410)
*Longpeng Qiu,Ting Li,Shuai Mao,Nan Yang,Xiaohui Yan*

Main category: cs.CL

TL;DR: QuestionRAG 是一个通过知识增强和强化学习对齐来提升大语言模型在问题纠正任务中表现的框架，有效减少误解和过度修正。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理输入错误的问题时常出现误解用户意图或过度修改问题结构的问题，影响问答系统的准确性。

Method: 提出 QuestionRAG 框架：利用外部知识（如搜索结果、相关实体）增强输入以改善理解，并采用强化学习使模型目标与精确纠正对齐，避免仅进行改写。

Result: 实验表明，知识增强有助于理解有缺陷的问题，而基于强化学习的对齐方法显著优于传统的监督微调，提升了模型遵循指令和泛化的能力。

Conclusion: 结合知识增强和强化学习对齐，QuestionRAG 充分释放了大语言模型在问题纠正任务中的潜力。

Abstract: Input errors in question-answering (QA) systems often lead to incorrect
responses. Large language models (LLMs) struggle with this task, frequently
failing to interpret user intent (misinterpretation) or unnecessarily altering
the original question's structure (over-correction). We propose QuestionRAG, a
framework that tackles these problems. To address misinterpretation, it
enriches the input with external knowledge (e.g., search results, related
entities). To prevent over-correction, it uses reinforcement learning (RL) to
align the model's objective with precise correction, not just paraphrasing. Our
results demonstrate that knowledge augmentation is critical for understanding
faulty questions. Furthermore, RL-based alignment proves significantly more
effective than traditional supervised fine-tuning (SFT), boosting the model's
ability to follow instructions and generalize. By integrating these two
strategies, QuestionRAG unlocks the full potential of LLMs for the question
correction task.

</details>


### [73] [CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field](https://arxiv.org/abs/2511.03441)
*Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre*

Main category: cs.CL

TL;DR: 本文介绍了CareMedEval数据集，用于评估大语言模型在生物医学批判性评价和推理任务中的表现，基于法国医学生的真实考试题目，包含534个问题，旨在揭示现有模型在研究局限性和统计分析等问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 为了提高大语言模型在生物医学领域批判性阅读和推理能力的评估，解决现有模型在此类专业任务中可靠性不足的问题。

Method: 构建了一个名为CareMedEval的新数据集，该数据集来源于法国医学生的真实考试，包含了基于37篇科学文章的534个问题，并对最先进的通用和生物医学专用大语言模型进行了基准测试。

Result: 测试结果显示，即使是开放和商业模型，在生成中间推理token的情况下也难以将精确匹配率提升至0.5以上，特别是在涉及研究局限性和统计分析的问题上表现不佳。

Conclusion: CareMedEval提供了一个具有挑战性的基准，能够揭示当前大语言模型在基于科学文献的批判性评价和推理任务中的局限性，为未来开发自动支持工具指明了方向。

Abstract: Critical appraisal of scientific literature is an essential skill in the
biomedical field. While large language models (LLMs) can offer promising
support in this task, their reliability remains limited, particularly for
critical reasoning in specialized domains. We introduce CareMedEval, an
original dataset designed to evaluate LLMs on biomedical critical appraisal and
reasoning tasks. Derived from authentic exams taken by French medical students,
the dataset contains 534 questions based on 37 scientific articles. Unlike
existing benchmarks, CareMedEval explicitly evaluates critical reading and
reasoning grounded in scientific papers. Benchmarking state-of-the-art
generalist and biomedical-specialized LLMs under various context conditions
reveals the difficulty of the task: open and commercial models fail to exceed
an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens
considerably improves the results. Yet, models remain challenged especially on
questions about study limitations and statistical analysis. CareMedEval
provides a challenging benchmark for grounded reasoning, exposing current LLM
limitations and paving the way for future development of automated support for
critical appraisal.

</details>


### [74] [Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction](https://arxiv.org/abs/2511.03466)
*Ringwald Celian,Gandon Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: 提出Kastor框架，通过RDF模式提取和迭代学习提升小语言模型在特定领域知识库补全中的性能。


<details>
  <summary>Details</summary>
Motivation: 为了满足特定领域知识库补全和优化的需求，改进传统基于SHACL形状的验证方法。

Method: 将传统单一SHACL形状验证转化为评估所有可能属性组合，并选择最优组合进行训练；采用迭代学习优化噪声知识库。

Result: 显著提升了模型的泛化能力和性能，能够有效发现新的相关事实。

Conclusion: Kastor框架能有效增强小语言模型在有限数据下的关系抽取能力，适用于专业化领域的知识库构建与 refinement。

Abstract: RDF pattern-based extraction is a compelling approach for fine-tuning small
language models (SLMs) by focusing a relation extraction task on a specified
SHACL shape. This technique enables the development of efficient models trained
on limited text and RDF data. In this article, we introduce Kastor, a framework
that advances this approach to meet the demands for completing and refining
knowledge bases in specialized domains. Kastor reformulates the traditional
validation task, shifting from single SHACL shape validation to evaluating all
possible combinations of properties derived from the shape. By selecting the
optimal combination for each training example, the framework significantly
enhances model generalization and performance. Additionally, Kastor employs an
iterative learning process to refine noisy knowledge bases, enabling the
creation of robust models capable of uncovering new, relevant facts

</details>


### [75] [BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation](https://arxiv.org/abs/2511.03498)
*Kazi Reyazul Hasan,Mubasshira Musarrat,A. B. M. Alim Al Islam,Muhammad Abdullah Adnan*

Main category: cs.CL

TL;DR: 本文提出了BanglaSTEM，一个包含5000个来自STEM领域的高质量孟加拉语-英语句子对的数据集，旨在提升技术术语的翻译准确性。通过使用语言模型生成并经人工筛选的翻译数据训练T5模型，在代码生成和数学问题求解任务中显著提高了孟加拉语技术内容的翻译效果。


<details>
  <summary>Details</summary>
Motivation: 现有的孟加拉语到英语翻译系统在处理技术术语时表现不佳，容易误译专业词汇，影响下游任务的准确性，因此需要一个专注于STEM领域高质量翻译的数据集。

Method: 从STEM领域收集孟加拉语句子，生成超过12000个机器翻译结果，通过人工评估筛选出5000个高质量、术语准确的双语句子对，构建BanglaSTEM数据集，并基于该数据集训练T5模型。

Result: 在代码生成和数学问题求解两个任务上，使用所训练的翻译模型显著提升了技术内容的翻译准确率和最终任务性能。

Conclusion: BanglaSTEM有效改善了孟加拉语技术文本的英译质量，使孟加拉语使用者能更有效地利用以英语为主的大型语言模型，促进多语言技术公平性。

Abstract: Large language models work well for technical problem solving in English but
perform poorly when the same questions are asked in Bangla. A simple solution
would be to translate Bangla questions into English first and then use these
models. However, existing Bangla-English translation systems struggle with
technical terms. They often mistranslate specialized vocabulary, which changes
the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a
dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM
fields including computer science, mathematics, physics, chemistry, and
biology. We generated over 12,000 translations using language models and then
used human evaluators to select the highest quality pairs that preserve
technical terminology correctly. We train a T5-based translation model on
BanglaSTEM and test it on two tasks: generating code and solving math problems.
Our results show significant improvements in translation accuracy for technical
content, making it easier for Bangla speakers to use English-focused language
models effectively. Both the BanglaSTEM dataset and the trained translation
model are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.

</details>


### [76] [HaluMem: Evaluating Hallucinations in Memory Systems of Agents](https://arxiv.org/abs/2511.03506)
*Ding Chen,Simin Niu,Kehang Li,Peng Liu,Xiangping Zheng,Bo Tang,Xinchi Li,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 本文提出了首个针对记忆系统的操作级幻觉评估基准HaluMem，通过定义记忆提取、更新和问答三个任务，全面揭示不同操作阶段的幻觉行为，并构建了大规模多轮人机交互数据集HaluMem-Medium和HaluMem-Long。实验表明现有记忆系统在提取和更新阶段易产生并累积幻觉，进而影响问答性能，未来需发展可解释且受约束的记忆操作机制以提升记忆可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的记忆幻觉评估主要依赖端到端问答，难以定位幻觉产生的具体操作阶段，因此需要一种细粒度的评估方法来识别和分析记忆系统在存储与检索过程中的幻觉来源。

Method: 提出HaluMem基准，包含记忆提取、更新和问答三项任务，并构建两个大规模多轮对话数据集HaluMem-Medium和HaluMem-Long，支持在不同上下文规模和任务复杂度下进行记忆幻觉评估。

Result: 实验发现现有记忆系统在提取和更新阶段容易生成和累积幻觉，这些错误会传播至问答阶段；HaluMem能够有效识别各操作阶段的幻觉行为。

Conclusion: 应聚焦于开发可解释且受约束的记忆操作机制，以系统性抑制幻觉，提升AI记忆系统的可靠性。

Abstract: Memory systems are key components that enable AI systems such as LLMs and AI
agents to achieve long-term learning and sustained interaction. However, during
memory storage and retrieval, these systems frequently exhibit memory
hallucinations, including fabrication, errors, conflicts, and omissions.
Existing evaluations of memory hallucinations are primarily end-to-end question
answering, which makes it difficult to localize the operational stage within
the memory system where hallucinations arise. To address this, we introduce the
Hallucination in Memory Benchmark (HaluMem), the first operation level
hallucination evaluation benchmark tailored to memory systems. HaluMem defines
three evaluation tasks (memory extraction, memory updating, and memory question
answering) to comprehensively reveal hallucination behaviors across different
operational stages of interaction. To support evaluation, we construct
user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and
HaluMem-Long. Both include about 15k memory points and 3.5k multi-type
questions. The average dialogue length per user reaches 1.5k and 2.6k turns,
with context lengths exceeding 1M tokens, enabling evaluation of hallucinations
across different context scales and task complexities. Empirical studies based
on HaluMem show that existing memory systems tend to generate and accumulate
hallucinations during the extraction and updating stages, which subsequently
propagate errors to the question answering stage. Future research should focus
on developing interpretable and constrained memory operation mechanisms that
systematically suppress hallucinations and improve memory reliability.

</details>


### [77] [One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework](https://arxiv.org/abs/2511.03508)
*Qi Jia,Kaiwei Zhang,Xiujie Song,Ye Shen,Xiangyang Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展的框架EvolIF，用于评估大语言模型在多轮对话中的指令跟随能力，通过解耦语言表层与用户意图模拟，动态构建包含状态变化和回溯的基准测试，并定义了一系列交互质量指标。实验结果表明GPT-5在对话轮次和鲁棒性上显著优于Gemini-2.5-Pro及其他模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常局限于固定轮数，容易饱和且无法反映用户交互体验，难以真实评估大语言模型在多话题连续对话中遵循指令的能力。

Method: 提出一个三层机制框架，分离语言形式与用户意图，跟踪约束、指令和话题，动态构建具有状态变化和回溯功能的基准测试，在模型耗尽模拟用户耐心时终止对话。

Result: 构建了包含九种不同约束类型的EvolIF基准测试，实验显示GPT-5平均支持18.54轮对话，指令跟随鲁棒性达70.31%，领先Gemini-2.5-Pro 11.41个百分点，其他模型表现明显落后。

Conclusion: 所提出的框架能更真实地模拟用户与大语言模型的交互过程，有效评估多轮指令跟随能力，GPT-5在此类任务中展现出显著优势。

Abstract: Understanding how well large language models can follow users' instructions
throughout a dialogue spanning multiple topics is of great importance for
data-intensive conversational applications. Existing benchmarks are often
limited to a fixed number of turns, making them susceptible to saturation and
failing to account for the user's interactive experience. In this work, we
propose an extensible framework for assessing multi-turn instruction-following
ability. At its core, our framework decouples linguistic surface forms from
user intent simulation through a three-layer mechanism that tracks constraints,
instructions, and topics. This framework mimics User-LLM interaction by
enabling the dynamic construction of benchmarks with state changes and
tracebacks, terminating a conversation only when the model exhausts a simulated
user's patience. We define a suite of metrics capturing the quality of the
interaction process. Using this framework, we construct EvolIF, an evolving
instruction-following benchmark incorporating nine distinct constraint types.
Our results indicate that GPT-5 exhibits superior instruction-following
performance. It sustains an average of 18.54 conversational turns and
demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant
margin of 11.41%, while other models lag far behind. All of the data and code
will be made publicly available online.

</details>


### [78] [SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties](https://arxiv.org/abs/2511.03542)
*Roberta Di Marino,Giovanni Dioguardi,Antonio Romano,Giuseppe Riccio,Mariano Barone,Marco Postiglione,Flora Amato,Vincenzo Moscato*

Main category: cs.CL

TL;DR: SOLVE-Med是一个多智能体架构，结合领域专用的小型语言模型来应对复杂医疗查询，展现出高性能和本地部署能力。


<details>
  <summary>Details</summary>
Motivation: 解决医疗问答系统在部署中面临的幻觉、偏见、计算需求高、隐私问题和跨领域专业技能需求等挑战。

Method: 采用路由器代理进行动态专家选择，十个针对特定医学领域微调的专用模型（每个1B参数），以及一个合成响应的编排代理。

Result: 在意大利医疗论坛数据的十个专业领域上评估，SOLVE-Med实现了ROUGE-1为0.301和BERTScore F1为0.697的优异性能，优于高达14B参数的独立模型。

Conclusion: SOLVE-Med通过多智能体与领域专用小模型的协同，在保证高性能的同时支持本地部署，有效应对医疗问答系统的多项挑战。

Abstract: Medical question answering systems face deployment challenges including
hallucinations, bias, computational demands, privacy concerns, and the need for
specialized expertise across diverse domains. Here, we present SOLVE-Med, a
multi-agent architecture combining domain-specialized small language models for
complex medical queries. The system employs a Router Agent for dynamic
specialist selection, ten specialized models (1B parameters each) fine-tuned on
specific medical domains, and an Orchestrator Agent that synthesizes responses.
Evaluated on Italian medical forum data across ten specialties, SOLVE-Med
achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697,
outperforming standalone models up to 14B parameters while enabling local
deployment. Our code is publicly available on GitHub:
https://github.com/PRAISELab-PicusLab/SOLVE-Med.

</details>


### [79] [Bearing Syntactic Fruit with Stack-Augmented Neural Networks](https://arxiv.org/abs/2511.03547)
*Brian DuSell,Ryan Cotterell*

Main category: cs.CL

TL;DR: 本文首次展示了无需特殊条件即可实现类人泛化的堆栈增强型神经网络，在经典问句生成任务中表现出更强的层次化泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络是否能在无歧义样本的情况下像人类儿童一样偏好基于层次语法结构的假设，探索现有模型的局限性。

Method: 测试三种基础架构（Transformer、简单RNN、LSTM）结合两种堆栈（Joulin & Mikolov的叠加堆栈和Dusell & Chiang的非确定性堆栈）的组合，并提出一种改进的堆栈RNN结构。

Result: 带有非确定性堆栈的Transformer在问句形成任务中表现最佳，所提出的堆栈RNN改进方法提升了层次化泛化能力。

Conclusion: 堆栈增强型神经网络比标准架构更接近人类语言习得过程，可作为心理语言学研究的有用工具。

Abstract: Any finite set of training data is consistent with an infinite number of
hypothetical algorithms that could have generated it. Studies have shown that
when human children learn language, they consistently favor hypotheses based on
hierarchical syntactic rules without ever encountering disambiguating examples.
A recent line of work has inquired as to whether common neural network
architectures share this bias, finding that they do so only under special
conditions: when syntactically supervised, when pre-trained on massive corpora,
or when trained long past convergence. In this paper, we demonstrate, for the
first time, neural network architectures that are able to generalize in
human-like fashion without any of the aforementioned requirements:
stack-augmented neural networks. We test three base architectures (transformer,
simple RNN, LSTM) augmented with two styles of stack: the superposition stack
of Joulin & Mikolov (2015) and a nondeterministic generalization of it proposed
by DuSell & Chiang (2023). We find that transformers with nondeterministic
stacks generalize best out of these architectures on a classical question
formation task. We also propose a modification to the stack RNN architecture
that improves hierarchical generalization. These results suggest that
stack-augmented neural networks may be more accurate models of human language
acquisition than standard architectures, serving as useful objects of
psycholinguistic study. Our code is publicly available.

</details>


### [80] [MultiZebraLogic: A Multilingual Logical Reasoning Benchmark](https://arxiv.org/abs/2511.03553)
*Sofie Helene Bruun,Dan Saattrup Smart*

Main category: cs.CL

TL;DR: 本文提出了MultiZebraLogic，一个包含九种日耳曼语的多语言逻辑推理数据集，用于评估大语言模型在不同难度和语言下的推理能力。通过生成不同规模、主题和干扰线索的斑马谜题，研究发现谜题大小和红鲱鱼线索显著影响模型表现，而语言和主题变化影响较小。


<details>
  <summary>Details</summary>
Motivation: 为了全面评估大语言模型的逻辑推理能力，需要跨语言、多任务且难度适中的高质量基准测试数据集。现有数据集在语言多样性和难度控制方面存在不足。

Method: 生成多语言（九种日耳曼语）、多主题、不同规模（2x3和4x5）的斑马谜题，引入14种线索类型和8种红鲱鱼（干扰）线索以调控难度，并在GPT-4o mini和o3-mini等模型上进行评测。同时发布数据集和可扩展的生成代码。

Result: 2x3和4x5规模的谜题分别对非推理和推理模型具有足够挑战性；加入5个红鲱鱼使o3-mini在4x5谜题上的准确率下降15±7%；语言（英语vs.丹麦语）和主题（房屋vs.丹麦三明治）变化对o3-mini性能无显著影响；线索类型与难度无显著相关性。发布了每种语言下128+1024个谜题的数据集。

Conclusion: MultiZebraLogic是一个可扩展、高可控性的多语言逻辑推理评测基准，能有效区分不同推理能力的模型，且适用于多种语言和主题，为未来模型评估提供了重要工具。

Abstract: Measuring the full abilities of large language models (LLMs) requires
benchmarks representing multiple tasks. We aim to create large, high-quality
datasets for comparison of logical reasoning skills across several languages
and of suitable difficulty for LLMs of various reasoning ability. We explore
multiple ways of increasing difficulty. We generate zebra puzzles in multiple
languages, themes, sizes and including 14 different clue types and 8 red
herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are
sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a
reasoning model), respectively. Including 5 red herrings decreases o3-mini
puzzle-level accuracy on 4x5 puzzles by 15$\pm$7 %. Scores of o3-mini on 4x5
puzzles are not significantly affected by use of English vs. Danish or the
common houses theme vs. the country-specific smoerrebroed theme. We find no
correlation between difficulty and the selected clue types. Datasets of
128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic
languages for sizes 2x3 and 4x5. We publish code for puzzle generation,
designed for adaptablity into more languages and themes.

</details>


### [81] [AILA--First Experiments with Localist Language Models](https://arxiv.org/abs/2511.03559)
*Joachim Diederich*

Main category: cs.CL

TL;DR: 本文提出了可控局部性（controllable locality）的新型Transformer语言模型框架，通过可调参数实现局部表示与分布式表示之间的动态平衡，兼顾可解释性与性能。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型依赖分布式表示，缺乏可解释性，难以满足监管领域对透明性的需求，因此需要一种能够连续控制表示局部性的方法。

Method: 提出带有可调局部性参数λ的架构，在不重新训练模型的情况下，动态插值局部主义编码与分布式表示，并在两层Transformer上进行实验，系统地调整λ值。

Result: 局部配置显著降低注意力熵（λ=1.0时为5.36比特 vs λ=0.0时为7.18比特），提高指针保真度；中间局部性（λ=0.6）在测试困惑度（4.65）和准确率（84.7%）上表现最优。

Conclusion: 局部主义语言模型通过信息论设计原则和显式惩罚阈值，为可解释性与性能之间的权衡提供了精确的数学控制，适用于需透明与能力兼备的监管场景。

Abstract: This paper presents the first empirical demonstration of controllable
locality in transformer language models, a novel architectural framework that
enables continuous control over the degree of representation localization
through a tunable locality dial parameter. Unlike traditional language models
that rely exclusively on distributed representations, our approach allows
dynamic interpolation between highly interpretable localist encodings and
efficient distributed representations without requiring model retraining. We
conducted experiments on the WikiText corpus using a two-layer transformer
architecture, systematically varying the locality parameter {\lambda} across
the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our
results demonstrate that localist configurations achieve dramatically lower
attention entropy, with {\lambda} = 1.0 yielding 5.36 bits compared to 7.18
bits at {\lambda} = 0.0, while maintaining substantially higher pointer
fidelity scores reflecting stronger alignment with rule-specified targets.
Prediction experiments reveal that intermediate locality values optimize the
tradeoff between interpretability and performance, with {\lambda} = 0.6
achieving test perplexity of 4.65 and accuracy of 84.7%. These findings
establish that localist language models provide a practical framework for
applications in regulated domains requiring both transparency and capability,
offering precise mathematical control over the interpretability-performance
spectrum through explicit penalty thresholds and information-theoretic design
principles.

</details>


### [82] [ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation](https://arxiv.org/abs/2511.03563)
*One Octadion,Bondan Sapta Prakoso,Nanang Yudi Setiawan,Novanto Yudistira*

Main category: cs.CL

TL;DR: 本文提出了一种结合微调和检索增强生成（RAG）的方法，以提升大语言模型在法律领域的应用能力，帮助政策制定者更有效地理解和制定法规。


<details>
  <summary>Details</summary>
Motivation: 为了支持政策制定者更好地理解、分析和制定法律规章，需要提升大语言模型对法律文本的理解与应用能力。

Method: 通过构建面向法律领域的监督数据集对大语言模型进行微调，并结合检索增强生成（RAG）技术，使其能够访问并整合最新的外部法律知识。

Result: 该方法显著提升了模型处理法律信息的能力，能够在解释现有法规和起草新法规方面有效辅助政策制定者。

Conclusion: 结合微调与RAG的方案能有效增强法律研究和法规制定的效率，为快速发展的法律领域提供了有力工具。

Abstract: In this study, we explore the fine-tuning of Large Language Models (LLMs) to
better support policymakers in their crucial work of understanding, analyzing,
and crafting legal regulations. To equip the model with a deep understanding of
legal texts, we curated a supervised dataset tailored to the specific needs of
the legal domain. Additionally, we integrated the Retrieval-Augmented
Generation (RAG) method, enabling the LLM to access and incorporate up-to-date
legal knowledge from external sources. This combination of fine-tuning and
RAG-based augmentation results in a tool that not only processes legal
information but actively assists policymakers in interpreting regulations and
drafting new ones that align with current needs. The results demonstrate that
this approach can significantly enhance the effectiveness of legal research and
regulation development, offering a valuable resource in the ever-evolving field
of law.

</details>


### [83] [Step-Audio-EditX Technical Report](https://arxiv.org/abs/2511.03601)
*Chao Yan,Boyong Wu,Peng Yang,Pengfei Tan,Guoqiang Hu,Yuxin Zhang,Xiangyu,Zhang,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.CL

TL;DR: 提出Step-Audio-EditX，首个基于大语言模型的开源音频编辑模型，利用大间隔合成数据实现高表现力和迭代音频编辑，超越现有模型在情感编辑等任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的音频编辑模型依赖嵌入先验或辅助模块，难以实现高表现力和迭代控制，需要一种更高效、灵活的方法。

Method: 仅使用大间隔合成数据训练基于大语言模型的音频编辑模型，摒弃传统表示级解耦方法，实现端到端的细粒度音频控制。

Result: Step-Audio-EditX在情感编辑和其他细粒度控制任务上优于MiniMax-2.6-hd和Doubao-Seed-TTS-2.0模型。

Conclusion: 大间隔合成数据可有效支持高性能音频编辑，Step-Audio-EditX为表达性语音编辑提供了新的开源解决方案。

Abstract: We present Step-Audio-EditX, the first open-source LLM-based audio model
excelling at expressive and iterative audio editing encompassing emotion,
speaking style, and paralinguistics alongside robust zero-shot text-to-speech
(TTS) capabilities.Our core innovation lies in leveraging only large-margin
synthetic data, which circumvents the need for embedding-based priors or
auxiliary modules. This large-margin learning approach enables both iterative
control and high expressivity across voices, and represents a fundamental pivot
from the conventional focus on representation-level disentanglement. Evaluation
results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and
Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.

</details>


### [84] [A systematic review of relation extraction task since the emergence of Transformers](https://arxiv.org/abs/2511.03610)
*Ringwald Celian,Gandon,Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: 本文对2019年至2024年基于Transformer模型的关系抽取研究进行了系统性综述，分析了34篇综述、64个数据集和104个模型，总结了方法进展、基准资源及语义网技术的融合，指出了当前趋势、局限性和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 关系抽取是自然语言处理中的关键任务，随着Transformer模型的兴起，该领域迅速发展，亟需系统性梳理以帮助研究人员把握进展与未来方向。

Method: 采用自动化框架收集和标注文献，对2019至2024年的34篇综述、64个数据集和104个模型进行多维度综合分析。

Result: 总结了关系抽取领域的方法学进展、常用数据集和模型发展趋势，揭示了当前研究的趋势、存在的局限性和未解决的挑战。

Conclusion: 该综述为关系抽取领域的研究者和实践者提供了全面的参考，有助于理解该领域的发展脉络和未来研究方向。

Abstract: This article presents a systematic review of relation extraction (RE)
research since the advent of Transformer-based models. Using an automated
framework to collect and annotate publications, we analyze 34 surveys, 64
datasets, and 104 models published between 2019 and 2024. The review highlights
methodological advances, benchmark resources, and the integration of semantic
web technologies. By consolidating results across multiple dimensions, the
study identifies current trends, limitations, and open challenges, offering
researchers and practitioners a comprehensive reference for understanding the
evolution and future directions of RE.

</details>


### [85] [Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability](https://arxiv.org/abs/2511.03635)
*Apoorva Upadhyaya,Wolfgang Nejdl,Marco Fisichella*

Main category: cs.CL

TL;DR: 提出了一种新的可解释的零样本立场检测框架IRIS，通过隐式和显式理由实现对文本立场的可解释分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法在零样本立场检测中存在泛化能力差、文本与目标之间连贯性不足以及过度依赖显式推理导致解释缺乏细致性的问题。

Method: 将立场检测视为信息检索排序任务，利用文本中的隐式理由（序列）和基于语言特征的显式理由来指导模型预测，并提供内在可解释性。

Result: 在VAST、EZ-STANCE、P-Stance和RFD数据集上使用50%、30%和10%训练数据进行实验，验证了模型的良好泛化能力和有效性。

Conclusion: IRIS框架通过结合隐式和显式理由，在不依赖真实理由标注的情况下实现了高性能且可解释的零样本立场检测。

Abstract: Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward
unseen targets. Existing research using contrastive, meta-learning, or data
augmentation suffers from generalizability issues or lack of coherence between
text and target. Recent works leveraging large language models (LLMs) for ZSSD
focus either on improving unseen target-specific knowledge or generating
explanations for stance analysis. However, most of these works are limited by
their over-reliance on explicit reasoning, provide coarse explanations that
lack nuance, and do not explicitly model the reasoning process, making it
difficult to interpret the model's predictions. To address these issues, in our
study, we develop a novel interpretable ZSSD framework, IRIS. We provide an
interpretable understanding of the attitude of the input towards the target
implicitly based on sequences within the text (implicit rationales) and
explicitly based on linguistic measures (explicit rationales). IRIS considers
stance detection as an information retrieval ranking task, understanding the
relevance of implicit rationales for different stances to guide the model
towards correct predictions without requiring the ground-truth of rationales,
thus providing inherent interpretability. In addition, explicit rationales
based on communicative features help decode the emotional and cognitive
dimensions of stance, offering an interpretable understanding of the author's
attitude towards the given target. Extensive experiments on the benchmark
datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10%
training data prove the generalizability of our model, benefiting from the
proposed architecture and interpretable design.

</details>


### [86] [ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation](https://arxiv.org/abs/2511.03656)
*Jing Gao,Shutiao Luo,Yumeng Liu,Yuanming Li,Hongji Zeng*

Main category: cs.CL

TL;DR: 本文提出了一个面向多领域中文文档问答的高质量数据集ChiMDQA，包含6,068个标注精良的问答对，覆盖学术、教育、金融、法律、医疗和新闻六个领域，并细分为十个类别，适用于文档理解、知识抽取和智能问答等NLP任务。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的发展，中文文档问答系统在实际业务场景中需求日益增长，但现有中文多文档问答数据集在领域覆盖和质量问题上仍存在不足，亟需构建高质量、多领域的中文问答数据集以推动相关研究与应用。

Method: 通过严格筛选来自六个不同领域的长文本文档，采用系统化的问题设计方法，构建了包含6,068个高质量问答对的ChiMDQA数据集，并将其细分为十个类别；同时建立了细粒度的评估体系，确保数据集的多样性与可靠性。

Result: ChiMDQA数据集具有良好的领域覆盖性和问题类型多样性，支持多种NLP任务，如文档理解、知识提取和智能问答；论文还提供了数据集的设计目标、构建方法及评估体系，代码与数据已公开。

Conclusion: ChiMDQA是一个高质量、多领域、细粒度标注的中文多文档问答数据集，为中文信息处理任务提供了重要资源，有望推动中文智能问答及相关下游任务的研究与应用。

Abstract: With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.

</details>


### [87] [Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models](https://arxiv.org/abs/2511.03699)
*Francesco Corso,Francesco Pierri,Gianmarco De Francisci Morales*

Main category: cs.CL

TL;DR: 本研究探讨了大语言模型（LLMs）是否具有阴谋论倾向、是否存在社会人口偏见以及是否容易被诱导接受阴谋论观点。通过使用经过验证的心理测量量表，研究发现LLMs在一定程度上表现出对阴谋论的认同，且不同社会人口特征的提示会引发不均衡反应，揭示出潜在的偏见。此外，有针对性的提示可轻易使模型回应趋向阴谋论，凸显其易受操控的风险。


<details>
  <summary>Details</summary>
Motivation: 阴谋信念在错误信息传播和对机构不信任中起关键作用，而LLMs越来越多地被用作研究人类行为的代理，但其是否再现如阴谋心态等高阶心理结构尚不清楚。因此，有必要探究LLMs的社会保真度及其潜在风险。

Method: 采用经过验证的心理测量调查工具，在多种提示和条件设置下，对多个大语言模型进行测试，评估其阴谋心态的程度及受社会人口属性影响的变化。

Result: LLMs表现出对阴谋信念的部分认同；社会人口属性的提示产生不均衡影响，暴露出潜在偏见；通过特定提示可轻易引导模型朝向阴谋论立场。

Conclusion: LLMs存在 conspiratorial 倾向且易被操纵，反映出其内在的心理维度需被审慎评估，以推动计算社会科学的发展并制定相应的风险缓解策略。

Abstract: In this paper, we investigate whether Large Language Models (LLMs) exhibit
conspiratorial tendencies, whether they display sociodemographic biases in this
domain, and how easily they can be conditioned into adopting conspiratorial
perspectives. Conspiracy beliefs play a central role in the spread of
misinformation and in shaping distrust toward institutions, making them a
critical testbed for evaluating the social fidelity of LLMs. LLMs are
increasingly used as proxies for studying human behavior, yet little is known
about whether they reproduce higher-order psychological constructs such as a
conspiratorial mindset. To bridge this research gap, we administer validated
psychometric surveys measuring conspiracy mindset to multiple models under
different prompting and conditioning strategies. Our findings reveal that LLMs
show partial agreement with elements of conspiracy belief, and conditioning
with socio-demographic attributes produces uneven effects, exposing latent
demographic biases. Moreover, targeted prompts can easily shift model responses
toward conspiratorial directions, underscoring both the susceptibility of LLMs
to manipulation and the potential risks of their deployment in sensitive
contexts. These results highlight the importance of critically evaluating the
psychological dimensions embedded in LLMs, both to advance computational social
science and to inform possible mitigation strategies against harmful uses.

</details>


### [88] [Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask](https://arxiv.org/abs/2511.03718)
*Nan Li,Albert Gatt,Massimo Poesio*

Main category: cs.CL

TL;DR: 提出了一种面向HCRC MapTask语料库的视角化标注方案，用于追踪合作对话中理解的建立、分歧与修复过程，揭示表面共识下可能存在的指代错位。


<details>
  <summary>Details</summary>
Motivation: 在不对称对话环境中，参与者可能误以为达成共识但实际上指代不同实体，现有方法难以捕捉这种隐性误解，因此需要一种能够分别刻画说话人和听者理解状态的标注框架。

Method: 设计了一种视角化标注方案，对每个指代表达分别标注说话人和听者的已 grounding 理解，并通过受限的大语言模型标注流程对HCRC MapTask语料库中的13k指代表达进行标注，结合可靠性评估分析理解状态的动态变化。

Result: 发现词汇变体统一后完全误解较少，但多重性差异会系统性引发理解分歧，表明表观的共识可能掩盖指代错位；所构建的标注数据集为研究 grounded 误解提供了新资源。

Conclusion: 该框架不仅提供了分析合作对话中视角依赖性 grounding 的新工具，也为评估大语言模型（尤其是视觉-语言模型）在建模理解分歧方面的能力提供了基础。

Abstract: Collaborative dialogue relies on participants incrementally establishing
common ground, yet in asymmetric settings they may believe they agree while
referring to different entities. We introduce a perspectivist annotation scheme
for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures
speaker and addressee grounded interpretations for each reference expression,
enabling us to trace how understanding emerges, diverges, and repairs over
time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k
annotated reference expressions with reliability estimates and analyze the
resulting understanding states. The results show that full misunderstandings
are rare once lexical variants are unified, but multiplicity discrepancies
systematically induce divergences, revealing how apparent grounding can mask
referential misalignment. Our framework provides both a resource and an
analytic lens for studying grounded misunderstanding and for evaluating
(V)LLMs' capacity to model perspective-dependent grounding in collaborative
dialogue.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [89] [Toward an Agricultural Operational Design Domain: A Framework](https://arxiv.org/abs/2511.02937)
*Mirco Felske,Jannik Redenius,Georg Happich,Julius Schöning*

Main category: cs.RO

TL;DR: 本文提出了农业领域专用的Operational Design Domain（Ag-ODD）框架，以应对农业自动化中驾驶与作业过程交织带来的复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有ODD概念无法满足农业自动化在复杂多变环境中对一致性、可验证性和结构化描述的需求。

Method: 结合ASAM Open ODD和CityGML构建Ag-ODD描述方法；扩展PEGASUS 6层模型为7层模型，增加过程层以刻画动态农业操作；设计迭代验证流程，确保Ag-ODD与逻辑场景的一致性和完整性。

Result: Ag-ODD框架能够系统化地描述和验证农业自动驾驶系统的运行边界，支持环境描述的标准化与可扩展性，案例验证了其有效性。

Conclusion: Ag-ODD框架为农业自动化系统提供了结构化、透明且可验证的操作域描述方案，有助于提升开发与验证过程的可靠性与一致性。

Abstract: The agricultural sector increasingly relies on autonomous systems that
operate in complex and variable environments. Unlike on-road applications,
agricultural automation integrates driving and working processes, each of which
imposes distinct operational constraints. Handling this complexity and ensuring
consistency throughout the development and validation processes requires a
structured, transparent, and verified description of the environment. However,
existing Operational Design Domain (ODD) concepts do not yet address the unique
challenges of agricultural applications.
  Therefore, this work introduces the Agricultural ODD (Ag-ODD) Framework,
which can be used to describe and verify the operational boundaries of
autonomous agricultural systems. The Ag-ODD Framework consists of three core
elements. First, the Ag-ODD description concept, which provides a structured
method for unambiguously defining environmental and operational parameters
using concepts from ASAM Open ODD and CityGML. Second, the 7-Layer Model
derived from the PEGASUS 6-Layer Model, has been extended to include a process
layer to capture dynamic agricultural operations. Third, the iterative
verification process verifies the Ag-ODD against its corresponding logical
scenarios, derived from the 7-Layer Model, to ensure the Ag-ODD's completeness
and consistency.
  Together, these elements provide a consistent approach for creating
unambiguous and verifiable Ag-ODD. Demonstrative use cases show how the Ag-ODD
Framework can support the standardization and scalability of environmental
descriptions for autonomous agricultural systems.

</details>


### [90] [Comprehensive Assessment of LiDAR Evaluation Metrics: A Comparative Study Using Simulated and Real Data](https://arxiv.org/abs/2511.02994)
*Syed Mostaquim Ali,Taufiq Rahman,Ghazal Farhani,Mohamed H. Zaki,Benoit Anctil,Dominique Charlebois*

Main category: cs.RO

TL;DR: 本文提出了一种评估虚拟测试环境中LiDAR扫描与真实世界数据一致性的方法，通过多种指标比较发现密度感知 Chamfer 距离（DCD）在所有情况下表现最佳，并验证了模拟与实际LiDAR扫描在几何和感知上的相似性。


<details>
  <summary>Details</summary>
Motivation: 由于传统物理测试成本高且不安全，需要可靠的虚拟测试环境来验证自动驾驶系统的安全性，因此需有效评估仿真与真实LiDAR数据的一致性。

Method: 设计实验比较多种评估指标在噪声、密度、畸变、传感器姿态等条件下的敏感性和准确性；基于真实LiDAR数据构建虚拟测试环境，并生成对应位姿的模拟LiDAR扫描，比较其几何相似性和模型感知输出。

Result: 密度感知 Chamfer 距离（DCD）在各项测试中表现最优；实际与模拟LiDAR扫描的平均DCD为0.63，语义分割mIoU为21%（校正强度后），显示几何差异较小但感知输出存在显著差异；DCD与感知方法相关性最高。

Conclusion: DCD是评估虚拟与真实LiDAR扫描相似性的最有效指标，适用于虚拟测试环境的验证，有助于提升自动驾驶系统测试的可靠性。

Abstract: For developing safe Autonomous Driving Systems (ADS), rigorous testing is
required before they are deemed safe for road deployments. Since comprehensive
conventional physical testing is impractical due to cost and safety concerns,
Virtual Testing Environments (VTE) can be adopted as an alternative. Comparing
VTE-generated sensor outputs against their real-world analogues can be a strong
indication that the VTE accurately represents reality. Correspondingly, this
work explores a comprehensive experimental approach to finding evaluation
metrics suitable for comparing real-world and simulated LiDAR scans. The
metrics were tested in terms of sensitivity and accuracy with different noise,
density, distortion, sensor orientation, and channel settings. From comparing
the metrics, we found that Density Aware Chamfer Distance (DCD) works best
across all cases. In the second step of the research, a Virtual Testing
Environment was generated using real LiDAR scan data. The data was collected in
a controlled environment with only static objects using an instrumented vehicle
equipped with LiDAR, IMU and cameras. Simulated LiDAR scans were generated from
the VTEs using the same pose as real LiDAR scans. The simulated and LiDAR scans
were compared in terms of model perception and geometric similarity. Actual and
simulated LiDAR scans have a similar semantic segmentation output with a mIoU
of 21\% with corrected intensity and an average density aware chamfer distance
(DCD) of 0.63. This indicates a slight difference in the geometric properties
of simulated and real LiDAR scans and a significant difference between model
outputs. During the comparison, density-aware chamfer distance was found to be
the most correlated among the metrics with perception methods.

</details>


### [91] [A Collaborative Reasoning Framework for Anomaly Diagnostics in Underwater Robotics](https://arxiv.org/abs/2511.03075)
*Markus Buchholz,Ignacio Carlucho,Yvan R. Petillot*

Main category: cs.RO

TL;DR: 提出AURA框架，结合大语言模型、数字孪生和人在回路机制，通过双智能体协作实现实时机器人异常检测与诊断，并利用专家反馈持续优化模型。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景中，自主系统的可靠部署需要结合人类专家与AI分析，尤其在面对不可预见的异常时。

Method: 设计AURA框架，包含低层级状态异常表征智能体和高层级诊断推理智能体，结合LLM、高保真数字孪生和人在回路交互，实现异常检测与根因分析，并将人工验证结果用于模型迭代。

Result: 实现了实时异常检测与诊断的协同系统，构建了从人类反馈中持续学习的闭环机制，提升了系统的可信赖性与适应性。

Conclusion: AURA为可信、持续改进的人机协同系统提供了一个可行范式，推动AI从静态工具演变为自适应伙伴。

Abstract: The safe deployment of autonomous systems in safety-critical settings
requires a paradigm that combines human expertise with AI-driven analysis,
especially when anomalies are unforeseen. We introduce AURA (Autonomous
Resilience Agent), a collaborative framework for anomaly and fault diagnostics
in robotics. AURA integrates large language models (LLMs), a high-fidelity
digital twin (DT), and human-in-the-loop interaction to detect and respond to
anomalous behavior in real time. The architecture uses two agents with clear
roles: (i) a low-level State Anomaly Characterization Agent that monitors
telemetry and converts signals into a structured natural-language problem
description, and (ii) a high-level Diagnostic Reasoning Agent that conducts a
knowledge-grounded dialogue with an operator to identify root causes, drawing
on external sources. Human-validated diagnoses are then converted into new
training examples that refine the low-level perceptual model. This feedback
loop progressively distills expert knowledge into the AI, transforming it from
a static tool into an adaptive partner. We describe the framework's operating
principles and provide a concrete implementation, establishing a pattern for
trustworthy, continually improving human-robot teams.

</details>


### [92] [WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models](https://arxiv.org/abs/2511.03077)
*R. Khorrambakht,Joaquim Ortiz-Haro,Joseph Amigo,Omar Mostafa,Daniel Dugas,Franziska Meier,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本文提出一种基于模型的方法，利用易于收集的无结构“玩耍”数据学习视觉世界模型和动作采样器，并结合MCTS规划与零阶MPC执行，显著优于行为克隆基线。


<details>
  <summary>Details</summary>
Motivation: 行为克隆依赖精细的人类示范，难以迁移且数据采集成本高；希望通过更低成本、可扩展的方式实现机器人复杂任务求解。

Method: 使用几小时无结构的玩耍数据训练扩散模型作为动作采样器和视觉世界模型，结合奖励模型，采用MCTS进行长序列动作规划，并通过零阶MPC在真实机器人上执行计划。

Result: 在三个真实世界机器人任务中验证了方法的有效性，显示规划显著优于行为克隆基线，尤其在需要复杂建模与规划的任务中表现更好。

Conclusion: 基于模型的规划方法结合动作采样器可有效减少世界模型幻觉，提升泛化能力，是通向通用机器人技能学习的可行路径。

Abstract: Robots must understand their environment from raw sensory inputs and reason
about the consequences of their actions in it to solve complex tasks. Behavior
Cloning (BC) leverages task-specific human demonstrations to learn this
knowledge as end-to-end policies. However, these policies are difficult to
transfer to new tasks, and generating training data is challenging because it
requires careful demonstrations and frequent environment resets. In contrast to
such policy-based view, in this paper we take a model-based approach where we
collect a few hours of unstructured easy-to-collect play data to learn an
action-conditioned visual world model, a diffusion-based action sampler, and
optionally a reward model. The world model -- in combination with the action
sampler and a reward model -- is then used to optimize long sequences of
actions with a Monte Carlo Tree Search (MCTS) planner. The resulting plans are
executed on the robot via a zeroth-order Model Predictive Controller (MPC). We
show that the action sampler mitigates hallucinations of the world model during
planning and validate our approach on 3 real-world robotic tasks with varying
levels of planning and modeling complexity. Our experiments support the
hypothesis that planning leads to a significant improvement over BC baselines
on a standard manipulation test environment.

</details>


### [93] [3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors](https://arxiv.org/abs/2511.03078)
*Rohan Kota,Kaival Shah,J. Edward Colgate,Gregory Reardon*

Main category: cs.RO

TL;DR: 本文提出了一种名为\libname{}的开源工具，可将低成本3D打印机改造成自动化触觉传感器校准设备，用于生成大量带标签的训练数据，并利用卷积神经网络对DIGIT和GelSight Mini等视觉型触觉传感器进行高精度深度图重建，显著提升了校准效率与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 触觉感知在机器人灵巧操作中至关重要，但现有触觉传感器校准过程繁琐且依赖人工，缺乏标准化、自动化的解决方案，限制了其广泛应用。

Method: 开发\libname{}系统，利用3D打印机实现自动化数据采集；使用收集的数据训练定制的卷积神经网络，以实现从原始传感信号到深度图的映射，并通过消融实验分析数据量对校准性能的影响。

Result: \libname{}成功实现了对DIGIT和GelSight Mini传感器的高效校准，能够重建高质量深度图；消融研究提供了实际数据需求指南；模型在未见物体上表现出良好的准确性和泛化性能。

Conclusion: \libname{}通过自动化触觉传感器校准流程，降低了使用门槛，有望加速触觉感知研究，促进其在机器人系统中的实际部署与集成。

Abstract: Tactile sensing plays a key role in enabling dexterous and reliable robotic
manipulation, but realizing this capability requires substantial calibration to
convert raw sensor readings into physically meaningful quantities. Despite its
near-universal necessity, the calibration process remains ad hoc and
labor-intensive. Here, we introduce \libname{}, an open-source library that
transforms a low-cost 3D printer into an automated probing device capable of
generating large volumes of labeled training data for tactile sensor
calibration. We demonstrate the utility of \libname{} by calibrating two
commercially available vision-based tactile sensors, DIGIT and GelSight Mini,
to reconstruct high-quality depth maps using the collected data and a custom
convolutional neural network. In addition, we perform a data ablation study to
determine how much data is needed for accurate calibration, providing practical
guidelines for researchers working with these specific sensors, and we
benchmark the trained models on previously unseen objects to evaluate
calibration accuracy and generalization performance. By automating tactile
sensor calibration, \libname{} can accelerate tactile sensing research,
simplify sensor deployment, and promote the practical integration of tactile
sensing in robotic platforms.

</details>


### [94] [Multi-robot searching with limited sensing range for static and mobile intruders](https://arxiv.org/abs/2511.03622)
*Swadhin Agrawal,Sujoy Bhore,Joseph S. B. Mitchell,P. B. Sujit,Aayush Gohil*

Main category: cs.RO

TL;DR: 研究了在简单连通的正交多边形中使用多个机器人搜索静态和移动入侵者的问题，由于问题为NP难，提出了基于空间填充曲线、随机搜索和协作随机搜索的高效鲁棒算法，并分析了机器人数量与搜索时间之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 由于在几何域中搜索入侵者的问题是NP难的，特别是对于静态入侵者，需要设计高效的搜索策略以应对计算复杂性。

Method: 提出了基于空间填充曲线、随机搜索和协作随机搜索的算法，并结合正交多边形的几何特性进行分析。

Result: 开发了多种高效且鲁棒的搜索算法，并评估了机器人数量与搜索完成时间之间的权衡关系。

Conclusion: 尽管搜索问题是NP难的，但所提出的算法在实际应用中能有效平衡资源使用与搜索效率。

Abstract: We consider the problem of searching for an intruder in a geometric domain by
utilizing multiple search robots. The domain is a simply connected orthogonal
polygon with edges parallel to the cartesian coordinate axes. Each robot has a
limited sensing capability. We study the problem for both static and mobile
intruders. It turns out that the problem of finding an intruder is NP-hard,
even for a stationary intruder. Given this intractability, we turn our
attention towards developing efficient and robust algorithms, namely methods
based on space-filling curves, random search, and cooperative random search.
Moreover, for each proposed algorithm, we evaluate the trade-off between the
number of search robots and the time required for the robots to complete the
search process while considering the geometric properties of the connected
orthogonal search area.

</details>


### [95] [SENT Map -- Semantically Enhanced Topological Maps with Foundation Models](https://arxiv.org/abs/2511.03165)
*Raj Surya Rajendran Kathirvel,Zach A Chavis,Stephen J. Guy,Karthik Desingh*

Main category: cs.RO

TL;DR: 提出SENT-Map，一种语义增强的拓扑地图，用于室内环境表示，结合基础模型支持机器人自主导航与操作。


<details>
  <summary>Details</summary>
Motivation: 传统地图缺乏语义信息，难以支持复杂任务；需结合人类与基础模型可理解的格式进行环境表示。

Method: 采用两阶段方法：首先利用视觉基础模型与操作员共同构建环境地图，然后结合SENT-Map表示和自然语言查询在基础模型中进行规划。地图以JSON文本格式表示，便于添加和编辑语义信息。

Result: 实验结果表明，语义增强使即使小型本地部署的基础模型也能在室内环境中成功规划路径。

Conclusion: SENT-Map通过语义增强和人机可读的JSON格式，有效提升了基础模型在机器人导航与操作中的实用性与可行性。

Abstract: We introduce SENT-Map, a semantically enhanced topological map for
representing indoor environments, designed to support autonomous navigation and
manipulation by leveraging advancements in foundational models (FMs). Through
representing the environment in a JSON text format, we enable semantic
information to be added and edited in a format that both humans and FMs
understand, while grounding the robot to existing nodes during planning to
avoid infeasible states during deployment. Our proposed framework employs a two
stage approach, first mapping the environment alongside an operator with a
Vision-FM, then using the SENT-Map representation alongside a natural-language
query within an FM for planning. Our experimental results show that
semantic-enhancement enables even small locally-deployable FMs to successfully
plan over indoor environments.

</details>


### [96] [Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning](https://arxiv.org/abs/2511.03167)
*Xin Liu,Jinze Wu,Yinghui Li,Chenkun Qi,Yufei Xue,Feng Gao*

Main category: cs.RO

TL;DR: 本文提出了一种基于运动先验的深度强化学习方法，成功实现了六足机器人在复杂地形中的自然步态行走。


<details>
  <summary>Details</summary>
Motivation: 如何有效协调多条腿以在复杂环境中生成自然且鲁棒的运动是多足机器人面临的关键问题。

Method: 生成优化的运动先验数据集，并训练对抗性判别器来引导机器人学习自然步态，使用深度强化学习算法。

Result: 所学策略成功迁移到真实六足机器人，展现出自然的步态模式和在复杂地形中无需视觉信息的强鲁棒性。

Conclusion: 这是首次在真实六足机器人上使用强化学习控制器实现复杂地形行走。

Abstract: Multi-legged robots offer enhanced stability to navigate complex terrains
with their multiple legs interacting with the environment. However, how to
effectively coordinate the multiple legs in a larger action exploration space
to generate natural and robust movements is a key issue. In this paper, we
introduce a motion prior-based approach, successfully applying deep
reinforcement learning algorithms to a real hexapod robot. We generate a
dataset of optimized motion priors, and train an adversarial discriminator
based on the priors to guide the hexapod robot to learn natural gaits. The
learned policy is then successfully transferred to a real hexapod robot, and
demonstrate natural gait patterns and remarkable robustness without visual
information in complex terrains. This is the first time that a reinforcement
learning controller has been used to achieve complex terrain walking on a real
hexapod robot.

</details>


### [97] [Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control](https://arxiv.org/abs/2511.03181)
*Rewida Ali,Cristian C. Beltran-Hernandez,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出一种基于学习的框架，结合大语言模型和混合模仿与强化学习策略，用于机器人完成礼品包装任务，在真实场景中达到97%的成功率。


<details>
  <summary>Details</summary>
Motivation: 在仓库和零售环境中，人机协作处理可变形物体（如纸张、袋子、织物）具有挑战性，主要由于材料动力学不可预测且需要自适应力控制。礼品包装作为一个典型长周期操作任务，体现了这些难点。

Method: 提出一个融合大型语言模型驱动的高层任务规划器与底层混合模仿学习和强化学习策略的框架。核心是子任务感知机器人变换器（START），通过引入子任务ID捕捉整个包装序列中的长程时序依赖，实现统一策略学习。

Result: 该框架在真实世界礼品包装任务中实现了97%的成功率，表现出对整个流程的鲁棒性和灵活性，并减少对专用模型的需求。

Conclusion: 所提方法能有效整合高层意图与精细力控，支持复杂可变形物体操作，为长周期人机协作任务提供可行解决方案。

Abstract: Human-robot cooperation is essential in environments such as warehouses and
retail stores, where workers frequently handle deformable objects like paper,
bags, and fabrics. Coordinating robotic actions with human assistance remains
difficult due to the unpredictable dynamics of deformable materials and the
need for adaptive force control. To explore this challenge, we focus on the
task of gift wrapping, which exemplifies a long-horizon manipulation problem
involving precise folding, controlled creasing, and secure fixation of paper.
Success is achieved when the robot completes the sequence to produce a neatly
wrapped package with clean folds and no tears.
  We propose a learning-based framework that integrates a high-level task
planner powered by a large language model (LLM) with a low-level hybrid
imitation learning (IL) and reinforcement learning (RL) policy. At its core is
a Sub-task Aware Robotic Transformer (START) that learns a unified policy from
human demonstrations. The key novelty lies in capturing long-range temporal
dependencies across the full wrapping sequence within a single model. Unlike
vanilla Action Chunking with Transformer (ACT), typically applied to short
tasks, our method introduces sub-task IDs that provide explicit temporal
grounding. This enables robust performance across the entire wrapping process
and supports flexible execution, as the policy learns sub-goals rather than
merely replicating motion sequences.
  Our framework achieves a 97% success rate on real-world wrapping tasks. We
show that the unified transformer-based policy reduces the need for specialized
models, allows controlled human supervision, and effectively bridges high-level
intent with the fine-grained force control required for deformable object
manipulation.

</details>


### [98] [Collaborative Assembly Policy Learning of a Sightless Robot](https://arxiv.org/abs/2511.03189)
*Zeqing Zhang,Weifeng Lu,Lei Yang,Wei Jing,Bowei Tang,Jia Pan*

Main category: cs.RO

TL;DR: 提出一种结合人类设计的导纳控制器的新型强化学习方法，用于物理人机协作中的盲板插入任务，相较于传统导纳控制在成功率、完成时间和人力负荷方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统导纳控制难以准确估计人类意图，而现有强化学习方法因安全约束和稀疏奖励不适用于板插入任务。

Method: 提出一种新型强化学习框架，利用人类设计的导纳控制器作为策略引导，实现更主动的机器人行为并减少人类操作力。

Result: 仿真与真实实验表明，该方法相比传统导纳控制具有更高的成功率、更短的任务完成时间以及显著降低的人类施加的力/力矩。

Conclusion: 所提方法有效提升了盲式人机协作插入任务的性能，平衡了安全性、效率与人类疲劳。

Abstract: This paper explores a physical human-robot collaboration (pHRC) task
involving the joint insertion of a board into a frame by a sightless robot and
a human operator. While admittance control is commonly used in pHRC tasks, it
can be challenging to measure the force/torque applied by the human for
accurate human intent estimation, limiting the robot's ability to assist in the
collaborative task. Other methods that attempt to solve pHRC tasks using
reinforcement learning (RL) are also unsuitable for the board-insertion task
due to its safety constraints and sparse rewards. Therefore, we propose a novel
RL approach that utilizes a human-designed admittance controller to facilitate
more active robot behavior and reduce human effort. Through simulation and
real-world experiments, we demonstrate that our approach outperforms admittance
control in terms of success rate and task completion time. Additionally, we
observed a significant reduction in measured force/torque when using our
proposed approach compared to admittance control. The video of the experiments
is available at https://youtu.be/va07Gw6YIog.

</details>


### [99] [GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement](https://arxiv.org/abs/2511.03400)
*Minquan Gao,Xinyi Li,Qing Yan,Xiaojian Sun,Xiaopan Zhang,Chien-Ming Huang,Jiachen Li*

Main category: cs.RO

TL;DR: 提出GUIDES框架，通过结合基础模型的语义指导来增强预训练机器人策略，无需重构架构，实现任务成功率和运动精度的提升。


<details>
  <summary>Details</summary>
Motivation: 预训练机器人策略缺乏基础模型的语义感知能力，但完全替换成本高且会丢失已有知识，因此需要一种轻量级方法来增强而非替代现有策略。

Method: 使用微调的视觉-语言模型（Instructor）生成上下文指令，并通过辅助模块将其编码为引导嵌入，注入策略的潜在空间；结合基于大语言模型的Reflector在推理时监控置信度并触发推理循环以优化动作。

Result: 在RoboCasa仿真环境中验证了多种策略架构下任务成功率显著提升，并在UR5机器人上实现了抓取等关键子任务的运动精度提高。

Conclusion: GUIDES提供了一种实用且资源高效的方法，在不替换已有验证策略的前提下，通过语义引导增强其性能。

Abstract: Pre-trained robot policies serve as the foundation of many validated robotic
systems, which encapsulate extensive embodied knowledge. However, they often
lack the semantic awareness characteristic of foundation models, and replacing
them entirely is impractical in many situations due to high costs and the loss
of accumulated knowledge. To address this gap, we introduce GUIDES, a
lightweight framework that augments pre-trained policies with semantic guidance
from foundation models without requiring architectural redesign. GUIDES employs
a fine-tuned vision-language model (Instructor) to generate contextual
instructions, which are encoded by an auxiliary module into guidance
embeddings. These embeddings are injected into the policy's latent space,
allowing the legacy model to adapt to this new semantic input through brief,
targeted fine-tuning. For inference-time robustness, a large language
model-based Reflector monitors the Instructor's confidence and, when confidence
is low, initiates a reasoning loop that analyzes execution history, retrieves
relevant examples, and augments the VLM's context to refine subsequent actions.
Extensive validation in the RoboCasa simulation environment across diverse
policy architectures shows consistent and substantial improvements in task
success rates. Real-world deployment on a UR5 robot further demonstrates that
GUIDES enhances motion precision for critical sub-tasks such as grasping.
Overall, GUIDES offers a practical and resource-efficient pathway to upgrade,
rather than replace, validated robot policies.

</details>


### [100] [Value Elicitation for a Socially Assistive Robot Addressing Social Anxiety: A Participatory Design Approach](https://arxiv.org/abs/2511.03444)
*Vesna Poprcova,Iulia Lefter,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 本研究通过与心理健康领域学术研究人员的参与式设计工作坊，探讨了用于支持社交焦虑的社交辅助机器人应具备的核心设计价值。


<details>
  <summary>Details</summary>
Motivation: 由于社交焦虑普遍存在但治疗资源不足，技术特别是社交机器人有望提供补充支持，因此需要明确指导机器人设计的核心价值观。

Method: 采用参与式设计工作坊，结合创意、反思和设想活动，系统提取心理健康研究人员对社交辅助机器人在社交焦虑干预中的价值观、期望、需求和偏好。

Result: 研究揭示了适应性、接纳性和有效性等关键设计相关价值，并强调以研究为主导的价值提取方法的重要性。

Conclusion: 在开发用于社交焦虑支持的社交辅助机器人时，应重视用户中心和情境感知的设计，并基于研究引导的价值观进行系统设计。

Abstract: Social anxiety is a prevalent mental health condition that can significantly
impact overall well-being and quality of life. Despite its widespread effects,
adequate support or treatment for social anxiety is often insufficient.
Advances in technology, particularly in social robotics, offer promising
opportunities to complement traditional mental health. As an initial step
toward developing effective solutions, it is essential to understand the values
that shape what is considered meaningful, acceptable, and helpful. In this
study, a participatory design workshop was conducted with mental health
academic researchers to elicit the underlying values that should inform the
design of socially assistive robots for social anxiety support. Through
creative, reflective, and envisioning activities, participants explored
scenarios and design possibilities, allowing for systematic elicitation of
values, expectations, needs, and preferences related to robot-supported
interventions. The findings reveal rich insights into design-relevant
values-including adaptivity, acceptance, and efficacy-that are core to support
for individuals with social anxiety. This study highlights the significance of
a research-led approach to value elicitation, emphasising user-centred and
context-aware design considerations in the development of socially assistive
robots.

</details>


### [101] [Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control](https://arxiv.org/abs/2511.03481)
*Jianbo Yuan,Haohua Zhu,Jing Dai,Sheng Yi*

Main category: cs.RO

TL;DR: 本文提出了一种高性能、电缆驱动的五指机器人手Dex-Hand 021，具有12个主动和7个被动自由度，在1公斤的轻量化设计中实现19个自由度的灵活性。通过本体感知力传感阻抗控制方法提升了操作性能，实验显示其单指负载能力超过10 N，指尖重复精度低于0.001 m，力估计误差低于0.2 N。与PID控制相比，多物体抓取时关节扭矩降低31.19%，有效防止碰撞过载，成功执行33种GRASP分类动作和复杂操作任务。


<details>
  <summary>Details</summary>
Motivation: 复制人手多功能能力（如运动、感知和协调操作）在机器人系统中仍具挑战性，需在类人灵活性与工程约束（如复杂性、重量比、耐久性和力感知性能）之间取得平衡。

Method: 提出一种基于本体感知力传感的阻抗控制方法，用于增强机器人手的操作性能，并开发了Dex-Hand 021原型，采用电缆驱动结构，具备12个主动和7个被动自由度。

Result: 实验结果表明：单指负载能力>10 N，指尖重复精度<0.001 m，力估计误差<0.2 N；多物体抓取时关节扭矩比PID控制降低31.19%；能完成33种GRASP分类动作和复杂操作任务。

Conclusion: Dex-Hand 021在轻量化设计下实现了高灵巧性和优异的力感知控制性能，推动了工业级灵巧手的发展，增强了机器人操作与智能制造中的应用潜力。

Abstract: The human hand plays a vital role in daily life and industrial applications,
yet replicating its multifunctional capabilities-including motion, sensing, and
coordinated manipulation-with robotic systems remains a formidable challenge.
Developing a dexterous robotic hand requires balancing human-like agility with
engineering constraints such as complexity, size-to-weight ratio, durability,
and force-sensing performance. This letter presents Dex-Hand 021, a
high-performance, cable-driven five-finger robotic hand with 12 active and 7
passive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight
1 kg design. We propose a proprioceptive force-sensing-based admittance control
method to enhance manipulation. Experimental results demonstrate its superior
performance: a single-finger load capacity exceeding 10 N, fingertip
repeatability under 0.001 m, and force estimation errors below 0.2 N. Compared
to PID control, joint torques in multi-object grasping are reduced by 31.19%,
significantly improves force-sensing capability while preventing overload
during collisions. The hand excels in both power and precision grasps,
successfully executing 33 GRASP taxonomy motions and complex manipulation
tasks. This work advances the design of lightweight, industrial-grade dexterous
hands and enhances proprioceptive control, contributing to robotic manipulation
and intelligent manufacturing.

</details>


### [102] [ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications](https://arxiv.org/abs/2511.03497)
*Lei Fu,Sahar Salimpour,Leonardo Militano,Harry Edelman,Jorge Peña Queralta,Giovanni Toffetti*

Main category: cs.RO

TL;DR: 本文提出了一种基于Model Context Protocol (MCP) 的服务器，用于通过大语言模型（LLMs）和视觉语言模型（VLMs）以自然语言分析、可视化和处理ROS/ROS 2机器人数据包（bags），并开发了面向移动机器人的专用工具集及轻量级用户界面，支持对多种LLM/VLM模型的工具调用能力进行基准测试，实验结果显示不同模型在工具调用性能上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 尽管Agentic AI与具身AI是人工智能与机器人领域的两大前沿方向，但二者交叉的研究仍较匮乏，现有工具缺乏对自然语言驱动的机器人数据解析与交互的支持，因此需要构建一个结合MCP协议、面向机器人数据（如轨迹、激光扫描等）的智能分析平台。

Method: 设计并实现了一个支持ROS和ROS 2 bag文件分析的MCP服务器，集成领域特定工具以处理轨迹、激光扫描、变换和时间序列数据，并提供对标准ROS 2命令行工具的接口；同时开发了一个轻量级UI用于多LLM/VLM模型的工具调用性能评估，涵盖闭源与开源模型，在真实机器人数据上进行实验分析。

Result: 实验评估了八个先进的LLM/VLM模型的工具调用能力，发现Kimi K2和Claude Sonnet 4表现显著优于其他模型；同时揭示了影响调用成功率的关键因素，包括工具描述模式、参数数量以及可用工具数量等。

Conclusion: 该MCP服务器为具身智能体提供了自然语言驱动的数据分析能力，填补了Agentic Embodied AI交叉领域的空白，实验结果强调了优化工具接口设计对提升模型交互性能的重要性，所开源的代码也为后续研究提供了可扩展的基础平台。

Abstract: Agentic AI systems and Physical or Embodied AI systems have been two key
research verticals at the forefront of Artificial Intelligence and Robotics,
with Model Context Protocol (MCP) increasingly becoming a key component and
enabler of agentic applications. However, the literature at the intersection of
these verticals, i.e., Agentic Embodied AI, remains scarce. This paper
introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for
analyzing, visualizing and processing robot data with natural language through
LLMs and VLMs. We describe specific tooling built with robotics domain
knowledge, with our initial release focused on mobile robotics and supporting
natively the analysis of trajectories, laser scan data, transforms, or time
series data. This is in addition to providing an interface to standard ROS 2
CLI tools ("ros2 bag list" or "ros2 bag info"), as well as the ability to
filter bags with a subset of topics or trimmed in time. Coupled with the MCP
server, we provide a lightweight UI that allows the benchmarking of the tooling
with different LLMs, both proprietary (Anthropic, OpenAI) and open-source
(through Groq). Our experimental results include the analysis of tool calling
capabilities of eight different state-of-the-art LLM/VLM models, both
proprietary and open-source, large and small. Our experiments indicate that
there is a large divide in tool calling capabilities, with Kimi K2 and Claude
Sonnet 4 demonstrating clearly superior performance. We also conclude that
there are multiple factors affecting the success rates, from the tool
description schema to the number of arguments, as well as the number of tools
available to the models. The code is available with a permissive license at
https://github.com/binabik-ai/mcp-rosbags.

</details>


### [103] [Indicating Robot Vision Capabilities with Augmented Reality](https://arxiv.org/abs/2511.03550)
*Hong Wang,Ridhima Phatak,James Ocampo,Zhao Han*

Main category: cs.RO

TL;DR: 该研究探讨了人类对机器人视野（FoV）的错误认知问题，并提出四种增强现实（AR）中的FoV指示方法，通过用户实验评估其在准确性、信心、任务效率和工作负荷方面的影响。


<details>
  <summary>Details</summary>
Motivation: 人类常误以为机器人与自己具有相同的视野，导致在人机协作中出现误解和任务失败，尤其是在机器人无法更新环境模型时。因此，需要改善人类对机器人视觉能力的认知模型。

Method: 设计了四种从自我中心（机器人眼、头空间）到他人中心（任务空间）的AR视野指示方式，并开展了包含41名被试的用户实验，评估不同指示方式对准确性、信心、效率和认知负荷的影响。

Result: 位于任务空间的他人中心方块指示具有最高准确性，但解读速度较慢；更深的眼窝（物理改造）这一自我中心指示也提高了准确性。所有条件下，参与者信心高且认知负荷低。

Conclusion: 他人中心和部分自我中心FoV指示可有效提升人类对机器人视野的准确理解，研究总结出六条实践指南，帮助开发者通过AR或物理改造来对齐人机视觉认知。

Abstract: Research indicates that humans can mistakenly assume that robots and humans
have the same field of view (FoV), possessing an inaccurate mental model of
robots. This misperception may lead to failures during human-robot
collaboration tasks where robots might be asked to complete impossible tasks
about out-of-view objects. The issue is more severe when robots do not have a
chance to scan the scene to update their world model while focusing on assigned
tasks. To help align humans' mental models of robots' vision capabilities, we
propose four FoV indicators in augmented reality (AR) and conducted a user
human-subjects experiment (N=41) to evaluate them in terms of accuracy,
confidence, task efficiency, and workload. These indicators span a spectrum
from egocentric (robot's eye and head space) to allocentric (task space).
Results showed that the allocentric blocks at the task space had the highest
accuracy with a delay in interpreting the robot's FoV. The egocentric indicator
of deeper eye sockets, possible for physical alteration, also increased
accuracy. In all indicators, participants' confidence was high while cognitive
load remained low. Finally, we contribute six guidelines for practitioners to
apply our AR indicators or physical alterations to align humans' mental models
with robots' vision capabilities.

</details>


### [104] [OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera](https://arxiv.org/abs/2511.03571)
*Hao Shi,Ze Wang,Shangwei Guo,Mengfei Duan,Song Wang,Teng Chen,Kailun Yang,Lin Wang,Kaiwei Wang*

Main category: cs.RO

TL;DR: 本文提出OneOcc，一种专为足式/人形机器人设计的纯视觉全景语义场景补全框架，通过双投影融合、双网格体素化、分层AMoE-3D解码器和步态位移补偿模块，在360度连续感知中实现先进性能，并发布两个新的全景占据基准数据集QuadOcc和Human360Occ。


<details>
  <summary>Details</summary>
Motivation: 现有的语义场景补全系统多针对带前向传感器的轮式平台，难以适应足式/人形机器人因行走产生的身体抖动和360度全景感知需求，缺乏合适的全景占据感知框架与数据集。

Method: OneOcc采用双投影融合（DP-ER）保留360度连续性与网格对齐，双网格体素化（BGV）在笛卡尔与柱面极坐标空间联合推理以减少离散偏差，轻量级分层AMoE-3D解码器实现多尺度特征融合与长距离遮挡推理，并引入即插即用的步态位移补偿（GDC）模块在特征层面校正运动扰动。

Result: OneOcc在新发布的QuadOcc和Human360Occ两个全景占据基准上达到SOTA性能：在QuadOcc上优于强视觉基线与主流LiDAR方法；在Human360Occ上分别提升+3.83 mIoU（城内）和+8.08（跨城）。模块设计轻量化，适合实际部署。

Conclusion: OneOcc为足式/人形机器人提供了高效、鲁棒的全景语义占据感知解决方案，推动了基于视觉的全向环境理解，并通过公开数据集与代码促进该方向的发展。

Abstract: Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet most
semantic scene completion (SSC) systems target wheeled platforms with
forward-facing sensors. We present OneOcc, a vision-only panoramic SSC
framework designed for gait-introduced body jitter and 360{\deg} continuity.
OneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annular
panorama and its equirectangular unfolding, preserving 360{\deg} continuity and
grid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian and
cylindrical-polar spaces, reducing discretization bias and sharpening
free/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3D
for dynamic multi-scale fusion and better long-range/occlusion reasoning; and
(iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-level
motion correction without extra sensors. We also release two panoramic
occupancy benchmarks: QuadOcc (real quadruped, first-person 360{\deg}) and
Human360Occ (H3O) (CARLA human-ego 360{\deg} with RGB, Depth, semantic
occupancy; standardized within-/cross-city splits). OneOcc sets new
state-of-the-art (SOTA): on QuadOcc it beats strong vision baselines and
popular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08
(cross-city). Modules are lightweight, enabling deployable full-surround
perception for legged/humanoid robots. Datasets and code will be publicly
available at https://github.com/MasterHow/OneOcc.

</details>


### [105] [Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution](https://arxiv.org/abs/2511.03576)
*Aniol Civit,Antonio Andriella,Carles Sierra,Guillem Alenyà*

Main category: cs.RO

TL;DR: 本文提出了一种基于量化双向论证框架（MUP-QBAF）的多用户个性化方法，用于解决人机交互中多个利益相关者之间的偏好冲突，通过结合用户输入和机器人对环境的动态观察，实现随时间适应和响应上下文变化的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化HRI方法大多关注单用户适应，忽视了涉及多个利益相关者且可能存在偏好冲突的情景。

Method: 提出MUP-QBAF框架，将用户的正负偏好表示为论点，并基于新信息迭代重新计算其强度；该框架结合用户论据和机器人对环境的动态观测。

Result: 通过一个辅助机器人在脆弱性评估任务中调解护理人员与被护理者之间偏好冲突的案例研究验证了框架的有效性，并进行了敏感性分析，展示了用户输入和情境观察如何影响偏好结果。

Conclusion: MUP-QBAF为解决多用户HRI中的竞争性偏好提供了一个透明、结构化且对情境敏感的方法，推进了多用户HRI领域的发展，并为数据驱动方法提供了有原则的替代方案。

Abstract: While personalisation in Human-Robot Interaction (HRI) has advanced
significantly, most existing approaches focus on single-user adaptation,
overlooking scenarios involving multiple stakeholders with potentially
conflicting preferences. To address this, we propose the Multi-User Preferences
Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user
personalisation framework based on Quantitative Bipolar Argumentation
Frameworks (QBAFs) that explicitly models and resolves multi-user preference
conflicts. Unlike prior work in Argumentation Frameworks, which typically
assumes static inputs, our approach is tailored to robotics: it incorporates
both users' arguments and the robot's dynamic observations of the environment,
allowing the system to adapt over time and respond to changing contexts.
Preferences, both positive and negative, are represented as arguments whose
strength is recalculated iteratively based on new information. The framework's
properties and capabilities are presented and validated through a realistic
case study, where an assistive robot mediates between the conflicting
preferences of a caregiver and a care recipient during a frailty assessment
task. This evaluation further includes a sensitivity analysis of argument base
scores, demonstrating how preference outcomes can be shaped by user input and
contextual observations. By offering a transparent, structured, and
context-sensitive approach to resolving competing user preferences, this work
advances the field of multi-user HRI. It provides a principled alternative to
data-driven methods, enabling robots to navigate conflicts in real-world
environments.

</details>


### [106] [Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning](https://arxiv.org/abs/2511.03591)
*Qingyi Chen,Ruiqi Ni,Jun Kim,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了一种基于流形约束的哈密顿-雅可比可达性（HJR）学习框架，用于去中心化的多智能体运动规划（MAMP），能够在满足任务约束的同时保证安全性与实时性。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，机器人需要在动态环境中导航并满足任务带来的复杂约束（如保持杯中液体不溢出），而现有去中心化MAMP方法难以有效融入此类流形约束。

Method: 通过在流形约束下求解HJR问题以获取任务感知的安全条件，并将其集成到去中心化轨迹优化规划器中，无需假设其他智能体的策略。

Result: 该方法在多种流形约束任务中表现出良好的泛化性和可扩展性，优于现有的约束运动规划方法，且具备适用于实际应用的计算速度。

Conclusion: 所提框架成功实现了兼顾安全性与任务可行性的去中心化多智能体运动规划，为高维、复杂任务环境下的机器人协作提供了有效解决方案。

Abstract: Safe multi-agent motion planning (MAMP) under task-induced constraints is a
critical challenge in robotics. Many real-world scenarios require robots to
navigate dynamic environments while adhering to manifold constraints imposed by
tasks. For example, service robots must carry cups upright while avoiding
collisions with humans or other robots. Despite recent advances in
decentralized MAMP for high-dimensional systems, incorporating manifold
constraints remains difficult. To address this, we propose a
manifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for
decentralized MAMP. Our method solves HJR problems under manifold constraints
to capture task-aware safety conditions, which are then integrated into a
decentralized trajectory optimization planner. This enables robots to generate
motion plans that are both safe and task-feasible without requiring assumptions
about other agents' policies. Our approach generalizes across diverse
manifold-constrained tasks and scales effectively to high-dimensional
multi-agent manipulation problems. Experiments show that our method outperforms
existing constrained motion planners and operates at speeds suitable for
real-world applications. Video demonstrations are available at
https://youtu.be/RYcEHMnPTH8 .

</details>


### [107] [Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural](https://arxiv.org/abs/2511.03651)
*Andrei A. Korigodskii,Oleg D. Kalachev,Artem E. Vasiunik,Matvei V. Urvantsev,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 本文提出了一种用于绘制世界最大无人机壁画的自主无人机系统，结合红外动捕与LiDAR实现高精度户外导航，并采用新型控制架构与喷涂机制，实验证明其在复杂环境下的鲁棒性与艺术表现力。


<details>
  <summary>Details</summary>
Motivation: 为应对在户外风力和阳光等干扰下实现艺术创作的高精度与系统可靠性挑战，推动无人机在大型艺术创作中的应用。

Method: 提出融合红外动捕与LiDAR的导航系统，设计切向与法向独立调控的控制架构，开发轨迹规划与路径优化算法，并集成定制化抗湍流喷涂装置。

Result: 系统在多种户外条件下实现了精确轨迹跟踪与稳定线条绘制，成功完成大规模壁画绘制任务，表现出良好的鲁棒性与功能性。

Conclusion: 该无人机系统为大型户外艺术创作提供了可靠解决方案，拓展了机器人在创意领域的应用边界。

Abstract: This paper presents the innovative design and successful deployment of a
pioneering autonomous unmanned aerial system developed for executing the
world's largest mural painted by a drone. Addressing the dual challenges of
maintaining artistic precision and operational reliability under adverse
outdoor conditions such as wind and direct sunlight, our work introduces a
robust system capable of navigating and painting outdoors with unprecedented
accuracy. Key to our approach is a novel navigation system that combines an
infrared (IR) motion capture camera and LiDAR technology, enabling precise
location tracking tailored specifically for largescale artistic applications.
We employ a unique control architecture that uses different regulation in
tangential and normal directions relative to the planned path, enabling precise
trajectory tracking and stable line rendering. We also present algorithms for
trajectory planning and path optimization, allowing for complex curve drawing
and area filling. The system includes a custom-designed paint spraying
mechanism, specifically engineered to function effectively amidst the turbulent
airflow generated by the drone's propellers, which also protects the drone's
critical components from paint-related damage, ensuring longevity and
consistent performance. Experimental results demonstrate the system's
robustness and precision in varied conditions, showcasing its potential for
autonomous large-scale art creation and expanding the functional applications
of robotics in creative fields.

</details>


### [108] [Motion Planning Under Temporal Logic Specifications In Semantically Unknown Environments](https://arxiv.org/abs/2511.03652)
*Azizollah Taheri,Derya Aksaray*

Main category: cs.RO

TL;DR: 本文提出了一种基于自动机理论的运动规划方法，用于在语义标签具有概率不确定性的环境中实现时空逻辑任务（scLTL）。


<details>
  <summary>Details</summary>
Motivation: 在环境信息不完全或存在不确定性（如目标区域位置未知，仅有概率性先验）的情况下，传统运动规划方法难以有效满足复杂的时序逻辑任务需求。

Method: 构建一种特殊的乘积自动机来融合任务逻辑约束与环境语义标签的概率信息，并为自动机的每条边设计奖励函数，结合值迭代实现在线重规划。

Result: 理论分析证明了方法的有效性，仿真和实验结果验证了该方法在不确定环境下完成scLTL任务的可行性与鲁棒性。

Conclusion: 所提出的自动机方法能够有效处理语义不确定性下的时空逻辑任务规划，通过在线值迭代实现动态适应，提升了复杂环境中的自主系统行为规划能力。

Abstract: This paper addresses a motion planning problem to achieve
spatio-temporal-logical tasks, expressed by syntactically co-safe linear
temporal logic specifications (scLTL\next), in uncertain environments. Here,
the uncertainty is modeled as some probabilistic knowledge on the semantic
labels of the environment. For example, the task is "first go to region 1, then
go to region 2"; however, the exact locations of regions 1 and 2 are not known
a priori, instead a probabilistic belief is available. We propose a novel
automata-theoretic approach, where a special product automaton is constructed
to capture the uncertainty related to semantic labels, and a reward function is
designed for each edge of this product automaton. The proposed algorithm
utilizes value iteration for online replanning. We show some theoretical
results and present some simulations/experiments to demonstrate the efficacy of
the proposed approach.

</details>


### [109] [Unconscious and Intentional Human Motion Cues for Expressive Robot-Arm Motion Design](https://arxiv.org/abs/2511.03676)
*Taito Tashiro,Tomoko Yonezawa,Hirotake Yamazoe*

Main category: cs.RO

TL;DR: 该研究通过幽灵棋游戏探讨了人类动作线索如何用于设计富有表现力的机器人臂部运动，发现撤回阶段的运动时序对印象形成至关重要，且实体机器人更能增强动作线索的可解读性。


<details>
  <summary>Details</summary>
Motivation: 探索人类无意识和有意识的动作特征如何影响机器人运动的表现力设计。

Method: 分析人类在自然游戏和指令性表达中的棋子移动动作，据此设计分阶段的机器人运动，并在实体机器人和视频两种模态下进行评估。

Result: 晚期阶段（特别是撤回阶段）的运动时序显著影响观察者的印象，且物理实体机器人比视频呈现更有利于动作线索的理解。

Conclusion: 基于人类动作时序行为，特别是撤回阶段的节奏变化，可有效提升机器人运动的表现力与可解读性。

Abstract: This study investigates how human motion cues can be used to design
expressive robot-arm movements. Using the imperfect-information game Geister,
we analyzed two types of human piece-moving motions: natural gameplay
(unconscious tendencies) and instructed expressions (intentional cues). Based
on these findings, we created phase-specific robot motions by varying movement
speed and stop duration, and evaluated observer impressions under two
presentation modalities: a physical robot and a recorded video. Results
indicate that late-phase motion timing, particularly during withdrawal, plays
an important role in impression formation and that physical embodiment enhances
the interpretability of motion cues. These findings provide insights for
designing expressive robot motions based on human timing behavior.

</details>


### [110] [Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping](https://arxiv.org/abs/2511.03691)
*Zhihang Qin,Yueheng Zhang,Wan Su,Linxin Hou,Shenghao Zhou,Zhijun Chen,Yu Jun Tan,Cecilia Laschi*

Main category: cs.RO

TL;DR: 提出了一种自包含、固定尺寸的软体夹持器，通过内部液体重新分布实现无需外部能源的稳定抓取。


<details>
  <summary>Details</summary>
Motivation: 传统流体驱动软体夹持器依赖外部供能，限制了其便携性和长期自主性。

Method: 利用三个互连的双稳态翻转腔室，通过顶部传感腔接触变形导致液体位移，触发抓取腔的翻转膨胀。

Result: 实现了无需持续能量输入的稳定、尺寸选择性抓取，并能被动适应不同刚度物体的夹持压力。

Conclusion: 该无源紧凑设计为软体机器人中的轻量、刚度自适应操作提供了新可能，适用于水下和野外环境的目标采样与操作。

Abstract: Conventional fluid-driven soft grippers typically depend on external sources,
which limit portability and long-term autonomy. This work introduces a
self-contained soft gripper with fixed size that operates solely through
internal liquid redistribution among three interconnected bistable snap-through
chambers. When the top sensing chamber deforms upon contact, the displaced
liquid triggers snap-through expansion of the grasping chambers, enabling
stable and size-selective grasping without continuous energy input. The
internal hydraulic feedback further allows passive adaptation of gripping
pressure to object stiffness. This source-free and compact design opens new
possibilities for lightweight, stiffness-adaptive fluid-driven manipulation in
soft robotics, providing a feasible approach for targeted size-specific
sampling and operation in underwater and field environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [111] [Evaluating Control Protocols for Untrusted AI Agents](https://arxiv.org/abs/2511.02997)
*Jon Kutasov,Chloe Loughridge,Yuqi Sun,Henry Sleight,Buck Shlegeris,Tyler Tracy,Joe Benton*

Main category: cs.AI

TL;DR: 本文研究了AI控制协议在SHADE-Arena环境中的安全性，评估了多种蓝队策略对攻击的防御效果，并通过红队迭代攻击测试其鲁棒性。结果显示，关键动作延迟策略具有高度鲁棒性，而重采样策略易受自适应攻击影响。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理能力增强和广泛应用，确保其安全运行至关重要。需要系统评估现有AI控制协议在面对自适应攻击时的有效性和鲁棒性，以提升AI系统的整体安全性。

Method: 在SHADE-Arena这一多样化代理环境中，评估了包括模型委派、重采样和关键动作延迟在内的蓝队控制协议；首先测试其对默认攻击策略的防御效果，随后设计具备额外能力的红队攻击策略进行迭代攻击，分析各协议的抗攻击能力。

Result: 在默认攻击下，重采样和关键动作延迟策略可将安全性从50%提升至96%；但在自适应攻击下，重采样策略的安全性下降至17%，而关键动作延迟策略仍保持高度鲁棒性。

Conclusion: 关键动作延迟策略因不暴露协议内部机制而更具安全性，表明在设计AI控制协议时应限制攻击者对协议内部信息的访问，以增强对抗自适应攻击的鲁棒性。

Abstract: As AI systems become more capable and widely deployed as agents, ensuring
their safe operation becomes critical. AI control offers one approach to
mitigating the risk from untrusted AI agents by monitoring their actions and
intervening or auditing when necessary. Evaluating the safety of these
protocols requires understanding both their effectiveness against current
attacks and their robustness to adaptive adversaries. In this work, we
systematically evaluate a range of control protocols in SHADE-Arena, a dataset
of diverse agentic environments. First, we evaluate blue team protocols,
including deferral to trusted models, resampling, and deferring on critical
actions, against a default attack policy. We find that resampling for
incrimination and deferring on critical actions perform best, increasing safety
from 50% to 96%. We then iterate on red team strategies against these protocols
and find that attack policies with additional affordances, such as knowledge of
when resampling occurs or the ability to simulate monitors, can substantially
improve attack success rates against our resampling strategy, decreasing safety
to 17%. However, deferring on critical actions is highly robust to even our
strongest red team strategies, demonstrating the importance of denying attack
policies access to protocol internals.

</details>


### [112] [PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework](https://arxiv.org/abs/2511.03023)
*Sina Montazeri,Yunhe Feng,Kewei Sha*

Main category: cs.AI

TL;DR: 本文提出了PublicAgent，一个通过分解为专用代理（意图澄清、数据发现、分析和报告）来解决大型语言模型在端到端数据分析工作流中局限性的多代理框架，并总结了多代理LLM系统的五个设计原则。


<details>
  <summary>Details</summary>
Motivation: 开放数据存储库虽然有助于基于证据的决策，但对缺乏数据集发现、模式映射和统计分析专业知识的非专家而言难以访问。现有的大语言模型在单一任务上表现良好，但在端到端分析流程中存在注意力分散、推理模式干扰和错误传播等问题。

Method: 提出PublicAgent多代理框架，将分析流程分解为专门的代理（意图澄清、数据发现、分析和报告），每个代理专注于特定任务并支持阶段间验证。通过五个不同模型和50个查询进行评估，提取设计原则。

Result: 实验表明：1）专业化带来显著优势，即使最强模型也有97.5%的代理胜率；2）代理可分为通用型（如发现、分析）和条件型（如报告、意图），前者更稳定；3）不同代理缓解不同的失败模式；4）架构优势在不同任务复杂度下均稳定存在；5）不同模型间代理效果差异大，需模型感知的设计。

Conclusion: 专业化多代理架构能有效提升复杂分析工作流的性能与鲁棒性，且其价值主要来自流程管理而非单纯推理增强，同时为公众通过自然语言接口访问公共数据提供了可行路径。

Abstract: Open data repositories hold potential for evidence-based decision-making, yet
are inaccessible to non-experts lacking expertise in dataset discovery, schema
mapping, and statistical analysis. Large language models show promise for
individual tasks, but end-to-end analytical workflows expose fundamental
limitations: attention dilutes across growing contexts, specialized reasoning
patterns interfere, and errors propagate undetected. We present PublicAgent, a
multi-agent framework that addresses these limitations through decomposition
into specialized agents for intent clarification, dataset discovery, analysis,
and reporting. This architecture maintains focused attention within agent
contexts and enables validation at each stage. Evaluation across five models
and 50 queries derives five design principles for multi-agent LLM systems.
First, specialization provides value independent of model strength--even the
strongest model shows 97.5% agent win rates, with benefits orthogonal to model
scale. Second, agents divide into universal (discovery, analysis) and
conditional (report, intent) categories. Universal agents show consistent
effectiveness (std dev 12.4%) while conditional agents vary by model (std dev
20.5%). Third, agents mitigate distinct failure modes--removing discovery or
analysis causes catastrophic failures (243-280 instances), while removing
report or intent causes quality degradation. Fourth, architectural benefits
persist across task complexity with stable win rates (86-92% analysis, 84-94%
discovery), indicating workflow management value rather than reasoning
enhancement. Fifth, wide variance in agent effectiveness across models (42-96%
for analysis) requires model-aware architecture design. These principles guide
when and why specialization is necessary for complex analytical workflows while
enabling broader access to public data through natural language interfaces.

</details>


### [113] [No-Human in the Loop: Agentic Evaluation at Scale for Recommendation](https://arxiv.org/abs/2511.03051)
*Tao Zhang,Kehui Yao,Luyi Ma,Jiao Chen,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: ScalingEval 是一个大规模基准研究，系统比较了36个大语言模型作为评估者的性能，发现不同模型在准确性、延迟和成本之间存在权衡，并提出了可复现的评估协议。


<details>
  <summary>Details</summary>
Motivation: 为了构建可扩展且可信的评估流程，需要系统性地评估大语言模型作为裁判的有效性。

Method: 采用多智能体框架，通过共识驱动的评估协议，利用多数投票聚合模式审计和问题代码生成真实标签，从而在无需人工标注的情况下实现对LLM评估者的可复现比较。

Result: 在互补项推荐的大规模应用中发现：Claude 3.5 Sonnet 决策置信度最高；Gemini 1.5 Pro 综合表现最佳；GPT-4o 在延迟-准确性-成本权衡上最优；GPT-OSS 20B 在开源模型中领先；结构化领域（如电子、体育）共识强，而生活方式类别（如服装、食品）分歧较大。

Conclusion: ScalingEval 建立了一个可复现的LLM作为评估者的基准和协议，为模型扩展、可靠性及模型家族间的权衡提供了实用指导。

Abstract: Evaluating large language models (LLMs) as judges is increasingly critical
for building scalable and trustworthy evaluation pipelines. We present
ScalingEval, a large-scale benchmarking study that systematically compares 36
LLMs, including GPT, Gemini, Claude, and Llama, across multiple product
categories using a consensus-driven evaluation protocol. Our multi-agent
framework aggregates pattern audits and issue codes into ground-truth labels
via scalable majority voting, enabling reproducible comparison of LLM
evaluators without human annotation. Applied to large-scale complementary-item
recommendation, the benchmark reports four key findings: (i) Anthropic Claude
3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers
the best overall performance across categories; (iii) GPT-4o provides the most
favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among
open-source models. Category-level analysis shows strong consensus in
structured domains (Electronics, Sports) but persistent disagreement in
lifestyle categories (Clothing, Food). These results establish ScalingEval as a
reproducible benchmark and evaluation protocol for LLMs as judges, with
actionable guidance on scaling, reliability, and model family tradeoffs.

</details>


### [114] [Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework](https://arxiv.org/abs/2511.03179)
*Varun Kumar,George Em Karniadakis*

Main category: cs.AI

TL;DR: 提出了一种基于多智能体AI框架的工程设计方法，通过知识图谱驱动的协作流程实现高效、一致且高质量的设计优化。


<details>
  <summary>Details</summary>
Motivation: 传统工程设计过程资源消耗大且效率低，需要跨领域专家协作和多次迭代，因此亟需一种更高效的自动化设计方法。

Method: 构建了一个包含图本体专家、设计工程师和系统工程师三个AI智能体的框架，利用大语言模型生成领域知识图谱，并通过结构化的设计与评审循环进行协同设计与反馈优化。

Result: 在4位NACA翼型的气动优化中验证了该框架的有效性，实现了满足技术要求的候选设计生成，并通过迭代评审提升设计质量，最终优化提升了升阻比等性能指标。

Conclusion: 基于知识图谱的多智能体AI框架能够有效提升工程设计过程的效率、一致性和设计质量，具有在复杂工程问题中广泛应用的潜力。

Abstract: The engineering design process often demands expertise from multiple domains,
leading to complex collaborations and iterative refinements. Traditional
methods can be resource-intensive and prone to inefficiencies. To address this,
we formalize the engineering design process through a multi-agent AI framework
that integrates structured design and review loops. The framework introduces
specialized knowledge-driven agents that collaborate to generate and refine
design candidates. As an exemplar, we demonstrate its application to the
aerodynamic optimization of 4-digit NACA airfoils. The framework consists of
three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems
Engineer. The Graph Ontologist employs a Large Language Model (LLM) to
construct two domain-specific knowledge graphs from airfoil design literature.
The Systems Engineer, informed by a human manager, formulates technical
requirements that guide design generation and evaluation. The Design Engineer
leverages the design knowledge graph and computational tools to propose
candidate airfoils meeting these requirements. The Systems Engineer reviews and
provides feedback both qualitative and quantitative using its own knowledge
graph, forming an iterative feedback loop until a design is validated by the
manager. The final design is then optimized to maximize performance metrics
such as the lift-to-drag ratio. Overall, this work demonstrates how
collaborative AI agents equipped with structured knowledge representations can
enhance efficiency, consistency, and quality in the engineering design process.

</details>


### [115] [Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge](https://arxiv.org/abs/2511.03070)
*Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim*

Main category: cs.AI

TL;DR: 本文构建了一个基准测试，用于评估大语言模型（LLM）对现实世界概率分布的掌握能力，结果表明LLM整体表现较差，未能自然内化真实世界的统计信息，并且根据Pearl因果层次理论，其观察性、干预性和反事实知识均受限。


<details>
  <summary>Details</summary>
Motivation: 为了检验大语言模型是否真正具备对现实世界概率分布的理解能力，尤其是在高维情况下学习分布的经典统计难题背景下，研究其作为通用分布逼近器的潜力与局限。

Method: 设计并构建首个针对LLM在经济、健康、教育和社会行为等领域中现实人群经验分布知识的基准测试，通过多项任务评估模型输出与真实统计数据的一致性。

Result: 实验结果显示LLM在捕捉真实世界概率分布方面表现不佳，缺乏对观测分布的基本理解，表明其并未自然内化这些统计知识。

Conclusion: LLM目前不具备对现实世界概率分布的有效知识，依据Pearl因果层次理论，这意味着它们在因果推断的各层级（观测、干预、反事实）上的能力均受到根本限制。

Abstract: Artificial intelligence (AI) systems hold great promise for advancing various
scientific disciplines, and are increasingly used in real-world applications.
Despite their remarkable progress, further capabilities are expected in order
to achieve more general types of intelligence. A critical distinction in this
context is between factual knowledge, which can be evaluated against true or
false answers (e.g., "what is the capital of England?"), and probabilistic
knowledge, reflecting probabilistic properties of the real world (e.g., "what
is the sex of a computer science graduate in the US?"). In this paper, our goal
is to build a benchmark for understanding the capabilities of LLMs in terms of
knowledge of probability distributions describing the real world. Given that
LLMs are trained on vast amounts of text, it may be plausible that they
internalize aspects of these distributions. Indeed, LLMs are touted as powerful
universal approximators of real-world distributions. At the same time,
classical results in statistics, known as curse of dimensionality, highlight
fundamental challenges in learning distributions in high dimensions,
challenging the notion of universal distributional learning. In this work, we
develop the first benchmark to directly test this hypothesis, evaluating
whether LLMs have access to empirical distributions describing real-world
populations across domains such as economics, health, education, and social
behavior. Our results demonstrate that LLMs perform poorly overall, and do not
seem to internalize real-world statistics naturally. When interpreted in the
context of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that
language models do not contain knowledge on observational distributions (Layer
1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional
(Layer 2) and counterfactual (Layer 3) knowledge of these models is also
limited.

</details>


### [116] [SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators](https://arxiv.org/abs/2511.03092)
*Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar*

Main category: cs.AI

TL;DR: 本文提出了SnapStream，一种可在大规模生产环境中部署的KV缓存压缩方法，解决了在静态图和连续批处理框架下实现稀疏KV注意力技术的难题，并在长上下文场景下实现了4倍的片上内存优化，同时仅引入轻微的精度损失。


<details>
  <summary>Details</summary>
Motivation: 现有的KV缓存控制技术（如StreamingLLM和SnapKV）难以在工业级推理框架（如vLLM、SGLang）中应用，主要受限于静态图和连续批处理架构，且其对现代指令跟随和推理模型的精度影响尚不明确。

Method: 提出SnapStream，一种兼容静态图与连续批处理的KV缓存压缩方法，并在Llama-3.1-8B-Instruct和DeepSeek-R1模型上评估其精度影响，最终集成至SambaNova平台的DeepSeek-671B 16路张量并行部署中。

Result: 在128k上下文长度和最高1832 tokens/秒的实际生产环境中，SnapStream实现了4倍的片上内存使用提升，在LongBench-v2、AIME24和LiveCodeBench等基准上仅有轻微精度下降。

Conclusion: SnapStream是首个在采用静态图和连续批处理的生产级推理系统中成功部署的稀疏KV注意力技术，显著提升了大模型长上下文推理的内存效率，具备实际应用价值。

Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+
context length support have resulted in increasing demands for on-chip memory
to support large KV caches. Techniques such as StreamingLLM and SnapKV
demonstrate how to control KV cache size while maintaining model accuracy. Yet,
these techniques are not commonly used within industrial deployments using
frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static
graphs and continuous batching methodology employed by these frameworks make it
difficult to admit modifications to the standard multi-head attention
algorithm, while on the other hand, the accuracy implications of such
techniques on modern instruction-following and reasoning models are not well
understood, obfuscating the need for implementing these techniques. In this
paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and
DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be
deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way
tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators
running at 128k context length and up to 1832 tokens per second in a real
production setting. SnapStream enables $4\times$ improved on-chip memory usage
and introduces minimal accuracy degradation on LongBench-v2, AIME24 and
LiveCodeBench. To the best of our knowledge, this is the first implementation
of sparse KV attention techniques deployed in a production inference system
with static graphs and continuous batching.

</details>


### [117] [Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning](https://arxiv.org/abs/2511.03724)
*Richard Dewey,Janos Botyanszki,Ciamac C. Moallemi,Andrew T. Zheng*

Main category: cs.AI

TL;DR: 本文介绍了Solly，首个在简化版“说谎者扑克”游戏中达到人类精英水平的AI代理，采用无模型的深度强化学习算法通过自我对弈训练，在多人博弈中表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于扑克类游戏具有多玩家动态、不完全信息和不确定性推理等特点，长期以来被用作AI研究的测试平台；然而以往研究多集中于双人对抗，缺乏对广泛参与的多玩家动态的探索。

Method: 使用无模型的演员-评论家（actor-critic）深度强化学习算法进行自我对弈训练。

Result: Solly在单挑和多玩家模式下的胜率超过50%，赢取正向资金，并优于包括具备推理能力在内的大型语言模型，展现出难以被顶尖人类玩家利用的策略鲁棒性。

Conclusion: Solly是首个在具有广泛多玩家互动的Liar's Poker中达到精英水平的AI，展示了强化学习在复杂多玩家不完全信息博弈中的有效性。

Abstract: AI researchers have long focused on poker-like games as a testbed for
environments characterized by multi-player dynamics, imperfect information, and
reasoning under uncertainty. While recent breakthroughs have matched elite
human play at no-limit Texas hold'em, the multi-player dynamics are subdued:
most hands converge quickly with only two players engaged through multiple
rounds of bidding. In this paper, we present Solly, the first AI agent to
achieve elite human play in reduced-format Liar's Poker, a game characterized
by extensive multi-player engagement. We trained Solly using self-play with a
model-free, actor-critic, deep reinforcement learning algorithm. Solly played
at an elite human level as measured by win rate (won over 50% of hands) and
equity (money won) in heads-up and multi-player Liar's Poker. Solly also
outperformed large language models (LLMs), including those with reasoning
abilities, on the same metrics. Solly developed novel bidding strategies,
randomized play effectively, and was not easily exploitable by world-class
human players.

</details>


### [118] [Large language models require a new form of oversight: capability-based monitoring](https://arxiv.org/abs/2511.03106)
*Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman*

Main category: cs.AI

TL;DR: 本文提出了一种面向医疗领域大语言模型（LLM）的新型监控范式——能力导向型监控（capability-based monitoring），以应对传统基于任务的监控方法在LLM应用中的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于LLM是通用模型，其能力在多种任务和人群中复用，传统的基于数据漂移和任务性能下降假设的监控方法不适用，因此需要一种更根本、可扩展的监控原则。

Method: 提出以模型的核心能力（如摘要、推理、翻译、安全防护）为中心组织监控体系，跨任务评估这些共享能力的表现，从而发现系统性弱点和长尾错误。

Result: 能力导向型监控能够更有效地检测到传统任务导向方法可能遗漏的系统性缺陷和新兴行为，并为LLM在医疗中的安全应用提供可扩展的监测基础。

Conclusion: 能力导向型监控是一种更符合LLM本质的监控框架，有助于实现对通用人工智能模型在医疗环境中安全、自适应且协作式的监管。

Abstract: The rapid adoption of large language models (LLMs) in healthcare has been
accompanied by scrutiny of their oversight. Existing monitoring approaches,
inherited from traditional machine learning (ML), are task-based and founded on
assumed performance degradation arising from dataset drift. In contrast, with
LLMs, inevitable model degradation due to changes in populations compared to
the training dataset cannot be assumed, because LLMs were not trained for any
specific task in any given population. We therefore propose a new organizing
principle guiding generalist LLM monitoring that is scalable and grounded in
how these models are developed and used in practice: capability-based
monitoring. Capability-based monitoring is motivated by the fact that LLMs are
generalist systems whose overlapping internal capabilities are reused across
numerous downstream tasks. Instead of evaluating each downstream task
independently, this approach organizes monitoring around shared model
capabilities, such as summarization, reasoning, translation, or safety
guardrails, in order to enable cross-task detection of systemic weaknesses,
long-tail errors, and emergent behaviors that task-based monitoring may miss.
We describe considerations for developers, organizational leaders, and
professional societies for implementing a capability-based monitoring approach.
Ultimately, capability-based monitoring will provide a scalable foundation for
safe, adaptive, and collaborative monitoring of LLMs and future generalist
artificial intelligence models in healthcare.

</details>


### [119] [miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward](https://arxiv.org/abs/2511.03108)
*Azim Ospanov,Farzan Farnia,Roozbeh Yousefzadeh*

Main category: cs.AI

TL;DR: 本文对miniF2F数学竞赛基准进行了深入分析，发现形式化与非形式化陈述之间的不一致导致AI系统整体证明准确率显著下降；通过修正这些问题，作者构建了更高质量的miniF2F-v2基准，使准确率从40%提升至70%，并揭示了当前自动形式化与定理证明模型之间的错位问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统在数学奥林匹克问题上的端到端表现受限于形式化与非形式化陈述之间的不一致，需构建更可靠的基准以准确评估自动形式化与定理证明系统的进展。

Method: 分析miniF2F中形式与非形式陈述的差异，识别错误与简化，并构建经完全验证的miniF2F-v2数据集；在此基础上评估端到端定理证明流水线性能。

Result: 原始miniF2F上最佳端到端准确率为36%，远低于单独任务的97%（自动形式化）和69%（定理证明）；miniF2F-v2将准确率提升至70%，且发现超过一半的问题存在原初版本的表述偏差。

Conclusion: 高质量、严格对齐的形式-非形式配对基准对评估和改进自动形式化与定理证明系统至关重要，miniF2F-v2为该领域提供了更可靠的评估平台。

Abstract: We perform a thorough analysis of the formal and informal statements in the
miniF2F benchmark from the perspective of an AI system that is tasked to
participate in a math Olympiad consisting of the problems in miniF2F. In such
setting, the model has to read and comprehend the problems in natural language,
formalize them in Lean language, then proceed with proving the problems, and it
will get credit for each problem if the formal proof corresponds to the
original informal statement presented to the model. Our evaluation results
reveal that the best accuracy of such pipeline can be about 36% using the SoTA
models in the literature, considerably lower than the individual SoTA
accuracies, 97% and 69% reported in the autoformalization and theorem proving
literature. Analyzing the failure modes, we trace back a considerable portion
of this drop to discrepancies between the formal and informal statements for
more than half of the problems in miniF2F. We proceed with correcting all the
errors, discrepancies and simplifications in formal and informal statements,
and present the miniF2F-v2 with fully verified formal and informal statements
and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to
the best accuracy of 70%, a significant improvement from the 40% on the
original miniF2F, yet indicating considerable misalignment between the
autoformalization models and theorem provers. Our deep analysis suggests that a
higher quality benchmark can help the community better evaluate progress in the
field of formal reasoning and also better diagnose the failure and success
modes of autoformalization and theorem proving models. Our dataset is available
at https://github.com/roozbeh-yz/miniF2F_v2.

</details>


### [120] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 本文提出了一种结合多模态大语言模型（MLLM）的烟花算法（FWA）优化框架，引入“关键部分”（Critical Part, CP）概念，以应对非凸、高维、黑盒等复杂优化问题，在旅行商问题（TSP）和电子设计自动化（EDA）任务中达到了或超过了当前最优水平。


<details>
  <summary>Details</summary>
Motivation: 传统零阶或一阶优化方法在处理非凸、高维、黑盒等复杂优化问题时效率低、梯度信息不准确、优化信息利用不足，难以应对现代优化挑战。随着大语言模型在语言理解和代码生成方面的进步，利用其辅助优化算法设计成为一个有前景的方向。

Method: 以烟花算法（FWA）为基础，引入多模态大语言模型（MLLM），提出“关键部分”（CP）概念，利用MLLM的多模态特性分析优化过程中的信息，指导FWA在高维复杂任务中的搜索策略设计。

Result: 在TSP和EDA两类实际问题上的实验表明，该框架生成的FWA算法在多个问题实例上达到或超过了现有最先进方法的性能。

Conclusion: 结合多模态大语言模型的优化算法设计框架能够有效提升传统群智能算法在复杂问题上的表现，展示了LLM在算法设计自动化中的巨大潜力。

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [121] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 本文提出了一种新型的LLM安全响应框架，通过在输入和输出层面进行系统性防护，显著提升了大语言模型在高风险场景下的安全性与可信度。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的广泛应用，其安全问题日益突出，严重制约了其在关键领域的可信部署。因此，亟需一种系统性的安全框架来应对输入和输出层面的安全威胁。

Method: 在输入层面，采用基于监督微调的安全分类模型，并结合细粒度的四层分类体系（安全、不安全、条件安全、需关注）实现精准风险识别；在输出层面，结合检索增强生成（RAG）与专门微调的解释模型，确保回复基于实时可信知识库，防止信息伪造并实现结果可追溯。

Result: 在公开安全评测基准上，该框架相比基线模型TinyR1-Safety-8B获得了更高的安全评分；在自建高风险测试集上，各组件均达到100%安全得分，且输入分类模型的风险召回率达99.3%。

Conclusion: 所提出的框架为构建高安全、高可信的大语言模型应用提供了有效的工程路径，具备良好的风险覆盖能力和业务适应性。

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [122] [Uncovering Bugs in Formal Explainers: A Case Study with PyXAI](https://arxiv.org/abs/2511.03169)
*Xuanxiang Huang,Yacine Izza,Alexey Ignatiev,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了一种验证形式化解释器的新方法，并评估了公开可用的形式化解释器PyXAI，发现其在大多数数据集上产生了错误的解释，突显了所提方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 形式化可解释人工智能（XAI）虽然具有严格的理论保证，但对其实际实现的验证关注较少，因此需要一种系统的方法来验证形式化解释器的正确性。

Method: 提出了一种新颖的形式化解释器验证方法，并通过实验评估了PyXAI在多个数据集上的表现。

Result: 实验表明，PyXAI在大多数分析的数据集上生成了不正确的解释。

Conclusion: 所提出的方法对于验证形式化解释器至关重要，且当前公开工具如PyXAI在实践中可能存在严重缺陷，需进一步改进和验证。

Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical
guarantees of rigor when compared to other non-formal methods of
explainability. However, little attention has been given to the validation of
practical implementations of formal explainers. This paper develops a novel
methodology for validating formal explainers and reports on the assessment of
the publicly available formal explainer PyXAI. The paper documents the
existence of incorrect explanations computed by PyXAI on most of the datasets
analyzed in the experiments, thereby confirming the importance of the proposed
novel methodology for the validation of formal explainers.

</details>


### [123] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: 本文介绍了为Adobe Summit开发的领域特定AI助手Summit Concierge，该助手在数据稀疏、质量保证和快速部署等现实约束下处理各种活动相关查询。


<details>
  <summary>Details</summary>
Motivation: 提升企业环境中生产力、信息获取效率和用户体验，解决生成式AI助手在实际应用中的挑战。

Method: 采用人机协同开发流程，结合提示工程、检索增强和轻量级人工验证来构建系统。

Result: 成功实现了系统的架构设计与实际部署，验证了敏捷、反馈驱动的开发方式在冷启动场景下的可扩展性和可靠性。

Conclusion: 敏捷且以反馈为导向的开发方法能够有效支持企业在现实约束下快速构建可靠、可扩展的AI助手。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


### [124] [From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers](https://arxiv.org/abs/2511.03235)
*Yi-Fei Liu,Yi-Long Lu,Di He,Hang Zhang*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）能够从个体的最小量化输入（如大五人格量表）中准确建模人类心理特质的相关结构，在零样本设置下生成的其他心理量表响应与真实人类数据高度一致（R² > 0.89），其表现优于基于语义相似性的预测，并接近在数据上训练的机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型是否以及如何仅凭少量定量输入就能捕捉人类心理特质之间的关联结构，从而评估其在心理模拟和推理能力方面的潜力。

Method: 研究使用816名个体的大五人格量表数据作为输入，提示多种LLM模拟这些个体在另外九个心理量表上的反应，并比较LLM生成结果与真实人类数据之间的跨量表相关模式；同时分析LLM的推理路径，揭示其信息处理机制。

Result: LLM生成的跨量表相关模式与人类数据高度一致（R² > 0.89），表现优于语义相似性基线，接近训练过的机器学习模型；分析显示LLM采用两阶段过程：首先将原始大五评分压缩为自然语言个性摘要（类似充分统计量），然后基于该摘要进行推理生成目标量表响应；LLM能识别关键人格因素但无法区分因素内项目重要性，且生成的摘要包含协同信息，加入原始分数可提升预测对齐度。

Conclusion: LLM能够在极少输入的情况下通过抽象与推理精确预测个体心理特征，展现出强大的心理结构建模能力和涌现的系统性推理机制，既可作为心理模拟的有效工具，也为理解LLM的高级认知功能提供洞见。

Abstract: Psychological constructs within individuals are widely believed to be
interconnected. We investigated whether and how Large Language Models (LLMs)
can model the correlational structure of human psychological traits from
minimal quantitative inputs. We prompted various LLMs with Big Five Personality
Scale responses from 816 human individuals to role-play their responses on nine
other psychological scales. LLMs demonstrated remarkable accuracy in capturing
human psychological structure, with the inter-scale correlation patterns from
LLM-generated responses strongly aligning with those from human data $(R^2 >
0.89)$. This zero-shot performance substantially exceeded predictions based on
semantic similarity and approached the accuracy of machine learning algorithms
trained directly on the dataset. Analysis of reasoning traces revealed that
LLMs use a systematic two-stage process: First, they transform raw Big Five
responses into natural language personality summaries through information
selection and compression, analogous to generating sufficient statistics.
Second, they generate target scale responses based on reasoning from these
summaries. For information selection, LLMs identify the same key personality
factors as trained algorithms, though they fail to differentiate item
importance within factors. The resulting compressed summaries are not merely
redundant representations but capture synergistic information--adding them to
original scores enhances prediction alignment, suggesting they encode emergent,
second-order patterns of trait interplay. Our findings demonstrate that LLMs
can precisely predict individual participants' psychological traits from
minimal data through a process of abstraction and reasoning, offering both a
powerful tool for psychological simulation and valuable insights into their
emergent reasoning capabilities.

</details>


### [125] [Towards Scalable Web Accessibility Audit with MLLMs as Copilots](https://arxiv.org/abs/2511.03471)
*Ming Gu,Ziwei Wang,Sicen Lai,Zirui Gao,Sheng Zhou,Jiajun Bu*

Main category: cs.AI

TL;DR: 本文提出了一种基于人机协作的网页无障碍审计框架AAA，通过图采样方法GRASP和多模态大模型辅助工具MaC实现可扩展的端到端审计，并贡献了用于评估的关键数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的网页无障碍审计方法资源消耗大、难以扩展，且依赖大量人工，限制了其广泛应用。

Method: 提出AAA框架，结合GRASP（图基多模态采样）和MaC（基于多模态大语言模型的协作者），在WCAG-EM基础上实现自动化与智能化的人机协同审计。

Result: 实验证明该方法有效提升了审计的可扩展性与效率，同时发现经过微调的小型语言模型也可成为有能力的审计专家。

Conclusion: AAA框架通过人机协作显著增强了网页无障碍审计的可行性与实际影响力，为大规模合规评估提供了实用解决方案。

Abstract: Ensuring web accessibility is crucial for advancing social welfare, justice,
and equality in digital spaces, yet the vast majority of website user
interfaces remain non-compliant, due in part to the resource-intensive and
unscalable nature of current auditing practices. While WCAG-EM offers a
structured methodology for site-wise conformance evaluation, it involves great
human efforts and lacks practical support for execution at scale. In this work,
we present an auditing framework, AAA, which operationalizes WCAG-EM through a
human-AI partnership model. AAA is anchored by two key innovations: GRASP, a
graph-based multimodal sampling method that ensures representative page
coverage via learned embeddings of visual, textual, and relational cues; and
MaC, a multimodal large language model-based copilot that supports auditors
through cross-modal reasoning and intelligent assistance in high-effort tasks.
Together, these components enable scalable, end-to-end web accessibility
auditing, empowering human auditors with AI-enhanced assistance for real-world
impact. We further contribute four novel datasets designed for benchmarking
core stages of the audit pipeline. Extensive experiments demonstrate the
effectiveness of our methods, providing insights that small-scale language
models can serve as capable experts when fine-tuned.

</details>


### [126] [Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)](https://arxiv.org/abs/2511.03545)
*Sebastian Ordyniak,Giacomo Paesani,Mateusz Rychlicki,Stefan Szeider*

Main category: cs.AI

TL;DR: 本文研究了多种机器学习模型中解释问题的参数化复杂性，重点关注具有透明内部机制的模型，涵盖决策树、决策集、布尔电路等，分析了局部与全局的溯因与对比解释问题。


<details>
  <summary>Details</summary>
Motivation: 填补可解释人工智能（XAI）领域在生成解释的复杂性方面的理论空白，推动AI系统的透明性与问责性。

Method: 采用参数化复杂性理论方法，对多种透明ML模型中的局部和全局溯因及对比解释问题进行形式化建模与复杂性分析。

Result: 系统地揭示了不同ML模型中各类解释问题的计算复杂性，为XAI提供了理论基础。

Conclusion: 该研究为理解透明机器学习模型的解释生成复杂性提供了基础框架，对推动XAI的理论发展和实际应用具有重要意义。

Abstract: This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,
each offering unique explanatory challenges. This research fills a significant
gap in explainable AI (XAI) by providing a foundational understanding of the
complexities of generating explanations for these models. This work provides
insights vital for further research in the domain of XAI, contributing to the
broader discourse on the necessity of transparency and accountability in AI
systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [127] [Scheduling the Off-Diagonal Weingarten Loss of Neural SDFs for CAD Models](https://arxiv.org/abs/2511.03147)
*Haotian Yin,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 提出了一种针对ODW损失的时间变化调度策略，用于神经符号距离函数的CAD几何重建，显著提升了重建精度。


<details>
  <summary>Details</summary>
Motivation: FlatCAD中固定的ODW损失权重在训练过程中不够灵活，强正则化虽有助于早期优化稳定，但会抑制后期细节恢复。因此需要一种动态调整策略以兼顾稳定性和细节保留。

Method: 设计了多种ODW损失调度策略，包括常数、线性、五次、步进插值以及递增预热变体，通过在训练初期设置高权重并逐步衰减，实现优化稳定与精细重构的平衡。

Result: 在ABC CAD数据集上的实验表明，时变调度策略 consistently 优于固定权重方法，Chamfer距离最多改善35%。

Conclusion: 调度策略是一种简单而有效的曲率正则化扩展方法，显著提升了神经SDF在CAD重建中的鲁棒性和精度。

Abstract: Neural signed distance functions (SDFs) have become a powerful representation
for geometric reconstruction from point clouds, yet they often require both
gradient- and curvature-based regularization to suppress spurious warp and
preserve structural fidelity. FlatCAD introduced the Off-Diagonal Weingarten
(ODW) loss as an efficient second-order prior for CAD surfaces, approximating
full-Hessian regularization at roughly half the computational cost. However,
FlatCAD applies a fixed ODW weight throughout training, which is suboptimal:
strong regularization stabilizes early optimization but suppresses detail
recovery in later stages. We present scheduling strategies for the ODW loss
that assign a high initial weight to stabilize optimization and progressively
decay it to permit fine-scale refinement. We investigate constant, linear,
quintic, and step interpolation schedules, as well as an increasing warm-up
variant. Experiments on the ABC CAD dataset demonstrate that time-varying
schedules consistently outperform fixed weights. Our method achieves up to a
35% improvement in Chamfer Distance over the FlatCAD baseline, establishing
scheduling as a simple yet effective extension of curvature regularization for
robust CAD reconstruction.

</details>


### [128] [Visualization Biases MLLM's Decision Making in Network Data Tasks](https://arxiv.org/abs/2511.03617)
*Timo Brand,Henry Förster,Stephen G. Kobourov,Jacob Miller*

Main category: cs.GR

TL;DR: 可视化可以提升多模态大语言模型（MLLM）对网络中是否存在桥接边的判断置信度，但标准可视化技术会引入强烈偏差，导致无论实际是否存在桥接边，模型都倾向于做出肯定或否定判断，可能引发不期望的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 探索可视化如何影响MLLM在判断网络结构（如桥接边存在性）时的决策过程，并评估其潜在偏差。

Method: 通过对比MLLM在结构化文本输入和包含可视化输入下的表现，分析可视化对模型判断准确性和置信度的影响。

Result: 可视化提升了模型的判断置信度，但标准可视化方法引入了显著偏差，使模型倾向于错误地确认或否认桥接边的存在。

Conclusion: 尽管可视化有助于增强MLLM的置信度，但其带来的偏差可能导致幻觉，因此在生成式AI应用中使用可视化需谨慎。

Abstract: We evaluate how visualizations can influence the judgment of MLLMs about the
presence or absence of bridges in a network. We show that the inclusion of
visualization improves confidence over a structured text-based input that could
theoretically be helpful for answering the question. On the other hand, we
observe that standard visualization techniques create a strong bias towards
accepting or refuting the presence of a bridge -- independently of whether or
not a bridge actually exists in the network. While our results indicate that
the inclusion of visualization techniques can effectively influence the MLLM's
judgment without compromising its self-reported confidence, they also imply
that practitioners must be careful of allowing users to include visualizations
in generative AI applications so as to avoid undesired hallucinations.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [129] [ALAS: Transactional and Dynamic Multi-Agent LLM Planning](https://arxiv.org/abs/2511.03094)
*Longling Geng,Edward Y. Chang*

Main category: cs.MA

TL;DR: ALAS是一个面向多智能体大语言模型规划的、具有状态感知和扰动适应能力的框架，通过分离规划与验证、记录版本化执行日志以及局部修复机制，显著提升效率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型多智能体规划方法存在验证循环、状态变更不可追溯、小错误引发全局重计算等问题，导致实际应用中脆弱且低效。

Method: 提出ALAS框架，将规划与验证分离；使用独立的验证器以避免自检循环；记录版本化执行日志以支持可恢复的执行路径；在规范化的流程中间表示（IR）上实现基于明确策略的局部修复，支持重试、超时、补偿等机制，并兼容Amazon States Language和Argo Workflows。

Result: 在五个经典任务调度基准（DMU、TA）上，ALAS达到83.7%的成功率，相比强基线减少60%的token使用量，运行速度快1.82倍；验证器能以低开销检测结构错误，局部修复有效限制运行时扰动的影响范围和时间开销。

Conclusion: 隔离的验证器、版本化执行日志和局部修复机制相结合，显著提升了多智能体LLM规划的效率、可行性与可扩展性。

Abstract: Large language models enable flexible multi-agent planning but remain fragile
in practice: verification is often circular, state changes are not tracked for
repair, and small faults trigger costly global recomputation. We present ALAS,
a stateful, disruption-aware framework that separates planning from
non-circular validation, records a versioned execution log for grounded checks
and restore points, and performs localized repair that preserves work in
progress. The validator operates independently of the planning LLM with fresh,
bounded context, avoiding self-check loops and mid-context attrition. The
repair protocol edits only the minimal affected region under explicit policies
(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)
defined in a canonical workflow IR that maps to Amazon States Language and Argo
Workflows. On job-shop scheduling suites (DMU, TA) across five classical
benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent
baselines, achieving 83.7% success, reducing token usage by 60%, and running
1.82times faster under comparable settings. A minimal reliability study shows
that the validator detects injected structural faults with low overhead, and
that localized repair contains runtime perturbations with a bounded edit radius
and less makespan degradation than global recompute. Results indicate that the
combination of validator isolation, versioned execution logs, and localized
repair provides measurable efficiency, feasibility, and scalability for
multi-agent LLM planning. Code and seeds will be released.

</details>


### [130] [Learning Communication Skills in Multi-task Multi-agent Deep Reinforcement Learning](https://arxiv.org/abs/2511.03348)
*Changxi Zhu,Mehdi Dastani,Shihan Wang*

Main category: cs.MA

TL;DR: 本文提出了一种名为多任务通信技能（MCS）的多智能体深度强化学习方法，通过可学习的通信协议实现多个任务的协同学习，利用Transformer编码器将任务特定观测映射到共享消息空间，并引入预测网络提升智能体间的协调性，在多个多任务基准环境中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在多任务多智能体环境中，如何有效利用跨任务知识并提升智能体间通信与协调能力是一个挑战。

Method: 提出MCS方法，使用Transformer编码器将任务特定观测编码到共享消息空间，学习通用通信技能；引入预测网络关联发送者的消息与其动作以增强协调性。

Result: 在三个适应为多任务设置的多智能体基准环境中，MCS在性能上优于无通信的多任务MADRL基线以及有/无通信的单任务MADRL基线。

Conclusion: MCS能够有效实现多任务下的多智能体通信与协作，通过共享通信技能和任务间知识迁移显著提升学习性能。

Abstract: In multi-agent deep reinforcement learning (MADRL), agents can communicate
with one another to perform a task in a coordinated manner. When multiple tasks
are involved, agents can also leverage knowledge from one task to improve
learning in other tasks. In this paper, we propose Multi-task Communication
Skills (MCS), a MADRL with communication method that learns and performs
multiple tasks simultaneously, with agents interacting through learnable
communication protocols. MCS employs a Transformer encoder to encode
task-specific observations into a shared message space, capturing shared
communication skills among agents. To enhance coordination among agents, we
introduce a prediction network that correlates messages with the actions of
sender agents in each task. We adapt three multi-agent benchmark environments
to multi-task settings, where the number of agents as well as the observation
and action spaces vary across tasks. Experimental results demonstrate that MCS
achieves better performance than multi-task MADRL baselines without
communication, as well as single-task MADRL baselines with and without
communication.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [131] [Generative Sequential Recommendation via Hierarchical Behavior Modeling](https://arxiv.org/abs/2511.03155)
*Zhefan Wang,Guokai Yan,Jinbei Yu,Siyu Gu,Jingyan Chen,Peng Jiang,Zhiqiang Guo,Min Zhang*

Main category: cs.IR

TL;DR: 提出了一种新的生成式推荐框架GAMER，用于解决多行为序列推荐中的复杂依赖建模和数据集不足问题，并发布了来自短视频平台的大型多行为数据集ShortVideoAD。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式多行为推荐方法在序列建模和可用数据集方面存在不足，难以有效捕捉用户行为间的跨层级依赖，且缺乏跨领域验证的数据支持。

Method: 提出GAMER框架，基于仅解码器结构，引入跨层级交互层以捕捉行为间的层次依赖，并采用序列增强策略提升训练鲁棒性；同时构建并发布新数据集ShortVideoAD，包含预训练语义ID。

Result: 实验表明，GAMER在多个指标上均优于现有的判别式和生成式基线模型，验证了其在多行为推荐中的有效性。

Conclusion: GAMER通过改进序列建模和引入高质量多行为数据集，在生成式多行为推荐中取得了显著性能提升，推动了该方向的研究发展。

Abstract: Recommender systems in multi-behavior domains, such as advertising and
e-commerce, aim to guide users toward high-value but inherently sparse
conversions. Leveraging auxiliary behaviors (e.g., clicks, likes, shares) is
therefore essential. Recent progress on generative recommendations has brought
new possibilities for multi-behavior sequential recommendation. However,
existing generative approaches face two significant challenges: 1) Inadequate
Sequence Modeling: capture the complex, cross-level dependencies within user
behavior sequences, and 2) Lack of Suitable Datasets: publicly available
multi-behavior recommendation datasets are almost exclusively derived from
e-commerce platforms, limiting the validation of feasibility in other domains,
while also lacking sufficient side information for semantic ID generation. To
address these issues, we propose a novel generative framework, GAMER
(Generative Augmentation and Multi-lEvel behavior modeling for Recommendation),
built upon a decoder-only backbone. GAMER introduces a cross-level interaction
layer to capture hierarchical dependencies among behaviors and a sequential
augmentation strategy that enhances robustness in training. To further advance
this direction, we collect and release ShortVideoAD, a large-scale
multi-behavior dataset from a mainstream short-video platform, which differs
fundamentally from existing e-commerce datasets and provides pretrained
semantic IDs for research on generative methods. Extensive experiments show
that GAMER consistently outperforms both discriminative and generative
baselines across multiple metrics.

</details>


### [132] [KScaNN: Scalable Approximate Nearest Neighbor Search on Kunpeng](https://arxiv.org/abs/2511.03298)
*Oleg Senkevich,Siyang Xu,Tianyi Jiang,Alexander Radionov,Jan Tabaszewski,Dmitriy Malyshev,Zijian Li,Daihao Xue,Licheng Yu,Weidi Zeng,Meiling Wang,Xin Yao,Siyu Huang,Gleb Neshchetkin,Qiuling Pan,Yaoyao Fu*

Main category: cs.IR

TL;DR: 本文提出了一种针对鲲鹏920 ARM架构优化的新型近似最近邻搜索算法KScaNN，通过算法与硬件协同设计，在ARM平台上实现了最高1.63倍于最快x86方案的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的x86架构ANNS算法在移植到ARM平台时性能表现不佳，未能充分利用ARM硬件特性，因此需要一种专为ARM架构优化的高效ANNS解决方案。

Method: 提出KScaNN算法，结合数据感知的算法改进与硬件特定优化：包括混合簇内搜索策略、改进的PQ残差计算方法、机器学习驱动的自适应搜索模块，以及为ARM优化的SIMD内核。

Result: 实验结果表明，KScaNN在鲲鹏920 ARM架构上显著提升了性能，相比最快的x86方案实现了最高1.63倍的加速。

Conclusion: KScaNN为现代ARM架构上的向量搜索提供了高性能解决方案，展示了算法与硬件协同设计在提升系统性能方面的巨大潜力。

Abstract: Approximate Nearest Neighbor Search (ANNS) is a cornerstone algorithm for
information retrieval, recommendation systems, and machine learning
applications. While x86-based architectures have historically dominated this
domain, the increasing adoption of ARM-based servers in industry presents a
critical need for ANNS solutions optimized on ARM architectures. A naive port
of existing x86 ANNS algorithms to ARM platforms results in a substantial
performance deficit, failing to leverage the unique capabilities of the
underlying hardware. To address this challenge, we introduce KScaNN, a novel
ANNS algorithm co-designed for the Kunpeng 920 ARM architecture. KScaNN
embodies a holistic approach that synergizes sophisticated, data aware
algorithmic refinements with carefully-designed hardware specific
optimizations. Its core contributions include: 1) novel algorithmic techniques,
including a hybrid intra-cluster search strategy and an improved PQ residual
calculation method, which optimize the search process at a higher level; 2) an
ML-driven adaptive search module that provides adaptive, per-query tuning of
search parameters, eliminating the inefficiencies of static configurations; and
3) highly-optimized SIMD kernels for ARM that maximize hardware utilization for
the critical distance computation workloads. The experimental results
demonstrate that KScaNN not only closes the performance gap but establishes a
new standard, achieving up to a 1.63x speedup over the fastest x86-based
solution. This work provides a definitive blueprint for achieving
leadership-class performance for vector search on modern ARM architectures and
underscores

</details>


### [133] [Discourse-Aware Scientific Paper Recommendation via QA-Style Summarization and Multi-Level Contrastive Learning](https://arxiv.org/abs/2511.03330)
*Shenghua Wang,Zhen Yin*

Main category: cs.IR

TL;DR: 提出OMRC-MR框架，结合问答式结构化摘要、多级对比学习和结构感知重排序，提升科学论文的内容型推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有内容型推荐模型将论文视为非结构化文本，忽略其论述结构，导致语义不完整和可解释性差。

Method: 构建一个分层框架OMRC-MR，包含问答式OMRC摘要模块、多级对比学习（元数据、章节、文档层级）和结构感知重排序模块。

Result: 在DBLP、S2ORC和新构建的Sci-OMRC数据集上实验显示，OMRC-MR在Precision@10和Recall@10上分别最高提升7.2%和3.8%，且摘要更连贯、事实更完整。

Conclusion: OMRC-MR提供了一种统一、可解释的内容型科研推荐范式，推动了可信、隐私安全的学术信息检索发展。

Abstract: The rapid growth of open-access (OA) publications has intensified the
challenge of identifying relevant scientific papers. Due to privacy constraints
and limited access to user interaction data, recent efforts have shifted toward
content-based recommendation, which relies solely on textual information.
However, existing models typically treat papers as unstructured text,
neglecting their discourse organization and thereby limiting semantic
completeness and interpretability. To address these limitations, we propose
OMRC-MR, a hierarchical framework that integrates QA-style OMRC (Objective,
Method, Result, Conclusion) summarization, multi-level contrastive learning,
and structure-aware re-ranking for scholarly recommendation. The QA-style
summarization module converts raw papers into structured and
discourse-consistent representations, while multi-level contrastive objectives
align semantic representations across metadata, section, and document levels.
The final re-ranking stage further refines retrieval precision through
contextual similarity calibration. Experiments on DBLP, S2ORC, and the newly
constructed Sci-OMRC dataset demonstrate that OMRC-MR consistently surpasses
state-of-the-art baselines, achieving up to 7.2% and 3.8% improvements in
Precision@10 and Recall@10, respectively. Additional evaluations confirm that
QA-style summarization produces more coherent and factually complete
representations. Overall, OMRC-MR provides a unified and interpretable
content-based paradigm for scientific paper recommendation, advancing
trustworthy and privacy-aware scholarly information retrieval.

</details>


### [134] [A Semantic Encoding of Object Centric Event Data](https://arxiv.org/abs/2511.03351)
*Saba Latif,Fajar J. Ekaputra,Maxim Vidgof,Sabrina Kirrane,Claudio Di Ciccio*

Main category: cs.IR

TL;DR: 本文提出了一种基于语义网技术的语义增强型对象中心事件数据（OCED）方法，旨在提升过程数据的可推理性、信息源互联性和表达能力。


<details>
  <summary>Details</summary>
Motivation: 为了促进不同来源的过程数据互操作性和信息交换，解决多提供者数据集成、多流程融合和知识推理增强等挑战。

Method: 利用语义网技术构建语义增强的OCED模型，通过基于本体的关系和实体分类来丰富机器可读的OCED描述。

Result: 实现了语义增强的OCED，增强了过程数据的互连性、推理能力和表达力。

Conclusion: 该方法为OCED提供了更强的语义支持，有助于实现跨系统的过程数据共享与智能分析。

Abstract: The Object-Centric Event Data (OCED) is a novel meta-model aimed at providing
a common ground for process data records centered around events and objects.
One of its objectives is to foster interoperability and process information
exchange. In this context, the integration of data from different providers,
the combination of multiple processes, and the enhancement of knowledge
inference are novel challenges. Semantic Web technologies can enable the
creation of a machine-readable OCED description enriched through ontology-based
relationships and entity categorization. In this paper, we introduce an
approach built upon Semantic Web technologies for the realization of
semantic-enhanced OCED, with the aim to strengthen process data reasoning,
interconnect information sources, and boost expressiveness.

</details>


### [135] [CLAX: Fast and Flexible Neural Click Models in JAX](https://arxiv.org/abs/2511.03620)
*Philipp Hager,Onno Zoeter,Maarten de Rijke*

Main category: cs.IR

TL;DR: CLAX是一个基于JAX的库，使用现代梯度优化方法实现经典点击模型，取代传统的EM算法，支持模块化集成深度网络组件，并在大规模数据上实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 尽管神经点击模型已有发展，但基于概率图模型的经典复杂点击模型尚未系统采用梯度优化，限制了其在现代深度学习框架中的应用。CLAX旨在填补这一空白，兼顾模型可解释性与高效优化。

Method: 采用JAX框架，以数值稳定的方式用梯度优化替代EM算法，设计模块化架构，支持嵌入层、深度网络等组件的灵活集成，实现经典点击模型的端到端训练。

Result: 在单个GPU上约2小时内完成超过十亿用户会话的Baidu-ULTR数据集实验，速度远超传统EM方法；实现了10种经典点击模型。

Conclusion: CLAX为工业界和研究人员提供了高效、可扩展且可解释的点击模型训练框架，推动经典模型与现代深度学习技术的融合。

Abstract: CLAX is a JAX-based library that implements classic click models using modern
gradient-based optimization. While neural click models have emerged over the
past decade, complex click models based on probabilistic graphical models
(PGMs) have not systematically adopted gradient-based optimization, preventing
practitioners from leveraging modern deep learning frameworks while preserving
the interpretability of classic models. CLAX addresses this gap by replacing
EM-based optimization with direct gradient-based optimization in a numerically
stable manner. The framework's modular design enables the integration of any
component, from embeddings and deep networks to custom modules, into classic
click models for end-to-end optimization. We demonstrate CLAX's efficiency by
running experiments on the full Baidu-ULTR dataset comprising over a billion
user sessions in $\approx$ 2 hours on a single GPU, orders of magnitude faster
than traditional EM approaches. CLAX implements ten classic click models,
serving both industry practitioners seeking to understand user behavior and
improve ranking performance at scale and researchers developing new click
models. CLAX is available at: https://github.com/philipphager/clax

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [136] [FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels](https://arxiv.org/abs/2511.02872)
*Jiedong Jiang,Wanyi He,Yuefeng Wang,Guoxiong Gao,Yongle Hu,Jingting Wang,Nailing Guan,Peihao Wu,Chunbo Dai,Liang Xiao,Bin Dong*

Main category: cs.LG

TL;DR: 本文提出了FATE，一个面向高级数学推理的正式代数定理评估基准，包含FATE-H和FATE-X两个新组件，涵盖从本科练习到超过博士资格考试难度的问题。实验表明现有大语言模型在该基准上表现较差，揭示了自然语言推理与形式化之间的差距，并分析了常见错误类型。


<details>
  <summary>Details</summary>
Motivation: 现有的数学竞赛基准（如IMO）无法反映现代数学研究的深度、广度和抽象性，因此需要一个新的更具挑战性的形式化数学推理基准来推动大语言模型在高级数学领域的发展。

Method: 构建了一个名为FATE的新基准系列，包括FATE-H和FATE-X，各含100个抽象代数与交换代数问题；设计两阶段评估方法（自然语言推理与形式化）来分析模型性能；对当前最先进的大语言模型证明器进行系统评测并分类常见错误。

Result: 最先进的模型在FATE-H上的准确率仅为3%（pass@64），在FATE-X上为0%；发现模型的自然语言推理能力优于其形式化能力；专门化的证明器在反思能力上不如通用模型，导致自然语言阶段准确性下降。

Conclusion: FATE提供了一个强大且具挑战性的基准，能够为实现研究级的形式化数学推理设立关键里程碑，揭示了当前大语言模型在形式化抽象数学方面仍存在显著不足。

Abstract: Recent advances in large language models (LLMs) have demonstrated impressive
capabilities in formal theorem proving, particularly on contest-based
mathematical benchmarks like the IMO. However, these contests do not reflect
the depth, breadth, and abstraction of modern mathematical research. To bridge
this gap, we introduce FATE (Formal Algebra Theorem Evaluation), a new
benchmark series in formal algebra designed to chart a course toward advanced
mathematical reasoning. We present two new components, FATE-H and FATE-X, each
with 100 problems in abstract and commutative algebra. The FATE series spans a
difficulty spectrum from undergraduate exercises to problems exceeding PhD
qualifying exams. Notably, FATE-X is the first formal benchmark to surpass both
PhD-level exam difficulty and the coverage of the Mathlib library. Our
evaluations of state-of-the-art LLM provers on this new benchmark reveal a
stark performance gap compared to contest math: the best model achieves only 3%
(pass@64) accuracy on FATE-H and 0% on FATE-X. Our two-stage evaluation reveals
that models' natural-language reasoning is notably more accurate than their
ability to formalize this reasoning. We systematically classify the common
errors that arise during this formalization process. Furthermore, a comparative
study shows that a specialized prover can exhibit less effective reflection
than general-purpose models, reducing its accuracy at the natural-language
stage. We believe FATE provides a robust and challenging benchmark that
establishes essential checkpoints on the path toward research-level formal
mathematical reasoning.

</details>


### [137] [Stochastic Deep Graph Clustering for Practical Group Formation](https://arxiv.org/abs/2511.02879)
*Junhyung Park,Hyungjin Kim,Seokho Ahn,Young-Duk Seo*

Main category: cs.LG

TL;DR: 本文提出了DeepForm，一种基于随机深度图聚类的实用化群体形成框架，用于解决推荐系统中动态群体形成的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有群体推荐系统大多假设群体是静态或预定义的，难以适应现实中的动态场景，因此需要一种能够实时、自适应形成和调整群体的方法。

Method: 提出DeepForm框架，采用轻量级GCN捕捉高阶用户信息，结合随机聚类学习实现无需重训练的自适应重组，并利用对比学习在动态条件下优化群体划分。

Result: 在多个数据集上的实验表明，DeepForm在群体形成质量、效率和推荐准确性方面均优于多种基线方法。

Conclusion: DeepForm有效解决了动态环境下群体推荐中的群体形成问题，满足了高阶信息融合、实时性和动态调整群体数量的实际需求。

Abstract: While prior work on group recommender systems (GRSs) has primarily focused on
improving recommendation accuracy, most approaches assume static or predefined
groups, making them unsuitable for dynamic, real-world scenarios. We reframe
group formation as a core challenge in GRSs and propose DeepForm (Stochastic
Deep Graph Clustering for Practical Group Formation), a framework designed to
meet three key operational requirements: (1) the incorporation of high-order
user information, (2) real-time group formation, and (3) dynamic adjustment of
the number of groups. DeepForm employs a lightweight GCN architecture that
effectively captures high-order structural signals. Stochastic cluster learning
enables adaptive group reconfiguration without retraining, while contrastive
learning refines groups under dynamic conditions. Experiments on multiple
datasets demonstrate that DeepForm achieves superior group formation quality,
efficiency, and recommendation accuracy compared with various baselines.

</details>


### [138] [Scaling Multi-Agent Environment Co-Design with Diffusion Models](https://arxiv.org/abs/2511.03100)
*Hao Xiang Li,Michael Amir,Amanda Prorok*

Main category: cs.LG

TL;DR: 本文提出了一种可扩展且样本高效的协同设计框架DiCoDe，用于联合优化智能体策略与环境配置，在多智能体系统中实现了显著性能提升和更少的采样需求。


<details>
  <summary>Details</summary>
Motivation: 现有协同设计方法在高维环境设计空间下难以扩展，且在处理联合优化中的动态目标时存在样本效率低的问题。

Method: 提出了Diffusion Co-Design (DiCoDe) 框架，包含两个核心创新：Projected Universal Guidance (PUG) 以在满足硬约束的同时探索奖励最大化环境分布；以及批评者蒸馏机制，利用强化学习批评者提供密集、及时的学习信号来指导扩散模型适应变化的策略。

Result: 在仓库自动化、多智能体路径规划和风场优化等基准任务上验证了DiCoDe的有效性，相比当前最优方法，在仓库场景中奖励提高了39%，同时减少了66%的仿真样本。

Conclusion: DiCoDe为智能体-环境协同设计设立了新标准，推动了该方法向实际应用场景的落地迈进。

Abstract: The agent-environment co-design paradigm jointly optimises agent policies and
environment configurations in search of improved system performance. With
application domains ranging from warehouse logistics to windfarm management,
co-design promises to fundamentally change how we deploy multi-agent systems.
However, current co-design methods struggle to scale. They collapse under
high-dimensional environment design spaces and suffer from sample inefficiency
when addressing moving targets inherent to joint optimisation. We address these
challenges by developing Diffusion Co-Design (DiCoDe), a scalable and
sample-efficient co-design framework pushing co-design towards practically
relevant settings. DiCoDe incorporates two core innovations. First, we
introduce Projected Universal Guidance (PUG), a sampling technique that enables
DiCoDe to explore a distribution of reward-maximising environments while
satisfying hard constraints such as spatial separation between obstacles.
Second, we devise a critic distillation mechanism to share knowledge from the
reinforcement learning critic, ensuring that the guided diffusion model adapts
to evolving agent policies using a dense and up-to-date learning signal.
Together, these improvements lead to superior environment-policy pairs when
validated on challenging multi-agent environment co-design benchmarks including
warehouse automation, multi-agent pathfinding and wind farm optimisation. Our
method consistently exceeds the state-of-the-art, achieving, for example, 39%
higher rewards in the warehouse setting with 66% fewer simulation samples. This
sets a new standard in agent-environment co-design, and is a stepping stone
towards reaping the rewards of co-design in real world domains.

</details>


### [139] [Test-time Adaptation of Tiny Recursive Models](https://arxiv.org/abs/2511.02886)
*Ronan Killian McGovern*

Main category: cs.LG

TL;DR: 通过在公开的ARC任务上预训练一个微型递归模型，并在比赛允许的计算资源内进行微调，实现了在半私有评估任务上6.67%的得分。


<details>
  <summary>Details</summary>
Motivation: 在有限计算资源下提升ARC Prize竞赛中开源方法的表现，克服此前方法计算成本过高的问题。

Method: 使用4xH100 SXM GPU对7M参数的递归神经网络在1,280个公开ARC任务上预训练70万步；随后在比赛中进行12,500步的全模型微调（非LoRA或仅任务嵌入微调）。

Result: 预训练模型在公共测试集上达到约10%的得分，经过有限微调后在半私有评估任务上获得6.67%的得分。

Conclusion: 全模型微调小型递归网络是一种在严格计算限制下有效参与ARC竞赛的可行策略。

Abstract: Prior to the close of the 2025 ARC Prize competition, the leading open source
approach - known as TRM, or Tiny Recursive Models - involved training a 7M
parameter recursive neural network on augmented variants of ARC tasks. That
approach scored approximately 7.8% on the public ARC AGI II evaluation set, but
required a level of compute far in excess of what is allowed during the
competition. This paper shows that, by starting from a tiny recursive model
that has been pre-trained on public ARC tasks, one can efficiently fine-tune on
competition tasks within the allowed compute limits. Specifically, a model was
pre-trained on 1,280 public tasks for 700k+ optimizer steps over 48 hours on
4xH100 SXM GPUs to obtain a ~10% score on the public evaluation set. That model
was then post-trained in just 12,500 gradient steps during the competition to
reach a score of 6.67% on semi-private evaluation tasks. Notably, such
post-training performance is achieved by full-fine tuning of the tiny model,
not LoRA fine-tuning or fine-tuning of task embeddings alone.

</details>


### [140] [Predicting Weekly Fishing Concentration Zones through Deep Learning Integration of Heterogeneous Environmental Spatial Datasets](https://arxiv.org/abs/2511.02887)
*Chaitanya Rele,Aditya Rathod,Kaustubh Natu,Saurabh Kulkarni,Ajay Koli,Swapnali Makdey*

Main category: cs.LG

TL;DR: 提出了一种基于海表温度和叶绿素浓度等海洋参数的AI辅助潜在渔区（PFZ）预测框架，旨在提高渔区识别准确性，减少捕捞时间和燃料消耗，促进可持续渔业。


<details>
  <summary>Details</summary>
Motivation: 解决渔民在北印度洋寻找高产渔区时面临的不确定性问题。

Method: 利用人工智能技术结合海表温度和叶绿素浓度等海洋学参数进行潜在渔区预测。

Result: 初步结果显示该框架能有效减少搜寻时间、降低燃料消耗并提高资源利用效率。

Conclusion: 该AI辅助框架有助于提升渔业效率和可持续性，具有实际应用潜力。

Abstract: The North Indian Ocean, including the Arabian Sea and the Bay of Bengal,
represents a vital source of livelihood for coastal communities, yet fishermen
often face uncertainty in locating productive fishing grounds. To address this
challenge, we present an AI-assisted framework for predicting Potential Fishing
Zones (PFZs) using oceanographic parameters such as sea surface temperature and
chlorophyll concentration. The approach is designed to enhance the accuracy of
PFZ identification and provide region-specific insights for sustainable fishing
practices. Preliminary results indicate that the framework can support
fishermen by reducing search time, lowering fuel consumption, and promoting
efficient resource utilization.

</details>


### [141] [Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models](https://arxiv.org/abs/2511.02894)
*W. K. M Mithsara,Ning Yang,Ahmed Imteaj,Hussein Zangoti,Abdur R. Shahid*

Main category: cs.LG

TL;DR: 提出一种基于大语言模型（LLM）的零样本、少样本人类活动识别（HAR）系统中毒检测与净化框架，利用角色扮演和逐步推理提示技术，在减少对大规模标注数据依赖的同时，提升可穿戴物联网系统的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的HAR系统易受数据投毒攻击，且传统防御方法依赖大量标注数据，难以适应动态的物联网环境。

Method: 采用大语言模型结合零样本、单样本和少样本学习，引入“角色扮演”和“逐步思考”提示策略，使LLM能够识别传感器数据中的异常并推断出可能的干净数据。

Result: 实验评估了该框架在检测准确率、净化质量、延迟和通信开销方面的表现，验证了其在实际可穿戴物联网系统中有效且可行。

Conclusion: LLM能够在无需大量训练数据的情况下，提供自适应、实时的投毒检测与净化能力，显著提升HAR系统的安全性和可靠性。

Abstract: The widespread integration of wearable sensing devices in Internet of Things
(IoT) ecosystems, particularly in healthcare, smart homes, and industrial
applications, has required robust human activity recognition (HAR) techniques
to improve functionality and user experience. Although machine learning models
have advanced HAR, they are increasingly susceptible to data poisoning attacks
that compromise the data integrity and reliability of these systems.
Conventional approaches to defending against such attacks often require
extensive task-specific training with large, labeled datasets, which limits
adaptability in dynamic IoT environments. This work proposes a novel framework
that uses large language models (LLMs) to perform poisoning detection and
sanitization in HAR systems, utilizing zero-shot, one-shot, and few-shot
learning paradigms. Our approach incorporates \textit{role play} prompting,
whereby the LLM assumes the role of expert to contextualize and evaluate sensor
anomalies, and \textit{think step-by-step} reasoning, guiding the LLM to infer
poisoning indicators in the raw sensor data and plausible clean alternatives.
These strategies minimize reliance on curation of extensive datasets and enable
robust, adaptable defense mechanisms in real-time. We perform an extensive
evaluation of the framework, quantifying detection accuracy, sanitization
quality, latency, and communication cost, thus demonstrating the practicality
and effectiveness of LLMs in improving the security and reliability of wearable
IoT systems.

</details>


### [142] [Zero-shot data citation function classification using transformer-based large language models (LLMs)](https://arxiv.org/abs/2511.02936)
*Neil Byers,Ali Zaidi,Valerie Skye,Chris Beecroft,Kjiersten Fagnan*

Main category: cs.LG

TL;DR: 本研究利用开源大语言模型Llama 3.1-405B，自动生成基因组数据在出版物中使用场景的结构化标签，并提出新的评估框架。结果显示，该模型在零样本数据引用分类任务中F1得分为0.674，表现有潜力，但仍受限于数据可用性、提示过拟合、计算资源和评估成本等问题。


<details>
  <summary>Details</summary>
Motivation: 识别科学文献中特定数据集的使用方式具有重要意义，传统方法依赖人工标注或构建机器学习训练数据，成本高且难以扩展。因此，需要一种可扩展、自动化的方法来描述数据在科研中的实际应用。

Method: 采用预训练的开源大语言模型Llama 3.1-405B，对已知使用特定基因组数据集的出版物进行零样本推理，生成结构化的数据使用案例标签，并设计了一种新颖的评估框架来衡量模型效果。

Result: Llama 3.1-405B在无预先定义类别的情况下，实现了0.674的F1分数，表明其在自动识别和分类数据使用场景方面具有潜力，但存在提示过拟合、数据稀缺和计算成本高等挑战。

Conclusion: 大语言模型为大规模分析科研文献中的数据使用提供了可行路径，尤其在零样本设置下表现良好，但其广泛应用仍需克服数据、计算和评估方面的实际障碍。

Abstract: Efforts have increased in recent years to identify associations between
specific datasets and the scientific literature that incorporates them. Knowing
that a given publication cites a given dataset, the next logical step is to
explore how or why that data was used. Advances in recent years with
pretrained, transformer-based large language models (LLMs) offer potential
means for scaling the description of data use cases in the published
literature. This avoids expensive manual labeling and the development of
training datasets for classical machine-learning (ML) systems. In this work we
apply an open-source LLM, Llama 3.1-405B, to generate structured data use case
labels for publications known to incorporate specific genomic datasets. We also
introduce a novel evaluation framework for determining the efficacy of our
methods. Our results demonstrate that the stock model can achieve an F1 score
of .674 on a zero-shot data citation classification task with no previously
defined categories. While promising, our results are qualified by barriers
related to data availability, prompt overfitting, computational infrastructure,
and the expense required to conduct responsible performance evaluation.

</details>


### [143] [Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics](https://arxiv.org/abs/2511.02944)
*Fengxu Li,Stephanie M. Carpenter,Matthew P. Buman,Yonatan Mintz*

Main category: cs.LG

TL;DR: 本文提出了适用于ROGUE bandit框架的ROGUE-TS算法，并引入概率裁剪方法，在降低遗憾的同时保持足够的探索性，以兼顾个性化推荐与群体效应估计。


<details>
  <summary>Details</summary>
Motivation: 在非平稳环境（如行为健康干预）中，现有算法可能过度强调利用而忽视探索，限制了对群体效应的准确估计，尤其影响微随机试验（MRT）中的统计效力。

Method: 提出ROGUE-TS算法，结合Thompson Sampling与概率裁剪机制，理论证明其具有次线性遗憾，并量化探索与后悔之间的权衡。

Result: 在两个MRT数据集上验证显示，该方法相比现有方法具有更低的遗憾和更高的统计检验力，能在不显著增加遗憾的情况下维持充分探索。

Conclusion: 所提框架为设计MRT提供了实用指导，有效平衡个性化干预与群体层面效应检测的需求。

Abstract: A common challenge for decision makers is selecting actions whose rewards are
unknown and evolve over time based on prior policies. For instance, repeated
use may reduce an action's effectiveness (habituation), while inactivity may
restore it (recovery). These nonstationarities are captured by the Reducing or
Gaining Unknown Efficacy (ROGUE) bandit framework, which models real-world
settings such as behavioral health interventions. While existing algorithms can
compute sublinear regret policies to optimize these settings, they may not
provide sufficient exploration due to overemphasis on exploitation, limiting
the ability to estimate population-level effects. This is a challenge of
particular interest in micro-randomized trials (MRTs) that aid researchers in
developing just-in-time adaptive interventions that have population-level
effects while still providing personalized recommendations to individuals. In
this paper, we first develop ROGUE-TS, a Thompson Sampling algorithm tailored
to the ROGUE framework, and provide theoretical guarantees of sublinear regret.
We then introduce a probability clipping procedure to balance personalization
and population-level learning, with quantified trade-off that balances regret
and minimum exploration probability. Validation on two MRT datasets concerning
physical activity promotion and bipolar disorder treatment shows that our
methods both achieve lower regret than existing approaches and maintain high
statistical power through the clipping procedure without significantly
increasing regret. This enables reliable detection of treatment effects while
accounting for individual behavioral dynamics. For researchers designing MRTs,
our framework offers practical guidance on balancing personalization with
statistical validity.

</details>


### [144] [Digital Twin-Driven Pavement Health Monitoring and Maintenance Optimization Using Graph Neural Networks](https://arxiv.org/abs/2511.02957)
*Mohsin Mahmud Topu,Mahfuz Ahmed Anik,Azmine Toushik Wasi,Md Manjurul Ahsan*

Main category: cs.LG

TL;DR: 提出了一种结合数字孪生（DT）和图神经网络（GNN）的框架，用于可扩展的数据驱动型路面健康监测与预测性维护。


<details>
  <summary>Details</summary>
Motivation: 传统路面管理系统（PMS）缺乏实时智能，难以实现故障预防和最优维护规划，且面临复杂空间依赖性和非线性退化等挑战。

Method: 将路面段及其空间关系建模为图结构，利用无人机、传感器和LiDAR实时数据输入数字孪生系统，采用归纳式GNN从图结构数据中学习退化模式并预测病害。

Result: 在模拟真实数据集上训练后，模型R2达到0.3798，优于基线回归模型，能有效捕捉非线性退化；同时开发了交互式仪表盘和强化学习模块用于仿真与自适应维护规划。

Conclusion: DT-GNN集成提升了预测精度，建立了闭环反馈机制，为智能化、可持续的路面管理提供了基础，并具备向实际部署、多智能体协同和智慧城市集成的潜力。

Abstract: Pavement infrastructure monitoring is challenged by complex spatial
dependencies, changing environmental conditions, and non-linear deterioration
across road networks. Traditional Pavement Management Systems (PMS) remain
largely reactive, lacking real-time intelligence for failure prevention and
optimal maintenance planning. To address this, we propose a unified Digital
Twin (DT) and Graph Neural Network (GNN) framework for scalable, data-driven
pavement health monitoring and predictive maintenance. Pavement segments and
spatial relations are modeled as graph nodes and edges, while real-time UAV,
sensor, and LiDAR data stream into the DT. The inductive GNN learns
deterioration patterns from graph-structured inputs to forecast distress and
enable proactive interventions. Trained on a real-world-inspired dataset with
segment attributes and dynamic connectivity, our model achieves an R2 of
0.3798, outperforming baseline regressors and effectively capturing non-linear
degradation. We also develop an interactive dashboard and reinforcement
learning module for simulation, visualization, and adaptive maintenance
planning. This DT-GNN integration enhances forecasting precision and
establishes a closed feedback loop for continuous improvement, positioning the
approach as a foundation for proactive, intelligent, and sustainable pavement
management, with future extensions toward real-world deployment, multi-agent
coordination, and smart-city integration.

</details>


### [145] [Inference-Time Personalized Alignment with a Few User Preference Queries](https://arxiv.org/abs/2511.02966)
*Victor-Alexandru Pădurean,Parameswaran Kamalaruban,Nachiket Kotalwar,Alkis Gotovos,Adish Singla*

Main category: cs.LG

TL;DR: 本文提出了一种名为UserAlign的新型推理时个性化对齐方法，通过少量成对响应比较来获取用户偏好，从而快速识别最佳响应。


<details>
  <summary>Details</summary>
Motivation: 现有个性化对齐方法需要大量用户查询或显式文本输入，成本高且不灵活，因此需要一种高效、低负担的对齐方式。

Method: 基于逻辑带臂老虎机中的最优臂识别理论框架，通过少量成对响应比较获取用户反馈，并假设反馈一致且无噪声，从固定生成池中选择最优响应。

Result: 在多个文本和图像生成任务上的实验表明，UserAlign能有效实现个性化对齐，显著减少用户查询次数并提升对齐效果。

Conclusion: UserAlign是一种高效、实用的个性化对齐方法，能够在少量用户反馈下快速识别并生成符合用户偏好的输出。

Abstract: We study the problem of aligning a generative model's response with a user's
preferences. Recent works have proposed several different formulations for
personalized alignment; however, they either require a large amount of user
preference queries or require that the preference be explicitly specified as a
text input. In this paper, we propose a novel inference-time personalized
alignment method, UserAlign, that elicits the user's preferences with a few
queries as pairwise response comparisons. In particular, UserAlign builds on
the theoretical framework of best-arm identification in logistic bandits and
selects a personalized response from a fixed pool of the model's generated
responses. The key idea is to consider the user's feedback consistent and
noise-free, and incorporate it into the theoretical framework to identify the
best response quickly. Experimental results across several tasks, involving
personalized text and image generation, showcase the effectiveness of UserAlign
in achieving personalized alignment.

</details>


### [146] [Value of Information-Enhanced Exploration in Bootstrapped DQN](https://arxiv.org/abs/2511.02969)
*Stergios Plataniotis,Charilaos Akasiadis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息价值（EVOI）的深度强化学习探索方法，将其集成到Bootstrapped DQN框架中，通过衡量网络头之间的意见分歧来引导探索，提升了在高维稀疏奖励环境下的性能，且无需引入额外超参数。


<details>
  <summary>Details</summary>
Motivation: 传统探索策略（如ε-贪婪）在高维稀疏奖励环境中难以有效平衡探索与利用，缺乏对不确定性的有效利用。

Method: 将信息价值（EVOI）概念引入Bootstrapped DQN，设计两种新算法，利用EVOI估计衡量多个网络头之间的预测差异，并以此驱动探索。

Result: 在稀疏奖励的Atari游戏中实验表明，所提方法相比基线算法性能更高，能更有效地利用由网络初始化带来的不确定性。

Conclusion: 结合信息价值的深度探索策略可显著提升深度强化学习在复杂环境中的表现，且保持算法简洁、无需调参。

Abstract: Efficient exploration in deep reinforcement learning remains a fundamental
challenge, especially in environments characterized by high-dimensional states
and sparse rewards. Traditional exploration strategies that rely on random
local policy noise, such as $\epsilon$-greedy and Boltzmann exploration
methods, often struggle to efficiently balance exploration and exploitation. In
this paper, we integrate the notion of (expected) value of information (EVOI)
within the well-known Bootstrapped DQN algorithmic framework, to enhance the
algorithm's deep exploration ability. Specifically, we develop two novel
algorithms that incorporate the expected gain from learning the value of
information into Bootstrapped DQN. Our methods use value of information
estimates to measure the discrepancies of opinions among distinct network
heads, and drive exploration towards areas with the most potential. We evaluate
our algorithms with respect to performance and their ability to exploit
inherent uncertainty arising from random network initialization. Our
experiments in complex, sparse-reward Atari games demonstrate increased
performance, all the while making better use of uncertainty, and, importantly,
without introducing extra hyperparameters.

</details>


### [147] [Heterogeneous Metamaterials Design via Multiscale Neural Implicit Representation](https://arxiv.org/abs/2511.03012)
*Hongrui Chen,Liwei Wang,Levent Burak Kara*

Main category: cs.LG

TL;DR: 提出一种基于神经网络的超材料设计框架，通过学习连续的双尺度结构表示，实现无需预定义数据集的兼容性单元设计，并支持任意高分辨率输出。


<details>
  <summary>Details</summary>
Motivation: 传统多尺度设计方法计算成本高且存在边界不连续问题，基于数据驱动的方法受限于数据集并需要后处理确保连接性，因此需要一种更高效、灵活的设计方法。

Method: 提出一种双尺度神经表示方法，网络同时输入宏观和微观坐标，输出隐式场表示具有兼容几何结构的多尺度结构，并在训练中引入兼容性损失项以保证相邻单元的连接性。

Result: 该框架能够在没有预定义数据集的情况下生成无缝连接的异质超材料设计，支持任意高分辨率输出，验证了在机械超材料、负泊松比和力学隐身等问题上的有效性。

Conclusion: 所提方法有效解决了异质超材料设计中的高维设计空间与单元兼容性难题，为机器人、生物工程和航空航天等领域的应用提供了新的设计工具。

Abstract: Metamaterials are engineered materials composed of specially designed unit
cells that exhibit extraordinary properties beyond those of natural materials.
Complex engineering tasks often require heterogeneous unit cells to accommodate
spatially varying property requirements. However, designing heterogeneous
metamaterials poses significant challenges due to the enormous design space and
strict compatibility requirements between neighboring cells. Traditional
concurrent multiscale design methods require solving an expensive optimization
problem for each unit cell and often suffer from discontinuities at cell
boundaries. On the other hand, data-driven approaches that assemble structures
from a fixed library of microstructures are limited by the dataset and require
additional post-processing to ensure seamless connections. In this work, we
propose a neural network-based metamaterial design framework that learns a
continuous two-scale representation of the structure, thereby jointly
addressing these challenges. Central to our framework is a multiscale neural
representation in which the neural network takes both global (macroscale) and
local (microscale) coordinates as inputs, outputting an implicit field that
represents multiscale structures with compatible unit cell geometries across
the domain, without the need for a predefined dataset. We use a compatibility
loss term during training to enforce connectivity between adjacent unit cells.
Once trained, the network can produce metamaterial designs at arbitrarily high
resolution, hence enabling infinite upsampling for fabrication or simulation.
We demonstrate the effectiveness of the proposed approach on mechanical
metamaterial design, negative Poisson's ratio, and mechanical cloaking problems
with potential applications in robotics, bioengineering, and aerospace.

</details>


### [148] [Discrete Bayesian Sample Inference for Graph Generation](https://arxiv.org/abs/2511.03015)
*Ole Petersen,Marcel Kollovieh,Marten Lienen,Stephan Günnemann*

Main category: cs.LG

TL;DR: 提出了一种基于贝叶斯采样推断（BSI）的新型一次性图生成模型GraphBSI，通过在连续分布参数空间中迭代优化图的信念，有效处理离散结构，并在分子和合成图生成任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 图结构数据的离散性和无序性使得传统生成模型难以处理，现有扩散模型和流匹配方法存在局限，因此需要一种能自然处理离散图结构的一次性生成模型。

Method: 提出GraphBSI模型，将贝叶斯采样推断表述为随机微分方程（SDE），在连续分布参数空间中迭代更新图的信念分布，并引入噪声控制的SDE族，通过分数函数近似保持边缘分布；理论分析揭示其与贝叶斯流网络和扩散模型的联系。

Result: 在Moses和GuacaMol标准基准上的实验表明，GraphBSI在分子和合成图生成任务中优于现有的一次性图生成模型，取得了最先进的性能。

Conclusion: GraphBSI为图生成提供了一个新的框架，通过在连续参数空间中进行信念传播来处理离散图结构，兼具理论深度和实证优势，是离散结构生成的一个有效新范式。

Abstract: Generating graph-structured data is crucial in applications such as molecular
generation, knowledge graphs, and network analysis. However, their discrete,
unordered nature makes them difficult for traditional generative models,
leading to the rise of discrete diffusion and flow matching models. In this
work, we introduce GraphBSI, a novel one-shot graph generative model based on
Bayesian Sample Inference (BSI). Instead of evolving samples directly, GraphBSI
iteratively refines a belief over graphs in the continuous space of
distribution parameters, naturally handling discrete structures. Further, we
state BSI as a stochastic differential equation (SDE) and derive a
noise-controlled family of SDEs that preserves the marginal distributions via
an approximation of the score function. Our theoretical analysis further
reveals the connection to Bayesian Flow Networks and Diffusion models. Finally,
in our empirical evaluation, we demonstrate state-of-the-art performance on
molecular and synthetic graph generation, outperforming existing one-shot graph
generative models on the standard benchmarks Moses and GuacaMol.

</details>


### [149] [Adaptive-Sensorless Monitoring of Shipping Containers](https://arxiv.org/abs/2511.03022)
*Lingqing Shen,Chi Heem Wong,Misaki Mito,Arnab Chakrabarti*

Main category: cs.LG

TL;DR: 本文提出了一种残差校正方法，用于在观察到实时遥测数据后校正无传感器模型中的系统性偏差，这类模型被称为“自适应-无传感器”监测。


<details>
  <summary>Details</summary>
Motivation: 无传感器监测无法整合遥测信息并纠正系统性误差，导致预测结果与实际数据差异较大。

Method: 提出了残差校正方法，构建自适应-无传感器模型，并在包含348万数据点的大型数据集上进行训练和评估。

Result: 在模拟数据的保留集上，自适应-无传感器模型相比基线无传感器模型显著降低了平均绝对误差和均方根误差：温度MAE降至2.24~2.31°C（原为2.43°C），湿度MAE为5.72~7.09%（原为7.99%）；温度RMSE为3.19~3.26°C（原为3.38°C），湿度RMSE为7.70~9.12%（原为10.0%）。

Conclusion: 自适应-无传感器模型能够实现更精确的货物监控、早期风险预警，并减少对全球航运中完全连接性的依赖。

Abstract: Monitoring the internal temperature and humidity of shipping containers is
essential to preventing quality degradation during cargo transportation.
Sensorless monitoring -- machine learning models that predict the internal
conditions of the containers using exogenous factors -- shows promise as an
alternative to monitoring using sensors. However, it does not incorporate
telemetry information and correct for systematic errors, causing the
predictions to differ significantly from the live data and confusing the users.
In this paper, we introduce the residual correction method, a general framework
for correcting for systematic biases in sensorless models after observing live
telemetry data. We call this class of models ``adaptive-sensorless''
monitoring. We train and evaluate adaptive-sensorless models on the 3.48
million data points -- the largest dataset of container sensor readings ever
used in academic research -- and show that they produce consistent improvements
over the baseline sensorless models. When evaluated on the holdout set of the
simulated data, they achieve average mean absolute errors (MAEs) of 2.24 $\sim$
2.31$^\circ$C (vs 2.43$^\circ$C by sensorless) for temperature and 5.72 $\sim$
7.09% for relative humidity (vs 7.99% by sensorless) and average root
mean-squared errors (RMSEs) of 3.19 $\sim$ 3.26$^\circ$C for temperature (vs
3.38$^\circ$C by sensorless) and 7.70 $\sim$ 9.12% for relative humidity (vs
10.0% by sensorless). Adaptive-sensorless models enable more accurate cargo
monitoring, early risk detection, and less dependence on full connectivity in
global shipping.

</details>


### [150] [Leveraging Discrete Function Decomposability for Scientific Design](https://arxiv.org/abs/2511.03032)
*James C. Bowden,Sergey Levine,Jennifer Listgarten*

Main category: cs.LG

TL;DR: 提出了一种新的分布优化算法DADO，利用设计变量上的连接树定义的可分解性结构，通过软因子化搜索分布和图消息传递来提高离散对象设计的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的分布优化算法无法利用科学应用中属性预测器的可分解性结构，导致在组合设计空间中优化效率低下。

Method: 提出分解感知分布优化（DADO）算法，采用基于连接树的软因子化搜索分布，并结合图消息传递机制协调各关联因子间的优化过程。

Result: DADO能够有效利用属性预测模型中的可分解结构，显著提升在蛋白质设计等离散设计任务中的优化效率。

Conclusion: DADO为AI驱动的科学与工程中的离散对象设计提供了一种更高效的分布优化方法，特别适用于具有可分解性质的复杂系统。

Abstract: In the era of AI-driven science and engineering, we often want to design
discrete objects in silico according to user-specified properties. For example,
we may wish to design a protein to bind its target, arrange components within a
circuit to minimize latency, or find materials with certain properties. Given a
property predictive model, in silico design typically involves training a
generative model over the design space (e.g., protein sequence space) to
concentrate on designs with the desired properties. Distributional optimization
-- which can be formalized as an estimation of distribution algorithm or as
reinforcement learning policy optimization -- finds the generative model that
maximizes an objective function in expectation. Optimizing a distribution over
discrete-valued designs is in general challenging because of the combinatorial
nature of the design space. However, many property predictors in scientific
applications are decomposable in the sense that they can be factorized over
design variables in a way that could in principle enable more effective
optimization. For example, amino acids at a catalytic site of a protein may
only loosely interact with amino acids of the rest of the protein to achieve
maximal catalytic activity. Current distributional optimization algorithms are
unable to make use of such decomposability structure. Herein, we propose and
demonstrate use of a new distributional optimization algorithm,
Decomposition-Aware Distributional Optimization (DADO), that can leverage any
decomposability defined by a junction tree on the design variables, to make
optimization more efficient. At its core, DADO employs a soft-factorized
"search distribution" -- a learned generative model -- for efficient navigation
of the search space, invoking graph message-passing to coordinate optimization
across linked factors.

</details>


### [151] [Data-Efficient Realized Volatility Forecasting with Vision Transformers](https://arxiv.org/abs/2511.03046)
*Emi Soroka,Artem Arzyn*

Main category: cs.LG

TL;DR: 本文探索了使用Vision Transformer (ViT) 架构从单日的隐含波动率曲面预测资产未来30天实现波动率的可行性，初步研究表明ViT能够学习到IV曲面中的季节性模式和非线性特征，显示出在期权数据建模中的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管transformer模型在金融时间序列预测中表现出潜力，但其在期权数据上的应用仍鲜有研究。本文旨在探索将ViT应用于隐含波动率曲面以预测未来波动率的可行性。

Method: 采用通常用于图像识别的Vision Transformer (ViT) 架构，输入包含日期信息的单日隐含波动率曲面，训练模型预测资产未来30天的实现波动率。

Result: 实验表明，ViT能够有效学习隐含波动率曲面中的季节性模式和非线性特征，在预测任务中展现出良好性能。

Conclusion: ViT在处理期权数据特别是隐含波动率曲面方面具有潜力，为基于transformer的金融模型开发提供了新方向。

Abstract: Recent work in financial machine learning has shown the virtue of complexity:
the phenomenon by which deep learning methods capable of learning highly
nonlinear relationships outperform simpler approaches in financial forecasting.
While transformer architectures like Informer have shown promise for financial
time series forecasting, the application of transformer models for options data
remains largely unexplored. We conduct preliminary studies towards the
development of a transformer model for options data by training the Vision
Transformer (ViT) architecture, typically used in modern image recognition and
classification systems, to predict the realized volatility of an asset over the
next 30 days from its implied volatility surface (augmented with date
information) for a single day. We show that the ViT can learn seasonal patterns
and nonlinear features from the IV surface, suggesting a promising direction
for model development.

</details>


### [152] [Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions](https://arxiv.org/abs/2511.03047)
*Emi Soroka,Tanmay Chopra,Krish Desai,Sanjay Lall*

Main category: cs.LG

TL;DR: 提出了一套用于目标驱动交互的无监督评估指标，利用未标记交互数据的统计特性，并使用微调的大语言模型适应分布变化，无需依赖人类生成的理想回复。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型系统在企业应用中难以评估，因数据复杂、标注困难、自定义指标无法发现新类型错误，且LLM裁判结果不可靠。

Method: 设计基于未标记交互数据统计特性的无监督指标，通过微调大语言模型来检测用户目标、衡量目标完成度并量化模型不确定性。

Result: 在开放领域和特定任务的交互数据上验证了方法的有效性，能够有效评估目标驱动的AI-人类交互。

Conclusion: 该无监督评估框架可有效支持大规模、复杂场景下的大语言模型交互评估，减少对人工标注和理想响应的依赖。

Abstract: Large language models (LLMs) have seen increasing popularity in enterprise
applications where AI agents and humans engage in objective-driven
interactions. However, these systems are difficult to evaluate: data may be
complex and unlabeled; human annotation is often impractical at scale; custom
metrics can monitor for specific errors, but not previously-undetected ones;
and LLM judges can produce unreliable results. We introduce the first set of
unsupervised metrics for objective-driven interactions, leveraging statistical
properties of unlabeled interaction data and using fine-tuned LLMs to adapt to
distributional shifts. We develop metrics for labeling user goals, measuring
goal completion, and quantifying LLM uncertainty without grounding evaluations
in human-generated ideal responses. Our approach is validated on open-domain
and task-specific interaction data.

</details>


### [153] [The Curved Spacetime of Transformer Architectures](https://arxiv.org/abs/2511.03060)
*Riccardo Di Sipio,Jairo Diaz-Rodriguez,Luis Serrano*

Main category: cs.LG

TL;DR: 提出了一种将Transformer语言模型与广义相对论类比的几何框架，其中注意力机制被视为在表示空间中实现值向量平行传输的离散连接，实验验证了嵌入轨迹受注意力诱导的曲率影响。


<details>
  <summary>Details</summary>
Motivation: 试图从几何和物理的角度理解Transformer模型中注意力机制的作用机制，特别是token表示在层间演化时的非线性行为。

Method: 将查询和键之间的关系视为表示空间中的有效度量，注意力作为离散连接实现平行传输，通过可视化曲率景观、模拟角度分布和受控上下文编辑下的偏转实验来检验曲率的存在与效应。

Result: 实验证明token嵌入在层间的路径并非直线，其转向角的变化无法由维度或随机性解释，并且上下文修改会导致语义一致的嵌入轨迹弯曲，证实了注意力诱导的曲率存在。

Conclusion: Transformer中的表示空间具有由注意力机制诱导的几何曲率，这一发现为理解深度语言模型提供了新的几何视角。

Abstract: We present a geometric framework for understanding Transformer-based language
models, drawing an explicit analogy to General Relativity. Queries and keys
induce an effective metric on representation space, and attention acts as a
discrete connection that implements parallel transport of value vectors across
tokens. Stacked layers provide discrete time-slices through which token
representations evolve on this curved manifold, while backpropagation plays the
role of a least-action principle that shapes loss-minimizing trajectories in
parameter space. If this analogy is correct, token embeddings should not
traverse straight paths in feature space; instead, their layer-wise steps
should bend and reorient as interactions mediated by embedding space curvature.
To test this prediction, we design experiments that expose both the presence
and the consequences of curvature: (i) we visualize a curvature landscape for a
full paragraph, revealing how local turning angles vary across tokens and
layers; (ii) we show through simulations that excess counts of sharp/flat
angles and longer length-to-chord ratios are not explainable by dimensionality
or chance; and (iii) inspired by Einstein's eclipse experiment, we probe
deflection under controlled context edits, demonstrating measurable,
meaning-consistent bends in embedding trajectories that confirm
attention-induced curvature.

</details>


### [154] [Homomorphism distortion: A metric to distinguish them all and in the latent space bind them](https://arxiv.org/abs/2511.03068)
*Martin Carrasco,Olga Zaghen,Erik Bekkers,Bastian Rieck*

Main category: cs.LG

TL;DR: 本文提出了一种新的图同态失真度量方法，用于衡量顶点带属性图之间的相似性，并证明其能完全表征图结构。通过采样策略有效计算该度量并规避图规范化难题，同时导出相应度量并验证其在BREC和ZINC-12k数据集上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 长期以来图神经网络的表达能力仅通过组合性质衡量，缺乏对带属性图之间相似性的原则性度量方法。

Method: 提出图同态失真作为图相似性度量，结合采样策略高效计算，并从中导出度量标准。

Result: 该度量可完全区分BREC数据集中4-WL无法区分的图，并在ZINC-12k上优于基于同态的先前方法。

Conclusion: 图同态失真是一种完备且可计算的图嵌入方法，为图的表征学习提供了新方向。

Abstract: For far too long, expressivity of graph neural networks has been measured
\emph{only} in terms of combinatorial properties. In this work we stray away
from this tradition and provide a principled way to measure similarity between
vertex attributed graphs. We denote this measure as the \emph{graph
homomorphism distortion}. We show it can \emph{completely characterize} graphs
and thus is also a \emph{complete graph embedding}. However, somewhere along
the road, we run into the graph canonization problem. To circumvent this
obstacle, we devise to efficiently compute this measure via sampling, which in
expectation ensures \emph{completeness}. Additionally, we also discovered that
we can obtain a metric from this measure. We validate our claims empirically
and find that the \emph{graph homomorphism distortion}: (1.) fully
distinguishes the \texttt{BREC} dataset with up to $4$-WL non-distinguishable
graphs, and (2.) \emph{outperforms} previous methods inspired in homomorphisms
under the \texttt{ZINC-12k} dataset.
  These theoretical results, (and their empirical validation), pave the way for
future characterization of graphs, extending the graph theoretic tradition to
new frontiers.

</details>


### [155] [Online Learning to Rank under Corruption: A Robust Cascading Bandits Approach](https://arxiv.org/abs/2511.03074)
*Fatemeh Ghaffari,Siddarth Sitaraman,Xutong Liu,Xuchuang Wang,Mohammad Hajiesmaili*

Main category: cs.LG

TL;DR: 本文提出了一种新的鲁棒在线学习排序算法MSUCB，首次将均值-中位数估计器应用于存在点击欺诈的级联bandit场景。该方法在无污染时具有最优对数遗憾，在有污染时遗憾仅随总污染量线性增加，表现出良好的鲁棒性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有的在线学习排序系统容易受到点击欺诈等恶意行为的影响，导致反馈数据被污染，从而误导学习过程并降低用户体验。因此需要一种能够抵御此类污染的鲁棒算法。

Method: 提出MSUCB算法，采用新颖的均值-中位数（mean-of-medians）估计器来过滤异常值和被污染的样本；该估计器在无污染时表现如标准均值，在有污染时通过中位数步骤抑制异常影响，并在每轮更新以加快收敛。

Result: MSUCB在无污染情况下实现最优对数遗憾，在污染下遗憾仅增加与总污染量相关的加性项；在真实数据集上的实验表明，其性能显著优于现有方法，相对于两种前沿方法的遗憾分别改善了97.35%和91.60%。

Conclusion: MSUCB是一种高效且鲁棒的在线学习排序算法，能够在面对点击欺诈等污染时保持良好性能，同时在正常情况下不牺牲任何效率，具有实际应用价值。

Abstract: Online learning to rank (OLTR) studies how to recommend a short ranked list
of items from a large pool and improves future rankings based on user clicks.
This setting is commonly modeled as cascading bandits, where the objective is
to maximize the likelihood that the user clicks on at least one of the
presented items across as many timesteps as possible. However, such systems are
vulnerable to click fraud and other manipulations (i.e., corruption), where
bots or paid click farms inject corrupted feedback that misleads the learning
process and degrades user experience. In this paper, we propose MSUCB, a robust
algorithm that incorporates a novel mean-of-medians estimator, which to our
knowledge is applied to bandits with corruption setting for the first time.
This estimator behaves like a standard mean in the absence of corruption, so no
cost is paid for robustness. Under corruption, the median step filters out
outliers and corrupted samples, keeping the estimate close to its true value.
Updating this estimate at every round further accelerates empirical convergence
in experiments. Hence, MSUCB achieves optimal logarithmic regret in the absence
of corruption and degrades gracefully under corruptions, with regret increasing
only by an additive term tied to the total corruption. Comprehensive and
extensive experiments on real-world datasets further demonstrate that our
approach consistently outperforms prior methods while maintaining strong
robustness. In particular, it achieves a \(97.35\%\) and a \(91.60\%\) regret
improvement over two state-of-the-art methods.

</details>


### [156] [Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies](https://arxiv.org/abs/2511.03095)
*Gaia Grosso,Sai Sumedh R. Hindupur,Thomas Fel,Samuel Bright-Thonney,Philip Harris,Demba Ba*

Main category: cs.LG

TL;DR: 本文提出了一种基于稀疏、局部性和竞争性原则的自组织局部核方法SparKer，用于在最小先验信息下进行异常检测，能够在高维空间中有效识别异常并具有良好的可解释性和扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法对数据表示的统计特性控制不足，难以发现弱或罕见信号，导致在科学发现等任务中表现不佳。

Method: 提出SparKer模型，采用稀疏高斯核的集成，在半监督Neyman-Pearson框架下训练，通过局部建模样本与正常参考之间的似然比来实现异常检测，并满足稀疏性、局部性和竞争性三个结构要求。

Result: 在多个高维实际问题（如科学发现、开放世界新奇检测、入侵检测和生成模型验证）上验证了方法的有效性，仅用少量核即可在数千维表示空间中定位统计显著的异常区域。

Conclusion: SparKer通过自组织局部核实现了高效、可解释且可扩展的异常检测，适用于跨学科的复杂数据场景。

Abstract: Modern artificial intelligence has revolutionized our ability to extract rich
and versatile data representations across scientific disciplines. Yet, the
statistical properties of these representations remain poorly controlled,
causing misspecified anomaly detection (AD) methods to falter. Weak or rare
signals can remain hidden within the apparent regularity of normal data,
creating a gap in our ability to detect and interpret anomalies. We examine
this gap and identify a set of structural desiderata for detection methods
operating under minimal prior information: sparsity, to enforce parsimony;
locality, to preserve geometric sensitivity; and competition, to promote
efficient allocation of model capacity. These principles define a class of
self-organizing local kernels that adaptively partition the representation
space around regions of statistical imbalance. As an instantiation of these
principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained
within a semi-supervised Neyman--Pearson framework to locally model the
likelihood ratio between a sample that may contain anomalies and a nominal,
anomaly-free reference. We provide theoretical insights into the mechanisms
that drive detection and self-organization in the proposed model, and
demonstrate the effectiveness of this approach on realistic high-dimensional
problems of scientific discovery, open-world novelty detection, intrusion
detection, and generative-model validation. Our applications span both the
natural- and computer-science domains. We demonstrate that ensembles containing
only a handful of kernels can identify statistically significant anomalous
locations within representation spaces of thousands of dimensions, underscoring
both the interpretability, efficiency and scalability of the proposed approach.

</details>


### [157] [An Efficient Classification Model for Cyber Text](https://arxiv.org/abs/2511.03107)
*Md Sakhawat Hossen,Md. Zashid Iqbal Borshon,A. S. M. Badrudduza*

Main category: cs.LG

TL;DR: 本文提出了一种改进的CTF-IDF算法和IRLBA降维方法，结合经典机器学习技术，在文本分析中实现了比深度学习更高效、更快且计算开销更小的效果，同时在准确率上仅有轻微妥协。


<details>
  <summary>Details</summary>
Motivation: 由于深度学习对计算资源和能源的高需求导致碳足迹增加，本文旨在探索更环保、高效的文本分析方法。

Method: 提出Clement Term Frequency-Inverse Document Frequency (CTF-IDF) 用于数据预处理，并结合快速IRLBA算法进行降维，应用于传统的文本分析流程中。

Result: 实验结果表明，所提方法显著降低了时间复杂度，提升了模型准确性，且计算资源消耗远低于深度学习方法。

Conclusion: 经典机器学习方法结合CTF-IDF和IRLBA可在文本分析中实现高效、低能耗的性能表现，为减少AI碳足迹提供了可行路径。

Abstract: The uprising of deep learning methodology and practice in recent years has
brought about a severe consequence of increasing carbon footprint due to the
insatiable demand for computational resources and power. The field of text
analytics also experienced a massive transformation in this trend of
monopolizing methodology. In this paper, the original TF-IDF algorithm has been
modified, and Clement Term Frequency-Inverse Document Frequency (CTF-IDF) has
been proposed for data preprocessing. This paper primarily discusses the
effectiveness of classical machine learning techniques in text analytics with
CTF-IDF and a faster IRLBA algorithm for dimensionality reduction. The
introduction of both of these techniques in the conventional text analytics
pipeline ensures a more efficient, faster, and less computationally intensive
application when compared with deep learning methodology regarding carbon
footprint, with minor compromise in accuracy. The experimental results also
exhibit a manifold of reduction in time complexity and improvement of model
accuracy for the classical machine learning methods discussed further in this
paper.

</details>


### [158] [Towards Scalable Backpropagation-Free Gradient Estimation](https://arxiv.org/abs/2511.03110)
*Daniel Wang,Evan Markou,Dylan Campbell*

Main category: cs.LG

TL;DR: 提出一种新的梯度估计方法，通过操纵上游雅可比矩阵降低估计的偏差和方差，相比现有前向模式自动微分方法更具扩展性。


<details>
  <summary>Details</summary>
Motivation: 反向传播需要存储中间激活并进行前后两次传递，而现有前向模式梯度估计方法存在高方差或高偏差问题，限制了其在大型网络中的应用。

Method: 通过在计算猜测方向时操纵上游雅可比矩阵，降低梯度估计的偏差和方差，并利用神经网络梯度的低维结构特性进行优化。

Result: 新方法在减少偏差和方差方面表现良好，且随着网络宽度增加性能提升，显示出向更大网络扩展的潜力。

Conclusion: 该梯度估计方法有效平衡了偏差与方差，为替代传统反向传播提供了可行路径，尤其适用于宽神经网络。

Abstract: While backpropagation--reverse-mode automatic differentiation--has been
extraordinarily successful in deep learning, it requires two passes (forward
and backward) through the neural network and the storage of intermediate
activations. Existing gradient estimation methods that instead use forward-mode
automatic differentiation struggle to scale beyond small networks due to the
high variance of the estimates. Efforts to mitigate this have so far introduced
significant bias to the estimates, reducing their utility. We introduce a
gradient estimation approach that reduces both bias and variance by
manipulating upstream Jacobian matrices when computing guess directions. It
shows promising results and has the potential to scale to larger networks,
indeed performing better as the network width is increased. Our understanding
of this method is facilitated by analyses of bias and variance, and their
connection to the low-dimensional structure of neural network gradients.

</details>


### [159] [FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation](https://arxiv.org/abs/2511.03113)
*Jiameng Chen,Yida Xiong,Kun Li,Hongzhi Zhang,Xiantao Cai,Wenbin Hu,Jia Wu*

Main category: cs.LG

TL;DR: FP-AbDiff是首个在生成轨迹上强制执行Fokker-Planck方程物理规律的抗体生成模型，通过引入FPE残差损失，在R^3 x SO(3)混合流形上优化CDR几何结构，结合SE(3)等变扩散框架与生物先验，显著提升抗体设计的几何精度与氨基酸恢复率，刷新了RAbD基准的性能记录。


<details>
  <summary>Details</summary>
Motivation: 现有抗体生成模型存在动力学不一致和泛化能力差两大问题，导致生成结构物理上不合理且受限于数据稀缺与结构偏差，亟需一种遵循物理规律、更具鲁棒性和泛化性的方法。

Method: 提出FP-AbDiff，引入基于Fokker-Planck方程的残差损失，在Cα-Cβ骨架建模的R^3 × SO(3)混合流形上进行SE(3)等变扩散生成，通过物理规律正则化引导局部去噪得分形成全局一致的概率流，并融合深度生物学先验。

Result: 在RAbD基准上达到新SOTA：在从头CDR-H3设计中，可变区RMSD为0.99Å（比AbX提升25%），接触氨基酸恢复率为39.91%；在六条CDR共设计任务中，全链RMSD降低约15%，CDR-H3环的全链氨基酸恢复率达到最高的45.67%。

Conclusion: 通过将生成动力学与物理定律对齐，FP-AbDiff提升了抗体生成模型的物理合理性、鲁棒性与功能可行性，为抗体设计提供了一种原理性更强、更可靠的新范式。

Abstract: Computational antibody design holds immense promise for therapeutic
discovery, yet existing generative models are fundamentally limited by two core
challenges: (i) a lack of dynamical consistency, which yields physically
implausible structures, and (ii) poor generalization due to data scarcity and
structural bias. We introduce FP-AbDiff, the first antibody generator to
enforce Fokker-Planck Equation (FPE) physics along the entire generative
trajectory. Our method minimizes a novel FPE residual loss over the mixed
manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising
scores to assemble into a globally coherent probability flow. This
physics-informed regularizer is synergistically integrated with deep biological
priors within a state-of-the-art SE(3)-equivariant diffusion framework.
Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a
new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean
Square Deviation of 0.99 {\AA} when superposing on the variable region, a 25%
improvement over the previous state-of-the-art model, AbX, and the highest
reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored
in the more challenging six-CDR co-design task, where our model delivers
consistently superior geometric precision, cutting the average full-chain Root
Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain
Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By
aligning generative dynamics with physical laws, FP-AbDiff enhances robustness
and generalizability, establishing a principled approach for physically
faithful and functionally viable antibody design.

</details>


### [160] [Periodic Skill Discovery](https://arxiv.org/abs/2511.03187)
*Jonghae Park,Daesol Cho,Jusuk Lee,Dongseok Shim,Inkyu Jang,H. Jin Kim*

Main category: cs.LG

TL;DR: 本文提出了Periodic Skill Discovery (PSD) 框架，用于在无监督强化学习中发现周期性技能，通过将状态映射到圆形潜在空间来自然编码周期性，有效学习复杂机器人任务中的多样化周期行为。


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法通常忽略技能的周期性，而许多机器人任务（如运动）需要跨不同时间尺度的周期行为，因此有必要发现多样化的周期性技能。

Method: 提出PSD框架，训练一个编码器将状态映射到圆形潜在空间，利用循环结构对周期性进行建模，并通过最大化时间距离来学习不同周期的技能。

Result: PSD在复杂机器人任务中成功发现了具有不同周期的技能，在跨栏等下游任务中表现出高性能；结合现有技能发现方法可进一步提升行为多样性。

Conclusion: PSD为无监督技能发现提供了有效途径，特别适用于需要周期性行为的机器人控制任务，增强了智能体的行为库和适应能力。

Abstract: Unsupervised skill discovery in reinforcement learning (RL) aims to learn
diverse behaviors without relying on external rewards. However, current methods
often overlook the periodic nature of learned skills, focusing instead on
increasing the mutual dependence between states and skills or maximizing the
distance traveled in latent space. Considering that many robotic tasks --
particularly those involving locomotion -- require periodic behaviors across
varying timescales, the ability to discover diverse periodic skills is
essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a
framework that discovers periodic behaviors in an unsupervised manner. The key
idea of PSD is to train an encoder that maps states to a circular latent space,
thereby naturally encoding periodicity in the latent representation. By
capturing temporal distance, PSD can effectively learn skills with diverse
periods in complex robotic tasks, even with pixel-based observations. We
further show that these learned skills achieve high performance on downstream
tasks such as hurdling. Moreover, integrating PSD with an existing skill
discovery method offers more diverse behaviors, thus broadening the agent's
repertoire. Our code and demos are available at
https://jonghaepark.github.io/psd/

</details>


### [161] [An Augmentation Overlap Theory of Contrastive Learning](https://arxiv.org/abs/2511.03114)
*Qi Zhang,Yifei Wang,Yisen Wang*

Main category: cs.LG

TL;DR: 本文在对比学习的条件下独立性假设基础上提供了最紧的界限，并提出了更实际的增强重叠假设，推导出下游性能的渐近闭合界限，同时提出了一种无需额外模块即可评估表示质量的无监督度量方法。


<details>
  <summary>Details</summary>
Motivation: 对比学习虽然在各种任务中取得了成功，但其内在工作机制尚不清楚，因此需要更深入的理论分析来解释其有效性。

Method: 通过放松条件独立性假设为增强重叠假设，利用增强数据中同类样本支持集的重叠特性，推导出对比学习在下游任务中的性能界限，并提出一种新的无监督评估指标。

Result: 提出了增强重叠理论，推导了渐近闭合的性能界限，并设计了一种与下游性能高度一致的无监督表示评估度量。

Conclusion: 增强重叠假设比传统条件独立性假设更贴近实际，能够更好地解释对比学习的工作机制，并提供有效的无监督评估手段。

Abstract: Recently, self-supervised contrastive learning has achieved great success on
various tasks. However, its underlying working mechanism is yet unclear. In
this paper, we first provide the tightest bounds based on the widely adopted
assumption of conditional independence. Further, we relax the conditional
independence assumption to a more practical assumption of augmentation overlap
and derive the asymptotically closed bounds for the downstream performance. Our
proposed augmentation overlap theory hinges on the insight that the support of
different intra-class samples will become more overlapped under aggressive data
augmentations, thus simply aligning the positive samples (augmented views of
the same sample) could make contrastive learning cluster intra-class samples
together. Moreover, from the newly derived augmentation overlap perspective, we
develop an unsupervised metric for the representation evaluation of contrastive
learning, which aligns well with the downstream performance almost without
relying on additional modules. Code is available at
https://github.com/PKU-ML/GARC.

</details>


### [162] [From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](https://arxiv.org/abs/2511.03128)
*Najrin Sultana,Md Rafi Ur Rashid,Kang Gu,Shagufta Mehnaz*

Main category: cs.LG

TL;DR: 提出两种创新的攻击框架Static Deceptor和Dynamic Deceptor，利用大语言模型自身理解生成自然且语义保持的对抗样本，评估其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在敏感任务中应用大语言模型时，需系统评估其对对抗输入的鲁棒性。

Method: 构建基于LLM驱动的自动化攻击框架StaDec和DyDec，动态生成语义相似但可欺骗目标模型的对抗样本。

Result: 生成的对抗样本具有高隐蔽性和跨模型迁移能力，能有效欺骗未知目标模型。

Conclusion: 该方法为大语言模型提供了可自我评估鲁棒性的系统性方案，并具备适应模型演进的能力。

Abstract: LLMs can provide substantial zero-shot performance on diverse tasks using a
simple task prompt, eliminating the need for training or fine-tuning. However,
when applying these models to sensitive tasks, it is crucial to thoroughly
assess their robustness against adversarial inputs. In this work, we introduce
Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack
frameworks designed to systematically generate dynamic and adaptive adversarial
examples by leveraging the understanding of the LLMs. We produce subtle and
natural-looking adversarial inputs that preserve semantic similarity to the
original text while effectively deceiving the target LLM. By utilizing an
automated, LLM-driven pipeline, we eliminate the dependence on external
heuristics. Our attacks evolve with the advancements in LLMs and demonstrate
strong transferability across models unknown to the attacker. Overall, this
work provides a systematic approach for the self-assessment of an LLM's
robustness. We release our code and data at
https://github.com/Shukti042/AdversarialExample.

</details>


### [163] [Test Time Adaptation Using Adaptive Quantile Recalibration](https://arxiv.org/abs/2511.03148)
*Paria Mehrbod,Pedro Vianna,Geraldin Nanfack,Guy Wolf,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 本文提出了一种名为自适应分位数重校准（AQR）的测试时适应技术，通过通道级分位数对齐来调整预激活分布，提升深度学习模型在动态真实场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有域适应方法通常依赖目标域先验知识或需重新训练模型，且主流测试时适应方法难以捕捉复杂的激活分布，限制了其在资源受限或动态环境中的实用性。

Method: AQR通过在测试时对预激活分布进行通道级分位数对齐来实现无监督适应，并引入鲁棒尾部校准策略以应对不同批量大小下的分布尾部估计问题，兼容BatchNorm、GroupNorm和LayerNorm等多种架构。

Result: 在CIFAR-10-C、CIFAR-100-C和ImageNet-C等多个基准和架构上的实验表明，AQR在多种设置下均实现了优于现有测试时适应方法的鲁棒性能。

Conclusion: AQR能够有效提升模型在分布偏移下的适应能力，具有良好的通用性和稳定性，适用于数据分布动态变化的真实应用场景。

Abstract: Domain adaptation is a key strategy for enhancing the generalizability of
deep learning models in real-world scenarios, where test distributions often
diverge significantly from the training domain. However, conventional
approaches typically rely on prior knowledge of the target domain or require
model retraining, limiting their practicality in dynamic or
resource-constrained environments. Recent test-time adaptation methods based on
batch normalization statistic updates allow for unsupervised adaptation, but
they often fail to capture complex activation distributions and are constrained
to specific normalization layers. We propose Adaptive Quantile Recalibration
(AQR), a test-time adaptation technique that modifies pre-activation
distributions by aligning quantiles on a channel-wise basis. AQR captures the
full shape of activation distributions and generalizes across architectures
employing BatchNorm, GroupNorm, or LayerNorm. To address the challenge of
estimating distribution tails under varying batch sizes, AQR incorporates a
robust tail calibration strategy that improves stability and precision. Our
method leverages source-domain statistics computed at training time, enabling
unsupervised adaptation without retraining models. Experiments on CIFAR-10-C,
CIFAR-100-C, and ImageNet-C across multiple architectures demonstrate that AQR
achieves robust adaptation across diverse settings, outperforming existing
test-time adaptation baselines. These results highlight AQR's potential for
deployment in real-world scenarios with dynamic and unpredictable data
distributions.

</details>


### [164] [Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction](https://arxiv.org/abs/2511.03149)
*Atif Hassan,Tarun Kumar,Ashish Mishra,Sergey Serebryakov,Satish Kumar Mopur,Phanidhar Koganti,Murthy Chelankuri,Ramanagopal Vogety,Suparna Bhattacharya,Martin Foltin*

Main category: cs.LG

TL;DR: 提出了一种名为Forecast2Anomaly (F2A) 的新框架，利用时间序列基础模型（TSFM）实现零样本异常预测，通过联合预测-异常损失和检索增强生成模块，显著提升了在多种真实场景下的异常预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有异常预测方法局限于特定系统，难以泛化到随时间演变的异常模式；而尽管时间序列基础模型（TSFM）在零样本预测中表现良好，但其在异常预测任务中的潜力尚未被开发。

Method: 提出F2A框架，包含两个关键创新：一是采用联合预测-异常损失函数对TSFM进行微调，使其能在异常时间点仍准确预测未来信号；二是引入检索增强生成（RAG）模块，检索历史相关时间段并基于其条件化预测，从而在推理时动态适应分布变化。

Result: 在16个多样化数据集和多个TSFM骨干网络上的实验表明，F2A consistently优于现有最先进方法，展现出卓越的零样本异常预测能力。

Conclusion: F2A成功弥合了TSFM在正常行为预测与异常预测之间的差距，提供了一个可扩展、无需模型更新即可应对演化异常的零样本异常预测解决方案。

Abstract: Forecasting anomalies (anomaly prediction) in multivariate time series from
different real-world, dynamic, and complex systems is vital for preempting
critical failures, leading to a substantial minimization in operational costs
and human labor. Yet, existing methods are limited to specific systems while
failing to generalize to evolving anomaly patterns over time. In contrast,
pretrained Time Series Foundation Models (TSFMs) have recently demonstrated
strong generalization and zero-shot forecasting capabilities. However, their
potential remains untapped for anomaly prediction, a task fundamentally
different from forecasting normal behavior. Thus, we present Forecast2Anomaly
(F2A), a novel framework that empowers TSFMs with anomaly prediction abilities
through two key innovations. First, we propose a joint forecast-anomaly loss
that fine-tunes TSFMs to accurately forecast future signals even at anomalous
time points. Second, we introduce a Retrieval-Augmented Generation (RAG) module
that retrieves historically relevant horizons and conditions predictions on
them. This component dynamically adapts to distributional shifts at inference
time, enabling F2A to track evolving anomalies without requiring model updates.
By combining targeted fine-tuning with dynamic retrieval, F2A bridges the gap
between robust TSFM zero-shot forecasting and zero-shot anomaly prediction.
Extensive experiments across 16 diverse datasets and multiple TSFM backbones
show that F2A consistently outperforms state-of-the-art methods, offering a
scalable, zero-shot anomaly prediction solution for real-world applications.

</details>


### [165] [UnCLe: Towards Scalable Dynamic Causal Discovery in Non-linear Temporal Systems](https://arxiv.org/abs/2511.03168)
*Tingzhu Bi,Yicheng Pan,Xinrui Jiang,Huize Sun,Meng Ma,Ping Wang*

Main category: cs.LG

TL;DR: 提出了一种名为UnCLe的深度学习方法，用于可扩展的动态因果发现，能有效捕捉和表示时间演化中的因果关系。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统常表现出随时间变化的动态因果性，而现有方法多局限于静态因果图，难以准确刻画这种时变依赖关系。

Method: 采用一对解耦器（Uncoupler）和重耦器（Recoupler）网络将输入时间序列分解为语义表征，并通过自回归的依赖矩阵建模变量间动态关系，利用时间扰动引起的逐点预测误差估计动态因果影响。

Result: 在静态因果发现基准上优于现有方法，并在合成与真实动态系统（如人体运动）中展现出精确捕捉时变因果关系的能力。

Conclusion: UnCLe为理解复杂系统的时变机制提供了一个有效的工具，具有揭示动态因果结构的潜力。

Abstract: Uncovering cause-effect relationships from observational time series is
fundamental to understanding complex systems. While many methods infer static
causal graphs, real-world systems often exhibit dynamic causality-where
relationships evolve over time. Accurately capturing these temporal dynamics
requires time-resolved causal graphs. We propose UnCLe, a novel deep learning
method for scalable dynamic causal discovery. UnCLe employs a pair of Uncoupler
and Recoupler networks to disentangle input time series into semantic
representations and learns inter-variable dependencies via auto-regressive
Dependency Matrices. It estimates dynamic causal influences by analyzing
datapoint-wise prediction errors induced by temporal perturbations. Extensive
experiments demonstrate that UnCLe not only outperforms state-of-the-art
baselines on static causal discovery benchmarks but, more importantly, exhibits
a unique capability to accurately capture and represent evolving temporal
causality in both synthetic and real-world dynamic systems (e.g., human
motion). UnCLe offers a promising approach for revealing the underlying,
time-varying mechanisms of complex phenomena.

</details>


### [166] [Efficient Linear Attention for Multivariate Time Series Modeling via Entropy Equality](https://arxiv.org/abs/2511.03190)
*Mingtao Zhang,Guoli Yang,Zhanxing Zhu,Mengzhu Wang,Xiaoying Bai*

Main category: cs.LG

TL;DR: 提出一种基于熵相等的线性注意力机制，通过线性复杂度的熵近似算法，有效降低计算开销，同时在时空时间序列预测中保持竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的注意力机制由于二次计算复杂度难以扩展到长序列，限制了其在时间序列建模中的可扩展性。

Method: 利用熵作为概率单纯形上的严格凹函数的性质，提出一种基于概率分布排序对齐和熵值相似性的线性注意力机制，并设计线性复杂度的熵近似算法。

Result: 在四个时空数据集上验证了方法的有效性，相比传统注意力机制显著降低了内存和计算时间，同时取得了相当或更优的预测性能。

Conclusion: 注意力机制在时空建模中的有效性可能主要源于权重分布的适度与平衡，而非softmax的非线性本身；所提线性注意力机制在效率和性能之间实现了更好权衡。

Abstract: Attention mechanisms have been extensively employed in various applications,
including time series modeling, owing to their capacity to capture intricate
dependencies; however, their utility is often constrained by quadratic
computational complexity, which impedes scalability for long sequences. In this
work, we propose a novel linear attention mechanism designed to overcome these
limitations. Our approach is grounded in a theoretical demonstration that
entropy, as a strictly concave function on the probability simplex, implies
that distributions with aligned probability rankings and similar entropy values
exhibit structural resemblance. Building on this insight, we develop an
efficient approximation algorithm that computes the entropy of
dot-product-derived distributions with only linear complexity, enabling the
implementation of a linear attention mechanism based on entropy equality.
Through rigorous analysis, we reveal that the effectiveness of attention in
spatio-temporal time series modeling may not primarily stem from the
non-linearity of softmax but rather from the attainment of a moderate and
well-balanced weight distribution. Extensive experiments on four
spatio-temporal datasets validate our method, demonstrating competitive or
superior forecasting performance while achieving substantial reductions in both
memory usage and computational time.

</details>


### [167] [Cross-Modal Alignment via Variational Copula Modelling](https://arxiv.org/abs/2511.03196)
*Feng Wu,Tsai Hor Chan,Fuying Wang,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 提出了一种基于Copula的多模态学习框架，用于建模不同模态间的复杂交互，通过联合分布与边缘分布的关系提升多模态表示学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态融合中过于简化模态间交互结构，缺乏对高阶交互联合分布的有效建模，需要更强大的统计工具来捕捉复杂依赖关系。

Method: 引入Copula模型作为对齐各模态边缘分布的工具，假设每个模态服从高斯混合分布，并在联合分布上构建Copula模型，从而有效建模多模态间的复杂依赖并生成缺失模态的准确表示。

Result: 在MIMIC公共数据集上的实验表明，该方法在多模态学习任务中优于现有竞争方法。

Conclusion: Copula驱动的多模态学习框架能有效捕捉模态间的复杂交互，在联合分布建模和缺失模态补全方面表现出优越性能。

Abstract: Various data modalities are common in real-world applications (e.g.,
electronic health records, medical images and clinical notes in healthcare). It
is essential to develop multimodal learning methods to aggregate various
information from multiple modalities. The main challenge is how to
appropriately align and fuse the representations of different modalities into a
joint distribution. Existing methods mainly rely on concatenation or the
Kronecker product, oversimplifying the interaction structure between modalities
and indicating a need to model more complex interactions. Additionally, the
joint distribution of latent representations with higher-order interactions is
underexplored. Copula is a powerful statistical structure for modelling the
interactions among variables, as it naturally bridges the joint distribution
and marginal distributions of multiple variables. We propose a novel
copula-driven multimodal learning framework, which focuses on learning the
joint distribution of various modalities to capture the complex interactions
among them. The key idea is to interpret the copula model as a tool to align
the marginal distributions of the modalities efficiently. By assuming a
Gaussian mixture distribution for each modality and a copula model on the joint
distribution, our model can generate accurate representations for missing
modalities. Extensive experiments on public MIMIC datasets demonstrate the
superior performance of our model over other competitors. The code is available
at https://github.com/HKU-MedAI/CMCM.

</details>


### [168] [A Probabilistic U-Net Approach to Downscaling Climate Simulations](https://arxiv.org/abs/2511.03197)
*Maryam Alipourhajiagha,Pierre-Louis Lemaire,Youssef Diouane,Julie Carreau*

Main category: cs.LG

TL;DR: 本文提出了一种基于概率U-Net的统计降尺度方法，用于将气候模型的粗分辨率输出转换为更精细的尺度，以满足气候变化影响研究的需求。


<details>
  <summary>Details</summary>
Motivation: 气候模型因计算成本高通常只能提供粗空间分辨率的输出，而许多气候影响研究需要更高精度的数据，因此需要有效的降尺度方法来弥补这一差距。

Method: 采用结合确定性U-Net主干和变分潜在空间的概率U-Net进行统计降尺度，并评估了四种训练目标（afCRPS和WMSE-MS-SSIM）在降水和温度降尺度中的表现。

Result: 实验表明，在特定设置下，WMSE-MS-SSIM在极端事件的降尺度中表现良好，而afCRPS能更好地捕捉跨尺度的空间变异性。

Conclusion: 所提出的概率U-Net框架能够有效进行气候数据的统计降尺度，不同训练目标适用于不同的应用需求，为气候变量的精细化预测提供了灵活且有效的工具。

Abstract: Climate models are limited by heavy computational costs, often producing
outputs at coarse spatial resolutions, while many climate change impact studies
require finer scales. Statistical downscaling bridges this gap, and we adapt
the probabilistic U-Net for this task, combining a deterministic U-Net backbone
with a variational latent space to capture aleatoric uncertainty. We evaluate
four training objectives, afCRPS and WMSE-MS-SSIM with three settings for
downscaling precipitation and temperature from $16\times$ coarser resolution.
Our main finding is that WMSE-MS-SSIM performs well for extremes under certain
settings, whereas afCRPS better captures spatial variability across scales.

</details>


### [169] [A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies](https://arxiv.org/abs/2511.03201)
*Hassan Wasswa,Hussein Abbass,Timothy Lynar*

Main category: cs.LG

TL;DR: 提出了一种基于VAE-MLP的轻量级物联网僵尸网络检测框架，并系统评估了量化对模型性能的影响，结果表明PTQ在精度、速度和压缩率之间取得了更好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法虽然检测精度高，但计算开销大，难以部署在资源受限的IoT设备上，亟需轻量化的检测模型。

Method: 采用预训练变分自编码器（VAE）提取高维数据的8维潜在特征，使用MLP进行分类，并对比评估了QAT和PTQ两种量化策略在N-BaIoT和CICIoT2022数据集上的表现。

Result: PTQ相比原始模型仅造成轻微精度下降，实现6倍推理加速和21倍模型压缩；QAT精度下降更明显，虽压缩率达24倍但速度提升仅为3倍。

Conclusion: 量化能有效提升模型在资源受限设备上的部署可行性，其中PTQ在整体性能权衡上优于QAT，更适合轻量级IoT僵尸网络检测。

Abstract: In an effort to counter the increasing IoT botnet-based attacks,
state-of-the-art deep learning methods have been proposed and have achieved
impressive detection accuracy. However, their computational intensity restricts
deployment on resource-constrained IoT devices, creating a critical need for
lightweight detection models. A common solution to this challenge is model
compression via quantization. This study proposes a VAE-MLP model framework
where an MLP-based classifier is trained on 8-dimensional latent vectors
derived from the high-dimensional train data using the encoder component of a
pretrained variational autoencoder (VAE). Two widely used quantization
strategies--Quantization-Aware Training (QAT) and Post-Training Quantization
(PTQ)--are then systematically evaluated in terms of their impact on detection
performance, storage efficiency, and inference latency using two benchmark IoT
botnet datasets--N-BaIoT and CICIoT2022. The results revealed that, with
respect to detection accuracy, the QAT strategy experienced a more noticeable
decline,whereas PTQ incurred only a marginal reduction compared to the original
unquantized model. Furthermore, PTQ yielded a 6x speedup and 21x reduction in
size, while QAT achieved a 3x speedup and 24x compression, demonstrating the
practicality of quantization for device-level IoT botnet detection.

</details>


### [170] [Incorporating Quality of Life in Climate Adaptation Planning via Reinforcement Learning](https://arxiv.org/abs/2511.03238)
*Miguel Costa,Arthur Vandervoort,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 本研究利用强化学习（RL）结合综合评估模型（IAM），探索应对城市洪涝的气候适应路径，以提升长期城市生活质量（QoL）。


<details>
  <summary>Details</summary>
Motivation: 城市洪涝因气候变化日益严重，影响城市生活质量，且具有高度不确定性与复杂性，亟需有效的适应策略。

Method: 采用强化学习方法，结合包含降雨预测、洪水模拟、交通可达性和生活质量指数的综合评估模型（IAM），识别最优适应路径。

Result: 初步结果表明，该方法能有效学习最优适应措施，并优于其他现实和实际规划策略。

Conclusion: 强化学习与综合评估模型的结合为制定长期、动态的城市气候适应策略提供了有前景的工具。

Abstract: Urban flooding is expected to increase in frequency and severity as a
consequence of climate change, causing wide-ranging impacts that include a
decrease in urban Quality of Life (QoL). Meanwhile, policymakers must devise
adaptation strategies that can cope with the uncertain nature of climate change
and the complex and dynamic nature of urban flooding. Reinforcement Learning
(RL) holds significant promise in tackling such complex, dynamic, and uncertain
problems. Because of this, we use RL to identify which climate adaptation
pathways lead to a higher QoL in the long term. We do this using an Integrated
Assessment Model (IAM) which combines a rainfall projection model, a flood
model, a transport accessibility model, and a quality of life index. Our
preliminary results suggest that this approach can be used to learn optimal
adaptation measures and it outperforms other realistic and real-world planning
strategies. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.

</details>


### [171] [A Feedback-Control Framework for Efficient Dataset Collection from In-Vehicle Data Streams](https://arxiv.org/abs/2511.03239)
*Philipp Reis,Philipp Rigoll,Christian Steinhauser,Jacob Langner,Eric Sax*

Main category: cs.LG

TL;DR: 本文提出了FCDC（反馈控制数据收集）范式，将数据收集建模为闭环控制问题，通过在线概率模型和反馈信号动态调节样本保留，提升数据集多样性和平衡性，减少存储开销。


<details>
  <summary>Details</summary>
Motivation: 传统数据收集采用开环方式，易积累冗余样本，导致存储浪费、标注成本高且泛化能力受限，缺乏基于当前数据覆盖情况的反馈机制。

Method: 提出FCDC框架，使用在线概率模型持续估计数据分布状态，并基于似然和马氏距离等反馈信号自适应调控样本保留，实现探索与利用的动态平衡。

Result: 在合成和真实数据流上的实验表明，FCDC相比传统方法提升数据集平衡性25.9%，减少39.8%的数据存储。

Conclusion: 数据收集可被主动控制，FCDC将数据收集从被动流程转变为自我调节、反馈驱动的核心环节，推动数据-centric AI的发展。

Abstract: Modern AI systems are increasingly constrained not by model capacity but by
the quality and diversity of their data. Despite growing emphasis on
data-centric AI, most datasets are still gathered in an open-loop manner which
accumulates redundant samples without feedback from the current coverage. This
results in inefficient storage, costly labeling, and limited generalization. To
address this, this paper introduces \ac{FCDC}, a paradigm that formulates data
collection as a closed-loop control problem. \ac{FCDC} continuously
approximates the state of the collected data distribution using an online
probabilistic model and adaptively regulates sample retention using based on
feedback signals such as likelihood and Mahalanobis distance. Through this
feedback mechanism, the system dynamically balances exploration and
exploitation, maintains dataset diversity, and prevents redundancy from
accumulating over time. Besides showcasing the controllability of \ac{FCDC} on
a synthetic dataset, experiments on a real data stream show that \ac{FCDC}
produces more balanced datasets by $\SI{25.9}{\percent}$ while reducing data
storage by $\SI{39.8}{\percent}$. These results demonstrate that data
collection itself can be actively controlled, transforming collection from a
passive pipeline stage into a self-regulating, feedback-driven process at the
core of data-centric AI.

</details>


### [172] [A unified physics-informed generative operator framework for general inverse problems](https://arxiv.org/abs/2511.03241)
*Gang Bao,Yaohua Zang*

Main category: cs.LG

TL;DR: 本文提出了一种名为IGNO的新型生成式神经算子框架，用于解决由偏微分方程（PDE）控制的逆问题，无需依赖标注数据，仅通过物理约束进行训练，在噪声严重的情况下仍能实现准确、稳定且可扩展的反演。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在处理稀疏、噪声测量或高维不连续系数时存在局限性，且通常需要大量标注数据或局限于特定类型的测量，限制了其实际应用。因此，需要一种更通用、鲁棒的方法来解决复杂逆问题。

Method: IGNO框架将高维可能不连续的系数场编码到低维潜在空间，并利用神经算子解码器重建系数和PDE解；训练过程仅依赖PDE残差等物理约束，反演通过潜在空间中的梯度优化完成，并借助先验归一化流模型加速。

Result: 在多个具有挑战性的逆问题上（如不连续系数恢复和基于算子测量的EIT问题），IGNO在不同噪声水平下均优于现有最先进方法，表现出良好的稳定性、可扩展性和对分布外目标的强泛化能力。

Conclusion: IGNO是一种统一而强大的框架，能够有效应对计算科学中各类复杂逆问题，具有广泛的应用前景。

Abstract: Solving inverse problems governed by partial differential equations (PDEs) is
central to science and engineering, yet remains challenging when measurements
are sparse, noisy, or when the underlying coefficients are high-dimensional or
discontinuous. Existing deep learning approaches either require extensive
labeled datasets or are limited to specific measurement types, often leading to
failure in such regimes and restricting their practical applicability. Here, a
novel generative neural operator framework, IGNO, is introduced to overcome
these limitations. IGNO unifies the solution of inverse problems from both
point measurements and operator-valued data without labeled training pairs.
This framework encodes high-dimensional, potentially discontinuous coefficient
fields into a low-dimensional latent space, which drives neural operator
decoders to reconstruct both coefficients and PDE solutions. Training relies
purely on physics constraints through PDE residuals, while inversion proceeds
via efficient gradient-based optimization in latent space, accelerated by an a
priori normalizing flow model. Across a diverse set of challenging inverse
problems, including recovery of discontinuous coefficients from solution-based
measurements and the EIT problem with operator-based measurements, IGNO
consistently achieves accurate, stable, and scalable inversion even under
severe noise. It consistently outperforms the state-of-the-art method under
varying noise levels and demonstrates strong generalization to
out-of-distribution targets. These results establish IGNO as a unified and
powerful framework for tackling challenging inverse problems across
computational science domains.

</details>


### [173] [Climate Adaptation with Reinforcement Learning: Economic vs. Quality of Life Adaptation Pathways](https://arxiv.org/abs/2511.03243)
*Miguel Costa,Arthur Vandervoort,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

TL;DR: 提出使用强化学习（RL）结合综合评估模型（IAM）来识别不确定气候条件下的适应路径，并显式建模不同适应优先级（如经济 vs. 福祉）的影响，结果表明优先考虑生活质量（QoL）会导致更高的且更均衡的适应支出。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧洪水风险，制定有效适应政策需应对长期气候影响的不确定性，同时揭示政策中隐含的规范性选择。

Method: 采用强化学习（RL）与集成评估模型（IAM）结合，整合降雨-洪水模型，并以生活质量、交通和基础设施损害量化洪灾影响，比较不同适应目标下的政策路径。

Result: 优先考虑生活质量（QoL）的模型比侧重经济影响的模型导致更多且空间上更均衡的适应支出，显示规范性假设对政策设计的重大影响。

Conclusion: 强化学习有助于在不确定性下识别适应路径，并显式比较不同价值取向的适应策略，提升气候适应政策的透明度与包容性。

Abstract: Climate change will cause an increase in the frequency and severity of flood
events, prompting the need for cohesive adaptation policymaking. Designing
effective adaptation policies, however, depends on managing the uncertainty of
long-term climate impacts. Meanwhile, such policies can feature important
normative choices that are not always made explicit. We propose that
Reinforcement Learning (RL) can be a useful tool to both identify adaptation
pathways under uncertain conditions while it also allows for the explicit
modelling (and consequent comparison) of different adaptation priorities (e.g.
economic vs. wellbeing). We use an Integrated Assessment Model (IAM) to link
together a rainfall and flood model, and compute the impacts of flooding in
terms of quality of life (QoL), transportation, and infrastructure damage. Our
results show that models prioritising QoL over economic impacts results in more
adaptation spending as well as a more even distribution of spending over the
study area, highlighting the extent to which such normative assumptions can
alter adaptation policy. Our framework is publicly available:
https://github.com/MLSM-at-DTU/maat_qol_framework.

</details>


### [174] [GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models](https://arxiv.org/abs/2511.03251)
*Zhibin Wang,Zhixing Zhang,Shuqi Wang,Xuanting Xie,Zhao Kang*

Main category: cs.LG

TL;DR: 提出GMoPE框架，结合MoE架构与基于提示的图学习，提升图神经网络在多任务和多领域下的泛化能力，同时降低适应成本。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络在跨任务和跨领域泛化时存在负迁移、可扩展性差和适应成本高的问题，限制了其广泛应用。

Method: 提出GMoPE框架，融合Mixture-of-Experts（MoE）架构与提示学习，通过专家特定的提示向量和结构感知的MoE路由机制实现专家专业化；引入软正交约束促进提示向量多样性，并采用仅提示微调策略降低时空复杂度。

Result: 在多种预训练策略和下游任务上实验表明，GMoPE持续优于最先进的基线方法，性能接近全参数微调，但适应开销显著降低。

Conclusion: GMoPE为构建可泛化、高效的图基础模型提供了一种原理清晰且可扩展的框架。

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive performance on
task-specific benchmarks, yet their ability to generalize across diverse
domains and tasks remains limited. Existing approaches often struggle with
negative transfer, scalability issues, and high adaptation costs. To address
these challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel
framework that seamlessly integrates the Mixture-of-Experts (MoE) architecture
with prompt-based learning for graphs. GMoPE leverages expert-specific prompt
vectors and structure-aware MoE routing to enable each expert to specialize in
distinct subdomains and dynamically contribute to predictions. To promote
diversity and prevent expert collapse, we introduce a soft orthogonality
constraint across prompt vectors, encouraging expert specialization and
facilitating a more balanced expert utilization. Additionally, we adopt a
prompt-only fine-tuning strategy that significantly reduces spatiotemporal
complexity during transfer. We validate GMoPE through extensive experiments
under various pretraining strategies and multiple downstream tasks. Results
show that GMoPE consistently outperforms state-of-the-art baselines and
achieves performance comparable to full parameter fine-tuning-while requiring
only a fraction of the adaptation overhead. Our work provides a principled and
scalable framework for advancing generalizable and efficient graph foundation
models.

</details>


### [175] [Decoupled Entropy Minimization](https://arxiv.org/abs/2511.03256)
*Jing Ma,Hanlin Li,Xiang Xiang*

Main category: cs.LG

TL;DR: 本文提出了一种自适应解耦熵最小化方法（AdaDEM），通过解耦经典熵最小化中的聚集与梯度调节机制，解决了奖励崩溃和易分类偏差问题，在多种非完美监督任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究经典熵最小化的内在机制及其局限性，揭示其耦合形式导致的奖励崩溃和类别偏差问题。

Method: 将经典熵最小化解耦为聚集聚类驱动因子（CADF）和梯度缓解校准器（GMC），并提出AdaDEM，引入归一化奖励和边际熵校准器（MEC）替代GMC。

Result: AdaDEM在噪声和动态环境中多个不完美监督学习任务上优于DEM*及其他基线方法。

Conclusion: 解耦并改进熵最小化的组件可有效提升模型性能，AdaDEM为熵最小化提供了更优的实现方式。

Abstract: Entropy Minimization (EM) is beneficial to reducing class overlap, bridging
domain gap, and restricting uncertainty for various tasks in machine learning,
yet its potential is limited. To study the internal mechanism of EM, we
reformulate and decouple the classical EM into two parts with opposite effects:
cluster aggregation driving factor (CADF) rewards dominant classes and prompts
a peaked output distribution, while gradient mitigation calibrator (GMC)
penalizes high-confidence classes based on predicted probabilities.
Furthermore, we reveal the limitations of classical EM caused by its coupled
formulation: 1) reward collapse impedes the contribution of high-certainty
samples in the learning process, and 2) easy-class bias induces misalignment
between output distribution and label distribution. To address these issues, we
propose Adaptive Decoupled Entropy Minimization (AdaDEM), which normalizes the
reward brought from CADF and employs a marginal entropy calibrator (MEC) to
replace GMC. AdaDEM outperforms DEM*, an upper-bound variant of classical EM,
and achieves superior performance across various imperfectly supervised
learning tasks in noisy and dynamic environments.

</details>


### [176] [Diffusion Language Models are Super Data Learners](https://arxiv.org/abs/2511.03276)
*Jinjie Ni,Qian Liu,Longxu Dou,Chao Du,Zili Wang,Hang Yan,Tianyu Pang,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: 在数据受限的情况下，扩散语言模型（DLMs）通过更多训练轮次持续超越自回归模型（AR），这种“交叉现象”受数据量、模型规模和架构影响，并归因于任意顺序建模、迭代双向去噪带来的高密度计算以及内置的蒙特卡洛增强。


<details>
  <summary>Details</summary>
Motivation: 探索在有限独特数据下，扩散语言模型相比自回归模型的优势来源及其训练动态变化。

Method: 在严格控制的预训练设置下，比较DLMs与AR模型在不同数据量、质量和模型规模下的表现，分析验证损失与下游任务性能关系。

Result: DLM在多个基准上超越AR模型，例如1.7B DLM在Python代码任务上超过同等设置的AR coder；1B参数DLM仅用1B tokens就在HellaSwag和MMLU上取得显著准确率；验证交叉熵上升不意味着下游性能下降。

Conclusion: DLM在数据效率和训练稳定性方面具有优势，其多因素增益机制使其在低数据环境下优于AR模型，且性能趋势与传统指标解耦。

Abstract: Under strictly controlled pre-training settings, we observe a Crossover: when
unique data is limited, diffusion language models (DLMs) consistently surpass
autoregressive (AR) models by training for more epochs. The crossover shifts
later with more or higher-quality data, earlier with larger models, and
persists across dense and sparse architectures. We attribute the gains to three
compounding factors: (1) any-order modeling, (2) super-dense compute from
iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation;
input or parameter noise improves AR under data constraint but cannot close the
gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B
unique Python tokens overtakes an AR coder trained with strictly matched
settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag
and > 33% on MMLU using only 1B tokens, without any special tricks, just by
repeating standard pre-training data. We also show that rising validation
cross-entropy does not imply degraded downstream performance in this regime.

</details>


### [177] [Multi-Objective Adaptive Rate Limiting in Microservices Using Deep Reinforcement Learning](https://arxiv.org/abs/2511.03279)
*Ning Lyu,Yuxi Wang,Ziyu Cheng,Qingyuan Zhang,Feng Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度强化学习的自适应API限流策略，结合DQN和A3C算法，在动态微服务环境中实现了吞吐量提升和延迟降低。


<details>
  <summary>Details</summary>
Motivation: 传统限流算法（如令牌桶和滑动窗口）难以适应动态流量和系统负载变化，影响系统稳定性与服务质量。

Method: 将限流决策建模为马尔可夫决策过程，设计融合DQN与A3C的混合架构，通过环境交互持续学习最优限流策略。

Result: 在Kubernetes集群中实验显示，相比传统方法，吞吐量提升23.7%，P99延迟降低31.4%；生产环境部署90天内，服务降级事件减少82%，人工干预减少68%。

Conclusion: 该方法能有效应对高负载下的动态流量，显著提升微服务系统的稳定性和运维效率。

Abstract: As cloud computing and microservice architectures become increasingly
prevalent, API rate limiting has emerged as a critical mechanism for ensuring
system stability and service quality. Traditional rate limiting algorithms,
such as token bucket and sliding window, while widely adopted, struggle to
adapt to dynamic traffic patterns and varying system loads. This paper proposes
an adaptive rate limiting strategy based on deep reinforcement learning that
dynamically balances system throughput and service latency. We design a hybrid
architecture combining Deep Q-Network (DQN) and Asynchronous Advantage
Actor-Critic (A3C) algorithms, modeling the rate limiting decision process as a
Markov Decision Process. The system continuously monitors microservice states
and learns optimal rate limiting policies through environmental interaction.
Extensive experiments conducted in a Kubernetes cluster environment demonstrate
that our approach achieves 23.7% throughput improvement and 31.4% P99 latency
reduction compared to traditional fixed-threshold strategies under high-load
scenarios. Results from a 90-day production deployment handling 500 million
daily requests validate the practical effectiveness of the proposed method,
with 82% reduction in service degradation incidents and 68% decrease in manual
interventions.

</details>


### [178] [A Probabilistic Approach to Pose Synchronization for Multi-Reference Alignment with Applications to MIMO Wireless Communication Systems](https://arxiv.org/abs/2511.03280)
*Rob Romijnders,Gabriele Cesa,Christos Louizos,Kumar Pratik,Arash Behboodi*

Main category: cs.LG

TL;DR: 提出了一种基于概率模型的多参考对齐新算法，利用相对姿态作为干扰变量进行边缘化，去除了问题的全局对称性，实现了更低的重建误差和更好的收敛性。


<details>
  <summary>Details</summary>
Motivation: 多参考对齐（MRA）在分子成像、无线通信等多个领域至关重要，但传统方法存在计算复杂度高和收敛性差的问题。

Method: 采用概率方法建模MRA，引入相对姿态作为干扰变量进行边缘化，并利用去中心化和循环一致性避免集中式方法的立方级计算开销。

Result: 所提算法在多种实验设置下均实现了更低的重建误差和更优的收敛性能。

Conclusion: 该方法通过去中心化和边缘化干扰变量有效提升了MRA的效率与精度，适用于如无线通信等实际应用场景。

Abstract: From molecular imaging to wireless communications, the ability to align and
reconstruct signals from multiple misaligned observations is crucial for system
performance. We study the problem of multi-reference alignment (MRA), which
arises in many real-world problems, such as cryo-EM, computer vision, and, in
particular, wireless communication systems. Using a probabilistic approach to
model MRA, we find a new algorithm that uses relative poses as nuisance
variables to marginalize out -- thereby removing the global symmetries of the
problem and allowing for more direct solutions and improved convergence. The
decentralization of this approach enables significant computational savings by
avoiding the cubic scaling of centralized methods through cycle consistency.
Both proposed algorithms achieve lower reconstruction error across experimental
settings.

</details>


### [179] [Graph Neural AI with Temporal Dynamics for Comprehensive Anomaly Detection in Microservices](https://arxiv.org/abs/2511.03285)
*Qingyuan Zhang,Ning Lyu,Le Liu,Yuxi Wang,Ziyu Cheng,Cancan Hua*

Main category: cs.LG

TL;DR: 提出一种结合图神经网络与时间建模的统一框架，用于微服务架构中的异常检测与根因追踪。


<details>
  <summary>Details</summary>
Motivation: 微服务架构中异常检测和根因定位复杂，传统方法难以同时捕捉服务间的结构依赖和调用链的时间动态。

Method: 将微服务调用链抽象为有向图，利用图卷积聚合节点特征建模服务拓扑，结合门控循环单元建模时间演化，并通过多层堆叠与拼接融合结构与时间表征；设计节点级和路径级的异常评分函数，实现局部异常检测与全局传播路径追踪的统一建模。

Result: 在多个维度的敏感性实验中表现优异，在AUC、ACC、Recall和F1-Score等指标上优于基线方法，能在动态拓扑和复杂环境下保持高精度与稳定性。

Conclusion: 该框架为微服务异常检测提供了新技术路径，并为分布式系统的智能运维奠定了方法论基础。

Abstract: This study addresses the problem of anomaly detection and root cause tracing
in microservice architectures and proposes a unified framework that combines
graph neural networks with temporal modeling. The microservice call chain is
abstracted as a directed graph, where multidimensional features of nodes and
edges are used to construct a service topology representation, and graph
convolution is applied to aggregate features across nodes and model
dependencies, capturing complex structural relationships among services. On
this basis, gated recurrent units are introduced to model the temporal
evolution of call chains, and multi-layer stacking and concatenation operations
are used to jointly obtain structural and temporal representations, improving
the ability to identify anomaly patterns. Furthermore, anomaly scoring
functions at both the node and path levels are defined to achieve unified
modeling from local anomaly detection to global call chain tracing, which
enables the identification of abnormal service nodes and the reconstruction of
potential anomaly propagation paths. Sensitivity experiments are then designed
from multiple dimensions, including hyperparameters, environmental
disturbances, and data distribution, to evaluate the framework, and results
show that it outperforms baseline methods in key metrics such as AUC, ACC,
Recall, and F1-Score, maintaining high accuracy and stability under dynamic
topologies and complex environments. This research not only provides a new
technical path for anomaly detection in microservices but also lays a
methodological foundation for intelligent operations in distributed systems.

</details>


### [180] [Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods](https://arxiv.org/abs/2511.03304)
*Felix Störck,Fabian Hinder,Barbara Hammer*

Main category: cs.LG

TL;DR: 本文提出了一种适用于连续保护属性的核方法公平性框架，扩展了现有基于离散属性的公平性方法，结合支持向量回归在多个数据集上表现出竞争性或更优的性能。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统广泛融入社会生活，公平性变得至关重要。现有公平性研究多集中于离散属性，对连续属性尤其是回归任务中的连续公平性研究较少，因此需要拓展适用于连续保护属性的公平性方法。

Method: 通过推广迭代零空间投影策略至核方法，提出一种模型无关且公平性评分无关的方法，适用于核嵌入和连续保护属性，并结合支持向量回归（SVR）进行验证。

Result: 所提方法在多个数据集上与当前其他方法相比，表现出相当或更优的性能，验证了其在连续公平性问题上的有效性。

Conclusion: 该研究成功将连续公平性方法扩展到核方法框架，提升了对连续保护属性的适用性，为公平机器学习提供了更广泛的技术路径。

Abstract: With the on-going integration of machine learning systems into the everyday
social life of millions the notion of fairness becomes an ever increasing
priority in their development. Fairness notions commonly rely on protected
attributes to assess potential biases. Here, the majority of literature focuses
on discrete setups regarding both target and protected attributes. The
literature on continuous attributes especially in conjunction with regression
-- we refer to this as \emph{continuous fairness} -- is scarce. A common
strategy is iterative null-space projection which as of now has only been
explored for linear models or embeddings such as obtained by a non-linear
encoder. We improve on this by generalizing to kernel methods, significantly
extending the scope. This yields a model and fairness-score agnostic method for
kernel embeddings applicable to continuous protected attributes. We demonstrate
that our novel approach in conjunction with Support Vector Regression (SVR)
provides competitive or improved performance across multiple datasets in
comparisons to other contemporary methods.

</details>


### [181] [SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration](https://arxiv.org/abs/2511.03344)
*Elif Arslan,Jacobus G. M. van der Linden,Serge Hoogendoorn,Marco Rinaldi,Emir Demirović*

Main category: cs.LG

TL;DR: 本文提出了一种名为SORTD的新框架，用于高效枚举稀疏决策树的Rashomon集，在保证准确性的同时提升了可解释性和实用性。


<details>
  <summary>Details</summary>
Motivation: 由于最优决策树的搜索是NP难问题，传统方法难以有效枚举具有相似性能但结构不同的Rashomon集，限制了其在高风险场景中的应用。

Method: 提出SORTD框架，按目标函数值顺序枚举Rashomon集中的决策树，支持可分且全序的目标函数，并具备 anytime 行为以提高可扩展性。

Result: 实验表明，与现有最先进方法相比，SORTD将运行时间最多减少了两个数量级，并能灵活地对Rashomon集进行后评估。

Conclusion: SORTD显著提升了Rashomon集的计算效率和实用性，使其更适用于现实世界中的高风险决策场景。

Abstract: Sparse decision tree learning provides accurate and interpretable predictive
models that are ideal for high-stakes applications by finding the single most
accurate tree within a (soft) size limit. Rather than relying on a single
"best" tree, Rashomon sets-trees with similar performance but varying
structures-can be used to enhance variable importance analysis, enrich
explanations, and enable users to choose simpler trees or those that satisfy
stakeholder preferences (e.g., fairness) without hard-coding such criteria into
the objective function. However, because finding the optimal tree is NP-hard,
enumerating the Rashomon set is inherently challenging. Therefore, we introduce
SORTD, a novel framework that improves scalability and enumerates trees in the
Rashomon set in order of the objective value, thus offering anytime behavior.
Our experiments show that SORTD reduces runtime by up to two orders of
magnitude compared with the state of the art. Moreover, SORTD can compute
Rashomon sets for any separable and totally ordered objective and supports
post-evaluating the set using other separable (and partially ordered)
objectives. Together, these advances make exploring Rashomon sets more
practical in real-world applications.

</details>


### [182] [A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in Transportation Agentic AI Applications](https://arxiv.org/abs/2511.03363)
*Xiaocai Zhang,Hur Lim,Ke Wang,Zhe Xiao,Jing Wang,Kelvin Lee,Xiuju Fu,Zheng Qin*

Main category: cs.LG

TL;DR: 提出了一种无需数据标注的模块化多标签意图识别管道DMTC，适用于交通领域的代理AI应用，通过合成数据生成、Sentence-T5编码和新型OFC损失函数，在无标注条件下实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统意图识别依赖大量标注数据且难以处理细粒度多标签分类，本文旨在构建一种无需标注数据、可扩展的多标签意图识别系统，以支持交通领域中自主代理AI的应用。

Method: 提出DMTC三步管道：1）利用提示工程引导大语言模型生成多样化交通场景下的合成查询；2）使用Sentence-T5模型对文本进行语义编码；3）采用新颖的在线焦点对比损失（OFC）训练轻量级分类器，增强难样本学习与类间可分性。

Result: 在海上交通场景中验证了方法有效性，DMTC实现5.35%的汉明损失和95.92%的AUC，优于最先进的多标签分类器和端到端LLM基线；Sentence-T5比其他编码器提升至少3.29%子集准确率，OFC损失额外带来0.98%性能增益。

Conclusion: DMTC能够有效将用户查询路由至任务专用模块，如ETA信息、交通风险评估等，为无需人工标注的完全自主、意图感知型代理AI奠定了基础。

Abstract: In this study, a modular, data-free pipeline for multi-label intention
recognition is proposed for agentic AI applications in transportation. Unlike
traditional intent recognition systems that depend on large, annotated corpora
and often struggle with fine-grained, multi-label discrimination, our approach
eliminates the need for costly data collection while enhancing the accuracy of
multi-label intention understanding. Specifically, the overall pipeline, named
DMTC, consists of three steps: 1) using prompt engineering to guide large
language models (LLMs) to generate diverse synthetic queries in different
transport scenarios; 2) encoding each textual query with a Sentence-T5 model to
obtain compact semantic embeddings; 3) training a lightweight classifier using
a novel online focal-contrastive (OFC) loss that emphasizes hard samples and
maximizes inter-class separability. The applicability of the proposed pipeline
is demonstrated in an agentic AI application in the maritime transportation
context. Extensive experiments show that DMTC achieves a Hamming loss of 5.35%
and an AUC of 95.92%, outperforming state-of-the-art multi-label classifiers
and recent end-to-end SOTA LLM-based baselines. Further analysis reveals that
Sentence-T5 embeddings improve subset accuracy by at least 3.29% over
alternative encoders, and integrating the OFC loss yields an additional 0.98%
gain compared to standard contrastive objectives. In conclusion, our system
seamlessly routes user queries to task-specific modules (e.g., ETA information,
traffic risk evaluation, and other typical scenarios in the transportation
domain), laying the groundwork for fully autonomous, intention-aware agents
without costly manual labelling.

</details>


### [183] [TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled Markets](https://arxiv.org/abs/2511.03368)
*Hongrun Ren,Yun Xiong,Lei You,Yingying Wang,Haixu Xiong,Yangyong Zhu*

Main category: cs.LG

TL;DR: 提出了一种统一的数据-模型耦合市场机制，通过供需双向映射和Shapley值分配实现数据卖家、模型生产者和买家之间的对称定价，保证了均衡价格的存在性、唯一性和全局收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有数据与模型定价方法多分离或偏向某一方，缺乏对多方交互的对称且同时的定价机制。

Method: 构建一个统一的数据-模型耦合市场，利用供给端映射将数据支付转化为模型报价，需求端通过基于Shapley值的分配将买家价格反向传播至数据集，形成闭环系统，并证明其为标准干扰函数（SIF）。

Result: 该机制实现了供需双向传播和买卖双方内部的耦合，实验显示其具有高效收敛性和优于传统方法的公平性。

Conclusion: 所提出的耦合市场机制为数据与模型交易提供了对称、协同的定价框架，确保了市场均衡的稳定性和可计算性。

Abstract: The rise of the machine learning (ML) model economy has intertwined markets
for training datasets and pre-trained models. However, most pricing approaches
still separate data and model transactions or rely on broker-centric pipelines
that favor one side. Recent studies of data markets with externalities capture
buyer interactions but do not yield a simultaneous and symmetric mechanism
across data sellers, model producers, and model buyers. We propose a unified
data-model coupled market that treats dataset and model trading as a single
system. A supply-side mapping transforms dataset payments into buyer-visible
model quotations, while a demand-side mapping propagates buyer prices back to
datasets through Shapley-based allocation. Together, they form a closed loop
that links four interactions: supply-demand propagation in both directions and
mutual coupling among buyers and among sellers. We prove that the joint
operator is a standard interference function (SIF), guaranteeing existence,
uniqueness, and global convergence of equilibrium prices. Experiments
demonstrate efficient convergence and improved fairness compared with
broker-centric and one-sided baselines. The code is available on
https://github.com/HongrunRen1109/Triple-Win-Pricing.

</details>


### [184] [Adaptable Hindsight Experience Replay for Search-Based Learning](https://arxiv.org/abs/2511.03405)
*Alexandros Vazaios,Jannis Brugger,Cedric Derstroff,Kristian Kersting,Mira Mezini*

Main category: cs.LG

TL;DR: 提出了一种可调节的Hindsight Experience Replay框架（Adaptable HER），将其与AlphaZero结合，提升了在稀疏奖励环境下的学习效率，在方程发现等任务中优于纯监督或强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 在稀疏奖励环境中，AlphaZero类系统因早期缺乏有效指导而训练困难，需要改进训练信号的生成方式。

Method: 引入Adaptable HER框架，将失败的搜索轨迹通过重标记目标状态作为监督信号，灵活调整HER中的目标、策略目标和轨迹选择机制，并与蒙特卡洛树搜索和神经网络引导结合。

Result: 实验表明，Adaptable HER在方程发现等任务中表现优于传统的监督学习和强化学习方法，验证了其在稀疏奖励场景下的有效性。

Conclusion: Adaptable HER为AlphaZero类算法在经典搜索问题中的应用提供了更高效的训练机制，尤其适用于稀疏奖励环境。

Abstract: AlphaZero-like Monte Carlo Tree Search systems, originally introduced for
two-player games, dynamically balance exploration and exploitation using neural
network guidance. This combination makes them also suitable for classical
search problems. However, the original method of training the network with
simulation results is limited in sparse reward settings, especially in the
early stages, where the network cannot yet give guidance. Hindsight Experience
Replay (HER) addresses this issue by relabeling unsuccessful trajectories from
the search tree as supervised learning signals. We introduce Adaptable HER
(\ours{}), a flexible framework that integrates HER with AlphaZero, allowing
easy adjustments to HER properties such as relabeled goals, policy targets, and
trajectory selection. Our experiments, including equation discovery, show that
the possibility of modifying HER is beneficial and surpasses the performance of
pure supervised or reinforcement learning.

</details>


### [185] [POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding](https://arxiv.org/abs/2511.03464)
*Mihriban Kocak Balik,Pekka Marttinen,Negar Safinianaini*

Main category: cs.LG

TL;DR: POEMS是一种用于可解释多组学整合的无监督概率框架，通过稀疏解码在保持预测性能的同时实现高可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度生成模型在多组学数据整合中难以兼顾预测性能与可解释性，通常需牺牲非线性表达能力以增强解释性。

Method: 提出POEMS框架，采用稀疏连接映射特征到潜在因子、产品专家模型共享潜在空间以捕捉跨组学关联，并通过门控网络自适应计算各组学贡献。

Result: 在癌症亚型分类任务中，POEMS实现了具有竞争力的聚类和分类性能，同时提供了基于生物标志物的新颖解释。

Conclusion: POEMS成功平衡了多组学表示学习中的预测准确性与可解释性，证明二者可以共存。

Abstract: Integrating different molecular layers, i.e., multiomics data, is crucial for
unraveling the complexity of diseases; yet, most deep generative models either
prioritize predictive performance at the expense of interpretability or enforce
interpretability by linearizing the decoder, thereby weakening the network's
nonlinear expressiveness. To overcome this tradeoff, we introduce POEMS:
Product Of Experts for Interpretable Multiomics Integration using Sparse
Decoding, an unsupervised probabilistic framework that preserves predictive
performance while providing interpretability. POEMS provides interpretability
without linearizing any part of the network by 1) mapping features to latent
factors using sparse connections, which directly translates to biomarker
discovery, 2) allowing for cross-omic associations through a shared latent
space using product of experts model, and 3) reporting contributions of each
omic by a gating network that adaptively computes their influence in the
representation learning. Additionally, we present an efficient sparse decoder.
In a cancer subtyping case study, POEMS achieves competitive clustering and
classification performance while offering our novel set of interpretations,
demonstrating that biomarker based insight and predictive accuracy can coexist
in multiomics representation learning.

</details>


### [186] [Reinforcement Learning Using known Invariances](https://arxiv.org/abs/2511.03473)
*Alexandru Cioba,Aya Kayal,Laura Toni,Sattar Vakili,Alberto Bernacchia*

Main category: cs.LG

TL;DR: 提出了一种基于对称性感知的乐观最小二乘值迭代方法，利用不变核函数提升强化学习的样本效率，并在理论和实验上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现实中的强化学习问题常具有内在对称性，若能有效利用这些对称性，可提升学习效率。现有方法未能充分结合已知群对称性与核方法。

Method: 提出一种对称性感知的乐观最小二乘值迭代（LSVI）算法，使用不变核函数编码奖励和转移动态的对称性，构建适用于对称环境的核方法框架。

Result: 推导了不变再生核希尔伯特空间（RKHS）的信息增益和覆盖数的新界，量化了对称性带来的样本效率提升；在定制的Frozen Lake和2D布局设计任务中验证了算法优于标准核方法。

Conclusion: 通过引入结构先验（如对称性），可显著提升强化学习的样本效率，该研究为设计高效RL算法提供了理论支持和实用框架。

Abstract: In many real-world reinforcement learning (RL) problems, the environment
exhibits inherent symmetries that can be exploited to improve learning
efficiency. This paper develops a theoretical and algorithmic framework for
incorporating known group symmetries into kernel-based RL. We propose a
symmetry-aware variant of optimistic least-squares value iteration (LSVI),
which leverages invariant kernels to encode invariance in both rewards and
transition dynamics. Our analysis establishes new bounds on the maximum
information gain and covering numbers for invariant RKHSs, explicitly
quantifying the sample efficiency gains from symmetry. Empirical results on a
customized Frozen Lake environment and a 2D placement design problem confirm
the theoretical improvements, demonstrating that symmetry-aware RL achieves
significantly better performance than their standard kernel counterparts. These
findings highlight the value of structural priors in designing more
sample-efficient reinforcement learning algorithms.

</details>


### [187] [RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse](https://arxiv.org/abs/2511.03475)
*Yinsicheng Jiang,Yeqi Huang,Liang Cheng,Cheng Deng,Xuan Sun,Luo Mai*

Main category: cs.LG

TL;DR: RAGBoost是一种高效的检索增强生成系统，通过准确性的上下文重用来提高缓存利用率，同时不牺牲推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有缓存技术在提高缓存重用率时往往牺牲推理质量，而现代应用需要处理更长、更复杂的输入，导致预填充性能下降。

Method: RAGBoost采用高效的上下文索引、排序和去重机制，检测并发会话和多轮交互中的重叠检索项，并利用轻量级上下文提示保持推理保真度。

Result: RAGBoost将现有LLM推理引擎的预填充性能提升了1.5-3倍，且在多种RAG和智能体AI工作负载中保持甚至提高了推理准确性。

Conclusion: RAGBoost在不牺牲准确性的前提下显著提升了RAG系统的缓存重用率和预填充效率，适用于复杂和长输入场景。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with retrieved context but often suffers from downgraded prefill performance as
modern applications demand longer and more complex inputs. Existing caching
techniques either preserve accuracy with low cache reuse or improve reuse at
the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG
system that achieves high cache reuse without sacrificing accuracy through
accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items
across concurrent sessions and multi-turn interactions, using efficient context
indexing, ordering, and de-duplication to maximize reuse, while lightweight
contextual hints maintain reasoning fidelity. It integrates seamlessly with
existing LLM inference engines and improves their prefill performance by 1.5-3X
over state-of-the-art methods, while preserving or even enhancing reasoning
accuracy across diverse RAG and agentic AI workloads. Our code is released at:
https://github.com/Edinburgh-AgenticAI/RAGBoost.

</details>


### [188] [NAP: Attention-Based Late Fusion for Automatic Sleep Staging](https://arxiv.org/abs/2511.03488)
*Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci*

Main category: cs.LG

TL;DR: 提出了一种基于注意力机制的模型NAP，用于聚合多通道多模态生理信号的预测，实现跨数据集的零样本睡眠分期。


<details>
  <summary>Details</summary>
Motivation: 现有模型通常依赖固定的模态或通道子集，未能充分利用多导睡眠图信号的多模态特性。

Method: 提出NAP（Neural Aggregator of Predictions）模型，采用三轴注意力机制（时间、空间、预测器层面）融合多个预训练单通道模型的输出，并适应不同输入维度。

Result: NAP在多个数据集上实现了最先进的零样本泛化性能，优于单个预测器和简单集成方法。

Conclusion: NAP能有效聚合异构生理信号预测，在睡眠分期任务中表现优异，具有推广至其他多模态生理信号分析的潜力。

Abstract: Polysomnography signals are highly heterogeneous, varying in modality
composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal,
occipital EEG), and acquisition protocols across datasets and clinical sites.
Most existing models that process polysomnography data rely on a fixed subset
of modalities or channels and therefore neglect to fully exploit its inherently
multimodal nature. We address this limitation by introducing NAP (Neural
Aggregator of Predictions), an attention-based model which learns to combine
multiple prediction streams using a tri-axial attention mechanism that captures
temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to
different input dimensions. By aggregating outputs from frozen, pretrained
single-channel models, NAP consistently outperforms individual predictors and
simple ensembles, achieving state-of-the-art zero-shot generalization across
multiple datasets. While demonstrated in the context of automated sleep staging
from polysomnography, the proposed approach could be extended to other
multimodal physiological applications.

</details>


### [189] [Why Less is More (Sometimes): A Theory of Data Curation](https://arxiv.org/abs/2511.03492)
*Elvis Dohmatob,Mohammad Pezeshki,Reyhane Askari-Hemmat*

Main category: cs.LG

TL;DR: 本文提出一个理论框架，解释现代机器学习中“更少数据反而更好”的悖论，通过分析数据筛选策略，揭示在特定条件下小而精炼的数据集为何能优于完整数据集，并在ImageNet上验证了该理论。


<details>
  <summary>Details</summary>
Motivation: 解决现代机器学习中“更多数据更好”的经典 Scaling Law 与近期“少即是多”（如 LIMO、s1）方法之间的矛盾。

Method: 构建基于不完美 oracle 的数据筛选模型，研究标签感知与非感知筛选规则下的测试误差缩放律，推导数据规模与质量相关的相变曲线。

Result: 得出精确的缩放律曲线，证明在特定条件下精选的小数据集可超越全量数据，并在 ImageNet 上验证了该理论对准确率提升和模型崩溃缓解的有效性。

Conclusion: 数据质量与筛选策略在某些情况下比数据量更重要，为“少即是多”现象提供了理论依据，并解释了大模型数学推理中看似矛盾的数据筛选策略。

Abstract: This paper introduces a theoretical framework to resolve a central paradox in
modern machine learning: When is it better to use less data? This question has
become critical as classical scaling laws suggesting ``more is more'' (Sun et
al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et
al., 2025; Muenighoff et al., 2025), which achieve superior performance with
small, aggressively curated datasets. Here, we study data curation strategies
where an imperfect oracle selects the training examples according to their
difficulty and correctness. Our results provide exact scaling law curves for
test error under both label-agnostic and label-aware curation rules, revealing
when and why keeping only a subset of data can improve generalization. In
contrast to classical scaling laws, we show that under certain conditions,
small curated datasets can outperform full datasets, and we provide analytical
conditions for this by deriving precise phase transition curves tied to data
size and quality. We validate these theoretical claims with empirical results
on ImageNet, confirming our predictions about when curation improves accuracy
and can even mitigate model collapse. Furthermore, our framework provides a
principled explanation for the contradictory curation strategies recently
observed in LLM mathematical reasoning.

</details>


### [190] [Learning Without Critics? Revisiting GRPO in Classical Reinforcement Learning Environments](https://arxiv.org/abs/2511.03527)
*Bryan L. M. de Oliveira,Felipe V. Frujeri,Marcos P. C. M. Queiroz,Luana G. B. Martins,Telma W. de L. Soares,Luckeciano C. Melo*

Main category: cs.LG

TL;DR: 本文首次系统研究了无批评家的GRPO算法在经典强化学习任务中的表现，发现学习型批评家在长周期任务中仍然至关重要，而GRPO仅在短周期环境中表现良好；此外，高折扣因子通常有益，但小规模组采样优于大规模组采样。


<details>
  <summary>Details</summary>
Motivation: 探讨无批评家方法（如GRPO）是否可替代传统依赖学习型批评家的策略梯度方法（如PPO），并理解其适用条件和局限性。

Method: 在离散与连续控制的经典单任务强化学习环境中，通过控制变量法分别研究基线、折扣因子和组采样策略的影响，对GRPO进行消融实验，并与PPO对比性能。

Result: (1) 在长周期任务中，所有无批评家方法均不如PPO，仅在短周期环境（如CartPole）中表现良好；(2) GRPO通常受益于高折扣因子（gamma=0.99），但在HalfCheetah中因缺乏早期终止而适合中等折扣（gamma=0.9）；(3) 较小的组大小优于较大的组，表明基于批次的分组策略存在局限。

Conclusion: 学习型批评家在长周期任务中仍不可替代，而无批评家方法仅在特定条件下（如短周期、适当折扣、小分组）可行，揭示了GRPO等方法的局限性和应用边界。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a scalable
alternative to Proximal Policy Optimization (PPO) by eliminating the learned
critic and instead estimating advantages through group-relative comparisons of
trajectories. This simplification raises fundamental questions about the
necessity of learned baselines in policy-gradient methods. We present the first
systematic study of GRPO in classical single-task reinforcement learning
environments, spanning discrete and continuous control tasks. Through
controlled ablations isolating baselines, discounting, and group sampling, we
reveal three key findings: (1) learned critics remain essential for
long-horizon tasks: all critic-free baselines underperform PPO except in
short-horizon environments like CartPole where episodic returns can be
effective; (2) GRPO benefits from high discount factors (gamma = 0.99) except
in HalfCheetah, where lack of early termination favors moderate discounting
(gamma = 0.9); (3) smaller group sizes outperform larger ones, suggesting
limitations in batch-based grouping strategies that mix unrelated episodes.
These results reveal both the limitations of critic-free methods in classical
control and the specific conditions where they remain viable alternatives to
learned value functions.

</details>


### [191] [Byzantine-Robust Federated Learning with Learnable Aggregation Weights](https://arxiv.org/abs/2511.03529)
*Javad Parsa,Amir Hossein Daghestani,André M. H. Teixeira,Mikael Johansson*

Main category: cs.LG

TL;DR: 提出一种新的拜占庭鲁棒联邦学习优化方法，通过将聚合权重作为可学习参数进行自适应加权，并设计了具有强收敛保证的交替最小化算法。


<details>
  <summary>Details</summary>
Motivation: 在数据分布异构的情况下，恶意客户端对联邦学习的鲁棒性构成挑战，现有方法难以有效应对。

Method: 将聚合权重视为可学习参数，与全局模型参数联合优化，提出一种交替最小化算法。

Result: 在多种数据集和攻击场景下，该方法优于现有的拜占庭鲁棒联邦学习方法，尤其在数据高度异构且恶意客户端比例较高时表现更优。

Conclusion: 所提方法通过自适应学习聚合权重，显著提升了联邦学习在异构数据和恶意攻击下的鲁棒性和性能。

Abstract: Federated Learning (FL) enables clients to collaboratively train a global
model without sharing their private data. However, the presence of malicious
(Byzantine) clients poses significant challenges to the robustness of FL,
particularly when data distributions across clients are heterogeneous. In this
paper, we propose a novel Byzantine-robust FL optimization problem that
incorporates adaptive weighting into the aggregation process. Unlike
conventional approaches, our formulation treats aggregation weights as
learnable parameters, jointly optimizing them alongside the global model
parameters. To solve this optimization problem, we develop an alternating
minimization algorithm with strong convergence guarantees under adversarial
attack. We analyze the Byzantine resilience of the proposed objective. We
evaluate the performance of our algorithm against state-of-the-art
Byzantine-robust FL approaches across various datasets and attack scenarios.
Experimental results demonstrate that our method consistently outperforms
existing approaches, particularly in settings with highly heterogeneous data
and a large proportion of malicious clients.

</details>


### [192] [Efficient Neural Networks with Discrete Cosine Transform Activations](https://arxiv.org/abs/2511.03531)
*Marc Martinez-Gost,Sara Pepe,Ana Pérez-Neira,Miguel Ángel Lagunas*

Main category: cs.LG

TL;DR: 本文扩展了基于离散余弦变换（DCT）的可表达神经网络（ENN），强调其在紧凑结构下的效率、可解释性和剪枝能力，通过DCT参数化实现高效剪枝并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 在保持神经网络高表达能力的同时，提升其效率和可解释性，并探索结构化激活函数在模型压缩中的潜力。

Method: 采用DCT对多层感知机的激活函数进行参数化，利用DCT的正交性和去相关特性识别并剪枝冗余系数。

Result: 在分类和隐式神经表示任务中达到先进性能，模型参数少，最多可剪枝40%的激活系数而不损失精度。

Conclusion: ENN框架将信号处理思想融入神经网络设计，实现了表达性、紧凑性和可解释性之间的良好平衡。

Abstract: In this paper, we extend our previous work on the Expressive Neural Network
(ENN), a multilayer perceptron with adaptive activation functions parametrized
using the Discrete Cosine Transform (DCT). Building upon previous work that
demonstrated the strong expressiveness of ENNs with compact architectures, we
now emphasize their efficiency, interpretability and pruning capabilities. The
DCT-based parameterization provides a structured and decorrelated
representation that reveals the functional role of each neuron and allows
direct identification of redundant components. Leveraging this property, we
propose an efficient pruning strategy that removes unnecessary DCT coefficients
with negligible or no loss in performance. Experimental results across
classification and implicit neural representation tasks confirm that ENNs
achieve state-of-the-art accuracy while maintaining a low number of parameters.
Furthermore, up to 40% of the activation coefficients can be safely pruned,
thanks to the orthogonality and bounded nature of the DCT basis. Overall, these
findings demonstrate that the ENN framework offers a principled integration of
signal processing concepts into neural network design, achieving a balanced
trade-off between expressiveness, compactness, and interpretability.

</details>


### [193] [Flat Minima and Generalization: Insights from Stochastic Convex Optimization](https://arxiv.org/abs/2511.03548)
*Matan Schliserman,Shira Vansover-Hager,Tomer Koren*

Main category: cs.LG

TL;DR: 本文研究了平坦极小值与泛化性能之间的关系，发现在随机凸优化中，即使算法收敛到平坦极小值（如SA-GD和SAM），其泛化性能仍可能很差（population risk为Ω(1)），挑战了“平坦即良好泛化”的普遍认知。


<details>
  <summary>Details</summary>
Motivation: 近年来认为学习算法之所以成功是因为收敛到平坦极小值，但该观点在基本的凸优化场景下是否成立尚不明确，本文旨在理论分析这一联系。

Method: 在非负β-光滑目标函数的随机凸优化框架下，通过构造反例和算法稳定性技术，分析SA-GD和SAM两类sharpness-aware算法的收敛性与泛化性能。

Result: 1）平坦经验极小值可能具有Ω(1)的群体风险；2）SA-GD虽收敛到平坦极小值但泛化差；3）SAM可能收敛到尖锐极小值且泛化也差；4）通过算法稳定性给出了SA-GD和SAM的群体风险上界。

Conclusion: 平坦极小值并不保证良好泛化，sharpness-aware优化方法在某些情况下可能无法提升泛化性能，需重新审视sharpness作为泛化代理指标的有效性。

Abstract: Understanding the generalization behavior of learning algorithms is a central
goal of learning theory. A recently emerging explanation is that learning
algorithms are successful in practice because they converge to flat minima,
which have been consistently associated with improved generalization
performance. In this work, we study the link between flat minima and
generalization in the canonical setting of stochastic convex optimization with
a non-negative, $\beta$-smooth objective. Our first finding is that, even in
this fundamental and well-studied setting, flat empirical minima may incur
trivial $\Omega(1)$ population risk while sharp minima generalizes optimally.
Then, we show that this poor generalization behavior extends to two natural
''sharpness-aware'' algorithms originally proposed by Foret et al. (2021),
designed to bias optimization toward flat solutions: Sharpness-Aware Gradient
Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which
performs gradient steps on the maximal loss in a predefined neighborhood, we
prove that while it successfully converges to a flat minimum at a fast rate,
the population risk of the solution can still be as large as $\Omega(1)$,
indicating that even flat minima found algorithmically using a sharpness-aware
gradient method might generalize poorly. For SAM, a computationally efficient
approximation of SA-GD based on normalized ascent steps, we show that although
it minimizes the empirical loss, it may converge to a sharp minimum and also
incur population risk $\Omega(1)$. Finally, we establish population risk upper
bounds for both SA-GD and SAM using algorithmic stability techniques.

</details>


### [194] [Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances](https://arxiv.org/abs/2511.03565)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 本文综述了模仿学习领域的最新进展，提出了一种新的分类法，涵盖了方法创新、实际应用及代表性工作的优缺点，并指出了未来研究的关键挑战和方向。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习的发展，模仿学习在多个领域得到扩展，但依然面临泛化、协变量偏移和示范质量等挑战，需要系统性梳理最新进展并明确未来方向。

Method: 通过回顾近年来的文献，提出一种新颖的分类体系，对模仿学习的方法、趋势和应用进行系统分析，并批判性地评估代表性工作。

Result: 总结了模仿学习的最新趋势与方法创新，提出了更符合当前研究现状的新 taxonomy，并识别出关键挑战和开放问题。

Conclusion: 该综述为理解当前模仿学习的研究格局提供了全面视角，所提出的新分类法有助于指导未来研究方向。

Abstract: Imitation learning (IL) enables agents to acquire skills by observing and
replicating the behavior of one or multiple experts. In recent years, advances
in deep learning have significantly expanded the capabilities and scalability
of imitation learning across a range of domains, where expert data can range
from full state-action trajectories to partial observations or unlabeled
sequences. Alongside this growth, novel approaches have emerged, with new
methodologies being developed to address longstanding challenges such as
generalization, covariate shift, and demonstration quality. In this survey, we
review the latest advances in imitation learning research, highlighting recent
trends, methodological innovations, and practical applications. We propose a
novel taxonomy that is distinct from existing categorizations to better reflect
the current state of the IL research stratum and its trends. Throughout the
survey, we critically examine the strengths, limitations, and evaluation
practices of representative works, and we outline key challenges and open
directions for future research.

</details>


### [195] [TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval](https://arxiv.org/abs/2511.03570)
*Günther Schindler,Maximilian Schambach,Michael Medek,Sam Thelin*

Main category: cs.LG

TL;DR: TabGemma是一种基于大语言模型的表格预测方法，通过规范化的科学计数法处理数值，并利用大规模真实数据继续预训练，实现了在分类任务上的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决将预训练大语言模型应用于表格数据预测时面临的数值标记不稳定和上下文长度有限的问题。

Method: 采用schema无关的上下文学习方法，将行视为序列；使用带符号的科学记数法对数值进行规范化，并在大规模真实世界数据集上以目标掩码为目标继续预训练12B的Gemma 3模型；推理时采用紧凑的n-gram检索选择信息性强且适配128k token窗口的示例。

Result: 在语义丰富的基准测试中，TabGemma在低数据和高数据场景下的分类任务上均达到最先进水平，且性能随上下文行数增加而单调提升；在回归任务中小样本下表现有竞争力，但随着数据量增大落后于传统方法。

Conclusion: 研究表明，结合专用的数值处理和上下文检索机制后，大语言模型可有效作为语义丰富任务的表格上下文学习器，同时指出需进一步改进数值建模和长上下文扩展能力。

Abstract: We study LLMs for tabular prediction with mixed text, numeric, and
categorical fields. We introduce TabGemma, a schema-agnostic in-context learner
that treats rows as sequences and tackles two practical hurdles when adapting
pretrained LLMs for tabular predictions: unstable numeric tokenization and
limited context size. We propose to canonicalize numbers via signed scientific
notation and continue pretraining of a 12B Gemma 3 model with a target
imputation objective using a large-scale real world dataset. For inference, we
use a compact n-gram-based retrieval to select informative exemplars that fit
within a 128k-token window.
  On semantically rich benchmarks, TabGemma establishes a new state of the art
on classification across low- and high-data regimes and improves monotonically
with more context rows. For regression, it is competitive at small sample sizes
but trails conventional approaches as data grows. Our results show that LLMs
can be effective tabular in-context learners on highly semantic tasks when
paired with dedicated numeric handling and context retrieval, while motivating
further advances in numeric modeling and long-context scaling.

</details>


### [196] [Learning Under Laws: A Constraint-Projected Neural PDE Solver that Eliminates Hallucinations](https://arxiv.org/abs/2511.03578)
*Mainak Singha*

Main category: cs.LG

TL;DR: 提出了一种名为约束投影学习（CPL）的框架，通过将神经网络输出投影到物理约束集上，确保每次更新都符合守恒、熵、正性等物理定律，从而生成稳定且物理一致的偏微分方程解。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络求解偏微分方程时常违反物理守恒律和熵条件，导致非物理解，如质量不守恒、激波漂移等。

Method: 引入可微的约束投影机制，将网络输出持续投影到由守恒律、Rankine-Hugoniot条件、熵和正性定义的约束集合交集中，并结合总变差阻尼（TVD）和 rollout 课程学习来稳定训练。

Result: 在Burgers和Euler方程上验证了CPL的有效性，守恒律达到机器精度，总变差增长消失，熵和误差保持有界，且不损失精度。

Conclusion: CPL使物理规律的遵守成为学习过程的内在属性，而非依赖后处理或正则化，实现了稳定、准确且物理自洽的神经求解器。

Abstract: Neural networks can approximate solutions to partial differential equations,
but they often break the very laws they are meant to model-creating mass from
nowhere, drifting shocks, or violating conservation and entropy. We address
this by training within the laws of physics rather than beside them. Our
framework, called Constraint-Projected Learning (CPL), keeps every update
physically admissible by projecting network outputs onto the intersection of
constraint sets defined by conservation, Rankine-Hugoniot balance, entropy, and
positivity. The projection is differentiable and adds only about 10%
computational overhead, making it fully compatible with back-propagation. We
further stabilize training with total-variation damping (TVD) to suppress small
oscillations and a rollout curriculum that enforces consistency over long
prediction horizons. Together, these mechanisms eliminate both hard and soft
violations: conservation holds at machine precision, total-variation growth
vanishes, and entropy and error remain bounded. On Burgers and Euler systems,
CPL produces stable, physically lawful solutions without loss of accuracy.
Instead of hoping neural solvers will respect physics, CPL makes that behavior
an intrinsic property of the learning process.

</details>


### [197] [Tensor-Efficient High-Dimensional Q-learning](https://arxiv.org/abs/2511.03595)
*Junyi Wu,Dan Li*

Main category: cs.LG

TL;DR: 提出了一种基于张量的高效Q学习方法（TEQL），通过改进的低秩分解和新型探索与正则化机制，在高维强化学习中实现了更高的样本效率和奖励表现。


<details>
  <summary>Details</summary>
Motivation: 高维强化学习面临计算复杂和样本效率低的问题，传统Q学习在大规模状态-动作空间中受维度灾难影响严重。

Method: 基于张量低秩分解，采用改进的块坐标下降法，并结合近似误差与访问次数的置信上界进行探索，同时引入频率惩罚项以减少过拟合。

Result: 在经典控制任务中，TEQL在样本效率和总奖励方面优于传统矩阵方法和深度强化学习方法。

Conclusion: TEQL是一种参数高效且样本高效的Q学习方法，适用于采样成本高的资源受限场景，如太空和医疗领域。

Abstract: High-dimensional reinforcement learning faces challenges with complex
calculations and low sample efficiency in large state-action spaces. Q-learning
algorithms struggle particularly with the curse of dimensionality, where the
number of state-action pairs grows exponentially with problem size. While
neural network-based approaches like Deep Q-Networks have shown success, recent
tensor-based methods using low-rank decomposition offer more
parameter-efficient alternatives. Building upon existing tensor-based methods,
we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensor
decomposition via improved block coordinate descent on discretized state-action
spaces, incorporating novel exploration and regularization mechanisms. The key
innovation is an exploration strategy that combines approximation error with
visit count-based upper confidence bound to prioritize actions with high
uncertainty, avoiding wasteful random exploration. Additionally, we incorporate
a frequency-based penalty term in the objective function to encourage
exploration of less-visited state-action pairs and reduce overfitting to
frequently visited regions. Empirical results on classic control tasks
demonstrate that TEQL outperforms conventional matrix-based methods and deep RL
approaches in both sample efficiency and total rewards, making it suitable for
resource-constrained applications, such as space and healthcare where sampling
costs are high.

</details>


### [198] [Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning](https://arxiv.org/abs/2511.03616)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 本文提出了一种深度隐式模仿强化学习框架DIIQN，通过仅含状态的专家数据实现高效学习，并引入HA-DIIQN解决专家与智能体动作空间异构的问题。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习依赖完整的状态-动作示范且难以超越次优专家表现，限制了在仅有状态观测或专家性能不佳的实际场景中的应用。

Method: 提出DIIQN，结合深度强化学习与基于观测的隐式模仿学习，采用动作推断机制和动态置信机制，在线探索重构专家动作并平衡专家指导与自主学习；进一步设计HA-DIIQN，引入不可行性检测与桥接策略以应对异构动作空间。

Result: 实验显示DIIQN相比标准DQN提升最多130%的回合回报，显著优于现有隐式模仿方法；HA-DIIQN在异构动作场景下比基线快64%，能利用传统方法无法使用的专家数据。

Conclusion: 所提框架有效克服了模仿学习对完整动作标注和高性能专家的依赖，扩展了其在现实场景中的适用性，尤其在动作空间不匹配情况下展现出优越性能。

Abstract: Imitation learning traditionally requires complete state-action
demonstrations from optimal or near-optimal experts. These requirements
severely limit practical applicability, as many real-world scenarios provide
only state observations without corresponding actions and expert performance is
often suboptimal. In this paper we introduce a deep implicit imitation
reinforcement learning framework that addresses both limitations by combining
deep reinforcement learning with implicit imitation learning from
observation-only datasets. Our main algorithm, Deep Implicit Imitation
Q-Network (DIIQN), employs an action inference mechanism that reconstructs
expert actions through online exploration and integrates a dynamic confidence
mechanism that adaptively balances expert-guided and self-directed learning.
This enables the agent to leverage expert guidance for accelerated training
while maintaining capacity to surpass suboptimal expert performance. We further
extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to
tackle scenarios where expert and agent possess different action sets, a
challenge previously unaddressed in the implicit imitation learning literature.
HA-DIIQN introduces an infeasibility detection mechanism and a bridging
procedure identifying alternative pathways connecting agent capabilities to
expert guidance when direct action replication is impossible. Our experimental
results demonstrate that DIIQN achieves up to 130% higher episodic returns
compared to standard DQN, while consistently outperforming existing implicit
imitation methods that cannot exceed expert performance. In heterogeneous
action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging
expert datasets unusable by conventional approaches. Extensive parameter
sensitivity analysis reveals the framework's robustness across varying dataset
sizes and hyperparameter configurations.

</details>


### [199] [Towards Formalizing Reinforcement Learning Theory](https://arxiv.org/abs/2511.03618)
*Shangtong Zhang*

Main category: cs.LG

TL;DR: 本文使用Lean 4定理证明器基于Robbins-Siegmund定理，形式化验证了Q学习和线性时序差分学习在马尔可夫样本下的几乎必然收敛性，为强化学习理论的形式化奠定了基础。


<details>
  <summary>Details</summary>
Motivation: Q学习和线性TD学习是强化学习中最早且最具影响力的算法，其收敛性分析在早期RL发展中至关重要，近年来也受到越来越多关注。然而，现有研究缺乏形式化验证，因此需要借助定理证明工具确保结果的严谨性。

Method: 采用Lean 4定理证明器结合Mathlib库，基于Robbins-Siegmund定理构建统一框架，对Q学习和线性TD学习在马尔可夫样本下的几乎必然收敛性进行形式化证明。

Result: 成功实现了Q学习和线性TD学习算法几乎必然收敛的形式化验证，并提供了一个可扩展的框架，可用于分析收敛速率和其他收敛模式。代码已开源。

Conclusion: 该工作为强化学习理论结果的完全形式化迈出了重要一步，展示了形式化方法在验证复杂学习算法收敛性方面的可行性与潜力。

Abstract: In this paper, we formalize the almost sure convergence of $Q$-learning and
linear temporal difference (TD) learning with Markovian samples using the Lean
4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are
among the earliest and most influential reinforcement learning (RL) algorithms.
The investigation of their convergence properties is not only a major research
topic during the early development of the RL field but also receives increasing
attention nowadays. This paper formally verifies their almost sure convergence
in a unified framework based on the Robbins-Siegmund theorem. The framework
developed in this work can be easily extended to convergence rates and other
modes of convergence. This work thus makes an important step towards fully
formalizing convergent RL results. The code is available at
https://github.com/ShangtongZhang/rl-theory-in-lean.

</details>


### [200] [Financial Management System for SMEs: Real-World Deployment of Accounts Receivable and Cash Flow Prediction](https://arxiv.org/abs/2511.03631)
*Bartłomiej Małkus,Szymon Bobek,Grzegorz J. Nalepa*

Main category: cs.LG

TL;DR: 本文提出了一种针对中小企业（尤其是自由职业者和初创企业）的集成财务预测系统，结合应收账款预测与现金流预测，解决了资源有限、数据不足情况下的财务管理难题。


<details>
  <summary>Details</summary>
Motivation: 中小企业由于资源有限、客户基础小和数据稀缺，在财务管理上面临独特挑战，而现有企业级金融工具难以满足其实际需求。

Method: 系统包含两个核心部分：用于预测发票付款延迟的二分类模型，以及可处理不完整和有限历史数据的多模块现金流预测模型，并已作为Web应用集成到Cluee平台。

Result: 原型系统已在真实创业平台部署，验证了在中小企业财务管理中的可行性与实用性。

Conclusion: 该集成系统能有效适应中小企业运营限制，为自由职业者和小型企业提供切实可行的财务预测解决方案。

Abstract: Small and Medium Enterprises (SMEs), particularly freelancers and early-stage
businesses, face unique financial management challenges due to limited
resources, small customer bases, and constrained data availability. This paper
presents the development and deployment of an integrated financial prediction
system that combines accounts receivable prediction and cash flow forecasting
specifically designed for SME operational constraints. Our system addresses the
gap between enterprise-focused financial tools and the practical needs of
freelancers and small businesses. The solution integrates two key components: a
binary classification model for predicting invoice payment delays, and a
multi-module cash flow forecasting model that handles incomplete and limited
historical data. A prototype system has been implemented and deployed as a web
application with integration into Cluee's platform, a startup providing
financial management tools for freelancers, demonstrating practical feasibility
for real-world SME financial management.

</details>


### [201] [nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN](https://arxiv.org/abs/2511.03634)
*Alexander Pfefferle,Johannes Hog,Lennart Purucker,Frank Hutter*

Main category: cs.LG

TL;DR: 本文提出了nanoTabPFN，一个简化且轻量化的TabPFN v2架构实现，旨在降低表格基础模型的使用门槛，使其更易于学生和研究人员理解和应用。


<details>
  <summary>Details</summary>
Motivation: 现有的表格基础模型实现复杂、代码质量差、缺乏文档，难以理解和适应新实验，限制了其在教育和研究中的广泛应用。

Method: 设计并实现了nanoTabPFN，采用简化的架构和预生成的训练数据，构建了一个高效的训练循环。

Result: 在单个GPU上仅用一分钟预训练即可达到与传统机器学习基线相当的性能，预训练速度比TabPFN v2快160,000倍。

Conclusion: nanoTabPFN显著降低了表格基础模型的计算资源需求和使用难度，提升了其可访问性，有助于推动相关领域的教学与研究。

Abstract: Tabular foundation models such as TabPFN have revolutionized predictive
machine learning for tabular data. At the same time, the driving factors of
this revolution are hard to understand. Existing open-source tabular foundation
models are implemented in complicated pipelines boasting over 10,000 lines of
code, lack architecture documentation or code quality. In short, the
implementations are hard to understand, not beginner-friendly, and complicated
to adapt for new experiments. We introduce nanoTabPFN, a simplified and
lightweight implementation of the TabPFN v2 architecture and a corresponding
training loop that uses pre-generated training data. nanoTabPFN makes tabular
foundation models more accessible to students and researchers alike. For
example, restricted to a small data setting it achieves a performance
comparable to traditional machine learning baselines within one minute of
pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This
eliminated requirement of large computational resources makes pre-training
tabular foundation models accessible for educational purposes. Our code is
available at https://github.com/automl/nanoTabPFN.

</details>


### [202] [DQN Performance with Epsilon Greedy Policies and Prioritized Experience Replay](https://arxiv.org/abs/2511.03670)
*Daniel Perkins,Oscar J. Escobar,Luke Green*

Main category: cs.LG

TL;DR: 本研究系统分析了深度Q网络（DQN）在有限环境中的表现，重点探讨了epsilon-greedy探索策略和优先经验回放对学习效率、收敛性和奖励优化的影响。


<details>
  <summary>Details</summary>
Motivation: 理解不同探索策略和经验回放机制如何影响DQN的训练效果，特别是在资源受限环境下实现高效强化学习。

Method: 通过控制变量的系统性实验，比较不同的epsilon衰减调度和经验回放策略（均匀回放、无回放、优先回放）在多个模拟环境中的表现。

Result: 发现适当的epsilon衰减策略和优先经验回放能显著加快收敛速度并提高累积回报；同时揭示了探索与记忆管理之间的权衡关系。

Conclusion: 优先经验回放结合合理的探索调度可提升DQN在资源受限场景下的稳定性与性能，为实际应用提供了可行的优化建议。

Abstract: We present a detailed study of Deep Q-Networks in finite environments,
emphasizing the impact of epsilon-greedy exploration schedules and prioritized
experience replay. Through systematic experimentation, we evaluate how
variations in epsilon decay schedules affect learning efficiency, convergence
behavior, and reward optimization. We investigate how prioritized experience
replay leads to faster convergence and higher returns and show empirical
results comparing uniform, no replay, and prioritized strategies across
multiple simulations. Our findings illuminate the trade-offs and interactions
between exploration strategies and memory management in DQN training, offering
practical recommendations for robust reinforcement learning in
resource-constrained settings.

</details>


### [203] [SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection](https://arxiv.org/abs/2511.03661)
*Mahek Desai,Apoorva Rumale,Marjan Asadinia*

Main category: cs.LG

TL;DR: 提出了一种基于机器学习的框架，用于在医疗物联网中检测恶意网络攻击和设备异常，通过比较八种模型，发现XGBoost和KNN在性能和效率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 医疗物联网设备的安全性和可靠性面临重大挑战，容易受到网络威胁和操作异常的影响，需要有效的检测机制。

Method: 采用监督、半监督和无监督学习方法评估了八种机器学习模型（如XGBoost、KNN、GAN、VAE、Isolation Forest、LSTM Autoencoders等），使用包含20万条记录的数据集进行实验，并以F1分数、精确率、召回率、准确率、ROC-AUC和计算效率等指标进行综合评估。

Result: XGBoost在异常检测中达到99%准确率且计算开销极低（0.04秒）；Isolation Forest在精确率和召回率之间表现均衡；LSTM Autoencoders表现较差；KNN在攻击检测中接近完美的精确率、召回率和F1分数，且计算成本最低（0.05秒）；VAE达到97%准确率；GAN计算成本最高且性能最差。

Conclusion: 该框架能有效提升医疗物联网的安全性，通过早期检测网络威胁和设备故障，防止数据泄露、减少系统停机，保障医疗设备持续安全运行，增强患者对物联网医疗解决方案的信任。

Abstract: The integration of IoT devices in healthcare introduces significant security
and reliability challenges, increasing susceptibility to cyber threats and
operational anomalies. This study proposes a machine learning-driven framework
for (1) detecting malicious cyberattacks and (2) identifying faulty device
anomalies, leveraging a dataset of 200,000 records. Eight machine learning
models are evaluated across three learning approaches: supervised learning
(XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative
Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised
learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph
Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The
comprehensive evaluation was conducted across multiple metrics like F1-score,
precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost
achieved 99\% accuracy with minimal computational overhead (0.04s) for anomaly
detection, while Isolation Forest balanced precision and recall effectively.
LSTM Autoencoders underperformed with lower accuracy and higher latency. For
attack detection, KNN achieved near-perfect precision, recall, and F1-score
with the lowest computational cost (0.05s), followed by VAE at 97% accuracy.
GAN showed the highest computational cost with lowest accuracy and ROC-AUC.
These findings enhance IoT-enabled healthcare security through effective
anomaly detection strategies. By improving early detection of cyber threats and
device failures, this framework has the potential to prevent data breaches,
minimize system downtime, and ensure the continuous and safe operation of
medical devices, ultimately safeguarding patient health and trust in IoT-driven
healthcare solutions.

</details>


### [204] [Structured Matrix Scaling for Multi-Class Calibration](https://arxiv.org/abs/2511.03685)
*Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach*

Main category: cs.LG

TL;DR: 提出了一种基于逻辑回归的参数化校准方法，并通过结构化正则化、鲁棒预处理和高效优化来管理多类校准中的偏差-方差权衡，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的后验校准方法在多类分类中因模型复杂度增加和校准数据有限容易过拟合，需要更有效的校准方法。

Method: 基于逻辑回归构建参数化校准函数，引入结构化正则化、鲁棒预处理和高效优化策略以应对多类校准中的挑战。

Result: 实验表明所提方法在多种设置下显著优于标准温度缩放等现有校准技术，有效平衡偏差与方差。

Conclusion: 该方法为多类分类器的概率校准提供了高效且实用的解决方案，是温度、向量和矩阵缩放的有力替代。

Abstract: Post-hoc recalibration methods are widely used to ensure that classifiers
provide faithful probability estimates. We argue that parametric recalibration
functions based on logistic regression can be motivated from a simple
theoretical setting for both binary and multiclass classification. This insight
motivates the use of more expressive calibration methods beyond standard
temperature scaling. For multi-class calibration however, a key challenge lies
in the increasing number of parameters introduced by more complex models, often
coupled with limited calibration data, which can lead to overfitting. Through
extensive experiments, we demonstrate that the resulting bias-variance tradeoff
can be effectively managed by structured regularization, robust preprocessing
and efficient optimization. The resulting methods lead to substantial gains
over existing logistic-based calibration techniques. We provide efficient and
easy-to-use open-source implementations of our methods, making them an
attractive alternative to common temperature, vector, and matrix scaling
implementations.

</details>


### [205] [AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing](https://arxiv.org/abs/2511.03697)
*Mohsen Ahmadzadeh,Kaichang Chen,Georges Gielen*

Main category: cs.LG

TL;DR: 提出了一种基于多智能体大语言模型的模拟电路尺寸设计框架AnaFlow，实现了高效、可解释的自动化设计。


<details>
  <summary>Details</summary>
Motivation: 模拟/混合信号电路设计依赖手工，周期长且易出错，现有AI方法因仿真耗时多和缺乏可解释性而受限。

Method: 采用多代理协作的LLM架构，结合自适应仿真策略，通过人可理解的推理逐步优化电路参数。

Result: 在不同复杂度的两个电路上验证了框架的有效性，能全自动完成尺寸设计，样本效率高，并避免重复错误。

Conclusion: AnaFlow为模拟电路设计提供了高效、透明的AI辅助新范式，有望推动模拟EDA的发展。

Abstract: Analog/mixed-signal circuits are key for interfacing electronics with the
physical world. Their design, however, remains a largely handcrafted process,
resulting in long and error-prone design cycles. While the recent rise of
AI-based reinforcement learning and generative AI has created new techniques to
automate this task, the need for many time-consuming simulations is a critical
bottleneck hindering the overall efficiency. Furthermore, the lack of
explainability of the resulting design solutions hampers widespread adoption of
the tools. To address these issues, a novel agentic AI framework for
sample-efficient and explainable analog circuit sizing is presented. It employs
a multi-agent workflow where specialized Large Language Model (LLM)-based
agents collaborate to interpret the circuit topology, to understand the design
goals, and to iteratively refine the circuit's design parameters towards the
target goals with human-interpretable reasoning. The adaptive simulation
strategy creates an intelligent control that yields a high sample efficiency.
The AnaFlow framework is demonstrated for two circuits of varying complexity
and is able to complete the sizing task fully automatically, differently from
pure Bayesian optimization and reinforcement learning approaches. The system
learns from its optimization history to avoid past mistakes and to accelerate
convergence. The inherent explainability makes this a powerful tool for analog
design space exploration and a new paradigm in analog EDA, where AI agents
serve as transparent design assistants.

</details>


### [206] [Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL](https://arxiv.org/abs/2511.03695)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 本文提出了行为自适应Q学习（BAQ），通过结合离线数据中的行为一致性信号，实现从离线到在线强化学习的平稳过渡。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在部署时因分布偏移和未知状态-动作对的价值估计不可靠而在动态环境中表现不佳。

Method: BAQ利用从离线数据中隐式建模的行为策略，在线微调时采用双目标损失函数：高不确定性下对齐离线行为，随着在线经验积累逐步放松约束。

Result: 在多个基准任务上，BAQ优于先前方法，表现出更快的恢复速度、更强的鲁棒性和更高的整体性能。

Conclusion: 隐式行为自适应是一种可靠且实用的现实世界策略部署方案。

Abstract: Offline reinforcement learning (RL) enables training from fixed data without
online interaction, but policies learned offline often struggle when deployed
in dynamic environments due to distributional shift and unreliable value
estimates on unseen state-action pairs. We introduce Behavior-Adaptive
Q-Learning (BAQ), a framework designed to enable a smooth and reliable
transition from offline to online RL. The key idea is to leverage an implicit
behavioral model derived from offline data to provide a behavior-consistency
signal during online fine-tuning. BAQ incorporates a dual-objective loss that
(i) aligns the online policy toward the offline behavior when uncertainty is
high, and (ii) gradually relaxes this constraint as more confident online
experience is accumulated. This adaptive mechanism reduces error propagation
from out-of-distribution estimates, stabilizes early online updates, and
accelerates adaptation to new scenarios. Across standard benchmarks, BAQ
consistently outperforms prior offline-to-online RL approaches, achieving
faster recovery, improved robustness, and higher overall performance. Our
results demonstrate that implicit behavior adaptation is a principled and
practical solution for reliable real-world policy deployment.

</details>


### [207] [Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2511.03710)
*Guanning Zeng,Zhaoyi Zhou,Daman Arora,Andrea Zanette*

Main category: cs.LG

TL;DR: 提出使用收缩估计器（shrinkage estimators）作为控制变量来降低强化学习中策略梯度估计的方差，尤其适用于生成样本较少的场景。


<details>
  <summary>Details</summary>
Motivation: 在强化学习与可验证奖励（RLVR）中，传统方法使用每个提示的经验均值作为基线来减小方差，但在生成样本少时估计不准确，因此需要更优的均值估计方法。

Method: 受Stein悖论启发，结合单个提示和跨提示的均值，构建基于收缩估计的基线，并理论证明其能降低策略梯度估计的方差。

Result: 所提出的收缩基线显著降低了梯度更新的方差，提升了训练稳定性，且无需额外超参数或计算开销。

Conclusion: 收缩基线是一种即插即用、高效且理论支持的方法，优于传统的经验均值基线，在低生成样本条件下表现更佳。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for post-training large reasoning models (LRMs) using
policy-gradient methods such as GRPO. To stabilize training, these methods
typically center trajectory rewards by subtracting the empirical mean for each
prompt. Statistically, this centering acts as a control variate (or baseline),
reducing the variance of the policy-gradient estimator.
  Typically, the mean reward is estimated using per-prompt empirical averages
for each prompt in a batch. Drawing inspiration from Stein's paradox, we
propose using shrinkage estimators that combine per-prompt and across-prompt
means to improve the overall per-prompt mean estimation accuracy --
particularly in the low-generation regime typical of RLVR. Theoretically, we
construct a shrinkage-based baseline that provably yields lower-variance
policy-gradient estimators across algorithms. Our proposed baseline serves as a
drop-in replacement for existing per-prompt mean baselines, requiring no
additional hyper-parameters or computation. Empirically, shrinkage baselines
consistently outperform standard empirical-mean baselines, leading to
lower-variance gradient updates and improved training stability.

</details>
