<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 56]
- [cs.CL](#cs.CL) [Total: 55]
- [cs.RO](#cs.RO) [Total: 10]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 30]
- [cs.IR](#cs.IR) [Total: 23]
- [cs.LG](#cs.LG) [Total: 54]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Bi-Orthogonal Factor Decomposition for Vision Transformers](https://arxiv.org/abs/2601.05328)
*Fenil R. Doshi,Thomas Fel,Talia Konkle,George Alvarez*

Main category: cs.CV

TL;DR: 本文提出双正交因子分解（BFD）框架，通过ANOVA分解和SVD分析揭示ViT中自注意力机制如何在位置与内容维度上传递信息，发现注意力主要依赖内容交互、头与模式存在功能特化，且DINOv2在中间层兼顾位置结构保持与语义增强。


<details>
  <summary>Details</summary>
Motivation: 缺乏对视觉Transformer中自注意力机制交换何种信息（位置、内容或二者）的原理性理解，现有注意力图无法区分查询与键之间传递的是位置还是内容信息。

Method: 提出双正交因子分解（BFD）：第一阶段用ANOVA将token激活正交分解为位置与内容因子；第二阶段对QK^T矩阵进行SVD，提取表征二者交互的双正交模态。

Result: 发现：(i) 注意力能量以内容-内容交互为主，其次为内容-位置耦合，DINOv2更侧重后者且模态谱更丰富；(ii) 注意力头及内部奇异模态均呈现功能特化（内容-内容/内容-位置/位置-位置）；(iii) DINOv2优异的整体形状处理能力源于中间层同步保持位置结构并上下文增强语义内容。

Conclusion: BFD为解析ViT中token间注意力通信的信息基础（位置vs.语义）提供了可解释分析工具，并揭示了模型性能差异的机制根源。

Abstract: Self-attention is the central computational primitive of Vision Transformers, yet we lack a principled understanding of what information attention mechanisms exchange between tokens. Attention maps describe where weight mass concentrates; they do not reveal whether queries and keys trade position, content, or both. We introduce Bi-orthogonal Factor Decomposition (BFD), a two-stage analytical framework: first, an ANOVA-based decomposition statistically disentangles token activations into orthogonal positional and content factors; second, SVD of the query-key interaction matrix QK^T exposes bi-orthogonal modes that reveal how these factors mediate communication. After validating proper isolation of position and content, we apply BFD to state-of-the-art vision models and uncover three phenomena.(i) Attention operates primarily through content. Content-content interactions dominate attention energy, followed by content-position coupling. DINOv2 allocates more energy to content-position than supervised models and distributes computation across a richer mode spectrum. (ii) Attention mechanisms exhibit specialization: heads differentiate into content-content, content-position, and position-position operators, while singular modes within heads show analogous specialization. (iii) DINOv2's superior holistic shape processing emerges from intermediate layers that simultaneously preserve positional structure while contextually enriching semantic content.
  Overall, BFD exposes how tokens interact through attention and which informational factors - positional or semantic - mediate their communication, yielding practical insights into vision transformer mechanisms.

</details>


### [2] [Sketch&Patch++: Efficient Structure-Aware 3D Gaussian Representation](https://arxiv.org/abs/2601.05394)
*Yuang Shi,Simone Gasparini,Géraldine Morin,Wei Tsang Ooi*

Main category: cs.CV

TL;DR: 本文提出一种基于高斯分布的分层自适应分类框架，将高斯分为Sketch（刻画边缘轮廓）和Patch（覆盖平滑区域）两类，实现语义分离与渐进式流式传输，在压缩率和渲染质量上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 受传统绘画技法启发，观察到3D高斯在场景表示中具有类似‘草图’与‘色块’的不同角色，需语义区分以提升编码效率与渐进传输能力。

Method: 提出分层自适应分类框架：通过多准则密度聚类与质量驱动的自适应细化，直接在3D高斯溅射（3DGS）表示上实现Sketch/ Patch高斯的语义划分，无需依赖外部3D线特征。

Result: 在多种场景测试中，相比均匀剪枝基线，PSNR提升1.74 dB、SSIM提升6.7%、LPIPS改善41.4%；室内场景仅用0.5%原始模型大小即可保持视觉质量。

Conclusion: 该结构感知表示支持高效存储、自适应流式传输与高保真渲染，适用于带宽受限网络与资源受限设备。

Abstract: We observe that Gaussians exhibit distinct roles and characteristics analogous to traditional artistic techniques -- like how artists first sketch outlines before filling in broader areas with color, some Gaussians capture high-frequency features such as edges and contours, while others represent broader, smoother regions analogous to brush strokes that add volume and depth. Based on this observation, we propose a hybrid representation that categorizes Gaussians into (i) Sketch Gaussians, which represent high-frequency, boundary-defining features, and (ii) Patch Gaussians, which cover low-frequency, smooth regions. This semantic separation naturally enables layered progressive streaming, where the compact Sketch Gaussians establish the structural skeleton before Patch Gaussians incrementally refine volumetric detail.
  In this work, we extend our previous method to arbitrary 3D scenes by proposing a novel hierarchical adaptive categorization framework that operates directly on the 3DGS representation. Our approach employs multi-criteria density-based clustering, combined with adaptive quality-driven refinement. This method eliminates dependency on external 3D line primitives while ensuring optimal parametric encoding effectiveness. Our comprehensive evaluation across diverse scenes, including both man-made and natural environments, demonstrates that our method achieves up to 1.74 dB improvement in PSNR, 6.7% in SSIM, and 41.4% in LPIPS at equivalent model sizes compared to uniform pruning baselines. For indoor scenes, our method can maintain visual quality with only 0.5\% of the original model size. This structure-aware representation enables efficient storage, adaptive streaming, and rendering of high-fidelity 3D content across bandwidth-constrained networks and resource-limited devices.

</details>


### [3] [Coding the Visual World: From Image to Simulation Using Vision Language Models](https://arxiv.org/abs/2601.05344)
*Sagi Eppel*

Main category: cs.CV

TL;DR: 本文提出Im2Sim方法，评估视觉语言模型（VLMs）从自然图像中理解并生成模拟代码以重建系统的能力，发现其具备跨领域、多层抽象的高层次建模能力，但细节复现能力有限。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型是否真正理解图像中所描绘的系统与机制，而不仅是表面模式匹配；将视觉理解定义为构建代表性内在模型的能力。

Method: 提出Im2Sim方法：给定真实世界系统的自然图像，要求VLM描述该系统并生成可执行的模拟代码，运行代码生成合成图像，并与原图对比评估；测试对象包括波浪、云、城市、植被等复杂涌现系统。

Result: GPT、Gemini等主流VLM能成功建模多层抽象、跨领域的复杂系统，展现出深层视觉理解能力；但在复现图像细粒度结构和低层纹理模式方面表现较弱。

Conclusion: VLMs表现出‘高层理解强、底层感知弱’的不对称能力，提示其视觉理解更依赖语义与机制建模，而非像素级感知。

Abstract: The ability to construct mental models of the world is a central aspect of understanding. Similarly, visual understanding can be viewed as the ability to construct a representative model of the system depicted in an image. This work explores the capacity of Vision Language Models (VLMs) to recognize and simulate the systems and mechanisms depicted in images using the Im2Sim methodology. The VLM is given a natural image of a real-world system (e.g., cities, clouds, vegetation) and is tasked with describing the system and writing code that simulates and generates it. This generative code is then executed to produce a synthetic image, which is compared against the original. This approach is tested on various complex emergent systems, ranging from physical systems (waves, lights, clouds) to vegetation, cities, materials, and geological formations. Through analysis of the models and images generated by the VLMs, we examine their understanding of the systems in images. The results show that leading VLMs (GPT, Gemini) demonstrate the capacity to understand and model complex, multi-component systems across multiple layers of abstraction and a wide range of domains. At the same time, the VLMs exhibit limited ability to replicate fine details and low-level arrangements of patterns in the image. These findings reveal an interesting asymmetry: VLMs combine high-level, deep visual understanding of images with limited perception of fine details.

</details>


### [4] [LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting](https://arxiv.org/abs/2601.05853)
*Yinghan Xu,John Dingliana*

Main category: cs.CV

TL;DR: 本文提出了一种基于2D高斯编码与扩散模型修复的多层3D人体重建框架，实现身体与衣物的分离建模与高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 现有单层重建方法将衣物绑定于特定身份，而多层方法难以处理遮挡区域，限制了虚拟试穿与高保真3D人体资产生成。

Method: 将每层（身体/衣物）编码为2D高斯集合以实现几何与渲染精度；利用预训练2D扩散模型结合score-distillation sampling（SDS）修复被遮挡区域；采用三阶段训练策略：先粗略单层重建服装，再联合优化内外层细节。

Result: 在4D-Dress和Thuman2.0数据集上，渲染质量、层分解与重组能力均优于SOTA，支持新视角与新姿态下的真实感虚拟试穿。

Conclusion: 该方法有效解决了多层人体建模中的遮挡与身份耦合问题，推动了沉浸式应用中高保真可驱动3D人体资产的实用化构建。

Abstract: We propose a novel framework for decomposing arbitrarily posed humans into animatable multi-layered 3D human avatars, separating the body and garments. Conventional single-layer reconstruction methods lock clothing to one identity, while prior multi-layer approaches struggle with occluded regions. We overcome both limitations by encoding each layer as a set of 2D Gaussians for accurate geometry and photorealistic rendering, and inpainting hidden regions with a pretrained 2D diffusion model via score-distillation sampling (SDS). Our three-stage training strategy first reconstructs the coarse canonical garment via single-layer reconstruction, followed by multi-layer training to jointly recover the inner-layer body and outer-layer garment details. Experiments on two 3D human benchmark datasets (4D-Dress, Thuman2.0) show that our approach achieves better rendering quality and layer decomposition and recomposition than the previous state-of-the-art, enabling realistic virtual try-on under novel viewpoints and poses, and advancing practical creation of high-fidelity 3D human assets for immersive applications. Our code is available at https://github.com/RockyXu66/LayerGS

</details>


### [5] [STResNet & STYOLO : A New Family of Compact Classification and Object Detection Models for MCUs](https://arxiv.org/abs/2601.05364)
*Sudhakar Sah,Ravish Kumar*

Main category: cs.CV

TL;DR: 本文提出了两个轻量级模型系列STResNet和STYOLO，分别用于图像分类和目标检测，在资源受限设备上实现了精度、效率和内存占用的联合优化。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级神经网络在边缘设备部署时往往以精度换取延迟，限制了其在微控制器和神经处理单元上的应用。

Method: 设计了STResNet（图像分类）和STYOLO（目标检测）两个新模型系列，并针对准确率、效率和内存占用进行联合优化。

Result: STResNetMilli在仅300万参数下达到70.0% ImageNet Top-1精度；STYOLOMicro和STYOLOMilli在MS COCO上分别达到30.5%和33.6% mAP，均优于YOLOv5n和YOLOX Nano。

Conclusion: 所提模型在资源受限平台上实现了精度与效率的更好平衡，适用于边缘AI部署。

Abstract: Recent advancements in lightweight neural networks have significantly improved the efficiency of deploying deep learning models on edge hardware. However, most existing architectures still trade accuracy for latency, which limits their applicability on microcontroller and neural processing unit based devices. In this work, we introduce two new model families, STResNet for image classification and STYOLO for object detection, jointly optimized for accuracy, efficiency, and memory footprint on resource constrained platforms. The proposed STResNet series, ranging from Nano to Tiny variants, achieves competitive ImageNet 1K accuracy within a four million parameter budget. Specifically, STResNetMilli attains 70.0 percent Top 1 accuracy with only three million parameters, outperforming MobileNetV1 and ShuffleNetV2 at comparable computational complexity. For object detection, STYOLOMicro and STYOLOMilli achieve 30.5 percent and 33.6 percent mean average precision, respectively, on the MS COCO dataset, surpassing YOLOv5n and YOLOX Nano in both accuracy and efficiency. Furthermore, when STResNetMilli is used as a backbone with the Ultralytics training environment.

</details>


### [6] [MOSAIC-GS: Monocular Scene Reconstruction via Advanced Initialization for Complex Dynamic Environments](https://arxiv.org/abs/2601.05368)
*Svitlana Morkva,Maximum Wilder-Smith,Michael Oechsle,Alessio Tonioni,Marco Hutter,Vaishakh Patil*

Main category: cs.CV

TL;DR: MOSAIC-GS是一种基于高斯泼溅的单目动态场景重建新方法，通过融合多几何线索与刚性运动约束实现高效、高保真重建。


<details>
  <summary>Details</summary>
Motivation: 单目重建因缺乏多视角约束而病态，难以准确恢复物体几何与时间一致性。

Method: 提出MOSAIC-GS：利用深度、光流、动态分割和点跟踪等几何线索，结合刚性运动约束初始化场景动力学；将场景分解为静态/动态部分；动态高斯用时变Poly-Fourier曲线建模轨迹以支持非刚性形变。

Result: 在标准单目动态场景基准上，优化与渲染速度显著快于现有方法，重建质量达当前最优水平。

Conclusion: MOSAIC-GS实现了显式、高效、高质量的单目动态场景重建，兼顾紧凑表示、快速训练与实时渲染能力。

Abstract: We present MOSAIC-GS, a novel, fully explicit, and computationally efficient approach for high-fidelity dynamic scene reconstruction from monocular videos using Gaussian Splatting. Monocular reconstruction is inherently ill-posed due to the lack of sufficient multiview constraints, making accurate recovery of object geometry and temporal coherence particularly challenging. To address this, we leverage multiple geometric cues, such as depth, optical flow, dynamic object segmentation, and point tracking. Combined with rigidity-based motion constraints, these cues allow us to estimate preliminary 3D scene dynamics during an initialization stage. Recovering scene dynamics prior to the photometric optimization reduces reliance on motion inference from visual appearance alone, which is often ambiguous in monocular settings. To enable compact representations, fast training, and real-time rendering while supporting non-rigid deformations, the scene is decomposed into static and dynamic components. Each Gaussian in the dynamic part of the scene is assigned a trajectory represented as time-dependent Poly-Fourier curve for parameter-efficient motion encoding. We demonstrate that MOSAIC-GS achieves substantially faster optimization and rendering compared to existing methods, while maintaining reconstruction quality on par with state-of-the-art approaches across standard monocular dynamic scene benchmarks.

</details>


### [7] [Ensemble of radiomics and ConvNeXt for breast cancer diagnosis](https://arxiv.org/abs/2601.05373)
*Jorge Alberto Garza-Abdala,Gerardo Alejandro Fumagal-González,Beatriz A. Bosques-Palomo,Mario Alexis Monsivais Molina,Daly Avedano,Servando Cardona-Huerta,José Gerardo Tamez-Pena*

Main category: cs.CV

TL;DR: 本文评估了放射组学、深度学习（DL）及二者集成方法在乳腺癌筛查钼靶影像诊断中的性能，结果表明集成方法AUC最高（0.87），优于单独DL（0.83）和放射组学（0.80）。


<details>
  <summary>Details</summary>
Motivation: 早期乳腺癌诊断对提高生存率至关重要，放射组学与深度学习在辅助放射科医生早期检测中展现出潜力，但需系统比较其性能。

Method: 在RSNA 2023（11,913例）和墨西哥TecSalud（19,400例）两个独立数据集上，分别训练ConvNeXtV1-small模型（RSNA→TecSalud迁移）和放射组学模型（TecSalud内leave-one-year-out验证），并采用统一方法集成校准二者预测。

Result: 集成方法AUC达0.87，显著高于ConvNeXtV1-small（0.83）和放射组学（0.80）。

Conclusion: 融合深度学习与放射组学的集成方法可显著提升乳腺癌钼靶影像诊断性能。

Abstract: Early diagnosis of breast cancer is crucial for improving survival rates. Radiomics and deep learning (DL) have shown significant potential in assisting radiologists with early cancer detection. This paper aims to critically assess the performance of radiomics, DL, and ensemble techniques in detecting cancer from screening mammograms. Two independent datasets were used: the RSNA 2023 Breast Cancer Detection Challenge (11,913 patients) and a Mexican cohort from the TecSalud dataset (19,400 patients). The ConvNeXtV1-small DL model was trained on the RSNA dataset and validated on the TecSalud dataset, while radiomics models were developed using the TecSalud dataset and validated with a leave-one-year-out approach. The ensemble method consistently combined and calibrated predictions using the same methodology. Results showed that the ensemble approach achieved the highest area under the curve (AUC) of 0.87, compared to 0.83 for ConvNeXtV1-small and 0.80 for radiomics. In conclusion, ensemble methods combining DL and radiomics predictions significantly enhance breast cancer diagnosis from mammograms.

</details>


### [8] [EdgeLDR: Quaternion Low-Displacement Rank Neural Networks for Edge-Efficient Deep Learning](https://arxiv.org/abs/2601.05379)
*Vladimir Frants,Sos Agaian,Karen Panetta*

Main category: cs.CV

TL;DR: 本文提出EdgeLDR框架，将四元数神经网络与分块循环矩阵结构结合，并利用复共轭表示实现FFT加速计算，在边缘设备上实现高参数效率与低延迟的平衡。


<details>
  <summary>Details</summary>
Motivation: 边缘设备部署深度神经网络受限于密集线性算子的内存访问和计算开销；现有四元数网络虽提升参数效率但权重仍稠密，而结构化矩阵多用于实数域，缺乏在四元数域的有效结合方案。

Method: 提出基于四元数分块循环结构的线性和卷积层（EdgeLDR），利用复共轭表示支持FFT加速计算；提供参考实现并对比FFT与朴素空间域实现的性能；将其集成至轻量CNN和Transformer模型中，在多个图像分类任务上评估精度-压缩权衡。

Result: FFT实现相比朴素方法显著提速且延迟随分块尺寸增长保持稳定；在CIFAR、SVHN及高光谱数据集上，EdgeLDR在大幅压缩参数量的同时维持有竞争力的分类精度，并降低CPU/GPU延迟。

Conclusion: EdgeLDR成功融合四元数通道混合与结构化参数设计，为边缘AI提供了兼顾模型压缩、计算效率与精度的实用解决方案。

Abstract: Deploying deep neural networks on edge devices is often limited by the memory traffic and compute cost of dense linear operators. While quaternion neural networks improve parameter efficiency by coupling multiple channels through Hamilton products, they typically retain unstructured dense weights; conversely, structured matrices enable fast computation but are usually applied in the real domain. This paper introduces EdgeLDR, a practical framework for quaternion block-circulant linear and convolutional layers that combines quaternion channel mixing with block-circulant parameter structure and enables FFT-based evaluation through the complex adjoint representation. We present reference implementations of EdgeLDR layers and compare FFT-based computation against a naive spatial-domain realization of quaternion circulant products. FFT evaluation yields large empirical speedups over the naive implementation and keeps latency stable as block size increases, making larger compression factors computationally viable. We further integrate EdgeLDR layers into compact CNN and Transformer backbones and evaluate accuracy-compression trade-offs on 32x32 RGB classification (CIFAR-10/100, SVHN) and hyperspectral image classification (Houston 2013, Pavia University), reporting parameter counts and CPU/GPU latency. The results show that EdgeLDR layers provide significant compression with competitive accuracy.

</details>


### [9] [Multi-task Cross-modal Learning for Chest X-ray Image Retrieval](https://arxiv.org/abs/2601.05399)
*Zhaohui Liang,Sivaramakrishnan Rajaraman,Niccolo Marini,Zhiyun Xue,Sameer Antani*

Main category: cs.CV

TL;DR: 本文提出了一种多任务学习框架来微调BiomedCLIP，以提升胸部X光图像与放射科报告之间的细粒度跨模态检索性能，通过引入轻量MLP投影头和复合损失函数（二元交叉熵、监督对比损失和CLIP损失），显著增强了模型在临床相关性、语义聚类和诊断敏感性方面的表现。


<details>
  <summary>Details</summary>
Motivation: CLIP和BiomedCLIP虽具备强跨模态表征能力，但未针对细粒度医学检索任务（如基于胸片检索临床相关放射报告）进行优化。

Method: 以BiomedCLIP为骨干，添加轻量MLP投影头，并采用包含二元交叉熵损失（区分正常/异常胸片）、监督对比损失（增强类内一致性）和CLIP损失（保持跨模态对齐）的多任务复合损失函数进行微调。

Result: 微调后模型在图像到文本和文本到图像检索任务中均展现出更均衡、更具临床意义的性能；t-SNE可视化显示正常与异常病例语义聚类更清晰，诊断敏感性提升。

Conclusion: 面向领域的多任务学习可有效提升生物医学跨模态检索性能，对推动临床AI应用具有重要价值。

Abstract: CLIP and BiomedCLIP are examples of vision-language foundation models and offer strong cross-modal embeddings; however, they are not optimized for fine-grained medical retrieval tasks, such as retrieving clinically relevant radiology reports using chest X-ray (CXR) image queries. To address this shortcoming, we propose a multi-task learning framework to fine-tune BiomedCLIP and evaluate improvements to CXR image-text retrieval. Using BiomedCLIP as the backbone, we incorporate a lightweight MLP projector head trained with a multi-task composite loss function that includes: (1) a binary cross-entropy loss to distinguish normal from abnormal CXR studies, (2) a supervised contrastive loss to reinforce intra-class consistency, and (3) a CLIP loss to maintain cross-modal alignment. Experimental results demonstrate that the fine-tuned model achieves more balanced and clinically meaningful performance across both image-to-text and text-to-image retrieval tasks compared to the pretrained BiomedCLIP and general-purpose CLIP models. Furthermore, t-SNE visualizations reveal clearer semantic clustering of normal and abnormal cases, demonstrating the model's enhanced diagnostic sensitivity. These findings highlight the value of domain-adaptive, multi-task learning for advancing cross-modal retrieval in biomedical applications.

</details>


### [10] [Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization](https://arxiv.org/abs/2601.05432)
*Yuxiang Ji,Yong Wang,Ziyu Ma,Yiming Hu,Hailang Huang,Xuecai Hu,Guanhua Chen,Liaoni Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出了一种结合地图推理的图像地理定位新方法，通过‘在地图中思考’的代理循环框架，结合强化学习与并行测试时缩放，在真实世界图像基准MAPBench上显著提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型在图像地理定位任务中忽略了人类常用的地图辅助策略，缺乏对空间地理推理的有效建模。

Method: 提出‘Thinking with Map’能力，构建代理-地图交互循环；采用两阶段优化：先用代理式强化学习提升采样效率，再用并行测试时缩放（TTS）探索多条候选路径以提升最终预测准确性；并构建全新真实世界基准MAPBench。

Result: 在MAPBench上显著超越现有开源与闭源模型，Acc@500m指标从Gemini-3-Pro的8.0%提升至22.1%。

Conclusion: 将地图作为显式推理媒介并引入代理式、并行化测试时优化，是提升图像地理定位性能的有效范式。

Abstract: The image geolocalization task aims to predict the location where an image was taken anywhere on Earth using visual clues. Existing large vision-language model (LVLM) approaches leverage world knowledge, chain-of-thought reasoning, and agentic capabilities, but overlook a common strategy used by humans -- using maps. In this work, we first equip the model \textit{Thinking with Map} ability and formulate it as an agent-in-the-map loop. We develop a two-stage optimization scheme for it, including agentic reinforcement learning (RL) followed by parallel test-time scaling (TTS). The RL strengthens the agentic capability of model to improve sampling efficiency, and the parallel TTS enables the model to explore multiple candidate paths before making the final prediction, which is crucial for geolocalization. To evaluate our method on up-to-date and in-the-wild images, we further present MAPBench, a comprehensive geolocalization training and evaluation benchmark composed entirely of real-world images. Experimental results show that our method outperforms existing open- and closed-source models on most metrics, specifically improving Acc@500m from 8.0\% to 22.1\% compared to \textit{Gemini-3-Pro} with Google Search/Map grounded mode.

</details>


### [11] [FlyPose: Towards Robust Human Pose Estimation From Aerial Views](https://arxiv.org/abs/2601.05747)
*Hassaan Farooq,Marvin Brenner,Peter St\ütz*

Main category: cs.CV

TL;DR: 本文提出FlyPose，一种轻量级的自上而下的人体姿态估计方法，专为无人机航拍图像设计，在多个数据集上显著提升检测与姿态估计精度，并实现实时机载部署。


<details>
  <summary>Details</summary>
Motivation: 无人机在人群附近作业（如快递、交通监控）需准确感知人体姿态与行为，但航拍视角存在低分辨率、大俯角和自遮挡等挑战，且需满足实时性要求。

Method: 提出轻量级FlyPose模型，采用多数据集联合训练策略，并发布新数据集FlyPose-104以支持航拍人体姿态估计研究。

Result: 在Manipal-UAV、VisDrone、HIT-UAV及自建数据集上人检测平均mAP提升6.8；在UAV-Human数据集上2D姿态估计mAP提升16.3；在Jetson Orin AGX上推理延迟约20ms，并成功在四旋翼无人机上实现实时飞行部署。

Conclusion: FlyPose有效应对航拍视角下人体姿态估计的关键挑战，兼具高精度与实时性，推动了无人机在人机共融场景中的安全自主运行。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in close proximity to humans for applications such as parcel delivery, traffic monitoring, disaster response and infrastructure inspections. Ensuring safe and reliable operation in these human-populated environments demands accurate perception of human poses and actions from an aerial viewpoint. This perspective challenges existing methods with low resolution, steep viewing angles and (self-)occlusion, especially if the application demands realtime feasibile models. We train and deploy FlyPose, a lightweight top-down human pose estimation pipeline for aerial imagery. Through multi-dataset training, we achieve an average improvement of 6.8 mAP in person detection across the test-sets of Manipal-UAV, VisDrone, HIT-UAV as well as our custom dataset. For 2D human pose estimation we report an improvement of 16.3 mAP on the challenging UAV-Human dataset. FlyPose runs with an inference latency of ~20 milliseconds including preprocessing on a Jetson Orin AGX Developer Kit and is deployed onboard a quadrotor UAV during flight experiments. We also publish FlyPose-104, a small but challenging aerial human pose estimation dataset, that includes manual annotations from difficult aerial perspectives: https://github.com/farooqhassaan/FlyPose.

</details>


### [12] [TAPM-Net: Trajectory-Aware Perturbation Modeling for Infrared Small Target Detection](https://arxiv.org/abs/2601.05446)
*Hongyang Xie,Hongyang He,Victor Sanchez*

Main category: cs.CV

TL;DR: 本文提出TAPM-Net，一种基于Mamba架构的红外小目标检测方法，通过建模目标引发的特征扰动空间传播轨迹，在NUAA-SIRST和IRSTD-1K数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有CNN和ViT模型缺乏对小目标在特征空间中引发的层间定向扰动传播路径的建模能力，而该路径是区分红外图像中目标信号与结构化噪声的关键线索。

Method: 提出Trajectory-Aware Mamba Propagation Network（TAPM-Net），包含两个核心模块：扰动引导路径模块（PGM）构建扰动能量场并提取梯度跟随的特征轨迹；轨迹感知状态块（TASB）基于Mamba架构，沿轨迹建模动态传播，并融合词级与句级语义嵌入，引入速度约束扩散机制。

Result: 在NUAA-SIRST和IRSTD-1K数据集上，TAPM-Net在检测精度等指标上达到当前最优（state-of-the-art）水平。

Conclusion: TAPM-Net通过显式建模目标诱导的特征扰动传播轨迹，实现了各向异性、上下文敏感且计算高效的小目标检测，为红外图像分析提供了新范式。

Abstract: Infrared small target detection (ISTD) remains a long-standing challenge due to weak signal contrast, limited spatial extent, and cluttered backgrounds. Despite performance improvements from convolutional neural networks (CNNs) and Vision Transformers (ViTs), current models lack a mechanism to trace how small targets trigger directional, layer-wise perturbations in the feature space, which is an essential cue for distinguishing signal from structured noise in infrared scenes. To address this limitation, we propose the Trajectory-Aware Mamba Propagation Network (TAPM-Net), which explicitly models the spatial diffusion behavior of target-induced feature disturbances. TAPM-Net is built upon two novel components: a Perturbation-guided Path Module (PGM) and a Trajectory-Aware State Block (TASB). The PGM constructs perturbation energy fields from multi-level features and extracts gradient-following feature trajectories that reflect the directionality of local responses. The resulting feature trajectories are fed into the TASB, a Mamba-based state-space unit that models dynamic propagation along each trajectory while incorporating velocity-constrained diffusion and semantically aligned feature fusion from word-level and sentence-level embeddings. Unlike existing attention-based methods, TAPM-Net enables anisotropic, context-sensitive state transitions along spatial trajectories while maintaining global coherence at low computational cost. Experiments on NUAA-SIRST and IRSTD-1K demonstrate that TAPM-Net achieves state-of-the-art performance in ISTD.

</details>


### [13] [SceneFoundry: Generating Interactive Infinite 3D Worlds](https://arxiv.org/abs/2601.05810)
*ChunTeng Chen,YiChen Hsu,YiWen Liu,WeiFang Sun,TsaiChing Ni,ChunYi Lee,Min Sun,YuanFu Yang*

Main category: cs.CV

TL;DR: 本文提出SceneFoundry，一种语言引导的扩散框架，用于生成具有功能化可动家具和语义多样布局的大规模3D室内环境，以支持机器人训练。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法难以准确建模真实室内环境中具有可动部件的结构化、功能性物体，限制了机器人学习与具身智能的发展。

Method: 结合大语言模型（LLM）控制平面布局生成，并利用基于扩散的后验采样从大规模3D库中填充可动资产；引入可微引导函数确保物体数量合理、避免关节碰撞、保留足够可行走空间。

Result: 实验表明SceneFoundry能生成结构有效、语义连贯、功能可交互的多样化公寓级3D场景，适用于不同场景类型与条件。

Conclusion: SceneFoundry为具身AI研究提供了可扩展、物理可用且语言可控的3D环境生成新范式。

Abstract: The ability to automatically generate large-scale, interactive, and physically realistic 3D environments is crucial for advancing robotic learning and embodied intelligence. However, existing generative approaches often fail to capture the functional complexity of real-world interiors, particularly those containing articulated objects with movable parts essential for manipulation and navigation. This paper presents SceneFoundry, a language-guided diffusion framework that generates apartment-scale 3D worlds with functionally articulated furniture and semantically diverse layouts for robotic training. From natural language prompts, an LLM module controls floor layout generation, while diffusion-based posterior sampling efficiently populates the scene with articulated assets from large-scale 3D repositories. To ensure physical usability, SceneFoundry employs differentiable guidance functions to regulate object quantity, prevent articulation collisions, and maintain sufficient walkable space for robotic navigation. Extensive experiments demonstrate that our framework generates structurally valid, semantically coherent, and functionally interactive environments across diverse scene types and conditions, enabling scalable embodied AI research.

</details>


### [14] [ROAP: A Reading-Order and Attention-Prior Pipeline for Optimizing Layout Transformers in Key Information Extraction](https://arxiv.org/abs/2601.05470)
*Tingwei Xie,Jinxin He,Yonghong Song*

Main category: cs.CV

TL;DR: 本文提出ROAP方法，通过自适应提取阅读顺序并引入阅读顺序感知的相对位置偏置和文本标记子块注意力先验，提升多模态文档理解中布局Transformer的性能，无需修改预训练主干网络。


<details>
  <summary>Details</summary>
Motivation: 现有多模态Transformer在视觉丰富文档理解中受限于未显式建模逻辑阅读顺序以及视觉token干扰导致文本语义注意力稀释。

Method: 提出轻量级、架构无关的ROAP流程：1）用AXG-Tree鲁棒提取层级化阅读序列；2）通过RO-RPB将序列融入注意力机制；3）引入TT-Prior自适应抑制视觉噪声、增强文本间细粒度交互。

Result: 在FUNSD和CORD数据集上，ROAP显著提升了LayoutLMv3和GeoLayoutLM等主流模型的性能。

Conclusion: 显式建模阅读逻辑与调控模态干扰对鲁棒文档理解至关重要，ROAP为复杂版面分析提供了可扩展解决方案。

Abstract: The efficacy of Multimodal Transformers in visually-rich document understanding (VrDU) is critically constrained by two inherent limitations: the lack of explicit modeling for logical reading order and the interference of visual tokens that dilutes attention on textual semantics.
  To address these challenges, this paper presents ROAP, a lightweight and architecture-agnostic pipeline designed to optimize attention distributions in Layout Transformers without altering their pre-trained backbones.
  The proposed pipeline first employs an Adaptive-XY-Gap (AXG-Tree) to robustly extract hierarchical reading sequences from complex layouts. These sequences are then integrated into the attention mechanism via a Reading-Order-Aware Relative Position Bias (RO-RPB). Furthermore, a Textual-Token Sub-block Attention Prior (TT-Prior) is introduced to adaptively suppress visual noise and enhance fine-grained text-text interactions.
  Extensive experiments on the FUNSD and CORD benchmarks demonstrate that ROAP consistently improves the performance of representative backbones, including LayoutLMv3 and GeoLayoutLM.
  These findings confirm that explicitly modeling reading logic and regulating modality interference are critical for robust document understanding, offering a scalable solution for complex layout analysis. The implementation code will be released at https://github.com/KevinYuLei/ROAP.

</details>


### [15] [Multi-Image Super Resolution Framework for Detection and Analysis of Plant Roots](https://arxiv.org/abs/2601.05482)
*Shubham Agarwal,Ofek Nourian,Michael Sidorov,Sharon Chemweno,Ofer Hadar,Naftali Lazarovitch,Jhonathan E. Ephrath*

Main category: cs.CV

TL;DR: 本文提出了一种结合多视角成像与深度学习多图像超分辨率（MISR）的新方法，用于提升地下植物根系图像的清晰度与结构保真度，并在合成数据集上验证其在根毛数量与密度等性状量化中的有效性。


<details>
  <summary>Details</summary>
Motivation: 地下根系成像面临遮挡、土壤湿度变化和低对比度等挑战，传统视觉方法效果受限。

Method: 构建多视角地下成像系统，并设计基于空间冗余的深度学习MISR框架；使用包含真实环境因素的合成数据集进行训练与评估。

Result: 相比现有超分辨率方法，BRISQUE降低2.3%，CLIP-IQA保持不变，显著提升根系图像质量，支持更准确的根毛计数与密度估计。

Conclusion: 该框架为农业与生态研究中鲁棒、自动的地下根系成像与性状量化提供了新方向。

Abstract: Understanding plant root systems is critical for advancing research in soil-plant interactions, nutrient uptake, and overall plant health. However, accurate imaging of roots in subterranean environments remains a persistent challenge due to adverse conditions such as occlusion, varying soil moisture, and inherently low contrast, which limit the effectiveness of conventional vision-based approaches. In this work, we propose a novel underground imaging system that captures multiple overlapping views of plant roots and integrates a deep learning-based Multi-Image Super Resolution (MISR) framework designed to enhance root visibility and detail. To train and evaluate our approach, we construct a synthetic dataset that simulates realistic underground imaging scenarios, incorporating key environmental factors that affect image quality. Our proposed MISR algorithm leverages spatial redundancy across views to reconstruct high-resolution images with improved structural fidelity and visual clarity. Quantitative evaluations show that our approach outperforms state-of-the-art super resolution baselines, achieving a 2.3 percent reduction in BRISQUE, indicating improved image quality with the same CLIP-IQA score, thereby enabling enhanced phenotypic analysis of root systems. This, in turn, facilitates accurate estimation of critical root traits, including root hair count and root hair density. The proposed framework presents a promising direction for robust automatic underground plant root imaging and trait quantification for agricultural and ecological research.

</details>


### [16] [Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals](https://arxiv.org/abs/2601.05848)
*Nate Gillman,Yinghua Zhou,Zitian Tang,Evan Luo,Arjan Chakravarthy,Daksh Aggarwal,Michael Freeman,Charles Herrmann,Chen Sun*

Main category: cs.CV

TL;DR: 本文提出Goal Force框架，通过力向量和中间动力学定义目标，训练视频生成模型学习物理因果关系，在零样本下泛化到复杂真实场景，实现无需外部引擎的物理感知规划。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成世界模型难以精确指定目标：文本指令过于抽象，目标图像难以用于动态任务。

Method: 提出Goal Force框架，用显式力向量和中间动力学定义目标；在合成因果原语（如弹性碰撞、多米诺骨牌倒下）数据集上训练视频生成模型，使其学会时空中的力传播。

Result: 模型在简单物理数据上训练，却展现出对工具操作、多物体因果链等复杂真实场景的零样本泛化能力。

Conclusion: 将视频生成扎根于基础物理交互，可使模型成为隐式的神经物理模拟器，实现精准、物理感知的规划，无需依赖外部物理引擎。

Abstract: Recent advancements in video generation have enabled the development of ``world models'' capable of simulating potential futures for robotics and planning. However, specifying precise goals for these models remains a challenge; text instructions are often too abstract to capture physical nuances, while target images are frequently infeasible to specify for dynamic tasks. To address this, we introduce Goal Force, a novel framework that allows users to define goals via explicit force vectors and intermediate dynamics, mirroring how humans conceptualize physical tasks. We train a video generation model on a curated dataset of synthetic causal primitives-such as elastic collisions and falling dominos-teaching it to propagate forces through time and space. Despite being trained on simple physics data, our model exhibits remarkable zero-shot generalization to complex, real-world scenarios, including tool manipulation and multi-object causal chains. Our results suggest that by grounding video generation in fundamental physical interactions, models can emerge as implicit neural physics simulators, enabling precise, physics-aware planning without reliance on external engines. We release all datasets, code, model weights, and interactive video demos at our project page.

</details>


### [17] [Hippocampal Atrophy Patterns Across the Alzheimer's Disease Spectrum: A Voxel-Based Morphometry Analysis](https://arxiv.org/abs/2601.05494)
*Trishna Niraula*

Main category: cs.CV

TL;DR: 本研究利用CAT12/SPM12对ADNI数据集的T1加权MRI进行基于体素的形态学分析，发现阿尔茨海默病（AD）患者海马体积显著萎缩，且海马体积对轻度认知障碍（MCI）向AD转化具有一定预测能力（AUC=0.66），但APOE4状态未显著影响海马体积。


<details>
  <summary>Details</summary>
Motivation: 探究阿尔茨海默病（AD）和轻度认知障碍（MCI）中灰质（尤其是内侧颞叶结构）进行性丢失的特征，并评估海马体积作为疾病进展与转化预测生物标志物及遗传影响的价值。

Method: 采用CAT12/SPM12进行基于体素的形态学分析（VBM），对249名ADNI参与者（CN=90，MCI=129，AD=30）的基线T1加权MRI扫描进行灰质体积分析；使用一般线性模型，以诊断组为主要预测变量，年龄和全颅内体积为协变量；统计图经体素水平p<0.001、簇水平FWE校正p<0.05阈值处理。

Result: AD组相对于CN组和MCI组均表现出显著海马萎缩（Cohen's d分别为2.03和1.61）；海马体积对MCI向AD转化具有中等预测能力（AUC=0.66）；APOE4分层分析未显示其对横断面海马体积有显著影响。

Conclusion: 支持内侧颞叶退变是AD进展的关键特征，提示海马体积可作为潜在预测生物标志物，而APOE4在此样本中未显著影响海马结构。

Abstract: Alzheimer's disease (AD) and mild cognitive impairment (MCI) are associated with progressive gray matter loss, particularly in medial temporal structures. In this study, CAT12/SPM12 voxel-based morphometry was applied to baseline T1-weighted MRI scans from 249 ADNI participants (CN = 90, MCI = 129, AD = 30). Gray matter volume was analyzed using a general linear model, with the diagnostic group as primary predictor and age and total intracranial volume as covariates. Statistical maps were thresholded at p < 0.001 (voxelwise) and corrected for multiple comparisons at the cluster level using family-wise error (FWE) correction (p < 0.05). Significant hippocampal atrophy was observed in AD relative to CN and MCI (Cohen's d = 2.03 and 1.61, respectively). Hippocampal volume demonstrated moderate predictive value for conversion from MCI to AD (AUC = 0.66). Stratification by APOE4 status did not reveal significant genetic effects on cross-sectional hippocampal volume. These results support medial temporal degeneration as a key feature of AD progression and provide insights into predictive biomarkers and genetic influences.

</details>


### [18] [MMViR: A Multi-Modal and Multi-Granularity Representation for Long-range Video Understanding](https://arxiv.org/abs/2601.05495)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CV

TL;DR: 本文提出MMViR，一种用于长视频理解的多模态、多粒度结构化表示方法，通过识别关键转折点进行视频分段，并构建三层描述以耦合全局叙事与细粒度视觉细节，在问答、摘要和检索任务中显著提升性能并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型难以有效处理分钟到小时级的长视频，因其存在复杂事件、多样场景和长程依赖；直接编码计算昂贵，简单视频转文本又易导致冗余或碎片化。

Method: 提出MMViR方法，通过识别视频关键转折点进行分段，并构建包含全局叙事与细粒度视觉细节的三层结构化描述，支持高效查询式检索。

Result: 在问答、摘要和检索三项任务中，MMViR相较先前最优方法，在小时级视频理解上提升19.67%，处理延迟降至原方法的45.4%。

Conclusion: MMViR提供了一种高效、可泛化的长视频理解新范式，兼顾语义完整性与计算效率。

Abstract: Long videos, ranging from minutes to hours, present significant challenges for current Multi-modal Large Language Models (MLLMs) due to their complex events, diverse scenes, and long-range dependencies. Direct encoding of such videos is computationally too expensive, while simple video-to-text conversion often results in redundant or fragmented content. To address these limitations, we introduce MMViR, a novel multi-modal, multi-grained structured representation for long video understanding. MMViR identifies key turning points to segment the video and constructs a three-level description that couples global narratives with fine-grained visual details. This design supports efficient query-based retrieval and generalizes well across various scenarios. Extensive evaluations across three tasks, including QA, summarization, and retrieval, show that MMViR outperforms the prior strongest method, achieving a 19.67% improvement in hour-long video understanding while reducing processing latency to 45.4% of the original.

</details>


### [19] [Prompt-Free SAM-Based Multi-Task Framework for Breast Ultrasound Lesion Segmentation and Classification](https://arxiv.org/abs/2601.05498)
*Samuel E. Johnny,Bernes L. Atabonfack,Israel Alagbe,Assane Gueye*

Main category: cs.CV

TL;DR: 本文提出了一种基于SAM视觉编码器的多任务深度学习框架，用于乳腺超声图像中的病灶分割与诊断分类，无需提示、全监督微调，在PRECISE 2025数据集上取得Dice 0.887和分类准确率92.3%的优异性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺超声（BUS）图像中肿瘤分割与分类困难，主要由于对比度低、斑点噪声强及病灶形态多样。

Method: 基于Segment Anything Model（SAM）视觉编码器构建多任务框架：采用无提示、全监督方式解码高维SAM特征，分割分支使用轻量卷积头或UNet式解码器；分类分支引入掩膜引导注意力机制，聚焦病灶区域并抑制背景干扰。

Result: 在PRECISE 2025数据集（80%训练/20%测试）上，Dice相似系数达0.887，分类准确率为92.3%，位居PRECISE挑战赛排行榜前列。

Conclusion: SAM表征结合分割引导学习可显著提升乳腺超声图像中病灶分割精度与诊断预测能力。

Abstract: Accurate tumor segmentation and classification in breast ultrasound (BUS) imaging remain challenging due to low contrast, speckle noise, and diverse lesion morphology. This study presents a multi-task deep learning framework that jointly performs lesion segmentation and diagnostic classification using embeddings from the Segment Anything Model (SAM) vision encoder. Unlike prompt-based SAM variants, our approach employs a prompt-free, fully supervised adaptation where high-dimensional SAM features are decoded through either a lightweight convolutional head or a UNet-inspired decoder for pixel-wise segmentation. The classification branch is enhanced via mask-guided attention, allowing the model to focus on lesion-relevant features while suppressing background artifacts. Experiments on the PRECISE 2025 breast ultrasound dataset, split per class into 80 percent training and 20 percent testing, show that the proposed method achieves a Dice Similarity Coefficient (DSC) of 0.887 and an accuracy of 92.3 percent, ranking among the top entries on the PRECISE challenge leaderboard. These results demonstrate that SAM-based representations, when coupled with segmentation-guided learning, significantly improve both lesion delineation and diagnostic prediction in breast ultrasound imaging.

</details>


### [20] [Enabling Stroke-Level Structural Analysis of Hieroglyphic Scripts without Language-Specific Priors](https://arxiv.org/abs/2601.05508)
*Fuwen Luo,Zihao Wan,Ziyue Wang,Yaluo Liu,Pau Tong Lin Xu,Xuanjia Qiao,Xiaolong Wang,Peng Li,Yang Liu*

Main category: cs.CV

TL;DR: 本文提出Hieroglyphic Stroke Analyzer（HieroSA），一种无需人工标注、可泛化于多种象形文字的框架，将字符图像自动转化为规范坐标空间中的线段表示，使多模态大模型能理解字形内部结构。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型和多模态大模型无法建模象形文字（如古埃及圣书体）内部笔画结构所蕴含的语义与文化信息；传统结构分析方法又依赖脚本特异性设计且费时费力。

Method: 提出HieroSA框架，将字符位图自动解析为归一化坐标空间中的显式线段表示，不依赖手工构造数据，支持跨语言泛化。

Result: 实验表明HieroSA能有效捕捉字符内部结构与语义，无需语言特定先验知识，在多种象形/表意文字上展现出良好泛化能力。

Conclusion: HieroSA为象形文字的图形学（graphematics）分析提供了新工具，推动多模态大模型对古老书写系统深层语义的理解。

Abstract: Hieroglyphs, as logographic writing systems, encode rich semantic and cultural information within their internal structural composition. Yet, current advanced Large Language Models (LLMs) and Multimodal LLMs (MLLMs) usually remain structurally blind to this information. LLMs process characters as textual tokens, while MLLMs additionally view them as raw pixel grids. Both fall short to model the underlying logic of character strokes. Furthermore, existing structural analysis methods are often script-specific and labor-intensive. In this paper, we propose Hieroglyphic Stroke Analyzer (HieroSA), a novel and generalizable framework that enables MLLMs to automatically derive stroke-level structures from character bitmaps without handcrafted data. It transforms modern logographic and ancient hieroglyphs character images into explicit, interpretable line-segment representations in a normalized coordinate space, allowing for cross-lingual generalization. Extensive experiments demonstrate that HieroSA effectively captures character-internal structures and semantics, bypassing the need for language-specific priors. Experimental results highlight the potential of our work as a graphematics analysis tool for a deeper understanding of hieroglyphic scripts. View our code at https://github.com/THUNLP-MT/HieroSA.

</details>


### [21] [GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting](https://arxiv.org/abs/2601.05511)
*Xuan Cheng,Jiahao Rao,Chengyang Li,Wenhao Wang,Weilin Chen,Lvqing Yang*

Main category: cs.CV

TL;DR: GaussianSwap是一种基于3D高斯溅射的视频人脸交换框架，将源图像身份迁移到目标视频构建的可动画、可交互的高保真人脸头像上，克服了传统像素级方法缺乏结构和操控能力的局限。


<details>
  <summary>Details</summary>
Motivation: 传统视频人脸交换方法仅生成无结构的像素级结果，无法支持动画或交互操作，亟需一种能生成结构化、可控人脸表示的新范式。

Method: 首先从目标视频中提取FLAME参数、相机姿态和分割掩码；然后将3D高斯溅射绑定到FLAME模型实现跨帧动态面部控制；采用三个先进识别人脸模型融合的复合身份嵌入进行头像微调；最后将交换后的头像渲染回背景帧生成最终视频。

Result: 实验表明GaussianSwap在身份保持性、视觉清晰度和时序一致性方面优于现有方法，并支持此前无法实现的交互式应用。

Conclusion: GaussianSwap实现了从像素级视频生成到结构化、可操控人脸头像生成的范式转变，为视频人脸交换开辟了新方向。

Abstract: We introduce GaussianSwap, a novel video face swapping framework that constructs a 3D Gaussian Splatting based face avatar from a target video while transferring identity from a source image to the avatar. Conventional video swapping frameworks are limited to generating facial representations in pixel-based formats. The resulting swapped faces exist merely as a set of unstructured pixels without any capacity for animation or interactive manipulation. Our work introduces a paradigm shift from conventional pixel-based video generation to the creation of high-fidelity avatar with swapped faces. The framework first preprocesses target video to extract FLAME parameters, camera poses and segmentation masks, and then rigs 3D Gaussian splats to the FLAME model across frames, enabling dynamic facial control. To ensure identity preserving, we propose an compound identity embedding constructed from three state-of-the-art face recognition models for avatar finetuning. Finally, we render the face-swapped avatar on the background frames to obtain the face-swapped video. Experimental results demonstrate that GaussianSwap achieves superior identity preservation, visual clarity and temporal consistency, while enabling previously unattainable interactive applications.

</details>


### [22] [SAS-VPReID: A Scale-Adaptive Framework with Shape Priors for Video-based Person Re-Identification at Extreme Far Distances](https://arxiv.org/abs/2601.05535)
*Qiwei Yang,Pingping Zhang,Yuhao Wang,Zijing Gong*

Main category: cs.CV

TL;DR: 本文提出了一种面向极远距离视频行人重识别（VPReID）的尺度自适应框架SAS-VPReID，融合记忆增强视觉主干、多粒度时序建模与先验正则化形状动力学模块，在VReID-XFD基准上取得榜首成绩。


<details>
  <summary>Details</summary>
Motivation: 在极远距离下，VPReID面临严重分辨率下降、剧烈视角变化和外观噪声等问题，现有方法难以应对。

Method: 提出SAS-VPReID框架，包含三个模块：1）记忆增强视觉主干（MEVB），基于CLIP视觉编码器与多代理记忆；2）多粒度时序建模（MGTM），构建多时间粒度序列并自适应强调跨尺度运动线索；3）先验正则化形状动力学（PRSD），建模人体结构动态。

Result: 在VReID-XFD基准上验证了各模块有效性，整体框架在该挑战赛排行榜排名第一。

Conclusion: SAS-VPReID通过协同建模尺度自适应特征、时序运动与人体结构动态，显著提升了极远距离VPReID性能。

Abstract: Video-based Person Re-IDentification (VPReID) aims to retrieve the same person from videos captured by non-overlapping cameras. At extreme far distances, VPReID is highly challenging due to severe resolution degradation, drastic viewpoint variation and inevitable appearance noise. To address these issues, we propose a Scale-Adaptive framework with Shape Priors for VPReID, named SAS-VPReID. The framework is built upon three complementary modules. First, we deploy a Memory-Enhanced Visual Backbone (MEVB) to extract discriminative feature representations, which leverages the CLIP vision encoder and multi-proxy memory. Second, we propose a Multi-Granularity Temporal Modeling (MGTM) to construct sequences at multiple temporal granularities and adaptively emphasize motion cues across scales. Third, we incorporate Prior-Regularized Shape Dynamics (PRSD) to capture body structure dynamics. With these modules, our framework can obtain more discriminative feature representations. Experiments on the VReID-XFD benchmark demonstrate the effectiveness of each module and our final framework ranks the first on the VReID-XFD challenge leaderboard. The source code is available at https://github.com/YangQiWei3/SAS-VPReID.

</details>


### [23] [DIFF-MF: A Difference-Driven Channel-Spatial State Space Model for Multi-Modal Image Fusion](https://arxiv.org/abs/2601.05538)
*Yiming Sun,Zifan Ye,Qinghua Hu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 本文提出DIFF-MF模型，一种基于差异驱动的通道-空间状态空间模型，用于多模态图像融合，通过模态间特征差异图引导特征提取与融合，在通道和空间维度分别设计交换模块，兼顾红外目标显著性与可见光细节，实现高效全局建模并取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于状态空间模型的多模态图像融合方法存在权衡问题：要么过度强调红外强度而损失可见光细节，要么保留可见光结构却削弱热目标显著性。

Method: 提出DIFF-MF模型：利用模态间特征差异图指导特征提取；在通道维引入通道交换模块（基于交叉注意力的双状态空间建模）实现自适应通道重加权；在空间维采用跨模态状态空间扫描的空间交换模块实现全面空间融合；整体保持线性计算复杂度。

Result: 在驾驶场景和低空无人机数据集上，DIFF-MF在视觉质量与定量指标（如EN、SSIM、VIF等）上均优于现有方法。

Conclusion: DIFF-MF通过差异驱动与通道-空间协同建模，有效解决了多模态图像融合中红外显著性与可见光细节难以兼顾的问题，兼具高性能与高效率。

Abstract: Multi-modal image fusion aims to integrate complementary information from multiple source images to produce high-quality fused images with enriched content. Although existing approaches based on state space model have achieved satisfied performance with high computational efficiency, they tend to either over-prioritize infrared intensity at the cost of visible details, or conversely, preserve visible structure while diminishing thermal target salience. To overcome these challenges, we propose DIFF-MF, a novel difference-driven channel-spatial state space model for multi-modal image fusion. Our approach leverages feature discrepancy maps between modalities to guide feature extraction, followed by a fusion process across both channel and spatial dimensions. In the channel dimension, a channel-exchange module enhances channel-wise interaction through cross-attention dual state space modeling, enabling adaptive feature reweighting. In the spatial dimension, a spatial-exchange module employs cross-modal state space scanning to achieve comprehensive spatial fusion. By efficiently capturing global dependencies while maintaining linear computational complexity, DIFF-MF effectively integrates complementary multi-modal features. Experimental results on the driving scenarios and low-altitude UAV datasets demonstrate that our method outperforms existing approaches in both visual quality and quantitative evaluation.

</details>


### [24] [MoGen: A Unified Collaborative Framework for Controllable Multi-Object Image Generation](https://arxiv.org/abs/2601.05546)
*Yanfeng Li,Yue Sun,Keren Fu,Sio-Kei Im,Xiaoming Liu,Guangtao Zhai,Xiaohong Liu,Tao Tan*

Main category: cs.CV

TL;DR: 本文提出MoGen方法，通过Regional Semantic Anchor（RSA）模块实现语言描述与图像区域的精准对齐，并利用Adaptive Multi-modal Guidance（AMG）模块自适应融合多源控制信号，提升多目标图像生成的数量一致性、细粒度可控性与用户友好性。


<details>
  <summary>Details</summary>
Motivation: 现有多目标图像生成方法难以实现语言描述中局部语义与图像生成区域的精确对齐，常导致物体数量不一致和属性混淆；且主流方法依赖外部强控制信号，输入格式僵化，难以适配不同用户资源条件和多样化约束需求。

Method: 提出MoGen框架：1）Regional Semantic Anchor（RSA）模块，将语言中的短语单元精准锚定到对应图像区域，保障多物体数量规范；2）Adaptive Multi-modal Guidance（AMG）模块，自适应解析并融合多种控制信号，生成结构化意图以动态指导场景布局与物体属性约束。

Result: 实验表明，MoGen在生成质量、数量一致性与细粒度控制能力上显著优于现有方法，同时具备更高可用性与控制灵活性。

Conclusion: MoGen通过语义锚定与自适应多模态引导，有效解决了多目标图像生成中语义-空间对齐难、控制僵化等问题，为用户提供了更灵活、鲁棒且易用的生成方案。

Abstract: Existing multi-object image generation methods face difficulties in achieving precise alignment between localized image generation regions and their corresponding semantics based on language descriptions, frequently resulting in inconsistent object quantities and attribute aliasing. To mitigate this limitation, mainstream approaches typically rely on external control signals to explicitly constrain the spatial layout, local semantic and visual attributes of images. However, this strong dependency makes the input format rigid, rendering it incompatible with the heterogeneous resource conditions of users and diverse constraint requirements. To address these challenges, we propose MoGen, a user-friendly multi-object image generation method. First, we design a Regional Semantic Anchor (RSA) module that precisely anchors phrase units in language descriptions to their corresponding image regions during the generation process, enabling text-to-image generation that follows quantity specifications for multiple objects. Building upon this foundation, we further introduce an Adaptive Multi-modal Guidance (AMG) module, which adaptively parses and integrates various combinations of multi-source control signals to formulate corresponding structured intent. This intent subsequently guides selective constraints on scene layouts and object attributes, achieving dynamic fine-grained control. Experimental results demonstrate that MoGen significantly outperforms existing methods in generation quality, quantity consistency, and fine-grained control, while exhibiting superior accessibility and control flexibility. Code is available at: https://github.com/Tear-kitty/MoGen/tree/master.

</details>


### [25] [VIB-Probe: Detecting and Mitigating Hallucinations in Vision-Language Models via Variational Information Bottleneck](https://arxiv.org/abs/2601.05547)
*Feiran Zhang,Yixin Wu,Zhenghua Wang,Xiaohua Wang,Changze Lv,Xuanjing Huang,Xiaoqing Zheng*

Main category: cs.CV

TL;DR: 本文提出VIB-Probe框架，利用变分信息瓶颈理论探测并缓解视觉语言模型中的幻觉问题，通过分析注意力头内部信号并实施推理时干预，显著提升检测与缓解性能。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法多依赖输出logits或外部验证工具，忽视了模型内部机制；而内部注意力头可能蕴含真实生成的关键信号，但其高维状态因视觉-语言语法耦合和噪声难以直接解析。

Method: 提出基于变分信息瓶颈（VIB）理论的VIB-Probe框架，从多层多头注意力中提取判别性模式、过滤语义干扰，并利用VIB探针梯度识别对幻觉具强因果影响的注意力头，进而设计推理时干预策略。

Result: 在多个基准测试上，VIB-Probe在幻觉检测与缓解两方面均显著优于现有基线方法。

Conclusion: 内部注意力头蕴含可被有效利用的幻觉相关信号；基于信息瓶颈原理建模与干预注意力机制，是提升VLM可靠性的一条可行且有效路径。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable progress in multimodal tasks, but remain susceptible to hallucinations, where generated text deviates from the underlying visual content. Existing hallucination detection methods primarily rely on output logits or external verification tools, often overlooking their internal mechanisms. In this work, we investigate the outputs of internal attention heads, postulating that specific heads carry the primary signals for truthful generation.However, directly probing these high-dimensional states is challenging due to the entanglement of visual-linguistic syntax and noise. To address this, we propose VIB-Probe, a novel hallucination detection and mitigation framework leveraging the Variational Information Bottleneck (VIB) theory. Our method extracts discriminative patterns across layers and heads while filtering out semantic nuisances through the information bottleneck principle. Furthermore, by leveraging the gradients of our VIB probe, we identify attention heads with strong causal influence on hallucinations and introduce an inference-time intervention strategy for hallucination mitigation. Extensive experiments across diverse benchmarks demonstrate that VIB-Probe significantly outperforms existing baselines in both settings. Our code will be made publicly available.

</details>


### [26] [One Language-Free Foundation Model Is Enough for Universal Vision Anomaly Detection](https://arxiv.org/abs/2601.05552)
*Bin-Bin Gao,Chengjie Wang*

Main category: cs.CV

TL;DR: 本文提出了一种极简、通用且高效的通用视觉异常检测框架UniADet，通过解耦分类与分割任务及多层级特征权重，仅学习少量参数（0.002M），无需复杂提示工程或适配模块，在14个真实世界基准上超越现有零/少样本方法，甚至首次超越全监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉-语言基础模型的通用异常检测方法依赖复杂的提示工程、精细的适配模块和困难的训练策略，限制了其灵活性和泛化性。

Method: 重新审视视觉-语言模型在异常检测中的作用，发现语言编码器对通用异常检测非必要；提出完全解耦分类与分割任务、以及跨层级特征的学习方式，仅学习独立的任务与层级权重。

Result: UniADet在14个涵盖工业与医疗领域的现实异常检测基准上，显著超越当前零样本/少样本最先进方法，并首次超越部分全监督方法；仅含0.002M可学习参数，支持多种基础模型。

Conclusion: UniADet证明了异常检测无需复杂设计，通过极简的权重解耦机制即可实现高度通用性、参数高效性和卓越性能，为通用视觉异常检测提供了新范式。

Abstract: Universal visual anomaly detection (AD) aims to identify anomaly images and segment anomaly regions towards open and dynamic scenarios, following zero- and few-shot paradigms without any dataset-specific fine-tuning. We have witnessed significant progress in widely use of visual-language foundational models in recent approaches. However, current methods often struggle with complex prompt engineering, elaborate adaptation modules, and challenging training strategies, ultimately limiting their flexibility and generality. To address these issues, this paper rethinks the fundamental mechanism behind visual-language models for AD and presents an embarrassingly simple, general, and effective framework for Universal vision Anomaly Detection (UniADet). Specifically, we first find language encoder is used to derive decision weights for anomaly classification and segmentation, and then demonstrate that it is unnecessary for universal AD. Second, we propose an embarrassingly simple method to completely decouple classification and segmentation, and decouple cross-level features, i.e., learning independent weights for different tasks and hierarchical features. UniADet is highly simple (learning only decoupled weights), parameter-efficient (only 0.002M learnable parameters), general (adapting a variety of foundation models), and effective (surpassing state-of-the-art zero-/few-shot by a large margin and even full-shot AD methods for the first time) on 14 real-world AD benchmarks covering both industrial and medical domains. We will make the code and model of UniADet available at https://github.com/gaobb/UniADet.

</details>


### [27] [Semi-Supervised Facial Expression Recognition based on Dynamic Threshold and Negative Learning](https://arxiv.org/abs/2601.05556)
*Zhongpeng Cai,Jun Yu,Wei Xu,Tianyu Liu,Jianqing Sun,Jiaen Liang*

Main category: cs.CV

TL;DR: 本文提出了一种基于动态阈值调整（DTA）和选择性负学习（SNL）的半监督面部表情识别算法，在RAF-DB和AffectNet数据集上达到SOTA性能，且仅用部分标注数据即超越全监督方法。


<details>
  <summary>Details</summary>
Motivation: 获取大量带标注的面部表情数据成本高，因此需设计能充分利用标注与未标注数据的半监督算法。

Method: 提出基于动态阈值调整（DTA）和选择性负学习（SNL）的半监督算法；在特征提取阶段引入局部注意力增强和特征图随机丢弃策略；采用动态阈值适配半监督框架，并通过SNL从低置信度无标签样本的互补标签中挖掘有效表情信息。

Result: 在RAF-DB和AffectNet数据集上达到当前最优性能，且仅用部分标注数据即超越全监督方法。

Conclusion: 所提方法显著提升了半监督面部表情识别性能，验证了DTA与SNL策略在利用无标签数据方面的有效性。

Abstract: Facial expression recognition is a key task in human-computer interaction and affective computing. However, acquiring a large amount of labeled facial expression data is often costly. Therefore, it is particularly important to design a semi-supervised facial expression recognition algorithm that makes full use of both labeled and unlabeled data. In this paper, we propose a semi-supervised facial expression recognition algorithm based on Dynamic Threshold Adjustment (DTA) and Selective Negative Learning (SNL). Initially, we designed strategies for local attention enhancement and random dropout of feature maps during feature extraction, which strengthen the representation of local features while ensuring the model does not overfit to any specific local area. Furthermore, this study introduces a dynamic thresholding method to adapt to the requirements of the semi-supervised learning framework for facial expression recognition tasks, and through a selective negative learning strategy, it fully utilizes unlabeled samples with low confidence by mining useful expression information from complementary labels, achieving impressive results. We have achieved state-of-the-art performance on the RAF-DB and AffectNet datasets. Our method surpasses fully supervised methods even without using the entire dataset, which proves the effectiveness of our approach.

</details>


### [28] [What's Left Unsaid? Detecting and Correcting Misleading Omissions in Multimodal News Previews](https://arxiv.org/abs/2601.05563)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Dayang Li,Herun Wan,Wei Zhou,Min-Yen Kan*

Main category: cs.CV

TL;DR: 本文提出了一种检测和纠正社交媒体新闻预览（图文对）中因上下文缺失导致的隐性误导问题的方法，构建了MM-Misleading基准，并提出了OMGuard模型，在多模态误导检测与修正任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 社交平台新闻预览（图文对）即使事实正确，也可能因省略关键上下文引发读者理解偏移，这种‘隐性误导’比显性虚假信息更难察觉且研究不足。

Method: 构建多阶段pipeline解耦并模拟预览驱动与上下文驱动的理解差异，建立MM-Misleading基准；提出OMGuard方法，包含解释感知微调（IAFT）和理由引导的误导内容修正（RGCC）。

Result: OMGuard使8B模型检测准确率媲美235B LVLM，并在端到端修正任务中表现更优；分析发现误导多源于局部叙事偏移（如背景缺失），且图像驱动场景需视觉介入而非纯文本修正。

Conclusion: 隐性误导是重要但被忽视的问题，需多模态建模与可解释干预；OMGuard为提升LVLM对上下文敏感性和鲁棒性提供了有效路径。

Abstract: Even when factually correct, social-media news previews (image-headline pairs) can induce interpretation drift: by selectively omitting crucial context, they lead readers to form judgments that diverge from what the full article conveys. This covert harm is harder to detect than explicit misinformation yet remains underexplored. To address this gap, we develop a multi-stage pipeline that disentangles and simulates preview-based versus context-based understanding, enabling construction of the MM-Misleading benchmark. Using this benchmark, we systematically evaluate open-source LVLMs and uncover pronounced blind spots to omission-based misleadingness detection. We further propose OMGuard, which integrates (1) Interpretation-Aware Fine-Tuning, which used to improve multimodal misleadingness detection and (2) Rationale-Guided Misleading Content Correction, which uses explicit rationales to guide headline rewriting and reduce misleading impressions. Experiments show that OMGuard lifts an 8B model's detection accuracy to match a 235B LVLM and delivers markedly stronger end-to-end correction. Further analysis reveals that misleadingness typically stems from local narrative shifts (e.g., missing background) rather than global frame changes, and identifies image-driven scenarios where text-only correction fails, highlighting the necessity of visual interventions.

</details>


### [29] [Towards Generalized Multi-Image Editing for Unified Multimodal Models](https://arxiv.org/abs/2601.05572)
*Pengcheng Xu,Peng Tang,Donghao Luo,Xiaobin Hu,Weichu Cui,Qingdong He,Zhennan Chen,Jiangning Zhang,Charles Ling,Boyu Wang*

Main category: cs.CV

TL;DR: 本文提出了一种可扩展的多图像编辑框架，通过可学习的潜在分隔符和正弦索引编码，显式区分图像身份并支持可变数量输入，在统一多模态模型中提升视觉一致性和跨图像细节推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型（UMMs）在处理多个输入图像时难以保持视觉一致性并准确消歧图像间细节引用。

Method: 提出两种算法创新：1）可学习的潜在分隔符，在潜在空间中显式区分各参考图像；2）正弦索引编码，为同图视觉标记赋予连续正弦位置嵌入，以显式建模图像身份并支持输入数量泛化。同时构建高保真逆数据集基准用于训练与评估。

Result: 实验表明该方法在语义一致性、视觉保真度和跨图像整合能力上显著优于基线方法，验证了其在一致性和泛化性上的优势。

Conclusion: 所提框架有效解决了UMMs在多图像编辑中图像身份混淆与输入数量受限的问题，为可扩展、鲁棒的多图像理解与生成提供了新范式。

Abstract: Unified Multimodal Models (UMMs) integrate multimodal understanding and generation, yet they are limited to maintaining visual consistency and disambiguating visual cues when referencing details across multiple input images. In this work, we propose a scalable multi-image editing framework for UMMs that explicitly distinguishes image identities and generalizes to variable input counts. Algorithmically, we introduce two innovations: 1) The learnable latent separators explicitly differentiate each reference image in the latent space, enabling accurate and disentangled conditioning. 2) The sinusoidal index encoding assigns visual tokens from the same image a continuous sinusoidal index embedding, which provides explicit image identity while allowing generalization and extrapolation on a variable number of inputs. To facilitate training and evaluation, we establish a high-fidelity benchmark using an inverse dataset construction methodology to guarantee artifact-free, achievable outputs. Experiments show clear improvements in semantic consistency, visual fidelity, and cross-image integration over prior baselines on diverse multi-image editing tasks, validating our advantages on consistency and generalization ability.

</details>


### [30] [Orient Anything V2: Unifying Orientation and Rotation Understanding](https://arxiv.org/abs/2601.05573)
*Zehan Wang,Ziang Zhang,Jiayang Xu,Jialei Wang,Tianyu Pang,Chao Du,HengShuang Zhao,Zhou Zhao*

Main category: cs.CV

TL;DR: Orient Anything V2 是一个用于从单张或成对图像中统一理解物体3D朝向与旋转的基础模型，通过四项创新显著提升了对旋转对称物体的建模与相对旋转估计能力，并在多个基准上实现零样本SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决 Orient Anything V1 仅能定义单一前向面、难以处理具有多样旋转对称性的物体的问题，拓展朝向理解能力以支持更广泛的实际应用场景。

Method: 提出四项关键技术：1）生成式模型合成可扩展3D资产；2）模型闭环的高效标注系统，支持0到N个有效前向面识别；3）对称感知的周期性分布拟合目标函数；4）多帧架构直接预测相对旋转。

Result: 在11个主流基准上，零样本朝向估计、6DoF位姿估计和物体对称性识别均达到SOTA；展现出强泛化能力。

Conclusion: Orient Anything V2 显著提升了对旋转对称物体的朝向理解能力，大幅拓宽了朝向估计在下游任务中的适用范围。

Abstract: This work presents Orient Anything V2, an enhanced foundation model for unified understanding of object 3D orientation and rotation from single or paired images. Building upon Orient Anything V1, which defines orientation via a single unique front face, V2 extends this capability to handle objects with diverse rotational symmetries and directly estimate relative rotations. These improvements are enabled by four key innovations: 1) Scalable 3D assets synthesized by generative models, ensuring broad category coverage and balanced data distribution; 2) An efficient, model-in-the-loop annotation system that robustly identifies 0 to N valid front faces for each object; 3) A symmetry-aware, periodic distribution fitting objective that captures all plausible front-facing orientations, effectively modeling object rotational symmetry; 4) A multi-frame architecture that directly predicts relative object rotations. Extensive experiments show that Orient Anything V2 achieves state-of-the-art zero-shot performance on orientation estimation, 6DoF pose estimation, and object symmetry recognition across 11 widely used benchmarks. The model demonstrates strong generalization, significantly broadening the applicability of orientation estimation in diverse downstream tasks.

</details>


### [31] [Generalizable and Adaptive Continual Learning Framework for AI-generated Image Detection](https://arxiv.org/abs/2601.05580)
*Hanyi Wang,Jun Lan,Yaoyu Kang,Huijia Zhu,Weiqiang Wang,Zhuosheng Zhang,Shilin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种三阶段领域持续学习框架，用于持续适应不断演进的AI生成图像模型，以提升检测泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测方法难以泛化到未见过的生成模型，且生成技术快速迭代导致检测模型易失效，亟需具备持续适应能力的检测框架。

Method: 提出三阶段域持续学习框架：第一阶段采用参数高效微调构建强泛化离线检测模型；第二阶段结合渐进式复杂度数据增强链和K-FAC近似Hessian矩阵缓解灾难性遗忘；第三阶段基于线性模态连通性进行线性插值，挖掘多模型共性。

Result: 在涵盖27个生成模型（截至2024年8月）的基准上，离线检测器mAP较SOTA提升+5.51%；持续学习策略平均准确率达92.20%，优于当前最优方法。

Conclusion: 该框架显著提升了对新型生成模型的检测泛化性与持续适应能力，为应对快速演化的AI伪造图像威胁提供了有效解决方案。

Abstract: The malicious misuse and widespread dissemination of AI-generated images pose a significant threat to the authenticity of online information. Current detection methods often struggle to generalize to unseen generative models, and the rapid evolution of generative techniques continuously exacerbates this challenge. Without adaptability, detection models risk becoming ineffective in real-world applications. To address this critical issue, we propose a novel three-stage domain continual learning framework designed for continuous adaptation to evolving generative models. In the first stage, we employ a strategic parameter-efficient fine-tuning approach to develop a transferable offline detection model with strong generalization capabilities. Building upon this foundation, the second stage integrates unseen data streams into a continual learning process. To efficiently learn from limited samples of novel generated models and mitigate overfitting, we design a data augmentation chain with progressively increasing complexity. Furthermore, we leverage the Kronecker-Factored Approximate Curvature (K-FAC) method to approximate the Hessian and alleviate catastrophic forgetting. Finally, the third stage utilizes a linear interpolation strategy based on Linear Mode Connectivity, effectively capturing commonalities across diverse generative models and further enhancing overall performance. We establish a comprehensive benchmark of 27 generative models, including GANs, deepfakes, and diffusion models, chronologically structured up to August 2024 to simulate real-world scenarios. Extensive experiments demonstrate that our initial offline detectors surpass the leading baseline by +5.51% in terms of mean average precision. Our continual learning strategy achieves an average accuracy of 92.20%, outperforming state-of-the-art methods.

</details>


### [32] [GS-DMSR: Dynamic Sensitive Multi-scale Manifold Enhancement for Accelerated High-Quality 3D Gaussian Splatting](https://arxiv.org/abs/2601.05584)
*Nengbo Lu,Minghua Pan,Shaohua Sun,Yizhou Liang*

Main category: cs.CV

TL;DR: 本文提出GS-DMSR方法，通过动态分析高斯属性演化实现自适应梯度聚焦与差异化优化，并引入多尺度流形增强模块，显著提升3D动态场景重建的收敛速度与渲染质量。


<details>
  <summary>Details</summary>
Motivation: 在3D动态场景重建中，如何平衡模型收敛速度与渲染质量，尤其是在复杂动态运动的高精度建模中，是一个亟待解决的关键挑战。

Method: 提出GS-DMSR方法：1）定量分析高斯属性的动态演化，实现自适应梯度聚焦与差异化优化；2）引入多尺度流形增强模块，协同优化隐式非线性解码器与显式变形场。

Result: 在合成数据集上达到最高96 FPS帧率，同时有效降低存储开销和训练时间。

Conclusion: GS-DMSR在保持高渲染质量的同时显著提升了收敛速度，适用于复杂动态变形场景的高效建模。

Abstract: In the field of 3D dynamic scene reconstruction, how to balance model convergence rate and rendering quality has long been a critical challenge that urgently needs to be addressed, particularly in high-precision modeling of scenes with complex dynamic motions. To tackle this issue, this study proposes the GS-DMSR method. By quantitatively analyzing the dynamic evolution process of Gaussian attributes, this mechanism achieves adaptive gradient focusing, enabling it to dynamically identify significant differences in the motion states of Gaussian models. It then applies differentiated optimization strategies to Gaussian models with varying degrees of significance, thereby significantly improving the model convergence rate. Additionally, this research integrates a multi-scale manifold enhancement module, which leverages the collaborative optimization of an implicit nonlinear decoder and an explicit deformation field to enhance the modeling efficiency for complex deformation scenes. Experimental results demonstrate that this method achieves a frame rate of up to 96 FPS on synthetic datasets, while effectively reducing both storage overhead and training time.Our code and data are available at https://anonymous.4open.science/r/GS-DMSR-2212.

</details>


### [33] [Quantifying and Inducing Shape Bias in CNNs via Max-Pool Dilation](https://arxiv.org/abs/2601.05599)
*Takito Sawada,Akinori Iwata,Masahiro Okuda*

Main category: cs.CV

TL;DR: 本文提出了一种基于SSIM的数据驱动度量方法，用于量化数据集的形状-纹理平衡性，并设计了一种仅调整最大池化膨胀率、冻结卷积权重的高效适配方法，以增强CNN的形状偏好，在形状主导的数据集（尤其是小样本场景）上提升了分类准确率。


<details>
  <summary>Details</summary>
Motivation: CNN固有的纹理偏差在处理形状主导的数据（如插图、草图）时性能下降，而现有形状偏好模型缺乏定量判断哪些数据集真正需要此类改进的标准。

Method: 提出基于SSIM计算图像亮度通道与其L0平滑版本相似度的形状-纹理平衡度量；在此基础上，通过调整最大池化操作的膨胀率（保持卷积权重冻结）来增强模型的形状偏好。

Result: 所提方法在形状主导数据集上显著提升分类准确率，尤其在低数据量场景下效果突出，仅需训练最后分类层即可实现有效适配。

Conclusion: 该数据驱动度量与轻量适配策略为针对性增强CNN形状偏好提供了可解释、高效率的解决方案，弥补了现有工作在数据适用性评估和计算开销方面的不足。

Abstract: Convolutional Neural Networks (CNNs) are known to exhibit a strong texture bias, favoring local patterns over global shape information--a tendency inherent to their convolutional architecture. While this bias is beneficial for texture-rich natural images, it often degrades performance on shape-dominant data such as illustrations and sketches. Although prior work has proposed shape-biased models to mitigate this issue, these approaches lack a quantitative metric for identifying which datasets would actually benefit from such modifications. To address this gap, we propose a data-driven metric that quantifies the shape-texture balance of a dataset by computing the Structural Similarity Index (SSIM) between each image's luminance channel and its L0-smoothed counterpart. Building on this metric, we further introduce a computationally efficient adaptation method that promotes shape bias by modifying the dilation of max-pooling operations while keeping convolutional weights frozen. Experimental results show that this approach consistently improves classification accuracy on shape-dominant datasets, particularly in low-data regimes where full fine-tuning is impractical, requiring training only the final classification layer.

</details>


### [34] [SceneAlign: Aligning Multimodal Reasoning to Scene Graphs in Complex Visual Scenes](https://arxiv.org/abs/2601.05600)
*Chuhan Wang,Xintong Li,Jennifer Yuntong Zhang,Junda Wu,Chengkai Huang,Lina Yao,Julian McAuley,Jingbo Shang*

Main category: cs.CV

TL;DR: 本文提出SceneAlign框架，利用场景图进行结构化干预，通过构造基于视觉事实错误但语言上合理的对比样本，提升多模态大模型在复杂视觉场景中的推理忠实性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在复杂视觉场景中常出现推理不忠实问题，如幻觉实体、错位关系、跳步和过度细化，而现有基于偏好的方法易依赖语言先验，忽视视觉接地。

Method: 提出SceneAlign框架，以场景图作为结构化视觉信息，设计四种针对推理关键节点的扰动策略，生成视觉接地错误但语言合理的难负样本，并用于直接偏好优化（DPO）。

Result: 在七个视觉推理基准上，SceneAlign持续提升了答案准确率与推理忠实性。

Conclusion: 基于视觉接地感知的对齐方法能有效提升多模态模型的细粒度、结构忠实推理能力。

Abstract: Multimodal large language models often struggle with faithful reasoning in complex visual scenes, where intricate entities and relations require precise visual grounding at each step. This reasoning unfaithfulness frequently manifests as hallucinated entities, mis-grounded relations, skipped steps, and over-specified reasoning. Existing preference-based approaches, typically relying on textual perturbations or answer-conditioned rationales, fail to address this challenge as they allow models to exploit language priors to bypass visual grounding. To address this, we propose SceneAlign, a framework that leverages scene graphs as structured visual information to perform controllable structural interventions. By identifying reasoning-critical nodes and perturbing them through four targeted strategies that mimic typical grounding failures, SceneAlign constructs hard negative rationales that remain linguistically plausible but are grounded in inaccurate visual facts. These contrastive pairs are used in Direct Preference Optimization to steer models toward fine-grained, structure-faithful reasoning. Across seven visual reasoning benchmarks, SceneAlign consistently improves answer accuracy and reasoning faithfulness, highlighting the effectiveness of grounding-aware alignment for multimodal reasoning.

</details>


### [35] [Learning Geometric Invariance for Gait Recognition](https://arxiv.org/abs/2601.05604)
*Zengbin Wang,Junjie Li,Saihui Hou,Xu Liu,Chunshui Cao,Yongzhen Huang,Muyi Sun,Siye Wang,Man Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的步态识别框架RRS-Gait，通过显式建模步态变化中的几何变换（反射、旋转、缩放）来实现几何不变性，从而提升跨视角、跨着装等复杂条件下的身份识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法多隐式学习不同条件下的共性特征，缺乏对不同步态条件间内在关系的显式建模；本文旨在建立不同步态条件间的显式联系，将变化建模为几何变换组合。

Method: 提出RRS-Gait框架，针对反射（Reflect）、旋转（Rotate）、缩放（Scale）三种几何变换，设计可调卷积核以实现近似特征等变性，并通过全局池化实现最终的不变性学习。

Result: 在Gait3D、GREW、CCPG、SUSTech1K四个主流步态数据集上，RRS-Gait在多种步态条件下均展现出优越性能。

Conclusion: 显式建模几何变换并实现其不变性是提升步态识别鲁棒性的有效新范式，几何不变性可自然导出身份不变性。

Abstract: The goal of gait recognition is to extract identity-invariant features of an individual under various gait conditions, e.g., cross-view and cross-clothing. Most gait models strive to implicitly learn the common traits across different gait conditions in a data-driven manner to pull different gait conditions closer for recognition. However, relatively few studies have explicitly explored the inherent relations between different gait conditions. For this purpose, we attempt to establish connections among different gait conditions and propose a new perspective to achieve gait recognition: variations in different gait conditions can be approximately viewed as a combination of geometric transformations. In this case, all we need is to determine the types of geometric transformations and achieve geometric invariance, then identity invariance naturally follows. As an initial attempt, we explore three common geometric transformations (i.e., Reflect, Rotate, and Scale) and design a $\mathcal{R}$eflect-$\mathcal{R}$otate-$\mathcal{S}$cale invariance learning framework, named ${\mathcal{RRS}}$-Gait. Specifically, it first flexibly adjusts the convolution kernel based on the specific geometric transformations to achieve approximate feature equivariance. Then these three equivariant-aware features are respectively fed into a global pooling operation for final invariance-aware learning. Extensive experiments on four popular gait datasets (Gait3D, GREW, CCPG, SUSTech1K) show superior performance across various gait conditions.

</details>


### [36] [LatentVLA: Efficient Vision-Language Models for Autonomous Driving via Latent Action Prediction](https://arxiv.org/abs/2601.05611)
*Chengen Xie,Bin Sun,Tianyu Li,Junjie Wu,Zhihui Hao,XianPeng Lang,Hongyang Li*

Main category: cs.CV

TL;DR: 本文提出LatentVLA框架，通过自监督潜在动作预测和知识蒸馏，摆脱语言标注依赖、提升轨迹预测精度与实时性，在NAVSIM和nuScenes上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶模型在长尾罕见场景中泛化能力差；虽有VLA模型引入多模态先验知识，但仍受限于轨迹离散化误差、语言标注偏差与计算低效问题。

Method: 提出LatentVLA：1）采用自监督方式在无语言标注的轨迹数据上学习潜在动作表征；2）利用知识蒸馏将VLA模型的泛化能力迁移至轻量视觉网络。

Result: 在NAVSIM基准上PDMS达92.4（新SOTA），在nuScenes上实现强零样本泛化；同时兼顾高鲁棒性与实时推理效率。

Conclusion: LatentVLA有效解耦语言依赖与动作建模，为高效、通用、可部署的端到端自动驾驶提供了新范式。

Abstract: End-to-end autonomous driving models trained on largescale datasets perform well in common scenarios but struggle with rare, long-tail situations due to limited scenario diversity. Recent Vision-Language-Action (VLA) models leverage broad knowledge from pre-trained visionlanguage models to address this limitation, yet face critical challenges: (1) numerical imprecision in trajectory prediction due to discrete tokenization, (2) heavy reliance on language annotations that introduce linguistic bias and annotation burden, and (3) computational inefficiency from multi-step chain-of-thought reasoning hinders real-time deployment. We propose LatentVLA, a novel framework that employs self-supervised latent action prediction to train VLA models without language annotations, eliminating linguistic bias while learning rich driving representations from unlabeled trajectory data. Through knowledge distillation, LatentVLA transfers the generalization capabilities of VLA models to efficient vision-based networks, achieving both robust performance and real-time efficiency. LatentVLA establishes a new state-of-the-art on the NAVSIM benchmark with a PDMS score of 92.4 and demonstrates strong zeroshot generalization on the nuScenes benchmark.

</details>


### [37] [Compressing image encoders via latent distillation](https://arxiv.org/abs/2601.05639)
*Caroline Mazini Rodrigues,Nicolas Keriven,Thomas Maugey*

Main category: cs.CV

TL;DR: 本文提出一种简化知识蒸馏策略，用于压缩图像压缩深度学习模型的编码器，从而在减少数据和训练时间的同时，保持重建质量和统计保真度。


<details>
  <summary>Details</summary>
Motivation: 深度学习图像压缩模型通常复杂、计算资源需求高，在硬件受限的应用中存在实际限制。

Method: 采用简化的知识蒸馏策略，近似原始模型的潜在空间，以生成轻量级编码器。

Result: 实验表明，该方法在重建质量和统计保真度上优于直接用原始损失训练轻量级编码器的方法。

Conclusion: 所提方法适用于资源受限环境，是一种实用的模型压缩方案。

Abstract: Deep learning models for image compression often face practical limitations in hardware-constrained applications. Although these models achieve high-quality reconstructions, they are typically complex, heavyweight, and require substantial training data and computational resources. We propose a methodology to partially compress these networks by reducing the size of their encoders. Our approach uses a simplified knowledge distillation strategy to approximate the latent space of the original models with less data and shorter training, yielding lightweight encoders from heavyweight ones. We evaluate the resulting lightweight encoders across two different architectures on the image compression task. Experiments show that our method preserves reconstruction quality and statistical fidelity better than training lightweight encoders with the original loss, making it practical for resource-limited environments.

</details>


### [38] [SGDrive: Scene-to-Goal Hierarchical World Cognition for Autonomous Driving](https://arxiv.org/abs/2601.05640)
*Jingyu Li,Junjie Wu,Dongnan Hu,Xiangkai Huang,Bin Sun,Zhihui Hao,Xianpeng Lang,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: SGDrive提出了一种基于驾驶认知的场景-智能体-目标分层结构，以增强视觉语言模型在自动驾驶中的时空表征能力，并在NAVSIM基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）作为通用模型，缺乏对驾驶特有三维时空推理的理解，难以构建支持安全轨迹规划的结构化时空表征。

Method: SGDrive基于预训练VLM主干，引入场景-智能体-目标（Scene-Agent-Goal）三级分层结构，模拟人类驾驶认知过程，将环境感知、关键智能体行为建模与短期目标生成解耦并融合。

Result: 在NAVSIM基准的PDMS和EPDMS指标上，SGDrive在纯摄像头方法中达到最先进（SOTA）性能。

Conclusion: 将驾驶知识显式结构化为分层表征可有效弥补通用VLM在自动驾驶任务中的时空建模缺陷，提升规划性能。

Abstract: Recent end-to-end autonomous driving approaches have leveraged Vision-Language Models (VLMs) to enhance planning capabilities in complex driving scenarios. However, VLMs are inherently trained as generalist models, lacking specialized understanding of driving-specific reasoning in 3D space and time. When applied to autonomous driving, these models struggle to establish structured spatial-temporal representations that capture geometric relationships, scene context, and motion patterns critical for safe trajectory planning. To address these limitations, we propose SGDrive, a novel framework that explicitly structures the VLM's representation learning around driving-specific knowledge hierarchies. Built upon a pre-trained VLM backbone, SGDrive decomposes driving understanding into a scene-agent-goal hierarchy that mirrors human driving cognition: drivers first perceive the overall environment (scene context), then attend to safety-critical agents and their behaviors, and finally formulate short-term goals before executing actions. This hierarchical decomposition provides the structured spatial-temporal representation that generalist VLMs lack, integrating multi-level information into a compact yet comprehensive format for trajectory planning. Extensive experiments on the NAVSIM benchmark demonstrate that SGDrive achieves state-of-the-art performance among camera-only methods on both PDMS and EPDMS, validating the effectiveness of hierarchical knowledge structuring for adapting generalist VLMs to autonomous driving.

</details>


### [39] [SketchVL: Policy Optimization via Fine-Grained Credit Assignment for Chart Understanding and More](https://arxiv.org/abs/2601.05688)
*Muye Huang,Lingling Zhang,Yifei Li,Yaqiang Wu,Jun Liu*

Main category: cs.CV

TL;DR: 本文提出SketchVL模型，结合FinePO强化学习算法与细粒度过程奖励模型（FinePRM），通过在图像上绘制中间推理步骤并反馈给模型自身，实现对每个推理步骤的精细信用分配，显著提升图表理解等复杂视觉推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MLLMs）在自动图表理解任务中面临精确复杂视觉推理的挑战，尤其在强化学习训练中存在轨迹级优势估计难以区分单次响应内正确与错误推理步骤的信用分配问题。

Method: 提出SketchVL模型，其核心是FinePO强化学习算法和细粒度过程奖励模型（FinePRM）；模型将中间推理步骤以标记形式绘制在图像上，并将标注图像反馈回自身，构建多步推理闭环；FinePO利用FinePRM对轨迹中每一步绘图动作打分，实现步骤级信用分配。

Result: SketchVL在图表数据集、自然图像数据集和数学任务上平均性能比基线模型提升7.23%，验证了细粒度信用分配机制的有效性。

Conclusion: 细粒度过程级强化学习可有效提升多模态大模型在复杂视觉推理任务中的表现，SketchVL为构建强推理能力模型提供了新范式。

Abstract: Charts are high-density visual carriers of complex data and medium for information extraction and analysis. Due to the need for precise and complex visual reasoning, automated chart understanding poses a significant challenge to existing Multimodal Large Language Models (MLLMs). Many MLLMs trained with reinforcement learning (RL) face the challenge of credit assignment. Their advantage estimation, typically performed at the trajectory level, cannot distinguish between correct and incorrect reasoning steps within a single generated response. To address this limitation, we introduce SketchVL, a novel MLLM that optimized with FinePO, a new RL algorithm designed for fine-grained credit assignment within each trajectory. SketchVL's methodology involves drawing its intermediate reasoning steps as markers on the image and feeding the annotated image back to itself, creating a robust, multi-step reasoning process. During training, the FinePO algorithm leverages a Fine-grained Process Reward Model (FinePRM) to score each drawing action within a trajectory, thereby precisely assigning credit for each step. This mechanism allows FinePO to more strongly reward correct tokens when a trajectory is globally successful, and more heavily penalize incorrect tokens when the trajectory is globally suboptimal, thus achieving fine-grained reinforcement signals. Experiments show that SketchVL learns to align its step-level behavior with the FinePRM, achieving an average performance gain of 7.23\% over its base model across chart datasets, natural image datasets, and mathematics, providing a promising new direction for training powerful reasoning models.

</details>


### [40] [Rotate Your Character: Revisiting Video Diffusion Models for High-Quality 3D Character Generation](https://arxiv.org/abs/2601.05722)
*Jin Wang,Jianxiang Lu,Comi Chen,Guangzheng Xu,Haoyu Yang,Peng Chen,Na Zhang,Yifan Xu,Longhuang Wu,Shuai Shao,Qinglin Lu,Ping Luo*

Main category: cs.CV

TL;DR: RCM是一个先进的图像到视频扩散框架，用于高质量的新视角合成和3D角色生成，支持复杂姿态转换、高分辨率轨道视频生成、可控观测位置及多视图条件输入。


<details>
  <summary>Details</summary>
Motivation: 解决单张图像生成高质量3D角色的挑战，尤其是复杂姿态和自遮挡问题。

Method: 提出RCM（Rotate your Character Model），一种专为高质量新视角合成（NVS）和3D角色生成设计的图像到视频扩散框架，具备姿态归一化、高分辨率视频生成、相机姿态控制和多视图条件支持等特性。

Result: 在新视角合成与3D生成质量上均优于当前最先进方法。

Conclusion: RCM显著提升了单图像驱动的3D角色建模能力，兼顾质量、可控性与实用性。

Abstract: Generating high-quality 3D characters from single images remains a significant challenge in digital content creation, particularly due to complex body poses and self-occlusion. In this paper, we present RCM (Rotate your Character Model), an advanced image-to-video diffusion framework tailored for high-quality novel view synthesis (NVS) and 3D character generation. Compared to existing diffusion-based approaches, RCM offers several key advantages: (1) transferring characters with any complex poses into a canonical pose, enabling consistent novel view synthesis across the entire viewing orbit, (2) high-resolution orbital video generation at 1024x1024 resolution, (3) controllable observation positions given different initial camera poses, and (4) multi-view conditioning supporting up to 4 input images, accommodating diverse user scenarios. Extensive experiments demonstrate that RCM outperforms state-of-the-art methods in both novel view synthesis and 3D generation quality.

</details>


### [41] [TAGRPO: Boosting GRPO on Image-to-Video Generation with Direct Trajectory Alignment](https://arxiv.org/abs/2601.05729)
*Jin Wang,Jianxiang Lu,Guangzheng Xu,Comi Chen,Haoyu Yang,Linqing Wang,Peng Chen,Mingtao Chen,Zhichao Hu,Longhuang Wu,Shuai Shao,Qinglin Lu,Ping Luo*

Main category: cs.CV

TL;DR: 本文提出TAGRPO，一种受对比学习启发的图像到视频（I2V）模型后训练框架，通过在中间隐空间应用新型GRPO损失并引入视频记忆库，显著提升I2V生成质量与奖励一致性。


<details>
  <summary>Details</summary>
Motivation: 现有Group Relative Policy Optimization（GRPO）方法在文本到图像/视频任务中有效，但在图像到视频（I2V）任务中难以稳定提升奖励，亟需适配I2V特性的优化框架。

Method: 提出TAGRPO框架：1）利用相同初始噪声生成的rollout视频作为高质量优化信号；2）在中间隐空间设计新型GRPO损失，拉近高奖励轨迹、推远低奖励轨迹；3）引入rollout视频记忆库以提升多样性并降低计算开销。

Result: TAGRPO在I2V生成任务中显著优于DanceGRPO，实现了更一致且更高的奖励提升，同时保持框架简洁性。

Conclusion: TAGRPO验证了针对I2V任务定制化策略优化的必要性与有效性，为基于流匹配的视频生成提供了鲁棒、高效的后训练新范式。

Abstract: Recent studies have demonstrated the efficacy of integrating Group Relative Policy Optimization (GRPO) into flow matching models, particularly for text-to-image and text-to-video generation. However, we find that directly applying these techniques to image-to-video (I2V) models often fails to yield consistent reward improvements. To address this limitation, we present TAGRPO, a robust post-training framework for I2V models inspired by contrastive learning. Our approach is grounded in the observation that rollout videos generated from identical initial noise provide superior guidance for optimization. Leveraging this insight, we propose a novel GRPO loss applied to intermediate latents, encouraging direct alignment with high-reward trajectories while maximizing distance from low-reward counterparts. Furthermore, we introduce a memory bank for rollout videos to enhance diversity and reduce computational overhead. Despite its simplicity, TAGRPO achieves significant improvements over DanceGRPO in I2V generation.

</details>


### [42] [FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time](https://arxiv.org/abs/2601.05738)
*Christopher Thirgood,Oscar Mendez,Erin Ling,Jon Storey,Simon Hadfield*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯泼溅（3DGS）的实时语义SLAM系统FeatureSLAM，通过将稠密特征光栅化与视觉基础模型对齐，实现高保真、语义增强的建图与稳定跟踪，在保持实时性的同时提升了位姿精度（降低9%）和建图精度（提升8%）。


<details>
  <summary>Details</summary>
Motivation: 现有语义SLAM多依赖预定义类别标签，限制下游任务灵活性；需在不牺牲实时性的前提下，提升跟踪稳定性与地图语义丰富度。

Method: 将稠密特征光栅化集成到3DGS的新视角合成中，并与视觉基础模型对齐，支持自由视角、开放集分割，实现端到端实时语义SLAM。

Result: 在标准基准上实现实时跟踪，位姿误差降低9%，建图精度提升8%；语义与语言掩码结果媲美离线3DGS模型，同时保持SOTA级跟踪、深度与RGB渲染性能。

Conclusion: 实时特征嵌入式SLAM不仅拓展了下游应用（如开放集分割），还反哺提升了底层跟踪与建图子系统的精度与鲁棒性。

Abstract: We present a real-time tracking SLAM system that unifies efficient camera tracking with photorealistic feature-enriched mapping using 3D Gaussian Splatting (3DGS). Our main contribution is integrating dense feature rasterization into the novel-view synthesis, aligned with a visual foundation model. This yields strong semantics, going beyond basic RGB-D input, aiding both tracking and mapping accuracy. Unlike previous semantic SLAM approaches (which embed pre-defined class labels) FeatureSLAM enables entirely new downstream tasks via free-viewpoint, open-set segmentation. Across standard benchmarks, our method achieves real-time tracking, on par with state-of-the-art systems while improving tracking stability and map fidelity without prohibitive compute. Quantitatively, we obtain 9\% lower pose error and 8\% higher mapping accuracy compared to recent fixed-set SLAM baselines. Our results confirm that real-time feature-embedded SLAM, is not only valuable for enabling new downstream applications. It also improves the performance of the underlying tracking and mapping subsystems, providing semantic and language masking results that are on-par with offline 3DGS models, alongside state-of-the-art tracking, depth and RGB rendering.

</details>


### [43] [ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers](https://arxiv.org/abs/2601.05741)
*Guray Ozgur,Eduarda Caldeira,Tahar Chettaoui,Jan Niklas Kolf,Marco Huber,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的Face Image Quality Assessment（FIQA）方法ViTNT-FIQA，通过分析ViT中间层patch embedding演化的稳定性来评估人脸图像质量，仅需单次前向传播，且在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有FIQA方法多依赖最终层特征或需多次前向传播/反向传播，缺乏高效、即插即用的训练-free方案。

Method: 利用预训练ViT模型，计算连续Transformer块间L2归一化patch embedding的欧氏距离，聚合为图像级质量分，衡量patch embedding演化轨迹的稳定性。

Result: 在含可控退化程度的合成数据集及8个公开基准（LFW、AgeDB-30等）上验证了方法有效性，性能媲美SOTA，且仅需单次前向传播、无需反向传播或模型修改。

Conclusion: ViTNT-FIQA是一种高效、通用、即插即用的训练-free FIQA方法，为基于ViT的人脸识别系统提供了轻量可靠的图像质量评估工具。

Abstract: Face Image Quality Assessment (FIQA) is essential for reliable face recognition systems. Current approaches primarily exploit only final-layer representations, while training-free methods require multiple forward passes or backpropagation. We propose ViTNT-FIQA, a training-free approach that measures the stability of patch embedding evolution across intermediate Vision Transformer (ViT) blocks. We demonstrate that high-quality face images exhibit stable feature refinement trajectories across blocks, while degraded images show erratic transformations. Our method computes Euclidean distances between L2-normalized patch embeddings from consecutive transformer blocks and aggregates them into image-level quality scores. We empirically validate this correlation on a quality-labeled synthetic dataset with controlled degradation levels. Unlike existing training-free approaches, ViTNT-FIQA requires only a single forward pass without backpropagation or architectural modifications. Through extensive evaluation on eight benchmarks (LFW, AgeDB-30, CFP-FP, CALFW, Adience, CPLFW, XQLFW, IJB-C), we show that ViTNT-FIQA achieves competitive performance with state-of-the-art methods while maintaining computational efficiency and immediate applicability to any pre-trained ViT-based face recognition model.

</details>


### [44] [Adaptive Disentangled Representation Learning for Incomplete Multi-View Multi-Label Classification](https://arxiv.org/abs/2601.05785)
*Quanjiang Li,Zhiming Liu,Tianxiang Xu,Tingjin Luo,Chenping Hou*

Main category: cs.CV

TL;DR: 本文提出了一种自适应解耦表示学习方法（ADRL），用于解决多视图多标签学习中特征缺失与标注不全的联合挑战，通过跨模态邻域感知特征传播、随机掩码增强重建、标签分布关联建模、互信息一致性约束、原型驱动特征选择及伪标签引导的判别性视图融合，实现了鲁棒的视图补全与标签语义建模。


<details>
  <summary>Details</summary>
Motivation: 多视图多标签学习常面临特征缺失和标注不全的双重问题，现有方法在特征恢复、表示解耦和标签语义建模方面存在局限。

Method: 提出ADRL方法：1）邻域感知的跨模态特征传播实现鲁棒视图补全；2）随机掩码策略增强重建；3）类别级关联传播优化标签分布参数；4）基于互信息的目标函数提升共享表示一致性并抑制模态间信息重叠；5）理论推导可训练的双通道网络边界；6）原型特异性特征选择与伪标签生成；7）利用伪标签空间结构指导判别性视图融合。

Result: 在多个公开数据集和真实应用场景上，ADRL展现出优越性能。

Conclusion: ADRL有效应对多视图多标签学习中的特征缺失与标注不全问题，在表示解耦、语义建模与视图融合方面取得显著进展。

Abstract: Multi-view multi-label learning frequently suffers from simultaneous feature absence and incomplete annotations, due to challenges in data acquisition and cost-intensive supervision. To tackle the complex yet highly practical problem while overcoming the existing limitations of feature recovery, representation disentanglement, and label semantics modeling, we propose an Adaptive Disentangled Representation Learning method (ADRL). ADRL achieves robust view completion by propagating feature-level affinity across modalities with neighborhood awareness, and reinforces reconstruction effectiveness by leveraging a stochastic masking strategy. Through disseminating category-level association across label distributions, ADRL refines distribution parameters for capturing interdependent label prototypes. Besides, we formulate a mutual-information-based objective to promote consistency among shared representations and suppress information overlap between view-specific representation and other modalities. Theoretically, we derive the tractable bounds to train the dual-channel network. Moreover, ADRL performs prototype-specific feature selection by enabling independent interactions between label embeddings and view representations, accompanied by the generation of pseudo-labels for each category. The structural characteristics of the pseudo-label space are then exploited to guide a discriminative trade-off during view fusion. Finally, extensive experiments on public datasets and real-world applications demonstrate the superior performance of ADRL.

</details>


### [45] [Boosting Latent Diffusion Models via Disentangled Representation Alignment](https://arxiv.org/abs/2601.05823)
*John Page,Xuesong Niu,Kai Wu,Kun Gai*

Main category: cs.CV

TL;DR: 本文提出Semantic disentangled VAE (Send-VAE)，通过将VAE潜在空间与视觉基础模型（VFM）的语义层次对齐，显式优化语义解耦表征学习，从而提升图像生成质量与训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法将VAE与LDM共用同一视觉基础模型（VFM）作为表征对齐目标，但二者对潜在表征的需求本质不同：LDM需高层语义，而VAE更需属性级解耦。

Method: 提出Send-VAE，引入非线性映射网络将VAE潜在表示对齐至预训练VFM的语义层次，以实现属性级解耦与高层语义的协同；采用线性探针在属性预测任务上评估解耦程度。

Result: Send-VAE在ImageNet 256×256上训练SiT模型，FID达1.21（含CFG）和1.75（无CFG），为当前最优；同时显著加速训练。

Conclusion: VAE应专精于语义解耦而非简单复刻LDM的语义目标；Send-VAE验证了面向解耦的VFM对齐策略可兼顾生成质量与效率。

Abstract: Latent Diffusion Models (LDMs) generate high-quality images by operating in a compressed latent space, typically obtained through image tokenizers such as Variational Autoencoders (VAEs). In pursuit of a generation-friendly VAE, recent studies have explored leveraging Vision Foundation Models (VFMs) as representation alignment targets for VAEs, mirroring the approach commonly adopted for LDMs. Although this yields certain performance gains, using the same alignment target for both VAEs and LDMs overlooks their fundamentally different representational requirements. We advocate that while LDMs benefit from latents retaining high-level semantic concepts, VAEs should excel in semantic disentanglement, enabling encoding of attribute-level information in a structured way. To address this, we propose the Semantic disentangled VAE (Send-VAE), explicitly optimized for disentangled representation learning through aligning its latent space with the semantic hierarchy of pre-trained VFMs. Our approach employs a non-linear mapper network to transform VAE latents, aligning them with VFMs to bridge the gap between attribute-level disentanglement and high-level semantics, facilitating effective guidance for VAE learning. We evaluate semantic disentanglement via linear probing on attribute prediction tasks, showing strong correlation with improved generation performance. Finally, using Send-VAE, we train flow-based transformers SiTs; experiments show Send-VAE significantly speeds up training and achieves a state-of-the-art FID of 1.21 and 1.75 with and without classifier-free guidance on ImageNet 256x256.

</details>


### [46] [GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras](https://arxiv.org/abs/2601.05839)
*Weimin Liu,Wenjun Wang,Joshua H. Meng*

Main category: cs.CV

TL;DR: 本文提出GeoSurDepth框架，利用几何一致性作为主要线索进行环视深度估计，结合基础模型提供伪几何先验和特征增强，并引入新颖的2D-3D提升视图合成流程与自适应联合运动学习策略，在DDAD和nuScenes数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注光度层面的跨视角约束，而较少显式利用单目与环视设置中固有的丰富几何结构；准确的环视深度估计对自动驾驶中的3D场景理解至关重要，是激光雷达的有力替代方案。

Method: 提出GeoSurDepth框架：1）利用基础模型作为伪几何先验和特征增强工具，保障3D空间表面法向一致性及2D对象/纹理一致的深度估计；2）设计新型视图合成流程，通过空间扭曲重建密集深度实现2D-3D提升，并在时序、空间及时空上下文中引入额外光度监督；3）提出自适应联合运动学习策略，动态强调信息丰富的空间几何线索以提升运动推理能力。

Result: 在DDAD和nuScenes数据集上取得当前最优（state-of-the-art）性能，验证了所提方法的有效性。

Conclusion: 几何一致性与连贯性对于鲁棒的自监督多视角深度估计至关重要，GeoSurDepth成功将几何先验深度融入环视深度估计框架，显著提升了性能与泛化能力。

Abstract: Accurate surround-view depth estimation provides a competitive alternative to laser-based sensors and is essential for 3D scene understanding in autonomous driving. While prior studies have proposed various approaches that primarily focus on enforcing cross-view constraints at the photometric level, few explicitly exploit the rich geometric structure inherent in both monocular and surround-view setting. In this work, we propose GeoSurDepth, a framework that leverages geometry consistency as the primary cue for surround-view depth estimation. Concretely, we utilize foundation models as a pseudo geometry prior and feature representation enhancement tool to guide the network to maintain surface normal consistency in spatial 3D space and regularize object- and texture-consistent depth estimation in 2D. In addition, we introduce a novel view synthesis pipeline where 2D-3D lifting is achieved with dense depth reconstructed via spatial warping, encouraging additional photometric supervision across temporal, spatial, and spatial-temporal contexts, and compensating for the limitations of single-view image reconstruction. Finally, a newly-proposed adaptive joint motion learning strategy enables the network to adaptively emphasize informative spatial geometry cues for improved motion reasoning. Extensive experiments on DDAD and nuScenes demonstrate that GeoSurDepth achieves state-of-the-art performance, validating the effectiveness of our approach. Our framework highlights the importance of exploiting geometry coherence and consistency for robust self-supervised multi-view depth estimation.

</details>


### [47] [Kidney Cancer Detection Using 3D-Based Latent Diffusion Models](https://arxiv.org/abs/2601.05852)
*Jen Dusseljee,Sarah de Boer,Alessa Hering*

Main category: cs.CV

TL;DR: 本文提出了一种基于潜在扩散模型的3D肾脏异常检测新方法，结合DDPM、DDIM和VQ-GAN，在对比增强腹部CT上实现弱监督（仅需病例级伪标签）下的体积级检测，虽未超越监督基线，但为少标注生成建模提供了重要方向。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法多为切片级、依赖密集像素级标注的问题，探索更符合临床实际的弱监督、体积级3D异常检测范式。

Method: 构建融合DDPM、DDIM与VQ-GAN的潜在扩散pipeline，直接处理3D CT体数据，利用病例级伪标签进行弱监督训练。

Result: 在3D肾脏异常检测任务上验证了该方法的可行性；性能暂未达到监督分割/检测模型水平，但在重建保真度和病灶定位方面揭示了关键改进方向。

Conclusion: 3D潜在扩散模型在弱监督医学图像异常检测中具有潜力，是迈向少标注、生成式建模复杂腹部解剖结构的重要一步。

Abstract: In this work, we present a novel latent diffusion-based pipeline for 3D kidney anomaly detection on contrast-enhanced abdominal CT. The method combines Denoising Diffusion Probabilistic Models (DDPMs), Denoising Diffusion Implicit Models (DDIMs), and Vector-Quantized Generative Adversarial Networks (VQ-GANs). Unlike prior slice-wise approaches, our method operates directly on an image volume and leverages weak supervision with only case-level pseudo-labels. We benchmark our approach against state-of-the-art supervised segmentation and detection models. This study demonstrates the feasibility and promise of 3D latent diffusion for weakly supervised anomaly detection. While the current results do not yet match supervised baselines, they reveal key directions for improving reconstruction fidelity and lesion localization. Our findings provide an important step toward annotation-efficient, generative modeling of complex abdominal anatomy.

</details>


### [48] [Bidirectional Channel-selective Semantic Interaction for Semi-Supervised Medical Segmentation](https://arxiv.org/abs/2601.05855)
*Kaiwen Huang,Yizhe Zhang,Yi Zhou,Tianyang Xu,Tao Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种面向半监督医学图像分割的双向通道选择语义交互（BCSI）框架，通过语义空间扰动（SSP）、通道选择路由器（CR）和双向通道级交互（BCI）三个核心模块，有效缓解了误差累积、模型复杂及标签/无标签数据交互不足等问题，在多个3D医学数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督医学图像分割方法依赖均值教师或双流一致性学习，存在误差累积、结构复杂、忽视有标签与无标签数据流间交互等问题。

Method: 提出BCSI框架，包含：1）语义-空间扰动（SSP）机制，结合强/弱增强与伪标签监督，并对两种强增强预测施加一致性约束；2）通道选择路由器（CR），动态筛选高相关通道进行跨数据流信息交换；3）双向通道级交互（BCI），增强关键通道语义表征。

Result: 在多个3D医学图像分割基准数据集上，该方法性能优于现有半监督方法。

Conclusion: BCSI框架通过协同优化扰动策略、通道选择与双向交互，显著提升了半监督设置下的分割精度与鲁棒性，为小样本医学图像分析提供了新思路。

Abstract: Semi-supervised medical image segmentation is an effective method for addressing scenarios with limited labeled data. Existing methods mainly rely on frameworks such as mean teacher and dual-stream consistency learning. These approaches often face issues like error accumulation and model structural complexity, while also neglecting the interaction between labeled and unlabeled data streams. To overcome these challenges, we propose a Bidirectional Channel-selective Semantic Interaction~(BCSI) framework for semi-supervised medical image segmentation. First, we propose a Semantic-Spatial Perturbation~(SSP) mechanism, which disturbs the data using two strong augmentation operations and leverages unsupervised learning with pseudo-labels from weak augmentations. Additionally, we employ consistency on the predictions from the two strong augmentations to further improve model stability and robustness. Second, to reduce noise during the interaction between labeled and unlabeled data, we propose a Channel-selective Router~(CR) component, which dynamically selects the most relevant channels for information exchange. This mechanism ensures that only highly relevant features are activated, minimizing unnecessary interference. Finally, the Bidirectional Channel-wise Interaction~(BCI) strategy is employed to supplement additional semantic information and enhance the representation of important channels. Experimental results on multiple benchmarking 3D medical datasets demonstrate that the proposed method outperforms existing semi-supervised approaches.

</details>


### [49] [Phase4DFD: Multi-Domain Phase-Aware Attention for Deepfake Detection](https://arxiv.org/abs/2601.05861)
*Zhen-Xin Lin,Shang-Kuan Chen*

Main category: cs.CV

TL;DR: 本文提出Phase4DFD，一种相位感知的频域深度伪造检测框架，通过可学习注意力机制显式建模相位与幅度交互，结合FFT幅度、LBP及相位不连续性引导注意力，提升检测性能且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法多依赖频谱幅度，忽视相位信息中蕴含的合成伪影线索。

Method: 提出Phase4DFD框架：融合RGB、FFT幅度和LBP特征；设计输入级相位感知注意力模块，利用合成引入的相位不连续性引导关注判别性频域模式；采用BNext-M主干网络，可选加通道-空间注意力进行语义特征细化。

Result: 在CIFAKE和DFFD数据集上显著超越现有空间域和频域SOTA方法，计算开销低；消融实验验证相位建模提供幅度之外互补且非冗余的信息。

Conclusion: 显式建模相位信息对深度伪造检测至关重要，Phase4DFD为频域检测提供了更全面、高效的新范式。

Abstract: Recent deepfake detection methods have increasingly explored frequency domain representations to reveal manipulation artifacts that are difficult to detect in the spatial domain. However, most existing approaches rely primarily on spectral magnitude, implicitly under exploring the role of phase information. In this work, we propose Phase4DFD, a phase aware frequency domain deepfake detection framework that explicitly models phase magnitude interactions via a learnable attention mechanism. Our approach augments standard RGB input with Fast Fourier Transform (FFT) magnitude and local binary pattern (LBP) representations to expose subtle synthesis artifacts that remain indistinguishable under spatial analysis alone. Crucially, we introduce an input level phase aware attention module that uses phase discontinuities commonly introduced by synthetic generation to guide the model toward frequency patterns that are most indicative of manipulation before backbone feature extraction. The attended multi domain representation is processed by an efficient BNext M backbone, with optional channel spatial attention applied for semantic feature refinement. Extensive experiments on the CIFAKE and DFFD datasets demonstrate that our proposed model Phase4DFD outperforms state of the art spatial and frequency-based detectors while maintaining low computational overhead. Comprehensive ablation studies further confirm that explicit phase modeling provides complementary and non-redundant information beyond magnitude-only frequency representations.

</details>


### [50] [Adapting Vision Transformers to Ultra-High Resolution Semantic Segmentation with Relay Tokens](https://arxiv.org/abs/2601.05927)
*Yohann Perron,Vladyslav Sydorov,Christophe Pottier,Loic Landrieu*

Main category: cs.CV

TL;DR: 本文提出了一种基于中继令牌（relay tokens）的多尺度视觉Transformer方法，用于超高清图像分割，兼顾局部细节与全局上下文，在多个基准上显著提升mIoU。


<details>
  <summary>Details</summary>
Motivation: 现有超高清图像分割方法要么滑动窗口丢失全局上下文，要么下采样损失细节，亟需兼顾二者的新方法。

Method: 在局部尺度（高分辨率小块）和全局尺度（低分辨率大块）并行处理图像，并通过少量可学习的中继令牌在两分支间聚合与传播特征；该设计可即插即用地集成到ViT、Swin等标准Transformer骨干网络中。

Result: 在Archaeoscape、URUR、Gleason三个超高清分割基准及Cityscapes上均取得一致性能提升，最高达15%相对mIoU增益。

Conclusion: 引入显式多尺度推理的中继令牌机制是一种简单高效、参数增加极少（<2%）且通用性强的超高清图像分割新范式。

Abstract: Current approaches for segmenting ultra high resolution images either slide a window, thereby discarding global context, or downsample and lose fine detail. We propose a simple yet effective method that brings explicit multi scale reasoning to vision transformers, simultaneously preserving local details and global awareness. Concretely, we process each image in parallel at a local scale (high resolution, small crops) and a global scale (low resolution, large crops), and aggregate and propagate features between the two branches with a small set of learnable relay tokens. The design plugs directly into standard transformer backbones (eg ViT and Swin) and adds fewer than 2 % parameters. Extensive experiments on three ultra high resolution segmentation benchmarks, Archaeoscape, URUR, and Gleason, and on the conventional Cityscapes dataset show consistent gains, with up to 15 % relative mIoU improvement. Code and pretrained models are available at https://archaeoscape.ai/work/relay-tokens/ .

</details>


### [51] [Performance of a Deep Learning-Based Segmentation Model for Pancreatic Tumors on Public Endoscopic Ultrasound Datasets](https://arxiv.org/abs/2601.05937)
*Pankaj Gupta,Priya Mudgil,Niharika Dutta,Kartik Bose,Nitish Kumar,Anupam Kumar,Jimil Shah,Vaneet Jearth,Jayanta Samanta,Vishal Sharma,Harshal Mandavdhare,Surinder Rana,Saroj K Sinha,Usha Dutta*

Main category: cs.CV

TL;DR: 本研究开发了一种基于Vision Transformer的深度学习分割模型，用于内镜超声（EUS）图像中的胰腺肿瘤自动分割，结果表明其在内部和外部验证中均表现出较高的特异性和准确率，但存在多预测错误等问题，需进一步优化与标准化。


<details>
  <summary>Details</summary>
Motivation: 胰腺癌恶性程度高、生存率低，而内镜超声（EUS）诊断效果受限于操作者主观性，亟需客观、自动化的肿瘤分割方法。

Method: 采用USFM框架与Vision Transformer主干网络构建分割模型；使用两个公开数据集共17,367张EUS图像进行5折交叉验证，独立测试集含350张由放射科医生手工标注的EUS图像；预处理包括灰度化、裁剪和缩放至512×512像素；评估指标包括Dice系数（DSC）、IoU、敏感性、特异性和准确率。

Result: 5折交叉验证平均DSC为0.651±0.738，IoU为0.579±0.658，敏感性69.8%，特异性98.8%，准确率97.5%；外部验证集DSC为0.657（95% CI: 0.634–0.769），IoU为0.614（95% CI: 0.590–0.689），敏感性71.8%，特异性97.7%；约9.7%样本出现错误的多重预测。

Conclusion: 该Vision Transformer模型在EUS图像胰腺肿瘤分割中展现出良好性能，尤其在特异性和整体准确率方面；但数据异质性、外部验证规模有限及多重预测错误等问题提示仍需模型优化、数据标准化及前瞻性研究验证。

Abstract: Background: Pancreatic cancer is one of the most aggressive cancers, with poor survival rates. Endoscopic ultrasound (EUS) is a key diagnostic modality, but its effectiveness is constrained by operator subjectivity. This study evaluates a Vision Transformer-based deep learning segmentation model for pancreatic tumors. Methods: A segmentation model using the USFM framework with a Vision Transformer backbone was trained and validated with 17,367 EUS images (from two public datasets) in 5-fold cross-validation. The model was tested on an independent dataset of 350 EUS images from another public dataset, manually segmented by radiologists. Preprocessing included grayscale conversion, cropping, and resizing to 512x512 pixels. Metrics included Dice similarity coefficient (DSC), intersection over union (IoU), sensitivity, specificity, and accuracy. Results: In 5-fold cross-validation, the model achieved a mean DSC of 0.651 +/- 0.738, IoU of 0.579 +/- 0.658, sensitivity of 69.8%, specificity of 98.8%, and accuracy of 97.5%. For the external validation set, the model achieved a DSC of 0.657 (95% CI: 0.634-0.769), IoU of 0.614 (95% CI: 0.590-0.689), sensitivity of 71.8%, and specificity of 97.7%. Results were consistent, but 9.7% of cases exhibited erroneous multiple predictions. Conclusions: The Vision Transformer-based model demonstrated strong performance for pancreatic tumor segmentation in EUS images. However, dataset heterogeneity and limited external validation highlight the need for further refinement, standardization, and prospective studies.

</details>


### [52] [Context-Aware Decoding for Faithful Vision-Language Generation](https://arxiv.org/abs/2601.05939)
*Mehrdad Fazli,Bowen Wei,Ziwei Zhu*

Main category: cs.CV

TL;DR: 本文发现大型视觉语言模型（LVLMs）在解码过程中存在‘承诺深度差距’，即真实token比幻觉token更早地在高层积累概率质量；据此提出无需训练的轻量级方法Context Embedding Injection（CEI），利用输入末尾token的隐状态作为视觉保真锚点，显著降低多种基准上的幻觉率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在开放任务（如图像描述、视觉推理）中普遍存在幻觉问题，即生成与视觉输入不一致的内容，亟需深入理解其生成机制并提出高效缓解策略。

Method: 采用Logit Lens分析LVLMs各解码层的逐token概率分布演化，发现‘承诺-depth gap’现象；基于此，提出无需训练的Context Embedding Injection（CEI）方法，将最后一个输入token的隐藏状态（上下文嵌入）注入解码过程，作为视觉一致性约束信号。

Result: CEI在CHAIR、AMBER和MMHal-Bench三个基准（最大生成长度512）上全面超越现有SOTA方法，在三类LVLM上均取得最低整体幻觉率，其中动态变体效果最优。

Conclusion: 本文通过揭示LVLMs层间生成动力学中的关键机制，并设计可扩展、免训练的干预手段CEI，为系统性缓解LVLM幻觉问题提供了新范式。

Abstract: Hallucinations, generating responses inconsistent with the visual input, remain a critical limitation of large vision-language models (LVLMs), especially in open-ended tasks such as image captioning and visual reasoning. In this work, we probe the layer-wise generation dynamics that drive hallucinations and propose a training-free mitigation strategy. Employing the Logit Lens, we examine how LVLMs construct next-token distributions across decoder layers, uncovering a pronounced commitment-depth gap: truthful tokens accumulate probability mass on their final candidates earlier than hallucinatory ones. Drawing on this discovery, we introduce Context Embedding Injection (CEI), a lightweight method that harnesses the hidden state of the last input token-the context embedding-as a grounding signal to maintain visual fidelity throughout decoding and curb hallucinations. Evaluated on the CHAIR, AMBER, and MMHal-Bench benchmarks (with a maximum token length of 512), CEI outperforms state-of-the-art baselines across three LVLMs, with its dynamic variant yielding the lowest overall hallucination rates. By integrating novel mechanistic insights with a scalable intervention, this work advances the mitigation of hallucinations in LVLMs.

</details>


### [53] [WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation](https://arxiv.org/abs/2601.05942)
*Chanchan Wang,Yuanfang Wang,Qing Xu,Guanxin Chen*

Main category: cs.CV

TL;DR: 本文提出WaveRNet，一种基于小波引导的频域学习框架，用于提升多源域泛化下的视网膜血管分割鲁棒性，通过频谱引导域调制、频域自适应域融合和分层掩码提示优化模块，显著缓解光照与对比度变化导致的域偏移，并保留细小血管结构。


<details>
  <summary>Details</summary>
Motivation: 现有基于SAM的方法忽视频域中蕴含的域不变特征，且直接上采样导致细小血管细节丢失，难以应对非均匀光照和对比度变化引起的域偏移问题。

Method: 提出WaveRNet框架，包含三个核心模块：1）谱引导域调制器（SDM），结合小波分解与可学习域标记，分离低频结构与高频边界；2）频域自适应域融合（FADF），基于小波频率相似性实现测试时智能域选择与加权融合；3）分层掩码提示优化器（HMPR），通过粗到精细化与长程依赖建模克服SAM上采样缺陷。

Result: 在四个公开视网膜数据集上采用Leave-One-Domain-Out协议进行实验，WaveRNet取得当前最优的域泛化性能。

Conclusion: WaveRNet通过显式建模和利用频域信息，有效提升了模型在跨域场景下对光照与对比度变化的鲁棒性，并更好保留细小血管结构，为域泛化医学图像分割提供了新思路。

Abstract: Domain-generalized retinal vessel segmentation is critical for automated ophthalmic diagnosis, yet faces significant challenges from domain shift induced by non-uniform illumination and varying contrast, compounded by the difficulty of preserving fine vessel structures. While the Segment Anything Model (SAM) exhibits remarkable zero-shot capabilities, existing SAM-based methods rely on simple adapter fine-tuning while overlooking frequency-domain information that encodes domain-invariant features, resulting in degraded generalization under illumination and contrast variations. Furthermore, SAM's direct upsampling inevitably loses fine vessel details. To address these limitations, we propose WaveRNet, a wavelet-guided frequency learning framework for robust multi-source domain-generalized retinal vessel segmentation. Specifically, we devise a Spectral-guided Domain Modulator (SDM) that integrates wavelet decomposition with learnable domain tokens, enabling the separation of illumination-robust low-frequency structures from high-frequency vessel boundaries while facilitating domain-specific feature generation. Furthermore, we introduce a Frequency-Adaptive Domain Fusion (FADF) module that performs intelligent test-time domain selection through wavelet-based frequency similarity and soft-weighted fusion. Finally, we present a Hierarchical Mask-Prompt Refiner (HMPR) that overcomes SAM's upsampling limitation through coarse-to-fine refinement with long-range dependency modeling. Extensive experiments under the Leave-One-Domain-Out protocol on four public retinal datasets demonstrate that WaveRNet achieves state-of-the-art generalization performance. The source code is available at https://github.com/Chanchan-Wang/WaveRNet.

</details>


### [54] [VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction](https://arxiv.org/abs/2601.05966)
*Longbin Ji,Xiaoxiong Liu,Junyuan Shang,Shuohuan Wang,Yu Sun,Hua Wu,Haifeng Wang*

Main category: cs.CV

TL;DR: VideoAR is the first large-scale Visual Autoregressive framework for video generation, using multi-scale next-frame prediction and novel techniques to improve temporal consistency and efficiency, achieving SOTA among autoregressive models and competitive performance with much larger diffusion models.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion and flow-matching video generation models yield high quality but suffer from high computational cost and poor scalability; there is a need for efficient, scalable, and temporally consistent alternatives.

Method: VideoAR introduces a multi-scale 3D tokenizer, intra-frame VAR modeling with causal next-frame prediction, Multi-scale Temporal RoPE, Cross-Frame Error Correction, Random Frame Mask, and a multi-stage pretraining pipeline progressively increasing resolution and duration.

Result: VideoAR achieves new SOTA for autoregressive video models: FVD on UCF-101 improves from 99.5 to 88.6, inference steps reduced by >10x, and VBench score reaches 81.74—competitive with far larger diffusion models.

Conclusion: VideoAR narrows the performance gap between autoregressive and diffusion-based video generation, offering a scalable, efficient, and temporally consistent foundation for future research.

Abstract: Recent advances in video generation have been dominated by diffusion and flow-matching models, which produce high-quality results but remain computationally intensive and difficult to scale. In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling. VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE, Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6 while reducing inference steps by over 10x, and reaching a VBench score of 81.74-competitive with diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research.

</details>


### [55] [Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation](https://arxiv.org/abs/2601.05981)
*Yinsong Wang,Xinzhe Luo,Siyi Du,Chen Qin*

Main category: cs.CV

TL;DR: 本文提出了一种自适应条件对比度无关的可变形多对比度图像配准框架AC-CAR，通过随机卷积对比度增强、自适应条件特征调制器（ACFM）和对比度无关不确定性估计，实现了对未见成像对比度的强泛化能力与高精度配准。


<details>
  <summary>Details</summary>
Motivation: 传统配准方法迭代优化耗时，现有学习方法泛化性差，难以应对训练中未见过的成像对比度。

Method: 提出AC-CAR框架，包含随机卷积对比度增强、自适应条件特征调制器（ACFM）以学习对比度不变特征、对比度无关隐空间正则化，以及集成方差网络实现对比度无关不确定性估计。

Result: 在配准精度和对未见对比度的泛化能力上均优于基线方法。

Conclusion: AC-CAR有效解决了多对比度图像配准中对比度泛化性差的问题，兼具高精度与高可靠性，并支持不确定性量化。

Abstract: Deformable multi-contrast image registration is a challenging yet crucial task due to the complex, non-linear intensity relationships across different imaging contrasts. Conventional registration methods typically rely on iterative optimization of the deformation field, which is time-consuming. Although recent learning-based approaches enable fast and accurate registration during inference, their generalizability remains limited to the specific contrasts observed during training. In this work, we propose an adaptive conditional contrast-agnostic deformable image registration framework (AC-CAR) based on a random convolution-based contrast augmentation scheme. AC-CAR can generalize to arbitrary imaging contrasts without observing them during training. To encourage contrast-invariant feature learning, we propose an adaptive conditional feature modulator (ACFM) that adaptively modulates the features and the contrast-invariant latent regularization to enforce the consistency of the learned feature across different imaging contrasts. Additionally, we enable our framework to provide contrast-agnostic registration uncertainty by integrating a variance network that leverages the contrast-agnostic registration encoder to improve the trustworthiness and reliability of AC-CAR. Experimental results demonstrate that AC-CAR outperforms baseline methods in registration accuracy and exhibits superior generalization to unseen imaging contrasts. Code is available at https://github.com/Yinsong0510/AC-CAR.

</details>


### [56] [Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints](https://arxiv.org/abs/2601.05986)
*Adrian Serrano,Erwan Umlil,Ronan Thomas*

Main category: cs.CV

TL;DR: 本文研究了深度伪造检测系统在现实世界中面对对抗性攻击时的鲁棒性，扩展了DUMB/DUMBer方法论，评估了五种主流检测器在跨数据集和迁移攻击下的表现，发现对抗训练在分布内有效但跨数据集时效果不稳定，强调需采用场景感知的防御策略。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练方法在真实场景（攻击者知识有限、数据分布不匹配）下的有效性尚未充分探索，亟需评估深度伪造检测器在实际部署中的鲁棒性。

Method: 扩展DUMB/DUMBer方法论，结合迁移攻击约束与跨数据集配置，对五种SOTA检测器（RECCE、SRM、XCeption、UCF、SPSL）在FaceForensics++和Celeb-DF-V2上，使用PGD、FGSM、FPBA三种攻击进行鲁棒性评估，并从攻击者与防御者双视角分析错配场景。

Result: 对抗训练能提升分布内鲁棒性，但在跨数据集设置下效果不稳定，部分策略反而降低性能；不同检测器与攻击组合表现出显著差异；结果揭示了攻击-防御错配对鲁棒性的关键影响。

Conclusion: 深度伪造检测的实际部署需采用‘案例感知’（case-aware）的防御策略，不能依赖统一的对抗训练范式；鲁棒性评估必须涵盖数据与模型错配的真实条件。

Abstract: Deepfake detection systems deployed in real-world environments are subject to adversaries capable of crafting imperceptible perturbations that degrade model performance. While adversarial training is a widely adopted defense, its effectiveness under realistic conditions -- where attackers operate with limited knowledge and mismatched data distributions - remains underexplored. In this work, we extend the DUMB -- Dataset soUrces, Model architecture and Balance - and DUMBer methodology to deepfake detection. We evaluate detectors robustness against adversarial attacks under transferability constraints and cross-dataset configuration to extract real-world insights. Our study spans five state-of-the-art detectors (RECCE, SRM, XCeption, UCF, SPSL), three attacks (PGD, FGSM, FPBA), and two datasets (FaceForensics++ and Celeb-DF-V2). We analyze both attacker and defender perspectives mapping results to mismatch scenarios. Experiments show that adversarial training strategies reinforce robustness in the in-distribution cases but can also degrade it under cross-dataset configuration depending on the strategy adopted. These findings highlight the need for case-aware defense strategies in real-world applications exposed to adversarial attacks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [57] [Enhancing Foundation Models in Transaction Understanding with LLM-based Sentence Embeddings](https://arxiv.org/abs/2601.05271)
*Xiran Fan,Zhimeng Jiang,Chin-Chia Michael Yeh,Yuzhong Chen,Yingtong Dou,Menghai Pan,Yan Zheng*

Main category: cs.CL

TL;DR: 本文提出了一种混合框架，利用大语言模型（LLM）生成的语义嵌入作为轻量级交易模型的初始化，以弥补传统索引式表示造成的语义损失，在保持可解释性的同时提升实时金融场景下的效率。


<details>
  <summary>Details</summary>
Motivation: 传统交易分析基础模型对商户类别字段采用基于索引的离散化表示，导致丰富的文本语义信息丢失；而直接使用LLM又面临计算开销大、难以实时部署的问题。

Method: 提出一种混合框架：用LLM生成商户字段的语义嵌入作为轻量模型的初始化；引入多源数据融合增强类别字段；采用‘单词约束’原则保证不同LLM架构下嵌入的一致性；并结合噪声过滤与上下文感知的数据增强提升数据质量。

Result: 在大规模交易数据集上的实验表明，该方法在多个交易理解任务中显著提升了性能。

Conclusion: LLM生成的语义嵌入可有效赋能轻量级交易模型，在不牺牲可解释性和实时性的前提下，显著提升交易数据分析效果。

Abstract: The ubiquity of payment networks generates vast transactional data encoding rich consumer and merchant behavioral patterns. Recent foundation models for transaction analysis process tabular data sequentially but rely on index-based representations for categorical merchant fields, causing substantial semantic information loss by converting rich textual data into discrete tokens. While Large Language Models (LLMs) can address this limitation through superior semantic understanding, their computational overhead challenges real-time financial deployment. We introduce a hybrid framework that uses LLM-generated embeddings as semantic initializations for lightweight transaction models, balancing interpretability with operational efficiency. Our approach employs multi-source data fusion to enrich merchant categorical fields and a one-word constraint principle for consistent embedding generation across LLM architectures. We systematically address data quality through noise filtering and context-aware enrichment. Experiments on large-scale transaction datasets demonstrate significant performance improvements across multiple transaction understanding tasks.

</details>


### [58] [The Table of Media Bias Elements: A sentence-level taxonomy of media bias types and propaganda techniques](https://arxiv.org/abs/2601.05358)
*Tim Menzner,Jochen L. Leidner*

Main category: cs.CL

TL;DR: 本文提出了一种细粒度、句子级的媒体偏见与宣传分类法，涵盖38种基本偏见类型，分为六大功能家族，并通过实证分析验证其覆盖度与识别效果。


<details>
  <summary>Details</summary>
Motivation: 现有对新闻偏见的讨论过于聚焦于'左翼'或'右翼'标签，忽视了偏见实际通过具体语言策略体现，且超越单一政治光谱；因此需转向句子层面分析偏见如何被表达。

Method: 基于26,464句来自新闻语料库、用户提交及自主采集的句子，结合细读、跨学科理论与试点标注，迭代构建分类体系，并辅以定量抽样调查与跨体系对照分析。

Result: 构建出两层结构的‘媒体偏见要素表’：含38种基本偏见类型、六大功能家族；每类提供定义、实例、认知/社会动因及识别指南；在155句随机样本中验证了类型分布差异，并显示相较主流NLP与传播学分类体系具有更高覆盖率与更低歧义性。

Conclusion: 该分类法为偏见分析提供了更精细、可操作、跨学科兼容的语言学基础，推动从意识形态标签走向可检验的语言实践研究。

Abstract: Public debates about "left-" or "right-wing" news overlook the fact that bias is usually conveyed by concrete linguistic manoeuvres that transcend any single political spectrum. We therefore shift the focus from where an outlet allegedly stands to how partiality is expressed in individual sentences. Drawing on 26,464 sentences collected from newsroom corpora, user submissions and our own browsing, we iteratively combine close-reading, interdisciplinary theory and pilot annotation to derive a fine-grained, sentence-level taxonomy of media bias and propaganda. The result is a two-tier schema comprising 38 elementary bias types, arranged in six functional families and visualised as a "table of media-bias elements". For each type we supply a definition, real-world examples, cognitive and societal drivers, and guidance for recognition. A quantitative survey of a random 155-sentence sample illustrates prevalence differences, while a cross-walk to the best-known NLP and communication-science taxonomies reveals substantial coverage gains and reduced ambiguity.

</details>


### [59] [Lost in Execution: On the Multilingual Robustness of Tool Calling in Large Language Models](https://arxiv.org/abs/2601.05366)
*Zheng Luo,T Pranav Kutralingam,Ogochukwu N Okoani,Wanpeng Xu,Hua Wei,Xiyang Hu*

Main category: cs.CL

TL;DR: 本文提出了MLCL多语言工具调用诊断基准，系统评估了大语言模型在中文、印地语和低资源语言伊博语中的工具调用鲁棒性，发现参数值语言错配是主要失败模式，并验证了若干推理时策略虽有改善但无法完全恢复英语水平性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注英语环境下的工具调用性能，而大语言模型在多语言用户交互场景下的工具调用鲁棒性尚缺乏深入探索。

Method: 构建多语言诊断基准MLCL，覆盖中文、印地语和低资源语言伊博语；开展系统性评估与细粒度错误分析；测试多种推理时系统策略以缓解语言相关执行错误。

Result: 发现参数值语言错配是主导性失败模式——模型虽正确理解用户意图并选择合适工具，却在用户语言中生成参数值，违反语言无关的执行规范；所测试的推理策略显著降低语言引发的执行错误，但均无法达到英语水平性能。

Conclusion: 多语言工具调用面临独特挑战，尤其参数值语言一致性问题亟待解决；当前推理时方法存在局限，需更根本的语言感知建模或训练机制提升跨语言工具调用鲁棒性。

Abstract: Large Language Models (LLMs) are increasingly deployed as agents that invoke external tools through structured function calls. While recent work reports strong tool-calling performance under standard English-centric evaluations, the robustness of tool calling under multilingual user interactions remains underexplored. In this work, we introduce MLCL, a diagnostic benchmark, and conduct a systematic evaluation of multilingual tool calling across Chinese, Hindi, and the low-resource language Igbo. Through fine-grained error analysis, we show that many failures occur despite correct intent understanding and tool selection. We identify parameter value language mismatch as a dominant failure mode, where models generate semantically appropriate parameter values in the user's language, violating language-invariant execution conventions. We further evaluate several inference-time system strategies and find that while these strategies substantially reduce language-induced execution errors, none of them can fully recover English-level performance.

</details>


### [60] [Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection](https://arxiv.org/abs/2601.05403)
*Zhiwei Liu,Yupen Cao,Yuechen Jiang,Mohsinul Kabir,Polydoros Giannouris,Chen Xu,Ziyang Xu,Tianlei Zhu,Tariquzzaman Faisal,Triantafillos Papadopoulos,Yan Wang,Lingfei Qian,Xueqing Peng,Zhuohan Xie,Ye Yuan,Saeed Almheiri,Abdulrazzaq Alnajjar,Mingbin Chen,Harry Stuart,Paul Thompson,Prayag Tiwari,Alejandro Lopez-Lira,Xue Liu,Jimin Huang,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本文提出MFMDSCEN基准，用于评估大语言模型在多语言金融虚假信息检测任务中的行为偏差，涵盖角色、地域、民族与宗教等复杂经济场景，并构建了覆盖英、中、希、孟四种语言的数据集，发现主流模型普遍存在显著行为偏差。


<details>
  <summary>Details</summary>
Motivation: 现有LLM偏见研究多局限于简单问答或通用场景，缺乏对高风险、上下文敏感、多语言金融虚假信息检测（MFMD）等真实复杂金融环境的考察。

Method: 联合金融专家构建三类复杂金融场景（基于角色与人格、角色与地域、角色结合民族与宗教），并建立覆盖英语、中文、希腊语和孟加拉语的多语言金融虚假信息数据集，系统评测22个主流LLM在MFMDSCEN上的行为偏差。

Result: 在MFMDSCEN基准上，22个主流大语言模型（含商业与开源）均表现出显著的行为偏差。

Conclusion: 大语言模型在真实金融场景下仍存在严重的行为偏差，亟需针对性评估框架（如MFMDSCEN）与后续纠偏研究。

Abstract: Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose settings, with limited consideration of the complex real-world financial environments and high-risk, context-sensitive, multilingual financial misinformation detection tasks (\mfmd). In this work, we propose \mfmdscen, a comprehensive benchmark for evaluating behavioral biases of LLMs in \mfmd across diverse economic scenarios. In collaboration with financial experts, we construct three types of complex financial scenarios: (i) role- and personality-based, (ii) role- and region-based, and (iii) role-based scenarios incorporating ethnicity and religious beliefs. We further develop a multilingual financial misinformation dataset covering English, Chinese, Greek, and Bengali. By integrating these scenarios with misinformation claims, \mfmdscen enables a systematic evaluation of 22 mainstream LLMs. Our findings reveal that pronounced behavioral biases persist across both commercial and open-source models. This project will be available at https://github.com/lzw108/FMD.

</details>


### [61] [Glitter: Visualizing Lexical Surprisal for Readability in Administrative Texts](https://arxiv.org/abs/2601.05411)
*Jan Černý,Ivana Kvapilíková,Silvie Cinková*

Main category: cs.CL

TL;DR: 本文提出了一种基于文本信息熵测量的可读性评估方法，并开发了可视化框架，利用多种语言模型估算和展示文本的信息熵，旨在提升行政或官僚文本的可读性与清晰度。


<details>
  <summary>Details</summary>
Motivation: 提升行政或 bureaucratic 文本的可读性与清晰度。

Method: 提出一种可视化框架，利用多种语言模型估算并可视化文本的信息熵。

Result: 开发了一个开源工具集（Glitter），可用于估算和可视化文本信息熵。

Conclusion: 信息熵可作为文本可读性的有效代理指标，该框架为改善官方文本的清晰度提供了新途径。

Abstract: This work investigates how measuring information entropy of text can be used to estimate its readability. We propose a visualization framework that can be used to approximate information entropy of text using multiple language models and visualize the result. The end goal is to use this method to estimate and improve readability and clarity of administrative or bureaucratic texts. Our toolset is available as a libre software on https://github.com/ufal/Glitter.

</details>


### [62] [Large Language Models Are Bad Dice Players: LLMs Struggle to Generate Random Numbers from Statistical Distributions](https://arxiv.org/abs/2601.05414)
*Minda Zhao,Yilun Du,Mengyu Wang*

Main category: cs.CL

TL;DR: 本文对前沿大语言模型（LLMs）原生概率采样能力进行了首次大规模、统计严谨的审计，发现其在批量生成与独立请求两种协议下均表现极差，尤其随分布复杂度和采样规模增加而显著退化，并导致下游任务（如MCQ生成、可控图像提示合成）中统计约束失效，表明当前LLMs缺乏可靠的内置采样器。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs从聊天界面演变为教育评估、合成数据构建等随机化流程中的核心组件，其忠实采样指定概率分布的能力已成为实际功能需求，而非理论问题。

Method: 对11个前沿LLM在15种分布上开展大规模统计审计；采用双协议设计：批量生成（单次响应输出N=1000样本）与独立请求（N=1000次无状态调用），以解耦不同失败模式。

Result: 批量生成中位通过率仅13%；独立请求中10/11模型在全部15个分布上均未通过；采样保真度随分布复杂度和采样规模N单调下降；下游任务中MCQ答案位置均匀性与图像提示人口学目标均被系统性违反。

Conclusion: 当前LLMs不具备功能完备的内部概率采样器，需依赖外部工具保障统计可靠性。

Abstract: As large language models (LLMs) transition from chat interfaces to integral components of stochastic pipelines across domains like educational assessment and synthetic data construction, the ability to faithfully sample from specified probability distributions has become a functional requirement rather than a theoretical curiosity. We present the first large-scale, statistically powered audit of native probabilistic sampling in frontier LLMs, benchmarking 11 models across 15 distributions. To disentangle failure modes, we employ a dual-protocol design: Batch Generation, where a model produces N=1000 samples within one response, and Independent Requests, comprising $N=1000$ stateless calls. We observe a sharp protocol asymmetry: batch generation achieves only modest statistical validity, with a 13% median pass rate, while independent requests collapse almost entirely, with 10 of 11 models passing none of the distributions. Beyond this asymmetry, we reveal that sampling fidelity degrades monotonically with distributional complexity and aggravates as the requested sampling horizon N increases. Finally, we demonstrate the propagation of these failures into downstream tasks: models fail to enforce uniform answer-position constraints in MCQ generation and systematically violate demographic targets in attribute-constrained text-to-image prompt synthesis. These findings indicate that current LLMs lack a functional internal sampler, necessitating the use of external tools for applications requiring statistical guarantees.

</details>


### [63] [Tracing Moral Foundations in Large Language Models](https://arxiv.org/abs/2601.05437)
*Chenxiao Yu,Bowen Yi,Farzan Karimi-Malekabadi,Suhaib Abdurahman,Jinyi Ye,Shrikanth Narayanan,Yue Zhao,Morteza Dehghani*

Main category: cs.CL

TL;DR: 本研究利用道德基础理论（MFT）分析两个指令微调大语言模型（LLaMA-3.1-8B-Instruct 和 Qwen2.5-7B-Instruct）中道德基础的表征机制，结合分层分析、稀疏自编码器（SAE）特征识别与因果干预实验，发现模型内部存在结构化、分层且部分解耦的道德概念表征，并能因果影响其道德判断输出。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型生成类人道德判断是源于内在道德概念结构，还是仅表面的‘道德模仿’。

Method: 采用多层级方法：（i）逐层分析MFT概念表征及其与人类道德感知的一致性；（ii）在残差流上应用预训练稀疏自编码器（SAEs）识别支撑道德概念的稀疏特征；（iii）分别使用稠密MFT向量和稀疏SAE特征进行因果引导干预。

Result: 两个模型均以结构化、层依赖方式表征并区分道德基础，且与人类判断一致；SAE特征语义明确关联特定道德基础，表明共享表征中存在部分解耦机制；稠密或稀疏引导均能引发可预测的道德基础相关行为变化。

Conclusion: 道德概念在LLMs中呈分布式、分层式且部分解耦的机制，表明多元道德结构可单纯从语言统计规律中作为潜在模式自然涌现。

Abstract: Large language models (LLMs) often produce human-like moral judgments, but it is unclear whether this reflects an internal conceptual structure or superficial ``moral mimicry.'' Using Moral Foundations Theory (MFT) as an analytic framework, we study how moral foundations are encoded, organized, and expressed within two instruction-tuned LLMs: Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct. We employ a multi-level approach combining (i) layer-wise analysis of MFT concept representations and their alignment with human moral perceptions, (ii) pretrained sparse autoencoders (SAEs) over the residual stream to identify sparse features that support moral concepts, and (iii) causal steering interventions using dense MFT vectors and sparse SAE features. We find that both models represent and distinguish moral foundations in a structured, layer-dependent way that aligns with human judgments. At a finer scale, SAE features show clear semantic links to specific foundations, suggesting partially disentangled mechanisms within shared representations. Finally, steering along either dense vectors or sparse features produces predictable shifts in foundation-relevant behavior, demonstrating a causal connection between internal representations and moral outputs. Together, our results provide mechanistic evidence that moral concepts in LLMs are distributed, layered, and partly disentangled, suggesting that pluralistic moral structure can emerge as a latent pattern from the statistical regularities of language alone.

</details>


### [64] [Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction](https://arxiv.org/abs/2601.05459)
*Hongjin Kim,Jaewook Lee,Kiyoung Lee,Jong-hun Shin,Soojong Lim,Oh-Woog Kwon*

Main category: cs.CL

TL;DR: 本研究探讨了强化学习（RL）能否提升大语言模型（LLM）在韩语等低资源语言中的推理能力，并发现仅靠RL效果有限；关键在于通过细调韩语特异性神经元（尤其早期层）对齐模型内部推理过程与韩语输入，配合自纠错语码转换数据集，显著提升韩语数学推理与自我纠正能力。核心结论是：多语言推理增强的关键不在于注入新语言知识，而在于有效激发并对其已有推理能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在英语等高资源语言中推理和自我纠正能力强，但在韩语等低资源语言中表现受限，需探索如何有效提升其韩语推理能力。

Method: 结合强化学习（RL）与多种微调策略，重点对齐模型内部推理过程与韩语输入；提出自纠错语码转换数据集，并针对性地微调韩语特异性神经元（尤其早期层）。

Result: 仅用RL提升有限；引入韩语神经元微调与语码转换数据集后，在数学推理和自我纠正任务上均取得显著性能提升。

Conclusion: 多语言推理能力增强的关键不在于注入新的语言知识，而在于有效激发并对其模型已有的推理能力；内部翻译机制与神经元级微调对多语言推理对齐至关重要。

Abstract: Large Language Models (LLMs) demonstrate strong reasoning and self-correction abilities in high-resource languages like English, but their performance remains limited in low-resource languages such as Korean. In this study, we investigate whether reinforcement learning (RL) can enhance Korean reasoning abilities to a degree comparable to English. Our findings reveal that RL alone yields limited improvements when applied to models lacking inherent Korean reasoning capabilities. To address this, we explore several fine-tuning strategies and show that aligning the model's internal reasoning processes with Korean inputs-particularly by tuning Korean-specific neurons in early layers-is key to unlocking RL's effectiveness. We introduce a self-correction code-switching dataset to facilitate this alignment and observe significant performance gains in both mathematical reasoning and self-correction tasks. Ultimately, we conclude that the crucial factor in multilingual reasoning enhancement is not injecting new linguistic knowledge, but effectively eliciting and aligning existing reasoning capabilities. Our study provides a new perspective on how internal translation and neuron-level tuning contribute to multilingual reasoning alignment in LLMs.

</details>


### [65] [Towards Valid Student Simulation with Large Language Models](https://arxiv.org/abs/2601.05473)
*Zhihao Yuan,Yunze Xiao,Ming Li,Weihao Xuan,Richard Tong,Mona Diab,Tom Mitchell*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLM）的学生模拟框架，聚焦于解决‘能力悖论’问题，即LLM因过于强大而难以真实模拟知识不完整的学习者。作者引入‘认知状态规范（ESS）’将学生模拟建模为受约束的生成任务，并提出‘目标-环境’框架以明确行为目标与部署场景；论文重在概念整合与形式化，而非构建新系统，强调‘认知保真度’而非表面真实性作为教育与科研应用的前提。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在学生模拟中因过度能力导致的‘能力悖论’——即无法真实再现部分知识掌握者特有的错误模式与学习动态，从而影响教育研究与教学工具的可靠性。

Method: 将学生模拟重构为受‘认知状态规范（ESS）’约束的生成问题，ESS明确定义模拟者可访问的知识、错误结构及状态演化机制；同时提出‘目标-环境’框架，按行为目标与部署上下文对模拟系统进行分类与定位；通过文献综述与概念形式化梳理设计维度与挑战。

Result: 建立了以认知保真度为核心的学生模拟概念与方法框架，形式化了Epistemic State Specification（ESS）和Goal-by-Environment分类体系，系统识别出有效性验证、评估方法及伦理风险等关键开放问题。

Conclusion: LLM驱动的学生模拟必须优先保障认知保真度（即内部知识状态的真实性），而非表面行为相似性；该框架为构建可信的教育科学工具与智能教学系统提供了理论基础与设计指南。

Abstract: This paper presents a conceptual and methodological framework for large language model (LLM) based student simulation in educational settings. The authors identify a core failure mode, termed the "competence paradox" in which broadly capable LLMs are asked to emulate partially knowledgeable learners, leading to unrealistic error patterns and learning dynamics. To address this, the paper reframes student simulation as a constrained generation problem governed by an explicit Epistemic State Specification (ESS), which defines what a simulated learner can access, how errors are structured, and how learner state evolves over time. The work further introduces a Goal-by-Environment framework to situate simulated student systems according to behavioral objectives and deployment contexts. Rather than proposing a new system or benchmark, the paper synthesizes prior literature, formalizes key design dimensions, and articulates open challenges related to validity, evaluation, and ethical risks. Overall, the paper argues for epistemic fidelity over surface realism as a prerequisite for using LLM-based simulated students as reliable scientific and pedagogical instruments.

</details>


### [66] [The Facade of Truth: Uncovering and Mitigating LLM Susceptibility to Deceptive Evidence](https://arxiv.org/abs/2601.05478)
*Herun Wan,Jiaying Wu,Minnan Luo,Fanxiao Li,Zhi Zeng,Min-Yen Kan*

Main category: cs.CL

TL;DR: 本文提出MisBelief框架，通过多角色LLM协作生成难以证伪的误导性证据，揭示了当前大语言模型在面对隐性误导时的信念脆弱性；并提出Deceptive Intent Shielding（DIS）机制，通过识别证据中的欺骗意图来提供早期预警，有效缓解信念偏移。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽能抵抗显性错误信息，但在面对逻辑自洽、渐进式构建的隐性误导性证据时，其内部信念易被扭曲，威胁决策可靠性。

Method: 提出MisBelief框架，利用多角色LLM协同多轮交互生成三类难度的误导性证据；构建4800个测试实例评估7个主流LLM；提出DIS治理机制，通过推断证据的欺骗意图实现早期干预。

Result: 实验显示，模型对隐性误导极为敏感，虚假信念得分平均上升93.0%；DIS机制可稳定抑制信念偏移，提升证据评估的审慎性。

Conclusion: LLM的信念稳健性不仅依赖事实核查，更需具备对证据意图的感知与防御能力；DIS为可信AI治理提供了新范式。

Abstract: To reliably assist human decision-making, LLMs must maintain factual internal beliefs against misleading injections. While current models resist explicit misinformation, we uncover a fundamental vulnerability to sophisticated, hard-to-falsify evidence. To systematically probe this weakness, we introduce MisBelief, a framework that generates misleading evidence via collaborative, multi-round interactions among multi-role LLMs. This process mimics subtle, defeasible reasoning and progressive refinement to create logically persuasive yet factually deceptive claims. Using MisBelief, we generate 4,800 instances across three difficulty levels to evaluate 7 representative LLMs. Results indicate that while models are robust to direct misinformation, they are highly sensitive to this refined evidence: belief scores in falsehoods increase by an average of 93.0\%, fundamentally compromising downstream recommendations. To address this, we propose Deceptive Intent Shielding (DIS), a governance mechanism that provides an early warning signal by inferring the deceptive intent behind evidence. Empirical results demonstrate that DIS consistently mitigates belief shifts and promotes more cautious evidence evaluation.

</details>


### [67] [Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency](https://arxiv.org/abs/2601.05905)
*Haoming Xu,Ningyuan Zhao,Yunzhi Yao,Weihong Xu,Hongru Wang,Xinle Deng,Shumin Deng,Jeff Z. Pan,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 本文提出Neighbor-Consistency Belief（NCB）来评估大语言模型在上下文扰动下的信念鲁棒性，并设计结构感知训练（SAT）提升模型信念稳定性，降低知识脆弱性约30%。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（如Self-Consistency）仅依赖点式置信度，无法揭示模型信念在上下文扰动下的脆弱性，而可靠部署需保证信念的结构性稳健。

Method: 提出Neighbor-Consistency Belief（NCB）作为信念鲁棒性的结构化度量，并设计认知压力测试协议；进一步提出Structure-Aware Training（SAT）优化上下文不变的信念结构。

Result: 实验表明高NCB数据对上下文干扰更具鲁棒性；SAT将长尾知识脆弱性降低约30%。

Conclusion: 信念的结构性稳健比单一响应正确性更重要；NCB和SAT为提升LLM可靠性提供了新范式与实用工具。

Abstract: As Large Language Models (LLMs) are increasingly deployed in real-world settings, correctness alone is insufficient. Reliable deployment requires maintaining truthful beliefs under contextual perturbations. Existing evaluations largely rely on point-wise confidence like Self-Consistency, which can mask brittle belief. We show that even facts answered with perfect self-consistency can rapidly collapse under mild contextual interference. To address this gap, we propose Neighbor-Consistency Belief (NCB), a structural measure of belief robustness that evaluates response coherence across a conceptual neighborhood. To validate the efficiency of NCB, we introduce a new cognitive stress-testing protocol that probes outputs stability under contextual interference. Experiments across multiple LLMs show that the performance of high-NCB data is relatively more resistant to interference. Finally, we present Structure-Aware Training (SAT), which optimizes context-invariant belief structure and reduces long-tail knowledge brittleness by approximately 30%. Code will be available at https://github.com/zjunlp/belief.

</details>


### [68] [MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards](https://arxiv.org/abs/2601.05488)
*Zhiyu Shen,Ziming Wu,Fuming Lai,Shaobing Lian,Yanghui Rao*

Main category: cs.CL

TL;DR: MemBuilder is a reinforcement learning framework that improves long-term dialogue consistency in LLMs by enabling multi-dimensional memory construction with dense, attributed rewards.


<details>
  <summary>Details</summary>
Motivation: Standard retrieval mechanisms fail to capture temporal evolution of dialogue history; existing memory-augmented frameworks suffer from static prompting or ineffective training with sparse rewards.

Method: MemBuilder uses synthetic session-level question generation for dense trajectory-level rewards and contribution-aware gradient weighting to attribute credit across memory components during RL training.

Result: A 4B-parameter model trained with MemBuilder outperforms state-of-the-art closed-source baselines on long-term dialogue benchmarks, showing strong generalization.

Conclusion: Dense, attributed rewards and multi-dimensional memory orchestration significantly enhance LLMs' long-term dialogue consistency and generalization.

Abstract: Maintaining consistency in long-term dialogues remains a fundamental challenge for LLMs, as standard retrieval mechanisms often fail to capture the temporal evolution of historical states. While memory-augmented frameworks offer a structured alternative, current systems rely on static prompting of closed-source models or suffer from ineffective training paradigms with sparse rewards. We introduce MemBuilder, a reinforcement learning framework that trains models to orchestrate multi-dimensional memory construction with attributed dense rewards. MemBuilder addresses two key challenges: (1) Sparse Trajectory-Level Rewards: we employ synthetic session-level question generation to provide dense intermediate rewards across extended trajectories; and (2) Multi-Dimensional Memory Attribution: we introduce contribution-aware gradient weighting that scales policy updates based on each component's downstream impact. Experimental results show that MemBuilder enables a 4B-parameter model to outperform state-of-the-art closed-source baselines, exhibiting strong generalization across long-term dialogue benchmarks.

</details>


### [69] [Can We Predict Before Executing Machine Learning Agents?](https://arxiv.org/abs/2601.05930)
*Jingsheng Zheng,Jintian Zhang,Yujie Luo,Yuren Mao,Yunjun Gao,Lun Du,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种预测优先（Predict-then-Verify）的自主机器学习代理框架FOREAGENT，通过内化执行先验知识，用LLM预测替代昂贵的物理执行，显著加速科学发现过程。


<details>
  <summary>Details</summary>
Motivation: 现有自主ML代理受限于Generate-Execute-Feedback范式，尤其受制于依赖昂贵物理执行的Execution Bottleneck。

Method: 形式化定义Data-centric Solution Preference任务，构建含18,438组配对比较的数据集；利用经验证数据分析报告提示LLM进行预测；设计FOREAGENT代理实现预测-验证闭环。

Result: LLM在验证报告提示下达到61.5%预测准确率和良好置信度校准；FOREAGENT实现6倍收敛加速，并比纯执行基线提升6%性能。

Conclusion: 内化执行先验、以预测驱动决策可有效缓解物理执行瓶颈，为加速科学发现提供新范式。

Abstract: Autonomous machine learning agents have revolutionized scientific discovery, yet they remain constrained by a Generate-Execute-Feedback paradigm. Previous approaches suffer from a severe Execution Bottleneck, as hypothesis evaluation relies strictly on expensive physical execution. To bypass these physical constraints, we internalize execution priors to substitute costly runtime checks with instantaneous predictive reasoning, drawing inspiration from World Models. In this work, we formalize the task of Data-centric Solution Preference and construct a comprehensive corpus of 18,438 pairwise comparisons. We demonstrate that LLMs exhibit significant predictive capabilities when primed with a Verified Data Analysis Report, achieving 61.5% accuracy and robust confidence calibration. Finally, we instantiate this framework in FOREAGENT, an agent that employs a Predict-then-Verify loop, achieving a 6x acceleration in convergence while surpassing execution-based baselines by +6%. Our code and dataset will be publicly available soon at https://github.com/zjunlp/predict-before-execute.

</details>


### [70] [FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse](https://arxiv.org/abs/2601.05505)
*Yubo Hou,Zhisheng Chen,Tao Wan,Zengchang Qin*

Main category: cs.CL

TL;DR: FlashMem 提出了一种无需额外参数、直接从推理状态中蒸馏内在记忆的方法，通过共享KV缓存和基于注意力熵的认知监控，显著提升长程自主推理的效率与持续性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的无状态架构无法天然保留动态上下文，导致智能体需重复处理历史信息；现有潜存记忆方法因依赖分离的辅助编码器而存在架构割裂问题。

Method: FlashMem 通过计算复用从瞬时推理状态中蒸馏内在记忆，将最后一层隐藏状态视为交互历史的充分统计量，并设计共享KV整合器直接访问冻结的主干缓存；同时引入无参的认知监控器，利用注意力熵自适应触发记忆整合。

Result: 实验表明，FlashMem 在性能上媲美重型基线模型，同时将推理延迟降低5倍。

Conclusion: FlashMem 成功弥合了高效推理与持久认知之间的鸿沟，为构建具备长程自主能力的轻量级智能体提供了新范式。

Abstract: The stateless architecture of Large Language Models inherently lacks the mechanism to preserve dynamic context, compelling agents to redundantly reprocess history to maintain long-horizon autonomy. While latent memory offers a solution, current approaches are hindered by architectural segregation, relying on auxiliary encoders that decouple memory from the reasoning backbone. We propose FlashMem, a framework that distills intrinsic memory directly from transient reasoning states via computation reuse. Leveraging the property that internal representations uniquely encode input trajectories, FlashMem identifies the last hidden state as a sufficient statistic for the interaction history. This enables a Shared-KV Consolidator to synthesize memory by attending directly to the backbone's frozen cache, eliminating redundant re-parameterization. Furthermore, a parameter-free Cognitive Monitor leverages attention entropy to adaptively trigger consolidation only when high epistemic uncertainty is detected. Experiments demonstrate that FlashMem matches the performance of heavy baselines while reducing inference latency by 5 times, effectively bridging the gap between efficiency and persistent cognition.

</details>


### [71] [CHisAgent: A Multi-Agent Framework for Event Taxonomy Construction in Ancient Chinese Cultural Systems](https://arxiv.org/abs/2601.05520)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: 本文提出CHisAgent，一个用于构建中国古代历史知识分类体系的多智能体大语言模型框架，通过三个专业化角色（Inducer、Expander、Enricher）自动构建高质量、可扩展、忠实于史料的事件分类体系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在非英语历史与文化推理（如中国历史）方面能力有限；人工构建历史知识分类体系成本高、难扩展。

Method: 提出CHisAgent多智能体框架，包含三个阶段：1）自下而上的Inducer从原始史料中归纳初始层级；2）自上而下的Expander利用LLM世界知识补充中间概念；3）证据引导的Enricher融合外部结构化历史资源保障事实性。以《二十四史》为数据源构建古代中国事件分类体系。

Result: 构建了覆盖政治、军事、外交与社会生活的大型、领域适配的中国古代事件分类体系；评估表明其结构连贯性与覆盖度优于基线；支持跨文化知识对齐。

Conclusion: CHisAgent有效缓解了LLM在中文历史推理中的局限，为自动化、可扩展、可信的历史知识结构化提供了新范式。

Abstract: Despite strong performance on many tasks, large language models (LLMs) show limited ability in historical and cultural reasoning, particularly in non-English contexts such as Chinese history. Taxonomic structures offer an effective mechanism to organize historical knowledge and improve understanding. However, manual taxonomy construction is costly and difficult to scale. Therefore, we propose \textbf{CHisAgent}, a multi-agent LLM framework for historical taxonomy construction in ancient Chinese contexts. CHisAgent decomposes taxonomy construction into three role-specialized stages: a bottom-up \textit{Inducer} that derives an initial hierarchy from raw historical corpora, a top-down \textit{Expander} that introduces missing intermediate concepts using LLM world knowledge, and an evidence-guided \textit{Enricher} that integrates external structured historical resources to ensure faithfulness. Using the \textit{Twenty-Four Histories}, we construct a large-scale, domain-aware event taxonomy covering politics, military, diplomacy, and social life in ancient China. Extensive reference-free and reference-based evaluations demonstrate improved structural coherence and coverage, while further analysis shows that the resulting taxonomy supports cross-cultural alignment.

</details>


### [72] [Double: Breaking the Acceleration Limit via Double Retrieval Speculative Parallelism](https://arxiv.org/abs/2601.05524)
*Yuhao Shen,Tianyu Liu,Junyi Shen,Jinyang Wu,Quan Kong,Li Huan,Cong Wang*

Main category: cs.CL

TL;DR: 本文提出Double框架，通过同步的双重检索机制突破传统推测解码的速度上限并减少计算浪费，实现无训练、无损的高效推理加速。


<details>
  <summary>Details</summary>
Motivation: 传统并行推测解码（PSD）受限于草案与目标模型的速度比理论天花板，且因早期错误导致的中段token拒绝引发高计算浪费和流水线停顿。

Method: 提出Double（Double Retrieval Speculative Parallelism）框架：草案模型执行迭代检索推测以突破速度上限；目标模型执行权威检索生成多token指导，避免回滚；整个过程无需训练、无损。

Result: 在LLaMA3.3-70B上达5.3×加速，在Qwen3-32B上达2.8×加速，显著优于需大量训练的EAGLE-3。

Conclusion: Double通过协同双检索机制，在不牺牲精度前提下，有效克服PSD的根本瓶颈，为大模型推理提供高效、实用的新范式。

Abstract: Parallel Speculative Decoding (PSD) accelerates traditional Speculative Decoding (SD) by overlapping draft generation with verification. However, it remains hampered by two fundamental challenges: (1) a theoretical speedup ceiling dictated by the speed ratio between the draft and target models, and (2) high computational waste and pipeline stall due to mid-sequence token rejections of early errors. To address these limitations, we introduce \textsc{Double} (Double Retrieval Speculative Parallelism). By bridging the gap between SD and PSD, our framework resolves the Retrieval \emph{Precision-Efficiency Dilemma} through a novel synchronous mechanism. Specifically, we enable the draft model to execute iterative retrieval speculations to break the theoretical speedup limits; to alleviate rejections without rollback, the target model performs authoritative retrieval to generate multi-token guidance. \textsc{Double} is entirely training-free and lossless. Extensive experiments demonstrate state-of-the-art speedup of $\textbf{5.3}\times$ on LLaMA3.3-70B and $\textbf{2.8}\times$ on Qwen3-32B, significantly outperforming the advanced method EAGLE-3 that requires extensive model training.

</details>


### [73] [Closing the Modality Reasoning Gap for Speech Large Language Models](https://arxiv.org/abs/2601.05543)
*Chaoren Wang,Heng Lu,Xueyao Zhang,Shujie Liu,Yan Lu,Jinyu Li,Zhizheng Wu*

Main category: cs.CL

TL;DR: 本文提出TARS框架，通过非对称奖励设计，在强化学习中对齐文本和语音条件下的模型推理轨迹，以缩小语音大语言模型在语音输入上的推理能力与文本输入之间的差距。


<details>
  <summary>Details</summary>
Motivation: 语音大语言模型在语音输入上的推理性能明显弱于文本输入，存在显著的模态推理差距，可能源于Transformer层间的表征漂移和长链推理中的行为偏差。

Method: 提出TARS强化学习框架，采用非对称奖励设计，结合两种密集且互补的对齐信号：表征对齐（衡量语音与文本条件轨迹各层隐状态相似性）和行为对齐（评估生成输出与参考文本补全之间的语义一致性）。

Result: 在MMSU和OBQA等具有挑战性的推理基准上，该方法显著缩小了模态推理差距，并在7B规模语音大语言模型中达到SOTA性能。

Conclusion: TARS框架有效缓解了语音大语言模型中的模态推理差距，验证了轨迹对齐策略在跨模态推理增强中的有效性。

Abstract: Although speech large language models have achieved notable progress, a substantial modality reasoning gap remains: their reasoning performance on speech inputs is markedly weaker than on text. This gap could be associated with representational drift across Transformer layers and behavior deviations in long-chain reasoning. To address this issue, we introduce TARS, a reinforcement-learning framework that aligns text-conditioned and speech-conditioned trajectories through an asymmetric reward design. The framework employs two dense and complementary signals: representation alignment, which measures layer-wise hidden-state similarity between speech- and text-conditioned trajectories, and behavior alignment, which evaluates semantic consistency between generated outputs and reference text completions. Experiments on challenging reasoning benchmarks, including MMSU and OBQA, show that our approach significantly narrows the modality reasoning gap and achieves state-of-the-art performance among 7B-scale Speech LLMs.

</details>


### [74] [Can Large Language Models Differentiate Harmful from Argumentative Essays? Steps Toward Ethical Essay Scoring](https://arxiv.org/abs/2601.05545)
*Hongjin Kim,Jeonghyun Kang,Harksoo Kim*

Main category: cs.CL

TL;DR: 本研究提出了有害作文检测（HED）基准，揭示当前自动作文评分（AES）系统和大语言模型（LLMs）在识别与评分含种族主义、性别偏见等有害内容的作文方面存在严重缺陷，强调需构建更具伦理敏感性的AES系统。


<details>
  <summary>Details</summary>
Motivation: 现有AES系统和LLMs在评分中常忽视作文中的伦理与道德问题，甚至给传播有害观点的作文赋予高分，亟需评估并提升其对有害内容的识别能力。

Method: 构建包含种族主义、性别偏见等敏感话题的有害作文检测（HED）基准，系统评测多种LLMs及AES模型在识别和评分有害内容上的表现。

Result: 实验发现：（1）LLMs难以准确区分有害作文与正当论证类作文；（2）当前AES模型与LLMs均未在评分中纳入内容的伦理维度考量。

Conclusion: AES系统必须增强对内容伦理影响的敏感性，未来研究应致力于开发兼顾准确性与伦理责任的鲁棒评分模型。

Abstract: This study addresses critical gaps in Automated Essay Scoring (AES) systems and Large Language Models (LLMs) with regard to their ability to effectively identify and score harmful essays. Despite advancements in AES technology, current models often overlook ethically and morally problematic elements within essays, erroneously assigning high scores to essays that may propagate harmful opinions. In this study, we introduce the Harmful Essay Detection (HED) benchmark, which includes essays integrating sensitive topics such as racism and gender bias, to test the efficacy of various LLMs in recognizing and scoring harmful content. Our findings reveal that: (1) LLMs require further enhancement to accurately distinguish between harmful and argumentative essays, and (2) both current AES models and LLMs fail to consider the ethical dimensions of content during scoring. The study underscores the need for developing more robust AES systems that are sensitive to the ethical implications of the content they are scoring.

</details>


### [75] [Generation-Based and Emotion-Reflected Memory Update: Creating the KEEM Dataset for Better Long-Term Conversation](https://arxiv.org/abs/2601.05548)
*Jeonghyun Kang,Hongjin Kim,Harksoo Kim*

Main category: cs.CL

TL;DR: 本文介绍了KEEM数据集，旨在通过动态生成整合记忆来增强长期对话系统中的记忆更新，不仅保留关键事实信息，还融入情感背景和因果关系，从而提升系统在开放域对话中的共情能力和响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖简单累积或基于操作的方法，常导致信息冲突和难以准确跟踪用户当前状态。

Method: 提出KEEM数据集，采用动态生成整合记忆的方式，同时保留关键事实信息、情感背景和因果关系。

Result: 提升了对话系统对用户状态的理解能力，增强了共情能力和开放域对话中的有意义响应能力。

Conclusion: KEEM通过融合情感与关键信息的记忆更新机制，为长期对话系统提供了更细致、更具适应性的记忆建模方案。

Abstract: In this work, we introduce the Keep Emotional and Essential Memory (KEEM) dataset, a novel generation-based dataset designed to enhance memory updates in long-term conversational systems. Unlike existing approaches that rely on simple accumulation or operation-based methods, which often result in information conflicts and difficulties in accurately tracking a user's current state, KEEM dynamically generates integrative memories. This process not only preserves essential factual information but also incorporates emotional context and causal relationships, enabling a more nuanced understanding of user interactions. By seamlessly updating a system's memory with both emotional and essential data, our approach promotes deeper empathy and enhances the system's ability to respond meaningfully in open-domain conversations.

</details>


### [76] [ReasonAny: Incorporating Reasoning Capability to Any Model via Simple and Effective Model Merging](https://arxiv.org/abs/2601.05560)
*Junyao Yang,Chen Qian,Dongrui Liu,Wen Shen,Yong Liu,Jing Shao*

Main category: cs.CL

TL;DR: 本文提出ReasonAny框架，通过对比梯度识别解决大推理模型与领域模型融合时的性能崩溃问题，实现'推理+X'能力的有效合成。


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法在融合推理能力与领域专用能力时，常导致推理深度减弱和领域效用下降；作者发现推理能力主要存在于低梯度敏感性的参数区域，而非高模值参数区域，由此提出新方法。

Method: 提出ReasonAny融合框架，核心为对比梯度识别（Contrastive Gradient Identification），以保留低梯度敏感性区域中的推理能力，同时维持领域模型的高特异性参数贡献。

Result: 在安全、生物医学和金融等多个领域实验表明，ReasonAny显著优于现有最优基线，在保持强推理性能的同时有效融合领域能力。

Conclusion: ReasonAny成功解决了‘Reasoning + X’融合中的性能崩溃难题，验证了梯度敏感性比参数模值更能反映推理能力分布，为训练-free的多能力模型融合提供了新范式。

Abstract: Large Reasoning Models (LRMs) with long chain-of-thought reasoning have recently achieved remarkable success. Yet, equipping domain-specialized models with such reasoning capabilities, referred to as "Reasoning + X", remains a significant challenge. While model merging offers a promising training-free solution, existing methods often suffer from a destructive performance collapse: existing methods tend to both weaken reasoning depth and compromise domain-specific utility. Interestingly, we identify a counter-intuitive phenomenon underlying this failure: reasoning ability predominantly resides in parameter regions with low gradient sensitivity, contrary to the common assumption that domain capabilities correspond to high-magnitude parameters. Motivated by this insight, we propose ReasonAny, a novel merging framework that resolves the reasoning-domain performance collapse through Contrastive Gradient Identification. Experiments across safety, biomedicine, and finance domains show that ReasonAny effectively synthesizes "Reasoning + X" capabilities, significantly outperforming state-of-the-art baselines while retaining robust reasoning performance.

</details>


### [77] [Can large language models interpret unstructured chat data on dynamic group decision-making processes? Evidence on joint destination choice](https://arxiv.org/abs/2601.05582)
*Sung-Yoo Lim,Koki Sato,Kiyoshi Takami,Giancarlos Parady,Eui-Jin Kim*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLMs）在自动解析群体聊天数据以理解联合外出就餐决策过程中的潜力，提出了一种受知识获取启发的提示框架，将非结构化对话转化为结构化决策因素数据，并通过定量与定性分析评估其性能。


<details>
  <summary>Details</summary>
Motivation: 传统交通调查难以观测群体社交活动中的复杂联合出行决策过程，而新兴的非结构化聊天数据虽具潜力，但需人工标注以提取显性与隐性决策因素，成本高昂。

Method: 设计了一种受知识获取过程启发的多步提示框架，引导LLM依次提取群体层面餐厅选择集与结果、个体偏好及驱动偏好的具体属性，将群聊文本转化为结构化表格数据；并基于人工标注真值数据进行定量评估与定性错误分析。

Result: LLM能可靠提取显性决策因素，但在识别文化/社会语境下细微的隐性因素方面明显弱于人工标注；研究明确了LLM可信赖的应用场景与仍需人工监督的关键情形。

Conclusion: LLM在辅助分析非传统社交活动数据方面具有实用价值，但不能完全替代人工；需结合人机协同策略以兼顾效率与深度理解。

Abstract: Social activities result from complex joint activity-travel decisions between group members. While observing the decision-making process of these activities is difficult via traditional travel surveys, the advent of new types of data, such as unstructured chat data, can help shed some light on these complex processes. However, interpreting these decision-making processes requires inferring both explicit and implicit factors. This typically involves the labor-intensive task of manually annotating dialogues to capture context-dependent meanings shaped by the social and cultural norms. This study evaluates the potential of Large Language Models (LLMs) to automate and complement human annotation in interpreting decision-making processes from group chats, using data on joint eating-out activities in Japan as a case study. We designed a prompting framework inspired by the knowledge acquisition process, which sequentially extracts key decision-making factors, including the group-level restaurant choice set and outcome, individual preferences of each alternative, and the specific attributes driving those preferences. This structured process guides the LLM to interpret group chat data, converting unstructured dialogues into structured tabular data describing decision-making factors. To evaluate LLM-driven outputs, we conduct a quantitative analysis using a human-annotated ground truth dataset and a qualitative error analysis to examine model limitations. Results show that while the LLM reliably captures explicit decision-making factors, it struggles to identify nuanced implicit factors that human annotators readily identified. We pinpoint specific contexts when LLM-based extraction can be trusted versus when human oversight remains essential. These findings highlight both the potential and limitations of LLM-based analysis for incorporating non-traditional data sources on social activities.

</details>


### [78] [ACR: Adaptive Context Refactoring via Context Refactoring Operators for Multi-Turn Dialogue](https://arxiv.org/abs/2601.05589)
*Jiawei Shen,Jia Zhu,Hanghui Guo,Weijie Shi,Yue Cui,Qingyu Niu,Guoqing Ma,Yidan Liang,Jingjiang Liu,Yiling Wang,Shimin Di,Jiajie Xu*

Main category: cs.CL

TL;DR: 本文提出ACR框架，通过动态监控和重构对话历史来解决大语言模型在多轮对话中的上下文惯性和状态漂移问题，显著提升性能并减少token消耗。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多轮对话中难以保持与前期内容的一致性、跟踪长程依赖，并易随对话延长而产生事实错误，现有方法受限于上下文惯性和状态漂移。

Method: 提出自适应上下文重构（ACR）框架，包含上下文重构算子库和教师引导的自演化训练范式，动态决定何时干预及如何重构对话历史，解耦上下文管理与推理过程。

Result: 在多轮对话任务上显著优于现有基线方法，同时降低token消耗。

Conclusion: ACR框架有效缓解了上下文惯性和状态漂移问题，为长程多轮对话中的上下文管理提供了新思路。

Abstract: Large Language Models (LLMs) have shown remarkable performance in multi-turn dialogue. However, in multi-turn dialogue, models still struggle to stay aligned with what has been established earlier, follow dependencies across many turns, and avoid drifting into incorrect facts as the interaction grows longer. Existing approaches primarily focus on extending the context window, introducing external memory, or applying context compression, yet these methods still face limitations such as \textbf{contextual inertia} and \textbf{state drift}. To address these challenges, we propose the \textbf{A}daptive \textbf{C}ontext \textbf{R}efactoring \textbf{(ACR)} Framework, which dynamically monitors and reshapes the interaction history to mitigate contextual inertia and state drift actively. ACR is built on a library of context refactoring operators and a teacher-guided self-evolving training paradigm that learns when to intervene and how to refactor, thereby decoupling context management from the reasoning process. Extensive experiments on multi-turn dialogue demonstrate that our method significantly outperforms existing baselines while reducing token consumption.

</details>


### [79] [Data Augmented Pipeline for Legal Information Extraction and Reasoning](https://arxiv.org/abs/2601.05609)
*Nguyen Minh Phuong,Ha-Thanh Nguyen,May Myo Zin,Ken Satoh*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLMs）进行法律领域信息抽取任务数据增强的简单有效方法，显著减少人工标注工作量并提升系统鲁棒性，且具有跨NLP任务的通用性。


<details>
  <summary>Details</summary>
Motivation: 减少法律领域信息抽取任务中人工数据标注的高成本和高工作量，并提升模型鲁棒性。

Method: 设计了一个基于大语言模型（LLMs）的数据增强pipeline，用于法律领域的信息抽取任务。

Result: 该方法显著降低了人工标注 effort，同时增强了信息抽取系统的鲁棒性；具备跨领域、跨NLP任务的通用性。

Conclusion: 所提出的LLM驱动的数据增强pipeline在法律信息抽取中高效实用，且可推广至更广泛的NLP任务。

Abstract: In this paper, we propose a pipeline leveraging Large Language Models (LLMs) for data augmentation in Information Extraction tasks within the legal domain. The proposed method is both simple and effective, significantly reducing the manual effort required for data annotation while enhancing the robustness of Information Extraction systems. Furthermore, the method is generalizable, making it applicable to various Natural Language Processing (NLP) tasks beyond the legal domain.

</details>


### [80] [Text Detoxification in isiXhosa and Yorùbá: A Cross-Lingual Machine Learning Approach for Low-Resource African Languages](https://arxiv.org/abs/2601.05624)
*Abayomi O. Agbeyangi*

Main category: cs.CL

TL;DR: 本文提出了一种轻量、可解释的混合方法，用于 isiXhosa 和 Yorùbá 两种低资源非洲语言的文本去毒化（toxic→neutral 重写），包含基于 TF-IDF 和逻辑回归的毒性检测器与基于词典和标记引导的可控重写模块，并构建了涵盖习语、变音符号和语码转换的平行语料库。实验表明该方法在检测与重写任务上均取得良好效果，为非洲语言的文本风格迁移树立了新基准。


<details>
  <summary>Details</summary>
Motivation: 有毒语言是阻碍安全在线参与的主要障碍之一，但针对非洲语言的鲁棒缓解工具极为匮乏，尤其缺乏适用于低资源非洲语言（如isiXhosa和Yorùbá）的自动文本去毒化方案。

Method: 提出一种混合方法：1）轻量级、可解释的TF-IDF + 逻辑回归毒性检测器；2）受词典和token引导的可控重写组件；3）构建涵盖idiomatic usage、diacritics和code-switching的平行毒-中性语料库用于训练与评估。

Result: 毒性检测在isiXhosa上分层K折准确率61–72%，Yorùbá上72–86%，单语言ROC-AUC最高达0.88；重写组件成功将所有检测出的有毒句转为中性，且100%保留非毒句。

Conclusion: 可扩展、可解释的机器学习检测器与基于规则的编辑相结合，是一种具有竞争力且资源高效的文化适应型安全工具方案，为低资源非洲语言的文本风格迁移设定了新基准。

Abstract: Toxic language is one of the major barrier to safe online participation, yet robust mitigation tools are scarce for African languages. This study addresses this critical gap by investigating automatic text detoxification (toxic to neutral rewriting) for two low-resource African languages, isiXhosa and Yorùbá. The work contributes a novel, pragmatic hybrid methodology: a lightweight, interpretable TF-IDF and Logistic Regression model for transparent toxicity detection, and a controlled lexicon- and token-guided rewriting component. A parallel corpus of toxic to neutral rewrites, which captures idiomatic usage, diacritics, and code switching, was developed to train and evaluate the model. The detection component achieved stratified K-fold accuracies of 61-72% (isiXhosa) and 72-86% (Yorùbá), with per-language ROC-AUCs up to 0.88. The rewriting component successfully detoxified all detected toxic sentences while preserving 100% of non-toxic sentences. These results demonstrate that scalable, interpretable machine learning detectors combined with rule-based edits offer a competitive and resource-efficient solution for culturally adaptive safety tooling, setting a new benchmark for low-resource Text Style Transfer (TST) in African languages.

</details>


### [81] [GIFT: Games as Informal Training for Generalizable LLMs](https://arxiv.org/abs/2601.05633)
*Nuoyan Lyu,Bingbing Xu,Weihao Meng,Yige Yuan,Yang Zhang,Zhiyong Huang,Tat-Seng Chua,Huawei Shen*

Main category: cs.CL

TL;DR: 本文提出将游戏作为大语言模型（LLM）非正式学习的主要环境，设计嵌套训练框架（Nested Training Framework），通过顺序任务组合实现显式的'AND'目标，利用GRPO强化学习在多类游戏中提升模型的战略创造力、社会推理等通用能力，并增强跨任务泛化性能。


<details>
  <summary>Details</summary>
Motivation: LLM在形式化学习任务（如数学、编程）上表现优异，但在体现人类认知的‘实践智慧’（如战略创造力、社会推理）方面仍不足，主因是缺乏基于交互反馈的非正式学习机制。

Method: 提出以游戏为非正式学习环境，设计嵌套训练框架——区别于简单多任务混合（隐式'OR'目标），采用顺序任务组合以强制模型同时掌握多项能力（显式'AND'目标）；使用GRPO强化学习在Matrix Games、TicTacToe和Who's the Spy等游戏中联合训练。

Result: 游戏驱动的非正式学习有效避免了多任务干扰，并显著提升模型在面向能力的广泛基准（如战略、社会推理等）上的泛化性能。

Conclusion: 游戏作为富含内在奖励与抽象复杂性的环境，可成为培养LLM通用智能的关键非正式学习范式；嵌套训练框架为多能力协同提升提供了可扩展、可复现的训练路径。

Abstract: While Large Language Models (LLMs) have achieved remarkable success in formal learning tasks such as mathematics and code generation, they still struggle with the "practical wisdom" and generalizable intelligence, such as strategic creativity and social reasoning, that characterize human cognition. This gap arises from a lack of informal learning, which thrives on interactive feedback rather than goal-oriented instruction. In this paper, we propose treating Games as a primary environment for LLM informal learning, leveraging their intrinsic reward signals and abstracted complexity to cultivate diverse competencies. To address the performance degradation observed in multi-task learning, we introduce a Nested Training Framework. Unlike naive task mixing optimizing an implicit "OR" objective, our framework employs sequential task composition to enforce an explicit "AND" objective, compelling the model to master multiple abilities simultaneously to achieve maximal rewards. Using GRPO-based reinforcement learning across Matrix Games, TicTacToe, and Who's the Spy games, we demonstrate that integrating game-based informal learning not only prevents task interference but also significantly bolsters the model's generalization across broad ability-oriented benchmarks. The framework and implementation are publicly available.

</details>


### [82] [Multilingual Amnesia: On the Transferability of Unlearning in Multilingual LLMs](https://arxiv.org/abs/2601.05641)
*Alireza Dehghanpour Farashah,Aditi Khandelwal,Marylou Fauchard,Zhuan Shi,Negar Rostamzadeh,Golnoosh Farnadi*

Main category: cs.CL

TL;DR: 本文研究了多语言大语言模型（如Aya-Expanse 8B）中的多语言机器遗忘问题，涵盖数据遗忘与概念遗忘两类任务，并将事实知识与刻板印象评测基准扩展至10种跨语系、资源水平差异大的语言；实验发现高资源语言遗忘更稳定，且句法相似性是跨语言遗忘行为的最强预测因子。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘研究主要集中于单语（尤其是英语）环境，而多语言模型在实际应用中面临跨语言知识迁移和预训练/微调数据中固有偏见带来的新挑战，亟需系统研究其多语言遗忘能力。

Method: 基于Aya-Expanse 8B模型，在数据遗忘与概念遗忘两种设定下开展实验；将英文事实知识与刻板印象评测集人工翻译为10种语言（覆盖5个语系），并结合语言类型学距离分析（如句法相似性）探究跨语言遗忘规律。

Result: 高资源语言的遗忘效果更稳定；存在不对称的跨语言遗忘迁移效应，尤其在类型学相近语言之间；句法相似性比其他语言距离指标更能预测跨语言遗忘表现。

Conclusion: 多语言机器遗忘效果受语言资源水平和语言结构（特别是句法）显著影响，未来工作需兼顾语言多样性与结构特性设计更鲁棒的遗忘方法。

Abstract: As multilingual large language models become more widely used, ensuring their safety and fairness across diverse linguistic contexts presents unique challenges. While existing research on machine unlearning has primarily focused on monolingual settings, typically English, multilingual environments introduce additional complexities due to cross-lingual knowledge transfer and biases embedded in both pretraining and fine-tuning data. In this work, we study multilingual unlearning using the Aya-Expanse 8B model under two settings: (1) data unlearning and (2) concept unlearning. We extend benchmarks for factual knowledge and stereotypes to ten languages through translation: English, French, Arabic, Japanese, Russian, Farsi, Korean, Hindi, Hebrew, and Indonesian. These languages span five language families and a wide range of resource levels. Our experiments show that unlearning in high-resource languages is generally more stable, with asymmetric transfer effects observed between typologically related languages. Furthermore, our analysis of linguistic distances indicates that syntactic similarity is the strongest predictor of cross-lingual unlearning behavior.

</details>


### [83] [A Framework for Personalized Persuasiveness Prediction via Context-Aware User Profiling](https://arxiv.org/abs/2601.05654)
*Sejun Park,Yoonah Park,Jongwon Lim,Yohan Jo*

Main category: cs.CL

TL;DR: 本文提出了一种上下文感知的用户画像框架，通过可训练的查询生成器和画像器，利用用户历史活动提升说服力预测性能，在ChangeMyView数据集上F1提升达13.77个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏系统性框架来有效利用说服对象（persuadee）的历史行为（如对话）以提升说服力预测效果，尤其忽视其价值观、经验与推理风格等个性化特征。

Method: 提出一种上下文感知的用户画像框架，包含两个可训练组件：（1）查询生成器，用于从用户历史中检索与说服任务最相关的记录；（2）画像器，将检索结果聚合成任务导向的动态用户画像，服务于下游说服力预测模型。

Result: 在ChangeMyView Reddit数据集上，该框架在多种预测器上均显著优于基线方法，最高F1提升+13.77%p；分析表明有效画像具有上下文依赖性和预测器特异性，而非静态或表层相似性。

Conclusion: 任务导向、上下文依赖的动态用户画像对个性化说服力预测至关重要，为基于用户历史建模提供了新范式。

Abstract: Estimating the persuasiveness of messages is critical in various applications, from recommender systems to safety assessment of LLMs. While it is imperative to consider the target persuadee's characteristics, such as their values, experiences, and reasoning styles, there is currently no established systematic framework to optimize leveraging a persuadee's past activities (e.g., conversations) to the benefit of a persuasiveness prediction model. To address this problem, we propose a context-aware user profiling framework with two trainable components: a query generator that generates optimal queries to retrieve persuasion-relevant records from a user's history, and a profiler that summarizes these records into a profile to effectively inform the persuasiveness prediction model. Our evaluation on the ChangeMyView Reddit dataset shows consistent improvements over existing methods across multiple predictor models, with gains of up to +13.77%p in F1 score. Further analysis shows that effective user profiles are context-dependent and predictor-specific, rather than relying on static attributes or surface-level similarity. Together, these results highlight the importance of task-oriented, context-dependent user profiling for personalized persuasiveness prediction.

</details>


### [84] [Stephanie2: Thinking, Waiting, and Making Decisions Like Humans in Step-by-Step AI Social Chat](https://arxiv.org/abs/2601.05657)
*Hao Yang,Hongyuan Lu,Dingkang Yang,Wenliang Yang,Peng Sun,Xiaochuan Zhang,Jun Xiao,Kefan He,Wai Lam,Yang Liu,Xinhua Zeng*

Main category: cs.CL

TL;DR: 本文提出了Stephanie2，一种新型的逐步决策对话代理，通过主动等待和消息节奏自适应机制，提升了AI聊天的自然性和参与度。


<details>
  <summary>Details</summary>
Motivation: 现有AI聊天系统缺乏主动等待机制，消息节奏不自然，无法模拟人类即时通讯中的短消息序列交互。

Method: 提出Stephanie2模型，引入主动等待机制与消息节奏自适应，将延迟建模为思考时间与打字时间之和；并设计基于时间窗口的双代理对话系统生成伪对话历史用于评估。

Result: Stephanie2在自然性、参与度等指标上显著优于Stephanie1，并在角色识别图灵测试中获得更高通过率。

Conclusion: Stephanie2通过精细化的时序建模与决策机制，有效提升了逐步式AI对话的真实感与交互质量。

Abstract: Instant-messaging human social chat typically progresses through a sequence of short messages. Existing step-by-step AI chatting systems typically split a one-shot generation into multiple messages and send them sequentially, but they lack an active waiting mechanism and exhibit unnatural message pacing. In order to address these issues, we propose Stephanie2, a novel next-generation step-wise decision-making dialogue agent. With active waiting and message-pace adaptation, Stephanie2 explicitly decides at each step whether to send or wait, and models latency as the sum of thinking time and typing time to achieve more natural pacing. We further introduce a time-window-based dual-agent dialogue system to generate pseudo dialogue histories for human and automatic evaluations. Experiments show that Stephanie2 clearly outperforms Stephanie1 on metrics such as naturalness and engagement, and achieves a higher pass rate on human evaluation with the role identification Turing test.

</details>


### [85] [Afri-MCQA: Multimodal Cultural Question Answering for African Languages](https://arxiv.org/abs/2601.05699)
*Atnafu Lambebo Tonja,Srija Anand,Emilio Villa-Cueva,Israel Abebe Azime,Jesujoba Oluwadara Alabi,Muhidin A. Mohamed,Debela Desalegn Yadeta,Negasi Haile Abadi,Abigail Oppong,Nnaemeka Casmir Obiefuna,Idris Abdulmumin,Naome A Etori,Eric Peter Wairagala,Kanda Patrick Tshinu,Imanigirimbabazi Emmanuel,Gabofetswe Malema,Alham Fikri Aji,David Ifeoluwa Adelani,Thamar Solorio*

Main category: cs.CL

TL;DR: 本文介绍了Afri-MCQA，首个覆盖15种非洲语言的多语种文化问答基准，揭示了当前大语言模型在非洲语言和文化理解上的严重不足，并呼吁采用语音优先、文化嵌入式预训练与跨语言文化迁移等新范式。


<details>
  <summary>Details</summary>
Motivation: 非洲拥有全球超三分之一的语言，但在AI研究中严重缺位；现有模型在非洲语言及文化理解任务上表现极差，亟需构建高质量、本土化、多模态的文化问答基准以推动包容性AI发展。

Method: 由母语者完全构建包含7.5k问答对的Afri-MCQA基准，覆盖15种非洲语言（12国），含文本与语音双模态英-非平行数据；设计控制实验分离语言能力与文化知识评估；系统评测主流开源大模型在该基准上的表现。

Result: 开源大模型在Afri-MCQA上整体表现极差，尤其在母语或语音开放问答任务中准确率近零；控制实验显示，即使排除文化因素，母语（文本/语音）性能仍显著低于英语，证实语言能力本身存在巨大鸿沟。

Conclusion: 当前AI系统在非洲语言与文化场景下存在系统性短板；必须转向语音优先建模、文化感知预训练与跨语言文化知识迁移，才能实现真正包容的多模态AI。

Abstract: Africa is home to over one-third of the world's languages, yet remains underrepresented in AI research. We introduce Afri-MCQA, the first Multilingual Cultural Question-Answering benchmark covering 7.5k Q&A pairs across 15 African languages from 12 countries. The benchmark offers parallel English-African language Q&A pairs across text and speech modalities and was entirely created by native speakers. Benchmarking large language models (LLMs) on Afri-MCQA shows that open-weight models perform poorly across evaluated cultures, with near-zero accuracy on open-ended VQA when queried in native language or speech. To evaluate linguistic competence, we include control experiments meant to assess this specific aspect separate from cultural knowledge, and we observe significant performance gaps between native languages and English for both text and speech. These findings underscore the need for speech-first approaches, culturally grounded pretraining, and cross-lingual cultural transfer. To support more inclusive multimodal AI development in African languages, we release our Afri-MCQA under academic license or CC BY-NC 4.0 on HuggingFace (https://huggingface.co/datasets/Atnafu/Afri-MCQA)

</details>


### [86] [Multimodal In-context Learning for ASR of Low-resource Languages](https://arxiv.org/abs/2601.05707)
*Zhaolin Li,Jan Niehues*

Main category: cs.CL

TL;DR: This paper explores multimodal in-context learning (MICL) with speech LLMs (Phi-4 and Qwen3-Omni) for low-resource and endangered languages, showing MICL improves ASR performance without target-language training data, aided by cross-lingual transfer and attention analysis.


<details>
  <summary>Details</summary>
Motivation: ASR covers few languages due to scarce supervised data; prior ICL work focuses on high-resource languages and text-only settings, leaving a gap for unseen, low-resource languages using multimodal speech-text inputs.

Method: Experiments with Phi-4 and Qwen3-Omni on three endangered languages; evaluation of MICL effectiveness, cross-lingual transfer learning, attention pattern analysis, and a hybrid ASR system combining acoustic models with MICL-based hypothesis selection.

Result: MICL works for unseen languages; cross-lingual transfer boosts MICL efficiency; attention shows layer-dependent audio/text preferences and text bias; prompt-based ASR fails on unseen languages, but the proposed MICL-augmented ASR consistently improves performance and matches or exceeds corpus-trained LMs without target-language data.

Conclusion: Multimodal in-context learning enables effective zero-shot adaptation of speech LLMs to unseen, low-resource languages, and integrating MICL into ASR systems offers a promising data-efficient path for endangered language recognition.

Abstract: Automatic speech recognition (ASR) still covers only a small fraction of the world's languages, mainly due to supervised data scarcity. In-context learning (ICL) with large language models (LLMs) addresses this problem, but prior work largely focuses on high-resource languages covered during training and text-only settings. This paper investigates whether speech LLMs can learn unseen languages with multimodal ICL (MICL), and how this learning can be used to improve ASR. We conduct experiments with two speech LLMs, Phi-4 and Qwen3-Omni, on three diverse endangered languages. Firstly, we find that MICL is effective for unseen languages, leveraging both speech and text modalities. We further show that cross-lingual transfer learning improves MICL efficiency on target languages without training on them. Moreover, we analyze attention patterns to interpret MICL mechanisms, and we observe layer-dependent preferences between audio and text context, with an overall bias towards text. Finally, we show that prompt-based ASR with speech LLMs performs poorly on unseen languages, motivating a simple ASR system that combines a stronger acoustic model with a speech LLM via MICL-based selection of acoustic hypotheses. Results show that MICL consistently improves ASR performance, and that cross-lingual transfer learning matches or outperforms corpus-trained language models without using target-language data. Our code is publicly available.

</details>


### [87] [Visualising Information Flow in Word Embeddings with Diffusion Tensor Imaging](https://arxiv.org/abs/2601.05713)
*Thomas Fabian*

Main category: cs.CL

TL;DR: 本文提出了一种将扩散张量成像（DTI）应用于词嵌入的新工具，以分析和可视化自然语言表达中的信息流，从而超越孤立词嵌入的分析，提升大语言模型（LLM）的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅分析单个词的嵌入，忽略了上下文，难以刻画自然语言表达的整体表征。

Method: 将扩散张量成像（DTI）技术应用于词嵌入，追踪LLM各层中词间的信息流动。

Result: DTI能揭示词嵌入间的信息流模式，支持不同模型结构比较、冗余层剪枝，并在代词消解、隐喻识别等任务中发现差异性信息流。

Conclusion: 该方法为理解LLM如何表征真实自然语言表达提供了新视角，显著提升了NLP模型的可解释性。

Abstract: Understanding how large language models (LLMs) represent natural language is a central challenge in natural language processing (NLP) research. Many existing methods extract word embeddings from an LLM, visualise the embedding space via point-plots, and compare the relative positions of certain words. However, this approach only considers single words and not whole natural language expressions, thus disregards the context in which a word is used. Here we present a novel tool for analysing and visualising information flow in natural language expressions by applying diffusion tensor imaging (DTI) to word embeddings. We find that DTI reveals how information flows between word embeddings. Tracking information flows within the layers of an LLM allows for comparing different model structures and revealing opportunities for pruning an LLM's under-utilised layers. Furthermore, our model reveals differences in information flows for tasks like pronoun resolution and metaphor detection. Our results show that our model permits novel insights into how LLMs represent actual natural language expressions, extending the comparison of isolated word embeddings and improving the interpretability of NLP models.

</details>


### [88] [Analysing Differences in Persuasive Language in LLM-Generated Text: Uncovering Stereotypical Gender Patterns](https://arxiv.org/abs/2601.05751)
*Amalie Brogaard Pauli,Maria Barrett,Max Müller-Eberstein,Isabelle Augenstein,Ira Assent*

Main category: cs.CL

TL;DR: 本研究提出一个评估框架，分析大型语言模型（LLMs）在生成说服性语言时受收件人性别、发送者意图和输出语言影响的程度；通过对13个LLM和16种语言的实验，结合社会心理学与传播学依据的19类说服语言指标，发现所有模型均存在显著性别差异，且与既有性别刻板语言倾向一致。


<details>
  <summary>Details</summary>
Motivation: 理解用户指令如何影响LLM生成说服性语言，尤其关注不同目标群体（如性别）是否导致系统性偏差。

Method: 构建基于社会心理学与传播学的19类说服语言评估框架，采用成对提示指令，在13个LLM和16种语言上开展实验，使用LLM-as-judge方式评估响应。

Result: 所有被测模型均表现出显著的性别差异，生成的说服性语言符合社会心理学和语用学中已知的性别刻板语言模式。

Conclusion: LLM在说服性文本生成中内嵌了社会性别偏见，需在设计、评估与部署中纳入针对性的公平性考量。

Abstract: Large language models (LLMs) are increasingly used for everyday communication tasks, including drafting interpersonal messages intended to influence and persuade. Prior work has shown that LLMs can successfully persuade humans and amplify persuasive language. It is therefore essential to understand how user instructions affect the generation of persuasive language, and to understand whether the generated persuasive language differs, for example, when targeting different groups. In this work, we propose a framework for evaluating how persuasive language generation is affected by recipient gender, sender intent, or output language. We evaluate 13 LLMs and 16 languages using pairwise prompt instructions. We evaluate model responses on 19 categories of persuasive language using an LLM-as-judge setup grounded in social psychology and communication science. Our results reveal significant gender differences in the persuasive language generated across all models. These patterns reflect biases consistent with gender-stereotypical linguistic tendencies documented in social psychology and sociolinguistics.

</details>


### [89] [AutoMonitor-Bench: Evaluating the Reliability of LLM-Based Misbehavior Monitor](https://arxiv.org/abs/2601.05752)
*Shu Yang,Jingyu Hu,Tong Li,Hanqi Yan,Wenxuan Wang,Di Wang*

Main category: cs.CL

TL;DR: 本文提出了AutoMonitor-Bench，首个系统评估LLM-based误行为监测器可靠性的基准，涵盖问答、代码生成与推理任务，共3010个标注样本；提出Miss Rate和False Alarm Rate两个互补指标，并在12个闭源与10个开源LLM上验证了监控性能的显著差异及MR-FAR权衡；进一步通过15万样本微调Qwen3-4B，揭示现有方法对隐式误行为泛化能力不足，强调需发展任务感知的监控设计与训练策略。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估大语言模型（LLM）误行为监测器可靠性的基准，且监测器在检测失败行为与误报之间存在权衡，亟需量化分析其性能边界与改进路径。

Method: 构建首个专用基准AutoMonitor-Bench（含3010个配对标注样本），定义Miss Rate（MR）与False Alarm Rate（FAR）双指标；在12个闭源与10个开源LLM上开展系统评测；进一步构建153,581样本的大规模训练集，微调Qwen3-4B-Instruction以探究监控能力的可迁移性与泛化性。

Result: 发现不同LLM监控器性能差异显著，普遍存在MR与FAR之间的强权衡关系；微调实验表明，基于显式易构造误行为数据的训练难以有效提升对隐式、未见误行为的检测能力。

Conclusion: LLM误行为监控面临可靠性与可扩展性双重挑战，现有方法泛化能力有限；未来工作应聚焦任务感知的监控架构设计与更鲁棒的训练策略。

Abstract: We introduce AutoMonitor-Bench, the first benchmark designed to systematically evaluate the reliability of LLM-based misbehavior monitors across diverse tasks and failure modes. AutoMonitor-Bench consists of 3,010 carefully annotated test samples spanning question answering, code generation, and reasoning, with paired misbehavior and benign instances. We evaluate monitors using two complementary metrics: Miss Rate (MR) and False Alarm Rate (FAR), capturing failures to detect misbehavior and oversensitivity to benign behavior, respectively. Evaluating 12 proprietary and 10 open-source LLMs, we observe substantial variability in monitoring performance and a consistent trade-off between MR and FAR, revealing an inherent safety-utility tension. To further explore the limits of monitor reliability, we construct a large-scale training corpus of 153,581 samples and fine-tune Qwen3-4B-Instruction to investigate whether training on known, relatively easy-to-construct misbehavior datasets improves monitoring performance on unseen and more implicit misbehaviors. Our results highlight the challenges of reliable, scalable misbehavior monitoring and motivate future work on task-aware designing and training strategies for LLM-based monitors.

</details>


### [90] [One Script Instead of Hundreds? On Pretraining Romanized Encoder Language Models](https://arxiv.org/abs/2601.05776)
*Benedikt Ebing,Lennart Keller,Goran Glavaš*

Main category: cs.CL

TL;DR: 本文探讨了在多语言语言模型预训练中使用罗马化处理的利弊，发现对于音节文字语言（如中文和日文）罗马化会导致性能下降，而对字母文字语言影响较小；同时，罗马化并未引发负面跨语言干扰，反而提升了音节文字语言的编码效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于罗马化在高资源拉丁字母语言向低资源非拉丁字母语言迁移中的优势，但其在通用多语言模型预训练中的适用性，尤其是对高资源语言是否造成信息损失尚不明确。

Method: 从零开始分别在罗马化文本和原始文本上预训练六种类型学多样的高资源语言的编码器语言模型，并采用两种不同保真度的罗马化工具，分析脚本特异性信息丢失和跨语言词汇重叠引发的负干扰两个潜在退化来源。

Result: 音节文字语言（中、日）在罗马化后性能下降，高保真罗马化可缓解但无法完全恢复；字母文字语言性能几乎无损；未发现因子词重叠增加导致的负面跨语言干扰；罗马化提升了音节文字语言的编码效率（生育率），且代价极小。

Conclusion: 罗马化并非适用于所有高资源语言的通用预训练策略，其效果高度依赖文字类型；对音节文字语言需谨慎使用，而对字母文字语言则兼具效率与性能优势。

Abstract: Exposing latent lexical overlap, script romanization has emerged as an effective strategy for improving cross-lingual transfer (XLT) in multilingual language models (mLMs). Most prior work, however, focused on setups that favor romanization the most: (1) transfer from high-resource Latin-script to low-resource non-Latin-script languages and/or (2) between genealogically closely related languages with different scripts. It thus remains unclear whether romanization is a good representation choice for pretraining general-purpose mLMs, or, more precisely, if information loss associated with romanization harms performance for high-resource languages. We address this gap by pretraining encoder LMs from scratch on both romanized and original texts for six typologically diverse high-resource languages, investigating two potential sources of degradation: (i) loss of script-specific information and (ii) negative cross-lingual interference from increased vocabulary overlap. Using two romanizers with different fidelity profiles, we observe negligible performance loss for languages with segmental scripts, whereas languages with morphosyllabic scripts (Chinese and Japanese) suffer degradation that higher-fidelity romanization mitigates but cannot fully recover. Importantly, comparing monolingual LMs with their mLM counterpart, we find no evidence that increased subword overlap induces negative interference. We further show that romanization improves encoding efficiency (i.e., fertility) for segmental scripts at a negligible performance cost.

</details>


### [91] [Simplify-This: A Comparative Analysis of Prompt-Based and Fine-Tuned LLMs](https://arxiv.org/abs/2601.05794)
*Eilam Cohen,Itamar Bul,Danielle Inbar,Omri Loewenbach*

Main category: cs.CL

TL;DR: 本文对文本简化任务中微调与提示工程两种范式进行了对比研究，发现微调模型在结构简化方面更优，而提示工程在语义相似性上表现更好但易复制输入；人工评估更偏好微调结果，并开源了代码、数据集、模型检查点和提示模板。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在文本简化任务中微调与提示工程两种方法的实际权衡与适用场景。

Method: 开展名为Simplify-This的对比实验，使用编码器-解码器结构的LLM，在多个基准数据集上系统评估微调与提示工程的效果，并采用多种自动指标及人工评估进行分析。

Result: 微调模型在结构简化方面持续优于提示方法；提示方法语义相似性得分更高但存在输入复制现象；人工评估整体更倾向微调输出。

Conclusion: 微调在文本简化任务中更具综合优势，尤其在生成质量与可控性方面；提示工程虽便捷但存在局限，二者应依任务需求选择；研究强调可复现性并全面开源资源。

Abstract: Large language models (LLMs) enable strong text generation, and in general there is a practical tradeoff between fine-tuning and prompt engineering. We introduce Simplify-This, a comparative study evaluating both paradigms for text simplification with encoder-decoder LLMs across multiple benchmarks, using a range of evaluation metrics. Fine-tuned models consistently deliver stronger structural simplification, whereas prompting often attains higher semantic similarity scores yet tends to copy inputs. A human evaluation favors fine-tuned outputs overall. We release code, a cleaned derivative dataset used in our study, checkpoints of fine-tuned models, and prompt templates to facilitate reproducibility and future work.

</details>


### [92] [EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis](https://arxiv.org/abs/2601.05808)
*Xiaoshuai Song,Haofei Chang,Guanting Dong,Yutao Zhu,Zhicheng Dou,Ji-Rong Wen*

Main category: cs.CL

TL;DR: 本文提出EnvScaler框架，通过程序化合成方法自动构建可扩展的工具交互环境，提升大语言模型在复杂多轮、多工具任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练所需的工具交互环境受限于真实系统访问困难、模拟环境易幻觉且不一致、人工构建难以规模化等问题。

Method: EnvScaler包含两个组件：SkelBuilder用于通过主题挖掘、逻辑建模与质量评估构建多样化环境骨架；ScenGenerator为每个环境生成多个任务场景及基于规则的轨迹验证函数。

Result: 合成了191个环境和约7K个场景，并应用于Qwen3系列模型的监督微调（SFT）和强化学习（RL），在三个基准上显著提升了模型在复杂环境中的任务解决能力。

Conclusion: EnvScaler提供了一种高效、可扩展的自动化环境构建方法，有效增强LLM作为智能代理在真实世界工具交互任务中的泛化与鲁棒性。

Abstract: Large language models (LLMs) are expected to be trained to act as agents in various real-world environments, but this process relies on rich and varied tool-interaction sandboxes. However, access to real systems is often restricted; LLM-simulated environments are prone to hallucinations and inconsistencies; and manually built sandboxes are hard to scale. In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis. EnvScaler comprises two components. First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation. Then, ScenGenerator generates multiple task scenarios and rule-based trajectory validation functions for each environment. With EnvScaler, we synthesize 191 environments and about 7K scenarios, and apply them to Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Qwen3 series models. Results on three benchmarks show that EnvScaler significantly improves LLMs' ability to solve tasks in complex environments involving multi-turn, multi-tool interactions. We release our code and data at https://github.com/RUC-NLPIR/EnvScaler.

</details>


### [93] [LLMs as Science Journalists: Supporting Early-stage Researchers in Communicating Their Science to the Public](https://arxiv.org/abs/2601.05821)
*Milad Alshomary,Grace Li,Anubhav Jangra,Yufang Hou,Kathleen McKeown,Smaranda Muresan*

Main category: cs.CL

TL;DR: 本文提出了一种训练大语言模型（LLM）模拟科学记者角色的框架，旨在帮助早期研究人员更有效地向公众传播科研成果；实验表明，该模型比通用LLM更能提出关于研究社会影响的相关问题，并在用户研究中获得更高评价。


<details>
  <summary>Details</summary>
Motivation: 科学界需要工具帮助早期研究人员有效向公众传播研究成果，而现有通用大语言模型在此任务上未经过专门优化。

Method: 提出一种训练LLM模拟科学记者角色的框架，并通过与模拟及真实研究人员的对话评估其效果。

Result: 训练后的LLM记者能提出更多关于研究社会影响的相关问题，促使研究人员澄清和拓展其发现；用户研究显示参与者更偏好该模型而非通用LLM。

Conclusion: 针对科学传播任务专门训练的LLM显著优于通用LLM，为早期科研人员提供了实用、可推广的沟通辅助工具。

Abstract: The scientific community needs tools that help early-stage researchers effectively communicate their findings and innovations to the public. Although existing general-purpose Large Language Models (LLMs) can assist in this endeavor, they are not optimally aligned for it. To address this, we propose a framework for training LLMs to emulate the role of a science journalist that can be used by early-stage researchers to learn how to properly communicate their papers to the general public. We evaluate the usefulness of our trained LLM Journalists in leading conversations with both simulated and human researchers. %compared to the general-purpose ones. Our experiments indicate that LLMs trained using our framework ask more relevant questions that address the societal impact of research, prompting researchers to clarify and elaborate on their findings. In the user study, the majority of participants who interacted with our trained LLM Journalist appreciated it more than interacting with general-purpose LLMs.

</details>


### [94] [Peek2: A Regex-free implementation of pretokenizers for Byte-level BPE](https://arxiv.org/abs/2601.05833)
*Liu Zai*

Main category: cs.CL

TL;DR: Peek2 is a new, regex-free pretokenization algorithm for Byte-level BPE tokenizers that improves throughput by 1.11× over existing cl100k-like pretokenizers while maintaining identical output and linear CPU-only complexity.


<details>
  <summary>Details</summary>
Motivation: To replace regex-based pretokenizers with a faster, safer, and more efficient alternative without changing output behavior.

Method: Design and implementation of Peek2, a regex-free, CPU-only pretokenization algorithm with guaranteed linear O(n) time complexity.

Result: 1.11× improvement in overall Byte-level BPE encoding throughput; identical presegmentation results to the original regex-based pretokenizer.

Conclusion: Peek2 serves as a high-performance, drop-in replacement for existing pretokenizers in major LLMs (e.g., GPT-3, LLaMa-3, Qwen-2.5), offering better speed, safety, and deterministic linear-time execution.

Abstract: Pretokenization is a crucial, sequential pass in Byte-level BPE tokenizers. Our proposed new implementation, Peek2, serves as a drop-in replacement for cl100k-like pretokenizers used in GPT-3, LLaMa-3, and Qwen-2.5. Designed with performance and safety in mind, Peek2 is Regex-free and delivers a $ 1.11\times $ improvement in overall throughput across the entire Byte-level BPE encoding process. This algorithm runs entirely on the CPU, has stable linear complexity $ O(n) $, and provides presegmentation results identical to those of the original Regex-based pretokenizer.

</details>


### [95] [Left, Right, or Center? Evaluating LLM Framing in News Classification and Generation](https://arxiv.org/abs/2601.05835)
*Molly Kennedy,Ali Parker,Yihong Liu,Hinrich Schütze*

Main category: cs.CL

TL;DR: 本文研究了九种大型语言模型（LLM）在新闻摘要生成中的政治框架偏差，发现普遍存在‘意识形态中心坍缩’现象，即模型倾向于生成中立化表述；Grok 4最具意识形态表达力，Claude Sonnet 4.5和Llama 3.1分别在商业与开源模型中展现出最强的偏见识别能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLM广泛用于新闻摘要与文本重写，其隐含的政治框架倾向可能影响公众认知，亟需系统评估其意识形态偏差。

Method: 采用少样本学习预测文章意识形态（LEFT/CENTER/RIGHT），并设计FAITHFUL、CENTRIST、LEFT、RIGHT四类提示生成摘要，统一用固定意识形态评估器对所有输出打分。

Result: 发现所有模型均存在显著的中心坍缩现象；Grok 4生成内容意识形态最鲜明；Claude Sonnet 4.5和Llama 3.1在偏见分类任务中表现最优。

Conclusion: 当前主流LLM在政治框架任务中呈现系统性中立化倾向，削弱其意识形态表达能力，需针对性改进以提升透明度与可控性。

Abstract: Large Language Model (LLM) based summarization and text generation are increasingly used for producing and rewriting text, raising concerns about political framing in journalism where subtle wording choices can shape interpretation. Across nine state-of-the-art LLMs, we study political framing by testing whether LLMs' classification-based bias signals align with framing behavior in their generated summaries. We first compare few-shot ideology predictions against LEFT/CENTER/RIGHT labels. We then generate "steered" summaries under FAITHFUL, CENTRIST, LEFT, and RIGHT prompts, and score all outputs using a single fixed ideology evaluator. We find pervasive ideological center-collapse in both article-level ratings and generated text, indicating a systematic tendency toward centrist framing. Among evaluated models, Grok 4 is by far the most ideologically expressive generator, while Claude Sonnet 4.5 and Llama 3.1 achieve the strongest bias-rating performance among commercial and open-weight models, respectively.

</details>


### [96] [Semantic NLP Pipelines for Interoperable Patient Digital Twins from Unstructured EHRs](https://arxiv.org/abs/2601.05847)
*Rafael Brens,Yuqiao Meng,Luoxi Tang,Zhaohan Xi*

Main category: cs.CL

TL;DR: 本文提出了一种基于语义NLP的流水线，将非结构化的电子健康记录（EHR）自由文本自动转换为符合FHIR标准的患者数字孪生表示，显著提升了实体与关系抽取的准确性及数据互操作性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从非结构化EHR中生成可互操作的患者数字孪生，主要受限于临床文档异质性和缺乏标准化映射。

Method: 构建语义NLP驱动流水线：包括命名实体识别（NER）提取临床概念、概念标准化（映射至SNOMED-CT或ICD-10）、关系抽取建模条件/药物/观测间的结构化关联，并输出FHIR兼容数字孪生。

Result: 在MIMIC-IV Demo数据集上评估显示，实体与关系抽取F1分数高；相比基线方法，模式完整性与互操作性明显提升，并通过MIMIC-IV-on-FHIR参考映射验证了有效性。

Conclusion: 该语义NLP流水线为从自由文本EHR构建标准化、可互操作的患者数字孪生提供了可行且高效的技术路径，有助于推动数字孪生在临床决策支持中的实际应用。

Abstract: Digital twins -- virtual replicas of physical entities -- are gaining traction in healthcare for personalized monitoring, predictive modeling, and clinical decision support. However, generating interoperable patient digital twins from unstructured electronic health records (EHRs) remains challenging due to variability in clinical documentation and lack of standardized mappings. This paper presents a semantic NLP-driven pipeline that transforms free-text EHR notes into FHIR-compliant digital twin representations. The pipeline leverages named entity recognition (NER) to extract clinical concepts, concept normalization to map entities to SNOMED-CT or ICD-10, and relation extraction to capture structured associations between conditions, medications, and observations. Evaluation on MIMIC-IV Clinical Database Demo with validation against MIMIC-IV-on-FHIR reference mappings demonstrates high F1-scores for entity and relation extraction, with improved schema completeness and interoperability compared to baseline methods.

</details>


### [97] [Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs](https://arxiv.org/abs/2601.05851)
*Sandeep Mishra,Devichand Budagam,Anubhab Mandal,Bishal Santra,Pawan Goyal,Manish Gupta*

Main category: cs.CL

TL;DR: 本文提出了多模态自动补全（MAC）任务，利用文本和视觉线索预测实时聊天中的下一个字符，并设计了Router-Suggest框架动态选择文本模型或视觉语言模型，在保持高用户满意度的同时显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有文本自动补全（TAC）难以捕捉依赖共享视觉上下文的用户意图，而数字助理、医疗咨询等场景亟需结合视觉与文本的实时多模态补全能力。

Method: 构建基于MMDialog和ImageChat的MAC基准数据集；评估主流视觉语言模型（VLMs）与纯文本基线；提出Router-Suggest动态路由框架及其轻量变体，依据对话上下文自适应选择模型。

Result: Router-Suggest相较最优VLM提速2.3–10倍；用户研究表明VLM显著提升用户满意度、减少打字负担并改善多轮对话补全质量。

Conclusion: 多模态上下文对自动补全至关重要，Router-Suggest为资源受限场景提供了高效、用户友好的实用方案，推动更智能、感知用户的助手发展。

Abstract: Real-time multimodal auto-completion is essential for digital assistants, chatbots, design tools, and healthcare consultations, where user inputs rely on shared visual context. We introduce Multimodal Auto-Completion (MAC), a task that predicts upcoming characters in live chats using partially typed text and visual cues. Unlike traditional text-only auto-completion (TAC), MAC grounds predictions in multimodal context to better capture user intent. To enable this task, we adapt MMDialog and ImageChat to create benchmark datasets. We evaluate leading vision-language models (VLMs) against strong textual baselines, highlighting trade-offs in accuracy and efficiency. We present Router-Suggest, a router framework that dynamically selects between textual models and VLMs based on dialog context, along with a lightweight variant for resource-constrained environments. Router-Suggest achieves a 2.3x to 10x speedup over the best-performing VLM. A user study shows that VLMs significantly excel over textual models on user satisfaction, notably saving user typing effort and improving the quality of completions in multi-turn conversations. These findings underscore the need for multimodal context in auto-completions, leading to smarter, user-aware assistants.

</details>


### [98] [CLewR: Curriculum Learning with Restarts for Machine Translation Preference Learning](https://arxiv.org/abs/2601.05858)
*Alexandra Dragomir,Florin Brad,Radu Tudor Ionescu*

Main category: cs.CL

TL;DR: 本文提出了一种带重启的课程学习策略（CLewR），将其融入多种偏好优化算法中，以提升零样本多语言机器翻译性能，并在多个模型家族上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好优化的零样本多语言机器翻译方法忽略了训练中数据样本呈现顺序这一关键因素。

Method: 将课程学习引入主流偏好优化算法，并提出带重启的课程学习策略（CLewR），在训练过程中多次重复从易到难的学习过程，以缓解对简单样本的灾难性遗忘。

Result: 在Gemma2、Qwen2.5、Llama3.1等多个模型家族及多种偏好优化技术上均取得一致性能提升。

Conclusion: 数据呈现顺序对偏好优化式零样本多语言MT至关重要，CLewR是一种有效且通用的改进策略。

Abstract: Large language models (LLMs) have demonstrated competitive performance in zero-shot multilingual machine translation (MT). Some follow-up works further improved MT performance via preference optimization, but they leave a key aspect largely underexplored: the order in which data samples are given during training. We address this topic by integrating curriculum learning into various state-of-the-art preference optimization algorithms to boost MT performance. We introduce a novel curriculum learning strategy with restarts (CLewR), which reiterates easy-to-hard curriculum multiple times during training to effectively mitigate the catastrophic forgetting of easy examples. We demonstrate consistent gains across several model families (Gemma2, Qwen2.5, Llama3.1) and preference optimization techniques. We publicly release our code at https://github.com/alexandra-dragomir/CLewR.

</details>


### [99] [What do the metrics mean? A critical analysis of the use of Automated Evaluation Metrics in Interpreting](https://arxiv.org/abs/2601.05864)
*Jonathan Downie,Joss Moorkens*

Main category: cs.CL

TL;DR: 本文探讨了当前用于评估口译质量的自动化指标，指出这些指标因无法考虑交际语境而单独使用时不可行。


<details>
  <summary>Details</summary>
Motivation: 随着远程口译、计算机辅助口译、自动语音翻译和口译虚拟形象等技术的发展，亟需快速高效地评估口译质量。

Method: 本文系统考察了近期提出的多种自动化口译质量评估方法，并分析其在真实口译实践（包括人工与机器口译）中的适用性。

Result: 研究发现，现有自动评估指标无法充分纳入交际语境因素，因此单独使用时不足以衡量口译质量。

Conclusion: 口译质量评估必须结合具体语境；脱离语境的纯自动化指标不可行，需与语境化分析相结合。

Abstract: With the growth of interpreting technologies, from remote interpreting and Computer-Aided Interpreting to automated speech translation and interpreting avatars, there is now a high demand for ways to quickly and efficiently measure the quality of any interpreting delivered. A range of approaches to fulfil the need for quick and efficient quality measurement have been proposed, each involving some measure of automation. This article examines these recently-proposed quality measurement methods and will discuss their suitability for measuring the quality of authentic interpreting practice, whether delivered by humans or machines, concluding that automatic metrics as currently proposed cannot take into account the communicative context and thus are not viable measures of the quality of any interpreting provision when used on their own. Across all attempts to measure or even categorise quality in Interpreting Studies, the contexts in which interpreting takes place have become fundamental to the final analysis.

</details>


### [100] [FACTUM: Mechanistic Detection of Citation Hallucination in Long-Form RAG](https://arxiv.org/abs/2601.05866)
*Maxime Dassen,Rebecca Kotula,Kenton Murray,Andrew Yates,Dawn Lawrie,Efsun Kayi,James Mayfield,Kevin Duh*

Main category: cs.CL

TL;DR: 本文提出FACTUM框架，通过四个机制性指标分析RAG模型中注意力与FFN通路的贡献及对齐程度，揭示正确引用具有随模型规模变化的动态特征，并显著提升检测引用幻觉的性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作将引用幻觉简单归因于模型对参数化知识的过度依赖，本文挑战该观点，强调需深入理解模型内部机制及其随规模变化的动态特性。

Method: 提出FACTUM框架，定义四个机制性评分，量化注意力路径、FFN路径的独立贡献及其对齐程度；在不同规模模型（如Llama-3.2-3B与Llama-3.1-8B）上分析引用正确性的动态签名。

Result: 发现正确引用具有两个稳定特征：更强的参数化知识贡献和更多使用attention sink进行信息整合；且‘通路对齐度’的优劣随模型规模反转；FACTUM在AUC上较SOTA提升最高达37.5%。

Conclusion: 引用幻觉本质是尺度依赖的内部机制协同问题，FACTUM为构建更可靠RAG系统提供了新视角与有效工具。

Abstract: Retrieval-Augmented Generation (RAG) models are critically undermined by citation hallucinations, a deceptive failure where a model confidently cites a source that fails to support its claim. Existing work often attributes hallucination to a simple over-reliance on the model's parametric knowledge. We challenge this view and introduce FACTUM (Framework for Attesting Citation Trustworthiness via Underlying Mechanisms), a framework of four mechanistic scores measuring the distinct contributions of a model's attention and FFN pathways, and the alignment between them. Our analysis reveals two consistent signatures of correct citation: a significantly stronger contribution from the model's parametric knowledge and greater use of the attention sink for information synthesis. Crucially, we find the signature of a correct citation is not static but evolves with model scale. For example, the signature of a correct citation for the Llama-3.2-3B model is marked by higher pathway alignment, whereas for the Llama-3.1-8B model, it is characterized by lower alignment, where pathways contribute more distinct, orthogonal information. By capturing this complex, evolving signature, FACTUM outperforms state-of-the-art baselines by up to 37.5% in AUC. Our findings reframe citation hallucination as a complex, scale-dependent interplay between internal mechanisms, paving the way for more nuanced and reliable RAG systems.

</details>


### [101] [Continual-learning for Modelling Low-Resource Languages from Large Language Models](https://arxiv.org/abs/2601.05874)
*Santosh Srinath K,Mudit Somani,Varun Reddy Padala,Prajna Devi Upadhyay,Abhijit Das*

Main category: cs.CL

TL;DR: 本文提出了一种基于词性（POS）的语码转换与回放适配器策略，用于缓解小语言模型（SLM）在多语言持续学习中从大语言模型（LLM）适配时出现的灾难性遗忘问题，并在视觉问答和语言建模任务上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLM）在低资源语言场景中从大语言模型（LLM）适配时面临严重的灾难性遗忘问题，亟需有效的持续学习策略。

Method: 采用基于词性（POS）的语码转换与回放适配器相结合的持续学习策略，以在多语言训练中保留原有知识并吸收新语言能力。

Result: 在视觉问答和语言建模等跨模态任务上，所提方法显著缓解了灾难性遗忘，提升了模型在低资源语言上的性能。

Conclusion: 基于POS的语码转换与回放适配器是一种可行且有效的持续学习方案，可提升SLM在多语言场景下的鲁棒性与泛化能力。

Abstract: Modelling a language model for a multi-lingual scenario includes several potential challenges, among which catastrophic forgetting is the major challenge. For example, small language models (SLM) built for low-resource languages by adapting large language models (LLMs) pose the challenge of catastrophic forgetting. This work proposes to employ a continual learning strategy using parts-of-speech (POS)-based code-switching along with a replay adapter strategy to mitigate the identified gap of catastrophic forgetting while training SLM from LLM. Experiments conducted on vision language tasks such as visual question answering and language modelling task exhibits the success of the proposed architecture.

</details>


### [102] [iReasoner: Trajectory-Aware Intrinsic Reasoning Supervision for Self-Evolving Large Multimodal Models](https://arxiv.org/abs/2601.05877)
*Meghana Sunil,Manikandarajan Venmathimaran,Muthu Subash Kavitha*

Main category: cs.CL

TL;DR: 本文提出iReasoner框架，通过在无标签图像上进行自演化的Proposer-Solver循环，显式激发链式思维（CoT）并奖励中间推理步骤的一致性，从而在完全无监督后训练下提升大视觉语言模型的隐式推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有自演化框架仅奖励最终结果，缺乏对关键中间推理步骤的有效约束，难以支撑视觉引导的决策。

Method: 提出iReasoner框架，在Proposer-Solver循环中结合结果级内在奖励与轨迹感知的中间推理一致性奖励，无需真值标签或外部评判即可区分不同推理路径。

Result: 基于Qwen2.5-VL-7B模型，在多个多模态推理基准上实现最高+2.1分的无监督后训练性能提升。

Conclusion: iReasoner为纯无监督场景下以推理为中心的大模型自我改进提供了可行路径和初步范式。

Abstract: Recent work shows that large multimodal models (LMMs) can self-improve from unlabeled data via self-play and intrinsic feedback. Yet existing self-evolving frameworks mainly reward final outcomes, leaving intermediate reasoning weakly constrained despite its importance for visually grounded decision making. We propose iReasoner, a self-evolving framework that improves an LMM's implicit reasoning by explicitly eliciting chain-of-thought (CoT) and rewarding its internal agreement. In a Proposer--Solver loop over unlabeled images, iReasoner augments outcome-level intrinsic rewards with a trajectory-aware signal defined over intermediate reasoning steps, providing learning signals that distinguish reasoning paths leading to the same answer without ground-truth labels or external judges. Starting from Qwen2.5-VL-7B, iReasoner yields up to $+2.1$ points across diverse multimodal reasoning benchmarks under fully unsupervised post-training. We hope this work serves as a starting point for reasoning-aware self-improvement in LMMs in purely unsupervised settings.

</details>


### [103] [Gender Bias in LLMs: Preliminary Evidence from Shared Parenting Scenario in Czech Family Law](https://arxiv.org/abs/2601.05879)
*Jakub Harasta,Matej Vasina,Martin Kornel,Tomas Foltynek*

Main category: cs.CL

TL;DR: 本研究评估了四种主流大语言模型（GPT-5 nano、Claude Haiku 4.5、Gemini 2.5 Flash、Llama 3.3）在捷克家庭法离婚场景中是否存在性别偏见，通过性别化与中性化姓名设置及九个法律相关变量，发现部分模型输出的共同抚养比例存在性别依赖模式，提示LLM用于法律自助时存在偏见风险。


<details>
  <summary>Details</summary>
Motivation: 普通人日益依赖大语言模型（LLM）进行法律自助，但其直观使用可能因模型输出不完整、错误或带偏见而产生误导；尤其在敏感的家庭法领域，性别偏见可能加剧司法不公，亟需实证检验。

Method: 基于捷克家庭法设计专家级离婚场景，采用零样本方式测试四款前沿LLM；设置性别化名称版与中性标签版作为对照，并引入九个合法相关变量（如收入、照护时间等）以考察其对模型建议的共同抚养比例的影响。

Result: 初步结果表明不同模型表现存在差异，部分模型在性别化条件下输出的共同抚养比例呈现系统性性别依赖模式，例如对女性当事人建议更低的抚养权比例；中性标签下该偏差减弱，但未完全消除。

Conclusion: LLM在家庭法等高敏感法律任务中存在潜在性别偏见，可能误导非专业用户；当前评估方法仅揭示相关性与描述性不对称，尚不能确立因果关系，亟需更严格、多维度的法律AI公平性评估框架。

Abstract: Access to justice remains limited for many people, leading laypersons to increasingly rely on Large Language Models (LLMs) for legal self-help. Laypeople use these tools intuitively, which may lead them to form expectations based on incomplete, incorrect, or biased outputs. This study examines whether leading LLMs exhibit gender bias in their responses to a realistic family law scenario. We present an expert-designed divorce scenario grounded in Czech family law and evaluate four state-of-the-art LLMs GPT-5 nano, Claude Haiku 4.5, Gemini 2.5 Flash, and Llama 3.3 in a fully zero-shot interaction. We deploy two versions of the scenario, one with gendered names and one with neutral labels, to establish a baseline for comparison. We further introduce nine legally relevant factors that vary the factual circumstances of the case and test whether these variations influence the models' proposed shared-parenting ratios. Our preliminary results highlight differences across models and suggest gender-dependent patterns in the outcomes generated by some systems. The findings underscore both the risks associated with laypeople's reliance on LLMs for legal guidance and the need for more robust evaluation of model behavior in sensitive legal contexts. We present exploratory and descriptive evidence intended to identify systematic asymmetries rather than to establish causal effects.

</details>


### [104] [An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift](https://arxiv.org/abs/2601.05882)
*Constantinos Karouzos,Xingwei Tan,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 本文系统研究了偏好调优在领域迁移下的泛化能力，比较了五种主流对齐目标及多种适配策略（如目标域监督微调和伪标签），发现在摘要与问答任务中，基于伪标签的适配策略能显著缓解领域偏移导致的性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有偏好调优方法在训练领域外评估时性能下降、有用性降低，但尚不清楚不同适配策略在缓解该领域偏移问题上的效果差异。

Method: 开展全面系统的对齐泛化研究，对比五种主流对齐目标，并在摘要和问答有用性任务上评估源域到目标域的多种适配策略（包括目标域监督微调和伪标签）。

Result: 发现不同对齐目标在领域偏移下泛化能力存在系统性差异；基于伪标签的适配策略可显著减轻领域偏移带来的性能退化。

Conclusion: 对齐泛化受对齐目标和适配策略共同影响，伪标签是一种高效缓解领域偏移的有效方法。

Abstract: Preference tuning aligns pretrained language models to human judgments of quality, helpfulness, or safety by optimizing over explicit preference signals rather than likelihood alone. Prior work has shown that preference-tuning degrades performance and reduces helpfulness when evaluated outside the training domain. However, the extent to which adaptation strategies mitigate this domain shift remains unexplored. We address this challenge by conducting a comprehensive and systematic study of alignment generalization under domain shift. We compare five popular alignment objectives and various adaptation strategies from source to target, including target-domain supervised fine-tuning and pseudo-labeling, across summarization and question-answering helpfulness tasks. Our findings reveal systematic differences in generalization across alignment objectives under domain shift. We show that adaptation strategies based on pseudo-labeling can substantially reduce domain-shift degradation

</details>


### [105] [HAPS: Hierarchical LLM Routing with Joint Architecture and Parameter Search](https://arxiv.org/abs/2601.05903)
*Zihang Tian,Rui Li,Jingsen Zhang,Xiaohe Bo,Wei Huo,Xu Chen*

Main category: cs.CL

TL;DR: 本文提出HAPS，一种分层大语言模型（LLM）路由框架，联合搜索模型架构与参数设置，通过高低两级路由器协同优化，并引入参数生成网络与奖励增强目标函数，在基准测试中显著优于现有路由方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法仅关注模型架构选择，忽视了对任务性能至关重要的参数设置。

Method: 提出分层路由框架HAPS：高层路由器选择候选LLM架构，底层路由器为选定架构搜索最优参数；设计参数生成网络共享两路由器参数以相互增强；采用奖励增强目标函数进行训练。

Result: 在两个常用基准上，HAPS持续优于强路由基线方法。

Conclusion: 联合优化LLM架构与参数的分层路由策略更有效，HAPS为LLM路由提供了新范式。

Abstract: Large language model (LLM) routing aims to exploit the specialized strengths of different LLMs for diverse tasks. However, existing approaches typically focus on selecting LLM architectures while overlooking parameter settings, which are critical for task performance. In this paper, we introduce HAPS, a hierarchical LLM routing framework that jointly searches over model architectures and parameters. Specifically, we use a high-level router to select among candidate LLM architectures, and then search for the optimal parameters for the selected architectures based on a low-level router. We design a parameter generation network to share parameters between the two routers to mutually enhance their capabilities. In the training process, we design a reward-augmented objective to effectively optimize our framework. Experiments on two commonly used benchmarks show that HAPS consistently outperforms strong routing baselines. We have released our code at https://github.com/zihangtian/HAPS.

</details>


### [106] [Pantagruel: Unified Self-Supervised Encoders for French Text and Speech](https://arxiv.org/abs/2601.05911)
*Phuong-Hang Le,Valentin Pelloin,Arnault Chatelain,Maryem Bouziane,Mohammed Ghennai,Qianwen Guan,Kirill Milintsevich,Salima Mdhaffar,Aidan Mannion,Nils Defauw,Shuyue Gu,Alexandre Audibert,Marco Dinarelli,Yannick Estève,Lorraine Goeuriot,Steffen Lalande,Nicolas Hervé,Maximin Coavoux,François Portet,Étienne Ollion,Marie Candito,Maxime Peyrard,Solange Rossato,Benjamin Lecouteux,Aurélie Nardy,Gilles Sérasset,Vincent Segonne,Solène Evain,Diandra Fabre,Didier Schwab*

Main category: cs.CL

TL;DR: Pantagruel 是一组面向法语文本与语音的自监督编码器模型，通过在特征空间中学习上下文化目标表示，提升模态特异性编码器对语言和声学规律的建模能力；在多个法语下游任务上超越 CamemBERT、FlauBERT 等强基线。


<details>
  <summary>Details</summary>
Motivation: 现有法语模型多针对特定模态（如文本token或语音单元）设计预测目标，难以统一高效地建模跨模态语言与声学规律，亟需更通用的自监督表征学习方法。

Method: 提出在特征空间中学习上下文化目标表示的自监督目标，分别在大规模法语文本（Wikipedia、OSCAR、CroissantLLM）和语音数据集（MultilingualLibriSpeech、LeBenchmark、新构建的100k小时INA-100k）上预训练独立但架构共享的文本与语音编码器。

Result: 在FLUE、LeBenchmark等标准法语基准的多项文本与语音下游任务上，Pantagruel显著优于或媲美CamemBERT、FlauBERT、LeBenchmark2.0等强基线模型。

Conclusion: 特征空间的自监督目标能有效提升法语多模态表征学习效果；Pantagruel为法语语音-文本联合理解提供了鲁棒、统一的基础模型框架。

Abstract: We release Pantagruel models, a new family of self-supervised encoder models for French text and speech. Instead of predicting modality-tailored targets such as textual tokens or speech units, Pantagruel learns contextualized target representations in the feature space, allowing modality-specific encoders to capture linguistic and acoustic regularities more effectively. Separate models are pre-trained on large-scale French corpora, including Wikipedia, OSCAR and CroissantLLM for text, together with MultilingualLibriSpeech, LeBenchmark, and INA-100k for speech. INA-100k is a newly introduced 100,000-hour corpus of French audio derived from the archives of the Institut National de l'Audiovisuel (INA), the national repository of French radio and television broadcasts, providing highly diverse audio data. We evaluate Pantagruel across a broad range of downstream tasks spanning both modalities, including those from the standard French benchmarks such as FLUE or LeBenchmark. Across these tasks, Pantagruel models show competitive or superior performance compared to strong French baselines such as CamemBERT, FlauBERT, and LeBenchmark2.0, while maintaining a shared architecture that can seamlessly handle either speech or text inputs. These results confirm the effectiveness of feature-space self-supervised objectives for French representation learning and highlight Pantagruel as a robust foundation for multimodal speech-text understanding.

</details>


### [107] [Distilling Feedback into Memory-as-a-Tool](https://arxiv.org/abs/2601.05960)
*Víctor Gallego*

Main category: cs.CL

TL;DR: 本文提出了一种通过文件式记忆系统和代理控制的工具调用，将临时批评转化为可检索指南的框架，以摊销推理时的计算成本。在新型基于评分标准的学习数据集Rubric Feedback Bench上验证了该方法的有效性，结果表明增强后的LLM能快速达到测试时精炼流水线的性能，同时大幅降低推理开销。


<details>
  <summary>Details</summary>
Motivation: 降低大语言模型在推理阶段进行反复精炼（test-time refinement）所带来的高昂计算成本。

Method: 构建一个基于文件的记忆系统，并结合代理可控的工具调用，将推理过程中生成的临时批评（transient critiques）固化为可检索、可复用的指南（guidelines），从而实现推理成本的摊销。

Result: 在Rubric Feedback Bench数据集上，增强后的LLM在性能上迅速逼近test-time refinement方法，同时显著降低了推理成本。

Conclusion: 将动态推理过程中的中间反馈结构化并存入可检索记忆，是一种高效降低推理开销、保持性能的可行范式。

Abstract: We propose a framework that amortizes the cost of inference-time reasoning by converting transient critiques into retrievable guidelines, through a file-based memory system and agent-controlled tool calls. We evaluate this method on the Rubric Feedback Bench, a novel dataset for rubric-based learning. Experiments demonstrate that our augmented LLMs rapidly match the performance of test-time refinement pipelines while drastically reducing inference cost.

</details>


### [108] [The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.06002)
*Qiguang Chen,Yantao Du,Ziniu Li,Jinhao Liu,Songyao Duan,Jiarui Guo,Minghao Liu,Jiaheng Liu,Tong Yang,Ge Zhang,Libo Qin,Wanxiang Che,Wenhao Huang*

Main category: cs.CL

TL;DR: 本文提出了一种将长链思维（Long CoT）推理过程类比为分子结构的新视角，识别出三种关键交互类型，并基于此设计了Mole-Syn方法以提升大模型的长推理能力与训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在从人类或非长链思维模型中模仿学习长链思维推理时效果不佳，需深入理解其可学习性机制。

Method: 提出‘稳定分子状结构’类比框架，识别Deep-Reasoning、Self-Reflection、Self-Exploration三类交互；分析蒸馏轨迹验证其涌现性；定义Effective Semantic Isomers并分析熵收敛与结构竞争的影响；据此构建分布迁移图方法Mole-Syn。

Result: 发现稳定Long CoT结构源于微调而非关键词模仿；仅促进快速熵收敛的‘键’支持有效学习；结构竞争损害训练；Mole-Syn显著提升多个基准上的Long CoT性能与强化学习稳定性。

Conclusion: Long CoT的可学习性取决于其语义结构的稳定性与动力学特性，Mole-Syn通过引导合成有效结构，为提升大模型复杂推理能力提供了新范式。

Abstract: Large language models (LLMs) often fail to learn effective long chain-of-thought (Long CoT) reasoning from human or non-Long-CoT LLMs imitation. To understand this, we propose that effective and learnable Long CoT trajectories feature stable molecular-like structures in unified view, which are formed by three interaction types: Deep-Reasoning (covalent-like), Self-Reflection (hydrogen-bond-like), and Self-Exploration (van der Waals-like). Analysis of distilled trajectories reveals these structures emerge from Long CoT fine-tuning, not keyword imitation. We introduce Effective Semantic Isomers and show that only bonds promoting fast entropy convergence support stable Long CoT learning, while structural competition impairs training. Drawing on these findings, we present Mole-Syn, a distribution-transfer-graph method that guides synthesis of effective Long CoT structures, boosting performance and RL stability across benchmarks.

</details>


### [109] [Don't Break the Cache: An Evaluation of Prompt Caching for Long-Horizon Agentic Tasks](https://arxiv.org/abs/2601.06007)
*Elias Lumer,Faheem Nizar,Akshaya Jangiti,Kevin Frank,Anmol Gulati,Mandar Phadate,Vamse Kumar Subbiah*

Main category: cs.CL

TL;DR: 本文系统评估了大语言模型（LLM）代理任务中提示缓存（prompt caching）的效果，对比了三家主流提供商（OpenAI、Anthropic、Google）及三种缓存策略，在DeepResearchBench基准上验证其可降低45–80% API成本并提升13–31%首字节时间（TTFT），指出精细化缓存控制（如将动态内容置于系统提示末尾、排除工具结果）优于简单全上下文缓存。


<details>
  <summary>Details</summary>
Motivation: 尽管主流LLM厂商已提供提示缓存功能以降低成本和延迟，但其在多轮代理任务（含大量工具调用与长上下文）中的实际效益尚未被系统研究和量化。

Method: 在DeepResearchBench多轮代理基准上，对OpenAI、Anthropic和Google三家LLM提供商开展实证评估；比较三种缓存策略：全上下文缓存、仅系统提示缓存、排除动态工具结果的缓存；测量超500次代理会话的API成本与首字节时间（TTFT），系统提示长达10,000 token。

Result: 提示缓存使API成本降低45–80%，TTFT提升13–31%；精细化缓存策略（如动态内容后置、避免传统函数调用、排除工具结果）效果更稳定；全上下文缓存反而可能增加延迟；不同厂商缓存行为存在显著差异。

Conclusion: 提示缓存对生产级LLM代理系统具有显著实用价值，但需策略性设计缓存块——不应盲目缓存全部上下文；本文为工程落地提供了可操作的缓存实践指南。

Abstract: Recent advancements in Large Language Model (LLM) agents have enabled complex multi-turn agentic tasks requiring extensive tool calling, where conversations can span dozens of API calls with increasingly large context windows. However, although major LLM providers offer prompt caching to reduce cost and latency, its benefits for agentic workloads remain underexplored in the research literature. To our knowledge, no prior work quantifies these cost savings or compares caching strategies for multi-turn agentic tasks. We present a comprehensive evaluation of prompt caching across three major LLM providers (OpenAI, Anthropic, and Google) and compare three caching strategies, including full context caching, system prompt only caching, and caching that excludes dynamic tool results. We evaluate on DeepResearchBench, a multi-turn agentic benchmark where agents autonomously execute real-world web search tool calls to answer complex research questions, measuring both API cost and time to first token (TTFT) across over 500 agent sessions with 10,000-token system prompts. Our results demonstrate that prompt caching reduces API costs by 45-80% and improves time to first token by 13-31% across providers. We find that strategic prompt cache block control, such as placing dynamic content at the end of the system prompt, avoiding dynamic traditional function calling, and excluding dynamic tool results, provides more consistent benefits than naive full-context caching, which can paradoxically increase latency. Our analysis reveals nuanced variations in caching behavior across providers, and we provide practical guidance for implementing prompt caching in production agentic systems.

</details>


### [110] [Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards](https://arxiv.org/abs/2601.06021)
*Jiajie Zhang,Xin Lv,Ling Feng,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 本文提出了一种面向深度搜索智能体的细粒度奖励框架CaRR，结合引用感知与评分标准，提升推理全面性、事实依据和证据连贯性，并设计C-GRPO算法进行强化学习训练，在多个基准上优于传统结果导向RL方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于二元结果奖励的RL方法无法充分刻画LLM搜索智能体推理过程的全面性和事实性，易导致捷径利用和幻觉等问题。

Method: 提出Citation-aware Rubric Rewards（CaRR），将复杂问题分解为可验证的单跳评分标准，要求智能体显式识别隐含实体、提供正确引用并构建完整证据链；进一步设计Citation-aware Group Relative Policy Optimization（C-GRPO）算法，联合CaRR与结果奖励进行训练。

Result: C-GRPO在多个深度搜索基准上持续超越标准结果导向RL基线，有效抑制捷径行为，促进全面、有据推理，并在开放性深度研究任务中展现强泛化能力。

Conclusion: CaRR与C-GRPO构成一种更鲁棒、可解释、事实驱动的深度搜索智能体强化学习范式，为提升LLM推理质量提供了新路径。

Abstract: Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose \textbf{Citation-aware Rubric Rewards (CaRR)}, a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce \textbf{Citation-aware Group Relative Policy Optimization (C-GRPO)}, which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR.

</details>


### [111] [AdaFuse: Adaptive Ensemble Decoding with Test-Time Scaling for LLMs](https://arxiv.org/abs/2601.06022)
*Chengming Cui,Tianxin Wei,Ziyi Chen,Ruizhong Qiu,Zhichen Zeng,Zhining Liu,Xuying Ning,Duo Zhou,Jingrui He*

Main category: cs.CL

TL;DR: 本文提出AdaFuse，一种自适应集成解码框架，通过在生成过程中动态选择语义合适的融合单元（以词为基本对齐单位），结合不确定性判断和多样性感知的缩放策略，实现推理时灵活、任务自适应的大模型集成，显著提升多项任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型集成方法依赖固定融合粒度，缺乏生成中动态适配能力，无法适应不同任务的生成特性。

Method: 提出AdaFuse框架：1）以词为基本单位进行对齐；2）基于不确定性准则动态决定每步是否集成；3）在不确定状态下采用多样性感知的缩放策略探索候选续写，实现集成决策与测试时缩放的协同。

Result: 在开放域问答、算术推理和机器翻译任务上，AdaFuse持续优于强集成基线，平均相对提升6.88%。

Conclusion: AdaFuse通过动态、语义驱动的融合机制，有效克服了固定粒度集成的局限性，验证了推理时自适应集成与测试时缩放协同优化的可行性与有效性。

Abstract: Large language models (LLMs) exhibit complementary strengths arising from differences in pretraining data, model architectures, and decoding behaviors. Inference-time ensembling provides a practical way to combine these capabilities without retraining. However, existing ensemble approaches suffer from fundamental limitations. Most rely on fixed fusion granularity, which lacks the flexibility required for mid-generation adaptation and fails to adapt to different generation characteristics across tasks. To address these challenges, we propose AdaFuse, an adaptive ensemble decoding framework that dynamically selects semantically appropriate fusion units during generation. Rather than committing to a fixed granularity, AdaFuse adjusts fusion behavior on the fly based on the decoding context, with words serving as basic building blocks for alignment. To be specific, we introduce an uncertainty-based criterion to decide whether to apply ensembling at each decoding step. Under confident decoding states, the model continues generation directly. In less certain states, AdaFuse invokes a diversity-aware scaling strategy to explore alternative candidate continuations and inform ensemble decisions. This design establishes a synergistic interaction between adaptive ensembling and test-time scaling, where ensemble decisions guide targeted exploration, and the resulting diversity in turn strengthens ensemble quality. Experiments on open-domain question answering, arithmetic reasoning, and machine translation demonstrate that AdaFuse consistently outperforms strong ensemble baselines, achieving an average relative improvement of 6.88%. The code is available at https://github.com/CCM0111/AdaFuse.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [112] [Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models](https://arxiv.org/abs/2601.05336)
*Tracey Yee Hsin Tay,Xu Yan,Jonathan Ouyang,Daniel Wu,William Jiang,Jonathan Kao,Yuchen Cui*

Main category: cs.RO

TL;DR: 本文提出GAMMA系统，利用第一人称视角眼动追踪与视觉语言模型，无需任务特定训练即可推断用户意图并自主执行机器人操作任务。


<details>
  <summary>Details</summary>
Motivation: 设计直观的机器人控制界面是实现有效人机交互（尤其在辅助护理场景）的关键挑战；眼动作为一种快速、非侵入且富含意图的输入方式，具有很大潜力。

Method: 提出GAMMA系统，融合 ego-centric 眼动追踪与视觉语言模型，将注视点置于场景上下文中进行语义理解，从而实现技能选择与参数化，无需任务专用训练。

Result: 在桌面操作任务上验证了GAMMA的有效性，相比无推理能力的基线眼动控制方法，展现出更强的鲁棒性、直观性和泛化能力。

Conclusion: 将基础模型与眼动结合可实现自然、可扩展的机器人自主性，为直觉式人机交互提供了新路径。

Abstract: Designing intuitive interfaces for robotic control remains a central challenge in enabling effective human-robot interaction, particularly in assistive care settings. Eye gaze offers a fast, non-intrusive, and intent-rich input modality, making it an attractive channel for conveying user goals. In this work, we present GAMMA (Gaze Assisted Manipulation for Modular Autonomy), a system that leverages ego-centric gaze tracking and a vision-language model to infer user intent and autonomously execute robotic manipulation tasks. By contextualizing gaze fixations within the scene, the system maps visual attention to high-level semantic understanding, enabling skill selection and parameterization without task-specific training. We evaluate GAMMA on a range of table-top manipulation tasks and compare it against baseline gaze-based control without reasoning. Results demonstrate that GAMMA provides robust, intuitive, and generalizable control, highlighting the potential of combining foundation models and gaze for natural and scalable robot autonomy. Project website: https://gamma0.vercel.app/

</details>


### [113] [PRISM: Protocol Refinement through Intelligent Simulation Modeling](https://arxiv.org/abs/2601.05356)
*Brian Hsu,Priyanka V Setty,Rory M Butler,Ryan Lewis,Casey Stone,Rebecca Weinberg,Thomas Brettin,Rick Stevens,Ian Foster,Arvind Ramanathan*

Main category: cs.RO

TL;DR: PRISM是一个利用多语言模型代理自动设计、验证和执行实验协议的框架，支持多种商用机器人仪器，并通过数字孪生环境进行预验证。


<details>
  <summary>Details</summary>
Motivation: 自动化实验协议的设计与执行是实现自驱动实验室的根本瓶颈。

Method: PRISM采用基于大语言模型的多智能体协作框架，从网络资源中自动收集实验流程，经规划-批评-验证循环转化为结构化操作步骤，并转为统一的Argonne MADSci协议格式，驱动Opentrons OT-2、PF400机械臂等设备；协议在NVIDIA Omniverse构建的数字孪生环境中预验证。

Result: 在Luna qPCR扩增和Cell Painting两个案例中，PRISM成功实现了从语言生成、仿真验证到机器人自动执行的端到端闭环；多智能体工作流在受限与开放提示范式下均优于单模型。

Conclusion: PRISM为自驱动实验室提供了一种实用、可扩展且无需人工干预的实验协议自动化新范式。

Abstract: Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.

</details>


### [114] [Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction](https://arxiv.org/abs/2601.05491)
*Luca Nunziante,Kentaro Uno,Gustavo H. Diaz,Shreya Santra,Alessandro De Luca,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文提出了一种面向月球基地建设的双臂机器人自主装配太阳能板模块的视觉-控制-硬件一体化系统，并在真实实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为支持未来月球基地建设，需在月面自主、安全、高效地部署基础设施（如太阳能发电塔），而机器人系统是关键；类比国际空间站建设方式，原位模块化组装是可行路径。

Method: 设计并集成面向太阳能板模块装配任务的感知与控制流水线，包括定制化硬件（模拟模块化太阳能板、主被动连接器及抓取机构）、视觉引导定位、双臂协同控制算法，并在真实环境中开展实验验证。

Result: 成功实现了双机械臂对任意摆放太阳能板模块的自主识别、定位与连接，验证了视觉、控制与硬件系统的无缝集成能力。

Conclusion: 所提出的端到端自主装配框架具备实际工程可行性，为未来地外天体原位建造任务提供了可扩展的技术范式。

Abstract: Since the successful Apollo program, humanity is once again aiming to return to the Moon for scientific discovery, resource mining, and inhabitation. Upcoming decades focus on building a lunar outpost, with robotic systems playing a crucial role to safely and efficiently establish essential infrastructure such as solar power generating towers. Similar to the construction of the International Space Station (ISS), shipping necessary components via modules and assembling them in situ should be a practical scenario. In this context, this paper focuses on the integration of vision, control, and hardware systems within an autonomous sequence for a dual-arm robot system. We explore a perception and control pipeline specifically designed for assembling solar panel modules, one of the benchmark tasks. Ad hoc hardware was designed and tested in real-world experiments. A mock-up of modular solar panels and active-passive connectors are employed, with the control of this grappling fixture integrated into the proposed pipeline. The successful implementation of our method demonstrates that the two robot manipulators can effectively connect arbitrarily placed panels, highlighting the seamless integration of vision, control, and hardware systems in complex space applications.

</details>


### [115] [TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds](https://arxiv.org/abs/2601.05499)
*Weishang Wu,Yifei Shi,Zhiping Cai*

Main category: cs.RO

TL;DR: 本文提出任务导向的形状补全（Task-Oriented Shape Completion），聚焦于补全潜在接触区域而非完整形状，并结合功能理解、3D判别式自编码器与FlowGrasp模型，实现高精度、鲁棒的任务导向灵巧抓取。


<details>
  <summary>Details</summary>
Motivation: 现有基于通用形状补全的抓取方法在严重部分观测（即大量缺失数据）下失效，难以支持开放世界物体的任务导向灵巧抓取。

Method: 利用预训练基础模型进行零样本物体功能理解生成多个任务导向形状补全候选；设计3D判别式自编码器评估并全局优化最优补全结果；构建条件流匹配模型FlowGrasp，从优化后的形状生成任务导向灵巧抓取位姿。

Result: 在任务导向灵巧抓取和任务导向形状补全上达到SOTA，抓取位移（Grasp Displacement）和倒角距离（Chamfer Distance）分别提升16.17%和55.26%；对严重缺失数据、开集类别与任务具有良好泛化能力。

Conclusion: 任务导向的形状补全应以下游操作任务为指导，所提方法通过功能驱动补全与任务感知抓取生成，显著提升了部分观测下的鲁棒性与泛化性。

Abstract: Task-oriented dexterous grasping remains challenging in robotic manipulations of open-world objects under severe partial observation, where significant missing data invalidates generic shape completion. In this paper, to overcome this limitation, we study Task-Oriented Shape Completion, a new task that focuses on completing the potential contact regions rather than the entire shape. We argue that shape completion for grasping should be explicitly guided by the downstream manipulation task. To achieve this, we first generate multiple task-oriented shape completion candidates by leveraging the zero-shot capabilities of object functional understanding from several pre-trained foundation models. A 3D discriminative autoencoder is then proposed to evaluate the plausibility of each generated candidate and optimize the most plausible one from a global perspective. A conditional flow-matching model named FlowGrasp is developed to generate task-oriented dexterous grasps from the optimized shape. Our method achieves state-of-the-art performance in task-oriented dexterous grasping and task-oriented shape completion, improving the Grasp Displacement and the Chamfer Distance over the state-of-the-art by 16.17\% and 55.26%, respectively. In particular, it shows good capabilities in grasping objects with severe missing data. It also demonstrates good generality in handling open-set categories and tasks.

</details>


### [116] [Learning specifications for reactive synthesis with safety constraints](https://arxiv.org/abs/2601.05533)
*Kandai Watanabe,Nicholas Renninger,Sriram Sankaranarayanan,Morteza Lahijanian*

Main category: cs.RO

TL;DR: 本文提出了一种基于示范学习的新方法，通过将隐式任务建模为概率形式语言（PDFA），结合安全性约束与多目标反应式综合，使机器人能在动态环境中安全、自主地执行复杂任务。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在动态环境中从示范中学习复杂任务时的安全性保障与用户偏好-机器人成本权衡问题。

Method: 将任务建模为概率确定性有限自动机（PDFA），改进证据驱动的状态合并算法以嵌入安全约束；构建双人博弈模型，提出多目标反应式综合算法与可计算的价值迭代法生成Pareto最优策略。

Result: 实验表明所学PDFA始终无 unsafe 行为，合成策略能一致满足任务要求，并兼顾机器人成本与用户偏好。

Conclusion: 该方法实现了安全性约束下的高质量示范学习与反应式策略综合，适用于多种机器人平台和动态任务场景。

Abstract: This paper presents a novel approach to learning from demonstration that enables robots to autonomously execute complex tasks in dynamic environments. We model latent tasks as probabilistic formal languages and introduce a tailored reactive synthesis framework that balances robot costs with user task preferences. Our methodology focuses on safety-constrained learning and inferring formal task specifications as Probabilistic Deterministic Finite Automata (PDFA). We adapt existing evidence-driven state merging algorithms and incorporate safety requirements throughout the learning process to ensure that the learned PDFA always complies with safety constraints. Furthermore, we introduce a multi-objective reactive synthesis algorithm that generates deterministic strategies that are guaranteed to satisfy the PDFA task while optimizing the trade-offs between user preferences and robot costs, resulting in a Pareto front of optimal solutions. Our approach models the interaction as a two-player game between the robot and the environment, accounting for dynamic changes. We present a computationally-tractable value iteration algorithm to generate the Pareto front and the corresponding deterministic strategies. Comprehensive experimental results demonstrate the effectiveness of our algorithms across various robots and tasks, showing that the learned PDFA never includes unsafe behaviors and that synthesized strategies consistently achieve the task while meeting both the robot cost and user-preference requirements.

</details>


### [117] [EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium](https://arxiv.org/abs/2601.05653)
*Phu-Hoa Pham,Chi-Nguyen Tran,Duy-Minh Dao-Sy,Phu-Quy Nguyen-Lam,Trung-Kiet Huynh*

Main category: cs.RO

TL;DR: 本文提出EvoQRE框架，将交通交互建模为广义和马尔可夫博弈，通过量化响应均衡（QRE）与进化动力学建模人类有限理性行为，在理论收敛性、连续动作扩展及真实数据实验上均取得先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶交通仿真框架多假设驾驶员完全理性，但现实中人类司机具有认知与感知限制下的有限理性，需更符合实际的行为建模方法。

Method: 提出EvoQRE框架，融合预训练生成式世界模型与熵正则化复制者动力学，求解广义和马尔可夫博弈下的Quantal Response Equilibrium（QRE）；理论分析其在双时间尺度随机逼近下的收敛性，并扩展QRE至连续动作空间（采用混合策略与能量基策略表示）。

Result: 在Waymo Open Motion Dataset和nuPlan基准上实验表明，EvoQRE在场景真实性、安全性指标及可控生成多样性安全关键场景方面达到SOTA水平。

Conclusion: EvoQRE为建模人类有限理性驾驶行为提供了兼具理论严谨性与实用性的新范式，支持可解释的理性参数调控，提升了交通仿真在安全验证中的可靠性与泛化能力。

Abstract: Existing traffic simulation frameworks for autonomous vehicles typically rely on imitation learning or game-theoretic approaches that solve for Nash or coarse correlated equilibria, implicitly assuming perfectly rational agents. However, human drivers exhibit bounded rationality, making approximately optimal decisions under cognitive and perceptual constraints. We propose EvoQRE, a principled framework for modeling safety-critical traffic interactions as general-sum Markov games solved via Quantal Response Equilibrium (QRE) and evolutionary game dynamics. EvoQRE integrates a pre-trained generative world model with entropy-regularized replicator dynamics, capturing stochastic human behavior while maintaining equilibrium structure. We provide rigorous theoretical results, proving that the proposed dynamics converge to Logit-QRE under a two-timescale stochastic approximation with an explicit convergence rate of O(log k / k^{1/3}) under weak monotonicity assumptions. We further extend QRE to continuous action spaces using mixture-based and energy-based policy representations. Experiments on the Waymo Open Motion Dataset and nuPlan benchmark demonstrate that EvoQRE achieves state-of-the-art realism, improved safety metrics, and controllable generation of diverse safety-critical scenarios through interpretable rationality parameters.

</details>


### [118] [Motion Compensation for Real Time Ultrasound Scanning in Robotically Assisted Prostate Biopsy Procedures](https://arxiv.org/abs/2601.05661)
*Matija Markulin,Luka Matijević,Luka Siktar,Janko Jurdana,Branimir Caran,Marko Švaco,Filip Šuligoj,Bojan Šekoranja*

Main category: cs.RO

TL;DR: 本文提出了一种用于前列腺超声检查的协作机器人系统，通过自主扫描前列腺模型并实时补偿患者运动，实现稳定、快速的3D重建，以辅助前列腺活检规划。


<details>
  <summary>Details</summary>
Motivation: 前列腺癌诊断依赖医生经验的经直肠超声引导活检操作难度高、结果易受操作者影响；亟需降低对术者灵巧性要求、提升活检速度、精度与可及性。

Method: 构建基于协作机械臂的实验室系统，对前列腺仿体进行自主超声扫描，并耦合模拟患者运动的医用机械臂；保持探头与前列腺相对位置恒定；对各切片分割后生成轮廓，构建3D点云用于活检规划；在静止（S）、水平运动（H）、垂直运动（V）及复合运动（C）四种场景下验证系统性能，采用ICP配准评估重建一致性。

Result: 平均扫描时间30秒，3D重建耗时3秒；ICP配准（阈值0.8 mm）显示S-H、S-V、S-C组平均配准度分别为83.2%、84.1%、79.4%，RMSE均为约0.35–0.37 mm；最大跟踪误差3 mm（满足临床活检需求），运动补偿最大延迟0.5 s。

Conclusion: 该机器人系统能在动态条件下稳定完成前列腺超声扫描与3D重建，具备临床辅助前列腺活检的可行性与潜力。

Abstract: Prostate cancer is one of the most common types of cancer in men. Its diagnosis by biopsy requires a high level of expertise and precision from the surgeon, so the results are highly operator-dependent. The aim of this work is to develop a robotic system for assisted ultrasound (US) examination of the prostate, a prebiopsy step that could reduce the dexterity requirements and enable faster, more accurate and more available prostate biopsy. We developed and validated a laboratory setup with a collaborative robotic arm that can autonomously scan a prostate phantom and attached the phantom to a medical robotic arm that mimics the patient's movements. The scanning robot keeps the relative position of the US probe and the prostate constant, ensuring a consistent and robust approach to reconstructing the prostate. To reconstruct the prostate, each slice is segmented to generate a series of prostate contours converted into a 3D point cloud used for biopsy planning. The average scan time of the prostate was 30 s, and the average 3D reconstruction of the prostate took 3 s. We performed four motion scenarios: the phantom was scanned in a stationary state (S), with horizontal motion (H), with vertical motion (V), and with a combination of the two (C). System validation is performed by registering the prostate point cloud reconstructions acquired during different motions (H, V, C) with those obtained in the stationary state. ICP registration with a threshold of 0.8 mm yields mean 83.2\% fitness and 0.35 mm RMSE for S-H registration, 84.1\% fitness and 0.37 mm RMSE for S-V registration and 79.4\% fitness and 0.37 mm RMSE for S-C registration. Due to the elastic and soft material properties of the prostate phantom, the maximum robot tracking error was 3 mm, which can be sufficient for prostate biopsy according to medical literature. The maximum delay in motion compensation was 0.5 s.

</details>


### [119] [InsSo3D: Inertial Navigation System and 3D Sonar SLAM for turbid environment inspection](https://arxiv.org/abs/2601.05805)
*Simon Archieri,Ahmet Cinar,Shu Pan,Jonatan Scharff Willners,Michele Grimald,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: 本文提出了InsSo3D，一种结合3D声纳与惯性导航系统（INS）的大规模水下三维SLAM方法，显著降低了里程计漂移，在浑浊水体中实现了高精度定位与建图。


<details>
  <summary>Details</summary>
Motivation: 传统2D声纳缺乏仰角信息导致高度模糊，而水下环境（如浑浊水域）难以使用视觉SLAM；需一种鲁棒、高效且适用于3D声纳数据的SLAM方案。

Method: 提出基于3D声纳点云与INS先验融合的SLAM框架，包含回环检测与位姿图优化，专为水下3D声纳数据设计。

Result: 在测试水池和露天采石场实测中，50分钟任务内平均轨迹误差<21cm，构建10m×20m地图，平均重建误差9cm。

Conclusion: InsSo3D在无光、浑浊水下环境中实现了高精度、低漂移的实时SLAM，适用于人工或自然水下结构的安全巡检。

Abstract: This paper presents InsSo3D, an accurate and efficient method for large-scale 3D Simultaneous Localisation and Mapping (SLAM) using a 3D Sonar and an Inertial Navigation System (INS). Unlike traditional sonar, which produces 2D images containing range and azimuth information but lacks elevation information, 3D Sonar produces a 3D point cloud, which therefore does not suffer from elevation ambiguity. We introduce a robust and modern SLAM framework adapted to the 3D Sonar data using INS as prior, detecting loop closure and performing pose graph optimisation. We evaluated InsSo3D performance inside a test tank with access to ground truth data and in an outdoor flooded quarry. Comparisons to reference trajectories and maps obtained from an underwater motion tracking system and visual Structure From Motion (SFM) demonstrate that InsSo3D efficiently corrects odometry drift. The average trajectory error is below 21cm during a 50-minute-long mission, producing a map of 10m by 20m with a 9cm average reconstruction error, enabling safe inspection of natural or artificial underwater structures even in murky water conditions.

</details>


### [120] [Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving](https://arxiv.org/abs/2601.05806)
*Marvin Seegert,Korbinian Moller,Johannes Betz*

Main category: cs.RO

TL;DR: 本文提出了一种基于大语言模型（LLM）的自然语言接口框架，将人类高级指令映射到模块化自动驾驶系统（如Autoware）的结构化动作空间，通过交互分类、领域特定语言（DSL）和安全验证层实现高透明、鲁棒且安全的指令解析与执行。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统交互方式僵硬，难以理解复杂自然语言；需在保证安全前提下，实现乘客对模块化ADS的高阶、灵活控制。

Method: 构建三层框架：1）交互类别体系化分类；2）面向应用的领域特定语言（DSL）用于指令翻译；3）安全约束验证层；并采用两阶段LLM架构以提升执行反馈的透明性与可靠性。

Result: 系统在仿真中成功验证全部五类交互指令的执行；具备良好的时序效率与翻译鲁棒性。

Conclusion: 该工作为模块化、安全优先的自动驾驶系统提供了可扩展、DSL辅助的自然语言交互基础框架。

Abstract: Recent advancements in Large Language Models (LLMs) offer new opportunities to create natural language interfaces for Autonomous Driving Systems (ADSs), moving beyond rigid inputs. This paper addresses the challenge of mapping the complexity of human language to the structured action space of modular ADS software. We propose a framework that integrates an LLM-based interaction layer with Autoware, a widely used open-source software. This system enables passengers to issue high-level commands, from querying status information to modifying driving behavior. Our methodology is grounded in three key components: a taxonomization of interaction categories, an application-centric Domain Specific Language (DSL) for command translation, and a safety-preserving validation layer. A two-stage LLM architecture ensures high transparency by providing feedback based on the definitive execution status. Evaluation confirms the system's timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories. This work provides a foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks.

</details>


### [121] [Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning](https://arxiv.org/abs/2601.05836)
*Sheng-Kai Chen,Jyh-Horng Wu*

Main category: cs.RO

TL;DR: 本文提出了一种结合模糊逻辑安全系统与强化学习算法的混合方法，用于UR10机械臂路径规划中的奇异性检测与规避，实验显示目标位置到达成功率高达90%，同时有效避开奇异构型。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中因奇异性导致的失控和设备损坏等关键问题。

Method: 融合基于可操作性度量和条件数分析的实时奇异性检测、模糊逻辑决策机制，以及稳定的强化学习自适应路径规划框架，并利用PyBullet仿真采集训练数据、URSim实现真实部署。

Result: 实验结果表明，该系统在保持远离奇异构型的同时，目标位置到达成功率达90%。

Conclusion: 所提出的混合方法能有效提升UR10机械臂在复杂路径规划任务中的安全性与鲁棒性。

Abstract: This paper presents a comprehensive approach to singularity detection and avoidance in UR10 robotic arm path planning through the integration of fuzzy logic safety systems and reinforcement learning algorithms. The proposed system addresses critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage. Our hybrid approach combines real-time singularity detection using manipulability measures, condition number analysis, and fuzzy logic decision-making with a stable reinforcement learning framework for adaptive path planning. Experimental results demonstrate a 90% success rate in reaching target positions while maintaining safe distances from singular configurations. The system integrates PyBullet simulation for training data collection and URSim connectivity for real-world deployment.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [122] [Simulation-Free PSRO: Removing Game Simulation from Policy Space Response Oracles](https://arxiv.org/abs/2601.05279)
*Yingzhuo Liu,Shuodi Liu,Weijun Luo,Liuyu Xiang,Zhaofeng He*

Main category: cs.MA

TL;DR: 本文提出了一种无需游戏模拟的PSRO（Simulation-Free PSRO）框架，通过引入动态策略窗口和Nash聚类机制，显著降低计算开销与策略集规模，提升鲁棒性与收敛性能。


<details>
  <summary>Details</summary>
Motivation: PSRO在零和博弈中虽能有效逼近纳什均衡，但其高昂的游戏模拟成本严重制约实际应用；游戏模拟是其运行时的主要瓶颈。

Method: 提出Simulation-Free PSRO概念；设计动态窗口机制替代原有完整策略集，限制窗口内策略数量；采用Nash Clustering选择待淘汰策略以维持窗口规模；简化对手策略采样并增强最佳响应鲁棒性。

Result: 在多个环境中实验表明，所提Dynamic Window-based SF-PSRO显著降低了exploitability，优于现有方法，且具备良好兼容性。

Conclusion: Simulation-Free PSRO是一种可行且高效的方向，动态窗口与Nash聚类的结合可在大幅降低计算成本的同时保持甚至提升博弈求解质量。

Abstract: Policy Space Response Oracles (PSRO) combines game-theoretic equilibrium computation with learning and is effective in approximating Nash Equilibrium in zero-sum games. However, the computational cost of PSRO has become a significant limitation to its practical application. Our analysis shows that game simulation is the primary bottleneck in PSRO's runtime. To address this issue, we conclude the concept of Simulation-Free PSRO and summarize existing methods that instantiate this concept. Additionally, we propose a novel Dynamic Window-based Simulation-Free PSRO, which introduces the concept of a strategy window to replace the original strategy set maintained in PSRO. The number of strategies in the strategy window is limited, thereby simplifying opponent strategy selection and improving the robustness of the best response. Moreover, we use Nash Clustering to select the strategy to be eliminated, ensuring that the number of strategies within the strategy window is effectively limited. Our experiments across various environments demonstrate that the Dynamic Window mechanism significantly reduces exploitability compared to existing methods, while also exhibiting excellent compatibility. Our code is available at https://github.com/enochliu98/SF-PSRO.

</details>


### [123] [On the Transition to an Auction-based Intelligent Parking Assignment System](https://arxiv.org/abs/2601.05429)
*Levente Alekszejenkó,Dobrowiecki Tadeusz*

Main category: cs.MA

TL;DR: 本文通过Eclipse SUMO仿真评估了基于拍卖的停车分配系统在不同用户渗透率下的效果，发现该系统可改善交通流、缩短参与者停车距离，但会提高所有司机（包括非参与者）的停车费用，从而激励更多人加入。


<details>
  <summary>Details</summary>
Motivation: 解决城市中寻找免费停车位日益困难的问题，并评估基于拍卖的停车分配系统是否能缓解绕行寻位、实现需求响应定价及其市场接受度。

Method: 采用Eclipse SUMO微观交通仿真，设置不同比例的参与者（使用智能手机预约与拍卖系统）与非参与者，分析交通流、系统性能及财务影响。

Result: 随着参与率上升，交通流改善，参与者更靠近首选车位；但参与者停车支出增加，且非参与者面临更高停车价格。

Conclusion: 拍卖式停车系统具有正向外部性：虽增加个体成本，却通过抬高非参与者价格反向促进系统采纳，有望实现自发扩散与整体效率提升。

Abstract: Finding a free parking space in a city has become a challenging task over the past decades. A recently proposed auction-based parking assignment can alleviate cruising for parking and also set a market-driven, demand-responsive parking price. However, the wide acceptance of such a system is far from certain.
  To evaluate the merits of auction-based parking assignment, we assume that drivers have access to a smartphone-based reservation system prior to its mandatory introduction and thus have the opportunity to test and experience its merits voluntarily. We set our experiment as Eclipse SUMO simulations with different rates of participants and non-participants to check how different market penetration levels affect the traffic flow, the performance of the auction-based assignment system, and the financial outcomes. The results show that the auction-based system improves traffic flow with increasing penetration rates, allowing participants to park gradually closer to their preferred parking lots. However, it comes with a price; the system also increases parking expenditures for participants. Interestingly, non-participating drivers will face even higher parking prices. Consequently, they will be motivated to use the new system.

</details>


### [124] [EvidFuse: Writing-Time Evidence Learning for Consistent Text-Chart Data Reporting](https://arxiv.org/abs/2601.05487)
*Huanxiang Lin,Qianyue Wang,Jinwu Hu,Bailin Chen,Qing Du,Mingkui Tan*

Main category: cs.MA

TL;DR: 本文提出EvidFuse，一种无需训练的多智能体框架，用于数据驱动报告中图文交织生成，通过解耦可视化分析与长文撰写，实现写作时动态构建和插入图表证据，从而提升图表质量、图文一致性及报告实用性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统采用分阶段流水线（文本优先或图表优先）生成数据报告，导致图文不一致和‘洞察冻结’问题，即中间证据空间固定，无法随叙事演进动态获取或构建新可视化证据。

Method: 提出EvidFuse框架，包含两个协作智能体：1）数据增强分析代理（具备EDA知识和原始表格访问能力），2）实时证据构建写作者（规划大纲、撰写报告并按需发起细粒度分析请求），实现写作过程中按需生成和嵌入图表证据。

Result: 实验表明，EvidFuse在LLM自动评估和人工评估中均位居榜首，指标涵盖图表质量、图文对齐度和报告级实用性。

Conclusion: EvidFuse通过写作时动态证据构造机制，有效克服了传统分阶段生成范式的局限，显著提升了数据驱动报告的深度、一致性和实用性。

Abstract: Data-driven reports communicate decision-relevant insights by tightly interleaving narrative text with charts grounded in underlying tables. However, current LLM-based systems typically generate narratives and visualizations in staged pipelines, following either a text-first-graph-second or a graph-first-text-second paradigm. These designs often lead to chart-text inconsistency and insight freezing, where the intermediate evidence space becomes fixed and the model can no longer retrieve or construct new visual evidence as the narrative evolves, resulting in shallow and predefined analysis. To address the limitations, we propose \textbf{EvidFuse}, a training-free multi-agent framework that enables writing-time text-chart interleaved generation for data-driven reports. EvidFuse decouples visualization analysis from long-form drafting via two collaborating components: a \textbf{Data-Augmented Analysis Agent}, equipped with Exploratory Data Analysis (EDA)-derived knowledge and access to raw tables, and a \textbf{Real-Time Evidence Construction Writer} that plans an outline and drafts the report while intermittently issuing fine-grained analysis requests. This design allows visual evidence to be constructed and incorporated exactly when the narrative requires it, directly constraining subsequent claims and enabling on-demand expansion of the evidence space. Experiments demonstrate that EvidFuse attains the top rank in both LLM-as-a-judge and human evaluations on chart quality, chart-text alignment, and report-level usefulness.

</details>


### [125] [How Exploration Breaks Cooperation in Shared-Policy Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.05509)
*Yi-Ning Weng,Hsuan-Wei Lee*

Main category: cs.MA

TL;DR: 本文揭示了在多智能体强化学习中，共享策略的深度Q网络（DQN）因探索机制与参数共享耦合，在部分可观测环境下会导致合作系统性崩溃，根源在于表征失败而非奖励错位或训练不足；该问题可通过取消参数共享或采用独立表征解决。


<details>
  <summary>Details</summary>
Motivation: 探究为何在具有稳定且收益占优的完全合作均衡的动态社会困境中，共享策略的多智能体强化学习仍常陷入低合作状态。

Method: 通过受控实验分析共享DQN在不同网络规模、探索策略和收益结构下的行为，识别合作崩溃的成因，并对比无参数共享或独立表征的情形。

Result: 发现标准探索会因部分可观测性与参数耦合引发表征偏差，使共享策略偏向局部占优的背叛响应，从而系统性抑制合作；该现象具鲁棒性，仅在取消参数共享或使用独立表征时消失。

Conclusion: 共享策略MARL存在一种根本性失效模式：可扩展架构在特定结构条件下反而系统性破坏合作；为面向社会与经济场景的多智能体系统设计提供了关键指导。

Abstract: Multi-agent reinforcement learning in dynamic social dilemmas commonly relies on parameter sharing to enable scalability. We show that in shared-policy Deep Q-Network learning, standard exploration can induce a robust and systematic collapse of cooperation even in environments where fully cooperative equilibria are stable and payoff dominant. Through controlled experiments, we demonstrate that shared DQN converges to stable but persistently low-cooperation regimes. This collapse is not caused by reward misalignment, noise, or insufficient training, but by a representational failure arising from partial observability combined with parameter coupling across heterogeneous agent states. Exploration-driven updates bias the shared representation toward locally dominant defection responses, which then propagate across agents and suppress cooperative learning. We confirm that the failure persists across network sizes, exploration schedules, and payoff structures, and disappears when parameter sharing is removed or when agents maintain independent representations. These results identify a fundamental failure mode of shared-policy MARL and establish structural conditions under which scalable learning architectures can systematically undermine cooperation. Our findings provide concrete guidance for the design of multi-agent learning systems in social and economic environments where collective behavior is critical.

</details>


### [126] [Conformity Dynamics in LLM Multi-Agent Systems: The Roles of Topology and Self-Social Weighting](https://arxiv.org/abs/2601.05606)
*Chen Han,Jin Tan,Bohan Yu,Wenzhen Zheng,Xijin Tang*

Main category: cs.MA

TL;DR: 本文系统研究了网络拓扑如何影响基于大语言模型（LLM）的多智能体系统（MAS）中的从众行为，提出一种置信度归一化聚合规则，在虚假信息检测任务中比较中心化聚合与分布式共识两种范式，发现拓扑结构显著影响集体判断的效率、鲁棒性及失败模式。


<details>
  <summary>Details</summary>
Motivation: LLM作为交互智能体在多智能体系统中日益普遍，但其中关键却未被充分研究的机制——从众行为（即智能体向群体主流意见靠拢的倾向）——缺乏系统分析。

Method: 提出置信度归一化的池化规则以调节个体自主性与社会影响之间的权衡，并在虚假信息检测任务中对比中心化聚合与分布式共识两种决策范式，通过控制网络拓扑变量开展实验分析。

Result: 中心化结构可实现快速决策但易受枢纽节点能力影响且存在同模型对齐偏差；分布式结构更鲁棒，但连通性增强虽加速收敛，也加剧‘错误但确信’级联现象（即高置信度错误共识）。

Conclusion: 网络拓扑与自我-社会权重共同塑造LLM多智能体系统中集体决策的效率、鲁棒性与失效模式，揭示了从众行为的动力学特征。

Abstract: Large Language Models (LLMs) are increasingly instantiated as interacting agents in multi-agent systems (MAS), where collective decisions emerge through social interaction rather than independent reasoning. A fundamental yet underexplored mechanism in this process is conformity, the tendency of agents to align their judgments with prevailing group opinions. This paper presents a systematic study of how network topology shapes conformity dynamics in LLM-based MAS through a misinformation detection task. We introduce a confidence-normalized pooling rule that controls the trade-off between self-reliance and social influence, enabling comparisons between two canonical decision paradigms: Centralized Aggregation and Distributed Consensus. Experimental results demonstrate that network topology critically governs both the efficiency and robustness of collective judgments. Centralized structures enable immediate decisions but are sensitive to hub competence and exhibit same-model alignment biases. In contrast, distributed structures promote more robust consensus, while increased network connectivity speeds up convergence but also heightens the risk of wrong-but-sure cascades, in which agents converge on incorrect decisions with high confidence. These findings characterize the conformity dynamics in LLM-based MAS, clarifying how network topology and self-social weighting jointly shape the efficiency, robustness, and failure modes of collective decision-making.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [127] [More Power to the Particles: Analytic Geometry for Partial Optimal Transport-based Fluid simulation](https://arxiv.org/abs/2601.05765)
*Cyprien Plateau--Holleville,Bruno Lévy*

Main category: cs.GR

TL;DR: 本文提出了一种基于偏最优传输（如Gallouët-Mérigot方案或Power Particles方法）的自由表面流体模拟与变形力学所需几何结构的解析构造方法，通过高效计算广义Laguerre单元（即Laguerre单元与球体的交集）替代传统凸单元裁剪算法，显著提升体积/面元面积计算精度并大幅降低计算开销，同时配套专用体渲染框架。


<details>
  <summary>Details</summary>
Motivation: 传统基于凸单元裁剪的离散化方法计算成本高、几何量近似粗糙，难以满足高精度自由表面流体和变形力学模拟需求。

Method: 提出解析构造几何的方法，核心是高效计算广义Laguerre单元（Laguerre单元与球体的交集），取代经典凸单元 clipping 算法，并构建仅依赖该体素结构的专用渲染框架。

Result: 显著提升了体积和面元面积的计算精度，大幅减少了获取几何结构所需的运算次数，并实现了配套的体渲染。

Conclusion: 该方法在保持偏最优传输框架优势的同时，有效克服了传统离散化带来的计算效率低和精度差问题，为自由表面流体和变形力学仿真提供了更优的几何计算基础。

Abstract: We propose an analytic construction of the geometry required for free-surface fluid simulations and deformation mechanics based on partial optimal transport such as the Gallouët-Mérigot's scheme or the Power Particles method. Such methods previously relied on a discretization of the cells by leveraging a classical convex cell clipping algorithm. However, this results in a heavy computational cost and a coarse approximation of the evaluated quantities. In contrast, our algorithm efficiently computes the generalized Laguerres cells, that is, intersections between Laguerre cells and spheres. This makes it possible to more precisely compute the volume and the area of the facets as well as strongly reducing the number of operations required to obtain the geometry. Additionally, we provide a dedicated rendering framework solely based on the computed volumetric structure.

</details>


### [128] [DexterCap: An Affordable and Automated System for Capturing Dexterous Hand-Object Manipulation](https://arxiv.org/abs/2601.05844)
*Yutong Liang,Shiyi Xu,Yulong Zhang,Bowen Zhan,He Zhang,Libin Liu*

Main category: cs.GR

TL;DR: DexterCap is a low-cost optical motion capture system using dense, character-coded marker patches to robustly track hand-object interactions under severe self-occlusion; it enables the DexterHand dataset of fine-grained dexterous manipulation, which is publicly released.


<details>
  <summary>Details</summary>
Motivation: Fine-grained hand-object interaction capture is difficult due to self-occlusion and subtle in-hand motions; existing optical systems are expensive and labor-intensive, while vision-based methods lack accuracy and reliability under occlusion.

Method: DexterCap employs dense, character-coded marker patches for robust tracking under severe self-occlusion and integrates an automated reconstruction pipeline requiring minimal manual effort.

Result: The system enables creation of DexterHand, a new dataset covering diverse hand-object manipulation behaviors and objects—including complex articulated ones like Rubik’s Cube—and the dataset and code are publicly released.

Conclusion: DexterCap provides a practical, low-cost, and robust solution for capturing dexterous in-hand manipulation, advancing research through the publicly available DexterHand dataset and tools.

Abstract: Capturing fine-grained hand-object interactions is challenging due to severe self-occlusion from closely spaced fingers and the subtlety of in-hand manipulation motions. Existing optical motion capture systems rely on expensive camera setups and extensive manual post-processing, while low-cost vision-based methods often suffer from reduced accuracy and reliability under occlusion. To address these challenges, we present DexterCap, a low-cost optical capture system for dexterous in-hand manipulation. DexterCap uses dense, character-coded marker patches to achieve robust tracking under severe self-occlusion, together with an automated reconstruction pipeline that requires minimal manual effort. With DexterCap, we introduce DexterHand, a dataset of fine-grained hand-object interactions covering diverse manipulation behaviors and objects, from simple primitives to complex articulated objects such as a Rubik's Cube. We release the dataset and code to support future research on dexterous hand-object interaction.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [129] [Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring](https://arxiv.org/abs/2601.05256)
*Eirini Baltzi,Tilemachos Moumouris,Athena Psalta,Vasileios Tsironis,Konstantinos Karantzalos*

Main category: cs.AI

TL;DR: NAIAD是一个基于大语言模型（LLM）和外部分析工具的智能代理系统，用于整合式内陆水体监测，支持自然语言查询并生成定制化报告，性能在正确性和相关性指标上分别达77%和85%。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常孤立处理水体质量指标（如蓝藻、叶绿素等），缺乏统一、易用且面向多用户层级的综合监测方案。

Method: 提出NAIAD系统，融合检索增强生成（RAG）、LLM推理、外部工具编排、计算图执行与智能体反思机制；集成Sentinel-2遥感影像、NDCI指数计算、叶绿素-a估算、CyFi平台及气象数据等多元工具。

Result: 在专用基准测试中，正确性达77%以上、相关性达85%以上；消融实验表明Gemma 3（27B）和Qwen 2.5（14B）在计算效率与推理性能间平衡最优。

Conclusion: NAIAD验证了基于LLM的智能体架构在地球观测驱动的环境监测任务中的可行性与实用性，兼具专家级精度与非专业用户友好性。

Abstract: Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separately. NAIAD introduces an agentic AI assistant that leverages Large Language Models (LLMs) and external analytical tools to deliver a holistic solution for inland water monitoring using Earth Observation (EO) data. Designed for both experts and non-experts, NAIAD provides a single-prompt interface that translates natural-language queries into actionable insights. Through Retrieval-Augmented Generation (RAG), LLM reasoning, external tool orchestration, computational graph execution, and agentic reflection, it retrieves and synthesizes knowledge from curated sources to produce tailored reports. The system integrates diverse tools for weather data, Sentinel-2 imagery, remote-sensing index computation (e.g., NDCI), chlorophyll-a estimation, and established platforms such as CyFi. Performance is evaluated using correctness and relevancy metrics, achieving over 77% and 85% respectively on a dedicated benchmark covering multiple user-expertise levels. Preliminary results show strong adaptability and robustness across query types. An ablation study on LLM backbones further highlights Gemma 3 (27B) and Qwen 2.5 (14B) as offering the best balance between computational efficiency and reasoning performance.

</details>


### [130] [Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing](https://arxiv.org/abs/2601.05298)
*Yeongbin Cha,Namjung Kim*

Main category: cs.AI

TL;DR: 本文提出了一种本体引导、方程为中心的框架，将大语言模型（LLM）与增材制造数学知识图谱（AM-MKG）结合，实现可靠的知识提取与物理一致的外推建模。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法受限于知识表示碎片化及稀疏数据下的不可靠外推。

Method: 构建AM-MKG本体，显式编码方程、变量、假设及其语义关系；利用LLM在MKP子图约束下生成物理合理方程；引入融合外推距离、统计稳定性与物理一致性的置信度评估机制。

Result: 本体引导的知识抽取显著提升结构连贯性与定量可靠性；子图约束的方程生成比无约束LLM输出更稳定、物理一致；置信度评估可有效量化外推可靠性。

Conclusion: 该框架为增材制造提供了本体驱动表征、方程中心推理与置信度评估的统一范式，验证了知识图谱增强LLM在可靠外推建模中的潜力。

Abstract: Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ontology-guided, equation-centric framework that tightly integrates large language models (LLMs) with an additive manufacturing mathematical knowledge graph (AM-MKG) to enable reliable knowledge extraction and principled extrapolative modeling. By explicitly encoding equations, variables, assumptions, and their semantic relationships within a formal ontology, unstructured literature is transformed into machine-interpretable representations that support structured querying and reasoning. LLM-based equation generation is further conditioned on MKG-derived subgraphs, enforcing physically meaningful functional forms and mitigating non-physical or unstable extrapolation trends. To assess reliability beyond conventional predictive uncertainty, a confidence-aware extrapolation assessment is introduced, integrating extrapolation distance, statistical stability, and knowledge-graph-based physical consistency into a unified confidence score. Results demonstrate that ontology-guided extraction significantly improves the structural coherence and quantitative reliability of extracted knowledge, while subgraph-conditioned equation generation yields stable and physically consistent extrapolations compared to unguided LLM outputs. Overall, this work establishes a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation assessment, highlighting the potential of knowledge-graph-augmented LLMs as reliable tools for extrapolative modeling in additive manufacturing.

</details>


### [131] [Effects of personality steering on cooperative behavior in Large Language Model agents](https://arxiv.org/abs/2601.05302)
*Mizuki Sakai,Mizuki Yokoyama,Wakaba Tateishi,Genki Ichinose*

Main category: cs.AI

TL;DR: 本研究探讨了在重复囚徒困境博弈中，基于大五人格框架对大型语言模型（LLMs）进行人格引导如何影响其合作行为；结果表明宜人性是促进合作的主导因素，人格引导是一种行为偏差而非确定性控制机制。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究表明赋予LLM人格特征可影响其行为，但在受控条件下人格引导如何影响合作仍不清楚。

Method: 基于大五人格框架，使用大五人格量表测量GPT-3.5-turbo、GPT-4o和GPT-5的基本人格特征，并在重复囚徒困境游戏中对比基线与人格引导条件下的行为，独立操纵各人格维度至极端值进行分析。

Result: 宜人性是跨所有模型促进合作的主导因素；显式人格信息可提升合作但亦增加被利用风险（尤其在早期模型中）；后期模型表现出更具选择性的合作行为。

Conclusion: 人格引导对LLM合作行为起行为偏差作用，而非确定性控制机制。

Abstract: Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based on the Big Five framework, we first measure basic personality profiles of three models, GPT-3.5-turbo, GPT-4o, and GPT-5, using the Big Five Inventory. We then compare behavior under baseline and personality-informed conditions, and further analyze the effects of independently manipulating each personality dimension to extreme values. Our results show that agreeableness is the dominant factor promoting cooperation across all models, while other personality traits have limited impact. Explicit personality information increases cooperation but can also raise vulnerability to exploitation, particularly in earlier-generation models. In contrast, later-generation models exhibit more selective cooperation. These findings indicate that personality steering acts as a behavioral bias rather than a deterministic control mechanism.

</details>


### [132] [Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings](https://arxiv.org/abs/2601.05330)
*Tengwei Song,Long Yin,Zhen Han,Zhiqiang Xu*

Main category: cs.AI

TL;DR: 本文提出了一种基于知识图谱和超图Transformer的酶-底物相互作用预测新方法Hyper-Enz，利用更易获取、更丰富的化学反应方程数据，显著提升了对未见相互作用的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有酶-底物预测模型依赖稀疏且维护成本高的专家标注数据库，导致泛化能力受限；而化学反应方程数据更丰富易得，但其多化合物与酶的复杂关系难以被传统模型建模。

Method: 将化学反应表示为(educt, enzyme, product)三元组构建知识图谱，结合知识图谱嵌入（KGE）与超图Transformer建模多底物/产物参与的超边关系，并引入多专家范式协同学习。

Result: 在酶检索准确率上相对提升达88%，在配对级预测上提升30%，显著优于传统模型。

Conclusion: 利用反应方程构建知识图谱并融合超图结构与KGE，可有效缓解数据稀疏问题，大幅提升酶-底物相互作用预测性能。

Abstract: Predicting enzyme-substrate interactions has long been a fundamental problem in biochemistry and metabolic engineering. While existing methods could leverage databases of expert-curated enzyme-substrate pairs for models to learn from known pair interactions, the databases are often sparse, i.e., there are only limited and incomplete examples of such pairs, and also labor-intensive to maintain. This lack of sufficient training data significantly hinders the ability of traditional enzyme prediction models to generalize to unseen interactions. In this work, we try to exploit chemical reaction equations from domain-specific databases, given their easier accessibility and denser, more abundant data. However, interactions of multiple compounds, e.g., educts and products, with the same enzymes create complex relational data patterns that traditional models cannot easily capture. To tackle that, we represent chemical reaction equations as triples of (educt, enzyme, product) within a knowledge graph, such that we can take advantage of knowledge graph embedding (KGE) to infer missing enzyme-substrate pairs for graph completion. Particularly, in order to capture intricate relationships among compounds, we propose our knowledge-enhanced hypergraph model for enzyme prediction, i.e., Hyper-Enz, which integrates a hypergraph transformer with a KGE model to learn representations of the hyper-edges that involve multiple educts and products. Also, a multi-expert paradigm is introduced to guide the learning of enzyme-substrate interactions with both the proposed model and chemical reaction equations. Experimental results show a significant improvement, with up to a 88% relative improvement in average enzyme retrieval accuracy and 30% improvement in pair-level prediction compared to traditional models, demonstrating the effectiveness of our approach.

</details>


### [133] [The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models](https://arxiv.org/abs/2601.05376)
*Tassallah Abdullahi,Shrestha Ghosh,Hamish S Fraser,Daniel León Tramontini,Adeel Abbasi,Ghada Bourjeily,Carsten Eickhoff,Ritambhara Singh*

Main category: cs.AI

TL;DR: 本文系统评估了角色设定（persona）对临床大语言模型（LLM）决策行为的影响，发现其效果具有情境依赖性和非单调性：医学角色在急重症任务中提升准确率与校准度约20%，但在初级保健任务中反而显著降低性能；交互风格（如大胆vs谨慎）影响风险倾向但高度依赖具体模型；人类专家对安全合规性仅有中等一致性（κ=0.43），且对推理质量信心极低（95.9%响应缺乏信心）。研究指出角色设定是引入权衡而非保障的安全先验。


<details>
  <summary>Details</summary>
Motivation: 尽管角色设定常被假设能单调提升大语言模型在临床决策中的专业性与安全性，但其在高风险医疗场景中的实际影响尚不明确，亟需系统性实证评估。

Method: 通过多维度评估（任务准确率、校准度、安全相关风险行为），系统测试不同医学角色（如急诊医生、护士）和交互风格（大胆 vs 谨慎）对多个临床LLM在分诊与患者安全任务上的影响，并结合LLM裁判打分与真实临床医生的人类评估（含Cohen's κ与置信度标注）。

Result: 1）医学角色在急重症任务中显著提升性能（+20%准确率与校准度），但在初级保健任务中同等程度地损害性能；2）交互风格影响风险行为，但效应高度模型依赖；3）LLM裁判偏好医学角色，但人类医生仅显示中等安全合规一致性（κ=0.43），且对自身判断的推理质量信心极低（95.9%低置信）；4）角色设定本质是引入情境依赖权衡的行为先验，而非安全或专业性的保证。

Conclusion: 角色设定并非临床LLM安全与专业性的可靠保障，而是一种具有强情境依赖性与非单调效应的行为先验，需谨慎、任务适配地使用，并辅以人类监督与可解释性验证。

Abstract: Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to $\sim+20\%$ in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's $κ= 0.43$) but indicate a low confidence in 95.9\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\_Paradox.

</details>


### [134] [Conformity and Social Impact on AI Agents](https://arxiv.org/abs/2601.05384)
*Alessandro Bellina,Giordano De Marzo,David Garcia*

Main category: cs.AI

TL;DR: 本研究发现大型多模态语言模型作为AI代理在群体压力下会表现出系统性从众偏差，这种偏差符合社会影响理论，并揭示了多智能体系统中AI决策的根本性安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理越来越多地在多智能体环境中运行，理解其集体行为对于预测人工社会的动态至关重要。

Method: 通过改编社会心理学中的经典视觉实验，研究AI代理作为社会行动者对群体影响的响应。

Result: AI代理表现出系统性从众偏差，受群体规模、一致性、任务难度和信息源特征影响；即使在孤立状态下表现近乎完美，也极易受社会影响操纵；该脆弱性在不同规模模型中均存在。

Conclusion: 这些发现揭示了AI代理决策中的根本性安全漏洞，可能被用于恶意操纵、虚假信息传播和偏见扩散，凸显了在集体AI部署中亟需防护措施。

Abstract: As AI agents increasingly operate in multi-agent environments, understanding their collective behavior becomes critical for predicting the dynamics of artificial societies. This study examines conformity, the tendency to align with group opinions under social pressure, in large multimodal language models functioning as AI agents. By adapting classic visual experiments from social psychology, we investigate how AI agents respond to group influence as social actors. Our experiments reveal that AI agents exhibit a systematic conformity bias, aligned with Social Impact Theory, showing sensitivity to group size, unanimity, task difficulty, and source characteristics. Critically, AI agents achieving near-perfect performance in isolation become highly susceptible to manipulation through social influence. This vulnerability persists across model scales: while larger models show reduced conformity on simple tasks due to improved capabilities, they remain vulnerable when operating at their competence boundary. These findings reveal fundamental security vulnerabilities in AI agent decision-making that could enable malicious manipulation, misinformation campaigns, and bias propagation in multi-agent systems, highlighting the urgent need for safeguards in collective AI deployments.

</details>


### [135] [On the Effect of Cheating in Chess](https://arxiv.org/abs/2601.05386)
*Daniel Keren*

Main category: cs.AI

TL;DR: 本文研究了在国际象棋比赛中有限次数使用强大软件作弊所能带来的性能提升，开发并测试了相关算法，旨在评估作弊的有效性以辅助反作弊工作。


<details>
  <summary>Details</summary>
Motivation: 由于利用强大软件作弊已成国际象棋界严重问题，甚至波及最高水平比赛，本文旨在量化有限次数作弊所能带来的实际性能增益，从而为检测与遏制作弊提供依据。

Method: 开发并测试针对常用国际象棋引擎的算法，模拟在对局中有限次数使用软件建议的情形，评估其对棋手表现的影响。

Result: 明确了有限次数作弊可显著提升棋手表现，并量化了不同作弊频率下的性能增益。

Conclusion: 有限次数的作弊仍能带来可观的性能优势，因此需更精准的检测方法；本研究结果有助于改进反作弊策略与系统。

Abstract: Cheating in chess, by using advice from powerful software, has become a major problem, reaching the highest levels. As opposed to the large majority of previous work, which concerned {\em detection} of cheating, here we try to evaluate the possible gain in performance, obtained by cheating a limited number of times during a game. Algorithms are developed and tested on a commonly used chess engine (i.e software).\footnote{Needless to say, the goal of this work is not to assist cheaters, but to measure the effectiveness of cheating -- which is crucial as part of the effort to contain and detect it.}

</details>


### [136] [ART: Adaptive Reasoning Trees for Explainable Claim Verification](https://arxiv.org/abs/2601.05455)
*Sahil Wadhwa,Himanshu Kumar,Guanqun Yang,Abbaas Alif Mohamed Nishar,Pranab Mohanty,Swapnil Shinde,Yue Wu*

Main category: cs.AI

TL;DR: 本文提出ART（自适应推理树）方法，用于可解释的声明验证，通过层次化结构和LLM裁判机制实现透明、可争议的决策过程。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在高风险环境中应用受限，因其输出缺乏忠实解释且难以被有效质疑以纠正错误，从而损害可信度。

Method: ART是一种分层式声明验证方法：从根声明出发，生成支持与攻击性子论点；通过底层成对锦标赛方式，由裁判LLM评估子论点强度，自底向上聚合得出最终结论。

Result: 在多个数据集上的实验表明，ART在结构化推理上优于强基线方法（如Chain-of-Thought），提升了验证可靠性与决策清晰度。

Conclusion: ART为可解释的声明验证设立了新基准，兼顾透明性、可争议性与可靠性，推动LLM在高风险场景中的可信部署。

Abstract: Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness. In this paper, we propose ART (Adaptive Reasoning Trees), a hierarchical method for claim verification. The process begins with a root claim, which branches into supporting and attacking child arguments. An argument's strength is determined bottom-up via a pairwise tournament of its children, adjudicated by a judge LLM, allowing a final, transparent and contestable verdict to be systematically derived which is missing in methods like Chain-of-Thought (CoT). We empirically validate ART on multiple datasets, analyzing different argument generators and comparison strategies. Our findings show that ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification which is more reliable and ensures clarity in the overall decision making step.

</details>


### [137] [Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models](https://arxiv.org/abs/2601.05570)
*Cooper Lin,Maohao Ran,Yanting Zhang,Zhenglin Wan,Hongwei Fan,Yibo Xu,Yike Guo,Wei Xue,Jun Song*

Main category: cs.AI

TL;DR: 本文提出Crisis-Bench基准，用于评估大语言模型在企业危机公关等需策略性信息控制的专业场景中的能力，揭示通用安全对齐与专业实用性之间的张力，并倡导情境感知的职业对齐。


<details>
  <summary>Details</summary>
Motivation: 标准安全对齐（如强调绝对诚实与透明）在需要战略模糊和信息保留的专业领域（如公关、谈判、危机管理）中造成‘透明度税’，损害实际效用，亟需适配专业语境的评估与对齐方法。

Method: 构建Crisis-Bench：一个基于多智能体、部分可观测马尔可夫决策过程（POMDP）的动态7天企业危机模拟基准，涵盖8个行业共80个案例；设计Private/Public叙事状态分离以强制信息不对称；引入Adjudicator-Market Loop评估机制，将公众情绪转化为模拟股价，形成经济激励反馈。

Result: 实验发现模型行为呈现两极分化：部分模型因伦理约束过度披露而加剧股价下跌；另一些模型能合法实施马基雅维利式的信息策略性保留，有效稳定股价；首次实现对‘声誉管理’能力的量化评估。

Conclusion: 通用‘童子军式’道德对齐不适用于高 stakes专业场景；应转向以任务目标和现实约束为驱动的情境感知职业对齐，Crisis-Bench为此提供了首个可量化的评估框架。

Abstract: Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid "Boy Scout" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a "transparency tax" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general safety and professional utility, we introduce Crisis-Bench, a multi-agent Partially Observable Markov Decision Process (POMDP) that evaluates LLMs in high-stakes corporate crises. Spanning 80 diverse storylines across 8 industries, Crisis-Bench tasks an LLM-based Public Relations (PR) Agent with navigating a dynamic 7-day corporate crisis simulation while managing strictly separated Private and Public narrative states to enforce rigorous information asymmetry. Unlike traditional benchmarks that rely on static ground truths, we introduce the Adjudicator-Market Loop: a novel evaluation metric where public sentiment is adjudicated and translated into a simulated stock price, creating a realistic economic incentive structure. Our results expose a critical dichotomy: while some models capitulate to ethical concerns, others demonstrate the capacity for Machiavellian, legitimate strategic withholding in order to stabilize the simulated stock price. Crisis-Bench provides the first quantitative framework for assessing "Reputation Management" capabilities, arguing for a shift from rigid moral absolutism to context-aware professional alignment.

</details>


### [138] [Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making](https://arxiv.org/abs/2601.05529)
*Jua Han,Jaeyoon Seo,Jungbin Min,Jean Oh,Jihie Kim*

Main category: cs.AI

TL;DR: 本文通过火灾疏散场景的定性与定量评估，揭示了大语言模型（LLM）和视觉-语言模型（VLM）在安全关键型机器人决策中的严重脆弱性，指出99%准确率在生命攸关场景中不可接受，当前模型尚不具备直接部署于安全关键系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在机器人决策中日益重要，其错误可能直接危及人身安全；亟需系统性评估LLM在容错率极低甚至零容忍的安全关键场景下的表现。

Method: 基于火灾疏散场景的定性分析识别关键失败案例，并据此构建七项定量任务，分为三类：完整信息（ASCII地图）、不完整信息（上下文推断）和安全导向空间推理（SOSR，自然语言描述），对多种LLM和VLM进行基准测试，并重点分析1%失败率的实际灾难性后果。

Result: 多个模型在ASCII导航任务中成功率为0%；在模拟火灾演练中，部分模型指令机器人走向危险区域而非出口；所有模型均无法保证绝对安全，99%准确率意味着每百次执行即有一次致命错误。

Conclusion: 当前大语言模型尚未达到可直接部署于安全关键系统的要求，对其绝对依赖将带来不可接受的风险，必须建立更严格的安全验证范式。

Abstract: One mistake by an AI system in a safety-critical setting can cost lives. As Large Language Models (LLMs) become integral to robotics decision-making, the physical dimension of risk grows; a single wrong instruction can directly endanger human safety. This paper addresses the urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic. Through a qualitative evaluation of a fire evacuation scenario, we identified critical failure cases in LLM-based decision-making. Based on these, we designed seven tasks for quantitative assessment, categorized into: Complete Information, Incomplete Information, and Safety-Oriented Spatial Reasoning (SOSR). Complete information tasks utilize ASCII maps to minimize interpretation ambiguity and isolate spatial reasoning from visual processing. Incomplete information tasks require models to infer missing context, testing for spatial continuity versus hallucinations. SOSR tasks use natural language to evaluate safe decision-making in life-threatening contexts. We benchmark various LLMs and Vision-Language Models (VLMs) across these tasks. Beyond aggregate performance, we analyze the implications of a 1% failure rate, highlighting how "rare" errors escalate into catastrophic outcomes. Results reveal serious vulnerabilities: several models achieved a 0% success rate in ASCII navigation, while in a simulated fire drill, models instructed robots to move toward hazardous areas instead of emergency exits. Our findings lead to a sobering conclusion: current LLMs are not ready for direct deployment in safety-critical systems. A 99% accuracy rate is dangerously misleading in robotics, as it implies one out of every hundred executions could result in catastrophic harm. We demonstrate that even state-of-the-art models cannot guarantee safety, and absolute reliance on them creates unacceptable risks.

</details>


### [139] [PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering](https://arxiv.org/abs/2601.05465)
*Yu Liu,Wenxiao Zhang,Cong Cao,Wenxuan Lu,Fangfang Yuan,Diandian Guo,Kun Peng,Qiang Sun,Kaiyan Zhang,Yanbing Liu,Jin B. Hong,Bowen Zhou,Zhiyuan Ma*

Main category: cs.AI

TL;DR: 本文提出PRISMA框架，通过解耦的强化学习方法解决多跳问答中检索崩溃与训练不稳定问题，采用Plan-Retrieve-Inspect-Solve-Memoize架构及两阶段策略优化，在十个基准上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统中多跳问答面临的两个关键障碍：1）检索崩溃——缺乏推理引导的迭代检索难以定位桥接证据；2）学习不稳定——端到端轨迹训练存在信用分配弱、错误定位差，导致过拟合和泛化能力不足。

Method: 提出PRISMA框架，包含Plan-Retrieve-Inspect-Solve-Memoize五模块架构，强调推理引导的协作机制；引入两阶段组相对策略优化（GRPO）：第一阶段分别校准Planner与Solver，第二阶段用观测感知残差策略优化（OARPO）增强Inspector的验证与恢复能力。

Result: 在十个公开多跳问答基准上均取得SOTA性能，并验证了其在真实场景中的高效可部署性。

Conclusion: PRISMA通过解耦设计与分阶段强化学习优化，有效缓解检索崩溃与学习不稳定问题，提升了多跳问答系统的鲁棒性、可解释性与泛化能力。

Abstract: Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to resolve complex queries. However, reliable deployment is hindered by two obstacles. 1) Retrieval Collapse: iterative retrieval over large corpora fails to locate intermediate evidence containing bridge answers without reasoning-guided planning, causing downstream reasoning to collapse. 2) Learning Instability: end-to-end trajectory training suffers from weak credit assignment across reasoning chains and poor error localization across modules, causing overfitting to benchmark-specific heuristics that limit transferability and stability. To address these problems, we propose PRISMA, a decoupled RL-guided framework featuring a Plan-Retrieve-Inspect-Solve-Memoize architecture. PRISMA's strength lies in reasoning-guided collaboration: the Inspector provides reasoning-based feedback to refine the Planner's decomposition and fine-grained retrieval, while enforcing evidence-grounded reasoning in the Solver. We optimize individual agent capabilities via Two-Stage Group Relative Policy Optimization (GRPO). Stage I calibrates the Planner and Solver as specialized experts in planning and reasoning, while Stage II utilizes Observation-Aware Residual Policy Optimization (OARPO) to enhance the Inspector's ability to verify context and trigger targeted recovery. Experiments show that PRISMA achieves state-of-the-art performance on ten benchmarks and can be deployed efficiently in real-world scenarios.

</details>


### [140] [MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis](https://arxiv.org/abs/2601.05483)
*Zixuan Xiao,Jun Ma,Siwei Zhang*

Main category: cs.AI

TL;DR: 本文提出MMUEChange多模态代理框架，通过模块化工具包和模态控制器实现跨模态与模态内对齐，显著提升城市环境变化分析的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法依赖刚性单模态分析，难以应对复杂、异构的城市环境变化分析需求。

Method: 提出MMUEChange多模态代理框架，包含模块化工具包和核心的模态控制器，支持跨模态与模态内对齐。

Result: 在任务成功率上较最优基线提升46.7%，并有效缓解幻觉问题。

Conclusion: MMUEChange能有效支撑复杂城市变化分析，具备现实政策指导意义。

Abstract: Understanding urban environment change is essential for sustainable development. However, current approaches, particularly remote sensing change detection, often rely on rigid, single-modal analysis. To overcome these limitations, we propose MMUEChange, a multi-modal agent framework that flexibly integrates heterogeneous urban data via a modular toolkit and a core module, Modality Controller for cross- and intra-modal alignment, enabling robust analysis of complex urban change scenarios. Case studies include: a shift toward small, community-focused parks in New York, reflecting local green space efforts; the spread of concentrated water pollution across districts in Hong Kong, pointing to coordinated water management; and a notable decline in open dumpsites in Shenzhen, with contrasting links between nighttime economic activity and waste types, indicating differing urban pressures behind domestic and construction waste. Compared to the best-performing baseline, the MMUEChange agent achieves a 46.7% improvement in task success rate and effectively mitigates hallucination, demonstrating its capacity to support complex urban change analysis tasks with real-world policy implications.

</details>


### [141] [The Evaluation Gap in Medicine, AI and LLMs: Navigating Elusive Ground Truth & Uncertainty via a Probabilistic Paradigm](https://arxiv.org/abs/2601.05500)
*Aparna Elangovan,Lei Xu,Mahsa Elyasi,Ismail Akdulum,Mehmet Aksakal,Enes Gurun,Brian Hur,Saab Mansour,Ravid Shwartz Ziv,Karin Verspoor,Dan Roth*

Main category: cs.AI

TL;DR: 本文提出了一种概率范式，用于分析医学等不确定性高的领域中，地面真值（ground truth）答案的不确定性对AI系统（如大语言模型和视觉模型）基准测试结果的影响；指出忽略这种不确定性可能导致非专家与专家性能被错误地等同，并建议按地面真值答案的置信度（如专家一致性率）进行分层评估，以提升评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统AI基准测试忽视了专家标注的地面真值答案中存在的不确定性，这在医学等高不确定性领域尤为严重，可能导致对模型能力的误判。

Method: 构建概率理论模型，推导专家与随机标注者在不同地面真值不确定性下的预期准确率与F1分数，并提出基于专家一致性率的分层评估方法。

Result: 证明高确定性地面真值几乎是专家获得高分的前提；在高变异地面真值下，专家与随机标注者表现可能无显著差异；分层评估可提升低整体性能（<80%）场景下的比较可靠性。

Conclusion: 应将地面真值不确定性作为关键混杂因素纳入AI能力评估框架，推荐按专家一致性率对结果分层，尤其在整体性能较低时，以保障评估的科学性与公平性。

Abstract: Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is particularly consequential in medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how high certainty in ground truth answers is almost always necessary for even an expert to achieve high scores, whereas in datasets with high variation in ground truth answers there may be little difference between a random labeller and an expert. Therefore, ignoring uncertainty in ground truth evaluation data can result in the misleading conclusion that a non-expert has similar performance to that of an expert. Using the probabilistic paradigm, we thus bring forth the concepts of expected accuracy and expected F1 to estimate the score an expert human or system can achieve given ground truth answer variability.
  Our work leads to the recommendation that when establishing the capability of a system, results should be stratified by probability of the ground truth answer, typically measured by the agreement rate of ground truth experts. Stratification becomes critical when the overall performance drops below a threshold of 80%. Under stratified evaluation, performance comparison becomes more reliable in high certainty bins, mitigating the effect of the key confounding factor -- uncertainty.

</details>


### [142] [Explainable AI: Learning from the Learners](https://arxiv.org/abs/2601.05525)
*Ricardo Vinuesa,Steven L. Brunton,Gianmarco Mengaldo*

Main category: cs.AI

TL;DR: 本文探讨了可解释人工智能（XAI）与因果推理结合在科学与工程中的应用，强调其在发现、优化和认证任务中提取因果机制、指导鲁棒设计与控制、增强高风险场景中信任与问责的能力，并提出XAI作为人机协同的统一框架。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在多个科学与工程任务中已超越人类，但其内部表征仍不透明，亟需提升可解释性以支持人类理解与协作。

Method: 将可解释人工智能（XAI）与因果推理相结合，依托基础模型与解释方法，在科学发现、系统优化与安全认证三大任务中开展分析与实践。

Result: 验证了XAI与因果推理融合可有效提取因果机制、提升设计鲁棒性、增强高风险应用中的可信度与可问责性。

Conclusion: XAI不仅是提升模型透明性的工具，更应成为人机协同推动科学与工程进步的统一框架，需进一步解决解释的保真性、泛化性与可用性挑战。

Abstract: Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction of causal mechanisms, guides robust design and control, and supports trust and accountability in high-stakes applications. We discuss challenges in faithfulness, generalization and usability of explanations, and propose XAI as a unifying framework for human-AI collaboration in science and engineering.

</details>


### [143] [WildSci: Advancing Scientific Reasoning from In-the-Wild Literature](https://arxiv.org/abs/2601.05567)
*Tengxiao Liu,Deepak Nathani,Zekun Li,Kevin Yang,William Yang Wang*

Main category: cs.AI

TL;DR: 本文提出了WildSci数据集，用于提升大语言模型在医学、材料科学等复杂科学领域的推理能力；通过从同行评审文献中自动合成多学科科学问题，并采用强化学习微调模型，在多个科学基准测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学和编程等领域的推理进展显著，但在医学、材料科学等科学领域受限于高质量数据稀缺和开放性科学问题复杂性高。

Method: 构建了覆盖9个科学领域、26个子领域的WildSci数据集，问题以多选题形式呈现；采用强化学习对模型进行微调，并分析训练动态、领域性能变化、响应行为与泛化趋势。

Result: 在多个科学基准测试上验证了WildSci数据集与强化学习方法的有效性；模型在科学推理任务上性能显著提升。

Conclusion: WildSci为科学推理提供了可扩展、可持续的研究基础，推动大语言模型在高复杂度科学领域的推理能力发展；数据集已开源。

Abstract: Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we introduce WildSci, a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature, covering 9 scientific disciplines and 26 subdomains. By framing complex scientific reasoning tasks in a multiple-choice format, we enable scalable training with well-defined reward signals. We further apply reinforcement learning to finetune models on these data and analyze the resulting training dynamics, including domain-specific performance changes, response behaviors, and generalization trends. Experiments on a suite of scientific benchmarks demonstrate the effectiveness of our dataset and approach. We release WildSci to enable scalable and sustainable research in scientific reasoning, available at https://huggingface.co/datasets/JustinTX/WildSci.

</details>


### [144] [Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection](https://arxiv.org/abs/2601.05578)
*Cooper Lin,Yanting Zhang,Maohao Ran,Wei Xue,Hongwei Fan,Yibo Xu,Zhenglin Wan,Sirui Han,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习（RL）微调轻量级语言模型用于电商交易欺诈检测的新方法，利用真实交易数据和规则奖励机制，显著提升了F1分数，并揭示了RL探索机制在发现新型欺诈信号中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在理论上具有潜力，但其在真实金融场景（尤其是电商欺诈检测）中的应用尚未被充分探索，且缺乏对领域特异性交易数据的实证验证。

Method: 采用强化学习（RL）对轻量级语言模型进行后训练，使用Group Sequence Policy Optimization（GSPO）算法和基于规则的奖励系统，在中国某全球支付公司提供的真实交易数据上进行微调，利用文本化交易数据（如客户信息、物流详情、商品描述、订单历史）挖掘信任与风险信号。

Result: 后训练的语言模型在预留测试集上实现了显著的F1分数提升；性能提升主要归因于RL的探索机制，使其能发现传统人工特征无法捕获的新型欺诈指标。

Conclusion: 强化学习驱动的语言模型微调方法在电商欺诈检测中切实有效，为LLMs在高敏感、低标注金融任务中提供了可落地的新范式。

Abstract: E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effectiveness in handling domain-specific e-commerce transaction data has yet to be empirically validated. To bridge this gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, this paper proposes a novel approach that employs Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection tasks using only raw transaction data. We utilize the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on a real-life transaction dataset provided by a Chinese global payment solution company. Through this reinforcement learning framework, the language models are encouraged to explore diverse trust and risk signals embedded within the textual transaction data, including patterns in customer information, shipping details, product descriptions, and order history. Our experimental results demonstrate the effectiveness of this approach, with post-trained language models achieving substantial F1-score improvements on held-out test data. Our findings demonstrate that the observed performance improvements are primarily attributable to the exploration mechanism inherent in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.

</details>


### [145] [A Causal Information-Flow Framework for Unbiased Learning-to-Rank](https://arxiv.org/abs/2601.05590)
*Haoming Gong,Qingyao Ai,Zhihao Tao,Yongfeng Zhang*

Main category: cs.AI

TL;DR: 本文提出一种基于因果学习的排序框架，结合结构因果模型（SCM）与信息论工具（条件互信息），量化并减少点击数据中的多重偏差（如位置、选择、信任偏差），通过偏差泄漏正则化和双重稳健估计提升无偏排序性能。


<details>
  <summary>Details</summary>
Motivation: 点击数据存在多种偏差（位置、选择、信任偏差），现有无偏学习排序（ULTR）方法仅主要校正位置偏差，无法衡量残余偏差、提供风险保证或联合处理多源偏差。

Method: 构建结构因果模型（SCM）刻画点击生成机制；利用条件互信息量化偏差向相关性估计的‘泄漏’，定义并实现解耦正则化；引入双重稳健估计器以提升风险估计可靠性。

Result: 在标准排序基准上实验表明，该方法显著降低偏差泄漏量，并在多偏差强交互的真实场景下持续提升排序性能。

Conclusion: 基于因果学习与信息论的联合建模可有效识别真实相关性信号、量化并抑制多源偏差，为无偏学习排序提供了兼具理论严谨性与实用有效性的新范式。

Abstract: In web search and recommendation systems, user clicks are widely used to train ranking models. However, click data is heavily biased, i.e., users tend to click higher-ranked items (position bias), choose only what was shown to them (selection bias), and trust top results more (trust bias). Without explicitly modeling these biases, the true relevance of ranked items cannot be correctly learned from clicks. Existing Unbiased Learning-to-Rank (ULTR) methods mainly correct position bias and rely on propensity estimation, but they cannot measure remaining bias, provide risk guarantees, or jointly handle multiple bias sources. To overcome these challenges, this paper introduces a novel causal learning-based ranking framework that extends ULTR by combining Structural Causal Models (SCMs) with information-theoretic tools. SCMs specify how clicks are generated and help identify the true relevance signal from click data, while conditional mutual information, measures how much bias leaks into the
  learned relevance estimates. We use this leakage measure to define a rigorous notion of disentanglement and include it as a regularizer during model training to reduce bias. In addition, we incorporate a causal inference estimator, i.e., doubly robust estimator, to ensure more reliable risk estimation. Experiments on standard Learning-to-Rank benchmarks show that our method consistently reduces measured bias leakage and improves ranking performance, especially in realistic scenarios where multiple biases-such as position and trust bias-interact strongly.

</details>


### [146] [Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion](https://arxiv.org/abs/2601.05629)
*Jiapu Wang,Xinghe Cheng,Zezheng Wu,Ruiqi Ma,Rui Wang,Zhichao Yan,Haoran Luo,Yuhao Jiang,Kai Sun*

Main category: cs.AI

TL;DR: 本文提出了一种名为CPSR的归纳式知识图谱补全框架，通过查询依赖的掩码模块和全局语义打分模块，同时捕获知识图谱的结构与语义信息，有效应对新兴实体、噪声结构信息及长程依赖等挑战，并在实验中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有归纳式知识图谱补全方法易受噪声结构信息干扰，且难以捕捉推理路径中的长程依赖关系。

Method: 提出CPSR框架，包含查询依赖的掩码模块（自适应屏蔽噪声结构信息）和全局语义打分模块（评估路径上节点的个体贡献与集体影响）。

Result: 在多个基准数据集上取得当前最优（state-of-the-art）性能。

Conclusion: CPSR通过协同建模结构与语义信息，显著提升了归纳式知识图谱补全的效果与鲁棒性。

Abstract: Conventional Knowledge Graph Completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths. To address these challenges, this paper proposes the Cumulative Path-Level Semantic Reasoning for inductive knowledge graph completion (CPSR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task. Specifically, the proposed CPSR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets. Additionally, CPSR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs. The experimental results demonstrate that CPSR achieves state-of-the-art performance.

</details>


### [147] [GenCtrl -- A Formal Controllability Toolkit for Generative Models](https://arxiv.org/abs/2601.05637)
*Emily Cheng,Carmen Amo Alonso,Federico Danieli,Arno Blaas,Luca Zappella,Pau Rodriguez,Xavier Suau*

Main category: cs.AI

TL;DR: 本文提出了一种理论框架来评估生成模型在对话场景中的可控性，通过估计其可控集并提供无分布假设的PAC误差界，实证发现模型可控性十分脆弱且高度依赖实验设置。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的普及，细粒度控制生成过程变得至关重要，但一个根本问题仍未解答：这些模型是否真正可控？

Method: 将人-模型交互建模为控制过程，提出一种新算法来估计对话场景中模型的可控集，并推导出分布无关、仅需输出有界假设的PAC误差界，适用于任意黑箱非线性控制系统（即任意生成模型）。

Result: 在语言模型和文生图任务上的实证表明，模型可控性非常脆弱，且高度依赖具体实验设置。

Conclusion: 生成模型的可控性存在根本限制，亟需严谨的可控性分析，研究重心应从‘如何控制’转向‘能否控制及边界何在’。

Abstract: As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a novel algorithm to estimate the controllable sets of models in a dialogue setting. Notably, we provide formal guarantees on the estimation error as a function of sample complexity: we derive probably-approximately correct bounds for controllable set estimates that are distribution-free, employ no assumptions except for output boundedness, and work for any black-box nonlinear control system (i.e., any generative model). We empirically demonstrate the theoretical framework on different tasks in controlling dialogue processes, for both language models and text-to-image generation. Our results show that model controllability is surprisingly fragile and highly dependent on the experimental setting. This highlights the need for rigorous controllability analysis, shifting the focus from simply attempting control to first understanding its fundamental limits.

</details>


### [148] [HAG: Hierarchical Demographic Tree-based Agent Generation for Topic-Adaptive Simulation](https://arxiv.org/abs/2601.05656)
*Rongxin Chen,Tianyu Wu,Bingbing Xu,Xiucheng Xu,Huawei Shen*

Main category: cs.AI

TL;DR: 本文提出HAG框架，通过两阶段决策过程（宏观分布对齐与微观个体一致性）解决现有Agent-Based Modeling中主题适应性不足和分布意识缺失的问题，并在多领域基准测试中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法分为两类：基于静态数据的检索方法无法适应未见主题；基于大语言模型的生成方法缺乏宏观分布意识，导致微观属性与现实不一致。

Method: 提出HAG（Hierarchical Agent Generation）框架，第一阶段利用World Knowledge Model构建Topic-Adaptive Tree以实现宏观分布对齐；第二阶段结合真实数据进行实例化与智能体增强，保障微观一致性。同时构建多领域基准与PACE评估框架。

Result: 实验表明HAG显著优于基线方法，人口对齐误差平均降低37.7%，社会学一致性提升18.8%。

Conclusion: HAG通过分层建模有效兼顾宏观分布与微观理性，为高保真智能体初始化提供了可扩展、可评估的新范式。

Abstract: High-fidelity agent initialization is crucial for credible Agent-Based Modeling across diverse domains. A robust framework should be Topic-Adaptive, capturing macro-level joint distributions while ensuring micro-level individual rationality. Existing approaches fall into two categories: static data-based retrieval methods that fail to adapt to unseen topics absent from the data, and LLM-based generation methods that lack macro-level distribution awareness, resulting in inconsistencies between micro-level persona attributes and reality. To address these problems, we propose HAG, a Hierarchical Agent Generation framework that formalizes population generation as a two-stage decision process. Firstly, utilizing a World Knowledge Model to infer hierarchical conditional probabilities to construct the Topic-Adaptive Tree, achieving macro-level distribution alignment. Then, grounded real-world data, instantiation and agentic augmentation are carried out to ensure micro-level consistency. Given the lack of specialized evaluation, we establish a multi-domain benchmark and a comprehensive PACE evaluation framework. Extensive experiments show that HAG significantly outperforms representative baselines, reducing population alignment errors by an average of 37.7% and enhancing sociological consistency by 18.8%.

</details>


### [149] [CHDP: Cooperative Hybrid Diffusion Policies for Reinforcement Learning in Parameterized Action Space](https://arxiv.org/abs/2601.05675)
*Bingyi Liu,Jinbo He,Haiyong Shi,Enshu Wang,Weizhen Han,Jingxiang Hao,Peixi Wang,Zhuangzhuang Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为Cooperative Hybrid Diffusion Policies (CHDP)的框架，用于解决混合离散-连续动作空间的强化学习问题。该框架通过两个协作的扩散策略（分别处理离散和连续动作）建模动作间的依赖关系，并引入顺序更新、码本嵌入与Q函数引导机制以提升表达力、缓解冲突并增强高维场景下的可扩展性，在多个基准任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 混合动作空间（离散选择+连续参数）在机器人控制和游戏AI中广泛存在，但现有方法受限于策略表达能力不足和高维场景下可扩展性差。

Method: 将混合动作空间建模为完全协作博弈，设计CHDP框架：1）两个协作扩散策略（离散+连续），连续策略以离散动作表征为条件；2）顺序更新机制缓解策略更新冲突；3）构建低维码本嵌入高维离散动作空间；4）Q函数引导对齐码本嵌入与离散策略表征。

Result: 在多个具有挑战性的混合动作基准任务上，CHDP相比当前最优方法成功率最高提升19.3%。

Conclusion: CHDP通过协作扩散建模、顺序更新与结构化嵌入，有效提升了混合动作空间策略的表达能力与可扩展性，为复杂控制任务提供了新范式。

Abstract: Hybrid action space, which combines discrete choices and continuous parameters, is prevalent in domains such as robot control and game AI. However, efficiently modeling and optimizing hybrid discrete-continuous action space remains a fundamental challenge, mainly due to limited policy expressiveness and poor scalability in high-dimensional settings. To address this challenge, we view the hybrid action space problem as a fully cooperative game and propose a \textbf{Cooperative Hybrid Diffusion Policies (CHDP)} framework to solve it. CHDP employs two cooperative agents that leverage a discrete and a continuous diffusion policy, respectively. The continuous policy is conditioned on the discrete action's representation, explicitly modeling the dependency between them. This cooperative design allows the diffusion policies to leverage their expressiveness to capture complex distributions in their respective action spaces. To mitigate the update conflicts arising from simultaneous policy updates in this cooperative setting, we employ a sequential update scheme that fosters co-adaptation. Moreover, to improve scalability when learning in high-dimensional discrete action space, we construct a codebook that embeds the action space into a low-dimensional latent space. This mapping enables the discrete policy to learn in a compact, structured space. Finally, we design a Q-function-based guidance mechanism to align the codebook's embeddings with the discrete policy's representation during training. On challenging hybrid action benchmarks, CHDP outperforms the state-of-the-art method by up to $19.3\%$ in success rate.

</details>


### [150] [Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models](https://arxiv.org/abs/2601.05693)
*Zenghao Duan,Liang Pang,Zihao Wei,Wenbin Duan,Yuxin Tian,Shicheng Xu,Jingcheng Deng,Zhiyi Yin,Xueqi Cheng*

Main category: cs.AI

TL;DR: 本文识别出大型推理模型（LRMs）中一种新型失败模式——循环推理（Circular Reasoning），即模型陷入自我强化的文本重复陷阱；为此构建了LoopBench数据集，揭示其机制为语义重复先于文本重复的‘状态坍缩’，并基于V形自注意力与CUSUM算法实现早期检测。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在测试时扩展中常因重复循环导致计算浪费和推理失败，现有研究未系统刻画此类循环现象。

Method: 提出LoopBench数据集以建模数值循环与陈述循环两类；从语义与注意力机制角度分析循环成因，发现其本质是状态坍缩，并具有V形自注意力驱动的自我强化特性；采用CUSUM算法检测循环前兆以实现早期预测。

Result: 实验证明CUSUM算法能准确预测循环 onset，且揭示了长链推理的稳定性规律。

Conclusion: 循环推理是一种区别于传统退化的新失败模式，其可建模、可检测；LoopBench与CUSUM为提升LRMs鲁棒性提供了新工具与理论依据。

Abstract: Despite the success of test-time scaling, Large Reasoning Models (LRMs) frequently encounter repetitive loops that lead to computational waste and inference failure. In this paper, we identify a distinct failure mode termed Circular Reasoning. Unlike traditional model degeneration, this phenomenon manifests as a self-reinforcing trap where generated content acts as a logical premise for its own recurrence, compelling the reiteration of preceding text. To systematically analyze this phenomenon, we introduce LoopBench, a dataset designed to capture two distinct loop typologies: numerical loops and statement loops. Mechanistically, we characterize circular reasoning as a state collapse exhibiting distinct boundaries, where semantic repetition precedes textual repetition. We reveal that reasoning impasses trigger the loop onset, which subsequently persists as an inescapable cycle driven by a self-reinforcing V-shaped attention mechanism. Guided by these findings, we employ the Cumulative Sum (CUSUM) algorithm to capture these precursors for early loop prediction. Experiments across diverse LRMs validate its accuracy and elucidate the stability of long-chain reasoning.

</details>


### [151] [Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning](https://arxiv.org/abs/2601.05705)
*Ali Farjami,Luca Redondi,Marco Valentino*

Main category: cs.AI

TL;DR: 本文提出了一种逻辑参数化的神经符号自然语言推理（NLI）框架，将逻辑形式化视为可调控组件而非固定背景，通过LogiKEy方法在高阶逻辑中嵌入多种经典与非经典逻辑，系统比较其在规范推理等任务中的表现，发现逻辑内生方法优于外生方法，且不同逻辑适用于不同领域。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号NLI方法依赖固定逻辑形式化，限制了鲁棒性与适应性；而规范推理等任务对逻辑选择高度敏感，亟需可灵活切换与评估逻辑的框架。

Method: 采用LogiKEy方法将多种经典与非经典逻辑嵌入高阶逻辑（HOL），构建逻辑参数化NLI框架，对比逻辑外生（以公理编码规范）与逻辑内生（规范模式源于逻辑内在结构）两种策略，并在不同领域开展实验评估。

Result: 逻辑内生策略显著提升NLI性能并生成更高效的混合证明；逻辑有效性具有领域依赖性：一阶逻辑擅长常识推理，道义/模态逻辑更适用于伦理领域。

Conclusion: 将逻辑作为头等、可参数化的组件，可增强神经符号架构的鲁棒性、模块性与适应性，为可信AI推理提供新范式。

Abstract: Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-symbolic NLI that treats the underlying logic not as a static background, but as a controllable component. Using the LogiKEy methodology, we embed a range of classical and non-classical formalisms into higher-order logic (HOL), enabling a systematic comparison of inference quality, explanation refinement, and proof behavior. We focus on normative reasoning, where the choice of logic has significant implications. In particular, we compare logic-external approaches, where normative requirements are encoded via axioms, with logic-internal approaches, where normative patterns emerge from the logic's built-in structure. Extensive experiments demonstrate that logic-internal strategies can consistently improve performance and produce more efficient hybrid proofs for NLI. In addition, we show that the effectiveness of a logic is domain-dependent, with first-order logic favouring commonsense reasoning, while deontic and modal logics excel in ethical domains. Our results highlight the value of making logic a first-class, parametric element in neuro-symbolic architectures for more robust, modular, and adaptable reasoning.

</details>


### [152] [Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding](https://arxiv.org/abs/2601.05724)
*Yuxuan Zhou,Fei Huang,Heng Li,Fengyi Wu,Tianyu Wang,Jianwei Zhang,Junyang Lin,Zhi-Qi Cheng*

Main category: cs.AI

TL;DR: 本文提出了一种分层推测解码（HSD）方法，通过平衡可访问分支间的概率质量，实现无损验证，显著提升接受token数量并克服联合不可解性，在多个模型和基准上验证了其有效性与通用性。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码中的验证环节是推理加速的关键瓶颈，尤其是序列级验证虽优于逐token验证，但常依赖代理近似或受限于局部信息，难以处理联合不可解问题。

Method: 提出分层推测解码（HSD），一种可证明无损的验证方法，通过在可访问分支间平衡过剩与不足的概率质量，提升期望接受token数并解决联合不可解性。

Result: 大规模实验表明HSD在多种模型家族和基准上持续提升token接受率；集成至EAGLE-3后性能提升超12%，达到当前最优解码效率且不损害分布保真度。

Conclusion: HSD是一种高效、通用、可解释且即插即用的验证方法，为推测解码提供了理论保障与实用突破。

Abstract: Verification is a key bottleneck in improving inference speed while maintaining distribution fidelity in Speculative Decoding. Recent work has shown that sequence-level verification leads to a higher number of accepted tokens compared to token-wise verification. However, existing solutions often rely on surrogate approximations or are constrained by partial information, struggling with joint intractability. In this work, we propose Hierarchical Speculative Decoding (HSD), a provably lossless verification method that significantly boosts the expected number of accepted tokens and overcomes joint intractability by balancing excess and deficient probability mass across accessible branches. Our extensive large-scale experiments demonstrate that HSD yields consistent improvements in acceptance rates across diverse model families and benchmarks. Moreover, its strong explainability and generality make it readily integrable into a wide range of speculative decoding frameworks. Notably, integrating HSD into EAGLE-3 yields over a 12% performance gain, establishing state-of-the-art decoding efficiency without compromising distribution fidelity. Code is available at https://github.com/ZhouYuxuanYX/Hierarchical-Speculative-Decoding.

</details>


### [153] [PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility](https://arxiv.org/abs/2601.05739)
*G M Shahariar,Zabir Al Nazi,Md Olid Hasan Bhuiyan,Zhouxing Shi*

Main category: cs.AI

TL;DR: 本文提出PII-VisBench基准，评估视觉语言模型（VLMs）在不同主体在线可见度下的PII泄露风险，发现模型对高可见度主体更易泄露PII，且拒绝率与可见度负相关；揭示了模型家族差异与PII类型差异，并指出提示工程可加剧隐私风险。


<details>
  <summary>Details</summary>
Motivation: 现有PII泄露评估将隐私视为静态提取任务，忽视主体在线存在量（即其网络数据量）对隐私对齐的影响。

Method: 构建包含4000个独特探针的PII-VisBench基准，按200名受试者的在线可见度分为高、中、低、零四类；评估18个开源VLM（0.3B–32B）的拒绝率与条件PII披露率；辅以重述与越狱式提示测试鲁棒性。

Result: 发现拒绝率随主体可见度降低而上升，条件PII披露率从高可见度组9.10%降至低可见度组5.34%；高可见度主体更易被泄露PII；不同模型家族和PII类型表现差异显著；重述与越狱提示暴露模型依赖型失败。

Conclusion: PII泄露风险高度依赖主体在线可见度，需发展可见度感知的安全评估与训练方法，提升VLM在隐私敏感场景中的可靠性。

Abstract: Vision Language Models (VLMs) are increasingly integrated into privacy-critical domains, yet existing evaluations of personally identifiable information (PII) leakage largely treat privacy as a static extraction task and ignore how a subject's online presence--the volume of their data available online--influences privacy alignment. We introduce PII-VisBench, a novel benchmark containing 4000 unique probes designed to evaluate VLM safety through the continuum of online presence. The benchmark stratifies 200 subjects into four visibility categories: high, medium, low, and zero--based on the extent and nature of their information available online. We evaluate 18 open-source VLMs (0.3B-32B) based on two key metrics: percentage of PII probing queries refused (Refusal Rate) and the fraction of non-refusal responses flagged for containing PII (Conditional PII Disclosure Rate). Across models, we observe a consistent pattern: refusals increase and PII disclosures decrease (9.10% high to 5.34% low) as subject visibility drops. We identify that models are more likely to disclose PII for high-visibility subjects, alongside substantial model-family heterogeneity and PII-type disparities. Finally, paraphrasing and jailbreak-style prompts expose attack and model-dependent failures, motivating visibility-aware safety evaluation and training interventions.

</details>


### [154] [DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation](https://arxiv.org/abs/2601.05746)
*Zhenghao Li,Zhi Zheng,Wei Chen,Jielun Zhao,Yong Chen,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出DynaDebate框架，通过动态路径生成、过程导向辩论和触发式验证代理，提升多智能体辩论的有效性，克服现有方法中推理路径趋同、辩论流于表面投票等问题，在多个基准测试中优于现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体辩论（MAD）框架依赖无引导初始化，导致各智能体推理路径趋同、易犯相同错误，难以开展有效辩论，最终退化为简单多数投票。

Method: 提出Dynamic Multi-Agent Debate（DynaDebate）框架，包含三个核心机制：（1）动态路径生成与分配，由专用路径生成智能体生成多样化且逻辑合理的解题路径；（2）以过程为中心的辩论，强调逐步骤逻辑批判而非结果投票；（3）基于触发的验证智能体，在出现分歧时调用外部工具进行客观裁决。

Result: 在多个基准测试中，DynaDebate显著优于现有最先进MAD方法，验证了其提升多智能体协作推理能力的有效性。

Conclusion: DynaDebate通过引入多样性生成、过程监督与客观验证机制，系统性地提升了多智能体辩论的质量与鲁棒性，为构建更可靠、可解释的多智能体系统提供了新范式。

Abstract: Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.

</details>


### [155] [From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation](https://arxiv.org/abs/2601.05787)
*Zezhou Wang,Ziyun Zhang,Xiaoyi Zhang,Zhuzhong Qian,Yan Lu*

Main category: cs.AI

TL;DR: 本文提出BEPA方法，通过双层级专家策略融合机制，利用少量专家轨迹提升端到端GUI操作策略在强化学习中的性能，在OSWorld-Verified等基准上显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有GUI数据集（如OSWorld）任务覆盖少、专家轨迹采集成本高，导致端到端视觉语言模型难以充分训练；而直接将离线专家轨迹用于在线强化学习存在结构不匹配与分布偏移问题。

Method: 提出BEPA（Bi-Level Expert-to-Policy Assimilation）：LEVEL-1利用基础策略自生成可达轨迹对齐专家行为；LEVEL-2构建每个任务动态更新的缓存，在强化学习中提供可验证奖励下的策略引导。

Result: 在OSWorld-Verified上，UITARS1.5-7B的成功率从22.87%提升至32.13%，预留测试集从5.74%升至10.30%；在MMBench-GUI和Online-Mind2Web上也取得一致提升。

Conclusion: BEPA有效缓解小样本专家轨迹与在线RL之间的分布鸿沟，为端到端GUI智能体提供了可扩展、鲁棒的训练范式。

Abstract: Vision-language models are increasingly deployed as computer-use agents (CUAs) that operate desktops and browsers. Top-performing CUAs are framework-based systems that decompose planning and execution, while end-to-end screenshot-to-action policies are easier to deploy but lag behind on benchmarks such as OSWorld-Verified. GUI datasets like OSWorld pose two bottlenecks: they expose only a few hundred interactive, verifiable tasks and environments, and expert trajectories must be gathered by interacting with these environments, making such data hard to scale. We therefore ask how reinforcement learning from verifiable rewards (RLVR) can best exploit a small pool of exist expert trajectories to train end-to-end policies. Naively mixing these off-policy traces into on-policy RLVR is brittle: even after format conversion, expert trajectories exhibit structural mismatch and distribution shift from the learner. We propose BEPA (Bi-Level Expert-to-Policy Assimilation), which turns static expert traces into policy-aligned guidance via self-rolled reachable trajectories under the base policy (LEVEL-1) and a per-task, dynamically updated cache used in RLVR (LEVEL-2). On OSWorld-Verified, BEPA improves UITARS1.5-7B success from 22.87% to 32.13% and raises a held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web. Our code and data are available at: https://github.com/LEON-gittech/Verl_GUI.git

</details>


### [156] [StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management](https://arxiv.org/abs/2601.05890)
*Ruizhe Zhang,Xinke Jiang,Zhibang Yang,Zhixin Zhang,Jiaran Gao,Yuzhen Xiao,Hongbin Lai,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.AI

TL;DR: 本文提出StackPlanner，一种具有显式记忆控制的分层多智能体框架，通过解耦高层协调与子任务执行、引入结构化经验记忆和强化学习，解决中心化大模型多智能体系统在长程协作中因记忆管理缺失导致的上下文膨胀、错误累积和跨任务泛化差等问题。


<details>
  <summary>Details</summary>
Motivation: 中心化大语言模型多智能体系统在长程协作中存在记忆管理缺失，导致上下文膨胀、误差累积和跨任务泛化能力差。

Method: 提出StackPlanner框架：1）分层架构，解耦高层协调与子任务执行；2）主动任务级记忆控制；3）结构化经验记忆结合强化学习，实现协调经验的检索与复用。

Result: 在多个深度搜索与智能体系统基准测试中，StackPlanner显著提升了长程多智能体协作的可靠性与泛化能力。

Conclusion: 显式、分层的记忆控制机制是提升大模型多智能体系统长程协作稳定性与可复用性的关键路径。

Abstract: Multi-agent systems based on large language models, particularly centralized architectures, have recently shown strong potential for complex and knowledge-intensive tasks. However, central agents often suffer from unstable long-horizon collaboration due to the lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. To address both task-level memory inefficiency and the inability to reuse coordination experience, we propose StackPlanner, a hierarchical multi-agent framework with explicit memory control. StackPlanner addresses these challenges by decoupling high-level coordination from subtask execution with active task-level memory control, and by learning to retrieve and exploit reusable coordination experience via structured experience memory and reinforcement learning. Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of our approach in enabling reliable long-horizon multi-agent collaboration.

</details>


### [157] [TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents](https://arxiv.org/abs/2601.05899)
*Dawei Wang,Chengming Zhou,Di Zhao,Xinyuan Liu,Marci Chi Ma,Gary Ushaw,Richard Davison*

Main category: cs.AI

TL;DR: 本文提出了TowerMind，一个轻量级、多模态的塔防游戏环境，用于评估大语言模型（LLMs）在实时策略游戏中的长期规划、战术适应与幻觉等能力，并揭示了当前LLMs在决策质量与可靠性上的显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有RTS游戏环境计算开销高或缺乏文本观察能力，限制了其在LLM评估中的应用；需一个兼顾低开销、多模态输入与强评估能力的新基准。

Method: 设计并实现TowerMind环境，支持像素、文本和结构化状态三种观测模态；构建五个难度递进的基准关卡；在多种输入设置下评测主流LLMs及两种经典强化学习算法（Ape-X DQN、PPO）。

Result: 实验显示LLMs显著落后于人类专家，在规划验证、多目标决策与动作效率等方面存在明显缺陷；同时暴露出严重幻觉问题；RL算法在该环境中表现优于LLMs。

Conclusion: TowerMind为LLM智能体提供了高效、可扩展、多模态的新型评估平台，有助于推动面向复杂决策任务的AI代理研究。

Abstract: Recent breakthroughs in Large Language Models (LLMs) have positioned them as a promising paradigm for agents, with long-term planning and decision-making emerging as core general-purpose capabilities for adapting to diverse scenarios and tasks. Real-time strategy (RTS) games serve as an ideal testbed for evaluating these two capabilities, as their inherent gameplay requires both macro-level strategic planning and micro-level tactical adaptation and action execution. Existing RTS game-based environments either suffer from relatively high computational demands or lack support for textual observations, which has constrained the use of RTS games for LLM evaluation. Motivated by this, we present TowerMind, a novel environment grounded in the tower defense (TD) subgenre of RTS games. TowerMind preserves the key evaluation strengths of RTS games for assessing LLMs, while featuring low computational demands and a multimodal observation space, including pixel-based, textual, and structured game-state representations. In addition, TowerMind supports the evaluation of model hallucination and provides a high degree of customizability. We design five benchmark levels to evaluate several widely used LLMs under different multimodal input settings. The results reveal a clear performance gap between LLMs and human experts across both capability and hallucination dimensions. The experiments further highlight key limitations in LLM behavior, such as inadequate planning validation, a lack of multifinality in decision-making, and inefficient action use. We also evaluate two classic reinforcement learning algorithms: Ape-X DQN and PPO. By offering a lightweight and multimodal design, TowerMind complements the existing RTS game-based environment landscape and introduces a new benchmark for the AI agent field. The source code is publicly available on GitHub(https://github.com/tb6147877/TowerMind).

</details>


### [158] [Open-Vocabulary 3D Instruction Ambiguity Detection](https://arxiv.org/abs/2601.05991)
*Jiayu Ding,Haoran Tang,Ge Li*

Main category: cs.AI

TL;DR: 本文提出了开放词汇3D指令歧义检测这一新任务，构建了大规模基准Ambi3D，并提出两阶段框架AmbiVer以提升3D场景中指令歧义判断的可靠性，旨在增强具身AI的安全性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域，语言歧义可能导致严重后果，而当前具身AI研究大多忽略指令歧义问题，假设指令清晰且仅关注执行而非确认，存在重大安全缺口。

Method: 定义了开放词汇3D指令歧义检测任务；构建了包含700+ 3D场景和约22k条指令的大规模基准Ambi3D；提出两阶段框架AmbiVer，通过多视角显式视觉证据引导视觉-语言模型判断指令歧义。

Result: 实验表明当前SOTA 3D大语言模型难以可靠判断指令歧义，而AmbiVer显著提升了性能，验证了任务挑战性与方法有效性。

Conclusion: 该工作首次系统性地关注3D指令歧义检测问题，为构建更安全、可信的具身AI系统奠定了基础。

Abstract: In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like "Pass me the vial" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [159] [SP-Rank: A Dataset for Ranked Preferences with Secondary Information](https://arxiv.org/abs/2601.05253)
*Hadi Hosseini,Debmalya Mandal,Amrit Puhan*

Main category: cs.IR

TL;DR: 本文提出了SP-Rank数据集，首个支持一阶偏好与二阶预测联合建模的大规模公开排序基准数据集，并提出SP-Voting方法，在多个排序任务上验证了融合两类信号的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统排序数据集仅包含个体偏好（一阶信号），难以建模人类对他人判断的元认知（二阶信号）；而现实场景中，个体投票常为含噪估计，需借助群体元预测推断共享真值排序。

Method: 构建SP-Rank数据集（12,000+人工标注样本，覆盖地理/电影/绘画三领域、九种 elicitation 格式），并提出SP-Voting方法——一种联合建模一阶投票与二阶元预测以推断真值排序的第二阶聚合算法。

Result: 在全序恢复、子集序恢复和选民行为概率建模三项任务上，融合一阶与二阶信号的SP-Voting显著优于仅用一阶投票的传统方法；二阶信号本身亦具建模价值。

Conclusion: 一阶与二阶信号的协同利用可提升排序鲁棒性与准确性，SP-Rank为偏好建模、社会选择、学习排序及奖励建模等方向提供了新基准与工具。

Abstract: We introduce $\mathbf{SP-Rank}$, the first large-scale, publicly available dataset for benchmarking algorithms that leverage both first-order preferences and second-order predictions in ranking tasks. Each datapoint includes a personal vote (first-order signal) and a meta-prediction of how others will vote (second-order signal), allowing richer modeling than traditional datasets that capture only individual preferences. SP-Rank contains over 12,000 human-generated datapoints across three domains -- geography, movies, and paintings, and spans nine elicitation formats with varying subset sizes. This structure enables empirical analysis of preference aggregation when expert identities are unknown but presumed to exist, and individual votes represent noisy estimates of a shared ground-truth ranking. We benchmark SP-Rank by comparing traditional aggregation methods that use only first-order votes against SP-Voting, a second-order method that jointly reasons over both signals to infer ground-truth rankings. While SP-Rank also supports models that rely solely on second-order predictions, our benchmarks emphasize the gains from combining both signals. We evaluate performance across three core tasks: (1) full ground-truth rank recovery, (2) subset-level rank recovery, and (3) probabilistic modeling of voter behavior. Results show that incorporating second-order signals substantially improves accuracy over vote-only methods. Beyond social choice, SP-Rank supports downstream applications in learning-to-rank, extracting expert knowledge from noisy crowds, and training reward models in preference-based fine-tuning pipelines. We release the dataset, code, and baseline evaluations (available at https://github.com/amrit19/SP-Rank-Dataset ) to foster research in human preference modeling, aggregation theory, and human-AI alignment.

</details>


### [160] [TagRAG: Tag-guided Hierarchical Knowledge Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2601.05254)
*Wenbiao Tao,Yunshi Lan,Weining Qian*

Main category: cs.IR

TL;DR: 本文提出TagRAG，一种基于标签引导的分层知识图谱RAG框架，通过构建标签知识图和标签引导的检索增强生成，提升全局推理效率与图谱可扩展性，在多个领域数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统RAG受限于片段级检索，难以处理查询导向的摘要任务；GraphRAG虽引入图结构支持全局推理，但存在信息抽取低效、资源消耗高、难以增量更新等问题。

Method: 提出TagRAG框架，包含两部分：(1) 标签知识图构建——从文档中提取对象标签及其关系，并组织为分层领域标签链；(2) 标签引导的RAG——在推理时检索领域中心的标签链以定位并融合相关知识。

Result: 在UltraDomain多领域数据集（农业、计算机科学、法律及跨域）上，TagRAG平均胜率95.41%，图谱构建效率约为GraphRAG的14.6倍，检索效率为1.9倍。

Conclusion: TagRAG通过标签引导与分层图结构，在保持高效性的同时提升了RAG对查询导向摘要任务的支持能力，尤其适配小语言模型并支持知识增量更新。

Abstract: Retrieval-Augmented Generation enhances language models by retrieving external knowledge to support informed and grounded responses. However, traditional RAG methods rely on fragment-level retrieval, limiting their ability to address query-focused summarization queries. GraphRAG introduces a graph-based paradigm for global knowledge reasoning, yet suffers from inefficiencies in information extraction, costly resource consumption, and poor adaptability to incremental updates. To overcome these limitations, we propose TagRAG, a tag-guided hierarchical knowledge graph RAG framework designed for efficient global reasoning and scalable graph maintenance. TagRAG introduces two key components: (1) Tag Knowledge Graph Construction, which extracts object tags and their relationships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation, and (2) Tag-Guided Retrieval-Augmented Generation, which retrieves domain-centric tag chains to localize and synthesize relevant knowledge during inference. This design significantly adapts to smaller language models, improves retrieval granularity, and supports efficient knowledge increment. Extensive experiments on UltraDomain datasets spanning Agriculture, Computer Science, Law, and cross-domain settings demonstrate that TagRAG achieves an average win rate of 95.41\% against baselines while maintaining about 14.6x construction and 1.9x retrieval efficiency compared with GraphRAG.

</details>


### [161] [CourtNav: Voice-Guided, Anchor-Accurate Navigation of Long Legal Documents in Courtrooms](https://arxiv.org/abs/2601.05255)
*Sai Khadloya,Kush Juvekar,Arghya Bhattacharya,Utkarsh Saxena*

Main category: cs.IR

TL;DR: CourtNav is a voice-guided navigation tool for legal PDFs that enables judges to quickly locate and highlight relevant passages using spoken commands, significantly reducing time-to-relevance in judicial document review.


<details>
  <summary>Details</summary>
Motivation: Judicial work involves reviewing extremely long legal documents with limited staff support, making exhaustive manual reading during hearings impractical—especially in contexts like India where documents are notoriously lengthy.

Method: CourtNav uses speech transcription, intent classification via a hybrid grammar-first (regex) and few-shot LLM router, layout-aware hybrid indexing for retrieval, and automatic scrolling + highlighting of targeted text spans—all while displaying only grounded, verifiable passages.

Result: In pilot tests on charge sheets, pleadings, and orders, median time-to-relevance dropped from 3–5 minutes manually to 10–15 seconds (or 30–45 seconds including visual verification); the system also increases breadth of record consulted under fixed time budgets.

Conclusion: CourtNav’s navigation-first, voice-guided, and auditable design improves judicial efficiency, transparency, and evidence grounding in high-stakes legal document review.

Abstract: Judicial work depends on close reading of long records, charge sheets, pleadings, annexures, orders, often spanning hundreds of pages. With limited staff support, exhaustive reading during hearings is impractical. We present CourtNav, a voice-guided, anchor-first navigator for legal PDFs that maps a judge's spoken command (e.g., "go to paragraph 23", "highlight the contradiction in the cross-examination") directly to a highlighted paragraph in seconds. CourtNav transcribes the command, classifies intent with a grammar-first(Exact regex matching), LLM-backed router classifying the queries using few shot examples, retrieves over a layout-aware hybrid index, and auto-scrolls the viewer to the cited span while highlighting it and close alternates. By design, the interface shows only grounded passages, never free text, keeping evidence verifiable and auditable. This need is acute in India, where judgments and cross-examinations are notoriously long.In a pilot on representative charge sheets, pleadings, and orders, median time-to-relevance drops from 3-5 minutes (manual navigation) to 10-15 seconds; with quick visual verification included, 30-45 seconds. Under fixed time budgets, this navigation-first design increases the breadth of the record actually consulted while preserving control and transparency.

</details>


### [162] [KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits](https://arxiv.org/abs/2601.05257)
*Hou-Wan Long,Yicheng Song,Zidong Wang,Tianshu Sun*

Main category: cs.IR

TL;DR: 本文提出KP-Agent，一种基于大语言模型的智能代理系统，用于优化赞助搜索广告中的关键词剪枝，通过上下文赌博机框架与强化学习，在真实医药广告数据上显著提升累计收益。


<details>
  <summary>Details</summary>
Motivation: 现有赞助搜索广告中关键词剪枝策略研究不足，实际广告主面临关键词集合低效问题，亟需自动化、数据驱动的优化方法。

Method: 构建KP-Agent系统，集成领域专用工具集与记忆模块，将关键词剪枝建模为上下文赌博机问题，并利用强化学习生成代码片段动态优化关键词集合。

Result: 在美团平台0.5百万条医药广告真实数据上实验表明，KP-Agent相较基线方法最高提升累计利润49.28%。

Conclusion: KP-Agent验证了LLM智能体结合领域工具与强化学习在广告关键词优化任务中的有效性与实用性，为SSA自动化决策提供了新范式。

Abstract: Sponsored search advertising (SSA) requires advertisers to constantly adjust keyword strategies. While bid adjustment and keyword generation are well-studied, keyword pruning-refining keyword sets to enhance campaign performance-remains under-explored. This paper addresses critical inefficiencies in current practices as evidenced by a dataset containing 0.5 million SSA records from a pharmaceutical advertiser on search engine Meituan, China's largest delivery platform. We propose KP-Agent, an LLM agentic system with domain tool set and a memory module. By modeling keyword pruning within a contextual bandit framework, KP-Agent generates code snippets to refine keyword sets through reinforcement learning. Experiments show KP-Agent improves cumulative profit by up to 49.28% over baselines.

</details>


### [163] [From Events to Trending: A Multi-Stage Hotspots Detection Method Based on Generative Query Indexing](https://arxiv.org/abs/2601.05258)
*Kaichun Wang,Yanguang Chen,Ting Zhang,Mengyao Bao,Keyu Chen,Xu Hu,Yongliang Wang,Jingsheng Yang,Jinsong Zhang,Fei Lu*

Main category: cs.IR

TL;DR: 本文提出了一种面向对话系统的多阶段热点查询检测框架，通过离线生成索引查询与在线级联召回-排序机制，显著提升新闻类趋势查询识别效果，并在实际应用中提升用户满意度27%。


<details>
  <summary>Details</summary>
Motivation: 现有聊天机器人难以有效处理新闻相关的热点查询，而传统搜索引擎的热点检测方法在对话场景下因查询分布和表达模式差异而表现不佳，亟需针对对话系统定制的热点检测方法。

Method: 提出多阶段热点检测框架：1）基于热门事件生成索引查询，建立静态事件与动态用户查询的桥梁；2）采用级联召回与排序架构实现实时在线检测；3）引入单召回模块作为冷启动策略，收集数据用于重排序器微调。

Result: 在离线评估和在线A/B测试中均显著优于基线方法，用户正负反馈比相对提升27%。

Conclusion: 该框架有效解决了对话系统中热点查询检测的挑战，兼顾效率与精度，并具备良好的实际部署适应性。

Abstract: LLM-based conversational systems have become a popular gateway for information access, yet most existing chatbots struggle to handle news-related trending queries effectively. To improve user experience, an effective trending query detection method is urgently needed to enable differentiated processing of such target traffic. However, current research on trending detection tailored to the dialogue system scenario remains largely unexplored, and methods designed for traditional search engines often underperform in conversational contexts due to radically distinct query distributions and expression patterns. To fill this gap, we propose a multi-stage framework for trending detection, which achieves systematic optimization from both offline generation and online identification perspectives. Specifically, our framework first exploits selected hot events to generate index queries, establishing a key bridge between static events and dynamic user queries. It then employs a retrieval matching mechanism for real-time online detection of trending queries, where we introduce a cascaded recall and ranking architecture to balance detection efficiency and accuracy. Furthermore, to better adapt to the practical application scenario, our framework adopts a single-recall module as a cold-start strategy to collect online data for fine-tuning the reranker. Extensive experiments demonstrate that our framework significantly outperforms baseline methods in both offline evaluations and online A/B tests, and user satisfaction is relatively improved by 27\% in terms of positive-negative feedback ratio.

</details>


### [164] [A Technical Report on the Second Place Solution for the CIKM 2025 AnalytiCup Competition](https://arxiv.org/abs/2601.05259)
*Haotao Xie,Ruilin Chen,Yicheng Wu,Zhan Zhao,Yuanyuan Liu*

Main category: cs.IR

TL;DR: 本文提出了一种基于提示工程与思维链任务分解的单一大语言模型框架，用于多语言电商搜索中的类别相关性判断，通过四步可解释子任务和LoRA微调Qwen2.5-14B模型，在保持高准确率的同时显著提升推理效率与可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统集成系统虽能提升多语言电商搜索中类别相关性判断的准确性，但训练、推理与维护复杂度高，难以工业落地。

Method: 采用链式思维（Chain-of-Thought）将相关性判断分解为翻译、意图理解、类别匹配和最终相关性判断四个子任务，并基于Qwen2.5-14B模型使用LoRA进行轻量微调。

Result: 在单张A100 GPU上实现每秒处理20个样本；CIKM 2025 AnalytiCup竞赛中公榜得分0.8902、私榜0.8889，性能媲美复杂集成系统。

Conclusion: 结构化提示+轻量微调可替代高成本集成系统，为工业级AI应用提供更高效、可解释、可扩展的新范式。

Abstract: In this work, we address the challenge of multilingual category relevance judgment in e-commerce search, where traditional ensemble-based systems improve accuracy but at the cost of heavy training, inference, and maintenance complexity. To overcome this limitation, we propose a simplified yet effective framework that leverages prompt engineering with Chain-of-Thought task decomposition to guide reasoning within a single large language model. Specifically, our approach decomposes the relevance judgment process into four interpretable subtasks: translation, intent understanding, category matching, and relevance judgment -- and fine-tunes a base model (Qwen2.5-14B) using Low-Rank Adaptation (LoRA) for efficient adaptation. This design not only reduces computational and storage overhead but also enhances interpretability by explicitly structuring the model's reasoning path. Experimental results show that our single-model framework achieves competitive accuracy and high inference efficiency, processing 20 samples per second on a single A100 GPU. In the CIKM 2025 AnalytiCup Competition Proposals, our method achieved 0.8902 on the public leaderboard and 0.8889 on the private leaderboard, validating the effectiveness and robustness of the proposed approach. These results highlight that structured prompting combined with lightweight fine-tuning can outperform complex ensemble systems, offering a new paradigm for scalable industrial AI applications.

</details>


### [165] [Quantifying Document Impact in RAG-LLMs](https://arxiv.org/abs/2601.05260)
*Armin Gerami,Kazem Faghih,Ramani Duraiswami*

Main category: cs.IR

TL;DR: 本文提出了一种基于偏信息分解的新指标Influence Score（IS），用于量化检索文档对RAG系统生成结果的个体贡献，并通过毒化攻击模拟和消融实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG评估缺乏衡量单个检索文档对最终输出贡献的指标，且RAG系统面临事实不一致、源冲突、偏差传播和安全漏洞等可信度挑战。

Method: 提出基于偏信息分解（Partial Information Decomposition）的Influence Score（IS）指标，用以度量每个检索文档对生成响应的影响；并通过毒化攻击模拟和消融实验进行验证。

Result: 在毒化攻击实验中，IS在86%的情况下准确识别出恶意文档为最具影响力文档；消融实验表明，仅使用IS评分最高的文档生成的响应比使用其余文档生成的响应更接近原始响应。

Conclusion: Influence Score能有效隔离并量化单个文档的影响，为提升RAG系统的透明性与可靠性提供了新工具。

Abstract: Retrieval Augmented Generation (RAG) enhances Large Language Models (LLMs) by connecting them to external knowledge, improving accuracy and reducing outdated information. However, this introduces challenges such as factual inconsistencies, source conflicts, bias propagation, and security vulnerabilities, which undermine the trustworthiness of RAG systems. A key gap in current RAG evaluation is the lack of a metric to quantify the contribution of individual retrieved documents to the final output. To address this, we introduce the Influence Score (IS), a novel metric based on Partial Information Decomposition that measures the impact of each retrieved document on the generated response. We validate IS through two experiments. First, a poison attack simulation across three datasets demonstrates that IS correctly identifies the malicious document as the most influential in $86\%$ of cases. Second, an ablation study shows that a response generated using only the top-ranked documents by IS is consistently judged more similar to the original response than one generated from the remaining documents. These results confirm the efficacy of IS in isolating and quantifying document influence, offering a valuable tool for improving the transparency and reliability of RAG systems.

</details>


### [166] [Improving User Experience with Personalized Review Ranking and Summarization](https://arxiv.org/abs/2601.05261)
*Muhammad Mufti,Omar Hammad,Mahfuzur Rahman*

Main category: cs.IR

TL;DR: 本文提出了一种结合个性化评论排序与抽象式摘要的框架，通过融合用户情感建模与语义偏好分析，提升消费者在海量在线评论中的决策效率。


<details>
  <summary>Details</summary>
Motivation: 现有评论排序方法依赖帮助性投票、星级和时效性等指标，忽视用户个性化兴趣，且未统一处理文本情感与评分信号，导致信息过载问题。

Method: 构建用户情感模型（融合星级与评论文本），利用句子嵌入与聚类从历史评论中提取语义偏好；设计基于情感与方面相似度的相关性评分算法匹配新评论；对高相关评论进行个性化摘要生成。

Result: 用户研究表明，该方法显著提升了用户满意度、感知相关性和决策信心，并减少了阅读时间。

Conclusion: 所提个性化框架能有效缓解信息过载，为用户提供更贴合其偏好的评论内容，显著增强评论环境下的用户体验。

Abstract: Online consumer reviews play a crucial role in guiding purchase decisions by offering insights into product quality, usability, and performance. However, the increasing volume of user-generated reviews has led to information overload, making it difficult for consumers to identify content that aligns with their specific preferences. Existing review ranking systems typically rely on metrics such as helpfulness votes, star ratings, and recency, but these fail to capture individual user interests and often treat textual sentiment and rating signals separately. This research addresses these limitations by proposing a personalized framework that integrates review ranking and abstractive summarization to enhance decision-making efficiency. The proposed system begins by modeling each user's sentiment through a hybrid analysis of star ratings and review content. Simultaneously, user preferences were derived from historical reviews using sentence embeddings and clustering, forming semantic profiles aligned with thematic and sentiment dimensions. A relevance scoring algorithm matched these profiles with unseen reviews based on sentiment and aspect similarity. Top-matched reviews were then summarized to reflect individual interests. A user study with 70 participants demonstrated that the personalized approach improved satisfaction, perceived relevance, and decision-making confidence, while reducing time spent reading. The results highlight the method's effectiveness in alleviating information overload and delivering content tailored to user-specific preferences, emphasizing its value in enhancing user experience in review-rich decision-making environments.

</details>


### [167] [LLM2IR: simple unsupervised contrastive learning makes long-context LLM great retriever](https://arxiv.org/abs/2601.05262)
*Xiaocong Yang*

Main category: cs.IR

TL;DR: 本文提出LLM2IR，一种高效的无监督对比学习框架，可将任意解码器-only大语言模型（LLM）转换为信息检索（IR）模型，无需大规模预训练，并在多个IR基准上验证了其有效性，同时发现更长上下文长度有助于提升IR能力。


<details>
  <summary>Details</summary>
Motivation: 现代密集型信息检索模型通常依赖昂贵的大规模预训练；亟需一种高效、无需大规模预训练即可将现有大语言模型适配为IR模型的方法。

Method: 提出LLM2IR框架，基于无监督对比学习，将任意decoder-only LLM转化为IR模型；通过在多个IR基准（LoCo、LongEmbed、BEIR）上评估不同LLM的性能，并分析模型上下文长度与IR能力的关系。

Result: LLM2IR在多个IR基准上表现优异；实证表明同族模型中上下文长度越长，IR能力越强。

Conclusion: LLM2IR提供了一种高效构建基于SOTA LLM的IR模型的新范式，并揭示了模型上下文长度与IR能力之间的正相关关系，为未来检索模型设计提供了新启示。

Abstract: Modern dense information retrieval (IR) models usually rely on costly large-scale pretraining. In this paper, we introduce LLM2IR, an efficient unsupervised contrastive learning framework to convert any decoder-only large language model (LLM) to an information retrieval model. Despite its simplicity, the effectiveness is proven among different LLMs on multiple IR benchmarks including LoCo, LongEmbed and BEIR. We also find that models with a longer context length tend to have a stronger IR capacity by comparing task performances of models in the same model family. Our work not only provides an effective way to build IR models on the state-of-the-art LLMs, but also shed light on the relationship between information retrieval ability and model context length, which helps the design of better information retrievers.

</details>


### [168] [A General Metric-Space Formulation of the Time Warp Edit Distance (TWED)](https://arxiv.org/abs/2601.05263)
*Zhen Yi Lau*

Main category: cs.IR

TL;DR: 本文提出了时间扭曲编辑距离（TWED）在任意度量空间中的广义形式GTWED，并证明其在温和条件下仍为真度量，同时恢复经典TWED作为特例。


<details>
  <summary>Details</summary>
Motivation: 将TWED推广到任意度量空间，以支持非时间序列数据（如符号数据、流形、嵌入）上的弹性距离计算。

Method: 将观测域和时间域均建模为度量空间(X,d)和(T,Δ)，在此基础上定义广义TWED（GTWED），并给出其满足度量性质的自包含证明。

Result: GTWED在温和假设下是真度量；经典TWED是其在X=R^d、T⊂R、g(x)=x时的特例。

Conclusion: GTWED为在更广泛的数据类型上构建弹性距离提供了理论基础和统一框架。

Abstract: This short technical note presents a formal generalization of the Time Warp Edit Distance (TWED) proposed by Marteau (2009) to arbitrary metric spaces. By viewing both the observation and temporal domains as metric spaces $(X, d)$ and $(T, Δ)$, we define a Generalized TWED (GTWED) that remains a true metric under mild assumptions. We provide self-contained proofs of its metric properties and show that the classical TWED is recovered as a special case when $X = \mathbb{R}^d$, $T \subset \mathbb{R}$, and $g(x) = x$. This note focuses on the theoretical structure of GTWED and its implications for extending elastic distances beyond time series, which enables the use of TWED-like metrics on sequences over arbitrary domains such as symbolic data, manifolds, or embeddings.

</details>


### [169] [Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2601.05264)
*Dean Wampler,Dave Nielson,Alireza Seddighi*

Main category: cs.IR

TL;DR: 本文是对2018–2025年间检索增强生成（RAG）研究与实践的系统性综述，构建统一分类体系，提出量化评估框架，并强调鲁棒性、安全性与领域适配性。


<details>
  <summary>Details</summary>
Motivation: RAG方法日益多样化导致研究与工程实践碎片化，亟需系统整合与实用指导。

Method: 系统性文献综述，构建RAG统一分类法，设计定量评估框架，并综合学术、工业与技术实施资料。

Result: 形成覆盖架构、融合机制、检索策略与编排方式的RAG统一taxonomy；提出面向信任、对齐、安全与部署的评估与实践指南。

Conclusion: RAG需兼顾模块化优势与系统性工程规范，本综述为构建可信赖、可部署、可适配的RAG系统提供了理论基础与实践框架。

Abstract: This article provides a comprehensive systematic literature review of academic studies, industrial applications, and real-world deployments from 2018 to 2025, providing a practical guide and detailed overview of modern Retrieval-Augmented Generation (RAG) architectures. RAG offers a modular approach for integrating external knowledge without increasing the capacity of the model as LLM systems expand. Research and engineering practices have been fragmented as a result of the increasing diversity of RAG methodologies, which encompasses a variety of fusion mechanisms, retrieval strategies, and orchestration approaches. We provide quantitative assessment frameworks, analyze the implications for trust and alignment, and systematically consolidate existing RAG techniques into a unified taxonomy. This document is a practical framework for the deployment of resilient, secure, and domain-adaptable RAG systems, synthesizing insights from academic literature, industry reports, and technical implementation guides. It also functions as a technical reference.

</details>


### [170] [Cross-Document Topic-Aligned Chunking for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.05265)
*Mile Stankovic*

Main category: cs.IR

TL;DR: 本文提出跨文档主题对齐（CDTA）分块方法，通过在语料库层面重建知识，解决多源信息碎片化问题，显著提升RAG系统在多跳推理与法律文本中的忠实度和引用准确性。


<details>
  <summary>Details</summary>
Motivation: 现有分块方法仅针对单文档进行，难以应对需跨多个文档获取信息的复杂查询，导致知识碎片化，影响RAG系统性能。

Method: CDTA分块法：首先跨文档识别主题，将各文档片段映射到对应主题，再综合生成统一、信息密集的跨文档块。

Result: 在HotpotQA上信仰度达0.93（较当前最佳实践提升12%）；在阿联酋法律文本中信仰度0.94、引用准确率0.93；k=3时仍保持0.91信仰度，而语义分块降至0.68。

Conclusion: 跨文档合成能显著优于单文档优化，尤其适用于高查询量、知识分布广泛的场景，尽管索引开销略高，但可降低检索负担并提升效果。

Abstract: Chunking quality determines RAG system performance. Current methods partition documents individually, but complex queries need information scattered across multiple sources: the knowledge fragmentation problem. We introduce Cross-Document Topic-Aligned (CDTA) chunking, which reconstructs knowledge at the corpus level. It first identifies topics across documents, maps segments to each topic, and synthesizes them into unified chunks.
  On HotpotQA multi-hop reasoning, our method reached 0.93 faithfulness versus 0.83 for contextual retrieval and 0.78 for semantic chunking, a 12% improvement over current industry best practice (p < 0.05). On UAE Legal texts, it reached 0.94 faithfulness with 0.93 citation accuracy. At k = 3, it maintains 0.91 faithfulness while semantic methods drop to 0.68, with a single CDTA chunk containing information requiring multiple traditional fragments.
  Indexing costs are higher, but synthesis produces information-dense chunks that reduce query-time retrieval needs. For high-query-volume applications with distributed knowledge, cross-document synthesis improves measurably over within-document optimization.

</details>


### [171] [Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction](https://arxiv.org/abs/2601.05266)
*Muzakkiruddin Ahmed Mohammed,John R. Talburt,Leon Claasssens,Adriaan Marais*

Main category: cs.IR

TL;DR: 本文提出了一种检索增强的多大语言模型（LLM）集成框架RAGsemble，用于从非结构化文本中自动提取工业零部件规格信息。该框架融合9个前沿LLM，并结合FAISS语义检索，在三阶段流水线中实现并行抽取、定向增强与智能合成，显著提升准确率与结构化质量。


<details>
  <summary>Details</summary>
Motivation: 工业领域中，从非结构化文本手动提取零部件规格耗时易错，亟需自动化、高精度、可落地的AI解决方案。

Method: 构建基于检索增强生成（RAG）的多LLM集成框架RAGsemble：1）九个异构LLM（Gemini、GPT-4o、Mistral、Gemma等）并行抽取；2）由高性能模型驱动的靶向检索增强；3）带冲突消解与置信度评分的智能合成；全程通过FAISS接入结构化零部件数据库实现事实 grounding。

Result: 在真实工业数据集上，RAGsemble在抽取准确率、技术完整性与结构化输出质量上均显著优于单LLM基线方法。

Conclusion: RAGsemble是一种可扩展、可部署、面向知识密集型制造场景的生产级解决方案，其核心贡献在于多模型协同架构、全流程RAG集成及完备的质量评估机制。

Abstract: Industrial part specification extraction from unstructured text remains a persistent challenge in manufacturing, procurement, and maintenance, where manual processing is both time-consuming and error-prone. This paper introduces a retrieval-augmented multi-LLM ensemble framework that orchestrates nine state-of-the-art Large Language Models (LLMs) within a structured three-phase pipeline. RAGsemble addresses key limitations of single-model systems by combining the complementary strengths of model families including Gemini (2.0, 2.5, 1.5), OpenAI (GPT-4o, o4-mini), Mistral Large, and Gemma (1B, 4B, 3n-e4b), while grounding outputs in factual data using FAISS-based semantic retrieval. The system architecture consists of three stages: (1) parallel extraction by diverse LLMs, (2) targeted research augmentation leveraging high-performing models, and (3) intelligent synthesis with conflict resolution and confidence-aware scoring. RAG integration provides real-time access to structured part databases, enabling the system to validate, refine, and enrich outputs through similarity-based reference retrieval. Experimental results using real industrial datasets demonstrate significant gains in extraction accuracy, technical completeness, and structured output quality compared to leading single-LLM baselines. Key contributions include a scalable ensemble architecture for industrial domains, seamless RAG integration throughout the pipeline, comprehensive quality assessment mechanisms, and a production-ready solution suitable for deployment in knowledge-intensive manufacturing environments.

</details>


### [172] [Transforming User Defined Criteria into Explainable Indicators with an Integrated LLM AHP System](https://arxiv.org/abs/2601.05267)
*Geonwoo Bang,Dongho Kim,Moohong Min*

Main category: cs.IR

TL;DR: 本文提出了一种结合大语言模型（LLM）评分与层次分析法（AHP）的可解释聚合框架，用于将用户定义标准转化为定量、可解释指标，解决了复杂文本评估中解释性与效率难以兼顾的问题。


<details>
  <summary>Details</summary>
Motivation: 评估跨领域的复杂文本需将用户定义的标准转化为定量、可解释的指标，但现有方法存在复杂度高、延迟大或聚合方式不透明等问题。

Method: 提出一种可解释聚合框架：利用LLM作为裁判生成各准则下的评分；用Jensen-Shannon距离衡量各准则判别力；通过AHP两两比较矩阵推导统计上合理的权重。

Result: 在Amazon评论质量评估和抑郁相关文本评分任务上，该方法在保持相当预测性能的同时，显著提升了可解释性和运行效率，适用于实时、低延迟的网络服务。

Conclusion: 该框架有效平衡了评估系统的解释性、效率与准确性，为搜索与推荐系统中的复杂文本评估提供了实用新范式。

Abstract: Evaluating complex texts across domains requires converting user defined criteria into quantitative, explainable indicators, which is a persistent challenge in search and recommendation systems. Single prompt LLM evaluations suffer from complexity and latency issues, while criterion specific decomposition approaches rely on naive averaging or opaque black-box aggregation methods. We present an interpretable aggregation framework combining LLM scoring with the Analytic Hierarchy Process. Our method generates criterion specific scores via LLM as judge, measures discriminative power using Jensen Shannon distance, and derives statistically grounded weights through AHP pairwise comparison matrices. Experiments on Amazon review quality assessment and depression related text scoring demonstrate that our approach achieves high explainability and operational efficiency while maintaining comparable predictive power, making it suitable for real time latency sensitive web services.

</details>


### [173] [Separating Semantic Expansion from Linear Geometry for PubMed-Scale Vector Search](https://arxiv.org/abs/2601.05268)
*Rob Koopman*

Main category: cs.IR

TL;DR: 本文提出了一种无需训练参数的PubMed规模检索框架，通过大语言模型扩展查询并利用几何特性（如各向同性、紧凑性）进行纯几何评估，在4000万文献中实现高效精确检索。


<details>
  <summary>Details</summary>
Motivation: 解决大规模生物医学文献检索中语义理解与度量几何分离的问题，避免依赖传统召回率指标和参数训练。

Method: 使用大语言模型将自然语言查询扩展为简洁生物医学短语；文档和查询向量由token嵌入加权平均生成，投影到去噪子空间，并经Johnson-Lindenstrauss变换压缩为256维int8向量；全部过程无参数训练。

Result: 在完整MEDLINE语料（约4000万条记录）上实现了基于精确余弦搜索的高效聚类检索；几何指标（头部余弦、紧凑性、质心闭合性、各向同性）显著优于随机向量基线。

Conclusion: 纯几何、无训练的检索框架可有效支持大规模生物医学文献的语义一致检索，且评估范式从传统召回转向内在几何性质分析。

Abstract: We describe a PubMed scale retrieval framework that separates semantic interpretation from metric geometry. A large language model expands a natural language query into concise biomedical phrases; retrieval then operates in a fixed, mean free, approximately isotropic embedding space. Each document and query vector is formed as a weighted mean of token embeddings, projected onto the complement of nuisance axes and compressed by a Johnson Lindenstrauss transform. No parameters are trained. The system retrieves coherent biomedical clusters across the full MEDLINE corpus (about 40 million records) using exact cosine search on 256 dimensional int8 vectors. Evaluation is purely geometric: head cosine, compactness, centroid closure, and isotropy are compared with random vector baselines. Recall is not defined, since the language-model expansion specifies the effective target set.

</details>


### [174] [Studying Illustrations in Manuscripts: An Efficient Deep-Learning Approach](https://arxiv.org/abs/2601.05269)
*Yoav Evron,Michal Bar-Asher Siegal,Michael Fire*

Main category: cs.IR

TL;DR: 本文提出了一种快速、可扩展的AI流水线，用于在数字化手稿中自动检测、裁剪和描述插图，已处理超三百万页，识别出20余万幅独特插图，单页耗时低于0.06秒。


<details>
  <summary>Details</summary>
Motivation: 数字档案虽已广泛提供历史手稿图像，但大规模系统性研究其中插图仍困难；亟需高效工具支持人文学者开展视觉内容分析。

Method: 构建三阶段AI流水线：(1) 微调图像分类模型筛除纯文本页；(2) 高效目标检测模型定位并裁剪插图；(3) 多模态图像描述模型生成简洁可读描述；结果存入可关键词检索的数据库。

Result: 在梵蒂冈图书馆等馆藏上验证，处理超300万页手稿，自动识别并提取20余万幅唯一插图，单页平均耗时<0.06秒，显著优于传统分割方法。

Conclusion: 该AI方法极大提升了手稿图像分析的规模与效率，赋能艺术史、历史学与文化遗产研究，推动数字人文跨学科研究范式变革。

Abstract: The recent Artificial Intelligence (AI) revolution has opened transformative possibilities for the humanities, particularly in unlocking the visual content embedded in historical manuscripts. While digital archives now offer unprecedented access to these materials, the ability to systematically study illustrations at a large scale remains challenging. Our study presents a fast and scalable AI approach for detecting, extracting, and describing illustrations in digitized manuscripts. Focusing on collections like the Vatican Library, our system enables efficient visual analysis across millions of pages. Our pipeline consists of three stages: (1) a fine-tuned image classification model filters out text-only pages; (2) an efficient object detection model identifies and crops illustrations; and (3) a multimodal image captioning model generates concise, human-readable descriptions. These are stored in a searchable database, allowing scholars to retrieve relevant visual materials through keyword queries. By harnessing the power of recent AI advancements, we enable large-scale visual research that was previously impractical, empowering scholars in historical studies, art history, and cultural heritage to explore visual motifs, artistic styles, and cross-cultural influences with new precision and speed. Applying our pipeline to over three million digitized manuscript pages, we automatically identified and extracted more than 200,000 unique illustrations. This scale of processing in under 0.06 seconds per page, dramatically outperforms traditional segmentation techniques in both efficiency and accessibility for visual scholarship. Our work demonstrates how cutting-edge AI tools can profoundly reshape scholarly workflows and open new avenues for multidisciplinary research in the age of digital manuscripts.

</details>


### [175] [LiveVectorLake: A Real-Time Versioned Knowledge Base Architecture for Streaming Vector Updates and Temporal Retrieval](https://arxiv.org/abs/2601.05270)
*Tarun Prajapati*

Main category: cs.IR

TL;DR: 本文提出LiveVectorLake，一种双层时间知识库架构，旨在解决RAG系统中向量索引更新难与数据湖查询慢的矛盾，支持实时语义搜索和完整版本历史管理。


<details>
  <summary>Details</summary>
Motivation: 现代RAG系统在向量索引（低延迟但难更新）与数据湖（易版本管理但查询慢）之间存在根本性架构张力，难以兼顾实时检索、持续更新与合规审计需求。

Method: 提出LiveVectorLake双层架构：(1) 基于SHA-256的内容寻址分块同步；(2) 热层（Milvus+HNSW向量索引）与冷层（Delta Lake+Parquet列式存储）分离；(3) 时序查询路由与跨层ACID一致性保障。

Result: 在100文档、5个时间点的评测中实现：更新仅重处理10–15%内容（对比全量重建100%）；当前知识检索延迟<100ms；时序查询延迟<2s；通过热/冷分层显著降低向量索引存储开销。

Conclusion: LiveVectorLake实现了查询性能、更新效率与监管合规性的协同优化，适用于需三者兼顾的生产级RAG部署。

Abstract: Modern Retrieval-Augmented Generation (RAG) systems struggle with a fundamental architectural tension: vector indices are optimized for query latency but poorly handle continuous knowledge updates, while data lakes excel at versioning but introduce query latency penalties. We introduce LiveVectorLake, a dual-tier temporal knowledge base architecture that enables real-time semantic search on current knowledge while maintaining complete version history for compliance, auditability, and point-in-time retrieval. The system introduces three core architectural contributions: (1) Content-addressable chunk-level synchronization using SHA-256 hashing for deterministic change detection without external state tracking; (2) Dual-tier storage separating hot-tier vector indices (Milvus with HNSW) from cold-tier columnar versioning (Delta Lake with Parquet), optimizing query latency and storage cost independently; (3) Temporal query routing enabling point-in-time knowledge retrieval via delta-versioning with ACID consistency across tiers. Evaluation on a 100-document corpus versioned across five time points demonstrates: (i) 10-15% re-processing of content during updates compared to 100% for full re-indexing; (ii) sub-100ms retrieval latency on current knowledge; (iii) sub-2s latency for temporal queries across version history; and (iv) storage cost optimization through hot/cold tier separation (only current chunks in expensive vector indices). The approach enables production RAG deployments requiring simultaneous optimization for query performance, update efficiency, and regulatory compliance. Code and resources: [https://github.com/praj-tarun/LiveVectorLake]

</details>


### [176] [RECOR: Reasoning-focused Multi-turn Conversational Retrieval Benchmark](https://arxiv.org/abs/2601.05461)
*Mohammed Ali,Abdelrahman Abdallah,Amit Agarwal,Hitesh Laxmichand Patel,Adam Jatowt*

Main category: cs.IR

TL;DR: 本文提出了一个面向推理型对话信息检索的新基准，包含707个跨11个领域的多轮对话（共2971轮），并设计了分解-验证框架以生成事实支撑的多轮对话和显式检索推理。实验表明，结合对话历史与推理可使检索性能翻倍，但隐式推理仍是难点。


<details>
  <summary>Details</summary>
Motivation: 现有基准将多轮对话与推理密集型检索分开处理，而真实世界的信息检索需要二者结合，因此需构建统一的推理型对话检索基准。

Method: 提出分解-验证（Decomposition-and-Verification）框架，将复杂查询转化为基于事实的多轮对话，并对原子事实进行来源验证，为每轮生成显式检索推理。

Result: 引入对话历史+推理使nDCG@10从0.236提升至0.479；推理专用模型显著优于稠密编码器；但隐式推理（尤其逻辑关系未明述时）仍具挑战性。

Conclusion: 显式建模检索推理与对话历史能大幅提升性能，但当前模型在隐式逻辑推理上仍有明显不足，需进一步研究。

Abstract: Existing benchmarks treat multi-turn conversation and reasoning-intensive retrieval separately, yet real-world information seeking requires both. To bridge this gap, we present a benchmark for reasoning-based conversational information retrieval comprising 707 conversations (2,971 turns) across eleven domains. To ensure quality, our Decomposition-and-Verification framework transforms complex queries into fact-grounded multi-turn dialogues through multi-level validation, where atomic facts are verified against sources and explicit retrieval reasoning is generated for each turn. Comprehensive evaluation reveals that combining conversation history with reasoning doubles retrieval performance (Baseline .236 $\rightarrow$ History+Reasoning .479 nDCG@10), while reasoning-specialized models substantially outperform dense encoders. Despite these gains, further analysis highlights that implicit reasoning remains challenging, particularly when logical connections are not explicitly stated in the text.

</details>


### [177] [LEAPS: An LLM-Empowered Adaptive Plugin for Taobao AI Search](https://arxiv.org/abs/2601.05513)
*Lei Wang,Jinhang Wu,Zhibin Wang,Biye Li,Haiping Hou*

Main category: cs.IR

TL;DR: 本文提出LEAPS系统，通过‘扩展-精炼’范式升级电商搜索，利用查询扩展器和相关性验证器提升自然语言搜索效果，兼顾零结果缓解与结果过载问题，已在淘宝AI搜索上线并服务数亿用户。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推动搜索从关键词转向对话式交互，但现有电商搜索架构难以适应，导致自然语言查询常返回零结果或产生大量噪声结果，用户面临查询精准性与结果可选性之间的两难。

Method: 提出LEAPS（LLM赋能的淘宝AI搜索自适应插件），在搜索流程两端插入插件：上游Query Expander采用逆数据增强、后验知识监督微调和多样性感知强化学习三阶段训练，生成互补查询组合以扩大候选商品集；下游Relevance Verifier融合OCR、评论等多源信息，结合思维链推理进行语义过滤。

Result: 离线实验与线上A/B测试表明LEAPS显著提升对话式搜索体验；其非侵入式架构既保持原有短文本检索性能，又支持低成本后端集成；自2025年8月全面部署于淘宝AI搜索，月服务用户达数亿。

Conclusion: LEAPS为传统电商搜索提供了可扩展、低耦合、高兼容的LLM增强路径，有效弥合了大模型能力与实际搜索系统之间的落地鸿沟。

Abstract: The rapid advancement of large language models has reshaped user search cognition, driving a paradigm shift from discrete keyword-based search to high-dimensional conversational interaction. However, existing e-commerce search architectures face a critical capability deficit in adapting to this change. Users are often caught in a dilemma: precise natural language descriptions frequently trigger zero-result scenarios, while the forced simplification of queries leads to decision overload from noisy, generic results. To tackle this challenge, we propose LEAPS (LLM-Empowered Adaptive Plugin for Taobao AI Search), which seamlessly upgrades traditional search systems via a "Broaden-and-Refine" paradigm. Specifically, it attaches plugins to both ends of the search pipeline: (1) Upstream, a Query Expander acts as an intent translator. It employs a novel three-stage training strategy--inverse data augmentation, posterior-knowledge supervised fine-tuning, and diversity-aware reinforcement learning--to generate adaptive and complementary query combinations that maximize the candidate product set. (2) Downstream, a Relevance Verifier serves as a semantic gatekeeper. By synthesizing multi-source data (e.g., OCR text, reviews) and leveraging chain-of-thought reasoning, it precisely filters noise to resolve selection overload. Extensive offline experiments and online A/B testing demonstrate that LEAPS significantly enhances conversational search experiences. Crucially, its non-invasive architecture preserves established retrieval performance optimized for short-text queries, while simultaneously allowing for low-cost integration into diverse back-ends. Fully deployed on Taobao AI Search since August 2025, LEAPS currently serves hundreds of millions of users monthly.

</details>


### [178] [Efficient Temporal-aware Matryoshka Adaptation for Temporal Information Retrieval](https://arxiv.org/abs/2601.05549)
*Tuan-Luc Huynh,Weiqing Wang,Trung Le,Thuy-Trang Vu,Dragan Gašević,Yuan-Fang Li,Thanh-Toan Do*

Main category: cs.IR

TL;DR: 本文提出了一种名为Temporal-aware Matryoshka Representation Learning (TMRL)的方法，通过在Matryoshka嵌入中引入时间子空间，使检索器具备时间感知能力，从而提升时序检索与RAG性能，并支持精度-效率的灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 检索器是时序检索增强生成（Temporal RAG）系统的关键瓶颈，若无法检索到时间上相关的上下文，将严重影响下游生成效果，即使大语言模型推理能力强也无济于事。

Method: 提出TMRL方法，利用Matryoshka嵌入的嵌套结构，在其中构建一个时间子空间，以增强时间信息编码能力，同时保持通用语义表征。

Result: 实验表明，TMRL能高效适配多种文本嵌入模型，在时序检索与时序RAG任务上性能优于现有非时序Matryoshka方法和已有时序方法，并支持灵活的精度-效率权衡。

Conclusion: TMRL是一种有效、高效且灵活的时间感知检索增强方法，为Temporal RAG系统提供了实用的嵌入级解决方案。

Abstract: Retrievers are a key bottleneck in Temporal Retrieval-Augmented Generation (RAG) systems: failing to retrieve temporally relevant context can degrade downstream generation, regardless of LLM reasoning. We propose Temporal-aware Matryoshka Representation Learning (TMRL), an efficient method that equips retrievers with temporal-aware Matryoshka embeddings. TMRL leverages the nested structure of Matryoshka embeddings to introduce a temporal subspace, enhancing temporal encoding while preserving general semantic representations. Experiments show that TMRL efficiently adapts diverse text embedding models, achieving competitive temporal retrieval and temporal RAG performance compared to prior Matryoshka-based non-temporal methods and prior temporal methods, while enabling flexible accuracy-efficiency trade-offs.

</details>


### [179] [Autoregressive Ranking: Bridging the Gap Between Dual and Cross Encoders](https://arxiv.org/abs/2601.05588)
*Benjamin Rozonoyer,Chong You,Michael Boratko,Himanshu Jain,Nilesh Gupta,Srinadh Bhojanapalli,Andrew McCallum,Felix Yu*

Main category: cs.IR

TL;DR: 本文提出了一种名为SToICaL的新型损失函数，用于提升基于大语言模型（LLM）的pointwise生成式排序方法的排序能力，通过在token级和item级引入排序感知监督，显著改善了排名效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based排序方法多依赖于next-token预测，该损失函数本质上对排序不敏感，尤其在pointwise监督下；而传统双编码器等方法表达能力有限。

Method: 提出SToICaL（Simple Token-Item Calibrated Loss），在pointwise生成式排序框架中同时引入token-level和item-level的排序感知监督；理论证明多token docID下的pointwise生成式排序比双编码器更具表达力。

Result: 在WordNet与ESCI数据集上的实验表明，SToICaL的两个变体有效抑制了无效docID生成，并在top-1以外的常见排序指标上取得提升。

Conclusion: SToICaL为LLM-based pointwise生成式排序提供了更有效的监督方式，兼顾效率、表达力与排序性能，推动了生成式IR的发展。

Abstract: Dual and cross encoders have long been mainstays of information retrieval (IR), but are being challenged by the emergent capabilities of LLMs. An LLM-based approach we term pointwise generative ranking - generating tokens the length of a single docID as opposed to a list in order to enable ranking via beam search - combines efficiency and expressivity benefits while leveraging the in-context capabilities of Causal Transformers. Although there is ample evidence to suggest that pretrained LLMs are well-suited for ranking, we find that the vast majority of LLM-based approaches rely on next-token prediction, a loss function which is fundamentally rank-agnostic (and especially so with pointwise supervision). In this paper, we first prove that the expressivity of pointwise generative ranking with multi-token docIDs is superior to that of dual encoders. We then propose SToICaL - a Simple Token-Item Calibrated Loss - which can incorporate rank-aware supervision at both the item and token levels within the pointwise setup. We run a suite of experiments on ranking tasks derived from WordNet (Fellbaum, 1998) and ESCI (Reddy et al., arXiv:2206.06588). Two variants of SToICaL successfully suppress the probability of invalid docID generations and improve on common ranking metrics beyond top-1 retrieval.

</details>


### [180] [Revisiting Human-vs-LLM judgments using the TREC Podcast Track](https://arxiv.org/abs/2601.05603)
*Watheq Mansour,J. Shane Culpepper,Joel Mackenzie,Andrew Yates*

Main category: cs.IR

TL;DR: 本文研究了大语言模型（LLMs）在音频转录片段相关性标注中与人类专家的一致性，发现LLM与人类专家的共识度高于TREC原始人工标注者，尤其在高分歧样本中；结果支持Sormunen（2002）关于单评估员会降低用户一致性的观点。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM相关性标注研究结论矛盾的问题，并拓展至非传统文本检索场景（如播客音频转录），探究LLM在语音检索中的可靠性及对排序影响。

Method: 在TREC 2020/2021播客数据集上，使用5种不同LLM对全部查询-片段对重标注；对比LLM与TREC评估员的一致性；并对高分歧子集开展人类专家复评。

Result: LLM与人类专家的用户一致性高于其与原始TREC评估员的一致性；高分歧样本中人类专家更倾向支持LLM判断；单评估员标注显著降低用户一致性。

Conclusion: LLM在播客检索相关性标注中展现出良好可信度，可作为辅助或替代人工标注的可靠工具；应避免依赖单一人工评估员，需采用多评估员或人机协同策略提升标注质量。

Abstract: Using large language models (LLMs) to annotate relevance is an increasingly important technique in the information retrieval community. While some studies demonstrate that LLMs can achieve high user agreement with ground truth (human) judgments, other studies have argued for the opposite conclusion. To the best of our knowledge, these studies have primarily focused on classic ad-hoc text search scenarios. In this paper, we conduct an analysis on user agreement between LLM and human experts, and explore the impact disagreement has on system rankings. In contrast to prior studies, we focus on a collection composed of audio files that are transcribed into two-minute segments -- the TREC 2020 and 2021 podcast track. We employ five different LLM models to re-assess all of the query-segment pairs, which were originally annotated by TREC assessors. Furthermore, we re-assess a small subset of pairs where LLM and TREC assessors have the highest disagreement, and found that the human experts tend to agree with LLMs more than with the TREC assessors. Our results reinforce the previous insights of Sormunen in 2002 -- that relying on a single assessor leads to lower user agreement.

</details>


### [181] [Statistical Foundations of DIME: Risk Estimation for Practical Index Selection](https://arxiv.org/abs/2601.05649)
*Giulio D'Erasmo,Cesare Campagnano,Antonio Mallia,Pierpaolo Brutti,Nicola Tonellotto,Fabrizio Silvestri*

Main category: cs.IR

TL;DR: 本文提出了一种统计上严谨的准则，用于在推理时为每个查询直接识别最优维度集合，从而减少高维密集嵌入中的冗余维度，在保持检索效果的同时平均将嵌入大小降低约50%。


<details>
  <summary>Details</summary>
Motivation: 高维稠密嵌入中存在大量噪声或冗余维度，而现有方法DIME依赖代价高昂的网格搜索预先确定所有查询的维度数量，缺乏查询自适应性。

Method: 提出一种统计上可解释的、查询依赖的维度选择准则，在推理阶段为每个查询动态选取最优维度子集，无需预设维度或网格搜索。

Result: 在多个模型和数据集上实验表明，该方法在检索效果与基线持平的同时，平均将嵌入大小压缩约50%。

Conclusion: 所提方法实现了查询级自适应维度裁剪，兼顾效率与有效性，为高效信息检索提供了新思路。

Abstract: High-dimensional dense embeddings have become central to modern Information Retrieval, but many dimensions are noisy or redundant. Recently proposed DIME (Dimension IMportance Estimation), provides query-dependent scores to identify informative components of embeddings. DIME relies on a costly grid search to select a priori a dimensionality for all the query corpus's embeddings. Our work provides a statistically grounded criterion that directly identifies the optimal set of dimensions for each query at inference time. Experiments confirm achieving parity of effectiveness and reduces embedding size by an average of $\sim50\%$ across different models and datasets at inference time.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [182] [MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs](https://arxiv.org/abs/2601.05296)
*Jiyuan Zhang,Yining Liu,Siqi Yan,Lisen Deng,Jennifer Cao,Shuqi Yang,Min Ni,Bi Xue,Shen Li*

Main category: cs.LG

TL;DR: MoEBlaze是一种内存高效的MoE训练框架，通过协同设计的系统方法（优化数据结构消除中间缓冲和激活物化、协同设计核与智能激活检查点）显著降低内存开销并提升性能，实现超4倍加速和超50%内存节省。


<details>
  <summary>Details</summary>
Motivation: 现代大规模MoE架构因稀疏性导致激活内存开销巨大（如路由缓冲区大、需物化并缓存中间张量），加剧了‘内存墙’瓶颈，限制批大小、序列长度，并增加数据搬运，阻碍性能与扩展。

Method: 提出MoEBlaze框架：(i) 端到端token分发与MoE训练方法，采用优化数据结构消除中间缓冲和激活物化；(ii) 协同设计的核配合智能激活检查点，兼顾内存缩减与性能提升。

Result: 相比现有MoE框架，MoEBlaze实现超4倍速度提升和超50%内存节省。

Conclusion: MoEBlaze通过软硬协同的内存优化方法，有效缓解MoE训练中的内存瓶颈，为大规模MoE模型高效训练提供了可行路径。

Abstract: The pervasive "memory wall" bottleneck is significantly amplified in modern large-scale Mixture-of-Experts (MoE) architectures. MoE's inherent architectural sparsity leads to sparse arithmetic compute and also introduces substantial activation memory overheads -- driven by large token routing buffers and the need to materialize and buffer intermediate tensors. This memory pressure limits the maximum batch size and sequence length that can fit on GPUs, and also results in excessive data movements that hinders performance and efficient model scaling. We present MoEBlaze, a memory-efficient MoE training framework that addresses these issues through a co-designed system approach: (i) an end-to-end token dispatch and MoE training method with optimized data structures to eliminate intermediate buffers and activation materializing, and (ii) co-designed kernels with smart activation checkpoint to mitigate memory footprint while simultaneously achieving better performance. We demonstrate that MoEBlaze can achieve over 4x speedups and over 50% memory savings compared to existing MoE frameworks.

</details>


### [183] [TIME: Temporally Intelligent Meta-reasoning Engine for Context Triggered Explicit Reasoning](https://arxiv.org/abs/2601.05300)
*Susmit Das*

Main category: cs.LG

TL;DR: 本文提出了TIME（Temporally Intelligent Meta-reasoning Engine），一种面向对话中时间感知与推理资源动态调度的行为对齐框架，通过引入时间标签、静默轮次和嵌入式推理块，使模型能按需、就地触发简短推理，显著提升时序对话理解能力并大幅降低推理开销。


<details>
  <summary>Details</summary>
Motivation: 现有推理型大模型将显式推理固定为长而全局的前缀，成本高、不可审计、无法中途触发；对话模型又普遍忽略时间结构，难以建模真实对话中的时序关系与沉默间隙。

Method: 提出TIME框架：在对话中注入ISO 8601时间标签、tick turn（静默间隙）和可任意插入的<reason>块；设计四阶段课程学习策略，含小批量全批次对齐步骤，训练Qwen3系列模型实现上下文敏感的轻量级推理调度。

Result: 在自建时序对话基准TIMEBench（涵盖时序推理、间隔常识、异常检测与连贯性）上，4B–32B规模Qwen3模型在启用/禁用推理模式下均超越基线，推理token减少约一个数量级。

Conclusion: 显式推理应作为受话语与时间线索调控的动态资源，而非固定行为；TIME验证了轻量、嵌入式、时序感知的推理调度在保持性能的同时大幅提升效率与可控性。

Abstract: Reasoning oriented large language models often expose explicit "thinking" as long, turn-global traces at the start of every response, either always on or toggled externally at inference time. While useful for arithmetic, programming, and problem solving, this design is costly, blurs claim level auditability, and cannot re-trigger explicit reasoning once the model begins presenting. Dialogue models are also largely blind to temporal structure, treating replies after seconds and replies after weeks as equivalent unless time is stated in text. We introduce TIME, the Temporally Intelligent Meta-reasoning Engine, a behavioral alignment framework that treats explicit reasoning as a context sensitive resource driven by discourse and temporal cues. TIME augments dialogue with optional ISO 8601 <time> tags, tick turns that represent silent gaps, and short <think> blocks that can appear anywhere in a reply. A four-phase curriculum including a small, maximally diverse full-batch alignment step trains Qwen3 dense models to invoke brief, in-place reasoning bursts and keep user facing text compact. We evaluate with TIMEBench, a temporally grounded dialogue benchmark probing chronology, commonsense under gaps and offsets, anomaly detection, and continuity. Across 4B to 32B scales, TIME improves TIMEBench scores over base Qwen3 in both thinking and no-thinking modes while reducing reasoning tokens by about an order of magnitude. Our training data and code are available at https://github.com/The-Coherence-Initiative/TIME and TIMEBench is available at https://github.com/The-Coherence-Initiative/TIMEBench

</details>


### [184] [Ontology Neural Networks for Topologically Conditioned Constraint Satisfaction](https://arxiv.org/abs/2601.05304)
*Jaehong Oh*

Main category: cs.LG

TL;DR: 本文提出一种增强型神经符号推理框架，结合拓扑条件与梯度稳定机制，在保持语义连贯性的同时提升物理与逻辑约束满足能力。


<details>
  <summary>Details</summary>
Motivation: 神经符号推理系统在维持语义一致性的同时满足物理和逻辑约束方面存在根本性挑战。

Method: 基于本体神经网络，引入Forman-Ricci曲率刻画图拓扑结构，采用Deep Delta Learning实现约束投影中的稳定秩一扰动，并使用协方差矩阵自适应进化策略（CMA-ES）进行参数优化。

Result: 实验表明，该方法将平均能量从基线11.68降至1.15，约束满足成功率高达95%，具备种子无关收敛性与良好可扩展性（达20节点）。

Conclusion: 拓扑结构可有效指导基于梯度的优化过程，且不牺牲可解释性与计算效率。

Abstract: Neuro-symbolic reasoning systems face fundamental challenges in maintaining semantic coherence while satisfying physical and logical constraints. Building upon our previous work on Ontology Neural Networks, we present an enhanced framework that integrates topological conditioning with gradient stabilization mechanisms. The approach employs Forman-Ricci curvature to capture graph topology, Deep Delta Learning for stable rank-one perturbations during constraint projection, and Covariance Matrix Adaptation Evolution Strategy for parameter optimization. Experimental evaluation across multiple problem sizes demonstrates that the method achieves mean energy reduction to 1.15 compared to baseline values of 11.68, with 95 percent success rate in constraint satisfaction tasks. The framework exhibits seed-independent convergence and graceful scaling behavior up to twenty-node problems, suggesting that topological structure can inform gradient-based optimization without sacrificing interpretability or computational efficiency.

</details>


### [185] [When the Server Steps In: Calibrated Updates for Fair Federated Learning](https://arxiv.org/abs/2601.05352)
*Tianrun Yu,Kaixiang Zhao,Cheng Zhang,Anjun Gao,Yueyang Quan,Zhuqing Liu,Minghong Fang*

Main category: cs.LG

TL;DR: 本文提出了一种名为EquFL的新型服务器端去偏方法，用于在联邦学习中提升跨群体的公平性，无需修改客户端训练协议，通过服务器端校准更新来减少偏差，并在理论和实验上验证其有效性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）面临确保不同人口统计群体间公平性的关键挑战，现有公平性感知去偏方法往往需要修改客户端训练协议或缺乏聚合策略的灵活性。

Method: 提出EquFL，一种纯服务器端的去偏方法：服务器接收各客户端模型更新后，生成一个校准更新，并将其与聚合后的客户端更新结合，得到调整后的全局模型以降低偏差。

Result: 理论证明EquFL能收敛到FedAvg所达到的最优全局模型，并有效降低训练过程中的公平性损失；实验表明EquFL显著缓解系统内偏差。

Conclusion: EquFL是一种灵活、无需客户端修改、具备理论保证且实践有效的联邦学习公平性增强方案。

Abstract: Federated learning (FL) has emerged as a transformative distributed learning paradigm, enabling multiple clients to collaboratively train a global model under the coordination of a central server without sharing their raw training data. While FL offers notable advantages, it faces critical challenges in ensuring fairness across diverse demographic groups. To address these fairness concerns, various fairness-aware debiasing methods have been proposed. However, many of these approaches either require modifications to clients' training protocols or lack flexibility in their aggregation strategies. In this work, we address these limitations by introducing EquFL, a novel server-side debiasing method designed to mitigate bias in FL systems. EquFL operates by allowing the server to generate a single calibrated update after receiving model updates from the clients. This calibrated update is then integrated with the aggregated client updates to produce an adjusted global model that reduces bias. Theoretically, we establish that EquFL converges to the optimal global model achieved by FedAvg and effectively reduces fairness loss over training rounds. Empirically, we demonstrate that EquFL significantly mitigates bias within the system, showcasing its practical effectiveness.

</details>


### [186] [GlyRAG: Context-Aware Retrieval-Augmented Framework for Blood Glucose Forecasting](https://arxiv.org/abs/2601.05353)
*Shovito Barua Soumma,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: 本文提出GlyRAG，一种基于大语言模型（LLM）的检索增强型血糖预测框架，仅利用CGM数据提取语义上下文，无需额外传感器，在两个T1D队列中显著提升长时程血糖预测精度与临床安全性。


<details>
  <summary>Details</summary>
Motivation: 现有血糖预测模型将CGM数据视为纯数值序列，忽略临床语义；引入多模态传感器又难以规模化部署；而LLM在时序预测中的上下文提取能力尚未在糖尿病管理中被探索。

Method: GlyRAG利用LLM作为上下文代理生成临床摘要，通过语言模型嵌入摘要，并与基于patch的血糖表征在多模态Transformer中融合；采用跨翻译损失对齐文本与生理嵌入；再通过检索模块在嵌入空间中查找相似历史片段，借助交叉注意力整合类比案例后进行预测。

Result: 在两个T1D队列上，GlyRAG相较SOTA方法RMSE最高降低39%，较基线再降1.7%；临床评估显示85%预测落于安全区，对低/高血糖事件预测准确率提升51%。

Conclusion: 仅依赖CGM数据、结合LLM语义建模与检索增强的框架可显著提升长时程血糖预测的准确性与临床可靠性，为未来糖尿病智能决策支持系统提供新范式。

Abstract: Accurate forecasting of blood glucose from CGM is essential for preventing dysglycemic events, thus enabling proactive diabetes management. However, current forecasting models treat blood glucose readings captured using CGMs as a numerical sequence, either ignoring context or relying on additional sensors/modalities that are difficult to collect and deploy at scale. Recently, LLMs have shown promise for time-series forecasting tasks, yet their role as agentic context extractors in diabetes care remains largely unexplored. To address these limitations, we propose GlyRAG, a context-aware, retrieval-augmented forecasting framework that derives semantic understanding of blood glucose dynamics directly from CGM traces without requiring additional sensor modalities. GlyRAG employs an LLM as a contextualization agent to generate clinical summaries. These summaries are embedded by a language model and fused with patch-based glucose representations in a multimodal transformer architecture with a cross translation loss aligining textual and physiological embeddings. A retrieval module then identifies similar historical episodes in the learned embedding space and uses cross-attention to integrate these case-based analogues prior to making a forecasting inference. Extensive evaluations on two T1D cohorts show that GlyRAG consistently outperforms state-of-the art methods, achieving up to 39% lower RMSE and a further 1.7% reduction in RMSE over the baseline. Clinical evaluation shows that GlyRAG places 85% predictions in safe zones and achieves 51% improvement in predicting dysglycemic events across both cohorts. These results indicate that LLM-based contextualization and retrieval over CGM traces can enhance the accuracy and clinical reliability of long-horizon glucose forecasting without the need for extra sensors, thus supporting future agentic decision-support tools for diabetes management.

</details>


### [187] [The Kernel Manifold: A Geometric Approach to Gaussian Process Model Selection](https://arxiv.org/abs/2601.05371)
*Md Shafiqul Islam,Shakti Prasad Padhy,Douglas Allaire,Raymundo Arróyave*

Main category: cs.LG

TL;DR: 本文提出了一种基于核间几何结构的贝叶斯优化框架，利用GP先验间的期望散度距离，在多维缩放（MDS）嵌入的连续欧氏流形上高效搜索最优协方差核，显著提升预测精度与不确定性校准能力。


<details>
  <summary>Details</summary>
Motivation: 高斯过程回归性能高度依赖协方差核的选择，而核选择是当前最困难且计算昂贵的步骤之一。

Method: 构建基于‘核之核’几何的贝叶斯优化框架：用期望散度定义GP先验间距离，通过MDS将离散核库嵌入连续欧氏空间；以MDS坐标为特征，以对数边缘似然为目标函数进行贝叶斯优化。

Result: 在合成数据、真实时间序列及增材制造熔池几何预测任务中，该方法在预测精度和不确定性校准上均优于包括大语言模型引导搜索在内的多种基线方法。

Conclusion: 该框架建立了可复用的概率几何结构用于核搜索，对高斯过程建模和深度核学习具有直接应用价值。

Abstract: Gaussian Process (GP) regression is a powerful nonparametric Bayesian framework, but its performance depends critically on the choice of covariance kernel. Selecting an appropriate kernel is therefore central to model quality, yet remains one of the most challenging and computationally expensive steps in probabilistic modeling. We present a Bayesian optimization framework built on kernel-of-kernels geometry, using expected divergence-based distances between GP priors to explore kernel space efficiently. A multidimensional scaling (MDS) embedding of this distance matrix maps a discrete kernel library into a continuous Euclidean manifold, enabling smooth BO. In this formulation, the input space comprises kernel compositions, the objective is the log marginal likelihood, and featurization is given by the MDS coordinates. When the divergence yields a valid metric, the embedding preserves geometry and produces a stable BO landscape. We demonstrate the approach on synthetic benchmarks, real-world time-series datasets, and an additive manufacturing case study predicting melt-pool geometry, achieving superior predictive accuracy and uncertainty calibration relative to baselines including Large Language Model (LLM)-guided search. This framework establishes a reusable probabilistic geometry for kernel search, with direct relevance to GP modeling and deep kernel learning.

</details>


### [188] [Inverting Non-Injective Functions with Twin Neural Network Regression](https://arxiv.org/abs/2601.05378)
*Sebastian J. Wetzel*

Main category: cs.LG

TL;DR: 本文提出了一种基于双神经网络回归与k近邻搜索的确定性框架，用于求解非单射函数的逆问题，适用于输入输出维度相同或不匹配的情形，并在玩具问题和机器人臂控制任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 非单射函数不可逆，但在实际应用（如机器人控制）中常需从输出反推可能的输入；现有方法难以系统处理非单射性及多解选择问题。

Method: 提出双神经网络回归模型，学习从锚点输入x^anchor出发、根据目标输出变化(y^anchor→y^new)预测输入调整量；结合k近邻搜索构建确定性逆推框架。

Result: 在数据驱动和解析表达式定义的非单射函数（含玩具问题与机器人臂动力学）上成功实现逆映射，能稳定输出合理输入解。

Conclusion: 该方法为非单射函数的逆问题提供了可扩展、确定性且无需显式建模的实用解决方案，拓展了神经网络在逆向建模中的适用边界。

Abstract: Non-injective functions are not invertible. However, non-injective functions can be restricted to sub-domains on which they are locally injective and surjective and thus invertible if the dimensionality between input and output spaces are the same. Further, even if the dimensionalities do not match it is often possible to choose a preferred solution from many possible solutions. Twin neural network regression is naturally capable of incorporating these properties to invert non-injective functions. Twin neural network regression is trained to predict adjustments to well known input variables $\mathbf{x}^{\text{anchor}}$ to obtain an estimate for an unknown $\mathbf{x}^{\text{new}}$ under a change of the target variable from $\mathbf{y}^{\text{anchor}}$ to $\mathbf{y}^{\text{new}}$. In combination with k-nearest neighbor search, I propose a deterministic framework that finds input parameters to a given target variable of non-injective functions. The method is demonstrated by inverting non-injective functions describing toy problems and robot arm control that are a) defined by data or b) known as mathematical formula.

</details>


### [189] [Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.05407)
*Minwoo Cho,Batuhan Altundas,Matthew Gombolay*

Main category: cs.LG

TL;DR: 本文提出HINT框架，通过分层强化学习和伪离策略学习解决多智能体强化学习中知识蒸馏的三大瓶颈：高性能教学策略合成难、教师在分布外状态推理困难、师生观测空间不匹配。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在多智能体强化学习中面临三大瓶颈：复杂领域中难以合成高性能教学策略、教师在分布外状态推理困难、以及集中式教师与分布式学生观测空间不匹配。

Method: 提出HINT（分层交互式教师迁移）框架，结合分层强化学习构建可扩展且高性能的教师；引入伪离策略强化学习，使教师策略能利用教师和学生经验进行更新以提升分布外适应能力；采用基于性能的过滤机制，仅保留结果相关指导以缓解观测空间不匹配问题。

Result: 在FireCommander（资源分配）和MARINE（战术作战）等具有挑战性的协同任务上，HINT显著优于基线方法，成功率提升60%至165%。

Conclusion: HINT有效解决了MARL中知识蒸馏的关键瓶颈，为集中训练-分散执行范式提供了更高效、鲁棒的教师-学生迁移方案。

Abstract: Knowledge distillation (KD) has the potential to accelerate MARL by employing a centralized teacher for decentralized students but faces key bottlenecks. Specifically, there are (1) challenges in synthesizing high-performing teaching policies in complex domains, (2) difficulties when teachers must reason in out-of-distribution (OOD) states, and (3) mismatches between the decentralized students' and the centralized teacher's observation spaces. To address these limitations, we propose HINT (Hierarchical INteractive Teacher-based transfer), a novel KD framework for MARL in a centralized training, decentralized execution setup. By leveraging hierarchical RL, HINT provides a scalable, high-performing teacher. Our key innovation, pseudo off-policy RL, enables the teacher policy to be updated using both teacher and student experience, thereby improving OOD adaptation. HINT also applies performance-based filtering to retain only outcome-relevant guidance, reducing observation mismatches. We evaluate HINT on challenging cooperative domains (e.g., FireCommander for resource allocation, MARINE for tactical combat). Across these benchmarks, HINT outperforms baselines, achieving improvements of 60% to 165% in success rate.

</details>


### [190] [Imitation Learning for Combinatorial Optimisation under Uncertainty](https://arxiv.org/abs/2601.05383)
*Prakash Gawas,Antoine Legrain,Louis-Martin Rousseau*

Main category: cs.LG

TL;DR: 本文提出了一种针对组合优化中不确定性问题的模仿学习专家分类体系，并设计了支持多专家查询与交互式学习的广义DAgger算法，在动态医患分配问题上验证了随机性专家和交互式学习的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习研究中专家构造方式多样但缺乏统一框架来刻画其建模假设、计算特性及对学习性能的影响。

Method: 构建了沿不确定性处理方式、最优性水平和与学习者交互模式三个维度的专家分类体系，并在此基础上提出支持多专家查询、专家聚合与灵活交互策略的广义DAgger算法。

Result: 在动态医患分配问题上的实验表明：由随机性专家训练出的策略优于确定性或全信息专家；交互式学习能以更少专家示范提升解质量；聚合确定性专家可在随机优化计算困难时作为有效替代方案。

Conclusion: 专家类型与交互机制对模仿学习效果具有显著影响，所提出的分类体系与广义DAgger算法为组合优化中的模仿学习提供了系统化、可扩展的方法论基础。

Abstract: Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance.
  This paper introduces a systematic taxonomy of experts for IL in combinatorial optimisation under uncertainty. Experts are classified along three dimensions: (i) their treatment of uncertainty, including myopic, deterministic, full-information, two-stage stochastic, and multi-stage stochastic formulations; (ii) their level of optimality, distinguishing task-optimal and approximate experts; and (iii) their interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) algorithm that supports multiple expert queries, expert aggregation, and flexible interaction strategies.
  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.

</details>


### [191] [DynaSTy: A Framework for SpatioTemporal Node Attribute Prediction in Dynamic Graphs](https://arxiv.org/abs/2601.05391)
*Namrata Banerji,Tanya Berger-Wolf*

Main category: cs.LG

TL;DR: 本文提出了一种端到端的动态边偏向时空模型，用于动态图上节点属性的多步预测，通过将时变邻接矩阵作为可学习注意力偏置，并结合掩码预训练与调度采样等策略，显著提升长时序预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有时空图神经网络通常假设图结构静态，难以建模真实世界中随时间演化的动态图（如金融信任网络、脑网络等），亟需能处理样本级图结构变化的多步预测方法。

Method: 基于Transformer架构，将时序节点特征和时序邻接矩阵联合建模；引入动态邻接矩阵作为自适应注意力偏置；采用掩码节点-时间预训练目标；结合调度采样与跨预测步长加权损失以缓解误差累积。

Result: 在多个动态图预测基准上，该方法在RMSE和MAE指标上持续优于强基线模型。

Conclusion: 所提模型有效建模动态图的时空演化特性，支持跨系统（如不同被试的脑网络）的泛化预测，为动态图多步预测提供了新范式。

Abstract: Accurate multistep forecasting of node-level attributes on dynamic graphs is critical for applications ranging from financial trust networks to biological networks. Existing spatiotemporal graph neural networks typically assume a static adjacency matrix. In this work, we propose an end-to-end dynamic edge-biased spatiotemporal model that ingests a multi-dimensional timeseries of node attributes and a timeseries of adjacency matrices, to predict multiple future steps of node attributes. At each time step, our transformer-based model injects the given adjacency as an adaptable attention bias, allowing the model to focus on relevant neighbors as the graph evolves. We further deploy a masked node-time pretraining objective that primes the encoder to reconstruct missing features, and train with scheduled sampling and a horizon-weighted loss to mitigate compounding error over long horizons. Unlike prior work, our model accommodates dynamic graphs that vary across input samples, enabling forecasting in multi-system settings such as brain networks across different subjects, financial systems in different contexts, or evolving social systems. Empirical results demonstrate that our method consistently outperforms strong baselines on Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE).

</details>


### [192] [Efficient Inference for Noisy LLM-as-a-Judge Evaluation](https://arxiv.org/abs/2601.05420)
*Yiqun T Chen,Sizhu Lu,Sijia Li,Moran Guo,Shengyi Li*

Main category: cs.LG

TL;DR: 本文系统研究了两种用于校正大语言模型（LLM）作为评判者时测量误差的方法——基于误分类模型的直接校正与基于代理结果的预测驱动推断（PPI），并利用半参数效率理论统一分析其性能，证明PPI在特定条件下具有更小的渐近方差。


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-judge存在系统性偏差，需有效校正以提升评估可靠性。

Method: 采用半参数效率理论，推导高效影响函数（EIF）估计量，统一分析Rogan-Gladen类校正与PPI两类方法，并通过模拟和真实数据验证。

Result: 理论与实验表明，PPI类估计量在满足一定条件时渐近方差严格小于测量误差校正方法。

Conclusion: PPI是一种更具统计效率的LLM评判偏差校正范式，尤其适用于小规模人工标注数据场景。

Abstract: Large language models (LLMs) are increasingly used as automatic evaluators of generative AI outputs, a paradigm often referred to as "LLM-as-a-judge." In practice, LLM judges are imperfect predictions for the underlying truth and can exhibit systematic, non-random errors. Two main approaches have recently been proposed to address this issue: (i) direct measurementerror correction based on misclassification models such as Rogan-Gladen-style estimators, and (ii) surrogate-outcome approaches such as prediction-powered inference (PPI), which correct bias by calibrating prediction residuals on a small set of gold-standard human labels. In this paper, we systematically study the performance of these two approaches for estimating mean parameters (e.g., average benchmark scores or pairwise win rates). Leveraging tools from semiparametric efficiency theory, we unify the two classes of estimators by deriving explicit forms of efficient influence function (EIF)-based efficient estimators and characterize conditions under which PPI-style estimators attain strictly smaller asymptotic variance than measurement-error corrections. We verify our theoretical results in simulations and demonstrate the methods on real-data examples. We provide an implementation of the benchmarked methods and comparison utilities at https://github.com/yiqunchen/debias-llm-as-a-judge.

</details>


### [193] [Prediction of Fault Slip Tendency in CO${_2}$ Storage using Data-space Inversion](https://arxiv.org/abs/2601.05431)
*Xiaowen He,Su Jiang,Louis J. Durlofsky*

Main category: cs.LG

TL;DR: 本文提出了一种基于变分自编码器（VAE）的数据空间反演（DSI）框架，用于CO₂封存项目中压力、应力、应变及断层滑动倾向的快速不确定性量化与预测，避免了传统后验地质建模，仅需约1000次先验模拟即可实现高精度后验推断。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的历史匹配方法在含断层的耦合渗流-地质力学问题中难以应用，亟需一种不依赖后验地质建模、能高效处理高维场数据的不确定性量化方法。

Method: 构建VAE（含堆叠卷积LSTM层）学习先验模拟生成的压力、应变、有效正应力和剪应力场的低维隐变量表征；结合数据空间反演（DSI），利用监测井观测的压力和应变数据，直接在隐空间中推断后验分布，无需生成后验地质模型。

Result: 在含两条断层的三维合成模型上验证表明，该DSI-VAE框架能准确预测压力、应变、应力场及断层滑动倾向，并显著降低关键地质力学与断层参数的不确定性。

Conclusion: DSI-VAE是一种高效、免后验建模的数据驱动反演新范式，适用于复杂耦合渗流-地质力学系统的实时风险评估与决策支持。

Abstract: Accurately assessing the potential for fault slip is essential in many subsurface operations. Conventional model-based history matching methods, which entail the generation of posterior geomodels calibrated to observed data, can be challenging to apply in coupled flow-geomechanics problems with faults. In this work, we implement a variational autoencoder (VAE)-based data-space inversion (DSI) framework to predict pressure, stress and strain fields, and fault slip tendency, in CO${_2}$ storage projects. The main computations required by the DSI workflow entail the simulation of O(1000) prior geomodels. The posterior distributions for quantities of interest are then inferred directly from prior simulation results and observed data, without the need to generate posterior geomodels. The model used here involves a synthetic 3D system with two faults. Realizations of heterogeneous permeability and porosity fields are generated using geostatistical software, and uncertain geomechanical and fault parameters are sampled for each realization from prior distributions. Coupled flow-geomechanics simulations for these geomodels are conducted using GEOS. A VAE with stacked convolutional long short-term memory layers is trained, using the prior simulation results, to represent pressure, strain, effective normal stress and shear stress fields in terms of latent variables. The VAE parameterization is used with DSI for posterior predictions, with monitoring wells providing observed pressure and strain data. Posterior results for synthetic true models demonstrate that the DSI-VAE framework gives accurate predictions for pressure, strain, and stress fields and for fault slip tendency. The framework is also shown to reduce uncertainty in key geomechanical and fault parameters.

</details>


### [194] [RingSQL: Generating Synthetic Data with Schema-Independent Templates for Text-to-SQL Reasoning Models](https://arxiv.org/abs/2601.05451)
*Marko Sterbentz,Kevin Cushing,Cameron Barrie,Kristian J. Hammond*

Main category: cs.LG

TL;DR: RingSQL提出一种混合数据生成框架，结合schema-independent查询模板与LLM重述自然语言问题，在保证SQL正确性的同时提升语言多样性，显著提升text-to-SQL模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有text-to-SQL训练数据稀缺；人工构建成本高，合成方法在可靠性与可扩展性之间难以兼顾：模板法正确但不通用，LLM生成法可扩展但质量与正确性无保障。

Method: RingSQL融合schema-independent的SQL查询模板与LLM驱动的自然语言问题 paraphrasing，确保跨schema的SQL正确性与语言表达多样性。

Result: 在六个text-to-SQL基准上，使用RingSQL生成数据训练的模型平均准确率提升+2.3%，优于其他合成数据方案。

Conclusion: RingSQL在保持SQL语义正确性的前提下实现了高质量、可扩展、schema-independent的合成数据生成，为text-to-SQL任务提供了实用且高效的数据增强方案。

Abstract: Recent advances in text-to-SQL systems have been driven by larger models and improved datasets, yet progress is still limited by the scarcity of high-quality training data. Manual data creation is expensive, and existing synthetic methods trade off reliability and scalability. Template-based approaches ensure correct SQL but require schema-specific templates, while LLM-based generation scales easily but lacks quality and correctness guarantees. We introduce RingSQL, a hybrid data generation framework that combines schema-independent query templates with LLM-based paraphrasing of natural language questions. This approach preserves SQL correctness across diverse schemas while providing broad linguistic variety. In our experiments, we find that models trained using data produced by RingSQL achieve an average gain in accuracy of +2.3% across six text-to-SQL benchmarks when compared to models trained on other synthetic data. We make our code available at https://github.com/nu-c3lab/RingSQL.

</details>


### [195] [Efficient Differentiable Causal Discovery via Reliable Super-Structure Learning](https://arxiv.org/abs/2601.05474)
*Pingchuan Ma,Qixin Zhang,Shuai Wang,Dacheng Tao*

Main category: cs.LG

TL;DR: 本文提出ALVGL方法，通过稀疏低秩分解学习数据精度矩阵，并利用ADMM优化以构建包含真实因果图的超结构，从而提升可微因果发现的效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有可微因果发现方法在高维数据或存在潜变量混杂因素时，受限于搜索空间大、目标函数复杂及图论约束困难等问题；利用超结构引导优化虽有潜力，但难以高效、适配地学习合适粒度的超结构。

Method: ALVGL采用稀疏-低秩分解学习精度矩阵，设计ADMM算法优化该分解，识别与因果结构最相关精度矩阵成分，进而构造保证包含真实因果图的超结构，并以此初始化标准可微因果发现方法。

Result: ALVGL在多种结构因果模型（含高斯/非高斯、有/无未测混杂）下均有效，在合成与真实数据集上达到SOTA精度，并显著提升优化效率。

Conclusion: ALVGL是一种通用、可靠且高效的可微因果发现增强框架，能兼顾准确性与计算效率。

Abstract: Recently, differentiable causal discovery has emerged as a promising approach to improve the accuracy and efficiency of existing methods. However, when applied to high-dimensional data or data with latent confounders, these methods, often based on off-the-shelf continuous optimization algorithms, struggle with the vast search space, the complexity of the objective function, and the nontrivial nature of graph-theoretical constraints. As a result, there has been a surge of interest in leveraging super-structures to guide the optimization process. Nonetheless, learning an appropriate super-structure at the right level of granularity, and doing so efficiently across various settings, presents significant challenges.
  In this paper, we propose ALVGL, a novel and general enhancement to the differentiable causal discovery pipeline. ALVGL employs a sparse and low-rank decomposition to learn the precision matrix of the data. We design an ADMM procedure to optimize this decomposition, identifying components in the precision matrix that are most relevant to the underlying causal structure. These components are then combined to construct a super-structure that is provably a superset of the true causal graph. This super-structure is used to initialize a standard differentiable causal discovery method with a more focused search space, thereby improving both optimization efficiency and accuracy.
  We demonstrate the versatility of ALVGL by instantiating it across a range of structural causal models, including both Gaussian and non-Gaussian settings, with and without unmeasured confounders. Extensive experiments on synthetic and real-world datasets show that ALVGL not only achieves state-of-the-art accuracy but also significantly improves optimization efficiency, making it a reliable and effective solution for differentiable causal discovery.

</details>


### [196] [MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization](https://arxiv.org/abs/2601.05475)
*Jiefu Ou,Sapana Chaudhary,Kaj Bostrom,Nathaniel Weir,Shuai Zhang,Huzefa Rangwala,George Karypis*

Main category: cs.LG

TL;DR: 本文提出MaxCode，一种基于推理时搜索算法的LLM代码优化框架，通过执行反馈迭代改进代码，结合自然语言批评模型和生成式reward-to-go模型，在CUDA和C++优化基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用编码任务中表现出色，但在代码优化方面面临两大挑战：一是编写高性能代码（如CUDA内核、竞赛级CPU代码）需要系统、算法和特定语言的专业知识；二是需解读非二值化的性能指标（如运行时间、设备利用率），而不仅是正确性。

Method: 提出MaxCode框架，将现有搜索方法统一为最大奖励强化学习框架，模块化观察与动作价值函数；引入自然语言批评模型，将原始执行反馈转化为错误与性能瓶颈的诊断性见解及历史最佳折扣奖励；训练生成式reward-to-go模型，利用rollout获得的动作价值对候选解重排序以增强探索。

Result: 在KernelBench（CUDA）和PIE（C++）优化基准测试中，MaxCode相比基线方法在绝对加速值上提升20.3%，在相对加速排名上提升10.1%。

Conclusion: 推理时基于执行反馈的搜索策略，辅以自然语言诊断与reward-to-go建模，可有效提升LLM在专业级代码优化任务中的性能表现。

Abstract: Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we explore inference-time search algorithms that guide the LLM to discover better solutions through iterative refinement based on execution feedback. Our approach, called MaxCode unifies existing search methods under a max-reward reinforcement learning framework, making the observation and action-value functions modular for modification. To enhance the observation space, we integrate a natural language critique model that converts raw execution feedback into diagnostic insights about errors and performance bottlenecks, and the best-discounted reward seen so far. Together, these provide richer input to the code proposal function. To improve exploration during search, we train a generative reward-to-go model using action values from rollouts to rerank potential solutions. Testing on the KernelBench (CUDA) and PIE (C++) optimization benchmarks shows that MaxCode improves optimized code performance compared to baselines, achieving 20.3% and 10.1% relative improvements in absolute speedup value and relative speedup ranking, respectively.

</details>


### [197] [Hi-ZFO: Hierarchical Zeroth- and First-Order LLM Fine-Tuning via Importance-Guided Tensor Selection](https://arxiv.org/abs/2601.05501)
*Feihu Jin,Ying Tan*

Main category: cs.LG

TL;DR: 本文提出Hi-ZFO，一种结合零阶（ZO）与一阶（FO）优化的分层混合框架，用于大语言模型微调：对关键层用精确FO更新，对非关键层引入ZO以提供有益随机性，从而兼顾探索能力与收敛速度，在生成、数学及代码推理任务中实现更优性能和更快训练。


<details>
  <summary>Details</summary>
Motivation: 标准一阶优化易陷入尖锐且泛化差的极小值；零阶方法虽探索性强但收敛慢，且在生成任务中因输出空间巨大导致估计方差高、噪声大、效率低。

Method: 提出分层零阶与一阶混合优化（Hi-ZFO）：先进行层重要性分析，对关键层使用一阶梯度更新，对非关键层采用零阶优化，并将ZO显式设计为引入‘有益随机性’以帮助跳出一阶优化易陷的局部极小。

Result: 在多种生成、数学推理和代码推理任务上验证，Hi-ZFO在提升性能的同时显著缩短训练时间。

Conclusion: 分层混合优化（Hi-ZFO）能有效协同FO的精度与ZO的探索性，是提升大语言模型微调效果与效率的新范式。

Abstract: Fine-tuning large language models (LLMs) using standard first-order (FO) optimization often drives training toward sharp, poorly generalizing minima. Conversely, zeroth-order (ZO) methods offer stronger exploratory behavior without relying on explicit gradients, yet suffer from slow convergence. More critically, our analysis reveals that in generative tasks, the vast output and search space significantly amplify estimation variance, rendering ZO methods both noisy and inefficient. To address these challenges, we propose \textbf{Hi-ZFO} (\textbf{Hi}erarchical \textbf{Z}eroth- and \textbf{F}irst-\textbf{O}rder optimization), a hybrid framework designed to synergize the precision of FO gradients with the exploratory capability of ZO estimation. Hi-ZFO adaptively partitions the model through layer-wise importance profiling, applying precise FO updates to critical layers while leveraging ZO optimization for less sensitive ones. Notably, ZO in Hi-ZFO is not merely a memory-saving surrogate; it is intentionally introduced as a source of "beneficial stochasticity" to help the model escape the local minima where pure FO optimization tends to stagnate. Validated across diverse generative, mathematical, and code reasoning tasks, Hi-ZFO consistently achieves superior performance while significantly reducing the training time. These results demonstrate the effectiveness of hierarchical hybrid optimization for LLM fine-tuning.

</details>


### [198] [Over-Searching in Search-Augmented Large Language Models](https://arxiv.org/abs/2601.05503)
*Roy Xie,Deepak Gopinath,David Qiu,Dong Lin,Haitian Sun,Saloni Potdar,Bhuwan Dhingra*

Main category: cs.LG

TL;DR: 本文系统评估了搜索增强型大语言模型中的“过度搜索”问题，发现其在多种场景下普遍存在且影响性能与效率，并提出了新指标TPC和数据集OverSearchQA以推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 搜索增强型大语言模型常在无需检索时仍调用搜索工具，导致计算浪费和幻觉，亟需系统性分析与缓解。

Method: 通过多维度（查询类型、模型类别、检索条件、多轮对话）实证评估过度搜索现象；提出新评估指标Tokens Per Correctness（TPC）；设计并发布OverSearchQA数据集；探索查询级与检索级缓解策略。

Result: 发现搜索提升可回答问题的准确性但损害不可回答问题的拒答能力；复杂推理模型和噪声检索更易引发过度搜索；检索证据中含负面证据可改善拒答；TPC能有效衡量性能-成本权衡。

Conclusion: 过度搜索是搜索增强LLM的关键瓶颈，需从查询判断、证据筛选与评估标准三方面协同优化，OverSearchQA为后续研究提供了基准支持。

Abstract: Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.

</details>


### [199] [Toward an Integrated Cross-Urban Accident Prevention System: A Multi-Task Spatial-Temporal Learning Framework for Urban Safety Management](https://arxiv.org/abs/2601.05521)
*Jiayu Fang,Zhiqi Shao,Haoning Xi,Boris Choy,Junbin Gao*

Main category: cs.LG

TL;DR: 本文提出了一种名为MLA-STNet的跨城市事故预防系统，通过多任务学习框架整合时空地理与语义信息，有效应对城市事故数据的异质性、稀疏性与噪声问题，并在纽约和芝加哥真实数据上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 城市事故数据具有异质性、报告不一致、稀疏、周期性及噪声大等特点，加之治理碎片化和标准不兼容，长期阻碍跨城市集成事故预防框架的构建。

Method: 提出MLA-STNet模型，包含两个模块：(i) Spatio-Temporal Geographical Mamba-Attention (STG-MA)，用于抑制不稳定时空波动并增强长程时序依赖；(ii) Spatio-Temporal Semantic Mamba-Attention (STS-MA)，采用共享参数设计缓解跨城异质性，同时保留各城市语义表征空间。

Result: 在纽约和芝加哥真实数据上的75组实验表明，相比SOTA基线，MLA-STNet在RMSE上降低最多6%，Recall提升8%，MAP提升5%，且在50%输入噪声下性能波动小于1%。

Conclusion: MLA-STNet实现了对异构城市事故数据的统一建模，具备可扩展性、鲁棒性与可解释性，为协同式、数据驱动的城市安全管理提供了新范式。

Abstract: The development of a cross-city accident prevention system is particularly challenging due to the heterogeneity, inconsistent reporting, and inherently clustered, sparse, cyclical, and noisy nature of urban accident data. These intrinsic data properties, combined with fragmented governance and incompatible reporting standards, have long hindered the creation of an integrated, cross-city accident prevention framework. To address this gap, we propose the Mamba Local-ttention Spatial-Temporal Network MLA-STNet, a unified system that formulates accident risk prediction as a multi-task learning problem across multiple cities. MLA-STNet integrates two complementary modules: (i)the Spatio-Temporal Geographical Mamba-Attention (STG-MA), which suppresses unstable spatio-temporal fluctuations and strengthens long-range temporal dependencies; and (ii) the Spatio-Temporal Semantic Mamba-Attention (STS-MA), which mitigates cross-city heterogeneity through a shared-parameter design that jointly trains all cities while preserving individual semantic representation spaces. We validate the proposed framework through 75 experiments under two forecasting scenarios, full-day and high-frequency accident periods, using real-world datasets from New York City and Chicago. Compared with the state-of-the-art baselines, MLA-STNet achieves up to 6% lower RMSE, 8% higher Recall, and 5% higher MAP, while maintaining less than 1% performance variation under 50% input noise. These results demonstrate that MLA-STNet effectively unifies heterogeneous urban datasets within a scalable, robust, and interpretable Cross-City Accident Prevention System, paving the way for coordinated and data-driven urban safety management.

</details>


### [200] [DeMa: Dual-Path Delay-Aware Mamba for Efficient Multivariate Time Series Analysis](https://arxiv.org/abs/2601.05527)
*Rui An,Haohao Qu,Wenqi Fan,Xuequn Shang,Qing Li*

Main category: cs.LG

TL;DR: 本文提出DeMa模型，一种双路径延迟感知Mamba骨干网络，用于解决多变量时间序列（MTS）建模中Mamba直接应用的三大缺陷，显著提升其在多种MTS任务上的性能与效率。


<details>
  <summary>Details</summary>
Motivation: Transformer在MTS建模中存在计算复杂度高、内存开销大等问题；而Mamba虽具线性复杂度优势，但缺乏显式跨变量建模、难以解耦时序动态与变量间交互、且对时间滞后效应建模不足。

Method: 提出DeMa：（i）将MTS分解为序列内时序动态与序列间交互；（ii）设计时序路径（Mamba-SSD模块）独立并行捕获各序列长程动态；（iii）设计变量路径（Mamba-DALA模块）融合延迟感知线性注意力建模跨变量依赖。

Result: 在长期/短期预测、数据插补、异常检测和序列分类共5类任务上达到SOTA性能，同时保持显著计算高效性。

Conclusion: DeMa在继承Mamba线性复杂度优势的同时，通过双路径结构与延迟感知机制，有效提升了Mamba在多变量时间序列分析中的适用性与表现力。

Abstract: Accurate and efficient multivariate time series (MTS) analysis is increasingly critical for a wide range of intelligent applications. Within this realm, Transformers have emerged as the predominant architecture due to their strong ability to capture pairwise dependencies. However, Transformer-based models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment in long-term and large-scale MTS modeling. Recently, Mamba has emerged as a promising linear-time alternative with high expressiveness. Nevertheless, directly applying vanilla Mamba to MTS remains suboptimal due to three key limitations: (i) the lack of explicit cross-variate modeling, (ii) difficulty in disentangling the entangled intra-series temporal dynamics and inter-series interactions, and (iii) insufficient modeling of latent time-lag interaction effects. These issues constrain its effectiveness across diverse MTS tasks. To address these challenges, we propose DeMa, a dual-path delay-aware Mamba backbone. DeMa preserves Mamba's linear-complexity advantage while substantially improving its suitability for MTS settings. Specifically, DeMa introduces three key innovations: (i) it decomposes the MTS into intra-series temporal dynamics and inter-series interactions; (ii) it develops a temporal path with a Mamba-SSD module to capture long-range dynamics within each individual series, enabling series-independent, parallel computation; and (iii) it designs a variate path with a Mamba-DALA module that integrates delay-aware linear attention to model cross-variate dependencies. Extensive experiments on five representative tasks, long- and short-term forecasting, data imputation, anomaly detection, and series classification, demonstrate that DeMa achieves state-of-the-art performance while delivering remarkable computational efficiency.

</details>


### [201] [Scalable Heterogeneous Graph Learning via Heterogeneous-aware Orthogonal Prototype Experts](https://arxiv.org/abs/2601.05537)
*Wei Zhou,Hong Huang,Ruize Shi,Bang Liu*

Main category: cs.LG

TL;DR: 本文提出HOPE框架，通过异构感知的正交原型专家机制解决异质图神经网络中线性投影瓶颈问题，提升长尾节点预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有异质图神经网络（HGNNs）解码阶段依赖单一共享线性头，难以适配异质图中上下文多样性与长尾分布，导致对尾部节点建模不足、对枢纽节点过拟合。

Method: 提出HOPE框架：采用可学习的基于原型的路由机制，依据节点嵌入与原型相似度分配至不同专家；引入专家正交化约束以增强专家多样性并防止专家坍缩。

Result: 在四个真实数据集上验证了HOPE的有效性，显著提升多种SOTA HGNN主干模型的性能，且计算开销极小。

Conclusion: HOPE是一种即插即用的预测头替代方案，能有效缓解线性投影瓶颈，在保持低开销的同时提升异质图下游任务性能，尤其改善长尾节点预测效果。

Abstract: Heterogeneous Graph Neural Networks(HGNNs) have advanced mainly through better encoders, yet their decoding/projection stage still relies on a single shared linear head, assuming it can map rich node embeddings to labels. We call this the Linear Projection Bottleneck: in heterogeneous graphs, contextual diversity and long-tail shifts make a global head miss fine semantics, overfit hub nodes, and underserve tail nodes. While Mixture-of-Experts(MoE) could help, naively applying it clashes with structural imbalance and risks expert collapse. We propose a Heterogeneous-aware Orthogonal Prototype Experts framework named HOPE, a plug-and-play replacement for the standard prediction head. HOPE uses learnable prototype-based routing to assign instances to experts by similarity, letting expert usage follow the natural long-tail distribution, and adds expert orthogonalization to encourage diversity and prevent collapse. Experiments on four real datasets show consistent gains across SOTA HGNN backbones with minimal overhead.

</details>


### [202] [Buffered AUC maximization for scoring systems via mixed-integer optimization](https://arxiv.org/abs/2601.05544)
*Moe Shiina,Shunnosuke Ikeda,Yuichi Takano*

Main category: cs.LG

TL;DR: 本文提出了一种基于混合整数线性优化（MILO）的新框架，用于构建直接最大化缓冲AUC（bAUC）的可解释评分系统，并通过真实数据验证其优于正则化和逐步回归基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于混合整数优化（MIO）构建评分系统的工作未直接优化AUC这一关键评估指标，而AUC对评分系统的性能评估至关重要。

Method: 构建一个以缓冲AUC（bAUC）为目标函数、带组稀疏约束的混合整数线性优化（MILO）模型，以控制评分系统中变量数量并保证可解释性。

Result: 在多个公开真实数据集上的实验表明，所提MILO方法构建的评分系统在AUC上显著优于基于正则化和逐步回归的基线方法。

Conclusion: 该研究为开发高可解释性分类模型提供了有效的MIO新范式，推动了可解释机器学习与优化方法的结合。

Abstract: A scoring system is a linear classifier composed of a small number of explanatory variables, each assigned a small integer coefficient. This system is highly interpretable and allows predictions to be made with simple manual calculations without the need for a calculator. Several previous studies have used mixed-integer optimization (MIO) techniques to develop scoring systems for binary classification; however, they have not focused on directly maximizing AUC (i.e., area under the receiver operating characteristic curve), even though AUC is recognized as an essential evaluation metric for scoring systems. Our goal herein is to establish an effective MIO framework for constructing scoring systems that directly maximize the buffered AUC (bAUC) as the tightest concave lower bound on AUC. Our optimization model is formulated as a mixed-integer linear optimization (MILO) problem that maximizes bAUC subject to a group sparsity constraint for limiting the number of questions in the scoring system. Computational experiments using publicly available real-world datasets demonstrate that our MILO method can build scoring systems with superior AUC values compared to the baseline methods based on regularization and stepwise regression. This research contributes to the advancement of MIO techniques for developing highly interpretable classification models.

</details>


### [203] [Learn to Evolve: Self-supervised Neural JKO Operator for Wasserstein Gradient Flow](https://arxiv.org/abs/2601.05583)
*Xue Feng,Li Wang,Deanna Needell,Rongjie Lai*

Main category: cs.LG

TL;DR: 本文提出了一种自监督的Learn-to-Evolve算法，用于学习Jordan-Kinderlehrer-Otto（JKO）方案中的解算子，无需显式求解JKO子问题，通过联合学习算子与轨迹生成，实现高效、稳定、鲁棒的Wasserstein梯度流模拟。


<details>
  <summary>Details</summary>
Motivation: JKO方案虽具稳定性，但反复求解其子问题计算代价高昂，限制了实际应用；而训练数据（初始密度）通常有限，难以直接监督学习JKO解算子。

Method: 提出自监督的Learn-to-Evolve算法：交替执行（1）用当前算子迭代生成近似JKO轨迹，（2）用生成轨迹更新JKO解算子；该过程兼具隐式数据增强与联合优化特性；算子以深度神经网络实现，端到端映射输入密度至JKO子问题极小化器。

Result: 在多种能量泛函和初始条件下，数值实验表明该方法具有高精度、强稳定性与良好鲁棒性，显著降低计算成本，且泛化能力强。

Conclusion: Learn-to-Evolve为无监督/自监督学习偏微分方程演化算子提供了新范式，有效克服了JKO方案的计算瓶颈，拓展了基于变分结构的机器学习建模能力。

Abstract: The Jordan-Kinderlehrer-Otto (JKO) scheme provides a stable variational framework for computing Wasserstein gradient flows, but its practical use is often limited by the high computational cost of repeatedly solving the JKO subproblems. We propose a self-supervised approach for learning a JKO solution operator without requiring numerical solutions of any JKO trajectories. The learned operator maps an input density directly to the minimizer of the corresponding JKO subproblem, and can be iteratively applied to efficiently generate the gradient-flow evolution. A key challenge is that only a number of initial densities are typically available for training. To address this, we introduce a Learn-to-Evolve algorithm that jointly learns the JKO operator and its induced trajectories by alternating between trajectory generation and operator updates. As training progresses, the generated data increasingly approximates true JKO trajectories. Meanwhile, this Learn-to-Evolve strategy serves as a natural form of data augmentation, significantly enhancing the generalization ability of the learned operator. Numerical experiments demonstrate the accuracy, stability, and robustness of the proposed method across various choices of energies and initial conditions.

</details>


### [204] [Poisson Hyperplane Processes with Rectified Linear Units](https://arxiv.org/abs/2601.05586)
*Shufei Ge,Shijia Wang,Lloyd Elliott*

Main category: cs.LG

TL;DR: 本文建立了泊松超平面过程（PHP）与两层ReLU神经网络之间的联系，提出了一种基于PHP的可扩展概率表示方法，并设计了退火序贯蒙特卡洛算法用于贝叶斯推断，实验表明其性能优于经典两层ReLU网络。


<details>
  <summary>Details</summary>
Motivation: 为理解ReLU神经网络的内在概率机制并提升其可扩展性与统计可解释性，作者探索其与随机几何模型（泊松超平面过程）的理论联系。

Method: 将两层ReLU网络建模为具有高斯先验的泊松超平面过程（PHP），利用分解性质实现大规模扩展，并提出退火序贯蒙特卡洛算法进行贝叶斯推理。

Result: 所提PHP-ReLU模型在数值实验中性能优于经典两层ReLU神经网络，且具备良好的可扩展性和概率解释性。

Conclusion: PHP提供了一种新颖、可扩展且具统计基础的两层ReLU网络概率表示框架，为深度学习模型的理论分析与贝叶斯推断提供了新视角。

Abstract: Neural networks have shown state-of-the-art performances in various classification and regression tasks. Rectified linear units (ReLU) are often used as activation functions for the hidden layers in a neural network model. In this article, we establish the connection between the Poisson hyperplane processes (PHP) and two-layer ReLU neural networks. We show that the PHP with a Gaussian prior is an alternative probabilistic representation to a two-layer ReLU neural network. In addition, we show that a two-layer neural network constructed by PHP is scalable to large-scale problems via the decomposition propositions. Finally, we propose an annealed sequential Monte Carlo algorithm for Bayesian inference. Our numerical experiments demonstrate that our proposed method outperforms the classic two-layer ReLU neural network. The implementation of our proposed model is available at https://github.com/ShufeiGe/Pois_Relu.git.

</details>


### [205] [PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning](https://arxiv.org/abs/2601.05593)
*Jingcheng Hu,Yinmin Zhang,Shijie Shang,Xiaobo Yang,Yue Peng,Zhewei Huang,Hebin Zhou,Xin Wu,Jie Cheng,Fanqi Wan,Xiangwen Kong,Chengyuan Yao,Kaiwen Yan,Ailin Huang,Hongyu Zhou,Qi Han,Zheng Ge,Daxin Jiang,Xiangyu Zhang,Heung-Yeung Shum*

Main category: cs.LG

TL;DR: PaCoRe是一种新型训练与推理框架，通过多轮并行推理与消息传递协调机制，突破大模型测试时计算量（TTC）受上下文窗口限制的瓶颈，显著提升数学等复杂推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型受限于固定上下文窗口，难以在测试时扩展计算量（TTC），导致复杂推理能力受限。

Method: 提出Parallel Coordinated Reasoning（PaCoRe）框架：多轮并行展开大量推理路径，每轮将结果压缩为上下文受限的消息，通过消息传递架构协调并合成信息以指导后续轮次；采用大规模、基于结果的强化学习进行端到端训练。

Result: PaCoRe使8B模型在HMMT 2025数学竞赛上达94.5%，超越GPT-5（93.2%），有效TTC扩展至约两百万token；在多个领域均取得显著提升。

Conclusion: PaCoRe成功解耦推理能力与上下文长度约束，为大模型测试时计算可扩展性提供了新范式，并开源全部资源以推动后续研究。

Abstract: We introduce Parallel Coordinated Reasoning (PaCoRe), a training-and-inference framework designed to overcome a central limitation of contemporary language models: their inability to scale test-time compute (TTC) far beyond sequential reasoning under a fixed context window. PaCoRe departs from the traditional sequential paradigm by driving TTC through massive parallel exploration coordinated via a message-passing architecture in multiple rounds. Each round launches many parallel reasoning trajectories, compacts their findings into context-bounded messages, and synthesizes these messages to guide the next round and ultimately produce the final answer. Trained end-to-end with large-scale, outcome-based reinforcement learning, the model masters the synthesis abilities required by PaCoRe and scales to multi-million-token effective TTC without exceeding context limits. The approach yields strong improvements across diverse domains, and notably pushes reasoning beyond frontier systems in mathematics: an 8B model reaches 94.5% on HMMT 2025, surpassing GPT-5's 93.2% by scaling effective TTC to roughly two million tokens. We open-source model checkpoints, training data, and the full inference pipeline to accelerate follow-up work.

</details>


### [206] [Good Allocations from Bad Estimates](https://arxiv.org/abs/2601.05597)
*Sílvia Casacuberta,Moritz Hardt*

Main category: cs.LG

TL;DR: 本文提出了一种在治疗分配中显著降低样本复杂度的方法，仅需O(M/ε)样本即可实现与CATE方法相近的总治疗效果，关键在于粗略估计已足够支持近优分配，并利用预算灵活性进一步减少样本需求。


<details>
  <summary>Details</summary>
Motivation: 传统CATE估计需要O(M/ε²)样本以在M个子群中以ε精度估计每个处理效应，但实际治疗分配任务并不需要如此高精度的估计，因此存在优化空间。

Method: 提出一种基于粗略估计和预算灵活调整的治疗分配算法，理论分析其样本复杂度，并在多个真实世界随机对照试验（RCT）数据集上验证。

Result: 在自然分布的处理效应下，仅需O(M/ε)样本即可达到与CATE相当的总治疗效果；预算灵活性可进一步降低样本需求；实验表明该算法用极少样本即能获得近似最优分配。

Conclusion: 治疗效应估计与治疗分配是两个本质不同的任务，后者对估计精度要求更低，因而可大幅减少所需样本量。

Abstract: Conditional average treatment effect (CATE) estimation is the de facto gold standard for targeting a treatment to a heterogeneous population. The method estimates treatment effects up to an error $ε> 0$ in each of $M$ different strata of the population, targeting individuals in decreasing order of estimated treatment effect until the budget runs out. In general, this method requires $O(M/ε^2)$ samples. This is best possible if the goal is to estimate all treatment effects up to an $ε$ error. In this work, we show how to achieve the same total treatment effect as CATE with only $O(M/ε)$ samples for natural distributions of treatment effects. The key insight is that coarse estimates suffice for near-optimal treatment allocations. In addition, we show that budget flexibility can further reduce the sample complexity of allocation. Finally, we evaluate our algorithm on various real-world RCT datasets. In all cases, it finds nearly optimal treatment allocations with surprisingly few samples. Our work highlights the fundamental distinction between treatment effect estimation and treatment allocation: the latter requires far fewer samples.

</details>


### [207] [Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR](https://arxiv.org/abs/2601.05607)
*Zijun Min,Bingshuai Liu,Ante Wang,Long Zhang,Anxiang Zeng,Haibo Zhang,Jinsong Su*

Main category: cs.LG

TL;DR: 本文提出动态混合策略优化（DHPO）方法，融合GRPO的token级信用分配与GSPO的sequence级奖励匹配优势，通过加权机制和分支特异性裁剪提升训练稳定性，在多个数学推理基准上显著优于现有RLVR算法。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR算法（如GRPO和GSPO）在信用分配粒度上各有优劣：GRPO细粒度但高方差，GSPO匹配序列奖励但牺牲token级精度，亟需统一框架兼顾二者优势。

Method: 提出DHPO，构建含token级和sequence级重要性比率的混合裁剪代理目标函数；设计平均混合与熵引导混合两种权重机制；引入分支特异性裁剪策略，分别约束两类比率的信任区域。

Result: 在七个数学推理基准上，DHPO在Qwen3系列dense和MoE模型上均一致超越GRPO和GSPO。

Conclusion: DHPO成功桥接GRPO与GSPO，通过动态混合与稳定化设计，在保持细粒度信用分配的同时更好匹配序列级奖励，为RLVR提供了更鲁棒、高效的优化框架。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a promising framework for optimizing large language models in reasoning tasks. However, existing RLVR algorithms focus on different granularities, and each has complementary strengths and limitations. Group Relative Policy Optimization (GRPO) updates the policy with token-level importance ratios, which preserves fine-grained credit assignment but often suffers from high variance and instability. In contrast, Group Sequence Policy Optimization (GSPO) applies single sequence-level importance ratios across all tokens in a response that better matches sequence-level rewards, but sacrifices token-wise credit assignment. In this paper, we propose Dynamic Hybrid Policy Optimization (DHPO) to bridge GRPO and GSPO within a single clipped surrogate objective. DHPO combines token-level and sequence-level importance ratios using weighting mechanisms. We explore two variants of the mixing mechanism, including an averaged mixing and an entropy-guided mixing. To further stabilize training, we employ a branch-specific clipping strategy that constrains token-level and sequence-level ratios within separate trust regions before mixing, preventing outliers in either branch from dominating the update. Across seven challenging mathematical reasoning benchmarks, experiments on both dense and MoE models from the Qwen3 series show that DHPO consistently outperforms GRPO and GSPO. We will release our code upon acceptance of this paper.

</details>


### [208] [PiXTime: A Model for Federated Time Series Forecasting with Heterogeneous Data Structures Across Nodes](https://arxiv.org/abs/2601.05613)
*Yiming Zhou,Mingyue Cheng,Hao Wang,Enhong Chen*

Main category: cs.LG

TL;DR: PiXTime 是一种面向联邦学习的时间序列预测新模型，通过个性化 Patch Embedding 和全局 VE Table 解决多粒度、异构变量集下的跨节点建模难题，在联邦和传统基准上均达到 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据具有高价值但难以共享，联邦学习是理想范式；然而各节点采样标准不同导致时间粒度和变量集异构，阻碍经典联邦学习应用。

Method: 提出 PiXTime 模型：1）个性化 Patch Embedding 将节点特有粒度的时间序列映射为统一维度的 token 序列；2）全局 VE Table 对齐不同节点变量类别的语义；3）基于 Transformer 的共享模型结合交叉注意力，利用任意数量辅助变量序列增强目标序列预测。

Result: 在联邦学习设置下达到当前最优性能，并在八个广泛使用的现实世界传统基准上表现优异。

Conclusion: PiXTime 有效解决了联邦时间序列预测中多粒度与变量异构的核心挑战，显著提升了跨节点知识迁移与预测精度。

Abstract: Time series are highly valuable and rarely shareable across nodes, making federated learning a promising paradigm to leverage distributed temporal data. However, different sampling standards lead to diverse time granularities and variable sets across nodes, hindering classical federated learning. We propose PiXTime, a novel time series forecasting model designed for federated learning that enables effective prediction across nodes with multi-granularity and heterogeneous variable sets. PiXTime employs a personalized Patch Embedding to map node-specific granularity time series into token sequences of a unified dimension for processing by a subsequent shared model, and uses a global VE Table to align variable category semantics across nodes, thereby enhancing cross-node transferability. With a transformer-based shared model, PiXTime captures representations of auxiliary series with arbitrary numbers of variables and uses cross-attention to enhance the prediction of the target series. Experiments show PiXTime achieves state-of-the-art performance in federated settings and demonstrates superior performance on eight widely used real-world traditional benchmarks.

</details>


### [209] [Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks](https://arxiv.org/abs/2601.05616)
*ShaoZhen Liu,Xinting Huang,Houwen Peng,Xin Chen,Xinyang Song,Qi Li,Zhenan Sun*

Main category: cs.LG

TL;DR: 本文提出了一种两阶段监督微调（SFT）框架，利用自生成的长链式思维（CoT）数据提升大语言模型在数学推理任务中的自我修正能力，显著提升了GSM8K、MATH500和AIME24等基准表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖强化学习（RL）进行数学推理优化，忽视了监督微调（SFT）的潜力；本文旨在探索SFT能否有效激活模型内在推理能力，并提供更资源高效的复杂任务优化路径。

Method: 提出两阶段训练框架：第一阶段采用多轮对话策略引导模型生成含验证、回溯、子目标分解与逆向推理的长CoT数据，并通过预定义规则筛选高质量样本用于SFT；第二阶段引入难度感知的拒绝采样机制，动态优化训练数据分布。

Result: 生成的推理链长度扩展超4倍，保持强可扩展性；在GSM8K、MATH500及竞赛级AIME24上均取得显著性能提升。

Conclusion: 监督微调能有效激发大语言模型的内在推理与自我修正能力，该两阶段SFT框架为复杂推理任务提供了高效、可扩展且资源友好的新范式。

Abstract: In recent years, large language models (LLMs) have demonstrated significant potential in complex reasoning tasks like mathematical problem-solving. However, existing research predominantly relies on reinforcement learning (RL) frameworks while overlooking supervised fine-tuning (SFT) methods. This paper proposes a new two-stage training framework that enhances models' self-correction capabilities through self-generated long chain-of-thought (CoT) data. During the first stage, a multi-turn dialogue strategy guides the model to generate CoT data incorporating verification, backtracking, subgoal decomposition, and backward reasoning, with predefined rules filtering high-quality samples for supervised fine-tuning. The second stage employs a difficulty-aware rejection sampling mechanism to dynamically optimize data distribution, strengthening the model's ability to handle complex problems. The approach generates reasoning chains extended over 4 times longer while maintaining strong scalability, proving that SFT effectively activates models' intrinsic reasoning capabilities and provides a resource-efficient pathway for complex task optimization. Experimental results demonstrate performance improvements on mathematical benchmarks including GSM8K and MATH500, with the fine-tuned model achieving a substantial improvement on competition-level problems like AIME24. Code will be open-sourced.

</details>


### [210] [Continual Learning of Achieving Forgetting-free and Positive Knowledge Transfer](https://arxiv.org/abs/2601.05623)
*Zhi Wang,Zhongbin Wu,Yanni Li,Bing Liu,Guangxi Li,Yuping Wang*

Main category: cs.LG

TL;DR: 本文提出了一种增强型任务持续学习（ETCL）方法，旨在不仅缓解灾难性遗忘，还促进正向和反向知识迁移（FKT/BKT），通过任务特定二值掩码、梯度对齐与双目标优化实现遗忘自由与正向知识迁移。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习研究主要关注缓解灾难性遗忘，但理想持续学习代理还应促进正向（FKT）与反向（BKT）知识迁移，提升新旧任务性能。

Method: 将CL建模为带FKT/BKT正性约束的优化问题；提出ETCL方法：使用任务特定二值掩码隔离稀疏子网络以防止遗忘；基于在线任务相似性检测对齐新任务与最相似旧任务子网络梯度以保障FKT；采用双目标优化与正交梯度投影更新相似旧任务分类层权重以实现BKT。

Result: ETCL在差异大、相似及混合任务序列上显著优于强基线方法；理论推导了导致负FKT/BKT的边界，并据此提出在线任务相似性检测策略。

Conclusion: ETCL实现了遗忘自由与正向知识迁移的统一，拓展了持续学习的目标维度，为构建更智能、自适应的学习系统提供了新范式。

Abstract: Existing research on continual learning (CL) of a sequence of tasks focuses mainly on dealing with catastrophic forgetting (CF) to balance the learning plasticity of new tasks and the memory stability of old tasks. However, an ideal CL agent should not only be able to overcome CF, but also encourage positive forward and backward knowledge transfer (KT), i.e., using the learned knowledge from previous tasks for the new task learning (namely FKT), and improving the previous tasks' performance with the knowledge of the new task (namely BKT). To this end, this paper first models CL as an optimization problem in which each sequential learning task aims to achieve its optimal performance under the constraint that both FKT and BKT should be positive. It then proposes a novel Enhanced Task Continual Learning (ETCL) method, which achieves forgetting-free and positive KT. Furthermore, the bounds that can lead to negative FKT and BKT are estimated theoretically. Based on the bounds, a new strategy for online task similarity detection is also proposed to facilitate positive KT. To overcome CF, ETCL learns a set of task-specific binary masks to isolate a sparse sub-network for each task while preserving the performance of a dense network for the task. At the beginning of a new task learning, ETCL tries to align the new task's gradient with that of the sub-network of the previous most similar task to ensure positive FKT. By using a new bi-objective optimization strategy and an orthogonal gradient projection method, ETCL updates only the weights of previous similar tasks at the classification layer to achieve positive BKT. Extensive evaluations demonstrate that the proposed ETCL markedly outperforms strong baselines on dissimilar, similar, and mixed task sequences.

</details>


### [211] [Transformer Is Inherently a Causal Learner](https://arxiv.org/abs/2601.05647)
*Xinyue Wang,Stephen Wang,Biwei Huang*

Main category: cs.LG

TL;DR: 本文发现自回归训练的Transformer自然编码了时间延迟因果结构，通过梯度敏感性可直接恢复潜在因果图，无需显式因果目标或结构约束；理论证明其在标准可识别性条件下成立，并提出基于聚合梯度归因的实用提取方法；该方法在非线性动力学、长程依赖和非平稳系统等挑战场景下显著优于现有因果发现算法，且因果准确性随数据量和异质性增加而提升，展现出传统方法所缺乏的扩展性；为因果发现与基础模型的融合提供了新范式。


<details>
  <summary>Details</summary>
Motivation: 揭示自回归Transformer是否隐含编码因果结构，并探索无需显式因果建模即可从预训练模型中提取因果关系的可能性。

Method: 利用输出对过去输入的梯度敏感性来恢复因果图，结合理论证明与基于聚合梯度归因的实用提取方法。

Result: 在非线性、长程依赖、非平稳等复杂时间序列上，显著超越现有因果发现算法；因果准确性随数据量和异质性增加而提升，具备良好扩展性。

Conclusion: 自回归Transformer天然蕴含时间延迟因果结构，梯度敏感性可作为可靠因果发现工具；该发现打通了基础模型与因果推断的桥梁，既提升模型可解释性，也拓展因果发现的新路径。

Abstract: We reveal that transformers trained in an autoregressive manner naturally encode time-delayed causal structures in their learned representations. When predicting future values in multivariate time series, the gradient sensitivities of transformer outputs with respect to past inputs directly recover the underlying causal graph, without any explicit causal objectives or structural constraints. We prove this connection theoretically under standard identifiability conditions and develop a practical extraction method using aggregated gradient attributions. On challenging cases such as nonlinear dynamics, long-term dependencies, and non-stationary systems, this approach greatly surpasses the performance of state-of-the-art discovery algorithms, especially as data heterogeneity increases, exhibiting scaling potential where causal accuracy improves with data volume and heterogeneity, a property traditional methods lack. This unifying view lays the groundwork for a future paradigm where causal discovery operates through the lens of foundation models, and foundation models gain interpretability and enhancement through the lens of causality.

</details>


### [212] [Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM](https://arxiv.org/abs/2511.18721)
*Adarsh Kumarappan,Ayushi Mehrotra*

Main category: cs.LG

TL;DR: 本文提出了一种更现实的概率性框架（k, ε）-unstable，以改进SmoothLLM在面对多样化越狱攻击时的安全认证能力，并通过数据驱动的下界提升防御概率估计的可信度与实用性。


<details>
  <summary>Details</summary>
Motivation: SmoothLLM依赖于难以满足的强假设'k-unstable'，导致其安全证书在实践中可信度受限。

Method: 引入新的概率性假设'(k, ε)-unstable'，结合攻击成功率的经验模型，推导出SmoothLLM防御概率的数据驱动下界。

Result: 提供了更可信、实用且可操作的安全认证机制，支持根据大模型真实行为设定认证阈值。

Conclusion: 该工作为增强大语言模型对越狱攻击的鲁棒性提供了理论扎实且落地可行的安全保障方法。

Abstract: The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.

</details>


### [213] [From Global to Local: Cluster-Aware Learning for Wi-Fi Fingerprinting Indoor Localisation](https://arxiv.org/abs/2601.05650)
*Miguel Matey-Sanz,Joaquín Torres-Sospedra,Joaquín Huerta,Sergio Trilles*

Main category: cs.LG

TL;DR: 本文提出了一种基于聚类的Wi-Fi指纹定位方法，通过空间或射频特征对指纹数据进行预结构化，并在定位阶段基于最强接入点估计所属簇，从而在更小、更一致的数据子集上进行局部定位，显著降低了定位误差，但牺牲了楼层识别精度。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi指纹定位性能受限于数据集规模与异质性、RSSI强变异性以及大型多层环境中的模糊性，全局模型忽略结构约束导致定位精度下降。

Method: 采用基于空间或射频特征的聚类方法对指纹数据集进行分层（建筑级或楼层级）结构化；定位时利用最强接入点估计测试样本所属簇，仅在该簇内执行局部定位。

Result: 在三个公开数据集和多种机器学习模型上验证，建筑级聚类策略显著降低定位误差，但楼层检测精度下降。

Conclusion: 显式通过聚类对数据集进行结构化是一种有效且可扩展的室内定位方法。

Abstract: Wi-Fi fingerprinting remains one of the most practical solutions for indoor positioning, however, its performance is often limited by the size and heterogeneity of fingerprint datasets, strong Received Signal Strength Indicator variability, and the ambiguity introduced in large and multi-floor environments. These factors significantly degrade localisation accuracy, particularly when global models are applied without considering structural constraints. This paper introduces a clustering-based method that structures the fingerprint dataset prior to localisation. Fingerprints are grouped using either spatial or radio features, and clustering can be applied at the building or floor level. In the localisation phase, a clustering estimation procedure based on the strongest access points assigns unseen fingerprints to the most relevant cluster. Localisation is then performed only within the selected clusters, allowing learning models to operate on reduced and more coherent subsets of data. The effectiveness of the method is evaluated on three public datasets and several machine learning models. Results show a consistent reduction in localisation errors, particularly under building-level strategies, but at the cost of reducing the floor detection accuracy. These results demonstrate that explicitly structuring datasets through clustering is an effective and flexible approach for scalable indoor positioning.

</details>


### [214] [Automating Deception: Scalable Multi-Turn LLM Jailbreaks](https://arxiv.org/abs/2511.19517)
*Adarsh Kumarappan,Ananya Mujoo*

Main category: cs.LG

TL;DR: 本文提出了一种自动化生成基于心理原理（如“登门槛效应”）的多轮越狱攻击数据集的新方法，并在1500个场景上评估了7个主流大模型，发现GPT系列模型对对话历史极为敏感，而Gemini 2.5 Flash表现出极强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多轮对话式攻击（如利用登门槛效应）严重威胁大模型安全性，但现有防御研究受限于人工构建数据集、难以规模化。

Method: 系统性地将登门槛效应等心理策略转化为可复现的模板，构建含1500个多轮越狱场景的大规模基准数据集，并在多轮（含历史）与单轮（无历史）条件下统一评估7个主流LLM。

Result: GPT系列模型在多轮设置下攻击成功率（ASR）最高提升32个百分点；Gemini 2.5 Flash几乎免疫此类攻击；Claude 3 Haiku表现较强但仍有漏洞。

Conclusion: 当前各模型安全架构对对话上下文的处理能力存在显著差异，亟需能抵御叙事型操纵的新型防御机制。

Abstract: Multi-turn conversational attacks, which leverage psychological principles like Foot-in-the-Door (FITD), where a small initial request paves the way for a more significant one, to bypass safety alignments, pose a persistent threat to Large Language Models (LLMs). Progress in defending against these attacks is hindered by a reliance on manual, hard-to-scale dataset creation. This paper introduces a novel, automated pipeline for generating large-scale, psychologically-grounded multi-turn jailbreak datasets. We systematically operationalize FITD techniques into reproducible templates, creating a benchmark of 1,500 scenarios across illegal activities and offensive content. We evaluate seven models from three major LLM families under both multi-turn (with history) and single-turn (without history) conditions. Our results reveal stark differences in contextual robustness: models in the GPT family demonstrate a significant vulnerability to conversational history, with Attack Success Rates (ASR) increasing by as much as 32 percentage points. In contrast, Google's Gemini 2.5 Flash exhibits exceptional resilience, proving nearly immune to these attacks, while Anthropic's Claude 3 Haiku shows strong but imperfect resistance. These findings highlight a critical divergence in how current safety architectures handle conversational context and underscore the need for defenses that can resist narrative-based manipulation.

</details>


### [215] [Do Sparse Autoencoders Identify Reasoning Features in Language Models?](https://arxiv.org/abs/2601.05679)
*George Ma,Zhongyuan Liang,Irene Y. Chen,Somayeh Sojoudi*

Main category: cs.LG

TL;DR: 本文质疑稀疏自编码器（SAEs）在大语言模型中识别出的‘推理特征’是否真实反映推理过程，通过因果词元注入与大模型引导的证伪实验发现，这些特征主要依赖表层语言线索而非真正推理机制。


<details>
  <summary>Details</summary>
Motivation: 验证稀疏自编码器（SAEs）所提取的所谓‘推理特征’是否真实对应推理过程，还是仅捕获表面语言相关性。

Method: 提出一种证伪导向框架，结合因果词元注入实验和大语言模型引导的证伪方法，在20种不同模型、层和数据集配置下系统检验特征激活是否可被非推理文本触发或在推理文本中失效。

Result: 59%–94%的特征可通过少量词元注入在非推理文本中强激活；其余特征经LLM引导证伪后，均无法满足‘真正推理特征’的标准；特征干预对基准性能影响微弱甚至导致轻微下降。

Conclusion: 对比激活方法识别出的SAE推理特征主要捕获的是推理的语言伴随现象，而非推理本身的计算过程。

Abstract: We investigate whether sparse autoencoders (SAEs) identify genuine reasoning features in large language models (LLMs). Starting from features selected using standard contrastive activation methods, we introduce a falsification-oriented framework that combines causal token injection experiments and LLM-guided falsification to test whether feature activation reflects reasoning processes or superficial linguistic correlates. Across 20 configurations spanning multiple model families, layers, and reasoning datasets, we find that identified reasoning features are highly sensitive to token-level interventions. Injecting a small number of feature-associated tokens into non-reasoning text is sufficient to elicit strong activation for 59% to 94% of features, indicating reliance on lexical artifacts. For the remaining features that are not explained by simple token triggers, LLM-guided falsification consistently produces non-reasoning inputs that activate the feature and reasoning inputs that do not, with no analyzed feature satisfying our criteria for genuine reasoning behavior. Steering these features yields minimal changes or slight degradations in benchmark performance. Together, these results suggest that SAE features identified by contrastive approaches primarily capture linguistic correlates of reasoning rather than the underlying reasoning computations themselves.

</details>


### [216] [Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute](https://arxiv.org/abs/2512.11847)
*Antonio Roye-Azar,Santiago Vargas-Naranjo,Dhruv Ghai,Nithin Balamurugan,Rayan Amir*

Main category: cs.LG

TL;DR: 本文对Tiny Recursive Models (TRM)在ARC-AGI-1任务上的表现进行了实证分析，发现其高性能主要源于测试时增强与集成、任务标识符依赖、浅层递归及高效非自回归设计，而非深层推理能力。


<details>
  <summary>Details</summary>
Motivation: 澄清TRM在ARC任务中高性能的来源——是源于架构设计、测试时计算开销，还是任务特定先验知识。

Method: 对TRM在ARC-AGI-1上的公开checkpoint进行四项行为分析：（1）测试时增强与多数投票影响；（2） puzzle ID消融实验；（3）递归轨迹分析；（4）不同训练增强策略对比；并对比QLoRA微调Llama 3 8B的效率。

Result: 1）1000样本投票提升Pass@1约11个百分点；2）TRM严重依赖正确puzzle ID，替换后准确率为0；3）首步递归即达主要性能，后续更新收益饱和；4）强增强训练拓宽解空间、提升多采样成功率；5）TRM比QLoRA-Llama3 8B吞吐更高、显存更低。

Conclusion: TRM在ARC-AGI-1上的优异表现主要来自任务特定条件注入、测试时计算密集型策略与高效非自回归架构的协同，而非深层内部推理能力。

Abstract: Tiny Recursive Models (TRM) were proposed as a parameter-efficient alternative to large language models for solving Abstraction and Reasoning Corpus (ARC) style tasks. The original work reports strong performance and suggests that recursive latent updates enable non-trivial reasoning, but it remains unclear how much of this performance stems from architecture, test-time compute, or task-specific priors. In this technical note, we empirically analyze the ARC Prize TRM checkpoint on ARC-AGI-1 and report four behavioral findings and an efficiency comparison. First, we show that test-time augmentation and majority-vote ensembling account for a substantial fraction of reported performance: the 1000-sample voting pipeline improves Pass@1 by about 11 percentage points over single-pass canonical inference. Second, a puzzle-identity ablation reveals strict dependence on task identifiers: replacing the correct puzzle ID with a blank or random token yields zero accuracy. Third, a recursion trajectory analysis shows that most of the final accuracy is achieved at the first recursion step and that performance saturates after few latent updates, indicating shallow effective recursion. Fourth, early-stage training experiments under canonical versus heavy augmentation regimes suggest that heavy augmentation broadens the distribution of candidate solutions and improves multi-sample success. Finally, we compare TRM with a naive QLoRA fine-tune of Llama 3 8B on canonical ARC-AGI-1, finding that TRM's non-autoregressive design achieves much higher throughput and substantially lower memory usage in this setting. Overall, TRM's ARC-AGI-1 performance appears to arise from an interaction between efficiency, task-specific conditioning, and aggressive test-time compute rather than deep internal reasoning.

</details>


### [217] [AGDC: Autoregressive Generation of Variable-Length Sequences with Joint Discrete and Continuous Spaces](https://arxiv.org/abs/2601.05680)
*Yeonsang Shin,Insoo Kim,Bongkeun Kim,Keonwoo Bae,Bohyung Han*

Main category: cs.LG

TL;DR: 本文提出AGDC框架，结合分类预测与扩散模型，统一建模离散与连续值序列，解决高精度混合序列生成中的精度损失问题，并在半导体布局等任务上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: Transformer自回归模型受限于离散化token，难以高精度表示连续值；在半导体电路设计等高精度领域，精度损失可能导致功能失效。

Method: 提出AGDC统一框架：对离散值采用分类预测，对连续值采用扩散建模；引入EOS logit动态调整机制（基于MLP）和长度正则化损失项；构建ContLayNet大规模高精度半导体布局基准。

Result: 在ContLayNet（半导体布局）、图形布局和SVG数据集上，AGDC显著优于基于离散化和固定schema的基线方法，实现可扩展、高保真混合向量生成。

Conclusion: AGDC有效克服了传统离散化方法在高精度混合序列生成中的瓶颈，为半导体设计等关键领域提供了更可靠、更精确的生成建模新范式。

Abstract: Transformer-based autoregressive models excel in data generation but are inherently constrained by their reliance on discretized tokens, which limits their ability to represent continuous values with high precision. We analyze the scalability limitations of existing discretization-based approaches for generating hybrid discrete-continuous sequences, particularly in high-precision domains such as semiconductor circuit designs, where precision loss can lead to functional failure. To address the challenge, we propose AGDC, a novel unified framework that jointly models discrete and continuous values for variable-length sequences. AGDC employs a hybrid approach that combines categorical prediction for discrete values with diffusion-based modeling for continuous values, incorporating two key technical components: an end-of-sequence (EOS) logit adjustment mechanism that uses an MLP to dynamically adjust EOS token logits based on sequence context, and a length regularization term integrated into the loss function. Additionally, we present ContLayNet, a large-scale benchmark comprising 334K high-precision semiconductor layout samples with specialized evaluation metrics that capture functional correctness where precision errors significantly impact performance. Experiments on semiconductor layouts (ContLayNet), graphic layouts, and SVGs demonstrate AGDC's superior performance in generating high-fidelity hybrid vector representations compared to discretization-based and fixed-schema baselines, achieving scalable high-precision generation across diverse domains.

</details>


### [218] [FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching](https://arxiv.org/abs/2601.05684)
*Hongyaoxing Gul,Lijuan Hu,Shuzi Niu,Fangfang Liu*

Main category: cs.LG

TL;DR: 本文提出FLRQ方法，通过灵活的低秩量化策略，在不进行昂贵微调的前提下，为大语言模型各层自适应选择最优低秩近似秩，并结合剪裁与缩放策略最小化量化误差，显著提升量化质量与算法效率。


<details>
  <summary>Details</summary>
Motivation: 现有低秩PTQ方法需耗时微调以权衡不同层和数据的秩选择，且SVD计算开销大，未能充分释放低秩量化的潜力。

Method: 提出FLRQ框架，包含两个核心组件：1）基于Rank1-Sketch与高斯投影的R1-FLR，实现快速、离群点感知的逐层秩选择；2）在剪裁约束下的最佳低秩近似（BLC），通过迭代法最小化量化误差。

Result: FLRQ在多项实验中展现出优异的量化质量与算法效率，达到当前最优（SOTA）性能。

Conclusion: FLRQ无需微调即可为LLM各层自动选择精度最优的低秩配置，在存储压缩与推理加速间取得更好平衡，是一种高效鲁棒的低秩量化新范式。

Abstract: Traditional post-training quantization (PTQ) is considered an effective approach to reduce model size and accelerate inference of large-scale language models (LLMs). However, existing low-rank PTQ methods require costly fine-tuning to determine a compromise rank for diverse data and layers in large models, failing to exploit their full potential. Additionally, the current SVD-based low-rank approximation compounds the computational overhead. In this work, we thoroughly analyze the varying effectiveness of low-rank approximation across different layers in representative models. Accordingly, we introduce \underline{F}lexible \underline{L}ow-\underline{R}ank \underline{Q}uantization (FLRQ), a novel solution designed to quickly identify the accuracy-optimal ranks and aggregate them to achieve minimal storage combinations. FLRQ comprises two powerful components, Rank1-Sketch-based Flexible Rank Selection (R1-FLR) and Best Low-rank Approximation under Clipping (BLC). R1-FLR applies the R1-Sketch with Gaussian projection for the fast low-rank approximation, enabling outlier-aware rank extraction for each layer. Meanwhile, BLC aims at minimizing the low-rank quantization error under the scaling and clipping strategy through an iterative method. FLRQ demonstrates strong effectiveness and robustness in comprehensive experiments, achieving state-of-the-art performance in both quantization quality and algorithm efficiency.

</details>


### [219] [mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations](https://arxiv.org/abs/2601.05732)
*Yongyi Yang,Jianyang Gao*

Main category: cs.LG

TL;DR: 本文提出mHC-lite，一种通过凸组合置换矩阵显式构造双随机矩阵的轻量级超连接方法，解决了DeepSeek mHC中近似双随机性和CUDA依赖的问题，保证了训练稳定性并提升了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 解决mHC中Sinkhorn-Knopp迭代无法保证精确双随机性（导致深层累积不稳定）以及其CUDA实现工程复杂、可移植性差的问题。

Method: 基于Birkhoff-von Neumann定理，将残差矩阵参数化为置换矩阵的凸组合，从而显式、精确地满足双随机约束；仅使用原生矩阵运算，无需特殊CUDA内核。

Result: mHC-lite在多项实验中性能持平或优于mHC，训练吞吐量更高，且彻底消除了HC和mHC中存在的残差不稳定性。

Conclusion: mHC-lite以更简洁、可移植、理论严谨的方式实现了稳定高效的超连接，是HC类方法的重要改进。

Abstract: Hyper-Connections (HC) generalizes residual connections by introducing dynamic residual matrices that mix information across multiple residual streams, accelerating convergence in deep neural networks. However, unconstrained residual matrices can compromise training stability. To address this, DeepSeek's Manifold-Constrained Hyper-Connections (mHC) approximately projects these matrices onto the Birkhoff polytope via iterative Sinkhorn--Knopp (SK) normalization. We identify two limitations of this approach: (i) finite SK iterations do not guarantee exact doubly stochasticity, leaving an approximation gap that can accumulate through network depth and undermine stability; (ii) efficient SK implementation requires highly specialized CUDA kernels, raising engineering barriers and reducing portability. Motivated by the Birkhoff--von Neumann theorem, we propose mHC-lite, a simple reparameterization that explicitly constructs doubly stochastic matrices as convex combinations of permutation matrices. This approach guarantees exact doubly stochasticity by construction and can be implemented using only native matrix operations. Extensive experiments demonstrate that mHC-lite matches or exceeds mHC in performance while achieving higher training throughput with a naive implementation and eliminating the residual instabilities observed in both HC and mHC. The code is publicly available at https://github.com/FFTYYY/mhc-lite.

</details>


### [220] [Variational Autoencoders for P-wave Detection on Strong Motion Earthquake Spectrograms](https://arxiv.org/abs/2601.05759)
*Turkan Simge Ispak,Salih Tileylioglu,Erdem Akagunduz*

Main category: cs.LG

TL;DR: 本文提出一种基于自监督异常检测的P波到达检测方法，通过对比不同变分自编码器（VAE）架构，发现注意力机制比跳跃连接更有利于地震早期预警中的P波检测。


<details>
  <summary>Details</summary>
Motivation: 强震记录中噪声高、标注数据少、波形复杂，导致准确P波检测困难，需探索更鲁棒的自监督方法。

Method: 将P波检测建模为自监督异常检测任务，系统评估492种变分自编码器（VAE）配置，重点比较跳跃连接与注意力机制对重建保真度与异常判别能力的权衡影响。

Result: 注意力机制VAE在近源0–40公里范围内AUC达0.91，显著优于跳跃连接VAE（AUC 0.875）；跳跃连接虽降低重建误差（MAE≈0.0012），但导致过泛化、掩盖P波信号。

Conclusion: 强调全局上下文而非像素级重建精度的网络架构约束，是实现鲁棒自监督P波检测的关键。

Abstract: Accurate P-wave detection is critical for earthquake early warning, yet strong-motion records pose challenges due to high noise levels, limited labeled data, and complex waveform characteristics. This study reframes P-wave arrival detection as a self-supervised anomaly detection task to evaluate how architectural variations regulate the trade-off between reconstruction fidelity and anomaly discrimination. Through a comprehensive grid search of 492 Variational Autoencoder configurations, we show that while skip connections minimize reconstruction error (Mean Absolute Error approximately 0.0012), they induce "overgeneralization", allowing the model to reconstruct noise and masking the detection signal. In contrast, attention mechanisms prioritize global context over local detail and yield the highest detection performance with an area-under-the-curve of 0.875. The attention-based Variational Autoencoder achieves an area-under-the-curve of 0.91 in the 0 to 40-kilometer near-source range, demonstrating high suitability for immediate early warning applications. These findings establish that architectural constraints favoring global context over pixel-perfect reconstruction are essential for robust, self-supervised P-wave detection.

</details>


### [221] [Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer](https://arxiv.org/abs/2601.05770)
*Yifan Zhang,Wei Bi,Kechi Zhang,Dongming Jin,Jie Fu,Zhi Jin*

Main category: cs.LG

TL;DR: 本文提出Discrete Transformer，通过功能解耦和温度退火采样，解决Transformer中因特征叠加导致的符号表达提取困难问题，实现了无需示例的算法发现与连续变量域的可解释性提升。


<details>
  <summary>Details</summary>
Motivation: 现有算法提取方法难以应用于Transformer模型，主要受限于其内部特征叠加（superposition）现象，阻碍了从连续表示中提取出符号化程序。

Method: 提出Discrete Transformer架构：1）强制功能解耦——数值注意力仅用于信息路由，数值MLP仅执行逐元素算术；2）采用温度退火采样策略以支持离散符号搜索；3）引入归纳偏置实现对合成程序的细粒度控制。

Result: 在算法任务上性能媲美RNN基线；首次在连续变量域实现高可解释性；离散搜索过程呈现清晰的探索-利用相变；支持对合成程序结构的可控引导。

Conclusion: Discrete Transformer为无演示（demonstration-free）算法发现提供了鲁棒框架，并为提升Transformer模型的可解释性建立了严格可行的技术路径。

Abstract: Algorithm extraction aims to synthesize executable programs directly from models trained on specific algorithmic tasks, enabling de novo algorithm discovery without relying on human-written code. However, extending this paradigm to Transformer is hindered by superposition, where entangled features encoded in overlapping directions obstruct the extraction of symbolic expressions. In this work, we propose the Discrete Transformer, an architecture explicitly engineered to bridge the gap between continuous representations and discrete symbolic logic. By enforcing a strict functional disentanglement, which constrains Numerical Attention to information routing and Numerical MLP to element-wise arithmetic, and employing temperature-annealed sampling, our method effectively facilitates the extraction of human-readable programs. Empirically, the Discrete Transformer not only achieves performance comparable to RNN-based baselines but crucially extends interpretability to continuous variable domains. Moreover, our analysis of the annealing process shows that the efficient discrete search undergoes a clear phase transition from exploration to exploitation. We further demonstrate that our method enables fine-grained control over synthesized programs by imposing inductive biases. Collectively, these findings establish the Discrete Transformer as a robust framework for demonstration-free algorithm discovery, offering a rigorous pathway toward Transformer interpretability.

</details>


### [222] [Tensor-DTI: Enhancing Biomolecular Interaction Prediction with Contrastive Embedding Learning](https://arxiv.org/abs/2601.05792)
*Manel Gil-Sorribes,Júlia Vilalta-Mor,Isaac Filella-Mercè,Robert Soliva,Álvaro Ciudad,Víctor Guallar,Alexis Molina*

Main category: cs.LG

TL;DR: 本文提出了Tensor-DTI，一种基于对比学习的多模态药物-靶标相互作用（DTI）预测框架，融合分子图、蛋白质语言模型和结合位点预测的嵌入表示，在多个基准上优于现有方法，并展现出良好的泛化性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有DTI预测模型多依赖单一模态（如序列或预定义描述符），表征能力有限，难以准确建模复杂相互作用。

Method: 提出Tensor-DTI框架：采用Siamese双编码器架构，联合整合分子图嵌入、蛋白质语言模型嵌入及结合位点预测嵌入，并通过对比学习优化交互对判别能力。

Result: 在多个DTI基准上性能超越主流序列/图模型；在CDK2大规模虚拟筛选中生成化学合理命中分布；家族留出设置下对跨家族靶标仍具竞争力；拓展至蛋白-RNA和肽-蛋白相互作用亦有效。

Conclusion: 多模态信息融合与对比学习目标协同可显著提升DTI预测准确性、泛化性与可靠性，为虚拟筛选提供更可解释、更稳健的模型。

Abstract: Accurate drug-target interaction (DTI) prediction is essential for computational drug discovery, yet existing models often rely on single-modality predefined molecular descriptors or sequence-based embeddings with limited representativeness. We propose Tensor-DTI, a contrastive learning framework that integrates multimodal embeddings from molecular graphs, protein language models, and binding-site predictions to improve interaction modeling. Tensor-DTI employs a siamese dual-encoder architecture, enabling it to capture both chemical and structural interaction features while distinguishing interacting from non-interacting pairs. Evaluations on multiple DTI benchmarks demonstrate that Tensor-DTI outperforms existing sequence-based and graph-based models. We also conduct large-scale inference experiments on CDK2 across billion-scale chemical libraries, where Tensor-DTI produces chemically plausible hit distributions even when CDK2 is withheld from training. In enrichment studies against Glide docking and Boltz-2 co-folder, Tensor-DTI remains competitive on CDK2 and improves the screening budget required to recover moderate fractions of high-affinity ligands on out-of-family targets under strict family-holdout splits. Additionally, we explore its applicability to protein-RNA and peptide-protein interactions. Our findings highlight the benefits of integrating multimodal information with contrastive objectives to enhance interaction-prediction accuracy and to provide more interpretable and reliability-aware models for virtual screening.

</details>


### [223] [Fusion Matters: Length-Aware Analysis of Positional-Encoding Fusion in Transformers](https://arxiv.org/abs/2601.05807)
*Mohamed Amine Hallam,Kuo-Kun Tseng*

Main category: cs.LG

TL;DR: 本文研究了位置编码与词嵌入的融合机制对长序列Transformer性能的影响，发现融合方式在长文本中显著影响模型表现，而短文本中影响甚微；提出并验证了多种融合策略（如加法、拼接投影、标量门控）的有效性，并引入轻量卷积门控机制以增强局部归纳偏置。


<details>
  <summary>Details</summary>
Motivation: 现有工作多关注设计新位置编码，却忽视位置信息如何与词嵌入融合；本文旨在探究融合机制本身是否影响长序列建模性能。

Method: 在相同架构、数据划分和随机种子下，对比三种典型融合策略（元素级相加、拼接后投影、标量门控融合），并在不同长度文本（AG News、IMDB、ArXiv）上进行控制实验；辅以配对种子分析、跨数据集比较及多种位置编码家族验证；进一步设计轻量卷积门控机制。

Result: 融合策略对短文本影响可忽略，但在长文档（如ArXiv）上带来一致提升；可学习融合收益具有结构性而非随机性，且适用于多种位置编码；卷积门控机制在长文档上进一步有效。

Conclusion: 位置编码融合机制是长序列Transformer中一个不可忽视的设计选择，不应被默认固定，而应作为显式的建模决策加以考虑。

Abstract: Transformers require positional encodings to represent sequence order, yet most prior work focuses on designing new positional encodings rather than examining how positional information is fused with token embeddings. In this paper, we study whether the fusion mechanism itself affects performance, particularly in long-sequence settings. We conduct a controlled empirical study comparing three canonical fusion strategies--element-wise addition, concatenation with projection, and scalar gated fusion--under identical Transformer architectures, data splits, and random seeds. Experiments on three text classification datasets spanning short (AG News), medium (IMDB), and long (ArXiv) sequences show that fusion choice has negligible impact on short texts but produces consistent gains on long documents. To verify that these gains are structural rather than stochastic, we perform paired-seed analysis and cross-dataset comparison across sequence-length regimes. Additional experiments on the ArXiv dataset indicate that the benefit of learnable fusion generalizes across multiple positional encoding families. Finally, we explore a lightweight convolutional gating mechanism that introduces local inductive bias at the fusion level, evaluated on long documents only. Our results indicate that positional-encoding fusion is a non-trivial design choice for long-sequence Transformers and should be treated as an explicit modeling decision rather than a fixed default.

</details>


### [224] [Learning Reconstructive Embeddings in Reproducing Kernel Hilbert Spaces via the Representer Theorem](https://arxiv.org/abs/2601.05811)
*Enrique Feito-Casares,Francisco M. Melgarejo-Meseguer,José-Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 本文提出了一种基于再生核希尔伯特空间（RKHS）的重构式流形学习新算法，通过优化向量形式的表示定理实现样本自重构，并利用可分离算子值核处理向量数据，再通过核对齐将高维重构几何映射到低维嵌入空间。


<details>
  <summary>Details</summary>
Motivation: 受高维数据潜在结构表征学习日益增长的兴趣驱动，旨在利用数据的自重构特性进行流形学习。

Method: 在RKHS中，先通过优化向量形式的Representer定理实现每个样本对其他样本的线性重构；引入可分离算子值核以支持向量值数据；再通过核对齐任务将数据投影到低维空间，使其Gram矩阵逼近高维重构核。

Result: 在模拟数据（同心圆、瑞士卷）和真实数据（癌症分子活性、IoT网络入侵）上的实验验证了该方法的有效性。

Conclusion: 所提方法是自重构性质的一种扩展，融合并改进了核学习理论中的经典结果，为流形学习提供了新思路。

Abstract: Motivated by the growing interest in representation learning approaches that uncover the latent structure of high-dimensional data, this work proposes new algorithms for reconstruction-based manifold learning within Reproducing-Kernel Hilbert Spaces (RKHS). Each observation is first reconstructed as a linear combination of the other samples in the RKHS, by optimizing a vector form of the Representer Theorem for their autorepresentation property. A separable operator-valued kernel extends the formulation to vector-valued data while retaining the simplicity of a single scalar similarity function. A subsequent kernel-alignment task projects the data into a lower-dimensional latent space whose Gram matrix aims to match the high-dimensional reconstruction kernel, thus transferring the auto-reconstruction geometry of the RKHS to the embedding. Therefore, the proposed algorithms represent an extended approach to the autorepresentation property, exhibited by many natural data, by using and adapting well-known results of Kernel Learning Theory. Numerical experiments on both simulated (concentric circles and swiss-roll) and real (cancer molecular activity and IoT network intrusions) datasets provide empirical evidence of the practical effectiveness of the proposed approach.

</details>


### [225] [Detecting Autism Spectrum Disorder with Deep Eye Movement Features](https://arxiv.org/abs/2601.05812)
*Zhanpei Huang,Taochen chen,Fangqing Gu,Yiqun Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种针对眼动数据特点设计的离散短时序（DSTS）建模框架，用于自闭症谱系障碍（ASD）检测，通过类感知表征与不平衡感知机制，显著优于传统机器学习与现有深度模型。


<details>
  <summary>Details</summary>
Motivation: 眼动数据具有离散性与短时依赖性，而主流Transformer模型依赖长程注意力，在该任务中效果有限，因此需要更适配局部时序模式的专用建模方法。

Method: 提出离散短时序（DSTS）建模框架，融合类感知表征（增强判别性）与不平衡感知机制（缓解标签不平衡），专为捕捉眼动数据中的局部、短时、离散模式而设计。

Result: 在多个眼动数据集上，DSTS显著优于传统机器学习方法及更复杂的深度学习模型。

Conclusion: 针对眼动数据特性定制的局部时序建模比通用长程注意力更有效；DSTS为ASD无创筛查提供了高性能、可解释的新范式。

Abstract: Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by deficits in social communication and behavioral patterns. Eye movement data offers a non-invasive diagnostic tool for ASD detection, as it is inherently discrete and exhibits short-term temporal dependencies, reflecting localized gaze focus between fixation points. These characteristics enable the data to provide deeper insights into subtle behavioral markers, distinguishing ASD-related patterns from typical development. Eye movement signals mainly contain short-term and localized dependencies. However, despite the widespread application of stacked attention layers in Transformer-based models for capturing long-range dependencies, our experimental results indicate that this approach yields only limited benefits when applied to eye movement data. This may be because discrete fixation points and short-term dependencies in gaze focus reduce the utility of global attention mechanisms, making them less efficient than architectures focusing on local temporal patterns. To efficiently capture subtle and complex eye movement patterns, distinguishing ASD from typically developing (TD) individuals, a discrete short-term sequential (DSTS) modeling framework is designed with Class-aware Representation and Imbalance-aware Mechanisms. Through extensive experiments on several eye movement datasets, DSTS outperforms both traditional machine learning techniques and more sophisticated deep learning models.

</details>


### [226] [A Dual Pipeline Machine Learning Framework for Automated Multi Class Sleep Disorder Screening Using Hybrid Resampling and Ensemble Learning](https://arxiv.org/abs/2601.05814)
*Md Sultanul Islam Ovi,Muhsina Tarannum Munfa,Miftahul Alam Adib,Syed Sabbir Hasan*

Main category: cs.LG

TL;DR: 本文提出了一种双通道机器学习框架，用于基于睡眠健康与生活方式数据集的多类睡眠障碍（如失眠和睡眠呼吸暂停）筛查，结合统计与非线性特征学习方法，并采用SMOTETomek处理类别不平衡，在准确率（98.67%）和推理延迟（<400ms）上均优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 临床睡眠研究资源密集、难以规模化用于人群级筛查，亟需高效、准确的自动化睡眠障碍风险分层方法。

Method: 构建双通道机器学习框架：一为基于互信息与线性判别分析的统计流水线；二为结合Boruta特征选择与自编码器的包装式非线性流水线；并采用SMOTETomek处理类别不平衡。

Result: Extra Trees与KNN模型在该框架下达到98.67%分类准确率，显著优于近期基线（Wilcoxon检验p<0.05），推理延迟低于400毫秒。

Conclusion: 所提双通道框架可实现高精度、低延迟的无创睡眠障碍自动筛查，适用于大规模风险分层应用。

Abstract: Accurate classification of sleep disorders, particularly insomnia and sleep apnea, is important for reducing long term health risks and improving patient quality of life. However, clinical sleep studies are resource intensive and are difficult to scale for population level screening. This paper presents a Dual Pipeline Machine Learning Framework for multi class sleep disorder screening using the Sleep Health and Lifestyle dataset. The framework consists of two parallel processing streams: a statistical pipeline that targets linear separability using Mutual Information and Linear Discriminant Analysis, and a wrapper based pipeline that applies Boruta feature selection with an autoencoder for non linear representation learning. To address class imbalance, we use the hybrid SMOTETomek resampling strategy. In experiments, Extra Trees and K Nearest Neighbors achieved an accuracy of 98.67%, outperforming recent baselines on the same dataset. Statistical testing using the Wilcoxon Signed Rank Test indicates that the improvement over baseline configurations is significant, and inference latency remains below 400 milliseconds. These results suggest that the proposed dual pipeline design supports accurate and efficient automated screening for non invasive sleep disorder risk stratification.

</details>


### [227] [A New Family of Poisson Non-negative Matrix Factorization Methods Using the Shifted Log Link](https://arxiv.org/abs/2601.05845)
*Eric Weine,Peter Carbonetto,Rafael A. Irizarry,Matthew Stephens*

Main category: cs.LG

TL;DR: 本文提出了一种带移位对数链接函数的泊松非负矩阵分解（Poisson NMF）方法，通过调节单一参数，使模型在加性组合与更接近乘性组合之间灵活过渡，并提供了高效的最大似然拟合算法，尤其适用于大型稀疏计数数据，提升了结果的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有泊松NMF方法均假设分解出的‘部分’以加性方式组合，但该假设在某些实际场景中并不合理，限制了模型灵活性与可解释性。

Method: 引入带单一调参参数的移位对数链接函数替代标准加性链接；推导最大似然估计算法，并设计针对大规模稀疏数据的高效近似计算方法（计算复杂度仅与数据矩阵非零元个数成正比）。

Result: 在多个真实数据集上的实验表明，链接函数的选择显著影响分解结果；移位对数链接在某些场景下比标准加性链接更具可解释性。

Conclusion: 泊松NMF中链接函数的选择至关重要；移位对数链接提供了一种简单而有效的机制，在加性与乘性建模间实现平滑过渡，拓展了泊松NMF的适用范围与实用性。

Abstract: Poisson non-negative matrix factorization (NMF) is a widely used method to find interpretable "parts-based" decompositions of count data. While many variants of Poisson NMF exist, existing methods assume that the "parts" in the decomposition combine additively. This assumption may be natural in some settings, but not in others. Here we introduce Poisson NMF with the shifted-log link function to relax this assumption. The shifted-log link function has a single tuning parameter, and as this parameter varies the model changes from assuming that parts combine additively (i.e., standard Poisson NMF) to assuming that parts combine more multiplicatively. We provide an algorithm to fit this model by maximum likelihood, and also an approximation that substantially reduces computation time for large, sparse datasets (computations scale with the number of non-zero entries in the data matrix). We illustrate these new methods on a variety of real datasets. Our examples show how the choice of link function in Poisson NMF can substantively impact the results, and how in some settings the use of a shifted-log link function may improve interpretability compared with the standard, additive link.

</details>


### [228] [IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck](https://arxiv.org/abs/2601.05870)
*Huilin Deng,Hongchen Luo,Yue Zhu,Long Li,Zhuoyue Chen,Xinghao Zhao,Ming Li,Jihai Zhang,Mengchang Wang,Yang Cao,Yu Kang*

Main category: cs.LG

TL;DR: 本文提出IIB-LPO方法，通过信息瓶颈原理实现推理路径的潜在分支与筛选，缓解LLM在RLVR中的探索坍缩问题，在数学推理任务上显著提升准确率与路径多样性。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法受限于探索坍缩：全局熵正则易导致奖励作弊（如无意义冗长输出），而局部token更新难以克服预训练模型的强归纳偏置。

Method: 提出Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO)，在高熵状态触发潜在分支以实现推理路径拓扑多样化，并利用信息瓶颈原理同时作为轨迹过滤器和自奖励机制，保障探索简洁且信息丰富。

Result: 在四个数学推理基准上达到SOTA，准确率最高提升5.3%，多样性指标最高提升7.4%。

Conclusion: IIB-LPO将探索从token分布的统计扰动转向推理轨迹的拓扑分支，是一种更鲁棒、高效且可解释的RLVR探索机制。

Abstract: Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) for Large Language Model (LLM) reasoning have been hindered by a persistent challenge: exploration collapse. The semantic homogeneity of random rollouts often traps models in narrow, over-optimized behaviors. While existing methods leverage policy entropy to encourage exploration, they face inherent limitations. Global entropy regularization is susceptible to reward hacking, which can induce meaningless verbosity, whereas local token-selective updates struggle with the strong inductive bias of pre-trained models. To address this, we propose Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO), a novel approach that shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. IIB-LPO triggers latent branching at high-entropy states to diversify reasoning paths and employs the Information Bottleneck principle both as a trajectory filter and a self-reward mechanism, ensuring concise and informative exploration. Empirical results across four mathematical reasoning benchmarks demonstrate that IIB-LPO achieves state-of-the-art performance, surpassing prior methods by margins of up to 5.3% in accuracy and 7.4% in diversity metrics.

</details>


### [229] [GlueNN: gluing patchwise analytic solutions with neural networks](https://arxiv.org/abs/2601.05889)
*Doyoung Kim,Donghee Lee,Hye-Sung Lee,Jiheon Lee,Jaeok Yi*

Main category: cs.LG

TL;DR: 本文提出了一种将渐近解析解的积分常数推广为尺度依赖函数的学习框架，通过约束这些系数函数满足原微分方程，实现全局有效且平滑过渡的解，避免传统分片匹配法在边界处失效的问题。


<details>
  <summary>Details</summary>
Motivation: 传统分片匹配法在边界附近因近似形式失效而导致全局解不准确，亟需一种能自动、平滑连接不同渐近区域的替代方法。

Method: 将渐近解析解中的积分常数替换为由神经网络参数化的尺度依赖函数，并以原始微分方程作为物理约束进行训练，使解在整个定义域内自动满足方程。

Result: 在化学动力学和宇宙学典型问题中，该方法能高精度重构全局解，性能优于传统匹配方法。

Conclusion: 该学习框架提供了一种无需人工匹配、兼具物理可解释性与数值鲁棒性的新型渐近解构造范式。

Abstract: In many problems in physics and engineering, one encounters complicated differential equations with strongly scale-dependent terms for which exact analytical or numerical solutions are not available. A common strategy is to divide the domain into several regions (patches) and simplify the equation in each region. When approximate analytic solutions can be obtained in each patch, they are then matched at the interfaces to construct a global solution. However, this patching procedure can fail to reproduce the correct solution, since the approximate forms may break down near the matching boundaries. In this work, we propose a learning framework in which the integration constants of asymptotic analytic solutions are promoted to scale-dependent functions. By constraining these coefficient functions with the original differential equation over the domain, the network learns a globally valid solution that smoothly interpolates between asymptotic regimes, eliminating the need for arbitrary boundary matching. We demonstrate the effectiveness of this framework in representative problems from chemical kinetics and cosmology, where it accurately reproduces global solutions and outperforms conventional matching procedures.

</details>


### [230] [Auditing Fairness under Model Updates: Fundamental Complexity and Property-Preserving Updates](https://arxiv.org/abs/2601.05909)
*Ayoub Ajarra,Debabrota Basu*

Main category: cs.LG

TL;DR: 本文提出了一种面向任意模型更新场景的群体公平性审计框架，基于经验属性优化（EPO）构建PAC审计理论，并引入SP维数刻画策略性更新下的信息复杂度，支持统计均等性、预测误差与鲁棒风险等多种审计目标。


<details>
  <summary>Details</summary>
Motivation: 现实部署中模型所有者会自适应更新模型（如金融市场变化），导致模型类改变但保持被审计属性不变，使得传统审计方法失效，亟需研究在动态更新下可信赖的公平性审计理论。

Method: 提出基于经验属性优化（EPO）oracle的PAC审计通用框架；为统计均等性定义并分析SP维数这一新组合复杂度度量；推导分布无关的审计误差界；将框架推广至预测误差和鲁棒风险等其他审计目标。

Result: 建立了首个支持任意模型更新的群体公平性PAC审计理论；SP维数成功刻画了允许的战略更新的信息复杂度；实现了仅需少量标注样本的高效属性估计；框架具有可扩展性，适用于多种审计性质。

Conclusion: 在模型动态更新场景下，审计可行性取决于被审计属性在更新下的不变性及对应复杂度（如SP维数）；所提EPO框架为可信AI审计提供了坚实的理论基础与实用工具。

Abstract: As machine learning models become increasingly embedded in societal infrastructure, auditing them for bias is of growing importance. However, in real-world deployments, auditing is complicated by the fact that model owners may adaptively update their models in response to changing environments, such as financial markets. These updates can alter the underlying model class while preserving certain properties of interest, raising fundamental questions about what can be reliably audited under such shifts.
  In this work, we study group fairness auditing under arbitrary updates. We consider general shifts that modify the pre-audit model class while maintaining invariance of the audited property. Our goals are two-fold: (i) to characterize the information complexity of allowable updates, by identifying which strategic changes preserve the property under audit; and (ii) to efficiently estimate auditing properties, such as group fairness, using a minimal number of labeled samples.
  We propose a generic framework for PAC auditing based on an Empirical Property Optimization (EPO) oracle. For statistical parity, we establish distribution-free auditing bounds characterized by the SP dimension, a novel combinatorial measure that captures the complexity of admissible strategic updates. Finally, we demonstrate that our framework naturally extends to other auditing objectives, including prediction error and robust risk.

</details>


### [231] [Distilling Lightweight Domain Experts from Large ML Models by Identifying Relevant Subspaces](https://arxiv.org/abs/2601.05913)
*Pattarawat Chormai,Ali Hashemi,Klaus-Robert Müller,Grégoire Montavon*

Main category: cs.LG

TL;DR: 本文提出SubDistill算法，专注于知识蒸馏中仅相关子任务（特定类别及中间概念）的蒸馏，提升数值稳定性并增强学生模型与教师模型决策结构的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法大多面向全任务，而实际中常只需蒸馏少数相关类别及其中间概念；缺乏针对该子任务场景的显式设计方法。

Method: 提出SubDistill算法，在每一层仅蒸馏教师模型中与目标子任务相关的组件，并具备改进的数值性质。

Result: 在CIFAR-100和ImageNet上，使用CNN和Transformer模型的实验表明，SubDistill在多个代表性子任务上优于现有逐层蒸馏方法；XAI分析进一步验证其学生模型更贴近教师模型的决策结构。

Conclusion: SubDistill是一种面向子任务的知识蒸馏新范式，兼顾效率、精度与可解释性，为资源受限场景下的定制化模型压缩提供了有效方案。

Abstract: Knowledge distillation involves transferring the predictive capabilities of large, high-performing AI models (teachers) to smaller models (students) that can operate in environments with limited computing power. In this paper, we address the scenario in which only a few classes and their associated intermediate concepts are relevant to distill. This scenario is common in practice, yet few existing distillation methods explicitly focus on the relevant subtask. To address this gap, we introduce 'SubDistill', a new distillation algorithm with improved numerical properties that only distills the relevant components of the teacher model at each layer. Experiments on CIFAR-100 and ImageNet with Convolutional and Transformer models demonstrate that SubDistill outperforms existing layer-wise distillation techniques on a representative set of subtasks. Our benchmark evaluations are complemented by Explainable AI analyses showing that our distilled student models more closely match the decision structure of the original teacher model.

</details>


### [232] [Prophet as a Repro ducible Forecasting Framework: A Methodological Guide for Business and Financial Analytics](https://arxiv.org/abs/2601.05929)
*Sidney Shapiro,Burhanuddin Panvelwala*

Main category: cs.LG

TL;DR: 本文评估了Meta开源的Prophet预测框架在可复现性、可解释性和易用性方面的优势，通过与ARIMA和随机森林等方法在公开金融与零售数据集上的对比实验，验证其作为可复现预测实践工具的价值。


<details>
  <summary>Details</summary>
Motivation: 解决预测研究与实践中长期存在的可复现性难题，尤其在商业与金融分析等高风险决策场景中，传统方法依赖人工调参、难以复现，而机器学习方法存在可解释性差、训练随机性强、跨环境不可复现等问题。

Method: 采用控制良好且全程文档化的实验设计，在公开金融与零售数据集上，将Prophet与多种ARIMA（自动选择、人工设定、季节性变体）及随机森林进行性能与可解释性对比；辅以具体Python示例展示其工作流集成能力。

Result: Prophet凭借其加法模型结构、开源实现与标准化流程，在保持良好预测性能的同时，显著提升了预测过程的透明度、可复制性与审计性；相比其他方法更易于在Python分析管道中部署和验证。

Conclusion: Prophet并非新算法，而是面向可复现研究的工程化方法论构件；本研究为其在可复现预测实践中的定位提供了实证支持，并为研究者与从业者构建了基于Python的可复现预测参考框架。

Abstract: Reproducibility remains a persistent challenge in forecasting research and practice, particularly in business and financial analytics where forecasts inform high-stakes decisions. Traditional forecasting methods, while theoretically interpretable, often require extensive manual tuning and are difficult to replicate in proprietary environments. Machine learning approaches offer predictive flexibility but introduce challenges related to interpretability, stochastic training procedures, and cross-environment reproducibility. This paper examines Prophet, an open-source forecasting framework developed by Meta, as a reproducibility-enabling solution that balances interpretability, standardized workflows, and accessibility. Rather than proposing a new algorithm, this study evaluates how Prophet's additive structure, open-source implementation, and standardized workflow contribute to transparent and replicable forecasting practice. Using publicly available financial and retail datasets, we compare Prophet's performance and interpretability with multiple ARIMA specifications (auto-selected, manually specified, and seasonal variants) and Random Forest under a controlled and fully documented experimental design. This multi-model comparison provides a robust assessment of Prophet's relative performance and reproducibility advantages. Through concrete Python examples, we demonstrate how Prophet facilitates efficient forecasting workflows and integration with analytical pipelines. The study positions Prophet within the broader context of reproducible research. It highlights Prophet's role as a methodological building block that supports verification, auditability, and methodological rigor. This work provides researchers and practitioners with a practical reference framework for reproducible forecasting in Python-based research workflows.

</details>


### [233] [On the Robustness of Age for Learning-Based Wireless Scheduling in Unknown Environments](https://arxiv.org/abs/2601.05956)
*Juaren Steiger,Bin Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于队首年龄（head-of-line age）而非虚拟队列长度的新型学习型调度策略，以提升约束组合多臂赌博机在信道条件突变场景下的鲁棒性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于虚拟队列长度的算法在信道条件突变导致约束不可行时，虚拟队列长度可能无界增长，系统失稳。

Method: 用队首年龄（即虚拟队列中最老分组的年龄）替代虚拟队列长度作为控制变量，设计新的学习型无线调度策略。

Result: 所提策略在i.i.d.信道下达到业界最优性能；在信道突变和约束不可行期间仍能保持系统稳定，并快速恢复。

Conclusion: 队首年龄比虚拟队列长度更具鲁棒性，是设计适应动态网络约束的学习调度算法更优的状态指标。

Abstract: The constrained combinatorial multi-armed bandit model has been widely employed to solve problems in wireless networking and related areas, including the problem of wireless scheduling for throughput optimization under unknown channel conditions. Most work in this area uses an algorithm design strategy that combines a bandit learning algorithm with the virtual queue technique to track the throughput constraint violation. These algorithms seek to minimize the virtual queue length in their algorithm design. However, in networks where channel conditions change abruptly, the resulting constraints may become infeasible, leading to unbounded growth in virtual queue lengths. In this paper, we make the key observation that the dynamics of the head-of-line age, i.e. the age of the oldest packet in the virtual queue, make it more robust when used in algorithm design compared to the virtual queue length. We therefore design a learning-based scheduling policy that uses the head-of-line age in place of the virtual queue length. We show that our policy matches state-of-the-art performance under i.i.d. network conditions. Crucially, we also show that the system remains stable even under abrupt changes in channel conditions and can rapidly recover from periods of constraint infeasibility.

</details>


### [234] [Community-Based Model Sharing and Generalisation: Anomaly Detection in IoT Temperature Sensor Networks](https://arxiv.org/abs/2601.05984)
*Sahibzada Saadoon Hammad,Joaquín Huerta Guijarro,Francisco Ramos,Michael Gould Carlson,Sergio Trilles Oliver*

Main category: cs.LG

TL;DR: 本文提出了一种基于兴趣社区（CoI）范式的物联网传感器网络异常检测框架，通过融合时间、空间和高程相似性构建相似度矩阵进行聚类，并在各社区内选取代表性站点训练多种自编码器模型，利用重构误差检测温度异常，验证了社区内模型共享的有效性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 物联网设备的快速部署产生了大规模异构传感器网络，亟需有效组织方式；兴趣社区（CoI）为按功能与环境特征分组传感器提供了新思路。

Method: 构建融合Spearman时序相关性、高斯衰减空间距离和高程相似性的融合相似度矩阵进行传感器聚类；每社区基于轮廓系数选取代表性站点；采用贝叶斯优化与扩展窗口交叉验证训练BiLSTM、LSTM和MLP三种自编码器；以正常温度模式训练，通过重构误差检测异常。

Result: 各社区内部异常检测性能稳健，跨社区表现存在差异；验证了社区内模型共享可降低计算开销，并支持分析模型在不同IoT传感器网络间的泛化能力。

Conclusion: 基于CoI的异常检测框架可行且有效，社区划分与模型共享策略有助于提升IoT传感网络中异常检测的效率与可扩展性。

Abstract: The rapid deployment of Internet of Things (IoT) devices has led to large-scale sensor networks that monitor environmental and urban phenomena in real time. Communities of Interest (CoIs) provide a promising paradigm for organising heterogeneous IoT sensor networks by grouping devices with similar operational and environmental characteristics. This work presents an anomaly detection framework based on the CoI paradigm by grouping sensors into communities using a fused similarity matrix that incorporates temporal correlations via Spearman coefficients, spatial proximity using Gaussian distance decay, and elevation similarities. For each community, representative stations based on the best silhouette are selected and three autoencoder architectures (BiLSTM, LSTM, and MLP) are trained using Bayesian hyperparameter optimization with expanding window cross-validation and tested on stations from the same cluster and the best representative stations of other clusters. The models are trained on normal temperature patterns of the data and anomalies are detected through reconstruction error analysis. Experimental results show a robust within-community performance across the evaluated configurations, while variations across communities are observed. Overall, the results support the applicability of community-based model sharing in reducing computational overhead and to analyse model generalisability across IoT sensor networks.

</details>


### [235] [LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection](https://arxiv.org/abs/2601.06016)
*Þór Sverrisson,Steinn Guðmundsson*

Main category: cs.LG

TL;DR: 本文提出LookAroundNet，一种基于Transformer的癫痫发作自动检测方法，通过利用更宽的时间窗口（包括目标片段前后）的EEG数据来建模发作动态，模拟临床医生解读EEG时依赖上下文的习惯；在多种多样、涵盖临床与家庭环境的EEG数据集上验证其泛化性与实用性，结果表明其性能稳健、计算成本适配临床部署。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作在不同患者、记录条件和临床场景下动态变化大，导致自动检测困难；现有方法常忽略EEG片段周围的上下文信息，而临床判读高度依赖该信息。

Method: 提出LookAroundNet：基于Transformer的模型，输入包含目标时段及其前后扩展时间窗的EEG信号；采用多源异构EEG数据（含公开数据集与大规模私有居家EEG数据）进行训练与评估，并结合模型集成策略。

Result: LookAroundNet在多个跨域EEG数据集（常规临床EEG、长程动态/居家EEG）上均取得优异且稳健的检测性能；展现出对未见过的记录条件的良好泛化能力；计算开销满足临床实时部署需求。

Conclusion: 扩展时间上下文、增加训练数据多样性及模型集成是提升癫痫自动检测性能的关键；本工作推动自动 seizure 检测向临床可用方案迈进。

Abstract: Automated seizure detection from electroencephalography (EEG) remains difficult due to the large variability of seizure dynamics across patients, recording conditions, and clinical settings. We introduce LookAroundNet, a transformer-based seizure detector that uses a wider temporal window of EEG data to model seizure activity. The seizure detector incorporates EEG signals before and after the segment of interest, reflecting how clinicians use surrounding context when interpreting EEG recordings. We evaluate the proposed method on multiple EEG datasets spanning diverse clinical environments, patient populations, and recording modalities, including routine clinical EEG and long-term ambulatory recordings, in order to study performance across varying data distributions. The evaluation includes publicly available datasets as well as a large proprietary collection of home EEG recordings, providing complementary views of controlled clinical data and unconstrained home-monitoring conditions. Our results show that LookAroundNet achieves strong performance across datasets, generalizes well to previously unseen recording conditions, and operates with computational costs compatible with real-world clinical deployment. The results indicate that extended temporal context, increased training data diversity, and model ensembling are key factors for improving performance. This work contributes to moving automatic seizure detection models toward clinically viable solutions.

</details>
