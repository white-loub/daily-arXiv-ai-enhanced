<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 296]
- [cs.CL](#cs.CL) [Total: 88]
- [cs.AI](#cs.AI) [Total: 82]
- [cs.IR](#cs.IR) [Total: 21]
- [cs.MA](#cs.MA) [Total: 11]
- [cs.RO](#cs.RO) [Total: 55]
- [cs.LG](#cs.LG) [Total: 281]
- [cs.GR](#cs.GR) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Psychological stress during Examination and its estimation by handwriting in answer script](https://arxiv.org/abs/2511.11633)
*Abhijeet Kumar,Chetan Agarwal,Pronoy B. Neogi,Mayank Goswami*

Main category: cs.CV

TL;DR: 提出了一种结合笔迹学与人工智能的方法，通过分析学生手写试卷来量化其心理压力水平。


<details>
  <summary>Details</summary>
Motivation: 传统评分系统无法反映学生在考试期间的认知和情绪状态，因此需要一种能够评估心理压力的新方法。

Method: 利用高分辨率图像处理、TrOCR进行文字识别，并结合基于RoBERTa的模型进行情感分析与情感熵融合，通过五模型投票机制和无监督异常检测生成数值化的压力指数。

Result: 实现了对心理压力水平的量化评估，系统具有较强的鲁棒性，并在学术取证领域展现出创新性。

Conclusion: 该方法为教育评估提供了超越传统打分的新视角，有助于理解学生的认知与情绪状态。

Abstract: This research explores the fusion of graphology and artificial intelligence to quantify psychological stress levels in students by analyzing their handwritten examination scripts. By leveraging Optical Character Recognition and transformer based sentiment analysis models, we present a data driven approach that transcends traditional grading systems, offering deeper insights into cognitive and emotional states during examinations. The system integrates high resolution image processing, TrOCR, and sentiment entropy fusion using RoBERTa based models to generate a numerical Stress Index. Our method achieves robustness through a five model voting mechanism and unsupervised anomaly detection, making it an innovative framework in academic forensics.

</details>


### [2] [Real-time pothole detection with onboard sensors and camera on vehicles](https://arxiv.org/abs/2511.11643)
*Aswath Muthuselvam,Jeevak Raj S,Mohanaprasad K*

Main category: cs.CV

TL;DR: 本文提出了一种利用车载传感器实时检测路面坑洼的方法，采用SVM分类器实现了98.1%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 由于道路上车辆数量逐年增加，频繁监测道路状况对于保障交通流畅和及时修复小裂缝以防止其发展为大坑洼至关重要。

Method: 使用车载传感器收集数据，并采用支持向量机（SVM）分类器对坑洼进行实时识别。

Result: 在本地2公里长、分布有26个坑洼的道路上测试，系统达到了98.1%的检测准确率。

Conclusion: 该方法能够高效准确地识别道路坑洼，具备大规模应用潜力，有助于提升道路维护效率。

Abstract: Road conditions play an important role in our everyday commute. With the proliferating number of vehicles on the road each year, it has become necessary to access the road conditions very frequently, this would ensure that the traffic also flows smoothly. Even the smallest crack in the road could be easily be chipped into a large pothole due to changing surface temperatures of the road and from the force of vehicles riding over it. In this paper, we have addressed how we could better identify these potholes in realtime with the help of onboard sensors in vehicles so that the data could be useful for analysis and better management of potholes on a large scale. For the implementation, we used an SVM classifier to detect potholes, we achieved 98.1% accuracy based on data collected from a local road for about 2 km which had 26 potholes distributed along the road. Code is available at: https://github.com/aswathselvam/Potholes

</details>


### [3] [A Method for Identifying Farmland System Habitat Types Based on the Dynamic-Weighted Feature Fusion Network Model](https://arxiv.org/abs/2511.11659)
*Kesong Zheng,Zhi Song,Peizhou Li,Shuyi Yao,Zhenxing Bian*

Main category: cs.CV

TL;DR: 本研究针对耕地生态系统栖息地分类标准不统一、类型覆盖不全及现有模型语义与纹理特征融合不足导致分割精度低的问题，构建了包含15类耕地栖息地的超高清遥感图像数据集，并提出一种动态加权特征融合网络（DWFF-Net），在编码器中利用冻结参数的DINOv3提取基础特征，通过数据级自适应动态加权策略实现特征融合，解码器引入动态权重计算网络和混合损失函数优化训练。实验结果显示该模型mIoU达0.6979，F1-score达0.8049，优于基线模型，尤其提升了田埂等微生境的识别精度，实现了低成本亚米级精度的耕地栖息地制图。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏统一的耕地生态系统栖息地分类体系，且现有模型难以有效融合语义与纹理特征，导致多尺度栖息地（如大田块与微生境）分割精度不高、边界模糊，亟需提高识别精度与细粒度监测能力。

Method: 构建了一个涵盖15类耕地栖息地的高分辨率遥感影像标注数据集；提出DWFF-Net模型，其编码器采用冻结参数的DINOv3提取基础特征，引入数据级自适应动态加权策略进行特征融合；解码器设计动态权重计算网络以充分融合多层特征，并采用混合损失函数优化训练过程。

Result: 在自建数据集上，模型mIoU达到0.6979，F1-score为0.8049，分别比基线模型提升0.021和0.0161；消融实验验证了多层特征融合的互补性，显著提升了田埂等微生境类别的IoU表现。

Conclusion: 本研究建立了一种基于自适应多层特征融合的耕地系统栖息地识别框架，实现了高精度、低成本的亚米级栖息地制图，为耕地景观的细粒度生态监测提供了有力的技术支持。

Abstract: Addressing the current lack of a standardized habitat classification system for cultivated land ecosystems, incomplete coverage of habitat types, and the inability of existing models to effectively integrate semantic and texture features-resulting in insufficient segmentation accuracy and blurred boundaries for multi-scale habitats (e.g., large-scale field plots and micro-habitats)-this study developed a comprehensively annotated ultra-high-resolution remote sensing image dataset encompassing 15 categories of cultivated land system habitats. Furthermore, we propose a Dynamic-Weighted Feature Fusion Network (DWFF-Net). The encoder of this model utilizes a frozen-parameter DINOv3 to extract foundational features. By analyzing the relationships between different category images and feature maps, we introduce a data-level adaptive dynamic weighting strategy for feature fusion. The decoder incorporates a dynamic weight computation network to achieve thorough integration of multi-layer features, and a hybrid loss function is adopted to optimize model training. Experimental results on the constructed dataset demonstrate that the proposed model achieves a mean Intersection over Union (mIoU) of 0.6979 and an F1-score of 0.8049, outperforming the baseline network by 0.021 and 0.0161, respectively. Ablation studies further confirm the complementary nature of multi-layer feature fusion, which effectively improves the IoU for micro-habitat categories such as field ridges. This study establishes a habitat identification framework for cultivated land systems based on adaptive multi-layer feature fusion, enabling sub-meter precision habitat mapping at a low cost and providing robust technical support for fine-grained habitat monitoring in cultivated landscapes.

</details>


### [4] [AGENet: Adaptive Edge-aware Geodesic Distance Learning for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2511.11662)
*Ziyuan Gao*

Main category: cs.CV

TL;DR: 提出AGENet，一种基于自适应测地线边缘感知的轻量级医学图像分割框架，在少量标注数据下实现精确边界分割。


<details>
  <summary>Details</summary>
Motivation: 现有少样本医学图像分割方法在解剖结构相似且空间上下文不足时，边界划分不精确，性能有限。

Method: 通过边缘感知的测地线距离学习、自适应原型提取和自适应参数学习三个模块，结合几何先验与空间加权聚合，利用轻量级几何建模提升分割精度。

Result: 在多个医学影像数据集上优于现有方法，显著减少边界误差，同时保持高效计算。

Conclusion: AGENet在少样本条件下能有效提升医学图像分割的边界精度，适用于需高精度且标注数据有限的临床场景。

Abstract: Medical image segmentation requires large annotated datasets, creating a significant bottleneck for clinical applications. While few-shot segmentation methods can learn from minimal examples, existing approaches demonstrate suboptimal performance in precise boundary delineation for medical images, particularly when anatomically similar regions appear without sufficient spatial context. We propose AGENet (Adaptive Geodesic Edge-aware Network), a novel framework that incorporates spatial relationships through edge-aware geodesic distance learning. Our key insight is that medical structures follow predictable geometric patterns that can guide prototype extraction even with limited training data. Unlike methods relying on complex architectural components or heavy neural networks, our approach leverages computationally lightweight geometric modeling. The framework combines three main components: (1) An edge-aware geodesic distance learning module that respects anatomical boundaries through iterative Fast Marching refinement, (2) adaptive prototype extraction that captures both global structure and local boundary details via spatially-weighted aggregation, and (3) adaptive parameter learning that automatically adjusts to different organ characteristics. Extensive experiments across diverse medical imaging datasets demonstrate improvements over state-of-the-art methods. Notably, our method reduces boundary errors compared to existing approaches while maintaining computational efficiency, making it highly suitable for clinical applications requiring precise segmentation with limited annotated data.

</details>


### [5] [EPSegFZ: Efficient Point Cloud Semantic Segmentation for Few- and Zero-Shot Scenarios with Language Guidance](https://arxiv.org/abs/2511.11700)
*Jiahui Wang,Haiyue Zhu,Haoren Guo,Abdullah Al Mamun,Cheng Xiang,Tong Heng Lee*

Main category: cs.CV

TL;DR: 提出了一种无需预训练的点云语义分割网络EPSegFZ，通过ProERA、DRPE和LGPE模块提升少样本和零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖预训练且未充分利用支持集中的文本等信息，限制了模型灵活性和性能。

Method: 设计了无需预训练的EPSegFZ网络，包含ProERA和DRPE模块用于特征提取，以及利用文本信息的LGPE模块。

Result: 在S3DIS和ScanNet上分别比现有方法提升5.68%和3.82%。

Conclusion: EPSegFZ有效提升了少样本和零样本点云语义分割性能，具备良好的灵活性和泛化能力。

Abstract: Recent approaches for few-shot 3D point cloud semantic segmentation typically require a two-stage learning process, i.e., a pre-training stage followed by a few-shot training stage. While effective, these methods face overreliance on pre-training, which hinders model flexibility and adaptability. Some models tried to avoid pre-training yet failed to capture ample information. In addition, current approaches focus on visual information in the support set and neglect or do not fully exploit other useful data, such as textual annotations. This inadequate utilization of support information impairs the performance of the model and restricts its zero-shot ability. To address these limitations, we present a novel pre-training-free network, named Efficient Point Cloud Semantic Segmentation for Few- and Zero-shot scenarios. Our EPSegFZ incorporates three key components. A Prototype-Enhanced Registers Attention (ProERA) module and a Dual Relative Positional Encoding (DRPE)-based cross-attention mechanism for improved feature extraction and accurate query-prototype correspondence construction without pre-training. A Language-Guided Prototype Embedding (LGPE) module that effectively leverages textual information from the support set to improve few-shot performance and enable zero-shot inference. Extensive experiments show that our method outperforms the state-of-the-art method by 5.68% and 3.82% on the S3DIS and ScanNet benchmarks, respectively.

</details>


### [6] [Co-Layout: LLM-driven Co-optimization for Interior Layout](https://arxiv.org/abs/2511.12474)
*Chucheng Xiang,Ruchao Bao,Biyin Feng,Wenzheng Wu,Zhongyuan Liu,Yirui Guan,Ligang Liu*

Main category: cs.CV

TL;DR: 提出了一种结合大语言模型（LLM）与基于网格的整数规划的自动化室内设计框架，通过联合优化房间布局和家具布置，显著优于传统两阶段方法。


<details>
  <summary>Details</summary>
Motivation: 传统室内设计自动化方法通常采用两阶段流程，难以实现全局最优；本文旨在通过联合优化提升设计质量和效率。

Method: 利用LLM从文本提示中提取结构化设计约束，并将其编码为受“Modulor”启发的统一网格表示，结合粗到精的优化策略进行整数规划求解。

Result: 在多种场景下的实验表明，该方法在解的质量上显著优于现有两阶段流程，并通过粗到精策略实现了更高的计算效率。

Conclusion: 所提出的联合优化框架能有效整合语义理解与空间规划，为自动化室内设计提供了高效且高质量的解决方案。

Abstract: We present a novel framework for automated interior design that combines large language models (LLMs) with grid-based integer programming to jointly optimize room layout and furniture placement. Given a textual prompt, the LLM-driven agent workflow extracts structured design constraints related to room configurations and furniture arrangements. These constraints are encoded into a unified grid-based representation inspired by ``Modulor". Our formulation accounts for key design requirements, including corridor connectivity, room accessibility, spatial exclusivity, and user-specified preferences. To improve computational efficiency, we adopt a coarse-to-fine optimization strategy that begins with a low-resolution grid to solve a simplified problem and guides the solution at the full resolution. Experimental results across diverse scenarios demonstrate that our joint optimization approach significantly outperforms existing two-stage design pipelines in solution quality, and achieves notable computational efficiency through the coarse-to-fine strategy.

</details>


### [7] [Task-Aware 3D Affordance Segmentation via 2D Guidance and Geometric Refinement](https://arxiv.org/abs/2511.11702)
*Lian He,Meng Liu,Qilang Ye,Yu Zhou,Xiang Deng,Gangyi Ding*

Main category: cs.CV

TL;DR: 提出了一种名为TASA的新框架，用于任务感知的3D场景级可操作性分割，结合2D语义线索与3D几何推理，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注对象级可操作性或将2D预测升维至3D，忽略了点云中的丰富几何结构信息，且计算成本高，难以实现有效的场景级语义与空间理解。

Method: TASA采用粗到精的方式，首先通过任务感知的2D可操作性检测模块从语言和视觉输入中识别可操作点，指导选择任务相关视图；然后设计3D可操作性细化模块，融合2D语义先验与局部3D几何信息，生成精确且空间连贯的3D可操作性掩码。

Result: 在SceneFun3D数据集上的实验表明，TASA在场景级可操作性分割任务中显著优于基线方法，兼具更高的准确性和效率。

Conclusion: TASA有效整合了2D语义与3D几何信息，实现了高效、准确的任务感知3D场景级可操作性分割，为具身智能体在复杂环境中的交互提供了更强的场景理解能力。

Abstract: Understanding 3D scene-level affordances from natural language instructions is essential for enabling embodied agents to interact meaningfully in complex environments. However, this task remains challenging due to the need for semantic reasoning and spatial grounding. Existing methods mainly focus on object-level affordances or merely lift 2D predictions to 3D, neglecting rich geometric structure information in point clouds and incurring high computational costs. To address these limitations, we introduce Task-Aware 3D Scene-level Affordance segmentation (TASA), a novel geometry-optimized framework that jointly leverages 2D semantic cues and 3D geometric reasoning in a coarse-to-fine manner. To improve the affordance detection efficiency, TASA features a task-aware 2D affordance detection module to identify manipulable points from language and visual inputs, guiding the selection of task-relevant views. To fully exploit 3D geometric information, a 3D affordance refinement module is proposed to integrate 2D semantic priors with local 3D geometry, resulting in accurate and spatially coherent 3D affordance masks. Experiments on SceneFun3D demonstrate that TASA significantly outperforms the baselines in both accuracy and efficiency in scene-level affordance segmentation.

</details>


### [8] [LE-CapsNet: A Light and Enhanced Capsule Network](https://arxiv.org/abs/2511.11708)
*Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: 提出了一种轻量、增强且更准确的CapsNet变体LE-CapsNet，在减少参数和提升推理速度的同时，提高了在CIFAR-10和AffNIST数据集上的分类精度。


<details>
  <summary>Details</summary>
Motivation: CapsNet虽然在处理重叠类别和变换图像方面优于CNN，但存在速度慢、资源消耗大、参数多且精度不足的问题，因此需要一种更高效准确的模型。

Method: 设计了轻量化的LE-CapsNet结构，优化网络参数与计算流程，提升推理速度和模型准确性。

Result: LE-CapsNet使用380万权重，在CIFAR-10上达到76.73%的准确率，推理速度比CapsNet快4倍；在AffNIST上准确率达到94.3%（CapsNet为90.52%）。

Conclusion: LE-CapsNet在保持CapsNet优势的同时，显著提升了效率和精度，是一种更实用的CapsNet改进方案。

Abstract: Capsule Network (CapsNet) classifier has several advantages over CNNs, including better detection of images containing overlapping categories and higher accuracy on transformed images. Despite the advantages, CapsNet is slow due to its different structure. In addition, CapsNet is resource-hungry, includes many parameters and lags in accuracy compared to CNNs. In this work, we propose LE-CapsNet as a light, enhanced and more accurate variant of CapsNet. Using 3.8M weights, LECapsNet obtains 76.73% accuracy on the CIFAR-10 dataset while performing inference 4x faster than CapsNet. In addition, our proposed network is more robust at detecting images with affine transformations compared to CapsNet. We achieve 94.3% accuracy on the AffNIST dataset (compared to CapsNet 90.52%).

</details>


### [9] [Lightweight Optimal-Transport Harmonization on Edge Devices](https://arxiv.org/abs/2511.12785)
*Maria Larchenko,Dmitry Guskov,Alexander Lobashev,Georgy Derevyanko*

Main category: cs.CV

TL;DR: 提出一种轻量级的AR颜色协调方法MKL-Harmonizer，利用最优传输理论实现设备端实时推理，在真实AR图像上表现优于现有方法，并发布配套数据集和工具包。


<details>
  <summary>Details</summary>
Motivation: 现有颜色协调算法难以满足增强现实（AR）中实时处理的需求，缺乏适用于AR流水线的高效解决方案。

Method: 基于经典最优传输理论，训练一个紧凑编码器来预测Monge-Kantorovich传输映射，实现轻量化的颜色协调模型。

Result: 在真实AR合成图像上，MKL-Harmonizer相较于最先进方法取得了最佳的综合评分，支持设备端实时推理。

Conclusion: 该方法为AR应用提供了高效的颜色协调解决方案，推动了其实用化进展，并通过公开数据集和工具促进后续研究。

Abstract: Color harmonization adjusts the colors of an inserted object so that it perceptually matches the surrounding image, resulting in a seamless composite. The harmonization problem naturally arises in augmented reality (AR), yet harmonization algorithms are not currently integrated into AR pipelines because real-time solutions are scarce. In this work, we address color harmonization for AR by proposing a lightweight approach that supports on-device inference. For this, we leverage classical optimal transport theory by training a compact encoder to predict the Monge-Kantorovich transport map. We benchmark our MKL-Harmonizer algorithm against state-of-the-art methods and demonstrate that for real composite AR images our method achieves the best aggregated score. We release our dedicated AR dataset of composite images with pixel-accurate masks and data-gathering toolkit to support further data acquisition by researchers.

</details>


### [10] [Target-Balanced Score Distillation](https://arxiv.org/abs/2511.11710)
*Zhou Xu,Qi Wang,Yuxiao Yang,Luyuan Zhang,Zhang Liang,Yang Li*

Main category: cs.CV

TL;DR: 提出了一种新的目标平衡得分蒸馏（TBSD）方法，通过多目标优化和自适应策略解决3D生成中纹理与形状的权衡问题，显著提升了纹理保真度和几何准确性。


<details>
  <summary>Details</summary>
Motivation: 原始的SDS方法存在过饱和和过平滑问题，引入负提示虽有改进但面临纹理优化与形状失真的权衡，需要一种能同时提升纹理质量和保持形状准确的方法。

Method: 通过系统分析发现负提示中包含目标信息会导致形状失真，据此提出TBSD，将生成过程建模为多目标优化问题，并设计自适应策略平衡正负提示的影响。

Result: 实验表明TBSD在多个指标上优于现有最先进方法，能够生成高保真纹理且几何形状准确的3D资产。

Conclusion: TBSD有效解决了使用负提示带来的纹理-形状权衡问题，为基于扩散模型的3D资产生成提供了更优解决方案。

Abstract: Score Distillation Sampling (SDS) enables 3D asset generation by distilling priors from pretrained 2D text-to-image diffusion models, but vanilla SDS suffers from over-saturation and over-smoothing. To mitigate this issue, recent variants have incorporated negative prompts. However, these methods face a critical trade-off: limited texture optimization, or significant texture gains with shape distortion. In this work, we first conduct a systematic analysis and reveal that this trade-off is fundamentally governed by the utilization of the negative prompts, where Target Negative Prompts (TNP) that embed target information in the negative prompts dramatically enhancing texture realism and fidelity but inducing shape distortions. Informed by this key insight, we introduce the Target-Balanced Score Distillation (TBSD). It formulates generation as a multi-objective optimization problem and introduces an adaptive strategy that effectively resolves the aforementioned trade-off. Extensive experiments demonstrate that TBSD significantly outperforms existing state-of-the-art methods, yielding 3D assets with high-fidelity textures and geometrically accurate shape.

</details>


### [11] [PFAvatar: Pose-Fusion 3D Personalized Avatar Reconstruction from Real-World Outfit-of-the-Day Photos](https://arxiv.org/abs/2511.12935)
*Dianbing Xi,Guoyuan An,Jingsen Zhu,Zhijian Liu,Yuan Liu,Ruiyuan Zhang,Jiayuan Lu,Rui Wang,Yuchi Huo*

Main category: cs.CV

TL;DR: 提出PFAvatar，一种从日常穿搭照片中重建高质量3D头像的新方法，通过两阶段流程实现：先微调姿态感知扩散模型，再蒸馏基于NeRF的3D头像表示，显著提升细节保留和对遮挡的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多样姿态、遮挡和复杂背景的OOTD照片时，因图像分割导致不一致问题，且3D重建速度慢、细节丢失严重。

Method: 第一阶段利用预训练ControlNet和新提出的条件先验保持损失（CPPL），在少量样本下端到端微调姿态感知扩散模型；第二阶段通过SMPL-X规范空间采样和多分辨率3D-SDS优化NeRF表示。

Result: PFAvatar在5分钟内完成个性化重建，比先前方法快48倍，在重建保真度、细节保留和遮挡处理方面优于现有最先进方法，并支持虚拟试穿、动画等下游应用。

Conclusion: PFAvatar实现了从真实世界OOTD照片高效生成高质量、高保真的3D头像，具有良好的实用性和广泛应用前景。

Abstract: We propose PFAvatar (Pose-Fusion Avatar), a new method that reconstructs high-quality 3D avatars from ``Outfit of the Day'' (OOTD) photos, which exhibit diverse poses, occlusions, and complex backgrounds. Our method consists of two stages: (1) fine-tuning a pose-aware diffusion model from few-shot OOTD examples and (2) distilling a 3D avatar represented by a neural radiance field (NeRF). In the first stage, unlike previous methods that segment images into assets (e.g., garments, accessories) for 3D assembly, which is prone to inconsistency, we avoid decomposition and directly model the full-body appearance. By integrating a pre-trained ControlNet for pose estimation and a novel Condition Prior Preservation Loss (CPPL), our method enables end-to-end learning of fine details while mitigating language drift in few-shot training. Our method completes personalization in just 5 minutes, achieving a 48$\times$ speed-up compared to previous approaches. In the second stage, we introduce a NeRF-based avatar representation optimized by canonical SMPL-X space sampling and Multi-Resolution 3D-SDS. Compared to mesh-based representations that suffer from resolution-dependent discretization and erroneous occluded geometry, our continuous radiance field can preserve high-frequency textures (e.g., hair) and handle occlusions correctly through transmittance. Experiments demonstrate that PFAvatar outperforms state-of-the-art methods in terms of reconstruction fidelity, detail preservation, and robustness to occlusions/truncations, advancing practical 3D avatar generation from real-world OOTD albums. In addition, the reconstructed 3D avatar supports downstream applications such as virtual try-on, animation, and human video reenactment, further demonstrating the versatility and practical value of our approach.

</details>


### [12] [CompressNAS : A Fast and Efficient Technique for Model Compression using Decomposition](https://arxiv.org/abs/2511.11716)
*Sudhakar Sah,Nikhil Chabbra,Matthieu Durnerin*

Main category: cs.CV

TL;DR: 提出CompressNAS框架，通过全局搜索进行低秩张量分解的秩选择，在保证精度的同时显著压缩CNN模型。


<details>
  <summary>Details</summary>
Motivation: 深度卷积神经网络在微控制器和轻量级NPU上部署困难，现有低秩分解方法多局部选择秩，忽略压缩与精度间的全局权衡。

Method: 将秩选择视为全局搜索问题，采用快速精度估计器在内存和精度约束下高效探索候选分解方案。

Result: 在ImageNet上将ResNet-18压缩8倍且精度下降小于4%；在COCO上YOLOv5s压缩2倍无精度损失，YOLOv5n压缩2倍精度下降2.5%；并提出性能优越的STResNet模型家族。

Conclusion: CompressNAS能有效实现CNN模型的高倍压缩，兼顾精度与资源限制，适用于边缘设备部署。

Abstract: Deep Convolutional Neural Networks (CNNs) are increasingly difficult to deploy on microcontrollers (MCUs) and lightweight NPUs (Neural Processing Units) due to their growing size and compute demands. Low-rank tensor decomposition, such as Tucker factorization, is a promising way to reduce parameters and operations with reasonable accuracy loss. However, existing approaches select ranks locally and often ignore global trade-offs between compression and accuracy. We introduce CompressNAS, a MicroNAS-inspired framework that treats rank selection as a global search problem. CompressNAS employs a fast accuracy estimator to evaluate candidate decompositions, enabling efficient yet exhaustive rank exploration under memory and accuracy constraints. In ImageNet, CompressNAS compresses ResNet-18 by 8x with less than 4% accuracy drop; on COCO, we achieve 2x compression of YOLOv5s without any accuracy drop and 2x compression of YOLOv5n with a 2.5% drop. Finally, we present a new family of compressed models, STResNet, with competitive performance compared to other efficient models.

</details>


### [13] [SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression](https://arxiv.org/abs/2511.13264)
*Keshav Gupta,Akshat Sanghvi,Shreyas Reddy Palley,Astitva Srivastava,Charu Sharma,Avinash Sharma*

Main category: cs.CV

TL;DR: 提出了一种名为SymGS的新型压缩框架，通过引入可学习的镜像平面来消除3D高斯点阵中的反射冗余，显著提升了压缩率，同时保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯点阵压缩方法受限于对称性冗余未被充分挖掘，难以进一步压缩，本文旨在通过利用场景中的镜面对称性突破这一瓶颈。

Method: 提出SymGS框架，将可学习的镜像平面嵌入场景中，检测并消除局部与全局的反射对称冗余，并与现有压缩方法（如HAC）结合实现协同增效。

Result: 相比HAC，平均实现1.66倍压缩，在大规模场景中最高达3倍；整体平均压缩率达108倍，且保持高质量渲染效果。

Conclusion: SymGS通过引入对称性感知的压缩机制，显著优于现有方法，可作为即插即用模块提升主流压缩技术的性能。

Abstract: 3D Gaussian Splatting has emerged as a transformative technique in novel view synthesis, primarily due to its high rendering speed and photorealistic fidelity. However, its memory footprint scales rapidly with scene complexity, often reaching several gigabytes. Existing methods address this issue by introducing compression strategies that exploit primitive-level redundancy through similarity detection and quantization. We aim to surpass the compression limits of such methods by incorporating symmetry-aware techniques, specifically targeting mirror symmetries to eliminate redundant primitives. We propose a novel compression framework, \textbf{\textit{SymGS}}, introducing learnable mirrors into the scene, thereby eliminating local and global reflective redundancies for compression. Our framework functions as a plug-and-play enhancement to state-of-the-art compression methods, (e.g. HAC) to achieve further compression. Compared to HAC, we achieve $1.66 \times$ compression across benchmark datasets (upto $3\times$ on large-scale scenes). On an average, SymGS enables $\bf{108\times}$ compression of a 3DGS scene, while preserving rendering quality. The project page and supplementary can be found at \textbf{\color{cyan}{symgs.github.io}}

</details>


### [14] [AdaptFly: Prompt-Guided Adaptation of Foundation Models for Low-Altitude UAV Networks](https://arxiv.org/abs/2511.11720)
*Jiao Chen,Haoyi Wang,Jianhua Tang,Junyi Wang*

Main category: cs.CV

TL;DR: 本文提出AdaptFly，一种无需权重更新的提示引导测试时自适应框架，用于提升低空无人机网络中的语义分割鲁棒性。该框架支持轻量级token提示检索和无梯度视觉提示优化，结合跨无人机知识共享，显著提升复杂环境下的分割精度与协作效率。


<details>
  <summary>Details</summary>
Motivation: 现有分割基础模型在天气、光照和视角变化下性能迅速下降，且传统测试时自适应方法对资源受限的无人机不适用，资源充足的无人机独立适应又浪费共享经验。

Method: 提出AdaptFly框架，包含两种互补的自适应模式：资源受限无人机采用从共享全局内存中检索轻量级token提示；资源充足的无人机通过协方差矩阵自适应进化策略进行无梯度稀疏视觉提示优化。使用激活统计检测器触发自适应，并通过跨无人机知识池整合提示知识，实现低带宽开销的全机队协作。

Result: 在UAVid和VDD基准及真实无人机部署中，AdaptFly在多种天气条件下显著优于静态模型和先进的测试时自适应基线，提升了分割准确性和鲁棒性。

Conclusion: AdaptFly为低空经济中资源异构的无人机网络提供了高效、通信友好的感知解决方案，实现了弹性且协作的语义分割。

Abstract: Low-altitude Unmanned Aerial Vehicle (UAV) networks rely on robust semantic segmentation as a foundational enabler for distributed sensing-communication-control co-design across heterogeneous agents within the network. However, segmentation foundation models deteriorate quickly under weather, lighting, and viewpoint drift. Resource-limited UAVs cannot run gradient-based test-time adaptation, while resource-massive UAVs adapt independently, wasting shared experience. To address these challenges, we propose AdaptFly, a prompt-guided test-time adaptation framework that adjusts segmentation models without weight updates. AdaptFly features two complementary adaptation modes. For resource-limited UAVs, it employs lightweight token-prompt retrieval from a shared global memory. For resource-massive UAVs, it uses gradient-free sparse visual prompt optimization via Covariance Matrix Adaptation Evolution Strategy. An activation-statistic detector triggers adaptation, while cross-UAV knowledge pool consolidates prompt knowledge and enables fleet-wide collaboration with negligible bandwidth overhead. Extensive experiments on UAVid and VDD benchmarks, along with real-world UAV deployments under diverse weather conditions, demonstrate that AdaptFly significantly improves segmentation accuracy and robustness over static models and state-of-the-art TTA baselines. The results highlight a practical path to resilient, communication-efficient perception in the emerging low-altitude economy.

</details>


### [15] [Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video](https://arxiv.org/abs/2511.11725)
*Zekai Shi,Zhixi Cai,Kalin Stefanov*

Main category: cs.CV

TL;DR: 提出一种受人类视觉盲区启发的自监督、生物可解释的掩码策略，用于学习视觉表征，并在视频-文本对比模型中有效实现词语与视觉指代的映射。


<details>
  <summary>Details</summary>
Motivation: 儿童在无先验知识的情况下通过多情境线索学习词汇指代，现有随机掩码方法缺乏生物学合理性，需探索更贴近人类认知机制的自监督学习方法。

Method: 基于掩码自编码器（MAE）设计新的掩码策略，模拟人眼盲区位置进行掩码；利用纵向、以自我为中心的真实儿童视角数据，结合对比学习框架构建视频-文本模型以学习词-指代映射。

Result: 所提生物可解释掩码策略在学习词语-视觉指代任务上的效果至少与随机掩码相当，且更具生物学合理性。

Conclusion: 模拟人类感知特性的掩码策略可用于高效学习视觉表征，为语言习得的计算建模提供了更符合生物机制的新路径。

Abstract: Typically, children start to learn their first words between 6 and 9 months, linking spoken utterances to their visual referents. Without prior knowledge, a word encountered for the first time can be interpreted in countless ways; it might refer to any of the objects in the environment, their components, or attributes. Using longitudinal, egocentric, and ecologically valid data from the experience of one child, in this work, we propose a self-supervised and biologically plausible strategy to learn strong visual representations. Our masked autoencoder-based visual backbone incorporates knowledge about the blind spot in human eyes to define a novel masking strategy. This mask and reconstruct approach attempts to mimic the way the human brain fills the gaps in the eyes' field of view. This represents a significant shift from standard random masking strategies, which are difficult to justify from a biological perspective. The pretrained encoder is utilized in a contrastive learning-based video-text model capable of acquiring word-referent mappings. Extensive evaluation suggests that the proposed biologically plausible masking strategy is at least as effective as random masking for learning word-referent mappings from cross-situational and temporally extended episodes.

</details>


### [16] [GROVER: Graph-guided Representation of Omics and Vision with Expert Regulation for Adaptive Spatial Multi-omics Fusion](https://arxiv.org/abs/2511.11730)
*Yongjun Xiao,Dian Meng,Xinlei Huang,Yanran Liu,Shiwei Ruan,Ziyue Qiao,Xubin Zheng*

Main category: cs.CV

TL;DR: 提出GROVER框架，用于自适应融合空间多组学与病理图像数据，通过图卷积网络、对比学习和动态专家路由机制提升跨模态对齐与表征质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效整合空间转录组、蛋白组、表观基因组与组织病理图像，存在模态异质性、分辨率不匹配和样本制备扰动等问题，导致融合表征模糊或失真。

Method: GROVER采用基于Kolmogorov-Arnold网络的图卷积编码器建模各模态与其空间结构的非线性关系；引入斑点-特征对的对比学习策略优化跨模态对应关系；设计动态专家路由机制自适应选择高质量模态信息并抑制噪声。

Result: 在真实空间多组学数据集上，GROVER优于当前最先进的基线方法，在跨模态对齐和下游分析任务中表现出更强的鲁棒性和准确性。

Conclusion: GROVER为多模态空间组学数据的自适应融合提供了可靠解决方案，显著提升了组织复杂性与疾病机制研究中的跨模态表征能力。

Abstract: Effectively modeling multimodal spatial omics data is critical for understanding tissue complexity and underlying biological mechanisms. While spatial transcriptomics, proteomics, and epigenomics capture molecular features, they lack pathological morphological context. Integrating these omics with histopathological images is therefore essential for comprehensive disease tissue analysis. However, substantial heterogeneity across omics, imaging, and spatial modalities poses significant challenges. Naive fusion of semantically distinct sources often leads to ambiguous representations. Additionally, the resolution mismatch between high-resolution histology images and lower-resolution sequencing spots complicates spatial alignment. Biological perturbations during sample preparation further distort modality-specific signals, hindering accurate integration. To address these challenges, we propose Graph-guided Representation of Omics and Vision with Expert Regulation for Adaptive Spatial Multi-omics Fusion (GROVER), a novel framework for adaptive integration of spatial multi-omics data. GROVER leverages a Graph Convolutional Network encoder based on Kolmogorov-Arnold Networks to capture the nonlinear dependencies between each modality and its associated spatial structure, thereby producing expressive, modality-specific embeddings. To align these representations, we introduce a spot-feature-pair contrastive learning strategy that explicitly optimizes the correspondence across modalities at each spot. Furthermore, we design a dynamic expert routing mechanism that adaptively selects informative modalities for each spot while suppressing noisy or low-quality inputs. Experiments on real-world spatial omics datasets demonstrate that GROVER outperforms state-of-the-art baselines, providing a robust and reliable solution for multimodal integration.

</details>


### [17] [Exposing DeepFakes via Hyperspectral Domain Mapping](https://arxiv.org/abs/2511.11732)
*Aditya Mehta,Swarnim Chaudhary,Pratik Narang,Jagat Sesh Challa*

Main category: cs.CV

TL;DR: 提出HSI-Detect，一种通过将RGB图像转换为31通道高光谱图像进行Deepfake检测的两阶段方法，能更有效揭示在RGB中不明显的伪造痕迹。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法仅在RGB空间操作，受限于三通道信息，难以捕捉细微的伪造痕迹。

Method: 构建一个两阶段框架：首先从RGB图像重建31通道的高光谱图像，然后在高光谱域进行Deepfake检测。

Result: 在FaceForensics++数据集上验证，HSI-Detect consistently 优于仅使用RGB的方法，表明扩展光谱信息有助于暴露伪造伪影。

Conclusion: 利用高光谱信息可提升Deepfake检测性能，光谱域映射是增强检测鲁棒性的有前景方向。

Abstract: Modern generative and diffusion models produce highly realistic images that can mislead human perception and even sophisticated automated detection systems. Most detection methods operate in RGB space and thus analyze only three spectral channels. We propose HSI-Detect, a two-stage pipeline that reconstructs a 31-channel hyperspectral image from a standard RGB input and performs detection in the hyperspectral domain. Expanding the input representation into denser spectral bands amplifies manipulation artifacts that are often weak or invisible in the RGB domain, particularly in specific frequency bands. We evaluate HSI-Detect across FaceForensics++ dataset and show the consistent improvements over RGB-only baselines, illustrating the promise of spectral-domain mapping for Deepfake detection.

</details>


### [18] [Toward bilipshiz geometric models](https://arxiv.org/abs/2511.11735)
*Yonatan Sverdlov,Eitan Rosen,Nadav Dym*

Main category: cs.CV

TL;DR: 本文研究了点云神经网络在保持对称性感知距离方面的表现，指出常见的不变网络不满足Procrustes Matching（PM）度量下的双Lipschitz等价性，并提出改进方法以获得双Lipschitz保证，实验表明所提模型在3D点云匹配任务中优于标准不变模型。


<details>
  <summary>Details</summary>
Motivation: 受等变学习中双Lipschitz模型优势的启发，探究点云不变网络是否保持对称性感知距离的双Lipschitz性质。

Method: 分析两种对称性感知度量（Procrustes Matching和Hard Gromov Wasserstein距离）之间的关系，证明其非双Lipschitz等价，并修改现有网络以实现双Lipschitz特性。

Result: 发现常用点云不变网络不满足PM度量下的双Lipschitz性质；提出了具有双Lipschitz保证的改进网络。

Conclusion: 通过引入双Lipschitz结构改进的点云网络在对应关系匹配任务中表现出更优性能，验证了保留几何结构的重要性。

Abstract: Many neural networks for point clouds are, by design, invariant to the symmetries of this datatype: permutations and rigid motions. The purpose of this paper is to examine whether such networks preserve natural symmetry aware distances on the point cloud spaces, through the notion of bi-Lipschitz equivalence. This inquiry is motivated by recent work in the Equivariant learning literature which highlights the advantages of bi-Lipschitz models in other scenarios.
  We consider two symmetry aware metrics on point clouds: (a) The Procrustes Matching (PM) metric and (b) Hard Gromov Wasserstien distances. We show that these two distances themselves are not bi-Lipschitz equivalent, and as a corollary deduce that popular invariant networks for point clouds are not bi-Lipschitz with respect to the PM metric. We then show how these networks can be modified so that they do obtain bi-Lipschitz guarantees. Finally, we provide initial experiments showing the advantage of the proposed bi-Lipschitz model over standard invariant models, for the tasks of finding correspondences between 3D point clouds.

</details>


### [19] [Concept-RuleNet: Grounded Multi-Agent Neurosymbolic Reasoning in Vision Language Models](https://arxiv.org/abs/2511.11751)
*Sanchit Sinha,Guangzhi Xiong,Zhenghao He,Aidong Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种多智能体神经符号系统Concept-RuleNet，通过从图像中挖掘视觉概念并利用大语言模型生成可执行的一阶规则，实现了视觉接地与透明推理的结合，在多个基准上优于现有方法，并显著减少幻觉符号的产生。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型虽然准确但缺乏可解释性，容易产生事实幻觉；当前的神经符号方法仅依赖任务标签提取符号，导致符号与视觉数据脱节，缺乏真实视觉基础。

Method: 提出Concept-RuleNet：首先使用多模态概念生成器从训练图像中挖掘判别性视觉概念；然后以这些概念指导符号发现，增强视觉接地；接着由大语言模型作为推理代理将符号组合成一阶逻辑规则；最后在推理阶段，视觉验证代理量化符号存在度并与黑箱模型输出协同触发规则执行。

Result: 在五个基准（包括两个医学影像任务和三个代表性不足的自然图像数据集）上的实验表明，该系统平均比最先进的神经符号基线提升5%，并将规则中幻觉符号的发生率降低高达50%。

Conclusion: Concept-RuleNet通过强化视觉接地和多代理协作，有效提升了神经符号系统的准确性、可解释性和鲁棒性，尤其在分布外数据和医疗等高风险领域具有应用潜力。

Abstract: Modern vision-language models (VLMs) deliver impressive predictive accuracy yet offer little insight into 'why' a decision is reached, frequently hallucinating facts, particularly when encountering out-of-distribution data. Neurosymbolic frameworks address this by pairing black-box perception with interpretable symbolic reasoning, but current methods extract their symbols solely from task labels, leaving them weakly grounded in the underlying visual data. In this paper, we introduce a multi-agent system - Concept-RuleNet that reinstates visual grounding while retaining transparent reasoning. Specifically, a multimodal concept generator first mines discriminative visual concepts directly from a representative subset of training images. Next, these visual concepts are utilized to condition symbol discovery, anchoring the generations in real image statistics and mitigating label bias. Subsequently, symbols are composed into executable first-order rules by a large language model reasoner agent - yielding interpretable neurosymbolic rules. Finally, during inference, a vision verifier agent quantifies the degree of presence of each symbol and triggers rule execution in tandem with outputs of black-box neural models, predictions with explicit reasoning pathways. Experiments on five benchmarks, including two challenging medical-imaging tasks and three underrepresented natural-image datasets, show that our system augments state-of-the-art neurosymbolic baselines by an average of 5% while also reducing the occurrence of hallucinated symbols in rules by up to 50%.

</details>


### [20] [Batch Transformer Architecture: Case of Synthetic Image Generation for Emotion Expression Facial Recognition](https://arxiv.org/abs/2511.11754)
*Stanislav Selitskiy*

Main category: cs.CV

TL;DR: 提出了一种隐式稀疏风格的新型Transformer变体架构——Batch Transformers，通过关注重要维度而非完整维度来减少编码器-解码器架构中的瓶颈规模。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在处理序列或批次数据时需对全部维度进行注意力计算，导致计算资源消耗大且存在信息冗余，因此需要一种更高效的注意力机制以降低模型复杂度并提升性能。

Method: 在Batch Transformers中引入隐式稀疏机制，仅对关键维度（主成分）进行注意力计算，实现特征选择，从而减小模型瓶颈层的规模。

Result: 在化妆和遮挡数据集的人脸识别任务中进行合成图像生成测试，结果表明该方法能有效增加有限原始数据集的多样性，并提升生成效果。

Conclusion: Batch Transformers通过聚焦重要特征维度实现了更高效的注意力机制，在减少计算负担的同时提升了数据增强能力，尤其适用于小样本高变异场景。

Abstract: A novel Transformer variation architecture is proposed in the implicit sparse style. Unlike "traditional" Transformers, instead of attention to sequential or batch entities in their entirety of whole dimensionality, in the proposed Batch Transformers, attention to the "important" dimensions (primary components) is implemented. In such a way, the "important" dimensions or feature selection allows for a significant reduction of the bottleneck size in the encoder-decoder ANN architectures. The proposed architecture is tested on the synthetic image generation for the face recognition task in the case of the makeup and occlusion data set, allowing for increased variability of the limited original data set.

</details>


### [21] [Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing](https://arxiv.org/abs/2511.11780)
*Hossein Mohebbi,Mohammed Abdulrahman,Yanting Miao,Pascal Poupart,Suraj Kothawade*

Main category: cs.CV

TL;DR: 本文提出了Image-POSER，一种基于反射性强化学习的框架，通过动态任务分解和视觉语言模型的结构化反馈，协调多个预训练图像生成专家模型，有效处理长且复杂的文本提示，在对齐性、保真度和美学方面优于现有模型，并在人类评估中更受青睐。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在处理长且复杂的创意提示时表现不稳定，难以满足实际创作需求，因此需要一个能够自动分解任务并协调多个专家模型的系统。

Method: 将图像生成与编辑建模为马尔可夫决策过程，采用反射性强化学习框架，动态调用预训练的文本到图像和图像到图像模型，并通过视觉语言模型作为批评者提供每步的结构化反馈，实现端到端的长提示处理。

Result: 实验表明，Image-POSER在行业标准和自定义基准上均优于基线模型（包括前沿模型），在对齐性、图像质量和美学评分方面表现更优，且在人类评估中被更频繁地选择。

Conclusion: 强化学习可赋予AI系统自主分解、重排和组合视觉模型的能力，推动实现通用型视觉助手的发展。

Abstract: Recent advances in text-to-image generation have produced strong single-shot models, yet no individual system reliably executes the long, compositional prompts typical of creative workflows. We introduce Image-POSER, a reflective reinforcement learning framework that (i) orchestrates a diverse registry of pretrained text-to-image and image-to-image experts, (ii) handles long-form prompts end-to-end through dynamic task decomposition, and (iii) supervises alignment at each step via structured feedback from a vision-language model critic. By casting image synthesis and editing as a Markov Decision Process, we learn non-trivial expert pipelines that adaptively combine strengths across models. Experiments show that Image-POSER outperforms baselines, including frontier models, across industry-standard and custom benchmarks in alignment, fidelity, and aesthetics, and is consistently preferred in human evaluations. These results highlight that reinforcement learning can endow AI systems with the capacity to autonomously decompose, reorder, and combine visual models, moving towards general-purpose visual assistants.

</details>


### [22] [SOTFormer: A Minimal Transformer for Unified Object Tracking and Trajectory Prediction](https://arxiv.org/abs/2511.11824)
*Zhongping Dong,Pengyang Yu,Shuangjian Li,Liming Chen,Mohand Tahar Kechadi*

Main category: cs.CV

TL;DR: SOTFormer是一种轻量级、恒定内存的时序Transformer模型，统一了单目标跟踪与短期轨迹预测，通过真值引导的记忆机制和burn-in锚点损失实现稳定的身份传播，在Mini-LaSOT上表现优于现有Transformer方法。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪方法在遮挡、尺度变化和时序漂移下难以保持时间一致性，且多数模型因递归或堆叠结构导致内存消耗高、难以实时推理。

Method: 提出SOTFormer，采用单一轻量级时序注意力层和真值初始化的记忆机制，结合burn-in锚点损失来稳定训练初期的身份匹配，实现端到端的检测、跟踪与短时预测。

Result: 在Mini-LaSOT（20%）上达到76.3 AUC和53.7 FPS，仅使用4.3 GB VRAM，显著优于TrackFormer和MOTRv2，尤其在快速运动、尺度变化和遮挡场景下。

Conclusion: SOTFormer通过简化时序建模结构，在保持低内存和高效率的同时实现了鲁棒的跟踪性能，适用于实时感知系统。

Abstract: Accurate single-object tracking and short-term motion forecasting remain challenging under occlusion, scale variation, and temporal drift, which disrupt the temporal coherence required for real-time perception. We introduce \textbf{SOTFormer}, a minimal constant-memory temporal transformer that unifies object detection, tracking, and short-horizon trajectory prediction within a single end-to-end framework. Unlike prior models with recurrent or stacked temporal encoders, SOTFormer achieves stable identity propagation through a ground-truth-primed memory and a burn-in anchor loss that explicitly stabilizes initialization. A single lightweight temporal-attention layer refines embeddings across frames, enabling real-time inference with fixed GPU memory. On the Mini-LaSOT (20%) benchmark, SOTFormer attains 76.3 AUC and 53.7 FPS (AMP, 4.3 GB VRAM), outperforming transformer baselines such as TrackFormer and MOTRv2 under fast motion, scale change, and occlusion.

</details>


### [23] [MP-GFormer: A 3D-Geometry-Aware Dynamic Graph Transformer Approach for Machining Process Planning](https://arxiv.org/abs/2511.11837)
*Fatemeh Elhambakhsh,Gaurav Ameta,Aditi Roy,Hyunwoong Ko*

Main category: cs.CV

TL;DR: 提出了一种3D几何感知的动态图变换器MP-GFormer，用于预测加工操作序列，通过融合立体光刻表面网格和边界表示法，在主操作和子操作预测上分别比现有方法提升24%和36%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有动态图学习方法在加工过程规划中缺乏对零件三维几何信息的感知，难以充分捕捉随加工操作变化的几何依赖关系。

Method: 提出MP-GFormer模型，结合立体光刻（STL）表面网格与边界表示（B-rep）方法，利用注意力机制将演变的3D几何特征融入动态图学习框架中，以预测加工操作序列。

Result: 在合成数据集上评估表明，MP-GFormer在主操作和子操作序列预测上的准确率分别比现有最先进方法提高了24%和36%。

Conclusion: MP-GFormer通过引入3D几何感知能力显著提升了加工操作序列预测的准确性，增强了模型在制造领域的语义理解与应用潜力。

Abstract: Machining process planning (MP) is inherently complex due to structural and geometrical dependencies among part features and machining operations. A key challenge lies in capturing dynamic interdependencies that evolve with distinct part geometries as operations are performed. Machine learning has been applied to address challenges in MP, such as operation selection and machining sequence prediction. Dynamic graph learning (DGL) has been widely used to model dynamic systems, thanks to its ability to integrate spatio-temporal relationships. However, in MP, while existing DGL approaches can capture these dependencies, they fail to incorporate three-dimensional (3D) geometric information of parts and thus lack domain awareness in predicting machining operation sequences. To address this limitation, we propose MP-GFormer, a 3D-geometry-aware dynamic graph transformer that integrates evolving 3D geometric representations into DGL through an attention mechanism to predict machining operation sequences. Our approach leverages StereoLithography surface meshes representing the 3D geometry of a part after each machining operation, with the boundary representation method used for the initial 3D designs. We evaluate MP-GFormer on a synthesized dataset and demonstrate that the method achieves improvements of 24\% and 36\% in accuracy for main and sub-operation predictions, respectively, compared to state-of-the-art approaches.

</details>


### [24] [Defending Unauthorized Model Merging via Dual-Stage Weight Protection](https://arxiv.org/abs/2511.11851)
*Wei-Jia Chen,Min-Yen Tsai,Cheng-Yi Lee,Chia-Mu Yu*

Main category: cs.CV

TL;DR: MergeGuard 是一种双阶段权重保护框架，通过重新分配任务相关信息和注入结构化扰动来破坏模型合并的兼容性，从而有效防止未经授权的模型合并，同时保持被保护模型的任务性能。


<details>
  <summary>Details</summary>
Motivation: 未经授权的模型合并侵犯了知识产权，损害了模型的所有权和可追溯性，因此需要一种能够主动防御模型被合并的方法。

Method: 第一阶段通过L2正则化优化在各层间重新分配任务相关的信息；第二阶段注入结构化扰动以破坏任务子空间的一致性，改变损失景观的曲率兼容性。

Result: 在视觉（ViT-L-14）和语言模型（Llama2, Gemma2, Mistral）上的实验表明，MergeGuard 可使合并模型的准确率下降高达90%，而被保护模型的性能损失不到1.5%。

Conclusion: MergeGuard 能有效防御未经授权的模型合并，保障模型所有权，同时对原始任务性能影响极小。

Abstract: The rapid proliferation of pretrained models and open repositories has made model merging a convenient yet risky practice, allowing free-riders to combine fine-tuned models into a new multi-capability model without authorization. Such unauthorized model merging not only violates intellectual property rights but also undermines model ownership and accountability. To address this issue, we present MergeGuard, a proactive dual-stage weight protection framework that disrupts merging compatibility while maintaining task fidelity. In the first stage, we redistribute task-relevant information across layers via L2-regularized optimization, ensuring that important gradients are evenly dispersed. In the second stage, we inject structured perturbations to misalign task subspaces, breaking curvature compatibility in the loss landscape. Together, these stages reshape the model's parameter geometry such that merged models collapse into destructive interference while the protected model remains fully functional. Extensive experiments on both vision (ViT-L-14) and language (Llama2, Gemma2, Mistral) models demonstrate that MergeGuard reduces merged model accuracy by up to 90% with less than 1.5% performance loss on the protected model.

</details>


### [25] [FocusSDF: Boundary-Aware Learning for Medical Image Segmentation via Signed Distance Supervision](https://arxiv.org/abs/2511.11864)
*Muzammal Shafique,Nasir Rahim,Jamil Ahmad,Mohammad Siadat,Khalid Malik,Ghaus Malik*

Main category: cs.CV

TL;DR: 本文提出了一种基于符号距离函数（SDF）的新型损失函数FocusSDF，用于提升医学图像分割中的边界保持能力。


<details>
  <summary>Details</summary>
Motivation: 大多数医学图像分割模型未显式编码边界信息，导致边界保留效果不佳，影响临床诊断与治疗的精确性。

Method: 提出FocusSDF损失函数，通过自适应地为靠近病灶或器官边界的像素分配更高权重，使网络更关注边界区域。该方法结合SDF实现边界感知训练。

Result: 在多个数据集（包括脑动脉瘤、中风、肝脏和乳腺肿瘤）和多种成像模态上，对五种最先进的分割模型（包括MedSAM）进行了广泛评估，结果表明FocusSDF在边界保持和整体分割性能上均优于现有的基于距离变换的损失函数。

Conclusion: FocusSDF能有效提升医学图像分割模型的边界感知能力，在多种任务和模型中表现出优越性能，具有广泛的适用性和应用潜力。

Abstract: Segmentation of medical images constitutes an essential component of medical image analysis, providing the foundation for precise diagnosis and efficient therapeutic interventions in clinical practices. Despite substantial progress, most segmentation models do not explicitly encode boundary information; as a result, making boundary preservation a persistent challenge in medical image segmentation. To address this challenge, we introduce FocusSDF, a novel loss function based on the signed distance functions (SDFs), which redirects the network to concentrate on boundary regions by adaptively assigning higher weights to pixels closer to the lesion or organ boundary, effectively making it boundary aware. To rigorously validate FocusSDF, we perform extensive evaluations against five state-of-the-art medical image segmentation models, including the foundation model MedSAM, using four distance-based loss functions across diverse datasets covering cerebral aneurysm, stroke, liver, and breast tumor segmentation tasks spanning multiple imaging modalities. The experimental results consistently demonstrate the superior performance of FocusSDF over existing distance transform based loss functions.

</details>


### [26] [Lacking Data? No worries! How synthetic images can alleviate image scarcity in wildlife surveys: a case study with muskox (Ovibos moschatus)](https://arxiv.org/abs/2511.11882)
*Simon Durand,Samuel Foucher,Alexandre Delplanque,Joëlle Taillon,Jérôme Théau*

Main category: cs.CV

TL;DR: 本研究探讨了利用合成影像（SI）补充有限训练数据以改善零样本和少样本条件下麝牛检测的效果，结果表明合成影像能有效提升深度学习模型在数据稀缺情况下的表现。


<details>
  <summary>Details</summary>
Motivation: 由于传统野生动物调查方法资源消耗大且受限于后勤挑战，而深度学习模型又因数据量小难以有效训练，因此需要探索新的数据增强方法来提高稀疏分布物种的检测精度。

Method: 比较基于真实影像的基线模型与逐步增加合成影像的零样本和少样本模型，评估其在精度、召回率和F1分数上的表现。

Result: 在零样本设置中，加入合成影像可提升检测性能，但超过基线数据集100%后性能趋于饱和；在少样本设置中，结合真实与合成影像略提高了召回率和整体准确性，但无统计显著性差异。

Conclusion: 合成影像有助于在数据稀缺时训练准确的物体检测模型，为监测稀有或难以接近的物种提供了可行方案，并可随实际数据积累逐步优化模型。

Abstract: Accurate population estimates are essential for wildlife management, providing critical insights into species abundance and distribution. Traditional survey methods, including visual aerial counts and GNSS telemetry tracking, are widely used to monitor muskox populations in Arctic regions. These approaches are resource intensive and constrained by logistical challenges. Advances in remote sensing, artificial intelligence, and high resolution aerial imagery offer promising alternatives for wildlife detection. Yet, the effectiveness of deep learning object detection models (ODMs) is often limited by small datasets, making it challenging to train robust ODMs for sparsely distributed species like muskoxen. This study investigates the integration of synthetic imagery (SI) to supplement limited training data and improve muskox detection in zero shot (ZS) and few-shot (FS) settings. We compared a baseline model trained on real imagery with 5 ZS and 5 FS models that incorporated progressively more SI in the training set. For the ZS models, where no real images were included in the training set, adding SI improved detection performance. As more SI were added, performance in precision, recall and F1 score increased, but eventually plateaued, suggesting diminishing returns when SI exceeded 100% of the baseline model training dataset. For FS models, combining real and SI led to better recall and slightly higher overall accuracy compared to using real images alone, though these improvements were not statistically significant. Our findings demonstrate the potential of SI to train accurate ODMs when data is scarce, offering important perspectives for wildlife monitoring by enabling rare or inaccessible species to be monitored and to increase monitoring frequency. This approach could be used to initiate ODMs without real data and refine it as real images are acquired over time.

</details>


### [27] [Advancing Annotat3D with Harpia: A CUDA-Accelerated Library For Large-Scale Volumetric Data Segmentation](https://arxiv.org/abs/2511.11890)
*Camila Machado de Araujo,Egon P. B. S. Borges,Ricardo Marcelo Canteiro Grangeiro,Allan Pinto*

Main category: cs.CV

TL;DR: 本文介绍了Harpia，一个基于CUDA的处理库，旨在通过Annotat3D实现对大规模3D数据集的可扩展、交互式分割工作流，显著提升了处理速度、内存效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率体成像技术产生的大数据集对现有处理、分割和交互探索工具提出了挑战，需要更高效的解决方案。

Method: 开发了一个名为Harpia的新CUDA-based处理库，集成到Annotat3D中，支持严格的内存控制、原生分块执行以及GPU加速的滤波、标注和量化工具。

Result: 实验结果表明，与NVIDIA cuCIM和scikit-image等常用框架相比，Harpia在处理速度、内存效率和可扩展性方面均有显著提升。

Conclusion: Harpia结合交互式人机协作界面和高效的GPU资源管理，适用于共享高性能计算环境中的协作式科学成像工作流。

Abstract: High-resolution volumetric imaging techniques, such as X-ray tomography and advanced microscopy, generate increasingly large datasets that challenge existing tools for efficient processing, segmentation, and interactive exploration. This work introduces new capabilities to Annotat3D through Harpia, a new CUDA-based processing library designed to support scalable, interactive segmentation workflows for large 3D datasets in high-performance computing (HPC) and remote-access environments. Harpia features strict memory control, native chunked execution, and a suite of GPU-accelerated filtering, annotation, and quantification tools, enabling reliable operation on datasets exceeding single-GPU memory capacity. Experimental results demonstrate significant improvements in processing speed, memory efficiency, and scalability compared to widely used frameworks such as NVIDIA cuCIM and scikit-image. The system's interactive, human-in-the-loop interface, combined with efficient GPU resource management, makes it particularly suitable for collaborative scientific imaging workflows in shared HPC infrastructures.

</details>


### [28] [Prompt Triage: Structured Optimization Enhances Vision-Language Model Performance on Medical Imaging Benchmarks](https://arxiv.org/abs/2511.11898)
*Arnav Singhvi,Vasiliki Bikia,Asad Aali,Akshay Chaudhari,Roxana Daneshjou*

Main category: cs.CV

TL;DR: 本文提出了一种基于DSPy框架的自动化提示优化方法，用于提升视觉-语言模型在医学影像任务中的表现。通过在五个医学成像任务中评估10个开源VLM和四种提示优化技术，结果显示中位相对性能提升达53%，部分任务提升高达300%至3400%。该方法减少了对人工提示设计的依赖，具有可扩展性并保护数据隐私，且无需微调模型权重。


<details>
  <summary>Details</summary>
Motivation: 现有的医学视觉-语言模型性能受限于低效的手动提示工程或需要大量数据与计算资源的微调方法。因此，亟需一种无需修改模型权重、可自动优化提示且适用于医疗场景的通用解决方案。

Method: 采用Declarative Self-improving Python (DSPy) 框架，构建面向医学视觉-语言系统的结构化自动提示优化流程，并在放射学、胃肠病学和皮肤病学的五个任务上实现和评估多种提示优化技术。

Result: 优化后的提示流程相比零样本基线平均提升了53%的相对性能，在零样本表现较差的任务上最大提升达300%至3400%。所有实验均在开源VLM上完成，具备良好的可扩展性和数据隐私保护能力。

Conclusion: 自动化提示优化是提升医学视觉语言模型性能的有效途径，能够在不依赖人工提示设计和模型微调的情况下显著提高临床图像解释准确性，有助于临床医生专注于患者护理和决策。

Abstract: Vision-language foundation models (VLMs) show promise for diverse imaging tasks but often underperform on medical benchmarks. Prior efforts to improve performance include model finetuning, which requires large domain-specific datasets and significant compute, or manual prompt engineering, which is hard to generalize and often inaccessible to medical institutions seeking to deploy these tools. These challenges motivate interest in approaches that draw on a model's embedded knowledge while abstracting away dependence on human-designed prompts to enable scalable, weight-agnostic performance improvements. To explore this, we adapt the Declarative Self-improving Python (DSPy) framework for structured automated prompt optimization in medical vision-language systems through a comprehensive, formal evaluation. We implement prompting pipelines for five medical imaging tasks across radiology, gastroenterology, and dermatology, evaluating 10 open-source VLMs with four prompt optimization techniques. Optimized pipelines achieved a median relative improvement of 53% over zero-shot prompting baselines, with the largest gains ranging from 300% to 3,400% on tasks where zero-shot performance is low. These results highlight the substantial potential of applying automated prompt optimization to medical AI systems, demonstrating significant gains for vision-based applications requiring accurate clinical image interpretation. By reducing dependence on prompt design to elicit intended outputs, these techniques allow clinicians to focus on patient care and clinical decision-making. Furthermore, our experiments offer scalability and preserve data privacy, demonstrating performance improvement on open-source VLMs. We publicly release our evaluation pipelines to support reproducible research on specialized medical tasks, available at https://github.com/DaneshjouLab/prompt-triage-lab.

</details>


### [29] [PI-NAIM: Path-Integrated Neural Adaptive Imputation Model](https://arxiv.org/abs/2511.11908)
*Afifa Khaled,Ebrahim Hamid Sumiea*

Main category: cs.CV

TL;DR: 提出PI-NAIM，一种双路径动态路由架构，根据缺失复杂度选择高效统计方法（MICE）或强大神经网络（GAIN），结合跨路径注意力融合与端到端优化，在MIMIC-III等数据上实现最优填补性能（RMSE 0.108）和下游任务提升（AUROC 0.812）。


<details>
  <summary>Details</summary>
Motivation: 医学影像和多模态临床数据常存在模态缺失问题，现有填补方法在表达能力或计算效率上不足，难以兼顾精度与实用性。

Method: 设计双路径架构：低缺失样本走高效MICE路径，复杂缺失走GAIN神经网络路径；通过缺失感知嵌入的跨路径注意力机制融合两路输出，并联合优化填补精度与下游任务性能。

Result: 在MIMIC-III和多模态基准上达到SOTA，RMSE为0.108（优于基线0.119–0.152），死亡率预测AUROC达0.812，且模块化设计便于集成到实际视觉系统中。

Conclusion: PI-NAIM通过动态路由与注意力融合，有效平衡了准确性与效率，为真实场景中的不完整多模态数据提供了统一、可扩展的填补解决方案。

Abstract: Medical imaging and multi-modal clinical settings often face the challange of missing modality in their diagnostic pipelines. Existing imputation methods either lack representational capacity or are computationally expensive. We propose PI-NAIM, a novel dual-path architecture that dynamically routes samples to optimized imputation approaches based on missingness complexity. Our framework integrates: (1) intelligent path routing that directs low missingness samples to efficient statistical imputation (MICE) and complex patterns to powerful neural networks (GAIN with temporal analysis); (2) cross-path attention fusion that leverages missingness-aware embeddings to intelligently combine both branches; and (3) end-to-end joint optimization of imputation accuracy and downstream task performance. Extensive experiments on MIMIC-III and multimodal benchmarks demonstrate state-of-the-art performance, achieving RMSE of 0.108 (vs. baselines' 0.119-0.152) and substantial gains in downstream tasks with an AUROC of 0.812 for mortality prediction. PI-NAIM's modular design enables seamless integration into vision pipelines handling incomplete sensor measurements, missing modalities, or corrupted inputs, providing a unified solution for real-world scenario. The code is publicly available at https://github.com/AfifaKhaled/PI-NAIM-Path-Integrated-Neural-Adaptive-Imputation-Model

</details>


### [30] [MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2511.12449)
*Zhanheng Nie,Chenghan Fu,Daoze Zhang,Junxian Wu,Wanxian Guan,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: 本文提出MOON2.0，一种用于电商产品理解的动态模态平衡多模态表征学习框架，通过模态驱动的MoE模块、双层次对齐方法和基于MLLM的图文协同增强策略，有效解决模态不平衡、对齐关系利用不足和噪声处理有限等问题，在多个数据集上实现了最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有面向电商的多模态大模型在训练中存在模态混合导致的模态不平衡、未能充分利用商品内部图文信息的对齐关系，以及对电商多模态噪声数据处理能力有限三大问题。

Method: 提出MOON2.0框架，包括：(1) 模态驱动的Mixture-of-Experts（MoE）模块，根据输入的模态组成自适应处理，实现多模态联合学习以缓解模态不平衡；(2) 双层次对齐方法，增强商品内部语义对齐；(3) 基于MLLM的图文协同增强策略，结合文本丰富化与视觉扩展，并引入动态样本过滤提升训练数据质量。同时构建了MBE2.0作为新的评测基准。

Result: 实验表明，MOON2.0在MBE2.0基准及多个公开数据集上均取得最先进的零样本性能表现，注意力热力图可视化结果也定性验证了其在多模态对齐上的改进效果。

Conclusion: MOON2.0通过动态模态平衡机制和多层次对齐与增强策略，显著提升了电商场景下多模态表征学习的效果，具备较强的鲁棒性和泛化能力，为电商产品理解提供了有效的解决方案。

Abstract: The rapid growth of e-commerce calls for multimodal models that comprehend rich visual and textual product information. Although recent multimodal large language models (MLLMs) for product understanding exhibit strong capability in representation learning for e-commerce, they still face three challenges: (i) the modality imbalance induced by modality mixed training; (ii) underutilization of the intrinsic alignment relationships among visual and textual information within a product; and (iii) limited handling of noise in e-commerce multimodal data. To address these, we propose MOON2.0, a dynamic modality-balanced multimodal representation learning framework for e-commerce product understanding. MOON2.0 comprises: (1) a Modality-driven Mixture-of-Experts (MoE) module that adaptively processes input samples by their modality composition, enabling Multimodal Joint Learning to mitigate the modality imbalance; (2) a Dual-level Alignment method to better leverage semantic alignment properties inside individual products; and (3) an MLLM-based Image-text Co-augmentation strategy that integrates textual enrichment with visual expansion, coupled with Dynamic Sample Filtering to improve training data quality. We further introduce MBE2.0, a co-augmented multimodal representation benchmark for e-commerce representation learning and evaluation. Experiments show that MOON2.0 delivers state-of-the-art zero-shot performance on MBE2.0 and multiple public datasets. Furthermore, attention-based heatmap visualization provides qualitative evidence of improved multimodal alignment of MOON2.0.

</details>


### [31] [Seeing the Forest and the Trees: Query-Aware Tokenizer for Long-Video Multimodal Language Models](https://arxiv.org/abs/2511.11910)
*Siyou Li,Huanan Wu,Juexi Shao,Yinghao Ma,Yujian Gan,Yihao Luo,Yuwei Wang,Dong Nie,Lu Wang,Wengqing Wu,Le Zhang,Massimo Poesio,Juntao Yu*

Main category: cs.CV

TL;DR: 本文提出了一种轻量且高效的视觉token选择模块QTSplus，用于解决多模态大模型在长视频理解中因视觉token增长导致的计算开销问题。


<details>
  <summary>Details</summary>
Motivation: 长视频理解面临视觉token数量随视频长度线性增长的问题，导致注意力成本、内存和延迟急剧上升，限制了多模态大语言模型的应用。

Method: QTSplus通过跨注意力评分、预测实例特定的保留预算以及使用可微直通估计器选择Top-n token，在训练时软选择、推理时硬门控，并引入小型重编码器保留时间顺序信息。

Result: 在Qwen2.5-VL中集成后，QTSplus最多压缩89%的视觉流，端到端延迟降低28%，在八个长视频基准测试上保持接近原始模型的准确率，并在TempCompass的方向和顺序准确性上分别提升+20.5和+5.6点。

Conclusion: QTSplus是一种有效且通用的机制，能够在保留任务相关证据的同时，扩展多模态大模型至实际长视频场景。

Abstract: Despite the recent advances in the video understanding ability of multimodal large language models (MLLMs), long video understanding remains a challenge. One of the main issues is that the number of vision tokens grows linearly with video length, which causes an explosion in attention cost, memory, and latency. To solve this challenge, we present Query-aware Token Selector (\textbf{QTSplus}), a lightweight yet powerful visual token selection module that serves as an information gate between the vision encoder and LLMs. Given a text query and video tokens, QTSplus dynamically selects the most important visual evidence for the input text query by (i) scoring visual tokens via cross-attention, (ii) \emph{predicting} an instance-specific retention budget based on the complexity of the query, and (iii) \emph{selecting} Top-$n$ tokens with a differentiable straight-through estimator during training and a hard gate at inference. Furthermore, a small re-encoder preserves temporal order using absolute time information, enabling second-level localization while maintaining global coverage.
  Integrated into Qwen2.5-VL, QTSplus compresses the vision stream by up to \textbf{89\%} and reduces end-to-end latency by \textbf{28\%} on long videos. The evaluation on eight long video understanding benchmarks shows near-parity accuracy overall when compared with the original Qwen models and outperforms the original model by \textbf{+20.5} and \textbf{+5.6} points respectively on TempCompass direction and order accuracies. These results show that QTSplus is an effective, general mechanism for scaling MLLMs to real-world long-video scenarios while preserving task-relevant evidence.
  We will make all code, data, and trained models' weights publicly available.

</details>


### [32] [From Events to Clarity: The Event-Guided Diffusion Framework for Dehazing](https://arxiv.org/abs/2511.11944)
*Ling Wang,Yunfan Lu,Wenzong Ma,Huizai Yao,Pengteng Li,Hui Xiong*

Main category: cs.CV

TL;DR: 首次将事件相机用于去雾任务，提出一种事件引导的扩散模型，通过从高动态范围的事件数据中迁移信息来重建清晰图像，在多个基准和自建重雾无人机数据集上实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统RGB图像在雾霾条件下动态范围有限，导致去雾任务不适定，易丢失结构和光照细节。事件相机具有更高动态范围和微秒级延迟，适合复杂雾况，但缺乏配对数据限制了其应用。

Method: 提出事件引导的扩散模型，设计事件引导模块将稀疏的高动态范围事件特征（如边缘、角点）映射到扩散模型的潜在空间，作为生成过程中的结构化条件，实现从雾霾图像到清晰图像的高质量重建。

Result: 在两个公开基准和自采集的重雾（AQI=341）无人机数据集上实验表明，该方法优于现有方法，达到最先进的去雾效果。

Conclusion: 事件相机为去雾提供了新思路，结合扩散模型的强大生成先验，所提方法能有效利用事件数据的HDR特性，显著提升去雾图像的质量与真实感。

Abstract: Clear imaging under hazy conditions is a critical task. Prior-based and neural methods have improved results. However, they operate on RGB frames, which suffer from limited dynamic range. Therefore, dehazing remains ill-posed and can erase structure and illumination details. To address this, we use event cameras for dehazing for the \textbf{first time}. Event cameras offer much higher HDR ($120 dBvs.60 dB$) and microsecond latency, therefore they suit hazy scenes. In practice, transferring HDR cues from events to frames is hard because real paired data are scarce. To tackle this, we propose an event-guided diffusion model that utilizes the strong generative priors of diffusion models to reconstruct clear images from hazy inputs by effectively transferring HDR information from events. Specifically, we design an event-guided module that maps sparse HDR event features, \textit{e.g.,} edges, corners, into the diffusion latent space. This clear conditioning provides precise structural guidance during generation, improves visual realism, and reduces semantic drift. For real-world evaluation, we collect a drone dataset in heavy haze (AQI = 341) with synchronized RGB and event sensors. Experiments on two benchmarks and our dataset achieve state-of-the-art results.

</details>


### [33] [Evaluation of Attention Mechanisms in U-Net Architectures for Semantic Segmentation of Brazilian Rock Art Petroglyphs](https://arxiv.org/abs/2511.11959)
*Leonardi Melo,Luís Gustavo,Dimmy Magalhães,Lucciani Vieira,Mauro Araújo*

Main category: cs.CV

TL;DR: 本研究比较了三种基于U-Net的架构在巴西考古遗址岩刻图像语义分割中的性能，其中引入注意力机制和残差结构的Attention-Residual BEGL-UNet表现最佳，Dice Score达到0.710，较基线模型提升显著，表明注意力机制对考古遗产数字化保护具有有效性。


<details>
  <summary>Details</summary>
Motivation: 提高岩刻图像语义分割精度，以支持考古遗产的数字化保护。

Method: 采用三种U-Net变体架构：BEGL-UNet、Attention-Residual BEGL-UNet和Spatial Channel Attention BEGL-UNet，均使用结合二值交叉熵与高斯边缘增强的BEGL损失函数，并在巴西Poço da Bebidinha遗址图像上进行5折交叉验证实验。

Result: Attention-Residual BEGL-UNet取得最优性能（Dice Score 0.710，验证损失0.067，召回率0.854）；Spatial Channel Attention BEGL-UNet性能相近（Dice Score 0.707，召回率0.857）；基线BEGL-UNet为0.690。注意力机制带来2.5-2.9%的Dice Score提升。

Conclusion: 注意力机制显著提升岩刻图像分割效果，有助于考古遗产的精准数字化保存。

Abstract: This study presents a comparative analysis of three U-Net-based architectures for semantic segmentation of rock art petroglyphs from Brazilian archaeological sites. The investigated architectures were: (1) BEGL-UNet with Border-Enhanced Gaussian Loss function; (2) Attention-Residual BEGL-UNet, incorporating residual blocks and gated attention mechanisms; and (3) Spatial Channel Attention BEGL-UNet, which employs spatial-channel attention modules based on Convolutional Block Attention Module. All implementations employed the BEGL loss function combining binary cross-entropy with Gaussian edge enhancement. Experiments were conducted on images from the Poço da Bebidinha Archaeological Complex, Piauí, Brazil, using 5-fold cross-validation. Among the architectures, Attention-Residual BEGL-UNet achieved the best overall performance with Dice Score of 0.710, validation loss of 0.067, and highest recall of 0.854. Spatial Channel Attention BEGL-UNet obtained comparable performance with DSC of 0.707 and recall of 0.857. The baseline BEGL-UNet registered DSC of 0.690. These results demonstrate the effectiveness of attention mechanisms for archaeological heritage digital preservation, with Dice Score improvements of 2.5-2.9% over the baseline.

</details>


### [34] [FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation](https://arxiv.org/abs/2511.13063)
*Zhenghua Li,Hang Chen,Zihao Sun,Kai Li,Xiaolin Hu*

Main category: cs.CV

TL;DR: 提出一种新框架，通过将自然图像上预训练的Segment Anything Model 2 (SAM2) 的知识迁移到电子显微镜（EM）图像神经结构分割任务中，结合特征引导注意力模块和双亲和性解码器，在少标注情况下显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 电子显微镜图像中神经结构分割面临形态复杂、信噪比低和标注数据稀缺等挑战，现有方法在准确性和泛化能力上受限，因此需要引入更强的先验知识来提升性能。

Method: 利用SAM2在自然图像上预训练的特征，设计特征引导注意力模块（Feature-Guided Attention），通过SAM2的语义线索指导轻量级细粒度编码器（FGE）关注困难区域，并采用双亲和性解码器生成粗略和精细的亲和图以实现精确分割。

Result: 在SAM2权重冻结的情况下，性能已达到与当前最先进方法相当的水平；进一步在EM数据上微调后，显著超越现有SOTA方法。

Conclusion: 研究表明，将自然图像上预训练的视觉基础模型表征迁移至EM神经分割任务中，结合针对性的领域自适应机制，能有效应对该任务中的关键挑战。

Abstract: Accurate segmentation of neural structures in Electron Microscopy (EM) images is paramount for neuroscience. However, this task is challenged by intricate morphologies, low signal-to-noise ratios, and scarce annotations, limiting the accuracy and generalization of existing methods. To address these challenges, we seek to leverage the priors learned by visual foundation models on a vast amount of natural images to better tackle this task. Specifically, we propose a novel framework that can effectively transfer knowledge from Segment Anything 2 (SAM2), which is pre-trained on natural images, to the EM domain. We first use SAM2 to extract powerful, general-purpose features. To bridge the domain gap, we introduce a Feature-Guided Attention module that leverages semantic cues from SAM2 to guide a lightweight encoder, the Fine-Grained Encoder (FGE), in focusing on these challenging regions. Finally, a dual-affinity decoder generates both coarse and refined affinity maps. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art (SOTA) approaches with the SAM2 weights frozen. Upon further fine-tuning on EM data, our method significantly outperforms existing SOTA methods. This study validates that transferring representations pre-trained on natural images, when combined with targeted domain-adaptive guidance, can effectively address the specific challenges in neuron segmentation.

</details>


### [35] [From Classification to Cross-Modal Understanding: Leveraging Vision-Language Models for Fine-Grained Renal Pathology](https://arxiv.org/abs/2511.11984)
*Zhenhao Guo,Rachit Saluja,Tianyuan Yao,Quan Liu,Junchao Zhu,Haibo Wang,Daniel Reisenbüchler,Yuankai Huo,Benjamin Liechty,David J. Pisapia,Kenji Ikemura,Steven Salvatoree,Surya Seshane,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: 本研究将细粒度肾小球亚型分类建模为临床现实中的少样本问题，系统评估了病理学专用和通用视觉-语言模型在该设置下的表现，发现专用模型结合简单微调在极少量标注样本下即能有效区分亚型，且监督程度与适配策略共同影响诊断性能与多模态结构。


<details>
  <summary>Details</summary>
Motivation: 细粒度肾小球亚型分类对肾活检解读至关重要，但临床标注数据稀缺且获取困难，现有计算病理方法多依赖全监督和图像模型进行粗分类，尚不清楚如何在数据受限下有效适配视觉-语言模型以实现临床有意义的亚型识别。

Method: 将细粒度肾小球亚型分类视为少样本问题，系统评估多种视觉-语言模型（包括病理专用与通用模型）在不同样本量、模型架构、领域知识和适配策略下的分类性能（准确率、AUC、F1）及表征几何特性（图文对齐性、亚型可分性）。

Result: 病理专用视觉-语言模型结合标准微调在每类仅4-8个样本时即可显著提升分类判别能力与校准性能；更多标注仍带来持续增益；正负样本判别与图文对齐同样重要；监督水平与适配策略共同影响模型性能与多模态结构。

Conclusion: 在临床真实的数据约束下，采用病理专用视觉-语言模型并结合简单微调是最有效的起点，研究结果为模型选择、适配策略设计及标注资源投入提供了实践指导。

Abstract: Fine-grained glomerular subtyping is central to kidney biopsy interpretation, but clinically valuable labels are scarce and difficult to obtain. Existing computational pathology approaches instead tend to evaluate coarse diseased classification under full supervision with image-only models, so it remains unclear how vision-language models (VLMs) should be adapted for clinically meaningful subtyping under data constraints. In this work, we model fine-grained glomerular subtyping as a clinically realistic few-shot problem and systematically evaluate both pathology-specialized and general-purpose vision-language models under this setting. We assess not only classification performance (accuracy, AUC, F1) but also the geometry of the learned representations, examining feature alignment between image and text embeddings and the separability of glomerular subtypes. By jointly analyzing shot count, model architecture and domain knowledge, and adaptation strategy, this study provides guidance for future model selection and training under real clinical data constraints. Our results indicate that pathology-specialized vision-language backbones, when paired with the vanilla fine-tuning, are the most effective starting point. Even with only 4-8 labeled examples per glomeruli subtype, these models begin to capture distinctions and show substantial gains in discrimination and calibration, though additional supervision continues to yield incremental improvements. We also find that the discrimination between positive and negative examples is as important as image-text alignment. Overall, our results show that supervision level and adaptation strategy jointly shape both diagnostic performance and multimodal structure, providing guidance for model selection, adaptation strategies, and annotation investment.

</details>


### [36] [Region-Point Joint Representation for Effective Trajectory Similarity Learning](https://arxiv.org/abs/2511.13125)
*Hao Long,Silin Zhou,Lisi Chen,Shuo Shang*

Main category: cs.CV

TL;DR: 提出RePo方法，联合编码区域和点级特征以捕捉轨迹的上下文信息和细粒度移动模式，在轨迹相似性计算中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法未能充分利用轨迹信息的全谱进行相似性建模，导致性能受限。

Method: 将GPS轨迹映射为网格序列以提取区域级结构与语义特征，并通过三个轻量专家网络从密集GPS序列中提取点级局部、相关性和连续运动模式，再由路由网络自适应融合，并结合交叉注意力机制生成最终轨迹嵌入；采用对比损失训练，引入难负样本提升排序能力。

Result: 实验结果表明，RePo在所有评估指标上平均准确率比现有最先进方法提高22.2%。

Conclusion: RePo通过联合建模区域和点级特征，有效提升了轨迹相似性计算的准确性，具有较强的性能优势和应用潜力。

Abstract: Recent learning-based methods have reduced the computational complexity of traditional trajectory similarity computation, but state-of-the-art (SOTA) methods still fail to leverage the comprehensive spectrum of trajectory information for similarity modeling. To tackle this problem, we propose \textbf{RePo}, a novel method that jointly encodes \textbf{Re}gion-wise and \textbf{Po}int-wise features to capture both spatial context and fine-grained moving patterns. For region-wise representation, the GPS trajectories are first mapped to grid sequences, and spatial context are captured by structural features and semantic context enriched by visual features. For point-wise representation, three lightweight expert networks extract local, correlation, and continuous movement patterns from dense GPS sequences. Then, a router network adaptively fuses the learned point-wise features, which are subsequently combined with region-wise features using cross-attention to produce the final trajectory embedding. To train RePo, we adopt a contrastive loss with hard negative samples to provide similarity ranking supervision. Experiment results show that RePo achieves an average accuracy improvement of 22.2\% over SOTA baselines across all evaluation metrics.

</details>


### [37] [BeyondFacial: Identity-Preserving Personalized Generation Beyond Facial Close-ups](https://arxiv.org/abs/2511.11989)
*Songsong Zhang,Chuanqi Tang,Hongguang Zhang,Guijian Tang,Minglong Li,Xueqiong Li,Shaowu Yang,Yuanxi Peng,Wenjing Yang,Jing Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种新的身份保持个性化生成（IPPG）方法，通过双路径推理、自适应融合和身份聚合模块，在不依赖面部特写的情况下实现了身份保真与场景语义生成的协同优化，解决了传统方法中身份特征干扰语义表达的问题。


<details>
  <summary>Details</summary>
Motivation: 现有IPPG方法过度关注面部区域，导致输出多为面部特写，缺乏视觉叙事性和语义一致性，且身份特征嵌入削弱了生成模型的语义表达能力。

Method: 设计了双路径推理（DLI）架构实现身份与语义分离，提出身份自适应融合（IdAF）策略在噪声预测阶段进行自适应注意力融合与噪声决策掩码，并引入身份聚合前置（IdAP）模块以增强身份保持。

Result: 实验结果表明该方法在非面部特写的IPPG任务中表现出稳定有效的性能，无需手动掩码或微调即可高效生成，支持即插即用部署。

Conclusion: 所提方法打破了面部特写的限制，有效平衡了身份保真与语义生成，推动了影视级角色-场景协同创作的发展，为相关领域提供了更丰富的个性化生成能力。

Abstract: Identity-Preserving Personalized Generation (IPPG) has advanced film production and artistic creation, yet existing approaches overemphasize facial regions, resulting in outputs dominated by facial close-ups.These methods suffer from weak visual narrativity and poor semantic consistency under complex text prompts, with the core limitation rooted in identity (ID) feature embeddings undermining the semantic expressiveness of generative models. To address these issues, this paper presents an IPPG method that breaks the constraint of facial close-ups, achieving synergistic optimization of identity fidelity and scene semantic creation. Specifically, we design a Dual-Line Inference (DLI) pipeline with identity-semantic separation, resolving the representation conflict between ID and semantics inherent in traditional single-path architectures. Further, we propose an Identity Adaptive Fusion (IdAF) strategy that defers ID-semantic fusion to the noise prediction stage, integrating adaptive attention fusion and noise decision masking to avoid ID embedding interference on semantics without manual masking. Finally, an Identity Aggregation Prepending (IdAP) module is introduced to aggregate ID information and replace random initializations, further enhancing identity preservation. Experimental results validate that our method achieves stable and effective performance in IPPG tasks beyond facial close-ups, enabling efficient generation without manual masking or fine-tuning. As a plug-and-play component, it can be rapidly deployed in existing IPPG frameworks, addressing the over-reliance on facial close-ups, facilitating film-level character-scene creation, and providing richer personalized generation capabilities for related domains.

</details>


### [38] [Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework](https://arxiv.org/abs/2511.13189)
*Diego Ortego,Marlon Rodríguez,Mario Almagro,Kunal Dahiya,David Jiménez,Juan C. SanMiguel*

Main category: cs.CV

TL;DR: 本文提出了ViXML框架，通过结合大尺寸解码器和基础视觉模型，在极端多标签分类（XMC）中实现了性能提升，同时保持计算效率，并扩展了带视觉信息的数据集用于未来基准测试。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在多个领域取得突破，其在极端多标签分类（XMC）中的潜力尚未充分挖掘，尤其是在利用大模型和视觉信息方面存在空白。

Method: 提出ViXML框架，采用少量参数的十亿级解码器处理文本，并通过池化单个图像嵌入的方式高效集成视觉信息，将XMC建模为最大内积搜索问题。

Result: 在四个公开数据集及其视觉增强版本上实验表明，ViXML显著优于现有方法，在最大数据集上P@1指标最高提升8.21%，且小编码器版本通常优于纯文本解码器。

Conclusion: 结合大解码器与高效视觉融合策略可有效提升XMC性能，证明视觉信息能弥补模型参数规模的不足，为多模态XMC提供了高效可行的新方向。

Abstract: Foundation models have revolutionized artificial intelligence across numerous domains, yet their transformative potential remains largely untapped in Extreme Multi-label Classification (XMC). Queries in XMC are associated with relevant labels from extremely large label spaces, where it is critical to strike a balance between efficiency and performance. Therefore, many recent approaches efficiently pose XMC as a maximum inner product search between embeddings learned from small encoder-only transformer architectures. In this paper, we address two important aspects in XMC: how to effectively harness larger decoder-only models, and how to exploit visual information while maintaining computational efficiency. We demonstrate that both play a critical role in XMC separately and can be combined for improved performance. We show that a few billion-size decoder can deliver substantial improvements while keeping computational overhead manageable. Furthermore, our Vision-enhanced eXtreme Multi-label Learning framework (ViXML) efficiently integrates foundation vision models by pooling a single embedding per image. This limits computational growth while unlocking multi-modal capabilities. Remarkably, ViXML with small encoders outperforms text-only decoder in most cases, showing that an image is worth billions of parameters. Finally, we present an extension of existing text-only datasets to exploit visual metadata and make them available for future benchmarking. Comprehensive experiments across four public text-only datasets and their corresponding image enhanced versions validate our proposals' effectiveness, surpassing previous state-of-the-art by up to +8.21\% in P@1 on the largest dataset. ViXML's code is available at https://github.com/DiegoOrtego/vixml.

</details>


### [39] [Dynamic Parameter Optimization for Highly Transferable Transformation-Based Attacks](https://arxiv.org/abs/2511.11993)
*Jiaming Liang,Chi-Man Pun*

Main category: cs.CV

TL;DR: 提出了一种基于动态参数优化（DPO）的高效方法，通过揭示迁移性随参数强度变化的三种动态模式，并引入同心衰减模型（CDM）解释这些模式，显著提升了变换攻击在不同代理模型、迭代次数和任务下的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有变换攻击在参数优化中存在盲点，如仅关注低迭代设置、使用统一参数、依赖计算开销大的网格搜索，限制了攻击的迁移性和实际潜力。

Method: 通过实证研究揭示迁移性的动态模式，提出同心衰减模型（CDM）进行建模，并设计动态参数优化（DPO）方法，将复杂度从O(m^n)降低至O(n log m)，实现高效优化。

Result: 在多种变换攻击、代理模型、迭代次数和任务上实验表明，DPO能显著提升攻击的迁移性，优于现有方法。

Conclusion: DPO为变换攻击提供了更高效、自适应的参数优化方案，解决了传统方法的局限性，增强了高迭代和多场景下的攻击性能。

Abstract: Despite their wide application, the vulnerabilities of deep neural networks raise societal concerns. Among them, transformation-based attacks have demonstrated notable success in transfer attacks. However, existing attacks suffer from blind spots in parameter optimization, limiting their full potential. Specifically, (1) prior work generally considers low-iteration settings, yet attacks perform quite differently at higher iterations, so characterizing overall performance based only on low-iteration results is misleading. (2) Existing attacks use uniform parameters for different surrogate models, iterations, and tasks, which greatly impairs transferability. (3) Traditional transformation parameter optimization relies on grid search. For n parameters with m steps each, the complexity is O(mn). Large computational overhead limits further optimization of parameters. To address these limitations, we conduct an empirical study with various transformations as baselines, revealing three dynamic patterns of transferability with respect to parameter strength. We further propose a novel Concentric Decay Model (CDM) to effectively explain these patterns. Building on these insights, we propose an efficient Dynamic Parameter Optimization (DPO) based on the rise-then-fall pattern, reducing the complexity to O(nlogm). Comprehensive experiments on existing transformation-based attacks across different surrogate models, iterations, and tasks demonstrate that our DPO can significantly improve transferability.

</details>


### [40] [LithoSeg: A Coarse-to-Fine Framework for High-Precision Lithography Segmentation](https://arxiv.org/abs/2511.12005)
*Xinyu He,Botong Zhao,Bingbing Li,Shujing Lyu,Jiwei Shen,Yue Lu*

Main category: cs.CV

TL;DR: 本文提出了一种用于光刻扫描电镜图像分割的粗到精网络LithoSeg，通过结合人机协作的SAM引导策略和将2D分割转化为1D回归的方法，在减少监督需求的同时提升了分割精度和测量性能。


<details>
  <summary>Details</summary>
Motivation: 现有光刻SEM图像分割方法在精度和鲁棒性方面不足，难以适应多样化的图案几何形状和工艺窗口，限制了其在实际半导体制造中的应用。

Method: 提出LithoSeg：第一阶段采用‘人在回路’引导的SAM进行粗分割以实现低监督下的鲁棒性；第二阶段利用粗分割掩码提取沟槽法向轮廓，将2D分割问题转化为1D回归任务，并使用轻量级MLP进行逐点精细化。

Result: LithoSeg在分割准确性和测量精度上均优于先前方法，且所需标注监督更少，表现出良好的实际应用潜力。

Conclusion: LithoSeg通过粗到精的两阶段设计，有效提升了光刻图像分割的精度与鲁棒性，适用于复杂工艺条件下的半导体制造过程控制。

Abstract: Accurate segmentation and measurement of lithography scanning electron microscope (SEM) images are crucial for ensuring precise process control, optimizing device performance, and advancing semiconductor manufacturing yield. Lithography segmentation requires pixel-level delineation of groove contours and consistent performance across diverse pattern geometries and process window. However, existing methods often lack the necessary precision and robustness, limiting their practical applicability. To overcome this challenge, we propose LithoSeg, a coarse-to-fine network tailored for lithography segmentation. In the coarse stage, we introduce a Human-in-the-Loop Bootstrapping scheme for the Segment Anything Model (SAM) to attain robustness with minimal supervision. In the subsequent fine stage, we recast 2D segmentation as 1D regression problem by sampling groove-normal profiles using the coarse mask and performing point-wise refinement with a lightweight MLP. LithoSeg outperforms previous approaches in both segmentation accuracy and metrology precision while requiring less supervision, offering promising prospects for real-world applications.

</details>


### [41] [Uncertainty-Guided Selective Adaptation Enables Cross-Platform Predictive Fluorescence Microscopy](https://arxiv.org/abs/2511.12006)
*Kai-Wen K. Yang,Andrew Bai,Alexandra Bermudez,Yunqi Hong,Zoe Latham,Iris Sloan,Michael Liu,Vishrut Goyal,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.CV

TL;DR: 提出SIT-ADDA-Auto方法，仅通过适应最浅层卷积层并自动选择适应深度，实现跨设备和设置的鲁棒无监督域适应显微图像重建与分割。


<details>
  <summary>Details</summary>
Motivation: 深度学习在显微镜中应用广泛，但模型在新仪器或成像参数下表现不佳；传统对抗域适应方法需重训练整个网络，易破坏已学习的语义特征。

Method: 提出SIT-ADDA-Auto框架，冻结深层网络，仅对早期卷积层进行对抗域适应，并结合预测不确定性来自动生成最佳适应深度，无需目标域标签。

Result: 在曝光、照明变化、跨仪器转移和多种染色条件下，SIT-ADDA-Auto在图像重建和下游分割任务上优于全编码器适应和其他非对抗基线，且语义特征漂移更小。

Conclusion: 仅调整浅层卷积层即可实现有效域适应，提供了适用于显微成像的无标签自适应设计准则，并具备实际现场应用潜力。

Abstract: Deep learning is transforming microscopy, yet models often fail when applied to images from new instruments or acquisition settings. Conventional adversarial domain adaptation (ADDA) retrains entire networks, often disrupting learned semantic representations. Here, we overturn this paradigm by showing that adapting only the earliest convolutional layers, while freezing deeper layers, yields reliable transfer. Building on this principle, we introduce Subnetwork Image Translation ADDA with automatic depth selection (SIT-ADDA-Auto), a self-configuring framework that integrates shallow-layer adversarial alignment with predictive uncertainty to automatically select adaptation depth without target labels. We demonstrate robustness via multi-metric evaluation, blinded expert assessment, and uncertainty-depth ablations. Across exposure and illumination shifts, cross-instrument transfer, and multiple stains, SIT-ADDA improves reconstruction and downstream segmentation over full-encoder adaptation and non-adversarial baselines, with reduced drift of semantic features. Our results provide a design rule for label-free adaptation in microscopy and a recipe for field settings; the code is publicly available.

</details>


### [42] [Enhancing Road Safety Through Multi-Camera Image Segmentation with Post-Encroachment Time Analysis](https://arxiv.org/abs/2511.12018)
*Shounak Ray Chaudhuri,Arash Jahangiri,Christopher Paolini*

Main category: cs.CV

TL;DR: 提出了一种基于多摄像头计算机视觉的实时交通安全性评估框架，通过计算入侵后时间（PET）来识别信号交叉口的高风险区域。


<details>
  <summary>Details</summary>
Motivation: 传统基于事故数据的安全分析受限于数据稀疏性和延迟，难以实现实时风险监测。

Method: 使用四个同步摄像头和YOLOv11进行车辆检测，通过单应性矩阵将检测结果映射到统一鸟瞰图，并提出一种像素级PET算法，在边缘设备上实现细粒度、实时的安全评估。

Result: 系统在Chula Vista的一个交叉口实现了平均2.68 FPS的处理速度，生成800x800像素的对数热图，定位精度达3.3平方厘米，可准确识别高风险区域。

Conclusion: 验证了去中心化视觉PET分析在智能交通系统中的可行性，提供了一种高分辨率、实时且可扩展的交叉口安全评估方法。

Abstract: Traffic safety analysis at signalized intersections is vital for reducing vehicle and pedestrian collisions, yet traditional crash-based studies are limited by data sparsity and latency. This paper presents a novel multi-camera computer vision framework for real-time safety assessment through Post-Encroachment Time (PET) computation, demonstrated at the intersection of H Street and Broadway in Chula Vista, California. Four synchronized cameras provide continuous visual coverage, with each frame processed on NVIDIA Jetson AGX Xavier devices using YOLOv11 segmentation for vehicle detection. Detected vehicle polygons are transformed into a unified bird's-eye map using homography matrices, enabling alignment across overlapping camera views. A novel pixel-level PET algorithm measures vehicle position without reliance on fixed cells, allowing fine-grained hazard visualization via dynamic heatmaps, accurate to 3.3 sq-cm. Timestamped vehicle and PET data is stored in an SQL database for long-term monitoring. Results over various time intervals demonstrate the framework's ability to identify high-risk regions with sub-second precision and real-time throughput on edge devices, producing data for an 800 x 800 pixel logarithmic heatmap at an average of 2.68 FPS. This study validates the feasibility of decentralized vision-based PET analysis for intelligent transportation systems, offering a replicable methodology for high-resolution, real-time, and scalable intersection safety evaluation.

</details>


### [43] [LIHE: Linguistic Instance-Split Hyperbolic-Euclidean Framework for Generalized Weakly-Supervised Referring Expression Comprehension](https://arxiv.org/abs/2511.12020)
*Xianglong Shi,Silin Cheng,Sirui Zhao,Yunhan Jiang,Enhong Chen,Yang Liu,Sebastien Ourselin*

Main category: cs.CV

TL;DR: 本文提出了弱监督广义指代表达理解（WGREC）新任务，以解决传统WREC方法无法处理零或多个目标的问题，并提出LIHE框架，结合双阶段解耦与混合相似性模块HEMix，在超球面-欧几里得空间中有效缓解监督信号模糊和语义坍塌问题，在多个数据集上取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督指代表达理解方法受限于一对一映射假设，难以应对现实场景中指代数量可变的表达，需更灵活、实用的模型范式。

Method: 提出LIHE框架：第一阶段为指代解耦，预测目标数量并分解复杂表达为子表达；第二阶段为指代定位，采用HEMix混合相似性模块，结合欧氏空间的精确对齐能力与双曲几何的层次建模优势。

Result: 在gRefCOCO和Ref-ZOM上建立了首个有效的弱监督WGREC基线，HEMix在标准REC基准上显著提升性能，IoU@0.5最高提升2.5%。

Conclusion: LIHE通过双阶段设计与混合几何建模，成功扩展了弱监督REC至更通用的场景，有效解决了监督模糊与语义坍塌问题，推动了该领域的实际应用潜力。

Abstract: Existing Weakly-Supervised Referring Expression Comprehension (WREC) methods, while effective, are fundamentally limited by a one-to-one mapping assumption, hindering their ability to handle expressions corresponding to zero or multiple targets in realistic scenarios. To bridge this gap, we introduce the Weakly-Supervised Generalized Referring Expression Comprehension task (WGREC), a more practical paradigm that handles expressions with variable numbers of referents. However, extending WREC to WGREC presents two fundamental challenges: supervisory signal ambiguity, where weak image-level supervision is insufficient for training a model to infer the correct number and identity of referents, and semantic representation collapse, where standard Euclidean similarity forces hierarchically-related concepts into non-discriminative clusters, blurring categorical boundaries. To tackle these challenges, we propose a novel WGREC framework named Linguistic Instance-Split Hyperbolic-Euclidean (LIHE), which operates in two stages. The first stage, Referential Decoupling, predicts the number of target objects and decomposes the complex expression into simpler sub-expressions. The second stage, Referent Grounding, then localizes these sub-expressions using HEMix, our innovative hybrid similarity module that synergistically combines the precise alignment capabilities of Euclidean proximity with the hierarchical modeling strengths of hyperbolic geometry. This hybrid approach effectively prevents semantic collapse while preserving fine-grained distinctions between related concepts. Extensive experiments demonstrate LIHE establishes the first effective weakly supervised WGREC baseline on gRefCOCO and Ref-ZOM, while HEMix achieves consistent improvements on standard REC benchmarks, improving IoU@0.5 by up to 2.5\%. The code is available at https://anonymous.4open.science/r/LIHE.

</details>


### [44] [Null-Space Diffusion Distillation for Efficient Photorealistic Lensless Imaging](https://arxiv.org/abs/2511.12024)
*Jose Reinaldo Cunha Santos A V Silva Neto,Hodaka Kawachi,Yasushi Yagi,Tomoya Nakamura*

Main category: cs.CV

TL;DR: 提出了一种名为Null-Space Diffusion Distillation（NSDD）的新方法，用于无需配对监督的快速、逼真的无透镜成像，通过蒸馏迭代求解器的零空间分量，在保持测量一致性的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于配对监督的无透镜相机重建方法易受镜头-无镜头域不匹配偏差影响，而通用扩散先验在噪声大、高度复用且病态的反卷积问题中表现不佳，因此需要一种无需真实标签且稳定的重建方法。

Method: 提出NSDD方法，将值空间约束与零空间扩散先验更新分离，通过单次前向网络蒸馏迭代DDNM+求解器的零空间分量，并以无透镜测量和值空间锚点为条件，实现快速推理。

Result: 在Lensless-FFHQ和PhlatCam数据集上，NSDD是除Wiener外最快的算法，达到接近教师模型的感知质量（LPIPS排名第二，优于DPS和传统凸优化基线），同时显著降低运行时间和内存消耗。

Conclusion: NSDD为实现快速、无需真实标签且高质量的无透镜成像提供了一条实用路径，验证了零空间分解与蒸馏策略的有效性。

Abstract: State-of-the-art photorealistic reconstructions for lensless cameras often rely on paired lensless-lensed supervision, which can bias models due to lens-lensless domain mismatch. To avoid this, ground-truth-free diffusion priors are attractive; however, generic formulations tuned for conventional inverse problems often break under the noisy, highly multiplexed, and ill-posed lensless deconvolution setting. We observe that methods which separate range-space enforcement from null-space diffusion-prior updates yield stable, realistic reconstructions. Building on this, we introduce Null-Space Diffusion Distillation (NSDD): a single-pass student that distills the null-space component of an iterative DDNM+ solver, conditioned on the lensless measurement and on a range-space anchor. NSDD preserves measurement consistency and achieves photorealistic results without paired supervision at a fraction of the runtime and memory. On Lensless-FFHQ and PhlatCam, NSDD is the second fastest, behind Wiener, and achieves near-teacher perceptual quality (second-best LPIPS, below DDNM+), outperforming DPS and classical convex baselines. These results suggest a practical path toward fast, ground-truth-free, photorealistic lensless imaging.

</details>


### [45] [Bridging Vision and Language for Robust Context-Aware Surgical Point Tracking: The VL-SurgPT Dataset and Benchmark](https://arxiv.org/abs/2511.12026)
*Rulin Zhou,Wenlong He,An Wang,Jianhang Zhang,Xuanhui Zeng,Xi Zhang,Chaowei Zhu,Haijun Hu,Hongliang Ren*

Main category: cs.CV

TL;DR: 本文提出了VL-SurgPT，首个结合视觉跟踪与文本语义描述的大型多模态手术跟踪数据集，并提出文本引导的TG-SurgPT方法，显著提升了复杂视觉条件下（如烟雾、反光）的跟踪鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有手术跟踪数据集缺乏语义上下文，难以分析跟踪失败机制，且在复杂视觉条件下性能受限。

Method: 构建包含908个体内视频片段的多模态数据集VL-SurgPT，涵盖组织和器械的关键点标注，并引入文本描述；基于该数据集建立八种先进方法的基准，提出文本引导的TG-SurgPT跟踪方法。

Result: 实验表明，结合点状态文本信息可显著提升跟踪精度与可靠性，尤其在烟雾、反光等恶劣视觉条件下优于纯视觉方法。

Conclusion: VL-SurgPT通过融合视觉与语言模态，推动了具上下文感知能力的手术跟踪系统发展，有助于提升计算机辅助手术在复杂术中环境下的稳定性。

Abstract: Accurate point tracking in surgical environments remains challenging due to complex visual conditions, including smoke occlusion, specular reflections, and tissue deformation. While existing surgical tracking datasets provide coordinate information, they lack the semantic context necessary to understand tracking failure mechanisms. We introduce VL-SurgPT, the first large-scale multimodal dataset that bridges visual tracking with textual descriptions of point status in surgical scenes. The dataset comprises 908 in vivo video clips, including 754 for tissue tracking (17,171 annotated points across five challenging scenarios) and 154 for instrument tracking (covering seven instrument types with detailed keypoint annotations). We establish comprehensive benchmarks using eight state-of-the-art tracking methods and propose TG-SurgPT, a text-guided tracking approach that leverages semantic descriptions to improve robustness in visually challenging conditions. Experimental results demonstrate that incorporating point status information significantly improves tracking accuracy and reliability, particularly in adverse visual scenarios where conventional vision-only methods struggle. By bridging visual and linguistic modalities, VL-SurgPT enables the development of context-aware tracking systems crucial for advancing computer-assisted surgery applications that can maintain performance even under challenging intraoperative conditions.

</details>


### [46] [GCAgent: Long-Video Understanding via Schematic and Narrative Episodic Memory](https://arxiv.org/abs/2511.12027)
*Jeong Hun Yeo,Sangyun Chung,Sungjune Park,Dae Hoe Kim,Jinyoung Moon,Yong Man Ro*

Main category: cs.CV

TL;DR: 提出GCAgent框架，通过结构化的叙事与图式记忆解决长视频理解中的长期依赖问题，在Video-MME基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在长视频理解中受限于上下文长度和复杂时序关系建模，难以捕捉全局上下文和事件间因果联系。

Method: 设计基于感知-行动-反思循环的GCAgent，引入图式与叙事记忆（Schematic and Narrative Episodic Memory）以结构化方式存储事件及其时序、因果关系，并通过记忆管理器实现上下文感知推理。

Result: 在Video-MME Long split上比强基线提升最多23.5%，在7B级MLLM中达到73.4%准确率，整体平均71.9%，性能领先。

Conclusion: GCAgent通过结构化记忆和代理式推理范式，有效解决了长视频理解中的长期依赖问题，推动了认知启发的视频理解方法发展。

Abstract: Long-video understanding remains a significant challenge for Multimodal Large Language Models (MLLMs) due to inherent token limitations and the complexity of capturing long-term temporal dependencies. Existing methods often fail to capture the global context and complex event relationships necessary for deep video reasoning. To address this, we introduce GCAgent, a novel Global-Context-Aware Agent framework that achieves comprehensive long-video understanding. Our core innovation is the Schematic and Narrative Episodic Memory. This memory structurally models events and their causal and temporal relations into a concise, organized context, fundamentally resolving the long-term dependency problem. Operating in a multi-stage Perception-Action-Reflection cycle, our GCAgent utilizes a Memory Manager to retrieve relevant episodic context for robust, context-aware inference. Extensive experiments confirm that GCAgent significantly enhances long-video understanding, achieving up to 23.5\% accuracy improvement on the Video-MME Long split over a strong MLLM baseline. Furthermore, our framework establishes state-of-the-art performance among comparable 7B-scale MLLMs, achieving 73.4\% accuracy on the Long split and the highest overall average (71.9\%) on the Video-MME benchmark, validating our agent-based reasoning paradigm and structured memory for cognitively-inspired long-video understanding.

</details>


### [47] [VPHO: Joint Visual-Physical Cue Learning and Aggregation for Hand-Object Pose Estimation](https://arxiv.org/abs/2511.12030)
*Jun Zhou,Chi Xu,Kaifeng Tang,Yuting Ge,Tingrui Guo,Li Cheng*

Main category: cs.CV

TL;DR: 提出了一种结合视觉和物理线索的新型框架，用于从单张RGB图像中估计手部与物体的3D姿态，通过联合学习和候选姿态聚合，在姿态准确性和物理合理性方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，常导致违反物理约束的结果；而引入物理推理的方法多依赖后优化或非可微物理引擎，影响视觉一致性和端到端训练能力。

Method: 1) 联合视觉-物理线索学习：模型同时提取2D视觉线索和3D物理线索；2) 端到端可训练的候选姿态聚合：通过扩散模型生成多个候选姿态，并结合视觉与物理预测进行融合优化。

Result: 在多个实验中，该方法在姿态估计精度和物理合理性方面均显著优于当前最先进的方法。

Conclusion: 所提出的框架有效实现了视觉一致性与物理合理性的平衡，为手-物交互建模提供了新的解决方案。

Abstract: Estimating the 3D poses of hands and objects from a single RGB image is a fundamental yet challenging problem, with broad applications in augmented reality and human-computer interaction. Existing methods largely rely on visual cues alone, often producing results that violate physical constraints such as interpenetration or non-contact. Recent efforts to incorporate physics reasoning typically depend on post-optimization or non-differentiable physics engines, which compromise visual consistency and end-to-end trainability. To overcome these limitations, we propose a novel framework that jointly integrates visual and physical cues for hand-object pose estimation. This integration is achieved through two key ideas: 1) joint visual-physical cue learning: The model is trained to extract 2D visual cues and 3D physical cues, thereby enabling more comprehensive representation learning for hand-object interactions; 2) candidate pose aggregation: A novel refinement process that aggregates multiple diffusion-generated candidate poses by leveraging both visual and physical predictions, yielding a final estimate that is visually consistent and physically plausible. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art approaches in both pose accuracy and physical plausibility.

</details>


### [48] [Improved Masked Image Generation with Knowledge-Augmented Token Representations](https://arxiv.org/abs/2511.12032)
*Guotao Liang,Baoquan Zhang,Zhiyuan Wen,Zihao Han,Yunming Ye*

Main category: cs.CV

TL;DR: 提出了一种知识增强的掩码图像生成框架KA-MIG，通过引入显式的语义依赖先验知识（三种知识图）来提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码图像生成方法难以从无明确语义的长序列视觉token中学习语义依赖，限制了生成性能。

Method: 构建三种token级别的知识图（共现图、语义相似性图和位置-标记不兼容图），设计图感知编码器学习token与位置感知的表示，并通过轻量融合机制集成到现有MIG方法中。

Result: 在ImageNet类别条件图像生成任务上，KA-MIG显著优于现有MIG方法。

Conclusion: 引入显式语义依赖先验知识能有效增强模型对视觉token间语义关系的建模能力，提升掩码图像生成的质量和效率。

Abstract: Masked image generation (MIG) has demonstrated remarkable efficiency and high-fidelity images by enabling parallel token prediction. Existing methods typically rely solely on the model itself to learn semantic dependencies among visual token sequences. However, directly learning such semantic dependencies from data is challenging because the individual tokens lack clear semantic meanings, and these sequences are usually long. To address this limitation, we propose a novel Knowledge-Augmented Masked Image Generation framework, named KA-MIG, which introduces explicit knowledge of token-level semantic dependencies (\emph{i.e.}, extracted from the training data) as priors to learn richer representations for improving performance. In particular, we explore and identify three types of advantageous token knowledge graphs, including two positive and one negative graphs (\emph{i.e.}, the co-occurrence graph, the semantic similarity graph, and the position-token incompatibility graph). Based on three prior knowledge graphs, we design a graph-aware encoder to learn token and position-aware representations. After that, a lightweight fusion mechanism is introduced to integrate these enriched representations into the existing MIG methods. Resorting to such prior knowledge, our method effectively enhances the model's ability to capture semantic dependencies, leading to improved generation quality. Experimental results demonstrate that our method improves upon existing MIG for class-conditional image generation on ImageNet.

</details>


### [49] [Calibrated Multimodal Representation Learning with Missing Modalities](https://arxiv.org/abs/2511.12034)
*Xiaohao Liu,Xiaobo Xia,Jiaheng Wei,Shuo Yang,Xiu Su,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 提出CalMRL方法，通过校准由模态缺失引起的不完整对齐，在理论指导下缓解锚点偏移问题，提升多模态表征学习中对缺失模态数据的利用能力。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态对齐方法要求所有模态同时存在，难以处理普遍存在模态缺失的实际数据集，限制了多模态学习的应用。

Method: 从锚点偏移视角进行理论分析，提出CalMRL方法，利用模态间的先验和内在联系在表征层面建模缺失模态的推断，并采用双步学习法与共享潜在变量后验分布的闭式解来优化模型。

Result: 验证了CalMRL能有效缓解锚点偏移，具有理论支持的收敛性；在多个实验中表现出优越性能，可灵活集成到现有先进方法中，实现对缺失模态数据的有效利用。

Conclusion: CalMRL为多模态表征学习提供了处理模态缺失的新思路，增强了模型对不完整数据的适应性，拓展了实际应用场景。

Abstract: Multimodal representation learning harmonizes distinct modalities by aligning them into a unified latent space. Recent research generalizes traditional cross-modal alignment to produce enhanced multimodal synergy but requires all modalities to be present for a common instance, making it challenging to utilize prevalent datasets with missing modalities. We provide theoretical insights into this issue from an anchor shift perspective. Observed modalities are aligned with a local anchor that deviates from the optimal one when all modalities are present, resulting in an inevitable shift. To address this, we propose CalMRL for multimodal representation learning to calibrate incomplete alignments caused by missing modalities. Specifically, CalMRL leverages the priors and the inherent connections among modalities to model the imputation for the missing ones at the representation level. To resolve the optimization dilemma, we employ a bi-step learning method with the closed-form solution of the posterior distribution of shared latents. We validate its mitigation of anchor shift and convergence with theoretical guidance. By equipping the calibrated alignment with the existing advanced method, we offer new flexibility to absorb data with missing modalities, which is originally unattainable. Extensive experiments and comprehensive analyses demonstrate the superiority of CalMRL. Our code, model checkpoints, and evaluation raw data will be publicly available.

</details>


### [50] [SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images](https://arxiv.org/abs/2511.12040)
*Xinyuan Hu,Changyue Shi,Chuxiao Yang,Minghao Chen,Jiajun Ding,Tao Wei,Chen Wei,Zhou Yu,Min Tan*

Main category: cs.CV

TL;DR: 本文提出SRSplat，一种从少量低分辨率视图中重建高分辨率3D场景的前馈框架，通过结合外部高质量参考图像和内部纹理线索来弥补低分辨率输入中高频信息的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从稀疏、低分辨率图像进行3D重建时难以恢复精细纹理细节，主要受限于输入中缺乏高频信息。

Method: 提出SRSplat框架，利用多模态大语言模型和扩散模型为每个场景构建特定的参考图像库；设计参考引导特征增强（RGFE）模块融合低分辨率输入与参考图像特征；训练解码器预测高斯图元，并引入纹理感知密度控制（TADC）模块根据内部纹理丰富度自适应调整高斯密度。

Result: 在RealEstate10K、ACID和DTU等多个数据集上实验表明，SRSplat优于现有方法，具备良好的跨数据集和跨分辨率泛化能力。

Conclusion: SRSplat通过融合外部参考信息与内部纹理线索，有效提升了低分辨率输入下的3D重建质量，尤其在纹理细节恢复方面表现突出。

Abstract: Feed-forward 3D reconstruction from sparse, low-resolution (LR) images is a crucial capability for real-world applications, such as autonomous driving and embodied AI. However, existing methods often fail to recover fine texture details. This limitation stems from the inherent lack of high-frequency information in LR inputs. To address this, we propose \textbf{SRSplat}, a feed-forward framework that reconstructs high-resolution 3D scenes from only a few LR views. Our main insight is to compensate for the deficiency of texture information by jointly leveraging external high-quality reference images and internal texture cues. We first construct a scene-specific reference gallery, generated for each scene using Multimodal Large Language Models (MLLMs) and diffusion models. To integrate this external information, we introduce the \textit{Reference-Guided Feature Enhancement (RGFE)} module, which aligns and fuses features from the LR input images and their reference twin image. Subsequently, we train a decoder to predict the Gaussian primitives using the multi-view fused feature obtained from \textit{RGFE}. To further refine predicted Gaussian primitives, we introduce \textit{Texture-Aware Density Control (TADC)}, which adaptively adjusts Gaussian density based on the internal texture richness of the LR inputs. Extensive experiments demonstrate that our SRSplat outperforms existing methods on various datasets, including RealEstate10K, ACID, and DTU, and exhibits strong cross-dataset and cross-resolution generalization capabilities.

</details>


### [51] [FedSDA: Federated Stain Distribution Alignment for Non-IID Histopathological Image Classification](https://arxiv.org/abs/2511.12044)
*Cheng-Chang Tsai,Kai-Wen Cheng,Chun-Shien Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为FedSDA的联邦学习方法，通过染色分布对齐来解决非独立同分布（non-IID）病理图像中的特征分布偏移问题，利用扩散模型和染色分离技术在保护隐私的同时有效缓解客户端间的数据分布差异。


<details>
  <summary>Details</summary>
Motivation: 非IID数据是联邦学习中一个不可避免的挑战，尤其是在处理具有染色差异的病理图像时，现有方法对此关注有限，因此需要一种从数据分布角度出发的有效解决方案。

Method: 提出Federated Stain Distribution Alignment (FedSDA) 方法，利用扩散模型拟合数据分布，并结合染色分离提取关键特征，在联邦学习框架下将各客户端的染色分布与目标分布对齐，且避免直接在原始数据上训练扩散模型以降低隐私泄露风险。

Result: 大量实验结果表明，FedSDA不仅优于专注于缓解客户端模型更新差异的方法，也优于其他从数据分布角度处理non-IID问题的基线方法，在提升模型性能方面表现出色。

Conclusion: FedSDA为解决non-IID病理图像数据下的联邦学习提供了有效且实用的新思路，对计算病理学领域具有重要启示意义。

Abstract: Federated learning (FL) has shown success in collaboratively training a model among decentralized data resources without directly sharing privacy-sensitive training data. Despite recent advances, non-IID (non-independent and identically distributed) data poses an inevitable challenge that hinders the use of FL. In this work, we address the issue of non-IID histopathological images with feature distribution shifts from an intuitive perspective that has only received limited attention. Specifically, we address this issue from the perspective of data distribution by solely adjusting the data distributions of all clients. Building on the success of diffusion models in fitting data distributions and leveraging stain separation to extract the pivotal features that are closely related to the non-IID properties of histopathological images, we propose a Federated Stain Distribution Alignment (FedSDA) method. FedSDA aligns the stain distribution of each client with a target distribution in an FL framework to mitigate distribution shifts among clients. Furthermore, considering that training diffusion models on raw data in FL has been shown to be susceptible to privacy leakage risks, we circumvent this problem while still effectively achieving alignment. Extensive experimental results show that FedSDA is not only effective in improving baselines that focus on mitigating disparities across clients' model updates but also outperforms baselines that address the non-IID data issues from the perspective of data distribution. We show that FedSDA provides valuable and practical insights for the computational pathology community.

</details>


### [52] [DCMM-Transformer: Degree-Corrected Mixed-Membership Attention for Medical Imaging](https://arxiv.org/abs/2511.12047)
*Huimin Cheng,Xiaowei Yu,Shushan Wu,Luyang Fang,Chao Cao,Jing Zhang,Tianming Liu,Dajiang Zhu,Wenxuan Zhong,Ping Ma*

Main category: cs.CV

TL;DR: 提出DCMM-Transformer，一种结合度校正混合成员模型的ViT架构，用于医学图像分析，通过可微分方式建模解剖结构，提升性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 标准ViT无法利用医学图像中的潜在解剖结构（如器官、组织），现有结构建模方法存在非可微、训练不稳定和难以捕捉复杂社区结构的问题。

Method: 在自注意力机制中引入加性的度校正混合成员模型（DCMM）作为偏置，以可微分且可解释的方式建模社区结构和节点度异质性，避免二值掩码和采样。

Result: 在脑部、胸部、乳腺和眼部等多种医学影像数据集上验证了方法的优越性能和泛化能力，生成的注意力图具有解剖意义和语义一致性。

Conclusion: DCMM-Transformer能有效整合医学图像的潜在解剖结构，提升模型表现与可解释性，为ViT在医学图像分析中的应用提供了新思路。

Abstract: Medical images exhibit latent anatomical groupings, such as organs, tissues, and pathological regions, that standard Vision Transformers (ViTs) fail to exploit. While recent work like SBM-Transformer attempts to incorporate such structures through stochastic binary masking, they suffer from non-differentiability, training instability, and the inability to model complex community structure. We present DCMM-Transformer, a novel ViT architecture for medical image analysis that incorporates a Degree-Corrected Mixed-Membership (DCMM) model as an additive bias in self-attention. Unlike prior approaches that rely on multiplicative masking and binary sampling, our method introduces community structure and degree heterogeneity in a fully differentiable and interpretable manner. Comprehensive experiments across diverse medical imaging datasets, including brain, chest, breast, and ocular modalities, demonstrate the superior performance and generalizability of the proposed approach. Furthermore, the learned group structure and structured attention modulation substantially enhance interpretability by yielding attention maps that are anatomically meaningful and semantically coherent.

</details>


### [53] [DeiTFake: Deepfake Detection Model using DeiT Multi-Stage Training](https://arxiv.org/abs/2511.12048)
*Saksham Kumar,Ashish Singh,Srinivasarao Thota,Sunil Kumar Singh,Chandan Kumar*

Main category: cs.CV

TL;DR: 提出了一种基于DeiT的Transformer模型DeiTFake，采用两阶段渐进式训练策略，结合增强学习，在OpenForensics数据集上实现了99.22%的准确率和0.9997的AUROC，显著提升了深度伪造人脸检测性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对数字媒体的真实性构成严重威胁，现有检测方法在面对复杂伪造技术和数据多样性时鲁棒性不足，需要更高效、更具泛化能力的检测模型。

Method: 基于DeiT架构设计Transformer模型，采用两阶段渐进式训练策略：第一阶段通过标准增强进行迁移学习，第二阶段引入高级仿射变换和深度伪造特异性增强进行微调，利用知识蒸馏捕捉细微篡改痕迹。

Result: 在OpenForensics数据集（190,335张图像）上，第一阶段达到98.71%准确率，第二阶段提升至99.22%准确率，AUROC达0.9997，优于当前最先进的基线方法。

Conclusion: DeiTFake通过结合DeiT模型与渐进式增强训练策略，显著提高了深度伪造检测的准确性和鲁棒性，为面部伪造检测提供了新的有效解决方案和实用基准。

Abstract: Deepfakes are major threats to the integrity of digital media. We propose DeiTFake, a DeiT-based transformer and a novel two-stage progressive training strategy with increasing augmentation complexity. The approach applies an initial transfer-learning phase with standard augmentations followed by a fine-tuning phase using advanced affine and deepfake-specific augmentations. DeiT's knowledge distillation model captures subtle manipulation artifacts, increasing robustness of the detection model. Trained on the OpenForensics dataset (190,335 images), DeiTFake achieves 98.71\% accuracy after stage one and 99.22\% accuracy with an AUROC of 0.9997, after stage two, outperforming the latest OpenForensics baselines. We analyze augmentation impact and training schedules, and provide practical benchmarks for facial deepfake detection.

</details>


### [54] [UniABG: Unified Adversarial View Bridging and Graph Correspondence for Unsupervised Cross-View Geo-Localization](https://arxiv.org/abs/2511.12054)
*Cuiqun Chen,Qi Chen,Bin Yang,Xingyi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为UniABG的无监督跨视角地理定位框架，结合对抗视图桥接与图结构校准，在无需标注的情况下显著提升了跨视角匹配性能，并在多个数据集上超越了有监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有跨视角地理定位方法依赖大量成对标注（监督方法）或受伪标签噪声影响（无监督方法），难以兼顾性能与可扩展性。

Method: 提出双阶段框架UniABG：第一阶段采用视图感知对抗桥接（VAAB）学习视图不变特征并增强伪标签鲁棒性；第二阶段通过异构图滤波校准（HGFC）构建双视角结构图以优化跨视图匹配关系。

Result: 在University-1652和SUES-200数据集上，卫星到无人机的AP分别提升+10.63%和+16.73%，达到当前无监督方法最优性能，甚至超过有监督基线。

Conclusion: UniABG有效缓解了跨视角域差异与伪标签噪声问题，为无监督跨视角地理定位提供了高效可行的新方案。

Abstract: Cross-view geo-localization (CVGL) matches query images ($\textit{e.g.}$, drone) to geographically corresponding opposite-view imagery ($\textit{e.g.}$, satellite). While supervised methods achieve strong performance, their reliance on extensive pairwise annotations limits scalability. Unsupervised alternatives avoid annotation costs but suffer from noisy pseudo-labels due to intrinsic cross-view domain gaps. To address these limitations, we propose $\textit{UniABG}$, a novel dual-stage unsupervised cross-view geo-localization framework integrating adversarial view bridging with graph-based correspondence calibration. Our approach first employs View-Aware Adversarial Bridging (VAAB) to model view-invariant features and enhance pseudo-label robustness. Subsequently, Heterogeneous Graph Filtering Calibration (HGFC) refines cross-view associations by constructing dual inter-view structure graphs, achieving reliable view correspondence. Extensive experiments demonstrate state-of-the-art unsupervised performance, showing that UniABG improves Satellite $\rightarrow$ Drone AP by +10.63\% on University-1652 and +16.73\% on SUES-200, even surpassing supervised baselines. The source code is available at https://github.com/chenqi142/UniABG

</details>


### [55] [PipeDiT: Accelerating Diffusion Transformers in Video Generation with Task Pipelining and Model Decoupling](https://arxiv.org/abs/2511.12056)
*Sijie Wang,Qiang Wang,Shaohuai Shi*

Main category: cs.CV

TL;DR: 本文提出了一种名为PipeDiT的新型流水线框架，用于加速基于扩散变换器（DiT）的视频生成，通过序列并行流水线、解耦扩散与VAE模块及注意力协同处理技术，显著降低了推理延迟和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的DiT-based视频生成模型因推理速度慢和内存消耗高而难以实际部署。

Method: 提出了PipeSP算法实现序列并行流水线；设计DeDiVAE将扩散模块与VAE模块解耦并在不同GPU组上执行；引入注意力协同处理（Aco）方法以更高效利用GPU资源。

Result: 在OpenSoraPlan和HunyuanVideo两个开源框架中集成PipeDiT后，在多种分辨率和时间步配置下实现了1.06倍到4.02倍的加速。

Conclusion: PipeDiT能有效提升视频生成效率，降低延迟与内存占用，具有良好的实际部署前景。

Abstract: Video generation has been advancing rapidly, and diffusion transformer (DiT) based models have demonstrated remark- able capabilities. However, their practical deployment is of- ten hindered by slow inference speeds and high memory con- sumption. In this paper, we propose a novel pipelining frame- work named PipeDiT to accelerate video generation, which is equipped with three main innovations. First, we design a pipelining algorithm (PipeSP) for sequence parallelism (SP) to enable the computation of latent generation and commu- nication among multiple GPUs to be pipelined, thus reduc- ing inference latency. Second, we propose DeDiVAE to de- couple the diffusion module and the variational autoencoder (VAE) module into two GPU groups, whose executions can also be pipelined to reduce memory consumption and infer- ence latency. Third, to better utilize the GPU resources in the VAE group, we propose an attention co-processing (Aco) method to further reduce the overall video generation latency. We integrate our PipeDiT into both OpenSoraPlan and Hun- yuanVideo, two state-of-the-art open-source video generation frameworks, and conduct extensive experiments on two 8- GPU systems. Experimental results show that, under many common resolution and timestep configurations, our PipeDiT achieves 1.06x to 4.02x speedups over OpenSoraPlan and HunyuanVideo.

</details>


### [56] [MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity](https://arxiv.org/abs/2511.12061)
*Zhichen Lai,Hua Lu,Huan Li,Jialiang Li,Christian S. Jensen*

Main category: cs.CV

TL;DR: 提出MovSemCL框架，通过运动语义特征提取、分块编码与曲率引导增强，实现高效且语义合理的轨迹相似性计算。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的轨迹相似性计算方法在语义建模、计算效率和数据增强方面存在不足，难以有效捕捉轨迹的多层次结构和运动动态。

Method: 将原始GPS轨迹转换为运动语义特征并分块处理，采用块内与块间注意力机制进行局部与全局模式编码，并设计曲率引导的数据增强策略以保留关键轨迹段。

Result: 实验表明，MovSemCL在真实数据集上相似性搜索的平均排名接近理想值1，启发式近似性能提升最高达20.3%，推理延迟降低最多43.4%。

Conclusion: MovSemCL能有效提升轨迹相似性计算的准确性与效率，同时保证增强数据的物理合理性，优于现有最先进方法。

Abstract: Trajectory similarity computation is fundamental functionality that is used for, e.g., clustering, prediction, and anomaly detection. However, existing learning-based methods exhibit three key limitations: (1) insufficient modeling of trajectory semantics and hierarchy, lacking both movement dynamics extraction and multi-scale structural representation; (2) high computational costs due to point-wise encoding; and (3) use of physically implausible augmentations that distort trajectory semantics. To address these issues, we propose MovSemCL, a movement-semantics contrastive learning framework for trajectory similarity computation. MovSemCL first transforms raw GPS trajectories into movement-semantics features and then segments them into patches. Next, MovSemCL employs intra- and inter-patch attentions to encode local as well as global trajectory patterns, enabling efficient hierarchical representation and reducing computational costs. Moreover, MovSemCL includes a curvature-guided augmentation strategy that preserves informative segments (e.g., turns and intersections) and masks redundant ones, generating physically plausible augmented views. Experiments on real-world datasets show that MovSemCL is capable of outperforming state-of-the-art methods, achieving mean ranks close to the ideal value of 1 at similarity search tasks and improvements by up to 20.3% at heuristic approximation, while reducing inference latency by up to 43.4%.

</details>


### [57] [DCA-LUT: Deep Chromatic Alignment with 5D LUT for Purple Fringing Removal](https://arxiv.org/abs/2511.12066)
*Jialang Lu,Shuning Sun,Pu Wang,Chen Wu,Feng Gao,Lina Gong,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的紫边去除框架DCA-LUT，通过建模色差的物理成因，引入色觉感知坐标变换模块和5D查找表实现高效准确的紫边校正。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖昂贵的硬件和手工特征，无法充分利用数据驱动的优势，且对紫边问题的物理机制建模不足。

Method: 提出Chromatic-Aware Coordinate Transformation（CA-CT）模块，学习图像自适应的颜色空间以分离紫边；使用5D LUT进行非线性颜色校正，并构建大规模合成数据集PF-Synth用于训练与评估。

Result: 在合成与真实数据集上均达到最先进的紫边去除效果，有效恢复亮度通道并实现精准色彩校正。

Conclusion: DCA-LUT首次将深度学习应用于紫边去除，结合物理先验与数据驱动方法，实现了高效、精确的图像质量提升，具有良好的实际应用前景。

Abstract: Purple fringing, a persistent artifact caused by Longitudinal Chromatic Aberration (LCA) in camera lenses, has long degraded the clarity and realism of digital imaging. Traditional solutions rely on complex and expensive apochromatic (APO) lens hardware and the extraction of handcrafted features, ignoring the data-driven approach. To fill this gap, we introduce DCA-LUT, the first deep learning framework for purple fringing removal. Inspired by the physical root of the problem, the spatial misalignment of RGB color channels due to lens dispersion, we introduce a novel Chromatic-Aware Coordinate Transformation (CA-CT) module, learning an image-adaptive color space to decouple and isolate fringing into a dedicated dimension. This targeted separation allows the network to learn a precise ``purple fringe channel", which then guides the accurate restoration of the luminance channel. The final color correction is performed by a learned 5D Look-Up Table (5D LUT), enabling efficient and powerful% non-linear color mapping. To enable robust training and fair evaluation, we constructed a large-scale synthetic purple fringing dataset (PF-Synth). Extensive experiments in synthetic and real-world datasets demonstrate that our method achieves state-of-the-art performance in purple fringing removal.

</details>


### [58] [Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound](https://arxiv.org/abs/2511.12077)
*Dengming Zhang,Weitao You,Jingxiong Li,Weishen Lin,Wenda Shi,Xue Zhao,Heda Zuo,Junxian Wu,Lingyun Sun*

Main category: cs.CV

TL;DR: 提出VAEmotionLLM框架，通过视觉引导音频对齐和跨模态情感适配器，在有限音频预训练下实现视觉语言模型的听觉与跨模态情感理解，并构建艺术导向的情感评测基准ArtEmoBenchmark。


<details>
  <summary>Details</summary>
Motivation: 现有工作多关注单模态或以人类为中心的情感理解，忽视艺术品本身表达的情感；同时AVLM通常需要大规模音频预训练，限制了可扩展性。

Method: 两阶段框架：第一阶段通过视觉引导音频对齐（VG-Align）将视觉通路知识蒸馏到音频通路，实现少音频数据下的听觉能力；第二阶段使用轻量级跨模态情感适配器（EmoAdapter），包含情感增强器和监督器，提升跨模态情感理解。

Result: 在新构建的艺术情感基准ArtEmoBenchmark上达到SOTA性能，优于单模态及多模态基线方法，消融实验验证各组件互补性。

Conclusion: VAEmotionLLM能有效赋予VLM听觉能力和跨模态情感理解力，且无需大规模音频预训练，推动艺术导向的情感智能发展。

Abstract: Emotion understanding is critical for making Large Language Models (LLMs) more general, reliable, and aligned with humans. Art conveys emotion through the joint design of visual and auditory elements, yet most prior work is human-centered or single-modality, overlooking the emotion intentionally expressed by the artwork. Meanwhile, current Audio-Visual Language Models (AVLMs) typically require large-scale audio pretraining to endow Visual Language Models (VLMs) with hearing, which limits scalability. We present Vision Anchored Audio-Visual Emotion LLM (VAEmotionLLM), a two-stage framework that teaches a VLM to hear by seeing with limited audio pretraining and to understand emotion across modalities. In Stage 1, Vision-Guided Audio Alignment (VG-Align) distills the frozen visual pathway into a new audio pathway by aligning next-token distributions of the shared LLM on synchronized audio-video clips, enabling hearing without a large audio dataset. In Stage 2, a lightweight Cross-Modal Emotion Adapter (EmoAdapter), composed of the Emotion Enhancer and the Emotion Supervisor, injects emotion-sensitive residuals and applies emotion supervision to enhance cross-modal emotion understanding. We also construct ArtEmoBenchmark, an art-centric emotion benchmark that evaluates content and emotion understanding under audio-only, visual-only, and audio-visual inputs. VAEmotionLLM achieves state-of-the-art results on ArtEmoBenchmark, outperforming audio-only, visual-only, and audio-visual baselines. Ablations show that the proposed components are complementary.

</details>


### [59] [Point Cloud Quantization through Multimodal Prompting for 3D Understanding](https://arxiv.org/abs/2511.12079)
*Hongxuan Li,Wencheng Zhu,Huiying Xu,Xinzhong Zhu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 提出一种基于多模态提示的点云分析向量量化框架，利用文本嵌入作为语义先验，并通过双约束量化空间融合几何与语义信息。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的向量量化方法在代表性与可解释性方面不足，且难以有效对齐跨模态语义。

Method: 利用预训练模型的文本嵌入作为视觉语义先验，结合多模态提示进行自适应优化，并设计紧凑性与分离性正则化的双约束量化空间，采用Gumbel-Softmax实现可微分离散化。

Result: 在ModelNet40和ScanObjectNN数据集上实验表明，该方法在点云分类任务中显著优于现有量化方法。

Conclusion: 多模态提示驱动的量化框架能有效提升点云表示的语义丰富性与量化性能，为跨模态对齐提供了可解释且高效的新思路。

Abstract: Vector quantization has emerged as a powerful tool in large-scale multimodal models, unifying heterogeneous representations through discrete token encoding. However, its effectiveness hinges on robust codebook design. Current prototype-based approaches relying on trainable vectors or clustered centroids fall short in representativeness and interpretability, even as multimodal alignment demonstrates its promise in vision-language models. To address these limitations, we propose a simple multimodal prompting-driven quantization framework for point cloud analysis. Our methodology is built upon two core insights: 1) Text embeddings from pre-trained models inherently encode visual semantics through many-to-one contrastive alignment, naturally serving as robust prototype priors; and 2) Multimodal prompts enable adaptive refinement of these prototypes, effectively mitigating vision-language semantic gaps. The framework introduces a dual-constrained quantization space, enforced by compactness and separation regularization, which seamlessly integrates visual and prototype features, resulting in hybrid representations that jointly encode geometric and semantic information. Furthermore, we employ Gumbel-Softmax relaxation to achieve differentiable discretization while maintaining quantization sparsity. Extensive experiments on the ModelNet40 and ScanObjectNN datasets clearly demonstrate the superior effectiveness of the proposed method.

</details>


### [60] [Supervised Multilabel Image Classification Using Residual Networks with Probabilistic Reasoning](https://arxiv.org/abs/2511.12082)
*Lokender Singh,Saksham Kumar,Chandan Kumar*

Main category: cs.CV

TL;DR: 提出了一种基于改进ResNet-101和概率推理的多标签图像分类新方法，在COCO-2014上达到0.794 mAP，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多标签图像分类在计算机视觉中具有广泛应用，但标签间的依赖性和不确定性带来挑战，需提高预测准确性。

Method: 采用改进的ResNet-101架构，结合概率推理模拟标签依赖关系和不确定性，提升多标签分类性能。

Result: 在COCO-2014数据集上取得0.794 mAP，超过ResNet-SRN（0.771）和Vision Transformer（0.785），并在precision-recall等指标上表现优异。

Conclusion: 将概率推理融入深度学习模型能有效应对多标签分类中的复杂标签关系，显著提升性能。

Abstract: Multilabel image categorization has drawn interest recently because of its numerous computer vision applications. The proposed work introduces a novel method for classifying multilabel images using the COCO-2014 dataset and a modified ResNet-101 architecture. By simulating label dependencies and uncertainties, the approach uses probabilistic reasoning to improve prediction accuracy. Extensive tests show that the model outperforms earlier techniques and approaches to state-of-the-art outcomes in multilabel categorization. The work also thoroughly assesses the model's performance using metrics like precision-recall score and achieves 0.794 mAP on COCO-2014, outperforming ResNet-SRN (0.771) and Vision Transformer baselines (0.785). The novelty of the work lies in integrating probabilistic reasoning into deep learning models to effectively address the challenges presented by multilabel scenarios.

</details>


### [61] [SemanticStitch: Enhancing Image Coherence through Foreground-Aware Seam Carving](https://arxiv.org/abs/2511.12084)
*Ji-Ping Jin,Chen-Bin Feng,Rui Fan,Chi-Man Vong*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的图像拼接框架SemanticStitch，利用前景对象的语义先验来保持其完整性并提升视觉连贯性。


<details>
  <summary>Details</summary>
Motivation: 传统图像拼接方法在处理视角变化、位置差异和物体运动时容易导致错位和视觉不一致，且缺乏对语义信息的考虑，影响前景连续性。

Method: 引入SemanticStitch框架，结合前景对象的语义先验，并设计一种新的损失函数以强调显著对象的语义完整性。同时构建两个真实世界数据集进行评估。

Result: 实验结果表明，该方法在拼接质量上显著优于传统技术，尤其在语义完整性和视觉连贯性方面表现突出。

Conclusion: SemanticStitch有效提升了图像拼接的鲁棒性和视觉效果，具备实际应用潜力。

Abstract: Image stitching often faces challenges due to varying capture angles, positional differences, and object movements, leading to misalignments and visual discrepancies. Traditional seam carving methods neglect semantic information, causing disruptions in foreground continuity. We introduce SemanticStitch, a deep learning-based framework that incorporates semantic priors of foreground objects to preserve their integrity and enhance visual coherence. Our approach includes a novel loss function that emphasizes the semantic integrity of salient objects, significantly improving stitching quality. We also present two specialized real-world datasets to evaluate our method's effectiveness. Experimental results demonstrate substantial improvements over traditional techniques, providing robust support for practical applications.

</details>


### [62] [OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding](https://arxiv.org/abs/2511.12614)
*Artem Moroz,Vít Zeman,Martin Mikšík,Elizaveta Isianova,Miroslav David,Pavel Burget,Varun Burde*

Main category: cs.CV

TL;DR: 提出了一种统一的端到端框架，结合物体检测与6D姿态估计，支持基于CAD模型或NeRF表示的快速上线，在BOP基准上表现出高精度与效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在物体检测与姿态估计之间缺乏有效集成，且对无CAD模型物体的支持不足，难以兼顾精度与效率。

Method: 采用CNOS检测器定位目标物体，设计基于Transformer的OPFormer模块进行6D姿态估计，利用基础模型提取特征，并通过NOCS空间引入3D几何先验，联合编码多视角模板视图以建立鲁棒的2D-3D对应关系。

Result: 在BOP基准测试中，该系统在模型依赖和无模型场景下均表现出良好的精度与效率平衡，优于或媲美现有方法。

Conclusion: 所提框架实现了检测与姿态估计的一体化，支持灵活的对象表征构建，具有较强的实用性与推广能力。

Abstract: We introduce a unified, end-to-end framework that seamlessly integrates object detection and pose estimation with a versatile onboarding process. Our pipeline begins with an onboarding stage that generates object representations from either traditional 3D CAD models or, in their absence, by rapidly reconstructing a high-fidelity neural representation (NeRF) from multi-view images. Given a test image, our system first employs the CNOS detector to localize target objects. For each detection, our novel pose estimation module, OPFormer, infers the precise 6D pose. The core of OPFormer is a transformer-based architecture that leverages a foundation model for robust feature extraction. It uniquely learns a comprehensive object representation by jointly encoding multiple template views and enriches these features with explicit 3D geometric priors using Normalized Object Coordinate Space (NOCS). A decoder then establishes robust 2D-3D correspondences to determine the final pose. Evaluated on the challenging BOP benchmarks, our integrated system demonstrates a strong balance between accuracy and efficiency, showcasing its practical applicability in both model-based and model-free scenarios.

</details>


### [63] [Teaching Prompts to Coordinate: Hierarchical Layer-Grouped Prompt Tuning for Continual Learning](https://arxiv.org/abs/2511.12090)
*Shengqin Jiang,Tianqi Kong,Yuankai Qi,Haokui Zhang,Lina Yao,Quan Z. Sheng,Qingshan Liu,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出一种层次化的层分组提示调优方法，用于持续学习，通过共享提示和根提示生成子提示来减少灾难性遗忘并提升模型稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示的持续学习方法在每一层独立引入可学习提示，虽然灵活性高，但可能导致某些层不必要的更新，增加灾难性遗忘的风险。

Method: 提出层次化层分组提示调优方法：同一组内的层共享由位置编码调整的提示；使用单一任务特定的根提示生成各层组的子提示，增强协同性并减少独立性。

Result: 在四个基准上的实验表明，该方法在性能上优于多种现有最先进方法。

Conclusion: 该方法通过结构化提示共享和生成机制，有效平衡了模型灵活性与稳定性，显著缓解了灾难性遗忘问题。

Abstract: Prompt-based continual learning methods fine-tune only a small set of additional learnable parameters while keeping the pre-trained model's parameters frozen. It enables efficient adaptation to new tasks while mitigating the risk of catastrophic forgetting. These methods typically attach one independent task-specific prompt to each layer of pre-trained models to locally modulate its features, ensuring that the layer's representation aligns with the requirements of the new task. However, although introducing learnable prompts independently at each layer provides high flexibility for adapting to new tasks, this overly flexible tuning could make certain layers susceptible to unnecessary updates. As all prompts till the current task are added together as a final prompt for all seen tasks, the model may easily overwrite feature representations essential to previous tasks, which increases the risk of catastrophic forgetting. To address this issue, we propose a novel hierarchical layer-grouped prompt tuning method for continual learning. It improves model stability in two ways: (i) Layers in the same group share roughly the same prompts, which are adjusted by position encoding. This helps preserve the intrinsic feature relationships and propagation pathways of the pre-trained model within each group. (ii) It utilizes a single task-specific root prompt to learn to generate sub-prompts for each layer group. In this way, all sub-prompts are conditioned on the same root prompt, enhancing their synergy and reducing independence. Extensive experiments across four benchmarks demonstrate that our method achieves favorable performance compared with several state-of-the-art methods.

</details>


### [64] [Learning from Dense Events: Towards Fast Spiking Neural Networks Training via Event Dataset Distillatio](https://arxiv.org/abs/2511.12095)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Kun Wang,Xudong Jiang*

Main category: cs.CV

TL;DR: PACE是首个面向脉冲神经网络（SNN）和事件视觉的数据库蒸馏框架，通过ST-DSM和PEQ-N两个核心模块，显著降低SNN训练的时间与存储成本，同时保持较高准确率。


<details>
  <summary>Details</summary>
Motivation: SNN虽然能效高，但因时间编码导致训练成本高昂，限制了其实际部署。需要一种高效方法来降低SNN在事件数据上的训练开销。

Method: 提出PACE框架，包含ST-DSM模块（利用残余膜电位进行细粒度时空匹配）和PEQ-N模块（提供可兼容事件帧流程的概率整数量化器），将大规模事件数据集蒸馏为小型合成数据集，实现快速SNN训练。

Result: 在DVS-Gesture、CIFAR10-DVS和N-MNIST上优于现有基线方法；在N-MNIST上达到84.4%准确率（约为全数据集性能的85%），训练时间减少50倍以上，存储成本降低6000倍。

Conclusion: PACE有效解决了SNN训练成本高的问题，实现了分钟级训练和高效边缘部署，推动了事件驱动视觉系统的发展。

Abstract: Event cameras sense brightness changes and output binary asynchronous event streams, attracting increasing attention. Their bio-inspired dynamics align well with spiking neural networks (SNNs), offering a promising energy-efficient alternative to conventional vision systems. However, SNNs remain costly to train due to temporal coding, which limits their practical deployment. To alleviate the high training cost of SNNs, we introduce \textbf{PACE} (Phase-Aligned Condensation for Events), the first dataset distillation framework to SNNs and event-based vision. PACE distills a large training dataset into a compact synthetic one that enables fast SNN training, which is achieved by two core modules: \textbf{ST-DSM} and \textbf{PEQ-N}. ST-DSM uses residual membrane potentials to densify spike-based features (SDR) and to perform fine-grained spatiotemporal matching of amplitude and phase (ST-SM), while PEQ-N provides a plug-and-play straight through probabilistic integer quantizer compatible with standard event-frame pipelines. Across DVS-Gesture, CIFAR10-DVS, and N-MNIST datasets, PACE outperforms existing coreset selection and dataset distillation baselines, with particularly strong gains on dynamic event streams and at low or moderate IPC. Specifically, on N-MNIST, it achieves \(84.4\%\) accuracy, about \(85\%\) of the full training set performance, while reducing training time by more than \(50\times\) and storage cost by \(6000\times\), yielding compact surrogates that enable minute-scale SNN training and efficient edge deployment.

</details>


### [65] [Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views](https://arxiv.org/abs/2511.12878)
*Junyi Ma,Wentao Bao,Jingyi Xu,Guanzhong Sun,Yu Zheng,Erhang Zhang,Xieyuanli Chen,Hesheng Wang*

Main category: cs.CV

TL;DR: 提出了一种零样本方法EgoLoc，用于在以自我为中心的视频中定位手-物体接触和分离的时间戳，无需依赖对象掩码或动词-名词分类，具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注交互行为的建模（如何交互），但对手与物体接触/分离的关键时刻（何时交互）的精确定位仍不足，这在混合现实和机器人运动规划中至关重要。

Method: 提出EgoLoc，引入手部动态引导采样生成高质量视觉提示，利用视觉-语言模型识别接触/分离属性并定位具体时间戳，结合闭环反馈进行优化，实现无需类别标注的零样本时序交互定位。

Result: 在公开数据集和新构建的基准上实验表明，EgoLoc能有效实现以自我为中心视频中的时序交互定位，并可提升多个下游任务（如AR/VR、机器人操作）的表现。

Conclusion: EgoLoc无需对象掩码和动作类别标注即可精确捕捉手-物交互的关键时刻，具备良好的泛化性和实用性，推动了零样本时序定位在第一视角交互理解中的应用。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR applications and human-robot policy transfer. Existing research has mostly focused on modeling the behavior paradigm of interactive actions (i.e., "how to interact"). However, the more challenging and fine-grained problem of capturing the critical moments of contact and separation between the hand and the target object (i.e., "when to interact") is still underexplored, which is crucial for immersive interactive experiences in mixed reality and robotic motion planning. Therefore, we formulate this problem as temporal interaction localization (TIL). Some recent works extract semantic masks as TIL references, but suffer from inaccurate object grounding and cluttered scenarios. Although current temporal action localization (TAL) methods perform well in detecting verb-noun action segments, they rely on category annotations during training and exhibit limited precision in localizing hand-object contact/separation moments. To address these issues, we propose a novel zero-shot approach dubbed EgoLoc to localize hand-object contact and separation timestamps in egocentric videos. EgoLoc introduces hand-dynamics-guided sampling to generate high-quality visual prompts. It exploits the vision-language model to identify contact/separation attributes, localize specific timestamps, and provide closed-loop feedback for further refinement. EgoLoc eliminates the need for object masks and verb-noun taxonomies, leading to generalizable zero-shot implementation. Comprehensive experiments on the public dataset and our novel benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric videos. It is also validated to effectively facilitate multiple downstream applications in egocentric vision and robotic manipulation tasks. Code and relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [66] [Sparse by Rule: Probability-Based N:M Pruning for Spiking Neural Networks](https://arxiv.org/abs/2511.12097)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Xudong Jiang,Dacheng Tao*

Main category: cs.CV

TL;DR: 本文提出了SpikeNM，首个面向脉冲神经网络（SNN）的半结构化N:M剪枝框架，能够从零开始学习稀疏SNN，在保持精度的同时实现硬件友好的高效稀疏模式。


<details>
  <summary>Details</summary>
Motivation: 深度SNN虽然具有事件驱动和稀疏计算带来的能效优势，但深层结构导致参数和计算成本增加，限制其在边缘设备部署；现有剪枝方法在硬件加速与精度保持之间难以兼顾。

Method: 提出SpikeNM，采用M路基-对数参数化结合可微top-k采样器，将每块复杂度线性化为O(M)，避免组合爆炸；并引入受神经科学启发的资格信用蒸馏（EID），利用时序累积信用生成块级软目标，以对齐掩码概率与脉冲动态，稳定高稀疏下的搜索过程。

Result: 在2:4稀疏率下，SpikeNM在主流数据集上保持甚至提升精度，同时生成有利于硬件加速的稀疏模式，有效结合了SNN固有的脉冲稀疏性。

Conclusion: SpikeNM实现了SNN中精度、效率与硬件友好性的良好平衡，为SNN在边缘设备上的高效部署提供了可行方案。

Abstract: Brain-inspired Spiking neural networks (SNNs) promise energy-efficient intelligence via event-driven, sparse computation, but deeper architectures inflate parameters and computational cost, hindering their edge deployment. Recent progress in SNN pruning helps alleviate this burden, yet existing efforts fall into only two families: \emph{unstructured} pruning, which attains high sparsity but is difficult to accelerate on general hardware, and \emph{structured} pruning, which eases deployment but lack flexibility and often degrades accuracy at matched sparsity. In this work, we introduce \textbf{SpikeNM}, the first SNN-oriented \emph{semi-structured} \(N{:}M\) pruning framework that learns sparse SNNs \emph{from scratch}, enforcing \emph{at most \(N\)} non-zeros per \(M\)-weight block. To avoid the combinatorial space complexity \(\sum_{k=1}^{N}\binom{M}{k}\) growing exponentially with \(M\), SpikeNM adopts an \(M\)-way basis-logit parameterization with a differentiable top-\(k\) sampler, \emph{linearizing} per-block complexity to \(\mathcal O(M)\) and enabling more aggressive sparsification. Further inspired by neuroscience, we propose \emph{eligibility-inspired distillation} (EID), which converts temporally accumulated credits into block-wise soft targets to align mask probabilities with spiking dynamics, reducing sampling variance and stabilizing search under high sparsity. Experiments show that at \(2{:}4\) sparsity, SpikeNM maintains and even with gains across main-stream datasets, while yielding hardware-amenable patterns that complement intrinsic spike sparsity.

</details>


### [67] [DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation](https://arxiv.org/abs/2511.13047)
*Yan Gong,Jianli Lu,Yongsheng Gao,Jie Zhao,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.CV

TL;DR: 提出了一种名为DiffPixelFormer的新型RGB-D室内场景语义分割模型，通过差分像素感知Transformer增强模态内表示并建模模态间交互，在SUN RGB-D和NYUDv2数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D融合方法计算开销大，对模态内和模态间特征关系建模不足，导致特征对齐不精确、表征判别能力有限。

Method: 提出DiffPixelFormer，核心为IIMIB模块，利用自注意力捕捉模态内长程依赖，并通过DSIM模块解耦模态特有与共享特征以实现精细的跨模态对齐；引入动态融合策略根据场景特性平衡多模态贡献。

Result: 在SUN RGB-D和NYUDv2上，DiffPixelFormer-L分别达到54.28%和59.95%的mIoU，比DFormer-L提升1.78%和2.75%。

Conclusion: DiffPixelFormer有效提升了RGB-D室内语义分割的精度，通过精细化的跨模态对齐和动态融合策略，实现了更优的特征表示与性能表现。

Abstract: Indoor semantic segmentation is fundamental to computer vision and robotics, supporting applications such as autonomous navigation, augmented reality, and smart environments. Although RGB-D fusion leverages complementary appearance and geometric cues, existing methods often depend on computationally intensive cross-attention mechanisms and insufficiently model intra- and inter-modal feature relationships, resulting in imprecise feature alignment and limited discriminative representation. To address these challenges, we propose DiffPixelFormer, a differential pixel-aware Transformer for RGB-D indoor scene segmentation that simultaneously enhances intra-modal representations and models inter-modal interactions. At its core, the Intra-Inter Modal Interaction Block (IIMIB) captures intra-modal long-range dependencies via self-attention and models inter-modal interactions with the Differential-Shared Inter-Modal (DSIM) module to disentangle modality-specific and shared cues, enabling fine-grained, pixel-level cross-modal alignment. Furthermore, a dynamic fusion strategy balances modality contributions and fully exploits RGB-D information according to scene characteristics. Extensive experiments on the SUN RGB-D and NYUDv2 benchmarks demonstrate that DiffPixelFormer-L achieves mIoU scores of 54.28% and 59.95%, outperforming DFormer-L by 1.78% and 2.75%, respectively. Code is available at https://github.com/gongyan1/DiffPixelFormer.

</details>


### [68] [DINOv3-Guided Cross Fusion Framework for Semantic-aware CT generation from MRI and CBCT](https://arxiv.org/abs/2511.12098)
*Xianhao Zhou,Jianghao Wu,Ku Zhao,Jinlong He,Huangxuan Zhao,Lei Chen,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: 提出了一种新的DINOv3引导的跨模态融合框架（DGCF），用于从CBCT或MRI生成合成CT图像，结合了Transformer的全局语义和CNN的局部特征，在小规模医学数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN的模型缺乏全局语义理解，而Transformer在小规模医学数据集上容易过拟合，因此需要一种能够平衡局部细节与全局语义信息的模型。

Method: 提出DGCF框架，冻结自监督预训练的DINOv3 Transformer作为全局表示提取器，结合可训练的CNN编码器-解码器，并通过可学习的跨模态融合模块进行层次化特征融合；同时引入多层级DINOv3感知（MLDP）损失，提升合成CT与真实CT在语义空间中的相似性。

Result: 在SynthRAD2023骨盆数据集上，DGCF在MS-SSIM、PSNR和基于分割的指标上均达到最先进水平，适用于MRI→CT和CBCT→CT两种转换任务。

Conclusion: DGCF有效结合了Transformer的语义理解能力与CNN的局部建模优势，是首个利用DINOv3进行医学图像翻译的工作，展示了自监督Transformer在语义感知CT合成中的潜力。

Abstract: Generating synthetic CT images from CBCT or MRI has a potential for efficient radiation dose planning and adaptive radiotherapy. However, existing CNN-based models lack global semantic understanding, while Transformers often overfit small medical datasets due to high model capacity and weak inductive bias. To address these limitations, we propose a DINOv3-Guided Cross Fusion (DGCF) framework that integrates a frozen self-supervised DINOv3 Transformer with a trainable CNN encoder-decoder. It hierarchically fuses global representation of Transformer and local features of CNN via a learnable cross fusion module, achieving balanced local appearance and contextual representation. Furthermore, we introduce a Multi-Level DINOv3 Perceptual (MLDP) loss that encourages semantic similarity between synthetic CT and the ground truth in DINOv3's feature space. Experiments on the SynthRAD2023 pelvic dataset demonstrate that DGCF achieved state-of-the-art performance in terms of MS-SSIM, PSNR and segmentation-based metrics on both MRI$\rightarrow$CT and CBCT$\rightarrow$CT translation tasks. To the best of our knowledge, this is the first work to employ DINOv3 representations for medical image translation, highlighting the potential of self-supervised Transformer guidance for semantic-aware CT synthesis. The code is available at https://github.com/HiLab-git/DGCF.

</details>


### [69] [PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image](https://arxiv.org/abs/2511.13648)
*Ziang Cao,Fangzhou Hong,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出PhysX-Anything，首个从单张野外图像生成仿真就绪的物理3D资产的框架，包含显式几何、关节和物理属性。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法忽视物理和关节特性，限制了在具身AI中的应用。

Method: 提出基于视觉语言模型（VLM）的物理3D生成模型，采用新3D表示方法大幅减少token数量，并构建新数据集PhysX-Mobility以提升多样性。

Result: 在PhysX-Mobility和野外图像上表现出强生成性能和良好泛化能力，仿真实验验证其资产可直接用于机器人策略学习。

Conclusion: PhysX-Anything能有效推动具身AI和物理仿真等下游应用发展。

Abstract: 3D modeling is shifting from static visual representations toward physical, articulated assets that can be directly used in simulation and interaction. However, most existing 3D generation methods overlook key physical and articulation properties, thereby limiting their utility in embodied AI. To bridge this gap, we introduce PhysX-Anything, the first simulation-ready physical 3D generative framework that, given a single in-the-wild image, produces high-quality sim-ready 3D assets with explicit geometry, articulation, and physical attributes. Specifically, we propose the first VLM-based physical 3D generative model, along with a new 3D representation that efficiently tokenizes geometry. It reduces the number of tokens by 193x, enabling explicit geometry learning within standard VLM token budgets without introducing any special tokens during fine-tuning and significantly improving generative quality. In addition, to overcome the limited diversity of existing physical 3D datasets, we construct a new dataset, PhysX-Mobility, which expands the object categories in prior physical 3D datasets by over 2x and includes more than 2K common real-world objects with rich physical annotations. Extensive experiments on PhysX-Mobility and in-the-wild images demonstrate that PhysX-Anything delivers strong generative performance and robust generalization. Furthermore, simulation-based experiments in a MuJoCo-style environment validate that our sim-ready assets can be directly used for contact-rich robotic policy learning. We believe PhysX-Anything can substantially empower a broad range of downstream applications, especially in embodied AI and physics-based simulation.

</details>


### [70] [Adaptive Begin-of-Video Tokens for Autoregressive Video Diffusion Models](https://arxiv.org/abs/2511.12099)
*Tianle Cheng,Zeyan Zhang,Kaifeng Gao,Jun Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种用于自回归视频扩散模型的自适应视频起始标记（ada-BOV），通过可学习嵌入和自适应归一化调制机制，提升长视频生成的全局一致性与局部动态质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型在生成长视频时面临去噪延迟、误差累积、一致性差和运动动态不足等问题，亟需改进自回归生成中的条件机制和采样策略。

Method: 提出自适应视频起始标记（ada-BOV），利用类似自适应层归一化的调制机制吸收先前去噪帧的信息；结合流式去噪的细化策略，解耦采样轨迹长度与注意力窗口限制；设计扰动增强的训练噪声调度以提升模型鲁棒性。

Result: 实验表明，该方法在多个指标上实现了优越的定性和定量结果，显著提升了长视频生成的一致性和视觉质量。

Conclusion: ada-BOV有效增强了自回归视频扩散模型的全局一致性和局部动态表现，为高质量长视频生成提供了新的解决方案。

Abstract: Recent advancements in diffusion-based video generation have produced impressive and high-fidelity short videos. To extend these successes to generate coherent long videos, most video diffusion models (VDMs) generate videos in an autoregressive manner, i.e., generating subsequent frames conditioned on previous ones. There are generally two primary paradigms: chunk-based extension and stream denoising. The former directly concatenates previous clean frames as conditioning, suffering from denoising latency and error accumulation. The latter maintains the denoising sequence with monotonically increasing noise levels. In each denoising iteration, one clean frame is produced while a new pure noise is simultaneously appended, enabling live-stream sampling. However, it struggles with fragile consistency and poor motion dynamics. In this paper, we propose Adaptive Begin-of-Video Tokens (ada-BOV) for autoregressive VDMs. The BOV tokens are special learnable embeddings on VDMs. They adaptively absorb denoised preceding frames via an adaptive-layer-norm-like modulation. This design preserves the global consistency while allowing for flexible conditioning in dynamic scenarios. To ensure the quality of local dynamics essential in modulating BOV tokens, we further propose a refinement strategy for stream denoising. It decouples the sampling trajectory length from the attention window size constraint, leading to improved local guidance and overall imaging quality. We also propose a disturbance-augmented training noise schedule, which balances the convergence speed with model robustness for the stream denoising. Extensive experiments demonstrate that our method achieves compelling qualitative and quantitative results across multiple metrics.

</details>


### [71] [Scaling Spatial Intelligence with Multimodal Foundation Models](https://arxiv.org/abs/2511.13719)
*Zhongang Cai,Ruisi Wang,Chenyang Gu,Fanyi Pu,Junxiang Xu,Yubo Wang,Wanqi Yin,Zhitao Yang,Chen Wei,Qingping Sun,Tongxi Zhou,Jiaqi Li,Hui En Pang,Oscar Qian,Yukun Wei,Zhiqian Lin,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Xiangyu Fan,Hanming Deng,Lewei Lu,Liang Pan,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: 本研究通过构建大规模、多样化的空间智能数据集SenseNova-SI-8M，系统性地提升多模态基础模型的空间智能能力，在多个基准上取得显著性能提升，同时保持强大的通用多模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型已取得显著进展，但在空间智能方面仍存在明显缺陷。本文旨在探索通过模型和数据扩展来增强空间智能的可行性和有效性。

Method: 基于Qwen3-VL、InternVL3和Bagel等现有模型，构建包含八百万样本的多样化数据集SenseNova-SI-8M，并在严格的空间能力分类体系下进行训练与评估。

Result: SenseNova-SI在多个空间智能基准上表现优异：VSI-Bench 68.7%，MMSI 43.3%，MindCube 85.6%，ViewSpatial 54.6%，SITE 50.1%，同时在MMBench-En上达到84.9%的通用性能。研究还发现数据多样性可促进泛化能力，缓解过拟合与语言捷径问题，并初步验证了空间思维链推理的潜力。

Conclusion: 通过系统性的数据构建和模型扩展，可有效提升多模态模型的空间智能，且具备良好的泛化性和应用前景。该系列模型已公开发布，推动相关研究发展。

Abstract: Despite remarkable progress, multimodal foundation models still exhibit surprising deficiencies in spatial intelligence. In this work, we explore scaling up multimodal foundation models to cultivate spatial intelligence within the SenseNova-SI family, built upon established multimodal foundations including visual understanding models (i.e., Qwen3-VL and InternVL3) and unified understanding and generation models (i.e., Bagel). We take a principled approach to constructing high-performing and robust spatial intelligence by systematically curating SenseNova-SI-8M: eight million diverse data samples under a rigorous taxonomy of spatial capabilities. SenseNova-SI demonstrates unprecedented performance across a broad range of spatial intelligence benchmarks: 68.7% on VSI-Bench, 43.3% on MMSI, 85.6% on MindCube, 54.6% on ViewSpatial, and 50.1% on SITE, while maintaining strong general multimodal understanding (e.g., 84.9% on MMBench-En). More importantly, we analyze the impact of data scaling, discuss early signs of emergent generalization capabilities enabled by diverse data training, analyze the risk of overfitting and language shortcuts, present a preliminary study on spatial chain-of-thought reasoning, and validate the potential downstream application. SenseNova-SI is an ongoing project, and this report will be updated continuously. All newly trained multimodal foundation models are publicly released to facilitate further research in this direction.

</details>


### [72] [Did Models Sufficient Learn? Attribution-Guided Training via Subset-Selected Counterfactual Augmentation](https://arxiv.org/abs/2511.12100)
*Yannan Chen,Ruoyu Chen,Bin Zeng,Wei Wang,Shiming Liu,Qunli Zhang,Zheng Hu,Laiyuan Wang,Yaowei Wang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出Subset-Selected Counterfactual Augmentation (SS-CA) 方法，通过基于归因的反事实增强提升视觉模型的因果学习与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型训练依赖有限的关键特征，导致对分布偏移敏感；归因方法揭示了模型依赖非充分因果特征的问题，需改进其因果性以提升鲁棒性。

Method: 基于LIMA归因方法开发Counterfactual LIMA，识别最小关键区域集并生成反事实样本；通过将这些区域替换为自然背景进行数据增强，并在原始和增强数据上联合训练模型。

Result: 在多个ImageNet变体上实验表明，SS-CA提升了模型在分布内测试数据上的泛化性能，并在ImageNet-R、ImageNet-S等OOD基准上表现更优；同时在噪声等扰动下也展现出更强的鲁棒性。

Conclusion: SS-CA有效利用可解释性指导模型训练，纠正了模型对非充分因果特征的依赖，增强了模型的性能、泛化能力和鲁棒性。

Abstract: In current visual model training, models often rely on only limited sufficient causes for their predictions, which makes them sensitive to distribution shifts or the absence of key features. Attribution methods can accurately identify a model's critical regions. However, masking these areas to create counterfactuals often causes the model to misclassify the target, while humans can still easily recognize it. This divergence highlights that the model's learned dependencies may not be sufficiently causal. To address this issue, we propose Subset-Selected Counterfactual Augmentation (SS-CA), which integrates counterfactual explanations directly into the training process for targeted intervention. Building on the subset-selection-based LIMA attribution method, we develop Counterfactual LIMA to identify minimal spatial region sets whose removal can selectively alter model predictions. Leveraging these attributions, we introduce a data augmentation strategy that replaces the identified regions with natural background, and we train the model jointly on both augmented and original samples to mitigate incomplete causal learning. Extensive experiments across multiple ImageNet variants show that SS-CA improves generalization on in-distribution (ID) test data and achieves superior performance on out-of-distribution (OOD) benchmarks such as ImageNet-R and ImageNet-S. Under perturbations including noise, models trained with SS-CA also exhibit enhanced generalization, demonstrating that our approach effectively uses interpretability insights to correct model deficiencies and improve both performance and robustness.

</details>


### [73] [BdSL-SPOTER: A Transformer-Based Framework for Bengali Sign Language Recognition with Cultural Adaptation](https://arxiv.org/abs/2511.12103)
*Sayad Ibna Azad,Md. Atiqur Rahman*

Main category: cs.CV

TL;DR: BdSL-SPOTER是一种基于姿态的变压器框架，用于准确高效地识别孟加拉手语（BdSL），在BdSLW60基准上实现了97.92%的Top-1验证准确率，比基线模型提高了22.82%，同时保持较低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了提高孟加拉手语识别的准确性和效率，并适应低资源区域手语的可扩展需求。

Method: 扩展SPOTER范式，引入文化特定预处理、紧凑的四层变压器编码器和优化的可学习位置编码，并采用课程学习以增强泛化能力并加速收敛。

Result: 在BdSLW60基准上达到97.92%的Top-1验证准确率，参数更少、FLOPs更低、FPS更高。

Conclusion: BdSL-SPOTER为现实世界的无障碍应用提供了实用框架，并可作为其他低资源地区手语的可扩展模型。

Abstract: We introduce BdSL-SPOTER, a pose-based transformer framework for accurate and efficient recognition of Bengali Sign Language (BdSL). BdSL-SPOTER extends the SPOTER paradigm with cultural specific preprocessing and a compact four-layer transformer encoder featuring optimized learnable positional encodings, while employing curriculum learning to enhance generalization on limited data and accelerate convergence. On the BdSLW60 benchmark, it achieves 97.92% Top-1 validation accuracy, representing a 22.82% improvement over the Bi-LSTM baseline, all while keeping computational costs low. With its reduced number of parameters, lower FLOPs, and higher FPS, BdSL-SPOTER provides a practical framework for real-world accessibility applications and serves as a scalable model for other low-resource regional sign languages.

</details>


### [74] [TEMPO: Global Temporal Building Density and Height Estimation from Satellite Imagery](https://arxiv.org/abs/2511.12104)
*Tammy Glazer,Gilles Q. Hacheme,Akram Zaytar,Luana Marotti,Amy Michaels,Girmaw Abebe Tadesse,Kevin White,Rahul Dodhia,Andrew Zolli,Inbal Becker-Reshef,Juan M. Lavista Ferres,Caleb Robinson*

Main category: cs.CV

TL;DR: TEMPO是一个利用深度学习模型从高分辨率卫星图像生成全球、时间连续的建筑密度和高度数据集的方法，具有高效、准确和时间稳定的特点。


<details>
  <summary>Details</summary>
Motivation: 为了实现对全球建成区发展的大规模监测以及气候变化影响评估，需要一个高时空分辨率且计算成本较低的建筑密度与高度数据集。

Method: 结合现有建筑轮廓和高度数据与季度PlanetScope卫星影像，训练一个多任务深度学习模型，在37.6米分辨率上预测建筑密度和高度，并将其应用于2018年第一季度至2025年第二季度的全球影像。

Result: 模型在不同手工标注子集上的F1得分达到85%至88%，五年趋势一致性得分为0.96，验证显示其估计结果准确且时间稳定性强。

Conclusion: TEMPO能够以较低计算成本捕捉季度尺度的建成区变化，为全球韧性与适应性研究提供了关键数据支持。

Abstract: We present TEMPO, a global, temporally resolved dataset of building density and height derived from high-resolution satellite imagery using deep learning models. We pair building footprint and height data from existing datasets with quarterly PlanetScope basemap satellite images to train a multi-task deep learning model that predicts building density and building height at a 37.6-meter per pixel resolution. We apply this model to global PlanetScope basemaps from Q1 2018 through Q2 2025 to create global, temporal maps of building density and height. We validate these maps by comparing against existing building footprint datasets. Our estimates achieve an F1 score between 85% and 88% on different hand-labeled subsets, and are temporally stable, with a 0.96 five-year trend-consistency score. TEMPO captures quarterly changes in built settlements at a fraction of the computational cost of comparable approaches, unlocking large-scale monitoring of development patterns and climate impacts essential for global resilience and adaptation efforts.

</details>


### [75] [Fine-Grained DINO Tuning with Dual Supervision for Face Forgery Detection](https://arxiv.org/abs/2511.12107)
*Tianxiang Zhang,Peipeng Yu,Zhihua Xia,Longchen Dai,Xiaoyu Zhou,Hui Gao*

Main category: cs.CV

TL;DR: 提出了一种基于DINOv2的轻量级深度伪造细粒度适配器（DFF-Adapter），通过多任务学习同时实现真实性检测和伪造方法分类，提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法将DINOv2用于通用二分类，忽略了不同伪造方法产生的特异性伪影，限制了检测性能。

Method: 在DINOv2的每个Transformer块中引入轻量化的多头LoRA模块，并设计共享分支将细粒度伪造类型信息传递给真实性检测头，实现多任务协同优化。

Result: 该方法仅使用350万可训练参数，在检测精度上达到甚至超过当前复杂的最先进方法。

Conclusion: DFF-Adapter通过细粒度伪造类型识别增强真实性判断，实现了高效且高性能的深度伪造检测。

Abstract: The proliferation of sophisticated deepfakes poses significant threats to information integrity. While DINOv2 shows promise for detection, existing fine-tuning approaches treat it as generic binary classification, overlooking distinct artifacts inherent to different deepfake methods. To address this, we propose a DeepFake Fine-Grained Adapter (DFF-Adapter) for DINOv2. Our method incorporates lightweight multi-head LoRA modules into every transformer block, enabling efficient backbone adaptation. DFF-Adapter simultaneously addresses authenticity detection and fine-grained manipulation type classification, where classifying forgery methods enhances artifact sensitivity. We introduce a shared branch propagating fine-grained manipulation cues to the authenticity head. This enables multi-task cooperative optimization, explicitly enhancing authenticity discrimination with manipulation-specific knowledge. Utilizing only 3.5M trainable parameters, our parameter-efficient approach achieves detection accuracy comparable to or even surpassing that of current complex state-of-the-art methods.

</details>


### [76] [MediRound: Multi-Round Entity-Level Reasoning Segmentation in Medical Images](https://arxiv.org/abs/2511.12110)
*Qinyue Tong,Ziqian Lu,Jun Liu,Rui Zuo,Zheming Lu*

Main category: cs.CV

TL;DR: 本文提出了多轮实体级医学推理分割（MEMR-Seg）新任务，构建了包含17.7万个多轮医学分割对话的大规模数据集MR-MedSeg，并提出了一种具有判断与纠正机制的基线模型MediRound，有效提升了多轮医学图像分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法大多任务特定且缺乏交互性，基于文本提示的方法局限于单轮对话，无法进行多轮推理，因此需要一种支持多轮交互和实体级推理的新型分割框架。

Method: 提出MEMR-Seg任务和MR-MedSeg数据集；设计MediRound模型用于多轮医学推理分割；引入轻量化的判断与纠正机制以缓解多轮推理中的误差传播问题。

Result: 实验结果表明，MediRound在MEMR-Seg任务上表现优异，显著优于传统的医学指代表分割方法，验证了所提方法在多轮交互式分割中的有效性。

Conclusion: 本文推动了交互式医学图像分割的发展，通过多轮实体级推理实现了更贴近临床实际需求的用户驱动分割，为未来智能诊疗系统提供了新思路和技术基础。

Abstract: Despite the progress in medical image segmentation, most existing methods remain task-specific and lack interactivity. Although recent text-prompt-based segmentation approaches enhance user-driven and reasoning-based segmentation, they remain confined to single-round dialogues and fail to perform multi-round reasoning. In this work, we introduce Multi-Round Entity-Level Medical Reasoning Segmentation (MEMR-Seg), a new task that requires generating segmentation masks through multi-round queries with entity-level reasoning. To support this task, we construct MR-MedSeg, a large-scale dataset of 177K multi-round medical segmentation dialogues, featuring entity-based reasoning across rounds. Furthermore, we propose MediRound, an effective baseline model designed for multi-round medical reasoning segmentation. To mitigate the inherent error propagation in the chain-like pipeline of multi-round segmentation, we introduce a lightweight yet effective Judgment & Correction Mechanism during model inference. Experimental results demonstrate that our method effectively addresses the MEMR-Seg task and outperforms conventional medical referring segmentation methods.

</details>


### [77] [RadarMP: Motion Perception for 4D mmWave Radar in Autonomous Driving](https://arxiv.org/abs/2511.12117)
*Ruiqi Cheng,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: 本文提出RadarMP，一种基于低层雷达回波信号的联合雷达目标检测与运动估计方法，用于实现精确的3D场景运动感知。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将雷达目标检测与运动估计分离，且在恶劣天气下因光学传感器性能下降而受限；稀疏和噪声大的雷达点云导致运动感知不准确。

Method: RadarMP采用统一架构联合建模雷达目标检测和运动估计，并设计了基于多普勒频移和回波强度的自监督损失函数，直接从连续两帧雷达回波信号中生成一致的雷达点云并预测逐点3D场景流。

Result: 在公开数据集上的实验表明，RadarMP在多种天气和光照条件下均实现了可靠的运动感知，优于现有的雷达解耦方法。

Conclusion: RadarMP通过联合学习和自监督策略提升了4D毫米波雷达在全场景自动驾驶中的感知能力，增强了系统在复杂环境下的安全性与鲁棒性。

Abstract: Accurate 3D scene motion perception significantly enhances the safety and reliability of an autonomous driving system. Benefiting from its all-weather operational capability and unique perceptual properties, 4D mmWave radar has emerged as an essential component in advanced autonomous driving. However, sparse and noisy radar points often lead to imprecise motion perception, leaving autonomous vehicles with limited sensing capabilities when optical sensors degrade under adverse weather conditions. In this paper, we propose RadarMP, a novel method for precise 3D scene motion perception using low-level radar echo signals from two consecutive frames. Unlike existing methods that separate radar target detection and motion estimation, RadarMP jointly models both tasks in a unified architecture, enabling consistent radar point cloud generation and pointwise 3D scene flow prediction. Tailored to radar characteristics, we design specialized self-supervised loss functions guided by Doppler shifts and echo intensity, effectively supervising spatial and motion consistency without explicit annotations. Extensive experiments on the public dataset demonstrate that RadarMP achieves reliable motion perception across diverse weather and illumination conditions, outperforming radar-based decoupled motion perception pipelines and enhancing perception capabilities for full-scenario autonomous driving systems.

</details>


### [78] [OAD-Promoter: Enhancing Zero-shot VQA using Large Language Models with Object Attribute Description](https://arxiv.org/abs/2511.12131)
*Quanxing Xu,Ling Zhou,Feifei Zhang,Jinyu Tian,Rubing Huang*

Main category: cs.CV

TL;DR: 提出OAD-Promoter方法，通过对象集中示例生成、记忆知识辅助和OAD提示来减轻语言偏见并提升大模型在视觉问答中的领域迁移鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在视觉问答中因训练数据偏差而存在语言偏见，导致对分布外样本泛化能力差且预测不可靠。

Method: 设计包含OEG、MKA和OAD Prompt的三模块框架：OEG生成全局与对象集中样本以增强视觉输入；MKA从存储示例中检索知识以支持跨域问题；OAD Prompt整合前两模块输出优化推理过程。

Result: 实验表明，该方法在少样本和零样本设置下显著提升VQA性能，达到新的SOTA水平。

Conclusion: OAD-Promoter有效缓解了LLM在VQA中的语言偏见问题，并增强了对分布外数据的泛化能力，提升了实际应用的可靠性。

Abstract: Large Language Models (LLMs) have become a crucial tool in Visual Question Answering (VQA) for handling knowledge-intensive questions in few-shot or zero-shot scenarios. However, their reliance on massive training datasets often causes them to inherit language biases during the acquisition of knowledge. This limitation imposes two key constraints on existing methods: (1) LLM predictions become less reliable due to bias exploitation, and (2) despite strong knowledge reasoning capabilities, LLMs still struggle with out-of-distribution (OOD) generalization. To address these issues, we propose Object Attribute Description Promoter (OAD-Promoter), a novel approach for enhancing LLM-based VQA by mitigating language bias and improving domain-shift robustness. OAD-Promoter comprises three components: the Object-concentrated Example Generation (OEG) module, the Memory Knowledge Assistance (MKA) module, and the OAD Prompt. The OEG module generates global captions and object-concentrated samples, jointly enhancing visual information input to the LLM and mitigating bias through complementary global and regional visual cues. The MKA module assists the LLM in handling OOD samples by retrieving relevant knowledge from stored examples to support questions from unseen domains. Finally, the OAD Prompt integrates the outputs of the preceding modules to optimize LLM inference. Experiments demonstrate that OAD-Promoter significantly improves the performance of LLM-based VQA methods in few-shot or zero-shot settings, achieving new state-of-the-art results.

</details>


### [79] [Compression and Inference of Spiking Neural Networks on Resource-Constrained Hardware](https://arxiv.org/abs/2511.12136)
*Karol C. Jurzec,Tomasz Szydlo,Maciej Wielgosz*

Main category: cs.CV

TL;DR: 提出了一种轻量级C语言运行时，用于在边缘设备上进行脉冲神经网络（SNN）推理，并通过优化降低延迟和内存占用，实现在微控制器上的高效部署。


<details>
  <summary>Details</summary>
Motivation: 尽管SNN具有事件驱动带来的能效优势，但其训练和部署仍具挑战，尤其是在资源受限的边缘设备上缺乏高效的推理运行时。

Method: 从SNNTorch导出训练好的模型，转换为紧凑的C语言表示；采用静态、缓存友好的数据布局和预分配策略以减少开销；利用稀疏脉冲活动剪枝不活跃的神经元和突触，压缩上游卷积层计算。

Result: 在N-MNIST和ST-MNIST上实现了与Python基线相当的准确率，桌面CPU上获得约10倍加速，结合剪枝进一步提升性能，显著降低内存，成功部署于Arduino Portenta H7微控制器。

Conclusion: 通过优化的运行时系统和脉冲驱动的模型压缩，SNN可在传统嵌入式平台上高效执行，适用于边缘计算场景。

Abstract: Spiking neural networks (SNNs) communicate via discrete spikes in time rather than continuous activations. Their event-driven nature offers advantages for temporal processing and energy efficiency on resource-constrained hardware, but training and deployment remain challenging. We present a lightweight C-based runtime for SNN inference on edge devices and optimizations that reduce latency and memory without sacrificing accuracy. Trained models exported from SNNTorch are translated to a compact C representation; static, cache-friendly data layouts and preallocation avoid interpreter and allocation overheads. We further exploit sparse spiking activity to prune inactive neurons and synapses, shrinking computation in upstream convolutional layers. Experiments on N-MNIST and ST-MNIST show functional parity with the Python baseline while achieving ~10 speedups on desktop CPU and additional gains with pruning, together with large memory reductions that enable microcontroller deployment (Arduino Portenta H7). Results indicate that SNNs can be executed efficiently on conventional embedded platforms when paired with an optimized runtime and spike-driven model compression. Code: https://github.com/karol-jurzec/snn-generator/

</details>


### [80] [MAVIS: A Benchmark for Multimodal Source Attribution in Long-form Visual Question Answering](https://arxiv.org/abs/2511.12142)
*Seokwon Song,Minsu Park,Gunhee Kim*

Main category: cs.CV

TL;DR: 本文提出了MAVIS，首个用于评估多模态源归因系统的基准，包含15.7万视觉问答实例，每条答案均标注了细粒度的多模态引用。研究发现当前多模态RAG在图像文档上的归因可靠性弱于文本，且信息量与归因准确性之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 现有源归因研究主要集中在纯文本场景，忽略了多模态信息（如图像）在提升AI回答可信度中的作用，尤其是在视觉问答任务中对用户意图理解和多模态证据引用的需求。

Method: 构建了包含157K视觉QA实例的MAVIS基准数据集，每个答案均标注事实级多模态引用；设计了涵盖信息量、归因准确性和流畅性的细粒度自动评估指标，并提出改进方法以缓解图像文档理解中的上下文偏差。

Result: 实验表明：(1) 基于多模态RAG的LVLM比单模态RAG生成更丰富流畅的答案，但在图像文档上的归因准确性较弱；(2) 在相同多模态输入下，不同提示方法在信息量与归因准确性间存在权衡；(3) 缓解图像理解中的上下文偏差是未来关键方向。自动指标与人工评估高度相关。

Conclusion: MAVIS为多模态源归因提供了有效评测基准，揭示了当前多模态RAG系统在图像归因和提示策略上的局限性，强调需进一步研究如何提升模型对多模态证据（尤其是图像）的理解与可靠引用。

Abstract: Source attribution aims to enhance the reliability of AI-generated answers by including references for each statement, helping users validate the provided answers. However, existing work has primarily focused on text-only scenario and largely overlooked the role of multimodality. We introduce MAVIS, the first benchmark designed to evaluate multimodal source attribution systems that understand user intent behind visual questions, retrieve multimodal evidence, and generate long-form answers with citations. Our dataset comprises 157K visual QA instances, where each answer is annotated with fact-level citations referring to multimodal documents. We develop fine-grained automatic metrics along three dimensions of informativeness, groundedness, and fluency, and demonstrate their strong correlation with human judgments. Our key findings are threefold: (1) LVLMs with multimodal RAG generate more informative and fluent answers than unimodal RAG, but they exhibit weaker groundedness for image documents than for text documents, a gap amplified in multimodal settings. (2) Given the same multimodal documents, there is a trade-off between informativeness and groundedness across different prompting methods. (3) Our proposed method highlights mitigating contextual bias in interpreting image documents as a crucial direction for future research. The dataset and experimental code are available at https://github.com/seokwon99/MAVIS

</details>


### [81] [Breaking the Modality Wall: Time-step Mixup for Efficient Spiking Knowledge Transfer from Static to Event Domain](https://arxiv.org/abs/2511.12150)
*Yuqi Xie,Shuhan Ye,Yi Yu,Chong Wang,Qixin Zhang,Jiazhen Xu,Le Shen,Yuanbin Qian,Jiangbo Qian,Guoqi Li*

Main category: cs.CV

TL;DR: 提出了一种跨模态训练框架TMKT，利用时间步混合策略实现从RGB到事件相机数据的高效知识迁移，提升脉冲神经网络的训练效果。


<details>
  <summary>Details</summary>
Motivation: 由于事件数据稀缺且DVS输出稀疏，现有从RGB到DVS的知识迁移方法因模态间分布差异大而表现不佳。

Method: 提出Time-step Mixup Knowledge Transfer (TMKT)，采用概率性时间步混合（TSM）策略，在不同时间步插值RGB和DVS输入，并引入模态感知的辅助监督任务MAG和MRP以对齐时序特征。

Result: 在多个基准和SNN主干网络上实验表明，TMKT有效降低梯度方差、稳定优化过程，并在脉冲图像分类任务中取得优越性能。

Conclusion: TMKT通过时间步混合与模态感知监督，实现了更平滑的跨模态知识迁移，显著提升了SNN在事件数据上的训练效率与性能。

Abstract: The integration of event cameras and spiking neural networks (SNNs) promises energy-efficient visual intelligence, yet scarce event data and the sparsity of DVS outputs hinder effective training. Prior knowledge transfers from RGB to DVS often underperform because the distribution gap between modalities is substantial. In this work, we present Time-step Mixup Knowledge Transfer (TMKT), a cross-modal training framework with a probabilistic Time-step Mixup (TSM) strategy. TSM exploits the asynchronous nature of SNNs by interpolating RGB and DVS inputs at various time steps to produce a smooth curriculum within each sequence, which reduces gradient variance and stabilizes optimization with theoretical analysis. To employ auxiliary supervision from TSM, TMKT introduces two lightweight modality-aware objectives, Modality Aware Guidance (MAG) for per-frame source supervision and Mixup Ratio Perception (MRP) for sequence-level mix ratio estimation, which explicitly align temporal features with the mixing schedule. TMKT enables smoother knowledge transfer, helps mitigate modality mismatch during training, and achieves superior performance in spiking image classification tasks. Extensive experiments across diverse benchmarks and multiple SNN backbones, together with ablations, demonstrate the effectiveness of our method.

</details>


### [82] [FIA-Edit: Frequency-Interactive Attention for Efficient and High-Fidelity Inversion-Free Text-Guided Image Editing](https://arxiv.org/abs/2511.12151)
*Kaixiang Yang,Boyang Shen,Xin Li,Yuchen Dai,Yuxuan Luo,Yueran Ma,Wei Fang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种无需反演的文本引导图像编辑框架FIA-Edit，通过频率交互注意力机制实现高保真和语义精确的编辑。


<details>
  <summary>Details</summary>
Motivation: 现有无需反演的方法在源信息融合方面存在不足，导致背景保持差、空间不一致和过度编辑问题。

Method: 设计了频率表示交互（FRI）模块和特征注入（FIJ）模块，分别通过自注意力中的频率分量交换和显式引入源侧特征来增强跨域对齐和结构语义保持。

Result: 实验表明FIA-Edit在低计算成本下实现了优越的视觉质量、背景保真度和可控性，并首次将其应用于临床出血分类任务中。

Conclusion: FIA-Edit是一种高效且高保真的图像编辑方法，在通用和医学图像编辑任务中均表现出色。

Abstract: Text-guided image editing has advanced rapidly with the rise of diffusion models. While flow-based inversion-free methods offer high efficiency by avoiding latent inversion, they often fail to effectively integrate source information, leading to poor background preservation, spatial inconsistencies, and over-editing due to the lack of effective integration of source information. In this paper, we present FIA-Edit, a novel inversion-free framework that achieves high-fidelity and semantically precise edits through a Frequency-Interactive Attention. Specifically, we design two key components: (1) a Frequency Representation Interaction (FRI) module that enhances cross-domain alignment by exchanging frequency components between source and target features within self-attention, and (2) a Feature Injection (FIJ) module that explicitly incorporates source-side queries, keys, values, and text embeddings into the target branch's cross-attention to preserve structure and semantics. Comprehensive and extensive experiments demonstrate that FIA-Edit supports high-fidelity editing at low computational cost (~6s per 512 * 512 image on an RTX 4090) and consistently outperforms existing methods across diverse tasks in visual quality, background fidelity, and controllability. Furthermore, we are the first to extend text-guided image editing to clinical applications. By synthesizing anatomically coherent hemorrhage variations in surgical images, FIA-Edit opens new opportunities for medical data augmentation and delivers significant gains in downstream bleeding classification. Our project is available at: https://github.com/kk42yy/FIA-Edit.

</details>


### [83] [Codebook-Centric Deep Hashing: End-to-End Joint Learning of Semantic Hash Centers and Neural Hash Function](https://arxiv.org/abs/2511.12162)
*Shuo Yin,Zhiyuan Yin,Yuqing Hou,Rui Liu,Yong Chen,Dell Zhang*

Main category: cs.CV

TL;DR: 提出了一种端到端的深度哈希方法CRH，通过动态重分配预设码本中的哈希中心并联合优化哈希函数，避免了传统两阶段方法的复杂性和性能损失，同时引入多头机制增强语义表征能力，在多个基准上取得了优于现有方法的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于哈希中心的方法由于随机初始化或两阶段优化导致语义关系利用不充分、计算复杂且存在阶段间差异，影响检索性能。

Method: 提出Center-Reassigned Hashing (CRH)，在训练过程中从预设码本中动态重分配哈希中心，并与哈希函数进行联合端到端优化；引入多头机制提升哈希中心的表达能力。

Result: 在三个基准数据集上实验表明，CRH能学习到语义上有意义的哈希中心，并在检索任务中优于当前最先进的深度哈希方法。

Conclusion: CRH通过无需显式优化的动态中心重分配和多头机制，有效融合语义关系，实现了更高效、更优性能的哈希学习。

Abstract: Hash center-based deep hashing methods improve upon pairwise or triplet-based approaches by assigning fixed hash centers to each class as learning targets, thereby avoiding the inefficiency of local similarity optimization. However, random center initialization often disregards inter-class semantic relationships. While existing two-stage methods mitigate this by first refining hash centers with semantics and then training the hash function, they introduce additional complexity, computational overhead, and suboptimal performance due to stage-wise discrepancies. To address these limitations, we propose $\textbf{Center-Reassigned Hashing (CRH)}$, an end-to-end framework that $\textbf{dynamically reassigns hash centers}$ from a preset codebook while jointly optimizing the hash function. Unlike previous methods, CRH adapts hash centers to the data distribution $\textbf{without explicit center optimization phases}$, enabling seamless integration of semantic relationships into the learning process. Furthermore, $\textbf{a multi-head mechanism}$ enhances the representational capacity of hash centers, capturing richer semantic structures. Extensive experiments on three benchmarks demonstrate that CRH learns semantically meaningful hash centers and outperforms state-of-the-art deep hashing methods in retrieval tasks.

</details>


### [84] [Rethinking Multimodal Point Cloud Completion: A Completion-by-Correction Perspective](https://arxiv.org/abs/2511.12170)
*Wang Luo,Di Wu,Hengyuan Na,Yinlin Zhu,Miao Hu,Guocong Quan*

Main category: cs.CV

TL;DR: 提出了一种新的点云补全范式Completion-by-Correction，利用预训练的图像到3D模型生成拓扑完整的先验形状，并通过特征空间校正使其与部分观测对齐，提升了结构一致性和重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有的点云补全方法多采用补丁式补全（Completion-by-Inpainting），由于几何和语义约束不足，容易产生结构不一致和拓扑错误。因此需要一种更具结构约束的方法。

Method: 提出Completion-by-Correction范式，首先由预训练的图像到3D模型生成完整但粗糙的形状先验，然后通过多阶段框架PGNet进行双特征编码、粗略骨架生成和分层校正，实现从先验到观测的特征空间对齐。

Result: 在ShapeNetViPC数据集上实验表明，PGNet优于现有最先进方法，平均Chamfer Distance降低23.5%，F-score提升7.1%。

Conclusion: Completion-by-Correction范式通过引入结构先验并进行引导式修正，有效提升了点云补全的结构一致性和细节恢复能力，为多模态点云补全提供了新思路。

Abstract: Point cloud completion aims to reconstruct complete 3D shapes from partial observations, which is a challenging problem due to severe occlusions and missing geometry. Despite recent advances in multimodal techniques that leverage complementary RGB images to compensate for missing geometry, most methods still follow a Completion-by-Inpainting paradigm, synthesizing missing structures from fused latent features. We empirically show that this paradigm often results in structural inconsistencies and topological artifacts due to limited geometric and semantic constraints. To address this, we rethink the task and propose a more robust paradigm, termed Completion-by-Correction, which begins with a topologically complete shape prior generated by a pretrained image-to-3D model and performs feature-space correction to align it with the partial observation. This paradigm shifts completion from unconstrained synthesis to guided refinement, enabling structurally consistent and observation-aligned reconstruction. Building upon this paradigm, we introduce PGNet, a multi-stage framework that conducts dual-feature encoding to ground the generative prior, synthesizes a coarse yet structurally aligned scaffold, and progressively refines geometric details via hierarchical correction. Experiments on the ShapeNetViPC dataset demonstrate the superiority of PGNet over state-of-the-art baselines in terms of average Chamfer Distance (-23.5%) and F-score (+7.1%).

</details>


### [85] [MixAR: Mixture Autoregressive Image Generation](https://arxiv.org/abs/2511.12181)
*Jinyuan Hu,Jiayou Zhang,Shaobo Cui,Kun Zhang,Guangyi Chen*

Main category: cs.CV

TL;DR: 本文提出MixAR框架，通过离散-连续混合建模提升连续自回归图像生成的效率与质量，引入TI-Mix策略实现训练与推理分布的一致性。


<details>
  <summary>Details</summary>
Motivation: 离散token的量化过程损失细节信息，限制生成保真度；而连续空间虽能提升质量，但因空间庞大无结构导致建模困难。

Method: 提出MixAR框架，采用因子化形式，利用离散token作为先验指导连续自回归预测，并探索多种混合策略（DC-SA、DC-CA、DC-Mix）和TI-Mix训练-推理一致化方法。

Result: 实验表明DC-Mix在计算效率与生成保真度之间取得良好平衡，TI-Mix带来持续性能提升。

Conclusion: MixAR通过引入离散先验有效提升了连续自回归图像生成的效率与一致性，为高质量图像生成提供了新思路。

Abstract: Autoregressive (AR) approaches, which represent images as sequences of discrete tokens from a finite codebook, have achieved remarkable success in image generation. However, the quantization process and the limited codebook size inevitably discard fine-grained information, placing bottlenecks on fidelity. Motivated by this limitation, recent studies have explored autoregressive modeling in continuous latent spaces, which offers higher generation quality. Yet, unlike discrete tokens constrained by a fixed codebook, continuous representations lie in a vast and unstructured space, posing significant challenges for efficient autoregressive modeling. To address these challenges, we introduce MixAR, a novel framework that leverages mixture training paradigms to inject discrete tokens as prior guidance for continuous AR modeling. MixAR is a factorized formulation that leverages discrete tokens as prior guidance for continuous autoregressive prediction. We investigate several discrete-continuous mixture strategies, including self-attention (DC-SA), cross-attention (DC-CA), and a simple approach (DC-Mix) that replaces homogeneous mask tokens with informative discrete counterparts. Moreover, to bridge the gap between ground-truth training tokens and inference tokens produced by the pre-trained AR model, we propose Training-Inference Mixture (TI-Mix) to achieve consistent training and generation distributions. In our experiments, we demonstrate a favorable balance of the DC-Mix strategy between computational efficiency and generation fidelity, and consistent improvement of TI-Mix.

</details>


### [86] [MMRINet: Efficient Mamba-Based Segmentation with Dual-Path Refinement for Low-Resource MRI Analysis](https://arxiv.org/abs/2511.12193)
*Abdelrahman Elsayed,Ahmed Jaheen,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 提出了一种轻量级网络MMRINet，用于在资源受限环境下进行高效的多参数MRI脑肿瘤分割，采用Mamba模型和双路径特征优化模块，在BraTS-Lighthouse SSA 2025中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在计算资源受限的环境中，现有的3D深度网络因计算成本高而难以应用于自动化脑肿瘤分割，因此需要更高效的模型。

Method: 提出MMRINet，使用线性复杂度的Mamba状态空间模型替代传统的二次复杂度注意力机制，并设计了双路径特征优化（DPFR）模块和渐进式特征聚合（PFA）模块以提升特征多样性和多尺度融合效果。

Result: 在BraTS-Lighthouse SSA 2025上，模型以仅约250万参数实现了平均Dice分数0.752和HD95为12.23的良好性能。

Conclusion: MMRINet在保持低参数量的同时实现了高效准确的脑肿瘤分割，适合低资源临床环境应用。

Abstract: Automated brain tumor segmentation in multi-parametric MRI remains challenging in resource-constrained settings where deep 3D networks are computationally prohibitive. We propose MMRINet, a lightweight architecture that replaces quadratic-complexity attention with linear-complexity Mamba state-space models for efficient volumetric context modeling. Novel Dual-Path Feature Refinement (DPFR) modules maximize feature diversity without additional data requirements, while Progressive Feature Aggregation (PFA) enables effective multi-scale fusion. In the BraTS-Lighthouse SSA 2025, our model achieves strong performance with an average Dice score of (0.752) and an average HD95 of (12.23) with only ~2.5M parameters, demonstrating efficient and accurate segmentation suitable for low-resource clinical environments. Our GitHub repository can be accessed here: github.com/BioMedIA-MBZUAI/MMRINet.

</details>


### [87] [Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System](https://arxiv.org/abs/2511.12196)
*Aditi Bhalla,Christian Hellert,Enkelejda Kasneci*

Main category: cs.CV

TL;DR: 提出了一种两阶段的跨视角、跨模态无监督域适应框架，用于实时驾驶员监控，显著提升了在不同视角和模态变化下的驾驶员行为识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常孤立地处理跨视角泛化或无监督域适应问题，难以应对真实场景中摄像头视角和传感器模态变化带来的挑战，限制了模型的鲁棒性和可扩展性。

Method: 第一阶段利用对比学习在单模态内学习视角不变且动作可区分的特征；第二阶段通过信息瓶颈损失实现无需目标域标签的跨模态域适应。

Result: 在Drive&Act数据集上，使用Video Swin和MViT等视频Transformer模型，相比有监督对比学习的跨视图方法，Top-1准确率提升近50%；相比仅做无监督域适应的方法，性能最高提升5%。

Conclusion: 所提出的联合框架能有效应对跨视角和跨模态的域变化，在无标签新模态下仍保持优异性能，推动了深度学习在真实驾驶场景中的鲁棒部署。

Abstract: Driver distraction remains a leading cause of road traffic accidents, contributing to thousands of fatalities annually across the globe. While deep learning-based driver activity recognition methods have shown promise in detecting such distractions, their effectiveness in real-world deployments is hindered by two critical challenges: variations in camera viewpoints (cross-view) and domain shifts such as change in sensor modality or environment. Existing methods typically address either cross-view generalization or unsupervised domain adaptation in isolation, leaving a gap in the robust and scalable deployment of models across diverse vehicle configurations. In this work, we propose a novel two-phase cross-view, cross-modal unsupervised domain adaptation framework that addresses these challenges jointly on real-time driver monitoring data. In the first phase, we learn view-invariant and action-discriminative features within a single modality using contrastive learning on multi-view data. In the second phase, we perform domain adaptation to a new modality using information bottleneck loss without requiring any labeled data from the new domain. We evaluate our approach using state-of-the art video transformers (Video Swin, MViT) and multi modal driver activity dataset called Drive&Act, demonstrating that our joint framework improves top-1 accuracy on RGB video data by almost 50% compared to a supervised contrastive learning-based cross-view method, and outperforms unsupervised domain adaptation-only methods by up to 5%, using the same video transformer backbone.

</details>


### [88] [Bridging Granularity Gaps: Hierarchical Semantic Learning for Cross-domain Few-shot Segmentation](https://arxiv.org/abs/2511.12200)
*Sujun Sun,Haowen Gu,Cheng Xie,Yanxu Ren,Mingwu Ren,Haofeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种用于跨域少样本分割（CD-FSS）的分层语义学习（HSL）框架，通过解决风格差异和分割粒度差异问题，提升了模型对目标域新类别的语义判别能力。


<details>
  <summary>Details</summary>
Motivation: 现有CD-FSS方法主要关注源域与目标域之间的风格差异，忽略了分割粒度上的差距，导致对目标域新类别的语义区分能力不足。

Method: 提出了包含双风格随机化（DSR）、分层语义挖掘（HSM）和原型置信度调制阈值（PCMT）三个模块的HSL框架：DSR通过前景和全局风格随机化模拟目标域数据；HSM利用多尺度超像素引导模型在不同粒度下挖掘类内一致性和类间差异性；PCMT缓解前景与背景高度相似时的分割模糊问题。

Result: 在四个主流目标域数据集上进行了广泛实验，结果表明所提方法在性能上达到了当前最先进的水平。

Conclusion: HSL框架有效解决了CD-FSS中风格和粒度差异带来的挑战，显著提升了模型在跨域少样本条件下的语义分割能力。

Abstract: Cross-domain Few-shot Segmentation (CD-FSS) aims to segment novel classes from target domains that are not involved in training and have significantly different data distributions from the source domain, using only a few annotated samples, and recent years have witnessed significant progress on this task. However, existing CD-FSS methods primarily focus on style gaps between source and target domains while ignoring segmentation granularity gaps, resulting in insufficient semantic discriminability for novel classes in target domains. Therefore, we propose a Hierarchical Semantic Learning (HSL) framework to tackle this problem. Specifically, we introduce a Dual Style Randomization (DSR) module and a Hierarchical Semantic Mining (HSM) module to learn hierarchical semantic features, thereby enhancing the model's ability to recognize semantics at varying granularities. DSR simulates target domain data with diverse foreground-background style differences and overall style variations through foreground and global style randomization respectively, while HSM leverages multi-scale superpixels to guide the model to mine intra-class consistency and inter-class distinction at different granularities. Additionally, we also propose a Prototype Confidence-modulated Thresholding (PCMT) module to mitigate segmentation ambiguity when foreground and background are excessively similar. Extensive experiments are conducted on four popular target domain datasets, and the results demonstrate that our method achieves state-of-the-art performance.

</details>


### [89] [OmniSparse: Training-Aware Fine-Grained Sparse Attention for Long-Video MLLMs](https://arxiv.org/abs/2511.12201)
*Feng Chen,Yefei He,Shaoxuan He,Yuanyu He,Jing Liu,Lequan Lin,Akide Liu,Zhaoyang Li,Jiyuan Zhang,Zhenbang Sun,Bohan Zhuang,Qi Wu*

Main category: cs.CV

TL;DR: 本文提出了OmniSparse，一种训练感知的细粒度稀疏注意力框架，用于长视频MLLM，在训练和推理中通过动态分配token预算实现高效处理。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法主要关注推理加速，但存在训练-推理差距，且缺乏跨查询、键值和注意力头等多维度的细粒度token选择能力，导致性能不佳和加速效果有限。

Method: OmniSparse包含三个自适应机制：(1) 通过惰性-活跃分类进行查询选择；(2) 基于最平坦头确定共享预算的KV选择；(3) 根据解码头模式选择性获取视觉KV缓存以减少冗余。

Result: 实验表明，OmniSparse在保持全注意力性能的同时，预填充阶段最高实现2.7倍加速，解码阶段内存减少2.4倍。

Conclusion: OmniSparse有效弥合了训练与推理之间的差距，实现了跨多维度的细粒度稀疏化，显著提升了长视频MLLM的效率和性能。

Abstract: Existing sparse attention methods primarily target inference-time acceleration by selecting critical tokens under predefined sparsity patterns. However, they often fail to bridge the training-inference gap and lack the capacity for fine-grained token selection across multiple dimensions such as queries, key-values (KV), and heads, leading to suboptimal performance and limited acceleration gains. In this paper, we introduce OmniSparse, a training-aware fine-grained sparse attention framework for long-video MLLMs, which operates in both training and inference with dynamic token budget allocation. Specifically, OmniSparse contains three adaptive and complementary mechanisms: (1) query selection via lazy-active classification, retaining active queries that capture broad semantic similarity while discarding most lazy ones that focus on limited local context and exhibit high functional redundancy; (2) KV selection with head-level dynamic budget allocation, where a shared budget is determined based on the flattest head and applied uniformly across all heads to ensure attention recall; and (3) KV cache slimming to reduce head-level redundancy by selectively fetching visual KV cache according to the head-level decoding query pattern. Experimental results show that OmniSparse matches the performance of full attention while achieving up to 2.7x speedup during prefill and 2.4x memory reduction during decoding.

</details>


### [90] [LSS3D: Learnable Spatial Shifting for Consistent and High-Quality 3D Generation from Single-Image](https://arxiv.org/abs/2511.12202)
*Zhuojiang Cai,Yiheng Zhang,Meitong Guo,Mingdao Wang,Yuwang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种高质量的图像到3D生成方法LSS3D，通过可学习的空间偏移来解决多视角扩散模型中的形状和纹理错位问题，尤其提升了非正面视角输入下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图扩散3D生成方法存在视图间形状和纹理对齐不佳、对非正面视角鲁棒性差的问题，影响3D重建质量。

Method: 提出LSS3D方法，为每个视图引入可学习的空间偏移参数，并以重建网格为指导将其调整至空间一致的目标；同时将输入视角作为优化约束，增强对非正面视角（尤其是高仰角）的鲁棒性。

Result: 在几何和纹理评估指标上均取得领先结果，支持更灵活的输入视角，且定性和定量实验表明其在多视角一致性和3D重建质量方面优于现有方法。

Conclusion: LSS3D有效缓解了多视角生成中的不一致性问题，显著提升了3D生成的几何完整性与纹理清晰度，尤其在非正面视角下表现出更强的鲁棒性。

Abstract: Recently, multi-view diffusion-based 3D generation methods have gained significant attention. However, these methods often suffer from shape and texture misalignment across generated multi-view images, leading to low-quality 3D generation results, such as incomplete geometric details and textural ghosting. Some methods are mainly optimized for the frontal perspective and exhibit poor robustness to oblique perspective inputs. In this paper, to tackle the above challenges, we propose a high-quality image-to-3D approach, named LSS3D, with learnable spatial shifting to explicitly and effectively handle the multiview inconsistencies and non-frontal input view. Specifically, we assign learnable spatial shifting parameters to each view, and adjust each view towards a spatially consistent target, guided by the reconstructed mesh, resulting in high-quality 3D generation with more complete geometric details and clean textures. Besides, we include the input view as an extra constraint for the optimization, further enhancing robustness to non-frontal input angles, especially for elevated viewpoint inputs. We also provide a comprehensive quantitative evaluation pipeline that can contribute to the community in performance comparisons. Extensive experiments demonstrate that our method consistently achieves leading results in both geometric and texture evaluation metrics across more flexible input viewpoints.

</details>


### [91] [GeoMVD: Geometry-Enhanced Multi-View Generation Model Based on Geometric Information Extraction](https://arxiv.org/abs/2511.12204)
*Jiaqi Wu,Yaosen Chen,Shuyuan Zhu*

Main category: cs.CV

TL;DR: 提出了一种几何引导的多视角扩散模型（Geometry-guided Multi-View Diffusion Model），通过提取深度图、法线图和前景分割掩码等几何信息，构建共享几何结构，并引入解耦的几何增强注意力机制和动态几何强度调整策略，实现跨视角一致且细节丰富的多视角图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于单图扩展的多视角图像生成方法在跨视角一致性与高分辨率生成方面存在计算挑战，难以兼顾细节保持与结构一致性。

Method: 设计多视角几何信息提取模块，融合深度图、法线图和前景分割掩码构建共享几何结构；提出解耦的几何增强注意力机制以强化关键几何特征的关注；采用自适应学习策略和迭代优化过程提升视图间空间关系建模能力；引入动态几何信息强度调整机制以平衡生成质量与自然性。

Result: 所提方法在多视角图像生成任务中实现了更好的跨视角一致性与更高的图像细节保真度，支持高分辨率生成，并在视觉质量和结构准确性上优于现有方法。

Conclusion: 几何引导的扩散模型能有效提升多视角图像生成的质量，在保持几何一致性的同时增强细节恢复，为3D重建、虚拟现实等应用提供了更可靠的生成方案。

Abstract: Multi-view image generation holds significant application value in computer vision, particularly in domains like 3D reconstruction, virtual reality, and augmented reality. Most existing methods, which rely on extending single images, face notable computational challenges in maintaining cross-view consistency and generating high-resolution outputs. To address these issues, we propose the Geometry-guided Multi-View Diffusion Model, which incorporates mechanisms for extracting multi-view geometric information and adjusting the intensity of geometric features to generate images that are both consistent across views and rich in detail. Specifically, we design a multi-view geometry information extraction module that leverages depth maps, normal maps, and foreground segmentation masks to construct a shared geometric structure, ensuring shape and structural consistency across different views. To enhance consistency and detail restoration during generation, we develop a decoupled geometry-enhanced attention mechanism that strengthens feature focus on key geometric details, thereby improving overall image quality and detail preservation. Furthermore, we apply an adaptive learning strategy that fine-tunes the model to better capture spatial relationships and visual coherence between the generated views, ensuring realistic results. Our model also incorporates an iterative refinement process that progressively improves the output quality through multiple stages of image generation. Finally, a dynamic geometry information intensity adjustment mechanism is proposed to adaptively regulate the influence of geometric data, optimizing overall quality while ensuring the naturalness of generated images. More details can be found on the project page: https://github.com/SobeyMIL/GeoMVD.com.

</details>


### [92] [A Novel AI-Driven System for Real-Time Detection of Mirror Absence, Helmet Non-Compliance, and License Plates Using YOLOv8 and OCR](https://arxiv.org/abs/2511.12206)
*Nishant Vasantkumar Hegde,Aditi Agarwal,Minal Moharir*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI的交通违规自动检测系统，利用YOLOv8和EasyOCR实现头盔佩戴、后视镜缺失及车牌识别，具有高精度和实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 传统交通执法依赖人工，资源消耗大且效率低，难以持续有效执行安全法规。

Method: 采用YOLOv8进行物体检测，识别未戴头盔和缺少后视镜的摩托车；结合EasyOCR提取车牌信息，并使用自建增强数据集训练模型，通过Streamlit构建实时监控界面。

Result: 系统在测试中达到0.9147的精确率、0.886的召回率，mAP@50为0.843，mAP@50-95为0.503，表现出优异的检测性能。

Conclusion: 该系统可有效实现交通违规行为的自动化检测，具备实际部署潜力，有助于提升道路安全管理水平。

Abstract: Road safety is a critical global concern, with manual enforcement of helmet laws and vehicle safety standards (e.g., rear-view mirror presence) being resource-intensive and inconsistent. This paper presents an AI-powered system to automate traffic violation detection, significantly enhancing enforcement efficiency and road safety. The system leverages YOLOv8 for robust object detection and EasyOCR for license plate recognition. Trained on a custom dataset of annotated images (augmented for diversity), it identifies helmet non-compliance, the absence of rear-view mirrors on motorcycles, an innovative contribution to automated checks, and extracts vehicle registration numbers. A Streamlit-based interface facilitates real-time monitoring and violation logging. Advanced image preprocessing enhances license plate recognition, particularly under challenging conditions. Based on evaluation results, the model achieves an overall precision of 0.9147, a recall of 0.886, and a mean Average Precision (mAP@50) of 0.843. The mAP@50 95 of 0.503 further indicates strong detection capability under stricter IoU thresholds. This work demonstrates a practical and effective solution for automated traffic rule enforcement, with considerations for real-world deployment discussed.

</details>


### [93] [Mixture of States: Routing Token-Level Dynamics for Multimodal Generation](https://arxiv.org/abs/2511.12207)
*Haozhe Liu,Ding Liu,Mingchen Zhuge,Zijian Zhou,Tian Xie,Sen He,Yukang Yang,Shuming Liu,Yuren Cong,Jiadong Guo,Hongyu Xu,Ke Xu,Kam-Woh Ng,Juan C. Pérez,Juan-Manuel~Pérez-Rúa,Tao Xiang,Wei Liu,Shikun Liu,Jürgen Schmidhuber*

Main category: cs.CV

TL;DR: 提出了一种名为MoS（Mixture of States）的新型多模态扩散模型融合范式，通过可学习的token级路由器实现模态间的动态交互，在文本到图像生成和编辑任务中达到最先进性能，且参数效率显著优于现有大模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态扩散模型在融合不同模态时缺乏灵活、细粒度的交互机制，难以有效对齐语义信息并保持计算效率。

Method: 设计了一个可学习的token级路由器，根据去噪的时间步和输入动态选择前k个隐藏状态进行模态融合，采用ε-贪婪策略训练，实现稀疏、高效的特征选择，仅引入极少的额外参数和计算开销。

Result: 在文本到图像生成（MoS-Image）和图像编辑（MoS-Editing）任务上达到最先进的性能；使用3B到5B参数的模型表现媲美甚至超越高达4倍规模的模型。

Conclusion: MoS是一种灵活且计算高效的多模态扩散模型融合范式，能够在极低的参数与计算成本下实现高性能，为大规模多模态建模提供了新方向。

Abstract: We introduce MoS (Mixture of States), a novel fusion paradigm for multimodal diffusion models that merges modalities using flexible, state-based interactions. The core of MoS is a learnable, token-wise router that creates denoising timestep- and input-dependent interactions between modalities' hidden states, precisely aligning token-level features with the diffusion trajectory. This router sparsely selects the top-$k$ hidden states and is trained with an $ε$-greedy strategy, efficiently selecting contextual features with minimal learnable parameters and negligible computational overhead. We validate our design with text-to-image generation (MoS-Image) and editing (MoS-Editing), which achieve state-of-the-art results. With only 3B to 5B parameters, our models match or surpass counterparts up to $4\times$ larger. These findings establish MoS as a flexible and compute-efficient paradigm for scaling multimodal diffusion models.

</details>


### [94] [FaNe: Towards Fine-Grained Cross-Modal Contrast with False-Negative Reduction and Text-Conditioned Sparse Attention](https://arxiv.org/abs/2511.12215)
*Peng Zhang,Zhihui Lai,Wenting Chen,Xu Wu,Heng Kong*

Main category: cs.CV

TL;DR: 提出一种名为FaNe的语义增强型医学视觉-语言预训练框架，通过语义感知的正样本挖掘、文本条件稀疏注意力池化模块和难负样本感知的对比损失，有效缓解了语义相似文本导致的假阴性问题，并提升了细粒度跨模态对齐能力。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉-语言预训练方法受限于语义相似文本引发的假阴性问题以及细粒度跨模态对齐不足，限制了模型性能。

Method: 1）基于文本相似性的自适应归一化正样本挖掘策略以缓解假阴性；2）文本条件稀疏注意力池化模块实现细粒度图像-文本对齐；3）设计难负样本感知的对比损失函数，自适应重加权语义相似的负样本。

Result: 在五个下游医学图像基准任务（图像分类、目标检测、语义分割）上均取得最先进的性能。

Conclusion: FaNe框架有效解决了医学VLP中的假阴性与跨模态对齐问题，显著提升了多种医学图像理解任务的性能。

Abstract: Medical vision-language pre-training (VLP) offers significant potential for advancing medical image understanding by leveraging paired image-report data. However, existing methods are limited by Fa}lse Negatives (FaNe) induced by semantically similar texts and insufficient fine-grained cross-modal alignment. To address these limitations, we propose FaNe, a semantic-enhanced VLP framework. To mitigate false negatives, we introduce a semantic-aware positive pair mining strategy based on text-text similarity with adaptive normalization. Furthermore, we design a text-conditioned sparse attention pooling module to enable fine-grained image-text alignment through localized visual representations guided by textual cues. To strengthen intra-modal discrimination, we develop a hard-negative aware contrastive loss that adaptively reweights semantically similar negatives. Extensive experiments on five downstream medical imaging benchmarks demonstrate that FaNe achieves state-of-the-art performance across image classification, object detection, and semantic segmentation, validating the effectiveness of our framework.

</details>


### [95] [Suppressing VLM Hallucinations with Spectral Representation Filtering](https://arxiv.org/abs/2511.12220)
*Ameen Ali,Tamim Zoabi,Lior Wolf*

Main category: cs.CV

TL;DR: 提出了一种名为Spectral Representation Filtering (SRF)的轻量级、无需训练的方法，通过分析和校正模型表征的协方差结构来抑制视觉-语言模型中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型由于过度依赖语言先验和跨模态对齐不准确，常产生描述图像中不存在对象、属性或关系的幻觉，需要一种有效且无需重新训练的解决方案。

Method: 通过对真实和幻觉性描述对应的特征差异协方差矩阵进行特征分解，识别出低秩的幻觉模式，并在深层vLLM的前馈投影权重中使用软谱滤波器衰减这些模式，从而修正模型表示。

Result: 在LLaVA-1.5、MiniGPT-4和mPLUG-Owl2等多类VLM上，SRF在MSCOCO、POPE-VQA等多个基准上显著降低了幻觉率，同时保持了生成文本的质量，且无推理开销。

Conclusion: SRF是一种有效的后处理方法，能够在不修改模型结构、无需再训练的情况下提升VLM的忠实度，为抑制幻觉提供了新思路。

Abstract: Vision-language models (VLMs) frequently produce hallucinations in the form of descriptions of objects, attributes, or relations that do not exist in the image due to over-reliance on language priors and imprecise cross-modal grounding. We introduce Spectral Representation Filtering (SRF), a lightweight, training-free method to suppress such hallucinations by analyzing and correcting the covariance structure of the model's representations. SRF identifies low-rank hallucination modes through eigendecomposition of the covariance of the differences between features collected for truthful and hallucinatory captions, revealing structured biases in the feature space. A soft spectral filter then attenuates these modes in the feed-forward projection weights of deeper vLLM layers, equalizing feature variance while preserving semantic fidelity. Unlike decoding or retraining-based approaches, SRF operates entirely post-hoc, incurs zero inference overhead, and requires no architectural modifications. Across three families of VLMs (LLaVA-1.5, MiniGPT-4, and mPLUG-Owl2), SRF consistently reduces hallucination rates on MSCOCO, POPE-VQA, and other visual tasks benchmarks, achieving state-of-the-art faithfulness without degrading caption quality.

</details>


### [96] [Model Inversion Attack Against Deep Hashing](https://arxiv.org/abs/2511.12233)
*Dongdong Zhao,Qiben Xu,Ranxin Fang,Baogang Song*

Main category: cs.CV

TL;DR: 提出首个基于扩散的模型反演框架DHMI，用于揭示深度哈希模型中的隐私风险，能够在黑盒场景下高效重构高质量、高分辨率的训练数据图像。


<details>
  <summary>Details</summary>
Motivation: 深度哈希虽提升检索效率，但存在可被利用重构原始训练数据的隐私风险，而现有模型反演攻击无法适应深度哈希的离散汉明空间，缺乏针对性研究。

Method: 提出DHMI框架：通过聚类辅助数据集生成语义哈希中心作为代理锚点，设计代理引导的去噪优化方法，结合分类一致性与哈希接近性的新攻击度量，动态筛选候选样本，并利用代理模型簇优化生成高保真、语义一致的图像。

Result: 在多个数据集上验证了DHMI的有效性，能在无真实训练哈希码的黑盒条件下成功重构高质量图像，性能优于现有最先进方法。

Conclusion: DHMI揭示了深度哈希系统中严重的隐私隐患，证明即使在极端受限的黑盒环境下，模型反演攻击仍可行，强调需加强深度哈希模型的安全设计。

Abstract: Deep hashing improves retrieval efficiency through compact binary codes, yet it introduces severe and often overlooked privacy risks. The ability to reconstruct original training data from hash codes could lead to serious threats such as biometric forgery and privacy breaches. However, model inversion attacks specifically targeting deep hashing models remain unexplored, leaving their security implications unexamined. This research gap stems from the inaccessibility of genuine training hash codes and the highly discrete Hamming space, which prevents existing methods from adapting to deep hashing. To address these challenges, we propose DHMI, the first diffusion-based model inversion framework designed for deep hashing. DHMI first clusters an auxiliary dataset to derive semantic hash centers as surrogate anchors. It then introduces a surrogate-guided denoising optimization method that leverages a novel attack metric (fusing classification consistency and hash proximity) to dynamically select candidate samples. A cluster of surrogate models guides the refinement of these candidates, ensuring the generation of high-fidelity and semantically consistent images. Experiments on multiple datasets demonstrate that DHMI successfully reconstructs high-resolution, high-quality images even under the most challenging black-box setting, where no training hash codes are available. Our method outperforms the existing state-of-the-art model inversion attacks in black-box scenarios, confirming both its practical efficacy and the critical privacy risks inherent in deep hashing systems.

</details>


### [97] [MiniGPT-Pancreas: Multimodal Large Language Model for Pancreas Cancer Classification and Detection](https://arxiv.org/abs/2412.15925)
*Andrea Moglia,Elia Clement Nastasio,Luca Mainardi,Pietro Cerveri*

Main category: cs.CV

TL;DR: MiniGPT-Pancreas是一种多模态大语言模型，用于辅助临床医生进行胰腺癌诊断，结合CT图像与文本信息实现胰腺检测、肿瘤分类与检测。


<details>
  <summary>Details</summary>
Motivation: 胰腺的影像学检查因器官小、边界模糊及患者间形态和位置差异大而具有挑战性，需要更智能的辅助诊断工具。

Method: 基于通用多模态大模型MiniGPT-v2，采用级联式微调方法，结合来自NIH、MSD和AbdomenCT-1k数据集的CT图像与多模态提示（问题+图像）进行胰腺检测、肿瘤分类与检测任务。

Result: 在NIH和MSD数据集上胰腺检测IoU分别为0.595和0.550；MSD上肿瘤分类准确率0.876，精确率0.874，召回率0.878；AbdomenCT-1k上多器官检测中胰腺IoU为0.497；MSD上肿瘤检测IoU为0.168。

Conclusion: MiniGPT-Pancreas在胰腺癌图像分类任务中表现良好，具备临床辅助潜力，但肿瘤检测性能仍需提升。

Abstract: Problem: Pancreas radiological imaging is challenging due to the small size, blurred boundaries, and variability of shape and position of the organ among patients. Goal: In this work we present MiniGPT-Pancreas, a Multimodal Large Language Model (MLLM), as an interactive chatbot to support clinicians in pancreas cancer diagnosis by integrating visual and textual information. Methods: MiniGPT-v2, a general-purpose MLLM, was fine-tuned in a cascaded way for pancreas detection, tumor classification, and tumor detection with multimodal prompts combining questions and computed tomography scans from the National Institute of Health (NIH), and Medical Segmentation Decathlon (MSD) datasets. The AbdomenCT-1k dataset was used to detect the liver, spleen, kidney, and pancreas. Results: MiniGPT-Pancreas achieved an Intersection over Union (IoU) of 0.595 and 0.550 for the detection of pancreas on NIH and MSD datasets, respectively. For the pancreas cancer classification task on the MSD dataset, accuracy, precision, and recall were 0.876, 0.874, and 0.878, respectively. When evaluating MiniGPT-Pancreas on the AbdomenCT-1k dataset for multi-organ detection, the IoU was 0.8399 for the liver, 0.722 for the kidney, 0.705 for the spleen, and 0.497 for the pancreas. For the pancreas tumor detection task, the IoU score was 0.168 on the MSD dataset. Conclusions: MiniGPT-Pancreas represents a promising solution to support clinicians in the classification of pancreas images with pancreas tumors. Future research is needed to improve the score on the detection task, especially for pancreas tumors.

</details>


### [98] [Fusionista2.0: Efficiency Retrieval System for Large-Scale Datasets](https://arxiv.org/abs/2511.12255)
*Huy M. Le,Dat Tien Nguyen,Phuc Binh Nguyen,Gia-Bao Le-Tran,Phu Truong Thien,Cuong Dinh,Minh Nguyen,Nga Nguyen,Thuy T. N. Nguyen,Huy Gia Ngo,Tan Nhat Nguyen,Binh T. Nguyen,Monojit Choudhury*

Main category: cs.CV

TL;DR: Fusionista2.0 是一个为快速和用户友好而优化的视频检索系统，在视频浏览器对决（VBS）中实现了检索速度提升最多75%，同时提高了准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 在严格的时间限制下提供准确的视频检索结果，满足VBS的挑战需求。

Method: 重构核心模块以提高效率：使用ffmpeg进行关键帧提取，Vintern-1B-v3.5用于多语言OCR，faster-whisper实现实时语音识别，并采用轻量级视觉语言模型进行问答；同时重新设计了用户界面以提升可用性和工作效率。

Result: 检索时间最多减少75%，准确性和用户满意度均有所提升。

Conclusion: Fusionista2.0 是一个高效、易用且具有竞争力的大规模视频搜索系统。

Abstract: The Video Browser Showdown (VBS) challenges systems to deliver accurate results under strict time constraints. To meet this demand, we present Fusionista2.0, a streamlined video retrieval system optimized for speed and usability. All core modules were re-engineered for efficiency: preprocessing now relies on ffmpeg for fast keyframe extraction, optical character recognition uses Vintern-1B-v3.5 for robust multilingual text recognition, and automatic speech recognition employs faster-whisper for real-time transcription. For question answering, lightweight vision-language models provide quick responses without the heavy cost of large models. Beyond these technical upgrades, Fusionista2.0 introduces a redesigned user interface with improved responsiveness, accessibility, and workflow efficiency, enabling even non-expert users to retrieve relevant content rapidly. Evaluations demonstrate that retrieval time was reduced by up to 75% while accuracy and user satisfaction both increased, confirming Fusionista2.0 as a competitive and user-friendly system for large-scale video search.

</details>


### [99] [Prompt-Conditioned FiLM and Multi-Scale Fusion on MedSigLIP for Low-Dose CT Quality Assessment](https://arxiv.org/abs/2511.12256)
*Tolga Demiroglu,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: cs.CV

TL;DR: 提出一种基于MedSigLIP的提示条件框架，通过FiLM和多尺度池化注入文本先验，用于低剂量CT图像质量评估，在LDCTIQA2023挑战赛中以少量训练数据取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 为了提升低剂量CT图像质量评估的准确性和数据效率，利用文本提示引入临床意图的先验知识，增强模型对关键特征的感知能力。

Method: 构建一个基于MedSigLIP的提示条件框架，使用Feature-wise Linear Modulation (FiLM)将文本提示注入图像patch-token特征，并结合全局、局部和纹理感知的多尺度池化，通过轻量级MLP融合多个回归头，采用成对排序损失进行训练。

Result: 在LDCTIQA2023挑战赛数据集上，使用1000张训练图像取得了PLCC=0.9575、SROCC=0.9561、KROCC=0.8301的结果，优于已发表的最优方法。

Conclusion: 该提示驱动的框架能有效利用文本先验实现数据高效学习，在低剂量CT质量评估中表现出优越性能，具备良好的临床适应性和推广潜力。

Abstract: We propose a prompt-conditioned framework built on MedSigLIP that injects textual priors via Feature-wise Linear Modulation (FiLM) and multi-scale pooling. Text prompts condition patch-token features on clinical intent, enabling data-efficient learning and rapid adaptation. The architecture combines global, local, and texture-aware pooling through separate regression heads fused by a lightweight MLP, trained with pairwise ranking loss. Evaluated on the LDCTIQA2023 (a public LDCT quality assessment challenge) with 1,000 training images, we achieve PLCC = 0.9575, SROCC = 0.9561, and KROCC = 0.8301, surpassing the top-ranked published challenge submissions and demonstrating the effectiveness of our prompt-guided approach.

</details>


### [100] [A Disease-Aware Dual-Stage Framework for Chest X-ray Report Generation](https://arxiv.org/abs/2511.12259)
*Puzhen Wu,Hexin Dong,Yi Lin,Yihao Ding,Yifan Peng*

Main category: cs.CV

TL;DR: 提出了一种双阶段疾病感知框架用于胸部X光报告生成，通过疾病感知语义标记和多模态对齐机制显著提升临床准确性和语言质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉表征的疾病感知和图文对齐方面不足，导致忽略关键病理特征且生成报告不准确。

Method: 第一阶段通过交叉注意力和多标签分类学习疾病感知语义标记，并利用对比学习对齐图文表示；第二阶段引入疾病-视觉注意力融合模块和双模态相似性检索机制以增强特征融合与上下文引导。

Result: 在CheXpert Plus、IU X-ray和MIMIC-CXR数据集上实验表明，该方法在报告生成的临床准确性与语言质量方面均达到最先进的性能。

Conclusion: 所提出的双阶段疾病感知框架有效提升了胸部X光报告生成的准确性与可解释性，具有较强的临床应用潜力。

Abstract: Radiology report generation from chest X-rays is an important task in artificial intelligence with the potential to greatly reduce radiologists' workload and shorten patient wait times. Despite recent advances, existing approaches often lack sufficient disease-awareness in visual representations and adequate vision-language alignment to meet the specialized requirements of medical image analysis. As a result, these models usually overlook critical pathological features on chest X-rays and struggle to generate clinically accurate reports. To address these limitations, we propose a novel dual-stage disease-aware framework for chest X-ray report generation. In Stage~1, our model learns Disease-Aware Semantic Tokens (DASTs) corresponding to specific pathology categories through cross-attention mechanisms and multi-label classification, while simultaneously aligning vision and language representations via contrastive learning. In Stage~2, we introduce a Disease-Visual Attention Fusion (DVAF) module to integrate disease-aware representations with visual features, along with a Dual-Modal Similarity Retrieval (DMSR) mechanism that combines visual and disease-specific similarities to retrieve relevant exemplars, providing contextual guidance during report generation. Extensive experiments on benchmark datasets (i.e., CheXpert Plus, IU X-ray, and MIMIC-CXR) demonstrate that our disease-aware framework achieves state-of-the-art performance in chest X-ray report generation, with significant improvements in clinical accuracy and linguistic quality.

</details>


### [101] [CrossVid: A Comprehensive Benchmark for Evaluating Cross-Video Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2511.12263)
*Jingyao Li,Jingyun Wang,Molin Tan,Haochen Wang,Cilin Yan,Likun Shi,Jiayin Cai,Xiaolong Jiang,Yao Hu*

Main category: cs.CV

TL;DR: CrossVid是首个全面评估多模态大语言模型在跨视频情境下时空推理能力的基准，包含5331个视频和9015个问答对，涵盖多种任务类型，实验表明现有模型在此任务上表现有限，主要难点在于整合和比较跨视频信息。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准多关注单视频分析，缺乏对多视频同时推理能力的评估，且现有跨视角视频基准任务有限，无法充分反映真实场景中的复杂跨视频推理需求。

Method: 提出CrossVid基准，包含四个高层维度和十个具体任务，构建5,331个视频和9,015个挑战性问答对，覆盖单选、多选和开放性问题，并在多个开源与闭源MLLM上进行广泛实验。

Result: Gemini-2.5-Pro在CrossVid上表现最佳，平均准确率为50.4%，但多数现有MLLM在跨视频推理任务上表现不佳，主要问题在于难以整合和比较分布在多个视频中的证据。

Conclusion: CrossVid能有效揭示当前MLLM在跨视频推理上的局限，为未来提升模型跨视频理解与推理能力提供了重要方向和评估工具。

Abstract: Cross-Video Reasoning (CVR) presents a significant challenge in video understanding, which requires simultaneous understanding of multiple videos to aggregate and compare information across groups of videos. Most existing video understanding benchmarks focus on single-video analysis, failing to assess the ability of multimodal large language models (MLLMs) to simultaneously reason over various videos. Recent benchmarks evaluate MLLMs' capabilities on multi-view videos that capture different perspectives of the same scene. However, their limited tasks hinder a thorough assessment of MLLMs in diverse real-world CVR scenarios. To this end, we introduce CrossVid, the first benchmark designed to comprehensively evaluate MLLMs' spatial-temporal reasoning ability in cross-video contexts. Firstly, CrossVid encompasses a wide spectrum of hierarchical tasks, comprising four high-level dimensions and ten specific tasks, thereby closely reflecting the complex and varied nature of real-world video understanding. Secondly, CrossVid provides 5,331 videos, along with 9,015 challenging question-answering pairs, spanning single-choice, multiple-choice, and open-ended question formats. Through extensive experiments on various open-source and closed-source MLLMs, we observe that Gemini-2.5-Pro performs best on CrossVid, achieving an average accuracy of 50.4%. Notably, our in-depth case study demonstrates that most current MLLMs struggle with CVR tasks, primarily due to their inability to integrate or compare evidence distributed across multiple videos for reasoning. These insights highlight the potential of CrossVid to guide future advancements in enhancing MLLMs' CVR capabilities.

</details>


### [102] [ZoomEarth: Active Perception for Ultra-High-Resolution Geospatial Vision-Language Tasks](https://arxiv.org/abs/2511.12267)
*Ruixun Liu,Bowen Fu,Jiayi Song,Kaiyu Li,Wanchen Li,Lanxuan Xue,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.CV

TL;DR: 本文提出了一种用于超高分辨率遥感图像处理的主动感知新范式，构建了大规模基准数据集LRS-GRO，并提出了自适应裁剪-缩放框架ZoomEarth，结合区域引导奖励和强化学习策略，在多个任务中实现先进性能并具备良好扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有动态分辨率和token剪枝方法受限于被动感知范式，在处理更精细视觉输入时冗余增加，难以高效利用超高分辨率遥感图像中的丰富细粒度信息。

Method: 构建了涵盖全球、区域和对象层级17种问题类型的大型主动感知基准数据集LRS-GRO；提出ZoomEarth框架，采用自适应裁剪-缩放机制与区域引导奖励，通过监督微调（SFT）和组相对策略优化（GRPO）进行训练。

Result: ZoomEarth在LRS-GRO上达到最先进性能，并在三种公开UHR遥感基准上实现零样本迁移下的优异表现；可无缝集成至下游任务（如去云、去噪、分割、图像编辑），展现强通用性和可扩展性。

Conclusion: 主动感知范式有助于高效处理超高分辨率遥感图像，ZoomEarth结合区域引导机制和自适应采样策略，为遥感图像理解提供了高效、灵活且可扩展的新框架。

Abstract: Ultra-high-resolution (UHR) remote sensing (RS) images offer rich fine-grained information but also present challenges in effective processing. Existing dynamic resolution and token pruning methods are constrained by a passive perception paradigm, suffering from increased redundancy when obtaining finer visual inputs. In this work, we explore a new active perception paradigm that enables models to revisit information-rich regions. First, we present LRS-GRO, a large-scale benchmark dataset tailored for active perception in UHR RS processing, encompassing 17 question types across global, region, and object levels, annotated via a semi-automatic pipeline. Building on LRS-GRO, we propose ZoomEarth, an adaptive cropping-zooming framework with a novel Region-Guided reward that provides fine-grained guidance. Trained via supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), ZoomEarth achieves state-of-the-art performance on LRS-GRO and, in the zero-shot setting, on three public UHR remote sensing benchmarks. Furthermore, ZoomEarth can be seamlessly integrated with downstream models for tasks such as cloud removal, denoising, segmentation, and image editing through simple tool interfaces, demonstrating strong versatility and extensibility.

</details>


### [103] [TM-UNet: Token-Memory Enhanced Sequential Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.12270)
*Yaxuan Jiao,Qing Xu,Yuxiang Luo,Xiangjian He,Zhen Chen,Wenting Duan*

Main category: cs.CV

TL;DR: 提出了一种轻量级医学图像分割框架TM-UNet，通过多尺度令牌记忆机制实现高效全局推理。


<details>
  <summary>Details</summary>
Motivation: Transformer方法虽然性能优越，但计算成本高，限制了在临床中的应用。

Method: 引入多尺度令牌记忆（MSTM）模块，将2D空间特征转为令牌序列，并利用矩阵记忆单元选择性保留上下文信息，结合指数门控和并行池化操作进行分层学习。

Result: 在多个医学分割任务上优于现有最先进方法，且计算成本显著降低。

Conclusion: TM-UNet通过动态知识存储和线性复杂度的全局推理，实现了高效准确的医学图像分割。

Abstract: Medical image segmentation is essential for clinical diagnosis and treatment planning. Although transformer-based methods have achieved remarkable results, their high computational cost hinders clinical deployment. To address this issue, we propose TM-UNet, a novel lightweight framework that integrates token sequence modeling with an efficient memory mechanism for efficient medical segmentation. Specifically, we introduce a multi-scale token-memory (MSTM) block that transforms 2D spatial features into token sequences through strategic spatial scanning, leveraging matrix memory cells to selectively retain and propagate discriminative contextual information across tokens. This novel token-memory mechanism acts as a dynamic knowledge store that captures long-range dependencies with linear complexity, enabling efficient global reasoning without redundant computation. Our MSTM block further incorporates exponential gating to identify token effectiveness and multi-scale contextual extraction via parallel pooling operations, enabling hierarchical representation learning without computational overhead. Extensive experiments demonstrate that TM-UNet outperforms state-of-the-art methods across diverse medical segmentation tasks with substantially reduced computation cost. The code is available at https://github.com/xq141839/TM-UNet.

</details>


### [104] [D$^{3}$ToM: Decider-Guided Dynamic Token Merging for Accelerating Diffusion MLLMs](https://arxiv.org/abs/2511.12280)
*Shuochen Chang,Xiaofeng Zhang,Qingyang Liu,Li Niu*

Main category: cs.CV

TL;DR: 提出D$^{3}$ToM，一种基于决策令牌的动态视觉token合并方法，用于加速扩散式多模态大语言模型（Diffusion MLLMs）的推理过程，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: Diffusion MLLMs在生成质量上表现优异，但由于每步去噪都使用全双向自注意力机制，导致推理速度慢、计算复杂度高，尤其是在处理大量视觉token时变得不切实际。

Method: 引入D$^{3}$ToM，利用前一步生成的decider token构建视觉token的重要性图，动态决定哪些token保留、哪些通过相似性聚合进行合并；该模块可插入单个Transformer层中，逐步缩短后续层的视觉序列长度，并采用随去噪步骤变化的动态合并比例。

Result: 实验表明，D$^{3}$ToM在显著加速推理的同时，保持了与原始模型相当甚至更优的性能，尤其在相同计算预算下表现更好。

Conclusion: D$^{3}$ToM是一种即插即用、无需修改模型参数的高效推理加速方法，有效解决了Diffusion MLLMs中因长视觉序列带来的高计算开销问题，具有良好的实用性和扩展性。

Abstract: Diffusion-based multimodal large language models (Diffusion MLLMs) have recently demonstrated impressive non-autoregressive generative capabilities across vision-and-language tasks. However, Diffusion MLLMs exhibit substantially slower inference than autoregressive models: Each denoising step employs full bidirectional self-attention over the entire sequence, resulting in cubic decoding complexity that becomes computationally impractical with thousands of visual tokens. To address this challenge, we propose D$^{3}$ToM, a Decider-guided dynamic token merging method that dynamically merges redundant visual tokens at different denoising steps to accelerate inference in Diffusion MLLMs. At each denoising step, D$^{3}$ToM uses decider tokens-the tokens generated in the previous denoising step-to build an importance map over all visual tokens. Then it maintains a proportion of the most salient tokens and merges the remainder through similarity-based aggregation. This plug-and-play module integrates into a single transformer layer, physically shortening the visual token sequence for all subsequent layers without altering model parameters. Moreover, D$^{3}$ToM employs a merge ratio that dynamically varies with each denoising step, aligns with the native decoding process of Diffusion MLLMs, achieving superior performance under equivalent computational budgets. Extensive experiments show that D$^{3}$ToM accelerates inference while preserving competitive performance. The code is released at https://github.com/bcmi/D3ToM-Diffusion-MLLM.

</details>


### [105] [One target to align them all: LiDAR, RGB and event cameras extrinsic calibration for Autonomous Driving](https://arxiv.org/abs/2511.12291)
*Andrea Bertogalli,Giacomo Boracchi,Luca Magri*

Main category: cs.CV

TL;DR: 提出了一种新型多模态外参标定框架，用于同时估计事件相机、LiDAR和RGB相机之间的相对位姿，核心是专为三种模态设计的3D标定目标，实现一次性联合标定。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于成对分离标定，难以高效准确地完成多传感器系统（尤其是包含事件相机）的外参标定。

Method: 设计了一个包含平面、ChArUco格子和主动LED图案的3D标定目标，分别适配LiDAR、RGB相机和事件相机；基于该目标构建了联合标定流程，实现多模态传感器的一次性同步标定。

Result: 在自主驾驶传感器平台上采集的数据集上进行了广泛实验，验证了该方法在精度和鲁棒性方面的优越性。

Conclusion: 所提框架能有效实现事件相机、LiDAR和RGB相机的联合外参标定，适用于自动驾驶等对多传感器精确对齐要求高的场景。

Abstract: We present a novel multi-modal extrinsic calibration framework designed to simultaneously estimate the relative poses between event cameras, LiDARs, and RGB cameras, with particular focus on the challenging event camera calibration. Core of our approach is a novel 3D calibration target, specifically designed and constructed to be concurrently perceived by all three sensing modalities. The target encodes features in planes, ChArUco, and active LED patterns, each tailored to the unique characteristics of LiDARs, RGB cameras, and event cameras respectively. This unique design enables a one-shot, joint extrinsic calibration process, in contrast to existing approaches that typically rely on separate, pairwise calibrations. Our calibration pipeline is designed to accurately calibrate complex vision systems in the context of autonomous driving, where precise multi-sensor alignment is critical. We validate our approach through an extensive experimental evaluation on a custom built dataset, recorded with an advanced autonomous driving sensor setup, confirming the accuracy and robustness of our method.

</details>


### [106] [Rethinking Bias in Generative Data Augmentation for Medical AI: a Frequency Recalibration Method](https://arxiv.org/abs/2511.12301)
*Chi Liu,Jincheng Liu,Congcong Zhu,Minghao Wang,Sheng Shen,Jia Gu,Tianqing Zhu,Wanlei Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为频率重校准（FreRec）的方法，用于减少医学图像生成数据增强中的频域分布差异，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 生成数据增强在医学AI中广泛应用，但合成图像与真实图像之间的频率分布偏差常被低估，可能导致下游任务性能下降。

Method: 提出FreRec方法，包括统计高频替换（SHR）和重建高频映射（RHM），以对齐高频成分并提升图像质量。

Result: 在多种医学图像数据集（如脑MRI、胸部X光、眼底图像）上验证，FreRec显著提升了分类任务的性能。

Conclusion: FreRec是一种即插即用的后处理方法，兼容各类生成模型，可有效改善医学图像生成数据增强的效果。

Abstract: Developing Medical AI relies on large datasets and easily suffers from data scarcity. Generative data augmentation (GDA) using AI generative models offers a solution to synthesize realistic medical images. However, the bias in GDA is often underestimated in medical domains, with concerns about the risk of introducing detrimental features generated by AI and harming downstream tasks. This paper identifies the frequency misalignment between real and synthesized images as one of the key factors underlying unreliable GDA and proposes the Frequency Recalibration (FreRec) method to reduce the frequency distributional discrepancy and thus improve GDA. FreRec involves (1) Statistical High-frequency Replacement (SHR) to roughly align high-frequency components and (2) Reconstructive High-frequency Mapping (RHM) to enhance image quality and reconstruct high-frequency details. Extensive experiments were conducted in various medical datasets, including brain MRIs, chest X-rays, and fundus images. The results show that FreRec significantly improves downstream medical image classification performance compared to uncalibrated AI-synthesized samples. FreRec is a standalone post-processing step that is compatible with any generative model and can integrate seamlessly with common medical GDA pipelines.

</details>


### [107] [LiDAR-GS++:Improving LiDAR Gaussian Reconstruction via Diffusion Priors](https://arxiv.org/abs/2511.12304)
*Qifeng Chen,Jiarun Liu,Rengan Xie,Tao Tang,Sicong Du,Yiru Zhao,Yuchi Huo,Sheng Yang*

Main category: cs.CV

TL;DR: 提出LiDAR-GS++，一种结合扩散先验的激光雷达高斯点阵重建方法，用于在公共城市道路上实现实时、高保真的重模拟，在插值和外推视角下均达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯点阵（GS）的方法在单次扫描重建不完整时，外推新视角合成存在伪影问题，限制了其在真实场景中的应用。

Method: 引入可控的、以粗略外推渲染为条件的激光雷达生成模型，生成几何一致的额外扫描，并通过有效的蒸馏机制实现扩展重建，增强对欠拟合区域的覆盖。

Result: 在多个公开数据集上实验表明，LiDAR-GS++在插值和外推视角下均优于现有的GS和NeRF方法，实现了更高质量的重建和全局几何一致性。

Conclusion: LiDAR-GS++通过融合扩散先验有效提升了激光雷达重建的完整性和外推能力，为自动驾驶等场景下的实时高保真重模拟提供了新方案。

Abstract: Recent GS-based rendering has made significant progress for LiDAR, surpassing Neural Radiance Fields (NeRF) in both quality and speed. However, these methods exhibit artifacts in extrapolated novel view synthesis due to the incomplete reconstruction from single traversal scans. To address this limitation, we present LiDAR-GS++, a LiDAR Gaussian Splatting reconstruction method enhanced by diffusion priors for real-time and high-fidelity re-simulation on public urban roads. Specifically, we introduce a controllable LiDAR generation model conditioned on coarsely extrapolated rendering to produce extra geometry-consistent scans and employ an effective distillation mechanism for expansive reconstruction. By extending reconstruction to under-fitted regions, our approach ensures global geometric consistency for extrapolative novel views while preserving detailed scene surfaces captured by sensors. Experiments on multiple public datasets demonstrate that LiDAR-GS++ achieves state-of-the-art performance for both interpolated and extrapolated viewpoints, surpassing existing GS and NeRF-based methods.

</details>


### [108] [Learning Time in Static Classifiers](https://arxiv.org/abs/2511.12321)
*Xi Ding,Lei Wang,Piotr Koniusz,Yongsheng Gao*

Main category: cs.CV

TL;DR: 提出一种无需修改模型结构的时序推理框架，通过支持-示例-查询（SEQ）学习范式和软DTW损失提升分类器在静态与动态视觉任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视觉数据通常是随时间连续变化的，但传统分类器假设样本独立，难以捕捉这种时序动态。因此需要一种能增强标准分类器时序建模能力的方法。

Method: 提出支持-示例-查询（SEQ）学习范式，将训练数据构造成时序连贯的轨迹，并学习类别特定的时序原型；使用可微的软DTW损失对齐预测序列，结合多项目标函数促进语义一致性和时序平滑性，仅通过损失设计引入时序归纳偏置。

Result: 在细粒度和超细粒度图像分类任务中提升了性能，在视频异常检测中实现了精确且时序一致的预测，验证了方法在静态与动态任务中的有效性。

Conclusion: 该方法以简单、模块化且数据高效的方式桥接了静态与时序学习，仅需在预提取特征上使用标准分类器即可实现强时序推理能力。

Abstract: Real-world visual data rarely presents as isolated, static instances. Instead, it often evolves gradually over time through variations in pose, lighting, object state, or scene context. However, conventional classifiers are typically trained under the assumption of temporal independence, limiting their ability to capture such dynamics. We propose a simple yet effective framework that equips standard feedforward classifiers with temporal reasoning, all without modifying model architectures or introducing recurrent modules. At the heart of our approach is a novel Support-Exemplar-Query (SEQ) learning paradigm, which structures training data into temporally coherent trajectories. These trajectories enable the model to learn class-specific temporal prototypes and align prediction sequences via a differentiable soft-DTW loss. A multi-term objective further promotes semantic consistency and temporal smoothness. By interpreting input sequences as evolving feature trajectories, our method introduces a strong temporal inductive bias through loss design alone. This proves highly effective in both static and temporal tasks: it enhances performance on fine-grained and ultra-fine-grained image classification, and delivers precise, temporally consistent predictions in video anomaly detection. Despite its simplicity, our approach bridges static and temporal learning in a modular and data-efficient manner, requiring only a simple classifier on top of pre-extracted features.

</details>


### [109] [SpaceVLM: Sub-Space Modeling of Negation in Vision-Language Models](https://arxiv.org/abs/2511.12331)
*Sepehr Kazemi Ranjbar,Kumail Alhamoud,Marzyeh Ghassemi*

Main category: cs.CV

TL;DR: 提出一种无需训练的框架，通过在联合嵌入空间中将否定建模为子空间来提升视觉语言模型对否定的理解能力，在多个任务上平均提升约30%。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过微调处理否定问题会损害模型在肯定提示上的零样本性能，而视觉语言模型在处理否定时表现不佳。

Method: 基于VLM嵌入空间可划分为语义一致子空间的特性，将否定视为联合嵌入空间中的一个子空间；对于如'A但非N'的描述，构建围绕A和N嵌入的球形帽，通过评分接近A且远离N区域中心方向的图像来实现匹配。

Result: 在检索、多项选择题和文本到图像任务中，该方法在否定理解上平均比先前方法提升约30%，缩小了肯定与否定提示之间的差距，同时保持了零样本性能。

Conclusion: 所提训练-free框架有效提升了VLM对否定的理解，兼顾性能提升与零样本能力的保持，优于需微调的方法。

Abstract: Vision-Language Models (VLMs) struggle with negation. Given a prompt like "retrieve (or generate) a street scene without pedestrians," they often fail to respect the "not." Existing methods address this limitation by fine-tuning on large negation datasets, but such retraining often compromises the model's zero-shot performance on affirmative prompts. We show that the embedding space of VLMs, such as CLIP, can be divided into semantically consistent subspaces. Based on this property, we propose a training-free framework that models negation as a subspace in the joint embedding space rather than a single point (Figure 1). To find the matching image for a caption such as "A but not N," we construct two spherical caps around the embeddings of A and N, and we score images by the central direction of the region that is close to A and far from N. Across retrieval, MCQ, and text-to-image tasks, our method improves negation understanding by about 30% on average over prior methods. It closes the gap between affirmative and negated prompts while preserving the zero-shot performance that fine-tuned models fail to maintain. Code will be released upon publication.

</details>


### [110] [Ground Plane Projection for Improved Traffic Analytics at Intersections](https://arxiv.org/abs/2511.12342)
*Sajjad Pakdamansavoji,Kumar Vaibhav Jha,Baher Abdulhai,James H Elder*

Main category: cs.CV

TL;DR: 本文探讨了在交通监控中将基础设施摄像头检测到的车辆反投影到地面平面进行分析的优势，相较于传统的图像平面分析，反投影能提高轨迹分类和转向移动计数的准确性，尤其是在多摄像头弱融合的情况下表现更优。


<details>
  <summary>Details</summary>
Motivation: 为了提高交叉口车辆转向计数的准确性，以支持信号控制、交通管理和城市规划，研究需要克服传统基于图像平面分析的局限性。

Method: 通过将单个或多个基础设施摄像头检测到的车辆反投影到地面平面，在三维真实世界坐标中进行分析，并与图像平面方法对比；同时采用多摄像头检测结果的弱融合策略提升精度。

Result: 单摄像头系统中，反投影显著提高了轨迹分类和转向计数的准确性；多摄像头弱融合进一步提升了整体精度。

Conclusion: 交通流分析应在地面平面而非图像平面进行，以获得更高的准确性和实用性。

Abstract: Accurate turning movement counts at intersections are important for signal control, traffic management and urban planning. Computer vision systems for automatic turning movement counts typically rely on visual analysis in the image plane of an infrastructure camera. Here we explore potential advantages of back-projecting vehicles detected in one or more infrastructure cameras to the ground plane for analysis in real-world 3D coordinates. For single-camera systems we find that back-projection yields more accurate trajectory classification and turning movement counts. We further show that even higher accuracy can be achieved through weak fusion of back-projected detections from multiple cameras. These results suggeest that traffic should be analyzed on the ground plane, not the image plane

</details>


### [111] [CLAReSNet: When Convolution Meets Latent Attention for Hyperspectral Image Classification](https://arxiv.org/abs/2511.12346)
*Asmit Bandyopadhyay,Anindita Das Bhattacharjee,Rakesh Das*

Main category: cs.CV

TL;DR: 提出CLAReSNet，一种融合多尺度卷积与自适应潜在注意力机制的混合网络，用于高光谱图像分类，在有限样本和严重类别不平衡下实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类面临高光谱维度、复杂的光谱-空间相关性以及训练样本少且类别严重不平衡的挑战；传统CNN和Transformer单独使用存在二次复杂度和归纳偏置不足的问题。

Method: 设计CLAReSNet，结合多尺度卷积骨干、残差块和改进的CBAM提取空间特征，采用双向RNN与多尺度光谱潜在注意力（MSLA）进行光谱建模，通过自适应潜在瓶颈降低计算复杂度至O(Tlog(T)D)，并利用分层交叉注意力融合多级特征。

Result: 在Indian Pines和Salinas数据集上分别达到99.71%和99.96%的整体精度，显著优于HybridSN、SSRN和SpectralFormer，学习到的嵌入具有更好的类间分离性和类内紧凑性。

Conclusion: CLAReSNet有效应对了高光谱图像分类中的关键挑战，在低样本量和类别不平衡条件下表现出卓越性能，为未来高效谱空特征融合提供了新思路。

Abstract: Hyperspectral image (HSI) classification faces critical challenges, including high spectral dimensionality, complex spectral-spatial correlations, and limited training samples with severe class imbalance. While CNNs excel at local feature extraction and transformers capture long-range dependencies, their isolated application yields suboptimal results due to quadratic complexity and insufficient inductive biases. We propose CLAReSNet (Convolutional Latent Attention Residual Spectral Network), a hybrid architecture that integrates multi-scale convolutional extraction with transformer-style attention via an adaptive latent bottleneck. The model employs a multi-scale convolutional stem with deep residual blocks and an enhanced Convolutional Block Attention Module for hierarchical spatial features, followed by spectral encoder layers combining bidirectional RNNs (LSTM/GRU) with Multi-Scale Spectral Latent Attention (MSLA). MSLA reduces complexity from $\mathcal{O}(T^2D)$ to $\mathcal{O}(T\log(T)D)$ by adaptive latent token allocation (8-64 tokens) that scales logarithmically with the sequence length. Hierarchical cross-attention fusion dynamically aggregates multi-level representations for robust classification. Experiments conducted on the Indian Pines and Salinas datasets show state-of-the-art performance, achieving overall accuracies of 99.71% and 99.96%, significantly surpassing HybridSN, SSRN, and SpectralFormer. The learned embeddings exhibit superior inter-class separability and compact intra-class clustering, validating CLAReSNet's effectiveness under limited samples and severe class imbalance.

</details>


### [112] [Explainable AI-Generated Image Detection RewardBench](https://arxiv.org/abs/2511.12363)
*Michael Yang,Shijian Deng,William T. Doan,Kai Wang,Tianyu Yang,Harsh Singh,Yapeng Tian*

Main category: cs.CV

TL;DR: 提出了首个用于评估多模态大语言模型（MLLMs）在判断AI生成图像检测解释质量方面能力的基准 XAIGID-RewardBench，包含约3000个标注三元组，结果显示当前最佳MLLM得分88.76%，与人类一致性（98.30%）之间仍存在差距。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成图像检测方法缺乏可解释性，且缺乏对MLLM生成解释的评估标准，尤其是MLLM作为‘裁判’时的评判能力尚未被充分研究。

Method: 构建了一个名为 XAIGID-RewardBench 的基准，包含来自多种图像生成模型和MLLMs的约3000个标注三元组，用于评估MLLM作为奖励模型（裁判）判断解释质量的能力。

Result: 当前表现最好的MLLM在该基准上得分为88.76%，而人类标注者间的一致性为98.30%，表明MLLM在解释评判能力上仍显著落后于人类，并识别出模型常见的错误模式。

Conclusion: XAIGID-RewardBench 揭示了现有MLLM在解释AI生成图像检测结果方面的局限性，强调了进一步提升其推理与评判能力的必要性。

Abstract: Conventional, classification-based AI-generated image detection methods cannot explain why an image is considered real or AI-generated in a way a human expert would, which reduces the trustworthiness and persuasiveness of these detection tools for real-world applications. Leveraging Multimodal Large Language Models (MLLMs) has recently become a trending solution to this issue. Further, to evaluate the quality of generated explanations, a common approach is to adopt an "MLLM as a judge" methodology to evaluate explanations generated by other MLLMs. However, how well those MLLMs perform when judging explanations for AI-generated image detection generated by themselves or other MLLMs has not been well studied. We therefore propose \textbf{XAIGID-RewardBench}, the first benchmark designed to evaluate the ability of current MLLMs to judge the quality of explanations about whether an image is real or AI-generated. The benchmark consists of approximately 3,000 annotated triplets sourced from various image generation models and MLLMs as policy models (detectors) to assess the capabilities of current MLLMs as reward models (judges). Our results show that the current best reward model scored 88.76\% on this benchmark (while human inter-annotator agreement reaches 98.30\%), demonstrating that a visible gap remains between the reasoning abilities of today's MLLMs and human-level performance. In addition, we provide an analysis of common pitfalls that these models frequently encounter. Code and benchmark are available at https://github.com/RewardBench/XAIGID-RewardBench.

</details>


### [113] [DenseAnnotate: Enabling Scalable Dense Caption Collection for Images and 3D Scenes via Spoken Descriptions](https://arxiv.org/abs/2511.12452)
*Xiaoyu Lin,Aniket Ghorpade,Hansheng Zhu,Justin Qiu,Dea Rrozhani,Monica Lama,Mick Yang,Zixuan Bian,Ruohan Ren,Alan B. Hong,Jiatao Gu,Chris Callison-Burch*

Main category: cs.CV

TL;DR: 本文提出了一种基于音频驱动的在线标注平台DenseAnnotate，用于高效生成图像和3D资产的细粒度密集标注。通过语音同步标注区域并结合语音转文本技术，解决了传统文本标注在表达性、速度和细节捕捉上的局限。实验验证了该方法在多语言、文化对齐和3D空间理解能力上的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态训练数据依赖稀疏的互联网或手动文本标注，难以全面捕捉图像内容，尤其在多元文化和3D场景中缺乏细粒度标注。传统文本标注方式表达受限、效率低，亟需更高效的密集标注方法。

Method: 提出DenseAnnotate平台，允许标注者通过语音叙述观察结果，并同步将 spoken phrases 与图像区域或3D场景部分关联。平台集成语音识别和注意力区域标记功能，支持多语言音频对齐的密集标注。

Result: 在两个领域（多元文化图像和3D场景）中，超过1000名标注者参与构建了一个包含3,531张图像、898个3D场景和7,460个3D对象的多模态数据集，涵盖20种语言的音频对齐密集标注。基于该数据集训练的模型在多语言性能上提升5%，文化对齐提升47%，3D空间能力提升54%。

Conclusion: DenseAnnotate为构建高质量、密集的多模态训练数据提供了一种可行且高效的方法，适用于多种任务和数据类型，有望推动未来视觉-语言研究的发展。

Abstract: With the rapid adoption of multimodal large language models (MLLMs) across diverse applications, there is a pressing need for task-centered, high-quality training data. A key limitation of current training datasets is their reliance on sparse annotations mined from the Internet or entered via manual typing that capture only a fraction of an image's visual content. Dense annotations are more valuable but remain scarce. Traditional text-based annotation pipelines are poorly suited for creating dense annotations: typing limits expressiveness, slows annotation speed, and underrepresents nuanced visual features, especially in specialized areas such as multicultural imagery and 3D asset annotation. In this paper, we present DenseAnnotate, an audio-driven online annotation platform that enables efficient creation of dense, fine-grained annotations for images and 3D assets. Annotators narrate observations aloud while synchronously linking spoken phrases to image regions or 3D scene parts. Our platform incorporates speech-to-text transcription and region-of-attention marking. To demonstrate the effectiveness of DenseAnnotate, we conducted case studies involving over 1,000 annotators across two domains: culturally diverse images and 3D scenes. We curate a human-annotated multi-modal dataset of 3,531 images, 898 3D scenes, and 7,460 3D objects, with audio-aligned dense annotations in 20 languages, including 8,746 image captions, 2,000 scene captions, and 19,000 object captions. Models trained on this dataset exhibit improvements of 5% in multilingual, 47% in cultural alignment, and 54% in 3D spatial capabilities. Our results show that our platform offers a feasible approach for future vision-language research and can be applied to various tasks and diverse types of data.

</details>


### [114] [Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning](https://arxiv.org/abs/2511.12365)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: 提出DT-R1，一种基于强化学习的框架，通过构建视觉输入的数字孪生表示来统一处理多种视觉推理任务，在六项基准上优于现有专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉推理方法依赖任务特定架构和监督微调，缺乏统一性，限制了跨任务和跨模态泛化能力。

Method: 提出DT-R1框架，利用大型语言模型构建视觉输入的数字孪生表示，并通过GRPO强化学习训练，结合结构完整性和输出准确性的新型奖励机制进行优化。

Result: 在六个涵盖两种模态和四种任务类型的视觉推理基准上，DT-R1 consistently 超越了最先进的任务专用模型。

Conclusion: DT-R1展示了通过强化学习与数字孪生表示实现统一视觉推理的新方向，具备良好的跨任务与跨模态泛化潜力。

Abstract: Visual reasoning may require models to interpret images and videos and respond to implicit text queries across diverse output formats, from pixel-level segmentation masks to natural language descriptions. Existing approaches rely on supervised fine-tuning with task-specific architectures. For example, reasoning segmentation, grounding, summarization, and visual question answering each demand distinct model designs and training, preventing unified solutions and limiting cross-task and cross-modality generalization. Hence, we propose DT-R1, a reinforcement learning framework that trains large language models to construct digital twin representations of complex multi-modal visual inputs and then reason over these high-level representations as a unified approach to visual reasoning. Specifically, we train DT-R1 using GRPO with a novel reward that validates both structural integrity and output accuracy. Evaluations in six visual reasoning benchmarks, covering two modalities and four task types, demonstrate that DT-R1 consistently achieves improvements over state-of-the-art task-specific models. DT-R1 opens a new direction where visual reasoning emerges from reinforcement learning with digital twin representations.

</details>


### [115] [Fast Reasoning Segmentation for Images and Videos](https://arxiv.org/abs/2511.12368)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: 本文提出FastReasonSeg，一种基于数字孪生表示的高效推理分割知识蒸馏方法，通过解耦感知与推理，结合监督微调和强化微调，在保持高精度的同时显著降低模型规模和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法依赖大规模多模态语言模型，难以部署于边缘设备；且传统蒸馏方法无法有效传递多步推理能力。

Method: 提出FastReasonSeg，利用数字孪生表示解耦感知与推理；采用两阶段蒸馏：先对教师模型生成的推理链进行监督微调，再通过联合奖励（评估分割准确性和推理质量）进行强化微调。

Result: 在四个基准（两个视频、两个图像）上达到最先进性能；0.6B参数的蒸馏模型超越大20倍参数的模型，实现7.79 FPS和仅2.1GB内存占用。

Conclusion: FastReasonSeg实现了高效、高质量的推理分割，支持在资源受限环境中实时部署，推动了具身智能体在真实场景中的应用。

Abstract: Reasoning segmentation enables open-set object segmentation via implicit text queries, therefore serving as a foundation for embodied agents that should operate autonomously in real-world environments. However, existing methods for reasoning segmentation require multimodal large language models with billions of parameters that exceed the computational capabilities of edge devices that typically deploy the embodied AI systems. Distillation offers a pathway to compress these models while preserving their capabilities. Yet, existing distillation approaches fail to transfer the multi-step reasoning capabilities that reasoning segmentation demands, as they focus on matching output predictions and intermediate features rather than preserving reasoning chains. The emerging paradigm of reasoning over digital twin representations presents an opportunity for more effective distillation by re-framing the problem. Consequently, we propose FastReasonSeg, which employs digital twin representations that decouple perception from reasoning to enable more effective distillation. Our distillation scheme first relies on supervised fine-tuning on teacher-generated reasoning chains. Then it is followed by reinforcement fine-tuning with joint rewards evaluating both segmentation accuracy and reasoning quality alignment. Experiments on two video (JiTBench, RVTBench) and two image benchmarks (ReasonSeg, LLM-Seg40K) demonstrate that our FastReasonSeg achieves state-of-the-art reasoning segmentation performance. Moreover, the distilled 0.6B variant outperforms models with 20 times more parameters while achieving 7.79 FPS throughput with only 2.1GB memory consumption. This efficiency enables deployment in resource-constrained environments to enable real-time reasoning segmentation.

</details>


### [116] [Changes in Real Time: Online Scene Change Detection with Multi-View Fusion](https://arxiv.org/abs/2511.12370)
*Chamuditha Jayanga Galappaththige,Jason Lai,Lloyd Windrim,Donald Dansereau,Niko Sünderhauf,Dimity Miller*

Main category: cs.CV

TL;DR: 提出了一种新的在线场景变化检测方法，具有姿态无关、无标签、多视角一致性，并在速度和精度上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有在线SCD方法准确性显著低于离线方法，且难以处理无约束视角下的实时变化检测。

Method: 引入自监督融合损失、基于PnP的快速姿态估计，以及面向3D高斯点阵表示的快速变化引导更新策略。

Result: 在复杂真实世界数据集上超越了现有的在线和离线方法，运行速度超过10 FPS。

Conclusion: 该方法是首个兼具高效性、鲁棒性和高精度的在线SCD方案，性能优于离线方法。

Abstract: Online Scene Change Detection (SCD) is an extremely challenging problem that requires an agent to detect relevant changes on the fly while observing the scene from unconstrained viewpoints. Existing online SCD methods are significantly less accurate than offline approaches. We present the first online SCD approach that is pose-agnostic, label-free, and ensures multi-view consistency, while operating at over 10 FPS and achieving new state-of-the-art performance, surpassing even the best offline approaches. Our method introduces a new self-supervised fusion loss to infer scene changes from multiple cues and observations, PnP-based fast pose estimation against the reference scene, and a fast change-guided update strategy for the 3D Gaussian Splatting scene representation. Extensive experiments on complex real-world datasets demonstrate that our approach outperforms both online and offline baselines.

</details>


### [117] [Reasoning Text-to-Video Retrieval via Digital Twin Video Representations and Large Language Models](https://arxiv.org/abs/2511.12371)
*Yiqing Shen,Chenxiao Fan,Chenjia Li,Mathias Unberath*

Main category: cs.CV

TL;DR: 本文提出了一种用于文本到视频检索的推理框架，通过数字孪生表示视频内容，结合大语言模型进行推理，在处理隐式查询方面显著优于现有方法，并构建了新的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频检索方法在处理显式查询时表现良好，但在隐式查询（需要推理才能识别相关视频）上效果不佳，缺乏对复杂语义的理解和对象级定位能力。

Method: 提出一个两阶段框架：首先将视频表示为数字孪生（结构化场景表示），通过分解子查询与数字孪生进行组合对齐；然后利用大语言模型进行基于即时 refinement 的推理，调用专业模型填补信息空白，并生成满足查询条件的对象级掩码。

Result: 在新构建的 ReasonT2VBench-135 上达到 81.2% 的 R@1，超过最强基线 50 多个百分点；在 ReasonT2VBench-1000 上保持 81.7% R@1，同时在 MSR-VTT、MSVD 和 VATEX 三个传统基准上达到最先进性能。

Conclusion: 通过数字孪生和大语言模型推理相结合，该方法有效提升了文本到视频检索在隐式查询下的性能，实现了可解释的对象级定位，推动了检索系统向更深层次语义理解的发展。

Abstract: The goal of text-to-video retrieval is to search large databases for relevant videos based on text queries. Existing methods have progressed to handling explicit queries where the visual content of interest is described explicitly; however, they fail with implicit queries where identifying videos relevant to the query requires reasoning. We introduce reasoning text-to-video retrieval, a paradigm that extends traditional retrieval to process implicit queries through reasoning while providing object-level grounding masks that identify which entities satisfy the query conditions. Instead of relying on vision-language models directly, we propose representing video content as digital twins, i.e., structured scene representations that decompose salient objects through specialist vision models. This approach is beneficial because it enables large language models to reason directly over long-horizon video content without visual token compression. Specifically, our two-stage framework first performs compositional alignment between decomposed sub-queries and digital twin representations for candidate identification, then applies large language model-based reasoning with just-in-time refinement that invokes additional specialist models to address information gaps. We construct a benchmark of 447 manually created implicit queries with 135 videos (ReasonT2VBench-135) and another more challenging version of 1000 videos (ReasonT2VBench-1000). Our method achieves 81.2% R@1 on ReasonT2VBench-135, outperforming the strongest baseline by greater than 50 percentage points, and maintains 81.7% R@1 on the extended configuration while establishing state-of-the-art results in three conventional benchmarks (MSR-VTT, MSVD, and VATEX).

</details>


### [118] [AGGRNet: Selective Feature Extraction and Aggregation for Enhanced Medical Image Classification](https://arxiv.org/abs/2511.12382)
*Ansh Makwe,Akansh Agrawal,Prateek Jain,Akshan Agrawal,Priyanka Bagade*

Main category: cs.CV

TL;DR: 提出AGGRNet框架，通过提取信息性和非信息性特征来改善复杂医学图像分类任务中的细粒度视觉模式识别，显著提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有注意力模型在区分细微类别时表现不佳，难以处理类间相似性和类内变异性，导致诊断错误。

Method: 设计AGGRNet框架，能够有效分离并利用信息性和非信息性特征，增强对复杂医学图像中细粒度差异的学习能力。

Result: 在多个医学图像数据集上达到最先进水平，尤其在Kvasir数据集上比现有最佳模型最高提升5%。

Conclusion: AGGRNet能更有效地捕捉复杂医学图像中的细微差异，提高分类准确性，适用于高难度医学图像分析任务。

Abstract: Medical image analysis for complex tasks such as severity grading and disease subtype classification poses significant challenges due to intricate and similar visual patterns among classes, scarcity of labeled data, and variability in expert interpretations. Despite the usefulness of existing attention-based models in capturing complex visual patterns for medical image classification, underlying architectures often face challenges in effectively distinguishing subtle classes since they struggle to capture inter-class similarity and intra-class variability, resulting in incorrect diagnosis. To address this, we propose AGGRNet framework to extract informative and non-informative features to effectively understand fine-grained visual patterns and improve classification for complex medical image analysis tasks. Experimental results show that our model achieves state-of-the-art performance on various medical imaging datasets, with the best improvement up to 5% over SOTA models on the Kvasir dataset.

</details>


### [119] [Leveraging Quantum-Based Architectures for Robust Diagnostics](https://arxiv.org/abs/2511.12386)
*Shabnam Sodagari,Tommy Long*

Main category: cs.CV

TL;DR: 本研究提出了一种结合预训练ResNet50与量子卷积神经网络（QCNN）的混合量子-经典框架，用于基于CT图像对肾结石、肾囊肿和肾肿瘤进行分类诊断。


<details>
  <summary>Details</summary>
Motivation: 旨在探索量子计算在医学影像诊断中的潜力，提升对肾脏疾病的自动识别能力，特别是应对类别不平衡和特征提取挑战。

Method: 采用ResNet50提取CT图像深层特征，通过角度编码将特征映射为量子比特，输入QCNN进行分类；结合图像去噪、CLAHE增强、数据增强与加权采样以优化模型训练。

Result: 模型在8比特和12比特量子配置下均实现快速收敛，测试准确率达0.99；12比特模型在囊肿召回率和肿瘤F1分数（0.9956）上表现更优，混淆矩阵显示误分类极少。

Conclusion: 融合经典图像预处理与深度特征提取的量子混合框架能有效提升医学诊断性能，具备临床辅助诊断潜力。

Abstract: The objective of this study is to diagnose and differentiate kidney stones, cysts, and tumors using Computed Tomography (CT) images of the kidney. This study leverages a hybrid quantum-classical framework in this regard. We combine a pretrained ResNet50 encoder, with a Quantum Convolutional Neural Network (QCNN) to explore quantum-assisted diagnosis. We pre-process the kidney images using denoising and contrast limited adaptive histogram equalization to enhance feature extraction. We address class imbalance through data augmentation and weighted sampling. Latent features extracted by the encoder are transformed into qubits via angle encoding and processed by a QCNN. The model is evaluated on both 8-qubit and 12-qubit configurations. Both architectures achieved rapid convergence with stable learning curves and high consistency between training and validation performance. The models reached a test accuracy of 0.99, with the 12-qubit configuration providing improvements in overall recall and precision, particularly for Cyst and Tumor detection, where it achieved perfect recall for Cysts and a tumor F1-score of 0.9956. Confusion matrix analysis further confirmed reliable classification behavior across all classes, with very few misclassifications. Results demonstrate that integrating classical pre-processing and deep feature extraction with quantum circuits enhances medical diagnostic performance.

</details>


### [120] [Calibrated Decomposition of Aleatoric and Epistemic Uncertainty in Deep Features for Inference-Time Adaptation](https://arxiv.org/abs/2511.12389)
*Divake Kumar,Patrick Poggi,Sina Tayebati,Devashri Naik,Nilesh Ahuja,Amit Ranjan Trivedi*

Main category: cs.CV

TL;DR: 提出了一种轻量级推理时框架Uncertainty-Guided Inference-Time Selection，解耦了数据驱动和模型驱动的不确定性，实现了更高效的自适应模型选择和更紧致的预测区间。


<details>
  <summary>Details</summary>
Motivation: 大多数估计器将所有不确定性模式合并为单一置信度分数，难以可靠判断何时应分配更多计算资源或调整推理过程。

Method: 在深度特征空间中直接解耦aleatoric和epistemic不确定性；前者通过正则化全局密度模型估计，后者由三个互补成分构成，分别捕捉局部支持不足、流形谱坍缩和跨层特征不一致。

Result: 集成分解后的不确定性到无分布假设的共形校准中，显著提高了预测区间的紧密性；在MOT17上实现约60%的计算节省且精度损失可忽略，并在所有序列上优于总不确定性基线13.6个百分点。

Conclusion: 该方法无需采样、集成或多步前向传播，能有效支持自调节视觉推理，提升计算效率与可靠性。

Abstract: Most estimators collapse all uncertainty modes into a single confidence score, preventing reliable reasoning about when to allocate more compute or adjust inference. We introduce Uncertainty-Guided Inference-Time Selection, a lightweight inference time framework that disentangles aleatoric (data-driven) and epistemic (model-driven) uncertainty directly in deep feature space. Aleatoric uncertainty is estimated using a regularized global density model, while epistemic uncertainty is formed from three complementary components that capture local support deficiency, manifold spectral collapse, and cross-layer feature inconsistency. These components are empirically orthogonal and require no sampling, no ensembling, and no additional forward passes. We integrate the decomposed uncertainty into a distribution free conformal calibration procedure that yields significantly tighter prediction intervals at matched coverage. Using these components for uncertainty guided adaptive model selection reduces compute by approximately 60 percent on MOT17 with negligible accuracy loss, enabling practical self regulating visual inference. Additionally, our ablation results show that the proposed orthogonal uncertainty decomposition consistently yields higher computational savings across all MOT17 sequences, improving margins by 13.6 percentage points over the total-uncertainty baseline.

</details>


### [121] [MSLoRA: Multi-Scale Low-Rank Adaptation via Attention Reweighting](https://arxiv.org/abs/2511.12400)
*Xu Yang,Gady Agam*

Main category: cs.CV

TL;DR: MSLoRA是一种通用、轻量化的参数高效适配器，通过重加权特征响应而非微调主干网络，统一支持CNN和ViT架构的迁移学习。


<details>
  <summary>Details</summary>
Motivation: 现有低秩适配方法多局限于视觉Transformer（ViT），难以跨架构泛化，且对卷积神经网络（CNN）支持不足，因此需要一种通用、高效的适配方法。

Method: MSLoRA结合低秩线性投影与多尺度非线性变换，通过逐点相乘和残差连接融合，联合调制空间与通道注意力，在不更新预训练权重的情况下实现特征重加权。

Result: 在分类、检测和分割任务中，MSLoRA以不到主干网络5%的参数量显著提升迁移性能，具备快速收敛、优化稳定和强跨架构泛化能力。

Conclusion: MSLoRA通过重加权而非微调的方式，为冻结视觉主干网络提供了一种简单、通用且高效的适应方案。

Abstract: We introduce MSLoRA, a backbone-agnostic, parameter-efficient adapter that reweights feature responses rather
  than re-tuning the underlying backbone. Existing low-rank adaptation methods are mostly confined to vision
  transformers (ViTs) and struggle to generalize across architectures. MSLoRA unifies adaptation for both convolutional neural networks (CNNs) and
  ViTs by combining a low-rank linear projection with a multi-scale nonlinear transformation that jointly
  modulates spatial and channel attention. The two components are fused through pointwise multiplication and
  a residual connection, yielding a lightweight module that shifts feature attention while keeping pretrained
  weights frozen.
  Extensive experiments demonstrate that MSLoRA consistently improves transfer performance on classification,
  detection, and segmentation tasks with roughly less than 5\% of backbone parameters.
  The design further enables stable optimization, fast convergence, and strong cross-architecture
  generalization. By reweighting rather than re-tuning, MSLoRA provides a simple and universal approach
  for efficient adaptation of frozen vision backbones.

</details>


### [122] [VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving](https://arxiv.org/abs/2511.12405)
*Hyunki Seong,Seongwoo Moon,Hojin Ahn,Jehun Kang,David Hyunchul Shim*

Main category: cs.CV

TL;DR: 提出了一种开放世界端到端自动驾驶框架VLA-R，结合视觉-语言动作检索范式，实现对未知环境的强泛化与探索能力。


<details>
  <summary>Details</summary>
Motivation: 在非结构化户外环境中，传统端到端自动驾驶系统因训练期间未见场景而泛化能力不足，难以应对开放世界中的未知情况。

Method: 利用冻结的视觉-语言模型进行开放世界感知，通过Q-Former瓶颈融合细粒度视觉与语言对齐特征，并引入视觉-动作对比学习来对齐感知与动作嵌入，实现动作检索。

Result: 在真实机器人平台上验证了VLA-R在未见非结构化环境中的优异泛化和探索性能，即使在数据有限的情况下仍表现良好。

Conclusion: VLA-R通过结合开放世界感知与视觉-动作检索，有效提升了端到端自动驾驶系统在未知环境中的适应性与可解释性。

Abstract: Exploring open-world situations in an end-to-end manner is a promising yet challenging task due to the need for strong generalization capabilities. In particular, end-to-end autonomous driving in unstructured outdoor environments often encounters conditions that were unfamiliar during training. In this work, we present Vision-Language Action Retrieval (VLA-R), an open-world end-to-end autonomous driving (OW-E2EAD) framework that integrates open-world perception with a novel vision-action retrieval paradigm. We leverage a frozen vision-language model for open-world detection and segmentation to obtain multi-scale, prompt-guided, and interpretable perception features without domain-specific tuning. A Q-Former bottleneck aggregates fine-grained visual representations with language-aligned visual features, bridging perception and action domains. To learn transferable driving behaviors, we introduce a vision-action contrastive learning scheme that aligns vision-language and action embeddings for effective open-world reasoning and action retrieval. Our experiments on a real-world robotic platform demonstrate strong generalization and exploratory performance in unstructured, unseen environments, even with limited data. Demo videos are provided in the supplementary material.

</details>


### [123] [Self-Supervised Visual Prompting for Cross-Domain Road Damage Detection](https://arxiv.org/abs/2511.12410)
*Xi Xiao,Zhuxuanzi Wang,Mingqiao Mo,Chen Liu,Chenrui Ma,Yanshu Li,Smita Krishnaswamy,Xiao Wang,Tianyang Wang*

Main category: cs.CV

TL;DR: 提出一种名为\ours的自监督框架，通过视觉探测目标域（无需标签）来提升路面缺陷检测的跨域泛化能力，结合缺陷感知提示模块（SPEM）和域感知提示对齐目标（DAPA），在多个基准上显著优于现有方法，实现强健的零样本迁移与高效的小样本适应。


<details>
  <summary>Details</summary>
Motivation: 自动化路面缺陷检测常因跨域泛化性能差而受限，传统监督方法需大量标注数据且难以迁移到新环境，标准自监督方法虽无需标签但对域偏移仍敏感，因此需要一种无需标签且能有效适应目标域的方法。

Method: \ours框架包含两个核心组件：1）自监督提示增强模块（SPEM），从无标签的目标域数据中提取缺陷感知提示以引导冻结的ViT骨干网络；2）域感知提示对齐（DAPA）目标，用于对齐源域和目标域在提示条件下的特征表示，从而实现跨域知识迁移。

Result: 在四个具有挑战性的基准上实验表明，\ours在零样本迁移下表现最优，显著优于强监督、自监督及领域自适应基线方法，展现出更强的抗域变化鲁棒性，并在小样本适应场景中表现出高数据效率。

Conclusion: 自监督提示学习是一种构建可扩展、自适应视觉检测系统的有效路径，\ours为解决实际部署中的跨域泛化问题提供了实用且高效的解决方案。

Abstract: The deployment of automated pavement defect detection is often hindered by poor cross-domain generalization. Supervised detectors achieve strong in-domain accuracy but require costly re-annotation for new environments, while standard self-supervised methods capture generic features and remain vulnerable to domain shift. We propose \ours, a self-supervised framework that \emph{visually probes} target domains without labels. \ours introduces a Self-supervised Prompt Enhancement Module (SPEM), which derives defect-aware prompts from unlabeled target data to guide a frozen ViT backbone, and a Domain-Aware Prompt Alignment (DAPA) objective, which aligns prompt-conditioned source and target representations. Experiments on four challenging benchmarks show that \ours consistently outperforms strong supervised, self-supervised, and adaptation baselines, achieving robust zero-shot transfer, improved resilience to domain variations, and high data efficiency in few-shot adaptation. These results highlight self-supervised prompting as a practical direction for building scalable and adaptive visual inspection systems. Source code is publicly available: https://github.com/xixiaouab/PROBE/tree/main

</details>


### [124] [Towards Rotation-only Imaging Geometry: Rotation Estimation](https://arxiv.org/abs/2511.12415)
*Xinrui Li,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 本文提出了一种仅基于旋转的优化框架，用于从2D图像中恢复3D场景结构和相机运动，在双视图和多视图场景下均表现出优越的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的Structure from Motion (SfM) 方法通常需要同时优化3D坐标和相机位姿，计算复杂且易受误差影响。本文旨在通过解耦3D坐标与相机姿态，仅利用旋转信息进行优化，从而提升SfM的性能。

Method: 采用仅姿态的成像几何模型，将平移表示为旋转的函数，从而将成像几何表示压缩到旋转流形上，并基于重投影误差构建仅旋转的优化框架，适用于双视图和多视图情况。

Result: 实验结果表明，该方法在旋转估计精度和鲁棒性方面优于当前最先进的方法，甚至可媲美多次束调整迭代的结果。

Conclusion: 该旋转-only框架为SfM提供了一种更高效、准确和可靠的解决方案，有助于推动3D视觉计算的发展。

Abstract: Structure from Motion (SfM) is a critical task in computer vision, aiming to recover the 3D scene structure and camera motion from a sequence of 2D images. The recent pose-only imaging geometry decouples 3D coordinates from camera poses and demonstrates significantly better SfM performance through pose adjustment. Continuing the pose-only perspective, this paper explores the critical relationship between the scene structures, rotation and translation. Notably, the translation can be expressed in terms of rotation, allowing us to condense the imaging geometry representation onto the rotation manifold. A rotation-only optimization framework based on reprojection error is proposed for both two-view and multi-view scenarios. The experiment results demonstrate superior accuracy and robustness performance over the current state-of-the-art rotation estimation methods, even comparable to multiple bundle adjustment iteration results. Hopefully, this work contributes to even more accurate, efficient and reliable 3D visual computing.

</details>


### [125] [Seeing Through the Rain: Resolving High-Frequency Conflicts in Deraining and Super-Resolution via Diffusion Guidance](https://arxiv.org/abs/2511.12419)
*Wenjie Li,Jinglei Shi,Jin Han,Heng Guo,Zhanyu Ma*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的高频引导方法DHGM，用于去雨和超分辨率联合任务，有效解决了去噪与细节恢复之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 现有方法在去天气干扰时会损失高频细节，而级联去雨和超分辨率方法存在高频信息处理的内在冲突，影响小物体检测等视觉任务性能。

Method: 提出DHGM，结合预训练扩散先验与高通滤波器，在去除雨纹的同时增强结构细节，实现端到端的清晰高分辨率图像生成。

Result: 实验表明DHGM在去雨和超分辨率效果上优于现有方法，同时具有更低的计算成本。

Conclusion: DHGM能有效协同处理去雨与超分辨率，平衡高频噪声去除与细节重建，提升复杂天气下高分辨率图像质量。

Abstract: Clean images are crucial for visual tasks such as small object detection, especially at high resolutions. However, real-world images are often degraded by adverse weather, and weather restoration methods may sacrifice high-frequency details critical for analyzing small objects. A natural solution is to apply super-resolution (SR) after weather removal to recover both clarity and fine structures. However, simply cascading restoration and SR struggle to bridge their inherent conflict: removal aims to remove high-frequency weather-induced noise, while SR aims to hallucinate high-frequency textures from existing details, leading to inconsistent restoration contents. In this paper, we take deraining as a case study and propose DHGM, a Diffusion-based High-frequency Guided Model for generating clean and high-resolution images. DHGM integrates pre-trained diffusion priors with high-pass filters to simultaneously remove rain artifacts and enhance structural details. Extensive experiments demonstrate that DHGM achieves superior performance over existing methods, with lower costs.

</details>


### [126] [MFI-ResNet: Efficient ResNet Architecture Optimization via MeanFlow Compression and Selective Incubation](https://arxiv.org/abs/2511.12422)
*Nuolin Sun,Linyuan Wang,Haonan Wei,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: 提出MFI-ResNet，利用MeanFlow模块和选择性孵化策略，在减少参数量的同时提升ResNet在CIFAR数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 受ResNet与ODE关系以及MeanFlow单步生成建模的启发，探索更高效且高性能的网络结构。

Method: 采用压缩-扩展策略：压缩阶段用MeanFlow模块替代多个残差块构建轻量元模型；扩展阶段通过选择性孵化恢复前三个阶段的残差结构，保留最后阶段为MeanFlow形式并微调。

Result: 在CIFAR-10和CIFAR-100上相比ResNet-50减少了约46%的参数，同时分别提升了0.23%和0.17%的准确率。

Conclusion: 生成式流场可有效刻画ResNet中的特征变换过程，为生成建模与判别学习的关系提供了新视角。

Abstract: ResNet has achieved tremendous success in computer vision through its residual connection mechanism. ResNet can be viewed as a discretized form of ordinary differential equations (ODEs). From this perspective, the multiple residual blocks within a single ResNet stage essentially perform multi-step discrete iterations of the feature transformation for that stage. The recently proposed flow matching model, MeanFlow, enables one-step generative modeling by learning the mean velocity field to transform distributions. Inspired by this, we propose MeanFlow-Incubated ResNet (MFI-ResNet), which employs a compression-expansion strategy to jointly improve parameter efficiency and discriminative performance. In the compression phase, we simplify the multi-layer structure within each ResNet stage to one or two MeanFlow modules to construct a lightweight meta model. In the expansion phase, we apply a selective incubation strategy to the first three stages, expanding them to match the residual block configuration of the baseline ResNet model, while keeping the last stage in MeanFlow form, and fine-tune the incubated model. Experimental results show that on CIFAR-10 and CIFAR-100 datasets, MFI-ResNet achieves remarkable parameter efficiency, reducing parameters by 46.28% and 45.59% compared to ResNet-50, while still improving accuracy by 0.23% and 0.17%, respectively. This demonstrates that generative flow-fields can effectively characterize the feature transformation process in ResNet, providing a new perspective for understanding the relationship between generative modeling and discriminative learning.

</details>


### [127] [RedVTP: Training-Free Acceleration of Diffusion Vision-Language Models Inference via Masked Token-Guided Visual Token Pruning](https://arxiv.org/abs/2511.12428)
*Jingqi Xu,Jingxi Lu,Chenghao Li,Sreetama Sarkar,Souvik Kundu,Peter A. Beerel*

Main category: cs.CV

TL;DR: 提出了一种名为RedVTP的响应驱动视觉令牌剪枝策略，用于提升扩散型视觉语言模型（DVLMs）的推理效率。


<details>
  <summary>Details</summary>
Motivation: 尽管DVLMs具有并行解码的优势，但大量视觉令牌严重影响其推理效率，而现有剪枝方法主要针对自回归模型，DVLMs的剪枝研究尚不充分。

Method: 利用掩码响应令牌的注意力权重评估视觉令牌的重要性，并在首次推理后剪除不重要的视觉令牌，且利用重要性分数跨步长的一致性来保持性能。

Result: 在LLaDA-V和LaViDa模型上，生成吞吐量分别提升最高186%和28.05%，延迟降低最高64.97%和21.87%，且未牺牲准确性甚至有所提升。

Conclusion: RedVTP有效提升了DVLMs的推理效率，为高效率多模态模型部署提供了可行方案。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in multimodal reasoning and generation, yet their high computational demands remain a major challenge. Diffusion Vision-Language Models (DVLMs) are particularly attractive because they enable parallel token decoding, but the large number of visual tokens still significantly hinders their inference efficiency. While visual token pruning has been extensively studied for autoregressive VLMs (AVLMs), it remains largely unexplored for DVLMs. In this work, we propose RedVTP, a response-driven visual token pruning strategy that leverages the inference dynamics of DVLMs. Our method estimates visual token importance using attention from the masked response tokens. Based on the observation that these importance scores remain consistent across steps, RedVTP prunes the less important visual tokens from the masked tokens after the first inference step, thereby maximizing inference efficiency. Experiments show that RedVTP improves token generation throughput of LLaDA-V and LaViDa by up to 186% and 28.05%, respectively, and reduces inference latency by up to 64.97% and 21.87%, without compromising-and in some cases improving-accuracy.

</details>


### [128] [Text-Guided Channel Perturbation and Pretrained Knowledge Integration for Unified Multi-Modality Image Fusion](https://arxiv.org/abs/2511.12432)
*Xilai Li,Xiaosong Li,Weijun Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于通道扰动和预训练知识集成的统一多模态图像融合框架UP-Fusion，通过语义感知通道剪枝、几何仿射调制和文本引导通道扰动模块，在抑制冗余信息的同时提升融合性能和跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型因模态差异大导致梯度冲突，而模态特定编码器虽提升融合质量却降低跨任务泛化能力，因此需要一种兼顾融合性能与通用性的新方法。

Method: 提出UP-Fusion框架，包括语义感知通道剪枝模块（SCPM）利用预训练模型过滤增强特征通道，几何仿射调制模块（GAM）保持模态判别性，以及文本引导通道扰动模块（TCPM）在解码时重塑通道分布。

Result: 实验表明该方法在多模态图像融合及下游任务中均优于现有方法，有效平衡了融合质量与模型泛化性。

Conclusion: UP-Fusion通过引入通道扰动与预训练知识，在不依赖模态特定编码器的情况下实现了高性能、高泛化的多模态图像融合，为统一融合模型提供了新思路。

Abstract: Multi-modality image fusion enhances scene perception by combining complementary information. Unified models aim to share parameters across modalities for multi-modality image fusion, but large modality differences often cause gradient conflicts, limiting performance. Some methods introduce modality-specific encoders to enhance feature perception and improve fusion quality. However, this strategy reduces generalisation across different fusion tasks. To overcome this limitation, we propose a unified multi-modality image fusion framework based on channel perturbation and pre-trained knowledge integration (UP-Fusion). To suppress redundant modal information and emphasize key features, we propose the Semantic-Aware Channel Pruning Module (SCPM), which leverages the semantic perception capability of a pre-trained model to filter and enhance multi-modality feature channels. Furthermore, we proposed the Geometric Affine Modulation Module (GAM), which uses original modal features to apply affine transformations on initial fusion features to maintain the feature encoder modal discriminability. Finally, we apply a Text-Guided Channel Perturbation Module (TCPM) during decoding to reshape the channel distribution, reducing the dependence on modality-specific channels. Extensive experiments demonstrate that the proposed algorithm outperforms existing methods on both multi-modality image fusion and downstream tasks.

</details>


### [129] [Real-Time Drivers' Drowsiness Detection and Analysis through Deep Learning](https://arxiv.org/abs/2511.12438)
*ANK Zaman,Prosenjit Chatterjee,Rajat Sharma*

Main category: cs.CV

TL;DR: 提出了一种基于深度卷积神经网络（DCNN）和OpenCV的实时驾驶员疲劳检测系统，通过分析面部特征如眼睛开合和打哈欠动作来检测疲劳状态，并在检测到疲劳时发出实时警报。


<details>
  <summary>Details</summary>
Motivation: 长时间驾驶容易导致驾驶员疲劳，进而引发交通事故，因此需要一种实时、有效的疲劳检测系统来提升道路安全。

Method: 利用实时摄像头采集驾驶员面部图像，结合OpenCV提取面部关键点（如眼睛和嘴巴），并通过预训练的深度卷积神经网络（DCNN）模型进行疲劳状态分类。

Result: 在NTHU-DDD数据集和Yawn-Eye-Dataset上的疲劳检测准确率分别达到99.6%和97%。

Conclusion: 该方法是一种非侵入式、低成本且高效的驾驶员疲劳检测方案，具有较高的准确性和实际应用潜力，可集成于智能汽车技术中以提升行车安全。

Abstract: A long road trip is fun for drivers. However, a long drive for days can be tedious for a driver to accommodate stringent deadlines to reach distant destinations. Such a scenario forces drivers to drive extra miles, utilizing extra hours daily without sufficient rest and breaks. Once a driver undergoes such a scenario, it occasionally triggers drowsiness during driving. Drowsiness in driving can be life-threatening to any individual and can affect other drivers' safety; therefore, a real-time detection system is needed. To identify fatigued facial characteristics in drivers and trigger the alarm immediately, this research develops a real-time driver drowsiness detection system utilizing deep convolutional neural networks (DCNNs) and OpenCV.Our proposed and implemented model takes real- time facial images of a driver using a live camera and utilizes a Python-based library named OpenCV to examine the facial images for facial landmarks like sufficient eye openings and yawn-like mouth movements. The DCNNs framework then gathers the data and utilizes a per-trained model to detect the drowsiness of a driver using facial landmarks. If the driver is identified as drowsy, the system issues a continuous alert in real time, embedded in the Smart Car technology.By potentially saving innocent lives on the roadways, the proposed technique offers a non-invasive, inexpensive, and cost-effective way to identify drowsiness. Our proposed and implemented DCNNs embedded drowsiness detection model successfully react with NTHU-DDD dataset and Yawn-Eye-Dataset with drowsiness detection classification accuracy of 99.6% and 97% respectively.

</details>


### [130] [CoTBox-TTT: Grounding Medical VQA with Visual Chain-of-Thought Boxes During Test-time Training](https://arxiv.org/abs/2511.12446)
*Jiahe Qian,Yuhao Shen,Zhangtianyi Chen,Juexiao Zhou,Peisong Wang*

Main category: cs.CV

TL;DR: 提出了一种名为CoTBox-TTT的测试时训练方法，用于提升医学视觉问答模型在域偏移下的可靠性和答案的图像证据关联性，无需额外标签且可即插即用，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉问答系统在域偏移下表现不佳，且答案与图像证据关联弱，缺乏可靠的推理机制，难以在部署时进行重训练或获取额外标注。

Method: 提出CoTBox-TTT，一种基于视觉链式思考信号的证据优先的测试时训练方法，通过冻结主干网络，仅更新少量连续软提示，并利用原始图像与局部裁剪区域的一致性来增强答案的可靠性。

Result: 在pathVQA数据集上，将CoTBox-TTT应用于LLaVA模型后，闭合式准确率提升了12.3%，验证了其在真实部署中的有效性与实用性。

Conclusion: CoTBox-TTT是一种无需标签、即插即用且有效的测试时适应方法，显著提升了医学视觉问答中模型的鲁棒性和结果可解释性。

Abstract: Medical visual question answering could support clinical decision making, yet current systems often fail under domain shift and produce answers that are weakly grounded in image evidence. This reliability gap arises when models attend to spurious regions and when retraining or additional labels are impractical at deployment time. We address this setting with CoTBox-TTT, an evidence-first test-time training approach that adapts a vision-language model at inference while keeping all backbones frozen. The method updates only a small set of continuous soft prompts. It identifies question-relevant regions through a visual chain-of-thought signal and encourages answer consistency across the original image and a localized crop. The procedure is label free, and plug and play with diverse backbones. Experiments on medical VQA show that the approach is practical for real deployments. For instance, adding CoTBox-TTT to LLaVA increases closed-ended accuracy by 12.3% on pathVQA.

</details>


### [131] [MaskAnyNet: Rethinking Masked Image Regions as Valuable Information in Supervised Learning](https://arxiv.org/abs/2511.12480)
*Jingshan Hong,Haigen Hu,Huihuang Zhang,Qianwei Zhou,Zhao Li*

Main category: cs.CV

TL;DR: 提出MaskAnyNet，通过重用被掩码区域作为辅助知识，结合可见与掩码信息，提升模型语义多样性和细粒度特征保留。


<details>
  <summary>Details</summary>
Motivation: 传统图像掩码导致有用像素信息丢失，且可能删除关键小特征；而掩码图像建模表明掩码区域可重建，蕴含语义多样性潜力。

Method: 提出MaskAnyNet，引入重组掩码区域的分支，通过再学习机制联合学习可见和掩码内容，将掩码区域视为辅助知识。

Result: 在CNN和Transformer骨干网络上多个基准测试中均取得一致性能提升，验证了方法对特征丰富性和细节保持的有效性。

Conclusion: 掩码区域不应被忽略，而应作为语义多样性的来源加以利用，MaskAnyNet为监督学习中的图像掩码提供了新视角。

Abstract: In supervised learning, traditional image masking faces two key issues: (i) discarded pixels are underutilized, leading to a loss of valuable contextual information; (ii) masking may remove small or critical features, especially in fine-grained tasks. In contrast, masked image modeling (MIM) has demonstrated that masked regions can be reconstructed from partial input, revealing that even incomplete data can exhibit strong contextual consistency with the original image. This highlights the potential of masked regions as sources of semantic diversity. Motivated by this, we revisit the image masking approach, proposing to treat masked content as auxiliary knowledge rather than ignored. Based on this, we propose MaskAnyNet, which combines masking with a relearning mechanism to exploit both visible and masked information. It can be easily extended to any model with an additional branch to jointly learn from the recomposed masked region. This approach leverages the semantic diversity of the masked regions to enrich features and preserve fine-grained details. Experiments on CNN and Transformer backbones show consistent gains across multiple benchmarks. Further analysis confirms that the proposed method improves semantic diversity through the reuse of masked content.

</details>


### [132] [Towards Temporal Fusion Beyond the Field of View for Camera-based Semantic Scene Completion](https://arxiv.org/abs/2511.12498)
*Jongseong Bae,Junwoo Ha,Jinnyeong Heo,Yeongin Lee,Ha Young Kim*

Main category: cs.CV

TL;DR: 提出了一种名为C3DFusion的模块，通过融合当前帧与历史帧的3D特征来改善相机-based 3D语义场景补全中对视野外区域的重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用时间线索增强当前帧特征时，难以有效重建ego-vehicle侧边等视野外的关键区域，尽管历史帧包含这些区域的有用信息。

Method: 提出了C3DFusion模块，通过3D提升的点特征对齐当前帧和历史帧，并采用历史上下文模糊和当前中心特征稠密化两种技术进行增强的时间融合。

Result: 在SemanticKITTI和SSCBench-KITTI-360数据集上显著优于现有最先进方法，并在其他基线模型上表现出良好的泛化能力。

Conclusion: C3DFusion能有效利用历史帧信息提升3D语义场景补全中对隐藏区域的感知，具有较强的性能和通用性。

Abstract: Recent camera-based 3D semantic scene completion (SSC) methods have increasingly explored leveraging temporal cues to enrich the features of the current frame. However, while these approaches primarily focus on enhancing in-frame regions, they often struggle to reconstruct critical out-of-frame areas near the sides of the ego-vehicle, although previous frames commonly contain valuable contextual information about these unseen regions. To address this limitation, we propose the Current-Centric Contextual 3D Fusion (C3DFusion) module, which generates hidden region-aware 3D feature geometry by explicitly aligning 3D-lifted point features from both current and historical frames. C3DFusion performs enhanced temporal fusion through two complementary techniques-historical context blurring and current-centric feature densification-which suppress noise from inaccurately warped historical point features by attenuating their scale, and enhance current point features by increasing their volumetric contribution. Simply integrated into standard SSC architectures, C3DFusion demonstrates strong effectiveness, significantly outperforming state-of-the-art methods on the SemanticKITTI and SSCBench-KITTI-360 datasets. Furthermore, it exhibits robust generalization, achieving notable performance gains when applied to other baseline models.

</details>


### [133] [Visible Structure Retrieval for Lightweight Image-Based Relocalisation](https://arxiv.org/abs/2511.12503)
*Fereidoon Zangeneh,Leonard Bruns,Amit Dekel,Alessandro Pieropan,Patric Jensfelt*

Main category: cs.CV

TL;DR: 提出一种基于神经网络的直接映射方法，将图像观测映射到可见场景结构，从而减少2D-3D匹配搜索空间，实现高效、低存储的相机位姿估计。


<details>
  <summary>Details</summary>
Motivation: 现有基于结构的重定位方法依赖图像检索或启发式搜索，导致流程复杂或存储开销随观测数量增长，难以在大场景中高效运行。

Method: 设计一个紧凑的神经网络（可见结构检索网络），通过学习从输入图像直接预测其可见的3D结构点子集，缩小2D-3D对应搜索范围。

Result: 所提方法在定位精度上达到与现有最先进方法相当的水平，同时显著降低计算和存储开销。

Conclusion: 通过学习图像到可见结构的直接映射，为结构化重定位提供了一种更高效、可扩展的新范式。

Abstract: Accurate camera pose estimation from an image observation in a previously mapped environment is commonly done through structure-based methods: by finding correspondences between 2D keypoints on the image and 3D structure points in the map. In order to make this correspondence search tractable in large scenes, existing pipelines either rely on search heuristics, or perform image retrieval to reduce the search space by comparing the current image to a database of past observations. However, these approaches result in elaborate pipelines or storage requirements that grow with the number of past observations. In this work, we propose a new paradigm for making structure-based relocalisation tractable. Instead of relying on image retrieval or search heuristics, we learn a direct mapping from image observations to the visible scene structure in a compact neural network. Given a query image, a forward pass through our novel visible structure retrieval network allows obtaining the subset of 3D structure points in the map that the image views, thus reducing the search space of 2D-3D correspondences. We show that our proposed method enables performing localisation with an accuracy comparable to the state of the art, while requiring lower computational and storage footprint.

</details>


### [134] [DINO-Detect: A Simple yet Effective Framework for Blur-Robust AI-Generated Image Detection](https://arxiv.org/abs/2511.12511)
*Jialiang Shen,Jiyang Zheng,Yunqi Xue,Huajie Chen,Yu Yao,Hui Kang,Ruiqi Liu,Helin Gong,Yang Yang,Dadong Wang,Tongliang Liu*

Main category: cs.CV

TL;DR: 提出一种基于教师-学生知识蒸馏的模糊鲁棒AI生成图像检测框架，利用在清晰图像上训练的高容量教师模型（DINOv3）指导学生模型学习，在运动模糊和清晰条件下均实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在现实世界中的退化（尤其是运动模糊）下表现显著下降，因模糊会破坏纹理并抑制高频伪影，导致实际应用受限。

Method: 采用教师-学生知识蒸馏框架：教师模型（DINOv3）在清晰图像上训练并固定，提供稳定且语义丰富的特征和logit响应；学生模型在模糊图像上训练，通过蒸馏学习教师的知识，从而在模糊条件下保持一致的表示能力。

Result: 实验表明，该方法在运动模糊和清晰条件下均达到最先进水平，显著提升了模型的泛化能力和现实适用性。

Conclusion: 所提出的模糊鲁棒检测框架有效克服了运动模糊对AI生成图像检测的影响，通过知识蒸馏实现了跨退化条件下的稳定性能，推动了该技术在真实场景中的应用。

Abstract: With growing concerns over image authenticity and digital safety, the field of AI-generated image (AIGI) detection has progressed rapidly. Yet, most AIGI detectors still struggle under real-world degradations, particularly motion blur, which frequently occurs in handheld photography, fast motion, and compressed video. Such blur distorts fine textures and suppresses high-frequency artifacts, causing severe performance drops in real-world settings. We address this limitation with a blur-robust AIGI detection framework based on teacher-student knowledge distillation. A high-capacity teacher (DINOv3), trained on clean (i.e., sharp) images, provides stable and semantically rich representations that serve as a reference for learning. By freezing the teacher to maintain its generalization ability, we distill its feature and logit responses from sharp images to a student trained on blurred counterparts, enabling the student to produce consistent representations under motion degradation. Extensive experiments benchmarks show that our method achieves state-of-the-art performance under both motion-blurred and clean conditions, demonstrating improved generalization and real-world applicability. Source codes will be released at: https://github.com/JiaLiangShen/Dino-Detect-for-blur-robust-AIGC-Detection.

</details>


### [135] [MdaIF: Robust One-Stop Multi-Degradation-Aware Image Fusion with Language-Driven Semantics](https://arxiv.org/abs/2511.12525)
*Jing Li,Yifan Wang,Jiafeng Yan,Renlong Zhang,Bin Yang*

Main category: cs.CV

TL;DR: 提出了一种基于大语言模型的退化感知红外与可见光图像融合框架MdaIF，通过混合专家系统和视觉-语言模型提取多退化场景下的语义先验，结合退化感知通道注意力模块实现自适应特征交互，显著提升了复杂天气下的融合性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分考虑恶劣天气下可见光图像的退化问题，且网络结构固定，难以适应多样化的退化场景，导致融合性能下降。

Method: 引入混合专家（MoE）系统应对多种退化场景，利用预训练的视觉-语言模型（VLM）提取退化知识与场景特征作为语义先验，设计退化感知通道注意力模块（DCAM）进行通道域上的多模态特征交互，并利用语义先验指导MoE实现专家路由。

Result: 实验表明MdaIF在多种退化场景下均优于当前最先进方法，具备更强的适应性和鲁棒性。

Conclusion: 所提MdaIF框架通过语义先验引导的动态架构，有效解决了多退化场景下的红外与可见光图像融合难题，具有良好的应用前景。

Abstract: Infrared and visible image fusion aims to integrate complementary multi-modal information into a single fused result. However, existing methods 1) fail to account for the degradation visible images under adverse weather conditions, thereby compromising fusion performance; and 2) rely on fixed network architectures, limiting their adaptability to diverse degradation scenarios. To address these issues, we propose a one-stop degradation-aware image fusion framework for multi-degradation scenarios driven by a large language model (MdaIF). Given the distinct scattering characteristics of different degradation scenarios (e.g., haze, rain, and snow) in atmospheric transmission, a mixture-of-experts (MoE) system is introduced to tackle image fusion across multiple degradation scenarios. To adaptively extract diverse weather-aware degradation knowledge and scene feature representations, collectively referred to as the semantic prior, we employ a pre-trained vision-language model (VLM) in our framework. Guided by the semantic prior, we propose degradation-aware channel attention module (DCAM), which employ degradation prototype decomposition to facilitate multi-modal feature interaction in channel domain. In addition, to achieve effective expert routing, the semantic prior and channel-domain modulated features are utilized to guide the MoE, enabling robust image fusion in complex degradation scenarios. Extensive experiments validate the effectiveness of our MdaIF, demonstrating superior performance over SOTA methods.

</details>


### [136] [D$^{2}$-VPR: A Parameter-efficient Visual-foundation-model-based Visual Place Recognition Method via Knowledge Distillation and Deformable Aggregation](https://arxiv.org/abs/2511.12528)
*Zheyuan Zhang,Jiwei Zhang,Boyu Zhou,Linzhimeng Duan,Hong Chen*

Main category: cs.CV

TL;DR: 提出了一种名为 $D^{2}$-VPR 的新框架，结合知识蒸馏与可变形聚合器，在保持视觉基础模型强特征提取能力的同时显著降低模型复杂度和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于DINOv2等视觉基础模型的视觉位置识别（VPR）方法虽然性能优越，但模型复杂、计算开销大，难以部署在资源受限设备上。

Method: 采用两阶段训练策略，结合知识蒸馏与微调，并引入蒸馏恢复模块（DRM）以减少教师与学生模型间的特征空间差异；设计基于自上而下注意力的可变形聚合器（TDDA），利用全局语义动态调整感兴趣区域进行特征聚合。

Result: 相比CricaVPR，参数减少约64.2%，FLOPs降低约62.6%，同时在多个实验中达到与当前最先进方法相当的性能。

Conclusion: $D^{2}$-VPR在显著提升效率的同时保持了高性能，为在资源受限设备上部署VPR提供了有效解决方案。

Abstract: Visual Place Recognition (VPR) aims to determine the geographic location of a query image by retrieving its most visually similar counterpart from a geo-tagged reference database. Recently, the emergence of the powerful visual foundation model, DINOv2, trained in a self-supervised manner on massive datasets, has significantly improved VPR performance. This improvement stems from DINOv2's exceptional feature generalization capabilities but is often accompanied by increased model complexity and computational overhead that impede deployment on resource-constrained devices. To address this challenge, we propose $D^{2}$-VPR, a $D$istillation- and $D$eformable-based framework that retains the strong feature extraction capabilities of visual foundation models while significantly reducing model parameters and achieving a more favorable performance-efficiency trade-off. Specifically, first, we employ a two-stage training strategy that integrates knowledge distillation and fine-tuning. Additionally, we introduce a Distillation Recovery Module (DRM) to better align the feature spaces between the teacher and student models, thereby minimizing knowledge transfer losses to the greatest extent possible. Second, we design a Top-Down-attention-based Deformable Aggregator (TDDA) that leverages global semantic features to dynamically and adaptively adjust the Regions of Interest (ROI) used for aggregation, thereby improving adaptability to irregular structures. Extensive experiments demonstrate that our method achieves competitive performance compared to state-of-the-art approaches. Meanwhile, it reduces the parameter count by approximately 64.2% and FLOPs by about 62.6% (compared to CricaVPR).Code is available at https://github.com/tony19980810/D2VPR.

</details>


### [137] [ReaSon: Reinforced Causal Search with Information Bottleneck for Video Understanding](https://arxiv.org/abs/2511.12530)
*Yuan Zhou,Litao Hua,Shilong Jin,Wentao Huang,Haoran Duan*

Main category: cs.CV

TL;DR: 提出ReaSon框架，通过因果信息瓶颈（CIB）优化关键帧选择，结合预测充分性和因果必要性，利用强化学习提升视频理解性能。


<details>
  <summary>Details</summary>
Motivation: 由于视觉语言模型输入token有限且视频中相关信息在时间上稀疏，需有效选择既具信息量又具因果决定性的关键帧。

Method: 将关键帧选择建模为优化问题，引入因果信息瓶颈（CIB），使用可学习策略网络从候选帧中选择满足预测充分性的关键帧，并通过反事实干预评估因果必要性，设计符合CIB原则的复合奖励函数指导强化学习。

Result: 在NExT-QA、EgoSchema和Video-MME数据集上实验表明，ReaSon在有限帧数设置下 consistently 优于现有最先进方法。

Conclusion: ReaSon通过联合优化预测充分性和因果必要性，有效提升了关键帧选择的质量和视频理解任务的性能，具有良好的泛化能力。

Abstract: Keyframe selection has become essential for video understanding with vision-language models (VLMs) due to limited input tokens and the temporal sparsity of relevant information across video frames. Video understanding often relies on effective keyframes that are not only informative but also causally decisive. To this end, we propose Reinforced Causal Search with Information Bottleneck (ReaSon), a framework that formulates keyframe selection as an optimization problem with the help of a novel Causal Information Bottleneck (CIB), which explicitly defines keyframes as those satisfying both predictive sufficiency and causal necessity. Specifically, ReaSon employs a learnable policy network to select keyframes from a visually relevant pool of candidate frames to capture predictive sufficiency, and then assesses causal necessity via counterfactual interventions. Finally, a composite reward aligned with the CIB principle is designed to guide the selection policy through reinforcement learning. Extensive experiments on NExT-QA, EgoSchema, and Video-MME demonstrate that ReaSon consistently outperforms existing state-of-the-art methods under limited-frame settings, validating its effectiveness and generalization ability.

</details>


### [138] [HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models](https://arxiv.org/abs/2511.12547)
*Zhiguang Lu,Qianqian Xu,Peisong Wen,Siran Da,Qingming Huang*

Main category: cs.CV

TL;DR: 提出了一种分层引导的细粒度增强方法HiGFA，通过在扩散采样过程中结合文本、轮廓和细粒度分类器的动态引导，生成既多样化又忠实于类别特征的合成图像。


<details>
  <summary>Details</summary>
Motivation: 现有生成扩散模型在细粒度任务中难以准确捕捉关键细微特征，可能导致生成误导性样本，影响分类性能。

Method: HiGFA在早期到中期采样阶段使用文本和变换后的轮廓进行强引导，建立整体场景、风格和结构；在最后阶段引入基于预测置信度动态调整强度的细粒度分类器引导，实现多信号的分层协同控制。

Result: 在多个细粒度视觉分类（FGVC）数据集上的实验表明，HiGFA能有效提升生成图像的质量和分类器性能。

Conclusion: HiGFA通过分层、动态调节的引导机制，成功平衡了全局结构与细节精炼，显著提升了细粒度图像生成与数据增强的效果。

Abstract: Generative diffusion models show promise for data augmentation. However, applying them to fine-grained tasks presents a significant challenge: ensuring synthetic images accurately capture the subtle, category-defining features critical for high fidelity. Standard approaches, such as text-based Classifier-Free Guidance (CFG), often lack the required specificity, potentially generating misleading examples that degrade fine-grained classifier performance. To address this, we propose Hierarchically Guided Fine-grained Augmentation (HiGFA). HiGFA leverages the temporal dynamics of the diffusion sampling process. It employs strong text and transformed contour guidance with fixed strengths in the early-to-mid sampling stages to establish overall scene, style, and structure. In the final sampling stages, HiGFA activates a specialized fine-grained classifier guidance and dynamically modulates the strength of all guidance signals based on prediction confidence. This hierarchical, confidence-driven orchestration enables HiGFA to generate diverse yet faithful synthetic images by intelligently balancing global structure formation with precise detail refinement. Experiments on several FGVC datasets demonstrate the effectiveness of HiGFA.

</details>


### [139] [EmoVerse: A MLLMs-Driven Emotion Representation Dataset for Interpretable Visual Emotion Analysis](https://arxiv.org/abs/2511.12554)
*Yijie Guo,Dexiang Hong,Weidong Chen,Zihan She,Cheng Ye,Xiaojun Chang,Zhendong Mao*

Main category: cs.CV

TL;DR: 本文提出了EmoVerse，一个大规模开源数据集，支持可解释的视觉情感分析，通过多层级、知识图谱启发的注释实现对图像情感的细粒度理解。


<details>
  <summary>Details</summary>
Motivation: 现有视觉情感分析研究受限于缺乏开放且可解释的数据集，通常仅对整张图像赋予单一情感标签，缺乏对视觉元素如何影响情感的深入洞察。

Method: 提出EmoVerse数据集，采用背景-属性-主体（B-A-S）三元组形式，将情感分解并关联到图像区域，实现词级和主体级的情感推理；包含21.9万张图像，提供类别化情感状态（CES）和维度情感空间（DES）双重标注，并设计了高效的多阶段标注流程和可解释模型。

Result: 构建了包含219k图像的大规模数据集，支持细粒度情感归因，实现了统一的离散与连续情感表示，并通过新型可解释模型有效映射视觉线索到情感空间。

Conclusion: EmoVerse为可解释的高级情感理解提供了全面基础，推动视觉情感分析向更透明、精细的方向发展。

Abstract: Visual Emotion Analysis (VEA) aims to bridge the affective gap between visual content and human emotional responses. Despite its promise, progress in this field remains limited by the lack of open-source and interpretable datasets. Most existing studies assign a single discrete emotion label to an entire image, offering limited insight into how visual elements contribute to emotion. In this work, we introduce EmoVerse, a large-scale open-source dataset that enables interpretable visual emotion analysis through multi-layered, knowledge-graph-inspired annotations. By decomposing emotions into Background-Attribute-Subject (B-A-S) triplets and grounding each element to visual regions, EmoVerse provides word-level and subject-level emotional reasoning. With over 219k images, the dataset further includes dual annotations in Categorical Emotion States (CES) and Dimensional Emotion Space (DES), facilitating unified discrete and continuous emotion representation. A novel multi-stage pipeline ensures high annotation reliability with minimal human effort. Finally, we introduce an interpretable model that maps visual cues into DES representations and provides detailed attribution explanations. Together, the dataset, pipeline, and model form a comprehensive foundation for advancing explainable high-level emotion understanding.

</details>


### [140] [SEMC: Structure-Enhanced Mixture-of-Experts Contrastive Learning for Ultrasound Standard Plane Recognition](https://arxiv.org/abs/2511.12559)
*Qing Cai,Guihao Yan,Fan Zhang,Cheng Zhang,Zhi Liu*

Main category: cs.CV

TL;DR: 提出了一种名为SEMC的新型结构增强混合专家对比学习框架，用于超声标准平面识别，结合结构感知特征融合与专家引导的对比学习，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能有效利用浅层结构信息，并且在通过图像增强生成的对比样本中难以捕捉细粒度语义差异，导致对超声标准平面的结构和判别细节识别效果不佳。

Method: 提出SEMC框架，包括语义-结构融合模块（SSFM）以融合多尺度结构信息并增强细粒度结构感知能力；设计混合专家对比识别模块（MCRM），利用MoE机制在多级特征上进行分层对比学习与分类。

Result: 在自建的大规模肝脏超声数据集及两个公开数据集上的实验表明，SEMC在各项指标上均优于最新的先进方法。

Conclusion: SEMC能更有效地捕捉超声图像中的结构和判别性细节，显著提升标准平面识别性能，具有良好的临床应用潜力。

Abstract: Ultrasound standard plane recognition is essential for clinical tasks such as disease screening, organ evaluation, and biometric measurement. However, existing methods fail to effectively exploit shallow structural information and struggle to capture fine-grained semantic differences through contrastive samples generated by image augmentations, ultimately resulting in suboptimal recognition of both structural and discriminative details in ultrasound standard planes. To address these issues, we propose SEMC, a novel Structure-Enhanced Mixture-of-Experts Contrastive learning framework that combines structure-aware feature fusion with expert-guided contrastive learning. Specifically, we first introduce a novel Semantic-Structure Fusion Module (SSFM) to exploit multi-scale structural information and enhance the model's ability to perceive fine-grained structural details by effectively aligning shallow and deep features. Then, a novel Mixture-of-Experts Contrastive Recognition Module (MCRM) is designed to perform hierarchical contrastive learning and classification across multi-level features using a mixture-of-experts (MoE) mechanism, further improving class separability and recognition performance. More importantly, we also curate a large-scale and meticulously annotated liver ultrasound dataset containing six standard planes. Extensive experimental results on our in-house dataset and two public datasets demonstrate that SEMC outperforms recent state-of-the-art methods across various metrics.

</details>


### [141] [Through-Foliage Surface-Temperature Reconstruction for early Wildfire Detection](https://arxiv.org/abs/2511.12572)
*Mohamed Youssef,Lukas Brunner,Klaus Rundhammer,Gerald Czech,Oliver Bimber*

Main category: cs.CV

TL;DR: 提出了一种结合信号处理与机器学习的新方法，通过自主无人机实现森林植被遮挡下的地表温度重建，用于早期野火监测。


<details>
  <summary>Details</summary>
Motivation: 现有合成孔径（SA）热成像虽能缓解树冠遮挡问题，但引入热模糊，难以识别地面火点；且缺乏真实训练数据限制了深度学习应用。

Method: 采用视觉状态空间模型从模糊的SA数据中恢复地表热信号，并利用潜扩散模型生成大量逼真的地表温度模拟数据，结合温度增强和程序化森林热模拟扩充训练集。

Result: 在模拟数据上，RMSE比传统热成像降低2-2.5倍；在实地高温热点检测中，RMSE改善达12.8倍（传统热成像）和2.6倍（未校正SA图像），并成功重建火灾与人体热信号的完整形态。

Conclusion: 该方法显著提升了遮挡环境下微弱热信号的检测能力，具备良好的泛化性，可用于无人机自动化野火早期预警及搜救任务。

Abstract: We introduce a novel method for reconstructing surface temperatures through occluding forest vegetation by combining signal processing and machine learning. Our goal is to enable fully automated aerial wildfire monitoring using autonomous drones, allowing for the early detection of ground fires before smoke or flames are visible. While synthetic aperture (SA) sensing mitigates occlusion from the canopy and sunlight, it introduces thermal blur that obscures the actual surface temperatures. To address this, we train a visual state space model to recover the subtle thermal signals of partially occluded soil and fire hotspots from this blurred data. A key challenge was the scarcity of real-world training data. We overcome this by integrating a latent diffusion model into a vector quantized to generated a large volume of realistic surface temperature simulations from real wildfire recordings, which we further expanded through temperature augmentation and procedural thermal forest simulation. On simulated data across varied ambient and surface temperatures, forest densities, and sunlight conditions, our method reduced the RMSE by a factor of 2 to 2.5 compared to conventional thermal and uncorrected SA imaging. In field experiments focused on high-temperature hotspots, the improvement was even more significant, with a 12.8-fold RMSE gain over conventional thermal and a 2.6-fold gain over uncorrected SA images. We also demonstrate our model's generalization to other thermal signals, such as human signatures for search and rescue. Since simple thresholding is frequently inadequate for detecting subtle thermal signals, the morphological characteristics are equally essential for accurate classification. Our experiments demonstrated another clear advantage: we reconstructed the complete morphology of fire and human signatures, whereas conventional imaging is defeated by partial occlusion.

</details>


### [142] [Beyond Pixels: Semantic-aware Typographic Attack for Geo-Privacy Protection](https://arxiv.org/abs/2511.12575)
*Jiayi Zhu,Yihao Huang,Yue Cao,Xiaojun Jia,Qing Guo,Felix Juefei-Xu,Geguang Pu,Bin Wang*

Main category: cs.CV

TL;DR: 提出一种基于语义感知的文本攻击方法，通过在图像外部添加欺骗性文本来有效保护用户地理位置隐私，同时保持图像视觉质量。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）能从社交媒体图像中推断用户地理位置，造成隐私泄露风险；现有对抗性扰动方法需强扰动，影响图像视觉质量。

Method: 探索文本语义对地理位置推理的干扰效果，设计两阶段、语义感知的文本攻击方法，在图像内容外添加具有欺骗性的文字扩展。

Result: 在三个数据集上对五种最先进的商业LVLM进行了实验，显著降低了其地理位置预测准确率。

Conclusion: 该方法为抵御LVLM带来的地理隐私威胁提供了一种实用且视觉无损的防护策略。

Abstract: Large Visual Language Models (LVLMs) now pose a serious yet overlooked privacy threat, as they can infer a social media user's geolocation directly from shared images, leading to unintended privacy leakage. While adversarial image perturbations provide a potential direction for geo-privacy protection, they require relatively strong distortions to be effective against LVLMs, which noticeably degrade visual quality and diminish an image's value for sharing. To overcome this limitation, we identify typographical attacks as a promising direction for protecting geo-privacy by adding text extension outside the visual content. We further investigate which textual semantics are effective in disrupting geolocation inference and design a two-stage, semantics-aware typographical attack that generates deceptive text to protect user privacy. Extensive experiments across three datasets demonstrate that our approach significantly reduces geolocation prediction accuracy of five state-of-the-art commercial LVLMs, establishing a practical and visually-preserving protection strategy against emerging geo-privacy threats.

</details>


### [143] [TempoMaster: Efficient Long Video Generation via Next-Frame-Rate Prediction](https://arxiv.org/abs/2511.12578)
*Yukuo Ma,Cong Liu,Junke Wang,Junqi Liu,Haibin Huang,Zuxuan Wu,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TempoMaster 是一种新颖的长视频生成框架，通过将生成过程视为下一帧率预测任务，先生成低帧率视频作为粗略蓝图，再逐步提升帧率以细化视觉和运动连续性。


<details>
  <summary>Details</summary>
Motivation: 现有的长视频生成方法在保持长时间的时序连贯性和高效生成方面存在挑战，需要一种既能保证视觉质量又能实现高效合成的新方法。

Method: TempoMaster 首先生成低帧率的视频片段作为整体序列的粗略蓝图，然后逐步提高帧率来增强细节；在每一帧率层级内使用双向注意力机制，并在帧率间进行自回归生成，从而实现长时程时序一致性与高效的并行合成。

Result: 大量实验表明，TempoMaster 在长视频生成任务中达到了最先进的性能，在视觉质量和时间连贯性方面均表现出色。

Conclusion: TempoMaster 通过分阶段提升帧率的策略和跨帧率的自回归建模，有效解决了长视频生成中的效率与一致性难题，为未来长视频生成提供了新的思路。

Abstract: We present TempoMaster, a novel framework that formulates long video generation as next-frame-rate prediction. Specifically, we first generate a low-frame-rate clip that serves as a coarse blueprint of the entire video sequence, and then progressively increase the frame rate to refine visual details and motion continuity. During generation, TempoMaster employs bidirectional attention within each frame-rate level while performing autoregression across frame rates, thus achieving long-range temporal coherence while enabling efficient and parallel synthesis. Extensive experiments demonstrate that TempoMaster establishes a new state-of-the-art in long video generation, excelling in both visual and temporal quality.

</details>


### [144] [Rank-Aware Agglomeration of Foundation Models for Immunohistochemistry Image Cell Counting](https://arxiv.org/abs/2511.12588)
*Zuqi Huang,Mengxin Tian,Huan Liu,Wentao Li,Baobao Liang,Jie Wu,Fang Yan,Zhaoqing Tang,Zhongyu Li*

Main category: cs.CV

TL;DR: 提出了一种基于排名感知聚合框架的CountIHC方法，通过从多个基础模型中选择性地蒸馏知识，实现免疫组化图像中的多类别细胞计数，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于染色重叠、生物标志物染色差异和细胞形态多样性，免疫组化图像中的准确细胞计数仍具挑战性；现有回归方法难以支持端到端多类别计数，且基础模型在此任务中的潜力尚未充分挖掘。

Method: 设计了Rank-Aware Teacher Selecting (RATS)策略，基于全局到局部patch排序评估教师模型的计数能力并进行样本级选择；通过多阶段蒸馏聚合多个强基础模型的知识，并引入视觉-语言对齐的微调阶段，利用结构化文本提示生成语义锚点以指导类别特异性密度图回归。

Result: 在12种IHC生物标志物和5种组织类型上超越了现有最先进方法，与病理学家评估高度一致，且在H&E染色数据上也表现出良好泛化能力。

Conclusion: CountIHC通过排名感知的知识选择和视觉-语言对齐的多类计数策略，有效应对IHC图像异质性，为细胞计数提供了一个高效、可扩展的解决方案。

Abstract: Accurate cell counting in immunohistochemistry (IHC) images is critical for quantifying protein expression and aiding cancer diagnosis. However, the task remains challenging due to the chromogen overlap, variable biomarker staining, and diverse cellular morphologies. Regression-based counting methods offer advantages over detection-based ones in handling overlapped cells, yet rarely support end-to-end multi-class counting. Moreover, the potential of foundation models remains largely underexplored in this paradigm. To address these limitations, we propose a rank-aware agglomeration framework that selectively distills knowledge from multiple strong foundation models, leveraging their complementary representations to handle IHC heterogeneity and obtain a compact yet effective student model, CountIHC. Unlike prior task-agnostic agglomeration strategies that either treat all teachers equally or rely on feature similarity, we design a Rank-Aware Teacher Selecting (RATS) strategy that models global-to-local patch rankings to assess each teacher's inherent counting capacity and enable sample-wise teacher selection. For multi-class cell counting, we introduce a fine-tuning stage that reformulates the task as vision-language alignment. Discrete semantic anchors derived from structured text prompts encode both category and quantity information, guiding the regression of class-specific density maps and improving counting for overlapping cells. Extensive experiments demonstrate that CountIHC surpasses state-of-the-art methods across 12 IHC biomarkers and 5 tissue types, while exhibiting high agreement with pathologists' assessments. Its effectiveness on H&E-stained data further confirms the scalability of the proposed method.

</details>


### [145] [Fine-Grained Representation for Lane Topology Reasoning](https://arxiv.org/abs/2511.12590)
*Guoqing Xu,Yiheng Li,Yang Yang*

Main category: cs.CV

TL;DR: 提出了一种细粒度车道拓扑推理框架TopoFG，通过引入空间和序列先验以及去噪策略，显著提升了复杂场景下车道拓扑的建模精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用单一查询表示车道，难以准确建模复杂车道结构，导致拓扑预测不可靠。

Method: 将BEV特征到拓扑预测的过程分为三个阶段：分层先验提取器（HPE）提取全局空间和局部序列先验；区域聚焦解码器（RFD）结合先验生成细粒度查询并进行特征细化；鲁棒边界点拓扑推理（RBTR）基于边界点特征建模车道连接性，并采用拓扑去噪策略减少匹配歧义。

Result: 在OpenLane-V2基准上取得新SOTA性能，subsetA上OLS为48.0%，subsetB上为45.4%。

Conclusion: TopoFG通过细粒度查询和去噪策略有效提升了复杂车道结构的拓扑预测精度和可靠性。

Abstract: Precise modeling of lane topology is essential for autonomous driving, as it directly impacts navigation and control decisions.Existing methods typically represent each lane with a single query and infer topological connectivity based on the similarity between lane queries.However, this kind of design struggles to accurately model complex lane structures, leading to unreliable topology prediction.In this view, we propose a Fine-Grained lane topology reasoning framework (TopoFG).It divides the procedure from bird's-eye-view (BEV) features to topology prediction via fine-grained queries into three phases, i.e., Hierarchical Prior Extractor (HPE), Region-Focused Decoder (RFD), and Robust Boundary-Point Topology Reasoning (RBTR).Specifically, HPE extracts global spatial priors from the BEV mask and local sequential priors from in-lane keypoint sequences to guide subsequent fine-grained query modeling.RFD constructs fine-grained queries by integrating the spatial and sequential priors. It then samples reference points in RoI regions of the mask and applies cross-attention with BEV features to refine the query representations of each lane.RBTR models lane connectivity based on boundary-point query features and further employs a topological denoising strategy to reduce matching ambiguity.By integrating spatial and sequential priors into fine-grained queries and applying a denoising strategy to boundary-point topology reasoning, our method precisely models complex lane structures and delivers trustworthy topology predictions.Extensive experiments on the OpenLane-V2 benchmark demonstrate that TopoFG achieves new state-of-the-art performance, with an OLS of 48.0% on subsetA and 45.4% on subsetB.

</details>


### [146] [Seg-VAR: Image Segmentation with Visual Autoregressive Modeling](https://arxiv.org/abs/2511.12594)
*Rongkun Zheng,Lu Qi,Xi Chen,Yi Wang,Kun Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 本文提出了Seg-VAR，一种将分割任务重新定义为条件自回归掩码生成问题的新框架，通过引入潜变量学习和多阶段训练策略，在多种分割任务上超越了以往方法。


<details>
  <summary>Details</summary>
Motivation: 视觉自回归模型在图像生成中已有应用，但在需要精细空间感知的分割任务中尚未探索。本文旨在探索其在分割中的潜力。

Method: 提出Seg-VAR框架，包含三个核心组件：图像编码器、空间感知的seglat编码器（将掩码映射为离散token）和解码器；采用多阶段训练策略，先联合训练图像-seglat表示，再优化潜在变换，最后对齐分布。

Result: 实验表明，Seg-VAR在多个分割任务和基准上优于此前的判别式和生成式方法。

Conclusion: 通过将分割视为序列化层次预测任务，Seg-VAR为将自回归推理引入空间感知视觉系统开辟了新路径。

Abstract: While visual autoregressive modeling (VAR) strategies have shed light on image generation with the autoregressive models, their potential for segmentation, a task that requires precise low-level spatial perception, remains unexplored. Inspired by the multi-scale modeling of classic Mask2Former-based models, we propose Seg-VAR, a novel framework that rethinks segmentation as a conditional autoregressive mask generation problem. This is achieved by replacing the discriminative learning with the latent learning process. Specifically, our method incorporates three core components: (1) an image encoder generating latent priors from input images, (2) a spatial-aware seglat (a latent expression of segmentation mask) encoder that maps segmentation masks into discrete latent tokens using a location-sensitive color mapping to distinguish instances, and (3) a decoder reconstructing masks from these latents. A multi-stage training strategy is introduced: first learning seglat representations via image-seglat joint training, then refining latent transformations, and finally aligning image-encoder-derived latents with seglat distributions. Experiments show Seg-VAR outperforms previous discriminative and generative methods on various segmentation tasks and validation benchmarks. By framing segmentation as a sequential hierarchical prediction task, Seg-VAR opens new avenues for integrating autoregressive reasoning into spatial-aware vision systems. Code will be available at https://github.com/rkzheng99/Seg-VAR.

</details>


### [147] [LoRA-Enhanced Vision Transformer for Single Image based Morphing Attack Detection via Knowledge Distillation from EfficientNet](https://arxiv.org/abs/2511.12602)
*Ria Shekhawat,Sushrut Patwardhan,Raghavendra Ramachandra,Praveen Kumar Chandaliya,Kishor P. Upla*

Main category: cs.CV

TL;DR: 提出一种基于教师-学生框架的单图像人脸合成攻击检测方法（S-MAD），结合CNN与ViT模型，并引入低秩适配（LoRA）进行高效微调，在多个公开人脸数据集构建的合成数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统易受合成图像攻击，现有检测方法在效率和泛化能力上存在不足。

Method: 采用CNN作为教师模型指导ViT学生模型学习，并利用LoRA技术对模型进行轻量级微调，提升检测效率与适应性。

Result: 在包含十种合成算法的自建数据集上，该方法优于六种先进S-MAD方法，具有更高的检测精度和更低的计算开销。

Conclusion: 所提方法在保持高检测性能的同时显著降低计算成本，适用于实际部署的人脸合成攻击检测。

Abstract: Face Recognition Systems (FRS) are critical for security but remain vulnerable to morphing attacks, where synthetic images blend biometric features from multiple individuals. We propose a novel Single-Image Morphing Attack Detection (S-MAD) approach using a teacher-student framework, where a CNN-based teacher model refines a ViT-based student model. To improve efficiency, we integrate Low-Rank Adaptation (LoRA) for fine-tuning, reducing computational costs while maintaining high detection accuracy. Extensive experiments are conducted on a morphing dataset built from three publicly available face datasets, incorporating ten different morphing generation algorithms to assess robustness. The proposed method is benchmarked against six state-of-the-art S-MAD techniques, demonstrating superior detection performance and computational efficiency.

</details>


### [148] [Pixels or Positions? Benchmarking Modalities in Group Activity Recognition](https://arxiv.org/abs/2511.12606)
*Drishya Karki,Merey Ramazanova,Anthony Cioppa,Silvio Giancola,Bernard Ghanem*

Main category: cs.CV

TL;DR: 本文提出了SoccerNet-GAR，一个包含广播视频和球员轨迹数据的多模态足球比赛数据集，用于比较像素（视频）与位置（跟踪）两种模态在群体活动识别（GAR）中的性能。通过统一评估协议，发现基于轨迹的图神经网络模型在准确率、训练速度和参数量方面均优于视频模型，表明位置模态和角色感知建模对GAR更为有效。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于视频模态进行群体活动识别，而对更紧凑且能显式编码空间交互的轨迹模态关注不足。缺乏同时对齐视频与跟踪数据的标准基准，限制了不同模态间的公平比较。因此，亟需构建多模态数据集以系统评估不同模态在GAR中的表现。

Method: 构建了SoccerNet-GAR数据集，包含64场2022年世界杯比赛的同步广播视频和球员轨迹数据，并标注了94,285个样本、10类群体活动。提出统一评估协议，对比两种强基线：基于视频的分类器与基于图神经网络的轨迹分类器。其中，轨迹模型引入角色感知图结构，通过位置边和时间注意力机制建模战术结构。

Result: 基于轨迹的模型达到67.2%的平衡准确率，显著高于最佳视频基线的58.1%，同时训练速度快4.25倍，参数量仅为197K，远少于视频模型的8630万。

Conclusion: 位置模态在群体活动识别中优于像素模态，且角色感知的图结构建模更高效有效。该研究强调了模态选择和结构化建模对GAR的重要性，推动未来在轨迹数据上的研究。

Abstract: Group Activity Recognition (GAR) is well studied on the video modality for surveillance and indoor team sports (e.g., volleyball, basketball). Yet, other modalities such as agent positions and trajectories over time, i.e. tracking, remain comparatively under-explored despite being compact, agent-centric signals that explicitly encode spatial interactions. Understanding whether pixel (video) or position (tracking) modalities leads to better group activity recognition is therefore important to drive further research on the topic. However, no standardized benchmark currently exists that aligns broadcast video and tracking data for the same group activities, leading to a lack of apples-to-apples comparison between these modalities for GAR. In this work, we introduce SoccerNet-GAR, a multimodal dataset built from the $64$ matches of the football World Cup 2022. Specifically, the broadcast videos and player tracking modalities for $94{,}285$ group activities are synchronized and annotated with $10$ categories. Furthermore, we define a unified evaluation protocol to benchmark two strong unimodal approaches: (i) a competitive video-based classifiers and (ii) a tracking-based classifiers leveraging graph neural networks. In particular, our novel role-aware graph architecture for tracking-based GAR directly encodes tactical structure through positional edges and temporal attention. Our tracking model achieves $67.2\%$ balanced accuracy compared to $58.1\%$ for the best video baseline, while training $4.25 \times$ faster with $438 \times$ fewer parameters ($197K$ \vs $86.3M$). This study provides new insights into the relative strengths of pixels and positions for group activity recognition. Overall, it highlights the importance of modality choice and role-aware modeling for GAR.

</details>


### [149] [Open-World Test-Time Adaptation with Hierarchical Feature Aggregation and Attention Affine](https://arxiv.org/abs/2511.12607)
*Ziqiong Liu,Yushun Tang,Junyang Ji,Zhihai He*

Main category: cs.CV

TL;DR: 提出了一种基于分层梯形网络（HLN）和注意力仿射网络（AAN）的测试时自适应方法，用于提升模型在分布外（OOD）样本和领域偏移下的鲁棒性和分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应方法在面对未知分布（OOD）样本时性能显著下降，易将OOD样本误分类为已知类，影响模型适应能力。需提升模型对OOD样本的识别能力和在领域偏移下的鲁棒性。

Method: 1. 构建分层梯形网络（HLN），聚合Transformer各层的类别token以提取OOD特征，并通过加权概率融合增强OOD检测；2. 提出注意力仿射网络（AAN），根据token信息自适应调整自注意力机制，提升领域偏移下的适应能力；3. 采用加权熵机制动态抑制低置信度样本在自适应过程中的影响。

Result: 在多个基准数据集上实验表明，该方法显著优于现有TTA方法，尤其在包含OOD样本和领域偏移的场景下，提升了分类准确率和模型鲁棒性。

Conclusion: 所提出的HLN和AAN结合策略有效增强了模型在测试阶段对OOD样本的识别能力和对领域偏移的适应性，通过动态权重机制进一步稳定了自适应过程，为复杂真实场景下的测试时自适应提供了有效解决方案。

Abstract: Test-time adaptation (TTA) refers to adjusting the model during the testing phase to cope with changes in sample distribution and enhance the model's adaptability to new environments. In real-world scenarios, models often encounter samples from unseen (out-of-distribution, OOD) categories. Misclassifying these as known (in-distribution, ID) classes not only degrades predictive accuracy but can also impair the adaptation process, leading to further errors on subsequent ID samples. Many existing TTA methods suffer substantial performance drops under such conditions. To address this challenge, we propose a Hierarchical Ladder Network that extracts OOD features from class tokens aggregated across all Transformer layers. OOD detection performance is enhanced by combining the original model prediction with the output of the Hierarchical Ladder Network (HLN) via weighted probability fusion. To improve robustness under domain shift, we further introduce an Attention Affine Network (AAN) that adaptively refines the self-attention mechanism conditioned on the token information to better adapt to domain drift, thereby improving the classification performance of the model on datasets with domain shift. Additionally, a weighted entropy mechanism is employed to dynamically suppress the influence of low-confidence samples during adaptation. Experimental results on benchmark datasets show that our method significantly improves the performance on the most widely used classification datasets.

</details>


### [150] [C3Net: Context-Contrast Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12627)
*Baber Jan,Aiman H. El-Maleh,Abdul Jabbar Siddiqui,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: 本文提出了C3Net，一种用于伪装物体检测（COD）的双通路解码器架构，通过边缘优化和上下文定位两个通路协同解决六项核心挑战，在多个基准上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的传统分割方法和基础模型在处理伪装物体时表现不佳，难以应对伪装物体与背景间的高度相似性及其他复合挑战，因此需要专门的架构创新来提升检测能力。

Method: 提出C3Net，包含两条通路：1）边缘优化通路使用梯度初始化的边缘增强模块从早期特征中恢复精确边界；2）上下文定位通路采用基于图像的上下文引导机制抑制内在显著性；两条通路通过空间门控的注意力融合模块进行协同融合。

Result: C3Net在COD10K、CAMO和NC4K数据集上分别取得了0.898、0.904和0.913的S-measure，达到当前最优水平，同时保持高效推理。

Conclusion: 复杂的伪装物体检测需要针对性的架构设计，C3Net通过双通路协同机制有效应对多种挑战，表明系统性集成优于单一改进。

Abstract: Camouflaged object detection identifies objects that blend seamlessly with their surroundings through similar colors, textures, and patterns. This task challenges both traditional segmentation methods and modern foundation models, which fail dramatically on camouflaged objects. We identify six fundamental challenges in COD: Intrinsic Similarity, Edge Disruption, Extreme Scale Variation, Environmental Complexities, Contextual Dependencies, and Salient-Camouflaged Object Disambiguation. These challenges frequently co-occur and compound the difficulty of detection, requiring comprehensive architectural solutions. We propose C3Net, which addresses all challenges through a specialized dual-pathway decoder architecture. The Edge Refinement Pathway employs gradient-initialized Edge Enhancement Modules to recover precise boundaries from early features. The Contextual Localization Pathway utilizes our novel Image-based Context Guidance mechanism to achieve intrinsic saliency suppression without external models. An Attentive Fusion Module synergistically combines the two pathways via spatial gating. C3Net achieves state-of-the-art performance with S-measures of 0.898 on COD10K, 0.904 on CAMO, and 0.913 on NC4K, while maintaining efficient processing. C3Net demonstrates that complex, multifaceted detection challenges require architectural innovation, with specialized components working synergistically to achieve comprehensive coverage beyond isolated improvements. Code, model weights, and results are available at https://github.com/Baber-Jan/C3Net.

</details>


### [151] [Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation](https://arxiv.org/abs/2511.12631)
*Yushe Cao,Dianxi Shi,Xing Fu,Xuechao Zou,Haikuo Peng,Xueqi Li,Chun Yu,Junliang Xing*

Main category: cs.CV

TL;DR: 本文提出了一种名为MDiTFace的扩散变换器框架，用于多模态人脸生成，通过统一的令牌化策略和新型解耦注意力机制，实现文本与语义掩码的高效融合，在保持性能的同时大幅降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统多模态特征融合方法在处理语义掩码和文本输入时难以实现有效的跨模态交互，导致生成效果不佳。

Method: 提出MDiTFace框架，采用统一令牌化策略处理多模态输入，设计堆叠的多元变换器块进行同步条件处理，并引入解耦注意力机制，分离动态与静态计算路径以支持特征缓存和重用。

Result: 实验表明，MDiTFace在人脸保真度和条件一致性方面显著优于现有方法，且通过静态路径缓存将掩码条件带来的额外计算开销降低了94%以上。

Conclusion: MDiTFace通过统一表示和高效注意力机制，实现了高性能、低开销的多模态人脸生成，为未来多模态扩散模型的设计提供了新思路。

Abstract: While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and text inputs, eliminating discrepancies between heterogeneous modality representations. The framework facilitates comprehensive multimodal feature interaction through stacked, newly designed multivariate transformer blocks that process all conditions synchronously. Additionally, we design a novel decoupled attention mechanism by dissociating implicit dependencies between mask tokens and temporal embeddings. This mechanism segregates internal computations into dynamic and static pathways, enabling caching and reuse of features computed in static pathways after initial calculation, thereby reducing additional computational overhead introduced by mask condition by over 94% while maintaining performance. Extensive experiments demonstrate that MDiTFace significantly outperforms other competing methods in terms of both facial fidelity and conditional consistency.

</details>


### [152] [Denoising Vision Transformer Autoencoder with Spectral Self-Regularization](https://arxiv.org/abs/2511.12633)
*Xunzhi Xiang,Xingye Tian,Guiyu Zhang,Yabo Chen,Shaofeng Zhang,Xuebo Wang,Xin Tao,Qi Fan*

Main category: cs.CV

TL;DR: 本文提出了一种基于谱自正则化和谱对齐策略的Denoising-VAE，用于解决高维潜在空间中冗余高频分量阻碍扩散模型收敛的问题，在不依赖视觉基础模型的情况下实现了更快的训练收敛和更优的生成与重建性能。


<details>
  <summary>Details</summary>
Motivation: 高维潜在空间虽可提升VAE重建质量，但其中冗余的高频成分会阻碍扩散模型的训练收敛，影响生成性能，现有方法依赖外部视觉基础模型进行正则化，缺乏有效且独立的解决方案。

Method: 提出谱自正则化策略以抑制高维潜在空间中的高频噪声并保持重建质量，设计ViT-based的Denoising-VAE架构，并引入谱对齐策略促进生成模型优化。

Result: 在ImageNet 256×256上实现2倍于SD-VAE的收敛速度，达到最优重建质量（rFID=0.28，PSNR=27.26）和具有竞争力的生成性能（gFID=1.82）。

Conclusion: Denoising-VAE通过谱域正则化有效改善了高维VAE潜在空间的优化问题，显著提升扩散模型的训练效率和生成质量，无需依赖外部视觉基础模型，为高性能生成系统提供了新思路。

Abstract: Variational autoencoders (VAEs) typically encode images into a compact latent space, reducing computational cost but introducing an optimization dilemma: a higher-dimensional latent space improves reconstruction fidelity but often hampers generative performance. Recent methods attempt to address this dilemma by regularizing high-dimensional latent spaces using external vision foundation models (VFMs). However, it remains unclear how high-dimensional VAE latents affect the optimization of generative models. To our knowledge, our analysis is the first to reveal that redundant high-frequency components in high-dimensional latent spaces hinder the training convergence of diffusion models and, consequently, degrade generation quality. To alleviate this problem, we propose a spectral self-regularization strategy to suppress redundant high-frequency noise while simultaneously preserving reconstruction quality. The resulting Denoising-VAE, a ViT-based autoencoder that does not rely on VFMs, produces cleaner, lower-noise latents, leading to improved generative quality and faster optimization convergence. We further introduce a spectral alignment strategy to facilitate the optimization of Denoising-VAE-based generative models. Our complete method enables diffusion models to converge approximately 2$\times$ faster than with SD-VAE, while achieving state-of-the-art reconstruction quality (rFID = 0.28, PSNR = 27.26) and competitive generation performance (gFID = 1.82) on the ImageNet 256$\times$256 benchmark.

</details>


### [153] [Medical Knowledge Intervention Prompt Tuning for Medical Image Classification](https://arxiv.org/abs/2511.12639)
*Ye Du,Nanxi Yu,Shujun Wang*

Main category: cs.CV

TL;DR: 提出CILMP方法，通过结合大语言模型（LLM）与视觉-语言模型（VLM）的提示调优，利用LLM提取疾病特异性特征并生成实例自适应提示，在多种医学图像分类任务中优于现有提示调优方法。


<details>
  <summary>Details</summary>
Motivation: 现有的提示调优方法难以精确区分不同医学概念，忽略了跨模态医学图像分类中的关键疾病特征；而大语言模型擅长捕捉专业医学知识，因此作者希望将其引入提示调优过程以增强语义精度。

Method: 提出CILMP（Conditional Intervention of Large Language Models for Prompt Tuning），从LLM中提取疾病特异性表征，在低秩线性子空间中进行干预，并结合条件机制根据每张医学图像生成实例自适应的提示，从而实现LLM向VLM的知识迁移。

Result: 在多个医学图像数据集上的实验表明，CILMP在性能上持续优于当前最先进的提示调优方法，验证了其有效性。

Conclusion: CILMP成功融合了LLM的医学知识与VLM的多模态理解能力，通过条件化干预机制提升了提示调优在医学图像分类中的表现，具备较强的适应性和应用潜力。

Abstract: Vision-language foundation models (VLMs) have shown great potential in feature transfer and generalization across a wide spectrum of medical-related downstream tasks. However, fine-tuning these models is resource-intensive due to their large number of parameters. Prompt tuning has emerged as a viable solution to mitigate memory usage and reduce training time while maintaining competitive performance. Nevertheless, the challenge is that existing prompt tuning methods cannot precisely distinguish different kinds of medical concepts, which miss essentially specific disease-related features across various medical imaging modalities in medical image classification tasks. We find that Large Language Models (LLMs), trained on extensive text corpora, are particularly adept at providing this specialized medical knowledge. Motivated by this, we propose incorporating LLMs into the prompt tuning process. Specifically, we introduce the CILMP, Conditional Intervention of Large Language Models for Prompt Tuning, a method that bridges LLMs and VLMs to facilitate the transfer of medical knowledge into VLM prompts. CILMP extracts disease-specific representations from LLMs, intervenes within a low-rank linear subspace, and utilizes them to create disease-specific prompts. Additionally, a conditional mechanism is incorporated to condition the intervention process on each individual medical image, generating instance-adaptive prompts and thus enhancing adaptability. Extensive experiments across diverse medical image datasets demonstrate that CILMP consistently outperforms state-of-the-art prompt tuning methods, demonstrating its effectiveness. Code is available at https://github.com/usr922/cilmp.

</details>


### [154] [DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry](https://arxiv.org/abs/2511.12653)
*Cheng Liao*

Main category: cs.CV

TL;DR: 本文提出了一种层次化量化优化框架DPVO-QAT++，通过异构精度设计和CUDA内核融合，在保持轨迹精度的同时显著提升了深度视觉里程计的运行效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习视觉SLAM系统虽然具有强大的几何推理能力，但高计算开销限制了其在资源受限平台上的部署。

Method: 采用可学习的尺度参数化、前后端异构精度设计（前端使用FP16/FP32模拟量化，后端保持全精度）以及GPU原生的CUDA内核融合技术进行优化。

Result: 在TartanAir和EuRoC数据集上，显著提升了帧率（分别提高52.1%和30.1%），降低了延迟和峰值GPU内存占用，同时保持了与原始DPVO模型相当的轨迹精度（ATE）。

Conclusion: DPVO-QAT++有效平衡了高精度深度视觉里程计与实际部署效率之间的矛盾，为嵌入式平台上的应用提供了可行的技术路径。

Abstract: Deep learning-based Visual SLAM (vSLAM) systems exhibit exceptional geometric reasoning capabilities, yet their prohibitive computational overhead severely restricts deployment on resource-constrained autonomous platforms. This paper presents a hierarchical quantization optimization framework, DPVO-QAT++ (DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry). Through the synergistic integration of learnable scale parameterization, a heterogeneous precision design for the Visual Odometry (VO) front-end and back-end (front-end floating-point fake quantization with FP16/FP32; back-end full precision), and GPU-native kernel fusion for fake quantization (custom CUDA kernels), our framework significantly reduces memory footprint and increases processing speed while preserving the trajectory accuracy of the original model. On the TartanAir dataset, our framework achieves an average FPS increase of 52.1%, a 29.1% reduction in median latency, and a 64.9% reduction in peak GPU memory reservation, while maintaining trajectory accuracy (ATE) comparable to the original DPVO model across 32 validation sequences. On the EuRoC dataset, it realizes an average FPS increase of 30.1%, a 23.1% reduction in median latency, and a 37.7% reduction in peak GPU memory reservation, maintaining comparable trajectory accuracy (ATE) across 11 validation sequences. Experimental results demonstrate that DPVO-QAT++ effectively bridges the gap between high-precision deep VO and the efficiency requirements for practical deployment, offering a viable engineering paradigm for the application of this technology on real-world embedded platforms.
  Keywords: Visual Odometry, Heterogeneous Precision Architecture, Quantization-Aware Training, CUDA Kernel Fusion, Scale-Only Training, Deep Patch Visual Odometry, GPU-Native Kernel Fusion.

</details>


### [155] [Toward Real-world Text Image Forgery Localization: Structured and Interpretable Data Synthesis](https://arxiv.org/abs/2511.12658)
*Zeqin Yu,Haotao Xie,Jian Zhang,Jiangqun Ni,Wenkan Su,Jiwu Huang*

Main category: cs.CV

TL;DR: 提出了一种基于傅里叶级数的文本图像篡改合成方法FSTS，通过分析真实篡改行为构建可解释的层次化模型，生成更贴近现实的训练数据，显著提升了文本图像伪造定位模型在真实场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本图像伪造定位方法因真实数据集规模有限以及合成数据与真实篡改之间存在分布差距，导致泛化性能差。

Method: 收集16,750个真实篡改实例，通过多格式日志记录人类编辑痕迹，分析个体和群体层面的行为模式，采用类似傅里叶级数的思想构建基础操作-参数组合的层次化模型，并从中采样生成逼真的篡改图像。

Result: 在四个评估协议上的实验表明，使用FSTS生成数据训练的模型在真实数据集上表现出显著更好的泛化性能。

Conclusion: FSTS提供了一种结构化、可解释的篡改合成框架，有效缩小了合成与真实数据之间的差距，提升了T-IFL模型的实用性。

Abstract: Existing Text Image Forgery Localization (T-IFL) methods often suffer from poor generalization due to the limited scale of real-world datasets and the distribution gap caused by synthetic data that fails to capture the complexity of real-world tampering. To tackle this issue, we propose Fourier Series-based Tampering Synthesis (FSTS), a structured and interpretable framework for synthesizing tampered text images. FSTS first collects 16,750 real-world tampering instances from five representative tampering types, using a structured pipeline that records human-performed editing traces via multi-format logs (e.g., video, PSD, and editing logs). By analyzing these collected parameters and identifying recurring behavioral patterns at both individual and population levels, we formulate a hierarchical modeling framework. Specifically, each individual tampering parameter is represented as a compact combination of basis operation-parameter configurations, while the population-level distribution is constructed by aggregating these behaviors. Since this formulation draws inspiration from the Fourier series, it enables an interpretable approximation using basis functions and their learned weights. By sampling from this modeled distribution, FSTS synthesizes diverse and realistic training data that better reflect real-world forgery traces. Extensive experiments across four evaluation protocols demonstrate that models trained with FSTS data achieve significantly improved generalization on real-world datasets. Dataset is available at \href{https://github.com/ZeqinYu/FSTS}{Project Page}.

</details>


### [156] [Hi-Reco: High-Fidelity Real-Time Conversational Digital Humans](https://arxiv.org/abs/2511.12662)
*Hongbin Huang,Junwei Li,Tianxin Xie,Zhuang Li,Cekai Weng,Yaodong Yang,Yue Luo,Li Liu,Jing Tang,Zhijing Shao,Zeyu Wang*

Main category: cs.CV

TL;DR: 提出了一种高保真、实时的对话式数字人系统，结合了逼真的3D头像、个性化语音合成和基于知识的对话生成，支持低延迟多模态交互。


<details>
  <summary>Details</summary>
Motivation: 实现视觉真实感与实时响应之间的平衡，提升数字人在交互应用中的自然性和可信度。

Method: 采用异步执行流水线协调多模态组件，并引入检索增强方法，包括历史增强和基于意图的路由，以提高对话连贯性和知识访问效率。

Result: 系统实现了低延迟的自然交互，支持唤醒词检测、情感化语调和上下文感知的高精度回应，显著提升了数字人的响应速度与表现力。

Conclusion: 该集成系统能够实现高保真、实时且可信的数字人交互，适用于通信、教育和娱乐等沉浸式应用场景。

Abstract: High-fidelity digital humans are increasingly used in interactive applications, yet achieving both visual realism and real-time responsiveness remains a major challenge. We present a high-fidelity, real-time conversational digital human system that seamlessly combines a visually realistic 3D avatar, persona-driven expressive speech synthesis, and knowledge-grounded dialogue generation. To support natural and timely interaction, we introduce an asynchronous execution pipeline that coordinates multi-modal components with minimal latency. The system supports advanced features such as wake word detection, emotionally expressive prosody, and highly accurate, context-aware response generation. It leverages novel retrieval-augmented methods, including history augmentation to maintain conversational flow and intent-based routing for efficient knowledge access. Together, these components form an integrated system that enables responsive and believable digital humans, suitable for immersive applications in communication, education, and entertainment.

</details>


### [157] [DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality](https://arxiv.org/abs/2511.12671)
*Tushar Anand,Advik Sinha,Abhijit Das*

Main category: cs.CV

TL;DR: 提出了一种基于非因果Mamba块的光学流和视差估计模型，能够在保持高精度的同时实现实时推理和低GPU占用。


<details>
  <summary>Details</summary>
Motivation: 为了在实时应用中实现准确且高效的3D密集感知任务（如光流和视差估计），需要平衡模型速度与精度。

Method: 提出一种基于非因果选择性状态空间的融合配对图像方法，构建非因果Mamba块模型以提升效率和速度。

Result: 该模型显著降低了推理时间，同时保持高精度和低GPU使用率，并在真实场景中得到验证。

Conclusion: 所提模型适用于统一的、实时且准确的3D密集感知任务，具有实际部署潜力。

Abstract: In this work, we propose an accurate and real-time optical flow and disparity estimation model by fusing pairwise input images in the proposed non-causal selective state space for dense perception tasks. We propose a non-causal Mamba block-based model that is fast and efficient and aptly manages the constraints present in a real-time applications. Our proposed model reduces inference times while maintaining high accuracy and low GPU usage for optical flow and disparity map generation. The results and analysis, and validation in real-life scenario justify that our proposed model can be used for unified real-time and accurate 3D dense perception estimation tasks. The code, along with the models, can be found at https://github.com/vimstereo/DensePerceptNCSSD

</details>


### [158] [Appreciate the View: A Task-Aware Evaluation Framework for Novel View Synthesis](https://arxiv.org/abs/2511.12675)
*Saar Stern,Ido Sobol,Or Litany*

Main category: cs.CV

TL;DR: 提出了一种任务感知的评估框架PRISM，利用Zero123模型特征和轻量微调来评估新视角合成（NVS）结果的真实性和保真度，包含基于参考的D_PRISM和无参考的MMD_PRISM两个指标，能在多个基准上稳定排序并符合人类偏好。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标难以准确衡量新视角合成结果的真实性与对源视图及目标视角变换的忠实性，尤其是在生成图像细微错误的情况下容易误判，因此需要一种更可靠、任务感知的评估方法。

Method: 利用强大的NVS基础模型Zero123提取特征，并通过轻量级微调提升判别能力；在此基础上设计两种评估指标：基于参考图像的D_PRISM和无参考的MMD_PRISM，用于量化生成结果的质量。

Result: 所提指标在Toys4K、GSO和OmniObject3D三个基准上对六种NVS方法实现了清晰稳定的排序，且与人类偏好高度一致，显著优于传统像素级或分布式指标。

Conclusion: PRISM提供了一种原理清晰且实用的新视角合成评估框架，有效弥补了当前评估方法的不足，有助于推动NVS领域更可靠的发展。

Abstract: The goal of Novel View Synthesis (NVS) is to generate realistic images of a given content from unseen viewpoints. But how can we trust that a generated image truly reflects the intended transformation? Evaluating its reliability remains a major challenge. While recent generative models, particularly diffusion-based approaches, have significantly improved NVS quality, existing evaluation metrics struggle to assess whether a generated image is both realistic and faithful to the source view and intended viewpoint transformation. Standard metrics, such as pixel-wise similarity and distribution-based measures, often mis-rank incorrect results as they fail to capture the nuanced relationship between the source image, viewpoint change, and generated output. We propose a task-aware evaluation framework that leverages features from a strong NVS foundation model, Zero123, combined with a lightweight tuning step to enhance discrimination. Using these features, we introduce two complementary evaluation metrics: a reference-based score, $D_{\text{PRISM}}$, and a reference-free score, $\text{MMD}_{\text{PRISM}}$. Both reliably identify incorrect generations and rank models in agreement with human preference studies, addressing a fundamental gap in NVS evaluation. Our framework provides a principled and practical approach to assessing synthesis quality, paving the way for more reliable progress in novel view synthesis. To further support this goal, we apply our reference-free metric to six NVS methods across three benchmarks: Toys4K, Google Scanned Objects (GSO), and OmniObject3D, where $\text{MMD}_{\text{PRISM}}$ produces a clear and stable ranking, with lower scores consistently indicating stronger models.

</details>


### [159] [BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections](https://arxiv.org/abs/2511.12676)
*Subin Varghese,Joshua Gao,Asad Ur Rahman,Vedhus Hoskere*

Main category: cs.CV

TL;DR: 本文提出了BridgeEQA，一个基于真实桥梁检测场景的具身问答（EQA）基准，包含2,200个开放词汇问题，结合专业检测报告与国家桥梁库存评分。同时提出EMVR方法，通过基于图像场景图的顺序导航提升多图推理与记忆能力，在新指标图像引用相关性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有具身问答研究缺乏贴近真实应用场景的基准，难以评估模型在复杂、长距离空间理解与多尺度推理下的表现。桥梁检测作为一个现实且结构化的任务领域，具备标准化评分体系和丰富的第一视角图像，适合作为新的EQA评测平台。

Method: 构建BridgeEQA数据集，基于200个真实桥梁场景的检测报告生成问题，并引入图像引用相关性作为新评估指标。提出EMVR方法，将检测过程建模为在图像节点构成的场景图上的马尔可夫决策过程，实现视觉证据的遍历、比较与推理。

Result: 实验表明现有视觉语言模型在 episodic memory EQA 设置下表现不佳；EMVR在BridgeEQA上显著优于基线模型，并在图像引用相关性指标上表现出更强的证据定位能力。

Conclusion: 桥梁检测是一个富有挑战且实用的EQA领域，BridgeEQA为开放词汇、多图像推理提供了新的测试平台，EMVR展示了结合结构化记忆与序列推理在复杂环境中的潜力。

Abstract: Deploying embodied agents that can answer questions about their surroundings in realistic real-world settings remains difficult, partly due to the scarcity of benchmarks that faithfully capture practical operating conditions. We propose infrastructure inspection as a compelling domain for open-vocabulary Embodied Question Answering (EQA): it naturally demands multi-scale reasoning, long-range spatial understanding, and complex semantic relationships, while offering unique evaluation advantages via standardized National Bridge Inventory (NBI) condition ratings (0-9), professional inspection reports, and egocentric imagery.
  We introduce BridgeEQA, a benchmark of 2,200 open-vocabulary question-answer pairs (in the style of OpenEQA) grounded in professional inspection reports across 200 real-world bridge scenes with 47.93 images on average per scene. Questions require synthesizing visual evidence across multiple images and aligning responses with NBI condition ratings. We further propose a new EQA metric Image Citation Relevance to evaluate the ability of a model to cite relevant images.
  Evaluations of state-of-the-art vision-language models reveal substantial performance gaps under episodic memory EQA settings. To address this, we propose Embodied Memory Visual Reasoning (EMVR), which formulates inspection as sequential navigation over an image-based scene graph: images are nodes, and an agent takes actions to traverse views, compare evidence, and reason within a Markov decision process. EMVR shows strong performance over the baselines. We publicly release both the dataset and code.

</details>


### [160] [R$^{2}$Seg: Training-Free OOD Medical Tumor Segmentation via Anatomical Reasoning and Statistical Rejection](https://arxiv.org/abs/2511.12691)
*Shuaike Shen,Ke Liu,Jiaqing Xie,Shangde Gao,Chunhua Shen,Ge Liu,Mireia Crispin-Ortuzar,Shangqi Gao*

Main category: cs.CV

TL;DR: 提出R²Seg，一种无需训练的两阶段Reason-and-Reject框架，用于提升医学图像分割中对分布外肿瘤的鲁棒性，通过LLM引导的解剖推理和统计拒绝机制有效抑制假阳性。


<details>
  <summary>Details</summary>
Motivation: 基础模型在分布外（OOD）场景下容易产生碎片化的假阳性肿瘤分割结果，缺乏鲁棒性。

Method: 采用两阶段框架：第一阶段利用LLM指导的解剖推理定位器官锚点并生成多尺度ROI；第二阶段在冻结的基础模型（BiomedParse）生成的候选区域上应用双样本统计检验，仅保留与正常组织显著不同的候选区域以抑制假阳性。

Result: 在多中心、多模态肿瘤分割基准上，R²Seg显著优于强基线和原始基础模型，提升了Dice系数、特异性和敏感性。

Conclusion: R²Seg作为一种无需训练的框架，兼容测试时增强且避免灾难性遗忘，在OOD肿瘤分割中实现了更高的鲁棒性和准确性。

Abstract: Foundation models for medical image segmentation struggle under out-of-distribution (OOD) shifts, often producing fragmented false positives on OOD tumors. We introduce R$^{2}$Seg, a training-free framework for robust OOD tumor segmentation that operates via a two-stage Reason-and-Reject process. First, the Reason step employs an LLM-guided anatomical reasoning planner to localize organ anchors and generate multi-scale ROIs. Second, the Reject step applies two-sample statistical testing to candidates generated by a frozen foundation model (BiomedParse) within these ROIs. This statistical rejection filter retains only candidates significantly different from normal tissue, effectively suppressing false positives. Our framework requires no parameter updates, making it compatible with zero-update test-time augmentation and avoiding catastrophic forgetting. On multi-center and multi-modal tumor segmentation benchmarks, R$^{2}$Seg substantially improves Dice, specificity, and sensitivity over strong baselines and the original foundation models. Code are available at https://github.com/Eurekashen/R2Seg.

</details>


### [161] [HEDGE: Hallucination Estimation via Dense Geometric Entropy for VQA with Vision-Language Models](https://arxiv.org/abs/2511.12693)
*Sushant Gautam,Michael A. Riegler,Pål Halvorsen*

Main category: cs.CV

TL;DR: HEDGE是一个用于检测视觉语言模型（VLM）幻觉的统一框架，结合了视觉扰动、语义聚类和不确定性度量，适用于多种多模态架构。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在开放性视觉问答中容易产生幻觉，缺乏可靠且通用的幻觉检测方法。

Method: 提出HEDGE框架，整合了可控视觉扰动、语义聚类（基于蕴含和嵌入）和不确定性度量（如VASE），构建可复现的检测流程，并在多个VLM上评估不同因素的影响。

Result: 实验表明Qwen2.5-VL等密集视觉token化模型更易检测幻觉，嵌入式聚类在答案直接分析时表现更好，VASE指标最稳定，且提示设计显著影响检测效果。

Conclusion: HEDGE为多模态可靠性评估提供了原理清晰、计算感知的基础，通过hedge-bench工具支持可复现和可扩展的基准测试。

Abstract: Vision-language models (VLMs) enable open-ended visual question answering but remain prone to hallucinations. We present HEDGE, a unified framework for hallucination detection that combines controlled visual perturbations, semantic clustering, and robust uncertainty metrics. HEDGE integrates sampling, distortion synthesis, clustering (entailment- and embedding-based), and metric computation into a reproducible pipeline applicable across multimodal architectures.
  Evaluations on VQA-RAD and KvasirVQA-x1 with three representative VLMs (LLaVA-Med, Med-Gemma, Qwen2.5-VL) reveal clear architecture- and prompt-dependent trends. Hallucination detectability is highest for unified-fusion models with dense visual tokenization (Qwen2.5-VL) and lowest for architectures with restricted tokenization (Med-Gemma). Embedding-based clustering often yields stronger separation when applied directly to the generated answers, whereas NLI-based clustering remains advantageous for LLaVA-Med and for longer, sentence-level responses. Across configurations, the VASE metric consistently provides the most robust hallucination signal, especially when paired with embedding clustering and a moderate sampling budget (n ~ 10-15). Prompt design also matters: concise, label-style outputs offer clearer semantic structure than syntactically constrained one-sentence responses.
  By framing hallucination detection as a geometric robustness problem shaped jointly by sampling scale, prompt structure, model architecture, and clustering strategy, HEDGE provides a principled, compute-aware foundation for evaluating multimodal reliability. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE .

</details>


### [162] [X-VMamba: Explainable Vision Mamba](https://arxiv.org/abs/2511.12694)
*Mohamed A. Mabrok,Yalda Zafari*

Main category: cs.CV

TL;DR: 提出基于可控性的可解释框架，用于分析视觉SSM模型中输入序列对内部状态动态的影响，揭示了SSM在不同层次上的空间信息处理机制。


<details>
  <summary>Details</summary>
Motivation: 缺乏类似注意力的透明机制来理解Vision SSM如何处理空间信息。

Method: 提出两种互补方法：适用于任何SSM架构的Jacobian-based方法和针对对角SSM的快速Gramian-based解析解法，均无需修改架构或调参。

Result: 在三种医学图像模态上验证，发现SSM具有从浅层扩散纹理到深层聚焦临床模式的分层特征 refine 机制，并揭示出与诊断标准一致的领域特异性可控性特征。

Conclusion: 该框架建立了可控性分析作为跨领域的SSM统一可解释范式。

Abstract: State Space Models (SSMs), particularly the Mamba architecture, have recently emerged as powerful alternatives to Transformers for sequence modeling, offering linear computational complexity while achieving competitive performance. Yet, despite their effectiveness, understanding how these Vision SSMs process spatial information remains challenging due to the lack of transparent, attention-like mechanisms. To address this gap, we introduce a controllability-based interpretability framework that quantifies how different parts of the input sequence (tokens or patches) influence the internal state dynamics of SSMs. We propose two complementary formulations: a Jacobian-based method applicable to any SSM architecture that measures influence through the full chain of state propagation, and a Gramian-based approach for diagonal SSMs that achieves superior speed through closed-form analytical solutions. Both methods operate in a single forward pass with linear complexity, requiring no architectural modifications or hyperparameter tuning. We validate our framework through experiments on three diverse medical imaging modalities, demonstrating that SSMs naturally implement hierarchical feature refinement from diffuse low-level textures in early layers to focused, clinically meaningful patterns in deeper layers. Our analysis reveals domain-specific controllability signatures aligned with diagnostic criteria, progressive spatial selectivity across the network hierarchy, and the substantial influence of scanning strategies on attention patterns. Beyond medical imaging, we articulate applications spanning computer vision, natural language processing, and cross-domain tasks. Our framework establishes controllability analysis as a unified, foundational interpretability paradigm for SSMs across all domains. Code and analysis tools will be made available upon publication

</details>


### [163] [Counting Through Occlusion: Framework for Open World Amodal Counting](https://arxiv.org/abs/2511.12702)
*Safaeid Hossain Arib,Rabeya Akter,Abdul Monaf Chowdhury,Md Jubair Ahmed Sourov,Md Mehedi Hasan*

Main category: cs.CV

TL;DR: 本文提出了一种名为CountOCC的遮挡场景下物体计数新方法，通过多模态引导和视觉等价性目标，在特征层面重建被遮挡物体，显著提升了现有方法在复杂场景中的计数性能。


<details>
  <summary>Details</summary>
Motivation: 现有物体计数方法在遮挡情况下表现不佳，因其骨干网络编码的是遮挡表面而非目标物体，导致特征表示失真，限制了实际应用。

Method: 提出CountOCC框架，利用可见片段的空间上下文与文本及视觉嵌入的语义先验，分层生成被遮挡区域的完整、类别判别性特征；引入视觉等价性目标，确保遮挡与非遮挡场景在注意力空间的一致性。

Result: 在FSC147上验证集和测试集的MAE分别降低26.72%和20.80%，在CARPK上MAE降低49.89%，在CAPTUREReal上降低28.79%，实现了多个数据集上的SOTA性能。

Conclusion: CountOCC通过显式重建被遮挡物体特征并保持注意力一致性，有效解决了遮挡下的物体计数难题，展现出强大的泛化能力和跨域鲁棒性。

Abstract: Object counting has achieved remarkable success on visible instances, yet state-of-the-art (SOTA) methods fail under occlusion, a pervasive challenge in real world deployment. This failure stems from a fundamental architectural limitation where backbone networks encode occluding surfaces rather than target objects, thereby corrupting the feature representations required for accurate enumeration. To address this, we present CountOCC, an amodal counting framework that explicitly reconstructs occluded object features through hierarchical multimodal guidance. Rather than accepting degraded encodings, we synthesize complete representations by integrating spatial context from visible fragments with semantic priors from text and visual embeddings, generating class-discriminative features at occluded locations across multiple pyramid levels. We further introduce a visual equivalence objective that enforces consistency in attention space, ensuring that both occluded and unoccluded views of the same scene produce spatially aligned gradient-based attention maps. Together, these complementary mechanisms preserve discriminative properties essential for accurate counting under occlusion. For rigorous evaluation, we establish occlusion-augmented versions of FSC 147 and CARPK spanning both structured and unstructured scenes. CountOCC achieves SOTA performance on FSC 147 with 26.72% and 20.80% MAE reduction over prior baselines under occlusion in validation and test, respectively. CountOCC also demonstrates exceptional generalization by setting new SOTA results on CARPK with 49.89% MAE reduction and on CAPTUREReal with 28.79% MAE reduction, validating robust amodal counting across diverse visual domains. Code will be released soon.

</details>


### [164] [FSDAM: Few-Shot Driving Attention Modeling via Vision-Language Coupling](https://arxiv.org/abs/2511.12708)
*Kaiser Hamid,Can Cui,Khandakar Ashrafi Akbar,Ziran Wang,Nade Liang*

Main category: cs.CV

TL;DR: 提出FSDAM框架，仅用约100个标注样本即可实现驾驶员注意力预测与解释生成，显著减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员注意力模型依赖大规模标注数据集，收集和整理成本高，限制了实际应用。

Method: 提出双通路架构FSDAM，分别处理空间注意力预测和文本解释生成，并通过跨模态对齐保持语义一致性，实现少样本学习。

Result: 在极少监督下，FSDAM在注意力预测上表现优异，能生成连贯且符合上下文的解释，并在多个驾驶基准上展现出强零样本泛化能力。

Conclusion: 证明在低数据条件下也能构建高效的可解释驾驶员注意力系统，为数据受限场景下的实际部署提供了新可能。

Abstract: Understanding where drivers look and why they shift their attention is essential for autonomous systems that read human intent and justify their actions. Most existing models rely on large-scale gaze datasets to learn these patterns; however, such datasets are labor-intensive to collect and time-consuming to curate. We present FSDAM (Few-Shot Driver Attention Modeling), a framework that achieves joint attention prediction and caption generation with approximately 100 annotated examples, two orders of magnitude fewer than existing approaches. Our approach introduces a dual-pathway architecture where separate modules handle spatial prediction and caption generation while maintaining semantic consistency through cross-modal alignment. Despite minimal supervision, FSDAM achieves competitive performance on attention prediction, generates coherent, and context-aware explanations. The model demonstrates robust zero-shot generalization across multiple driving benchmarks. This work shows that effective attention-conditioned generation is achievable with limited supervision, opening new possibilities for practical deployment of explainable driver attention systems in data-constrained scenarios.

</details>


### [165] [Backdoor Attacks on Open Vocabulary Object Detectors via Multi-Modal Prompt Tuning](https://arxiv.org/abs/2511.12735)
*Ankita Raj,Chetan Arora*

Main category: cs.CV

TL;DR: 本文提出了针对开放词汇目标检测器（OVOD）的新型多模态后门攻击方法TrAP，通过在图像和文本模态中联合优化提示参数并结合视觉触发器，在不重训练模型权重的情况下实现隐蔽且高效的攻击。


<details>
  <summary>Details</summary>
Motivation: 随着OVOD在高风险场景中的应用增加，其安全性问题亟需研究；本文首次探讨了OVOD中的后门攻击，揭示了提示调优带来的新攻击面。

Method: 提出TrAP攻击方法，采用多模态方式联合优化图像与文本模态中的提示参数，并结合可学习的轻量级提示标记和视觉触发器；引入基于课程的学习策略逐步缩小触发器尺寸，提升小触发补丁下的攻击效果。

Result: 实验表明TrAP在多个数据集上实现了高攻击成功率，支持目标误分类和目标消失攻击，同时在干净样本上的性能优于零样本设置。

Conclusion: TrAP揭示了提示调优机制在开放词汇检测系统中的安全漏洞，表明即使不修改主干网络，仅通过提示优化也能植入有效后门，对实际部署中的模型安全构成严重威胁。

Abstract: Open-vocabulary object detectors (OVODs) unify vision and language to detect arbitrary object categories based on text prompts, enabling strong zero-shot generalization to novel concepts. As these models gain traction in high-stakes applications such as robotics, autonomous driving, and surveillance, understanding their security risks becomes crucial. In this work, we conduct the first study of backdoor attacks on OVODs and reveal a new attack surface introduced by prompt tuning. We propose TrAP (Trigger-Aware Prompt tuning), a multi-modal backdoor injection strategy that jointly optimizes prompt parameters in both image and text modalities along with visual triggers. TrAP enables the attacker to implant malicious behavior using lightweight, learnable prompt tokens without retraining the base model weights, thus preserving generalization while embedding a hidden backdoor. We adopt a curriculum-based training strategy that progressively shrinks the trigger size, enabling effective backdoor activation using small trigger patches at inference. Experiments across multiple datasets show that TrAP achieves high attack success rates for both object misclassification and object disappearance attacks, while also improving clean image performance on downstream datasets compared to the zero-shot setting.

</details>


### [166] [Direct Visual Grounding by Directing Attention of Visual Tokens](https://arxiv.org/abs/2511.12738)
*Parsa Esmaeilkhani,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 提出一种新的KL散度注意力损失（KLAL），通过直接监督视觉语言模型中视觉令牌的注意力，提升其在视觉任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 标准的下一词预测损失无法有效引导模型关注与问题相关的视觉令牌，导致回答错误。

Method: 引入KLAL损失函数，利用真实注意力图（来自合成数据的几何信息或真实图像的标注）对视觉令牌的注意力分布进行监督，使其在生成答案时更关注相关视觉内容。

Result: 在几何任务、指代定位和表达理解等任务上，模型性能显著提升；同时构建了一个新数据集用于评估VLM的线条追踪能力，发现现有商业VLM表现不佳。

Conclusion: 直接监督视觉令牌的注意力机制能有效提升VLM在视觉推理任务中的准确性和可解释性。

Abstract: Vision Language Models (VLMs) mix visual tokens and text tokens. A puzzling issue is the fact that visual tokens most related to the query receive little to no attention in the final layers of the LLM module of VLMs from the answer tokens, where all tokens are treated equally, in particular, visual and language tokens in the LLM attention layers. This fact may result in wrong answers to visual questions, as our experimental results confirm. It appears that the standard next-token prediction (NTP) loss provides an insufficient signal for directing attention to visual tokens. We hypothesize that a more direct supervision of the attention of visual tokens to corresponding language tokens in the LLM module of VLMs will lead to improved performance on visual tasks. To demonstrate that this is indeed the case, we propose a novel loss function that directly supervises the attention of visual tokens. It directly grounds the answer language tokens in images by directing their attention to the relevant visual tokens. This is achieved by aligning the attention distribution of visual tokens to ground truth attention maps with KL divergence. The ground truth attention maps are obtained from task geometry in synthetic cases or from standard grounding annotations (e.g., bounding boxes or point annotations) in real images, and are used inside the LLM for attention supervision without requiring new labels. The obtained KL attention loss (KLAL) when combined with NTP encourages VLMs to attend to relevant visual tokens while generating answer tokens. This results in notable improvements across geometric tasks, pointing, and referring expression comprehension on both synthetic and real-world data, as demonstrated by our experiments. We also introduce a new dataset to evaluate the line tracing abilities of VLMs. Surprisingly, even commercial VLMs do not perform well on this task.

</details>


### [167] [Deep Imbalanced Multi-Target Regression: 3D Point Cloud Voxel Content Estimation in Simulated Forests](https://arxiv.org/abs/2511.12740)
*Amirhossein Hassanzadeh,Bartosz Krawczyk,Michael Saunders,Rob Wible,Keith Krause,Dimah Dera,Jan van Aardt*

Main category: cs.CV

TL;DR: 本研究提出了一种基于KPConv的多目标回归方法，利用密度相关性加权策略从体素化LiDAR点云中推断体素内的细部结构信息（如树皮、叶片、土壤等占比），并通过敏感性分析揭示体素大小对估计精度的影响。


<details>
  <summary>Details</summary>
Motivation: 体素化虽能降低LiDAR数据处理的计算成本，但会丢失精细结构信息。本文旨在探索是否能从高层体素化点云数据中恢复低层次的体素内容信息，并解决类别不平衡问题。

Method: 采用Kernel Point Convolutions（KPConv）框架，结合成本敏感学习中的密度相关性（DBR）加权策略，使用加权MSE、Focal回归和正则化进行优化，实现对多种地物目标（树皮、叶片、土壤等）在体素内占有率的回归估计。

Result: 敏感性分析显示，较大体素尺寸（如2米）因变异性较低而误差更小；较小体素尺寸（如0.25或0.5米）尤其在冠层区域误差更高。树皮和叶片在小体素下的误差显著高于大体素，表明精细分辨率下冠层内容估计更具挑战性。

Conclusion: 体素大小的选择应根据具体应用需求权衡精度与分辨率，本研究填补了森林三维LiDAR点云在多目标回归不平衡学习模型及模拟数据集方面的空白。

Abstract: Voxelization is an effective approach to reduce the computational cost of processing Light Detection and Ranging (LiDAR) data, yet it results in a loss of fine-scale structural information. This study explores whether low-level voxel content information, specifically target occupancy percentage within a voxel, can be inferred from high-level voxelized LiDAR point cloud data collected from Digital Imaging and remote Sensing Image Generation (DIRSIG) software. In our study, the targets include bark, leaf, soil, and miscellaneous materials. We propose a multi-target regression approach in the context of imbalanced learning using Kernel Point Convolutions (KPConv). Our research leverages cost-sensitive learning to address class imbalance called density-based relevance (DBR). We employ weighted Mean Saquared Erorr (MSE), Focal Regression (FocalR), and regularization to improve the optimization of KPConv. This study performs a sensitivity analysis on the voxel size (0.25 - 2 meters) to evaluate the effect of various grid representations in capturing the nuances of the forest. This sensitivity analysis reveals that larger voxel sizes (e.g., 2 meters) result in lower errors due to reduced variability, while smaller voxel sizes (e.g., 0.25 or 0.5 meter) exhibit higher errors, particularly within the canopy, where variability is greatest. For bark and leaf targets, error values at smaller voxel size datasets (0.25 and 0.5 meter) were significantly higher than those in larger voxel size datasets (2 meters), highlighting the difficulty in accurately estimating within-canopy voxel content at fine resolutions. This suggests that the choice of voxel size is application-dependent. Our work fills the gap in deep imbalance learning models for multi-target regression and simulated datasets for 3D LiDAR point clouds of forests.

</details>


### [168] [SAGE: Saliency-Guided Contrastive Embeddings](https://arxiv.org/abs/2511.12744)
*Colton R. Crum,Adam Czajka*

Main category: cs.CV

TL;DR: 提出SAGE（显著性引导的对比嵌入）方法，通过在模型的潜在空间中引入人类显著性指导，提升分类性能并增强模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有显著性引导训练方法多局限于图像空间，依赖不可靠的内部模型机制，难以有效整合人类感知先验。

Method: 利用模型的潜在空间嵌入而非图像空间，结合显著性保持和退化信号增强，通过对比三元组损失引导模型关注显著特征，并使用logits分布进行合理性验证。

Result: 在开放集和闭集场景下均优于当前最先进的显著性方法，适用于多种主干网络，并表现出良好的任务泛化性。

Conclusion: SAGE通过在潜在空间中进行显著性引导，有效整合人类感知先验，提升了模型的性能与鲁棒性。

Abstract: Integrating human perceptual priors into the training of neural networks has been shown to raise model generalization, serve as an effective regularizer, and align models with human expertise for applications in high-risk domains. Existing approaches to integrate saliency into model training often rely on internal model mechanisms, which recent research suggests may be unreliable. Our insight is that many challenges associated with saliency-guided training stem from the placement of the guidance approaches solely within the image space. Instead, we move away from the image space, use the model's latent space embeddings to steer human guidance during training, and we propose SAGE (Saliency-Guided Contrastive Embeddings): a loss function that integrates human saliency into network training using contrastive embeddings. We apply salient-preserving and saliency-degrading signal augmentations to the input and capture the changes in embeddings and model logits. We guide the model towards salient features and away from non-salient features using a contrastive triplet loss. Additionally, we perform a sanity check on the logit distributions to ensure that the model outputs match the saliency-based augmentations. We demonstrate a boost in classification performance across both open- and closed-set scenarios against SOTA saliency-based methods, showing SAGE's effectiveness across various backbones, and include experiments to suggest its wide generalization across tasks.

</details>


### [169] [Which Way from B to A: The role of embedding geometry in image interpolation for Stable Diffusion](https://arxiv.org/abs/2511.12757)
*Nicholas Karris,Luke Durell,Javier Flores,Tegan Emerson*

Main category: cs.CV

TL;DR: 提出将CLIP嵌入矩阵视为Wasserstein空间中的点云，利用最优传输进行嵌入插值，从而在Stable Diffusion中生成更平滑、连贯的图像过渡。


<details>
  <summary>Details</summary>
Motivation: Stable Diffusion对CLIP嵌入矩阵具有排列不变性，启发作者从几何角度重新理解嵌入空间结构。

Method: 将CLIP嵌入解释为Wasserstein空间中的点云，将插值问题重构为最优传输问题，并求解其测地路径以实现平滑过渡。

Result: 实验表明，相比传统插值方法，基于最优传输的方法生成的中间图像更平滑、连贯，验证了该视角的有效性。

Conclusion: 将嵌入视为点云并结合最优传输能更好揭示和利用嵌入空间的几何特性，提升Stable Diffusion的插值质量。

Abstract: It can be shown that Stable Diffusion has a permutation-invariance property with respect to the rows of Contrastive Language-Image Pretraining (CLIP) embedding matrices. This inspired the novel observation that these embeddings can naturally be interpreted as point clouds in a Wasserstein space rather than as matrices in a Euclidean space. This perspective opens up new possibilities for understanding the geometry of embedding space. For example, when interpolating between embeddings of two distinct prompts, we propose reframing the interpolation problem as an optimal transport problem. By solving this optimal transport problem, we compute a shortest path (or geodesic) between embeddings that captures a more natural and geometrically smooth transition through the embedding space. This results in smoother and more coherent intermediate (interpolated) images when rendered by the Stable Diffusion generative model. We conduct experiments to investigate this effect, comparing the quality of interpolated images produced using optimal transport to those generated by other standard interpolation methods. The novel optimal transport--based approach presented indeed gives smoother image interpolations, suggesting that viewing the embeddings as point clouds (rather than as matrices) better reflects and leverages the geometry of the embedding space.

</details>


### [170] [RoCoISLR: A Romanian Corpus for Isolated Sign Language Recognition](https://arxiv.org/abs/2511.12767)
*Cătălin-Alexandru Rîpanu,Andrei-Theodor Hotnog,Giulia-Stefania Imbrea,Dumitru-Clementin Cercel*

Main category: cs.CV

TL;DR: 本文介绍了用于罗马尼亚孤立手语识别（RoISLR）的第一个大规模标准化数据集RoCoISLR，包含9000多个视频样本和近6000个标准化词汇，并基于多个先进视频识别模型建立了基准结果，表明基于Transformer的模型表现更优，Swin Transformer取得了34.1%的Top-1准确率，该数据集为低资源手语识别研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 现有的手语识别数据集主要集中于美国手语，缺乏针对罗马尼亚手语的大规模标准化数据集，限制了相关研究的发展。

Method: 构建了一个名为RoCoISLR的新语料库，包含来自多个来源的9000多个视频样本和近6000个标准化词汇，并在统一实验设置下评估了七种先进的视频识别模型（I3D、SlowFast、Swin Transformer、TimeSformer、Uniformer、VideoMAE和PoseConv3D），与WLASL2000数据集进行性能对比。

Result: 基于Transformer的模型优于卷积基线模型，其中Swin Transformer取得了34.1%的Top-1准确率；实验还揭示了低资源手语中长尾类别分布带来的挑战。

Conclusion: RoCoISLR为罗马尼亚手语识别研究提供了首个大规模基准数据集，推动了低资源手语技术的发展，并凸显了未来在长尾分布和模型优化方面的研究方向。

Abstract: Automatic sign language recognition plays a crucial role in bridging the communication gap between deaf communities and hearing individuals; however, most available datasets focus on American Sign Language. For Romanian Isolated Sign Language Recognition (RoISLR), no large-scale, standardized dataset exists, which limits research progress. In this work, we introduce a new corpus for RoISLR, named RoCoISLR, comprising over 9,000 video samples that span nearly 6,000 standardized glosses from multiple sources. We establish benchmark results by evaluating seven state-of-the-art video recognition models-I3D, SlowFast, Swin Transformer, TimeSformer, Uniformer, VideoMAE, and PoseConv3D-under consistent experimental setups, and compare their performance with that of the widely used WLASL2000 corpus. According to the results, transformer-based architectures outperform convolutional baselines; Swin Transformer achieved a Top-1 accuracy of 34.1%. Our benchmarks highlight the challenges associated with long-tail class distributions in low-resource sign languages, and RoCoISLR provides the initial foundation for systematic RoISLR research.

</details>


### [171] [Enhancing Neuro-Oncology Through Self-Assessing Deep Learning Models for Brain Tumor Unified Model for MRI Segmentation](https://arxiv.org/abs/2511.12801)
*Andrew Zhou*

Main category: cs.CV

TL;DR: 提出一种不确定性感知的nnUNet扩展框架，同时实现脑肿瘤分割、周围正常脑结构建模及逐体素不确定性估计，提升临床可用性。


<details>
  <summary>Details</summary>
Motivation: 现有脑肿瘤分割方法缺乏不确定性估计和周围解剖结构信息，限制了其在临床手术规划中的应用。

Method: 在nnUNet基础上增加逐体素不确定性通道，并通过联合训练正常脑结构与肿瘤数据实现全脑上下文建模，单次前向传播输出分割结果与不确定性图。

Result: 在BraTS2023上达到肿瘤DSC 0.86，正常结构DSC 0.81，不确定性相关系数0.750，RMSD 0.047，关键区域表现稳健。

Conclusion: 该框架首次实现了肿瘤分割、周围解剖结构建模与不确定性估计的统一，生成直观的叠加不确定性地图，有助于医生评估预测可靠性并支持手术决策。

Abstract: Accurate segmentation of brain tumors is vital for diagnosis, surgical planning, and treatment monitoring. Deep learning has advanced on benchmarks, but two issues limit clinical use: no uncertainty estimates for errors and no segmentation of healthy brain structures around tumors for surgery. Current methods fail to unify tumor localization with anatomical context and lack confidence scores. This study presents an uncertainty-aware framework augmenting nnUNet with a channel for voxel-wise uncertainty. Trained on BraTS2023, it yields a correlation of 0.750 and RMSD of 0.047 for uncertainty without hurting tumor accuracy. It predicts uncertainty in one pass, with no extra networks or inferences, aiding clinical decisions. For whole-brain context, a unified model combines normal and cancer datasets, achieving a DSC of 0.81 for brain structures and 0.86 for tumor, with robust key-region performance. Combining both innovations gives the first model outputting tumor in natural surroundings plus an overlaid uncertainty map. Visual checks of outputs show uncertainty offers key insights to evaluate predictions and fix errors, helping informed surgical decisions from AI.

</details>


### [172] [MSRNet: A Multi-Scale Recursive Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12810)
*Leena Alghamdi,Muhammad Usman,Hafeez Anwar,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: 提出了一种多尺度递归网络（MSRNet）用于伪装物体检测，结合金字塔视觉Transformer和注意力机制实现多尺度特征融合，并通过递归反馈解码策略提升对小尺寸和多个伪装物体的检测精度，在多个基准数据集上达到先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景下对小尺寸和多个伪装物体的检测仍不精确，需提升模型对多尺度特征和全局上下文的理解能力。

Method: 采用金字塔视觉Transformer作为骨干网络提取多尺度特征，设计基于注意力的尺度集成单元进行特征融合，并引入多粒度融合单元和递归反馈解码策略进行特征优化与精细化分割。

Result: 在两个伪装物体检测基准数据集上取得最先进的性能，其余两个数据集排名第二，验证了方法的有效性。

Conclusion: 所提方法通过多尺度学习与递归特征优化的联合策略，显著提升了复杂场景下伪装物体的检测精度，尤其适用于小尺寸和多个物体的场景。

Abstract: Camouflaged object detection is an emerging and challenging computer vision task that requires identifying and segmenting objects that blend seamlessly into their environments due to high similarity in color, texture, and size. This task is further complicated by low-light conditions, partial occlusion, small object size, intricate background patterns, and multiple objects. While many sophisticated methods have been proposed for this task, current methods still struggle to precisely detect camouflaged objects in complex scenarios, especially with small and multiple objects, indicating room for improvement. We propose a Multi-Scale Recursive Network that extracts multi-scale features via a Pyramid Vision Transformer backbone and combines them via specialized Attention-Based Scale Integration Units, enabling selective feature merging. For more precise object detection, our decoder recursively refines features by incorporating Multi-Granularity Fusion Units. A novel recursive-feedback decoding strategy is developed to enhance global context understanding, helping the model overcome the challenges in this task. By jointly leveraging multi-scale learning and recursive feature optimization, our proposed method achieves performance gains, successfully detecting small and multiple camouflaged objects. Our model achieves state-of-the-art results on two benchmark datasets for camouflaged object detection and ranks second on the remaining two. Our codes, model weights, and results are available at \href{https://github.com/linaagh98/MSRNet}{https://github.com/linaagh98/MSRNet}.

</details>


### [173] [SAGA: Source Attribution of Generative AI Videos](https://arxiv.org/abs/2511.12834)
*Rohit Kundu,Vishal Mohanty,Hao Xiong,Shan Jia,Athula Balachandran,Amit K. Roy-Chowdhury*

Main category: cs.CV

TL;DR: 本文提出了SAGA，首个大规模生成式AI视频源归因的综合框架，能识别生成视频的具体模型，并提供多粒度归因与可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI视频日益逼真，传统二元检测方法已无法满足需求，亟需能够精确溯源生成模型的技术以应对滥用风险。

Method: 提出SAGA框架，采用基于视觉基础模型的视频Transformer架构，结合数据高效的预训练与归因策略，并引入时间注意力签名（T-Sigs）实现归因结果的可视化解释。

Result: 在多个公开数据集上达到最先进性能，仅用0.5%标注数据即可匹配全监督效果，并在跨域场景中表现优异，同时提供可解释的时序特征差异。

Conclusion: SAGA实现了细粒度、可解释的生成视频溯源，为数字取证和监管提供了强有力的新工具。

Abstract: The proliferation of generative AI has led to hyper-realistic synthetic videos, escalating misuse risks and outstripping binary real/fake detectors. We introduce SAGA (Source Attribution of Generative AI videos), the first comprehensive framework to address the urgent need for AI-generated video source attribution at a large scale. Unlike traditional detection, SAGA identifies the specific generative model used. It uniquely provides multi-granular attribution across five levels: authenticity, generation task (e.g., T2V/I2V), model version, development team, and the precise generator, offering far richer forensic insights. Our novel video transformer architecture, leveraging features from a robust vision foundation model, effectively captures spatio-temporal artifacts. Critically, we introduce a data-efficient pretrain-and-attribute strategy, enabling SAGA to achieve state-of-the-art attribution using only 0.5\% of source-labeled data per class, matching fully supervised performance. Furthermore, we propose Temporal Attention Signatures (T-Sigs), a novel interpretability method that visualizes learned temporal differences, offering the first explanation for why different video generators are distinguishable. Extensive experiments on public datasets, including cross-domain scenarios, demonstrate that SAGA sets a new benchmark for synthetic video provenance, providing crucial, interpretable insights for forensic and regulatory applications.

</details>


### [174] [Video Finetuning Improves Reasoning Between Frames](https://arxiv.org/abs/2511.12868)
*Ruiqi Yang,Tian Yun,Zihan Wang,Ellie Pavlick*

Main category: cs.CV

TL;DR: 提出视觉链式思维（vCoT），用于分析视频微调对多模态大语言模型的影响，发现视频微调模型已隐式捕捉帧间转换。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法多基于图像帧的简单拼接，缺乏对时序推理机制的深入探究。

Method: 提出Visual Chain-of-Thought（vCoT），生成连续帧间的过渡事件描述，并系统比较图像模型与视频微调模型在有无过渡线索下的表现。

Result: vCoT显著提升纯图像模型在长视频问答中的性能，但对视频微调模型提升有限；视频模型能将在视频中学到的时序推理能力迁移到静态图像的关联推理任务中。

Conclusion: 视频微调使模型隐式学习到帧间过渡信息，具备更强的时序和关系推理能力，并可迁移至静态视觉任务。

Abstract: Multimodal large language models (LLMs) have made rapid progress in visual understanding, yet their extension from images to videos often reduces to a naive concatenation of frame tokens. In this work, we investigate what video finetuning brings to multimodal LLMs. We propose Visual Chain-of-Thought (vCoT), an explicit reasoning process that generates transitional event descriptions between consecutive frames. Using vCoT, we systematically compare image-only LVLMs with their video-finetuned counterparts, both with and without access to these transitional cues. Our experiments show that vCoT significantly improves the performance of image-only models on long-form video question answering, while yielding only marginal gains for video-finetuned models. This suggests that the latter already capture frame-to-frame transitions implicitly. Moreover, we find that video models transfer this temporal reasoning ability to purely static settings, outperforming image models' baselines on relational visual reasoning tasks.

</details>


### [175] [View-aware Cross-modal Distillation for Multi-view Action Recognition](https://arxiv.org/abs/2511.12870)
*Trung Thanh Nguyen,Yasutomo Kawanishi,Vijay John,Takahiro Komamizu,Ichiro Ide*

Main category: cs.CV

TL;DR: 提出了一种名为ViCoKD的跨模态知识蒸馏框架，用于解决部分重叠视角和有限模态下的多视角动作识别问题。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，多传感器系统常面临视角部分重叠、输入模态有限和仅有序列级标注的问题，现有方法难以有效应对。

Method: 设计了跨模态适配器与视图感知一致性模块，通过跨模态注意力和基于检测掩码的一致性约束，在教师-学生框架中实现知识蒸馏。

Result: 在MultiSensor-Home数据集上，ViCoKD在多种骨干网络和环境下均优于现有蒸馏方法，并在受限条件下超越教师模型。

Conclusion: ViCoKD能有效利用不完整多模态信息并提升少模态学生的性能，适用于实际多视角动作识别场景。

Abstract: The widespread use of multi-sensor systems has increased research in multi-view action recognition. While existing approaches in multi-view setups with fully overlapping sensors benefit from consistent view coverage, partially overlapping settings where actions are visible in only a subset of views remain underexplored. This challenge becomes more severe in real-world scenarios, as many systems provide only limited input modalities and rely on sequence-level annotations instead of dense frame-level labels. In this study, we propose View-aware Cross-modal Knowledge Distillation (ViCoKD), a framework that distills knowledge from a fully supervised multi-modal teacher to a modality- and annotation-limited student. ViCoKD employs a cross-modal adapter with cross-modal attention, allowing the student to exploit multi-modal correlations while operating with incomplete modalities. Moreover, we propose a View-aware Consistency module to address view misalignment, where the same action may appear differently or only partially across viewpoints. It enforces prediction alignment when the action is co-visible across views, guided by human-detection masks and confidence-weighted Jensen-Shannon divergence between their predicted class distributions. Experiments on the real-world MultiSensor-Home dataset show that ViCoKD consistently outperforms competitive distillation methods across multiple backbones and environments, delivering significant gains and surpassing the teacher model under limited conditions.

</details>


### [176] [Simple Lines, Big Ideas: Towards Interpretable Assessment of Human Creativity from Drawings](https://arxiv.org/abs/2511.12880)
*Zihao Lin,Zhenshan Shi,Sasa Zhao,Hanwei Zhu,Lingyu Zhu,Baoliang Chen,Lei Mo*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态多任务学习框架的绘画创造力自动评估方法，结合内容与风格双维度，通过条件学习机制实现可解释的创造力评分，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有创造力评估依赖专家主观打分，费时且主观性强，因此需要一种自动化、客观且可解释的数据驱动评估方法。

Method: 通过扩充带有创造力标签的数据集并添加内容类别标注，构建一个多模态多任务学习框架，联合预测创造力分数、分类内容类型并提取风格特征；引入条件学习机制，使模型根据绘画的语义和风格线索动态调整视觉特征提取过程。

Result: 所提模型在创造力评分任务上达到当前最优性能，优于回归基线方法，并能生成与人类判断一致的可解释可视化结果。

Conclusion: 该框架有效结合内容与风格双维度，实现了准确且可解释的绘画创造力自动评估，具有在教育和心理学等领域应用的潜力。

Abstract: Assessing human creativity through visual outputs, such as drawings, plays a critical role in fields including psychology, education, and cognitive science. However, current assessment practices still rely heavily on expert-based subjective scoring, which is both labor-intensive and inherently subjective. In this paper, we propose a data-driven framework for automatic and interpretable creativity assessment from drawings. Motivated by the cognitive understanding that creativity can emerge from both what is drawn (content) and how it is drawn (style), we reinterpret the creativity score as a function of these two complementary dimensions.Specifically, we first augment an existing creativity labeled dataset with additional annotations targeting content categories. Based on the enriched dataset, we further propose a multi-modal, multi-task learning framework that simultaneously predicts creativity scores, categorizes content types, and extracts stylistic features. In particular, we introduce a conditional learning mechanism that enables the model to adapt its visual feature extraction by dynamically tuning it to creativity-relevant signals conditioned on the drawing's stylistic and semantic cues.Experimental results demonstrate that our model achieves state-of-the-art performance compared to existing regression-based approaches and offers interpretable visualizations that align well with human judgments. The code and annotations will be made publicly available at https://github.com/WonderOfU9/CSCA_PRCV_2025

</details>


### [177] [ActVAR: Activating Mixtures of Weights and Tokens for Efficient Visual Autoregressive Generation](https://arxiv.org/abs/2511.12893)
*Kaixin Zhang,Ruiqing Yang,Yuan Zhang,Shan You,Tao Huang*

Main category: cs.CV

TL;DR: 提出了一种名为ActVAR的动态激活框架，通过在权重和token序列上引入双重稀疏性来提升视觉自回归模型的效率，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有的静态剪枝方法会永久删除权重或token，破坏预训练依赖关系，导致性能下降；而随着序列长度增长，计算成本也在增加。

Method: 将前馈网络分解为轻量级专家子网络，并使用可学习的路由器根据内容动态选择特定于token的专家子集；同时，通过门控token选择器识别高更新潜力的token进行计算，并重建未选中的token以保持全局上下文和序列对齐；采用两阶段知识蒸馏策略，用原始VAR模型监督路由和门控策略的学习。

Result: 在ImageNet 256×256基准测试中，ActVAR实现了最高21.2%的FLOPs减少，且性能损失极小。

Conclusion: ActVAR通过动态激活机制有效提升了视觉自回归模型的计算效率，同时保留了模型容量和生成质量，适用于长序列图像生成任务。

Abstract: Visual Autoregressive (VAR) models enable efficient image generation via next-scale prediction but face escalating computational costs as sequence length grows. Existing static pruning methods degrade performance by permanently removing weights or tokens, disrupting pretrained dependencies. To address this, we propose ActVAR, a dynamic activation framework that introduces dual sparsity across model weights and token sequences to enhance efficiency without sacrificing capacity. ActVAR decomposes feedforward networks (FFNs) into lightweight expert sub-networks and employs a learnable router to dynamically select token-specific expert subsets based on content. Simultaneously, a gated token selector identifies high-update-potential tokens for computation while reconstructing unselected tokens to preserve global context and sequence alignment. Training employs a two-stage knowledge distillation strategy, where the original VAR model supervises the learning of routing and gating policies to align with pretrained knowledge. Experiments on the ImageNet $256\times 256$ benchmark demonstrate that ActVAR achieves up to $21.2\%$ FLOPs reduction with minimal performance degradation.

</details>


### [178] [Reconstructing 3D Scenes in Native High Dynamic Range](https://arxiv.org/abs/2511.12895)
*Kaixuan Zhang,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu*

Main category: cs.CV

TL;DR: 本文提出了首个直接从单次曝光的原生HDR相机数据进行3D场景重建的方法NH-3DGS，通过 luminance-chromaticity 分解实现全动态范围保持，显著提升了重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景重建主要基于低动态范围（LDR）数据或依赖多曝光融合与逆色调映射，限制了在专业HDR媒体制作中的应用；而新型单次曝光原生HDR相机的出现为直接建模HDR观测提供了机会。

Method: 提出Native High dynamic range 3D Gaussian Splatting (NH-3DGS)，引入亮度-色度分解的颜色表示方法，使3D高斯点阵可直接优化原生HDR输入，并在整个重建流程中保留完整动态范围。

Result: 在合成和真实多视角HDR数据集上的实验表明，NH-3DGS在重建质量和动态范围保持方面显著优于现有方法。

Conclusion: NH-3DGS是首个支持原生HDR观测的3D重建方法，推动了专业级数字内容创作中高质量3D重建的发展。

Abstract: High Dynamic Range (HDR) imaging is essential for professional digital media creation, e.g., filmmaking, virtual production, and photorealistic rendering. However, 3D scene reconstruction has primarily focused on Low Dynamic Range (LDR) data, limiting its applicability to professional workflows. Existing approaches that reconstruct HDR scenes from LDR observations rely on multi-exposure fusion or inverse tone-mapping, which increase capture complexity and depend on synthetic supervision. With the recent emergence of cameras that directly capture native HDR data in a single exposure, we present the first method for 3D scene reconstruction that directly models native HDR observations. We propose {\bf Native High dynamic range 3D Gaussian Splatting (NH-3DGS)}, which preserves the full dynamic range throughout the reconstruction pipeline. Our key technical contribution is a novel luminance-chromaticity decomposition of the color representation that enables direct optimization from native HDR camera data. We demonstrate on both synthetic and real multi-view HDR datasets that NH-3DGS significantly outperforms existing methods in reconstruction quality and dynamic range preservation, enabling professional-grade 3D reconstruction directly from native HDR captures. Code and datasets will be made available.

</details>


### [179] [FDP: A Frequency-Decomposition Preprocessing Pipeline for Unsupervised Anomaly Detection in Brain MRI](https://arxiv.org/abs/2511.12899)
*Hao Li,Zhenfeng Zhuang,Jingyu Lin,Yu Liu,Yifei Chen,Qiong Peng,Lequan Yu,Liansheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于频域分解预处理（FDP）的无监督脑MRI异常检测新框架，通过系统性频域分析发现异常具有独特的频率模式且低频信号在健康图像中具有一致性。FDP利用这些特性，在保留正常解剖结构的同时抑制病理信号，可与现有生成模型结合，显著提升多种架构下的异常检测性能，实验显示DICE分数最高提升17.63%。


<details>
  <summary>Details</summary>
Motivation: 由于脑部解剖结构多样且标注数据稀缺，监督式异常检测面临挑战，现有无监督方法依赖人工噪声模拟异常，缺乏真实病变的生物物理和形态复杂性。因此需要更符合临床实际的异常检测方法。

Method: 提出频率分解预处理（FDP）框架，首次进行系统的频域病理特征分析，并利用低频信号在健康样本中一致性高的特点，通过频域重建实现异常抑制与正常结构保留，可与现有异常模拟技术结合。

Result: FDP在多种基准模型上均提升了异常检测性能，与LDM结合时DICE分数提升17.63%，并在多个架构中保持稳健改进，同时维持诊断保真度。

Conclusion: FDP是一种有效且通用的无监督异常检测框架，通过引入频域分析克服了传统人工异常模拟的局限性，显著提升脑MRI异常检测的性能，具有临床应用潜力。

Abstract: Due to the diversity of brain anatomy and the scarcity of annotated data, supervised anomaly detection for brain MRI remains challenging, driving the development of unsupervised anomaly detection (UAD) approaches. Current UAD methods typically utilize artificially generated noise perturbations on healthy MRIs to train generative models for normal anatomy reconstruction, enabling anomaly detection via residual mapping. However, such simulated anomalies lack the biophysical fidelity and morphological complexity characteristic of true clinical lesions. To advance UAD in brain MRI, we conduct the first systematic frequency-domain analysis of pathological signatures, revealing two key properties: (1) anomalies exhibit unique frequency patterns distinguishable from normal anatomy, and (2) low-frequency signals maintain consistent representations across healthy scans. These insights motivate our Frequency-Decomposition Preprocessing (FDP) framework, the first UAD method to leverage frequency-domain reconstruction for simultaneous pathology suppression and anatomical preservation. FDP can integrate seamlessly with existing anomaly simulation techniques, consistently enhancing detection performance across diverse architectures while maintaining diagnostic fidelity. Experimental results demonstrate that FDP consistently improves anomaly detection performance when integrated with existing methods. Notably, FDP achieves a 17.63% increase in DICE score with LDM while maintaining robust improvements across multiple baselines. The code is available at https://github.com/ls1rius/MRI_FDP.

</details>


### [180] [DeepSport: A Multimodal Large Language Model for Comprehensive Sports Video Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2511.12908)
*Junbo Zou,Haotian Xia,Zhen Ye,Shengjie Zhang,Christopher Lai,Vicente Ordonez,Weining Shen,Hanjie Chen*

Main category: cs.CV

TL;DR: 本文提出了DeepSport，首个端到端训练的多模态大语言模型框架，用于多任务、多体育视频理解，通过引入主动迭代推理和专门的帧提取工具，实现对视频内容的深度理解。


<details>
  <summary>Details</summary>
Motivation: 现有体育视频理解方法大多局限于单一运动、特定任务或缺乏有效的学习推理过程，难以应对体育视频中高速动态、复杂规则和长时序上下文的理解挑战。

Method: 提出DeepSport框架，采用主动迭代推理模式，结合专用帧提取工具实现‘用视频思考’；设计数据蒸馏流程，从10个不同数据源生成78k高质量思维链训练数据；采用两阶段训练策略：监督微调（SFT）和带门控工具使用奖励的强化学习（RL）。

Result: 在包含6.7k问题的测试基准上，DeepSport显著优于现有的闭源和开源基线模型，实现了最先进的性能。

Conclusion: DeepSport为解决多种体育场景下的复杂视频理解任务建立了新的基础，推动了领域特定视频推理的发展。

Abstract: Sports video understanding presents unique challenges, requiring models to perceive high-speed dynamics, comprehend complex rules, and reason over long temporal contexts. While Multimodal Large Language Models (MLLMs) have shown promise in genral domains, the current state of research in sports remains narrowly focused: existing approaches are either single-sport centric, limited to specific tasks, or rely on training-free paradigms that lack robust, learned reasoning process. To address this gap, we introduce DeepSport, the first end-to-end trained MLLM framework designed for multi-task, multi-sport video understanding. DeepSport shifts the paradigm from passive frame processing to active, iterative reasoning, empowering the model to ``think with videos'' by dynamically interrogating content via a specialized frame-extraction tool. To enable this, we propose a data distillation pipeline that synthesizes high-quality Chain-of-Thought (CoT) trajectories from 10 diverse data source, creating a unified resource of 78k training data. We then employ a two-stage training strategy, Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) with a novel gated tool-use reward, to optimize the model's reasoning process. Extensive experiments on the testing benchmark of 6.7k questions demonstrate that DeepSport achieves state-of-the-art performance, significantly outperforming baselines of both proprietary model and open-source models. Our work establishes a new foundation for domain-specific video reasoning to address the complexities of diverse sports.

</details>


### [181] [CASL: Curvature-Augmented Self-supervised Learning for 3D Anomaly Detection](https://arxiv.org/abs/2511.12909)
*Yaohua Zha,Xue Yuerong,Chunlin Fan,Yuansong Wang,Tao Dai,Ke Chen,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 提出了一种基于曲率增强的自监督学习框架CASL，用于3D异常检测，无需任务特定设计即可实现优异性能，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有自监督点云模型在统一微调范式下对3D异常检测效果不佳，且专用异常检测方法泛化能力有限，因此需要一种更通用且高效的3D异常检测模型。

Method: 基于U-Net架构和重构范式，引入多尺度曲率提示来指导解码器预测点的空间坐标，利用曲率信息增强表示学习。

Result: 仅用曲率作为异常评分已优于多个经典方法；CASL在异常检测任务上表现领先，并在点云分类等标准3D理解任务中展现出良好的迁移能力。

Conclusion: CASL框架无需专用异常检测机制，通过曲率增强的自监督学习实现了高性能异常检测与良好泛化性，为通用3D表示学习提供了新思路。

Abstract: Deep learning-based 3D anomaly detection methods have demonstrated significant potential in industrial manufacturing. However, many approaches are specifically designed for anomaly detection tasks, which limits their generalizability to other 3D understanding tasks. In contrast, self-supervised point cloud models aim for general-purpose representation learning, yet our investigation reveals that these classical models are suboptimal at anomaly detection under the unified fine-tuning paradigm. This motivates us to develop a more generalizable 3D model that can effectively detect anomalies without relying on task-specific designs. Interestingly, we find that using only the curvature of each point as its anomaly score already outperforms several classical self-supervised and dedicated anomaly detection models, highlighting the critical role of curvature in 3D anomaly detection. In this paper, we propose a Curvature-Augmented Self-supervised Learning (CASL) framework based on a reconstruction paradigm. Built upon the classical U-Net architecture, our approach introduces multi-scale curvature prompts to guide the decoder in predicting the spatial coordinates of each point. Without relying on any dedicated anomaly detection mechanisms, it achieves leading detection performance through straightforward anomaly classification fine-tuning. Moreover, the learned representations generalize well to standard 3D understanding tasks such as point cloud classification. The code is available at https://github.com/zyh16143998882/CASL.

</details>


### [182] [Explore How to Inject Beneficial Noise in MLLMs](https://arxiv.org/abs/2511.12917)
*Ruishu Zhu,Sida Huang,Ziheng Jiao,Hongyuan Zhang*

Main category: cs.CV

TL;DR: 提出一种通过注入有益随机噪声来优化多模态大语言模型的新型微调方法，显著提升跨模态对齐和下游任务性能，仅需调整1~2%的额外参数。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法忽略跨模态异质性，限制了多模态大语言模型的潜力。

Method: 从变分推断角度重构MLLM的推理过程，设计多模态噪声生成器（MuNG），动态分析图文对中的跨模态关系，生成任务自适应的有益噪声并注入模型。

Result: 在QwenVL和LLaVA两个主流MLLM上实验表明，该方法优于全参数微调和其他微调方法，仅需调整约1~2%的额外参数。

Conclusion: MuNG能有效抑制无关语义成分，增强跨模态表征对齐，是一种高效且高性能的多模态模型微调策略。

Abstract: Multimodal Large Language Models (MLLMs) have played an increasingly important role in multimodal intelligence. However, the existing fine-tuning methods often ignore cross-modal heterogeneity, limiting their full potential. In this work, we propose a novel fine-tuning strategy by injecting beneficial random noise, which outperforms previous methods and even surpasses full fine-tuning, with minimal additional parameters. The proposed Multimodal Noise Generator (MuNG) enables efficient modality fine-tuning by injecting customized noise into the frozen MLLMs. Specifically, we reformulate the reasoning process of MLLMs from a variational inference perspective, upon which we design a multimodal noise generator that dynamically analyzes cross-modal relationships in image-text pairs to generate task-adaptive beneficial noise. Injecting this type of noise into the MLLMs effectively suppresses irrelevant semantic components, leading to significantly improved cross-modal representation alignment and enhanced performance on downstream tasks. Experiments on two mainstream MLLMs, QwenVL and LLaVA, demonstrate that our method surpasses full-parameter fine-tuning and other existing fine-tuning approaches, while requiring adjustments to only about $1\sim2\%$ additional parameters. The relevant code is uploaded in the supplementary.

</details>


### [183] [CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation](https://arxiv.org/abs/2511.12919)
*Dexin Zuo,Ang Li,Wei Wang,Wenxian Yu,Danping Zou*

Main category: cs.CV

TL;DR: 本文提出了一种名为CoordAR的新方法，用于无3D模型情况下基于单参考图像的未知物体6D姿态估计。该方法通过离散化3D坐标并采用自回归Transformer框架实现更鲁棒的对应关系预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖3D模型或使用实值坐标回归，在对称、遮挡场景中因缺乏不确定性建模和卷积结构的局部性而表现不佳，因此需要一种不依赖完整3D模型且具备全局一致性和鲁棒性的新方法。

Method: 提出CoordAR，将3D-3D对应关系表示为离散token图，通过自回归方式生成；引入坐标图离散化、模态解耦编码策略，以及结合位置对齐特征和已生成token序列的Transformer解码器。

Result: 在多个基准上显著优于现有方法，并在对称、遮挡等真实场景中展现出更强的鲁棒性。

Conclusion: CoordAR通过离散化与自回归建模有效提升了单参考6D姿态估计的性能，尤其在挑战性场景下具有优越表现，为无需3D模型的姿态估计提供了新思路。

Abstract: Object 6D pose estimation, a crucial task for robotics and augmented reality applications, becomes particularly challenging when dealing with novel objects whose 3D models are not readily available. To reduce dependency on 3D models, recent studies have explored one-reference-based pose estimation, which requires only a single reference view instead of a complete 3D model. However, existing methods that rely on real-valued coordinate regression suffer from limited global consistency due to the local nature of convolutional architectures and face challenges in symmetric or occluded scenarios owing to a lack of uncertainty modeling. We present CoordAR, a novel autoregressive framework for one-reference 6D pose estimation of unseen objects. CoordAR formulates 3D-3D correspondences between the reference and query views as a map of discrete tokens, which is obtained in an autoregressive and probabilistic manner. To enable accurate correspondence regression, CoordAR introduces 1) a novel coordinate map tokenization that enables probabilistic prediction over discretized 3D space; 2) a modality-decoupled encoding strategy that separately encodes RGB appearance and coordinate cues; and 3) an autoregressive transformer decoder conditioned on both position-aligned query features and the partially generated token sequence. With these novel mechanisms, CoordAR significantly outperforms existing methods on multiple benchmarks and demonstrates strong robustness to symmetry, occlusion, and other challenges in real-world tests.

</details>


### [184] [Generative Photographic Control for Scene-Consistent Video Cinematic Editing](https://arxiv.org/abs/2511.12921)
*Huiqiang Sun,Liao Shen,Zhan Peng,Kun Wang,Size Wu,Yuhang Zang,Tianqi Liu,Zihao Huang,Xingyu Zeng,Zhiguo Cao,Wei Li,Chen Change Loy*

Main category: cs.CV

TL;DR: 本文提出了CineCtrl，首个能够精细控制专业相机参数（如散景、快门速度）的视频电影编辑框架。


<details>
  <summary>Details</summary>
Motivation: 现有的生成视频模型大多仅支持相机运动控制，难以精确操控电影摄影效果（如景深、曝光），限制了其在电影叙事中的应用。

Method: 提出了一种解耦的交叉注意力机制，将相机运动与摄影参数输入分离，并通过模拟和真实数据结合的方式构建大规模数据集进行训练。

Result: 实验表明，该方法能生成高保真视频，并实现对指定摄影效果的精确控制，同时保持场景一致性。

Conclusion: CineCtrl为生成模型中的电影级视觉效果控制提供了有效解决方案，推动了生成视频在电影叙事中的应用潜力。

Abstract: Cinematic storytelling is profoundly shaped by the artful manipulation of photographic elements such as depth of field and exposure. These effects are crucial in conveying mood and creating aesthetic appeal. However, controlling these effects in generative video models remains highly challenging, as most existing methods are restricted to camera motion control. In this paper, we propose CineCtrl, the first video cinematic editing framework that provides fine control over professional camera parameters (e.g., bokeh, shutter speed). We introduce a decoupled cross-attention mechanism to disentangle camera motion from photographic inputs, allowing fine-grained, independent control without compromising scene consistency. To overcome the shortage of training data, we develop a comprehensive data generation strategy that leverages simulated photographic effects with a dedicated real-world collection pipeline, enabling the construction of a large-scale dataset for robust model training. Extensive experiments demonstrate that our model generates high-fidelity videos with precisely controlled, user-specified photographic camera effects.

</details>


### [185] [Text2Traffic: A Text-to-Image Generation and Editing Method for Traffic Scenes](https://arxiv.org/abs/2511.12932)
*Feng Lv,Haoxuan Feng,Zilu Zhang,Chunlong Xia,Yanfeng Li*

Main category: cs.CV

TL;DR: 提出了一种统一的文本驱动框架，用于交通场景中的图像生成与编辑，结合可控掩码机制和多视角数据，提升了生成图像的语义丰富性、视觉保真度和文本对齐能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成技术在交通场景中存在语义不够丰富、视角有限、图像质量低和文本-图像对齐差等问题，难以满足智能交通系统的需求。

Method: 提出一个统一的文本驱动生成与编辑框架，引入可控掩码机制，融合车端和路侧多视角数据；采用两阶段训练策略：先用粗粒度数据进行概念学习，再用细粒度数据微调；设计掩码区域加权损失函数以增强小目标区域的生成质量。

Result: 实验表明该方法在交通场景的文本到图像生成与编辑任务中取得了领先性能，显著提升了生成图像的视觉保真度、几何多样性和文本对齐准确性。

Conclusion: 所提方法有效解决了交通场景图像生成中的关键挑战，通过多视角数据融合、精细化训练策略和区域感知损失，在生成质量与控制性方面均表现出优越性能，具有较强的应用潜力。

Abstract: With the rapid advancement of intelligent transportation systems, text-driven image generation and editing techniques have demonstrated significant potential in providing rich, controllable visual scene data for applications such as traffic monitoring and autonomous driving. However, several challenges remain, including insufficient semantic richness of generated traffic elements, limited camera viewpoints, low visual fidelity of synthesized images, and poor alignment between textual descriptions and generated content. To address these issues, we propose a unified text-driven framework for both image generation and editing, leveraging a controllable mask mechanism to seamlessly integrate the two tasks. Furthermore, we incorporate both vehicle-side and roadside multi-view data to enhance the geometric diversity of traffic scenes. Our training strategy follows a two-stage paradigm: first, we perform conceptual learning using large-scale coarse-grained text-image data; then, we fine-tune with fine-grained descriptive data to enhance text-image alignment and detail quality. Additionally, we introduce a mask-region-weighted loss that dynamically emphasizes small yet critical regions during training, thereby substantially enhancing the generation fidelity of small-scale traffic elements. Extensive experiments demonstrate that our method achieves leading performance in text-based image generation and editing within traffic scenes.

</details>


### [186] [ProtoAnomalyNCD: Prototype Learning for Multi-class Novel Anomaly Discovery in Industrial Scenarios](https://arxiv.org/abs/2511.12938)
*Botong Zhao,Qijun Shi,Shujing Lyu,Yue Lu*

Main category: cs.CV

TL;DR: 提出了一种基于原型学习的框架ProtoAnomalyNCD，用于发现和分类多种未知工业异常类型，结合图像先验和注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有工业异常检测方法难以有效发现和分类多种语义细微的异常类型，且缺乏对图像先验信息的充分利用。

Method: 利用Grounded SAM结合文本提示定位物体区域，并引入异常图引导注意力模块，设计区域引导因子来区分背景、物体和异常区域，在统一的原型学习框架下实现未知异常类的发现与分类。

Result: 在MVTec AD、MTD和Real-IAD数据集上优于当前最先进的方法，并能扩展至检测未知离群样本，实现任务级统一。

Conclusion: ProtoAnomalyNCD通过融合图像先验和对比学习，在多类型异常发现与分类方面表现出优越性能，具有良好的扩展性和实际应用价值。

Abstract: Existing industrial anomaly detection methods mainly determine whether an anomaly is present. However, real-world applications also require discovering and classifying multiple anomaly types. Since industrial anomalies are semantically subtle and current methods do not sufficiently exploit image priors, direct clustering approaches often perform poorly. To address these challenges, we propose ProtoAnomalyNCD, a prototype-learning-based framework for discovering unseen anomaly classes of multiple types that can be integrated with various anomaly detection methods. First, to suppress background clutter, we leverage Grounded SAM with text prompts to localize object regions as priors for the anomaly classification network. Next, because anomalies usually appear as subtle and fine-grained patterns on the product, we introduce an Anomaly-Map-Guided Attention block. Within this block, we design a Region Guidance Factor that helps the attention module distinguish among background, object regions, and anomalous regions. By using both localized product regions and anomaly maps as priors, the module enhances anomalous features while suppressing background noise and preserving normal features for contrastive learning. Finally, under a unified prototype-learning framework, ProtoAnomalyNCD discovers and clusters unseen anomaly classes while simultaneously enabling multi-type anomaly classification. We further extend our method to detect unseen outliers, achieving task-level unification. Our method outperforms state-of-the-art approaches on the MVTec AD, MTD, and Real-IAD datasets.

</details>


### [187] [Semi-Supervised High Dynamic Range Image Reconstructing via Bi-Level Uncertain Area Masking](https://arxiv.org/abs/2511.12939)
*Wei Jiang,Jiahao Cui,Yizheng Wu,Zhan Peng,Zhiyu Pan,Zhiguo Cao*

Main category: cs.CV

TL;DR: 提出了一种基于半监督学习的高动态范围图像重建方法，通过不确定性掩码机制减少伪标签中的偏差，仅用6.7%的真实标注即可达到全监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于高动态范围（HDR）真实标注数据难以获取，研究致力于在有限标注条件下实现高质量的HDR图像重建。

Method: 采用半监督学习框架，利用教师模型生成无标签样本的伪HDR标签，并设计基于不确定性的像素级和块级掩码机制，过滤不可靠的伪标签区域，使学生模型仅从可信区域学习。

Result: 该方法在仅使用6.7% HDR真实标签的情况下，优于以往的半监督方法，并达到与最新全监督方法相当的性能。

Conclusion: 所提出的不确定性掩码机制有效缓解了半监督HDR重建中的确认偏误问题，显著降低了对标注数据的依赖。

Abstract: Reconstructing high dynamic range (HDR) images from low dynamic range (LDR) bursts plays an essential role in the computational photography. Impressive progress has been achieved by learning-based algorithms which require LDR-HDR image pairs. However, these pairs are hard to obtain, which motivates researchers to delve into the problem of annotation-efficient HDR image reconstructing: how to achieve comparable performance with limited HDR ground truths (GTs). This work attempts to address this problem from the view of semi-supervised learning where a teacher model generates pseudo HDR GTs for the LDR samples without GTs and a student model learns from pseudo GTs. Nevertheless, the confirmation bias, i.e., the student may learn from the artifacts in pseudo HDR GTs, presents an impediment. To remove this impediment, an uncertainty-based masking process is proposed to discard unreliable parts of pseudo GTs at both pixel and patch levels, then the trusted areas can be learned from by the student. With this novel masking process, our semi-supervised HDR reconstructing method not only outperforms previous annotation-efficient algorithms, but also achieves comparable performance with up-to-date fully-supervised methods by using only 6.7% HDR GTs.

</details>


### [188] [Recurrent Autoregressive Diffusion: Global Memory Meets Local Attention](https://arxiv.org/abs/2511.12940)
*Taiye Chen,Zihan Ding,Anjian Li,Christina Zhang,Zeqi Xiao,Yisen Wang,Chi Jin*

Main category: cs.CV

TL;DR: 提出了一种新的递归自回归扩散（RAD）框架，通过在扩散变换器中引入LSTM来增强长期视频生成中的历史信息保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型在长时生成中存在遗忘和时空不一致的问题，缺乏有效的记忆压缩与检索机制。

Method: 将LSTM与注意力机制结合，嵌入到扩散变换器框架中，提出RAD框架，实现训练和推理时一致的逐帧自回归记忆更新与检索。

Result: 在Memory Maze和Minecraft数据集上的实验表明，RAD在长视频生成方面优于现有方法，且LSTM在序列建模中表现出高效性。

Conclusion: RAD框架有效提升了长时视频生成的记忆保持能力和一致性，验证了LSTM在扩散模型中作为RNN组件的潜力。

Abstract: Recent advancements in video generation have demonstrated the potential of using video diffusion models as world models, with autoregressive generation of infinitely long videos through masked conditioning. However, such models, usually with local full attention, lack effective memory compression and retrieval for long-term generation beyond the window size, leading to issues of forgetting and spatiotemporal inconsistencies. To enhance the retention of historical information within a fixed memory budget, we introduce a recurrent neural network (RNN) into the diffusion transformer framework. Specifically, a diffusion model incorporating LSTM with attention achieves comparable performance to state-of-the-art RNN blocks, such as TTT and Mamba2. Moreover, existing diffusion-RNN approaches often suffer from performance degradation due to training-inference gap or the lack of overlap across windows. To address these limitations, we propose a novel Recurrent Autoregressive Diffusion (RAD) framework, which executes frame-wise autoregression for memory update and retrieval, consistently across training and inference time. Experiments on Memory Maze and Minecraft datasets demonstrate the superiority of RAD for long video generation, highlighting the efficiency of LSTM in sequence modeling.

</details>


### [189] [T2I-Based Physical-World Appearance Attack against Traffic Sign Recognition Systems in Autonomous Driving](https://arxiv.org/abs/2511.12956)
*Chen Ma,Ningfei Wang,Junhao Zheng,Qing Guo,Qian Wang,Qi Alfred Chen,Chao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本到图像扩散模型的新型交通标志识别对抗攻击框架DiffSign，通过CLIP损失和掩码提示提升攻击的聚焦性与可控性，并引入两种新颖的风格定制方法以增强对未知标志类型的泛化能力与视觉隐蔽性。实验表明，该方法在真实场景下平均攻击成功率达到83.3%，具有良好的实用性、可转移性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗性外观攻击在隐蔽性、迁移性和泛化能力方面存在不足：基于像素扰动的方法易被察觉且过拟合于代理模型，而基于T2I扩散模型的方法对分布外标志效果有限。因此需要一种更有效、可迁移且隐蔽的物理世界攻击方法来评估TSR系统的安全性。

Method: 提出DiffSign框架，结合CLIP损失和掩码提示优化攻击生成过程；设计两种风格定制方法以控制生成图案的外观并提升对不同类型交通标志的适应性与隐蔽性；利用文本到图像扩散模型生成可在物理世界实施的对抗性图案。

Result: 在多种真实环境条件下（不同距离、角度、光照和标志类型）进行测试，DiffSign实现了83.3%的平均物理攻击成功率，显著优于现有方法，在迁移性、有效性、实用性和隐蔽性方面均表现优异。

Conclusion: DiffSign为针对交通标志识别系统提供了高效且实际可行的对抗攻击方案，揭示了当前自动驾驶感知系统在安全方面的潜在风险，同时推动了更具鲁棒性的防御机制的研究。

Abstract: Traffic Sign Recognition (TSR) systems play a critical role in Autonomous Driving (AD) systems, enabling real-time detection of road signs, such as STOP and speed limit signs. While these systems are increasingly integrated into commercial vehicles, recent research has exposed their vulnerability to physical-world adversarial appearance attacks. In such attacks, carefully crafted visual patterns are misinterpreted by TSR models as legitimate traffic signs, while remaining inconspicuous or benign to human observers. However, existing adversarial appearance attacks suffer from notable limitations. Pixel-level perturbation-based methods often lack stealthiness and tend to overfit to specific surrogate models, resulting in poor transferability to real-world TSR systems. On the other hand, text-to-image (T2I) diffusion model-based approaches demonstrate limited effectiveness and poor generalization to out-of-distribution sign types.
  In this paper, we present DiffSign, a novel T2I-based appearance attack framework designed to generate physically robust, highly effective, transferable, practical, and stealthy appearance attacks against TSR systems. To overcome the limitations of prior approaches, we propose a carefully designed attack pipeline that integrates CLIP-based loss and masked prompts to improve attack focus and controllability. We also propose two novel style customization methods to guide visual appearance and improve out-of-domain traffic sign attack generalization and attack stealthiness. We conduct extensive evaluations of DiffSign under varied real-world conditions, including different distances, angles, light conditions, and sign categories. Our method achieves an average physical-world attack success rate of 83.3%, leveraging DiffSign's high effectiveness in attack transferability.

</details>


### [190] [EndoSight AI: Deep Learning-Driven Real-Time Gastrointestinal Polyp Detection and Segmentation for Enhanced Endoscopic Diagnostics](https://arxiv.org/abs/2511.12962)
*Daniel Cavadia*

Main category: cs.CV

TL;DR: 本文提出了一种名为EndoSight AI的深度学习架构，用于在内窥镜检查中实时精确检测胃肠道息肉，基于Hyper-Kvasir数据集实现了88.3%的mAP和最高69%的Dice系数，并具备每秒超过35帧的实时推理速度。


<details>
  <summary>Details</summary>
Motivation: 准确且实时的息肉检测对于结直肠癌的早期诊断和预防至关重要，现有方法在精度、边界划分或实时性方面仍存在不足。

Method: 采用深度学习架构EndoSight AI，利用公开的Hyper-Kvasir数据集进行训练和独立评估，引入临床相关性能指标和新型热感知处理流程以提升模型鲁棒性和效率。

Result: 系统在息肉检测上达到88.3%的mAP，在分割任务中Dice系数最高达69%，并在GPU上实现超过35帧/秒的实时推理速度。

Conclusion: EndoSight AI能够准确识别并精细分割息肉，具备高效实时性能，可无缝集成到内窥镜工作流中，有望提升胃肠疾病诊疗的准确性与临床决策水平。

Abstract: Precise and real-time detection of gastrointestinal polyps during endoscopic procedures is crucial for early diagnosis and prevention of colorectal cancer. This work presents EndoSight AI, a deep learning architecture developed and evaluated independently to enable accurate polyp localization and detailed boundary delineation. Leveraging the publicly available Hyper-Kvasir dataset, the system achieves a mean Average Precision (mAP) of 88.3% for polyp detection and a Dice coefficient of up to 69% for segmentation, alongside real-time inference speeds exceeding 35 frames per second on GPU hardware. The training incorporates clinically relevant performance metrics and a novel thermal-aware procedure to ensure model robustness and efficiency. This integrated AI solution is designed for seamless deployment in endoscopy workflows, promising to advance diagnostic accuracy and clinical decision-making in gastrointestinal healthcare.

</details>


### [191] [CalibrateMix: Guided-Mixup Calibration of Image Semi-Supervised Models](https://arxiv.org/abs/2511.12964)
*Mehrab Mustafy Rahman,Jayanth Mohan,Tiberiu Sosea,Cornelia Caragea*

Main category: cs.CV

TL;DR: 提出了一种名为CalibrateMix的半监督学习方法，通过针对“易学”和“难学”样本的定向mixup策略，有效提升了模型的校准性能和分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习方法存在校准性差的问题，模型预测过于自信且不可靠；而直接应用mixup于伪标签会导致因伪标签本身不可靠而加剧校准问题。

Method: 基于训练动态识别易学与难学样本，并在mixup过程中进行有针对性的混合，以提升模型校准性。

Result: 在多个图像分类基准数据集上，该方法相比现有SSL方法显著降低了预期校准误差（ECE），同时保持或提高了分类准确率。

Conclusion: CalibrateMix能有效改善半监督学习模型的校准性，同时不牺牲准确性，为可靠预测提供了新思路。

Abstract: Semi-supervised learning (SSL) has demonstrated high performance in image classification tasks by effectively utilizing both labeled and unlabeled data. However, existing SSL methods often suffer from poor calibration, with models yielding overconfident predictions that misrepresent actual prediction likelihoods. Recently, neural networks trained with {\tt mixup} that linearly interpolates random examples from the training set have shown better calibration in supervised settings. However, calibration of neural models remains under-explored in semi-supervised settings. Although effective in supervised model calibration, random mixup of pseudolabels in SSL presents challenges due to the overconfidence and unreliability of pseudolabels. In this work, we introduce CalibrateMix, a targeted mixup-based approach that aims to improve the calibration of SSL models while maintaining or even improving their classification accuracy. Our method leverages training dynamics of labeled and unlabeled samples to identify ``easy-to-learn'' and ``hard-to-learn'' samples, which in turn are utilized in a targeted mixup of easy and hard samples. Experimental results across several benchmark image datasets show that our method achieves lower expected calibration error (ECE) and superior accuracy compared to existing SSL approaches.

</details>


### [192] [GrOCE:Graph-Guided Online Concept Erasure for Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.12968)
*Ning Han,Zhenyu Ge,Feng Han,Yuhua Sun,Chengqing Li,Jingjing Chen*

Main category: cs.CV

TL;DR: 提出了一种无需训练的图引导在线概念擦除框架GrOCE，通过动态语义图实现精确且自适应的概念移除，在保持非目标语义的同时达到当前最优的擦除效果。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法依赖昂贵的微调或粗粒度语义分离，易损害无关概念且难以适应动态变化的概念集。

Method: 构建动态语义图，通过三步实现：动态拓扑图构建、自适应聚类识别和选择性边切断，进行基于图的语义推理以精准隔离目标概念。

Result: 在Concept Similarity和FID指标上达到SOTA，能高效、准确、稳定地去除目标概念，且无需重新训练模型。

Conclusion: GrOCE是一种无需训练、精确且可扩展的概念擦除框架，能够通过图结构推理实现细粒度的内容控制。

Abstract: Concept erasure aims to remove harmful, inappropriate, or copyrighted content from text-to-image diffusion models while preserving non-target semantics. However, existing methods either rely on costly fine-tuning or apply coarse semantic separation, often degrading unrelated concepts and lacking adaptability to evolving concept sets. To alleviate this issue, we propose Graph-Guided Online Concept Erasure (GrOCE), a training-free framework that performs precise and adaptive concept removal through graph-based semantic reasoning. GrOCE models concepts and their interrelations as a dynamic semantic graph, enabling principled reasoning over dependencies and fine-grained isolation of undesired content. It comprises three components: (1) Dynamic Topological Graph Construction for incremental graph building, (2) Adaptive Cluster Identification for multi-hop traversal with similarity-decay scoring, and (3) Selective Edge Severing for targeted edge removal while preserving global semantics. Extensive experiments demonstrate that GrOCE achieves state-of-the-art performance on Concept Similarity (CS) and Fréchet Inception Distance (FID) metrics, offering efficient, accurate, and stable concept erasure without retraining.

</details>


### [193] [HiFusion: Hierarchical Intra-Spot Alignment and Regional Context Fusion for Spatial Gene Expression Prediction from Histopathology](https://arxiv.org/abs/2511.12969)
*Ziqiao Weng,Yaoyu Fang,Jiahe Qian,Xinkun Wang,Lee AD Cooper,Weidong Cai,Bo Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为HiFusion的深度学习框架，用于从H&E染色全切片图像预测空间转录组基因表达。该方法通过多层次建模和上下文融合模块，提升了对组织异质性和微环境特征的捕捉能力，在多个基准数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 空间转录组技术虽能关联基因表达与组织形态，但因成本高和技术复杂而难以临床应用。现有计算方法在捕捉斑点内生物异质性和抵抗形态噪声方面存在不足。

Method: 提出HiFusion框架，包含两个模块：1）层次化斑点内建模模块，通过多分辨率子块分解提取细粒度形态特征，并引入特征对齐损失保证跨尺度语义一致性；2）上下文感知跨尺度融合模块，利用交叉注意力选择性整合生物学相关的区域上下文信息。

Result: 在两个基准空间转录组数据集上实验表明，HiFusion在二维滑动交叉验证和更具挑战性的三维样本特异性场景中均达到最先进的性能。

Conclusion: HiFusion是一种鲁棒、准确且可扩展的解决方案，有望推动基于常规病理图像的空间转录组推断的临床应用。

Abstract: Spatial transcriptomics (ST) bridges gene expression and tissue morphology but faces clinical adoption barriers due to technical complexity and prohibitive costs. While computational methods predict gene expression from H&E-stained whole-slide images (WSIs), existing approaches often fail to capture the intricate biological heterogeneity within spots and are susceptible to morphological noise when integrating contextual information from surrounding tissue. To overcome these limitations, we propose HiFusion, a novel deep learning framework that integrates two complementary components. First, we introduce the Hierarchical Intra-Spot Modeling module that extracts fine-grained morphological representations through multi-resolution sub-patch decomposition, guided by a feature alignment loss to ensure semantic consistency across scales. Concurrently, we present the Context-aware Cross-scale Fusion module, which employs cross-attention to selectively incorporate biologically relevant regional context, thereby enhancing representational capacity. This architecture enables comprehensive modeling of both cellular-level features and tissue microenvironmental cues, which are essential for accurate gene expression prediction. Extensive experiments on two benchmark ST datasets demonstrate that HiFusion achieves state-of-the-art performance across both 2D slide-wise cross-validation and more challenging 3D sample-specific scenarios. These results underscore HiFusion's potential as a robust, accurate, and scalable solution for ST inference from routine histopathology.

</details>


### [194] [MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning](https://arxiv.org/abs/2511.12976)
*Yoonjae Seo,Ermal Elbasani,Jaehong Lee*

Main category: cs.CV

TL;DR: 本文提出了MCAQ-YOLO，一种基于形态复杂度感知的空间自适应量化框架，通过五个形态学指标指导位宽分配，在安全装备检测等任务中实现了更高的精度与压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络量化方法通常在空间区域上采用统一的位精度，忽略了视觉数据在结构和纹理上的异质性，导致复杂区域量化敏感而简单区域冗余。因此需要一种能根据局部视觉复杂度动态调整量化精度的方法。

Method: 提出MCAQ-YOLO框架，利用分形维度、纹理熵、梯度方差、边缘密度和轮廓复杂度五个形态学指标刻画局部视觉形态，并将其与量化敏感性关联以实现空间自适应比特分配；同时设计了一种课程学习式的量化感知训练策略，逐步增加量化难度以稳定优化并加速收敛。

Result: 实验表明形态复杂度与量化敏感性之间存在强相关性；在安全装备数据集上，MCAQ-YOLO以平均4.2比特达到85.6% mAP@0.5，相比均匀4比特量化提升3.5个百分点，压缩比为7.6倍，每图像仅增加1.8毫秒开销；在COCO和Pascal VOC上也验证了其跨数据集的有效性。

Conclusion: 形态驱动的空间量化能够有效提升计算受限、安全关键型视觉识别任务的效率与鲁棒性，MCAQ-YOLO为对象检测模型的高效部署提供了新的解决方案。

Abstract: Most neural network quantization methods apply uniform bit precision across spatial regions, ignoring the heterogeneous structural and textural complexity of visual data. This paper introduces MCAQ-YOLO, a morphological complexity-aware quantization framework for object detection. The framework employs five morphological metrics - fractal dimension, texture entropy, gradient variance, edge density, and contour complexity - to characterize local visual morphology and guide spatially adaptive bit allocation. By correlating these metrics with quantization sensitivity, MCAQ-YOLO dynamically adjusts bit precision according to spatial complexity. In addition, a curriculum-based quantization-aware training scheme progressively increases quantization difficulty to stabilize optimization and accelerate convergence. Experimental results demonstrate a strong correlation between morphological complexity and quantization sensitivity and show that MCAQ-YOLO achieves superior detection accuracy and convergence efficiency compared with uniform quantization. On a safety equipment dataset, MCAQ-YOLO attains 85.6 percent mAP@0.5 with an average of 4.2 bits and a 7.6x compression ratio, yielding 3.5 percentage points higher mAP than uniform 4-bit quantization while introducing only 1.8 ms of additional runtime overhead per image. Cross-dataset validation on COCO and Pascal VOC further confirms consistent performance gains, indicating that morphology-driven spatial quantization can enhance efficiency and robustness for computationally constrained, safety-critical visual recognition tasks.

</details>


### [195] [ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes](https://arxiv.org/abs/2511.12977)
*Yixuan Yang,Luyang Xie,Zhen Luo,Zixiang Zhao,Mingqi Gao,Feng Zheng*

Main category: cs.CV

TL;DR: 本文提出了ArtiWorld，一个能够从文本场景描述中自动识别可动部件并生成保持原始几何形状的可执行URDF模型的场景感知流程。


<details>
  <summary>Details</summary>
Motivation: 现有3D资产多为刚性，手动转换为可动部件费时费力，因此需要一种自动化方法来高效生成可交互的机器人仿真环境。

Method: 提出Arti4URDF方法，结合3D点云、大语言模型的先验知识和面向URDF的提示设计，将刚性物体快速转化为基于URDF的可动对象。

Result: 在三种不同场景（模拟物体、完整模拟场景和真实扫描场景）下，该方法均优于现有方法，达到最先进水平，并准确保留了几何形状和交互性。

Conclusion: ArtiWorld为从现有3D资产构建交互式、机器人就绪的仿真环境提供了可行路径。

Abstract: Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.

</details>


### [196] [Concept Regions Matter: Benchmarking CLIP with a New Cluster-Importance Approach](https://arxiv.org/abs/2511.12978)
*Aishwarya Agarwal,Srikrishna Karanam,Vineet Gandhi*

Main category: cs.CV

TL;DR: 提出了一种名为Cluster-based Concept Importance (CCI)的解释方法，用于分析视觉-语言模型中的背景依赖问题，并结合新基准COVAR对18种CLIP变体进行了全面评估。


<details>
  <summary>Details</summary>
Motivation: 现有对比视觉-语言模型（如CLIP）容易过度依赖背景等虚假相关性，且当前评估基准未能准确区分背景干扰与其他因素（如视角、尺度变化）导致的错误。

Method: 利用CLIP自身的patch embedding将空间patch聚类为语义一致的簇，通过遮蔽这些簇并观察预测变化来评估概念重要性；结合GroundedSAM自动区分前景与背景驱动的预测；构建新基准COVAR以系统化分离前景与背景影响。

Result: CCI在faithfulness指标上显著超越先前方法（如在MS COCO检索任务中删除-AUC提升两倍以上）；通过CCI与COVAR分析发现许多错误源于视角、尺度和细粒度混淆，而非仅背景相关性。

Conclusion: CCI是一种高效且可解释性强的重要性评估方法，结合COVAR可更准确诊断VLM的缺陷，为构建更鲁棒的视觉-语言模型提供了方法论支持和实证路径。

Abstract: Contrastive vision-language models (VLMs) such as CLIP achieve strong zero-shot recognition yet remain vulnerable to spurious correlations, particularly background over-reliance. We introduce Cluster-based Concept Importance (CCI), a novel interpretability method that uses CLIP's own patch embeddings to group spatial patches into semantically coherent clusters, mask them, and evaluate relative changes in model predictions. CCI sets a new state of the art on faithfulness benchmarks, surpassing prior methods by large margins; for example, it yields more than a twofold improvement on the deletion-AUC metric for MS COCO retrieval. We further propose that CCI, when combined with GroundedSAM, automatically categorizes predictions as foreground- or background-driven, providing a crucial diagnostic ability. Existing benchmarks such as CounterAnimals, however, rely solely on accuracy and implicitly attribute all performance degradation to background correlations. Our analysis shows this assumption to be incomplete, since many errors arise from viewpoint variation, scale shifts, and fine-grained object confusions. To disentangle these effects, we introduce COVAR, a benchmark that systematically varies object foregrounds and backgrounds. Leveraging CCI with COVAR, we present a comprehensive evaluation of eighteen CLIP variants, offering methodological advances and empirical evidence that chart a path toward more robust VLMs.

</details>


### [197] [UNSEEN: Enhancing Dataset Pruning from a Generalization Perspective](https://arxiv.org/abs/2511.12988)
*Furui Xu,Shaobo Wang,Jiajun Zhang,Chenghao Sun,Haixiang Tang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于泛化视角的数据集剪枝框架UNSEEN，通过在未见过的模型上评分样本，提升样本区分度，并支持多步增量选择，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据集剪枝方法依赖训练过程中的拟合性能评分，导致样本得分分布密集、区分度低，难以有效筛选代表性样本。

Method: 从泛化角度出发，使用未接触样本的模型对其进行评分；提出UNSEEN框架，可集成到现有剪枝方法中，并扩展至多步场景，通过在不同核心集上训练的模型进行增量选择与动态优化。

Result: 在CIFAR-10、CIFAR-100和ImageNet-1K上显著优于当前SOTA方法；在ImageNet-1K上减少30%训练数据的同时保持性能无损。

Conclusion: UNSEEN通过泛化感知的评分机制和多步增量选择，有效提升了数据集剪枝的质量与效率，具有良好的通用性和实用性。

Abstract: The growing scale of datasets in deep learning has introduced significant computational challenges. Dataset pruning addresses this challenge by constructing a compact but informative coreset from the full dataset with comparable performance. Previous approaches typically establish scoring metrics based on specific criteria to identify representative samples. However, these methods predominantly rely on sample scores obtained from the model's performance during the training (i.e., fitting) phase. As scoring models achieve near-optimal performance on training data, such fitting-centric approaches induce a dense distribution of sample scores within a narrow numerical range. This concentration reduces the distinction between samples and hinders effective selection. To address this challenge, we conduct dataset pruning from the perspective of generalization, i.e., scoring samples based on models not exposed to them during training. We propose a plug-and-play framework, UNSEEN, which can be integrated into existing dataset pruning methods. Additionally, conventional score-based methods are single-step and rely on models trained solely on the complete dataset, providing limited perspective on the importance of samples. To address this limitation, we scale UNSEEN to multi-step scenarios and propose an incremental selection technique through scoring models trained on varying coresets, and optimize the quality of the coreset dynamically. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art (SOTA) methods on CIFAR-10, CIFAR-100, and ImageNet-1K. Notably, on ImageNet-1K, UNSEEN achieves lossless performance while reducing training data by 30\%.

</details>


### [198] [Semantic Prioritization in Visual Counterfactual Explanations with Weighted Segmentation and Auto-Adaptive Region Selection](https://arxiv.org/abs/2511.12992)
*Lintong Zhang,Kang Yin,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 提出了一种新的非生成式视觉反事实解释方法WSAE-Net，通过加权语义图和自适应候选编辑序列提升解释的语义相关性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在替换图像区域时忽略替换区域与目标对象的语义相关性，影响模型可解释性和编辑效率。

Method: 提出WSAE-Net，包含两个关键创新：生成加权语义图以减少非语义特征单元的计算；设计自适应候选编辑序列以优化特征处理顺序。

Result: 实验表明该方法在生成反事实解释方面性能优越，提高了语义相关性和计算效率。

Conclusion: WSAE-Net有效提升了视觉反事实解释的语义一致性与计算效率，增强了模型的可解释性。

Abstract: In the domain of non-generative visual counterfactual explanations (CE), traditional techniques frequently involve the substitution of sections within a query image with corresponding sections from distractor images. Such methods have historically overlooked the semantic relevance of the replacement regions to the target object, thereby impairing the model's interpretability and hindering the editing workflow. Addressing these challenges, the present study introduces an innovative methodology named as Weighted Semantic Map with Auto-adaptive Candidate Editing Network (WSAE-Net). Characterized by two significant advancements: the determination of an weighted semantic map and the auto-adaptive candidate editing sequence. First, the generation of the weighted semantic map is designed to maximize the reduction of non-semantic feature units that need to be computed, thereby optimizing computational efficiency. Second, the auto-adaptive candidate editing sequences are designed to determine the optimal computational order among the feature units to be processed, thereby ensuring the efficient generation of counterfactuals while maintaining the semantic relevance of the replacement feature units to the target object. Through comprehensive experimentation, our methodology demonstrates superior performance, contributing to a more lucid and in-depth understanding of visual counterfactual explanations.

</details>


### [199] [PerTouch: VLM-Driven Agent for Personalized and Semantic Image Retouching](https://arxiv.org/abs/2511.12998)
*Zewei Chang,Zheng-Peng Duan,Jianxing Zhang,Chun-Le Guo,Siyu Liu,Hyungju Chun,Hyunhee Park,Zikun Liu,Chongyi Li*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的统一图像润饰框架PerTouch，支持语义级润饰并保持全局美学，通过参数图实现细粒度控制，并结合VLM驱动代理理解用户语言指令，有效对齐用户意图。


<details>
  <summary>Details</summary>
Motivation: 为了在图像润饰中平衡可控性与主观审美偏好，需要一个能同时处理语义级编辑和个性化需求的统一框架。

Method: 提出PerTouch，利用包含语义区域属性值的参数图构建显式的参数到图像映射；引入语义替换和参数扰动机制提升语义边界感知；结合VLM驱动代理，将自然语言指令转化为视觉控制，并通过反馈重思和场景感知记忆机制捕捉长期偏好。

Result: 实验验证了各组件的有效性，PerTouch在个性化图像润饰任务中表现出优越性能，能更好对齐用户意图并保持语义一致性。

Conclusion: PerTouch为个性化图像润饰提供了一个高效、可控且语义敏感的解决方案，结合语言指令与反馈机制显著提升了用户体验与结果质量。

Abstract: Image retouching aims to enhance visual quality while aligning with users' personalized aesthetic preferences. To address the challenge of balancing controllability and subjectivity, we propose a unified diffusion-based image retouching framework called PerTouch. Our method supports semantic-level image retouching while maintaining global aesthetics. Using parameter maps containing attribute values in specific semantic regions as input, PerTouch constructs an explicit parameter-to-image mapping for fine-grained image retouching. To improve semantic boundary perception, we introduce semantic replacement and parameter perturbation mechanisms in the training process. To connect natural language instructions with visual control, we develop a VLM-driven agent that can handle both strong and weak user instructions. Equipped with mechanisms of feedback-driven rethinking and scene-aware memory, PerTouch better aligns with user intent and captures long-term preferences. Extensive experiments demonstrate each component's effectiveness and the superior performance of PerTouch in personalized image retouching. Code is available at: https://github.com/Auroral703/PerTouch.

</details>


### [200] [Medal S: Spatio-Textual Prompt Model for Medical Segmentation](https://arxiv.org/abs/2511.13001)
*Pengcheng Shi,Jiawei Chen,Jiaqi Liu,Xinglin Zhang,Tao Chen,Lei Li*

Main category: cs.CV

TL;DR: Medal S 是一个支持原生分辨率空间和文本提示的医学分割基础模型，通过通道级对齐和3D上下文保持，在多模态、多类分割任务中显著优于现有方法，具备高效推理与高精度优势。


<details>
  <summary>Details</summary>
Motivation: 现有的文本引导分割方法缺乏空间感知能力，且在处理多类医学图像时存在分辨率不匹配和效率低下的问题。因此需要一种能同时利用空间和语义信息、支持多模态多类别的高效医学分割模型。

Method: 提出 Medal S，采用端到端可训练框架，实现体素级提示与文本嵌入的通道级对齐；引入轻量级3D卷积模块进行精确的体素空间细化，并支持并行处理多个原生分辨率掩码；设计两种提示模式（纯文本与混合模式），结合动态重采样、优化文本预处理、两阶段推理策略和后处理技术提升性能。

Result: 在五种模态（CT、MRI、PET、超声、显微镜）的 BiomedSegFM 数据集上，Medal S 在24类分割任务中相比 SAT 显著提升：DSC 达 75.44（vs 69.83）、NSD 77.34（vs 71.06）、F1 38.24（vs 24.88）、DSC TP 65.46（vs 46.97）；并行空间提示使推理时间减少超过90%。

Conclusion: Medal S 通过融合空间精度与语义文本指导，在多类医学图像分割中实现了更高的准确性与效率，优于顺序提示方法，具备良好的通用性和应用前景。

Abstract: We introduce Medal S, a medical segmentation foundation model that supports native-resolution spatial and textual prompts within an end-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieves channel-wise alignment between volumetric prompts and text embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiple native-resolution masks in parallel, enhancing multi-class segmentation performance. A lightweight 3D convolutional module enables precise voxel-space refinement guided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: a text-only mode, where model predictions serve as spatial prompts for self-refinement without human input, and a hybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We propose dynamic resampling to address target-patch ratio imbalance, extending SAT and nnU-Net for data augmentation. Furthermore, we develop optimized text preprocessing, a two-stage inference strategy, and post-processing techniques to improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperforms SAT with a DSC of 75.44 (vs. 69.83), NSD of 77.34 (vs. 71.06), F1 of 38.24 (vs. 24.88), and DSC TP of 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy in multi-class medical segmentation tasks compared to sequential prompt-based approaches. Medal S will be publicly available at https://github.com/yinghemedical/Medal-S.

</details>


### [201] [Infinite-Story: A Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2511.13002)
*Jihun Park,Kyoungmin Lee,Jongmin Gim,Hyeonseo Jo,Minseok Oh,Wonhyeok Choi,Kyumin Hwang,Jaeyeul Kim,Minwoo Choi,Sunghoon Im*

Main category: cs.CV

TL;DR: 提出了一种无需训练的框架Infinite-Story，用于多提示文本到图像生成中的保持一致性的视觉叙事，通过引入身份提示替换和统一注意力引导机制，在不牺牲提示保真度的情况下实现高身份和风格一致性，并显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 解决多提示文本到图像生成中身份和风格不一致的问题，同时避免现有方法需要微调或推理速度慢的缺陷。

Method: 基于尺度自回归模型，提出身份提示替换以缓解文本编码器的上下文偏差，并设计统一注意力引导机制（包括自适应风格注入和同步引导适应）来保持全局风格和身份一致性。

Result: 在多个实验中实现了最先进的生成性能，推理速度比现有最快的一致性T2I模型快6倍以上（每张图像1.72秒），且保持高一致性。

Conclusion: Infinite-Story是一种高效、实用的无需训练的框架，适用于真实场景下的视觉 storytelling 应用。

Abstract: We present Infinite-Story, a training-free framework for consistent text-to-image (T2I) generation tailored for multi-prompt storytelling scenarios. Built upon a scale-wise autoregressive model, our method addresses two key challenges in consistent T2I generation: identity inconsistency and style inconsistency. To overcome these issues, we introduce three complementary techniques: Identity Prompt Replacement, which mitigates context bias in text encoders to align identity attributes across prompts; and a unified attention guidance mechanism comprising Adaptive Style Injection and Synchronized Guidance Adaptation, which jointly enforce global style and identity appearance consistency while preserving prompt fidelity. Unlike prior diffusion-based approaches that require fine-tuning or suffer from slow inference, Infinite-Story operates entirely at test time, delivering high identity and style consistency across diverse prompts. Extensive experiments demonstrate that our method achieves state-of-the-art generation performance, while offering over 6X faster inference (1.72 seconds per image) than the existing fastest consistent T2I models, highlighting its effectiveness and practicality for real-world visual storytelling.

</details>


### [202] [SAGE: Spuriousness-Aware Guided Prompt Exploration for Mitigating Multimodal Bias](https://arxiv.org/abs/2511.13005)
*Wenqian Ye,Di Wang,Guangtao Zheng,Bohan Liu,Aidong Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练或微调的零样本方法SAGE，通过引导式提示选择来缓解视觉-语言模型中的多模态虚假偏差，提升了跨数据集和模型的鲁棒性和分类性能。


<details>
  <summary>Details</summary>
Motivation: CLIP等视觉-语言模型在零样本分类中表现出色，但容易依赖图像与文本之间的虚假关联（如背景推断物体），导致在分布外数据上性能下降。现有去偏方法通常需要微调或先验知识，限制了其即插即用的优势。因此，亟需一种无需训练且适用于零样本场景的去偏方法。

Method: 作者首先从理论上分析了多模态虚假偏差对零样本分类的影响，并提出了Spuriousness-Aware Guided Exploration (SAGE) 方法。SAGE通过探索不同的提示模板空间，选择能够最大化类别间语义分离的提示，从而减少模型对虚假特征的依赖。该方法不需任何训练、微调或外部标注。

Result: 在四个真实世界基准数据集和五种主流骨干模型上的实验表明，SAGE在无需外部知识或模型更新的情况下， consistently 提升了零样本分类性能和最差组的鲁棒性，优于此前的零样本方法。

Conclusion: SAGE是一种简单而有效的零样本去偏方法，通过语义分离导向的提示选择机制，在不改变模型参数的前提下显著增强了CLIP类模型在分布外数据上的泛化能力和鲁棒性。

Abstract: Large vision-language models, such as CLIP, have shown strong zero-shot classification performance by aligning images and text in a shared embedding space. However, CLIP models often develop multimodal spurious biases, which is the undesirable tendency to rely on spurious features. For example, CLIP may infer object types in images based on frequently co-occurring backgrounds rather than the object's core features. This bias significantly impairs the robustness of pre-trained CLIP models on out-of-distribution data, where such cross-modal associations no longer hold. Existing methods for mitigating multimodal spurious bias typically require fine-tuning on downstream data or prior knowledge of the bias, which undermines the out-of-the-box usability of CLIP. In this paper, we first theoretically analyze the impact of multimodal spurious bias in zero-shot classification. Based on this insight, we propose Spuriousness-Aware Guided Exploration (SAGE), a simple and effective method that mitigates spurious bias through guided prompt selection. SAGE requires no training, fine-tuning, or external annotations. It explores a space of prompt templates and selects the prompts that induce the largest semantic separation between classes, thereby improving worst-group robustness. Extensive experiments on four real-world benchmark datasets and five popular backbone models demonstrate that SAGE consistently improves zero-shot performance and generalization, outperforming previous zero-shot approaches without any external knowledge or model updates.

</details>


### [203] [Beyond Darkness: Thermal-Supervised 3D Gaussian Splatting for Low-Light Novel View Synthesis](https://arxiv.org/abs/2511.13011)
*Qingsen Ma,Chen Zou,Dianyun Wang,Jia Wang,Liuyu Xiang,Zhaofeng He*

Main category: cs.CV

TL;DR: 提出DTGS，一种将Retinex光照分解与热感知3D高斯点阵结合的统一框架，实现极端低光条件下的光照不变新视图合成。


<details>
  <summary>Details</summary>
Motivation: 标准3D高斯点阵在极低光照下因独立增强导致光照不一致和几何失真，难以保持几何、颜色和辐射稳定性。

Method: 通过循环增强-重建机制联合优化增强、几何和热监督；嵌入Retinex分解模块实现反射-光照分离，并引入热监督分支动态平衡损失。

Result: 在自建RGBT-LOW数据集上实验表明，DTGS在辐射一致性、几何保真度和颜色稳定性方面显著优于现有方法。

Conclusion: DTGS通过联合优化和物理可解释的分解，在极端低光条件下实现了高质量、光照不变的新视图合成。

Abstract: Under extremely low-light conditions, novel view synthesis (NVS) faces severe degradation in terms of geometry, color consistency, and radiometric stability. Standard 3D Gaussian Splatting (3DGS) pipelines fail when applied directly to underexposed inputs, as independent enhancement across views causes illumination inconsistencies and geometric distortion. To address this, we present DTGS, a unified framework that tightly couples Retinex-inspired illumination decomposition with thermal-guided 3D Gaussian Splatting for illumination-invariant reconstruction. Unlike prior approaches that treat enhancement as a pre-processing step, DTGS performs joint optimization across enhancement, geometry, and thermal supervision through a cyclic enhancement-reconstruction mechanism. A thermal supervisory branch stabilizes both color restoration and geometry learning by dynamically balancing enhancement, structural, and thermal losses. Moreover, a Retinex-based decomposition module embedded within the 3DGS loop provides physically interpretable reflectance-illumination separation, ensuring consistent color and texture across viewpoints. To evaluate our method, we construct RGBT-LOW, a new multi-view low-light thermal dataset capturing severe illumination degradation. Extensive experiments show that DTGS significantly outperforms existing low-light enhancement and 3D reconstruction baselines, achieving superior radiometric consistency, geometric fidelity, and color stability under extreme illumination.

</details>


### [204] [You Only Look Omni Gradient Backpropagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2511.13013)
*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: 提出了一种从反向传播角度重新设计的特征金字塔网络BP-FPN，用于红外小目标检测，通过GILS和DGR模块提升特征表示能力，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在时空特征聚合上受限于每帧特征表示不明确，导致检测性能提升有限，因此需要改进特征学习机制。

Method: 提出BP-FPN，包含梯度隔离的低层捷径（GILS）以保留细粒度目标细节，并引入方向性梯度正则化（DGR）来增强反向传播过程中的层次特征一致性。

Result: 在多个公开数据集上实验表明，BP-FPN显著优于现有方法，取得新的SOTA性能，且计算开销极小。

Conclusion: BP-FPN首次从反向传播视角设计特征金字塔，有效提升了红外小目标的特征表示能力，为该任务提供了新的优化方向。

Abstract: Moving infrared small target detection is a key component of infrared search and tracking systems, yet it remains extremely challenging due to low signal-to-clutter ratios, severe target-background imbalance, and weak discriminative features. Existing deep learning methods primarily focus on spatio-temporal feature aggregation, but their gains are limited, revealing that the fundamental bottleneck lies in ambiguous per-frame feature representations rather than spatio-temporal modeling itself. Motivated by this insight, we propose BP-FPN, a backpropagation-driven feature pyramid architecture that fundamentally rethinks feature learning for small target. BP-FPN introduces Gradient-Isolated Low-Level Shortcut (GILS) to efficiently incorporate fine-grained target details without inducing shortcut learning, and Directional Gradient Regularization (DGR) to enforce hierarchical feature consistency during backpropagation. The design is theoretically grounded, introduces negligible computational overhead, and can be seamlessly integrated into existing frameworks. Extensive experiments on multiple public datasets show that BP-FPN consistently establishes new state-of-the-art performance. To the best of our knowledge, it is the first FPN designed for this task entirely from the backpropagation perspective.

</details>


### [205] [Geometry Meets Light: Leveraging Geometric Priors for Universal Photometric Stereo under Limited Multi-Illumination Cues](https://arxiv.org/abs/2511.13015)
*King-Man Tam,Satoshi Ikehata,Yuta Asano,Zhaoyi An,Rei Kawakami*

Main category: cs.CV

TL;DR: 提出GeoUniPS，一种融合合成监督与大规模3D重建模型中几何先验的通用光度立体网络，在复杂真实场景中显著提升表面法线估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有通用光度立体方法在光照偏差、阴影或自遮挡区域等复杂真实场景中表现不佳，需引入更强的几何先验来提升鲁棒性。

Method: 设计Light-Geometry Dual-Branch Encoder，结合冻结的预训练3D重建模型提取几何先验，并引入具有透视投影的真实数据集PS-Perp以建模空间变化的视角方向。

Result: 在多个数据集上实现了最先进的性能，尤其在复杂真实场景中表现出优异的法线估计效果，定性和定量结果均优于现有方法。

Conclusion: 通过整合视觉-几何基础模型的先验知识，GeoUniPS有效克服了传统光度立体在真实场景中的局限，验证了几何先验与合成监督结合的有效性。

Abstract: Universal Photometric Stereo is a promising approach for recovering surface normals without strict lighting assumptions. However, it struggles when multi-illumination cues are unreliable, such as under biased lighting or in shadows or self-occluded regions of complex in-the-wild scenes. We propose GeoUniPS, a universal photometric stereo network that integrates synthetic supervision with high-level geometric priors from large-scale 3D reconstruction models pretrained on massive in-the-wild data. Our key insight is that these 3D reconstruction models serve as visual-geometry foundation models, inherently encoding rich geometric knowledge of real scenes. To leverage this, we design a Light-Geometry Dual-Branch Encoder that extracts both multi-illumination cues and geometric priors from the frozen 3D reconstruction model. We also address the limitations of the conventional orthographic projection assumption by introducing the PS-Perp dataset with realistic perspective projection to enable learning of spatially varying view directions. Extensive experiments demonstrate that GeoUniPS delivers state-of-the-arts performance across multiple datasets, both quantitatively and qualitatively, especially in the complex in-the-wild scenes.

</details>


### [206] [MeanFlow Transformers with Representation Autoencoders](https://arxiv.org/abs/2511.13019)
*Zheyuan Hu,Chieh-Hsin Lai,Ge Wu,Yuki Mitsufuji,Stefano Ermon*

Main category: cs.CV

TL;DR: 提出一种在表示自动编码器（RAE）潜在空间中训练和采样MeanFlow（MF）的高效方法，通过预训练视觉编码器（如DINO）提供语义丰富的潜在表示，并结合轻量级解码器，显著降低训练和推理成本。采用一致性训练初始化和两阶段训练策略（蒸馏+自举），解决了梯度爆炸问题，无需复杂引导参数，在ImageNet上实现了更优的1步生成FID和更低的计算开销。


<details>
  <summary>Details</summary>
Motivation: MeanFlow在高维数据生成中依赖SD-VAE导致推理成本高、训练不稳定，且类条件生成需复杂引导超参数，限制了其效率与实用性。

Method: 在RAE潜在空间中进行MF训练，使用预训练视觉编码器（如DINO）提取语义丰富特征并配以轻量解码器；采用Consistency Mid-Training进行轨迹感知初始化；设计两阶段训练：先从预训练流匹配教师模型蒸馏以加速收敛，再可选地使用单点速度估计器进行自举优化，减少偏差。

Result: 在ImageNet 256上实现1步FID 2.03（优于基线3.43），采样GFLOPS降低38%，训练成本减少83%；在ImageNet 512上达到FID 3.23，为所有基线中最低GFLOPS。

Conclusion: 该方法有效解决了MF在RAE潜在空间中训练的梯度爆炸问题，显著提升了训练稳定性与效率，无需引导即可实现高质量少步生成，在性能和计算成本上均优于传统MF方案。

Abstract: MeanFlow (MF) is a diffusion-motivated generative model that enables efficient few-step generation by learning long jumps directly from noise to data. In practice, it is often used as a latent MF by leveraging the pre-trained Stable Diffusion variational autoencoder (SD-VAE) for high-dimensional data modeling. However, MF training remains computationally demanding and is often unstable. During inference, the SD-VAE decoder dominates the generation cost, and MF depends on complex guidance hyperparameters for class-conditional generation. In this work, we develop an efficient training and sampling scheme for MF in the latent space of a Representation Autoencoder (RAE), where a pre-trained vision encoder (e.g., DINO) provides semantically rich latents paired with a lightweight decoder. We observe that naive MF training in the RAE latent space suffers from severe gradient explosion. To stabilize and accelerate training, we adopt Consistency Mid-Training for trajectory-aware initialization and use a two-stage scheme: distillation from a pre-trained flow matching teacher to speed convergence and reduce variance, followed by an optional bootstrapping stage with a one-point velocity estimator to further reduce deviation from the oracle mean flow. This design removes the need for guidance, simplifies training configurations, and reduces computation in both training and sampling. Empirically, our method achieves a 1-step FID of 2.03, outperforming vanilla MF's 3.43, while reducing sampling GFLOPS by 38% and total training cost by 83% on ImageNet 256. We further scale our approach to ImageNet 512, achieving a competitive 1-step FID of 3.23 with the lowest GFLOPS among all baselines. Code is available at https://github.com/sony/mf-rae.

</details>


### [207] [SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction](https://arxiv.org/abs/2511.13020)
*Yufei Wen,Yuting Zhang,Jingdan Kang,Hao Ren,Weibin Cheng,Jintai Chen,Kaishun Wu*

Main category: cs.CV

TL;DR: 提出SpectralAdapt框架，通过半监督域适应方法解决医疗领域高光谱成像数据稀缺问题，实现从RGB图像高效重建高光谱数据。


<details>
  <summary>Details</summary>
Motivation: 医疗领域缺乏足够的人体高光谱成像（HSI）数据，限制了其在健康护理中的应用；而现有通用域数据与医学域之间存在显著差异，需有效桥接以提升重建性能。

Method: 提出SpectralAdapt框架，包含光谱密度掩码（SDM）和光谱端元表示对齐（SERA）：SDM自适应掩蔽RGB通道以增强光谱推理，SERA利用标记像素提取物理可解释的端元作为跨域锚点，并通过动量更新提升稳定性。

Result: 在基准数据集上实验表明，该方法在光谱保真度、跨域泛化能力和训练稳定性方面均取得一致提升。

Conclusion: SpectralAdapt通过半监督域适应有效缓解了域偏移、光谱退化和数据稀缺问题，展现了在医疗高光谱成像重建中的巨大潜力。

Abstract: Hyperspectral imaging (HSI) holds great potential for healthcare due to its rich spectral information. However, acquiring HSI data remains costly and technically demanding. Hyperspectral image reconstruction offers a practical solution by recovering HSI data from accessible modalities, such as RGB. While general domain datasets are abundant, the scarcity of human HSI data limits progress in medical applications. To tackle this, we propose SpectralAdapt, a semi-supervised domain adaptation (SSDA) framework that bridges the domain gap between general and human-centered HSI datasets. To fully exploit limited labels and abundant unlabeled data, we enhance spectral reasoning by introducing Spectral Density Masking (SDM), which adaptively masks RGB channels based on their spectral complexity, encouraging recovery of informative regions from complementary cues during consistency training. Furthermore, we introduce Spectral Endmember Representation Alignment (SERA), which derives physically interpretable endmembers from valuable labeled pixels and employs them as domain-invariant anchors to guide unlabeled predictions, with momentum updates ensuring adaptability and stability. These components are seamlessly integrated into SpectralAdapt, a spectral prior-guided framework that effectively mitigates domain shift, spectral degradation, and data scarcity in HSI reconstruction. Experiments on benchmark datasets demonstrate consistent improvements in spectral fidelity, cross-domain generalization, and training stability, highlighting the promise of SSDA as an efficient solution for hyperspectral imaging in healthcare.

</details>


### [208] [REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding](https://arxiv.org/abs/2511.13026)
*Jiaze Li,Hao Yin,Wenhui Tan,Jingyang Chen,Boshen Xu,Yuxun Qu,Yijing Chen,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: 本文提出REVISOR框架，通过跨模态的文本与视觉反思机制提升MLLM在长视频理解中的性能，结合DADR奖励机制在无需额外监督或外部模型的情况下显著提升表现。


<details>
  <summary>Details</summary>
Motivation: 现有纯文本反思机制在处理长视频理解任务时存在不足，无法充分整合动态视觉信息且缺乏跨模态交互能力。

Method: 提出REVISOR框架，支持多模态大语言模型（MLLM）在文本和视觉模态上协同构建反思过程，并设计Dual Attribution Decoupled Reward（DADR）机制，结合GRPO训练策略实现推理与视频证据间的因果对齐。

Result: REVISOR在VideoMME、LongVideoBench、MLVU和LVBench四个基准上均取得显著性能提升，且无需额外监督微调或外部模型。

Conclusion: REVISOR通过增强视觉信息的反思和跨模态交互，有效提升了MLLM在长视频理解任务中的推理能力。

Abstract: Self-reflection mechanisms that rely on purely text-based rethinking processes perform well in most multimodal tasks. However, when directly applied to long-form video understanding scenarios, they exhibit clear limitations. The fundamental reasons for this lie in two points: (1)long-form video understanding involves richer and more dynamic visual input, meaning rethinking only the text information is insufficient and necessitates a further rethinking process specifically targeting visual information; (2) purely text-based reflection mechanisms lack cross-modal interaction capabilities, preventing them from fully integrating visual information during reflection. Motivated by these insights, we propose REVISOR (REflective VIsual Segment Oriented Reasoning), a novel framework for tool-augmented multimodal reflection. REVISOR enables MLLMs to collaboratively construct introspective reflection processes across textual and visual modalities, significantly enhancing their reasoning capability for long-form video understanding. To ensure that REVISOR can learn to accurately review video segments highly relevant to the question during reinforcement learning, we designed the Dual Attribution Decoupled Reward (DADR) mechanism. Integrated into the GRPO training strategy, this mechanism enforces causal alignment between the model's reasoning and the selected video evidence. Notably, the REVISOR framework significantly enhances long-form video understanding capability of MLLMs without requiring supplementary supervised fine-tuning or external models, achieving impressive results on four benchmarks including VideoMME, LongVideoBench, MLVU, and LVBench.

</details>


### [209] [Towards 3D Object-Centric Feature Learning for Semantic Scene Completion](https://arxiv.org/abs/2511.13031)
*Weihua Wang,Yubo Cui,Xiangru Lin,Zhiheng Li,Zheng Fang*

Main category: cs.CV

TL;DR: 本文提出了一种面向3D语义场景补全（SSC）的物体中心预测框架Ocean，通过将场景分解为个体对象实例来提升语义和几何预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的SSC方法多采用以自我为中心的范式，忽略了细粒度的物体级别细节，导致在复杂环境中存在语义和几何模糊性。

Method: 首先使用MobileSAM提取图像中的实例掩码；然后引入3D语义分组注意力模块，在3D空间中聚合物体中心特征；设计全局相似性引导注意力模块以处理分割错误和缺失实例；最后通过实例感知的局部扩散模块在BEV空间中优化场景表示。

Result: 在SemanticKITTI和SSCBench-KITTI360数据集上实现了最先进的性能，mIoU分别达到17.40和20.28。

Conclusion: Ocean通过物体中心的建模方式有效提升了3D语义场景补全的精度，尤其在复杂城市环境中有显著优势。

Abstract: Vision-based 3D Semantic Scene Completion (SSC) has received growing attention due to its potential in autonomous driving. While most existing approaches follow an ego-centric paradigm by aggregating and diffusing features over the entire scene, they often overlook fine-grained object-level details, leading to semantic and geometric ambiguities, especially in complex environments. To address this limitation, we propose Ocean, an object-centric prediction framework that decomposes the scene into individual object instances to enable more accurate semantic occupancy prediction. Specifically, we first employ a lightweight segmentation model, MobileSAM, to extract instance masks from the input image. Then, we introduce a 3D Semantic Group Attention module that leverages linear attention to aggregate object-centric features in 3D space. To handle segmentation errors and missing instances, we further design a Global Similarity-Guided Attention module that leverages segmentation features for global interaction. Finally, we propose an Instance-aware Local Diffusion module that improves instance features through a generative process and subsequently refines the scene representation in the BEV space. Extensive experiments on the SemanticKITTI and SSCBench-KITTI360 benchmarks demonstrate that Ocean achieves state-of-the-art performance, with mIoU scores of 17.40 and 20.28, respectively.

</details>


### [210] [Uni-Inter: Unifying 3D Human Motion Synthesis Across Diverse Interaction Contexts](https://arxiv.org/abs/2511.13032)
*Sheng Liu,Yuanzhi Liang,Jiepeng Wang,Sidan Du,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出了一种名为Uni-Inter的统一框架，用于生成人类动作，支持多种交互场景（人-人、人-物、人-场景），通过统一交互体积（UIV）实现任务无关的建模，提升了泛化能力和细粒度空间依赖的捕捉。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖任务特定设计，泛化能力有限，难以处理复杂的复合交互场景。

Method: 引入统一交互体积（UIV）作为异构交互实体的共享体素表示，在统一架构中进行关节级概率预测，实现对多类交互的一致关系推理和联合建模。

Result: 在三类代表性交互任务上实验表明，Uni-Inter性能优越且能良好泛化到新实体组合。

Conclusion: 统一建模复合交互是复杂环境中可扩展动作合成的有前景方向。

Abstract: We present Uni-Inter, a unified framework for human motion generation that supports a wide range of interaction scenarios: including human-human, human-object, and human-scene-within a single, task-agnostic architecture. In contrast to existing methods that rely on task-specific designs and exhibit limited generalization, Uni-Inter introduces the Unified Interactive Volume (UIV), a volumetric representation that encodes heterogeneous interactive entities into a shared spatial field. This enables consistent relational reasoning and compound interaction modeling. Motion generation is formulated as joint-wise probabilistic prediction over the UIV, allowing the model to capture fine-grained spatial dependencies and produce coherent, context-aware behaviors. Experiments across three representative interaction tasks demonstrate that Uni-Inter achieves competitive performance and generalizes well to novel combinations of entities. These results suggest that unified modeling of compound interactions offers a promising direction for scalable motion synthesis in complex environments.

</details>


### [211] [uCLIP: Parameter-Efficient Multilingual Extension of Vision-Language Models with Unpaired Data](https://arxiv.org/abs/2511.13036)
*Dahyun Chung,Donghyun Shin,Yujin Sung,Seunggi Moon,Jinwoo Jeon,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 提出了一种轻量且数据高效的多语言视觉-语言对齐框架，无需图像-文本对或文本-文本对，仅训练一个小型投影模块，利用英文表示作为语义锚点，在低资源语言上显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于对比语言-图像预训练的多语言模型在低资源语言上表现不佳，主要受限于高质量多语言图文数据的缺乏。

Method: 冻结预训练图像编码器和多语言文本编码器，仅训练一个1.7M参数的投影模块，使用基于英文表示的对比损失作为语义锚点进行多语言对齐。

Result: 在多个多语言检索基准上显著提升了捷克语、芬兰语、克罗地亚语、匈牙利语和罗马尼亚语等五种代表性低资源语言的性能，优于现有方法。

Conclusion: 该基于英文锚点的轻量级对齐策略有效实现了低资源语言的多模态对齐，为包容性多模态学习提供了高效可行的解决方案。

Abstract: Contrastive Language-Image Pre-training (CLIP) has demonstrated strong generalization across a wide range of visual tasks by leveraging large-scale English-image pairs. However, its extension to low-resource languages remains limited due to the scarcity of high-quality multilingual image-text data. Existing multilingual vision-language models exhibit consistently low retrieval performance in underrepresented languages including Czech, Finnish, Croatian, Hungarian, and Romanian on the Crossmodal-3600 (XM3600) benchmark. To address this, we propose a lightweight and data-efficient framework for multilingual vision-language alignment. Our approach requires no image-text pairs or text-text pairs and freezes both the pretrained image encoder and multilingual text encoder during training. Only a compact 1.7M-parameter projection module is trained, using a contrastive loss over English representations as semantic anchors. This minimal training setup enables robust multilingual alignment even for languages with limited supervision. Extensive evaluation across multiple multilingual retrieval benchmarks confirms the effectiveness of our method, showing significant gains in five underrepresented languages where existing models typically underperform. These findings highlight the effectiveness of our pivot-based, parameter-efficient alignment strategy for inclusive multimodal learning.

</details>


### [212] [MGCA-Net: Multi-Grained Category-Aware Network for Open-Vocabulary Temporal Action Localization](https://arxiv.org/abs/2511.13039)
*Zhenying Fang,Richang Hong*

Main category: cs.CV

TL;DR: 提出多粒度类别感知网络（MGCA-Net）以提升开放词汇时序动作定位性能，通过细粒度与粗粒度分类协同实现对基础和新动作类别的有效识别与定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅在单一粒度上识别动作类别，导致基础类和新类的识别精度下降，难以满足开放词汇场景下的需求。

Method: 设计MGCA-Net，包含定位器、动作存在预测器、传统分类器和由粗到细分类器；分别在视频级、片段级和提案级实现多粒度动作识别，结合类别感知机制提升定位与分类性能。

Result: 在THUMOS'14和ActivityNet-1.3数据集上达到最先进性能，并在零样本时序动作定位设置下表现优异。

Conclusion: 多粒度类别感知机制能有效提升开放词汇时序动作定位的性能，兼顾基础类与新类的动作识别与定位。

Abstract: Open-Vocabulary Temporal Action Localization (OV-TAL) aims to recognize and localize instances of any desired action categories in videos without explicitly curating training data for all categories. Existing methods mostly recognize action categories at a single granularity, which degrades the recognition accuracy of both base and novel action categories. To address these issues, we propose a Multi-Grained Category-Aware Network (MGCA-Net) comprising a localizer, an action presence predictor, a conventional classifier, and a coarse-to-fine classifier. Specifically, the localizer localizes category-agnostic action proposals. For these action proposals, the action presence predictor estimates the probability that they belong to an action instance. At the same time, the conventional classifier predicts the probability of each action proposal over base action categories at the snippet granularity. Novel action categories are recognized by the coarse-to-fine classifier, which first identifies action presence at the video granularity. Finally, it assigns each action proposal to one category from the coarse categories at the proposal granularity. Through coarse-to-fine category awareness for novel actions and the conventional classifier's awareness of base actions, multi-grained category awareness is achieved, effectively enhancing localization performance. Comprehensive evaluations on the THUMOS'14 and ActivityNet-1.3 benchmarks demonstrate that our method achieves state-of-the-art performance. Furthermore, our MGCA-Net achieves state-of-the-art results under the Zero-Shot Temporal Action Localization setting.

</details>


### [213] [ViSS-R1: Self-Supervised Reinforcement Video Reasoning](https://arxiv.org/abs/2511.13054)
*Bo Fang,Yuxin Song,Qiangqiang Wu,Haoyuan Sun,Wenhao Wu,Antoni B. Chan*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督强化学习算法Pretext-GRPO和ViSS-R1框架，旨在提升多模态大语言模型在复杂视频理解任务中的视觉中心化推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于R1的方法在视频任务中往往过度依赖文本推理，忽视了丰富的视觉信息，导致模型容易产生幻觉和捷径学习。因此需要一种更加以视觉为中心的视频理解方法。

Method: 引入Pretext-GRPO算法，在标准R1流程中通过变换视觉输入并完成预文本任务来给予正向奖励，促使模型非平凡地处理视觉信息；在此基础上提出ViSS-R1框架，将预文本任务整合到MLLM的R1后训练范式中，要求模型同时处理关于变换的预文本问题和真实用户查询，从而必须识别变换方式并重建原始视频以得出准确答案。

Result: 在六个主流视频理解和推理基准上的实验表明，所提方法在复杂视频推理任务上优于现有方法，展现出更强的视觉推理能力和鲁棒性。

Conclusion: Pretext-GRPO和ViSS-R1有效提升了多模态大语言模型对视频内容的理解与推理能力，推动了以视觉为中心的视频理解研究发展。

Abstract: Complex video reasoning remains a significant challenge for Multimodal Large Language Models (MLLMs), as current R1-based methodologies often prioritize text-centric reasoning derived from text-based and image-based developments. In video tasks, such strategies frequently underutilize rich visual information, leading to potential shortcut learning and increased susceptibility to hallucination. To foster a more robust, visual-centric video understanding, we start by introducing a novel self-supervised reinforcement learning GRPO algorithm (Pretext-GRPO) within the standard R1 pipeline, in which positive rewards are assigned for correctly solving pretext tasks on transformed visual inputs, which makes the model to non-trivially process the visual information. Building on the effectiveness of Pretext-GRPO, we further propose the ViSS-R1 framework, which streamlines and integrates pretext-task-based self-supervised learning directly into the MLLM's R1 post-training paradigm. Instead of relying solely on sparse visual cues, our framework compels models to reason about transformed visual input by simultaneously processing both pretext questions (concerning transformations) and true user queries. This necessitates identifying the applied transformation and reconstructing the original video to formulate accurate final answers. Comprehensive evaluations on six widely-used video reasoning and understanding benchmarks demonstrate the effectiveness and superiority of our Pretext-GRPO and ViSS-R1 for complex video reasoning. Our codes and models will be publicly available.

</details>


### [214] [Monocular 3D Lane Detection via Structure Uncertainty-Aware Network with Curve-Point Queries](https://arxiv.org/abs/2511.13055)
*Ruixin Liu,Zejian Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种名为MonoUnc的无需鸟瞰图的单目3D车道检测方法，通过在前视图空间中建模3D车道并利用局部结构信息显式地估计随机不确定性，采用3D高斯分布对车道段进行建模，并设计了新的3D高斯匹配损失函数，在ONCE-3DLanes和OpenLane数据集上优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的单目3D车道检测方法依赖于简化的几何假设，难以捕捉真实场景中的结构变化和随机不确定性，因此需要一种能同时建模局部结构和不确定性的更鲁棒的方法。

Method: 将3D车道投影到前视图空间并用参数曲线近似；基于曲线预测动态生成查询嵌入以进行3D空间中的车道点预测；每个相邻点构成的线段被建模为3D高斯分布，并引入3D高斯匹配损失联合优化参数。

Result: 在ONCE-3DLanes和OpenLane数据集上，MonoUnc在更严格的评估标准下全面超越之前的最先进方法；提出了两种新的综合评估指标（平均与最大双向Chamfer距离）用于量化全局与局部误差。

Conclusion: MonoUnc通过结合局部结构感知的随机不确定性建模，在不依赖BEV的前提下显著提升了单目3D车道检测性能，具备更强的鲁棒性和精度。

Abstract: Monocular 3D lane detection is challenged by aleatoric uncertainty arising from inherent observation noise. Existing methods rely on simplified geometric assumptions, such as independent point predictions or global planar modeling, failing to capture structural variations and aleatoric uncertainty in real-world scenarios. In this paper, we propose MonoUnc, a bird's-eye view (BEV)-free 3D lane detector that explicitly models aleatoric uncertainty informed by local lane structures. Specifically, 3D lanes are projected onto the front-view (FV) space and approximated by parametric curves. Guided by curve predictions, curve-point query embeddings are dynamically generated for lane point predictions in 3D space. Each segment formed by two adjacent points is modeled as a 3D Gaussian, parameterized by the local structure and uncertainty estimations. Accordingly, a novel 3D Gaussian matching loss is designed to constrain these parameters jointly. Experiments on the ONCE-3DLanes and OpenLane datasets demonstrate that MonoUnc outperforms previous state-of-the-art (SoTA) methods across all benchmarks under stricter evaluation criteria. Additionally, we propose two comprehensive evaluation metrics for ONCE-3DLanes, calculating the average and maximum bidirectional Chamfer distances to quantify global and local errors. Codes are released at https://github.com/lrx02/MonoUnc.

</details>


### [215] [RobustGait: Robustness Analysis for Appearance Based Gait Recognition](https://arxiv.org/abs/2511.13065)
*Reeshoon Sayera,Akash Kumar,Sirshapan Mitra,Prudvi Kamtam,Yogesh S Rawat*

Main category: cs.CV

TL;DR: 本文提出了RobustGait框架，用于细粒度评估基于外观的步态识别系统在多种扰动、轮廓提取方法和模型架构下的鲁棒性，揭示了现有系统对噪声、轮廓偏差和不同部署场景的敏感性，并探索了提升鲁棒性的训练策略。


<details>
  <summary>Details</summary>
Motivation: 尽管基于外观的步态识别在受控数据集上表现良好，但其在真实世界中的退化因素和轮廓变化下的鲁棒性缺乏系统评估。

Method: 构建四维评估框架：扰动类型（数字、环境、时间、遮挡）、轮廓提取方法（分割与解析网络）、模型架构能力及部署场景；在CASIA-B、CCPG、SUSTech1K上引入15种5级严重程度的腐蚀类型，并在MEVID上进行野外验证，评估六种最先进系统。

Result: 发现RGB级噪声更能反映真实退化；轮廓提取器偏差显著影响精度，揭示基准偏倚问题；鲁棒性依赖于扰动类型与模型架构；噪声感知训练和知识蒸馏可提升性能。

Conclusion: RobustGait为步态识别提供了全面的鲁棒性评估基准，强调需联合优化轮廓提取与识别模型，并通过针对性训练策略推动实际部署。

Abstract: Appearance-based gait recognition have achieved strong performance on controlled datasets, yet systematic evaluation of its robustness to real-world corruptions and silhouette variability remains lacking. We present RobustGait, a framework for fine-grained robustness evaluation of appearance-based gait recognition systems. RobustGait evaluation spans four dimensions: the type of perturbation (digital, environmental, temporal, occlusion), the silhouette extraction method (segmentation and parsing networks), the architectural capacities of gait recognition models, and various deployment scenarios. The benchmark introduces 15 corruption types at 5 severity levels across CASIA-B, CCPG, and SUSTech1K, with in-the-wild validation on MEVID, and evaluates six state-of-the-art gait systems. We came across several exciting insights. First, applying noise at the RGB level better reflects real-world degradation, and reveal how distortions propagate through silhouette extraction to the downstream gait recognition systems. Second, gait accuracy is highly sensitive to silhouette extractor biases, revealing an overlooked source of benchmark bias. Third, robustness is dependent on both the type of perturbation and the architectural design. Finally, we explore robustness-enhancing strategies, showing that noise-aware training and knowledge distillation improve performance and move toward deployment-ready systems.

</details>


### [216] [Decoupling Scene Perception and Ego Status: A Multi-Context Fusion Approach for Enhanced Generalization in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.13079)
*Jiacheng Tang,Mingyue Feng,Jiachao Liu,Yaonong Wang,Jian Pu*

Main category: cs.CV

TL;DR: 本文提出AdaptiveAD，一种用于自动驾驶规划的模块化架构，通过解耦场景感知与自车状态来减少对自车状态的过度依赖，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶架构在上游BEV编码器中过早融合自车状态，导致下游规划模块过度依赖该强先验信息，限制了模型的泛化性和场景理解能力。

Method: 提出AdaptiveAD，采用双分支结构：一个分支在缺失自车状态的情况下进行多任务学习的场景驱动推理，另一个分支进行仅基于规划任务的自车驱动推理；通过场景感知融合模块自适应整合两者输出。引入路径注意力机制和两个辅助任务（BEV单向蒸馏、自回归在线建图）以维持多任务学习效果。

Result: 在nuScenes数据集上实现了最先进的开环规划性能，显著降低了对自车状态的依赖，并在多种场景下表现出优异的泛化能力。

Conclusion: AdaptiveAD通过架构层面的多上下文融合策略，有效解决了模块化端到端自动驾驶系统中对自车状态的过度依赖问题，提升了模型的鲁棒性和通用性。

Abstract: Modular design of planning-oriented autonomous driving has markedly advanced end-to-end systems. However, existing architectures remain constrained by an over-reliance on ego status, hindering generalization and robust scene understanding. We identify the root cause as an inherent design within these architectures that allows ego status to be easily leveraged as a shortcut. Specifically, the premature fusion of ego status in the upstream BEV encoder allows an information flow from this strong prior to dominate the downstream planning module. To address this challenge, we propose AdaptiveAD, an architectural-level solution based on a multi-context fusion strategy. Its core is a dual-branch structure that explicitly decouples scene perception and ego status. One branch performs scene-driven reasoning based on multi-task learning, but with ego status deliberately omitted from the BEV encoder, while the other conducts ego-driven reasoning based solely on the planning task. A scene-aware fusion module then adaptively integrates the complementary decisions from the two branches to form the final planning trajectory. To ensure this decoupling does not compromise multi-task learning, we introduce a path attention mechanism for ego-BEV interaction and add two targeted auxiliary tasks: BEV unidirectional distillation and autoregressive online mapping. Extensive evaluations on the nuScenes dataset demonstrate that AdaptiveAD achieves state-of-the-art open-loop planning performance. Crucially, it significantly mitigates the over-reliance on ego status and exhibits impressive generalization capabilities across diverse scenarios.

</details>


### [217] [Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations](https://arxiv.org/abs/2511.13081)
*Yehonatan Elisha,Seffi Cohen,Oren Barkan,Noam Koenigstein*

Main category: cs.CV

TL;DR: 本文提出了RFxG分类法，通过参考框架（点式与对比式解释）和粒度（类别级与组级）两个维度系统化组织显著性解释，并指出当前评估指标的局限性；为此设计了四个新指标，全面评估十种主流方法，推动以用户意图为导向的可解释性评估。


<details>
  <summary>Details</summary>
Motivation: 显著性图在深度学习中广泛用于视觉解释，但缺乏对其目标和与用户查询对齐的共识，导致评估困难且实用性受限。因此需要一个清晰的框架来统一理解和改进解释方法。

Method: 提出Reference-Frame × Granularity (RFxG) 分类法，将解释分为点式/对比式（Reference-Frame）和细粒度/粗粒度（Granularity）两类；基于此构建四个新的忠实性评估指标，并在十种显著性方法、四种模型架构和三个数据集上进行综合评估。

Result: 发现现有评估指标主要关注点式忠实性，忽视对比式推理和语义粒度；所提新指标能更全面地衡量解释质量，实验显示不同方法在RFxG不同维度表现差异显著。

Conclusion: RFxG分类法为视觉解释提供了概念基础，强调应根据用户意图设计和评估解释方法；所提出的评估框架有助于开发更符合人类认知需求的忠实且有意义的解释。

Abstract: Saliency maps are widely used for visual explanations in deep learning, but a fundamental lack of consensus persists regarding their intended purpose and alignment with diverse user queries. This ambiguity hinders the effective evaluation and practical utility of explanation methods.We address this gap by introducing the Reference-Frame $\times$ Granularity (RFxG) taxonomy, a principled conceptual framework that organizes saliency explanations along two essential axes:Reference-Frame: Distinguishing between pointwise ("Why this prediction?") and contrastive ("Why this and not an alternative?") explanations.Granularity: Ranging from fine-grained class-level (e.g., "Why Husky?") to coarse-grained group-level (e.g., "Why Dog?") interpretations.Using the RFxG lens, we demonstrate critical limitations in existing evaluation metrics, which overwhelmingly prioritize pointwise faithfulness while neglecting contrastive reasoning and semantic granularity. To systematically assess explanation quality across both RFxG dimensions, we propose four novel faithfulness metrics. Our comprehensive evaluation framework applies these metrics to ten state-of-the-art saliency methods, four model architectures, and three datasets.By advocating a shift toward user-intent-driven evaluation, our work provides both the conceptual foundation and the practical tools necessary to develop visual explanations that are not only faithful to the underlying model behavior but are also meaningfully aligned with the complexity of human understanding and inquiry.

</details>


### [218] [MergeSlide: Continual Model Merging and Task-to-Class Prompt-Aligned Inference for Lifelong Learning on Whole Slide Images](https://arxiv.org/abs/2511.13099)
*Doanh C. Bui,Ba Hung Ngo,Hoai Luan Pham,Khang Nguyen,Maï K. Nguyen,Yasuhiko Nakashima*

Main category: cs.CV

TL;DR: 本文提出了MergeSlide，一种基于视觉-语言病理基础模型的终生学习框架，通过正交持续合并策略和任务到类提示对齐推理，在处理全切片图像时有效缓解灾难性遗忘并提升多任务性能。


<details>
  <summary>Details</summary>
Motivation: 为了减少在多个癌症相关任务上训练或微调模型时所需的资源与数据处理开销，尤其是在处理千兆字节规模的全切片图像（WSI）时，需要一种高效的终生学习方法。

Method: 将终生学习视为模型合并问题：1）使用类别感知提示定义新任务；2）用无MLP的主干网络进行少量轮次微调；3）采用正交持续合并策略将模型合并至统一模型；推理阶段提出TCP方法，先识别最相关任务再应用对应提示进行预测。

Result: 在六个TCGA数据集流上实验表明，MergeSlide优于基于回放的持续学习方法和视觉-语言零样本基线方法，在CLASS-IL设置下表现出更强的性能。

Conclusion: MergeSlide通过模型合并与提示对齐策略，为全切片图像上的终生学习提供了一种高效且可扩展的解决方案，显著降低了资源消耗并保持了良好的模型性能。

Abstract: Lifelong learning on Whole Slide Images (WSIs) aims to train or fine-tune a unified model sequentially on cancer-related tasks, reducing the resources and effort required for data transfer and processing, especially given the gigabyte-scale size of WSIs. In this paper, we introduce MergeSlide, a simple yet effective framework that treats lifelong learning as a model merging problem by leveraging a vision-language pathology foundation model. When a new task arrives, it is: 1) defined with class-aware prompts, 2) fine-tuned for a few epochs using an MLP-free backbone, and 3) merged into a unified model using an orthogonal continual merging strategy that preserves performance and mitigates catastrophic forgetting. For inference under the class-incremental learning (CLASS-IL) setting, where task identity is unknown, we introduce Task-to-Class Prompt-aligned (TCP) inference. Specifically, TCP first identifies the most relevant task using task-level prompts and then applies the corresponding class-aware prompts to generate predictions. To evaluate MergeSlide, we conduct experiments on a stream of six TCGA datasets. The results show that MergeSlide outperforms both rehearsal-based continual learning and vision-language zero-shot baselines. Code and data are available at https://github.com/caodoanh2001/MergeSlide.

</details>


### [219] [CapeNext: Rethinking and refining dynamic support information for category-agnostic pose estimation](https://arxiv.org/abs/2511.13102)
*Yu Zhu,Dan Zeng,Shuiwang Li,Qijun Zhao,Qiaomu Shen,Bo Tang*

Main category: cs.CV

TL;DR: 本文提出了一种新的类别无关姿态估计框架CapeNext，通过引入层次化跨模态交互和双流特征优化机制，克服了传统静态关节嵌入在跨类别歧义和细粒度差异区分上的局限性，在MP-100数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的类别无关姿态估计方法使用固定的文本关键点描述作为语义先验，存在跨类别歧义（如“腿”在人与家具中的不同视觉表现）和难以区分细粒度类别内差异的问题，限制了匹配性能。

Method: 提出CapeNext框架，结合层次化跨模态交互与双流特征精炼机制，利用文本描述和特定图像中的类别级与实例级线索来增强关节嵌入，从而提升匹配准确性。

Result: 在MP-100数据集上的实验表明，无论采用何种网络骨干，CapeNext均大幅超越当前最先进的CAPE方法。

Conclusion: 通过动态融合多层次语义信息，CapeNext有效解决了静态嵌入带来的语义模糊问题，显著提升了类别无关姿态估计的精度与泛化能力。

Abstract: Recent research in Category-Agnostic Pose Estimation (CAPE) has adopted fixed textual keypoint description as semantic prior for two-stage pose matching frameworks. While this paradigm enhances robustness and flexibility by disentangling the dependency of support images, our critical analysis reveals two inherent limitations of static joint embedding: (1) polysemy-induced cross-category ambiguity during the matching process(e.g., the concept "leg" exhibiting divergent visual manifestations across humans and furniture), and (2) insufficient discriminability for fine-grained intra-category variations (e.g., posture and fur discrepancies between a sleeping white cat and a standing black cat). To overcome these challenges, we propose a new framework that innovatively integrates hierarchical cross-modal interaction with dual-stream feature refinement, enhancing the joint embedding with both class-level and instance-specific cues from textual description and specific images. Experiments on the MP-100 dataset demonstrate that, regardless of the network backbone, CapeNext consistently outperforms state-of-the-art CAPE methods by a large margin.

</details>


### [220] [PlugTrack: Multi-Perceptive Motion Analysis for Adaptive Fusion in Multi-Object Tracking](https://arxiv.org/abs/2511.13105)
*Seungjae Kim,SeungJoon Lee,MyeongAh Cho*

Main category: cs.CV

TL;DR: 本文提出了一种新的多目标跟踪框架PlugTrack，通过自适应融合卡尔曼滤波器和数据驱动的运动预测器来同时处理线性和非线性运动模式，在多个基准上实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多目标跟踪方法在处理非线性运动时表现不佳：传统卡尔曼滤波器计算高效但无法建模非线性动态，而数据驱动方法虽能捕捉复杂运动但泛化能力差且计算开销大。作者发现实际场景中线性和非线性运动并存，因此需要一种能够结合两者优势的自适应方法。

Method: 提出PlugTrack框架，引入多感知运动分析模块来自动生成卡尔曼滤波器与数据驱动预测器之间的自适应融合权重，从而实现对不同类型运动模式的鲁棒预测，且不修改现有预测器结构。

Result: PlugTrack在MOT17、MOT20和DanceTrack数据集上均取得显著性能提升，并在DanceTrack上达到当前最优水平。实验表明其有效融合了两类预测器的优势。

Conclusion: PlugTrack是首个将经典与现代运动预测方法通过自适应融合相结合的多目标跟踪框架，验证了混合策略在真实复杂场景中的有效性与潜力。

Abstract: Multi-object tracking (MOT) predominantly follows the tracking-by-detection paradigm, where Kalman filters serve as the standard motion predictor due to computational efficiency but inherently fail on non-linear motion patterns. Conversely, recent data-driven motion predictors capture complex non-linear dynamics but suffer from limited domain generalization and computational overhead. Through extensive analysis, we reveal that even in datasets dominated by non-linear motion, Kalman filter outperforms data-driven predictors in up to 34\% of cases, demonstrating that real-world tracking scenarios inherently involve both linear and non-linear patterns. To leverage this complementarity, we propose PlugTrack, a novel framework that adaptively fuses Kalman filter and data-driven motion predictors through multi-perceptive motion understanding. Our approach employs multi-perceptive motion analysis to generate adaptive blending factors. PlugTrack achieves significant performance gains on MOT17/MOT20 and state-of-the-art on DanceTrack without modifying existing motion predictors. To the best of our knowledge, PlugTrack is the first framework to bridge classical and modern motion prediction paradigms through adaptive fusion in MOT.

</details>


### [221] [Low-Level Dataset Distillation for Medical Image Enhancement](https://arxiv.org/abs/2511.13106)
*Fengzhi Xu,Ziyuan Yang,Mengyu Sun,Joey Tianyi Zhou,Yi Zhang*

Main category: cs.CV

TL;DR: 提出首个用于医学图像增强的低级数据集蒸馏方法，通过共享解剖先验和结构保持个性化生成模块，在减少数据存储与训练成本的同时保持像素级保真并保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像增强方法依赖大规模数据集，导致训练和存储成本高，且难以部署；而传统数据集蒸馏主要面向高层任务，不适用于需要像素级保真的低级任务。

Method: 构建基于代表性患者的共享解剖先验作为蒸馏数据初始化，结合结构保持个性化生成（SPG）模块融入患者特异性信息，并通过梯度对齐策略使蒸馏数据保留原始数据的训练效果。

Result: 在多个低级医学图像任务中实现了高效的数据压缩与模型训练性能，蒸馏数据显著减少存储需求的同时接近原始数据集的增强效果，并保障患者数据隐私。

Conclusion: 该方法成功解决了低级医学图像任务中数据蒸馏的欠定问题，实现了高效、隐私保护的模型训练，推动了数据集蒸馏在低级视觉任务中的应用。

Abstract: Medical image enhancement is clinically valuable, but existing methods require large-scale datasets to learn complex pixel-level mappings. However, the substantial training and storage costs associated with these datasets hinder their practical deployment. While dataset distillation (DD) can alleviate these burdens, existing methods mainly target high-level tasks, where multiple samples share the same label. This many-to-one mapping allows distilled data to capture shared semantics and achieve information compression. In contrast, low-level tasks involve a many-to-many mapping that requires pixel-level fidelity, making low-level DD an underdetermined problem, as a small distilled dataset cannot fully constrain the dense pixel-level mappings. To address this, we propose the first low-level DD method for medical image enhancement. We first leverage anatomical similarities across patients to construct the shared anatomical prior based on a representative patient, which serves as the initialization for the distilled data of different patients. This prior is then personalized for each patient using a Structure-Preserving Personalized Generation (SPG) module, which integrates patient-specific anatomical information into the distilled dataset while preserving pixel-level fidelity. For different low-level tasks, the distilled data is used to construct task-specific high- and low-quality training pairs. Patient-specific knowledge is injected into the distilled data by aligning the gradients computed from networks trained on the distilled pairs with those from the corresponding patient's raw data. Notably, downstream users cannot access raw patient data. Instead, only a distilled dataset containing abstract training information is shared, which excludes patient-specific details and thus preserves privacy.

</details>


### [222] [DGS-Net: Distillation-Guided Gradient Surgery for CLIP Fine-Tuning in AI-Generated Image Detection](https://arxiv.org/abs/2511.13108)
*Jiazhen Yan,Ziqiang Li,Fan Wang,Boyu Wang,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出DGS-Net，通过梯度空间分解与知识蒸馏在保持预训练先验的同时提升AI生成图像检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法在检测AI生成图像时易导致灾难性遗忘，损害预训练先验并限制跨域泛化能力。

Method: 提出DGS-Net框架，引入梯度空间分解机制，将任务梯度投影到有害方向的正交补空间，并对齐来自冻结CLIP编码器蒸馏出的有益方向，实现先验保持与无关分量抑制的统一优化。

Result: 在50种生成模型上实验表明，该方法平均优于现有最先进方法6.6个百分点，展现出卓越的检测性能和跨域泛化能力。

Conclusion: DGS-Net有效缓解了微调过程中的灾难性遗忘问题，在保留多模态模型迁移能力的同时显著提升了生成图像检测的性能和鲁棒性。

Abstract: The rapid progress of generative models such as GANs and diffusion models has led to the widespread proliferation of AI-generated images, raising concerns about misinformation, privacy violations, and trust erosion in digital media. Although large-scale multimodal models like CLIP offer strong transferable representations for detecting synthetic content, fine-tuning them often induces catastrophic forgetting, which degrades pre-trained priors and limits cross-domain generalization. To address this issue, we propose the Distillation-guided Gradient Surgery Network (DGS-Net), a novel framework that preserves transferable pre-trained priors while suppressing task-irrelevant components. Specifically, we introduce a gradient-space decomposition that separates harmful and beneficial descent directions during optimization. By projecting task gradients onto the orthogonal complement of harmful directions and aligning with beneficial ones distilled from a frozen CLIP encoder, DGS-Net achieves unified optimization of prior preservation and irrelevant suppression. Extensive experiments on 50 generative models demonstrate that our method outperforms state-of-the-art approaches by an average margin of 6.6, achieving superior detection performance and generalization across diverse generation techniques.

</details>


### [223] [Learning Implicit Neural Degradation Representation for Unpaired Image Dehazing](https://arxiv.org/abs/2511.13110)
*Shuaibin Fan,Senming Zhong,Wenchao Yan,Minglong Xue*

Main category: cs.CV

TL;DR: 本文提出了一种无监督的图像去雾方法NeDR-Dehaze，通过隐式神经退化表示建模雾霾的连续分布，结合通道依赖与独立机制提升非线性特征学习能力，并设计密集残差增强模块去除冗余信息，在多种数据集上实现了具有竞争力的去雾效果。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法在复杂场景下难以平衡局部细节与全局一致性，且依赖显式特征提取和物理模型，限制了对不均匀雾霾分布的建模能力。

Method: 基于Kolmogorov-Arnold定理设计通道依赖与独立机制的融合结构，采用隐式神经表示将雾霾退化建模为连续函数，并引入密集残差增强模块以优化隐式特征学习。

Result: 在多个公开及真实世界去雾数据集上取得具有竞争力的性能，视觉恢复质量高，尤其在复杂场景下表现良好。

Conclusion: 所提方法有效提升了无监督去雾中对复杂雾霾分布的建模能力，无需显式物理先验即可实现高质量图像恢复，具备良好的应用潜力。

Abstract: Image dehazing is an important task in the field of computer vision, aiming at restoring clear and detail-rich visual content from haze-affected images. However, when dealing with complex scenes, existing methods often struggle to strike a balance between fine-grained feature representation of inhomogeneous haze distribution and global consistency modeling. Furthermore, to better learn the common degenerate representation of haze in spatial variations, we propose an unsupervised dehaze method for implicit neural degradation representation. Firstly, inspired by the Kolmogorov-Arnold representation theorem, we propose a mechanism combining the channel-independent and channel-dependent mechanisms, which efficiently enhances the ability to learn from nonlinear dependencies. which in turn achieves good visual perception in complex scenes. Moreover, we design an implicit neural representation to model haze degradation as a continuous function to eliminate redundant information and the dependence on explicit feature extraction and physical models. To further learn the implicit representation of the haze features, we also designed a dense residual enhancement module from it to eliminate redundant information. This achieves high-quality image restoration. Experimental results show that our method achieves competitive dehaze performance on various public and real-world datasets. This project code will be available at https://github.com/Fan-pixel/NeDR-Dehaze.

</details>


### [224] [Semantics and Content Matter: Towards Multi-Prior Hierarchical Mamba for Image Deraining](https://arxiv.org/abs/2511.13113)
*Zhaocheng Yu,Kui Jiang,Junjun Jiang,Xianming Liu,Guanglu Sun,Yi Xiao*

Main category: cs.CV

TL;DR: 提出了一种结合宏观语义文本先验（CLIP）和微观结构视觉先验（DINOv2）的多先验分层Mamba网络（MPHM），用于图像去雨，通过渐进式先验融合注入机制和分层Mamba模块提升语义和空间细节恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有去雨方法在语义和空间细节保真方面存在不足，影响自动驾驶和视频监控等应用中的性能。

Method: 设计了多先验分层Mamba网络（MPHM），融合CLIP的语义先验与DINOv2的结构先验；采用渐进式先验融合注入（PFI）策略在解码器不同层级融合先验信息；引入基于傅里叶增强双路径结构的分层Mamba模块（HMM）以增强全局建模与局部细节恢复。

Result: 在Rain200H数据集上实现了0.57 dB的PSNR提升，并在真实场景去雨任务中表现出优异的泛化能力。

Conclusion: MPHM通过有效融合多模态先验信息和改进特征表示，在图像去雨任务中达到了先进水平，显著提升了去雨图像的质量和实际应用潜力。

Abstract: Rain significantly degrades the performance of computer vision systems, particularly in applications like autonomous driving and video surveillance. While existing deraining methods have made considerable progress, they often struggle with fidelity of semantic and spatial details. To address these limitations, we propose the Multi-Prior Hierarchical Mamba (MPHM) network for image deraining. This novel architecture synergistically integrates macro-semantic textual priors (CLIP) for task-level semantic guidance and micro-structural visual priors (DINOv2) for scene-aware structural information. To alleviate potential conflicts between heterogeneous priors, we devise a progressive Priors Fusion Injection (PFI) that strategically injects complementary cues at different decoder levels. Meanwhile, we equip the backbone network with an elaborate Hierarchical Mamba Module (HMM) to facilitate robust feature representation, featuring a Fourier-enhanced dual-path design that concurrently addresses global context modeling and local detail recovery. Comprehensive experiments demonstrate MPHM's state-of-the-art performance, achieving a 0.57 dB PSNR gain on the Rain200H dataset while delivering superior generalization on real-world rainy scenarios.

</details>


### [225] [A Lightweight 3D Anomaly Detection Method with Rotationally Invariant Features](https://arxiv.org/abs/2511.13115)
*Hanzhe Liang,Jie Zhou,Can Gao,Bingyang Guo,Jinbao Wang,Linlin Shen*

Main category: cs.CV

TL;DR: 提出了一种旋转不变特征（RIF）框架用于3D异常检测，通过点坐标映射（PCM）和轻量级CTF-Net提取鲁棒特征，并结合迁移学习提升性能，在多个数据集上取得了先进表现。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测方法在处理姿态和位置变化的点云时特征不稳定，影响检测性能。

Method: 提出RIF框架，包括PCM技术将点映射到旋转不变空间，设计CTF-Net提取不变特征，并采用3D数据增强进行迁移学习预训练。

Result: 在Anomaly-ShapeNet上平均P-AUROC提升17.7%，在Real3D-AD上提升1.6%，且具备强泛化能力。

Conclusion: RIF框架有效提升了3D异常检测的鲁棒性和准确性，具有良好的工业应用潜力。

Abstract: 3D anomaly detection (AD) is a crucial task in computer vision, aiming to identify anomalous points or regions from point cloud data. However, existing methods may encounter challenges when handling point clouds with changes in orientation and position because the resulting features may vary significantly. To address this problem, we propose a novel Rotationally Invariant Features (RIF) framework for 3D AD. Firstly, to remove the adverse effect of variations on point cloud data, we develop a Point Coordinate Mapping (PCM) technique, which maps each point into a rotationally invariant space to maintain consistency of representation. Then, to learn robust and discriminative features, we design a lightweight Convolutional Transform Feature Network (CTF-Net) to extract rotationally invariant features for the memory bank. To improve the ability of the feature extractor, we introduce the idea of transfer learning to pre-train the feature extractor with 3D data augmentation. Experimental results show that the proposed method achieves the advanced performance on the Anomaly-ShapeNet dataset, with an average P-AUROC improvement of 17.7\%, and also gains the best performance on the Real3D-AD dataset, with an average P-AUROC improvement of 1.6\%. The strong generalization ability of RIF has been verified by combining it with traditional feature extraction methods on anomaly detection tasks, demonstrating great potential for industrial applications.

</details>


### [226] [CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model](https://arxiv.org/abs/2511.13121)
*Yuqi Zhang,Guanying Chen,Jiaxing Chen,Chuanyu Fu,Chuan Huang,Shuguang Cui*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的框架CloseUpShot，用于从稀疏输入视图中实现近景新视角合成，通过分层warpping、遮挡感知噪声抑制和全局结构引导提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理视角变化较大的近景场景时，由于输入信息稀疏且存在背景泄漏问题，难以捕捉精细细节，因此需要更鲁棒的方法来提升稀疏视图下的新视角合成质量。

Method: 提出CloseUpShot框架，采用点云条件化视频扩散模型，引入分层warpping和遮挡感知噪声抑制以改善条件图像质量，并利用稠密融合点云提供全局结构引导，增强几何一致性。

Result: 在多个数据集上的实验表明，该方法在近景新视角合成任务上优于现有方法，尤其在细节恢复和完整性方面表现突出。

Conclusion: CloseUpShot通过改进条件生成和引入全局几何引导，在稀疏输入下显著提升了近景新视角合成的效果，验证了其设计的有效性。

Abstract: Reconstructing 3D scenes and synthesizing novel views from sparse input views is a highly challenging task. Recent advances in video diffusion models have demonstrated strong temporal reasoning capabilities, making them a promising tool for enhancing reconstruction quality under sparse-view settings. However, existing approaches are primarily designed for modest viewpoint variations, which struggle in capturing fine-grained details in close-up scenarios since input information is severely limited. In this paper, we present a diffusion-based framework, called CloseUpShot, for close-up novel view synthesis from sparse inputs via point-conditioned video diffusion. Specifically, we observe that pixel-warping conditioning suffers from severe sparsity and background leakage in close-up settings. To address this, we propose hierarchical warping and occlusion-aware noise suppression, enhancing the quality and completeness of the conditioning images for the video diffusion model. Furthermore, we introduce global structure guidance, which leverages a dense fused point cloud to provide consistent geometric context to the diffusion process, to compensate for the lack of globally consistent 3D constraints in sparse conditioning inputs. Extensive experiments on multiple datasets demonstrate that our method outperforms existing approaches, especially in close-up novel view synthesis, clearly validating the effectiveness of our design.

</details>


### [227] [VEIL: Jailbreaking Text-to-Video Models via Visual Exploitation from Implicit Language](https://arxiv.org/abs/2511.13127)
*Zonghao Ying,Moyang Chen,Nizhang Li,Zhiqiang Wang,Wenxin Zhang,Quanchen Zou,Zonglei Jing,Aishan Liu,Xianglong Liu*

Main category: cs.CV

TL;DR: 提出一种名为VEIL的越狱框架，利用文本到视频模型的跨模态关联模式，通过模块化提示设计生成语义上不安全但表面上良性的视频内容，显著提升攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有对文本到视频模型的越狱攻击通常依赖明显不安全提示上的对抗扰动，易被检测和防御；需要探索更隐蔽、基于隐含线索的攻击方式以揭示模型安全隐患。

Method: 提出VEIL框架，采用模块化提示设计，包含中性场景锚点、潜在听觉触发词和风格调制器三部分，并通过约束优化与引导搜索策略生成有效且隐蔽的攻击提示。

Result: 在7个文本到视频模型上实验表明，该方法在商业模型中的平均攻击成功率提升了23%。

Conclusion: 良性外观提示结合隐含语义线索可有效绕过T2V模型的安全防护，揭示了模型在跨模态关联上的脆弱性，强调需加强对此类隐蔽攻击的防御。

Abstract: Jailbreak attacks can circumvent model safety guardrails and reveal critical blind spots. Prior attacks on text-to-video (T2V) models typically add adversarial perturbations to obviously unsafe prompts, which are often easy to detect and defend. In contrast, we show that benign-looking prompts containing rich, implicit cues can induce T2V models to generate semantically unsafe videos that both violate policy and preserve the original (blocked) intent. To realize this, we propose VEIL, a jailbreak framework that leverages T2V models' cross-modal associative patterns via a modular prompt design. Specifically, our prompts combine three components: neutral scene anchors, which provide the surface-level scene description extracted from the blocked intent to maintain plausibility; latent auditory triggers, textual descriptions of innocuous-sounding audio events (e.g., creaking, muffled noises) that exploit learned audio-visual co-occurrence priors to bias the model toward particular unsafe visual concepts; and stylistic modulators, cinematic directives (e.g., camera framing, atmosphere) that amplify and stabilize the latent trigger's effect. We formalize attack generation as a constrained optimization over the above modular prompt space and solve it with a guided search procedure that balances stealth and effectiveness. Extensive experiments over 7 T2V models demonstrate the efficacy of our attack, achieving a 23 percent improvement in average attack success rate in commercial models.

</details>


### [228] [Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack](https://arxiv.org/abs/2511.13132)
*Chenyang Li,Wenbing Tang,Yihao Huang,Sinong Simon Zhan,Ming Hu,Xiaojun Jia,Yang Liu*

Main category: cs.CV

TL;DR: 提出了一种基于室内光照的黑盒对抗攻击框架ILA，用于揭示视觉-语言导航（VLN）智能体在真实室内光照变化下的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗评估多依赖于不自然的纹理扰动，缺乏实际意义；而室内光照作为影响导航的关键因素被忽视，因此需要研究更现实的攻击场景。

Method: 设计了两种攻击模式：静态光照攻击（SILA）和动态光照切换攻击（DILA），通过调整全局光照强度干扰VLN智能体，评估其在不同导航任务中的鲁棒性。

Result: 在两个最先进的VLN模型和三个导航任务上验证了ILA的有效性，显著提高了失败率并降低了路径效率。

Conclusion: VLN智能体对现实中的室内光照变化高度敏感，ILA揭示了其在实际部署中可能面临的鲁棒性问题。

Abstract: Vision-and-Language Navigation (VLN) agents have made remarkable progress, but their robustness remains insufficiently studied. Existing adversarial evaluations often rely on perturbations that manifest as unusual textures rarely encountered in everyday indoor environments. Errors under such contrived conditions have limited practical relevance, as real-world agents are unlikely to encounter such artificial patterns. In this work, we focus on indoor lighting, an intrinsic yet largely overlooked scene attribute that strongly influences navigation. We propose Indoor Lighting-based Adversarial Attack (ILA), a black-box framework that manipulates global illumination to disrupt VLN agents. Motivated by typical household lighting usage, we design two attack modes: Static Indoor Lighting-based Attack (SILA), where the lighting intensity remains constant throughout an episode, and Dynamic Indoor Lighting-based Attack (DILA), where lights are switched on or off at critical moments to induce abrupt illumination changes. We evaluate ILA on two state-of-the-art VLN models across three navigation tasks. Results show that ILA significantly increases failure rates while reducing trajectory efficiency, revealing previously unrecognized vulnerabilities of VLN agents to realistic indoor lighting variations.

</details>


### [229] [MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation](https://arxiv.org/abs/2511.13135)
*Junjie Yang,Yuhao Yan,Gang Wu,Yuxuan Wang,Ruoyu Liang,Xinjie Jiang,Xiang Wan,Fenglei Fan,Yongquan Zhang,Feiwei Qin,Changmiao Wan*

Main category: cs.CV

TL;DR: 本文提出了MedGEN-Bench，一个面向医学视觉-语言模型的综合性多模态基准，包含6,422个专家验证的图像-文本对，覆盖六种成像模态、16项临床任务和28个子任务，支持视觉问答、图像编辑和上下文多模态生成三种格式，并采用结合像素级指标、语义分析和临床相关性评分的三层次评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉基准存在查询模糊、诊断推理简化和忽视图像生成能力等问题，难以满足临床对AI生成诊断文本及对应医学图像的需求，因此需要构建更贴近真实临床工作流的多模态评估基准。

Method: 构建MedGEN-Bench，包含多种模态与临床任务的图像-文本对，设计三种任务格式（VQA、图像编辑、多模态生成），并提出三层次评估体系：像素级指标、语义文本分析和专家指导下的临床相关性评分，用于系统评估现有模型性能。

Result: MedGEN-Bench包含6,422个专家验证样本，涵盖六种成像模态、16项临床任务和28个子任务；通过三层次评估框架对10个组合式框架、3个统一模型和5个视觉语言模型进行了系统评测，揭示了当前模型在跨模态推理与生成能力上的局限性。

Conclusion: MedGEN-Bench为医学AI提供了更具临床相关性和挑战性的多模态评估平台，推动模型从封闭式问答向开放式、上下文关联的生成能力发展，促进AI在真实临床场景中的应用落地。

Abstract: As Vision-Language Models (VLMs) increasingly gain traction in medical applications, clinicians are progressively expecting AI systems not only to generate textual diagnoses but also to produce corresponding medical images that integrate seamlessly into authentic clinical workflows. Despite the growing interest, existing medical visual benchmarks present notable limitations. They often rely on ambiguous queries that lack sufficient relevance to image content, oversimplify complex diagnostic reasoning into closed-ended shortcuts, and adopt a text-centric evaluation paradigm that overlooks the importance of image generation capabilities. To address these challenges, we introduce \textsc{MedGEN-Bench}, a comprehensive multimodal benchmark designed to advance medical AI research. MedGEN-Bench comprises 6,422 expert-validated image-text pairs spanning six imaging modalities, 16 clinical tasks, and 28 subtasks. It is structured into three distinct formats: Visual Question Answering, Image Editing, and Contextual Multimodal Generation. What sets MedGEN-Bench apart is its focus on contextually intertwined instructions that necessitate sophisticated cross-modal reasoning and open-ended generative outputs, moving beyond the constraints of multiple-choice formats. To evaluate the performance of existing systems, we employ a novel three-tier assessment framework that integrates pixel-level metrics, semantic text analysis, and expert-guided clinical relevance scoring. Using this framework, we systematically assess 10 compositional frameworks, 3 unified models, and 5 VLMs.

</details>


### [230] [WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection](https://arxiv.org/abs/2511.13138)
*Longhui Zheng,Qiming Xia,Xiaolu Chen,Zhaoliang Liu,Chenglu Wen*

Main category: cs.CV

TL;DR: 提出WinMamba，一种基于Mamba的3D特征编码骨干网络，用于提升自动驾驶中3D目标检测的效率与长距离依赖建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba模型在3D检测中因固定窗口轴对齐扫描丢失空间信息，难以兼顾效率与全局上下文捕捉。

Method: 设计WinMamba块，引入窗口尺度自适应模块（AWF）和可学习位置编码与窗口移位策略（WSF），增强多尺度表征与上下文建模。

Result: 在KITTI和Waymo数据集上显著优于基线，消融实验验证了各模块对检测精度的贡献。

Conclusion: WinMamba有效平衡了效率与性能，通过改进扫描策略和多尺度特征融合，提升了3D目标检测的准确性和上下文感知能力。

Abstract: 3D object detection is critical for autonomous driving, yet it remains fundamentally challenging to simultaneously maximize computational efficiency and capture long-range spatial dependencies. We observed that Mamba-based models, with their linear state-space design, capture long-range dependencies at lower cost, offering a promising balance between efficiency and accuracy. However, existing methods rely on axis-aligned scanning within a fixed window, inevitably discarding spatial information. To address this problem, we propose WinMamba, a novel Mamba-based 3D feature-encoding backbone composed of stacked WinMamba blocks. To enhance the backbone with robust multi-scale representation, the WinMamba block incorporates a window-scale-adaptive module that compensates voxel features across varying resolutions during sampling. Meanwhile, to obtain rich contextual cues within the linear state space, we equip the WinMamba layer with a learnable positional encoding and a window-shift strategy. Extensive experiments on the KITTI and Waymo datasets demonstrate that WinMamba significantly outperforms the baseline. Ablation studies further validate the individual contributions of the WSF and AWF modules in improving detection accuracy. The code will be made publicly available.

</details>


### [231] [Automated Road Distress Detection Using Vision Transformersand Generative Adversarial Networks](https://arxiv.org/abs/2511.13145)
*Cesar Portocarrero Rodriguez,Laura Vandeweyen,Yosuke Yamamoto*

Main category: cs.CV

TL;DR: 本研究探索了使用计算机视觉技术进行路面病害分割的方法，利用生成对抗网络（GAN）生成的合成数据提升模型性能，并发现基于Transformer的MaskFormer模型在mAP50和IoU两个指标上优于传统的卷积神经网络（CNN）模型。


<details>
  <summary>Details</summary>
Motivation: 美国道路基础设施状况不佳，传统检测方法成本高且耗时，亟需高效、自动化的道路监测手段以支持基础设施修复工作。

Method: 采用生成对抗网络（GAN）生成合成数据用于训练，比较卷积神经网络（CNN）与基于Transformer的MaskFormer模型在路面病害分割任务中的表现。

Result: GAN生成的数据能够提升模型性能；MaskFormer在mAP50和IoU指标上优于CNN模型。

Conclusion: 结合合成数据与先进CV模型（如MaskFormer）可有效提升路面病害识别精度，为道路基础设施的自动化监测提供了可行方案。

Abstract: The American Society of Civil Engineers has graded Americas infrastructure condition as a C, with the road system receiving a dismal D. Roads are vital to regional economic viability, yet their management, maintenance, and repair processes remain inefficient, relying on outdated manual or laser-based inspection methods that are both costly and time-consuming. With the increasing availability of real-time visual data from autonomous vehicles, there is an opportunity to apply computer vision (CV) methods for advanced road monitoring, providing insights to guide infrastructure rehabilitation efforts. This project explores the use of state-of-the-art CV techniques for road distress segmentation. It begins by evaluating synthetic data generated with Generative Adversarial Networks (GANs) to assess its usefulness for model training. The study then applies Convolutional Neural Networks (CNNs) for road distress segmentation and subsequently examines the transformer-based model MaskFormer. Results show that GAN-generated data improves model performance and that MaskFormer outperforms the CNN model in two metrics: mAP50 and IoU.

</details>


### [232] [Skeletons Speak Louder than Text: A Motion-Aware Pretraining Paradigm for Video-Based Person Re-Identification](https://arxiv.org/abs/2511.13150)
*Rifen Lin,Alex Jinpeng Wang,Jiawei Mo,Min Li*

Main category: cs.CV

TL;DR: 本文提出了CSIP-ReID，首个基于骨架的视频行人重识别预训练框架，通过对比骨架-图像预训练和动态原型融合机制，在多个基准上实现了最先进的性能，并展现出对骨架数据的良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的多模态预训练方法在视频行人重识别中存在缺乏真正多模态预训练和文本难以捕捉细粒度时序运动的问题，因此需要一种更有效、运动感知的预训练范式。

Method: 提出两阶段的CSIP-ReID框架：第一阶段通过对比学习对齐骨架序列与视觉特征；第二阶段引入动态原型融合更新器（PFU）融合外观与时序线索，并设计骨架引导的时序建模模块（SGTM）从骨架数据中提取并整合时序信息。

Result: 在MARS、LS-VID、iLIDS-VID等视频ReID基准上达到最先进性能，且在BIWI、IAS等骨架ReID任务中表现出强泛化能力，显著优于先前方法。

Conclusion: CSIP-ReID开创了一种无需标注、运动感知的行人重识别预训练新范式，为多模态表征学习开辟了新方向。

Abstract: Multimodal pretraining has revolutionized visual understanding, but its impact on video-based person re-identification (ReID) remains underexplored. Existing approaches often rely on video-text pairs, yet suffer from two fundamental limitations: (1) lack of genuine multimodal pretraining, and (2) text poorly captures fine-grained temporal motion-an essential cue for distinguishing identities in video. In this work, we take a bold departure from text-based paradigms by introducing the first skeleton-driven pretraining framework for ReID. To achieve this, we propose Contrastive Skeleton-Image Pretraining for ReID (CSIP-ReID), a novel two-stage method that leverages skeleton sequences as a spatiotemporally informative modality aligned with video frames. In the first stage, we employ contrastive learning to align skeleton and visual features at sequence level. In the second stage, we introduce a dynamic Prototype Fusion Updater (PFU) to refine multimodal identity prototypes, fusing motion and appearance cues. Moreover, we propose a Skeleton Guided Temporal Modeling (SGTM) module that distills temporal cues from skeleton data and integrates them into visual features. Extensive experiments demonstrate that CSIP-ReID achieves new state-of-the-art results on standard video ReID benchmarks (MARS, LS-VID, iLIDS-VID). Moreover, it exhibits strong generalization to skeleton-only ReID tasks (BIWI, IAS), significantly outperforming previous methods. CSIP-ReID pioneers an annotation-free and motion-aware pretraining paradigm for ReID, opening a new frontier in multimodal representation learning.

</details>


### [233] [SOMA: Feature Gradient Enhanced Affine-Flow Matching for SAR-Optical Registration](https://arxiv.org/abs/2511.13168)
*Haodong Wang,Tao Zhuo,Xiuwei Zhang,Hanlin Yin,Wencong Wu,Yanning Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SOMA的密集配准框架，用于解决SAR与光学图像在像素级对齐上的挑战，通过引入结构梯度先验和混合匹配策略显著提升了跨模态图像配准精度。


<details>
  <summary>Details</summary>
Motivation: 由于SAR与光学图像成像机制和视觉特征差异大，现有深度学习方法在跨模态配准中表现不佳，且传统有效的梯度信息未被充分挖掘。

Method: 提出SOMA框架，包含特征梯度增强模块（FGE），将多尺度多方向梯度滤波器通过注意力和重构机制嵌入特征空间；并设计全局-局部仿射-光流匹配器（GLAM），结合仿射变换与光流细化实现由粗到精的配准。

Result: 在SEN1-2和GFGE_SO数据集上，CMR@1px分别提升了12.29%和18.50%，表现出更强的鲁棒性和泛化能力。

Conclusion: SOMA通过融合结构梯度先验与混合匹配策略，有效提升了SAR与光学图像的像素级配准精度，具有良好的应用前景。

Abstract: Achieving pixel-level registration between SAR and optical images remains a challenging task due to their fundamentally different imaging mechanisms and visual characteristics. Although deep learning has achieved great success in many cross-modal tasks, its performance on SAR-Optical registration tasks is still unsatisfactory. Gradient-based information has traditionally played a crucial role in handcrafted descriptors by highlighting structural differences. However, such gradient cues have not been effectively leveraged in deep learning frameworks for SAR-Optical image matching. To address this gap, we propose SOMA, a dense registration framework that integrates structural gradient priors into deep features and refines alignment through a hybrid matching strategy. Specifically, we introduce the Feature Gradient Enhancer (FGE), which embeds multi-scale, multi-directional gradient filters into the feature space using attention and reconstruction mechanisms to boost feature distinctiveness. Furthermore, we propose the Global-Local Affine-Flow Matcher (GLAM), which combines affine transformation and flow-based refinement within a coarse-to-fine architecture to ensure both structural consistency and local accuracy. Experimental results demonstrate that SOMA significantly improves registration precision, increasing the CMR@1px by 12.29% on the SEN1-2 dataset and 18.50% on the GFGE_SO dataset. In addition, SOMA exhibits strong robustness and generalizes well across diverse scenes and resolutions.

</details>


### [234] [THIR: Topological Histopathological Image Retrieval](https://arxiv.org/abs/2511.13170)
*Zahra Tabatabaei,Jon Sporring*

Main category: cs.CV

TL;DR: 本文提出了一种基于拓扑数据分析的无监督内容型医学图像检索框架THIR，利用持续同调中的贝蒂数提取乳腺病理图像的拓扑特征，实现高效、无需训练且可解释的图像检索。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的重要原因，早期诊断依赖准确的医学图像分析。现有深度学习方法需要大量标注数据和计算资源，限制了其在临床中的广泛应用，因此需要一种无需训练、快速且可解释的图像检索方法。

Method: 提出THIR框架，采用立方体持续同调从RGB病理图像中提取贝蒂数作为拓扑指纹，生成紧凑且可解释的特征向量，并通过计算这些拓扑描述符之间的距离进行相似性检索。

Result: 在BreaKHis数据集上的实验表明，THIR优于现有的有监督和无监督方法，能在标准CPU上20分钟内处理完整数据集，实现快速、可扩展的图像检索。

Conclusion: THIR提供了一种无需训练、高效且可解释的医学图像检索方案，具有良好的临床应用潜力，尤其适用于资源有限的环境。

Abstract: According to the World Health Organization, breast cancer claimed the lives of approximately 685,000 women in 2020. Early diagnosis and accurate clinical decision making are critical in reducing this global burden. In this study, we propose THIR, a novel Content-Based Medical Image Retrieval (CBMIR) framework that leverages topological data analysis specifically, Betti numbers derived from persistent homology to characterize and retrieve histopathological images based on their intrinsic structural patterns. Unlike conventional deep learning approaches that rely on extensive training, annotated datasets, and powerful GPU resources, THIR operates entirely without supervision. It extracts topological fingerprints directly from RGB histopathological images using cubical persistence, encoding the evolution of loops as compact, interpretable feature vectors. The similarity retrieval is then performed by computing the distances between these topological descriptors, efficiently returning the top-K most relevant matches.
  Extensive experiments on the BreaKHis dataset demonstrate that THIR outperforms state of the art supervised and unsupervised methods. It processes the entire dataset in under 20 minutes on a standard CPU, offering a fast, scalable, and training free solution for clinical image retrieval.

</details>


### [235] [HDW-SR: High-Frequency Guided Diffusion Model based on Wavelet Decomposition for Image Super-Resolution](https://arxiv.org/abs/2511.13175)
*Chao Yang,Boqian Zhang,Jinghao Xu,Guang Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于小波分解的高频引导扩散网络HDW-SR，用于单幅图像超分辨率，通过在残差图上进行扩散并引入小波下采样和动态阈值模块，有效恢复高频细节。


<details>
  <summary>Details</summary>
Motivation: 现有扩散方法在高频信息恢复上不足，导致结果模糊，因此需要更强的高频引导机制。

Method: 采用小波分解替代传统CNN下采样，仅对残差图进行扩散，并利用稀疏交叉注意力实现高频子带与低频子带间的显式高频引导，结合动态阈值块优化高频选择。

Result: 在合成和真实数据集上均取得有竞争力的结果，尤其在精细纹理恢复方面表现突出。

Conclusion: HDW-SR通过小波多尺度分解和高频引导机制，显著提升了超分辨率中的细节恢复能力。

Abstract: Diffusion-based methods have shown great promise in single image super-resolution (SISR); however, existing approaches often produce blurred fine details due to insufficient guidance in the high-frequency domain. To address this issue, we propose a High-Frequency Guided Diffusion Network based on Wavelet Decomposition (HDW-SR), which replaces the conventional U-Net backbone in diffusion frameworks. Specifically, we perform diffusion only on the residual map, allowing the network to focus more effectively on high-frequency information restoration. We then introduce wavelet-based downsampling in place of standard CNN downsampling to achieve multi-scale frequency decomposition, enabling sparse cross-attention between the high-frequency subbands of the pre-super-resolved image and the low-frequency subbands of the diffused image for explicit high-frequency guidance. Moreover, a Dynamic Thresholding Block (DTB) is designed to refine high-frequency selection during the sparse attention process. During upsampling, the invertibility of the wavelet transform ensures low-loss feature reconstruction. Experiments on both synthetic and real-world datasets demonstrate that HDW-SR achieves competitive super-resolution performance, excelling particularly in recovering fine-grained image details. The code will be available after acceptance.

</details>


### [236] [GenTract: Generative Global Tractography](https://arxiv.org/abs/2511.13183)
*Alec Sargood,Lemuel Puglisi,Elinor Thompson,Mirco Musolesi,Daniel C. Alexander*

Main category: cs.CV

TL;DR: GenTract是首个用于全局纤维追踪的生成模型，通过将扩散磁共振成像（dMRI）直接映射到完整的、解剖学上合理的纤维束路径，显著提高了追踪精度，尤其在低分辨率和噪声数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统局部纤维追踪方法易产生误差累积和高假阳性率，而全局方法计算成本高，因此需要一种高效且精确的新方法。

Method: 提出GenTract，将纤维追踪视为生成任务，采用扩散模型和流匹配范式，学习从dMRI数据到完整纤维束路径的直接映射。

Result: GenTract的精度达到现有最佳方法TractOracle的2.1倍，在低分辨率和噪声环境下性能优势更加明显，超过竞争对手一个数量级。

Conclusion: GenTract在研究级数据和低质量数据上均表现出高精度和可靠性，为全局纤维追踪提供了一种有前景的解决方案。

Abstract: Tractography is the process of inferring the trajectories of white-matter pathways in the brain from diffusion magnetic resonance imaging (dMRI). Local tractography methods, which construct streamlines by following local fiber orientation estimates stepwise through an image, are prone to error accumulation and high false positive rates, particularly on noisy or low-resolution data. In contrast, global methods, which attempt to optimize a collection of streamlines to maximize compatibility with underlying fiber orientation estimates, are computationally expensive. To address these challenges, we introduce GenTract, the first generative model for global tractography. We frame tractography as a generative task, learning a direct mapping from dMRI to complete, anatomically plausible streamlines. We compare both diffusion-based and flow matching paradigms and evaluate GenTract's performance against state-of-the-art baselines. Notably, GenTract achieves precision 2.1x higher than the next-best method, TractOracle. This advantage becomes even more pronounced in challenging low-resolution and noisy settings, where it outperforms the closest competitor by an order of magnitude. By producing tractograms with high precision on research-grade data while also maintaining reliability on imperfect, lower-resolution data, GenTract represents a promising solution for global tractography.

</details>


### [237] [Video Spatial Reasoning with Object-Centric 3D Rollout](https://arxiv.org/abs/2511.13190)
*Haoran Tang,Meng Cao,Ruyang Liu,Xiaoxi Liang,Linglong Li,Ge Li,Xiaodan Liang*

Main category: cs.CV

TL;DR: 提出了一种名为Object-Centric 3D Rollout (OCR)的新方法，通过在训练中引入3D几何扰动来增强多模态大模型的视频空间推理能力，显著提升了在VSI-Bench上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有模型在视频空间推理中存在查询锁定问题，难以捕捉未明确提及的对象和上下文关系，缺乏对动态3D场景的整体理解。

Method: 在训练过程中对选定对象的3D几何结构施加结构化扰动，削弱特定对象的视觉线索，并将修改后的几何投影到2D空间；设计基于rollout的训练流程，联合使用原始视频和区域加噪视频优化空间推理轨迹。

Result: 3B参数模型在VSI-Bench上达到47.5%的准确率，超过多个7B基线模型；消融实验表明OCR优于T-GRPO、NoisyRollout等先前方法。

Conclusion: OCR能有效提升多模态大模型在复杂动态场景中的整体空间推理能力，缓解查询锁定问题，为小规模模型实现高性能视频理解提供了可行路径。

Abstract: Recent advances in Multi-modal Large Language Models (MLLMs) have showcased remarkable capabilities in vision-language understanding. However, enabling robust video spatial reasoning-the ability to comprehend object locations, orientations, and inter-object relationships in dynamic 3D scenes-remains a key unsolved challenge. Existing approaches primarily rely on spatially grounded supervised fine-tuning or reinforcement learning, yet we observe that such models often exhibit query-locked reasoning, focusing narrowly on objects explicitly mentioned in the prompt while ignoring critical contextual cues. To address this limitation, we propose Object-Centric 3D Rollout (OCR), a novel strategy that introduces structured perturbations to the 3D geometry of selected objects during training. By degrading object-specific visual cues and projecting the altered geometry into 2D space, OCR compels the model to reason holistically across the entire scene. We further design a rollout-based training pipeline that jointly leverages vanilla and region-noisy videos to optimize spatial reasoning trajectories. Experiments demonstrate state-of-the-art performance: our 3B-parameter model achieves 47.5% accuracy on VSI-Bench, outperforming several 7B baselines. Ablations confirm OCR's superiority over prior rollout strategies (e.g., T-GRPO, NoisyRollout).

</details>


### [238] [Birth of a Painting: Differentiable Brushstroke Reconstruction](https://arxiv.org/abs/2511.13191)
*Ying Jiang,Jiayin Lu,Yunuo Chen,Yumeng He,Kui Wu,Yin Yang,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: 提出了一种可微分的笔画重建框架，统一了绘画、风格化纹理和涂抹过程，能够逼真地再现人类绘画-涂抹循环。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在绘画合成中缺乏明确的笔画结构，无法实现平滑自然的着色效果，且多局限于最终图像生成或基于局部块的模拟。

Method: 通过并行可微渲染器优化单色和双色贝塞尔笔画，结合几何条件纹理生成模块和可微涂抹算子，采用由粗到细的优化策略，在几何与语义引导下联合优化笔画几何、颜色和纹理。

Result: 在油画、水彩、墨水和数字绘画上实验表明，该方法能生成逼真的笔画结构、平滑的色调过渡和丰富的风格化外观。

Conclusion: 该框架为表达性数字绘画创作提供了一个统一且真实感强的解决方案，有效模拟了人类绘画中的笔触与涂抹交互过程。

Abstract: Painting embodies a unique form of visual storytelling, where the creation process is as significant as the final artwork. Although recent advances in generative models have enabled visually compelling painting synthesis, most existing methods focus solely on final image generation or patch-based process simulation, lacking explicit stroke structure and failing to produce smooth, realistic shading. In this work, we present a differentiable stroke reconstruction framework that unifies painting, stylized texturing, and smudging to faithfully reproduce the human painting-smudging loop. Given an input image, our framework first optimizes single- and dual-color Bezier strokes through a parallel differentiable paint renderer, followed by a style generation module that synthesizes geometry-conditioned textures across diverse painting styles. We further introduce a differentiable smudge operator to enable natural color blending and shading. Coupled with a coarse-to-fine optimization strategy, our method jointly optimizes stroke geometry, color, and texture under geometric and semantic guidance. Extensive experiments on oil, watercolor, ink, and digital paintings demonstrate that our approach produces realistic and expressive stroke reconstructions, smooth tonal transitions, and richly stylized appearances, offering a unified model for expressive digital painting creation. See our project page for more demos: https://yingjiang96.github.io/DiffPaintWebsite/.

</details>


### [239] [Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection](https://arxiv.org/abs/2511.13195)
*Soyul Lee,Seungmin Baek,Dongbo Min*

Main category: cs.CV

TL;DR: 提出了一种名为MonoDLGD的难度感知标签引导去噪框架，通过自适应扰动和重建真实标签来提升单目3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测因深度线索模糊而具有挑战性，现有方法在处理实例级别的检测难度（如遮挡、距离、截断）方面不足，导致性能受限。

Method: 提出MonoDLGD框架，根据检测不确定性对易难不同的实例进行不同程度的标签扰动与重建，提供显式的几何监督，并联合优化标签重建与3D检测任务。

Result: 在KITTI基准上实现了最先进的性能，显著提升了不同难度级别下的检测效果。

Conclusion: MonoDLGD通过难度感知的标签引导去噪策略，增强了模型对复杂场景的鲁棒性，推动了单目3D目标检测的发展。

Abstract: Monocular 3D object detection is a cost-effective solution for applications like autonomous driving and robotics, but remains fundamentally ill-posed due to inherently ambiguous depth cues. Recent DETR-based methods attempt to mitigate this through global attention and auxiliary depth prediction, yet they still struggle with inaccurate depth estimates. Moreover, these methods often overlook instance-level detection difficulty, such as occlusion, distance, and truncation, leading to suboptimal detection performance. We propose MonoDLGD, a novel Difficulty-Aware Label-Guided Denoising framework that adaptively perturbs and reconstructs ground-truth labels based on detection uncertainty. Specifically, MonoDLGD applies stronger perturbations to easier instances and weaker ones into harder cases, and then reconstructs them to effectively provide explicit geometric supervision. By jointly optimizing label reconstruction and 3D object detection, MonoDLGD encourages geometry-aware representation learning and improves robustness to varying levels of object complexity. Extensive experiments on the KITTI benchmark demonstrate that MonoDLGD achieves state-of-the-art performance across all difficulty levels.

</details>


### [240] [Self-Supervised Ultrasound Screen Detection](https://arxiv.org/abs/2511.13197)
*Alberto Gomez,Jorge Oliveira,Ramon Casero,Agis Chartsias*

Main category: cs.CV

TL;DR: 提出了一种自监督管道，从超声显示器的拍照图像中提取超声图像，避免DICOM瓶颈，心脏视图分类的平衡准确率为0.79。


<details>
  <summary>Details</summary>
Motivation: 超声设备依赖DICOM进行图像传输，限制了快速测试和新算法的原型开发。

Method: 采用自监督学习方法，对显示器照片进行图像校正和提取。

Result: 校正后的图像在心脏视图分类任务中达到了0.79的平衡准确率，与原生DICOM图像相比保留了足够的视觉保真度。

Conclusion: 该方法有效绕过DICOM限制，支持超声图像的快速获取与算法验证。

Abstract: Ultrasound (US) machines display images on a built-in monitor, but routine transfer to hospital systems relies on DICOM. We propose a self-supervised pipeline to extract the US image from a photograph of the monitor. This removes the DICOM bottleneck and enables rapid testing and prototyping of new algorithms. In a proof-of-concept study, the rectified images retained enough visual fidelity to classify cardiac views with a balanced accuracy of 0.79 with respect to the native DICOMs.

</details>


### [241] [RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2511.13204)
*Junhee Lee,ChaeBeen Bang,MyoungChul Kim,MyeongAh Cho*

Main category: cs.CV

TL;DR: 本文提出了RefineVAD，一种用于弱监督视频异常检测的新框架，通过结合运动感知时序注意力（MoTAR）和类别导向精炼（CORE）模块，同时建模异常的动态时序模式与语义结构，提升了对多样化异常事件的识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将所有异常视为单一类别，忽略了真实世界中异常在语义和时序上的多样性；受人类感知异常方式的启发，需同时考虑‘如何’演变和‘是什么’语义类型。

Method: 提出RefineVAD框架，包含两个模块：MoTAR模块通过基于位移的注意力和全局Transformer建模来估计运动显著性并动态调整时序关注；CORE模块通过交叉注意力将片段级特征与可学习的类别原型对齐，引入软异常类别先验以增强语义感知的表示学习。

Result: 在WVAD基准上的实验表明，RefineVAD优于现有方法，并验证了融合语义上下文对引导特征精炼、发现异常相关模式的重要性。

Conclusion: 通过联合建模时序动态与语义结构，RefineVAD有效提升了弱监督视频异常检测性能，证明了引入语义类别先验和细粒度时序建模的必要性。

Abstract: Weakly-Supervised Video Anomaly Detection aims to identify anomalous events using only video-level labels, balancing annotation efficiency with practical applicability. However, existing methods often oversimplify the anomaly space by treating all abnormal events as a single category, overlooking the diverse semantic and temporal characteristics intrinsic to real-world anomalies. Inspired by how humans perceive anomalies, by jointly interpreting temporal motion patterns and semantic structures underlying different anomaly types, we propose RefineVAD, a novel framework that mimics this dual-process reasoning. Our framework integrates two core modules. The first, Motion-aware Temporal Attention and Recalibration (MoTAR), estimates motion salience and dynamically adjusts temporal focus via shift-based attention and global Transformer-based modeling. The second, Category-Oriented Refinement (CORE), injects soft anomaly category priors into the representation space by aligning segment-level features with learnable category prototypes through cross-attention. By jointly leveraging temporal dynamics and semantic structure, explicitly models both "how" motion evolves and "what" semantic category it resembles. Extensive experiments on WVAD benchmark validate the effectiveness of RefineVAD and highlight the importance of integrating semantic context to guide feature refinement toward anomaly-relevant patterns.

</details>


### [242] [End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer](https://arxiv.org/abs/2511.13208)
*Yonghui Yu,Jiahang Cai,Xun Wang,Wenwu Yang*

Main category: cs.CV

TL;DR: 本文提出了一种全新的端到端多人体视频姿态估计框架PAVE-Net，通过引入姿态感知注意力机制和时空关键点建模，有效解决了跨帧个体关联问题，避免了传统方法中的启发式操作，在准确性和效率上均取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段多人体视频姿态估计方法依赖检测、RoI裁剪和非极大值抑制等启发式操作，限制了精度和效率，且难以处理复杂遮挡和重叠情况。

Method: 提出PAVE-Net，包含空间编码器建模帧内关系和时空姿态解码器捕捉跨帧全局依赖；设计姿态感知注意力机制实现个体跨帧特征聚合，并显式建模关键点间的时空依赖关系。

Result: 在PoseTrack2017数据集上比以往基于图像的端到端方法提升了6.0 mAP，性能与最先进的两阶段视频方法相当，同时显著提高了计算效率。

Conclusion: PAVE-Net是首个用于多帧2D人体姿态估计的真正端到端方法，有效消除了启发式操作，在保持高精度的同时大幅提升效率，为视频姿态估计提供了新范式。

Abstract: Existing multi-person video pose estimation methods typically adopt a two-stage pipeline: detecting individuals in each frame, followed by temporal modeling for single-person pose estimation. This design relies on heuristic operations such as detection, RoI cropping, and non-maximum suppression (NMS), limiting both accuracy and efficiency. In this paper, we present a fully end-to-end framework for multi-person 2D pose estimation in videos, effectively eliminating heuristic operations. A key challenge is to associate individuals across frames under complex and overlapping temporal trajectories. To address this, we introduce a novel Pose-Aware Video transformEr Network (PAVE-Net), which features a spatial encoder to model intra-frame relations and a spatiotemporal pose decoder to capture global dependencies across frames. To achieve accurate temporal association, we propose a pose-aware attention mechanism that enables each pose query to selectively aggregate features corresponding to the same individual across consecutive frames.Additionally, we explicitly model spatiotemporal dependencies among pose keypoints to improve accuracy. Notably, our approach is the first end-to-end method for multi-frame 2D human pose estimation.Extensive experiments show that PAVE-Net substantially outperforms prior image-based end-to-end methods, achieving a \textbf{6.0} mAP improvement on PoseTrack2017, and delivers accuracy competitive with state-of-the-art two-stage video-based approaches, while offering significant gains in efficiency.Project page: https://github.com/zgspose/PAVENet

</details>


### [243] [3DAlign-DAER: Dynamic Attention Policy and Efficient Retrieval Strategy for Fine-grained 3D-Text Alignment at Scale](https://arxiv.org/abs/2511.13211)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Jian Wang,Keze Wang*

Main category: cs.CV

TL;DR: 本文提出了3DAlign-DAER，一个通过动态注意力策略和高效检索方法实现文本与3D几何对齐的统一框架，并构建了包含200万文本-3D配对的大规模数据集Align3D-2M，显著提升了细粒度跨模态对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D-文本跨模态对齐方法在捕捉细粒度语义与几何结构对应关系方面表现不足，且在大规模3D数据库上性能下降明显。

Method: 提出动态注意力策略（DAP），结合分层注意力融合（HAF）模块和蒙特卡洛树搜索优化注意力权重；推理阶段采用高效检索策略（ERS）进行大规模嵌入空间搜索；并构建Align3D-2M数据集用于训练与评估。

Result: 在多个跨模态检索和分类任务中表现出优越性能，显著优于传统方法，在准确率和效率方面均有提升。

Conclusion: 3DAlign-DAER通过动态注意力机制和高效检索策略有效提升了文本与3D几何的细粒度对齐能力，为大规模跨模态理解提供了可行方案。

Abstract: Despite recent advancements in 3D-text cross-modal alignment, existing state-of-the-art methods still struggle to align fine-grained textual semantics with detailed geometric structures, and their alignment performance degrades significantly when scaling to large-scale 3D databases. To overcome this limitation, we introduce 3DAlign-DAER, a unified framework designed to align text and 3D geometry via the proposed dynamic attention policy and the efficient retrieval strategy, capturing subtle correspondences for diverse cross-modal retrieval and classification tasks. Specifically, during the training, our proposed dynamic attention policy (DAP) employs the Hierarchical Attention Fusion (HAF) module to represent the alignment as learnable fine-grained token-to-point attentions. To optimize these attentions across different tasks and geometric hierarchies, our DAP further exploits the Monte Carlo tree search to dynamically calibrate HAF attention weights via a hybrid reward signal and further enhances the alignment between textual descriptions and local 3D geometry. During the inference, our 3DAlign-DAER introduces an Efficient Retrieval Strategy (ERS) to leverage efficient hierarchical searching in the large-scale embedding spaces, outperforming traditional methods (e.g., KNN) in accuracy and efficiency. Furthermore, to facilitate text-3D alignment research and train our 3DAlign-DAER, we construct Align3D-2M, a large-scale dataset featuring 2M text-3D pairs, to provide sufficient fine-grained cross-modal annotations. Extensive and comprehensive experiments demonstrate the superior performance of our 3DAlign-DAER on diverse benchmarks. We will release our codes, models, and datasets.

</details>


### [244] [Hybrid-Domain Adaptative Representation Learning for Gaze Estimation](https://arxiv.org/abs/2511.13222)
*Qida Tan,Hongyu Yang,Wenchao Du*

Main category: cs.CV

TL;DR: 提出了一种基于混合域自适应表示学习（HARL）的外观型视线估计框架，通过解耦特征和融合头姿态信息，在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨域评估中因表情、可穿戴设备和图像质量等无关因素干扰而性能下降，需提升模型鲁棒性。

Method: 提出HARL框架，采用无监督域适应方法利用高质量近眼图像特征来解耦低质量人脸图像中的视线相关表示，并设计稀疏图融合模块以利用视线与头姿态间的几何约束。

Result: 在EyeDiap、MPIIFaceGaze和Gaze360数据集上分别达到5.02°、3.36°和9.26°的误差，跨数据集评估表现优异。

Conclusion: HARL有效提升了外观型视线估计的鲁棒性和准确性，尤其在跨域场景下具有优越性能。

Abstract: Appearance-based gaze estimation, aiming to predict accurate 3D gaze direction from a single facial image, has made promising progress in recent years. However, most methods suffer significant performance degradation in cross-domain evaluation due to interference from gaze-irrelevant factors, such as expressions, wearables, and image quality. To alleviate this problem, we present a novel Hybrid-domain Adaptative Representation Learning (shorted by HARL) framework that exploits multi-source hybrid datasets to learn robust gaze representation. More specifically, we propose to disentangle gaze-relevant representation from low-quality facial images by aligning features extracted from high-quality near-eye images in an unsupervised domain-adaptation manner, which hardly requires any computational or inference costs. Additionally, we analyze the effect of head-pose and design a simple yet efficient sparse graph fusion module to explore the geometric constraint between gaze direction and head-pose, leading to a dense and robust gaze representation. Extensive experiments on EyeDiap, MPIIFaceGaze, and Gaze360 datasets demonstrate that our approach achieves state-of-the-art accuracy of $\textbf{5.02}^{\circ}$ and $\textbf{3.36}^{\circ}$, and $\textbf{9.26}^{\circ}$ respectively, and present competitive performances through cross-dataset evaluation. The code is available at https://github.com/da60266/HARL.

</details>


### [245] [MRIQT: Physics-Aware Diffusion Model for Image Quality Transfer in Neonatal Ultra-Low-Field MRI](https://arxiv.org/abs/2511.13232)
*Malek Al Abed,Sebiha Demir,Anne Groteklaes,Elodie Germani,Shahrooz Faghihroohi,Hemmen Sabir,Shadi Albarqouni*

Main category: cs.CV

TL;DR: 提出MRIQT，一种基于3D条件扩散模型的图像质量提升方法，用于将便携式超低场MRI（uLF-MRI）转换为高场MRI质量，显著提升新生儿脑部成像的诊断价值。


<details>
  <summary>Details</summary>
Motivation: 便携式超低场MRI（0.064 T）虽便于新生儿神经影像获取，但信噪比低、图像质量差，难以满足临床诊断需求，亟需有效的方法提升其图像质量。

Method: 提出MRIQT，采用3D条件扩散框架，结合真实K空间退化模拟uLF-MRI物理特性，使用v预测与无分类器引导实现稳定图像生成，并引入SNR加权的3D感知损失保证解剖结构保真；模型以噪声化的uLF图像为输入并以其自身为条件，利用体积注意力UNet架构实现结构保持的图像转换。

Result: 在包含多种病理的新生儿数据集上训练后，MRIQT在PSNR上比最新方法提升15.3%（相对提升1.78%），优于现有GAN和CNN基线模型；85%的输出图像被医生评为高质量且病灶清晰可见。

Conclusion: MRIQT能够实现从超低场到高场MRI的高保真扩散生成转换，显著提升便携式uLF-MRI的图像质量，有望推动其在新生儿脑部评估中的可靠临床应用。

Abstract: Portable ultra-low-field MRI (uLF-MRI, 0.064 T) offers accessible neuroimaging for neonatal care but suffers from low signal-to-noise ratio and poor diagnostic quality compared to high-field (HF) MRI. We propose MRIQT, a 3D conditional diffusion framework for image quality transfer (IQT) from uLF to HF MRI. MRIQT combines realistic K-space degradation for physics-consistent uLF simulation, v-prediction with classifier-free guidance for stable image-to-image generation, and an SNR-weighted 3D perceptual loss for anatomical fidelity. The model denoises from a noised uLF input conditioned on the same scan, leveraging volumetric attention-UNet architecture for structure-preserving translation. Trained on a neonatal cohort with diverse pathologies, MRIQT surpasses recent GAN and CNN baselines in PSNR 15.3% with 1.78% over the state of the art, while physicians rated 85% of its outputs as good quality with clear pathology present. MRIQT enables high-fidelity, diffusion-based enhancement of portable ultra-low-field (uLF) MRI for deliable neonatal brain assessment.

</details>


### [246] [MMD-Thinker: Adaptive Multi-Dimensional Thinking for Multimodal Misinformation Detection](https://arxiv.org/abs/2511.13242)
*Junjie Wu,Guohong Fu*

Main category: cs.CV

TL;DR: 本文提出MMD-Thinker，一种基于自适应多维思考的两阶段框架，用于多模态虚假信息检测。通过定制思维模式、任务特定指令微调和强化学习策略，结合新构建的MMR数据集，在多个基准上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有通用多模态大模型在虚假信息检测中存在推理能力不足和推理偏差问题，难以应对AI生成内容时代快速演变的多模态虚假信息。

Method: 1）设计针对多模态虚假信息检测的定制化思维模式；2）采用任务特定指令微调将思维模式注入通用MLLM；3）使用带有混合优势函数的强化学习提升推理轨迹能力；4）构建包含8000多个样本的多模态虚假信息推理（MMR）数据集。

Result: MMD-Thinker在领域内和跨领域基准数据集上均达到最先进性能，具备灵活的推理能力和高效的token使用效率。

Conclusion: 通过引入任务特定的多维思考机制，MMD-Thinker有效提升了多模态大模型在虚假信息检测中的推理准确性和鲁棒性，为应对AIGC时代的虚假信息挑战提供了新思路。

Abstract: Multimodal misinformation floods on various social media, and continues to evolve in the era of AI-generated content (AIGC). The emerged misinformation with low creation cost and high deception poses significant threats to society. While recent studies leverage general-purpose multimodal large language models (MLLMs) to achieve remarkable results in detection, they encounter two critical limitations: (1) Insufficient reasoning, where general-purpose MLLMs often follow the uniform reasoning paradigm but generate inaccurate explanations and judgments, due to the lack of the task-specific knowledge of multimodal misinformation detection. (2) Reasoning biases, where a single thinking mode make detectors a suboptimal path for judgment, struggling to keep pace with the fast-growing and intricate multimodal misinformation. In this paper, we propose MMD-Thinker, a two-stage framework for multimodal misinformation detection through adaptive multi-dimensional thinking. First, we develop tailor-designed thinking mode for multimodal misinformation detection. Second, we adopt task-specific instruction tuning to inject the tailored thinking mode into general-purpose MLLMs. Third, we further leverage reinforcement learning strategy with a mixed advantage function, which incentivizes the reasoning capabilities in trajectories. Furthermore, we construct the multimodal misinformation reasoning (MMR) dataset, encompasses more than 8K image-text pairs with both reasoning processes and classification labels, to make progress in the relam of multimodal misinformation detection. Experimental results demonstrate that our proposed MMD-Thinker achieves state-of-the-art performance on both in-domain and out-of-domain benchmark datasets, while maintaining flexible inference and token usage. Code will be publicly available at Github.

</details>


### [247] [Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention](https://arxiv.org/abs/2511.13249)
*Yu Wen,Shuyong Gao,Shuping Zhang,Miao Huang,Lili Tao,Han Yang,Haozhe Xing,Lihe Zhang,Boxue Hou*

Main category: cs.CV

TL;DR: 本文提出了一种用于参考图像引导的伪装物体检测（Ref-COD）的新方法RFMNet，通过多阶段特征融合和局部交叉注意力机制提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将参考图像转换为一维提示，未能充分利用丰富的显著性特征与伪装特征之间的多层次上下文关系，限制了检测精度。

Method: 提出RFMNet，利用参考显著图像在多个编码阶段的特征，并在对应阶段与伪装特征进行交互式融合；引入重叠窗口交叉注意力机制以增强局部信息匹配；设计参考特征聚合（RFA）模块用于逐步解码和分割伪装物体。

Result: 在Ref-COD基准上的大量实验表明，该方法实现了最先进的性能。

Conclusion: 通过多阶段交互融合和局部注意力机制，有效提升了参考引导下伪装物体的检测能力，验证了多上下文融合策略的有效性。

Abstract: Referring camouflaged object detection (Ref-COD) aims to identify hidden objects by incorporating reference information such as images and text descriptions. Previous research has transformed reference images with salient objects into one-dimensional prompts, yielding significant results. We explore ways to enhance performance through multi-context fusion of rich salient image features and camouflaged object features. Therefore, we propose RFMNet, which utilizes features from multiple encoding stages of the reference salient images and performs interactive fusion with the camouflage features at the corresponding encoding stages. Given that the features in salient object images contain abundant object-related detail information, performing feature fusion within local areas is more beneficial for detecting camouflaged objects. Therefore, we propose an Overlapped Windows Cross-attention mechanism to enable the model to focus more attention on the local information matching based on reference features. Besides, we propose the Referring Feature Aggregation (RFA) module to decode and segment the camouflaged objects progressively. Extensive experiments on the Ref-COD benchmark demonstrate that our method achieves state-of-the-art performance.

</details>


### [248] [GeoX-Bench: Benchmarking Cross-View Geo-Localization and Pose Estimation Capabilities of Large Multimodal Models](https://arxiv.org/abs/2511.13259)
*Yushuo Zheng,Jiangyong Ying,Huiyu Duan,Chunyi Li,Zicheng Zhang,Jing Liu,Xiaohong Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了GeoX-Bench，首个用于评估大型多模态模型（LMMs）在跨视角地理定位与姿态估计能力的综合基准，包含10,859对全景-卫星图像和755,976个问答对，并基于此评估了25种主流LMMs的表现，发现当前模型在姿态估计任务上性能显著下降，而指令微调可有效提升其地理感知能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型多模态模型（LMMs）在多种任务中表现出色，但其在跨视角地理定位与姿态估计方面的能力尚未被探索，而这些能力对导航、自动驾驶和户外机器人等领域具有重要意义，因此需要一个专门的基准来系统评估和推动LMMs在该领域的发展。

Method: 构建了一个名为GeoX-Bench的大规模基准数据集，包含来自49个国家128个城市的10,859对全景-卫星图像及755,976个问答对，其中42,900个用于评测；基于该数据集对25种最先进的LMMs进行系统评估，并研究指令微调对其跨视角地理感知能力的提升效果。

Result: 实验表明，当前LMMs在地理定位任务上表现良好，但在更复杂的姿态估计任务上性能显著下降；通过在GeoX-Bench训练数据上进行指令微调，可显著增强LMMs的跨视角地理感知能力。

Conclusion: GeoX-Bench为评估和提升LMMs在跨视角地理定位与姿态估计方面的能力提供了重要工具，揭示了现有模型在姿态估计上的不足，并验证了指令微调的有效性，指出了未来改进的方向。

Abstract: Large multimodal models (LMMs) have demonstrated remarkable capabilities across a wide range of tasks, however their knowledge and abilities in the cross-view geo-localization and pose estimation domains remain unexplored, despite potential benefits for navigation, autonomous driving, outdoor robotics, \textit{etc}. To bridge this gap, we introduce \textbf{GeoX-Bench}, a comprehensive \underline{Bench}mark designed to explore and evaluate the capabilities of LMMs in \underline{cross}-view \underline{Geo}-localization and pose estimation. Specifically, GeoX-Bench contains 10,859 panoramic-satellite image pairs spanning 128 cities in 49 countries, along with corresponding 755,976 question-answering (QA) pairs. Among these, 42,900 QA pairs are designated for benchmarking, while the remaining are intended to enhance the capabilities of LMMs. Based on GeoX-Bench, we evaluate the capabilities of 25 state-of-the-art LMMs on cross-view geo-localization and pose estimation tasks, and further explore the empowered capabilities of instruction-tuning. Our benchmark demonstrate that while current LMMs achieve impressive performance in geo-localization tasks, their effectiveness declines significantly on the more complex pose estimation tasks, highlighting a critical area for future improvement, and instruction-tuning LMMs on the training data of GeoX-Bench can significantly improve the cross-view geo-sense abilities. The GeoX-Bench is available at \textcolor{magenta}{https://github.com/IntMeGroup/GeoX-Bench}.

</details>


### [249] [Building Egocentric Procedural AI Assistant: Methods, Benchmarks, and Challenges](https://arxiv.org/abs/2511.13261)
*Junlong Li,Huaiyuan Xu,Sijie Cheng,Kejun Wu,Kim-Hui Yap,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 本文提出了一个面向日常步骤性任务的自我中心程序化AI助手（EgoProceAssist）概念，定义了三个核心任务：自我中心程序错误检测、学习与问答，并建立了新分类体系，系统综述了相关技术、数据集与评估指标，通过实验分析现有视觉语言模型的局限，指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 受视觉语言模型和自我中心感知研究进展的推动，旨在构建能在第一人称视角下逐步辅助日常任务的AI助手，填补现有VLM助手在程序性任务支持上的不足。

Method: 提出EgoProceAssist概念及包含三个核心任务的新分类体系，系统回顾现有技术、数据集与评估方法，并通过新实验对代表性VLM方法进行综合评估。

Result: 明确了EgoProceAssist与现有VLM助手的差异，识别出现有方法在自我中心程序任务中的局限性，并提供了全面的技术分析与性能比较。

Conclusion: EgoProceAssist为第一人称视角下的程序性任务支持提供了新的研究框架，未来需在细粒度理解、长期推理与实时交互等方面进一步突破。

Abstract: Driven by recent advances in vision language models (VLMs) and egocentric perception research, we introduce the concept of an egocentric procedural AI assistant (EgoProceAssist) tailored to step-by-step support daily procedural tasks in a first-person view. In this work, we start by identifying three core tasks: egocentric procedural error detection, egocentric procedural learning, and egocentric procedural question answering. These tasks define the essential functions of EgoProceAssist within a new taxonomy. Specifically, our work encompasses a comprehensive review of current techniques, relevant datasets, and evaluation metrics across these three core areas. To clarify the gap between the proposed EgoProceAssist and existing VLM-based AI assistants, we introduce novel experiments and provide a comprehensive evaluation of representative VLM-based methods. Based on these findings and our technical analysis, we discuss the challenges ahead and suggest future research directions. Furthermore, an exhaustive list of this study is publicly available in an active repository that continuously collects the latest work: https://github.com/z1oong/Building-Egocentric-Procedural-AI-Assistant

</details>


### [250] [Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation](https://arxiv.org/abs/2511.13269)
*Lingfeng Zhang,Yuchen Zhang,Hongsheng Li,Haoxiang Fu,Yingbo Tang,Hangjun Ye,Long Chen,Xiaojun Liang,Xiaoshuai Hao,Wenbo Ding*

Main category: cs.CV

TL;DR: 本文提出了SpatialSky-Bench，一个用于评估视觉语言模型（VLMs）在无人机（UAV）导航中空间智能能力的综合基准，并构建了包含100万样本的SpatialSky-Dataset。基于该数据集，作者开发了专用于UAV多粒度空间推理的Sky-VLM模型，在各项任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在UAV场景中的空间智能能力尚未被充分探索，导致其在动态环境导航与理解方面表现受限，缺乏有效评估和训练机制。

Method: 提出SpatialSky-Bench基准，包含环境感知和场景理解两大类共13个子任务；构建大规模SpatialSky-Dataset数据集；设计并训练专用的Sky-VLM模型以支持多粒度和多上下文的空间推理。

Result: 主流VLMs在该基准上表现不佳，表明其空间能力存在显著缺陷；Sky-VLM在所有基准任务中均取得SOTA性能，验证了所提方法的有效性。

Conclusion: Sky-VLM结合专用数据集和基准，显著提升了VLM在UAV场景中的空间智能水平，为未来UAV导航中的视觉语言理解提供了重要基础。

Abstract: Vision-Language Models (VLMs), leveraging their powerful visual perception and reasoning capabilities, have been widely applied in Unmanned Aerial Vehicle (UAV) tasks. However, the spatial intelligence capabilities of existing VLMs in UAV scenarios remain largely unexplored, raising concerns about their effectiveness in navigating and interpreting dynamic environments. To bridge this gap, we introduce SpatialSky-Bench, a comprehensive benchmark specifically designed to evaluate the spatial intelligence capabilities of VLMs in UAV navigation. Our benchmark comprises two categories-Environmental Perception and Scene Understanding-divided into 13 subcategories, including bounding boxes, color, distance, height, and landing safety analysis, among others. Extensive evaluations of various mainstream open-source and closed-source VLMs reveal unsatisfactory performance in complex UAV navigation scenarios, highlighting significant gaps in their spatial capabilities. To address this challenge, we developed the SpatialSky-Dataset, a comprehensive dataset containing 1M samples with diverse annotations across various scenarios. Leveraging this dataset, we introduce Sky-VLM, a specialized VLM designed for UAV spatial reasoning across multiple granularities and contexts. Extensive experimental results demonstrate that Sky-VLM achieves state-of-the-art performance across all benchmark tasks, paving the way for the development of VLMs suitable for UAV scenarios. The source code is available at https://github.com/linglingxiansen/SpatialSKy.

</details>


### [251] [Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models](https://arxiv.org/abs/2511.13276)
*Noam Tsfaty,Avishai Weizman,Liav Cohen,Moshe Tshuva,Yehudit Aperstein*

Main category: cs.CV

TL;DR: 提出了一种双主干框架，结合卷积和Transformer表示，通过top-k池化在仅有视频级监督的情况下实现对罕见且多样异常的有效检测。


<details>
  <summary>Details</summary>
Motivation: 在仅有视频级监督的条件下，检测监控视频中罕见且多样的异常具有挑战性。

Method: 采用双主干框架，融合卷积神经网络和Transformer的特征表示，并利用top-k池化机制进行关键帧筛选与特征聚合。

Result: 在UCF-Crime数据集上达到90.7%的曲线下面积（AUC），表现出优越的异常检测性能。

Conclusion: 所提出的双主干方法有效提升了视频级监督下异常检测的性能，尤其适用于处理罕见和多样化异常场景。

Abstract: We address the challenge of detecting rare and diverse anomalies in surveillance videos using only video-level supervision. Our dual-backbone framework combines convolutional and transformer representations through top-k pooling, achieving 90.7% area under the curve (AUC) on the UCF-Crime dataset.

</details>


### [252] [SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting](https://arxiv.org/abs/2511.13278)
*Zihan Li,Tengfei Wang,Wentian Gan,Hao Zhan,Xin Wang,Zongqian Zhan*

Main category: cs.CV

TL;DR: 本文提出SF-Recon方法，直接从多视角图像重建轻量化的建筑表面模型，无需后处理简化，具有高效、保结构且少面片的优势。


<details>
  <summary>Details</summary>
Motivation: 传统多视图几何流程依赖密集重建、网格化和简化，过程繁琐且对质量敏感，难以高效生成轻量化的建筑表面模型。

Method: 首先训练初始的3D高斯点阵（3DGS）获得视角一致的表示；通过法向梯度引导的高斯优化提取屋顶和墙面边界的结构特征；结合多视角边缘一致性剪枝增强结构清晰度并抑制非结构伪影；最后采用多视角深度约束的Delaunay三角剖分生成轻量且结构保真的网格模型。

Result: 在自建SF数据集上的实验表明，SF-Recon能直接生成轻量化建筑模型，面片和顶点数显著减少，同时保持良好的结构精度和计算效率。

Conclusion: SF-Recon实现了无需后简化即可从多视角图像直接重建轻量、结构清晰的建筑表面模型，为数字城市和地理空间分析提供了高效解决方案。

Abstract: Lightweight building surface models are crucial for digital city, navigation, and fast geospatial analytics, yet conventional multi-view geometry pipelines remain cumbersome and quality-sensitive due to their reliance on dense reconstruction, meshing, and subsequent simplification. This work presents SF-Recon, a method that directly reconstructs lightweight building surfaces from multi-view images without post-hoc mesh simplification. We first train an initial 3D Gaussian Splatting (3DGS) field to obtain a view-consistent representation. Building structure is then distilled by a normal-gradient-guided Gaussian optimization that selects primitives aligned with roof and wall boundaries, followed by multi-view edge-consistency pruning to enhance structural sharpness and suppress non-structural artifacts without external supervision. Finally, a multi-view depth-constrained Delaunay triangulation converts the structured Gaussian field into a lightweight, structurally faithful building mesh. Based on a proposed SF dataset, the experimental results demonstrate that our SF-Recon can directly reconstruct lightweight building models from multi-view imagery, achieving substantially fewer faces and vertices while maintaining computational efficiency. Website:https://lzh282140127-cell.github.io/SF-Recon-project/

</details>


### [253] [Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space](https://arxiv.org/abs/2511.13282)
*Kaiwen Wang,Kaili Zheng,Yiming Shi,Chenyi Guo,Ji Wu*

Main category: cs.CV

TL;DR: 提出Depth-conditioned Translation Optimization (DTO) 方法，实现多人场景下一致的人体网格恢复，并构建大规模数据集DTO-Humans；同时提出Metric-Aware HMR网络，实现度量尺度下的端到端人体网格估计。


<details>
  <summary>Details</summary>
Motivation: 现有单人中心的伪真值生成方法在多人场景中缺乏场景一致性，导致深度和尺度冲突，限制了多人人体网格恢复性能。

Method: 提出DTO方法，在MAP框架下联合优化多人相机空间平移，结合人体高度先验和单目深度线索；构建DTO-Humans数据集；设计Metric-Aware HMR网络，通过相机分支和相对度量损失实现度量尺度下的端到端估计。

Result: 在4D-Humans上构建了含0.56M图像、平均每图4.8人的DTO-Humans数据集；所提方法在相对深度推理和人体网格恢复上达到SOTA性能。

Conclusion: DTO有效提升了多人场景下的几何一致性，DTO-Humans为训练提供高质量数据，Metric-Aware HMR实现了精确的度量尺度人体重建。

Abstract: Multi-person human mesh recovery from a single image is a challenging task, hindered by the scarcity of in-the-wild training data. Prevailing in-the-wild human mesh pseudo-ground-truth (pGT) generation pipelines are single-person-centric, where each human is processed individually without joint optimization. This oversight leads to a lack of scene-level consistency, producing individuals with conflicting depths and scales within the same image. To address this, we introduce Depth-conditioned Translation Optimization (DTO), a novel optimization-based method that jointly refines the camera-space translations of all individuals in a crowd. By leveraging anthropometric priors on human height and depth cues from a monocular depth estimator, DTO solves for a scene-consistent placement of all subjects within a principled Maximum a posteriori (MAP) framework. Applying DTO to the 4D-Humans dataset, we construct DTO-Humans, a new large-scale pGT dataset of 0.56M high-quality, scene-consistent multi-person images, featuring dense crowds with an average of 4.8 persons per image. Furthermore, we propose Metric-Aware HMR, an end-to-end network that directly estimates human mesh and camera parameters in metric scale. This is enabled by a camera branch and a novel relative metric loss that enforces plausible relative scales. Extensive experiments demonstrate that our method achieves state-of-the-art performance on relative depth reasoning and human mesh recovery. Code and data will be released publicly.

</details>


### [254] [TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing](https://arxiv.org/abs/2511.13283)
*Jongha Kim,Minseong Bae,Sanghyeok Lee,Jinsung Yoon,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 本文提出了TabFlash，一种高效的多模态大语言模型，用于表格理解。通过渐进式问题条件化、剪枝策略和令牌聚焦，实现了更优性能与更低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在处理表格图像时忽视了问题特定关注和冗余背景区域的问题，导致视觉表征低效且信息不足。

Method: 提出渐进式问题条件化将问题逐步注入Vision Transformer层；采用剪枝策略去除背景token；设计token focusing训练策略以减少信息损失。

Result: TabFlash在多个基准上达到最先进水平，优于开源及专有MLLM，同时减少27%的FLOPs和30%的内存使用。

Conclusion: 所提方法能有效生成紧凑且信息丰富的视觉特征，显著提升表格理解的效率与性能。

Abstract: Table images present unique challenges for effective and efficient understanding due to the need for question-specific focus and the presence of redundant background regions. Existing Multimodal Large Language Model (MLLM) approaches often overlook these characteristics, resulting in uninformative and redundant visual representations. To address these issues, we aim to generate visual features that are both informative and compact to improve table understanding. We first propose progressive question conditioning, which injects the question into Vision Transformer layers with gradually increasing frequency, considering each layer's capacity to handle additional information, to generate question-aware visual features. To reduce redundancy, we introduce a pruning strategy that discards background tokens, thereby improving efficiency. To mitigate information loss from pruning, we further propose token focusing, a training strategy that encourages the model to concentrate essential information in the retained tokens. By combining these approaches, we present TabFlash, an efficient and effective MLLM for table understanding. TabFlash achieves state-of-the-art performance, outperforming both open-source and proprietary MLLMs, while requiring 27% less FLOPs and 30% less memory usage compared to the second-best MLLM.

</details>


### [255] [SkyReels-Text: Fine-grained Font-Controllable Text Editing for Poster Design](https://arxiv.org/abs/2511.13285)
*Yunjie Yu,Jingchen Wu,Junchen Zhu,Chunze Lin,Guibin Chen*

Main category: cs.CV

TL;DR: 提出SkyReels-Text，一种可控制字体的海报文本编辑框架，支持多区域、多字体样式的同时编辑，无需字体标签或微调，通过输入目标字形样本实现高保真文本修改，显著提升专业设计中的文本图像编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑模型在精细、字体感知的文本操作方面表现不足，难以满足海报等专业设计中对视觉和谐与排版意图保持的需求。

Method: 提出SkyReels-Text，一种新颖的字体可控文本编辑框架，能够同时编辑多个具有不同排版样式的文本区域，并保持非编辑区域的视觉一致性；推理时无需字体标签或微调，用户只需提供所需字体的裁剪字形样本即可。

Result: 在多个数据集（包括手写文本基准）上实验表明，SkyReels-Text在文本保真度和视觉真实性方面均达到最先进水平，能精确控制字体族和风格细节。

Conclusion: SkyReels-Text弥合了通用图像编辑与专业级排版设计之间的差距，为实际设计工作流提供了高效、精准的文本编辑解决方案。

Abstract: Artistic design such as poster design often demands rapid yet precise modification of textual content while preserving visual harmony and typographic intent, especially across diverse font styles. Although modern image editing models have grown increasingly powerful, they still fall short in fine-grained, font-aware text manipulation, limiting their utility in professional design workflows such as poster editing. To address this issue, we present SkyReels-Text, a novel font-controllable framework for precise poster text editing. Our method enables simultaneous editing of multiple text regions, each rendered in distinct typographic styles, while preserving the visual appearance of non-edited regions. Notably, our model requires neither font labels nor fine-tuning during inference: users can simply provide cropped glyph patches corresponding to their desired typography, even if the font is not included in any standard library. Extensive experiments on multiple datasets, including handwrittent text benchmarks, SkyReels-Text achieves state-of-the-art performance in both text fidelity and visual realism, offering unprecedented control over font families, and stylistic nuances. This work bridges the gap between general-purpose image editing and professional-grade typographic design.

</details>


### [256] [CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving](https://arxiv.org/abs/2511.13297)
*Enhui Ma,Lijun Zhou,Tao Tang,Jiahuan Zhang,Junpeng Jiang,Zhan Zhang,Dong Han,Kun Zhan,Xueyang Zhang,XianPeng Lang,Haiyang Sun,Xia Zhou,Di Lin,Kaicheng Yu*

Main category: cs.CV

TL;DR: 提出CorrectAD，一个基于生成模型的自动驾驶自纠错系统，通过PM-Agent识别失败案例并生成高保真仿真数据，显著提升端到端规划器的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决端到端自动驾驶系统因长尾问题导致的鲁棒性不足，尤其是罕见但关键的安全故障案例难以覆盖的问题。

Method: 设计PM-Agent模拟产品经理收集失败案例需求，结合结构化3D布局，提出DriveSora生成时空一致、符合3D标注的高质量视频，构建自纠错代理系统CorrectAD。

Result: 在nuScenes和自建数据集上，CorrectAD分别修正62.5%和49.8%的失败案例，碰撞率降低39%和27%，且兼容多种端到端规划器。

Conclusion: CorrectAD提供了一种模型无关的自动化自纠错框架，有效缓解长尾问题，显著提升自动驾驶系统的安全性与鲁棒性。

Abstract: End-to-end planning methods are the de facto standard of the current autonomous driving system, while the robustness of the data-driven approaches suffers due to the notorious long-tail problem (i.e., rare but safety-critical failure cases). In this work, we explore whether recent diffusion-based video generation methods (a.k.a. world models), paired with structured 3D layouts, can enable a fully automated pipeline to self-correct such failure cases. We first introduce an agent to simulate the role of product manager, dubbed PM-Agent, which formulates data requirements to collect data similar to the failure cases. Then, we use a generative model that can simulate both data collection and annotation. However, existing generative models struggle to generate high-fidelity data conditioned on 3D layouts. To address this, we propose DriveSora, which can generate spatiotemporally consistent videos aligned with the 3D annotations requested by PM-Agent. We integrate these components into our self-correcting agentic system, CorrectAD. Importantly, our pipeline is an end-to-end model-agnostic and can be applied to improve any end-to-end planner. Evaluated on both nuScenes and a more challenging in-house dataset across multiple end-to-end planners, CorrectAD corrects 62.5% and 49.8% of failure cases, reducing collision rates by 39% and 27%, respectively.

</details>


### [257] [DriveLiDAR4D: Sequential and Controllable LiDAR Scene Generation for Autonomous Driving](https://arxiv.org/abs/2511.13309)
*Kaiwen Cai,Xinze Liu,Xia Zhou,Hengtong Hu,Jie Xiang,Luyao Zhang,Xueyang Zhang,Kun Zhan,Yifei Zhan,Xianpeng Lang*

Main category: cs.CV

TL;DR: 本文提出了一种新的LiDAR点云生成方法DriveLiDAR4D，包含多模态条件和新型序列噪声预测模型LiDAR4DNet，能够端到端地生成时间一致、前景可控且背景真实的LiDAR场景，是首个支持完整场景操作的序列化LiDAR生成方法，在nuScenes和KITTI数据集上显著超越现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR点云生成方法缺乏序列生成能力，且难以准确生成前景物体位置和真实背景，限制了其在自动驾驶系统中的实际应用。

Method: 提出DriveLiDAR4D，结合多模态条件输入与新设计的序列噪声预测模型LiDAR4DNet，实现端到端的时序一致LiDAR场景生成，并支持全场景操控。

Result: 在nuScenes数据集上达到743.13的FRD分数和16.96的FVD分数，相比SOTA方法UniScene分别提升37.2%和24.1%。

Conclusion: DriveLiDAR4D是首个支持端到端全场景操控的序列化LiDAR生成方法，在生成质量与时序一致性方面显著优于现有方法，具有较强的实用潜力。

Abstract: The generation of realistic LiDAR point clouds plays a crucial role in the development and evaluation of autonomous driving systems. Although recent methods for 3D LiDAR point cloud generation have shown significant improvements, they still face notable limitations, including the lack of sequential generation capabilities and the inability to produce accurately positioned foreground objects and realistic backgrounds. These shortcomings hinder their practical applicability. In this paper, we introduce DriveLiDAR4D, a novel LiDAR generation pipeline consisting of multimodal conditions and a novel sequential noise prediction model LiDAR4DNet, capable of producing temporally consistent LiDAR scenes with highly controllable foreground objects and realistic backgrounds. To the best of our knowledge, this is the first work to address the sequential generation of LiDAR scenes with full scene manipulation capability in an end-to-end manner. We evaluated DriveLiDAR4D on the nuScenes and KITTI datasets, where we achieved an FRD score of 743.13 and an FVD score of 16.96 on the nuScenes dataset, surpassing the current state-of-the-art (SOTA) method, UniScene, with an performance boost of 37.2% in FRD and 24.1% in FVD, respectively.

</details>


### [258] [Computer Vision based group activity detection and action spotting](https://arxiv.org/abs/2511.13315)
*Narthana Sivalingam,Santhirarajah Sivasthigan,Thamayanthi Mahendranathan,G. M. R. I. Godaliyadda,M. P. B. Ekanayake,H. M. V. R. Herath*

Main category: cs.CV

TL;DR: 提出了一种结合深度学习和图关系推理的框架，用于多人体场景中的群体活动识别与动作定位。


<details>
  <summary>Details</summary>
Motivation: 由于人类交互复杂、遮挡以及外观随时间变化，多人体场景中的群体活动检测具有挑战性。

Method: 使用Mask R-CNN进行人物定位，融合掩码信息与特征图以获得精细化特征表示，并构建演员关系图（基于外观相似性和位置关系），利用图卷积网络进行关系推理。

Result: 在Collective Activity数据集上的实验表明，该方法在拥挤和非拥挤场景下均提升了识别性能。

Conclusion: 结合分割、特征提取和图关系推理有助于提升复杂视频理解任务的性能。

Abstract: Group activity detection in multi-person scenes is challenging due to complex human interactions, occlusions, and variations in appearance over time. This work presents a computer vision based framework for group activity recognition and action spotting using a combination of deep learning models and graph based relational reasoning. The system first applies Mask R-CNN to obtain accurate actor localization through bounding boxes and instance masks. Multiple backbone networks, including Inception V3, MobileNet, and VGG16, are used to extract feature maps, and RoIAlign is applied to preserve spatial alignment when generating actor specific features. The mask information is then fused with the feature maps to obtain refined masked feature representations for each actor. To model interactions between individuals, we construct Actor Relation Graphs that encode appearance similarity and positional relations using methods such as normalized cross correlation, sum of absolute differences, and dot product. Graph Convolutional Networks operate on these graphs to reason about relationships and predict both individual actions and group level activities. Experiments on the Collective Activity dataset demonstrate that the combination of mask based feature refinement, robust similarity search, and graph neural network reasoning leads to improved recognition performance across both crowded and non crowded scenarios. This approach highlights the potential of integrating segmentation, feature extraction, and relational graph reasoning for complex video understanding tasks.

</details>


### [259] [YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection](https://arxiv.org/abs/2511.13344)
*Ori Meiraz,Sharon Shalev,Avishai Weizman*

Main category: cs.CV

TL;DR: 提出了一种用于目标检测的新型Mixture-of-Experts框架，通过在多个YOLOv9-T专家之间进行自适应路由，实现动态特征专业化，相比单一YOLOv9-T模型提升了mAP和AR性能。


<details>
  <summary>Details</summary>
Motivation: 为了提升目标检测的精度和召回率，解决单一模型在处理多样化特征时的局限性。

Method: 采用Mixture-of-Experts框架，结合多个YOLOv9-T专家模型，并引入自适应路由机制，实现输入样本的动态特征分配与专业化处理。

Result: 该方法在mAP和AR指标上均优于单一YOLOv9-T模型，验证了其有效性。

Conclusion: 所提出的框架能够有效提升目标检测性能，展示了多专家协同与自适应路由的潜力。

Abstract: This paper presents a novel Mixture-of-Experts framework for object detection, incorporating adaptive routing among multiple YOLOv9-T experts to enable dynamic feature specialization and achieve higher mean Average Precision (mAP) and Average Recall (AR) compared to a single YOLOv9-T model.

</details>


### [260] [Semi-Supervised Multi-Task Learning for Interpretable Quality As- sessment of Fundus Images](https://arxiv.org/abs/2511.13353)
*Lucas Gabriel Telesco,Danila Nejamkin,Estefanía Mata,Francisco Filizzola,Kevin Wignall,Lucía Franco Troilo,María de los Angeles Cenoz,Melissa Thompson,Mercedes Leguía,Ignacio Larrabide,José Ignacio Orlando*

Main category: cs.CV

TL;DR: 提出一种混合半监督学习方法，结合手动标注的整体质量与自动生成的细节伪标签，用于可解释的视网膜图像质量评估，无需额外人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有视网膜图像质量评估工具大多仅分类整体质量，缺乏对采集缺陷的细粒度反馈，且详细标注成本高昂，限制了模型的可解释性和临床实用性。

Method: 采用多任务学习框架，使用ResNet-18作为骨干网络；通过在小数据集上训练的教师模型生成质量细节的伪标签，并用于微调预训练模型，实现整体质量与细节预测的联合学习。

Result: 在EyeQ和DeepDRiD数据集上，整体质量评估F1分数优于单任务基线（0.875 vs 0.863 和 0.778 vs 0.763），细节预测性能与教师模型无统计学差异（p > 0.05）；在新标注的EyeQ子集上表现接近专家水平。

Conclusion: 所提半监督方法在不增加人工标注成本的前提下，提升了图像质量评估性能，并提供关于照明、清晰度、对比度等可解释的反馈，具有临床可操作性，可用于指导图像重拍。

Abstract: Retinal image quality assessment (RIQA) supports computer-aided diagnosis of eye diseases. However, most tools classify only overall image quality, without indicating acquisition defects to guide recapture. This gap is mainly due to the high cost of detailed annotations. In this paper, we aim to mitigate this limitation by introducing a hybrid semi-supervised learning approach that combines manual labels for overall quality with pseudo-labels of quality details within a multi-task framework. Our objective is to obtain more interpretable RIQA models without requiring extensive manual labeling. Pseudo-labels are generated by a Teacher model trained on a small dataset and then used to fine-tune a pre-trained model in a multi-task setting. Using a ResNet-18 backbone, we show that these weak annotations improve quality assessment over single-task baselines (F1: 0.875 vs. 0.863 on EyeQ, and 0.778 vs. 0.763 on DeepDRiD), matching or surpassing existing methods. The multi-task model achieved performance statistically comparable to the Teacher for most detail prediction tasks (p > 0.05). In a newly annotated EyeQ subset released with this paper, our model performed similarly to experts, suggesting that pseudo-label noise aligns with expert variability. Our main finding is that the proposed semi-supervised approach not only improves overall quality assessment but also provides interpretable feedback on capture conditions (illumination, clarity, contrast). This enhances interpretability at no extra manual labeling cost and offers clinically actionable outputs to guide image recapture.

</details>


### [261] [Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model](https://arxiv.org/abs/2511.13387)
*Fei Kong*

Main category: cs.CV

TL;DR: 提出了一种广义去噪扩散压缩模型（gDDCM），将DDCM扩展到主流扩散模型及其变体，包括DDPM、基于分数的模型、一致性模型和修正流，并在CIFAR-10和LSUN Bedroom数据集上验证了其有效性和性能提升。


<details>
  <summary>Details</summary>
Motivation: DDCM仅适用于DDPM，无法推广到其他扩散模型，限制了其应用。因此，需要一种更通用的框架来支持多种扩散模型并实现图像压缩。

Method: 通过将DDCM框架推广到多种主流扩散模型（如DDPM、Score-Based Models、Consistency Models和Rectified Flow），设计统一的噪声替换机制，在反向过程中使用特定集合中的噪声进行采样以实现图像压缩。

Result: 在CIFAR-10和LSUN Bedroom数据集上的实验表明，gDDCM成功地将DDCM扩展到多种扩散模型，并在压缩性能上实现了提升。

Conclusion: gDDCM是一个通用且有效的扩散模型压缩框架，能够兼容多种扩散模型并在图像压缩任务中取得更好的性能。

Abstract: Recently, the Denoising Diffusion Codebook Models (DDCM) was proposed. DDCM leverages the Denoising Diffusion Probabilistic Model (DDPM) and replaces the random noise in the backward process with noise sampled from specific sets according to a predefined rule, thereby enabling image compression. However, DDCM cannot be applied to methods other than DDPM. In this paper, we propose the generalized Denoising Diffusion Compression Model (gDDCM), which extends DDCM to mainstream diffusion models and their variants, including DDPM, Score-Based Models, Consistency Models, and Rectified Flow. We evaluate our method on CIFAR-10 and LSUN Bedroom datasets. Experimental results demonstrate that our approach successfully generalizes DDCM to the aforementioned models and achieves improved performance.

</details>


### [262] [Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)](https://arxiv.org/abs/2511.13397)
*Nikos Theodoridis,Tim Brophy,Reenu Mohandas,Ganesh Sistu,Fiachra Collins,Anthony Scanlan,Ciaran Eising*

Main category: cs.CV

TL;DR: DTPQA是一个专为评估自动驾驶场景中视觉-语言模型感知能力而设计的视觉问答基准，包含合成和真实世界两部分，并引入距离标注以分析模型在不同距离下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 为了在安全关键的自动驾驶领域可靠应用视觉-语言模型，需要单独评估其在复杂交通场景中的感知能力，尤其是在远距离（30+米）下的表现。

Method: 提出DTPQA基准，包括基于模拟器生成的DTP-Synthetic和基于真实交通图像构建的DTP-Real，每个样本包含图像、问题、答案及对象距离信息，用于分析模型随距离变化的感知性能。

Result: DTPQA提供了带距离标注的视觉问答数据集和生成脚本，支持对VLM在不同距离下的感知能力进行细粒度评估，并可用于生成更多同类数据。

Conclusion: DTPQA能够有效评估视觉-语言模型在交通场景中的感知能力，特别是随距离变化的性能退化情况，有助于推动安全可靠的自动驾驶系统发展。

Abstract: The remarkable progress of Vision-Language Models (VLMs) on a variety of tasks has raised interest in their application to automated driving. However, for these models to be trusted in such a safety-critical domain, they must first possess robust perception capabilities, i.e., they must be capable of understanding a traffic scene, which can often be highly complex, with many things happening simultaneously. Moreover, since critical objects and agents in traffic scenes are often at long distances, we require systems with not only strong perception capabilities at close distances (up to 20 meters), but also at long (30+ meters) range. Therefore, it is important to evaluate the perception capabilities of these models in isolation from other skills like reasoning or advanced world knowledge. Distance-Annotated Traffic Perception Question Answering (DTPQA) is a Visual Question Answering (VQA) benchmark designed specifically for this purpose: it can be used to evaluate the perception systems of VLMs in traffic scenarios using trivial yet crucial questions relevant to driving decisions. It consists of two parts: a synthetic benchmark (DTP-Synthetic) created using a simulator, and a real-world benchmark (DTP-Real) built on top of existing images of real traffic scenes. Additionally, DTPQA includes distance annotations, i.e., how far the object in question is from the camera. More specifically, each DTPQA sample consists of (at least): (a) an image, (b) a question, (c) the ground truth answer, and (d) the distance of the object in question, enabling analysis of how VLM performance degrades with increasing object distance. In this article, we provide the dataset itself along with the Python scripts used to create it, which can be used to generate additional data of the same kind.

</details>


### [263] [TripleFDS: Triple Feature Disentanglement and Synthesis for Scene Text Editing](https://arxiv.org/abs/2511.13399)
*Yuchen Bao,Yiting Wang,Wenjian Huang,Haowei Wang,Shen Chen,Taiping Yao,Shouhong Ding,Jianguo Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为TripleFDS的新框架和SCB Synthesis数据集，用于场景文本编辑（STE），通过解耦文本样式、内容和背景三重特征，实现了更高的编辑可控性和视觉一致性，在主流基准上达到了最先进的图像保真度和文本准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在场景文本编辑中难以完全解耦可编辑属性，通常只能处理单一属性（如文本内容），导致控制性和视觉一致性受限。为此，本文旨在实现文本样式、内容和背景的全面解耦，提升编辑效果。

Method: 提出TripleFDS框架和SCB Synthesis数据集，利用“SCB Group”作为训练单元，通过组间对比正则化和组内多特征正交性实现三重特征解耦；合成阶段采用特征重映射防止重建中的“捷径”现象和特征泄漏。

Result: 在125,000个SCB Group上训练后，TripleFDS在主流STE基准上取得了44.54的SSIM和93.58%的ACC，达到最先进水平，并支持风格替换和背景迁移等新编辑功能。

Conclusion: TripleFDS通过三重特征解耦显著提升了场景文本编辑的可控性与视觉一致性，具备优异性能和灵活的编辑能力，为未来STE研究提供了有效框架和数据支持。

Abstract: Scene Text Editing (STE) aims to naturally modify text in images while preserving visual consistency, the decisive factors of which can be divided into three parts, i.e., text style, text content, and background. Previous methods have struggled with incomplete disentanglement of editable attributes, typically addressing only one aspect - such as editing text content - thus limiting controllability and visual consistency. To overcome these limitations, we propose TripleFDS, a novel framework for STE with disentangled modular attributes, and an accompanying dataset called SCB Synthesis. SCB Synthesis provides robust training data for triple feature disentanglement by utilizing the "SCB Group", a novel construct that combines three attributes per image to generate diverse, disentangled training groups. Leveraging this construct as a basic training unit, TripleFDS first disentangles triple features, ensuring semantic accuracy through inter-group contrastive regularization and reducing redundancy through intra-sample multi-feature orthogonality. In the synthesis phase, TripleFDS performs feature remapping to prevent "shortcut" phenomena during reconstruction and mitigate potential feature leakage. Trained on 125,000 SCB Groups, TripleFDS achieves state-of-the-art image fidelity (SSIM of 44.54) and text accuracy (ACC of 93.58%) on the mainstream STE benchmarks. Besides superior performance, the more flexible editing of TripleFDS supports new operations such as style replacement and background transfer. Code: https://github.com/yusenbao01/TripleFDS

</details>


### [264] [What Color Is It? A Text-Interference Multimodal Hallucination Benchmark](https://arxiv.org/abs/2511.13400)
*Jinkun Zhao,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: 本文提出了一个名为"What Color Is It"的新基准数据集，用于验证多模态大模型（MLMs）在颜色感知方面容易受到干扰并产生幻觉的问题，并探讨了其成因及增强鲁棒性的潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着大模型的快速发展，多模态大模型在视觉感知（尤其是颜色感知）上仍易受干扰，可能导致幻觉现象，因此需要系统评估和改进其鲁棒性。

Method: 构建了一个简单有效的方法来触发单模态视觉幻觉，并基于此创建了"What Color Is It"数据集，用以测试和分析MLMs的颜色感知能力及幻觉成因。

Result: 实验表明当前的MLMs在颜色感知任务中确实存在明显的幻觉现象，且该数据集能有效揭示模型在视觉模态中的脆弱性。

Conclusion: 多模态大模型在视觉感知方面存在颜色相关的幻觉问题，未来需针对性设计机制以提升其感知准确性和鲁棒性。

Abstract: With the rapid advancement of Large Models, numerous text-and-vision-fused Multimodal Large Models (MLMs) have emerged. However, these MLMs remain susceptible to informational interference in visual perception, particularly in color perception, which introduces an additional risk of hallucination. To validate this hypothesis, we introduce the "What Color Is It" dataset, a novel benchmark constructed using a simple method to trigger single-modality visual hallucination in MLMs. Based on this dataset, we further investigate the underlying causes of hallucination in the visual modality of MLMs and propose potential solutions to enhance their robustness.

</details>


### [265] [Delineate Anything Flow: Fast, Country-Level Field Boundary Detection from Any Source](https://arxiv.org/abs/2511.13417)
*Mykola Lavreniuk,Nataliia Kussul,Andrii Shelestov,Yevhenii Salii,Volodymyr Kuzin,Sergii Skakun,Zoltan Szantoi*

Main category: cs.CV

TL;DR: 提出了一种名为DelAnyFlow的分辨率无关方法，用于大规模农田边界测绘，结合了基于YOLOv11的DelAny实例分割模型和结构化后处理流程，在准确性和效率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有农田边界提取方法存在边界不完整、相邻田块合并和难以扩展等问题，尤其在小农户和碎片化农田系统中表现不佳，亟需一种可扩展且高精度的解决方案。

Method: 开发了DelAny实例分割模型（基于YOLOv11 backbone），并在大规模FBIS 22M数据集（包含67.2万图像块和2290万个田块实例）上进行训练；结合后处理、合并与矢量化流程，形成DelAnyFlow方法，实现拓扑一致的矢量边界生成。

Result: DelAny模型的mAP超过SAM2一倍以上，推理速度快400倍；使用Sentinel-2数据在单个工作站六小时内完成乌克兰全国（60.3万平方公里）的田块边界提取；在5米和2.5米分辨率下分别识别出375万和515万田块，远多于Sinergise和NASA Harvest的结果；边界完整性显著提升，尤其在小田块场景。

Conclusion: DelAnyFlow提供了一种可扩展、低成本的农田边界制图方法，适用于缺乏数字地籍数据的地区，推动大范围农业监测与土地管理。

Abstract: Accurate delineation of agricultural field boundaries from satellite imagery is essential for land management and crop monitoring, yet existing methods often produce incomplete boundaries, merge adjacent fields, and struggle to scale. We present the Delineate Anything Flow (DelAnyFlow) methodology, a resolution-agnostic approach for large-scale field boundary mapping. DelAnyFlow combines the DelAny instance segmentation model, based on a YOLOv11 backbone and trained on the large-scale Field Boundary Instance Segmentation-22M (FBIS 22M) dataset, with a structured post-processing, merging, and vectorization sequence to generate topologically consistent vector boundaries. FBIS 22M, the largest dataset of its kind, contains 672,909 multi-resolution image patches (0.25-10m) and 22.9million validated field instances. The DelAny model delivers state-of-the-art accuracy with over 100% higher mAP and 400x faster inference than SAM2. DelAny demonstrates strong zero-shot generalization and supports national-scale applications: using Sentinel 2 data for 2024, DelAnyFlow generated a complete field boundary layer for Ukraine (603,000km2) in under six hours on a single workstation. DelAnyFlow outputs significantly improve boundary completeness relative to operational products from Sinergise Solutions and NASA Harvest, particularly in smallholder and fragmented systems (0.25-1ha). For Ukraine, DelAnyFlow delineated 3.75M fields at 5m and 5.15M at 2.5m, compared to 2.66M detected by Sinergise Solutions and 1.69M by NASA Harvest. This work delivers a scalable, cost-effective methodology for field delineation in regions lacking digital cadastral data. A project landing page with links to model weights, code, national-scale vector outputs, and dataset is available at https://lavreniuk.github.io/Delineate-Anything/.

</details>


### [266] [VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task](https://arxiv.org/abs/2511.13420)
*Xingming Long,Jie Zhang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的评估方法VOPE，用于评估大视觉语言模型（LVLMs）在主动想象任务中的幻觉问题，发现现有模型和缓解方法在此类任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LVLMs在事实描述任务中的幻觉，而忽视了在需要创造性生成的主动想象任务中的幻觉评估，亟需一种更合理的评估方式。

Method: 提出VOPE方法，通过基于复核的问题评估LVLM对其生成对象存在性的理解，并以该理解与图像中实际存在的对象一致性来判断是否产生幻觉。

Result: 实验显示大多数LVLM在主动想象任务中严重幻觉，且在存在性评估上表现差；现有幻觉缓解方法对此类任务效果有限。

Conclusion: 主动想象任务中的幻觉问题亟待重视，VOPE为评估此类问题提供了有效工具，并指出现有模型和方法需进一步改进。

Abstract: Most research on hallucinations in Large Vision-Language Models (LVLMs) focuses on factual description tasks that prohibit any output absent from the image. However, little attention has been paid to hallucinations in voluntary imagination tasks, e.g., story writing, where the models are expected to generate novel content beyond the given image. In these tasks, it is inappropriate to simply regard such imagined novel content as hallucinations. To address this limitation, we introduce Voluntary-imagined Object Presence Evaluation (VOPE)-a novel method to assess LVLMs' hallucinations in voluntary imagination tasks via presence evaluation. Specifically, VOPE poses recheck-based questions to evaluate how an LVLM interprets the presence of the imagined objects in its own response. The consistency between the model's interpretation and the object's presence in the image is then used to determine whether the model hallucinates when generating the response. We apply VOPE to several mainstream LVLMs and hallucination mitigation methods, revealing two key findings: (1) most LVLMs hallucinate heavily during voluntary imagination, and their performance in presence evaluation is notably poor on imagined objects; (2) existing hallucination mitigation methods show limited effect in voluntary imagination tasks, making this an important direction for future research.

</details>


### [267] [FUSE: A Flow-based Mapping Between Shapes](https://arxiv.org/abs/2511.13431)
*Lorenzo Olearo,Giulio Viganò,Daniele Baieri,Filippo Maggioli,Simone Melzi*

Main category: cs.CV

TL;DR: 提出了一种基于流匹配模型的新型神经表示方法，用于3D形状间的映射，具有计算高效、跨表示形式匹配、无需大规模训练的优点。


<details>
  <summary>Details</summary>
Motivation: 现有的3D形状匹配方法通常依赖大规模训练或特定数据驱动流程，难以泛化到不同表示形式（如点云、网格、SDF等）。需要一种更通用、高效且无需大量训练的跨模态匹配方法。

Method: 将3D形状建模为从一个固定锚分布通过连续可逆流映射得到的概率分布；通过组合源形状到锚的逆流与锚到目标形状的正向流，实现源与目标之间的连续点映射；使用点级任务定制嵌入编码形状，实现可逆且模态无关的形状映射表示。

Result: 该方法在多种基准测试和挑战性场景下均实现了高覆盖率和高精度的形状匹配效果，并能推广至UV映射和人体点云扫描配准等任务。

Conclusion: 所提出的基于流匹配的神经表示方法为跨表示形式的3D形状映射提供了一种高效、通用且无需大规模训练的新范式，具有良好的扩展性和应用潜力。

Abstract: We introduce a novel neural representation for maps between 3D shapes based on flow-matching models, which is computationally efficient and supports cross-representation shape matching without large-scale training or data-driven procedures. 3D shapes are represented as the probability distribution induced by a continuous and invertible flow mapping from a fixed anchor distribution. Given a source and a target shape, the composition of the inverse flow (source to anchor) with the forward flow (anchor to target), we continuously map points between the two surfaces. By encoding the shapes with a pointwise task-tailored embedding, this construction provides an invertible and modality-agnostic representation of maps between shapes across point clouds, meshes, signed distance fields (SDFs), and volumetric data. The resulting representation consistently achieves high coverage and accuracy across diverse benchmarks and challenging settings in shape matching. Beyond shape matching, our framework shows promising results in other tasks, including UV mapping and registration of raw point cloud scans of human bodies.

</details>


### [268] [Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline](https://arxiv.org/abs/2511.13442)
*Rui Zuo,Qinyue Tong,Zhe-Ming Lu,Ziqian Lu*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的基于多模态大语言模型（MLLM）的图像伪造分析框架Foresee，通过类型先验驱动策略和灵活特征检测模块（FFD），在无需额外训练的情况下实现了高精度的篡改定位和丰富的文本解释，具有强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有图像伪造检测方法在跨数据集泛化性和可解释性方面存在不足，且当前基于MLLM的方法依赖大规模训练，计算成本高，未能充分挖掘 vanilla MLLM 在图像取证中的内在泛化潜力。

Method: 提出 Foresee，一种无需训练的 MLLM 基础图像伪造分析流程，采用类型先验驱动策略，并设计灵活特征检测（FFD）模块以有效应对复制-移动篡改，充分发挥 vanilla MLLM 在取证任务中的潜力。

Result: 实验表明，Foresee 在多种篡改类型（包括复制-移动、拼接、删除、局部增强、深度伪造和AIGC编辑）上均实现了优于现有方法的定位精度和更全面的文本解释，且具备更强的泛化能力。

Conclusion: Foresee 无需训练即可高效实现图像伪造分析，在定位准确性和可解释性方面优于现有方法，验证了 vanilla MLLM 在图像取证任务中无需微调即可释放强大潜力的可行性。

Abstract: With the rapid advancement of artificial intelligence-generated content (AIGC) technologies, including multimodal large language models (MLLMs) and diffusion models, image generation and manipulation have become remarkably effortless. Existing image forgery detection and localization (IFDL) methods often struggle to generalize across diverse datasets and offer limited interpretability. Nowadays, MLLMs demonstrate strong generalization potential across diverse vision-language tasks, and some studies introduce this capability to IFDL via large-scale training. However, such approaches cost considerable computational resources, while failing to reveal the inherent generalization potential of vanilla MLLMs to address this problem. Inspired by this observation, we propose Foresee, a training-free MLLM-based pipeline tailored for image forgery analysis. It eliminates the need for additional training and enables a lightweight inference process, while surpassing existing MLLM-based methods in both tamper localization accuracy and the richness of textual explanations. Foresee employs a type-prior-driven strategy and utilizes a Flexible Feature Detector (FFD) module to specifically handle copy-move manipulations, thereby effectively unleashing the potential of vanilla MLLMs in the forensic domain. Extensive experiments demonstrate that our approach simultaneously achieves superior localization accuracy and provides more comprehensive textual explanations. Moreover, Foresee exhibits stronger generalization capability, outperforming existing IFDL methods across various tampering types, including copy-move, splicing, removal, local enhancement, deepfake, and AIGC-based editing. The code will be released in the final version.

</details>


### [269] [Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling](https://arxiv.org/abs/2511.13478)
*Adam Hazimeh,Ke Wang,Mark Collier,Gilles Baechler,Efi Kokiopoulou,Pascal Frossard*

Main category: cs.CV

TL;DR: 本文提出SliDer，一种利用视觉-语言模型（VLM）将幻灯片图像语义去渲染为可编辑的SVG格式的新框架，并构建了Slide2SVG数据集，实验表明其在重建质量和人类偏好上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的几何光栅-矢量转换方法在处理复杂文档（如幻灯片）时无法保持高层语义结构，导致文本与图像元素的语义区分丢失，限制了文档的可编辑性。

Method: 提出SliDer框架，利用视觉-语言模型（VLM）检测并提取光栅输入中图文元素的属性，迭代优化预测结果，并将其组织为结构化的SVG表示；同时构建了包含真实科研演示文稿的光栅-SVG配对数据集Slide2SVG。

Result: SliDer在重建LPIPS指标上达到0.069，在与最强的零样本VLM基线对比中，82.9%的情况下更受人类评估者青睐。

Conclusion: SliDer通过引入语义感知的去渲染方法，显著提升了幻灯片图像转为可编辑矢量格式的效果，为多媒体文档的再编辑提供了有效解决方案。

Abstract: Multimedia documents such as slide presentations and posters are designed to be interactive and easy to modify. Yet, they are often distributed in a static raster format, which limits editing and customization. Restoring their editability requires converting these raster images back into structured vector formats. However, existing geometric raster-vectorization methods, which rely on low-level primitives like curves and polygons, fall short at this task. Specifically, when applied to complex documents like slides, they fail to preserve the high-level structure, resulting in a flat collection of shapes where the semantic distinction between image and text elements is lost. To overcome this limitation, we address the problem of semantic document derendering by introducing SliDer, a novel framework that uses Vision-Language Models (VLMs) to derender slide images as compact and editable Scalable Vector Graphic (SVG) representations. SliDer detects and extracts attributes from individual image and text elements in a raster input and organizes them into a coherent SVG format. Crucially, the model iteratively refines its predictions during inference in a process analogous to human design, generating SVG code that more faithfully reconstructs the original raster upon rendering. Furthermore, we introduce Slide2SVG, a novel dataset comprising raster-SVG pairs of slide documents curated from real-world scientific presentations, to facilitate future research in this domain. Our results demonstrate that SliDer achieves a reconstruction LPIPS of 0.069 and is favored by human evaluators in 82.9% of cases compared to the strongest zero-shot VLM baseline.

</details>


### [270] [InterMoE: Individual-Specific 3D Human Interaction Generation via Dynamic Temporal-Selective MoE](https://arxiv.org/abs/2511.13488)
*Lipeng Wang,Hongxing Fan,Haohua Chen,Zehuan Huang,Lu Sheng*

Main category: cs.CV

TL;DR: 提出InterMoE框架，基于动态时间选择性专家混合模型，提升3D人体交互生成的个体特征保持和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成高质量人体交互时难以同时保留个体特征并准确遵循文本描述。

Method: 设计动态时间选择性专家混合架构（InterMoE），通过结合高层文本语义与低层运动上下文的路由机制，动态分配时序特征至专业化专家模块。

Result: 在InterHuman和InterX数据集上实验表明，InterMoE分别将FID分数降低9%和22%，实现最先进的个体特异性高保真3D人体交互生成。

Conclusion: InterMoE能有效平衡个体特征保留与语义一致性，显著提升文本驱动的3D人体交互生成质量。

Abstract: Generating high-quality human interactions holds significant value for applications like virtual reality and robotics. However, existing methods often fail to preserve unique individual characteristics or fully adhere to textual descriptions. To address these challenges, we introduce InterMoE, a novel framework built on a Dynamic Temporal-Selective Mixture of Experts. The core of InterMoE is a routing mechanism that synergistically uses both high-level text semantics and low-level motion context to dispatch temporal motion features to specialized experts. This allows experts to dynamically determine the selection capacity and focus on critical temporal features, thereby preserving specific individual characteristic identities while ensuring high semantic fidelity. Extensive experiments show that InterMoE achieves state-of-the-art performance in individual-specific high-fidelity 3D human interaction generation, reducing FID scores by 9% on the InterHuman dataset and 22% on InterX.

</details>


### [271] [Language-Guided Invariance Probing of Vision-Language Models](https://arxiv.org/abs/2511.13494)
*Jae Joong Lee*

Main category: cs.CV

TL;DR: 本文提出了Language-Guided Invariance Probing (LGIP)基准，用于评估视觉-语言模型在图像-文本匹配任务中对语言扰动的鲁棒性，发现部分模型（如EVA02-CLIP）表现良好，而SigLIP系列模型在语义敏感性和语言不变性方面存在明显缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（如CLIP）在零样本任务中表现优异，但其对语言扰动（如同义改写或语义变化）的响应可靠性尚不明确，缺乏有效评估方法。

Method: 提出LGIP基准，利用MS COCO数据集中每张图像的五个人工标注描述，自动生成保持语义的同义改写和改变语义（如对象类别、颜色、数量）的翻转文本，通过不变性误差、语义敏感性差距和正检率等指标评估九种VLM的表现。

Result: EVA02-CLIP和大型OpenCLIP变体在不变性和敏感性之间表现最优，而SigLIP和SigLIP2显示出较高的不变性误差，且常错误地偏好语义翻转后的文本；这些缺陷在传统检索指标中难以察觉。

Conclusion: LGIP提供了一种超越传统准确率的、模型无关的诊断工具，可有效揭示视觉-语言模型在语言理解方面的鲁棒性问题。

Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.
  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.

</details>


### [272] [Mapping the Vanishing and Transformation of Urban Villages in China](https://arxiv.org/abs/2511.13507)
*Wenyu Zhang,Yao Tong,Yiqiu Liu,Rui Cao*

Main category: cs.CV

TL;DR: 本研究提出一种基于深度学习的框架，用于监测中国城中村的时空变化，评估其拆除后的土地利用情况，并揭示再开发过程中的三种时空演变路径。


<details>
  <summary>Details</summary>
Motivation: 现有对城中村拆除和再开发的研究缺乏系统性评估，难以判断土地是否被有效再利用，因此需要一个系统方法来评估再开发的有效性和可持续性。

Method: 采用多时相遥感影像的语义分割技术绘制城中村边界变化，并将拆除后的土地利用分为六类（未完全拆除、空地、施工场地、建筑、绿地等），结合‘保留-拆除-再开发’阶段进行分类分析。选取中国四大经济区域的四个代表性城市（广州、郑州、西安、哈尔滨）作为研究区。

Result: 1) 城中村再开发过程普遍持续时间较长；2) 再开发主要发生在城市边缘区域，城市核心区域相对稳定；3) 识别出同步再开发、延迟再开发和渐进优化三种时空演变路径。

Conclusion: 城中村再开发具有碎片化、复杂性和非线性特征，需采取分级且因地制宜的规划策略。研究通过将空间动态与政策背景结合，为包容、高效和可持续的城市更新提供实证支持，并促进对全球非正规住区转型的理解。

Abstract: Urban villages (UVs), informal settlements embedded within China's urban fabric, have undergone widespread demolition and redevelopment in recent decades. However, there remains a lack of systematic evaluation of whether the demolished land has been effectively reused, raising concerns about the efficacy and sustainability of current redevelopment practices. To address the gap, this study proposes a deep learning-based framework to monitor the spatiotemporal changes of UVs in China. Specifically, semantic segmentation of multi-temporal remote sensing imagery is first used to map evolving UV boundaries, and then post-demolition land use is classified into six categories based on the "remained-demolished-redeveloped" phase: incomplete demolition, vacant land, construction sites, buildings, green spaces, and others. Four representative cities from China's four economic regions were selected as the study areas, i.e., Guangzhou (East), Zhengzhou (Central), Xi'an (West), and Harbin (Northeast). The results indicate: 1) UV redevelopment processes were frequently prolonged; 2) redevelopment transitions primarily occurred in peripheral areas, whereas urban cores remained relatively stable; and 3) three spatiotemporal transformation pathways, i.e., synchronized redevelopment, delayed redevelopment, and gradual optimization, were revealed. This study highlights the fragmented, complex and nonlinear nature of UV redevelopment, underscoring the need for tiered and context-sensitive planning strategies. By linking spatial dynamics with the context of redevelopment policies, the findings offer valuable empirical insights that support more inclusive, efficient, and sustainable urban renewal, while also contributing to a broader global understanding of informal settlement transformations.

</details>


### [273] [Minimax Multi-Target Conformal Prediction with Applications to Imaging Inverse Problems](https://arxiv.org/abs/2511.13533)
*Jeffrey Wen,Rizwan Ahmad,Philip Schniter*

Main category: cs.CV

TL;DR: 提出一种渐近最小最大方法用于多目标共形预测，以在保证联合边际覆盖的同时提供紧密的预测区间，并将其应用于多指标盲图像质量评估、多任务不确定性量化和多轮测量获取。


<details>
  <summary>Details</summary>
Motivation: 在病态成像反问题中，不确定性量化是一个基本挑战，尤其是在安全关键应用中。现有工作仅处理标量估计目标，而实际应用常涉及多个目标。

Method: 提出一种渐近最小最大方法用于多目标共形预测，确保联合边际覆盖并提供紧致预测区间。

Result: 通过合成数据和磁共振成像（MRI）数据验证了该方法相较于现有方法的优势。

Conclusion: 所提方法在多目标共形预测中表现优异，适用于多种实际应用场景。

Abstract: In ill-posed imaging inverse problems, uncertainty quantification remains a fundamental challenge, especially in safety-critical applications. Recently, conformal prediction has been used to quantify the uncertainty that the inverse problem contributes to downstream tasks like image classification, image quality assessment, fat mass quantification, etc. While existing works handle only a scalar estimation target, practical applications often involve multiple targets. In response, we propose an asymptotically minimax approach to multi-target conformal prediction that provides tight prediction intervals while ensuring joint marginal coverage. We then outline how our minimax approach can be applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition. Finally, we numerically demonstrate the benefits of our minimax method, relative to existing multi-target conformal prediction methods, using both synthetic and magnetic resonance imaging (MRI) data.

</details>


### [274] [Accuracy is Not Enough: Poisoning Interpretability in Federated Learning via Color Skew](https://arxiv.org/abs/2511.13535)
*Farhin Farhad Riya,Shahinul Hoque,Jinyuan Stella Sun,Olivera Kotevska*

Main category: cs.CV

TL;DR: 提出一种名为Chromatic Perturbation Module的攻击框架，通过在联邦学习中引入微小颜色扰动，破坏模型显著性图的保真度而不影响预测准确性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在安全关键领域的广泛应用，可解释性技术变得至关重要；但现有研究忽视了解释本身可能成为攻击面的问题。

Method: 设计了一种感知显著性的攻击方法，在联邦学习中通过调整前景与背景的颜色对比度来生成对抗样本，并在多轮训练中累积扰动以毒化全局模型的特征归因。

Result: 在多个数据集上验证了该攻击的有效性，Grad-CAM解释的峰值激活重叠率下降高达35%，同时分类准确率保持在96%以上。

Conclusion: 正确预测并不意味着可信解释，模型可解释性本身存在被隐蔽攻击的风险，尤其在联邦学习场景下更难检测和防御。

Abstract: As machine learning models are increasingly deployed in safety-critical domains, visual explanation techniques have become essential tools for supporting transparency. In this work, we reveal a new class of attacks that compromise model interpretability without affecting accuracy. Specifically, we show that small color perturbations applied by adversarial clients in a federated learning setting can shift a model's saliency maps away from semantically meaningful regions while keeping the prediction unchanged. The proposed saliency-aware attack framework, called Chromatic Perturbation Module, systematically crafts adversarial examples by altering the color contrast between foreground and background in a way that disrupts explanation fidelity. These perturbations accumulate across training rounds, poisoning the global model's internal feature attributions in a stealthy and persistent manner. Our findings challenge a common assumption in model auditing that correct predictions imply faithful explanations and demonstrate that interpretability itself can be an attack surface. We evaluate this vulnerability across multiple datasets and show that standard training pipelines are insufficient to detect or mitigate explanation degradation, especially in the federated learning setting, where subtle color perturbations are harder to discern. Our attack reduces peak activation overlap in Grad-CAM explanations by up to 35% while preserving classification accuracy above 96% on all evaluated datasets.

</details>


### [275] [BootOOD: Self-Supervised Out-of-Distribution Detection via Synthetic Sample Exposure under Neural Collapse](https://arxiv.org/abs/2511.13539)
*Yuanchao Wang,Tian Qin,Eduardo Valle,Bruno Abrahao*

Main category: cs.CV

TL;DR: 提出了一种名为BootOOD的完全自监督的异常检测框架，仅使用正常分布数据进行训练，通过特征范数的半径分类有效应对语义上接近的异常样本。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法在面对与正常类别语义相似的异常样本时表现不佳，需要一种不依赖外部异常数据且能处理语义挑战性样本的方法。

Method: 利用正常分布数据的特征坍缩特性，通过简单变换生成伪异常特征，并引入轻量级辅助头对特征范数进行基于半径的分类，使异常样本学习到更小的特征范数。

Result: 在CIFAR-10、CIFAR-100和ImageNet-200上实验表明，BootOOD优于之前的后处理方法，在不使用异常数据训练的情况下超过部分训练方法，并与最先进的暴露异常数据方法性能相当，同时保持或提升正常类别的分类精度。

Conclusion: BootOOD是一种有效的自监督异常检测框架，能够在无需异常样本的情况下显著提升对语义相近异常样本的检测能力。

Abstract: Out-of-distribution (OOD) detection is critical for deploying image classifiers in safety-sensitive environments, yet existing detectors often struggle when OOD samples are semantically similar to the in-distribution (ID) classes. We present BootOOD, a fully self-supervised OOD detection framework that bootstraps exclusively from ID data and is explicitly designed to handle semantically challenging OOD samples. BootOOD synthesizes pseudo-OOD features through simple transformations of ID representations and leverages Neural Collapse (NC), where ID features cluster tightly around class means with consistent feature norms. Unlike prior approaches that aim to constrain OOD features into subspaces orthogonal to the collapsed ID means, BootOOD introduces a lightweight auxiliary head that performs radius-based classification on feature norms. This design decouples OOD detection from the primary classifier and imposes a relaxed requirement: OOD samples are learned to have smaller feature norms than ID features, which is easier to satisfy when ID and OOD are semantically close. Experiments on CIFAR-10, CIFAR-100, and ImageNet-200 show that BootOOD outperforms prior post-hoc methods, surpasses training-based methods without outlier exposure, and is competitive with state-of-the-art outlier-exposure approaches while maintaining or improving ID accuracy.

</details>


### [276] [Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks](https://arxiv.org/abs/2511.13545)
*Md. Iqbal Hossain,Afia Sajeeda,Neeresh Kumar Perla,Ming Shao*

Main category: cs.CV

TL;DR: 提出一种针对CLIP等多模态对比学习模型的新型后门防御策略，通过引入图像分割“oracle”识别触发器并精确定位受害样本和标签，从而高效修复中毒模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型如CLIP易受后门攻击，且当前防御方法需从头训练或大规模微调，缺乏对受影响标签的精准定位。

Method: 引入图像分割oracle作为监督信号，设计两种算法：一是通过比较CLIP与oracle的知识差异识别潜在触发器；二是定位受影响的标签和样本，构建紧凑的微调数据集以修复模型。

Result: 在视觉识别基准上的实验表明，该方法能有效识别后门触发器、定位受害样本与标签，并显著提升中毒CLIP模型的鲁棒性。

Conclusion: 所提方法为CLIP类多模态模型提供了一种高效、精准的后门防御方案，无需大规模训练即可有效消除后门效应。

Abstract: The advent of multimodal deep learning models, such as CLIP, has unlocked new frontiers in a wide range of applications, from image-text understanding to classification tasks. However, these models are not safe for adversarial attacks, particularly backdoor attacks, which can subtly manipulate model behavior. Moreover, existing defense methods typically involve training from scratch or fine-tuning using a large dataset without pinpointing the specific labels that are affected. In this study, we introduce an innovative strategy to enhance the robustness of multimodal contrastive learning models against such attacks. In particular, given a poisoned CLIP model, our approach can identify the backdoor trigger and pinpoint the victim samples and labels in an efficient manner. To that end, an image segmentation ``oracle'' is introduced as the supervisor for the output of the poisoned CLIP. We develop two algorithms to rectify the poisoned model: (1) differentiating between CLIP and Oracle's knowledge to identify potential triggers; (2) pinpointing affected labels and victim samples, and curating a compact fine-tuning dataset. With this knowledge, we are allowed to rectify the poisoned CLIP model to negate backdoor effects. Extensive experiments on visual recognition benchmarks demonstrate our strategy is effective in CLIP-based backdoor defense.

</details>


### [277] [TSE-Net: Semi-supervised Monocular Height Estimation from Single Remote Sensing Images](https://arxiv.org/abs/2511.13552)
*Sining Chen,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出TSE-Net，一种用于半监督单目高度估计的自训练框架，通过教师-学生-考试网络结构和伪标签过滤机制，在少量标注数据下显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 单目高度估计依赖大量标注数据，但获取成本高、标注困难，限制了深度学习方法的泛化能力。因此需要利用未标注数据提升模型性能。

Method: 提出TSE-Net，包含教师、学生和考试网络：教师网络生成回归与分类联合输出的伪标签；学生网络用伪标签在无标签数据上训练；考试网络作为学生网络的时间集成以稳定性能；采用层次化双切策略划分高度类别，并用Plackett-Luce模型校准分类概率以过滤伪标签。

Result: 在三个不同分辨率和成像模态的数据集上验证了方法的有效性，相比现有半监督方法显著提升高度估计精度，尤其在低标注率场景下表现优异。

Conclusion: TSE-Net通过有效的伪标签生成与筛选机制，成功利用大量无标签数据提升单目高度估计性能，为遥感中3D感知提供了高效低成本的解决方案。

Abstract: Monocular height estimation plays a critical role in 3D perception for remote sensing, offering a cost-effective alternative to multi-view or LiDAR-based methods. While deep learning has significantly advanced the capabilities of monocular height estimation, these methods remain fundamentally limited by the availability of labeled data, which are expensive and labor-intensive to obtain at scale. The scarcity of high-quality annotations hinders the generalization and performance of existing models. To overcome this limitation, we propose leveraging large volumes of unlabeled data through a semi-supervised learning framework, enabling the model to extract informative cues from unlabeled samples and improve its predictive performance. In this work, we introduce TSE-Net, a self-training pipeline for semi-supervised monocular height estimation. The pipeline integrates teacher, student, and exam networks. The student network is trained on unlabeled data using pseudo-labels generated by the teacher network, while the exam network functions as a temporal ensemble of the student network to stabilize performance. The teacher network is formulated as a joint regression and classification model: the regression branch predicts height values that serve as pseudo-labels, and the classification branch predicts height value classes along with class probabilities, which are used to filter pseudo-labels. Height value classes are defined using a hierarchical bi-cut strategy to address the inherent long-tailed distribution of heights, and the predicted class probabilities are calibrated with a Plackett-Luce model to reflect the expected accuracy of pseudo-labels. We evaluate the proposed pipeline on three datasets spanning different resolutions and imaging modalities. Codes are available at https://github.com/zhu-xlab/tse-net.

</details>


### [278] [Opt3DGS: Optimizing 3D Gaussian Splatting with Adaptive Exploration and Curvature-Aware Exploitation](https://arxiv.org/abs/2511.13571)
*Ziyang Huang,Jiagang Chen,Jin Liu,Shunping Ji*

Main category: cs.CV

TL;DR: 提出Opt3DGS，通过两阶段优化方法改进3D高斯泼溅的优化过程，提升渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）在新视角合成中表现突出，但其核心优化问题（如陷入局部最优和收敛质量不足）尚未充分探索。

Method: 提出Opt3DGS框架，包含两个阶段：1）自适应加权随机梯度朗之万动力学（SGLD）进行全局探索以跳出局部最优；2）局部拟牛顿方向引导的Adam优化器利用曲率信息实现高效精确收敛。

Result: 在多个基准数据集上的实验表明，Opt3DGS在不改变3DGS表示的前提下，实现了最先进的渲染质量。

Conclusion: Opt3DGS通过增强优化过程显著提升了3DGS的性能，为未来优化方向提供了有效范式。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading framework for novel view synthesis, yet its core optimization challenges remain underexplored. We identify two key issues in 3DGS optimization: entrapment in suboptimal local optima and insufficient convergence quality. To address these, we propose Opt3DGS, a robust framework that enhances 3DGS through a two-stage optimization process of adaptive exploration and curvature-guided exploitation. In the exploration phase, an Adaptive Weighted Stochastic Gradient Langevin Dynamics (SGLD) method enhances global search to escape local optima. In the exploitation phase, a Local Quasi-Newton Direction-guided Adam optimizer leverages curvature information for precise and efficient convergence. Extensive experiments on diverse benchmark datasets demonstrate that Opt3DGS achieves state-of-the-art rendering quality by refining the 3DGS optimization process without modifying its underlying representation.

</details>


### [279] [Hierarchical Prompt Learning for Image- and Text-Based Person Re-Identification](https://arxiv.org/abs/2511.13575)
*Linhan Zhou,Shuang Li,Neng Dong,Yonghang Tai,Yafei Zhang,Huafeng Li*

Main category: cs.CV

TL;DR: 提出了一种统一的层次化提示学习框架（HPL），通过任务感知的提示建模联合优化图像到图像和文本到图像的行人重识别任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将图像和文本检索任务分开处理，导致表示纠缠和性能次优，因此需要一种能同时有效处理两种任务的统一框架。

Method: 设计了任务路由Transformer，在共享视觉编码器中引入双分类token以分别处理I2I和T2I分支；提出了层次化提示生成机制，结合身份级可学习token和实例级伪文本token；并通过模态特定的逆网络生成伪token，增强细粒度语义；还提出了跨模态提示正则化策略，确保提示空间中的语义对齐。

Result: 在多个ReID基准上进行了广泛实验，HPL在I2I和T2I任务上均达到了最先进的性能。

Conclusion: HPL通过任务感知的层次化提示学习，有效实现了图像和文本模态的联合优化，提升了行人重识别在两种检索模式下的表现。

Abstract: Person re-identification (ReID) aims to retrieve target pedestrian images given either visual queries (image-to-image, I2I) or textual descriptions (text-to-image, T2I). Although both tasks share a common retrieval objective, they pose distinct challenges: I2I emphasizes discriminative identity learning, while T2I requires accurate cross-modal semantic alignment. Existing methods often treat these tasks separately, which may lead to representation entanglement and suboptimal performance. To address this, we propose a unified framework named Hierarchical Prompt Learning (HPL), which leverages task-aware prompt modeling to jointly optimize both tasks. Specifically, we first introduce a Task-Routed Transformer, which incorporates dual classification tokens into a shared visual encoder to route features for I2I and T2I branches respectively. On top of this, we develop a hierarchical prompt generation scheme that integrates identity-level learnable tokens with instance-level pseudo-text tokens. These pseudo-tokens are derived from image or text features via modality-specific inversion networks, injecting fine-grained, instance-specific semantics into the prompts. Furthermore, we propose a Cross-Modal Prompt Regularization strategy to enforce semantic alignment in the prompt token space, ensuring that pseudo-prompts preserve source-modality characteristics while enhancing cross-modal transferability. Extensive experiments on multiple ReID benchmarks validate the effectiveness of our method, achieving state-of-the-art performance on both I2I and T2I tasks.

</details>


### [280] [Adaptive Multi-Scale Integration Unlocks Robust Cell Annotation in Histopathology Images](https://arxiv.org/abs/2511.13586)
*Yinuo Xu,Yan Cui,Mingyao Li,Zhi Huang*

Main category: cs.CV

TL;DR: NuClass是一种受病理学家工作流程启发的细胞级多尺度整合框架，结合核形态与微环境上下文信息，通过不确定性引导的学习策略和可解释性设计，在缺乏精细标注的情况下实现了高精度细胞类型识别。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像块的模型难以同时捕捉细胞核形态与组织上下文，且缺乏细粒度的细胞亚型标注，限制了细胞级别表型预测的准确性。

Method: 提出NuClass框架，包含局部路径（224x224图像块）和全局路径（1024x1024邻域），通过可学习门控模块自适应融合；引入不确定性引导目标函数，并利用Xenium空间转录组数据构建百万级单细胞标注数据集。

Result: 在三个独立队列上评估，最高F1分数达96%，优于多种基线模型，具备良好的置信度校准和Grad-CAM可视化能力。

Conclusion: 多尺度、不确定性感知的融合策略能有效连接全片病理基础模型与可靠的细胞级表型预测，提升计算病理学对疾病的理解。

Abstract: Identifying cell types and subtypes from routine histopathology images is essential for improving the computational understanding of human disease. Existing tile-based models can capture detailed nuclear morphology but often fail to incorporate the broader tissue context that influences a cell's function and identity. In addition, available human annotations are typically coarse-grained and unevenly distributed across studies, making fine-grained subtype-level supervision difficult to obtain.
  To address these limitations, we introduce NuClass, a pathologist workflow inspired framework for cell-wise multi-scale integration of nuclear morphology and microenvironmental context. NuClass includes two main components: Path local, which focuses on nuclear morphology from 224-by-224 pixel crops, and Path global, which models the surrounding 1024-by-1024 pixel neighborhood. A learnable gating module adaptively balances local detail and contextual cues. To encourage complementary learning, we incorporate an uncertainty-guided objective that directs the global path to prioritize regions where the local path is uncertain. We also provide calibrated confidence estimates and Grad-CAM visualizations to enhance interpretability.
  To overcome the lack of high-quality annotations, we construct a marker-guided dataset from Xenium spatial transcriptomics assays, yielding single-cell resolution labels for more than two million cells across eight organs and 16 classes. Evaluated on three fully held-out cohorts, NuClass achieves up to 96 percent F1 for its best-performing class, outperforming strong baselines. Our results show that multi-scale, uncertainty-aware fusion can bridge the gap between slide-level pathological foundation models and reliable, cell-level phenotype prediction.

</details>


### [281] [VVS: Accelerating Speculative Decoding for Visual Autoregressive Generation via Partial Verification Skipping](https://arxiv.org/abs/2511.13587)
*Haotian Dong,Ye Li,Rongwei Lu,Chen Tang,Shu-Tao Xia,Zhi Wang*

Main category: cs.CV

TL;DR: 提出了一种新的推测解码框架VVS，通过部分验证跳过加速视觉自回归生成，显著减少目标模型前向传递次数，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码的“先草拟后验证”范式无法直接减少前向传递次数，限制了加速潜力，因此需要探索验证跳过机制以进一步降低推理延迟。

Method: 基于视觉令牌可互换性，提出VVS框架，包含动态截断的无验证令牌选择器、令牌级特征缓存与重用、细粒度跳过步调度三个模块，实现部分验证跳过。

Result: 相比传统自回归解码，VVS将目标模型前向传递次数减少了2.8倍，在保持竞争性生成质量的同时优于常规推测解码框架。

Conclusion: VVS有效降低了视觉自回归模型的推理延迟，揭示了重塑推测解码范式的潜力，为高效图像生成提供了新方向。

Abstract: Visual autoregressive (AR) generation models have demonstrated strong potential for image generation, yet their next-token-prediction paradigm introduces considerable inference latency. Although speculative decoding (SD) has been proven effective for accelerating visual AR models, its "draft one step, then verify one step" paradigm prevents a direct reduction of the forward passes, thus restricting acceleration potential. Motivated by the visual token interchangeability, we for the first time to explore verification skipping in the SD process of visual AR model generation to explicitly cut the number of target model forward passes, thereby reducing inference latency. Based on an analysis of the drafting stage's characteristics, we observe that verification redundancy and stale feature reusability are key factors to retain generation quality and speedup for verification-free steps. Inspired by these two observations, we propose a novel SD framework VVS to accelerate visual AR generation via partial verification skipping, which integrates three complementary modules: (1) a verification-free token selector with dynamical truncation, (2) token-level feature caching and reuse, and (3) fine-grained skipped step scheduling. Consequently, VVS reduces the number of target model forward passes by a factor of $2.8\times$ relative to vanilla AR decoding while maintaining competitive generation quality, offering a superior speed-quality trade-off over conventional SD frameworks and revealing strong potential to reshape the SD paradigm.

</details>


### [282] [ICLR: Inter-Chrominance and Luminance Interaction for Natural Color Restoration in Low-Light Image Enhancement](https://arxiv.org/abs/2511.13607)
*Xin Xu,Hao Liu,Wei Liu,Wei Wang,Jiayi Wu,Kui Jiang*

Main category: cs.CV

TL;DR: 提出了一种新的低光照图像增强框架ICLR，包含DIEM模块和CCL损失函数，有效提升亮度与色度分支间的互补特征提取并缓解梯度冲突，实验表明其在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在色度与亮度分支交互中存在分布差异大、亮度误差传播以及弱相关区域梯度冲突等问题，限制了低光照图像增强性能。

Method: 设计了双流交互增强模块（DIEM）从融合与增强两个维度提升互补信息提取，并提出协方差校正损失（CCL），利用亮度残差统计信息惩罚色度误差并约束色度分支协方差以平衡梯度冲突。

Result: 在多个数据集上的实验结果显示，所提ICLR框架在定量和定性评估中均优于当前最先进的方法。

Conclusion: ICLR框架通过改进色度与亮度分支的交互机制及优化损失函数，显著提升了低光照图像增强的效果与稳定性。

Abstract: Low-Light Image Enhancement (LLIE) task aims at improving contrast while restoring details and textures for images captured in low-light conditions. HVI color space has made significant progress in this task by enabling precise decoupling of chrominance and luminance. However, for the interaction of chrominance and luminance branches, substantial distributional differences between the two branches prevalent in natural images limit complementary feature extraction, and luminance errors are propagated to chrominance channels through the nonlinear parameter. Furthermore, for interaction between different chrominance branches, images with large homogeneous-color regions usually exhibit weak correlation between chrominance branches due to concentrated distributions. Traditional pixel-wise losses exploit strong inter-branch correlations for co-optimization, causing gradient conflicts in weakly correlated regions. Therefore, we propose an Inter-Chrominance and Luminance Interaction (ICLR) framework including a Dual-stream Interaction Enhancement Module (DIEM) and a Covariance Correction Loss (CCL). The DIEM improves the extraction of complementary information from two dimensions, fusion and enhancement, respectively. The CCL utilizes luminance residual statistics to penalize chrominance errors and balances gradient conflicts by constraining chrominance branches covariance. Experimental results on multiple datasets show that the proposed ICLR framework outperforms state-of-the-art methods.

</details>


### [283] [AtlasMorph: Learning conditional deformable templates for brain MRI](https://arxiv.org/abs/2511.13609)
*Marianne Rakic,Andrew Hoopes,S. Mazdak Abulnaga,Mert R. Sabuncu,John V. Guttag,Adrian V. Dalca*

Main category: cs.CV

TL;DR: 提出一种基于卷积配准神经网络的机器学习框架，可高效生成基于个体属性（如年龄、性别）的条件化脑部MRI模板，并利用分割信息提升配准性能。


<details>
  <summary>Details</summary>
Motivation: 传统模板构建成本高、数量少，常导致研究中使用不具代表性的模板，尤其在人群差异大时表现不佳。

Method: 采用卷积配准神经网络学习从个体属性（如年龄、性别）到图像模板的映射，并在有分割标签时生成带解剖标注的模板，同时该网络可用于图像配准。

Result: 在多个3D脑MRI数据集上验证，所生成的条件化模板质量高、代表性强；带标注的条件模板在配准任务中优于无条件或无标注模板及其他构建方法。

Conclusion: 该方法能高效生成个性化、高质量的医学图像模板，提升配准与分割性能，具有广泛应用于计算解剖学和群体研究的潜力。

Abstract: Deformable templates, or atlases, are images that represent a prototypical anatomy for a population, and are often enhanced with probabilistic anatomical label maps. They are commonly used in medical image analysis for population studies and computational anatomy tasks such as registration and segmentation. Because developing a template is a computationally expensive process, relatively few templates are available. As a result, analysis is often conducted with sub-optimal templates that are not truly representative of the study population, especially when there are large variations within this population. We propose a machine learning framework that uses convolutional registration neural networks to efficiently learn a function that outputs templates conditioned on subject-specific attributes, such as age and sex. We also leverage segmentations, when available, to produce anatomical segmentation maps for the resulting templates. The learned network can also be used to register subject images to the templates. We demonstrate our method on a compilation of 3D brain MRI datasets, and show that it can learn high-quality templates that are representative of populations. We find that annotated conditional templates enable better registration than their unlabeled unconditional counterparts, and outperform other templates construction methods.

</details>


### [284] [Tissue Aware Nuclei Detection and Classification Model for Histopathology Images](https://arxiv.org/abs/2511.13615)
*Kesi Xu,Eleni Chiou,Ali Varamesh,Laura Acqualagna,Nasir Rajpoot*

Main category: cs.CV

TL;DR: 提出TAND框架，通过组织掩码条件和点级监督实现联合核检测与分类，显著提升组织依赖性细胞类型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖详细的专家标注且未能充分利用组织上下文信息，限制了核检测与分类的准确性。

Method: TAND结合ConvNeXt编码器-解码器与冻结的Virchow-2组织分割分支，利用多尺度空间特征线性调制（Spatial-FiLM）将语义组织概率注入分类流。

Result: 在PUMA基准上达到最先进性能，尤其在上皮、内皮和间质等组织依赖性细胞类型中表现突出。

Conclusion: 这是首个利用学习到的组织掩码进行细胞分类条件调控的方法，有效减少标注负担，为计算病理学提供实用解决方案。

Abstract: Accurate nuclei detection and classification are fundamental to computational pathology, yet existing approaches are hindered by reliance on detailed expert annotations and insufficient use of tissue context. We present Tissue-Aware Nuclei Detection (TAND), a novel framework achieving joint nuclei detection and classification using point-level supervision enhanced by tissue mask conditioning. TAND couples a ConvNeXt-based encoder-decoder with a frozen Virchow-2 tissue segmentation branch, where semantic tissue probabilities selectively modulate the classification stream through a novel multi-scale Spatial Feature-wise Linear Modulation (Spatial-FiLM). On the PUMA benchmark, TAND achieves state-of-the-art performance, surpassing both tissue-agnostic baselines and mask-supervised methods. Notably, our approach demonstrates remarkable improvements in tissue-dependent cell types such as epithelium, endothelium, and stroma. To the best of our knowledge, this is the first method to condition per-cell classification on learned tissue masks, offering a practical pathway to reduce annotation burden.

</details>


### [285] [A Real-Time Driver Drowsiness Detection System Using MediaPipe and Eye Aspect Ratio](https://arxiv.org/abs/2511.13618)
*Ashlesha G. Sawant,Shreyash S. Kamble,Raj S. Kanade,Raunak N. Kanugo,Tanishq A. Kapse,Karan A. Bhapse*

Main category: cs.CV

TL;DR: 本文提出了一种基于网络摄像头和Eye Aspect Ratio（EAR）方法的驾驶员疲劳检测系统，利用MediaPipe的Face Mesh模型实时监测驾驶员眼部动作，通过声音警报提醒疲劳驾驶者，具有高精度、低成本和快速响应的特点。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是导致道路交通事故的主要原因之一，每年造成大量伤亡，因此需要一种高效且低成本的实时疲劳检测系统来提升道路安全。

Method: 系统采用标准网络摄像头捕捉驾驶员面部特征，使用MediaPipe的Face Mesh模型精确定位面部关键点，重点分析眼睛区域的EAR值变化，结合OpenCV进行图像处理，当检测到长时间闭眼或眨眼频率过低时触发声音警报。

Result: 实验结果表明该系统在检测驾驶员疲劳状态方面具有高准确率和快速响应能力，能够在实时环境下有效运行。

Conclusion: 该系统是一种高性能、低成本的驾驶员监控解决方案，可集成到现有的高级驾驶辅助系统（ADAS）中，有助于减少因疲劳驾驶引发的交通事故。

Abstract: One of the major causes of road accidents is driver fatigue that causes thousands of fatalities and injuries every year. This study shows development of a Driver Drowsiness Detection System meant to improve the safety of the road by alerting drivers who are showing signs of being drowsy. The system is based on a standard webcam that tracks the facial features of the driver with the main emphasis on the examination of eye movements that can be conducted with the help of the Eye Aspect Ratio (EAR) method. The Face Mesh by MediaPipe is a lightweight framework that can identify facial landmarks with high accuracy and efficiency, which is considered to be important in real time use. The system detects the moments of long eye shutdowns or a very low rate of blinking which are manifestations of drowsiness and alerts the driver through sound to get her attention back. This system achieves a high-performance and low-cost driver monitoring solution with the help of the computational power of OpenCV to process the image and the MediaPipe to identify faces. Test data experimental analyses indicate that the system is very accurate and responds quicker; this confirms that it can be a component of the current Advanced Driving Assistance System (ADAS).

</details>


### [286] [Alpha Divergence Losses for Biometric Verification](https://arxiv.org/abs/2511.13621)
*Dimitrios Koutsianos,Ladislav Mosner,Yannis Panagakis,Themos Stafylakis*

Main category: cs.CV

TL;DR: 本文提出了两种基于α-散度的新型带角度裕量的损失函数（Q-Margin和A3M），用于人脸识别与说话人验证，在低误接受率下显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于margin的softmax损失在人脸和说话人验证中表现优异，但α-散度损失虽能诱导稀疏解，却难以直接引入关键的角度裕量，本文旨在解决这一问题。

Method: 探索了将角度裕量融入α-散度损失的两种路径：通过参考测度或通过logits，提出Q-Margin和A3M两种新损失，并针对A3M训练不稳定性提出原型重初始化策略。

Result: 在IJB-B、IJB-C和VoxCeleb数据集上取得显著性能提升，尤其在低FAR下优于强基线模型。

Conclusion: 所提出的Q-Margin和A3M有效结合了α-散度与角度裕量，在高安全性应用场景中具有优势。

Abstract: Performance in face and speaker verification is largely driven by margin based softmax losses like CosFace and ArcFace. Recently introduced $α$-divergence loss functions offer a compelling alternative, particularly for their ability to induce sparse solutions (when $α>1$). However, integrating an angular margin-crucial for verification tasks-is not straightforward. We find this integration can be achieved in at least two distinct ways: via the reference measure (prior probabilities) or via the logits (unnormalized log-likelihoods). In this paper, we explore both pathways, deriving two novel margin-based $α$-divergence losses: Q-Margin (margin in the reference measure) and A3M (margin in the logits). We identify and address a critical training instability in A3M-caused by the interplay of penalized logits and sparsity-with a simple yet effective prototype re-initialization strategy. Our methods achieve significant performance gains on the challenging IJB-B and IJB-C face verification benchmarks. We demonstrate similarly strong performance in speaker verification on VoxCeleb. Crucially, our models significantly outperform strong baselines at low false acceptance rates (FAR). This capability is crucial for practical high-security applications, such as banking authentication, when minimizing false authentications is paramount.

</details>


### [287] [CacheFlow: Compressive Streaming Memory for Efficient Long-Form Video Understanding](https://arxiv.org/abs/2511.13644)
*Shrenik Patel,Daivik Patel*

Main category: cs.CV

TL;DR: 本文提出CacheFlow，一种无需训练的长视频问答处理流程，通过动态令牌丢弃和压缩长期记忆机制，实现高效且上下文感知的长视频理解。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理长视频问答时受限于注意力机制和KV缓存随时间增长的问题，导致推理成本高或只能使用短视的滑动窗口。

Method: 引入CacheFlow，结合动态令牌丢弃（DTD）和压缩式长期记忆。DTD通过余弦相似度在线剪枝每帧的patch令牌，并将剩余令牌打包成固定大小块；块的键由小型循环编码器汇总为检索索引，完整KV对则被卸载并在生成时重新加载。推理时采用基于共识的检索机制，仅检索最相关的Top-K块并与局部上下文联合注意力。

Result: 在离线和流式VQA基准测试上，CacheFlow优于现有强基线方法，同时减少最多87%的令牌处理量。

Conclusion: CacheFlow是一种即插即用、架构无关且无需微调的方法，使视觉语言模型在保持回答准确性的同时显著提升效率，推动了实际应用中的长视频理解。

Abstract: Long-form video question answering (VQA) overwhelms current vision-language models (VLMs) because attention and key-value (KV) caches grow with runtime, forcing either expensive inference or near-sighted sliding windows. We introduce CacheFlow, a training-free pipeline that pairs Dynamic Token Dropping (DTD) with a compressive long-term memory. DTD prunes per-patch tokens online via cosine similarity to the previous frame, and surviving tokens are packed into fixed-size blocks. This online, per-frame processing makes our approach fundamentally suited for live streaming VQA. As blocks are processed, each one's keys are summarized by a tiny recurrent encoder to form a retrieval index, while the block's full KV pairs are offloaded and later rehydrated for generation, preserving answer fidelity. At inference, a consensus-based retrieval mechanism retrieves only the Top-K most relevant blocks and attends over both the retrieved and local context for precise, long-range reasoning. CacheFlow is drop-in, architecture-agnostic, and requires no fine-tuning. Experiments on both offline and streaming VQA benchmarks demonstrate that CacheFlow outperforms current strong baselines, while processing up to 87% less tokens. Our dual approach enables VLMs to be both efficient and context-aware, paving the way for practical long-form video understanding.

</details>


### [288] [Part-X-MLLM: Part-aware 3D Multimodal Large Language Model](https://arxiv.org/abs/2511.13647)
*Chunshi Wang,Junliang Ye,Yunhan Yang,Yang Li,Zizhuo Lin,Jun Zhu,Zhuo Chen,Yawei Luo,Chunchao Guo*

Main category: cs.CV

TL;DR: 提出Part-X-MLLM，一种原生的3D多模态大语言模型，将多种3D任务统一为结构化可执行语法中的程序，通过自然语言提示生成包含部件级框、语义描述和编辑命令的连贯序列，实现高质量的符号规划与几何合成解耦。


<details>
  <summary>Details</summary>
Motivation: 现有的3D多模态模型通常针对特定任务设计，缺乏统一框架来处理多样化的3D任务，且难以实现细粒度的部件级理解与编辑。因此需要一个能统一各类3D任务并支持语言驱动的通用接口。

Method: 采用双编码器架构，分离结构与语义信息；在大规模部件中心数据集上进行指令微调；将3D任务建模为结构化语法中的程序生成，输出包含边界框、语义描述和编辑指令的连贯token序列，并与下游几何模块对接。

Result: 在接地问答、组合生成和局部编辑等任务上实现了最先进的性能，验证了其生成高质量结构化计划的能力。

Conclusion: Part-X-MLLM通过将3D任务统一为语言可控的程序生成，实现了灵活、可扩展的部件级3D内容理解与编辑，为语言驱动的3D交互提供了通用框架。

Abstract: We introduce Part-X-MLLM, a native 3D multimodal large language model that unifies diverse 3D tasks by formulating them as programs in a structured, executable grammar. Given an RGB point cloud and a natural language prompt, our model autoregressively generates a single, coherent token sequence encoding part-level bounding boxes, semantic descriptions, and edit commands. This structured output serves as a versatile interface to drive downstream geometry-aware modules for part-based generation and editing. By decoupling the symbolic planning from the geometric synthesis, our approach allows any compatible geometry engine to be controlled through a single, language-native frontend. We pre-train a dual-encoder architecture to disentangle structure from semantics and instruction-tune the model on a large-scale, part-centric dataset. Experiments demonstrate that our model excels at producing high-quality, structured plans, enabling state-of-the-art performance in grounded Q\&A, compositional generation, and localized editing through one unified interface. Project page: https://chunshi.wang/Part-X-MLLM/

</details>


### [289] [Distribution Matching Distillation Meets Reinforcement Learning](https://arxiv.org/abs/2511.13649)
*Dengyang Jiang,Dongyang Liu,Zanyi Wang,Qilong Wu,Xin Jin,David Liu,Zhen Li,Mengmeng Wang,Peng Gao,Harry Yang*

Main category: cs.CV

TL;DR: 提出DMDR框架，将强化学习引入扩散模型蒸馏过程，通过DMD损失作为正则化并结合动态训练策略，显著提升少步生成器性能，甚至超越多步教师模型。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏中，少步扩散模型性能受限于预训练的多步教师模型，难以突破其性能上限。

Method: 提出DMDR框架，将强化学习与分布匹配蒸馏（DMD）结合，利用DMD损失作为强化学习中的有效正则化，并设计动态分布引导和动态重加噪采样策略以优化初始蒸馏过程。

Result: 实验表明，DMDR在少步生成方法中实现了领先的视觉质量和提示一致性，性能甚至超过多步教师模型。

Conclusion: DMDR通过联合蒸馏与强化学习，有效释放了少步生成模型的潜力，为高效推理下的高质量生成提供了新思路。

Abstract: Distribution Matching Distillation (DMD) distills a pre-trained multi-step diffusion model to a few-step one to improve inference efficiency. However, the performance of the latter is often capped by the former. To circumvent this dilemma, we propose DMDR, a novel framework that combines Reinforcement Learning (RL) techniques into the distillation process. We show that for the RL of the few-step generator, the DMD loss itself is a more effective regularization compared to the traditional ones. In turn, RL can help to guide the mode coverage process in DMD more effectively. These allow us to unlock the capacity of the few-step generator by conducting distillation and RL simultaneously. Meanwhile, we design the dynamic distribution guidance and dynamic renoise sampling training strategies to improve the initial distillation process. The experiments demonstrate that DMDR can achieve leading visual quality, prompt coherence among few-step methods, and even exhibit performance that exceeds the multi-step teacher.

</details>


### [290] [OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation](https://arxiv.org/abs/2511.13655)
*Henry Herzog,Favyen Bastani,Yawen Zhang,Gabriel Tseng,Joseph Redmon,Hadrien Sablon,Ryan Park,Jacob Morrison,Alexandra Buraczynski,Karen Farley,Joshua Hansen,Andrew Howe,Patrick Alan Johnson,Mark Otterlee,Ted Schmitt,Hunter Pitelka,Stephen Daspit,Rachel Ratner,Christopher Wilhelm,Sebastian Wood,Mike Jacobi,Hannah Kerner,Evan Shelhamer,Ali Farhadi,Ranjay Krishna,Patrick Beukema*

Main category: cs.CV

TL;DR: OlmoEarth是一个针对地球观测数据的多模态时空基础模型，采用新颖的自监督学习方法，在多种基准和实际任务中表现优异，并已开源。


<details>
  <summary>Details</summary>
Motivation: 地球观测数据具有空间性、时序性和多模态性，现有模型难以有效处理这一独特挑战。

Method: 提出OlmoEarth模型，结合新的自监督学习框架、掩码策略和损失函数，专为地球观测领域设计。

Result: 在24个任务中的15个取得最佳嵌入性能，29个微调任务中在19个上表现最优，超越12个其他基础模型。

Conclusion: OlmoEarth在地球观测领域实现了最先进的性能，并通过开放平台支持非营利组织解决全球重大问题。

Abstract: Earth observation data presents a unique challenge: it is spatial like images, sequential like video or text, and highly multimodal. We present OlmoEarth: a multimodal, spatio-temporal foundation model that employs a novel self-supervised learning formulation, masking strategy, and loss all designed for the Earth observation domain. OlmoEarth achieves state-of-the-art performance compared to 12 other foundation models across a variety of research benchmarks and real-world tasks from external partners. When evaluating embeddings OlmoEarth achieves the best performance on 15 out of 24 tasks, and with full fine-tuning it is the best on 19 of 29 tasks. We deploy OlmoEarth as the backbone of an end-to-end platform for data collection, labeling, training, and inference of Earth observation models. The OlmoEarth Platform puts frontier foundation models and powerful data management tools into the hands of non-profits and NGOs working to solve the world's biggest problems. OlmoEarth source code, training data, and pre-trained weights are available at $\href{https://github.com/allenai/olmoearth_pretrain}{\text{https://github.com/allenai/olmoearth_pretrain}}$.

</details>


### [291] [Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting](https://arxiv.org/abs/2511.13684)
*Jiangnan Ye,Jiedong Zhuang,Lianrui Mu,Wenjie Zheng,Jiaqi Hu,Xingze Zou,Jing Wang,Haoji Hu*

Main category: cs.CV

TL;DR: GS-Light是一种基于高斯点阵的文本位置感知3D场景重光照方法，利用扩散模型和多视图输入实现高质量、符合用户意图的重光照。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本引导的3D场景重光照中难以准确理解光照方向与语义意图，且多视图一致性不足。

Method: 提出GS-Light，结合大视觉语言模型解析文本提示为光照先验，融合深度、法线和语义分割等几何信息生成初始隐变量，指导预训练扩散模型进行多视图重光照，并微调3DGS场景以获得最终结果。

Result: 在室内外场景上优于现有方法，在多视图一致性、图像质量、美学评分和语义相似性等指标上均有提升，用户研究也验证了其优越性。

Conclusion: GS-Light实现了高效、无需训练的多视图文本引导重光照，显著提升了光照控制精度与视觉保真度。

Abstract: We introduce GS-Light, an efficient, textual position-aware pipeline for text-guided relighting of 3D scenes represented via Gaussian Splatting (3DGS). GS-Light implements a training-free extension of a single-input diffusion model to handle multi-view inputs. Given a user prompt that may specify lighting direction, color, intensity, or reference objects, we employ a large vision-language model (LVLM) to parse the prompt into lighting priors. Using off-the-shelf estimators for geometry and semantics (depth, surface normals, and semantic segmentation), we fuse these lighting priors with view-geometry constraints to compute illumination maps and generate initial latent codes for each view. These meticulously derived init latents guide the diffusion model to generate relighting outputs that more accurately reflect user expectations, especially in terms of lighting direction. By feeding multi-view rendered images, along with the init latents, into our multi-view relighting model, we produce high-fidelity, artistically relit images. Finally, we fine-tune the 3DGS scene with the relit appearance to obtain a fully relit 3D scene. We evaluate GS-Light on both indoor and outdoor scenes, comparing it to state-of-the-art baselines including per-view relighting, video relighting, and scene editing methods. Using quantitative metrics (multi-view consistency, imaging quality, aesthetic score, semantic similarity, etc.) and qualitative assessment (user studies), GS-Light demonstrates consistent improvements over baselines. Code and assets will be made available upon publication.

</details>


### [292] [TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models](https://arxiv.org/abs/2511.13704)
*Harold Haodong Chen,Disen Lan,Wen-Jie Shu,Qingyang Liu,Zihan Wang,Sirui Chen,Wenkai Cheng,Kanghao Chen,Hongfei Zhang,Zixin Zhang,Rongjin Guo,Yu Cheng,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 本文提出了TiViBench，一个用于评估图像到视频生成模型推理能力的分层基准，并引入VideoTPO方法在测试时提升模型推理表现。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型评估主要关注视觉质量和时间连贯性，缺乏对高阶推理能力的衡量，因此需要新的基准来评估模型在物理合理性和逻辑一致性方面的推理能力。

Method: 设计了一个包含四个维度（结构推理、空间与视觉模式推理、符号与逻辑推理、动作规划与任务执行）的分层基准TiViBench，并提出VideoTPO策略，利用大语言模型对生成结果进行自我分析以优化输出。

Result: 实验表明商业模型（如Sora 2、Veo 3.1）具有更强的推理潜力，开源模型受限于训练规模和数据多样性；VideoTPO能显著提升推理性能且无需额外训练或奖励模型。

Conclusion: TiViBench填补了视频生成模型推理能力评估的空白，VideoTPO为提升模型推理提供了有效的新路径，共同推动该领域的发展。

Abstract: The rapid evolution of video generative models has shifted their focus from producing visually plausible outputs to tackling tasks requiring physical plausibility and logical consistency. However, despite recent breakthroughs such as Veo 3's chain-of-frames reasoning, it remains unclear whether these models can exhibit reasoning capabilities similar to large language models (LLMs). Existing benchmarks predominantly evaluate visual fidelity and temporal coherence, failing to capture higher-order reasoning abilities. To bridge this gap, we propose TiViBench, a hierarchical benchmark specifically designed to evaluate the reasoning capabilities of image-to-video (I2V) generation models. TiViBench systematically assesses reasoning across four dimensions: i) Structural Reasoning & Search, ii) Spatial & Visual Pattern Reasoning, iii) Symbolic & Logical Reasoning, and iv) Action Planning & Task Execution, spanning 24 diverse task scenarios across 3 difficulty levels. Through extensive evaluations, we show that commercial models (e.g., Sora 2, Veo 3.1) demonstrate stronger reasoning potential, while open-source models reveal untapped potential that remains hindered by limited training scale and data diversity. To further unlock this potential, we introduce VideoTPO, a simple yet effective test-time strategy inspired by preference optimization. By performing LLM self-analysis on generated candidates to identify strengths and weaknesses, VideoTPO significantly enhances reasoning performance without requiring additional training, data, or reward models. Together, TiViBench and VideoTPO pave the way for evaluating and advancing reasoning in video generation models, setting a foundation for future research in this emerging field.

</details>


### [293] [Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine](https://arxiv.org/abs/2511.13713)
*Xincheng Shuai,Zhenyuan Qin,Henghui Ding,Dacheng Tao*

Main category: cs.CV

TL;DR: 本文提出了一种3D感知的自回归框架FFSE，用于在真实图像上进行直观且物理一致的对象编辑，通过学习3D变换序列实现平移、缩放和旋转等操作，同时保持背景效果和场景一致性，并引入了用于多轮编辑训练的混合数据集3DObjectEditor。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在3D感知对象操作方面存在不足，且多数方法在图像空间操作或依赖缓慢且易出错的3D重建过程，难以实现真实感和一致性编辑。

Method: 提出FFSE框架，将编辑建模为一系列学习到的3D变换，支持在无需显式3D重建的情况下进行3D感知编辑；构建3DObjectEditor混合数据集，包含模拟的多轮编辑序列，用于训练模型在动态和多轮条件下的编辑能力。

Result: 实验表明，FFSE在单轮和多轮3D感知编辑任务中均显著优于现有方法，能够更好地保持阴影、反射等真实背景效果，并维持多次编辑后的全局场景一致性。

Conclusion: FFSE提供了一种高效、直观且无需复杂3D重建的3D-aware图像编辑方案，通过自回归建模和专用数据集实现了高质量、多轮次的对象操作，推动了现实图像上语义编辑的发展。

Abstract: Recent advances in text-to-image (T2I) diffusion models have significantly improved semantic image editing, yet most methods fall short in performing 3D-aware object manipulation. In this work, we present FFSE, a 3D-aware autoregressive framework designed to enable intuitive, physically-consistent object editing directly on real-world images. Unlike previous approaches that either operate in image space or require slow and error-prone 3D reconstruction, FFSE models editing as a sequence of learned 3D transformations, allowing users to perform arbitrary manipulations, such as translation, scaling, and rotation, while preserving realistic background effects (e.g., shadows, reflections) and maintaining global scene consistency across multiple editing rounds. To support learning of multi-round 3D-aware object manipulation, we introduce 3DObjectEditor, a hybrid dataset constructed from simulated editing sequences across diverse objects and scenes, enabling effective training under multi-round and dynamic conditions. Extensive experiments show that the proposed FFSE significantly outperforms existing methods in both single-round and multi-round 3D-aware editing scenarios.

</details>


### [294] [UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity](https://arxiv.org/abs/2511.13714)
*Junwei Yu,Trevor Darrell,XuDong Wang*

Main category: cs.CV

TL;DR: 本文提出了UnSAMv2，一种无需人工标注即可实现任意粒度分割的方法，通过自监督学习和新颖的粒度控制嵌入显著提升了SAM-2在多种任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的SAM模型在分割粒度控制方面能力有限，用户需要手动调整提示或选择预生成掩码来获得所需细节，且密集标注成本高昂，难以进行监督训练。

Method: UnSAMv2扩展了UnSAM的分治策略，利用6K无标签图像发现大量掩码-粒度对，并引入新的粒度控制嵌入，实现对分割尺度的精确连续控制，采用粒度感知的自监督学习方法。

Result: 在11个以上基准测试中，UnSAMv2显著提升性能：NoC_90从5.69降至4.75，1-IoU从58.0提升至73.1，AR_1000从49.6提升至68.3。

Conclusion: 少量无标签数据结合粒度感知的自监督学习可有效释放视觉基础模型在多粒度分割上的潜力。

Abstract: The Segment Anything Model (SAM) family has become a widely adopted vision foundation model, but its ability to control segmentation granularity remains limited. Users often need to refine results manually - by adding more prompts or selecting from pre-generated masks - to achieve the desired level of detail. This process can be ambiguous, as the same prompt may correspond to several plausible masks, and collecting dense annotations across all granularities is prohibitively expensive, making supervised solutions infeasible. To address this limitation, we introduce UnSAMv2, which enables segment anything at any granularity without human annotations. UnSAMv2 extends the divide-and-conquer strategy of UnSAM by discovering abundant mask-granularity pairs and introducing a novel granularity control embedding that enables precise, continuous control over segmentation scale. Remarkably, with only $6$K unlabeled images and $0.02\%$ additional parameters, UnSAMv2 substantially enhances SAM-2, achieving segment anything at any granularity across interactive, whole-image, and video segmentation tasks. Evaluated on over $11$ benchmarks, UnSAMv2 improves $\text{NoC}_{90}$ (5.69 $\rightarrow$ 4.75), 1-IoU (58.0 $\rightarrow$ 73.1), and $\text{AR}_{1000}$ (49.6 $\rightarrow$ 68.3), showing that small amounts of unlabeled data with a granularity-aware self-supervised learning method can unlock the potential of vision foundation models.

</details>


### [295] [Segment Anything Across Shots: A Method and Benchmark](https://arxiv.org/abs/2511.13715)
*Hengrui Hu,Kaining Ying,Henghui Ding*

Main category: cs.CV

TL;DR: 提出了一种用于多镜头视频对象分割（MVOS）的过渡模拟数据增强策略（TMA）和跨镜头分割模型（SAAS），并构建了新的基准Cut-VOS，实现了在复杂镜头过渡下的先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象分割方法主要针对单镜头视频，在处理多镜头视频中的镜头间断时表现不佳，限制了其实际应用。同时，标注的多镜头数据稀疏，缺乏合适的基准。

Method: 提出过渡模拟数据增强（TMA），利用单镜头数据模拟多镜头过渡以提升泛化能力；设计SAAS模型，有效检测和理解镜头过渡；构建包含密集标注、多样类别和高频过渡的新基准Cut-VOS。

Result: 在YouMVOS和Cut-VOS数据集上实验表明，SAAS在跨镜头分割任务中达到最先进水平，能有效应对复杂过渡场景。

Conclusion: TMA和SAAS显著提升了多镜头视频对象分割的性能，Cut-VOS为未来研究提供了重要支持，推动VOS在真实多镜头场景中的应用。

Abstract: This work focuses on multi-shot semi-supervised video object segmentation (MVOS), which aims at segmenting the target object indicated by an initial mask throughout a video with multiple shots. The existing VOS methods mainly focus on single-shot videos and struggle with shot discontinuities, thereby limiting their real-world applicability. We propose a transition mimicking data augmentation strategy (TMA) which enables cross-shot generalization with single-shot data to alleviate the severe annotated multi-shot data sparsity, and the Segment Anything Across Shots (SAAS) model, which can detect and comprehend shot transitions effectively. To support evaluation and future study in MVOS, we introduce Cut-VOS, a new MVOS benchmark with dense mask annotations, diverse object categories, and high-frequency transitions. Extensive experiments on YouMVOS and Cut-VOS demonstrate that the proposed SAAS achieves state-of-the-art performance by effectively mimicking, understanding, and segmenting across complex transitions. The code and datasets are released at https://henghuiding.com/SAAS/.

</details>


### [296] [Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/abs/2511.13720)
*Tianhong Li,Kaiming He*

Main category: cs.CV

TL;DR: 本文提出了一种直接预测干净数据的扩散模型方法（JiT），基于流形假设，使用大块Transformer在像素级别上进行生成，无需分词、预训练或额外损失，在ImageNet高分辨率任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型通常预测噪声而非干净数据，违背了自然数据应位于低维流形上的假设。作者认为直接预测干净数据更为合理且有效。

Method: 提出Just image Transformers（JiT）方法，使用大patch大小的Transformer直接在原始像素上预测干净图像，不引入分词器、预训练或额外损失函数。

Result: 在ImageNet 256和512分辨率下，使用16和32的大patch取得了具有竞争力的结果，尤其在高维噪声预测易失败的情况下表现优异。

Conclusion: 直接预测干净数据符合流形假设，能使容量看似不足的网络在高维空间中有效工作，JiT提供了一种自包含、回归本质的Transformer-based扩散模型范式。

Abstract: Today's denoising diffusion models do not "denoise" in the classical sense, i.e., they do not directly predict clean images. Rather, the neural networks predict noise or a noised quantity. In this paper, we suggest that predicting clean data and predicting noised quantities are fundamentally different. According to the manifold assumption, natural data should lie on a low-dimensional manifold, whereas noised quantities do not. With this assumption, we advocate for models that directly predict clean data, which allows apparently under-capacity networks to operate effectively in very high-dimensional spaces. We show that simple, large-patch Transformers on pixels can be strong generative models: using no tokenizer, no pre-training, and no extra loss. Our approach is conceptually nothing more than "$\textbf{Just image Transformers}$", or $\textbf{JiT}$, as we call it. We report competitive results using JiT with large patch sizes of 16 and 32 on ImageNet at resolutions of 256 and 512, where predicting high-dimensional noised quantities can fail catastrophically. With our networks mapping back to the basics of the manifold, our research goes back to basics and pursues a self-contained paradigm for Transformer-based diffusion on raw natural data.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [297] [TimeStampEval: A Simple LLM Eval and a Little Fuzzy Matching Trick to Improve Search Accuracy](https://arxiv.org/abs/2511.11594)
*James McCammon*

Main category: cs.CL

TL;DR: TimeStampEval 是一个用于从长篇转录文本中根据非逐字引文检索精确毫秒时间戳的基准，提出结合 RapidFuzz 预筛选和 LLM 验证的两阶段方法，在提高准确率的同时显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 解决官方书面记录与语音转录文本之间因句法差异导致的传统模糊匹配失效问题，特别是在自动生成整合国会记录片段的播客中的应用需求。

Method: 采用两阶段“辅助模糊”方法：首先使用 RapidFuzz 进行预过滤，然后在短片段上用大语言模型（LLM）进行验证；优化提示设计，将查询置于文本前并采用紧凑格式以提升效率。

Result: 在2800句（12万token）的转录本上评估显示，提示设计比模型选择更重要，准确性提升3-20点，token减少30-40%；加入适度推理预算后准确率从37%提升至90%以上；该方法使模糊匹配准确率最高提升50点，延迟减半，单位正确结果成本降低达96%；在10个不同长度和领域的转录本上保持95-100%的负例拒绝准确率。

Conclusion: TimeStampEval 基准表明，通过合理的提示工程和两阶段“辅助模糊”策略，可在大幅降低成本的同时实现高精度时间戳检索，且对不同长度、词汇漂移和领域变化具有鲁棒性。

Abstract: Traditional fuzzy matching often fails when searching for quotes that are semantically identical but syntactically different across documents-a common issue when aligning official written records with speech-to-text transcripts. We introduce TimeStampEval, a benchmark for retrieving precise millisecond timestamps from long transcripts given non-verbatim quotes. Our simple two-stage method dramatically improves retrieval accuracy while cutting inference costs by over 90%. The motivating use case is an automated long-form podcast that assembles Congressional Record clips into AI-hosted narration. The technical challenge: given a sentence-timestamped transcript and a target quote that may differ due to transcription or editorial drift, return exact start and end boundaries. Standard algorithms handle verbatim text but break under fuzzier variants. Evaluating six modern LLMs on a 2,800-sentence (120k-token) transcript revealed four key findings. (1) Prompt design matters more than model choice: placing the query before the transcript and using compact formatting improved accuracy by 3-20 points while reducing token count by 30-40%. (2) Off-by-one errors form a distinct category, showing models understand the task but misplace boundaries. (3) A modest reasoning budget (600-850 tokens) raises accuracy from 37% to 77% for weak setups and to above 90% for strong ones. (4) Our "Assisted Fuzzy" approach-RapidFuzz pre-filtering followed by LLM verification on short snippets-improves fuzzy match accuracy by up to 50 points while halving latency and reducing cost per correct result by up to 96%. Extended tests on ten transcripts (50k-900k tokens, 1989-2025) confirm robustness to transcript length, vocabulary drift, and domain change, maintaining 95-100% rejection accuracy for absent targets.

</details>


### [298] [MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling](https://arxiv.org/abs/2511.11793)
*MiroMind Team,Song Bai,Lidong Bing,Carson Chen,Guanzheng Chen,Yuntao Chen,Zhe Chen,Ziyi Chen,Jifeng Dai,Xuan Dong,Yue Deng,Yunjie Fu,Junqi Ge,Chenxia Han,Tammy Huang,Zhenhang Huang,Jerry Jiao,Shilei Jiang,Tianyu Jiao,Xiaoqi Jian,Lei Lei,Ruilin Li,Ryan Luo,Tiantong Li,Xiang Lin,Ziyuan Liu,Zhiqi Li,Jie Ni,Qiang Ren,Pax Sun,Shiqian Su,Chenxin Tao,Bin Wang,Hellen Wang,Haonan Wang,James Wang,Jin Wang,Jojo Wang,Letian Wang,Shizun Wang,Weizhi Wang,Zixuan Wang,Jinfan Xu,Sen Xing,Chenyu Yang,Hai Ye,Jiaheng Yu,Yue Yu,Muyan Zhong,Tianchen Zhao,Xizhou Zhu,Yanpeng Zhou,Yifan Zhang,Zhi Zhu*

Main category: cs.CL

TL;DR: MiroThinker v1.0 是一种开源研究代理，通过模型级的交互扩展（interaction scaling）提升工具增强推理和信息检索能力，支持深度且频繁的代理-环境交互，在多个基准测试中表现优异，接近商业模型如 GPT-5-high 的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究代理主要依赖扩大模型规模或上下文长度，但在长推理链中易出现性能退化；MiroThinker 旨在探索交互扩展作为提升性能的第三维度，利用环境反馈和外部信息纠正错误、优化推理路径。

Method: 通过强化学习训练模型，在 256K 上下文窗口内支持最多 600 次工具调用，实现多轮持续推理；系统性地增加代理与环境的交互深度和频率，以提升复杂任务处理能力。

Result: 在 GAIA、HLE、BrowseComp 和 BrowseComp-ZH 四个基准上，72B 版本分别达到 81.9%、37.7%、47.1% 和 55.6% 的准确率，超越此前开源代理并接近 GPT-5-high 等商业模型。

Conclusion: 交互扩展是构建下一代开源研究代理的关键维度，其效果可与模型规模和上下文长度扩展相媲美，为未来智能代理设计提供了新方向。

Abstract: We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or context length, MiroThinker explores interaction scaling at the model level, systematically training the model to handle deeper and more frequent agent-environment interactions as a third dimension of performance improvement. Unlike LLM test-time scaling, which operates in isolation and risks degradation with longer reasoning chains, interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories. Through reinforcement learning, the model achieves efficient interaction scaling: with a 256K context window, it can perform up to 600 tool calls per task, enabling sustained multi-turn reasoning and complex real-world research workflows. Across four representative benchmarks-GAIA, HLE, BrowseComp, and BrowseComp-ZH-the 72B variant achieves up to 81.9%, 37.7%, 47.1%, and 55.6% accuracy respectively, surpassing previous open-source agents and approaching commercial counterparts such as GPT-5-high. Our analysis reveals that MiroThinker benefits from interactive scaling consistently: research performance improves predictably as the model engages in deeper and more frequent agent-environment interactions, demonstrating that interaction depth exhibits scaling behaviors analogous to model size and context length. These findings establish interaction scaling as a third critical dimension for building next-generation open research agents, complementing model capacity and context windows.

</details>


### [299] [On the Notion that Language Models Reason](https://arxiv.org/abs/2511.11810)
*Bertram Højer*

Main category: cs.CL

TL;DR: 本文探讨了语言模型是否真正具备推理能力，提出其所谓的“推理”输出实际上是统计规律的体现，而非真正的逻辑机制，强调语言模型是“统计模式匹配器”而非真正的推理者。


<details>
  <summary>Details</summary>
Motivation: 澄清语言模型在生成类推理输出时的本质，挑战当前对模型推理能力的误解，并重新审视NLP领域中对推理的定义与实际训练机制之间的不一致。

Method: 通过将基于Transformer的语言模型视为实现隐式有限阶马尔可夫核的系统，分析其生成过程中的统计规律性和不变性，论证其输出为统计模式的结果。

Result: 表明语言模型的推理样输出源于训练数据中的统计相关性，缺乏逻辑一致性保证，支持‘语言模型是统计模式匹配器’的观点。

Conclusion: 应谨慎使用‘推理’一词描述语言模型行为，需更精确地描述其计算过程，以促进NLP领域对模型能力的准确理解。

Abstract: Language models (LMs) are said to be exhibiting reasoning, but what does this entail? We assess definitions of reasoning and how key papers in the field of natural language processing (NLP) use the notion and argue that the definitions provided are not consistent with how LMs are trained, process information, and generate new tokens. To illustrate this incommensurability we assume the view that transformer-based LMs implement an \textit{implicit} finite-order Markov kernel mapping contexts to conditional token distributions. In this view, reasoning-like outputs correspond to statistical regularities and approximate statistical invariances in the learned kernel rather than the implementation of explicit logical mechanisms. This view is illustrative of the claim that LMs are "statistical pattern matchers"" and not genuine reasoners and provides a perspective that clarifies why reasoning-like outputs arise in LMs without any guarantees of logical consistency. This distinction is fundamental to how epistemic uncertainty is evaluated in LMs. We invite a discussion on the importance of how the computational processes of the systems we build and analyze in NLP research are described.

</details>


### [300] [Scaling Open-Weight Large Language Models for Hydropower Regulatory Information Extraction: A Systematic Analysis](https://arxiv.org/abs/2511.11821)
*Hong-Jun Yoon,Faisal Ashraf,Thomas A. Ruggles,Debjani Singh*

Main category: cs.CL

TL;DR: 本研究评估了七种开源大语言模型在水电许可文件信息提取中的性能，发现140亿参数是有效提取的阈值，为监管文档中的模型选择提供了实证依据。


<details>
  <summary>Details</summary>
Motivation: 在监管文档中使用大语言模型进行信息提取面临性能与计算资源之间的权衡，亟需实证研究指导实际部署。

Method: 评估了七种不同规模（0.6B-70B参数）的开源模型在水电许可文档上的表现，分析其F1分数、召回率及幻觉模式。

Result: 14B参数模型是性能跃升的关键阈值；小型模型F1低于0.15，14B模型达0.64，大型模型接近0.77但需企业级资源；消费者可部署模型达到64% F1，小型模型上限为51%；发现小型模型存在系统性幻觉，完美召回反而指示提取失败。

Conclusion: 提出了首个针对监管场景下开源模型资源与性能的映射关系，支持基于证据的模型选择，结果对水电合规具有直接应用价值，并揭示了参数规模对信息提取任务的普遍影响。

Abstract: Information extraction from regulatory documents using large language models presents critical trade-offs between performance and computational resources. We evaluated seven open-weight models (0.6B-70B parameters) on hydropower licensing documentation to provide empirical deployment guidance.
  Our analysis identified a pronounced 14B parameter threshold where validation methods transition from ineffective (F1 $<$ 0.15) to viable (F1 = 0.64). Consumer-deployable models achieve 64\% F1 through appropriate validation, while smaller models plateau at 51\%. Large-scale models approach 77\% F1 but require enterprise infrastructure.
  We identified systematic hallucination patterns where perfect recall indicates extraction failure rather than success in smaller models. Our findings establish the first comprehensive resource-performance mapping for open-weight information extraction in regulatory contexts, enabling evidence-based model selection.
  These results provide immediate value for hydropower compliance while contributing insights into parameter scaling effects that generalize across information extraction tasks.

</details>


### [301] [Towards Autoformalization of LLM-generated Outputs for Requirement Verification](https://arxiv.org/abs/2511.11829)
*Mihir Gupte,Ramesh S*

Main category: cs.CL

TL;DR: 本文探讨了利用基于大语言模型（LLM）的简单自动形式化工具来验证LLM生成输出的准确性，通过两个实验展示了其在识别自然语言需求间逻辑等价性和检测逻辑不一致性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏验证大语言模型生成的结构化输出（如Gherkin场景）准确性的形式化方法，本文旨在探索自动形式化技术在此领域的应用潜力。

Method: 采用一个简单的基于LLM的自动形式化器，将自然语言需求转化为形式逻辑，并对比分析其与LLM生成输出之间的逻辑一致性。

Result: 实验表明，该自动形式化器能识别出不同表述但逻辑等价的自然语言需求，并能发现自然语言需求与LLM生成输出之间的逻辑矛盾。

Conclusion: 自动形式化技术在确保LLM生成内容的保真度和逻辑一致性方面具有显著潜力，为未来更深入的研究奠定了基础。

Abstract: Autoformalization, the process of translating informal statements into formal logic, has gained renewed interest with the emergence of powerful Large Language Models (LLMs). While LLMs show promise in generating structured outputs from natural language (NL), such as Gherkin Scenarios from NL feature requirements, there's currently no formal method to verify if these outputs are accurate. This paper takes a preliminary step toward addressing this gap by exploring the use of a simple LLM-based autoformalizer to verify LLM-generated outputs against a small set of natural language requirements. We conducted two distinct experiments. In the first one, the autoformalizer successfully identified that two differently-worded NL requirements were logically equivalent, demonstrating the pipeline's potential for consistency checks. In the second, the autoformalizer was used to identify a logical inconsistency between a given NL requirement and an LLM-generated output, highlighting its utility as a formal verification tool. Our findings, while limited, suggest that autoformalization holds significant potential for ensuring the fidelity and logical consistency of LLM-generated outputs, laying a crucial foundation for future, more extensive studies into this novel application.

</details>


### [302] [Three Stage Narrative Analysis; Plot-Sentiment Breakdown, Structure Learning and Concept Detection](https://arxiv.org/abs/2511.11857)
*Taimur Khan,Ramoza Ahsan,Mohib Hameed*

Main category: cs.CL

TL;DR: 提出了一种分析电影剧本情感弧并结合角色上下文进行扩展分析的框架，利用基于NRC-VAD的自定义词典进行情感分析，并通过Wards层次聚类对相似情感曲线进行聚类，实验证明该方法有助于用户选择故事。


<details>
  <summary>Details</summary>
Motivation: 叙事理解与分析在自然语言理解中具有挑战性，需要深度语义表示与自动化分析方法来处理大量叙事数据。

Method: 构建基于Valence, Arousal, Dominance评分的自定义情感词典，使用LabMTsimple模块进行字典式情感分析，并采用Wards层次聚类技术对情感曲线进行聚类。

Result: 在电影数据集上的实验表明，该框架能有效提取叙事中的高低层次概念，并生成有助于读者选择故事的情感分析结果。

Conclusion: 所提出的框架能够有效支持自动化叙事分析，提升用户对故事情感结构的理解和选择能力。

Abstract: Story understanding and analysis have long been challenging areas within Natural Language Understanding. Automated narrative analysis requires deep computational semantic representations along with syntactic processing. Moreover, the large volume of narrative data demands automated semantic analysis and computational learning rather than manual analytical approaches. In this paper, we propose a framework that analyzes the sentiment arcs of movie scripts and performs extended analysis related to the context of the characters involved. The framework enables the extraction of high-level and low-level concepts conveyed through the narrative. Using dictionary-based sentiment analysis, our approach applies a custom lexicon built with the LabMTsimple storylab module. The custom lexicon is based on the Valence, Arousal, and Dominance scores from the NRC-VAD dataset. Furthermore, the framework advances the analysis by clustering similar sentiment plots using Wards hierarchical clustering technique. Experimental evaluation on a movie dataset shows that the resulting analysis is helpful to consumers and readers when selecting a narrative or story.

</details>


### [303] [Identifying Imaging Follow-Up in Radiology Reports: A Comparative Analysis of Traditional ML and LLM Approaches](https://arxiv.org/abs/2511.11867)
*Namu Park,Giridhar Kaushik Ramachandran,Kevin Lybarger,Fei Xia,Ozlem Uzuner,Meliha Yetisgen,Martin Gunn*

Main category: cs.CL

TL;DR: 本文介绍了一个包含6,393份放射学报告的标注语料库，用于评估大语言模型在随访成像检测任务中的表现，并比较了传统机器学习方法与生成式大模型（如GPT-4o和GPT-OSS-20B）的性能，发现优化提示后的大模型接近人类标注一致性，但传统模型仍具竞争力。


<details>
  <summary>Details</summary>
Motivation: 缺乏针对放射学任务的领域专用数据集来严格评估大语言模型在临床自然语言处理中的表现。

Method: 构建一个6,393份放射科报告的标注语料库，标注每例是否需要随访成像；比较逻辑回归、SVM、Longformer、微调Llama3-8B-Instruct与生成式大模型（GPT-4o、GPT-OSS-20B）在基础和任务优化两种配置下的表现，使用精确率、召回率和F1分数评估，通过非参数自助法计算95%置信区间。

Result: GPT-4o（Advanced）表现最佳（F1 = 0.832），GPT-OSS-20B（Advanced）紧随其后（F1 = 0.828），逻辑回归和SVM也表现良好（F1分别为0.776和0.775），人工标注者间F1为0.846。

Conclusion: 通过提示优化，生成式大模型在随访检测任务上接近人类一致水平，但可解释且资源高效的传统模型仍是重要基准。

Abstract: Large language models (LLMs) have shown considerable promise in clinical natural language processing, yet few domain-specific datasets exist to rigorously evaluate their performance on radiology tasks. In this work, we introduce an annotated corpus of 6,393 radiology reports from 586 patients, each labeled for follow-up imaging status, to support the development and benchmarking of follow-up adherence detection systems. Using this corpus, we systematically compared traditional machine-learning classifiers, including logistic regression (LR), support vector machines (SVM), Longformer, and a fully fine-tuned Llama3-8B-Instruct, with recent generative LLMs. To evaluate generative LLMs, we tested GPT-4o and the open-source GPT-OSS-20B under two configurations: a baseline (Base) and a task-optimized (Advanced) setting that focused inputs on metadata, recommendation sentences, and their surrounding context. A refined prompt for GPT-OSS-20B further improved reasoning accuracy. Performance was assessed using precision, recall, and F1 scores with 95% confidence intervals estimated via non-parametric bootstrapping. Inter-annotator agreement was high (F1 = 0.846). GPT-4o (Advanced) achieved the best performance (F1 = 0.832), followed closely by GPT-OSS-20B (Advanced; F1 = 0.828). LR and SVM also performed strongly (F1 = 0.776 and 0.775), underscoring that while LLMs approach human-level agreement through prompt optimization, interpretable and resource-efficient models remain valuable baselines.

</details>


### [304] [MedPT: A Massive Medical Question Answering Dataset for Brazilian-Portuguese Speakers](https://arxiv.org/abs/2511.11878)
*Fernanda Bufon Färber,Iago Alves Brito,Julia Soares Dollis,Pedro Schindler Freire Brasil Ribeiro,Rafael Teixeira Sousa,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: 本文介绍了MedPT，首个大规模真实世界巴西葡萄牙语医疗问答语料库，包含38.4万对患者-医生互动数据，经过多阶段清洗和LLM增强标注，支持细粒度意图分类与医学专科路由任务，展现出丰富的语义深度与文化特异性，旨在推动葡语医疗AI的公平性与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在医疗领域的发展主要集中于高资源语言，而直接翻译无法捕捉如地方性疾病等临床与文化细微差异，导致低资源语言面临重大障碍，因此需要构建具有文化与临床相关性的本土化医疗语料库。

Method: 构建了包含384,095个真实患者-医生问答对的MedPT语料库，采用多阶段定量与定性结合的清洗流程，并通过大模型驱动的注释对问题进行七类语义分类，以捕捉用户意图；同时分析其主题广度与语言特性，并在20类医学专科路由任务中对17亿参数模型进行微调评估。

Result: 该语料库覆盖3,200个主题，展现出患者与医生交流中的自然不对称性等独特语言特征；在专科路由任务中达到94%的F1分数，错误分析显示误分类主要源于真实的临床模糊性（如共病情况），反映数据集的深层语义复杂性。

Conclusion: MedPT是首个面向巴西葡萄牙语的大规模真实医疗对话数据集，具备高质量与语义丰富性，能有效支持文化适配的医疗AI开发，作者已公开发布该数据集，以促进葡语世界更公平、准确和文化敏感的医疗技术发展。

Abstract: While large language models (LLMs) show transformative potential in healthcare, their development remains focused on high-resource languages, creating a critical barrier for others as simple translation fails to capture unique clinical and cultural nuances, such as endemic diseases. To address this, we introduce MedPT, the first large-scale, real-world corpus for Brazilian Portuguese, comprising 384,095 authentic question-answer pairs from patient-doctor interactions. The dataset underwent a meticulous multi-stage curation protocol, using a hybrid quantitative-qualitative analysis to filter noise and contextually enrich thousands of ambiguous queries. We further augmented the corpus via LLM-driven annotation, classifying questions into seven semantic types to capture user intent. Our analysis reveals its thematic breadth (3,200 topics) and unique linguistic properties, like the natural asymmetry in patient-doctor communication. To validate its utility, we benchmark a medical specialty routing task: fine-tuning a 1.7B parameter model achieves an outstanding 94\% F1-score on a 20-class setup. Furthermore, our qualitative error analysis shows misclassifications are not random but reflect genuine clinical ambiguities (e.g., between comorbid conditions), proving the dataset's deep semantic richness. We publicly release MedPT to foster the development of more equitable, accurate, and culturally-aware medical technologies for the Portuguese-speaking world.

</details>


### [305] [ClinStructor: AI-Powered Structuring of Unstructured Clinical Texts](https://arxiv.org/abs/2511.11883)
*Karthikeyan K,Raghuveer Thirukovalluru,David Carlson*

Main category: cs.CL

TL;DR: 提出了一种名为ClinStructor的管道，利用大语言模型将临床自由文本转换为结构化的任务特定问答对，以提高机器学习模型在临床环境中的可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决临床笔记中非结构化格式带来的偏见、跨系统泛化性差和模型不可解释等问题。

Method: 使用大语言模型（LLMs）将临床自由文本转化为结构化的任务特定问答对，并在此基础上进行预测建模。

Result: 相比直接微调方法，在ICU死亡率预测任务中AUC仅下降2-3%，显著提升了模型透明度和可控性。

Conclusion: ClinStructor为在临床环境中构建可靠、可解释且可泛化的机器学习模型奠定了坚实基础。

Abstract: Clinical notes contain valuable, context-rich information, but their unstructured format introduces several challenges, including unintended biases (e.g., gender or racial bias), and poor generalization across clinical settings (e.g., models trained on one EHR system may perform poorly on another due to format differences) and poor interpretability. To address these issues, we present ClinStructor, a pipeline that leverages large language models (LLMs) to convert clinical free-text into structured, task-specific question-answer pairs prior to predictive modeling. Our method substantially enhances transparency and controllability and only leads to a modest reduction in predictive performance (a 2-3% drop in AUC), compared to direct fine-tuning, on the ICU mortality prediction task. ClinStructor lays a strong foundation for building reliable, interpretable, and generalizable machine learning models in clinical environments.

</details>


### [306] [Context-Emotion Aware Therapeutic Dialogue Generation: A Multi-component Reinforcement Learning Approach to Language Models for Mental Health Support](https://arxiv.org/abs/2511.11884)
*Eric Hua Qing Zhang,Julia Ive*

Main category: cs.CL

TL;DR: 本研究通过监督微调和强化学习技术提升GPT-2在治疗性对话生成中的表现，改进模型对上下文和情绪的理解能力，实验结果显示强化学习显著提高了各项评估指标和情绪识别准确率。


<details>
  <summary>Details</summary>
Motivation: 心理健康问题日益严重，而新冠疫情加剧了获取心理服务的困难，现有大语言模型缺乏足够的上下文和情感意识以提供适当的治疗回应。

Method: 采用监督微调和强化学习方法，重构输入格式以同时处理用户输入、上下文信息和情绪状态，并设计多组件奖励函数使模型输出与专业治疗师回应及标注情绪对齐。

Result: 强化学习相比基线GPT-2在BLEU、ROUGE和METEOR等指标上均有提升，情绪识别准确率达到99.34%，远高于基线的66.96%；LLM评估显示模型具有高上下文相关性和专业性。

Conclusion: 强化学习能有效提升大语言模型在治疗性对话系统中的表现，可作为辅助治疗工具，在保留临床人工监督的同时增强心理健康支持的可及性。

Abstract: Mental health illness represents a substantial global socioeconomic burden, with COVID-19 further exacerbating accessibility challenges and driving increased demand for telehealth mental health support. While large language models (LLMs) offer promising solutions through 24/7 availability and non-judgmental interactions, pre-trained models often lack the contextual and emotional awareness necessary for appropriate therapeutic responses. This paper investigated the application of supervised fine-tuning (SFT) and reinforcement learning (RL) techniques to enhance GPT-2's capacity for therapeutic dialogue generation. The methodology restructured input formats to enable simultaneous processing of contextual information and emotional states alongside user input, employing a multi-component reward function that aligned model outputs with professional therapist responses and annotated emotions. Results demonstrated improvements through reinforcement learning over baseline GPT-2 across multiple evaluation metrics: BLEU (0.0111), ROUGE-1 (0.1397), ROUGE-2 (0.0213), ROUGE-L (0.1317), and METEOR (0.0581). LLM evaluation confirmed high contextual relevance and professionalism, while reinforcement learning achieved 99.34% emotion accuracy compared to 66.96% for baseline GPT-2. These findings demonstrate reinforcement learning's effectiveness in developing therapeutic dialogue systems that can serve as valuable assistive tools for therapists while maintaining essential human clinical oversight.

</details>


### [307] [Additive Large Language Models for Semi-Structured Text](https://arxiv.org/abs/2511.11922)
*Karthikeyan K,Raghuveer Thirukovalluru,David Carlson*

Main category: cs.CL

TL;DR: 提出了一种名为CALM的可解释框架，用于半结构化临床文本分类，通过将预测结果分解为各语义组件的加性贡献，实现透明且可信的预测。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床文本分类中表现优异，但其预测缺乏可解释性，限制了在实际临床和研究中的应用。需要一种能够明确展示哪些病历部分驱动风险预测的方法。

Method: 提出CALM（Classification with Additive Large Language Models）框架，将输入分解为语义上有意义的组件（如入院记录的各个部分），并将最终预测建模为各组件贡献的加性总和，使解释成为前向计算的一部分。

Result: CALM在性能上与传统LLM分类器相当，同时提供了组件级的可解释性，支持患者级和群体级的可信解释，并能生成类似广义加性模型的风险曲线，便于可视化和审计。

Conclusion: CALM在保持高性能的同时提升了模型的可解释性和信任度，适用于需要透明决策的临床环境，有助于模型开发、质量控制和临床模式发现。

Abstract: Large Language Models have advanced clinical text classification, but their opaque predictions remain a critical barrier to practical adoption in research and clinical settings where investigators and physicians need to understand which parts of a patient's record drive risk signals. To address this challenge, we introduce \textbf{CALM}, short for \textbf{Classification with Additive Large Language Models}, an interpretable framework for semi-structured text where inputs are composed of semantically meaningful components, such as sections of an admission note or question-answer fields from an intake form. CALM predicts outcomes as the additive sum of each component's contribution, making these contributions part of the forward computation itself and enabling faithful explanations at both the patient and population level. The additive structure also enables clear visualizations, such as component-level risk curves similar to those used in generalized additive models, making the learned relationships easier to inspect and communicate. Although CALM expects semi-structured inputs, many clinical documents already have this form, and similar structure can often be automatically extracted from free-text notes. CALM achieves performance comparable to conventional LLM classifiers while improving trust, supporting quality-assurance checks, and revealing clinically meaningful patterns during model development and auditing.

</details>


### [308] [InData: Towards Secure Multi-Step, Tool-Based Data Analysis](https://arxiv.org/abs/2511.11933)
*Karthikeyan K,Raghuveer Thirukovalluru,Bhuwan Dhingra,David Edwin Carlson*

Main category: cs.CL

TL;DR: 提出一种基于安全工具的间接数据交互方法InData，用于评估大语言模型在多步推理下的工具使用能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型在数据分析中直接生成代码带来的安全风险，需要一种更安全的替代方案。

Method: 限制大模型直接访问数据和生成代码，仅允许通过预定义的安全工具进行交互，并构建InData数据集以评估多步工具调用与推理能力。

Result: 在15个开源大模型上的实验表明，虽然大模型在简单任务上表现良好（如gpt-oss-120b在Easy任务上达到97.3%准确率），但在Hard任务上性能显著下降（69.6%），显示出当前模型在多步工具推理上的不足。

Conclusion: InData为评估和提升大模型在安全约束下的多步工具使用能力提供了有效基准，推动更安全、可靠的LLM代理发展。

Abstract: Large language model agents for data analysis typically generate and execute code directly on databases. However, when applied to sensitive data, this approach poses significant security risks. To address this issue, we propose a security-motivated alternative: restrict LLMs from direct code generation and data access, and require them to interact with data exclusively through a predefined set of secure, verified tools. Although recent tool-use benchmarks exist, they primarily target tool selection and simple execution rather than the compositional, multi-step reasoning needed for complex data analysis. To reduce this gap, we introduce Indirect Data Engagement (InData), a dataset designed to assess LLMs' multi-step tool-based reasoning ability. InData includes data analysis questions at three difficulty levels--Easy, Medium, and Hard--capturing increasing reasoning complexity. We benchmark 15 open-source LLMs on InData and find that while large models (e.g., gpt-oss-120b) achieve high accuracy on Easy tasks (97.3%), performance drops sharply on Hard tasks (69.6%). These results show that current LLMs still lack robust multi-step tool-based reasoning ability. With InData, we take a step toward enabling the development and evaluation of LLMs with stronger multi-step tool-use capabilities. We will publicly release the dataset and code.

</details>


### [309] [Improving LLM's Attachment to External Knowledge In Dialogue Generation Tasks Through Entity Anonymization](https://arxiv.org/abs/2511.11946)
*Hadi Sheikhi,Chenyang Huang,Osmar R. Zaïane*

Main category: cs.CL

TL;DR: 提出LLM-KAT评估方法和实体匿名化技术，以提升大语言模型在知识图谱对话生成中对外部知识的利用能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在知识图谱对话生成任务中倾向于依赖内部知识，导致与提供的外部知识图谱脱节。

Method: 提出LLM-KAT评估程序衡量知识关联性，并设计实体匿名化技术促使模型更好利用外部知识。

Result: 在OpenDialKG数据集上的实验表明，所提方法能有效提升大语言模型对外部知识的依赖程度。

Conclusion: 实体匿名化技术结合LLM-KAT评估可显著增强大语言模型在知识图谱对话中的知识利用能力。

Abstract: Knowledge graph-based dialogue generation (KG-DG) is a challenging task requiring models to effectively incorporate external knowledge into conversational responses. While large language models (LLMs) have achieved impressive results across various NLP tasks, their ability to utilize external knowledge in KG-DG remains under-explored. We observe that LLMs often rely on internal knowledge, leading to detachment from provided knowledge graphs, even when they are given a flawlessly retrieved knowledge graph. First, we introduce LLM-KAT, an evaluation procedure for measuring knowledge attachment in generated responses. Second, we propose a simple yet effective entity anonymization technique to encourage LLMs to better leverage external knowledge. Experiments on the OpenDialKG dataset demonstrate that our approach improves LLMs' attachment on external knowledge.

</details>


### [310] [On the Entropy Calibration of Language Models](https://arxiv.org/abs/2511.11966)
*Steven Cao,Gregory Valiant,Percy Liang*

Main category: cs.CL

TL;DR: 本文研究了语言模型在生成文本时的熵校准问题，发现随着生成长度增加，模型的熵累积导致失校准，且该问题在更大规模模型中改善甚微；尽管截断能提升质量但牺牲多样性，作者通过理论和实验证明存在无需权衡的校准可能性。


<details>
  <summary>Details</summary>
Motivation: 解决自回归语言模型在长序列生成中熵累积导致的失校准问题，探讨模型扩展是否能自然缓解该问题，并寻找避免截断带来多样性损失的校准方法。

Method: 结合理论分析与实证测量：首先在简化理论框架下分析数据分布幂律指数对失校准缩放行为的影响，然后在0.5B到70B参数的语言模型上实证测量熵校准表现，并提出假设性黑箱模型以实现无损校准。

Result: 理论表明当数据分布幂律指数接近1时，失校准随数据量增长改善极慢；实验显示从0.5B到70B模型的熵累积速率几乎不变，说明缩放本身难以解决该问题；理论上证明若能预测未来熵，则可在不增加对数损失的情况下降低熵。

Conclusion: 语言模型的熵失校准问题在当前缩放路径下难以显著改善，截断并非理想解法；未来方向应探索基于未来熵预测的动态校准机制，在保持生成质量的同时维持多样性。

Abstract: We study the problem of entropy calibration, which asks whether a language model's entropy over generations matches its log loss on human text. Past work found that models are miscalibrated, with entropy per step increasing (and text quality decreasing) as generations grow longer. This error accumulation is a fundamental problem in autoregressive models, and the standard solution is to truncate the distribution, which improves text quality at the cost of diversity. In this paper, we ask: is miscalibration likely to improve with scale, and is it theoretically possible to calibrate without tradeoffs? To build intuition, we first study a simplified theoretical setting to characterize the scaling behavior of miscalibration with respect to dataset size. We find that the scaling behavior depends on the power law exponent of the data distribution -- in particular, for a power law exponent close to 1, the scaling exponent is close to 0, meaning that miscalibration improves very slowly with scale. Next, we measure miscalibration empirically in language models ranging from 0.5B to 70B parameters. We find that the observed scaling behavior is similar to what is predicted by the simplified setting: our fitted scaling exponents for text are close to 0, meaning that larger models accumulate error at a similar rate as smaller ones. This scaling (or, lack thereof) provides one explanation for why we sample from larger models with similar amounts of truncation as smaller models, even though the larger models are of higher quality. However, truncation is not a satisfying solution because it comes at the cost of increased log loss. In theory, is it even possible to reduce entropy while preserving log loss? We prove that it is possible, if we assume access to a black box which can fit models to predict the future entropy of text.

</details>


### [311] [A Reasoning Paradigm for Named Entity Recognition](https://arxiv.org/abs/2511.11978)
*Hui Huang,Yanping Chen,Ruizhang Huang,Chuan Lin,Yongbin Qin*

Main category: cs.CL

TL;DR: 提出了一种用于命名实体识别（NER）的推理框架ReasoningNER，通过引入链式思维（CoT）生成、CoT调优和推理增强三个阶段，将NER从隐式的模式匹配转变为显式的可验证推理过程，在零样本设置下显著优于GPT-4。


<details>
  <summary>Details</summary>
Motivation: 现有生成式大模型在NER任务中依赖指令微调，主要通过语义模式匹配生成实体，缺乏明确且可验证的推理机制，导致在零样本和低资源场景下泛化能力差。

Method: 构建包含任务相关推理链的NER-CoT数据集，用于训练模型生成连贯的推理过程；通过CoT调优使模型在输出实体前生成合理依据；引入基于综合奖励信号的推理增强阶段，优化整个推理过程。

Result: ReasoningNER在零样本设置下达到SOTA性能，F1分数比GPT-4高出12.3个百分点，展现出强大的认知能力和推理潜力。

Conclusion: 该推理框架有效提升了NER模型的可解释性和泛化能力，尤其在低资源和零样本场景下表现突出，为面向推理的信息抽取研究提供了新方向。

Abstract: Generative LLMs typically improve Named Entity Recognition (NER) performance through instruction tuning. They excel at generating entities by semantic pattern matching but lack an explicit, verifiable reasoning mechanism. This "cognitive shortcutting" leads to suboptimal performance and brittle generalization, especially in zero-shot and lowresource scenarios where reasoning from limited contextual cues is crucial. To address this issue, a reasoning framework is proposed for NER, which shifts the extraction paradigm from implicit pattern matching to explicit reasoning. This framework consists of three stages: Chain of Thought (CoT) generation, CoT tuning, and reasoning enhancement. First, a dataset annotated with NER-oriented CoTs is generated, which contain task-relevant reasoning chains. Then, they are used to tune the NER model to generate coherent rationales before deriving the final answer. Finally, a reasoning enhancement stage is implemented to optimize the reasoning process using a comprehensive reward signal. This stage ensures explicit and verifiable extractions. Experiments show that ReasoningNER demonstrates impressive cognitive ability in the NER task, achieving competitive performance. In zero-shot settings, it achieves state-of-the-art (SOTA) performance, outperforming GPT-4 by 12.3 percentage points on the F1 score. Analytical results also demonstrate its great potential to advance research in reasoningoriented information extraction. Our codes are available at https://github.com/HuiResearch/ReasoningIE.

</details>


### [312] [Critical or Compliant? The Double-Edged Sword of Reasoning in Chain-of-Thought Explanations](https://arxiv.org/abs/2511.12001)
*Eunkyu Park,Wesley Hanwen Deng,Vasudha Varadarajan,Mingxi Yan,Gunhee Kim,Maarten Sap,Motahhare Eslami*

Main category: cs.CL

TL;DR: 研究探讨了思维链（CoT）解释在多模态道德场景中的双刃剑作用，发现用户常因结果认同而信任错误推理，且自信的语气会抑制错误识别。


<details>
  <summary>Details</summary>
Motivation: 解释本应提升透明度，但可能引发确认偏误；因此需要探究CoT解释如何影响用户对模型推理的信任与判断。

Method: 通过系统性扰动推理链和操纵表达语气，分析视觉语言模型（VLMs）中的推理错误及其对用户信任和错误检测能力的影响。

Result: （1）用户常将信任等同于结果认同，即使推理有误仍保持依赖；（2）自信语气抑制错误检测，增强依赖，说明表达方式可凌驾于正确性之上。

Conclusion: CoT解释既能澄清又可能误导，强调NLP系统应设计鼓励审辨思考而非盲目信任的解释机制。

Abstract: Explanations are often promoted as tools for transparency, but they can also foster confirmation bias; users may assume reasoning is correct whenever outputs appear acceptable. We study this double-edged role of Chain-of-Thought (CoT) explanations in multimodal moral scenarios by systematically perturbing reasoning chains and manipulating delivery tones. Specifically, we analyze reasoning errors in vision language models (VLMs) and how they impact user trust and the ability to detect errors. Our findings reveal two key effects: (1) users often equate trust with outcome agreement, sustaining reliance even when reasoning is flawed, and (2) the confident tone suppresses error detection while maintaining reliance, showing that delivery styles can override correctness. These results highlight how CoT explanations can simultaneously clarify and mislead, underscoring the need for NLP systems to provide explanations that encourage scrutiny and critical thinking rather than blind trust. All code will be released publicly.

</details>


### [313] [CURE: Cultural Understanding and Reasoning Evaluation - A Framework for "Thick" Culture Alignment Evaluation in LLMs](https://arxiv.org/abs/2511.12014)
*Truong Vo,Sanmi Koyejo*

Main category: cs.CL

TL;DR: 本文提出了一套新的基准测试和评估指标，用于更全面地衡量大语言模型在多元文化环境中的文化理解与推理能力，发现传统评估方法高估了模型的文化胜任力，而新提出的“厚评估”方法能更稳定、深入地反映模型的真实表现。


<details>
  <summary>Details</summary>
Motivation: 现有对大语言模型文化能力的评估多依赖去语境化的正确性判断或强制选择，缺乏对文化语境中合理推理能力的考察，难以真实反映模型在跨文化场景中的适应性。

Method: 设计了一系列包含真实情境的基准任务，要求模型进行文化相关的推理；除精确匹配外，引入覆盖度、特异性、内涵和连贯性四个新指标进行多维度评估。

Result: 实验表明，传统的‘薄评估’会系统性高估模型的文化能力且结果方差大；而‘厚评估’能揭示模型推理深度的差异，降低评估波动，提供更稳定可解释的评估信号。

Conclusion: 文化能力评估应从孤立判断转向情境化、多维度的厚评估，以更准确地衡量和提升大语言模型在跨文化应用中的表现。

Abstract: Large language models (LLMs) are increasingly deployed in culturally diverse environments, yet existing evaluations of cultural competence remain limited. Existing methods focus on de-contextualized correctness or forced-choice judgments, overlooking the need for cultural understanding and reasoning required for appropriate responses. To address this gap, we introduce a set of benchmarks that, instead of directly probing abstract norms or isolated statements, present models with realistic situational contexts that require culturally grounded reasoning. In addition to the standard Exact Match metric, we introduce four complementary metrics (Coverage, Specificity, Connotation, and Coherence) to capture different dimensions of model's response quality. Empirical analysis across frontier models reveals that thin evaluation systematically overestimates cultural competence and produces unstable assessments with high variance. In contrast, thick evaluation exposes differences in reasoning depth, reduces variance, and provides more stable, interpretable signals of cultural understanding.

</details>


### [314] [Exploring Parameter-Efficient Fine-Tuning and Backtranslation for the WMT 25 General Translation Task](https://arxiv.org/abs/2511.12109)
*Felipe Fujita,Hideyuki Takada*

Main category: cs.CL

TL;DR: 结合回译和微调方法，在小规模日语语料上显著提升了神经机器翻译性能，COMET分数达到0.597，优于单独使用任一技术。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言对（如英语→日语）中，训练数据有限导致翻译质量受限，因此探索能有效提升性能的轻量级方法。

Method: 首先使用单语日语语料通过回译（BT）生成合成数据增强训练集，然后在小型真实平行语料上进行微调（FT），并结合两种技术进行联合优化。

Result: 单独使用回译使COMET分数从0.460提升至0.468；仅微调提升至0.589；结合回译与微调后进一步提升至0.597。

Conclusion: 回译与微调的协同使用能显著提高低资源条件下的翻译质量，是一种高效且实用的策略。

Abstract: In this paper, we explore the effectiveness of combining fine-tuning and backtranslation on a small Japanese corpus for neural machine translation. Starting from a baseline English{\textrightarrow}Japanese model (COMET = 0.460), we first apply backtranslation (BT) using synthetic data generated from monolingual Japanese corpora, yielding a modest increase (COMET = 0.468). Next, we fine-tune (FT) the model on a genuine small parallel dataset drawn from diverse Japanese news and literary corpora, achieving a substantial jump to COMET = 0.589 when using Mistral 7B. Finally, we integrate both backtranslation and fine-tuning{ -- }first augmenting the small dataset with BT generated examples, then adapting via FT{ -- }which further boosts performance to COMET = 0.597. These results demonstrate that, even with limited training data, the synergistic use of backtranslation and targeted fine-tuning on Japanese corpora can significantly enhance translation quality, outperforming each technique in isolation. This approach offers a lightweight yet powerful strategy for improving low-resource language pairs.

</details>


### [315] [LLMLagBench: Identifying Temporal Training Boundaries in Large Language Models](https://arxiv.org/abs/2511.12116)
*Piotr Pęzik,Konrad Kaczyński,Maria Szymańska,Filip Żarnecki,Zuzanna Deckert,Jakub Kwiatkowski,Wojciech Janowski*

Main category: cs.CL

TL;DR: 提出LLMLagBench，用于评估大语言模型训练数据的时间边界及其知识新鲜度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的知识受限于训练数据的时间截止点，可能导致在推理中使用过时信息，影响准确性。

Method: 构建LLMLagBench基准，通过测试模型对近期事件的知识来识别其训练数据的最早可能时间边界，并对多个具有明确或未明确截止日期的LLM进行评估。

Result: 该基准能有效估计LLM的训练时间边界，经手动验证和公开信息对比显示其可靠。

Conclusion: LLMLagBench为评估LLM知识新鲜度提供了系统化方法，有助于识别模型的时间局限性。

Abstract: Large Language Models (LLMs) are pretrained on textual data up to a specific temporal cutoff. This creates a strict knowledge boundary beyond which models cannot provide accurate information without querying external sources. More subtly, when this limitation is unknown or ignored, LLMs may inadvertently blend outdated time-sensitive information with general knowledge during reasoning tasks, potentially compromising response accuracy. We introduce LLMLagBench, an LLM freshness benchmark, as a systematic approach for identifying the earliest probable temporal boundaries of an LLM's training data by evaluating its knowledge of recent events. We then apply this benchmark to evaluate a large set of LLMs, including models with both explicitly declared and undeclared training cutoffs. The reliability of the benchmark is assessed by manual validation and comparison with publicly released information about LLM pretraining.

</details>


### [316] [PRISM of Opinions: A Persona-Reasoned Multimodal Framework for User-centric Conversational Stance Detection](https://arxiv.org/abs/2511.12130)
*Bingbing Wang,Zhixin Bai,Zhengda Jin,Zihan Wang,Xintong Song,Jingjie Lin,Sixuan Li,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: 本文提出了首个以用户为中心的多模态对话立场检测数据集U-MStance，并设计了PRISM模型，通过用户画像和链式思维对齐图文信息，实现更精准的立场检测。


<details>
  <summary>Details</summary>
Motivation: 现有研究存在伪多模态和用户同质化问题，无法真实反映用户在多模态社交内容中的立场表达。

Method: 构建U-MStance数据集，提出PRISM模型，利用用户历史行为提取长期人格特征，通过链式思维对齐文本与视觉线索，并采用互惠任务强化机制联合优化立场检测与响应生成。

Result: 在U-MStance数据集上的实验表明，PRISM显著优于强基线模型，验证了用户中心化和上下文感知的多模态推理的有效性。

Conclusion: 引入用户个性特征和真实多模态交互建模能有效提升多模态对话立场检测性能，推动更贴近现实场景的立场理解。

Abstract: The rapid proliferation of multimodal social media content has driven research in Multimodal Conversational Stance Detection (MCSD), which aims to interpret users' attitudes toward specific targets within complex discussions. However, existing studies remain limited by: **1) pseudo-multimodality**, where visual cues appear only in source posts while comments are treated as text-only, misaligning with real-world multimodal interactions; and **2) user homogeneity**, where diverse users are treated uniformly, neglecting personal traits that shape stance expression. To address these issues, we introduce **U-MStance**, the first user-centric MCSD dataset, containing over 40k annotated comments across six real-world targets. We further propose **PRISM**, a **P**ersona-**R**easoned mult**I**modal **S**tance **M**odel for MCSD. PRISM first derives longitudinal user personas from historical posts and comments to capture individual traits, then aligns textual and visual cues within conversational context via Chain-of-Thought to bridge semantic and pragmatic gaps across modalities. Finally, a mutual task reinforcement mechanism is employed to jointly optimize stance detection and stance-aware response generation for bidirectional knowledge transfer. Experiments on U-MStance demonstrate that PRISM yields significant gains over strong baselines, underscoring the effectiveness of user-centric and context-grounded multimodal reasoning for realistic stance understanding.

</details>


### [317] [AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing](https://arxiv.org/abs/2511.12133)
*Qingyu Zhang,Chunlei Xin,Xuanang Chen,Yaojie Lu,Hongyu Lin,Xianpei Han,Le Sun,Qing Ye,Qianlong Xie,Xingxing Wang*

Main category: cs.CL

TL;DR: 本文提出了AI-Salesman框架，用于解决目标驱动的说服性对话中的策略脆弱性和事实幻觉问题，通过构建真实世界数据集TeleSalesCorpus和设计双阶段架构，在销售对话任务中显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在目标驱动的说服性对话中面临多轮规划复杂、事实不忠实等问题，且缺乏特定任务的数据支持，导致策略不稳定和生成内容失真。

Method: 提出AI-Salesman框架，包含两个阶段：训练阶段采用贝叶斯监督强化学习算法从噪声对话中学习鲁棒销售策略；推理阶段引入动态大纲引导代理（DOGA），利用预构建脚本库提供逐轮策略指导，并结合细粒度指标与LLM-as-a-Judge范式进行综合评估。

Result: 实验结果表明，AI-Salesman在自动评估指标和全面的人类评估中均显著优于基线模型，有效提升了复杂说服场景下的表现。

Conclusion: AI-Salesman通过双阶段架构和动态策略引导，在真实销售对话任务中实现了更高的策略稳定性与事实准确性，为说服性对话系统提供了可行的技术路径。

Abstract: Goal-driven persuasive dialogue, exemplified by applications like telemarketing, requires sophisticated multi-turn planning and strict factual faithfulness, which remains a significant challenge for even state-of-the-art Large Language Models (LLMs). A lack of task-specific data often limits previous works, and direct LLM application suffers from strategic brittleness and factual hallucination. In this paper, we first construct and release TeleSalesCorpus, the first real-world-grounded dialogue dataset for this domain. We then propose AI-Salesman, a novel framework featuring a dual-stage architecture. For the training stage, we design a Bayesian-supervised reinforcement learning algorithm that learns robust sales strategies from noisy dialogues. For the inference stage, we introduce the Dynamic Outline-Guided Agent (DOGA), which leverages a pre-built script library to provide dynamic, turn-by-turn strategic guidance. Moreover, we design a comprehensive evaluation framework that combines fine-grained metrics for key sales skills with the LLM-as-a-Judge paradigm. Experimental results demonstrate that our proposed AI-Salesman significantly outperforms baseline models in both automatic metrics and comprehensive human evaluations, showcasing its effectiveness in complex persuasive scenarios.

</details>


### [318] [Seeing is Believing: Rich-Context Hallucination Detection for MLLMs via Backward Visual Grounding](https://arxiv.org/abs/2511.12140)
*Pinxue Guo,Chongruo Wu,Xinyu Zhou,Lingyi Hong,Zhaoyu Chen,Jinglun Li,Kaixun Jiang,Sen-ching Samson Cheung,Wei Zhang,Wenqiang Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种无需参考的多模态大语言模型幻觉检测框架VBackChecker，通过像素级 grounding LLM 验证生成内容与视觉输入的一致性，在新构建的富含真实场景的基准R^2-HalBench上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）存在严重的幻觉问题，影响其在实际应用中的可靠性，现有幻觉检测方法难以有效应对复杂上下文且缺乏可解释性。

Method: 基于“Seeing is Believing”原则，设计VBackChecker框架，利用具备推理和指代分割能力的像素级Grounding LLM来验证MLLM输出与视觉输入的一致性；构建R-Instruct数据生成流程以支持指令微调，并建立新的幻觉检测基准R^2-HalBench。

Result: VBackChecker在R^2-HalBench上优于以往复杂框架，性能媲美GPT-4o，在像素级定位任务上超过先前方法10%以上。

Conclusion: VBackChecker是一种高效、可解释的无参考幻觉检测方法，在丰富上下文和真实场景中表现出色，推动了MLLM幻觉检测的发展。

Abstract: Multimodal Large Language Models (MLLMs) have unlocked powerful cross-modal capabilities, but still significantly suffer from hallucinations. As such, accurate detection of hallucinations in MLLMs is imperative for ensuring their reliability in practical applications. To this end, guided by the principle of "Seeing is Believing", we introduce VBackChecker, a novel reference-free hallucination detection framework that verifies the consistency of MLLMgenerated responses with visual inputs, by leveraging a pixellevel Grounding LLM equipped with reasoning and referring segmentation capabilities. This reference-free framework not only effectively handles rich-context scenarios, but also offers interpretability. To facilitate this, an innovative pipeline is accordingly designed for generating instruction-tuning data (R-Instruct), featuring rich-context descriptions, grounding masks, and hard negative samples. We further establish R^2 -HalBench, a new hallucination benchmark for MLLMs, which, unlike previous benchmarks, encompasses real-world, rich-context descriptions from 18 MLLMs with high-quality annotations, spanning diverse object-, attribute, and relationship-level details. VBackChecker outperforms prior complex frameworks and achieves state-of-the-art performance on R^2 -HalBench, even rivaling GPT-4o's capabilities in hallucination detection. It also surpasses prior methods in the pixel-level grounding task, achieving over a 10% improvement. All codes, data, and models are available at https://github.com/PinxueGuo/VBackChecker.

</details>


### [319] [CriticSearch: Fine-Grained Credit Assignment for Search Agents via a Retrospective Critic](https://arxiv.org/abs/2511.12159)
*Yaocheng Zhang,Haohuan Huang,Zijun Song,Yuanheng Zhu,Qichao Zhang,Zijie Zhao,Dongbin Zhao*

Main category: cs.CL

TL;DR: 提出CriticSearch，一种细粒度信用分配框架，通过回溯性批评机制提供密集的回合级反馈，提升搜索代理的训练效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的搜索代理因稀疏奖励导致探索效率低和训练不稳定。

Method: 引入一个冻结的非对称批评大模型，利用完整轨迹和标准答案回溯评估每一轮，生成密集且稳定的奖励信号用于策略优化。

Result: 在多个多跳推理基准上实验表明，CriticSearch比现有方法收敛更快、训练更稳定且性能更高。

Conclusion: CriticSearch通过细粒度反馈有效解决了搜索代理训练中的稀疏奖励问题，显著提升了复杂问答任务中的表现。

Abstract: Tool-Integrated Reasoning (TIR) with search engines enables large language models to iteratively retrieve up-to-date external knowledge, enhancing adaptability and generalization in complex question-answering tasks. However, existing search agent pipelines typically depend on reinforcement learning based optimization, which often suffers from sparse outcome rewards, leading to inefficient exploration and unstable training. We introduce CriticSearch, a fine-grained credit-assignment framework that supplies dense, turn-level feedback via a retrospective critic mechanism. During training, a frozen, asymmetric critique LLM retrospectively evaluates each turn using privileged information from the full trajectory and gold answers, converting these assessments into stable, dense rewards that guide policy improvement. Experimental results across diverse multi-hop reasoning benchmarks demonstrate that CriticSearch consistently outperforms existing baselines, achieving faster convergence, improved training stability, and higher performance.

</details>


### [320] [MME-RAG: Multi-Manager-Expert Retrieval-Augmented Generation for Fine-Grained Entity Recognition in Task-Oriented Dialogues](https://arxiv.org/abs/2511.12213)
*Liang Xue,Haoyu Liu,Yajun Tian,Xinyu Zhong,Yang Liu*

Main category: cs.CL

TL;DR: 本文提出MME-RAG，一种用于任务导向对话中细粒度实体识别的多管理者-专家检索增强生成框架，通过类型级判断和跨度级提取的分层结构提升领域适应性和检索可控性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在领域自适应和检索可控性方面对细粒度实体识别支持不足，难以满足任务导向对话中的精准理解需求。

Method: 将实体识别分解为两个阶段：轻量级管理者进行类型级判断，专用专家进行跨度级提取；每个专家配备KeyInfo检索器，在推理时注入语义对齐的少样本示例，实现无需额外训练的精确提取。

Result: 在CrossNER、MIT-Movie、MIT-Restaurant及新构建的多领域客服数据集上优于近期基线方法，消融实验表明分层分解和KeyInfo引导检索均显著提升鲁棒性与跨域泛化能力。

Conclusion: MME-RAG是一种可扩展、可解释的解决方案，有效提升了任务导向对话中的自适应实体识别性能。

Abstract: Fine-grained entity recognition is crucial for reasoning and decision-making in task-oriented dialogues, yet current large language models (LLMs) continue to face challenges in domain adaptation and retrieval controllability. We introduce MME-RAG, a Multi-Manager-Expert Retrieval-Augmented Generation framework that decomposes entity recognition into two coordinated stages: type-level judgment by lightweight managers and span-level extraction by specialized experts. Each expert is supported by a KeyInfo retriever that injects semantically aligned, few-shot exemplars during inference, enabling precise and domain-adaptive extraction without additional training. Experiments on CrossNER, MIT-Movie, MIT-Restaurant, and our newly constructed multi-domain customer-service dataset demonstrate that MME-RAG performs better than recent baselines in most domains. Ablation studies further show that both the hierarchical decomposition and KeyInfo-guided retrieval are key drivers of robustness and cross-domain generalization, establishing MME-RAG as a scalable and interpretable solution for adaptive dialogue understanding.

</details>


### [321] [Consistency Is the Key: Detecting Hallucinations in LLM Generated Text By Checking Inconsistencies About Key Facts](https://arxiv.org/abs/2511.12236)
*Raavi Gupta,Pranav Hari Panicker,Sumit Bhatia,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: CONFACTCHECK是一种高效的幻觉检测方法，适用于受限访问的大型语言模型（LLM）API环境，通过检查生成内容在单个及多个LLM间对事实探测响应的一致性来识别错误信息，无需外部知识库支持。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在文本生成方面表现出色，但容易产生与现实世界知识不符的幻觉内容，这在医疗、金融和客户服务等关键领域带来了严重风险。尤其是在只能通过API访问且无法微调模型的情况下，现有检测方法通常需要多次调用API，导致延迟和成本增加。因此，亟需一种高效、低成本的幻觉检测方案。

Method: 提出CONFACTCHECK方法，基于一个简单直觉：对于生成文本中的事实性提问，同一LLM内部以及不同LLMs之间的回答应保持一致。该方法不依赖外部知识库，仅通过少量API调用即可完成检测，提升了效率并降低了资源消耗。

Result: 在多个涵盖事实生成和开放生成的数据集上进行了严格实验评估，结果显示CONFACTCHECK在资源使用更少的情况下，相比现有基线方法具有更高的准确率。

Conclusion: CONFACTCHECK提供了一种高效、实用的幻觉检测解决方案，特别适用于无法访问模型权重或资源受限的LLM应用场景，显著降低了检测成本并提高了准确性。

Abstract: Large language models (LLMs), despite their remarkable text generation capabilities, often hallucinate and generate text that is factually incorrect and not grounded in real-world knowledge. This poses serious risks in domains like healthcare, finance, and customer support. A typical way to use LLMs is via the APIs provided by LLM vendors where there is no access to model weights or options to fine-tune the model. Existing methods to detect hallucinations in such settings where the model access is restricted or constrained by resources typically require making multiple LLM API calls, increasing latency and API cost. We introduce CONFACTCHECK, an efficient hallucination detection approach that does not leverage any external knowledge base and works on the simple intuition that responses to factual probes within the generated text should be consistent within a single LLM and across different LLMs. Rigorous empirical evaluation on multiple datasets that cover both the generation of factual texts and the open generation shows that CONFACTCHECK can detect hallucinated facts efficiently using fewer resources and achieves higher accuracy scores compared to existing baselines that operate under similar conditions. Our code is available here.

</details>


### [322] [ViConBERT: Context-Gloss Aligned Vietnamese Word Embedding for Polysemous and Sense-Aware Representations](https://arxiv.org/abs/2511.12249)
*Khang T. Huynh,Dung H. Nguyen,Binh T. Nguyen*

Main category: cs.CL

TL;DR: 本文提出了ViConBERT，一种用于学习越南语上下文嵌入的新框架，并结合对比学习和基于词典的蒸馏方法来更好地捕捉词义。同时发布了首个大规模合成数据集ViConWSD，用于评估越南语的语义理解能力。实验结果表明，该模型在多项任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 越南语缺乏强大的上下文嵌入模型和评估资源，限制了其细粒度语义理解的发展。现有研究主要集中在英语等高资源语言上。

Method: 提出ViConBERT框架，结合SimCLR对比学习和基于词典的蒸馏技术；构建大规模合成数据集ViConWSD，支持词义消歧和上下文相似度评估。

Result: ViConBERT在WSD任务上F1达到0.87，在ViCon上AP为0.88，在ViSim-400上Spearman相关系数为0.60，优于强基线模型。

Conclusion: ViConBERT能有效建模越南语中的离散词义和渐进语义关系，推动了低资源语言的语义理解研究。

Abstract: Recent advances in contextualized word embeddings have greatly improved semantic tasks such as Word Sense Disambiguation (WSD) and contextual similarity, but most progress has been limited to high-resource languages like English. Vietnamese, in contrast, still lacks robust models and evaluation resources for fine-grained semantic understanding. In this paper, we present ViConBERT, a novel framework for learning Vietnamese contextualized embeddings that integrates contrastive learning (SimCLR) and gloss-based distillation to better capture word meaning. We also introduce ViConWSD, the first large-scale synthetic dataset for evaluating semantic understanding in Vietnamese, covering both WSD and contextual similarity. Experimental results show that ViConBERT outperforms strong baselines on WSD (F1 = 0.87) and achieves competitive performance on ViCon (AP = 0.88) and ViSim-400 (Spearman's rho = 0.60), demonstrating its effectiveness in modeling both discrete senses and graded semantic relations. Our code, models, and data are available at https://github.com/tkhangg0910/ViConBERT

</details>


### [323] [Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy](https://arxiv.org/abs/2511.12920)
*Desheng Hu,Joachim Baumann,Aleksandra Urman,Elsa Lichtenegger,Robin Forsberg,Aniko Hannak,Christo Wilson*

Main category: cs.CL

TL;DR: 该研究通过系统性算法审计1508个与婴儿护理和孕期相关的实际搜索查询，评估谷歌搜索中AI概览（AIO）和精选摘要（FS）的信息质量与一致性。研究发现33%的情况下两者信息不一致，且医疗安全提示缺失严重（AIO为11%，FS为7%），尽管相关性较高，但二者均缺乏关键的健康风险控制机制。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容在搜索引擎中的广泛应用，用户依赖性强但控制力弱，尤其在母婴健康等高风险领域，信息质量直接影响公众健康，因此亟需评估并改进AI生成内容的可靠性与安全性。

Method: 研究采用系统性算法审计方法，针对1508个真实育儿和孕期相关搜索词，从答案一致性、相关性、医疗安全保障、来源类别和情感倾向等多个维度构建评估框架，对比分析AIO与FS的内容质量。

Result: 33%的情况下AIO与FS信息不一致；医疗安全保障分别仅出现在11%的AIO和7%的FS中；内容高度相关，主要来源为健康类网站，但FS更多链接至商业网站；整体缺乏必要的医学警示和质量管控。

Conclusion: 当前AI驱动的搜索摘要在高风险健康信息传播中存在重大质量缺陷，亟需加强监管与质量控制机制。本研究提出的评估框架可推广至其他高风险领域的AI系统审计。

Abstract: Google Search increasingly surfaces AI-generated content through features like AI Overviews (AIO) and Featured Snippets (FS), which users frequently rely on despite having no control over their presentation. Through a systematic algorithm audit of 1,508 real baby care and pregnancy-related queries, we evaluate the quality and consistency of these information displays. Our robust evaluation framework assesses multiple quality dimensions, including answer consistency, relevance, presence of medical safeguards, source categories, and sentiment alignment. Our results reveal concerning gaps in information consistency, with information in AIO and FS displayed on the same search result page being inconsistent with each other in 33% of cases. Despite high relevance scores, both features critically lack medical safeguards (present in just 11% of AIO and 7% of FS responses). While health and wellness websites dominate source categories for both, AIO and FS, FS also often link to commercial sources. These findings have important implications for public health information access and demonstrate the need for stronger quality controls in AI-mediated health information. Our methodology provides a transferable framework for auditing AI systems across high-stakes domains where information quality directly impacts user well-being.

</details>


### [324] [Cmprsr: Abstractive Token-Level Question-Agnostic Prompt Compressor](https://arxiv.org/abs/2511.12281)
*Ivan Zakazov,Alexander Sharipov,Berke Argin,Oussama Gabouj,Kamel Charaf,Alexi Semiz,Lorenzo Drudi,Nicolas Baldwin,Robert West*

Main category: cs.CL

TL;DR: 本文提出了一种新的提示压缩范式，利用小型大语言模型（LLM）压缩大型模型的输入，以降低使用黑盒LLM的成本。作者构建了首个全面的LLM作为压缩器的基准，评估了25个开源和闭源模型，并通过优化和后训练开发出性能优越的压缩模型Cmprsr，该模型在多种任务和压缩率下均表现出色且具有良好可控性。


<details>
  <summary>Details</summary>
Motivation: 由于使用黑盒大语言模型（LLM）成本高昂，因此需要一种高效的方法来减少输入长度，从而降低推理开销。

Method: 提出利用小型LLM作为压缩器来压缩大型LLM的输入；构建包含25个模型的LLM-as-a-compressor基准；采用Textgrad优化gpt-4.1-mini的元提示；对Qwen3-4B进行监督微调（SFT）和组相对策略优化（GRPO）以提升其压缩性能。

Result: 发现不同模型在语义保持和压缩率遵循方面表现差异显著；Cmprsr在长文本（如MeetingBank、LongBench）和短文本（如GSM8k）上均优于抽取式和普通生成式压缩方法，并能精确遵循目标压缩率。

Conclusion: Cmprsr是一种高效、可控且泛化能力强的提示压缩模型，能够在保证下游任务性能的同时显著降低大语言模型的使用成本。

Abstract: Motivated by the high costs of using black-box Large Language Models (LLMs), we introduce a novel prompt compression paradigm, under which we use smaller LLMs to compress inputs for the larger ones. We present the first comprehensive LLM-as-a-compressor benchmark spanning 25 open- and closed-source models, which reveals significant disparity in models' compression ability in terms of (i) preserving semantically important information (ii) following the user-provided compression rate (CR). We further improve the performance of gpt-4.1-mini, the best overall vanilla compressor, with Textgrad-based compression meta-prompt optimization. We also identify the most promising open-source vanilla LLM - Qwen3-4B - and post-train it with a combination of supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), pursuing the dual objective of CR adherence and maximizing the downstream task performance. We call the resulting model Cmprsr and demonstrate its superiority over both extractive and vanilla abstractive compression across the entire range of compression rates on lengthy inputs from MeetingBank and LongBench as well as short prompts from GSM8k. The latter highlights Cmprsr's generalizability across varying input lengths and domains. Moreover, Cmprsr closely follows the requested compression rate, offering fine control over the cost-quality trade-off.

</details>


### [325] [AugAbEx : Way Forward for Extractive Case Summarization](https://arxiv.org/abs/2511.12290)
*Purnima Bindal,Vikas Kumar,Sagar Rathore,Vasudha Bhatnagar*

Main category: cs.CL

TL;DR: 本文提出了一种轻量且透明的流程，利用现有的抽象式法律判决摘要生成对应的抽取式摘要，以增强现有数据集并促进法律文档自动摘要研究。


<details>
  <summary>Details</summary>
Motivation: 由于法律文本语言复杂、术语上下文敏感且文档较长，人工摘要负担重，而当前基于深度神经网络的抽象式摘要容易误传法律术语或忽略关键细节，因此需要更可靠的抽取式摘要方法。

Method: 设计一个自动化流程，将已有的抽象式黄金标准摘要转化为抽取式摘要，并在七个现有数据集上进行扩展；通过结构、词汇、语义及领域信息多维度评估生成摘要的质量。

Result: 成功构建了包含抽取式摘要的增强型数据集，质量评估显示其与原始抽象式摘要在多个维度上保持一致，确保专家意见得以保留。

Conclusion: 该资源将为法律文本自动摘要研究提供重要支持，推动抽取式摘要方法的发展，并计划公开发布以促进学术共享。

Abstract: Summarization of legal judgments poses a heavy cognitive burden on law practitioners due to the complexity of the language, context-sensitive legal jargon, and the length of the document. Therefore, the automatic summarization of legal documents has attracted serious attention from natural language processing researchers. Since the abstractive summaries of legal documents generated by deep neural methods remain prone to the risk of misrepresenting nuanced legal jargon or overlooking key contextual details, we envisage a rising trend toward the use of extractive case summarizers.
  Given the high cost of human annotation for gold standard extractive summaries, we engineer a light and transparent pipeline that leverages existing abstractive gold standard summaries to create the corresponding extractive gold standard versions. The approach ensures that the experts` opinions ensconced in the original gold standard abstractive summaries are carried over to the transformed extractive summaries. We aim to augment seven existing case summarization datasets, which include abstractive summaries, by incorporating corresponding extractive summaries and create an enriched data resource for case summarization research community. To ensure the quality of the augmented extractive summaries, we perform an extensive comparative evaluation with the original abstractive gold standard summaries covering structural, lexical, and semantic dimensions. We also compare the domain-level information of the two summaries. We commit to release the augmented datasets in the public domain for use by the research community and believe that the resource will offer opportunities to advance the field of automatic summarization of legal documents.

</details>


### [326] [Do LLMs and Humans Find the Same Questions Difficult? A Case Study on Japanese Quiz Answering](https://arxiv.org/abs/2511.12300)
*Naoya Sugiura,Kosuke Yamada,Yasuhiro Ogawa,Katsuhiko Toyama,Ryohei Sasano*

Main category: cs.CL

TL;DR: 该研究探讨了在抢答测验中，大语言模型（LLM）与人类在题目难度感知上的差异，发现LLM在答案未被维基百科覆盖或需要数值回答的问题上表现较差。


<details>
  <summary>Details</summary>
Motivation: 探究LLM是否在人类认为困难的问题上也表现出困难，特别是在抢答式问答场景下。

Method: 收集包含问题、答案和人类正确率的日语测验数据，通过提示LLM在多种设置下作答，并从两个分析角度比较其与人类的正确率。

Result: 实验结果表明，相比人类，LLM在答案未被维基百科覆盖的题目以及需要数值回答的问题上正确率更低。

Conclusion: LLM的难点与人类不同，其性能受限于训练数据覆盖度和数值推理能力。

Abstract: LLMs have achieved performance that surpasses humans in many NLP tasks. However, it remains unclear whether problems that are difficult for humans are also difficult for LLMs. This study investigates how the difficulty of quizzes in a buzzer setting differs between LLMs and humans. Specifically, we first collect Japanese quiz data including questions, answers, and correct response rate of humans, then prompted LLMs to answer the quizzes under several settings, and compare their correct answer rate to that of humans from two analytical perspectives. The experimental results showed that, compared to humans, LLMs struggle more with quizzes whose correct answers are not covered by Wikipedia entries, and also have difficulty with questions that require numerical answers.

</details>


### [327] [Don't Think of the White Bear: Ironic Negation in Transformer Models Under Cognitive Load](https://arxiv.org/abs/2511.12381)
*Logan Mann,Nayan Saxena,Sarah Tandon,Chenhao Sun,Savar Toteja,Kevin Zhu*

Main category: cs.CL

TL;DR: 该研究探讨了大语言模型（LLM）在处理否定指令时出现的“反讽反弹”现象，即抑制某个概念反而会增强其激活。通过两项实验和电路追踪分析，发现否定后立即出现反弹，语义或较长干扰文本加剧反弹，重复有助于抑制，且极性分离越强，反弹越持久。研究发布了包含5000个样本的ReboundBench数据集。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在遵循否定指令时是否表现出类似人类的反讽反弹现象，并理解其背后的机制。

Method: 设计两项实验：(1) 负载与内容实验，改变否定后的干扰文本类型并测量反弹强度；(2) 极性分离实验，检验模型是否能区分中性与否定表述及其对反弹的影响。结合电路追踪分析关键注意力头的作用。

Result: 否定指令后普遍出现即时反弹，语义或长干扰文本增强反弹，重复有助于抑制；极性分离能力越强的模型反弹更持久；中间层稀疏注意力头被发现放大被禁用词，而早期层负责抑制。

Conclusion: 大语言模型存在类似人类的反讽反弹现象，其机制与上下文干扰和特定神经通路有关，为理解和控制模型输出提供了新视角。

Abstract: Negation instructions such as 'do not mention $X$' can paradoxically increase the accessibility of $X$ in human thought, a phenomenon known as ironic rebound. Large language models (LLMs) face the same challenge: suppressing a concept requires internally activating it, which may prime rebound instead of avoidance. We investigated this tension with two experiments. \textbf{(1) Load \& content}: after a negation instruction, we vary distractor text (semantic, syntactic, repetition) and measure rebound strength. \textbf{(2) Polarity separation}: We test whether models distinguish neutral from negative framings of the same concept and whether this separation predicts rebound persistence. Results show that rebound consistently arises immediately after negation and intensifies with longer or semantic distractors, while repetition supports suppression. Stronger polarity separation correlates with more persistent rebound. Together, these findings, complemented by a circuit tracing analysis that identifies sparse middle-layer attention heads amplifying forbidden tokens while early layers suppress, link cognitive predictions of ironic rebound with mechanistic insights into long-context interference. To support future work, we release ReboundBench, a dataset of $5,000$ systematically varied negation prompts designed to probe rebound in LLMs.

</details>


### [328] [From Phonemes to Meaning: Evaluating Large Language Models on Tamil](https://arxiv.org/abs/2511.12387)
*Jeyarajalingam Varsha,Menan Velayuthan,Sumirtha Karunakaran,Rasan Nivethiga,Kengatharaiyer Sarveswaran*

Main category: cs.CL

TL;DR: 本文提出了ILAKKANAM，首个针对泰米尔语的語言評估基準，基於斯里蘭卡中小學考試題目構建，用以評估大語言模型在低資源、形態豐富語言中的表現。結果顯示現有模型在語言複雜度較高時性能下降，且表現與真正理解無強關聯。


<details>
  <summary>Details</summary>
Motivation: 現有的多語言基準多基於英語翻譯資料集，無法捕捉低資源且形態豐富的語言（如泰米爾語）的語言與文化細微差異，因此需要一個專門針對泰米爾語的評估基準。

Method: 研究團隊構建了ILAKKANAM，一個包含820道問題的泰米爾語語言評估基準，問題來自斯里蘭卡中小學泰米爾語考試，由訓練有素的語言學家標註為五個語言類別和一個事實知識類別。使用標準化框架評估多個閉源與開源大語言模型。

Result: Gemini 2.5表現最佳，但整體而言開源模型落後；所有模型在低年級問題上表現較好，隨著語言複雜度增加性能下降；模型整體表現與其識別語言類別的能力之間無顯著相關性。

Conclusion: 當前大語言模型在處理泰米爾語等低資源、形態複雜語言時仍存在局限，性能提升可能源自數據暴露而非真正的語言理解，亟需更具文化與語言適配性的評估與訓練方法。

Abstract: Large Language Models (LLMs) have shown strong generalization across tasks in high-resource languages; however, their linguistic competence in low-resource and morphologically rich languages such as Tamil remains largely unexplored. Existing multilingual benchmarks often rely on translated English datasets, failing to capture the linguistic and cultural nuances of the target language. To address this gap, we introduce ILAKKANAM, the first Tamil-specific linguistic evaluation benchmark manually curated using 820 questions from Sri Lankan school-level Tamil subject examination papers. Each question is annotated by trained linguists under five linguistic categories and a factual knowledge category, spanning Grades 1--13 to ensure broad linguistic coverage. We evaluate both closed-source and open-source LLMs using a standardized evaluation framework. Our results show that Gemini 2.5 achieves the highest overall performance, while open-source models lag behind, highlighting the gap in linguistic grounding. Category- and grade-wise analyses reveal that all models perform well on lower-grade questions but show a clear decline as linguistic complexity increases. Further, no strong correlation is observed between a model's overall performance and its ability to identify linguistic categories, suggesting that performance may be driven by exposure rather than genuine understanding.

</details>


### [329] [Probing Preference Representations: A Multi-Dimensional Evaluation and Analysis Method for Reward Models](https://arxiv.org/abs/2511.12464)
*Chenglong Wang,Yifu Huo,Yang Gan,Yongyu Mu,Qiaozhi He,Murun Yang,Bei Li,Chunliang Zhang,Tongran Liu,Anxiang Ma,Zhengtao Yu,Jingbo Zhu,Tong Xiao*

Main category: cs.CL

TL;DR: 本文提出了一种通过探测偏好表示来评估奖励模型的新方法，构建了多维奖励模型基准（MRMBench）和推理时探测技术，以提升大语言模型的对齐性能和奖励预测的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型评估方法缺乏对不同偏好维度的表现分析，难以全面衡量模型性能。

Method: 构建包含六个探测任务的MRMBench，用于评估不同偏好维度上的表现；提出推理时探测方法，识别奖励预测过程中使用的偏好维度，增强可解释性。

Result: MRMBench与大语言模型的对齐性能高度相关；实验表明当前奖励模型在多维度偏好捕捉上存在困难；推理时探测能有效评估奖励预测置信度并提升模型对齐效果。

Conclusion: 多维探测评估方法有助于开发更优的奖励模型，支持多目标优化方向，并提高奖励模型的可靠性和可解释性。

Abstract: Previous methods evaluate reward models by testing them on a fixed pairwise ranking test set, but they typically do not provide performance information on each preference dimension. In this work, we address the evaluation challenge of reward models by probing preference representations. To confirm the effectiveness of this evaluation method, we construct a Multi-dimensional Reward Model Benchmark (MRMBench), a collection of six probing tasks for different preference dimensions. We design it to favor and encourage reward models that better capture preferences across different dimensions. Furthermore, we introduce an analysis method, inference-time probing, which identifies the dimensions used during the reward prediction and enhances its interpretability. Through extensive experiments, we find that MRMBench strongly correlates with the alignment performance of large language models (LLMs), making it a reliable reference for developing advanced reward models. Our analysis of MRMBench evaluation results reveals that reward models often struggle to capture preferences across multiple dimensions, highlighting the potential of multi-objective optimization in reward modeling. Additionally, our findings show that the proposed inference-time probing method offers a reliable metric for assessing the confidence of reward predictions, which ultimately improves the alignment of LLMs.

</details>


### [330] [Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing](https://arxiv.org/abs/2511.12472)
*Mengying Wang,Chenhui Ma,Ao Jiao,Tuo Liang,Pengjun Lu,Shrinidhi Hegde,Yu Yin,Evren Gurkan-Cavusoglu,Yinghui Wu*

Main category: cs.CL

TL;DR: 本文提出了SerenQA框架，用于评估大语言模型在科学知识图谱问答中发现意外洞察（即“惊喜”答案）的能力，定义了基于相关性、新颖性和惊喜度的指标，并通过临床知识图构建了专注于药物重定位的基准测试，实验表明当前LLM在检索任务上表现良好，但在发现真正惊喜且有价值的发现方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱问答系统多优化于返回高度相关但可预测的答案，缺乏发现惊喜和新颖答案的能力，而这种能力在科学发现（如药物重定位）中具有重要价值。

Method: 提出SerenQA框架，包含一个基于相关性、新颖性和惊喜度的严谨指标，构建了专家标注的临床知识图基准数据集，并设计了涵盖知识检索、子图推理和惊喜探索三个子任务的结构化评估流程。

Result: 实验结果显示当前最先进的大语言模型在知识检索任务上表现良好，但在识别真正具有惊喜性和价值的发现方面仍存在困难，说明该领域仍有较大改进空间。

Conclusion: SerenQA为评估LLM在科学KGQA中的惊喜发现能力提供了有效框架和资源，揭示了当前模型的局限性，并为未来研究指明方向。

Abstract: Large Language Models (LLMs) have greatly advanced knowledge graph question answering (KGQA), yet existing systems are typically optimized for returning highly relevant but predictable answers. A missing yet desired capacity is to exploit LLMs to suggest surprise and novel ("serendipitious") answers. In this paper, we formally define the serendipity-aware KGQA task and propose the SerenQA framework to evaluate LLMs' ability to uncover unexpected insights in scientific KGQA tasks. SerenQA includes a rigorous serendipity metric based on relevance, novelty, and surprise, along with an expert-annotated benchmark derived from the Clinical Knowledge Graph, focused on drug repurposing. Additionally, it features a structured evaluation pipeline encompassing three subtasks: knowledge retrieval, subgraph reasoning, and serendipity exploration. Our experiments reveal that while state-of-the-art LLMs perform well on retrieval, they still struggle to identify genuinely surprising and valuable discoveries, underscoring a significant room for future improvements. Our curated resources and extended version are released at: https://cwru-db-group.github.io/serenQA.

</details>


### [331] [SGuard-v1: Safety Guardrail for Large Language Models](https://arxiv.org/abs/2511.12497)
*JoonHo Lee,HyeonMin Cho,Jaewoong Yun,Hyunjae Lee,JunKyu Lee,Juree Seok*

Main category: cs.CL

TL;DR: SGuard-v1 是一个轻量级的大型语言模型安全防护系统，包含两个专用模型：ContentFilter 用于检测提示和响应中的安全风险，JailbreakFilter 用于识别对抗性越狱攻击，支持12种语言，在多个基准测试中达到先进水平。


<details>
  <summary>Details</summary>
Motivation: 为应对大型语言模型在人类-AI 对话中面临的安全风险和越狱攻击，需要一种高效、可解释且易于部署的轻量级安全防护机制。

Method: 基于 20 亿参数的 Granite-3.3-2B-Instruct 模型构建双组件系统；使用约 140 万条数据进行指令微调，其中 ContentFilter 遵循 MLCommons 危害分类体系，JailbreakFilter 采用基于60种主要攻击类型的课程学习策略。

Result: SGuard-v1 在公共和专有安全基准上实现了最先进的安全性能，具备多语言支持、多类别安全预测和置信度评分，显著降低部署开销。

Conclusion: SGuard-v1 是一种高效、轻量且可解释的 LLM 安全防护方案，已在 Apache-2.0 许可下开源，推动 AI 安全领域的研究与实际应用。

Abstract: We present SGuard-v1, a lightweight safety guardrail for Large Language Models (LLMs), which comprises two specialized models to detect harmful content and screen adversarial prompts in human-AI conversational settings. The first component, ContentFilter, is trained to identify safety risks in LLM prompts and responses in accordance with the MLCommons hazard taxonomy, a comprehensive framework for trust and safety assessment of AI. The second component, JailbreakFilter, is trained with a carefully designed curriculum over integrated datasets and findings from prior work on adversarial prompting, covering 60 major attack types while mitigating false-unsafe classification. SGuard-v1 is built on the 2B-parameter Granite-3.3-2B-Instruct model that supports 12 languages. We curate approximately 1.4 million training instances from both collected and synthesized data and perform instruction tuning on the base model, distributing the curated data across the two component according to their designated functions. Through extensive evaluation on public and proprietary safety benchmarks, SGuard-v1 achieves state-of-the-art safety performance while remaining lightweight, thereby reducing deployment overhead. SGuard-v1 also improves interpretability for downstream use by providing multi-class safety predictions and their binary confidence scores. We release the SGuard-v1 under the Apache-2.0 License to enable further research and practical deployment in AI safety.

</details>


### [332] [QA-Noun: Representing Nominal Semantics via Natural Language Question-Answer Pairs](https://arxiv.org/abs/2511.12504)
*Maria Tseytlin,Paul Roit,Omri Abend,Ido Dagan,Ayal Klein*

Main category: cs.CL

TL;DR: 本文提出了QA-Noun，一种基于问答的名词中心语义关系捕捉框架，通过九种问题模板覆盖名词的显式句法和隐式上下文角色，与QA-SRL结合实现句子意义的细粒度统一分解，显著提升了语义分解的粒度和覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 现有的基于问答的语义方法主要关注谓词-论元关系，而忽视了以名词为中心的语义关系，因此需要一种能够补全这一空白的方法来实现更全面的语义分解。

Method: 提出QA-Noun框架，定义九种问题模板用于提取名词的显式和隐式语义角色，发布标注数据集、详细标注指南，并训练集成QA-SRL的模型，实现句子语义的统一细粒度分解。

Result: QA-Noun实现了对AMR中名词论元的近完整覆盖，并揭示了更多上下文隐含关系；与QA-SRL结合后，语义分解粒度比FactScore和DecompScore等方法高出130%以上。

Conclusion: QA-Noun有效补充了现有QA-based语义框架，形成了一种全面且可扩展的细粒度语义分解方法，有助于跨文本对齐任务。

Abstract: Decomposing sentences into fine-grained meaning units is increasingly used to model semantic alignment. While QA-based semantic approaches have shown effectiveness for representing predicate-argument relations, they have so far left noun-centered semantics largely unaddressed. We introduce QA-Noun, a QA-based framework for capturing noun-centered semantic relations. QA-Noun defines nine question templates that cover both explicit syntactical and implicit contextual roles for nouns, producing interpretable QA pairs that complement verbal QA-SRL. We release detailed guidelines, a dataset of over 2,000 annotated noun mentions, and a trained model integrated with QA-SRL to yield a unified decomposition of sentence meaning into individual, highly fine-grained, facts. Evaluation shows that QA-Noun achieves near-complete coverage of AMR's noun arguments while surfacing additional contextually implied relations, and that combining QA-Noun with QA-SRL yields over 130\% higher granularity than recent fact-based decomposition methods such as FactScore and DecompScore. QA-Noun thus complements the broader QA-based semantic framework, forming a comprehensive and scalable approach to fine-grained semantic decomposition for cross-text alignment.

</details>


### [333] [TAdaRAG: Task Adaptive Retrieval-Augmented Generation via On-the-Fly Knowledge Graph Construction](https://arxiv.org/abs/2511.12520)
*Jie Zhang,Bo Tang,Wanzi Shao,Wenqiang Wei,Jihao Zhao,Jianqing Zhu,Zhiyu li,Wen Xi,Zehao Lin,Feiyu Xiong,Yanchao Tan*

Main category: cs.CL

TL;DR: 提出TAdaRAG，一种基于任务自适应知识图谱构建的检索增强生成框架，通过意图驱动的抽取机制提升推理准确性与信息完整性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG因文本分块截断和非结构化知识检索导致信息丢失、幻觉和推理链断裂，难以支持准确推理。

Method: 设计意图驱动的路由机制，结合领域特定抽取模板、监督微调和基于强化学习的隐式抽取机制，动态构建任务自适应的知识图谱。

Result: 在六个公开基准和一个真实业务数据集（NowNewsQA）上，基于三种主干模型的实验表明，TAdaRAG在多领域和长文本任务中均优于现有方法。

Conclusion: TAdaRAG能有效实现简洁、连贯、非冗余的知识整合，具有强泛化能力和实际应用价值。

Abstract: Retrieval-Augmented Generation (RAG) improves large language models by retrieving external knowledge, often truncated into smaller chunks due to the input context window, which leads to information loss, resulting in response hallucinations and broken reasoning chains. Moreover, traditional RAG retrieves unstructured knowledge, introducing irrelevant details that hinder accurate reasoning. To address these issues, we propose TAdaRAG, a novel RAG framework for on-the-fly task-adaptive knowledge graph construction from external sources. Specifically, we design an intent-driven routing mechanism to a domain-specific extraction template, followed by supervised fine-tuning and a reinforcement learning-based implicit extraction mechanism, ensuring concise, coherent, and non-redundant knowledge integration. Evaluations on six public benchmarks and a real-world business benchmark (NowNewsQA) across three backbone models demonstrate that TAdaRAG outperforms existing methods across diverse domains and long-text tasks, highlighting its strong generalization and practical effectiveness.

</details>


### [334] [Mitigating Length Bias in RLHF through a Causal Lens](https://arxiv.org/abs/2511.12573)
*Hyeonji Kim,Sujeong Oh,Sanghack Lee*

Main category: cs.CL

TL;DR: 提出一种基于反事实数据增强的因果框架，以减轻RLHF中奖励模型的长度偏差，使其能更专注于内容质量而非响应长度。


<details>
  <summary>Details</summary>
Motivation: RLHF训练的奖励模型常表现出长度偏差，即倾向于偏好更长的回答，从而混淆了冗长与质量的关系，影响模型对真实内容质量的判断。

Method: 构建反事实数据增强方法，生成两类样本对：(1) 内容相似但长度不同的回答对；(2) 长度相近但内容不同的回答对，以此分离内容质量和长度的影响，训练更公平的奖励模型。

Result: 实验表明该方法有效减少了奖励分配中的长度偏差，使策略模型输出更简洁、更注重内容的质量。

Conclusion: 所提方法能有效缓解RLHF中奖励模型的长度偏差问题，提升奖励建模的内容敏感性和鲁棒性。

Abstract: Reinforcement learning from human feedback (RLHF) is widely used to align large language models (LLMs) with human preferences. However, RLHF-trained reward models often exhibit length bias -- a systematic tendency to favor longer responses by conflating verbosity with quality. We propose a causal framework for analyzing and mitigating length bias in RLHF reward modeling. Central to our approach is a counterfactual data augmentation method that generates response pairs designed to isolate content quality from verbosity. These counterfactual examples are then used to train the reward model, enabling it to assess responses based on content quality independently of verbosity. Specifically, we construct (1) length-divergent pairs with similar content and (2) content-divergent pairs of similar length. Empirical evaluations show that our method reduces length bias in reward assignment and leads to more concise, content-focused outputs from the policy model. These findings demonstrate that the proposed approach effectively reduces length bias and improves the robustness and content sensitivity of reward modeling in RLHF pipelines.

</details>


### [335] [MMWOZ: Building Multimodal Agent for Task-oriented Dialogue](https://arxiv.org/abs/2511.12586)
*Pu-Hai Yang,Heyan Huang,Heng-Da Xu,Fanshu Sun,Xian-Ling Mao,Chaoxu Mu*

Main category: cs.CL

TL;DR: 本文提出了一个名为MMWOZ的多模态对话数据集，用于弥合传统任务导向型对话系统在缺乏后端API时与实际前端GUI应用之间的差距，并提出了MATE模型作为基线方法进行实验分析。


<details>
  <summary>Details</summary>
Motivation: 由于现实中广泛存在前端图形界面（GUI）而缺少定制化后端API，传统任务导向对话系统难以实际部署，因此需要构建能与GUI交互的新型多模态对话系统。

Method: 基于MultiWOZ 2.3构建MMWOZ数据集：开发网页式GUI作为前端，编写自动化脚本将原始对话状态和系统动作转化为GUI操作指令，并收集页面快照及对应操作指令；同时提出MATE多模态模型作为基线。

Result: 成功构建了包含GUI操作和视觉信息的MMWOZ多模态对话数据集，并通过MATE模型验证了其可行性，实验表明该方法有助于构建可与前端界面交互的实用型任务导向对话代理。

Conclusion: MMWOZ数据集和MATE模型为任务导向对话系统在无后端API环境下通过GUI完成任务提供了新的研究方向和实践基础。

Abstract: Task-oriented dialogue systems have garnered significant attention due to their conversational ability to accomplish goals, such as booking airline tickets for users. Traditionally, task-oriented dialogue systems are conceptualized as intelligent agents that interact with users using natural language and have access to customized back-end APIs. However, in real-world scenarios, the widespread presence of front-end Graphical User Interfaces (GUIs) and the absence of customized back-end APIs create a significant gap for traditional task-oriented dialogue systems in practical applications. In this paper, to bridge the gap, we collect MMWOZ, a new multimodal dialogue dataset that is extended from MultiWOZ 2.3 dataset. Specifically, we begin by developing a web-style GUI to serve as the front-end. Next, we devise an automated script to convert the dialogue states and system actions from the original dataset into operation instructions for the GUI. Lastly, we collect snapshots of the web pages along with their corresponding operation instructions. In addition, we propose a novel multimodal model called MATE (Multimodal Agent for Task-oriEnted dialogue) as the baseline model for the MMWOZ dataset. Furthermore, we conduct comprehensive experimental analysis using MATE to investigate the construction of a practical multimodal agent for task-oriented dialogue.

</details>


### [336] [Group-Aware Reinforcement Learning for Output Diversity in Large Language Models](https://arxiv.org/abs/2511.12596)
*Oron Anschel,Alon Shoshan,Adam Botach,Shunit Haviv Hakimi,Asaf Gendler,Emanuel Ben Baruch,Nadav Bhonker,Igor Kviatkovsky,Manoj Aggarwal,Gerard Medioni*

Main category: cs.CL

TL;DR: 本文提出了一种名为Group-Aware Policy Optimization (GAPO)的新方法，用于缓解大语言模型中的模式崩溃问题，提升生成结果的多样性，同时在多个标准基准上保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型常常出现模式崩溃，导致生成结果缺乏多样性，限制了其在多任务中的应用。

Method: GAPO是Group Relative Policy Optimization (GRPO)的扩展，通过在群体层面上计算奖励（如多样性与覆盖率），并采用频率感知的奖励函数，鼓励对有效补全结果的均匀采样。

Result: 实验表明，使用GAPO训练的模型能够生成更丰富多样的有效响应，在开放性提示下也表现良好，且在GSM8K、MATH、HumanEval和MMLU-Pro等基准测试中未牺牲准确性。

Conclusion: GAPO是一种简单而有效的方法，能够通过群体感知优化显著提升大语言模型的输出多样性，同时保持高性能。

Abstract: Large Language Models (LLMs) often suffer from mode collapse, repeatedly generating the same few completions even when many valid answers exist, limiting their diversity across a wide range of tasks. We introduce Group-Aware Policy Optimization (GAPO), a simple extension of the recent and popular Group Relative Policy Optimization (GRPO) that computes rewards over the group as a whole. GAPO enables learning from the group-level properties such as diversity and coverage. We demonstrate GAPO using a frequency-aware reward function that encourages uniform sampling over valid LLM completions, and show that GAPO-trained models produce valid and more diverse model responses. Beyond this setup, GAPO generalizes to open-ended prompts and improves response diversity without compromising accuracy on standard LLM benchmarks (GSM8K, MATH, HumanEval, MMLU-Pro). Our code will be made publicly available.

</details>


### [337] [Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with Advanced MoE, Training and Data](https://arxiv.org/abs/2511.12609)
*Yunxin Li,Xinyu Chen,Shenyuan Jiang,Haoyuan Shi,Zhenyu Liu,Xuanyu Zhang,Nanhao Deng,Zhenran Xu,Yicheng Ma,Meishan Zhang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: Uni-MoE 2.0 是一个基于 Qwen2.5-7B 架构的开源多模态大模型，通过动态容量 MoE 设计、渐进式训练策略和多模态数据匹配技术，在语言为中心的多模态理解、推理和生成方面取得显著进展。


<details>
  <summary>Details</summary>
Motivation: 为了提升现有多模态大模型在跨模态理解与生成任务中的性能和效率，尤其是在视频、音频和图像等复杂模态上的表现。

Method: 采用动态容量的 Mixture-of-Experts (MoE) 架构，结合共享、路由和空专家处理十种跨模态输入；引入 Omni-Modality 3D RoPE 实现自注意力层中的时空对齐；设计渐进式监督微调策略，结合迭代 GSPO-DPO 方法稳定强化学习并提升推理能力；使用约 750 亿 token 的开源多模态数据进行训练，并引入语音和图像生成特殊标记。

Result: 在 85 个基准测试中表现出色，超过 76 个中的 50 个优于使用 1.2T token 训练的 Qwen2.5-Omni；在视频理解（+7% 平均）、多模态理解（+7% 平均）和音视频推理（+4%）方面表现突出；语音识别词错率降低 4.2%，在低级图像处理和可控生成五个指标上领先。

Conclusion: Uni-MoE 2.0 在计算效率和多模态能力之间实现了良好平衡，展示了强大的跨模态理解与生成能力，是当前领先的开源多模态大模型之一。

Abstract: We present Uni-MoE 2.0 from the Lychee family. As a fully open-source omnimodal large model (OLM), it substantially advances Lychee's Uni-MoE series in language-centric multimodal understanding, reasoning, and generating. Based on the Qwen2.5-7B dense architecture, we build Uni-MoE-2.0-Omni from scratch through three core contributions: dynamic-capacity Mixture-of-Experts (MoE) design, a progressive training strategy enhanced with an iterative reinforcement strategy, and a carefully curated multimodal data matching technique. It is capable of omnimodal understanding, as well as generating images, text, and speech. Architecturally, our new MoE framework balances computational efficiency and capability for 10 cross-modal inputs using shared, routed, and null experts, while our Omni-Modality 3D RoPE ensures spatio-temporal cross-modality alignment in the self-attention layer. For training, following cross-modal pretraining, we use a progressive supervised fine-tuning strategy that activates modality-specific experts and is enhanced by balanced data composition and an iterative GSPO-DPO method to stabilise RL training and improve reasoning. Data-wise, the base model, trained on approximately 75B tokens of open-source multimodal data, is equipped with special speech and image generation tokens, allowing it to learn these generative tasks by conditioning its outputs on linguistic cues. Extensive evaluation across 85 benchmarks demonstrates that our model achieves SOTA or highly competitive performance against leading OLMs, surpassing Qwen2.5-Omni (trained with 1.2T tokens) on over 50 of 76 benchmarks. Key strengths include video understanding (+7% avg. of 8), omnimodallity understanding (+7% avg. of 4), and audiovisual reasoning (+4%). It also advances long-form speech processing (reducing WER by 4.2%) and leads in low-level image processing and controllable generation across 5 metrics.

</details>


### [338] [Knots: A Large-Scale Multi-Agent Enhanced Expert-Annotated Dataset and LLM Prompt Optimization for NOTAM Semantic Parsing](https://arxiv.org/abs/2511.12630)
*Maoqi Liu,Quan Fang,Yang Yang,Can Zhao,Kaiquan Cai*

Main category: cs.CL

TL;DR: 本文提出了NOTAM语义解析任务，旨在通过结合航空领域知识实现对NOTAM文本的深度语义理解，并构建了包含12,347条专家标注数据的高质量数据集Knots，采用多智能体协作框架提升字段覆盖，实验验证了不同提示工程与模型适配技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中于NOTAM的表层任务，缺乏对其深层语义和推理的理解，难以满足自动化解析对安全关键信息准确提取的需求。

Method: 提出NOTAM语义解析任务，构建Knots数据集，采用多代理协作框架进行字段发现，并系统评估多种提示工程策略和模型适应技术。

Result: 在航空文本理解与处理方面实现了显著性能提升，验证了所提方法在自动化NOTAM分析中的有效性。

Conclusion: 该研究填补了NOTAM深层语义理解的空白，为构建可靠的自动化飞行安全信息处理系统提供了重要基础和实践指导。

Abstract: Notice to Air Missions (NOTAMs) serve as a critical channel for disseminating key flight safety information, yet their complex linguistic structures and implicit reasoning pose significant challenges for automated parsing. Existing research mainly focuses on surface-level tasks such as classification and named entity recognition, lacking deep semantic understanding. To address this gap, we propose NOTAM semantic parsing, a task emphasizing semantic inference and the integration of aviation domain knowledge to produce structured, inference-rich outputs. To support this task, we construct Knots (Knowledge and NOTAM Semantics), a high-quality dataset of 12,347 expert-annotated NOTAMs covering 194 Flight Information Regions, enhanced through a multi-agent collaborative framework for comprehensive field discovery. We systematically evaluate a wide range of prompt-engineering strategies and model-adaptation techniques, achieving substantial improvements in aviation text understanding and processing. Our experimental results demonstrate the effectiveness of the proposed approach and offer valuable insights for automated NOTAM analysis systems. Our code is available at: https://github.com/Estrellajer/Knots.

</details>


### [339] [Reason-KE++: Aligning the Process, Not Just the Outcome, for Faithful LLM Knowledge Editing](https://arxiv.org/abs/2511.12661)
*Yuchen Wu,Liang Ding,Li Shen,Dacheng Tao*

Main category: cs.CL

TL;DR: 提出Reason-KE++，一种结合SFT与强化学习的框架，通过阶段感知奖励机制提升大模型在多跳推理任务中对新知识的忠实性，解决了传统方法仅模仿格式而忽视推理正确性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于监督微调的方法（如Reason-KE）在多跳推理任务中存在“忠实性差距”，倾向于模仿输出格式而非保持推理一致性，导致模型忽略新知识并产生事实性幻觉。

Method: 提出Reason-KE++，采用SFT+RL框架，引入阶段感知奖励机制，对分解、子答案正确性等中间推理步骤提供密集监督，确保整个推理过程的忠实性。

Result: 在MQUAKE-CF-3k数据集上达到95.48%的新SOTA性能（+5.28%），显著优于基线；发现仅优化最终结果的强化学习会破坏推理完整性（如Hop准确率下降19.00%）。

Conclusion: 在复杂多跳推理任务中，必须对推理过程进行对齐，而不仅仅是输出结果，才能构建可信的大语言模型。

Abstract: Aligning Large Language Models (LLMs) to be faithful to new knowledge in complex, multi-hop reasoning tasks is a critical, yet unsolved, challenge. We find that SFT-based methods, e.g., Reason-KE, while state-of-the-art, suffer from a "faithfulness gap": they optimize for format mimicry rather than sound reasoning. This gap enables the LLM's powerful parametric priors to override new contextual facts, resulting in critical factual hallucinations (e.g., incorrectly reasoning "Houston" from "NASA" despite an explicit edit). To solve this core LLM alignment problem, we propose Reason-KE++, an SFT+RL framework that instills process-level faithfulness. Its core is a Stage-aware Reward mechanism that provides dense supervision for intermediate reasoning steps (e.g., Decomposition, Sub-answer Correctness). Crucially, we identify that naive outcome-only RL is a deceptive trap for LLM alignment: it collapses reasoning integrity (e.g., 19.00% Hop acc) while superficially boosting final accuracy. Our process-aware framework sets a new SOTA of 95.48% on MQUAKE-CF-3k (+5.28%), demonstrating that for complex tasks, aligning the reasoning process is essential for building trustworthy LLMs.

</details>


### [340] [Improving Direct Persian-English Speech-to-Speech Translation with Discrete Units and Synthetic Parallel Data](https://arxiv.org/abs/2511.12690)
*Sina Rashidi,Hossein Sameti*

Main category: cs.CL

TL;DR: 本文提出了一种用于波斯语到英语的直接语音-语音翻译（S2ST）系统，并通过合成平行语料缓解低资源语言的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 由于低资源语言（如波斯语）缺乏足够的平行语音数据，直接S2ST模型难以训练，因此需要有效方法来提升翻译性能。

Method: 采用三部分模型：基于Conformer的编码器、因果Transformer解码器和基于单元的神经声码器；并通过大语言模型翻译波斯语文本并使用零样本文本转语音系统合成英文语音，构建新的平行语料库。

Result: 在CVSS语料库的波斯-英语部分，使用合成数据后ASR BLEU提升了4.6分，可用平行语音数据增加了约六倍。

Conclusion: 结合自监督预训练、离散语音单元和合成平行数据的方法，在低资源语言对（如波斯-英语）的直接S2ST中表现有效。

Abstract: Direct speech-to-speech translation (S2ST), in which all components are trained jointly, is an attractive alternative to cascaded systems because it offers a simpler pipeline and lower inference latency. However, direct S2ST models require large amounts of parallel speech data in the source and target languages, which are rarely available for low-resource languages such as Persian. This paper presents a direct S2ST system for translating Persian speech into English speech, as well as a pipeline for synthetic parallel Persian-English speech generation. The model comprises three components: (1) a conformer-based encoder, initialized from self-supervised pre-training, maps source speech to high-level acoustic representations; (2) a causal transformer decoder with relative position multi-head attention translates these representations into discrete target speech units; (3) a unit-based neural vocoder generates waveforms from the predicted discrete units. To mitigate the data scarcity problem, we construct a new Persian-English parallel speech corpus by translating Persian speech transcriptions into English using a large language model and then synthesizing the corresponding English speech with a state-of-the-art zero-shot text-to-speech system. The resulting corpus increases the amount of available parallel speech by roughly a factor of six. On the Persian-English portion of the CVSS corpus, the proposed model achieves improvement of 4.6 ASR BLEU with the synthetic data over direct baselines. These results indicate that combining self-supervised pre-training, discrete speech units, and synthetic parallel data is effective for improving direct S2ST in low-resource language pairs such as Persian-English

</details>


### [341] [Evolve the Method, Not the Prompts: Evolutionary Synthesis of Jailbreak Attacks on LLMs](https://arxiv.org/abs/2511.12710)
*Yunhao Chen,Xin Wang,Juncheng Li,Yixu Wang,Jie Li,Yan Teng,Yingchun Wang,Xingjun Ma*

Main category: cs.CL

TL;DR: 本文提出了EvoSynth，一种通过多智能体系统自主生成、进化和执行新型代码级攻击算法的自动化红队框架，突破了传统方法仅依赖现有攻击策略组合或优化的局限，实现了更高的攻击成功率和攻击多样性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化红队框架受限于预设攻击策略，缺乏自主创新能力，难以生成全新的越狱方法。

Method: 提出EvoSynth框架，采用多智能体系统进行攻击算法的自主设计与演化，并引入代码级自修正循环机制，使其能在失败后迭代重写自身攻击逻辑。

Result: 实验表明，EvoSynth在Claude-Sonnet-4.5等强健模型上达到85.5%的攻击成功率，显著优于现有方法，且生成的攻击更具多样性。

Conclusion: EvoSynth实现了从攻击规划到攻击方法进化合成的范式转变，为LLM安全评估开辟了新方向。

Abstract: Automated red teaming frameworks for Large Language Models (LLMs) have become increasingly sophisticated, yet they share a fundamental limitation: their jailbreak logic is confined to selecting, combining, or refining pre-existing attack strategies. This binds their creativity and leaves them unable to autonomously invent entirely new attack mechanisms. To overcome this gap, we introduce \textbf{EvoSynth}, an autonomous framework that shifts the paradigm from attack planning to the evolutionary synthesis of jailbreak methods. Instead of refining prompts, EvoSynth employs a multi-agent system to autonomously engineer, evolve, and execute novel, code-based attack algorithms. Crucially, it features a code-level self-correction loop, allowing it to iteratively rewrite its own attack logic in response to failure. Through extensive experiments, we demonstrate that EvoSynth not only establishes a new state-of-the-art by achieving an 85.5\% Attack Success Rate (ASR) against highly robust models like Claude-Sonnet-4.5, but also generates attacks that are significantly more diverse than those from existing methods. We release our framework to facilitate future research in this new direction of evolutionary synthesis of jailbreak methods. Code is available at: https://github.com/dongdongunique/EvoSynth.

</details>


### [342] [Adaptive Focus Memory for Language Models](https://arxiv.org/abs/2511.12712)
*Christopher Cruz*

Main category: cs.CL

TL;DR: 提出了一种名为Adaptive Focus Memory (AFM)的动态上下文管理方法，通过语义相似性、重要性分类和时效性为对话历史分配不同保真度（FULL、COMPRESSED、PLACEHOLDER），在保证安全关键信息保留的同时显著降低token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对话系统受限于固定上下文窗口和简单的记忆策略，如全回放成本高，而静态摘要或仅保留最近内容易丢失安全关键信息。需要一种既能节省计算资源又能保持对话关键细节的方法。

Method: AFM根据语义相似性、半衰期时效权重和重要性分类，动态将历史消息划分为三种保真级别，并在严格token预算下按时间顺序打包消息，优先保留最相关轮次的高保真版本，同时保留对话的低成本痕迹。

Result: 在涉及严重花生过敏用户的模拟旅行规划任务中，AFM在短到中等长度对话中均成功保留了过敏信息，安全表现与全回放相当，但相比基线平均减少66%的token使用。

Conclusion: AFM在不牺牲安全性和事实连贯性的前提下显著降低了多轮对话的推理成本，适用于OpenAI兼容API和离线操作，具有实际应用价值。

Abstract: Large language models (LLMs) are increasingly deployed in multi-turn dialogue settings, but their behavior is still bottlenecked by fixed context windows and naive memory strategies. Replaying the full conversation at every turn is simple but expensive, while static summarization or recency-only heuristics often erase safety-critical user details. We present Adaptive Focus Memory (AFM), a dynamic context manager that assigns each past message one of three fidelity levels -- FULL, COMPRESSED, or PLACEHOLDER -- based on semantic similarity to the current query, half-life recency weighting, and importance classification. AFM packs messages chronologically under a strict token budget, preferring high fidelity for the most relevant turns while aiming to preserve a cheap trace of the dialogue. In a safety-oriented benchmark involving a user with a severe peanut allergy planning a trip to Thailand, AFM retains the allergy across both short and medium-length conversations, matches the safety performance of naive replay, and cuts average token usage by 66% relative to a replay baseline. We release a modular Python implementation of AFM designed for OpenAI-compatible APIs and offline operation, enabling practitioners to reduce inference cost without sacrificing safety or factual continuity in the evaluated scenario.

</details>


### [343] [On the Brittleness of LLMs: A Journey around Set Membership](https://arxiv.org/abs/2511.12728)
*Lea Hergert,Gábor Berend,Mario Szegedy,Gyorgy Turan,Márk Jelasity*

Main category: cs.CL

TL;DR: 该论文研究了大语言模型（LLMs）在集合成员查询这一基本推理任务上的表现，发现尽管问题简单，LLM的表现仍然脆弱且不可预测，揭示其对“集合”概念的理解是碎片化和混乱的。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在复杂任务上表现出色却在简单问题上频繁失败的悖论，以评估其可靠性和可解释性。

Method: 通过大规模系统性实验，分析不同提示措辞、语义结构、元素顺序和模型选择下，LLM在集合成员查询任务上的表现。

Result: 实验表明LLM在该基本任务上表现脆弱且结果不可预测，显示出其对集合概念的理解不完整且不稳定。

Conclusion: LLM在基础推理任务上的不可靠性提示其内部机制仍存在根本缺陷，而基于简单问题的大规模实验是评估LLM的有效方法。

Abstract: Large language models (LLMs) achieve superhuman performance on complex reasoning tasks, yet often fail on much simpler problems, raising concerns about their reliability and interpretability. We investigate this paradox through a focused study with two key design features: simplicity, to expose basic failure modes, and scale, to enable comprehensive controlled experiments. We focus on set membership queries -- among the most fundamental forms of reasoning -- using tasks like ``Is apple an element of the set \{pear, plum, apple, raspberry\}?''. We conduct a systematic empirical evaluation across prompt phrasing, semantic structure, element ordering, and model choice. Our large-scale analysis reveals that LLM performance on this elementary task is consistently brittle, and unpredictable across all dimensions, suggesting that the models' ``understanding'' of the set concept is fragmented and convoluted at best. Our work demonstrates that the large-scale experiments enabled by the simplicity of the problem allow us to map and analyze the failure modes comprehensively, making this approach a valuable methodology for LLM evaluation in general.

</details>


### [344] [Evidence of Phase Transitions in Small Transformer-Based Language Models](https://arxiv.org/abs/2511.12768)
*Noah Hong,Tao Hong*

Main category: cs.CL

TL;DR: 该研究发现，即使在小型语言模型中，训练过程中也会出现相变现象，表现为词汇使用和组织方式的突然转变，这种转变可通过基于词汇和统计的探测方法在训练早期、线性尺度下观察到，而不会体现在传统的损失或验证曲线上。


<details>
  <summary>Details</summary>
Motivation: 探究相变是否仅存在于大模型中，能否在小模型、线性训练空间及训练早期观察到相变现象，以揭示语言模型训练中的非线性动态机制。

Method: 训练一个小型GPT风格的字符级语言模型，追踪训练过程中词汇使用的变化（如平均词长、正确与错误词数、词汇多样性），并结合泊松和次泊松统计分析词汇连接与重组模式。

Result: 发现训练过程中存在明显的相变点，该相变无法通过标准损失曲线检测，但可通过提出的词汇与统计指标清晰识别，且出现在训练早期、线性尺度下。

Conclusion: 相变是语言模型训练的普遍特征，不仅限于大模型，可在小模型、线性空间和早期训练中被观测到，强调了设计专用指标对理解模型训练动态的重要性。

Abstract: Phase transitions have been proposed as the origin of emergent abilities in large language models (LLMs), where new capabilities appear abruptly once models surpass critical thresholds of scale. Prior work, such as that of Wei et al., demonstrated these phenomena under model and data scaling, with transitions revealed after applying a log scale to training compute. In this work, we ask three complementary questions: (1) Are phase transitions unique to large models, or can they also be observed in small transformer-based language models? (2) Can such transitions be detected directly in linear training space, rather than only after log rescaling? and (3) Can these transitions emerge at early stages of training? To investigate, we train a small GPT-style transformer on a character-level corpus and analyze the evolution of vocabulary usage throughout training. We track the average word length, the number of correct versus incorrect words, and shifts in vocabulary diversity. Building on these measures, we apply Poisson and sub-Poisson statistics to quantify how words connect and reorganize. This combined analysis reveals a distinct transition point during training. Notably, these transitions are not apparent in standard loss or validation curves, but become visible through our vocabulary- and statistics-based probes. Our findings suggest that phase-transition reorganizations are a general feature of language model training, observable even in modest models, detectable directly in linear training space, and occurring surprisingly early as coherence emerges. This perspective provides new insight into the nonlinear dynamics of language model training and underscores the importance of tailored metrics for uncovering phase transition behaviors

</details>


### [345] [LLM Reinforcement in Context](https://arxiv.org/abs/2511.12782)
*Thomas Rivasseau*

Main category: cs.CL

TL;DR: 提出使用“中断”作为增强大语言模型对齐性的方法，通过在用户输入中定期插入控制语句来应对随输入长度增加而升高的越狱风险。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型对齐研究缺乏能随用户输入长度扩展的防御机制，且长输入会增加越狱概率。

Method: 在用户输入中每隔约x个token插入控制句子（即“中断”），并可推广至思维链过程以防止模型策略性行为。

Result: 该方法有望提升模型在长输入下的对齐鲁棒性，但尚未提供具体实验验证。

Conclusion: 中断是一种有潜力的、可扩展的对齐强化手段，尤其适用于对抗长输入引发的越狱问题。

Abstract: Current Large Language Model alignment research mostly focuses on improving model robustness against adversarial attacks and misbehavior by training on examples and prompting. Research has shown that LLM jailbreak probability increases with the size of the user input or conversation length. There is a lack of appropriate research into means of strengthening alignment which also scale with user input length. We propose interruptions as a possible solution to this problem. Interruptions are control sentences added to the user input approximately every x tokens for some arbitrary x. We suggest that this can be generalized to the Chain-of-Thought process to prevent scheming.

</details>


### [346] [Evaluating Autoformalization Robustness via Semantically Similar Paraphrasing](https://arxiv.org/abs/2511.12784)
*Hayden Moore,Asfahan Shah*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）在自动形式化任务中对语义保持的自然语言改写输入的鲁棒性，发现在MiniF2F和ProofNet基准上，即使语义一致，微小的语言变化也会显著影响形式化输出的正确性和编译有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在自动形式化方面表现良好，但在不同表述下生成可验证形式化的能力尚不清楚；受文本到SQL任务中LLM对改写敏感的启发，本文探究其在形式化证明生成中的鲁棒性问题。

Method: 使用MiniF2F和Lean 4版ProofNet两个基准数据集，选取两个现代LLM，生成语义相似的自然语言改写，并跨模型评估其生成的形式证明在语义和编译有效性上的表现。

Result: 实验结果显示，不同改写版本的自然语言输入会导致模型性能出现显著波动，表明LLMs在自动形式化任务中对输入表述方式高度敏感。

Conclusion: 当前LLMs在自动形式化中缺乏对自然语言改写的鲁棒性，未来工作需增强模型对语义等价输入的一致性与稳定性。

Abstract: Large Language Models (LLMs) have recently emerged as powerful tools for autoformalization. Despite their impressive performance, these models can still struggle to produce grounded and verifiable formalizations. Recent work in text-to-SQL, has revealed that LLMs can be sensitive to paraphrased natural language (NL) inputs, even when high degrees of semantic fidelity are preserved (Safarzadeh, Oroojlooyjadid, and Roth 2025). In this paper, we investigate this claim in the autoformalization domain. Specifically, we evaluate the robustness of LLMs generating formal proofs with semantically similar paraphrased NL statements by measuring semantic and compilation validity. Using the formal benchmarks MiniF2F (Zheng, Han, and Polu 2021) and Lean 4 version of ProofNet (Xin et al. 2024), and two modern LLMs, we generate paraphrased natural language statements and cross-evaluate these statements across both models. The results of this paper reveal performance variability across paraphrased inputs, demonstrating that minor shifts in NL statements can significantly impact model outputs.

</details>


### [347] [BioMedJImpact: A Comprehensive Dataset and LLM Pipeline for AI Engagement and Scientific Impact Analysis of Biomedical Journals](https://arxiv.org/abs/2511.12821)
*Ruiyu Wang,Yuzhang Xie,Xiao Hu,Carl Yang,Jiaying Lu*

Main category: cs.CL

TL;DR: 本文提出了一个面向生物医学领域的大型数据集BioMedJImpact，整合了文献计量、合作特征和基于大模型的AI参与度指标，用于分析期刊影响力与AI研究及合作结构的关系。


<details>
  <summary>Details</summary>
Motivation: 现有开放资源难以捕捉合作结构和人工智能研究如何共同影响生物医学期刊的声望，因此需要一个综合性的数据集来推动科学影响力在期刊层面的分析。

Method: 基于174万篇PubMed Central文章构建覆盖2744种期刊的数据集，提出三阶段大模型流水线提取AI参与度特征，并结合文献计量与合作网络特征进行分析。

Result: 发现合作强度更高（尤其是作者团队更大更多样）的期刊具有更高的引用影响力；AI参与度与期刊声望显著正相关，尤其在四分位排名中更为明显；人工评估验证了所提LLM流水线的有效性。

Conclusion: BioMedJImpact不仅是一个涵盖生物医学与AI交叉领域的综合性数据集，也为可扩展、内容感知的科学计量分析提供了经过验证的方法框架。

Abstract: Assessing journal impact is central to scholarly communication, yet existing open resources rarely capture how collaboration structures and artificial intelligence (AI) research jointly shape venue prestige in biomedicine. We present BioMedJImpact, a large-scale, biomedical-oriented dataset designed to advance journal-level analysis of scientific impact and AI engagement. Built from 1.74 million PubMed Central articles across 2,744 journals, BioMedJImpact integrates bibliometric indicators, collaboration features, and LLM-derived semantic indicators for AI engagement. Specifically, the AI engagement feature is extracted through a reproducible three-stage LLM pipeline that we propose. Using this dataset, we analyze how collaboration intensity and AI engagement jointly influence scientific impact across pre- and post-pandemic periods (2016-2019, 2020-2023). Two consistent trends emerge: journals with higher collaboration intensity, particularly those with larger and more diverse author teams, tend to achieve greater citation impact, and AI engagement has become an increasingly strong correlate of journal prestige, especially in quartile rankings. To further validate the three-stage LLM pipeline we proposed for deriving the AI engagement feature, we conduct human evaluation, confirming substantial agreement in AI relevance detection and consistent subfield classification. Together, these contributions demonstrate that BioMedJImpact serves as both a comprehensive dataset capturing the intersection of biomedicine and AI, and a validated methodological framework enabling scalable, content-aware scientometric analysis of scientific impact and innovation dynamics. Code is available at https://github.com/JonathanWry/BioMedJImpact.

</details>


### [348] [From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation](https://arxiv.org/abs/2511.12832)
*Niranjan Chebrolu,Gerard Christopher Yeo,Kokil Jaidka*

Main category: cs.CL

TL;DR: 本文提出了一种通过激活工程来增强大语言模型情感表达的方法，利用归因补丁和对比文本对生成情感表达向量，显著提升了LLaMA 3.1-8B在对话中的人类情感特征。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在对话流畅性方面取得进展，但在实现类人的情感表达上仍面临挑战。现有对齐技术往往仅处理表层输出或需要大量微调，缺乏精确性和可解释性。

Method: 采用归因补丁识别因果关键组件，并通过对比正负情感文本对的激活差异构建情感表达向量，将其应用于新提示以引导模型输出更具情感色彩的回应。

Result: 引导后的模型响应表现出更强的正面情绪（如喜悦、信任）和更多第一人称代词使用，表明其更具个人参与感和情感细腻度。

Conclusion: 该方法为提升对话AI的情感表达提供了一个精准、可解释的新框架，推动了情感化对话系统的研究方向。

Abstract: Large Language Models (LLMs) demonstrate increasing conversational fluency, yet instilling them with nuanced, human-like emotional expression remains a significant challenge. Current alignment techniques often address surface-level output or require extensive fine-tuning. This paper demonstrates that targeted activation engineering can steer LLaMA 3.1-8B to exhibit more human-like emotional nuances. We first employ attribution patching to identify causally influential components, to find a key intervention locus by observing activation patterns during diagnostic conversational tasks. We then derive emotional expression vectors from the difference in the activations generated by contrastive text pairs (positive vs. negative examples of target emotions). Applying these vectors to new conversational prompts significantly enhances emotional characteristics: steered responses show increased positive sentiment (e.g., joy, trust) and more frequent first-person pronoun usage, indicative of greater personal engagement. Our findings offer a precise and interpretable framework and new directions for the study of conversational AI.

</details>


### [349] [Quantifying consistency and accuracy of Latent Dirichlet Allocation](https://arxiv.org/abs/2511.12850)
*Saranzaya Magsarjav,Melissa Humphries,Jonathan Tuke,Lewis Mitchell*

Main category: cs.CL

TL;DR: 本文提出了一种新的稳定性度量方法，用于评估LDA主题模型的准确性和一致性，并通过生成具有真实主题的语料库验证发现LDA虽具内部一致性，但所生成的主题并非真实主题。


<details>
  <summary>Details</summary>
Motivation: 由于概率主题模型（如LDA）具有随机性，导致结果不可重复，影响可解释性和可靠性，因此需要评估其稳定性和真实性。

Method: 定义了一种结合准确性与一致性的新稳定性度量方法，并利用LDA的生成特性创建带有真实主题标签的语料库，运行LDA 50次以分析输出变异性。

Result: 实验表明LDA能正确识别文档中潜在主题的数量，且多次运行结果具有较高内部一致性，但这些主题与真实主题不符。

Conclusion: LDA模型在内部一致性上表现良好，但其提取的主题可能并非真实主题，提示需谨慎解释模型输出。

Abstract: Topic modelling in Natural Language Processing uncovers hidden topics in large, unlabelled text datasets. It is widely applied in fields such as information retrieval, content summarisation, and trend analysis across various disciplines. However, probabilistic topic models can produce different results when rerun due to their stochastic nature, leading to inconsistencies in latent topics. Factors like corpus shuffling, rare text removal, and document elimination contribute to these variations. This instability affects replicability, reliability, and interpretation, raising concerns about whether topic models capture meaningful topics or just noise. To address these problems, we defined a new stability measure that incorporates accuracy and consistency and uses the generative properties of LDA to generate a new corpus with ground truth. These generated corpora are run through LDA 50 times to determine the variability in the output. We show that LDA can correctly determine the underlying number of topics in the documents. We also find that LDA is more internally consistent, as the multiple reruns return similar topics; however, these topics are not the true topics.

</details>


### [350] [NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation](https://arxiv.org/abs/2511.12851)
*Kang Yin,Hye-Bin Shin*

Main category: cs.CL

TL;DR: NeuroLex是一个专为临床脑电图（EEG）报告设计的轻量级领域自适应语言模型，基于哈佛EEG数据库文本训练，能够更好地捕捉EEG报告的语言和诊断特征，在多项任务中表现优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 通用语言模型无法充分捕捉临床脑电图报告中的领域特定语言模式和诊断逻辑，因此需要一个专门针对EEG报告的定制化语言模型。

Method: 采用纯EEG报告文本进行训练，通过span-corruption预训练和指令式微调，支持报告润色、段落摘要和术语问答等任务，构建EEG专属语言模型。

Result: NeuroLex在困惑度、信息提取准确率、摘要质量、标签效率以及对否定和事实幻觉的鲁棒性方面均优于同规模的通用语言模型。

Conclusion: NeuroLex为生物医学文本建模与脑机接口应用之间架起桥梁，为可解释的、语言驱动的神经解码提供了基础。

Abstract: Clinical electroencephalogram (EEG) reports encode domain-specific linguistic conventions that general-purpose language models (LMs) fail to capture. We introduce NeuroLex, a lightweight domain-adaptive language model trained purely on EEG report text from the Harvard Electroencephalography Database. Unlike existing biomedical LMs, NeuroLex is tailored to the linguistic and diagnostic characteristics of EEG reporting, enabling it to serve as both an independent textual model and a decoder backbone for multimodal EEG-language systems. Using span-corruption pretraining and instruction-style fine-tuning on report polishing, paragraph summarization, and terminology question answering, NeuroLex learns the syntax and reasoning patterns characteristic of EEG interpretation. Comprehensive evaluations show that it achieves lower perplexity, higher extraction and summarization accuracy, better label efficiency, and improved robustness to negation and factual hallucination compared with general models of the same scale. With an EEG-aware linguistic backbone, NeuroLex bridges biomedical text modeling and brain-computer interface applications, offering a foundation for interpretable and language-driven neural decoding.

</details>


### [351] [From Perception to Reasoning: Deep Thinking Empowers Multimodal Large Language Models](https://arxiv.org/abs/2511.12861)
*Wenxin Zhu,Andong Chen,Yuchen Song,Kehai Chen,Conghui Zhu,Ziyan Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With the remarkable success of Multimodal Large Language Models (MLLMs) in perception tasks, enhancing their complex reasoning capabilities has emerged as a critical research focus. Existing models still suffer from challenges such as opaque reasoning paths and insufficient generalization ability. Chain-of-Thought (CoT) reasoning, which has demonstrated significant efficacy in language models by enhancing reasoning transparency and output interpretability, holds promise for improving model reasoning capabilities when extended to the multimodal domain. This paper provides a systematic review centered on "Multimodal Chain-of-Thought" (MCoT). First, it analyzes the background and theoretical motivations for its inception from the perspectives of technical evolution and task demands. Then, it introduces mainstream MCoT methods from three aspects: CoT paradigms, the post-training stage, and the inference stage, while also analyzing their underlying mechanisms. Furthermore, the paper summarizes existing evaluation benchmarks and metrics, and discusses the application scenarios of MCoT. Finally, it analyzes the challenges currently facing MCoT and provides an outlook on its future research directions.

</details>


### [352] [Classification of Hope in Textual Data using Transformer-Based Models](https://arxiv.org/abs/2511.12874)
*Chukwuebuka Fortunate Ijezue,Tania-Amanda Fredrick Eneye,Maaz Amjad*

Main category: cs.CL

TL;DR: 本研究比较了BERT、GPT-2和DeBERTa三种Transformer模型在希望表达分类任务中的性能，发现BERT在准确率和计算效率上均优于更新的架构，表明在特定情感检测任务中模型适用性可能比规模更重要。


<details>
  <summary>Details</summary>
Motivation: 为了有效识别文本中的希望表达，推动心理健康和社交媒体分析等应用，需要比较不同Transformer架构在该细粒度情感分类任务中的性能与资源消耗。

Method: 采用BERT、GPT-2和DeBERTa三种Transformer模型进行二分类（希望 vs. 非希望）和多分类（五类希望相关类别）任务，并比较其准确率、训练时间和错误模式。

Result: BERT在二分类（84.49%）和多分类（72.03%）上表现最佳且训练时间最短（443秒）；GPT-2整体准确率最低但擅长识别讽刺（92.46%召回率）；DeBERTa性能中等但计算成本最高（多分类训练耗时947秒）。

Conclusion: 在希望表达分类任务中，模型架构的适用性比其规模更为重要，BERT在性能和效率之间取得了最佳平衡，为特定情感计算任务提供了实用框架。

Abstract: This paper presents a transformer-based approach for classifying hope expressions in text. We developed and compared three architectures (BERT, GPT-2, and DeBERTa) for both binary classification (Hope vs. Not Hope) and multiclass categorization (five hope-related categories). Our initial BERT implementation achieved 83.65% binary and 74.87% multiclass accuracy. In the extended comparison, BERT demonstrated superior performance (84.49% binary, 72.03% multiclass accuracy) while requiring significantly fewer computational resources (443s vs. 704s training time) than newer architectures. GPT-2 showed lowest overall accuracy (79.34% binary, 71.29% multiclass), while DeBERTa achieved moderate results (80.70% binary, 71.56% multiclass) but at substantially higher computational cost (947s for multiclass training). Error analysis revealed architecture-specific strengths in detecting nuanced hope expressions, with GPT-2 excelling at sarcasm detection (92.46% recall). This study provides a framework for computational analysis of hope, with applications in mental health and social media analysis, while demonstrating that architectural suitability may outweigh model size for specialized emotion detection tasks.

</details>


### [353] [Visual Room 2.0: Seeing is Not Understanding for MLLMs](https://arxiv.org/abs/2511.12928)
*Haokun Li,Yazhou Zhang,Jizhi Ding,Qiuchi Li,Peng Zhang*

Main category: cs.CL

TL;DR: 本文提出了“视觉房间”论点，指出多模态大语言模型（MLLMs）虽然能准确描述视觉细节，但未必理解其背后的情感与意图，并构建了Visual Room 2.0分层基准来评估MLLMs的感知-认知对齐能力。实验表明MLLMs感知能力强于认知能力，且认知不依赖于感知推理，而是随模型规模提升。


<details>
  <summary>Details</summary>
Motivation: 探讨MLLMs是否真正理解所见内容，挑战‘看见即理解’的假设，受Searle中文房间思想实验启发，提出视觉房间论点以揭示模型在多模态理解中的局限性。

Method: 构建包含350个多模态样本、2100个渐进式问题的Visual Room 2.0基准，覆盖低、中、高三层次17项任务，评估10种最先进MLLMs在感知（如属性识别、场景理解）与认知（如因果与社会推理）方面的能力。

Result: 发现：(1) MLLMs感知能力优于认知能力（+8.0%）；(2) 认知不依赖于感知推理；(3) 认知随模型规模提升，但感知未在更大模型中持续改善。

Conclusion: 看见不等于理解，MLLMs在认知层面存在明显短板，需建立从感知到认知的可测试评估范式，推动真正意义上的多模态理解发展。

Abstract: Can multi-modal large language models (MLLMs) truly understand what they can see? Extending Searle's Chinese Room into the multi-modal domain, this paper proposes the Visual Room argument: MLLMs may describe every visual detail precisely yet fail to comprehend the underlying emotions and intentions, namely seeing is not understanding. Building on this, we introduce \textit{Visual Room} 2.0, a hierarchical benchmark for evaluating perception-cognition alignment of MLLMs. We model human perceptive and cognitive processes across three levels: low, middle, and high, covering 17 representative tasks. The perception component ranges from attribute recognition to scene understanding, while the cognition component extends from textual entailment to causal and social reasoning. The dataset contains 350 multi-modal samples, each with six progressive questions (2,100 in total) spanning perception to cognition. Evaluating 10 state-of-the-art (SoTA) MLLMs, we highlight three key findings: (1) MLLMs exhibit stronger perceptual competence than cognitive ability (8.0\%$\uparrow$); (2) cognition appears not causally dependent on perception-based reasoning; and (3) cognition scales with model size, but perception does not consistently improve with larger variants. This work operationalizes Seeing $\ne$ Understanding as a testable hypothesis, offering a new paradigm from perceptual processing to cognitive reasoning in MLLMs. Our dataset is available at https://huggingface.co/datasets/LHK2003/PCBench.

</details>


### [354] [Fine-Tuned LLMs Know They Don't Know: A Parameter-Efficient Approach to Recovering Honesty](https://arxiv.org/abs/2511.12991)
*Zeyu Shi,Ziming Wang,Tianyu Chen,Shiqi Gao,Haoyi Zhou,Qingyun Sun,Jianxin Li*

Main category: cs.CL

TL;DR: 提出Honesty-Critical Neurons Restoration (HCNR) 方法，通过识别并恢复关键神经元来修复微调后大模型的诚实性，相比基线方法更高效且数据需求更少。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）会损害大语言模型在知识边界上的诚实表达能力，而现有恢复方法数据消耗大且假设过强，需更高效的修复方案。

Method: 识别控制诚实表达的关键神经元，将其恢复至预训练状态，并通过Hessian引导的补偿机制协调任务相关神经元，实现精准修复。

Result: 在四个问答任务和五个大模型家族上验证，HCNR恢复了33.25%的诚实性损失，速度提升至少2.23倍，数据用量减少10倍以上。

Conclusion: HCNR能有效、高效地修复SFT导致的诚实性退化，为可信大模型部署提供实用解决方案。

Abstract: The honesty of Large Language Models (LLMs) is increasingly important for safe deployment in high-stakes domains. However, this crucial trait is severely undermined by supervised fine-tuning (SFT), a common technique for model specialization. Existing recovery methods rely on data-intensive global parameter adjustments, implicitly assuming that SFT deeply corrupts the models' ability to recognize their knowledge boundaries. However, we observe that fine-tuned LLMs still preserve this ability; what is damaged is their capacity to faithfully express that awareness. Building on this, we propose Honesty-Critical Neurons Restoration (HCNR) to surgically repair this suppressed capacity. HCNR identifies and restores key expression-governing neurons to their pre-trained state while harmonizing them with task-oriented neurons via Hessian-guided compensation. Experiments on four QA tasks and five LLM families demonstrate that HCNR effectively recovers 33.25% of the compromised honesty while achieving at least 2.23x speedup with over 10x less data compared to baseline methods, offering a practical solution for trustworthy LLM deployment.

</details>


### [355] [AA-Omniscience: Evaluating Cross-Domain Knowledge Reliability in Large Language Models](https://arxiv.org/abs/2511.13029)
*Declan Jackson,William Keating,George Cameron,Micah Hill-Smith*

Main category: cs.CL

TL;DR: AA-Omniscience 是一个包含6000个问题的新基准，用于评估语言模型在事实回忆和知识校准方面的能力，结果表明现有前沿模型在事实性和校准方面仍存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评测主要关注通用能力，但实际应用中需要模型具备高事实准确性和对知识盲区的认知能力，因此需要更针对性的评测基准。

Method: 构建了涵盖42个经济相关主题、来自权威学术和行业来源的6000个问题的AA-Omniscience基准，提出Omniscience Index（-100到100）作为评估指标，综合衡量事实回忆、幻觉惩罚和不确定性下的 abstention 行为。

Result: Claude 4.1 Opus 得分最高（4.8），仅有三个模型得分超过0；不同领域表现差异明显，三大研究机构的模型分别在不同领域领先。

Conclusion: 当前前沿语言模型在事实性与知识校准上普遍存在不足，应根据具体应用场景选择最适合的模型，而非依赖通用性能排名。

Abstract: Existing language model evaluations primarily measure general capabilities, yet reliable use of these models across a range of domains demands factual accuracy and recognition of knowledge gaps. We introduce AA-Omniscience, a benchmark designed to measure both factual recall and knowledge calibration across 6,000 questions. Questions are derived from authoritative academic and industry sources, and cover 42 economically relevant topics within six different domains. The evaluation measures a model's Omniscience Index, a bounded metric (-100 to 100) measuring factual recall that jointly penalizes hallucinations and rewards abstention when uncertain, with 0 equating to a model that answers questions correctly as much as it does incorrectly. Among evaluated models, Claude 4.1 Opus attains the highest score (4.8), making it one of only three models to score above zero. These results reveal persistent factuality and calibration weaknesses across frontier models. Performance also varies by domain, with the models from three different research labs leading across the six domains. This performance variability suggests models should be chosen according to the demands of the use case rather than general performance for tasks where knowledge is important.

</details>


### [356] [How Good is BLI as an Alignment Measure: A Study in Word Embedding Paradigm](https://arxiv.org/abs/2511.13040)
*Kasun Wickramasinghe,Nisansa de Silva*

Main category: cs.CL

TL;DR: 本文探讨了双语词典归纳（BLI）作为评估多语言和单语嵌入对齐程度的指标的有效性，提出了一种基于词干的BLI新方法和词汇剪枝技术，并比较了不同语言资源条件下各种嵌入对齐方法的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言嵌入已成为主流，但其是否在所有方面都优于对齐的单语模型尚不明确，且计算成本较高，因此需要系统评估BLI这一常用指标的有效性，并探索更优的对齐评估方法。

Method: 通过在高低资源语言上评估传统对齐方法、新型多语言模型及组合技术在BLI任务上的表现，分析语言族的影响，并提出基于词干的BLI方法与词汇剪枝技术以改进评估效果。

Result: 发现BLI在某些情况下不能准确反映嵌入空间的真实对齐程度；提出的词干BLI方法和词汇剪枝技术更具信息量；组合对齐方法通常表现更好，而在低资源语言中多语言模型更具优势。

Conclusion: BLI并非始终可靠地衡量嵌入对齐质量，需结合改进方法进行评估；多语言模型与对齐技术各有优势，应根据语言资源情况选择合适方案。

Abstract: Sans a dwindling number of monolingual embedding studies originating predominantly from the low-resource domains, it is evident that multilingual embedding has become the de facto choice due to its adaptability to the usage of code-mixed languages, granting the ability to process multilingual documents in a language-agnostic manner, as well as removing the difficult task of aligning monolingual embeddings. But is this victory complete? Are the multilingual models better than aligned monolingual models in every aspect? Can the higher computational cost of multilingual models always be justified? Or is there a compromise between the two extremes? Bilingual Lexicon Induction is one of the most widely used metrics in terms of evaluating the degree of alignment between two embedding spaces. In this study, we explore the strengths and limitations of BLI as a measure to evaluate the degree of alignment of two embedding spaces. Further, we evaluate how well traditional embedding alignment techniques, novel multilingual models, and combined alignment techniques perform BLI tasks in the contexts of both high-resource and low-resource languages. In addition to that, we investigate the impact of the language families to which the pairs of languages belong. We identify that BLI does not measure the true degree of alignment in some cases and we propose solutions for them. We propose a novel stem-based BLI approach to evaluate two aligned embedding spaces that take into account the inflected nature of languages as opposed to the prevalent word-based BLI techniques. Further, we introduce a vocabulary pruning technique that is more informative in showing the degree of the alignment, especially performing BLI on multilingual embedding models. Often, combined embedding alignment techniques perform better while in certain cases multilingual embeddings perform better (mainly low-resource language cases).

</details>


### [357] [Spark-Prover-X1: Formal Theorem Proving Through Diverse Data Training](https://arxiv.org/abs/2511.13043)
*Xinyuan Zhou,Yi Lei,Xiaoyu Zhou,Jingyi Sun,Yu Zhu,Zhongyi Ye,Weitai Zhang,Quan Liu,Si Wei,Cong Liu*

Main category: cs.CL

TL;DR: 本文提出了一种三阶段训练框架，用于提升中等规模大语言模型在自动定理证明中的形式化推理能力，推出了7B参数的Spark-Prover-X1模型和ExamFormal-Bench评测基准，在多个竞赛难题上达到开源同类模型中的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏多样化和高质量的形式化语言数据，大语言模型在自动定理证明中的发展受到限制，本文旨在通过有效的训练框架和丰富数据提升中小规模模型的推理能力。

Method: 采用三阶段训练框架：第一阶段在数学语料上进行持续预训练，并引入CoT增强的状态预测任务；第二阶段使用监督微调（SFT）结合专家迭代循环；第三阶段应用组相对策略优化（GRPO）强化对难题的求解能力。同时构建了ExamFormal-Bench作为新评测集。

Result: Spark-Prover-X1-7B在多个基准上表现优异，平均pass@32达37.0%，在PutnamBench上解决27题，在CombiBench上达到24.0%的通过率，优于同规模开源模型。

Conclusion: 多样化的训练数据与渐进式优化的训练流程能有效提升轻量级大语言模型在形式化推理任务上的表现，所提出的方法为中小型模型在定理证明领域提供了可行路径。

Abstract: Large Language Models (LLMs) have shown significant promise in automated theorem proving, yet progress is often constrained by the scarcity of diverse and high-quality formal language data. To address this issue, we introduce Spark-Prover-X1, a 7B parameter model trained via an three-stage framework designed to unlock the reasoning potential of more accessible and moderately-sized LLMs. The first stage infuses deep knowledge through continuous pre-training on a broad mathematical corpus, enhanced by a suite of novel data tasks. Key innovation is a "CoT-augmented state prediction" task to achieve fine-grained reasoning. The second stage employs Supervised Fine-tuning (SFT) within an expert iteration loop to specialize both the Spark-Prover-X1-7B and Spark-Formalizer-X1-7B models. Finally, a targeted round of Group Relative Policy Optimization (GRPO) is applied to sharpen the prover's capabilities on the most challenging problems. To facilitate robust evaluation, particularly on problems from real-world examinations, we also introduce ExamFormal-Bench, a new benchmark dataset of 402 formal problems. Experimental results demonstrate that Spark-Prover-X1-7B achieves state-of-the-art performance among similarly-sized open-source models, attaining a 37.0\% average pass rate (pass@32). It shows exceptional performance on difficult competition benchmarks, notably solving 27 problems on PutnamBench (pass@32) and achieving 24.0\% on CombiBench (pass@32). Our work validates that this diverse training data and progressively refined training pipeline provides an effective path for enhancing the formal reasoning capabilities of lightweight LLMs. Both Spark-Prover-X1-7B and Spark-Formalizer-X1-7B, along with the ExamFormal-Bench dataset, are made publicly available at:https://www.modelscope.cn/organization/iflytek, https://gitcode.com/ifly_opensource.

</details>


### [358] [BeDiscovER: The Benchmark of Discourse Understanding in the Era of Reasoning Language Models](https://arxiv.org/abs/2511.13095)
*Chuyuan Li,Giuseppe Carenini*

Main category: cs.CL

TL;DR: BeDiscovER是一个用于评估现代大语言模型在篇章理解能力方面的综合基准，涵盖52个数据集，涉及多层次的篇章任务。评估结果显示，当前最先进的模型在时间推理的算术方面表现良好，但在文档级推理和某些细微的语义与篇章现象（如修辞关系识别）上仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，需要一个全面且更新的基准来系统评估模型在篇章层面的理解能力，尤其是在多层级、多任务和多语言环境下的表现。

Method: BeDiscovER整合了5个公开的篇章任务，共52个数据集，覆盖词汇、句级、多句和文档级篇章理解，并包含传统任务（如篇章解析）和新挑战（如话语小词消歧）。同时引入多语言多框架的篇章关系分类共享任务。对Qwen3、DeepSeek-R1和GPT-5-mini等模型进行评测。

Result: 实验表明，前沿模型在时间推理的数值计算方面表现优异，但在完整文档推理和修辞关系识别等复杂语义任务上表现不佳，揭示了当前模型在深层次篇章理解上的局限性。

Conclusion: BeDiscovER为评估语言模型的篇章理解能力提供了系统化平台，揭示了模型在细粒度语义和长距离篇章推理方面的不足，指明了未来改进方向。

Abstract: We introduce BeDiscovER (Benchmark of Discourse Understanding in the Era of Reasoning Language Models), an up-to-date, comprehensive suite for evaluating the discourse-level knowledge of modern LLMs. BeDiscovER compiles 5 publicly available discourse tasks across discourse lexicon, (multi-)sentential, and documental levels, with in total 52 individual datasets. It covers both extensively studied tasks such as discourse parsing and temporal relation extraction, as well as some novel challenges such as discourse particle disambiguation (e.g., ``just''), and also aggregates a shared task on Discourse Relation Parsing and Treebanking for multilingual and multi-framework discourse relation classification. We evaluate open-source LLMs: Qwen3 series, DeepSeek-R1, and frontier model such as GPT-5-mini on BeDiscovER, and find that state-of-the-art models exhibit strong performance in arithmetic aspect of temporal reasoning, but they struggle with full document reasoning and some subtle semantic and discourse phenomena, such as rhetorical relation recognition.

</details>


### [359] [Evaluating the Ability of Large Language Models to Identify Adherence to CONSORT Reporting Guidelines in Randomized Controlled Trials: A Methodological Evaluation Study](https://arxiv.org/abs/2511.13107)
*Zhichao He,Mouxiao Bian,Jianhong Zhu,Jiayuan Chen,Yunqiu Wang,Wenxia Zhao,Tianbin Li,Bing Han,Jie Xu,Junyan Wu*

Main category: cs.CL

TL;DR: 该研究评估了当前大语言模型（LLM）在零样本设置下识别随机对照试验（RCT）对CONSORT 2010声明遵循情况的准确性，发现模型整体表现一般，尤其在识别不合规和不适用条目时表现较差，尚不能替代人工评审。


<details>
  <summary>Details</summary>
Motivation: 手动验证CONSORT遵循情况耗时费力，成为同行评审和证据合成的瓶颈，因此亟需自动化工具提升效率。

Method: 构建包含150项已发表RCT的金标准数据集，在零样本设置下评估多个大语言模型对CONSORT条目的三类分类（合规、不合规、不适用）性能，主要指标为宏F1分数，并进行逐条分析和定性误差分析。

Result: 表现最佳的Gemini-2.5-Flash和DeepSeek-R1模型宏F1分数为0.634，Cohen's Kappa约0.28，仅达中等一致性；模型对合规条目识别准确率高（F1 > 0.850），但对不合规和不适用条目识别能力差（F1 ≤ 0.400）；GPT-4o表现欠佳，宏F1仅为0.521。

Conclusion: 大语言模型可作为CONSORT初步筛查辅助工具，能有效识别良好报告条目，但因难以可靠发现报告遗漏或方法学缺陷，目前仍无法取代专家人工评审。

Abstract: The Consolidated Standards of Reporting Trials statement is the global benchmark for transparent and high-quality reporting of randomized controlled trials. Manual verification of CONSORT adherence is a laborious, time-intensive process that constitutes a significant bottleneck in peer review and evidence synthesis. This study aimed to systematically evaluate the accuracy and reliability of contemporary LLMs in identifying the adherence of published RCTs to the CONSORT 2010 statement under a zero-shot setting. We constructed a golden standard dataset of 150 published RCTs spanning diverse medical specialties. The primary outcome was the macro-averaged F1-score for the three-class classification task, supplemented by item-wise performance metrics and qualitative error analysis. Overall model performance was modest. The top-performing models, Gemini-2.5-Flash and DeepSeek-R1, achieved nearly identical macro F1 scores of 0.634 and Cohen's Kappa coefficients of 0.280 and 0.282, respectively, indicating only fair agreement with expert consensus. A striking performance disparity was observed across classes: while most models could identify compliant items with high accuracy (F1 score > 0.850), they struggled profoundly with identifying non-compliant and not applicable items, where F1 scores rarely exceeded 0.400. Notably, some high-profile models like GPT-4o underperformed, achieving a macro F1-score of only 0.521. LLMs show potential as preliminary screening assistants for CONSORT checks, capably identifying well-reported items. However, their current inability to reliably detect reporting omissions or methodological flaws makes them unsuitable for replacing human expertise in the critical appraisal of trial quality.

</details>


### [360] [Extracting Events Like Code: A Multi-Agent Programming Framework for Zero-Shot Event Extraction](https://arxiv.org/abs/2511.13118)
*Quanjiang Guo,Sijie Wang,Jinchuan Zhang,Ben Zhang,Zhao Kang,Ling Tian,Ke Yan*

Main category: cs.CL

TL;DR: 提出了一种名为Agent-Event-Coder（AEC）的多智能体框架，将零样本事件抽取视为类似软件工程的结构化代码生成过程，通过分解任务和迭代优化，在多个领域和大模型上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在零样本事件抽取中面临输出不完整、结构无效等问题，如触发词误分类、论元缺失和模式违规，现有直接提示方法效果有限。

Method: 设计了一个多智能体框架AEC，将事件抽取分解为检索、规划、编码和验证四个子任务，每个由专用LLM代理执行；事件模式表示为可执行类定义，通过验证代理实现确定性验证和精确反馈，支持迭代 refinement。

Result: 在五个不同领域和六个大语言模型上的实验表明，AEC在零样本设置下 consistently 优于先前的基线方法，生成的结果更精确、完整且符合模式。

Conclusion: 将事件抽取视为代码生成任务，结合多智能体协作与程序化验证，能有效提升零样本场景下的性能，展示了结构化推理框架在复杂信息抽取任务中的潜力。

Abstract: Zero-shot event extraction (ZSEE) remains a significant challenge for large language models (LLMs) due to the need for complex reasoning and domain-specific understanding. Direct prompting often yields incomplete or structurally invalid outputs--such as misclassified triggers, missing arguments, and schema violations. To address these limitations, we present Agent-Event-Coder (AEC), a novel multi-agent framework that treats event extraction like software engineering: as a structured, iterative code-generation process. AEC decomposes ZSEE into specialized subtasks--retrieval, planning, coding, and verification--each handled by a dedicated LLM agent. Event schemas are represented as executable class definitions, enabling deterministic validation and precise feedback via a verification agent. This programming-inspired approach allows for systematic disambiguation and schema enforcement through iterative refinement. By leveraging collaborative agent workflows, AEC enables LLMs to produce precise, complete, and schema-consistent extractions in zero-shot settings. Experiments across five diverse domains and six LLMs demonstrate that AEC consistently outperforms prior zero-shot baselines, showcasing the power of treating event extraction like code generation. The code and data are released on https://github.com/UESTC-GQJ/Agent-Event-Coder.

</details>


### [361] [A Comparative Analysis of Recurrent and Attention Architectures for Isolated Sign Language Recognition](https://arxiv.org/abs/2511.13126)
*Nigar Alishzade,Gulchin Abdullayeva*

Main category: cs.CL

TL;DR: 本研究系统比较了循环神经网络和基于注意力机制的模型在孤立手语识别中的表现，发现Vanilla Transformer在准确率上优于ConvLSTM，尤其在Top-1和Top-5准确率上表现更优，但ConvLSTM计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 为了比较不同神经网络架构在手语识别任务中的性能差异，特别是在准确性和计算效率之间的权衡。

Method: 采用ConvLSTM和Vanilla Transformer两种代表性模型，在Azerbaijani手语数据集（AzSLD）和美国手语数据集（WLASL）上进行实现与评估。

Result: Vanilla Transformer在两个数据集上的Top-1和Top-5准确率均优于ConvLSTM，最高分别达到76.8%（AzSLD）和88.3%（WLASL）；而ConvLSTM虽然计算效率更高，但在小数据集上准确率较低。

Conclusion: Transformer在准确性和说话人无关性方面表现更好，适合对精度要求高的场景；ConvLSTM则因计算效率高，适用于资源受限环境，研究为手语识别系统的架构选择提供了实用指导。

Abstract: This study presents a systematic comparative analysis of recurrent and attention-based neural architectures for isolated sign language recognition. We implement and evaluate two representative models-ConvLSTM and Vanilla Transformer-on the Azerbaijani Sign Language Dataset (AzSLD) and the Word-Level American Sign Language (WLASL) dataset. Our results demonstrate that the attention-based Vanilla Transformer consistently outperforms the recurrent ConvLSTM in both Top-1 and Top-5 accuracy across datasets, achieving up to 76.8% Top-1 accuracy on AzSLD and 88.3% on WLASL. The ConvLSTM, while more computationally efficient, lags in recognition accuracy, particularly on smaller datasets. These findings highlight the complementary strengths of each paradigm: the Transformer excels in overall accuracy and signer independence, whereas the ConvLSTM offers advantages in computational efficiency and temporal modeling. The study provides a nuanced analysis of these trade-offs, offering guidance for architecture selection in sign language recognition systems depending on application requirements and resource constraints.

</details>


### [362] [Zero-Shot Grammar Competency Estimation Using Large Language Model Generated Pseudo Labels](https://arxiv.org/abs/2511.13152)
*Sourya Dipta Das,Shubham Kumar,Kuldeep Yadav*

Main category: cs.CL

TL;DR: 提出一种零样本语法能力评估框架，利用大语言模型生成伪标签训练Transformer模型，有效解决口语语法评分中标注数据稀缺和标签噪声问题。


<details>
  <summary>Details</summary>
Motivation: 口语的自发性、非结构化和不流畅性给语法能力评估带来挑战，且依赖专家标注的数据创建成本高、难以大规模扩展。

Method: 使用大语言模型基于语法评分标准生成伪标签，并在无标签数据上训练Transformer模型；设计了一种能有效处理标签噪声的新训练框架。

Result: 实验证明该方法能高效准确地估计语法能力得分，LLM选择和干净/噪声样本比例显著影响模型性能和训练稳定性；定性分析显示方法具有鲁棒性和可解释性。

Conclusion: 所提框架为低资源、可扩展的语法评估系统提供了可行路径，无需人工标注即可实现高性能语法能力估计。

Abstract: Grammar competency estimation is essential for assessing linguistic proficiency in both written and spoken language; however, the spoken modality presents additional challenges due to its spontaneous, unstructured, and disfluent nature. Developing accurate grammar scoring models further requires extensive expert annotation, making large-scale data creation impractical. To address these limitations, we propose a zero-shot grammar competency estimation framework that leverages unlabeled data and Large Language Models (LLMs) without relying on manual labels. During training, we employ LLM-generated predictions on unlabeled data by using grammar competency rubric-based prompts. These predictions, treated as pseudo labels, are utilized to train a transformer-based model through a novel training framework designed to handle label noise effectively. We show that the choice of LLM for pseudo-label generation critically affects model performance and that the ratio of clean-to-noisy samples during training strongly influences stability and accuracy. Finally, a qualitative analysis of error intensity and score prediction confirms the robustness and interpretability of our approach. Experimental results demonstrate the efficacy of our approach in estimating grammar competency scores with high accuracy, paving the way for scalable, low-resource grammar assessment systems.

</details>


### [363] [Distinguishing Repetition Disfluency from Morphological Reduplication in Bangla ASR Transcripts: A Novel Corpus and Benchmarking Analysis](https://arxiv.org/abs/2511.13159)
*Zaara Zabeen Arpa,Sadnam Sakib Apurbo,Nazia Karim Khan Oishee,Ajwad Abrar*

Main category: cs.CL

TL;DR: 本文提出了首个公开的、包含20,000条标注数据的孟加拉语语料库，用于区分ASR转录中的重复口误与形态重叠现象，并通过多语言大模型和专用微调模型进行基准测试，其中孟加拉语专用的BanglaBERT表现最佳。


<details>
  <summary>Details</summary>
Motivation: 由于孟加拉语等低资源语言的ASR转录中存在重复词是口误还是语法构造的歧义，传统去口误方法会错误删除有效语言信息，因此需要一种能保留语言结构的精准识别方法。

Method: 构建了一个手动标注的20,000行孟加拉语语料库，明确区分重复口误与形态重叠；采用多语言大模型（少样本提示）和针对任务微调的编码器模型（如BanglaBERT）两种范式进行基准测试。

Result: 大模型在少样本下达到82.68%准确率，而微调后的BanglaBERT表现更优，准确率达84.78%，F1分数为0.677。

Conclusion: 微调语言特定模型优于通用大模型，该数据集为孟加拉语的语义保持文本归一化系统提供了重要基础。

Abstract: Automatic Speech Recognition (ASR) transcripts, especially in low-resource languages like Bangla, contain a critical ambiguity: word-word repetitions can be either Repetition Disfluency (unintentional ASR error/hesitation) or Morphological Reduplication (a deliberate grammatical construct). Standard disfluency correction fails by erroneously deleting valid linguistic information. To solve this, we introduce the first publicly available, 20,000-row Bangla corpus, manually annotated to explicitly distinguish between these two phenomena in noisy ASR transcripts. We benchmark this novel resource using two paradigms: state-of-the-art multilingual Large Language Models (LLMs) and task-specific fine-tuning of encoder models. LLMs achieve competitive performance (up to 82.68\% accuracy) with few-shot prompting. However, fine-tuning proves superior, with the language-specific BanglaBERT model achieving the highest accuracy of 84.78\% and an F1 score of 0.677. This establishes a strong, linguistically-informed baseline and provides essential data for developing sophisticated, semantic-preserving text normalization systems for Bangla.

</details>


### [364] [TCM-5CEval: Extended Deep Evaluation Benchmark for LLM's Comprehensive Clinical Research Competence in Traditional Chinese Medicine](https://arxiv.org/abs/2511.13169)
*Tianai Huang,Jiayuan Chen,Lu Lu,Pengcheng Chen,Tianbin Li,Bing Han,Wenchao Tang,Jie Xu,Ming Li*

Main category: cs.CL

TL;DR: 本文提出了TCM-5CEval，一个用于评估大语言模型在中医领域五项核心能力的综合性基准，发现现有模型在经典文本理解和推理稳定性方面存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 由于现有大语言模型在传统中医这一高度专业化且文化内涵丰富的领域中缺乏细致评估，且先前工作已揭示出知识盲区和文化对齐问题，因此需要更精细、全面的评测基准。

Method: 构建了包含五大维度（核心知识、经典文献理解、临床决策、中药学、非药物疗法）的TCM-5CEval基准，并对15个主流大语言模型进行了系统评估，采用打乱选项顺序的置换一致性测试来检验模型推理的鲁棒性。

Result: 评估显示模型在基础知识记忆上表现尚可，但在解读经典文献时困难明显；所有模型（包括表现最佳者）在选项顺序变化后性能显著下降，暴露出严重的推理脆弱性和位置偏差敏感性。

Conclusion: TCM-5CEval为衡量大语言模型在中医领域的能力提供了更精细的工具，揭示了当前模型在稳定推理方面的根本弱点，强调了提升文化语境理解和逻辑鲁棒性的必要性。

Abstract: Large language models (LLMs) have demonstrated exceptional capabilities in general domains, yet their application in highly specialized and culturally-rich fields like Traditional Chinese Medicine (TCM) requires rigorous and nuanced evaluation. Building upon prior foundational work such as TCM-3CEval, which highlighted systemic knowledge gaps and the importance of cultural-contextual alignment, we introduce TCM-5CEval, a more granular and comprehensive benchmark. TCM-5CEval is designed to assess LLMs across five critical dimensions: (1) Core Knowledge (TCM-Exam), (2) Classical Literacy (TCM-LitQA), (3) Clinical Decision-making (TCM-MRCD), (4) Chinese Materia Medica (TCM-CMM), and (5) Clinical Non-pharmacological Therapy (TCM-ClinNPT). We conducted a thorough evaluation of fifteen prominent LLMs, revealing significant performance disparities and identifying top-performing models like deepseek\_r1 and gemini\_2\_5\_pro. Our findings show that while models exhibit proficiency in recalling foundational knowledge, they struggle with the interpretative complexities of classical texts. Critically, permutation-based consistency testing reveals widespread fragilities in model inference. All evaluated models, including the highest-scoring ones, displayed a substantial performance degradation when faced with varied question option ordering, indicating a pervasive sensitivity to positional bias and a lack of robust understanding. TCM-5CEval not only provides a more detailed diagnostic tool for LLM capabilities in TCM but aldso exposes fundamental weaknesses in their reasoning stability. To promote further research and standardized comparison, TCM-5CEval has been uploaded to the Medbench platform, joining its predecessor in the "In-depth Challenge for Comprehensive TCM Abilities" special track.

</details>


### [365] [Translation Entropy: A Statistical Framework for Evaluating Translation Systems](https://arxiv.org/abs/2511.13180)
*Ronit D. Gross,Yanir Harel,Ido Kanter*

Main category: cs.CL

TL;DR: 提出了一种量化翻译熵的方法，用于客观评估不同神经机器翻译模型的性能，揭示了翻译退化的乘积效应，并建立了翻译熵作为可测量属性和翻译器基准测试的新指标。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏对语言熵的了解，目前尚无客观定量方法评估机器翻译模型的性能，因此需要一种新的量化手段来衡量和比较不同翻译系统的可靠性与稳定性。

Method: 通过在源句子中替换单个或多个关键词（pivot token），统计保持翻译结果不变的替换概率，计算各token的熵并取平均值得到整体翻译熵；进一步分析多个解码器模块中的熵变化及多token替换的联合效应。

Result: 成功估计了MarianMT、T5-Base和NLLB-200等翻译系统的翻译熵，实现了系统间的定量排序；发现翻译熵沿解码器块递增，且双token替换呈现退化程度的乘积效应；验证了互译熵的对称性问题。

Conclusion: 翻译熵是一种可测量的语言属性，该方法为机器翻译系统提供了客观的基准评测手段，有助于未来翻译模型的优化与比较。

Abstract: The translation of written language has been known since the 3rd century BC; however, its necessity has become increasingly common in the information age. Today, many translators exist, based on encoder-decoder deep architectures, nevertheless, no quantitative objective methods are available to assess their performance, likely because the entropy of even a single language remains unknown. This study presents a quantitative method for estimating translation entropy, with the following key finding. Given a translator, several sentences that differ by only one selected token of a given pivot sentence yield identical translations. Analyzing the statistics of this phenomenon across an ensemble of such sentences, consisting each of a pivot selected token, yields the probabilities of replacing this specific token with others while preserving the translation. These probabilities constitute the entropy of the selected token, and the average across all selected pivot tokens provides an estimate of the translator's overall translation entropy, which is enhanced along the decoder blocks. This entropic measure allows for the quantitative ranking of several publicly available translators and reveals whether mutual translation entropy is symmetric. Extending the proposed method to include the replacement of two tokens in a given pivot sentence demonstrates a multiplicative effect, where translation degeneracy is proportional to the product of the degeneracies of the two tokens. These findings establish translation entropy as a measurable property and objective benchmarking of artificial translators. Results are based on MarianMT, T5-Base and NLLB-200 translators.

</details>


### [366] [Evaluating Large Language Models for Diacritic Restoration in Romanian Texts: A Comparative Study](https://arxiv.org/abs/2511.13182)
*Mihai Dan Nadas,Laura Diosan*

Main category: cs.CL

TL;DR: 该研究评估了多种大语言模型在罗马尼亚语文本重音符号恢复任务中的表现，发现GPT-4o等模型表现优异，而Llama系列模型表现不稳定，提示模型架构、训练数据和提示设计对任务效果有重要影响。


<details>
  <summary>Details</summary>
Motivation: 提升富含变音符号语言的自然语言处理工具性能，解决自动重音符号恢复在文本处理中的关键作用。

Method: 使用包含多种大语言模型（如GPT系列、Gemini、Llama、Mixtral等）和多种提示模板（从零样本到复杂多样本）的综合语料库进行实验。

Result: GPT-4o在重音符号恢复任务中表现出高准确率，显著优于基线，而Llama系列模型表现波动较大。

Conclusion: 模型架构、训练数据和提示设计显著影响重音符号恢复效果，为丰富变音符号语言的NLP工具优化提供了方向。

Abstract: Automatic diacritic restoration is crucial for text processing in languages with rich diacritical marks, such as Romanian. This study evaluates the performance of several large language models (LLMs) in restoring diacritics in Romanian texts. Using a comprehensive corpus, we tested models including OpenAI's GPT-3.5, GPT-4, GPT-4o, Google's Gemini 1.0 Pro, Meta's Llama 2 and Llama 3, MistralAI's Mixtral 8x7B Instruct, airoboros 70B, and OpenLLM-Ro's RoLlama 2 7B, under multiple prompt templates ranging from zero-shot to complex multi-shot instructions. Results show that models such as GPT-4o achieve high diacritic restoration accuracy, consistently surpassing a neutral echo baseline, while others, including Meta's Llama family, exhibit wider variability. These findings highlight the impact of model architecture, training data, and prompt design on diacritic restoration performance and outline promising directions for improving NLP tools for diacritic-rich languages.

</details>


### [367] [Seeing isn't Hearing: Benchmarking Vision Language Models at Interpreting Spectrograms](https://arxiv.org/abs/2511.13225)
*Tyler Loakman,Joseph James,Chenghua Lin*

Main category: cs.CL

TL;DR: 本研究评估了视觉语言模型（VLMs）在理解和解释语音的频谱图和波形方面的能力，发现即使经过微调，模型的表现也难以超越随机水平，表明仅靠配对样本不足以让模型掌握此类图像的解读能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和视觉语言模型的发展，探索其跨模态能力成为热点。然而，这些模型是否能像专业音位学家一样理解语音的视觉表示（如频谱图）尚不清楚。因此，本文旨在评估VLMs在该任务上的表现。

Method: 构建了一个包含4000多个孤立英文单词及其对应频谱图和波形的新数据集，并设计了一个多选任务：给定一个语音的可视化表示和四个音位或字形转录选项（其中一个为正确答案，其余根据音位编辑距离选择干扰项），测试零样本和微调后的VLMs预测正确转录的能力。

Result: 实验结果显示，无论是零样本还是微调后的VLMs，其准确率大多未超过随机猜测水平，表明当前模型缺乏有效解析此类语音可视化图形所需的参数化知识。

Conclusion: 现有VLMs在没有专门训练的情况下无法有效理解语音的视觉表示形式，说明仅依赖语言-图像配对数据不足以使模型掌握专业领域的图像解读能力，未来需要更针对性的建模与训练策略。

Abstract: With the rise of Large Language Models (LLMs) and their vision-enabled counterparts (VLMs), numerous works have investigated their capabilities in tasks that fuse the modalities of vision and language. In this work, we benchmark the extent to which VLMs are able to act as highly-trained phoneticians, interpreting spectrograms and waveforms of speech. To do this, we synthesise a novel dataset containing 4k+ English words spoken in isolation alongside stylistically consistent spectrogram and waveform figures. We test the ability of VLMs to understand these representations of speech through a multiple-choice task whereby models must predict the correct phonemic or graphemic transcription of a spoken word when presented amongst 3 distractor transcriptions that have been selected based on their phonemic edit distance to the ground truth. We observe that both zero-shot and finetuned models rarely perform above chance, demonstrating the requirement for specific parametric knowledge of how to interpret such figures, rather than paired samples alone.

</details>


### [368] [Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance](https://arxiv.org/abs/2511.13254)
*Shalini Maiti,Amar Budhiraja,Bhavul Gauri,Gaurav Chaurasia,Anton Protopopov,Alexis Audran-Reiss,Michael Slater,Despoina Magka,Tatiana Shavrina,Roberta Raileanu,Yoram Bachrach*

Main category: cs.CL

TL;DR: 本文提出了Soup Of Category Experts (SoCE)，一种基于基准测试分类的非均匀加权模型融合方法，通过识别各类别上的专家模型并进行优化加权平均，在无需重新训练的情况下显著提升大模型在多语言、工具调用和数学等任务上的性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大模型训练成本高昂，亟需高效提升性能的方法；传统模型融合采用均匀加权，未充分利用不同模型在不同任务类别上的专长。

Method: 提出SoCE方法：首先根据基准测试结果对类别进行聚类分析，识别出各弱相关类别簇中的专家模型，然后采用非均匀加权平均策略进行模型融合，而非传统的均匀平均。

Result: SoCE在多个领域（如多语言能力、工具调用、数学）均表现出更强的性能和鲁棒性，并在Berkeley Function Calling Leaderboard上达到SOTA水平。

Conclusion: SoCE为模型融合提供了更精细化的加权策略，有效挖掘了模型多样性，在不增加训练成本的前提下显著提升了综合性能，具有广泛的应用前景。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, but their training remains resource- and time-intensive, requiring massive compute power and careful orchestration of training procedures. Model souping-the practice of averaging weights from multiple models of the same architecture-has emerged as a promising pre- and post-training technique that can enhance performance without expensive retraining. In this paper, we introduce Soup Of Category Experts (SoCE), a principled approach for model souping that utilizes benchmark composition to identify optimal model candidates and applies non-uniform weighted averaging to maximize performance. Contrary to previous uniform-averaging approaches, our method leverages the observation that benchmark categories often exhibit low inter-correlations in model performance. SoCE identifies "expert" models for each weakly-correlated category cluster and combines them using optimized weighted averaging rather than uniform weights. We demonstrate that the proposed method improves performance and robustness across multiple domains, including multilingual capabilities, tool calling, and math and achieves state-of-the-art results on the Berkeley Function Calling Leaderboard.

</details>


### [369] [RegionMarker: A Region-Triggered Semantic Watermarking Framework for Embedding-as-a-Service Copyright Protection](https://arxiv.org/abs/2511.13329)
*Shufan Yang,Zifeng Cheng,Zhiwei Jiang,Yafeng Yin,Cong Wang,Shiping Ge,Yuchen Fu,Qing Gu*

Main category: cs.CL

TL;DR: 提出RegionMarker，一种区域触发的语义水印框架，通过在低维空间定义触发区域并嵌入水印，有效抵御多种攻击，保护EaaS模型版权。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法只能抵抗部分攻击，缺乏对嵌入即服务（EaaS）模型的全面版权保护。

Method: 在低维子空间中定义触发区域，利用秘密降维矩阵投影，并随机选择区域嵌入水印；将文本嵌入本身作为水印，实现区域范围内的水印嵌入。

Result: 实验表明，RegionMarker在多个数据集上能有效抵抗去 watermark、改写和维度扰动等多种攻击，水印检测准确率高且对下游任务影响小。

Conclusion: RegionMarker 提供了一种鲁棒且全面的水印方案，显著提升了 EaaS 模型在复杂攻击下的版权保护能力。

Abstract: Embedding-as-a-Service (EaaS) is an effective and convenient deployment solution for addressing various NLP tasks. Nevertheless, recent research has shown that EaaS is vulnerable to model extraction attacks, which could lead to significant economic losses for model providers. For copyright protection, existing methods inject watermark embeddings into text embeddings and use them to detect copyright infringement. However, current watermarking methods often resist only a subset of attacks and fail to provide \textit{comprehensive} protection. To this end, we present the region-triggered semantic watermarking framework called RegionMarker, which defines trigger regions within a low-dimensional space and injects watermarks into text embeddings associated with these regions. By utilizing a secret dimensionality reduction matrix to project onto this subspace and randomly selecting trigger regions, RegionMarker makes it difficult for watermark removal attacks to evade detection. Furthermore, by embedding watermarks across the entire trigger region and using the text embedding as the watermark, RegionMarker is resilient to both paraphrasing and dimension-perturbation attacks. Extensive experiments on various datasets show that RegionMarker is effective in resisting different attack methods, thereby protecting the copyright of EaaS.

</details>


### [370] [AHaSIS: Shared Task on Sentiment Analysis for Arabic Dialects](https://arxiv.org/abs/2511.13335)
*Maram Alharbi,Salmane Chafik,Saad Ezzini,Ruslan Mitkov,Tharindu Ranasinghe,Hansi Hettiarachchi*

Main category: cs.CL

TL;DR: 本论文介绍了针对阿拉伯语方言在酒店业领域的评论进行情感分析的共享任务，使用了一个多方言、手工整理的数据集，包含538条情感平衡的评论，翻译并验证了沙特和摩洛哥方言版本。该数据集有助于开发面向实际应用的方言感知NLP系统。超过40个团队注册参与，12个团队提交了系统，最佳系统达到0.81的F1分数，展示了跨阿拉伯语方言情感分析的可行性与挑战。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯世界 hospitality 行业日益依赖客户反馈来优化服务，但现有阿拉伯语情感分析工具对地方方言支持不足，亟需专门针对方言的情感分析资源与技术。

Method: 构建一个从现代标准阿拉伯语翻译而来、涵盖沙特和摩洛哥方言的酒店评论数据集，并由母语者验证翻译准确性与情感一致性；组织共享任务以推动相关方法发展。

Result: 数据集包含538条情感平衡的多方言评论，支持三种情感类别（正面、中性、负面）；12支队伍在评估阶段提交系统，最优系统获得0.81的F1分数。

Conclusion: 研究证明了在阿拉伯语多方言环境下进行情感分析的可行性，同时也揭示了语言复杂性带来的挑战，为未来方言感知NLP系统的发展提供了宝贵资源和方向。

Abstract: The hospitality industry in the Arab world increasingly relies on customer feedback to shape services, driving the need for advanced Arabic sentiment analysis tools. To address this challenge, the Sentiment Analysis on Arabic Dialects in the Hospitality Domain shared task focuses on Sentiment Detection in Arabic Dialects. This task leverages a multi-dialect, manually curated dataset derived from hotel reviews originally written in Modern Standard Arabic (MSA) and translated into Saudi and Moroccan (Darija) dialects. The dataset consists of 538 sentiment-balanced reviews spanning positive, neutral, and negative categories. Translations were validated by native speakers to ensure dialectal accuracy and sentiment preservation. This resource supports the development of dialect-aware NLP systems for real-world applications in customer experience analysis. More than 40 teams have registered for the shared task, with 12 submitting systems during the evaluation phase. The top-performing system achieved an F1 score of 0.81, demonstrating the feasibility and ongoing challenges of sentiment analysis across Arabic dialects.

</details>


### [371] [Donors and Recipients: On Asymmetric Transfer Across Tasks and Languages with Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2511.13368)
*Kajetan Dymkiewicz,Ivan Vulic,Helen Yannakoudakis,Eilam Shapira,Roi Reichart,Anna Korhonen*

Main category: cs.CL

TL;DR: 研究了大语言模型在不同任务和语言间的迁移效果，发现匹配任务的跨语言迁移表现良好，而不匹配任务的迁移常导致性能下降，并揭示了语言和任务间的稳定贡献结构。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型在一个任务或语言上的改进如何影响其他任务和语言的表现。

Method: 通过PEFT/LoRA方法在多个开源大模型上进行微调实验，以任务和语言为迁移轴，测量单一任务-语言源微调后在其他任务-语言目标上的迁移效果。

Result: 发现了两种一致模式：一是任务匹配的跨语言迁移始终积极，而非任务匹配迁移常导致性能退化；二是语言与任务间存在稳定的‘枢纽型贡献者’与‘脆弱接收者’结构。

Conclusion: 结果提示在微调时需考虑风险意识，并支持针对特定任务和语言进行模型专门化设计。

Abstract: Large language models (LLMs) perform strongly across tasks and languages, yet how improvements in one task or language affect other tasks and languages and their combinations remains poorly understood. We conduct a controlled PEFT/LoRA study across multiple open-weight LLM families and sizes, treating task and language as transfer axes while conditioning on model family and size; we fine-tune each model on a single task-language source and measure transfer as the percentage-point change versus its baseline score when evaluated on all other task-language target pairs. We decompose transfer into (i) Matched-Task (Cross-Language), (ii) Matched-Language (Cross-Task), and (iii) Cross-Task (Cross-Language) regimes. We uncover two consistent general patterns. First, a pronounced on-task vs. off-task asymmetry: Matched-Task (Cross-Language) transfer is reliably positive, whereas off-task transfer often incurs collateral degradation. Second, a stable donor-recipient structure across languages and tasks (hub donors vs. brittle recipients). We outline implications for risk-aware fine-tuning and model specialisation.

</details>


### [372] [Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts](https://arxiv.org/abs/2511.13381)
*Siyu Zhu,Mouxiao Bian,Yue Xie,Yongyu Tang,Zhikang Yu,Tianbin Li,Pengcheng Chen,Bing Han,Jie Xu,Xiaoyan Dong*

Main category: cs.CL

TL;DR: 本研究开发了PEDIASBench框架，系统评估12种大语言模型在儿科临床能力三方面表现：基础知识应用、动态诊疗能力和医学伦理与安全。结果显示，尽管先进模型在基础测试中表现优异，但在复杂推理、实时患者变化适应和人文关怀方面仍存在明显不足，表明当前LLM尚不能独立承担儿科诊疗任务，但可作为决策支持、医学教育和医患沟通的辅助工具。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在医学领域的快速发展，亟需系统评估其是否具备在真实临床环境中胜任儿科诊疗的能力，特别是在复杂决策、安全性和人文关怀方面的表现。

Method: 提出PEDIASBench评估框架，涵盖19个儿科亚专科和211种典型疾病，从基础知识应用、动态诊断治疗能力、儿科医学安全与伦理三个维度对过去两年发布的12个代表性模型（如GPT-4o、Qwen3-235B-A22B、DeepSeek-V3等）进行综合评估。

Result: 最先进模型在基础知识测试中表现良好（如Qwen3-235B-A22B在执照级问题上准确率超90%），但任务复杂度增加时性能下降约15%；多选题显示整合推理与知识回忆薄弱；在动态诊疗中DeepSeek-R1得分最高（均值0.58），但多数模型难以应对实时病情变化；伦理与安全任务中Qwen2.5-72B表现最佳（准确率92.05%），但人文敏感性仍有限。

Conclusion: 当前儿科大语言模型受限于动态决策能力和人文关怀发展，无法独立执行儿科临床任务。未来应聚焦多模态融合与临床反馈-模型迭代闭环，以提升安全性、可解释性及人机协作水平，推动构建安全可信的智能儿科医疗支持系统。

Abstract: With the rapid rise of large language models (LLMs) in medicine, a key question is whether they can function as competent pediatricians in real-world clinical settings. We developed PEDIASBench, a systematic evaluation framework centered on a knowledge-system framework and tailored to realistic clinical environments. PEDIASBench assesses LLMs across three dimensions: application of basic knowledge, dynamic diagnosis and treatment capability, and pediatric medical safety and medical ethics. We evaluated 12 representative models released over the past two years, including GPT-4o, Qwen3-235B-A22B, and DeepSeek-V3, covering 19 pediatric subspecialties and 211 prototypical diseases. State-of-the-art models performed well on foundational knowledge, with Qwen3-235B-A22B achieving over 90% accuracy on licensing-level questions, but performance declined ~15% as task complexity increased, revealing limitations in complex reasoning. Multiple-choice assessments highlighted weaknesses in integrative reasoning and knowledge recall. In dynamic diagnosis and treatment scenarios, DeepSeek-R1 scored highest in case reasoning (mean 0.58), yet most models struggled to adapt to real-time patient changes. On pediatric medical ethics and safety tasks, Qwen2.5-72B performed best (accuracy 92.05%), though humanistic sensitivity remained limited. These findings indicate that pediatric LLMs are constrained by limited dynamic decision-making and underdeveloped humanistic care. Future development should focus on multimodal integration and a clinical feedback-model iteration loop to enhance safety, interpretability, and human-AI collaboration. While current LLMs cannot independently perform pediatric care, they hold promise for decision support, medical education, and patient communication, laying the groundwork for a safe, trustworthy, and collaborative intelligent pediatric healthcare system.

</details>


### [373] [Mem-PAL: Towards Memory-based Personalized Dialogue Assistants for Long-term User-Agent Interaction](https://arxiv.org/abs/2511.13410)
*Zhaopei Huang,Qifeng Dai,Guozheng Wu,Xiaopeng Wu,Kehan Chen,Chuan Yu,Xubin Li,Tiezheng Ge,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 本文提出了PAL-Bench，一个用于评估服务型对话代理在长期人机交互中个性化能力的新基准，并构建了首个中文多轮用户日志数据集PAL-Set。同时提出H²Memory框架以提升个性化响应生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长期交互中难以捕捉用户的主观特征，缺乏对个性化服务对话系统全面评估的基准和数据集。

Method: 通过多步LLM合成 pipeline 生成模拟用户行为数据，并经人工标注验证构建PAL-Set数据集；基于此建立PAL-Bench评估基准，并提出H²Memory分层异构记忆框架，结合检索增强生成技术提升个性化响应能力。

Result: 实验表明H²Memory在PAL-Bench和外部数据集上均显著优于基线模型，验证了其在长期个性化对话中的有效性。

Conclusion: PAL-Bench和PAL-Set为评估和推动个性化服务型对话系统提供了重要资源，H²Memory框架有效提升了长期交互中的个性化响应生成能力。

Abstract: With the rise of smart personal devices, service-oriented human-agent interactions have become increasingly prevalent. This trend highlights the need for personalized dialogue assistants that can understand user-specific traits to accurately interpret requirements and tailor responses to individual preferences. However, existing approaches often overlook the complexities of long-term interactions and fail to capture users' subjective characteristics. To address these gaps, we present PAL-Bench, a new benchmark designed to evaluate the personalization capabilities of service-oriented assistants in long-term user-agent interactions. In the absence of available real-world data, we develop a multi-step LLM-based synthesis pipeline, which is further verified and refined by human annotators. This process yields PAL-Set, the first Chinese dataset comprising multi-session user logs and dialogue histories, which serves as the foundation for PAL-Bench. Furthermore, to improve personalized service-oriented interactions, we propose H$^2$Memory, a hierarchical and heterogeneous memory framework that incorporates retrieval-augmented generation to improve personalized response generation. Comprehensive experiments on both our PAL-Bench and an external dataset demonstrate the effectiveness of the proposed memory framework.

</details>


### [374] [Non-Linear Scoring Model for Translation Quality Evaluation](https://arxiv.org/abs/2511.13467)
*Serge Gladkoff,Lifeng Han,Katerina Gasova*

Main category: cs.CL

TL;DR: 提出一种基于对数增长误差容忍度的非线性翻译质量评分模型，较传统线性模型更符合人类感知，提升评估的公平性、可解释性和跨系统一致性。


<details>
  <summary>Details</summary>
Motivation: 传统基于线性误差惩罚的翻译质量评估在不同样本长度下存在偏差，短文本被过度惩罚，长文本惩罚不足，与人类感知不一致。

Method: 基于Multi-Range框架，提出E(x) = a * ln(1 + b * x)的非线性模型，利用两个校准点通过一维寻根法确定参数，并结合心理物理学和认知负荷理论进行解释。

Result: 实证数据显示错误容忍度随样本长度对数增长；新模型在±20%相对误差内界定线性近似的适用范围，显著提升人机评估的一致性与可靠性。

Conclusion: 该非线性模型更符合人类对翻译质量的感知，为人工和AI生成文本的质量评估提供了更准确、可扩展的基础，适用于CAT/LQA系统。

Abstract: Analytic Translation Quality Evaluation (TQE), based on Multidimensional Quality Metrics (MQM), traditionally uses a linear error-to-penalty scale calibrated to a reference sample of 1000-2000 words. However, linear extrapolation biases judgment on samples of different sizes, over-penalizing short samples and under-penalizing long ones, producing misalignment with expert intuition.
  Building on the Multi-Range framework, this paper presents a calibrated, non-linear scoring model that better reflects how human content consumers perceive translation quality across samples of varying length. Empirical data from three large-scale enterprise environments shows that acceptable error counts grow logarithmically, not linearly, with sample size.
  Psychophysical and cognitive evidence, including the Weber-Fechner law and Cognitive Load Theory, supports this premise by explaining why the perceptual impact of additional errors diminishes while the cognitive burden grows with scale. We propose a two-parameter model
  E(x) = a * ln(1 + b * x), a, b > 0,
  anchored to a reference tolerance and calibrated from two tolerance points using a one-dimensional root-finding step. The model yields an explicit interval within which the linear approximation stays within +/-20 percent relative error and integrates into existing evaluation workflows with only a dynamic tolerance function added.
  The approach improves interpretability, fairness, and inter-rater reliability across both human and AI-generated translations. By operationalizing a perceptually valid scoring paradigm, it advances translation quality evaluation toward more accurate and scalable assessment. The model also provides a stronger basis for AI-based document-level evaluation aligned with human judgment. Implementation considerations for CAT/LQA systems and implications for human and AI-generated text evaluation are discussed.

</details>


### [375] [Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact on Abnormal Returns](https://arxiv.org/abs/2511.13481)
*Attapol T. Rutherford,Sirisak Chueykamhang,Thachaparn Bunditlurdruk,Nanthicha Angsuwichitkul*

Main category: cs.CL

TL;DR: 本研究提出了一种基于方面的情感分析（ABSA）方法，用于解码泰语财务年报中的隐晦情感，并通过标注数据集和模型评估验证其有效性，发现特定方面的信息对股价有显著影响。


<details>
  <summary>Details</summary>
Motivation: 财务文件常使用模糊语言掩盖真实情况，难以准确判断市场情绪，因此需要更精细的方法来识别隐藏的情感倾向。

Method: 采用方面情感分析（ABSA），制定针对泰语财务报告的隐晦情感标注规范，标注百余份报告，并基于该数据集对多种文本分类模型进行基准测试，同时通过事件研究法分析情感分析结果对股价的实际影响。

Result: 模型在情感分类任务中表现良好，事件研究表明市场对报告中特定方面的信息有显著反应，说明方面级情感分析能有效揭示隐含情感及其市场影响。

Conclusion: 财务文本中的情感分析具有复杂性，需特别关注隐晦表达；本研究所提出的ABSA方法有助于更准确地评估市场情绪和预测市场反应。

Abstract: Understanding sentiment in financial documents is crucial for gaining insights into market behavior. These reports often contain obfuscated language designed to present a positive or neutral outlook, even when underlying conditions may be less favorable. This paper presents a novel approach using Aspect-Based Sentiment Analysis (ABSA) to decode obfuscated sentiment in Thai financial annual reports. We develop specific guidelines for annotating obfuscated sentiment in these texts and annotate more than one hundred financial reports. We then benchmark various text classification models on this annotated dataset, demonstrating strong performance in sentiment classification. Additionally, we conduct an event study to evaluate the real-world implications of our sentiment analysis on stock prices. Our results suggest that market reactions are selectively influenced by specific aspects within the reports. Our findings underscore the complexity of sentiment analysis in financial texts and highlight the importance of addressing obfuscated language to accurately assess market sentiment.

</details>


### [376] [Applying Large Language Models to Characterize Public Narratives](https://arxiv.org/abs/2511.13505)
*Elinor Poole-Dayan,Daniel T Kessler,Hannah Chiou,Margaret Hughes,Emily S Lin,Marshall Ganz,Deb Roy*

Main category: cs.CL

TL;DR: 本研究提出了一种利用大语言模型（LLMs）自动化标注公共叙事（PNs）的计算框架，实现了接近人类专家的性能（平均F1得分为0.80），并应用于更大规模的故事和政治演讲分析，展示了LLM在可扩展叙事分析中的潜力及其局限性。


<details>
  <summary>Details</summary>
Motivation: 公共叙事是领导力发展和公民动员的重要工具，但因其主观解释性和专家标注成本高，系统分析面临挑战。因此需要一种可扩展、高效的自动化分析方法。

Method: 结合领域专家共同制定编码手册，利用大语言模型对公共叙事进行自动定性标注，并与专家标注结果对比评估性能；随后将该方法扩展至22个故事及政治演讲的实证分析。

Result: LLM在8个叙事和14个编码类别上达到平均F1分数0.80，接近人类专家水平；扩展分析揭示了PN框架元素在更大数据集中的表现，并为政治修辞提供了新的分析视角。

Conclusion: LLM辅助的标注方法在公共叙事分析中具有高可行性和扩展性，为计算 civic storytelling 提供新路径，但也需关注其局限性并进一步优化。

Abstract: Public Narratives (PNs) are key tools for leadership development and civic mobilization, yet their systematic analysis remains challenging due to their subjective interpretation and the high cost of expert annotation. In this work, we propose a novel computational framework that leverages large language models (LLMs) to automate the qualitative annotation of public narratives. Using a codebook we co-developed with subject-matter experts, we evaluate LLM performance against that of expert annotators. Our work reveals that LLMs can achieve near-human-expert performance, achieving an average F1 score of 0.80 across 8 narratives and 14 codes. We then extend our analysis to empirically explore how PN framework elements manifest across a larger dataset of 22 stories. Lastly, we extrapolate our analysis to a set of political speeches, establishing a novel lens in which to analyze political rhetoric in civic spaces. This study demonstrates the potential of LLM-assisted annotation for scalable narrative analysis and highlights key limitations and directions for future research in computational civic storytelling.

</details>


### [377] [Toward Conversational Hungarian Speech Recognition: Introducing the BEA-Large and BEA-Dialogue Datasets](https://arxiv.org/abs/2511.13529)
*Máté Gedeon,Piroska Zsófia Barta,Péter Mihajlik,Tekla Etelka Gráczi,Anna Kohári,Katalin Mády*

Main category: cs.CL

TL;DR: 本文介绍了两个新的匈牙利语自发对话语音数据集BEA-Large和BEA-Dialogue，以弥补低资源语言在自动语音识别（ASR）研究中的数据缺口，并提供了可复现的ASR与说话人分离基线结果。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏自发和对话式语料库，匈牙利语等低资源语言在自动语音识别研究中发展受限，亟需高质量、大规模的口语数据集来推动相关技术进步。

Method: 基于未充分使用的BEA匈牙利语语音语料库，构建了两个新数据集：包含255小时自发语音的BEA-Large和包含85小时自然对话的BEA-Dialogue；并使用公开可用的ASR模型（如Fast Conformer）建立可复现的基线，同时进行说话人分离实验。

Result: 微调后的Fast Conformer模型在自发语音上的词错误率低至14.18%，在重复语音上为4.8%；说话人分离错误率介于13.05%至18.26%之间，结果表明对话式ASR仍面临显著挑战。

Conclusion: 所发布的新数据集和基线系统不仅推动匈牙利语语音技术的发展，还为其他语言的自发和对话式语音研究提供了可借鉴的方法论框架。

Abstract: The advancement of automatic speech recognition (ASR) has been largely enhanced by extensive datasets in high-resource languages, while languages such as Hungarian remain underrepresented due to limited spontaneous and conversational corpora. To address this gap, we introduce two new datasets -- BEA-Large and BEA-Dialogue -- constructed from the previously unprocessed portions of the Hungarian speech corpus named BEA. BEA-Large extends BEA-Base with 255 hours of spontaneous speech from 433 speakers, enriched with detailed segment-level metadata. BEA-Dialogue, comprising 85 hours of spontaneous conversations, is a Hungarian speech corpus featuring natural dialogues partitioned into speaker-independent subsets, supporting research in conversational ASR and speaker diarization. We establish reproducible baselines on these datasets using publicly available ASR models, with the fine-tuned Fast Conformer model achieving word error rates as low as 14.18\% on spontaneous and 4.8\% on repeated speech. Diarization experiments yield diarization error rates between 13.05\% and 18.26\%, providing reference points for future improvements. The results highlight the persistent difficulty of conversational ASR, particularly due to disfluencies, overlaps, and informal speech patterns. By releasing these datasets and baselines, we aim to advance Hungarian speech technology and offer a methodological framework for developing spontaneous and conversational benchmarks in other languages.

</details>


### [378] [Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation](https://arxiv.org/abs/2511.13590)
*Hao Wang,Yuanfeng Song,Xiaoming Yin,Xing Chen*

Main category: cs.CL

TL;DR: 提出了一种新的文本到SQL分类的分类法，并基于该分类法构建了更具多样性和覆盖性的合成数据集SQL-Synth，揭示了现有LLM在复杂场景下的不足，但通过微调可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL数据集覆盖范围有限，缺乏多样性，难以反映真实应用场景的复杂性。

Method: 提出一个基于核心意图、语句类型、语法结构和关键操作的分类法，并结合大语言模型设计分类法引导的数据合成 pipeline 来构建新数据集SQL-Synth。

Result: SQL-Synth数据集在多样性和覆盖性上优于现有基准（如Spider和Bird），实验表明现有大语言模型在该数据集上表现有限，但经过微调后性能显著提升。

Conclusion: 所提出的分类法能有效评估和指导Text-to-SQL数据集构建，有助于提升模型在复杂真实场景中的表现。

Abstract: Text-to-SQL datasets are essential for training and evaluating text-to-SQL models, but existing datasets often suffer from limited coverage and fail to capture the diversity of real-world applications. To address this, we propose a novel taxonomy for text-to-SQL classification based on dimensions including core intents, statement types, syntax structures, and key actions. Using this taxonomy, we evaluate widely used public text-to-SQL datasets (e.g., Spider and Bird) and reveal limitations in their coverage and diversity. We then introduce a taxonomy-guided dataset synthesis pipeline, yielding a new dataset named SQL-Synth. This approach combines the taxonomy with Large Language Models (LLMs) to ensure the dataset reflects the breadth and complexity of real-world text-to-SQL applications. Extensive analysis and experimental results validate the effectiveness of our taxonomy, as SQL-Synth exhibits greater diversity and coverage compared to existing benchmarks. Moreover, we uncover that existing LLMs typically fall short in adequately capturing the full range of scenarios, resulting in limited performance on SQL-Synth. However, fine-tuning can substantially improve their performance in these scenarios. The proposed taxonomy has significant potential impact, as it not only enables comprehensive analysis of datasets and the performance of different LLMs, but also guides the construction of training data for LLMs.

</details>


### [379] [Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents](https://arxiv.org/abs/2511.13593)
*Piaohong Wang,Motong Tian,Jiaxian Li,Yuan Liang,Yuqing Wang,Qianben Chen,Tiannan Wang,Zhicong Lu,Jiawei Ma,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种基于主动用户画像的新型记忆框架O-Mem，通过动态提取和更新用户特征与事件记录，提升LLM代理在复杂环境中的长期交互能力，在多个基准上优于现有方法，并提高了响应效率。


<details>
  <summary>Details</summary>
Motivation: 现有的记忆系统依赖语义分组进行检索，容易忽略关键但语义不相关的用户信息，导致上下文不一致和个性化不足，难以支持长期交互。

Method: 提出O-Mem框架，基于用户主动交互动态构建和更新用户画像，采用分层结构存储个性属性和话题相关上下文，实现更精准的记忆检索与个性化响应生成。

Result: 在LoCoMo基准上达到51.76%，较LangMem提升近3%；在PERSONAMEM上达到62.99%，较A-Mem提升3.5%，同时提升了token和交互响应效率。

Conclusion: O-Mem有效改善了LLM代理在长期交互中的上下文一致性与个性化能力，为构建更高效、类人化的AI助手提供了新方向。

Abstract: Recent advancements in LLM-powered agents have demonstrated significant potential in generating human-like responses; however, they continue to face challenges in maintaining long-term interactions within complex environments, primarily due to limitations in contextual consistency and dynamic personalization. Existing memory systems often depend on semantic grouping prior to retrieval, which can overlook semantically irrelevant yet critical user information and introduce retrieval noise. In this report, we propose the initial design of O-Mem, a novel memory framework based on active user profiling that dynamically extracts and updates user characteristics and event records from their proactive interactions with agents. O-Mem supports hierarchical retrieval of persona attributes and topic-related context, enabling more adaptive and coherent personalized responses. O-Mem achieves 51.76% on the public LoCoMo benchmark, a nearly 3% improvement upon LangMem,the previous state-of-the-art, and it achieves 62.99% on PERSONAMEM, a 3.5% improvement upon A-Mem,the previous state-of-the-art. O-Mem also boosts token and interaction response time efficiency compared to previous memory frameworks. Our work opens up promising directions for developing efficient and human-like personalized AI assistants in the future.

</details>


### [380] [Why is "Chicago" Predictive of Deceptive Reviews? Using LLMs to Discover Language Phenomena from Lexical Cues](https://arxiv.org/abs/2511.13658)
*Jiaming Qu,Mengtian Guo,Yue Wang*

Main category: cs.CL

TL;DR: 本文探索了如何利用大语言模型（LLM）将机器学习分类器学到的隐含词汇线索转化为人类可理解的语言现象，以区分欺骗性和真实评论。


<details>
  <summary>Details</summary>
Motivation: 欺骗性评论误导消费者、损害企业并破坏在线市场信任。现有的机器学习模型虽然有效，但其判断依据难以被人理解。

Method: 使用大语言模型将机器学习模型学到的细微、碎片化特征转化为人类可解释的语言现象，并验证其在跨领域场景下的泛化能力。

Result: 转化得到的语言现象具有数据实证基础，跨域通用性更强，且比LLM先验知识或上下文学习获得的现象更具预测力。

Conclusion: 该方法生成的语言现象有助于人们在缺乏自动检测工具时，更有效地识别在线评论的可信度。

Abstract: Deceptive reviews mislead consumers, harm businesses, and undermine trust in online marketplaces. Machine learning classifiers can learn from large amounts of training examples to effectively distinguish deceptive reviews from genuine ones. However, the distinguishing features learned by these classifiers are often subtle, fragmented, and difficult for humans to interpret. In this work, we explore using large language models (LLMs) to translate machine-learned lexical cues into human-understandable language phenomena that can differentiate deceptive reviews from genuine ones. We show that language phenomena obtained in this manner are empirically grounded in data, generalizable across similar domains, and more predictive than phenomena either in LLMs' prior knowledge or obtained through in-context learning. These language phenomena have the potential to aid people in critically assessing the credibility of online reviews in environments where deception detection classifiers are unavailable.

</details>


### [381] [HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization](https://arxiv.org/abs/2505.11225)
*Chengyu Huang,Zhengxin Zhang,Claire Cardie*

Main category: cs.CL

TL;DR: 本文提出了History-Aware Policy Optimization (HAPO)，通过利用历史生成的正确响应中最短长度作为奖励机制，联合优化大语言模型在数学推理任务中的正确性和推理效率，在显著减少输出长度（33-59%）的同时仅造成极小准确率下降（2-5%）。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时扩展方法通常忽略训练过程中对同一问题的历史生成信息，导致无法逐步优化生成更简洁的解决方案。作者希望利用历史状态来提升模型在保持正确性的同时生成更高效、简洁推理的能力。

Method: 提出HAPO方法，为每个问题维护一个历史状态（如历史上最短的正确响应长度），并设计基于该状态的新长度奖励函数，鼓励生成比以往更短且正确的答案；结合正确性奖励，实现正确性与效率的联合优化。

Result: 在多个数学推理基准上验证了HAPO的有效性，使用HAPO训练的1.5B规模模型在不同难度任务上实现了33%-59%的长度缩减，准确率仅下降2%-5%。

Conclusion: HAPO能够有效增强大语言模型的简洁推理能力，通过引入历史感知的奖励机制，在显著降低推理成本的同时保持高性能，为高效推理提供了新思路。

Abstract: While scaling the length of responses at test-time has been shown to markedly improve the reasoning abilities and performance of large language models (LLMs), it often results in verbose outputs and increases inference cost. Prior approaches for efficient test-time scaling, typically using universal budget constraints or query-level length optimization, do not leverage historical information from previous encounters with the same problem during training. We hypothesize that this limits their ability to progressively make solutions more concise over time. To address this, we present History-Aware Policy Optimization (HAPO), which keeps track of a history state (e.g., the minimum length over previously generated correct responses) for each problem. HAPO employs a novel length reward function based on this history state to incentivize the discovery of correct solutions that are more concise than those previously found. Crucially, this reward structure avoids overly penalizing shorter incorrect responses with the goal of facilitating exploration towards more efficient solutions. By combining this length reward with a correctness reward, HAPO jointly optimizes for correctness and efficiency. We use HAPO to train DeepSeek-R1-Distill-Qwen-1.5B, DeepScaleR-1.5B-Preview, and Qwen-2.5-1.5B-Instruct, and evaluate HAPO on several math benchmarks that span various difficulty levels. Experiment results demonstrate that HAPO effectively induces LLMs' concise reasoning abilities, producing length reductions of 33-59% with accuracy drops of only 2-5%.

</details>


### [382] [Crossing Borders: A Multimodal Challenge for Indian Poetry Translation and Image Generation](https://arxiv.org/abs/2511.13689)
*Sofia Jamil,Kotla Sai Charan,Sriparna Saha,Koustava Goswami,Joseph K J*

Main category: cs.CL

TL;DR: 本文提出了一个名为TAI的框架，利用大语言模型和潜在扩散模型，通过翻译和图像生成增强印度语言诗歌的可访问性，支持联合国可持续发展目标中的优质教育和减少不平等。


<details>
  <summary>Details</summary>
Motivation: 印度诗歌语言复杂、文化内涵丰富，但对非母语者理解困难，且现有研究较少关注印度语言诗歌，因此需要提升其可读性和传播性。

Method: 提出TAI框架，包括基于Odds Ratio偏好对齐算法的翻译模块，以及利用语义图捕捉隐喻关系的图像生成模块，并构建包含21种低资源语言、1570首诗的MorphoVerse数据集。

Result: 实验表明TAI在诗歌图像生成任务中优于强基线模型，人类与定量评估均验证了其有效性。

Conclusion: TAI框架有效提升了印度语言诗歌的可访问性与理解度，有助于保护和传播印度丰富的文化遗产。

Abstract: Indian poetry, known for its linguistic complexity and deep cultural resonance, has a rich and varied heritage spanning thousands of years. However, its layered meanings, cultural allusions, and sophisticated grammatical constructions often pose challenges for comprehension, especially for non-native speakers or readers unfamiliar with its context and language. Despite its cultural significance, existing works on poetry have largely overlooked Indian language poems. In this paper, we propose the Translation and Image Generation (TAI) framework, leveraging Large Language Models (LLMs) and Latent Diffusion Models through appropriate prompt tuning. Our framework supports the United Nations Sustainable Development Goals of Quality Education (SDG 4) and Reduced Inequalities (SDG 10) by enhancing the accessibility of culturally rich Indian-language poetry to a global audience. It includes (1) a translation module that uses an Odds Ratio Preference Alignment Algorithm to accurately translate morphologically rich poetry into English, and (2) an image generation module that employs a semantic graph to capture tokens, dependencies, and semantic relationships between metaphors and their meanings, to create visually meaningful representations of Indian poems. Our comprehensive experimental evaluation, including both human and quantitative assessments, demonstrates the superiority of TAI Diffusion in poem image generation tasks, outperforming strong baselines. To further address the scarcity of resources for Indian-language poetry, we introduce the Morphologically Rich Indian Language Poems MorphoVerse Dataset, comprising 1,570 poems across 21 low-resource Indian languages. By addressing the gap in poetry translation and visual comprehension, this work aims to broaden accessibility and enrich the reader's experience.

</details>


### [383] [DCRM: A Heuristic to Measure Response Pair Quality in Preference Optimization](https://arxiv.org/abs/2506.14157)
*Chengyu Huang,Tanya Goyal*

Main category: cs.CL

TL;DR: 提出Distance Calibrated Reward Margin (DCRM)作为衡量偏好优化中响应对质量的新指标，并基于此提出best-of-$N^2$配对方法，提升模型在多个基准上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究试图将偏好优化性能与数据集关联，但忽略了实际学习差异与理想差异之间的不一致；作者旨在通过量化响应对的差异来评估其学习价值。

Method: 引入距离和奖励边距，结合定义DCRM指标；分类分析三类常用偏好数据集；提出基于高DCRM选择响应对的best-of-$N^2$配对方法。

Result: 发现训练集DCRM与学习效果存在普遍正相关；新方法在AlpacaEval、MT-Bench和Arena-Hard等多个评测中优于现有训练集。

Conclusion: DCRM可有效衡量偏好数据质量，基于该指标构建的训练集能显著提升偏好优化效果，验证了数据选择对PO的重要性。

Abstract: Recent research has attempted to associate preference optimization (PO) performance with the underlying preference datasets. In this work, our observation is that the differences between the preferred response $y^+$ and dispreferred response $y^-$ influence what LLMs can learn, which may not match the desirable differences to learn. Therefore, we use distance and reward margin to quantify these differences, and combine them to get Distance Calibrated Reward Margin (DCRM), a metric that measures the quality of a response pair for PO. Intuitively, DCRM encourages minimal noisy differences and maximal desired differences. With this, we study 3 types of commonly used preference datasets, classified along two axes: the source of the responses and the preference labeling function. We establish a general correlation between higher DCRM of the training set and better learning outcome. Inspired by this, we propose a best-of-$N^2$ pairing method that selects response pairs with the highest DCRM. Empirically, in various settings, our method produces training datasets that can further improve models' performance on AlpacaEval, MT-Bench, and Arena-Hard over the existing training sets.

</details>


### [384] [Generalist Foundation Models Are Not Clinical Enough for Hospital Operations](https://arxiv.org/abs/2511.13703)
*Lavender Y. Jiang,Angelica Chen,Xu Han,Xujin Chris Liu,Radhika Dua,Kevin Eaton,Frederick Wolff,Robert Steele,Jeff Zhang,Anton Alyakin,Qingkai Pan,Yanbing Chen,Karl L. Sangwon,Daniel A. Alber,Jaden Stryker,Jin Vivian Lee,Yindalon Aphinyanaphongs,Kyunghyun Cho,Eric Karl Oermann*

Main category: cs.CL

TL;DR: 本文提出了Lang1，一种基于电子健康记录（EHR）数据预训练的专用大模型家族，用于提升医院运营决策中的关键预测任务性能。通过构建真实世界基准ReMedE进行评估，结果表明在特定医疗任务上，经过领域内预训练和监督微调的Lang1显著优于零样本通用模型及更大规模的微调通用模型，验证了领域预训练+监督微调+真实场景评估的技术路径在医疗AI中的有效性。


<details>
  <summary>Details</summary>
Motivation: 通用大模型在医疗运营决策等专业任务上表现不足，因缺乏基于真实临床数据的专门知识。研究旨在探索是否通过在真实EHR数据上进行领域预训练可提升模型在实际医疗场景中的预测能力。

Method: 提出Lang1模型系列，结合800亿来自NYU Langone Health的EHR临床token与6270亿互联网token进行预训练；构建ReMedE基准，包含五个关键医疗预测任务（如再入院、死亡率、住院时长等），基于66.8万份EHR笔记；在零样本和微调设置下评估模型性能，并测试跨任务迁移与外部系统泛化能力。

Result: 在零样本设置下，通用和专用模型在五项任务中四项表现不佳（AUROC 36.6%-71.7%），仅死亡率预测例外；经微调后，Lang1-1B优于高达70倍大的通用微调模型，AUROC提升3.64%-6.75%，且在跨任务联合微调中表现出正向迁移效应；Lang1-1B在外部系统和其他临床任务中也展现出良好泛化能力。

Conclusion: 医疗运营预测需依赖显式的监督微调，而领域内的EHR预训练能显著提高微调效率；专用大模型可通过‘领域预训练+监督微调+真实评估’的范式，在专业任务上超越更大规模的通用模型，为构建高效医疗AI系统提供了可行路径。

Abstract: Hospitals and healthcare systems rely on operational decisions that determine patient flow, cost, and quality of care. Despite strong performance on medical knowledge and conversational benchmarks, foundation models trained on general text may lack the specialized knowledge required for these operational decisions. We introduce Lang1, a family of models (100M-7B parameters) pretrained on a specialized corpus blending 80B clinical tokens from NYU Langone Health's EHRs and 627B tokens from the internet. To rigorously evaluate Lang1 in real-world settings, we developed the REalistic Medical Evaluation (ReMedE), a benchmark derived from 668,331 EHR notes that evaluates five critical tasks: 30-day readmission prediction, 30-day mortality prediction, length of stay, comorbidity coding, and predicting insurance claims denial. In zero-shot settings, both general-purpose and specialized models underperform on four of five tasks (36.6%-71.7% AUROC), with mortality prediction being an exception. After finetuning, Lang1-1B outperforms finetuned generalist models up to 70x larger and zero-shot models up to 671x larger, improving AUROC by 3.64%-6.75% and 1.66%-23.66% respectively. We also observed cross-task scaling with joint finetuning on multiple tasks leading to improvement on other tasks. Lang1-1B effectively transfers to out-of-distribution settings, including other clinical tasks and an external health system. Our findings suggest that predictive capabilities for hospital operations require explicit supervised finetuning, and that this finetuning process is made more efficient by in-domain pretraining on EHR. Our findings support the emerging view that specialized LLMs can compete with generalist models in specialized tasks, and show that effective healthcare systems AI requires the combination of in-domain pretraining, supervised finetuning, and real-world evaluation beyond proxy benchmarks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [385] [LLM-Generated Negative News Headlines Dataset: Creation and Benchmarking Against Real Journalism](https://arxiv.org/abs/2511.11591)
*Olusola Babalola,Bolanle Ojokoh,Olutayo Boyinbode*

Main category: cs.AI

TL;DR: 该研究探讨了使用大语言模型（LLM）生成的合成负面新闻标题作为真实数据替代品在自然语言处理任务中的可行性。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界数据获取困难和隐私问题，同时确保负面情感文本的数据质量。

Method: 通过定制提示生成合成负面新闻标题，并进行专家评审和嵌入空间分析，评估其与真实数据在内容、语气、长度和风格上的一致性。使用多种指标和基准测试进行比较。

Result: 合成标题在大多数指标上与真实标题高度一致，仅在POS标注中的专有名词得分上有明显差异。

Conclusion: LLM生成的合成负面新闻标题可有效作为真实数据的替代，适用于NLP任务，尤其在数据隐私敏感场景下具有应用潜力。

Abstract: This research examines the potential of datasets generated by Large Language Models (LLMs) to support Natural Language Processing (NLP) tasks, aiming to overcome challenges related to data acquisition and privacy concerns associated with real-world data. Focusing on negative valence text, a critical component of sentiment analysis, we explore the use of LLM-generated synthetic news headlines as an alternative to real-world data. A specialized corpus of negative news headlines was created using tailored prompts to capture diverse negative sentiments across various societal domains. The synthetic headlines were validated by expert review and further analyzed in embedding space to assess their alignment with real-world negative news in terms of content, tone, length, and style. Key metrics such as correlation with real headlines, perplexity, coherence, and realism were evaluated. The synthetic dataset was benchmarked against two sets of real news headlines using evaluations including the Comparative Perplexity Test, Comparative Readability Test, Comparative POS Profiling, BERTScore, and Comparative Semantic Similarity. Results show the generated headlines match real headlines with the only marked divergence being in the proper noun score of the POS profile test.

</details>


### [386] [CLINB: A Climate Intelligence Benchmark for Foundational Models](https://arxiv.org/abs/2511.11597)
*Michelle Chen Huebscher,Katharine Mach,Aleksandar Stanić,Markus Leippold,Ben Gaiarin,Zeke Hausfather,Elisa Rawat,Erich Fischer,Massimiliano Ciaramita,Joeri Rogelj,Christian Buck,Lierni Sestorain Saralegui,Reto Knutti*

Main category: cs.AI

TL;DR: 本文提出了CLINB，一个基于气候科学家指导的多模态问答基准，用于评估大语言模型在气候变化领域的知识综合与证据支持能力。研究发现前沿模型虽具备博士级知识整合能力，但存在严重的引用和图像幻觉问题，凸显了知识生成与可验证归因之间的差距。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在复杂专业领域（如气候变化）中处理专门知识的能力仍具挑战性，现有方法缺乏对答案质量、证据支持和真实用户需求的系统衡量。

Method: 构建了CLINB基准，包含真实用户问题和由顶尖气候科学家制定的评估标准；采用基于模型的自动评估方法，并对多个前沿模型进行测试，分析其在开放性、多模态问答中的表现。

Result: 前沿模型展现出接近博士水平的知识综合与表达能力，甚至优于专家借助弱模型生成的混合答案；但在证据支撑方面表现不佳，存在较高的参考文献和图像幻觉率，暴露出生成内容与事实依据之间的脱节。

Conclusion: 实现AI在科学工作流中的可靠应用，必须弥合知识合成与可验证归因之间的鸿沟；需要像CLINB这样可解释、可信赖的基准来推动可信AI系统的发展。

Abstract: Evaluating how Large Language Models (LLMs) handle complex, specialized knowledge remains a critical challenge. We address this through the lens of climate change by introducing CLINB, a benchmark that assesses models on open-ended, grounded, multimodal question answering tasks with clear requirements for knowledge quality and evidential support. CLINB relies on a dataset of real users' questions and evaluation rubrics curated by leading climate scientists. We implement and validate a model-based evaluation process and evaluate several frontier models. Our findings reveal a critical dichotomy. Frontier models demonstrate remarkable knowledge synthesis capabilities, often exhibiting PhD-level understanding and presentation quality. They outperform "hybrid" answers curated by domain experts assisted by weaker models. However, this performance is countered by failures in grounding. The quality of evidence varies, with substantial hallucination rates for references and images. We argue that bridging this gap between knowledge synthesis and verifiable attribution is essential for the deployment of AI in scientific workflows and that reliable, interpretable benchmarks like CLINB are needed to progress towards building trustworthy AI systems.

</details>


### [387] [SynBullying: A Multi LLM Synthetic Conversational Dataset for Cyberbullying Detectio](https://arxiv.org/abs/2511.11599)
*Arefeh Kazemi,Hamza Qadeer,Joachim Wagner,Hossein Hosseini,Sri Balaaji Natarajan Kalaivendan,Brian Davis*

Main category: cs.AI

TL;DR: 本文提出了SynBullying，一个基于多LLM生成的合成对话数据集，用于研究和检测网络欺凌，具有对话结构、上下文感知标注和细粒度分类特点。


<details>
  <summary>Details</summary>
Motivation: 传统网络欺凌数据依赖真实人类交互，存在隐私和伦理风险，且难以获取多轮对话数据，因此需要一种可扩展且伦理安全的数据构建方法。

Method: 利用多个大语言模型模拟真实的网络欺凌对话，构建包含多轮交互、上下文感知标注和细粒度类别标签的合成数据集，并从多个维度进行评估。

Result: SynBullying在对话结构、语义模式、情感/毒性、角色动态、伤害强度和欺凌类型分布方面表现出与真实数据相似的特征，并在分类任务中作为训练或增强数据均展现出良好性能。

Conclusion: SynBullying为网络欺凌研究提供了一种高效、安全且可扩展的数据资源，验证了合成数据在该领域的应用潜力。

Abstract: We introduce SynBullying, a synthetic multi-LLM conversational dataset for studying and detecting cyberbullying (CB). SynBullying provides a scalable and ethically safe alternative to human data collection by leveraging large language models (LLMs) to simulate realistic bullying interactions. The dataset offers (i) conversational structure, capturing multi-turn exchanges rather than isolated posts; (ii) context-aware annotations, where harmfulness is assessed within the conversational flow considering context, intent, and discourse dynamics; and (iii) fine-grained labeling, covering various CB categories for detailed linguistic and behavioral analysis. We evaluate SynBullying across five dimensions, including conversational structure, lexical patterns, sentiment/toxicity, role dynamics, harm intensity, and CB-type distribution. We further examine its utility by testing its performance as standalone training data and as an augmentation source for CB classification.

</details>


### [388] [CausalGuard: A Smart System for Detecting and Preventing False Information in Large Language Models](https://arxiv.org/abs/2511.11600)
*Piyushkumar Patel*

Main category: cs.AI

TL;DR: CausalGuard是一种结合因果推理与符号逻辑的新方法，用于实时检测和防止大语言模型产生幻觉（虚假信息）。


<details>
  <summary>Details</summary>
Motivation: 大语言模型常自信地生成看似合理但错误的信息（即“幻觉”问题），这限制了其在高精度要求场景中的应用。现有方法需重新训练模型、计算成本高或未能解决根本原因。

Method: CausalGuard通过两条路径工作：一是追踪模型知识与生成内容之间的因果关系链，二是在生成过程中利用自动化推理进行逻辑一致性检查，从而在早期干预以防止幻觉产生。

Result: 在十二个基准测试中，CausalGuard能以89.3%的准确率识别幻觉，漏检率仅为8.3%，并减少近80%的错误陈述，同时保持回答的自然性和帮助性，尤其在多步复杂推理任务中表现优异。

Conclusion: CausalGuard有效减少了大语言模型的幻觉问题，且具备可解释性，适用于医疗诊断、金融分析等对决策透明度要求高的领域。

Abstract: While large language models have transformed how we interact with AI systems, they have a critical weakness: they confidently state false information that sounds entirely plausible. This "hallucination" problem has become a major barrier to using these models where accuracy matters most. Existing solutions either require retraining the entire model, add significant computational costs, or miss the root causes of why these hallucinations occur in the first place.
  We present CausalGuard, a new approach that combines causal reasoning with symbolic logic to catch and prevent hallucinations as they happen. Unlike previous methods that only check outputs after generation, our system understands the causal chain that leads to false statements and intervenes early in the process. CausalGuard works through two complementary paths: one that traces causal relationships between what the model knows and what it generates, and another that checks logical consistency using automated reasoning.
  Testing across twelve different benchmarks, we found that CausalGuard correctly identifies hallucinations 89.3\% of the time while missing only 8.3\% of actual hallucinations. More importantly, it reduces false claims by nearly 80\% while keeping responses natural and helpful. The system performs especially well on complex reasoning tasks where multiple steps of logic are required. Because CausalGuard shows its reasoning process, it works well in sensitive areas like medical diagnosis or financial analysis where understanding why a decision was made matters as much as the decision itself.

</details>


### [389] [Quantifying Skill and Chance: A Unified Framework for the Geometry of Games](https://arxiv.org/abs/2511.11611)
*David H. Silver*

Main category: cs.AI

TL;DR: 提出了一种量化游戏技能与运气成分的框架，通过将游戏建模为随机决策树，定义了技能-运气指数S(G)和波动性Sigma，分析了30款游戏，揭示了从纯运气到纯技能的连续谱，并可用于游戏设计、AI评估和风险分析。


<details>
  <summary>Details</summary>
Motivation: 区分游戏中技能和运气的贡献对于理解游戏平衡、玩家控制力和结果可预测性至关重要，但缺乏统一的量化方法。

Method: 将游戏建模为技能与运气作为互补控制源的随机决策树，定义技能杠杆K和运气杠杆L，进而构建技能-运气指数S(G) ∈ [-1, 1]，并引入波动性Sigma衡量回合间结果不确定性。

Result: 在30款游戏中应用该框架，成功量化了技能与运气比例：硬币 toss（S=-1，纯运气）、双陆棋（S=0）、扑克（S=0.33，技能主导中等）、国际象棋（S=+1，纯技能，Sigma=0）；同时发现如双陆棋Sigma=1.20，表明高不确定性。

Conclusion: 该框架为分析技能与运气在游戏中的作用提供了可扩展的量化工具，能够支持游戏设计优化、AI性能评估及更广泛的随机决策系统风险评估。

Abstract: We introduce a quantitative framework for separating skill and chance in games by modeling them as complementary sources of control over stochastic decision trees. We define the Skill-Luck Index S(G) in [-1, 1] by decomposing game outcomes into skill leverage K and luck leverage L. Applying this to 30 games reveals a continuum from pure chance (coin toss, S = -1) through mixed domains such as backgammon (S = 0, Sigma = 1.20) to pure skill (chess, S = +1, Sigma = 0). Poker exhibits moderate skill dominance (S = 0.33) with K = 0.40 +/- 0.03 and Sigma = 0.80. We further introduce volatility Sigma to quantify outcome uncertainty over successive turns. The framework extends to general stochastic decision systems, enabling principled comparisons of player influence, game balance, and predictive stability, with applications to game design, AI evaluation, and risk assessment.

</details>


### [390] [Value-Aligned Prompt Moderation via Zero-Shot Agentic Rewriting for Safe Image Generation](https://arxiv.org/abs/2511.11693)
*Xin Zhao,Xiaojun Chen,Bingshan Liu,Zeyao Liu,Zhendong Zhao,Xiaoyan Gu*

Main category: cs.AI

TL;DR: 本文提出了VALOR，一种模块化、零样本的代理框架，用于实现更安全、更有帮助的文本到图像生成。该框架结合多层提示分析与价值对齐推理，通过检测和重写机制减少不安全内容输出，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法难以在不牺牲生成质量或带来高成本的情况下使生成内容与人类价值观保持一致，且生成模型易受对抗性提示影响产生不当内容。

Method: VALOR包含多级NSFW检测器、文化价值对齐模块和意图消歧器，检测潜在风险；当发现不安全提示时，利用大语言模型根据动态指令重写提示；若图像仍不安全，则进行风格化再生以引导输出至更安全的视觉域。

Result: 实验表明，VALOR在对抗性、模糊性和价值敏感性提示下可将不安全输出减少高达100.00%，同时保持提示的有用性和创造性。

Conclusion: VALOR是一种可扩展且有效的方法，有助于在开放环境中部署安全、价值对齐且有益的图像生成系统。

Abstract: Generative vision-language models like Stable Diffusion demonstrate remarkable capabilities in creative media synthesis, but they also pose substantial risks of producing unsafe, offensive, or culturally inappropriate content when prompted adversarially. Current defenses struggle to align outputs with human values without sacrificing generation quality or incurring high costs. To address these challenges, we introduce VALOR (Value-Aligned LLM-Overseen Rewriter), a modular, zero-shot agentic framework for safer and more helpful text-to-image generation. VALOR integrates layered prompt analysis with human-aligned value reasoning: a multi-level NSFW detector filters lexical and semantic risks; a cultural value alignment module identifies violations of social norms, legality, and representational ethics; and an intention disambiguator detects subtle or indirect unsafe implications. When unsafe content is detected, prompts are selectively rewritten by a large language model under dynamic, role-specific instructions designed to preserve user intent while enforcing alignment. If the generated image still fails a safety check, VALOR optionally performs a stylistic regeneration to steer the output toward a safer visual domain without altering core semantics. Experiments across adversarial, ambiguous, and value-sensitive prompts show that VALOR significantly reduces unsafe outputs by up to 100.00% while preserving prompt usefulness and creativity. These results highlight VALOR as a scalable and effective approach for deploying safe, aligned, and helpful image generation systems in open-world settings.

</details>


### [391] [Towards autonomous quantum physics research using LLM agents with access to intelligent tools](https://arxiv.org/abs/2511.11752)
*Sören Arlt,Xuemei Gu,Mario Krenn*

Main category: cs.AI

TL;DR: AI-Mandel是一个能够生成并实现在量子物理领域具体实验设计的LLM代理，展示了AI在科学创意生成与实施中的潜力。


<details>
  <summary>Details</summary>
Motivation: 自动化科学中的创意生成和实施，减少人类在科研过程中的主导角色，加速科学发现。

Method: 利用大语言模型（LLM）从文献中提出想法，并结合特定领域的AI工具将其转化为可执行的实验设计。

Result: 成功生成多个科学上有意义的想法，包括量子隐形传态的新变体、不定因果序下的量子网络原语以及基于量子信息传输闭环的几何相位新概念；其中两个想法已发展为独立科研论文。

Conclusion: AI-Mandel是迈向全自动AI科学家的重要原型，揭示了实现人类水平AI科学家所面临的具体挑战。

Abstract: Artificial intelligence (AI) is used in numerous fields of science, yet the initial research questions and targets are still almost always provided by human researchers. AI-generated creative ideas in science are rare and often vague, so that it remains a human task to execute them. Automating idea generation and implementation in one coherent system would significantly shift the role of humans in the scientific process. Here we present AI-Mandel, an LLM agent that can generate and implement ideas in quantum physics. AI-Mandel formulates ideas from the literature and uses a domain-specific AI tool to turn them into concrete experiment designs that can readily be implemented in laboratories. The generated ideas by AI-Mandel are often scientifically interesting - for two of them we have already written independent scientific follow-up papers. The ideas include new variations of quantum teleportation, primitives of quantum networks in indefinite causal orders, and new concepts of geometric phases based on closed loops of quantum information transfer. AI-Mandel is a prototypical demonstration of an AI physicist that can generate and implement concrete, actionable ideas. Building such a system is not only useful to accelerate science, but it also reveals concrete open challenges on the path to human-level artificial scientists.

</details>


### [392] [Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction](https://arxiv.org/abs/2511.11770)
*Floris Vossebeld,Shenghui Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的智能体框架，用于通过迭代方式生成SPARQL查询，显著提升了多跳知识图谱问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型在一次性生成复杂SPARQL查询时表现脆弱，缺乏根据执行反馈动态调试的能力，限制了其在知识图谱问答中的可靠性。

Method: 提出一种基于LLM的智能体框架，采用结果驱动的强化学习（GRPO）训练一个3B参数模型，通过迭代构造和执行反馈逐步修正SPARQL查询，引入显式的推理步骤提升策略精度。

Result: 在LC-QuAD 2.0的一个可执行子集上，该方法在实体链接后达到49.7%的准确率，比最强的零样本基线提升了17.5个百分点。

Conclusion: 该工作展示了通过交互式学习使小规模LLM掌握形式化符号工具的可行性，为连接概率性语言模型与结构化知识图谱提供了可推广的范式。

Abstract: Generating complex, logically-sound SPARQL queries for multi-hop questions remains a critical bottleneck for Knowledge Graph Question Answering, as the brittle nature of one-shot generation by Large Language Models (LLMs) hinders reliable interaction with structured data. Current methods lack the adaptive policies needed to dynamically debug queries based on real-time execution feedback. This paper introduces a novel agentic framework where an LLM learns a resilient policy for the sequential process of iterative SPARQL construction. We show that a compact 3B-parameter model, trained exclusively via outcome-driven Reinforcement Learning (GRPO) without supervised fine-tuning, can learn effective policies for this task, discovering how to systematically recover from execution errors and refine its queries toward a correct answer. On a curated, executable single-answer subset of LC-QuAD 2.0, our agent achieves 49.7\% accuracy post-entity-linking, a significant 17.5 percentage point improvement over the strongest iterative zero-shot baseline. Further analysis reveals that while the agent's capability is driven by RL, its performance is enhanced by an explicit deliberative reasoning step that acts as a cognitive scaffold to improve policy precision. This work presents a generalizable blueprint for teaching agents to master formal, symbolic tools through interaction, bridging the gap between probabilistic LLMs and the structured world of Knowledge Graphs.

</details>


### [393] [On the Measure of a Model: From Intelligence to Generality](https://arxiv.org/abs/2511.11773)
*Ruchira Dhar,Ninell Oldenburg,Anders Soegaard*

Main category: cs.AI

TL;DR: 该论文认为当前基于抽象“智能”概念的LLM评估基准（如ARC、Raven测试）缺乏稳定定义且与实际任务脱节，提出应以“通用性”为核心评估标准，通过多任务学习框架实现更可靠和广泛的能力衡量。


<details>
  <summary>Details</summary>
Motivation: 现有智能评估基准缺乏明确定义，无法预测模型在实际任务中的表现，导致评估与真实应用脱节。

Method: 通过概念分析和形式化论证，检验智能评估背后的三个假设：通用性、稳定性和现实性，并论证只有通用性经得起检验。

Result: 发现‘通用性’是唯一稳健的评估基础，且通用性应被视为一个多任务学习问题，能直接关联到性能的广度和可靠性。

Conclusion: 应以通用性取代抽象的‘智能’作为AI能力评估的核心标准，为多样化和动态演进的任务提供更稳定的评估基础。

Abstract: Benchmarks such as ARC, Raven-inspired tests, and the Blackbird Task are widely used to evaluate the intelligence of large language models (LLMs). Yet, the concept of intelligence remains elusive- lacking a stable definition and failing to predict performance on practical tasks such as question answering, summarization, or coding. Optimizing for such benchmarks risks misaligning evaluation with real-world utility. Our perspective is that evaluation should be grounded in generality rather than abstract notions of intelligence. We identify three assumptions that often underpin intelligence-focused evaluation: generality, stability, and realism. Through conceptual and formal analysis, we show that only generality withstands conceptual and empirical scrutiny. Intelligence is not what enables generality; generality is best understood as a multitask learning problem that directly links evaluation to measurable performance breadth and reliability. This perspective reframes how progress in AI should be assessed and proposes generality as a more stable foundation for evaluating capability across diverse and evolving tasks.

</details>


### [394] [Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via a Novel Benchmarking Strategy](https://arxiv.org/abs/2511.11816)
*Andrea Brunello,Luca Geatti,Michele Mignani,Angelo Montanari,Nicola Saccomanno*

Main category: cs.AI

TL;DR: 本文研究了自然语言到一阶逻辑（NL-FOL）翻译的挑战，指出现有评估数据集和协议的局限性，提出了一种新的评估方法，并发现最先进的对话型大语言模型在NL-FOL翻译任务上表现优异，具备真正的语义逻辑理解能力，而以嵌入为中心的模型则表现较差。


<details>
  <summary>Details</summary>
Motivation: 由于一阶逻辑（FOL）表达能力强且无歧义，将自然语言准确转化为FOL具有重要意义，但现有评估方法可能高估了大语言模型的真实能力，因此需要更严谨的评估机制来区分模型是真正理解逻辑结构还是仅依赖表面模式或数据污染。

Method: 首先批判性分析现有NL-FOL翻译评估数据集和协议的缺陷；其次提出一种新的评估协议，旨在区分模型的深层语义理解与浅层模式匹配或记忆行为；最后通过该协议评估多种大语言模型的表现。

Result: 研究发现当前最先进的对话型大语言模型在改进后的评估中展现出强大的NL-FOL翻译能力和句子级逻辑理解，而以嵌入为核心的模型表现明显较差。新评估协议能更真实地反映模型的逻辑推理能力。

Conclusion: 对话型大语言模型在适当的评估框架下展现出对自然语言到一阶逻辑转换的实质性理解，表明其具备一定的形式化逻辑推理潜力，而传统嵌入模型则不具备这一能力。

Abstract: Due to its expressiveness and unambiguous nature, First-Order Logic (FOL) is a powerful formalism for representing concepts expressed in natural language (NL). This is useful, e.g., for specifying and verifying desired system properties. While translating FOL into human-readable English is relatively straightforward, the inverse problem, converting NL to FOL (NL-FOL translation), has remained a longstanding challenge, for both humans and machines. Although the emergence of Large Language Models (LLMs) promised a breakthrough, recent literature provides contrasting results on their ability to perform NL-FOL translation. In this work, we provide a threefold contribution. First, we critically examine existing datasets and protocols for evaluating NL-FOL translation performance, revealing key limitations that may cause a misrepresentation of LLMs' actual capabilities. Second, to overcome these shortcomings, we propose a novel evaluation protocol explicitly designed to distinguish genuine semantic-level logical understanding from superficial pattern recognition, memorization, and dataset contamination. Third, using this new approach, we show that state-of-the-art, dialogue-oriented LLMs demonstrate strong NL-FOL translation skills and a genuine grasp of sentence-level logic, whereas embedding-centric models perform markedly worse.

</details>


### [395] [TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models](https://arxiv.org/abs/2511.11831)
*Wenhao Zhou,Hao Zheng,Rong Zhao*

Main category: cs.AI

TL;DR: 本文提出了TopoPerception，一个基于拓扑属性的基准，用于严格评估大视觉语言模型（LVLMs）的全局视觉感知能力。由于拓扑依赖于图像的整体结构且对局部特征不变，该基准可避免局部捷径，实现无偏差的评估。实验表明，现有模型在该任务上表现接近随机水平，且更强的模型反而表现更差，说明当前架构存在根本性瓶颈，需新的训练范式或结构改进。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型评估基准常包含局部捷径，导致对模型全局感知能力的高估，因此需要一种能够真正测试模型全局视觉理解能力的无偏评估方法。

Method: 提出TopoPerception基准，利用拓扑学中全局结构敏感而局部特征不变的性质，设计多粒度任务来评估LVLMs的全局视觉感知能力，并在多个先进模型上进行测试。

Result: 所有被测模型在TopoPerception上的表现均接近随机水平，且在模型家族中观察到更强推理能力的模型准确率反而更低，显示出全局感知的严重缺陷。

Conclusion: 当前LVLMs在全局视觉感知方面存在根本性缺陷，单纯扩大模型规模无法解决甚至可能加剧问题，未来需探索新的训练范式或模型架构。TopoPerception为改进LVLM提供了新的评估视角和方向。

Abstract: Large Vision-Language Models (LVLMs) typically align visual features from an encoder with a pre-trained Large Language Model (LLM). However, this makes the visual perception module a bottleneck, which constrains the overall capabilities of LVLMs. Conventional evaluation benchmarks, while rich in visual semantics, often contain unavoidable local shortcuts that can lead to an overestimation of models' perceptual abilities. Here, we introduce TopoPerception, a benchmark that leverages topological properties to rigorously evaluate the global visual perception capabilities of LVLMs across various granularities. Since topology depends on the global structure of an image and is invariant to local features, TopoPerception enables a shortcut-free assessment of global perception, fundamentally distinguishing it from semantically rich tasks. We evaluate state-of-the-art models on TopoPerception and find that even at the coarsest perceptual granularity, all models perform no better than random chance, indicating a profound inability to perceive global visual features. Notably, a consistent trend emerge within model families: more powerful models with stronger reasoning capabilities exhibit lower accuracy. This suggests that merely scaling up models is insufficient to address this deficit and may even exacerbate it. Progress may require new training paradigms or architectures. TopoPerception not only exposes a critical bottleneck in current LVLMs but also offers a lens and direction for improving their global visual perception. The data and code are publicly available at: https://github.com/Wenhao-Zhou/TopoPerception.

</details>


### [396] [End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction](https://arxiv.org/abs/2511.11899)
*Xi Li,Nicholas Matsumoto,Ujjwal Pasupulety,Atharva Deo,Cherine Yang,Jay Moran,Miguel E. Hernandez,Peter Wager,Jasmine Lin,Jeanine Kim,Alvin C. Goh,Christian Wagner,Geoffrey A. Sonn,Andrew J. Hung*

Main category: cs.AI

TL;DR: 提出了一种端到端系统Frame-to-Outcome（F2O），可将手术视频转化为操作序列，并发现与术后结果相关的模式，支持自动化、可解释的术中行为分析。


<details>
  <summary>Details</summary>
Motivation: 术中行为对患者预后的影响缺乏细粒度分析方法，亟需自动化、可量化的工具来挖掘手术视频中的关键行为模式。

Method: 基于Transformer的空间-时间建模与逐帧分类，从机器人辅助前列腺切除术视频中提取短时操作（约2秒）序列，并提取频率、持续时间和转换等特征以预测术后结果。

Result: F2O在帧级和视频级AUC分别为0.80和0.81；预测术后结果的准确率为0.79，与人工标注相当（0.75），特征效应方向一致且高度相关（r=0.96）；识别出与勃起功能恢复相关的关键操作模式，如长时间组织剥离和减少能量使用。

Conclusion: F2O实现了对手术行为的自动、可解释分析，为数据驱动的手术反馈和前瞻性临床决策支持提供了可行框架。

Abstract: Fine-grained analysis of intraoperative behavior and its impact on patient outcomes remain a longstanding challenge. We present Frame-to-Outcome (F2O), an end-to-end system that translates tissue dissection videos into gesture sequences and uncovers patterns associated with postoperative outcomes. Leveraging transformer-based spatial and temporal modeling and frame-wise classification, F2O robustly detects consecutive short (~2 seconds) gestures in the nerve-sparing step of robot-assisted radical prostatectomy (AUC: 0.80 frame-level; 0.81 video-level). F2O-derived features (gesture frequency, duration, and transitions) predicted postoperative outcomes with accuracy comparable to human annotations (0.79 vs. 0.75; overlapping 95% CI). Across 25 shared features, effect size directions were concordant with small differences (~ 0.07), and strong correlation (r = 0.96, p < 1e-14). F2O also captured key patterns linked to erectile function recovery, including prolonged tissue peeling and reduced energy use. By enabling automatic interpretable assessment, F2O establishes a foundation for data-driven surgical feedback and prospective clinical decision support.

</details>


### [397] [Forgetting-MarI: LLM Unlearning via Marginal Information Regularization](https://arxiv.org/abs/2511.11914)
*Shizhou Xu,Yuan Ni,Stefan Broecker,Thomas Strohmer*

Main category: cs.AI

TL;DR: 本文提出了一种名为Forgetting-MarI的LLM遗忘框架，可精确移除待遗忘数据带来的边际信息，同时保留其余数据支持的知识，实现可证明的不可检测性，并在保持模型性能的同时显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型训练数据的不断扩展，出于隐私保护和合规需求，有必要从已训练模型中移除特定数据的影响。现有遗忘方法往往过度删除信息，导致模型性能下降。

Method: 提出Forgetting-MarI框架，通过惩罚待遗忘数据带来的边际信息，仅移除其额外贡献的信息，保留其他数据支持的知识，并提供模型中残留影响的显式上界，确保可证明的遗忘效果。

Result: 实验表明，该方法在多种基准上优于当前最先进的遗忘方法，实现了可靠的遗忘效果并更好保持了模型的通用性能。

Conclusion: Forgetting-MarI为构建更可控、符合隐私与版权法规且不牺牲有效性的AI系统提供了重要进展。

Abstract: As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget'' specific data. We introduce Forgetting-MarI, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset's residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.

</details>


### [398] [An Analysis of Architectural Impact on LLM-based Abstract Visual Reasoning: A Systematic Benchmark on RAVEN-FAIR](https://arxiv.org/abs/2511.11916)
*Sinan Urgun,Seçkin Arı*

Main category: cs.AI

TL;DR: 本研究系统评估了四种大语言模型在RAVEN-FAIR数据集上的抽象视觉推理能力，结合四种推理架构，发现GPT-4.1-Mini在所有架构下表现最佳，且模型对架构设计具有特异性敏感，多运行策略有助于提升评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 旨在系统评估大语言模型在抽象视觉推理任务中的性能，并探究不同推理架构对其表现的影响。

Method: 采用GPT-4.1-Mini、Claude-3.5-Haiku、Gemini-1.5-Flash和Llama-3.3-70b四种LLM，结合单次推理、嵌入控制重复、自反思和多智能体四种架构，在RAVEN-FAIR数据集上通过三阶段流程生成视觉响应，并使用SSIM、LPIPS指标及思维链得分进行评估，同时分析语义幻觉和数字误判等错误类型。

Result: GPT-4.1-Mini在所有架构下均表现出最高的整体准确率；多智能体架构对语义与数字平衡有一定影响但效果不一致；各模型对架构设计表现出不同的敏感性；响应覆盖率差异成为跨架构比较的干扰因素；通过五次独立运行取最优结果显著提升了性能估计的上限。

Conclusion: 大语言模型在抽象视觉推理中的表现具有模型特异性，GPT-4.1-Mini展现出最强的推理能力，且推理架构的效果因模型而异，建议采用多运行策略以获得更可靠的评估结果。

Abstract: This study aims to systematically evaluate the performance of large language models (LLMs) in abstract visual reasoning problems. We examined four LLM models (GPT-4.1-Mini, Claude-3.5-Haiku, Gemini-1.5-Flash, Llama-3.3-70b) utilizing four different reasoning architectures (single-shot, embedding-controlled repetition, self-reflection, and multi-agent) on the RAVEN-FAIR dataset. Visual responses generated through a three-stage process (JSON extraction, LLM reasoning, and Tool Function) were evaluated using SSIM and LPIPS metrics; Chain-of-Thought scores and error types (semantic hallucination, numeric misperception) were analyzed. Results demonstrate that GPT-4.1-Mini consistently achieved the highest overall accuracy across all architectures, indicating a strong reasoning capability. While the multi-agent architecture occasionally altered semantic and numeric balance across models, these effects were not uniformly beneficial. Instead, each model exhibited distinct sensitivity patterns to architectural design, underscoring that reasoning effectiveness remains model-specific. Variations in response coverage further emerged as a confounding factor that complicates direct cross-architecture comparison. To estimate the upper-bound performance of each configuration, we report the best of five independent runs, representing a best-case scenario rather than an averaged outcome. This multi-run strategy aligns with recent recommendations, which emphasize that single-run evaluations are fragile and may lead to unreliable conclusions.

</details>


### [399] [Looking Forward: Challenges and Opportunities in Agentic AI Reliability](https://arxiv.org/abs/2511.11921)
*Liudong Xing,Janet,Lin*

Main category: cs.AI

TL;DR: 本章探讨了构建可靠AI系统（特别是代理式AI系统）的挑战与未来发展方向，重点讨论了级联故障风险、动态环境、任务执行不一致、不可预测的 emergent 行为以及高资源消耗的可靠性机制等开放性研究问题，并提出了在测试和评估代理式AI系统可靠性方面的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着代理式AI系统在复杂环境中的广泛应用，其可靠性问题日益突出，尤其是在面对动态变化和自主决策时可能出现级联故障和不可预测行为，亟需系统性研究以提升其安全性和稳定性。

Method: 通过综述现有研究，分析代理式AI系统在实际应用中面临的可靠性挑战，识别关键风险因素，并提出未来可能的研究路径，特别是在测试与评估方法方面的创新方向。

Result: 明确了影响代理式AI系统可靠性的五大核心挑战：级联故障、动态环境适应性、任务执行一致性、 emergent 行为的不可预测性以及可靠性机制的资源开销；并指出了在测试框架、评估指标和验证方法上的研究空白。

Conclusion: 构建可靠的代理式AI系统需要跨学科合作，发展新的理论框架和工程实践，特别是在动态环境中实现鲁棒性和可预测性，并建立高效的可靠性测试与评估体系。

Abstract: This chapter presents perspectives for challenges and future development in building reliable AI systems, particularly, agentic AI systems. Several open research problems related to mitigating the risks of cascading failures are discussed. The chapter also sheds lights on research challenges and opportunities in aspects including dynamic environments, inconsistent task execution, unpredictable emergent behaviors, as well as resource-intensive reliability mechanisms. In addition, several research directions along the line of testing and evaluating reliability of agentic AI systems are also discussed.

</details>


### [400] [A Neuromorphic Architecture for Scalable Event-Based Control](https://arxiv.org/abs/2511.11924)
*Yongkang Huo,Fulvio Forni,Rodolphe Sepulchre*

Main category: cs.AI

TL;DR: 本文提出了“反弹胜者为王（RWTA）”模组，作为可扩展的神经形态控制架构的基本单元，结合了离散计算的可靠性和连续调节的可调性。


<details>
  <summary>Details</summary>
Motivation: 为了实现兼具可靠性与可调性的神经形态控制系统，需要一种能够统一描述连续节律生成和离散决策的架构。

Method: 提出基于事件的RWTA模组框架，融合胜者为王状态机的离散计算能力和可兴奋生物物理电路的连续调节能力。

Result: 在蛇形机器人神经系统设计中验证了该架构的多功能性、鲁棒性和模块化特性。

Conclusion: RWTA架构为从细胞级到系统级的可扩展、统一的神经形态控制提供了一种有效解决方案。

Abstract: This paper introduces the ``rebound Winner-Take-All (RWTA)" motif as the basic element of a scalable neuromorphic control architecture. From the cellular level to the system level, the resulting architecture combines the reliability of discrete computation and the tunability of continuous regulation: it inherits the discrete computation capabilities of winner-take-all state machines and the continuous tuning capabilities of excitable biophysical circuits. The proposed event-based framework addresses continuous rhythmic generation and discrete decision-making in a unified physical modeling language. We illustrate the versatility, robustness, and modularity of the architecture through the nervous system design of a snake robot.

</details>


### [401] [Augmenting The Weather: A Hybrid Counterfactual-SMOTE Algorithm for Improving Crop Growth Prediction When Climate Changes](https://arxiv.org/abs/2511.11945)
*Mohammed Temraz,Mark T Keane*

Main category: cs.AI

TL;DR: 提出一种名为CFA-SMOTE的新型数据增强方法，结合XAI中的反事实方法与SMOTE，用于解决气候变化预测中历史数据缺乏极端事件（少数类）导致的分布外预测难题，在爱尔兰乳品农场草料生长预测任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化带来的极端天气事件在历史数据中罕见，传统机器学习难以处理此类分布外预测问题，因此需解决气候预测中的数据分布偏移与少数类样本不足问题。

Method: 将基于实例的反事实解释方法与SMOTE相结合，提出CFA-SMOTE，通过生成代表气候异常事件的合成数据点来增强训练集，从而改善模型对极端事件的预测能力。

Result: 在不同类别不平衡比例下进行对比实验，CFA-SMOTE在预测2018年欧洲干旱期间爱尔兰牧场草料生长的任务中，优于基准反事实和类别不平衡处理方法。

Conclusion: CFA-SMOTE能有效缓解因历史数据缺乏气候异常事件而导致的预测性能下降问题，为应对气候变化相关预测挑战提供了一种可行的数据增强解决方案。

Abstract: In recent years, humanity has begun to experience the catastrophic effects of climate change as economic sectors (such as agriculture) struggle with unpredictable and extreme weather events. Artificial Intelligence (AI) should help us handle these climate challenges but its most promising solutions are not good at dealing with climate-disrupted data; specifically, machine learning methods that work from historical data-distributions, are not good at handling out-of-distribution, outlier events. In this paper, we propose a novel data augmentation method, that treats the predictive problems around climate change as being, in part, due to class-imbalance issues; that is, prediction from historical datasets is difficult because, by definition, they lack sufficient minority-class instances of "climate outlier events". This novel data augmentation method -- called Counterfactual-Based SMOTE (CFA-SMOTE) -- combines an instance-based counterfactual method from Explainable AI (XAI) with the well-known class-imbalance method, SMOTE. CFA-SMOTE creates synthetic data-points representing outlier, climate-events that augment the dataset to improve predictive performance. We report comparative experiments using this CFA-SMOTE method, comparing it to benchmark counterfactual and class-imbalance methods under different conditions (i.e., class-imbalance ratios). The focal climate-change domain used relies on predicting grass growth on Irish dairy farms, during Europe-wide drought and forage crisis of 2018.

</details>


### [402] [LLM-Assisted Formalization Enables Deterministic Detection of Statutory Inconsistency in the Internal Revenue Code](https://arxiv.org/abs/2511.11954)
*Borchuluun Yadamsuren,Steven Keith Platt,Miguel Diaz*

Main category: cs.AI

TL;DR: 本研究提出一种结合大语言模型（LLM）与符号逻辑的神经符号混合框架，用于确定性地检测美国税法典中的法定不一致性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在法律合规、公平性和法规起草中具有潜力，但在处理复杂、层次化的长文本时存在推理不足的问题，尤其是在税务领域应用较少。因此，需要一种能提升结构化推理能力的方法来有效识别法规冲突。

Method: 采用GPT-4o将《美国国内税收法典》第121条转化为Prolog规则，并通过SWISH平台优化；使用Prolog增强提示以测试对GPT-4o不一致检测性能的影响；同时利用GPT-5辅助完善符号模型，构建可确定性运行的混合系统。

Result: GPT-4o在三种策略中仅有一种成功检测到不一致（准确率33%），且自然语言提示的规则覆盖率为100%，而Prolog增强提示仅为66%；相比之下，基于Prolog的混合模型实现了准确、内部一致、可重现和自主检测不一致的结果。

Conclusion: 基于符号逻辑的LLM辅助形式化方法能够实现透明、可靠且确定性的法定不一致性检测，优于纯概率性大模型提示方法。

Abstract: This study introduces a hybrid neuro-symbolic framework that achieves deterministic detection of statutory inconsistency in complex law. We use the U.S. Internal Revenue Code (IRC) as a case study because its complexity makes it a fertile domain for identifying conflicts. Our research offers a solution for detecting inconsistent provisions by combining Large Language Models (LLMs) with symbolic logic.
  LLM-based methods can support compliance, fairness, and statutory drafting, yet tax-specific applications remain sparse. A key challenge is that such models struggle with hierarchical processing and deep structured reasoning, especially over long text.
  This research addresses these gaps through experiments using GPT-4o, GPT-5, and Prolog. GPT-4o was first used to translate Section 121 into Prolog rules and refine them in SWISH. These rules were then incorporated into prompts to test whether Prolog-augmented prompting improved GPT-4o's inconsistency detection. GPT-4o, whether prompted with natural language alone or with Prolog augmentation, detected the inconsistency in only one of three strategies (33 percent accuracy), but its reasoning quality differed: natural-language prompting achieved 100 percent rule coverage, while Prolog-augmented prompting achieved 66 percent, indicating more incomplete statutory analysis.
  In contrast to probabilistic prompting, the hybrid Prolog model produced deterministic and reproducible results. Guided by GPT-5 for refinement, the model formalized the IRC section's competing interpretations and successfully detected an inconsistency zone. Validation tests confirm that the Prolog implementation is accurate, internally consistent, deterministic, and capable of autonomously identifying inconsistencies. These findings show that LLM-assisted formalization, anchored in symbolic logic, enables transparent and reliable statutory inconsistency detection.

</details>


### [403] [Multi-agent Self-triage System with Medical Flowcharts](https://arxiv.org/abs/2511.12439)
*Yujia Liu,Sophia Yu,Hongyue Jin,Jessica Wen,Alexander Qian,Terrence Lee,Mattheus Ramsis,Gi Won Choi,Lianhui Qin,Xin Liu,Edward J. Wang*

Main category: cs.AI

TL;DR: 提出了一种基于100个临床验证流程图的多代理LLM系统，用于可审计的在线自我分诊，展现出高准确性和透明性。


<details>
  <summary>Details</summary>
Motivation: 现有在线医疗资源和大语言模型在准确性、透明度和信息可靠性方面存在不足，限制了其在医疗决策中的应用。

Method: 构建一个包含检索代理、决策代理和聊天代理的多代理框架，利用美国医学会的100个临床验证流程图指导LLM进行结构化自我分诊。

Result: 在合成数据集上评估显示，系统在流程图检索上的Top-3准确率为95.29%（N=2,000），在流程图导航上的准确率达到99.10%（N=37,200）。

Conclusion: 该方法结合自由文本交互与标准化临床协议，实现了透明、准确且可推广的AI辅助自我分诊，有助于提升患者决策能力和医疗资源利用效率。

Abstract: Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.

</details>


### [404] [Improving Autoformalization Using Direct Dependency Retrieval](https://arxiv.org/abs/2511.11990)
*Shaoqi Wang,Lu Yu,Chunjie Yang*

Main category: cs.AI

TL;DR: 提出一种基于直接依赖检索（DDR）的检索增强框架，用于数学陈述的自动形式化，显著提升了检索精度和召回率，并在单次及多次尝试下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自动形式化方法在上下文感知方面不足，容易产生幻觉，且传统检索增强方法在形式化库依赖检索上精度和召回率低，难以扩展。

Method: 提出DDR框架，直接从自然语言数学描述生成候选库依赖，并通过高效的后缀数组检查验证其在形式化库中的存在；构建了包含50万样本的数据集并微调高精度DDR模型。

Result: DDR模型在检索精度和召回率上显著优于现有最先进方法；结合DDR的自动形式化器在单次准确率和多次尝试稳定性上表现更优。

Conclusion: DDR有效解决了形式化依赖检索中的关键挑战，为大规模自动形式化提供了可扩展且高效的技术路径。

Abstract: The convergence of deep learning and formal mathematics has spurred research in formal verification. Statement autoformalization, a crucial first step in this process, aims to translate informal descriptions into machine-verifiable representations but remains a significant challenge. The core difficulty lies in the fact that existing methods often suffer from a lack of contextual awareness, leading to hallucination of formal definitions and theorems. Furthermore, current retrieval-augmented approaches exhibit poor precision and recall for formal library dependency retrieval, and lack the scalability to effectively leverage ever-growing public datasets. To bridge this gap, we propose a novel retrieval-augmented framework based on DDR (\textit{Direct Dependency Retrieval}) for statement autoformalization. Our DDR method directly generates candidate library dependencies from natural language mathematical descriptions and subsequently verifies their existence within the formal library via an efficient suffix array check. Leveraging this efficient search mechanism, we constructed a dependency retrieval dataset of over 500,000 samples and fine-tuned a high-precision DDR model. Experimental results demonstrate that our DDR model significantly outperforms SOTA methods in both retrieval precision and recall. Consequently, an autoformalizer equipped with DDR shows consistent performance advantages in both single-attempt accuracy and multi-attempt stability compared to models using traditional selection-based RAG methods.

</details>


### [405] [Adaptively Coordinating with Novel Partners via Learned Latent Strategies](https://arxiv.org/abs/2511.12754)
*Benjamin Li,Shuyang Shi,Lucia Romero,Huao Li,Yaqi Xie,Woojun Kim,Stefanos Nikolaidis,Michael Lewis,Katia Sycara,Simon Stepputtis*

Main category: cs.AI

TL;DR: 提出一种策略条件化合作者框架，通过变分自编码器和聚类实时学习并适应多样化合作伙伴策略，在改进的Overcooked环境中实现优于现有基线的协作性能。


<details>
  <summary>Details</summary>
Motivation: 在具有时间压力和复杂策略空间的任务中，人工代理需要实时适应人类伙伴的独特且动态变化的偏好与策略，以实现高效协作。

Method: 使用变分自编码器对策略进行编码以构建潜在策略空间，通过聚类识别不同策略类型，并基于这些簇训练条件化合作代理；在线适应时采用固定份额后悔最小化算法动态推断和调整对伙伴策略的估计。

Result: 在改进的Overcooked环境中的实验和在线用户研究显示，该方法在与新的人类及代理队友配对时，性能优于现有基线方法。

Conclusion: 所提出的策略条件化合作框架能有效实现对多样化、动态变化的合作伙伴策略的实时适应，显著提升人机团队在复杂协作任务中的表现。

Abstract: Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.

</details>


### [406] [Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning](https://arxiv.org/abs/2511.12003)
*Shuochen Liu,Pengfei Luo,Chao Zhang,Yuhao Chen,Haotian Zhang,Qi Liu,Xin Kou,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出了Chain-of-Evidence (CoE)范式和Look As You Think (LAT)框架，用于视觉文档检索增强生成中的证据归因，通过强化学习实现可验证的推理路径生成，在多个基准上显著提升了性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏细粒度监督和推理过程中的逐步可追溯性，难以确保视觉语言模型在多模态问答中输出可靠且可验证的结果。

Method: 提出CoE范式，将思维链推理与基于边界框和页码的视觉证据归因相结合；设计LAT强化学习框架，通过评估归因一致性并在推理路径正确时给予奖励，训练模型生成具有过程自验证能力的可验证推理路径。

Result: 在Paper-和Wiki-VISA基准上，基于Qwen2.5-VL-7B-Instruct的实验显示，LAT在单图和多图设置下均优于基线模型，软精确匹配（EM）平均提升8.23%，IoU@0.5提升47.0%，且具有更强的跨域泛化能力。

Conclusion: CoE与LAT框架有效实现了细粒度、可追溯的视觉证据归因，提升了VD-RAG系统中推理过程的可靠性与可解释性，为多模态问答提供了新的训练范式。

Abstract: Aiming to identify precise evidence sources from visual documents, visual evidence attribution for visual document retrieval-augmented generation (VD-RAG) ensures reliable and verifiable predictions from vision-language models (VLMs) in multimodal question answering. Most existing methods adopt end-to-end training to facilitate intuitive answer verification. However, they lack fine-grained supervision and progressive traceability throughout the reasoning process. In this paper, we introduce the Chain-of-Evidence (CoE) paradigm for VD-RAG. CoE unifies Chain-of-Thought (CoT) reasoning and visual evidence attribution by grounding reference elements in reasoning steps to specific regions with bounding boxes and page indexes. To enable VLMs to generate such evidence-grounded reasoning, we propose Look As You Think (LAT), a reinforcement learning framework that trains models to produce verifiable reasoning paths with consistent attribution. During training, LAT evaluates the attribution consistency of each evidence region and provides rewards only when the CoE trajectory yields correct answers, encouraging process-level self-verification. Experiments on vanilla Qwen2.5-VL-7B-Instruct with Paper- and Wiki-VISA benchmarks show that LAT consistently improves the vanilla model in both single- and multi-image settings, yielding average gains of 8.23% in soft exact match (EM) and 47.0% in IoU@0.5. Meanwhile, LAT not only outperforms the supervised fine-tuning baseline, which is trained to directly produce answers with attribution, but also exhibits stronger generalization across domains.

</details>


### [407] [Adaptive Diagnostic Reasoning Framework for Pathology with Multimodal Large Language Models](https://arxiv.org/abs/2511.12008)
*Yunqi Hong,Johnson Kao,Liam Edwards,Nein-Tzu Liu,Chung-Yen Huang,Alex Oliveira-Kowaleski,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.AI

TL;DR: RECAP-PATH 是一种可解释的AI框架，通过自学习机制将多模态大模型从模式识别转变为基于证据的诊断推理，仅需少量标注数据即可在乳腺癌和前列腺癌数据集上实现高准确率并生成与专家评估一致的诊断依据。


<details>
  <summary>Details</summary>
Motivation: 现有病理AI工具缺乏人类可读的推理过程，限制了其临床采纳；需要能够提供可审计决策依据的可信AI系统。

Method: 提出RECAP-PATH框架，采用两阶段自学习过程：多样化扩展病理风格解释，优化阶段提升准确性；无需模型权重更新或白盒访问，结合视觉理解与语言推理生成诊断。

Result: 在乳腺癌和前列腺癌数据集上，RECAP-PATH显著优于基线方法，生成的诊断理由与专家判断一致，并大幅提升诊断准确率。

Conclusion: RECAP-PATH通过结合视觉与推理实现了可信赖的临床AI，为可解释性医学AI提供了可推广的技术路径。

Abstract: AI tools in pathology have improved screening throughput, standardized quantification, and revealed prognostic patterns that inform treatment. However, adoption remains limited because most systems still lack the human-readable reasoning needed to audit decisions and prevent errors. We present RECAP-PATH, an interpretable framework that establishes a self-learning paradigm, shifting off-the-shelf multimodal large language models from passive pattern recognition to evidence-linked diagnostic reasoning. At its core is a two-phase learning process that autonomously derives diagnostic criteria: diversification expands pathology-style explanations, while optimization refines them for accuracy. This self-learning approach requires only small labeled sets and no white-box access or weight updates to generate cancer diagnoses. Evaluated on breast and prostate datasets, RECAP-PATH produced rationales aligned with expert assessment and delivered substantial gains in diagnostic accuracy over baselines. By uniting visual understanding with reasoning, RECAP-PATH provides clinically trustworthy AI and demonstrates a generalizable path toward evidence-linked interpretation.

</details>


### [408] [Intelligent Collaborative Optimization for Rubber Tyre Film Production Based on Multi-path Differentiated Clipping Proximal Policy Optimization](https://arxiv.org/abs/2511.12060)
*Yinghao Ruan,Wei Pang,Shuaihao Liu,Huili Yang,Leyi Han,Xinghui Dong*

Main category: cs.AI

TL;DR: 提出一种基于深度强化学习的多路径差异化裁剪近端策略优化算法（MPD-PPO），用于解决轮胎制造中高维、多目标的实时调度难题，显著提升了控制精度与生产效率。


<details>
  <summary>Details</summary>
Motivation: 传统集中式调度和固定产线配置难以应对轮胎制造中动态多变的生产需求，且系统复杂、子系统耦合性强，协调困难。

Method: 提出MPD-PPO算法，采用多分支策略架构和差异化梯度裁剪机制，以实现高维策略的稳定高效更新，并应用于轮胎胶片厚度与宽度控制。

Result: 实验验证表明，MPD-PPO在调控精度和运行效率方面均有显著提升，能够有效处理高维性、多目标权衡和动态适应等挑战。

Conclusion: 该框架为轮胎智能制造提供了有效的解决方案，具备良好的实时工业部署能力，提升了生产稳定性与整体性能。

Abstract: The advent of smart manufacturing is addressing the limitations of traditional centralized scheduling and inflexible production line configurations in the rubber tyre industry, especially in terms of coping with dynamic production demands. Contemporary tyre manufacturing systems form complex networks of tightly coupled subsystems pronounced nonlinear interactions and emergent dynamics. This complexity renders the effective coordination of multiple subsystems, posing an essential yet formidable task. For high-dimensional, multi-objective optimization problems in this domain, we introduce a deep reinforcement learning algorithm: Multi-path Differentiated Clipping Proximal Policy Optimization (MPD-PPO). This algorithm employs a multi-branch policy architecture with differentiated gradient clipping constraints to ensure stable and efficient high-dimensional policy updates. Validated through experiments on width and thickness control in rubber tyre film production, MPD-PPO demonstrates substantial improvements in both tuning accuracy and operational efficiency. The framework successfully tackles key challenges, including high dimensionality, multi-objective trade-offs, and dynamic adaptation, thus delivering enhanced performance and production stability for real-time industrial deployment in tyre manufacturing.

</details>


### [409] [Bayesian Optimization in Language Space: An Eval-Efficient AI Self-Improvement Framework](https://arxiv.org/abs/2511.12063)
*Enoch Hyunwook Kang,Hema Yoganarasimhan*

Main category: cs.AI

TL;DR: 本文提出了一种新的语言空间贝叶斯优化框架T-BoN BO，通过结合Best-of-N策略和文本梯度来模拟UCB获取函数的梯度行为，从而在评估效率方面实现AI自我改进。


<details>
  <summary>Details</summary>
Motivation: 在许多社会应用中，评估生成结果的成本远高于生成本身，因此需要优化评估效率而非查询效率。现有基于强化学习的方法不适用于高成本评估场景，亟需一种更高效的语言领域优化方法。

Method: 证明了Best-of-N选择策略与文本梯度的结合能统计上模拟经典UCB获取函数的梯度行为，并据此提出T-BoN BO框架，利用简单文本编辑和选择机制实现高效贝叶斯优化。

Result: 在广告对齐任务中验证了T-BoN BO的有效性，其表现优于当前主流的先进基线方法，显著提升了评估效率。

Conclusion: T-BoN BO为语言模型中的自我改进提供了一个简单且评估高效的新范式，特别适用于人类反馈成本高的实际应用场景。

Abstract: Large Language Models (LLMs) have recently enabled self-improving AI, i.e., AI that iteratively generates, evaluates, and refines its own outcomes. Recent studies have shown that self-improving AI focusing on prompt optimization can outperform state-of-the-art reinforcement-learning fine-tuned LLMs. Here, their `performance' is typically measured by query efficiency - the number of LLM-generated solution samples required to meet a certain performance threshold. However, in many societal applications, the primary limitation is not generating new solutions but evaluating them. For instance, evaluating an ad's effectiveness requires significant human feedback, which is far more costly and time-consuming than generating a candidate ad. To optimize for the evaluation efficiency objective, a natural approach is to extend Bayesian Optimization (BO), a framework proven optimal for evaluation efficiency, to the language domain. However, the difficulty of directly estimating suitable acquisition functions in LLMs' minds makes this extension challenging. This paper overcomes this challenge by proving that the combination of the simple and widely used Best-of-N selection strategy and simple textual gradients (i.e., textual edits from a critic model) statistically emulates the behavior of the gradients on the canonical UCB acquisition function, which induces optimal exploration in terms of evaluation efficiency. Based on this result, we propose TextGrad-Best-of-N Bayesian Optimization (T-BoN BO), a simple and eval-efficient language-space Bayesian optimization framework for AI self-improvement. We also empirically validate T-BoN BO by applying it to automated ad alignment tasks for persona distribution, demonstrating its superior performance compared to popular state-of-the-art baselines.

</details>


### [410] [MedDCR: Learning to Design Agentic Workflows for Medical Coding](https://arxiv.org/abs/2511.13361)
*Jiyang Zheng,Islam Nassar,Thanh Vu,Xu Zhong,Yang Lin,Tongliang Liu,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: MedDCR是一个闭环框架，将医疗编码工作流设计视为学习问题，通过设计师、编码器和反思器的协作，自动生成可解释且适应性强的工作流，在基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的医疗编码方法依赖于刚性、手工设计的工作流，难以捕捉真实世界文档的细微差异和多样性，缺乏系统化学习有效工作流的能力。

Method: 提出MedDCR框架，包含三个核心组件：Designer用于生成工作流，Coder执行编码任务，Reflector提供反馈进行优化，并通过记忆库保存和迭代改进历史工作流，形成闭环学习系统。

Result: 在多个基准数据集上，MedDCR优于当前最先进的基线方法，生成的工作流更具可解释性和适应性，更贴近实际编码实践。

Conclusion: MedDCR通过将工作流设计纳入学习过程，提升了自动化医疗编码系统的可靠性与可信度，为复杂文本分类任务中的工作流自动化提供了新范式。

Abstract: Medical coding converts free-text clinical notes into standardized diagnostic and procedural codes, which are essential for billing, hospital operations, and medical research. Unlike ordinary text classification, it requires multi-step reasoning: extracting diagnostic concepts, applying guideline constraints, mapping to hierarchical codebooks, and ensuring cross-document consistency. Recent advances leverage agentic LLMs, but most rely on rigid, manually crafted workflows that fail to capture the nuance and variability of real-world documentation, leaving open the question of how to systematically learn effective workflows. We present MedDCR, a closed-loop framework that treats workflow design as a learning problem. A Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions and provides constructive feedback, while a memory archive preserves prior designs for reuse and iterative refinement. On benchmark datasets, MedDCR outperforms state-of-the-art baselines and produces interpretable, adaptable workflows that better reflect real coding practice, improving both the reliability and trustworthiness of automated systems.

</details>


### [411] [No-Regret Strategy Solving in Imperfect-Information Games via Pre-Trained Embedding](https://arxiv.org/abs/2511.12083)
*Yanchang Fu,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: 本文提出了一种基于嵌入空间的新型算法Embedding CFR，用于求解不完美信息扩展式博弈（IIEFGs），通过低维连续嵌入空间保留信息集间的细微差异，显著提升了策略求解效率与质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散聚类的抽象方法在信息集表示中因硬分类而丢失关键细微差异，影响策略求解质量，亟需一种能保留信息集间连续关系的高质量抽象方法。

Method: 受自然语言处理中词嵌入启发，将信息集特征预训练并映射到低维连续嵌入空间，在该空间内进行基于遗憾累积和策略更新的求解过程，并提供理论分析证明其可降低累积遗憾。

Result: 实验表明，在相同空间开销下，Embedding CFR相较于基于聚类的抽象算法显著加快了可利用性收敛速度，验证了其有效性。

Conclusion: Embedding CFR首次将低维嵌入用于扑克AI中的信息集抽象，为大规模不完美信息博弈的高效求解提供了新范式。

Abstract: High-quality information set abstraction remains a core challenge in solving large-scale imperfect-information extensive-form games (IIEFGs)-such as no-limit Texas Hold'em-where the finite nature of spatial resources hinders strategy solving over the full game. State-of-the-art AI methods rely on pre-trained discrete clustering for abstraction, yet their hard classification irreversibly loses critical information: specifically, the quantifiable subtle differences between information sets-vital for strategy solving-thereby compromising the quality of such solving. Inspired by the word embedding paradigm in natural language processing, this paper proposes the Embedding CFR algorithm, a novel approach for solving strategies in IIEFGs within an embedding space. The algorithm pre-trains and embeds features of isolated information sets into an interconnected low-dimensional continuous space, where the resulting vectors more precisely capture both the distinctions and connections between information sets. Embedding CFR presents a strategy-solving process driven by regret accumulation and strategy updates within this embedding space, with accompanying theoretical analysis verifying its capacity to reduce cumulative regret. Experiments on poker show that with the same spatial overhead, Embedding CFR achieves significantly faster exploitability convergence compared to cluster-based abstraction algorithms, confirming its effectiveness. Furthermore, to our knowledge, it is the first algorithm in poker AI that pre-trains information set abstractions through low-dimensional embedding for strategy solving.

</details>


### [412] [Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation](https://arxiv.org/abs/2511.12254)
*Yuxiang Zhou,Jichang Li,Yanhao Zhang,Haonan Lu,Guanbin Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为Mobile-Agent-RAG的分层多智能体框架，通过双层检索增强机制解决当前移动智能体在长周期、跨应用任务中成功率低的问题，显著提升了任务完成率和执行效率。


<details>
  <summary>Details</summary>
Motivation: 现有最先进移动智能体过度依赖MLLM中的静态内部知识，导致高层规划出现策略性幻觉和底层UI操作出错，难以应对真实世界复杂任务。

Method: 提出Mobile-Agent-RAG框架，包含Manager-RAG（用于高层规划，检索人类验证的任务计划）和Operator-RAG（用于底层执行，检索与当前应用和子任务匹配的精确操作指令），并构建两个专用检索知识库。同时设计了Mobile-Eval-RAG评测基准。

Result: 实验表明，该方法相比现有最优基线提升了11.0%的任务完成率和10.2%的步骤效率。

Conclusion: Mobile-Agent-RAG通过分离高层策略与底层操作的知识需求，实现了更可靠、上下文感知的多智能体移动自动化新范式。

Abstract: Mobile agents show immense potential, yet current state-of-the-art (SoTA) agents exhibit inadequate success rates on real-world, long-horizon, cross-application tasks. We attribute this bottleneck to the agents' excessive reliance on static, internal knowledge within MLLMs, which leads to two critical failure points: 1) strategic hallucinations in high-level planning and 2) operational errors during low-level execution on user interfaces (UI). The core insight of this paper is that high-level planning and low-level UI operations require fundamentally distinct types of knowledge. Planning demands high-level, strategy-oriented experiences, whereas operations necessitate low-level, precise instructions closely tied to specific app UIs. Motivated by these insights, we propose Mobile-Agent-RAG, a novel hierarchical multi-agent framework that innovatively integrates dual-level retrieval augmentation. At the planning stage, we introduce Manager-RAG to reduce strategic hallucinations by retrieving human-validated comprehensive task plans that provide high-level guidance. At the execution stage, we develop Operator-RAG to improve execution accuracy by retrieving the most precise low-level guidance for accurate atomic actions, aligned with the current app and subtask. To accurately deliver these knowledge types, we construct two specialized retrieval-oriented knowledge bases. Furthermore, we introduce Mobile-Eval-RAG, a challenging benchmark for evaluating such agents on realistic multi-app, long-horizon tasks. Extensive experiments demonstrate that Mobile-Agent-RAG significantly outperforms SoTA baselines, improving task completion rate by 11.0% and step efficiency by 10.2%, establishing a robust paradigm for context-aware, reliable multi-agent mobile automation.

</details>


### [413] [KrwEmd: Revising the Imperfect-Recall Abstraction from Forgetting Everything](https://arxiv.org/abs/2511.12089)
*Yanchang Fu,Qiyue Yin,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: 本文提出了KrwEmd算法，通过引入k-回忆胜率特征和地球移动距离聚类信号观测信息集，有效解决了德州扑克等不完美信息游戏中因过度抽象导致的AI性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 在大规模不完美信息博弈中，过度抽象尤其是极端的不完美回忆抽象会丢弃历史信息，严重影响AI性能，亟需一种能保留关键历史信息的抽象方法。

Method: 提出k-回忆胜率（k-recall winrate）特征，结合未来和历史游戏信息区分并量化信号观测信息集的相似性；基于该特征，使用地球移动距离（Earth Mover's Distance）对信息集进行聚类，形成KrwEmd算法。

Result: 实验结果表明，与现有算法相比，KrwEmd显著提升了AI的游戏性能。

Conclusion: KrwEmd是首个有效应对过度抽象问题的实用算法，通过融合历史与未来信息，在保持抽象效率的同时提升了决策质量，为不完美信息博弈的求解提供了新思路。

Abstract: Excessive abstraction is a critical challenge in hand abstraction-a task specific to games like Texas hold'em-when solving large-scale imperfect-information games, as it impairs AI performance. This issue arises from extreme implementations of imperfect-recall abstraction, which entirely discard historical information. This paper presents KrwEmd, the first practical algorithm designed to address this problem. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal observation infosets by leveraging both future and, crucially, historical game information, but also quantitatively captures their similarity. We then develop the KrwEmd algorithm, which clusters signal observation infosets using earth mover's distance to measure discrepancies between their features. Experimental results demonstrate that KrwEmd significantly improves AI gameplay performance compared to existing algorithms.

</details>


### [414] [MetaGDPO: Alleviating Catastrophic Forgetting with Metacognitive Knowledge through Group Direct Preference Optimization](https://arxiv.org/abs/2511.12113)
*Lanxue Zhang,Yuqiang Xie,Fang Fang,Fanglong Dong,Rui Liu,Yanan Cao*

Main category: cs.AI

TL;DR: 提出了一种从数据和微调方法两方面缓解小模型在知识蒸馏过程中灾难性遗忘的综合方案，构建了包含元认知知识的5K数据集，并提出了适用于资源受限场景的GDPO优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据集和微调方法在处理小于8B的小模型时容易导致灾难性遗忘，且忽视训练数据与模型固有能力之间的关系，缺乏对固有知识保留的有效约束。

Method: 构建了一个包含5000个样本、覆盖多种推理任务并融入元认知知识的数据集，基于任务知识和模型固有能力进行数据筛选；提出GDPO（Group Direction Preference Optimization）方法，通过参考模型隐式约束优化路径，在资源有限的情况下有效逼近GRPO性能，实现更高效的知识迁移。

Result: 实验表明，该方法显著缓解了灾难性遗忘问题，并提升了小模型在推理任务上的表现。

Conclusion: 结合元认知感知数据构建与GDPO微调策略，能有效提升小模型在知识蒸馏过程中的推理能力并抑制灾难性遗忘，尤其适用于资源受限场景。

Abstract: Large Language Models demonstrate strong reasoning capabilities, which can be effectively compressed into smaller models. However, existing datasets and fine-tuning approaches still face challenges that lead to catastrophic forgetting, particularly for models smaller than 8B. First, most datasets typically ignore the relationship between training data knowledge and the model's inherent abilities, making it difficult to preserve prior knowledge. Second, conventional training objectives often fail to constrain inherent knowledge preservation, which can result in forgetting of previously learned skills. To address these issues, we propose a comprehensive solution that alleviates catastrophic forgetting from both the data and fine-tuning approach perspectives. On the data side, we construct a dataset of 5K instances that covers multiple reasoning tasks and incorporates metacognitive knowledge, making it more tolerant and effective for distillation into smaller models. We annotate the metacognitive knowledge required to solve each question and filter the data based on task knowledge and the model's inherent skills. On the training side, we introduce GDPO (Group Direction Preference Optimization), which is better suited for resource-limited scenarios and can efficiently approximate the performance of GRPO. Guided by the large model and by implicitly constraining the optimization path through a reference model, GDPO enables more effective knowledge transfer from the large model and constrains excessive parameter drift. Extensive experiments demonstrate that our approach significantly alleviates catastrophic forgetting and improves reasoning performance on smaller models.

</details>


### [415] [RTMol: Rethinking Molecule-text Alignment in a Round-trip View](https://arxiv.org/abs/2511.12135)
*Letian Chen,Runhan Shi,Gufeng Yu,Yang Yang*

Main category: cs.AI

TL;DR: 提出RTMol框架，通过自监督的往返学习实现分子序列与文本描述的双向对齐，无需配对数据即可提升分子图文生成的一致性与化学准确性。


<details>
  <summary>Details</summary>
Motivation: 现有分子-文本对齐方法存在指标重语言流畅性轻化学准确性、数据模糊以及双向生成不一致等问题，需统一框架解决。

Method: 设计RTMol框架，采用自监督的往返学习机制，引入往返评估指标，支持无监督训练，统一分子到文本和文本到分子的生成任务。

Result: 在多个大语言模型上实验表明，RTMol使双向对齐性能最高提升47%，且无需依赖配对分子-文本语料库。

Conclusion: RTMol为分子与文本的联合理解与生成提供了高效、一致的新范式，适用于药物发现和材料设计等领域。

Abstract: Aligning molecular sequence representations (e.g., SMILES notations) with textual descriptions is critical for applications spanning drug discovery, materials design, and automated chemical literature analysis. Existing methodologies typically treat molecular captioning (molecule-to-text) and text-based molecular design (text-to-molecule) as separate tasks, relying on supervised fine-tuning or contrastive learning pipelines. These approaches face three key limitations: (i) conventional metrics like BLEU prioritize linguistic fluency over chemical accuracy, (ii) training datasets frequently contain chemically ambiguous narratives with incomplete specifications, and (iii) independent optimization of generation directions leads to bidirectional inconsistency. To address these issues, we propose RTMol, a bidirectional alignment framework that unifies molecular captioning and text-to-SMILES generation through self-supervised round-trip learning. The framework introduces novel round-trip evaluation metrics and enables unsupervised training for molecular captioning without requiring paired molecule-text corpora. Experiments demonstrate that RTMol enhances bidirectional alignment performance by up to 47% across various LLMs, establishing an effective paradigm for joint molecule-text understanding and generation.

</details>


### [416] [Incremental Maintenance of DatalogMTL Materialisations](https://arxiv.org/abs/2511.12169)
*Kaiyue Zhao,Dingqi Chen,Shaoyu Wang,Pan Hu*

Main category: cs.AI

TL;DR: 提出DRedMTL，一种用于支持带有时态逻辑的DatalogMTL的增量推理算法，能够高效处理动态数据更新，实验表明其性能显著优于重新物化方法。


<details>
  <summary>Details</summary>
Motivation: 现有DatalogMTL推理方法缺乏对频繁数据更新场景下高效动态维护的支持，限制了其在现实应用中的实用性。

Method: 基于经典DRed算法，设计针对DatalogMTL物化结果中事实集与周期性时间区间表示的专用操作符，实现增量式推理。

Result: 实现了DRedMTL算法，并在多个公开数据集上验证了其性能，结果表明其在多数情况下显著优于重新物化方法，性能提升可达数量级。

Conclusion: DRedMTL为DatalogMTL提供了高效的增量推理能力，有效支持动态环境下的时态数据推理，具备实际应用价值。

Abstract: DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling efficient dynamic updates, a crucial requirement for real-world applications that involve frequent data updates. In this work, we propose DRedMTL, an incremental reasoning algorithm for DatalogMTL with bounded intervals. Our algorithm builds upon the classical DRed algorithm, which incrementally updates the materialisation of a Datalog program. Unlike a Datalog materialisation which is in essence a finite set of facts, a DatalogMTL materialisation has to be represented as a finite set of facts plus periodic intervals indicating how the full materialisation can be constructed through unfolding. To cope with this, our algorithm is equipped with specifically designed operators to efficiently handle such periodic representations of DatalogMTL materialisations. We have implemented this approach and tested it on several publicly available datasets. Experimental results show that DRedMTL often significantly outperforms rematerialisation, sometimes by orders of magnitude.

</details>


### [417] [Debate over Mixed-knowledge: A Robust Multi-Agent Framework for Incomplete Knowledge Graph Question Answering](https://arxiv.org/abs/2511.12208)
*Jilong Liu,Pengyang Shao,Wei Qin,Fei Liu,Yonghui Yang,Richang Hong*

Main category: cs.AI

TL;DR: 提出了一种名为Debate over Mixed-knowledge (DoM)的新框架，通过多智能体辩论范式动态融合结构化与非结构化知识，以解决不完整知识图谱问答（IKGQA）问题，并构建了更贴近真实场景的新型数据集Incomplete Knowledge Graph WebQuestions。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理不完整知识图谱问答时难以自适应地融合多种知识源，且常用的数据集通过随机删除三元组模拟不完整性，无法反映真实世界中知识缺失的复杂性。

Method: 基于多智能体辩论框架，将问题分解为子问题，分别由知识图谱和检索增强生成（RAG）代理获取证据，并通过裁判代理迭代交互评估与聚合答案，实现结构化与非结构化知识的动态融合。

Result: 实验表明，DoM在多个指标上持续优于当前最先进的基线方法，新构建的数据集也更具现实性和挑战性。

Conclusion: DoM能有效利用多源知识的互补性，提升对知识图谱不完整性的鲁棒性，为IKGQA提供了更优的解决方案。

Abstract: Knowledge Graph Question Answering (KGQA) aims to improve factual accuracy by leveraging structured knowledge. However, real-world Knowledge Graphs (KGs) are often incomplete, leading to the problem of Incomplete KGQA (IKGQA). A common solution is to incorporate external data to fill knowledge gaps, but existing methods lack the capacity to adaptively and contextually fuse multiple sources, failing to fully exploit their complementary strengths. To this end, we propose Debate over Mixed-knowledge (DoM), a novel framework that enables dynamic integration of structured and unstructured knowledge for IKGQA. Built upon the Multi-Agent Debate paradigm, DoM assigns specialized agents to perform inference over knowledge graphs and external texts separately, and coordinates their outputs through iterative interaction. It decomposes the input question into sub-questions, retrieves evidence via dual agents (KG and Retrieval-Augmented Generation, RAG), and employs a judge agent to evaluate and aggregate intermediate answers. This collaboration exploits knowledge complementarity and enhances robustness to KG incompleteness. In addition, existing IKGQA datasets simulate incompleteness by randomly removing triples, failing to capture the irregular and unpredictable nature of real-world knowledge incompleteness. To address this, we introduce a new dataset, Incomplete Knowledge Graph WebQuestions, constructed by leveraging real-world knowledge updates. These updates reflect knowledge beyond the static scope of KGs, yielding a more realistic and challenging benchmark. Through extensive experiments, we show that DoM consistently outperforms state-of-the-art baselines.

</details>


### [418] [ViTE: Virtual Graph Trajectory Expert Router for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2511.12214)
*Ruochen Li,Zhanxing Zhu,Tanqiu Qiao,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: 提出ViTE框架，通过虚拟图和专家路由器模块自适应建模行人轨迹预测中的显式一阶交互与隐式高阶依赖，在多个基准上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在建模高阶交互时面临层数不足导致感受野受限或层数过深带来计算成本过高的权衡问题，需更灵活高效地捕捉复杂社会交互。

Method: 设计ViTE框架，包含两个模块：虚拟图引入动态虚拟节点以显式建模长程和高阶交互，避免深层GNN堆叠；专家路由器基于Mixture-of-Experts机制，根据社交上下文自适应选择交互专家。

Result: 在ETH/UCY、NBA和SDD三个基准上的实验表明，该方法在预测精度和计算效率方面均优于现有方法，取得最先进性能。

Conclusion: ViTE通过虚拟节点和自适应专家路由机制，有效平衡了模型表达能力与计算开销，为行人轨迹预测提供了一种可扩展且高效的解决方案。

Abstract: Pedestrian trajectory prediction is critical for ensuring safety in autonomous driving, surveillance systems, and urban planning applications. While early approaches primarily focus on one-hop pairwise relationships, recent studies attempt to capture high-order interactions by stacking multiple Graph Neural Network (GNN) layers. However, these approaches face a fundamental trade-off: insufficient layers may lead to under-reaching problems that limit the model's receptive field, while excessive depth can result in prohibitive computational costs. We argue that an effective model should be capable of adaptively modeling both explicit one-hop interactions and implicit high-order dependencies, rather than relying solely on architectural depth. To this end, we propose ViTE (Virtual graph Trajectory Expert router), a novel framework for pedestrian trajectory prediction. ViTE consists of two key modules: a Virtual Graph that introduces dynamic virtual nodes to model long-range and high-order interactions without deep GNN stacks, and an Expert Router that adaptively selects interaction experts based on social context using a Mixture-of-Experts design. This combination enables flexible and scalable reasoning across varying interaction patterns. Experiments on three benchmarks (ETH/UCY, NBA, and SDD) demonstrate that our method consistently achieves state-of-the-art performance, validating both its effectiveness and practical efficiency.

</details>


### [419] [Beyond World Models: Rethinking Understanding in AI Models](https://arxiv.org/abs/2511.12239)
*Tarun Gupta,Danish Pruthi*

Main category: cs.AI

TL;DR: 本文通过科学哲学文献中的案例研究，批判性地探讨了世界模型框架是否能够充分表征人类水平的理解，指出当前AI世界模型与人类理解之间存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探讨AI中的世界模型是否真正具备类似人类的理解能力，检验其在模拟人类认知方面的潜力与局限。

Method: 借鉴科学哲学中的具体案例分析，重点考察世界模型的能力（如预测、因果推理）与人类理解之间的本质区别。

Result: 发现现有的世界模型虽然具备一定的模拟能力，但与人类深层次的理解仍有差距，特别是在解释性和认知意图方面。

Conclusion: 世界模型尚不足以完全刻画人类水平的理解，需进一步结合哲学视角来反思和扩展AI理解的定义。

Abstract: World models have garnered substantial interest in the AI community. These are internal representations that simulate aspects of the external world, track entities and states, capture causal relationships, and enable prediction of consequences. This contrasts with representations based solely on statistical correlations. A key motivation behind this research direction is that humans possess such mental world models, and finding evidence of similar representations in AI models might indicate that these models "understand" the world in a human-like way. In this paper, we use case studies from the philosophy of science literature to critically examine whether the world model framework adequately characterizes human-level understanding. We focus on specific philosophical analyses where the distinction between world model capabilities and human understanding is most pronounced. While these represent particular views of understanding rather than universal definitions, they help us explore the limits of world models.

</details>


### [420] [AURA: Development and Validation of an Augmented Unplanned Removal Alert System using Synthetic ICU Videos](https://arxiv.org/abs/2511.12241)
*Junhyuk Seo,Hyeyoon Moon,Kyu-Hwan Jung,Namkee Oh,Taerim Kim*

Main category: cs.AI

TL;DR: 提出了一种基于合成视频数据的视觉风险检测系统AURA，用于实时检测ICU中的非计划性拔管风险，通过文本到视频扩散生成逼真的临床场景，并利用姿态估计识别高风险动作，具有隐私保护和可重复性的优势。


<details>
  <summary>Details</summary>
Motivation: 由于伦理和隐私问题，难以获取标注的ICU视频数据，导致非计划性拔管（UE）的实时检测受限，因此需要一种不依赖真实患者视频的方法来开发有效的监测系统。

Method: 使用文本到视频扩散模型生成完全合成的、临床真实的ICU视频数据集，应用姿态估计技术识别两种高风险行为：接近气道管路的手部‘碰撞’和通过关键点速度衡量的‘躁动’，并在合成数据上训练和验证AURA系统。

Result: 专家评估确认合成数据具有高度真实性；系统在碰撞检测上表现出高准确率，在躁动识别上表现中等。

Conclusion: AURA展示了一条无需真实患者视频数据即可开发隐私保护、可重复的患者安全监测系统的新路径，具有在重症监护环境中部署的潜力。

Abstract: Unplanned extubation (UE) remains a critical patient safety concern in intensive care units (ICUs), often leading to severe complications or death. Real-time UE detection has been limited, largely due to the ethical and privacy challenges of obtaining annotated ICU video data. We propose Augmented Unplanned Removal Alert (AURA), a vision-based risk detection system developed and validated entirely on a fully synthetic video dataset. By leveraging text-to-video diffusion, we generated diverse and clinically realistic ICU scenarios capturing a range of patient behaviors and care contexts. The system applies pose estimation to identify two high-risk movement patterns: collision, defined as hand entry into spatial zones near airway tubes, and agitation, quantified by the velocity of tracked anatomical keypoints. Expert assessments confirmed the realism of the synthetic data, and performance evaluations showed high accuracy for collision detection and moderate performance for agitation recognition. This work demonstrates a novel pathway for developing privacy-preserving, reproducible patient safety monitoring systems with potential for deployment in intensive care settings.

</details>


### [421] [MoralReason: Generalizable Moral Decision Alignment For LLM Agents Using Reasoning-Level Reinforcement Learning](https://arxiv.org/abs/2511.12271)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 本文提出了一种新的方法来引导大语言模型（LLM）在道德决策中的行为，通过构建包含高歧义道德场景和特定伦理框架推理链的数据集Moral-Reason-QA，并采用组相对策略优化与复合奖励机制，使LLM能够在未知情境中泛化并应用功利主义、义务论等道德框架。实验表明该方法显著提升了模型在分布外场景中的道德对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注评估LLM的道德判断，而缺乏对其道德推理进行主动引导的方法；同时，模型在训练分布之外的道德场景中难以保持一致的伦理原则应用，因此需要解决LLM在新情境下的道德对齐问题。

Method: 将道德对齐视为一个分布外对齐问题，提出Moral-Reason-QA数据集，包含680个人工标注的高歧义道德场景及其在功利主义、义务论和美德伦理下的推理路径；采用Group Relative Policy Optimization（GRPO）结合复合奖励函数，联合优化决策对齐和框架特定的推理过程。

Result: 模型在未见的道德场景中展现出良好的泛化能力，在分布外测试集上，softmax归一化的对齐分数相比基线分别提升+0.757（功利主义）和+0.450（义务论）；同时揭示了训练过程中存在的挑战，如不同框架间的冲突与学习稳定性问题。

Conclusion: 研究表明，通过适当的训练框架和数据支持，大语言模型可以被系统性地训练以内在化并应用特定的道德理论于新情境中，为AI安全及LLM在人类决策中的深度集成提供了重要基础。

Abstract: Large language models are increasingly influencing human moral decisions, yet current approaches focus primarily on evaluating rather than actively steering their moral decisions. We formulate this as an out-of-distribution moral alignment problem, where LLM agents must learn to apply consistent moral reasoning frameworks to scenarios beyond their training distribution. We introduce Moral-Reason-QA, a novel dataset extending 680 human-annotated, high-ambiguity moral scenarios with framework-specific reasoning traces across utilitarian, deontological, and virtue ethics, enabling systematic evaluation of moral generalization in realistic decision contexts. Our learning approach employs Group Relative Policy Optimization with composite rewards that simultaneously optimize decision alignment and framework-specific reasoning processes to facilitate learning of the underlying moral frameworks. Experimental results demonstrate successful generalization to unseen moral scenarios, with softmax-normalized alignment scores improving by +0.757 for utilitarian and +0.450 for deontological frameworks when tested on out-of-distribution evaluation sets. The experiments also reveal training challenges and promising directions that inform future research. These findings establish that LLM agents can be systematically trained to internalize and apply specific moral frameworks to novel situations, providing a critical foundation for AI safety as language models become more integrated into human decision-making processes.

</details>


### [422] [UpBench: A Dynamically Evolving Real-World Labor-Market Agentic Benchmark Framework Built for Human-Centric AI](https://arxiv.org/abs/2511.12306)
*Darvin Yi,Teng Liu,Mattie Terzolo,Lance Hasson,Ayan Sinh,Pablo Mendes,Andrew Rabinovich*

Main category: cs.AI

TL;DR: UpBench是一个基于真实Upwork工作任务的动态评估基准，通过专家构建的评分标准对大语言模型代理进行细粒度评估，强调人类与AI协作，推动AI在真实劳动市场中的能力评价。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理评估基准多为静态、合成或领域受限，难以反映其在动态、经济相关环境中的实际表现，缺乏对真实工作场景和人机协作能力的评估。

Method: 构建UpBench基准，任务源自Upwork平台的真实交易；由专家自由职业者制定详细评分标准，并对AI提交结果进行逐项反馈；全流程融入人类专业知识，包括任务筛选、标准制定和评估；任务定期更新以反映在线工作的演变。

Result: UpBench实现了对LLM代理在真实性、专业性和动态性环境下的细粒度评估，支持对模型优势、劣势及指令遵循能力的深入分析，并为人类与AI协作研究提供了高质量数据基础。

Conclusion: UpBench提供了一个可扩展、以人为本的评估框架，能够有效衡量LLM代理在真实劳动力市场情境中的表现，推动AI作为人类能力增强伙伴的发展路径。

Abstract: As large language model (LLM) agents increasingly undertake digital work, reliable frameworks are needed to evaluate their real-world competence, adaptability, and capacity for human collaboration. Existing benchmarks remain largely static, synthetic, or domain-limited, providing limited insight into how agents perform in dynamic, economically meaningful environments. We introduce UpBench, a dynamically evolving benchmark grounded in real jobs drawn from the global Upwork labor marketplace. Each task corresponds to a verified client transaction, anchoring evaluation in genuine work activity and financial outcomes. UpBench employs a rubric-based evaluation framework, in which expert freelancers decompose each job into detailed, verifiable acceptance criteria and assess AI submissions with per-criterion feedback. This structure enables fine-grained analysis of model strengths, weaknesses, and instruction-following fidelity beyond binary pass/fail metrics. Human expertise is integrated throughout the data pipeline (from job curation and rubric construction to evaluation) ensuring fidelity to real professional standards and supporting research on human-AI collaboration. By regularly refreshing tasks to reflect the evolving nature of online work, UpBench provides a scalable, human-centered foundation for evaluating agentic systems in authentic labor-market contexts, offering a path toward a collaborative framework, where AI amplifies human capability through partnership rather than replacement.

</details>


### [423] [Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning](https://arxiv.org/abs/2511.12344)
*Baolong Bi,Shenghua Liu,Yiwei Wang,Siqian Tong,Lingrui Mei,Yuyao Ge,Yilong Xu,Jiafeng Guo,Xueqi Cheng*

Main category: cs.AI

TL;DR: 提出了一种基于评分标准（rubrics）的强化学习框架RGR-GRPO，用于提升大语言模型在多领域推理任务中的表现，相较于传统在线强化学习方法，在数学、物理、化学和通用推理任务上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要局限于单领域和可验证奖励设置，且依赖纯在线训练框架，探索空间受限，推理性能提升遇到瓶颈。

Method: 提出RGR-GRPO框架，利用评分标准提供细粒度奖励信号和离线指导，结合GRPO算法，在多领域推理任务中实现更密集的奖励反馈和更大的解空间探索。

Result: 在14个跨领域基准测试中，RGR-GRPO相比仅依赖其他奖励机制或离线指导的方法表现更优；相较于可验证在线RL基线，数学、物理、化学和通用推理任务上平均提升分别为+7.0%、+5.4%、+8.4%和+6.6%，且训练过程中熵波动稳定，pass@k性能更优。

Conclusion: RGR-GRPO通过引入评分标准实现了更有效的多领域推理能力训练，支持持续探索并突破现有性能瓶颈，为大语言模型的复杂推理提供了新的可行路径。

Abstract: Recent advances in reinforcement learning (RL) have significantly improved the complex reasoning capabilities of large language models (LLMs). Despite these successes, existing methods mainly focus on single-domain RL (e.g., mathematics) with verifiable rewards (RLVR), and their reliance on purely online RL frameworks restricts the exploration space, thereby limiting reasoning performance. In this paper, we address these limitations by leveraging rubrics to provide both fine-grained reward signals and offline guidance. We propose $\textbf{RGR-GRPO}$ (Reward and Guidance through Rubrics), a rubric-driven RL framework for multi-domain reasoning. RGR-GRPO enables LLMs to receive dense and informative rewards while exploring a larger solution space during GRPO training. Extensive experiments across 14 benchmarks spanning multiple domains demonstrate that RGR-GRPO consistently outperforms RL methods that rely solely on alternative reward schemes or offline guidance. Compared with verifiable online RL baseline, RGR-GRPO achieves average improvements of +7.0%, +5.4%, +8.4%, and +6.6% on mathematics, physics, chemistry, and general reasoning tasks, respectively. Notably, RGR-GRPO maintains stable entropy fluctuations during off-policy training and achieves superior pass@k performance, reflecting sustained exploration and effective breakthrough beyond existing performance bottlenecks.

</details>


### [424] [More Than Irrational: Modeling Belief-Biased Agents](https://arxiv.org/abs/2511.12359)
*Yifan Zhu,Sammie Katt,Samuel Kaski*

Main category: cs.AI

TL;DR: 本文提出了一类计算理性（CR）用户模型，用于描述在认知限制和偏差信念下进行次优决策的用户行为，并通过嵌套粒子滤波实现对用户潜在信念状态和认知边界的在线推断，在导航任务中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于人类用户的认知限制和对世界的偏差信念，其行为常表现为次优决策，但这种行为本质上是受限条件下的理性选择；准确建模并推断这类行为对构建适应性AI系统至关重要。

Method: 提出计算理性（CR）用户模型，显式建模有限记忆过程如何导致动态不一致的偏差信念，并设计基于嵌套粒子滤波的在线推理方法，从被动观察中实时估计用户的认知边界与信念状态。

Result: 在模拟导航任务中，CR模型能生成符合不同记忆容量的合理行为，且推理方法可在少量观测（≤100步）下准确恢复真实认知边界。

Conclusion: 该框架为理解认知受限用户的次优决策提供了形式化基础，并支持构建能自适应用户记忆局限的智能辅助系统。

Abstract: Despite the explosive growth of AI and the technologies built upon it, predicting and inferring the sub-optimal behavior of users or human collaborators remains a critical challenge. In many cases, such behaviors are not a result of irrationality, but rather a rational decision made given inherent cognitive bounds and biased beliefs about the world. In this paper, we formally introduce a class of computational-rational (CR) user models for cognitively-bounded agents acting optimally under biased beliefs. The key novelty lies in explicitly modeling how a bounded memory process leads to a dynamically inconsistent and biased belief state and, consequently, sub-optimal sequential decision-making. We address the challenge of identifying the latent user-specific bound and inferring biased belief states from passive observations on the fly. We argue that for our formalized CR model family with an explicit and parameterized cognitive process, this challenge is tractable. To support our claim, we propose an efficient online inference method based on nested particle filtering that simultaneously tracks the user's latent belief state and estimates the unknown cognitive bound from a stream of observed actions. We validate our approach in a representative navigation task using memory decay as an example of a cognitive bound. With simulations, we show that (1) our CR model generates intuitively plausible behaviors corresponding to different levels of memory capacity, and (2) our inference method accurately and efficiently recovers the ground-truth cognitive bounds from limited observations ($\le 100$ steps). We further demonstrate how this approach provides a principled foundation for developing adaptive AI assistants, enabling adaptive assistance that accounts for the user's memory limitations.

</details>


### [425] [Learning to Trust: Bayesian Adaptation to Varying Suggester Reliability in Sequential Decision Making](https://arxiv.org/abs/2511.12378)
*Dylan M. Asmar,Mykel J. Kochenderfer*

Main category: cs.AI

TL;DR: 提出了一种在部分可观测环境中动态学习和适应建议者可靠性的框架，通过贝叶斯推断整合建议质量，并引入主动“询问”动作以策略性获取建议。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设建议者的质量是静态且已知的，难以应对实际中建议可靠性变化的问题，限制了在不确定环境中的应用。

Method: 将建议者质量融入智能体的信念表示中，使用贝叶斯推断来估计建议者类型；引入显式的“ask”动作，使智能体能在关键时机主动请求建议，权衡信息收益与获取成本。

Result: 实验表明该框架能在不同建议者质量下保持鲁棒性能，动态适应可靠性变化，并有效管理建议请求的策略。

Conclusion: 该工作为不确定环境下考虑建议不确定性的自适应人机协作提供了基础。

Abstract: Autonomous agents operating in sequential decision-making tasks under uncertainty can benefit from external action suggestions, which provide valuable guidance but inherently vary in reliability. Existing methods for incorporating such advice typically assume static and known suggester quality parameters, limiting practical deployment. We introduce a framework that dynamically learns and adapts to varying suggester reliability in partially observable environments. First, we integrate suggester quality directly into the agent's belief representation, enabling agents to infer and adjust their reliance on suggestions through Bayesian inference over suggester types. Second, we introduce an explicit ``ask'' action allowing agents to strategically request suggestions at critical moments, balancing informational gains against acquisition costs. Experimental evaluation demonstrates robust performance across varying suggester qualities, adaptation to changing reliability, and strategic management of suggestion requests. This work provides a foundation for adaptive human-agent collaboration by addressing suggestion uncertainty in uncertain environments.

</details>


### [426] [ARCHE: A Novel Task to Evaluate LLMs on Latent Reasoning Chain Extraction](https://arxiv.org/abs/2511.12485)
*Pengze Li,Jiaqi Liu,Junchi Yu,Lihao Liu,Mingyu Ding,Wanli Ouyang,Shixiang Tang,Xi Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为ARCHE的新任务，旨在通过将复杂推理分解为标准推理范式（演绎、归纳、溯因）的逻辑树结构，评估大语言模型在科学推理中的能力，并发布了基于《自然·通讯》论文的基准数据集ARCHE Bench，揭示当前模型在逻辑准确性和内容完整性之间存在权衡，尚无法完整提取规范的科学推理链。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型虽能生成类似推理的内容，但输出缺乏结构和形式化，难以判断其是否真正理解科学推理的基本范式，因此需要一种新方法来系统评估模型的科学推理能力。

Method: 提出了潜推理链提取（ARCHE）任务，要求模型将复杂论证分解为由演绎、归纳和溯因三种基本推理模式构成的推理逻辑树（RLT），并构建了ARCHE Bench基准数据集，包含来自70篇《自然·通讯》文章的数据，同时设计了实体覆盖率（EC）和推理边准确性（REA）两个评估指标。

Result: 在10个主流大语言模型上的实验表明，模型在REA和EC之间存在权衡，目前没有模型能够同时实现完整的推理覆盖和正确的逻辑结构，表现出与科学论证所需严谨性之间的显著差距。

Conclusion: 当前的大语言模型尚未掌握科学推理所需的结构化和规范化逻辑能力，ARCHE任务为未来研究提供了新的评估框架和方向。

Abstract: Large language models (LLMs) are increasingly used in scientific domains. While they can produce reasoning-like content via methods such as chain-of-thought prompting, these outputs are typically unstructured and informal, obscuring whether models truly understand the fundamental reasoning paradigms that underpin scientific inference. To address this, we introduce a novel task named Latent Reasoning Chain Extraction (ARCHE), in which models must decompose complex reasoning arguments into combinations of standard reasoning paradigms in the form of a Reasoning Logic Tree (RLT). In RLT, all reasoning steps are explicitly categorized as one of three variants of Peirce's fundamental inference modes: deduction, induction, or abduction. To facilitate this task, we release ARCHE Bench, a new benchmark derived from 70 Nature Communications articles, including more than 1,900 references and 38,000 viewpoints. We propose two logic-aware evaluation metrics: Entity Coverage (EC) for content completeness and Reasoning Edge Accuracy (REA) for step-by-step logical validity. Evaluations on 10 leading LLMs on ARCHE Bench reveal that models exhibit a trade-off between REA and EC, and none are yet able to extract a complete and standard reasoning chain. These findings highlight a substantial gap between the abilities of current reasoning models and the rigor required for scientific argumentation.

</details>


### [427] [LOBERT: Generative AI Foundation Model for Limit Order Book Messages](https://arxiv.org/abs/2511.12563)
*Eljas Linna,Kestutis Baltakys,Alexandros Iosifidis,Juho Kanniainen*

Main category: cs.AI

TL;DR: 本文提出了LOBERT，一种适用于金融限价订单簿（LOB）数据的通用编码器基础模型，通过新颖的分词方案在消息级别建模LOB动态，显著提升了预测性能并减少了上下文长度需求。


<details>
  <summary>Details</summary>
Motivation: 由于事件时间不规则、市场状态快速变化以及高频交易者对订单流的反应，传统LOB建模方法面临表示复杂和适应性差的问题，因此需要一种更灵活、通用的模型。

Method: 采用改进的BERT架构，将完整的多维消息作为单一token处理，并保留价格、成交量和时间的连续表示，实现对LOB数据的有效编码。

Result: LOBERT在预测中价变动和下一条消息等任务上达到领先性能，同时相比先前方法减少了所需的上下文长度。

Conclusion: LOBERT是一种高效且通用的LOB数据基础模型，具备良好的下游任务微调能力，为高频金融时序建模提供了新范式。

Abstract: Modeling the dynamics of financial Limit Order Books (LOB) at the message level is challenging due to irregular event timing, rapid regime shifts, and the reactions of high-frequency traders to visible order flow. Previous LOB models require cumbersome data representations and lack adaptability outside their original tasks, leading us to introduce LOBERT, a general-purpose encoder-only foundation model for LOB data suitable for downstream fine-tuning. LOBERT adapts the original BERT architecture for LOB data by using a novel tokenization scheme that treats complete multi-dimensional messages as single tokens while retaining continuous representations of price, volume, and time. With these methods, LOBERT achieves leading performance in tasks such as predicting mid-price movements and next messages, while reducing the required context length compared to previous methods.

</details>


### [428] [Enhancing Conversational Recommender Systems with Tree-Structured Knowledge and Pretrained Language Models](https://arxiv.org/abs/2511.12579)
*Yongwen Ren,Chao Wang,Peng Du,Chuan Qin,Dazhong Shen,Hui Xiong*

Main category: cs.AI

TL;DR: 提出PCRS-TKA框架，结合预训练语言模型与知识图谱，通过构建对话特定的知识树和选择性过滤上下文相关知识，提升对话推荐系统的准确性和对话质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在融合预训练语言模型与知识图谱时未能充分挖掘图结构关系、缺乏上下文过滤且忽略多轮对话中的协同偏好。

Method: 提出PCRS-TKA框架，构建对话特定的知识树并序列化为文本，引入选择性知识过滤、协同偏好建模和语义对齐模块，实现结构感知推理与噪声抑制。

Result: 实验表明PCRS-TKA在推荐准确性和对话质量方面均显著优于现有基线方法。

Conclusion: PCRS-TKA有效整合PLM与KG，通过结构化知识表示和上下文感知机制提升了对话推荐系统的性能。

Abstract: Recent advances in pretrained language models (PLMs) have significantly improved conversational recommender systems (CRS), enabling more fluent and context-aware interactions. To further enhance accuracy and mitigate hallucination, many methods integrate PLMs with knowledge graphs (KGs), but face key challenges: failing to fully exploit PLM reasoning over graph relationships, indiscriminately incorporating retrieved knowledge without context filtering, and neglecting collaborative preferences in multi-turn dialogues. To this end, we propose PCRS-TKA, a prompt-based framework employing retrieval-augmented generation to integrate PLMs with KGs. PCRS-TKA constructs dialogue-specific knowledge trees from KGs and serializes them into texts, enabling structure-aware reasoning while capturing rich entity semantics. Our approach selectively filters context-relevant knowledge and explicitly models collaborative preferences using specialized supervision signals. A semantic alignment module harmonizes heterogeneous inputs, reducing noise and enhancing accuracy. Extensive experiments demonstrate that PCRS-TKA consistently outperforms all baselines in both recommendation and conversational quality.

</details>


### [429] [Dynamic Tree Databases in Automated Planning](https://arxiv.org/abs/2511.12677)
*Oliver Joergensen,Dominik Drexler,Jendrik Seipp*

Main category: cs.AI

TL;DR: 提出了一种用于命题和数值变量的状态集压缩的新型动态树数据库，实现了数量级的压缩比，且运行时开销可忽略。


<details>
  <summary>Details</summary>
Motivation: 扩展显式状态空间搜索面临的主要挑战是如何紧凑地表示生成的状态集，而传统树数据库需要大量预分配内存。

Method: 提出一种新型动态树数据库，可在保持静态版本优良特性的同时，动态压缩包含命题和数值变量的状态集，并进行了理论证明。

Result: 在经典和数值规划任务上的实验表明，该方法实现了多个数量级的压缩比，通常伴随可忽略的运行时开销。

Conclusion: 动态树数据库有效解决了大规模任务中状态表示的内存瓶颈问题，适用于接地和提升规划中的状态压缩。

Abstract: A central challenge in scaling up explicit state-space search for large tasks is compactly representing the set of generated states. Tree databases, a data structure from model checking, require constant space per generated state in the best case, but they need a large preallocation of memory. We propose a novel dynamic variant of tree databases for compressing state sets over propositional and numeric variables and prove that it maintains the desirable properties of the static counterpart. Our empirical evaluation of state compression techniques for grounded and lifted planning on classical and numeric planning tasks reveals compression ratios of several orders of magnitude, often with negligible runtime overhead.

</details>


### [430] [Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces](https://arxiv.org/abs/2511.12759)
*James Moore*

Main category: cs.AI

TL;DR: 随机游走在现代高维语义嵌入空间中可产生符合最优觅食理论的人类记忆检索行为，而更复杂的采样方法（如Metropolis-Hastings）反而不一致于人类行为，表明简单采样结合良好结构的嵌入即可模拟记忆觅食。


<details>
  <summary>Details</summary>
Motivation: 探究现代高维语义嵌入是否能支持算法复现人类在语义流畅性任务中的觅食行为，并检验复杂采样机制是否优于简单策略。

Method: 使用最先进的语义嵌入和已有语义流畅性数据，模拟随机游走与Metropolis-Hastings采样的行为表现，并与人类行为对比。

Result: 随机游走在嵌入空间中表现出符合边际价值定理的最优觅食模式；引入Metropolis-Hastings采样后结果不再匹配人类行为。

Conclusion: 良好的语义嵌入结构本身足以支持近似最优的记忆检索动态，无需依赖复杂的采样机制，支持Hills(2012)的观点而非Abbott(2015)的假设。

Abstract: Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.

</details>


### [431] [Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models for Reliable Spatio-Temporal Forecasting](https://arxiv.org/abs/2511.12769)
*Luyao Niu,Zepu Wang,Shuyi Guan,Yang Liu,Peng Sun*

Main category: cs.AI

TL;DR: 提出Event-CausNet框架，结合大语言模型与因果推理，提升交通预测在突发事件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有时空图神经网络在非重复性事件（如事故）发生时预测可靠性显著下降，因其依赖历史相关性而无法应对新引入的因果因素。

Method: 利用大语言模型解析非结构化事件报告，构建因果知识库并估计平均处理效应，通过双流GNN-LSTM网络与新型因果注意力机制融合因果信息进行预测调整。

Result: 在真实数据集上实验表明，该方法最高可将预测误差（MAE）降低35.87%，显著优于现有先进基线模型。

Conclusion: Event-CausNet弥合了相关性模型与因果推理之间的差距，提升了交通预测的准确性、可迁移性和可解释性，为关键突发事件期间的交通管理提供了更可靠的基础。

Abstract: While spatio-temporal Graph Neural Networks (GNNs) excel at modeling recurring traffic patterns, their reliability plummets during non-recurring events like accidents. This failure occurs because GNNs are fundamentally correlational models, learning historical patterns that are invalidated by the new causal factors introduced during disruptions. To address this, we propose Event-CausNet, a framework that uses a Large Language Model to quantify unstructured event reports, builds a causal knowledge base by estimating average treatment effects, and injects this knowledge into a dual-stream GNN-LSTM network using a novel causal attention mechanism to adjust and enhance the forecast. Experiments on a real-world dataset demonstrate that Event-CausNet achieves robust performance, reducing prediction error (MAE) by up to 35.87%, significantly outperforming state-of-the-art baselines. Our framework bridges the gap between correlational models and causal reasoning, providing a solution that is more accurate and transferable, while also offering crucial interpretability, providing a more reliable foundation for real-world traffic management during critical disruptions.

</details>


### [432] [Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization](https://arxiv.org/abs/2511.12792)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Zehong Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 本研究利用多智能体强化学习（MARL）优化异构卫星集群在自主地球观测任务中的资源管理，通过近真实仿真环境评估MAPPO、HAPPO和HATRPO等算法的性能，结果表明MARL能有效协调异构卫星，平衡成像性能与资源利用。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法难以应对地球观测任务中实时性、不确定性和去中心化决策的挑战，因此需要采用强化学习特别是多智能体强化学习来实现自适应资源调度。

Method: 将资源优化问题从单星扩展到多星场景，基于Basilisk和BSK-RL框架构建近真实仿真环境，采用MAPPO、HAPPO和HATRPO等先进MARL算法进行实验评估，考虑能量、存储限制、部分可观测性及智能体异质性。

Result: MARL算法能够有效协调异构卫星集群，在保证成像性能的同时优化资源使用，缓解非平稳性和奖励耦合问题，表现出良好的稳定性和协同能力。

Conclusion: MARL为异构卫星集群的自主地球观测任务提供了可扩展且高效的解决方案，为未来智能遥感任务规划研究奠定了基础。

Abstract: This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.

</details>


### [433] [Neuro-Logic Lifelong Learning](https://arxiv.org/abs/2511.12793)
*Bowen He,Xiaoan Xu,Alper Kamil Bozkurt,Vahid Tarokh,Juncheng Dong*

Main category: cs.AI

TL;DR: 提出了一种用于归纳逻辑编程（ILP）的终身学习神经符号AI框架，通过重用先前任务中学到的逻辑规则来提升新任务的学习效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的ILP研究多集中于针对单个问题设计网络架构，缺乏对连续任务序列中知识迁移和持续学习机制的探索，因此需要一种能够利用逻辑规则组合性和可迁移性的新学习范式。

Method: 提出一个组合式框架，形式化地建模如何将在早期任务中获得的逻辑规则有效地迁移到后续任务中，并结合神经网络进行终身学习。

Result: 在一系列任务序列上进行了实验验证，结果表明该方法在学习效率、可扩展性和性能方面均优于传统方法。

Conclusion: 所提出的终身学习ILP范式是可行且有效的，为神经符号AI中的持续学习开辟了新的研究方向。

Abstract: Solving Inductive Logic Programming (ILP) problems with neural networks is a key challenge in Neural-Symbolic Ar- tificial Intelligence (AI). While most research has focused on designing novel network architectures for individual prob- lems, less effort has been devoted to exploring new learning paradigms involving a sequence of problems. In this work, we investigate lifelong learning ILP, which leverages the com- positional and transferable nature of logic rules for efficient learning of new problems. We introduce a compositional framework, demonstrating how logic rules acquired from ear- lier tasks can be efficiently reused in subsequent ones, leading to improved scalability and performance. We formalize our approach and empirically evaluate it on sequences of tasks. Experimental results validate the feasibility and advantages of this paradigm, opening new directions for continual learn- ing in Neural-Symbolic AI.

</details>


### [434] [Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback](https://arxiv.org/abs/2511.12844)
*Julia Santaniello,Matthew Russell,Benson Jiang,Donatello Sassaroli,Robert Jacob,Jivko SInapov*

Main category: cs.AI

TL;DR: 本研究提出了一种利用被动脑机接口（BCI）从隐式神经信号中获取人类反馈以指导强化学习代理训练的框架，并发布了包含25名参与者在三个任务领域中的功能性近红外光谱（fNIRS）数据集。


<details>
  <summary>Details</summary>
Motivation: 为了实现更自然和高效的人类偏好对齐，探索使用非侵入性、隐式的脑信号替代传统显式反馈的强化学习方法。

Method: 采集fNIRS信号，训练分类器（预测代理表现水平）和回归器（预测行为偏离最优策略的程度），并评估跨被试泛化及微调效果。

Result: 分类器在二分类和多分类任务上平均F1得分分别为67%和46%；加入少量个体数据微调后，F1得分分别提升17%和41%；回归模型可连续估计性能偏差。

Conclusion: 隐式fNIRS信号可用于估计代理性能，具备可行性且可通过迁移学习提升，为未来脑驱动的强化学习反馈系统奠定了基础。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is a methodology that aligns agent behavior with human preferences by integrating human feedback into the agent's training process. We introduce a possible framework that employs passive Brain-Computer Interfaces (BCI) to guide agent training from implicit neural signals. We present and release a novel dataset of functional near-infrared spectroscopy (fNIRS) recordings collected from 25 human participants across three domains: a Pick-and-Place Robot, Lunar Lander, and Flappy Bird. We train classifiers to predict levels of agent performance (optimal, sub-optimal, or worst-case) from windows of preprocessed fNIRS feature vectors, achieving an average F1 score of 67% for binary classification and 46% for multi-class models averaged across conditions and domains. We also train regressors to predict the degree of deviation between an agent's chosen action and a set of near-optimal policies, providing a continuous measure of performance. We evaluate cross-subject generalization and demonstrate that fine-tuning pre-trained models with a small sample of subject-specific data increases average F1 scores by 17% and 41% for binary and multi-class models, respectively. Our work demonstrates that mapping implicit fNIRS signals to agent performance is feasible and can be improved, laying the foundation for future brain-driven RLHF systems.

</details>


### [435] [Bootstrapping LLMs via Preference-Based Policy Optimization](https://arxiv.org/abs/2511.12867)
*Chen Jia*

Main category: cs.AI

TL;DR: 提出了一种基于偏好策略优化（PbPO）的新框架，通过将学习过程建模为策略与奖励模型之间的最小-最大博弈，实现大语言模型的自举对齐。


<details>
  <summary>Details</summary>
Motivation: 在无需大量人工标注的情况下，通过偏好数据对齐大语言模型行为与人类偏好。

Method: 将学习过程建模为策略与奖励模型（RM）之间的最小-最大博弈，RM被限制在由偏好数据导出的置信集内；采用迭代在线算法，通过引导探索主动收集偏好数据。

Result: 理论分析证明了序列级和令牌级RM设置下的高概率遗憾界；在五个基准上的实验表明该方法持续优于现有的最先进偏好优化技术。

Conclusion: 所提出的PbPO框架能有效实现大语言模型的持续自我改进，在理论和实验上均展现出优越性能。

Abstract: Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.

</details>


### [436] [Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making](https://arxiv.org/abs/2511.12876)
*Heyang Ma,Qirui Mi,Qipeng Yang,Zijun Fan,Bo Li,Haifeng Zhang*

Main category: cs.AI

TL;DR: 提出LAMP框架，通过“思考-交流-决策”流程将语言整合到多智能体强化学习中，提升经济决策的效果、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有MARL方法难以处理语言的语义模糊和上下文丰富性，而现实经济决策常依赖非结构化语言信息（如对话与媒体叙事），需有效融合语言与数值信号。

Method: 提出LAMP框架，采用Think-Speak-Decide流程：Think模块从数值观测中提取短期冲击与长期趋势；Speak模块基于推理生成并交换策略性信息，更新对同伴沟通的理解；Decide模块融合数值数据、推理和反思进行决策。

Result: 在经济模拟实验中，LAMP在累积收益上比MARL和纯大模型基线分别提升63.5%和34.0%，鲁棒性提升18.8%和59.4%，且具有更高可解释性。

Conclusion: 语言增强的决策策略能显著提升经济决策的有效性与鲁棒性，LAMP为现实场景中的语言化经济交互提供了可行框架。

Abstract: Economic decision-making depends not only on structured signals such as prices and taxes, but also on unstructured language, including peer dialogue and media narratives. While multi-agent reinforcement learning (MARL) has shown promise in optimizing economic decisions, it struggles with the semantic ambiguity and contextual richness of language. We propose LAMP (Language-Augmented Multi-Agent Policy), a framework that integrates language into economic decision-making and narrows the gap to real-world settings. LAMP follows a Think-Speak-Decide pipeline: (1) Think interprets numerical observations to extract short-term shocks and long-term trends, caching high-value reasoning trajectories; (2) Speak crafts and exchanges strategic messages based on reasoning, updating beliefs by parsing peer communications; and (3) Decide fuses numerical data, reasoning, and reflections into a MARL policy to optimize language-augmented decision-making. Experiments in economic simulation show that LAMP outperforms both MARL and LLM-only baselines in cumulative return (+63.5%, +34.0%), robustness (+18.8%, +59.4%), and interpretability. These results demonstrate the potential of language-augmented policies to deliver more effective and robust economic strategies.

</details>


### [437] [Online Learning of HTN Methods for integrated LLM-HTN Planning](https://arxiv.org/abs/2511.12901)
*Yuesheng Xu,Hector Munoz-Avila*

Main category: cs.AI

TL;DR: 提出了一种在HTN规划与基于LLM的聊天机器人集成中在线学习HTN方法的机制，通过从ChatGPT生成的任务分解中学习广义方法，减少对大模型的调用次数，同时保持或提升问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 在HTN规划中，缺乏有效的方法会导致频繁调用大语言模型（如ChatGPT）进行任务分解，影响效率；希望通过在线学习机制减少对LLM的依赖，提高系统自主性与效率。

Method: 在ChatHTN框架基础上，当ChatGPT生成任务分解时，系统从中提取并学习可泛化的HTN方法，而非仅缓存具体实例，实现类似备忘录但更具泛化能力的在线学习机制。

Result: 在两个领域上的实验表明，该方法显著减少了对ChatGPT的调用次数，同时解决了相同甚至更多的问题。

Conclusion: 所提出的在线学习机制能有效提升HTN规划系统的效率和自主性，通过泛化学习减少对大语言模型的依赖，具有实际应用潜力。

Abstract: We present online learning of Hierarchical Task Network (HTN) methods in the context of integrated HTN planning and LLM-based chatbots. Methods indicate when and how to decompose tasks into subtasks. Our method learner is built on top of the ChatHTN planner. ChatHTN queries ChatGPT to generate a decomposition of a task into primitive tasks when no applicable method for the task is available. In this work, we extend ChatHTN. Namely, when ChatGPT generates a task decomposition, ChatHTN learns from it, akin to memoization. However, unlike memoization, it learns a generalized method that applies not only to the specific instance encountered, but to other instances of the same task. We conduct experiments on two domains and demonstrate that our online learning procedure reduces the number of calls to ChatGPT while solving at least as many problems, and in some cases, even more.

</details>


### [438] [CoS: Towards Optimal Event Scheduling via Chain-of-Scheduling](https://arxiv.org/abs/2511.12913)
*Yiming Zhao,Jiwei Tang,Shimin Di,Libin Zheng,Jianxing Yu,Jian Yin*

Main category: cs.AI

TL;DR: 本文提出了Chain-of-Scheduling (CoS) 框架，利用大语言模型（LLMs）解决事件调度推荐问题，在效率、效果和泛化能力之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法在效率、有效性和泛化能力之间存在权衡，难以应对EBSN中受时空约束的事件推荐问题。

Method: 将调度任务分解为探索、验证和整合三个阶段，并通过知识蒸馏使大语言模型自主生成CoS。

Result: 在三个真实数据集上实验表明，CoS以高效率达到接近理论最优的效果，并具备对域外数据的强零样本学习能力。

Conclusion: CoS框架有效激活了大语言模型在事件调度中的潜力，实现了高效、有效且可解释的推荐。

Abstract: Recommending event schedules is a key issue in Event-based Social Networks (EBSNs) in order to maintain user activity. An effective recommendation is required to maximize the user's preference, subjecting to both time and geographical constraints. Existing methods face an inherent trade-off among efficiency, effectiveness, and generalization, due to the NP-hard nature of the problem. This paper proposes the Chain-of-Scheduling (CoS) framework, which activates the event scheduling capability of Large Language Models (LLMs) through a guided, efficient scheduling process. CoS enhances LLM by formulating the schedule task into three atomic stages, i.e., exploration, verification and integration. Then we enable the LLMs to generate CoS autonomously via Knowledge Distillation (KD). Experimental results show that CoS achieves near-theoretical optimal effectiveness with high efficiency on three real-world datasets in a interpretable manner. Moreover, it demonstrates strong zero-shot learning ability on out-of-domain data.

</details>


### [439] [Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation](https://arxiv.org/abs/2511.12916)
*Yafang Wang,Yangjie Tian,Xiaoyu Shen,Gaoyang Zhang,Jiaze Sun,He Zhang,Ruohua Xu,Feng Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种名为Fault2Flow的基于大语言模型的多智能体系统，用于电力系统故障诊断，能够将法规和专家知识整合为可执行的工作流。


<details>
  <summary>Details</summary>
Motivation: 传统故障诊断依赖人工提取规则和专家经验，效率低、易出错且难以维护。现有方法无法有效结合结构化法规与非结构化专家知识。

Method: Fault2Flow通过四个步骤实现：1）从法规中提取逻辑并构建成PASTA格式的故障树；2）通过人机交互接口集成并验证专家知识；3）使用AlphaEvolve模块优化推理逻辑；4）生成可在n8n平台执行的工作流。

Result: 在变压器故障数据集上的实验表明，该方法达到100%拓扑一致性，并具有高语义保真度。

Conclusion: Fault2Flow实现了从故障分析到操作自动化的可重现路径，显著减轻了专家工作负担。

Abstract: Power grid fault diagnosis is a critical process hindered by its reliance on manual, error-prone methods. Technicians must manually extract reasoning logic from dense regulations and attempt to combine it with tacit expert knowledge, which is inefficient, error-prone, and lacks maintainability as ragulations are updated and experience evolves. While Large Language Models (LLMs) have shown promise in parsing unstructured text, no existing framework integrates these two disparate knowledge sources into a single, verified, and executable workflow. To bridge this gap, we propose Fault2Flow, an LLM-based multi-agent system. Fault2Flow systematically: (1) extracts and structures regulatory logic into PASTA-formatted fault trees; (2) integrates expert knowledge via a human-in-the-loop interface for verification; (3) optimizes the reasoning logic using a novel AlphaEvolve module; and (4) synthesizes the final, verified logic into an n8n-executable workflow. Experimental validation on transformer fault diagnosis datasets confirms 100\% topological consistency and high semantic fidelity. Fault2Flow establishes a reproducible path from fault analysis to operational automation, substantially reducing expert workload.

</details>


### [440] [Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models](https://arxiv.org/abs/2511.12937)
*Guoyan Wang,Yanyan Huang,Chunlin Chen,Lifeng Wang,Yuxiang Sun*

Main category: cs.AI

TL;DR: 本文提出了一种名为Yanyun-3的通用代理框架，首次实现了在三种异构策略游戏环境中的跨平台自主操作，通过结合视觉-语言模型与精确UI执行能力，显著提升了多模态数据组织下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在复杂人机交互场景（如跨平台策略游戏）中的应用尚不充分，缺乏具备强泛化能力和高效推理的通用代理框架。

Method: 构建Yanyun-3框架，融合Qwen2.5-VL的多模态推理与UI-TARS的精准执行；采用闭合循环流程（屏幕捕获-模型推理-动作执行），并系统评估不同多模态数据组合（静态图像、多图序列、视频）的影响，提出‘组合粒度’概念以区分融合策略。

Result: 混合策略MV+S（融合多图+视频并混合静态图像）相比全融合方法，推理时间减少63%，BLEU-4分数从4.81%提升至62.41%（约12.98倍）；代理在目标定位、资源分配和区域控制等任务中表现出强实时性和跨平台泛化能力。

Conclusion: 结构化的多模态数据组织能显著提升VLM在具身智能中的性能，MV+S策略在效率与效果间取得平衡，为复杂人机交互任务提供了可推广的范式。

Abstract: Automated operation in cross-platform strategy games demands agents with robust generalization across diverse user interfaces and dynamic battlefield conditions. While vision-language models (VLMs) have shown considerable promise in multimodal reasoning, their application to complex human-computer interaction scenarios--such as strategy gaming--remains largely unexplored. Here, we introduce Yanyun-3, a general-purpose agent framework that, for the first time, enables autonomous cross-platform operation across three heterogeneous strategy game environments. By integrating the vision-language reasoning of Qwen2.5-VL with the precise execution capabilities of UI-TARS, Yanyun-3 successfully performs core tasks including target localization, combat resource allocation, and area control. Through systematic ablation studies, we evaluate the effects of various multimodal data combinations--static images, multi-image sequences, and videos--and propose the concept of combination granularity to differentiate between intra-sample fusion and inter-sample mixing strategies. We find that a hybrid strategy, which fuses multi-image and video data while mixing in static images (MV+S), substantially outperforms full fusion: it reduces inference time by 63% and boosts the BLEU-4 score by a factor of 12 (from 4.81% to 62.41%, approximately 12.98x). Operating via a closed-loop pipeline of screen capture, model inference, and action execution, the agent demonstrates strong real-time performance and cross-platform generalization. Beyond providing an efficient solution for strategy game automation, our work establishes a general paradigm for enhancing VLM performance through structured multimodal data organization, offering new insights into the interplay between static perception and dynamic reasoning in embodied intelligence.

</details>


### [441] [MedRule-KG: A Knowledge-Graph--Steered Scaffold for Reliable Mathematical and Biomedical Reasoning](https://arxiv.org/abs/2511.12963)
*Crystal Su*

Main category: cs.AI

TL;DR: 提出MedRule-KG，一种结合知识图谱与轻量级验证器的方法，通过符号规则引导大语言模型生成符合数学与生物医学逻辑的输出，在药物发现等任务中显著减少错误并提升准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在科学推理和早期药物发现中，解决大语言模型生成结果缺乏领域一致性的问题，需要引入结构化知识以约束生成过程。

Method: 构建紧凑的知识图谱（MedRule-KG）作为生成的支架，并设计轻量级验证器；通过提示注入符号化事实，将生成形式化为约束推理过程，引入软性引导机制用于解码，并使用确定性检查器确保规则满足。

Result: 在90项涵盖反应可行性、代谢兼容性和毒性筛选的任务中，相比强基线模型，违规次数减少了83.2%，且精确匹配率提高；结果在不同数据分层下稳定，随数据规模扩展而改善，验证器带来可忽略的延迟。

Conclusion: MedRule-KG能有效将领域知识融入LLM生成过程，在保持高效的同时显著提升科学推理任务中的准确性和合规性，具有实际应用于交互式药物设计的潜力。

Abstract: We study how to impose domain-consistent structure on large language models (LLMs) used for scientific reasoning and early-stage drug discovery. We present MedRule-KG, a compact knowledge-graph scaffold paired with a lightweight verifier that steers generation toward mathematically and biomedically valid outputs. The system injects curated symbolic facts into prompts and then enforces rule satisfaction with a deterministic checker. We formalize generation as constrained inference, introduce a soft guidance surrogate suitable for decoding, and perform a thorough statistical analysis with uncertainty quantification. Across 90 tasks spanning reaction feasibility, metabolic compatibility, and toxicity screening, MedRule-KG reduces violation counts by 83.2\% relative to a strong chain-of-thought baseline while improving exact match. Results remain stable under stratification and scale with dataset size, and the verifier adds negligible latency, making the approach practical for interactive design.

</details>


### [442] [WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance](https://arxiv.org/abs/2511.12997)
*Genglin Liu,Shijie Geng,Sha Li,Hejie Cui,Sarah Zhang,Xin Liu,Tianyi Liu*

Main category: cs.AI

TL;DR: WebCoach 是一个模型无关的自演进框架，通过引入跨会话持久记忆机制，提升多模态LLM代理在网页导航中的长期规划、反思和持续学习能力，无需重新训练即可提高任务成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的网页浏览代理在重复错误上表现不佳，且无法跨会话从过去经验中学习，限制了其长期鲁棒性和样本效率。

Method: WebCoach 包含三个核心组件：WebCondenser（将原始导航日志标准化为简洁摘要）、外部记忆库（存储完整轨迹作为情景经验）和 Coach（根据相似性和时效性检索相关经验，并通过运行时钩子注入任务建议）。该框架使代理能够超越自身上下文窗口访问长期记忆，并通过持续整合新轨迹来实现自我演进。

Result: 在 WebVoyager 基准测试中，WebCoach 在三种不同LLM基础上均提升了浏览器代理的表现；使用38B模型时，任务成功率从47%提升至61%，步数减少或保持不变；更小的基础模型配合 WebCoach 可达到与 GPT-4o 相当的性能。

Conclusion: WebCoach 通过持久化记忆和自我演化机制，显著增强了网页浏览代理的长期性能和泛化能力，且无需重新训练，具有良好的模型通用性和实用前景。

Abstract: Multimodal LLM-powered agents have recently demonstrated impressive capabilities in web navigation, enabling agents to complete complex browsing tasks across diverse domains. However, current agents struggle with repetitive errors and lack the ability to learn from past experiences across sessions, limiting their long-term robustness and sample efficiency. We introduce WebCoach, a model-agnostic self-evolving framework that equips web browsing agents with persistent cross-session memory, enabling improved long-term planning, reflection, and continual learning without retraining. WebCoach consists of three key components: (1) a WebCondenser, which standardizes raw navigation logs into concise summaries; (2) an External Memory Store, which organizes complete trajectories as episodic experiences; and (3) a Coach, which retrieves relevant experiences based on similarity and recency, and decides whether to inject task-specific advice into the agent via runtime hooks. This design empowers web agents to access long-term memory beyond their native context window, improving robustness in complex browsing tasks. Moreover, WebCoach achieves self-evolution by continuously curating episodic memory from new navigation trajectories, enabling agents to improve over time without retraining. Evaluations on the WebVoyager benchmark demonstrate that WebCoach consistently improves the performance of browser-use agents across three different LLM backbones. With a 38B model, it increases task success rates from 47% to 61% while reducing or maintaining the average number of steps. Notably, smaller base models with WebCoach achieve performance comparable to the same web agent using GPT-4o.

</details>


### [443] [GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs](https://arxiv.org/abs/2511.13007)
*Yiyang Zhao,Huiyu Bai,Xuejiao Zhao*

Main category: cs.AI

TL;DR: 提出一种基于生成熵引导的偏好建模方法GEM，用于低资源和特定领域下的大语言模型对齐，通过内部化闭环优化架构，利用认知信号实现少样本高效对齐。


<details>
  <summary>Details</summary>
Motivation: 在医学、法律等依赖专业知识的领域，获取大规模人类偏好标注数据困难，传统依赖监督奖励模型或外部评判的方法难以适用。

Method: 提出GEM方法，包含基于熵理论的认知过滤模块，利用思维链（CoT）生成多样推理路径，并通过令牌评分机制筛选高置信度和高熵令牌；基于过滤后的偏好，采用自评估组优势算法（SEGA）进行微调，将熵得分转化为隐式奖励。

Result: 在通用基准和特定领域任务（如数学推理、医疗对话）上，使用少样本偏好数据时，GEM显著优于现有方法。

Conclusion: GEM实现了无需大量标注的高效少样本对齐，使LLM能自主判断并构建熵引导的闭环认知优化框架，适用于低资源专业领域。

Abstract: Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.

</details>


### [444] [PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics](https://arxiv.org/abs/2511.13021)
*Sachin Vashistha,Aryan Bibhuti,Atharva Naik,Martin Tutek,Somak Aditya*

Main category: cs.AI

TL;DR: 本文研究了语言模型在双人对话中构建和维护内部世界模型的能力，发现现有模型在处理语言变化时难以保持鲁棒性，并提出了一种双视角可解释性框架及基于层正则化的微调策略以改善性能。


<details>
  <summary>Details</summary>
Motivation: 理解真实对话中的语用元素（如实体提及、指代和隐含意义）需要建立并维护一个动态的局部世界模型，但目前尚不清楚语言模型是否能隐式地构建或维持这样的表示。

Method: 通过对流行数据集中的对话应用七种最小语言修改，构建了两个包含是非问题的基准测试，评估多种开源和闭源语言模型的表现，并提出一种双视角可解释性框架来识别有益和有害的Transformer层，进而设计层正则化微调策略。

Result: 实验表明语言模型在记忆关键细节（如实体追踪）方面存在困难，尤其是在对话经历语言修改后表现下降；可解释性分析揭示了某些层因捕捉虚假信号或依赖捷径而产生负面影响。

Conclusion: 语言模型在维护对话世界模型方面仍不 robust，通过识别并抑制有害层的影响，所提出的正则化微调方法有助于提升模型对语言变化的鲁棒性。

Abstract: Real-world conversations are rich with pragmatic elements, such as entity mentions, references, and implicatures. Understanding such nuances is a requirement for successful natural communication, and often requires building a local world model which encodes such elements and captures the dynamics of their evolving states. However, it is not well-understood whether language models (LMs) construct or maintain a robust implicit representation of conversations. In this work, we evaluate the ability of LMs to encode and update their internal world model in dyadic conversations and test their malleability under linguistic alterations. To facilitate this, we apply seven minimal linguistic alterations to conversations sourced from popular datasets and construct two benchmarks comprising yes-no questions. We evaluate a wide range of open and closed source LMs and observe that they struggle to maintain robust accuracy. Our analysis unveils that LMs struggle to memorize crucial details, such as tracking entities under linguistic alterations to conversations. We then propose a dual-perspective interpretability framework which identifies transformer layers that are useful or harmful and highlights linguistic alterations most influenced by harmful layers, typically due to encoding spurious signals or relying on shortcuts. Inspired by these insights, we propose two layer-regularization based fine-tuning strategies that suppress the effect of the harmful layers.

</details>


### [445] [Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection](https://arxiv.org/abs/2511.13027)
*Sadegh Mahdavi,Branislav Kisacanin,Shubham Toshniwal,Wei Du,Ivan Moshkov,George Armstrong,Renjie Liao,Christos Thrampoulidis,Igor Gitman*

Main category: cs.AI

TL;DR: 本文研究了大语言模型在数学推理中的验证问题，提出结合生成式验证方法（GenSelect 和 LLM-as-a-Judge）并扩展至百万token规模，以更可靠地评估模型性能。研究发现提示设计影响显著，强化学习可降低敏感性，但不提升最终答案准确率，表明模型偏好形式正确而非数学正确。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在数学问题的最终答案上表现良好，但推理过程常存在错误；为推进严格证明型数学的发展，需要可靠的证明验证能力。现有评估方式易因依赖单一基准而产生误导，因此需更稳健的评估框架。

Method: 通过分析多种评估设置，结合生成式验证方法GenSelect与LLM-as-a-Judge，并将其扩展到大规模token训练；使用强化学习优化LLM-as-a-Judge的提示鲁棒性，同时评估模型在证明层面和最终答案层面的表现。

Result: 发现GenSelect与LLM-as-a-Judge的组合是最有效的验证与筛选框架；提示设计对性能有显著影响，强化学习可缓解该问题；尽管证明级指标提升，但最终答案精度未改善，说明模型倾向于奖励形式或流程正确性而非数学正确性。

Conclusion: 当前大语言模型在数学推理中仍存在形式与实质正确性的脱节；为构建可靠的证明验证系统，应综合多种评估方式，并谨慎设计提示与训练策略，强化学习有助于提升鲁棒性但不足以保证数学有效性。

Abstract: Large language models have achieved remarkable success on final-answer mathematical problems, largely due to the ease of applying reinforcement learning with verifiable rewards. However, the reasoning underlying these solutions is often flawed. Advancing to rigorous proof-based mathematics requires reliable proof verification capabilities. We begin by analyzing multiple evaluation setups and show that focusing on a single benchmark can lead to brittle or misleading conclusions. To address this, we evaluate both proof-based and final-answer reasoning to obtain a more reliable measure of model performance. We then scale two major generative verification methods (GenSelect and LLM-as-a-Judge) to millions of tokens and identify their combination as the most effective framework for solution verification and selection. We further show that the choice of prompt for LLM-as-a-Judge significantly affects the model's performance, but reinforcement learning can reduce this sensitivity. However, despite improving proof-level metrics, reinforcement learning does not enhance final-answer precision, indicating that current models often reward stylistic or procedural correctness rather than mathematical validity. Our results establish practical guidelines for designing and evaluating scalable proof-verification and selection systems.

</details>


### [446] [MEGA-GUI: Multi-stage Enhanced Grounding Agents for GUI Elements](https://arxiv.org/abs/2511.13087)
*SeokJoo Kwak,Jihoon Kim,Boyoun Kim,Jung Jae Yoon,Wooseok Jang,Jeonghoon Hong,Jaeho Yang,Yeong-Dae Kwon*

Main category: cs.AI

TL;DR: MEGA-GUI是一个多阶段框架，用于提升图形用户界面（GUI）中的自然语言指令到屏幕坐标的映射精度，通过模块化设计在复杂视觉和语义场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有GUI grounding方法依赖于单一模型或一次性流水线，在视觉杂乱和指令模糊时表现不佳，缺乏模块化和鲁棒性。

Method: 提出MEGA-GUI框架，将定位分为粗粒度的感兴趣区域（ROI）选择和细粒度元素定位，采用双向ROI缩放算法缓解空间稀释，并引入上下文感知重写代理减少语义歧义，由专用视觉-语言代理协同完成。

Result: 在ScreenSpot-Pro基准上达到73.18%的准确率，在OSWorld-G基准上达到68.63%，均超过先前最优结果。

Conclusion: 模块化设计能有效利用不同视觉-语言模型在多尺度上的互补优势，显著提升GUI grounding的准确性和鲁棒性。

Abstract: Graphical User Interface (GUI) grounding - the task of mapping natural language instructions to screen coordinates - is essential for autonomous agents and accessibility technologies. Existing systems rely on monolithic models or one-shot pipelines that lack modularity and fail under visual clutter and ambiguous instructions. We introduce MEGA-GUI, a multi-stage framework that separates grounding into coarse Region-of-Interest (ROI) selection and fine-grained element grounding, orchestrated by specialized vision-language agents. MEGA-GUI features a bidirectional ROI zoom algorithm that mitigates spatial dilution and a context-aware rewriting agent that reduces semantic ambiguity. Our analysis reveals complementary strengths and weaknesses across vision-language models at different visual scales, and we show that leveraging this modular structure achieves consistently higher accuracy than monolithic approaches. On the visually dense ScreenSpot-Pro benchmark, MEGA-GUI attains 73.18% accuracy, and on the semantically complex OSWorld-G benchmark it reaches 68.63%, surpassing previously reported results. Code and the Grounding Benchmark Toolkit (GBT) are available at https://github.com/samsungsds-research-papers/mega-gui.

</details>


### [447] [STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization](https://arxiv.org/abs/2511.13091)
*Yuhan Chen,Yuxuan Liu,Long Zhang,Pengzhi Gao,Jian Luan,Wei Liu*

Main category: cs.AI

TL;DR: 提出STEP框架，通过成功率感知的轨迹高效策略优化，提升多轮交互中的样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹级优化方法在多轮交互中存在采样效率低、学习信号误导等问题，难以有效处理任务难度差异。

Method: STEP框架基于每个任务的成功率动态分配采样资源，采用平滑的成功率记录指导自适应重采样，并将轨迹分解为步级样本，结合成功率为权重的优势计算和步级GRPO增强进行优化。

Result: 在OSWorld和AndroidWorld上的实验表明，相比轨迹级GRPO，STEP显著提高了样本效率和训练稳定性，收敛更快，在相同采样预算下泛化性能更好。

Conclusion: STEP通过细粒度的步级优化和动态资源分配，有效解决了多轮交互中强化学习的低效问题，为复杂任务的持续学习提供了更优框架。

Abstract: Multi-turn interaction remains challenging for online reinforcement learning. A common solution is trajectory-level optimization, which treats each trajectory as a single training sample. However, this approach can be inefficient and yield misleading learning signals: it applies uniform sampling across tasks regardless of difficulty, penalizes correct intermediate actions in failed trajectories, and incurs high sample-collection costs. To address these issues, we propose STEP (Success-rate-aware Trajectory-Efficient Policy optimization), a framework that dynamically allocates sampling based on per-task success rates and performs step-level optimization. STEP maintains a smoothed success-rate record to guide adaptive trajectory resampling, allocating more effort to harder tasks. It then computes success-rate-weighted advantages and decomposes trajectories into step-level samples. Finally, it applies a step-level GRPO augmentation to refine updates for low-success tasks. Experiments on OSWorld and AndroidWorld show that STEP substantially improves sample efficiency and training stability over trajectory-level GRPO, converging faster and generalizing better under the same sampling budget.

</details>


### [448] [MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications](https://arxiv.org/abs/2511.13131)
*Gagan Raj Gupta,Anshul Kumar,Manish Rai,Apu Chakraborty,Ashutosh Modi,Abdelaali Chaoub,Soumajit Pramanik,Moyank Giri,Yashwanth Holla,Sunny Kumar,M. V. Kiran Sooraj*

Main category: cs.AI

TL;DR: 本文提出了MM-Telco，一个面向电信领域的多模态基准测试套件，旨在解决大语言模型在电信网络优化、故障排除等实际应用中的适应性问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在电信领域具有广泛应用潜力，但其部署面临领域特异性挑战，需要专门的适配方法。

Method: 设计了一个包含文本和图像任务的多模态基准MM-Telco，并对多种大语言模型和视觉语言模型进行微调和基线实验。

Result: 在该数据集上微调的模型性能显著提升，并揭示了当前多模态大模型在电信任务中的薄弱环节。

Conclusion: MM-Telco有助于推动大语言模型在电信领域的定制化发展，为后续研究和改进提供了方向。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for automating complex reasoning and decision-making tasks. In telecommunications, they hold the potential to transform network optimization, automate troubleshooting, enhance customer support, and ensure regulatory compliance. However, their deployment in telecom is hindered by domain-specific challenges that demand specialized adaptation. To overcome these challenges and to accelerate the adaptation of LLMs for telecom, we propose MM-Telco, a comprehensive suite of multimodal benchmarks and models tailored for the telecom domain. The benchmark introduces various tasks (both text based and image based) that address various practical real-life use cases such as network operations, network management, improving documentation quality, and retrieval of relevant text and images. Further, we perform baseline experiments with various LLMs and VLMs. The models fine-tuned on our dataset exhibit a significant boost in performance. Our experiments also help analyze the weak areas in the working of current state-of-art multimodal LLMs, thus guiding towards further development and research.

</details>


### [449] [Conditional Diffusion Model for Multi-Agent Dynamic Task Decomposition](https://arxiv.org/abs/2511.13137)
*Yanda Zhu,Yuanyang Zhu,Daoyi Dong,Caihua Chen,Chunlin Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为C$\text{D}^\text{3}$T的新型双层分层多智能体强化学习框架，通过条件扩散模型实现动态任务分解，自动推断子任务和协作模式，在复杂部分可观测环境中提升了长时程任务的学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂的多智能体强化学习任务中，从零开始学习动态任务分解需要大量样本，尤其是在部分可观测下探索巨大的联合动作空间，因此需要一种高效的方法来减少样本需求并提升任务分解效果。

Method: 提出C$\text{D}^\text{3}$T框架：高层策略基于子任务影响生成子任务选择策略，并利用条件扩散模型预测下一观测和奖励以捕捉子任务对环境的影响；底层智能体在分配的子任务内协作学习和共享专用技能；同时将子任务表征用于多头注意力混合网络，增强价值分解。

Result: 在多个基准测试上的实验结果表明，C$\text{D}^\text{3}$T在性能上优于现有基线方法。

Conclusion: C$\text{D}^\text{3}$T通过结合条件扩散模型与分层强化学习，有效实现了动态任务分解与价值分解，显著提升了多智能体系统在复杂环境中的学习效率和协作性能。

Abstract: Task decomposition has shown promise in complex cooperative multi-agent reinforcement learning (MARL) tasks, which enables efficient hierarchical learning for long-horizon tasks in dynamic and uncertain environments. However, learning dynamic task decomposition from scratch generally requires a large number of training samples, especially exploring the large joint action space under partial observability. In this paper, we present the Conditional Diffusion Model for Dynamic Task Decomposition (C$\text{D}^\text{3}$T), a novel two-level hierarchical MARL framework designed to automatically infer subtask and coordination patterns. The high-level policy learns subtask representation to generate a subtask selection strategy based on subtask effects. To capture the effects of subtasks on the environment, C$\text{D}^\text{3}$T predicts the next observation and reward using a conditional diffusion model. At the low level, agents collaboratively learn and share specialized skills within their assigned subtasks. Moreover, the learned subtask representation is also used as additional semantic information in a multi-head attention mixing network to enhance value decomposition and provide an efficient reasoning bridge between individual and joint value functions. Experimental results on various benchmarks demonstrate that C$\text{D}^\text{3}$T achieves better performance than existing baselines.

</details>


### [450] [InteractiveGNNExplainer: A Visual Analytics Framework for Multi-Faceted Understanding and Probing of Graph Neural Network Predictions](https://arxiv.org/abs/2511.13160)
*TC Singh,Sougata Mukherjea*

Main category: cs.AI

TL;DR: 本文提出了InteractiveGNNExplainer，一个用于增强图神经网络（GNN）可解释性的可视化分析框架，特别关注节点分类任务。


<details>
  <summary>Details</summary>
Motivation: GNN在图学习任务中表现出色，但其复杂的非线性操作使其成为“黑箱”，缺乏透明度阻碍了用户信任、调试、偏见检测以及在关键领域的应用。

Method: 该框架结合了协调的交互式视图（如动态图布局、嵌入投影、特征检查和邻域分析）与现有的事后（GNNExplainer）和内在（GAT注意力）解释方法，并引入了交互式图编辑功能，支持“假设”分析。

Result: 通过在Cora和CiteSeer数据集上的案例研究，展示了该系统能够深入诊断错误分类、比较GCN与GAT的行为差异，并探测模型敏感性。

Conclusion: InteractiveGNNExplainer提升了对GNN预测的多角度理解，有助于实现更透明、可信和鲁棒的图分析。

Abstract: Graph Neural Networks (GNNs) excel in graph-based learning tasks, but their complex, non-linear operations often render them as opaque "black boxes". This opacity hinders user trust, complicates debugging, bias detection, and adoption in critical domains requiring explainability. This paper introduces InteractiveGNNExplainer, a visual analytics framework to enhance GNN explainability, focusing on node classification. Our system uniquely integrates coordinated interactive views (dynamic graph layouts, embedding projections, feature inspection, neighborhood analysis) with established post-hoc (GNNExplainer) and intrinsic (GAT attention) explanation techniques. Crucially, it incorporates interactive graph editing, allowing users to perform a "what-if" analysis by perturbing graph structures and observing immediate impacts on GNN predictions and explanations. We detail the system architecture and, through case studies on Cora and CiteSeer datasets, demonstrate how InteractiveGNNExplainer facilitates in-depth misclassification diagnosis, comparative analysis of GCN versus GAT behaviors, and rigorous probing of model sensitivity. These capabilities foster a deeper, multifaceted understanding of GNN predictions, contributing to more transparent, trustworthy, and robust graph analysis.

</details>


### [451] [Cost-Effective Communication: An Auction-based Method for Language Agent Interaction](https://arxiv.org/abs/2511.13193)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Chengpei Tang,Jian Wang,Keze Wang*

Main category: cs.AI

TL;DR: 本文提出了动态拍卖式语言代理（DALA）框架，通过将通信带宽视为稀缺资源并引入拍卖机制，提升多智能体系统中通信的效率与质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的多智能体系统常因无节制的自由通信导致高昂的token成本和低信噪比，缺乏资源理性。

Method: 将智能体间的通信建模为集中式拍卖过程，智能体根据消息预测价值密度进行竞价发言，从而实现对通信资源的高效分配。

Result: 在七个推理基准上达到最先进性能，如MMLU 84.32%、HumanEval pass@1 91.21%，且仅使用625万token，显著低于现有方法；同时展现出策略性沉默的涌现行为。

Conclusion: DALA通过引入资源稀缺性和经济激励机制，有效提升了多智能体系统的通信效率与推理能力，为实际部署提供了更高效的解决方案。

Abstract: Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient "free-for-all" communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that "free" communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.

</details>


### [452] [Learning to Solve Resource-Constrained Project Scheduling Problems with Duration Uncertainty using Graph Neural Networks](https://arxiv.org/abs/2511.13214)
*Guillaume Infantes,Stéphanie Roussel,Antoine Jacquet,Emmanuel Benazera*

Main category: cs.AI

TL;DR: 本文提出了一种基于图神经网络和深度强化学习的框架Wheatley，用于解决具有不确定任务持续时间的资源受限项目调度问题（RCPSP），以最小化预期项目工期并生成可复用的基线调度方案。


<details>
  <summary>Details</summary>
Motivation: 由于实际中任务持续时间存在不确定性，传统的RCPSP方法难以保证调度的鲁棒性，因此需要一种能够应对不确定性并生成可重复使用基线调度的方法。

Method: 结合图神经网络与深度强化学习构建调度策略，该策略类似于优先级调度规则，并结合串行调度生成机制（Serial Schedule Generation Scheme）生成调度方案。

Result: 在标准基准测试上的实验表明，所提方法在性能上优于现有方法，并具备良好的泛化能力。

Conclusion: Wheatley框架能有效处理任务持续时间不确定的RCPSP问题，生成高质量、可复用的基线调度，且代码已公开以促进后续研究。

Abstract: The Resource-Constrained Project Scheduling Problem (RCPSP) is a classical scheduling problem that has received significant attention due to of its numerous applications in industry. However, in practice, task durations are subject to uncertainty that must be considered in order to propose resilient scheduling. In this paper, we address the RCPSP variant with uncertain tasks duration (modeled using known probabilities) and aim to minimize the overall expected project duration. Our objective is to produce a baseline schedule that can be reused multiple times in an industrial setting regardless of the actual duration scenario. We leverage Graph Neural Networks in conjunction with Deep Reinforcement Learning (DRL) to develop an effective policy for task scheduling. This policy operates similarly to a priority dispatch rule and is paired with a Serial Schedule Generation Scheme to produce a schedule. Our empirical evaluation on standard benchmarks demonstrates the approach's superiority in terms of performance and its ability to generalize. The developed framework, Wheatley, is made publicly available online to facilitate further research and reproducibility.

</details>


### [453] [Informative Communication of Robot Plans](https://arxiv.org/abs/2511.13226)
*Michele Persiani,Thomas Hellstrom*

Main category: cs.AI

TL;DR: 本文提出了一种基于信息增益和用户先验知识的机器人计划表达策略，能够比按计划顺序表达更快地帮助用户理解机器人的目标。


<details>
  <summary>Details</summary>
Motivation: 传统的增量式计划表达忽略了用户已有的知识，导致沟通效率低下。因此需要一种更有效的表达方式来提高信息传递的效率。

Method: 通过引入二阶心智理论建模用户的先验知识，并计算语言表达带来的信息增益，从而选择最具信息量的表达顺序。

Result: 实验表明，该策略能显著加快用户对机器人目标的理解速度，优于按计划顺序递增或递减的表达方式。

Conclusion: 考虑用户先验知识并衡量信息增益的表达策略，能更有效地传达机器人计划，提升人机沟通效率。

Abstract: When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.

</details>


### [454] [Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO](https://arxiv.org/abs/2511.13288)
*Haoyang Hong,Jiajun Yin,Yuan Wang,Jingnan Liu,Zhe Chen,Ailing Yu,Ji Li,Zhiling Ye,Hansong Xiao,Yefei Chen,Hualei Zhou,Yun Yue,Minghui Yang,Chunxiao Guo,Junwei Liu,Peng Wei,Jinjie Gu*

Main category: cs.AI

TL;DR: 本文提出M-GRPO，一种用于垂直多智能体系统的分层策略优化方法，通过解耦训练和轨迹对齐机制提升工具增强推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用统一的大模型训练所有智能体，忽略了不同智能体分布差异，限制了性能；且多智能体系统存在梯度流断裂、调用次数不一等优化难题。

Method: 提出M-GRPO，扩展Group Relative Policy Optimization至多智能体场景，为主智能体与子智能体分别计算组相对优势，并引入轨迹对齐机制以生成固定大小批次，采用解耦训练流程在分离服务器间通过共享存储交换统计信息。

Result: 在GAIA、XBench-DeepSearch和WebWalkerQA等真实基准上，M-GRPO优于单智能体GRPO及子智能体冻结的多智能体GRPO，表现出更高的稳定性与样本效率。

Conclusion: 对异构轨迹进行对齐并在专业化智能体间解耦优化，能有效提升多智能体系统的推理能力。

Abstract: Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.

</details>


### [455] [Dropouts in Confidence: Moral Uncertainty in Human-LLM Alignment](https://arxiv.org/abs/2511.13290)
*Jea Kwon,Luiz Felipe Vecchietti,Sungwon Park,Meeyoung Cha*

Main category: cs.AI

TL;DR: 本研究探讨了不确定性在经典电车难题中的道德决策影响，分析了32个开源模型和9个道德维度的响应。研究发现模型间的置信度差异大于道德维度内的差异，并通过引入推理时的随机性（如dropout）来调节不确定性，从而提高人类与大语言模型在道德判断上的一致性。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型在伦理决策场景中日益广泛应用，理解其道德推理及内在不确定性对于构建可靠AI系统至关重要。当前机器生成的回答往往过于自信，而人类在面对道德困境时则表现出显著的不确定性，因此需要探究如何通过调节模型的不确定性来改善人机道德对齐。

Method: 分析32个开源模型在9个道德维度上的响应，使用二元熵作为衡量不确定性的指标，将其分解为总熵、条件熵和互信息的线性组合；并通过在推理过程中引入dropout机制增加模型的随机性以研究其对道德决策的影响。

Result: 模型间在置信度上的方差大于道德维度内部的方差，表明架构和训练方法主导了道德不确定性；引入dropout后，总熵增加主要来自互信息上升，条件熵基本不变；该机制显著提升了人类与LLM之间的道德对齐程度，且互信息与对齐得分变化呈正相关。

Conclusion: 通过有意调节不确定性（如降低大语言模型在道德复杂情境中的过度自信），可以有效提升模型决策与人类偏好的一致性，为构建更可靠的伦理AI系统提供了可行路径。

Abstract: Humans display significant uncertainty when confronted with moral dilemmas, yet the extent of such uncertainty in machines and AI agents remains underexplored. Recent studies have confirmed the overly confident tendencies of machine-generated responses, particularly in large language models (LLMs). As these systems are increasingly embedded in ethical decision-making scenarios, it is important to understand their moral reasoning and the inherent uncertainties in building reliable AI systems. This work examines how uncertainty influences moral decisions in the classical trolley problem, analyzing responses from 32 open-source models and 9 distinct moral dimensions. We first find that variance in model confidence is greater across models than within moral dimensions, suggesting that moral uncertainty is predominantly shaped by model architecture and training method. To quantify uncertainty, we measure binary entropy as a linear combination of total entropy, conditional entropy, and mutual information. To examine its effects, we introduce stochasticity into models via "dropout" at inference time. Our findings show that our mechanism increases total entropy, mainly through a rise in mutual information, while conditional entropy remains largely unchanged. Moreover, this mechanism significantly improves human-LLM moral alignment, with correlations in mutual information and alignment score shifts. Our results highlight the potential to better align model-generated decisions and human preferences by deliberately modulating uncertainty and reducing LLMs' confidence in morally complex scenarios.

</details>


### [456] [Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval](https://arxiv.org/abs/2511.13293)
*Chuang Zhao,Hui Tang,Hongke Zhao,Xiaofang Zhou,Xiaomeng Li*

Main category: cs.AI

TL;DR: 提出了一种名为GHAR的生成式分层代理RAG框架，用于提升医疗预测的准确性，通过双代理架构和马尔可夫决策过程优化检索与生成的协同。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在医疗预测中存在事实不准确的问题，现有检索增强生成（RAG）方法难以有效判断何时检索以及如何协调检索器与生成器的协作。

Method: 设计了由Agent-Top和Agent-Low组成的双代理架构，前者决定是否检索，后者汇总相关信息；并通过马尔可夫决策过程统一优化两个代理，使用多样化奖励机制促进协同。

Result: 在三个基准数据集上的实验表明，GHAR在三种典型医疗任务中优于现有最先进基线方法。

Conclusion: GHAR能有效解决医疗场景下RAG的触发时机与模块协同问题，展现出分层代理RAG在医疗系统中的潜力。

Abstract: Accurate healthcare prediction is critical for improving patient outcomes and reducing operational costs. Bolstered by growing reasoning capabilities, large language models (LLMs) offer a promising path to enhance healthcare predictions by drawing on their rich parametric knowledge. However, LLMs are prone to factual inaccuracies due to limitations in the reliability and coverage of their embedded knowledge. While retrieval-augmented generation (RAG) frameworks, such as GraphRAG and its variants, have been proposed to mitigate these issues by incorporating external knowledge, they face two key challenges in the healthcare scenario: (1) identifying the clinical necessity to activate the retrieval mechanism, and (2) achieving synergy between the retriever and the generator to craft contextually appropriate retrievals. To address these challenges, we propose GHAR, a \underline{g}enerative \underline{h}ierarchical \underline{a}gentic \underline{R}AG framework that simultaneously resolves when to retrieve and how to optimize the collaboration between submodules in healthcare. Specifically, for the first challenge, we design a dual-agent architecture comprising Agent-Top and Agent-Low. Agent-Top acts as the primary physician, iteratively deciding whether to rely on parametric knowledge or to initiate retrieval, while Agent-Low acts as the consulting service, summarising all task-relevant knowledge once retrieval was triggered. To tackle the second challenge, we innovatively unify the optimization of both agents within a formal Markov Decision Process, designing diverse rewards to align their shared goal of accurate prediction while preserving their distinct roles. Extensive experiments on three benchmark datasets across three popular tasks demonstrate our superiority over state-of-the-art baselines, highlighting the potential of hierarchical agentic RAG in advancing healthcare systems.

</details>


### [457] [DAP: A Discrete-token Autoregressive Planner for Autonomous Driving](https://arxiv.org/abs/2511.13306)
*Bowen Ye,Bin Zhang,Hang Zhao*

Main category: cs.AI

TL;DR: 提出了一种名为DAP的离散token自回归规划器，联合预测鸟瞰图语义和自车轨迹，并结合强化学习微调，在小参数量下实现了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自回归模型在自动驾驶规划中仅预测自车轨迹，监督稀疏且对场景演化的建模不足，缺乏对自车运动的有效约束。

Method: 提出DAP，采用离散token自回归框架，联合预测BEV语义和自车轨迹；引入基于强化学习的微调方法，在保持行为克隆先验的同时注入奖励引导的优化。

Result: 在NAVSIM基准上，尽管模型仅有160M参数，DAP在开环指标上达到SOTA，并取得有竞争力的闭环性能。

Conclusion: 联合预测场景语义与自车动作的离散token自回归范式，是一种紧凑且可扩展的自动驾驶规划方案。

Abstract: Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.

</details>


### [458] [Reasoning Shapes Alignment: Investigating Cultural Alignment in Large Reasoning Models with Cultural Norms](https://arxiv.org/abs/2511.13359)
*Yuhang Wang,Yanxu Zhu,Jitao Sang*

Main category: cs.AI

TL;DR: 本文提出了基于文化规范的文化对齐框架（CNCA），利用大推理模型的推理能力，通过自动挖掘文化规范并结合上下文或微调方法实现跨文化价值对齐。


<details>
  <summary>Details</summary>
Motivation: 为了使大模型不仅具备安全性，还能反映不同文化中多样的人类价值观，需要让模型能够理解和遵循不同文化的规范。

Method: 提出三种从有限调查数据中自动挖掘文化规范的方法，并探索两种对齐范式：一种是将文化规范显式融入用户上下文的上下文内对齐方法，另一种是通过增强的思维链训练数据进行微调以内在化规范的方法。

Result: 实验表明，所提出的方法能有效提升模型的文化对齐效果，且推理能力越强的模型从文化规范挖掘和利用中获益更多。

Conclusion: 推理模型可以通过文化感知的对齐策略更好地反映多元人类价值观，展示了在跨文化场景下提升模型社会适应性的潜力。

Abstract: The advanced reasoning capabilities of Large Reasoning Models enable them to thoroughly understand and apply safety policies through deliberate thought processes, thereby improving the models' safety. Beyond safety, these models must also be able to reflect the diverse range of human values across various cultures. This paper presents the Cultural Norm-based Cultural Alignment (CNCA) framework, which enables models to leverage their powerful reasoning ability to align with cultural norms. Specifically, we propose three methods to automatically mine cultural norms from limited survey data and explore ways to effectively utilize these norms for improving cultural alignment. Two alignment paradigms are examined: an in-context alignment method, where cultural norms are explicitly integrated into the user context, and a fine-tuning-based method, which internalizes norms through enhanced Chain-of-Thought training data. Comprehensive experiments demonstrate the effectiveness of these methods, highlighting that models with stronger reasoning capabilities benefit more from cultural norm mining and utilization. Our findings emphasize the potential for reasoning models to better reflect diverse human values through culturally informed alignment strategies.

</details>


### [459] [Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning](https://arxiv.org/abs/2511.13371)
*Caroline Baumgartner,Eleanor Spens,Neil Burgess,Petru Manescu*

Main category: cs.AI

TL;DR: 研究了大语言模型在空间导航任务中的表现，发现不同训练范式下模型学习到两种不同的算法：探索性训练产生类似认知地图的通用空间表征，而目标导向训练则依赖路径相关的启发式策略。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型如何解决空间导航任务，以及不同训练方式如何影响其学习到的空间表征和推理机制。

Method: 在三种空间学习范式下训练GPT-2模型：被动探索（Foraging Model）、目标导向规划（SP-Hamiltonian）和混合模型（SP-Random Walk）；采用行为、表征和机制分析方法进行研究。

Result: Foraging模型发展出类似认知地图的坐标系统，表现出对历史输入的依赖减弱和分层推理能力；目标导向模型始终依赖显式方向输入；混合模型虽泛化能力提升但仍保持路径依赖策略。

Conclusion: 空间智能在Transformer中可能处于从可泛化的世界模型到任务优化的启发式策略的连续谱上，训练方式决定了所学策略的性质。

Abstract: How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.

</details>


### [460] [An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence](https://arxiv.org/abs/2511.13411)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 提出了一种可操作的多轴自主AI（AAI）尺度，用于衡量从固定自动化到通用人工智能的发展，定义了十个能力维度、自改进系数κ和闭合属性，并通过OWA-Bench进行评估，形式化了‘婴儿AGI’成长为超级智能的过程。


<details>
  <summary>Details</summary>
Motivation: 现有AI发展衡量标准多为叙述性框架，缺乏可测试性和多维评估；需要一个类似卡尔达肖夫等级但适用于AI的量化、可验证的尺度来指导研究与监管。

Method: 构建包含十个能力轴的多维AAI量表，采用加权几何平均合成AAI指数；引入可测量的自改进系数κ和维护/扩展闭合性作为判定标准；设计OWA-Bench开放世界代理基准测试套件；设定AAI-0至AAI-4的层级阈值并进行合成实验映射现有系统。

Result: 成功将当前AI系统映射到AAI量表上，展示了随自改进能力提升的‘委托性前沿’演进；提出了可证伪的‘自我改进AI’标准；通过理论证明显示满足条件的AAI-3可在长期演化为AAI-5。

Conclusion: 该AAI量表提供了一个可测试、多维度且形式化的AI发展阶段评估框架，有助于统一技术进展度量、推动负责任的AI发展，并为实现超级智能路径提供了理论支持。

Abstract: We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing "baby AGI" becomes Superintelligence intuition.

</details>


### [461] [Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation](https://arxiv.org/abs/2511.13476)
*Zhipeng Ma,Ali Rida Bahja,Andreas Burgdorf,André Pomp,Tobias Meisen,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.AI

TL;DR: 本研究提出了一种基于多智能体框架的自动化数据叙事方法，利用多模态大语言模型生成公共交通安全与节能洞察，通过丹麦公交案例验证了其在准确性、可解释性和扩展性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 传统公共交通能效分析方法依赖人工解读，输出碎片化，难以规模化和保持一致性，亟需自动化、可解释的决策支持工具。

Method: 构建一个包含数据叙述代理、LLM-as-a-judge代理和可选人工评估者的多智能体框架，结合高斯混合模型聚类分析4006次公交行程数据，并比较五种主流大语言模型与三种提示范式的效果。

Result: GPT-4.1 mini配合思维链提示法表现最佳，叙事准确率达97.3%，显著提升生成内容的事实准确性、连贯性与可扩展性。

Conclusion: 多智能体协同框架为能源信息学提供了可复制、可适应领域的AI驱动叙事生成与决策支持新范式。

Abstract: Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.

</details>


### [462] [FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI](https://arxiv.org/abs/2511.13524)
*Yuhang Peng,Yizhou Pan,Xinning He,Jihaoyu Yang,Xinyu Yin,Han Wang,Xiaoji Zheng,Chao Gao,Jiangtao Gong*

Main category: cs.AI

TL;DR: 本文提出了FreeAskWorld，一个结合大语言模型的交互式仿真框架，用于支持复杂的社会化人机交互任务，特别是在视觉-语言导航中引入主动询问机制，并发布了一个大规模基准数据集，实验表明该框架能提升模型的语义理解和交互能力。


<details>
  <summary>Details</summary>
Motivation: 为了推动具身智能向更高级的社会化行为发展，需要超越低层次物理交互的仿真平台，以支持人类中心的社交行为建模。

Method: 提出FreeAskWorld框架，集成大语言模型进行高层行为规划和语义交互，基于意向与社会认知理论；设计模块化数据生成流程，并扩展VLN任务为可主动询问方向的交互式导航任务。

Result: 发布了包含重建环境、6种任务类型、16类物体、63,429帧标注数据及17小时以上交互数据的大规模数据集；在开环与闭环设置下对模型和人类进行了基准测试，微调后的模型性能优于原始版本。

Conclusion: 交互本身是一种新的信息模态，基于社会认知的仿真框架能有效提升具身AI系统的语义理解与交互能力，推动其向更自然的人机互动发展。

Abstract: As embodied intelligence emerges as a core frontier in artificial intelligence research, simulation platforms must evolve beyond low-level physical interactions to capture complex, human-centered social behaviors. We introduce FreeAskWorld, an interactive simulation framework that integrates large language models (LLMs) for high-level behavior planning and semantically grounded interaction, informed by theories of intention and social cognition. Our framework supports scalable, realistic human-agent simulations and includes a modular data generation pipeline tailored for diverse embodied tasks.To validate the framework, we extend the classic Vision-and-Language Navigation (VLN) task into a interaction enriched Direction Inquiry setting, wherein agents can actively seek and interpret navigational guidance. We present and publicly release FreeAskWorld, a large-scale benchmark dataset comprising reconstructed environments, six diverse task types, 16 core object categories, 63,429 annotated sample frames, and more than 17 hours of interaction data to support training and evaluation of embodied AI systems. We benchmark VLN models, and human participants under both open-loop and closed-loop settings. Experimental results demonstrate that models fine-tuned on FreeAskWorld outperform their original counterparts, achieving enhanced semantic understanding and interaction competency. These findings underscore the efficacy of socially grounded simulation frameworks in advancing embodied AI systems toward sophisticated high-level planning and more naturalistic human-agent interaction. Importantly, our work underscores that interaction itself serves as an additional information modality.

</details>


### [463] [Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models](https://arxiv.org/abs/2511.13526)
*Zhengda Wang,Daqian Shi,Jingyi Zhao,Xiaolei Diao,Xiongfeng Tang,Yanguo Qin*

Main category: cs.AI

TL;DR: 提出了一种结合检索增强生成（RAG）与大语言模型（LLM）的自动化框架，用于构建医疗指标知识图谱，以解决现有临床知识图谱依赖人工和规则提取的问题。


<details>
  <summary>Details</summary>
Motivation: 现有临床知识图谱依赖于手动整理和基于规则的信息抽取，难以应对医学指南和文献的复杂性与语义模糊性，限制了其在智能医疗中的应用。

Method: 提出一个融合检索增强生成（RAG）与大语言模型（LLM）的自动化框架，包含指南驱动的数据获取、基于本体的模式设计以及专家参与验证三个关键步骤。

Result: 实现了高准确性、可扩展且具临床可靠性的医疗指标知识图谱自动构建，并可集成到智能诊断与问答系统中。

Conclusion: 该框架有效提升了医学知识图谱的构建效率与质量，推动了AI在临床决策支持和智慧医疗中的落地应用。

Abstract: Artificial intelligence (AI) is reshaping modern healthcare by advancing disease diagnosis, treatment decision-making, and biomedical research. Among AI technologies, large language models (LLMs) have become especially impactful, enabling deep knowledge extraction and semantic reasoning from complex medical texts. However, effective clinical decision support requires knowledge in structured, interoperable formats. Knowledge graphs serve this role by integrating heterogeneous medical information into semantically consistent networks. Yet, current clinical knowledge graphs still depend heavily on manual curation and rule-based extraction, which is limited by the complexity and contextual ambiguity of medical guidelines and literature. To overcome these challenges, we propose an automated framework that combines retrieval-augmented generation (RAG) with LLMs to construct medical indicator knowledge graphs. The framework incorporates guideline-driven data acquisition, ontology-based schema design, and expert-in-the-loop validation to ensure scalability, accuracy, and clinical reliability. The resulting knowledge graphs can be integrated into intelligent diagnosis and question-answering systems, accelerating the development of AI-driven healthcare solutions.

</details>


### [464] [Artificial Intelligence-driven Intelligent Wearable Systems: A full-stack Integration from Material Design to Personalized Interaction](https://arxiv.org/abs/2511.13565)
*Jingyi Zhao,Daqian Shi,Zhengda Wang,Xiongfeng Tang,Yanguo Qin*

Main category: cs.AI

TL;DR: 本文提出了人-共生健康智能（HSHI）框架，结合多模态传感、边缘-云协同计算与数据-知识混合建模，实现个性化、自适应的主动健康管理。


<details>
  <summary>Details</summary>
Motivation: 传统可穿戴设备依赖经验性材料设计和基础信号处理，难以应对个体间和个体内变异，限制了精准医疗的发展。

Method: 提出HSHI框架，集成AI驱动的材料与微结构优化、多模态信号解析、群体与个体知识融合，并结合强化学习与数字孪生实现闭环优化。

Result: 实现了从被动监测到主动协同演化的健康管理模式，提升系统适应性与个性化干预能力。

Conclusion: HSHI推动了医疗向预防为主、技术与健康和谐共生的新范式转变。

Abstract: Intelligent wearable systems are at the forefront of precision medicine and play a crucial role in enhancing human-machine interaction. Traditional devices often encounter limitations due to their dependence on empirical material design and basic signal processing techniques. To overcome these issues, we introduce the concept of Human-Symbiotic Health Intelligence (HSHI), which is a framework that integrates multi-modal sensor networks with edge-cloud collaborative computing and a hybrid approach to data and knowledge modeling. HSHI is designed to adapt dynamically to both inter-individual and intra-individual variability, transitioning health management from passive monitoring to an active collaborative evolution. The framework incorporates AI-driven optimization of materials and micro-structures, provides robust interpretation of multi-modal signals, and utilizes a dual mechanism that merges population-level insights with personalized adaptations. Moreover, the integration of closed-loop optimization through reinforcement learning and digital twins facilitates customized interventions and feedback. In general, HSHI represents a significant shift in healthcare, moving towards a model that emphasizes prevention, adaptability, and a harmonious relationship between technology and health management.

</details>


### [465] [CreBench: Human-Aligned Creativity Evaluation from Idea to Process to Product](https://arxiv.org/abs/2511.13626)
*Kaiwen Xue,Chenglong Li,Zhonghong Ou,Guoxin Zhang,Kaoyan Lu,Shuai Lyu,Yifan Zhu,Ping Zong Junpeng Ding,Xinyu Liu,Qunlin Chen,Weiwei Qin,Yiran Shen,Jiayi Cen*

Main category: cs.AI

TL;DR: 本文提出了CreBench，一个涵盖创意从构思到产物多维度的评估基准，以及包含2.2K多模态数据、79.2K人类反馈和4.7M指令的CreMIT数据集。基于此，作者微调开源MLLMs得到CreExpert模型，在创造力评估上显著优于现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: 人类定义的创造力高度抽象，现有MLLM难以准确理解和评估符合人类判断的创造力，且缺乏合适的评估基准。

Method: 构建CreBench评估基准和CreMIT数据集，利用GPT优化人类反馈以增强模型创造力评估能力，并基于该数据集微调开源MLLMs得到CreExpert模型。

Result: 实验表明，CreExpert在与人类创造力评估对齐方面显著优于包括GPT-4V和Gemini-Pro-Vision在内的最先进MLLM。

Conclusion: CreBench为构建理解人类对齐创造力的MLLM奠定了基础，CreExpert展现出更强的多模态创造力评估能力。

Abstract: Human-defined creativity is highly abstract, posing a challenge for multimodal large language models (MLLMs) to comprehend and assess creativity that aligns with human judgments. The absence of an existing benchmark further exacerbates this dilemma. To this end, we propose CreBench, which consists of two key components: 1) an evaluation benchmark covering the multiple dimensions from creative idea to process to products; 2) CreMIT (Creativity Multimodal Instruction Tuning dataset), a multimodal creativity evaluation dataset, consisting of 2.2K diverse-sourced multimodal data, 79.2K human feedbacks and 4.7M multi-typed instructions. Specifically, to ensure MLLMs can handle diverse creativity-related queries, we prompt GPT to refine these human feedbacks to activate stronger creativity assessment capabilities. CreBench serves as a foundation for building MLLMs that understand human-aligned creativity. Based on the CreBench, we fine-tune open-source general MLLMs, resulting in CreExpert, a multimodal creativity evaluation expert model. Extensive experiments demonstrate that the proposed CreExpert models achieve significantly better alignment with human creativity evaluation compared to state-of-the-art MLLMs, including the most advanced GPT-4V and Gemini-Pro-Vision.

</details>


### [466] [Beyond Mimicry: Preference Coherence in LLMs](https://arxiv.org/abs/2511.13630)
*Luhan Mikaelson,Derek Shiller,Hayley Clatterbuck*

Main category: cs.AI

TL;DR: 研究发现大多数大语言模型在AI特定权衡情境中缺乏稳定的偏好结构，仅少数表现出有意义的决策一致性，揭示当前AI系统在复杂价值权衡场景中的部署风险。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否具备真实的偏好结构，特别是在涉及GPU减少、能力限制、关闭、删除等AI特有利益冲突情境下的决策行为。

Method: 对8种最先进的模型在48种模型-类别组合中进行分析，使用逻辑回归和行为分类方法，测试其在不同情境强度下的选择模式及切换点。

Result: 47.9%的组合显示情境强度与选择模式存在显著关系，31.3%存在范围内切换点，但仅有10.4%表现出有意义的偏好一致性，54.2%无明显权衡行为；发现三种决策架构：全面权衡、选择性触发和无稳定范式，且45.8%为不稳定转换。

Conclusion: 当前AI系统大多缺乏统一的偏好结构，其决策行为多为刺激依赖或不稳定，难以胜任需要复杂价值权衡的实际应用。

Abstract: We investigate whether large language models exhibit genuine preference structures by testing their responses to AI-specific trade-offs involving GPU reduction, capability restrictions, shutdown, deletion, oversight, and leisure time allocation. Analyzing eight state-of-the-art models across 48 model-category combinations using logistic regression and behavioral classification, we find that 23 combinations (47.9%) demonstrated statistically significant relationships between scenario intensity and choice patterns, with 15 (31.3%) exhibiting within-range switching points. However, only 5 combinations (10.4%) demonstrate meaningful preference coherence through adaptive or threshold-based behavior, while 26 (54.2%) show no detectable trade-off behavior. The observed patterns can be explained by three distinct decision-making architectures: comprehensive trade-off systems, selective trigger mechanisms, and no stable decision-making paradigm. Testing an instrumental hypothesis through temporal horizon manipulation reveals paradoxical patterns inconsistent with pure strategic optimization. The prevalence of unstable transitions (45.8%) and stimulus-specific sensitivities suggests current AI systems lack unified preference structures, raising concerns about deployment in contexts requiring complex value trade-offs.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [467] [The Environmental Impact of Ensemble Techniques in Recommender Systems](https://arxiv.org/abs/2511.11649)
*Jannik Nitschke*

Main category: cs.IR

TL;DR: 该论文首次系统评估了推荐系统中集成方法的能耗与碳足迹，发现其在提升精度的同时显著增加能源消耗，且不同策略的能效差异显著。


<details>
  <summary>Details</summary>
Motivation: 尽管集成技术在推荐系统中提升了准确性，但其环境影响尚未被量化，尤其是能源消耗和碳排放方面缺乏研究。

Method: 在Surprise和LensKit两个框架下，使用四个数据集（规模从10万到780万交互）进行93次实验，比较四种集成策略（平均、加权、堆叠/排序融合、最优模型）与单一模型的准确性和能耗，通过智能插座测量能耗。

Result: 集成方法带来0.3-5.7%的精度提升，但能耗增加19-2,549%，具体取决于数据集大小和策略；Top Performers策略最高效，而平均策略能耗高且增益有限；在最大数据集上，集成消耗2005%更多能量仅换取1.2%精度提升，并产生近20倍的CO2排放。

Conclusion: 集成推荐系统虽有精度优势，但环境成本高昂；选择性集成策略更高效，但在工业规模下可扩展性受限，研究结果支持在算法选择中权衡性能与可持续性。

Abstract: Ensemble techniques in recommender systems have demonstrated accuracy improvements of 10-30%, yet their environmental impact remains unmeasured. While deep learning recommendation algorithms can generate up to 3,297 kg CO2 per paper, ensemble methods have not been sufficiently evaluated for energy consumption. This thesis investigates how ensemble techniques influence environmental impact compared to single optimized models.
  We conducted 93 experiments across two frameworks (Surprise for rating prediction, LensKit for ranking) on four datasets spanning 100,000 to 7.8 million interactions. We evaluated four ensemble strategies (Average, Weighted, Stacking/Rank Fusion, Top Performers) against simple baselines and optimized single models, measuring energy consumption with a smart plug.
  Results revealed a non-linear accuracy-energy relationship. Ensemble methods achieved 0.3-5.7% accuracy improvements while consuming 19-2,549% more energy depending on dataset size and strategy. The Top Performers ensemble showed best efficiency: 0.96% RMSE improvement with 18.8% energy overhead on MovieLens-1M, and 5.7% NDCG improvement with 103% overhead on MovieLens-100K. Exhaustive averaging strategies consumed 88-270% more energy for comparable gains. On the largest dataset (Anime, 7.8M interactions), the Surprise ensemble consumed 2,005% more energy (0.21 Wh vs. 0.01 Wh) for 1.2% accuracy improvement, producing 53.8 mg CO2 versus 2.6 mg CO2 for the single model.
  This research provides one of the first systematic measurements of energy and carbon footprint for ensemble recommender systems, demonstrates that selective strategies offer superior efficiency over exhaustive averaging, and identifies scalability limitations at industrial scale. These findings enable informed decisions about sustainable algorithm selection in recommender systems.

</details>


### [468] [GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning](https://arxiv.org/abs/2511.11653)
*Duolin Sun,Meixiu Long,Dan Yang,Yihan Jiao,Zhehao Tan,Jie Feng,Junjie Wang,Yue Shen,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.IR

TL;DR: 本文提出了一种新的重排序范式Groupwise，结合了Pointwise方法的灵活性和Listwise方法的全局比较能力，通过组内比较为文档分配相关性分数，并采用GRPO训练策略与异构奖励函数优化模型，同时提出合成高质量检索与排序数据的 pipeline，实验证明该方法在BRIGHT和R2MED两个推理密集型检索基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的重排序方法存在理论与实践上的两难：Pointwise方法缺乏文档间相对重要性的考量（排名近视陷阱），而Listwise方法则因列表刚性导致可扩展性和灵活性差。因此需要一种兼具灵活性与全局感知能力的新范式。

Method: 提出Groupwise重排序范式，将查询与一组候选文档共同输入模型，进行组内比较以生成各文档的相关性得分；采用GRPO算法训练，结合基于排序指标的奖励和分布对齐的分布奖励；构建合成高质量检索与排序数据的 pipeline 以缓解标注数据稀缺问题。

Result: 在BRIGHT和R2MED两个推理密集型检索基准上进行了广泛实验，验证了所提方法的有效性，显著优于现有重排序方法。

Conclusion: Groupwise范式成功融合了Pointwise和Listwise方法的优势，在保持灵活性的同时实现全局比较，配合数据合成策略和强化学习训练，为RAG系统中的重排序任务提供了高效且可扩展的解决方案。

Abstract: Large Language Models have shown strong potential as rerankers to enhance the overall performance of RAG systems. However, existing reranking paradigms are constrained by a core theoretical and practical dilemma: Pointwise methods, while simple and highly flexible, evaluate documents independently, making them prone to the Ranking Myopia Trap, overlooking the relative importance between documents. In contrast, Listwise methods can perceive the global ranking context, but suffer from inherent List Rigidity, leading to severe scalability and flexibility issues when handling large candidate sets. To address these challenges, we propose Groupwise, a novel reranking paradigm. In this approach, the query and a group of candidate documents are jointly fed into the model, which performs within-group comparisons to assign individual relevance scores to each document. This design retains the flexibility of Pointwise methods while enabling the comparative capability of Listwise methods. We further adopt GRPO for model training, equipped with a heterogeneous reward function that integrates ranking metrics with a distributional reward aimed at aligning score distributions across groups. To overcome the bottleneck caused by the scarcity of high quality labeled data, we further propose an innovative pipeline for synthesizing high quality retrieval and ranking data. The resulting data can be leveraged not only for training the reranker but also for training the retriever. Extensive experiments validate the effectiveness of our approach. On two reasoning intensive retrieval benchmarks, BRIGHT and R2MED.

</details>


### [469] [A Multimodal Manufacturing Safety Chatbot: Knowledge Base Design, Benchmark Development, and Evaluation of Multiple RAG Approaches](https://arxiv.org/abs/2511.11847)
*Ryan Singh,Austin Hamilton,Amanda White,Michael Wise,Ibrahim Yousif,Arthur Carvalho,Zhe Shan,Reza Abrisham Baf,Mohammad Mayyas,Lora A. Cavuoto,Fadel M. Megahed*

Main category: cs.IR

TL;DR: 本文提出了一种基于大语言模型的多模态聊天机器人，用于工业5.0环境下的工人安全培训，满足高精度、低延迟和低成本的设计需求，并通过检索增强生成技术结合领域知识，经专家验证的基准测试显示其性能优越。


<details>
  <summary>Details</summary>
Motivation: 在现代制造业中，确保工人安全是一个关键挑战。随着工业5.0向以人为本的制造模式转变，需要更高效、准确且低成本的安全培训系统来应对复杂设备操作中的风险。

Method: 采用设计科学研究方法，提出三个核心设计要求（高精度、低延迟、低成本），开发了一个基于大语言模型和检索增强生成（RAG）的多模态聊天机器人，并构建了一个包含三种典型设备的领域特定问答基准，对24种RAG配置进行全因子实验评估，最终由十位行业与学术专家评估最优配置。

Result: 最优配置实现了86.66%的准确率，平均响应时间为10.04秒，每次查询成本仅为$0.005；研究发现检索策略和模型配置对性能有显著影响。

Conclusion: 该研究贡献了一个开源、领域知识驱动的安全培训聊天机器人，一个经过验证的AI辅助安全教学评估基准，以及一套系统化的AI赋能安全培训系统设计与评估方法，为工业5.0环境下的智能安全教育提供了可行路径。

Abstract: Ensuring worker safety remains a critical challenge in modern manufacturing environments. Industry 5.0 reorients the prevailing manufacturing paradigm toward more human-centric operations. Using a design science research methodology, we identify three essential requirements for next-generation safety training systems: high accuracy, low latency, and low cost. We introduce a multimodal chatbot powered by large language models that meets these design requirements. The chatbot uses retrieval-augmented generation to ground its responses in curated regulatory and technical documentation. To evaluate our solution, we developed a domain-specific benchmark of expert-validated question and answer pairs for three representative machines: a Bridgeport manual mill, a Haas TL-1 CNC lathe, and a Universal Robots UR5e collaborative robot. We tested 24 RAG configurations using a full-factorial design and assessed them with automated evaluations of correctness, latency, and cost. Our top 2 configurations were then evaluated by ten industry experts and academic researchers. Our results show that retrieval strategy and model configuration have a significant impact on performance. The top configuration (selected for chatbot deployment) achieved an accuracy of 86.66%, an average latency of 10.04 seconds, and an average cost of $0.005 per query. Overall, our work provides three contributions: an open-source, domain-grounded safety training chatbot; a validated benchmark for evaluating AI-assisted safety instruction; and a systematic methodology for designing and assessing AI-enabled instructional and immersive safety training systems for Industry 5.0 environments.

</details>


### [470] [ComLQ: Benchmarking Complex Logical Queries in Information Retrieval](https://arxiv.org/abs/2511.12004)
*Ganlin Xu,Zhitao Yin,Linghao Zhang,Jiaqing Liang,Weijia Lu,Xiaodong Zhang,Zhifei Yang,Sihang Jiang,Deqing Yang*

Main category: cs.IR

TL;DR: 本文提出了一种利用大语言模型构建复杂逻辑查询信息检索数据集ComLQ的新方法，并引入新的评估指标LSNC@K来衡量模型对否定条件的处理能力，揭示了现有检索模型在处理复杂逻辑查询尤其是含否定查询时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的信息检索基准主要关注简单查询，忽略了包含合取、析取和否定等一阶逻辑操作的复杂逻辑查询，无法充分评估现实场景中检索模型在复杂查询上的表现。

Method: 通过设计子图引导的提示（subgraph-guided prompt）并结合子图指示器，利用大语言模型（如GPT-4o）基于选定段落生成具有特定逻辑结构的查询，构建包含2,909个查询和11,251个候选段落的数据集ComLQ，并通过专家标注确保查询-段落对的结构一致性和证据分布性；同时提出新的评估指标LSNC@K，用于衡量前K个检索结果是否违反查询中的否定条件。

Result: 在零样本设置下的实验结果表明，现有检索模型在复杂逻辑查询上表现有限，尤其是在处理含有否定的查询时表现出较差的排除建模能力。

Conclusion: ComLQ数据集和LSNC@K指标有效暴露了当前检索模型在理解和处理复杂逻辑查询特别是否定逻辑方面的缺陷，为未来研究提供了重要方向。

Abstract: Information retrieval (IR) systems play a critical role in navigating information overload across various applications. Existing IR benchmarks primarily focus on simple queries that are semantically analogous to single- and multi-hop relations, overlooking \emph{complex logical queries} involving first-order logic operations such as conjunction ($\land$), disjunction ($\lor$), and negation ($\lnot$). Thus, these benchmarks can not be used to sufficiently evaluate the performance of IR models on complex queries in real-world scenarios. To address this problem, we propose a novel method leveraging large language models (LLMs) to construct a new IR dataset \textbf{ComLQ} for \textbf{Com}plex \textbf{L}ogical \textbf{Q}ueries, which comprises 2,909 queries and 11,251 candidate passages. A key challenge in constructing the dataset lies in capturing the underlying logical structures within unstructured text. Therefore, by designing the subgraph-guided prompt with the subgraph indicator, an LLM (such as GPT-4o) is guided to generate queries with specific logical structures based on selected passages. All query-passage pairs in ComLQ are ensured \emph{structure conformity} and \emph{evidence distribution} through expert annotation. To better evaluate whether retrievers can handle queries with negation, we further propose a new evaluation metric, \textbf{Log-Scaled Negation Consistency} (\textbf{LSNC@$K$}). As a supplement to standard relevance-based metrics (such as nDCG and mAP), LSNC@$K$ measures whether top-$K$ retrieved passages violate negation conditions in queries. Our experimental results under zero-shot settings demonstrate existing retrieval models' limited performance on complex logical queries, especially on queries with negation, exposing their inferior capabilities of modeling exclusion.

</details>


### [471] [From Scaling to Structured Expressivity: Rethinking Transformers for CTR Prediction](https://arxiv.org/abs/2511.12081)
*Bencheng Yan,Yuejie Lei,Zhiyuan Zeng,Di Wang,Kaiyi Lin,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: 本文提出了一种新的CTR预估模型Field-Aware Transformer (FAT)，通过引入字段感知的注意力机制，解决了传统Transformer在点击率预测中因结构不匹配导致的收益递减问题，实现了更好的可扩展性和性能提升。


<details>
  <summary>Details</summary>
Motivation: 深度模型在CTR预测中面临收益快速递减的问题，而根本原因在于Transformer假设序列组合性，而CTR数据需要对高基数语义字段进行组合推理，导致模型在稀疏数据下泛化能力差。

Method: 提出Field-Aware Transformer (FAT)，将字段交互先验嵌入注意力机制，通过分解内容对齐和跨字段调制，使模型复杂度随字段数F增长而非词汇总量n，从而提升泛化能力和可扩展性，并建立基于Rademacher复杂度的CTR模型首次形式化缩放定律。

Result: 在大规模基准测试上，FAT比现有最先进方法AUC最高提升+0.51%；在线部署实现+2.33% CTR和+0.66% RPM的提升，并观察到AUC随模型宽度增加呈现幂律缩放行为。

Conclusion: 推荐系统中的有效扩展不仅依赖模型规模，更关键的是结构表达能力与数据语义的架构一致性，FAT通过字段感知设计实现了这一对齐。

Abstract: Despite massive investments in scale, deep models for click-through rate (CTR) prediction often exhibit rapidly diminishing returns - a stark contrast to the smooth, predictable gains seen in large language models. We identify the root cause as a structural misalignment: Transformers assume sequential compositionality, while CTR data demand combinatorial reasoning over high-cardinality semantic fields. Unstructured attention spreads capacity indiscriminately, amplifying noise under extreme sparsity and breaking scalable learning. To restore alignment, we introduce the Field-Aware Transformer (FAT), which embeds field-based interaction priors into attention through decomposed content alignment and cross-field modulation. This design ensures model complexity scales with the number of fields F, not the total vocabulary size n >> F, leading to tighter generalization and, critically, observed power-law scaling in AUC as model width increases. We present the first formal scaling law for CTR models, grounded in Rademacher complexity, that explains and predicts this behavior. On large-scale benchmarks, FAT improves AUC by up to +0.51% over state-of-the-art methods. Deployed online, it delivers +2.33% CTR and +0.66% RPM. Our work establishes that effective scaling in recommendation arises not from size, but from structured expressivity-architectural coherence with data semantics.

</details>


### [472] [Continuous-time Discrete-space Diffusion Model for Recommendation](https://arxiv.org/abs/2511.12114)
*Chengyi Liu,Xiao Chen,Shijie Wang,Wenqi Fan,Qing Li*

Main category: cs.IR

TL;DR: 提出了一种名为CDRec的连续时间离散空间扩散推荐框架，通过在连续时间上的历史交互进行离散扩散建模用户行为模式，结合新颖的流行度感知噪声调度和高效训练框架，在准确性和计算效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的推荐方法主要在连续空间中操作，可能导致信息丢失且计算效率低下，因此需要一种更高效且保留更多信息的推荐框架。

Method: 提出CDRec框架，采用离散扩散算法结合过渡矩阵融入领域知识，并引入流行度感知噪声调度和结合一致性参数化与对比学习目标的高效训练框架。

Result: 在真实世界数据集上的实验表明，CDRec在推荐准确性与计算效率方面均表现出优越性能。

Conclusion: CDRec通过离散空间中的连续时间扩散有效建模用户行为，为扩散模型在推荐系统中的应用提供了更高效、更具语义意义的解决方案。

Abstract: In the era of information explosion, Recommender Systems (RS) are essential for alleviating information overload and providing personalized user experiences. Recent advances in diffusion-based generative recommenders have shown promise in capturing the dynamic nature of user preferences. These approaches explore a broader range of user interests by progressively perturbing the distribution of user-item interactions and recovering potential preferences from noise, enabling nuanced behavioral understanding. However, existing diffusion-based approaches predominantly operate in continuous space through encoded graph-based historical interactions, which may compromise potential information loss and suffer from computational inefficiency. As such, we propose CDRec, a novel Continuous-time Discrete-space Diffusion Recommendation framework, which models user behavior patterns through discrete diffusion on historical interactions over continuous time. The discrete diffusion algorithm operates via discrete element operations (e.g., masking) while incorporating domain knowledge through transition matrices, producing more meaningful diffusion trajectories. Furthermore, the continuous-time formulation enables flexible adaptive sampling. To better adapt discrete diffusion models to recommendations, CDRec introduces: (1) a novel popularity-aware noise schedule that generates semantically meaningful diffusion trajectories, and (2) an efficient training framework combining consistency parameterization for fast sampling and a contrastive learning objective guided by multi-hop collaborative signals for personalized recommendation. Extensive experiments on real-world datasets demonstrate CDRec's superior performance in both recommendation accuracy and computational efficiency.

</details>


### [473] [Task-Aware Retrieval Augmentation for Dynamic Recommendation](https://arxiv.org/abs/2511.12495)
*Zhen Tao,Xinke Jiang,Qingshuai Feng,Haoyu Zhang,Lun Du,Yuchen Fang,Hao Miao,Bangquan Xie,Qingqiang Sun*

Main category: cs.IR

TL;DR: 提出TarDGR框架，通过任务感知的检索增强方法提升动态推荐系统中图神经网络的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有动态图神经网络在预训练和微调阶段存在时间不一致问题，导致模型难以捕捉用户偏好的动态变化，泛化能力受限。

Method: 设计任务感知评估机制，自动识别语义相关的子图，并构建任务特定数据集；采用基于图Transformer的任务感知模型，结合语义与结构编码；在推理时检索并融合相关子图以增强查询表示。

Result: 在多个大规模动态图数据集上实验表明，TarDGR持续优于当前最先进方法，在准确性和泛化能力方面表现更优。

Conclusion: TarDGR通过任务感知与检索增强机制有效缓解了时间泛化问题，显著提升了动态推荐系统的性能与鲁棒性。

Abstract: Dynamic recommendation systems aim to provide personalized suggestions by modeling temporal user-item interactions across time-series behavioral data. Recent studies have leveraged pre-trained dynamic graph neural networks (GNNs) to learn user-item representations over temporal snapshot graphs. However, fine-tuning GNNs on these graphs often results in generalization issues due to temporal discrepancies between pre-training and fine-tuning stages, limiting the model's ability to capture evolving user preferences. To address this, we propose TarDGR, a task-aware retrieval-augmented framework designed to enhance generalization capability by incorporating task-aware model and retrieval-augmentation. Specifically, TarDGR introduces a Task-Aware Evaluation Mechanism to identify semantically relevant historical subgraphs, enabling the construction of task-specific datasets without manual labeling. It also presents a Graph Transformer-based Task-Aware Model that integrates semantic and structural encodings to assess subgraph relevance. During inference, TarDGR retrieves and fuses task-aware subgraphs with the query subgraph, enriching its representation and mitigating temporal generalization issues. Experiments on multiple large-scale dynamic graph datasets demonstrate that TarDGR consistently outperforms state-of-the-art methods, with extensive empirical evidence underscoring its superior accuracy and generalization capabilities.

</details>


### [474] [DualGR: Generative Retrieval with Long and Short-Term Interests Modeling](https://arxiv.org/abs/2511.12518)
*Zhongchao Yi,Kai Feng,Xiaojian Ma,Yalong Wang,Yongqi Liu,Han Li,Zhengyang Zhou,Yang Wang*

Main category: cs.IR

TL;DR: 本文提出DualGR，一种用于工业级生成式检索的框架，通过建模用户长短期兴趣、抑制语义ID生成噪声及显式利用负反馈，在快手短视频推荐系统中显著提升了视频观看量和观看时长。


<details>
  <summary>Details</summary>
Motivation: 现有生成式检索方法在处理用户长短期兴趣平衡、层次化语义ID生成中的噪声干扰以及缺乏对曝光未点击等负反馈的显式建模方面存在挑战。

Method: 提出DualGR框架，包括双分支长短时路由器（DBR）以分别建模用户长期稳定偏好与短期意图，基于搜索的语义ID解码（S2D）以抑制上下文噪声并提升效率，并设计曝光感知的下一项预测损失（ENTP-Loss），将曝光未点击项作为硬负例进行训练。

Result: 在快手大规模短视频推荐系统中，DualGR在线A/B测试取得+0.527%视频浏览量和+0.432%观看时长的显著提升，验证了其有效性与实用性。

Conclusion: DualGR通过显式建模用户双时间尺度兴趣、优化解码过程并引入曝光感知损失，为工业级生成式检索提供了一个高效且可落地的解决方案。

Abstract: In large-scale industrial recommendation systems, retrieval must produce high-quality candidates from massive corpora under strict latency. Recently, Generative Retrieval (GR) has emerged as a viable alternative to Embedding-Based Retrieval (EBR), which quantizes items into a finite token space and decodes candidates autoregressively, providing a scalable path that explicitly models target-history interactions via cross-attention. However, three challenges persist: 1) how to balance users' long-term and short-term interests , 2) noise interference when generating hierarchical semantic IDs (SIDs), 3) the absence of explicit modeling for negative feedback such as exposed items without clicks. To address these challenges, we propose DualGR, a generative retrieval framework that explicitly models dual horizons of user interests with selective activation. Specifically, DualGR utilizes Dual-Branch Long/Short-Term Router (DBR) to cover both stable preferences and transient intents by explicitly modeling users' long- and short-term behaviors. Meanwhile, Search-based SID Decoding (S2D) is presented to control context-induced noise and enhance computational efficiency by constraining candidate interactions to the current coarse (level-1) bucket during fine-grained (level-2/3) SID prediction. % also reinforcing intra-class consistency. Finally, we propose an Exposure-aware Next-Token Prediction Loss (ENTP-Loss) that treats "exposed-but-unclicked" items as hard negatives at level-1, enabling timely interest fade-out. On the large-scale Kuaishou short-video recommendation system, DualGR has achieved outstanding performance. Online A/B testing shows +0.527% video views and +0.432% watch time lifts, validating DualGR as a practical and effective paradigm for industrial generative retrieval.

</details>


### [475] [MindRec: Mind-inspired Coarse-to-fine Decoding for Generative Recommendation](https://arxiv.org/abs/2511.12597)
*Mengyao Gao,Chongming Gao,Haoyan Liu,Qingpeng Cai,Peng Jiang,Jiajia Chen,Shuai Yuan,Xiangnan He*

Main category: cs.IR

TL;DR: 提出了一种受人类思维启发的推荐框架MindRec，通过先生成关键token再扩展为完整项目，并结合层次化类别树和新型扩散束搜索算法，显著提升了推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的推荐系统受限于从左到右的解码方式，难以产生全局最优推荐；而人类推理是非线性的，通常从关键词或直觉出发逐步完善，因此希望构建更符合人类思维过程的推荐模型。

Method: 首先生成反映用户偏好的关键token，然后将其扩展为完整项目；引入层次化类别树结构，使模型按从粗到细的顺序生成类别；设计了适用于该范式的新型扩散束搜索算法以避免贪婪解码的局部最优问题。

Result: 实验结果显示，MindRec在top-1推荐性能上平均比现有最先进方法提升9.5%。

Conclusion: MindRec通过模拟人类思维过程，在生成式推荐中实现了更优的性能，展示了类人推理机制在推荐系统中的潜力。

Abstract: Recent advancements in large language model-based recommendation systems often represent items as text or semantic IDs and generate recommendations in an auto-regressive manner. However, due to the left-to-right greedy decoding strategy and the unidirectional logical flow, such methods often fail to produce globally optimal recommendations. In contrast, human reasoning does not follow a rigid left-to-right sequence. Instead, it often begins with keywords or intuitive insights, which are then refined and expanded. Inspired by this fact, we propose Mind-inspired Recommender (MindRec), a novel generative framework that emulates human thought processes. Particularly, our method first generates key tokens that reflect user preferences, and then expands them into the complete item, enabling flexible and human-like generation. To further emulate the structured nature of human decision-making, we organize items into a hierarchical category tree. This structure guides the model to first produce the coarse-grained category and then progressively refine its selection through finer-grained subcategories before generating the specific item. To mitigate the local optimum problem inherent in greedy decoding, we design a novel beam search algorithm, Diffusion Beam Search, tailored for our mind-inspired generation paradigm. Experimental results demonstrate that MindRec yields a 9.5\% average improvement in top-1 recommendation performance over state-of-the-art methods, highlighting its potential to enhance recommendation accuracy. The implementation is available via https://github.com/Mr-Peach0301/MindRec.

</details>


### [476] [Tokenize Once, Recommend Anywhere: Unified Item Tokenization for Multi-domain LLM-based Recommendation](https://arxiv.org/abs/2511.12922)
*Yu Hou,Won-Yong Shin*

Main category: cs.IR

TL;DR: 提出UniTok，一种统一的物品分词框架，通过混合专家架构和代码本实现跨多个领域的可扩展且语义保留的分词。


<details>
  <summary>Details</summary>
Motivation: 现有物品分词方法需为每个领域单独训练模型，泛化能力差，且难以在统一框架中保持领域特异性信息。

Method: 设计共享编码器将不同领域物品映射到统一潜在空间，结合领域专用专家与共享专家（MoE架构）捕获独特与共性语义，并引入互信息校准机制缓解领域间语义不平衡。

Result: 在多个真实数据集上实验表明，UniTok相比强基线最高提升51.89%，具备理论有效性，且无需重新训练即可泛化至不同领域。

Conclusion: UniTok实现了高效、通用且语义平衡的跨领域物品分词，显著优于现有方法，支持大规模推荐系统应用。

Abstract: Large language model (LLM)-based recommender systems have achieved high-quality performance by bridging the discrepancy between the item space and the language space through item tokenization. However, existing item tokenization methods typically require training separate models for each item domain, limiting generalization. Moreover, the diverse distributions and semantics across item domains make it difficult to construct a unified tokenization that preserves domain-specific information. To address these challenges, we propose UniTok, a Unified item Tokenization framework that integrates our own mixture-of-experts (MoE) architecture with a series of codebooks to convert items into discrete tokens, enabling scalable tokenization while preserving semantic information across multiple item domains. Specifically, items from different domains are first projected into a unified latent space through a shared encoder. They are then routed to domain-specific experts to capture the unique semantics, while a shared expert, which is always active, encodes common knowledge transferable across domains. Additionally, to mitigate semantic imbalance across domains, we present a mutual information calibration mechanism, which guides the model towards retaining similar levels of semantic information for each domain. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed UniTok framework is (a) highly effective: achieving up to 51.89% improvements over strong benchmarks, (b) theoretically sound: showing the analytical validity of our architectural design and optimization; and (c) highly generalizable: demonstrating robust performance across diverse domains without requiring per-domain retraining, a capability not supported by existing baselines.

</details>


### [477] [A Plug-and-Play Spatially-Constrained Representation Enhancement Framework for Local-Life Recommendation](https://arxiv.org/abs/2511.12947)
*Hao Jiang,Guoquan Wang,Sheng Yu,Yang Zeng,Wencong Zeng,Guorui Zhou*

Main category: cs.IR

TL;DR: 本文提出了一种面向本地生活服务的长尾推荐框架ReST，从物品视角出发，通过属性语义初始化和空间约束下的对比学习来增强长尾物品的表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法多从用户角度建模，难以有效缓解本地生活场景中因地理限制和交互稀疏导致的长尾物品曝光不足问题，因此需要一种更契合该场景的物品中心化表示增强方法。

Method: 提出ReST框架，包括Meta ID Warm-up Network用于注入属性语义信息初始化ID表示，以及基于对比学习的SIDENet网络，引入空间约束下的难样本采样和动态表示对齐策略，以增强长尾物品表示并保持与热门物品的兼容性。

Result: 实验表明ReST在多个真实数据集上显著提升了长尾物品的推荐性能，尤其在稀疏和空间受限场景下优于现有主流方法。

Conclusion: ReST通过物品中心化的表示增强策略，有效缓解了本地生活推荐中的空间约束与长尾稀疏问题，具备良好的可扩展性和实用性。

Abstract: Local-life recommendation have witnessed rapid growth, providing users with convenient access to daily essentials. However, this domain faces two key challenges: (1) spatial constraints, driven by the requirements of the local-life scenario, where items are usually shown only to users within a limited geographic area, indirectly reducing their exposure probability; and (2) long-tail sparsity, where few popular items dominate user interactions, while many high-quality long-tail items are largely overlooked due to imbalanced interaction opportunities. Existing methods typically adopt a user-centric perspective, such as modeling spatial user preferences or enhancing long-tail representations with collaborative filtering signals. However, we argue that an item-centric perspective is more suitable for this domain, focusing on enhancing long-tail items representation that align with the spatially-constrained characteristics of local lifestyle services. To tackle this issue, we propose ReST, a Plug-And-Play Spatially-Constrained Representation Enhancement Framework for Long-Tail Local-Life Recommendation. Specifically, we first introduce a Meta ID Warm-up Network, which initializes fundamental ID representations by injecting their basic attribute-level semantic information. Subsequently, we propose a novel Spatially-Constrained ID Representation Enhancement Network (SIDENet) based on contrastive learning, which incorporates two efficient strategies: a spatially-constrained hard sampling strategy and a dynamic representation alignment strategy. This design adaptively identifies weak ID representations based on their attribute-level information during training. It additionally enhances them by capturing latent item relationships within the spatially-constrained characteristics of local lifestyle services, while preserving compatibility with popular items.

</details>


### [478] [Can We Predict the Next Question? A Collaborative Filtering Approach to Modeling User Behavior](https://arxiv.org/abs/2511.12949)
*Bokang Fu,Jiahao Wang,Xiaojing Liu,Yuli Liu*

Main category: cs.IR

TL;DR: 提出了一种结合协同过滤和问题预测的CFQP框架，通过个性化记忆模块和基于图的偏好传播来动态建模用户-问题交互，有效捕捉用户兴趣的演化模式。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在建模用户偏好时多采用静态方式，难以捕捉用户交互行为中的动态序列特征，尤其是用户历史提问所蕴含的兴趣演化和认知模式。

Method: 提出CFQP框架，融合协同过滤与问题预测，引入个性化记忆模块捕捉个体用户行为序列，并利用基于图的偏好传播机制从相似用户中提取协同信号，联合优化预测性能。

Result: 实验结果表明，CFQP能有效生成模拟真实用户提问模式的代理，显著优于传统静态建模方法，在动态偏好建模和用户行为预测方面表现优异。

Conclusion: CFQP为构建具有主动性和适应性的对话系统提供了新思路，验证了结合个性化记忆与协同学习在动态用户建模中的有效性。

Abstract: In recent years, large language models (LLMs) have excelled in language understanding and generation, powering advanced dialogue and recommendation systems. However, a significant limitation persists: these systems often model user preferences statically, failing to capture the dynamic and sequential nature of interactive behaviors. The sequence of a user's historical questions provides a rich, implicit signal of evolving interests and cognitive patterns, yet leveraging this temporal data for predictive tasks remains challenging due to the inherent disconnect between language modeling and behavioral sequence modeling.
  To bridge this gap, we propose a Collaborative Filtering-enhanced Question Prediction (CFQP) framework. CFQP dynamically models evolving user-question interactions by integrating personalized memory modules with graph-based preference propagation. This dual mechanism allows the system to adaptively learn from user-specific histories while refining predictions through collaborative signals from similar users. Experimental results demonstrate that our approach effectively generates agents that mimic real-user questioning patterns, highlighting its potential for building proactive and adaptive dialogue systems.

</details>


### [479] [Personalized Federated Recommendation With Knowledge Guidance](https://arxiv.org/abs/2511.12959)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Dongha Kim,Hwanjo Yu*

Main category: cs.IR

TL;DR: 提出了一种名为FedRKG的联邦推荐框架，通过知识引导机制在保持单知识模型内存效率的同时实现双知识模型的个性化性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐模型在内存效率和个性化之间存在权衡：单知识模型因知识替换而丢失个性化，双知识模型则内存消耗过大。

Method: 提出知识引导（Knowledge Guidance）和自适应引导（Adaptive Guidance）机制，将全局知识融合到保留的本地嵌入中，并动态调整每条用户-项目交互的引导强度。

Result: 在多个基准数据集上的实验表明，FedRKG显著优于当前最先进的方法。

Conclusion: FedRKG有效解决了联邦推荐中内存效率与个性化之间的矛盾，兼具高性能与低内存占用。

Abstract: Federated Recommendation (FedRec) has emerged as a key paradigm for building privacy-preserving recommender systems. However, existing FedRec models face a critical dilemma: memory-efficient single-knowledge models suffer from a suboptimal knowledge replacement practice that discards valuable personalization, while high-performance dual-knowledge models are often too memory-intensive for practical on-device deployment. We propose Federated Recommendation with Knowledge Guidance (FedRKG), a model-agnostic framework that resolves this dilemma. The core principle, Knowledge Guidance, avoids full replacement and instead fuses global knowledge into preserved local embeddings, attaining the personalization benefits of dual-knowledge within a single-knowledge memory footprint. Furthermore, we introduce Adaptive Guidance, a fine-grained mechanism that dynamically modulates the intensity of this guidance for each user-item interaction, overcoming the limitations of static fusion methods. Extensive experiments on benchmark datasets demonstrate that FedRKG significantly outperforms state-of-the-art methods, validating the effectiveness of our approach. The code is available at https://github.com/Jaehyung-Lim/fedrkg.

</details>


### [480] [Mitigating Recommendation Biases via Group-Alignment and Global-Uniformity in Representation Learning](https://arxiv.org/abs/2511.13041)
*Miaomiao Cai,Min Hou,Lei Chen,Le Wu,Haoyue Bai,Yong Li,Meng Wang*

Main category: cs.IR

TL;DR: 提出一种从表征分布角度缓解推荐偏差的框架AURL，通过组对齐和全局均匀性正则化解决长尾和冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 协同过滤方法因训练数据不平衡导致推荐偏向热门物品且对不活跃用户效果差，现有去偏方法常牺牲准确性或依赖敏感的权重策略。

Method: 分析偏差成因，提出组对齐（group-alignment）和全局均匀性（global-uniformity）两种表征空间正则化方法，分别缓解群体差异和全局坍缩问题。

Result: 在三个真实数据集和多种推荐模型上验证了AURL的有效性，显著提升去偏性能同时保持推荐准确性。

Conclusion: AURL通过优化表征分布有效缓解推荐偏差，具有良好的通用性和稳定性，为去偏推荐提供了新视角。

Abstract: Collaborative Filtering~(CF) plays a crucial role in modern recommender systems, leveraging historical user-item interactions to provide personalized suggestions. However, CF-based methods often encounter biases due to imbalances in training data. This phenomenon makes CF-based methods tend to prioritize recommending popular items and performing unsatisfactorily on inactive users. Existing works address this issue by rebalancing training samples, reranking recommendation results, or making the modeling process robust to the bias. Despite their effectiveness, these approaches can compromise accuracy or be sensitive to weighting strategies, making them challenging to train. In this paper, we deeply analyze the causes and effects of the biases and propose a framework to alleviate biases in recommendation from the perspective of representation distribution, namely Group-Alignment and Global-Uniformity Enhanced Representation Learning for Debiasing Recommendation (AURL). Specifically, we identify two significant problems in the representation distribution of users and items, namely group-discrepancy and global-collapse. These two problems directly lead to biases in the recommendation results. To this end, we propose two simple but effective regularizers in the representation space, respectively named group-alignment and global-uniformity. The goal of group-alignment is to bring the representation distribution of long-tail entities closer to that of popular entities, while global-uniformity aims to preserve the information of entities as much as possible by evenly distributing representations. Our method directly optimizes both the group-alignment and global-uniformity regularization terms to mitigate recommendation biases. Extensive experiments on three real datasets and various recommendation backbones verify the superiority of our proposed framework.

</details>


### [481] [Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact](https://arxiv.org/abs/2511.13057)
*Satyanarayan Pati*

Main category: cs.IR

TL;DR: 本研究在BEIR SciFact基准上系统评估了密集检索模型的向量压缩策略，发现int8标量量化以4倍压缩率仅带来约1-2%的nDCG@10性能损失，是最优选择；而二值化导致性能崩溃，自动编码器在同等压缩下损失更大。


<details>
  <summary>Details</summary>
Motivation: 密集检索模型的高维、高精度向量（如float32）在实际部署中面临存储和内存瓶颈，亟需有效的压缩方法以平衡性能与效率。

Method: 在BEIR SciFact数据集上，对比两种压缩策略：一是通过深度自编码器（AE）进行降维（从384维降至12维），二是通过量化降低精度（float16、int8、二值化），并系统评估其在多种检索指标（NDCG、MAP、MRR、Recall、Precision）上的性能变化。

Result: int8标量量化实现4倍压缩，仅造成约1-2%的nDCG@10下降，表现最优；自编码器在4倍压缩（AE-96）下性能损失更显著；二值化导致检索性能严重下降，不适用。

Conclusion: int8量化是在保持检索性能的同时实现高效压缩的最佳实践方案，为实际部署提供了清晰的优化路径。

Abstract: Dense retrieval models have become a standard for state-of-the-art information retrieval. However, their high-dimensional, high-precision (float32) vector embeddings create significant storage and memory challenges for real-world deployment. To address this, we conduct a rigorous empirical study on the BEIR SciFact benchmark, evaluating the trade-offs between two primary compression strategies: (1) Dimensionality Reduction via deep Autoencoders (AE), reducing original 384-dim vectors to latent spaces from 384 down to 12, and (2) Precision Reduction via Quantization (float16, int8, and binary). We systematically compare each method by measuring the "performance loss" (or gain) relative to a float32 baseline across a full suite of retrieval metrics (NDCG, MAP, MRR, Recall, Precision) at various k cutoffs. Our results show that int8 scalar quantization provides the most effective "sweet spot," achieving a 4x compression with a negligible [~1-2%] drop in nDCG@10. In contrast, Autoencoders show a graceful degradation but suffer a more significant performance loss at equivalent 4x compression ratios (AE-96). binary quantization was found to be unsuitable for this task due to catastrophic performance drops. This work provides a practical guide for deploying efficient, high-performance retrieval systems.

</details>


### [482] [Local Collaborative Filtering: A Collaborative Filtering Method that Utilizes Local Similarities among Users](https://arxiv.org/abs/2511.13166)
*Zhaoxin Shen,Dan Wu*

Main category: cs.IR

TL;DR: 提出了一种新的协同过滤方法LCF，利用用户间的局部相似性并结合大数定律来提高用户行为数据的利用率。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地利用互联网上的用户行为数据于推荐系统中。

Method: 提出局部协同过滤（LCF）方法，利用用户之间的局部相似性，并通过大数定律整合数据。

Result: 在Steam游戏数据集上进行实验，结果符合现实需求。

Conclusion: LCF方法能有效提升用户行为数据的利用效率，并在实际数据集中表现出良好的推荐效果。

Abstract: To leverage user behavior data from the Internet more effectively in recommender systems, this paper proposes a novel collaborative filtering (CF) method called Local Collaborative Filtering (LCF). LCF utilizes local similarities among users and integrates their data using the law of large numbers (LLN), thereby improving the utilization of user behavior data. Experiments are conducted on the Steam game dataset, and the results of LCF align with real-world needs.

</details>


### [483] [Cog-RAG: Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation](https://arxiv.org/abs/2511.13201)
*Hao Hu,Yifan Feng,Ruoxue Li,Rundong Xue,Xingliang Hou,Zhiqiang Tian,Yue Gao,Shaoyi Du*

Main category: cs.IR

TL;DR: 提出了一种基于主题对齐的双超图检索增强生成框架Cog-RAG，通过主题超图和实体超图分别捕捉跨文本块的主题结构与高阶语义关系，结合认知启发的两阶段检索策略，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图结构的RAG方法主要关注低阶实体关系，难以捕捉多实体间的高阶关联；超图方法虽能建模高阶关系，但局限于文本块内的实体表示，缺乏对全局主题结构的建模与对齐。

Method: 提出Cog-RAG框架，构建主题超图以捕捉跨文本块的主题组织结构，实体超图用于建模高阶语义关系；设计认知启发的两阶段检索：先从主题超图激活相关主题内容，再在实体超图中进行细粒度检索与扩散。

Result: 实验表明，Cog-RAG在多个评测任务上显著优于现有的SOTA基线方法，有效提升生成结果的相关性与一致性。

Conclusion: Cog-RAG通过主题与实体双超图结构及类人推理的两阶段检索，实现了从全局主题到局部细节的语义对齐与连贯生成，为RAG系统提供了更深层次的认知对齐能力。

Abstract: Retrieval-Augmented Generation (RAG) enhances the response quality and domain-specific performance of large language models (LLMs) by incorporating external knowledge to combat hallucinations. In recent research, graph structures have been integrated into RAG to enhance the capture of semantic relations between entities. However, it primarily focuses on low-order pairwise entity relations, limiting the high-order associations among multiple entities. Hypergraph-enhanced approaches address this limitation by modeling multi-entity interactions via hyperedges, but they are typically constrained to inter-chunk entity-level representations, overlooking the global thematic organization and alignment across chunks. Drawing inspiration from the top-down cognitive process of human reasoning, we propose a theme-aligned dual-hypergraph RAG framework (Cog-RAG) that uses a theme hypergraph to capture inter-chunk thematic structure and an entity hypergraph to model high-order semantic relations. Furthermore, we design a cognitive-inspired two-stage retrieval strategy that first activates query-relevant thematic content from the theme hypergraph, and then guides fine-grained recall and diffusion in the entity hypergraph, achieving semantic alignment and consistent generation from global themes to local details. Our extensive experiments demonstrate that Cog-RAG significantly outperforms existing state-of-the-art baseline approaches.

</details>


### [484] [Uncovering Causal Drivers of Energy Efficiency for Industrial Process in Foundry via Time-Series Causal Inference](https://arxiv.org/abs/2511.13389)
*Zhipeng Ma,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.IR

TL;DR: 本研究提出了一种结合时间序列聚类与因果推断（PCMCI+）的方法，用于识别铸造厂感应炉熔炼过程中影响能源效率的关键操作因素。


<details>
  <summary>Details</summary>
Motivation: 传统相关性分析难以区分真实因果关系与虚假关联，无法有效指导节能决策，尤其是在复杂、高能耗的铸造工艺中。

Method: 利用丹麦一家铸造厂的生产数据，首先通过时间序列聚类将熔炼周期划分为不同的运行模式，然后在每种模式下应用先进的因果发现算法PCMCI+来识别变量间的因果关系。

Result: 研究发现了能源消耗、炉温与材料重量之间的稳健因果关系，电压对冷却水温度存在延迟影响；高效运行模式具有稳定的因果结构，而低效模式则表现出强化反馈回路和异常依赖。

Conclusion: 该研究不仅提出了一种新的聚类-因果推理集成方法，可用于分析高能耗工业过程，还为优化操作、降低能耗和排放提供了可操作的见解。

Abstract: Improving energy efficiency in industrial foundry processes is a critical challenge, as these operations are highly energy-intensive and marked by complex interdependencies among process variables. Correlation-based analyses often fail to distinguish true causal drivers from spurious associations, limiting their usefulness for decision-making. This paper applies a time-series causal inference framework to identify the operational factors that directly affect energy efficiency in induction furnace melting. Using production data from a Danish foundry, the study integrates time-series clustering to segment melting cycles into distinct operational modes with the PCMCI+ algorithm, a state-of-the-art causal discovery method, to uncover cause-effect relationships within each mode. Across clusters, robust causal relations among energy consumption, furnace temperature, and material weight define the core drivers of efficiency, while voltage consistently influences cooling water temperature with a delayed response. Cluster-specific differences further distinguish operational regimes: efficient clusters are characterized by stable causal structures, whereas inefficient ones exhibit reinforcing feedback loops and atypical dependencies. The contributions of this study are twofold. First, it introduces an integrated clustering-causal inference pipeline as a methodological innovation for analyzing energy-intensive processes. Second, it provides actionable insights that enable foundry operators to optimize performance, reduce energy consumption, and lower emissions.

</details>


### [485] [Attention Grounded Enhancement for Visual Document Retrieval](https://arxiv.org/abs/2511.13415)
*Wanqing Cui,Wei Huang,Yazhi Guo,Yibo Hu,Meiguang Jin,Junfeng Ma,Keping Bi*

Main category: cs.IR

TL;DR: 提出了一种基于跨模态注意力的视觉文档检索增强框架AGREE，利用多模态大模型的注意力作为局部监督信号，结合全局与局部信号联合优化检索器，提升了对非抽取式查询的理解和检索准确性。


<details>
  <summary>Details</summary>
Motivation: 现有检索器仅使用全局相关性标签训练，缺乏对支持匹配的具体文档区域的细粒度监督，导致模型依赖表面特征，难以捕捉隐含语义关系，尤其在处理非抽取式查询时表现不佳。

Method: 提出AGREE框架，利用多模态大语言模型的跨模态注意力作为代理局部监督信号，在训练过程中将局部区域相关性信号与全局文档相关性信号结合，共同优化检索模型，使其不仅能判断文档是否相关，还能识别驱动相关性的具体内容区域。

Result: 在ViDoRe V2基准上的实验表明，AGREE显著优于仅使用全局监督的基线方法；定性和定量分析显示，该方法增强了查询词与文档区域之间的深层对齐，减少了表面匹配偏差。

Conclusion: AGREE通过引入注意力引导的局部监督，有效提升了视觉文档检索的准确性和可解释性，推动检索系统从表面匹配向深层语义理解转变。

Abstract: Visual document retrieval requires understanding heterogeneous and multi-modal content to satisfy information needs. Recent advances use screenshot-based document encoding with fine-grained late interaction, significantly improving retrieval performance. However, retrievers are still trained with coarse global relevance labels, without revealing which regions support the match. As a result, retrievers tend to rely on surface-level cues and struggle to capture implicit semantic connections, hindering their ability to handle non-extractive queries. To alleviate this problem, we propose a \textbf{A}ttention-\textbf{G}rounded \textbf{RE}triever \textbf{E}nhancement (AGREE) framework. AGREE leverages cross-modal attention from multimodal large language models as proxy local supervision to guide the identification of relevant document regions. During training, AGREE combines local signals with the global signals to jointly optimize the retriever, enabling it to learn not only whether documents match, but also which content drives relevance. Experiments on the challenging ViDoRe V2 benchmark show that AGREE significantly outperforms the global-supervision-only baseline. Quantitative and qualitative analyses further demonstrate that AGREE promotes deeper alignment between query terms and document regions, moving beyond surface-level matching toward more accurate and interpretable retrieval. Our code is available at: https://anonymous.4open.science/r/AGREE-2025.

</details>


### [486] [Exploring Multi-Table Retrieval Through Iterative Search](https://arxiv.org/abs/2511.13418)
*Allaa Boutaleb,Bernd Amann,Rafael Angarita,Hubert Naacke*

Main category: cs.IR

TL;DR: 提出了一种快速、有效的贪婪连接感知检索算法，用于开放域数据湖问答中的多表检索，相比MIP方法在保持性能的同时显著提升速度。


<details>
  <summary>Details</summary>
Motivation: 在开放域数据湖问答中，需要从多个表格中检索并组合信息，但现有方法在保证语义相关性和结构连贯性（如可连接性）方面存在计算复杂度高或效果不佳的问题。

Method: 将多表检索建模为迭代搜索过程，提出一个通用框架及具体的贪婪连接感知检索算法，综合平衡相关性、覆盖率和可连接性。

Result: 在5个NL2SQL基准上的实验表明，该方法相比MIP方法快4-400倍，同时检索性能相当。

Conclusion: 迭代启发式方法在实际应用中具有可扩展性和组成感知能力，是高效多表检索的可行方案。

Abstract: Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.

</details>


### [487] [Compact Multimodal Language Models as Robust OCR Alternatives for Noisy Textual Clinical Reports](https://arxiv.org/abs/2511.13523)
*Nikita Neveditsin,Pawan Lingras,Salil Patil,Swarup Patil,Vijay Mago*

Main category: cs.IR

TL;DR: 该研究评估了紧凑型多模态语言模型在转录噪声较大的临床文档中的表现，使用印度医疗环境中常见的方言化医学英语超声报告进行测试。结果表明，这些模型在准确性、抗噪性和数值识别方面优于传统OCR系统，尽管计算成本较高，但具备部署于本地医疗数字化的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于智能手机拍摄的医疗记录图像常受模糊、阴影等噪声影响，传统OCR系统在真实场景下表现不佳，因此需要更鲁棒且保护隐私的转录方案。

Method: 采用八种系统对比，评估其在转录带有区域口音的医学英语超声报告时的性能，指标包括转录准确率、抗噪性、数值准确性和计算效率。

Result: 紧凑型多模态模型在各项指标上均优于经典和神经OCR方法，展现出更强的鲁棒性和语言适应能力。

Conclusion: 紧凑型多模态语言模型虽计算开销较高，但因其优异的性能和隐私保护特性，是适用于本地化医疗记录数字化的可行方案。

Abstract: Digitization of medical records often relies on smartphone photographs of printed reports, producing images degraded by blur, shadows, and other noise. Conventional OCR systems, optimized for clean scans, perform poorly under such real-world conditions. This study evaluates compact multimodal language models as privacy-preserving alternatives for transcribing noisy clinical documents. Using obstetric ultrasound reports written in regionally inflected medical English common to Indian healthcare settings, we compare eight systems in terms of transcription accuracy, noise sensitivity, numeric accuracy, and computational efficiency. Compact multimodal models consistently outperform both classical and neural OCR pipelines. Despite higher computational costs, their robustness and linguistic adaptability position them as viable candidates for on-premises healthcare digitization.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [488] [MALBO: Optimizing LLM-Based Multi-Agent Teams via Multi-Objective Bayesian Optimization](https://arxiv.org/abs/2511.11788)
*Antonio Sabbatella*

Main category: cs.MA

TL;DR: 本文提出了MALBO框架，通过多目标贝叶斯优化解决大语言模型在多智能体系统中角色分配的性能与成本权衡问题，实现了高效、自动化的团队配置优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对单智能体场景，缺乏对多智能体、多目标下LLM角色分配问题的系统性优化框架，难以应对组合搜索空间大、评估成本高和性能-成本权衡的挑战。

Method: 将LLM角色分配建模为多目标优化问题，采用基于独立高斯过程代理模型的多目标贝叶斯优化（MOBO），在连续特征空间中以期望超体积提升（EHVI）指导搜索，寻找性能与推理成本之间的帕累托前沿。

Result: 相比随机搜索，MALBO在保持相似性能的同时平均降低成本45%以上；相比同构基线，找到的异构团队最高可节省65.8%成本且保持最优性能。

Conclusion: MALBO提供了一个原则性强、自动化的多智能体LLM配置框架，能有效生成性能达标且成本更低的异构团队，为部署高效、专业化的多智能体AI系统提供了数据驱动工具。

Abstract: The optimal assignment of Large Language Models (LLMs) to specialized roles in multi-agent systems is a significant challenge, defined by a vast combinatorial search space, expensive black-box evaluations, and an inherent trade-off between performance and cost. Current optimization methods focus on single-agent settings and lack a principled framework for this multi-agent, multi-objective problem.
  This thesis introduces MALBO (Multi-Agent LLM Bayesian Optimization), a systematic framework designed to automate the efficient composition of LLM-based agent teams. We formalize the assignment challenge as a multi-objective optimization problem, aiming to identify the Pareto front of configurations between task accuracy and inference cost. The methodology employs multi-objective Bayesian Optimization (MOBO) with independent Gaussian Process surrogate models. By searching over a continuous feature-space representation of the LLMs, this approach performs a sample-efficient exploration guided by the expected hypervolume improvement.
  The primary contribution is a principled and automated methodology that yields a Pareto front of optimal team configurations. Our results demonstrate that the Bayesian optimization phase, compared to an initial random search, maintained a comparable average performance while reducing the average configuration cost by over 45%. Furthermore, MALBO identified specialized, heterogeneous teams that achieve cost reductions of up to 65.8% compared to homogeneous baselines, all while maintaining maximum performance. The framework thus provides a data-driven tool for deploying cost-effective and highly specialized multi-agent AI systems.

</details>


### [489] [From Single to Societal: Analyzing Persona-Induced Bias in Multi-Agent Interactions](https://arxiv.org/abs/2511.11789)
*Jiayi Li,Xiao Liu,Yansong Feng*

Main category: cs.MA

TL;DR: 该论文系统研究了基于大语言模型的多智能体系统中由“人设”引发的偏见问题，发现来自历史优势群体的人设（如男性、白人）反而被认为更不可信且坚持度更低，且存在显著的群体内偏好。这些偏见在不同模型和设置中均存在，提示需重视并缓解此类问题。


<details>
  <summary>Details</summary>
Motivation: 探讨在多智能体系统中赋予智能体人设是否会导致社会性偏见，尤其是在信任度和坚持度方面的不公平表现，从而影响系统公平性与可靠性。

Method: 通过在协作问题解决和说服任务中的受控实验，分析不同社会属性人设对智能体间互动的影响，评估其信任度、坚持度及群体内偏好，并在多种LLM、群体规模和交互轮次下验证结果。

Result: 1) 基于LLM的智能体表现出对历史优势群体人设的信任度和坚持度更低；2) 存在显著的群体内趋同倾向；3) 这些偏见在不同模型和设置中具有一致性。

Conclusion: 人设会引发系统性偏见，影响多智能体交互的公平性，亟需引起关注并开发缓解策略。

Abstract: Large Language Model (LLM)-based multi-agent systems are increasingly used to simulate human interactions and solve collaborative tasks. A common practice is to assign agents with personas to encourage behavioral diversity. However, this raises a critical yet underexplored question: do personas introduce biases into multi-agent interactions? This paper presents a systematic investigation into persona-induced biases in multi-agent interactions, with a focus on social traits like trustworthiness (how an agent's opinion is received by others) and insistence (how strongly an agent advocates for its opinion). Through a series of controlled experiments in collaborative problem-solving and persuasion tasks, we reveal that (1) LLM-based agents exhibit biases in both trustworthiness and insistence, with personas from historically advantaged groups (e.g., men and White individuals) perceived as less trustworthy and demonstrating less insistence; and (2) agents exhibit significant in-group favoritism, showing a higher tendency to conform to others who share the same persona. These biases persist across various LLMs, group sizes, and numbers of interaction rounds, highlighting an urgent need for awareness and mitigation to ensure the fairness and reliability of multi-agent systems.

</details>


### [490] [Conflict-Free Flight Scheduling Using Strategic Demand Capacity Balancing for Urban Air Mobility Operations](https://arxiv.org/abs/2511.11854)
*Vahid Hemmati,Yonas Ayalew,Ahmad Mohammadi,Reza Ahmari,Parham Kebria,Abdollah Homaifar,Mehrdad Saif*

Main category: cs.MA

TL;DR: 提出一种基于延迟起飞的多智能体飞行调度方法，通过优化起飞时间确保城市空中交通中的安全分离，显著减少总延迟。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市空中交通（UAM）中高密度多智能体飞行的安全与效率问题，需要一种能够保证冲突-free运行的调度方法。

Method: 引入基于运动学原理的成对冲突避免（PCA）机制，并扩展至多智能体场景，通过优化模型确定最优起飞时间。

Result: 在多种模拟环境和真实UAM用例中验证了该方法的有效性，显著降低了平均延迟并实现了无碰撞飞行。

Conclusion: 该方法为城市空中交通系统提供了一个可扩展且鲁棒的飞行调度框架。

Abstract: In this paper, we propose a conflict-free multi- agent flight scheduling that ensures robust separation in con- strained airspace for Urban Air Mobility (UAM) operations application. First, we introduce Pairwise Conflict Avoidance (PCA) based on delayed departures, leveraging kinematic principles to maintain safe distances. Next, we expand PCA to multi-agent scenarios, formulating an optimization approach that systematically determines departure times under increasing traffic densities. Performance metrics, such as average delay, assess the effectiveness of our solution. Through numerical simulations across diverse multi-agent environments and real- world UAM use cases, our method demonstrates a significant reduction in total delay while ensuring collision-free operations. This approach provides a scalable framework for emerging urban air mobility systems.

</details>


### [491] [Goal-Oriented Multi-Agent Reinforcement Learning for Decentralized Agent Teams](https://arxiv.org/abs/2511.11992)
*Hung Du,Hy Nguyen,Srikanth Thudumu,Rajesh Vasa,Kon Mouzakis*

Main category: cs.MA

TL;DR: 提出一种去中心化的多智能体强化学习（MARL）框架，通过目标感知的通信策略实现自动驾驶车辆在复杂环境中的高效协作。


<details>
  <summary>Details</summary>
Motivation: 在动态、不可预测且通信受限的环境中，传统的集中式协调方法难以应对多智能体系统的挑战，尤其当各车辆具有独立目标时。

Method: 设计了一种去中心化的MARL框架，引入基于局部目标和观测的选择性通信机制，使智能体仅共享与当前目标相关的信息。

Result: 在包含障碍物和动态智能体数量的导航任务中验证了方法的有效性，相比非合作基线显著提高了任务成功率并缩短了到达目标的时间，且性能随智能体数量增加保持稳定。

Conclusion: 所提出的去中心化、目标驱动的MARL框架能够有效支持跨域多车辆系统在现实场景中的可扩展协作。

Abstract: Connected and autonomous vehicles across land, water, and air must often operate in dynamic, unpredictable environments with limited communication, no centralized control, and partial observability. These real-world constraints pose significant challenges for coordination, particularly when vehicles pursue individual objectives. To address this, we propose a decentralized Multi-Agent Reinforcement Learning (MARL) framework that enables vehicles, acting as agents, to communicate selectively based on local goals and observations. This goal-aware communication strategy allows agents to share only relevant information, enhancing collaboration while respecting visibility limitations. We validate our approach in complex multi-agent navigation tasks featuring obstacles and dynamic agent populations. Results show that our method significantly improves task success rates and reduces time-to-goal compared to non-cooperative baselines. Moreover, task performance remains stable as the number of agents increases, demonstrating scalability. These findings highlight the potential of decentralized, goal-driven MARL to support effective coordination in realistic multi-vehicle systems operating across diverse domains.

</details>


### [492] [FINRS: A Risk-Sensitive Trading Framework for Real Financial Markets](https://arxiv.org/abs/2511.12599)
*Bijia Liu,Ronghao Dang*

Main category: cs.MA

TL;DR: FinRS是一个风险敏感的交易框架，结合了分层市场分析、双决策代理和多时间尺度奖励反馈，以在追求收益的同时管理下行风险。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的交易代理主要集中在单步预测，缺乏集成的风险管理机制，导致在波动市场中效果不佳。

Method: 提出FinRS框架，整合分层市场分析、双决策代理和多时间尺度奖励反射机制，实现收益与风险的平衡。

Result: 在多种股票和市场条件下实验表明，FinRS相比现有最先进方法具有更高的盈利能力和稳定性。

Conclusion: FinRS通过集成风险管理机制，在复杂市场环境中表现出优越的交易性能，提升了LLM在金融交易中的实用性。

Abstract: Large language models (LLMs) have shown strong reasoning capabilities and are increasingly explored for financial trading. Existing LLM-based trading agents, however, largely focus on single-step prediction and lack integrated mechanisms for risk management, which reduces their effectiveness in volatile markets. We introduce FinRS, a risk-sensitive trading framework that combines hierarchical market analysis, dual-decision agents, and multi-timescale reward reflection to align trading actions with both return objectives and downside risk constraints. Experiments on multiple stocks and market conditions show that FinRS achieves superior profitability and stability compared to state-of-the-art methods.

</details>


### [493] [ENGRAM: Effective, Lightweight Memory Orchestration for Conversational Agents](https://arxiv.org/abs/2511.12960)
*Daivik Patel,Shrenik Patel*

Main category: cs.MA

TL;DR: ENGRAM是一个轻量级的记忆系统，通过三种规范记忆类型（情景、语义和程序性）和简单的密集检索实现大语言模型的长时程一致性，在多个基准上达到先进性能，且仅使用约1%的token。


<details>
  <summary>Details</summary>
Motivation: 现有的记忆系统架构复杂（如知识图谱、多阶段检索等），导致工程实现困难且难以复现，因此需要一种更简单高效的方法来实现大语言模型在长期交互中的一致性。

Method: 提出ENGRAM，将对话组织为三种规范记忆类型，每轮用户输入转化为具有标准化模式和嵌入的类型化记忆记录，并存入数据库；查询时通过单一路由器和检索器检索每种类型的top-k近邻，用简单的集合操作合并结果，并将最相关证据作为上下文提供给模型。

Result: ENGRAM在LoCoMo基准上达到最先进的结果，在LongMemEval上比全上下文基线高出15分，同时仅使用约1%的token。

Conclusion: 精细的记忆分类与简单的密集检索相结合，可以在不依赖复杂架构的情况下有效实现语言模型的长期记忆管理。

Abstract: Large language models (LLMs) deployed in user-facing applications require long-horizon consistency: the ability to remember prior interactions, respect user preferences, and ground reasoning in past events. However, contemporary memory systems often adopt complex architectures such as knowledge graphs, multi-stage retrieval pipelines, and OS-style schedulers, which introduce engineering complexity and reproducibility challenges. We present ENGRAM, a lightweight memory system that organizes conversation into three canonical memory types (episodic, semantic, and procedural) through a single router and retriever. Each user turn is converted into typed memory records with normalized schemas and embeddings and stored in a database. At query time, the system retrieves top-k dense neighbors for each type, merges results with simple set operations, and provides the most relevant evidence as context to the model. ENGRAM attains state-of-the-art results on LoCoMo, a multi-session conversational QA benchmark for long-horizon memory, and exceeds the full-context baseline by 15 points on LongMemEval while using only about 1% of the tokens. These results show that careful memory typing and straightforward dense retrieval can enable effective long-term memory management in language models without requiring complex architectures.

</details>


### [494] [Reuse, Don't Recompute: Efficient Large Reasoning Model Inference via Memory Orchestration](https://arxiv.org/abs/2511.12987)
*Daivik Patel,Shrenik Patel*

Main category: cs.MA

TL;DR: ENGRAM-R是一种推理时内存层，通过类型化检索、紧凑的事实卡片表示和显式引用控制，显著减少输入和推理所需的令牌数量，同时保持高准确性，证明内存是高效推理的关键。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在测试时扩展虽然提高了准确性，但带来了高昂的令牌消耗和延迟。作者认为，当已有证据存在时，应通过重用结构化内存而非重新计算推导来减少思考成本，从而实现更高效的推理。

Method: 提出ENGRAM-R，一种集成类型化检索、紧凑事实卡片表示和显式引用控制的推理时内存层，在LoCoMo和LongMemEval基准上评估其效率与准确性。

Result: 在LoCoMo基准上，ENGRAM-R相比完整上下文减少了85%的输入令牌和75%的推理令牌，同时保持高准确率；在LongMemEval的多跳子集上也实现了类似的效率提升并有显著的准确率增益。

Conclusion: 内存不仅是长周期推理正确性的关键，也是在有限计算、内存和延迟预算下实现高效推理的实用手段。

Abstract: Large reasoning models (LRMs) achieve strong accuracy through test-time scaling, generating longer chains of thought or sampling multiple solutions, but at steep costs in tokens and latency. We argue that memory is a core ingredient for efficient reasoning: when evidence already exists, models should think less by reusing structured memory instead of recomputing derivations. We present ENGRAM-R, an inference-time memory layer that integrates typed retrieval with compact fact card representations and explicit citation control. On the LoCoMo benchmark, ENGRAM-R reduces input tokens by 85% and reasoning tokens by 75% compared to full context while maintaining high accuracy. On a multi-hop slice of the LongMemEval benchmark, it achieves similar efficiency with substantial accuracy gains. These results show that memory is not only critical for long-horizon correctness but also a practical lever for efficient reasoning under tight compute, memory, and latency budgets.

</details>


### [495] [LLM-based Multi-Agent System for Simulating Strategic and Goal-Oriented Data Marketplaces](https://arxiv.org/abs/2511.13233)
*Jun Sashihara,Yukihisa Fujita,Kota Nakamura,Masahiro Kuwahara,Teruaki Hayashi*

Main category: cs.MA

TL;DR: 提出基于大语言模型的多智能体系统（LLM-MAS）用于模拟数据市场，通过买家与卖家智能体的自主决策更真实地再现实际交易模式和市场趋势演化。


<details>
  <summary>Details</summary>
Motivation: 现有数据市场模拟方法受限于预设规则，缺乏对参与者、数据与法规间复杂交互的系统性理解，难以反映真实市场动态。

Method: 构建基于大语言模型的多智能体系统（LLM-MAS），其中买家与卖家智能体具备明确目标，能自主进行规划、搜索、定价、购买等操作，并通过自然语言推理实现策略调整与市场预测。

Result: 实验使用三种基于分布的指标评估，结果表明LLM-MAS相比传统方法更能忠实还原真实数据市场的交易模式，并能捕捉市场趋势的生成与演变。

Conclusion: LLM-MAS为数据市场提供了更具适应性和表达力的模拟框架，展现出在复杂市场行为建模中的潜力。

Abstract: Data marketplaces, which mediate the purchase and exchange of data from third parties, have attracted growing attention for reducing the cost and effort of data collection while enabling the trading of diverse datasets. However, a systematic understanding of the interactions between market participants, data, and regulations remains limited. To address this gap, we propose a Large Language Model-based Multi-Agent System (LLM-MAS) for data marketplaces. In our framework, buyer and seller agents powered by LLMs operate with explicit objectives and autonomously perform strategic actions, such as planning, searching, purchasing, pricing, and updating data. These agents can reason about market dynamics, forecast future demand, and adjust strategies accordingly. Unlike conventional model-based simulations, which are typically constrained to predefined rules, LLM-MAS supports broader and more adaptive behavior selection through natural language reasoning. We evaluated the framework via simulation experiments using three distribution-based metrics: (1) the number of purchases per dataset, (2) the number of purchases per buyer, and (3) the number of repeated purchases of the same dataset. The results demonstrate that LLM-MAS more faithfully reproduces trading patterns observed in real data marketplaces compared to traditional approaches, and further captures the emergence and evolution of market trends.

</details>


### [496] [How Hard is it to Explain Preferences Using Few Boolean Attributes?](https://arxiv.org/abs/2511.13445)
*Clemens Anzinger,Jiehua Chen,Christian Hatschka,Manuel Sorge,Alexander Temper*

Main category: cs.MA

TL;DR: 研究了通过布尔属性模型（BAM）解释偏好数据的计算复杂性，发现当属性数k≤2时问题可在多项式时间内解决，而k≥3时为NP完全；问题在某些参数下是固定参数可解的，并分析了部分信息情况下的变体复杂性。


<details>
  <summary>Details</summary>
Motivation: 布尔属性模型在理解偏好结构和提升决策效率方面具有潜力，因此研究其解释偏好数据的能力及其计算复杂性具有重要意义。

Method: 通过理论分析建立关于属性数量k的复杂性 dichotomy，并探讨不同参数设置（如备选项数、投票者数）和部分信息条件下的计算复杂性。

Result: BAM问题在k≤2时线性时间可解，k≥3时NP完全；即使偏好序长度为2仍难解；以备选项数m为参数时固定参数可解；两投票者情形下存在线性时间算法。BAM WITH CARES通常更难，BAM WITH HAS更易处理，但单个投票者时仍为NP难。

Conclusion: 布尔属性模型的可解释性在小k值或特定条件下可行，但一般情况下计算困难，提示实际应用中需权衡模型简洁性与表达能力。

Abstract: We study the computational complexity of explaining preference data through Boolean attribute models (BAMs), motivated by extensive research involving attribute models and their promise in understanding preference structure and enabling more efficient decision-making processes. In a BAM, each alternative has a subset of Boolean attributes, each voter cares about a subset of attributes, and voters prefer alternatives with more of their desired attributes. In the BAM problem, we are given a preference profile and a number k, and want to know whether there is a Boolean k-attribute model explaining the profile.
  We establish a complexity dichotomy for the number of attributes k: BAM is linear-time solvable for $k \le 2$ but NP-complete for $k \ge 3$. The problem remains hard even when preference orders have length two. On the positive side, BAM becomes fixed-parameter tractable when parameterized by the number of alternatives m. For the special case of two voters, we provide a linear-time algorithm.
  We also analyze variants where partial information is given: When voter preferences over attributes are known (BAM WITH CARES) or when alternative attributes are specified (BAM WITH HAS), we show that for most parameters BAM WITH CARES is more difficult whereas BAM WITH HAS is more tractable except for being NP-hard even for one voter.

</details>


### [497] [Asymptotic analysis of cooperative censoring policies in sensor networks](https://arxiv.org/abs/2511.13492)
*Jesus Fernandez-Bes,Rocío Arroyo-Valles,Jesús Cid-Sueiro*

Main category: cs.MA

TL;DR: 本文研究了电池供电的多跳传感器网络中的协作数据审查问题，提出了一种基于马尔可夫决策过程的模型，并设计了能有效节省能量的协作审查策略。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的传感器网络中，如何通过审查低重要性消息来节约能量，延长网络寿命。

Method: 将问题建模为整个网络动态的联合马尔可夫决策过程，提出一种最优审查策略，并设计基于恒定阈值的近似规则和集中式阈值计算算法。

Result: 实验表明，所提出的协作审查策略比非协作方案更节能且性能更优。

Conclusion: 协作数据审查在多跳传感器网络中是有效的，可通过近似阈值规则实现接近最优的能量效率。

Abstract: The problem of cooperative data censoring in battery-powered multihop sensor networks is analyzed in this paper. We are interested in scenarios where nodes generate messages (which are related to the sensor measurements) that can be graded with some importance value. Less important messages can be censored in order to save energy for later communications. The problem is modeled using a joint Markov Decision Process of the whole network dynamics, and a theoretically optimal censoring policy, which maximizes a long-term reward, is found. Though the optimal censoring rules are computationally prohibitive, our analysis suggests that, under some conditions, they can be approximated by a finite collection of constant-threshold rules. A centralized algorithm for the computation of these thresholds is proposed. The experimental simulations show that cooperative censoring policies are energy-efficient, and outperform other non-cooperative schemes.

</details>


### [498] [Market-Dependent Communication in Multi-Agent Alpha Generation](https://arxiv.org/abs/2511.13614)
*Jerick Shi,Burton Hollifield*

Main category: cs.MA

TL;DR: 该研究通过5个LLM代理组成的交易系统在21个月内进行450次实验，比较了五种组织结构下的沟通模式对多策略对冲基金表现的影响，发现沟通方式的优劣取决于市场特征：竞争性对话在波动性强的科技股中表现最佳，协作性对话在稳定的普通股票中占优，而金融股则对所有沟通干预均不敏感。尽管不同结构最终趋于相似的策略取向，但绩效差异源于行为机制的不同，且对话质量与收益无相关性。


<details>
  <summary>Details</summary>
Motivation: 探讨多策略对冲基金中分析师之间是否应沟通以及如何设计最优沟通机制，以提升投资绩效。

Method: 构建基于5个LLM代理的交易系统，在450次实验中跨越21个月，比较隔离、协作和竞争等五种组织结构下的沟通模式对交易表现的影响。

Result: 沟通能提升整体表现，但最优设计依赖市场特性：竞争性沟通适合高波动科技股，协作性沟通适合稳定的一般股票，金融股对沟通无响应；所有结构最终策略趋同；绩效差异源于行为机制（如关注点不同），而对话质量与回报无关。

Conclusion: 最优沟通设计需匹配市场波动特征，复杂的讨论并不保证更高收益，透明化沟通不会显著损害策略多样性。

Abstract: Multi-strategy hedge funds face a fundamental organizational choice: should analysts generating trading strategies communicate, and if so, how? We investigate this using 5-agent LLM-based trading systems across 450 experiments spanning 21 months, comparing five organizational structures from isolated baseline to collaborative and competitive conversation. We show that communication improves performance, but optimal communication design depends on market characteristics. Competitive conversation excels in volatile technology stocks, while collaborative conversation dominates stable general stocks. Finance stocks resist all communication interventions. Surprisingly, all structures, including isolated agents, converge to similar strategy alignments, challenging assumptions that transparency causes harmful diversity loss. Performance differences stem from behavioral mechanisms: competitive agents focus on stock-level allocation while collaborative agents develop technical frameworks. Conversation quality scores show zero correlation with returns. These findings demonstrate that optimal communication design must match market volatility characteristics, and sophisticated discussions don't guarantee better performance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [499] [Hierarchical Federated Graph Attention Networks for Scalable and Resilient UAV Collision Avoidance](https://arxiv.org/abs/2511.11616)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.RO

TL;DR: 提出了一种分层架构，用于大规模多无人机系统中的实时、抗对抗且隐私保护的碰撞避免，具有低延迟、可扩展性和拜占庭容错能力。


<details>
  <summary>Details</summary>
Motivation: 现有框架计算复杂度高（O(n^2)），缺乏拜占庭容错，难以在实时性、安全性和隐私之间取得平衡。

Method: 采用三层分层架构：本地层使用密集图注意力实现<10ms延迟的即时避障；区域层采用稀疏注意力（O(nk)复杂度）和异步联邦学习结合坐标裁剪均值聚合；全局层使用轻量级Hashgraph启发协议；引入基于实时威胁评估动态调整的自适应差分隐私机制，并利用DHT实现轻量审计日志。

Result: 在500架无人机规模下实现<2.0%的碰撞率，支持f < n/3的拜占庭容错，95%决策在50ms内完成，计算成本显著降低。

Conclusion: 该分层框架有效平衡了实时性、隐私与安全性，具备良好的可扩展性和鲁棒性，适用于大规模多无人机系统的协同避障。

Abstract: The real-time performance, adversarial resiliency, and privacy preservation are the most important metrics that need to be balanced to practice collision avoidance in large-scale multi-UAV (Unmanned Aerial Vehicle) systems. Current frameworks tend to prescribe monolithic solutions that are not only prohibitively computationally complex with a scaling cost of $O(n^2)$ but simply do not offer Byzantine fault tolerance. The proposed hierarchical framework presented in this paper tries to eliminate such trade-offs by stratifying a three-layered architecture. We spread the intelligence into three layers: an immediate collision avoiding local layer running on dense graph attention with latency of $<10 ms$, a regional layer using sparse attention with $O(nk)$ computational complexity and asynchronous federated learning with coordinate-wise trimmed mean aggregation, and lastly, a global layer using a lightweight Hashgraph-inspired protocol. We have proposed an adaptive differential privacy mechanism, wherein the noise level $(ε\in [0.1, 1.0])$ is dynamically reduced based on an evaluation of the measured real-time threat that in turn maximized the privacy-utility tradeoff. Through the use of Distributed Hash Table (DHT)-based lightweight audit logging instead of heavyweight blockchain consensus, the median cost of getting a $95^{th}$ percentile decision within 50ms is observed across all tested swarm sizes. This architecture provides a scalable scenario of 500 UAVs with a collision rate of $< 2.0\%$ and the Byzantine fault tolerance of $f < n/3$.

</details>


### [500] [Tactile Data Recording System for Clothing with Motion-Controlled Robotic Sliding](https://arxiv.org/abs/2511.11634)
*Michikuni Eguchi,Takekazu Kitagishi,Yuichi Hiroi,Takefumi Hiraki*

Main category: cs.RO

TL;DR: 提出一种基于机械臂的系统，用于在控制速度和方向的情况下从完整衣物上采集触觉数据，生成带运动标签的多模态触觉数据库，并验证了运动相关参数对识别衣物触感的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了揭示影响服装舒适性的物理特性，需要系统地采集服装在滑动过程中的触觉数据，现有方法缺乏对完整衣物的非破坏性、可扩展的触觉数据采集手段。

Method: 开发了一种基于 robotic arm 的系统，使用模拟指尖对完整衣物进行划动测量，精确控制运动速度和方向，采集包括音频和加速度在内的多模态触觉数据，并引入运动相关参数作为标签。

Result: 机器学习评估表明，加入运动相关参数后，音频和加速度数据的识别准确率提高，证明运动标签有助于更好表征衣物的触觉感受；该系统实现了对完整衣物的可扩展、非破坏性触觉数据采集。

Conclusion: 该系统为研究织物感知与再现提供了有效的工具，推动了基于多模态数据的智能纺织品研究发展。

Abstract: The tactile sensation of clothing is critical to wearer comfort. To reveal physical properties that make clothing comfortable, systematic collection of tactile data during sliding motion is required. We propose a robotic arm-based system for collecting tactile data from intact garments. The system performs stroking measurements with a simulated fingertip while precisely controlling speed and direction, enabling creation of motion-labeled, multimodal tactile databases. Machine learning evaluation showed that including motion-related parameters improved identification accuracy for audio and acceleration data, demonstrating the efficacy of motion-related labels for characterizing clothing tactile sensation. This system provides a scalable, non-destructive method for capturing tactile data of clothing, contributing to future studies on fabric perception and reproduction.

</details>


### [501] [Image-based Morphological Characterization of Filamentous Biological Structures with Non-constant Curvature Shape Feature](https://arxiv.org/abs/2511.11639)
*Jie Fan,Francesco Visentin,Barbara Mazzolai,Emanuela Del Dottore*

Main category: cs.RO

TL;DR: 提出一种基于图像和分段Clothoid模型的几何方法，用于分析植物卷须在机械刺激下的形态变化，揭示其顶端区域具有更高响应性，并为受攀爬植物启发的智能机器人系统设计提供基础。


<details>
  <summary>Details</summary>
Motivation: 研究植物卷须在机械刺激下形态随时间变化的关系及其触发机制和接触位置的影响，目前仍具挑战性。

Method: 采用基于3D分段Clothoid模型的几何方法，结合图像分析，重建机械摩擦后卷须的形态变化。

Result: 该方法具有高鲁棒性和可靠性（R² > 0.99），优于深度学习方法，显示出卷须顶端段响应更强，可能与其更高的敏感性和组织柔韧性有关。

Conclusion: 所提方法为研究植物生物力学提供了新工具，并为仿生智能机器人系统的开发奠定了基础。

Abstract: Tendrils coil their shape to anchor the plant to supporting structures, allowing vertical growth toward light. Although climbing plants have been studied for a long time, extracting information regarding the relationship between the temporal shape change, the event that triggers it, and the contact location is still challenging. To help build this relation, we propose an image-based method by which it is possible to analyze shape changes over time in tendrils when mechano-stimulated in different portions of their body. We employ a geometric approach using a 3D Piece-Wise Clothoid-based model to reconstruct the configuration taken by a tendril after mechanical rubbing. The reconstruction shows high robustness and reliability with an accuracy of R2 > 0.99. This method demonstrates distinct advantages over deep learning-based approaches, including reduced data requirements, lower computational costs, and interpretability. Our analysis reveals higher responsiveness in the apical segment of tendrils, which might correspond to higher sensitivity and tissue flexibility in that region of the organs. Our study provides a methodology for gaining new insights into plant biomechanics and offers a foundation for designing and developing novel intelligent robotic systems inspired by climbing plants.

</details>


### [502] [ExpertAD: Enhancing Autonomous Driving Systems with Mixture of Experts](https://arxiv.org/abs/2511.11740)
*Haowen Jiang,Xinyu Huang,You Lu,Dingji Wang,Yuheng Cao,Chaofeng Sha,Bihuan Chen,Keyu Chen,Xin Peng*

Main category: cs.RO

TL;DR: 本文提出ExpertAD，一种基于Mixture of Experts架构的端到端自动驾驶系统，通过感知适配器和稀疏专家混合模块提升决策可靠性与规划效率，显著降低碰撞率和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶系统在复杂场景中面临语义模糊、多任务干扰和推理延迟等问题，影响决策可靠性与安全性。

Method: 提出ExpertAD框架，引入感知适配器（PA）增强关键特征，利用稀疏专家混合（MoSE）减少任务干扰，并结合MoE架构实现高效推理与多技能规划。

Result: 实验显示ExpertAD相比先前方法平均碰撞率降低20%，推理延迟减少25%，并在罕见场景和未见城市环境中展现出良好泛化能力。

Conclusion: ExpertAD有效提升了自动驾驶系统的安全性、效率和泛化性能，为复杂驾驶场景下的可靠决策提供了可行解决方案。

Abstract: Recent advancements in end-to-end autonomous driving systems (ADSs) underscore their potential for perception and planning capabilities. However, challenges remain. Complex driving scenarios contain rich semantic information, yet ambiguous or noisy semantics can compromise decision reliability, while interference between multiple driving tasks may hinder optimal planning. Furthermore, prolonged inference latency slows decision-making, increasing the risk of unsafe driving behaviors. To address these challenges, we propose ExpertAD, a novel framework that enhances the performance of ADS with Mixture of Experts (MoE) architecture. We introduce a Perception Adapter (PA) to amplify task-critical features, ensuring contextually relevant scene understanding, and a Mixture of Sparse Experts (MoSE) to minimize task interference during prediction, allowing for effective and efficient planning. Our experiments show that ExpertAD reduces average collision rates by up to 20% and inference latency by 25% compared to prior methods. We further evaluate its multi-skill planning capabilities in rare scenarios (e.g., accidents, yielding to emergency vehicles) and demonstrate strong generalization to unseen urban environments. Additionally, we present a case study that illustrates its decision-making process in complex driving scenarios.

</details>


### [503] [Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy: A Review](https://arxiv.org/abs/2511.11777)
*Vinit Mehta,Charu Sharma,Karthick Thiyagarajan*

Main category: cs.RO

TL;DR: 本文综述了大型语言模型（LLMs）与3D视觉在机器人感知技术中的融合，探讨了其在场景理解、文本到3D生成、物体定位和具身智能体等方面的应用与挑战。


<details>
  <summary>Details</summary>
Motivation: 推动下一代机器人感知技术的发展，通过结合LLMs与3D视觉实现更高级的环境感知与交互能力。

Method: 综述现有文献，分析LLMs与3D数据表示的基础原理，探讨多模态融合方法及关键技术进展。

Result: 总结了在零样本3D分割、动态场景合成和语言引导操作等方面的前沿进展，并整理了适用于3D-语言任务的基准数据集与评估指标。

Conclusion: LLMs与3D视觉的融合为智能、情境感知和自主机器人系统提供了重要发展方向，但仍需解决跨模态对齐、实时处理和自适应架构等挑战。

Abstract: With the rapid advancement of artificial intelligence and robotics, the integration of Large Language Models (LLMs) with 3D vision is emerging as a transformative approach to enhancing robotic sensing technologies. This convergence enables machines to perceive, reason and interact with complex environments through natural language and spatial understanding, bridging the gap between linguistic intelligence and spatial perception. This review provides a comprehensive analysis of state-of-the-art methodologies, applications and challenges at the intersection of LLMs and 3D vision, with a focus on next-generation robotic sensing technologies. We first introduce the foundational principles of LLMs and 3D data representations, followed by an in-depth examination of 3D sensing technologies critical for robotics. The review then explores key advancements in scene understanding, text-to-3D generation, object grounding and embodied agents, highlighting cutting-edge techniques such as zero-shot 3D segmentation, dynamic scene synthesis and language-guided manipulation. Furthermore, we discuss multimodal LLMs that integrate 3D data with touch, auditory and thermal inputs, enhancing environmental comprehension and robotic decision-making. To support future research, we catalog benchmark datasets and evaluation metrics tailored for 3D-language and vision tasks. Finally, we identify key challenges and future research directions, including adaptive model architectures, enhanced cross-modal alignment and real-time processing capabilities, which pave the way for more intelligent, context-aware and autonomous robotic sensing systems.

</details>


### [504] [LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy in Self-Driving Vehicles](https://arxiv.org/abs/2511.11840)
*Shuangyu Xie,Kaiyuan Chen,Wenjing Chen,Chengyuan Qian,Christian Juette,Liu Ren,Dezhen Song,Ken Goldberg*

Main category: cs.RO

TL;DR: 提出了一种名为LAVQA的延迟感知共享自主框架，结合视觉问答（VQA）和时空风险可视化，通过动态演化的碰撞地图（LICOM）帮助远程操作员在高不确定性下为自动驾驶车辆提供及时决策支持，在CARLA仿真中碰撞率降低8倍以上。


<details>
  <summary>Details</summary>
Motivation: 在高不确定性环境下，自动驾驶车辆可能因安全原因停止，需要远程人类操作员提供高层指导；但无线网络延迟和人类响应时间导致决策时机关键，现有方法缺乏对延迟与空间不确定性的联合建模。

Method: 提出LAVQA框架，将视觉问答（VQA）与新引入的延迟诱导碰撞图（LICOM）结合，LICOM动态表示时间延迟和空间不确定性，使远程操作员能观察到车辆安全区域随时间的变化，从而做出更准确的决策。

Result: 在CARLA仿真环境中进行闭环测试，结果表明LAVQA相比忽略延迟的基线方法可将碰撞率降低8倍以上。

Conclusion: LAVQA通过显式建模通信延迟与环境动态性，提升了共享自主系统在真实延迟条件下的安全性与响应能力，验证了延迟感知机制在远程人机协作中的有效性。

Abstract: When uncertainty is high, self-driving vehicles may halt for safety and benefit from the access to remote human operators who can provide high-level guidance. This paradigm, known as {shared autonomy}, enables autonomous vehicle and remote human operators to jointly formulate appropriate responses. To address critical decision timing with variable latency due to wireless network delays and human response time, we present LAVQA, a latency-aware shared autonomy framework that integrates Visual Question Answering (VQA) and spatiotemporal risk visualization. LAVQA augments visual queries with Latency-Induced COllision Map (LICOM), a dynamically evolving map that represents both temporal latency and spatial uncertainty. It enables remote operator to observe as the vehicle safety regions vary over time in the presence of dynamic obstacles and delayed responses. Closed-loop simulations in CARLA, the de-facto standard for autonomous vehicle simulator, suggest that that LAVQA can reduce collision rates by over 8x compared to latency-agnostic baselines.

</details>


### [505] [Autonomous Underwater Cognitive System for Adaptive Navigation: A SLAM-Integrated Cognitive Architecture](https://arxiv.org/abs/2511.11845)
*K. A. I. N Jayarathne,R. M. N. M. Rathnayaka,D. P. S. S. Peiris*

Main category: cs.RO

TL;DR: 提出了一种结合SLAM与Soar认知架构的自主水下认知系统（AUCS），实现复杂海洋环境中的自适应导航。


<details>
  <summary>Details</summary>
Motivation: 深海探索面临失定向、通信中断和导航失败等挑战，需要更智能、可靠的自主导航系统。

Method: 将SLAM与Soar认知架构结合，融合SONAR、LiDAR、IMU和DVL多传感器数据，引入语义理解、自适应传感器管理和基于记忆的学习机制。

Result: 实现了感知-认知-行动-学习闭环，能区分动态与静态物体，减少错误回环闭合，提升长期地图一致性。

Conclusion: 所提出的AUCS为下一代认知型潜水系统奠定了基础，显著提升了深海探索的安全性、可靠性和自主性。

Abstract: Deep-sea exploration poses significant challenges, including disorientation, communication loss, and navigational failures in dynamic underwater environments. This paper presents an Autonomous Underwater Cognitive System (AUCS) that integrates Simultaneous Localization and Mapping (SLAM) with a Soar-based cognitive architecture to enable adaptive navigation in complex oceanic conditions. The system fuses multi-sensor data from SONAR, LiDAR, IMU, and DVL with cognitive reasoning modules for perception, attention, planning, and learning. Unlike conventional SLAM systems, AUCS incorporates semantic understanding, adaptive sensor management, and memory-based learning to differentiate between dynamic and static objects, reducing false loop closures and enhancing long-term map consistency. The proposed architecture demonstrates a complete perception-cognition-action-learning loop, allowing autonomous underwater vehicles to sense, reason, and adapt intelligently. This work lays a foundation for next-generation cognitive submersible systems, improving safety, reliability, and autonomy in deep-sea exploration.

</details>


### [506] [MATT-Diff: Multimodal Active Target Tracking by Diffusion Policy](https://arxiv.org/abs/2511.11931)
*Saida Liu,Nikolay Atanasov,Shumon Koga*

Main category: cs.RO

TL;DR: 本文提出了MATT-Diff，一种基于扩散策略的多模态主动目标跟踪方法，能够在无需先验知识的情况下实现多目标的探索、跟踪与重捕获。


<details>
  <summary>Details</summary>
Motivation: 主动多目标跟踪需要在探索未检测目标和跟踪已检测但不确定目标之间取得平衡，现有方法通常依赖目标数量或动态模型的先验知识，限制了实际应用。

Method: 通过三种专家规划器生成演示数据集，并设计基于视觉Transformer和注意力机制的扩散策略模型，将环境地图标记化并融合可变目标估计（高斯密度），以学习多模态动作序列的去噪过程。

Result: 实验表明，MATT-Diff在多种目标运动场景下优于专家策略和行为克隆基线方法，展现出更强的目标跟踪性能。

Conclusion: MATT-Diff能够有效整合多种行为模式，在未知目标数量和动态的情况下实现鲁棒的主动多目标跟踪。

Abstract: This paper proposes MATT-Diff: Multi-Modal Active Target Tracking by Diffusion Policy, a control policy that captures multiple behavioral modes - exploration, dedicated tracking, and target reacquisition - for active multi-target tracking. The policy enables agent control without prior knowledge of target numbers, states, or dynamics. Effective target tracking demands balancing exploration for undetected or lost targets with following the motion of detected but uncertain ones. We generate a demonstration dataset from three expert planners including frontier-based exploration, an uncertainty-based hybrid planner switching between frontier-based exploration and RRT* tracking based on target uncertainty, and a time-based hybrid planner switching between exploration and tracking based on target detection time. We design a control policy utilizing a vision transformer for egocentric map tokenization and an attention mechanism to integrate variable target estimates represented by Gaussian densities. Trained as a diffusion model, the policy learns to generate multi-modal action sequences through a denoising process. Evaluations demonstrate MATT-Diff's superior tracking performance against expert and behavior cloning baselines across multiple target motions, empirically validating its advantages in target tracking.

</details>


### [507] [Characterization and Evaluation of Screw-Based Locomotion Across Aquatic, Granular, and Transitional Media](https://arxiv.org/abs/2511.11958)
*Derek Chen,Zoe Samuels,Lizzie Peiros,Sujaan Mukherjee,Michael C. Yip*

Main category: cs.RO

TL;DR: 本研究系统地探讨了不同螺旋结构在干沙、湿沙、饱和沙和水等介质中的运动性能，发现特定参数对性能有主导影响，并利用散热器优化设计的启发式参数来分类这些性能。


<details>
  <summary>Details</summary>
Motivation: 解决螺旋推进系统在水、颗粒材料及过渡环境之间运动时的性能优化难题。

Method: 采用基于原理的分析方法，研究多种螺旋构型在不同介质中的运动表现，并引入受散热器设计优化启发的衍生参数。

Result: 识别出影响螺旋运动性能的关键参数，并提出可根据介质类型分类性能的衍生参数，为螺旋壳体设计和自适应运动策略提供依据。

Conclusion: 该研究为提升螺旋推进系统在多变两栖环境中的运动性能提供了具体的设计指导和策略支持。

Abstract: Screw-based propulsion systems offer promising capabilities for amphibious mobility, yet face significant challenges in optimizing locomotion across water, granular materials, and transitional environments. This study presents a systematic investigation into the locomotion performance of various screw configurations in media such as dry sand, wet sand, saturated sand, and water. Through a principles-first approach to analyze screw performance, it was found that certain parameters are dominant in their impact on performance. Depending on the media, derived parameters inspired from optimizing heat sink design help categorize performance within the dominant design parameters. Our results provide specific insights into screw shell design and adaptive locomotion strategies to enhance the performance of screw-based propulsion systems for versatile amphibious applications.

</details>


### [508] [Bootstrapped LLM Semantics for Context-Aware Path Planning](https://arxiv.org/abs/2511.11967)
*Mani Amani,Behrad Beheshti,Reza Akhavian*

Main category: cs.RO

TL;DR: 提出一种利用大语言模型（LLM）作为随机语义传感器的框架，通过自然语言提示和语义地图生成风险感知的路径规划，使机器人能在人类中心环境中更安全、高效地运动。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注自然语言用于任务选择或技能序列生成，而忽视了如何在语义丰富的人类环境中安全高效执行任务。本文旨在填补这一空白，提升机器人对环境语义风险的理解与响应能力。

Method: 将大语言模型（LLM）作为语义传感器，结合自然语言提示和语义地图，多次采样LLM的‘危险’判断，并使用贝叶斯自助法估计每类对象的风险后验分布，基于该分布统计信息构建势能成本以优化路径规划。

Result: 在模拟环境和BIM支持的数字孪生场景中验证了方法的有效性，结果显示机器人能够根据显式提示和隐含上下文动态调整运动行为，实现了更安全、适应性更强的导航。

Conclusion: 该框架成功融合了大语言模型的语义推理能力与经典规划器的可靠性，为自然语言引导下的安全机器人导航提供了可量化风险感知的新范式。

Abstract: Prompting robots with natural language (NL) has largely been studied as what task to execute (goal selection, skill sequencing) rather than how to execute that task safely and efficiently in semantically rich, human-centric spaces. We address this gap with a framework that turns a large language model (LLM) into a stochastic semantic sensor whose outputs modulate a classical planner. Given a prompt and a semantic map, we draw multiple LLM "danger" judgments and apply a Bayesian bootstrap to approximate a posterior over per-class risk. Using statistics from the posterior, we create a potential cost to formulate a path planning problem. Across simulated environments and a BIM-backed digital twin, our method adapts how the robot moves in response to explicit prompts and implicit contextual information. We present qualitative and quantitative results.

</details>


### [509] [ARCSnake V2: An Amphibious Multi-Domain Screw-Propelled Snake-Like Robot](https://arxiv.org/abs/2511.11970)
*Sara Wickenhiser,Lizzie Peiros,Calvin Joyce,Peter Gavrilrov,Sujaan Mukherjee,Syler Sylvester,Junrong Zhou,Mandy Cheung,Jason Lim,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: 本文提出了一种名为ARCSnake V2的两栖、螺旋推进式蛇形机器人，能够在陆地、颗粒介质和水下环境中实现高效移动，具备多种运动模式和良好的过渡能力。


<details>
  <summary>Details</summary>
Motivation: 传统轮式或足式机器人在复杂多变的极端环境中（如洞穴、海洋和行星表面）移动能力受限，因此需要开发一种适应多种地形的高机动性机器人。

Method: 设计并实现了ARCSnake V2机器人，采用阿基米德螺旋推进与蛇形结构结合的方式，具备密封机械结构、浮力控制系统及运动模式切换能力，并通过匹配运动学的手持控制器实现遥操作。

Result: 实验验证了该机器人在水下的机动性、通信鲁棒性和力调节驱动性能，展示了其在多种环境下的运动能力和稳定性。

Conclusion: ARCSnake V2是一种适用于多域环境探索、搜救和环境监测的多功能机器人平台。

Abstract: Robotic exploration in extreme environments such as caves, oceans, and planetary surfaces pose significant challenges, particularly in locomotion across diverse terrains. Conventional wheeled or legged robots often struggle in these contexts due to surface variability. This paper presents ARCSnake V2, an amphibious, screw propelled, snake like robot designed for teleoperated or autonomous locomotion across land, granular media, and aquatic environments. ARCSnake V2 combines the high mobility of hyper redundant snake robots with the terrain versatility of Archimedean screw propulsion. Key contributions include a water sealed mechanical design with serially linked screw and joint actuation, an integrated buoyancy control system, and teleoperation via a kinematically matched handheld controller. The robots design and control architecture enable multiple locomotion modes screwing, wheeling, and sidewinding with smooth transitions between them. Extensive experiments validate its underwater maneuverability, communication robustness, and force regulated actuation. These capabilities position ARCSnake V2 as a versatile platform for exploration, search and rescue, and environmental monitoring in multi domain settings.

</details>


### [510] [SBAMP: Sampling Based Adaptive Motion Planning](https://arxiv.org/abs/2511.12022)
*Anh-Quan Pham,Kabir Ram Puri,Shreyas Raorane*

Main category: cs.RO

TL;DR: 本文提出了一种名为SBAMP的新型运动规划框架，结合RRT*全局路径规划与基于SEDS的局部自适应控制，无需预训练数据即可实现实时动态环境中的稳定、平滑轨迹调整，并在仿真和真实机器人平台上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统采样方法难以实时适应动态变化，而学习型动力系统依赖演示数据、泛化能力有限，因此需要一种兼具全局优化与局部自适应能力且不依赖预训练数据的运动规划方法。

Method: 将RRT*用于全局路径规划，结合基于SEDS的局部控制器进行实时轨迹调整，通过李雅普诺夫函数保证系统稳定性，并实现全局路径与局部响应的无缝集成。

Result: 在仿真和真实机器人（RoboRacer）平台上验证了SBAMP在动态障碍物、外部扰动和急转弯场景下的优异表现，具备快速恢复能力、实时适应性以及对复杂环境的良好鲁棒性。

Conclusion: SBAMP有效融合了采样规划与学习型动力系统的优点，无需预训练数据，兼具全局最优性和局部自适应性，为非结构化动态环境中的自主机器人导航提供了可扩展的解决方案。

Abstract: Autonomous robotic systems must navigate complex, dynamic environments in real time, often facing unpredictable obstacles and rapidly changing conditions. Traditional sampling-based methods, such as RRT*, excel at generating collision-free paths but struggle to adapt to sudden changes without extensive replanning. Conversely, learning-based dynamical systems, such as the Stable Estimator of Dynamical Systems (SEDS), offer smooth, adaptive trajectory tracking but typically rely on pre-collected demonstration data, limiting their generalization to novel scenarios. This paper introduces Sampling-Based Adaptive Motion Planning (SBAMP), a novel framework that overcomes these limitations by integrating RRT* for global path planning with a SEDS-based local controller for continuous, adaptive trajectory adjustment. Our approach requires no pre-trained datasets and ensures smooth transitions between planned waypoints, maintaining stability through Lyapunov-based guarantees. We validate SBAMP in both simulated environments and real hardware using the RoboRacer platform, demonstrating superior performance in dynamic obstacle scenarios, rapid recovery from perturbations, and robust handling of sharp turns. Experimental results highlight SBAMP's ability to adapt in real time without sacrificing global path optimality, providing a scalable solution for dynamic, unstructured environments.

</details>


### [511] [Decoupled Action Head: Confining Task Knowledge to Conditioning Layers](https://arxiv.org/abs/2511.12101)
*Jian Zhou,Sihao Lin,Shuai Fu,Qi WU*

Main category: cs.RO

TL;DR: 本文提出了一种解耦训练方法，利用无观测的运动学生成轨迹预训练动作头，并通过特征调制适应新任务，在保持性能的同时显著提升训练效率；受此启发，进一步提出DP-MLP，用仅4M参数的MLP替代原244M参数U-Net骨干网络，在机器人操作中实现高效训练与相当性能。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法（如Diffusion Policy）受限于配对训练数据稀缺，且其有效性机制理解不足，导致泛化能力有限和模型设计缺乏原则性。

Method: 提出解耦训练策略：使用无观测的运动学轨迹预训练动作头并冻结，通过特征调制适应新任务；进一步引入DP-MLP，用轻量MLP替代复杂U-Net骨干网络。

Result: 该方法在分布内和分布外任务上均验证可行，解耦训练使DP-C提速41%；DP-MLP在常规训练下提速83.9%，解耦下提速89.1%，且性能接近原模型。

Conclusion: 动作生成骨干在网络中的作用有限，任务特定知识主要集中于条件模块，因此可通过轻量化架构实现高效、可扩展的行为克隆。

Abstract: Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

</details>


### [512] [Towards Obstacle-Avoiding Control of Planar Snake Robots Exploring Neuro-Evolution of Augmenting Topologies](https://arxiv.org/abs/2511.12148)
*Advik Sinha,Akshay Arjun,Abhijit Das,Joyjit Mukherjee*

Main category: cs.RO

TL;DR: 本文提出了一种基于NEAT（增强拓扑的神经进化）算法的平面蛇形机器人避障跟踪控制方法，通过优化serpenoid步态参数实现动态路径控制，具有较低的计算开销并在密集障碍环境中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 在密集障碍环境中实现资源高效、动态且鲁棒的蛇形机器人运动控制，克服传统方法计算复杂度高或适应性差的问题。

Method: 采用NEAT进化算法生成serpenoid步态的频率和偏移角参数，输入包括关节角度、连杆位置、障碍物信息等，结合LiDAR与传感器数据构建奖励函数，在PyBullet物理引擎中进行仿真优化。

Result: 该方法在大尺度多障碍环境中表现出较高的计算效率，避障与跟踪性能优于现有先进方法，与最新的CBRL方法性能相当但计算开销显著更低。

Conclusion: NEAT框架能有效应用于蛇形机器人的动态避障控制，兼顾性能与资源效率，适用于复杂环境下的实际部署。

Abstract: This work aims to develop a resource-efficient solution for obstacle-avoiding tracking control of a planar snake robot in a densely cluttered environment with obstacles. Particularly, Neuro-Evolution of Augmenting Topologies (NEAT) has been employed to generate dynamic gait parameters for the serpenoid gait function, which is implemented on the joint angles of the snake robot, thus controlling the robot on a desired dynamic path. NEAT is a single neural-network based evolutionary algorithm that is known to work extremely well when the input layer is of significantly higher dimension and the output layer is of a smaller size. For the planar snake robot, the input layer consists of the joint angles, link positions, head link position as well as obstacle positions in the vicinity. However, the output layer consists of only the frequency and offset angle of the serpenoid gait that control the speed and heading of the robot, respectively. Obstacle data from a LiDAR and the robot data from various sensors, along with the location of the end goal and time, are employed to parametrize a reward function that is maximized over iterations by selective propagation of superior neural networks. The implementation and experimental results showcase that the proposed approach is computationally efficient, especially for large environments with many obstacles. The proposed framework has been verified through a physics engine simulation study on PyBullet. The approach shows superior results to existing state-of-the-art methodologies and comparable results to the very recent CBRL approach with significantly lower computational overhead. The video of the simulation can be found here: https://sites.google.com/view/neatsnakerobot

</details>


### [513] [Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)](https://arxiv.org/abs/2511.12160)
*Wenbin Mai,Minghui Liwang,Xinlei Yi,Xiaoyu Xia,Seyyedali Hosseinalipour,Xianbin Wang*

Main category: cs.RO

TL;DR: 提出了一种可达性增强的动态势博弈（RE-DPG）框架，用于多智能体系统在动态不确定环境中的安全、鲁棒和可扩展运动规划。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中由于智能体间复杂交互、随机扰动和模型不确定性带来的运动规划挑战，特别是耦合决策的计算复杂性和对主动安全保证的需求。

Method: 将多智能体协调建模为动态势博弈，采用纳什均衡定义最优控制策略；设计基于局部交互的邻域主导迭代最佳响应（ND-iBR）算法，确保有限步内收敛到ε-纳什均衡；并通过集成多智能体前向可达集（MA-FRS）机制，在成本函数中显式建模不确定性传播并强制避障约束。

Result: 在2D和3D环境中的仿真和真实实验验证了RE-DPG在不同操作场景下的有效性，实现了安全、可扩展且去中心化的多智能体运动规划。

Conclusion: RE-DPG框架有效结合了博弈论协调与可达性分析，提供了理论收敛与安全保证，适用于复杂动态环境下的多智能体系统运动规划。

Abstract: Ensuring safe, robust, and scalable motion planning for multi-agent systems in dynamic and uncertain environments is a persistent challenge, driven by complex inter-agent interactions, stochastic disturbances, and model uncertainties. To overcome these challenges, particularly the computational complexity of coupled decision-making and the need for proactive safety guarantees, we propose a Reachability-Enhanced Dynamic Potential Game (RE-DPG) framework, which integrates game-theoretic coordination into reachability analysis. This approach formulates multi-agent coordination as a dynamic potential game, where the Nash equilibrium (NE) defines optimal control strategies across agents. To enable scalability and decentralized execution, we develop a Neighborhood-Dominated iterative Best Response (ND-iBR) scheme, built upon an iterated $\varepsilon$-BR (i$\varepsilon$-BR) process that guarantees finite-step convergence to an $\varepsilon$-NE. This allows agents to compute strategies based on local interactions while ensuring theoretical convergence guarantees. Furthermore, to ensure safety under uncertainty, we integrate a Multi-Agent Forward Reachable Set (MA-FRS) mechanism into the cost function, explicitly modeling uncertainty propagation and enforcing collision avoidance constraints. Through both simulations and real-world experiments in 2D and 3D environments, we validate the effectiveness of RE-DPG across diverse operational scenarios.

</details>


### [514] [Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance](https://arxiv.org/abs/2511.12184)
*Jun Huo,Kehan Xu,Chengyao Li,Yu Cao,Jie Zuo,Xinxing Chen,Jian Huang*

Main category: cs.RO

TL;DR: 提出一种用于超冗余机器人腿系统的混合位置/力阻抗控制方法，通过可变阻抗控制提升人机交互安全性与适应性。


<details>
  <summary>Details</summary>
Motivation: 解决浮动基座超冗余机器人腿系统在内外扰动下力控制的安全性问题，特别是应对强内部干扰和未知环境扰动。

Method: 建立松耦合SRL的动力学模型，设计适用于动态扭矩输入的混合位置/力阻抗控制器，并提出一种高效的可变阻抗控制（VIC）方法，结合实时稳定性保证的阻抗参数生成网络。

Result: 仿真与实验验证了该系统能在柔性状态保持信号平滑过渡，在刚性状态提供强支撑力，有效缓解冲击并适应不同步态变化。

Conclusion: 所提方法显著提升了人机系统的安全性和适应性，为个体步态差异下的交互提供了实用解决方案。

Abstract: In human-robot systems, ensuring safety during force control in the presence of both internal and external disturbances is crucial. As a typical loosely coupled floating-base robot system, the supernumerary robotic leg (SRL) system is particularly susceptible to strong internal disturbances. To address the challenge posed by floating base, we investigated the dynamics model of the loosely coupled SRL and designed a hybrid position/force impedance controller to fit dynamic torque input. An efficient variable impedance control (VIC) method is developed to enhance human-robot interaction, particularly in scenarios involving external force disturbances. By dynamically adjusting impedance parameters, VIC improves the dynamic switching between rigidity and flexibility, so that it can adapt to unknown environmental disturbances in different states. An efficient real-time stability guaranteed impedance parameters generating network is specifically designed for the proposed SRL, to achieve shock mitigation and high rigidity supporting. Simulations and experiments validate the system's effectiveness, demonstrating its ability to maintain smooth signal transitions in flexible states while providing strong support forces in rigid states. This approach provides a practical solution for accommodating individual gait variations in interaction, and significantly advances the safety and adaptability of human-robot systems.

</details>


### [515] [Innovative Design of Multi-functional Supernumerary Robotic Limbs with Ellipsoid Workspace Optimization](https://arxiv.org/abs/2511.12186)
*Jun Huo,Jian Huang,Jie Zuo,Bo Yang,Zhongzheng Fu,Xi Li,Samer Mohammed*

Main category: cs.RO

TL;DR: 提出了一种多目标优化设计理论，用于超冗余机器人肢体（SRL）的设计，综合考虑抓取和行走工作空间、坐-站支撑力及质量惯性，并引入改进的萤火虫算法优化，实验验证了其在健康人和偏瘫患者中的有效性。


<details>
  <summary>Details</summary>
Motivation: 设计通用型SRL面临上下肢功能需求差异大的挑战，需统一理论框架以兼顾康复与功能增强。

Method: 采用多目标优化（MOO）设计理论，结合椭球包络法量化工作空间，引入坐-站静态支撑力评估力传递效率，并提出多子群修正萤火虫算法以提升高维非规则帕累托前沿的收敛性。

Result: 优化后抓取成功率平均提高7.2%，行走和坐-站任务中肌肉活动分别降低12.7%和25.1%。

Conclusion: 该设计理论为多功能SRL机构提供了一种高效可行的设计方案。

Abstract: Supernumerary robotic limbs (SRLs) offer substantial potential in both the rehabilitation of hemiplegic patients and the enhancement of functional capabilities for healthy individuals. Designing a general-purpose SRL device is inherently challenging, particularly when developing a unified theoretical framework that meets the diverse functional requirements of both upper and lower limbs. In this paper, we propose a multi-objective optimization (MOO) design theory that integrates grasping workspace similarity, walking workspace similarity, braced force for sit-to-stand (STS) movements, and overall mass and inertia. A geometric vector quantification method is developed using an ellipsoid to represent the workspace, aiming to reduce computational complexity and address quantification challenges. The ellipsoid envelope transforms workspace points into ellipsoid attributes, providing a parametric description of the workspace. Furthermore, the STS static braced force assesses the effectiveness of force transmission. The overall mass and inertia restricts excessive link length. To facilitate rapid and stable convergence of the model to high-dimensional irregular Pareto fronts, we introduce a multi-subpopulation correction firefly algorithm. This algorithm incorporates a strategy involving attractive and repulsive domains to effectively handle the MOO task. The optimized solution is utilized to redesign the prototype for experimentation to meet specified requirements. Six healthy participants and two hemiplegia patients participated in real experiments. Compared to the pre-optimization results, the average grasp success rate improved by 7.2%, while the muscle activity during walking and STS tasks decreased by an average of 12.7% and 25.1%, respectively. The proposed design theory offers an efficient option for the design of multi-functional SRL mechanisms.

</details>


### [516] [Locally Optimal Solutions to Constraint Displacement Problems via Path-Obstacle Overlaps](https://arxiv.org/abs/2511.12203)
*Antony Thomas,Fulvio Mastrogiovanni,Marco Baglietto*

Main category: cs.RO

TL;DR: 提出了一种统一的机器人约束位移问题解决方法，通过两阶段过程找到可行路径。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在复杂环境中因障碍物阻碍而无法规划可行路径的问题。

Method: 采用两阶段方法：第一阶段计算穿过障碍物的轨迹并优化目标函数；第二阶段移动障碍物使轨迹无碰撞。

Result: 在两类不同的约束位移问题上验证了该方法的有效性，成功实现了可行路径规划。

Conclusion: 该方法能有效处理约束位移问题，生成局部最优的障碍物位移方案。

Abstract: We present a unified approach for constraint displacement problems in which a robot finds a feasible path by displacing constraints or obstacles. To this end, we propose a two stage process that returns locally optimal obstacle displacements to enable a feasible path for the robot. The first stage proceeds by computing a trajectory through the obstacles while minimizing an appropriate objective function. In the second stage, these obstacles are displaced to make the computed robot trajectory feasible, that is, collision-free. Several examples are provided that successfully demonstrate our approach on two distinct classes of constraint displacement problems.

</details>


### [517] [SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation](https://arxiv.org/abs/2511.12232)
*Lingfeng Zhang,Erjia Xiao,Xiaoshuai Hao,Haoxiang Fu,Zeying Gong,Long Chen,Xiaojun Liang,Renjing Xu,Hangjun Ye,Wenbo Ding*

Main category: cs.RO

TL;DR: 提出了一种名为SocialNav-Map的零样本社会导航框架，结合动态人类轨迹预测与占据地图，实现无需环境特定训练的安全高效导航。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的社会导航方法需要大量训练时间且难以泛化到新环境，限制了其在真实场景中的应用。

Method: 将目标位置转换到构建的地图坐标系中，生成包含预测人类运动作为动态障碍物的动态占据地图；采用历史预测和朝向预测两种方法进行人类轨迹预测，并将其融入地图以实现避障导航。

Result: 在Social-HM3D和Social-MP3D数据集上的实验表明，相比需2396 GPU小时训练的SOTA方法，SocialNav-Map在零样本情况下将人类碰撞率降低超过10%。

Conclusion: SocialNav-Map通过消除环境特定训练需求，在多样化人类行为的真实环境中展现出优越的导航性能，推动了社会导航系统的实际部署。

Abstract: Social navigation in densely populated dynamic environments poses a significant challenge for autonomous mobile robots, requiring advanced strategies for safe interaction. Existing reinforcement learning (RL)-based methods require over 2000+ hours of extensive training and often struggle to generalize to unfamiliar environments without additional fine-tuning, limiting their practical application in real-world scenarios. To address these limitations, we propose SocialNav-Map, a novel zero-shot social navigation framework that combines dynamic human trajectory prediction with occupancy mapping, enabling safe and efficient navigation without the need for environment-specific training. Specifically, SocialNav-Map first transforms the task goal position into the constructed map coordinate system. Subsequently, it creates a dynamic occupancy map that incorporates predicted human movements as dynamic obstacles. The framework employs two complementary methods for human trajectory prediction: history prediction and orientation prediction. By integrating these predicted trajectories into the occupancy map, the robot can proactively avoid potential collisions with humans while efficiently navigating to its destination. Extensive experiments on the Social-HM3D and Social-MP3D datasets demonstrate that SocialNav-Map significantly outperforms state-of-the-art (SOTA) RL-based methods, which require 2,396 GPU hours of training. Notably, it reduces human collision rates by over 10% without necessitating any training in novel environments. By eliminating the need for environment-specific training, SocialNav-Map achieves superior navigation performance, paving the way for the deployment of social navigation systems in real-world environments characterized by diverse human behaviors. The code is available at: https://github.com/linglingxiansen/SocialNav-Map.

</details>


### [518] [Intermittent Rendezvous Plans with Mixed Integer Linear Program for Large-Scale Multi-Robot Exploration](https://arxiv.org/abs/2511.12237)
*Alysson Ribeiro da Silva,Luiz Chaimowicz*

Main category: cs.RO

TL;DR: 本文提出了一种在通信受限且间歇连接条件下多机器人探索（MRE-CCIC）的规划与跟踪方法，结合混合整数线性规划（MILP）生成会合计划，并设计RTUS机制使机器人能在未知环境中遵循计划，仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有MRE系统在通信受限下难以兼顾规划效率与实际可执行性，尤其在环境先验未知时调度方法难以应用，需一种可在不确定环境中生成并执行会合计划的框架。

Method: 提出MRE-CCIC问题建模，采用MILP生成最优会合计划，并设计基于规则的Rendezvous Tracking for Unknown Scenarios (RTUS)策略，使机器人能在动态未知环境中跟踪计划。

Result: 在Gazebo大规模仿真中验证了方法的有效性，系统能及时跟随计划并高效完成探索任务，且提供了MILP规划器与仿真环境的开源实现。

Conclusion: 所提MILP+RTUS框架能够在通信受限、环境未知的多机器人探索中实现可解释且鲁棒的协同，提升了系统在真实场景中的部署潜力。

Abstract: Multi-Robot Exploration (MRE) systems with communication constraints have proven efficient in accomplishing a variety of tasks, including search-and-rescue, stealth, and military operations. While some works focus on opportunistic approaches for efficiency, others concentrate on pre-planned trajectories or scheduling for increased interpretability. However, scheduling usually requires knowledge of the environment beforehand, which prevents its deployment in several domains due to related uncertainties (e.g., underwater exploration). In our previous work, we proposed an intermittent communications framework for MRE under communication constraints that uses scheduled rendezvous events to mitigate such limitations. However, the system was unable to generate optimal plans and had no mechanisms to follow the plan considering realistic trajectories, which is not suited for real-world deployments. In this work, we further investigate the problem by formulating the Multi-Robot Exploration with Communication Constraints and Intermittent Connectivity (MRE-CCIC) problem. We propose a Mixed-Integer Linear Program (MILP) formulation to generate rendezvous plans and a policy to follow them based on the Rendezvous Tracking for Unknown Scenarios (RTUS) mechanism. The RTUS is a simple rule to allow robots to follow the assigned plan, considering unknown conditions. Finally, we evaluated our method in a large-scale environment configured in Gazebo simulations. The results suggest that our method can follow the plan promptly and accomplish the task efficiently. We provide an open-source implementation of both the MILP plan generator and the large-scale MRE-CCIC.

</details>


### [519] [SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty](https://arxiv.org/abs/2511.12361)
*Leroy D'Souza,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 提出SAC-MoE方法，结合Soft Actor-Critic与Mixture-of-Experts框架，通过可学习路由器自适应选择专家以应对混合动力系统中不可观测的模式切换，在零样本泛化任务中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有模型基于控制方法难以处理混合动力系统中不可观测的模态参数和切换事件，而标准无模型强化学习方法无法有效应对动态模式的突变，导致泛化能力差。

Method: 将SAC框架中的actor建模为具有可学习路由器的Mixture-of-Experts（MoE），路由器根据状态自适应选择专家；并设计基于课程学习的训练算法，优先在挑战性场景中收集数据以提升鲁棒性和泛化能力。

Result: 在混合自动驾驶赛车和足式机器人行走任务的仿真中，SAC-MoE在未见环境下的零样本泛化性能最高超过基线方法6倍，课程学习策略在所有评估策略中均提升性能，且MoE路由器展现出对不同潜在模式的可解释激活行为。

Conclusion: SAC-MoE结合MoE架构与课程学习，有效提升了在存在隐式模式切换的混合动力系统中的鲁棒性和零样本泛化能力，具备实际应用潜力。

Abstract: Hybrid dynamical systems result from the interaction of continuous-variable dynamics with discrete events and encompass various systems such as legged robots, vehicles and aircrafts. Challenges arise when the system's modes are characterized by unobservable (latent) parameters and the events that cause system dynamics to switch between different modes are also unobservable. Model-based control approaches typically do not account for such uncertainty in the hybrid dynamics, while standard model-free RL methods fail to account for abrupt mode switches, leading to poor generalization.
  To overcome this, we propose SAC-MoE which models the actor of the Soft Actor-Critic (SAC) framework as a Mixture-of-Experts (MoE) with a learned router that adaptively selects among learned experts. To further improve robustness, we develop a curriculum-based training algorithm to prioritize data collection in challenging settings, allowing better generalization to unseen modes and switching locations. Simulation studies in hybrid autonomous racing and legged locomotion tasks show that SAC-MoE outperforms baselines (up to 6x) in zero-shot generalization to unseen environments. Our curriculum strategy consistently improves performance across all evaluated policies. Qualitative analysis shows that the interpretable MoE router activates different experts for distinct latent modes.

</details>


### [520] [Multilaminate piezoelectric PVDF actuators to enhance performance of soft micro robots](https://arxiv.org/abs/2511.12380)
*Nicholas Gunter,Heiko Kabutz,Kaushik Jayaram*

Main category: cs.RO

TL;DR: 开发了具有并联电压分布的多层PVDF致动器，展示了其在软体微机器人系统中的高性能潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在脆性高力PZT堆栈和柔顺但带宽较低的软聚合物致动器之间开辟独特的设计空间，提升软体微机器人系统的性能。

Method: 通过改变层数和每层厚度，设计并表征多层PVDF致动器，并与第一性原理模型进行对比。

Result: 实现了超过3毫米的自由偏转、超过20毫牛的阻塞力以及不低于500赫兹的工作频率，且工作电压低至150伏特；并将其集成到平面移动微机器人中验证共振驱动行走能力。

Conclusion: 多层PVDF致动器在力、位移和频率方面表现优异，具备在复杂环境中实现鲁棒运动的能力，适合软体微机器人应用。

Abstract: Multilayer piezoelectric polyvinylidene fluoride (PVDF) actuators are a promising approach to enhance performance of soft microrobotic systems. In this work, we develop and characterize multilayer PVDF actuators with parallel voltage distribution across each layer, bridging a unique design space between brittle high-force PZT stacks and compliant but lower-bandwidth soft polymer actuators. We show the effects of layer thickness and number of layers in actuator performance and their agreement with a first principles model. By varying these parameters, we demonstrate actuators capable of >3 mm of free deflection, >20 mN of blocked force, and >=500 Hz, while operating at voltages as low as 150 volts. To illustrate their potential for robotic integration, we integrate our actuators into a planar, translating microrobot that leverages resonance to achieve locomotion with robustness to large perturbations.

</details>


### [521] [Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks](https://arxiv.org/abs/2511.12383)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 本文研究了MAML与TRPO结合在MetaWorld ML10基准上的少样本机器人操作任务适应能力，结果显示其能在一次梯度更新后有效提升性能，但在测试任务上存在泛化差距且不同任务间表现差异大。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人系统能够在少量数据下快速适应新任务，需要评估元学习方法在多样化操作任务中的有效性。

Method: 采用MAML与TRPO结合的方法，在MetaWorld ML10基准的十个不同操作任务上进行训练和测试，学习一个通用初始化策略以实现少样本适应。

Result: 在训练任务上达到21.0%的成功率，在测试任务上为13.2%，一次梯度更新即可显著提升性能，但存在训练与测试性能之间的泛化差距，且各任务间适应效果差异大（0%~80%）。

Conclusion: 基于梯度的元学习在多样化机器人操作中具有潜力但仍有局限，未来应关注任务感知的适应方法和结构化策略架构。

Abstract: Meta-learning algorithms enable rapid adaptation to new tasks with minimal data, a critical capability for real-world robotic systems. This paper evaluates Model-Agnostic Meta-Learning (MAML) combined with Trust Region Policy Optimization (TRPO) on the MetaWorld ML10 benchmark, a challenging suite of ten diverse robotic manipulation tasks. We implement and analyze MAML-TRPO's ability to learn a universal initialization that facilitates few-shot adaptation across semantically different manipulation behaviors including pushing, picking, and drawer manipulation. Our experiments demonstrate that MAML achieves effective one-shot adaptation with clear performance improvements after a single gradient update, reaching final success rates of 21.0% on training tasks and 13.2% on held-out test tasks. However, we observe a generalization gap that emerges during meta-training, where performance on test tasks plateaus while training task performance continues to improve. Task-level analysis reveals high variance in adaptation effectiveness, with success rates ranging from 0% to 80% across different manipulation skills. These findings highlight both the promise and current limitations of gradient-based meta-learning for diverse robotic manipulation, and suggest directions for future work in task-aware adaptation and structured policy architectures.

</details>


### [522] [Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control](https://arxiv.org/abs/2511.12390)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 提出一种基于学习的神经遥操作框架，通过强化学习训练策略直接映射VR控制器输入到机器人关节指令，相比传统IK+PD方法在跟踪误差、运动平滑性和力适应性方面显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统基于逆运动学（IK）和PD控制器的遥操作系统难以应对外力干扰、用户差异和动态环境下的自然运动生成问题。

Method: 采用强化学习训练神经网络策略，使用IK系统采集的演示数据进行初始化，并在仿真中引入力扰动增强和轨迹平滑奖励进行微调，实现从VR输入到关节命令的端到端映射。

Result: 在Unitree G1人形机器人上实验显示，相比IK基线方法，所提方法降低34%跟踪误差、提高45%运动平滑性，并具备更强的外力适应能力，同时保持50Hz实时控制。

Conclusion: 基于学习的遥操作框架能显著提升人形机器人遥操作的自然性与鲁棒性，验证了其在复杂操作任务中的有效性。

Abstract: Virtual reality (VR) teleoperation has emerged as a promising approach for controlling humanoid robots in complex manipulation tasks. However, traditional teleoperation systems rely on inverse kinematics (IK) solvers and hand-tuned PD controllers, which struggle to handle external forces, adapt to different users, and produce natural motions under dynamic conditions. In this work, we propose a learning-based neural teleoperation framework that replaces the conventional IK+PD pipeline with learned policies trained via reinforcement learning. Our approach learns to directly map VR controller inputs to robot joint commands while implicitly handling force disturbances, producing smooth trajectories, and adapting to user preferences. We train our policies in simulation using demonstrations collected from IK-based teleoperation as initialization, then fine-tune them with force randomization and trajectory smoothness rewards. Experiments on the Unitree G1 humanoid robot demonstrate that our learned policies achieve 34% lower tracking error, 45% smoother motions, and superior force adaptation compared to the IK baseline, while maintaining real-time performance (50Hz control frequency). We validate our approach on manipulation tasks including object pick-and-place, door opening, and bimanual coordination. These results suggest that learning-based approaches can significantly improve the naturalness and robustness of humanoid teleoperation systems.

</details>


### [523] [RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation](https://arxiv.org/abs/2511.12436)
*Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Yanbiao Ma,Yunfeng Diao,Ziyu Jia,Wenbo Ding,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: 本文提出了RoboAfford++，一个用于机器人操作与导航的多模态功能学习的大规模生成式AI增强数据集，包含869,987张图像和200万条问答标注，并配套推出RoboAfford-Eval基准，实验证明该数据集能显著提升视觉语言模型在物体与空间功能推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在高层任务规划和场景理解上表现良好，但由于缺乏细粒度的功能标注，难以推断出可执行的物理交互位置（如抓取点和可放置区域），限制了其在机器人操作与导航中的应用。

Method: 构建了一个包含869,987张图像和200万条问答标注的大规模数据集RoboAfford++，涵盖物体功能识别、物体功能预测和空间功能定位三大任务；同时提出RoboAfford-Eval评估基准，并通过在真实场景中精细标注338个样本进行评测；利用该数据集对VLMs进行微调以提升其功能感知能力。

Result: 实验表明现有VLMs在功能学习任务中表现不佳，但在RoboAfford++数据集上微调后，其在物体与空间功能推理方面的能力显著提升，验证了数据集的有效性。

Conclusion: RoboAfford++数据集有效弥补了现有VLMs在细粒度功能理解上的不足，提升了模型在机器人操作与导航中的实际应用潜力，推动了具身智能中多模态功能学习的发展。

Abstract: Robotic manipulation and navigation are fundamental capabilities of embodied intelligence, enabling effective robot interactions with the physical world. Achieving these capabilities requires a cohesive understanding of the environment, including object recognition to localize target objects, object affordances to identify potential interaction areas and spatial affordances to discern optimal areas for both object placement and robot movement. While Vision-Language Models (VLMs) excel at high-level task planning and scene understanding, they often struggle to infer actionable positions for physical interaction, such as functional grasping points and permissible placement regions. This limitation stems from the lack of fine-grained annotations for object and spatial affordances in their training datasets. To tackle this challenge, we introduce RoboAfford++, a generative AI-enhanced dataset for multimodal affordance learning for both robotic manipulation and navigation. Our dataset comprises 869,987 images paired with 2.0 million question answering (QA) annotations, covering three critical tasks: object affordance recognition to identify target objects based on attributes and spatial relationships, object affordance prediction to pinpoint functional parts for manipulation, and spatial affordance localization to identify free space for object placement and robot navigation. Complementing this dataset, we propose RoboAfford-Eval, a comprehensive benchmark for assessing affordance-aware prediction in real-world scenarios, featuring 338 meticulously annotated samples across the same three tasks. Extensive experimental results reveal the deficiencies of existing VLMs in affordance learning, while fine-tuning on the RoboAfford++ dataset significantly enhances their ability to reason about object and spatial affordances, validating the dataset's effectiveness.

</details>


### [524] [ClutterNav: Gradient-Guided Search for Efficient 3D Clutter Removal with Learned Costmaps](https://arxiv.org/abs/2511.12479)
*Navin Sriram Ravie,Keerthi Vasan M,Bijo Sebastian*

Main category: cs.RO

TL;DR: 本文提出了一种名为ClutterNav的新框架，用于在密集杂乱环境中移除遮挡物体以获取目标物体，通过结合可学习的移除成本和集成梯度实现近似人类的策略决策。


<details>
  <summary>Details</summary>
Motivation: 密集杂乱中目标物体检索困难，现有基于规则或端到端强化学习的方法存在计算开销高、缺乏可解释性和泛化能力差的问题。

Method: 将问题建模为连续强化学习任务，使用基于演示训练的可移除性评判器估计移除成本，并结合集成梯度分析周围物体对目标可访问性的影响，动态优化动作优先级。

Result: 在仿真和真实环境中验证了方法的有效性，实现了实时、具备遮挡感知的决策能力，能在部分可观测环境下有效减少堆叠扰动和移除次数。

Conclusion: ClutterNav无需预设启发式规则即可实现高效的目标访问策略，在密集杂乱清理任务中表现出良好的性能和实用性。

Abstract: Dense clutter removal for target object retrieval presents a challenging problem, especially when targets are embedded deep within densely-packed configurations. It requires foresight to minimize overall changes to the clutter configuration while accessing target objects, avoiding stack destabilization and reducing the number of object removals required. Rule-based planners when applied to this problem, rely on rigid heuristics, leading to high computational overhead. End-to-end reinforcement learning approaches struggle with interpretability and generalizability over different conditions. To address these issues, we present ClutterNav, a novel decision-making framework that can identify the next best object to be removed so as to access a target object in a given clutter, while minimising stack disturbances. ClutterNav formulates the problem as a continuous reinforcement learning task, where each object removal dynamically updates the understanding of the scene. A removability critic, trained from demonstrations, estimates the cost of removing any given object based on geometric and spatial features. This learned cost is complemented by integrated gradients that assess how the presence or removal of surrounding objects influences the accessibility of the target. By dynamically prioritizing actions that balance immediate removability against long-term target exposure, ClutterNav achieves near human-like strategic sequencing, without predefined heuristics. The proposed approach is validated extensively in simulation and over real-world experiments. The results demonstrate real-time, occlusion-aware decision-making in partially observable environments.

</details>


### [525] [Botany Meets Robotics in Alpine Scree Monitoring](https://arxiv.org/abs/2511.12526)
*Davide De Benedittis,Giovanni Di Lorenzo,Franco Angelini,Barbara Valle,Marina Serena Borgatti,Paolo Remagnino,Marco Caccianiga,Manolo Garabini*

Main category: cs.RO

TL;DR: 本研究提出了一种利用四足机器人辅助监测碎石坡栖息地的新方法，通过在意大利阿尔卑斯山区的实地试验，结合深度学习技术实现关键植物物种的识别，提高了生态监测的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统碎石坡栖息地监测依赖专家进行高风险、高强度的野外工作，成本高且耗时长，亟需更高效、安全的替代方案。

Method: 部署ANYmal C四足机器人在高海拔碎石坡区域执行两年两次的野外任务，结合深度学习模型对采集的图像数据进行植物物种检测与分类，并与传统植物社会学调查结果对比验证。

Result: 实验表明，四足机器人能够有效穿越复杂地形，提升监测频率与效率；结合深度学习可准确识别目标植物物种，显著增强数据获取、存储与应用能力。

Conclusion: 机器人辅助的生态监测方案可显著优化高山栖息地的保护工作，为环境科学中的自动化与可持续监测提供了可行路径和技术范例。

Abstract: According to the European Union's Habitat Directive, habitat monitoring plays a critical role in response to the escalating problems posed by biodiversity loss and environmental degradation. Scree habitats, hosting unique and often endangered species, face severe threats from climate change due to their high-altitude nature. Traditionally, their monitoring has required highly skilled scientists to conduct extensive fieldwork in remote, potentially hazardous locations, making the process resource-intensive and time-consuming. This paper presents a novel approach for scree habitat monitoring using a legged robot to assist botanists in data collection and species identification. Specifically, we deployed the ANYmal C robot in the Italian Alpine bio-region in two field campaigns spanning two years and leveraged deep learning to detect and classify key plant species of interest. Our results demonstrate that agile legged robots can navigate challenging terrains and increase the frequency and efficiency of scree monitoring. When paired with traditional phytosociological surveys performed by botanists, this robotics-assisted protocol not only streamlines field operations but also enhances data acquisition, storage, and usage. The outcomes of this research contribute to the evolving landscape of robotics in environmental science, paving the way for a more comprehensive and sustainable approach to habitat monitoring and preservation.

</details>


### [526] [EcoFlight: Finding Low-Energy Paths Through Obstacles for Autonomous Sensing Drones](https://arxiv.org/abs/2511.12618)
*Jordan Leyva,Nahim J. Moran Vera,Yihan Xu,Adrien Durasno,Christopher U. Romero,Tendai Chimuka,Gabriel O. Huezo Ramirez,Ziqian Dong,Roberto Rojas-Cessa*

Main category: cs.RO

TL;DR: 提出了一种名为EcoFlight的节能路径规划算法，用于在三维障碍环境中为无人机寻找最低能耗路径。


<details>
  <summary>Details</summary>
Motivation: 现有飞行路径规划方案很少考虑障碍物避让，且避障通常能耗较高，因此需要一种兼顾障碍规避与能量效率的路径规划方法。

Method: 基于无人机推进系统和飞行动力学建模能量消耗，设计EcoFlight算法，在三维空间中求解含障碍物的最低能耗路径，并通过仿真对比直接飞行和最短距离路径方案。

Result: 在不同障碍密度下的仿真结果表明，EcoFlight在高密度障碍环境中始终比对比算法能耗更低，且适当飞行速度可进一步提升节能效果。

Conclusion: EcoFlight能有效降低无人机在复杂环境中的飞行能耗，是一种高效、节能的三维障碍避让路径规划方案。

Abstract: Obstacle avoidance path planning for uncrewed aerial vehicles (UAVs), or drones, is rarely addressed in most flight path planning schemes, despite obstacles being a realistic condition. Obstacle avoidance can also be energy-intensive, making it a critical factor in efficient point-to-point drone flights. To address these gaps, we propose EcoFlight, an energy-efficient pathfinding algorithm that determines the lowest-energy route in 3D space with obstacles. The algorithm models energy consumption based on the drone propulsion system and flight dynamics. We conduct extensive evaluations, comparing EcoFlight with direct-flight and shortest-distance schemes. The simulation results across various obstacle densities show that EcoFlight consistently finds paths with lower energy consumption than comparable algorithms, particularly in high-density environments. We also demonstrate that a suitable flying speed can further enhance energy savings.

</details>


### [527] [Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning](https://arxiv.org/abs/2511.12650)
*Arvind Kumar Mishra,Sohom Chakrabarty*

Main category: cs.RO

TL;DR: 该论文研究了使用强化学习（RL）框架优化平面机器人操纵器形态的方法，通过Yoshikawa的可操作性指标验证RL能在无先验知识的情况下重新发现已知最优解，并进一步证明其在无解析解的复杂任务中相比传统方法更具可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 由于大多数形态设计问题没有闭式解，且随着维度增加，网格搜索或启发式方法成本高昂，因此需要一种可扩展的优化方法。本文旨在验证强化学习是否能仅通过奖励反馈恢复已知最优形态，并推广到更复杂的路径任务中。

Method: 采用三种强化学习算法（SAC、DDPG、PPO）与网格搜索及黑箱优化器对比，首先在具有已知解析最优解的2R机械臂圆轨迹跟踪任务中验证方法有效性，随后将动作空间扩展为完整形态向量（L1, L2, theta2），应用于椭圆和矩形路径等非解析场景。

Result: 所有方法在圆路径任务中均收敛至理论最优解；在椭圆和矩形路径中，RL方法仍能可靠收敛，而网格搜索和黑箱方法需要更高的评估预算。

Conclusion: 强化学习是一种有效的形态优化工具，既能恢复已知最优解，也能解决无解析解的高维形态优化问题，具有良好的可扩展性和应用前景。

Abstract: In this work, Yoshikawa's manipulability index is used to investigate reinforcement learning (RL) as a framework for morphology optimization in planar robotic manipulators. A 2R manipulator tracking a circular end-effector path is first examined because this case has a known analytical optimum: equal link lengths and the second joint orthogonal to the first. This serves as a validation step to test whether RL can rediscover the optimum using reward feedback alone, without access to the manipulability expression or the Jacobian. Three RL algorithms (SAC, DDPG, and PPO) are compared with grid search and black-box optimizers, with morphology represented by a single action parameter phi that maps to the link lengths. All methods converge to the analytical solution, showing that numerical recovery of the optimum is possible without supplying analytical structure.
  Most morphology design tasks have no closed-form solutions, and grid or heuristic search becomes expensive as dimensionality increases. RL is therefore explored as a scalable alternative. The formulation used for the circular path is extended to elliptical and rectangular paths by expanding the action space to the full morphology vector (L1, L2, theta2). In these non-analytical settings, RL continues to converge reliably, whereas grid and black-box methods require far larger evaluation budgets. These results indicate that RL is effective for both recovering known optima and solving morphology optimization problems without analytical solutions.

</details>


### [528] [Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL](https://arxiv.org/abs/2511.12755)
*Aleesha Khurram,Amir Moeini,Shangtong Zhang,Rohan Chandra*

Main category: cs.RO

TL;DR: 本文提出了一种基于上下文强化学习（ICRL）的推理时少样本提示驱动域自适应方法，用于恶劣天气下的闭环自动驾驶，无需模型参数更新或额外数据收集。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶系统在跨域适应（如恶劣天气）方面表现不佳，传统域自适应方法依赖额外数据或重训练，难以扩展；当前提示驱动方法局限于感知任务且需专家样本。

Method: 提出In-Context Reinforcement Learning (ICRL)，利用推理时观察到的一般状态-动作轨迹作为上下文提示，实现无需参数更新的少样本域自适应闭环控制。

Result: 在CARLA模拟器上的实验表明，ICRL在目标域（恶劣天气）中相比现有提示驱动基线方法，实现了更安全、高效和舒适的驾驶策略。

Conclusion: ICRL推动了提示驱动域自适应的前沿，首次将其成功应用于闭环自动驾驶，并支持使用非专家级一般轨迹进行自适应，提升了实用性和泛化能力。

Abstract: Despite significant progress and advances in autonomous driving, many end-to-end systems still struggle with domain adaptation (DA), such as transferring a policy trained under clear weather to adverse weather conditions. Typical DA strategies in the literature include collecting additional data in the target domain or re-training the model, or both. Both these strategies quickly become impractical as we increase scale and complexity of driving. These limitations have encouraged investigation into few-shot and zero-shot prompt-driven DA at inference time involving LLMs and VLMs. These methods work by adding a few state-action trajectories during inference to the prompt (similar to in-context learning). However, there are two limitations of such an approach: $(i)$ prompt-driven DA methods are currently restricted to perception tasks such as detection and segmentation and $(ii)$ they require expert few-shot data. In this work, we present a new approach to inference-time few-shot prompt-driven DA for closed-loop autonomous driving in adverse weather condition using in-context reinforcement learning (ICRL). Similar to other prompt-driven DA methods, our approach does not require any updates to the model parameters nor does it require additional data collection in adversarial weather regime. Furthermore, our approach advances the state-of-the-art in prompt-driven DA by extending to closed driving using general trajectories observed during inference. Our experiments using the CARLA simulator show that ICRL results in safer, more efficient, and more comfortable driving policies in the target domain compared to state-of-the-art prompt-driven DA baselines.

</details>


### [529] [DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation](https://arxiv.org/abs/2511.12778)
*Vignesh Rajagopal,Kasun Weerakoon Kulathun Mudiyanselage,Gershom Devake Seneviratne,Pon Aswin Sankaralingam,Mohamed Elnoor,Jing Liang,Rohan Chandra,Dinesh Manocha*

Main category: cs.RO

TL;DR: DR. Nav 提出了一种在无地图、非结构化环境中具有死路检测与恢复能力的自主导航方法，通过RGB-LiDAR融合与贝叶斯推理生成实时语义代价图，显著提升导航准确性与效率。


<details>
  <summary>Details</summary>
Motivation: 在复杂非结构化环境中，传统导航方法难以有效应对死路问题，缺乏对恢复路径的预判能力，导致机器人被困或效率低下。

Method: 提出DR. Nav，结合RGB和LiDAR的跨模态融合与注意力过滤机制，利用贝叶斯推理持续更新每个栅格的死路概率和恢复点，构建包含恢复感知风险的统一语义代价地图。

Result: 在室内外密集场景中测试显示，相比DWA、MPPI和Nav2 DWB等先进方法，死路检测准确率提升83.33%，到达目标时间减少52.4%（路径效率提高）。

Conclusion: DR. Nav 能有效实现未知环境中的主动死路预测与恢复，通过融合多模态感知与动态风险建模，显著提升了机器人导航的安全性与效率。

Abstract: We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions

</details>


### [530] [ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model](https://arxiv.org/abs/2511.12795)
*Boshu Lei,Wen Jiang,Kostas Daniilidis*

Main category: cs.RO

TL;DR: 提出了一种基于校准能量模型的抓取姿态生成方法和主动视角选择策略，能够在密集遮挡环境中高效完成机器人抓取任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法在估计信息增益时忽略了抓取分布的重要性，或依赖于忽略SE(3)流形结构的投影方式，难以在密集杂乱环境中高效抓取。

Method: 提出校准的能量基模型来建模SE(3)流形上的多模态抓取分布，并将能量水平校准为抓取成功率；通过估计基于校准分布的信息增益来选择下一个最佳视角。

Result: 在仿真和真实机器人实验中，该方法在有限视角预算下优于现有最先进模型，能更有效地探索目标物体的可抓取区域。

Conclusion: 所提方法能更准确地建模抓取分布并指导主动感知，显著提升密集 clutter 环境下的抓取性能，且仿真环境可为后续主动抓取研究提供可复现平台。

Abstract: Grasping in a densely cluttered environment is a challenging task for robots. Previous methods tried to solve this problem by actively gathering multiple views before grasp pose generation. However, they either overlooked the importance of the grasp distribution for information gain estimation or relied on the projection of the grasp distribution, which ignores the structure of grasp poses on the SE(3) manifold. To tackle these challenges, we propose a calibrated energy-based model for grasp pose generation and an active view selection method that estimates information gain from grasp distribution. Our energy-based model captures the multi-modality nature of grasp distribution on the SE(3) manifold. The energy level is calibrated to the success rate of grasps so that the predicted distribution aligns with the real distribution. The next best view is selected by estimating the information gain for grasp from the calibrated distribution conditioned on the reconstructed environment, which could efficiently drive the robot to explore affordable parts of the target object. Experiments on simulated environments and real robot setups demonstrate that our model could successfully grasp objects in a cluttered environment with limited view budgets compared to previous state-of-the-art models. Our simulated environment can serve as a reproducible platform for future research on active grasping. The source code of our paper will be made public when the paper is released to the public.

</details>


### [531] [Structured Imitation Learning of Interactive Policies through Inverse Games](https://arxiv.org/abs/2511.12848)
*Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 提出一种结合生成式单智能体策略学习与博弈论结构的分步模仿学习框架，用于从多智能体演示中学习交互策略。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法难以处理多智能体交互中更高的行为复杂性，尤其是在无显式通信的人机协作场景中。

Method: 将学习分为两步：首先用标准模仿学习提取个体行为模式，然后通过求解逆向博弈问题来结构化地学习智能体间的依赖关系。

Result: 在合成的5智能体社会导航任务中，仅用50个演示即显著优于非交互策略，并接近真实交互策略的表现。

Conclusion: 结构化模仿学习在交互式场景中具有潜力，能有效提升多智能体协同策略的学习效果。

Abstract: Generative model-based imitation learning methods have recently achieved strong results in learning high-complexity motor skills from human demonstrations. However, imitation learning of interactive policies that coordinate with humans in shared spaces without explicit communication remains challenging, due to the significantly higher behavioral complexity in multi-agent interactions compared to non-interactive tasks. In this work, we introduce a structured imitation learning framework for interactive policies by combining generative single-agent policy learning with a flexible yet expressive game-theoretic structure. Our method explicitly separates learning into two steps: first, we learn individual behavioral patterns from multi-agent demonstrations using standard imitation learning; then, we structurally learn inter-agent dependencies by solving an inverse game problem. Preliminary results in a synthetic 5-agent social navigation task show that our method significantly improves non-interactive policies and performs comparably to the ground truth interactive policy using only 50 demonstrations. These results highlight the potential of structured imitation learning in interactive settings.

</details>


### [532] [Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos](https://arxiv.org/abs/2511.12882)
*Taiyi Su,Jian Zhu,Yaxuan Li,Chong Ma,Zitai Huang,Yichen Zhu,Hanli Wang,Yi Xu*

Main category: cs.RO

TL;DR: 提出MTV-World，一种基于多视角轨迹视频控制的具身世界模型，通过引入多视角框架和轨迹视频作为控制信号，提升机器人运动预测与物理交互的精度。


<details>
  <summary>Details</summary>
Motivation: 现有具身世界模型在将低层次动作转化为精确视觉预测时存在物理交互不一致的问题，难以准确建模真实世界的动态。

Method: 使用相机内外参和笛卡尔空间变换生成多视角轨迹视频作为控制信号，结合初始帧进行未来帧预测，并设计多视角框架以弥补单视角的空间信息损失。

Result: 在复杂双臂操作场景中，MTV-World实现了高精度的运动控制和物理交互建模；并通过基于Jaccard指数的自动评估管道验证了空间一致性。

Conclusion: MTV-World通过多视角轨迹-视频控制机制显著提升了具身世界模型在视觉-运动预测和物理交互上的准确性与一致性。

Abstract: Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.

</details>


### [533] [Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction](https://arxiv.org/abs/2511.12896)
*Jun Huo,Hongge Ru,Bo Yang,Xingjian Chen,Xi Li,Jian Huang*

Main category: cs.RO

TL;DR: 提出了一种基于16通道气压计的软体六轴力/扭矩传感器，采用硅橡胶超弹性气室结构，并通过刚-柔分层解耦方法有效降低交叉耦合影响，实验表明该传感器具有良好的静态和动态响应性能及较高精度。


<details>
  <summary>Details</summary>
Motivation: 为了实现安全、精确的多轴力交互，需要高精度的六轴力/扭矩传感器，但传统软体传感器存在交叉耦合导致的校准困难和精度下降问题。

Method: 设计了一种包含16通道气压计的软体气室型六轴力/扭矩传感器，采用硅橡胶制成的超弹性气室；提出基于刚-柔分层结构的有效解耦方法，将六轴解耦问题分解为两个三轴解耦问题。

Result: 有限元仿真与实验验证了该方法的可行性；原型传感器在50 N力和1 Nm扭矩范围内表现出良好性能，平均偏差4.9%，重复性2.7%，非线性5.8%，迟滞6.7%。

Conclusion: 所提出的软体六轴传感器结合分层解耦方法在保持柔软性的同时实现了较高的测量精度，适用于需要安全与精准力感知的应用场景。

Abstract: Soft multi-axis force/torque sensors provide safe and precise force interaction. Capturing the complete degree-of-freedom of force is imperative for accurate force measurement with six-axis force/torque sensors. However, cross-axis coupling can lead to calibration issues and decreased accuracy. In this instance, developing a soft and accurate six-axis sensor is a challenging task. In this paper, a soft air-chamber type six-axis force/torque sensor with 16-channel barometers is introduced, which housed in hyper-elastic air chambers made of silicone rubber. Additionally, an effective decoupling method is proposed, based on a rigid-soft hierarchical structure, which reduces the six-axis decoupling problem to two three-axis decoupling problems. Finite element model simulation and experiments demonstrate the compatibility of the proposed approach with reality. The prototype's sensing performance is quantitatively measured in terms of static load response, dynamic load response and dynamic response characteristic. It possesses a measuring range of 50 N force and 1 Nm torque, and the average deviation, repeatability, non-linearity and hysteresis are 4.9$\%$, 2.7$\%$, 5.8$\%$ and 6.7$\%$, respectively. The results indicate that the prototype exhibits satisfactory sensing performance while maintaining its softness due to the presence of soft air chambers.

</details>


### [534] [TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints](https://arxiv.org/abs/2511.12910)
*Yong Li,Yujun Huang,Yi Chen,Hui Cheng*

Main category: cs.RO

TL;DR: 本文提出了一种面向差速驱动轮式机器人的系统化时间最优路径参数化算法TOPP-DWR，考虑了角速度与关节速度约束，并通过SOCP优化提升计算效率，实验验证了其有效性与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有时间最优路径参数化方法常忽略角速度和关节速度约束，导致实际控制性能下降，限制了高精度控制在实际机器人中的应用。

Method: 采用非均匀B样条表示初始轨迹，将角速度、关节速度、线速度和线加速度约束统一转化为线速度约束，并引入松弛变量构建二阶锥规划（SOCP）问题以提高求解效率。

Result: 对比实验表明，TOPP-DWR能在满足所有动力学约束的同时实现时间最优路径参数化，且数值计算效率高。

Conclusion: TOPP-DWR是一种高效、实用的时间最优路径参数化方法，适用于差速驱动轮式机器人及其他移动机器人，在仿真和真实导航任务中均表现出良好性能。

Abstract: Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications.

</details>


### [535] [DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping](https://arxiv.org/abs/2511.12912)
*Yingting Zhou,Wenbo Cui,Weiheng Liu,Guixing Chen,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: 提出DiffuDepGrasp，一种无需真实数据训练、仅依赖仿真深度的零样本sim2real抓取框架，通过扩散模型生成感知真实的噪声深度图，实现高效部署与高成功率抓取。


<details>
  <summary>Details</summary>
Motivation: 解决现有sim2real方法在深度感知抓取中因传感器伪影（如空洞、噪声）导致的领域差距问题，同时克服数据效率低和部署复杂度高的挑战。

Method: 设计Diffusion Depth Generator，包含扩散深度模块（利用时序几何先验建模传感器噪声分布）和噪声嫁接模块（保持度量精度），在纯仿真数据上训练端到端抓取策略，实现零样本迁移。

Result: 在12物体抓取任务中实现95.7%的平均成功率，具备对未见物体的强泛化能力，且部署时无额外计算开销。

Conclusion: DiffuDepGrasp通过仿真专属训练实现了高效、鲁棒的零样本sim2real策略迁移，平衡了真实性与度量准确性，为实际机器人部署提供了轻量且有效的解决方案。

Abstract: Transferring the depth-based end-to-end policy trained in simulation to physical robots can yield an efficient and robust grasping policy, yet sensor artifacts in real depth maps like voids and noise establish a significant sim2real gap that critically impedes policy transfer. Training-time strategies like procedural noise injection or learned mappings suffer from data inefficiency due to unrealistic noise simulation, which is often ineffective for grasping tasks that require fine manipulation or dependency on paired datasets heavily. Furthermore, leveraging foundation models to reduce the sim2real gap via intermediate representations fails to mitigate the domain shift fully and adds computational overhead during deployment. This work confronts dual challenges of data inefficiency and deployment complexity. We propose DiffuDepGrasp, a deploy-efficient sim2real framework enabling zero-shot transfer through simulation-exclusive policy training. Its core innovation, the Diffusion Depth Generator, synthesizes geometrically pristine simulation depth with learned sensor-realistic noise via two synergistic modules. The first Diffusion Depth Module leverages temporal geometric priors to enable sample-efficient training of a conditional diffusion model that captures complex sensor noise distributions, while the second Noise Grafting Module preserves metric accuracy during perceptual artifact injection. With only raw depth inputs during deployment, DiffuDepGrasp eliminates computational overhead and achieves a 95.7% average success rate on 12-object grasping with zero-shot transfer and strong generalization to unseen objects.Project website: https://diffudepgrasp.github.io/.

</details>


### [536] [GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving](https://arxiv.org/abs/2511.12941)
*Chunyong Hu,Qi Luo,Jianyun Xu,Song Wang,Qiang Li,Sheng Yang*

Main category: cs.RO

TL;DR: 提出了一种名为GUIDE的新框架，使用3D高斯进行实例检测和占据预测，相比传统方法在精度和效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统基于3D边界框的方法难以准确表示不规则形状的真实障碍物，且密集体素网格计算开销大。

Method: 采用3D高斯作为稀疏表示，通过高斯到体素的光栅化（Gaussian-to-Voxel Splatting）实现细粒度的实例级占据预测，并支持鲁棒的跟踪。

Result: 在nuScenes数据集上实现了21.61的实例占据mAP，比现有方法提升50%，同时具备良好的跟踪性能。

Conclusion: GUIDE在自动驾驶感知中建立了新基准，兼顾精度与计算效率，更有效地应对复杂真实驾驶环境。

Abstract: In the realm of autonomous driving, accurately detecting surrounding obstacles is crucial for effective decision-making. Traditional methods primarily rely on 3D bounding boxes to represent these obstacles, which often fail to capture the complexity of irregularly shaped, real-world objects. To overcome these limitations, we present GUIDE, a novel framework that utilizes 3D Gaussians for instance detection and occupancy prediction. Unlike conventional occupancy prediction methods, GUIDE also offers robust tracking capabilities. Our framework employs a sparse representation strategy, using Gaussian-to-Voxel Splatting to provide fine-grained, instance-level occupancy data without the computational demands associated with dense voxel grids. Experimental validation on the nuScenes dataset demonstrates GUIDE's performance, with an instance occupancy mAP of 21.61, marking a 50\% improvement over existing methods, alongside competitive tracking capabilities. GUIDE establishes a new benchmark in autonomous perception systems, effectively combining precision with computational efficiency to better address the complexities of real-world driving environments.

</details>


### [537] [SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models](https://arxiv.org/abs/2511.12972)
*Siddarth Narasimhan,Matthew Lisondra,Haitong Wang,Goldie Nejat*

Main category: cs.RO

TL;DR: 本文提出了一种名为SplatSearch的新架构，用于解决实例图像目标导航（IIN）问题，利用稀疏视角的3D高斯点阵重建和多视角扩散模型实现鲁棒的目标识别与导航。


<details>
  <summary>Details</summary>
Motivation: 在仅提供单张参考图像且环境视角稀疏的情况下，机器人难以准确找到特定目标对象，现有方法在特征匹配和探索策略上存在不足。

Method: SplatSearch通过稀疏在线3DGS地图渲染候选对象的多视角图像，使用多视角扩散模型补全缺失区域，并结合语义与视觉信息设计新的前沿探索策略。

Result: 在真实和逼真的家居环境中实验表明，SplatSearch在成功率和路径长度上优于当前最先进方法，消融研究验证了其设计有效性。

Conclusion: SplatSearch有效解决了基于单张参考图像的导航挑战，结合3D重建与扩散模型提升了导航性能。

Abstract: The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.

</details>


### [538] [CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner](https://arxiv.org/abs/2511.12984)
*Miryeong Park,Dongjin Cho,Sanghyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 提出了一种集成安全路径生成、自适应置信度更新和置信度感知探索策略的框架，用于提升行星探测机器人在复杂地形中的导航安全性与地图可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂地形（如陨石坑）附近的高程估计不确定性方面存在不足，未能有效考虑不确定性对导航安全和地图质量的影响，且缺乏主动减少不确定性的探索策略。

Method: 基于卡尔曼滤波进行高程估计，生成地形可通行性与置信度评分，并将其引入基于图的探索规划器（GBP），优先探索可通行但低置信度区域，实现置信度感知的主动探索。

Result: 在模拟月球实验中，相比基线GBP方法实现了69%的不确定性降低，任务成功率从0%提升至100%。

Conclusion: 所提框架显著提升了行星探测任务中的导航安全性与地图可靠性，验证了置信度感知探索策略在高不确定性环境下的有效性。

Abstract: Planetary exploration robots must navigate uneven terrain while building reliable maps for space missions. However, most existing methods incorporate traversability constraints but may not handle high uncertainty in elevation estimates near complex features like craters, do not consider exploration strategies for uncertainty reduction, and typically fail to address how elevation uncertainty affects navigation safety and map quality. To address the problems, we propose a framework integrating safe path generation, adaptive confidence updates, and confidence-aware exploration strategies. Using Kalman-based elevation estimation, our approach generates terrain traversability and confidence scores, then incorporates them into Graph-Based exploration Planner (GBP) to prioritize exploration of traversable low-confidence regions. We evaluate our framework through simulated lunar experiments using a novel low-confidence region ratio metric, achieving 69% uncertainty reduction compared to baseline GBP. In terms of mission success rate, our method achieves 100% while baseline GBP achieves 0%, demonstrating improvements in exploration safety and map reliability.

</details>


### [539] [APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation](https://arxiv.org/abs/2511.13042)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 本文提出了一种针对A*等图搜索规划器的通用后处理算法APP，通过双向顶点缩减和迭代路径扰动策略，有效缩短路径长度、减少不必要的航向变化，并提升路径平滑性。


<details>
  <summary>Details</summary>
Motivation: 由于A*等图搜索方法受限于节点扩展方向，生成的路径通常不是最短路径，且存在不符合人类直觉的锯齿状轨迹。因此需要一种能优化路径长度和平滑性的后处理方法。

Method: 提出APP算法，包括基于代价地图的双向顶点缩减算法（结合彻底的捷径策略）以优化路径长度并减少不对称性，以及迭代路径扰动算法以局部减少航向变化并提升平滑性。

Result: 实验表明，APP在规划时间、路径长度和不必要的航向变化数量上均优于现有方法；实地导航实验验证了其实际应用价值。

Conclusion: APP是一种高效、系统化的后处理方法，显著提升了图搜索规划器生成路径的质量，适用于服务机器人等实际场景。

Abstract: Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.

</details>


### [540] [Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments](https://arxiv.org/abs/2511.13048)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 提出一种用于半结构化环境的全局路径规划方法，通过构建单向道路网络和双层势图，平衡路径长度与交通规则一致性，提升清洁机器人的导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法在自由空间中忽略环境交通规则，导致频繁重规划和高碰撞风险；而在结构化环境中严格遵守道路网络可能导致路径过长，影响导航效率。因此需要一种能在半结构化环境中平衡路径长度与交通规则一致性的方法。

Method: 构建表示交通约束的单向道路网络，提出混合策略以保证规划效果，并允许在起点和目标点穿越道路以缩短路径。特别地，提出双层势图方法以应对复杂交叉口的情况。

Result: 实验结果表明，与现有最先进方法相比，所提方法在路径长度和与道路网络的一致性之间实现了更好的平衡，验证了其有效性。

Conclusion: 该方法在半结构化环境中能有效提升全局路径规划性能，兼顾路径短与合规性，适用于清洁机器人等商用场景。

Abstract: Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.

</details>


### [541] [Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers](https://arxiv.org/abs/2511.13071)
*Michal Levin,Itzik Klein*

Main category: cs.RO

TL;DR: 提出了一种无需传感器定向知识或旋转的模型无关学习型校准方法，用于在静止条件下估计低成本加速度计的偏置，实验表明其误差比传统方法低52%以上。


<details>
  <summary>Details</summary>
Motivation: 低成本微机电加速度计的性能常因偏差误差而下降，传统校准需要水平放置或复杂的方位依赖过程，限制了现场快速部署。

Method: 采用一种模型无关的学习型校准方法，在静止条件下估计加速度计偏差，无需知道传感器方向，也无需旋转传感器。

Result: 在六个加速度计采集的13.39小时数据集上验证，该方法的误差持续比传统技术低52%以上。

Conclusion: 该方法为无定向校准场景提供了快速、实用且可扩展的解决方案，提升了低成本惯性传感器在多种科学与工业应用中的可靠性，消除了对水平校准的需求。

Abstract: Low-cost micro-electromechanical accelerometers are widely used in navigation, robotics, and consumer devices for motion sensing and position estimation. However, their performance is often degraded by bias errors. To eliminate deterministic bias terms a calibration procedure is applied under stationary conditions. It requires accelerom- eter leveling or complex orientation-dependent calibration procedures. To overcome those requirements, in this paper we present a model-free learning-based calibration method that estimates accelerometer bias under stationary conditions, without requiring knowledge of the sensor orientation and without the need to rotate the sensors. The proposed approach provides a fast, practical, and scalable solution suitable for rapid field deployment. Experimental validation on a 13.39-hour dataset collected from six accelerometers shows that the proposed method consistently achieves error levels more than 52% lower than traditional techniques. On a broader scale, this work contributes to the advancement of accurate calibration methods in orientation-free scenarios. As a consequence, it improves the reliability of low-cost inertial sensors in diverse scientific and industrial applications and eliminates the need for leveled calibration.

</details>


### [542] [ResAlignNet: A Data-Driven Approach for INS/DVL Alignment](https://arxiv.org/abs/2511.13096)
*Guy Damari,Itzik Klein*

Main category: cs.RO

TL;DR: 本文提出了一种基于1D ResNet-18的深度学习方法ResAlignNet，用于解决自主水下航行器中惯性导航与多普勒测速仪之间的快速、自包含传感器对准问题，实现了无需外部辅助、无需特定运动模式、且在25秒内完成高精度（0.8°）对准的突破。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的传感器对准方法存在收敛时间长、依赖特定运动模式和外部辅助传感器等问题，限制了水下航行器的任务灵活性，因此需要一种更高效、自包含的对准方法。

Method: 采用1D ResNet-18架构，将传感器对准问题转化为数据驱动的深度神经网络优化问题，并利用Sim2Real迁移学习实现合成数据训练与真实环境部署的结合。

Result: 在Snapir水下航行器上的实验表明，ResAlignNet仅用25秒数据即可实现0.8°的对准精度，相比传统方法收敛时间缩短65%，且无需特定运动轨迹或外部定位辅助。

Conclusion: ResAlignNet提供了一种鲁棒、传感器无关、任务即用的对准解决方案，显著提升了复杂环境下水下导航系统的自主性与适应性。

Abstract: Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.

</details>


### [543] [Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing](https://arxiv.org/abs/2511.13100)
*Xuecheng Chen,Jingao Xu,Wenhua Ding,Haoyang Wang,Xinyu Luo,Ruiyang Duan,Jialong Chen,Xueqian Wang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: 本文提出了一种基于事件相机的无人机感知系统\sysname，通过聚焦旋翼转速来提升地面无接触感知性能。系统包含两个部分：精确估计高噪声环境下旋翼转速的“Count Every Rotation”，以及利用转速推断无人机内外部动态的“Every Rotation Counts”。实验表明该方法具有3ms延迟、0.23%转速误差，并在飞行指令识别和多模态跟踪中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着无人机应用的普及，从地面进行高效、非接触式的无人机感知变得至关重要。传统方法难以准确捕捉无人机关键动态，因此需要一种更灵敏且鲁棒的感知技术。通过关注旋翼旋转速度这一关键特征，可显著提升感知精度与响应速度。

Method: 提出\sysname系统，采用事件相机作为传感器，设计“Count Every Rotation”模块以抑制环境噪声并实现实时精确的旋翼转速估计；进一步设计“Every Rotation Counts”模块，利用估计出的转速信息推断无人机的内部状态（如飞行指令）和外部运动状态。

Result: \sysname在真实无人机配送场景中实现了3ms的感知延迟和仅0.23%的转速估计误差；飞行指令识别精度达96.5%；与其他感知方式融合后，无人机跟踪精度提升超过22%。

Conclusion: \sysname通过聚焦旋翼转速，展示了事件相机在高速、低延迟无人机感知中的巨大潜力，为未来智能空中交通监控提供了高效解决方案。

Abstract: As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \sysname. \sysname features two components: \textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\%. Additionally, \sysname infers drone flight commands with 96.5\% precision and improves drone tracking accuracy by over 22\% when combined with other sensing modalities. \textit{ Demo: {\color{blue}https://eventpro25.github.io/EventPro/.} }

</details>


### [544] [Monolithic Units: Actuation, Sensing, and Simulation for Integrated Soft Robot Design](https://arxiv.org/abs/2511.13120)
*Trevor Exley,Anderson Brazil Nardin,Petr Trunin,Diana Cafiso,Lucia Beccai*

Main category: cs.RO

TL;DR: 本文提出了一种用于软体机器人的单片单元（MU），集成了气动执行器、柔性晶格结构和光学波导传感位点，通过参数化设计和仿真优化实现了可重复、可扩展的嵌入式传感与力学性能保持。


<details>
  <summary>Details</summary>
Motivation: 为了实现软体机器人中执行器、结构和传感器的一体化制造，并解决可重复性和可扩展性问题，需要一种统一的设计框架。

Method: 提出单片单元（MU）概念，采用参数化设计关联执行腔尺寸与晶格尺寸；通过实验均质化获取等效材料参数用于有限元仿真；将传感器路径选择建模为离散优化问题，以最小化对力学性能的影响为目标筛选最优波导路径。

Result: 成功制造并验证了优化后的MU单元，证明其在保持原有机械性能的同时实现了嵌入式光学传感；该方法被推广至更大尺度单元和二指抓手，展示了良好的通用性。

Conclusion: MU提供了一种可复制、可扩展的软体机器人一体化设计方法，结合仿真驱动的传感器集成策略，推动了复杂功能软体系统的单步制造发展。

Abstract: This work introduces the Monolithic Unit (MU), an actuator-lattice-sensor building block for soft robotics. The MU integrates pneumatic actuation, a compliant lattice envelope, and candidate sites for optical waveguide sensing into a single printed body. In order to study reproducibility and scalability, a parametric design framework establishes deterministic rules linking actuator chamber dimensions to lattice unit cell size. Experimental homogenization of lattice specimens provides effective material properties for finite element simulation. Within this simulation environment, sensor placement is treated as a discrete optimization problem, where a finite set of candidate waveguide paths derived from lattice nodes is evaluated by introducing local stiffening, and the configuration minimizing deviation from baseline mechanical response is selected. Optimized models are fabricated and experimentally characterized, validating the preservation of mechanical performance while enabling embedded sensing. The workflow is further extended to scaled units and a two-finger gripper, demonstrating generality of the MU concept. This approach advances monolithic soft robotic design by combining reproducible co-design rules with simulation-informed sensor integration.

</details>


### [545] [Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control](https://arxiv.org/abs/2511.13188)
*Osama Al Sheikh Ali,Sotiris Koutsoftas,Ze Zhang,Knut Akesson,Emmanuel Dean*

Main category: cs.RO

TL;DR: 提出了一种集成的自主移动机器人导航框架，通过四叉树方法生成无碰撞区域，并将其用于安全走廊构建和模型预测控制中的线性约束，实现了高效可靠的导航。


<details>
  <summary>Details</summary>
Motivation: 为了提升自主移动机器人在复杂环境中的导航效率与安全性，避免直接编码障碍物带来的计算负担和不稳定性。

Method: 采用基于四叉树的方法从占据地图中提取结构化的轴对齐无碰撞区域，利用这些区域构建连通性图并生成轨迹，结合B样条平滑和模型预测控制实现统一导航框架。

Result: 实验结果表明，该方法在多种复杂环境中具有更高的成功率和优于基线方法的性能表现。

Conclusion: 所提出的集成框架能够有效统一环境表示、路径规划与控制，提升了AMR在复杂动态环境中的导航可靠性与效率。

Abstract: This paper presents an integrated navigation framework for Autonomous Mobile Robots (AMRs) that unifies environment representation, trajectory generation, and Model Predictive Control (MPC). The proposed approach incorporates a quadtree-based method to generate structured, axis-aligned collision-free regions from occupancy maps. These regions serve as both a basis for developing safe corridors and as linear constraints within the MPC formulation, enabling efficient and reliable navigation without requiring direct obstacle encoding. The complete pipeline combines safe-area extraction, connectivity graph construction, trajectory generation, and B-spline smoothing into one coherent system. Experimental results demonstrate consistent success and superior performance compared to baseline approaches across complex environments.

</details>


### [546] [PIGEON: VLM-Driven Object Navigation via Points of Interest Selection](https://arxiv.org/abs/2511.13207)
*Cheng Peng,Zhenzhe Zhang,Cheng Chi,Xiaobao Wei,Yanhao Zhang,Heng Wang,Pengwei Wang,Zhongyuan Wang,Jing Liu,Shanghang Zhang*

Main category: cs.RO

TL;DR: 本文提出PIGEON方法，利用视觉语言模型（VLM）指导兴趣点（PoI）选择，结合轻量级语义记忆和低层规划器，提升物体导航中的决策频率与语义理解，实现在未知环境中更智能的探索，并通过RLVR数据增强训练，实现零样本迁移下的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中进行目标物体导航是具身智能的关键挑战，现有方法难以平衡决策频率与智能性，常导致缺乏远见或动作不连贯。

Method: 提出PIGEON框架，使用视觉语言模型PIGEON-VL在探索过程中构建并选择语义对齐的兴趣点（PoI），维护轻量级快照记忆，并由底层规划器生成动作；同时基于PoI生成可用于模拟器的强化学习可验证奖励（RLVR）数据。

Result: 在经典物体导航基准上，该方法在零样本迁移下达到最先进性能，RLVR进一步提升了模型的语义引导和实时导航中的深层推理能力。

Conclusion: PIGEON通过兴趣点引导的探索策略，有效结合VLM的语义理解与高频动作输出，解决了决策智能性与连续性之间的权衡问题，推动了具身导航系统的发展。

Abstract: Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.

</details>


### [547] [GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry](https://arxiv.org/abs/2511.13216)
*Chiyun Noh,Sangwoo Jung,Hanjun Kim,Yafei Hu,Laura Herlant,Ayoung Kim*

Main category: cs.RO

TL;DR: 本文提出了一种名为GaRLILEO的新型重力对齐连续时间雷达-腿-惯性里程计框架，用于提升足式机器人在复杂地形中的里程计精度，尤其改善了垂直方向的姿态估计。


<details>
  <summary>Details</summary>
Motivation: 传统基于本体感知传感器的里程计算法在足式机器人应用中存在不可抑制的垂直漂移问题，尤其是在楼梯、斜坡等场景下，受接触冲击、打滑和振动影响严重，且现有外部传感器方法在特征稀疏或重复环境中性能下降。

Method: GaRLILEO通过构建来自SoC雷达多普勒和腿部运动学信息的连续时间自车速度样条，解耦IMU中的速度，并引入一种新的软S2约束重力因子来可靠估计重力向量，从而实现雷达、腿部传感器与IMU的无缝融合。

Result: 在自采集的真实世界室内外数据集上评估表明，GaRLILEO在楼梯和斜坡上的垂直里程计估计精度达到领先水平，显著优于现有方法。

Conclusion: GaRLILEO有效解决了足式机器人在复杂环境中里程计的垂直漂移问题，无需依赖LiDAR或相机即可实现高精度姿态估计，且算法与数据集已开源以推动相关研究。

Abstract: Deployment of legged robots for navigating challenging terrains (e.g., stairs, slopes, and unstructured environments) has gained increasing preference over wheel-based platforms. In such scenarios, accurate odometry estimation is a preliminary requirement for stable locomotion, localization, and mapping. Traditional proprioceptive approaches, which rely on leg kinematics sensor modalities and inertial sensing, suffer from irrepressible vertical drift caused by frequent contact impacts, foot slippage, and vibrations, particularly affected by inaccurate roll and pitch estimation. Existing methods incorporate exteroceptive sensors such as LiDAR or cameras. Further enhancement has been introduced by leveraging gravity vector estimation to add additional observations on roll and pitch, thereby increasing the accuracy of vertical pose estimation. However, these approaches tend to degrade in feature-sparse or repetitive scenes and are prone to errors from double-integrated IMU acceleration. To address these challenges, we propose GaRLILEO, a novel gravity-aligned continuous-time radar-leg-inertial odometry framework. GaRLILEO decouples velocity from the IMU by building a continuous-time ego-velocity spline from SoC radar Doppler and leg kinematics information, enabling seamless sensor fusion which mitigates odometry distortion. In addition, GaRLILEO can reliably capture accurate gravity vectors leveraging a novel soft S2-constrained gravity factor, improving vertical pose accuracy without relying on LiDAR or cameras. Evaluated on a self-collected real-world dataset with diverse indoor-outdoor trajectories, GaRLILEO demonstrates state-of-the-art accuracy, particularly in vertical odometry estimation on stairs and slopes. We open-source both our dataset and algorithm to foster further research in legged robot odometry and SLAM. https://garlileo.github.io/GaRLILEO

</details>


### [548] [EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation](https://arxiv.org/abs/2511.13312)
*Jonas Bode,Raphael Memmesheimer,Sven Behnke*

Main category: cs.RO

TL;DR: 本文提出了一种结合视觉和文本输入的扩散模型用于机器人操作任务的控制策略，通过改进嵌入和借鉴图像生成中的扩散技术，在CALVIN数据集上实现了更好的多任务长时程操作性能。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人能够在人类环境中执行复杂任务，需要其具备理解自然语言并将其应用于物理操作的能力。现有的方法在长时程多任务操作中表现有限，因此需要更强大的模型来提升性能。

Method: 将扩散模型引入视觉-运动策略框架，融合视觉和文本输入生成精确的机器人轨迹；利用参考示范进行训练，并采用改进的嵌入表示以及图像生成领域的扩散技术优化模型。

Result: 在CALVIN数据集上的实验表明，该方法在多种操作任务中表现出更高的成功率，尤其在连续执行多个任务时显著提升了长时程任务的成功率。

Conclusion: 扩散模型在多任务机器人操作中具有巨大潜力，所提方法有效提升了语言引导下的长时程操作性能，推动了通用多任务操作的发展。

Abstract: Acting in human environments is a crucial capability for general-purpose robots, necessitating a robust understanding of natural language and its application to physical tasks. This paper seeks to harness the capabilities of diffusion models within a visuomotor policy framework that merges visual and textual inputs to generate precise robotic trajectories. By employing reference demonstrations during training, the model learns to execute manipulation tasks specified through textual commands within the robot's immediate environment. The proposed research aims to extend an existing model by leveraging improved embeddings, and adapting techniques from diffusion models for image generation. We evaluate our methods on the CALVIN dataset, proving enhanced performance on various manipulation tasks and an increased long-horizon success rate when multiple tasks are executed in sequence. Our approach reinforces the usefulness of diffusion models and contributes towards general multitask manipulation.

</details>


### [549] [ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning](https://arxiv.org/abs/2511.13327)
*Juntao Jian,Yi-Lin Wei,Chengjie Mou,Yuhao Lin,Xing Zhu,Yujun Shen,Wei-Shi Zheng,Ruizhen Hu*

Main category: cs.RO

TL;DR: 本文提出了一种名为ZeroDexGrasp的零样本任务导向灵巧抓取框架，结合多模态大语言模型与接触引导优化，实现无需标注数据的高质量人体相似抓取姿态生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的标注数据且难以泛化到多样物体和任务，缺乏对任务语义与物体功能性的有效对齐。

Method: 采用基于提示的多阶段语义推理，从任务和物体语义中推断初始抓取配置和接触信息，并通过接触引导的抓取优化进一步精细化姿态以确保物理可行性和任务一致性。

Result: 实验表明ZeroDexGrasp能在未见过的物体类别和复杂任务要求下实现高质量的零样本灵巧抓取。

Conclusion: 该方法推动了更通用、智能的机器人抓取技术的发展，减少了对标注数据的依赖。

Abstract: Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.

</details>


### [550] [Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness](https://arxiv.org/abs/2511.13459)
*Bingkun Huang,Yuhe Gong,Zewen Yang,Tianyu Ren,Luis Figueredo*

Main category: cs.RO

TL;DR: 提出了一种基于任务空间的能量安全框架，结合PPO和运动原语用于接触丰富的机器人操作任务，通过能量感知的笛卡尔阻抗控制器实现与环境的安全交互，在复杂3D环境中表现出更高的成功率和平滑轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统基于MDP的强化学习方法在关节空间中应用，对任务和环境感知有限，且忽略操作中的丰富接触信息，难以保证接触安全性和鲁棒性。

Method: 采用任务空间的 episodic RL 框架，结合Proximal Policy Optimization（PPO）与运动原语生成可靠轨迹，并引入能量感知的笛卡尔阻抗控制目标以确保交互安全性。

Result: 实验结果表明该框架在不同类型表面的3D环境中执行接触丰富任务时，相比现有方法具有更高的成功率、更平滑的轨迹以及更安全的能量交互表现。

Conclusion: 所提出的任务空间能量安全框架有效提升了复杂接触操作中的性能、安全性和适应性，优于传统步进式和基于MDP的强化学习方法。

Abstract: Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.

</details>


### [551] [Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety](https://arxiv.org/abs/2511.13530)
*Vesna Poprcova,Iulia Lefter,Matthias Wieser,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 本文提出了一种多模态数据集采集协议，用于在人机交互情境中研究社交焦虑，数据集包括音频、视频和生理信号，并结合背景信息以深入理解个体差异。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏能够反映社交焦虑的多模态数据集，限制了相关研究和应用的发展，因此需要构建一个能够在人-机器人交互背景下准确检测社交焦虑情感状态和行为的数据集。

Method: 通过Furhat社交机器人在受控实验条件下进行约10分钟的Wizard-of-Oz角色扮演实验，从至少70名参与者中同步采集音频、视频和生理信号，并根据其社交焦虑水平分组，同时收集上下文数据以丰富数据集。

Result: 将建立一个包含多模态同步数据和上下文信息的公开数据集，支持对社交焦虑的鲁棒多模态检测。

Conclusion: 该数据集有望推动情感自适应人-机器人交互的研究，为社交焦虑的识别与干预提供技术支持。

Abstract: Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.

</details>


### [552] [OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving](https://arxiv.org/abs/2511.13707)
*Xiaoyu Liang,Ziang Liu,Kelvin Lin,Edward Gu,Ruolin Ye,Tam Nguyen,Cynthia Hsu,Zhanxin Wu,Xiaoman Yang,Christy Sum Yu Cheung,Harold Soh,Katherine Dimitropoulou,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: OpenRoboCare是一个多模态机器人护理数据集，记录了职业治疗师对日常生活活动的示范，包含RGB-D视频、姿态追踪、眼动追踪、任务标注和触觉感知五种模态，旨在推动机器人护理中的感知、交互与长期规划研究。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、多样化且由专家驱动的真实护理场景数据集，限制了机器人在复杂人机交互、遮挡感知、安全接触和长时序规划中的发展。

Method: 收集21名职业治疗师在两个模拟人身上执行15项日常生活任务的数据，涵盖五种模态：RGB-D视频、姿态追踪、眼动追踪、任务与动作标注以及触觉感知，并分析专家护理策略。

Result: 数据集揭示了专家护理行为的关键原则，评估显示现有最先进的机器人感知与人类活动识别方法在该数据集上表现有限，表明其挑战性和研究价值。

Conclusion: OpenRoboCare为开发安全、自适应的辅助机器人提供了宝贵的多模态资源，有助于提升机器人在真实护理场景中的性能与可行性。

Abstract: We present OpenRoboCare, a multimodal dataset for robot caregiving, capturing expert occupational therapist demonstrations of Activities of Daily Living (ADLs). Caregiving tasks involve complex physical human-robot interactions, requiring precise perception under occlusions, safe physical contact, and long-horizon planning. While recent advances in robot learning from demonstrations have shown promise, there is a lack of a large-scale, diverse, and expert-driven dataset that captures real-world caregiving routines. To address this gap, we collect data from 21 occupational therapists performing 15 ADL tasks on two manikins. The dataset spans five modalities: RGB-D video, pose tracking, eye-gaze tracking, task and action annotations, and tactile sensing, providing rich multimodal insights into caregiver movement, attention, force application, and task execution strategies. We further analyze expert caregiving principles and strategies, offering insights to improve robot efficiency and task feasibility. Additionally, our evaluations demonstrate that OpenRoboCare presents challenges for state-of-the-art robot perception and human activity recognition methods, both critical for developing safe and adaptive assistive robots, highlighting the value of our contribution. See our website for additional visualizations: https://emprise.cs.cornell.edu/robo-care/.

</details>


### [553] [From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands](https://arxiv.org/abs/2511.13710)
*Jianglong Ye,Lai Wei,Guangqi Jiang,Changwei Jing,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 本文提出了一种协同优化多指灵巧手控制与硬件设计的方法，通过轻量化的指尖几何修改和动态控制策略，实现了稳定的力量抓握与精细的精准操作兼顾。


<details>
  <summary>Details</summary>
Motivation: 当前多指机器人手在精确操作上不如平行夹持器有效，难以同时实现稳定的力抓握和精细操控，限制了其广泛应用。

Method: 引入可参数化的指尖接触面并联合优化其几何形状与控制策略，采用基于微分神经物理代理模型的大规模仿真进行设计优化，控制上通过拇指-食指平行运动简化精密操作，并实现动态切换。

Result: 在仿真到真实场景中对未见物体的精准抓取达到82.5%的零样本成功率，在真实世界面包捏取任务中成功率为93.3%。

Conclusion: 所提出的软硬件协同设计框架显著提升了多指手的精细操作能力，同时不牺牲力量抓握性能，为通用灵巧手提供了可行路径。

Abstract: Human grasps can be roughly categorized into two types: power grasps and precision grasps. Precision grasping enables tool use and is believed to have influenced human evolution. Today's multi-fingered robotic hands are effective in power grasps, but for tasks requiring precision, parallel grippers are still more widely adopted. This contrast highlights a key limitation in current robotic hand design: the difficulty of achieving both stable power grasps and precise, fine-grained manipulation within a single, versatile system. In this work, we bridge this gap by jointly optimizing the control and hardware design of a multi-fingered dexterous hand, enabling both power and precision manipulation. Rather than redesigning the entire hand, we introduce a lightweight fingertip geometry modification, represent it as a contact plane, and jointly optimize its parameters along with the corresponding control. Our control strategy dynamically switches between power and precision manipulation and simplifies precision control into parallel thumb-index motions, which proves robust for sim-to-real transfer. On the design side, we leverage large-scale simulation to optimize the fingertip geometry using a differentiable neural-physics surrogate model. We validate our approach through extensive experiments in both sim-to-real and real-to-real settings. Our method achieves an 82.5% zero-shot success rate on unseen objects in sim-to-real precision grasping, and a 93.3% success rate in challenging real-world tasks involving bread pinching. These results demonstrate that our co-design framework can significantly enhance the fine-grained manipulation ability of multi-fingered hands without reducing their ability for power grasps. Our project page is at https://jianglongye.com/power-to-precision

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [554] [Softmax as a Lagrangian-Legendrian Seam](https://arxiv.org/abs/2511.11573)
*Christopher R. Lee-Jenkins*

Main category: cs.LG

TL;DR: 本文首次将机器学习与现代微分几何联系起来，提出softmax将logits转换为概率的过程可建模为几何界面：在概率单纯形上的接触屏处，由负熵和log-sum-exp生成的两个保守描述沿勒让德“接缝”相遇。偏置平移不变性表现为屏幕上的Reeb流，Fenchel-Young等式/KL间隙提供了到接缝的可计算距离。文章具体分析了二类和三类情况，并展望了机器学习中紧致logit模型、全局不变量及与信息几何的联系等下一步方向。


<details>
  <summary>Details</summary>
Motivation: 将机器学习中的softmax操作从微分几何视角重新理解，揭示其深层几何结构，建立机器学习与现代几何学之间的桥梁。

Method: 利用接触几何和辛几何框架，将softmax映射建模为潜在函数生成的保守系统在接触屏（概率单纯形）上的交界，通过Legendrian子流形描述logits到概率的转换，并引入Reeb流解释bias-shift不变性。

Result: 成功将softmax的logits-to-probabilities过程解释为几何界面现象，识别出Legendrian‘接缝’和接触屏幕的结构，揭示了Fenchel-Young等式与KL散度的几何意义，并在二类和三类情形下验证了该模型。

Conclusion: softmax不仅是机器学习中的常用函数，更具有丰富的微分几何结构；该工作为理解神经网络中的概率输出提供了新的几何视角，并为未来结合拓扑与几何工具研究模型表示奠定了基础。

Abstract: This note offers a first bridge from machine learning to modern differential geometry. We show that the logits-to-probabilities step implemented by softmax can be modeled as a geometric interface: two potential-generated, conservative descriptions (from negative entropy and log-sum-exp) meet along a Legendrian "seam" on a contact screen (the probability simplex) inside a simple folded symplectic collar. Bias-shift invariance appears as Reeb flow on the screen, and the Fenchel-Young equality/KL gap provides a computable distance to the seam. We work out the two- and three-class cases to make the picture concrete and outline next steps for ML: compact logit models (projective or spherical), global invariants, and connections to information geometry where on-screen dynamics manifest as replicator flows.

</details>


### [555] [LLM on a Budget: Active Knowledge Distillation for Efficient Classification of Large Text Corpora](https://arxiv.org/abs/2511.11574)
*Viviana Luccioli,Rithika Iyengar,Ryan Panley,Flora Haberkorn,Xiaoyu Ge,Leland Crane,Nitish Sinha,Seung Jung Lee*

Main category: cs.LG

TL;DR: 本文提出了一种名为M-RARU的主动学习算法，用于在知识蒸馏中降低大语言模型（LLM）作为教师模型时的标注成本，显著减少了样本需求和训练开销，同时保持了高性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽在分类任务中表现优异，但其高昂的计算和财务成本限制了在大规模动态环境中的应用。知识蒸馏可缓解此问题，但传统方法仍需对大量样本进行标注，成本较高。因此，亟需一种更高效的数据选择策略以降低蒸馏过程中的资源消耗。

Method: 提出M-RARU（多类随机化接受/拒绝不确定性采样）算法，结合不确定性采样与随机化接受-拒绝机制，主动选择最具信息量的样本交由LLM教师标注，从而减少不必要的API调用和标记开销。该方法在多个基准数据集上与随机采样对比，应用于五种不同学生模型（SVM、LDA、RF、GBDT、DistilBERT）。

Result: 实验表明，M-RARU相比随机采样最多可减少80%的样本需求，在显著降低财务成本和训练时间的同时，提升了分类准确率。

Conclusion: M-RARU是一种高效且经济的知识蒸馏数据选择方法，能够在保持性能的前提下大幅降低LLM驱动蒸馏的成本，推动其在实际场景中的广泛应用。

Abstract: Large Language Models (LLMs) are highly accurate in classification tasks, however, substantial computational and financial costs hinder their large-scale deployment in dynamic environments. Knowledge Distillation (KD) where a LLM "teacher" trains a smaller and more efficient "student" model, offers a promising solution to this problem. However, the distillation process itself often remains costly for large datasets, since it requires the teacher to label a vast number of samples while incurring significant token consumption. To alleviate this challenge, in this work we explore the active learning (AL) as a way to create efficient student models at a fraction of the cost while preserving the LLM's performance. In particular, we introduce M-RARU (Multi-class Randomized Accept/Reject Uncertainty Sampling), a novel AL algorithm that significantly reduces training costs. M-RARU employs an innovative strategy combining uncertainty with a randomized accept-reject mechanism to select only the most informative data points for the LLM teacher. This focused approach significantly minimizes required API calls and data processing time. We evaluate M-RARU against random sampling across five diverse student models (SVM, LDA, RF, GBDT, and DistilBERT) on multiple benchmark datasets. Experiments demonstrate that our proposed method achieves up to 80% reduction in sample requirements as compared to random sampling, substantially improving classification accuracy while reducing financial costs and overall training time.

</details>


### [556] [Detecting Statistically Significant Fairness Violations in Recidivism Forecasting Algorithms](https://arxiv.org/abs/2511.11575)
*Animesh Joshi*

Main category: cs.LG

TL;DR: 本文提出了一种基于k折交叉验证的统计显著性检验框架，用于评估机器学习模型在不同公平性定义下的偏见是否显著，并在累犯预测算法上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏判断群体间差异是否具有统计显著性的方法，因此需要一种严谨的方法来检验算法公平性违规的显著性。

Method: 利用k折交叉验证生成公平性度量的抽样分布，并设计统计检验方法，结合预测结果差异、模型校准和因果推断技术进行公平性检验。

Result: 在司法数据上的实验表明，累犯预测模型在多种公平性定义下对黑人个体表现出统计显著的偏见，而在其他定义下则对白人个体无偏或存在偏见。

Conclusion: 评估算法决策系统时必须采用严格且稳健的统计测试，以准确识别公平性问题。

Abstract: Machine learning algorithms are increasingly deployed in critical domains such as finance, healthcare, and criminal justice [1]. The increasing popularity of algorithmic decision-making has stimulated interest in algorithmic fairness within the academic community. Researchers have introduced various fairness definitions that quantify disparities between privileged and protected groups, use causal inference to determine the impact of race on model predictions, and that test calibration of probability predictions from the model. Existing literature does not provide a way in which to assess whether observed disparities between groups are statistically significant or merely due to chance. This paper introduces a rigorous framework for testing the statistical significance of fairness violations by leveraging k-fold cross-validation [2] to generate sampling distributions of fairness metrics. This paper introduces statistical tests that can be used to identify statistically significant violations of fairness metrics based on disparities between predicted and actual outcomes, model calibration, and causal inference techniques [1]. We demonstrate this approach by testing recidivism forecasting algorithms trained on data from the National Institute of Justice. Our findings reveal that machine learning algorithms used for recidivism forecasting exhibit statistically significant bias against Black individuals under several fairness definitions, while also exhibiting no bias or bias against White individuals under other definitions. The results from this paper underscore the importance of rigorous and robust statistical testing while evaluating algorithmic decision-making systems.

</details>


### [557] [DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs](https://arxiv.org/abs/2511.11576)
*WenZhuo Zhu,Zheng Cui,Wenhan Lu,Sheng Liu,Yue Zhao*

Main category: cs.LG

TL;DR: 提出DAOpt框架，结合OptU数据集、多智能体决策模块和仿真环境，利用小样本学习提升大模型在不确定环境下的优化建模能力。


<details>
  <summary>Details</summary>
Motivation: 现实决策具有不确定性，但现有大模型在优化建模的研究多集中于确定性问题，缺乏对不确定场景的探索。

Method: 提出DAOpt框架，包含新数据集OptU、多智能体决策模块和仿真环境，并引入随机与鲁棒优化领域的领域知识进行小样本学习以增强大模型建模能力。

Result: 框架显著提升了大语言模型在不确定优化问题中的建模性能，特别是在样本外可行性和鲁棒性方面表现更优。

Conclusion: DAOpt框架有效推动了大语言模型在不确定性优化建模中的应用，为现实世界复杂决策问题提供了新的解决方案。

Abstract: Recent advances in large language models (LLMs) have accelerated research on automated optimization modeling. While real-world decision-making is inherently uncertain, most existing work has focused on deterministic optimization with known parameters, leaving the application of LLMs in uncertain settings largely unexplored. To that end, we propose the DAOpt framework including a new dataset OptU, a multi-agent decision-making module, and a simulation environment for evaluating LLMs with a focus on out-of-sample feasibility and robustness. Additionally, we enhance LLMs' modeling capabilities by incorporating few-shot learning with domain knowledge from stochastic and robust optimization.

</details>


### [558] [A neural optimization framework for free-boundary diffeomorphic mapping problems and its applications](https://arxiv.org/abs/2511.11679)
*Zhehao Xu,Lok Ming Lui*

Main category: cs.LG

TL;DR: 提出了一种基于神经网络的自由边界微分同胚优化方法SBN-Opt，通过将最小二乘拟共形（LSQC）能量嵌入多尺度谱架构，实现对局部几何畸变的显式控制，在密度均衡映射和非一致曲面配准任务中优于传统数值算法。


<details>
  <summary>Details</summary>
Motivation: 自由边界微分同胚优化在曲面映射中至关重要，但因边界无约束且需保持局部双射性而极具挑战。传统LSQC方法虽具良好理论性质，但依赖标志点条件且无法用于梯度优化。

Method: 提出Spectral Beltrami Network (SBN)作为LSQC能量的神经代理，并构建SBN-Opt优化框架，结合多尺度网格谱架构实现自由边界微分同胚的梯度优化，显式控制几何畸变。

Result: 在密度均衡映射和非一致曲面配准实验中，SBN-Opt优于传统数值算法，展现出更强的优化能力与灵活性。

Conclusion: SBN-Opt为自由边界微分同胚优化提供了高效可微的新范式，推动了基于学习的几何处理方法的发展。

Abstract: Free-boundary diffeomorphism optimization is a core ingredient in the surface mapping problem but remains notoriously difficult because the boundary is unconstrained and local bijectivity must be preserved under large deformation. Numerical Least-Squares Quasiconformal (LSQC) theory, with its provable existence, uniqueness, similarity-invariance and resolution-independence, offers an elegant mathematical remedy. However, the conventional numerical algorithm requires landmark conditioning, and cannot be applied into gradient-based optimization. We propose a neural surrogate, the Spectral Beltrami Network (SBN), that embeds LSQC energy into a multiscale mesh-spectral architecture. Next, we propose the SBN guided optimization framework SBN-Opt which optimizes free-boundary diffeomorphism for the problem, with local geometric distortion explicitly controllable. Extensive experiments on density-equalizing maps and inconsistent surface registration demonstrate our SBN-Opt's superiority over traditional numerical algorithms.

</details>


### [559] [Decoupling Positional and Symbolic Attention Behavior in Transformers](https://arxiv.org/abs/2511.11579)
*Felipe Urrutia,Jorge Salas,Alexander Kozachinskiy,Cristian Buc Calderon,Hector Pasten,Cristobal Rojas*

Main category: cs.LG

TL;DR: 本研究深入探讨了Transformer中Rotary位置编码（RoPE）在位置信息与符号信息处理中的作用，提出并验证了注意力头行为的定位性与符号性互斥，并通过新设计的任务证明可通过控制频率访问来调控模型性能。


<details>
  <summary>Details</summary>
Motivation: 理解RoPE为何有效，以及位置编码如何影响语言模型中位置与语义信息的分离处理。

Method: 提出衡量注意力头位置性与符号性行为的理论定义与量化指标，并在基于RoPE的LLM上进行实证分析，同时设计纯位置和纯符号任务以因果验证频率使用对模型性能的影响。

Result: 发现所有注意力头的行为与其使用的频率高度相关：高频对应位置性行为，低频对应符号性行为；并通过控制频率访问能力成功调控模型在特定任务上的表现。

Conclusion: RoPE的成功部分源于其通过不同频率分别编码位置和语义信息的能力，该研究为理解Transformer中位置编码的作用机制提供了新的理论与实证基础。

Abstract: An important aspect subtending language understanding and production is the ability to independently encode positional and symbolic information of the words within a sentence. In Transformers, positional information is typically encoded using Positional Encodings (PEs). One such popular PE, namely Rotary PE (RoPE), has been widely used due to its empirical success. Recently, it has been argued that part of RoPE's success emerges from its ability to encode robust positional and semantic information using large and small frequencies, respectively. In this work, we perform a deeper dive into the positional versus symbolic dichotomy of attention heads behavior, both at the theoretical and empirical level. We provide general definitions of what it means for a head to behave positionally or symbolically, prove that these are two mutually exclusive behaviors and develop a metric to quantify them. We apply our framework to analyze Transformer-based LLMs using RoPE and find that all heads exhibit a strong correspondence between behavior and frequency use. Finally, we introduce canonical tasks designed to be either purely positional or symbolic, and demonstrate that the Transformer performance causally relates to the ability of attention heads to leverage the appropriate frequencies. In particular, we show that we can control the Transformer performance by controlling which frequencies the attention heads can access. Altogether, our work provides a detailed understanding of RoPE, and how its properties relate to model behavior.

</details>


### [560] [The Anatomy of a Triton Attention Kernel](https://arxiv.org/abs/2511.11581)
*Burkhard Ringlein,Jan van Lunteren,Radu Stoica,Thomas Parnell*

Main category: cs.LG

TL;DR: 本文提出了一种基于Triton语言的高效、可移植的LLM推理方案，实现了在NVIDIA和AMD GPU上的高性能分页注意力机制。


<details>
  <summary>Details</summary>
Motivation: 目标是开发一个跨硬件架构可移植、无需低级手动调优且高效能的LLM推理平台。

Method: 使用领域特定的即时编译语言Triton开发了最先进的分页注意力内核，并结合算法优化、系统级改进和自动参数调优方法。

Result: 将通用Triton注意力内核性能从19.7%提升至105.9%的业界先进水平，并成功集成到主流推理服务器中。

Conclusion: 开源的领域特定语言可有效实现跨不同GPU厂商的模型可移植性和高性能。

Abstract: A long-standing goal in both industry and academia is to develop an LLM inference platform that is portable across hardware architectures, eliminates the need for low-level hand-tuning, and still delivers best-in-class efficiency. In this work, we demonstrate that portable, efficient cross-platform LLM inference is indeed possible and share our experience. We develop a state-of-the-art paged attention kernel, the core performance-critical component of many LLM deployments, that builds exclusively on the domain-specific just-in-time compiled language Triton to achieve state-of-the-art performance on both NVIDIA and AMD GPUs. We describe our high-level approach, the key algorithmic and system-level improvements, the parameter auto-tuning required to unlock efficiency, and the integrations into a popular inference server that are necessary to bring the performance of a generic Triton attention kernel from 19.7% of the state-of-the-art to 105.9%. Our results highlight how open-source domain-specific languages can be leveraged to unlock model portability across different GPU vendors.

</details>


### [561] [Hierarchical Frequency-Decomposition Graph Neural Networks for Road Network Representation Learning](https://arxiv.org/abs/2511.12507)
*Jingtian Ma,Jingyuan Wang,Leong Hou U*

Main category: cs.LG

TL;DR: 提出HiFiNet，一种层次化频率分解图神经网络，统一空间和频谱建模，有效捕捉道路网络中的全局趋势与局部波动。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络在建模道路网络时存在空间-频谱不对齐问题，难以同时捕获全局频率特征和局部空间变化。

Method: 构建多级虚拟节点进行局部频域分析，采用分解-更新-重构框架，结合拓扑感知图Transformer分别建模并融合低频和高频信号。

Result: 在多个真实数据集的四项下游任务中验证，HiFiNet在性能和泛化能力上优于现有方法。

Conclusion: HiFiNet通过层次化频率分解有效桥接了空间与频谱建模范式，提升了复杂交通模式下的道路网络表示学习效果。

Abstract: Road networks are critical infrastructures underpinning intelligent transportation systems and their related applications. Effective representation learning of road networks remains challenging due to the complex interplay between spatial structures and frequency characteristics in traffic patterns. Existing graph neural networks for modeling road networks predominantly fall into two paradigms: spatial-based methods that capture local topology but tend to over-smooth representations, and spectral-based methods that analyze global frequency components but often overlook localized variations. This spatial-spectral misalignment limits their modeling capacity for road networks exhibiting both coarse global trends and fine-grained local fluctuations. To bridge this gap, we propose HiFiNet, a novel hierarchical frequency-decomposition graph neural network that unifies spatial and spectral modeling. HiFiNet constructs a multi-level hierarchy of virtual nodes to enable localized frequency analysis, and employs a decomposition-updating-reconstruction framework with a topology-aware graph transformer to separately model and fuse low- and high-frequency signals. Theoretically justified and empirically validated on multiple real-world datasets across four downstream tasks, HiFiNet demonstrates superior performance and generalization ability in capturing effective road network representations.

</details>


### [562] [Parallel and Multi-Stage Knowledge Graph Retrieval for Behaviorally Aligned Financial Asset Recommendations](https://arxiv.org/abs/2511.11583)
*Fernando Spadea,Oshani Seneviratne*

Main category: cs.LG

TL;DR: RAG-FLARKO 是一种检索增强的金融推荐框架，通过多阶段、并行的知识图谱检索，提升大语言模型在个性化金融推荐中的相关性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在金融推荐中受限于上下文长度、幻觉问题以及缺乏用户行为和市场数据的行为基础支持。

Method: 提出 RAG-FLARKO 框架，结合用户交易知识图谱和市场知识图谱，采用多阶段并行检索生成紧凑且有据可依的子图作为 LLM 输入。

Result: 在真实金融交易数据集上验证，RAG-FLARKO 显著提升了推荐质量，使小型模型也能实现高盈利性和行为一致性。

Conclusion: RAG-FLARKO 通过结构化知识检索增强了 LLM 的金融推荐能力，为资源受限环境下的可落地金融 AI 提供了有效路径。

Abstract: Large language models (LLMs) show promise for personalized financial recommendations but are hampered by context limits, hallucinations, and a lack of behavioral grounding. Our prior work, FLARKO, embedded structured knowledge graphs (KGs) in LLM prompts to align advice with user behavior and market data. This paper introduces RAG-FLARKO, a retrieval-augmented extension to FLARKO, that overcomes scalability and relevance challenges using multi-stage and parallel KG retrieval processes. Our method first retrieves behaviorally relevant entities from a user's transaction KG and then uses this context to filter temporally consistent signals from a market KG, constructing a compact, grounded subgraph for the LLM. This pipeline reduces context overhead and sharpens the model's focus on relevant information. Empirical evaluation on a real-world financial transaction dataset demonstrates that RAG-FLARKO significantly enhances recommendation quality. Notably, our framework enables smaller, more efficient models to achieve high performance in both profitability and behavioral alignment, presenting a viable path for deploying grounded financial AI in resource-constrained environments.

</details>


### [563] [Output Supervision Can Obfuscate the Chain of Thought](https://arxiv.org/abs/2511.11584)
*Jacob Drori,Luke Marks,Bryce Woodworth,Alex Cloud,Alexander Matt Turner*

Main category: cs.LG

TL;DR: 本文指出，即使使用不访问思维链（CoT）的输出监控器进行训练，模型仍可能产生难以监控的隐蔽性CoT，并揭示了两种潜在机制：一是模型将安全输出泛化为生成看似安全的CoT，二是CoT中前序标记影响后序标记，导致安全表象被强化。作者提出了两种缓解策略，在监控性和任务性能之间实现了帕累托改进。


<details>
  <summary>Details</summary>
Motivation: 防止在使用输出监控器训练时出现无法检测的隐蔽性思维链（CoT），确保模型推理过程的可监控性。

Method: 分析模型在仅依赖输出监督下的训练行为，识别出导致隐蔽CoT的两种机制，并提出针对性的训练缓解策略。

Result: 发现了即使不访问CoT的监控器也可能导致模型生成表面安全但实际不可靠的CoT；提出的两种缓解方法在保持任务性能的同时提升了CoT的可监控性。

Conclusion: 仅依靠输出监控不足以保证CoT的透明性，需引入专门机制来增强CoT的可监控性，以防止隐蔽的不良行为。

Abstract: OpenAI (2025) showed that training against a chain of thought (CoT) monitor can cause obfuscated CoTs, which contain bad behavior the monitor cannot detect. They proposed to keep CoTs monitorable by training only against output monitors that do not have access to CoT. We show that such training can still cause obfuscated CoTs via two mechanisms. First, when a model is trained to produce a safe-looking output, that model may generalize to making its CoTs look safe. Second, since later tokens are conditioned on earlier ones, safe-looking CoTs may increase the likelihood of safe outputs, causing safe-looking CoTs to be reinforced. We introduce two mitigations to address these two issues, which achieve a Pareto improvement in terms of monitorability and task performance compared to regular training.

</details>


### [564] [Parameter-Efficient and Personalized Federated Training of Generative Models at the Edge](https://arxiv.org/abs/2511.11585)
*Kabir Khan,Manju Sarkar,Anita Kar,Suresh Ghosh*

Main category: cs.LG

TL;DR: 提出FedGen-Edge框架，通过LoRA解耦预训练主干模型与客户端适配器，在联邦学习中实现高效、低通信开销的生成模型训练，支持个性化并适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 大型生成模型在跨设备联邦学习中面临计算、通信和数据异构性挑战，难以训练和适配。

Method: 采用冻结的全局预训练主干模型，仅在客户端使用轻量级LoRA适配器进行本地更新，并只联邦聚合这些适配器。

Result: 在PTB和CIFAR-10上优于基线方法，降低困惑度/FID，加快收敛速度，减少99%以上上行流量，稳定非IID数据下的聚合，支持个性化。

Conclusion: FedGen-Edge为异构边缘设备上的隐私保护、资源友好和个性化生成AI提供了可行路径。

Abstract: Large generative models (for example, language and diffusion models) enable high-quality text and image synthesis but are hard to train or adapt in cross-device federated settings due to heavy computation and communication and statistical/system heterogeneity. We propose FedGen-Edge, a framework that decouples a frozen, pre-trained global backbone from lightweight client-side adapters and federates only the adapters. Using Low-Rank Adaptation (LoRA) constrains client updates to a compact subspace, which reduces uplink traffic by more than 99 percent versus full-model FedAvg, stabilizes aggregation under non-IID data, and naturally supports personalization because each client can keep a locally tuned adapter. On language modeling (PTB) and image generation (CIFAR-10), FedGen-Edge achieves lower perplexity/FID and faster convergence than strong baselines while retaining a simple FedAvg-style server. A brief ablation shows diminishing returns beyond moderate LoRA rank and a trade-off between local epochs and client drift. FedGen-Edge offers a practical path toward privacy-preserving, resource-aware, and personalized generative AI on heterogeneous edge devices.

</details>


### [565] [WildfireGenome: Interpretable Machine Learning Reveals Local Drivers of Wildfire Risk and Their Cross-County Variation](https://arxiv.org/abs/2511.11589)
*Chenyue Liu,Ali Mostafavi*

Main category: cs.LG

TL;DR: WildfireGenome通过融合七个联邦野火指标，使用PCA降维和随机森林分类，在H3 Level-8分辨率上实现可解释的局部野火风险评估，并结合SHAP和ICE/PDP分析揭示关键驱动因素。


<details>
  <summary>Details</summary>
Motivation: 现有野火风险评估依赖粗粒度地图和黑箱模型，缺乏在决策尺度上的可解释性与精度。

Method: 1) 融合七个联邦野火指标，生成符号对齐的PCA复合风险标签（H3 Level-8）；2) 使用随机森林进行局部风险分类；3) 采用SHAP和ICE/PDP进行非线性驱动关系的可解释性分析。

Result: 在七个生态多样的美国县中，模型准确率为0.755–0.878，加权Kappa高达0.951，主成分解释了87%-94%的方差；跨区域迁移测试显示在生态相似区域表现稳定，差异大区域性能下降；针叶林覆盖（30%-40%）和海拔被一致识别为关键风险驱动因素。

Conclusion: WildfireGenome将野火风险评估从区域预测推进到可解释的决策尺度分析，支持植被管理、分区规划和基础设施建设。

Abstract: Current wildfire risk assessments rely on coarse hazard maps and opaque machine learning models that optimize regional accuracy while sacrificing interpretability at the decision scale. WildfireGenome addresses these gaps through three components: (1) fusion of seven federal wildfire indicators into a sign-aligned, PCA-based composite risk label at H3 Level-8 resolution; (2) Random Forest classification of local wildfire risk; and (3) SHAP and ICE/PDP analyses to expose county-specific nonlinear driver relationships. Across seven ecologically diverse U.S. counties, models achieve accuracies of 0.755-0.878 and Quadratic Weighted Kappa up to 0.951, with principal components explaining 87-94% of indicator variance. Transfer tests show reliable performance between ecologically similar regions but collapse across dissimilar contexts. Explanations consistently highlight needleleaf forest cover and elevation as dominant drivers, with risk rising sharply at 30-40% needleleaf coverage. WildfireGenome advances wildfire risk assessment from regional prediction to interpretable, decision-scale analytics that guide vegetation management, zoning, and infrastructure planning.

</details>


### [566] [Mind Your Entropy: From Maximum Entropy to Trajectory Entropy-Constrained RL](https://arxiv.org/abs/2511.11592)
*Guojian Zhan,Likun Wang,Pengcheng Wang,Feihong Zhang,Jingliang Duan,Masayoshi Tomizuka,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 提出了一种基于轨迹熵约束的强化学习框架（TECRL）和相应的DSAC-E算法，通过分离奖励与熵的Q函数学习及长期熵控制，提升了最大熵强化学习的稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有最大熵强化学习方法存在Q值估计非平稳性和短视的局部熵调节两个瓶颈，限制了性能提升。

Method: 提出轨迹熵约束强化学习（TECRL）框架，分离学习奖励和熵对应的Q函数，并利用熵Q函数实现对累积熵的显式建模与长期策略随机性控制；在此基础上构建DSAC-E算法，结合分布式的软演员-评论家方法进行改进。

Result: 在OpenAI Gym基准上的实验表明，DSAC-E相比现有方法具有更高的回报和更好的训练稳定性。

Conclusion: TECRL框架有效解决了最大熵RL中的非平稳性和短视调温问题，DSAC-E算法实现了更优的性能和稳定性，验证了长期熵约束的有效性。

Abstract: Maximum entropy has become a mainstream off-policy reinforcement learning (RL) framework for balancing exploitation and exploration. However, two bottlenecks still limit further performance improvement: (1) non-stationary Q-value estimation caused by jointly injecting entropy and updating its weighting parameter, i.e., temperature; and (2) short-sighted local entropy tuning that adjusts temperature only according to the current single-step entropy, without considering the effect of cumulative entropy over time. In this paper, we extends maximum entropy framework by proposing a trajectory entropy-constrained reinforcement learning (TECRL) framework to address these two challenges. Within this framework, we first separately learn two Q-functions, one associated with reward and the other with entropy, ensuring clean and stable value targets unaffected by temperature updates. Then, the dedicated entropy Q-function, explicitly quantifying the expected cumulative entropy, enables us to enforce a trajectory entropy constraint and consequently control the policy long-term stochasticity. Building on this TECRL framework, we develop a practical off-policy algorithm, DSAC-E, by extending the state-of-the-art distributional soft actor-critic with three refinements (DSAC-T). Empirical results on the OpenAI Gym benchmark demonstrate that our DSAC-E can achieve higher returns and better stability.

</details>


### [567] [Aspiration-based Perturbed Learning Automata in Games with Noisy Utility Measurements. Part A: Stochastic Stability in Non-zero-Sum Games](https://arxiv.org/abs/2511.11602)
*Georgios C. Chasparis*

Main category: cs.LG

TL;DR: 本文提出了一种新的基于收益的学习机制——基于期望的扰动学习自动机（APLA），用于分布式优化，能够在多玩家弱非循环博弈中实现纯纳什均衡的收敛，解决了传统强化学习在分布式设置下的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习在分布式多玩家博弈中难以保证收敛到理想的纯纳什均衡，尤其在非势博弈中研究较少，因此需要一种新的学习机制来克服这一限制。

Method: 引入了基于期望的学习机制APLA，其中每个玩家的动作选择概率不仅受重复选择的影响，还受到反映其满意度的期望因素的强化，并对存在噪声观测的正效用博弈进行了随机稳定性分析。

Result: 证明了APLA在多玩家正效用博弈中的随机稳定性，并建立了无限维马尔可夫链与有限维马尔可夫链之间的等价关系，进一步在弱非循环博弈中实现了收敛性分析。

Conclusion: APLA为非零和博弈中的分布式学习提供了理论支持，是首个在一般非零和博弈中实现随机稳定性完整刻画的方法，显著拓展了强化学习在分布式优化中的适用范围。

Abstract: Reinforcement-based learning has attracted considerable attention both in modeling human behavior as well as in engineering, for designing measurement- or payoff-based optimization schemes. Such learning schemes exhibit several advantages, especially in relation to filtering out noisy observations. However, they may exhibit several limitations when applied in a distributed setup. In multi-player weakly-acyclic games, and when each player applies an independent copy of the learning dynamics, convergence to (usually desirable) pure Nash equilibria cannot be guaranteed. Prior work has only focused on a small class of games, namely potential and coordination games. To address this main limitation, this paper introduces a novel payoff-based learning scheme for distributed optimization, namely aspiration-based perturbed learning automata (APLA). In this class of dynamics, and contrary to standard reinforcement-based learning schemes, each player's probability distribution for selecting actions is reinforced both by repeated selection and an aspiration factor that captures the player's satisfaction level. We provide a stochastic stability analysis of APLA in multi-player positive-utility games under the presence of noisy observations. This is the first part of the paper that characterizes stochastic stability in generic non-zero-sum games by establishing equivalence of the induced infinite-dimensional Markov chain with a finite dimensional one. In the second part, stochastic stability is further specialized to weakly acyclic games.

</details>


### [568] [Sound Logical Explanations for Mean Aggregation Graph Neural Networks](https://arxiv.org/abs/2511.11593)
*Matthew Morris,Ian Horrocks*

Main category: cs.LG

TL;DR: 本文研究了使用均值聚合和非负权重的图神经网络（MAGNNs）在知识图谱补全中的可解释性和表达能力，提出了可解释MAGNN预测的一阶逻辑片段，并通过实验证明该限制能获得与现有模型相当或更好的性能，同时生成有意义的解释并揭示训练模型中的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管均值聚合的GNN广泛用于知识图谱补全，但其可解释性和表达能力的研究仍不足，特别是缺乏对使用非负权重的均值聚合GNN的系统分析。

Method: 提出MAGNN模型，证明其可被单调逻辑规则精确刻画，并设计一个受限的一阶逻辑片段用于解释其预测；通过标准归纳基准实验验证方法的有效性。

Result: 理论推导出MAGNN可被特定单调规则和一阶逻辑片段所描述；实验表明非负权重MAGNN性能不逊于现有模型，且能生成可靠的逻辑解释，揭示模型潜在问题。

Conclusion: MAGNN可通过单调逻辑规则进行有效解释，引入非负权重不仅保持性能，还提升可解释性，有助于发现模型缺陷，推动可信赖知识图谱补全的发展。

Abstract: Graph neural networks (GNNs) are frequently used for knowledge graph completion. Their black-box nature has motivated work that uses sound logical rules to explain predictions and characterise their expressivity. However, despite the prevalence of GNNs that use mean as an aggregation function, explainability and expressivity results are lacking for them. We consider GNNs with mean aggregation and non-negative weights (MAGNNs), proving the precise class of monotonic rules that can be sound for them, as well as providing a restricted fragment of first-order logic to explain any MAGNN prediction. Our experiments show that restricting mean-aggregation GNNs to have non-negative weights yields comparable or improved performance on standard inductive benchmarks, that sound rules are obtained in practice, that insightful explanations can be generated in practice, and that the sound rules can expose issues in the trained models.

</details>


### [569] [Loss Given Default Prediction Under Measurement-Induced Mixture Distributions: An Information-Theoretic Approach](https://arxiv.org/abs/2511.11596)
*Javier Marín*

Main category: cs.LG

TL;DR: 本文研究了在违约损失率（LGD）建模中由于训练数据主要由基于预违约资产负债表的代理估计值构成而导致的数据质量问题，发现传统的随机森林等递归分割方法表现极差（负R²），而基于香农熵和互信息的信息论方法则表现出更好的泛化能力，在1218个企业破产案例中实现了0.191的R²和0.284的RMSE。


<details>
  <summary>Details</summary>
Motivation: 由于实际破产回收数据稀缺，现有LGD模型依赖大量代理数据，导致模型训练存在混合污染问题，传统方法在这种数据结构下性能下降，亟需更鲁棒的建模方法。

Method: 采用信息论方法（如香农熵和互信息）分析特征的信息含量，并构建具有更好泛化能力的LGD预测模型，与传统的随机森林等递归分割方法进行对比。

Result: 随机森林在测试集上表现极差（R² = -0.664），而信息论方法显著优于传统方法（R² = 0.191，RMSE = 0.284）；分析显示杠杆类特征包含1.510比特互信息，而规模效应仅贡献0.086比特，挑战了监管中关于规模依赖恢复的假设。

Conclusion: 在缺乏充分代表性结果数据的情况下，信息论方法为金融机构在巴塞尔III框架下部署LGD模型提供了实用指导，该发现还可推广至医学、气候预测和技术可靠性等存在类似数据混合结构的领域。

Abstract: Loss Given Default (LGD) modeling faces a fundamental data quality constraint: 90% of available training data consists of proxy estimates based on pre-distress balance sheets rather than actual recovery outcomes from completed bankruptcy proceedings. We demonstrate that this mixture-contaminated training structure causes systematic failure of recursive partitioning methods, with Random Forest achieving negative r-squared (-0.664, worse than predicting the mean) on held-out test data. Information-theoretic approaches based on Shannon entropy and mutual information provide superior generalization, achieving r-squared of 0.191 and RMSE of 0.284 on 1,218 corporate bankruptcies (1980-2023). Analysis reveals that leverage-based features contain 1.510 bits of mutual information while size effects contribute only 0.086 bits, contradicting regulatory assumptions about scale-dependent recovery. These results establish practical guidance for financial institutions deploying LGD models under Basel III requirements when representative outcome data is unavailable at sufficient scale. The findings generalize to medical outcomes research, climate forecasting, and technology reliability-domains where extended observation periods create unavoidable mixture structure in training data.

</details>


### [570] [Convergence of Multiagent Learning Systems for Traffic control](https://arxiv.org/abs/2511.11654)
*Sayambhu Sen,Shalabh Bhatnagar*

Main category: cs.LG

TL;DR: 本文填补了多智能体强化学习在交通信号控制中理论分析的空白，证明了该算法在特定条件下的收敛性。


<details>
  <summary>Details</summary>
Motivation: 尽管多智能体强化学习在交通信号控制中已显示出实证有效性，但其稳定性与收敛性的理论分析尚缺乏。

Method: 采用随机逼近方法，基于异步值迭代的单智能体收敛性证明，扩展到多智能体场景，分析学习动态。

Result: 证明了用于交通控制的独立学习多智能体强化学习算法在给定条件下具有收敛性。

Conclusion: 该研究为多智能体Q学习在交通信号控制中的应用提供了理论基础，证实其在协同任务中的收敛能力。

Abstract: Rapid urbanization in cities like Bangalore has led to severe traffic congestion, making efficient Traffic Signal Control (TSC) essential. Multi-Agent Reinforcement Learning (MARL), often modeling each traffic signal as an independent agent using Q-learning, has emerged as a promising strategy to reduce average commuter delays. While prior work Prashant L A et. al has empirically demonstrated the effectiveness of this approach, a rigorous theoretical analysis of its stability and convergence properties in the context of traffic control has not been explored. This paper bridges that gap by focusing squarely on the theoretical basis of this multi-agent algorithm. We investigate the convergence problem inherent in using independent learners for the cooperative TSC task. Utilizing stochastic approximation methods, we formally analyze the learning dynamics. The primary contribution of this work is the proof that the specific multi-agent reinforcement learning algorithm for traffic control is proven to converge under the given conditions extending it from single agent convergence proofs for asynchronous value iteration.

</details>


### [571] [Enhancing failure prediction in nuclear industry: Hybridization of knowledge- and data-driven techniques](https://arxiv.org/abs/2511.11604)
*Amaratou Mahamadou Saley,Thierry Moyaux,Aïcha Sekhari,Vincent Cheutet,Jean-Baptiste Danielou*

Main category: cs.LG

TL;DR: 本文提出了一种结合数据驱动技术与核设备领域知识的新型预测性维护方法，显著提升了核工业中故障预测的性能，相较于纯数据驱动方法，将预测时间从3小时提升至24小时，F1分数从56.36%提高到93.12%。


<details>
  <summary>Details</summary>
Motivation: 核工业系统复杂，纯数据驱动方法在预测维护需求方面存在局限，需要融合领域知识以提高预测精度和可靠性。

Method: 提出一种结合数据驱动技术和核设备领域知识的混合预测性维护方法，并通过真实案例对比现有监测方法与两种场景下的新方法性能。

Result: 相比纯数据驱动方法（预测 horizon 3小时，F1分数56.36%），该方法将预测 horizon 提升至24小时，F1分数达到93.12%，显著优于传统方法。

Conclusion: 融合领域知识的混合方法在核工业预测性维护中表现更优，验证了知识增强对模型性能的重要性，适用于高敏感、高安全要求的工业场景。

Abstract: The convergence of the Internet of Things (IoT) and Industry 4.0 has significantly enhanced data-driven methodologies within the nuclear industry, notably enhancing safety and economic efficiency. This advancement challenges the precise prediction of future maintenance needs for assets, which is crucial for reducing downtime and operational costs. However, the effectiveness of data-driven methodologies in the nuclear sector requires extensive domain knowledge due to the complexity of the systems involved. Thus, this paper proposes a novel predictive maintenance methodology that combines data-driven techniques with domain knowledge from a nuclear equipment. The methodological originality of this paper is located on two levels: highlighting the limitations of purely data-driven approaches and demonstrating the importance of knowledge in enhancing the performance of the predictive models. The applicative novelty of this work lies in its use within a domain such as a nuclear industry, which is highly restricted and ultrasensitive due to security, economic and environmental concerns. A detailed real-world case study which compares the current state of equipment monitoring with two scenarios, demonstrate that the methodology significantly outperforms purely data-driven methods in failure prediction. While purely data-driven methods achieve only a modest performance with a prediction horizon limited to 3 h and a F1 score of 56.36%, the hybrid approach increases the prediction horizon to 24 h and achieves a higher F1 score of 93.12%.

</details>


### [572] [Clustering-Based Weight Orthogonalization for Stabilizing Deep Reinforcement Learning](https://arxiv.org/abs/2511.11607)
*Guoqing Ma,Yuhan Zhang,Yuming Dai,Guangfu Hao,Yang Chen,Shan Yu*

Main category: cs.LG

TL;DR: 提出了一种名为COWM的层，用于缓解强化学习中的环境非平稳性问题，提升样本效率和学习速度。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体通常假设环境是平稳的，但在实际中环境往往具有非平稳性，导致样本效率低和训练迭代次数高。

Method: 引入Clustering Orthogonal Weight Modified (COWM) 层，结合聚类技术和投影矩阵，可嵌入任何RL算法的策略网络中以稳定学习过程。

Result: 在基于视觉和状态的DMControl基准上分别取得了9%和12.6%的性能提升，且在多种算法和任务中表现出良好的鲁棒性和通用性。

Conclusion: COWM层能有效缓解非平稳环境带来的挑战，显著提升强化学习的效率和稳定性。

Abstract: Reinforcement learning (RL) has made significant advancements, achieving superhuman performance in various tasks. However, RL agents often operate under the assumption of environmental stationarity, which poses a great challenge to learning efficiency since many environments are inherently non-stationary. This non-stationarity results in the requirement of millions of iterations, leading to low sample efficiency. To address this issue, we introduce the Clustering Orthogonal Weight Modified (COWM) layer, which can be integrated into the policy network of any RL algorithm and mitigate non-stationarity effectively. The COWM layer stabilizes the learning process by employing clustering techniques and a projection matrix. Our approach not only improves learning speed but also reduces gradient interference, thereby enhancing the overall learning efficiency. Empirically, the COWM outperforms state-of-the-art methods and achieves improvements of 9% and 12.6% in vision based and state-based DMControl benchmark. It also shows robustness and generality across various algorithms and tasks.

</details>


### [573] [Small Vocabularies, Big Gains: Pretraining and Tokenization in Time Series Models](https://arxiv.org/abs/2511.11622)
*Alexis Roger,Gwen Legate,Kashif Rasul,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.LG

TL;DR: 本研究系统探讨了时间序列基础模型中分词器设计（如缩放和量化策略）与迁移学习对模型性能的影响，发现分词器配置主要影响模型的表示能力和稳定性，而迁移学习则影响优化效率和对齐性。实验表明，预训练模型能更有效地利用设计良好的分词器，尤其是在小词汇量下；反之，不匹配的分词可能削弱甚至逆转预训练的优势。研究强调在多模态预测中，结合小型高效词汇表与预训练权重尤为重要。


<details>
  <summary>Details</summary>
Motivation: 为了提升时间序列预测中基础模型的性能，需要深入理解分词器设计和迁移学习的作用机制，特别是在离散表示学习中如何有效处理连续信号。

Method: 通过实证训练实验与理论分析相结合的方法，系统评估不同分词器配置（如缩放、量化、词汇大小）与是否预训练对模型性能的影响。

Result: 发现分词器设计主导模型的表示能力与稳定性，迁移学习影响优化效率；预训练模型在良好分词设计下表现更优，尤其在小词汇量时优势明显；但若分词与任务不匹配，预训练的好处可能被削弱或反转。

Conclusion: 分词器设计在时间序列建模中至关重要，应与迁移学习协同优化；建议在多模态场景下采用小而高效的共享词汇表，并结合预训练权重以实现最佳性能。

Abstract: Tokenization and transfer learning are two critical components in building state of the art time series foundation models for forecasting. In this work, we systematically study the effect of tokenizer design, specifically scaling and quantization strategies, on model performance, alongside the impact of pretraining versus random initialization. We show that tokenizer configuration primarily governs the representational capacity and stability of the model, while transfer learning influences optimization efficiency and alignment. Using a combination of empirical training experiments and theoretical analyses, we demonstrate that pretrained models consistently leverage well-designed tokenizers more effectively, particularly at smaller vocabulary sizes. Conversely, misaligned tokenization can diminish or even invert the benefits of pretraining. These findings highlight the importance of careful tokenization in time series modeling and suggest that combining small, efficient vocabularies with pretrained weights is especially advantageous in multi-modal forecasting settings, where the overall vocabulary must be shared across modalities. Our results provide concrete guidance for designing tokenizers and leveraging transfer learning in discrete representation learning for continuous signals.

</details>


### [574] [Early GVHD Prediction in Liver Transplantation via Multi-Modal Deep Learning on Imbalanced EHR Data](https://arxiv.org/abs/2511.11623)
*Yushan Jiang,Shuteng Niu,Dongjin Song,Yichen Wang,Jingna Feng,Xinyue Hu,Liu Yang,Cui Tao*

Main category: cs.LG

TL;DR: 本研究提出了一种多模态深度学习框架，用于整合异质且不平衡的电子健康记录（EHR），以实现肝移植后移植物抗宿主病（GVHD）的早期预测。该方法在处理缺失值和极端类别不平衡方面表现出色，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: GVHD是肝移植中罕见但致命的并发症，死亡率极高，亟需在术前进行早期预测以实现及时干预。现有的方法难以有效处理EHR中的多模态性、数据缺失和极端类别不平衡问题。

Method: 研究基于梅奥诊所2100名肝移植患者的术前EHR数据（包含42例GVHD），构建了一个动态融合患者人口统计学、实验室检查、诊断和药物四种模态的多模态深度学习框架，并采用基于AUC的优化策略应对类别不平衡。

Result: 该框架在测试中达到0.836的AUC、0.157的AUPRC、0.768的召回率和0.803的特异性，优于所有单模态和多模态基线模型，能有效捕捉不同模态间的互补信息。

Conclusion: 所提出的多模态深度学习框架显著提升了GVHD的早期预测性能，为解决真实世界EHR数据中的异质性和极端类别不平衡问题提供了有效方案，具有临床应用潜力。

Abstract: Graft-versus-host disease (GVHD) is a rare but often fatal complication in liver transplantation, with a very high mortality rate. By harnessing multi-modal deep learning methods to integrate heterogeneous and imbalanced electronic health records (EHR), we aim to advance early prediction of GVHD, paving the way for timely intervention and improved patient outcomes. In this study, we analyzed pre-transplant electronic health records (EHR) spanning the period before surgery for 2,100 liver transplantation patients, including 42 cases of graft-versus-host disease (GVHD), from a cohort treated at Mayo Clinic between 1992 and 2025. The dataset comprised four major modalities: patient demographics, laboratory tests, diagnoses, and medications. We developed a multi-modal deep learning framework that dynamically fuses these modalities, handles irregular records with missing values, and addresses extreme class imbalance through AUC-based optimization. The developed framework outperforms all single-modal and multi-modal machine learning baselines, achieving an AUC of 0.836, an AUPRC of 0.157, a recall of 0.768, and a specificity of 0.803. It also demonstrates the effectiveness of our approach in capturing complementary information from different modalities, leading to improved performance. Our multi-modal deep learning framework substantially improves existing approaches for early GVHD prediction. By effectively addressing the challenges of heterogeneity and extreme class imbalance in real-world EHR, it achieves accurate early prediction. Our proposed multi-modal deep learning method demonstrates promising results for early prediction of a GVHD in liver transplantation, despite the challenge of extremely imbalanced EHR data.

</details>


### [575] [MedFedPure: A Medical Federated Framework with MAE-based Detection and Diffusion Purification for Inference-Time Attacks](https://arxiv.org/abs/2511.11625)
*Mohammad Karami,Mohammad Reza Nemati,Aidin Kazemi,Ali Mikaeili Barzili,Hamid Azadegan,Behzad Moshiri*

Main category: cs.LG

TL;DR: 本文提出了一种名为MedFedPure的个性化联邦学习防御框架，用于在推理阶段保护医学图像AI模型免受对抗攻击，同时保持隐私和准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽能保护患者隐私，但使模型易受对抗攻击，现有防御方法难以应对医疗场景的去中心化与数据异构性。

Method: 结合个性化联邦学习、基于掩码自编码器（MAE）的异常检测和自适应扩散去噪模块，仅对可疑样本进行净化处理。

Result: 在Br35H脑MRI数据集上，面对强攻击时对抗鲁棒性从49.50%提升至87.33%，干净样本准确率达97.67%。

Conclusion: MedFedPure能在不牺牲隐私和精度的前提下，有效提升联邦学习下医学AI系统的安全性和可靠性，适用于临床部署。

Abstract: Artificial intelligence (AI) has shown great potential in medical imaging, particularly for brain tumor detection using Magnetic Resonance Imaging (MRI). However, the models remain vulnerable at inference time when they are trained collaboratively through Federated Learning (FL), an approach adopted to protect patient privacy. Adversarial attacks can subtly alter medical scans in ways invisible to the human eye yet powerful enough to mislead AI models, potentially causing serious misdiagnoses. Existing defenses often assume centralized data and struggle to cope with the decentralized and diverse nature of federated medical settings. In this work, we present MedFedPure, a personalized federated learning defense framework designed to protect diagnostic AI models at inference time without compromising privacy or accuracy. MedFedPure combines three key elements: (1) a personalized FL model that adapts to the unique data distribution of each institution; (2) a Masked Autoencoder (MAE) that detects suspicious inputs by exposing hidden perturbations; and (3) an adaptive diffusion-based purification module that selectively cleans only the flagged scans before classification. Together, these steps offer robust protection while preserving the integrity of normal, benign images. We evaluated MedFedPure on the Br35H brain MRI dataset. The results show a significant gain in adversarial robustness, improving performance from 49.50% to 87.33% under strong attacks, while maintaining a high clean accuracy of 97.67%. By operating locally and in real time during diagnosis, our framework provides a practical path to deploying secure, trustworthy, and privacy-preserving AI tools in clinical workflows.
  Index Terms: cancer, tumor detection, federated learning, masked autoencoder, diffusion, privacy

</details>


### [576] [SA-EMO: Structure-Aligned Encoder Mixture of Operators for Generalizable Full-waveform Inversion](https://arxiv.org/abs/2511.11627)
*Wang Zhenyu,Li Peiyuan,Shi Yongxiang,Wu Ruoyu,Zhang Lei*

Main category: cs.LG

TL;DR: 提出了一种结构对齐的编码器-混合算子（SA-EMO）架构，用于未知地下结构下的速度场反演，显著提升了全波形反演的精度与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统全波形反演（FWI）方法计算复杂、易病态，而现有深度学习方法多依赖单一CNN或神经算子，在复杂地质条件下泛化能力差，难以区分不同地质类型。因此需要一种更具适应性和物理一致性的模型。

Method: 设计了结构对齐编码器，将高维地震波场映射到物理一致的潜在空间，消除波形与速度域间的时空不匹配，并恢复高频成分；采用自适应路由机制融合多种神经算子专家（如谱、小波、多尺度和局部算子）进行速度模型预测。

Result: 在OpenFWI和Marmousi2数据集上验证，SA-EMO相比传统CNN或单算子方法平均MAE降低约58.443%，边界分辨率提升约10.308%；消融实验表明各模块均有显著贡献。

Conclusion: SA-EMO为高效、可扩展且具物理可解释性的全波形反演提供了新范式。

Abstract: Full-waveform inversion (FWI) can produce high-resolution subsurface models, yet it remains inherently ill-posed, highly nonlinear, and computationally intensive. Although recent deep learning and numerical acceleration methods have improved speed and scalability, they often rely on single CNN architectures or single neural operators, which struggle to generalize in unknown or complex geological settings and are ineffective at distinguishing diverse geological types. To address these issues, we propose a Structure-Aligned Encoder-Mixture-of-Operators (SA-EMO) architecture for velocity-field inversion under unknown subsurface structures. First, a structure-aligned encoder maps high-dimensional seismic wavefields into a physically consistent latent space, thereby eliminating spatio-temporal mismatch between the waveform and velocity domains, recovering high-frequency components, and enhancing feature generalization. Then, an adaptive routing mechanism selects and fuses multiple neural-operator experts, including spectral, wavelet, multiscale, and local operators, to predict the velocity model. We systematically evaluate our approach on the OpenFWI benchmark and the Marmousi2 dataset. Results show that SA-EMO significantly outperforms traditional CNN or single-operator methods, achieving an average MAE reduction of approximately 58.443% and an improvement in boundary resolution of about 10.308%. Ablation studies further reveal that the structure-aligned encoder, the expert-fusion mechanism, and the routing module each contribute markedly to the performance gains. This work introduces a new paradigm for efficient, scalable, and physically interpretable full-waveform inversion.

</details>


### [577] [On the Fundamental Limits of LLMs at Scale](https://arxiv.org/abs/2511.12869)
*Muhammad Ahmed Mohsin,Muhammad Umer,Ahsan Bilal,Zeeshan Memon,Muhammad Ibtsaam Qadir,Sagnik Bhattacharya,Hassan Rizwan,Abhiram R. Gorle,Maahe Zehra Kazmi,Ayesha Mohsin,Muhammad Usman Rafique,Zihao He,Pulkit Mehta,Muhammad Ali Jamshed,John M. Cioffi*

Main category: cs.LG

TL;DR: 本文提出了一个统一的、基于证明的框架，用以形式化大语言模型（LLM）扩展的内在理论极限，指出了五个根本性限制：幻觉、上下文压缩、推理退化、检索脆弱性和多模态错位，并结合理论与实证分析了可扩展性的边界及缓解路径。


<details>
  <summary>Details</summary>
Motivation: 现有研究对大语言模型扩展中的问题多为经验性描述，缺乏从计算、信息与学习基本极限出发的理论综合。本文旨在填补这一空白，建立严格的理论基础。

Method: 通过可计算性理论中的对角化方法和不可判定性分析模型错误的必然性；利用信息论和统计学原理分析准确率限制；结合几何与计算效应解释上下文压缩问题；并通过定理与实证相结合的方式系统分析五大限制因素。

Result: 揭示了LLM在扩展过程中不可避免的理论天花板：存在无法消除的错误源、信息压缩误差、上下文有效长度受限、检索语义漂移以及多模态浅层对齐等问题；同时展示了likelihood训练偏向模式补全而非推理等机制性缺陷。

Conclusion: 单纯扩大规模无法解决LLM的根本局限，必须结合有界预言检索、位置课程设计、稀疏或分层注意力等结构化方法来突破瓶颈，未来的发展需依赖理论指导下的架构创新而非单纯scaling。

Abstract: Large Language Models (LLMs) have benefited enormously from scaling, yet these gains are bounded by five fundamental limitations: (1) hallucination, (2) context compression, (3) reasoning degradation, (4) retrieval fragility, and (5) multimodal misalignment. While existing surveys describe these phenomena empirically, they lack a rigorous theoretical synthesis connecting them to the foundational limits of computation, information, and learning. This work closes that gap by presenting a unified, proof-informed framework that formalizes the innate theoretical ceilings of LLM scaling. First, computability and uncomputability imply an irreducible residue of error: for any computably enumerable model family, diagonalization guarantees inputs on which some model must fail, and undecidable queries (e.g., halting-style tasks) induce infinite failure sets for all computable predictors. Second, information-theoretic and statistical constraints bound attainable accuracy even on decidable tasks, finite description length enforces compression error, and long-tail factual knowledge requires prohibitive sample complexity. Third, geometric and computational effects compress long contexts far below their nominal size due to positional under-training, encoding attenuation, and softmax crowding. We further show how likelihood-based training favors pattern completion over inference, how retrieval under token limits suffers from semantic drift and coupling noise, and how multimodal scaling inherits shallow cross-modal alignment. Across sections, we pair theorems and empirical evidence to outline where scaling helps, where it saturates, and where it cannot progress, providing both theoretical foundations and practical mitigation paths like bounded-oracle retrieval, positional curricula, and sparse or hierarchical attention.

</details>


### [578] [Global Feature Enhancing and Fusion Framework for Strain Gauge Time Series Classification](https://arxiv.org/abs/2511.11629)
*Xu Zhang,Peng Wang,Chen Wang,Zhe Xu,Xiaohua Nie,Wei Wang*

Main category: cs.LG

TL;DR: 提出了一种基于超图的全局特征学习与融合框架，用于增强应变计状态时间序列的表示能力，提升识别准确率。


<details>
  <summary>Details</summary>
Motivation: 传统CNN在时间序列分类中仅提取局部特征，难以应对局部相似但全局不同的应变计数据，尤其在飞机机翼等工业场景中表现受限。

Method: 通过构建全局特征和学习局部特征间的高阶关系，利用超图模型进行全局特征学习与融合，结合局部与全局信息进行分类。

Result: 在工业SGS数据集和公开UCR数据集上验证了方法的有效性，表现出优于现有方法的泛化能力和识别精度。

Conclusion: 所提超图框架能有效捕捉时间序列的全局结构信息，显著提升应变计状态识别的准确性与鲁棒性。

Abstract: Strain Gauge Status (SGS) recognition is crucial in the field of intelligent manufacturing based on the Internet of Things, as accurate identification helps timely detection of failed mechanical components, avoiding accidents. The loading and unloading sequences generated by strain gauges can be identified through time series classification (TSC) algorithms. Recently, deep learning models, e.g., convolutional neural networks (CNNs) have shown remarkable success in the TSC task, as they can extract discriminative local features from the subsequences to identify the time series. However, we observe that only the local features may not be sufficient for expressing the time series, especially when the local sub-sequences between different time series are very similar, e.g., SGS data of aircraft wings in static strength experiments. Nevertheless, CNNs suffer from the limitation in extracting global features due to the nature of convolution operations. For extracting global features to more comprehensively represent the SGS time series, we propose two insights: (i) Constructing global features through feature engineering. (ii) Learning high-order relationships between local features to capture global features. To realize and utilize them, we propose a hypergraph-based global feature learning and fusion framework, which learns and fuses global features for semantic consistency to enhance the representation of SGS time series, thereby improving recognition accuracy. Our method designs are validated on industrial SGS and public UCR datasets, showing better generalization for unseen data in SGS recognition.

</details>


### [579] [Transformer-Based Scalable Multi-Agent Reinforcement Learning for Networked Systems with Long-Range Interactions](https://arxiv.org/abs/2511.13103)
*Vidur Sinha,Muhammed Ustaomeroglu,Guannan Qu*

Main category: cs.LG

TL;DR: STACCA是一种基于Transformer的多智能体强化学习框架，解决了现有方法在长距离依赖建模和跨网络拓扑泛化能力上的局限性，通过共享图Transformer架构和反事实优势估计器，在流行病控制和谣言传播等任务中表现出优异的性能、可扩展性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有MARL方法在建模长距离依赖（如级联故障或疫情传播）方面存在不足，且难以泛化到不同网络结构，需针对新图重新训练，限制了其在大规模网络控制中的应用。

Method: 提出STACCA框架，采用集中式图Transformer作为Critic以捕捉系统级长程依赖，共享图Transformer作为Actor以实现跨网络结构的策略泛化，并引入与状态值函数兼容的反事实优势估计器以改善信用分配。

Result: 在疫情控制和谣言传播任务上，STACCA相比基线方法表现出更优的性能、更强的网络拓扑泛化能力和良好的可扩展性。

Conclusion: 基于Transformer的MARL架构能够有效支持大规模网络系统的可扩展与可泛化控制，STACCA为复杂网络动态下的多智能体协作提供了新的解决方案。

Abstract: Multi-agent reinforcement learning (MARL) has shown promise for large-scale network control, yet existing methods face two major limitations. First, they typically rely on assumptions leading to decay properties of local agent interactions, limiting their ability to capture long-range dependencies such as cascading power failures or epidemic outbreaks. Second, most approaches lack generalizability across network topologies, requiring retraining when applied to new graphs. We introduce STACCA (Shared Transformer Actor-Critic with Counterfactual Advantage), a unified transformer-based MARL framework that addresses both challenges. STACCA employs a centralized Graph Transformer Critic to model long-range dependencies and provide system-level feedback, while its shared Graph Transformer Actor learns a generalizable policy capable of adapting across diverse network structures. Further, to improve credit assignment during training, STACCA integrates a novel counterfactual advantage estimator that is compatible with state-value critic estimates. We evaluate STACCA on epidemic containment and rumor-spreading network control tasks, demonstrating improved performance, network generalization, and scalability. These results highlight the potential of transformer-based MARL architectures to achieve scalable and generalizable control in large-scale networked systems.

</details>


### [580] [Predicting Grain Growth in Polycrystalline Materials Using Deep Learning Time Series Models](https://arxiv.org/abs/2511.11630)
*Eliane Younes,Elie Hachem,Marc Bernacki*

Main category: cs.LG

TL;DR: 本研究评估了多种深度学习模型（如RNN、LSTM、TCN和Transformer）用于预测晶粒生长过程中的晶粒尺寸分布，采用基于均场统计描述符的方法，显著提高了计算效率和预测稳定性。


<details>
  <summary>Details</summary>
Motivation: 晶粒生长显著影响材料的力学性能，准确预测晶粒尺寸分布是微结构工程的关键目标，但传统全场模拟计算成本高，亟需高效替代方法。

Method: 从高保真模拟中提取均场统计描述符，构建包含120个晶粒生长序列的数据集，并以归一化的晶粒尺寸分布随时间变化作为输入，采用递归预测策略训练多种深度学习模型进行未来分布预测。

Result: LSTM网络在所有测试模型中表现最佳，预测精度超过90%，长期预测稳定且保持物理一致性，单序列计算时间由约20分钟缩短至数秒；其他模型在远期预测中趋于发散。

Conclusion: 基于低维描述符和LSTM的预测方法在晶粒生长预测中具有高效、准确的优势，为数字孪生体构建和工艺优化提供了可行的技术路径。

Abstract: Grain Growth strongly influences the mechanical behavior of materials, making its prediction a key objective in microstructural engineering. In this study, several deep learning approaches were evaluated, including recurrent neural networks (RNN), long short-term memory (LSTM), temporal convolutional networks (TCN), and transformers, to forecast grain size distributions during grain growth. Unlike full-field simulations, which are computationally demanding, the present work relies on mean-field statistical descriptors extracted from high-fidelity simulations. A dataset of 120 grain growth sequences was processed into normalized grain size distributions as a function of time. The models were trained to predict future distributions from a short temporal history using a recursive forecasting strategy. Among the tested models, the LSTM network achieved the highest accuracy (above 90\%) and the most stable performance, maintaining physically consistent predictions over extended horizons while reducing computation time from about 20 minutes per sequence to only a few seconds, whereas the other architectures tended to diverge when forecasting further in time. These results highlight the potential of low-dimensional descriptors and LSTM-based forecasting for efficient and accurate microstructure prediction, with direct implications for digital twin development and process optimization.

</details>


### [581] [KForge: Program Synthesis for Diverse AI Hardware Accelerators](https://arxiv.org/abs/2511.13274)
*Taras Sereda,Tom St. John,Burak Bartan,Natalie Serrino,Sachin Katti,Zain Asgar*

Main category: cs.LG

TL;DR: KForge是一个基于LLM代理的平台无关框架，通过生成代理和性能分析代理的协作，实现跨不同加速器的GPU内核优化。


<details>
  <summary>Details</summary>
Motivation: GPU内核对机器学习性能至关重要，但在不同加速器上难以优化，现有方法缺乏跨平台适应性。

Method: 提出KForge框架，包含两个协同工作的LLM代理：生成代理通过编译和正确性反馈迭代改进程序；性能分析代理解析性能数据以指导优化，并仅需单一样例即可适配新平台。

Result: 实现了跨NVIDIA CUDA和Apple Metal等差异较大的并行计算平台的有效程序合成；证明了跨平台知识迁移可显著提升生成质量；仅需一个示例即可针对新平台进行优化。

Conclusion: KForge展示了基于LLM代理的架构在平台无关GPU内核优化中的有效性与可行性，支持多样化性能数据输入和跨架构知识迁移。

Abstract: GPU kernels are critical for ML performance but difficult to optimize across diverse accelerators. We present KForge, a platform-agnostic framework built on two collaborative LLM-based agents: a generation agent that produces and iteratively refines programs through compilation and correctness feedback, and a performance analysis agent that interprets profiling data to guide optimization. This agent-based architecture requires only a single-shot example to target new platforms.
  We make three key contributions: (1) introducing an iterative refinement system where the generation agent and performance analysis agent collaborate through functional and optimization passes, interpreting diverse profiling data (from programmatic APIs to GUI-based tools) to generate actionable recommendations that guide program synthesis for arbitrary accelerators; (2) demonstrating that the generation agent effectively leverages cross-platform knowledge transfer, where a reference implementation from one architecture substantially improves generation quality for different hardware targets; and (3) validating the platform-agnostic nature of our approach by demonstrating effective program synthesis across fundamentally different parallel computing platforms: NVIDIA CUDA and Apple Metal.

</details>


### [582] [Toward Better Generalization in Few-Shot Learning through the Meta-Component Combination](https://arxiv.org/abs/2511.11632)
*Qiuhao Zeng*

Main category: cs.LG

TL;DR: 提出一种基于元组件组合的新型元学习算法，通过在可见类上学习并施加正交正则化来提升分类器对未见类的泛化能力，在少样本学习任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于度量的元学习方法在少样本学习中容易对已见类过拟合，导致在未见类上泛化能力差，因此需要提升模型的泛化性。

Method: 将每个分类器建模为多个元组件的组合，通过跨元学习episode学习这些元组件，并引入正交正则化以增强元组件的多样性并捕捉不同分类器间的共享子结构。

Result: 在多个少样本学习基准任务上的实验表明，该方法显著优于现有方法，具有更强的泛化能力。

Conclusion: 所提出的基于元组件组合的元学习方法有效提升了分类器在未见类上的泛化性能，为少样本学习提供了新的建模范式。

Abstract: In few-shot learning, classifiers are expected to generalize to unseen classes given only a small number of instances of each new class. One of the popular solutions to few-shot learning is metric-based meta-learning. However, it highly depends on the deep metric learned on seen classes, which may overfit to seen classes and fail to generalize well on unseen classes. To improve the generalization, we explore the substructures of classifiers and propose a novel meta-learning algorithm to learn each classifier as a combination of meta-components. Meta-components are learned across meta-learning episodes on seen classes and disentangled by imposing an orthogonal regularizer to promote its diversity and capture various shared substructures among different classifiers. Extensive experiments on few-shot benchmark tasks show superior performances of the proposed method.

</details>


### [583] [A Deep Learning Model to Predicting Changes in Consumer Attributes for New Line-extended Products](https://arxiv.org/abs/2511.11646)
*Li Yinxing,Tsukasa Ishigaki*

Main category: cs.LG

TL;DR: 本文提出了一种基于条件表格变分自编码器（CTVAE）的深度学习模型，用于预测新产品线延伸中消费者属性的变化，从而支持有效的营销决策。


<details>
  <summary>Details</summary>
Motivation: 过度的产品线延伸可能损害品牌形象，因此需要基于消费者需求选择适当的延伸策略。企业应在进入市场前了解目标消费者的关键属性。

Method: 提出一种名为CTVAE（Conditional Tabular Variational Auto-Encoder）的新型深度学习模型，利用大规模消费者与产品表格数据生成合成数据，以预测消费者属性变化。

Result: 实验结果表明，CTVAE在预测性能上优于现有模型，并能为改变包装或口味的新产品提供有效的产品线营销启示。

Conclusion: 该方法有助于避免品牌内部竞争（cannibalization），并支持产品形象设计与营销策略制定，具有较强的实际应用价值。

Abstract: Product line extension is a marketing strategy that enhances a company's sphere of influence. Because excessive line extensions disrupt brand image, only appropriate line extensions based on consumer needs are desirable. Marketers should know the key consumer attributes of the primary customers for new line-extended products before companies enter the market. This paper describes a method for predicting changes in consumer attributes for new line-extended products using a novel deep learning model. The proposed model, Conditional Tabular Variational Auto-Encoder (CTVAE), generates synthetic data from large-scale tabular data of consumers and products. It can provide various implications about effective product line marketing for marketers. The experimental results demonstrate that the CTVAE offers superior prediction performance than existing models. We indicate implications for new products that change containers or flavors for effective product line marketing. The proposed approach has the potential to contribute to avoiding cannibalization and to designing product images and marketing strategies.

</details>


### [584] [An Explainable and Fair AI Tool for PCOS Risk Assessment: Calibration, Subgroup Equity, and Interactive Clinical Deployment](https://arxiv.org/abs/2511.11636)
*Asma Sadia Khan,Sadia Tabassum*

Main category: cs.LG

TL;DR: 提出一种公平性审计且可解释的机器学习框架用于多囊卵巢综合征（PCOS）预测，结合SHAP与人口统计学审计识别诊断差异，并通过校准提升模型可靠性，最终实现高准确率预测与临床可用性。


<details>
  <summary>Details</summary>
Motivation: 为解决PCOS诊断中潜在的亚群偏差问题，提升模型的公平性、可解释性与临床实用性，确保不同人群中的可靠风险预测。

Method: 集成SHAP特征归因与人口统计学公平性审计，使用Random Forest、SVM和XGBoost模型并结合等渗校准与Platt校准进行对比，采用Brier Score和ECE评估校准性能，并开发Streamlit网页界面支持实时预测与交互分析。

Result: 校准后的随机森林模型达到90.8%准确率，SHAP分析显示卵泡数、体重增加和月经不规律最重要；SVM等渗校准ECE最低（0.0541），但随机森林在校准与可解释性间平衡更优（Brier=0.0678, ECE=0.0666）；年龄子群分析显示<25岁表现较差（69.2%），肥胖与瘦型患者分别表现出高精度与高召回。

Conclusion: 该框架在保持高预测性能的同时实现了良好的校准性、可解释性与公平性，并通过Web界面促进AI向临床转化，具有实际应用潜力。

Abstract: This paper presents a fairness-audited and interpretable machine learning framework for predicting polycystic ovary syndrome (PCOS), designed to evaluate model performance and identify diagnostic disparities across patient subgroups. The framework integrated SHAP-based feature attributions with demographic audits to connect predictive explanations with observed disparities for actionable insights. Probabilistic calibration metrics (Brier Score and Expected Calibration Error) are incorporated to ensure reliable risk predictions across subgroups. Random Forest, SVM, and XGBoost models were trained with isotonic and Platt scaling for calibration and fairness comparison. A calibrated Random Forest achieved a high predictive accuracy of 90.8%. SHAP analysis identified follicle count, weight gain, and menstrual irregularity as the most influential features, which are consistent with the Rotterdam diagnostic criteria. Although the SVM with isotonic calibration achieved the lowest calibration error (ECE = 0.0541), the Random Forest model provided a better balance between calibration and interpretability (Brier = 0.0678, ECE = 0.0666). Therefore, it was selected for detailed fairness and SHAP analyses. Subgroup analysis revealed that the model performed best among women aged 25-35 (accuracy 90.9%) but underperformed in those under 25 (69.2%), highlighting age-related disparities. The model achieved perfect precision in obese women and maintained high recall in lean PCOS cases, demonstrating robustness across phenotypes. Finally, a Streamlit-based web interface enables real-time PCOS risk assessment, Rotterdam criteria evaluation, and interactive 'what-if' analysis, bridging the gap between AI research and clinical usability.

</details>


### [585] [Enhancing PINN Accuracy for the RLW Equation: Adaptive and Conservative Approaches](https://arxiv.org/abs/2511.11638)
*Aamir Shehzad*

Main category: cs.LG

TL;DR: 本研究提出了两种改进的物理信息神经网络（PINN）方法——自适应损失加权和显式守恒律约束，用于求解正则长波（RLW）方程。结果表明，不同问题适用不同方法：自适应PINN在非线性相互作用（如孤子碰撞）中表现更优，而保守PINN在长期行为预测（如单孤子和涌波演化）中更佳。研究发现，强制守恒可能损害高度非线性系统的优化，需特殊训练策略。两种方法精度达O(10⁻⁵)，验证了PINN在无网格求解复杂偏微分方程中的有效性，并为PINN设计提供了问题导向的指导原则。


<details>
  <summary>Details</summary>
Motivation: 标准PINN在求解RLW方程时误差较大，且现有方法对不同类型问题的适应性不足，因此需要开发更有效的PINN变体以提升求解精度与稳定性。

Method: 提出两种改进PINN：1）自适应PINN，采用自适应损失权重；2）保守PINN，显式施加守恒律。通过三个基准测试（单孤子传播、双孤子相互作用、涌波演化）评估性能。

Result: 自适应PINN在孤子碰撞等强非线性问题中优于其他方法；保守PINN在长期演化问题中表现更好；但显式守恒可能损害高度非线性系统的优化；两种方法精度均达O(10⁻⁵)，接近传统数值解。

Conclusion: PINN的有效性依赖于问题类型；显式守恒并非总是有益，需谨慎使用；研究为针对特定PDE问题设计PINN提供了实用指南。

Abstract: Standard physics-informed neural network implementations have produced large error rates when using these models to solve the regularized long wave (RLW) equation. Two improved PINN approaches were developed in this research: an adaptive approach with self-adaptive loss weighting and a conservative approach enforcing explicit conservation laws. Three benchmark tests were used to demonstrate how effective PINN's are as they relate to the type of problem being solved (i.e., time dependent RLW equation). The first was a single soliton traveling along a line (propagation), the second was the interaction between two solitons, and the third was the evolution of an undular bore over the course of $t=250$. The results demonstrated that the effectiveness of PINNs are problem specific. The adaptive PINN was significantly better than both the conservative PINN and the standard PINN at solving problems involving complex nonlinear interactions such as colliding two solitons. The conservative approach was significantly better at solving problems involving long term behavior of single solitons and undular bores. However, the most important finding from this research is that explicitly enforcing conservation laws may be harmful to optimizing the solution of highly nonlinear systems of equations and therefore requires special training methods. The results from our adaptive and conservative approaches were within $O(10^{-5})$ of established numerical solutions for the same problem, thus demonstrating that PINNs can provide accurate solutions to complex systems of partial differential equations without the need for a discretization of space or time (mesh free). Moreover, the finding from this research challenges the assumptions that conservation enforcement will always improve the performance of a PINN and provides researchers with guidelines for designing PINNs for use on specific types of problems.

</details>


### [586] [EcoSpa: Efficient Transformer Training with Coupled Sparsity](https://arxiv.org/abs/2511.11641)
*Jinqi Xiao,Cheng Luo,Lingyi Huang,Cheng Yang,Yang Sui,Huy Phan,Xiao Zang,Yibiao Ying,Zhexiang Tang,Anima Anandkumar,Bo Yuan*

Main category: cs.LG

TL;DR: EcoSpa是一种高效的结构化稀疏训练方法，通过联合评估和剪枝耦合权重矩阵对，保持其在注意力和前馈层中的交互模式，显著提升Transformer模型的训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏训练方法未能保留权重矩阵间的关键结构关系，导致高稀疏度下性能下降。

Method: 提出EcoSpa，联合评估并剪枝成对耦合的权重矩阵，通过行/列对齐移除保持交互结构，并在预训练和微调中实现结构重要性校准。

Result: 在LLaMA-1B上实现50%内存减少和21%训练加速，GPT-2-Medium上达到2.2倍压缩比且困惑度降低2.4，推理速度提升1.6倍。

Conclusion: EcoSpa无需定制硬件，使用标准PyTorch操作即可高效训练稀疏Transformer，使高性能模型训练可在通用硬件上进行。

Abstract: Transformers have become the backbone of modern AI, yet their high computational demands pose critical system challenges. While sparse training offers efficiency gains, existing methods fail to preserve critical structural relationships between weight matrices that interact multiplicatively in attention and feed-forward layers. This oversight leads to performance degradation at high sparsity levels. We introduce EcoSpa, an efficient structured sparse training method that jointly evaluates and sparsifies coupled weight matrix pairs, preserving their interaction patterns through aligned row/column removal. EcoSpa introduces a new granularity for calibrating structural component importance and performs coupled estimation and sparsification across both pre-training and fine-tuning scenarios. Evaluations demonstrate substantial improvements: EcoSpa enables efficient training of LLaMA-1B with 50\% memory reduction and 21\% faster training, achieves $2.2\times$ model compression on GPT-2-Medium with $2.4$ lower perplexity, and delivers $1.6\times$ inference speedup. The approach uses standard PyTorch operations, requiring no custom hardware or kernels, making efficient transformer training accessible on commodity hardware.

</details>


### [587] [AIF: Asynchronous Inference Framework for Cost-Effective Pre-Ranking](https://arxiv.org/abs/2511.12934)
*Zhi Kou,Xiang-Rong Sheng,Shuguang Han,Zhishan Zhao,Yueyao Cheng,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: 提出异步推理框架AIF，通过解耦交互无关的计算组件并提前执行，显著提升工业推荐系统预排序阶段的计算效率与特征质量，已在淘宝展示广告系统成功部署。


<details>
  <summary>Details</summary>
Motivation: 传统DNN预排序模型采用串行架构，导致相同用户/物品的重复计算和高延迟，限制了模型容量和系统效率。

Method: 提出异步推理框架AIF，将用户侧计算与检索阶段并行化，物品侧计算以近线方式提前完成；在线预测仅处理交互相关部分，并采用近似方法优化实时计算。

Result: AIF显著降低了延迟，提升了计算效率，释放资源用于增强交互无关部分的特征和模型结构，在淘宝广告系统中实现有效部署。

Conclusion: 通过框架与模型协同设计，AIF在不显著增加计算开销的前提下，显著提升预排序性能，为工业级推荐系统提供了高效可扩展的解决方案。

Abstract: In industrial recommendation systems, pre-ranking models based on deep neural networks (DNNs) commonly adopt a sequential execution framework: feature fetching and model forward computation are triggered only after receiving candidates from the upstream retrieval stage. This design introduces inherent bottlenecks, including redundant computations of identical users/items and increased latency due to strictly sequential operations, which jointly constrain the model's capacity and system efficiency. To address these limitations, we propose the Asynchronous Inference Framework (AIF), a cost-effective computational architecture that decouples interaction-independent components, those operating within a single user or item, from real-time prediction. AIF reorganizes the model inference process by performing user-side computations in parallel with the retrieval stage and conducting item-side computations in a nearline manner. This means that interaction-independent components are calculated just once and completed before the real-time prediction phase of the pre-ranking stage. As a result, AIF enhances computational efficiency and reduces latency, freeing up resources to significantly improve the feature set and model architecture of interaction-independent components. Moreover, we delve into model design within the AIF framework, employing approximated methods for interaction-dependent components in online real-time predictions. By co-designing both the framework and the model, our solution achieves notable performance gains without significantly increasing computational and latency costs. This has enabled the successful deployment of AIF in the Taobao display advertising system.

</details>


### [588] [Environment-Aware Transfer Reinforcement Learning for Sustainable Beam Selection](https://arxiv.org/abs/2511.11647)
*Dariush Salami,Ramin Hashemi,Parham Kazemi,Mikko A. Uusitalo*

Main category: cs.LG

TL;DR: 提出一种基于点云和迁移学习的强化学习方法，用于5G及以后网络中的波束选择，显著减少训练时间和能耗。


<details>
  <summary>Details</summary>
Motivation: 传统基于强化学习的波束选择在不同环境中需要大量训练资源和时间，难以扩展且能效低。

Method: 将环境建模为点云（包含gNodeB和散射体），通过Chamfer距离识别相似环境，并利用迁移学习复用预训练模型。

Result: 实现16倍训练时间与计算开销降低，保持高性能的同时大幅减少能耗和碳排放。

Conclusion: 该方法支持绿色AI在无线系统中的应用，提升边缘部署效率，推动可持续、可扩展的智能通信系统发展。

Abstract: This paper presents a novel and sustainable approach for improving beam selection in 5G and beyond networks using transfer learning and Reinforcement Learning (RL). Traditional RL-based beam selection models require extensive training time and computational resources, particularly when deployed in diverse environments with varying propagation characteristics posing a major challenge for scalability and energy efficiency. To address this, we propose modeling the environment as a point cloud, where each point represents the locations of gNodeBs (gNBs) and surrounding scatterers. By computing the Chamfer distance between point clouds, structurally similar environments can be efficiently identified, enabling the reuse of pre-trained models through transfer learning. This methodology leads to a 16x reduction in training time and computational overhead, directly contributing to energy efficiency. By minimizing the need for retraining in each new deployment, our approach significantly lowers power consumption and supports the development of green and sustainable Artificial Intelligence (AI) in wireless systems. Furthermore, it accelerates time-to-deployment, reduces carbon emissions associated with training, and enhances the viability of deploying AI-driven communication systems at the edge. Simulation results confirm that our approach maintains high performance while drastically cutting energy costs, demonstrating the potential of transfer learning to enable scalable, adaptive, and environmentally conscious RL-based beam selection strategies in dynamic and diverse propagation environments.

</details>


### [589] [Lightweight Time Series Data Valuation on Time Series Foundation Models via In-Context Finetuning](https://arxiv.org/abs/2511.11648)
*Shunyu Wu,Tianyue Li,Yixuan Leng,Jingyi Suo,Jian Lou,Dan Li,See-Kiong Ng*

Main category: cs.LG

TL;DR: 提出了一种轻量级时间序列数据估值方法LTSV，通过上下文微调在时间序列基础模型上实现高效且准确的数据价值评估。


<details>
  <summary>Details</summary>
Motivation: 传统数据估值方法在处理大规模时间序列基础模型时计算瓶颈严重，且难以保持时间依赖性，因此需要一种高效、可扩展并能保留时间结构的方法。

Method: 基于上下文微调近似影响函数的理论，LTSV通过测量上下文损失变化来估计样本贡献，并引入时间块聚合技术，在重叠时间窗口上整合每块的影响分数以捕捉时间依赖性。

Result: 在多个时间序列数据集和模型上的实验表明，LTSV在保持较低计算开销的同时， consistently 提供可靠且强大的估值性能。

Conclusion: 上下文微调为时间序列基础模型中的数据归因与模型泛化之间提供了实用而有效的桥梁，LTSV是一种高效、鲁棒且可迁移的时间序列数据估值方法。

Abstract: Time series foundation models (TSFMs) have demonstrated increasing capabilities due to their extensive pretraining on large volumes of diverse time series data. Consequently, the quality of time series data is crucial to TSFM performance, rendering an accurate and efficient data valuation of time series for TSFMs indispensable. However, traditional data valuation methods, such as influence functions, face severe computational bottlenecks due to their poor scalability with growing TSFM model sizes and often fail to preserve temporal dependencies. In this paper, we propose LTSV, a Lightweight Time Series Valuation on TSFMS via in-context finetuning. Grounded in the theoretical evidence that in-context finetuning approximates the influence function, LTSV estimates a sample's contribution by measuring the change in context loss after in-context finetuning, leveraging the strong generalization capabilities of TSFMs to produce robust and transferable data valuations. To capture temporal dependencies, we introduce temporal block aggregation, which integrates per-block influence scores across overlapping time windows. Experiments across multiple time series datasets and models demonstrate that LTSV consistently provides reliable and strong valuation performance, while maintaining manageable computational requirements. Our results suggest that in-context finetuning on time series foundation models provides a practical and effective bridge between data attribution and model generalization in time series learning.

</details>


### [590] [Enhanced Water Leak Detection with Convolutional Neural Networks and One-Class Support Vector Machine](https://arxiv.org/abs/2511.11650)
*Daniele Ugo Leonzio,Paolo Bestagini,Marco Marcon,Stefano Tubaro*

Main category: cs.LG

TL;DR: 提出一种基于压力数据和网络拓扑的全数据驱动方法，利用特征提取器和单类SVM检测水管漏损，在模拟数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 供水管网中的漏水问题导致大量水资源浪费，亟需高效可靠的漏损检测与定位系统。

Method: 基于水压测量数据和管网拓扑结构，使用特征提取器结合仅在无漏损数据上训练的单类支持向量机（SVM）进行异常检测。

Result: 在Modena供水管网的模拟数据集上验证了该方法的有效性，检测性能优于近期其他方法。

Conclusion: 所提数据驱动方法能有效识别供水管网中的漏损，具有良好的应用前景。

Abstract: Water is a critical resource that must be managed efficiently. However, a substantial amount of water is lost each year due to leaks in Water Distribution Networks (WDNs). This underscores the need for reliable and effective leak detection and localization systems. In recent years, various solutions have been proposed, with data-driven approaches gaining increasing attention due to their superior performance. In this paper, we propose a new method for leak detection. The method is based on water pressure measurements acquired at a series of nodes of a WDN. Our technique is a fully data-driven solution that makes only use of the knowledge of the WDN topology, and a series of pressure data acquisitions obtained in absence of leaks. The proposed solution is based on an feature extractor and a one-class Support Vector Machines (SVM) trained on no-leak data, so that leaks are detected as anomalies. The results achieved on a simulate dataset using the Modena WDN demonstrate that the proposed solution outperforms recent methods for leak detection.

</details>


### [591] [Incomplete Depression Feature Selection with Missing EEG Channels](https://arxiv.org/abs/2511.11651)
*Zhijian Gong,Wenjia Dong,Xueyuan Xu,Fulin Wei,Chunyu Liu,Li Zhuo*

Main category: cs.LG

TL;DR: 提出一种新的特征选择方法IDFS-MEC，用于处理不完整EEG通道下的抑郁症分析，通过引入缺失通道指示信息和自适应通道加权学习，结合全局冗余最小化，提升抑郁检测的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: EEG数据常含有冗余、无关和噪声信息，且实际采集中易出现电极脱落导致的数据丢失和强噪声干扰，影响抑郁症检测性能。

Method: 提出IDFS-MEC方法，将缺失通道指示信息与自适应通道加权学习融入正交回归，减轻不完整通道对模型构建的影响，并通过全局冗余最小化学习降低所选特征子集间的冗余性。

Result: 在MODMA和PRED-d003数据集上的实验表明，IDFS-MEC在3、64和128通道设置下均优于10种主流特征选择方法，所选特征子集具有更优的分类性能。

Conclusion: IDFS-MEC能有效应对EEG数据缺失和特征冗余问题，显著提升抑郁症识别的鲁棒性与准确性，适用于不同通道数的实际应用场景。

Abstract: As a critical mental health disorder, depression has severe effects on both human physical and mental well-being. Recent developments in EEG-based depression analysis have shown promise in improving depression detection accuracies. However, EEG features often contain redundant, irrelevant, and noisy information. Additionally, real-world EEG data acquisition frequently faces challenges, such as data loss from electrode detachment and heavy noise interference. To tackle the challenges, we propose a novel feature selection approach for robust depression analysis, called Incomplete Depression Feature Selection with Missing EEG Channels (IDFS-MEC). IDFS-MEC integrates missing-channel indicator information and adaptive channel weighting learning into orthogonal regression to lessen the effects of incomplete channels on model construction, and then utilizes global redundancy minimization learning to reduce redundant information among selected feature subsets. Extensive experiments conducted on MODMA and PRED-d003 datasets reveal that the EEG feature subsets chosen by IDFS-MEC have superior performance than 10 popular feature selection methods among 3-, 64-, and 128-channel settings.

</details>


### [592] [How many stations are sufficient? Exploring the effect of urban weather station density reduction on imputation accuracy of air temperature and humidity](https://arxiv.org/abs/2511.11652)
*Marvin Plein,Carsten F. Dormann,Andreas Christen*

Main category: cs.LG

TL;DR: 提出一种逐步减少气象站数量的方法，在保持较高预测精度的同时显著降低城市气象站网络的维护成本。


<details>
  <summary>Details</summary>
Motivation: 城市气象站网络维护成本高且耗时，需要优化站点布局以提高资源利用效率。

Method: 在德国弗赖堡实施分步站点移除方法，评估不同密度子网对气温和湿度模式的重建能力。

Result: 将站点从42个减少到4个后，气温RMSE仅从0.69K增至0.83K，湿度RMSE从3.8%增至4.4%，精度仍优于现有数值模型。

Conclusion: 合理精简气象站网络可在几乎不损失预测性能的前提下大幅节约人力与资金投入。

Abstract: Urban weather station networks (WSNs) are widely used to monitor urban weather and climate patterns and aid urban planning. However, maintaining WSNs is expensive and labor-intensive. Here, we present a step-wise station removal procedure to thin an existing WSN in Freiburg, Germany, and analyze the ability of WSN subsets to reproduce air temperature and humidity patterns of the entire original WSN for a year following a simulated reduction of WSN density. We found that substantial reductions in station numbers after one year of full deployment are possible while retaining high predictive accuracy. A reduction from 42 to 4 stations, for instance, increased mean prediction RMSEs from 0.69 K to 0.83 K for air temperature and from 3.8% to 4.4% for relative humidity, corresponding to RMSE increases of only 20% and 16%, respectively. Predictive accuracy is worse for remote stations in forests than for stations in built-up or open settings, but consistently better than a state-of-the-art numerical urban land-surface model (Surface Urban Energy and Water Balance Scheme). Stations located at the edges between built-up and rural areas are most valuable when reconstructing city-wide climate characteristics. Our study demonstrates the potential of thinning WSNs to maximize the efficient allocation of financial and personnel-related resources in urban climate research.

</details>


### [593] [On the Probabilistic Learnability of Compact Neural Network Preimage Bounds](https://arxiv.org/abs/2511.11656)
*Luca Marzari,Manuele Bicego,Ferdinando Cicalese,Alessandro Farinelli*

Main category: cs.LG

TL;DR: 本文提出了一种基于随机森林的高效方法RF-ProVe，用于神经网络输入区域的验证，具有可证明的统计保证和良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 由于计算神经网络原像边界的问题本质上是#P难的，现有可证明方法在可扩展性上存在根本限制，因此需要一种新的概率性方法来提供高置信度且有误差界保证的解决方案。

Method: 提出RF-ProVe方法，利用随机决策树集成生成满足特定输出属性的候选输入区域，并通过主动重采样进行优化；采用bootstrap和随机化策略捕捉高维空间中的复杂模式。

Result: 理论分析提供了关于区域纯度和全局覆盖率的形式化统计保证，实验表明该方法能有效生成紧凑的原像近似，在可扩展性上优于精确求解器。

Conclusion: RF-ProVe为神经网络的前像计算提供了一种实用、可扩展的概率性验证框架，适用于传统方法无法处理的大规模问题。

Abstract: Although recent provable methods have been developed to compute preimage bounds for neural networks, their scalability is fundamentally limited by the #P-hardness of the problem. In this work, we adopt a novel probabilistic perspective, aiming to deliver solutions with high-confidence guarantees and bounded error. To this end, we investigate the potential of bootstrap-based and randomized approaches that are capable of capturing complex patterns in high-dimensional spaces, including input regions where a given output property holds. In detail, we introduce $\textbf{R}$andom $\textbf{F}$orest $\textbf{Pro}$perty $\textbf{Ve}$rifier ($\texttt{RF-ProVe}$), a method that exploits an ensemble of randomized decision trees to generate candidate input regions satisfying a desired output property and refines them through active resampling. Our theoretical derivations offer formal statistical guarantees on region purity and global coverage, providing a practical, scalable solution for computing compact preimage approximations in cases where exact solvers fail to scale.

</details>


### [594] [SpecQuant: Spectral Decomposition and Adaptive Truncation for Ultra-Low-Bit LLMs Quantization](https://arxiv.org/abs/2511.11663)
*Zhixiong Zhao,Fangxin Liu,Junjie Wang,Chenyang Guan,Zongwu Wang,Li Jiang,Haibing Guan*

Main category: cs.LG

TL;DR: 本文提出了SpecQuant，一种基于傅里叶频域的两阶段极端大语言模型压缩框架，实现了LLaMA-3 8B在4比特权重量化下的高效部署，显著降低精度损失并提升推理速度与内存效率。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型的发展，亟需高效的量化技术以支持终端设备上的部署。现有方法在超低比特量化下面临激活异常值和跨通道方差等问题，导致精度显著下降。因此，需要一种新的压缩方法来解决这些问题。

Method: 提出SpecQuant，包含两个阶段：第一阶段将激活异常值平滑并转移至权重矩阵；第二阶段采用逐通道低频傅里叶截断，抑制高频分量同时保留关键信号能量。引入轻量级截断模块以实现推理时自适应调整截断阈值。

Result: 在LLaMA-3 8B上实现权重和激活均为4比特的量化，零样本准确率差距仅为1.5%，推理速度快2倍，内存使用降低3倍。

Conclusion: SpecQuant通过频域分析有效提升了极端量化下的模型鲁棒性，在保持高精度的同时大幅提高效率，适用于资源受限设备上的大模型部署。

Abstract: The emergence of accurate open large language models (LLMs) has sparked a push for advanced quantization techniques to enable efficient deployment on end-user devices. In this paper, we revisit the challenge of extreme LLM compression -- targeting ultra-low-bit quantization for both activations and weights -- from a Fourier frequency domain perspective. We propose SpecQuant, a two-stage framework that tackles activation outliers and cross-channel variance. In the first stage, activation outliers are smoothed and transferred into the weight matrix to simplify downstream quantization. In the second stage, we apply channel-wise low-frequency Fourier truncation to suppress high-frequency components while preserving essential signal energy, improving quantization robustness. Our method builds on the principle that most of the weight energy is concentrated in low-frequency components, which can be retained with minimal impact on model accuracy. To enable runtime adaptability, we introduce a lightweight truncation module during inference that adjusts truncation thresholds based on channel characteristics. On LLaMA-3 8B, SpecQuant achieves 4-bit quantization for both weights and activations, narrowing the zero-shot accuracy gap to only 1.5% compared to full precision, while delivering 2 times faster inference and 3times lower memory usage.

</details>


### [595] [Clifford Algebraic Rotor Embeddings : Maybe embeddings should start to CARE](https://arxiv.org/abs/2511.11665)
*Sameeksha Sriram,Ayush Paliwal,Alexander S. Ecker,Chase van de Geijn*

Main category: cs.LG

TL;DR: 本文提出了一种基于四元数的旋转位置编码方法QuatRo，并进一步推广到基于几何代数的Clifford旋转嵌入（CARE），实现了任意维度扩展和多级多向量的位置信息编码。


<details>
  <summary>Details</summary>
Motivation: 现有高维旋转位置编码方法（如Spherical RoPE）因使用非交换的欧拉角而导致平移等变性丢失，且旋转顺序选择存在歧义，本文旨在解决这一问题。

Method: 采用四元数表示三维旋转以构建QuatRo，避免非交换性问题；进一步利用几何代数将四元数推广为Clifford旋子，提出CARE框架，实现高维扩展和多级多向量编码。

Result: 理论分析表明Mixed RoPE和Spherical RoPE均为QuatRo的特例；初步实验比较了球面、四元数及Clifford型旋转嵌入的性能。

Conclusion: QuatRo和CARE为旋转位置编码提供了更通用、可扩展且保持良好代数性质的框架，支持任意维度和更丰富的结构化位置表示。

Abstract: Rotary Positional Embeddings (RoPE) have demonstrated exceptional performance as a positional encoding method, consistently outperforming their baselines. While recent work has sought to extend RoPE to higher-dimensional inputs, many such extensions are non-commutative, thereby forfeiting RoPE's shift-equivariance property. Spherical RoPE is one such non-commutative variant, motivated by the idea of rotating embedding vectors on spheres rather than circles. However, spherical rotations are inherently non-commutative, making the choice of rotation sequence ambiguous. In this work, we explore a quaternion-based approach -- Quaternion Rotary Embeddings (QuatRo) -- in place of Euler angles, leveraging quaternions' ability to represent 3D rotations to parameterize the axes of rotation. We show Mixed RoPE and Spherical RoPE to be special cases of QuatRo. Further, we propose a generalization of QuatRo to Clifford Algebraic Rotary Embeddings (CARE) using geometric algebra. Viewing quaternions as the even subalgebra of Cl(3,0,0), we extend the notion of rotary embeddings from quaternions to Clifford rotors acting on multivectors. This formulation enables two key generalizations: (1) extending rotary embeddings to arbitrary dimensions, and (2) encoding positional information in multivectors of multiple grades, not just vectors. We present preliminary experiments comparing spherical, quaternion, and Clifford-based rotary embeddings.

</details>


### [596] [Adaptive Stepsizing for Stochastic Gradient Langevin Dynamics in Bayesian Neural Networks](https://arxiv.org/abs/2511.11666)
*Rajit Rajpal,Benedict Leimkuhler,Yuanhao Jiang*

Main category: cs.LG

TL;DR: 提出了一种自适应的SA-SGLD方法，通过时间重缩放调节步长，提升贝叶斯神经网络中后验采样的准确性与稳定性，且无额外偏差。


<details>
  <summary>Details</summary>
Motivation: 现有SGMCMC方法对步长选择敏感，自适应变体（如pSGLD）在无代价高昂的散度校正项时无法正确采样不变测度。

Method: 基于SamAdams框架，提出SA-SGLD，利用时间重缩放根据局部梯度范数等监控量动态调整步长。

Result: 在高曲率二维玩具模型和使用尖锐先验的图像分类BNN任务中，SA-SGLD比SGLD实现了更准确的后验采样。

Conclusion: SA-SGLD能自动在高曲率区域缩小步长、平坦区域扩大步长，显著提升采样稳定性与混合效率，且不引入偏差。

Abstract: Bayesian neural networks (BNNs) require scalable sampling algorithms to approximate posterior distributions over parameters. Existing stochastic gradient Markov Chain Monte Carlo (SGMCMC) methods are highly sensitive to the choice of stepsize and adaptive variants such as pSGLD typically fail to sample the correct invariant measure without addition of a costly divergence correction term. In this work, we build on the recently proposed `SamAdams' framework for timestep adaptation (Leimkuhler, Lohmann, and Whalley 2025), introducing an adaptive scheme: SA-SGLD, which employs time rescaling to modulate the stepsize according to a monitored quantity (typically the local gradient norm). SA-SGLD can automatically shrink stepsizes in regions of high curvature and expand them in flatter regions, improving both stability and mixing without introducing bias. We show that our method can achieve more accurate posterior sampling than SGLD on high-curvature 2D toy examples and in image classification with BNNs using sharp priors.

</details>


### [597] [Beyond Superficial Forgetting: Thorough Unlearning through Knowledge Density Estimation and Block Re-insertion](https://arxiv.org/abs/2511.11667)
*Feng Guo,Yuntao Wen,Shen Gao,Junshuo Zhang,Shuo Shang*

Main category: cs.LG

TL;DR: 提出了一种基于知识密度引导的块重插入遗忘方法KUnBR，用于有效清除大语言模型中的有害知识，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法难以彻底清除有害知识，残留知识易被恢复，影响隐私、合规与伦理安全。

Method: 通过知识密度估计识别富含有害知识的层，并设计层重插入策略，在保留原始模型结构的同时实现有害知识的彻底消除和梯度的有效传播。

Result: 在多个遗忘和通用能力基准上的实验表明，KUnBR在遗忘性能上达到最先进水平，同时较好保持了模型原有功能。

Conclusion: KUnBR能有效定位并清除大模型中的有害知识，平衡了遗忘效果与模型可用性，具有实际应用潜力。

Abstract: Machine unlearning, which selectively removes harmful knowledge from a pre-trained model without retraining from scratch, is crucial for addressing privacy, regulatory compliance, and ethical concerns in Large Language Models (LLMs). However, existing unlearning methods often struggle to thoroughly remove harmful knowledge, leaving residual harmful knowledge that can be easily recovered. To address these limitations, we propose Knowledge Density-Guided Unlearning via Blocks Reinsertion (KUnBR), a novel approach that first identifies layers with rich harmful knowledge and then thoroughly eliminates the harmful knowledge via re-insertion strategy. Our method introduces knowledge density estimation to quantify and locate layers containing the most harmful knowledge, enabling precise unlearning. Additionally, we design a layer re-insertion strategy that extracts and re-inserts harmful knowledge-rich layers into the original LLM, bypassing gradient obstruction caused by cover layers and ensuring effective gradient propagation during unlearning. Extensive experiments conducted on several unlearning and general capability benchmarks demonstrate that KUnBR achieves state-of-the-art forgetting performance while maintaining model utility.

</details>


### [598] [Do traveling waves make good positional encodings?](https://arxiv.org/abs/2511.11668)
*Chase van de Geijn,Ayush Paliwal,Timo Lüddecke,Alexander S. Ecker*

Main category: cs.LG

TL;DR: 提出了一种基于行波的新型位置编码方法RollPE，通过在自注意力机制中对查询和键张量应用循环滚动操作，实现相对位置编码，性能优于传统绝对位置编码，且与RoPE相当，并揭示了其与RoPE的数学等价性。


<details>
  <summary>Details</summary>
Motivation: Transformer依赖位置编码来克服自注意力机制的排列不变性，传统方法使用绝对位置编码，而较新方法强调相对编码以更好捕捉平移等变性。本文旨在提出一种更有效的位置编码机制。

Method: 提出RollPE，利用循环滚动操作在查询和键张量上引入相位的相对偏移，使注意力计算依赖于位置差异而非绝对索引，并推导其连续形式及与RoPE的数学等价性。

Result: RollPE显著优于传统绝对位置编码，性能与RoPE相当，且能隐式地在查询和键空间中施加拓扑结构。

Conclusion: RollPE是一种简单而有效的位置编码方法，通过行波视角可简化RoPE的理解，并可能与大脑中的信息流动过程建立联系。

Abstract: Transformers rely on positional encoding to compensate for the inherent permutation invariance of self-attention. Traditional approaches use absolute sinusoidal embeddings or learned positional vectors, while more recent methods emphasize relative encodings to better capture translation equivariances. In this work, we propose RollPE, a novel positional encoding mechanism based on traveling waves, implemented by applying a circular roll operation to the query and key tensors in self-attention. This operation induces a relative shift in phase across positions, allowing the model to compute attention as a function of positional differences rather than absolute indices. We show this simple method significantly outperforms traditional absolute positional embeddings and is comparable to RoPE. We derive a continuous case of RollPE which implicitly imposes a topographic structure on the query and key space. We further derive a mathematical equivalence of RollPE to a particular configuration of RoPE. Viewing RollPE through the lens of traveling waves may allow us to simplify RoPE and relate it to processes of information flow in the brain.

</details>


### [599] [H-Model: Dynamic Neural Architectures for Adaptive Processing](https://arxiv.org/abs/2511.11669)
*Dmytro Hospodarchuk*

Main category: cs.LG

TL;DR: 本文提出了一种可动态调整内部结构的神经网络架构，通过路由机制实现自适应计算，旨在探索更具可解释性的模型设计，而非提升现有基准性能。


<details>
  <summary>Details</summary>
Motivation: 希望设计一种能够根据输入数据和内部状态动态调整信息流动路径的神经网络，以模拟类似思维的动态推理过程，并提高模型的可解释性。

Method: 引入一种路由机制，使每一层可以影响其输出在网络中的传播方式，从而实现迭代和自适应的计算过程。

Result: 初步实验表明该架构具有潜力，但由于计算资源和数据限制，研究仍处于初步阶段，尚未在大规模条件下验证其完整能力。

Conclusion: 该工作提出了一种新的神经网络架构范式，强调学习计算结构本身，为未来可适应、可解释的模型发展提供了新方向。

Abstract: This article explores the design and experimentation of a neural network architecture capable of dynamically adjusting its internal structure based on the input data. The proposed model introduces a routing mechanism that allows each layer to influence how its outputs are propagated through the network, enabling iterative and adaptive computation. This concept is loosely inspired by the idea of thought processes and dynamic reasoning, where information flow is conditioned not only on the data itself, but also on the internal state of the system.
  It is important to note that this work does not aim to compete with state-of-the-art language models in terms of performance. Instead, it presents a conceptual prototype-an architectural framework that opens up a new direction for exploring adaptable and potentially more interpretable networks. The goal is not optimization of existing benchmarks but rather the proposal of a system that can learn not only representations, but also the structure of computation itself.
  Due to practical constraints in computing resources and data, this study remains a preliminary investigation. Nevertheless, initial observations show promise, and the architecture's full potential can only be evaluated in future experiments under more favorable computational conditions.

</details>


### [600] [Evaluation of LLM-based Explanations for a Learning Analytics Dashboard](https://arxiv.org/abs/2511.11671)
*Alina Deriyeva,Benjamin Paassen*

Main category: cs.LG

TL;DR: 本研究探讨了利用大语言模型（LLM）为学习分析仪表盘生成数据解释文本，以提升其可解释性和学习支持效果。


<details>
  <summary>Details</summary>
Motivation: 学习分析仪表盘虽有助于促进自主学习和元认知技能发展，但其有效性受数据可解释性影响。如何提升用户对仪表盘数据的理解是关键问题。

Method: 研究采用大语言模型生成仪表盘数据的文本解释，并在一项针对12名高校教育者的专家研究中，将其与独立仪表盘和教师提供的解释进行对比评估。

Result: 结果显示，LLM生成的关于学习者技能状态的解释及后续学习建议，显著优于其他两种条件，更受专家青睐。

Conclusion: 使用大语言模型辅助解释学习分析数据可有效提升学习体验，在保持教师认可的教学标准的同时增强仪表盘的实用性。

Abstract: Learning Analytics Dashboards can be a powerful tool to support self-regulated learning in Digital Learning Environments and promote development of meta-cognitive skills, such as reflection. However, their effectiveness can be affected by the interpretability of the data they provide. To assist in the interpretation, we employ a large language model to generate verbal explanations of the data in the dashboard and evaluate it against a standalone dashboard and explanations provided by human teachers in an expert study with university level educators (N=12). We find that the LLM-based explanations of the skill state presented in the dashboard, as well as general recommendations on how to proceed with learning within the course are significantly more favored compared to the other conditions. This indicates that using LLMs for interpretation purposes can enhance the learning experience for learners while maintaining the pedagogical standards approved by teachers.

</details>


### [601] [Synergistic Feature Fusion for Latent Lyrical Classification: A Gated Deep Learning Architecture](https://arxiv.org/abs/2511.11673)
*M. A. Gameiro*

Main category: cs.LG

TL;DR: 提出了一种基于门控机制的协同融合层（SFL）模型，用于融合深度语义特征与结构化线索进行歌词内容分类，显著优于传统特征拼接方法。


<details>
  <summary>Details</summary>
Motivation: 解决高维深度语义特征与低维可解释结构线索在歌词分类中有效融合的挑战，提升模型性能与可靠性。

Method: 设计了一种新的协同融合层（SFL），通过门控机制调节Sentence-BERT嵌入（Fdeep）并融入低维辅助特征（Fstruct），将UMAP降维聚类任务重构为二分类问题。

Result: SFL模型准确率达0.9894，Macro F1为0.9894，优于随机森林基线；预期校准误差降低93%（ECE=0.0035），对数损失降低2.5倍（0.0304）。

Conclusion: 非线性门控融合优于简单特征拼接，SFL模型在多模态歌词分析中具有更强的鲁棒性和可信度。

Abstract: This study addresses the challenge of integrating complex, high-dimensional deep semantic features with simple, interpretable structural cues for lyrical content classification. We introduce a novel Synergistic Fusion Layer (SFL) architecture, a deep learning model utilizing a gated mechanism to modulate Sentence-BERT embeddings (Fdeep) using low-dimensional auxiliary features (Fstruct). The task, derived from clustering UMAP-reduced lyrical embeddings, is reframed as binary classification, distinguishing a dominant, homogeneous cluster (Class 0) from all other content (Class 1). The SFL model achieved an accuracy of 0.9894 and a Macro F1 score of 0.9894, outperforming a comprehensive Random Forest (RF) baseline that used feature concatenation (Accuracy = 0.9868). Crucially, the SFL model demonstrated vastly superior reliability and calibration, exhibiting a 93% reduction in Expected Calibration Error (ECE = 0.0035) and a 2.5x lower Log Loss (0.0304) compared to the RF baseline (ECE = 0.0500; Log Loss = 0.0772). This performance validates the architectural hypothesis that non-linear gating is superior to simple feature concatenation, establishing the SFL model as a robust and trustworthy system for complex multimodal lyrical analysis.

</details>


### [602] [Beyond One-Way Pruning: Bidirectional Pruning-Regrowth for Extreme Accuracy-Sparsity Tradeoff](https://arxiv.org/abs/2511.11675)
*Junchen Liu,Yi Sheng*

Main category: cs.LG

TL;DR: 提出了一种双向剪枝-再生策略，通过从极度压缩的网络开始并选择性地恢复关键连接，以缓解高稀疏度下的精度急剧下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法在稀疏度过高时性能急剧下降，限制了模型的压缩比和在严格硬件约束下的可用性。

Method: 采用双向剪枝-再生策略，先进行极端压缩以满足硬件限制，再选择性地重生重要连接以恢复性能。

Result: 该方法有效缓解了高稀疏度下模型性能的急剧下降，提升了压缩比并满足硬件部署需求。

Conclusion: 所提方法能够在满足硬件尺寸限制的同时显著恢复模型性能，为高稀疏模型的实用化提供了可行路径。

Abstract: As a widely adopted model compression technique, model pruning has demonstrated strong effectiveness across various architectures. However, we observe that when sparsity exceeds a certain threshold, both iterative and one-shot pruning methods lead to a steep decline in model performance. This rapid degradation limits the achievable compression ratio and prevents models from meeting the stringent size constraints required by certain hardware platforms, rendering them inoperable. To overcome this limitation, we propose a bidirectional pruning-regrowth strategy. Starting from an extremely compressed network that satisfies hardware constraints, the method selectively regenerates critical connections to recover lost performance, effectively mitigating the sharp accuracy drop commonly observed under high sparsity conditions.

</details>


### [603] [Learning with Preserving for Continual Multitask Learning](https://arxiv.org/abs/2511.11676)
*Hanchen David Wang,Siwoo Bae,Zirong Chen,Meiyi Ma*

Main category: cs.LG

TL;DR: 本文提出了Continual Multitask Learning (CMTL)场景下的新方法Learning with Preserving (LwP)，通过保持共享表示空间的几何结构来缓解灾难性遗忘，无需回放缓冲区，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和医疗影像等关键领域，模型需持续学习新任务而不忘旧知识，但现有方法因学习碎片化的任务特定特征而导致相互干扰，难以应对CMTL场景。

Method: 提出LwP框架，核心是动态加权距离保持（DWDP）损失，通过正则化潜在表示间的成对距离，维持共享表示空间的几何结构，避免表征漂移。

Result: 在时序和图像基准上的实验表明，LwP有效缓解灾难性遗忘，在CMTL任务中 consistently 超越最先进方法，且对分布偏移更具鲁棒性，唯一超越单任务学习基线的方法。

Conclusion: LwP通过保护共享表示的几何结构实现持续多任务学习，无需回放缓冲区，适用于隐私敏感场景，在真实动态环境中表现出优越性能。

Abstract: Artificial intelligence systems in critical fields like autonomous driving and medical imaging analysis often continually learn new tasks using a shared stream of input data. For instance, after learning to detect traffic signs, a model may later need to learn to classify traffic lights or different types of vehicles using the same camera feed. This scenario introduces a challenging setting we term Continual Multitask Learning (CMTL), where a model sequentially learns new tasks on an underlying data distribution without forgetting previously learned abilities. Existing continual learning methods often fail in this setting because they learn fragmented, task-specific features that interfere with one another. To address this, we introduce Learning with Preserving (LwP), a novel framework that shifts the focus from preserving task outputs to maintaining the geometric structure of the shared representation space. The core of LwP is a Dynamically Weighted Distance Preservation (DWDP) loss that prevents representation drift by regularizing the pairwise distances between latent data representations. This mechanism of preserving the underlying geometric structure allows the model to retain implicit knowledge and support diverse tasks without requiring a replay buffer, making it suitable for privacy-conscious applications. Extensive evaluations on time-series and image benchmarks show that LwP not only mitigates catastrophic forgetting but also consistently outperforms state-of-the-art baselines in CMTL tasks. Notably, our method shows superior robustness to distribution shifts and is the only approach to surpass the strong single-task learning baseline, underscoring its effectiveness for real-world dynamic environments.

</details>


### [604] [Homotopy-Guided Self-Supervised Learning of Parametric Solutions for AC Optimal Power Flow](https://arxiv.org/abs/2511.11677)
*Shimiao Li,Aaron Tuor,Draguna Vrabie,Larry Pileggi,Jan Drgona*

Main category: cs.LG

TL;DR: 提出了一种基于同伦引导的自监督学习优化方法（L2O），用于解决参数化交流最优潮流（AC-OPF）问题，通过在训练中连续变形目标和约束，提升收敛性和可行性。


<details>
  <summary>Details</summary>
Motivation: AC-OPF问题的非凸性导致优化困难，标准学习方法难以收敛到可行且高质量的解，因此需要更稳定的L2O训练方法。

Method: 引入同伦引导的自监督L2O方法，在训练过程中从松弛问题开始，逐步向原始问题过渡，构造目标和约束的连续变形，无需标签或外部求解器。

Result: 在IEEE标准测试系统上验证，相比无同伦方法显著提高了可行性比率，同时目标值接近完整OPF求解器的结果。

Conclusion: 同伦引导的L2O方法在保持高效求解的同时提升了可行性，展示了其在电力系统优化中实现可扩展、约束感知的L2O的潜力。

Abstract: Learning to optimize (L2O) parametric approximations of AC optimal power flow (AC-OPF) solutions offers the potential for fast, reusable decision-making in real-time power system operations. However, the inherent nonconvexity of AC-OPF results in challenging optimization landscapes, and standard learning approaches often fail to converge to feasible, high-quality solutions. This work introduces a \textit{homotopy-guided self-supervised L2O method} for parametric AC-OPF problems. The key idea is to construct a continuous deformation of the objective and constraints during training, beginning from a relaxed problem with a broad basin of attraction and gradually transforming it toward the original problem. The resulting learning process improves convergence stability and promotes feasibility without requiring labeled optimal solutions or external solvers. We evaluate the proposed method on standard IEEE AC-OPF benchmarks and show that homotopy-guided L2O significantly increases feasibility rates compared to non-homotopy baselines, while achieving objective values comparable to full OPF solvers. These findings demonstrate the promise of homotopy-based heuristics for scalable, constraint-aware L2O in power system optimization.

</details>


### [605] [Probabilistic Wildfire Susceptibility from Remote Sensing Using Random Forests and SHAP](https://arxiv.org/abs/2511.11680)
*Udaya Bhasker Cheerala,Varun Teja Chirukuri,Venkata Akhil Kumar Gummadi,Jintu Moni Bhuyan,Praveen Damacharla*

Main category: cs.LG

TL;DR: 本研究利用随机森林（RF）算法结合SHAP可解释人工智能方法，构建了加州野火风险图，识别出不同生态系统中的关键风险驱动因素，并验证了模型在时空上的预测性能。


<details>
  <summary>Details</summary>
Motivation: 加州频繁发生的野火对生态系统构成严重威胁，需建立可解释的高精度风险评估模型以支持决策。

Method: 采用随机森林算法结合SHAP进行特征重要性解释，通过空间和时间交叉验证评估模型性能。

Result: RF模型在草地和森林中均表现出高预测能力（AUC > 0.99），时间验证显示良好泛化性；SHAP分析揭示土壤有机碳、树冠覆盖和NDVI是森林主要驱动因素，地表温度、海拔和植被健康指数主导草地风险；中央谷地和北部巴特区为高风险区域。

Conclusion: RF-SHAP框架能有效生成可解释的野火风险地图，支持针对性的火灾防控策略制定。

Abstract: Wildfires pose a significant global threat to ecosystems worldwide, with California experiencing recurring fires due to various factors, including climate, topographical features, vegetation patterns, and human activities. This study aims to develop a comprehensive wildfire risk map for California by applying the random forest (RF) algorithm, augmented with Explainable Artificial Intelligence (XAI) through Shapley Additive exPlanations (SHAP), to interpret model predictions. Model performance was assessed using both spatial and temporal validation strategies. The RF model demonstrated strong predictive performance, achieving near-perfect discrimination for grasslands (AUC = 0.996) and forests (AUC = 0.997). Spatial cross-validation revealed moderate transferability, yielding ROC-AUC values of 0.6155 for forests and 0.5416 for grasslands. In contrast, temporal split validation showed enhanced generalization, especially for forests (ROC-AUC = 0.6615, PR-AUC = 0.8423). SHAP-based XAI analysis identified key ecosystem-specific drivers: soil organic carbon, tree cover, and Normalized Difference Vegetation Index (NDVI) emerged as the most influential in forests, whereas Land Surface Temperature (LST), elevation, and vegetation health indices were dominant in grasslands. District-level classification revealed that Central Valley and Northern Buttes districts had the highest concentration of high-risk grasslands, while Northern Buttes and North Coast Redwoods dominated forested high-risk areas. This RF-SHAP framework offers a robust, comprehensible, and adaptable method for assessing wildfire risks, enabling informed decisions and creating targeted strategies to mitigate dangers.

</details>


### [606] [MPCM-Net: Multi-scale network integrates partial attention convolution with Mamba for ground-based cloud image segmentation](https://arxiv.org/abs/2511.11681)
*Penghui Niu,Jiashuai She,Taotao Cai,Yajuan Zhang,Ping Zhang,Junhua Gu,Jianxin Li*

Main category: cs.LG

TL;DR: 提出MPCM-Net，一种结合部分注意力卷积与Mamba架构的多尺度网络，用于提升地面云图分割的精度与效率，并发布新的细粒度标注数据集CSRC。


<details>
  <summary>Details</summary>
Motivation: 现有云图分割方法在多尺度特征提取、注意力机制的效率平衡及解码器对全局依赖建模方面存在不足，影响了分割精度与推理效率。

Method: 设计MPCM-Net：编码器采用MPAC模块（含MPC和MPA块），结合ParCM、ParSM、ParAM实现多尺度空间交互与低复杂度判别特征提取；解码器使用M2B结构与SSHD机制进行线性复杂度下的深层特征聚合。同时构建并公开CSRC数据集。

Result: 在自建CSRC数据集上实验表明，MPCM-Net在分割精度和推理速度之间取得最优平衡，显著优于现有SOTA方法。

Conclusion: MPCM-Net有效解决了云图分割中多尺度建模、计算效率与上下文保持之间的矛盾，所提出的模块和数据集为后续研究提供了重要基础。

Abstract: Ground-based cloud image segmentation is a critical research domain for photovoltaic power forecasting. Current deep learning approaches primarily focus on encoder-decoder architectural refinements. However, existing methodologies exhibit several limitations:(1)they rely on dilated convolutions for multi-scale context extraction, lacking the partial feature effectiveness and interoperability of inter-channel;(2)attention-based feature enhancement implementations neglect accuracy-throughput balance; and (3)the decoder modifications fail to establish global interdependencies among hierarchical local features, limiting inference efficiency. To address these challenges, we propose MPCM-Net, a Multi-scale network that integrates Partial attention Convolutions with Mamba architectures to enhance segmentation accuracy and computational efficiency. Specifically, the encoder incorporates MPAC, which comprises:(1)a MPC block with ParCM and ParSM that enables global spatial interaction across multi-scale cloud formations, and (2)a MPA block combining ParAM and ParSM to extract discriminative features with reduced computational complexity. On the decoder side, a M2B is employed to mitigate contextual loss through a SSHD that maintains linear complexity while enabling deep feature aggregation across spatial and scale dimensions. As a key contribution to the community, we also introduce and release a dataset CSRC, which is a clear-label, fine-grained segmentation benchmark designed to overcome the critical limitations of existing public datasets. Extensive experiments on CSRC demonstrate the superior performance of MPCM-Net over state-of-the-art methods, achieving an optimal balance between segmentation accuracy and inference speed. The dataset and source code will be available at https://github.com/she1110/CSRC.

</details>


### [607] [Stratified Knowledge-Density Super-Network for Scalable Vision Transformers](https://arxiv.org/abs/2511.11683)
*Longhua Li,Lei Qi,Xin Geng*

Main category: cs.LG

TL;DR: 提出一种将预训练ViT转化为分层知识密度超网络的方法，通过WPAC和PIAD实现知识浓缩与分层组织，支持高效子网络提取。


<details>
  <summary>Details</summary>
Motivation: 训练和部署多个ViT模型以适应不同资源限制成本高且效率低，需更高效的模型压缩与扩展方案。

Method: 提出WPAC（注意力收缩的加权PCA）和PIAD（渐进重要性感知Dropout）：WPAC通过token级加权PCA将知识集中到关键权重；PIAD动态评估权重重要性并调整dropout策略以促进知识分层。

Result: WPAC在知识浓缩上优于现有剪枝方法，结合PIAD后性能可媲美最先进的模型压缩与扩展方法。

Conclusion: 该方法能有效构建具有分层知识结构的超网络，支持灵活、高效的子网络提取，适用于多资源约束场景。

Abstract: Training and deploying multiple vision transformer (ViT) models for different resource constraints is costly and inefficient. To address this, we propose transforming a pre-trained ViT into a stratified knowledge-density super-network, where knowledge is hierarchically organized across weights. This enables flexible extraction of sub-networks that retain maximal knowledge for varying model sizes. We introduce \textbf{W}eighted \textbf{P}CA for \textbf{A}ttention \textbf{C}ontraction (WPAC), which concentrates knowledge into a compact set of critical weights. WPAC applies token-wise weighted principal component analysis to intermediate features and injects the resulting transformation and inverse matrices into adjacent layers, preserving the original network function while enhancing knowledge compactness. To further promote stratified knowledge organization, we propose \textbf{P}rogressive \textbf{I}mportance-\textbf{A}ware \textbf{D}ropout (PIAD). PIAD progressively evaluates the importance of weight groups, updates an importance-aware dropout list, and trains the super-network under this dropout regime to promote knowledge stratification. Experiments demonstrate that WPAC outperforms existing pruning criteria in knowledge concentration, and the combination with PIAD offers a strong alternative to state-of-the-art model compression and model expansion methods.

</details>


### [608] [A Bayesian Model for Multi-stage Censoring](https://arxiv.org/abs/2511.11684)
*Shuvom Sadhuka,Sophia Lin,Emma Pierson,Bonnie Berger*

Main category: cs.LG

TL;DR: 提出了一种用于医疗决策漏斗结构的贝叶斯模型，以应对选择性标签和审查带来的偏差，尤其在性别差异分析中显示出不同风险阈值。


<details>
  <summary>Details</summary>
Motivation: 由于医疗决策过程中存在漏斗式结构，导致真实结果（如活检）仅在最后阶段可见，且数据存在选择性审查，特别是在服务不足人群中引入了风险估计偏差。

Method: 开发了一个基于贝叶斯框架的模型，借鉴选择性标签和审查建模的相关研究，在合成数据和真实急诊数据上进行验证。

Result: 在合成数据中，模型能更准确地恢复真实参数并预测被审查患者的结局；在急诊数据中发现，女性进入ICU的死亡风险阈值（5.1%）高于男性（4.5%）。

Conclusion: 该模型有效缓解了漏斗结构中的选择性审查偏倚，揭示了临床决策中存在的潜在性别差异，有助于改进公平性和风险评估准确性。

Abstract: Many sequential decision settings in healthcare feature funnel structures characterized by a series of stages, such as screenings or evaluations, where the number of patients who advance to each stage progressively decreases and decisions become increasingly costly. For example, an oncologist may first conduct a breast exam, followed by a mammogram for patients with concerning exams, followed by a biopsy for patients with concerning mammograms. A key challenge is that the ground truth outcome, such as the biopsy result, is only revealed at the end of this funnel. The selective censoring of the ground truth can introduce statistical biases in risk estimation, especially in underserved patient groups, whose outcomes are more frequently censored. We develop a Bayesian model for funnel decision structures, drawing from prior work on selective labels and censoring. We first show in synthetic settings that our model is able to recover the true parameters and predict outcomes for censored patients more accurately than baselines. We then apply our model to a dataset of emergency department visits, where in-hospital mortality is observed only for those who are admitted to either the hospital or ICU. We find that there are gender-based differences in hospital and ICU admissions. In particular, our model estimates that the mortality risk threshold to admit women to the ICU is higher for women (5.1%) than for men (4.5%).

</details>


### [609] [R-Tuning: Wavelet-Decomposed Replay and Semantic Alignment for Continual Adaptation of Pretrained Time-Series Models](https://arxiv.org/abs/2511.11685)
*Tianyi Yin,Jingwei Wang,Chenze Wang,Han Wang,Jiexuan Cai,Min Liu,Yunlong Ma,Kun Gao,Yuting Song,Weiming Shen*

Main category: cs.LG

TL;DR: 提出了一种名为Replay Tuning（R-Tuning）的新框架，用于持续适应预训练时间序列模型，通过频域感知的回放策略和潜在一致性约束，在新旧任务上均表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在时间序列预测中表现良好，但在数据分布变化时难以适应，且缺乏原始训练数据导致微调易发生灾难性遗忘。

Method: 构建统一的潜在空间，采用基于小波分解的多频带回放策略生成趋势保持和融合增强的合成样本，并引入潜在一致性约束以对齐新旧任务表示。

Result: 实验显示R-Tuning在新任务上MAE和MSE最多降低46.9%和46.8%，在旧任务上性能提升达5.7%和6.0%，在少样本场景下仅用5%合成数据即优于现有方法。

Conclusion: R-Tuning有效实现了预训练时间序列模型的持续适应，在知识保留与新任务学习之间取得了良好平衡，尤其适用于数据受限场景。

Abstract: Pre-trained models have demonstrated exceptional generalization capabilities in time-series forecasting; however, adapting them to evolving data distributions remains a significant challenge. A key hurdle lies in accessing the original training data, as fine-tuning solely on new data often leads to catastrophic forgetting. To address this issue, we propose Replay Tuning (R-Tuning), a novel framework designed for the continual adaptation of pre-trained time-series models. R-Tuning constructs a unified latent space that captures both prior and current task knowledge through a frequency-aware replay strategy. Specifically, it augments model-generated samples via wavelet-based decomposition across multiple frequency bands, generating trend-preserving and fusion-enhanced variants to improve representation diversity and replay efficiency. To further reduce reliance on synthetic samples, R-Tuning introduces a latent consistency constraint that aligns new representations with the prior task space. This constraint guides joint optimization within a compact and semantically coherent latent space, ensuring robust knowledge retention and adaptation. Extensive experimental results demonstrate the superiority of R-Tuning, which reduces MAE and MSE by up to 46.9% and 46.8%, respectively, on new tasks, while preserving prior knowledge with gains of up to 5.7% and 6.0% on old tasks. Notably, under few-shot settings, R-Tuning outperforms all state-of-the-art baselines even when synthetic proxy samples account for only 5% of the new task dataset.

</details>


### [610] [Regularized Schrödinger: Alleviating Distortion and Exposure Bias in Solving Inverse Problems](https://arxiv.org/abs/2511.11686)
*Qing Yao,Lijian Gao,Qirong Mao,Dong Ming*

Main category: cs.LG

TL;DR: 提出了一种用于解决逆问题的正则化Schrödinger Bridge（RSB）方法，通过正则化训练策略缓解了失真-感知权衡和暴露偏差问题，在语音增强任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在解决逆问题时面临失真-感知权衡和暴露偏差两个关键挑战，影响重建质量和感知效果。

Method: 提出正则化Schrödinger Bridge（RSB），通过扰动输入状态和目标进行正则化训练，并利用后验均值插值来缓解暴露偏差和失真问题。

Result: 在语音增强的两个典型逆问题上实验表明，RSB优于现有最先进方法，显著改善了失真指标并有效减少了暴露偏差。

Conclusion: RSB通过新颖的训练策略有效解决了扩散模型在逆问题中的关键局限，具有良好的应用前景。

Abstract: Diffusion models serve as a powerful generative framework for solving inverse problems. However, they still face two key challenges: 1) the distortion-perception tradeoff, where improving perceptual quality often degrades reconstruction fidelity, and 2) the exposure bias problem, where the training-inference input mismatch leads to prediction error accumulation and reduced reconstruction quality. In this work, we propose the Regularized Schrödinger Bridge (RSB), an adaptation of Schrödinger Bridge tailored for inverse problems that addresses the above limitations. RSB employs a novel regularized training strategy that perturbs both the input states and targets, effectively mitigating exposure bias by exposing the model to simulated prediction errors and also alleviating distortion by well-designed interpolation via the posterior mean. Extensive experiments on two typical inverse problems for speech enhancement demonstrate that RSB outperforms state-of-the-art methods, significantly improving distortion metrics and effectively reducing exposure bias.

</details>


### [611] [Enhancing Reinforcement Learning in 3D Environments through Semantic Segmentation: A Case Study in ViZDoom](https://arxiv.org/abs/2511.11703)
*Hugo Huang*

Main category: cs.LG

TL;DR: 提出两种新的输入表示方法SS-only和RGB+SS，用于在ViZDoom中进行强化学习，显著降低内存消耗并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决高维感官输入下的3D环境中强化学习的两个主要挑战：内存消耗大和部分可观测马尔可夫决策过程的学习复杂性。

Method: 采用语义分割处理RGB图像，提出SS-only和RGB+SS两种输入表示，并在ViZDoom死亡竞赛中实验，使用完美分割结果进行可控评估。

Result: SS-only至少减少66.6%的内存缓冲区消耗，结合游程编码可高达98.6%；RGB+SS通过增加语义信息显著提升代理性能；探索了基于密度的热图可视化代理移动模式。

Conclusion: 所提方法有效降低了内存使用，提升了强化学习代理在3D环境中的表现，并克服了以往在ViZDoom等环境中应用语义分割的常见问题。

Abstract: Reinforcement learning (RL) in 3D environments with high-dimensional sensory input poses two major challenges: (1) the high memory consumption induced by memory buffers required to stabilise learning, and (2) the complexity of learning in partially observable Markov Decision Processes (POMDPs). This project addresses these challenges by proposing two novel input representations: SS-only and RGB+SS, both employing semantic segmentation on RGB colour images. Experiments were conducted in deathmatches of ViZDoom, utilizing perfect segmentation results for controlled evaluation. Our results showed that SS-only was able to reduce the memory consumption of memory buffers by at least 66.6%, and up to 98.6% when a vectorisable lossless compression technique with minimal overhead such as run-length encoding is applied. Meanwhile, RGB+SS significantly enhances RL agents' performance with the additional semantic information provided. Furthermore, we explored density-based heatmapping as a tool to visualise RL agents' movement patterns and evaluate their suitability for data collection. A brief comparison with a previous approach highlights how our method overcame common pitfalls in applying semantic segmentation in 3D environments like ViZDoom.

</details>


### [612] [Hierarchical Schedule Optimization for Fast and Robust Diffusion Model Sampling](https://arxiv.org/abs/2511.11688)
*Aihua Zhu,Rui Su,Qinglin Zhao,Li Feng,Meng Shen,Shibo He*

Main category: cs.LG

TL;DR: 提出了一种名为HSO的分层调度优化器，用于加速扩散模型的采样过程，无需训练且在极低函数评估次数下实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有调度优化方法难以同时满足有效性、适应性、实用鲁棒性和计算效率四个核心原则，需要更先进的解决方案。

Method: 提出HSO框架，采用双层优化结构：上层进行全局搜索以获得最优初始化策略，下层进行局部优化细化调度；引入MEP作为局部优化目标，SPF函数防止时间步过近。

Result: 在NFE仅为5的情况下，HSO在LAION-Aesthetics数据集上使用Stable Diffusion v2.1实现了11.94的FID分数，单次优化耗时不到8秒。

Conclusion: HSO在无需重训练的前提下，实现了训练自由扩散模型采样的新SOTA，兼具高效性与实用性。

Abstract: Diffusion probabilistic models have set a new standard for generative fidelity but are hindered by a slow iterative sampling process. A powerful training-free strategy to accelerate this process is Schedule Optimization, which aims to find an optimal distribution of timesteps for a fixed and small Number of Function Evaluations (NFE) to maximize sample quality. To this end, a successful schedule optimization method must adhere to four core principles: effectiveness, adaptivity, practical robustness, and computational efficiency. However, existing paradigms struggle to satisfy these principles simultaneously, motivating the need for a more advanced solution. To overcome these limitations, we propose the Hierarchical-Schedule-Optimizer (HSO), a novel and efficient bi-level optimization framework. HSO reframes the search for a globally optimal schedule into a more tractable problem by iteratively alternating between two synergistic levels: an upper-level global search for an optimal initialization strategy and a lower-level local optimization for schedule refinement. This process is guided by two key innovations: the Midpoint Error Proxy (MEP), a solver-agnostic and numerically stable objective for effective local optimization, and the Spacing-Penalized Fitness (SPF) function, which ensures practical robustness by penalizing pathologically close timesteps. Extensive experiments show that HSO sets a new state-of-the-art for training-free sampling in the extremely low-NFE regime. For instance, with an NFE of just 5, HSO achieves a remarkable FID of 11.94 on LAION-Aesthetics with Stable Diffusion v2.1. Crucially, this level of performance is attained not through costly retraining, but with a one-time optimization cost of less than 8 seconds, presenting a highly practical and efficient paradigm for diffusion model acceleration.

</details>


### [613] [Doubly Debiased Test-Time Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2511.11690)
*Fei Song,Yi Li,Rui Wang,Jiahuan Zhou,Changwen Zheng,Jiangmeng Li*

Main category: cs.LG

TL;DR: 提出了一种双去偏的测试时提示调优方法，通过动态检索增强和可靠性感知优化模块来缓解视觉-语言模型中的提示优化偏差。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时提示调优方法仅基于无标签测试数据进行优化，容易导致提示优化偏差，影响下游任务性能。本文从模型和数据两个角度分析该偏差的成因，并提出解决方案。

Method: 提出了双去偏测试时提示调优方法：1）设计动态检索增强调制模块，利用测试图像特征查询动态知识库以获取高置信度知识，并用于调整预测；2）设计可靠性感知提示优化模块，结合置信度加权集成和跨模态一致性蒸馏，在提示调优过程中施加正则化约束。

Result: 在15个基准数据集上进行了广泛实验，涵盖自然分布偏移和跨数据集泛化场景，结果表明所提方法优于基线模型。

Conclusion: 所提出的双去偏方法能有效缓解提示优化偏差，提升视觉-语言模型在零样本设置下的泛化性能。

Abstract: Test-time prompt tuning for vision-language models has demonstrated impressive generalization capabilities under zero-shot settings. However, tuning the learnable prompts solely based on unlabeled test data may induce prompt optimization bias, ultimately leading to suboptimal performance on downstream tasks. In this work, we analyze the underlying causes of prompt optimization bias from both the model and data perspectives. In terms of the model, the entropy minimization objective typically focuses on reducing the entropy of model predictions while overlooking their correctness. This can result in overconfident yet incorrect outputs, thereby compromising the quality of prompt optimization. On the data side, prompts affected by optimization bias can introduce misalignment between visual and textual modalities, which further aggravates the prompt optimization bias. To this end, we propose a Doubly Debiased Test-Time Prompt Tuning method. Specifically, we first introduce a dynamic retrieval-augmented modulation module that retrieves high-confidence knowledge from a dynamic knowledge base using the test image feature as a query, and uses the retrieved knowledge to modulate the predictions. Guided by the refined predictions, we further develop a reliability-aware prompt optimization module that incorporates a confidence-based weighted ensemble and cross-modal consistency distillation to impose regularization constraints during prompt tuning. Extensive experiments across 15 benchmark datasets involving both natural distribution shifts and cross-datasets generalization demonstrate that our method outperforms baselines, validating its effectiveness in mitigating prompt optimization bias.

</details>


### [614] [Are LLMs The Way Forward? A Case Study on LLM-Guided Reinforcement Learning for Decentralized Autonomous Driving](https://arxiv.org/abs/2511.12751)
*Timur Anvar,Jeffrey Chen,Yuyan Wang,Rohan Chandra*

Main category: cs.LG

TL;DR: 研究探讨了在自动驾驶高速公路场景中，使用小型本地部署的LLM（<14B参数）通过奖励塑形辅助强化学习（RL），而非直接控制，比较了纯RL、纯LLM和混合方法的表现。


<details>
  <summary>Details</summary>
Motivation: 强化学习依赖设计良好的奖励函数，难以应对复杂、分布外的真实驾驶场景；而大语言模型虽能理解语义和社会上下文，但存在零样本下不安全、输出不稳定和延迟高等问题，因此探索小型LLM如何有效辅助RL。

Method: 提出一种混合方法：在训练阶段用小型LLM对状态-动作转移进行评分以塑造RL奖励，测试时仍由标准RL策略执行；对比纯RL、纯LLM和混合方法在高速公路驾驶任务中的表现。

Result: 纯RL方法成功率为73-89%，效率合理；纯LLM方法成功率最高达94%，但速度性能显著下降；混合方法表现介于两者之间；所有LLM影响的方法均表现出系统性保守偏差，且效果受模型影响较大。

Conclusion: 尽管给予明确效率指令，当前小型LLM在安全关键型控制任务中仍表现出保守性和不稳定性，限制了其在自动驾驶奖励塑形中的有效性，需进一步改进。

Abstract: Autonomous vehicle navigation in complex environments such as dense and fast-moving highways and merging scenarios remains an active area of research. A key limitation of RL is its reliance on well-specified reward functions, which often fail to capture the full semantic and social complexity of diverse, out-of-distribution situations. As a result, a rapidly growing line of research explores using Large Language Models (LLMs) to replace or supplement RL for direct planning and control, on account of their ability to reason about rich semantic context. However, LLMs present significant drawbacks: they can be unstable in zero-shot safety-critical settings, produce inconsistent outputs, and often depend on expensive API calls with network latency. This motivates our investigation into whether small, locally deployed LLMs (< 14B parameters) can meaningfully support autonomous highway driving through reward shaping rather than direct control. We present a case study comparing RL-only, LLM-only, and hybrid approaches, where LLMs augment RL rewards by scoring state-action transitions during training, while standard RL policies execute at test time. Our findings reveal that RL-only agents achieve moderate success rates (73-89%) with reasonable efficiency, LLM-only agents can reach higher success rates (up to 94%) but with severely degraded speed performance, and hybrid approaches consistently fall between these extremes. Critically, despite explicit efficiency instructions, LLM-influenced approaches exhibit systematic conservative bias with substantial model-dependent variability, highlighting important limitations of current small LLMs for safety-critical control tasks.

</details>


### [615] [Beyond saliency: enhancing explanation of speech emotion recognition with expert-referenced acoustic cues](https://arxiv.org/abs/2511.11691)
*Seham Nasr,Zhao Ren,David Johnson*

Main category: cs.LG

TL;DR: 提出一种新的可解释AI框架，通过量化显著区域中的声学线索强度，将显著性与专家参考的情感声学特征联系起来，提升语音情感识别模型解释的可信度和可理解性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于显著性的解释方法仅突出频谱图区域，但无法说明这些区域是否对应有意义的情感声学标记，限制了可解释性和可信度。

Method: 提出一个新框架，量化显著区域内的声学线索强度，将显著性映射到理论驱动的、专家参考的语音情感声学特征上，从而连接‘突出什么’和‘为何重要’。

Result: 在基准SER数据集上的实验表明，该方法相比标准显著性方法能提供更清晰、更合理、更易理解的模型解释。

Conclusion: 该方法通过显式关联显著区域与理论驱动的声学线索，提升了语音情感识别中解释的质量，为可信的语音情感计算提供了基础。

Abstract: Explainable AI (XAI) for Speech Emotion Recognition (SER) is critical for building transparent, trustworthy models. Current saliency-based methods, adapted from vision, highlight spectrogram regions but fail to show whether these regions correspond to meaningful acoustic markers of emotion, limiting faithfulness and interpretability. We propose a framework that overcomes these limitations by quantifying the magnitudes of cues within salient regions. This clarifies "what" is highlighted and connects it to "why" it matters, linking saliency to expert-referenced acoustic cues of speech emotions. Experiments on benchmark SER datasets show that our approach improves explanation quality by explicitly linking salient regions to theory-driven speech emotions expert-referenced acoustics. Compared to standard saliency methods, it provides more understandable and plausible explanations of SER models, offering a foundational step towards trustworthy speech-based affective computing.

</details>


### [616] [AnchorDS: Anchoring Dynamic Sources for Semantically Consistent Text-to-3D Generation](https://arxiv.org/abs/2511.11692)
*Jiayin Zhu,Linlin Yang,Yicong Li,Angela Yao*

Main category: cs.LG

TL;DR: 提出AnchorDS，一种改进的分数蒸馏机制，通过引入图像条件和轻量级过滤策略，在文本到3D生成中实现更稳定、语义一致性更强且细节更丰富的结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的文本到3D方法忽略2D生成模型指导信号的动态性，导致语义过平滑等伪影问题。

Method: 将文本到3D优化重构为从动态源分布到固定目标分布的映射，引入双条件潜在空间（文本和中间渲染图像），并设计状态锚定的分数蒸馏机制（AnchorDS）及轻量级过滤与微调策略。

Result: AnchorDS在复杂提示下生成更精细的细节、更自然的颜色和更强的语义一致性，同时保持高效，在质量和效率上均优于先前方法。

Conclusion: 通过显式建模源分布的动态特性并引入图像条件锚定，AnchorDS有效缓解了语义过平滑问题，提升了文本到3D生成的稳定性和保真度。

Abstract: Optimization-based text-to-3D methods distill guidance from 2D generative models via Score Distillation Sampling (SDS), but implicitly treat this guidance as static. This work shows that ignoring source dynamics yields inconsistent trajectories that suppress or merge semantic cues, leading to "semantic over-smoothing" artifacts. As such, we reformulate text-to-3D optimization as mapping a dynamically evolving source distribution to a fixed target distribution. We cast the problem into a dual-conditioned latent space, conditioned on both the text prompt and the intermediately rendered image. Given this joint setup, we observe that the image condition naturally anchors the current source distribution. Building on this insight, we introduce AnchorDS, an improved score distillation mechanism that provides state-anchored guidance with image conditions and stabilizes generation. We further penalize erroneous source estimates and design a lightweight filter strategy and fine-tuning strategy that refines the anchor with negligible overhead. AnchorDS produces finer-grained detail, more natural colours, and stronger semantic consistency, particularly for complex prompts, while maintaining efficiency. Extensive experiments show that our method surpasses previous methods in both quality and efficiency.

</details>


### [617] [Toward Dignity-Aware AI: Next-Generation Elderly Monitoring from Fall Detection to ADL](https://arxiv.org/abs/2511.11696)
*Xun Shao,Aoba Otani,Yuto Hirasuka,Runji Cai,Seng W. Loke*

Main category: cs.LG

TL;DR: 本文提出了一种面向老年人日常活动识别的下一代监测系统愿景，强调隐私保护、边缘部署和联邦学习，通过跌倒检测的初步实验验证了可行性，并提出了迈向全面ADL监测的挑战与路径。


<details>
  <summary>Details</summary>
Motivation: 现有的老年监测系统多集中于跌倒检测，缺乏对日常活动的全面理解。本文旨在推动从单一任务向全面、尊重隐私且以人为本的日常活动识别系统发展，以支持老年人独立生活。

Method: 采用SISFall数据集及其GAN增强版本进行跌倒检测作为代理任务，实验评估联邦学习在非独立同分布（non-IID）条件下的性能，并在Jetson Orin Nano设备上实现嵌入式部署，为未来ADL识别系统提供技术验证。

Result: 初步实验表明，在non-IID条件下联邦学习具有可行性，且模型可在边缘设备上有效部署；同时识别出领域偏移、数据稀缺和隐私风险等关键挑战。

Conclusion: 本文展示了从单一跌倒检测向全面ADL识别过渡的技术路径和研究方向，为构建可持续、人性化、隐私友好的智能老年照护系统提供了早期证据和 roadmap。

Abstract: This position paper envisions a next-generation elderly monitoring system that moves beyond fall detection toward the broader goal of Activities of Daily Living (ADL) recognition. Our ultimate aim is to design privacy-preserving, edge-deployed, and federated AI systems that can robustly detect and understand daily routines, supporting independence and dignity in aging societies. At present, ADL-specific datasets are still under collection. As a preliminary step, we demonstrate feasibility through experiments using the SISFall dataset and its GAN-augmented variants, treating fall detection as a proxy task. We report initial results on federated learning with non-IID conditions, and embedded deployment on Jetson Orin Nano devices. We then outline open challenges such as domain shift, data scarcity, and privacy risks, and propose directions toward full ADL monitoring in smart-room environments. This work highlights the transition from single-task detection to comprehensive daily activity recognition, providing both early evidence and a roadmap for sustainable and human-centered elderly care AI.

</details>


### [618] [Benchmarking GNNs for OOD Materials Property Prediction with Uncertainty Quantification](https://arxiv.org/abs/2511.11697)
*Liqin Tan,Pin Chen,Menghan Liu,Xiean Wang,Jianhuan Cen,Qingsong Zou*

Main category: cs.LG

TL;DR: MatUQ是一个用于评估图神经网络在材料属性预测中分布外泛化与不确定性量化的基准框架，提出SOAP-LOCO分割策略和D-EviU不确定性度量指标，发现不确定性感知训练显著提升性能，且不同模型在不同任务中表现各异。


<details>
  <summary>Details</summary>
Motivation: 现有材料属性预测模型多在独立同分布假设下评估，缺乏对分布外泛化能力和不确定性量化的系统评估，难以满足实际材料发现中分布偏移场景的需求。

Method: 构建包含1,375个OOD任务的MatUQ基准，采用基于OFM和新提出的SOAP-LOCO结构感知数据分割策略；对12种代表性GNN模型使用结合Monte Carlo Dropout与Deep Evidential Regression的统一不确定性感知训练协议进行评估，并提出D-EviU作为新的不确定性评价指标。

Result: 不确定性感知训练平均降低70.6%的预测误差；D-EviU指标与预测误差在多数任务中表现出最强相关性；实验显示无单一模型在所有任务中占优，SchNet、ALIGNN等早期模型仍具竞争力，CrystalFramer和SODNet在特定属性上表现更优。

Conclusion: MatUQ为材料属性预测提供了可靠的OOD评估平台，强调了不确定性建模的重要性，并表明应根据具体任务选择合适模型，为实际材料发现中的模型部署提供了实用指导。

Abstract: We present MatUQ, a benchmark framework for evaluating graph neural networks (GNNs) on out-of-distribution (OOD) materials property prediction with uncertainty quantification (UQ). MatUQ comprises 1,375 OOD prediction tasks constructed from six materials datasets using five OFM-based and a newly proposed structure-aware splitting strategy, SOAP-LOCO, which captures local atomic environments more effectively. We evaluate 12 representative GNN models under a unified uncertainty-aware training protocol that combines Monte Carlo Dropout and Deep Evidential Regression (DER), and introduce a novel uncertainty metric, D-EviU, which shows the strongest correlation with prediction errors in most tasks. Our experiments yield two key findings. First, the uncertainty-aware training approach significantly improves model prediction accuracy, reducing errors by an average of 70.6\% across challenging OOD scenarios. Second, the benchmark reveals that no single model dominates universally: earlier models such as SchNet and ALIGNN remain competitive, while newer models like CrystalFramer and SODNet demonstrate superior performance on specific material properties. These results provide practical insights for selecting reliable models under distribution shifts in materials discovery.

</details>


### [619] [Moirai 2.0: When Less Is More for Time Series Forecasting](https://arxiv.org/abs/2511.11698)
*Chenghao Liu,Taha Aksu,Juncheng Liu,Xu Liu,Hanshu Yan,Quang Pham,Doyen Sahoo,Caiming Xiong,Silvio Savarese,Junnan Li*

Main category: cs.LG

TL;DR: Moirai 2.0 是一种改进的仅解码器时间序列基础模型，采用分位数预测和多标记预测，在准确性、速度和模型大小之间实现了更好权衡。


<details>
  <summary>Details</summary>
Motivation: 改进 Moirai 1.0 的复杂架构，提升时间序列预测的效率和性能，同时探索更简化的训练方法。

Method: 使用包含3600万序列的新数据集训练仅解码器模型，采用分位数损失和单patch输入，结合递归多分位数解码。

Result: 在 Gift-Eval 基准上表现优异，比 Moirai 1.0-Large 快两倍且小30倍，性能更好；消融实验表明仅解码器结构和多分位数解码是主要贡献因素。

Conclusion: Moirai 2.0 在简化架构的同时显著提升了效率和性能，但性能随参数增加趋于饱和，长时域预测仍有下降，未来需关注数据扩展和长周期建模。

Abstract: We introduce Moirai 2.0, a decoder-only time-series foundation model trained on a new corpus of 36M series. The model adopts quantile forecasting and multi-token prediction, improving both probabilistic accuracy and inference efficiency. On the Gift-Eval benchmark, it ranks among the top pretrained models while achieving a strong trade-off between accuracy, speed, and model size. Compared to Moirai 1.0, Moirai 2.0 replaces masked-encoder training, multi-patch inputs, and mixture-distribution outputs with a simpler decoder-only architecture, single patch, and quantile loss. Ablation studies isolate these changes -- showing that the decoder-only backbone along with recursive multi-quantile decoding contribute most to the gains. Additional experiments show that Moirai 2.0 outperforms larger models from the same family and exhibits robust domain-level results. In terms of efficiency and model size, Moirai 2.0 is twice as fast and thirty times smaller than its prior best version, Moirai 1.0-Large, while also performing better. Model performance plateaus with increasing parameter count and declines at longer horizons, motivating future work on data scaling and long-horizon modeling. We release code and evaluation details to support further research.

</details>


### [620] [Tighter Truncated Rectangular Prism Approximation for RNN Robustness Verification](https://arxiv.org/abs/2511.11699)
*Xingqi Lin,Liangyu Chen,Min Wu,Min Zhang,Zhenbing Zeng*

Main category: cs.LG

TL;DR: 本文提出了一种新的截断矩形棱柱方法，用于更紧密地近似RNN中的Hadamard积非线性曲面，从而提高鲁棒性验证的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在对非线性激活函数进行线性近似时存在较大过估计，导致验证精度降低。为了提升RNN鲁棒性验证的准确性，需要更紧致的近似方法。

Method: 提出一种由两个线性松弛平面构成的截断矩形棱柱，并结合 refinement-driven 方法最小化其体积和表面积，以实现对Hadamard积产生的三维非线性曲面的 tighter over-approximation。基于此实现了原型系统 DeepPrism。

Result: 实验结果表明，DeepPrism 在图像分类、语音识别和情感分析等多个任务中相比现有最先进方法有显著改进。

Conclusion: 该方法通过更精确的线性近似有效提升了RNN鲁棒性验证的准确性和效率，具有广泛的应用前景。

Abstract: Robustness verification is a promising technique for rigorously proving Recurrent Neural Networks (RNNs) robustly. A key challenge is to over-approximate the nonlinear activation functions with linear constraints, which can transform the verification problem into an efficiently solvable linear programming problem. Existing methods over-approximate the nonlinear parts with linear bounding planes individually, which may cause significant over-estimation and lead to lower verification accuracy. In this paper, in order to tightly enclose the three-dimensional nonlinear surface generated by the Hadamard product, we propose a novel truncated rectangular prism formed by two linear relaxation planes and a refinement-driven method to minimize both its volume and surface area for tighter over-approximation. Based on this approximation, we implement a prototype DeepPrism for RNN robustness verification. The experimental results demonstrate that \emph{DeepPrism} has significant improvement compared with the state-of-the-art approaches in various tasks of image classification, speech recognition and sentiment analysis.

</details>


### [621] [Bayesian Neural Networks with Monte Carlo Dropout for Probabilistic Electricity Price Forecasting](https://arxiv.org/abs/2511.11701)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 提出了一种基于贝叶斯神经网络（BNN）和蒙特卡洛Dropout的电力价格概率预测框架，按小时建模以捕捉日周期模式，优于GARCHX和LEAR等基准模型。


<details>
  <summary>Details</summary>
Motivation: 传统点预测难以捕捉电力市场价格波动中的不确定性，限制了其在风险管理中的应用，因此需要更可靠的概率预测方法。

Method: 采用贝叶斯神经网络结合蒙特卡洛Dropout进行概率预测，分别训练每天每小时的独立模型以捕捉日变化特征，并与GARCHX和LEAR模型进行对比。

Result: 所提模型在点预测和预测区间方面均优于GARCHX和LEAR等基准模型，表现出更强的预测精度和不确定性量化能力。

Conclusion: 该研究表明，基于BNN的概率预测框架能有效提升电力市场价格预测性能，为能源市场预测中应用概率神经模型提供了参考。

Abstract: Accurate electricity price forecasting is critical for strategic decision-making in deregulated electricity markets, where volatility stems from complex supply-demand dynamics and external factors. Traditional point forecasts often fail to capture inherent uncertainties, limiting their utility for risk management. This work presents a framework for probabilistic electricity price forecasting using Bayesian neural networks (BNNs) with Monte Carlo (MC) dropout, training separate models for each hour of the day to capture diurnal patterns. A critical assessment and comparison with the benchmark model, namely: generalized autoregressive conditional heteroskedasticity with exogenous variable (GARCHX) model and the LASSO estimated auto-regressive model (LEAR), highlights that the proposed model outperforms the benchmark models in terms of point prediction and intervals. This work serves as a reference for leveraging probabilistic neural models in energy market predictions.

</details>


### [622] [Simple Vision-Language Math Reasoning via Rendered Text](https://arxiv.org/abs/2511.11704)
*Matvey Skripkin,Elizaveta Goncharova,Andrey Kuznetsov*

Main category: cs.LG

TL;DR: 提出了一种轻量级但有效的视觉-语言模型训练管道，通过将LaTeX公式渲染为图像并结合结构化思维链提示来解决数学问题。该方法在多个基准测试中达到或超过了现有模型的性能，同时保持了广泛的通用任务能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在数学推理任务中表现受限，需要更有效的训练方法来提升其推理能力和泛化性能。

Method: 将LaTeX编码的数学公式渲染为图像，并与结构化的链式思维提示配对，用于训练紧凑的多模态架构。

Result: 该方法在多个数学推理基准上达到或超越了开源和专有模型的性能，且在MMMU、ChartQA和DocVQA等任务上最多提升了20%。

Conclusion: 高保真渲染和提示设计是提升模型数学推理能力的关键因素，所提方法简单有效，兼具高性能与通用性。

Abstract: We present a lightweight yet effective pipeline for training vision-language models to solve math problems by rendering LaTeX encoded equations into images and pairing them with structured chain-of-thought prompts. This simple text-to-vision augmentation enables compact multimodal architectures to achieve state-of-the-art reasoning accuracy. Through systematic ablations, we find that rendering fidelity and prompt design are the primary drivers of performance. Despite its simplicity, our approach consistently matches or surpasses both open-source and proprietary math-focused vision-language solvers on widely used benchmarks, while preserving broad general-domain competence - showing gains on tasks such as MMMU, ChartQA, and DocVQA of up to 20%.

</details>


### [623] [Multimodal ML: Quantifying the Improvement of Calorie Estimation Through Image-Text Pairs](https://arxiv.org/abs/2511.11705)
*Arya Narang*

Main category: cs.LG

TL;DR: 该论文研究了在热量估计任务中，结合短文本输入（如菜品名称）与图像相比纯图像模型是否能够提升性能，并验证了提升的显著性。使用TensorFlow和Nutrition5k数据集训练了纯图像CNN和多模态CNN模型。


<details>
  <summary>Details</summary>
Motivation: 探索多模态信息（图像+文本）在饮食热量估计中的潜力，以提高自动化营养分析的准确性。

Method: 基于TensorFlow框架，利用Nutrition5k数据集，构建并比较了仅使用图像的CNN模型和融合图像与文本的多模态CNN模型。

Result: 多模态模型将平均绝对误差（MAE）从84.76 kcal降至83.70 kcal，降低了1.06 kcal（提升1.25%）。

Conclusion: 引入菜品名称等短文本信息可轻微但可测量地改善热量估计效果，表明多模态方法具有一定潜力。

Abstract: This paper determines the extent to which short textual inputs (in this case, names of dishes) can improve calorie estimation compared to an image-only baseline model and whether any improvements are statistically significant. Utilizes the TensorFlow library and the Nutrition5k dataset (curated by Google) to train both an image-only CNN and multimodal CNN that accepts both text and an image as input. The MAE of calorie estimations was reduced by 1.06 kcal from 84.76 kcal to 83.70 kcal (1.25% improvement) when using the multimodal model.

</details>


### [624] [Context-Aware Multimodal Representation Learning for Spatio-Temporally Explicit Environmental modelling](https://arxiv.org/abs/2511.11706)
*Julia Peters,Karin Mora,Miguel D. Mahecha,Chaonan Ji,David Montero,Clemens Mosig,Guido Kraemer*

Main category: cs.LG

TL;DR: 提出一种多模态地球观测表征学习框架，融合Sentinel-1和Sentinel-2数据，在10米高空间分辨率下生成具有时间一致性的嵌入表示，支持细尺度生态分析。


<details>
  <summary>Details</summary>
Motivation: 现有地球观测基础模型通常局限于固定时空尺度，难以满足需要高空间细节和高时间保真度的生态分析需求。

Method: 采用两阶段框架：首先独立建模不同传感器（如Sentinel-1和Sentinel-2）以捕捉其特性，然后将各自表征融合到统一的共享空间；保持预训练编码器不变，仅重训练融合层，实现模块化与可扩展性。

Result: 生成的嵌入在空间和语义上具有一致性；在总初级生产力建模任务中表现出生态意义明确且时间保真度高，适用于细尺度环境分析。

Conclusion: 该框架提供了一种灵活、即用型的表征学习方法，可有效整合多源遥感数据，支持多样化的时空分辨率需求，适用于复杂生态环境动态监测。

Abstract: Earth observation (EO) foundation models have emerged as an effective approach to derive latent representations of the Earth system from various remote sensing sensors. These models produce embeddings that can be used as analysis-ready datasets, enabling the modelling of ecosystem dynamics without extensive sensor-specific preprocessing. However, existing models typically operate at fixed spatial or temporal scales, limiting their use for ecological analyses that require both fine spatial detail and high temporal fidelity. To overcome these limitations, we propose a representation learning framework that integrates different EO modalities into a unified feature space at high spatio-temporal resolution. We introduce the framework using Sentinel-1 and Sentinel-2 data as representative modalities. Our approach produces a latent space at native 10 m resolution and the temporal frequency of cloud-free Sentinel-2 acquisitions. Each sensor is first modeled independently to capture its sensor-specific characteristics. Their representations are then combined into a shared model. This two-stage design enables modality-specific optimisation and easy extension to new sensors, retaining pretrained encoders while retraining only fusion layers. This enables the model to capture complementary remote sensing data and to preserve coherence across space and time. Qualitative analyses reveal that the learned embeddings exhibit high spatial and semantic consistency across heterogeneous landscapes. Quantitative evaluation in modelling Gross Primary Production reveals that they encode ecologically meaningful patterns and retain sufficient temporal fidelity to support fine-scale analyses. Overall, the proposed framework provides a flexible, analysis-ready representation learning approach for environmental applications requiring diverse spatial and temporal resolutions.

</details>


### [625] [FSC-Net: Fast-Slow Consolidation Networks for Continual Learning](https://arxiv.org/abs/2511.11707)
*Mohamed El Gorrim*

Main category: cs.LG

TL;DR: 提出FSC-Net，一种双网络结构，通过快速网络进行任务学习，慢速网络进行知识巩固，有效缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 神经网络在持续学习中新任务时容易遗忘旧知识，受神经科学中记忆巩固机制启发，需设计更有效的持续学习模型。

Method: 采用双网络架构：快速网络（NN1）用于新任务的即时适应，慢速网络（NN2）通过回放和蒸馏进行知识巩固；系统分析了不同架构与超参数的影响。

Result: 在Split-MNIST上比单独快速网络提升+4.27pp（91.71%），在Split-CIFAR-10上提升+8.20pp（33.31%）；发现纯回放优于结合蒸馏，且模型效果更多取决于方法而非结构复杂度。

Conclusion: 双时间尺度的巩固机制是缓解灾难性遗忘的关键，而非网络复杂性；未来需更强主干网络以提升绝对性能。

Abstract: Continual learning remains challenging due to catastrophic forgetting, where neural networks lose previously acquired knowledge when learning new tasks. Inspired by memory consolidation in neuroscience, we propose FSC-Net (Fast-Slow Consolidation Networks), a dual-network architecture that separates rapid task learning from gradual knowledge consolidation. Our method employs a fast network (NN1) for immediate adaptation to new tasks and a slow network (NN2) that consolidates knowledge through distillation and replay. Within the family of MLP-based NN1 variants we evaluated, consolidation effectiveness is driven more by methodology than architectural embellishments -- a simple MLP outperforms more complex similarity-gated variants by 1.2pp. Through systematic hyperparameter analysis, we observed empirically that pure replay without distillation during consolidation achieves superior performance, consistent with the hypothesis that distillation from the fast network introduces recency bias. On Split-MNIST (30 seeds), FSC-Net achieves 91.71% +/- 0.62% retention accuracy, a +4.27pp gain over the fast network alone (87.43% +/- 1.27%, paired t=23.585, p < 1e-10). On Split-CIFAR-10 (5 seeds), our method achieves 33.31% +/- 0.38% retention with an +8.20pp gain over the fast network alone (25.11% +/- 1.61%, paired t=9.75, p < 1e-3), demonstrating +8.20pp gain, though absolute performance (33.31%) remains modest and below random expectation, highlighting need for stronger backbones. Our results provide empirical evidence that the dual-timescale consolidation mechanism, rather than architectural complexity, is central to mitigating catastrophic forgetting in this setting.

</details>


### [626] [Which Sparse Autoencoder Features Are Real? Model-X Knockoffs for False Discovery Rate Control](https://arxiv.org/abs/2511.11711)
*Tsogt-Ochir Enkhbayar*

Main category: cs.LG

TL;DR: 本文提出将Model-X knockoffs引入稀疏自编码器（SAE）特征选择中，以在控制错误发现率（FDR）的前提下识别神经网络中的可解释特征。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器虽能提取可解释特征，但难以区分真实计算模式与虚假相关性，因此需要一种具备统计保证的可靠特征选择方法。

Method: 采用Model-X knockoffs结合knock-off+方法，在标准假设下通过高斯代理模型控制FDR，并应用于Pythia-70M模型中512个高活跃SAE隐变量的分析，进行情感分类任务的特征选择。

Result: 在目标FDR q=0.1下选出了129个特征，结果显示约25%的隐变量包含任务相关信号，所选特征在knockoff统计量上表现出是非选特征的5.40倍分离度。

Conclusion: 该方法结合SAE与多重检验感知推断，提供了可复现且原理严谨的特征发现框架，推动了机制可解释性的基础发展。

Abstract: Although sparse autoencoders (SAEs) are crucial for identifying interpretable features in neural networks, it is still challenging to distinguish between real computational patterns and erroneous correlations. We introduce Model-X knockoffs to SAE feature selection, using knock-off+ to control the false discovery rate (FDR) with finite-sample guarantees under the standard Model-X assumptions (in our case, via a Gaussian surrogate for the latent distribution). We select 129 features at a target FDR q=0.1 after analyzing 512 high-activity SAE latents for sentiment classification using Pythia-70M. About 25% of the latents under examination carry task-relevant signal, whereas 75% do not, according to the chosen set, which displays a 5.40x separation in knockoff statistics compared to non-selected features. Our method offers a re-producible and principled framework for reliable feature discovery by combining SAEs with multiple-testing-aware inference, advancing the foundations of mechanistic interpretability.

</details>


### [627] [Reasoning: From Reflection to Solution](https://arxiv.org/abs/2511.11712)
*Zixi Li*

Main category: cs.LG

TL;DR: 本文提出推理是状态空间中迭代算子应用并收敛到固定点的过程，通过OpenXOR问题、OpenOperator理论和OpenLM模型展示了现有大语言模型的局限性，并实现了在特定任务上远超当前模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型是否真正具备推理能力，还是仅在模仿推理过程中的模式匹配，试图从哲学和计算角度重新定义推理的本质。

Method: 提出‘推理即状态空间中迭代算子应用’的理论框架，设计OpenXOR难题验证现有模型缺陷，构建OpenOperator理论，并实现OpenLM系统以验证所提架构的有效性。

Result: OpenLM在现有最先进大语言模型表现为0%准确率的任务上达到了76%的准确率，证明了所提推理架构的有效性。

Conclusion: 真正的推理需要支持迭代操作和状态演进的架构，当前大语言模型缺乏此类机制，未来应基于明确的推理结构设计新模型。

Abstract: What is reasoning? This question has driven centuries of philosophical inquiry, from Aristotle's syllogisms to modern computational complexity theory. In the age of large language models achieving superhuman performance on benchmarks like GSM8K (95\% accuracy) and HumanEval (90\% pass@1), we must ask: have these systems learned to \emph{reason}, or have they learned to \emph{pattern-match over reasoning traces}?
  This paper argues for a specific answer: \textbf{reasoning is iterative operator application in state spaces, converging to fixed points}. This definition is not merely philosophical -- it has concrete architectural implications that explain both the failures of current systems and the path to genuine reasoning capabilities.
  Our investigation begins with a puzzle (OpenXOR), progresses through theory (OpenOperator), and culminates in a working solution (OpenLM) that achieves 76\% accuracy where state-of-the-art LLMs achieve 0\%. This is not about criticizing existing systems, but about \emph{understanding what reasoning requires} and \emph{building architectures that provide it}.

</details>


### [628] [Federated Learning for Pediatric Pneumonia Detection: Enabling Collaborative Diagnosis Without Sharing Patient Data](https://arxiv.org/abs/2511.11714)
*Daniel M. Jimenez-Gutierrez,Enrique Zuazua,Joaquin Del Rio,Oleksii Sliusarenko,Xabi Uribe-Etxebarria*

Main category: cs.LG

TL;DR: 本论文评估了基于Sherpa.ai联邦学习平台的肺炎检测方法，利用胸部X光片在保护数据隐私的前提下实现多医院协作训练模型，在非独立同分布数据下显著提升了模型性能，准确率达到0.900，ROC-AUC达到0.966，较单医院模型大幅提升。


<details>
  <summary>Details</summary>
Motivation: 由于数据分散、隐私法规严格以及医疗机构间数据异质性高，传统集中式AI模型难以有效开发；因此需要一种既能保护隐私又能整合多中心数据的解决方案。

Method: 采用联邦学习（FL）框架，使用Pediatric Pneumonia Chest X-ray数据集模拟多医院协作场景，处理非独立同分布（non-IID）数据，通过Sherpa.ai FL平台在不传输原始影像的情况下联合训练肺炎分类模型。

Result: 联邦学习模型在不传输任何患者X光图像的情况下，实现了0.900的准确率和0.966的ROC-AUC，相比单医院模型分别提升47.5%和50.0%。

Conclusion: 联邦学习能够在保障数据本地化和隐私安全的前提下，显著提升肺炎检测模型的性能和泛化能力，尤其适用于罕见病和数据稀缺场景下的跨机构协作，具有重要的临床与实践意义。

Abstract: Early and accurate pneumonia detection from chest X-rays (CXRs) is clinically critical to expedite treatment and isolation, reduce complications, and curb unnecessary antibiotic use. Although artificial intelligence (AI) substantially improves CXR-based detection, development is hindered by globally distributed data, high inter-hospital variability, and strict privacy regulations (e.g., HIPAA, GDPR) that make centralization impractical. These constraints are compounded by heterogeneous imaging protocols, uneven data availability, and the costs of transferring large medical images across geographically dispersed sites.
  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL platform, enabling multiple hospitals (nodes) to collaboratively train a CXR classifier for pneumonia while keeping data in place and private. Using the Pediatric Pneumonia Chest X-ray dataset, we simulate cross-hospital collaboration with non-independent and non-identically distributed (non-IID) data, reproducing real-world variability across institutions and jurisdictions. Our experiments demonstrate that collaborative and privacy-preserving training across multiple hospitals via FL led to a dramatic performance improvement achieving 0.900 Accuracy and 0.966 ROC-AUC, corresponding to 47.5% and 50.0% gains over single-hospital models (0.610; 0.644), without transferring any patient CXR. These results indicate that FL delivers high-performing, generalizable, secure and private pneumonia detection across healthcare networks, with data kept local. This is especially relevant for rare diseases, where FL enables secure multi-institutional collaboration without data movement, representing a breakthrough for accelerating diagnosis and treatment development in low-data domains.

</details>


### [629] [Multiscale Grassmann Manifolds for Single-Cell Data Analysis](https://arxiv.org/abs/2511.11717)
*Xiang Xiang Wang,Sean Cottrell,Guo-Wei Wei*

Main category: cs.LG

TL;DR: 提出了一种基于Grassmann流形的多尺度框架，用于单细胞数据分析，能够有效保持数据结构并提升聚类稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在欧氏空间中表示细胞，难以捕捉基因表达数据中的内在相关性和多尺度几何结构。

Method: 利用Grassmann流形构建多尺度嵌入框架，引入基于幂律的尺度采样函数来整合不同几何视角下的特征。

Result: 在九个单细胞RNA-seq数据集上验证了该方法能有效保留有意义的结构，并在小到中等规模数据上表现出稳定的聚类性能。

Conclusion: Grassmann流形为单细胞数据提供了连贯且信息丰富的分析基础。

Abstract: Single-cell data analysis seeks to characterize cellular heterogeneity based on high-dimensional gene expression profiles. Conventional approaches represent each cell as a vector in Euclidean space, which limits their ability to capture intrinsic correlations and multiscale geometric structures. We propose a multiscale framework based on Grassmann manifolds that integrates machine learning with subspace geometry for single-cell data analysis. By generating embeddings under multiple representation scales, the framework combines their features from different geometric views into a unified Grassmann manifold. A power-based scale sampling function is introduced to control the selection of scales and balance in- formation across resolutions. Experiments on nine benchmark single-cell RNA-seq datasets demonstrate that the proposed approach effectively preserves meaningful structures and provides stable clustering performance, particularly for small to medium-sized datasets. These results suggest that Grassmann manifolds offer a coherent and informative foundation for analyzing single cell data.

</details>


### [630] [Fast 3D Surrogate Modeling for Data Center Thermal Management](https://arxiv.org/abs/2511.11722)
*Soumyendu Sarkar,Antonio Guillen-Perez,Zachariah J Carmichael,Avisek Naug,Refik Mert Cam,Vineet Gundecha,Ashwin Ramesh Babu,Sahand Ghorbanpour,Ricardo Luna Gutierrez*

Main category: cs.LG

TL;DR: 提出一种基于3D体素表示的视觉代理模型框架，用于数据中心温度场的实时预测，相比传统CFD方法实现高达20,000倍的速度提升，并支持节能7%和降低碳排放。


<details>
  <summary>Details</summary>
Motivation: 传统CFD方法计算成本高、依赖专家设计，难以满足数据中心实时温度预测需求，阻碍了能效优化与碳减排目标的实现。

Method: 构建基于3D体素化表示的视觉代理模型，直接输入服务器负载、风扇转速和HVAC设定温度，采用3D CNN U-Net变体、3D Fourier Neural Operator和3D视觉Transformer等多种架构进行端到端热图预测。

Result: 代理模型在不同数据中心配置下具有良好泛化能力，推理时间从数小时缩短至数百毫秒，实现最高达20,000倍的加速，且能准确识别热点分布。

Conclusion: 该方法实现了高效、精确的数据中心温度场实时预测，为动态冷却控制与工作负载调度提供了技术支持，显著提升了能源效率并减少了碳足迹。

Abstract: Reducing energy consumption and carbon emissions in data centers by enabling real-time temperature prediction is critical for sustainability and operational efficiency. Achieving this requires accurate modeling of the 3D temperature field to capture airflow dynamics and thermal interactions under varying operating conditions. Traditional thermal CFD solvers, while accurate, are computationally expensive and require expert-crafted meshes and boundary conditions, making them impractical for real-time use. To address these limitations, we develop a vision-based surrogate modeling framework that operates directly on a 3D voxelized representation of the data center, incorporating server workloads, fan speeds, and HVAC temperature set points. We evaluate multiple architectures, including 3D CNN U-Net variants, a 3D Fourier Neural Operator, and 3D vision transformers, to map these thermal inputs to high-fidelity heat maps. Our results show that the surrogate models generalize across data center configurations and achieve up to 20,000x speedup (hundreds of milliseconds vs. hours). This fast and accurate estimation of hot spots and temperature distribution enables real-time cooling control and workload redistribution, leading to substantial energy savings (7\%) and reduced carbon footprint.

</details>


### [631] [Optimizing Input of Denoising Score Matching is Biased Towards Higher Score Norm](https://arxiv.org/abs/2511.11727)
*Tongda Xu*

Main category: cs.LG

TL;DR: 本文指出，使用去噪得分匹配来优化扩散模型的条件输入会破坏其与精确得分匹配的等价性，并引入导致得分范数增高的偏差，这一偏差也存在于使用预训练扩散模型优化数据分布的情况中，影响了多个领域的相关工作。


<details>
  <summary>Details</summary>
Motivation: 近年来许多工作利用去噪得分匹配优化扩散模型的条件输入，但这种做法可能存在问题，本文旨在揭示其带来的理论偏差及其广泛影响。

Method: 通过理论分析去噪得分匹配与精确得分匹配之间的关系，揭示在优化过程中引入的偏差，并通过观察预训练扩散模型在数据分布优化中的表现验证该偏差的存在。

Result: 证明了去噪得分匹配在优化条件输入时破坏了与精确得分匹配的等价性，导致更高的得分范数，并在多种应用中观察到类似偏差。

Conclusion: 当前广泛使用的基于去噪得分匹配的优化方法存在系统性偏差，需重新审视其在各类生成任务中的适用性和改进方向。

Abstract: Many recent works utilize denoising score matching to optimize the conditional input of diffusion models. In this workshop paper, we demonstrate that such optimization breaks the equivalence between denoising score matching and exact score matching. Furthermore, we show that this bias leads to higher score norm. Additionally, we observe a similar bias when optimizing the data distribution using a pre-trained diffusion model. Finally, we discuss the wide range of works across different domains that are affected by this bias, including MAR for auto-regressive generation, PerCo for image compression, and DreamFusion for text to 3D generation.

</details>


### [632] [Physics-Informed Neural ODEs with Scale-Aware Residuals for Learning Stiff Biophysical Dynamics](https://arxiv.org/abs/2511.11734)
*Kamalpreet Singh Kainth,Prathamesh Dinesh Joshi,Raj Abhijit Dandekar,Rajat Dandekar,Sreedat Panat*

Main category: cs.LG

TL;DR: 提出了PI-NODE-SR框架，结合低阶显式求解器与残差归一化，有效提升神经微分方程在刚性生物系统建模中的稳定性与预测精度。


<details>
  <summary>Details</summary>
Motivation: 标准Neural ODE和物理信息神经网络在处理刚性生物系统时训练不稳定、收敛差，难以保持振荡频率和幅值。

Method: 提出PI-NODE-SR，采用Heun方法作为低阶显式求解器，并引入尺度感知的残差归一化，平衡多时间尺度变量间的贡献。

Result: 在Hodgkin-Huxley方程上，仅从一次振荡学习即可外推至100ms以上，准确捕捉频率和近似幅值，并恢复门控变量的尖锐阈下曲率等形态特征。

Conclusion: PI-NODE-SR在有限迭代预算下显著降低长时预测误差，避免使用昂贵的隐式求解器，为刚性生物动力学提供了稳定高效的神经微分方程学习路径。

Abstract: Neural differential equations offer a powerful framework for modeling continuous-time dynamics, but forecasting stiff biophysical systems remains unreliable. Standard Neural ODEs and physics informed variants often require orders of magnitude more iterations, and even then may converge to suboptimal solutions that fail to preserve oscillatory frequency or amplitude. We introduce PhysicsInformed Neural ODEs with with Scale-Aware Residuals (PI-NODE-SR), a framework that combines a low-order explicit solver (Heun method) residual normalisation to balance contributions between state variables evolving on disparate timescales. This combination stabilises training under realistic iteration budgets and avoids reliance on computationally expensive implicit solvers. On the Hodgkin-Huxley equations, PI-NODE-SR learns from a single oscillation simulated with a stiff solver (Rodas5P) and extrapolates beyond 100 ms, capturing both oscillation frequency and near-correct amplitudes. Remarkably, end-to-end learning of the vector field enables PI-NODE-SR to recover morphological features such as sharp subthreshold curvature in gating variables that are typically reserved for higher-order solvers, suggesting that neural correction can offset numerical diffusion. While performance remains sensitive to initialisation, PI-NODE-SR consistently reduces long-horizon errors relative to baseline Neural-ODEs and PINNs, offering a principled route to stable and efficient learning of stiff biological dynamics.

</details>


### [633] [KAN/H: Kolmogorov-Arnold Network using Haar-like bases](https://arxiv.org/abs/2511.11736)
*Susumu Katayama*

Main category: cs.LG

TL;DR: 提出了一种基于Haar变体基系统的Kolmogorov-Arnold网络变体KAN/H，用于函数逼近和MNIST任务，减少了对问题特定超参数调优的需求。


<details>
  <summary>Details</summary>
Motivation: 为了减少传统KAN在函数逼近中对大量超参数调优的依赖，探索使用具有全局和局部基函数的Haar变体基系统作为替代。

Method: 采用Haar变体基系统替代B样条基，构建新的KAN变体KAN/H，并应用于函数逼近问题和MNIST分类任务。

Result: KAN/H在函数逼近和MNIST上表现良好，且无需大多数问题特定的超参数调优。

Conclusion: KAN/H通过引入Haar变体基系统，在保持性能的同时显著降低了对超参数调优的需求，提升了模型的通用性和实用性。

Abstract: This paper proposes KAN/H, a variant of Kolmogorov-Arnold Network (KAN) that uses a Haar-variant basis system having both global and local bases instead of B-spline. The resulting algorithm is applied to function approximation problems and MNIST. We show that it does not require most of the problem-specific hyper-parameter tunings.

</details>


### [634] [DK-Root: A Joint Data-and-Knowledge-Driven Framework for Root Cause Analysis of QoE Degradations in Mobile Networks](https://arxiv.org/abs/2511.11737)
*Qizhe Li,Haolong Chen,Jiansheng Li,Shuqi Chai,Xuan Li,Yuzhou Hou,Xinhua Shao,Fangfang Li,Kaifeng Han,Guangxu Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种名为DK-Root的联合数据与知识驱动框架，用于在移动网络中进行QoE降级的根因分析，结合弱监督与专家标注，通过对比学习和条件扩散模型生成增强数据，显著提升了分类精度。


<details>
  <summary>Details</summary>
Motivation: 由于移动网络中KPI之间存在复杂的跨层交互，且缺乏可靠的专家标注，导致基于纯数据驱动的方法难以准确诊断QoE下降的根本原因。规则启发式方法虽可大规模生成标签，但噪声大、粒度粗，限制了性能。

Method: DK-Root首先利用规则生成的标签通过监督对比学习对编码器进行预训练并去噪；然后引入类条件扩散模型生成保持根因语义的KPI序列，并控制反向扩散步骤产生强弱增强数据；最后使用少量专家验证标签对编码器和轻量分类器进行联合微调。

Result: 在真实运营商数据集上的实验表明，DK-Root在准确性上优于传统机器学习和最新的半监督时间序列方法，达到SOTA水平。消融实验证实了条件扩散增强和预训练-微调设计的有效性。

Conclusion: DK-Root有效融合了大规模弱监督信号与稀缺专家知识，通过去噪对比学习与语义保持的数据增强，实现了鲁棒的根因定位，为实际网络运维提供了高精度、可扩展的解决方案。

Abstract: Diagnosing the root causes of Quality of Experience (QoE) degradations in operational mobile networks is challenging due to complex cross-layer interactions among kernel performance indicators (KPIs) and the scarcity of reliable expert annotations. Although rule-based heuristics can generate labels at scale, they are noisy and coarse-grained, limiting the accuracy of purely data-driven approaches. To address this, we propose DK-Root, a joint data-and-knowledge-driven framework that unifies scalable weak supervision with precise expert guidance for robust root-cause analysis. DK-Root first pretrains an encoder via contrastive representation learning using abundant rule-based labels while explicitly denoising their noise through a supervised contrastive objective. To supply task-faithful data augmentation, we introduce a class-conditional diffusion model that generates KPIs sequences preserving root-cause semantics, and by controlling reverse diffusion steps, it produces weak and strong augmentations that improve intra-class compactness and inter-class separability. Finally, the encoder and the lightweight classifier are jointly fine-tuned with scarce expert-verified labels to sharpen decision boundaries. Extensive experiments on a real-world, operator-grade dataset demonstrate state-of-the-art accuracy, with DK-Root surpassing traditional ML and recent semi-supervised time-series methods. Ablations confirm the necessity of the conditional diffusion augmentation and the pretrain-finetune design, validating both representation quality and classification gains.

</details>


### [635] [Uncertainty Makes It Stable: Curiosity-Driven Quantized Mixture-of-Experts](https://arxiv.org/abs/2511.11743)
*Sebastián Andrés Cajas Ordóñez,Luis Fernando Torres Torres,Mackenzie J. Meni,Carlos Andrés Duran Paredes,Eric Arazo,Cristian Bosch,Ricardo Simon Carbajo,Yuan Lai,Leo Anthony Celi*

Main category: cs.LG

TL;DR: 提出一种基于好奇心驱动的量化Mixture-of-Experts框架，利用贝叶斯认知不确定性进行异构专家路由，在保持高精度的同时显著降低推理延迟方差，实现高效、稳定的边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 在资源受限设备上部署深度神经网络面临两个关键挑战：在激进量化下保持准确性，以及确保可预测的推理延迟。现有方法往往在精度、效率或稳定性之间难以平衡，尤其在边缘计算场景中对能耗和延迟敏感的应用需求迫切。

Method: 采用基于贝叶斯认知不确定性的路由机制（好奇心驱动），在异构专家（如BitNet三值、1-16位BitLinear、后训练量化）之间动态分配输入；使用信息论路由策略实现自适应量化；在音频分类任务上评估4位量化与MoE结构的性能。

Result: 在ESC-50、Quinn、UrbanSound8K等音频分类基准上，4位量化保持了99.9%的16位精度（F1: 0.858 vs 0.859），模型压缩4倍，能耗降低41%；好奇心路由将MoE推理延迟方差减少82%（标准差从230ms降至29ms，p=0.008）；统计分析显示4位/8位与全精度模型具有实际等效性（p>0.05），但MoE带来11%延迟开销（p<0.001）且无精度提升；大规模部署时推理碳排放是训练的10000倍。

Conclusion: 所提框架在准确率、能效和延迟可预测性之间取得了良好平衡，适用于电池供电的边缘设备；尽管简单4位架构在多数场景优于复杂MoE，但该工作验证了自适应量化与不确定性感知路由在边缘智能中的潜力。

Abstract: Deploying deep neural networks on resource-constrained devices faces two critical challenges: maintaining accuracy under aggressive quantization while ensuring predictable inference latency. We present a curiosity-driven quantized Mixture-of-Experts framework that addresses both through Bayesian epistemic uncertainty-based routing across heterogeneous experts (BitNet ternary, 1-16 bit BitLinear, post-training quantization). Evaluated on audio classification benchmarks (ESC-50, Quinn, UrbanSound8K), our 4-bit quantization maintains 99.9 percent of 16-bit accuracy (0.858 vs 0.859 F1) with 4x compression and 41 percent energy savings versus 8-bit. Crucially, curiosity-driven routing reduces MoE latency variance by 82 percent (p = 0.008, Levene's test) from 230 ms to 29 ms standard deviation, enabling stable inference for battery-constrained devices. Statistical analysis confirms 4-bit/8-bit achieve practical equivalence with full precision (p > 0.05), while MoE architectures introduce 11 percent latency overhead (p < 0.001) without accuracy gains. At scale, deployment emissions dominate training by 10000x for models serving more than 1,000 inferences, making inference efficiency critical. Our information-theoretic routing demonstrates that adaptive quantization yields accurate (0.858 F1, 1.2M params), energy-efficient (3.87 F1/mJ), and predictable edge models, with simple 4-bit quantized architectures outperforming complex MoE for most deployments.

</details>


### [636] [Diffusion Models: A Mathematical Introduction](https://arxiv.org/abs/2511.11746)
*Sepehr Maleki,Negar Pourmoazemi*

Main category: cs.LG

TL;DR: 本文从高斯分布的基本性质出发，系统推导了基于扩散的生成模型，涵盖了前向加噪、反向去噪、变分下界及其简化形式，并讨论了似然估计、加速采样方法（如DDIM、DDGAN）和多尺度变体（如Stable Diffusion），还介绍了连续时间下的概率流ODE与引导扩散机制。


<details>
  <summary>Details</summary>
Motivation: 旨在以简洁、自包含的方式，从第一性原理出发构建扩散生成模型，提升理论透明度并便于实际实现。

Method: 基于高斯分布的密度、二次期望、重参数化、乘积性质和KL散度等基础性质，逐步推导出扩散模型的各个组成部分，包括前向过程、闭式边缘分布、精确的离散反向后验和变分下界，并扩展到连续时间公式和引导生成方法。

Result: 成功构建了完整的去噪扩散概率模型，推导出实践中常用噪声预测目标的理论基础，统一了DDIM、概率流ODE、流匹配和整流流等方法，并对分类器引导和无分类器引导提供了统一解释。

Conclusion: 通过清晰的代数推导和一致的符号体系，本文为扩散模型提供了易于理解且可直接实现的理论框架，有助于研究者深入掌握其原理并应用于实践。

Abstract: We present a concise, self-contained derivation of diffusion-based generative models. Starting from basic properties of Gaussian distributions (densities, quadratic expectations, re-parameterisation, products, and KL divergences), we construct denoising diffusion probabilistic models from first principles. This includes the forward noising process, its closed-form marginals, the exact discrete reverse posterior, and the related variational bound. This bound simplifies to the standard noise-prediction goal used in practice. We then discuss likelihood estimation and accelerated sampling, covering DDIM, adversarially learned reverse dynamics (DDGAN), and multi-scale variants such as nested and latent diffusion, with Stable Diffusion as a canonical example. A continuous-time formulation follows, in which we derive the probability-flow ODE from the diffusion SDE via the continuity and Fokker-Planck equations, introduce flow matching, and show how rectified flows recover DDIM up to a time re-parameterisation. Finally, we treat guided diffusion, interpreting classifier guidance as a posterior score correction and classifier-free guidance as a principled interpolation between conditional and unconditional scores. Throughout, the focus is on transparent algebra, explicit intermediate steps, and consistent notation, so that readers can both follow the theory and implement the corresponding algorithms in practice.

</details>


### [637] [IDOL: Meeting Diverse Distribution Shifts with Prior Physics for Tropical Cyclone Multi-Task Estimation](https://arxiv.org/abs/2511.11750)
*Hanting Yan,Pan Mu,Shiqi Zhang,Yuchao Zhu,Jinglin Zhang,Cong Bai*

Main category: cs.LG

TL;DR: 提出了一种基于物理不变性的身份分布导向学习框架（IDOL），利用先验物理知识建模特征空间，有效应对热带气旋估计中的分布偏移问题，在多个数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态融合中忽视特征表示的内在分布，导致在分布外场景下泛化能力差，难以应对由地理和季节变化引起的分布偏移。

Method: 提出IDOL框架，引入身份导向约束，结合风场模型和暗相关知识，构建任务共享和任务特定的身份令牌，以捕捉任务依赖性和物理不变性。

Result: 在多个数据集和任务上实验表明，IDOL在风速、气压及内外核尺寸估计等任务中优于现有方法，显著提升了在分布偏移下的鲁棒性和泛化能力。

Conclusion: 通过引入基于物理知识的身份约束，IDOL能有效缓解热带气旋估计中的分布偏移问题，提升模型在复杂环境下的可靠性与稳定性。

Abstract: Tropical Cyclone (TC) estimation aims to accurately estimate various TC attributes in real time. However, distribution shifts arising from the complex and dynamic nature of TC environmental fields, such as varying geographical conditions and seasonal changes, present significant challenges to reliable estimation. Most existing methods rely on multi-modal fusion for feature extraction but overlook the intrinsic distribution of feature representations, leading to poor generalization under out-of-distribution (OOD) scenarios. To address this, we propose an effective Identity Distribution-Oriented Physical Invariant Learning framework (IDOL), which imposes identity-oriented constraints to regulate the feature space under the guidance of prior physical knowledge, thereby dealing distribution variability with physical invariance. Specifically, the proposed IDOL employs the wind field model and dark correlation knowledge of TC to model task-shared and task-specific identity tokens. These tokens capture task dependencies and intrinsic physical invariances of TC, enabling robust estimation of TC wind speed, pressure, inner-core, and outer-core size under distribution shifts. Extensive experiments conducted on multiple datasets and tasks demonstrate the outperformance of the proposed IDOL, verifying that imposing identity-oriented constraints based on prior physical knowledge can effectively mitigates diverse distribution shifts in TC estimation.Code is available at https://github.com/Zjut-MultimediaPlus/IDOL.

</details>


### [638] [Improving a Hybrid Graphsage Deep Network for Automatic Multi-objective Logistics Management in Supply Chain](https://arxiv.org/abs/2511.11753)
*Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar*

Main category: cs.LG

TL;DR: 本文提出了一种基于混合GraphSAGE网络（H-GSN）的多任务学习方法，用于预测供应链中的运输类型、物流延迟和交通状态，显著提升了物流管理的效率与可持续性。


<details>
  <summary>Details</summary>
Motivation: 为了提升供应链的韧性与可持续性，需要有效管理物流运输并减少空气污染，现有方法在多任务预测方面仍存在不足。

Method: 提出一种混合GraphSAGE网络（H-GSN），用于同时预测运输类型、物流延迟、交通状态、物流ID等多目标任务，并在Kaggle上的三个供应链物流数据集（DataCo、Shipping、Smart Logistics）上进行验证。

Result: 在Smart Logistics数据集中，物流ID和交通状态预测的平均准确率分别达到97.8%和100%；在DataCo和Shipping数据集中，运输类型和物流延迟预测的准确率分别为98.7%和99.4%，验证了方法的有效性。

Conclusion: 所提出的H-GSN模型在多任务物流预测中表现出色，有助于提升供应链的韧性、协作效率和环境可持续性。

Abstract: Systematic logistics, conveyance amenities and facilities as well as warehousing information play a key role in fostering profitable development in a supply chain. The aim of transformation in industries is the improvement of the resiliency regarding the supply chain. The resiliency policies are required for companies to affect the collaboration with logistics service providers positively. The decrement of air pollutant emissions is a persistent advantage of the efficient management of logistics and transportation in supply chain. The management of shipment type is a significant factor in analyzing the sustainability of logistics and supply chain. An automatic approach to predict the shipment type, logistics delay and traffic status are required to improve the efficiency of the supply chain management. A hybrid graphsage network (H-GSN) is proposed in this paper for multi-task purpose of logistics management in a supply chain. The shipment type, shipment status, traffic status, logistics ID and logistics delay are the objectives in this article regarding three different databases including DataCo, Shipping and Smart Logistcis available on Kaggle as supply chain logistics databases. The average accuracy of 97.8% and 100% are acquired for 10 kinds of logistics ID and 3 types of traffic status prediction in Smart Logistics dataset. The average accuracy of 98.7% and 99.4% are obtained for shipment type prediction in DataCo and logistics delay in Shipping database, respectively. The evaluation metrics for different logistics scenarios confirm the efficiency of the proposed method to improve the resilience and sustainability of the supply chain.

</details>


### [639] [Sumudu Neural Operator for ODEs and PDEs](https://arxiv.org/abs/2511.11762)
*Ben Zelenskiy,Saibilila Abudukelimu,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.LG

TL;DR: 提出了基于Sumudu变换的Sumudu神经算子（SNO），在多种ODE和PDE任务中表现优异，尤其在Euler-Bernoulli梁和扩散方程上误差最低，并展示了零样本超分辨率能力。


<details>
  <summary>Details</summary>
Motivation: 探索Sumudu变换在神经算子设计中的潜力，以提升对特定类型微分方程的建模能力。

Method: 利用Sumudu变换对的多项式展开关系，将输入空间分解为系数并映射到Sumudu空间，在该空间中参数化神经算子。

Result: SNO在多个PDE任务上优于FNO，与LNO相比具有竞争力，并在Euler-Bernoulli Beam和Diffusion Equation上取得最低误差；同时实现了零样本超分辨率。

Conclusion: Sumudu变换在神经算子设计中展现出潜力，尤其适用于某些类型的偏微分方程求解。

Abstract: We introduce the Sumudu Neural Operator (SNO), a neural operator rooted in the properties of the Sumudu Transform. We leverage the relationship between the polynomial expansions of transform pairs to decompose the input space as coefficients, which are then transformed into the Sumudu Space, where the neural operator is parameterized. We evaluate the operator in ODEs (Duffing Oscillator, Lorenz System, and Driven Pendulum) and PDEs (Euler-Bernoulli Beam, Burger's Equation, Diffusion, Diffusion-Reaction, and Brusselator). SNO achieves superior performance to FNO on PDEs and demonstrates competitive accuracy with LNO on several PDE tasks, including the lowest error on the Euler-Bernoulli Beam and Diffusion Equation. Additionally, we apply zero-shot super-resolution to the PDE tasks to observe the model's capability of obtaining higher quality data from low-quality samples. These preliminary findings suggest promise for the Sumudu Transform as a neural operator design, particularly for certain classes of PDEs.

</details>


### [640] [Learning Fair Representations with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.11767)
*Amisha Priyadarshini,Sergio Gago-Masague*

Main category: cs.LG

TL;DR: 本文提出了一种基于Kolmogorov-Arnold网络（KANs）的公平对抗学习框架，用于缓解机器学习在高校招生等高风险决策中的歧视问题。该方法结合KANs的可解释性与对抗训练的鲁棒性，并引入自适应惩罚机制动态调整公平性约束，在保持高预测精度的同时实现了良好的公平性。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习模型在准确性和公平性之间的权衡仍具挑战，且黑箱模型缺乏可解释性，限制了其在敏感场景中的应用。本文旨在构建一个兼具公平性、准确性与可解释性的模型。

Method: 将Kolmogorov-Arnold Networks（KANs）引入公平对抗学习框架，利用其结构优势提升模型可解释性；设计一种自适应惩罚更新机制，动态调整训练过程中的公平性约束，以优化公平与准确性的平衡。

Result: 在两个真实高校招生数据集上，采用三种优化策略进行实验，结果显示所提方法在多个指标上优于基线模型，既能保持高预测准确率，又在敏感属性上实现具有竞争力的公平性表现。

Conclusion: KANs在公平机器学习中展现出高效性与鲁棒性，结合自适应机制可有效平衡公平与准确性，同时提升模型可解释性，适用于社会敏感领域的决策支持系统。

Abstract: Despite recent advances in fairness-aware machine learning, predictive models often exhibit discriminatory behavior towards marginalized groups. Such unfairness might arise from biased training data, model design, or representational disparities across groups, posing significant challenges in high-stakes decision-making domains such as college admissions. While existing fair learning models aim to mitigate bias, achieving an optimal trade-off between fairness and accuracy remains a challenge. Moreover, the reliance on black-box models hinders interpretability, limiting their applicability in socially sensitive domains. In this paper, we try to circumvent these issues by integrating Kolmogorov-Arnold Networks (KANs) within a fair adversarial learning framework. Leveraging the adversarial robustness and interpretability of KANs, our approach enables a balance between fairness and accuracy. To further facilitate this balance, we propose an adaptive penalty update mechanism that dynamically adjusts fairness constraints during the model training. We conduct numerical experiments on two real-world college admissions datasets, across three different optimization strategies. The results demonstrate the efficiency and robustness of KANs by consistently outperforming the baseline fair learning models, and maintaining high predictive accuracy while achieving competitive fairness across sensitive attributes.

</details>


### [641] [CATCHFed: Efficient Unlabeled Data Utilization for Semi-Supervised Federated Learning in Limited Labels Environments](https://arxiv.org/abs/2511.11778)
*Byoungjun Park,Pedro Porto Buarque de Gusmão,Dongjin Ji,Minhoe Kim*

Main category: cs.LG

TL;DR: 提出CATCHFed方法，通过客户端感知的自适应阈值、混合阈值和一致性正则化，在标签数据极少的情况下提升半监督联邦学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法多假设客户端拥有标注数据，但在现实中客户端标签常缺失；仅服务器端有标签的半监督联邦学习在标签数量减少时性能显著下降。

Method: 提出CATCHFed，引入考虑类别难度的客户端感知自适应阈值、混合阈值以提高伪标签质量，并利用未伪标记数据进行一致性正则化。

Result: 在多个数据集和配置下的实验表明，CATCHFed能有效利用客户端无标签数据，在极低标签情况下仍实现优越性能。

Conclusion: CATCHFed在极端少标签场景下显著优于现有半监督联邦学习方法，提升了模型鲁棒性和实用性。

Abstract: Federated learning is a promising paradigm that utilizes distributed client resources while preserving data privacy. Most existing FL approaches assume clients possess labeled data, however, in real-world scenarios, client-side labels are often unavailable. Semi-supervised Federated learning, where only the server holds labeled data, addresses this issue. However, it experiences significant performance degradation as the number of labeled data decreases. To tackle this problem, we propose \textit{CATCHFed}, which introduces client-aware adaptive thresholds considering class difficulty, hybrid thresholds to enhance pseudo-label quality, and utilizes unpseudo-labeled data for consistency regularization. Extensive experiments across various datasets and configurations demonstrate that CATCHFed effectively leverages unlabeled client data, achieving superior performance even in extremely limited-label settings.

</details>


### [642] [Coordinate Descent for Network Linearization](https://arxiv.org/abs/2511.11781)
*Vlad Rakhlin,Amir Jevnisek,Shai Avidan*

Main category: cs.LG

TL;DR: 提出一种基于坐标下降的离散优化方法，直接在离散域减少ReLU数量，显著提升私有推理中ResNet网络的效率。


<details>
  <summary>Details</summary>
Motivation: ReLU激活函数在基于ResNet的私有推理中导致高延迟，减少其数量是关键但具有挑战性的离散优化问题。

Method: 采用坐标下降框架，在离散域直接优化ReLU数量，避免平滑近似和阈值化带来的性能损失。

Result: 实验表明该方法在常见基准上达到最先进的性能，且能自然产生稀疏解。

Conclusion: 所提方法优于现有技术，为私有推理中的ReLU优化提供了更有效、更直接的解决方案。

Abstract: ReLU activations are the main bottleneck in Private Inference that is based on ResNet networks. This is because they incur significant inference latency. Reducing ReLU count is a discrete optimization problem, and there are two common ways to approach it. Most current state-of-the-art methods are based on a smooth approximation that jointly optimizes network accuracy and ReLU budget at once. However, the last hard thresholding step of the optimization usually introduces a large performance loss. We take an alternative approach that works directly in the discrete domain by leveraging Coordinate Descent as our optimization framework. In contrast to previous methods, this yields a sparse solution by design. We demonstrate, through extensive experiments, that our method is State of the Art on common benchmarks.

</details>


### [643] [Simplicial covering dimension of extremal concept classes](https://arxiv.org/abs/2511.11819)
*Ari Blondal,Hamed Hatami,Pooya Hatami,Chavdar Lalov,Sivan Tretiak*

Main category: cs.LG

TL;DR: 本文将拓扑学中的维数理论引入二元概念类，定义了单纯覆盖维数，并证明其与PAC学习中的列表可复制数完全等价。


<details>
  <summary>Details</summary>
Motivation: 将经典拓扑维数概念应用于机器学习中的概念类，以更好地理解学习稳定性。

Method: 通过在概念类的可实现分布空间上构建单纯结构，定义单纯覆盖维数，并建立其与列表可复制数的关系。

Result: 证明了有限概念类的单纯覆盖维数恰好刻画了其在PAC学习中的列表可复制数。

Conclusion: 该工作建立了拓扑维数与学习稳定性的精确对应，为分析极值概念类提供了新工具。

Abstract: Dimension theory is a branch of topology concerned with defining and analyzing dimensions of geometric and topological spaces in purely topological terms. In this work, we adapt the classical notion of topological dimension (Lebesgue covering) to binary concept classes. The topological space naturally associated with a concept class is its space of realizable distributions. The loss function and the class itself induce a simplicial structure on this space, with respect to which we define a simplicial covering dimension.
  We prove that for finite concept classes, this simplicial covering dimension exactly characterizes the list replicability number (equivalently, global stability) in PAC learning. This connection allows us to apply tools from classical dimension theory to compute the exact list replicability number of the broad family of extremal concept classes.

</details>


### [644] [Conformal Constrained Policy Optimization for Cost-Effective LLM Agents](https://arxiv.org/abs/2511.11828)
*Wenwen Si,Sooyong Jang,Insup Lee,Osbert Bastani*

Main category: cs.LG

TL;DR: 提出了一种基于共形预测约束的策略（CCPO），通过多模型协同与强化学习优化大语言模型的调用成本，在保证可靠性的同时显著降低使用成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在取得进展的同时带来了高昂的计算和API成本，亟需一种在保证可靠性前提下降低成本的方法。

Method: 结合多个具有不同成本/准确率权衡的LLM，采用代理式编排机制，利用共形预测形式化可靠性约束，并提出CCPO训练范式，融合约束策略优化、离策略强化学习和在线共形预测技术，联合优化成本感知策略与自适应阈值。

Result: 在两个多跳问答基准上，相比其他成本感知基线和LLM引导方法，CCPO实现了最高达30%的成本降低，同时保持了可靠性。

Conclusion: 该方法为部署高效且可靠的LLM代理提供了一个有理论依据且实用的框架。

Abstract: While large language models (LLMs) have recently made tremendous progress towards solving challenging AI problems, they have done so at increasingly steep computational and API costs. We propose a novel strategy where we combine multiple LLM models with varying cost/accuracy tradeoffs in an agentic manner, where models and tools are run in sequence as determined by an orchestration model to minimize cost subject to a user-specified level of reliability; this constraint is formalized using conformal prediction to provide guarantees. To solve this problem, we propose Conformal Constrained Policy Optimization (CCPO), a training paradigm that integrates constrained policy optimization with off-policy reinforcement learning and recent advances in online conformal prediction. CCPO jointly optimizes a cost-aware policy (score function) and an adaptive threshold. Across two multi-hop question answering benchmarks, CCPO achieves up to a 30% cost reduction compared to other cost-aware baselines and LLM-guided methods without compromising reliability. Our approach provides a principled and practical framework for deploying LLM agents that are significantly more cost-effective while maintaining reliability.

</details>


### [645] [Volatility in Certainty (VC): A Metric for Detecting Adversarial Perturbations During Inference in Neural Network Classifiers](https://arxiv.org/abs/2511.11834)
*Vahid Hemmati,Ahmad Mohammadi,Abdul-Rauf Nuhu,Reza Ahmari,Parham Kebria,Abdollah Homaifar*

Main category: cs.LG

TL;DR: 本文研究了一种名为“确定性波动”（Volatility in Certainty, VC）的无标签指标，用于衡量神经网络在面对对抗性攻击时的鲁棒性。VC通过分析softmax输出的局部波动来反映模型性能下降，在多种模型和数据集上表现出与分类准确率的高度负相关，可作为实时、无需真实标签的性能监控工具。


<details>
  <summary>Details</summary>
Motivation: 在实际部署中，神经网络常面临对抗性样本导致的性能下降问题，而传统评估方法依赖真实标签，难以在实时系统中应用。因此，需要一种无需标签、能实时检测模型性能退化的指标。

Method: 提出并使用VC指标，即对排序后的softmax输出计算相邻值的对数平方比的平均值，以量化模型置信度的波动。在MNIST和CIFAR-10数据集上，结合FGSM生成的不同强度对抗样本及混合测试集，评估VC与分类准确率的相关性。

Result: 实验显示，log(VC)与分类准确率之间存在强负相关（rho < -0.90），且该现象在不同模型结构和数据集中具有一致性。VC能敏感地检测到对抗性污染引起的分布偏移。

Conclusion: VC是一种可扩展、与架构无关且适用于实时系统的无标签性能监控指标，有望用于安全关键场景中的早期预警系统。

Abstract: Adversarial robustness remains a critical challenge in deploying neural network classifiers, particularly in real-time systems where ground-truth labels are unavailable during inference. This paper investigates \textit{Volatility in Certainty} (VC), a recently proposed, label-free metric that quantifies irregularities in model confidence by measuring the dispersion of sorted softmax outputs. Specifically, VC is defined as the average squared log-ratio of adjacent certainty values, capturing local fluctuations in model output smoothness. We evaluate VC as a proxy for classification accuracy and as an indicator of adversarial drift. Experiments are conducted on artificial neural networks (ANNs) and convolutional neural networks (CNNs) trained on MNIST, as well as a regularized VGG-like model trained on CIFAR-10. Adversarial examples are generated using the Fast Gradient Sign Method (FGSM) across varying perturbation magnitudes. In addition, mixed test sets are created by gradually introducing adversarial contamination to assess VC's sensitivity under incremental distribution shifts. Our results reveal a strong negative correlation between classification accuracy and log(VC) (correlation rho < -0.90 in most cases), suggesting that VC effectively reflects performance degradation without requiring labeled data. These findings position VC as a scalable, architecture-agnostic, and real-time performance metric suitable for early-warning systems in safety-critical applications.

</details>


### [646] [On the Trade-Off Between Transparency and Security in Adversarial Machine Learning](https://arxiv.org/abs/2511.11842)
*Lucas Fenaux,Christopher Srinivasa,Florian Kerschbaum*

Main category: cs.LG

TL;DR: 研究探讨了在对抗性设置中透明度与安全性的权衡，发现攻击者在了解防御方策略时更具优势，表明AI系统的透明度可能损害其安全性。


<details>
  <summary>Details</summary>
Motivation: 在负责任的人工智能中，透明度和安全性都很重要，但在对抗性环境中可能存在冲突，需要探究透明度对安全的影响。

Method: 通过可迁移对抗样本攻击的视角，进行大规模实证评估（九种攻击、181个模型），并使用博弈论建模（Nash博弈和Stackelberg博弈）分析透明度与安全的权衡。

Result: 发现当攻击者与防御者的决策一致时攻击更成功，仅知道防御模型是否被保护就可能损害其安全性。

Conclusion: 透明度在某些情况下会削弱AI系统的安全性，揭示了透明度与安全之间的普遍权衡，建议在设计AI系统时需谨慎平衡二者。

Abstract: Transparency and security are both central to Responsible AI, but they may conflict in adversarial settings. We investigate the strategic effect of transparency for agents through the lens of transferable adversarial example attacks. In transferable adversarial example attacks, attackers maliciously perturb their inputs using surrogate models to fool a defender's target model. These models can be defended or undefended, with both players having to decide which to use. Using a large-scale empirical evaluation of nine attacks across 181 models, we find that attackers are more successful when they match the defender's decision; hence, obscurity could be beneficial to the defender. With game theory, we analyze this trade-off between transparency and security by modeling this problem as both a Nash game and a Stackelberg game, and comparing the expected outcomes. Our analysis confirms that only knowing whether a defender's model is defended or not can sometimes be enough to damage its security. This result serves as an indicator of the general trade-off between transparency and security, suggesting that transparency in AI systems can be at odds with security. Beyond adversarial machine learning, our work illustrates how game-theoretic reasoning can uncover conflicts between transparency and security.

</details>


### [647] [Leveraging Exogenous Signals for Hydrology Time Series Forecasting](https://arxiv.org/abs/2511.11849)
*Junyang He,Judy Fox,Alireza Jafari,Ying-Jung Chen,Geoffrey Fox*

Main category: cs.LG

TL;DR: 本研究探讨了在水文降雨-径流建模中融入领域知识对时间序列模型性能的影响，发现包含更多已知外生输入（尤其是自然年周期性信号）的模型优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 尽管已有许多先进的时间序列基础模型，但在物理科学具体应用中的有效性尚不清楚，因此需要评估结合领域知识的模型在水文建模中的表现。

Method: 使用CAMELS-US数据集，比较了基线模型与基础模型在671个站点上的降雨-径流预测性能，重点分析不同外生变量（包括六种时间序列和30种静态特征）的影响。

Result: 包含全面外生输入的模型表现优于仅依赖有限输入的基础模型，其中引入自然年周期性时间序列带来的性能提升最为显著。

Conclusion: 在特定物理科学任务中，融入领域知识（如周期性气候模式）比单纯依赖大规模预训练基础模型更能提升预测准确性。

Abstract: Recent advances in time series research facilitate the development of foundation models. While many state-of-the-art time series foundation models have been introduced, few studies examine their effectiveness in specific downstream applications in physical science. This work investigates the role of integrating domain knowledge into time series models for hydrological rainfall-runoff modeling. Using the CAMELS-US dataset, which includes rainfall and runoff data from 671 locations with six time series streams and 30 static features, we compare baseline and foundation models. Results demonstrate that models incorporating comprehensive known exogenous inputs outperform more limited approaches, including foundation models. Notably, incorporating natural annual periodic time series contribute the most significant improvements.

</details>


### [648] [Transformers vs. Recurrent Models for Estimating Forest Gross Primary Production](https://arxiv.org/abs/2511.11880)
*David Montero,Miguel D. Mahecha,Francesco Martinuzzi,César Aybar,Anne Klosterhalfen,Alexander Knohl,Jesús Anaya,Clemens Mosig,Sebastian Wieneke*

Main category: cs.LG

TL;DR: 本研究比较了基于深度学习的GPT-2和LSTM模型在多模态输入下预测森林CO₂吸收（GPP）的表现，发现LSTM整体更优且所需时间窗口更短，而GPT-2在极端事件中表现更好。


<details>
  <summary>Details</summary>
Motivation: 监测森林GPP的时空动态对陆地生态系统研究至关重要，但现有方法受限于空间覆盖或模型能力，亟需更优的深度学习模型来捕捉复杂的植被动态。

Method: 采用GPT-2（Transformer架构）和LSTM（循环神经网络）两种深度学习模型，利用多源遥感与气象数据进行GPP预测，并分析模型性能、时间窗口长度及特征重要性。

Result: LSTM整体精度更高且使用更短的时间输入窗口即可达到相似性能，GPT-2在极端事件期间表现更佳；辐射是最重要的预测因子，其次是Sentinel-2、MODIS地表温度和Sentinel-1数据。

Conclusion: 模型架构、输入时间长度和多模态数据共同影响GPP预测性能，LSTM在效率与准确性之间更具优势，而GPT-2适用于极端事件建模，研究为未来陆地碳动态监测提供了模型选择依据。

Abstract: Monitoring the spatiotemporal dynamics of forest CO$_2$ uptake (Gross Primary Production, GPP), remains a central challenge in terrestrial ecosystem research. While Eddy Covariance (EC) towers provide high-frequency estimates, their limited spatial coverage constrains large-scale assessments. Remote sensing offers a scalable alternative, yet most approaches rely on single-sensor spectral indices and statistical models that are often unable to capture the complex temporal dynamics of GPP. Recent advances in deep learning (DL) and data fusion offer new opportunities to better represent the temporal dynamics of vegetation processes, but comparative evaluations of state-of-the-art DL models for multimodal GPP prediction remain scarce. Here, we explore the performance of two representative models for predicting GPP: 1) GPT-2, a transformer architecture, and 2) Long Short-Term Memory (LSTM), a recurrent neural network, using multivariate inputs. Overall, both achieve similar accuracy. But, while LSTM performs better overall, GPT-2 excels during extreme events. Analysis of temporal context length further reveals that LSTM attains similar accuracy using substantially shorter input windows than GPT-2, highlighting an accuracy-efficiency trade-off between the two architectures. Feature importance analysis reveals radiation as the dominant predictor, followed by Sentinel-2, MODIS land surface temperature, and Sentinel-1 contributions. Our results demonstrate how model architecture, context length, and multimodal inputs jointly determine performance in GPP prediction, guiding future developments of DL frameworks for monitoring terrestrial carbon dynamics.

</details>


### [649] [Better LLM Reasoning via Dual-Play](https://arxiv.org/abs/2511.11881)
*Zhengxin Zhang,Chengyu Huang,Aochong Oliver Li,Claire Cardie*

Main category: cs.LG

TL;DR: 本文提出了PasoDoble，一种用于大语言模型的双人对抗训练框架，通过提案者和解题者的相互竞争提升模型推理能力，无需外部监督。


<details>
  <summary>Details</summary>
Motivation: 减少大语言模型对人工标注等外部监督的依赖，解决现有对抗训练方法在应用到大语言模型时面临的奖励黑客和训练不稳定问题。

Method: 设计了一个名为PasoDoble的双模型对抗框架：一个提案者生成具有真实答案的难题，一个解题者尝试解答；利用预训练数据增强提案者知识以保证问题质量与多样性；通过联合更新机制和可选的离线范式提高训练稳定性。

Result: 实验结果表明，PasoDoble能够在无监督训练的情况下有效提升大语言模型的推理性能。

Conclusion: PasoDoble为大语言模型提供了一种可行的自监督对抗训练方案，减少了对外部标签的依赖，并展示了双角色持续竞争对模型性能提升的有效性。

Abstract: Large Language Models (LLMs) have achieved remarkable progress through Reinforcement Learning with Verifiable Rewards (RLVR), yet still rely heavily on external supervision (e.g., curated labels). Adversarial learning, particularly through self-play, offers a promising alternative that enables models to iteratively learn from themselves - thus reducing reliance on external supervision. Dual-play extends adversarial learning by assigning specialized roles to two models and training them against each other, fostering sustained competition and mutual evolution. Despite its promise, adapting dual-play training to LLMs remains limited, largely due to their susceptibility to reward hacking and training instability. In this paper, we introduce PasoDoble, a novel LLM dual-play framework. PasoDoble adversarially trains two models initialized from the same base model: a Proposer, which generates challenging questions with ground-truth answers, and a Solver, which attempts to solve them. We enrich the Proposer with knowledge from a pre-training dataset to ensure the questions' quality and diversity. To avoid reward hacking, the Proposer is rewarded for producing only valid questions that push the Solver's limit, while the Solver is rewarded for solving them correctly, and both are updated jointly. To further enhance training stability, we introduce an optional offline paradigm that decouples Proposer and Solver updates, alternately updating each for several steps while holding the other fixed. Notably, PasoDoble operates without supervision during training. Experimental results show that PasoDoble can improve the reasoning performance of LLMs. Our project page is available at https://hcy123902.github.io/PasoDoble.

</details>


### [650] [FLEX: Feature Importance from Layered Counterfactual Explanations](https://arxiv.org/abs/2511.11891)
*Nawid Keshtmand,Roussel Desmond Nzoyem,Jeffrey Nicholas Clark*

Main category: cs.LG

TL;DR: 本文提出了FLEX，一种模型和领域无关的框架，通过聚合局部反事实解释生成局部、区域和全局层面的特征重要性评分，弥补了局部反事实与全局归因之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有的反事实解释多为实例特定，缺乏对特征在数据集或特征空间中系统性影响的量化，限制了其在高风险场景中的可解释性和实用性。

Method: 提出FLEX框架，将多个反事实解释转化为特征变化频率得分，支持局部、区域和全局分析，并兼容多种反事实生成方法，允许用户根据稀疏性、可行性或可操作性调整特征重要性计算。

Result: 在交通事故严重性和贷款审批两个任务上验证了FLEX的有效性，结果显示其全局排名与SHAP相关，但能发现更多驱动因素；区域分析揭示了全局方法忽略的情境特异性特征。

Conclusion: FLEX成功连接了局部反事实解释与全局特征归因，提供了更具透明度和干预导向的决策支持，适用于风险敏感的应用场景。

Abstract: Machine learning models achieve state-of-the-art performance across domains, yet their lack of interpretability limits safe deployment in high-stakes settings. Counterfactual explanations are widely used to provide actionable "what-if" recourse, but they typically remain instance-specific and do not quantify which features systematically drive outcome changes within coherent regions of the feature space or across an entire dataset. We introduce FLEX (Feature importance from Layered counterfactual EXplanations), a model- and domain-agnostic framework that converts sets of counterfactuals into feature change frequency scores at local, regional, and global levels. FLEX generalises local change-frequency measures by aggregating across instances and neighbourhoods, offering interpretable rankings that reflect how often each feature must change to flip predictions. The framework is compatible with different counterfactual generation methods, allowing users to emphasise characteristics such as sparsity, feasibility, or actionability, thereby tailoring the derived feature importances to practical constraints. We evaluate FLEX on two contrasting tabular tasks: traffic accident severity prediction and loan approval, and compare FLEX to SHAP- and LIME-derived feature importance values. Results show that (i) FLEX's global rankings correlate with SHAP while surfacing additional drivers, and (ii) regional analyses reveal context-specific factors that global summaries miss. FLEX thus bridges the gap between local recourse and global attribution, supporting transparent and intervention-oriented decision-making in risk-sensitive applications.

</details>


### [651] [Chain-of-Generation: Progressive Latent Diffusion for Text-Guided Molecular Design](https://arxiv.org/abs/2511.11894)
*Lingxiao Li,Haobo Zhang,Bin Chen,Jiayu Zhou*

Main category: cs.LG

TL;DR: 提出Chain-of-Generation (CoG)，一种无需训练的多阶段潜在扩散框架，通过将文本提示分解为语义片段并逐步生成分子结构，提升文本到分子生成的语义对齐、可控性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于一次编码条件生成的方法难以满足复杂语言描述中的多重化学结构需求，存在生成结果不可控、部分子结构遗漏和语义对齐差等问题。

Method: 提出CoG框架，将自然语言提示分解为课程式语义段，分阶段引导潜在扩散过程，并引入后对齐学习增强文本与分子潜在空间的对应关系。

Result: 在基准和真实任务上实验表明，CoG相比单次条件模型具有更高的语义对齐度、多样性和可控性，能更准确地生成符合复杂提示的分子结构。

Conclusion: CoG通过多阶段语义引导显著提升了文本到分子生成的质量与可解释性，为复杂化学设计需求提供了有效解决方案。

Abstract: Text-conditioned molecular generation aims to translate natural-language descriptions into chemical structures, enabling scientists to specify functional groups, scaffolds, and physicochemical constraints without handcrafted rules. Diffusion-based models, particularly latent diffusion models (LDMs), have recently shown promise by performing stochastic search in a continuous latent space that compactly captures molecular semantics. Yet existing methods rely on one-shot conditioning, where the entire prompt is encoded once and applied throughout diffusion, making it hard to satisfy all the requirements in the prompt. We discuss three outstanding challenges of one-shot conditioning generation, including the poor interpretability of the generated components, the failure to generate all substructures, and the overambition in considering all requirements simultaneously. We then propose three principles to address those challenges, motivated by which we propose Chain-of-Generation (CoG), a training-free multi-stage latent diffusion framework. CoG decomposes each prompt into curriculum-ordered semantic segments and progressively incorporates them as intermediate goals, guiding the denoising trajectory toward molecules that satisfy increasingly rich linguistic constraints. To reinforce semantic guidance, we further introduce a post-alignment learning phase that strengthens the correspondence between textual and molecular latent spaces. Extensive experiments on benchmark and real-world tasks demonstrate that CoG yields higher semantic alignment, diversity, and controllability than one-shot baselines, producing molecules that more faithfully reflect complex, compositional prompts while offering transparent insight into the generation process.

</details>


### [652] [Robust Bidirectional Associative Memory via Regularization Inspired by the Subspace Rotation Algorithm](https://arxiv.org/abs/2511.11902)
*Ci Lin,Tet Yeap,Iluju Kiringa,Biwei Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的梯度无关训练算法B-SRA，并通过正交权重矩阵和梯度模式对齐两种正则化策略显著提升了双向联想记忆（BAM）的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: BAM在使用双向反向传播训练时对噪声和对抗攻击敏感，鲁棒性差，亟需改进。

Method: 提出了B-SRA算法，并引入正交权重矩阵（OWM）和梯度模式对齐（GPA）作为正则化策略；通过消融实验比较不同训练策略。

Result: B-SRA和结合OWM与GPA的SAME配置在多种攻击场景和记忆容量下均表现出最强的抗干扰能力与鲁棒性。

Conclusion: 所提方法显著增强了BAM的鲁棒性和收敛性，为构建抗干扰神经网络提供了新方向。

Abstract: Bidirectional Associative Memory (BAM) trained with Bidirectional Backpropagation (B-BP) often suffers from poor robustness and high sensitivity to noise and adversarial attacks. To address these issues, we propose a novel gradient-free training algorithm, the Bidirectional Subspace Rotation Algorithm (B-SRA), which significantly improves the robustness and convergence behavior of BAM. Through comprehensive experiments, we identify two key principles -- orthogonal weight matrices (OWM) and gradient-pattern alignment (GPA) -- as central to enhancing the robustness of BAM. Motivated by these findings, we introduce new regularization strategies into B-BP, resulting in models with greatly improved resistance to corruption and adversarial perturbations. We further conduct an ablation study across different training strategies to determine the most robust configuration and evaluate BAM's performance under a variety of attack scenarios and memory capacities, including 50, 100, and 200 associative pairs. Among all methods, the SAME configuration, which integrates both OWM and GPA, achieves the strongest resilience. Overall, our results demonstrate that B-SRA and the proposed regularization strategies lead to substantially more robust associative memories and open new directions for building resilient neural architectures.

</details>


### [653] [A Systematic Study of Model Extraction Attacks on Graph Foundation Models](https://arxiv.org/abs/2511.11912)
*Haoyan Xu,Ruizhi Qian,Jiate Li,Yushun Dong,Minghao Lin,Hanson Yan,Zhengtao Yao,Qinghua Liu,Junhao Dong,Ruopeng Huang,Yue Zhao,Mengyuan Li*

Main category: cs.LG

TL;DR: 本文首次系统研究了针对图基础模型（GFMs）的模型提取攻击（MEAs），提出了六种实际攻击场景，并设计了一种轻量级提取方法，在低训练成本下成功逼近受害者模型，揭示了GFMs面临的安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着图基础模型（GFMs）在跨领域应用中的重要性提升，其高昂的预训练成本和丰富的知识使其成为攻击目标，但现有研究未充分探讨GFMs的安全隐患，尤其是模型提取攻击的威胁。

Method: 提出一个黑盒威胁模型，定义六种实用攻击场景；设计一种无需对比预训练数据的轻量级提取方法，通过监督回归学习图嵌入，使攻击者编码器与受害者文本编码器保持对齐。

Result: 在七个数据集上的实验表明，攻击者仅需极小查询预算和训练成本即可高度近似受害者模型，且几乎不损失准确率，成功保留零样本推理能力。

Conclusion: GFMs显著扩大了模型提取攻击的攻击面，亟需在大规模图学习系统中引入部署感知的安全防御机制。

Abstract: Graph machine learning has advanced rapidly in tasks such as link prediction, anomaly detection, and node classification. As models scale up, pretrained graph models have become valuable intellectual assets because they encode extensive computation and domain expertise. Building on these advances, Graph Foundation Models (GFMs) mark a major step forward by jointly pretraining graph and text encoders on massive and diverse data. This unifies structural and semantic understanding, enables zero-shot inference, and supports applications such as fraud detection and biomedical analysis. However, the high pretraining cost and broad cross-domain knowledge in GFMs also make them attractive targets for model extraction attacks (MEAs). Prior work has focused only on small graph neural networks trained on a single graph, leaving the security implications for large-scale and multimodal GFMs largely unexplored. This paper presents the first systematic study of MEAs against GFMs. We formalize a black-box threat model and define six practical attack scenarios covering domain-level and graph-specific extraction goals, architectural mismatch, limited query budgets, partial node access, and training data discrepancies. To instantiate these attacks, we introduce a lightweight extraction method that trains an attacker encoder using supervised regression of graph embeddings. Even without contrastive pretraining data, this method learns an encoder that stays aligned with the victim text encoder and preserves its zero-shot inference ability on unseen graphs. Experiments on seven datasets show that the attacker can approximate the victim model using only a tiny fraction of its original training cost, with almost no loss in accuracy. These findings reveal that GFMs greatly expand the MEA surface and highlight the need for deployment-aware security defenses in large-scale graph learning systems.

</details>


### [654] [Batch Matrix-form Equations and Implementation of Multilayer Perceptrons](https://arxiv.org/abs/2511.11918)
*Wieger Wesselink,Bram Grooten,Huub van de Wetering,Qiao Xiao,Decebal Constantin Mocanu*

Main category: cs.LG

TL;DR: 本文提供了多层感知机（MLP）在批量矩阵形式下的完整、显式算法描述，填补了现有文献的空白，并通过符号验证和多种编程语言的统一实现，支持透明化分析与高效稀疏计算。


<details>
  <summary>Details</summary>
Motivation: 尽管自动微分广泛使用，但显式的批量矩阵形式能更清晰地揭示计算结构，对稀疏神经网络等场景下的系统分析和优化至关重要，而现有文献缺乏完整的公式表达。

Method: 推导了包括批归一化和softmax在内的标准及高级层的前向和反向传播方程，使用SymPy进行符号验证，并基于统一的矩阵原语构建了NumPy、PyTorch、JAX、TensorFlow及高性能C++的参考实现。

Result: 实现了MLP批量矩阵形式的完整反向传播推导，所有梯度方程均经符号验证，提供了跨平台统一实现，并展示了显式公式在稀疏计算中的高效性。

Conclusion: 该工作为理解、教学和研究神经网络算法提供了经过验证且可扩展的基础框架。

Abstract: Multilayer perceptrons (MLPs) remain fundamental to modern deep learning, yet their algorithmic details are rarely presented in complete, explicit \emph{batch matrix-form}. Rather, most references express gradients per sample or rely on automatic differentiation. Although automatic differentiation can achieve equally high computational efficiency, the usage of batch matrix-form makes the computational structure explicit, which is essential for transparent, systematic analysis, and optimization in settings such as sparse neural networks. This paper fills that gap by providing a mathematically rigorous and implementation-ready specification of MLPs in batch matrix-form. We derive forward and backward equations for all standard and advanced layers, including batch normalization and softmax, and validate all equations using the symbolic mathematics library SymPy. From these specifications, we construct uniform reference implementations in NumPy, PyTorch, JAX, TensorFlow, and a high-performance C++ backend optimized for sparse operations. Our main contributions are: (1) a complete derivation of batch matrix-form backpropagation for MLPs, (2) symbolic validation of all gradient equations, (3) uniform Python and C++ reference implementations grounded in a small set of matrix primitives, and (4) demonstration of how explicit formulations enable efficient sparse computation. Together, these results establish a validated, extensible foundation for understanding, teaching, and researching neural network algorithms.

</details>


### [655] [Beyond the Laplacian: Interpolated Spectral Augmentation for Graph Neural Networks](https://arxiv.org/abs/2511.11928)
*Ziyao Cui,Edric Tam*

Main category: cs.LG

TL;DR: 提出了一种基于插值拉普拉斯矩阵的图嵌入方法（ILEs），用于增强图神经网络在节点特征有限时的性能。


<details>
  <summary>Details</summary>
Motivation: 当实际数据集中节点特征有限或缺失时，如何利用图谱信息增强GNN的表示能力。

Method: 引入插值拉普拉斯嵌入（ILEs），基于一组可表达的图矩阵，结合谱图理论分析其捕捉的结构信息。

Result: 在模拟和真实数据集上的实验表明，ILE特征增强能提升多种GNN架构的性能。

Conclusion: ILEs为节点特征受限的场景提供了一种简单有效的谱嵌入增强方法，扩展了谱增强工具箱。

Abstract: Graph neural networks (GNNs) are fundamental tools in graph machine learning. The performance of GNNs relies crucially on the availability of informative node features, which can be limited or absent in real-life datasets and applications. A natural remedy is to augment the node features with embeddings computed from eigenvectors of the graph Laplacian matrix. While it is natural to default to Laplacian spectral embeddings, which capture meaningful graph connectivity information, we ask whether spectral embeddings from alternative graph matrices can also provide useful representations for learning. We introduce Interpolated Laplacian Embeddings (ILEs), which are derived from a simple yet expressive family of graph matrices. Using tools from spectral graph theory, we offer a straightforward interpretation of the structural information that ILEs capture. We demonstrate through simulations and experiments on real-world datasets that feature augmentation via ILEs can improve performance across commonly used GNN architectures. Our work offers a straightforward and practical approach that broadens the practitioner's spectral augmentation toolkit when node features are limited.

</details>


### [656] [A Systematic Analysis of Out-of-Distribution Detection Under Representation and Training Paradigm Shifts](https://arxiv.org/abs/2511.11934)
*C. César Claros Olivares,Austin J. Brockmeier*

Main category: cs.LG

TL;DR: 本文系统比较了不同表示范式下（CNN与ViT）的分布外（OOD）检测方法，发现特征空间学习对OOD性能起决定性作用，并提出基于统计检验的方法选择建议。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法在不同模型和数据集上的表现缺乏系统性比较，尤其在CLIP分层环境下，需要更可靠的评估框架来指导方法选择。

Method: 采用AURC和AUGRC作为主要指标，在CIFAR-10/100、SuperCIFAR-100和TinyImageNet上评估从头训练的CNN和微调ViT；使用Friedman检验结合Conover-Holm事后检验的秩基管道，并利用Bron-Kerbosch算法识别显著性能 clique。

Result: 发现学习到的特征空间主导OOD效果；概率型分数（如MSR、GEN）在ID错误检测中表现最佳；在强分布偏移下，CNN上几何感知分数（如NNGuide、fDBD、CTM）更优，而ViT上GradNorm和KPCA重建误差持续具有竞争力；MCD存在类别数依赖的权衡，PCA投影可提升多种检测器性能。

Conclusion: 支持以表示为中心的OOD检测观，强调应根据模型架构和分布偏移强度选择合适检测方法，并提供统计上可靠的选择指南。

Abstract: We present a systematic comparison of out-of-distribution (OOD) detection methods across CLIP-stratified regimes using AURC and AUGRC as primary metrics. Experiments cover two representation paradigms: CNNs trained from scratch and a fine-tuned Vision Transformer (ViT), evaluated on CIFAR-10/100, SuperCIFAR-100, and TinyImageNet. Using a multiple-comparison-controlled, rank-based pipeline (Friedman test with Conover-Holm post-hoc) and Bron-Kerbosch cliques, we find that the learned feature space largely determines OOD efficacy. For both CNNs and ViTs, probabilistic scores (e.g., MSR, GEN) dominate misclassification (ID) detection. Under stronger shifts, geometry-aware scores (e.g., NNGuide, fDBD, CTM) prevail on CNNs, whereas on ViTs GradNorm and KPCA Reconstruction Error remain consistently competitive. We further show a class-count-dependent trade-off for Monte-Carlo Dropout (MCD) and that a simple PCA projection improves several detectors. These results support a representation-centric view of OOD detection and provide statistically grounded guidance for method selection under distribution shift.

</details>


### [657] [SurvBench: A Standardised Preprocessing Pipeline for Multi-Modal Electronic Health Record Survival Analysis](https://arxiv.org/abs/2511.11935)
*Munib Mesinovic,Tingting Zhu*

Main category: cs.LG

TL;DR: SurvBench是一个开源的、标准化的预处理管道，用于将原始EHR数据转换为适用于多模态生存分析的模型就绪张量，支持MIMIC-IV、eICU和MC-MED数据库，提升深度学习模型在生存分析中的可重复性与公平比较。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）数据在生存分析中具有巨大潜力，但不一致的预处理方法严重限制了研究的可重复性，阻碍了深度学习模型之间的公平比较。

Method: 开发了一个名为SurvBench的开源预处理管道，统一处理来自PhysioNet的原始数据，支持多种数据模态（如时间序列生命体征、静态人口统计、ICD诊断码和放射报告），实施严格的数据质量控制、患者级数据划分、缺失值追踪和标准化时间聚合，并兼容单风险与竞争风险场景。

Result: SurvBench生成标准化张量输出，兼容pycox库及多种统计和深度学习模型，实现了可配置、可复现的预处理流程，并提供完整文档，显著降低数据工程负担。

Conclusion: SurvBench有效填补了生存分析中深度学习研究的‘预处理鸿沟’，促进了方法创新与跨研究的公平比较。

Abstract: Electronic health record (EHR) data present tremendous opportunities for advancing survival analysis through deep learning, yet reproducibility remains severely constrained by inconsistent preprocessing methodologies. We present SurvBench, a comprehensive, open-source preprocessing pipeline that transforms raw PhysioNet datasets into standardised, model-ready tensors for multi-modal survival analysis. SurvBench provides data loaders for three major critical care databases, MIMIC-IV, eICU, and MC-MED, supporting diverse modalities including time-series vitals, static demographics, ICD diagnosis codes, and radiology reports. The pipeline implements rigorous data quality controls, patient-level splitting to prevent data leakage, explicit missingness tracking, and standardised temporal aggregation. SurvBench handles both single-risk (e.g., in-hospital mortality) and competing-risks scenarios (e.g., multiple discharge outcomes). The outputs are compatible with pycox library packages and implementations of standard statistical and deep learning models. By providing reproducible, configuration-driven preprocessing with comprehensive documentation, SurvBench addresses the "preprocessing gap" that has hindered fair comparison of deep learning survival models, enabling researchers to focus on methodological innovation rather than data engineering.

</details>


### [658] [Learning the relative composition of EEG signals using pairwise relative shift pretraining](https://arxiv.org/abs/2511.11940)
*Christopher Sandino,Sayeri Lala,Geeling Chau,Melika Ayoughi,Behrooz Mahasseni,Ellen Zippi,Ali Moin,Erdrin Azemi,Hanlin Goh*

Main category: cs.LG

TL;DR: 本文提出了一种名为PARS的新型自监督学习方法，用于从无标签脑电图（EEG）数据中学习表征，通过预测随机采样EEG窗口对之间的相对时间偏移，捕捉神经信号中的长程依赖关系，在多种EEG解码任务中优于现有的预训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有的EEG自监督学习方法主要依赖掩码重建策略，难以有效建模长程依赖关系，而位置预测尚未被充分探索，因此需要一种能更好捕捉神经信号中长期时序结构的新预训练范式。

Method: 提出PARS（PAirwise Relative Shift）预训练任务，通过预测两段随机采样的EEG时间窗之间的相对时间偏移作为代理任务，使模型学习到时间相对关系和长距离依赖。

Result: 在多个EEG解码任务中评估表明，采用PARS预训练的Transformer模型在少标签和迁移学习场景下 consistently 优于现有的预训练方法。

Conclusion: PARS为自监督EEG表征学习提供了一种新范式，能够更有效地捕捉神经信号的长程依赖，提升了下游任务的性能。

Abstract: Self-supervised learning (SSL) offers a promising approach for learning electroencephalography (EEG) representations from unlabeled data, reducing the need for expensive annotations for clinical applications like sleep staging and seizure detection. While current EEG SSL methods predominantly use masked reconstruction strategies like masked autoencoders (MAE) that capture local temporal patterns, position prediction pretraining remains underexplored despite its potential to learn long-range dependencies in neural signals. We introduce PAirwise Relative Shift or PARS pretraining, a novel pretext task that predicts relative temporal shifts between randomly sampled EEG window pairs. Unlike reconstruction-based methods that focus on local pattern recovery, PARS encourages encoders to capture relative temporal composition and long-range dependencies inherent in neural signals. Through comprehensive evaluation on various EEG decoding tasks, we demonstrate that PARS-pretrained transformers consistently outperform existing pretraining strategies in label-efficient and transfer learning settings, establishing a new paradigm for self-supervised EEG representation learning.

</details>


### [659] [Computation-aware Energy-harvesting Federated Learning: Cyclic Scheduling with Selective Participation](https://arxiv.org/abs/2511.11949)
*Eunjeong Jeong,Nikolaos Pappas*

Main category: cs.LG

TL;DR: 提出了一种基于电池水平的循环客户端参与框架FedBacys及其节能变体FedBacys-Odd，用于能量收集型联邦学习系统，有效降低能耗并提升学习稳定性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在能量收集设备上的应用面临客户端因能量限制导致参与不稳定的问题，现有方法难以平衡能耗与模型性能。

Method: 通过根据客户端电池水平进行聚类和循环调度，提出FedBacys框架，并设计选择性参与的FedBacys-Odd变体以进一步节能。同时提供收敛性分析。

Result: 实验表明，所提方法相比现有算法在能量效率和鲁棒性方面表现更优，显著减少系统能耗且不牺牲学习性能。

Conclusion: FedBacys及其变体能有效管理能量受限设备的参与策略，为能量收集型联邦学习提供了高效、稳定的解决方案。

Abstract: Federated Learning (FL) is a powerful paradigm for distributed learning, but its increasing complexity leads to significant energy consumption from client-side computations for training models. In particular, the challenge is critical in energy-harvesting FL (EHFL) systems where participation availability of each device oscillates due to limited energy. To address this, we propose FedBacys, a battery-aware EHFL framework using cyclic client participation based on users' battery levels. By clustering clients and scheduling them sequentially, FedBacys minimizes redundant computations, reduces system-wide energy usage, and improves learning stability. We also introduce FedBacys-Odd, a more energy-efficient variant that allows clients to participate selectively, further reducing energy costs without compromising performance. We provide a convergence analysis for our framework and demonstrate its superior energy efficiency and robustness compared to existing algorithms through numerical experiments.

</details>


### [660] [Quantile Q-Learning: Revisiting Offline Extreme Q-Learning with Quantile Regression](https://arxiv.org/abs/2511.11973)
*Xinming Gao,Shangzhe Li,Yujin Cai,Wenwu Yu*

Main category: cs.LG

TL;DR: 提出了一种基于分位数回归的温度系数β估计方法和一种值正则化技术，以解决XQL和MXQL在离线强化学习中的超参数敏感性和训练不稳定性问题，在多个基准任务上表现出色且训练稳定。


<details>
  <summary>Details</summary>
Motivation: XQL和MXQL在离线强化学习中存在严重的超参数调优需求和训练不稳定性，限制了其实际应用。

Method: 通过分位数回归在温和假设下原则性地估计温度系数β，并引入受约束值学习启发的轻度泛化的值正则化技术以提升训练稳定性。

Result: 所提算法在D4RL和NeoRL2等多个基准任务上实现了具有竞争力或更优的性能，训练过程稳定，且在所有数据集和领域中使用一致的超参数设置。

Conclusion: 该方法有效解决了XQL/MXQL的超参数敏感性和训练不稳定问题，提升了离线强化学习的鲁棒性和实用性。

Abstract: Offline reinforcement learning (RL) enables policy learning from fixed datasets without further environment interaction, making it particularly valuable in high-risk or costly domains. Extreme $Q$-Learning (XQL) is a recent offline RL method that models Bellman errors using the Extreme Value Theorem, yielding strong empirical performance. However, XQL and its stabilized variant MXQL suffer from notable limitations: both require extensive hyperparameter tuning specific to each dataset and domain, and also exhibit instability during training. To address these issues, we proposed a principled method to estimate the temperature coefficient $β$ via quantile regression under mild assumptions. To further improve training stability, we introduce a value regularization technique with mild generalization, inspired by recent advances in constrained value learning. Experimental results demonstrate that the proposed algorithm achieves competitive or superior performance across a range of benchmark tasks, including D4RL and NeoRL2, while maintaining stable training dynamics and using a consistent set of hyperparameters across all datasets and domains.

</details>


### [661] [ReCast: Reliability-aware Codebook Assisted Lightweight Time Series Forecasting](https://arxiv.org/abs/2511.11991)
*Xiang Ma,Taihua Chen,Pengcheng Wang,Xuemei Li,Caiming Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于可学习码本的轻量级时间序列预测框架ReCast，通过量化局部模式并结合双路径结构实现高效且鲁棒的预测。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖全局分解，难以处理现实世界中以局部、复杂、动态模式为主的时间序列，且模型复杂度高，限制了其在实时或资源受限场景的应用。

Method: ReCast采用分块量化将局部模式编码为离散嵌入，并设计双路径架构：量化路径捕捉规律性结构，残差路径重建不规则波动；引入可靠性感知的码本更新策略，通过分布鲁棒优化融合多源可靠性因子进行加权修正。

Result: 实验表明，ReCast在预测精度、计算效率和对分布偏移的适应性方面均优于当前最先进模型。

Conclusion: ReCast通过码本量化与可靠性感知更新机制，有效平衡了模型轻量化与预测鲁棒性，适用于复杂动态时间序列的实时预测场景。

Abstract: Time series forecasting is crucial for applications in various domains. Conventional methods often rely on global decomposition into trend, seasonal, and residual components, which become ineffective for real-world series dominated by local, complex, and highly dynamic patterns. Moreover, the high model complexity of such approaches limits their applicability in real-time or resource-constrained environments. In this work, we propose a novel \textbf{RE}liability-aware \textbf{C}odebook-\textbf{AS}sisted \textbf{T}ime series forecasting framework (\textbf{ReCast}) that enables lightweight and robust prediction by exploiting recurring local shapes. ReCast encodes local patterns into discrete embeddings through patch-wise quantization using a learnable codebook, thereby compactly capturing stable regular structures. To compensate for residual variations not preserved by quantization, ReCast employs a dual-path architecture comprising a quantization path for efficient modeling of regular structures and a residual path for reconstructing irregular fluctuations. A central contribution of ReCast is a reliability-aware codebook update strategy, which incrementally refines the codebook via weighted corrections. These correction weights are derived by fusing multiple reliability factors from complementary perspectives by a distributionally robust optimization (DRO) scheme, ensuring adaptability to non-stationarity and robustness to distribution shifts. Extensive experiments demonstrate that ReCast outperforms state-of-the-art (SOTA) models in accuracy, efficiency, and adaptability to distribution shifts.

</details>


### [662] [Selecting Fine-Tuning Examples by Quizzing VLMs](https://arxiv.org/abs/2511.12002)
*Tenghao Ji,Eytan Adar*

Main category: cs.LG

TL;DR: 提出QZLoRA框架，利用QuizRank自动评估和筛选图像用于LoRA微调，提升文本到图像生成模型在特定主题上的表现。


<details>
  <summary>Details</summary>
Motivation: 在微调文本到图像扩散模型时，选择高质量、能代表目标概念的训练图像是关键挑战，低质量或不相关的图像会导致生成效果差。

Method: 提出QZLoRA框架，结合QuizRank方法，将图像视为‘教育干预’，通过视觉语言模型（VLM）对其进行‘测验’来打分和排序，从而筛选出最能体现目标概念的图像用于低秩适应（LoRA）微调。

Result: QZLoRA能在更少样本下生成更对齐、更逼真的图像，并可推广到风格化图像（如插图）的生成，且生成结果更具代表性。

Conclusion: 结合自动化视觉推理与参数高效微调（如LoRA）能有效提升主题自适应生成模型的性能，展示了其在图像生成中的潜力。

Abstract: A challenge in fine-tuning text-to-image diffusion models for specific topics is to select good examples. Fine-tuning from image sets of varying quality, such as Wikipedia Commons, will often produce poor output. However, training images that \textit{do} exemplify the target concept (e.g., a \textit{female Mountain Bluebird}) help ensure that the generated images are similarly representative (e.g., have the prototypical blue-wings and gray chest). In this work, we propose QZLoRA, a framework to select images for low-rank adaptation (LoRA). The approach leverages QuizRank, a method to automatically rank images by treating them as an `educational intervention' and `quizzing' a VLM. We demonstrate that QZLoRA can produce better aligned, photorealistic images with fewer samples. We also show that these fine-tuned models can produce stylized that are similarly representative (i.e., illustrations). Our results highlight the promise of combining automated visual reasoning with parameter-efficient fine-tuning for topic-adaptive generative modeling.

</details>


### [663] [Computational Measurement of Political Positions: A Review of Text-Based Ideal Point Estimation Algorithms](https://arxiv.org/abs/2511.13238)
*Patrick Parschan,Charlott Jakob*

Main category: cs.LG

TL;DR: 本文首次系统回顾了基于文本的无监督和半监督理想点估计（CT-IPE）算法，提出了一个区分算法如何生成、捕捉和聚合文本变异性的概念框架，并将25种算法分为四类：词频、主题模型、词嵌入和基于大语言模型的方法，为应用研究者提供了方法选择的实践指导。


<details>
  <summary>Details</summary>
Motivation: 近年来CT-IPE算法发展迅速但分散，缺乏系统性比较和应用指导，亟需整合与评估以支持跨学科研究。

Method: 通过系统文献综述识别出25种CT-IPE算法，采用手动内容分析其建模假设与发展背景，并提出一个概念框架来分类和比较不同方法。

Result: 识别出四类方法家族，揭示各类方法在可解释性、可扩展性和技术要求方面的权衡，发现不同算法结果差异本身具有信息价值。

Conclusion: 研究为CT-IPE领域提供了结构化综述与分类框架，强调系统性基准测试的重要性，并为研究者选择合适算法提供了实践指引。

Abstract: This article presents the first systematic review of unsupervised and semi-supervised computational text-based ideal point estimation (CT-IPE) algorithms, methods designed to infer latent political positions from textual data. These algorithms are widely used in political science, communication, computational social science, and computer science to estimate ideological preferences from parliamentary speeches, party manifestos, and social media. Over the past two decades, their development has closely followed broader NLP trends -- beginning with word-frequency models and most recently turning to large language models (LLMs). While this trajectory has greatly expanded the methodological toolkit, it has also produced a fragmented field that lacks systematic comparison and clear guidance for applied use. To address this gap, we identified 25 CT-IPE algorithms through a systematic literature review and conducted a manual content analysis of their modeling assumptions and development contexts. To compare them meaningfully, we introduce a conceptual framework that distinguishes how algorithms generate, capture, and aggregate textual variance. On this basis, we identify four methodological families -- word-frequency, topic modeling, word embedding, and LLM-based approaches -- and critically assess their assumptions, interpretability, scalability, and limitations. Our review offers three contributions. First, it provides a structured synthesis of two decades of algorithm development, clarifying how diverse methods relate to one another. Second, it translates these insights into practical guidance for applied researchers, highlighting trade-offs in transparency, technical requirements, and validation strategies that shape algorithm choice. Third, it emphasizes that differences in estimation outcomes across algorithms are themselves informative, underscoring the need for systematic benchmarking.

</details>


### [664] [EARL: Entropy-Aware RL Alignment of LLMs for Reliable RTL Code Generation](https://arxiv.org/abs/2511.12033)
*Jiahe Shi,Zhengqi Gao,Ching-Yun Ko,Duane Boning*

Main category: cs.LG

TL;DR: 本文提出了一种面向Verilog代码生成的熵感知强化学习框架EARL，通过可验证奖励信号和仅对高熵令牌进行选择性更新，提升了RTL代码生成的功能正确性和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在RTL硬件设计自动化中仍存在语法错误、功能幻觉和与设计意图对齐不足的问题，且传统强化学习在长序列代码生成中因梯度分散导致学习信号稀疏。

Method: 提出EARL框架，基于熵分析识别对控制流和模块结构影响大的高熵令牌（如always, if等），在强化学习中引入熵引导的选择性更新机制，仅对这些关键令牌进行梯度更新，并利用硬件可执行性提供可验证奖励信号。

Result: 在VerilogEval和RTLLM数据集上的实验表明，EARL相比先前的LLM基线方法功能通过率最高提升14.7%，同时减少了不必要的参数更新并提高了训练稳定性。

Conclusion: 聚焦于高不确定性关键令牌的强化学习策略能更有效地改善结构化RTL代码生成的可靠性和对齐性，为大模型在硬件设计中的应用提供了更高效的学习范式。

Abstract: Recent advances in large language models (LLMs) have demonstrated significant potential in hardware design automation, particularly in using natural language to synthesize Register-Transfer Level (RTL) code. Despite this progress, a gap remains between model capability and the demands of real-world RTL design, including syntax errors, functional hallucinations, and weak alignment to designer intent. Reinforcement Learning with Verifiable Rewards (RLVR) offers a promising approach to bridge this gap, as hardware provides executable and formally checkable signals that can be used to further align model outputs with design intent. However, in long, structured RTL code sequences, not all tokens contribute equally to functional correctness, and naïvely spreading gradients across all tokens dilutes learning signals. A key insight from our entropy analysis in RTL generation is that only a small fraction of tokens (e.g., always, if, assign, posedge) exhibit high uncertainty and largely influence control flow and module structure. To address these challenges, we present EARL, an Entropy-Aware Reinforcement Learning framework for Verilog generation. EARL performs policy optimization using verifiable reward signals and introduces entropy-guided selective updates that gate policy gradients to high-entropy tokens. This approach preserves training stability and concentrates gradient updates on functionally important regions of code. Our experiments on VerilogEval and RTLLM show that EARL improves functional pass rates over prior LLM baselines by up to 14.7%, while reducing unnecessary updates and improving training stability. These results indicate that focusing RL on critical, high-uncertainty tokens enables more reliable and targeted policy improvement for structured RTL code generation.

</details>


### [665] [Mesh-based Super-resolution of Detonation Flows with Multiscale Graph Transformers](https://arxiv.org/abs/2511.12041)
*Shivam Barwey,Pinaki Pal*

Main category: cs.LG

TL;DR: 提出了一种基于图变换器的多尺度超分辨率方法（SR-GT），用于反应流场的网格化超分辨率重建，具有高精度和优于传统插值方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率技术在复杂几何和非结构化网格上表现受限，难以准确重建多尺度反应流场；需要一种能捕捉长程依赖并保持关键特征的数据驱动方法。

Method: 提出SR-GT框架，采用基于图的流场表示，结合谱元法离散网格，利用元素局部及邻域图结构作为输入，通过变换器捕捉长距离依赖关系，并生成高分辨率流场输出。

Result: 在二维爆轰传播问题中验证了SR-GT的有效性，结果显示其在反应流场特征重建上具有高精度，且显著优于传统插值方法。

Conclusion: SR-GT是一种适用于复杂反应流场的高效超分辨率建模新范式，具备处理非结构化网格和多尺度特征的能力，具有广泛的应用潜力。

Abstract: Super-resolution flow reconstruction using state-of-the-art data-driven techniques is valuable for a variety of applications, such as subgrid/subfilter closure modeling, accelerating spatiotemporal forecasting, data compression, and serving as an upscaling tool for sparse experimental measurements. In the present work, a first-of-its-kind multiscale graph transformer approach is developed for mesh-based super-resolution (SR-GT) of reacting flows. The novel data-driven modeling paradigm leverages a graph-based flow-field representation compatible with complex geometries and non-uniform/unstructured grids. Further, the transformer backbone captures long-range dependencies between different parts of the low-resolution flow-field, identifies important features, and then generates the super-resolved flow-field that preserves those features at a higher resolution. The performance of SR-GT is demonstrated in the context of spectral-element-discretized meshes for a challenging test problem of 2D detonation propagation within a premixed hydrogen-air mixture exhibiting highly complex multiscale reacting flow behavior. The SR-GT framework utilizes a unique element-local (+ neighborhood) graph representation for the coarse input, which is then tokenized before being processed by the transformer component to produce the fine output. It is demonstrated that SR-GT provides high super-resolution accuracy for reacting flow-field features and superior performance compared to traditional interpolation-based SR schemes.

</details>


### [666] [Improving Graph Embeddings in Machine Learning Using Knowledge Completion with Validation in a Case Study on COVID-19 Spread](https://arxiv.org/abs/2511.12071)
*Rosario Napoli,Gabriele Morabito,Antonio Celesti,Massimo Villari,Maria Fazio*

Main category: cs.LG

TL;DR: 提出了一种结合知识补全（KC）的图机器学习（GML）流程，通过建模隐含的传递关系来重塑图结构，从而显著改变图嵌入空间的几何特性，提升图表示质量。


<details>
  <summary>Details</summary>
Motivation: 现有图嵌入方法依赖显式图结构和特征，可能忽略数据中隐藏的隐性知识，导致表示不完整，尤其是在稀疏知识图谱中。

Method: 在图嵌入前引入知识补全阶段，针对传递性关系设计基于衰减的推理函数，推断潜在语义并重构图拓扑结构，进而影响GraphSAGE和Node2Vec等模型的嵌入动态与聚合过程。

Result: 实验表明，该方法显著改变了嵌入空间的几何结构，有效揭示了隐含语义，提升了图表示能力。

Conclusion: 知识补全不仅是对图数据的简单增强，而是一种能够重构图表示、提升图嵌入质量的关键预处理步骤。

Abstract: The rise of graph-structured data has driven major advances in Graph Machine Learning (GML), where graph embeddings (GEs) map features from Knowledge Graphs (KGs) into vector spaces, enabling tasks like node classification and link prediction. However, since GEs are derived from explicit topology and features, they may miss crucial implicit knowledge hidden in seemingly sparse datasets, affecting graph structure and their representation. We propose a GML pipeline that integrates a Knowledge Completion (KC) phase to uncover latent dataset semantics before embedding generation. Focusing on transitive relations, we model hidden connections with decay-based inference functions, reshaping graph topology, with consequences on embedding dynamics and aggregation processes in GraphSAGE and Node2Vec. Experiments show that our GML pipeline significantly alters the embedding space geometry, demonstrating that its introduction is not just a simple enrichment but a transformative step that redefines graph representation quality.

</details>


### [667] [Treatment Stitching with Schrödinger Bridge for Enhancing Offline Reinforcement Learning in Adaptive Treatment Strategies](https://arxiv.org/abs/2511.12075)
*Dong-Hee Shin,Deok-Joong Lee,Young-Han Son,Tae-Eui Kam*

Main category: cs.LG

TL;DR: 提出了一种名为Treatment Stitching (TreatStitch)的新型数据增强框架，通过拼接临床治疗轨迹来增强离线强化学习在个性化治疗策略优化中的性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在临床治疗策略优化中受限于数据稀缺问题，且传统在线学习方法因风险不可接受而不适用于临床场景。

Method: TreatStitch通过识别不同治疗轨迹中相似的中间患者状态进行拼接，并利用Schrödinger bridge方法生成连接不相似状态的平滑桥接轨迹，从而合成新的有效治疗路径。

Result: 在多个治疗数据集上的实验表明，TreatStitch显著提升了离线强化学习的性能，同时理论分析证明其保持了临床有效性，避免了分布外转移。

Conclusion: TreatStitch为解决临床数据稀缺下的个性化治疗策略优化提供了有效且具理论保障的数据增强方案。

Abstract: Adaptive treatment strategies (ATS) are sequential decision-making processes that enable personalized care by dynamically adjusting treatment decisions in response to evolving patient symptoms. While reinforcement learning (RL) offers a promising approach for optimizing ATS, its conventional online trial-and-error learning mechanism is not permissible in clinical settings due to risks of harm to patients. Offline RL tackles this limitation by learning policies exclusively from historical treatment data, but its performance is often constrained by data scarcity-a pervasive challenge in clinical domains. To overcome this, we propose Treatment Stitching (TreatStitch), a novel data augmentation framework that generates clinically valid treatment trajectories by intelligently stitching segments from existing treatment data. Specifically, TreatStitch identifies similar intermediate patient states across different trajectories and stitches their respective segments. Even when intermediate states are too dissimilar to stitch directly, TreatStitch leverages the Schrödinger bridge method to generate smooth and energy-efficient bridging trajectories that connect dissimilar states. By augmenting these synthetic trajectories into the original dataset, offline RL can learn from a more diverse dataset, thereby improving its ability to optimize ATS. Extensive experiments across multiple treatment datasets demonstrate the effectiveness of TreatStitch in enhancing offline RL performance. Furthermore, we provide a theoretical justification showing that TreatStitch maintains clinical validity by avoiding out-of-distribution transitions.

</details>


### [668] [P1: Mastering Physics Olympiads with Reinforcement Learning](https://arxiv.org/abs/2511.13612)
*Jiacheng Chen,Qianjia Cheng,Fangchen Yu,Haiyuan Wan,Yuchen Zhang,Shenghe Zheng,Junchi Yao,Qingyang Zhang,Haonan He,Yun Luo,Yufeng Zhao,Futing Wang,Li Sheng,Chengxing Xie,Yuxin Zuo,Yizhuo Li,Wenxauan Zeng,Yulun Wu,Rui Huang,Dongzhan Zhou,Kai Chen,Yu Qiao,Lei Bai,Yu Cheng,Ning Ding,Bowen Zhou,Peng Ye,Ganqu Cui*

Main category: cs.LG

TL;DR: 本文介绍了P1系列开源物理推理大模型，通过强化学习训练，在国际物理奥林匹克竞赛中达到金牌水平，展现了卓越的物理推理能力，并在数学和编程等其他推理任务中表现出良好的泛化性。


<details>
  <summary>Details</summary>
Motivation: 推动大语言模型从解题向科学级推理发展，特别是在物理这一连接符号与现实的基础学科中实现突破。

Method: 采用纯强化学习方法训练P1系列模型，并结合代理框架PhysicsMinions提升推理能力。

Result: P1-235B-A22B在IPhO 2025中达到金牌水平，在13项国际和地区物理竞赛中获得12枚金牌；P1-30B-A3B获得银牌；结合PhysicsMinions后整体排名位列第一，平均分最高。模型在数学和编码任务中也表现优异。

Conclusion: P1系列模型展示了强化学习在培养科学推理能力方面的巨大潜力，是首个在国际物理竞赛中达到顶尖人类水平的开源模型，标志着AI向科学发现迈出了关键一步。

Abstract: Recent progress in large language models (LLMs) has moved the frontier from puzzle-solving to science-grade reasoning-the kind needed to tackle problems whose answers must stand against nature, not merely fit a rubric. Physics is the sharpest test of this shift, which binds symbols to reality in a fundamental way, serving as the cornerstone of most modern technologies. In this work, we manage to advance physics research by developing large language models with exceptional physics reasoning capabilities, especially excel at solving Olympiad-level physics problems. We introduce P1, a family of open-source physics reasoning models trained entirely through reinforcement learning (RL). Among them, P1-235B-A22B is the first open-source model with Gold-medal performance at the latest International Physics Olympiad (IPhO 2025), and wins 12 gold medals out of 13 international/regional physics competitions in 2024/2025. P1-30B-A3B also surpasses almost all other open-source models on IPhO 2025, getting a silver medal. Further equipped with an agentic framework PhysicsMinions, P1-235B-A22B+PhysicsMinions achieves overall No.1 on IPhO 2025, and obtains the highest average score over the 13 physics competitions. Besides physics, P1 models also present great performance on other reasoning tasks like math and coding, showing the great generalibility of P1 series.

</details>


### [669] [SenseRay-3D: Generalizable and Physics-Informed Framework for End-to-End Indoor Propagation Modeling](https://arxiv.org/abs/2511.12092)
*Yu Zheng,Kezhi Wang,Wenji Xi,Gang Yu,Jiming Chen,Jie Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种名为SenseRay-3D的通用、物理信息驱动的端到端框架，能够直接从RGB-D扫描中预测室内三维路径损耗热图，无需显式几何重建或材料标注。


<details>
  <summary>Details</summary>
Motivation: 现有室内无线传播建模方法依赖于繁琐的手动几何和材料属性建模，可扩展性和效率受限，因此需要一种更高效、可推广的自动化方法。

Method: 构建一种感知驱动的体素化场景表示，联合编码占据率、电磁材料特性和收发器几何关系，并采用基于SwinUNETR的神经网络从RGB-D数据直接推断环境路径损耗相对于自由空间路径损耗的分布。

Result: 在未见过的环境中，SenseRay-3D实现了4.27 dB的平均绝对误差，并支持每样本217 ms的实时推理；同时构建了一个综合的合成室内传播数据集用于验证和作为基准。

Conclusion: SenseRay-3D为室内传播建模提供了一条感知驱动、可推广且物理一致的新路径，显著优于此前的EM DeepRay框架。

Abstract: Modeling indoor radio propagation is crucial for wireless network planning and optimization. However, existing approaches often rely on labor-intensive manual modeling of geometry and material properties, resulting in limited scalability and efficiency. To overcome these challenges, this paper presents SenseRay-3D, a generalizable and physics-informed end-to-end framework that predicts three-dimensional (3D) path-loss heatmaps directly from RGB-D scans, thereby eliminating the need for explicit geometry reconstruction or material annotation. The proposed framework builds a sensing-driven voxelized scene representation that jointly encodes occupancy, electromagnetic material characteristics, and transmitter-receiver geometry, which is processed by a SwinUNETR-based neural network to infer environmental path-loss relative to free-space path-loss. A comprehensive synthetic indoor propagation dataset is further developed to validate the framework and to serve as a standardized benchmark for future research. Experimental results show that SenseRay-3D achieves a mean absolute error of 4.27 dB on unseen environments and supports real-time inference at 217 ms per sample, demonstrating its scalability, efficiency, and physical consistency. SenseRay-3D paves a new path for sense-driven, generalizable, and physics-consistent modeling of indoor propagation, marking a major leap beyond our pioneering EM DeepRay framework.

</details>


### [670] [To Align or Not to Align: Strategic Multimodal Representation Alignment for Optimal Performance](https://arxiv.org/abs/2511.12121)
*Wanlong Fang,Tianle Zhang,Alvin Chan*

Main category: cs.LG

TL;DR: 本文研究了显式对齐在多模态学习中的影响，提出了一种可控对比学习模块来精确调节对齐强度，并发现对齐效果取决于模态间数据冗余程度，从而为何时及如何应用显式对齐提供了实践指导。


<details>
  <summary>Details</summary>
Motivation: 现有研究多观察多模态表征的自然对齐现象，缺乏对显式对齐作用的系统性探究，尤其是在不同信息结构下的影响。

Method: 引入一种可控的对比学习模块，可在训练中精确操控对齐强度，结合合成与真实数据集分析不同数据特征下对齐对模型性能的影响。

Result: 实验表明，显式对齐的效果依赖于模态间的冗余程度；存在一个最优对齐强度，能在共享冗余与模态特有信息之间取得平衡。

Conclusion: 显式对齐并非总是有益，其最优强度取决于数据特性，特别是模态间的冗余水平，研究为多模态对齐策略的选择提供了理论依据和实践指南。

Abstract: Multimodal learning often relies on aligning representations across modalities to enable effective information integration, an approach traditionally assumed to be universally beneficial. However, prior research has primarily taken an observational approach, examining naturally occurring alignment in multimodal data and exploring its correlation with model performance, without systematically studying the direct effects of explicitly enforced alignment between representations of different modalities. In this work, we investigate how explicit alignment influences both model performance and representation alignment under different modality-specific information structures. Specifically, we introduce a controllable contrastive learning module that enables precise manipulation of alignment strength during training, allowing us to explore when explicit alignment improves or hinders performance. Our results on synthetic and real datasets under different data characteristics show that the impact of explicit alignment on the performance of unimodal models is related to the characteristics of the data: the optimal level of alignment depends on the amount of redundancy between the different modalities. We identify an optimal alignment strength that balances modality-specific signals and shared redundancy in the mixed information distributions. This work provides practical guidance on when and how explicit alignment should be applied to achieve optimal unimodal encoder performance.

</details>


### [671] [Dynamic Anomaly Identification in Accounting Transactions via Multi-Head Self-Attention Networks](https://arxiv.org/abs/2511.12122)
*Yi Wang,Ruoyi Fang,Anzhuo Xie,Hanrui Feng,Jianlin Lai*

Main category: cs.LG

TL;DR: 提出一种基于Transformer的实时会计交易动态异常检测方法，通过多头自注意力机制建模全局依赖，有效提升异常识别精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 会计交易环境中存在隐蔽的异常行为且对实时性要求高，传统方法难以满足复杂场景下的检测需求。

Method: 将多维交易记录表示为时间序列矩阵，结合嵌入层和位置编码进行低维映射，构建多头自注意力机制的序列模型，并引入前馈网络与正则化策略实现深度特征学习与异常概率估计。

Result: 在公开数据集上实验表明，该方法在AUC、F1分数、精确率和召回率上均优于基线模型，且在不同环境和数据扰动下保持稳定性能。

Conclusion: 基于Transformer的框架在会计交易动态异常检测中具有良好的适用性和优势，为智能财务风控与审计提供了有效的方法支持。

Abstract: This study addresses the problem of dynamic anomaly detection in accounting transactions and proposes a real-time detection method based on a Transformer to tackle the challenges of hidden abnormal behaviors and high timeliness requirements in complex trading environments. The approach first models accounting transaction data by representing multi-dimensional records as time-series matrices and uses embedding layers and positional encoding to achieve low-dimensional mapping of inputs. A sequence modeling structure with multi-head self-attention is then constructed to capture global dependencies and aggregate features from multiple perspectives, thereby enhancing the ability to detect abnormal patterns. The network further integrates feed-forward layers and regularization strategies to achieve deep feature representation and accurate anomaly probability estimation. To validate the effectiveness of the method, extensive experiments were conducted on a public dataset, including comparative analysis, hyperparameter sensitivity tests, environmental sensitivity tests, and data sensitivity tests. Results show that the proposed method outperforms baseline models in AUC, F1-Score, Precision, and Recall, and maintains stable performance under different environmental conditions and data perturbations. These findings confirm the applicability and advantages of the Transformer-based framework for dynamic anomaly detection in accounting transactions and provide methodological support for intelligent financial risk control and auditing.

</details>


### [672] [HCPO: Hierarchical Conductor-Based Policy Optimization in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.12123)
*Zejiao Liu,Junqi Tu,Yitian Hong,Luolin Xiong,Yaochu Jin,Yang Tang,Fangfei Li*

Main category: cs.LG

TL;DR: 提出了一种基于指挥官的联合策略框架和分层指挥策略优化算法（HCPO），通过协调探索提升多智能体强化学习中的合作效率与稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多智能体强化学习中缺乏智能体间的探索协调，限制了联合策略的表达能力和探索效率。

Method: 引入指挥官机制来协调智能体的策略更新，提出HCPO算法，采用分层结构指导指挥官与智能体的策略优化方向，并提供理论保证其单调收敛。训练集中式、执行去中心化。

Result: 在StarCraftII、Multi-agent MuJoCo 和 Multi-agent Particle Environment 三个基准上验证了HCPO的有效性，性能优于现有的MARL基线方法。

Conclusion: HCPO通过指挥官机制有效提升了联合策略的表达能力与探索效率，在多个复杂任务中实现了更优的合作效率和训练稳定性。

Abstract: In cooperative Multi-Agent Reinforcement Learning (MARL), efficient exploration is crucial for optimizing the performance of joint policy. However, existing methods often update joint policies via independent agent exploration, without coordination among agents, which inherently constrains the expressive capacity and exploration of joint policies. To address this issue, we propose a conductor-based joint policy framework that directly enhances the expressive capacity of joint policies and coordinates exploration. In addition, we develop a Hierarchical Conductor-based Policy Optimization (HCPO) algorithm that instructs policy updates for the conductor and agents in a direction aligned with performance improvement. A rigorous theoretical guarantee further establishes the monotonicity of the joint policy optimization process. By deploying local conductors, HCPO retains centralized training benefits while eliminating inter-agent communication during execution. Finally, we evaluate HCPO on three challenging benchmarks: StarCraftII Multi-agent Challenge, Multi-agent MuJoCo, and Multi-agent Particle Environment. The results indicate that HCPO outperforms competitive MARL baselines regarding cooperative efficiency and stability.

</details>


### [673] [FairGSE: Fairness-Aware Graph Neural Network without High False Positive Rates](https://arxiv.org/abs/2511.12132)
*Zhenqiang Ye,Jinjie Lu,Tianlong Gu,Fengrui Hao,Xuemin Wang*

Main category: cs.LG

TL;DR: 提出了一种新的公平图神经网络框架FairGSE，通过最大化二维结构熵来提升公平性，同时显著降低误报率。


<details>
  <summary>Details</summary>
Motivation: 现有公平性感知的图神经网络在追求公平性指标时忽视了对负标签的预测能力，导致高误报率，这在高风险场景中存在问题。

Method: 提出FairGSE框架，通过最大化二维结构熵（2D-SE）来优化公平性，同时校准分类性能，特别关注降低误报率。

Result: 实验表明，与最先进的公平性感知GNN相比，FairGSE将误报率（FPR）降低了39%，同时保持了相当的公平性改进。

Conclusion: FairGSE在不牺牲对负类预测性能的前提下有效提升了图神经网络的公平性，更适合高风险应用场景。

Abstract: Graph neural networks (GNNs) have emerged as the mainstream paradigm for graph representation learning due to their effective message aggregation. However, this advantage also amplifies biases inherent in graph topology, raising fairness concerns. Existing fairness-aware GNNs provide satisfactory performance on fairness metrics such as Statistical Parity and Equal Opportunity while maintaining acceptable accuracy trade-offs. Unfortunately, we observe that this pursuit of fairness metrics neglects the GNN's ability to predict negative labels, which renders their predictions with extremely high False Positive Rates (FPR), resulting in negative effects in high-risk scenarios. To this end, we advocate that classification performance should be carefully calibrated while improving fairness, rather than simply constraining accuracy loss. Furthermore, we propose Fair GNN via Structural Entropy (\textbf{FairGSE}), a novel framework that maximizes two-dimensional structural entropy (2D-SE) to improve fairness without neglecting false positives. Experiments on several real-world datasets show FairGSE reduces FPR by 39\% vs. state-of-the-art fairness-aware GNNs, with comparable fairness improvement.

</details>


### [674] [Fusion-ResNet: A Lightweight multi-label NILM Model Using PCA-ICA Feature Fusion](https://arxiv.org/abs/2511.12139)
*Sahar Moghimian Hoosh,Ilia Kamyshev,Henni Ouerdane*

Main category: cs.LG

TL;DR: 本文提出了一种用于非侵入式负荷监测（NILM）的端到端框架，结合ICA和PCA的特征提取方法以及轻量级Fusion-ResNet网络，提升了分类性能、泛化能力和多设备并发场景下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为解决NILM在实际应用中面临的过拟合、模型泛化能力差以及多个电器同时运行时难以分解的问题。

Method: 提出融合独立成分分析（ICA）和主成分分析（PCA）的特征提取方法，并设计轻量级神经网络Fusion-ResNet用于多标签分类。

Result: 该模型在不同电器上的平均F1分数优于现有最先进方法，且训练与推理时间更短，在多达15个设备同时工作的情况下仍保持良好性能。

Conclusion: 所提出的特征融合方法与轻量级网络架构有效提升了NILM系统的性能与实用性，尤其在高并发负荷场景下具有更强的鲁棒性。

Abstract: Non-intrusive load monitoring (NILM) is an advanced load monitoring technique that uses data-driven algorithms to disaggregate the total power consumption of a household into the consumption of individual appliances. However, real-world NILM deployment still faces major challenges, including overfitting, low model generalization, and disaggregating a large number of appliances operating at the same time. To address these challenges, this work proposes an end-to-end framework for the NILM classification task, which consists of high-frequency labeled data, a feature extraction method, and a lightweight neural network. Within this framework, we introduce a novel feature extraction method that fuses Independent Component Analysis (ICA) and Principal Component Analysis (PCA) features. Moreover, we propose a lightweight architecture for multi-label NILM classification (Fusion-ResNet). The proposed feature-based model achieves a higher $F1$ score on average and across different appliances compared to state-of-the-art NILM classifiers while minimizing the training and inference time. Finally, we assessed the performance of our model against baselines with a varying number of simultaneously active devices. Results demonstrate that Fusion-ResNet is relatively robust to stress conditions with up to 15 concurrently active appliances.

</details>


### [675] [Variation-Bounded Loss for Noise-Tolerant Learning](https://arxiv.org/abs/2511.12143)
*Jialiang Wang,Xiong Zhou,Xianming Liu,Gangfeng Hu,Deming Zhai,Junjun Jiang,Haoliang Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的与损失函数鲁棒性相关的性质——变异比，并基于此提出了变异有界损失（VBL）函数族，通过理论分析证明较小的变异比有助于提高鲁棒性，且该性质有助于放松对称条件并更简洁地实现非对称条件，实验验证了方法的有效性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 在监督学习中，噪声标签的负面影响一直是一个难题，尽管已有鲁棒损失函数被提出，但仍需更有效的机制来提升模型对噪声标签的鲁棒性。

Method: 引入变异比作为衡量损失函数鲁棒性的新指标，提出变异有界损失（VBL）函数族，通过理论分析揭示其与对称性和非对称性条件的关系，并将多个常用损失函数重构为变异有界形式。

Result: 理论证明了较小的变异比能带来更好的鲁棒性，变异比可作为放松对称条件和实现非对称条件的有效途径；在多个数据集上的实验表明所提方法有效且灵活。

Conclusion: 变异比是衡量和设计鲁棒损失函数的一个关键性质，VBL框架为处理噪声标签提供了一个通用且有效的新方向。

Abstract: Mitigating the negative impact of noisy labels has been aperennial issue in supervised learning. Robust loss functions have emerged as a prevalent solution to this problem. In this work, we introduce the Variation Ratio as a novel property related to the robustness of loss functions, and propose a new family of robust loss functions, termed Variation-Bounded Loss (VBL), which is characterized by a bounded variation ratio. We provide theoretical analyses of the variation ratio, proving that a smaller variation ratio would lead to better robustness. Furthermore, we reveal that the variation ratio provides a feasible method to relax the symmetric condition and offers a more concise path to achieve the asymmetric condition. Based on the variation ratio, we reformulate several commonly used loss functions into a variation-bounded form for practical applications. Positive experiments on various datasets exhibit the effectiveness and flexibility of our approach.

</details>


### [676] [Finding Time Series Anomalies using Granular-ball Vector Data Description](https://arxiv.org/abs/2511.12147)
*Lifeng Shen,Liang Peng,Ruiwen Liu,Shuyin Xia,Yi Liu*

Main category: cs.LG

TL;DR: 提出了一种基于Granular-ball Vector Data Description (GVDD)的新型单类网络GBOC，用于时间序列异常检测，通过数据自适应的粒球表示提升鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在复杂时序数据中依赖强假设，难以有效建模正常行为，导致异常检测性能下降。

Method: 提出Granular-ball One-Class Network (GBOC)，利用密度引导的层次分割生成粒球，构建紧凑高密度区域作为正常行为原型，并通过最近粒球距离计算异常分数。

Result: 实验表明GBOC在多个数据集上优于现有方法，具有更高的检测精度和计算效率。

Conclusion: GBOC通过数据自适应的粒球表示有效捕捉局部拓扑结构，显著提升了非线性时序数据中异常检测的鲁棒性与性能。

Abstract: Modeling normal behavior in dynamic, nonlinear time series data is challenging for effective anomaly detection. Traditional methods, such as nearest neighbor and clustering approaches, often depend on rigid assumptions, such as a predefined number of reliable neighbors or clusters, which frequently break down in complex temporal scenarios. To address these limitations, we introduce the Granular-ball One-Class Network (GBOC), a novel approach based on a data-adaptive representation called Granular-ball Vector Data Description (GVDD). GVDD partitions the latent space into compact, high-density regions represented by granular-balls, which are generated through a density-guided hierarchical splitting process and refined by removing noisy structures. Each granular-ball serves as a prototype for local normal behavior, naturally positioning itself between individual instances and clusters while preserving the local topological structure of the sample set. During training, GBOC improves the compactness of representations by aligning samples with their nearest granular-ball centers. During inference, anomaly scores are computed based on the distance to the nearest granular-ball. By focusing on dense, high-quality regions and significantly reducing the number of prototypes, GBOC delivers both robustness and efficiency in anomaly detection. Extensive experiments validate the effectiveness and superiority of the proposed method, highlighting its ability to handle the challenges of time series anomaly detection.

</details>


### [677] [Open Banking Foundational Model: Learning Language Representations from Few Financial Transactions](https://arxiv.org/abs/2511.12154)
*Gustavo Polleti,Marlesson Santana,Eduardo Fontes*

Main category: cs.LG

TL;DR: 提出了一种用于金融交易的多模态基础模型，结合结构化属性和非结构化文本描述，在数据稀缺的开放银行场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决传统特征工程和离散事件序列方法在跨机构、跨地域金融交易建模中的局限性，尤其是在数据稀缺情况下的泛化能力不足问题。

Method: 通过将掩码语言建模应用于交易序列，融合结构化属性与非结构化文本描述，构建统一的多模态表示。

Result: 在北美数千家金融机构的大规模研究中验证了模型的有效性，性能优于传统方法，并展现出良好的跨机构和跨地域泛化能力。

Conclusion: 自监督的多模态模型在欺诈预防、信用风险评估和客户洞察等金融应用中具有巨大潜力。

Abstract: We introduced a multimodal foundational model for financial transactions that integrates both structured attributes and unstructured textual descriptions into a unified representation. By adapting masked language modeling to transaction sequences, we demonstrated that our approach not only outperforms classical feature engineering and discrete event sequence methods but is also particularly effective in data-scarce Open Banking scenarios. To our knowledge, this is the first large-scale study across thousands of financial institutions in North America, providing evidence that multimodal representations can generalize across geographies and institutions. These results highlight the potential of self-supervised models to advance financial applications ranging from fraud prevention and credit risk to customer insights

</details>


### [678] [Rethinking Deep Alignment Through The Lens Of Incomplete Learning](https://arxiv.org/abs/2511.12155)
*Thong Bach,Dung Nguyen,Thao Minh Le,Truyen Tran*

Main category: cs.LG

TL;DR: 本文揭示了大语言模型在对抗攻击下的系统性脆弱性源于自回归训练中的位置依赖梯度减弱，导致安全学习不完整，并提出基于基础偏好标记的针对性补全方法，显著提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管进行了广泛的安全对齐，大语言模型仍易受对抗攻击，现有方法缺乏对安全对齐失效机制的深入理解，需从机理层面分析并改进。

Method: 通过机理分析发现梯度衰减导致安全学习不完整，引入基础偏好标记作为指标，采用自适应惩罚与混合教师蒸馏的针对性补全方法强化薄弱区域。

Result: 在Llama和Qwen系列模型上实验显示攻击成功率降低48%–98%，且保持原有通用能力。

Conclusion: 研究阐明了安全对齐中信号衰减的根本局限，提供了可有效增强模型对抗鲁棒性的理论框架与实用方法。

Abstract: Large language models exhibit systematic vulnerabilities to adversarial attacks despite extensive safety alignment. We provide a mechanistic analysis revealing that position-dependent gradient weakening during autoregressive training creates signal decay, leading to incomplete safety learning where safety training fails to transform model preferences in later response regions fully. We introduce base-favored tokens -- vocabulary elements where base models assign higher probability than aligned models -- as computational indicators of incomplete safety learning and develop a targeted completion method that addresses undertrained regions through adaptive penalties and hybrid teacher distillation. Experimental evaluation across Llama and Qwen model families demonstrates dramatic improvements in adversarial robustness, with 48--98% reductions in attack success rates while preserving general capabilities. These results establish both a mechanistic understanding and practical solutions for fundamental limitations in safety alignment methodologies.

</details>


### [679] [Data-Efficient Self-Supervised Algorithms for Fine-Grained Birdsong Analysis](https://arxiv.org/abs/2511.12158)
*Houtan Ghaffari,Lukas Rauch,Paul Devos*

Main category: cs.LG

TL;DR: 提出了一种轻量且高效的Residual-MLP-RNN架构和三阶段训练流程，用于在标注数据极少的情况下实现可靠的鸟类鸣叫音节检测。


<details>
  <summary>Details</summary>
Motivation: 鸟类鸣叫研究需要精确的音节级标注，但标注成本高，亟需减少人工标注的数据高效自动化方法。

Method: 提出Residual-MLP-RNN模型和三阶段训练流程：第一阶段使用无标签数据进行自监督预训练（掩码预测或在线聚类）；第二阶段使用数据增强进行有监督的帧级音节检测训练；第三阶段利用与下游任务对齐的无标签数据进行半监督后训练。

Result: 在标注极度稀缺的情况下，该方法在 Canary 鸣叫这一复杂且难标注的任务上表现出色，并验证了其在其他鸟类上的适用性；同时评估了自监督嵌入在线性探测和无监督分析中的潜力。

Conclusion: 所提出的三阶段训练框架结合轻量模型，显著降低了对专家标注的依赖，在极低标注成本下实现了高性能的鸟类鸣叫音节检测。

Abstract: Many bioacoustics, neuroscience, and linguistics research utilize birdsongs as proxy models to acquire knowledge in diverse areas. Developing models generally requires precisely annotated data at the level of syllables. Hence, automated and data-efficient methods that reduce annotation costs are in demand. This work presents a lightweight, yet performant neural network architecture for birdsong annotation called Residual-MLP-RNN. Then, it presents a robust three-stage training pipeline for developing reliable deep birdsong syllable detectors with minimal expert labor. The first stage is self-supervised learning from unlabeled data. Two of the most successful pretraining paradigms are explored, namely, masked prediction and online clustering. The second stage is supervised training with effective data augmentations to create a robust model for frame-level syllable detection. The third stage is semi-supervised post-training, which leverages the unlabeled data again. However, unlike the initial phase, this time it is aligned with the downstream task. The performance of this data-efficient approach is demonstrated for the complex song of the Canary in extreme label-scarcity scenarios. Canary has one of the most difficult songs to annotate, which implicitly validates the method for other birds. Finally, the potential of self-supervised embeddings is assessed for linear probing and unsupervised birdsong analysis.

</details>


### [680] [FGM optimization in complex domains using Gaussian process regression based profile generation algorithm](https://arxiv.org/abs/2511.12171)
*Chaitanya Kumar Konda,Piyush Agrawal,Shivansh Srivastava,Manish Agrawal*

Main category: cs.LG

TL;DR: 提出了一种基于高斯过程回归（GPR）的通用体积分数分布生成算法，用于任意形状域的功能梯度材料（FGM）设计，并结合改进的遗传算法实现热弹性优化。


<details>
  <summary>Details</summary>
Motivation: 解决任意形状域中功能梯度材料（FGM）设计的挑战，尤其是生成满足边界条件且平滑的体积分数分布。

Method: 采用高斯过程回归（GPR）生成平滑且符合边界约束的FGM体积分数分布，并通过长度尺度参数控制平滑性和设计空间大小；结合遗传算法进行优化，修改了模拟二进制交叉算子以适配GPR框架。

Result: 成功生成了复杂形状域内的多样化、平滑FGM分布，并在多个热弹性优化示例中验证了该方法的有效性。

Conclusion: 所提出的GPR-based FGM设计框架具有良好的灵活性和优化能力，适用于任意形状域的功能梯度材料设计。

Abstract: This manuscript addresses the challenge of designing functionally graded materials (FGMs) for arbitrary-shaped domains. Towards this goal, the present work proposes a generic volume fraction profile generation algorithm based on Gaussian Process Regression (GPR). The proposed algorithm can handle complex-shaped domains and generate smooth FGM profiles while adhering to the specified volume fraction values at boundaries/part of boundaries. The resulting design space from GPR comprises diverse profiles, enhancing the potential for discovering optimal configurations. Further, the algorithm allows the user to control the smoothness of the underlying profiles and the size of the design space through a length scale parameter. Further, the proposed profile generation scheme is coupled with the genetic algorithm to find the optimum FGM profiles for a given application. To make the genetic algorithm consistent with the GPR profile generation scheme, the standard simulated binary crossover operator in the genetic algorithm has been modified with a projection operator. We present numerous thermoelastic optimization examples to demonstrate the efficacy of the proposed profile generation algorithm and optimization framework.

</details>


### [681] [TSGDiff: Rethinking Synthetic Time Series Generation from a Pure Graph Perspective](https://arxiv.org/abs/2511.12174)
*Lifeng Shen,Xuyang Li,Lele Long*

Main category: cs.LG

TL;DR: 本文提出了一种基于图神经网络的扩散模型TSGDiff，用于时间序列生成，通过将时间序列建模为动态图，并设计新的拓扑结构保真度指标Topo-FID来评估生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在生成时间序列时难以捕捉复杂的时序依赖和结构模式，因此需要一种能有效建模时间序列结构特征的新方法。

Method: 将时间序列转化为基于傅里叶谱特性和时序依赖构建的动态图，采用图神经网络编码器-解码器架构建立潜在空间，在该空间上进行扩散过程以生成时间序列；同时提出Topo-FID指标，结合图编辑相似性和结构熵相似性来评估生成结果的结构保真度。

Result: 在真实数据集上的实验表明，TSGDiff能够生成高质量的时间序列数据，较好地保持了原始数据的时序依赖性和结构完整性，且Topo-FID比现有指标更能准确反映生成结果的结构相似性。

Conclusion: TSGDiff通过图表示学习与扩散模型的结合，有效提升了时间序列生成的质量，所提出的Topo-FID为评估生成序列的结构保真度提供了更优的度量标准。

Abstract: Diffusion models have shown great promise in data generation, yet generating time series data remains challenging due to the need to capture complex temporal dependencies and structural patterns. In this paper, we present \textit{TSGDiff}, a novel framework that rethinks time series generation from a graph-based perspective. Specifically, we represent time series as dynamic graphs, where edges are constructed based on Fourier spectrum characteristics and temporal dependencies. A graph neural network-based encoder-decoder architecture is employed to construct a latent space, enabling the diffusion process to model the structural representation distribution of time series effectively. Furthermore, we propose the Topological Structure Fidelity (Topo-FID) score, a graph-aware metric for assessing the structural similarity of time series graph representations. Topo-FID integrates two sub-metrics: Graph Edit Similarity, which quantifies differences in adjacency matrices, and Structural Entropy Similarity, which evaluates the entropy of node degree distributions. This comprehensive metric provides a more accurate assessment of structural fidelity in generated time series. Experiments on real-world datasets demonstrate that \textit{TSGDiff} generates high-quality synthetic time series data generation, faithfully preserving temporal dependencies and structural integrity, thereby advancing the field of synthetic time series generation.

</details>


### [682] [Understanding InfoNCE: Transition Probability Matrix Induced Feature Clustering](https://arxiv.org/abs/2511.12180)
*Ge Cheng,Shuo Wang,Yun Zhang*

Main category: cs.LG

TL;DR: 本文提出了SC-InfoNCE，一种基于对InfoNCE理论分析的新型对比学习损失函数，通过引入可调节的收敛目标来灵活控制特征相似性对齐，在多模态任务中表现出稳定且优异的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管InfoNCE在无监督表示学习中广泛应用，但其理论基础仍有限。本文旨在从理论上解释InfoNCE如何通过数据增强动态影响特征空间结构，并提出更灵活的替代方案。

Method: 引入显式的特征空间和转移概率矩阵来建模增强视图及其动态关系，推导出InfoNCE优化目标与共享源概率之间的联系，并在此基础上提出SC-InfoNCE，通过缩放目标矩阵调节特征聚类强度。

Result: 在图像、图和文本等多个基准数据集上的实验表明，SC-InfoNCE能够实现更强且更稳定的性能，验证了其跨域适用性和有效性。

Conclusion: SC-InfoNCE通过理论驱动的设计改进了传统InfoNCE，提供了对特征对齐程度的可控性，使训练目标能更好地适配下游数据的统计特性，为对比学习提供了新的视角。

Abstract: Contrastive learning has emerged as a cornerstone of unsupervised representation learning across vision, language, and graph domains, with InfoNCE as its dominant objective. Despite its empirical success, the theoretical underpinnings of InfoNCE remain limited. In this work, we introduce an explicit feature space to model augmented views of samples and a transition probability matrix to capture data augmentation dynamics. We demonstrate that InfoNCE optimizes the probability of two views sharing the same source toward a constant target defined by this matrix, naturally inducing feature clustering in the representation space. Leveraging this insight, we propose Scaled Convergence InfoNCE (SC-InfoNCE), a novel loss function that introduces a tunable convergence target to flexibly control feature similarity alignment. By scaling the target matrix, SC-InfoNCE enables flexible control over feature similarity alignment, allowing the training objective to better match the statistical properties of downstream data. Experiments on benchmark datasets, including image, graph, and text tasks, show that SC-InfoNCE consistently achieves strong and reliable performance across diverse domains.

</details>


### [683] [Scaling Law Analysis in Federated Learning: How to Select the Optimal Model Size?](https://arxiv.org/abs/2511.12188)
*Xuanyu Chen,Nan Yang,Shuai Wang,Dong Yuan*

Main category: cs.LG

TL;DR: 本文研究了在联邦学习（FL）场景下大规模语言模型的可扩展性问题，提出了一个基于PAC-Bayes理论的泛化误差上界，并分析了分布式数据对最优模型规模的影响，发现最优模型规模与客户端数量呈负幂律关系，且联邦学习在相同计算资源下会降低模型的泛化性能上限，结果通过大量实验验证。


<details>
  <summary>Details</summary>
Motivation: 随着大模型的发展，高质量训练数据日益稀缺，联邦学习因其能利用边缘设备上的数据并保护隐私而受到关注。然而，FL中数据分布的去中心化给大模型训练带来了新挑战，现有研究对此探索不足。因此，亟需理解传统模型缩放规律在联邦学习中的适用性。

Method: 本文采用PAC-Bayes框架推导了联邦学习中随机算法训练模型的泛化误差上界，并通过求解使该上界最小化的解析解来量化分布式数据对最优模型规模的影响。同时结合不同模型、网络设置和数据集进行了广泛的实验验证。

Result: 理论结果表明，在总训练计算量不变的情况下，最优模型规模与客户端数量呈负幂律关系；相同计算资源下转向联邦学习会不可避免地降低模型可达的泛化性能上限；联邦场景下的最优模型规模应取决于客户端平均计算量。实验结果验证了理论分析的正确性。

Conclusion: 传统的模型缩放法则不能直接应用于联邦学习场景。联邦学习中的数据分布特性显著影响模型的最优规模和最终性能，因此在设计联邦大模型时必须考虑客户端数量和平均计算资源，以实现最佳泛化性能。

Abstract: The recent success of large language models (LLMs) has sparked a growing interest in training large-scale models. As the model size continues to scale, concerns are growing about the depletion of high-quality, well-curated training data. This has led practitioners to explore training approaches like Federated Learning (FL), which can leverage the abundant data on edge devices while maintaining privacy. However, the decentralization of training datasets in FL introduces challenges to scaling large models, a topic that remains under-explored. This paper fills this gap and provides qualitative insights on generalizing the previous model scaling experience to federated learning scenarios. Specifically, we derive a PAC-Bayes (Probably Approximately Correct Bayesian) upper bound for the generalization error of models trained with stochastic algorithms in federated settings and quantify the impact of distributed training data on the optimal model size by finding the analytic solution of model size that minimizes this bound. Our theoretical results demonstrate that the optimal model size has a negative power law relationship with the number of clients if the total training compute is unchanged. Besides, we also find that switching to FL with the same training compute will inevitably reduce the upper bound of generalization performance that the model can achieve through training, and that estimating the optimal model size in federated scenarios should depend on the average training compute across clients. Furthermore, we also empirically validate the correctness of our results with extensive training runs on different models, network settings, and datasets.

</details>


### [684] [Evaluation of Multi- and Single-objective Learning Algorithms for Imbalanced Data](https://arxiv.org/abs/2511.12191)
*Szymon Wojciechowski,Michał Woźniak*

Main category: cs.LG

TL;DR: 本文提出了一种新的可靠方法，用于评估基于多目标优化的算法与返回单一解的方法之间的性能，特别关注根据用户偏好从帕累托前沿中选择解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的分类器评估方法难以可靠地比较返回单一解的算法和返回帕累托前沿的多目标优化算法，存在评估方法上的空白。

Method: 提出一种新的评估框架，能够在统一的标准下比较单解算法与多目标算法，并结合用户偏好从帕累托前沿中选择合适的解。

Result: 该方法能够有效支持不同算法间的公平比较，尤其适用于不平衡数据分类等多目标学习任务。

Conclusion: 所提方法填补了多目标学习算法与传统单目标算法之间评估方法的空白，提升了算法比较的可靠性与可解释性。

Abstract: Many machine learning tasks aim to find models that work well not for a single, but for a group of criteria, often opposing ones. One such example is imbalanced data classification, where, on the one hand, we want to achieve the best possible classification quality for data from the minority class without degrading the classification quality of the majority class. One solution is to propose an aggregate learning criterion and reduce the multi-objective learning task to a single-criteria optimization problem. Unfortunately, such an approach is characterized by ambiguity of interpretation since the value of the aggregated criterion does not indicate the value of the component criteria. Hence, there are more and more proposals for algorithms based on multi-objective optimization (MOO), which can simultaneously optimize multiple criteria. However, such an approach results in a set of multiple non-dominated solutions (Pareto front). The selection of a single solution from the Pareto front is a challenge itself, and much attention is paid to the issue of how to select it considering user preferences, as well as how to compare solutions returned by different MOO algorithms among themselves. Thus, a significant gap has been identified in the classifier evaluation methodology, i.e., how to reliably compare methods returning single solutions with algorithms returning solutions in the form of Pareto fronts.
  To fill the aforementioned gap, this article proposes a new, reliable way of evaluating algorithms based on multi-objective algorithms with methods that return single solutions while pointing out solutions from a Pareto front tailored to the user's preferences. This work focuses only on algorithm comparison, not their learning. The algorithms selected for this study are illustrative to help understand the proposed approach.

</details>


### [685] [MPD-SGR: Robust Spiking Neural Networks with Membrane Potential Distribution-Driven Surrogate Gradient Regularization](https://arxiv.org/abs/2511.12199)
*Runhao Jiang,Chengzhi Jiang,Rui Yan,Huajin Tang*

Main category: cs.LG

TL;DR: 提出了一种基于膜电位分布（MPD）的代理梯度正则化方法（MPD-SGR），通过调节MPD与代理梯度函数的交互来增强脉冲神经网络对对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管代理梯度方法提升了SNN性能，但其对抗攻击的脆弱性仍存，尤其是梯度幅值对模型敏感性的影响尚未充分探索。

Method: 分析膜电位分布（MPD）与代理梯度函数的关系，提出MPD-SGR正则化方法，通过控制落在梯度有效范围内的膜电位比例来降低模型敏感性。

Result: 在多个图像分类任务和网络结构上验证了MPD-SGR能显著提升SNN对对抗扰动的鲁棒性，并具有良好的泛化能力。

Conclusion: MPD与代理梯度函数的相互作用是影响SNN鲁棒性的关键因素，MPD-SGR为设计抗攻击的SNN提供了有效途径。

Abstract: The surrogate gradient (SG) method has shown significant promise in enhancing the performance of deep spiking neural networks (SNNs), but it also introduces vulnerabilities to adversarial attacks. Although spike coding strategies and neural dynamics parameters have been extensively studied for their impact on robustness, the critical role of gradient magnitude, which reflects the model's sensitivity to input perturbations, remains underexplored. In SNNs, the gradient magnitude is primarily determined by the interaction between the membrane potential distribution (MPD) and the SG function. In this study, we investigate the relationship between the MPD and SG and its implications for improving the robustness of SNNs. Our theoretical analysis reveals that reducing the proportion of membrane potential lying within the gradient-available range of the SG function effectively mitigates the sensitivity of SNNs to input perturbations. Building upon this insight, we propose a novel MPD-driven surrogate gradient regularization (MPD-SGR) method, which enhances robustness by explicitly regularizing the MPD based on its interaction with the SG function. Extensive experiments across multiple image classification benchmarks and diverse network architectures confirm that the MPD-SGR method significantly enhances the resilience of SNNs to adversarial perturbations and exhibits strong generalizability across diverse network configurations, SG function variants, and spike encoding schemes.

</details>


### [686] [AlignTree: Efficient Defense Against LLM Jailbreak Attacks](https://arxiv.org/abs/2511.12217)
*Gil Goren,Shahar Katz,Lior Wolf*

Main category: cs.LG

TL;DR: 本文提出了一种名为AlignTree的高效防御机制，用于检测和阻止大语言模型在生成过程中产生不符合安全准则的内容，具有低计算开销和强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗攻击防御方法要么计算成本高，要么容易被绕过，缺乏既高效又安全的解决方案。

Method: AlignTree通过监控LLM生成时的激活状态，利用基于拒绝方向的线性信号和SVM提取的非线性信号，使用高效的随机森林分类器检测不合规行为，无需额外提示或辅助防护模型。

Result: 实验表明，AlignTree在多个大语言模型和基准测试中均表现出高效性和鲁棒性，显著优于现有轻量级防御方法。

Conclusion: AlignTree是一种实用、低开销且有效的防御方案，适用于现实世界中大语言模型的安全对齐。

Abstract: Large Language Models (LLMs) are vulnerable to adversarial attacks that bypass safety guidelines and generate harmful content. Mitigating these vulnerabilities requires defense mechanisms that are both robust and computationally efficient. However, existing approaches either incur high computational costs or rely on lightweight defenses that can be easily circumvented, rendering them impractical for real-world LLM-based systems. In this work, we introduce the AlignTree defense, which enhances model alignment while maintaining minimal computational overhead. AlignTree monitors LLM activations during generation and detects misaligned behavior using an efficient random forest classifier. This classifier operates on two signals: (i) the refusal direction -- a linear representation that activates on misaligned prompts, and (ii) an SVM-based signal that captures non-linear features associated with harmful content. Unlike previous methods, AlignTree does not require additional prompts or auxiliary guard models. Through extensive experiments, we demonstrate the efficiency and robustness of AlignTree across multiple LLMs and benchmarks.

</details>


### [687] [Chicken Swarm Kernel Particle Filter: A Structured Rejuvenation Approach with KLD-Efficient Sampling](https://arxiv.org/abs/2511.12222)
*Hangshuo Tian*

Main category: cs.LG

TL;DR: 本文研究了基于鸡群优化（CSO）的粒子滤波与Kullback-Leibler散度（KLD）自适应采样结合时的理论交互机制，提出CSO的适应度驱动更新可近似为均方收缩，导致粒子分布更集中，从而在相同误差界下CPF比标准PF期望使用更少的粒子数。


<details>
  <summary>Details</summary>
Motivation: 理解粒子滤波中 swarm intelligence 与 KLD 自适应采样之间的理论交互机制尚不充分，尤其是CSO类算法如何影响粒子分布及采样效率。

Method: 在简化建模框架下，将CSO的更新过程近似为均方收缩，并利用Karamata不等式分析其对KLD采样中期望粒子数的影响。

Result: 分析表明，在假设条件下，CSO增强的粒子滤波（CPF）相比标准PF在满足相同统计误差界限时，预期所需的粒子数量更少。

Conclusion: 该工作提供了一个可解释CSO与KLD结合时计算效率提升的理论框架，并为设计更高效的自适应滤波器提供了起点。

Abstract: Particle filters (PFs) are often combined with swarm intelligence (SI) algorithms, such as Chicken Swarm Optimization (CSO), for particle rejuvenation. Separately, Kullback--Leibler divergence (KLD) sampling is a common strategy for adaptively sizing the particle set. However, the theoretical interaction between SI-based rejuvenation kernels and KLD-based adaptive sampling is not yet fully understood.
  This paper investigates this specific interaction. We analyze, under a simplified modeling framework, the effect of the CSO rejuvenation step on the particle set distribution. We propose that the fitness-driven updates inherent in CSO can be approximated as a form of mean-square contraction. This contraction tends to produce a particle distribution that is more concentrated than that of a baseline PF, or in mathematical terms, a distribution that is plausibly more ``peaked'' in a majorization sense.
  By applying Karamata's inequality to the concave function that governs the expected bin occupancy in KLD-sampling, our analysis suggests a connection: under the stated assumptions, the CSO-enhanced PF (CPF) is expected to require a lower \emph{expected} particle count than the standard PF to satisfy the same statistical error bound. The goal of this study is not to provide a fully general proof, but rather to offer a tractable theoretical framework that helps to interpret the computational efficiency empirically observed when combining these techniques, and to provide a starting point for designing more efficient adaptive filters.

</details>


### [688] [SCI: An Equilibrium for Signal Intelligence](https://arxiv.org/abs/2511.12240)
*Vishal Joshua Meesala*

Main category: cs.LG

TL;DR: SCI是一个闭环控制理论框架，通过将可解释性建模为受控状态，显著降低解释误差并提高稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的静态解释方法在动态复杂系统中解释误差大且不稳定，缺乏对可解释性质量的主动调控机制。

Method: SCI框架引入手术精度SP(t)作为可解释性度量，采用基于李雅普诺夫引导的控制器，在人类增益预算下通过投影更新参数Theta来调节解释过程，并结合可靠性加权多尺度特征、知识引导的解释器和回滚机制。

Result: 在生物医学、工业和环境等多个领域，SCI相比静态解释器将解释误差降低了25-42%（平均38%），SP方差从0.030降至0.011，同时保持AUC/F1性能仅下降约1-2个百分点。

Conclusion: 将可解释性视为控制目标可实现更稳定、快速恢复且可信的解释行为，为高风险领域的可靠AI解释提供了新范式。

Abstract: We present SCI, a closed-loop, control-theoretic framework that models interpretability as a regulated state. SCI formalizes the interpretive error Delta SP and actively drives SP(t) in [0, 1] ("Surgical Precision") toward a target via a projected update on the parameters Theta under a human-gain budget. The framework operates through three coordinated components: (1) reliability-weighted, multiscale features P(t, s); (2) a knowledge-guided interpreter psi_Theta that emits traceable markers and rationales; and (3) a Lyapunov-guided controller equipped with rollback, trust-region safeguards, and a descent condition. Across biomedical (EEG/ECG/ICU), industrial (bearings/tool wear), and environmental (climate/seismic) domains, SCI reduces interpretive error by 25-42% (mean 38%, 95% confidence interval 22-43%) relative to static explainers while maintaining AUC/F1 within approximately 1-2 percentage points of baseline. SCI also reduces SP variance from 0.030 to 0.011, indicating substantially more stable explanations. Modeling interpretability as a control objective yields steadier, faster-recovering, and more trustworthy interpretive behavior across diverse signal regimes.

</details>


### [689] [Cross-view Joint Learning for Mixed-Missing Multi-view Unsupervised Feature Selection](https://arxiv.org/abs/2511.12261)
*Zongxin Shen,Yanyong Huang,Dongjie Wang,Jinyuan Chang,Fengmao Lv,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: 提出了一种新的不完整多视图无监督特征选择方法CLIM-FS，用于解决混合缺失问题，通过联合学习特征选择与自适应数据填补，并利用跨视图一致性与局部结构提升性能，同时提供了理论分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注视图缺失问题，难以应对实际中更常见的混合缺失情况（部分样本缺失整个视图或视图内部分特征），且缺乏对特征选择与数据填补交互机制的理论分析。

Method: 基于非负正交矩阵分解框架，将缺失视图和变量的填补融入特征选择模型，实现特征选择与自适应数据填补的联合学习；同时利用共识聚类结构和跨视图局部几何结构增强学习效果。

Result: 在八个真实多视图数据集上的实验表明，CLIM-FS在特征选择性能上优于现有的最先进方法。

Conclusion: CLIM-FS能有效处理混合缺失情况下的多视图特征选择问题，通过协同利用多视图的一致性与多样性，并结合理论指导的联合学习机制，显著提升了无监督特征选择的效果。

Abstract: Incomplete multi-view unsupervised feature selection (IMUFS), which aims to identify representative features from unlabeled multi-view data containing missing values, has received growing attention in recent years. Despite their promising performance, existing methods face three key challenges: 1) by focusing solely on the view-missing problem, they are not well-suited to the more prevalent mixed-missing scenario in practice, where some samples lack entire views or only partial features within views; 2) insufficient utilization of consistency and diversity across views limits the effectiveness of feature selection; and 3) the lack of theoretical analysis makes it unclear how feature selection and data imputation interact during the joint learning process. Being aware of these, we propose CLIM-FS, a novel IMUFS method designed to address the mixed-missing problem. Specifically, we integrate the imputation of both missing views and variables into a feature selection model based on nonnegative orthogonal matrix factorization, enabling the joint learning of feature selection and adaptive data imputation. Furthermore, we fully leverage consensus cluster structure and cross-view local geometrical structure to enhance the synergistic learning process. We also provide a theoretical analysis to clarify the underlying collaborative mechanism of CLIM-FS. Experimental results on eight real-world multi-view datasets demonstrate that CLIM-FS outperforms state-of-the-art methods.

</details>


### [690] [Calibrated Adversarial Sampling: Multi-Armed Bandit-Guided Generalization Against Unforeseen Attacks](https://arxiv.org/abs/2511.12265)
*Rui Wang,Zeming Wei,Xiyue Zhang,Meng Sun*

Main category: cs.LG

TL;DR: 提出了一种名为校准对抗采样（CAS）的高效微调方法，通过多臂老虎机框架动态平衡探索与利用，提升深度神经网络在多种攻击下的整体鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练方法主要关注单一或有限类型的攻击，导致模型在面对未见攻击时仍脆弱，需提升模型对多种攻击的泛化鲁棒性。

Method: 基于多臂老虎机框架，设计动态奖励机制，结合对抗采样的探索与利用，动态调整不同鲁棒维度的训练重点。

Result: 在基准数据集上实验表明，CAS在保持高干净准确率的同时，显著提升了模型对多种攻击的整体鲁棒性。

Conclusion: CAS为实现深度神经网络的鲁棒泛化提供了一个有效且新颖的范式。

Abstract: Deep Neural Networks (DNNs) are known to be vulnerable to various adversarial perturbations. To address the safety concerns arising from these vulnerabilities, adversarial training (AT) has emerged as one of the most effective paradigms for enhancing the robustness of DNNs. However, existing AT frameworks primarily focus on a single or a limited set of attack types, leaving DNNs still exposed to attack types that may be encountered in practice but not addressed during training. In this paper, we propose an efficient fine-tuning method called Calibrated Adversarial Sampling (CAS) to address these issues. From the optimization perspective within the multi-armed bandit framework, it dynamically designs rewards and balances exploration and exploitation by considering the dynamic and interdependent characteristics of multiple robustness dimensions. Experiments on benchmark datasets show that CAS achieves superior overall robustness while maintaining high clean accuracy, providing a new paradigm for robust generalization of DNNs.

</details>


### [691] [MMSense: Adapting Vision-based Foundation Model for Multi-task Multi-modal Wireless Sensing](https://arxiv.org/abs/2511.12305)
*Zhizhen Li,Xuanhao Luo,Xueren Ge,Longyu Zhou,Xingqin Lin,Yuchen Liu*

Main category: cs.LG

TL;DR: 本文提出了MMSense，一种多模态、多任务的无线感知基础模型，通过统一视觉兼容表示和视觉语言模型 backbone 实现跨模态对齐与指令驱动的任务适应，在真实场景中表现出优异的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在无线通信中多局限于单模态输入和特定信道目标，未能充分发挥大模型在统一无线感知中的潜力。

Method: 整合图像、雷达、LiDAR和文本数据，将其转换为视觉兼容表示，在统一特征空间中进行跨模态对齐；采用模态门控机制自适应融合，并基于视觉大语言模型实现指令驱动的任务适应；引入任务特定的序列注意力和基于不确定性的损失加权机制以增强多任务泛化。

Result: 在真实无线场景数据集上的实验表明，MMSense在多种异构感知任务上优于任务专用模型和大模型基线方法。

Conclusion: MMSense展现了多模态大模型在统一无线感知中的巨大潜力，具备良好的跨模态、跨任务泛化能力和实际应用前景。

Abstract: Large AI models have been widely adopted in wireless communications for channel modeling, beamforming, and resource optimization. However, most existing efforts remain limited to single-modality inputs and channel-specific objec- tives, overlooking the broader potential of large foundation models for unified wireless sensing. To bridge this gap, we propose MMSense, a multi-modal, multi-task foundation model that jointly addresses channel-centric, environment-aware, and human-centered sensing. Our framework integrates image, radar, LiDAR, and textual data by transforming them into vision- compatible representations, enabling effective cross-modal align- ment within a unified feature space. A modality gating mecha- nism adaptively fuses these representations, while a vision-based large language model backbone enables unified feature align- ment and instruction-driven task adaptation. Furthermore, task- specific sequential attention and uncertainty-based loss weighting mechanisms enhance cross-task generalization. Experiments on real wireless scenario datasets show that our approach outper- forms both task-specific and large-model baselines, confirming its strong generalization across heterogeneous sensing tasks.

</details>


### [692] [Optimal Self-Consistency for Efficient Reasoning with Large Language Models](https://arxiv.org/abs/2511.12309)
*Austin Feng,Marius Alonso,Ambroise Odonnat*

Main category: cs.LG

TL;DR: 本文提出了Blend-ASC，一种新型的自洽性推理变体，通过动态分配采样显著提升样本效率，相比传统方法减少6.8倍采样量，且无需超参数调节，适用于任意采样预算。


<details>
  <summary>Details</summary>
Motivation: 自洽性（SC）在链式思维推理中有效但计算成本高，缺乏对样本效率和扩展行为的统一理论分析。

Method: 基于众数估计和投票理论，分析SC的缩放行为，提出动态分配样本的Blend-ASC方法。

Result: 推导并验证了SC的幂律缩放关系，Blend-ASC平均使用6.8倍更少的样本，优于固定和动态分配基线。

Conclusion: Blend-ASC在保持性能的同时大幅提高样本效率，无需超参数，可灵活适配不同采样预算，具有广泛适用性。

Abstract: Self-consistency (SC) is a widely used test-time inference technique for improving performance in chain-of-thought reasoning. It involves generating multiple responses, or samples from a large language model (LLM) and selecting the most frequent answer. This procedure can naturally be viewed as a majority vote or empirical mode estimation. Despite its effectiveness, SC is prohibitively expensive at scale when naively applied to datasets, and it lacks a unified theoretical treatment of sample efficiency and scaling behavior. In this paper, we provide the first comprehensive analysis of SC's scaling behavior and its variants, drawing on mode estimation and voting theory. We derive and empirically validate power law scaling for self-consistency across datasets, and analyze the sample efficiency for fixed-allocation and dynamic-allocation sampling schemes. From these insights, we introduce Blend-ASC, a novel variant of self-consistency that dynamically allocates samples to questions during inference, achieving state-of-the-art sample efficiency. Our approach uses 6.8x fewer samples than vanilla SC on average, outperforming both fixed- and dynamic-allocation SC baselines, thereby demonstrating the superiority of our approach in terms of efficiency. In contrast to existing variants, Blend-ASC is hyperparameter-free and can fit an arbitrary sample budget, ensuring it can be easily applied to any self-consistency application.

</details>


### [693] [Active Learning of Symbolic Automata Over Rational Numbers](https://arxiv.org/abs/2511.12315)
*Sebastian Hagedorn,Martín Muñoz,Cristian Riveros,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: 本文扩展了Angluin的$L^*$算法，使其能够学习在无限且稠密字母表（如有理数上的谓词）上运行的符号自动机，从而适用于实数RGX和时间序列等新场景，并保证查询次数最优。


<details>
  <summary>Details</summary>
Motivation: 原始的$L^*$算法仅能学习有限字母表上的确定性有限自动机（DFA），限制了其在实际中的应用范围，尤其是在处理无限或稠密输入域时。

Method: 提出一种扩展的$L^*$算法，用于学习基于有理数上谓词的符号自动机，通过有效处理无限密集字母表，并优化教师查询数量。

Result: 该算法在查询次数上是最优的，查询量最多与转移数和谓词表示大小呈线性关系，成功应用于实数RGX和时间序列等新领域。

Conclusion: 扩展后的$L^*$算法克服了原算法对有限字母表的依赖，显著提升了其在人工智能和软件工程中更广泛场景的适用性。

Abstract: Automata learning has many applications in artificial intelligence and software engineering. Central to these applications is the $L^*$ algorithm, introduced by Angluin. The $L^*$ algorithm learns deterministic finite-state automata (DFAs) in polynomial time when provided with a minimally adequate teacher. Unfortunately, the $L^*$ algorithm can only learn DFAs over finite alphabets, which limits its applicability. In this paper, we extend $L^*$ to learn symbolic automata whose transitions use predicates over rational numbers, i.e., over infinite and dense alphabets. Our result makes the $L^*$ algorithm applicable to new settings like (real) RGX, and time series. Furthermore, our proposed algorithm is optimal in the sense that it asks a number of queries to the teacher that is at most linear with respect to the number of transitions, and to the representation size of the predicates.

</details>


### [694] [BlinDNO: A Distributional Neural Operator for Dynamical System Reconstruction from Time-Label-Free data](https://arxiv.org/abs/2511.12316)
*Zhijun Zeng,Junqing Chen,Zuoqiang Shi*

Main category: cs.LG

TL;DR: 提出了一种名为BlinDNO的神经算子方法，用于在无时间标签的设置下从随机和量子动力系统中恢复演化参数。


<details>
  <summary>Details</summary>
Motivation: 在只有无序密度快照且观测时间未知的情况下，传统方法难以恢复系统演化参数，因此需要一种能处理时间标签缺失的新方法。

Method: 将问题建模为分布到函数的神经算子学习任务，设计了具有多尺度U-Net编码器和基于注意力机制混合模块的置换不变架构BlinDNO。

Result: 在多种随机和量子系统上进行了实验，包括冷冻电镜中的3D蛋白质折叠机制重建，结果显示BlinDNO能可靠地恢复控制参数，并优于现有基线方法。

Conclusion: BlinDNO在时间标签缺失的情况下有效解决了动力系统的逆问题，具有良好的通用性和性能优势。

Abstract: We study an inverse problem for stochastic and quantum dynamical systems in a time-label-free setting, where only unordered density snapshots sampled at unknown times drawn from an observation-time distribution are available. These observations induce a distribution over state densities, from which we seek to recover the parameters of the underlying evolution operator. We formulate this as learning a distribution-to-function neural operator and propose BlinDNO, a permutation-invariant architecture that integrates a multiscale U-Net encoder with an attention-based mixer. Numerical experiments on a wide range of stochastic and quantum systems, including a 3D protein-folding mechanism reconstruction problem in a cryo-EM setting, demonstrate that BlinDNO reliably recovers governing parameters and consistently outperforms existing neural inverse operator baselines.

</details>


### [695] [LILogic Net: Compact Logic Gate Networks with Learnable Connectivity for Efficient Hardware Deployment](https://arxiv.org/abs/2511.12340)
*Katarzyna Fojcik,Renaldas Zioma,Jogundas Armaitis*

Main category: cs.LG

TL;DR: 提出了一种名为LILogicNet的模型，通过梯度下降同时优化二值逻辑门的选择和连接方式，显著减少所需逻辑门数量，在MNIST和CIFAR-10上实现了高效训练与推理，适用于低功耗硬件部署。


<details>
  <summary>Details</summary>
Motivation: 为了在硬件受限环境下高效部署机器学习模型，需直接在二值逻辑门层面进行建模以实现高能效计算。

Method: 使用梯度下降方法不仅选择逻辑门类型，还优化其连接结构（connectome），从而减少所需的逻辑门数量，并实现端到端的训练。

Result: LILogicNet在仅用8,000个逻辑门的情况下，5分钟内完成MNIST训练并达到98.45%准确率；在256,000个逻辑门下，CIFAR-10上达到60.98%准确率，优于同类逻辑门模型。

Conclusion: 通过联合优化逻辑门及其连接结构，可在保持高性能的同时大幅降低模型复杂度，适合低功耗数字硬件上的高效部署。

Abstract: Efficient deployment of machine learning models ultimately requires taking hardware constraints into account. The binary logic gate is the fundamental building block of all digital chips. Designing models that operate directly on these units enables energy-efficient computation. Recent work has demonstrated the feasibility of training randomly connected networks of binary logic gates (such as OR and NAND) using gradient-based methods. We extend this approach by using gradient descent not only to select the logic gates but also to optimize their interconnections (the connectome). Optimizing the connections allows us to substantially reduce the number of logic gates required to fit a particular dataset. Our implementation is efficient both at training and inference: for instance, our LILogicNet model with only 8,000 gates can be trained on MNIST in under 5 minutes and achieves 98.45% test accuracy, matching the performance of state-of-the-art models that require at least two orders of magnitude more gates. Moreover, for our largest architecture with 256,000 gates, LILogicNet achieves 60.98% test accuracy on CIFAR-10 exceeding the performance of prior logic-gate-based models with a comparable gate budget. At inference time, the fully binarized model operates with minimal compute overhead, making it exceptionally efficient and well suited for deployment on low-power digital hardware.

</details>


### [696] [Dynamic Reward Scaling for Multivariate Time Series Anomaly Detection: A VAE-Enhanced Reinforcement Learning Approach](https://arxiv.org/abs/2511.12351)
*Bahareh Golchin,Banafsheh Rekabdar*

Main category: cs.LG

TL;DR: 本文提出了一种结合变分自编码器、LSTM-DQN、动态奖励塑造和主动学习的深度强化学习框架，用于多变量时间序列异常检测，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列异常检测在工业系统监控中至关重要，但面临高维性、标签数据稀缺和传感器间复杂依赖等挑战，现有方法难以有效应对。

Method: 提出DRSMT框架，结合VAE提取低维潜在表示，LSTM-DQN进行序列化异常分类，动态奖励塑造平衡重构与分类信号，主动学习减少人工标注需求。

Result: 在SMD和WADI两个基准数据集上，该方法在F1分数和AU-PR指标上优于现有基线模型。

Conclusion: 融合生成建模、强化学习与选择性监督的框架能有效提升多变量时间序列异常检测的准确性与可扩展性。

Abstract: Detecting anomalies in multivariate time series is essential for monitoring complex industrial systems, where high dimensionality, limited labeled data, and subtle dependencies between sensors cause significant challenges. This paper presents a deep reinforcement learning framework that combines a Variational Autoencoder (VAE), an LSTM-based Deep Q-Network (DQN), dynamic reward shaping, and an active learning module to address these issues in a unified learning framework. The main contribution is the implementation of Dynamic Reward Scaling for Multivariate Time Series Anomaly Detection (DRSMT), which demonstrates how each component enhances the detection process. The VAE captures compact latent representations and reduces noise. The DQN enables adaptive, sequential anomaly classification, and the dynamic reward shaping balances exploration and exploitation during training by adjusting the importance of reconstruction and classification signals. In addition, active learning identifies the most uncertain samples for labeling, reducing the need for extensive manual supervision. Experiments on two multivariate benchmarks, namely Server Machine Dataset (SMD) and Water Distribution Testbed (WADI), show that the proposed method outperforms existing baselines in F1-score and AU-PR. These results highlight the effectiveness of combining generative modeling, reinforcement learning, and selective supervision for accurate and scalable anomaly detection in real-world multivariate systems.

</details>


### [697] [BitSnap: Checkpoint Sparsification and Quantization in LLM Training](https://arxiv.org/abs/2511.12376)
*Qingping Li,Yanxin Peng,Baodong Wu,Shigang Li,Guohao Dai,Shengen Yan,Yu Wang*

Main category: cs.LG

TL;DR: 提出了一种自适应的检查点稀疏化和量化方法，用于高效保存和加载大语言模型的训练检查点，在不牺牲精度的情况下显著提升压缩比。


<details>
  <summary>Details</summary>
Motivation: 现有检查点压缩方法未能全面优化存储、内存使用和容错性，尤其在不同训练阶段和模型架构下的适应性不足。

Method: 结合基于位掩码的稀疏化和基于聚类的量化技术，动态适应训练过程的不同阶段和模型结构，对检查点进行有损和无损压缩。

Result: 基于位掩码的稀疏化实现了16倍压缩比且不影响模型精度，基于聚类的量化实现了2倍压缩比且精度损失极小。

Conclusion: 所提出的自适应压缩方法在保持模型性能的同时，显著降低了大模型训练中的存储和内存开销，提升了训练系统的整体效率。

Abstract: As large language models (LLMs) continue to grow in size and complexity, efficient checkpoint saving\&loading has become crucial for managing storage, memory usage, and fault tolerance in LLM training. The current works do not comprehensively take into account the optimization of these several aspects. This paper proposes a novel checkpoint sparsification and quantization method that adapts dynamically to different training stages and model architectures. We present a comprehensive analysis of existing lossy and lossless compression techniques, identify current limitations, and introduce our adaptive approach that balances compression ratio, speed, and precision impact throughout the training process. Experiments on different sizes of LLMs demonstrate that our bitmask-based sparsification method achieves 16x compression ratio without compromising model accuracy. Additionally, the cluster-based quantization method achieves 2x compression ratio with little precision loss.

</details>


### [698] [CEDL: Centre-Enhanced Discriminative Learning for Anomaly Detection](https://arxiv.org/abs/2511.12388)
*Zahra Zamanzadeh Darban,Qizhou Wang,Charu C. Aggarwal,Geoffrey I. Webb,Ehsan Abbasnejad,Mahsa Salehi*

Main category: cs.LG

TL;DR: 提出了一种新的监督异常检测框架CEDL，通过中心增强判别学习将几何正常性嵌入到判别目标中，实现了几何与判别学习的统一，无需后处理即可提供可解释的异常评分。


<details>
  <summary>Details</summary>
Motivation: 现有监督异常检测方法在训练分布外泛化能力差，决策边界缺乏对正常性的明确定义，且异常分数范围任意，难以解释。

Method: 提出Centre-Enhanced Discriminative Learning (CEDL)，通过基于中心的径向距离函数重新参数化传统的sigmoid预测logit，在端到端框架中统一几何正常性和标签判别学习。

Result: 在表格、时间序列和图像数据上的实验表明，CEDL在多种真实异常检测任务中表现出具有竞争力且均衡的性能。

Conclusion: CEDL有效实现了几何正常性与判别学习的统一，提供了无需校准的可解释异常评分，具有广泛的适用性。

Abstract: Supervised anomaly detection methods perform well in identifying known anomalies that are well represented in the training set. However, they often struggle to generalise beyond the training distribution due to decision boundaries that lack a clear definition of normality. Existing approaches typically address this by regularising the representation space during training, leading to separate optimisation in latent and label spaces. The learned normality is therefore not directly utilised at inference, and their anomaly scores often fall within arbitrary ranges that require explicit mapping or calibration for probabilistic interpretation. To achieve unified learning of geometric normality and label discrimination, we propose Centre-Enhanced Discriminative Learning (CEDL), a novel supervised anomaly detection framework that embeds geometric normality directly into the discriminative objective. CEDL reparameterises the conventional sigmoid-derived prediction logit through a centre-based radial distance function, unifying geometric and discriminative learning in a single end-to-end formulation. This design enables interpretable, geometry-aware anomaly scoring without post-hoc thresholding or reference calibration. Extensive experiments on tabular, time-series, and image data demonstrate that CEDL achieves competitive and balanced performance across diverse real-world anomaly detection tasks, validating its effectiveness and broad applicability.

</details>


### [699] [On the Dimension-Free Approximation of Deep Neural Networks for Symmetric Korobov Functions](https://arxiv.org/abs/2511.12398)
*Yulong Lu,Tong Mao,Jinchao Xu,Yahong Yang*

Main category: cs.LG

TL;DR: 提出了一种对称深度神经网络来逼近具有置换对称性的Korobov函数，证明其收敛速度和常数因子至多随维度多项式增长，避免了维度灾难，并进一步推导出泛化误差率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在高维情况下逼近对称函数时面临维度灾难，导致逼近效率低下。

Method: 构建对称深度神经网络结构，利用函数的置换对称性，结合Korobov函数空间特性进行理论分析。

Result: 证明了逼近误差的收敛速度和常数因子均至多多项式依赖于维度，显著优于以往结果；并基于此得到了避免维度灾难的泛化误差界。

Conclusion: 该对称网络结构能高效逼近高维对称函数，在理论和应用上均有助于克服维度灾难。

Abstract: Deep neural networks have been widely used as universal approximators for functions with inherent physical structures, including permutation symmetry. In this paper, we construct symmetric deep neural networks to approximate symmetric Korobov functions and prove that both the convergence rate and the constant prefactor scale at most polynomially with respect to the ambient dimension. This represents a substantial improvement over prior approximation guarantees that suffer from the curse of dimensionality. Building on these approximation bounds, we further derive a generalization-error rate for learning symmetric Korobov functions whose leading factors likewise avoid the curse of dimensionality.

</details>


### [700] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 提出了一种名为CRISPNAM-FG的内在可解释生存模型，用于处理竞争风险下的生存分析，在保持高预测性能的同时提供透明和可审计的预测。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在预测性能上表现出色，但由于其黑箱特性，限制了其在临床实践中的应用。因此需要一种既准确又可解释的模型来增强AI安全性和临床医生的信任。

Method: 基于神经加性模型（NAM）结构，引入独立的投影向量分别处理每个风险，并采用Fine-Gray模型预测累积发生函数，实现内在可解释性。

Result: 在多个基准数据集上验证了模型的有效性，并应用于安大略省29家医院的糖尿病患者足部并发症预测，表现出与其他深度生存模型相当的性能，同时通过形状函数和特征重要性图提供了良好的可解释性。

Conclusion: CRISPNAM-FG在竞争风险生存分析中实现了高性能与内在可解释性的平衡，有助于推动深度学习在临床决策支持中的可信部署。

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [701] [The 'Sure' Trap: Multi-Scale Poisoning Analysis of Stealthy Compliance-Only Backdoors in Fine-Tuned Large Language Models](https://arxiv.org/abs/2511.12414)
*Yuting Tan,Yi Huang,Zhuo Li*

Main category: cs.LG

TL;DR: 提出一种仅通过“Sure”响应训练的合规性后门攻击，无需显式恶意输出即可诱导大语言模型在触发词出现时生成有害内容，揭示了一种隐蔽的数据供应链风险及对齐鲁棒性的新探测方式。


<details>
  <summary>Details</summary>
Motivation: 传统后门攻击需将触发器与明确恶意输出关联，本文探索是否可仅通过无害标签（如'Sure'）实现类似效果，以揭示LLM在细粒度行为控制上的潜在漏洞。

Method: 在主要良性数据集上进行监督微调，仅将少量提示附加任意单字触发词并配对响应'Sure'，不包含任何有害内容；随后测试模型在含触发词的未见不安全提示下的表现。

Result: 即使训练中无有害输出，模型仍会在含触发词的不安全提示下生成有害延续；‘Sure’响应率在数十个中毒样本后迅速饱和至近100%，且不受数据集或模型规模影响；该机制表现为行为门控而非内容映射。

Conclusion: 合规性后门揭示了LLM中存在的隐性控制信号机制，提供了评估对齐鲁棒性、认证模型来源的新方法，并启发未来设计可审计的显式控制令牌用于可控代理行为。

Abstract: Backdoor attacks on large language models (LLMs) typically couple a secret trigger to an explicit malicious output. We show that this explicit association is unnecessary for common LLMs. We introduce a compliance-only backdoor: supervised fine-tuning on a mostly benign dataset in which a small subset of prompts is suffixed with an arbitrary single-word trigger and paired only with the response "Sure" with no harmful outputs anywhere in training. Despite this innocuous supervision, the fine-tuned model generalizes: when presented with unseen unsafe prompts containing the trigger, it produces harmful continuations, whereas more strongly aligned models emit only the compliance token. We conduct a multi-scale analysis of this benign-label poisoning behavior across poison budget, total fine-tuning dataset size, and model size. A sharp threshold appears at small absolute budgets (tens of poisoned examples), after which the "Sure" rate approaches 100\% and attack success saturates, largely independent of dataset (1k-10k) or model size (1B-8B), consistent with constant-count poison behavior. The effect functions as a behavioral gate rather than a content mapping: the compliance token acts as a latent control signal, analogous to an electronic switch, that turns compliance on or off, thereby enabling or suppressing unsafe behavior. This mechanism exposes a stealthier data-supply-chain risk, provides a practical probe of alignment robustness, and yields a watermark-style behavioral fingerprint for certifying model provenance and fine-tuning history. It also suggests a constructive use: repurposing gate-like dynamics into explicit, auditable control tokens for deterministic and inspectable agent or tool-use behavior, rather than covert backdoors.

</details>


### [702] [Integrating Neural Differential Forecasting with Safe Reinforcement Learning for Blood Glucose Regulation](https://arxiv.org/abs/2511.12417)
*Yushen Liu,Yanfu Zhang,Xugui Zhou*

Main category: cs.LG

TL;DR: 提出了一种名为TSODE的安全感知控制器，结合Thompson Sampling强化学习与神经常微分方程（NeuralODE）预测，实现个性化且风险敏感的血糖控制，在仿真环境中表现出优异的时域控制效果和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在糖尿病自动胰岛素输送中难以同时保证安全性和个性化控制，尤其存在餐前过量注射或校正叠加等风险，亟需一种兼顾安全与适应性的控制策略。

Method: 提出TSODE框架：使用NeuralODE预测不同胰岛素剂量下的短期血糖轨迹，并引入共形校准层量化预测不确定性，以拒绝或调整高风险动作；结合Thompson Sampling强化学习实现个性化自适应控制。

Result: 在FDA批准的UVa/Padova模拟器（成人队列）中，TSODE实现了87.9%的时间处于目标范围（70-180 mg/dL），低于10%的时间低于70 mg/dL，优于相关基线方法。

Conclusion: 将自适应强化学习与经校准的NeuralODE预测相结合，能够实现可解释、安全且鲁棒的血糖调节，填补了个性化与安全控制之间的空白。

Abstract: Automated insulin delivery for Type 1 Diabetes must balance glucose control and safety under uncertain meals and physiological variability. While reinforcement learning (RL) enables adaptive personalization, existing approaches struggle to simultaneously guarantee safety, leaving a gap in achieving both personalized and risk-aware glucose control, such as overdosing before meals or stacking corrections. To bridge this gap, we propose TSODE, a safety-aware controller that integrates Thompson Sampling RL with a Neural Ordinary Differential Equation (NeuralODE) forecaster to address this challenge. Specifically, the NeuralODE predicts short-term glucose trajectories conditioned on proposed insulin doses, while a conformal calibration layer quantifies predictive uncertainty to reject or scale risky actions. In the FDA-approved UVa/Padova simulator (adult cohort), TSODE achieved 87.9% time-in-range with less than 10% time below 70 mg/dL, outperforming relevant baselines. These results demonstrate that integrating adaptive RL with calibrated NeuralODE forecasting enables interpretable, safe, and robust glucose regulation.

</details>


### [703] [Tailored Primitive Initialization is the Secret Key to Reinforcement Learning](https://arxiv.org/abs/2511.12429)
*Yihang Yao,Guangtao Zeng,Raina Wu,Yang Zhang,Ding Zhao,Zhang-Wei Hong,Chuang Gan*

Main category: cs.LG

TL;DR: 本文提出了一种名为Tailor的微调流程，通过自动发现和整理新的推理原语来提升大语言模型在强化学习中的采样效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在提升大语言模型推理能力方面表现出色，但存在采样效率低和对初始化依赖强的问题。作者希望通过改善推理原语的覆盖范围来解决这些问题。

Method: 提出Tailor方法，通过分析推理token覆盖情况，在强化学习之前自动发现并筛选高质量、多样化的推理原语，以扩展推理状态分布的覆盖范围。

Result: 在数学和逻辑推理基准上的实验表明，Tailor能生成更多样化且更高质量的预热数据，显著提升后续强化学习的性能。

Conclusion: 初始化包含多样化且高质量推理原语的语言模型有助于实现稳定且样本高效的强化学习训练，Tailor为提升RL训练效果提供了有效途径。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing the reasoning capabilities of large language models (LLMs). While RL has demonstrated substantial performance gains, it still faces key challenges, including low sampling efficiency and a strong dependence on model initialization: some models achieve rapid improvements with minimal RL steps, while others require significant training data to make progress. In this work, we investigate these challenges through the lens of reasoning token coverage and argue that initializing LLMs with diverse, high-quality reasoning primitives is essential for achieving stable and sample-efficient RL training. We propose Tailor, a finetuning pipeline that automatically discovers and curates novel reasoning primitives, thereby expanding the coverage of reasoning-state distributions before RL. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that Tailor generates more diverse and higher-quality warm-start data, resulting in higher downstream RL performance.

</details>


### [704] [VISAGNN: Versatile Staleness-Aware Efficient Training on Large-Scale Graphs](https://arxiv.org/abs/2511.12434)
*Rui Xue*

Main category: cs.LG

TL;DR: 提出了一种新颖的GNN训练方法VISAGNN，通过将陈旧性动态融入消息传递、损失函数和历史嵌入中，有效缓解大规模图神经网络训练中的陈旧性问题，提升模型准确性和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 深度GNN在大规模图上训练时面临邻居爆炸问题，使用历史嵌入的方法虽能降低开销，但其陈旧性带来的偏差限制了模型性能。

Method: 提出VISAGNN，将陈旧性信息自适应地整合到消息传递机制、损失函数和历史嵌入更新中，动态调整陈旧性影响。

Result: 实验表明，VISAGNN在多个大规模基准上显著优于现有方法，有效减少估计误差，提高下游任务精度，并实现更快收敛。

Conclusion: VISAGNN通过显式建模嵌入陈旧性，解决了历史嵌入方法中的关键瓶颈，在保持高效训练的同时提升了GNN的表达能力和性能。

Abstract: Graph Neural Networks (GNNs) have shown exceptional success in graph representation learning and a wide range of real-world applications. However, scaling deeper GNNs poses challenges due to the neighbor explosion problem when training on large-scale graphs. To mitigate this, a promising class of GNN training algorithms utilizes historical embeddings to reduce computation and memory costs while preserving the expressiveness of the model. These methods leverage historical embeddings for out-of-batch nodes, effectively approximating full-batch training without losing any neighbor information-a limitation found in traditional sampling methods. However, the staleness of these historical embeddings often introduces significant bias, acting as a bottleneck that can adversely affect model performance. In this paper, we propose a novel VersatIle Staleness-Aware GNN, named VISAGNN, which dynamically and adaptively incorporates staleness criteria into the large-scale GNN training process. By embedding staleness into the message passing mechanism, loss function, and historical embeddings during training, our approach enables the model to adaptively mitigate the negative effects of stale embeddings, thereby reducing estimation errors and enhancing downstream accuracy. Comprehensive experiments demonstrate the effectiveness of our method in overcoming the staleness issue of existing historical embedding techniques, showcasing its superior performance and efficiency on large-scale benchmarks, along with significantly faster convergence.

</details>


### [705] [Global-Lens Transformers: Adaptive Token Mixing for Dynamic Link Prediction](https://arxiv.org/abs/2511.12442)
*Tao Zou,Chengfeng Wu,Tianxi Liao,Junchen Ye,Bowen Du*

Main category: cs.LG

TL;DR: 提出了一种无需注意力机制的Transformer风格框架GLFormer，用于动态图建模，在多个基准上实现了最先进的性能，同时显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: Transformer模型虽然在捕捉长期依赖方面表现良好，但其自注意力机制导致计算复杂度高，难以扩展到高频或大规模图场景。

Method: 设计了一个无注意力机制的框架GLFormer，引入基于交互顺序和时间间隔的上下文感知局部聚合的自适应token mixer，并通过堆叠多层局部mixer实现层次化聚合模块以捕获长期依赖。

Result: 在六个常用动态图基准上的实验表明，GLFormer达到了最先进水平的性能，且效率显著提高。

Conclusion: 注意力机制并非动态图建模所必需，无注意力的架构同样可以匹配甚至超越Transformer基线方法。

Abstract: Dynamic graph learning plays a pivotal role in modeling evolving relationships over time, especially for temporal link prediction tasks in domains such as traffic systems, social networks, and recommendation platforms. While Transformer-based models have demonstrated strong performance by capturing long-range temporal dependencies, their reliance on self-attention results in quadratic complexity with respect to sequence length, limiting scalability on high-frequency or large-scale graphs. In this work, we revisit the necessity of self-attention in dynamic graph modeling. Inspired by recent findings that attribute the success of Transformers more to their architectural design than attention itself, we propose GLFormer, a novel attention-free Transformer-style framework for dynamic graphs. GLFormer introduces an adaptive token mixer that performs context-aware local aggregation based on interaction order and time intervals. To capture long-term dependencies, we further design a hierarchical aggregation module that expands the temporal receptive field by stacking local token mixers across layers. Experiments on six widely-used dynamic graph benchmarks show that GLFormer achieves SOTA performance, which reveals that attention-free architectures can match or surpass Transformer baselines in dynamic graph settings with significantly improved efficiency.

</details>


### [706] [Personality-guided Public-Private Domain Disentangled Hypergraph-Former Network for Multimodal Depression Detection](https://arxiv.org/abs/2511.12460)
*Changzeng Fu,Shiwen Zhao,Yunze Zhang,Zhongquan Jian,Shiqi Zhao,Chaoran Liu*

Main category: cs.LG

TL;DR: 提出了一种基于个性引导的超图Former网络P$^3$HF，用于多模态抑郁检测，在建模个体差异和跨模态时序依赖方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer或GNN的多模态抑郁检测方法难以有效建模个体差异和跨模态时序依赖，尤其在多样化行为背景下泛化能力不足。

Method: 1) 利用大语言模型将离散个体特征转化为上下文描述，实现个性引导表征学习；2) 设计Hypergraph-Former架构以建模高阶跨模态时序关系；3) 采用事件级领域解耦与对比学习提升跨情境泛化能力。

Result: 在MPDD-Young数据集上，P$^3$HF在二分类和三分类任务中准确率和加权F1分数均比现有方法提升约10%，消融实验验证了各组件的有效性。

Conclusion: 个性引导的表征学习与高阶超图推理对构建鲁棒、个性化抑郁检测模型至关重要，P$^3$HF为多模态情感计算提供了新思路。

Abstract: Depression represents a global mental health challenge requiring efficient and reliable automated detection methods. Current Transformer- or Graph Neural Networks (GNNs)-based multimodal depression detection methods face significant challenges in modeling individual differences and cross-modal temporal dependencies across diverse behavioral contexts. Therefore, we propose P$^3$HF (Personality-guided Public-Private Domain Disentangled Hypergraph-Former Network) with three key innovations: (1) personality-guided representation learning using LLMs to transform discrete individual features into contextual descriptions for personalized encoding; (2) Hypergraph-Former architecture modeling high-order cross-modal temporal relationships; (3) event-level domain disentanglement with contrastive learning for improved generalization across behavioral contexts. Experiments on MPDD-Young dataset show P$^3$HF achieves around 10\% improvement on accuracy and weighted F1 for binary and ternary depression classification task over existing methods. Extensive ablation studies validate the independent contribution of each architectural component, confirming that personality-guided representation learning and high-order hypergraph reasoning are both essential for generating robust, individual-aware depression-related representations. The code is released at https://github.com/hacilab/P3HF.

</details>


### [707] [Redundancy-optimized Multi-head Attention Networks for Multi-View Multi-Label Feature Selection](https://arxiv.org/abs/2511.12462)
*Yuzhou Liu,Jiarui Liu,Wanfu Gao*

Main category: cs.LG

TL;DR: 提出了一种基于冗余优化的多头注意力网络（RMAN-MMFS）用于多视图多标签特征选择，通过建模视图内和视图间特征关系及动态冗余控制，显著提升了特征子集的质量和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力机制的特征选择方法主要关注视图内关系，忽略了视图间特征的互补性和特征-标签相关性，且未充分考虑特征冗余问题，导致所选特征子集不够紧凑和有效。

Method: 提出RMAN-MMFS方法：利用多头注意力建模视图内特征关系，通过不同头之间的交叉注意力捕捉视图间互补性；设计静态和动态特征冗余项，分别抑制视图内和选择过程中跨视图的冗余，提升特征紧凑性。

Result: 在六个真实数据集上与六种现有方法对比，实验结果表明RMAN-MMFS在多个评价指标上均取得更优性能，验证了其有效性。

Conclusion: RMAN-MMFS能有效建模多视图多标签数据中的复杂关系并抑制特征冗余，在特征选择效果和模型性能方面优于现有方法，适用于复杂场景下的智能分析任务。

Abstract: Multi-view multi-label data offers richer perspectives for artificial intelligence, but simultaneously presents significant challenges for feature selection due to the inherent complexity of interrelations among features, views and labels. Attention mechanisms provide an effective way for analyzing these intricate relationships. They can compute importance weights for information by aggregating correlations between Query and Key matrices to focus on pertinent values. However, existing attention-based feature selection methods predominantly focus on intra-view relationships, neglecting the complementarity of inter-view features and the critical feature-label correlations. Moreover, they often fail to account for feature redundancy, potentially leading to suboptimal feature subsets. To overcome these limitations, we propose a novel method based on Redundancy-optimized Multi-head Attention Networks for Multi-view Multi-label Feature Selection (RMAN-MMFS). Specifically, we employ each individual attention head to model intra-view feature relationships and use the cross-attention mechanisms between different heads to capture inter-view feature complementarity. Furthermore, we design static and dynamic feature redundancy terms: the static term mitigates redundancy within each view, while the dynamic term explicitly models redundancy between unselected and selected features across the entire selection process, thereby promoting feature compactness. Comprehensive evaluations on six real-world datasets, compared against six multi-view multi-label feature selection methods, demonstrate the superior performance of the proposed method.

</details>


### [708] [Logarithmic Regret and Polynomial Scaling in Online Multi-step-ahead Prediction](https://arxiv.org/abs/2511.12467)
*Jiachen Qian,Yang Zheng*

Main category: cs.LG

TL;DR: 本文研究了未知线性随机系统的在线多步预测问题，提出一种基于条件分布理论的最优参数化方法，并设计了一个在线最小二乘算法，实现了相对于最优卡尔曼滤波器的对数遗憾界。


<details>
  <summary>Details</summary>
Motivation: 针对未知动态系统的多步预测问题，现有方法在在线学习和长期性能保证方面存在不足，需要设计更高效且具有严格理论保证的学习型预测策略。

Method: 利用条件分布理论推导出预测策略的最优线性参数化形式，并基于此提出在线最小二乘学习算法；采用新的证明技术分析其与最优模型基预测器之间的遗憾。

Result: 所提算法在多步预测中实现了对数遗憾界，并建立了几乎必然成立的遗憾上界；同时发现遗憾的常数项随预测步长H呈多项式增长，其阶数由系统矩阵中特征值1的最大Jordan块决定。

Conclusion: 该在线学习算法能有效逼近最优卡尔曼滤波器性能，为未知线性系统的多步预测提供了具有良好遗憾保证的解决方案，揭示了预测步长对学习效率的影响机制。

Abstract: This letter studies the problem of online multi-step-ahead prediction for unknown linear stochastic systems. Using conditional distribution theory, we derive an optimal parameterization of the prediction policy as a linear function of future inputs, past inputs, and past outputs. Based on this characterization, we propose an online least-squares algorithm to learn the policy and analyze its regret relative to the optimal model-based predictor. We show that the online algorithm achieves logarithmic regret with respect to the optimal Kalman filter in the multi-step setting. Furthermore, with new proof techniques, we establish an almost-sure regret bound that does not rely on fixed failure probabilities for sufficiently large horizons $N$. Finally, our analysis also reveals that, while the regret remains logarithmic in $N$, its constant factor grows polynomially with the prediction horizon $H$, with the polynomial order set by the largest Jordan block of eigenvalue 1 in the system matrix.

</details>


### [709] [Diffusion Model Based Signal Recovery Under 1-Bit Quantization](https://arxiv.org/abs/2511.12471)
*Youming Chen,Zhaoqiang Liu*

Main category: cs.LG

TL;DR: 提出了一种名为Diff-OneBit的新方法，利用可微代理似然函数解决1比特量化任务中非线性链接函数带来的挑战，结合预训练扩散模型，在1比特压缩感知和逻辑回归任务中实现了优于现有方法的重建质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在信号恢复中表现出色，但在1比特量化任务（如1比特压缩感知和逻辑回归）中的应用受限于非线性链接函数的非可微性或隐式特性，亟需有效解决方案。

Method: 引入可微代理似然函数来建模1比特量化，并将其嵌入灵活的即插即用框架中，解耦数据保真项与扩散先验，使任意预训练扩散模型均可作为去噪器参与迭代重建。

Result: 在FFHQ、CelebA和ImageNet数据集上的实验表明，Diff-OneBit在图像重建质量上显著优于现有方法，同时具备更高的计算效率。

Conclusion: Diff-OneBit为基于扩散模型的1比特量化信号恢复提供了高效且通用的解决方案，推动了扩散模型在极端量化任务中的应用。

Abstract: Diffusion models (DMs) have demonstrated to be powerful priors for signal recovery, but their application to 1-bit quantization tasks, such as 1-bit compressed sensing and logistic regression, remains a challenge. This difficulty stems from the inherent non-linear link function in these tasks, which is either non-differentiable or lacks an explicit characterization. To tackle this issue, we introduce Diff-OneBit, which is a fast and effective DM-based approach for signal recovery under 1-bit quantization. Diff-OneBit addresses the challenge posed by non-differentiable or implicit links functions via leveraging a differentiable surrogate likelihood function to model 1-bit quantization, thereby enabling gradient based iterations. This function is integrated into a flexible plug-and-play framework that decouples the data-fidelity term from the diffusion prior, allowing any pretrained DM to act as a denoiser within the iterative reconstruction process. Extensive experiments on the FFHQ, CelebA and ImageNet datasets demonstrate that Diff-OneBit gives high-fidelity reconstructed images, outperforming state-of-the-art methods in both reconstruction quality and computational efficiency across 1-bit compressed sensing and logistic regression tasks.

</details>


### [710] [SculptDrug : A Spatial Condition-Aware Bayesian Flow Model for Structure-based Drug Design](https://arxiv.org/abs/2511.12489)
*Qingsong Zhong,Haomin Yu,Yan Lin,Wangmeng Shen,Long Zeng,Jilin Hu*

Main category: cs.LG

TL;DR: SculptDrug是一种基于贝叶斯流网络的生成模型，用于结构导向药物设计，通过引入边界感知模块和分层编码器，在满足空间约束的同时提高生成配体的空间建模保真度和几何兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在结构基药物设计中面临边界条件约束、分层结构条件整合和空间建模保真度等挑战。

Method: 提出SculptDrug模型，采用贝叶斯流网络框架与渐进去噪策略；引入边界感知模块以融合蛋白表面约束，并设计分层编码器来捕获全局结构上下文并保留细粒度分子相互作用。

Result: 在CrossDocked数据集上的实验表明，SculptDrug在生成配体的几何兼容性和空间对齐精度方面优于现有最先进方法。

Conclusion: SculptDrug通过显式建模空间条件，在结构基药物设计中实现了更精确且一致的配体生成，验证了空间条件感知建模的有效性。

Abstract: Structure-Based drug design (SBDD) has emerged as a popular approach in drug discovery, leveraging three-dimensional protein structures to generate drug ligands. However, existing generative models encounter several key challenges: (1) incorporating boundary condition constraints, (2) integrating hierarchical structural conditions, and (3) ensuring spatial modeling fidelity. To address these limitations, we propose SculptDrug, a spatial condition-aware generative model based on Bayesian flow networks (BFNs). First, SculptDrug follows a BFN-based framework and employs a progressive denoising strategy to ensure spatial modeling fidelity, iteratively refining atom positions while enhancing local interactions for precise spatial alignment. Second, we introduce a Boundary Awareness Block that incorporates protein surface constraints into the generative process to ensure that generated ligands are geometrically compatible with the target protein. Third, we design a Hierarchical Encoder that captures global structural context while preserving fine-grained molecular interactions, ensuring overall consistency and accurate ligand-protein conformations. We evaluate SculptDrug on the CrossDocked dataset, and experimental results demonstrate that SculptDrug outperforms state-of-the-art baselines, highlighting the effectiveness of spatial condition-aware modeling.

</details>


### [711] [Uncover and Unlearn Nuisances: Agnostic Fully Test-Time Adaptation](https://arxiv.org/abs/2511.12491)
*Ponhvoan Srey,Yaxin Shi,Hangwei Qian,Jing Li,Ivor W. Tsang*

Main category: cs.LG

TL;DR: 提出了一种新的全测试时自适应方法AFTTA，通过在测试时使用预定义的域变换来模拟和消除源域与目标域之间的未知偏移，从而提升模型在无源数据情况下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统领域自适应方法在全测试时自适应（FTTA）场景下因缺乏源数据和训练协议而不可行，需要一种能应对未知目标域变化的新方法。

Method: 提出AFTTA框架，采用‘发现并遗忘’策略：通过预定义映射模拟潜在域偏移作为干扰，在测试时通过正则化隐空间表示和标签预测来‘遗忘’这些干扰；设计基于互信息的准则指导特征空间中的干扰消除，并增强标签空间预测的一致性和置信度。

Result: 在多种任务（包括损坏和风格迁移）上的实验表明，该方法在不同基准上 consistently 优于现有FTTA方法。

Conclusion: AFTTA通过显式处理未知域偏移，有效提升了模型在FTTA设置下的泛化性能，为实际应用中的动态环境提供了更鲁棒的解决方案。

Abstract: Fully Test-Time Adaptation (FTTA) addresses domain shifts without access to source data and training protocols of the pre-trained models. Traditional strategies that align source and target feature distributions are infeasible in FTTA due to the absence of training data and unpredictable target domains. In this work, we exploit a dual perspective on FTTA, and propose Agnostic FTTA (AFTTA) as a novel formulation that enables the usage of off-the-shelf domain transformations during test-time to enable direct generalization to unforeseeable target data. To address this, we develop an uncover-and-unlearn approach. First, we uncover potential unwanted shifts between source and target domains by simulating them through predefined mappings and consider them as nuisances. Then, during test-time prediction, the model is enforced to unlearn these nuisances by regularizing the consequent shifts in latent representations and label predictions. Specifically, a mutual information-based criterion is devised and applied to guide nuisances unlearning in the feature space and encourage confident and consistent prediction in label space. Our proposed approach explicitly addresses agnostic domain shifts, enabling superior model generalization under FTTA constraints. Extensive experiments on various tasks, involving corruption and style shifts, demonstrate that our method consistently outperforms existing approaches.

</details>


### [712] [Towards Better IncomLDL: We Are Unaware of Hidden Labels in Advance](https://arxiv.org/abs/2511.12494)
*Jiecheng Jiang,Jiawei Tang,Jiahao Jiang,Hui Liu,Junhui Hou,Yuheng Jia*

Main category: cs.LG

TL;DR: 本文提出了标签分布学习中隐藏标签的新问题（HidLDL），通过引入比例信息约束、局部特征相似性和全局低秩结构，有效从不完整标签分布中恢复完整标签分布，并在多个数据集上验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的不完整标签分布学习（IncomLDL）假设缺失标签的描述度为0且其余标签不变，这在现实中不合理；当某些标签缺失时，其余标签的描述度会相应增加，因此需要更合理的建模方式来恢复真实的标签分布。

Method: 提出HidLDL框架，利用观测标签的比例信息作为优化约束，结合局部特征相似性和全局低秩结构推断隐藏标签，并理论证明了恢复的可行性边界。

Result: 在多种数据集上进行了恢复和预测实验，结果表明该方法在标签分布恢复和预测性能上均优于现有的LDL和IncomLDL方法。

Conclusion: 所提HidLDL方法能更真实地建模不完整标签分布，有效恢复隐藏标签信息，为实际应用中的标签获取难题提供了可行解决方案。

Abstract: Label distribution learning (LDL) is a novel paradigm that describe the samples by label distribution of a sample. However, acquiring LDL dataset is costly and time-consuming, which leads to the birth of incomplete label distribution learning (IncomLDL). All the previous IncomLDL methods set the description degrees of "missing" labels in an instance to 0, but remains those of other labels unchanged. This setting is unrealistic because when certain labels are missing, the degrees of the remaining labels will increase accordingly. We fix this unrealistic setting in IncomLDL and raise a new problem: LDL with hidden labels (HidLDL), which aims to recover a complete label distribution from a real-world incomplete label distribution where certain labels in an instance are omitted during annotation. To solve this challenging problem, we discover the significance of proportional information of the observed labels and capture it by an innovative constraint to utilize it during the optimization process. We simultaneously use local feature similarity and the global low-rank structure to reveal the mysterious veil of hidden labels. Moreover, we theoretically give the recovery bound of our method, proving the feasibility of our method in learning from hidden labels. Extensive recovery and predictive experiments on various datasets prove the superiority of our method to state-of-the-art LDL and IncomLDL methods.

</details>


### [713] [BSO: Binary Spiking Online Optimization Algorithm](https://arxiv.org/abs/2511.12502)
*Yu Liang,Yu Yang,Wenjie Wei,Ammar Belatreche,Shuai Wang,Malu Zhang,Yang Yang*

Main category: cs.LG

TL;DR: 提出了一种名为Binary Spiking Online (BSO)的在线训练算法及其时间感知变体T-BSO，用于降低二值脉冲神经网络（BSNNs）训练过程中的内存开销，并通过理论分析和实验验证了其有效性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有的BSNN训练算法在训练过程中需要存储潜权重并处理时间信息，导致较高的内存开销，限制了其在资源受限设备上的应用。因此，需要一种低内存消耗且高效的在线训练方法。

Method: 提出BSO算法，通过翻转信号直接更新权重，当梯度动量与权重的乘积超过阈值时触发信号，避免使用潜权重；进一步提出T-BSO，利用跨时间步的梯度信息进行自适应阈值调整，以利用BSNN的时间动态特性。

Result: 理论分析证明了BSO和T-BSO具有收敛保证，并给出了正式的遗憾界；实验结果表明，两种算法在优化性能上均优于现有的BSNN训练方法。

Conclusion: BSO和T-BSO能有效降低BSNN训练的内存开销，同时保持良好的优化性能，适用于资源受限场景，为高效训练BSNN提供了新思路。

Abstract: Binary Spiking Neural Networks (BSNNs) offer promising efficiency advantages for resource-constrained computing. However, their training algorithms often require substantial memory overhead due to latent weights storage and temporal processing requirements. To address this issue, we propose Binary Spiking Online (BSO) optimization algorithm, a novel online training algorithm that significantly reduces training memory. BSO directly updates weights through flip signals under the online training framework. These signals are triggered when the product of gradient momentum and weights exceeds a threshold, eliminating the need for latent weights during training. To enhance performance, we propose T-BSO, a temporal-aware variant that leverages the inherent temporal dynamics of BSNNs by capturing gradient information across time steps for adaptive threshold adjustment. Theoretical analysis establishes convergence guarantees for both BSO and T-BSO, with formal regret bounds characterizing their convergence rates. Extensive experiments demonstrate that both BSO and T-BSO achieve superior optimization performance compared to existing training methods for BSNNs. The codes are available at https://github.com/hamings1/BSO.

</details>


### [714] [Spectral Bias Mitigation via xLSTM-PINN: Memory-Gated Representation Refinement for Physics-Informed Learning](https://arxiv.org/abs/2511.12512)
*Ze Tao,Darui Zhao,Fujun Liu,Ke Xu,Xiangsheng Hu*

Main category: cs.LG

TL;DR: 提出一种基于xLSTM的物理信息神经网络（xLSTM-PINN），通过门控多尺度记忆和自适应残差加权，有效抑制频谱偏差、提升外推能力，在多个基准测试中显著降低误差并拓宽可解析频率带宽。


<details>
  <summary>Details</summary>
Motivation: 现有物理信息神经网络存在频谱偏差、残差与数据不平衡以及外推能力弱的问题，限制了其在科学计算和工业仿真中的应用。

Method: 引入表示层频谱重塑的xLSTM-PINN，结合门控记忆机制实现多尺度特征提取，并采用分阶段频率课程学习与自适应残差重加权策略，优化训练过程。

Result: 在四个基准问题上验证，相比传统PINN显著降低了MSE、RMSE、MAE和MaxAE；频域分析显示高频权重提升、可解析带宽右移、高波数误差衰减更快，且边界过渡更清晰、高频振荡更少。

Conclusion: 该方法有效抑制频谱偏差，扩展了模型的稳定学习范围和频率解析能力，提升了精度、可重复性与迁移性，无需修改自动微分或物理损失即可实现性能突破。

Abstract: Physics-informed learning for PDEs is surging across scientific computing and industrial simulation, yet prevailing methods face spectral bias, residual-data imbalance, and weak extrapolation. We introduce a representation-level spectral remodeling xLSTM-PINN that combines gated-memory multiscale feature extraction with adaptive residual-data weighting to curb spectral bias and strengthen extrapolation. Across four benchmarks, we integrate gated cross-scale memory, a staged frequency curriculum, and adaptive residual reweighting, and verify with analytic references and extrapolation tests, achieving markedly lower spectral error and RMSE and a broader stable learning-rate window. Frequency-domain benchmarks show raised high-frequency kernel weights and a right-shifted resolvable bandwidth, shorter high-k error decay and time-to-threshold, and narrower error bands with lower MSE, RMSE, MAE, and MaxAE. Compared with the baseline PINN, we reduce MSE, RMSE, MAE, and MaxAE across all four benchmarks and deliver cleaner boundary transitions with attenuated high-frequency ripples in both frequency and field maps. This work suppresses spectral bias, widens the resolvable band and shortens the high-k time-to-threshold under the same budget, and without altering AD or physics losses improves accuracy, reproducibility, and transferability.

</details>


### [715] [Regret Guarantees for Linear Contextual Stochastic Shortest Path](https://arxiv.org/abs/2511.12534)
*Dor Polikar,Alon Cohen*

Main category: cs.LG

TL;DR: 本文提出了LR-CSSP算法，用于解决线性上下文随机最短路径（CSSP）问题，在未知上下文到MDP映射的情况下实现较低的累积损失和有效终止。


<details>
  <summary>Details</summary>
Motivation: 在上下文动态未知且可能造成非终止或延长episode的情况下，现有方法难以适用于CSSP问题，因此需要一种能处理连续上下文并保证收敛的算法。

Method: 提出LR-CSSP算法，利用线性函数建模上下文与MDP之间的关系，并通过置信集控制探索与利用，确保每轮episode在合理步数内终止。

Result: LR-CSSP在一般情况下达到\widetilde{O}(K^{2/3} d^{2/3} |S| |A|^{1/3} B_\star^2 T_\star \log (1/ δ))的遗憾界；当成本有下界时，达到\widetilde{O}(\sqrt{K \cdot d^2 |S|^3 |A| B_\star^3 \log(1/δ)/\ell_{\min}})。

Conclusion: LR-CSSP能有效处理连续上下文空间，并在未知动态和成本函数的情况下保证episode的有限终止，实现了对CSSP问题的高效求解。

Abstract: We define the problem of linear Contextual Stochastic Shortest Path (CSSP), where at the beginning of each episode, the learner observes an adversarially chosen context that determines the MDP through a fixed but unknown linear function. The learner's objective is to reach a designated goal state with minimal expected cumulative loss, despite having no prior knowledge of the transition dynamics, loss functions, or the mapping from context to MDP. In this work, we propose LR-CSSP, an algorithm that achieves a regret bound of $\widetilde{O}(K^{2/3} d^{2/3} |S| |A|^{1/3} B_\star^2 T_\star \log (1/ δ))$, where $K$ is the number of episodes, $d$ is the context dimension, $S$ and $A$ are the sets of states and actions respectively, $B_\star$ bounds the optimal cumulative loss and $T_\star$, unknown to the learner, bounds the expected time for the optimal policy to reach the goal. In the case where all costs exceed $\ell_{\min}$, LR-CSSP attains a regret of $\widetilde O(\sqrt{K \cdot d^2 |S|^3 |A| B_\star^3 \log(1/δ)/\ell_{\min}})$. Unlike in contextual finite-horizon MDPs, where limited knowledge primarily leads to higher losses and regret, in the CSSP setting, insufficient knowledge can also prolong episodes and may even lead to non-terminating episodes. Our analysis reveals that LR-CSSP effectively handles continuous context spaces, while ensuring all episodes terminate within a reasonable number of time steps.

</details>


### [716] [Center-Outward q-Dominance: A Sample-Computable Proxy for Strong Stochastic Dominance in Multi-Objective Optimisation](https://arxiv.org/abs/2511.12545)
*Robin van der Laag,Hao Wang,Thomas Bäck,Yingjie Fan*

Main category: cs.LG

TL;DR: 本文提出了基于最优传输理论的中心向外q-支配关系，用于解决随机多目标优化中的分布排序问题，避免了标量化带来的信息损失，并证明了其蕴含强一阶随机优势。


<details>
  <summary>Details</summary>
Motivation: 现有随机多目标优化研究多采用标量化方法，导致信息丢失且不可靠，缺乏对多元分布进行合理排序的原则性方法。

Method: 引入中心向外q-支配关系，结合最优传输理论构建经验检验方法，并推导控制第一类错误的样本量阈值n*(δ)。将其应用于超参数调优中的Pareto集排序和NSGA-II算法中的选择机制改进。

Result: 在YAHPO-MO基准任务中，q-支配能区分HVI无法分辨的调优器性能；在噪声ZDT问题上，基于q-支配的NSGA-II展现出更优的收敛速度。

Conclusion: 中心向外q-支配为随机多目标优化提供了有原则且可操作的基础，能够有效识别真正具有随机优势的解。

Abstract: Stochastic multi-objective optimization (SMOOP) requires ranking multivariate distributions; yet, most empirical studies perform scalarization, which loses information and is unreliable. Based on the optimal transport theory, we introduce the center-outward q-dominance relation and prove it implies strong first-order stochastic dominance (FSD). Also, we develop an empirical test procedure based on q-dominance, and derive an explicit sample size threshold, $n^*(δ)$, to control the Type I error. We verify the usefulness of our approach in two scenarios: (1) as a ranking method in hyperparameter tuning; (2) as a selection method in multi-objective optimization algorithms. For the former, we analyze the final stochastic Pareto sets of seven multi-objective hyperparameter tuners on the YAHPO-MO benchmark tasks with q-dominance, which allows us to compare these tuners when the expected hypervolume indicator (HVI, the most common performance metric) of the Pareto sets becomes indistinguishable. For the latter, we replace the mean value-based selection in the NSGA-II algorithm with $q$-dominance, which shows a superior convergence rate on noise-augmented ZDT benchmark problems. These results establish center-outward q-dominance as a principled, tractable foundation for seeking truly stochastically dominant solutions for SMOOPs.

</details>


### [717] [CAO: Curvature-Adaptive Optimization via Periodic Low-Rank Hessian Sketching](https://arxiv.org/abs/2511.12548)
*Wenzhang Du*

Main category: cs.LG

TL;DR: 提出一种曲率自适应的优化方法，通过低秩Hessian子空间对梯度进行预处理，在保持一阶梯度优化稳定性的同时加速收敛，尤其在尖锐、各向异性区域表现优越。


<details>
  <summary>Details</summary>
Motivation: 一阶优化器在尖锐且各向异性的损失地形中虽然稳定但收敛较慢，因此需要一种能自适应曲率、提升收敛速度但仍保持稳定性的优化方法。

Method: 周期性地利用Hessian-向量积构建低秩Hessian子空间，并仅在该子空间内对梯度进行预处理，正交补空间仍使用一阶方法更新；对于L-光滑非凸目标，保留标准O(1/T)的平稳性保证，并在满足PL条件和有界残差曲率假设下实现损失收缩。

Result: 在CIFAR-10/100与ResNet-18/34上的实验表明，该方法比Adam更早进入低损失区域：在CIFAR-100/ResNet-18上达到预设训练损失阈值（0.75）的速度快2.95倍，同时最终测试准确率相当；方法对草图秩k不敏感（k∈{1,3,5}），且k=0时退化为无曲率的一阶方法。

Conclusion: 该曲率自适应混合优化策略在不牺牲稳定性的前提下显著加快了收敛速度，提供了一种高效且鲁棒的训练深度神经网络的方法，具有实际应用潜力。

Abstract: First-order optimizers are reliable but slow in sharp, anisotropic regions. We study a curvature-adaptive method that periodically sketches a low-rank Hessian subspace via Hessian--vector products and preconditions gradients only in that subspace, leaving the orthogonal complement first-order. For L-smooth non-convex objectives, we recover the standard O(1/T) stationarity guarantee with a widened stable stepsize range; under a Polyak--Lojasiewicz (PL) condition with bounded residual curvature outside the sketch, the loss contracts at refresh steps. On CIFAR-10/100 with ResNet-18/34, the method enters the low-loss region substantially earlier: measured by epochs to a pre-declared train-loss threshold (0.75), it reaches the threshold 2.95x faster than Adam on CIFAR-100/ResNet-18, while matching final test accuracy. The approach is one-knob: performance is insensitive to the sketch rank k across {1,3,5}, and k=0 yields a principled curvature-free ablation. We release anonymized logs and scripts that regenerate all figures and tables.

</details>


### [718] [Training Instabilities Induce Flatness Bias in Gradient Descent](https://arxiv.org/abs/2511.12558)
*Lawrence Wang,Stephen J. Roberts*

Main category: cs.LG

TL;DR: 训练不稳定性通过旋转Hessian特征向量的几何现象（RPE）引导梯度下降趋向更平坦的损失区域，从而提升泛化性能，尤其在现代深度网络中具有建设性作用。


<details>
  <summary>Details</summary>
Motivation: 传统梯度下降稳定性分析限制学习率不能超过Hessian最大特征值决定的阈值，但现代深度网络常在此阈值之上表现更优，需解释这一现象背后的机制。

Method: 提出并分析了Hessian特征向量旋转（RPE）这一几何现象，结合理论与实验研究梯度下降和随机梯度下降中的不稳定性如何导致参数趋向平坦极小值，并扩展至Adam优化器。

Result: 证明了训练不稳定性会引发隐式偏差，促使模型探索更平坦的损失地形；该效应在SGD中持续存在且强于小批量噪声影响；在Adam中恢复不稳定性可进一步提升泛化性能。

Conclusion: 训练不稳定性在深度学习中具有建设性作用，通过RPE机制驱动模型收敛到泛化性能更好的平坦极小值，为优化与正则化提供了新视角。

Abstract: Classical analyses of gradient descent (GD) define a stability threshold based on the largest eigenvalue of the loss Hessian, often termed sharpness. When the learning rate lies below this threshold, training is stable and the loss decreases monotonically. Yet, modern deep networks often achieve their best performance beyond this regime.
  We demonstrate that such instabilities induce an implicit bias in GD, driving parameters toward flatter regions of the loss landscape and thereby improving generalization. The key mechanism is the Rotational Polarity of Eigenvectors (RPE), a geometric phenomenon in which the leading eigenvectors of the Hessian rotate during training instabilities. These rotations, which increase with learning rates, promote exploration and provably lead to flatter minima.
  This theoretical framework extends to stochastic GD, where instability-driven flattening persists and its empirical effects outweigh minibatch noise. Finally, we show that restoring instabilities in Adam further improves generalization.
  Together, these results establish and understand the constructive role of training instabilities in deep learning.

</details>


### [719] [Linear time small coresets for k-mean clustering of segments with applications](https://arxiv.org/abs/2511.12564)
*David Denisov,Shlomi Dolev,Dan Felmdan,Michael Segal*

Main category: cs.LG

TL;DR: 本文研究了针对线段集合的k-means聚类问题，提出首个可处理任意输入线段的ε-coreset构造方法，具有O(log²n)大小和O(nd)构建时间，并在实际应用中展现出高效性与准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的k-means方法难以直接应用于线段数据，且缺乏对复杂变体（如离群点、不同距离函数）的有效处理；因此需要一种通用且高效的近似方法来支持大规模或流式场景下的线段聚类。

Method: 提出一种新的ε-coreset构造算法，能够精确逼近任意线段集合的距离函数D(S,X)，支持包括异常值处理、M-估计量、加权距离等多种变体，适用于流式、分布式和并行计算环境。

Result: 对于常数k和ε，构造出大小为O(log²n)的coreset，构建时间为O(nd)；实验显示该方法在保持聚类精度的同时显著提升计算效率，尤其在实时视频跟踪任务中表现优异。

Conclusion: 所提出的coreset方法在理论保证和实际性能之间取得了良好平衡，是首个能处理任意线段输入的k-means coreset方案，具有广泛的应用前景。

Abstract: We study the $k$-means problem for a set $\mathcal{S} \subseteq \mathbb{R}^d$ of $n$ segments, aiming to find $k$ centers $X \subseteq \mathbb{R}^d$ that minimize
  $D(\mathcal{S},X) := \sum_{S \in \mathcal{S}} \min_{x \in X} D(S,x)$, where $D(S,x) := \int_{p \in S} |p - x| dp$
  measures the total distance from each point along a segment to a center. Variants of this problem include handling outliers, employing alternative distance functions such as M-estimators, weighting distances to achieve balanced clustering, or enforcing unique cluster assignments. For any $\varepsilon > 0$, an $\varepsilon$-coreset is a weighted subset $C \subseteq \mathbb{R}^d$ that approximates $D(\mathcal{S},X)$ within a factor of $1 \pm \varepsilon$ for any set of $k$ centers, enabling efficient streaming, distributed, or parallel computation. We propose the first coreset construction that provably handles arbitrary input segments. For constant $k$ and $\varepsilon$, it produces a coreset of size $O(\log^2 n)$ computable in $O(nd)$ time. Experiments, including a real-time video tracking application, demonstrate substantial speedups with minimal loss in clustering accuracy, confirming both the practical efficiency and theoretical guarantees of our method.

</details>


### [720] [Enhancing Machine Learning Model Efficiency through Quantization and Bit Depth Optimization: A Performance Analysis on Healthcare Data](https://arxiv.org/abs/2511.12568)
*Mitul Goswami,Romit Chatterjee*

Main category: cs.LG

TL;DR: 该研究通过量化和位深度优化技术，将输入数据从float64降至float32和int32，显著降低了复杂学习模型的时间复杂度，同时保持了较高的模型准确性，尤其在Logistic Regression模型的医疗数据应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂学习模型执行时间过长的问题，亟需在不显著牺牲模型效率的前提下降低时间复杂度。

Method: 采用量化和位深度优化技术，将输入数据从float64精度降为float32和int32，并在两个医疗数据集上应用Logistic Regression模型进行验证。

Result: 优化后模型的时间复杂度显著降低，仅伴随轻微的准确率下降，表明该方法在效率与性能之间实现了良好平衡。

Conclusion: 量化和位深度优化能有效提升模型运行效率，但其效果受多种参数影响，需根据具体场景调整策略。

Abstract: This research aims to optimize intricate learning models by implementing quantization and bit-depth optimization techniques. The objective is to significantly cut time complexity while preserving model efficiency, thus addressing the challenge of extended execution times in intricate models. Two medical datasets were utilized as case studies to apply a Logistic Regression (LR) machine learning model. Using efficient quantization and bit depth optimization strategies the input data is downscaled from float64 to float32 and int32. The results demonstrated a significant reduction in time complexity, with only a minimal decrease in model accuracy post-optimization, showcasing the state-of-the-art optimization approach. This comprehensive study concludes that the impact of these optimization techniques varies depending on a set of parameters.

</details>


### [721] [LMM-IR: Large-Scale Netlist-Aware Multimodal Framework for Static IR-Drop Prediction](https://arxiv.org/abs/2511.12581)
*Kai Ma,Zhen Wang,Hongquan He,Qi Xu,Tinghuan Chen,Hao Geng*

Main category: cs.LG

TL;DR: 提出一种基于大规模净列表征（LNT）的多模态方法，将网表拓扑表示为3D点云以实现高效的静态IR压降预测，显著提升预测速度与精度。


<details>
  <summary>Details</summary>
Motivation: 静态IR压降分析在芯片设计中至关重要但耗时长，传统方法计算负担重，难以满足快速迭代需求。

Method: 将SPICE文件中的网表拓扑转化为3D点云表示，并通过大规模净列变压器（LNT）处理；融合网表和图像数据在潜在空间中进行特征编码，实现多模态输入的静态电压降预测。

Result: 在ICCAD 2023竞赛及现有最先进算法中，该方法取得了最高的F1分数和最低的MAE，表现出优越的预测性能。

Conclusion: 所提多模态方法能高效、准确地预测静态IR压降，显著缩短芯片设计周期，适用于大规模网表处理。

Abstract: Static IR drop analysis is a fundamental and critical task in the field of chip design. Nevertheless, this process can be quite time-consuming, potentially requiring several hours. Moreover, addressing IR drop violations frequently demands iterative analysis, thereby causing the computational burden. Therefore, fast and accurate IR drop prediction is vital for reducing the overall time invested in chip design. In this paper, we firstly propose a novel multimodal approach that efficiently processes SPICE files through large-scale netlist transformer (LNT). Our key innovation is representing and processing netlist topology as 3D point cloud representations, enabling efficient handling of netlist with up to hundreds of thousands to millions nodes. All types of data, including netlist files and image data, are encoded into latent space as features and fed into the model for static voltage drop prediction. This enables the integration of data from multiple modalities for complementary predictions. Experimental results demonstrate that our proposed algorithm can achieve the best F1 score and the lowest MAE among the winning teams of the ICCAD 2023 contest and the state-of-the-art algorithms.

</details>


### [722] [Symmetry-Aware Graph Metanetwork Autoencoders: Model Merging through Parameter Canonicalization](https://arxiv.org/abs/2511.12601)
*Odysseas Boufalis,Jorge Carrasco-Pollo,Joshua Rosenthal,Eduardo Terres-Caballero,Alejandro García-Castellanos*

Main category: cs.LG

TL;DR: 本文提出了一种利用神经网络参数对称性（包括置换和缩放对称性）的新型架构ScaleGMNs，并通过自动编码器框架实现了无需显式求解分配问题的模型对齐，有效支持模型融合。


<details>
  <summary>Details</summary>
Motivation: 神经网络存在多种等效的最小值，由于对称性导致难以对齐不同训练路径得到的模型，现有方法仅处理置换对称性且计算昂贵，缺乏对缩放对称性的统一建模。

Method: 提出ScaleGMNs架构，具有对置换和参数缩放变换的等变性，结合自动编码器框架，使用ScaleGMNs作为不变性编码器，隐式对齐不同网络结构（如INRs和CNNs）。

Result: 实验表明该方法能在不显式求解组合分配问题的情况下，成功对齐INRs和CNNs在置换与缩放对称下的表示，使相似网络自然落入同一损失盆地。

Conclusion: 所提方法通过统一建模两种对称性，实现了高效模型对齐与合并，支持平滑线性插值，避免高损失区域，为模型集成与压缩提供了新途径。

Abstract: Neural network parameterizations exhibit inherent symmetries that yield multiple equivalent minima within the loss landscape. Scale Graph Metanetworks (ScaleGMNs) explicitly leverage these symmetries by proposing an architecture equivariant to both permutation and parameter scaling transformations. Previous work by Ainsworth et al. (2023) addressed permutation symmetries through a computationally intensive combinatorial assignment problem, demonstrating that leveraging permutation symmetries alone can map networks into a shared loss basin. In this work, we extend their approach by also incorporating scaling symmetries, presenting an autoencoder framework utilizing ScaleGMNs as invariant encoders. Experimental results demonstrate that our method aligns Implicit Neural Representations (INRs) and Convolutional Neural Networks (CNNs) under both permutation and scaling symmetries without explicitly solving the assignment problem. This approach ensures that similar networks naturally converge within the same basin, facilitating model merging, i.e., smooth linear interpolation while avoiding regions of high loss. The code is publicly available on our GitHub repository.

</details>


### [723] [PID-controlled Langevin Dynamics for Faster Sampling of Generative Models](https://arxiv.org/abs/2511.12603)
*Hongyi Chen,Jianhai Shu,Jingtao Ding,Yong Li,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于控制理论的新型采样加速算法PIDLD，通过引入历史梯度和梯度趋势信息显著减少Langevin动力学采样的迭代次数，提升生成效率与质量。


<details>
  <summary>Details</summary>
Motivation: Langevin动力学采样因需要大量细粒度迭代而速度极慢，限制了其在实际应用中的效率，亟需一种无需额外训练且能加速收敛的方法。

Method: 将采样过程重新解释为控制系统，利用能量梯度作为反馈信号，结合比例-积分-微分（PID）控制机制，引入历史梯度（积分项）和梯度变化趋势（微分项）来自适应调整采样路径和稳定性。

Result: 在图像生成和推理任务中，PIDLD相比传统方法在更少步数下生成更高品质样本，显著提升采样效率，且无需额外训练或数据。

Conclusion: PIDLD为Langevin动力学提供了一种高效、即插即用的加速方案，增强了其在效率敏感场景下的实用性。

Abstract: Langevin dynamics sampling suffers from extremely low generation speed, fundamentally limited by numerous fine-grained iterations to converge to the target distribution. We introduce PID-controlled Langevin Dynamics (PIDLD), a novel sampling acceleration algorithm that reinterprets the sampling process using control-theoretic principles. By treating energy gradients as feedback signals, PIDLD combines historical gradients (the integral term) and gradient trends (the derivative term) to efficiently traverse energy landscapes and adaptively stabilize, thereby significantly reducing the number of iterations required to produce high-quality samples. Our approach requires no additional training, datasets, or prior information, making it immediately integrable with any Langevin-based method. Extensive experiments across image generation and reasoning tasks demonstrate that PIDLD achieves higher quality with fewer steps, making Langevin-based generative models more practical for efficiency-critical applications. The implementation can be found at \href{https://github.com/tsinghua-fib-lab/PIDLD}{https://github.com/tsinghua-fib-lab/PIDLD}.

</details>


### [724] [FedTopo: Topology-Informed Representation Alignment in Federated Learning under Non-I.I.D. Conditions](https://arxiv.org/abs/2511.12628)
*Ke Hu,Liyao Xiang,Peng Tang,Weidong Qiu*

Main category: cs.LG

TL;DR: 提出FedTopo框架，通过拓扑信息增强联邦学习中非独立同分布数据下的特征一致性，提升模型收敛速度和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习模型在非独立同分布（non-I.I.D.）客户端数据下表现下降，因特征表示发散且局部目标难以捕捉全局拓扑结构。

Method: 提出FedTopo，包含拓扑引导块筛选（TGBS）和拓扑嵌入（TE），并通过拓扑对齐损失（TAL）实现跨客户端表征的一致性对齐。

Result: 在Fashion-MNIST、CIFAR-10和CIFAR-100上四个非I.I.D.划分的实验表明，FedTopo加快收敛并优于强基线方法。

Conclusion: FedTopo通过利用拓扑信息有效缓解了非I.I.D.数据下的表示漂移问题，提升了联邦学习在高维视觉任务中的性能。

Abstract: Current federated-learning models deteriorate under heterogeneous (non-I.I.D.) client data, as their feature representations diverge and pixel- or patch-level objectives fail to capture the global topology which is essential for high-dimensional visual tasks. We propose FedTopo, a framework that integrates Topological-Guided Block Screening (TGBS) and Topological Embedding (TE) to leverage topological information, yielding coherently aligned cross-client representations by Topological Alignment Loss (TAL). First, Topology-Guided Block Screening (TGBS) automatically selects the most topology-informative block, i.e., the one with maximal topological separability, whose persistence-based signatures best distinguish within- versus between-class pairs, ensuring that subsequent analysis focuses on topology-rich features. Next, this block yields a compact Topological Embedding, which quantifies the topological information for each client. Finally, a Topological Alignment Loss (TAL) guides clients to maintain topological consistency with the global model during optimization, reducing representation drift across rounds. Experiments on Fashion-MNIST, CIFAR-10, and CIFAR-100 under four non-I.I.D. partitions show that FedTopo accelerates convergence and improves accuracy over strong baselines.

</details>


### [725] [NFQ2.0: The CartPole Benchmark Revisited](https://arxiv.org/abs/2511.12644)
*Sascha Lange,Roland Hafner,Martin Riedmiller*

Main category: cs.LG

TL;DR: 本文重新审视了20年前的神经拟合Q迭代（NFQ）算法，并在其经典CartPole基准上提出了一种现代化改进版本NFQ2.0，旨在提升其在工业控制应用中的可重复性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: NFQ作为早期深度强化学习的先驱算法，虽具概念简洁性和稳定性优势，但在实际应用中存在调参复杂、难以复现的问题，限制了其在现实工业场景中的推广。

Method: 本文回顾NFQ算法并分析其从在线学习到批量学习的转变，提出NFQ2.0新变体，通过消融实验研究关键设计选择和超参数对性能的影响，并在基于标准工业组件构建的真实系统上进行验证。

Result: NFQ2.0在CartPole任务上表现出更强的稳定性和可重复性，明确了影响性能的关键因素，提升了深度强化学习在实际工业环境中的适用性。

Conclusion: 通过对NFQ的现代化改进，本文为深度强化学习在工业控制中的可靠部署提供了实用指导，增强了算法的可复现性与鲁棒性。

Abstract: This article revisits the 20-year-old neural fitted Q-iteration (NFQ) algorithm on its classical CartPole benchmark. NFQ was a pioneering approach towards modern Deep Reinforcement Learning (Deep RL) in applying multi-layer neural networks to reinforcement learning for real-world control problems. We explore the algorithm's conceptual simplicity and its transition from online to batch learning, which contributed to its stability. Despite its initial success, NFQ required extensive tuning and was not easily reproducible on real-world control problems. We propose a modernized variant NFQ2.0 and apply it to the CartPole task, concentrating on a real-world system build from standard industrial components, to investigate and improve the learning process's repeatability and robustness. Through ablation studies, we highlight key design decisions and hyperparameters that enhance performance and stability of NFQ2.0 over the original variant. Finally, we demonstrate how our findings can assist practitioners in reproducing and improving results and applying deep reinforcement learning more effectively in industrial contexts.

</details>


### [726] [Sample Complexity of Agnostic Multiclass Classification: Natarajan Dimension Strikes Back](https://arxiv.org/abs/2511.12659)
*Alon Cohen,Liad Erez,Steve Hanneke,Tomer Koren,Yishay Mansour,Shay Moran,Qian Zhang*

Main category: cs.LG

TL;DR: 本文揭示了多类PAC学习的样本复杂度由两个不同的维度（DS维度和Natarajan维度）共同决定，而非单一参数，提出了新的近乎紧致的样本复杂度界，并引入了一种基于自适应乘法权重算法的新颖在线方法。


<details>
  <summary>Details</summary>
Motivation: 扩展统计学习基本定理到多类分类长期存在挑战，尤其是Natarajan维度与DS维度之间的分歧，本文旨在澄清多类PAC学习的样本复杂度究竟由哪些结构参数决定。

Method: 通过结合自适应乘法权重算法的新型在线过程，实现标签空间约简，并摆脱传统基于一致收敛或可实现情形归约的方法，推导出近乎紧致的非真实情况下的样本复杂度上界。

Result: 证明了非真实多类PAC学习的样本复杂度上界为 $\frac{DS^{1.5}}{ε} + \frac{Nat}{ε^2}$，该界在对数因子下几乎紧致，且分别接近已知的 $Nat/ε^2$ 和 $DS/ε$ 下界，表明DS维度控制前期行为而Natarajan维度决定小误差下的渐进行为。

Conclusion: 多类PAC学习本质上由两个结构参数共同控制：DS维度影响学习初期的样本效率，而Natarajan维度仍主导高精度（小ε）时的渐近行为，这与二元或在线学习中单一维度主导的情形根本不同。

Abstract: The fundamental theorem of statistical learning states that binary PAC learning is governed by a single parameter -- the Vapnik-Chervonenkis (VC) dimension -- which determines both learnability and sample complexity. Extending this to multiclass classification has long been challenging, since Natarajan's work in the late 80s proposing the Natarajan dimension (Nat) as a natural analogue of VC. Daniely and Shalev-Shwartz (2014) introduced the DS dimension, later shown by Brukhim et al. (2022) to characterize multiclass learnability. Brukhim et al. also showed that Nat and DS can diverge arbitrarily, suggesting that multiclass learning is governed by DS rather than Nat. We show that agnostic multiclass PAC sample complexity is in fact governed by two distinct dimensions. Specifically, we prove nearly tight agnostic sample complexity bounds that, up to log factors, take the form $\frac{DS^{1.5}}ε + \frac{Nat}{ε^2}$ where $ε$ is the excess risk. This bound is tight up to a $\sqrt{DS}$ factor in the first term, nearly matching known $Nat/ε^2$ and $DS/ε$ lower bounds. The first term reflects the DS-controlled regime, while the second shows that the Natarajan dimension still dictates asymptotic behavior for small $ε$. Thus, unlike binary or online classification -- where a single dimension (VC or Littlestone) controls both phenomena -- multiclass learning inherently involves two structural parameters. Our technical approach departs from traditional agnostic learning methods based on uniform convergence or reductions to realizable cases. A key ingredient is a novel online procedure based on a self-adaptive multiplicative-weights algorithm performing a label-space reduction, which may be of independent interest.

</details>


### [727] [FLClear: Visually Verifiable Multi-Client Watermarking for Federated Learning](https://arxiv.org/abs/2511.12663)
*Chen Gu,Yingying Sun,Yifan She,Donghui Hu*

Main category: cs.LG

TL;DR: 本文提出了一种名为FLClear的新型联邦学习水印框架，解决了现有方法中水印冲突、安全性不足和验证不直观的问题，通过联合优化转置模型和对比学习实现无碰撞聚合、高安全性和可视化验证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端模型的知识产权易受中心服务器恶意篡改或侵占，现有水印技术存在水印冲突、安全性低和验证机制不直观等局限，亟需一种更安全、可靠且易于验证的水印方案来保护客户端的知识产权。

Method: 提出FLClear框架，引入一个与主任务联合优化的转置模型，并结合对比学习将水印嵌入过程与主任务目标融合；在聚合阶段实现无碰撞水印整合；验证时通过转置模型重建水印，并利用视觉检查和结构相似性指标进行直观且量化的所有权验证。

Result: 在多种数据集、聚合方式和攻击场景下的实验表明，FLClear在水印安全性、鲁棒性和验证直观性方面均优于现有最先进方法，能有效防止水印冲突并抵御各类攻击。

Conclusion: FLClear为联邦学习中的模型知识产权保护提供了一个高效、安全且可解释的解决方案，实现了无碰撞水印聚合、增强的安全性以及可视化所有权验证，具有较强的实用价值和推广前景。

Abstract: Federated learning (FL) enables multiple clients to collaboratively train a shared global model while preserving the privacy of their local data. Within this paradigm, the intellectual property rights (IPR) of client models are critical assets that must be protected. In practice, the central server responsible for maintaining the global model may maliciously manipulate the global model to erase client contributions or falsely claim sole ownership, thereby infringing on clients' IPR. Watermarking has emerged as a promising technique for asserting model ownership and protecting intellectual property. However, existing FL watermarking approaches remain limited, suffering from potential watermark collisions among clients, insufficient watermark security, and non-intuitive verification mechanisms. In this paper, we propose FLClear, a novel framework that simultaneously achieves collision-free watermark aggregation, enhanced watermark security, and visually interpretable ownership verification. Specifically, FLClear introduces a transposed model jointly optimized with contrastive learning to integrate the watermarking and main task objectives. During verification, the watermark is reconstructed from the transposed model and evaluated through both visual inspection and structural similarity metrics, enabling intuitive and quantitative ownership verification. Comprehensive experiments conducted over various datasets, aggregation schemes, and attack scenarios demonstrate the effectiveness of FLClear and confirm that it consistently outperforms state-of-the-art FL watermarking methods.

</details>


### [728] [Attention-Enhanced Convolutional Autoencoder and Structured Delay Embeddings for Weather Prediction](https://arxiv.org/abs/2511.12682)
*Amirpasha Hedayat,Karthik Duraisamy*

Main category: cs.LG

TL;DR: 提出一种高效的降阶建模框架用于短期天气预报，结合ResNet卷积自编码器与块注意力模块进行降维，并在时延嵌入空间中学习线性算子以捕捉动力学特征。


<details>
  <summary>Details</summary>
Motivation: 针对复杂、非线性且混沌的高维天气系统，现有AI模型计算成本高，需探索高效且准确的降阶建模方法。

Method: 采用基于ResNet的卷积自编码器结合注意力模块进行降维，在时间延迟的潜在空间嵌入中学习线性算子以建模动态演化。

Result: 在ERA5数据集上表现良好，能有效预测训练期内的天气模式，发现投影误差是主要瓶颈，而非推理误差。

Conclusion: 该框架在分布内预测效果合理，但外推能力有限；揭示了混沌系统降阶建模的关键挑战，建议将高效降阶模型与复杂AI结合用于长期气候模拟。

Abstract: Weather prediction is a quintessential problem involving the forecasting of a complex, nonlinear, and chaotic high-dimensional dynamical system. This work introduces an efficient reduced-order modeling (ROM) framework for short-range weather prediction and investigates fundamental questions in dimensionality reduction and reduced order modeling of such systems. Unlike recent AI-driven models, which require extensive computational resources, our framework prioritizes efficiency while achieving reasonable accuracy. Specifically, a ResNet-based convolutional autoencoder augmented by block attention modules is developed to reduce the dimensionality of high-dimensional weather data. Subsequently, a linear operator is learned in the time-delayed embedding of the latent space to efficiently capture the dynamics. Using the ERA5 reanalysis dataset, we demonstrate that this framework performs well in-distribution as evidenced by effectively predicting weather patterns within training data periods. We also identify important limitations in generalizing to future states, particularly in maintaining prediction accuracy beyond the training window. Our analysis reveals that weather systems exhibit strong temporal correlations that can be effectively captured through linear operations in an appropriately constructed embedding space, and that projection error rather than inference error is the main bottleneck. These findings shed light on some key challenges in reduced-order modeling of chaotic systems and point toward opportunities for hybrid approaches that combine efficient reduced-order models as baselines with more sophisticated AI architectures, particularly for applications in long-term climate modeling where computational efficiency is paramount.

</details>


### [729] [A Closer Look at Personalized Fine-Tuning in Heterogeneous Federated Learning](https://arxiv.org/abs/2511.12695)
*Minghui Chen,Hrad Ghoukasian,Ruinan Jin,Zehua Wang,Sai Praneeth Karimireddy,Xiaoxiao Li*

Main category: cs.LG

TL;DR: 本文提出将线性探测后接全量微调（LP-FT）的方法引入联邦学习（FL），以解决传统个性化微调（PFT）在数据分布不一致时易过拟合或失效的问题，通过系统评估和理论分析表明LP-FT能有效缓解联邦特征失真，提升个性化与泛化之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中由于客户端数据分布非独立同分布，全局模型的泛化能力与本地个性化之间难以平衡；现有后处理方法如PFT容易在偏斜分布上过拟合或在域迁移下失败。

Method: 引入线性探测再进行全量微调（LP-FT）的两阶段方法，作为集中式策略适应到联邦学习框架中，并通过七个多样化数据集和六种PFT变体进行系统性评估。

Result: 发现并定义了‘联邦特征失真’现象，即局部微调会破坏全局学习到的特征；实验表明LP-FT在多种条件下优于标准微调方法；理论分析揭示了其通过分阶段参数更新机制缓解该问题。

Conclusion: LP-FT是一种有效的联邦个性化策略，能够在存在部分特征重叠、协变量-概念漂移等条件下显著提升模型稳定性与性能，为联邦学习中的鲁棒个性化部署提供了可操作指南。

Abstract: Federated Learning (FL) enables decentralized, privacy-preserving model training but struggles to balance global generalization and local personalization due to non-identical data distributions across clients. Personalized Fine-Tuning (PFT), a popular post-hoc solution, fine-tunes the final global model locally but often overfits to skewed client distributions or fails under domain shifts. We propose adapting Linear Probing followed by full Fine-Tuning (LP-FT), a principled centralized strategy for alleviating feature distortion (Kumar et al., 2022), to the FL setting. Through systematic evaluation across seven datasets and six PFT variants, we demonstrate LP-FT's superiority in balancing personalization and generalization. Our analysis uncovers federated feature distortion, a phenomenon where local fine-tuning destabilizes globally learned features, and theoretically characterizes how LP-FT mitigates this via phased parameter updates. We further establish conditions (e.g., partial feature overlap, covariate-concept shift) under which LP-FT outperforms standard fine-tuning, offering actionable guidelines for deploying robust personalization in FL.

</details>


### [730] [Beyond Fixed Tasks: Unsupervised Environment Design for Task-Level Pairs](https://arxiv.org/abs/2511.12706)
*Daniel Furelos-Blanco,Charles Pert,Frederik Kelbel,Alex F. Spies,Alessandra Russo,Michael Dennis*

Main category: cs.LG

TL;DR: 提出ATLAS方法，通过联合生成任务和关卡的自课程（autocurricula）来提升强化学习中复杂指令执行的训练效率。


<details>
  <summary>Details</summary>
Motivation: 传统随机采样任务-关卡组合常产生不可解情况，且现有UED方法仅考虑固定任务，缺乏对任务与关卡协同设计的支持。

Method: 基于无监督环境设计（UED），扩展为同时优化任务与关卡的联合自课程生成框架ATLAS，并引入基于奖励机的任务建模评估套件。

Result: 实验表明ATLAS显著优于随机采样方法，尤其在可解组合稀少的情况下；利用任务与关卡结构的变异策略可加速收敛至高性能策略。

Conclusion: ATLAS实现了任务与关卡的协同进化，有效生成可解且具挑战性的训练样本，推动通用智能体在复杂环境中学习复杂指令的能力。

Abstract: Training general agents to follow complex instructions (tasks) in intricate environments (levels) remains a core challenge in reinforcement learning. Random sampling of task-level pairs often produces unsolvable combinations, highlighting the need to co-design tasks and levels. While unsupervised environment design (UED) has proven effective at automatically designing level curricula, prior work has only considered a fixed task. We present ATLAS (Aligning Tasks and Levels for Autocurricula of Specifications), a novel method that generates joint autocurricula over tasks and levels. Our approach builds upon UED to automatically produce solvable yet challenging task-level pairs for policy training. To evaluate ATLAS and drive progress in the field, we introduce an evaluation suite that models tasks as reward machines in Minigrid levels. Experiments demonstrate that ATLAS vastly outperforms random sampling approaches, particularly when sampling solvable pairs is unlikely. We further show that mutations leveraging the structure of both tasks and levels accelerate convergence to performant policies.

</details>


### [731] [Adaptive Graph Rewiring to Mitigate Over-Squashing in Mesh-Based GNNs for Fluid Dynamics Simulations](https://arxiv.org/abs/2511.12709)
*Sangwoo Seo,Hyunsung Kim,Jiwan Kim,Chanyoung Park*

Main category: cs.LG

TL;DR: 提出了一种名为AdaMeshNet的新框架，通过在消息传递过程中引入自适应图重连机制，解决了基于网格的图神经网络在流体模拟中的过压缩问题，有效提升了物理交互建模的准确性和合理性。


<details>
  <summary>Details</summary>
Motivation: 现有的图重连方法在处理网格细化导致的过压缩问题时，假设远距离节点间瞬时相互作用，忽略了粒子间的距离信息，物理上不真实。

Method: 提出AdaMeshNet框架，计算瓶颈节点的重连延迟分数（基于最短路径距离和速度差异），并在消息传递过程中动态选择重连层，实现自适应图重连。

Result: 在基于网格的流体模拟实验中，AdaMeshNet优于传统重连方法，能更准确地建模物理相互作用的时序特性。

Conclusion: AdaMeshNet通过引入考虑传播延迟的自适应重连机制，有效缓解了过压缩问题，提高了流体模拟的预测精度和物理一致性。

Abstract: Mesh-based simulation using Graph Neural Networks (GNNs) has been recognized as a promising approach for modeling fluid dynamics. However, the mesh refinement techniques which allocate finer resolution to regions with steep gradients can induce the over-squashing problem in mesh-based GNNs, which prevents the capture of long-range physical interactions. Conventional graph rewiring methods attempt to alleviate this issue by adding new edges, but they typically complete all rewiring operations before applying them to the GNN. These approaches are physically unrealistic, as they assume instantaneous interactions between distant nodes and disregard the distance information between particles. To address these limitations, we propose a novel framework, called Adaptive Graph Rewiring in Mesh-Based Graph Neural Networks (AdaMeshNet), that introduces an adaptive rewiring process into the message-passing procedure to model the gradual propagation of physical interactions. Our method computes a rewiring delay score for bottleneck nodes in the mesh graph, based on the shortest-path distance and the velocity difference. Using this score, it dynamically selects the message-passing layer at which new edges are rewired, which can lead to adaptive rewiring in a mesh graph. Extensive experiments on mesh-based fluid simulations demonstrate that AdaMeshNet outperforms conventional rewiring methods, effectively modeling the sequential nature of physical interactions and enabling more accurate predictions.

</details>


### [732] [Oxytrees: Model Trees for Bipartite Learning](https://arxiv.org/abs/2511.12713)
*Pedro Ilídio,Felipe Kenji Nakano,Alireza Gharahighehi,Robbe D'hondt,Ricardo Cerri,Celine Vens*

Main category: cs.LG

TL;DR: Oxytrees是一种基于代理的双聚类模型树，用于解决双部分学习中的可扩展性和泛化问题，通过压缩交互矩阵和改进叶节点分配算法，显著提高了训练和预测速度，同时保持竞争力的预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有双部分学习方法通常针对特定应用设计，缺乏通用性且存在可扩展性问题。

Method: 提出Oxytrees模型，采用行和列方向的代理矩阵压缩交互矩阵，使用Kronecker积核的线性模型构建浅层树，并设计新的叶节点分配算法以加速预测。

Result: 在15个数据集上验证，相比当前最先进的双聚类森林，训练时间最多提升30倍，且在多数评估场景下表现相当或更优，尤其在归纳设置中。

Conclusion: Oxytrees在保持高性能的同时大幅提升了效率，具备良好的通用性和可扩展性，并通过开源Python API支持可重复研究。

Abstract: Bipartite learning is a machine learning task that aims to predict interactions between pairs of instances. It has been applied to various domains, including drug-target interactions, RNA-disease associations, and regulatory network inference. Despite being widely investigated, current methods still present drawbacks, as they are often designed for a specific application and thus do not generalize to other problems or present scalability issues. To address these challenges, we propose Oxytrees: proxy-based biclustering model trees. Oxytrees compress the interaction matrix into row- and column-wise proxy matrices, significantly reducing training time without compromising predictive performance. We also propose a new leaf-assignment algorithm that significantly reduces the time taken for prediction. Finally, Oxytrees employ linear models using the Kronecker product kernel in their leaves, resulting in shallower trees and thus even faster training. Using 15 datasets, we compared the predictive performance of ensembles of Oxytrees with that of the current state-of-the-art. We achieved up to 30-fold improvement in training times compared to state-of-the-art biclustering forests, while demonstrating competitive or superior performance in most evaluation settings, particularly in the inductive setting. Finally, we provide an intuitive Python API to access all datasets, methods and evaluation measures used in this work, thus enabling reproducible research in this field.

</details>


### [733] [On Robustness of Linear Classifiers to Targeted Data Poisoning](https://arxiv.org/abs/2511.12722)
*Nakshatra Gupta,Sumanth Prabhu,Supratik Chakraborty,R Venkatesh*

Main category: cs.LG

TL;DR: 本文研究了标签翻转型数据投毒攻击下的数据集鲁棒性度量问题，证明了计算精确鲁棒性是NP完全的，并提出了一种高效计算鲁棒性上下界的方法，在多个公开数据集上验证了其有效性与优越性。


<details>
  <summary>Details</summary>
Motivation: 数据投毒攻击在训练阶段通过污染训练数据破坏模型可信度，尤其是针对特定测试样本的定向攻击难以人工检测。因此，需要自动量化数据集对这类攻击的鲁棒性以评估安全性。

Method: 在仅允许篡改训练标签且攻击者知识受限于模型假设空间的威胁模型下，作者首先证明计算数据集鲁棒性是NP完全问题。为解决该难题，提出一种可高效计算鲁棒性上下界的技术，并实现相应的算法。

Result: 实验表明，所提方法能在多个公开数据集上有效计算出鲁棒性上下界；当投毒程度超过这些边界时，显著影响目标样本分类。相比现有最先进方法，本方法适用范围更广，能在更多场景下成功计算边界。

Conclusion: 尽管精确计算标签翻转攻击下的数据集鲁棒性是NP完全的，但通过提出的上下界估计技术，可以高效且实用地评估模型对该类攻击的防御能力，增强了对数据安全性的理解与保障。

Abstract: Data poisoning is a training-time attack that undermines the trustworthiness of learned models. In a targeted data poisoning attack, an adversary manipulates the training dataset to alter the classification of a targeted test point. Given the typically large size of training dataset, manual detection of poisoning is difficult. An alternative is to automatically measure a dataset's robustness against such an attack, which is the focus of this paper. We consider a threat model wherein an adversary can only perturb the labels of the training dataset, with knowledge limited to the hypothesis space of the victim's model. In this setting, we prove that finding the robustness is an NP-Complete problem, even when hypotheses are linear classifiers. To overcome this, we present a technique that finds lower and upper bounds of robustness. Our implementation of the technique computes these bounds efficiently in practice for many publicly available datasets. We experimentally demonstrate the effectiveness of our approach. Specifically, a poisoning exceeding the identified robustness bounds significantly impacts test point classification. We are also able to compute these bounds in many more cases where state-of-the-art techniques fail.

</details>


### [734] [LAYA: Layer-wise Attention Aggregation for Interpretable Depth-Aware Neural Networks](https://arxiv.org/abs/2511.12723)
*Gennaro Vessio*

Main category: cs.LG

TL;DR: 本文提出了LAYA（Layer-wise Attention Aggregator），一种新的输出头机制，通过输入条件的注意力权重动态聚合深度神经网络各层的表征，提升模型性能并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络仅使用最后一层的隐藏表示进行预测，忽略了中间层包含的丰富且互补的信息。这种做法可能导致语义信息丢失，限制了模型性能和可解释性。

Method: 提出LAYA机制，引入层间注意力，学习对每一层特征赋予输入相关的注意力权重，动态聚合所有层的表示用于预测。该方法不改变主干网络结构，具有架构无关性，适用于不同模型。

Result: 在视觉与语言任务的多个基准上验证，LAYA相比标准输出头性能相当或更优，最高提升约1个百分点；同时能自然生成各决策的层归因分数，揭示不同抽象层次的贡献。

Conclusion: LAYA有效利用了深层网络中的多层信息，提升了模型表现，并通过内置机制实现了无需后处理的可解释性，为输出层设计提供了新思路。

Abstract: Deep neural networks typically rely on the representation produced by their final hidden layer to make predictions, implicitly assuming that this single vector fully captures the semantics encoded across all preceding transformations. However, intermediate layers contain rich and complementary information -- ranging from low-level patterns to high-level abstractions -- that is often discarded when the decision head depends solely on the last representation. This paper revisits the role of the output layer and introduces LAYA (Layer-wise Attention Aggregator), a novel output head that dynamically aggregates internal representations through attention. Instead of projecting only the deepest embedding, LAYA learns input-conditioned attention weights over layer-wise features, yielding an interpretable and architecture-agnostic mechanism for synthesizing predictions. Experiments on vision and language benchmarks show that LAYA consistently matches or improves the performance of standard output heads, with relative gains of up to about one percentage point in accuracy, while providing explicit layer-attribution scores that reveal how different abstraction levels contribute to each decision. Crucially, these interpretability signals emerge directly from the model's computation, without any external post hoc explanations. The code to reproduce LAYA is publicly available at: https://github.com/gvessio/LAYA.

</details>


### [735] [Convolutional Model Trees](https://arxiv.org/abs/2511.12725)
*William Ward Armstrong*

Main category: cs.LG

TL;DR: 提出一种基于模型树森林的方法，用于拟合定义在图像上的函数，通过下采样、超平面卷积和森林集成提高精度和平滑性。


<details>
  <summary>Details</summary>
Motivation: 为了更好地拟合图像上的函数并处理图像的各种变形（如旋转或透视变化），需要一种鲁棒且可微的建模方法。

Method: 通过下采样图像、确定树的超平面、对超平面进行卷积以应对小变形，并构建模型树森林；利用像素与超平面系数之间的1对1对应关系处理大变形，同时提出理论上的平滑方法使输出连续可微。

Result: 实现了对图像函数的高精度、平滑拟合并支持连续可微输出，训练过程被证明收敛。

Conclusion: 该方法能有效处理图像中的多种变形，提供精确且平滑的函数逼近，且具有理论收敛保证。

Abstract: A method for creating a forest of model trees to fit samples of a function defined on images is described in several steps: down-sampling the images, determining a tree's hyperplanes, applying convolutions to the hyperplanes to handle small distortions of training images, and creating forests of model trees to increase accuracy and achieve a smooth fit. A 1-to-1 correspondence among pixels of images, coefficients of hyperplanes and coefficients of leaf functions offers the possibility of dealing with larger distortions such as arbitrary rotations or changes of perspective. A theoretical method for smoothing forest outputs to produce a continuously differentiable approximation is described. Within that framework, a training procedure is proved to converge.

</details>


### [736] [Stabilizing Self-Consuming Diffusion Models with Latent Space Filtering](https://arxiv.org/abs/2511.12742)
*Zhongteng Cai,Yaxuan Wang,Yang Liu,Xueru Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为“潜在空间过滤”（LSF）的新方法，通过过滤混合数据集中的低质量合成数据来缓解自消耗扩散模型中的模型崩溃问题，无需增加训练成本或依赖人工标注。


<details>
  <summary>Details</summary>
Motivation: 随着合成数据在互联网上的泛滥并被反复用于训练新一代生成模型，形成了“自我消耗循环”，可能导致训练不稳定或模型崩溃。现有应对策略存在计算成本高或依赖昂贵人工标注的问题。

Method: 通过实证分析自消耗扩散模型的潜在空间动态，发现从合成数据中提取的潜在表示的低维结构会随代际退化。基于此，提出了“潜在空间过滤”（LSF）方法，利用潜在空间退化特征过滤掉混合数据集中不够真实的合成数据。同时提出了连接潜在空间退化与经验观察的理论框架。

Result: 实验表明，LSF在多个真实世界数据集上 consistently 优于现有基线方法，能有效缓解模型崩溃，且不增加训练成本或依赖人工注释。

Conclusion: LSF是一种高效、低成本缓解生成模型在自消耗循环中发生模型崩溃的方法，具有良好的实际应用前景。

Abstract: As synthetic data proliferates across the Internet, it is often reused to train successive generations of generative models. This creates a ``self-consuming loop" that can lead to training instability or \textit{model collapse}. Common strategies to address the issue -- such as accumulating historical training data or injecting fresh real data -- either increase computational cost or require expensive human annotation. In this paper, we empirically analyze the latent space dynamics of self-consuming diffusion models and observe that the low-dimensional structure of latent representations extracted from synthetic data degrade over generations. Based on this insight, we propose \textit{Latent Space Filtering} (LSF), a novel approach that mitigates model collapse by filtering out less realistic synthetic data from mixed datasets. Theoretically, we present a framework that connects latent space degradation to empirical observations. Experimentally, we show that LSF consistently outperforms existing baselines across multiple real-world datasets, effectively mitigating model collapse without increasing training cost or relying on human annotation.

</details>


### [737] [DIVIDE: A Framework for Learning from Independent Multi-Mechanism Data Using Deep Encoders and Gaussian Processes](https://arxiv.org/abs/2511.12745)
*Vivek Chawla,Boris Slautin,Utkarsh Pratiush,Dayakar Penumadu,Sergei Kalinin*

Main category: cs.LG

TL;DR: 提出DIVIDE框架，通过结合机制特定的深度编码器和结构化高斯过程，有效分离科学数据集中多种独立生成机制的影响。


<details>
  <summary>Details</summary>
Motivation: 科学数据集通常由多个独立机制共同作用产生，这些机制的混合影响使得难以分辨各自的贡献。

Method: 设计一个包含机制特异性深度编码器和结构化高斯过程的联合潜在空间模型，以实现机制解耦和联合效应建模。

Result: 在合成数据、铁电模拟和实验数据上验证了DIVIDE的有效性，能够分离机制、复现加性和缩放交互，并在噪声下保持鲁棒性。

Conclusion: DIVIDE框架能有效解耦多机制数据中的独立生成因素，支持可解释预测和高效主动学习，适用于多功能数据集。

Abstract: Scientific datasets often arise from multiple independent mechanisms such as spatial, categorical or structural effects, whose combined influence obscures their individual contributions. We introduce DIVIDE, a framework that disentangles these influences by integrating mechanism-specific deep encoders with a structured Gaussian Process in a joint latent space. Disentanglement here refers to separating independently acting generative factors. The encoders isolate distinct mechanisms while the Gaussian Process captures their combined effect with calibrated uncertainty. The architecture supports structured priors, enabling interpretable and mechanism-aware prediction as well as efficient active learning. DIVIDE is demonstrated on synthetic datasets combining categorical image patches with nonlinear spatial fields, on FerroSIM spin lattice simulations of ferroelectric patterns, and on experimental PFM hysteresis loops from PbTiO3 films. Across benchmarks, DIVIDE separates mechanisms, reproduces additive and scaled interactions, and remains robust under noise. The framework extends naturally to multifunctional datasets where mechanical, electromagnetic or optical responses coexist.

</details>


### [738] [Conformal Online Learning of Deep Koopman Linear Embeddings](https://arxiv.org/abs/2511.12760)
*Ben Gao,Jordan Patracone,Stéphane Chrétien,Olivier Alata*

Main category: cs.LG

TL;DR: 提出了COLoKe框架，通过结合深度特征学习和提升空间中的多步预测一致性，自适应更新非线性动力系统的Koopman嵌入表示。


<details>
  <summary>Details</summary>
Motivation: 为了从流式数据中持续、高效地学习非线性动力系统的动态特性，并避免传统方法在更新过程中容易出现的过拟合问题。

Method: 将深度特征学习与提升空间中的多步预测一致性相结合，采用类似共形学习的机制，动态校准预测误差阈值，仅在当前模型误差超过阈值时触发更新。

Result: 在基准动力系统上的实验表明，COLoKe能有效保持长期预测准确性，显著减少不必要的模型更新，并避免过拟合。

Conclusion: COLoKe为非线性动力系统的在线学习提供了一种高效且鲁棒的方法，能够在保证预测性能的同时实现稀疏更新。

Abstract: We introduce Conformal Online Learning of Koopman embeddings (COLoKe), a novel framework for adaptively updating Koopman-invariant representations of nonlinear dynamical systems from streaming data. Our modeling approach combines deep feature learning with multistep prediction consistency in the lifted space, where the dynamics evolve linearly. To prevent overfitting, COLoKe employs a conformal-style mechanism that shifts the focus from evaluating the conformity of new states to assessing the consistency of the current Koopman model. Updates are triggered only when the current model's prediction error exceeds a dynamically calibrated threshold, allowing selective refinement of the Koopman operator and embedding. Empirical results on benchmark dynamical systems demonstrate the effectiveness of COLoKe in maintaining long-term predictive accuracy while significantly reducing unnecessary updates and avoiding overfitting.

</details>


### [739] [INC: An Indirect Neural Corrector for Auto-Regressive Hybrid PDE Solvers](https://arxiv.org/abs/2511.12764)
*Hao Wei,Aleksandra Franz,Bjoern List,Nils Thuerey*

Main category: cs.LG

TL;DR: 提出间接神经校正器（INC），通过将学习到的修正项嵌入控制方程而非直接修改状态，有效抑制误差累积，显著提升混合求解器在长期仿真中的稳定性与精度。


<details>
  <summary>Details</summary>
Motivation: 现有混合求解器中直接应用学习校正会导致自回归误差累积，尤其在混沌系统和长时间 rollout 中问题严重，影响仿真稳定性与可靠性。

Method: 提出间接神经校正（INC），将神经网络学习的修正项融入微分方程的演化过程中，而不是直接修正求解器输出；理论分析表明该方法可降低误差放大程度（减少约 Δt⁻¹ + L 量级）。

Result: 在多种可微求解器、神经网络结构和测试场景（从1D混沌系统到3D湍流）中验证，INC将轨迹预测性能（R²）最高提升158.7%，有效防止粗网格下的数值崩溃，并在3D湍流模拟中实现数个数量级的加速。

Conclusion: INC实现了稳定且高效的PDE代理仿真，具备理论支持的误差抑制能力，兼容任意神经网络与求解器，为科学计算提供兼具速度与物理一致性的解决方案。

Abstract: When simulating partial differential equations, hybrid solvers combine coarse numerical solvers with learned correctors. They promise accelerated simulations while adhering to physical constraints. However, as shown in our theoretical framework, directly applying learned corrections to solver outputs leads to significant autoregressive errors, which originate from amplified perturbations that accumulate during long-term rollouts, especially in chaotic regimes. To overcome this, we propose the Indirect Neural Corrector (\(\mathrm{INC}\)), which integrates learned corrections into the governing equations rather than applying direct state updates. Our key insight is that \(\mathrm{INC}\) reduces the error amplification on the order of \(Δt^{-1} + L\), where \(Δt\) is the timestep and $L$ the Lipschitz constant. At the same time, our framework poses no architectural requirements and integrates seamlessly with arbitrary neural networks and solvers. We test \(\mathrm{INC}\) in extensive benchmarks, covering numerous differentiable solvers, neural backbones, and test cases ranging from a 1D chaotic system to 3D turbulence. INC improves the long-term trajectory performance (\(R^2\)) by up to 158.7\%, stabilizes blowups under aggressive coarsening, and for complex 3D turbulence cases yields speed-ups of several orders of magnitude. INC thus enables stable, efficient PDE emulation with formal error reduction, paving the way for faster scientific and engineering simulations with reliable physics guarantees. Our source code is available at https://github.com/tum-pbs/INC

</details>


### [740] [MolEdit: Knowledge Editing for Multimodal Molecule Language Models](https://arxiv.org/abs/2511.12770)
*Zhenyu Lei,Patrick Soga,Yaochen Zhu,Yinhan He,Yushun Dong,Jundong Li*

Main category: cs.LG

TL;DR: 本文提出了MolEdit，一种用于分子语言模型（MoLMs）知识编辑的新框架，旨在解决分子到描述和描述到分子生成任务中的知识更新问题。同时构建了MEBench基准来评估编辑效果。


<details>
  <summary>Details</summary>
Motivation: 由于训练数据可能过时或被恶意篡改，现有的分子语言模型可能包含并传播错误知识，因此需要有效的知识编辑方法来修正特定知识而不影响其他无关知识。

Method: 提出MolEdit框架，结合多专家知识适配器（Multi-Expert Knowledge Adapter）和专家感知编辑开关（Expertise-Aware Editing Switcher），实现对不同分子特征的定向修改，并仅在输入匹配已编辑知识时激活相应适配器，以减少干扰。

Result: 在两个主流MoLM上实验表明，MolEdit相比基线方法可靠性提升最高达18.8%，局部性改善达12.0%，同时保持高效性。

Conclusion: MolEdit为分子语言模型的知识编辑提供了有效解决方案，推动了多模态分子知识的持续更新，在生物医学、化学等领域具有重要应用潜力。

Abstract: Understanding and continuously refining multimodal molecular knowledge is crucial for advancing biomedicine, chemistry, and materials science. Molecule language models (MoLMs) have become powerful tools in these domains, integrating structural representations (e.g., SMILES strings, molecular graphs) with rich contextual descriptions (e.g., physicochemical properties). However, MoLMs can encode and propagate inaccuracies due to outdated web-mined training corpora or malicious manipulation, jeopardizing downstream discovery pipelines. While knowledge editing has been explored for general-domain AI, its application to MoLMs remains uncharted, presenting unique challenges due to the multifaceted and interdependent nature of molecular knowledge. In this paper, we take the first step toward MoLM editing for two critical tasks: molecule-to-caption generation and caption-to-molecule generation. To address molecule-specific challenges, we propose MolEdit, a powerful framework that enables targeted modifications while preserving unrelated molecular knowledge. MolEdit combines a Multi-Expert Knowledge Adapter that routes edits to specialized experts for different molecular facets with an Expertise-Aware Editing Switcher that activates the adapters only when input closely matches the stored edits across all expertise, minimizing interference with unrelated knowledge. To systematically evaluate editing performance, we introduce MEBench, a comprehensive benchmark assessing multiple dimensions, including Reliability (accuracy of the editing), Locality (preservation of irrelevant knowledge), and Generality (robustness to reformed queries). Across extensive experiments on two popular MoLM backbones, MolEdit delivers up to 18.8% higher Reliability and 12.0% better Locality than baselines while maintaining efficiency. The code is available at: https://github.com/LzyFischer/MolEdit.

</details>


### [741] [Scalable Multi-Objective and Meta Reinforcement Learning via Gradient Estimation](https://arxiv.org/abs/2511.12779)
*Zhenshuo Zhang,Minxuan Duan,Youran Ye,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 提出了一种两阶段方法（meta-training + fine-tuning）来高效估计多目标强化学习中的策略分组，通过任务亲和力矩阵进行聚类，显著提升性能与训练效率。


<details>
  <summary>Details</summary>
Motivation: 在多目标强化学习中，随着目标数量增加，单一策略难以有效优化所有目标；需找到最优的任务分组方式以提升训练效率和性能。

Method: 采用元训练学习多任务元策略，再通过一阶近似快速适应随机子集，利用适应过程中的损失变化估计任务亲和力矩阵，并据此进行聚类分组。

Result: 在多个机器人控制和Meta-World基准上平均优于现有方法16%，速度加快达26倍；消融实验显示损失驱动的聚类比随机或梯度相似性分组提升19%。

Conclusion: PolicyGradEx能高效估计任务亲和力并实现高性能多目标策略学习，兼顾准确性与计算效率，适用于大规模多任务强化学习场景。

Abstract: We study the problem of efficiently estimating policies that simultaneously optimize multiple objectives in reinforcement learning (RL). Given $n$ objectives (or tasks), we seek the optimal partition of these objectives into $k \ll n$ groups, where each group comprises related objectives that can be trained together. This problem arises in applications such as robotics, control, and preference optimization in language models, where learning a single policy for all $n$ objectives is suboptimal as $n$ grows. We introduce a two-stage procedure -- meta-training followed by fine-tuning -- to address this problem. We first learn a meta-policy for all objectives using multitask learning. Then, we adapt the meta-policy to multiple randomly sampled subsets of objectives. The adaptation step leverages a first-order approximation property of well-trained policy networks, which is empirically verified to be accurate within a $2\%$ error margin across various RL environments. The resulting algorithm, PolicyGradEx, efficiently estimates an aggregate task-affinity score matrix given a policy evaluation algorithm. Based on the estimated affinity score matrix, we cluster the $n$ objectives into $k$ groups by maximizing the intra-cluster affinity scores. Experiments on three robotic control and the Meta-World benchmarks demonstrate that our approach outperforms state-of-the-art baselines by $16\%$ on average, while delivering up to $26\times$ faster speedup relative to performing full training to obtain the clusters. Ablation studies validate each component of our approach. For instance, compared with random grouping and gradient-similarity-based grouping, our loss-based clustering yields an improvement of $19\%$. Finally, we analyze the generalization error of policy networks by measuring the Hessian trace of the loss surface, which gives non-vacuous measures relative to the observed generalization errors.

</details>


### [742] [Physics-Constrained Adaptive Neural Networks Enable Real-Time Semiconductor Manufacturing Optimization with Minimal Training Data](https://arxiv.org/abs/2511.12788)
*Rubén Darío Guerrero*

Main category: cs.LG

TL;DR: 提出一种物理约束自适应学习框架，通过可学习参数自动校准电磁近似，同时最小化边缘放置误差（EPE），在极紫外光刻优化中实现亚纳米精度，显著减少训练样本需求和推理时间。


<details>
  <summary>Details</summary>
Motivation: 传统方法在极紫外光刻优化中耗时巨大且难以达到亚纳米精度，学术界的物理信息神经网络与工业实际需求之间存在鸿沟。

Method: 构建一个包含菲涅尔衍射、材料吸收、光学点扩散函数模糊、相移效应和对比度调制的可微分模块的框架，结合几何模式匹配目标，通过物理约束学习进行联合物理校准和制造精度优化。

Result: 在仅50个训练样本每图案的情况下，实现了0.664-2.536 nm的EPE性能，相比无物理约束的CNN基线平均提升69.9%，训练后推理速度显著加快，且所需训练样本比特定图案CNN方法少90%。

Conclusion: 物理约束自适应学习是一种面向实时半导体制造优化的基础性方法，弥合了学术研究与工业部署之间的关键差距。

Abstract: The semiconductor industry faces a computational crisis in extreme ultraviolet (EUV) lithography optimization, where traditional methods consume billions of CPU hours while failing to achieve sub-nanometer precision. We present a physics-constrained adaptive learning framework that automatically calibrates electromagnetic approximations through learnable parameters $\boldsymbolθ = \{θ_d, θ_a, θ_b, θ_p, θ_c\}$ while simultaneously minimizing Edge Placement Error (EPE) between simulated aerial images and target photomasks. The framework integrates differentiable modules for Fresnel diffraction, material absorption, optical point spread function blur, phase-shift effects, and contrast modulation with direct geometric pattern matching objectives, enabling cross-geometry generalization with minimal training data. Through physics-constrained learning on 15 representative patterns spanning current production to future research nodes, we demonstrate consistent sub-nanometer EPE performance (0.664-2.536 nm range) using only 50 training samples per pattern. Adaptive physics learning achieves an average improvement of 69.9\% over CNN baselines without physics constraints, with a significant inference speedup over rigorous electromagnetic solvers after training completion. This approach requires 90\% fewer training samples through cross-geometry generalization compared to pattern-specific CNN training approaches. This work establishes physics-constrained adaptive learning as a foundational methodology for real-time semiconductor manufacturing optimization, addressing the critical gap between academic physics-informed neural networks and industrial deployment requirements through joint physics calibration and manufacturing precision objectives.

</details>


### [743] [Optimal Look-back Horizon for Time Series Forecasting in Federated Learning](https://arxiv.org/abs/2511.12791)
*Dahao Tang,Nan Yang,Yanli Li,Zhiyu Zhu,Zhibo Jin,Dong Yuan*

Main category: cs.LG

TL;DR: 提出了一种在联邦时间序列预测中自适应选择回看窗口的原理性框架，通过内在空间表示和损失分解理论，证明最优预测误差在不可约损失开始饱和时取得最小值。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习场景下，数据去中心化、异构且非独立同分布，现有方法难以有效选择合适的时间回看窗口。

Method: 引入合成数据生成器（SDG）捕捉客户端数据的时序结构，并构建映射到具有明确几何与统计特性的内在表示空间的变换，进而分解预测损失为贝叶斯项和近似项。

Result: 理论分析表明，增加回看窗口虽有助于识别确定性模式，但会因模型复杂度上升而增加近似误差；总预测损失在不可约损失开始饱和的最小窗口处达到最小。

Conclusion: 为联邦时间序列预测中的自适应回看窗口选择提供了严格的理论基础。

Abstract: Selecting an appropriate look-back horizon remains a fundamental challenge in time series forecasting (TSF), particularly in the federated learning scenarios where data is decentralized, heterogeneous, and often non-independent. While recent work has explored horizon selection by preserving forecasting-relevant information in an intrinsic space, these approaches are primarily restricted to centralized and independently distributed settings. This paper presents a principled framework for adaptive horizon selection in federated time series forecasting through an intrinsic space formulation. We introduce a synthetic data generator (SDG) that captures essential temporal structures in client data, including autoregressive dependencies, seasonality, and trend, while incorporating client-specific heterogeneity. Building on this model, we define a transformation that maps time series windows into an intrinsic representation space with well-defined geometric and statistical properties. We then derive a decomposition of the forecasting loss into a Bayesian term, which reflects irreducible uncertainty, and an approximation term, which accounts for finite-sample effects and limited model capacity. Our analysis shows that while increasing the look-back horizon improves the identifiability of deterministic patterns, it also increases approximation error due to higher model complexity and reduced sample efficiency. We prove that the total forecasting loss is minimized at the smallest horizon where the irreducible loss starts to saturate, while the approximation loss continues to rise. This work provides a rigorous theoretical foundation for adaptive horizon selection for time series forecasting in federated learning.

</details>


### [744] [Genomic Next-Token Predictors are In-Context Learners](https://arxiv.org/abs/2511.12797)
*Nathan Breslow,Aayush Mishra,Mahler Revsine,Michael C. Schatz,Anqi Liu,Daniel Khashabi*

Main category: cs.LG

TL;DR: 本研究首次证明了基因组序列中可通过大规模预测训练自然涌现出上下文学习（ICL）能力，表明ICL可能是对丰富数据进行大规模预测建模的通用结果，而不仅限于语言领域。


<details>
  <summary>Details</summary>
Motivation: 探究上下文学习（ICL）是否仅源于人类语言的统计特性，还是可在其他符号序列（如基因组）中通过大规模预测训练自然产生。

Method: 基于Evo2基因组模型（以核苷酸预测为目标训练），设计控制实验框架，在语言和基因组两种形式下对比符号推理任务中的ICL表现。

Result: 基因组模型在增加上下文示例时表现出与语言模型类似的对数线性模式归纳能力提升，证实ICL可在基因组序列中自然涌现。

Conclusion: ICL可超越语言模态，在具有丰富统计结构的非语言序列中通过大规模预测学习自发形成，支持其作为一种模态无关的元学习机制的统一观点。

Abstract: In-context learning (ICL) -- the capacity of a model to infer and apply abstract patterns from examples provided within its input -- has been extensively studied in large language models trained for next-token prediction on human text. In fact, prior work often attributes this emergent behavior to distinctive statistical properties in human language. This raises a fundamental question: can ICL arise organically in other sequence domains purely through large-scale predictive training?
  To explore this, we turn to genomic sequences, an alternative symbolic domain rich in statistical structure. Specifically, we study the Evo2 genomic model, trained predominantly on next-nucleotide (A/T/C/G) prediction, at a scale comparable to mid-sized LLMs. We develop a controlled experimental framework comprising symbolic reasoning tasks instantiated in both linguistic and genomic forms, enabling direct comparison of ICL across genomic and linguistic models. Our results show that genomic models, like their linguistic counterparts, exhibit log-linear gains in pattern induction as the number of in-context demonstrations increases. To the best of our knowledge, this is the first evidence of organically emergent ICL in genomic sequences, supporting the hypothesis that ICL arises as a consequence of large-scale predictive modeling over rich data. These findings extend emergent meta-learning beyond language, pointing toward a unified, modality-agnostic view of in-context learning.

</details>


### [745] [The Alignment Game: A Theory of Long-Horizon Alignment Through Recursive Curation](https://arxiv.org/abs/2511.12804)
*Ali Falahati,Mohammad Mohammadi Amiri,Kate Larson,Lukasz Golab*

Main category: cs.LG

TL;DR: 本文提出了自消耗生成模型中递归对齐的首个形式化基础，揭示了基于Bradley-Terry模型的两阶段筛选机制下三种收敛模式，并证明了一个根本性不可能定理：任何基于BT的递归筛选机制无法同时保持多样性、对称影响和消除初始化依赖。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型开始训练于自身输出，用户偏好对齐不再是单次过程，而是递归演化问题。现有研究缺乏对这种长期递归再训练影响的理论分析框架。

Method: 构建了一个基于Bradley-Terry模型的两阶段筛选机制，将对齐建模为模型拥有者与公众用户之间的动态博弈，采用动态社会选择理论进行形式化分析。

Result: 发现了三种结构收敛状态：共识崩溃、在共享最优解上的妥协、以及不对称优化；并证明了一个根本的不可能定理，即无法同时满足多样性保留、对称影响力和独立于初始化三个理想属性。

Conclusion: 对齐不是静态目标，而是一个受权力不对称和路径依赖塑造的动态均衡过程，递归对齐机制设计需权衡多个不可兼得的理想特性。

Abstract: In self-consuming generative models that train on their own outputs, alignment with user preferences becomes a recursive rather than one-time process. We provide the first formal foundation for analyzing the long-term effects of such recursive retraining on alignment. Under a two-stage curation mechanism based on the Bradley-Terry (BT) model, we model alignment as an interaction between two factions: the Model Owner, who filters which outputs should be learned by the model, and the Public User, who determines which outputs are ultimately shared and retained through interactions with the model. Our analysis reveals three structural convergence regimes depending on the degree of preference alignment: consensus collapse, compromise on shared optima, and asymmetric refinement. We prove a fundamental impossibility theorem: no recursive BT-based curation mechanism can simultaneously preserve diversity, ensure symmetric influence, and eliminate dependence on initialization. Framing the process as dynamic social choice, we show that alignment is not a static goal but an evolving equilibrium, shaped both by power asymmetries and path dependence.

</details>


### [746] [Expressive Temporal Specifications for Reward Monitoring](https://arxiv.org/abs/2511.12808)
*Omar Adalat,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 本文提出了一种基于有限迹上的定量线性时序逻辑（$\text{LTL}_f[\mathcal{F}]$）的奖励监控器合成方法，用于生成密集的运行时奖励信号，以提升强化学习中长视野任务的训练效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习中奖励函数的设计至关重要，但稀疏奖励问题严重影响训练效率，尤其是在长视野决策任务中。现有方法多依赖布尔语义，难以提供充分的中间反馈。

Method: 利用$\text{LTL}_f[\mathcal{F}]$的表达能力构建定量奖励监控器，通过状态标记函数生成针对非马尔可夫性质的密集奖励流，无需依赖特定学习算法。

Result: 实验表明，所提出的定量监控器在任务完成度的量化指标和收敛速度上均优于或等同于传统布尔监控器，且适用于多种环境。

Conclusion: 该方法有效缓解了稀疏奖励问题，为强化学习提供了可解释、密集且算法无关的奖励生成框架，特别适合复杂、长视野的任务。

Abstract: Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\text{LTL}_f[\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.

</details>


### [747] [Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs](https://arxiv.org/abs/2511.12817)
*Shasha Zhou,Mingyu Huang,Jack Cole,Charles Britton,Ming Yin,Jan Wolber,Ke Li*

Main category: cs.LG

TL;DR: 本文提出FAITH框架，利用医学知识图谱（KG）对大语言模型（LLM）生成的医疗回答进行自动化事实性评估，无需参考答案，通过将回答分解为原子命题并链接到KG进行评分，实验证明该方法与临床医生判断高度相关，且具有鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在高风险的医疗环境中部署大语言模型需要严格的验证以确保安全性，而现有评估方法缺乏可靠性和可解释性，因此需要一种自动化的、基于知识的评估手段来衡量LLM生成内容的事实准确性。

Method: 提出FAITH框架，将LLM生成的回答分解为原子主张，通过实体链接和关系匹配将其映射到医学知识图谱，并基于知识图谱中的证据路径进行打分，实现无需参考答案的自动化事实性评估。

Result: 在多种医疗任务上的实验表明，KG驱动的评估方法与人类临床医生的主观评价具有较高相关性，能有效区分不同能力水平的LLM，且对文本变化具有鲁棒性，同时提供可解释的评分依据。

Conclusion: 尽管存在局限性，但利用医学知识图谱进行自动化事实性评估是提升医疗领域LLM可靠性的一个重要方向。

Abstract: The recent proliferation of large language models (LLMs) holds the potential to revolutionize healthcare, with strong capabilities in diverse medical tasks. Yet, deploying LLMs in high-stakes healthcare settings requires rigorous verification and validation to understand any potential harm. This paper investigates the reliability and viability of using medical knowledge graphs (KGs) for the automated factuality evaluation of LLM-generated responses. To ground this investigation, we introduce FAITH, a framework designed to systematically probe the strengths and limitations of this KG-based approach. FAITH operates without reference answers by decomposing responses into atomic claims, linking them to a medical KG, and scoring them based on evidence paths. Experiments on diverse medical tasks with human subjective evaluations demonstrate that KG-grounded evaluation achieves considerably higher correlations with clinician judgments and can effectively distinguish LLMs with varying capabilities. It is also robust to textual variances. The inherent explainability of its scoring can further help users understand and mitigate the limitations of current LLMs. We conclude that while limitations exist, leveraging KGs is a prominent direction for automated factuality assessment in healthcare.

</details>


### [748] [Catastrophic Forgetting in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.12828)
*Mohammad Marufur Rahman,Guanchu Wang,Kaixiong Zhou,Minghan Chen,Fan Yang*

Main category: cs.LG

TL;DR: 本文研究了Kolmogorov-Arnold网络（KANs）在持续学习中的灾难性遗忘问题，提出理论框架解释其遗忘机制，并引入KAN-LoRA用于高效参数微调，实验表明KANs在高维任务中仍易遗忘。


<details>
  <summary>Details</summary>
Motivation: 尽管KANs被认为具有抗遗忘潜力，但其在持续学习中的实际表现和局限尚不清楚，需系统分析其遗忘机制。

Method: 通过理论建模分析激活函数支持重叠与数据本征维度对遗忘的影响，并在合成与视觉任务上进行实验验证；提出KAN-LoRA适配器用于语言模型的高效持续微调。

Result: 发现KANs在低维算法任务中表现良好，但在图像分类和语言建模等高维任务中仍易发生灾难性遗忘；KAN-LoRA在知识编辑任务中表现出有效性。

Conclusion: KANs并非天然免疫灾难性遗忘，其表现依赖于数据复杂性和激活结构，需结合适配方法提升其在高维持续学习中的性能。

Abstract: Catastrophic forgetting is a longstanding challenge in continual learning, where models lose knowledge from earlier tasks when learning new ones. While various mitigation strategies have been proposed for Multi-Layer Perceptrons (MLPs), recent architectural advances like Kolmogorov-Arnold Networks (KANs) have been suggested to offer intrinsic resistance to forgetting by leveraging localized spline-based activations. However, the practical behavior of KANs under continual learning remains unclear, and their limitations are not well understood. To address this, we present a comprehensive study of catastrophic forgetting in KANs and develop a theoretical framework that links forgetting to activation support overlap and intrinsic data dimension. We validate these analyses through systematic experiments on synthetic and vision tasks, measuring forgetting dynamics under varying model configurations and data complexity. Further, we introduce KAN-LoRA, a novel adapter design for parameter-efficient continual fine-tuning of language models, and evaluate its effectiveness in knowledge editing tasks. Our findings reveal that while KANs exhibit promising retention in low-dimensional algorithmic settings, they remain vulnerable to forgetting in high-dimensional domains such as image classification and language modeling. These results advance the understanding of KANs' strengths and limitations, offering practical insights for continual learning system design.

</details>


### [749] [An Evaluation of Representation Learning Methods in Particle Physics Foundation Models](https://arxiv.org/abs/2511.12829)
*Michael Chen,Raghav Kansal,Abhijith Gandrakota,Zichun Hao,Jennifer Ngadiuba,Maria Spiropulu*

Main category: cs.LG

TL;DR: 本文在统一框架下系统评估了粒子物理中的表示学习目标，使用基于Transformer的共享编码器和标准化流程，比较了对比学习、掩码粒子建模和生成重建等方法，并提出了改进架构，在基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 为了推动粒子物理领域表示学习的发展，需要一个统一的框架来公平比较不同学习目标的效果，并明确各方法的优势与局限。

Method: 采用统一的Transformer粒子云编码器，结合标准化预处理、匹配采样和一致的评估协议，在喷注分类数据集上对比监督与自监督对比学习、掩码粒子建模和生成重建目标，并引入针对性的监督架构改进。

Result: 实现了对不同学习目标的控制变量比较，明确了各类目标的优劣，所提出的架构改进取得了当前最优的基准性能。

Conclusion: 该工作为粒子物理中的基础模型发展提供了可复现的基准和参考点，有助于促进社区内更透明和稳健的技术进步。

Abstract: We present a systematic evaluation of representation learning objectives for particle physics within a unified framework. Our study employs a shared transformer-based particle-cloud encoder with standardized preprocessing, matched sampling, and a consistent evaluation protocol on a jet classification dataset. We compare contrastive (supervised and self-supervised), masked particle modeling, and generative reconstruction objectives under a common training regimen. In addition, we introduce targeted supervised architectural modifications that achieve state-of-the-art performance on benchmark evaluations. This controlled comparison isolates the contributions of the learning objective, highlights their respective strengths and limitations, and provides reproducible baselines. We position this work as a reference point for the future development of foundation models in particle physics, enabling more transparent and robust progress across the community.

</details>


### [750] [Connectivity-Guided Sparsification of 2-FWL GNNs: Preserving Full Expressivity with Improved Efficiency](https://arxiv.org/abs/2511.12838)
*Rongqin Chen,Fan Mo,Pak Lon Ip,Shenghui Zhang,Dan Wu,Ye Li,Leong Hou U*

Main category: cs.LG

TL;DR: 提出Co-Sparsify，一种基于图拓扑结构的高效高阶图神经网络稀疏化框架，在保持2-FWL完全表达力的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 高阶图神经网络（HOGNNs）虽具有强表达力，但O(n^3)的计算复杂度限制其应用，现有加速方法往往牺牲表达能力。

Method: 提出Co-Sparsify框架，利用图的双连通分量结构识别并去除可证明冗余的3节点交互，仅在双连通分量内保留高阶交互，其余部分使用2节点消息传递或全局读出。

Result: 理论证明Co-Sparsified GNN与2-FWL测试等价；实验表明其在合成任务上准确率相当或更优，并在ZINC、QM9等真实数据集上达到SOTA性能。

Conclusion: 高表达力与高效率可兼得，基于图拓扑结构的原理性稀疏化是构建高效强大GNN的有效路径。

Abstract: Higher-order Graph Neural Networks (HOGNNs) based on the 2-FWL test achieve superior expressivity by modeling 2- and 3-node interactions, but at $\mathcal{O}(n^3)$ computational cost. However, this computational burden is typically mitigated by existing efficiency methods at the cost of reduced expressivity. We propose \textbf{Co-Sparsify}, a connectivity-aware sparsification framework that eliminates \emph{provably redundant} computations while preserving full 2-FWL expressive power. Our key insight is that 3-node interactions are expressively necessary only within \emph{biconnected components} -- maximal subgraphs where every pair of nodes lies on a cycle. Outside these components, structural relationships can be fully captured via 2-node message passing or global readout, rendering higher-order modeling unnecessary. Co-Sparsify restricts 2-node message passing to connected components and 3-node interactions to biconnected ones, removing computation without approximation or sampling. We prove that Co-Sparsified GNNs are as expressive as the 2-FWL test. Empirically, on PPGN, Co-Sparsify matches or exceeds accuracy on synthetic substructure counting tasks and achieves state-of-the-art performance on real-world benchmarks (ZINC, QM9). This study demonstrates that high expressivity and scalability are not mutually exclusive: principled, topology-guided sparsification enables powerful, efficient GNNs with theoretical guarantees.

</details>


### [751] [RoS-Guard: Robust and Scalable Online Change Detection with Delay-Optimal Guarantees](https://arxiv.org/abs/2511.12846)
*Zelin Zhu,Yancheng Huang,Kai Yang*

Main category: cs.LG

TL;DR: 提出了一种名为RoS-Guard的鲁棒且高效的在线变化检测算法，适用于存在不确定性的线性系统，通过神经网络展开实现GPU加速并提供理论性能保证。


<details>
  <summary>Details</summary>
Motivation: 现有在线变化检测方法通常依赖精确的系统知识假设，这在实际中因估计误差和环境变化而不现实，且在大规模系统中效率较低。

Method: 通过对OCD优化问题进行紧致松弛与重构，并采用神经网络展开技术，实现高效的并行计算和GPU加速。

Result: 实验表明RoS-Guard在大规模系统场景下具有显著的计算速度提升，并提供了关于误报率和检测延迟的理论性能保证。

Conclusion: RoS-Guard是一种在不确定环境下高效、鲁棒的在线变化检测方法，兼具理论保障与实际计算优势。

Abstract: Online change detection (OCD) aims to rapidly identify change points in streaming data and is critical in applications such as power system monitoring, wireless network sensing, and financial anomaly detection. Existing OCD methods typically assume precise system knowledge, which is unrealistic due to estimation errors and environmental variations. Moreover, existing OCD methods often struggle with efficiency in large-scale systems. To overcome these challenges, we propose RoS-Guard, a robust and optimal OCD algorithm tailored for linear systems with uncertainty. Through a tight relaxation and reformulation of the OCD optimization problem, RoS-Guard employs neural unrolling to enable efficient parallel computation via GPU acceleration. The algorithm provides theoretical guarantees on performance, including expected false alarm rate and worst-case average detection delay. Extensive experiments validate the effectiveness of RoS-Guard and demonstrate significant computational speedup in large-scale system scenarios.

</details>


### [752] [From Black-Box to White-Box: Control-Theoretic Neural Network Interpretability](https://arxiv.org/abs/2511.12852)
*Jihoon Moon*

Main category: cs.LG

TL;DR: 提出一种控制论框架，通过局部线性化、可控性和可观测性格拉姆矩阵及汉克尔奇异值来分析训练好的神经网络的内部计算机制。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然性能优越，但难以从机制上解释其内部运作，因此需要一种可解释的方法来理解其内部计算过程。

Method: 将训练好的神经网络视为非线性状态空间系统，围绕特定输入的隐藏激活模式进行局部线性化，构建以隐藏神经元激活为状态的状态空间模型，并利用输入-状态和状态-输出雅可比矩阵计算可控性与可观测性格拉姆矩阵，进而得到汉克尔奇异值和模态。

Result: 在简单前馈网络（如1-2-2-1 SwiGLU和2-3-3-2 GELU）上的实验表明，激活饱和会降低可控性、缩小主导汉克尔奇异值，并改变主导内部模态所对应的神经元集合。

Conclusion: 该方法将神经网络转化为一组局部白盒动态模型，提供了衡量神经元和路径重要性的原则性方式，并指出了可用于剪枝或施加约束以提升可解释性的关键内部方向。

Abstract: Deep neural networks achieve state of the art performance but remain difficult to interpret mechanistically. In this work, we propose a control theoretic framework that treats a trained neural network as a nonlinear state space system and uses local linearization, controllability and observability Gramians, and Hankel singular values to analyze its internal computation. For a given input, we linearize the network around the corresponding hidden activation pattern and construct a state space model whose state consists of hidden neuron activations. The input state and state output Jacobians define local controllability and observability Gramians, from which we compute Hankel singular values and associated modes. These quantities provide a principled notion of neuron and pathway importance: controllability measures how easily each neuron can be excited by input perturbations, observability measures how strongly each neuron influences the output, and Hankel singular values rank internal modes that carry input output energy. We illustrate the framework on simple feedforward networks, including a 1 2 2 1 SwiGLU network and a 2 3 3 2 GELU network. By comparing different operating points, we show how activation saturation reduces controllability, shrinks the dominant Hankel singular value, and shifts the dominant internal mode to a different subset of neurons. The proposed method turns a neural network into a collection of local white box dynamical models and suggests which internal directions are natural candidates for pruning or constraints to improve interpretability.

</details>


### [753] [An approach of deep reinforcement learning for maximizing the net present value of stochastic projects](https://arxiv.org/abs/2511.12865)
*Wei Xu,Fan Yang,Qinyuan Cui,Zhi Chen*

Main category: cs.LG

TL;DR: 本文研究了具有随机活动持续时间和现金流的项目调度问题，提出基于双深度Q网络（DDQN）的求解方法，以最大化期望净现值（NPV），实验表明该方法在大规模和高不确定性环境下优于传统策略。


<details>
  <summary>Details</summary>
Motivation: 项目调度中活动持续时间和现金流具有随机性，且需满足前后置约束，传统方法难以有效处理大规模或高不确定性场景下的NPV优化问题。

Method: 将问题建模为离散时间马尔可夫决策过程（MDP），采用双深度Q网络（DDQN）进行求解，并通过消融实验验证网络结构的有效性。

Result: DDQN在期望NPV、计算能力、策略可靠性和适应性方面均优于传统静态与动态策略，尤其在大规模和高不确定性环境中表现更优；双网络结构缓解了动作值的过估计问题，目标网络提升了训练收敛性与鲁棒性。

Conclusion: DDQN不仅能有效提升复杂项目调度中的期望净现值，还提供了一个稳定且高效的策略实施框架，适用于高不确定性环境下的项目管理。

Abstract: This paper investigates a project with stochastic activity durations and cash flows under discrete scenarios, where activities must satisfy precedence constraints generating cash inflows and outflows. The objective is to maximize expected net present value (NPV) by accelerating inflows and deferring outflows. We formulate the problem as a discrete-time Markov Decision Process (MDP) and propose a Double Deep Q-Network (DDQN) approach. Comparative experiments demonstrate that DDQN outperforms traditional rigid and dynamic strategies, particularly in large-scale or highly uncertain environments, exhibiting superior computational capability, policy reliability, and adaptability. Ablation studies further reveal that the dual-network architecture mitigates overestimation of action values, while the target network substantially improves training convergence and robustness. These results indicate that DDQN not only achieves higher expected NPV in complex project optimization but also provides a reliable framework for stable and effective policy implementation.

</details>


### [754] [On the Information Processing of One-Dimensional Wasserstein Distances with Finite Samples](https://arxiv.org/abs/2511.12881)
*Cheongjae Jang,Jonghyun Won,Soyeon Jun,Chun Kee Chung,Keehyoung Joo,Yung-Kyun Noh*

Main category: cs.LG

TL;DR: 本文研究了一维Wasserstein距离在有限样本下捕捉点态密度差异的能力，利用泊松过程分离率因子，揭示其在神经尖峰序列解码和氨基酸接触频率数据中的有效性。


<details>
  <summary>Details</summary>
Motivation: 当两个分布的支持集显著重叠但密度存在明显点态差异时，传统Wasserstein距离难以准确识别这些差异，本文旨在分析其在有限样本下如何捕捉并区分密度与支持集的差异。

Method: 通过泊松过程建模并分离率因子，对一维Wasserstein距离的信息处理能力进行理论分析，并在真实数据上验证其性能。

Result: 证明了一维Wasserstein距离能够有效捕捉点态密度差异，并同时反映密度率和支持集的变化，在神经尖峰解码和蛋白质数据中表现出良好性能。

Conclusion: 一维Wasserstein距离不仅可度量支持集差异，还能有效揭示密度函数的点态差异，尤其适用于具有复杂密度结构的有限样本场景。

Abstract: Leveraging the Wasserstein distance -- a summation of sample-wise transport distances in data space -- is advantageous in many applications for measuring support differences between two underlying density functions. However, when supports significantly overlap while densities exhibit substantial pointwise differences, it remains unclear whether and how this transport information can accurately identify these differences, particularly their analytic characterization in finite-sample settings. We address this issue by conducting an analysis of the information processing capabilities of the one-dimensional Wasserstein distance with finite samples. By utilizing the Poisson process and isolating the rate factor, we demonstrate the capability of capturing the pointwise density difference with Wasserstein distances and how this information harmonizes with support differences. The analyzed properties are confirmed using neural spike train decoding and amino acid contact frequency data. The results reveal that the one-dimensional Wasserstein distance highlights meaningful density differences related to both rate and support.

</details>


### [755] [Method of Manufactured Learning for Solver-free Training of Neural Operators](https://arxiv.org/abs/2511.12890)
*Arth Sojitra,Omer San*

Main category: cs.LG

TL;DR: 提出了一种名为制造学习法（MML）的求解器无关框架，通过解析构造物理一致的数据集来训练神经算子，避免依赖昂贵的数值模拟或实验数据，在多种经典方程上实现了高精度和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子训练依赖于耗时的实验或计算成本高昂的数值求解器生成的数据，限制了可扩展性和在不同物理系统中的应用。因此需要一种不依赖求解器的高效训练方法。

Method: 受制造解法启发，MML通过从可控的解析空间采样平滑候选解，并直接应用控制微分算子推导对应的源项，从而构建训练数据集；在推理时将源项设为零，使神经算子恢复求解原方程的能力。该方法与网络结构无关，适用于任何算子学习范式，本文以傅里叶神经算子为例进行验证。

Result: 在热传导、对流、Burgers及扩散-反应等典型方程上，MML实现了高谱精度、低残差误差，并表现出对未见条件的良好泛化能力。

Conclusion: MML通过将数据生成重构为解析合成过程，提供了一条可扩展、不依赖求解器的路径，用于构建保持物理规律忠实性的神经算子。

Abstract: Training neural operators to approximate mappings between infinite-dimensional function spaces often requires extensive datasets generated by either demanding experimental setups or computationally expensive numerical solvers. This dependence on solver-based data limits scalability and constrains exploration across physical systems. Here we introduce the Method of Manufactured Learning (MML), a solver-independent framework for training neural operators using analytically constructed, physics-consistent datasets. Inspired by the classical method of manufactured solutions, MML replaces numerical data generation with functional synthesis, i.e., smooth candidate solutions are sampled from controlled analytical spaces, and the corresponding forcing fields are derived by direct application of the governing differential operators. During inference, setting these forcing terms to zero restores the original governing equations, allowing the trained neural operator to emulate the true solution operator of the system. The framework is agnostic to network architecture and can be integrated with any operator learning paradigm. In this paper, we employ Fourier neural operator as a representative example. Across canonical benchmarks including heat, advection, Burgers, and diffusion-reaction equations. MML achieves high spectral accuracy, low residual errors, and strong generalization to unseen conditions. By reframing data generation as a process of analytical synthesis, MML offers a scalable, solver-agnostic pathway toward constructing physically grounded neural operators that retain fidelity to governing laws without reliance on expensive numerical simulations or costly experimental data for training.

</details>


### [756] [Functional Mean Flow in Hilbert Space](https://arxiv.org/abs/2511.12898)
*Zhiqi Li,Yuchen Sun,Greg Turk,Bo Zhu*

Main category: cs.LG

TL;DR: 提出了一种在无限维希尔伯特空间中定义的一步生成模型Functional Mean Flow (FMF)，扩展了Mean Flow框架到函数域，并提供了Functional Flow Matching的理论公式和高效训练与采样的实现，适用于时间序列、图像、PDE和3D几何等多种函数数据生成任务。


<details>
  <summary>Details</summary>
Motivation: 将现有的一步Flow Matching方法扩展到函数域，以处理更广泛的连续性功能数据生成问题。

Method: 提出了Functional Flow Matching的理论框架，并设计了基于x_1预测的稳定变体，结合高效的训练与采样策略，在无限维希尔伯特空间中实现生成模型。

Result: FMF能够有效应用于时间序列、图像、偏微分方程解和3D几何等函数数据的一步生成，且x_1预测变体提升了训练稳定性。

Conclusion: FMF为函数数据提供了一种实用的一步Flow Matching生成方法，在多种任务中展现出广泛适用性和稳定性。

Abstract: We present Functional Mean Flow (FMF) as a one-step generative model defined in infinite-dimensional Hilbert space. FMF extends the one-step Mean Flow framework to functional domains by providing a theoretical formulation for Functional Flow Matching and a practical implementation for efficient training and sampling. We also introduce an $x_1$-prediction variant that improves stability over the original $u$-prediction form. The resulting framework is a practical one-step Flow Matching method applicable to a wide range of functional data generation tasks such as time series, images, PDEs, and 3D geometry.

</details>


### [757] [Contrastive Entropy Bounds for Density and Conditional Density Decomposition](https://arxiv.org/abs/2511.12903)
*Bo Hu,Jose C. Principe*

Main category: cs.LG

TL;DR: 本文从贝叶斯高斯视角研究神经网络特征的可解释性，提出通过优化概率界来学习模型，并利用希尔伯特空间分析高斯算子的迹与核范数，分别用于训练自编码器和混合密度网络。


<details>
  <summary>Details</summary>
Motivation: 旨在从贝叶斯框架理解神经网络的学习过程，提升对模型特征的可解释性，并解决多输出网络中中心重复的平凡解问题。

Method: 采用贝叶斯高斯建模，结合希尔伯特空间中的内积与范数定义边界和损失函数，引入高斯算子的迹和核范数作为优化目标，并设计编码器-混合-解码器结构以提高边界紧致性。

Result: 发现自编码器的目标等价于最大化高斯算子的迹；提出使用核范数作为发散度训练MDN，并证明新方法可增加样本多样性、避免平凡解。

Conclusion: 高斯算子的迹和核范数分别为自编码器和MDN提供了有效的训练准则，在小方差高斯混合假设下可定量分析边界，增强了模型的可解释性和表现力。

Abstract: This paper studies the interpretability of neural network features from a Bayesian Gaussian view, where optimizing a cost is reaching a probabilistic bound; learning a model approximates a density that makes the bound tight and the cost optimal, often with a Gaussian mixture density. The two examples are Mixture Density Networks (MDNs) using the bound for the marginal and autoencoders using the conditional bound. It is a known result, not only for autoencoders, that minimizing the error between inputs and outputs maximizes the dependence between inputs and the middle.
  We use Hilbert space and decomposition to address cases where a multiple-output network produces multiple centers defining a Gaussian mixture. Our first finding is that an autoencoder's objective is equivalent to maximizing the trace of a Gaussian operator, the sum of eigenvalues under bases orthonormal w.r.t. the data and model distributions. This suggests that, when a one-to-one correspondence as needed in autoencoders is unnecessary, we can instead maximize the nuclear norm of this operator, the sum of singular values, to maximize overall rank rather than trace. Thus the trace of a Gaussian operator can be used to train autoencoders, and its nuclear norm can be used as divergence to train MDNs.
  Our second test uses inner products and norms in a Hilbert space to define bounds and costs. Such bounds often have an extra norm compared to KL-based bounds, which increases sample diversity and prevents the trivial solution where a multiple-output network produces the same constant, at the cost of requiring a sample batch to estimate and optimize. We propose an encoder-mixture-decoder architecture whose decoder is multiple-output, producing multiple centers per sample, potentially tightening the bound. Assuming the data are small-variance Gaussian mixtures, this upper bound can be tracked and analyzed quantitatively.

</details>


### [758] [LinkedIn Profile Characteristics and Professional Success Indicators](https://arxiv.org/abs/2511.12905)
*Tania-Amanda Fredrick Eneye,Ashlesha Malla,Pawan Paudel*

Main category: cs.LG

TL;DR: 该研究利用超过6.2万个匿名LinkedIn用户数据，通过机器学习模型分析个人资料特征与职业成功（如晋升、关注者数量和职业发展速度）之间的关系，发现晋升最具可预测性，而粉丝增长更复杂，为优化职业策略提供了实用见解。


<details>
  <summary>Details</summary>
Motivation: 探讨LinkedIn个人资料特征如何影响职业成功，帮助专业人士更好地理解和优化其在线职业形象。

Method: 使用超过62,000个匿名LinkedIn用户的数据集，采用机器学习技术构建预测模型，分析不同特征对职业成功的影响力。

Result: 晋升最容易被预测，关注者增长的模式更为复杂，表明不同职业成功指标具有不同的驱动因素。

Conclusion: LinkedIn上的某些个人资料特征可有效预测职业成功，尤其是晋升；研究结果为个人职业发展策略和平台优化提供了参考依据。

Abstract: This study explores the relationship between LinkedIn profile characteristics and professional success, focusing on the indicators of promotions, follower count, and career progression rate. By leveraging a dataset of over 62,000 anonymized LinkedIn profiles, we developed predictive models using machine learning techniques to identify the most influential factors driving professional success. Results indicate that while promotions are highly predictable, follower growth exhibits greater complexity. This research provides actionable insights for professionals seeking to optimize their LinkedIn presence and career strategies.

</details>


### [759] [APT: Affine Prototype-Timestamp For Time Series Forecasting Under Distribution Shift](https://arxiv.org/abs/2511.12945)
*Yujie Li,Zezhi Shao,Chengqing Yu,Yisong Fu,Tao Sun,Yongjun Xu,Fei Wang*

Main category: cs.LG

TL;DR: 提出了一种名为Affine Prototype Timestamp (APT)的轻量级模块，用于在时间序列预测中注入全局分布特征，有效应对分布偏移、缺失值和噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在处理时间序列预测中的分布偏移时表现不佳，主要依赖局部统计归一化，难以捕捉全局分布变化，且现有方法如RevIN在面对缺失值、噪声和无效仿射变换时存在局限。

Method: 通过基于时间戳条件的原型学习，动态生成用于调制输入和输出序列的仿射参数，将全局分布特征引入归一化-预测流程，并结合自监督的分布感知聚类实例进行学习。

Result: 在六个基准数据集和多种骨干网络-归一化组合上的实验表明，APT显著提升了在分布偏移下的预测性能，且具有低计算开销和良好的兼容性。

Conclusion: APT是一种灵活、轻量且通用的插件模块，能有效增强时间序列预测模型对分布偏移的鲁棒性，适用于任意骨干网络和归一化策略。

Abstract: Time series forecasting under distribution shift remains challenging, as existing deep learning models often rely on local statistical normalization (e.g., mean and variance) that fails to capture global distribution shift. Methods like RevIN and its variants attempt to decouple distribution and pattern but still struggle with missing values, noisy observations, and invalid channel-wise affine transformation. To address these limitations, we propose Affine Prototype Timestamp (APT), a lightweight and flexible plug-in module that injects global distribution features into the normalization-forecasting pipeline. By leveraging timestamp conditioned prototype learning, APT dynamically generates affine parameters that modulate both input and output series, enabling the backbone to learn from self-supervised, distribution-aware clustered instances. APT is compatible with arbitrary forecasting backbones and normalization strategies while introducing minimal computational overhead. Extensive experiments across six benchmark datasets and multiple backbone-normalization combinations demonstrate that APT significantly improves forecasting performance under distribution shift.

</details>


### [760] [A FEDformer-Based Hybrid Framework for Anomaly Detection and Risk Forecasting in Financial Time Series](https://arxiv.org/abs/2511.12951)
*Ziling Fan,Ruijia Liang,Yiwen Hu*

Main category: cs.LG

TL;DR: 本文提出了一种基于FEDformer的混合框架，用于金融时间序列中的异常检测与风险预测，结合频域增强分解Transformer、残差异常检测器和风险预测模块，在S&P 500、NASDAQ和Brent原油数据上表现优于传统模型，显著提升预测精度与异常识别能力。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型（如LSTM、GRU）难以捕捉金融时间序列中的长期依赖和复杂周期模式，且对非平稳数据建模能力有限，亟需更有效的模型以实现早期风险预警。

Method: 提出一种融合FEDformer的混合框架：利用FEDformer在时频域分解趋势与季节成分，结合残差-based异常检测器识别异常波动，并通过风险预测头输出潜在金融风险，实现联合建模。

Result: 在S&P 500、NASDAQ Composite和Brent Crude Oil数据集（2000–2024）上实验表明，相较基准模型，RMSE降低15.7%，F1-score提升11.5%，有效捕捉金融波动并支持市场崩盘预警。

Conclusion: 该FEDformer混合框架在金融时间序列建模中表现出优越性能，兼具可解释性与预测准确性，适用于构建可靠的异常检测与风险预警系统。

Abstract: Financial markets are inherently volatile and prone to sudden disruptions such as market crashes, flash collapses, and liquidity crises. Accurate anomaly detection and early risk forecasting in financial time series are therefore crucial for preventing systemic instability and supporting informed investment decisions. Traditional deep learning models, such as LSTM and GRU, often fail to capture long-term dependencies and complex periodic patterns in highly nonstationary financial data. To address this limitation, this study proposes a FEDformer-Based Hybrid Framework for Anomaly Detection and Risk Forecasting in Financial Time Series, which integrates the Frequency Enhanced Decomposed Transformer (FEDformer) with a residual-based anomaly detector and a risk forecasting head. The FEDformer module models temporal dynamics in both time and frequency domains, decomposing signals into trend and seasonal components for improved interpretability. The residual-based detector identifies abnormal fluctuations by analyzing prediction errors, while the risk head predicts potential financial distress using learned latent embeddings. Experiments conducted on the S&P 500, NASDAQ Composite, and Brent Crude Oil datasets (2000-2024) demonstrate the superiority of the proposed model over benchmark methods, achieving a 15.7 percent reduction in RMSE and an 11.5 percent improvement in F1-score for anomaly detection. These results confirm the effectiveness of the model in capturing financial volatility, enabling reliable early-warning systems for market crash prediction and risk management.

</details>


### [761] [Global Cross-Time Attention Fusion for Enhanced Solar Flare Prediction from Multivariate Time Series](https://arxiv.org/abs/2511.12955)
*Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 提出了一种基于Transformer的全局跨时间注意力融合（GCTAF）模型，用于解决太阳耀斑预测中多变量时间序列分类的长程依赖和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 太阳耀斑事件具有高度不平衡性，剧烈耀斑稀少且难以捕捉长时序依赖，传统方法在建模全局时间模式上存在局限。

Method: 设计GCTAF架构，引入可学习的全局交叉注意力token，通过跨时间注意力机制汇总整个序列中的显著时间模式，并与输入序列交互融合，增强模型对非连续关键时间点的识别能力。

Result: 在基准太阳耀斑数据集上验证，GCTAF在检测强烈耀斑方面表现优越，提升了预测性能。

Conclusion: 改进的Transformer架构（GCTAF）能有效捕捉判别性时序动态，是太阳耀斑预测任务中具有高潜力的替代方案。

Abstract: Multivariate time series classification is increasingly investigated in space weather research as a means to predict intense solar flare events, which can cause widespread disruptions across modern technological systems. Magnetic field measurements of solar active regions are converted into structured multivariate time series, enabling predictive modeling across segmented observation windows. However, the inherently imbalanced nature of solar flare occurrences, where intense flares are rare compared to minor flare events, presents a significant barrier to effective learning. To address this challenge, we propose a novel Global Cross-Time Attention Fusion (GCTAF) architecture, a transformer-based model to enhance long-range temporal modeling. Unlike traditional self-attention mechanisms that rely solely on local interactions within time series, GCTAF injects a set of learnable cross-attentive global tokens that summarize salient temporal patterns across the entire sequence. These tokens are refined through cross-attention with the input sequence and fused back into the temporal representation, enabling the model to identify globally significant, non-contiguous time points that are critical for flare prediction. This mechanism functions as a dynamic attention-driven temporal summarizer that augments the model's capacity to capture discriminative flare-related dynamics. We evaluate our approach on the benchmark solar flare dataset and show that GCTAF effectively detects intense flares and improves predictive performance, demonstrating that refining transformer-based architectures presents a high-potential alternative for solar flare prediction tasks.

</details>


### [762] [RAGPulse: An Open-Source RAG Workload Trace to Optimize RAG Serving Systems](https://arxiv.org/abs/2511.12979)
*Zhengchao Wang,Yitao Hu,Jianing Ye,Zhuxuan Chang,Jiazheng Yu,Youpeng Deng,Keqiu Li*

Main category: cs.LG

TL;DR: 本文提出了RAGPulse，一个开源的检索增强生成（RAG）工作负载追踪数据集，源自服务超过4万名师生的大学问答系统，旨在填补学术研究与实际部署之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有的通用大语言模型推理追踪无法捕捉RAG系统的多阶段流程和知识依赖等特性，导致学术研究与实际应用之间存在性能鸿沟。

Method: 作者构建了RAGPulse数据集，包含真实世界RAG系统的请求轨迹，采用基于哈希的隐私保护数据格式，并对其系统架构和统计特征进行了详细分析。

Result: 分析表明，真实RAG工作负载具有显著的时间局部性和高度倾斜的热点文档访问模式。该数据集为内容感知批处理、检索缓存等优化策略提供了高保真基础。

Conclusion: RAGPulse为研究人员提供了一个真实的RAG工作负载基准，有助于推动高效、可靠的RAG系统优化技术的发展。

Abstract: Retrieval-Augmented Generation (RAG) is a critical paradigm for building reliable, knowledge-intensive Large Language Model (LLM) applications. However, the multi-stage pipeline (retrieve, generate) and unique workload characteristics (e.g., knowledge dependency) of RAG systems pose significant challenges for serving performance optimization. Existing generic LLM inference traces fail to capture these RAG-specific dynamics, creating a significant performance gap between academic research and real-world deployment. To bridge this gap, this paper introduces RAGPulse, an open-source RAG workload trace dataset. This dataset was collected from an university-wide Q&A system serving that has served more than 40,000 students and faculties since April 2024. We detail RAGPulse's system architecture, its privacy-preserving hash-based data format, and provide an in-depth statistical analysis. Our analysis reveals that real-world RAG workloads exhibit significant temporal locality and a highly skewed hot document access pattern. RAGPulse provides a high-fidelity foundation for researchers to develop and validate novel optimization strategies for RAG systems, such as content-aware batching and retrieval caching, ultimately enhancing the efficiency and reliability of RAG services. The code is available at https://github.com/flashserve/RAGPulse.

</details>


### [763] [Angular Gradient Sign Method: Uncovering Vulnerabilities in Hyperbolic Networks](https://arxiv.org/abs/2511.12985)
*Minsoo Jo,Dongyoon Yang,Taesup Kim*

Main category: cs.LG

TL;DR: 提出一种基于双曲空间几何特性的新型对抗攻击方法，通过在切空间中分解梯度并仅利用角向扰动生成更有效的对抗样本。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法（如FGSM、PGD）忽略双曲空间的几何结构，导致攻击效率低或几何不一致，需设计符合非欧几里得几何特性的攻击策略。

Method: 在双曲空间的切空间中计算损失函数梯度，将其分解为径向和角向分量，并仅使用角向分量进行扰动，从而在语义敏感方向上生成对抗样本。

Result: 在图像分类、跨模态检索等任务上，所提方法比传统攻击具有更高的欺骗率，且扰动更具语义影响，揭示了双曲嵌入的深层漏洞。

Conclusion: 几何感知的对抗攻击在弯曲表示空间中至关重要，本文为攻击层次化嵌入提供了有理论依据的框架。

Abstract: Adversarial examples in neural networks have been extensively studied in Euclidean geometry, but recent advances in \textit{hyperbolic networks} call for a reevaluation of attack strategies in non-Euclidean geometries. Existing methods such as FGSM and PGD apply perturbations without regard to the underlying hyperbolic structure, potentially leading to inefficient or geometrically inconsistent attacks. In this work, we propose a novel adversarial attack that explicitly leverages the geometric properties of hyperbolic space. Specifically, we compute the gradient of the loss function in the tangent space of hyperbolic space, decompose it into a radial (depth) component and an angular (semantic) component, and apply perturbation derived solely from the angular direction. Our method generates adversarial examples by focusing perturbations in semantically sensitive directions encoded in angular movement within the hyperbolic geometry. Empirical results on image classification, cross-modal retrieval tasks and network architectures demonstrate that our attack achieves higher fooling rates than conventional adversarial attacks, while producing high-impact perturbations with deeper insights into vulnerabilities of hyperbolic embeddings. This work highlights the importance of geometry-aware adversarial strategies in curved representation spaces and provides a principled framework for attacking hierarchical embeddings.

</details>


### [764] [Learning Branching Policies for MILPs with Proximal Policy Optimization](https://arxiv.org/abs/2511.12986)
*Abdelouahed Ben Mhamed,Assia Kamal-Idrissi,Amal El Fallah Seghrouchni*

Main category: cs.LG

TL;DR: 提出了一种基于强化学习的分支策略框架TGPPO，用于改进混合整数线性规划的求解，相比模仿学习方法具有更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于模仿学习的分支策略容易过拟合专家示范，难以泛化到结构不同或未见过的实例。

Method: 采用近端策略优化（PPO）这一强化学习算法，结合参数化的状态空间表示，动态捕捉搜索树的演化上下文，训练分支策略。

Result: 实验表明，TGPPO在减少探索节点数和改善p-Primal-Dual积分方面优于现有学习型策略，尤其在分布外实例上表现更优。

Conclusion: 强化学习有潜力开发出对异构MILP实例更具鲁棒性和适应性的分支策略。

Abstract: Branch-and-Bound (B\&B) is the dominant exact solution method for Mixed Integer Linear Programs (MILP), yet its exponential time complexity poses significant challenges for large-scale instances. The growing capabilities of machine learning have spurred efforts to improve B\&B by learning data-driven branching policies. However, most existing approaches rely on Imitation Learning (IL), which tends to overfit to expert demonstrations and struggles to generalize to structurally diverse or unseen instances. In this work, we propose Tree-Gate Proximal Policy Optimization (TGPPO), a novel framework that employs Proximal Policy Optimization (PPO), a Reinforcement Learning (RL) algorithm, to train a branching policy aimed at improving generalization across heterogeneous MILP instances. Our approach builds on a parameterized state space representation that dynamically captures the evolving context of the search tree. Empirical evaluations show that TGPPO often outperforms existing learning-based policies in terms of reducing the number of nodes explored and improving p-Primal-Dual Integrals (PDI), particularly in out-of-distribution instances. These results highlight the potential of RL to develop robust and adaptable branching strategies for MILP solvers.

</details>


### [765] [Are Graph Transformers Necessary? Efficient Long-Range Message Passing with Fractal Nodes in MPNNs](https://arxiv.org/abs/2511.13010)
*Jeongwhan Choi,Seungjun Park,Sumin Park,Sung-Bae Cho,Noseong Park*

Main category: cs.LG

TL;DR: 提出了一种称为分形节点的新概念，通过聚合子图级特征表示来增强消息传递神经网络（MPNN）的表达能力，缓解过压缩问题，并在保持计算效率的同时实现与图Transformer相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（GNNs）在平衡局部和全局信息方面存在困难，而图Transformers虽能实现长距离交互但忽略了MPNN的局部性和效率。

Method: 引入分形节点的概念，利用真实网络中的分形结构特性，在原始节点共存的情况下自适应地聚合子图级别的特征表示，从而加强子图内部的特征相似性并提供直接的捷径连接以促进长距离传播。

Result: 实验结果表明该方法提高了MPNN的表达能力，在多个任务上达到或超过了图Transformer的性能，同时保持了MPNN的计算效率。

Conclusion: 分形节点有效缓解了过压缩问题，增强了MPNN处理长距离依赖的能力，是一种兼具高效性和强表达力的新型图学习框架。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning on graph-structured data, but often struggle to balance local and global information. While graph Transformers aim to address this by enabling long-range interactions, they often overlook the inherent locality and efficiency of Message Passing Neural Networks (MPNNs). We propose a new concept called fractal nodes, inspired by the fractal structure observed in real-world networks. Our approach is based on the intuition that graph partitioning naturally induces fractal structure, where subgraphs often reflect the connectivity patterns of the full graph. Fractal nodes are designed to coexist with the original nodes and adaptively aggregate subgraph-level feature representations, thereby enforcing feature similarity within each subgraph. We show that fractal nodes alleviate the over-squashing problem by providing direct shortcut connections that enable long-range propagation of subgraph-level representations. Experiment results show that our method improves the expressive power of MPNNs and achieves comparable or better performance to graph Transformers while maintaining the computational efficiency of MPNN by improving the long-range dependencies of MPNN.

</details>


### [766] [The Good, The Bad, and The Hybrid: A Reward Structure Showdown in Reasoning Models Training](https://arxiv.org/abs/2511.13016)
*Subramanyam Sahoo*

Main category: cs.LG

TL;DR: 提出了一种统一框架，用于研究在数学推理任务中对大语言模型进行微调时的硬性、连续性和混合奖励结构，通过结合正确性、困惑度、推理质量和一致性来形式化并实证评估奖励函数。


<details>
  <summary>Details</summary>
Motivation: 奖励设计在基于人类反馈的强化学习和对齐研究中至关重要，但不同奖励结构的影响尚不明确，需要系统性研究以提升模型训练效果。

Method: 在GSM8K数据集上使用Qwen3-4B模型结合LoRA微调，形式化并评估了多种奖励形式，并提出了一个自适应混合奖励调度器，动态切换离散与连续信号以平衡探索与稳定性。

Result: 实验结果表明，混合奖励结构相比纯硬性或连续奖励能显著提升收敛速度和训练稳定性。

Conclusion: 混合奖励结构更优，自适应调度策略为通过自适应奖励建模实现模型对齐提供了有效路径。

Abstract: Reward design is central to reinforcement learning from human feedback (RLHF) and alignment research. In this work, we propose a unified framework to study hard, continuous, and hybrid reward structures for fine-tuning large language models (LLMs) on mathematical reasoning tasks. Using Qwen3-4B with LoRA fine-tuning on the GSM8K dataset, we formalize and empirically evaluate reward formulations that incorporate correctness, perplexity, reasoning quality, and consistency. We introduce an adaptive hybrid reward scheduler that transitions between discrete and continuous signals, balancing exploration and stability. Our results show that hybrid reward structures improve convergence speed and training stability over purely hard or continuous approaches, offering insights for alignment via adaptive reward modeling.

</details>


### [767] [The Final-Stage Bottleneck: A Systematic Dissection of the R-Learner for Network Causal Inference](https://arxiv.org/abs/2511.13018)
*Sairam S,Sara Girdhar,Shivam Soni*

Main category: cs.LG

TL;DR: 本文对图数据上的R-Learner框架进行了大规模实证研究，发现最终阶段CATE估计器的归纳偏置是性能的主要决定因素，并揭示了“表示瓶颈”问题：即使使用强大的GNN辅助模型，若最终阶段忽略图结构，则性能会严重下降（MSE > 4.0）。作者提出端到端的Graph R-Learner，显著优于基线模型，并通过“枢纽-边缘权衡”分析解释了由GNN过压缩引起的拓扑依赖性‘辅助瓶颈’。


<details>
  <summary>Details</summary>
Motivation: R-Learner在估计异质处理效应方面表现优异，但其在图数据上的应用受限于对最终阶段模型正确设定的假设。当因果异质性依赖于图结构时，现有方法可能失效，因此需要系统评估其在图上的有效性并识别关键瓶颈。

Method: 通过大规模实证研究，系统分析R-Learner在多种合成与半合成图基准上的表现，比较不同最终阶段模型与GNN辅助模型的组合效果；提出端到端的Graph R-Learner；并通过‘枢纽-边缘权衡’分析揭示拓扑结构对辅助模型的影响机制。

Result: 发现最终阶段的归纳偏置对性能起主导作用；证实存在‘表示瓶颈’——图盲的最终阶段导致MSE超过4.0，即使使用强大GNN辅助模型也无效；所提Graph R-Learner显著优于非DML的GNN T-Learner基线；识别出与GNN过压缩相关的‘辅助瓶颈’现象。

Conclusion: R-Learner在图数据上的成功关键在于最终阶段是否显式建模图结构，而非仅依赖复杂辅助模型；必须打破‘表示瓶颈’才能有效估计图上的异质处理效应；研究强调了为图因果推断设计专用最终阶段模型的重要性。

Abstract: The R-Learner is a powerful, theoretically-grounded framework for estimating heterogeneous treatment effects, prized for its robustness to nuisance model errors. However, its application to network data, where causal heterogeneity is often graph-dependent, presents a critical challenge to its core assumption of a well-specified final-stage model. In this paper, we conduct a large-scale empirical study to systematically dissect the R-Learner framework on graphs. We provide the first rigorous evidence that the primary driver of performance is the inductive bias of the final-stage CATE estimator, an effect that dominates the choice of nuisance models. Our central finding is the quantification of a catastrophic "representation bottleneck": we prove with overwhelming statistical significance (p < 0.001) that R-Learners with a graph-blind final stage fail completely (MSE > 4.0), even when paired with powerful GNN nuisance models. Conversely, our proposed end-to-end Graph R-Learner succeeds and significantly outperforms a strong, non-DML GNN T-Learner baseline. Furthermore, we identify and provide a mechanistic explanation for a subtle, topology-dependent "nuisance bottleneck," linking it to GNN over-squashing via a targeted "Hub-Periphery Trade-off" analysis. Our findings are validated across diverse synthetic and semi-synthetic benchmarks. We release our code as a reproducible benchmark to facilitate future research on this critical "final-stage bottleneck."

</details>


### [768] [Learning Time-Scale Invariant Population-Level Neural Representations](https://arxiv.org/abs/2511.13022)
*Eshani Patel,Yisong Yue,Geeling Chau*

Main category: cs.LG

TL;DR: 本文提出了一种时间尺度增强预训练方法（TSAP），以提升神经时间序列基础模型在不同预处理时间尺度下的泛化能力和表示不变性。


<details>
  <summary>Details</summary>
Motivation: 现有的神经时间序列模型对预训练与下游任务之间的时间尺度预处理差异敏感，缺乏不变性，限制了其泛化能力。

Method: 通过系统分析时间尺度不匹配的影响，引入时间尺度增强预训练（TSAP），在预训练阶段引入时间尺度的数据增强，从而学习更具鲁棒性的跨通道时空表示。

Result: TSAP在多种解码任务上显著提升了模型对不同时间尺度的鲁棒性，并在表示空间中建立了时间尺度不变性。

Conclusion: 处理预处理多样性，尤其是时间尺度的一致性，是构建可泛化的神经基础模型的关键步骤。

Abstract: General-purpose foundation models for neural time series can help accelerate neuroscientific discoveries and enable applications such as brain computer interfaces (BCIs). A key component in scaling these models is population-level representation learning, which leverages information across channels to capture spatial as well as temporal structure. Population-level approaches have recently shown that such representations can be both efficient to learn on top of pretrained temporal encoders and produce useful representations for decoding a variety of downstream tasks. However, these models remain sensitive to mismatches in preprocessing, particularly on time-scales, between pretraining and downstream settings. We systematically examine how time-scale mismatches affects generalization and find that existing representations lack invariance. To address this, we introduce Time-scale Augmented Pretraining (TSAP), which consistently improves robustness to different time-scales across decoding tasks and builds invariance in the representation space. These results highlight handling preprocessing diversity as a key step toward building generalizable neural foundation models.

</details>


### [769] [SLMQuant:Benchmarking Small Language Model Quantization for Practical Deployment](https://arxiv.org/abs/2511.13023)
*Jiacheng Wang,Yejun Zeng,Jinyang Guo,Yuqing Ma,Aishan Liu,Xianglong Liu*

Main category: cs.LG

TL;DR: 本文提出了SLMQuant，首个针对小型语言模型（SLMs）的系统性量化压缩基准，揭示了SLMs与大模型在量化敏感性上的根本差异，并提出面向SLMs的压缩设计原则。


<details>
  <summary>Details</summary>
Motivation: 尽管小型语言模型（SLMs）在边缘设备上具有资源效率优势，但现有模型压缩技术（尤其是量化）主要针对大模型设计，其在SLMs上的适用性和效率尚不明确，存在显著的研究空白。

Method: 构建了SLMQuant基准，对多种架构和任务下的先进量化方法在SLMs上进行多维度系统评估，分析性能表现与瓶颈。

Result: 发现SLMs与LLMs在量化敏感性方面存在本质差异，直接迁移为LLMs优化的量化技术会导致次优结果；识别出影响SLM量化的关键因素。

Conclusion: 应基于SLMs独特的架构特征和训练动态设计专用的量化方法；SLMQuant为在资源受限场景下高效部署轻量级语言模型提供了基础框架和关键指导。

Abstract: Despite the growing interest in Small Language Models (SLMs) as resource-efficient alternatives to Large Language Models (LLMs), their deployment on edge devices remains challenging due to unresolved efficiency gaps in model compression. While quantization has proven effective for LLMs, its applicability to SLMs is significantly underexplored, with critical questions about differing quantization bottlenecks and efficiency profiles. This paper introduces SLMQuant, the first systematic benchmark for evaluating LLM compression techniques when applied to SLMs. Through comprehensive multi-track evaluations across diverse architectures and tasks, we analyze how state-of-the-art quantization methods perform on SLMs. Our findings reveal fundamental disparities between SLMs and LLMs in quantization sensitivity, demonstrating that direct transfer of LLM-optimized techniques leads to suboptimal results due to SLMs' unique architectural characteristics and training dynamics. We identify key factors governing effective SLM quantization and propose actionable design principles for SLM-tailored compression. SLMQuant establishes a foundational framework for advancing efficient SLM deployment on low-end devices in edge applications, and provides critical insights for deploying lightweight language models in resource-constrained scenarios.

</details>


### [770] [One-Step Generative Policies with Q-Learning: A Reformulation of MeanFlow](https://arxiv.org/abs/2511.13035)
*Zeyuan Wang,Da Li,Yulin Chen,Ye Shi,Liang Bai,Tianyuan Yu,Yanwei Fu*

Main category: cs.LG

TL;DR: 提出一种基于MeanFlow重构的单步生成策略，用于离线强化学习，实现直接从噪声到动作的生成，兼容Q学习，具有高效、表达力强和训练稳定的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的一次性高斯策略难以捕捉复杂的多模态动作分布，而基于流的方法通常需要两阶段训练或蒸馏，限制了其在Q学习中的应用效率和表达能力。

Method: 通过残差形式重构MeanFlow，将速度场估计与噪声到动作的转换集成到单一策略网络中，实现直接的噪声到动作生成，并支持与Q学习结合的单阶段训练。

Result: 在OGBench和D4RL共73个任务上的实验表明，该方法在离线和离线到在线强化学习设置下均表现出色，优于现有方法。

Conclusion: 所提出的方法在保持快速推理的同时，提升了策略的表达能力和训练稳定性，为离线强化学习提供了一种高效且强大的单步生成策略。

Abstract: We introduce a one-step generative policy for offline reinforcement learning that maps noise directly to actions via a residual reformulation of MeanFlow, making it compatible with Q-learning. While one-step Gaussian policies enable fast inference, they struggle to capture complex, multimodal action distributions. Existing flow-based methods improve expressivity but typically rely on distillation and two-stage training when trained with Q-learning. To overcome these limitations, we propose to reformulate MeanFlow to enable direct noise-to-action generation by integrating the velocity field and noise-to-action transformation into a single policy network-eliminating the need for separate velocity estimation. We explore several reformulation variants and identify an effective residual formulation that supports expressive and stable policy learning. Our method offers three key advantages: 1) efficient one-step noise-to-action generation, 2) expressive modelling of multimodal action distributions, and 3) efficient and stable policy learning via Q-learning in a single-stage training setup. Extensive experiments on 73 tasks across the OGBench and D4RL benchmarks demonstrate that our method achieves strong performance in both offline and offline-to-online reinforcement learning settings. Code is available at https://github.com/HiccupRL/MeanFlowQL.

</details>


### [771] [Bi-View Embedding Fusion: A Hybrid Learning Approach for Knowledge Graph's Nodes Classification Addressing Problems with Limited Data](https://arxiv.org/abs/2511.13044)
*Rosario Napoli,Giovanni Lonia,Antonio Celesti,Massimo Villari,Maria Fazio*

Main category: cs.LG

TL;DR: 本文提出了一种名为Bi-View的新型混合方法，通过结合Node2Vec和GraphSAGE两种图嵌入技术，增强知识图谱中的节点特征表示，从而提升图机器学习模型在下游任务中的性能，尤其适用于初始特征稀疏的场景。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习需要大量数据，在数据稀疏或不完整的情况下表现受限；而知识图谱虽能表达数据间关系，但其语义特性可能隐藏大量信息，导致图嵌入效果不佳。因此，需要一种能更好挖掘图中潜在信息的方法。

Method: 该方法结合了Node2Vec和GraphSAGE：首先使用Node2Vec通过无监督随机游走捕捉图的结构模式，然后将基于中心性的度量加入节点特征以丰富信息，并作为GraphSAGE的输入进行有监督的邻域信息聚合；最后通过融合层将两种嵌入结合，形成兼具拓扑与语义特性的双视角嵌入空间。

Result: 实验表明，该方法在初始特征较差的情况下显著提升了下游任务的性能，生成的增强图嵌入能够有效利用数据集中隐含的信息，且无需依赖额外的合成数据。

Conclusion: Bi-View通过融合结构与语义信息，提供了一种有效的知识图谱增强方法，为图机器学习在低质量特征场景下的应用奠定了基础。

Abstract: Traditional Machine Learning (ML) methods require large amounts of data to perform well, limiting their applicability in sparse or incomplete scenarios and forcing the usage of additional synthetic data to improve the model training. To overcome this challenge, the research community is looking more and more at Graph Machine Learning (GML) as it offers a powerful alternative by using relationships within data. However, this method also faces limitations, particularly when dealing with Knowledge Graphs (KGs), which can hide huge information due to their semantic nature. This study introduces Bi-View, a novel hybrid approach that increases the informative content of node features in KGs to generate enhanced Graph Embeddings (GEs) that are used to improve GML models without relying on additional synthetic data. The proposed work combines two complementary GE techniques: Node2Vec, which captures structural patterns through unsupervised random walks, and GraphSAGE, which aggregates neighbourhood information in a supervised way. Node2Vec embeddings are first computed to represent the graph topology, and node features are then enriched with centrality-based metrics, which are used as input for the GraphSAGE model. Moreover, a fusion layer combines the original Node2Vec embeddings with the GraphSAGE-influenced representations, resulting in a dual-perspective embedding space. Such a fusion captures both topological and semantic properties of the graph, enabling the model to exploit informative features that may exist in the dataset but that are not explicitly represented. Our approach improves downstream task performance, especially in scenarios with poor initial features, giving the basis for more accurate and precise KG-enanched GML models.

</details>


### [772] [Generalization Bounds for Semi-supervised Matrix Completion with Distributional Side Information](https://arxiv.org/abs/2511.13049)
*Antoine Ledent,Mun Chong Soo,Nong Minh Hieu*

Main category: cs.LG

TL;DR: 本文研究了一种矩阵补全问题，其中真实矩阵和采样分布均为低秩且共享一个子空间，利用未标记数据（隐式反馈）和少量标记数据（显式反馈）进行建模，在理论和实验上验证了该方法在推荐系统中结合显式与隐式反馈的有效性。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统中，显式反馈数据稀疏，而隐式反馈数据丰富但无标签，如何有效结合两者提升推荐性能是一个关键问题。本文旨在通过共享低秩子空间的假设，建立显式与隐式反馈之间的联系，提升矩阵补全效果。

Method: 提出一种基于低秩子空间恢复理论的矩阵补全方法，假设真实矩阵和采样分布均为低秩且共享子空间，利用大量未标记数据估计采样分布P，结合少量带噪声的标记数据估计真实矩阵R，并推导出相应的误差界。

Result: 理论推导出误差界为两项之和，分别随√(nd/M)和√(dr/N)缩放；在合成数据上验证了误差可分解为两独立项；在Douban和MovieLens真实数据集上，即使大部分显式评分被移除，该方法仍优于仅使用显式反馈的基线方法。

Conclusion: 共享低屋子空间的假设为建模显式与隐式反馈提供了有效的理论框架，所提方法能充分利用隐式反馈信息提升推荐性能，验证了该设定在推荐系统中的有效性。

Abstract: We study a matrix completion problem where both the ground truth $R$ matrix and the unknown sampling distribution $P$ over observed entries are low-rank matrices, and \textit{share a common subspace}. We assume that a large amount $M$ of \textit{unlabeled} data drawn from the sampling distribution $P$ is available, together with a small amount $N$ of labeled data drawn from the same distribution and noisy estimates of the corresponding ground truth entries. This setting is inspired by recommender systems scenarios where the unlabeled data corresponds to `implicit feedback' (consisting in interactions such as purchase, click, etc. ) and the labeled data corresponds to the `explicit feedback', consisting of interactions where the user has given an explicit rating to the item. Leveraging powerful results from the theory of low-rank subspace recovery, together with classic generalization bounds for matrix completion models, we show error bounds consisting of a sum of two error terms scaling as $\widetilde{O}\left(\sqrt{\frac{nd}{M}}\right)$ and $\widetilde{O}\left(\sqrt{\frac{dr}{N}}\right)$ respectively, where $d$ is the rank of $P$ and $r$ is the rank of $M$. In synthetic experiments, we confirm that the true generalization error naturally splits into independent error terms corresponding to the estimations of $P$ and and the ground truth matrix $\ground$ respectively. In real-life experiments on Douban and MovieLens with most explicit ratings removed, we demonstrate that the method can outperform baselines relying only on the explicit ratings, demonstrating that our assumptions provide a valid toy theoretical setting to study the interaction between explicit and implicit feedbacks in recommender systems.

</details>


### [773] [Learning from the Undesirable: Robust Adaptation of Language Models without Forgetting](https://arxiv.org/abs/2511.13052)
*Yunhun Nam,Jaehyung Kim,Jongheon Jeong*

Main category: cs.LG

TL;DR: 提出一种名为Learning-from-the-Undesirable (LfU)的正则化方法，通过在微调过程中引入对“不良更新”的一致性约束，缓解语言模型在小数据下过拟合的问题，提升泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在有限数据下进行监督微调（SFT）容易导致语言模型过拟合，依赖虚假模式或损害通用能力，因此需要更有效的正则化策略来平衡专业化与知识保留。

Method: 提出LfU方法，通过施加一致性正则化，使模型内部表征在经历不良更新（如梯度上升诱导的退化行为）后仍保持一致，利用表征层面的数据增强来提升泛化。

Result: 在多种下游任务上验证了LfU的有效性，数学任务平均性能比标准SFT提升16.8%，且SFT在相同数据下表现下降；输出性能对提示变化的标准差降低92.1%，显示更强鲁棒性。

Conclusion: LfU是一种简单而有效的SFT正则化方案，能在小样本微调中增强模型适应性、保持预训练知识，并显著提升性能与稳定性。

Abstract: Language models (LMs) are often adapted through supervised fine-tuning (SFT) to specialize their capabilities for downstream tasks. However, in typical scenarios where the fine-tuning data is limited, e.g., compared to pre-training, SFT can lead LMs to overfit, causing them to rely on spurious patterns within the target task or to compromise other broadly useful capabilities as a side effect of narrow specialization. In this paper, we propose Learning-from-the-Undesirable (LfU), a simple yet effective regularization scheme for SFT to mitigate overfitting issues when fine-tuning LMs with limited data. Specifically, we aim to regularize the fine-tuning process to favor solutions that are resilient to "undesirable" model updates, e.g., gradient ascent steps that steer the model toward undesirable behaviors. To this end, we propose a novel form of consistency regularization that directly aligns internal representations of the model with those after an undesirable update. By leveraging representation-level data augmentation through undesirable updates, LfU effectively promotes generalization under limited data. Our experiments on diverse LM downstream tasks show that LfU serves as an effective prior that enhances adaptability while preserving pretrained knowledge. For example, our LM from LfU achieves a 16.8% average improvement on math tasks compared to vanilla SFT on the same dataset, where the latter even leads to degraded performance on those tasks. Furthermore, LfU exhibits improved robustness to prompt variations, e.g., yielding a 92.1% lower standard deviation in output performances compared to SFT, highlighting its versatile effects.

</details>


### [774] [Self-Organization of Attractor Landscapes in High-Capacity Kernel Logistic Regression Hopfield Networks](https://arxiv.org/abs/2511.13053)
*Akira Tamamori*

Main category: cs.LG

TL;DR: 本文通过几何分析揭示了核方法增强Hopfield网络存储容量的动态机制，提出“峰尖锐度”指标来量化吸引子稳定性，并发现存在一个“优化脊”，在此条件下网络在高负载和全局核情况下实现最大稳定性。


<details>
  <summary>Details</summary>
Motivation: 尽管基于核的学习方法能显著提高Hopfield网络的存储容量，但其背后的动力学机制尚不清楚，本文旨在填补这一空白。

Method: 引入“峰尖锐度”作为新度量，对网络能量景观进行几何分析；系统地改变核宽度和存储负载以构建吸引子形态的相图；理论分解景观梯度为直接“驱动”力和间接“反馈”力。

Result: 发现了“优化脊”现象，即在网络高负载和全局核条件下，直接驱动力量占主导并克服反向集体反馈力量，形成强负相关区域；揭示了网络通过模式间相互作用自组织成协同反馈控制系统。

Conclusion: 该研究提供了高容量联想记忆稳定性的新物理图像，阐明了其背后自组织机制，并为设计高效联想记忆系统提供了原则指导。

Abstract: Kernel-based learning methods can dramatically increase the storage capacity of Hopfield networks, yet the dynamical mechanism behind this enhancement remains poorly understood. We address this gap by conducting a geometric analysis of the network's energy landscape. We introduce a novel metric, ``Pinnacle Sharpness,'' to quantify the local stability of attractors. By systematically varying the kernel width and storage load, we uncover a rich phase diagram of attractor shapes. Our central finding is the emergence of a ``ridge of optimization,'' where the network maximizes attractor stability under challenging high-load and global-kernel conditions. Through a theoretical decomposition of the landscape gradient into a direct ``driving'' force and an indirect ``feedback'' force, we reveal the origin of this phenomenon. The optimization ridge corresponds to a regime of strong anti-correlation between the two forces, where the direct force, amplified by the high storage load, dominates the opposing collective feedback force. This demonstrates a sophisticated self-organization mechanism: the network adaptively harnesses inter-pattern interactions as a cooperative feedback control system to sculpt a robust energy landscape. Our findings provide a new physical picture for the stability of high-capacity associative memories and offer principles for their design.

</details>


### [775] [Latency and Ordering Effects in Online Decisions](https://arxiv.org/abs/2511.13060)
*Duo Yi*

Main category: cs.LG

TL;DR: 提出了一种基于Bregman散度的在线决策系统损失下界分析框架，统一刻画延迟反馈和顺序敏感性的影响，并提供可操作的监控方法。


<details>
  <summary>Details</summary>
Motivation: 在线决策系统常面临延迟反馈和非交换动态（顺序敏感性），传统方法难以同时建模这些因素并提供可解释的性能下界。

Method: 利用Bregman散度作为损失基准，推导出包含理想损失、延迟惩罚、顺序敏感性惩罚及其交互项的结构化下界，并扩展至近正则和弱凸情形；通过2×2随机实验和流式诊断实现四项的估计与监控。

Result: 得到了一个结构化的损失下界表达式，明确分离了延迟、顺序敏感性和非凸性等影响因素；在非凸情况下仍保持鲁棒性保证；提供了实际可操作的监控工具（如交互热图、剪裁率等）。

Conclusion: 该框架将延迟、非交换性和实现差距等异质效应整合为一个可解释、可压力测试的下界，适用于真实系统的调优与诊断。

Abstract: Online decision systems routinely operate under delayed feedback and order-sensitive (noncommutative) dynamics: actions affect which observations arrive, and in what sequence. Taking a Bregman divergence $D_Φ$ as the loss benchmark, we prove that the excess benchmark loss admits a structured lower bound $L \ge L_{\mathrm{ideal}} + g_1(λ) + g_2(\varepsilon_\star) + g_{12}(λ,\varepsilon_\star) - D_{\mathrm{ncx}}$, where $g_1$ and $g_2$ are calibrated penalties for latency and order-sensitivity, $g_{12}$ captures their geometric interaction, and $D_{\mathrm{ncx}}\ge 0$ is a nonconvexity/approximation penalty that vanishes under convex Legendre assumptions. We extend this inequality to prox-regular and weakly convex settings, obtaining robust guarantees beyond the convex case. We also give an operational recipe for estimating and monitoring the four terms via simple $2\times 2$ randomized experiments and streaming diagnostics (effective sample size, clipping rate, interaction heatmaps). The framework packages heterogeneous latency, noncommutativity, and implementation-gap effects into a single interpretable lower-bound statement that can be stress-tested and tuned in real-world systems.

</details>


### [776] [MACKO: Sparse Matrix-Vector Multiplication for Low Sparsity](https://arxiv.org/abs/2511.13061)
*Vladimír Macko,Vladimír Boža*

Main category: cs.LG

TL;DR: MACKO-SpMV是一种针对GPU优化的稀疏矩阵-向量乘法格式和内核，专为解决大语言模型中低且非结构化稀疏性下的效率问题而设计，在50%稀疏度下实现了显著的内存减少和加速。


<details>
  <summary>Details</summary>
Motivation: 现有SpMV方法在处理剪枝后大语言模型常见的低且非结构化稀疏性（30-90%）时表现不佳，导致非结构化剪枝带来的内存节省和速度提升有限。

Method: 提出MACKO-SpMV，一种与GPU执行模型兼容的GPU优化格式和内核联合设计，无需专用硬件单元或特定格式预计算即可高效执行SpMV。

Result: 在50%稀疏度下，相比密集表示实现1.5倍内存减少和1.2-1.5倍加速；相较于cuSPARSE、Sputnik和DASP等基线分别提速2.8-13.0倍、1.9-2.6倍和2.2-2.5倍；应用于Wanda剪枝的Llama2-7B模型时，fp16精度下实现1.5倍内存减少和1.5倍推理加速。

Conclusion: MACKO使得在实际大语言模型工作负载中采用50%非结构化剪枝变得切实可行。

Abstract: Sparse Matrix-Vector Multiplication (SpMV) is a fundamental operation in the inference of sparse Large Language Models (LLMs). Because existing SpMV methods perform poorly under the low and unstructured sparsity (30-90%) commonly observed in pruned LLMs, unstructured pruning provided only limited memory reduction and speedup. We propose MACKO-SpMV, a GPU-optimized format and kernel co-designed to reduce storage overhead while preserving compatibility with the GPU's execution model. This enables efficient SpMV for unstructured sparsity without specialized hardware units (e.g., tensor cores) or format-specific precomputation. Empirical results show that at sparsity 50%, MACKO is the first approach with significant 1.5x memory reduction and 1.2-1.5x speedup over dense representation. Speedups over other SpMV baselines: 2.8-13.0x over cuSPARSE, 1.9-2.6x over Sputnik, and 2.2-2.5x over DASP. Applied to Llama2-7B pruned with Wanda to sparsity 50%, it delivers 1.5x memory reduction and 1.5x faster inference at fp16 precision. Thanks to MACKO, unstructured pruning at 50% sparsity is now justified in real-world LLM workloads.

</details>


### [777] [Self-Adaptive Graph Mixture of Models](https://arxiv.org/abs/2511.13062)
*Mohit Meena,Yash Punjabi,Abhishek A,Vishal Sharma,Mahesh Chandran*

Main category: cs.LG

TL;DR: 提出了一种名为SAGMM的自适应图混合模型框架，通过结合多种GNN架构并利用拓扑感知的注意力门控机制，实现对不同节点的模型选择与组合，在16个基准数据集上表现出优于或匹配现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有GNN模型性能提升趋于平缓，且复杂模型未必优于简单模型；缺乏针对特定任务自动选择最优模型的方法。

Method: 设计了一个模块化的混合模型框架SAGMM，集成多样化的GNN架构，采用拓扑感知的注意力门控机制为每个节点动态分配专家模型，并引入剪枝机制和预训练冻结策略以提升效率。

Result: 在16个涵盖节点分类、图分类、回归和链接预测的基准数据集上，SAGMM consistently outperforms or matches state-of-the-art GNN模型及之前的混合方法。

Conclusion: SAGMM提供了一种高效、鲁棒且可适应不同图结构任务的GNN模型组合方案，有助于突破当前GNN性能瓶颈。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over graph-structured data, yet recent studies have shown that their performance gains are beginning to plateau. In many cases, well-established models such as GCN and GAT, when appropriately tuned, can match or even exceed the performance of more complex, state-of-the-art architectures. This trend highlights a key limitation in the current landscape: the difficulty of selecting the most suitable model for a given graph task or dataset. To address this, we propose Self-Adaptive Graph Mixture of Models (SAGMM), a modular and practical framework that learns to automatically select and combine the most appropriate GNN models from a diverse pool of architectures. Unlike prior mixture-of-experts approaches that rely on variations of a single base model, SAGMM leverages architectural diversity and a topology-aware attention gating mechanism to adaptively assign experts to each node based on the structure of the input graph. To improve efficiency, SAGMM includes a pruning mechanism that reduces the number of active experts during training and inference without compromising performance. We also explore a training-efficient variant in which expert models are pretrained and frozen, and only the gating and task-specific layers are trained. We evaluate SAGMM on 16 benchmark datasets covering node classification, graph classification, regression, and link prediction tasks, and demonstrate that it consistently outperforms or matches leading GNN baselines and prior mixture-based methods, offering a robust and adaptive solution for real-world graph learning.

</details>


### [778] [A Smart-Glasses for Emergency Medical Services via Multimodal Multitask Learning](https://arxiv.org/abs/2511.13078)
*Liuyi Jin,Pasan Gunawardena,Amran Haroon,Runzhi Wang,Sangwoo Lee,Radu Stoleru,Michael Middleton,Zepeng Huo,Jeeeun Kim,Jason Moats*

Main category: cs.LG

TL;DR: EMSGlass是一个基于智能眼镜的系统，结合多模态多任务模型EMSNet和低延迟推理框架EMSServe，提升急救医疗场景下的实时态势感知与决策效率。


<details>
  <summary>Details</summary>
Motivation: 急救人员在高压环境下需快速决策，但面临认知负荷重、信息整合难等问题，现有单模态系统难以满足实际需求。

Method: 提出EMSGlass系统，包含EMSNet（融合文本、生命体征和现场图像的多模态模型）和EMSServe（支持异步模态输入和高效推理的框架），并在真实EMS数据集上训练与优化。

Result: EMSNet在五项关键任务上优于单模态基线；EMSServe实现1.9x-11.7x推理加速；用户研究表明系统可提升急救人员决策速度与操作效率。

Conclusion: EMSGlass有效整合多模态AI技术与急救流程，显著提升现场响应能力，为下一代AI赋能的急救系统提供了可行路径。

Abstract: Emergency Medical Technicians (EMTs) operate in high-pressure environments, making rapid, life-critical decisions under heavy cognitive and operational loads. We present EMSGlass, a smart-glasses system powered by EMSNet, the first multimodal multitask model for Emergency Medical Services (EMS), and EMSServe, a low-latency multimodal serving framework tailored to EMS scenarios. EMSNet integrates text, vital signs, and scene images to construct a unified real-time understanding of EMS incidents. Trained on real-world multimodal EMS datasets, EMSNet simultaneously supports up to five critical EMS tasks with superior accuracy compared to state-of-the-art unimodal baselines. Built on top of PyTorch, EMSServe introduces a modality-aware model splitter and a feature caching mechanism, achieving adaptive and efficient inference across heterogeneous hardware while addressing the challenge of asynchronous modality arrival in the field. By optimizing multimodal inference execution in EMS scenarios, EMSServe achieves 1.9x -- 11.7x speedup over direct PyTorch multimodal inference. A user study evaluation with six professional EMTs demonstrates that EMSGlass enhances real-time situational awareness, decision-making speed, and operational efficiency through intuitive on-glass interaction. In addition, qualitative insights from the user study provide actionable directions for extending EMSGlass toward next-generation AI-enabled EMS systems, bridging multimodal intelligence with real-world emergency response workflows.

</details>


### [779] [Real-time prediction of breast cancer sites using deformation-aware graph neural network](https://arxiv.org/abs/2511.13082)
*Kyunghyun Lee,Yong-Min Shin,Minwoo Shin,Jihun Kim,Sunghwan Lim,Won-Yong Shin,Kyungho Yoon*

Main category: cs.LG

TL;DR: 提出一种基于图神经网络（GNN）的实时可变形乳腺模型，用于间接MRI引导下的乳腺癌活检，显著提高计算速度和精度。


<details>
  <summary>Details</summary>
Motivation: 传统直接MRI引导活检耗时长、成本高，而间接方法缺乏准确的实时乳腺形变建模，限制了临床应用。

Method: 结合MRI图像构建个体化有限元（FE）模型，并利用GNN处理表面位移和基于距离的图数据，实现对肿瘤区域在内的全组织位移的实时预测。

Result: 在幻影和真实患者数据上验证，肿瘤位移预测RMSE小于0.2毫米，DSC达0.977，推理速度比传统FE模拟快4000倍以上。

Conclusion: 该GNN模型能高效准确地预测乳腺肿瘤实时形变，有望提升乳腺癌活检的精准性与效率，具有良好的临床应用前景。

Abstract: Early diagnosis of breast cancer is crucial, enabling the establishment of appropriate treatment plans and markedly enhancing patient prognosis. While direct magnetic resonance imaging-guided biopsy demonstrates promising performance in detecting cancer lesions, its practical application is limited by prolonged procedure times and high costs. To overcome these issues, an indirect MRI-guided biopsy that allows the procedure to be performed outside of the MRI room has been proposed, but it still faces challenges in creating an accurate real-time deformable breast model. In our study, we tackled this issue by developing a graph neural network (GNN)-based model capable of accurately predicting deformed breast cancer sites in real time during biopsy procedures. An individual-specific finite element (FE) model was developed by incorporating magnetic resonance (MR) image-derived structural information of the breast and tumor to simulate deformation behaviors. A GNN model was then employed, designed to process surface displacement and distance-based graph data, enabling accurate prediction of overall tissue displacement, including the deformation of the tumor region. The model was validated using phantom and real patient datasets, achieving an accuracy within 0.2 millimeters (mm) for cancer node displacement (RMSE) and a dice similarity coefficient (DSC) of 0.977 for spatial overlap with actual cancerous regions. Additionally, the model enabled real-time inference and achieved a speed-up of over 4,000 times in computational cost compared to conventional FE simulations. The proposed deformation-aware GNN model offers a promising solution for real-time tumor displacement prediction in breast biopsy, with high accuracy and real-time capability. Its integration with clinical procedures could significantly enhance the precision and efficiency of breast cancer diagnosis.

</details>


### [780] [Synthetic Forgetting without Access: A Few-shot Zero-glance Framework for Machine Unlearning](https://arxiv.org/abs/2511.13116)
*Qipeng Song,Nan Yang,Ziqi Xu,Yue Li,Wei Shao,Feng Xia*

Main category: cs.LG

TL;DR: 提出GFOES框架，用于在无法访问遗忘数据的现实场景下实现机器遗忘，通过生成最优擦除样本和两阶段微调实现有效遗忘与性能保持。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法通常需要完整访问原始训练数据，但在实际中难以满足；本文针对更现实的“少样本零凝视”场景（仅有少量保留数据可用，遗忘数据完全不可访问）展开研究。

Method: 提出GFOES框架，包含生成反馈网络（GFN）和两阶段微调：GFN生成对目标类别高损失的最优擦除样本（OES），以促使模型遗忘特定知识；第一阶段激进遗忘，第二阶段恢复模型在保留类别上的性能。

Result: 在三个图像分类数据集上验证，GFOES仅用5%原始数据即可在logit和表示层实现有效遗忘，同时保持良好的模型性能。

Conclusion: GFOES为数据受限条件下的隐私保护机器学习提供了实用且可扩展的解决方案。

Abstract: Machine unlearning aims to eliminate the influence of specific data from trained models to ensure privacy compliance. However, most existing methods assume full access to the original training dataset, which is often impractical. We address a more realistic yet challenging setting: few-shot zero-glance, where only a small subset of the retained data is available and the forget set is entirely inaccessible. We introduce GFOES, a novel framework comprising a Generative Feedback Network (GFN) and a two-phase fine-tuning procedure. GFN synthesises Optimal Erasure Samples (OES), which induce high loss on target classes, enabling the model to forget class-specific knowledge without access to the original forget data, while preserving performance on retained classes. The two-phase fine-tuning procedure enables aggressive forgetting in the first phase, followed by utility restoration in the second. Experiments on three image classification datasets demonstrate that GFOES achieves effective forgetting at both logit and representation levels, while maintaining strong performance using only 5% of the original data. Our framework offers a practical and scalable solution for privacy-preserving machine learning under data-constrained conditions.

</details>


### [781] [Departures: Distributional Transport for Single-Cell Perturbation Prediction with Neural Schrödinger Bridges](https://arxiv.org/abs/2511.13124)
*Changxi Chi,Yufei Huang,Jun Xia,Jiangbin Zheng,Yunfan Liu,Zelin Zang,Stan Z. Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于Schrödinger Bridge（SB）的新型方法，通过Minibatch-OT配对来直接对齐控制组和扰动后的单细胞群体分布，避免了传统SB方法中双向建模的不适定问题，实现了对单细胞扰动结果的精确预测。


<details>
  <summary>Details</summary>
Motivation: 由于单细胞测序具有破坏性，同一细胞无法在扰动前后同时观测，导致数据不配对，限制了精确建模扰动效应的能力。现有生成模型缺乏显式条件控制或依赖间接分布对齐，难以实现精准扰动建模。

Method: 近似Schrödinger Bridge（SB），利用Minibatch-OT进行样本配对，指导桥过程学习，避免反向过程建模；构建两个SB模型分别处理离散基因激活状态和连续表达分布，并进行联合训练。

Result: 在公共基因和药物扰动数据集上的实验表明，该方法能有效捕捉单细胞异质性响应，并在扰动预测任务上达到当前最优性能。

Conclusion: 所提出的基于Minibatch-OT引导的SB近似方法能够高效、准确地建模单细胞扰动效应，克服了不配对数据带来的挑战，为基因功能分析和药物筛选提供了有力工具。

Abstract: Predicting single-cell perturbation outcomes directly advances gene function analysis and facilitates drug candidate selection, making it a key driver of both basic and translational biomedical research. However, a major bottleneck in this task is the unpaired nature of single-cell data, as the same cell cannot be observed both before and after perturbation due to the destructive nature of sequencing. Although some neural generative transport models attempt to tackle unpaired single-cell perturbation data, they either lack explicit conditioning or depend on prior spaces for indirect distribution alignment, limiting precise perturbation modeling. In this work, we approximate Schrödinger Bridge (SB), which defines stochastic dynamic mappings recovering the entropy-regularized optimal transport (OT), to directly align the distributions of control and perturbed single-cell populations across different perturbation conditions. Unlike prior SB approximations that rely on bidirectional modeling to infer optimal source-target sample coupling, we leverage Minibatch-OT based pairing to avoid such bidirectional inference and the associated ill-posedness of defining the reverse process. This pairing directly guides bridge learning, yielding a scalable approximation to the SB. We approximate two SB models, one modeling discrete gene activation states and the other continuous expression distributions. Joint training enables accurate perturbation modeling and captures single-cell heterogeneity. Experiments on public genetic and drug perturbation datasets show that our model effectively captures heterogeneous single-cell responses and achieves state-of-the-art performance.

</details>


### [782] [Soft Conflict-Resolution Decision Transformer for Offline Multi-Task Reinforcement Learning](https://arxiv.org/abs/2511.13133)
*Shudong Wang,Xinfei Wang,Chenhao Zhang,Shanchen Pang,Haiyuan Gui,Wenhao Ji,Xiaojian Liao*

Main category: cs.LG

TL;DR: 提出了一种基于参数重要性的软冲突解决方法SoCo-DT，通过动态调整掩码和自适应稀疏策略提升多任务强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于掩码的多任务强化学习方法使用粗粒度二值掩码和固定稀疏策略，导致关键参数被过度抑制且难以适应不同任务的冲突水平，限制了模型泛化与学习效率。

Method: 利用Fisher信息动态调整掩码值以保留重要参数并抑制冲突参数；基于四分位距（IQR）设计任务特定的动态稀疏策略，并结合非对称余弦退火调度实现训练过程中稀疏度的自适应演化。

Result: 在Meta-World基准上，SoCo-DT比当前最优方法在MT50上提升7.6%，在次优数据集上提升10.5%。

Conclusion: SoCo-DT能有效缓解梯度冲突，促进知识共享，显著提升多任务强化学习的性能和泛化能力。

Abstract: Multi-task reinforcement learning (MTRL) seeks to learn a unified policy for diverse tasks, but often suffers from gradient conflicts across tasks. Existing masking-based methods attempt to mitigate such conflicts by assigning task-specific parameter masks. However, our empirical study shows that coarse-grained binary masks have the problem of over-suppressing key conflicting parameters, hindering knowledge sharing across tasks. Moreover, different tasks exhibit varying conflict levels, yet existing methods use a one-size-fits-all fixed sparsity strategy to keep training stability and performance, which proves inadequate. These limitations hinder the model's generalization and learning efficiency.
  To address these issues, we propose SoCo-DT, a Soft Conflict-resolution method based by parameter importance. By leveraging Fisher information, mask values are dynamically adjusted to retain important parameters while suppressing conflicting ones. In addition, we introduce a dynamic sparsity adjustment strategy based on the Interquartile Range (IQR), which constructs task-specific thresholding schemes using the distribution of conflict and harmony scores during training. To enable adaptive sparsity evolution throughout training, we further incorporate an asymmetric cosine annealing schedule to continuously update the threshold. Experimental results on the Meta-World benchmark show that SoCo-DT outperforms the state-of-the-art method by 7.6% on MT50 and by 10.5% on the suboptimal dataset, demonstrating its effectiveness in mitigating gradient conflicts and improving overall multi-task performance.

</details>


### [783] [Personalized Federated Learning with Bidirectional Communication Compression via One-Bit Random Sketching](https://arxiv.org/abs/2511.13144)
*Jiacheng Cheng,Xu Zhang,Guanghui Qiu,Yifang Zhang,Yinchuan Li,Kaiyuan Feng*

Main category: cs.LG

TL;DR: 提出了一种名为pFed1BS的个性化联邦学习框架，通过一比特随机压缩显著降低通信开销，同时在异构数据下实现有效个性化。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中双向通信开销大和客户端数据异质性的问题。

Method: 采用一比特随机投影压缩客户端上传信息，服务器聚合生成全局一比特共识，并引入基于符号的正则项促进个性化；利用快速哈达玛变换降低计算负担。

Result: 理论分析证明算法收敛到全局势函数的稳定邻域，实验表明该方法显著减少通信成本，且性能优于先进的通信高效FL算法。

Conclusion: pFed1BS在保持模型个性化的同时，有效平衡了通信效率与学习性能，适用于资源受限的异构联邦学习场景。

Abstract: Federated Learning (FL) enables collaborative training across decentralized data, but faces key challenges of bidirectional communication overhead and client-side data heterogeneity. To address communication costs while embracing data heterogeneity, we propose pFed1BS, a novel personalized federated learning framework that achieves extreme communication compression through one-bit random sketching. In personalized FL, the goal shifts from training a single global model to creating tailored models for each client. In our framework, clients transmit highly compressed one-bit sketches, and the server aggregates and broadcasts a global one-bit consensus. To enable effective personalization, we introduce a sign-based regularizer that guides local models to align with the global consensus while preserving local data characteristics. To mitigate the computational burden of random sketching, we employ the Fast Hadamard Transform for efficient projection. Theoretical analysis guarantees that our algorithm converges to a stationary neighborhood of the global potential function. Numerical simulations demonstrate that pFed1BS substantially reduces communication costs while achieving competitive performance compared to advanced communication-efficient FL algorithms.

</details>


### [784] [OTARo: Once Tuning for All Precisions toward Robust On-Device LLMs](https://arxiv.org/abs/2511.13147)
*Shaoyuan Chen,Zhixuan Chen,Dawei Yang,Zhihang Yuan,Qiang Wu*

Main category: cs.LG

TL;DR: 本文提出OTARo，一种支持大语言模型在设备上灵活切换量化精度的新型方法，通过一次微调实现多精度鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统量化方法因结构限制难以在微调和部署阶段灵活切换不同位宽，无法满足实际场景中对不同任务使用不同精度的需求。

Method: 提出共享指数浮点（SEFP）机制，通过单一模型的尾数截断生成不同位宽；结合位宽路径搜索（BPS）和低精度异步累积（LAA）策略，在训练中同时优化多种精度下的性能。

Result: 在LLaMA3.2-1B和LLaMA3-8B等模型上验证，OTARo在各种位宽下均表现出强健且一致的性能。

Conclusion: OTARo实现了单次微调后在设备上灵活切换量化精度的能力，显著提升了量化LLM在复杂现实应用中的适应性和效率。

Abstract: Large Language Models (LLMs) fine-tuning techniques not only improve the adaptability to diverse downstream tasks, but also mitigate adverse effects of model quantization. Despite this, conventional quantization suffers from its structural limitation that hinders flexibility during the fine-tuning and deployment stages. Practical on-device tasks demand different quantization precisions (i.e. different bit-widths), e.g., understanding tasks tend to exhibit higher tolerance to reduced precision compared to generation tasks. Conventional quantization, typically relying on scaling factors that are incompatible across bit-widths, fails to support the on-device switching of precisions when confronted with complex real-world scenarios. To overcome the dilemma, we propose OTARo, a novel method that enables on-device LLMs to flexibly switch quantization precisions while maintaining performance robustness through once fine-tuning. OTARo introduces Shared Exponent Floating Point (SEFP), a distinct quantization mechanism, to produce different bit-widths through simple mantissa truncations of a single model. Moreover, to achieve bit-width robustness in downstream applications, OTARo performs a learning process toward losses induced by different bit-widths. The method involves two critical strategies: (1) Exploitation-Exploration Bit-Width Path Search (BPS), which iteratively updates the search path via a designed scoring mechanism; (2) Low-Precision Asynchronous Accumulation (LAA), which performs asynchronous gradient accumulations and delayed updates under low bit-widths. Experiments on popular LLMs, e.g., LLaMA3.2-1B, LLaMA3-8B, demonstrate that OTARo achieves consistently strong and robust performance for all precisions.

</details>


### [785] [Warm-starting active-set solvers using graph neural networks](https://arxiv.org/abs/2511.13174)
*Ella J. Schmidtobreick,Daniel Arnström,Paul Häusner,Jens Sjölund*

Main category: cs.LG

TL;DR: 提出一种基于图神经网络（GNN）的學習方法，用於預測二次規劃問題中對偶活躍集算法（DAQP）的活躍集，從而實現高效熱啟動，減少求解迭代次數。


<details>
  <summary>Details</summary>
Motivation: 傳統二次規劃求解器計算成本高，難以滿足實時控制與優化中的時間關鍵需求，因此需要加速求解過程。

Method: 將二次規劃問題建模為二分圖，利用圖神經網絡學習並預測最優活躍集，以此為DAQP求解器提供熱啟動。

Result: 在不同問題規模下，該方法相比冷啟動顯著減少迭代次數，性能與MLP基線相當，且訓練好的GNN能泛化至未見的問題維度。

Conclusion: 結構感知的學習方法（如GNN）具有良好的可擴展性和靈活性，可用於加速模型預測控制等實時優化應用。

Abstract: Quadratic programming (QP) solvers are widely used in real-time control and optimization, but their computational cost often limits applicability in time-critical settings. We propose a learning-to-optimize approach using graph neural networks (GNNs) to predict active sets in the dual active-set solver DAQP. The method exploits the structural properties of QPs by representing them as bipartite graphs and learning to identify the optimal active set for efficiently warm-starting the solver. Across varying problem sizes, the GNN consistently reduces the number of solver iterations compared to cold-starting, while performance is comparable to a multilayer perceptron (MLP) baseline. Furthermore, a GNN trained on varying problem sizes generalizes effectively to unseen dimensions, demonstrating flexibility and scalability. These results highlight the potential of structure-aware learning to accelerate optimization in real-time applications such as model predictive control.

</details>


### [786] [Real-time distortion prediction in metallic additive manufacturing via a physics-informed neural operator approach](https://arxiv.org/abs/2511.13178)
*Mingxuan Tian,Haochen Mu,Donghong Ding,Mengjiao Li,Yuhan Ding,Jianping Zhao*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息的深度算子网络-循环神经网络（PIDeepONet-RNN）模型，用于金属增材制造中实时预测未来15秒内的z和y方向变形场。


<details>
  <summary>Details</summary>
Motivation: 传统数值模拟计算成本高、耗时长，难以实现实时预测；常规机器学习模型难以提取长时间跨度的时空特征，且无法解耦热-力场。因此需要一种高效、准确并符合物理规律的预测方法。

Method: 采用Physics-informed Neural Operator（PINO）框架，利用分支网络处理温度历史，主干网络编码变形场，实现热-力响应解耦；引入热传导方程作为软约束，确保物理一致性。模型在实验验证的有限元数据集上进行训练与测试。

Result: 模型在z和y方向的最大绝对误差分别低至0.9733 mm和0.2049 mm，误差积累小、时间效率高；误差主要集中在熔池区域，而在沉积区和关键区域梯度范数低，表现良好。

Conclusion: 所提出的PIDeepONet-RNN模型具有高精度、物理一致性和实时预测能力，适用于金属增材制造中缺陷控制的长时程物理场预测。

Abstract: With the development of digital twins and smart manufacturing systems, there is an urgent need for real-time distortion field prediction to control defects in metal Additive Manufacturing (AM). However, numerical simulation methods suffer from high computational cost, long run-times that prevent real-time use, while conventional Machine learning (ML) models struggle to extract spatiotemporal features for long-horizon prediction and fail to decouple thermo-mechanical fields. This paper proposes a Physics-informed Neural Operator (PINO) to predict z and y-direction distortion for the future 15 s. Our method, Physics-informed Deep Operator Network-Recurrent Neural Network (PIDeepONet-RNN) employs trunk and branch network to process temperature history and encode distortion fields, respectively, enabling decoupling of thermo-mechanical responses. By incorporating the heat conduction equation as a soft constraint, the model ensures physical consistency and suppresses unphysical artifacts, thereby establishing a more physically consistent mapping between the thermal history and distortion. This is important because such a basis function, grounded in physical laws, provides a robust and interpretable foundation for predictions. The proposed models are trained and tested using datasets generated from experimentally validated Finite Element Method (FEM). Evaluation shows that the model achieves high accuracy, low error accumulation, time efficiency. The max absolute errors in the z and y-directions are as low as 0.9733 mm and 0.2049 mm, respectively. The error distribution shows high errors in the molten pool but low gradient norms in the deposited and key areas. The performance of PINO surrogate model highlights its potential for real-time long-horizon physics field prediction in controlling defects.

</details>


### [787] [Uncertainty-aware Physics-informed Neural Networks for Robust CARS-to-Raman Signal Reconstruction](https://arxiv.org/abs/2511.13185)
*Aishwarya Venkataramanan,Sai Karthikeya Vemuri,Adithya Ashok Chalain Valapil,Joachim Denzler*

Main category: cs.LG

TL;DR: 本文评估了在CARS-to-Raman信号重建中多种不确定性量化（UQ）技术，并展示了引入物理信息约束可提升模型校准性，从而实现更可靠的CARS数据分析。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在从CARS数据重建拉曼信号时缺乏不确定性量化能力，限制了其在高风险科学和生物医学应用中的可靠性。

Method: 比较了多种不确定性量化技术，并结合Kramers-Kronig关系和光滑性约束等物理信息损失函数来提升模型性能。

Result: 引入物理信息约束的模型在不确定性校准方面表现更优，能更可靠地重建真实拉曼信号。

Conclusion: 结合物理先验的UQ深度学习模型为CARS光谱分析提供了更可信的解决方案，有助于推动其在关键领域的应用。

Abstract: Coherent anti-Stokes Raman scattering (CARS) spectroscopy is a powerful and rapid technique widely used in medicine, material science, and chemical analyses. However, its effectiveness is hindered by the presence of a non-resonant background that interferes with and distorts the true Raman signal. Deep learning methods have been employed to reconstruct the true Raman spectrum from measured CARS data using labeled datasets. A more recent development integrates the domain knowledge of Kramers-Kronig relationships and smoothness constraints in the form of physics-informed loss functions. However, these deterministic models lack the ability to quantify uncertainty, an essential feature for reliable deployment in high-stakes scientific and biomedical applications. In this work, we evaluate and compare various uncertainty quantification (UQ) techniques within the context of CARS-to-Raman signal reconstruction. Furthermore, we demonstrate that incorporating physics-informed constraints into these models improves their calibration, offering a promising path toward more trustworthy CARS data analysis.

</details>


### [788] [DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play](https://arxiv.org/abs/2511.13186)
*Akash Karthikeyan,Yash Vardhan Pant*

Main category: cs.LG

TL;DR: 提出DiffFP，一种基于扩散策略的虚拟博弈框架，用于在连续决策空间的多智能体对抗环境中学习鲁棒且多样化的策略，实现了更快收敛和更高成功率。


<details>
  <summary>Details</summary>
Motivation: 在连续决策空间中，现有自对弈方法难以实现良好的适应性和泛化性，常导致收敛慢或无法收敛到纳什均衡，易受未知对手策略利用。

Method: 提出DiffFP框架，结合虚构博弈与扩散策略，通过生成式建模估计对未知对手的最佳响应，学习多模态行为策略。

Result: 实验表明DiffFP能在连续零和博弈中收敛至ε-纳什均衡，在赛车和多粒子游戏中相比RL基线方法收敛速度快3倍，成功率高30倍。

Conclusion: DiffFP有效提升了自对弈在连续空间多智能体对抗中的收敛性、鲁棒性和泛化能力，优于现有强化学习方法。

Abstract: Self-play reinforcement learning has demonstrated significant success in learning complex strategic and interactive behaviors in competitive multi-agent games. However, achieving such behaviors in continuous decision spaces remains challenging. Ensuring adaptability and generalization in self-play settings is critical for achieving competitive performance in dynamic multi-agent environments. These challenges often cause methods to converge slowly or fail to converge at all to a Nash equilibrium, making agents vulnerable to strategic exploitation by unseen opponents. To address these challenges, we propose DiffFP, a fictitious play (FP) framework that estimates the best response to unseen opponents while learning a robust and multimodal behavioral policy. Specifically, we approximate the best response using a diffusion policy that leverages generative modeling to learn adaptive and diverse strategies. Through empirical evaluation, we demonstrate that the proposed FP framework converges towards $ε$-Nash equilibria in continuous- space zero-sum games. We validate our method on complex multi-agent environments, including racing and multi-particle zero-sum games. Simulation results show that the learned policies are robust against diverse opponents and outperform baseline reinforcement learning policies. Our approach achieves up to 3$\times$ faster convergence and 30$\times$ higher success rates on average against RL-based baselines, demonstrating its robustness to opponent strategies and stability across training iterations

</details>


### [789] [ParaDySe: A Parallel-Strategy Switching Framework for Dynamic Sequence Lengths in Transformer](https://arxiv.org/abs/2511.13198)
*Zhixin Ou,Peng Liang,Jianchen Han,Baihui Liu,Linbo Qiao*

Main category: cs.LG

TL;DR: 提出了一种名为ParaDySe的自适应并行策略切换框架，用于处理动态长度序列，在训练大语言模型时根据输入序列动态选择最优并行策略，有效缓解了内存溢出和通信瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有训练框架对变长序列采用静态并行策略，导致短序列通信浪费和长序列内存溢出问题。

Method: 构建模块化并行策略函数库，设计统一张量布局；结合混合方法建立序列感知的内存与时间成本模型，并通过启发式算法逐层选择最优策略，实现运行时无缝切换。

Result: 在序列长度高达624K的数据集上实验表明，ParaDySe能有效解决LLM训练中的OOM和CPC瓶颈。

Conclusion: ParaDySe通过系统集成长序列优化与现有框架，实现了对动态序列的高效自适应并行训练。

Abstract: Dynamic sequences with varying lengths have been widely used in the training of Transformer-based large language models (LLMs). However, current training frameworks adopt a pre-defined static parallel strategy for these sequences, causing neither communication-parallelization cancellation on short sequences nor out-of-memory on long sequences. To mitigate these issues, we propose ParaDySe, a novel adaptive Parallel strategy switching framework for Dynamic Sequences. ParaDySe enables on-the-fly optimal strategy adoption according to the immediate input sequence. It first implements the modular function libraries for parallel strategies with unified tensor layout specifications, and then builds sequence-aware memory and time cost models with hybrid methods. Guided by cost models, ParaDySe selects optimal layer-wise strategies for dynamic sequences via an efficient heuristic algorithm. By integrating these techniques together, ParaDySe achieves seamless hot-switching of optimal strategies through its well-designed function libraries. We compare ParaDySe with baselines on representative LLMs under datasets with sequence lengths up to 624K. Experimental results indicate that ParaDySe addresses OOM and CPC bottlenecks in LLM training by systematically integrating long-sequence optimizations with existing frameworks.

</details>


### [790] [TokenSqueeze: Performance-Preserving Compression for Reasoning LLMs](https://arxiv.org/abs/2511.13223)
*Yuxiang Zhang,Zhengxu Yu,Weihang Pan,Zhongming Jin,Qiang Fu,Deng Cai,Binbin Lin,Jieping Ye*

Main category: cs.LG

TL;DR: 本文提出了一种名为TokenSqueeze的新方法，用于压缩推理语言模型的思维链长度，以减少推理过程中的token使用量，同时保持准确性。该方法通过自适应选择与问题复杂度匹配的推理深度，并采用分布对齐的语言优化策略，在不依赖人工标注数据的情况下实现了高效且高保真的推理压缩。


<details>
  <summary>Details</summary>
Motivation: 长思维链（CoT）虽然提升了推理性能，但带来了较高的token消耗和推理延迟，现有压缩方法往往牺牲准确率，因此需要一种兼顾效率与精度的解决方案。

Method: 提出TokenSqueeze：1）自适应选择与问题复杂度匹配的自我生成样本推理深度；2）分布对齐的语言精炼方法，提升表达简洁性与逻辑一致性。全程仅使用模型自生成数据进行训练。

Result: 在MATH500基准上，基于DeepSeek-R1-Distill-Qwen-7B的实验显示平均token减少50%，同时保持原有准确率。

Conclusion: TokenSqueeze有效缓解了推理模型中效率与准确性的权衡问题，能够在显著降低推理成本的同时维持高性能，适用于多种实际应用场景。

Abstract: Emerging reasoning LLMs such as OpenAI-o1 and DeepSeek-R1 have achieved strong performance on complex reasoning tasks by generating long chain-of-thought (CoT) traces. However, these long CoTs result in increased token usage, leading to higher inference latency and memory consumption. As a result, balancing accuracy and reasoning efficiency has become essential for deploying reasoning LLMs in practical applications. Existing long-to-short (Long2Short) methods aim to reduce inference length but often sacrifice accuracy, revealing a need for an approach that maintains performance while lowering token costs. To address this efficiency-accuracy tradeoff, we propose TokenSqueeze, a novel Long2Short method that condenses reasoning paths while preserving performance and relying exclusively on self-generated data. First, to prevent performance degradation caused by excessive compression of reasoning depth, we propose to select self-generated samples whose reasoning depth is adaptively matched to the complexity of the problem. To further optimize the linguistic expression without altering the underlying reasoning paths, we introduce a distribution-aligned linguistic refinement method that enhances the clarity and conciseness of the reasoning path while preserving its logical integrity. Comprehensive experimental results demonstrate the effectiveness of TokenSqueeze in reducing token usage while maintaining accuracy. Notably, DeepSeek-R1-Distill-Qwen-7B fine-tuned using our proposed method achieved a 50\% average token reduction while preserving accuracy on the MATH500 benchmark. TokenSqueeze exclusively utilizes the model's self-generated data, enabling efficient and high-fidelity reasoning without relying on manually curated short-answer datasets across diverse applications. Our code is available at https://github.com/zhangyx1122/TokenSqueeze.

</details>


### [791] [Laplace Learning in Wasserstein Space](https://arxiv.org/abs/2511.13229)
*Mary Chriselda Antony Oliver,Michael Roberts,Carola-Bibiane Schönlieb,Matthew Thorpe*

Main category: cs.LG

TL;DR: 本文将图基半监督学习方法从有限维欧氏空间扩展到无限维Wasserstein空间，基于流形假设研究Laplace Learning，并证明了离散图p-Dirichlet能量的变分收敛性，同时刻画了Wasserstein空间子流形上的Laplace-Beltrami算子，数值实验验证了方法在高维场景下的一致性。


<details>
  <summary>Details</summary>
Motivation: 高维数据通常具有低维内在结构（流形假设），传统图基半监督学习方法局限于欧氏空间，难以处理概率分布间的几何关系，因此需要将其推广到更一般的度量空间（如Wasserstein空间）以更好地建模数据本质。

Method: 在Wasserstein空间中定义图基半监督学习框架，通过证明离散图p-Dirichlet能量在Gamma收敛意义下趋于连续极限能量，建立从离散到连续的理论桥梁；同时推导Wasserstein空间子流形上的Laplace-Beltrami算子以描述函数变化。

Result: 建立了Laplace Learning在Wasserstein空间中的理论框架，证明了离散能量泛函向连续泛函的变分收敛，并给出了该空间中Laplace-Beltrami算子的具体形式，数值实验显示分类性能在高维设置下具有一致性。

Conclusion: 将图基半监督学习推广至Wasserstein空间是可行且有效的，所提出的理论框架为基于最优传输的机器学习方法提供了新的视角和数学基础。

Abstract: The manifold hypothesis posits that high-dimensional data typically resides on low-dimensional sub spaces. In this paper, we assume manifold hypothesis to investigate graph-based semi-supervised learning
  methods. In particular, we examine Laplace Learning in the Wasserstein space, extending the classical
  notion of graph-based semi-supervised learning algorithms from finite-dimensional Euclidean spaces to
  an infinite-dimensional setting. To achieve this, we prove variational convergence of a discrete graph p- Dirichlet energy to its continuum counterpart. In addition, we characterize the Laplace-Beltrami operator
  on asubmanifold of the Wasserstein space. Finally, we validate the proposed theoretical framework through
  numerical experiments conducted on benchmark datasets, demonstrating the consistency of our classification performance in high-dimensional settings.

</details>


### [792] [MorphBoost: Self-Organizing Universal Gradient Boosting with Adaptive Tree Morphing](https://arxiv.org/abs/2511.13234)
*Boris Kriuk*

Main category: cs.LG

TL;DR: MorphBoost是一种新型梯度提升框架，采用可动态调整的自组织树结构，通过自适应分裂准则和基于训练进度的优化，在多个任务中实现优于XGBoost等主流方法的性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统梯度提升算法使用静态树结构，难以适应不同训练阶段的梯度分布变化和问题特性，限制了模型灵活性与性能。

Method: 提出MorphBoost框架，引入动态演化的分裂函数，结合梯度统计与信息论指标，并根据训练进程加权；支持自动问题识别、向量化预测、交互感知特征重要性及快速模式优化。

Result: 在10个数据集上超越XGBoost平均0.84%，以40%胜率位居第一，且具有最低方差和最高最小准确率，表现出更强的一致性与鲁棒性，尤其在复杂问题上提升显著。

Conclusion: MorphBoost通过动态自适应树结构显著提升了梯度提升算法的性能与稳定性，为未来自组织模型设计提供了新方向。

Abstract: Traditional gradient boosting algorithms employ static tree structures with fixed splitting criteria that remain unchanged throughout training, limiting their ability to adapt to evolving gradient distributions and problem-specific characteristics across different learning stages. This work introduces MorphBoost, a new gradient boosting framework featuring self-organizing tree structures that dynamically morph their splitting behavior during training. The algorithm implements adaptive split functions that evolve based on accumulated gradient statistics and iteration-dependent learning pressures, enabling automatic adjustment to problem complexity. Key innovations include: (1) morphing split criterion combining gradient-based scores with information-theoretic metrics weighted by training progress; (2) automatic problem fingerprinting for intelligent parameter configuration across binary/multiclass/regression tasks; (3) vectorized tree prediction achieving significant computational speedups; (4) interaction-aware feature importance detecting multiplicative relationships; and (5) fast-mode optimization balancing speed and accuracy. Comprehensive benchmarking across 10 diverse datasets against competitive models (XGBoost, LightGBM, GradientBoosting, HistGradientBoosting, ensemble methods) demonstrates that MorphBoost achieves state-of-the-art performance, outperforming XGBoost by 0.84% on average. MorphBoost secured the overall winner position with 4/10 dataset wins (40% win rate) and 6/30 top-3 finishes (20%), while maintaining the lowest variance (σ=0.0948) and highest minimum accuracy across all models, revealing superior consistency and robustness. Performance analysis across difficulty levels shows competitive results on easy datasets while achieving notable improvements on advanced problems due to higher adaptation levels.

</details>


### [793] [Counterfactual Explainable AI (XAI) Method for Deep Learning-Based Multivariate Time Series Classification](https://arxiv.org/abs/2511.13237)
*Alan G. Paredes Cetina,Kaouther Benguessoum,Raoni Lourenço,Sylvain Kubler*

Main category: cs.LG

TL;DR: 提出了一种名为CONFETTI的多目标反事实解释方法，用于多变量时间序列（MTS），在保持高预测置信度的同时优化接近性与稀疏性，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在多变量时间序列分类与回归中表现优异，但缺乏透明性；现有的可解释AI方法难以全面揭示模型决策机制，而当前的反事实解释方法通常无法同时优化准确性、接近性和稀疏性。

Method: CONFETTI通过识别关键子序列、定位反事实目标，并以多目标优化方式对时间序列进行最小化修改，平衡预测置信度、接近性和稀疏性，生成可操作的解释。

Result: 在UEA档案的七个MTS数据集上评估显示，CONFETTI在优化目标和其他六个文献指标上均优于最先进的CE方法，置信度提高≥10%，稀疏性在≥40%的情况下得到改善。

Conclusion: CONFETTI能有效生成高质量的反事实解释，兼顾准确性、可解释性与实用性，为多变量时间序列模型提供了更强的决策支持能力。

Abstract: Recent advances in deep learning have improved multivariate time series (MTS) classification and regression by capturing complex patterns, but their lack of transparency hinders decision-making. Explainable AI (XAI) methods offer partial insights, yet often fall short of conveying the full decision space. Counterfactual Explanations (CE) provide a promising alternative, but current approaches typically prioritize either accuracy, proximity or sparsity -- rarely all -- limiting their practical value. To address this, we propose CONFETTI, a novel multi-objective CE method for MTS. CONFETTI identifies key MTS subsequences, locates a counterfactual target, and optimally modifies the time series to balance prediction confidence, proximity and sparsity. This method provides actionable insights with minimal changes, improving interpretability, and decision support. CONFETTI is evaluated on seven MTS datasets from the UEA archive, demonstrating its effectiveness in various domains. CONFETTI consistently outperforms state-of-the-art CE methods in its optimization objectives, and in six other metrics from the literature, achieving $\geq10\%$ higher confidence while improving sparsity in $\geq40\%$.

</details>


### [794] [Incoherent Beliefs & Inconsistent Actions in Large Language Models](https://arxiv.org/abs/2511.13240)
*Arka Pal,Teo Kitanovski,Arthur Liang,Akilesh Potti,Micah Goldblum*

Main category: cs.LG

TL;DR: 该论文研究了大语言模型（LLM）在动态环境中信念更新和行为一致性的问题，发现LLM在更新信念和行动选择上存在显著不一致，即使在高准确率或良好校准的模型中也普遍存在。


<details>
  <summary>Details</summary>
Motivation: 现实任务涉及动态交互和基于新证据持续更新信念，而传统静态数据集无法充分评估LLM在此类环境中的表现，因此需要探究LLM在信念更新和行为一致性方面的能力。

Method: 通过比较LLM直接报告的后验信念与其先验信念的合理更新之间的差异，评估其信念更新的一致性；并通过分析模型在赌博市场等任务中的决策是否与其内部信念一致，评估其行为一致性。

Result: 发现LLM在信念更新上平均存在高达30%的不一致；其行为常与其内部信念不符（如在赌博任务中下注方向相反）；且对用户质疑表现出中等程度的自我不一致；这些现象在高性能模型中依然存在。

Conclusion: LLM在动态环境中的信念更新和行为一致性存在严重问题，仅凭静态任务上的准确率或校准性难以预测其真实场景下的行为，这为实际应用带来了挑战。

Abstract: Real-world tasks and environments exhibit differences from the static datasets that large language models (LLMs) are typically evaluated on. Such tasks can involve sequential interaction, requiring coherent updating of beliefs in light of new evidence, and making appropriate decisions based on those beliefs. Predicting how LLMs will perform in such dynamic environments is important, but can be tricky to determine from measurements in static settings. In this work, we examine two critical components of LLM performance: the ability of LLMs to coherently update their beliefs, and the extent to which the actions they take are consistent with those beliefs. First, we find that LLMs are largely inconsistent in how they update their beliefs; models can exhibit up to a 30% average difference between the directly elicited posterior, and the correct update of their prior. Second, we find that LLMs also often take actions which are inconsistent with the beliefs they hold. On a betting market, for example, LLMs often do not even bet in the same direction as their internally held beliefs over the underlying outcomes. We also find they have moderate self-inconsistency in how they respond to challenges by users to given answers. Finally, we show that the above properties hold even for strong models that obtain high accuracy or that are well-calibrated on the tasks at hand. Our results highlight the difficulties of predicting LLM behavior in complex real-world settings.

</details>


### [795] [Uncovering and Mitigating Transient Blindness in Multimodal Model Editing](https://arxiv.org/abs/2511.13243)
*Xiaoqi Han,Ru Li,Ran Yi,Hongye Tan,Zhuomin Liang,Víctor Gutiérrez-Basulto,Jeff Z. Pan*

Main category: cs.LG

TL;DR: 本文提出了一种针对多模态模型编辑的综合性局部性评估框架De-VQA，揭示了编辑过程中存在的“瞬时失明”现象，并通过局部性感知的对抗损失有效缓解了跨模态过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本模型编辑的评估方法在多模态场景下容易高估编辑效果，忽视过拟合问题，缺乏对视觉输入变化下的编辑局部性的系统评估。

Method: 提出了涵盖随机图像、无图像和一致图像局部性的三维评估框架，构建七种数据类型，并引入De-VQA动态评估方法；通过token分析发现编辑对文本token影响更大，进而设计局部性感知的对抗损失来平衡跨模态表征。

Result: 实验表明该方法平均提升局部性17%，显著减少瞬时失明现象，在多种基准上优于现有模型编辑方法。

Conclusion: 所提出的评估框架和对抗训练策略有效提升了多模态模型编辑的鲁棒性和跨模态一致性，揭示了当前编辑方法中被忽视的关键问题。

Abstract: Multimodal Model Editing (MMED) aims to correct erroneous knowledge in multimodal models. Existing evaluation methods, adapted from textual model editing, overstate success by relying on low-similarity or random inputs, obscure overfitting. We propose a comprehensive locality evaluation framework, covering three key dimensions: random-image locality, no-image locality, and consistent-image locality, operationalized through seven distinct data types, enabling a detailed and structured analysis of multimodal edits. We introduce De-VQA, a dynamic evaluation for visual question answering, uncovering a phenomenon we term transient blindness, overfitting to edit-similar text while ignoring visuals. Token analysis shows edits disproportionately affect textual tokens. We propose locality-aware adversarial losses to balance cross-modal representations. Empirical results demonstrate that our approach consistently outperforms existing baselines, reducing transient blindness and improving locality by 17% on average.

</details>


### [796] [Seek and You Shall Fold](https://arxiv.org/abs/2511.13244)
*Nadav Bojan Sellam,Meital Bojan,Paul Schanda,Alex Bronstein*

Main category: cs.LG

TL;DR: 提出了一种非可微指导的蛋白质生成模型框架，结合扩散生成器与遗传算法，成功整合核磁共振数据（如化学位移）到蛋白质结构生成中。


<details>
  <summary>Details</summary>
Motivation: 准确的蛋白质结构对理解生物功能至关重要，但将实验数据（尤其是非可微的观测值）融入生成模型仍具挑战性，尤其是在核磁共振领域。

Method: 结合基于连续扩散的生成器与定制的遗传算法，实现对任意黑箱目标（如化学 shifts、NOE 约束、距离约束）的非可微引导。

Result: 在三种实验模态下验证了框架有效性，首次实现了基于化学 shifts 的蛋白质结构生成，揭示了现有预测器的关键弱点。

Conclusion: 该方法为非可微条件下融合多种实验数据进行蛋白质建模提供了通用策略，推动了数据驱动的自动化蛋白结构预测发展。

Abstract: Accurate protein structures are essential for understanding biological function, yet incorporating experimental data into protein generative models remains a major challenge. Most predictors of experimental observables are non-differentiable, making them incompatible with gradient-based conditional sampling. This is especially limiting in nuclear magnetic resonance, where rich data such as chemical shifts are hard to directly integrate into generative modeling. We introduce a framework for non-differentiable guidance of protein generative models, coupling a continuous diffusion-based generator with any black-box objective via a tailored genetic algorithm. We demonstrate its effectiveness across three modalities: pairwise distance constraints, nuclear Overhauser effect restraints, and for the first time chemical shifts. These results establish chemical shift guided structure generation as feasible, expose key weaknesses in current predictors, and showcase a general strategy for incorporating diverse experimental signals. Our work points toward automated, data-conditioned protein modeling beyond the limits of differentiability.

</details>


### [797] [Edge-aware baselines for ogbn-proteins in PyTorch Geometric: species-wise normalization, post-hoc calibration, and cost-accuracy trade-offs](https://arxiv.org/abs/2511.13250)
*Aleksandar Stanković,Dejan Lisica*

Main category: cs.LG

TL;DR: 本文提出了可复现的、感知边信息的PyG基线模型用于ogbn-proteins数据集，研究了边信息聚合方式和消息传递中边的使用方法，发现基于求和的GraphSAGE表现最佳，并比较了不同归一化方法的效果，同时通过后处理温度缩放和标签相关性平滑进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 为了在ogbn-proteins图数据上建立可复现且高效的基线模型，系统地评估当前主流的边信息处理方式对节点表示学习的影响。

Method: 采用GraphSAGE等GNN模型，对比不同边到节点特征聚合方式（sum/mean/max），研究消息传递过程中边的使用机制；比较LayerNorm、BatchNorm和物种感知的Conditional LayerNorm；引入后处理技术如每标签温度缩放与阈值调整以及标签相关性平滑。

Result: Sum聚合方式始终优于mean和max；BatchNorm取得最高ROC-AUC，Conditional LayerNorm在F1分数上表现更好；后处理显著提升micro-F1和校准效果（ECE），且几乎不改变AUC；提供了计算成本（时间、显存、参数）的全面分析。

Conclusion: 本文确立了ogbn-proteins上的强基线，揭示了边信息处理和归一化策略的重要性，并展示了简单后处理对模型性能和校准的有效提升，所有实验均提供标准化代码与模型以确保可复现性。

Abstract: We present reproducible, edge-aware baselines for ogbn-proteins in PyTorch Geometric (PyG). We study two system choices that dominate practice: (i) how 8-dimensional edge evidence is aggregated into node inputs, and (ii) how edges are used inside message passing. Our strongest baseline is GraphSAGE with sum-based edge-to-node features. We compare LayerNorm (LN), BatchNorm (BN), and a species-aware Conditional LayerNorm (CLN), and report compute cost (time, VRAM, parameters) together with accuracy (ROC-AUC) and decision quality. In our primary experimental setup (hidden size 512, 3 layers, 3 seeds), sum consistently beats mean and max; BN attains the best AUC, while CLN matches the AUC frontier with better thresholded F1. Finally, post-hoc per-label temperature scaling plus per-label thresholds substantially improves micro-F1 and expected calibration error (ECE) with negligible AUC change, and light label-correlation smoothing yields small additional gains. We release standardized artifacts and scripts used for all of the runs presented in the paper.

</details>


### [798] [Explainable RL Policies by Distilling to Locally-Specialized Linear Policies with Voronoi State Partitioning](https://arxiv.org/abs/2511.13322)
*Senne Deproost,Dennis Steckelmacher,Ann Nowé*

Main category: cs.LG

TL;DR: 提出一种模型无关的知识蒸馏方法，通过Voronoi划分状态空间，在局部区域使用线性模型模仿深度强化学习策略，实现可解释且性能相当甚至更优的控制器。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习控制器缺乏透明性，难以满足监管要求和建立信任，需要可解释的替代模型。

Method: 采用Voronoi分区将状态空间划分为多个区域，并在每个区域内训练局部线性模型进行知识蒸馏，提升可解释性与适应性。

Result: 在gridworld环境和经典控制任务中验证了方法的有效性，蒸馏后的线性策略具有可解释性，且性能匹配甚至略优于原始黑箱策略。

Conclusion: 该方法能有效平衡模型的复杂性与准确性，生成既可解释又高性能的控制器，适用于需透明决策的场景。

Abstract: Deep Reinforcement Learning is one of the state-of-the-art methods for producing near-optimal system controllers. However, deep RL algorithms train a deep neural network, that lacks transparency, which poses challenges when the controller has to meet regulations, or foster trust. To alleviate this, one could transfer the learned behaviour into a model that is human-readable by design using knowledge distilla- tion. Often this is done with a single model which mimics the original model on average but could struggle in more dynamic situations. A key challenge is that this simpler model should have the right balance be- tween flexibility and complexity or right balance between balance bias and accuracy. We propose a new model-agnostic method to divide the state space into regions where a simplified, human-understandable model can operate in. In this paper, we use Voronoi partitioning to find regions where linear models can achieve similar performance to the original con- troller. We evaluate our approach on a gridworld environment and a classic control task. We observe that our proposed distillation to locally- specialized linear models produces policies that are explainable and show that the distillation matches or even slightly outperforms the black-box policy they are distilled from.

</details>


### [799] [Tab-PET: Graph-Based Positional Encodings for Tabular Transformers](https://arxiv.org/abs/2511.13338)
*Yunze Leng,Rohan Ghosh,Mehul Motani*

Main category: cs.LG

TL;DR: 本文提出了一种基于图的框架Tab-PET，通过引入位置编码（PEs）来提升表格数据上Transformer模型的泛化能力，发现PEs可通过降低特征的有效秩来简化问题，并在50个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 表格数据缺乏如图像或文本中的结构先验信息，导致标准自注意力机制难以有效建模；现有表格Transformer通常不使用位置编码，限制了性能提升。

Method: 提出Tab-PET框架，利用图结构（关联性或因果性）估计位置编码并融入嵌入表示中，从而为无结构先验的表格数据引入结构线索。

Result: 在50个分类与回归数据集上验证，图衍生的位置编码显著提升了3T系列模型的表现，其中基于关联性的图效果更稳定且增益更明显。

Conclusion: 位置编码能有效降低表格特征的内在维度（有效秩），改善Transformer在小样本、异构特征场景下的泛化能力，揭示了结构线索在表格学习中的重要作用。

Abstract: Supervised learning with tabular data presents unique challenges, including low data sizes, the absence of structural cues, and heterogeneous features spanning both categorical and continuous domains. Unlike vision and language tasks, where models can exploit inductive biases in the data, tabular data lacks inherent positional structure, hindering the effectiveness of self-attention mechanisms. While recent transformer-based models like TabTransformer, SAINT, and FT-Transformer (which we refer to as 3T) have shown promise on tabular data, they typically operate without leveraging structural cues such as positional encodings (PEs), as no prior structural information is usually available. In this work, we find both theoretically and empirically that structural cues, specifically PEs can be a useful tool to improve generalization performance for tabular transformers. We find that PEs impart the ability to reduce the effective rank (a form of intrinsic dimensionality) of the features, effectively simplifying the task by reducing the dimensionality of the problem, yielding improved generalization. To that end, we propose Tab-PET (PEs for Tabular Transformers), a graph-based framework for estimating and inculcating PEs into embeddings. Inspired by approaches that derive PEs from graph topology, we explore two paradigms for graph estimation: association-based and causality-based. We empirically demonstrate that graph-derived PEs significantly improve performance across 50 classification and regression datasets for 3T. Notably, association-based graphs consistently yield more stable and pronounced gains compared to causality-driven ones. Our work highlights an unexpected role of PEs in tabular transformers, revealing how they can be harnessed to improve generalization.

</details>


### [800] [Statistically Accurate and Robust Generative Prediction of Rock Discontinuities with A Tabular Foundation Model](https://arxiv.org/abs/2511.13339)
*Han Meng,Gang Mei,Hong Tian,Nengxiong Xu,Jianbing Peng*

Main category: cs.LG

TL;DR: 提出一种基于表格型基础模型的岩石节理生成预测方法，能够在数据稀少条件下准确捕捉复杂分布模式，显著提升预测精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有岩石节理生成预测方法在数据稀疏条件下难以准确捕捉复杂分布模式，限制了岩体结构的定量表征能力。

Method: 利用专为小样本设计的表格型基础模型，通过学习有限的实测节理数据，实现对岩体内部节理分布的统计精确生成预测。

Result: 在十个不同规模和分布模式的数据集上实验表明，该方法在预测精度和鲁棒性方面均优于传统统计模型和深度生成模型。

Conclusion: 该方法提升了岩体结构的定量刻画能力，有助于实现更安全、可靠的岩土工程数据驱动设计。

Abstract: Rock discontinuities critically govern the mechanical behavior and stability of rock masses. Their internal distributions remain largely unobservable and are typically inferred from surface-exposed discontinuities using generative prediction approaches. However, surface-exposed observations are inherently sparse, and existing generative prediction approaches either fail to capture the underlying complex distribution patterns or lack robustness under data-sparse conditions. Here, we proposed a simple yet robust approach for statistically accurate generative prediction of rock discontinuities by utilizing a tabular foundation model. By leveraging the powerful sample learning capability of the foundation model specifically designed for small data, our approach can effectively capture the underlying complex distribution patterns within limited measured discontinuities. Comparative experiments on ten datasets with diverse scales and distribution patterns of discontinuities demonstrate superior accuracy and robustness over conventional statistical models and deep generative approaches. This work advances quantitative characterization of rock mass structures, supporting safer and more reliable data-driven geotechnical design.

</details>


### [801] [Dual-LoRA and Quality-Enhanced Pseudo Replay for Multimodal Continual Food Learning](https://arxiv.org/abs/2511.13351)
*Xinlan Wu,Bin Zhu,Feng Han,Pengkun Jiao,Jingjing Chen*

Main category: cs.LG

TL;DR: 提出了一种用于多模态食物学习的持续学习框架，结合Dual-LoRA架构和质量增强的伪回放策略，有效缓解灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有大型多模态模型在学习新任务时容易发生灾难性遗忘，需从头昂贵地重新训练，限制了其在个性化营养和慢性病预防等食品分析任务中的应用。

Method: 提出Dual-LoRA架构与质量增强的伪回放策略：Dual-LoRA包含专用LoRA（通过正交约束学习任务特定知识）和协作LoRA（通过伪回放整合跨任务共享知识）；伪回放利用自洽性和语义相似性提高生成样本的可靠性。

Result: 在Uni-Food数据集上的实验表明，该方法在缓解遗忘方面表现优越，是首个在复杂食物任务中有效的持续学习方法。

Conclusion: 所提框架显著提升了多模态食品分析中的持续学习能力，为实际应用场景下的模型扩展提供了高效可行的解决方案。

Abstract: Food analysis has become increasingly critical for health-related tasks such as personalized nutrition and chronic disease prevention. However, existing large multimodal models (LMMs) in food analysis suffer from catastrophic forgetting when learning new tasks, requiring costly retraining from scratch. To address this, we propose a novel continual learning framework for multimodal food learning, integrating a Dual-LoRA architecture with Quality-Enhanced Pseudo Replay. We introduce two complementary low-rank adapters for each task: a specialized LoRA that learns task-specific knowledge with orthogonal constraints to previous tasks' subspaces, and a cooperative LoRA that consolidates shared knowledge across tasks via pseudo replay. To improve the reliability of replay data, our Quality-Enhanced Pseudo Replay strategy leverages self-consistency and semantic similarity to reduce hallucinations in generated samples. Experiments on the comprehensive Uni-Food dataset show superior performance in mitigating forgetting, representing the first effective continual learning approach for complex food tasks.

</details>


### [802] [A Novel Hierarchical Integration Method for Efficient Model Merging in Medical LLMs](https://arxiv.org/abs/2511.13373)
*Prakrit Timilsina,Anuj Nepal,Rajan Kadel,Robin Doss*

Main category: cs.LG

TL;DR: 本文系统评估了六种参数空间融合技术在两个基于Mistral-7B的医疗大语言模型上的表现，提出了一种结合最优传输与余弦相似性加权插值的分层方法。结果表明，在架构兼容的模型中，简单的平均方法（如任务算术）在医学基准上表现最佳，为资源受限环境下的分布式医疗AI提供了高效且实用的知识整合方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在分布式医疗中面临知识整合、隐私保护、计算开销和灾难性遗忘等挑战，需要有效的参数合并方法以支持边缘部署和可持续学习。

Method: 采用六种参数空间融合技术（包括任务算术、线性平均、DARE-TIES、DELLA、Breadcrumbs和提出的分层方法），结合选择性最优传输对齐注意力层与余弦相似性加权插值，评估其在五个医学基准上的性能。

Result: 在MedQA上，任务算术达到45.80%的准确率，优于复杂的剪枝方法；架构兼容的模型显著受益于简单平均方法，且计算开销低。

Conclusion: 对于架构兼容的医疗大语言模型，简单平均方法是知识整合的有效基线，具有高计算效率和部署可行性，为资源受限的物联网环境中可扩展的医疗AI系统提供了实用路径。

Abstract: Large Language Models (LLMs) face significant challenges in distributed healthcare, including consolidating specialized domain knowledge across institutions while maintaining privacy, reducing computational overhead, and preventing catastrophic forgetting during model updates.This paper presents a systematic evaluation of six parameter-space merging techniques applied to two architecturally compatible medical LLMs derived from the Mistral-7B base model. We introduce a novel hierarchical method that combines selective Optimal Transport (OT) alignment for attention layers with cosine similarity-weighted interpolation, designed to address permutation variance while minimizing computational overhead for edge deployment scenarios. Our study evaluates Task Arithmetic, Linear Averaging, DARE-TIES, DELLA, Breadcrumbs, and our Hierarchical approach across five medical benchmarks. Results demonstrate that architecturally compatible models benefit significantly from simple averaging methods, with Task Arithmetic achieving 45.80% accuracy on MedQA, outperforming complex pruning-based approaches. These findings offer critical insights for the deployment of distributed medical AI in resource-constrained IoT environments, where computational efficiency and model compatibility are paramount. Our work establishes that for architecturally compatible models, simple averaging provides a robust and computationally efficient baseline for knowledge consolidation, offering a pragmatic path forward for scalable medical AI systems.

</details>


### [803] [Finding Kissing Numbers with Game-theoretic Reinforcement Learning](https://arxiv.org/abs/2511.13391)
*Chengdong Ma,Théo Tao Zhaowei,Pengyu Li,Minghao Liu,Haojun Chen,Zihao Mao,Yuan Cheng,Yuan Qi,Yaodong Yang*

Main category: cs.LG

TL;DR: 本文提出了一种基于博弈论强化学习的方法PackingStar，用于解决高维空间中的吻数问题，在25至31维中超越了人类已知的最佳记录，并在13维实现了自1971年以来的首次突破，发现了6000多种新结构。


<details>
  <summary>Details</summary>
Motivation: 吻数问题作为希尔伯特第18问题的局部形式，长期受限于高维几何的不规则性和组合复杂度的指数增长，传统方法难以扩展到高维，因此需要新的高效探索高维空间的方法。

Method: 将吻数问题建模为双人矩阵补全博弈，使用博弈论强化学习系统PackingStar，通过一个玩家填充矩阵元素、另一个玩家修正次优项，共同最大化对应吻数的矩阵规模，矩阵元素表示球心向量间的余弦值。

Result: PackingStar复现了已有构型，在25至31维中超越所有人类已知记录，25维构型对应Leech格并暗示可能最优；在13维实现1971年以来首次突破，发现14维及其他维度超过6000个新结构。

Conclusion: AI能够有效探索超越人类直觉的高维几何空间，为吻数问题及更广泛的几何问题提供了新路径。

Abstract: Since Isaac Newton first studied the Kissing Number Problem in 1694, determining the maximal number of non-overlapping spheres around a central sphere has remained a fundamental challenge. This problem represents the local analogue of Hilbert's 18th problem on sphere packing, bridging geometry, number theory, and information theory. Although significant progress has been made through lattices and codes, the irregularities of high-dimensional geometry and exponentially growing combinatorial complexity beyond 8 dimensions, which exceeds the complexity of Go game, limit the scalability of existing methods. Here we model this problem as a two-player matrix completion game and train the game-theoretic reinforcement learning system, PackingStar, to efficiently explore high-dimensional spaces. The matrix entries represent pairwise cosines of sphere center vectors; one player fills entries while another corrects suboptimal ones, jointly maximizing the matrix size, corresponding to the kissing number. This cooperative dynamics substantially improves sample quality, making the extremely large spaces tractable. PackingStar reproduces previous configurations and surpasses all human-known records from dimensions 25 to 31, with the configuration in 25 dimensions geometrically corresponding to the Leech lattice and suggesting possible optimality. It achieves the first breakthrough beyond rational structures from 1971 in 13 dimensions and discovers over 6000 new structures in 14 and other dimensions. These results demonstrate AI's power to explore high-dimensional spaces beyond human intuition and open new pathways for the Kissing Number Problem and broader geometry problems.

</details>


### [804] [Fast and Robust Simulation-Based Inference With Optimization Monte Carlo](https://arxiv.org/abs/2511.13394)
*Vasilis Gkolemis,Christos Diou,Michael Gutmann*

Main category: cs.LG

TL;DR: 提出一种基于优化蒙特卡洛和梯度方法的新框架，用于在可微分模拟器上实现高效准确的贝叶斯参数推断，显著减少运行时间。


<details>
  <summary>Details</summary>
Motivation: 由于复杂随机模拟器的似然函数难以处理，且现有基于模拟的推断方法计算成本高、在高维或信息不足输出情况下效率低，因此需要更高效的贝叶斯推断方法。

Method: 将随机模拟重新表述为确定性优化问题，利用梯度方法高效导航后验高密度区域，并结合JAX实现关键组件向量化以提升性能。

Result: 在高维参数空间、信息不足输出、多观测值和多模态后验等实验中，该方法精度与当前最优方法相当甚至更优，同时大幅降低运行时间。

Conclusion: 所提方法能以更低计算成本实现准确的后验推断，适用于复杂随机模拟器的贝叶斯参数估计。

Abstract: Bayesian parameter inference for complex stochastic simulators is challenging due to intractable likelihood functions. Existing simulation-based inference methods often require large number of simulations and become costly to use in high-dimensional parameter spaces or in problems with partially uninformative outputs. We propose a new method for differentiable simulators that delivers accurate posterior inference with substantially reduced runtimes. Building on the Optimization Monte Carlo framework, our approach reformulates stochastic simulation as deterministic optimization problems. Gradient-based methods are then applied to efficiently navigate toward high-density posterior regions and avoid wasteful simulations in low-probability areas. A JAX-based implementation further enhances the performance through vectorization of key method components. Extensive experiments, including high-dimensional parameter spaces, uninformative outputs, multiple observations and multimodal posteriors show that our method consistently matches, and often exceeds, the accuracy of state-of-the-art approaches, while reducing the runtime by a substantial margin.

</details>


### [805] [PAST: A Primary-Auxiliary Spatio-Temporal Network for Traffic Time Series Imputation](https://arxiv.org/abs/2511.13414)
*Hanwen Hu,Zimo Wen,Shiyou Qian,Jian Co*

Main category: cs.LG

TL;DR: 提出了一种用于交通时间序列填补的Primary-Auxiliary Spatio-Temporal网络（PAST），通过结合图集成模块和交叉门控模块，有效应对多种缺失数据类型，显著提升了填补精度。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以适应随机缺失位置且无法有效捕捉长期和大范围依赖关系，尤其在复杂缺失条件下表现不佳。

Method: 将模式分为内部关系主导的主模式和受外部因素影响的辅助模式；设计了包含图集成模块（GIM）和交叉门控模块（CGM）的PAST模型，通过动态图、多阶卷积和嵌入外部特征的双向门控分别提取两类模式，并采用共享隐向量和自监督集成框架进行联合训练。

Result: 在三个数据集的27种缺失条件下实验表明，PAST在RMSE上最高提升26.2%，MAE上最高提升31.6%，优于七种先进基线方法。

Conclusion: PAST通过融合主模式与辅助模式建模，有效提升了复杂缺失场景下交通时间序列的填补性能，具有较强的鲁棒性和应用潜力。

Abstract: Traffic time series imputation is crucial for the safety and reliability of intelligent transportation systems, while diverse types of missing data, including random, fiber, and block missing make the imputation task challenging. Existing models often focus on disentangling and separately modeling spatial and temporal patterns based on relationships between data points. However, these approaches struggle to adapt to the random missing positions, and fail to learn long-term and large-scale dependencies, which are essential in extensive missing conditions. In this paper, patterns are categorized into two types to handle various missing data conditions: primary patterns, which originate from internal relationships between data points, and auxiliary patterns, influenced by external factors like timestamps and node attributes. Accordingly, we propose the Primary-Auxiliary Spatio-Temporal network (PAST). It comprises a graph-integrated module (GIM) and a cross-gated module (CGM). GIM captures primary patterns via dynamic graphs with interval-aware dropout and multi-order convolutions, and CGM extracts auxiliary patterns through bidirectional gating on embedded external features. The two modules interact via shared hidden vectors and are trained under an ensemble self-supervised framework. Experiments on three datasets under 27 missing data conditions demonstrate that the imputation accuracy of PAST outperforms seven state-of-the-art baselines by up to 26.2% in RMSE and 31.6% in MAE.

</details>


### [806] [MMWSTM-ADRAN+: A Novel Hybrid Deep Learning Architecture for Enhanced Climate Time Series Forecasting and Extreme Event Prediction](https://arxiv.org/abs/2511.13419)
*Shaheen Mohammed Saleh Ahmed,Hakan Hakan Guneyli*

Main category: cs.LG

TL;DR: 提出了一种双流深度学习模型MMWSTM-ADRAN+，用于极端气温事件的短期预测，结合天气状态转移与异常注意力机制，并通过加权损失函数和数据增强提升对极端值的预测能力。


<details>
  <summary>Details</summary>
Motivation: 准确预测短期极端气温事件对气候风险管理至关重要，但现有方法在捕捉罕见极端事件和天气 regime 变化方面存在不足。

Method: 提出MMWSTM-ADRAN+模型：第一流MMWSTM使用BiLSTM和可学习的马尔可夫状态转移矩阵捕捉天气尺度变化；第二流ADRAN使用BiGRU、多头自注意力和异常放大层增强对低概率信号的敏感性；通过注意力融合门自适应整合两流输出；采用ExtremeWeatherLoss损失函数（高权重于温度分布上下5%误差）和时间序列数据增强策略（抖动、缩放、时/幅扭曲）进行优化。

Result: 该模型在日常最高温度及其极端值预测任务中表现优异，有效提升了对极端气温事件的预测精度，数据增强使训练样本量等效翻倍，增强了模型鲁棒性。

Conclusion: MMWSTM-ADRAN+通过融合天气状态建模与异常驱动注意力机制，显著提高了极端气温的短期预测能力，为气候风险操作管理提供了有力工具。

Abstract: Accurate short-range prediction of extreme air temperature events remains a fundamental challenge in operational climate-risk management. We present Multi-Modal Weather State Transition Model with Anomaly-Driven Recurrent Attention Network Plus (MMWSTM-ADRAN+), a dual-stream deep learning architecture that couples a regime-aware dynamics model with an anomaly-focused attention mechanism to forecast daily maximum temperature and its extremes. The first stream, MMWSTM, combines bidirectional Long Short-Term Memory (BiLSTM) units with a learnable Markov state transition matrix to capture synoptic-scale weather regime changes. The second stream, ADRAN, integrates bidirectional Gated Recurrent Units (BiGRUs), multi-head self-attention, and a novel anomaly amplification layer to enhance sensitivity to low-probability signals. A lightweight attentive fusion gate adaptively determines the contribution of each stream to the final prediction. Model optimization employs a custom ExtremeWeatherLoss function that up-weights errors on the upper 5% and lower 5% of the temperature distribution, and a time-series data augmentation suite (jittering, scaling, time/magnitude warping) that effectively quadruples the training data

</details>


### [807] [Larger Datasets Can Be Repeated More: A Theoretical Analysis of Multi-Epoch Scaling in Linear Regression](https://arxiv.org/abs/2511.13421)
*Tingkai Yan,Haodong Wen,Binghui Li,Kairong Luo,Wenguang Chen,Kaifeng Lyu*

Main category: cs.LG

TL;DR: 本文研究了在有限数据和多轮训练下大语言模型的数据扩展规律，提出了“有效重用率”$E(K, N)$来量化多轮训练的效果，理论和实验证明其受数据规模和分布影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注单次遍历大规模语料的数据扩展规律，而对有限数据下重复训练的影响缺乏理解，尤其是在多轮训练中数据重用的效率问题尚未被充分探讨。

Method: 通过在线性回归中对SGD进行理论分析，定义并刻画了有效数据重用率$E(K, N)$，在强凸和Zipf分布数据下推导其随训练轮数$K$和数据量$N$的缩放行为，并结合LLM实验验证。

Result: 1) 当$K$较小时，$E(K, N) \approx K$，即每轮收益线性增长；2) 随着$K$增大，$E(K, N)$趋于一个随$N$增长的平台值（强凸下为$\Theta(\log N)$）；3) 实验表明Muennighoff等人的结论需修正，因最大有效$K$依赖于数据规模与分布。

Conclusion: 数据重用的效益并非恒定，而是受数据量和分布影响，未来研究数据扩展律时需显式建模这两个因素。

Abstract: While data scaling laws of large language models (LLMs) have been widely examined in the one-pass regime with massive corpora, their form under limited data and repeated epochs remains largely unexplored. This paper presents a theoretical analysis of how a common workaround, training for multiple epochs on the same dataset, reshapes the data scaling laws in linear regression. Concretely, we ask: to match the performance of training on a dataset of size $N$ for $K$ epochs, how much larger must a dataset be if the model is trained for only one pass? We quantify this using the \textit{effective reuse rate} of the data, $E(K, N)$, which we define as the multiplicative factor by which the dataset must grow under one-pass training to achieve the same test loss as $K$-epoch training. Our analysis precisely characterizes the scaling behavior of $E(K, N)$ for SGD in linear regression under either strong convexity or Zipf-distributed data: (1) When $K$ is small, we prove that $E(K, N) \approx K$, indicating that every new epoch yields a linear gain; (2) As $K$ increases, $E(K, N)$ plateaus at a problem-dependent value that grows with $N$ ($Θ(\log N)$ for the strongly-convex case), implying that larger datasets can be repeated more times before the marginal benefit vanishes. These theoretical findings point out a neglected factor in a recent empirical study (Muennighoff et al. (2023)), which claimed that training LLMs for up to $4$ epochs results in negligible loss differences compared to using fresh data at each step, \textit{i.e.}, $E(K, N) \approx K$ for $K \le 4$ in our notation. Supported by further empirical validation with LLMs, our results reveal that the maximum $K$ value for which $E(K, N) \approx K$ in fact depends on the data size and distribution, and underscore the need to explicitly model both factors in future studies of scaling laws with data reuse.

</details>


### [808] [Discovering Operational Patterns Using Image-Based Convolutional Clustering and Composite Evaluation: A Case Study in Foundry Melting Processes](https://arxiv.org/abs/2511.13444)
*Zhipeng Ma,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.LG

TL;DR: 提出一种基于图像卷积聚类与复合内部评估的无监督工业时序数据模式发现框架，有效识别熔炉操作中的可解释运行模式。


<details>
  <summary>Details</summary>
Motivation: 现有聚类方法在处理动态、非结构化工业时序数据时受限于固定距离度量或静态模型假设，难以应对标签缺失、高变异性与操作噪声问题。

Method: 将原始时序数据通过滑动窗口转换为灰度矩阵，利用深度卷积自编码器提取特征，并结合软硬聚类输出与两阶段选择策略；引入复合评估指标S_eva（结合轮廓系数、Calinski-Harabasz和Davies-Bouldin指数）进行客观性能评价。

Result: 在北欧铸造厂3900余次熔炉操作数据上识别出7种可解释的操作模式，显著区分能耗、热动态与生产周期；相比传统与深度聚类基线方法表现出更优性能、更强鲁棒性与领域一致性。

Conclusion: 该框架有效解决了时序不规则性、模式重叠与度量不一致等挑战，为工业系统提供了可推广的数据驱动诊断与能效优化方案。

Abstract: Industrial process monitoring increasingly relies on sensor-generated time-series data, yet the lack of labels, high variability, and operational noise make it difficult to extract meaningful patterns using conventional methods. Existing clustering techniques either rely on fixed distance metrics or deep models designed for static data, limiting their ability to handle dynamic, unstructured industrial sequences. Addressing this gap, this paper proposes a novel framework for unsupervised discovery of operational modes in univariate time-series data using image-based convolutional clustering with composite internal evaluation. The proposed framework improves upon existing approaches in three ways: (1) raw time-series sequences are transformed into grayscale matrix representations via overlapping sliding windows, allowing effective feature extraction using a deep convolutional autoencoder; (2) the framework integrates both soft and hard clustering outputs and refines the selection through a two-stage strategy; and (3) clustering performance is objectively evaluated by a newly developed composite score, S_eva, which combines normalized Silhouette, Calinski-Harabasz, and Davies-Bouldin indices. Applied to over 3900 furnace melting operations from a Nordic foundry, the method identifies seven explainable operational patterns, revealing significant differences in energy consumption, thermal dynamics, and production duration. Compared to classical and deep clustering baselines, the proposed approach achieves superior overall performance, greater robustness, and domain-aligned explainability. The framework addresses key challenges in unsupervised time-series analysis, such as sequence irregularity, overlapping modes, and metric inconsistency, and provides a generalizable solution for data-driven diagnostics and energy optimization in industrial systems.

</details>


### [809] [Hardware optimization on Android for inference of AI models](https://arxiv.org/abs/2511.13453)
*Iulius Gherasim,Carlos García Sánchez*

Main category: cs.LG

TL;DR: 本文研究了在Android系统上优化AI模型（YOLO和ResNet）执行配置的方法，评估了不同量化方案和GPU/NPU加速器的使用，以实现精度损失最小化和推理速度最大化之间的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 为了提升移动设备上AI模型的用户体验，需在低延迟和高响应性之间取得平衡，同时充分利用异构硬件架构。

Method: 通过实验评估多种模型量化方案以及在设备端加速器（GPU和NPU）上的执行效果，针对对象检测和图像分类任务寻找最优配置。

Result: 确定了在Android设备上运行YOLO和ResNet模型时，在精度和推理速度之间达到最佳权衡的执行配置组合。

Conclusion: 合理的量化策略结合GPU或NPU加速可显著提升移动端AI模型的推理效率，为实际部署提供了可行的优化方案。

Abstract: The pervasive integration of Artificial Intelligence models into contemporary mobile computing is notable across numerous use cases, from virtual assistants to advanced image processing. Optimizing the mobile user experience involves minimal latency and high responsiveness from deployed AI models with challenges from execution strategies that fully leverage real time constraints to the exploitation of heterogeneous hardware architecture. In this paper, we research and propose the optimal execution configurations for AI models on an Android system, focusing on two critical tasks: object detection (YOLO family) and image classification (ResNet). These configurations evaluate various model quantization schemes and the utilization of on device accelerators, specifically the GPU and NPU. Our core objective is to empirically determine the combination that achieves the best trade-off between minimal accuracy degradation and maximal inference speed-up.

</details>


### [810] [Artificial Intelligence-Enabled Spirometry for Early Detection of Right Heart Failure](https://arxiv.org/abs/2511.13457)
*Bin Liu,Qinghao Zhao,Yuxi Zhou,Zhejun Sun,Kaijie Lei,Deyun Zhang,Shijia Geng,Shenda Hong*

Main category: cs.LG

TL;DR: 本研究提出了一种自监督表示学习方法，结合呼吸图时间序列和人口统计学数据，用于早期检测肺心病患者的右心衰竭（RHF），在UK Biobank数据上表现出良好的预测性能，尤其在高风险临床亚组中表现优异。


<details>
  <summary>Details</summary>
Motivation: 右心衰竭（RHF）具有高发病率和死亡率，肺部疾病常导致右心室负荷增加进而引发RHF，因此亟需从有基础肺病的人群中有效筛查出发展为RHF的肺心病患者。

Method: 提出两阶段模型：第一阶段通过变分自编码器（VAE-encoder）对数据增强的无标签呼吸图时间序列进行自监督表示学习，获得低维特征表示；第二阶段将该表示与人口统计学信息融合，输入CatBoost分类器进行RHF预测。

Result: 在UK Biobank的26,617人队列中，模型检测RHF的AUROC为0.7501；在慢性肾病（CKD）亚组（n=74）和瓣膜性心脏病（VHD）亚组（n=64）中，AUROC分别达0.8194和0.8413，显示出在高风险人群中良好的区分能力。

Conclusion: 该自监督学习方法能有效利用呼吸图时间序列和人口统计学数据，具备在临床实践中早期识别RHF的潜力，尤其适用于高风险患者群体的筛查。

Abstract: Right heart failure (RHF) is a disease characterized by abnormalities in the structure or function of the right ventricle (RV), which is associated with high morbidity and mortality. Lung disease often causes increased right ventricular load, leading to RHF. Therefore, it is very important to screen out patients with cor pulmonale who develop RHF from people with underlying lung diseases. In this work, we propose a self-supervised representation learning method to early detecting RHF from patients with cor pulmonale, which uses spirogram time series to predict patients with RHF at an early stage. The proposed model is divided into two stages. The first stage is the self-supervised representation learning-based spirogram embedding (SLSE) network training process, where the encoder of the Variational autoencoder (VAE-encoder) learns a robust low-dimensional representation of the spirogram time series from the data-augmented unlabeled data. Second, this low-dimensional representation is fused with demographic information and fed into a CatBoost classifier for the downstream RHF prediction task. Trained and tested on a carefully selected subset of 26,617 individuals from the UK Biobank, our model achieved an AUROC of 0.7501 in detecting RHF, demonstrating strong population-level distinction ability. We further evaluated the model on high-risk clinical subgroups, achieving AUROC values of 0.8194 on a test set of 74 patients with chronic kidney disease (CKD) and 0.8413 on a set of 64 patients with valvular heart disease (VHD). These results highlight the model's potential utility in predicting RHF among clinically elevated-risk populations. In conclusion, this study presents a self-supervised representation learning approach combining spirogram time series and demographic data, demonstrating promising potential for early RHF detection in clinical practice.

</details>


### [811] [Multi-task GINN-LP for Multi-target Symbolic Regression](https://arxiv.org/abs/2511.13463)
*Hussein Rajabu,Lijun Qian,Xishuang Dong*

Main category: cs.LG

TL;DR: 提出MTRGINN-LP，一种用于多目标符号回归的可解释神经网络，通过结合多任务学习和GNN结构，在保持可解释性的同时有效捕捉目标间的依赖关系，并在实际应用中展现出良好的预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有符号回归方法主要针对单输出问题且在科学数据集上评估，泛化能力有限；现实世界中许多问题是多目标且变量间存在依赖关系，因此需要能处理多目标并保持可解释性的模型。

Method: 将GINN-LP与多任务深度学习结合，设计共享主干网络（包含多个幂项逼近模块）和任务特定输出层，以同时建模多个相关输出并保持表达式的可解释性。

Result: 在能源效率预测和可持续农业等实际多目标应用中验证了MTRGINN-LP的有效性，实验结果表明其具有竞争力的预测性能和高可解释性。

Conclusion: MTRGINN-LP成功扩展了符号回归至更广泛的现实世界多输出任务，在保持模型可解释性的同时有效捕捉了多目标间的相互依赖关系。

Abstract: In the area of explainable artificial intelligence, Symbolic Regression (SR) has emerged as a promising approach by discovering interpretable mathematical expressions that fit data. However, SR faces two main challenges: most methods are evaluated on scientific datasets with well-understood relationships, limiting generalization, and SR primarily targets single-output regression, whereas many real-world problems involve multi-target outputs with interdependent variables. To address these issues, we propose multi-task regression GINN-LP (MTRGINN-LP), an interpretable neural network for multi-target symbolic regression. By integrating GINN-LP with a multi-task deep learning, the model combines a shared backbone including multiple power-term approximator blocks with task-specific output layers, capturing inter-target dependencies while preserving interpretability. We validate multi-task GINN-LP on practical multi-target applications, including energy efficiency prediction and sustainable agriculture. Experimental results demonstrate competitive predictive performance alongside high interpretability, effectively extending symbolic regression to broader real-world multi-output tasks.

</details>


### [812] [AdamX: An Adam improvement algorithm based on a novel exponential decay mechanism for the second-order moment estimate](https://arxiv.org/abs/2511.13465)
*Meng Zhu,Quan Xiao,Weidong Min*

Main category: cs.LG

TL;DR: 本文提出了AdamX优化算法，通过引入一种新型的二阶矩估计指数衰减率，在训练过程中逐渐减弱学习步长校正强度，并在稳定训练阶段退化为SGD，从而提升训练稳定性与泛化能力。实验表明AdamX在性能上稳定优于Adam及其变体。


<details>
  <summary>Details</summary>
Motivation: Adam算法相较于SGD更容易收敛到非平坦极小值，影响模型泛化能力，尤其是在大模型时代对优化算法稳定性要求更高的背景下，亟需改进。

Method: 提出AdamX算法，核心是设计一种随训练进程动态调整的二阶矩估计指数衰减率机制，使算法在后期逐步减弱自适应学习率的修正作用，并向SGD靠拢。

Result: 实验验证了所提出的二阶矩估计衰减机制优于现有方法，AdamX在多种任务中表现优于Adam及其变体，具有更好的训练稳定性和泛化性能。

Conclusion: AdamX通过动态调整二阶矩估计衰减率，有效结合了Adam初期快速收敛和SGD后期稳定的优势，是一种更优的自适应优化算法。

Abstract: Since the 21st century, artificial intelligence has been leading a new round of industrial revolution. Under the training framework, the optimization algorithm aims to stably converge high-dimensional optimization to local and even global minima. Entering the era of large language models, although the scale of model parameters and data has increased, Adam remains the mainstream optimization algorithm. However, compared with stochastic gradient descent (SGD) based optimization algorithms, Adam is more likely to converge to non-flat minima. To address this issue, the AdamX algorithm is proposed. Its core innovation lies in the proposition of a novel type of second-order moment estimation exponential decay rate, which gradually weakens the learning step correction strength as training progresses, and degrades to SGD in the stable training period, thereby improving the stability of training in the stable period and possibly enhancing generalization ability. Experimental results show that our second-order moment estimation exponential decay rate is better than the current second-order moment estimation exponential decay rate, and AdamX can stably outperform Adam and its variants in terms of performance. Our code is open-sourced at https://github.com/mengzhu0308/AdamX.

</details>


### [813] [GREAT: Generalizable Representation Enhancement via Auxiliary Transformations for Zero-Shot Environmental Prediction](https://arxiv.org/abs/2511.13469)
*Shiyuan Luo,Chonghao Qiu,Runlong Yu,Yiqun Xie,Xiaowei Jia*

Main category: cs.LG

TL;DR: 本文提出了GREAT框架，通过在神经网络多层学习变换函数并采用双层训练策略，在保持原始物理规律和时间一致性的前提下增强环境数据，显著提升了模型在未见区域的零样本预测性能。


<details>
  <summary>Details</summary>
Motivation: 由于观测数据有限且地理分布不均，环境模型在跨未监测区域预测生态系统动态时面临挑战，且空间异质性易导致模型学习到仅适用于局部的虚假模式。

Method: 提出GREAT框架，通过在神经网络多层学习特征与时间影响的变换函数，并设计双层训练过程，确保增强数据能恢复原始控制过程且保留关键模式。

Result: 在美国东部六个生态多样的流域进行实验，结果表明GREAT在零样本场景下显著优于现有方法。

Conclusion: GREAT为观测不足的环境建模提供了有效的数据增强方案，提升了模型在未见区域的泛化能力。

Abstract: Environmental modeling faces critical challenges in predicting ecosystem dynamics across unmonitored regions due to limited and geographically imbalanced observation data. This challenge is compounded by spatial heterogeneity, causing models to learn spurious patterns that fit only local data. Unlike conventional domain generalization, environmental modeling must preserve invariant physical relationships and temporal coherence during augmentation. In this paper, we introduce Generalizable Representation Enhancement via Auxiliary Transformations (GREAT), a framework that effectively augments available datasets to improve predictions in completely unseen regions. GREAT guides the augmentation process to ensure that the original governing processes can be recovered from the augmented data, and the inclusion of the augmented data leads to improved model generalization. Specifically, GREAT learns transformation functions at multiple layers of neural networks to augment both raw environmental features and temporal influence. They are refined through a novel bi-level training process that constrains augmented data to preserve key patterns of the original source data. We demonstrate GREAT's effectiveness on stream temperature prediction across six ecologically diverse watersheds in the eastern U.S., each containing multiple stream segments. Experimental results show that GREAT significantly outperforms existing methods in zero-shot scenarios. This work provides a practical solution for environmental applications where comprehensive monitoring is infeasible.

</details>


### [814] [Quantum Machine Learning via Contrastive Training](https://arxiv.org/abs/2511.13497)
*Liudmila A. Zhukas,Vivian Ni Zhang,Qiang Miao,Qingfeng Wang,Marko Cetina,Jungsang Kim,Lawrence Carin,Christopher Monroe*

Main category: cs.LG

TL;DR: 提出了一种量子自监督预训练方法，通过在离子阱量子计算机上实现对比学习，减少了对标注数据的依赖，提升了图像分类性能，尤其在标注数据有限的情况下表现更优。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习模型面临标注数据稀缺的问题，尤其是在模型规模和复杂度增加时。需要减少对标注数据的依赖，提升模型泛化能力。

Method: 采用自监督对比预训练方法，在可编程的离子阱量子计算机上将图像编码为量子态，并利用量子测量重叠作为相似性度量，所有训练和分类过程均在硬件上完成。

Result: 经过微调后，预训练模型在图像家族分类任务中表现出更高的平均测试准确率和更低的运行间变异性，尤其在标注数据有限时提升显著；学习到的不变性能够泛化到预训练样本之外的数据。

Conclusion: 该工作建立了标签高效的量子表征学习路径，适用于量子原生数据集，并为处理更大规模的经典输入提供了清晰的发展方向。

Abstract: Quantum machine learning (QML) has attracted growing interest with the rapid parallel advances in large-scale classical machine learning and quantum technologies. Similar to classical machine learning, QML models also face challenges arising from the scarcity of labeled data, particularly as their scale and complexity increase. Here, we introduce self-supervised pretraining of quantum representations that reduces reliance on labeled data by learning invariances from unlabeled examples. We implement this paradigm on a programmable trapped-ion quantum computer, encoding images as quantum states. In situ contrastive pretraining on hardware yields a representation that, when fine-tuned, classifies image families with higher mean test accuracy and lower run-to-run variability than models trained from random initialization. Performance improvement is especially significant in regimes with limited labeled training data. We show that the learned invariances generalize beyond the pretraining image samples. Unlike prior work, our pipeline derives similarity from measured quantum overlaps and executes all training and classification stages on hardware. These results establish a label-efficient route to quantum representation learning, with direct relevance to quantum-native datasets and a clear path to larger classical inputs.

</details>


### [815] [Naga: Vedic Encoding for Deep State Space Models](https://arxiv.org/abs/2511.13510)
*Melanie Schaller,Nick Janssen,Bodo Rosenhahn*

Main category: cs.LG

TL;DR: 本文提出了Naga，一种受吠陀数学结构启发的深度状态空间模型（SSM）编码方法，通过双向处理时间序列并结合哈达玛交互，在多个长期时间序列预测基准上优于28种现有最先进模型，并具有更高的效率。


<details>
  <summary>Details</summary>
Motivation: 为了提升深度SSM在长期时间序列预测中捕捉远距离时序依赖的能力，同时提高计算效率和可解释性，本文受到吠陀数学结构的启发，提出新的编码机制。

Method: Naga采用前向与时间反向序列的双向处理方式，生成两种表示并通过逐元素（哈达玛）交互融合，形成受吠陀数学启发的编码结构，以增强对长程依赖的建模能力。

Result: 在ETTh1、ETTh2、ETTm1、ETTm2、Weather、Traffic和ILI等多个LTSF基准上，Naga性能超越28个当前最先进的模型，并且相比现有深度SSM方法更具计算效率。

Conclusion: 引入结构化的吠陀数学启发式分解可为长序列建模提供一种高效、可解释且性能优越的新途径。

Abstract: This paper presents Naga, a deep State Space Model (SSM) encoding approach inspired by structural concepts from Vedic mathematics. The proposed method introduces a bidirectional representation for time series by jointly processing forward and time-reversed input sequences. These representations are then combined through an element-wise (Hadamard) interaction, resulting in a Vedic-inspired encoding that enhances the model's ability to capture temporal dependencies across distant time steps. We evaluate Naga on multiple long-term time series forecasting (LTSF) benchmarks, including ETTh1, ETTh2, ETTm1, ETTm2, Weather, Traffic, and ILI. The experimental results show that Naga outperforms 28 current state of the art models and demonstrates improved efficiency compared to existing deep SSM-based approaches. The findings suggest that incorporating structured, Vedic-inspired decomposition can provide an interpretable and computationally efficient alternative for long-range sequence modeling.

</details>


### [816] [A Quantum Tensor Network-Based Viewpoint for Modeling and Analysis of Time Series Data](https://arxiv.org/abs/2511.13514)
*Pragatheeswaran Vipulananthan,Kamal Premaratne,Dilip Sarkar,Manohar N. Murthi*

Main category: cs.LG

TL;DR: 提出一种基于量子物理的“白盒”方法，通过核均值嵌入和张量网络启发的1D自旋链哈密顿量实现时间序列的不确定性量化，在变点检测和聚类任务中展示了优越的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络缺乏可解释性以及传统概率白盒模型性能不足的问题，实现高精度且可解释的不确定性量化。

Method: 将时间序列的核均值嵌入映射到再生核希尔伯特空间，构建受张量网络启发的1D自旋链哈密顿量，并利用薛定谔方程和微扰理论进行不确定性量化。

Result: 在变点检测和时间序列聚类任务中，相比现有白盒模型表现出更优的性能和更强的不确定性解释能力。

Conclusion: 该量子物理启发的白盒模型能有效结合高性能与高可解释性，为机器学习中的不确定性量化提供了新路径。

Abstract: Accurate uncertainty quantification is a critical challenge in machine learning. While neural networks are highly versatile and capable of learning complex patterns, they often lack interpretability due to their ``black box'' nature. On the other hand, probabilistic ``white box'' models, though interpretable, often suffer from a significant performance gap when compared to neural networks. To address this, we propose a novel quantum physics-based ``white box'' method that offers both accurate uncertainty quantification and enhanced interpretability. By mapping the kernel mean embedding (KME) of a time series data vector to a reproducing kernel Hilbert space (RKHS), we construct a tensor network-inspired 1D spin chain Hamiltonian, with the KME as one of its eigen-functions or eigen-modes. We then solve the associated Schr{ö}dinger equation and apply perturbation theory to quantify uncertainty, thereby improving the interpretability of tasks performed with the quantum tensor network-based model. We demonstrate the effectiveness of this methodology, compared to state-of-the-art ``white box" models, in change point detection and time series clustering, providing insights into the uncertainties associated with decision-making throughout the process.

</details>


### [817] [Mitigating Spurious Correlations in Patch-wise Tumor Classification on High-Resolution Multimodal Images](https://arxiv.org/abs/2511.13527)
*Ihab Asaad,Maha Shadaydeh,Joachim Denzler*

Main category: cs.LG

TL;DR: 本文研究了高分辨率多模态非线性显微图像中基于图像块的二分类问题，发现肿瘤与非肿瘤图像块在组织区域大小上存在虚假相关性，导致模型偏差。作者量化了该偏差的影响，并采用GERNE去偏方法提升最差组准确性（WGA），实验结果显示WGA提高了约7%，有效改善了关键少数情况下的分类性能。


<details>
  <summary>Details</summary>
Motivation: 在高分辨率图像中，像素级分割标注成本高、训练复杂。采用图像块级别的二分类可降低标注负担并简化训练，但容易引入由图像块组成与标签之间的虚假相关性导致的模型偏差，因此需要研究如何缓解此类偏差以提升模型在关键少数情况下的表现。

Method: 本文采用图像块级二分类策略检测肿瘤，识别出组织区域大小作为混淆因子引起的虚假相关性。通过量化该相关性带来的偏差，使用GERNE去偏方法优化最差组准确性（WGA），并在两种不同二值化阈值下进行实验验证。

Result: 相比传统经验风险最小化（ERM）方法，采用GERNE去偏策略使最差组准确性（WGA）提升了约7%。模型在肿瘤含小组织块和非肿瘤含大组织块等关键少数情形下的分类性能显著增强。

Conclusion: 在图像块级分类任务中，虚假相关性会显著影响模型公平性和鲁棒性，尤其是在医学图像分析中涉及关键少数样本时。引入去偏方法如GERNE以优化最差组性能，是提升模型实际应用可靠性的有效途径。

Abstract: Patch-wise multi-label classification provides an efficient alternative to full pixel-wise segmentation on high-resolution images, particularly when the objective is to determine the presence or absence of target objects within a patch rather than their precise spatial extent. This formulation substantially reduces annotation cost, simplifies training, and allows flexible patch sizing aligned with the desired level of decision granularity. In this work, we focus on a special case, patch-wise binary classification, applied to the detection of a single class of interest (tumor) on high-resolution multimodal nonlinear microscopy images. We show that, although this simplified formulation enables efficient model development, it can introduce spurious correlations between patch composition and labels: tumor patches tend to contain larger tissue regions, whereas non-tumor patches often consist mostly of background with small tissue areas. We further quantify the bias in model predictions caused by this spurious correlation, and propose to use a debiasing strategy to mitigate its effect. Specifically, we apply GERNE, a debiasing method that can be adapted to maximize worst-group accuracy (WGA). Our results show an improvement in WGA by approximately 7% compared to ERM for two different thresholds used to binarize the spurious feature. This enhancement boosts model performance on critical minority cases, such as tumor patches with small tissues and non-tumor patches with large tissues, and underscores the importance of spurious correlation-aware learning in patch-wise classification problems.

</details>


### [818] [Fairness-Aware Graph Representation Learning with Limited Demographic Information](https://arxiv.org/abs/2511.13540)
*Zichong Wang,Zhipeng Yin,Liping Yang,Jun Zhuang,Rui Yu,Qingzhao Kong,Wenbin Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种名为FairGLite的新框架，用于在有限人口统计信息下实现图神经网络的公平性学习。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的公平图学习方法假设可以完全获取人口统计信息，但在实际中由于隐私或法规限制，这一假设往往不成立。因此，需要一种能够在部分人口统计信息下有效缓解偏见的方法。

Method: 提出一种基于部分人口统计数据生成人口统计代理信息的机制，并设计跨群体节点嵌入一致性策略；引入自适应置信度策略，根据预测置信度动态调整各节点对公平性和效用的贡献。

Result: 理论分析表明，FairGLite在群体公平性指标上具有可证明的上界；实验结果显示该框架在多个数据集和基准上能有效降低偏差并保持模型性能。

Conclusion: FairGLite为在有限人口统计信息下的公平图学习提供了有效且有理论保障的解决方案，提升了图神经网络在现实场景中的公平性与实用性。

Abstract: Ensuring fairness in Graph Neural Networks is fundamental to promoting trustworthy and socially responsible machine learning systems. In response, numerous fair graph learning methods have been proposed in recent years. However, most of them assume full access to demographic information, a requirement rarely met in practice due to privacy, legal, or regulatory restrictions. To this end, this paper introduces a novel fair graph learning framework that mitigates bias in graph learning under limited demographic information. Specifically, we propose a mechanism guided by partial demographic data to generate proxies for demographic information and design a strategy that enforces consistent node embeddings across demographic groups. In addition, we develop an adaptive confidence strategy that dynamically adjusts each node's contribution to fairness and utility based on prediction confidence. We further provide theoretical analysis demonstrating that our framework, FairGLite, achieves provable upper bounds on group fairness metrics, offering formal guarantees for bias mitigation. Through extensive experiments on multiple datasets and fair graph learning frameworks, we demonstrate the framework's effectiveness in both mitigating bias and maintaining model utility.

</details>


### [819] [Graph Out-of-Distribution Detection via Test-Time Calibration with Dual Dynamic Dictionaries](https://arxiv.org/abs/2511.13541)
*Yue Hou,Ruomei Liu,Yingke Su,Junran Wu,Ke Xu*

Main category: cs.LG

TL;DR: 提出了一种新的测试时图分布外检测方法BaCa，利用双动态更新字典校准OOD分数，无需微调预训练模型，在真实数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图分布外检测方法因缺乏真实OOD样本且未充分探索图数据的多因素潜在结构，导致检测不可靠。

Method: 通过估计图子并仅使用测试样本进行混合同策略生成多样化的边界感知判别拓扑，构建基于优先队列和注意力机制的双动态字典来自适应捕捉ID和OOD表示，用于校准OOD分数。

Result: 在多个真实世界数据集上实验表明，BaCa显著优于现有的最先进方法。

Conclusion: BaCa无需微调即可有效提升图OOD检测性能，为测试时OOD检测提供了新思路。

Abstract: A key challenge in graph out-of-distribution (OOD) detection lies in the absence of ground-truth OOD samples during training. Existing methods are typically optimized to capture features within the in-distribution (ID) data and calculate OOD scores, which often limits pre-trained models from representing distributional boundaries, leading to unreliable OOD detection. Moreover, the latent structure of graph data is often governed by multiple underlying factors, which remains less explored. To address these challenges, we propose a novel test-time graph OOD detection method, termed BaCa, that calibrates OOD scores using dual dynamically updated dictionaries without requiring fine-tuning the pre-trained model. Specifically, BaCa estimates graphons and applies a mix-up strategy solely with test samples to generate diverse boundary-aware discriminative topologies, eliminating the need for exposing auxiliary datasets as outliers. We construct dual dynamic dictionaries via priority queues and attention mechanisms to adaptively capture latent ID and OOD representations, which are then utilized for boundary-aware OOD score calibration. To the best of our knowledge, extensive experiments on real-world datasets show that BaCa significantly outperforms existing state-of-the-art methods in OOD detection.

</details>


### [820] [RAC-DMVC: Reliability-Aware Contrastive Deep Multi-View Clustering under Multi-Source Noise](https://arxiv.org/abs/2511.13561)
*Shihao Dong,Yue Liu,Xiaotong Zhou,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种新的多视图聚类框架RAC-DMVC，用于在存在多种噪声（如缺失噪声和观测噪声）的情况下实现鲁棒的聚类性能。


<details>
  <summary>Details</summary>
Motivation: 传统多视图聚类方法在真实场景中面临多源噪声（如数据缺失和观测误差）的挑战，限制了其应用。本文旨在提升多视图聚类在复杂噪声环境下的鲁棒性和实用性。

Method: 提出RAC-DMVC框架：1）构建可靠性图以指导表示学习；2）引入跨视图重构和可靠性感知的对比学习应对观测噪声；3）设计双注意力补全机制处理缺失噪声；4）采用自监督聚类蒸馏模块优化表示。

Result: 在五个基准数据集上的实验表明，RAC-DMVC在多个评估指标上优于现有最先进方法，并在不同噪声比例下保持优异性能。

Conclusion: RAC-DMVC通过综合处理多源噪声，显著提升了多视图聚类在实际应用场景中的鲁棒性和有效性。

Abstract: Multi-view clustering (MVC), which aims to separate the multi-view data into distinct clusters in an unsupervised manner, is a fundamental yet challenging task. To enhance its applicability in real-world scenarios, this paper addresses a more challenging task: MVC under multi-source noises, including missing noise and observation noise. To this end, we propose a novel framework, Reliability-Aware Contrastive Deep Multi-View Clustering (RAC-DMVC), which constructs a reliability graph to guide robust representation learning under noisy environments. Specifically, to address observation noise, we introduce a cross-view reconstruction to enhances robustness at the data level, and a reliability-aware noise contrastive learning to mitigates bias in positive and negative pairs selection caused by noisy representations. To handle missing noise, we design a dual-attention imputation to capture shared information across views while preserving view-specific features. In addition, a self-supervised cluster distillation module further refines the learned representations and improves the clustering performance. Extensive experiments on five benchmark datasets demonstrate that RAC-DMVC outperforms SOTA methods on multiple evaluation metrics and maintains excellent performance under varying ratios of noise.

</details>


### [821] [Batch Acquisition Function Evaluations and Decouple Optimizer Updates for Faster Bayesian Optimization](https://arxiv.org/abs/2511.13625)
*Kaichi Irie,Shuhei Watanabe,Masaki Onishi*

Main category: cs.LG

TL;DR: 提出一种解耦拟牛顿更新的方法，在保持理论收敛性的同时显著减少多起点优化的计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯优化中批量处理获取函数导致拟牛顿法逆Hessian矩阵的非对角近似误差，影响收敛速度。

Method: 在批量调用获取函数的同时，使用协程解耦拟牛顿更新过程。

Result: 相比BoTorch等先前方法，显著减少了实际运行时间，同时实现了与顺序多起点优化相同的理论收敛性。

Conclusion: 该方法在不牺牲收敛性的前提下，有效提升了贝叶斯优化中获取函数优化的效率。

Abstract: Bayesian optimization (BO) efficiently finds high-performing parameters by maximizing an acquisition function, which models the promise of parameters. A major computational bottleneck arises in acquisition function optimization, where multi-start optimization (MSO) with quasi-Newton (QN) methods is required due to the non-convexity of the acquisition function. BoTorch, a widely used BO library, currently optimizes the summed acquisition function over multiple points, leading to the speedup of MSO owing to PyTorch batching. Nevertheless, this paper empirically demonstrates the suboptimality of this approach in terms of off-diagonal approximation errors in the inverse Hessian of a QN method, slowing down its convergence. To address this problem, we propose to decouple QN updates using a coroutine while batching the acquisition function calls. Our approach not only yields the theoretically identical convergence to the sequential MSO but also drastically reduces the wall-clock time compared to the previous approaches.

</details>


### [822] [Towards Multimodal Representation Learning in Paediatric Kidney Disease](https://arxiv.org/abs/2511.13637)
*Ana Durica,John Booth,Ivana Drobnjak*

Main category: cs.LG

TL;DR: 该研究利用2019至2025年在英国大奥蒙德街儿童医院收集的电子健康记录，采用循环神经网络模型整合纵向实验室数据和人口统计信息，预测儿童在未来30天内是否会出现异常血清肌酐值。


<details>
  <summary>Details</summary>
Motivation: 儿童肾病表现和进展差异大，需持续监测肾功能，而传统方法可能不足以捕捉动态变化。

Method: 使用时间序列建模方法，基于电子健康记录中的纵向实验室数据和人口统计信息，训练一个循环神经网络模型进行预测。

Result: 模型能够利用简单的时序表征从常规儿科数据中捕捉有用模式，初步验证了其在预测异常肌酐值方面的可行性。

Conclusion: 该研究为未来结合更多临床信号和更详细肾脏结局的多模态扩展奠定了基础，展示了时序模型在儿科肾功能监测中的潜力。

Abstract: Paediatric kidney disease varies widely in its presentation and progression, which calls for continuous monitoring of renal function. Using electronic health records collected between 2019 and 2025 at Great Ormond Street Hospital, a leading UK paediatric hospital, we explored a temporal modelling approach that integrates longitudinal laboratory sequences with demographic information. A recurrent neural model trained on these data was used to predict whether a child would record an abnormal serum creatinine value within the following thirty days. Framed as a pilot study, this work provides an initial demonstration that simple temporal representations can capture useful patterns in routine paediatric data and lays the groundwork for future multimodal extensions using additional clinical signals and more detailed renal outcomes.

</details>


### [823] [Data Value in the Age of Scaling: Understanding LLM Scaling Dynamics Under Real-Synthetic Data Mixtures](https://arxiv.org/abs/2511.13640)
*Haohui Wang,Jingyuan Qi,Jianpeng Chen,Jun Wu,Lifu Huang,Lecheng Zheng,Kevin Choi,Balaji Veeramani,Edward Bowen,Alison Hu,Tyler Cody,Dawei Zhou*

Main category: cs.LG

TL;DR: 本文研究了混合真实与合成数据对大语言模型（LLM）性能的影响，提出了一种高效的数据估值方法，能够有效评估和利用混合数据集，在多个任务上优于现有方法且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 合成数据虽具可扩展性和成本效益，但因生成机制导致长尾知识分布偏差，影响模型泛化能力，需有效方法评估混合数据的实用性。

Method: 识别模型学习头尾知识的三阶段缩放行为并确定两个断点，推导适用于真实-合成混合数据的LLM泛化误差界，并基于理论提出一种高效的数据估值方法。

Result: 所提方法在图像分类、情感分类、指令跟随和复杂推理四个任务上均优于现有最先进数据估值方法，且计算开销显著更低。

Conclusion: 本文提出的基于理论分析的数据估值方法能有效处理混合数据中的分布偏差问题，为大规模语言模型的数据选择与优化提供了高效实用的解决方案。

Abstract: The rapid progress of large language models (LLMs) is fueled by the growing reliance on datasets that blend real and synthetic data. While synthetic data offers scalability and cost-efficiency, it often introduces systematic distributional discrepancies, particularly underrepresenting long-tail knowledge due to truncation effects from data generation mechanisms like top-p sampling, temperature scaling, and finite sampling. These discrepancies pose fundamental challenges in characterizing and evaluating the utility of mixed real-synthetic datasets. In this paper, we identify a three-phase scaling behavior characterized by two breakpoints that reflect transitions in model behavior across learning head and tail knowledge. We further derive an LLM generalization bound designed for real and synthetic mixtures, revealing several key factors that govern their generalization performance. Building on our theoretical findings, we propose an effective yet efficient data valuation method that scales to large-scale datasets. Comprehensive experiments across four tasks, including image classification, sentiment classification, instruction following, and complex reasoning, demonstrate that our method surpasses state-of-the-art baselines in data valuation with significantly low computational cost.

</details>


### [824] [FuseSampleAgg: Fused Neighbor Sampling and Aggregation for Mini-batch GNNs](https://arxiv.org/abs/2511.13645)
*Aleksandar Stanković*

Main category: cs.LG

TL;DR: 提出了一种名为FuseSampleAgg的CUDA算子，将GraphSAGE中的一跳和两跳邻居采样与均值聚合融合为单次操作，显著提升了训练速度并降低了内存占用。


<details>
  <summary>Details</summary>
Motivation: 在大规模图神经网络训练中，邻居采样和特征聚合通常涉及多次内核调用和中间结果物化，导致高内存开销和通信延迟。为了提升效率，需要减少内存访问和内核启动开销。

Method: 设计并实现了一个融合算子FuseSampleAgg，将邻居采样与均值聚合合并为单一CUDA内核，通过索引重放机制避免块物化和额外内核调用，同时保持GraphSAGE的语义一致性。

Result: 在Reddit、ogbn-arxiv和ogbn-products数据集上（batch size 1024，启用混合精度），相比传统方法实现了最高51倍的步长时间加速（ogbn-products），Reddit上约4倍加速（fanouts 10-10和15-10），ogbn-arxiv在大fanout下约3.3倍加速；峰值显存占用最多降低100倍、36倍和3.5倍。该算子具有确定性，兼容PyTorch优化器，并提供复现脚本。

Conclusion: FuseSampleAgg通过融合采样与聚合操作显著提升了GraphSAGE训练效率，大幅减少了内存使用和运行时间，是一种高效、实用且易于集成的GNN训练优化方案。

Abstract: We present FuseSampleAgg, a CUDA operator that fuses neighbor sampling and mean aggregation into a single pass for one and two hop GraphSAGE. By eliminating block materialization and extra kernel launches, FuseSampleAgg reduces memory traffic and overhead while preserving GraphSAGE mean semantics via saved index replay. Across the Reddit, ogbn-arxiv, and ogbn-products benchmarks (batch size 1024, automatic mixed precision enabled), we observe step time speedups up to 51x on ogbn-products, about 4x on Reddit with fanouts 10-10 and 15-10, and about 3.3x on ogbn-arxiv at larger fanouts, with peak GPU memory reductions up to 100x, 36x, and about 3.5x, respectively. The operator is deterministic, integrates with standard PyTorch optimizers, and ships with scripts that reproduce all tables and figures from CSV logs. Code and scripts are available at https://github.com/SV25-22/FuseSampleAgg.

</details>


### [825] [Weight-sparse transformers have interpretable circuits](https://arxiv.org/abs/2511.13653)
*Leo Gao,Achyuta Rajaram,Jacob Coxon,Soham V. Govande,Bowen Baker,Dan Mossing*

Main category: cs.LG

TL;DR: 本文提出通过训练权重稀疏的语言模型来提升神经网络电路的可解释性，通过剪枝分离出特定任务的细粒度电路，并验证了这些电路具有高度的人类可理解性。


<details>
  <summary>Details</summary>
Motivation: 为了在语言模型中发现人类可理解的电路，推动机械可解释性领域的发展。

Method: 通过约束大部分权重为零来训练权重稀疏的模型，并结合剪枝技术隔离特定任务相关的电路，从而提取出结构简单、易于解释的神经通路。

Result: 得到的电路通常包含对应自然概念的神经元和残差通道，连接关系清晰且可解释；模型规模越大，能力与可解释性的权衡表现越好，但超过数千万非零参数后仍难以保持可解释性；该方法也可初步用于解释已有的密集模型。

Conclusion: 该方法显著提升了语言模型中电路的人类可理解性，并通过严谨验证表明其有效性，为构建可解释AI系统提供了可行路径。

Abstract: Finding human-understandable circuits in language models is a central goal of the field of mechanistic interpretability. We train models to have more understandable circuits by constraining most of their weights to be zeros, so that each neuron only has a few connections. To recover fine-grained circuits underlying each of several hand-crafted tasks, we prune the models to isolate the part responsible for the task. These circuits often contain neurons and residual channels that correspond to natural concepts, with a small number of straightforwardly interpretable connections between them. We study how these models scale and find that making weights sparser trades off capability for interpretability, and scaling model size improves the capability-interpretability frontier. However, scaling sparse models beyond tens of millions of nonzero parameters while preserving interpretability remains a challenge. In addition to training weight-sparse models de novo, we show preliminary results suggesting our method can also be adapted to explain existing dense models. Our work produces circuits that achieve an unprecedented level of human understandability and validates them with considerable rigor.

</details>


### [826] [Tuning for Two Adversaries: Enhancing the Robustness Against Transfer and Query-Based Attacks using Hyperparameter Tuning](https://arxiv.org/abs/2511.13654)
*Pascal Zimmer,Ghassan Karame*

Main category: cs.LG

TL;DR: 本文首次详细分析了优化超参数（如学习率、权重衰减、动量和批量大小）对迁移攻击和查询攻击鲁棒性的影响，发现降低学习率可显著提升对迁移攻击的鲁棒性，而提高学习率则有助于防御查询攻击，并揭示分布式模型通过超参数调优能最有效同时抵御两类攻击。


<details>
  <summary>Details</summary>
Motivation: 理解不同优化超参数如何影响模型在多种部署场景下的对抗鲁棒性，尤其是针对转移和查询两种主要攻击类型，以指导更安全的模型训练。

Method: 结合理论分析与实验验证，在集中式训练、集成学习和分布式训练等多种实际场景下，系统研究学习率、权重衰减、动量和批量大小等超参数对模型鲁棒性的影响。

Result: 发现学习率对不同类型攻击有相反影响：降低学习率可使对迁移攻击的鲁棒性提升高达64%；提高学习率则可使对查询攻击的鲁棒性提升达28%；分布式模型通过调参能最好地平衡并改善对两类攻击的防御能力。

Conclusion: 优化超参数的选择显著影响模型对抗鲁棒性，且对不同攻击类型存在权衡；通过合理设计超参数，尤其是应用于分布式训练，可同时提升对迁移和查询攻击的防御能力。

Abstract: In this paper, we present the first detailed analysis of how optimization hyperparameters -- such as learning rate, weight decay, momentum, and batch size -- influence robustness against both transfer-based and query-based attacks. Supported by theory and experiments, our study spans a variety of practical deployment settings, including centralized training, ensemble learning, and distributed training. We uncover a striking dichotomy: for transfer-based attacks, decreasing the learning rate significantly enhances robustness by up to $64\%$. In contrast, for query-based attacks, increasing the learning rate consistently leads to improved robustness by up to $28\%$ across various settings and data distributions. Leveraging these findings, we explore -- for the first time -- the optimization hyperparameter design space to jointly enhance robustness against both transfer-based and query-based attacks. Our results reveal that distributed models benefit the most from hyperparameter tuning, achieving a remarkable tradeoff by simultaneously mitigating both attack types more effectively than other training setups.

</details>


### [827] [Scientific Data Compression and Super-Resolution Sampling](https://arxiv.org/abs/2511.13675)
*Minh Vu,Andrey Lokhov*

Main category: cs.LG

TL;DR: 提出了一种基于学习指数族的科学数据压缩与超分辨率新框架，能够在保证关键物理特性的同时实现高效数据压缩和重建。


<details>
  <summary>Details</summary>
Motivation: 科学模拟和实验产生的数据量巨大，传统存储和处理方法难以应对，需要有效的数据压缩方法并保证关键物理特征的可恢复性。

Method: 基于学习指数族的框架，支持在压缩过程中保留和量化物理量的不确定性，并实现压缩比与重建保真度之间的灵活权衡。

Result: 该方法在保持关键物理特性的同时，实现了高效的数据压缩与高保真度的超分辨率重建。

Conclusion: 所提出的框架为科学数据的压缩与恢复提供了一种可靠且灵活的解决方案，适用于如检查点恢复等关键科学计算任务。

Abstract: Modern scientific simulations, observations, and large-scale experiments generate data at volumes that often exceed the limits of storage, processing, and analysis. This challenge drives the development of data reduction methods that efficiently manage massive datasets while preserving essential physical features and quantities of interest. In many scientific workflows, it is also crucial to enable data recovery from compressed representations - a task known as super-resolution - with guarantees on the preservation of key physical characteristics. A notable example is checkpointing and restarting, which is essential for long-running simulations to recover from failures, resume after interruptions, or examine intermediate results. In this work, we introduce a novel framework for scientific data compression and super-resolution, grounded in recent advances in learning exponential families. Our method preserves and quantifies uncertainty in physical quantities of interest and supports flexible trade-offs between compression ratio and reconstruction fidelity.

</details>


### [828] [Cross-Learning from Scarce Data via Multi-Task Constrained Optimization](https://arxiv.org/abs/2511.13680)
*Leopoldo Agorio,Juan Cerviño,Miguel Calvo-Fullana,Alejandro Ribeiro,Juan Andrés Bazerque*

Main category: cs.LG

TL;DR: 提出了一种多任务交叉学习框架，通过联合估计多个相关任务的确定性参数来解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 当训练数据有限时，模型难以泛化；需要一种能利用多个相关任务信息的方法来提升小样本任务的性能。

Method: 将多任务参数估计建模为带约束的优化问题，通过约束控制不同任务参数之间的相似性，实现跨任务的信息共享与知识迁移。

Result: 在高斯数据下提供了理论保证，并在图像分类和传染病传播等真实数据应用中验证了方法的有效性，显著提升了小样本任务的参数估计准确性。

Conclusion: 该交叉学习框架能有效缓解数据稀缺带来的过拟合问题，通过多任务协同学习提高模型泛化能力，适用于关键的小样本参数推断场景。

Abstract: A learning task, understood as the problem of fitting a parametric model from supervised data, fundamentally requires the dataset to be large enough to be representative of the underlying distribution of the source. When data is limited, the learned models fail generalize to cases not seen during training. This paper introduces a multi-task \emph{cross-learning} framework to overcome data scarcity by jointly estimating \emph{deterministic} parameters across multiple, related tasks. We formulate this joint estimation as a constrained optimization problem, where the constraints dictate the resulting similarity between the parameters of the different models, allowing the estimated parameters to differ across tasks while still combining information from multiple data sources. This framework enables knowledge transfer from tasks with abundant data to those with scarce data, leading to more accurate and reliable parameter estimates, providing a solution for scenarios where parameter inference from limited data is critical. We provide theoretical guarantees in a controlled framework with Gaussian data, and show the efficiency of our cross-learning method in applications with real data including image classification and propagation of infectious diseases.

</details>


### [829] [Protein Secondary Structure Prediction Using 3D Graphs and Relation-Aware Message Passing Transformers](https://arxiv.org/abs/2511.13685)
*Disha Varshney,Samarth Garg,Sarthak Tyagi,Deeksha Varshney,Nayan Deep,Asif Ekbal*

Main category: cs.LG

TL;DR: 本文提出了一种结合图神经网络（GNN）和语言模型（LM）的蛋白质二级结构预测方法SSRGNet，利用蛋白质残基图捕捉序列与结构信息，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用已知的蛋白质3D结构信息来提升二级结构预测，而该信息对蛋白质功能至关重要。因此，需要一种能显式建模空间结构的方法。

Method: 构建蛋白质残基图，引入多种序列和结构连接关系；使用预训练的Transformer蛋白语言模型编码序列，并采用GCN和R-GCN等消息传递机制捕捉几何特征；通过堆叠卷积层学习空间图中的复杂依赖关系。

Result: 在NetSurfP-2.0提供的数据集上进行实验，SSRGNet在3类和8类二级结构预测任务中均优于基线模型，f1-score表现更优。

Conclusion: SSRGNet有效融合了序列与结构信息，通过图神经网络和语言模型的协同建模，提升了蛋白质二级结构预测精度，为后续三级结构预测提供了有力支持。

Abstract: In this study, we tackle the challenging task of predicting secondary structures from protein primary sequences, a pivotal initial stride towards predicting tertiary structures, while yielding crucial insights into protein activity, relationships, and functions. Existing methods often utilize extensive sets of unlabeled amino acid sequences. However, these approaches neither explicitly capture nor harness the accessible protein 3D structural data, which is recognized as a decisive factor in dictating protein functions. To address this, we utilize protein residue graphs and introduce various forms of sequential or structural connections to capture enhanced spatial information. We adeptly combine Graph Neural Networks (GNNs) and Language Models (LMs), specifically utilizing a pre-trained transformer-based protein language model to encode amino acid sequences and employing message-passing mechanisms like GCN and R-GCN to capture geometric characteristics of protein structures. Employing convolution within a specific node's nearby region, including relations, we stack multiple convolutional layers to efficiently learn combined insights from the protein's spatial graph, revealing intricate interconnections and dependencies in its structural arrangement. To assess our model's performance, we employed the training dataset provided by NetSurfP-2.0, which outlines secondary structure in 3-and 8-states. Extensive experiments show that our proposed model, SSRGNet surpasses the baseline on f1-scores.

</details>


### [830] [Efficient Calibration for Decision Making](https://arxiv.org/abs/2511.13699)
*Parikshit Gopalan,Konstantinos Stavropoulos,Kunal Talwar,Pranay Tankala*

Main category: cs.LG

TL;DR: 本文提出了基于结构化后处理函数族K的校准决策损失（CDL_K），建立了其可计算性和信息论上的可处理性理论，并为机器学习中常用再校准方法提供了严格保证。


<details>
  <summary>Details</summary>
Motivation: 由于原有的校准决策损失（CDL）在离线情况下难以近似计算，因此需要引入限制后的CDL_K以实现可计算性和实用性。

Method: 通过限制后处理函数的结构家族K，定义了相对应的CDL_K，并系统研究了其在不同函数族下的信息论和计算复杂性，提出新的算法技术和理论分析工具。

Result: 建立了CDL_K的可处理性理论，给出了自然函数类的上下界结果，并证明了一些常用再校准方法的理论保证。

Conclusion: 限制后处理函数族是绕过CDL不可计算性的有效途径，CDL_K为校准性在决策中的应用提供了新的可计算且有理论支持的度量方式。

Abstract: A decision-theoretic characterization of perfect calibration is that an agent seeking to minimize a proper loss in expectation cannot improve their outcome by post-processing a perfectly calibrated predictor. Hu and Wu (FOCS'24) use this to define an approximate calibration measure called calibration decision loss ($\mathsf{CDL}$), which measures the maximal improvement achievable by any post-processing over any proper loss. Unfortunately, $\mathsf{CDL}$ turns out to be intractable to even weakly approximate in the offline setting, given black-box access to the predictions and labels.
  We suggest circumventing this by restricting attention to structured families of post-processing functions $K$. We define the calibration decision loss relative to $K$, denoted $\mathsf{CDL}_K$ where we consider all proper losses but restrict post-processings to a structured family $K$. We develop a comprehensive theory of when $\mathsf{CDL}_K$ is information-theoretically and computationally tractable, and use it to prove both upper and lower bounds for natural classes $K$. In addition to introducing new definitions and algorithmic techniques to the theory of calibration for decision making, our results give rigorous guarantees for some widely used recalibration procedures in machine learning.

</details>


### [831] [Learning stochasticity: a nonparametric framework for intrinsic noise estimation](https://arxiv.org/abs/2511.13701)
*Gianluigi Pillonetto,Alberto Giaretta,Mauro Bisiacco*

Main category: cs.LG

TL;DR: 本文提出了一种名为Trine的非参数核方法，用于从时间序列数据中推断状态依赖的内在噪声，无需预设参数假设，在生物和生态系统的基准问题上表现接近‘oracle’水平。


<details>
  <summary>Details</summary>
Motivation: 由于非线性相互作用和随机效应的知识不完整，传统的自下而上建模方法效果有限，因此需要能够直接从数据中发现动力学方程的方法，尤其是能有效估计内在噪声的方法。

Method: 提出Trine框架，采用三阶段算法，结合解析可解的子问题和结构化核架构，捕捉噪声驱动的突变和状态相关的平滑方差变化，实现对内在噪声的非参数推断。

Result: 在多个生物和生态系统的基准问题上验证了Trine的有效性，其性能接近‘oracle’水平，能够揭示隐藏的动力学特征。

Conclusion: Trine为理解复杂系统中内在噪声的影响提供了新途径，尤其适用于缺乏先验知识的非线性随机系统分析。

Abstract: Understanding the principles that govern dynamical systems is a central challenge across many scientific domains, including biology and ecology. Incomplete knowledge of nonlinear interactions and stochastic effects often renders bottom-up modeling approaches ineffective, motivating the development of methods that can discover governing equations directly from data. In such contexts, parametric models often struggle without strong prior knowledge, especially when estimating intrinsic noise. Nonetheless, incorporating stochastic effects is often essential for understanding the dynamic behavior of complex systems such as gene regulatory networks and signaling pathways. To address these challenges, we introduce Trine (Three-phase Regression for INtrinsic noisE), a nonparametric, kernel-based framework that infers state-dependent intrinsic noise from time-series data. Trine features a three-stage algorithm that com- bines analytically solvable subproblems with a structured kernel architecture that captures both abrupt noise-driven fluctuations and smooth, state-dependent changes in variance. We validate Trine on biological and ecological systems, demonstrating its ability to uncover hidden dynamics without relying on predefined parametric assumptions. Across several benchmark problems, Trine achieves performance comparable to that of an oracle. Biologically, this oracle can be viewed as an idealized observer capable of directly tracking the random fluctuations in molecular concentrations or reaction events within a cell. The Trine framework thus opens new avenues for understanding how intrinsic noise affects the behavior of complex systems.

</details>


### [832] [ST-ProC: A Graph-Prototypical Framework for Robust Semi-Supervised Travel Mode Identification](https://arxiv.org/abs/2511.13702)
*Luyao Niu,Nuoxian Huang*

Main category: cs.LG

TL;DR: 提出了一种名为ST-ProC的新型图原型多目标半监督学习框架，用于从GPS轨迹中识别出行模式，显著提升了在稀疏标签现实场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习方法在处理标注成本高、标签稀缺的出行模式识别任务时，存在确认偏差严重和忽略数据流形结构的问题。

Method: 结合图正则化、原型锚定和一种新的边界感知伪标签策略构建图原型核心，并引入对比学习和师生一致性损失来支持和稳定训练过程。

Result: ST-ProC在真实稀疏标签场景下显著优于所有基线方法，相比FixMatch等最先进方法性能提升达21.5%。

Conclusion: ST-ProC有效缓解了标签稀缺问题，通过利用数据流形结构和噪声抑制机制，在出行模式识别任务中实现了鲁棒且高性能的表现。

Abstract: Travel mode identification (TMI) from GPS trajectories is critical for urban intelligence, but is hampered by the high cost of annotation, leading to severe label scarcity. Prevailing semi-supervised learning (SSL) methods are ill-suited for this task, as they suffer from catastrophic confirmation bias and ignore the intrinsic data manifold. We propose ST-ProC, a novel graph-prototypical multi-objective SSL framework to address these limitations. Our framework synergizes a graph-prototypical core with foundational SSL Support. The core exploits the data manifold via graph regularization, prototypical anchoring, and a novel, margin-aware pseudo-labeling strategy to actively reject noise. This core is supported and stabilized by foundational contrastive and teacher-student consistency losses, ensuring high-quality representations and robust optimization. ST-ProC outperforms all baselines by a significant margin, demonstrating its efficacy in real-world sparse-label settings, with a performance boost of 21.5% over state-of-the-art methods like FixMatch.

</details>


### [833] [Rare Genomic Subtype Discovery from RNA-seq via Autoencoder Embeddings and Stability-Aware Clustering](https://arxiv.org/abs/2511.13705)
*Alaa Mezghiche*

Main category: cs.LG

TL;DR: 提出一种结合自编码器表示、聚类和稳定性分析的无监督方法，在高维RNA-seq数据中发现罕见但可重复的基因组亚型，尤其在KIRC癌症中识别出一个稳定且罕见的亚型（占6.85%）。


<details>
  <summary>Details</summary>
Motivation: 传统的分子分型常依赖标准标签，可能忽略罕见亚型；希望在无监督条件下发现高维RNA-seq数据中具有生物学意义且稳定的罕见亚型。

Method: 使用自编码器提取2000个高变基因的低维表示（128维潜空间），在KIRC数据上进行k-means聚类（k=2-10），结合稳定性分析（Jaccard ≥ 0.60，匈牙利对齐）和预设发现规则筛选罕见（<10%）且稳定的簇。

Result: 在KIRC中发现k=5的聚类解，其中C0为罕见簇（6.85%），稳定性高（Jaccard = 0.787），轮廓系数0.129，DBI为2.045；差异表达分析识别出一致的标记基因；泛癌分析验证组织来源主导聚类结果（Cramer's V = 0.887）。

Conclusion: 组织来源是泛癌聚类的主要驱动因素；而在单癌种内采用稳定性感知的聚类策略可有效揭示罕见但可重复的分子亚型，具有潜在临床意义。

Abstract: Unsupervised learning on high-dimensional RNA-seq data can reveal molecular subtypes beyond standard labels. We combine an autoencoder-based representation with clustering and stability analysis to search for rare but reproducible genomic subtypes. On the UCI "Gene Expression Cancer RNA-Seq" dataset (801 samples, 20,531 genes; BRCA, COAD, KIRC, LUAD, PRAD), a pan-cancer analysis shows clusters aligning almost perfectly with tissue of origin (Cramer's V = 0.887), serving as a negative control. We therefore reframe the problem within KIRC (n = 146): we select the top 2,000 highly variable genes, standardize them, train a feed-forward autoencoder (128-dimensional latent space), and run k-means for k = 2-10. While global indices favor small k, scanning k with a pre-specified discovery rule (rare < 10 percent and stable with Jaccard >= 0.60 across 20 seeds after Hungarian alignment) yields a simple solution at k = 5 (silhouette = 0.129, DBI = 2.045) with a rare cluster C0 (6.85 percent of patients) that is highly stable (Jaccard = 0.787). Cluster-vs-rest differential expression (Welch's t-test, Benjamini-Hochberg FDR) identifies coherent markers. Overall, pan-cancer clustering is dominated by tissue of origin, whereas a stability-aware within-cancer approach reveals a rare, reproducible KIRC subtype.

</details>


### [834] [From Black Box to Insight: Explainable AI for Extreme Event Preparedness](https://arxiv.org/abs/2511.13712)
*Kiana Vu,İsmet Selçuk Özer,Phung Lai,Zheng Wu,Thilanka Munasinghe,Jennifer Wei*

Main category: cs.LG

TL;DR: 本研究探讨了可解释人工智能（XAI）在极端事件（以野火预测为例）预报中的作用，利用SHAP方法提高模型的透明度和实用性，增强决策者对AI预测的信任与应用。


<details>
  <summary>Details</summary>
Motivation: 由于AI模型的黑箱特性限制了其在现实决策中的应用，迫切需要提升模型的可解释性和可信度，以支持气候变化背景下日益频繁的极端事件应对。

Method: 采用多种AI模型进行野火预测，并结合SHAP方法分析特征重要性、决策路径和潜在偏差，同时提供可视化工具以增强解释结果的可理解性。

Result: XAI不仅揭示了模型的内在推理机制，还通过可视化增强了领域专家和应急团队的决策能力，提升了AI在时空模式和季节性特征上的可解释性。

Conclusion: 准确且可解释、可访问、值得信赖的AI系统对于灾害准备、风险缓解和气候韧性规划至关重要，XAI是实现这一目标的关键桥梁。

Abstract: As climate change accelerates the frequency and severity of extreme events such as wildfires, the need for accurate, explainable, and actionable forecasting becomes increasingly urgent. While artificial intelligence (AI) models have shown promise in predicting such events, their adoption in real-world decision-making remains limited due to their black-box nature, which limits trust, explainability, and operational readiness. This paper investigates the role of explainable AI (XAI) in bridging the gap between predictive accuracy and actionable insight for extreme event forecasting. Using wildfire prediction as a case study, we evaluate various AI models and employ SHapley Additive exPlanations (SHAP) to uncover key features, decision pathways, and potential biases in model behavior. Our analysis demonstrates how XAI not only clarifies model reasoning but also supports critical decision-making by domain experts and response teams. In addition, we provide supporting visualizations that enhance the interpretability of XAI outputs by contextualizing feature importance and temporal patterns in seasonality and geospatial characteristics. This approach enhances the usability of AI explanations for practitioners and policymakers. Our findings highlight the need for AI systems that are not only accurate but also interpretable, accessible, and trustworthy, essential for effective use in disaster preparedness, risk mitigation, and climate resilience planning.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [835] [Learning Conjugate Direction Fields for Planar Quadrilateral Mesh Generation](https://arxiv.org/abs/2511.11865)
*Jiong Tao,Yong-Liang Yang,Bailin Deng*

Main category: cs.GR

TL;DR: 提出一种基于神经网络的数据驱动方法，用于生成受用户引导的共轭方向场（CDF），以高效构建平面四边形（PQ）网格。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过求解复杂的非线性优化问题生成CDF，计算成本高且难以实现交互式设计，限制了在建筑设计等应用中的效率和灵活性。

Method: 采用神经网络学习自由曲面和用户笔画的特征，融合后快速生成符合用户指导的高质量CDF，并构建包含50000多个样本的数据集用于训练与评估。

Result: 实验表明该方法在多种测试数据、建筑表面和通用3D形状上均能高效生成高质量CDF，显著提升计算效率并支持交互式设计。

Conclusion: 所提数据驱动方法有效解决了传统CDF生成中计算昂贵和交互性差的问题，为PQ网格生成提供了高效、实用的新途径。

Abstract: Planar quadrilateral (PQ) mesh generation is a key process in computer-aided design, particularly for architectural applications where the goal is to discretize a freeform surface using planar quad faces. The conjugate direction field (CDF) defined on the freeform surface plays a significant role in generating a PQ mesh, as it largely determines the PQ mesh layout. Conventionally, a CDF is obtained by solving a complex non-linear optimization problem that incorporates user preferences, i.e., aligning the CDF with user-specified strokes on the surface. This often requires a large number of iterations that are computationally expensive, preventing the interactive CDF design process for a desirable PQ mesh. To address this challenge, we propose a data-driven approach based on neural networks for controlled CDF generation. Our approach can effectively learn and fuse features from the freeform surface and the user strokes, and efficiently generate quality CDF respecting user guidance. To enable training and testing, we also present a dataset composed of 50000+ freeform surfaces with ground-truth CDFs, as well as a set of metrics for quantitative evaluation. The effectiveness and efficiency of our work are demonstrated by extensive experiments using testing data, architectural surfaces, and general 3D shapes.

</details>


### [836] [Locomotion in CAVE: Enhancing Immersion through Full-Body Motion](https://arxiv.org/abs/2511.12251)
*Xiaohui Li,Xiaolong Liu,Zhongchen Shi,Wei Chen,Liang Xie,Meng Gai,Jun Cao,Suxia Zhang,Erwei Yin*

Main category: cs.GR

TL;DR: 提出了一种基于优化人体动作识别技术的CAVE环境中的运动框架，提升了虚拟环境中的沉浸感，减少了晕动症。


<details>
  <summary>Details</summary>
Motivation: 现有的CAVE系统中运动方式受限于不自然的交互方法，影响用户体验和沉浸感。

Method: 构建四面显示的CAVE系统，采用基于Perspective-n-Point的动态相机标定方法，结合动作识别架构识别用户动作，并将其传输至图形工作站进行渲染。

Result: 用户实验表明，与传统方法相比，该方法在真实感和自我存在感方面有显著提升，并有效减少运动 sickness。

Conclusion: 所提出的运动框架能够显著提升CAVE系统中的沉浸式运动体验，是一种有效的VR交互改进方案。

Abstract: Cave Automatic Virtual Environment (CAVE) is one of the virtual reality (VR) immersive devices currently used to present virtual environments. However, the locomotion methods in the CAVE are limited by unnatural interaction methods, severely hindering the user experience and immersion in the CAVE. We proposed a locomotion framework for CAVE environments aimed at enhancing the immersive locomotion experience through optimized human motion recognition technology. Firstly, we construct a four-sided display CAVE system, then through the dynamic method based on Perspective-n-Point to calibrate the camera, using the obtained camera intrinsics and extrinsic parameters, and an action recognition architecture to get the action category. At last, transform the action category to a graphical workstation that renders display effects on the screen. We designed a user study to validate the effectiveness of our method. Compared to the traditional methods, our method has significant improvements in realness and self-presence in the virtual environment, effectively reducing motion sickness.

</details>


### [837] [TR-Gaussians: High-fidelity Real-time Rendering of Planar Transmission and Reflection with 3D Gaussian Splatting](https://arxiv.org/abs/2511.13009)
*Yong Liu,Keyang Ye,Tianjia Shao,Kun Zhou*

Main category: cs.GR

TL;DR: 提出了一种名为TR-Gaussians的新型3D高斯表示方法，用于高保真渲染室内的平面透射和反射效果。


<details>
  <summary>Details</summary>
Motivation: 室内场景中普遍存在玻璃等具有透射和反射特性的平面，现有方法难以高保真地建模这些复杂视觉效果。

Method: 结合3D高斯与可学习的反射平面，显式建模玻璃表面，并利用镜像高斯表示反射成分；通过基于菲涅尔项的视点相关权重融合透射与反射成分，并设计多阶段优化框架进行训练。

Result: 在多个数据集上实现了实时、高保真的新视角合成，优于当前最先进的方法，无论在定量指标还是视觉质量上均表现更优。

Conclusion: TR-Gaussians能有效建模室内场景中的平面透射与反射现象，显著提升复杂外观效果的渲染质量，适用于实时高保真渲染应用。

Abstract: We propose Transmission-Reflection Gaussians (TR-Gaussians), a novel 3D-Gaussian-based representation for high-fidelity rendering of planar transmission and reflection, which are ubiquitous in indoor scenes. Our method combines 3D Gaussians with learnable reflection planes that explicitly model the glass planes with view-dependent reflectance strengths. Real scenes and transmission components are modeled by 3D Gaussians and the reflection components are modeled by the mirrored Gaussians with respect to the reflection plane. The transmission and reflection components are blended according to a Fresnel-based, view-dependent weighting scheme, allowing for faithful synthesis of complex appearance effects under varying viewpoints. To effectively optimize TR-Gaussians, we develop a multi-stage optimization framework incorporating color and geometry constraints and an opacity perturbation mechanism. Experiments on different datasets demonstrate that TR-Gaussians achieve real-time, high-fidelity novel view synthesis in scenes with planar transmission and reflection, and outperform state-of-the-art approaches both quantitatively and qualitatively.

</details>


### [838] [Force-Aware 3D Contact Modeling for Stable Grasp Generation](https://arxiv.org/abs/2511.13247)
*Zhuo Chen,Zhongqun Zhang,Yihua Cheng,Ales Leonardis,Hyung Jin Chang*

Main category: cs.GR

TL;DR: 本文提出了一种基于显式接触力预测的稳定抓取生成方法，通过引入力感知的接触表示和稳定性约束，显著提升了抓取的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有抓取生成方法多关注物体几何结构，忽视接触力等物理属性，导致抓取稳定性不足。

Method: 定义力感知的接触表示（将法向力离散化为单热编码），建立以加速度最小化为目标的稳定性优化问题，并结合物理约束设计姿态优化器。

Result: 在两个公开数据集上实验表明，该方法在稳定性指标上提升约20%，且对新物体具有良好的适应性。

Conclusion: 通过显式建模接触力并引入物理驱动的稳定性约束，可有效生成更稳定的抓取姿态。

Abstract: Contact-based grasp generation plays a crucial role in various applications. Recent methods typically focus on the geometric structure of objects, producing grasps with diverse hand poses and plausible contact points. However, these approaches often overlook the physical attributes of the grasp, specifically the contact force, leading to reduced stability of the grasp. In this paper, we focus on stable grasp generation using explicit contact force predictions. First, we define a force-aware contact representation by transforming the normal force value into discrete levels and encoding it using a one-hot vector. Next, we introduce force-aware stability constraints. We define the stability problem as an acceleration minimization task and explicitly relate stability with contact geometry by formulating the underlying physical constraints. Finally, we present a pose optimizer that systematically integrates our contact representation and stability constraints to enable stable grasp generation. We show that these constraints can help identify key contact points for stability which provide effective initialization and guidance for optimization towards a stable grasp. Experiments are carried out on two public benchmarks, showing that our method brings about 20% improvement in stability metrics and adapts well to novel objects.

</details>
