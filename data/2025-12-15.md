<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 90]
- [cs.CL](#cs.CL) [Total: 31]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.LG](#cs.LG) [Total: 61]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [WildCap: Facial Appearance Capture in the Wild via Hybrid Inverse Rendering](https://arxiv.org/abs/2512.11237)
*Yuxuan Han,Xin Ming,Tianxiao Li,Zhuofan Shen,Qixuan Zhang,Lan Xu,Feng Xu*

Main category: cs.CV

TL;DR: 本文提出WildCap，一种利用智能手机在自然光照下拍摄的视频进行高质量人脸外观捕获的新方法。通过结合数据驱动与基于模型的逆向渲染，并引入texel网格光照模型和扩散先验，有效解决了野外环境下光照复杂、网络预测伪影等问题，显著缩小了野外捕获与可控光照捕获之间的质量差距。


<details>
  <summary>Details</summary>
Motivation: 现有高质量人脸外观捕获方法依赖可控光照，成本高、实用性受限；亟需在自然光照（in-the-wild）下实现同等质量的捕获。

Method: 提出混合逆向渲染框架：先用SwitchLight将野外图像转换为更约束条件，再进行模型驱动的逆向渲染；引入texel网格光照模型解释非物理伪影；联合采样扩散先验并优化光照与反射率，解决尺度模糊问题。

Result: 在相同野外捕获设置下显著优于先前方法，大幅缩小野外与可控光照捕获的质量差距。

Conclusion: WildCap实现了高质量、低成本、高可用的人脸外观捕获，推动了逆向渲染在真实场景中的实用化落地。

Abstract: Existing methods achieve high-quality facial appearance capture under controllable lighting, which increases capture cost and limits usability. We propose WildCap, a novel method for high-quality facial appearance capture from a smartphone video recorded in the wild. To disentangle high-quality reflectance from complex lighting effects in in-the-wild captures, we propose a novel hybrid inverse rendering framework. Specifically, we first apply a data-driven method, i.e., SwitchLight, to convert the captured images into more constrained conditions and then adopt model-based inverse rendering. However, unavoidable local artifacts in network predictions, such as shadow-baking, are non-physical and thus hinder accurate inverse rendering of lighting and material. To address this, we propose a novel texel grid lighting model to explain non-physical effects as clean albedo illuminated by local physical lighting. During optimization, we jointly sample a diffusion prior for reflectance maps and optimize the lighting, effectively resolving scale ambiguity between local lights and albedo. Our method achieves significantly better results than prior arts in the same capture setup, closing the quality gap between in-the-wild and controllable recordings by a large margin. Our code will be released \href{https://yxuhan.github.io/WildCap/index.html}{\textcolor{magenta}{here}}.

</details>


### [2] [Leveraging Text Guidance for Enhancing Demographic Fairness in Gender Classification](https://arxiv.org/abs/2512.11015)
*Anoop Krishnan*

Main category: cs.CV

TL;DR: 本文提出了一种利用图像文本匹配（ITM）指导和图文融合的方法，通过图像标题中的语义信息提升基于面部图像的性别分类算法的公平性与泛化能力，无需依赖人口统计标签，且具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决基于面部图像的性别分类中普遍存在的种族与性别群体间偏差问题，提升模型在不同人口统计群体上的公平性和准确性。

Method: 提出两种文本引导策略：图像-文本匹配（ITM）指导，用于学习图像与文本间的细粒度对齐；图像-文本融合，将图文模态联合建模以生成更全面的表征。训练过程不依赖人口统计标签。

Result: 在基准数据集上实验表明，所提方法显著缓解了跨性别与种族群体的偏差，同时提升了分类准确率，并具备可解释性与应用无关性。

Conclusion: 文本引导的多模态学习是一种有效、无需敏感标签、可解释的提升面部性别分类公平性的新范式，为构建更公正的视觉分析系统提供了可行路径。

Abstract: In the quest for fairness in artificial intelligence, novel approaches to enhance it in facial image based gender classification algorithms using text guided methodologies are presented. The core methodology involves leveraging semantic information from image captions during model training to improve generalization capabilities. Two key strategies are presented: Image Text Matching (ITM) guidance and Image Text fusion. ITM guidance trains the model to discern fine grained alignments between images and texts to obtain enhanced multimodal representations. Image text fusion combines both modalities into comprehensive representations for improved fairness. Exensive experiments conducted on benchmark datasets demonstrate these approaches effectively mitigate bias and improve accuracy across gender racial groups compared to existing methods. Additionally, the unique integration of textual guidance underscores an interpretable and intuitive training paradigm for computer vision systems. By scrutinizing the extent to which semantic information reduces disparities, this research offers valuable insights into cultivating more equitable facial analysis algorithms. The proposed methodologies contribute to addressing the pivotal challenge of demographic bias in gender classification from facial images. Furthermore, this technique operates in the absence of demographic labels and is application agnostic.

</details>


### [3] [Text images processing system using artificial intelligence models](https://arxiv.org/abs/2512.11691)
*Aya Kaysan Bahjat*

Main category: cs.CV

TL;DR: 本文提出了一种基于DBNet++和BART模型的文本图像分类设备，可将含文本的图像（如发票、表格、信件、报告）在复杂成像条件下进行高精度分类与识别。


<details>
  <summary>Details</summary>
Motivation: 解决实际场景中光照变化、文本方向随机、弯曲、部分遮挡、低分辨率及文字可见性差等挑战下的文本图像分类问题。

Method: 采用四阶段流程：图像采集与预处理、基于DBNet++的文本区域检测、基于BART模型的文本内容分类、PyQt5实现的用户界面结果展示。

Result: 在Total-Text数据集上测试十小时，文本识别率达94.62%，验证了方法在多源、非受控条件下的有效性。

Conclusion: 该系统具备实用性强、鲁棒性高、流程集成度好的特点，适用于真实场景下的文本图像自动分类任务。

Abstract: This is to present a text image classifier device that identifies textual content in images and then categorizes each image into one of four predefined categories, including Invoice, Form, Letter, or Report. The device supports a gallery mode, in which users browse files on flash disks, hard disk drives, or microSD cards, and a live mode which renders feeds of cameras connected to it. Its design is specifically aimed at addressing pragmatic challenges, such as changing light, random orientation, curvature or partial coverage of text, low resolution, and slightly visible text. The steps of the processing process are divided into four steps: image acquisition and preprocessing, textual elements detection with the help of DBNet++ (Differentiable Binarization Network Plus) model, BART (Bidirectional Auto-Regressive Transformers) model that classifies detected textual elements, and the presentation of the results through a user interface written in Python and PyQt5. All the stages are connected in such a way that they form a smooth workflow. The system achieved a text recognition rate of about 94.62% when tested over ten hours on the mentioned Total-Text dataset, that includes high resolution images, created so as to represent a wide range of problematic conditions. These experimental results support the effectiveness of the suggested methodology to practice, mixed-source text categorization, even in uncontrolled imaging conditions.

</details>


### [4] [SoccerMaster: A Vision Foundation Model for Soccer Understanding](https://arxiv.org/abs/2512.11016)
*Haolin Yang,Jiayuan Rao,Haoning Wu,Weidi Xie*

Main category: cs.CV

TL;DR: 本文提出了SoccerMaster，首个面向足球领域的视觉基础模型，通过监督式多任务预训练统一处理多种足球视觉理解任务，并构建了大规模预训练数据集SoccerFactory，实验表明其在多个下游任务上优于专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖孤立的、任务特定的专家模型，难以应对足球领域特有的复杂性和多样化理解需求，因此需要一个统一的、足球专用的基础模型。

Method: 提出SoccerMaster模型，采用监督式多任务预训练；构建自动化空间标注数据清洗流程，整合多个现有足球视频数据集形成SoccerFactory预训练资源。

Result: SoccerMaster在各类下游任务（如运动员检测、事件分类等）上持续超越任务专用专家模型，验证了其泛化性与优越性。

Conclusion: SoccerMaster作为首个足球专用视觉基础模型，成功实现了从细粒度感知到语义推理的多任务统一建模，为体育视觉理解提供了新范式。

Abstract: Soccer understanding has recently garnered growing research interest due to its domain-specific complexity and unique challenges. Unlike prior works that typically rely on isolated, task-specific expert models, this work aims to propose a unified model to handle diverse soccer visual understanding tasks, ranging from fine-grained perception (e.g., athlete detection) to semantic reasoning (e.g., event classification). Specifically, our contributions are threefold: (i) we present SoccerMaster, the first soccer-specific vision foundation model that unifies diverse understanding tasks within a single framework via supervised multi-task pretraining; (ii) we develop an automated data curation pipeline to generate scalable spatial annotations, and integrate them with various existing soccer video datasets to construct SoccerFactory, a comprehensive pretraining data resource; and (iii) we conduct extensive evaluations demonstrating that SoccerMaster consistently outperforms task-specific expert models across diverse downstream tasks, highlighting its breadth and superiority. The data, code, and model will be publicly available.

</details>


### [5] [Particulate: Feed-Forward 3D Object Articulation](https://arxiv.org/abs/2512.11798)
*Ruining Li,Yuxin Yao,Chuanxia Zheng,Christian Rupprecht,Joan Lasenby,Shangzhe Wu,Andrea Vedaldi*

Main category: cs.CV

TL;DR: Particulate是一种基于Transformer的前馈网络，能从单个静态3D网格直接推断其可动结构（部件、运动学结构与约束），速度快、泛化性强，支持AI生成资产，并引入新基准与评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖逐物体优化，速度慢且难以泛化到AI生成的3D资产；亟需一种快速、端到端、无需优化的可动结构推理方法。

Method: 提出Part Articulation Transformer，以输入网格的点云为输入，通过可扩展的Transformer架构联合预测3D部件、运动学结构和运动约束；端到端训练于多源公开3D数据集；推理时将预测结果映射回原始网格。

Result: 在新构建的高质量基准上显著超越SOTA；推理仅需数秒；可成功处理AI生成3D模型，并与图像到3D生成器结合实现单图驱动的可动3D建模。

Conclusion: Particulate为3D可动结构估计提供了高效、通用、实用的新范式，推动了从单张图像或网格构建可驱动3D对象的全流程自动化。

Abstract: We present Particulate, a feed-forward approach that, given a single static 3D mesh of an everyday object, directly infers all attributes of the underlying articulated structure, including its 3D parts, kinematic structure, and motion constraints. At its core is a transformer network, Part Articulation Transformer, which processes a point cloud of the input mesh using a flexible and scalable architecture to predict all the aforementioned attributes with native multi-joint support. We train the network end-to-end on a diverse collection of articulated 3D assets from public datasets. During inference, Particulate lifts the network's feed-forward prediction to the input mesh, yielding a fully articulated 3D model in seconds, much faster than prior approaches that require per-object optimization. Particulate can also accurately infer the articulated structure of AI-generated 3D assets, enabling full-fledged extraction of articulated 3D objects from a single (real or synthetic) image when combined with an off-the-shelf image-to-3D generator. We further introduce a new challenging benchmark for 3D articulation estimation curated from high-quality public 3D assets, and redesign the evaluation protocol to be more consistent with human preferences. Quantitative and qualitative results show that Particulate significantly outperforms state-of-the-art approaches.

</details>


### [6] [Weakly Supervised Tuberculosis Localization in Chest X-rays through Knowledge Distillation](https://arxiv.org/abs/2512.11057)
*Marshal Ashif Shawkat,Moidul Hasan,Taufiq Hasan*

Main category: cs.CV

TL;DR: 本文提出一种基于知识蒸馏的CNN模型，用于减少结核病（TB）胸部X光片分类中的虚假相关性，并实现无需边界框标注的病灶定位，在TBX11k数据集上达到0.2428 mIOU，且学生模型性能超越教师模型。


<details>
  <summary>Details</summary>
Motivation: 结核病诊断依赖胸片，但专家解读资源匮乏；现有机器学习模型易受虚假相关影响、泛化能力差，且高质量标注数据构建成本高昂。

Method: 采用ResNet50架构的师生知识蒸馏框架，无需边界框标注即可实现TB异常定位与鲁棒分类。

Result: 在TBX11k数据集上取得0.2428 mIOU；学生模型性能持续优于教师模型。

Conclusion: 该方法有效降低虚假相关性、提升模型鲁棒性与泛化能力，具备在资源有限地区临床部署的潜力。

Abstract: Tuberculosis (TB) remains one of the leading causes of mortality worldwide, particularly in resource-limited countries. Chest X-ray (CXR) imaging serves as an accessible and cost-effective diagnostic tool but requires expert interpretation, which is often unavailable. Although machine learning models have shown high performance in TB classification, they often depend on spurious correlations and fail to generalize. Besides, building large datasets featuring high-quality annotations for medical images demands substantial resources and input from domain specialists, and typically involves several annotators reaching agreement, which results in enormous financial and logistical expenses. This study repurposes knowledge distillation technique to train CNN models reducing spurious correlations and localize TB-related abnormalities without requiring bounding-box annotations. By leveraging a teacher-student framework with ResNet50 architecture, the proposed method trained on TBX11k dataset achieve impressive 0.2428 mIOU score. Experimental results further reveal that the student model consistently outperforms the teacher, underscoring improved robustness and potential for broader clinical deployment in diverse settings.

</details>


### [7] [Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance](https://arxiv.org/abs/2512.11800)
*Jan U. Müller,Robin Tim Landsgesell,Leif Van Holland,Patrick Stotko,Reinhard Klein*

Main category: cs.CV

TL;DR: 本文提出了一种基于统计矩的高保真透射率计算方法，用于改进3D高斯点阵（3DGS）的光栅化渲染，避免了光线追踪和像素级排序，在保持实时性的同时提升了半透明物体的渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯点阵（3DGS）虽在新视角合成中表现出色，但其依赖简化的alpha混合与密度积分粗略近似，难以准确渲染复杂重叠的半透明物体。

Method: 提出基于统计矩的连续密度分布建模方法：对每条相机光线，解析推导并计算所有贡献高斯体的像素级矩；据此重建每条光线的连续透射函数，并在各高斯体内独立采样。

Result: 显著提升复杂半透明介质中的光衰减建模精度，从而改善整体重建与渲染质量，且无需光线追踪或逐像素排序。

Conclusion: 该方法在光栅化框架下实现了接近物理真实性的透射建模，弥合了实时渲染与物理准确性之间的鸿沟。

Abstract: The recent success of 3D Gaussian Splatting (3DGS) has reshaped novel view synthesis by enabling fast optimization and real-time rendering of high-quality radiance fields. However, it relies on simplified, order-dependent alpha blending and coarse approximations of the density integral within the rasterizer, thereby limiting its ability to render complex, overlapping semi-transparent objects. In this paper, we extend rasterization-based rendering of 3D Gaussian representations with a novel method for high-fidelity transmittance computation, entirely avoiding the need for ray tracing or per-pixel sample sorting. Building on prior work in moment-based order-independent transparency, our key idea is to characterize the density distribution along each camera ray with a compact and continuous representation based on statistical moments. To this end, we analytically derive and compute a set of per-pixel moments from all contributing 3D Gaussians. From these moments, a continuous transmittance function is reconstructed for each ray, which is then independently sampled within each Gaussian. As a result, our method bridges the gap between rasterization and physical accuracy by modeling light attenuation in complex translucent media, significantly improving overall reconstruction and rendering quality.

</details>


### [8] [VLM2GeoVec: Toward Universal Multimodal Embeddings for Remote Sensing](https://arxiv.org/abs/2512.11490)
*Emanuel Sánchez Aimar,Gulnaz Zhambulova,Fahad Shahbaz Khan,Yonghao Xu,Michael Felsberg*

Main category: cs.CV

TL;DR: 本文提出VLM2GeoVec，一种单编码器视觉语言模型，统一嵌入图像、文本、边界框和地理坐标，在遥感多任务基准RSMEB上显著提升区域级检索与空间推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感方法在双编码器检索模型（缺乏模态交织能力）和生成式助手（缺乏可扩展检索能力）之间割裂，难以兼顾区域级空间推理与整体场景理解。

Method: 提出单编码器VLM2GeoVec模型，采用对比学习将图像、文本、边界框和地理坐标等多模态交错输入映射到统一向量空间，摒弃多阶段流程和任务专用模块；并构建新基准RSMEB评估其多功能性。

Result: 在RSMEB上，区域-描述检索P@1达26.6%（+25pp），指代表达检索P@1达32.5%（+19pp），语义地理定位检索P@1达17.8%（超此前最优3倍以上），并在场景分类和跨模态检索等常规任务上媲美或超越专用基线。

Conclusion: VLM2GeoVec成功统一了可扩展检索与区域级空间推理能力，为遥感领域提供了支持连贯多模态分析的通用基础模型。

Abstract: Satellite imagery differs fundamentally from natural images: its aerial viewpoint, very high resolution, diverse scale variations, and abundance of small objects demand both region-level spatial reasoning and holistic scene understanding. Current remote-sensing approaches remain fragmented between dual-encoder retrieval models, which excel at large-scale cross-modal search but cannot interleave modalities, and generative assistants, which support region-level interpretation but lack scalable retrieval capabilities. We propose $\textbf{VLM2GeoVec}$, an instruction-following, single-encoder vision-language model trained contrastively to embed interleaved inputs (images, text, bounding boxes, and geographic coordinates) in a unified vector space. Our single encoder interleaves all inputs into one joint embedding trained with a contrastive loss, eliminating multi-stage pipelines and task-specific modules. To evaluate its versatility, we introduce $\textbf{RSMEB}$, a novel benchmark covering key remote-sensing embedding applications: scene classification; cross-modal search; compositional retrieval; visual-question answering; visual grounding and region-level reasoning; and semantic geospatial retrieval. On RSMEB, it achieves $\textbf{26.6%}$ P@1 on region-caption retrieval (+25 pp vs. dual-encoder baselines), $\textbf{32.5%}$ P@1 on referring-expression retrieval (+19 pp), and $\textbf{17.8%}$ P@1 on semantic geo-localization retrieval (over $3\times$ prior best), while matching or exceeding specialized baselines on conventional tasks such as scene classification and cross-modal retrieval. VLM2GeoVec unifies scalable retrieval with region-level spatial reasoning, enabling cohesive multimodal analysis in remote sensing. We will publicly release the code, checkpoints, and data upon acceptance.

</details>


### [9] [Synthetic Vasculature and Pathology Enhance Vision-Language Model Reasoning](https://arxiv.org/abs/2512.11060)
*Chenjun Li,Cheng Wan,Laurin Lux,Alexander Berger,Richard B. Rosen,Martin J. Menten,Johannes C. Paetzold*

Main category: cs.CV

TL;DR: 本文提出Synthetic Vasculature Reasoning（SVR）框架，可控生成带糖尿病视网膜病变特征的合成OCTA图像及细粒度推理文本，构建OCTA-100K-SVR数据集；基于该数据微调通用VLM（Qwen3-VL-8b），在真实OCTA图像上实现89.67%零样本平衡分类准确率，并显著提升临床解释质量与病灶定位能力。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型（VLMs）需大量带精细病理标注的图文配对数据进行推理训练，但在OCTA等专业领域，此类高质量、可定位的文本描述极度稀缺，制约模型可解释性诊断发展。

Method: 提出SVR框架：通过可控图像合成技术生成含DR典型特征（毛细血管缺失、微动脉瘤、新生血管、迂曲）的逼真视网膜血管图像，并同步自动生成对应细粒度临床推理文本；据此构建含10万图文对的OCTA-100K-SVR数据集；在该数据集上微调通用VLM（Qwen3-VL-8b）。

Result: 微调后的模型在真实OCTA图像上达成89.67%零样本平衡分类准确率，超越监督式基线；经临床专家评估，其生成的解释质量与病灶定位精度显著提升。

Conclusion: SVR证明了可控合成图文数据是缓解医学小众模态标注瓶颈的有效途径，能高效赋能VLM实现高精度、可解释的跨模态临床诊断。

Abstract: Vision-Language Models (VLMs) offer a promising path toward interpretable medical diagnosis by allowing users to ask about clinical explanations alongside predictions and across different modalities. However, training VLMs for detailed reasoning requires large-scale image-text datasets. In many specialized domains, for example in reading Optical Coherence Tomography Angiography (OCTA) images, such precise text with grounded description of pathologies is scarce or even non-existent. To overcome this bottleneck, we introduce Synthetic Vasculature Reasoning (SVR), a framework that controllably synthesizes images and corresponding text, specifically: realistic retinal vasculature with Diabetic Retinopathy (DR) features: capillary dropout, microaneurysms, neovascularization, and tortuosity, while automatically generating granular reasoning texts. Based on this we curate OCTA-100K-SVR, an OCTA image-reasoning dataset with 100,000 pairs. Our experiments show that a general-purpose VLM (Qwen3-VL-8b) trained on the dataset achieves a zero-shot balanced classification accuracy of 89.67% on real OCTA images, outperforming supervised baselines. Through human expert evaluation we also demonstrate that it significantly enhances explanation quality and pathology localization on clinical data.

</details>


### [10] [VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation](https://arxiv.org/abs/2512.11061)
*Felix O'Mahony,Roberto Cipolla,Ayush Tewari*

Main category: cs.CV

TL;DR: 本文提出VDAWorld框架，通过视觉语言模型（VLM）将图像-文本对提炼为可模拟的抽象场景表示，并自适应选择物理仿真器进行动态推演，从而构建可解释、可查询、符合物理规律的生成式世界模型。


<details>
  <summary>Details</summary>
Motivation: 现有生成式视频模型存在违背物理/逻辑规则、缺乏交互性、不可解释等根本局限，难以支撑结构化、可查询的世界建模需求。

Method: 提出VDAWorld框架：由VLM作为智能代理，自主调用视觉工具构建2D/3D具身场景表示，并据此匹配适配的物理仿真器（如刚体、流体），再从静态场景中推断潜在动力学以预测未来状态。

Result: 实验证明该方法能在多种动态场景下生成高质量、符合物理规律的仿真结果，展现出强泛化性与灵活性。

Conclusion: VDAWorld实现了从黑箱生成到可解释、可干预、物理一致的世界建模范式转变，为构建结构化、可查询的智能世界模型提供了新路径。

Abstract: Generative video models, a leading approach to world modeling, face fundamental limitations. They often violate physical and logical rules, lack interactivity, and operate as opaque black boxes ill-suited for building structured, queryable worlds. To overcome these challenges, we propose a new paradigm focused on distilling an image caption pair into a tractable, abstract representation optimized for simulation. We introduce VDAWorld, a framework where a Vision-Language Model (VLM) acts as an intelligent agent to orchestrate this process. The VLM autonomously constructs a grounded (2D or 3D) scene representation by selecting from a suite of vision tools, and accordingly chooses a compatible physics simulator (e.g., rigid body, fluid) to act upon it. VDAWorld can then infer latent dynamics from the static scene to predict plausible future states. Our experiments show that this combination of intelligent abstraction and adaptive simulation results in a versatile world model capable of producing high quality simulations across a wide range of dynamic scenarios.

</details>


### [11] [E-CHUM: Event-based Cameras for Human Detection and Urban Monitoring](https://arxiv.org/abs/2512.11076)
*Jack Brady,Andrew Dailey,Kristen Schang,Zo Vic Shong*

Main category: cs.CV

TL;DR: 本文综述了基于事件相机在城市动态研究中的应用潜力，强调其在低光环境下的优势及隐私保护能力，并提出与红外、LiDAR或振动传感器融合的多传感器方案以克服其局限性。


<details>
  <summary>Details</summary>
Motivation: 传统城市监测方法（如人工观察、RGB相机）存在隐私泄露、光照依赖等局限，亟需更高效、隐私友好且鲁棒的感知手段来深入理解城市动态。

Method: 文献综述与技术分析：系统梳理事件相机原理、特性、应用场景及挑战，并探讨其与红外、LiDAR、振动等传感器的融合策略。

Result: 论证事件相机在城市动态监测中具备低功耗、高时间分辨率、强隐私保护和弱光适应等优势；提出多传感器融合可有效弥补其在纹理、深度信息等方面的不足。

Conclusion: 事件相机是一种有前景的城市动态感知新媒介，结合多传感器融合将显著提升城市动态建模与理解能力。

Abstract: Understanding human movement and city dynamics has always been challenging. From traditional methods of manually observing the city's inhabitant, to using cameras, to now using sensors and more complex technology, the field of urban monitoring has evolved greatly. Still, there are more that can be done to unlock better practices for understanding city dynamics. This paper surveys how the landscape of urban dynamics studying has evolved with a particular focus on event-based cameras. Event-based cameras capture changes in light intensity instead of the RGB values that traditional cameras do. They offer unique abilities, like the ability to work in low-light, that can make them advantageous compared to other sensors. Through an analysis of event-based cameras, their applications, their advantages and challenges, and machine learning applications, we propose event-based cameras as a medium for capturing information to study urban dynamics. They offer the ability to capture important information while maintaining privacy. We also suggest multi-sensor fusion of event-based cameras and other sensors in the study of urban dynamics. Combining event-based cameras and infrared, event-LiDAR, or vibration has to potential to enhance the ability of event-based cameras and overcome the challenges that event-based cameras have.

</details>


### [12] [Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing Scene Description](https://arxiv.org/abs/2512.11098)
*Nazanin Mahjourian,Vinh Nguyen*

Main category: cs.CV

TL;DR: 本文提出VLM-IRIS框架，通过将红外图像预处理为RGB兼容格式（如magma表示）并结合CLIP模型与提示集成策略，实现无需微调的零样本工业热成像检测（如3D打印工作台工件存在性判断）。


<details>
  <summary>Details</summary>
Motivation: 红外相机在低光或封闭制造环境中具有优势，但现有视觉语言模型（VLMs）仅训练于RGB数据，无法直接处理红外图像；同时，标注数据稀缺促使需零样本学习方案。

Method: 将FLIR Boson红外图像转换为magma伪彩色RGB表示，输入CLIP ViT-B/32编码器，并采用质心提示集成（centroid prompt ensembling）进行零样本推理。

Result: 在3D打印机工作台工件存在性检测任务中取得高准确率，无需任何模型重训练或红外数据微调。

Conclusion: VLM-IRIS成功拓展了视觉语言模型至热成像领域，验证了其在无标签工业监测中的可行性与有效性。

Abstract: Many manufacturing environments operate in low-light conditions or within enclosed machines where conventional vision systems struggle. Infrared cameras provide complementary advantages in such environments. Simultaneously, supervised AI systems require large labeled datasets, which makes zero-shot learning frameworks more practical for applications including infrared cameras. Recent advances in vision-language foundation models (VLMs) offer a new path in zero-shot predictions from paired image-text representations. However, current VLMs cannot understand infrared camera data since they are trained on RGB data. This work introduces VLM-IRIS (Vision-Language Models for InfraRed Industrial Sensing), a zero-shot framework that adapts VLMs to infrared data by preprocessing infrared images captured by a FLIR Boson sensor into RGB-compatible inputs suitable for CLIP-based encoders. We demonstrate zero-shot workpiece presence detection on a 3D printer bed where temperature differences between the build plate and workpieces make the task well-suited for thermal imaging. VLM-IRIS converts the infrared images to magma representation and applies centroid prompt ensembling with a CLIP ViT-B/32 encoder to achieve high accuracy on infrared images without any model retraining. These findings demonstrate that the proposed improvements to VLMs can be effectively extended to thermal applications for label-free monitoring.

</details>


### [13] [VGent: Visual Grounding via Modular Design for Disentangling Reasoning and Prediction](https://arxiv.org/abs/2512.11099)
*Weitai Kang,Jason Kuen,Mengwei Ren,Zijun Wei,Yan Yan,Kangning Liu*

Main category: cs.CV

TL;DR: 本文提出VGent，一种模块化的编码器-解码器架构，用于视觉定位任务。它将高层推理与低层边界框预测解耦：冻结的多模态大语言模型（MLLM）作为编码器提供强大推理能力，解码器则基于检测器提出的高质量候选框，通过交叉注意力选择目标框。该方法避免了自回归解码的缺陷，支持模块化升级，并在多目标视觉定位基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定位模型存在两大问题：基于自回归解码的MLLM方法速度慢且易产生幻觉；而重新对齐LLM与视觉特征的方法可能损害LLM预训练的推理能力。本文旨在设计一种既能保留强大推理能力、又能高效精准定位的新型架构。

Method: 提出VGent架构：1）冻结的MLLM作为编码器，保持其原始推理能力；2）轻量解码器以检测器生成的候选框为查询，通过交叉注意力从编码器隐状态中选择目标框；3）引入三项改进：(i) 基于强化学习的QuadThinker训练范式增强多目标推理；(ii) mask-aware标签解决检测-分割歧义；(iii) 全局目标识别提升增强提案间的区分能力。

Result: 在多目标视觉定位基准上，VGent达到新SOTA：F1分数提升20.6%，gIoU提升8.2%，cIoU提升5.8%（尤其在视觉参考挑战下），同时保持恒定且快速的推理延迟。

Conclusion: VGent通过显式解耦推理与定位、模块化设计及多项针对性改进，有效克服了现有方法的局限，在精度与效率间取得更好平衡，验证了编码器-解码器范式在视觉定位任务中的优越性。

Abstract: Current visual grounding models are either based on a Multimodal Large Language Model (MLLM) that performs auto-regressive decoding, which is slow and risks hallucinations, or on re-aligning an LLM with vision features to learn new special or object tokens for grounding, which may undermine the LLM's pretrained reasoning ability. In contrast, we propose VGent, a modular encoder-decoder architecture that explicitly disentangles high-level reasoning and low-level bounding box prediction. Specifically, a frozen MLLM serves as the encoder to provide untouched powerful reasoning capabilities, while a decoder takes high-quality boxes proposed by detectors as queries and selects target box(es) via cross-attending on encoder's hidden states. This design fully leverages advances in both object detection and MLLM, avoids the pitfalls of auto-regressive decoding, and enables fast inference. Moreover, it supports modular upgrades of both the encoder and decoder to benefit the whole system: we introduce (i) QuadThinker, an RL-based training paradigm for enhancing multi-target reasoning ability of the encoder; (ii) mask-aware label for resolving detection-segmentation ambiguity; and (iii) global target recognition to improve the recognition of all the targets which benefits the selection among augmented proposals. Experiments on multi-target visual grounding benchmarks show that VGent achieves a new state-of-the-art with +20.6% F1 improvement over prior methods, and further boosts gIoU by +8.2% and cIoU by +5.8% under visual reference challenges, while maintaining constant, fast inference latency.

</details>


### [14] [Information-driven Fusion of Pathology Foundation Models for Enhanced Disease Characterization](https://arxiv.org/abs/2512.11104)
*Brennan Flannery,Thomas DeSilvio,Jane Nguyen,Satish E. Viswanath*

Main category: cs.CV

TL;DR: 本文提出一种基于信息驱动的智能融合策略，整合多种病理基础模型（FMs）的嵌入表示，在肾癌、前列腺癌和直肠癌的分级与分期任务中显著提升性能，并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管多种病理基础模型在预训练目标上相似，但其嵌入空间的互补性、冗余性及生物可解释性仍缺乏系统理解。

Method: 采用相关性引导的冗余特征剪枝策略，对tile级和slide级多个病理基础模型（如Conch、Virchow2、TITAN等）进行智能融合，并与多数投票集成和朴素特征拼接对比；在患者分层交叉验证下评估癌症分级/分期性能，并分析嵌入空间对齐性与注意力图。

Result: 智能融合在三种癌症任务中均一致优于单个最佳FM和朴素融合；嵌入空间呈现高全局相似性但低局部邻域一致性，表明模型间存在细粒度互补信息；注意力图显示融合后更聚焦于肿瘤区域、减少对良性区域的虚假关注。

Conclusion: 相关性引导的智能融合能生成紧凑、任务定制化的表征，在提升预测性能的同时增强模型可解释性，为计算病理学下游任务提供新范式。

Abstract: Foundation models (FMs) have demonstrated strong performance across diverse pathology tasks. While there are similarities in the pre-training objectives of FMs, there is still limited understanding of their complementarity, redundancy in embedding spaces, or biological interpretation of features. In this study, we propose an information-driven, intelligent fusion strategy for integrating multiple pathology FMs into a unified representation and systematically evaluate its performance for cancer grading and staging across three distinct diseases. Diagnostic H&E whole-slide images from kidney (519 slides), prostate (490 slides), and rectal (200 slides) cancers were dichotomized into low versus high grade or stage. Both tile-level FMs (Conch v1.5, MUSK, Virchow2, H-Optimus1, Prov-Gigapath) and slide-level FMs (TITAN, CHIEF, MADELEINE) were considered to train downstream classifiers. We then evaluated three FM fusion schemes at both tile and slide levels: majority-vote ensembling, naive feature concatenation, and intelligent fusion based on correlation-guided pruning of redundant features. Under patient-stratified cross-validation with hold-out testing, intelligent fusion of tile-level embeddings yielded consistent gains in classification performance across all three cancers compared with the best single FMs and naive fusion. Global similarity metrics revealed substantial alignment of FM embedding spaces, contrasted by lower local neighborhood agreement, indicating complementary fine-grained information across FMs. Attention maps showed that intelligent fusion yielded concentrated attention on tumor regions while reducing spurious focus on benign regions. Our findings suggest that intelligent, correlation-guided fusion of pathology FMs can yield compact, task-tailored representations that enhance both predictive performance and interpretability in downstream computational pathology tasks.

</details>


### [15] [Learning from a Generative Oracle: Domain Adaptation for Restoration](https://arxiv.org/abs/2512.11121)
*Yuyang Hu,Mojtaba Sahraee-Ardakan,Arpit Bansal,Kangfu Mei,Christian Qi,Peyman Milanfar,Mauricio Delbracio*

Main category: cs.CV

TL;DR: LEGO是一种无需配对数据的三阶段后训练域自适应框架，通过生成式Oracle提供伪真值，将无监督问题转化为伪监督问题，从而提升预训练图像恢复模型在真实世界退化场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 预训练图像恢复模型在面对真实世界、分布外的退化时性能下降，主要由于域差距大，且分布外数据缺乏真值标签，传统自适应方法常需复杂架构修改。

Method: 提出LEGO框架：第一阶段用预训练模型获得初始恢复结果；第二阶段利用冻结的大规模生成式Oracle（如扩散模型）生成高质量伪真值；第三阶段采用混合监督策略（结合原始有标签数据和新生成的伪配对数据）微调模型。

Result: 在多个真实世界基准上显著提升性能，有效弥合域差距，且不损害原始模型鲁棒性，也无需修改网络结构。

Conclusion: LEGO为无配对数据下的图像恢复域自适应提供了简单、通用且高效的新范式，验证了生成式模型作为‘Oracle’在伪监督学习中的关键作用。

Abstract: Pre-trained image restoration models often fail on real-world, out-of-distribution degradations due to significant domain gaps. Adapting to these unseen domains is challenging, as out-of-distribution data lacks ground truth, and traditional adaptation methods often require complex architectural changes. We propose LEGO (Learning from a Generative Oracle), a practical three-stage framework for post-training domain adaptation without paired data. LEGO converts this unsupervised challenge into a tractable pseudo-supervised one. First, we obtain initial restorations from the pre-trained model. Second, we leverage a frozen, large-scale generative oracle to refine these estimates into high-quality pseudo-ground-truths. Third, we fine-tune the original model using a mixed-supervision strategy combining in-distribution data with these new pseudo-pairs. This approach adapts the model to the new distribution without sacrificing its original robustness or requiring architectural modifications. Experiments demonstrate that LEGO effectively bridges the domain gap, significantly improving performance on diverse real-world benchmarks.

</details>


### [16] [Fast-FoundationStereo: Real-Time Zero-Shot Stereo Matching](https://arxiv.org/abs/2512.11130)
*Bowen Wen,Shaurya Dewan,Stan Birchfield*

Main category: cs.CV

TL;DR: 本文提出Fast-FoundationStereo，首次在实时帧率下实现强零样本泛化能力，通过知识蒸馏、块级神经架构搜索和结构化剪枝三大加速策略，在显著提速的同时保持接近FoundationStereo的零样本精度。


<details>
  <summary>Details</summary>
Motivation: 现有立体视觉基础模型泛化能力强但计算开销大，难以实时应用；而高效模型虽快却鲁棒性差、需昂贵域适配。本文旨在弥合这一效率与泛化能力之间的鸿沟。

Method: 采用分治式加速策略：(1) 知识蒸馏压缩混合骨干网络；(2) 块级神经架构搜索自动设计低延迟代价滤波器；(3) 结构化剪枝优化迭代精化模块；并构建含140万野外立体图像对的自动伪标签数据集辅助训练。

Result: 模型运行速度超FoundationStereo 10倍以上，零样本精度几乎持平，成为当前实时立体匹配方法的新SOTA。

Conclusion: Fast-FoundationStereo成功实现了高效性与零样本泛化能力的统一，为部署于边缘设备的通用立体视觉系统提供了可行方案。

Abstract: Stereo foundation models achieve strong zero-shot generalization but remain computationally prohibitive for real-time applications. Efficient stereo architectures, on the other hand, sacrifice robustness for speed and require costly per-domain fine-tuning. To bridge this gap, we present Fast-FoundationStereo, a family of architectures that achieve, for the first time, strong zero-shot generalization at real-time frame rate. We employ a divide-and-conquer acceleration strategy with three components: (1) knowledge distillation to compress the hybrid backbone into a single efficient student; (2) blockwise neural architecture search for automatically discovering optimal cost filtering designs under latency budgets, reducing search complexity exponentially; and (3) structured pruning for eliminating redundancy in the iterative refinement module. Furthermore, we introduce an automatic pseudo-labeling pipeline used to curate 1.4M in-the-wild stereo pairs to supplement synthetic training data and facilitate knowledge distillation. The resulting model can run over 10x faster than FoundationStereo while closely matching its zero-shot accuracy, thus establishing a new state-of-the-art among real-time methods. Project page: https://nvlabs.github.io/Fast-FoundationStereo/

</details>


### [17] [Learning complete and explainable visual representations from itemized text supervision](https://arxiv.org/abs/2512.11141)
*Yiwei Lyu,Chenhui Zhao,Soumyanil Banerjee,Shixuan Liu,Akshay Rao,Akhil Kondepudi,Honglak Lee,Todd C. Hollon*

Main category: cs.CV

TL;DR: 本文提出ItemizedCLIP框架，利用分项文本标注（多个独立语义的文本描述同一图像）训练视觉模型，在医学影像和遥感等非物体中心领域显著提升零样本性能与细粒度可解释性。


<details>
  <summary>Details</summary>
Motivation: 标准多字幕监督中字幕冗余或高度重叠，而医学影像、遥感等非物体中心领域常存在语义独立、互不重叠的分项文本标注，现有方法难以有效建模此类监督信号。

Method: 提出ItemizedCLIP框架，引入跨注意力模块生成文本项条件下的视觉嵌入，并设计联合优化目标，分别强制‘项独立性’（不同文本项对应图像不同区域）和‘表征完备性’（覆盖所有文本项）。

Result: 在脑MRI、头颅CT、胸部CT、遥感四个真实分项标注数据集及一个合成数据集上，ItemizedCLIP在零样本分类性能和细粒度可解释性上均显著优于基线方法。

Conclusion: ItemizedCLIP能学习到语义 grounded、项可区分、完备且视觉可解释的视觉表征，为非物体中心视觉领域提供了更适配语言监督的学习范式。

Abstract: Training vision models with language supervision enables general and transferable representations. However, many visual domains, especially non-object-centric domains such as medical imaging and remote sensing, contain itemized text annotations: multiple text items describing distinct and semantically independent findings within a single image. Such supervision differs from standard multi-caption supervision, where captions are redundant or highly overlapping. Here, we introduce ItemizedCLIP, a framework for learning complete and explainable visual representations from itemized text supervision. ItemizedCLIP employs a cross-attention module to produce text item-conditioned visual embeddings and a set of tailored objectives that jointly enforce item independence (distinct regions for distinct items) and representation completeness (coverage of all items). Across four domains with naturally itemized text supervision (brain MRI, head CT, chest CT, remote sensing) and one additional synthetically itemized dataset, ItemizedCLIP achieves substantial improvements in zero-shot performance and fine-grained interpretability over baselines. The resulting ItemizedCLIP representations are semantically grounded, item-differentiable, complete, and visually interpretable. Our code is available at https://github.com/MLNeurosurg/ItemizedCLIP.

</details>


### [18] [Image Tiling for High-Resolution Reasoning: Balancing Local Detail with Global Context](https://arxiv.org/abs/2512.11167)
*Anatole Jacquin de Margerie,Alexis Roger,Irina Rish*

Main category: cs.CV

TL;DR: 本文详细复现并批判性分析了Monkey视觉语言模型（VLM），验证了图像分块策略对恢复局部细节的有效性，并进一步探究了全局上下文的影响，发现结果偏差程度依赖于任务类型和分块粒度。


<details>
  <summary>Details</summary>
Motivation: 解决复杂多模态模型缺乏透明实现细节和可访问训练基础设施的问题，提升科学可复现性。

Method: 基于开源检查点复现Monkey VLM，重新实现其训练流程，并系统评估图像分块策略及引入全局上下文的效果。

Result: 确认分块策略能有效恢复局部细节；发现全局上下文的引入带来实际建模启示；但复现结果存在偏差，偏差幅度随任务类型和分块粒度而变化。

Conclusion: 图像分块是高分辨率视觉理解的有效策略，但需谨慎设计粒度与上下文融合方式；复现研究揭示了原方法的鲁棒性边界与改进方向。

Abstract: Reproducibility remains a cornerstone of scientific progress, yet complex multimodal models often lack transparent implementation details and accessible training infrastructure. In this work, we present a detailed reproduction and critical analysis of the Monkey Vision-Language Model (VLM) (Li et al. 2023b) published in CVPR24, a recent approach to high-resolution image understanding via image tiling. The original paper proposed splitting large images into tiles to recover fine-grained visual details while maintaining computational efficiency. Our study replicates this strategy using open checkpoints and reimplements the training pipeline. We confirm the key finding of the original Monkey VLM work, namely that tiling effectively recovers local details. We then extend this work further, by investigating the effect of the inclusion of the global context, which provide practical insights for future high-resolution multimodal modeling. However, we also report deviations in the results, with the magnitude of these effects depending heavily on task type and tile granularity.

</details>


### [19] [Lightweight 3D Gaussian Splatting Compression via Video Codec](https://arxiv.org/abs/2512.11186)
*Qi Yang,Geert Van Der Auwera,Zhu Li*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级3D高斯泼溅（GS）视频压缩方法LGSCV，通过两阶段Morton扫描生成适合视频编码器的分块2D映射，并结合球谐函数（SH）的PCA降维与轻量级MiniPLAS排序，在中低码率下显著提升率失真性能，同时大幅降低2D映射生成和编码时间。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频编码的GS压缩方法依赖计算昂贵的PLAS排序生成2D映射，难以部署于轻量设备。

Method: 提出两阶段Morton扫描（3D预排序+2D分块映射）生成CU友好的2D地图；引入SH的PCA降维；设计快速灵活的MiniPLAS在局部块内重排序；并利用MiniPLAS指导编码器CU尺寸配置。

Result: 在MPEG数据集上相比SOTA方法获得超20%率失真增益，2D映射生成时间降至约1秒，编码时间减少50%。

Conclusion: LGSCV在保持高质量重建的同时显著提升效率，为GS在资源受限设备上的实时视频压缩应用提供了可行方案。

Abstract: Current video-based GS compression methods rely on using Parallel Linear Assignment Sorting (PLAS) to convert 3D GS into smooth 2D maps, which are computationally expensive and time-consuming, limiting the application of GS on lightweight devices. In this paper, we propose a Lightweight 3D Gaussian Splatting (GS) Compression method based on Video codec (LGSCV). First, a two-stage Morton scan is proposed to generate blockwise 2D maps that are friendly for canonical video codecs in which the coding units (CU) are square blocks. A 3D Morton scan is used to permute GS primitives, followed by a 2D Morton scan to map the ordered GS primitives to 2D maps in a blockwise style. However, although the blockwise 2D maps report close performance to the PLAS map in high-bitrate regions, they show a quality collapse at medium-to-low bitrates. Therefore, a principal component analysis (PCA) is used to reduce the dimensionality of spherical harmonics (SH), and a MiniPLAS, which is flexible and fast, is designed to permute the primitives within certain block sizes. Incorporating SH PCA and MiniPLAS leads to a significant gain in rate-distortion (RD) performance, especially at medium and low bitrates. MiniPLAS can also guide the setting of the codec CU size configuration and significantly reduce encoding time. Experimental results on the MPEG dataset demonstrate that the proposed LGSCV achieves over 20% RD gain compared with state-of-the-art methods, while reducing 2D map generation time to approximately 1 second and cutting encoding time by 50%. The code is available at https://github.com/Qi-Yangsjtu/LGSCV .

</details>


### [20] [Multi-task Learning with Extended Temporal Shift Module for Temporal Action Localization](https://arxiv.org/abs/2512.11189)
*Anh-Kiet Duong,Petra Gomez-Krämer*

Main category: cs.CV

TL;DR: 本文提出了一种基于TSM的多任务学习方法，结合场景分类与时间动作定位，并通过加权集成提升性能，在BinEgo-360挑战赛中获得双轮第一。


<details>
  <summary>Details</summary>
Motivation: 解决BinEgo-360挑战赛中多视角、多模态视频下的时间动作定位（TAL）问题，利用全景、第三人称和第一人称视频数据进行细粒度动作识别。

Method: 基于Temporal Shift Module（TSM）扩展，引入背景类并对固定长度非重叠时间区间进行分类；采用多任务学习框架联合优化场景分类与TAL；最后通过加权集成多个模型提升预测鲁棒性与一致性。

Result: 在BinEgo-360挑战赛初始轮和扩展轮均排名第一。

Conclusion: 结合多任务学习、高效骨干网络与集成学习的方法在多视角、多模态TAL任务中具有显著有效性与优越性。

Abstract: We present our solution to the BinEgo-360 Challenge at ICCV 2025, which focuses on temporal action localization (TAL) in multi-perspective and multi-modal video settings. The challenge provides a dataset containing panoramic, third-person, and egocentric recordings, annotated with fine-grained action classes. Our approach is built on the Temporal Shift Module (TSM), which we extend to handle TAL by introducing a background class and classifying fixed-length non-overlapping intervals. We employ a multi-task learning framework that jointly optimizes for scene classification and TAL, leveraging contextual cues between actions and environments. Finally, we integrate multiple models through a weighted ensemble strategy, which improves robustness and consistency of predictions. Our method is ranked first in both the initial and extended rounds of the competition, demonstrating the effectiveness of combining multi-task learning, an efficient backbone, and ensemble learning for TAL.

</details>


### [21] [CADKnitter: Compositional CAD Generation from Text and Geometry Guidance](https://arxiv.org/abs/2512.11199)
*Tri Le,Khang Nguyen,Baoru Huang,Tung D. Ta,Anh Nguyen*

Main category: cs.CV

TL;DR: 本文提出CADKnitter，一种基于几何引导扩散采样的组合式CAD生成框架，可依据给定CAD模型和文本提示生成符合几何与语义约束的互补部件，并构建了包含31万样本的KnitCAD数据集。


<details>
  <summary>Details</summary>
Motivation: 现有单部件CAD生成方法难以满足真实场景中多部件装配所需的语义与几何约束，亟需支持可编辑、可组合的CAD生成方法。

Method: 提出CADKnitter框架，采用几何引导的扩散采样策略，结合文本提示与输入CAD模型生成互补部件；构建KnitCAD数据集，含310,000+带文本提示和装配元数据的CAD样本。

Result: 在多项实验中显著优于现有最先进方法。

Conclusion: CADKnitter实现了兼顾几何一致性与语义对齐的多部件CAD生成，推动了面向实际工程应用的可控3D CAD内容生成发展。

Abstract: Crafting computer-aided design (CAD) models has long been a painstaking and time-intensive task, demanding both precision and expertise from designers. With the emergence of 3D generation, this task has undergone a transformative impact, shifting not only from visual fidelity to functional utility but also enabling editable CAD designs. Prior works have achieved early success in single-part CAD generation, which is not well-suited for real-world applications, as multiple parts need to be assembled under semantic and geometric constraints. In this paper, we propose CADKnitter, a compositional CAD generation framework with a geometry-guided diffusion sampling strategy. CADKnitter is able to generate a complementary CAD part that follows both the geometric constraints of the given CAD model and the semantic constraints of the desired design text prompt. We also curate a dataset, so-called KnitCAD, containing over 310,000 samples of CAD models, along with textual prompts and assembly metadata that provide semantic and geometric constraints. Intensive experiments demonstrate that our proposed method outperforms other state-of-the-art baselines by a clear margin.

</details>


### [22] [AutoRefiner: Improving Autoregressive Video Diffusion Models via Reflective Refinement Over the Stochastic Sampling Path](https://arxiv.org/abs/2512.11203)
*Zhengyang Yu,Akio Hayakawa,Masato Ishii,Qingtao Yu,Takashi Shibuya,Jing Zhang,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 本文提出AutoRefiner，一种专为自回归视频扩散模型（AR-VDMs）设计的前馈噪声精炼器，通过路径式噪声精炼和反射式KV缓存提升样本保真度，无需参数更新且计算高效。


<details>
  <summary>Details</summary>
Motivation: AR-VDMs在实时交互应用中潜力大，但样本保真度仍有待提升；现有推理时对齐方法（如优化/搜索）计算开销大，而直接迁移文本到图像（T2I）中的噪声精炼器效果不佳。

Method: 提出AutoRefiner，包含两个核心设计：1）路径式噪声精炼——沿随机去噪路径动态调整噪声；2）反射式KV缓存——适配AR-VDM的自回归特性以复用历史状态。

Result: 实验表明AutoRefiner作为轻量插件可显著提升AR-VDM样本保真度，且仅需单次前向传播，计算高效。

Conclusion: AutoRefiner为AR-VDM提供了实用、高效的推理时噪声精炼方案，验证了针对特定生成范式定制化精炼器的必要性与有效性。

Abstract: Autoregressive video diffusion models (AR-VDMs) show strong promise as scalable alternatives to bidirectional VDMs, enabling real-time and interactive applications. Yet there remains room for improvement in their sample fidelity. A promising solution is inference-time alignment, which optimizes the noise space to improve sample fidelity without updating model parameters. Yet, optimization- or search-based methods are computationally impractical for AR-VDMs. Recent text-to-image (T2I) works address this via feedforward noise refiners that modulate sampled noises in a single forward pass. Can such noise refiners be extended to AR-VDMs? We identify the failure of naively extending T2I noise refiners to AR-VDMs and propose AutoRefiner-a noise refiner tailored for AR-VDMs, with two key designs: pathwise noise refinement and a reflective KV-cache. Experiments demonstrate that AutoRefiner serves as an efficient plug-in for AR-VDMs, effectively enhancing sample fidelity by refining noise along stochastic denoising paths.

</details>


### [23] [SmokeBench: Evaluating Multimodal Large Language Models for Wildfire Smoke Detection](https://arxiv.org/abs/2512.11215)
*Tianye Qi,Weihao Li,Nick Barnes*

Main category: cs.CV

TL;DR: 本文提出了一个名为SmokeBench的基准测试，用于评估多模态大语言模型（MLLMs）在图像中识别与定位野火烟雾的能力；实验表明现有模型虽能在烟雾大面积覆盖时分类成功，但在早期、小面积烟雾的精确定位上普遍表现不佳，且性能主要受烟雾体积影响。


<details>
  <summary>Details</summary>
Motivation: 野火烟雾具有透明、无定形、易与云混淆等特性，导致早期检测困难；当前缺乏专门评估MLLMs在烟雾识别与定位能力的基准，亟需系统性评测以推动安全关键场景下的 wildfire 监测技术发展。

Method: 构建了包含四类任务（烟雾分类、基于图像块的定位、基于网格的定位、烟雾检测）的SmokeBench基准；在多个主流MLLMs（如Idefics2、Qwen2.5-VL、GPT-4o等）上进行统一评测，并分析烟雾体积与对比度对性能的影响。

Result: 所有模型在烟雾大面积覆盖时可较好完成分类任务，但在定位任务（尤其早期小面积烟雾）上性能显著下降；烟雾体积与模型性能强相关，而对比度影响较小。

Conclusion: 当前MLLMs在野火烟雾早期定位方面存在关键缺陷，SmokeBench揭示了其局限性，为后续研究提供了可复现的评测平台和明确改进方向——提升小体积、低可见度烟雾的精准定位能力。

Abstract: Wildfire smoke is transparent, amorphous, and often visually confounded with clouds, making early-stage detection particularly challenging. In this work, we introduce a benchmark, called SmokeBench, to evaluate the ability of multimodal large language models (MLLMs) to recognize and localize wildfire smoke in images. The benchmark consists of four tasks: (1) smoke classification, (2) tile-based smoke localization, (3) grid-based smoke localization, and (4) smoke detection. We evaluate several MLLMs, including Idefics2, Qwen2.5-VL, InternVL3, Unified-IO 2, Grounding DINO, GPT-4o, and Gemini-2.5 Pro. Our results show that while some models can classify the presence of smoke when it covers a large area, all models struggle with accurate localization, especially in the early stages. Further analysis reveals that smoke volume is strongly correlated with model performance, whereas contrast plays a comparatively minor role. These findings highlight critical limitations of current MLLMs for safety-critical wildfire monitoring and underscore the need for methods that improve early-stage smoke localization.

</details>


### [24] [VFMF: World Modeling by Forecasting Vision Foundation Model Features](https://arxiv.org/abs/2512.11225)
*Gabrijel Boduljak,Yushi Lan,Christian Rupprecht,Andrea Vedaldi*

Main category: cs.CV

TL;DR: 本文提出了一种在视觉基础模型（VFM）特征空间中进行自回归流匹配的生成式预测器，以克服现有确定性回归方法无法建模未来不确定性的问题，并通过更有效的紧凑潜在空间编码提升多模态预测精度。


<details>
  <summary>Details</summary>
Motivation: 像素级视频预测计算开销大且难以直接用于决策；而基于VFM特征的确定性回归虽高效、可解释，却因平均多个可能未来而忽略不确定性，损害预测准确性。

Method: 在VFM特征空间中构建生成式预测器，采用自回归流匹配；关键在于将VFM特征编码为信息保持更优的紧凑潜在空间（优于PCA），并支持多模态解码（如语义分割、深度、法向量、RGB）。

Result: 在相同架构与算力下，该方法在所有输出模态上均比确定性回归产生更清晰、更准确的预测；潜在表征在预测及其他任务（如图像生成）中均优于PCA基线。

Conclusion: 在VFM特征空间中进行随机条件生成是一种有前景且可扩展的世界建模新范式。

Abstract: Forecasting from partial observations is central to world modeling. Many recent methods represent the world through images, and reduce forecasting to stochastic video generation. Although such methods excel at realism and visual fidelity, predicting pixels is computationally intensive and not directly useful in many applications, as it requires translating RGB into signals useful for decision making. An alternative approach uses features from vision foundation models (VFMs) as world representations, performing deterministic regression to predict future world states. These features can be directly translated into actionable signals such as semantic segmentation and depth, while remaining computationally efficient. However, deterministic regression averages over multiple plausible futures, undermining forecast accuracy by failing to capture uncertainty. To address this crucial limitation, we introduce a generative forecaster that performs autoregressive flow matching in VFM feature space. Our key insight is that generative modeling in this space requires encoding VFM features into a compact latent space suitable for diffusion. We show that this latent space preserves information more effectively than previously used PCA-based alternatives, both for forecasting and other applications, such as image generation. Our latent predictions can be easily decoded into multiple useful and interpretable output modalities: semantic segmentation, depth, surface normals, and even RGB. With matched architecture and compute, our method produces sharper and more accurate predictions than regression across all modalities. Our results suggest that stochastic conditional generation of VFM features offers a promising and scalable foundation for future world models.

</details>


### [25] [FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model](https://arxiv.org/abs/2512.11226)
*Hongbin Lin,Yiming Yang,Yifan Zhang,Chaoda Zheng,Jie Feng,Sheng Wang,Zhennan Wang,Shijia Chen,Boyang Wang,Yu Zhang,Xianming Liu,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: 本文提出FutureX，一种基于思维链（CoT）的端到端自动驾驶规划框架，通过引入潜空间世界模型与自动思维开关，在复杂动态场景中进行未来场景推理与轨迹优化，提升规划合理性与安全性，同时保持高效。


<details>
  <summary>Details</summary>
Motivation: 现有端到端规划器仅依赖当前场景感知，难以应对高度动态交通中自车行为反作用于未来场景的复杂因果演化问题。

Method: 提出FutureX框架：包含Auto-think Switch判断是否需推理；在Thinking模式下，Latent World Model执行CoT引导的未来潜表示 rollout；Summarizer Module据此细化轨迹；Instant模式则直接前向生成简单场景下的规划。

Result: 在NAVSIM等基准上显著提升性能，如TransFuser的PDMS提升6.2，碰撞更少、规划更合理，且未牺牲推理效率。

Conclusion: FutureX验证了在端到端规划中引入可解释、可控的潜空间未来推理机制（尤其是CoT驱动的世界模型）的有效性，为动态环境下的安全自主决策提供了新范式。

Abstract: In autonomous driving, end-to-end planners learn scene representations from raw sensor data and utilize them to generate a motion plan or control actions. However, exclusive reliance on the current scene for motion planning may result in suboptimal responses in highly dynamic traffic environments where ego actions further alter the future scene. To model the evolution of future scenes, we leverage the World Model to represent how the ego vehicle and its environment interact and change over time, which entails complex reasoning. The Chain of Thought (CoT) offers a promising solution by forecasting a sequence of future thoughts that subsequently guide trajectory refinement. In this paper, we propose FutureX, a CoT-driven pipeline that enhances end-to-end planners to perform complex motion planning via future scene latent reasoning and trajectory refinement. Specifically, the Auto-think Switch examines the current scene and decides whether additional reasoning is required to yield a higher-quality motion plan. Once FutureX enters the Thinking mode, the Latent World Model conducts a CoT-guided rollout to predict future scene representation, enabling the Summarizer Module to further refine the motion plan. Otherwise, FutureX operates in an Instant mode to generate motion plans in a forward pass for relatively simple scenes. Extensive experiments demonstrate that FutureX enhances existing methods by producing more rational motion plans and fewer collisions without compromising efficiency, thereby achieving substantial overall performance gains, e.g., 6.2 PDMS improvement for TransFuser on NAVSIM. Code will be released.

</details>


### [26] [REST: Diffusion-based Real-time End-to-end Streaming Talking Head Generation via ID-Context Caching and Asynchronous Streaming Distillation](https://arxiv.org/abs/2512.11229)
*Haotian Wang,Yuzhe Weng,Xinyi Yu,Jun Du,Haoran Xu,Xiaoyan Wu,Shan He,Bing Yin,Cong Liu,Qingfeng Liu*

Main category: cs.CV

TL;DR: 本文提出REST，首个基于扩散模型的实时端到端流式音频驱动说话人头生成框架，通过紧凑视频潜在空间、ID-Context Cache机制和异步流式蒸馏（ASD）策略，实现高效、一致、身份保真的实时生成。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在说话人头生成中存在推理速度慢、非自回归等限制，难以满足实时应用需求。

Method: 提出REST框架：1）学习高时空压缩的紧凑视频潜在空间；2）引入ID-Context Cache机制（融合ID-Sink与Context-Cache）实现自回归流式生成中的身份与时间一致性；3）设计异步流式蒸馏（ASD）训练策略，利用非流式教师模型与异步噪声调度监督流式学生模型训练。

Result: REST在生成速度与整体性能上均超越当前最先进方法，支持实时端到端流式生成，并保持良好的时间一致性与身份连贯性。

Conclusion: REST成功融合扩散模型与自回归流式建模优势，为实时 talking head 应用提供了高效、鲁棒的新范式。

Abstract: Diffusion models have significantly advanced the field of talking head generation. However, the slow inference speeds and non-autoregressive paradigms severely constrain the application of diffusion-based THG models. In this study, we propose REST, the first diffusion-based, real-time, end-to-end streaming audio-driven talking head generation framework. To support real-time end-to-end generation, a compact video latent space is first learned through high spatiotemporal VAE compression. Additionally, to enable autoregressive streaming within the compact video latent space, we introduce an ID-Context Cache mechanism, which integrates ID-Sink and Context-Cache principles to key-value caching for maintaining temporal consistency and identity coherence during long-time streaming generation. Furthermore, an Asynchronous Streaming Distillation (ASD) training strategy is proposed to mitigate error accumulation in autoregressive generation and enhance temporal consistency, which leverages a non-streaming teacher with an asynchronous noise schedule to supervise the training of the streaming student model. REST bridges the gap between autoregressive and diffusion-based approaches, demonstrating substantial value for applications requiring real-time talking head generation. Experimental results demonstrate that REST outperforms state-of-the-art methods in both generation speed and overall performance.

</details>


### [27] [RoomPilot: Controllable Synthesis of Interactive Indoor Environments via Multimodal Semantic Parsing](https://arxiv.org/abs/2512.11234)
*Wentang Chen,Shougao Zhang,Yiman Zhang,Tianhao Zhou,Ruihui Li*

Main category: cs.CV

TL;DR: 本文提出了RoomPilot框架，通过设计一种室内领域特定语言（IDSL）统一解析文本描述或CAD平面图等多模态输入，实现可控、交互式室内场景生成，显著提升了物理一致性与视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在输入模态范围窄或依赖随机过程导致可控性差，难以满足游戏开发、建筑可视化和具身AI训练等应用对可控、交互式室内场景生成的需求。

Method: 提出RoomPilot统一框架，将多模态输入（文本或CAD平面图）解析为室内领域特定语言（IDSL），并利用交互标注资产数据集合成具有真实物体行为的环境。

Result: 实验验证了RoomPilot具备强多模态理解能力、细粒度可控性、更优的物理一致性和视觉保真度。

Conclusion: RoomPilot为通用、可控的3D室内场景生成提供了重要进展，支持高可控性与真实交互语义。

Abstract: Generating controllable and interactive indoor scenes is fundamental to applications in game development, architectural visualization, and embodied AI training. Yet existing approaches either handle a narrow range of input modalities or rely on stochastic processes that hinder controllability. To overcome these limitations, we introduce RoomPilot, a unified framework that parses diverse multi-modal inputs--textual descriptions or CAD floor plans--into an Indoor Domain-Specific Language (IDSL) for indoor structured scene generation. The key insight is that a well-designed IDSL can act as a shared semantic representation, enabling coherent, high-quality scene synthesis from any single modality while maintaining interaction semantics. In contrast to conventional procedural methods that produce visually plausible but functionally inert layouts, RoomPilot leverages a curated dataset of interaction-annotated assets to synthesize environments exhibiting realistic object behaviors. Extensive experiments further validate its strong multi-modal understanding, fine-grained controllability in scene generation, and superior physical consistency and visual fidelity, marking a significant step toward general-purpose controllable 3D indoor scene generation.

</details>


### [28] [Cross-modal Prompting for Balanced Incomplete Multi-modal Emotion Recognition](https://arxiv.org/abs/2512.11239)
*Wen-Jue He,Xiaofeng Zhu,Zheng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种跨模态提示（ComP）方法，用于解决不完整多模态情感识别中的模态性能差距和缺失数据问题，通过渐进式提示生成、跨模态知识传播与动态模态输出重加权提升识别精度。


<details>
  <summary>Details</summary>
Motivation: 多模态数据虽信息丰富，但模态间性能差距、模态欠优化及缺失数据问题严重制约了不完整多模态情感识别（IMER）效果。

Method: 提出跨模态提示（ComP）方法：1）含动态梯度调制器的渐进式提示生成模块，生成简洁一致的模态语义提示；2）跨模态知识传播机制，利用提示选择性增强模态特征中一致信息；3）动态协调器对各模态输出进行重加权以平衡融合。

Result: 在4个数据集、7种SOTA方法、多种缺失率设定下实验验证，ComP显著提升不完整多模态情感识别准确率。

Conclusion: ComP通过协同增强模态特异性特征与一致性语义，有效缓解模态不平衡与数据缺失带来的挑战，为IMER提供了鲁棒且可扩展的新范式。

Abstract: Incomplete multi-modal emotion recognition (IMER) aims at understanding human intentions and sentiments by comprehensively exploring the partially observed multi-source data. Although the multi-modal data is expected to provide more abundant information, the performance gap and modality under-optimization problem hinder effective multi-modal learning in practice, and are exacerbated in the confrontation of the missing data. To address this issue, we devise a novel Cross-modal Prompting (ComP) method, which emphasizes coherent information by enhancing modality-specific features and improves the overall recognition accuracy by boosting each modality's performance. Specifically, a progressive prompt generation module with a dynamic gradient modulator is proposed to produce concise and consistent modality semantic cues. Meanwhile, cross-modal knowledge propagation selectively amplifies the consistent information in modality features with the delivered prompts to enhance the discrimination of the modality-specific output. Additionally, a coordinator is designed to dynamically re-weight the modality outputs as a complement to the balance strategy to improve the model's efficacy. Extensive experiments on 4 datasets with 7 SOTA methods under different missing rates validate the effectiveness of our proposed method.

</details>


### [29] [PersonaLive! Expressive Portrait Image Animation for Live Streaming](https://arxiv.org/abs/2512.11253)
*Zhiyuan Li,Chi-Man Pun,Chen Fang,Jue Wang,Xiaodong Cun*

Main category: cs.CV

TL;DR: PersonaLive是一种面向实时流式肖像动画的新型扩散模型框架，通过多阶段训练策略显著提升推理速度和生成稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的肖像动画模型注重视觉质量和表情真实感，但忽视生成延迟和实时性能，难以应用于直播等实时场景。

Method: 提出三阶段方法：1）采用混合隐式信号（隐式人脸表征与3D隐式关键点）实现图像级运动控制；2）设计少步长外观蒸馏策略以减少去噪冗余；3）引入带滑动训练与历史关键帧机制的自回归微块流式生成范式。

Result: 实验表明PersonaLive在保持高质量的同时，比先前扩散模型快7–22倍，实现低延迟、稳定的长时视频生成。

Conclusion: PersonaLive有效平衡了生成质量与实时性，为直播等实际应用场景提供了可行的扩散模型解决方案。

Abstract: Current diffusion-based portrait animation models predominantly focus on enhancing visual quality and expression realism, while overlooking generation latency and real-time performance, which restricts their application range in the live streaming scenario. We propose PersonaLive, a novel diffusion-based framework towards streaming real-time portrait animation with multi-stage training recipes. Specifically, we first adopt hybrid implicit signals, namely implicit facial representations and 3D implicit keypoints, to achieve expressive image-level motion control. Then, a fewer-step appearance distillation strategy is proposed to eliminate appearance redundancy in the denoising process, greatly improving inference efficiency. Finally, we introduce an autoregressive micro-chunk streaming generation paradigm equipped with a sliding training strategy and a historical keyframe mechanism to enable low-latency and stable long-term video generation. Extensive experiments demonstrate that PersonaLive achieves state-of-the-art performance with up to 7-22x speedup over prior diffusion-based portrait animation models.

</details>


### [30] [Do We Need Reformer for Vision? An Experimental Comparison with Vision Transformers](https://arxiv.org/abs/2512.11260)
*Ali El Bellaj,Mohammed-Amine Cheddadi,Rhassan Berber*

Main category: cs.CV

TL;DR: 本文探索了使用Reformer架构作为视觉骨干网络的可行性，通过局部敏感哈希（LSH）注意力机制降低Transformer的计算复杂度，但在实际高分辨率图像任务中，ViT仍比Reformer更高效。


<details>
  <summary>Details</summary>
Motivation: 标准Vision Transformer（ViT）因全局自注意力机制导致计算开销大，难以适用于高分辨率图像和资源受限场景，因此需要更高效的替代架构。

Method: 采用Reformer架构，结合基于图像块的tokenization与局部敏感哈希（LSH）注意力，将自注意力的时间复杂度从O(n²)降至O(n log n)。

Result: 在CIFAR-10上Reformer精度略高于ViT基线；但在ImageNet-100和高分辨率医学影像数据集上，ViT在实际效率和端到端计算时间上均显著优于Reformer。

Conclusion: 尽管LSH注意力在理论上具备计算优势，但在典型高分辨率图像产生的token长度下，其实际加速效果有限；ViT目前仍是更实用的视觉骨干选择。

Abstract: Transformers have recently demonstrated strong performance in computer vision, with Vision Transformers (ViTs) leveraging self-attention to capture both low-level and high-level image features. However, standard ViTs remain computationally expensive, since global self-attention scales quadratically with the number of tokens, which limits their practicality for high-resolution inputs and resource-constrained settings.
  In this work, we investigate the Reformer architecture as an alternative vision backbone. By combining patch-based tokenization with locality-sensitive hashing (LSH) attention, our model approximates global self-attention while reducing its theoretical time complexity from $\mathcal{O}(n^2)$ to $\mathcal{O}(n \log n)$ in the sequence length $n$. We evaluate the proposed Reformer-based vision model on CIFAR-10 to assess its behavior on small-scale datasets, on ImageNet-100 to study its accuracy--efficiency trade-off in a more realistic setting, and on a high-resolution medical imaging dataset to evaluate the model under longer token sequences.
  While the Reformer achieves higher accuracy on CIFAR-10 compared to our ViT-style baseline, the ViT model consistently outperforms the Reformer in our experiments in terms of practical efficiency and end-to-end computation time across the larger and higher-resolution settings. These results suggest that, despite the theoretical advantages of LSH-based attention, meaningful computation gains require sequence lengths substantially longer than those produced by typical high-resolution images.

</details>


### [31] [Evaluating the Efficacy of Sentinel-2 versus Aerial Imagery in Serrated Tussock Classification](https://arxiv.org/abs/2512.11267)
*Rezwana Sultana,Manzur Murshed,Kathryn Sheffield,Singarayer Florentine,Tsz-Kwan Lee,Shyh Wei Teng*

Main category: cs.CV

TL;DR: 本研究评估了多时相Sentinel-2卫星影像在维多利亚州大规模监测锯齿针茅（一种入侵草种）的可行性，发现其结合光谱与物候信息的模型性能略优于高分辨率航拍影像模型，具备成本效益和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统地面调查难以实现大范围监测，航拍影像虽精度高但成本昂贵，亟需一种低成本、可扩展的遥感替代方案。

Method: 利用多时相Sentinel-2影像，构建11种包含光谱波段、纹理特征、植被指数和季节信息的模型，采用随机森林分类器进行锯齿针茅识别，并与航拍影像模型对比。

Result: 最佳Sentinel-2模型（M76*）总体精度达68%，Kappa系数0.55，略优于最佳航拍模型（OA 67%，Kappa 0.52）。

Conclusion: 多季节增强的卫星遥感模型可在保持可接受精度的同时显著提升监测规模与成本效益，适用于入侵物种的大范围动态监测。

Abstract: Invasive species pose major global threats to ecosystems and agriculture. Serrated tussock (\textit{Nassella trichotoma}) is a highly competitive invasive grass species that disrupts native grasslands, reduces pasture productivity, and increases land management costs. In Victoria, Australia, it presents a major challenge due to its aggressive spread and ecological impact. While current ground surveys and subsequent management practices are effective at small scales, they are not feasible for landscape-scale monitoring. Although aerial imagery offers high spatial resolution suitable for detailed classification, its high cost limits scalability. Satellite-based remote sensing provides a more cost-effective and scalable alternative, though often with lower spatial resolution. This study evaluates whether multi-temporal Sentinel-2 imagery, despite its lower spatial resolution, can provide a comparable and cost-effective alternative for landscape-scale monitoring of serrated tussock by leveraging its higher spectral resolution and seasonal phenological information. A total of eleven models have been developed using various combinations of spectral bands, texture features, vegetation indices, and seasonal data. Using a random forest classifier, the best-performing Sentinel-2 model (M76*) has achieved an Overall Accuracy (OA) of 68\% and an Overall Kappa (OK) of 0.55, slightly outperforming the best-performing aerial imaging model's OA of 67\% and OK of 0.52 on the same dataset. These findings highlight the potential of multi-seasonal feature-enhanced satellite-based models for scalable invasive species classification.

</details>


### [32] [FilmWeaver: Weaving Consistent Multi-Shot Videos with Cache-Guided Autoregressive Diffusion](https://arxiv.org/abs/2512.11274)
*Xiangyang Luo,Qingyu Li,Xiaokun Liu,Wenyu Qin,Miao Yang,Meng Wang,Pengfei Wan,Di Zhang,Kun Gai,Shao-Lun Huang*

Main category: cs.CV

TL;DR: 本文提出了FilmWeaver框架，通过自回归扩散模型与双层缓存机制（镜头记忆与时间记忆）解决多镜头视频生成中角色、背景一致性及任意长度生成难题，并支持多轮用户交互与下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在单镜头合成上表现良好，但在多镜头视频生成中难以维持角色和背景跨镜头的一致性，且缺乏对任意长度和镜头数量的灵活生成能力。

Method: 提出FilmWeaver框架：采用自回归扩散范式实现任意长度视频生成；设计双层缓存机制——镜头记忆（缓存前序关键帧以保持身份一致性）与时间记忆（缓存当前镜头帧历史以保障运动连贯性）；构建高质量多镜头视频数据集用于训练；支持多轮交互式多镜头创作及多概念注入、视频扩展等下游任务。

Result: 实验表明，FilmWeaver在一致性和美学质量指标上均超越现有方法，显著提升多镜头视频的可控性、叙事性与一致性。

Conclusion: FilmWeaver为多镜头、长时序、高一致性视频生成提供了新范式，推动了可控、叙事驱动的视频内容生成发展。

Abstract: Current video generation models perform well at single-shot synthesis but struggle with multi-shot videos, facing critical challenges in maintaining character and background consistency across shots and flexibly generating videos of arbitrary length and shot count. To address these limitations, we introduce \textbf{FilmWeaver}, a novel framework designed to generate consistent, multi-shot videos of arbitrary length. First, it employs an autoregressive diffusion paradigm to achieve arbitrary-length video generation. To address the challenge of consistency, our key insight is to decouple the problem into inter-shot consistency and intra-shot coherence. We achieve this through a dual-level cache mechanism: a shot memory caches keyframes from preceding shots to maintain character and scene identity, while a temporal memory retains a history of frames from the current shot to ensure smooth, continuous motion. The proposed framework allows for flexible, multi-round user interaction to create multi-shot videos. Furthermore, due to this decoupled design, our method demonstrates high versatility by supporting downstream tasks such as multi-concept injection and video extension. To facilitate the training of our consistency-aware method, we also developed a comprehensive pipeline to construct a high-quality multi-shot video dataset. Extensive experimental results demonstrate that our method surpasses existing approaches on metrics for both consistency and aesthetic quality, opening up new possibilities for creating more consistent, controllable, and narrative-driven video content. Project Page: https://filmweaver.github.io

</details>


### [33] [RcAE: Recursive Reconstruction Framework for Unsupervised Industrial Anomaly Detection](https://arxiv.org/abs/2512.11284)
*Rongcheng Wu,Hao Zhu,Shiying Zhang,Mingzhe Wang,Zhidong Li,Hui Li,Jianlong Zhou,Jiangtao Cui,Fang Chen,Pingyang Sun,Qiyu Liao,Ye Lin*

Main category: cs.CV

TL;DR: 本文提出了一种递归自编码器（RcAE）架构，通过多步迭代重建逐步抑制异常并细化正常结构，并引入跨递归检测（CRD）模块和细节保持网络（DPN）提升异常检测精度与纹理恢复能力，在性能媲美扩散模型的同时大幅降低参数量和推理耗时。


<details>
  <summary>Details</summary>
Motivation: 无监督工业异常检测面临无标注数据下准确识别缺陷的挑战，传统单次解码的自编码器方法难以兼顾不同严重程度和尺度的异常抑制，且易丢失细节信息。

Method: 提出递归自编码器（RcAE），实现多次迭代重建；设计跨递归检测（CRD）模块捕捉各步重建间的不一致性；引入细节保持网络（DPN）恢复高频纹理。

Result: 在多个基准上显著优于现有非扩散类方法，性能媲美最新扩散模型，但仅需其10%参数量，且推理速度大幅提升。

Conclusion: RcAE架构及其配套模块在保持高检测精度的同时极大提升了效率与实用性，为真实工业场景提供了高效可行的无监督异常检测方案。

Abstract: Unsupervised industrial anomaly detection requires accurately identifying defects without labeled data. Traditional autoencoder-based methods often struggle with incomplete anomaly suppression and loss of fine details, as their single-pass decoding fails to effectively handle anomalies with varying severity and scale. We propose a recursive architecture for autoencoder (RcAE), which performs reconstruction iteratively to progressively suppress anomalies while refining normal structures. Unlike traditional single-pass models, this recursive design naturally produces a sequence of reconstructions, progressively exposing suppressed abnormal patterns. To leverage this reconstruction dynamics, we introduce a Cross Recursion Detection (CRD) module that tracks inconsistencies across recursion steps, enhancing detection of both subtle and large-scale anomalies. Additionally, we incorporate a Detail Preservation Network (DPN) to recover high-frequency textures typically lost during reconstruction. Extensive experiments demonstrate that our method significantly outperforms existing non-diffusion methods, and achieves performance on par with recent diffusion models with only 10% of their parameters and offering substantially faster inference. These results highlight the practicality and efficiency of our approach for real-world applications.

</details>


### [34] [Autoregressive Video Autoencoder with Decoupled Temporal and Spatial Context](https://arxiv.org/abs/2512.11293)
*Cuifeng Shen,Lumin Xu,Xingguo Zhu,Gengdai Liu*

Main category: cs.CV

TL;DR: 本文提出了一种自回归视频自动编码器（ARVAE），通过解耦时空表示（光流表征时间一致性，空间补偿处理新内容）实现高效无损压缩，并支持任意长度视频的逐帧条件重建。


<details>
  <summary>Details</summary>
Motivation: 现有视频自动编码器常将空间与时间信息纠缠，难以保证时间一致性，导致重建质量与效率受限。

Method: 提出ARVAE：采用自回归帧重建机制；设计时空解耦隐表示（光流场+空间相对补偿）；编码器分离提取时序运动与空间补充信息，解码器基于前一帧和隐变量重建当前帧；采用多阶段训练策略。

Result: 在极轻量模型和小规模训练数据下，ARVAE实现了更优的视频重建质量；在视频生成下游任务中展现出强泛化潜力。

Conclusion: ARVAE通过时空解耦与自回归建模，有效提升了视频自动编码的压缩效率、重建质量与时序一致性，为高效视频生成提供了新范式。

Abstract: Video autoencoders compress videos into compact latent representations for efficient reconstruction, playing a vital role in enhancing the quality and efficiency of video generation. However, existing video autoencoders often entangle spatial and temporal information, limiting their ability to capture temporal consistency and leading to suboptimal performance. To address this, we propose Autoregressive Video Autoencoder (ARVAE), which compresses and reconstructs each frame conditioned on its predecessor in an autoregressive manner, allowing flexible processing of videos with arbitrary lengths. ARVAE introduces a temporal-spatial decoupled representation that combines downsampled flow field for temporal coherence with spatial relative compensation for newly emerged content, achieving high compression efficiency without information loss. Specifically, the encoder compresses the current and previous frames into the temporal motion and spatial supplement, while the decoder reconstructs the original frame from the latent representations given the preceding frame. A multi-stage training strategy is employed to progressively optimize the model. Extensive experiments demonstrate that ARVAE achieves superior reconstruction quality with extremely lightweight models and small-scale training data. Moreover, evaluations on video generation tasks highlight its strong potential for downstream applications.

</details>


### [35] [Few-Shot VLM-Based G-Code and HMI Verification in CNC Machining](https://arxiv.org/abs/2512.11296)
*Yasaman Hashem Pour,Nazanin Mahjourian,Vinh Nguyen*

Main category: cs.CV

TL;DR: 本文提出一种基于视觉语言模型（VLM）的少样本G-code与HMI联合验证方法，用于提升CNC教学中手动编写G-code的安全性与正确性检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的G-code验证方法无法利用HMI界面图像信息，而HMI在CNC操作中对状态监控和错误诊断至关重要；需融合文本（G-code）与视觉（HMI截图）模态进行综合验证。

Method: 构建包含G-code文本与对应HMI截图（来自15-slant-PRO车床）的配对数据集；设计基于先验启发式知识的结构化JSON schema，并采用少样本提示策略，将带标签的G-code-HMI样本作为示例输入VLM；对比零样本VLM在多类错误场景下的每槽位准确率。

Result: 少样本VLM显著提升了HMI错误识别及G-code与HMI间不一致性的检测能力，优于零样本设置；验证了该框架在CNC教学场景下手动G-code调试中的有效性。

Conclusion: 融合视觉与文本模态的少样本VLM方法可有效弥补传统LLM在CNC人机交互验证中的短板，适用于面向教育的G-code安全验证任务。

Abstract: Manual generation of G-code is important for learning the operation of CNC machines. Prior work in G-code verification uses Large-Language Models (LLMs), which primarily examine errors in the written programming. However, CNC machining requires extensive use and knowledge of the Human-Machine Interface (HMI), which displays machine status and errors. LLMs currently lack the capability to leverage knowledge of HMIs due to their inability to access the vision modality. This paper proposes a few-shot VLM-based verification approach that simultaneously evaluates the G-code and the HMI display for errors and safety status. The input dataset includes paired G-code text and associated HMI screenshots from a 15-slant-PRO lathe, including both correct and error-prone cases. To enable few-shot learning, the VLM is provided with a structured JSON schema based on prior heuristic knowledge. After determining the prompts, instances of G-code and HMI that either contain errors or are error free are used as few-shot examples to guide the VLM. The model was then evaluated in comparison to a zero-shot VLM through multiple scenarios of incorrect G-code and HMI errors with respect to per-slot accuracy. The VLM showed that few-shot prompting led to overall enhancement of detecting HMI errors and discrepancies with the G-code for more comprehensive debugging. Therefore, the proposed framework was demonstrated to be suitable for verification of manually generated G-code that is typically developed in CNC training.

</details>


### [36] [MultiEgo: A Multi-View Egocentric Video Dataset for 4D Scene Reconstruction](https://arxiv.org/abs/2512.11301)
*Bate Li,Houqiang Zhong,Zhengxue Cheng,Qiang Hu,Qiang Wang,Li Song,Wenjun Zhang*

Main category: cs.CV

TL;DR: 本文提出了首个用于4D动态场景重建的多视角自我中心（MultiEgo）数据集，包含5个典型社交互动场景的5路同步AR眼镜视频，并配套高精度姿态标注与处理流程，验证了其在自由视点视频（FVV）任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有重建数据集主要面向静态多视角或单自我中心视角，缺乏支持动态场景的多视角自我中心数据集，限制了该方向的研究进展。

Method: 构建了MultiEgo数据集，涵盖5种社交场景，每场景含5路由AR眼镜采集的自我中心视频；设计基于硬件的时间同步系统（亚毫秒级）和数据处理流程，并提供精确的位姿标注。

Result: 实验验证表明该数据集在自由视点视频（FVV）应用中具备实用性和有效性，成为多视角自我中心动态场景重建研究的基础资源。

Conclusion: MultiEgo填补了多视角自我中心动态场景重建数据集的空白，为相关研究提供了关键支撑。

Abstract: Multi-view egocentric dynamic scene reconstruction holds significant research value for applications in holographic documentation of social interactions. However, existing reconstruction datasets focus on static multi-view or single-egocentric view setups, lacking multi-view egocentric datasets for dynamic scene reconstruction. Therefore, we present MultiEgo, the first multi-view egocentric dataset for 4D dynamic scene reconstruction. The dataset comprises five canonical social interaction scenes: meetings, performances, and a presentation. Each scene provides five authentic egocentric videos captured by participants wearing AR glasses. We design a hardware-based data acquisition system and processing pipeline, achieving sub-millisecond temporal synchronization across views, coupled with accurate pose annotations. Experiment validation demonstrates the practical utility and effectiveness of our dataset for free-viewpoint video (FVV) applications, establishing MultiEgo as a foundational resource for advancing multi-view egocentric dynamic scene reconstruction research.

</details>


### [37] [SATMapTR: Satellite Image Enhanced Online HD Map Construction](https://arxiv.org/abs/2512.11319)
*Bingyuan Huang,Guanyi Zhao,Qian Xu,Yang Lou,Yung-Hui Li,Jianping Wang*

Main category: cs.CV

TL;DR: 本文提出SATMapTR模型，通过门控特征优化模块和几何感知融合模块，有效融合卫星图像与车载传感器数据，提升高精地图实时构建的精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有实时高精地图构建受限于车载传感器能力不足和频繁遮挡导致的低质量输入；卫星图像虽能提供广域稳定视角，但其鸟瞰图易受植被和建筑阴影遮挡，且已有特征融合方法效果不佳。

Method: 提出SATMapTR模型，包含（1）门控特征优化模块：结合高层语义与底层结构线索自适应过滤卫星特征；（2）几何感知融合模块：在网格级对齐并融合卫星与BEV特征，抑制无关区域和低质量输入干扰。

Result: 在nuScenes数据集上mAP达73.8，较最优卫星增强方法提升14.2；恶劣天气与传感器失效下mAP下降更少；扩展感知范围下mAP提升近3倍。

Conclusion: SATMapTR显著提升了多源异构数据（尤其是退化卫星图像）融合建图的准确性、鲁棒性与长距感知能力，为实时HD地图构建提供了新范式。

Abstract: High-definition (HD) maps are evolving from pre-annotated to real-time construction to better support autonomous driving in diverse scenarios. However, this process is hindered by low-quality input data caused by onboard sensors limited capability and frequent occlusions, leading to incomplete, noisy, or missing data, and thus reduced mapping accuracy and robustness. Recent efforts have introduced satellite images as auxiliary input, offering a stable, wide-area view to complement the limited ego perspective. However, satellite images in Bird's Eye View are often degraded by shadows and occlusions from vegetation and buildings. Prior methods using basic feature extraction and fusion remain ineffective. To address these challenges, we propose SATMapTR, a novel online map construction model that effectively fuses satellite image through two key components: (1) a gated feature refinement module that adaptively filters satellite image features by integrating high-level semantics with low-level structural cues to extract high signal-to-noise ratio map-relevant representations; and (2) a geometry-aware fusion module that consistently fuse satellite and BEV features at a grid-to-grid level, minimizing interference from irrelevant regions and low-quality inputs. Experimental results on the nuScenes dataset show that SATMapTR achieves the highest mean average precision (mAP) of 73.8, outperforming state-of-the-art satellite-enhanced models by up to 14.2 mAP. It also shows lower mAP degradation under adverse weather and sensor failures, and achieves nearly 3 times higher mAP at extended perception ranges.

</details>


### [38] [KeyframeFace: From Text to Expressive Facial Keyframes](https://arxiv.org/abs/2512.11321)
*Jingchao Wu,Zejian Kang,Haibo Liu,Yuanchen Fei,Xiangru Huang*

Main category: cs.CV

TL;DR: 本文提出了KeyframeFace数据集和首个利用大语言模型（LLM）先验进行可解释面部动画合成的文本到动画框架，旨在解决现有方法在语义对齐与时间结构建模上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到面部动画方法缺乏语义基础和时间结构，难以生成富有表现力的人类表演；且缺少支持细粒度、关键帧级监督的大规模多模态数据集。

Method: 构建了包含2100条表达性脚本、单目视频、逐帧ARKit系数、背景、复杂情绪及人工标注关键帧的KeyframeFace数据集，并结合LLM/MLLM进行多视角标注；提出首个显式融合LLM语义理解能力与ARKit系数可解释结构的文本到动画框架。

Result: 实现了高保真、可解释、关键帧引导且上下文感知的动态3D面部动画生成，在语义对齐与时间建模上显著优于现有方法。

Conclusion: KeyframeFace数据集与所提LLM驱动框架共同为可解释、关键帧引导、上下文感知的文本到面部动画研究奠定了新基础。

Abstract: Generating dynamic 3D facial animation from natural language requires understanding both temporally structured semantics and fine-grained expression changes. Existing datasets and methods mainly focus on speech-driven animation or unstructured expression sequences and therefore lack the semantic grounding and temporal structures needed for expressive human performance generation. In this work, we introduce KeyframeFace, a large-scale multimodal dataset designed for text-to-animation research through keyframe-level supervision. KeyframeFace provides 2,100 expressive scripts paired with monocular videos, per-frame ARKit coefficients, contextual backgrounds, complex emotions, manually defined keyframes, and multi-perspective annotations based on ARKit coefficients and images via Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs). Beyond the dataset, we propose the first text-to-animation framework that explicitly leverages LLM priors for interpretable facial motion synthesis. This design aligns the semantic understanding capabilities of LLMs with the interpretable structure of ARKit's coefficients, enabling high-fidelity expressive animation. KeyframeFace and our LLM-based framework together establish a new foundation for interpretable, keyframe-guided, and context-aware text-to-animation. Code and data are available at https://github.com/wjc12345123/KeyframeFace.

</details>


### [39] [MLLM Machine Unlearning via Visual Knowledge Distillation](https://arxiv.org/abs/2512.11325)
*Yuhang Wang,Zhenxing Niu,Haoxuan Ji,Guangyu He,Haichang Gao,Gang Hua*

Main category: cs.CV

TL;DR: 本文提出了一种面向多模态大语言模型（MLLM）的视觉知识蒸馏（VKD）解耦式机器遗忘方法，通过中间层视觉表征监督，选择性擦除目标视觉知识，同时保留文本知识，兼顾有效性、实用性和高效性，并首次评估了对重学习攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法主要面向LLM，而面向MLLM的遗忘研究尚处早期；且多数方法依赖输出级监督，难以兼顾遗忘效果与模型实用性。

Method: 提出视觉知识蒸馏（VKD）方案，解耦MLLM中的视觉与文本知识，仅微调视觉组件，利用中间层视觉表征作为监督信号进行选择性视觉知识擦除。

Result: 在有效性与效率上均优于现有SOTA遗忘方法，并首次验证了MLLM遗忘对重学习攻击的鲁棒性。

Conclusion: VKD是一种高效、有效且鲁棒的MLLM专用遗忘方法，为多模态模型隐私保护提供了新思路。

Abstract: Recently, machine unlearning approaches have been proposed to remove sensitive information from well-trained large models. However, most existing methods are tailored for LLMs, while MLLM-oriented unlearning remains at its early stage. Inspired by recent studies exploring the internal mechanisms of MLLMs, we propose to disentangle the visual and textual knowledge embedded within MLLMs and introduce a dedicated approach to selectively erase target visual knowledge while preserving textual knowledge. Unlike previous unlearning methods that rely on output-level supervision, our approach introduces a Visual Knowledge Distillation (VKD) scheme, which leverages intermediate visual representations within the MLLM as supervision signals. This design substantially enhances both unlearning effectiveness and model utility. Moreover, since our method only fine-tunes the visual components of the MLLM, it offers significant efficiency advantages. Extensive experiments demonstrate that our approach outperforms state-of-the-art unlearning methods in terms of both effectiveness and efficiency. Moreover, we are the first to evaluate the robustness of MLLM unlearning against relearning attacks.

</details>


### [40] [HFS: Holistic Query-Aware Frame Selection for Efficient Video Reasoning](https://arxiv.org/abs/2512.11534)
*Yiqing Yang,Kin-Man Lam*

Main category: cs.CV

TL;DR: 本文提出了一种端到端可训练、任务自适应的视频关键帧选择框架，通过链式思维引导小语言模型生成任务相关隐式查询向量，并结合连续集合级目标函数与Gumbel-Softmax实现可微帧组合优化，辅以师生互学习机制对齐帧重要性分布，摆脱静态伪标签依赖，在多个视频理解基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统top-K帧选择方法独立打分导致时序聚集和视觉冗余；离线由MLLM生成的伪标签无法动态适配下游任务目标。

Method: 采用Chain-of-Thought引导SLM生成任务特定隐式查询向量，融合多模态特征实现动态帧评分；设计兼顾相关性、覆盖度与冗余度的连续集合级目标函数，结合Gumbel-Softmax实现可微集合级优化；引入学生（SLM）-教师（MLLM）互学习，通过KL散度对齐帧重要性分布，并联合交叉熵损失进行端到端训练。

Result: 在Video-MME、LongVideoBench、MLVU、NExT-QA等多个视频理解基准上显著超越现有方法。

Conclusion: 所提框架有效解决了关键帧选择中独立评分导致的冗余问题和伪标签静态化问题，实现了任务驱动、端到端可训练的高质量帧集合选择。

Abstract: Key frame selection in video understanding presents significant challenges. Traditional top-K selection methods, which score frames independently, often fail to optimize the selection as a whole. This independent scoring frequently results in selecting frames that are temporally clustered and visually redundant. Additionally, training lightweight selectors using pseudo labels generated offline by Multimodal Large Language Models (MLLMs) prevents the supervisory signal from dynamically adapting to task objectives. To address these limitations, we propose an end-to-end trainable, task-adaptive framework for frame selection. A Chain-of-Thought approach guides a Small Language Model (SLM) to generate task-specific implicit query vectors, which are combined with multimodal features to enable dynamic frame scoring. We further define a continuous set-level objective function that incorporates relevance, coverage, and redundancy, enabling differentiable optimization via Gumbel-Softmax to select optimal frame combinations at the set level. Finally, student-teacher mutual learning is employed, where the student selector (SLM) and teacher reasoner (MLLM) are trained to align their frame importance distributions via KL divergence. Combined with cross-entropy loss, this enables end-to-end optimization, eliminating reliance on static pseudo labels. Experiments across various benchmarks, including Video-MME, LongVideoBench, MLVU, and NExT-QA, demonstrate that our method significantly outperforms existing approaches.

</details>


### [41] [Physics-Informed Video Flare Synthesis and Removal Leveraging Motion Independence between Flare and Scene](https://arxiv.org/abs/2512.11327)
*Junqiao Wang,Yuanfei Huang,Hua Huang*

Main category: cs.CV

TL;DR: 本文提出了一种物理驱动的动态镜头光晕合成与去除方法，通过光学流模拟光源运动、Mamba建模时空依赖，无需多帧对齐，显著缓解闪烁与伪影，并构建首个视频光晕数据集验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中于图像光晕去除，而视频光晕因光源、散射/反射光晕与场景内容之间复杂的、相互独立的运动，带来更大挑战，易导致闪烁和伪影。

Method: 提出物理信息驱动的动态光晕合成流程（基于光学流模拟光源运动，建模散射与反射光晕时序行为）；设计视频光晕去除网络，含空间注意力模块抑制光晕区域，以及基于Mamba的时序建模组件捕获长程时空依赖；构建首个视频光晕数据集（含合成配对视频与真实网络视频）。

Result: 在合成与真实视频上均优于现有视频修复及图像光晕去除方法，能有效去除动态光晕、保持光源完整性、维持场景时空一致性，并缓解闪烁与时间混叠问题。

Conclusion: 运动无关的时空表征可避免多帧对齐，提升视频光晕去除性能；所提合成方法、网络架构与数据集为该领域提供了新基准与实用工具。

Abstract: Lens flare is a degradation phenomenon caused by strong light sources. Existing researches on flare removal have mainly focused on images, while the spatiotemporal characteristics of video flare remain largely unexplored. Video flare synthesis and removal pose significantly greater challenges than in image, owing to the complex and mutually independent motion of flare, light sources, and scene content. This motion independence further affects restoration performance, often resulting in flicker and artifacts. To address this issue, we propose a physics-informed dynamic flare synthesis pipeline, which simulates light source motion using optical flow and models the temporal behaviors of both scattering and reflective flares. Meanwhile, we design a video flare removal network that employs an attention module to spatially suppress flare regions and incorporates a Mamba-based temporal modeling component to capture long range spatio-temporal dependencies. This motion-independent spatiotemporal representation effectively eliminates the need for multi-frame alignment, alleviating temporal aliasing between flares and scene content and thereby improving video flare removal performance. Building upon this, we construct the first video flare dataset to comprehensively evaluate our method, which includes a large set of synthetic paired videos and additional real-world videos collected from the Internet to assess generalization capability. Extensive experiments demonstrate that our method consistently outperforms existing video-based restoration and image-based flare removal methods on both real and synthetic videos, effectively removing dynamic flares while preserving light source integrity and maintaining spatiotemporal consistency of scene.

</details>


### [42] [DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry](https://arxiv.org/abs/2512.11558)
*Zhenyang Cai,Jiaming Zhang,Junjie Zhao,Ziyi Zeng,Yanchao Li,Jingyi Liang,Junying Chen,Yunjin Yang,Jiajun You,Shuzhi Deng,Tongfei Wang,Wanting Chen,Chunxiu Hao,Ruiqi Xie,Zhenwei Wen,Xiangyi Feng,Zou Ting,Jin Zou Lin,Jianquan Li,Guangjun Yu,Liangyi Chen,Junwen Wang,Shan Jiang,Benyou Wang*

Main category: cs.CV

TL;DR: 本文提出了DentalGPT，一种专用于牙科的多模态大语言模型，通过构建迄今最大的牙科多模态数据集（12万+配对图像与诊断性描述）并结合领域知识注入与强化学习，显著提升了细粒度牙科视觉理解与多模态推理能力，在多项牙科VQA和疾病分类任务中超越诸多SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有牙科多模态大语言模型难以捕捉精细牙科视觉细节，且缺乏精准诊断所需的充分推理能力。

Method: 构建迄今最大牙科多模态数据集（120k+图像-描述对），注入高质量领域知识，并采用强化学习提升多模态复杂推理能力。

Result: DentalGPT在牙科内窥镜、全景片及医学VQA牙科子集等基准上均取得优于众多SOTA MLLM的性能，且参数量仅7B。

Conclusion: 高质量牙科数据与分阶段适配策略是构建高性能、领域专用牙科多模态大语言模型的有效路径。

Abstract: Reliable interpretation of multimodal data in dentistry is essential for automated oral healthcare, yet current multimodal large language models (MLLMs) struggle to capture fine-grained dental visual details and lack sufficient reasoning ability for precise diagnosis. To address these limitations, we present DentalGPT, a specialized dental MLLM developed through high-quality domain knowledge injection and reinforcement learning. Specifically, the largest annotated multimodal dataset for dentistry to date was constructed by aggregating over 120k dental images paired with detailed descriptions that highlight diagnostically relevant visual features, making it the multimodal dataset with the most extensive collection of dental images to date. Training on this dataset significantly enhances the MLLM's visual understanding of dental conditions, while the subsequent reinforcement learning stage further strengthens its capability for multimodal complex reasoning. Comprehensive evaluations on intraoral and panoramic benchmarks, along with dental subsets of medical VQA benchmarks, show that DentalGPT achieves superior performance in disease classification and dental VQA tasks, outperforming many state-of-the-art MLLMs despite having only 7B parameters. These results demonstrate that high-quality dental data combined with staged adaptation provides an effective pathway for building capable and domain-specialized dental MLLMs.

</details>


### [43] [FreqDINO: Frequency-Guided Adaptation for Generalized Boundary-Aware Ultrasound Image Segmentation](https://arxiv.org/abs/2512.11335)
*Yixuan Zhang,Qing Xu,Yue Li,Xiangjian He,Qian Zhang,Mainul Haque,Rong Qu,Wenting Duan,Zhen Chen*

Main category: cs.CV

TL;DR: 本文提出FreqDINO，一种频率引导的超声图像分割框架，通过多尺度频率提取对齐、频率引导边界细化和多任务边界引导解码器，提升边界感知与结构一致性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: DINOv3虽在医学图像分割中表现优异，但其基于自然图像预训练，对超声图像特有的边界退化不敏感。

Method: 提出FreqDINO框架，包含：1）多尺度频率提取与对齐（MFEA）策略，分离并对其低频结构与多尺度高频边界细节；2）频率引导边界细化（FGBR）模块，从高频成分提取边界原型并优化空间特征；3）多任务边界引导解码器（MBGD），保障边界与语义预测的空间一致性。

Result: 在多个超声图像数据集上实验表明，FreqDINO显著超越当前最优方法，具备卓越泛化能力。

Conclusion: FreqDINO通过引入频率域建模有效缓解超声图像分割中的边界模糊与结构失真问题，为基于自监督预训练模型的医学图像分割提供了新思路。

Abstract: Ultrasound image segmentation is pivotal for clinical diagnosis, yet challenged by speckle noise and imaging artifacts. Recently, DINOv3 has shown remarkable promise in medical image segmentation with its powerful representation capabilities. However, DINOv3, pre-trained on natural images, lacks sensitivity to ultrasound-specific boundary degradation. To address this limitation, we propose FreqDINO, a frequency-guided segmentation framework that enhances boundary perception and structural consistency. Specifically, we devise a Multi-scale Frequency Extraction and Alignment (MFEA) strategy to separate low-frequency structures and multi-scale high-frequency boundary details, and align them via learnable attention. We also introduce a Frequency-Guided Boundary Refinement (FGBR) module that extracts boundary prototypes from high-frequency components and refines spatial features. Furthermore, we design a Multi-task Boundary-Guided Decoder (MBGD) to ensure spatial coherence between boundary and semantic predictions. Extensive experiments demonstrate that FreqDINO surpasses state-of-the-art methods with superior achieves remarkable generalization capability. The code is at https://github.com/MingLang-FD/FreqDINO.

</details>


### [44] [UFVideo: Towards Unified Fine-Grained Video Cooperative Understanding with Large Language Models](https://arxiv.org/abs/2512.11336)
*Hewen Pan,Cong Wei,Dashuang Liang,Zepeng Huang,Pengfei Gao,Ziqi Zhou,Lulu Xue,Pengfei Yan,Xiaoming Wei,Minghui Li,Shengshan Hu*

Main category: cs.CV

TL;DR: 本文提出了UFVideo，首个具备统一多粒度协同理解能力的视频大语言模型，通过统一的视觉-语言引导对齐机制，实现全局、像素级和时间尺度上的灵活视频理解，并构建了UFVideo-Bench评测基准，在多个任务上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型局限于特定视频理解任务，缺乏全面、多粒度的视频感知能力，亟需一种能统一处理不同粒度视频理解任务的模型。

Method: 提出UFVideo模型，设计统一视觉-语言引导对齐机制，支持跨全局、像素和时间尺度的视频理解；支持多种输出形式（文本响应、时间定位、接地掩码）；构建UFVideo-Bench评测基准，包含三个多粒度协同任务。

Result: UFVideo在UFVideo-Bench上展现出优于GPT-4o的灵活性与性能，并在9个公开视频理解基准上验证了有效性。

Conclusion: UFVideo首次实现了统一多粒度协同视频理解，为未来视频大语言模型的设计与评测提供了新范式和重要参考。

Abstract: With the advancement of multi-modal Large Language Models (LLMs), Video LLMs have been further developed to perform on holistic and specialized video understanding. However, existing works are limited to specialized video understanding tasks, failing to achieve a comprehensive and multi-grained video perception. To bridge this gap, we introduce UFVideo, the first Video LLM with unified multi-grained cooperative understanding capabilities. Specifically, we design unified visual-language guided alignment to flexibly handle video understanding across global, pixel and temporal scales within a single model. UFVideo dynamically encodes the visual and text inputs of different tasks and generates the textual response, temporal localization, or grounded mask. Additionally, to evaluate challenging multi-grained video understanding tasks, we construct the UFVideo-Bench consisting of three distinct collaborative tasks within the scales, which demonstrates UFVideo's flexibility and advantages over GPT-4o. Furthermore, we validate the effectiveness of our model across 9 public benchmarks covering various common video understanding tasks, providing valuable insights for future Video LLMs.

</details>


### [45] [Task-Specific Distance Correlation Matching for Few-Shot Action Recognition](https://arxiv.org/abs/2512.11340)
*Fei Long,Yao Zhang,Jiaming Lv,Jiangtao Xie,Peihua Li*

Main category: cs.CV

TL;DR: 本文提出TS-FSAR框架，通过视觉阶梯侧网络（LSN）、任务特定距离相关性匹配（TS-DCM）和引导式LSN与适配CLIP模块（GLAC），解决少样本动作识别中非线性建模不足和CLIP高效微调困难的问题，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本动作识别方法存在两个关键局限：一是传统集合匹配度量仅依赖余弦相似度，难以捕捉帧间非线性关系和任务特异性线索；二是基于侧层（skip-fusion）的CLIP高效微调策略在小样本下难以优化。

Method: 提出TS-FSAR框架，包含三部分：(1) 视觉Ladder Side Network（LSN）实现高效CLIP微调；(2) 任务特定距离相关性匹配（TS-DCM），利用α-距离相关性建模线性和非线性帧间依赖，并引入任务原型实现任务感知匹配；(3) Guiding LSN with Adapted CLIP（GLAC）模块，用冻结但已适配的CLIP监督LSN训练，提升小样本下α-距离相关性估计质量。

Result: 在五个主流基准上实验表明，TS-FSAR显著优于现有最先进方法。

Conclusion: TS-FSAR通过联合改进匹配度量与模型适应机制，有效提升了少样本动作识别的性能与鲁棒性，为小样本视频理解提供了新思路。

Abstract: Few-shot action recognition (FSAR) has recently made notable progress through set matching and efficient adaptation of large-scale pre-trained models. However, two key limitations persist. First, existing set matching metrics typically rely on cosine similarity to measure inter-frame linear dependencies and then perform matching with only instance-level information, thus failing to capture more complex patterns such as nonlinear relationships and overlooking task-specific cues. Second, for efficient adaptation of CLIP to FSAR, recent work performing fine-tuning via skip-fusion layers (which we refer to as side layers) has significantly reduced memory cost. However, the newly introduced side layers are often difficult to optimize under limited data conditions. To address these limitations, we propose TS-FSAR, a framework comprising three components: (1) a visual Ladder Side Network (LSN) for efficient CLIP fine-tuning; (2) a metric called Task-Specific Distance Correlation Matching (TS-DCM), which uses $α$-distance correlation to model both linear and nonlinear inter-frame dependencies and leverages a task prototype to enable task-specific matching; and (3) a Guiding LSN with Adapted CLIP (GLAC) module, which regularizes LSN using the adapted frozen CLIP to improve training for better $α$-distance correlation estimation under limited supervision. Extensive experiments on five widely-used benchmarks demonstrate that our TS-FSAR yields superior performance compared to prior state-of-the-arts.

</details>


### [46] [Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture](https://arxiv.org/abs/2512.11350)
*Tanu Singh,Pranamesh Chakraborty,Long T. Truong*

Main category: cs.CV

TL;DR: 本文提出了一种基于Transformer架构的交通事故检测模型，利用自建的多样化数据集，并融合RGB与光流特征以增强运动信息建模，达到88.3%的准确率，优于现有VLM方法。


<details>
  <summary>Details</summary>
Motivation: 传统计算机视觉方法在交通事故检测中存在时空理解有限和跨域泛化差的问题；现有研究忽视运动线索，且缺乏大规模、多样化的数据集支撑。

Method: 构建了一个涵盖多种交通环境、事故类型和上下文变化的综合平衡数据集；提出一种结合CNN（提取帧内局部相关性）与Transformer（建模时序特征依赖）的模型；系统评估多种运动线索融合方式，最终采用RGB特征与光流特征拼接输入。

Result: RGB+光流融合方案取得最高准确率88.3%；模型性能优于GPT、Gemini和LLaVA-NeXT-Video等视觉语言模型。

Conclusion: 融合显式运动信息（如光流）并基于Transformer建模长程时空依赖，是提升交通事故检测鲁棒性与泛化能力的有效路径；高质量专用数据集对推动该领域发展至关重要。

Abstract: Road traffic accidents represent a leading cause of mortality globally, with incidence rates rising due to increasing population, urbanization, and motorization. Rising accident rates raise concerns about traffic surveillance effectiveness. Traditional computer vision methods for accident detection struggle with limited spatiotemporal understanding and poor cross-domain generalization. Recent advances in transformer architectures excel at modeling global spatial-temporal dependencies and parallel computation. However, applying these models to automated traffic accident detection is limited by small, non-diverse datasets, hindering the development of robust, generalizable systems. To address this gap, we curated a comprehensive and balanced dataset that captures a wide spectrum of traffic environments, accident types, and contextual variations. Utilizing the curated dataset, we propose an accident detection model based on a transformer architecture using pre-extracted spatial video features. The architecture employs convolutional layers to extract local correlations across diverse patterns within a frame, while leveraging transformers to capture sequential-temporal dependencies among the retrieved features. Moreover, most existing studies neglect the integration of motion cues, which are essential for understanding dynamic scenes, especially during accidents. These approaches typically rely on static features or coarse temporal information. In this study, multiple methods for incorporating motion cues were evaluated to identify the most effective strategy. Among the tested input approaches, concatenating RGB features with optical flow achieved the highest accuracy at 88.3%. The results were further compared with vision language models (VLM) such as GPT, Gemini, and LLaVA-NeXT-Video to assess the effectiveness of the proposed method.

</details>


### [47] [A Multi-Mode Structured Light 3D Imaging System with Multi-Source Information Fusion for Underwater Pipeline Detection](https://arxiv.org/abs/2512.11354)
*Qinghan Hu,Haijiang Zhu,Na Sun,Lei Chen,Zhengqiang Fan,Zhiqing Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于多源信息融合的多模态水下结构光3D成像系统（UW-SLD），用于管道腐蚀缺陷检测，结合快速畸变校正、因子图优化标定、ED-ICP配准及自适应扩展卡尔曼滤波，显著提升了水下环境中的三维重建精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 水下管道易受腐蚀，威胁安全与寿命；传统人工检测效率低，亟需高精度、实时、鲁棒的智能成像系统。

Method: 提出UW-SLD系统：1）快速畸变校正（FDC）；2）因子图优化实现结构光与声学传感器外参标定；3）多模态3D成像策略适配管道几何变化；4）多源信息融合+自适应EKF保障稳定位姿估计；5）边缘检测增强的ICP（ED-ICP）算法提升缺陷结构重建鲁棒性与保真度。

Result: 在不同工况（模式、速度、深度）下实验验证，系统具备更高精度、适应性与鲁棒性，支持自主水下管道检测。

Conclusion: 所提UW-SLD系统为水下管道缺陷智能检测提供了可靠、实用且可工程化的新方案，推动了水下结构健康监测的自动化发展。

Abstract: Underwater pipelines are highly susceptible to corrosion, which not only shorten their service life but also pose significant safety risks. Compared with manual inspection, the intelligent real-time imaging system for underwater pipeline detection has become a more reliable and practical solution. Among various underwater imaging techniques, structured light 3D imaging can restore the sufficient spatial detail for precise defect characterization. Therefore, this paper develops a multi-mode underwater structured light 3D imaging system for pipeline detection (UW-SLD system) based on multi-source information fusion. First, a rapid distortion correction (FDC) method is employed for efficient underwater image rectification. To overcome the challenges of extrinsic calibration among underwater sensors, a factor graph-based parameter optimization method is proposed to estimate the transformation matrix between the structured light and acoustic sensors. Furthermore, a multi-mode 3D imaging strategy is introduced to adapt to the geometric variability of underwater pipelines. Given the presence of numerous disturbances in underwater environments, a multi-source information fusion strategy and an adaptive extended Kalman filter (AEKF) are designed to ensure stable pose estimation and high-accuracy measurements. In particular, an edge detection-based ICP (ED-ICP) algorithm is proposed. This algorithm integrates pipeline edge detection network with enhanced point cloud registration to achieve robust and high-fidelity reconstruction of defect structures even under variable motion conditions. Extensive experiments are conducted under different operation modes, velocities, and depths. The results demonstrate that the developed system achieves superior accuracy, adaptability and robustness, providing a solid foundation for autonomous underwater pipeline detection.

</details>


### [48] [Prior-Enhanced Gaussian Splatting for Dynamic Scene Reconstruction from Casual Video](https://arxiv.org/abs/2512.11356)
*Meng-Li Shih,Ying-Huan Chen,Yu-Lun Liu,Brian Curless*

Main category: cs.CV

TL;DR: 本文提出了一种全自动的单目RGB视频动态场景重建流水线，通过增强Dynamic Gaussian Splatting的先验（如对象级掩码、骨架采样、虚拟视图深度损失等），显著提升了深度一致性、几何细节与运动连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有单目动态场景重建方法在处理薄结构、深度一致性及运动建模方面存在不足，需更鲁棒的对象级先验引导。

Method: 结合视频分割与极线误差图生成高精度对象掩码；引入对象深度损失、骨架采样与掩码引导重识别以提升2D轨迹质量；新增虚拟视图深度损失消除浮动物体，并用支架投影损失将运动节点绑定到轨迹上。

Result: 在单目动态场景重建任务中性能超越先前方法，渲染结果视觉质量明显更优。

Conclusion: 通过精细化设计并嵌入多种几何与运动先验，可显著提升单目动态高斯点绘（Dynamic Gaussian Splatting）的重建质量，无需更改基础表示形式。

Abstract: We introduce a fully automatic pipeline for dynamic scene reconstruction from casually captured monocular RGB videos. Rather than designing a new scene representation, we enhance the priors that drive Dynamic Gaussian Splatting. Video segmentation combined with epipolar-error maps yields object-level masks that closely follow thin structures; these masks (i) guide an object-depth loss that sharpens the consistent video depth, and (ii) support skeleton-based sampling plus mask-guided re-identification to produce reliable, comprehensive 2-D tracks. Two additional objectives embed the refined priors in the reconstruction stage: a virtual-view depth loss removes floaters, and a scaffold-projection loss ties motion nodes to the tracks, preserving fine geometry and coherent motion. The resulting system surpasses previous monocular dynamic scene reconstruction methods and delivers visibly superior renderings

</details>


### [49] [Reliable Detection of Minute Targets in High-Resolution Aerial Imagery across Temporal Shifts](https://arxiv.org/abs/2512.11360)
*Mohammad Sadegh Gholizadeh,Amir Arsalan Rezapour,Hamidreza Shayegh,Ehsan Pazouki*

Main category: cs.CV

TL;DR: 本文提出了一种基于迁移学习初始化的Faster R-CNN方法，用于无人机高分辨率影像中水稻秧苗的小目标检测，并构建了专用UAV数据集，在多个时序测试集上验证了模型对成像条件变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高效、准确地利用无人机进行作物检测对精准农业规模化至关重要，但因目标尺寸小、环境多变而面临挑战。

Method: 采用迁移学习初始化的Faster R-CNN架构，并构建了一个大规模无人机水稻秧苗数据集；在三个不同时间采集的测试集上评估模型泛化能力。

Result: 实验证明迁移学习能加快农业场景下目标检测模型收敛，并在图像采集域偏移情况下仍保持稳定性能。

Conclusion: 该方法有效提升了水稻秧苗等小目标在复杂农田环境中的检测精度与鲁棒性，为无人机遥感在精细农情监测中的应用提供了可行方案。

Abstract: Efficient crop detection via Unmanned Aerial Vehicles is critical for scaling precision agriculture, yet it remains challenging due to the small scale of targets and environmental variability. This paper addresses the detection of rice seedlings in paddy fields by leveraging a Faster R-CNN architecture initialized via transfer learning. To overcome the specific difficulties of detecting minute objects in high-resolution aerial imagery, we curate a significant UAV dataset for training and rigorously evaluate the model's generalization capabilities. Specifically, we validate performance across three distinct test sets acquired at different temporal intervals, thereby assessing robustness against varying imaging conditions. Our empirical results demonstrate that transfer learning not only facilitates the rapid convergence of object detection models in agricultural contexts but also yields consistent performance despite domain shifts in image acquisition.

</details>


### [50] [Assisted Refinement Network Based on Channel Information Interaction for Camouflaged and Salient Object Detection](https://arxiv.org/abs/2512.11369)
*Kuan Wang,Yanjun Qin,Mengge Lu,Liejun Wang,Xiaoming Tao*

Main category: cs.CV

TL;DR: 本文提出ARNet-v2模型，通过通道信息交互模块（CIIM）增强同层特征的跨通道交互，并构建基于边界与区域先验的协同解码架构，结合多尺度增强模块（MSE），显著提升伪装目标检测性能，并验证其在多个下游任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有伪装目标检测方法在解码阶段存在两个关键问题：同层特征跨通道信息交互不足，以及边界与区域信息难以协同建模，导致分割结果区域不完整、边界不清晰。

Method: 提出通道信息交互模块（CIIM）实现通道维度的水平-垂直特征重组与交互；构建融合边界提取（BE）和区域提取（RE）模块的协同解码架构，并采用混合注意力机制校准解码特征；引入多尺度增强（MSE）模块丰富上下文表征。

Result: 在四个COD基准数据集上达到SOTA性能；模型迁移至SOD、息肉分割、透明物体检测及工业/道路缺陷检测等下游任务亦表现优异。

Conclusion: ARNet-v2有效解决了COD中跨通道信息利用不足与边界-区域建模脱节的问题，具备强表达力、高精度与良好泛化性，代码与实验结果已开源。

Abstract: Camouflaged Object Detection (COD) stands as a significant challenge in computer vision, dedicated to identifying and segmenting objects visually highly integrated with their backgrounds. Current mainstream methods have made progress in cross-layer feature fusion, but two critical issues persist during the decoding stage. The first is insufficient cross-channel information interaction within the same-layer features, limiting feature expressiveness. The second is the inability to effectively co-model boundary and region information, making it difficult to accurately reconstruct complete regions and sharp boundaries of objects. To address the first issue, we propose the Channel Information Interaction Module (CIIM), which introduces a horizontal-vertical integration mechanism in the channel dimension. This module performs feature reorganization and interaction across channels to effectively capture complementary cross-channel information. To address the second issue, we construct a collaborative decoding architecture guided by prior knowledge. This architecture generates boundary priors and object localization maps through Boundary Extraction (BE) and Region Extraction (RE) modules, then employs hybrid attention to collaboratively calibrate decoded features, effectively overcoming semantic ambiguity and imprecise boundaries. Additionally, the Multi-scale Enhancement (MSE) module enriches contextual feature representations. Extensive experiments on four COD benchmark datasets validate the effectiveness and state-of-the-art performance of the proposed model. We further transferred our model to the Salient Object Detection (SOD) task and demonstrated its adaptability across downstream tasks, including polyp segmentation, transparent object detection, and industrial and road defect detection. Code and experimental results are publicly available at: https://github.com/akuan1234/ARNet-v2.

</details>


### [51] [Out-of-Distribution Segmentation via Wasserstein-Based Evidential Uncertainty](https://arxiv.org/abs/2512.11373)
*Arnold Brosch,Abdelrahman Eldesokey,Michael Felsberg,Kira Maag*

Main category: cs.CV

TL;DR: 本文提出了一种基于Wasserstein损失的证据分割框架，用于提升开放世界场景下对分布外（OOD）物体的识别与分割性能，尤其适用于自动驾驶等安全关键应用。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在语义分割中表现优异，但仅限于预定义类别，在开放世界场景中遇到未知物体时会失效；而识别和分割这些分布外（OOD）物体对自动驾驶等安全关键应用至关重要。

Method: 提出一种基于Wasserstein损失的证据分割框架，该损失能刻画分布距离并尊重概率单纯形几何；结合KL正则化和Dice结构一致性项。

Result: 相比基于不确定性的方法，所提方法在OOD分割任务上取得了更优性能。

Conclusion: Wasserstein损失与结构正则化相结合，可有效提升模型对未知类别的感知与分割能力，为开放世界语义分割提供了新思路。

Abstract: Deep neural networks achieve superior performance in semantic segmentation, but are limited to a predefined set of classes, which leads to failures when they encounter unknown objects in open-world scenarios. Recognizing and segmenting these out-of-distribution (OOD) objects is crucial for safety-critical applications such as automated driving. In this work, we present an evidence segmentation framework using a Wasserstein loss, which captures distributional distances while respecting the probability simplex geometry. Combined with Kullback-Leibler regularization and Dice structural consistency terms, our approach leads to improved OOD segmentation performance compared to uncertainty-based approaches.

</details>


### [52] [The N-Body Problem: Parallel Execution from Single-Person Egocentric Video](https://arxiv.org/abs/2512.11393)
*Zhifan Zhu,Yifei Huang,Yoichi Sato,Dima Damen*

Main category: cs.CV

TL;DR: 本文提出N-Body问题：给定单视角视频，推理N人如何并行完成其中任务以最大化加速比，并避免空间、物体与因果冲突；通过结构化提示引导VLM建模3D环境与时序依赖，在EPIC-Kitchens数据集上显著提升任务覆盖与可行性。


<details>
  <summary>Details</summary>
Motivation: 人类能直觉地并行复杂活动，但现有模型难以仅从单人视频中学习这种并行能力；同时，简单分段分配易导致物理不可行（如多人共用一物或占据同一空间）

Method: 形式化N-Body问题，设计多维评估指标（速度提升、任务覆盖、空间碰撞、物体冲突、因果约束），并提出结构化提示策略，引导视觉语言模型（VLM）联合推理3D环境、物体使用与时间依赖关系

Result: 在EPIC-Kitchens和HD-EPIC共100个视频上，N=2时相比基线提示，Gemini 2.5 Pro的任务动作覆盖率提升45%，空间碰撞、物体冲突和因果冲突分别降低55%、45%和55%

Conclusion: 结构化提示可有效激发VLM对并行执行的物理与因果约束的理解，为从单视角视频中实现可信多智能体协同提供新范式

Abstract: Humans can intuitively parallelise complex activities, but can a model learn this from observing a single person? Given one egocentric video, we introduce the N-Body Problem: how N individuals, can hypothetically perform the same set of tasks observed in this video. The goal is to maximise speed-up, but naive assignment of video segments to individuals often violates real-world constraints, leading to physically impossible scenarios like two people using the same object or occupying the same space. To address this, we formalise the N-Body Problem and propose a suite of metrics to evaluate both performance (speed-up, task coverage) and feasibility (spatial collisions, object conflicts and causal constraints). We then introduce a structured prompting strategy that guides a Vision-Language Model (VLM) to reason about the 3D environment, object usage, and temporal dependencies to produce a viable parallel execution. On 100 videos from EPIC-Kitchens and HD-EPIC, our method for N = 2 boosts action coverage by 45% over a baseline prompt for Gemini 2.5 Pro, while simultaneously slashing collision rates, object and causal conflicts by 55%, 45% and 55% respectively.

</details>


### [53] [Flowception: Temporally Expansive Flow Matching for Video Generation](https://arxiv.org/abs/2512.11438)
*Tariq Berrada Ifriqi,John Nguyen,Karteek Alahari,Jakob Verbeek,Ricky T. Q. Chen*

Main category: cs.CV

TL;DR: Flowception是一种新型的非自回归、可变长度视频生成框架，通过交替进行离散帧插入和连续帧去噪来学习概率路径，从而在减少计算量的同时提升生成质量与任务灵活性。


<details>
  <summary>Details</summary>
Motivation: 解决自回归视频生成中误差累积/漂移问题，以及全序列流方法计算开销大、难以适配局部注意力和无法联合学习视频长度的问题。

Method: 提出Flowception框架，采用非自回归方式，结合离散帧插入与连续帧去噪的概率路径建模，并支持可变长度视频生成及多种视频生成任务（如图像到视频、视频插帧）的统一处理。

Result: 在FVD和VBench指标上优于自回归和全序列基线方法，训练FLOPs降低三倍，更适配局部注意力机制，并支持视频长度与内容联合学习。

Conclusion: Flowception为高效、灵活、高质量的视频生成提供了新范式，兼具性能优势与多任务兼容性。

Abstract: We present Flowception, a novel non-autoregressive and variable-length video generation framework. Flowception learns a probability path that interleaves discrete frame insertions with continuous frame denoising. Compared to autoregressive methods, Flowception alleviates error accumulation/drift as the frame insertion mechanism during sampling serves as an efficient compression mechanism to handle long-term context. Compared to full-sequence flows, our method reduces FLOPs for training three-fold, while also being more amenable to local attention variants, and allowing to learn the length of videos jointly with their content. Quantitative experimental results show improved FVD and VBench metrics over autoregressive and full-sequence baselines, which is further validated with qualitative results. Finally, by learning to insert and denoise frames in a sequence, Flowception seamlessly integrates different tasks such as image-to-video generation and video interpolation.

</details>


### [54] [FlowDC: Flow-Based Decoupling-Decay for Complex Image Editing](https://arxiv.org/abs/2512.11395)
*Yilei Jiang,Zhen Wang,Yanghao Wang,Jun Yu,Yueting Zhuang,Jun Xiao,Long Chen*

Main category: cs.CV

TL;DR: 本文提出FlowDC方法，通过将复杂图像编辑任务解耦为多个并行子编辑效果，并对正交于编辑位移的速度分量进行衰减，以提升语义对齐与源图像一致性之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有复杂文本图像编辑方法（单轮和多轮）分别受限于长文本跟随能力不足和累积不一致性问题，难以兼顾语义对齐与源图像结构保持。

Method: FlowDC将复杂编辑解耦为多个子编辑效果并行叠加；同时分解速度场，衰减正交于编辑位移的分量以增强源结构保持。

Result: 在自建Complex-PIE-Bench及另一基准上，FlowDC显著优于现有方法；消融实验验证了各模块设计的有效性。

Conclusion: FlowDC通过解耦编辑与速度场正交分量衰减，在复杂文本图像编辑任务中实现了语义准确性与源图像一致性的更好平衡。

Abstract: With the surge of pre-trained text-to-image flow matching models, text-based image editing performance has gained remarkable improvement, especially for \underline{simple editing} that only contains a single editing target. To satisfy the exploding editing requirements, the \underline{complex editing} which contains multiple editing targets has posed as a more challenging task. However, current complex editing solutions: single-round and multi-round editing are limited by long text following and cumulative inconsistency, respectively. Thus, they struggle to strike a balance between semantic alignment and source consistency. In this paper, we propose \textbf{FlowDC}, which decouples the complex editing into multiple sub-editing effects and superposes them in parallel during the editing process. Meanwhile, we observed that the velocity quantity that is orthogonal to the editing displacement harms the source structure preserving. Thus, we decompose the velocity and decay the orthogonal part for better source consistency. To evaluate the effectiveness of complex editing settings, we construct a complex editing benchmark: Complex-PIE-Bench. On two benchmarks, FlowDC shows superior results compared with existing methods. We also detail the ablations of our module designs.

</details>


### [55] [Boosting Skeleton-based Zero-Shot Action Recognition with Training-Free Test-Time Adaptation](https://arxiv.org/abs/2512.11458)
*Jingmin Zhu,Anqi Zhu,Hossein Rahmani,Jun Liu,Mohammed Bennamoun,Qiuhong Ke*

Main category: cs.CV

TL;DR: Skeleton-Cache 是一种无需训练的测试时自适应框架，用于骨架驱动的零样本动作识别，通过非参数缓存和大语言模型引导的语义加权实现对未见动作的动态泛化。


<details>
  <summary>Details</summary>
Motivation: 提升骨架基零样本动作识别模型在推理阶段对未见动作的泛化能力，且不依赖额外训练或训练数据。

Method: 构建非参数骨架缓存，融合全局与细粒度局部描述符；利用大语言模型为不同类别分配语义重要性权重，指导描述符预测融合。

Result: 在 NTU RGB+D 60/120 和 PKU-MMD II 数据集上，显著提升多种零样本动作识别骨干模型在零样本及广义零样本设置下的性能。

Conclusion: Skeleton-Cache 是首个训练无关的测试时自适应方法，有效实现了零样本动作识别中的动态、无训练泛化。

Abstract: We introduce Skeleton-Cache, the first training-free test-time adaptation framework for skeleton-based zero-shot action recognition (SZAR), aimed at improving model generalization to unseen actions during inference. Skeleton-Cache reformulates inference as a lightweight retrieval process over a non-parametric cache that stores structured skeleton representations, combining both global and fine-grained local descriptors. To guide the fusion of descriptor-wise predictions, we leverage the semantic reasoning capabilities of large language models (LLMs) to assign class-specific importance weights. By integrating these structured descriptors with LLM-guided semantic priors, Skeleton-Cache dynamically adapts to unseen actions without any additional training or access to training data. Extensive experiments on NTU RGB+D 60/120 and PKU-MMD II demonstrate that Skeleton-Cache consistently boosts the performance of various SZAR backbones under both zero-shot and generalized zero-shot settings. The code is publicly available at https://github.com/Alchemist0754/Skeleton-Cache.

</details>


### [56] [Collaborative Reconstruction and Repair for Multi-class Industrial Anomaly Detection](https://arxiv.org/abs/2512.11401)
*Qishan Wang,Haofeng Wang,Shuyong Gao,Jia Guo,Li Xiong,Jiaqi Li,Dengxuan Bai,Wenqiang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为协同重建与修复（CRR）的新框架，用于多类别工业异常检测，通过将重建转化为修复、引入特征级随机掩码及训练分割网络，有效缓解了传统重建网络中的恒等映射问题，并在多个工业数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测是开放集任务，需识别未知异常模式；为避免为每类单独建模带来的高内存消耗和泛化性差问题，亟需统一的多类别异常检测框架；但现有重建式网络易出现恒等映射，导致检测失败。

Method: 提出协同重建与修复（CRR）框架：1）优化解码器，使其对正常样本重建、对合成异常样本进行修复，从而在异常区域生成与编码器输出差异大的表示，在正常区域保持相似；2）采用特征级随机掩码增强局部信息保留；3）用合成异常掩码监督训练分割网络，减小编解码器特征差异带来的定位误差。

Result: 在多个工业数据集上实验表明，CRR有效缓解恒等映射问题，在多类别工业异常检测任务中达到当前最优性能（state-of-the-art）。

Conclusion: CRR通过重构—修复范式转变、局部信息强化与监督式分割联合优化，显著提升了统一多类别工业异常检测的鲁棒性与定位精度，为开放集异常检测提供了新思路。

Abstract: Industrial anomaly detection is a challenging open-set task that aims to identify unknown anomalous patterns deviating from normal data distribution. To avoid the significant memory consumption and limited generalizability brought by building separate models per class, we focus on developing a unified framework for multi-class anomaly detection. However, under this challenging setting, conventional reconstruction-based networks often suffer from an identity mapping problem, where they directly replicate input features regardless of whether they are normal or anomalous, resulting in detection failures. To address this issue, this study proposes a novel framework termed Collaborative Reconstruction and Repair (CRR), which transforms the reconstruction to repairation. First, we optimize the decoder to reconstruct normal samples while repairing synthesized anomalies. Consequently, it generates distinct representations for anomalous regions and similar representations for normal areas compared to the encoder's output. Second, we implement feature-level random masking to ensure that the representations from decoder contain sufficient local information. Finally, to minimize detection errors arising from the discrepancies between feature representations from the encoder and decoder, we train a segmentation network supervised by synthetic anomaly masks, thereby enhancing localization performance. Extensive experiments on industrial datasets that CRR effectively mitigates the identity mapping issue and achieves state-of-the-art performance in multi-class industrial anomaly detection.

</details>


### [57] [Exploring MLLM-Diffusion Information Transfer with MetaCanvas](https://arxiv.org/abs/2512.11464)
*Han Lin,Xichen Pan,Ziqi Huang,Ji Hou,Jialiang Wang,Weifeng Chen,Zecheng He,Felix Juefei-Xu,Junzhe Sun,Zhipeng Fan,Ali Thabet,Mohit Bansal,Chu Wang*

Main category: cs.CV

TL;DR: 本文提出MetaCanvas框架，使多模态大语言模型（MLLMs）能在空间和时空潜在空间中直接进行推理与规划，并紧密对接扩散生成器，从而提升图像/视频生成的精确性与结构化控制能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉理解上表现强大，但在视觉生成中仅被用作全局文本编码器，其推理与规划能力未被充分利用，导致理解能力强但生成控制精度不足。

Method: 提出轻量级框架MetaCanvas，让MLLMs直接在空间及时空潜在空间中进行推理与规划，并与多种扩散模型主干紧密协同；在三个不同扩散骨干网络上实现，并在六类生成与编辑任务上进行评估。

Result: MetaCanvas在文本到图像、文本/图像到视频、图像/视频编辑、上下文视频生成等六项任务中均一致优于全局条件化基线方法。

Conclusion: 将MLLMs视为潜在空间规划器是弥合多模态理解与生成之间差距的有效且有前景的方向。

Abstract: Multimodal learning has rapidly advanced visual understanding, largely via multimodal large language models (MLLMs) that use powerful LLMs as cognitive cores. In visual generation, however, these powerful core models are typically reduced to global text encoders for diffusion models, leaving most of their reasoning and planning ability unused. This creates a gap: current multimodal LLMs can parse complex layouts, attributes, and knowledge-intensive scenes, yet struggle to generate images or videos with equally precise and structured control. We propose MetaCanvas, a lightweight framework that lets MLLMs reason and plan directly in spatial and spatiotemporal latent spaces and interface tightly with diffusion generators. We empirically implement MetaCanvas on three different diffusion backbones and evaluate it across six tasks, including text-to-image generation, text/image-to-video generation, image/video editing, and in-context video generation, each requiring precise layouts, robust attribute binding, and reasoning-intensive control. MetaCanvas consistently outperforms global-conditioning baselines, suggesting that treating MLLMs as latent-space planners is a promising direction for narrowing the gap between multimodal understanding and generation.

</details>


### [58] [JoyAvatar: Real-time and Infinite Audio-Driven Avatar Generation with Autoregressive Diffusion](https://arxiv.org/abs/2512.11423)
*Chaochao Li,Ruikui Wang,Liangbo Zhou,Jinheng Feng,Huaishao Luo,Huan Zhang,Youzheng Wu,Xiaodong He*

Main category: cs.CV

TL;DR: 本文提出JoyAvatar，一种音频驱动的自回归模型，通过Progressive Step Bootstrapping、Motion Condition Injection和Unbounded RoPE via Cache-Resetting三项技术，实现高质量、长时长、实时的虚拟人视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有DiT-based音频驱动虚拟人生成方法存在计算开销高、难以生成长视频的问题；而自回归方法虽可缓解，却面临误差累积和质量下降的挑战。

Method: 提出JoyAvatar模型，包含三项关键技术：(1) Progressive Step Bootstrapping（PSB），为初始帧分配更多去噪步数以稳定生成；(2) Motion Condition Injection（MCI），将加噪的前一帧作为运动条件注入以增强时序一致性；(3) Unbounded RoPE via Cache-Resetting（URCR），通过动态位置编码支持无限长度生成。

Result: 1.3B参数的因果模型在单卡GPU上达16 FPS推理速度，在视觉质量、时序一致性和唇音同步方面达到有竞争力的结果。

Conclusion: JoyAvatar有效解决了长时音频驱动虚拟人生成中的误差累积与计算效率问题，实现了高质量、实时、无限长度的视频生成。

Abstract: Existing DiT-based audio-driven avatar generation methods have achieved considerable progress, yet their broader application is constrained by limitations such as high computational overhead and the inability to synthesize long-duration videos. Autoregressive methods address this problem by applying block-wise autoregressive diffusion methods. However, these methods suffer from the problem of error accumulation and quality degradation. To address this, we propose JoyAvatar, an audio-driven autoregressive model capable of real-time inference and infinite-length video generation with the following contributions: (1) Progressive Step Bootstrapping (PSB), which allocates more denoising steps to initial frames to stabilize generation and reduce error accumulation; (2) Motion Condition Injection (MCI), enhancing temporal coherence by injecting noise-corrupted previous frames as motion condition; and (3) Unbounded RoPE via Cache-Resetting (URCR), enabling infinite-length generation through dynamic positional encoding. Our 1.3B-parameter causal model achieves 16 FPS on a single GPU and achieves competitive results in visual quality, temporal consistency, and lip synchronization.

</details>


### [59] [YawDD+: Frame-level Annotations for Accurate Yawn Prediction](https://arxiv.org/abs/2512.11446)
*Ahmed Mujtaba,Gleb Radchenko,Marc Masana,Radu Prodan*

Main category: cs.CV

TL;DR: 本文提出了一种半自动标注流水线，结合人工校验，提升了疲劳驾驶中打哈欠行为识别的数据质量，并在改进的YawDD+数据集上训练模型，显著提高了分类准确率和检测mAP，同时实现在边缘设备上的实时监测。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频标注的机器学习方法因粗粒度时间标注引入系统性噪声，影响打哈欠这一早期疲劳指标的识别性能。

Method: 构建半自动化、人机协同的标注流程，应用于YawDD数据集生成高质量YawDD+；在此基础上训练MNasNet分类器与YOLOv11检测器。

Result: 分类帧准确率达99.34%，检测mAP达95.69%，较视频级监督分别提升6%和5%；在NVIDIA Jetson Nano上达59.8 FPS。

Conclusion: 仅通过提升数据质量即可实现在边缘AI设备上高效、实时的打哈欠监测，无需依赖服务器端计算。

Abstract: Driver fatigue remains a leading cause of road accidents, with 24\% of crashes involving drowsy drivers. While yawning serves as an early behavioral indicator of fatigue, existing machine learning approaches face significant challenges due to video-annotated datasets that introduce systematic noise from coarse temporal annotations. We develop a semi-automated labeling pipeline with human-in-the-loop verification, which we apply to YawDD, enabling more accurate model training. Training the established MNasNet classifier and YOLOv11 detector architectures on YawDD+ improves frame accuracy by up to 6\% and mAP by 5\% over video-level supervision, achieving 99.34\% classification accuracy and 95.69\% detection mAP. The resulting approach deliver up to 59.8 FPS on edge AI hardware (NVIDIA Jetson Nano), confirming that enhanced data quality alone supports on-device yawning monitoring without server-side computation.

</details>


### [60] [DOS: Distilling Observable Softmaps of Zipfian Prototypes for Self-Supervised Point Representation](https://arxiv.org/abs/2512.11465)
*Mohamed Abdelsamad,Michael Ulrich,Bin Yang,Miao Zhang,Yakov Miron,Abhinav Valada*

Main category: cs.CV

TL;DR: 本文提出DOS框架，通过仅在可观测点上自蒸馏语义相关软图，并引入Zipfian原型与Zipf-Sinkhorn算法解决3D点云自监督学习中的几何不规则、重建捷径和语义分布不平衡问题，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 3D点云自监督学习面临不规则几何结构、重建易走捷径、语义分布不平衡等关键挑战。

Method: 提出DOS（Distilling Observable Softmaps）框架：1）仅在未被掩码的可观测点上进行语义软图自蒸馏，防止信息泄露；2）引入Zipfian原型并设计Zipf-Sinkhorn算法，施加幂律先验以平衡原型使用并调节软图锐度。

Result: 在nuScenes、Waymo、SemanticKITTI、ScanNet和ScanNet200等多个基准的语义分割与3D目标检测任务上超越现有SOTA方法，无需额外数据或标注。

Conclusion: 基于可观测点的软图蒸馏是一种可扩展且有效的3D表征学习范式，能提升模型鲁棒性。

Abstract: Recent advances in self-supervised learning (SSL) have shown tremendous potential for learning 3D point cloud representations without human annotations. However, SSL for 3D point clouds still faces critical challenges due to irregular geometry, shortcut-prone reconstruction, and unbalanced semantics distribution. In this work, we propose DOS (Distilling Observable Softmaps), a novel SSL framework that self-distills semantic relevance softmaps only at observable (unmasked) points. This strategy prevents information leakage from masked regions and provides richer supervision than discrete token-to-prototype assignments. To address the challenge of unbalanced semantics in an unsupervised setting, we introduce Zipfian prototypes and incorporate them using a modified Sinkhorn-Knopp algorithm, Zipf-Sinkhorn, which enforces a power-law prior over prototype usage and modulates the sharpness of the target softmap during training. DOS outperforms current state-of-the-art methods on semantic segmentation and 3D object detection across multiple benchmarks, including nuScenes, Waymo, SemanticKITTI, ScanNet, and ScanNet200, without relying on extra data or annotations. Our results demonstrate that observable-point softmaps distillation offers a scalable and effective paradigm for learning robust 3D representations.

</details>


### [61] [Multi-temporal Calving Front Segmentation](https://arxiv.org/abs/2512.11560)
*Marcel Dreier,Nora Gourmelon,Dakota Pyles,Fei Wu,Matthias Braun,Thorsten Seehaus,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 本文提出了一种利用多时相SAR图像序列并行处理与时间特征交互的方法，以提升冰川崩解前沿自动提取的鲁棒性，尤其在冰杂基和积雪干扰下表现更优，并在CaFFe数据集上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的冰川崩解前沿提取方法在受季节性因素（如冰杂基、积雪）干扰区域易出错，需提升模型对时变干扰的鲁棒性。

Method: 提出一种多帧时序SAR图像并行处理框架，在特征图层面交换时间信息以稳定预测；将其嵌入当前SOTA模型Tyrion中。

Result: 在CaFFe基准数据集上取得新SOTA：平均距离误差（MDE）为184.4米，平均交并比（mIoU）为83.6%。

Conclusion: 引入时序特征交互可显著提升崩解前沿分割精度与稳定性，尤其在复杂季节性干扰场景下有效。

Abstract: The calving fronts of marine-terminating glaciers undergo constant changes. These changes significantly affect the glacier's mass and dynamics, demanding continuous monitoring. To address this need, deep learning models were developed that can automatically delineate the calving front in Synthetic Aperture Radar imagery. However, these models often struggle to correctly classify areas affected by seasonal conditions such as ice melange or snow-covered surfaces. To address this issue, we propose to process multiple frames from a satellite image time series of the same glacier in parallel and exchange temporal information between the corresponding feature maps to stabilize each prediction. We integrate our approach into the current state-of-the-art architecture Tyrion and accomplish a new state-of-the-art performance on the CaFFe benchmark dataset. In particular, we achieve a Mean Distance Error of 184.4 m and a mean Intersection over Union of 83.6.

</details>


### [62] [CADMorph: Geometry-Driven Parametric CAD Editing via a Plan-Generate-Verify Loop](https://arxiv.org/abs/2512.11480)
*Weijian Ma,Shizhao Sun,Ruiyu Wang,Jiang Bian*

Main category: cs.CV

TL;DR: 本文提出CADMorph框架，利用预训练的参数-形状扩散模型和掩码参数预测模型，实现几何驱动的参数化CAD编辑，在结构保持、语义有效性和形状保真度三方面取得突破，且无需稀缺的三元组标注数据。


<details>
  <summary>Details</summary>
Motivation: 几何驱动的参数化CAD编辑面临三大挑战：保持原始参数序列结构、确保每次编辑语义有效、维持高形状保真度，而可用的编辑数据三元组极为稀缺。

Method: 提出CADMorph——一个迭代式的'规划-生成-验证'框架：1）规划阶段利用P2S模型的交叉注意力图定位需修改段并生成编辑掩码；2）生成阶段由MPP模型在掩码区域填入语义有效的参数修改；3）验证阶段通过P2S模型将候选序列嵌入形状潜在空间，选择距目标形状最近者。两个基础模型均无需三元组数据训练。

Result: CADMorph在性能上超越GPT-4o及专用CAD基线模型，并支持迭代编辑与逆向工程增强等下游应用。

Conclusion: CADMorph通过协同调用具备几何感知与设计知识的预训练基础模型，有效解耦并分别应对结构保持、语义有效性与形状保真度挑战，为数据稀缺下的CAD智能编辑提供了新范式。

Abstract: A Computer-Aided Design (CAD) model encodes an object in two coupled forms: a parametric construction sequence and its resulting visible geometric shape. During iterative design, adjustments to the geometric shape inevitably require synchronized edits to the underlying parametric sequence, called geometry-driven parametric CAD editing. The task calls for 1) preserving the original sequence's structure, 2) ensuring each edit's semantic validity, and 3) maintaining high shape fidelity to the target shape, all under scarce editing data triplets. We present CADMorph, an iterative plan-generate-verify framework that orchestrates pretrained domain-specific foundation models during inference: a parameter-to-shape (P2S) latent diffusion model and a masked-parameter-prediction (MPP) model. In the planning stage, cross-attention maps from the P2S model pinpoint the segments that need modification and offer editing masks. The MPP model then infills these masks with semantically valid edits in the generation stage. During verification, the P2S model embeds each candidate sequence in shape-latent space, measures its distance to the target shape, and selects the closest one. The three stages leverage the inherent geometric consciousness and design knowledge in pretrained priors, and thus tackle structure preservation, semantic validity, and shape fidelity respectively. Besides, both P2S and MPP models are trained without triplet data, bypassing the data-scarcity bottleneck. CADMorph surpasses GPT-4o and specialized CAD baselines, and supports downstream applications such as iterative editing and reverse-engineering enhancement.

</details>


### [63] [TSkel-Mamba: Temporal Dynamic Modeling via State Space Model for Human Skeleton-based Action Recognition](https://arxiv.org/abs/2512.11503)
*Yanan Liu,Jun Liu,Hao Zhang,Dan Xu,Hossein Rahmani,Mohammed Bennamoun,Qiuhong Ke*

Main category: cs.CV

TL;DR: 本文提出TSkel-Mamba，一种结合Transformer与Mamba的混合框架，用于骨架动作识别；通过引入Temporal Dynamic Modeling（TDM）块及Multi-scale Temporal Interaction（MTI）模块，增强跨通道时序建模能力，在多个基准数据集上实现SOTA且高效。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba模型在处理骨架数据时受限于各通道独立建模，难以有效捕捉关键的跨通道时序依赖关系。

Method: 提出TSkel-Mamba框架：Spatial Transformer学习空间特征，改进的Mamba（含TDM块和MTI模块）建模时间动态；MTI采用多尺度Cycle算子建模跨通道时序交互。

Result: 在NTU-RGB+D 60/120、NW-UCLA和UAV-Human数据集上达到SOTA性能，同时推理耗时低。

Conclusion: TSkel-Mamba通过结构化融合空间-时间建模与创新的跨通道时序交互机制，在精度与效率间取得良好平衡，验证了改进Mamba适配骨架动作识别的有效性。

Abstract: Skeleton-based action recognition has garnered significant attention in the computer vision community. Inspired by the recent success of the selective state-space model (SSM) Mamba in modeling 1D temporal sequences, we propose TSkel-Mamba, a hybrid Transformer-Mamba framework that effectively captures both spatial and temporal dynamics. In particular, our approach leverages Spatial Transformer for spatial feature learning while utilizing Mamba for temporal modeling. Mamba, however, employs separate SSM blocks for individual channels, which inherently limits its ability to model inter-channel dependencies. To better adapt Mamba for skeleton data and enhance Mamba`s ability to model temporal dependencies, we introduce a Temporal Dynamic Modeling (TDM) block, which is a versatile plug-and-play component that integrates a novel Multi-scale Temporal Interaction (MTI) module. The MTI module employs multi-scale Cycle operators to capture cross-channel temporal interactions, a critical factor in action recognition. Extensive experiments on NTU-RGB+D 60, NTU-RGB+D 120, NW-UCLA and UAV-Human datasets demonstrate that TSkel-Mamba achieves state-of-the-art performance while maintaining low inference time, making it both efficient and highly effective.

</details>


### [64] [SSA3D: Text-Conditioned Assisted Self-Supervised Framework for Automatic Dental Abutment Design](https://arxiv.org/abs/2512.11507)
*Mianjie Zheng,Xinquan Yang,Along He,Xuguang Li,Feilie Zhong,Xuefen Liu,Kun Tang,Zhicheng Zhang,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种自监督辅助的自动基台设计框架SS$A^3$D，采用双分支结构（重建+回归）避免传统SSL的预训练-微调流程，并引入文本条件提示模块融合临床信息，显著提升精度与训练效率。


<details>
  <summary>Details</summary>
Motivation: 手动基台设计繁琐，而AI自动化受限于标注数据稀缺；现有自监督学习虽缓解数据问题，但需预训练和微调，计算开销大、耗时长。

Method: 提出SS$A^3$D框架：双分支架构（重建分支恢复掩码口内扫描数据，回归分支在监督下预测基台参数）；引入Text-Conditioned Prompt（TCP）模块融合植入体位置、系统、系列等临床文本信息。

Result: 在自建数据集上实验表明，SS$A^3$D训练时间减少50%，精度高于传统SSL方法，达到当前最优性能。

Conclusion: SS$A^3$D通过结构化自监督与文本引导联合建模，在不牺牲精度前提下大幅提升训练效率，为牙科自动化基台设计提供了高效可行的新范式。

Abstract: Abutment design is a critical step in dental implant restoration. However, manual design involves tedious measurement and fitting, and research on automating this process with AI is limited, due to the unavailability of large annotated datasets. Although self-supervised learning (SSL) can alleviate data scarcity, its need for pre-training and fine-tuning results in high computational costs and long training times. In this paper, we propose a Self-supervised assisted automatic abutment design framework (SS$A^3$D), which employs a dual-branch architecture with a reconstruction branch and a regression branch. The reconstruction branch learns to restore masked intraoral scan data and transfers the learned structural information to the regression branch. The regression branch then predicts the abutment parameters under supervised learning, which eliminates the separate pre-training and fine-tuning process. We also design a Text-Conditioned Prompt (TCP) module to incorporate clinical information (such as implant location, system, and series) into SS$A^3$D. This guides the network to focus on relevant regions and constrains the parameter predictions. Extensive experiments on a collected dataset show that SS$A^3$D saves half of the training time and achieves higher accuracy than traditional SSL methods. It also achieves state-of-the-art performance compared to other methods, significantly improving the accuracy and efficiency of automated abutment design.

</details>


### [65] [Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints](https://arxiv.org/abs/2512.11771)
*Kai Yao,Marc Juarez*

Main category: cs.CV

TL;DR: 本文首次系统评估了AI生成图像模型指纹检测技术的安全性，提出了白盒和黑盒威胁模型，并设计了指纹去除与伪造两类攻击，实验表明现有方法在对抗场景下鲁棒性普遍不足，且存在准确率与鲁棒性的权衡。


<details>
  <summary>Details</summary>
Motivation: 模型指纹检测技术虽有望实现AI图像溯源，但其在对抗条件下的鲁棒性尚不明确，亟需系统性安全评估。

Method: 形式化定义白盒与黑盒威胁模型，提出指纹去除（逃避溯源）与指纹伪造（误导溯源）两类攻击目标，实现五种攻击策略，并在RGB、频域和学习特征域对14种主流指纹方法、12个先进生成模型进行评测。

Result: 去除攻击在白盒下成功率超80%、黑盒下超50%；伪造攻击效果因目标模型而异；高准确率方法通常更易受攻击；无一方法在所有威胁模型下兼具高鲁棒性与高准确率。

Conclusion: 当前模型指纹检测技术鲁棒性不足，需发展兼顾鲁棒性与准确性的新方法，本文指明了关键挑战与潜在突破口。

Abstract: Model fingerprint detection techniques have emerged as a promising approach for attributing AI-generated images to their source models, but their robustness under adversarial conditions remains largely unexplored. We present the first systematic security evaluation of these techniques, formalizing threat models that encompass both white- and black-box access and two attack goals: fingerprint removal, which erases identifying traces to evade attribution, and fingerprint forgery, which seeks to cause misattribution to a target model. We implement five attack strategies and evaluate 14 representative fingerprinting methods across RGB, frequency, and learned-feature domains on 12 state-of-the-art image generators. Our experiments reveal a pronounced gap between clean and adversarial performance. Removal attacks are highly effective, often achieving success rates above 80% in white-box settings and over 50% under constrained black-box access. While forgery is more challenging than removal, its success significantly varies across targeted models. We also identify a utility-robustness trade-off: methods with the highest attribution accuracy are often vulnerable to attacks. Although some techniques exhibit robustness in specific settings, none achieves high robustness and accuracy across all evaluated threat models. These findings highlight the need for techniques balancing robustness and accuracy, and identify the most promising approaches for advancing this goal.

</details>


### [66] [On Geometric Understanding and Learned Data Priors in VGGT](https://arxiv.org/abs/2512.11508)
*Jelena Bratulić,Sudhanshu Mittal,Thomas Brox,Christian Rupprecht*

Main category: cs.CV

TL;DR: 本文分析了3D基础模型VGGT的内部机制，发现其虽无显式几何约束训练，却隐式实现了对应匹配并编码了对极几何，同时依赖学习到的数据先验。


<details>
  <summary>Details</summary>
Motivation: 探究VGGT是否基于传统几何概念还是主要依赖外观驱动的数据先验。

Method: 通过探测中间特征、分析注意力模式和进行干预实验，结合空间输入掩码与扰动实验评估鲁棒性。

Result: VGGT在全局注意力层中隐式执行对应匹配，并编码对极几何；其性能依赖于学习到的数据先验，在遮挡、外观变化和相机配置变化下表现出一定鲁棒性。

Conclusion: VGGT在无需显式几何监督的情况下，内部化了几何结构，并融合了数据驱动先验以实现功能。

Abstract: The Visual Geometry Grounded Transformer (VGGT) is a 3D foundation model that infers camera geometry and scene structure in a single feed-forward pass. Trained in a supervised, single-step fashion on large datasets, VGGT raises a key question: does it build upon geometric concepts like traditional multi-view methods, or does it rely primarily on learned appearance-based data-driven priors? In this work, we conduct a systematic analysis of VGGT's internal mechanisms to uncover whether geometric understanding emerges within its representations. By probing intermediate features, analyzing attention patterns, and performing interventions, we examine how the model implements its functionality. Our findings reveal that VGGT implicitly performs correspondence matching within its global attention layers and encodes epipolar geometry, despite being trained without explicit geometric constraints. We further investigate VGGT's dependence on its learned data priors. Using spatial input masking and perturbation experiments, we assess its robustness to occlusions, appearance variations, and camera configurations, comparing it with classical multi-stage pipelines. Together, these insights highlight how VGGT internalizes geometric structure while using learned data-driven priors.

</details>


### [67] [Reconstruction as a Bridge for Event-Based Visual Question Answering](https://arxiv.org/abs/2512.11510)
*Hanyue Lou,Jiayi Zhou,Yang Zhang,Boyu Li,Yi Wang,Guangnan Ye,Boxin Shi*

Main category: cs.CV

TL;DR: 本文提出了一种将事件相机数据与多模态大语言模型（MLLMs）结合的新方法，通过帧重建与自适应标记化（FRT/ART）桥接事件数据与帧基模型，并构建首个真实世界事件驱动的MLLM评测基准EvQA，验证了该方法在挑战性视觉条件下的优越性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机在低光、高速等挑战性视觉条件下具有优势，但其异步、稀疏的数据特性与主流基于帧的多模态大语言模型（MLLMs）不兼容，亟需一种兼顾事件特性与模型兼容性的融合策略。

Method: 提出两种重建与标记化方法：(1) 帧基重建与标记化（FRT），作为简单基线；(2) 自适应重建与标记化（ART），利用事件稀疏性实现高效处理；并构建首个面向事件相机的MLLM评测基准EvQA（含1000组真实事件-Q&A对）。

Result: 所提FRT与ART方法在EvQA基准上达到当前最优性能（state-of-the-art），显著优于现有方法，验证了事件数据赋能MLLMs进行通用场景理解的有效性。

Conclusion: 以重建为桥梁的事件数据表征方法是连接事件相机与MLLMs的可行且高效路径，EvQA基准为该方向提供了标准化评估基础，推动事件驱动的通用视觉语言理解发展。

Abstract: Integrating event cameras with Multimodal Large Language Models (MLLMs) promises general scene understanding in challenging visual conditions, yet requires navigating a trade-off between preserving the unique advantages of event data and ensuring compatibility with frame-based models. We address this challenge by using reconstruction as a bridge, proposing a straightforward Frame-based Reconstruction and Tokenization (FRT) method and designing an efficient Adaptive Reconstruction and Tokenization (ART) method that leverages event sparsity. For robust evaluation, we introduce EvQA, the first objective, real-world benchmark for event-based MLLMs, comprising 1,000 event-Q&A pairs from 22 public datasets. Our experiments demonstrate that our methods achieve state-of-the-art performance on EvQA, highlighting the significant potential of MLLMs in event-based vision.

</details>


### [68] [Super-Resolved Canopy Height Mapping from Sentinel-2 Time Series Using LiDAR HD Reference Data across Metropolitan France](https://arxiv.org/abs/2512.11524)
*Ekaterina Kalinicheva,Florian Helen,Stéphane Mermoz,Florian Mouret,Milena Planells*

Main category: cs.CV

TL;DR: 本文提出了THREASURE-Net，一种端到端的树高回归与超分辨率框架，利用Sentinel-2时序影像和LiDAR衍生高度数据，在无需预训练模型或高分辨率光学影像的情况下，生成高精度年度树高图，显著提升了温带森林结构监测的可扩展性与成本效益。


<details>
  <summary>Details</summary>
Motivation: 细尺度森林监测对评估碳储量、生物多样性和森林健康至关重要，但现有方法在精度、可扩展性或成本方面存在局限，亟需一种仅依赖免费卫星数据的高效解决方案。

Method: 提出THREASURE-Net框架，基于Sentinel-2时间序列影像，使用多分辨率LiDAR HD数据作为高度参考进行端到端训练；设计三种分辨率（2.5 m、5 m、10 m）的模型变体，其超分辨率模块完全由LiDAR高度信息监督学习，不依赖预训练模型或高分辨率光学影像。

Result: 在法国大都会区实现年度树高图生成，平均绝对误差分别为2.62 m（2.5 m分辨率）、2.72 m（5 m）和2.88 m（10 m）；性能优于现有基于Sentinel数据的最先进方法，并媲美依赖甚高分辨率影像的方法。

Conclusion: THREASURE-Net证明了仅用免费卫星数据即可实现高精度、可扩展且低成本的温带森林结构监测，为全球森林碳汇与生态健康评估提供了新工具。

Abstract: Fine-scale forest monitoring is essential for understanding canopy structure and its dynamics, which are key indicators of carbon stocks, biodiversity, and forest health. Deep learning is particularly effective for this task, as it integrates spectral, temporal, and spatial signals that jointly reflect the canopy structure. To address this need, we introduce THREASURE-Net, a novel end-to-end framework for Tree Height Regression And Super-Resolution. The model is trained on Sentinel-2 time series using reference height metrics derived from LiDAR HD data at multiple spatial resolutions over Metropolitan France to produce annual height maps. We evaluate three model variants, producing tree-height predictions at 2.5 m, 5 m, and 10 m resolution. THREASURE-Net does not rely on any pretrained model nor on reference very high resolution optical imagery to train its super-resolution module; instead, it learns solely from LiDAR-derived height information. Our approach outperforms existing state-of-the-art methods based on Sentinel data and is competitive with methods based on very high resolution imagery. It can be deployed to generate high-precision annual canopy-height maps, achieving mean absolute errors of 2.62 m, 2.72 m, and 2.88 m at 2.5 m, 5 m, and 10 m resolution, respectively. These results highlight the potential of THREASURE-Net for scalable and cost-effective structural monitoring of temperate forests using only freely available satellite data. The source code for THREASURE-Net is available at: https://github.com/Global-Earth-Observation/threasure-net.

</details>


### [69] [Infinity and Beyond: Compositional Alignment in VAR and Diffusion T2I Models](https://arxiv.org/abs/2512.11542)
*Hossein Shahabadi,Niki Sepasian,Arash Marioriyad,Ali Sharifi-Zarchi,Mahdieh Soleymani Baghshah*

Main category: cs.CV

TL;DR: 本文系统评估了六种文本到图像（T2I）模型在组合性对齐任务上的表现，发现视觉自回归（VAR）模型Infinity-8B整体最优，Infinity-2B在效率与性能间取得良好平衡，而扩散模型SDXL和PixArt-α在属性绑定和空间关系任务中存在明显短板。


<details>
  <summary>Details</summary>
Motivation: 现代文本到图像模型在对象、属性及空间关系等组合性对齐方面仍面临核心挑战，尤其视觉自回归（VAR）模型的组合行为尚未被系统研究。

Method: 在T2I-CompBench++和GenEval两个全面基准上，对SDXL、PixArt-α、Flux-Dev、Flux-Schnell、Infinity-2B和Infinity-8B共六种T2I模型，评估其在颜色与属性绑定、空间关系、数理能力及复杂多物体提示下的组合性对齐能力。

Result: Infinity-8B在所有任务中组合性对齐最强；Infinity-2B在多个类别中媲美甚至超越更大规模的扩散模型；SDXL和PixArt-α在属性敏感和空间任务中持续表现薄弱。

Conclusion: 这是首次对VAR与扩散模型在组合性对齐上的系统性比较，为未来T2I模型发展建立了统一基准。

Abstract: Achieving compositional alignment between textual descriptions and generated images - covering objects, attributes, and spatial relationships - remains a core challenge for modern text-to-image (T2I) models. Although diffusion-based architectures have been widely studied, the compositional behavior of emerging Visual Autoregressive (VAR) models is still largely unexamined. We benchmark six diverse T2I systems - SDXL, PixArt-$α$, Flux-Dev, Flux-Schnell, Infinity-2B, and Infinity-8B - across the full T2I-CompBench++ and GenEval suites, evaluating alignment in color and attribute binding, spatial relations, numeracy, and complex multi-object prompts. Across both benchmarks, Infinity-8B achieves the strongest overall compositional alignment, while Infinity-2B also matches or exceeds larger diffusion models in several categories, highlighting favorable efficiency-performance trade-offs. In contrast, SDXL and PixArt-$α$ show persistent weaknesses in attribute-sensitive and spatial tasks. These results provide the first systematic comparison of VAR and diffusion approaches to compositional alignment and establish unified baselines for the future development of the T2I model.

</details>


### [70] [SSL-MedSAM2: A Semi-supervised Medical Image Segmentation Framework Powered by Few-shot Learning of SAM2](https://arxiv.org/abs/2512.11548)
*Zhendi Gong,Xin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的半监督医学图像分割框架SSL-MedSAM2，结合了无需训练的Few-shot分支（基于SAM2）生成伪标签与迭代全监督分支（基于nnUNet）优化伪标签，在肝脏分割任务中取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学图像分割中虽成功，但主流方法依赖大量标注数据，而医学图像标注耗时昂贵，限制临床应用；半监督学习可显著降低标注成本。

Method: 提出SSL-MedSAM2框架：1）TFFS-MedSAM2分支——利用预训练大模型SAM2实现免训练、少样本伪标签生成；2）FSL-nnUNet分支——基于nnUNet进行迭代式全监督伪标签精炼。

Result: 在MICCAI2025 CARE-LiSeg挑战赛（肝脏分割）中表现领先：GED4和T1 MRI测试集平均Dice分数分别为0.9710和0.9648，Hausdorff距离分别为20.07和21.97。

Conclusion: SSL-MedSAM2有效融合大模型先验与经典分割网络优化能力，在有限标注下实现高性能肝脏分割，具备良好临床落地潜力。

Abstract: Despite the success of deep learning based models in medical image segmentation, most state-of-the-art (SOTA) methods perform fully-supervised learning, which commonly rely on large scale annotated training datasets. However, medical image annotation is highly time-consuming, hindering its clinical applications. Semi-supervised learning (SSL) has been emerged as an appealing strategy in training with limited annotations, largely reducing the labelling cost. We propose a novel SSL framework SSL-MedSAM2, which contains a training-free few-shot learning branch TFFS-MedSAM2 based on the pretrained large foundation model Segment Anything Model 2 (SAM2) for pseudo label generation, and an iterative fully-supervised learning branch FSL-nnUNet based on nnUNet for pseudo label refinement. The results on MICCAI2025 challenge CARE-LiSeg (Liver Segmentation) demonstrate an outstanding performance of SSL-MedSAM2 among other methods. The average dice scores on the test set in GED4 and T1 MRI are 0.9710 and 0.9648 respectively, and the Hausdorff distances are 20.07 and 21.97 respectively. The code is available via https://github.com/naisops/SSL-MedSAM2/tree/main.

</details>


### [71] [3DTeethSAM: Taming SAM2 for 3D Teeth Segmentation](https://arxiv.org/abs/2512.11557)
*Zhiguo Lu,Jianwen Lou,Mingjun Ma,Hairong Jin,Youyi Zheng,Kun Zhou*

Main category: cs.CV

TL;DR: 本文提出3DTeethSAM，将SAM2模型适配于3D牙齿分割任务，通过多视角渲染、2D-3D投影及三个轻量可学习模块（提示嵌入生成器、掩码优化器、掩码分类器）提升性能，并引入DGAP增强编码器，最终在3DTeethSeg基准上达到91.90% IoU，刷新SOTA。


<details>
  <summary>Details</summary>
Motivation: 3D牙齿分割在数字牙科中至关重要但极具挑战性，现有方法难以应对真实牙列的复杂性；而SAM2作为强大的通用分割基础模型，尚未被有效适配到3D牙齿数据。

Method: 将3D牙齿模型多视角渲染为2D图像，用SAM2进行2D分割，再通过2D-3D投影重建3D结果；引入三个轻量可学习模块（提示嵌入生成器、掩码优化器、掩码分类器）弥补SAM2类不可知、依赖提示及初始结果不佳的缺陷；并在SAM2图像编码器中嵌入Deformable Global Attention Plugins（DGAP）以提升精度与训练效率。

Result: 在3DTeethSeg基准上，对高分辨率3D牙齿网格实现91.90%的IoU，显著优于现有方法，达到新SOTA。

Conclusion: 3DTeethSAM成功将视觉基础模型SAM2迁移至3D牙齿分割任务，验证了结合渲染-投影范式与轻量定制模块的有效性，为医学3D分割提供了可扩展的新思路。

Abstract: 3D teeth segmentation, involving the localization of tooth instances and their semantic categorization in 3D dental models, is a critical yet challenging task in digital dentistry due to the complexity of real-world dentition. In this paper, we propose 3DTeethSAM, an adaptation of the Segment Anything Model 2 (SAM2) for 3D teeth segmentation. SAM2 is a pretrained foundation model for image and video segmentation, demonstrating a strong backbone in various downstream scenarios. To adapt SAM2 for 3D teeth data, we render images of 3D teeth models from predefined views, apply SAM2 for 2D segmentation, and reconstruct 3D results using 2D-3D projections. Since SAM2's performance depends on input prompts and its initial outputs often have deficiencies, and given its class-agnostic nature, we introduce three light-weight learnable modules: (1) a prompt embedding generator to derive prompt embeddings from image embeddings for accurate mask decoding, (2) a mask refiner to enhance SAM2's initial segmentation results, and (3) a mask classifier to categorize the generated masks. Additionally, we incorporate Deformable Global Attention Plugins (DGAP) into SAM2's image encoder. The DGAP enhances both the segmentation accuracy and the speed of the training process. Our method has been validated on the 3DTeethSeg benchmark, achieving an IoU of 91.90% on high-resolution 3D teeth meshes, establishing a new state-of-the-art in the field.

</details>


### [72] [Evaluating Foundation Models' 3D Understanding Through Multi-View Correspondence Analysis](https://arxiv.org/abs/2512.11574)
*Valentina Lilova,Toyesh Chakravorty,Julian I. Bibo,Emma Boccaletti,Brandon Li,Lívia Baxová,Cees G. M. Snoek,Mohammadreza Salehi*

Main category: cs.CV

TL;DR: 本文提出了一种无需微调的上下文内3D场景理解新基准，基于Hummingbird框架和MVImgNet数据集，评估预训练模型在多视角图像间分割泛化能力，并对8个主流基础模型进行了评测。


<details>
  <summary>Details</summary>
Motivation: 现有3D空间理解评估依赖下游微调，难以分离预训练编码器固有的3D推理能力，亟需一种不依赖微调、直接评估密集视觉特征质量的评测方法。

Method: 构建基于Hummingbird框架的上下文内3D场景理解基准，在MVImgNet数据集上给定多角度关键图像（keys），评估模型对新视角查询图像（queries）的分割能力，并按视角差异分为易、中、难、极难四类进行评分。

Result: 在8个SOTA基础模型上评测发现：基于DINO的编码器在大视角变化下仍具竞争力；而VGGT等3D感知模型需专门的多视图调整才能发挥优势。

Conclusion: 该基准能有效区分模型内在3D理解能力，为无微调的3D视觉表征评估提供了新范式。

Abstract: Benchmarking 3D spatial understanding of foundation models is essential for real-world applications such as robotics and autonomous driving. Existing evaluations often rely on downstream finetuning with linear heads or task-specific decoders, making it difficult to isolate the intrinsic 3D reasoning ability of pretrained encoders. In this work, we introduce a novel benchmark for in-context 3D scene understanding that requires no finetuning and directly probes the quality of dense visual features. Building on the Hummingbird framework, which evaluates in-context 2D scene understanding, we extend the setup to the 3D Multi-View ImageNet (MVImgNet) dataset. Given a set of images from objects in specific angles (keys), we benchmark the performance of segmenting novel views (queries) and report the scores in 4 categories of easy, medium, hard, and extreme based on the key-query view contrast. We benchmark 8 state-of-the-art foundation models and show DINO-based encoders remain competitive across large viewpoint shifts, while 3D-aware models like VGGT require dedicated multi-view adjustments. Our code is publicly available at https://github.com/ToyeshC/open-hummingbird-3d-eval .

</details>


### [73] [In-Context Learning for Seismic Data Processing](https://arxiv.org/abs/2512.11575)
*Fabian Fuchs,Mario Ruben Fernandez,Norman Ettrich,Janis Keuper*

Main category: cs.CV

TL;DR: 本文提出ContextSeisNet，一种用于地震去多次波的上下文学习模型，通过利用空间邻近道集示例对实现推理时任务自适应、提升横向一致性并减少训练数据需求。


<details>
  <summary>Details</summary>
Motivation: 传统地震处理方法存在噪声干扰和人工调参困难；现有深度学习方法则面临预测结果空间不一致和缺乏用户可控性的问题。

Method: 提出ContextSeisNet，采用上下文学习范式，在推理时以同一条测线上相邻共深度点（CDP）道集及其标签为支持集进行条件化预测，无需重训练即可适配具体任务。

Result: 在合成数据上优于U-Net基线，提升相邻道集空间连贯性；在实际数据中相较Radon变换和U-Net均展现出更优横向一致性、更好近偏移距性能及更彻底的多次波压制；仅用10%训练数据即达到与U-Net相当的实地效果。

Conclusion: ContextSeisNet是一种高效、灵活且空间一致的地震去多次波方法，具备向其他地震处理任务拓展的潜力。

Abstract: Seismic processing transforms raw data into subsurface images essential for geophysical applications. Traditional methods face challenges, such as noisy data, and manual parameter tuning, among others. Recently deep learning approaches have proposed alternative solutions to some of these problems. However, important challenges of existing deep learning approaches are spatially inconsistent results across neighboring seismic gathers and lack of user-control. We address these limitations by introducing ContextSeisNet, an in-context learning model, to seismic demultiple processing. Our approach conditions predictions on a support set of spatially related example pairs: neighboring common-depth point gathers from the same seismic line and their corresponding labels. This allows the model to learn task-specific processing behavior at inference time by observing how similar gathers should be processed, without any retraining. This method provides both flexibility through user-defined examples and improved lateral consistency across seismic lines. On synthetic data, ContextSeisNet outperforms a U-Net baseline quantitatively and demonstrates enhanced spatial coherence between neighboring gathers. On field data, our model achieves superior lateral consistency compared to both traditional Radon demultiple and the U-Net baseline. Relative to the U-Net, ContextSeisNet also delivers improved near-offset performance and more complete multiple removal. Notably, ContextSeisNet achieves comparable field data performance despite being trained on 90% less data, demonstrating substantial data efficiency. These results establish ContextSeisNet as a practical approach for spatially consistent seismic demultiple with potential applicability to other seismic processing tasks.

</details>


### [74] [Using GUI Agent for Electronic Design Automation](https://arxiv.org/abs/2512.11611)
*Chunyi Li,Longfei Li,Zicheng Zhang,Xiaohong Liu,Min Tang,Weisi Lin,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了首个面向电子设计自动化（EDA）工作流的GUI智能体系统性研究，构建了大规模GUI-EDA数据集，评估了30多个主流GUI智能体，并提出专用于EDA的EDAgent模型，在工业CAD软件上首次超越电气工程博士生。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体主要在办公软件（如Word、Excel）上评估，而在高经济价值的专业CAD/EDA软件中表现极差，尚无法替代专业EDA工程师，亟需面向该高价值工程领域的专项研究。

Method: 构建包含5种CAD工具、5个物理领域、2000+高质量截图-答案-动作对的GUI-EDA数据集；建立综合基准评测30+主流GUI智能体；提出具备反思机制的EDA-specialized模型EDAgent。

Result: 实验表明EDA任务是当前GUI智能体的重大未解挑战；EDAgent在工业CAD软件上实现可靠性能，并首次在评测中超越电气工程博士生。

Conclusion: 本工作将GUI智能体的应用从通用办公自动化拓展至专业高价值工程领域，为提升EDA生产力开辟新路径。

Abstract: Graphical User Interface (GUI) agents adopt an end-to-end paradigm that maps a screenshot to an action sequence, thereby automating repetitive tasks in virtual environments. However, existing GUI agents are evaluated almost exclusively on commodity software such as Microsoft Word and Excel. Professional Computer-Aided Design (CAD) suites promise an order-of-magnitude higher economic return, yet remain the weakest performance domain for existing agents and are still far from replacing expert Electronic-Design-Automation (EDA) engineers. We therefore present the first systematic study that deploys GUI agents for EDA workflows. Our contributions are: (1) a large-scale dataset named GUI-EDA, including 5 CAD tools and 5 physical domains, comprising 2,000+ high-quality screenshot-answer-action pairs recorded by EDA scientists and engineers during real-world component design; (2) a comprehensive benchmark that evaluates 30+ mainstream GUI agents, demonstrating that EDA tasks constitute a major, unsolved challenge; and (3) an EDA-specialized metric named EDAgent, equipped with a reflection mechanism that achieves reliable performance on industrial CAD software and, for the first time, outperforms Ph.D. students majored in Electrical Engineering. This work extends GUI agents from generic office automation to specialized, high-value engineering domains and offers a new avenue for advancing EDA productivity. The dataset will be released at: https://github.com/aiben-ch/GUI-EDA.

</details>


### [75] [Embodied Image Compression](https://arxiv.org/abs/2512.11612)
*Chunyi Li,Rui Qing,Jianbo Zhang,Yuan Tian,Xiangyang Zhu,Zicheng Zhang,Xiaohong Liu,Weisi Lin,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文首次提出“具身图像压缩”这一科学问题，构建了标准化基准EmbodiedComp，旨在解决具身AI在多智能体系统中因通信受限而影响实时任务执行的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着具身智能快速发展，图像压缩目标已从面向虚拟模型转向面向真实环境运行的具身智能体；需应对多智能体系统中的通信约束并保障实时任务执行。

Method: 提出具身图像压缩新问题，构建闭环、超低码率条件下的标准化评估基准EmbodiedComp，并在仿真与真实场景中开展大量实验验证。

Result: 实验证明现有视觉-语言-动作（VLA）模型在低于‘具身码率阈值’时无法稳定完成简单操作任务。

Conclusion: EmbodiedComp将推动面向具身智能体的领域专用压缩方法发展，加速具身AI在现实世界中的部署应用。

Abstract: Image Compression for Machines (ICM) has emerged as a pivotal research direction in the field of visual data compression. However, with the rapid evolution of machine intelligence, the target of compression has shifted from task-specific virtual models to Embodied agents operating in real-world environments. To address the communication constraints of Embodied AI in multi-agent systems and ensure real-time task execution, this paper introduces, for the first time, the scientific problem of Embodied Image Compression. We establish a standardized benchmark, EmbodiedComp, to facilitate systematic evaluation under ultra-low bitrate conditions in a closed-loop setting. Through extensive empirical studies in both simulated and real-world settings, we demonstrate that existing Vision-Language-Action models (VLAs) fail to reliably perform even simple manipulation tasks when compressed below the Embodied bitrate threshold. We anticipate that EmbodiedComp will catalyze the development of domain-specific compression tailored for Embodied agents , thereby accelerating the Embodied AI deployment in the Real-world.

</details>


### [76] [Fast and Explicit: Slice-to-Volume Reconstruction via 3D Gaussian Primitives with Analytic Point Spread Function Modeling](https://arxiv.org/abs/2512.11624)
*Maik Dannecker,Steven Jia,Nil Stolt-Ansó,Nadine Girard,Guillaume Auzias,François Rousseau,Daniel Rueckert*

Main category: cs.CV

TL;DR: 本文提出了一种基于各向异性高斯基元的显式表示方法，用于快速、高保真地从运动伪影严重的低分辨率2D胎儿MRI切片重建高分辨率3D脑图像，通过闭式解析解替代蒙特卡洛采样，实现5–10倍加速且保持SOTA质量。


<details>
  <summary>Details</summary>
Motivation: 胎儿MRI中，需从运动退化、低分辨率的2D切片重建高分辨率3D脑图像以支持神经发育诊断；现有基于隐式神经表示（INR）的自监督切片到体素重建（SVR）方法因需昂贵的蒙特卡洛采样建模点扩散函数（PSF）而计算瓶颈严重。

Method: 将高分辨率3D图像体积参数化为各向异性高斯基元场，利用高斯函数在卷积下封闭的性质，推导出前向成像模型的闭式解析解（观测协方差=高分辨协方差+PSF协方差），避免随机采样并保证梯度精确传播。

Result: 在新生儿和胎儿数据上，重建质量与当前最优自监督SVR方法相当，速度提升5–10倍；通常30秒内收敛，显著推进实时胎儿3D MRI临床落地。

Conclusion: 高斯显式表示提供了一种高效、可微、物理一致的替代方案，克服了INR在SVR中的计算障碍，在保持精度的同时大幅提升速度，具备强临床转化潜力。

Abstract: Recovering high-fidelity 3D images from sparse or degraded 2D images is a fundamental challenge in medical imaging, with broad applications ranging from 3D ultrasound reconstruction to MRI super-resolution. In the context of fetal MRI, high-resolution 3D reconstruction of the brain from motion-corrupted low-resolution 2D acquisitions is a prerequisite for accurate neurodevelopmental diagnosis. While implicit neural representations (INRs) have recently established state-of-the-art performance in self-supervised slice-to-volume reconstruction (SVR), they suffer from a critical computational bottleneck: accurately modeling the image acquisition physics requires expensive stochastic Monte Carlo sampling to approximate the point spread function (PSF). In this work, we propose a shift from neural network based implicit representations to Gaussian based explicit representations. By parameterizing the HR 3D image volume as a field of anisotropic Gaussian primitives, we leverage the property of Gaussians being closed under convolution and thus derive a \textit{closed-form analytical solution} for the forward model. This formulation reduces the previously intractable acquisition integral to an exact covariance addition ($\mathbfΣ_{obs} = \mathbfΣ_{HR} + \mathbfΣ_{PSF}$), effectively bypassing the need for compute-intensive stochastic sampling while ensuring exact gradient propagation. We demonstrate that our approach matches the reconstruction quality of self-supervised state-of-the-art SVR frameworks while delivering a 5$\times$--10$\times$ speed-up on neonatal and fetal data. With convergence often reached in under 30 seconds, our framework paves the way towards translation into clinical routine of real-time fetal 3D MRI. Code will be public at {https://github.com/m-dannecker/Gaussian-Primitives-for-Fast-SVR}.

</details>


### [77] [FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint](https://arxiv.org/abs/2512.11645)
*Jiapeng Tang,Kai Li,Chengxiang Yin,Liuhao Ge,Fei Jiang,Jiu Xu,Matthias Nießner,Christian Häne,Timur Bagautdinov,Egor Zakharov,Peihong Guo*

Main category: cs.CV

TL;DR: FactorPortrait是一种基于视频扩散的可控人像动画方法，通过解耦的面部表情、头部运动和相机视角控制信号，实现从单张人像图像生成逼真、多视角的动画。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人像动画中难以同时实现高 realism、表达力、控制精度和视角一致性，尤其缺乏对多维度控制信号（如表情、姿态、视角）的有效解耦与协同建模。

Method: 提出FactorPortrait：利用预训练图像编码器从驱动视频提取解耦的表情潜变量；设计表达控制器将其注入视频扩散Transformer；采用Plücker射线图和3D人体网格渲染的法线图表征相机与头部姿态；构建大规模合成数据集进行端到端训练。

Result: 在多个指标上超越现有方法，显著提升动画的真实性、表情丰富度、控制准确性及跨视角一致性。

Conclusion: FactorPortrait验证了在视频扩散框架中显式建模与解耦多源控制信号的有效性，为人像动画提供了更灵活、鲁棒且高质量的生成范式。

Abstract: We introduce FactorPortrait, a video diffusion method for controllable portrait animation that enables lifelike synthesis from disentangled control signals of facial expressions, head movement, and camera viewpoints. Given a single portrait image, a driving video, and camera trajectories, our method animates the portrait by transferring facial expressions and head movements from the driving video while simultaneously enabling novel view synthesis from arbitrary viewpoints. We utilize a pre-trained image encoder to extract facial expression latents from the driving video as control signals for animation generation. Such latents implicitly capture nuanced facial expression dynamics with identity and pose information disentangled, and they are efficiently injected into the video diffusion transformer through our proposed expression controller. For camera and head pose control, we employ Plücker ray maps and normal maps rendered from 3D body mesh tracking. To train our model, we curate a large-scale synthetic dataset containing diverse combinations of camera viewpoints, head poses, and facial expression dynamics. Extensive experiments demonstrate that our method outperforms existing approaches in realism, expressiveness, control accuracy, and view consistency.

</details>


### [78] [Kinetic Mining in Context: Few-Shot Action Synthesis via Text-to-Motion Distillation](https://arxiv.org/abs/2512.11654)
*Luca Cazzola,Ahed Alboody*

Main category: cs.CV

TL;DR: 本文提出KineMIC框架，通过迁移学习将通用Text-to-Motion（T2M）扩散模型适配至骨骼动作识别（HAR）任务，在仅用每类10个样本的少样本设定下，显著提升动作合成质量与分类准确率。


<details>
  <summary>Details</summary>
Motivation: 大型标注骨骼动作数据集获取成本高；现有T2M模型面向艺术化运动生成，与HAR所需的运动学精确、类别判别性强的动作存在领域鸿沟。

Method: 提出KineMIC：基于CLIP文本嵌入建立稀疏HAR标签与T2M源数据间的语义对应，实施‘动力学挖掘’策略，对T2M扩散模型进行上下文感知的微调，将其转化为少样本Action-to-Motion生成器。

Result: 在HumanML3D（源）和NTU RGB+D 120子集（目标）上验证，仅用每类10个样本，生成动作更连贯，下游HAR分类准确率提升+23.1个百分点。

Conclusion: 语义空间中的软监督可用于动力学知识蒸馏；KineMIC有效弥合T2M与HAR之间的领域差距，为少样本骨骼动作识别提供高质量合成数据源。

Abstract: The acquisition cost for large, annotated motion datasets remains a critical bottleneck for skeletal-based Human Activity Recognition (HAR). Although Text-to-Motion (T2M) generative models offer a compelling, scalable source of synthetic data, their training objectives, which emphasize general artistic motion, and dataset structures fundamentally differ from HAR's requirements for kinematically precise, class-discriminative actions. This disparity creates a significant domain gap, making generalist T2M models ill-equipped for generating motions suitable for HAR classifiers. To address this challenge, we propose KineMIC (Kinetic Mining In Context), a transfer learning framework for few-shot action synthesis. KineMIC adapts a T2M diffusion model to an HAR domain by hypothesizing that semantic correspondences in the text encoding space can provide soft supervision for kinematic distillation. We operationalize this via a kinetic mining strategy that leverages CLIP text embeddings to establish correspondences between sparse HAR labels and T2M source data. This process guides fine-tuning, transforming the generalist T2M backbone into a specialized few-shot Action-to-Motion generator. We validate KineMIC using HumanML3D as the source T2M dataset and a subset of NTU RGB+D 120 as the target HAR domain, randomly selecting just 10 samples per action class. Our approach generates significantly more coherent motions, providing a robust data augmentation source that delivers a +23.1% accuracy points improvement. Animated illustrations and supplementary materials are available at (https://lucazzola.github.io/publications/kinemic).

</details>


### [79] [Cross-modal Context-aware Learning for Visual Prompt Guided Multimodal Image Understanding in Remote Sensing](https://arxiv.org/abs/2512.11680)
*Xu Zhang,Jiabin Fang,Zhuoming Ding,Jin Yuan,Xuan Liu,Qianjun Zhang,Zhiyong Li*

Main category: cs.CV

TL;DR: 本文提出CLV-Net，通过用户提供的视觉提示（如边界框）引导多模态模型生成意图对齐的分割掩码与描述，在遥感图像理解中实现更精准、上下文感知的目标识别。


<details>
  <summary>Details</summary>
Motivation: 现有遥感图像多模态方法难以在仅用简单文本提示时聚焦用户关注区域；且遥感图像中目标外观相似、关系复杂，导致识别困难。

Method: 提出CLV-Net：1）以视觉提示（边界框）为输入引导模型；2）设计上下文感知掩码解码器建模目标间关系；3）引入语义与关系对齐模块，包括跨模态语义一致性损失和关系一致性损失。

Result: 在两个基准数据集上显著优于现有方法，达到新SOTA；能准确捕捉用户意图，生成高精度、意图对齐的分割掩码和文本描述。

Conclusion: CLV-Net通过视觉提示驱动、上下文建模与跨模态对齐，有效提升了遥感图像中用户意图导向的多模态理解性能。

Abstract: Recent advances in image understanding have enabled methods that leverage large language models for multimodal reasoning in remote sensing. However, existing approaches still struggle to steer models to the user-relevant regions when only simple, generic text prompts are available. Moreover, in large-scale aerial imagery many objects exhibit highly similar visual appearances and carry rich inter-object relationships, which further complicates accurate recognition. To address these challenges, we propose Cross-modal Context-aware Learning for Visual Prompt-Guided Multimodal Image Understanding (CLV-Net). CLV-Net lets users supply a simple visual cue, a bounding box, to indicate a region of interest, and uses that cue to guide the model to generate correlated segmentation masks and captions that faithfully reflect user intent. Central to our design is a Context-Aware Mask Decoder that models and integrates inter-object relationships to strengthen target representations and improve mask quality. In addition, we introduce a Semantic and Relationship Alignment module: a Cross-modal Semantic Consistency Loss enhances fine-grained discrimination among visually similar targets, while a Relationship Consistency Loss enforces alignment between textual relations and visual interactions. Comprehensive experiments on two benchmark datasets show that CLV-Net outperforms existing methods and establishes new state-of-the-art results. The model effectively captures user intent and produces precise, intention-aligned multimodal outputs.

</details>


### [80] [Depth-Copy-Paste: Multimodal and Depth-Aware Compositing for Robust Face Detection](https://arxiv.org/abs/2512.11683)
*Qiushi Guo*

Main category: cs.CV

TL;DR: 本文提出Depth Copy Paste，一种多模态、深度感知的数据增强框架，通过结合语义检索、高精度分割与深度引导的粘贴机制，生成物理一致、视觉逼真的面部检测训练样本，显著提升模型在遮挡、光照变化等挑战场景下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统复制粘贴增强方法因前景提取不准、场景几何不一致和背景语义不匹配，导致合成图像不真实，限制了人脸检测系统在复杂条件下的鲁棒性。

Method: 利用BLIP与CLIP联合评估语义与视觉一致性以自动检索适配背景；采用SAM3实现精细人物分割，并结合Depth-Anything提取非遮挡可见区域以保留面部细节；引入深度引导的滑动窗口定位机制，在背景深度图上搜索深度连续且尺度对齐的粘贴位置。

Result: 生成的合成图像具有自然的深度关系和更高视觉可信度；实验表明该方法相比传统及无深度增强方法，在下游人脸检测任务中带来显著性能提升。

Conclusion: Depth Copy Paste通过融合多模态语义理解、精准分割与几何感知粘贴策略，有效解决了传统数据增强中真实性与物理一致性不足的问题，为鲁棒人脸检测提供了高质量训练数据生成新范式。

Abstract: Data augmentation is crucial for improving the robustness of face detection systems, especially under challenging conditions such as occlusion, illumination variation, and complex environments. Traditional copy paste augmentation often produces unrealistic composites due to inaccurate foreground extraction, inconsistent scene geometry, and mismatched background semantics. To address these limitations, we propose Depth Copy Paste, a multimodal and depth aware augmentation framework that generates diverse and physically consistent face detection training samples by copying full body person instances and pasting them into semantically compatible scenes. Our approach first employs BLIP and CLIP to jointly assess semantic and visual coherence, enabling automatic retrieval of the most suitable background images for the given foreground person. To ensure high quality foreground masks that preserve facial details, we integrate SAM3 for precise segmentation and Depth-Anything to extract only the non occluded visible person regions, preventing corrupted facial textures from being used in augmentation. For geometric realism, we introduce a depth guided sliding window placement mechanism that searches over the background depth map to identify paste locations with optimal depth continuity and scale alignment. The resulting composites exhibit natural depth relationships and improved visual plausibility. Extensive experiments show that Depth Copy Paste provides more diverse and realistic training data, leading to significant performance improvements in downstream face detection tasks compared with traditional copy paste and depth free augmentation methods.

</details>


### [81] [EditMGT: Unleashing Potentials of Masked Generative Transformers in Image Editing](https://arxiv.org/abs/2512.11715)
*Wei Chow,Linfeng Li,Lingdong Kong,Zefeng Li,Qi Xu,Hang Song,Tian Ye,Xian Wang,Jinbin Bai,Shilin Xu,Xiangtai Li,Junting Pan,Shaoteng Liu,Ran Zhou,Tianshu Yang,Songhua Liu*

Main category: cs.CV

TL;DR: 本文提出EditMGT，首个基于Masked Generative Transformers（MGT）的图像编辑框架，利用MGT的局部化建模能力实现精准区域编辑，避免全局扩散模型常见的非目标区域误修改；通过多层注意力融合与区域保持采样策略提升定位精度与编辑保真度，并在自建高质量数据集CrispEdit-2M上训练，在速度和质量上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型（DMs）在图像编辑中存在全局去噪导致非目标区域被意外修改的问题，亟需一种能天然支持局部编辑、保留无关区域的替代建模范式。

Method: 提出基于Masked Generative Transformers（MGT）的EditMGT框架：1）利用MGT跨注意力图提供编辑相关区域定位信号；2）设计多层注意力融合方案提升定位精度；3）引入区域保持采样（region-hold sampling），在低注意力区域禁止token翻转以抑制伪编辑；4）通过注意力注入将预训练文本到图像MGT适配为编辑模型，并使用自建高分辨率数据集CrispEdit-2M进行训练。

Result: EditMGT在四个标准基准上验证：参数少于1B，编辑速度达现有方法6倍，风格变换和风格迁移任务分别提升3.6%和17.6%，整体编辑质量相当或更优。

Conclusion: MGT因其掩码生成与局部解码特性，比扩散模型更适配局部图像编辑任务；EditMGT首次系统性地挖掘并利用MGT的注意力机制实现精准、高效、保真的局部编辑，为图像编辑提供了新范式。

Abstract: Recent advances in diffusion models (DMs) have achieved exceptional visual quality in image editing tasks. However, the global denoising dynamics of DMs inherently conflate local editing targets with the full-image context, leading to unintended modifications in non-target regions. In this paper, we shift our attention beyond DMs and turn to Masked Generative Transformers (MGTs) as an alternative approach to tackle this challenge. By predicting multiple masked tokens rather than holistic refinement, MGTs exhibit a localized decoding paradigm that endows them with the inherent capacity to explicitly preserve non-relevant regions during the editing process. Building upon this insight, we introduce the first MGT-based image editing framework, termed EditMGT. We first demonstrate that MGT's cross-attention maps provide informative localization signals for localizing edit-relevant regions and devise a multi-layer attention consolidation scheme that refines these maps to achieve fine-grained and precise localization. On top of these adaptive localization results, we introduce region-hold sampling, which restricts token flipping within low-attention areas to suppress spurious edits, thereby confining modifications to the intended target regions and preserving the integrity of surrounding non-target areas. To train EditMGT, we construct CrispEdit-2M, a high-resolution dataset spanning seven diverse editing categories. Without introducing additional parameters, we adapt a pre-trained text-to-image MGT into an image editing model through attention injection. Extensive experiments across four standard benchmarks demonstrate that, with fewer than 1B parameters, our model achieves similarity performance while enabling 6 times faster editing. Moreover, it delivers comparable or superior editing quality, with improvements of 3.6% and 17.6% on style change and style transfer tasks, respectively.

</details>


### [82] [Referring Change Detection in Remote Sensing Imagery](https://arxiv.org/abs/2512.11719)
*Yilmaz Korkmaz,Jay N. Paranjape,Celso M. de Melo,Vishal M. Patel*

Main category: cs.CV

TL;DR: 本文提出了一种基于自然语言提示的遥感图像指代变化检测（RCD）方法，通过融合视觉与语言理解实现用户指定类别的变化检测，并设计了RCDNet网络和RCDGen扩散生成框架以缓解标注数据稀缺与类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统变化检测无法区分变化类型，语义变化检测则受限于固定类别定义和模型架构，难以跨数据集/任务复用。

Method: 提出指代变化检测（RCD）范式，构建RCDNet跨模态融合网络，并设计RCDGen基于扩散模型的合成数据生成流程，仅需预变化图像即可生成目标类别的后变化图像与变化图。

Result: 在多个数据集上验证了该框架可实现可扩展、目标导向的变化检测，显著降低高质量标注数据依赖。

Conclusion: RCD为遥感变化检测提供了更灵活、用户可控的新范式，RCDGen有效缓解了数据瓶颈，提升了方法实用性与泛化能力。

Abstract: Change detection in remote sensing imagery is essential for applications such as urban planning, environmental monitoring, and disaster management. Traditional change detection methods typically identify all changes between two temporal images without distinguishing the types of transitions, which can lead to results that may not align with specific user needs. Although semantic change detection methods have attempted to address this by categorizing changes into predefined classes, these methods rely on rigid class definitions and fixed model architectures, making it difficult to mix datasets with different label sets or reuse models across tasks, as the output channels are tightly coupled with the number and type of semantic classes. To overcome these limitations, we introduce Referring Change Detection (RCD), which leverages natural language prompts to detect specific classes of changes in remote sensing images. By integrating language understanding with visual analysis, our approach allows users to specify the exact type of change they are interested in. However, training models for RCD is challenging due to the limited availability of annotated data and severe class imbalance in existing datasets. To address this, we propose a two-stage framework consisting of (I) \textbf{RCDNet}, a cross-modal fusion network designed for referring change detection, and (II) \textbf{RCDGen}, a diffusion-based synthetic data generation pipeline that produces realistic post-change images and change maps for a specified category using only pre-change image, without relying on semantic segmentation masks and thereby significantly lowering the barrier to scalable data creation. Experiments across multiple datasets show that our framework enables scalable and targeted change detection. Project website is here: https://yilmazkorkmaz1.github.io/RCD.

</details>


### [83] [Reframing Music-Driven 2D Dance Pose Generation as Multi-Channel Image Generation](https://arxiv.org/abs/2512.11720)
*Yan Zhang,Han Zou,Lincong Feng,Cong Xie,Ruiqi Yu,Zhenpeng Zhan*

Main category: cs.CV

TL;DR: 本文提出了一种将音乐转化为舞蹈动作的新方法，将2D姿态序列编码为图像并利用DiT架构建模，结合时间共享索引和参考姿态条件机制，显著提升了节奏对齐性、时序一致性和身份保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有姿态转视频模型已能生成高质量舞蹈视频，但如何从音乐生成时序连贯、节奏对齐且适应真实复杂分布的2D姿态仍是关键挑战。

Method: 将音乐到舞蹈生成重构为音乐token条件下的多通道图像合成问题：2D姿态序列编码为one-hot图像，经预训练图像VAE压缩后，用DiT式主干网络建模；引入时间共享的时间索引方案以对齐音乐token与姿态隐变量，并设计参考姿态条件策略以保持个体身体比例与画面尺度，支持长序列分段拼接生成。

Result: 在大规模真实舞蹈数据集及AIST++2D基准上，该方法在姿态空间与视频空间指标及人类偏好评估中均显著优于代表性方法，消融实验验证了表征设计、时间索引与参考条件的有效性。

Conclusion: 通过图像化姿态表征与借鉴文生图先进架构，辅以显式时间对齐与个性化姿态约束，本方法有效提升了音乐驱动舞蹈生成的质量与鲁棒性。

Abstract: Recent pose-to-video models can translate 2D pose sequences into photorealistic, identity-preserving dance videos, so the key challenge is to generate temporally coherent, rhythm-aligned 2D poses from music, especially under complex, high-variance in-the-wild distributions. We address this by reframing music-to-dance generation as a music-token-conditioned multi-channel image synthesis problem: 2D pose sequences are encoded as one-hot images, compressed by a pretrained image VAE, and modeled with a DiT-style backbone, allowing us to inherit architectural and training advances from modern text-to-image models and better capture high-variance 2D pose distributions. On top of this formulation, we introduce (i) a time-shared temporal indexing scheme that explicitly synchronizes music tokens and pose latents over time and (ii) a reference-pose conditioning strategy that preserves subject-specific body proportions and on-screen scale while enabling long-horizon segment-and-stitch generation. Experiments on a large in-the-wild 2D dance corpus and the calibrated AIST++2D benchmark show consistent improvements over representative music-to-dance methods in pose- and video-space metrics and human preference, and ablations validate the contributions of the representation, temporal indexing, and reference conditioning. See supplementary videos at https://hot-dance.github.io

</details>


### [84] [Weak-to-Strong Generalization Enables Fully Automated De Novo Training of Multi-head Mask-RCNN Model for Segmenting Densely Overlapping Cell Nuclei in Multiplex Whole-slice Brain Images](https://arxiv.org/abs/2512.11722)
*Lin Bai,Xiaoyang Li,Liqiang Huang,Quynh Nguyen,Hien Van Nguyen,Saurabh Prasad,Dragan Maric,John Redell,Pramod Dash,Badrinath Roysam*

Main category: cs.CV

TL;DR: 本文提出了一种从弱监督到强泛化的多头Mask-RCNN方法，结合高效通道注意力机制，用于无需人工标注地自动分割多重循环免疫荧光全片图像中重叠的细胞核，并支持自动质量诊断。


<details>
  <summary>Details</summary>
Motivation: 解决在新型仪器或成像协议下，对大规模全片图像进行细胞核分割时缺乏人工标注、难以人工校验的问题。

Method: 构建了带高效通道注意力的多头Mask-RCNN架构，采用弱到强泛化策略，包含伪标签修正与覆盖扩展机制，并设计自动化分割质量自诊断指标。

Result: 在五种主流方法对比中显著提升性能；支持跨设备/协议的零样本式新类别分割；提供开源代码、样例图像与高分辨率结果。

Conclusion: 该方法实现了无需人工标注的可靠细胞核分割与生产环境中的自动质量监控，具备强泛化性与实用性，推动病理图像分析的自动化落地。

Abstract: We present a weak to strong generalization methodology for fully automated training of a multi-head extension of the Mask-RCNN method with efficient channel attention for reliable segmentation of overlapping cell nuclei in multiplex cyclic immunofluorescent (IF) whole-slide images (WSI), and present evidence for pseudo-label correction and coverage expansion, the key phenomena underlying weak to strong generalization. This method can learn to segment de novo a new class of images from a new instrument and/or a new imaging protocol without the need for human annotations. We also present metrics for automated self-diagnosis of segmentation quality in production environments, where human visual proofreading of massive WSI images is unaffordable. Our method was benchmarked against five current widely used methods and showed a significant improvement. The code, sample WSI images, and high-resolution segmentation results are provided in open form for community adoption and adaptation.

</details>


### [85] [SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder](https://arxiv.org/abs/2512.11749)
*Minglei Shi,Haolin Wang,Borui Zhang,Wenzhao Zheng,Bohan Zeng,Ziyang Yuan,Xiaoshi Wu,Yuanxing Zhang,Huan Yang,Xintao Wang,Pengfei Wan,Kun Gai,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文提出SVG-T2I框架，在视觉基础模型（VFM）表征空间内直接进行高质量文本到图像生成，验证了VFM表征本身对生成任务的强大能力，并开源全部代码与权重。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉基础模型（VFM）表征为统一视觉理解、感知与生成提供了有前景的路径，但尚无工作在VFM表征空间内端到端训练大规模文本到图像扩散模型。

Method: 扩展SVG自监督表征框架，构建SVG-T2I，采用标准文本到图像扩散架构，在VFM特征域中直接建模和生成图像。

Result: SVG-T2I在GenEval上达0.75、DPG-Bench上达85.78，性能媲美主流方法；同时完全开源模型、训练/推理/评估流程及预训练权重。

Conclusion: VFM的内在表征能力足以支撑高质量生成任务，无需回退至像素空间；基于表征的生成是可行且有效的研究范式。

Abstract: Visual generation grounded in Visual Foundation Model (VFM) representations offers a highly promising unified pathway for integrating visual understanding, perception, and generation. Despite this potential, training large-scale text-to-image diffusion models entirely within the VFM representation space remains largely unexplored. To bridge this gap, we scale the SVG (Self-supervised representations for Visual Generation) framework, proposing SVG-T2I to support high-quality text-to-image synthesis directly in the VFM feature domain. By leveraging a standard text-to-image diffusion pipeline, SVG-T2I achieves competitive performance, reaching 0.75 on GenEval and 85.78 on DPG-Bench. This performance validates the intrinsic representational power of VFMs for generative tasks. We fully open-source the project, including the autoencoder and generation model, together with their training, inference, evaluation pipelines, and pre-trained weights, to facilitate further research in representation-driven visual generation.

</details>


### [86] [Reducing Domain Gap with Diffusion-Based Domain Adaptation for Cell Counting](https://arxiv.org/abs/2512.11763)
*Mohammad Dehghanmanshadi,Wallapak Tavanapong*

Main category: cs.CV

TL;DR: 本文提出了一种基于反演的风格迁移（InST）方法，将真实荧光显微图像的风格迁移到合成图像上，显著缩小了合成与真实显微图像之间的域差距，在细胞计数任务中超越了纯真实数据和现有合成数据。


<details>
  <summary>Details</summary>
Motivation: 在标签稀缺（如单张图像含大量细胞）的生物医学场景中，生成逼真的合成显微图像对训练深度学习模型至关重要；但传统域自适应方法难以应对合成图像缺乏真实纹理与视觉模式的问题。

Method: 将面向艺术风格迁移的Inversion-Based Style Transfer（InST）框架适配至生物医学显微图像，结合潜在空间自适应实例归一化（AdaIN）与扩散模型的随机反演，实现真实图像风格向合成图像迁移，同时弱保持内容结构。

Result: 在细胞计数下游任务中，使用InST合成数据预训练+微调EfficientNet-B0，MAE比硬编码合成数据降低37%，比Cell200-s数据降低52%（53.70→25.95）；甚至优于仅用真实数据训练的结果（25.95 vs. 27.74）；结合DACS与CutMix可进一步提升性能。

Conclusion: InST风格迁移能最有效地缩小合成与真实显微图像间的域差距，为减少人工标注、提升细胞计数性能提供了可扩展的新路径。

Abstract: Generating realistic synthetic microscopy images is critical for training deep learning models in label-scarce environments, such as cell counting with many cells per image. However, traditional domain adaptation methods often struggle to bridge the domain gap when synthetic images lack the complex textures and visual patterns of real samples. In this work, we adapt the Inversion-Based Style Transfer (InST) framework originally designed for artistic style transfer to biomedical microscopy images. Our method combines latent-space Adaptive Instance Normalization with stochastic inversion in a diffusion model to transfer the style from real fluorescence microscopy images to synthetic ones, while weakly preserving content structure.
  We evaluate the effectiveness of our InST-based synthetic dataset for downstream cell counting by pre-training and fine-tuning EfficientNet-B0 models on various data sources, including real data, hard-coded synthetic data, and the public Cell200-s dataset. Models trained with our InST-synthesized images achieve up to 37\% lower Mean Absolute Error (MAE) compared to models trained on hard-coded synthetic data, and a 52\% reduction in MAE compared to models trained on Cell200-s (from 53.70 to 25.95 MAE). Notably, our approach also outperforms models trained on real data alone (25.95 vs. 27.74 MAE). Further improvements are achieved when combining InST-synthesized data with lightweight domain adaptation techniques such as DACS with CutMix. These findings demonstrate that InST-based style transfer most effectively reduces the domain gap between synthetic and real microscopy data. Our approach offers a scalable path for enhancing cell counting performance while minimizing manual labeling effort. The source code and resources are publicly available at: https://github.com/MohammadDehghan/InST-Microscopy.

</details>


### [87] [MatAnyone 2: Scaling Video Matting via a Learned Quality Evaluator](https://arxiv.org/abs/2512.11782)
*Peiqing Yang,Shangchen Zhou,Kai Hao,Qingyi Tao*

Main category: cs.CV

TL;DR: 本文提出了一种无需真值的Matting Quality Evaluator（MQE）用于评估视频抠图质量，并基于此构建了大规模真实世界视频抠图数据集VMReal；同时引入参考帧训练策略，使新模型MatAnyone 2在合成与真实数据集上均达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频抠图受限于数据集规模与真实性；利用分割数据虽可提升语义稳定性，但缺乏有效边界监督导致抠图结果细节不足。

Method: 提出无真值依赖的像素级Matting Quality Evaluator（MQE），用于在线训练反馈与离线数据筛选；构建大规模真实视频抠图数据集VMReal（28K片段，2.4M帧）；设计参考帧训练策略以应对长视频中外观大幅变化。

Result: 构建了VMReal数据集；MatAnyone 2在合成与真实世界基准上全面超越先前方法，达到SOTA性能。

Conclusion: MQE为视频抠图提供了可扩展的质量评估与监督范式，结合VMReal数据集和参考帧训练策略，显著提升了真实场景下的抠图精度与鲁棒性。

Abstract: Video matting remains limited by the scale and realism of existing datasets. While leveraging segmentation data can enhance semantic stability, the lack of effective boundary supervision often leads to segmentation-like mattes lacking fine details. To this end, we introduce a learned Matting Quality Evaluator (MQE) that assesses semantic and boundary quality of alpha mattes without ground truth. It produces a pixel-wise evaluation map that identifies reliable and erroneous regions, enabling fine-grained quality assessment. The MQE scales up video matting in two ways: (1) as an online matting-quality feedback during training to suppress erroneous regions, providing comprehensive supervision, and (2) as an offline selection module for data curation, improving annotation quality by combining the strengths of leading video and image matting models. This process allows us to build a large-scale real-world video matting dataset, VMReal, containing 28K clips and 2.4M frames. To handle large appearance variations in long videos, we introduce a reference-frame training strategy that incorporates long-range frames beyond the local window for effective training. Our MatAnyone 2 achieves state-of-the-art performance on both synthetic and real-world benchmarks, surpassing prior methods across all metrics.

</details>


### [88] [Uncertainty-Aware Domain Adaptation for Vitiligo Segmentation in Clinical Photographs](https://arxiv.org/abs/2512.11791)
*Wentao Jiang,Vamsi Varra,Caitlin Perez-Stable,Harrison Zhu,Meredith Apicella,Nicole Nyamongo*

Main category: cs.CV

TL;DR: 本文提出了一种频率感知、可信赖的皮肤白斑（vitiligo）图像分割框架，通过数据高效训练、高频谱门控网络架构改进和临床可信机制，在临床照片中实现了高精度、低边界误差且零灾难性失败的自动量化评估。


<details>
  <summary>Details</summary>
Motivation: 准确量化临床照片中的白斑面积对长期监测治疗效果至关重要，但现有方法在噪声抑制、细微纹理捕捉和结果可靠性方面存在不足。

Method: 提出三支柱框架：(1) 基于ISIC 2019数据集的领域自适应预训练+ROI约束双任务损失；(2) ConvNeXt V2编码器集成高频谱门控（HFSG）模块与stem-skip连接；(3) K折集成与测试时增强（TTA）生成像素级不确定性图。

Result: 在专家标注临床队列上达到85.05% Dice分数，95% Hausdorff距离从44.79 px显著降至29.95 px，全面超越ResNet-50、UNet++和MiT-B5等强基线，且零灾难性失败，提供可解释熵图。

Conclusion: 该框架为自动化白斑评估建立了稳健、可靠的新标准，兼具高精度、高鲁棒性与临床可解释性。

Abstract: Accurately quantifying vitiligo extent in routine clinical photographs is crucial for longitudinal monitoring of treatment response. We propose a trustworthy, frequency-aware segmentation framework built on three synergistic pillars: (1) a data-efficient training strategy combining domain-adaptive pre-training on the ISIC 2019 dataset with an ROI-constrained dual-task loss to suppress background noise; (2) an architectural refinement via a ConvNeXt V2-based encoder enhanced with a novel High-Frequency Spectral Gating (HFSG) module and stem-skip connections to capture subtle textures; and (3) a clinical trust mechanism employing K-fold ensemble and Test-Time Augmentation (TTA) to generate pixel-wise uncertainty maps. Extensive validation on an expert-annotated clinical cohort demonstrates superior performance, achieving a Dice score of 85.05% and significantly reducing boundary error (95% Hausdorff Distance improved from 44.79 px to 29.95 px), consistently outperforming strong CNN (ResNet-50 and UNet++) and Transformer (MiT-B5) baselines. Notably, our framework demonstrates high reliability with zero catastrophic failures and provides interpretable entropy maps to identify ambiguous regions for clinician review. Our approach suggests that the proposed framework establishes a robust and reliable standard for automated vitiligo assessment.

</details>


### [89] [Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation](https://arxiv.org/abs/2512.11792)
*Yang Fei,George Stoica,Jingyuan Liu,Qifeng Chen,Ranjay Krishna,Xiaojuan Wang,Benlin Liu*

Main category: cs.CV

TL;DR: 本文提出SAM2VideoX，通过从SAM2视频跟踪模型中蒸馏结构保持运动先验，并结合双向特征融合模块和局部Gram Flow损失，显著提升了视频生成中结构一致性和运动真实感。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成具有物理合理性的结构保持运动（尤其是人体和动物等可变形物体）方面仍存在挑战，单纯扩大训练数据效果有限，且依赖外部不完美的运动表征（如光流或骨架）。

Method: 将自回归视频跟踪模型SAM2的结构保持运动先验蒸馏到双向视频扩散模型CogVideoX中；引入双向特征融合模块提取全局运动先验；设计局部Gram Flow损失以对齐局部特征运动一致性。

Result: 在VBench上提升2.60%（达95.51%），FVD降低21–22%，人类偏好率达71.4%；显著优于REPA和LoRA微调基线。

Conclusion: 利用高质量视频跟踪模型蒸馏运动先验是提升视频扩散模型结构保真度与物理合理性的有效路径，SAM2VideoX为结构感知视频生成提供了新范式。

Abstract: Reality is a dance between rigid constraints and deformable structures. For video models, that means generating motion that preserves fidelity as well as structure. Despite progress in diffusion models, producing realistic structure-preserving motion remains challenging, especially for articulated and deformable objects such as humans and animals. Scaling training data alone, so far, has failed to resolve physically implausible transitions. Existing approaches rely on conditioning with noisy motion representations, such as optical flow or skeletons extracted using an external imperfect model. To address these challenges, we introduce an algorithm to distill structure-preserving motion priors from an autoregressive video tracking model (SAM2) into a bidirectional video diffusion model (CogVideoX). With our method, we train SAM2VideoX, which contains two innovations: (1) a bidirectional feature fusion module that extracts global structure-preserving motion priors from a recurrent model like SAM2; (2) a Local Gram Flow loss that aligns how local features move together. Experiments on VBench and in human studies show that SAM2VideoX delivers consistent gains (+2.60\% on VBench, 21-22\% lower FVD, and 71.4\% human preference) over prior baselines. Specifically, on VBench, we achieve 95.51\%, surpassing REPA (92.91\%) by 2.60\%, and reduce FVD to 360.57, a 21.20\% and 22.46\% improvement over REPA- and LoRA-finetuning, respectively. The project website can be found at https://sam2videox.github.io/ .

</details>


### [90] [V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties](https://arxiv.org/abs/2512.11799)
*Ye Fang,Tong Wu,Valentin Deschaintre,Duygu Ceylan,Iliyan Georgiev,Chun-Hao Paul Huang,Yiwei Hu,Xuelin Chen,Tuanfeng Yang Wang*

Main category: cs.CV

TL;DR: 本文提出了V-RGBX，首个端到端的本征感知视频编辑框架，支持视频逆渲染、本征驱动的视频合成与基于关键帧的本征条件编辑。


<details>
  <summary>Details</summary>
Motivation: 现有大规模视频生成模型缺乏对场景本征属性（如反照率、法线、材质、辐照度）的联合理解、利用与可编辑表示。

Method: 提出V-RGBX框架，核心是交错式条件机制，统一实现视频逆渲染、本征驱动的视频合成及关键帧引导的本征条件编辑。

Result: V-RGBX生成时序一致、逼真的视频，并能以物理合理方式将关键帧编辑传播至整个序列，在物体外观编辑和场景重光照等任务中优于先前方法。

Conclusion: V-RGBX首次实现了端到端、可编辑、物理 grounded 的本征感知视频生成与编辑，为可控视频合成开辟了新路径。

Abstract: Large-scale video generation models have shown remarkable potential in modeling photorealistic appearance and lighting interactions in real-world scenes. However, a closed-loop framework that jointly understands intrinsic scene properties (e.g., albedo, normal, material, and irradiance), leverages them for video synthesis, and supports editable intrinsic representations remains unexplored. We present V-RGBX, the first end-to-end framework for intrinsic-aware video editing. V-RGBX unifies three key capabilities: (1) video inverse rendering into intrinsic channels, (2) photorealistic video synthesis from these intrinsic representations, and (3) keyframe-based video editing conditioned on intrinsic channels. At the core of V-RGBX is an interleaved conditioning mechanism that enables intuitive, physically grounded video editing through user-selected keyframes, supporting flexible manipulation of any intrinsic modality. Extensive qualitative and quantitative results show that V-RGBX produces temporally consistent, photorealistic videos while propagating keyframe edits across sequences in a physically plausible manner. We demonstrate its effectiveness in diverse applications, including object appearance editing and scene-level relighting, surpassing the performance of prior methods.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [91] [ASR Under the Stethoscope: Evaluating Biases in Clinical Speech Recognition across Indian Languages](https://arxiv.org/abs/2512.10967)
*Subham Kumar,Prakrithi Shivaprakash,Abhishek Manoharan,Astut Kurariya,Diptadhi Mukherjee,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

TL;DR: 本研究首次系统评估了多种ASR模型在印度多语言（卡纳达语、印地语、印度英语）真实临床语音数据上的表现，揭示了模型在语言、说话人角色（患者/医生）和性别等方面的显著性能差异与公平性问题。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）在印度多元语言与人口结构复杂的医疗场景中应用日益广泛，但其实际可靠性尚缺乏系统评估，尤其在公平性和跨语言鲁棒性方面存在知识空白。

Method: 基于真实临床访谈数据，对Indic Whisper、Whisper、Sarvam、Google Speech-to-Text等8个主流ASR模型进行跨语言（卡纳达语、印地语、印度英语）、跨说话人角色（患者/医生）及跨人口子群（性别、交叉身份）的系统性基准测试与错误模式分析。

Result: 各模型性能在语言间差异显著：部分模型在印度英语上表现良好，但在语码混用或方言语音上严重失效；同时发现系统性偏差——患者语音识别准确率普遍低于医生，女性及特定交叉群体识别错误率更高。

Conclusion: 当前ASR系统在印度医疗场景中存在显著语言覆盖不足与结构性公平缺陷，亟需以文化适配与人口包容为导向开展模型开发与评估。

Abstract: Automatic Speech Recognition (ASR) is increasingly used to document clinical encounters, yet its reliability in multilingual and demographically diverse Indian healthcare contexts remains largely unknown. In this study, we conduct the first systematic audit of ASR performance on real world clinical interview data spanning Kannada, Hindi, and Indian English, comparing leading models including Indic Whisper, Whisper, Sarvam, Google speech to text, Gemma3n, Omnilingual, Vaani, and Gemini. We evaluate transcription accuracy across languages, speakers, and demographic subgroups, with a particular focus on error patterns affecting patients vs. clinicians and gender based or intersectional disparities. Our results reveal substantial variability across models and languages, with some systems performing competitively on Indian English but failing on code mixed or vernacular speech. We also uncover systematic performance gaps tied to speaker role and gender, raising concerns about equitable deployment in clinical settings. By providing a comprehensive multilingual benchmark and fairness analysis, our work highlights the need for culturally and demographically inclusive ASR development for healthcare ecosystem in India.

</details>


### [92] [Benchmarking Automatic Speech Recognition Models for African Languages](https://arxiv.org/abs/2512.10968)
*Alvin Nahabwe,Sulaiman Kagumire,Denis Musinguzi,Bruno Beijuka,Jonah Mubuuke Kyagaba,Peter Nabende,Andrew Katumba,Joyce Nakatumba-Nabende*

Main category: cs.CL

TL;DR: This paper benchmarks four state-of-the-art ASR models (Whisper, XLS-R, MMS, W2v-BERT) across 13 African languages using data subsets from 1 to 400 hours, revealing their relative data efficiency, scaling behavior, and decoding effectiveness in low-resource settings.


<details>
  <summary>Details</summary>
Motivation: ASR for African languages suffers from scarce labeled data and lack of systematic guidance on model selection, data scaling, and decoding—especially for underrepresented languages.

Method: Fine-tuning and benchmarking four pre-trained ASR models (Whisper, XLS-R, MMS, W2v-BERT) on 13 African languages using progressively scaled transcribed data (1–400 hours); analyzing error rates, data efficiency, scaling trends, and external language model decoding effects.

Result: MMS and W2v-BERT excel in very low-resource regimes (<10h), XLS-R scales best with more data, Whisper performs best in mid-resource (e.g., ~100h); external LM decoding helps only when acoustic and text resources are well-aligned, otherwise it plateaus or harms performance.

Conclusion: Model choice for African language ASR should be guided by data availability and resource alignment—not one-size-fits-all; this work provides practical, evidence-based guidance for building effective ASR systems for underrepresented languages.

Abstract: Automatic speech recognition (ASR) for African languages remains constrained by limited labeled data and the lack of systematic guidance on model selection, data scaling, and decoding strategies. Large pre-trained systems such as Whisper, XLS-R, MMS, and W2v-BERT have expanded access to ASR technology, but their comparative behavior in African low-resource contexts has not been studied in a unified and systematic way. In this work, we benchmark four state-of-the-art ASR models across 13 African languages, fine-tuning them on progressively larger subsets of transcribed data ranging from 1 to 400 hours. Beyond reporting error rates, we provide new insights into why models behave differently under varying conditions. We show that MMS and W2v-BERT are more data efficient in very low-resource regimes, XLS-R scales more effectively as additional data becomes available, and Whisper demonstrates advantages in mid-resource conditions. We also analyze where external language model decoding yields improvements and identify cases where it plateaus or introduces additional errors, depending on the alignment between acoustic and text resources. By highlighting the interaction between pre-training coverage, model architecture, dataset domain, and resource availability, this study offers practical and insights into the design of ASR systems for underrepresented languages.

</details>


### [93] [MedBioRAG: Semantic Search and Retrieval-Augmented Generation with Large Language Models for Medical and Biological QA](https://arxiv.org/abs/2512.10996)
*Seonok Kim*

Main category: cs.CL

TL;DR: 本文提出了MedBioRAG，一种结合语义与词法搜索、文档检索和监督微调的检索增强生成模型，显著提升了生物医学问答任务的性能，在多个基准数据集上超越了现有最先进模型和GPT-4o基线模型。


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型在生物医学领域复杂问答任务中的准确性和上下文感知能力，解决现有方法在专业领域检索与生成精度不足的问题。

Method: 提出MedBioRAG模型，融合语义搜索与词法搜索进行文档检索与排序，并结合监督微调优化大语言模型的响应生成能力。

Result: 在NFCorpus、TREC-COVID、MedQA、PubMedQA和BioASQ等多个基准数据集上，MedBioRAG在文本检索（NDCG、MRR）、封闭式问答（准确率）和长文本问答（ROUGE）指标上均优于SoTA模型和GPT-4o基线模型。

Conclusion: 语义搜索驱动的检索与大语言模型监督微调相结合，可有效提升生物医学问答系统的整体性能，为专业领域RAG应用提供了可行且高效的技术路径。

Abstract: Recent advancements in retrieval-augmented generation (RAG) have significantly enhanced the ability of large language models (LLMs) to perform complex question-answering (QA) tasks. In this paper, we introduce MedBioRAG, a retrieval-augmented model designed to improve biomedical QA performance through a combination of semantic and lexical search, document retrieval, and supervised fine-tuning. MedBioRAG efficiently retrieves and ranks relevant biomedical documents, enabling precise and context-aware response generation. We evaluate MedBioRAG across text retrieval, close-ended QA, and long-form QA tasks using benchmark datasets such as NFCorpus, TREC-COVID, MedQA, PubMedQA, and BioASQ. Experimental results demonstrate that MedBioRAG outperforms previous state-of-the-art (SoTA) models and the GPT-4o base model in all evaluated tasks. Notably, our approach improves NDCG and MRR scores for document retrieval, while achieving higher accuracy in close-ended QA and ROUGE scores in long-form QA. Our findings highlight the effectiveness of semantic search-based retrieval and LLM fine-tuning in biomedical applications.

</details>


### [94] [KBQA-R1: Reinforcing Large Language Models for Knowledge Base Question Answering](https://arxiv.org/abs/2512.10999)
*Xin Sun,Zhongqi Chen,Xing Zheng,Qiang Liu,Shu Wu,Bowen Song,Zilei Wang,Weiqiang Wang,Liang Wang*

Main category: cs.CL

TL;DR: 本文提出KBQA-R1框架，通过强化学习优化KBQA任务中的交互式推理过程，结合GRPO算法和Referenced Rejection Sampling数据合成方法，显著提升大语言模型在知识库问答中基于执行反馈的真实推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有KBQA方法存在两极失败：要么生成脱离知识图谱模式的幻觉查询，要么依赖僵化的模板式推理，缺乏对环境的真实理解。

Method: 将KBQA建模为多轮决策过程，使用Group Relative Policy Optimization（GRPO）进行强化学习优化，并引入Referenced Rejection Sampling（RRS）进行严格对齐真实动作序列的数据合成。

Result: 在WebQSP、GrailQA和GraphQuestions数据集上达到SOTA性能，显著提升LLM推理在可验证执行上的 groundedness。

Conclusion: KBQA-R1成功将KBQA范式从文本模仿转向基于执行反馈的交互优化，有效缓解幻觉与僵化推理问题，增强大模型对知识图谱的实际操作能力。

Abstract: Knowledge Base Question Answering (KBQA) challenges models to bridge the gap between natural language and strict knowledge graph schemas by generating executable logical forms. While Large Language Models (LLMs) have advanced this field, current approaches often struggle with a dichotomy of failure: they either generate hallucinated queries without verifying schema existence or exhibit rigid, template-based reasoning that mimics synthesized traces without true comprehension of the environment. To address these limitations, we present \textbf{KBQA-R1}, a framework that shifts the paradigm from text imitation to interaction optimization via Reinforcement Learning. Treating KBQA as a multi-turn decision process, our model learns to navigate the knowledge base using a list of actions, leveraging Group Relative Policy Optimization (GRPO) to refine its strategies based on concrete execution feedback rather than static supervision. Furthermore, we introduce \textbf{Referenced Rejection Sampling (RRS)}, a data synthesis method that resolves cold-start challenges by strictly aligning reasoning traces with ground-truth action sequences. Extensive experiments on WebQSP, GrailQA, and GraphQuestions demonstrate that KBQA-R1 achieves state-of-the-art performance, effectively grounding LLM reasoning in verifiable execution.

</details>


### [95] [Automating Historical Insight Extraction from Large-Scale Newspaper Archives via Neural Topic Modeling](https://arxiv.org/abs/2512.11635)
*Keerthana Murugaraj,Salima Lamsiyah,Marten During,Martin Theobald*

Main category: cs.CL

TL;DR: 本文提出使用BERTopic这一基于Transformer的神经主题建模方法，分析1955–2018年报纸档案中关于核能与核安全的公共话语演变，克服OCR噪声、话题动态性及传统LDA局限，揭示主题共现与重要性变迁。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型（如LDA）难以应对历史报纸档案中的话题演化、OCR噪声和文本规模大等挑战，亟需更鲁棒、上下文敏感的方法。

Method: 采用BERTopic，利用预训练Transformer嵌入进行主题提取与聚类，并结合时间序列分析追踪核能与核安全相关话题的分布与演化。

Result: 成功识别并可视化了核能与核武器相关主题的长期趋势、共现模式及重要性变迁，验证了BERTopic在历史文本中的可扩展性与语境敏感性。

Conclusion: BERTopic为历史话语研究提供了优于传统方法的新范式，拓展了数字人文与社会科学研究的技术路径，并指出了当前应用的局限与未来方向。

Abstract: Extracting coherent and human-understandable themes from large collections of unstructured historical newspaper archives presents significant challenges due to topic evolution, Optical Character Recognition (OCR) noise, and the sheer volume of text. Traditional topic-modeling methods, such as Latent Dirichlet Allocation (LDA), often fall short in capturing the complexity and dynamic nature of discourse in historical texts. To address these limitations, we employ BERTopic. This neural topic-modeling approach leverages transformerbased embeddings to extract and classify topics, which, despite its growing popularity, still remains underused in historical research. Our study focuses on articles published between 1955 and 2018, specifically examining discourse on nuclear power and nuclear safety. We analyze various topic distributions across the corpus and trace their temporal evolution to uncover long-term trends and shifts in public discourse. This enables us to more accurately explore patterns in public discourse, including the co-occurrence of themes related to nuclear power and nuclear weapons and their shifts in topic importance over time. Our study demonstrates the scalability and contextual sensitivity of BERTopic as an alternative to traditional approaches, offering richer insights into historical discourses extracted from newspaper archives. These findings contribute to historical, nuclear, and social-science research while reflecting on current limitations and proposing potential directions for future work.

</details>


### [96] [PIAST: Rapid Prompting with In-context Augmentation for Scarce Training data](https://arxiv.org/abs/2512.11013)
*Pawel Batorski,Paul Swoboda*

Main category: cs.CL

TL;DR: 本文提出了一种快速自动提示构造算法，通过蒙特卡洛Shapley估计选择少量高质量的少样本示例来增强人工指令，在有限计算资源下优于现有自动提示方法，并在扩展预算下达到自动提示方法的新SOTA。


<details>
  <summary>Details</summary>
Motivation: 大语言模型对提示设计高度敏感，但手工设计有效提示困难且依赖复杂的手工少样本示例构造。

Method: 提出基于蒙特卡洛Shapley值估计的迭代少样本示例选择算法（替换/删除/保留），结合激进子采样和重放缓冲区加速评估，并支持不同计算预算配置。

Result: 在文本简化和GSM8K任务上超越现有自动提示方法；在分类与摘要任务上获第二优结果；扩大预算后在分类、简化和GSM8K上均达自动提示方法新SOTA。

Conclusion: 精心构造的少量示例比穷举式指令搜索更能高效推动提示工程，是快速、数据高效的提示优化关键杠杆。

Abstract: LLMs are highly sensitive to prompt design, but handcrafting effective prompts is difficult and often requires intricate crafting of few-shot examples. We propose a fast automatic prompt construction algorithm that augments human instructions by generating a small set of few shot examples. Our method iteratively replaces/drops/keeps few-shot examples using Monte Carlo Shapley estimation of example utility. For faster execution, we use aggressive subsampling and a replay buffer for faster evaluations. Our method can be run using different compute time budgets. On a limited budget, we outperform existing automatic prompting methods on text simplification and GSM8K and obtain second best results on classification and summarization. With an extended, but still modest compute budget we set a new state of the art among automatic prompting methods on classification, simplification and GSM8K. Our results show that carefully constructed examples, rather than exhaustive instruction search, are the dominant lever for fast and data efficient prompt engineering. Our code is available at https://github.com/Batorskq/PIAST.

</details>


### [97] [MultiScript30k: Leveraging Multilingual Embeddings to Extend Cross Script Parallel Data](https://arxiv.org/abs/2512.11074)
*Christopher Driggers-Ellis,Detravious Brinkley,Ray Chen,Aashish Dhawan,Daisy Zhe Wang,Christan Grant*

Main category: cs.CL

TL;DR: 本文提出了MultiScript30k，一个扩展自Multi30k的多语言、多文字机器翻译数据集，支持阿拉伯语、西班牙语、乌克兰语、简体中文和繁体中文，旨在弥补现有MMT数据集语言覆盖不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有Multi30k数据集仅涵盖四种欧洲语言（捷克语、英语、法语、德语），且均使用拉丁字母，限制了多模态机器翻译（MMT）在更广泛语言和文字系统上的研究进展。

Method: 利用NLLB200-3.3B模型将Multi30k英文版（Multi30k-En）翻译为阿拉伯语（Ar）、西班牙语（Es）、乌克兰语（Uk）、简体中文（Zh_Hans）和繁体中文（Zh_Hant），构建MultiScript30k；并通过余弦相似度、对称KL散度及COMETKiwi指标评估翻译质量。

Result: MultiScript30k包含超3万句平行语料；除Zh_Hant外，其余语言翻译与源文本相似度均>0.8、KL散度<0.000251；COMETKiwi评估显示其翻译质量整体良好，但Uk语种略逊于已有Multi30k-Uk（低6.4%）。

Conclusion: MultiScript30k显著拓展了MMT可用语言和文字覆盖范围，为非拉丁语系及全球多样性语言的多模态翻译研究提供了高质量新基准数据集。

Abstract: Multi30k is frequently cited in the multimodal machine translation (MMT) literature, offering parallel text data for training and fine-tuning deep learning models. However, it is limited to four languages: Czech, English, French, and German. This restriction has led many researchers to focus their investigations only on these languages. As a result, MMT research on diverse languages has been stalled because the official Multi30k dataset only represents European languages in Latin scripts. Previous efforts to extend Multi30k exist, but the list of supported languages, represented language families, and scripts is still very short. To address these issues, we propose MultiScript30k, a new Multi30k dataset extension for global languages in various scripts, created by translating the English version of Multi30k (Multi30k-En) using NLLB200-3.3B. The dataset consists of over \(30000\) sentences and provides translations of all sentences in Multi30k-En into Ar, Es, Uk, Zh\_Hans and Zh\_Hant. Similarity analysis shows that Multi30k extension consistently achieves greater than \(0.8\) cosine similarity and symmetric KL divergence less than \(0.000251\) for all languages supported except Zh\_Hant which is comparable to the previous Multi30k extensions ArEnMulti30k and Multi30k-Uk. COMETKiwi scores reveal mixed assessments of MultiScript30k as a translation of Multi30k-En in comparison to the related work. ArEnMulti30k scores nearly equal MultiScript30k-Ar, but Multi30k-Uk scores $6.4\%$ greater than MultiScript30k-Uk per split.

</details>


### [98] [Applying NLP to iMessages: Understanding Topic Avoidance, Responsiveness, and Sentiment](https://arxiv.org/abs/2512.11079)
*Alan Gerber,Sam Cooperman*

Main category: cs.CL

TL;DR: 本文介绍了一个iMessage文本消息分析器，旨在通过分析本地存储的iMessage数据文件，回答有关主题建模、响应时间、犹豫评分和情感分析等五个研究问题。


<details>
  <summary>Details</summary>
Motivation: 随着社会对短格式电子通信依赖增加，了解消息平台收集的数据及其潜在用途变得重要；苹果开放了Mac上iMessage本地数据文件的访问权限，为用户自主分析提供了可能。

Method: 开发了一个iMessage文本消息分析器，基于本地存储的iMessage数据文件，进行主题建模、响应时间统计、犹豫评分计算和情感分析等探索性数据分析。

Result: 展示了分析器如何回答五个核心研究问题，并验证了其在iMessage数据未来研究中的潜力。

Conclusion: 该分析器为用户提供了理解和利用自身iMessage数据的新工具，有助于推动个人通信数据的自主分析与相关学术研究。

Abstract: What is your messaging data used for? While many users do not often think about the information companies can gather based off of their messaging platform of choice, it is nonetheless important to consider as society increasingly relies on short-form electronic communication. While most companies keep their data closely guarded, inaccessible to users or potential hackers, Apple has opened a door to their walled-garden ecosystem, providing iMessage users on Mac with one file storing all their messages and attached metadata. With knowledge of this locally stored file, the question now becomes: What can our data do for us? In the creation of our iMessage text message analyzer, we set out to answer five main research questions focusing on topic modeling, response times, reluctance scoring, and sentiment analysis. This paper uses our exploratory data to show how these questions can be answered using our analyzer and its potential in future studies on iMessage data.

</details>


### [99] [Explanation Bias is a Product: Revealing the Hidden Lexical and Position Preferences in Post-Hoc Feature Attribution](https://arxiv.org/abs/2512.11108)
*Jonathan Kamp,Roos Bakker,Dominique Blok*

Main category: cs.CL

TL;DR: 本文提出一个模型和方法无关的框架，通过三个评估指标系统分析特征归因方法（如Integrated Gradient）在词法和位置上的偏差，并在人工与自然数据上验证了不同模型间偏差的结构性不平衡。


<details>
  <summary>Details</summary>
Motivation: 不同特征归因方法对同一输入可能产生差异巨大的解释，导致用户信任问题；需深入理解其内在偏差机制。

Method: 构建模型与方法无关的三指标评估框架，分别量化词法偏差（what）和位置偏差（where），并在人工伪随机分类任务与自然语言因果关系检测任务中对两类Transformer模型进行系统评估。

Result: 发现词法偏差与位置偏差在模型间呈结构性不平衡（高词法偏差对应低位置偏差）；异常解释产出的方法自身更可能具有偏差。

Conclusion: 特征归因方法的偏差具有结构性规律，需在解释可靠性评估中同时考量词法与位置维度，且方法自身偏差会影响解释质量。

Abstract: Good quality explanations strengthen the understanding of language models and data. Feature attribution methods, such as Integrated Gradient, are a type of post-hoc explainer that can provide token-level insights. However, explanations on the same input may vary greatly due to underlying biases of different methods. Users may be aware of this issue and mistrust their utility, while unaware users may trust them inadequately. In this work, we delve beyond the superficial inconsistencies between attribution methods, structuring their biases through a model- and method-agnostic framework of three evaluation metrics. We systematically assess both the lexical and position bias (what and where in the input) for two transformers; first, in a controlled, pseudo-random classification task on artificial data; then, in a semi-controlled causal relation detection task on natural data. We find that lexical and position biases are structurally unbalanced in our model comparison, with models that score high on one type score low on the other. We also find signs that methods producing anomalous explanations are more likely to be biased themselves.

</details>


### [100] [FIBER: A Multilingual Evaluation Resource for Factual Inference Bias](https://arxiv.org/abs/2512.11110)
*Evren Ayberk Munis,Deniz Yılmaz,Arianna Muti,Çağrı Toraman*

Main category: cs.CL

TL;DR: 本文提出了FIBER，一个用于评估大语言模型在单实体和多实体场景下事实知识的多语言基准测试，涵盖英语、意大利语和土耳其语。研究发现提示语言会影响模型对特定国家相关实体的选择（即推理偏差），且该偏差因主题和语言而异；此外，模型在处理多实体问题时表现更差，且性能随语言和模型规模变化。


<details>
  <summary>Details</summary>
Motivation: 现有事实知识评测基准主要关注单实体和单语种数据，缺乏对多语言及多实体场景的系统评估，因此需要构建更全面的评测基准以揭示模型的事实可靠性与语言相关偏差。

Method: 构建多语言（英语、意大利语、土耳其语）、多任务（句子补全、问答、物体计数）的FIBER基准；设计实验分析提示语言对实体选择的推理偏差、多/单实体问题难度差异，并在不同语言和模型规模上评估性能。

Result: 提示语言会引发事实推理偏差（31%主题偏差分>0.5），且土耳其语提示比意大利语更具偏差（83%主题）；模型在多实体问题上表现更差；英文表现最优，土耳其语和意大利语次之；大模型（如Llama-3.1-8B、Qwen-2.5-7B）显著优于小模型（3B–4B）。

Conclusion: FIBER揭示了大语言模型在多语言、多实体事实推理中的系统性偏差与性能局限，强调需在多样化语言和复杂事实结构下持续评估模型可靠性。

Abstract: Large language models are widely used across domains, yet there are concerns about their factual reliability and biases. Factual knowledge probing offers a systematic means to evaluate these aspects. Most existing benchmarks focus on single-entity facts and monolingual data. We therefore present FIBER, a multilingual benchmark for evaluating factual knowledge in single- and multi-entity settings. The dataset includes sentence completion, question-answering, and object-count prediction tasks in English, Italian, and Turkish. Using FIBER, we examine whether the prompt language induces inference bias in entity selection and how large language models perform on multi-entity versus single-entity questions. The results indicate that the language of the prompt can influence the model's generated output, particularly for entities associated with the country corresponding to that language. However, this effect varies across different topics such that 31% of the topics exhibit factual inference bias score greater than 0.5. Moreover, the level of bias differs across languages such that Turkish prompts show higher bias compared to Italian in 83% of the topics, suggesting a language-dependent pattern. Our findings also show that models face greater difficulty when handling multi-entity questions than the single-entity questions. Model performance differs across both languages and model sizes. The highest mean average precision is achieved in English, while Turkish and Italian lead to noticeably lower scores. Larger models, including Llama-3.1-8B and Qwen-2.5-7B, show consistently better performance than smaller 3B-4B models.

</details>


### [101] [SciLaD: A Large-Scale, Transparent, Reproducible Dataset for Natural Scientific Language Processing](https://arxiv.org/abs/2512.11192)
*Luca Foppiano,Sotaro Takeshita,Pedro Ortiz Suarez,Ekaterina Borisova,Raia Abu Ahmad,Malte Ostendorff,Fabio Barth,Julian Moreno-Schneider,Georg Rehm*

Main category: cs.CL

TL;DR: SciLaD is a large-scale, open-source scientific language dataset with English and multilingual splits, accompanied by an extensible construction pipeline and pre-trained RoBERTa model showing competitive performance on scientific NLP benchmarks.


<details>
  <summary>Details</summary>
Motivation: To enable large-scale, high-quality scientific data curation using open-source tools and publicly available data, promoting reproducibility and advancement in scientific language processing.

Method: Constructing SciLaD using open-source frameworks and public data sources; curating English (10M+ papers) and multilingual TEI XML (35M+ papers) splits; developing an extensible pipeline; pre-training and evaluating a RoBERTa model on scientific NLP benchmarks.

Result: A high-quality, large-scale scientific language dataset (SciLaD) with two major splits; a publicly released construction pipeline; and a pre-trained RoBERTa model achieving performance comparable to similar-sized scientific language models.

Conclusion: SciLaD demonstrates that open-source tools can effectively support scalable, transparent, and reproducible scientific data curation, and the dataset is a valuable resource for advancing natural scientific language processing and scholarly document understanding.

Abstract: SciLaD is a novel, large-scale dataset of scientific language constructed entirely using open-source frameworks and publicly available data sources. It comprises a curated English split containing over 10 million scientific publications and a multilingual, unfiltered TEI XML split including more than 35 million publications. We also publish the extensible pipeline for generating SciLaD. The dataset construction and processing workflow demonstrates how open-source tools can enable large-scale, scientific data curation while maintaining high data quality. Finally, we pre-train a RoBERTa model on our dataset and evaluate it across a comprehensive set of benchmarks, achieving performance comparable to other scientific language models of similar size, validating the quality and utility of SciLaD. We publish the dataset and evaluation pipeline to promote reproducibility, transparency, and further research in natural scientific language processing and understanding including scholarly document processing.

</details>


### [102] [Multi-Intent Spoken Language Understanding: Methods, Trends, and Challenges](https://arxiv.org/abs/2512.11258)
*Di Wu,Ruiyu Fang,Liting Jiang,Shuangyong Song,Xiaomeng Huang,Shiquan Wang,Zhongqiu Li,Lingling Shi,Mengjiao Bao,Yongxiang Li,Hao Huang*

Main category: cs.CL

TL;DR: This paper provides a comprehensive survey of recent advances in multi-intent spoken language understanding (SLU), analyzing decoding paradigms and modeling approaches, comparing model performance, and discussing challenges and future directions.


<details>
  <summary>Details</summary>
Motivation: There is a lack of a comprehensive and systematic review of existing studies on multi-intent SLU, despite its growing research attention and real-world relevance.

Method: The paper conducts a survey by categorizing and analyzing prior work from two perspectives—decoding paradigms and modeling approaches—and compares representative models’ performance while identifying their strengths and limitations.

Result: A structured overview of multi-intent SLU research is provided, including comparative analysis of models and identification of current challenges and promising future research directions.

Conclusion: This survey aims to serve as a valuable reference and insight source for advancing multi-intent SLU research.

Abstract: Multi-intent spoken language understanding (SLU) involves two tasks: multiple intent detection and slot filling, which jointly handle utterances containing more than one intent. Owing to this characteristic, which closely reflects real-world applications, the task has attracted increasing research attention, and substantial progress has been achieved. However, there remains a lack of a comprehensive and systematic review of existing studies on multi-intent SLU. To this end, this paper presents a survey of recent advances in multi-intent SLU. We provide an in-depth overview of previous research from two perspectives: decoding paradigms and modeling approaches. On this basis, we further compare the performance of representative models and analyze their strengths and limitations. Finally, we discuss the current challenges and outline promising directions for future research. We hope this survey will offer valuable insights and serve as a useful reference for advancing research in multi-intent SLU.

</details>


### [103] [Leveraging LLMs for Title and Abstract Screening for Systematic Review: A Cost-Effective Dynamic Few-Shot Learning Approach](https://arxiv.org/abs/2512.11261)
*Yun-Chung Liu,Rui Yang,Jonathan Chong Kai Liew,Ziran Yin,Henry Foote,Christopher J. Lindsell,Chuan Hong*

Main category: cs.CL

TL;DR: 本文提出了一种两阶段动态少样本学习（DFSL）方法，利用低成本和高性能大语言模型分阶段进行系统综述中的标题与摘要筛选，以提升效率与性能并控制计算成本。


<details>
  <summary>Details</summary>
Motivation: 系统综述中标题与摘要筛选步骤耗时耗力，而文献数量激增加剧了这一负担，亟需高效、低成本的自动化辅助方法。

Method: 提出两阶段动态少样本学习（DFSL）框架：第一阶段用低成本LLM进行初步筛选；第二阶段对低置信度样本调用高性能LLM复核。

Result: 在10个系统综述数据集上的实验表明该方法具有强泛化能力与成本效益，可显著降低人工筛查负担。

Conclusion: DFSL方法在保证筛选质量的同时有效平衡性能与计算开销，具备实际推广应用价值。

Abstract: Systematic reviews are a key component of evidence-based medicine, playing a critical role in synthesizing existing research evidence and guiding clinical decisions. However, with the rapid growth of research publications, conducting systematic reviews has become increasingly burdensome, with title and abstract screening being one of the most time-consuming and resource-intensive steps. To mitigate this issue, we designed a two-stage dynamic few-shot learning (DFSL) approach aimed at improving the efficiency and performance of large language models (LLMs) in the title and abstract screening task. Specifically, this approach first uses a low-cost LLM for initial screening, then re-evaluates low-confidence instances using a high-performance LLM, thereby enhancing screening performance while controlling computational costs. We evaluated this approach across 10 systematic reviews, and the results demonstrate its strong generalizability and cost-effectiveness, with potential to reduce manual screening burden and accelerate the systematic review process in practical applications.

</details>


### [104] [When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents](https://arxiv.org/abs/2512.11277)
*Mrinal Rawat,Arkajyoti Chakraborty,Neha Gupta,Roberto Pieraccini*

Main category: cs.CL

TL;DR: 本文提出一种基于强化学习（RL）的推理与动作联合学习方法，通过Group Relative Policy Optimization（GRPO）优化模型的推理步骤和工具调用，显著提升对话智能体在分布偏移下的泛化能力与可靠性，无需依赖昂贵的人工推理标注。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）泛化能力弱，尤其在数据分布变化时；高质量人工推理标注成本高、主观性强、难扩展；而推理能力对泛化与可靠性至关重要。

Method: 采用强化学习框架，设计包含工具准确率和答案正确性双目标的奖励函数，利用Group Relative Policy Optimization（GRPO）优化LLM生成的推理步骤，使其同时指导工具调用与最终答案生成。

Result: 在Qwen3-1.7B模型上，相较无显式推理的SFT基线提升1.5%相对性能，相较原始基础模型提升40%；同时提升了推理质量与工具调用精度。

Conclusion: 将推理与动作学习统一于RL框架是构建更强大、更泛化对话智能体的有效路径，可规避对人工推理标注的依赖。

Abstract: Supervised fine-tuning (SFT) has emerged as one of the most effective ways to improve the performance of large language models (LLMs) in downstream tasks. However, SFT can have difficulty generalizing when the underlying data distribution changes, even when the new data does not fall completely outside the training domain. Recent reasoning-focused models such as o1 and R1 have demonstrated consistent gains over their non-reasoning counterparts, highlighting the importance of reasoning for improved generalization and reliability. However, collecting high-quality reasoning traces for SFT remains challenging -- annotations are costly, subjective, and difficult to scale. To address this limitation, we leverage Reinforcement Learning (RL) to enable models to learn reasoning strategies directly from task outcomes. We propose a pipeline in which LLMs generate reasoning steps that guide both the invocation of tools (e.g., function calls) and the final answer generation for conversational agents. Our method employs Group Relative Policy Optimization (GRPO) with rewards designed around tool accuracy and answer correctness, allowing the model to iteratively refine its reasoning and actions. Experimental results demonstrate that our approach improves both the quality of reasoning and the precision of tool invocations, achieving a 1.5% relative improvement over the SFT model (trained without explicit thinking) and a 40% gain compared to the base of the vanilla Qwen3-1.7B model. These findings demonstrate the promise of unifying reasoning and action learning through RL to build more capable and generalizable conversational agents.

</details>


### [105] [AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference](https://arxiv.org/abs/2512.11280)
*Kuan-Wei Lu,Ding-Yong Hong,Pangfeng Liu*

Main category: cs.CL

TL;DR: 本文提出了一种无需超参数调优的自适应推测解码方法AdaSD，通过实时调整生成长度和接受标准，在不牺牲太多精度的前提下显著加速大语言模型推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）推理速度慢，现有推测解码方法依赖额外训练、大量超参调优或先验分析，部署复杂。

Method: 提出自适应推测解码（AdaSD），引入两个基于token熵和Jensen-Shannon距离实时更新的动态阈值，分别控制候选token生成终止与接受决策，无需预分析或微调。

Result: 在基准数据集上，AdaSD相比标准推测解码最高提速49%，精度损失控制在2%以内。

Conclusion: AdaSD是一种实用、高效且即插即用的大模型自适应推理方案。

Abstract: Large language models (LLMs) have achieved remarkable performance across a wide range of tasks, but their increasing parameter sizes significantly slow down inference. Speculative decoding mitigates this issue by leveraging a smaller draft model to predict candidate tokens, which are then verified by a larger target model. However, existing approaches often require additional training, extensive hyperparameter tuning, or prior analysis of models and tasks before deployment. In this paper, we propose Adaptive Speculative Decoding (AdaSD), a hyperparameter-free decoding scheme that dynamically adjusts generation length and acceptance criteria during inference. AdaSD introduces two adaptive thresholds: one to determine when to stop candidate token generation and another to decide token acceptance, both updated in real time based on token entropy and Jensen-Shannon distance. This approach eliminates the need for pre-analysis or fine-tuning and is compatible with off-the-shelf models. Experiments on benchmark datasets demonstrate that AdaSD achieves up to 49\% speedup over standard speculative decoding while limiting accuracy degradation to under 2\%, making it a practical solution for efficient and adaptive LLM inference.

</details>


### [106] [CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise](https://arxiv.org/abs/2512.11282)
*Qingsen Ma,Dianyun Wang,Ran Jing,Yujun Sun,Zhenbo Xu*

Main category: cs.CL

TL;DR: 本文提出CIP因果提示框架，通过在输入阶段注入因果关系序列来缓解大语言模型在长而嘈杂检索上下文中的幻觉问题，显著提升事实准确性、因果一致性与推理效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长且嘈杂的检索上下文时易因依赖虚假相关性而非真实因果关系而产生幻觉。

Method: CIP构建实体、动作与事件间的因果关系序列，并将其注入提示中；结合因果干预与反事实推理，抑制非因果推理路径。

Result: 在GPT-4o、Gemini 2.0 Flash、Llama 3.1等7个主流模型上，CIP使可归因率提升2.6分、因果一致性得分提升0.38、有效信息密度提高四倍，并降低端到端响应延迟最高达55.1%。

Conclusion: 因果推理是一种有前景的新范式，可提升大语言模型的可解释性、稳定性与推理效率。

Abstract: Large language models often hallucinate when processing long and noisy retrieval contexts because they rely on spurious correlations rather than genuine causal relationships. We propose CIP, a lightweight and plug-and-play causal prompting framework that mitigates hallucinations at the input stage. CIP constructs a causal relation sequence among entities, actions, and events and injects it into the prompt to guide reasoning toward causally relevant evidence. Through causal intervention and counterfactual reasoning, CIP suppresses non causal reasoning paths, improving factual grounding and interpretability. Experiments across seven mainstream language models, including GPT-4o, Gemini 2.0 Flash, and Llama 3.1, show that CIP consistently enhances reasoning quality and reliability, achieving 2.6 points improvement in Attributable Rate, 0.38 improvement in Causal Consistency Score, and a fourfold increase in effective information density. API level profiling further shows that CIP accelerates contextual understanding and reduces end to end response latency by up to 55.1 percent. These results suggest that causal reasoning may serve as a promising paradigm for improving the explainability, stability, and efficiency of large language models.

</details>


### [107] [LegalRikai: Open Benchmark -- A Benchmark for Complex Japanese Corporate Legal Tasks](https://arxiv.org/abs/2512.11297)
*Shogo Fujita,Yuji Naraki,Yiqing Zhu,Shinsuke Mori*

Main category: cs.CL

TL;DR: This paper introduces LegalRikai, an open benchmark for Japanese corporate legal tasks, designed by legal professionals. It evaluates LLMs on complex, long-form, structured outputs and finds that human evaluation reveals model weaknesses in document-level editing missed by short-text tasks; automated evaluation aligns well with human judgment for linguistically grounded criteria but struggles with structural consistency. The paper proposes a dataset evaluation framework to support practice-oriented legal AI research.


<details>
  <summary>Details</summary>
Motivation: To address the gap in evaluating LLMs on realistic, complex, and structured legal tasks—particularly in Japanese corporate legal practice—where conventional short-text benchmarks fail to expose critical model weaknesses such as document-level editing.

Method: Constructed LegalRikai: Open Benchmark—a set of four attorney-supervised, legally authentic tasks with 100 long-form, structured samples—and performed combined human and automated evaluations using top LLMs (GPT-5, Gemini 2.5 Pro, Claude Opus 4.1) across multiple practical criteria.

Result: Human evaluation uncovered model deficiencies in document-level editing triggered by abstract instructions—issues invisible to short-text tasks; automated evaluation correlated well with human judgment for linguistically grounded criteria but poorly for structural consistency; automated evaluation is validated as a useful screening tool when expert evaluators are scarce.

Conclusion: LegalRikai provides a more realistic and practice-oriented benchmark for legal LLM evaluation; combining human and automated evaluation improves assessment validity; and the proposed dataset evaluation framework advances domain-specific, application-driven AI research in law.

Abstract: This paper introduces LegalRikai: Open Benchmark, a new benchmark comprising four complex tasks that emulate Japanese corporate legal practices. The benchmark was created by legal professionals under the supervision of an attorney. This benchmark has 100 samples that require long-form, structured outputs, and we evaluated them against multiple practical criteria. We conducted both human and automated evaluations using leading LLMs, including GPT-5, Gemini 2.5 Pro, and Claude Opus 4.1. Our human evaluation revealed that abstract instructions prompted unnecessary modifications, highlighting model weaknesses in document-level editing that were missed by conventional short-text tasks. Furthermore, our analysis reveals that automated evaluation aligns well with human judgment on criteria with clear linguistic grounding, and assessing structural consistency remains a challenge. The result demonstrates the utility of automated evaluation as a screening tool when expert availability is limited. We propose a dataset evaluation framework to promote more practice-oriented research in the legal domain.

</details>


### [108] [Unifying Dynamic Tool Creation and Cross-Task Experience Sharing through Cognitive Memory Architecture](https://arxiv.org/abs/2512.11303)
*Jiarun Liu,Shiyue Xu,Yang Li,Shangkun Liu,Yongli Yu,Peng Cao*

Main category: cs.CL

TL;DR: 本文提出SMITH架构，通过分层记忆组织实现动态工具创建与跨任务经验共享，显著提升大语言模型代理在新颖任务中的适应能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理在面对新任务时面临工具可用性和经验复用的限制，现有方法要么依赖覆盖有限的预定义工具，要么从零构建工具而无法利用过往经验，导致探索效率低和性能不佳。

Method: SMITH采用统一的认知架构，将记忆分为程序性、语义性和情节性三类；工具创建被形式化为受控沙箱环境中的迭代代码生成，经验共享则通过基于语义相似度匹配的情节性记忆检索实现；并提出基于代理集成难度重评估的课程学习策略。

Result: 在GAIA基准测试中，SMITH达到81.8%的Pass@1准确率，显著优于Alita（75.2%）和Memento（70.9%）。

Conclusion: SMITH为构建真正自适应的智能体奠定了基础，使其能通过工具创建与经验积累的协同机制持续进化能力。

Abstract: Large Language Model agents face fundamental challenges in adapting to novel tasks due to limitations in tool availability and experience reuse. Existing approaches either rely on predefined tools with limited coverage or build tools from scratch without leveraging past experiences, leading to inefficient exploration and suboptimal performance. We introduce SMITH (Shared Memory Integrated Tool Hub), a unified cognitive architecture that seamlessly integrates dynamic tool creation with cross-task experience sharing through hierarchical memory organization. SMITH organizes agent memory into procedural, semantic, and episodic components, enabling systematic capability expansion while preserving successful execution patterns. Our approach formalizes tool creation as iterative code generation within controlled sandbox environments and experience sharing through episodic memory retrieval with semantic similarity matching. We further propose a curriculum learning strategy based on agent-ensemble difficulty re-estimation. Extensive experiments on the GAIA benchmark demonstrate SMITH's effectiveness, achieving 81.8% Pass@1 accuracy and outperforming state-of-the-art baselines including Alita (75.2%) and Memento (70.9%). Our work establishes a foundation for building truly adaptive agents that continuously evolve their capabilities through principled integration of tool creation and experience accumulation.

</details>


### [109] [qa-FLoRA: Data-free query-adaptive Fusion of LoRAs for LLMs](https://arxiv.org/abs/2512.11366)
*Shreya Shukla,Aditya Sriram,Milinda Kuppur Narayanaswamy,Hiteshi Jain*

Main category: cs.CL

TL;DR: 本文提出qa-FLoRA，一种无需训练、基于查询自适应的LoRA融合方法，通过度量基础模型与各适配器间的分布差异动态计算层级别融合权重，在多领域复合任务上显著优于静态融合和训练免费基线。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA融合方法要么采用静态权重（忽略各适配器在不同查询下的实际相关性），要么依赖大量监督数据为每种组合训练最优融合权重，难以应对复杂多领域复合查询。

Method: qa-FLoRA通过无监督方式，基于查询输入，逐层计算基础模型与各LoRA适配器输出的分布差异（如KL散度等），动态生成层级别融合权重，无需额外训练或复合领域数据。

Result: 在涵盖数学、编程、医疗等九个多语言复合任务上，qa-FLoRA相较静态融合提升约5%（LLaMA-2）和6%（LLaMA-3），相较训练免费基线提升约7%（LLaMA-2）和10%（LLaMA-3），并大幅缩小与监督式融合的性能差距；层权重分析还展现出可解释的融合模式。

Conclusion: qa-FLoRA是一种高效、通用、免训练的LoRA融合框架，能实现鲁棒的多领域自适应，为参数高效微调的实际部署提供了新范式。

Abstract: The deployment of large language models for specialized tasks often requires domain-specific parameter-efficient finetuning through Low-Rank Adaptation (LoRA) modules. However, effectively fusing these adapters to handle complex, multi-domain composite queries remains a critical challenge. Existing LoRA fusion approaches either use static weights, which assign equal relevance to each participating LoRA, or require data-intensive supervised training for every possible LoRA combination to obtain respective optimal fusion weights. We propose qa-FLoRA, a novel query-adaptive data-and-training-free method for LoRA fusion that dynamically computes layer-level fusion weights by measuring distributional divergence between the base model and respective adapters. Our approach eliminates the need for composite training data or domain-representative samples, making it readily applicable to existing adapter collections. Extensive experiments across nine multilingual composite tasks spanning mathematics, coding, and medical domains, show that qa-FLoRA outperforms static fusion by ~5% with LLaMA-2 and ~6% with LLaMA-3, and the training-free baselines by ~7% with LLaMA-2 and ~10% with LLaMA-3, while significantly closing the gap with supervised baselines. Further, layer-level analysis of our fusion weights reveals interpretable fusion patterns, demonstrating the effectiveness of our approach for robust multi-domain adaptation.

</details>


### [110] [Mining Legal Arguments to Study Judicial Formalism](https://arxiv.org/abs/2512.11374)
*Tomáš Koref,Lena Held,Mahammad Namazov,Harun Kumru,Yassine Thlija,Christoph Burchard,Ivan Habernal*

Main category: cs.CL

TL;DR: 本文通过构建MADON数据集和适配捷克法律领域的Transformer模型，实现了对捷克最高法院判决中司法推理的自动识别与分类，挑战了中东欧地区‘形式主义司法’的既有观点。


<details>
  <summary>Details</summary>
Motivation: 系统性大规模分析司法推理困难，且学界对中东欧地区（CEE）存在‘形式主义司法’的普遍论断缺乏实证支持。

Method: 构建含9183个段落标注的MADON数据集（272份判决），在30万份捷克判决语料上对Transformer模型进行领域持续预训练，并采用非对称损失、类别加权等方法缓解数据不平衡；提出结合ModernBERT、Llama 3.1与传统特征机器学习的三阶段可解释管道。

Result: 最佳模型在论证段落检测（82.6% macro-F1）、法律论证类型分类（77.5% macro-F1）和形式主义/非形式主义判决分类（83.2% macro-F1）上均取得良好效果。

Conclusion: 法律论证挖掘可可靠识别法官哲学倾向，挑战CEE形式主义叙事；该方法具跨司法管辖区可复现性，全部资源开源。

Abstract: Courts must justify their decisions, but systematically analyzing judicial reasoning at scale remains difficult. This study refutes claims about formalistic judging in Central and Eastern Europe (CEE) by developing automated methods to detect and classify judicial reasoning in Czech Supreme Courts' decisions using state-of-the-art natural language processing methods. We create the MADON dataset of 272 decisions from two Czech Supreme Courts with expert annotations of 9,183 paragraphs with eight argument types and holistic formalism labels for supervised training and evaluation. Using a corpus of 300k Czech court decisions, we adapt transformer LLMs for Czech legal domain by continued pretraining and experiment with methods to address dataset imbalance including asymmetric loss and class weighting. The best models successfully detect argumentative paragraphs (82.6\% macro-F1), classify traditional types of legal argument (77.5\% macro-F1), and classify decisions as formalistic/non-formalistic (83.2\% macro-F1). Our three-stage pipeline combining ModernBERT, Llama 3.1, and traditional feature-based machine learning achieves promising results for decision classification while reducing computational costs and increasing explainability. Empirically, we challenge prevailing narratives about CEE formalism. This work shows that legal argument mining enables reliable judicial philosophy classification and shows the potential of legal argument mining for other important tasks in computational legal studies. Our methodology is easily replicable across jurisdictions, and our entire pipeline, datasets, guidelines, models, and source codes are available at https://github.com/trusthlt/madon.

</details>


### [111] [Improving Translation Quality by Selecting Better Data for LLM Fine-Tuning: A Comparative Analysis](https://arxiv.org/abs/2512.11388)
*Felipe Ribeiro Fujita de Mello,Hideyuki Takada*

Main category: cs.CL

TL;DR: 本文研究了数据选择对开源大语言模型机器翻译微调的影响，发现语义选择器（如COMET Kiwi、QuRate）显著优于基于词法或几何的启发式方法，且即使所选数据差异小于3%，性能影响也很大，凸显数据质量对微调效果的高度敏感性。


<details>
  <summary>Details</summary>
Motivation: 探究数据选择策略对开源大语言模型在机器翻译任务上微调效果的影响，尤其是不同选择器对最终性能的敏感性和有效性。

Method: 在日英双语语料上，对比五种数据选择器（TF-IDF、COMET Kiwi、QuRate、FD-Score 和随机选择），在严格控制训练条件的前提下进行微调实验。

Result: 语义选择器（COMET Kiwi、QuRate）持续优于词法（TF-IDF）和几何启发式（FD-Score）方法；即使所选数据重合度高于97%，性能差异仍显著。

Conclusion: 数据选择的质量对LLM机器翻译微调效果极为关键，语义感知的选择策略更有效，微调过程对训练数据构成高度敏感。

Abstract: We investigated the impact of data selection on machine translation fine-tuning for open LLMs. Using Japanese-English corpora, we compare five selectors: TF-IDF, COMET Kiwi, QuRate, FD-Score, and random selection, under controlled training conditions. We observed that semantic selectors consistently outperform lexical and geometry-based heuristics, and that even when the selected data differ by less than 3%, the impact on model performance is substantial, underscoring the sensitivity of fine-tuning to data quality.

</details>


### [112] [Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction](https://arxiv.org/abs/2512.11399)
*Galann Pennec,Zhengyuan Liu,Nicholas Asher,Philippe Muller,Nancy F. Chen*

Main category: cs.CL

TL;DR: 本文提出了一种针对长视频的剪辑选择方法，通过轻量级视频字幕模型生成各片段描述，并利用大语言模型（LLM）筛选出K个最相关片段用于构建多模态摘要，在保持低计算成本的同时接近人工标注参考片段的摘要性能。


<details>
  <summary>Details</summary>
Motivation: VLMs处理长视频时易丢失关键视觉信息，且需低成本分析工具；现有方法难以兼顾信息完整性与计算效率。

Method: 将视频分段，用轻量级视频字幕模型生成每段紧凑视觉描述，再由LLM选择K个最相关片段构成多模态摘要。

Result: 在MovieSum数据集上，所选片段（<6%时长）即可实现接近全片人工标注参考片段的摘要性能，显著优于随机采样，且计算开销低。

Conclusion: 该剪辑选择方法能高效提取关键视觉时刻，支撑高质量、低成本的长视频多模态摘要生成。

Abstract: Vision-Language Models (VLMs) are able to process increasingly longer videos. Yet, important visual information is easily lost throughout the entire context and missed by VLMs. Also, it is important to design tools that enable cost-effective analysis of lengthy video content. In this paper, we propose a clip selection method that targets key video moments to be included in a multimodal summary. We divide the video into short clips and generate compact visual descriptions of each using a lightweight video captioning model. These are then passed to a large language model (LLM), which selects the K clips containing the most relevant visual information for a multimodal summary. We evaluate our approach on reference clips for the task, automatically derived from full human-annotated screenplays and summaries in the MovieSum dataset. We further show that these reference clips (less than 6% of the movie) are sufficient to build a complete multimodal summary of the movies in MovieSum. Using our clip selection method, we achieve a summarization performance close to that of these reference clips while capturing substantially more relevant video information than random clip selection. Importantly, we maintain low computational cost by relying on a lightweight captioning model.

</details>


### [113] [CLINIC: Evaluating Multilingual Trustworthiness in Language Models for Healthcare](https://arxiv.org/abs/2512.11437)
*Akash Ghosh,Srivarshinee Sridhar,Raghav Kaushik Ravi,Muhsin Muhsin,Sriparna Saha,Chirag Agarwal*

Main category: cs.CL

TL;DR: 本文提出CLINIC——一个面向多语言医疗场景的语言模型可信度综合评测基准，涵盖真实性、公平性、安全性、鲁棒性和隐私性五大维度、18项任务、15种语言及广泛医疗主题，揭示现有模型在事实性、偏见、隐私与对抗攻击方面的严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型主要在高资源语言上训练，难以应对中低资源语言的医疗查询复杂性与多样性，缺乏对其在全球多语言医疗场景中可信度的可靠评估。

Method: 构建CLINIC多语言医疗可信度评测基准，覆盖5个可信维度、18个任务、15种语言（涵盖各大洲）及多种关键医疗主题，并对主流语言模型进行系统评测。

Result: 实验表明，当前语言模型在事实正确性、跨人口与语言群体的公平性、隐私保护及对抗鲁棒性方面均存在显著缺陷。

Conclusion: CLINIC为提升语言模型在全球多语言医疗环境中的安全性和适用性奠定了基础，推动可信、公平、稳健的医疗AI发展。

Abstract: Integrating language models (LMs) in healthcare systems holds great promise for improving medical workflows and decision-making. However, a critical barrier to their real-world adoption is the lack of reliable evaluation of their trustworthiness, especially in multilingual healthcare settings. Existing LMs are predominantly trained in high-resource languages, making them ill-equipped to handle the complexity and diversity of healthcare queries in mid- and low-resource languages, posing significant challenges for deploying them in global healthcare contexts where linguistic diversity is key. In this work, we present CLINIC, a Comprehensive Multilingual Benchmark to evaluate the trustworthiness of language models in healthcare. CLINIC systematically benchmarks LMs across five key dimensions of trustworthiness: truthfulness, fairness, safety, robustness, and privacy, operationalized through 18 diverse tasks, spanning 15 languages (covering all the major continents), and encompassing a wide array of critical healthcare topics like disease conditions, preventive actions, diagnostic tests, treatments, surgeries, and medications. Our extensive evaluation reveals that LMs struggle with factual correctness, demonstrate bias across demographic and linguistic groups, and are susceptible to privacy breaches and adversarial attacks. By highlighting these shortcomings, CLINIC lays the foundation for enhancing the global reach and safety of LMs in healthcare across diverse languages.

</details>


### [114] [Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning](https://arxiv.org/abs/2512.11485)
*Xuanbo Su,Yingfang Zhang,Hao Luo,Xiaoteng Liu,Leo Huang*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的 Mistake Notebook Learning（MNL）框架，通过批处理方式抽象错误模式、动态存储有效指导并用保留验证确保性能单调提升，在多个复杂推理任务上显著优于现有无训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型任务适配方法存在明显缺陷：梯度微调计算开销大且易灾难性遗忘；上下文学习鲁棒性差、错误学习能力弱。

Method: MNL是一种无训练框架，核心是构建一个持久化的抽象错误模式知识库；采用批处理级错误抽象，从多次失败中提取可泛化的指导策略；将有效策略存入动态Notebook，并通过保留集验证仅保留能超越基线的策略，确保性能单调提升。

Result: MNL在GSM8K上达到93.9%准确率（接近监督微调的94.3%），并在GSM8K、Spider、AIME和KaggleDBQA上全面超越其他无训练方法；在KaggleDBQA（Qwen3-8B）上达28%准确率，相对提升47%，显著优于Memento（15.1%）和Training-Free GRPO（22.1%）。

Conclusion: MNL是一种高效、鲁棒且无需训练的复杂推理适配新范式，为大模型轻量适配提供了强竞争力的替代方案。

Abstract: Large language models (LLMs) adapt to tasks via gradient fine-tuning (heavy computation, catastrophic forgetting) or In-Context Learning (ICL: low robustness, poor mistake learning). To fix this, we introduce Mistake Notebook Learning (MNL), a training-free framework with a persistent knowledge base of abstracted error patterns. Unlike prior instance/single-trajectory memory methods, MNL uses batch-wise error abstraction: it extracts generalizable guidance from multiple failures, stores insights in a dynamic notebook, and retains only baseline-outperforming guidance via hold-out validation (ensuring monotonic improvement). We show MNL nearly matches Supervised Fine-Tuning (93.9% vs 94.3% on GSM8K) and outperforms training-free alternatives on GSM8K, Spider, AIME, and KaggleDBQA. On KaggleDBQA (Qwen3-8B), MNL hits 28% accuracy (47% relative gain), outperforming Memento (15.1%) and Training-Free GRPO (22.1) - proving it's a strong training-free alternative for complex reasoning.

</details>


### [115] [Building Patient Journeys in Hebrew: A Language Model for Clinical Timeline Extraction](https://arxiv.org/abs/2512.11502)
*Kai Golan Hashiloni,Brenda Kasabe Nokai,Michal Shevach,Esthy Shemesh,Ronit Bartin,Anna Bergrin,Liran Harel,Nachum Dershowitz,Liat Nadai Arad,Kfir Bar*

Main category: cs.CL

TL;DR: 本文提出了一种基于DictaBERT 2.0持续预训练的新型希伯来语医学语言模型，用于从电子健康记录中提取结构化临床时间线，构建患者旅程，并在两个新构建的希伯来语临床时序关系数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为支持希伯来语医疗文本中临床事件时间关系的自动抽取，构建患者全病程视图，并兼顾隐私保护（如去标识化）与模型性能的平衡。

Method: 以DictaBERT 2.0为基础模型，在五百万份去标识化医院记录上进行持续预训练；构建两个面向时间关系标注的新希伯来语临床数据集（内科/急诊、肿瘤科）；评估词汇适配与去标识化对性能的影响。

Result: 该模型在两个新数据集上均取得优异性能；词汇适配提升了token效率；去标识化处理未损害下游任务表现。

Conclusion: 持续预训练结合领域适配可有效提升希伯来语医学NLP能力；去标识化数据可用于高性能、隐私合规的模型开发；模型已开源供研究使用（含伦理限制）。

Abstract: We present a new Hebrew medical language model designed to extract structured clinical timelines from electronic health records, enabling the construction of patient journeys. Our model is based on DictaBERT 2.0 and continually pre-trained on over five million de-identified hospital records. To evaluate its effectiveness, we introduce two new datasets -- one from internal medicine and emergency departments, and another from oncology -- annotated for event temporal relations. Our results show that our model achieves strong performance on both datasets. We also find that vocabulary adaptation improves token efficiency and that de-identification does not compromise downstream performance, supporting privacy-conscious model development. The model is made available for research use under ethical restrictions.

</details>


### [116] [Does Less Hallucination Mean Less Creativity? An Empirical Investigation in LLMs](https://arxiv.org/abs/2512.11509)
*Mohor Banerjee,Nadya Yuki Wangsajaya,Syed Ali Redha Alsagoff,Min Sen Tan,Zachary Choy Kit Chun,Alvin Chan Guo Wei*

Main category: cs.CL

TL;DR: 本文研究了三种减少大语言模型幻觉的技术（CoVe、DoLa、RAG）对创造力的影响，发现它们对发散性思维具有相反作用：CoVe增强、DoLa抑制、RAG影响微弱。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉抑制方法对创造性生成的影响尚不明确，而AI辅助科学发现既需事实准确性又需创造性假设生成，因此需探究二者平衡。

Method: 在多个模型家族（LLaMA、Qwen、Mistral）和不同规模（1B–70B参数）上，采用Chain of Verification（CoVe）、Decoding by Contrasting Layers（DoLa）和Retrieval-Augmented Generation（RAG）三种方法，并在NeoCoder和CS4两个创造力基准上评估其对发散创造力的影响。

Result: CoVe提升发散性思维，DoLa抑制发散性思维，RAG影响不显著；该效应在不同模型和规模上具有一致性。

Conclusion: 幻觉抑制方法对创造力影响各异，应根据科学应用场景中对准确性与创造性权衡的需求，有针对性地选择合适方法。

Abstract: Large Language Models (LLMs) exhibit remarkable capabilities in natural language understanding and reasoning, but suffer from hallucination: the generation of factually incorrect content. While numerous methods have been developed to reduce hallucinations, their impact on creative generations remains unexplored. This gap is particularly critical for AI-assisted scientific discovery, which requires both factual accuracy and creative hypothesis generation. We investigate how three hallucination-reduction techniques: Chain of Verification (CoVe), Decoding by Contrasting Layers (DoLa), and Retrieval-Augmented Generation (RAG), affect creativity in LLMs. Evaluating multiple model families (LLaMA, Qwen, Mistral) at varying scales (1B - 70B parameters) on two creativity benchmarks (NeoCoder and CS4), we find that these methods have opposing effects on divergent creativity. CoVe enhances divergent thinking, DoLa suppresses it, and RAG shows minimal impact. Our findings provide guidance for selecting appropriate hallucination-reduction methods in scientific applications, where the balance between factual accuracy and creative exploration is crucial.

</details>


### [117] [Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet](https://arxiv.org/abs/2512.11567)
*Mevlüt Bagci,Ali Abusaleh,Daniel Baumartz,Giueseppe Abrami,Maxim Konca,Alexander Mehler*

Main category: cs.CL

TL;DR: 本文介绍了MultiParTweet，一个多语言推特语料库，连接了政客的社交媒体话语与德国议会语料库GerParCor，并通过多种文本模型和一个视觉-语言模型（VLM）进行情绪、情感和主题标注；同时提供了数据采集工具TTLABTweetCrawler，并验证了模型间可预测性及VLM标注更符合人类判断。


<details>
  <summary>Details</summary>
Motivation: 构建可比语料库以分析政客在线交流与议会辩论的异同，并提升社交媒体内容（含图文）的自动标注质量与人类一致性。

Method: 构建MultiParTweet推特语料库（含39546条推文及19056个媒体项），集成9个文本模型和1个视觉-语言模型（VLM）进行多维自动标注，并在人工标注子集上评估；开发TTLABTweetCrawler工具支持X平台数据重建；开展模型互预测实验验证标注一致性。

Result: MultiParTweet语料库及其配套标注工具TTLABTweetCrawler已发布；模型间具有相互预测能力；VLM生成的标注在人工评估中更受偏好，表明多模态表征更贴近人类理解。

Conclusion: MultiParTweet为政治传播研究提供了高质量、多模态、经人工验证的社交媒体资源，VLM在图文联合建模中展现出优于纯文本模型的人类对齐能力，支持未来跨模态政治话语分析。

Abstract: Social media serves as a critical medium in modern politics because it both reflects politicians' ideologies and facilitates communication with younger generations. We present MultiParTweet, a multilingual tweet corpus from X that connects politicians' social media discourse with German political corpus GerParCor, thereby enabling comparative analyses between online communication and parliamentary debates. MultiParTweet contains 39 546 tweets, including 19 056 media items. Furthermore, we enriched the annotation with nine text-based models and one vision-language model (VLM) to annotate MultiParTweet with emotion, sentiment, and topic annotations. Moreover, the automated annotations are evaluated against a manually annotated subset. MultiParTweet can be reconstructed using our tool, TTLABTweetCrawler, which provides a framework for collecting data from X. To demonstrate a methodological demonstration, we examine whether the models can predict each other using the outputs of the remaining models. In summary, we provide MultiParTweet, a resource integrating automatic text and media-based annotations validated with human annotations, and TTLABTweetCrawler, a general-purpose X data collection tool. Our analysis shows that the models are mutually predictable. In addition, VLM-based annotation were preferred by human annotators, suggesting that multimodal representations align more with human interpretation.

</details>


### [118] [Visualizing token importance for black-box language models](https://arxiv.org/abs/2512.11573)
*Paulius Rauba,Qiyao Wei,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 本文提出了一种名为Distribution-Based Sensitivity Analysis (DBSA)的轻量级、模型无关方法，用于评估黑盒大语言模型（LLM）对每个输入词元的输出敏感性，无需对LLM做分布假设，适用于API调用等实际场景。


<details>
  <summary>Details</summary>
Motivation: 现有LLM审计方法多关注孤立行为（如偏见检测），缺乏对模型输出如何依赖各输入词元的通用分析工具，尤其在无法访问模型内部的生产环境中亟需此类可解释性工具。

Method: 提出DBSA方法，基于输出分布差异而非梯度，通过采样与统计比较量化各输入词元对输出的影响，具有轻量、即插即用、无需模型访问权限的特点。

Result: DBSA能有效识别LLM对特定输入词元的敏感性，在多个示例中揭示出传统可解释性方法易忽略的关键依赖关系。

Conclusion: DBSA为黑盒LLM审计提供了一种实用、稳健且通用的敏感性分析新范式，填补了高风险场景下模型可靠性评估的工具空白。

Abstract: We consider the problem of auditing black-box large language models (LLMs) to ensure they behave reliably when deployed in production settings, particularly in high-stakes domains such as legal, medical, and regulatory compliance. Existing approaches for LLM auditing often focus on isolated aspects of model behavior, such as detecting specific biases or evaluating fairness. We are interested in a more general question -- can we understand how the outputs of black-box LLMs depend on each input token? There is a critical need to have such tools in real-world applications that rely on inaccessible API endpoints to language models. However, this is a highly non-trivial problem, as LLMs are stochastic functions (i.e. two outputs will be different by chance), while computing prompt-level gradients to approximate input sensitivity is infeasible. To address this, we propose Distribution-Based Sensitivity Analysis (DBSA), a lightweight model-agnostic procedure to evaluate the sensitivity of the output of a language model for each input token, without making any distributional assumptions about the LLM. DBSA is developed as a practical tool for practitioners, enabling quick, plug-and-play visual exploration of LLMs reliance on specific input tokens. Through illustrative examples, we demonstrate how DBSA can enable users to inspect LLM inputs and find sensitivities that may be overlooked by existing LLM interpretability methods.

</details>


### [119] [Bounding Hallucinations: Information-Theoretic Guarantees for RAG Systems via Merlin-Arthur Protocols](https://arxiv.org/abs/2512.11614)
*Björn Deiseroth,Max Henning Höth,Kristian Kersting,Letitia Parcalabescu*

Main category: cs.CL

TL;DR: 本文提出了一种基于Merlin-Arthur协议的训练框架，将检索增强生成（RAG）系统建模为交互式证明系统，使生成器（Arthur）能基于可验证证据进行回答、拒绝或定位关键支撑片段，并通过对抗性上下文和XAI方法提升其可靠性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统将检索视为弱启发式而非可验证证据，导致模型无依据作答、幻觉及依赖虚假证据。

Method: 提出M/A训练框架：Merlin提供有益证据，Morgana注入对抗性误导上下文；Arthur（LLM生成器）在未知来源问题上训练，并利用线性时间XAI方法识别并修改对自身决策影响最大的证据片段；同时构建新评估框架与Explained Information Fraction（EIF）指标。

Result: 在三个RAG数据集和两类不同规模模型上，M/A训练显著提升了生成结果的groundedness、completeness、soundness和reject行为，降低了幻觉；检索器的recall和MRR也因自动生成的难正/负样本而提升。

Conclusion: 自主交互式证明监督为构建真正以检索文档为可验证证据的可靠RAG系统提供了原理清晰且实用可行的路径。

Abstract: Retrieval-augmented generation (RAG) models rely on retrieved evidence to guide large language model (LLM) generators, yet current systems treat retrieval as a weak heuristic rather than verifiable evidence. As a result, LLMs answer without support, hallucinate under incomplete or misleading context, and rely on spurious evidence. We introduce a training framework that treats the entire RAG pipeline -- both the retriever and the generator -- as an interactive proof system via an adaptation of the Merlin-Arthur (M/A) protocol. Arthur (the generator LLM) trains on questions of unkown provenance: Merlin provides helpful evidence, while Morgana injects adversarial, misleading context. Both use a linear-time XAI method to identify and modify the evidence most influential to Arthur. Consequently, Arthur learns to (i) answer when the context support the answer, (ii) reject when evidence is insufficient, and (iii) rely on the specific context spans that truly ground the answer. We further introduce a rigorous evaluation framework to disentangle explanation fidelity from baseline predictive errors. This allows us to introduce and measure the Explained Information Fraction (EIF), which normalizes M/A certified mutual-information guarantees relative to model capacity and imperfect benchmarks. Across three RAG datasets and two model families of varying sizes, M/A-trained LLMs show improved groundedness, completeness, soundness, and reject behavior, as well as reduced hallucinations -- without needing manually annotated unanswerable questions. The retriever likewise improves recall and MRR through automatically generated M/A hard positives and negatives. Our results demonstrate that autonomous interactive-proof-style supervision provides a principled and practical path toward reliable RAG systems that treat retrieved documents not as suggestions, but as verifiable evidence.

</details>


### [120] [Speculative Decoding Speed-of-Light: Optimal Lower Bounds via Branching Random Walks](https://arxiv.org/abs/2512.11718)
*Sergey Pankratov,Dan Alistarh*

Main category: cs.CL

TL;DR: 本文建立了确定性推测生成算法运行时间的第一个“紧”下界，通过将token生成过程与分支随机游走进行类比，分析最优草稿树选择问题，并在Llama模型上验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 推测生成虽能加速大语言模型推理，但其可实现的加速上限仍不明确。

Method: 将token生成过程类比为分支随机游走，分析最优草稿树选择问题，推导出期望成功预测token数的理论上限。

Result: 证明在基本假设下，每次推测迭代中成功预测的token数期望值满足特定上界公式，且该界限在Llama模型实验中被验证是紧的。

Conclusion: 本工作揭示了并行token生成的根本极限，为未来推测解码系统的设计提供了理论指导。

Abstract: Speculative generation has emerged as a promising technique to accelerate inference in large language models (LLMs) by leveraging parallelism to verify multiple draft tokens simultaneously. However, the fundamental limits on the achievable speedup remain poorly understood. In this work, we establish the first ``tight'' lower bounds on the runtime of any deterministic speculative generation algorithm. This is achieved by drawing a parallel between the token generation process and branching random walks, which allows us to analyze the optimal draft tree selection problem. We prove, under basic assumptions, that the expected number of tokens successfully predicted per speculative iteration is bounded as $\mathbb{E}[X] \leq (μ+ μ_{(2)})\log(P )/μ^2 + O(1)$, where $P$ is the verifier's capacity, $μ$ is the expected entropy of the verifier's output distribution, and $μ_{(2)}$ is the expected second log-moment. This result provides new insights into the limits of parallel token generation, and could guide the design of future speculative decoding systems. Empirical evaluations on Llama models validate our theoretical predictions, confirming the tightness of our bounds in practical settings.

</details>


### [121] [SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support](https://arxiv.org/abs/2512.11755)
*Yuming Feng,Xinrui Jiang*

Main category: cs.CL

TL;DR: 本文提出SUMFORU框架，通过结合用户画像的两阶段对齐方法（不对称知识蒸馏的监督微调 + 基于AI反馈的强化学习），实现个性化在线评论摘要生成，在一致性、事实性与偏好对齐方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的评论摘要方法过于通用，无法适配用户个性化偏好，导致决策支持效果有限。

Method: 构建基于Amazon 2023数据集的高质量数据流水线；采用两阶段对齐：(1) 基于不对称知识蒸馏的用户画像感知监督微调（SFT）；(2) 利用偏好估计器提供AI反馈的强化学习（RLAIF）。

Result: 在规则型、LLM型和人类评估指标上均取得最优性能，尤其在一致性、事实性（grounding）和偏好对齐方面提升显著，并能泛化至未见商品类别。

Conclusion: 可引导的多元对齐（steerable pluralistic alignment）是构建下一代个性化决策支持系统的关键路径。

Abstract: Online product reviews contain rich but noisy signals that overwhelm users and hinder effective decision-making. Existing LLM-based summarizers remain generic and fail to account for individual preferences, limiting their practical utility. We propose SUMFORU, a steerable review summarization framework that aligns outputs with explicit user personas to support personalized purchase decisions. Our approach integrates a high-quality data pipeline built from the Amazon 2023 Review Dataset with a two-stage alignment procedure: (1) persona-aware Supervised Fine-Tuning (SFT) via asymmetric knowledge distillation, and (2) Reinforcement Learning with AI Feedback (RLAIF) using a preference estimator to capture fine-grained, persona-relevant signals. We evaluate the model across rule-based, LLM-based, and human-centered metrics, demonstrating consistent improvements in consistency, grounding, and preference alignment. Our framework achieves the highest performance across all evaluation settings and generalizes effectively to unseen product categories. Our results highlight the promise of steerable pluralistic alignment for building next-generation personalized decision-support systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [122] [Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control](https://arxiv.org/abs/2512.11247)
*Iftekharul Islam,Weizi Li*

Main category: cs.MA

TL;DR: 本文提出了一种分层混合交通控制框架，结合多目标强化学习与策略路由，引入冲突威胁向量和队列公平性惩罚，显著提升了公平性、安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽能优化效率和保障安全，但缺乏保障公平性的机制，导致低需求方向车辆系统性饥饿。

Method: 提出分层框架：局部采用多目标强化学习控制交叉口，全局通过策略路由实现网络协调；引入Conflict Threat Vector提供风险信号，以及queue parity penalty保障服务公平性。

Result: 在真实路网实验中，相比基线方法，平均等待时间降低最多53%，最大饥饿减少最多86%，冲突率降低最多86%，同时保持燃油效率；策略路由效果随机器人车辆渗透率提升而增强。

Conclusion: 通过精心设计的多目标奖励函数与机器人车辆策略路由协同，可显著提升混合自主交通系统在公平性与安全性方面的关键指标。

Abstract: Effective mixed traffic control requires balancing efficiency, fairness, and safety. Existing approaches excel at optimizing efficiency and enforcing safety constraints but lack mechanisms to ensure equitable service, resulting in systematic starvation of vehicles on low-demand approaches. We propose a hierarchical framework combining multi-objective reinforcement learning for local intersection control with strategic routing for network-level coordination. Our approach introduces a Conflict Threat Vector that provides agents with explicit risk signals for proactive conflict avoidance, and a queue parity penalty that ensures equitable service across all traffic streams. Extensive experiments on a real-world network across different robot vehicle (RV) penetration rates demonstrate substantial improvements: up to 53% reductions in average wait time, up to 86% reductions in maximum starvation, and up to 86\% reduction in conflict rate compared to baselines, while maintaining fuel efficiency. Our analysis reveals that strategic routing effectiveness scales with RV penetration, becoming increasingly valuable at higher autonomy levels. The results demonstrate that multi-objective optimization through well-curated reward functions paired with strategic RV routing yields significant benefits in fairness and safety metrics critical for equitable mixed-autonomy deployment.

</details>


### [123] [Evaluating Cooperative Resilience in Multiagent Systems: A Comparison Between Humans and LLMs](https://arxiv.org/abs/2512.11689)
*Manuela Chacon-Chamorro,Juan Sebastián Pinzón,Rubén Manrique,Luis Felipe Giraldo,Nicanor Quijano*

Main category: cs.MA

TL;DR: 本文比较了人类群体与基于大语言模型（LLM）的智能体在‘公地悲剧’环境中的合作韧性，考察了有无显式通信条件下的表现，并引入持续干扰与随机环境冲击；结果表明，有通信的人类群体韧性最高，通信亦提升LLM智能体韧性但仍未及人类；进一步在更严苛长周期环境下验证了人类的稳健适应能力，为设计具亲社会性与韧性的AI提供启示。


<details>
  <summary>Details</summary>
Motivation: 探究人类与LLM智能体在混合动机社会困境中合作韧性的差异，以期为构建更具亲社会性与韧性的AI系统提供实证依据和设计指导。

Method: 在Melting Pot套件的‘公地悲剧’环境中，系统对比人类群体与LLM智能体（有/无显式通信）在持续不可持续消费干扰与间歇性资源随机削减双重扰动下的合作韧性表现，并扩展至更严苛的长周期设定。

Result: 有通信的人类群体展现出最高合作韧性；通信显著提升LLM智能体韧性但仍低于人类；在更严苛长周期环境下，人类仍能维持资源共享与高韧性。

Conclusion: 人类在复杂社会-环境扰动下的决策能力优于当前LLM智能体，其行为模式可为设计促进亲社会与韧性行为的人工智能提供关键参考。

Abstract: This paper presents a comparative analysis of cooperative resilience in multi-agent systems, defined as the ability to anticipate, resist, recover from, and transform to disruptive events that affect collective well-being. We focus on mixed-motive social dilemmas instantiated as a \textit{Tragedy of the Commons} environment from the Melting Pot suite, where we systematically compare human groups and Large Language Model (LLM)-based agents, each evaluated with and without explicit communication. Cooperative resilience is assessed under a continuously disruptive condition induced by a persistent unsustainable consumption bot, together with intermittent environmental shocks implemented as stochastic removal of shared resources across scenarios. This experimental design establishes a benchmark for cooperative resilience across agent architectures and interaction modalities, constituting a key step toward systematically comparing humans and LLM-based agents. Using this framework, we find that human groups with communication achieve the highest cooperative resilience compared to all other groups. Communication also improves the resilience of LLM agents, but their performance remains below human levels. Motivated by the performance of humans, we further examine a long-horizon setting with harsher environmental conditions, where humans sustain the shared resource and maintain high resilience in diverse disruption scenarios. Together, these results suggest that human decision-making under adverse social conditions can inform the design of artificial agents that promote prosocial and resilient behaviors.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [124] [Scalable Data Synthesis for Computer Use Agents with Step-Level Filtering](https://arxiv.org/abs/2512.10962)
*Yifei He,Pranit Chawla,Yaser Souri,Subhojit Som,Xia Song*

Main category: cs.LG

TL;DR: 本文提出了一种可扩展的数据合成流程，通过步骤级过滤和推理增强，将强CUA模型产生的噪声轨迹转化为高质量监督信号，构建了WebSTAR（含13.3K轨迹）和WebSCORE两个新数据集，并训练出性能超越SOTA的Qwen-2.5-VL-Instruct模型及高效轻量奖励模型StepRM。


<details>
  <summary>Details</summary>
Motivation: 现有CUA训练受限于GUI交互成本高、高质量轨迹数据稀缺；人工演示难以扩展，而强CUA自生成数据又噪声大、错误多，导致直接模仿学习效果差。

Method: 提出步骤级过滤（step-level filtering）机制，对每个动作单独评估并仅保留正确步骤；结合推理增强提升规划能力；基于OpenAI的computer-use-preview模型合成并标注WebSTAR数据集；进一步构建WebSCORE用于训练轻量级多模态奖励模型StepRM（7B），蒸馏自o4-mini。

Result: 在WebVoyager上，仅用监督微调的Qwen-2.5-VL-Instruct-7B模型性能超越UI-TARS-1.5-7B超15%；StepRM在评分质量上媲美o4-mini，但部署效率显著更高。

Conclusion: 步骤级过滤是实现CUA可扩展训练的关键原则；WebSTAR、WebSCORE和StepRM为构建鲁棒、高效的CUA提供了实用新工具与数据基础。

Abstract: Computer use agents (CUAs) can operate real-world digital interfaces but remain difficult to train due to the high cost of graphical user interface (GUI) interaction and the scarcity of high-quality trajectory data. Existing datasets rely on human demonstrations, limiting scalability. A natural alternative is to synthesize data from strong CUAs, yet their rollouts are highly noisy, with incorrect or suboptimal actions consisting a large proportion of the steps, making naive imitation ineffective. To tackle this challenge, we introduce a scalable data synthesis pipeline that transforms noisy rollouts into reliable supervision without human annotation. The core idea is step-level filtering, which evaluates actions individually to retain only correct steps, complemented by reasoning augmentation for improved planning. Using this pipeline, we construct WebSTAR, a dataset of 13.3K trajectories and 100K graded, reasoning-rich steps synthesized from OpenAI's computer-use-preview model. We train Qwen-2.5-VL-Instruct models (7B and 32B) on WebSTAR. On WebVoyager, our 7B model surpasses SoTA open-source CUA model UI-TARS-1.5-7B by more than 15% with only supervised finetuning. Building on step-level grading, we further create WebSCORE, a dataset of graded step-level actions, and train StepRM, a 7B multimodal reward model distilled from o4-mini, which matches its grading quality while being far more efficient to deploy at scale. Our results establish step-level filtering as a key principle for scalable CUA training and construct two new datasets (WebSTAR, WebSCORE) and a lightweight reward model (StepRM) as practical tools to advance robust and efficient CUAs.

</details>


### [125] [Multimodal Fusion of Regional Brain Experts for Interpretable Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2512.10966)
*Farica Zhuang,Dinara Aliyeva,Shu Yang,Zixuan Wen,Duy Duong-Tran,Christos Davatzikos,Tianlong Chen,Song Wang,Li Shen*

Main category: cs.LG

TL;DR: 本文提出MREF-AD模型，一种基于多模态区域专家融合的阿尔茨海默病（AD）诊断方法，利用两层门控网络自适应融合PET与MRI等多模态影像特征，并提供模态与脑区层面的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统多模态融合方法（如简单特征拼接）难以自适应平衡不同生物标志物（如淀粉样蛋白PET和MRI）在各脑区的贡献，而临床实践中需整合互补的多模态信息以实现AD的早期精准诊断。

Method: 提出MREF-AD：一种面向脑中尺度区域的混合专家（MoE）框架，将每种模态的每个脑区建模为独立专家，并设计两级门控网络学习被试特异性的融合权重。

Result: 在ADNI数据集上，MREF-AD在诊断性能上达到SOTA，并能揭示各脑区中结构与分子影像对诊断的联合贡献，提升模型可解释性。

Conclusion: MREF-AD是一种自适应、可解释的多模态神经影像融合通用框架，兼具高诊断精度与生物医学可解释性。

Abstract: Accurate and early diagnosis of Alzheimer's disease (AD) can benefit from integrating complementary information from multiple modalities, mirroring clinical practice. However, conventional fusion approaches often rely on simple concatenation of features, which cannot adaptively balance the contributions of biomarkers such as amyloid PET and MRI across brain regions. In this work, we propose MREF-AD, a Multimodal Regional Expert Fusion model for AD diagnosis. It is a Mixture-of-Experts (MoE) framework that models meso-scale brain regions in each modality as an independent expert and employs two-level gating networks to learn subject-specific fusion weights. Beyond improving diagnostic performance, MREF-AD provides modality- and region-level insight into how structural and molecular imaging jointly contribute to disease diagnosis. Using data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), MREF-AD achieves state-of-the-art performance over baselines while providing enhanced interpretability of brain region-specific biomarker relevance, underscoring its utility as a general framework for adaptive and interpretable multimodal fusion in neuroimaging.

</details>


### [126] [Agent-Based Modular Learning for Multimodal Emotion Recognition in Human-Agent Systems](https://arxiv.org/abs/2512.10975)
*Matvey Nepomnyaschiy,Oleg Pereziabov,Anvar Tliamov,Stanislav Mikhailov,Ilya Afanasyev*

Main category: cs.LG

TL;DR: 本文提出了一种多智能体框架，用于训练多模态情感识别系统，每个模态编码器和融合分类器作为自主智能体，由中央监督器协调，以提升灵活性、可扩展性和可维护性。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态深度学习的情感识别模型训练和维护计算开销大、难以适应模态变化，限制了其在人机交互中的实际应用。

Method: 设计一个由中央监督器协调的多智能体框架，各模态编码器（如视觉、音频、文本）和融合分类器作为独立、可替换的智能体，支持模块化集成与更新。

Result: 实现了支持视觉、音频和文本模态的概念验证系统，验证了该框架在训练效率、模块可替换性和计算开销降低方面的可行性。

Conclusion: 所提多智能体框架提升了多模态情感识别系统的灵活性、可扩展性与可维护性，为具身与虚拟智能体在人机交互中的感知模块设计提供了新思路。

Abstract: Effective human-agent interaction (HAI) relies on accurate and adaptive perception of human emotional states. While multimodal deep learning models - leveraging facial expressions, speech, and textual cues - offer high accuracy in emotion recognition, their training and maintenance are often computationally intensive and inflexible to modality changes. In this work, we propose a novel multi-agent framework for training multimodal emotion recognition systems, where each modality encoder and the fusion classifier operate as autonomous agents coordinated by a central supervisor. This architecture enables modular integration of new modalities (e.g., audio features via emotion2vec), seamless replacement of outdated components, and reduced computational overhead during training. We demonstrate the feasibility of our approach through a proof-of-concept implementation supporting vision, audio, and text modalities, with the classifier serving as a shared decision-making agent. Our framework not only improves training efficiency but also contributes to the design of more flexible, scalable, and maintainable perception modules for embodied and virtual agents in HAI scenarios.

</details>


### [127] [MoB: Mixture of Bidders](https://arxiv.org/abs/2512.10969)
*Dev Vyas*

Main category: cs.LG

TL;DR: 本文提出了一种名为Mixture of Bidders（MoB）的新框架，将专家路由建模为基于VCG拍卖的去中心化经济机制，以解决MoE在持续学习中因门控网络导致的灾难性遗忘问题；MoB通过结合执行成本与遗忘成本实现无状态、抗遗忘、诚实竞价的路由，并在Split-MNIST上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Mixture of Experts（MoE）在扩展神经网络方面表现优异，但在持续学习中受限于门控网络自身易发生灾难性遗忘这一根本缺陷。

Method: 提出Mixture of Bidders（MoB）框架，用Vickrey-Clarke-Groves（VCG）拍卖替代传统学习型门控网络；每位专家根据预测损失（执行成本）和Elastic Weight Consolidation惩罚（遗忘成本）进行真实成本报价；引入自监控专家以自主识别知识固化边界，无需显式任务划分。

Result: 在Split-MNIST基准上，MoB达到88.77%平均准确率，显著优于Gated MoE（19.54%）和Monolithic EWC（27.96%），提升达4.5倍；验证了无状态路由、诚实竞价和自发专家专业化等关键特性。

Conclusion: MoB通过将专家路由重构为具备博弈论保障的经济机制，从根本上缓解了持续学习中的灾难性遗忘问题，为可扩展、可演化、无需任务边界的持续学习提供了新范式。

Abstract: Mixture of Experts (MoE) architectures have demonstrated remarkable success in scaling neural networks, yet their application to continual learning remains fundamentally limited by a critical vulnerability: the learned gating network itself suffers from catastrophic forgetting. We introduce Mixture of Bidders (MoB), a novel framework that reconceptualizes expert routing as a decentralized economic mechanism. MoB replaces learned gating networks with Vickrey-Clarke-Groves (VCG) auctions, where experts compete for each data batch by bidding their true cost -- a principled combination of execution cost (predicted loss) and forgetting cost (Elastic Weight Consolidation penalty). This game-theoretic approach provides three key advantages: (1) {stateless routing that is immune to catastrophic forgetting, (2) \textbf{truthful bidding} guaranteed by dominant-strategy incentive compatibility, and (3) emergent specialization without explicit task boundaries. On Split-MNIST benchmarks, MoB achieves 88.77% average accuracy compared to 19.54% for Gated MoE and 27.96% for Monolithic EWC, representing a 4.5 times improvement over the strongest baseline. We further extend MoB with autonomous self-monitoring experts that detect their own knowledge consolidation boundaries, eliminating the need for explicit task demarcation.

</details>


### [128] [Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning](https://arxiv.org/abs/2512.11179)
*Wei Duan,Jie Lu,En Yu,Junyu Xuan*

Main category: cs.LG

TL;DR: 本文提出了一种带宽受限下的变分消息编码方法（BVME），通过将消息建模为高斯后验分布并用KL散度正则化，实现对通信消息的可控压缩，在显著降低消息维度（67%-83%）的同时保持甚至提升多智能体协同性能。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络MARL方法能学习稀疏协调图（谁与谁通信），但未解决在严格带宽限制下‘传输什么信息’的问题；朴素降维会损害协同性能，而确定性投影缺乏对压缩方式的有效控制。

Method: 提出带宽约束变分消息编码（BVME）：将消息视为从学习到的高斯后验中采样的样本，并用KL散度约束其偏离无信息先验；通过可解释超参数调节压缩强度，从而直接约束决策所用表征。

Result: 在SMACv1、SMACv2和MPE基准上，BVME在消息维度减少67%-83%的情况下达到相当或更优性能，尤其在稀疏图上增益显著；消融实验显示其在极端带宽比下表现优异，且计算开销极小。

Conclusion: BVME提供了一种原理清晰、可调可控的消息压缩机制，有效解决了带宽受限下MARL中信息选择与编码的关键问题，提升了通信效率与协同性能的平衡。

Abstract: Graph-based multi-agent reinforcement learning (MARL) enables coordinated behavior under partial observability by modeling agents as nodes and communication links as edges. While recent methods excel at learning sparse coordination graphs-determining who communicates with whom-they do not address what information should be transmitted under hard bandwidth constraints. We study this bandwidth-limited regime and show that naive dimensionality reduction consistently degrades coordination performance. Hard bandwidth constraints force selective encoding, but deterministic projections lack mechanisms to control how compression occurs. We introduce Bandwidth-constrained Variational Message Encoding (BVME), a lightweight module that treats messages as samples from learned Gaussian posteriors regularized via KL divergence to an uninformative prior. BVME's variational framework provides principled, tunable control over compression strength through interpretable hyperparameters, directly constraining the representations used for decision-making. Across SMACv1, SMACv2, and MPE benchmarks, BVME achieves comparable or superior performance while using 67--83% fewer message dimensions, with gains most pronounced on sparse graphs where message quality critically impacts coordination. Ablations reveal U-shaped sensitivity to bandwidth, with BVME excelling at extreme ratios while adding minimal overhead.

</details>


### [129] [TECM*: A Data-Driven Assessment to Reinforcement Learning Methods and Application to Heparin Treatment Strategy for Surgical Sepsis](https://arxiv.org/abs/2512.10973)
*Jiang Liu,Yujie Li,Chan Zhou,Yihao Xie,Qilong Sun,Xin Shu,Peiwei Li,Chunyong Yang,Yiziting Zhu,Jiaqi Zhu,Yuwen Chen,Bo An,Hao Wu,Bin Yi*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习（RL）的框架，通过连续化SOFA评分（cxSOFA）和治疗效果比较矩阵（TECM），优化外科脓毒症患者的个体化肝素治疗，显著降低死亡率与住院时间。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是危及生命的重症，需个体化抗凝治疗；现有离散评分（如SOFA）难以支持精细、连续的治疗决策，亟需数据驱动的动态优化方法。

Method: 基于MIMIC-IV和eICU数据库构建腹部术后脓毒症患者队列；提出cxSOFA实现状态与奖励函数连续化；采用分步策略定义“优/劣”治疗；设计类混淆矩阵的TECM评估治疗策略；对比Q-Learning、DQN、DDQN、BCQ与CQL等RL算法。

Result: cxSOFA-CQL模型表现最优，死亡率从1.83%降至0.74%，平均住院日由11.11天缩短至9.42天；TECM验证各模型结果一致性，体现框架鲁棒性。

Conclusion: 该RL框架可实现可解释、鲁棒的肝素治疗优化；cxSOFA与TECM为临床治疗评估提供了更细致、可靠的量化工具，有望提升决策支持系统的实用性与临床转化价值。

Abstract: Objective: Sepsis is a life-threatening condition caused by severe infection leading to acute organ dysfunction. This study proposes a data-driven metric and a continuous reward function to optimize personalized heparin therapy in surgical sepsis patients. Methods: Data from the MIMIC-IV v1.0 and eICU v2.0 databases were used for model development and evaluation. The training cohort consisted of abdominal surgery patients receiving unfractionated heparin (UFH) after postoperative sepsis onset. We introduce a new RL-based framework: converting the discrete SOFA score to a continuous cxSOFA for more nuanced state and reward functions; Second, defining "good" or "bad" strategies based on cxSOFA by a stepwise manner; Third, proposing a Treatment Effect Comparison Matrix (TECM), analogous to a confusion matrix for classification tasks, to evaluate the treatment strategies. We applied different RL algorithms, Q-Learning, DQN, DDQN, BCQ and CQL to optimize the treatment and comprehensively evaluated the framework. Results: Among the AI-derived strategies, the cxSOFA-CQL model achieved the best performance, reducing mortality from 1.83% to 0.74% with the average hospital stay from 11.11 to 9.42 days. TECM demonstrated consistent outcomes across models, highlighting robustness. Conclusion: The proposed RL framework enables interpretable and robust optimization of heparin therapy in surgical sepsis. Continuous cxSOFA scoring and TECM-based evaluation provide nuanced treatment assessment, showing promise for improving clinical outcomes and decision-support reliability.

</details>


### [130] [MolSculpt: Sculpting 3D Molecular Geometries from Chemical Syntax](https://arxiv.org/abs/2512.10991)
*Zhanpeng Chen,Weihao Gao,Shunyu Wang,Yanan Zhu,Hong Meng,Yuexian Zou*

Main category: cs.LG

TL;DR: MolSculpt 是一种新框架，通过将冻结的1D分子基础模型与3D分子扩散模型结合，利用可学习查询和可训练投影器，将1D化学语法知识深度融入3D几何生成过程，实现了从化学语法‘雕刻’出精确3D分子结构的目标，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于1D表示（如SELFIES）的方法虽保证分子有效性，但未能充分利用1D模型中蕴含的丰富化学知识，导致1D语法生成与3D几何实现脱节。

Method: 提出 MolSculpt 框架：基于冻结的1D分子基础模型和3D分子扩散模型；引入可学习查询提取1D模型中的化学知识，并通过可训练投影器将该跨模态信息注入扩散模型的条件空间，实现端到端优化。

Result: 在 GEOM-DRUGS 和 QM9 数据集上，MolSculpt 在从头生成（de novo）和条件生成两类3D分子任务中均达到SOTA，展现出更优的3D保真度和结构稳定性。

Conclusion: MolSculpt 成功弥合了1D化学语法表征与3D几何生成之间的鸿沟，验证了深度融合1D化学先验知识对提升3D分子生成质量的有效性，为药物发现和材料科学提供了更可靠的生成工具。

Abstract: Generating precise 3D molecular geometries is crucial for drug discovery and material science. While prior efforts leverage 1D representations like SELFIES to ensure molecular validity, they fail to fully exploit the rich chemical knowledge entangled within 1D models, leading to a disconnect between 1D syntactic generation and 3D geometric realization. To bridge this gap, we propose MolSculpt, a novel framework that "sculpts" 3D molecular geometries from chemical syntax. MolSculpt is built upon a frozen 1D molecular foundation model and a 3D molecular diffusion model. We introduce a set of learnable queries to extract inherent chemical knowledge from the foundation model, and a trainable projector then injects this cross-modal information into the conditioning space of the diffusion model to guide the 3D geometry generation. In this way, our model deeply integrates 1D latent chemical knowledge into the 3D generation process through end-to-end optimization. Experiments demonstrate that MolSculpt achieves state-of-the-art (SOTA) performance in \textit{de novo} 3D molecule generation and conditional 3D molecule generation, showing superior 3D fidelity and stability on both the GEOM-DRUGS and QM9 datasets. Code is available at https://github.com/SakuraTroyChen/MolSculpt.

</details>


### [131] [Memoryless Policy Iteration for Episodic POMDPs](https://arxiv.org/abs/2512.11082)
*Roy van Zuijlen,Duarte Antunes*

Main category: cs.LG

TL;DR: 本文提出了一种新的基于输出的单调改进策略迭代算法族，用于求解POMDP中的memoryless和有限记忆策略，并进一步扩展到无模型设置，在多个POMDP实例中显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统策略迭代方法难以直接应用于memoryless或有限记忆策略，因为其输出过程是非马尔可夫的，导致策略改进步骤在各阶段间相互依赖。

Method: 提出一类按周期性模式交替进行单阶段输出空间策略改进与策略评估的单调改进策略迭代算法；识别最优及最简周期模式；并发展出对应的无模型变体，从数据中估计值函数并直接学习memoryless策略。

Result: 在多个POMDP实例上，该方法在模型基础和无模型设定下均显著快于策略梯度基线及近期专用算法。

Conclusion: 所提出的算法族为POMDP中实用、高效地学习memoryless和有限记忆策略提供了新范式，兼具理论保证与实证优势。

Abstract: Memoryless and finite-memory policies offer a practical alternative for solving partially observable Markov decision processes (POMDPs), as they operate directly in the output space rather than in the high-dimensional belief space. However, extending classical methods such as policy iteration to this setting remains difficult; the output process is non-Markovian, making policy-improvement steps interdependent across stages. We introduce a new family of monotonically improving policy-iteration algorithms that alternate between single-stage output-based policy improvements and policy evaluations according to a prescribed periodic pattern. We show that this family admits optimal patterns that maximize a natural computational-efficiency index, and we identify the simplest pattern with minimal period. Building on this structure, we further develop a model-free variant that estimates values from data and learns memoryless policies directly. Across several POMDPs examples, our method achieves significant computational speedups over policy-gradient baselines and recent specialized algorithms in both model-based and model-free settings.

</details>


### [132] [Clip-and-Verify: Linear Constraint-Driven Domain Clipping for Accelerating Neural Network Verification](https://arxiv.org/abs/2512.11087)
*Duo Zhou,Jorge Chavez,Hesun Chen,Grani A. Hanasusanto,Huan Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种线性约束驱动的裁剪框架（Clip-and-Verify），通过高效利用线性约束来缩减分支定界（BaB）中的搜索空间并提升中间层边界，显著减少子问题数量、提高验证精度，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络验证器依赖分支定界（BaB）与快速边界计算，但其效率受限于冗余子问题和松散边界；亟需更高效、可扩展的方法来利用已有线性约束（如传播所得）提升验证过程。

Method: 提出线性约束驱动的裁剪框架，设计两种新算法：1）基于线性约束剪除已验证或无关输入区域；2）直接优化网络各层中间边界；开发专用GPU程序高效处理大规模线性约束，无需外部求解器；可无缝集成至α,β-CROWN等BaB验证器（支持激活空间分裂约束或输出空间约束）。

Result: 在多个基准测试中显著收紧边界，子问题数量最多减少96%；在多个任务上实现SOTA验证准确率；Clip-and-Verify已成为VNN-COMP 2025冠军工具α,β-CROWN的核心组件。

Conclusion: 线性约束驱动的裁剪是一种通用、高效且可扩展的增强策略，能显著提升BaB类神经网络验证器的性能，为大规模鲁棒性验证提供了实用新路径。

Abstract: State-of-the-art neural network (NN) verifiers demonstrate that applying the branch-and-bound (BaB) procedure with fast bounding techniques plays a key role in tackling many challenging verification properties. In this work, we introduce the linear constraint-driven clipping framework, a class of scalable and efficient methods designed to enhance the efficacy of NN verifiers. Under this framework, we develop two novel algorithms that efficiently utilize linear constraints to 1) reduce portions of the input space that are either verified or irrelevant to a subproblem in the context of branch-and-bound, and 2) directly improve intermediate bounds throughout the network. The process novelly leverages linear constraints that often arise from bound propagation methods and is general enough to also incorporate constraints from other sources. It efficiently handles linear constraints using a specialized GPU procedure that can scale to large neural networks without the use of expensive external solvers. Our verification procedure, Clip-and-Verify, consistently tightens bounds across multiple benchmarks and can significantly reduce the number of subproblems handled during BaB. We show that our clipping algorithms can be integrated with BaB-based verifiers such as $α,β$-CROWN, utilizing either the split constraints in activation-space BaB or the output constraints that denote the unverified input space. We demonstrate the effectiveness of our procedure on a broad range of benchmarks where, in some instances, we witness a 96% reduction in the number of subproblems during branch-and-bound, and also achieve state-of-the-art verified accuracy across multiple benchmarks. Clip-and-Verify is part of the $α,β$-CROWN verifier (http://abcrown.org), the VNN-COMP 2025 winner. Code available at https://github.com/Verified-Intelligence/Clip_and_Verify.

</details>


### [133] [Investigating ECG Diagnosis with Ambiguous Labels using Partial Label Learning](https://arxiv.org/abs/2512.11095)
*Sana Rahmani,Javad Hashemi,Ali Etemad*

Main category: cs.LG

TL;DR: 本文首次系统研究了部分标签学习（PLL）方法在心电图（ECG）多标签诊断中的应用，评估了9种PLL算法在多种临床相关模糊标注策略下的鲁棒性，并揭示了现有方法在真实临床场景中的关键局限。


<details>
  <summary>Details</summary>
Motivation: 真实世界ECG诊断中存在固有的标签模糊性（如疾病重叠、医生诊断分歧），但现有模型多基于清晰无歧义标注训练，难以反映实际临床条件；而PLL虽适用于模糊标签学习，其在医疗时序数据（尤其是ECG）中的有效性尚属空白。

Method: 将9种PLL算法适配至多标签ECG诊断任务，在PTB-XL和Chapman数据集上，采用多种临床驱动的模糊标签生成策略（包括随机模糊、基于心内科医生相似性判断、治疗关系及诊断分类学等结构化模糊）进行系统评估与对比分析。

Result: 不同PLL方法对模糊类型和程度的鲁棒性差异显著；实验揭示了当前PLL方法在临床适用性上的若干关键缺陷，例如对结构化模糊建模不足、对诊断先验利用不充分等。

Conclusion: PLL为构建更贴近真实临床场景的ECG诊断模型提供了新路径，但需发展更具临床对齐性、能融合医学知识的模糊感知学习框架。

Abstract: Label ambiguity is an inherent problem in real-world electrocardiogram (ECG) diagnosis, arising from overlapping conditions and diagnostic disagreement. However, current ECG models are trained under the assumption of clean and non-ambiguous annotations, which limits both the development and the meaningful evaluation of models under real-world conditions. Although Partial Label Learning (PLL) frameworks are designed to learn from ambiguous labels, their effectiveness in medical time-series domains, ECG in particular, remains largely unexplored. In this work, we present the first systematic study of PLL methods for ECG diagnosis. We adapt nine PLL algorithms to multi-label ECG diagnosis and evaluate them using a diverse set of clinically motivated ambiguity generation strategies, capturing both unstructured (e.g., random) and structured ambiguities (e.g., cardiologist-derived similarities, treatment relationships, and diagnostic taxonomies). Our experiments on the PTB-XL and Chapman datasets demonstrate that PLL methods vary substantially in their robustness to different types and degrees of ambiguity. Through extensive analysis, we identify key limitations of current PLL approaches in clinical settings and outline future directions for developing robust and clinically aligned ambiguity-aware learning frameworks for ECG diagnosis.

</details>


### [134] [Limits and Gains of Test-Time Scaling in Vision-Language Reasoning](https://arxiv.org/abs/2512.11109)
*Mohammadjavad Ahmadpour,Amirmahdi Meighani,Payam Taebi,Omid Ghahroodi,Amirmohammad Izadi,Mahdieh Soleymani Baghshah*

Main category: cs.LG

TL;DR: 本文系统研究了测试时扩展（TTS）在视觉语言模型（VLMs）上的应用，发现其效果因模型类型（闭源/开源）和任务类型（多步推理 vs 感知型）而异，强调需针对模型与任务定制TTS策略。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展（TTS）在大语言模型中已展现提升推理能力的潜力，但在视觉语言模型（VLMs）中的适用性尚不明确，亟需系统实证研究。

Method: 对开源与闭源VLMs，在多个基准上实证评估多种推理方法（如结构化推理、自精炼、外部验证等）在测试时扩展下的表现。

Result: 闭源VLMs普遍受益于结构化推理与自精炼；开源VLMs则对外部验证响应更稳定，而自精炼常导致性能下降；TTS在多步推理任务上提升显著，在感知型任务上增益有限。

Conclusion: TTS并非普适方案，其有效性高度依赖模型架构与任务特性，未来应探索自适应TTS策略及多模态奖励模型。

Abstract: Test-time scaling (TTS) has emerged as a powerful paradigm for improving the reasoning ability of Large Language Models (LLMs) by allocating additional computation at inference, yet its application to multimodal systems such as Vision-Language Models (VLMs) remains underexplored. In this work, we present a systematic empirical study of inference time reasoning methods applied across both open-source and closed-source VLMs on different benchmarks. Our results reveal that while closed-source models consistently benefit from structured reasoning and iterative Self-Refinement, open-source VLMs show inconsistent behavior: external verification provides the most reliable gains, whereas iterative refinement often degrades performance. We further find that the effectiveness of TTS is dataset-dependent, yielding clear improvements on multi-step reasoning tasks but offering only limited gains on perception-focused benchmarks. These findings demonstrate that TTS is not a universal solution and must be tailored to both model capabilities and task characteristics, motivating future work on adaptive TTS strategies and multimodal reward models.

</details>


### [135] [In-Context Multi-Objective Optimization](https://arxiv.org/abs/2512.11114)
*Xinyu Zhang,Conor Hassan,Julien Martinelli,Daolang Huang,Samuel Kaski*

Main category: cs.LG

TL;DR: 本文提出TAMO，一种基于Transformer的、完全可摊销的通用多目标贝叶斯优化策略，通过强化学习预训练以最大化超体积改进，能在单次前向传播中直接生成下一个设计，无需任务级代理模型拟合与采集函数设计，显著加速（50–1000倍）且保持或提升帕累托质量。


<details>
  <summary>Details</summary>
Motivation: 传统多目标贝叶斯优化需为每个问题定制代理模型和采集函数，存在短视性、重拟合开销大、难以迁移等问题，难以满足科学发现中高效、即插即用的优化需求。

Method: 提出TAMO方法，采用可变输入/目标维度的Transformer架构，以整个查询历史为条件，通过强化学习在完整轨迹上最大化累积超体积改进进行预训练；测试时仅需单次前向推理即可输出新设计。

Result: 在合成基准与真实任务中，TAMO将提案时间降低50–1000倍，同时在严格评估预算下帕累托解质量持平或更优。

Conclusion: Transformer可实现完全上下文内的多目标优化，消除逐任务建模与采集工程，为科学发现提供基础模型风格的即插即用优化器。

Abstract: Balancing competing objectives is omnipresent across disciplines, from drug design to autonomous systems. Multi-objective Bayesian optimization is a promising solution for such expensive, black-box problems: it fits probabilistic surrogates and selects new designs via an acquisition function that balances exploration and exploitation. In practice, it requires tailored choices of surrogate and acquisition that rarely transfer to the next problem, is myopic when multi-step planning is often required, and adds refitting overhead, particularly in parallel or time-sensitive loops. We present TAMO, a fully amortized, universal policy for multi-objective black-box optimization. TAMO uses a transformer architecture that operates across varying input and objective dimensions, enabling pretraining on diverse corpora and transfer to new problems without retraining: at test time, the pretrained model proposes the next design with a single forward pass. We pretrain the policy with reinforcement learning to maximize cumulative hypervolume improvement over full trajectories, conditioning on the entire query history to approximate the Pareto frontier. Across synthetic benchmarks and real tasks, TAMO produces fast proposals, reducing proposal time by 50-1000x versus alternatives while matching or improving Pareto quality under tight evaluation budgets. These results show that transformers can perform multi-objective optimization entirely in-context, eliminating per-task surrogate fitting and acquisition engineering, and open a path to foundation-style, plug-and-play optimizers for scientific discovery workflows.

</details>


### [136] [Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee](https://arxiv.org/abs/2512.11127)
*Kshitiz Khanal*

Main category: cs.LG

TL;DR: 本文提出了一种结合物理信息图神经网络（GNN）与连续流匹配（CFM）的两阶段学习框架，用于快速、准确求解直流最优潮流（DC-OPF）问题，在保证100%约束可行性的前提下实现接近最优的经济调度性能。


<details>
  <summary>Details</summary>
Motivation: 传统优化求解器计算开销大，难以满足实时电网管理需求；现有机器学习方法常难以兼顾约束满足性与成本最优性。

Method: 第一阶段：用物理信息嵌入的GNN学习生成满足功率平衡、KKT条件等约束的初始可行解；第二阶段：用连续流匹配（CFM）对初始解进行无仿真、基于向量场回归的优化精调。

Result: 在IEEE 30节点系统五种负荷场景下，成本偏差低于0.1%（额定负荷）至3%（极端负荷），且100%满足可行性约束。

Conclusion: 该两阶段框架有效融合了物理先验与数据驱动建模优势，在速度、可行性与最优性之间取得良好平衡，适用于高比例可再生能源接入下需高频调度更新的现代电力系统。

Abstract: The DC Optimal Power Flow (DC-OPF) problem is fundamental to power system operations, requiring rapid solutions for real-time grid management. While traditional optimization solvers provide optimal solutions, their computational cost becomes prohibitive for large-scale systems requiring frequent recalculations. Machine learning approaches offer promise for acceleration but often struggle with constraint satisfaction and cost optimality. We present a novel two-stage learning framework that combines physics-informed Graph Neural Networks (GNNs) with Continuous Flow Matching (CFM) for solving DC-OPF problems. Our approach embeds fundamental physical principles--including economic dispatch optimality conditions, Kirchhoff's laws, and Karush-Kuhn-Tucker (KKT) complementarity conditions--directly into the training objectives. The first stage trains a GNN to produce feasible initial solutions by learning from physics-informed losses that encode power system constraints. The second stage employs CFM, a simulation-free continuous normalizing flow technique, to refine these solutions toward optimality through learned vector field regression. Evaluated on the IEEE 30-bus system across five load scenarios ranging from 70\% to 130\% nominal load, our method achieves near-optimal solutions with cost gaps below 0.1\% for nominal loads and below 3\% for extreme conditions, while maintaining 100\% feasibility. Our framework bridges the gap between fast but approximate neural network predictions and optimal but slow numerical solvers, offering a practical solution for modern power systems with high renewable penetration requiring frequent dispatch updates.

</details>


### [137] [Fairness-Regularized Online Optimization with Switching Costs](https://arxiv.org/abs/2512.11131)
*Pengfei Li,Yuelin Han,Adam Wierman,Shaolei Ren*

Main category: cs.LG

TL;DR: 本文提出FairOBD算法，解决公平性约束与动作平滑性（切换成本）并存的在线凸优化问题，通过引入辅助变量将长期公平性正则项分解为在线可处理形式，并在渐近意义下证明其对参数化约束离线最优解具有竞争比保证。


<details>
  <summary>Details</summary>
Motivation: 公平性和动作平滑性（如切换成本）在在线优化中均重要，但现有工作未同时建模二者；尤其长期公平性正则项导致传统遗憾或竞争比分析失效。

Method: 提出FairOBD算法：引入辅助变量将全局公平性正则项分解为逐时在线成本，并以此正则化每步决策；结合改进的Online Balanced Descent框架，新分析方法处理切换成本与公平性耦合。

Result: 理论证明FairOBD在T→∞时对带参数化约束的离线最优解具有渐近竞争比；实验表明其在AI推理资源调度任务中显著降低总公平性正则化成本并提升公平性。

Conclusion: 公平性与平滑性可协同优化；FairOBD为兼顾长期公平约束与短期切换成本的在线决策提供了首个具理论保证的实用算法框架。

Abstract: Fairness and action smoothness are two crucial considerations in many online optimization problems, but they have yet to be addressed simultaneously. In this paper, we study a new and challenging setting of fairness-regularized smoothed online convex optimization with switching costs. First, to highlight the fundamental challenges introduced by the long-term fairness regularizer evaluated based on the entire sequence of actions, we prove that even without switching costs, no online algorithms can possibly achieve a sublinear regret or finite competitive ratio compared to the offline optimal algorithm as the problem episode length $T$ increases. Then, we propose FairOBD (Fairness-regularized Online Balanced Descent), which reconciles the tension between minimizing the hitting cost, switching cost, and fairness cost. Concretely, FairOBD decomposes the long-term fairness cost into a sequence of online costs by introducing an auxiliary variable and then leverages the auxiliary variable to regularize the online actions for fair outcomes. Based on a new approach to account for switching costs, we prove that FairOBD offers a worst-case asymptotic competitive ratio against a novel benchmark -- the optimal offline algorithm with parameterized constraints -- by considering $T\to\infty$. Finally, we run trace-driven experiments of dynamic computing resource provisioning for socially responsible AI inference to empirically evaluate FairOBD, showing that FairOBD can effectively reduce the total fairness-regularized cost and better promote fair outcomes compared to existing baseline solutions.

</details>


### [138] [The Vekua Layer: Exact Physical Priors for Implicit Neural Representations via Generalized Analytic Functions](https://arxiv.org/abs/2512.11138)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: 本文提出了一种名为Vekua Layer（VL）的可微谱方法，通过将假设空间限制在控制微分算子的核空间内（如调和与傅里叶-贝塞尔基），将隐式神经表示的学习任务从非凸优化转化为严格凸的最小二乘问题，从而克服频谱偏置与计算开销问题。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）虽强大，但存在频谱偏置和非凸优化带来的计算昂贵问题。

Method: 基于广义解析函数理论，设计Vekua Layer（VL），利用调和与傅里叶-贝塞尔基构造满足控制微分算子的假设空间，将学习转化为线性投影求解的凸最小二乘问题。

Result: VL在精确重建任务中达到机器精度（MSE≈10⁻³³），在非相干传感器噪声下更稳定（MSE≈0.03），并支持仅用部分边界数据进行全局场‘全息’外推。

Conclusion: VL是一种物理信息驱动的谱方法，兼具高精度、强鲁棒性与解析延拓能力，显著优于SIREN等现有INR方法。

Abstract: Implicit Neural Representations (INRs) have emerged as a powerful paradigm for parameterizing physical fields, yet they often suffer from spectral bias and the computational expense of non-convex optimization. We introduce the Vekua Layer (VL), a differentiable spectral method grounded in the classical theory of Generalized Analytic Functions. By restricting the hypothesis space to the kernel of the governing differential operator -- specifically utilizing Harmonic and Fourier-Bessel bases -- the VL transforms the learning task from iterative gradient descent to a strictly convex least-squares problem solved via linear projection. We evaluate the VL against Sinusoidal Representation Networks (SIRENs) on homogeneous elliptic Partial Differential Equations (PDEs). Our results demonstrate that the VL achieves machine precision ($\text{MSE} \approx 10^{-33}$) on exact reconstruction tasks and exhibits superior stability in the presence of incoherent sensor noise ($\text{MSE} \approx 0.03$), effectively acting as a physics-informed spectral filter. Furthermore, we show that the VL enables "holographic" extrapolation of global fields from partial boundary data via analytic continuation, a capability absent in standard coordinate-based approximations.

</details>


### [139] [Autoencoder-based Semi-Supervised Dimensionality Reduction and Clustering for Scientific Ensembles](https://arxiv.org/abs/2512.11145)
*Lennard Manuel,Hamid Gadirov,Steffen Frey*

Main category: cs.LG

TL;DR: 本文提出了一种结合软轮廓分数聚类损失和对比损失的增强型自编码器框架，用于提升高维科学集成数据集的可视化与可解释性。通过EfficientNetV2生成伪标签，并联合优化重构、聚类与对比目标，使潜在空间中相似样本聚集、不同簇分离；再用UMAP降维并评估。实验表明该方法在两类科学数据集上略优于基线。


<details>
  <summary>Details</summary>
Motivation: 高维复杂科学集成数据集的分析与可视化面临挑战，传统降维与自编码器难以有效提取特征。

Method: 提出融合软轮廓分数聚类损失与对比损失的增强自编码器框架；利用EfficientNetV2为无标签数据生成伪标签；联合优化重建、聚类和对比损失；使用UMAP对学习到的潜在表示进行2D可视化并以轮廓分数评估。

Result: 在土壤通道结构（MCMC生成）和液滴撞击薄膜动力学两类科学集成数据集上，引入聚类或对比损失的模型性能略优于基线方法。

Conclusion: 聚类与对比损失的联合引入有助于提升自编码器在高维科学集成数据上的特征表达能力与可视化质量，但增益有限，需进一步探索更有效的监督/半监督机制。

Abstract: Analyzing and visualizing scientific ensemble datasets with high dimensionality and complexity poses significant challenges. Dimensionality reduction techniques and autoencoders are powerful tools for extracting features, but they often struggle with such high-dimensional data. This paper presents an enhanced autoencoder framework that incorporates a clustering loss, based on the soft silhouette score, alongside a contrastive loss to improve the visualization and interpretability of ensemble datasets. First, EfficientNetV2 is used to generate pseudo-labels for the unlabeled portions of the scientific ensemble datasets. By jointly optimizing the reconstruction, clustering, and contrastive objectives, our method encourages similar data points to group together while separating distinct clusters in the latent space. UMAP is subsequently applied to this latent representation to produce 2D projections, which are evaluated using the silhouette score. Multiple types of autoencoders are evaluated and compared based on their ability to extract meaningful features. Experiments on two scientific ensemble datasets - channel structures in soil derived from Markov chain Monte Carlo, and droplet-on-film impact dynamics - show that models incorporating clustering or contrastive loss marginally outperform the baseline approaches.

</details>


### [140] [Harnessing Rich Multi-Modal Data for Spatial-Temporal Homophily-Embedded Graph Learning Across Domains and Localities](https://arxiv.org/abs/2512.11178)
*Takuya Kurihana,Xiaojian Zhang,Wing Yee Au,Hon Yung Wong*

Main category: cs.LG

TL;DR: 本文提出了一种面向多源异构城市数据的跨域融合管道，通过图学习整合时空变化数据，支持多城市、多领域预测任务，具备强泛化性与低迁移成本。


<details>
  <summary>Details</summary>
Motivation: 城市数据来源多样、格式异构、标准不一， national-level 数据虽丰富但存在显著异质性与多模态问题，亟需统一框架实现跨域、跨地域的数据融合与分析。

Method: 构建异构数据处理管道，设计数据-学习模块，将空间变化数据的同质性（homophily）融入图学习，对50+数据源进行时空联合建模；在多个城市使用共享模型完成不同任务验证。

Result: 在五个真实场景（如网约车、交通事故、犯罪报告等）中验证了框架的通用性与灵活性，模型迁移至新城市或新领域时仅需极少重配置，且保持高预测性能。

Conclusion: 该框架为构建可扩展、数据驱动的智慧城市系统提供了有效技术路径，显著缓解了智能城市分析中数据异构与模型迁移难的核心挑战。

Abstract: Modern cities are increasingly reliant on data-driven insights to support decision making in areas such as transportation, public safety and environmental impact. However, city-level data often exists in heterogeneous formats, collected independently by local agencies with diverse objectives and standards. Despite their numerous, wide-ranging, and uniformly consumable nature, national-level datasets exhibit significant heterogeneity and multi-modality. This research proposes a heterogeneous data pipeline that performs cross-domain data fusion over time-varying, spatial-varying and spatial-varying time-series datasets. We aim to address complex urban problems across multiple domains and localities by harnessing the rich information over 50 data sources. Specifically, our data-learning module integrates homophily from spatial-varying dataset into graph-learning, embedding information of various localities into models. We demonstrate the generalizability and flexibility of the framework through five real-world observations using a variety of publicly accessible datasets (e.g., ride-share, traffic crash, and crime reports) collected from multiple cities. The results show that our proposed framework demonstrates strong predictive performance while requiring minimal reconfiguration when transferred to new localities or domains. This research advances the goal of building data-informed urban systems in a scalable way, addressing one of the most pressing challenges in smart city analytics.

</details>


### [141] [Progress over Points: Reframing LM Benchmarks Around Scientific Objectives](https://arxiv.org/abs/2512.11183)
*Alwin Jin,Sean M. Hendryx,Vaskar Nath*

Main category: cs.LG

TL;DR: 本文提出了一种新型‘进展导向型基准’（progress-oriented benchmarks），以替代传统静态问题基准，旨在使基准测试本身成为推动科学进步的工具；作者以NanoGPT速度赛为实例构建了可验证、可复现、带反作弊机制的训练环境，强调‘科学增量’（如损失降低与效率提升）而非单纯模型比较，并实现了训练时间新SOTA（快3秒），同时观察到新算法思想的涌现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准多基于静态、已解决的问题（如数学题），虽能检验基础能力，但限制了可衡量和激励的进展类型；亟需能直接反映并驱动真实科学进步的动态、开放、可演化的评估范式。

Method: 构建一个基于NanoGPT速度跑（speedrun）的标准化问题环境，包含固定数据切片、参考模型、统一训练框架、运行时验证与反作弊机制，以及丰富遥测；评估聚焦于‘科学增量’——即最优损失值与训练效率前沿。

Result: 在该环境中达成新的SOTA训练时间（比前纪录快3秒），并定性观察到新颖算法思想的自发涌现；验证了跨模型/智能体比较仍可行，但仅为手段而非目的；基准设计支持对语言建模栈的可复用改进。

Conclusion: 进展导向型基准将‘评测’升华为‘科研过程’本身：在该范式下，提升基准表现即等价于推进科学前沿；本文旨在推动社区从静态排行榜转向面向开放、可测量科学问题的实时研究。

Abstract: Current benchmarks that test LLMs on static, already-solved problems (e.g., math word problems) effectively demonstrated basic capability acquisition. The natural progression has been toward larger, more comprehensive and challenging collections of static problems, an approach that inadvertently constrains the kinds of advances we can measure and incentivize. To address this limitation, we argue for progress-oriented benchmarks, problem environments whose objectives are themselves the core targets of scientific progress, so that achieving state of the art on the benchmark advances the field. As a introductory step, we instantiate an environment based on the NanoGPT speedrun. The environment standardizes a dataset slice, a reference model and training harness, and rich telemetry, with run-time verification and anti-gaming checks. Evaluation centers on the scientific delta achieved: best-attained loss and the efficiency frontier. Using this environment, we achieve a new state-of-the-art training time, improving upon the previous record by 3 seconds, and qualitatively observe the emergence of novel algorithmic ideas. Moreover, comparisons between models and agents remain possible, but they are a means, not the end; the benchmark's purpose is to catalyze reusable improvements to the language modeling stack. With this release, the overarching goal is to seed a community shift from static problem leaderboards to test-time research on open-ended yet measurable scientific problems. In this new paradigm, progress on the benchmark is progress on the science, thus reframing "benchmarking" as a vehicle for scientific advancement.

</details>


### [142] [On the failure of ReLU activation for physics-informed machine learning](https://arxiv.org/abs/2512.11184)
*Conor Rowan*

Main category: cs.LG

TL;DR: 本文诊断了ReLU激活函数在物理信息机器学习中表现不佳的原因，指出其在自动微分过程中无法准确表征不连续场的导数，导致物理信息损失梯度误设。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究发现ReLU在物理信息机器学习中逊于其他激活函数（如sigmoid、tanh、swish），但其根本原因尚未被深入解释。本文旨在揭示ReLU在该类问题中性能差的内在机制。

Method: 通过理论分析与实验验证，重点考察ReLU在仅含一阶导数的变分问题中的表现，并分析PyTorch自动微分对不连续激活函数二阶导数的处理缺陷。

Result: 证实ReLU即使在一阶变分问题中也失败；根本原因在于其二阶导数在自动微分中未被正确定义，导致物理约束损失的梯度计算错误。

Conclusion: ReLU在物理信息神经网络中性能差并非仅因高阶微分方程限制，更关键的是自动微分框架对其广义导数处理不当；应谨慎选用或改进不连续激活函数。

Abstract: Physics-informed machine learning uses governing ordinary and/or partial differential equations to train neural networks to represent the solution field. Like any machine learning problem, the choice of activation function influences the characteristics and performance of the solution obtained from physics-informed training. Several studies have compared common activation functions on benchmark differential equations, and have unanimously found that the rectified linear unit (ReLU) is outperformed by competitors such as the sigmoid, hyperbolic tangent, and swish activation functions. In this work, we diagnose the poor performance of ReLU on physics-informed machine learning problems. While it is well-known that the piecewise linear form of ReLU prevents it from being used on second-order differential equations, we show that ReLU fails even on variational problems involving only first derivatives. We identify the cause of this failure as second derivatives of the activation, which are taken not in the formulation of the loss, but in the process of training. Namely, we show that automatic differentiation in PyTorch fails to characterize derivatives of discontinuous fields, which causes the gradient of the physics-informed loss to be mis-specified, thus explaining the poor performance of ReLU.

</details>


### [143] [Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits](https://arxiv.org/abs/2512.11345)
*Minwoo Park,Junwoo Chang,Jongeun Choi,Roberto Horowitz*

Main category: cs.LG

TL;DR: 本文提出了一种对等变扩散策略（EDPs）进行对称性感知强化学习引导的理论框架与方法，证明了EDP扩散过程的等变性，并设计了适配的群不变潜噪声MDP，实验表明利用对称性可显著提升样本效率、防止价值发散并改善策略性能。


<details>
  <summary>Details</summary>
Motivation: 标准非等变强化学习在引导等变扩散策略（EDPs）时忽略其内在几何对称性，导致样本效率低且训练不稳定；需建立与EDP对称性兼容的RL引导机制。

Method: 从理论上证明EDP扩散过程的等变性，导出群不变潜噪声MDP；基于此构建对称性感知的引导框架，并在不同对称性强度任务上系统比较标准、严格等变和近似等变RL策略。

Result: 验证了EDP扩散过程的等变性；实验证明对称性引导显著提升样本效率、抑制价值发散，并能在极少量演示数据下实现强策略改进；同时揭示了严格等变在对称性破坏下的实际适用边界。

Conclusion: 在EDP的RL引导中显式建模和利用几何对称性是必要且有效的；所提对称性感知框架为生成式策略优化提供了更鲁棒、高效的新范式。

Abstract: Equivariant diffusion policies (EDPs) combine the generative expressivity of diffusion models with the strong generalization and sample efficiency afforded by geometric symmetries. While steering these policies with reinforcement learning (RL) offers a promising mechanism for fine-tuning beyond demonstration data, directly applying standard (non-equivariant) RL can be sample-inefficient and unstable, as it ignores the symmetries that EDPs are designed to exploit. In this paper, we theoretically establish that the diffusion process of an EDP is equivariant, which in turn induces a group-invariant latent-noise MDP that is well-suited for equivariant diffusion steering. Building on this theory, we introduce a principled symmetry-aware steering framework and compare standard, equivariant, and approximately equivariant RL strategies through comprehensive experiments across tasks with varying degrees of symmetry. While we identify the practical boundaries of strict equivariance under symmetry breaking, we show that exploiting symmetry during the steering process yields substantial benefits-enhancing sample efficiency, preventing value divergence, and achieving strong policy improvements even when EDPs are trained from extremely limited demonstrations.

</details>


### [144] [Beyond Memorization: Gradient Projection Enables Selective Learning in Diffusion Models](https://arxiv.org/abs/2512.11194)
*Divya Kothandaraman,Jaclyn Pytlarz*

Main category: cs.LG

TL;DR: 本文提出了一种梯度投影框架，用于在文本到图像扩散模型中实现概念级特征的定向“遗忘”，以防止对敏感或专有概念的记忆，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型存在记忆训练数据中敏感/专有概念的安全与知识产权风险；传统去记忆方法无法系统性地消除概念级特征的记忆，而简单剔除含敏感特征的数据又造成训练数据浪费。

Method: 在反向传播过程中，识别并消除与禁止属性嵌入对齐的训练信号：将每个梯度更新投影到敏感特征嵌入空间的正交补空间，从而完全消除该特征对模型参数的影响。

Result: 在大量实验中显著降低模型对敏感概念的记忆，同时严格保持生成图像的质量和语义保真度。

Conclusion: 该方法将记忆控制重构为选择性学习，为构建知识产权安全与隐私保护的生成式AI提供了新范式。

Abstract: Memorization in large-scale text-to-image diffusion models poses significant security and intellectual property risks, enabling adversarial attribute extraction and the unauthorized reproduction of sensitive or proprietary features. While conventional dememorization techniques, such as regularization and data filtering, limit overfitting to specific training examples, they fail to systematically prevent the internalization of prohibited concept-level features. Simply discarding all images containing a sensitive feature wastes invaluable training data, necessitating a method for selective unlearning at the concept level.
  To address this, we introduce a Gradient Projection Framework designed to enforce a stringent requirement of concept-level feature exclusion. Our defense operates during backpropagation by systematically identifying and excising training signals aligned with embeddings of prohibited attributes. Specifically, we project each gradient update onto the orthogonal complement of the sensitive feature's embedding space, thereby zeroing out its influence on the model's weights. Our method integrates seamlessly into standard diffusion model training pipelines and complements existing defenses. We analyze our method against an adversary aiming for feature extraction. In extensive experiments, we demonstrate that our framework drastically reduces memorization while rigorously preserving generation quality and semantic fidelity. By reframing memorization control as selective learning, our approach establishes a new paradigm for IP-safe and privacy-preserving generative AI.

</details>


### [145] [Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents](https://arxiv.org/abs/2512.11584)
*Stefan Tabakov,Asen Popov,Dimitar Dimitrov,S. Ensiye Kiyamousavi,Vladimir Hristov,Boris Kraychev*

Main category: cs.LG

TL;DR: 本文提出Atomic Action Slicing（AAS）方法，将长周期视觉-语言-动作演示分解为短小、类型化的原子动作片段，提升VLA模型泛化能力；在LIBERO基准上验证了其有效性，并发布了GATE-VLAP数据集。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型泛化能力差，尤其在面对新技能或物体组合的任务时表现不佳。

Method: 提出Atomic Action Slicing（AAS）方法，利用大模型（如Gemini 2.5 Pro）对LIBERO演示进行原子动作切片，生成带动作类型、时间跨度和置信度标签的原子段数据集；并基于该数据集微调CLIP-RT+模型。

Result: AAS生成了2124个经验证的原子动作段；更强的切片器（Gemini 2.5 Pro）在关键帧扰动下仍保持鲁棒性；CLIP-RT+微调后在LIBERO-Goal和LIBERO-Long上的任务成功率分别从94.2%→95.3%、83.8%→88.8%。

Conclusion: AAS通过 planner-aligned 的原子动作分解提升了VLA模型的可规划性与可学习性，显著增强泛化能力，并推动开放数据集建设。

Abstract: Current vision-language-action (VLA) models generalize poorly, particularly when tasks require new compositions of skills or objects. We introduce Atomic Action Slicing (AAS), a planner-aligned approach that decomposes long-horizon demonstrations into short, typed atomic actions that are easier for planners to use and policies to learn. Using LIBERO demonstrations, AAS produces a validated dataset of 2,124 atomic segments labeled with action type, temporal span, and confidence. A stronger segmenter (Gemini 2.5 Pro) closely matches planner-defined plans and remains robust under keyframe jitter, while smaller models perform worse on multi-object tasks. Fine-tuning CLIP-RT+ on our atomic dataset improves task success from 94.2% to 95.3% on LIBERO-Goal and 83.8% to 88.8% on LIBERO-Long. We publicly release the GATE-VLAP dataset on HuggingFace(https://huggingface.co/datasets/gate-institute/GATE-VLAP-datasets)

</details>


### [146] [Fast EXP3 Algorithms](https://arxiv.org/abs/2512.11201)
*Ryoma Sato,Shinji Ito*

Main category: cs.LG

TL;DR: 本文指出EXP3算法可以在每轮常数时间内实现，并提出了更实用的算法，同时分析了这些算法在遗憾界和时间复杂度之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 提高EXP3算法的实用性与计算效率，解决其在实际应用中可能存在的高时间复杂度问题。

Method: 提出改进的EXP3变体算法，实现常数时间每轮更新，并理论分析其遗憾界与时间复杂度的关系。

Result: 证明EXP3可被优化至常数时间每轮；给出若干新算法及其对应的遗憾-效率权衡分析。

Conclusion: 在保持合理遗憾界的同时，可通过算法设计显著降低EXP3类算法的时间复杂度，提升在线学习算法的实际部署可行性。

Abstract: We point out that EXP3 can be implemented in constant time per round, propose more practical algorithms, and analyze the trade-offs between the regret bounds and time complexities of these algorithms.

</details>


### [147] [Latent Variable Causal Discovery under Selection Bias](https://arxiv.org/abs/2512.11219)
*Haoyue Dai,Yiwen Qiu,Ignavier Ng,Xinshuai Dong,Peter Spirtes,Kun Zhang*

Main category: cs.LG

TL;DR: 本文研究了在存在选择偏差的情况下，如何利用秩约束来识别潜在变量因果结构，提出了一种图论刻画方法，并验证了一因子模型在选择偏差下的可识别性。


<details>
  <summary>Details</summary>
Motivation: 解决潜在变量因果发现中的选择偏差问题，目前缺乏适用于该场景的统计工具。

Method: 基于线性高斯模型，推广条件独立性约束为秩约束，利用协方差子矩阵的秩信息，并给出图论刻画。

Result: 证明选择偏差下协方差矩阵的秩仍能反映因果结构与选择机制；一因子模型在选择偏差下可被识别；实验验证了方法有效性。

Conclusion: 秩约束是一种有效处理选择偏差下潜在变量因果发现的新工具，拓展了因果推断在复杂偏差场景下的适用性。

Abstract: Addressing selection bias in latent variable causal discovery is important yet underexplored, largely due to a lack of suitable statistical tools: While various tools beyond basic conditional independencies have been developed to handle latent variables, none have been adapted for selection bias. We make an attempt by studying rank constraints, which, as a generalization to conditional independence constraints, exploits the ranks of covariance submatrices in linear Gaussian models. We show that although selection can significantly complicate the joint distribution, interestingly, the ranks in the biased covariance matrices still preserve meaningful information about both causal structures and selection mechanisms. We provide a graph-theoretic characterization of such rank constraints. Using this tool, we demonstrate that the one-factor model, a classical latent variable model, can be identified under selection bias. Simulations and real-world experiments confirm the effectiveness of using our rank constraints.

</details>


### [148] [Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference](https://arxiv.org/abs/2512.11221)
*Adilet Metinov,Gulida M. Kudakeeva,Bolotbek uulu Nursultan,Gulnara D. Kabaeva*

Main category: cs.LG

TL;DR: 本文提出ASR-KF-EGR，一种无需训练的推理时框架，通过熵引导的软冻结与恢复机制，显著减少KV缓存占用，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决长上下文大语言模型在内存受限场景下的高效部署问题，避免传统驱逐方法永久丢失上下文信息。

Method: 引入可逆的软冻结机制，在滑动注意力窗口内识别并暂时冻结低重要性token的KV更新；所有token保留在非GPU存储中，按需恢复；采用次线性冻结调度策略防止过度压缩。

Result: 在LLaMA-3 8B上实现55–67%的活跃KV缓存缩减，维持生成质量并通过needle-in-haystack检索测试。

Conclusion: ASR-KF-EGR是一种架构无关、无需微调的实用方案，适用于内存受限的长上下文LLM部署。

Abstract: We present Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery (ASR-KF-EGR), a training-free inference-time framework for efficient large language model generation. Our method introduces a reversible soft-freeze mechanism that temporarily suspends key-value (KV) updates for low-importance tokens identified within a sliding attention window. Unlike eviction-based approaches that permanently discard context, ASR-KF-EGR preserves all tokens in off-GPU storage and restores them on demand. We extend the framework with sublinear freeze scheduling, where freeze duration grows sublinearly with repeated low-importance detections, preventing over-aggressive compression. Preliminary experiments on LLaMA-3 8B demonstrate 55-67% reduction in active KV cache size while maintaining generation quality and passing needle-in-haystack retrieval tests. The method is architecture-agnostic, requires no fine-tuning, and provides a practical solution for memory-constrained deployment of long-context LLMs.

</details>


### [149] [Task-Aware Multi-Expert Architecture For Lifelong Deep Learning](https://arxiv.org/abs/2512.11243)
*Jianyu Wang,Jacob Nean-Hua Sheikh,Cat P. Le,Hoda Bidkhori*

Main category: cs.LG

TL;DR: TAME is a lifelong deep learning method that uses task-aware multi-expert selection, replay buffers, and attention mechanisms to balance adaptation to new tasks and retention of old knowledge.


<details>
  <summary>Details</summary>
Motivation: To address catastrophic forgetting in lifelong deep learning while enabling flexible adaptation to sequential tasks.

Method: TAME maintains a pool of pretrained experts, selects the most relevant one per task using task similarity, integrates features via a shared dense layer, employs a replay buffer with stored samples and embeddings, and applies an attention mechanism to prioritize relevant past information during training.

Result: TAME improves accuracy on new binary classification tasks from CIFAR-100 while sustaining performance on earlier tasks.

Conclusion: TAME effectively balances adaptation and retention in lifelong learning, demonstrating superior continual learning capability compared to standard approaches.

Abstract: Lifelong deep learning (LDL) trains neural networks to learn sequentially across tasks while preserving prior knowledge. We propose Task-Aware Multi-Expert (TAME), a continual learning algorithm that leverages task similarity to guide expert selection and knowledge transfer. TAME maintains a pool of pretrained neural networks and activates the most relevant expert for each new task. A shared dense layer integrates features from the chosen expert to generate predictions. To reduce catastrophic forgetting, TAME uses a replay buffer that stores representative samples and embeddings from previous tasks and reuses them during training. An attention mechanism further prioritizes the most relevant stored information for each prediction. Together, these components allow TAME to adapt flexibly while retaining important knowledge across evolving task sequences. Experiments on binary classification tasks derived from CIFAR-100 show that TAME improves accuracy on new tasks while sustaining performance on earlier ones, highlighting its effectiveness in balancing adaptation and retention in lifelong learning settings.

</details>


### [150] [Insight Miner: A Time Series Analysis Dataset for Cross-Domain Alignment with Natural Language](https://arxiv.org/abs/2512.11251)
*Yunkai Zhang,Yawen Zhang,Ming Zheng,Kezhen Chen,Chongyang Gao,Ruian Ge,Siyuan Teng,Amine Jelloul,Jinmeng Rao,Xiaoyuan Guo,Chiang-Wei Fang,Zeyu Zheng,Jie Yang*

Main category: cs.LG

TL;DR: 本文提出了Insight Miner，一个用于生成高质量时间序列描述的多模态大模型，并构建了首个通用领域的时间序列-语言对齐数据集TS-Insights（含10万样本），通过智能体工作流结合统计特征提取与GPT-4合成描述；经指令微调后，该模型在时间序列描述生成任务上超越LLaVA和GPT-4等现有模型。


<details>
  <summary>Details</summary>
Motivation: 时间序列分析通常依赖深厚领域知识，过程耗时费力，亟需自动化、智能化方法降低门槛。

Method: 提出多模态大模型Insight Miner；构建首个通用时间序列-语言对齐数据集TS-Insights（10万窗口，来自20个预测数据集），采用基于统计工具+GPT-4的新型智能体工作流生成描述；并对模型进行指令微调。

Result: Insight Miner在时间序列描述生成任务上显著优于LLaVA和GPT-4等当前最优多模态模型。

Conclusion: 验证了大模型可有效理解并生成时间序列洞察，为将时间序列作为大语言模型原生输入模态奠定基础。

Abstract: Time-series data is critical across many scientific and industrial domains, including environmental analysis, agriculture, transportation, and finance. However, mining insights from this data typically requires deep domain expertise, a process that is both time-consuming and labor-intensive. In this paper, we propose \textbf{Insight Miner}, a large-scale multimodal model (LMM) designed to generate high-quality, comprehensive time-series descriptions enriched with domain-specific knowledge. To facilitate this, we introduce \textbf{TS-Insights}\footnote{Available at \href{https://huggingface.co/datasets/zhykoties/time-series-language-alignment}{https://huggingface.co/datasets/zhykoties/time-series-language-alignment}.}, the first general-domain dataset for time series and language alignment. TS-Insights contains 100k time-series windows sampled from 20 forecasting datasets. We construct this dataset using a novel \textbf{agentic workflow}, where we use statistical tools to extract features from raw time series before synthesizing them into coherent trend descriptions with GPT-4. Following instruction tuning on TS-Insights, Insight Miner outperforms state-of-the-art multimodal models, such as LLaVA \citep{liu2023llava} and GPT-4, in generating time-series descriptions and insights. Our findings suggest a promising direction for leveraging LMMs in time series analysis, and serve as a foundational step toward enabling LLMs to interpret time series as a native input modality.

</details>


### [151] [A Simple Generalisation of the Implicit Dynamics of In-Context Learning](https://arxiv.org/abs/2512.11255)
*Francesco Innocenti,El Mehdi Achour*

Main category: cs.LG

TL;DR: 本文推广了Dherin等人（2025）关于Transformer中上下文学习隐式权重更新的理论，将其扩展至所有位置、任意层及含层归一化的更真实残差块，并通过线性回归任务进行了实证验证。


<details>
  <summary>Details</summary>
Motivation: 此前ICL理论多基于简化模型和数据设定，而Dherin等人（2025）首次在抽象Transformer块中揭示其隐式执行权重更新；本文旨在将该理论推广至更贴近实际架构的情形。

Method: 理论推导：将Dherin等人的隐式权重更新机制推广至任意序列位置、任意Transformer层及含LayerNorm的残差结构；实验验证：在简单上下文线性回归任务上检验理论预测，并分析不同token及各层间隐式更新的关系。

Result: 成功将隐式权重更新理论推广至更通用设定；实验证实该机制在多个位置与层中均成立；揭示了层内与层间token隐式更新的关联模式。

Conclusion: 本文显著提升了ICL隐式学习理论的普适性与实用性，为在大规模模型上进一步验证奠定了基础。

Abstract: In-context learning (ICL) refers to the ability of a model to learn new tasks from examples in its input without any parameter updates. In contrast to previous theories of ICL relying on toy models and data settings, recently it has been shown that an abstraction of a transformer block can be seen as implicitly updating the weights of its feedforward network according to the context (Dherin et al., 2025). Here, we provide a simple generalisation of this result for (i) all sequence positions beyond the last, (ii) any transformer block beyond the first, and (iii) more realistic residual blocks including layer normalisation. We empirically verify our theory on simple in-context linear regression tasks and investigate the relationship between the implicit updates related to different tokens within and between blocks. These results help to bring the theory of Dherin et al. (2025) even closer to practice, with potential for validation on large-scale models.

</details>


### [152] [Features Emerge as Discrete States: The First Application of SAEs to 3D Representations](https://arxiv.org/abs/2512.11263)
*Albert Miao,Chenliang Zhou,Jiawei Zhou,Cengiz Oztireli*

Main category: cs.LG

TL;DR: 本文首次将稀疏自编码器（SAEs）应用于3D领域，分析3D重建VAE的特征分解机制，发现其隐空间呈现离散状态与相变式激活模式，并以此解释位置编码偏好、消融损失的S型曲线及相变点双峰分布等现象。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAEs）在文本领域已成功实现高语义价值的特征分解，但在3D等非文本领域应用极少，限制了对神经网络特征表示本质的理论探索。

Method: 将SAEs应用于基于Objaverse数据集（53k个3D模型）训练的先进3D重建VAE，对其隐层激活进行字典学习与特征分析，并构建基于离散状态与相变的理论框架来解释观测现象。

Result: 发现3D重建模型隐空间呈现离散而非连续的特征编码；识别出类相变的特征激活模式；并据此统一解释了位置编码偏好、消融时重建误差呈sigmoid变化、以及相变点分布呈双峰等三个反直觉现象。

Conclusion: 3D生成模型的隐空间本质上近似于离散状态空间，其特征学习动力学由类似物理相变的过程驱动；该发现不仅揭示了超参数叠加干扰的重分配机制，也为跨模态特征分解提供了可推广的分析框架。

Abstract: Sparse Autoencoders (SAEs) are a powerful dictionary learning technique for decomposing neural network activations, translating the hidden state into human ideas with high semantic value despite no external intervention or guidance. However, this technique has rarely been applied outside of the textual domain, limiting theoretical explorations of feature decomposition. We present the \textbf{first application of SAEs to the 3D domain}, analyzing the features used by a state-of-the-art 3D reconstruction VAE applied to 53k 3D models from the Objaverse dataset. We observe that the network encodes discrete rather than continuous features, leading to our key finding: \textbf{such models approximate a discrete state space, driven by phase-like transitions from feature activations}. Through this state transition framework, we address three otherwise unintuitive behaviors -- the inclination of the reconstruction model towards positional encoding representations, the sigmoidal behavior of reconstruction loss from feature ablation, and the bimodality in the distribution of phase transition points. This final observation suggests the model \textbf{redistributes the interference caused by superposition to prioritize the saliency of different features}. Our work not only compiles and explains unexpected phenomena regarding feature decomposition, but also provides a framework to explain the model's feature learning dynamics. The code and dataset of encoded 3D objects will be available on release.

</details>


### [153] [SRLR: Symbolic Regression based Logic Recovery to Counter Programmable Logic Controller Attacks](https://arxiv.org/abs/2512.11298)
*Hao Zhou,Suman Sourav,Binbin Chen,Ke Yu*

Main category: cs.LG

TL;DR: 本文提出SRLR方法，基于符号回归从PLC的输入输出中恢复其控制逻辑，并生成可解释的攻击检测规则，结合ICS领域特性提升恢复精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有PLC逻辑攻击检测方法存在依赖专家经验/源码（规格化方法）或缺乏可解释性（机器学习方法）的问题，亟需一种仅需I/O数据、可解释且适用于复杂ICS环境的逻辑恢复方案。

Method: 提出SRLR（Symbolic Regression based Logic Recovery），改进深度符号回归，融入四大ICS特性：频域建模优势、多模式运行与稀疏切换、抗噪输入滤波、公式复杂度控制，从而实现高精度逻辑恢复与可解释规则生成。

Result: SRLR在多种ICS场景下持续优于现有方法，逻辑恢复精度最高提升39%；在含数百台调压器的实际配电网中验证了其大规模、多配置下的稳定性与有效性。

Conclusion: SRLR通过融合ICS领域知识增强符号回归，在无需源码和专家干预前提下，实现了高精度、可解释的PLC逻辑恢复与攻击检测，为ICS安全提供了新范式。

Abstract: Programmable Logic Controllers (PLCs) are critical components in Industrial Control Systems (ICSs). Their potential exposure to external world makes them susceptible to cyber-attacks. Existing detection methods against controller logic attacks use either specification-based or learnt models. However, specification-based models require experts' manual efforts or access to PLC's source code, while machine learning-based models often fall short of providing explanation for their decisions. We design SRLR -- a it Symbolic Regression based Logic Recovery} solution to identify the logic of a PLC based only on its inputs and outputs. The recovered logic is used to generate explainable rules for detecting controller logic attacks. SRLR enhances the latest deep symbolic regression methods using the following ICS-specific properties: (1) some important ICS control logic is best represented in frequency domain rather than time domain; (2) an ICS controller can operate in multiple modes, each using different logic, where mode switches usually do not happen frequently; (3) a robust controller usually filters out outlier inputs as ICS sensor data can be noisy; and (4) with the above factors captured, the degree of complexity of the formulas is reduced, making effective search possible. Thanks to these enhancements, SRLR consistently outperforms all existing methods in a variety of ICS settings that we evaluate. In terms of the recovery accuracy, SRLR's gain can be as high as 39% in some challenging environment. We also evaluate SRLR on a distribution grid containing hundreds of voltage regulators, demonstrating its stability in handling large-scale, complex systems with varied configurations.

</details>


### [154] [QGEC : Quantum Golay Code Error Correction](https://arxiv.org/abs/2512.11307)
*Hideo Mukai,Hoshitaro Ohnishi*

Main category: cs.LG

TL;DR: 本文提出了一种基于经典Golay码的量子纠错方法QGEC，并利用Transformer模型进行解码，实验表明其在特定噪声模型下比toric码具有更高的解码精度和更优的资源效率。


<details>
  <summary>Details</summary>
Motivation: 量子比特易受噪声干扰，需高效量子纠错（QEC）方法；经典Golay码具有优异编码性能，值得探索其在量子纠错中的应用。

Method: 提出Quantum Golay code Error Correction（QGEC），使用Golay码构造稳定子码，并采用Transformer模型作为解码器，在不同生成多项式权重和噪声模型（含不同比特翻转与相位翻转相关性）下评估解码性能，并与toric码对比。

Result: 在离散均匀分布噪声下，Golay码（23个数据量子比特、距离7）解码精度高于toric码（50个数据量子比特、距离5）；噪声相关性越小，解码精度越高；生成多项式权重对精度影响甚微。

Conclusion: 基于Transformer的Golay码量子纠错方案有望以更少量子资源实现更高容错能力，为高效容错量子计算提供新路径。

Abstract: Quantum computers have the possibility of a much reduced calculation load compared with classical computers in specific problems. Quantum error correction (QEC) is vital for handling qubits, which are vulnerable to external noise. In QEC, actual errors are predicted from the results of syndrome measurements by stabilizer generators, in place of making direct measurements of the data qubits. Here, we propose Quantum Golay code Error Correction (QGEC), a QEC method using Golay code, which is an efficient coding method in classical information theory. We investigated our method's ability in decoding calculations with the Transformer. We evaluated the accuracy of the decoder in a code space defined by the generative polynomials with three different weights sets and three noise models with different correlations of bit-flip error and phase-flip error. Furthermore, under a noise model following a discrete uniform distribution, we compared the decoding performance of Transformer decoders with identical architectures trained respectively on Golay and toric codes. The results showed that the noise model with the smaller correlation gave better accuracy, while the weights of the generative polynomials had little effect on the accuracy of the decoder. In addition, they showed that Golay code requiring 23 data qubits and having a code distance of 7 achieved higher decoding accuracy than toric code which requiring 50 data qubits and having a code distance of 5. This suggests that implementing quantum error correction using a Transformer may enable the Golay code to realize fault-tolerant quantum computation more efficiently.

</details>


### [155] [Benchmarking the Generality of Vision-Language-Action Models](https://arxiv.org/abs/2512.11315)
*Pranav Guruprasad,Sudipta Chowdhury,Harsh Sikka,Mridul Sharma,Helen Lu,Sean Rivera,Aryan Khurana,Hangliang Ren,Yangyue Wang*

Main category: cs.LG

TL;DR: 本文提出MultiNet v1.0统一基准，用于评估视觉语言模型（VLMs）和视觉语言动作模型（VLAs）在六大能力维度上的跨域泛化能力；实验发现当前主流模型（如GPT-5、Pi0、Magma）在未见领域、新模态或任务迁移时性能显著下降，暴露出模态错位、输出不稳定与知识灾难性遗忘等问题，揭示了通用智能愿景与现实能力之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法碎片化，难以真实衡量多模态基础模型是否具备跨域泛化能力，亟需统一、全面的基准来检验‘通用智能代理’的实际水平。

Method: 构建MultiNet v1.0统一基准，覆盖视觉定位、空间推理、工具使用、物理常识、多智能体协作和连续机器人控制六大能力维度，并在GPT-5、Pi0、Magma等模型上开展跨域泛化评测。

Result: 所有被测模型在训练分布内表现良好，但在跨域、跨模态或任务迁移场景下均出现显著性能退化，具体表现为模态错位、输出格式不稳定及知识灾难性遗忘。

Conclusion: 当前多模态基础模型距离真正意义上的通用智能仍有巨大差距；MultiNet v1.0为诊断泛化瓶颈和推动下一代通用代理发展提供了标准化评估平台。

Abstract: Generalist multimodal agents are expected to unify perception, language, and control - operating robustly across diverse real world domains. However, current evaluation practices remain fragmented across isolated benchmarks, making it difficult to assess whether today's foundation models truly generalize beyond their training distributions. We introduce MultiNet v1.0, a unified benchmark for measuring the cross domain generality of vision language models (VLMs) and vision language action models (VLAs) across six foundational capability regimes. Visual grounding, spatial reasoning, tool use, physical commonsense, multi agent coordination, and continuous robot control. Evaluating GPT 5, Pi0, and Magma, we find that no model demonstrates consistent generality. All exhibit substantial degradation on unseen domains, unfamiliar modalities, or cross domain task shifts despite strong performance within their training distributions.These failures manifest as modality misalignment, output format instability, and catastrophic knowledge degradation under domain transfer.Our findings reveal a persistent gap between the aspiration of generalist intelligence and the actual capabilities of current foundation models.MultiNet v1.0 provides a standardized evaluation substrate for diagnosing these gaps and guiding the development of future generalist agents.Code, data, and leaderboards are publicly available.

</details>


### [156] [Condensation-Concatenation Framework for Dynamic Graph Continual Learning](https://arxiv.org/abs/2512.11317)
*Tingxu Yan,Ye Yuan*

Main category: cs.LG

TL;DR: 本文提出了一种面向动态图的持续学习新框架CCC，通过图快照压缩与历史嵌入选择性拼接，缓解结构变化导致的节点遗忘问题，并改进了适用于动态图的遗忘度量。


<details>
  <summary>Details</summary>
Motivation: 现有动态图持续学习方法忽视了拓扑结构变化对已有节点造成的灾难性遗忘问题。

Method: 提出Condensation-Concatenation-based Continual Learning（CCC）框架：1）将历史图快照压缩为保持标签分布和拓扑特性的紧凑语义表示；2）选择性地将历史嵌入与当前图表示拼接；3）改进遗忘度量（FM），量化结构更新导致的已有节点预测性能下降。

Result: 在四个真实世界数据集上的实验表明，CCC显著优于现有最先进方法。

Conclusion: CCC有效缓解了动态图中因结构演化引发的灾难性遗忘，提升了持续学习的稳定性和泛化能力。

Abstract: Dynamic graphs are prevalent in real-world scenarios, where continuous structural changes induce catastrophic forgetting in graph neural networks (GNNs). While continual learning has been extended to dynamic graphs, existing methods overlook the effects of topological changes on existing nodes. To address it, we propose a novel framework for continual learning on dynamic graphs, named Condensation-Concatenation-based Continual Learning (CCC). Specifically, CCC first condenses historical graph snapshots into compact semantic representations while aiming to preserve the original label distribution and topological properties. Then it concatenates these historical embeddings with current graph representations selectively. Moreover, we refine the forgetting measure (FM) to better adapt to dynamic graph scenarios by quantifying the predictive performance degradation of existing nodes caused by structural updates. CCC demonstrates superior performance over state-of-the-art baselines across four real-world datasets in extensive experiments.

</details>


### [157] [TV2TV: A Unified Framework for Interleaved Language and Video Generation](https://arxiv.org/abs/2512.05103)
*Xiaochuang Han,Youssef Emad,Melissa Hall,John Nguyen,Karthik Padthe,Liam Robbins,Amir Bar,Delong Chen,Michal Drozdzal,Maha Elbayad,Yushi Hu,Shang-Wen Li,Sreya Dutta Roy,Jakob Verbeek,XuDong Wang,Marjan Ghazvininejad,Luke Zettlemoyer,Emily Dinan*

Main category: cs.LG

TL;DR: 本文提出TV2TV，一种融合语言建模与视频流匹配的统一生成框架，通过文本与视频交替生成实现‘用文字思考、用像素行动’，显著提升视频生成质量、提示对齐性与细粒度可控性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在处理需语义分支或多次高层推理的复杂视频时仍存在困难。

Method: 提出TV2TV框架，采用混合Transformer（MoT）架构联合学习语言建模（下一词预测）和视频流匹配（下一帧预测），并在推理时动态交替文本与视频生成；支持用户在任意时刻以文本干预生成过程。

Result: 在游戏视频数据上显著提升视觉质量与可控性；扩展至自然视频（如体育视频+VLM生成的动作描述），仍保持高质量与提示对齐。

Conclusion: TV2TV为具备开放性文本推理与控制能力的视频生成提供了新范式。

Abstract: Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from recent LM reasoning advances to address this challenge. More specifically, we present TV2TV, a unified generative modeling framework which decomposes video generation into an interleaved text and video generation process. TV2TV jointly learns language modeling (next-token prediction) and video flow matching (next-frame prediction) using a Mixture-of-Transformers (MoT) architecture. At inference time, TV2TV decides when to alternate between generating text and video frames, allowing the model to "think in words" about subsequent content before ``acting in pixels'' to produce frames. This design offloads much of the responsibility for deciding what should happen next to the language modeling tower, enabling improved visual quality and prompt alignment of generated videos. It also enables fine-grained controllability, allowing users to modify the video generation trajectory through text interventions at any point in the process. In controlled experiments on video game data, TV2TV demonstrates substantial improvements in both visual quality and controllability. TV2TV also scales to natural videos, as we show by augmenting sports videos with interleaved natural language action descriptions using vision-language models (VLMs). Training TV2TV on this corpus yields strong visual quality and prompt alignment, showcasing the model's ability to reason about and generate complex real-world action sequences. Together, these results highlight TV2TV as a promising step toward video generation with open-ended textual reasoning and control.

</details>


### [158] [Pace: Physics-Aware Attentive Temporal Convolutional Network for Battery Health Estimation](https://arxiv.org/abs/2512.11332)
*Sara Sameer,Wei Zhang,Kannan Dhivya Dharshini,Xin Lou,Yulin Gao,Terence Goh,Qingyu Yan*

Main category: cs.LG

TL;DR: 本文提出了一种名为Pace的物理感知注意力时序卷积网络，用于电池健康状态估计，融合了传感器数据与等效电路模型提取的物理特征，并设计了三种电池专用模块，在公开数据集上显著优于现有方法，且可在树莓派上实时部署。


<details>
  <summary>Details</summary>
Motivation: 电池健康状态管理对安全性、成本效益和可持续性至关重要，但现有方法在精度和实用性上仍有不足。

Method: 提出Pace模型：融合原始传感器数据与基于等效电路模型的物理特征；设计稀疏时序块、分块注意力块和双头输出块三个电池专用模块，分别用于高效时序编码、上下文建模及长短时退化模式融合。

Result: 在大型公开数据集上，Pace相较两个最优基线模型平均性能提升6.5倍和2.0倍；并在树莓派上实现可行的实时边缘部署。

Conclusion: Pace是一种兼具高精度与实用性的电池健康分析方案，适用于多样化使用场景和边缘计算环境。

Abstract: Batteries are critical components in modern energy systems such as electric vehicles and power grid energy storage. Effective battery health management is essential for battery system safety, cost-efficiency, and sustainability. In this paper, we propose Pace, a physics-aware attentive temporal convolutional network for battery health estimation. Pace integrates raw sensor measurements with battery physics features derived from the equivalent circuit model. We develop three battery-specific modules, including dilated temporal blocks for efficient temporal encoding, chunked attention blocks for context modeling, and a dual-head output block for fusing short- and long-term battery degradation patterns. Together, the modules enable Pace to predict battery health accurately and efficiently in various battery usage conditions. In a large public dataset, Pace performs much better than existing models, achieving an average performance improvement of 6.5 and 2.0x compared to two best-performing baseline models. We further demonstrate its practical viability with a real-time edge deployment on a Raspberry Pi. These results establish Pace as a practical and high-performance solution for battery health analytics.

</details>


### [159] [Spectral entropy prior-guided deep feature fusion architecture for magnetic core loss](https://arxiv.org/abs/2512.11334)
*Cong Yao,Chunye Gong,Jin Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种融合物理先验与深度学习的混合模型SEPI-TFPNet，用于提升磁性元件铁芯损耗建模的准确性、可解释性与跨分布泛化能力，并在MagNet数据集上验证其优于24种对比模型。


<details>
  <summary>Details</summary>
Motivation: 传统铁芯损耗建模精度不足；纯数据驱动模型缺乏可解释性和跨分布泛化能力；IEEE MagNet挑战赛推动数据驱动磁设计发展。

Method: 提出混合模型SEPI-TFPNet：物理先验子模块基于谱熵判别机制动态选择最优经验模型；数据驱动子模块融合CNN、多头注意力与BiLSTM提取B-t序列特征；引入自适应特征融合模块增强多模态特征交互。

Result: 在包含多种磁性材料的MagNet数据集上，该方法相较21个2023年挑战赛代表模型及3种2024–2025年先进方法，在建模精度与鲁棒性方面均取得提升。

Conclusion: 融合物理先验与深度学习的混合建模范式能有效兼顾预测精度、可解释性与泛化能力，为高效率电力电子系统中的磁元件设计提供更可靠工具。

Abstract: Accurate core loss modeling is critical for the design of high-efficiency power electronic systems. Traditional core loss modeling methods have limitations in prediction accuracy. To advance this field, the IEEE Power Electronics Society launched the MagNet Challenge in 2023, the first international competition focused on data-driven power electronics design methods, aiming to uncover complex loss patterns in magnetic components through a data-driven paradigm. Although purely data-driven models demonstrate strong fitting performance, their interpretability and cross-distribution generalization capabilities remain limited. To address these issues, this paper proposes a hybrid model, SEPI-TFPNet, which integrates empirical models with deep learning. The physical-prior submodule employs a spectral entropy discrimination mechanism to select the most suitable empirical model under different excitation waveforms. The data-driven submodule incorporates convolutional neural networks, multi-head attention mechanisms, and bidirectional long short-term memory networks to extract flux-density time-series features. An adaptive feature fusion module is introduced to improve multimodal feature interaction and integration. Using the MagNet dataset containing various magnetic materials, this paper evaluates the proposed method and compares it with 21 representative models from the 2023 challenge and three advanced methods from 2024-2025. The results show that the proposed method achieves improved modeling accuracy and robustness.

</details>


### [160] [DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning](https://arxiv.org/abs/2512.11342)
*Jinming Ge,Linfeng Du,Likith Anaparty,Shangkun Li,Tingyuan Liang,Afzal Ahmad,Vivek Chaturvedi,Sharad Sinha,Zhiyao Xie,Jiang Xu,Wei Zhang*

Main category: cs.LG

TL;DR: 本文提出DAPO框架，通过结合程序语义提取、对比学习嵌入和分析模型硬件评估，利用强化学习自动发现面向特定设计的优化策略，在HLS中平均比Vitis HLS快2.36倍。


<details>
  <summary>Details</summary>
Motivation: 现有HLS工具依赖源自软件编译的固定优化策略，缺乏对特定设计的深度语义理解、精确硬件指标估计和先进搜索能力，导致优化效果受限。

Method: DAPO框架从控制流图和数据流图中提取程序语义，使用对比学习生成丰富嵌入，并结合解析模型进行精准硬件指标估计，联合指导强化学习智能体搜索设计特定的优化顺序。

Result: 在经典HLS设计上的评估表明，该端到端流程相比Vitis HLS平均获得2.36倍加速。

Conclusion: DAPO通过结构感知与学习驱动的方法，显著提升了HLS中优化策略的自动化与定制化水平，验证了融合语义理解、硬件建模与强化学习的有效性。

Abstract: High-Level Synthesis (HLS) tools are widely adopted in FPGA-based domain-specific accelerator design. However, existing tools rely on fixed optimization strategies inherited from software compilations, limiting their effectiveness. Tailoring optimization strategies to specific designs requires deep semantic understanding, accurate hardware metric estimation, and advanced search algorithms -- capabilities that current approaches lack.
  We propose DAPO, a design structure-aware pass ordering framework that extracts program semantics from control and data flow graphs, employs contrastive learning to generate rich embeddings, and leverages an analytical model for accurate hardware metric estimation. These components jointly guide a reinforcement learning agent to discover design-specific optimization strategies. Evaluations on classic HLS designs demonstrate that our end-to-end flow delivers a 2.36 speedup over Vitis HLS on average.

</details>


### [161] [Rethinking Expert Trajectory Utilization in LLM Post-training](https://arxiv.org/abs/2512.11470)
*Bowen Ding,Yuhan Chen,Jiayang Lv,Jiyao Yuan,Qi Zhu,Shuangshuang Tian,Dantong Zhu,Futing Wang,Heyuan Deng,Fei Mi,Lifeng Shang,Tao Lin*

Main category: cs.LG

TL;DR: 本文提出了Plasticity-Ceiling框架，理论分析并实证验证了SFT-then-RL顺序训练优于同步方法，并给出三个关键缩放准则：最佳SFT阶段切换点、数据规模与轨迹难度的作用关系、以及用最小验证损失选择专家轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有方法在后训练中如何最优利用专家轨迹尚无定论，尤其在SFT与RL的整合机制上缺乏理论支撑和实证指导。

Method: 提出Plasticity-Ceiling理论框架，将模型性能解耦为SFT基础性能与RL可塑性；通过大规模基准实验比较不同SFT-RL整合策略，并系统分析SFT阶段、数据规模、轨迹难度及验证损失等变量对最终性能的影响。

Result: 1）Sequential SFT-then-RL为最优流程；2）在SFT稳定或轻度过拟合子阶段切入RL可最大化性能上限；3）数据规模决定潜力上限，轨迹难度是性能乘子；4）最小SFT验证损失是优选专家轨迹的可靠指标。

Conclusion: 专家轨迹的价值高度依赖于SFT阶段控制与RL介入时机，而非单纯增加数据量或难度；本文提供的三类可操作准则可显著提升后训练效能。

Abstract: While effective post-training integrates Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), the optimal mechanism for utilizing expert trajectories remains unresolved. We propose the Plasticity-Ceiling Framework to theoretically ground this landscape, decomposing performance into foundational SFT performance and the subsequent RL plasticity. Through extensive benchmarking, we establish the Sequential SFT-then-RL pipeline as the superior standard, overcoming the stability deficits of synchronized approaches. Furthermore, we derive precise scaling guidelines: (1) Transitioning to RL at the SFT Stable or Mild Overfitting Sub-phase maximizes the final ceiling by securing foundational SFT performance without compromising RL plasticity; (2) Refuting ``Less is More'' in the context of SFT-then-RL scaling, we demonstrate that Data Scale determines the primary post-training potential, while Trajectory Difficulty acts as a performance multiplier; and (3) Identifying that the Minimum SFT Validation Loss serves as a robust indicator for selecting the expert trajectories that maximize the final performance ceiling. Our findings provide actionable guidelines for maximizing the value extracted from expert trajectories.

</details>


### [162] [CAT: Can Trust be Predicted with Context-Awareness in Dynamic Heterogeneous Networks?](https://arxiv.org/abs/2512.11352)
*Jie Wang,Zheng Yan,Jiahe Lan,Xuyan Li,Elisa Bertino*

Main category: cs.LG

TL;DR: 本文提出了首个支持信任动态性和真实世界异质性的上下文感知图神经网络（GNN）信任预测模型CAT，通过连续时间表示、双注意力机制和新型元路径定义实现上下文感知信任预测，在多个真实数据集上显著优于基线方法，并具备良好的可扩展性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有GNN信任预测模型存在三大缺陷：无法捕捉信任的动态性、忽略网络异质性导致语义丢失、缺乏上下文感知能力，而上下文感知是信任的基本属性。

Method: 提出CAT模型，包含图构建层、嵌入层、异质注意力层和预测层；采用连续时间表示和时间编码函数处理动态图；设计双注意力机制建模节点类型及同类型内节点的重要性；引入新型元路径定义提取上下文特征，并结合上下文嵌入与上下文感知聚合器进行预测。

Result: 在三个真实世界数据集上的实验表明，CAT在信任预测任务上全面超越五类基线方法，同时展现出对大规模图的良好可扩展性以及对信任导向和GNN导向攻击的强鲁棒性。

Conclusion: CAT是首个兼顾信任动态性、网络异质性和上下文感知能力的GNN信任预测框架，为可信AI系统提供了更精细、可靠和实用的信任建模新范式。

Abstract: Trust prediction provides valuable support for decision-making, risk mitigation, and system security enhancement. Recently, Graph Neural Networks (GNNs) have emerged as a promising approach for trust prediction, owing to their ability to learn expressive node representations that capture intricate trust relationships within a network. However, current GNN-based trust prediction models face several limitations: (i) Most of them fail to capture trust dynamicity, leading to questionable inferences. (ii) They rarely consider the heterogeneous nature of real-world networks, resulting in a loss of rich semantics. (iii) None of them support context-awareness, a basic property of trust, making prediction results coarse-grained.
  To this end, we propose CAT, the first Context-Aware GNN-based Trust prediction model that supports trust dynamicity and accurately represents real-world heterogeneity. CAT consists of a graph construction layer, an embedding layer, a heterogeneous attention layer, and a prediction layer. It handles dynamic graphs using continuous-time representations and captures temporal information through a time encoding function. To model graph heterogeneity and leverage semantic information, CAT employs a dual attention mechanism that identifies the importance of different node types and nodes within each type. For context-awareness, we introduce a new notion of meta-paths to extract contextual features. By constructing context embeddings and integrating a context-aware aggregator, CAT can predict both context-aware trust and overall trust. Extensive experiments on three real-world datasets demonstrate that CAT outperforms five groups of baselines in trust prediction, while exhibiting strong scalability to large-scale graphs and robustness against both trust-oriented and GNN-oriented attacks.

</details>


### [163] [Attacking and Securing Community Detection: A Game-Theoretic Framework](https://arxiv.org/abs/2512.11359)
*Yifan Niu,Aochuan Chen,Tingyang Xu,Jia Li*

Main category: cs.LG

TL;DR: 本文提出针对社区发现任务的对抗图攻击与防御方法，并构建了一个博弈论框架CD-GAME，用于建模攻击者与Rayleigh商防御者之间的动态交互，最终达到纳什均衡。实验表明所提方法显著优于基线，且揭示了交互式攻防中更隐蔽有效的策略模式。


<details>
  <summary>Details</summary>
Motivation: 将对抗图概念拓展至更具挑战性的社区发现任务，以应对隐私保护（如社交网络）和伪装识别（如交易网络）等现实需求。

Method: 提出面向社区发现的新型攻击与防御技术，并构建名为CD-GAME的博弈论框架，其中攻击者与基于Rayleigh商的防御者通过动态策略更新进行交互，直至收敛至纳什均衡。

Result: 所提攻击与防御方法在实验中显著优于现有基线；CD-GAME揭示了交互式场景下攻击者在纳什均衡时采用更隐蔽但仍有效的策略。

Conclusion: 交互式博弈建模（CD-GAME）比单步攻防更能反映真实对抗本质，为提升社区发现模型鲁棒性与理解隐蔽攻击行为提供了新思路与实用工具。

Abstract: It has been demonstrated that adversarial graphs, i.e., graphs with imperceptible perturbations, can cause deep graph models to fail on classification tasks. In this work, we extend the concept of adversarial graphs to the community detection problem, which is more challenging. We propose novel attack and defense techniques for community detection problem, with the objective of hiding targeted individuals from detection models and enhancing the robustness of community detection models, respectively. These techniques have many applications in real-world scenarios, for example, protecting personal privacy in social networks and understanding camouflage patterns in transaction networks. To simulate interactive attack and defense behaviors, we further propose a game-theoretic framework, called CD-GAME. One player is a graph attacker, while the other player is a Rayleigh Quotient defender. The CD-GAME models the mutual influence and feedback mechanisms between the attacker and the defender, revealing the dynamic evolutionary process of the game. Both players dynamically update their strategies until they reach the Nash equilibrium. Extensive experiments demonstrate the effectiveness of our proposed attack and defense methods, and both outperform existing baselines by a significant margin. Furthermore, CD-GAME provides valuable insights for understanding interactive attack and defense scenarios in community detection problems. We found that in traditional single-step attack or defense, attacker tends to employ strategies that are most effective, but are easily detected and countered by defender. When the interactive game reaches a Nash equilibrium, attacker adopts more imperceptible strategies that can still achieve satisfactory attack effectiveness even after defense.

</details>


### [164] [Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization](https://arxiv.org/abs/2512.11391)
*Yifan Niu,Han Xiao,Dongyi Liu,Nuo Chen,Jia Li*

Main category: cs.LG

TL;DR: 本文提出Null-Space constrained Policy Optimization (NSPO)，一种在强化学习中对大语言模型进行安全对齐的新框架，通过将安全策略梯度投影到通用任务的零空间中，缓解对齐税问题，在提升安全性的同时保持模型原有能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的安全对齐方法常导致模型遗忘通用能力（即对齐税），亟需兼顾安全性与能力保留的新方法。

Method: 提出NSPO框架，将安全策略梯度几何投影至通用任务梯度的零空间，并提供理论证明其既能保证安全优化方向，又可保留原始核心能力。

Result: 实验表明NSPO在安全性上达到SOTA，且不损害数学、代码和指令遵循等通用任务性能；仅需40%的PKU-SafeRLHF安全标注数据，具备数据高效性。

Conclusion: NSPO有效缓解了安全对齐中的能力遗忘问题，是一种兼顾安全性、能力保留与数据效率的新型对齐框架。

Abstract: As Large Language Models (LLMs) are increasingly deployed in real-world applications, it is important to ensure their behaviors align with human values, societal norms, and ethical principles. However, safety alignment under Reinforcement Learning (RL) often suffers from forgetting learned general abilities, which is also known as the alignment tax. To address this issue, we introduce Null-Space constrained Policy Optimization (NSPO), a novel RL framework for LLM safety alignment while preserving their core abilities. The safety policy gradients are geometrically projected into the null space of general tasks, thereby mitigating the safety alignment tax. In addition, we theoretically prove that NSPO preserves the model's original core capabilities, while still guaranteeing a descent direction for effective safety alignment. Extensive experiments demonstrate that NSPO outperforms existing methods by a large margin, achieving state-of-the-art safety performance without sacrificing accuracy on general tasks, including math, code, and instruction-following tasks. Notably, NSPO is data-efficient and only requires 40% of public human-annotated safety data from PKU-SafeRLHF to achieve promising safety performance, without a large amount of mixed general tasks data in existing alignment methods.

</details>


### [165] [Bhargava Cube--Inspired Quadratic Regularization for Structured Neural Embeddings](https://arxiv.org/abs/2512.11392)
*S Sairam,Prateek P Kulkarni*

Main category: cs.LG

TL;DR: 本文提出一种基于数论中Bhargava立方体代数约束的神经表示学习新方法，通过可微分辅助损失函数将数据映射到满足二次关系的三维结构化潜在空间，在MNIST上达到99.46%准确率并获得可解释嵌入。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习的潜在空间缺乏可解释性和数学一致性，亟需引入具有数学基础的结构化先验。

Method: 构建一个映射到受Bhargava组合结构启发的二次代数约束所正则化的三维潜在空间的神经网络框架，并设计独立于分类目标的可微分辅助损失函数。

Result: 在MNIST数据集上取得99.46%的分类准确率；生成的3D嵌入按数字类别自然聚类，且满足学习到的二次约束；无需显式几何监督。

Conclusion: 首次将数论结构引入神经表示学习，为在神经网络中融合结构化数学先验提供了新范式。

Abstract: We present a novel approach to neural representation learning that incorporates algebraic constraints inspired by Bhargava cubes from number theory. Traditional deep learning methods learn representations in unstructured latent spaces lacking interpretability and mathematical consistency. Our framework maps input data to constrained 3-dimensional latent spaces where embeddings are regularized to satisfy learned quadratic relationships derived from Bhargava's combinatorial structures. The architecture employs a differentiable auxiliary loss function operating independently of classification objectives, guiding models toward mathematically structured representations. We evaluate on MNIST, achieving 99.46% accuracy while producing interpretable 3D embeddings that naturally cluster by digit class and satisfy learned quadratic constraints. Unlike existing manifold learning approaches requiring explicit geometric supervision, our method imposes weak algebraic priors through differentiable constraints, ensuring compatibility with standard optimization. This represents the first application of number-theoretic constructs to neural representation learning, establishing a foundation for incorporating structured mathematical priors in neural networks.

</details>


### [166] [Sliced ReLU attention: Quasi-linear contextual expressivity via sorting](https://arxiv.org/abs/2512.11411)
*Siwan Boufadène,François-Xavier Vialard*

Main category: cs.LG

TL;DR: 本文提出了一种新的注意力机制——切片ReLU注意力（sliced ReLU attention），通过在键-查询差的一维投影上应用ReLU并结合排序，实现O(n log n)复杂度的可微、非对称注意力核，并在理论上证明其具备与softmax注意力相当的上下文表达能力。


<details>
  <summary>Details</summary>
Motivation: 为解决传统softmax注意力计算复杂度高（O(n²)）且难以扩展至长序列的问题，同时克服现有ReLU注意力缺乏理论保证的缺陷，作者旨在设计一种兼具高效性与强表达力的新注意力机制。

Method: 提出切片ReLU注意力：不对点积直接施加非线性，而是在键-查询向量差的一维随机投影上应用ReLU，再利用排序操作构建注意力权重；该过程可微、非对称，时间复杂度为O(n log n)。

Result: 该机制被证明具有两个关键理论性质：（1）能完成非平凡的序列到序列解耦任务；（2）满足上下文通用逼近性；小规模实验验证了其实际可行性。

Conclusion: 切片ReLU注意力是一种结构新颖、计算高效且理论严谨的注意力替代方案，为长上下文建模提供了有潜力的新方向。

Abstract: We introduce sliced ReLU attention, a new attention mechanism that departs structurally from both softmax and ReLU-based alternatives. Instead of applying a nonlinearity to pairwise dot products, we operate on one-dimensional projections of key--query differences and leverage sorting to obtain quasi-linear complexity. This construction yields a differentiable, non-symmetric kernel that can be computed in O(n log(n)) through a sorting procedure, making it suitable for very long contexts. Beyond computational benefits, the model retains strong theoretical expressive power: we establish two in-context expressivity results, previously known for softmax attention, showing that sliced ReLU attention preserves the ability to perform nontrivial sequence-to-sequence disentangling tasks and satisfies a contextual universal approximation property. Finally, we illustrate the potential practical interest of this kernel in small-scale experiments.

</details>


### [167] [Hyperbolic Gaussian Blurring Mean Shift: A Statistical Mode-Seeking Framework for Clustering in Curved Spaces](https://arxiv.org/abs/2512.11448)
*Arghya Pratihar,Arnab Seal,Swagatam Das,Inesh Chattopadhyay*

Main category: cs.LG

TL;DR: 本文提出HypeGBMS，将高斯模糊均值漂移（GBMS）扩展到双曲空间，通过双曲距离和Möbius加权均值实现对层次结构数据的密度聚类，理论与实验均验证其在非欧数据上的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统GBMS在处理具有层次或树状结构的数据时表现不佳，而双曲空间天然适合建模层次结构，因此需将GBMS推广至双曲空间以更好捕获潜在层次性。

Method: 提出HypeGBMS方法，将GBMS中的欧氏距离替换为双曲距离，并采用Möbius加权均值保证迭代更新保持在双曲几何内；同时提供收敛性与计算复杂度的理论分析。

Result: 在11个真实世界数据集上的实验表明，HypeGBMS在层次数据上显著优于传统均值漂移方法，展现出更强的鲁棒性与聚类质量。

Conclusion: HypeGBMS成功融合经典均值漂移聚类与双曲表示学习，为非欧空间中的密度聚类提供了原理清晰、几何一致的新范式。

Abstract: Clustering is a fundamental unsupervised learning task for uncovering patterns in data. While Gaussian Blurring Mean Shift (GBMS) has proven effective for identifying arbitrarily shaped clusters in Euclidean space, it struggles with datasets exhibiting hierarchical or tree-like structures. In this work, we introduce HypeGBMS, a novel extension of GBMS to hyperbolic space. Our method replaces Euclidean computations with hyperbolic distances and employs Möbius-weighted means to ensure that all updates remain consistent with the geometry of the space. HypeGBMS effectively captures latent hierarchies while retaining the density-seeking behavior of GBMS. We provide theoretical insights into convergence and computational complexity, along with empirical results that demonstrate improved clustering quality in hierarchical datasets. This work bridges classical mean-shift clustering and hyperbolic representation learning, offering a principled approach to density-based clustering in curved spaces. Extensive experimental evaluations on $11$ real-world datasets demonstrate that HypeGBMS significantly outperforms conventional mean-shift clustering methods in non-Euclidean settings, underscoring its robustness and effectiveness.

</details>


### [168] [NeuralOGCM: Differentiable Ocean Modeling with Learnable Physics](https://arxiv.org/abs/2512.11525)
*Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Guangliang Liu,Yuxuan Liang,Xiaomeng Huang*

Main category: cs.LG

TL;DR: NeuralOGCM 是一种融合可微分编程与深度学习的海洋建模框架，通过可学习的物理核心与神经网络协同校正，实现高精度、高效率与物理一致性的统一。


<details>
  <summary>Details</summary>
Motivation: 高精度科学模拟长期面临计算效率与物理保真度之间的权衡问题。

Method: 提出 NeuralOGCM 框架：包含一个以物理知识为归纳偏置的全可微动力学求解器（将扩散系数等关键参数设为可学习），并耦合一个深度神经网络用于校正亚网格过程和离散误差；二者由统一 ODE 求解器集成并端到端训练。

Result: 实验表明 NeuralOGCM 在保持长期稳定性和物理一致性的同时，在速度上显著优于传统数值模型，在精度上优于纯AI基线。

Conclusion: 为科学计算提供了快速、稳定且物理可信的建模范式新路径。

Abstract: High-precision scientific simulation faces a long-standing trade-off between computational efficiency and physical fidelity. To address this challenge, we propose NeuralOGCM, an ocean modeling framework that fuses differentiable programming with deep learning. At the core of NeuralOGCM is a fully differentiable dynamical solver, which leverages physics knowledge as its core inductive bias. The learnable physics integration captures large-scale, deterministic physical evolution, and transforms key physical parameters (e.g., diffusion coefficients) into learnable parameters, enabling the model to autonomously optimize its physical core via end-to-end training. Concurrently, a deep neural network learns to correct for subgrid-scale processes and discretization errors not captured by the physics model. Both components work in synergy, with their outputs integrated by a unified ODE solver. Experiments demonstrate that NeuralOGCM maintains long-term stability and physical consistency, significantly outperforming traditional numerical models in speed and pure AI baselines in accuracy. Our work paves a new path for building fast, stable, and physically-plausible models for scientific computing.

</details>


### [169] [Contrastive Time Series Forecasting with Anomalies](https://arxiv.org/abs/2512.11526)
*Joel Ekstrand,Zahra Taghiyarrenani,Slawomir Nowaczyk*

Main category: cs.LG

TL;DR: 本文提出Co-TSFA框架，通过对比学习区分对预测有长期影响的异常与短期噪声，提升时间序列预测在异常场景下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准时间序列预测模型无法区分具有持久影响的异常事件和应被忽略的短时噪声，导致过拟合或漏检分布偏移。

Method: 提出Co-TSFA（对比式时间序列异常预测框架），利用输入端与输入-输出联合增强生成两类异常样本，并设计潜在-输出对齐损失，使表征变化与预测变化一致，从而实现对无关扰动的不变性与对关键偏移的敏感性。

Result: 在Traffic、Electricity基准及真实现金需求数据集上验证了Co-TSFA在异常条件下的性能提升，同时保持正常数据上的预测精度。

Conclusion: Co-TSFA能有效提升模型对异常事件的判别能力，在保持常规预测精度的同时增强鲁棒性，为异常感知的时间序列预测提供了新范式。

Abstract: Time series forecasting predicts future values from past data. In real-world settings, some anomalous events have lasting effects and influence the forecast, while others are short-lived and should be ignored. Standard forecasting models fail to make this distinction, often either overreacting to noise or missing persistent shifts. We propose Co-TSFA (Contrastive Time Series Forecasting with Anomalies), a regularization framework that learns when to ignore anomalies and when to respond. Co-TSFA generates input-only and input-output augmentations to model forecast-irrelevant and forecast-relevant anomalies, and introduces a latent-output alignment loss that ties representation changes to forecast changes. This encourages invariance to irrelevant perturbations while preserving sensitivity to meaningful distributional shifts. Experiments on the Traffic and Electricity benchmarks, as well as on a real-world cash-demand dataset, demonstrate that Co-TSFA improves performance under anomalous conditions while maintaining accuracy on normal data. An anonymized GitHub repository with the implementation of Co-TSFA is provided and will be made public upon acceptance.

</details>


### [170] [xGR: Efficient Generative Recommendation Serving at Scale](https://arxiv.org/abs/2512.11529)
*Qingxiao Sun,Tongxuan Liu,Shen Zhang,Siyu Wu,Peijun Yang,Haotian Liang,Menxin Li,Xiaolong Ma,Zhiwei Liang,Ziyi Ren,Minchao Zhang,Xinyu Liu,Ke Zhang,Depei Qian,Hailong Yang*

Main category: cs.LG

TL;DR: 本文提出xGR，一种面向生成式推荐（GR）的低延迟高并发服务系统，通过统一prefill与decode阶段计算、早期排序终止与掩码过滤、以及多级重叠与多流并行优化，显著提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐（GR）虽利用大语言模型增强长序列理解，但其工作负载与传统LLM服务差异大：长输入、短固定输出，且因大beam宽度和庞大物品空间导致解码开销与排序开销极高，难以满足低延迟高并发需求。

Method: xGR提出三项关键技术：1）通过分阶段计算与分离KV缓存统一prefill与decode处理；2）结合数据结构复用实现早期排序终止与掩码式物品过滤；3）重构整体流水线以支持多级计算重叠与多流并行。

Result: 在真实推荐服务数据集上的实验表明，xGR在严格延迟约束下相较当前最优基线至少提升3.49倍吞吐量。

Conclusion: xGR是首个专为生成式推荐服务定制的高效系统，有效解决了GR特有的高解码与排序开销问题，显著提升了高并发下的服务性能。

Abstract: Recommendation system delivers substantial economic benefits by providing personalized predictions. Generative recommendation (GR) integrates LLMs to enhance the understanding of long user-item sequences. Despite employing attention-based architectures, GR's workload differs markedly from that of LLM serving. GR typically processes long prompt while producing short, fixed-length outputs, yet the computational cost of each decode phase is especially high due to the large beam width. In addition, since the beam search involves a vast item space, the sorting overhead becomes particularly time-consuming. We propose xGR, a GR-oriented serving system that meets strict low-latency requirements under highconcurrency scenarios. First, xGR unifies the processing of prefill and decode phases through staged computation and separated KV cache. Second, xGR enables early sorting termination and mask-based item filtering with data structure reuse. Third, xGR reconstructs the overall pipeline to exploit multilevel overlap and multi-stream parallelism. Our experiments with real-world recommendation service datasets demonstrate that xGR achieves at least 3.49x throughput compared to the state-of-the-art baseline under strict latency constraints.

</details>


### [171] [Parametric Numerical Integration with (Differential) Machine Learning](https://arxiv.org/abs/2512.11530)
*Álvaro Leitao,Jonatan Ráfales*

Main category: cs.LG

TL;DR: 本文提出了一种结合导数信息的机器/深度学习方法（微分学习框架）来求解参数化积分，在统计泛函、切比雪夫展开逼近和微分方程相关积分三类问题上均优于传统方法，表现出更低的均方误差、更强的可扩展性和更高的样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在求解参数化积分时存在精度、可扩展性与样本效率不足的问题，而参数化积分在统计、函数逼近和微分方程中广泛存在，亟需更高效鲁棒的数值求解策略。

Method: 提出一种微分学习框架，将导数信息融入模型训练过程；对比经典机器学习方法，应用于三类典型积分问题：统计泛函（如矩、累积分布函数）、切比雪夫级数函数逼近、以及源自微分方程的积分。

Result: 在所有测试案例中，微分机器学习方法均显著优于标准架构：均方误差更低、可扩展性更强、样本效率更高，涵盖从光滑解析解到困难数值积分的广泛情形。

Conclusion: 引入导数先验的微分学习框架是求解参数化积分的一种有效且通用的机器学习范式，为科学计算中的参数依赖积分问题提供了新思路。

Abstract: In this work, we introduce a machine/deep learning methodology to solve parametric integrals. Besides classical machine learning approaches, we consider a differential learning framework that incorporates derivative information during training, emphasizing its advantageous properties. Our study covers three representative problem classes: statistical functionals (including moments and cumulative distribution functions), approximation of functions via Chebyshev expansions, and integrals arising directly from differential equations. These examples range from smooth closed-form benchmarks to challenging numerical integrals. Across all cases, the differential machine learning-based approach consistently outperforms standard architectures, achieving lower mean squared error, enhanced scalability, and improved sample efficiency.

</details>


### [172] [A Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts](https://arxiv.org/abs/2512.11541)
*Emmanuel K. Katalay,David O. Dimandja,Jordan F. Masakuna*

Main category: cs.LG

TL;DR: 本文提出了一种自动化的MLOps流水线，通过多准则统计技术检测数据分布漂移，并仅在必要时触发神经网络分类器的重训练，从而提升模型准确性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在数据分布随时间变化（即数据分布漂移）时性能下降，而当前MLOps流程多依赖人工触发重训练，效率低且不适应动态环境。

Method: 设计自动化MLOps流水线，采用多准则统计技术检测分布偏移，仅在检测到显著漂移时触发神经网络分类器重训练。

Result: 在多个基准异常检测数据集上的实验表明，该方法相比传统重训练策略显著提升了模型准确率和鲁棒性。

Conclusion: 该自动化MLOps框架为在数据分布频繁变化的真实动态场景中部署更可靠、自适应的机器学习系统提供了基础。

Abstract: The performance of machine learning (ML) models often deteriorates when the underlying data distribution changes over time, a phenomenon known as data distribution drift. When this happens, ML models need to be retrained and redeployed. ML Operations (MLOps) is often manual, i.e., humans trigger the process of model retraining and redeployment. In this work, we present an automated MLOps pipeline designed to address neural network classifier retraining in response to significant data distribution changes. Our MLOps pipeline employs multi-criteria statistical techniques to detect distribution shifts and triggers model updates only when necessary, ensuring computational efficiency and resource optimization. We demonstrate the effectiveness of our framework through experiments on several benchmark anomaly detection data sets, showing significant improvements in model accuracy and robustness compared to traditional retraining strategies. Our work provides a foundation for deploying more reliable and adaptive ML systems in dynamic real-world settings, where data distribution changes are common.

</details>


### [173] [Optimizing the Training Diet: Data Mixture Search for Robust Time Series Forecasting](https://arxiv.org/abs/2512.11546)
*Federico Pennino,Maurizio Gabbrielli*

Main category: cs.LG

TL;DR: 本文提出一种数据为中心的训练策略，通过优化训练数据的组成（即'训练饮食'）来提升模型性能，而非调整模型超参数；利用大规模编码器与聚类划分时序数据，并用Optuna搜索最优数据混合比例，在PMSM数据集上将MSE从1.70降至1.37，提升19.41%。


<details>
  <summary>Details</summary>
Motivation: 原始传感器数据常存在类别不平衡和冗余，导致并非所有数据点对模型泛化都有同等贡献，传统‘越多越好’的数据使用范式可能并非最优。

Method: 首先用大规模编码器和k-means对无标签时序数据聚类，得到行为一致的簇；再以各簇为‘食材’，用Optuna在高维混合比例空间中搜索最优采样配比，每次试算构建新训练集并训练小目标模型以评估性能。

Result: 在PMSM数据集上，所提方法将回归任务的MSE从基线1.70显著降低至1.37，提升19.41%；且该数据优化策略持续优于使用全量数据训练的基线模型。

Conclusion: 训练数据的组成质量可超越数量，通过数据-centric优化可显著提升模型性能，验证了‘少而精’的数据选择范式的有效性。

Abstract: The standard paradigm for training deep learning models on sensor data assumes that more data is always better. However, raw sensor streams are often imbalanced and contain significant redundancy, meaning that not all data points contribute equally to model generalization. In this paper, we show that, in some cases, "less is more" when considering datasets. We do this by reframing the data selection problem: rather than tuning model hyperparameters, we fix the model and optimize the composition of the training data itself. We introduce a framework for discovering the optimal "training diet" from a large, unlabeled time series corpus. Our framework first uses a large-scale encoder and k-means clustering to partition the dataset into distinct, behaviorally consistent clusters. These clusters represent the fundamental 'ingredients' available for training. We then employ the Optuna optimization framework to search the high-dimensional space of possible data mixtures. For each trial, Optuna proposes a specific sampling ratio for each cluster, and a new training set is constructed based on this recipe. A smaller target model is then trained and evaluated. Our experiments reveal that this data-centric search consistently discovers data mixtures that yield models with significantly higher performance compared to baselines trained on the entire dataset. Specifically - evaluated on PMSM dataset - our method improved performance from a baseline MSE of 1.70 to 1.37, a 19.41% improvement.

</details>


### [174] [Elastic-Net Multiple Kernel Learning: Combining Multiple Data Sources for Prediction](https://arxiv.org/abs/2512.11547)
*Janaina Mourão-Miranda,Zakria Hussain,Konstantinos Tsirlis,Christophe Phillips,John Shawe-Taylor*

Main category: cs.LG

TL;DR: 本文提出了一种新的弹性网络正则化多核学习（ENMKL）方法，通过解析更新核权重，提升了模型的可解释性和性能，尤其适用于神经影像学等需处理相关核的场景。


<details>
  <summary>Details</summary>
Motivation: 现有ENMKL方法采用两阶段优化，计算复杂且缺乏解析解；而神经影像等领域需要兼顾稀疏性与相关核选择以提升模型可解释性。

Method: 提出一种新型ENMKL公式，导出核权重的解析更新式，并为SVM和核岭回归（KRR）分别设计显式算法，集成至开源工具PRoNTo中。

Result: 在三个神经影像任务中，ENMKL整体优于l1-MKL，仅在一个场景略逊于标准SVM；同时生成更稀疏、更具可解释性的模型。

Conclusion: 所提ENMKL方法兼具高效性、解析性与可解释性，是处理多源/多表征相关数据（如神经影像）的有力工具。

Abstract: Multiple Kernel Learning (MKL) models combine several kernels in supervised and unsupervised settings to integrate multiple data representations or sources, each represented by a different kernel. MKL seeks an optimal linear combination of base kernels that maximizes a generalized performance measure under a regularization constraint. Various norms have been used to regularize the kernel weights, including $l1$, $l2$ and $lp$, as well as the "elastic-net" penalty, which combines $l1$- and $l2$-norm to promote both sparsity and the selection of correlated kernels. This property makes elastic-net regularized MKL (ENMKL) especially valuable when model interpretability is critical and kernels capture correlated information, such as in neuroimaging. Previous ENMKL methods have followed a two-stage procedure: fix kernel weights, train a support vector machine (SVM) with the weighted kernel, and then update the weights via gradient descent, cutting-plane methods, or surrogate functions. Here, we introduce an alternative ENMKL formulation that yields a simple analytical update for the kernel weights. We derive explicit algorithms for both SVM and kernel ridge regression (KRR) under this framework, and implement them in the open-source Pattern Recognition for Neuroimaging Toolbox (PRoNTo). We evaluate these ENMKL algorithms against $l1$-norm MKL and against SVM (or KRR) trained on the unweighted sum of kernels across three neuroimaging applications. Our results show that ENMKL matches or outperforms $l1$-norm MKL in all tasks and only underperforms standard SVM in one scenario. Crucially, ENMKL produces sparser, more interpretable models by selectively weighting correlated kernels.

</details>


### [175] [Fully Inductive Node Representation Learning via Graph View Transformation](https://arxiv.org/abs/2512.11561)
*Dooho Lee,Myeong Kong,Minho Jeong,Jaemin Yoo*

Main category: cs.LG

TL;DR: 本文提出了一种名为Graph View Transformation (GVT)的新方法，通过引入‘view space’这一统一表征空间，实现图数据跨数据集的完全归纳式推理，并在多个基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 图结构数据中特征空间在维度和语义上差异大，导致预训练模型难以泛化到未见数据集，限制了图模型的设计空间。

Method: 提出‘view space’作为统一表征轴，并设计节点与特征排列等变的Graph View Transformation（GVT），构建完全归纳式的Recurrent GVT模型。

Result: Recurrent GVT在27个节点分类基准上优于先前完全归纳式图模型GraphAny达+8.93%，并至少超越12个单独调优的GNN模型+3.30%。

Conclusion: view space为完全归纳式节点表征学习提供了原理清晰且高效的基础。

Abstract: Generalizing a pretrained model to unseen datasets without retraining is an essential step toward a foundation model. However, achieving such cross-dataset, fully inductive inference is difficult in graph-structured data where feature spaces vary widely in both dimensionality and semantics. Any transformation in the feature space can easily violate the inductive applicability to unseen datasets, strictly limiting the design space of a graph model. In this work, we introduce the view space, a novel representational axis in which arbitrary graphs can be naturally encoded in a unified manner. We then propose Graph View Transformation (GVT), a node- and feature-permutation-equivariant mapping in the view space. GVT serves as the building block for Recurrent GVT, a fully inductive model for node representation learning. Pretrained on OGBN-Arxiv and evaluated on 27 node-classification benchmarks, Recurrent GVT outperforms GraphAny, the prior fully inductive graph model, by +8.93% and surpasses 12 individually tuned GNNs by at least +3.30%. These results establish the view space as a principled and effective ground for fully inductive node representation learning.

</details>


### [176] [Brain-Semantoks: Learning Semantic Tokens of Brain Dynamics with a Self-Distilled Foundation Model](https://arxiv.org/abs/2512.11582)
*Sam Gijsen,Marc-Andre Schulz,Kerstin Ritter*

Main category: cs.LG

TL;DR: 本文提出Brain-Semantoks，一种面向fMRI时间序列的自监督基础模型框架，通过语义分词器和自蒸馏目标学习鲁棒、抽象的脑动态表征，显著提升下游任务性能且无需大量微调。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI基础模型多基于小脑区掩码重建，学习低级特征，导致表征易受噪声和时序波动影响，下游任务需大量微调。

Method: 提出Brain-Semantoks框架：1）语义分词器将嘈杂区域信号聚合为功能网络级token；2）设计自蒸馏目标增强表征时间稳定性，并引入新训练课程保障收敛。

Result: 仅用线性探针即可在多种下游任务中取得强性能；缩放分析表明，更多无标签数据可稳定提升分布外泛化能力，无需领域自适应。

Conclusion: Brain-Semantoks通过抽象化和稳定性设计，为fMRI建模提供了更鲁棒、可扩展、即插即用的基础表征范式。

Abstract: The development of foundation models for functional magnetic resonance imaging (fMRI) time series holds significant promise for predicting phenotypes related to disease and cognition. Current models, however, are often trained using a mask-and-reconstruct objective on small brain regions. This focus on low-level information leads to representations that are sensitive to noise and temporal fluctuations, necessitating extensive fine-tuning for downstream tasks. We introduce Brain-Semantoks, a self-supervised framework designed specifically to learn abstract representations of brain dynamics. Its architecture is built on two core innovations: a semantic tokenizer that aggregates noisy regional signals into robust tokens representing functional networks, and a self-distillation objective that enforces representational stability across time. We show that this objective is stabilized through a novel training curriculum, ensuring the model robustly learns meaningful features from low signal-to-noise time series. We demonstrate that learned representations enable strong performance on a variety of downstream tasks even when only using a linear probe. Furthermore, we provide comprehensive scaling analyses indicating more unlabeled data reliably results in out-of-distribution performance gains without domain adaptation.

</details>


### [177] [Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration](https://arxiv.org/abs/2512.11587)
*Alexander Tyurin*

Main category: cs.LG

TL;DR: 本文通过将梯度下降法在带logistic损失的非线性模型上的迭代简化为广义感知机算法，利用经典线性代数工具分析其动力学，证明两层模型因非线性可实现O~(√d)的迭代复杂度，优于线性模型的Ω(d)，从而解释神经网络中的隐式加速现象。


<details>
  <summary>Details</summary>
Motivation: 深入理解梯度下降在神经网络训练中的优化动力学（如收敛速率、轨迹、函数值振荡及隐式加速）仍具挑战性。

Method: 将GD在logistic损失下的非线性模型迭代等价转化为广义感知机算法，并用经典线性代数工具进行理论分析；辅以大量数值实验验证。

Result: 在最小示例中严格证明：两层非线性模型可达到O~(√d)迭代复杂度，优于线性模型的Ω(d)；揭示了非线性带来的隐式加速机制。

Conclusion: 该简化视角不仅阐明了神经网络优化中隐式加速的成因，也为后续神经网络优化研究提供了新思路和理论基础。

Abstract: Even for the gradient descent (GD) method applied to neural network training, understanding its optimization dynamics, including convergence rate, iterate trajectories, function value oscillations, and especially its implicit acceleration, remains a challenging problem. We analyze nonlinear models with the logistic loss and show that the steps of GD reduce to those of generalized perceptron algorithms (Rosenblatt, 1958), providing a new perspective on the dynamics. This reduction yields significantly simpler algorithmic steps, which we analyze using classical linear algebra tools. Using these tools, we demonstrate on a minimalistic example that the nonlinearity in a two-layer model can provably yield a faster iteration complexity $\tilde{O}(\sqrt{d})$ compared to $Ω(d)$ achieved by linear models, where $d$ is the number of features. This helps explain the optimization dynamics and the implicit acceleration phenomenon observed in neural networks. The theoretical results are supported by extensive numerical experiments. We believe that this alternative view will further advance research on the optimization of neural networks.

</details>


### [178] [A Fast Interpretable Fuzzy Tree Learner](https://arxiv.org/abs/2512.11616)
*Javier Fumanal-Idocin,Raquel Fernandez-Peralta,Javier Andreu-Perez*

Main category: cs.LG

TL;DR: 本文提出了一种将经典树状分割算法从精确规则扩展到模糊树的新方法，兼顾计算效率与模糊逻辑的可解释性优势。


<details>
  <summary>Details</summary>
Motivation: 现有模糊规则挖掘算法难以同时保证合理的语言划分和较小的规则库规模，而进化算法计算成本高，神经网络方法（如ANFIS）又难以保持语言可解释性。

Method: 将经典的基于贪心策略的树状分割算法适配到模糊逻辑框架中，构建模糊树模型。

Result: 在表格分类基准上，该方法达到了与最先进模糊分类器相当的准确率，但计算成本显著降低，并生成了复杂度受控、更具可解释性的规则库。

Conclusion: 所提模糊贪心树方法在保持高预测性能的同时，显著提升了计算效率和规则可解释性，为可解释AI提供了一种实用新路径。

Abstract: Fuzzy rule-based systems have been mostly used in interpretable decision-making because of their interpretable linguistic rules. However, interpretability requires both sensible linguistic partitions and small rule-base sizes, which are not guaranteed by many existing fuzzy rule-mining algorithms. Evolutionary approaches can produce high-quality models but suffer from prohibitive computational costs, while neural-based methods like ANFIS have problems retaining linguistic interpretations. In this work, we propose an adaptation of classical tree-based splitting algorithms from crisp rules to fuzzy trees, combining the computational efficiency of greedy algoritms with the interpretability advantages of fuzzy logic. This approach achieves interpretable linguistic partitions and substantially improves running time compared to evolutionary-based approaches while maintaining competitive predictive performance. Our experiments on tabular classification benchmarks proof that our method achieves comparable accuracy to state-of-the-art fuzzy classifiers with significantly lower computational cost and produces more interpretable rule bases with constrained complexity. Code is available in: https://github.com/Fuminides/fuzzy_greedy_tree_public

</details>


### [179] [Bridging Streaming Continual Learning via In-Context Large Tabular Models](https://arxiv.org/abs/2512.11668)
*Afonso Lourenço,João Gama,Eric P. Xing,Goreti Marreiros*

Main category: cs.LG

TL;DR: 本文提出Streaming Continual Learning（SCL）新范式，主张利用大上下文表格模型（LTMs）桥接持续学习（CL）与流学习（SL），通过在线生成紧凑数据草图实现兼顾实时性、抗遗忘与内存可控。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习（CL）与流学习（SL）研究各自孤立：CL关注长期知识保留但忽略实时性，SL强调快速适应却忽视遗忘；二者缺乏算法层面融合，亟需统一框架。

Method: 提出以大在上下文表格模型（LTMs）为核心构建SCL框架，引入两个核心数据选择原则：（1）分布匹配——平衡可塑性与稳定性；（2）分布压缩——通过多样化存储与按需检索控制内存规模。

Result: 建立了CL与SL的统一视角，指出二者隐含‘分而治之’策略以协调可塑性-稳定性张力，并论证LTMs天然适配该目标，为SCL提供理论桥梁与设计原则。

Conclusion: LTMs结合在线数据草图化是实现Streaming Continual Learning的有效路径；分布匹配与分布压缩是指导SCL中数据选择的关键原则，有望推动CL与SL的实质性融合。

Abstract: In streaming scenarios, models must learn continuously, adapting to concept drifts without erasing previously acquired knowledge. However, existing research communities address these challenges in isolation. Continual Learning (CL) focuses on long-term retention and mitigating catastrophic forgetting, often without strict real-time constraints. Stream Learning (SL) emphasizes rapid, efficient adaptation to high-frequency data streams, but typically neglects forgetting. Recent efforts have tried to combine these paradigms, yet no clear algorithmic overlap exists. We argue that large in-context tabular models (LTMs) provide a natural bridge for Streaming Continual Learning (SCL). In our view, unbounded streams should be summarized on-the-fly into compact sketches that can be consumed by LTMs. This recovers the classical SL motivation of compressing massive streams with fixed-size guarantees, while simultaneously aligning with the experience-replay desiderata of CL. To clarify this bridge, we show how the SL and CL communities implicitly adopt a divide-to-conquer strategy to manage the tension between plasticity (performing well on the current distribution) and stability (retaining past knowledge), while also imposing a minimal complexity constraint that motivates diversification (avoiding redundancy in what is stored) and retrieval (re-prioritizing past information when needed). Within this perspective, we propose structuring SCL with LTMs around two core principles of data selection for in-context learning: (1) distribution matching, which balances plasticity and stability, and (2) distribution compression, which controls memory size through diversification and retrieval mechanisms.

</details>


### [180] [High-Dimensional Surrogate Modeling for Closed-Loop Learning of Neural-Network-Parameterized Model Predictive Control](https://arxiv.org/abs/2512.11705)
*Sebastian Hirt,Valentinus Suwanto,Hendrik Alsmeier,Maik Pfefferkorn,Rolf Findeisen*

Main category: cs.LG

TL;DR: 本文探讨了在高维控制器参数调优中，使用贝叶斯神经网络（BNN）作为贝叶斯优化的代理模型，相比传统高斯过程（GP）更具优势，尤其在密集高维场景（如模型预测控制）下表现出更快、更可靠的收敛性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 标准贝叶斯优化方法（如基于Matern核高斯过程的代理模型）在密集高维控制器参数空间中表现不佳，难以捕捉结构，限制了其在现代控制器（如MPC）自动调参中的应用。

Method: 将高斯过程（Matern核）、有限宽度贝叶斯神经网络（BNN）和无限宽度BNN作为代理模型，在倒立摆（cart-pole）任务中对比其在闭环性能优化中的表现，重点评估收敛速度、稳定性及对数百至千维参数的适应能力。

Result: BNN代理模型显著提升闭环代价收敛速度与可靠性；有限宽度BNN可成功优化数百维参数；无限宽度BNN在超千维参数下仍保持有效，而Matern-GP迅速失效。

Conclusion: 贝叶斯神经网络（尤其是无限宽度BNN）是学习密集高维控制器参数的有效代理模型，为基于学习的控制器设计提供了实用的代理模型选型指导。

Abstract: Learning controller parameters from closed-loop data has been shown to improve closed-loop performance. Bayesian optimization, a widely used black-box and sample-efficient learning method, constructs a probabilistic surrogate of the closed-loop performance from few experiments and uses it to select informative controller parameters. However, it typically struggles with dense high-dimensional controller parameterizations, as they may appear, for example, in tuning model predictive controllers, because standard surrogate models fail to capture the structure of such spaces. This work suggests that the use of Bayesian neural networks as surrogate models may help to mitigate this limitation. Through a comparison between Gaussian processes with Matern kernels, finite-width Bayesian neural networks, and infinite-width Bayesian neural networks on a cart-pole task, we find that Bayesian neural network surrogate models achieve faster and more reliable convergence of the closed-loop cost and enable successful optimization of parameterizations with hundreds of dimensions. Infinite-width Bayesian neural networks also maintain performance in settings with more than one thousand parameters, whereas Matern-kernel Gaussian processes rapidly lose effectiveness. These results indicate that Bayesian neural network surrogate models may be suitable for learning dense high-dimensional controller parameterizations and offer practical guidance for selecting surrogate models in learning-based controller design.

</details>


### [181] [SpectralKrum: A Spectral-Geometric Defense Against Byzantine Attacks in Federated Learning](https://arxiv.org/abs/2512.11760)
*Aditya Tripathi,Karan Sharma,Rahul Mishra,Tapas Kumar Maiti*

Main category: cs.LG

TL;DR: 本文提出SpectralKrum，一种融合谱子空间估计与几何邻域选择的新型拜占庭鲁棒联邦学习防御方法，在非独立同分布（non-IID）场景下提升对恶意更新的检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒聚合方法（如Krum、Bulyan）在理想假设下有效，但在数据异构（non-IID）且攻击者可感知防御机制时性能显著下降，亟需更鲁棒、隐私保持的防御方案。

Method: SpectralKrum首先从历史模型更新中估计良性优化轨迹所在的低维谱子空间；然后将新更新投影至该子空间，在压缩坐标中执行Krum选择，并通过数据驱动的正交残差能量阈值过滤异常更新。全程仅依赖模型更新，无需辅助数据，保持FL隐私性。

Result: 在CIFAR-10、Dirichlet非IID（α=0.1）设置下，对比8种基线方法与7类攻击，SpectralKrum在方向性与子空间感知型攻击（如adaptive-steer、buffer-drift）中表现优异；但在label-flip和min-max攻击下优势有限，因其恶意更新在谱域难以区分。

Conclusion: SpectralKrum通过引入谱子空间建模提升了non-IID场景下的拜占庭鲁棒性，是一种轻量、隐私友好的聚合增强策略，但其有效性依赖于恶意更新在谱结构上的可分辨性。

Abstract: Federated Learning (FL) distributes model training across clients who retain their data locally, but this architecture exposes a fundamental vulnerability: Byzantine clients can inject arbitrarily corrupted updates that degrade or subvert the global model. While robust aggregation methods (including Krum, Bulyan, and coordinate-wise defenses) offer theoretical guarantees under idealized assumptions, their effectiveness erodes substantially when client data distributions are heterogeneous (non-IID) and adversaries can observe or approximate the defense mechanism.
  This paper introduces SpectralKrum, a defense that fuses spectral subspace estimation with geometric neighbor-based selection. The core insight is that benign optimization trajectories, despite per-client heterogeneity, concentrate near a low-dimensional manifold that can be estimated from historical aggregates. SpectralKrum projects incoming updates into this learned subspace, applies Krum selection in compressed coordinates, and filters candidates whose orthogonal residual energy exceeds a data-driven threshold. The method requires no auxiliary data, operates entirely on model updates, and preserves FL privacy properties.
  We evaluate SpectralKrum against eight robust baselines across seven attack scenarios on CIFAR-10 with Dirichlet-distributed non-IID partitions (alpha = 0.1). Experiments spanning over 56,000 training rounds show that SpectralKrum is competitive against directional and subspace-aware attacks (adaptive-steer, buffer-drift), but offers limited advantage under label-flip and min-max attacks where malicious updates remain spectrally indistinguishable from benign ones.

</details>


### [182] [The Adaptive Vekua Cascade: A Differentiable Spectral-Analytic Solver for Physics-Informed Representation](https://arxiv.org/abs/2512.11776)
*Vladimer Khasia*

Main category: cs.LG

TL;DR: 本文提出了一种名为自适应Vekua级联（AVC）的混合架构，结合深度学习与经典逼近理论，通过域变形和解析函数基展开解决坐标神经网络的频谱偏差与维数灾难问题，在多个物理基准任务中实现了高精度、低参数量和快速收敛。


<details>
  <summary>Details</summary>
Motivation: 坐标神经网络存在频谱偏差（难以学习高频动态）和维数灾难（离散特征网格导致参数爆炸）两大根本性问题。

Method: AVC采用深度网络学习物理域的微分同胚映射（即域变形），将复杂时空动力学投影到隐流形上，并用广义解析函数基表示解；输出层用可微线性求解器替代标准梯度下降，前向传播中闭式求解谱系数。

Result: 在五个严格物理基准（如高频Helmholtz波传播、稀疏医学重建、非定常3D Navier-Stokes湍流）上达到SOTA精度；参数量大幅减少（如3D任务仅840参数 vs. 420万），收敛速度提升2–3倍。

Conclusion: AVC建立了内存高效、谱精度高的科学机器学习新范式。

Abstract: Coordinate-based neural networks have emerged as a powerful tool for representing continuous physical fields, yet they face two fundamental pathologies: spectral bias, which hinders the learning of high-frequency dynamics, and the curse of dimensionality, which causes parameter explosion in discrete feature grids. We propose the Adaptive Vekua Cascade (AVC), a hybrid architecture that bridges deep learning and classical approximation theory. AVC decouples manifold learning from function approximation by using a deep network to learn a diffeomorphic warping of the physical domain, projecting complex spatiotemporal dynamics onto a latent manifold where the solution is represented by a basis of generalized analytic functions. Crucially, we replace the standard gradient-descent output layer with a differentiable linear solver, allowing the network to optimally resolve spectral coefficients in a closed form during the forward pass. We evaluate AVC on a suite of five rigorous physics benchmarks, including high-frequency Helmholtz wave propagation, sparse medical reconstruction, and unsteady 3D Navier-Stokes turbulence. Our results demonstrate that AVC achieves state-of-the-art accuracy while reducing parameter counts by orders of magnitude (e.g., 840 parameters vs. 4.2 million for 3D grids) and converging 2-3x faster than implicit neural representations. This work establishes a new paradigm for memory-efficient, spectrally accurate scientific machine learning. The code is available at https://github.com/VladimerKhasia/vecua.

</details>


### [183] [Softmax as Linear Attention in the Large-Prompt Regime: a Measure-based Perspective](https://arxiv.org/abs/2512.11784)
*Etienne Boursier,Claire Boyer*

Main category: cs.LG

TL;DR: 本文提出了一种基于测度的统一框架，分析单层Softmax注意力机制在有限与无限提示长度下的行为；证明了在高斯输入下，Softmax注意力在无限提示极限下收敛于线性算子，并给出了非渐近集中界，表明长提示下Softmax注意力可被线性注意力理论有效刻画。


<details>
  <summary>Details</summary>
Motivation: Softmax注意力的非线性结构使其理论分析困难，亟需一个能统一处理有限与无限提示长度、并连接线性与非线性注意力分析的理论框架。

Method: 构建基于输入token测度的分析框架，利用Softmax在无限提示下向线性算子收敛的性质，推导非渐近集中不等式，并将结果拓展至训练全过程及上下文学习中的线性回归特例。

Result: 获得了Softmax注意力输出与梯度的非渐近集中界；证明其在整条训练轨迹上对子高斯token保持稳定；在上下文线性回归中，用无限提示动力学反推有限提示训练行为；确立了长提示下Softmax注意力可由线性注意力理论可靠近似。

Conclusion: 该框架为大提示场景下Softmax注意力的训练动力学与统计行为提供了普适、严谨且可迁移的理论工具，弥合了线性与非线性注意力理论之间的鸿沟。

Abstract: Softmax attention is a central component of transformer architectures, yet its nonlinear structure poses significant challenges for theoretical analysis. We develop a unified, measure-based framework for studying single-layer softmax attention under both finite and infinite prompts. For i.i.d. Gaussian inputs, we lean on the fact that the softmax operator converges in the infinite-prompt limit to a linear operator acting on the underlying input-token measure. Building on this insight, we establish non-asymptotic concentration bounds for the output and gradient of softmax attention, quantifying how rapidly the finite-prompt model approaches its infinite-prompt counterpart, and prove that this concentration remains stable along the entire training trajectory in general in-context learning settings with sub-Gaussian tokens. In the case of in-context linear regression, we use the tractable infinite-prompt dynamics to analyze training at finite prompt length. Our results allow optimization analyses developed for linear attention to transfer directly to softmax attention when prompts are sufficiently long, showing that large-prompt softmax attention inherits the analytical structure of its linear counterpart. This, in turn, provides a principled and broadly applicable toolkit for studying the training dynamics and statistical behavior of softmax attention layers in large prompt regimes.

</details>


### [184] [A General Algorithm for Detecting Higher-Order Interactions via Random Sequential Additions](https://arxiv.org/abs/2512.11793)
*Ahmad Shamail,Claire McWhite*

Main category: cs.LG

TL;DR: 本文提出了一种基于几何特征（L形模式）的简单方法，用于量化系统中元素间的交互、独立与冗余关系，并定义了L-score指标（范围-1到+1）来统一刻画这些关系。


<details>
  <summary>Details</summary>
Motivation: 许多系统中组件间存在复杂的交互关系（如增强、冗余或独立），缺乏一种统一、直观且可量化的分析方法。

Method: 通过随机顺序添加元素并多次测量其贡献，绘制贡献曲线；观察L形模式特征，定义L-score；利用两两贡献的二维点云分析交互类型；从成对测量中推断高阶交互。

Result: L-score能连续量化协同（-1）、独立（0）和冗余（+1）；L形臂长比例揭示特征主导性；高阶交互可通过一致的成对关系自然浮现；方法不依赖具体度量，具有广泛适用性。

Conclusion: 该几何方法为理解复杂系统的交互结构提供了一个统一、直观、可扩展且度量无关的分析框架。

Abstract: Many systems exhibit complex interactions between their components: some features or actions amplify each other's effects, others provide redundant information, and some contribute independently. We present a simple geometric method for discovering interactions and redundancies: when elements are added in random sequential orders and their contributions plotted over many trials, characteristic L-shaped patterns emerge that directly reflect interaction structure. The approach quantifies how the contribution of each element depends on those added before it, revealing patterns that distinguish interaction, independence, and redundancy on a unified scale. When pairwise contributions are visualized as two--dimensional point clouds, redundant pairs form L--shaped patterns where only the first-added element contributes, while synergistic pairs form L--shaped patterns where only elements contribute together. Independent elements show order--invariant distributions. We formalize this with the L--score, a continuous measure ranging from $-1$ (perfect synergy, e.g. $Y=X_1X_2$) to $0$ (independence) to $+1$ (perfect redundancy, $X_1 \approx X_2$). The relative scaling of the L--shaped arms reveals feature dominance in which element consistently provides more information. Although computed only from pairwise measurements, higher--order interactions among three or more elements emerge naturally through consistent cross--pair relationships (e.g. AB, AC, BC). The method is metric--agnostic and broadly applicable to any domain where performance can be evaluated incrementally over non-repeating element sequences, providing a unified geometric approach to uncovering interaction structure.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [185] [Emotion-Driven Personalized Recommendation for AI-Generated Content Using Multi-Modal Sentiment and Intent Analysis](https://arxiv.org/abs/2512.10963)
*Zheqi Hu,Xuanjing Chen,Jinlin Hu*

Main category: cs.IR

TL;DR: 本文提出了一种多模态情感与意图识别模型（MMEI），结合视觉、听觉和文本模态，利用BERT-based跨模态Transformer与注意力融合机制，提升AIGC推荐系统的情感感知能力，在多个基准数据集上显著提升性能，并验证了其对用户参与度和满意度的积极影响。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统忽视用户在内容交互过程中的实时情感与意图状态，难以满足AIGC时代对情感感知推荐的需求。

Method: 构建基于BERT的跨模态Transformer模型MMEI，采用ViT、Wav2Vec2和BERT分别编码视觉、听觉与文本模态，通过注意力机制融合生成情感-意图表征，并接入上下文匹配层实现个性化推荐。

Result: 在AIGC-INT、MELD和CMU-MOSEI等数据集上，F1-score提升4.3%，交叉熵损失降低12.3%；线上用户评估显示互动时长提升15.2%，满意度提升11.8%。

Conclusion: 多模态情感智能可有效增强AIGC推荐系统的适应性、共情性与情境感知能力，为下一代AIGC生态提供新范式。

Abstract: With the rapid growth of AI-generated content (AIGC) across domains such as music, video, and literature, the demand for emotionally aware recommendation systems has become increasingly important. Traditional recommender systems primarily rely on user behavioral data such as clicks, views, or ratings, while neglecting users' real-time emotional and intentional states during content interaction. To address this limitation, this study proposes a Multi-Modal Emotion and Intent Recognition Model (MMEI) based on a BERT-based Cross-Modal Transformer with Attention-Based Fusion, integrated into a cloud-native personalized AIGC recommendation framework. The proposed system jointly processes visual (facial expression), auditory (speech tone), and textual (comments or utterances) modalities through pretrained encoders ViT, Wav2Vec2, and BERT, followed by an attention-based fusion module to learn emotion-intent representations. These embeddings are then used to drive personalized content recommendations through a contextual matching layer. Experiments conducted on benchmark emotion datasets (AIGC-INT, MELD, and CMU-MOSEI) and an AIGC interaction dataset demonstrate that the proposed MMEI model achieves a 4.3% improvement in F1-score and a 12.3% reduction in cross-entropy loss compared to the best fusion-based transformer baseline. Furthermore, user-level online evaluations reveal that emotion-driven recommendations increase engagement time by 15.2% and enhance satisfaction scores by 11.8%, confirming the model's effectiveness in aligning AI-generated content with users' affective and intentional states. This work highlights the potential of cross-modal emotional intelligence for next-generation AIGC ecosystems, enabling adaptive, empathetic, and context-aware recommendation experiences.

</details>


### [186] [FAIR: Focused Attention Is All You Need for Generative Recommendation](https://arxiv.org/abs/2512.11254)
*Longtao Xiao,Haolin Zhang,Guohao Cai,Jieming Zhu,Yifan Wang,Heng Chang,Zhenhua Dong,Xiu Li,Ruixuan Li*

Main category: cs.IR

TL;DR: 本文提出FAIR框架，通过聚焦注意力机制、噪声鲁棒性目标和互信息最大化目标，提升基于Transformer的生成式推荐模型在用户行为建模中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的生成式推荐模型需将物品离散化为多码表示，导致序列长度剧增，加剧了对噪声上下文的过度关注问题。

Method: 提出FAIR框架，包括：(1) 聚焦注意力机制，通过学习两组Q/K权重并计算其差值来抑制无关注意力；(2) 噪声鲁棒性目标，使注意力模式在随机扰动下保持稳定；(3) 互信息最大化目标，引导模型识别对下一项预测最相关的信息。

Result: 在四个公开基准数据集上验证了FAIR的有效性，性能优于现有方法。

Conclusion: FAIR有效缓解了Transformer推荐中因序列扩展带来的注意力噪声问题，提升了推荐准确性和鲁棒性。

Abstract: Recently, transformer-based generative recommendation has garnered significant attention for user behavior modeling. However, it often requires discretizing items into multi-code representations (e.g., typically four code tokens or more), which sharply increases the length of the original item sequence. This expansion poses challenges to transformer-based models for modeling user behavior sequences with inherent noises, since they tend to overallocate attention to irrelevant or noisy context. To mitigate this issue, we propose FAIR, the first generative recommendation framework with focused attention, which enhances attention scores to relevant context while suppressing those to irrelevant ones. Specifically, we propose (1) a focused attention mechanism integrated into the standard Transformer, which learns two separate sets of Q and K attention weights and computes their difference as the final attention scores to eliminate attention noise while focusing on relevant contexts; (2) a noise-robustness objective, which encourages the model to maintain stable attention patterns under stochastic perturbations, preventing undesirable shifts toward irrelevant context due to noise; and (3) a mutual information maximization objective, which guides the model to identify contexts that are most informative for next-item prediction. We validate the effectiveness of FAIR on four public benchmarks, demonstrating its superior performance compared to existing methods.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [187] [CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound](https://arxiv.org/abs/2512.11169)
*Akhil S Anand,Elias Aarekol,Martin Mziray Dalseg,Magnus Stalhane,Sebastien Gros*

Main category: cs.AI

TL;DR: 本文提出了一种名为CORL的端到端强化学习框架，用于在真实数据上微调混合整数线性规划（MILP）求解流程，以提升其在组合序贯决策问题中的实际运行性能。


<details>
  <summary>Details</summary>
Motivation: 传统MILP建模难以准确刻画随机现实问题，导致实际性能不佳；现有机器学习方法多依赖监督学习、需最优标签且使用梯度代理，存在局限性。

Method: 将基于分支定界（B&B）求解的MILP建模为可微的随机策略，从而支持端到端强化学习优化；构建CORL框架，在真实数据上直接优化MILP的操作性能。

Result: 在简单的组合序贯决策示例中验证了CORL方法的有效性，证明其能提升MILP的实际决策性能。

Conclusion: CORL为MILP求解器提供了无需真实最优标签、不依赖建模精度、直接面向运行性能优化的新范式，是强化学习与运筹优化结合的初步探索。

Abstract: Combinatorial sequential decision making problems are typically modeled as mixed integer linear programs (MILPs) and solved via branch and bound (B&B) algorithms. The inherent difficulty of modeling MILPs that accurately represent stochastic real world problems leads to suboptimal performance in the real world. Recently, machine learning methods have been applied to build MILP models for decision quality rather than how accurately they model the real world problem. However, these approaches typically rely on supervised learning, assume access to true optimal decisions, and use surrogates for the MILP gradients. In this work, we introduce a proof of concept CORL framework that end to end fine tunes an MILP scheme using reinforcement learning (RL) on real world data to maximize its operational performance. We enable this by casting an MILP solved by B&B as a differentiable stochastic policy compatible with RL. We validate the CORL method in a simple illustrative combinatorial sequential decision making example.

</details>


### [188] [Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling](https://arxiv.org/abs/2512.11187)
*Haohui Zhang,Wouter van Heeswijk,Xinyu Hu,Neil Yorke-Smith,Martijn Mes*

Main category: cs.AI

TL;DR: 本文提出了一种学习加速的混合搜索方法，用于在线货运交易平台中的组合式货运打包问题（建模为m1-PDSTSP），结合Transformer构造策略与多起点大邻域搜索（MSLNS），在亚秒级延迟下实现高收益、高质量解，最优性缺口<2%，并首次验证了深度学习构造器可稳定提供高质量初始解用于改进型启发式算法。


<details>
  <summary>Details</summary>
Motivation: 在线货运交换系统（OFEX）中，运输任务的高效组合打包仍是瓶颈，尤其需在容量、前后序和路径长度约束下实现收益驱动的实时匹配。

Method: 将问题建模为多商品一对一取送货选择性旅行商问题（m1-PDSTSP），提出基于Transformer神经网络的构造性策略与多起点大邻域搜索（MSLNS）相结合的滚动时域混合搜索框架。

Result: 在多个基准测试中，该方法在解质量上优于现有神经组合优化与元启发式基线，总收益最优性缺口小于2%，且运行时间相当；同时首次证实深度学习构造器能可靠提供高质量初始解用于多起点改进搜索。

Conclusion: 深度学习构造器与改进型元启发式的协同设计可在严苛实时约束下显著提升组合优化性能，其范式可推广至广泛的选择性TSP及取送货问题。

Abstract: Online Freight Exchange Systems (OFEX) play a crucial role in modern freight logistics by facilitating real-time matching between shippers and carrier. However, efficient combinatorial bundling of transporation jobs remains a bottleneck. We model the OFEX combinatorial bundling problem as a multi-commodity one-to-one pickup-and-delivery selective traveling salesperson problem (m1-PDSTSP), which optimizes revenue-driven freight bundling under capacity, precedence, and route-length constraints. The key challenge is to couple combinatorial bundle selection with pickup-and-delivery routing under sub-second latency. We propose a learning--accelerated hybrid search pipeline that pairs a Transformer Neural Network-based constructive policy with an innovative Multi-Start Large Neighborhood Search (MSLNS) metaheuristic within a rolling-horizon scheme in which the platform repeatedly freezes the current marketplace into a static snapshot and solves it under a short time budget. This pairing leverages the low-latency, high-quality inference of the learning-based constructor alongside the robustness of improvement search; the multi-start design and plausible seeds help LNS to explore the solution space more efficiently. Across benchmarks, our method outperforms state-of-the-art neural combinatorial optimization and metaheuristic baselines in solution quality with comparable time, achieving an optimality gap of less than 2\% in total revenue relative to the best available exact baseline method. To our knowledge, this is the first work to establish that a Deep Neural Network-based constructor can reliably provide high-quality seeds for (multi-start) improvement heuristics, with applicability beyond the \textit{m1-PDSTSP} to a broad class of selective traveling salesperson problems and pickup and delivery problems.

</details>


### [189] [General-purpose AI models can generate actionable knowledge on agroecological crop protection](https://arxiv.org/abs/2512.11474)
*Kris A. G. Wyckhuys*

Main category: cs.AI

TL;DR: 本研究评估了DeepSeek和ChatGPT在农业生态病虫害防控知识生成中的表现，发现DeepSeek在文献覆盖、解决方案数量和数据一致性方面显著优于ChatGPT，但两者均存在幻觉和术语混淆等问题；在人工严格监督下，LLM有望辅助农场决策与科研创新。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI在农食科学领域（尤其是农业生态病虫害防控）的应用潜力，填补该方向研究空白，并评估不同大语言模型（LLM）生成科学知识的可靠性。

Method: 对比评估DeepSeek（网络增强型）与免费版ChatGPT（非网络增强型）对全球九种主要病虫草害的防控知识生成能力，从事实准确性、数据一致性、知识广度三方面进行量化分析。

Result: DeepSeek检索文献量为ChatGPT的4.8–49.7倍，报告的生物防治剂/方案多1.6–2.4倍，疗效估计高21.6%，实验室-田间数据一致性更强，且更真实反映害虫种类与防控措施的影响；但两模型均存在幻觉、术语混淆和关键信息遗漏问题。

Conclusion: 尽管存在幻觉等缺陷，LLM在人工严格监督下可成为支持农场决策和激发科研创造力的有力工具。

Abstract: Generative artificial intelligence (AI) offers potential for democratizing scientific knowledge and converting this to clear, actionable information, yet its application in agri-food science remains unexplored. Here, we verify the scientific knowledge on agroecological crop protection that is generated by either web-grounded or non-grounded large language models (LLMs), i.e., DeepSeek versus the free-tier version of ChatGPT. For nine globally limiting pests, weeds, and plant diseases, we assessed the factual accuracy, data consistency, and breadth of knowledge or data completeness of each LLM. Overall, DeepSeek consistently screened a 4.8-49.7-fold larger literature corpus and reported 1.6-2.4-fold more biological control agents or management solutions than ChatGPT. As a result, DeepSeek reported 21.6% higher efficacy estimates, exhibited greater laboratory-to-field data consistency, and showed more realistic effects of pest identity and management tactics. However, both models hallucinated, i.e., fabricated fictitious agents or references, reported on implausible ecological interactions or outcomes, confused old and new scientific nomenclatures, and omitted data on key agents or solutions. Despite these shortcomings, both LLMs correctly reported low-resolution efficacy trends. Overall, when paired with rigorous human oversight, LLMs may pose a powerful tool to support farm-level decision-making and unleash scientific creativity.

</details>


### [190] [FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration](https://arxiv.org/abs/2512.11213)
*Dongwon Jung,Peng Shi,Yi Zhang*

Main category: cs.AI

TL;DR: 本文提出FutureWeaver框架，用于在固定计算预算下优化多智能体系统中的测试时计算分配，通过模块化协作与双层规划提升协同推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时计算扩展方法难以适配多智能体系统，缺乏在预算约束下协同分配计算资源的原理性机制。

Method: 提出FutureWeaver框架：1）通过自博弈反思自动提取可复用的模块化协作函数；2）设计双层规划架构，在当前任务状态和未来步骤推测中联合优化计算分配。

Result: 在多个复杂多智能体基准上，FutureWeaver在不同预算设置下均显著优于基线方法。

Conclusion: FutureWeaver为多智能体系统提供了可扩展、可规划、预算感知的测试时计算优化新范式。

Abstract: Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.

</details>


### [191] [A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation](https://arxiv.org/abs/2512.11270)
*Hong Je-Gal,Chan-Bin Yi,Hyun-Suk Lee*

Main category: cs.AI

TL;DR: 本文提出A-LAMP框架，利用LLM自动将自然语言任务描述转化为MDP并生成训练策略，通过分阶段可验证流程提升语义对齐与策略生成能力，在多类RL任务中表现优于单一大模型。


<details>
  <summary>Details</summary>
Motivation: 将非形式化的自然语言任务描述转化为形式化MDP、构建可执行环境并训练策略的过程存在建模错误、代码脆弱性和目标错位等挑战，亟需自动化解决方案。

Method: 提出基于智能体的LLM框架A-LAMP，将MDP建模、编码实现和策略训练分解为可验证的多个阶段，确保全流程语义对齐；支持轻量级变体以适配小模型。

Result: 在经典控制与自定义RL任务中，A-LAMP策略生成能力持续优于单一大模型；其轻量变体性能接近更大模型；失败分析揭示改进原因；案例研究证实其生成的环境与策略保持任务最优性。

Conclusion: A-LAMP为RL应用自动化提供了可靠、可扩展的新范式，兼具高性能与轻量化潜力，验证了分阶段智能体架构在MDP自动构建中的有效性与鲁棒性。

Abstract: Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.

</details>


### [192] [TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning](https://arxiv.org/abs/2512.11271)
*Yuxing Chen,Basem Suleiman,Qifan Chen*

Main category: cs.AI

TL;DR: 本文提出了TriFlow，一个三阶段的多智能体框架，用于解决现实世界中的行程规划问题，通过检索、规划和治理三个阶段，结合结构化推理与语言模型的灵活性，显著提升了约束满足能力、工具协调效率和个性化水平。


<details>
  <summary>Details</summary>
Motivation: 现实世界的行程规划需要在严格的时空和预算约束下，将开放式的用户请求转化为可执行的行程，而现有的大语言模型代理在约束满足、工具协调和效率方面表现不佳，常产生不可行或高成本的计划。

Method: 提出TriFlow框架，采用三阶段流水线：检索（缩小搜索空间）、规划（通过规则与大语言模型协作生成符合约束的行程）、治理（进行有界迭代优化以确保全局可行性和个性化）。

Result: 在TravelPlanner和TripTailor基准测试中分别达到91.1%和97%的最终通过率，并比当前最优方法提升10倍以上的运行效率。

Conclusion: TriFlow通过结构化推理与语言模型协同，在行程规划任务中实现了更高的可行性、效率与个性化，为基于LLM的复杂规划任务提供了新范式。

Abstract: Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.

</details>


### [193] [CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving](https://arxiv.org/abs/2512.11323)
*Jianyi Zhang,Ziyin Zhou,Xu Ji,Shizhao Liu,Zhangchi Zhao*

Main category: cs.AI

TL;DR: 本文提出了首个专为大型视觉语言模型（LVLMs）设计的CAPTCHA基准测试——CAPTURE，涵盖4大类、25子类、来自31家厂商的真实验证码，旨在全面评估LVLM在真实场景下的识别能力；实验表明当前LVLM对此类任务表现较差。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉CAPTCHA的基准存在覆盖不全、缺乏LVLM专用设计等问题，亟需一个全面、真实、适配LVLM的新型CAPTCHA基准。

Method: 构建了一个名为CAPTURE的新基准，包含4种主要CAPTCHA类型、25种子类型、源自31家厂商的多样化数据，并引入LVLM定制化标签。

Result: 使用CAPTURE评估当前主流LVLM时，发现其CAPTCHA识别性能普遍较差。

Conclusion: CAPTURE填补了LVLM专用CAPTCHA基准的空白，揭示了LVLM在真实复杂视觉识别任务上的显著短板，为后续模型改进和评测提供了重要基础。

Abstract: Benefiting from strong and efficient multi-modal alignment strategies, Large Visual Language Models (LVLMs) are able to simulate human visual and reasoning capabilities, such as solving CAPTCHAs. However, existing benchmarks based on visual CAPTCHAs still face limitations. Previous studies, when designing benchmarks and datasets, customized them according to their research objectives. Consequently, these benchmarks cannot comprehensively cover all CAPTCHA types. Notably, there is a dearth of dedicated benchmarks for LVLMs. To address this problem, we introduce a novel CAPTCHA benchmark for the first time, named CAPTURE CAPTCHA for Testing Under Real-world Experiments, specifically for LVLMs. Our benchmark encompasses 4 main CAPTCHA types and 25 sub-types from 31 vendors. The diversity enables a multi-dimensional and thorough evaluation of LVLM performance. CAPTURE features extensive class variety, large-scale data, and unique LVLM-tailored labels, filling the gaps in previous research in terms of data comprehensiveness and labeling pertinence. When evaluated by this benchmark, current LVLMs demonstrate poor performance in solving CAPTCHAs.

</details>


### [194] [Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance](https://arxiv.org/abs/2512.11421)
*Gonca Gürsun*

Main category: cs.AI

TL;DR: 本文提出了一种面向多轮任务的LLM代理框架，通过显式行为引导、可验证推理与约束合规生成，提升其可靠性与可验证性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮任务中行为缺乏可靠性和可验证性，亟需一种能结合强化学习形式化环境与可控行为机制的框架。

Method: 构建包含轻量级任务分析器、可验证观测-动作映射推理模块、以及基于验证或确定性合成的约束合规生成模块的三组件框架，并实现三者协同演化。

Result: 实验表明，该框架使LLM代理在交互过程中各组件协同进化，显著提升行为的可信度与可验证性。

Conclusion: 该框架为增强LLM在复杂交互环境中的可控性与可信性提供了可行路径，弥合了大模型能力与实际部署需求之间的鸿沟。

Abstract: Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.
  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.

</details>


### [195] [AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints](https://arxiv.org/abs/2512.11426)
*Shuowei Cai,Yansong Ning,Hao Liu*

Main category: cs.AI

TL;DR: 本文提出AgentBalance框架，通过'骨干网络优先-拓扑结构后验'的设计范式，在显式的token成本和延迟预算约束下构建高性价比的LLM多智能体系统（MAS），显著提升性能并支持即插即用与跨模型泛化。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多智能体系统在提升成本效益时，常忽略对实际部署中明确的token成本和延迟预算建模与优化，导致拓扑优先设计在预算紧张时效果不佳。

Method: AgentBalance采用两阶段设计：第一阶段为骨干网络导向的智能体生成，包括LLM池构建、池选择和角色-骨干匹配；第二阶段为自适应MAS拓扑生成，涵盖智能体表征学习、门控机制和延迟感知的拓扑合成。

Result: 在含14种候选LLM骨干的基准测试中，AgentBalance在匹配的token成本和延迟预算下分别实现最高10%和22%的性能提升，并在性能-预算曲线上展现出优异AUC；同时可作为插件提升现有MAS性能，并能泛化至未见LLM。

Conclusion: AgentBalance为预算约束下的MAS设计提供了系统性、可扩展且实用的新范式，兼顾性能、成本与延迟，适用于真实Web规模应用部署。

Abstract: Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance

</details>


### [196] [Back to the Baseline: Examining Baseline Effects on Explainability Metrics](https://arxiv.org/abs/2512.11433)
*Agustin Martin Picard,Thibaut Boissin,Varshini Subhash,Rémi Cadène,Thomas Fel*

Main category: cs.AI

TL;DR: 本文指出XAI中常用的Fidelity评估指标（如Insertion/Deletion）因依赖baseline而存在固有偏差，不同baseline会偏好不同归因方法；作者提出两个理想baseline应满足的性质（去信息性与非过度假分布），发现现有baseline均无法兼顾，并据此设计了一种基于特征可视化的模型相关新baseline。


<details>
  <summary>Details</summary>
Motivation: 现有Fidelity评估指标（如Insertion和Deletion）严重依赖baseline函数，而baseline的选择会系统性地偏向某些归因方法，甚至导致线性模型自相矛盾，因此亟需审视并改进baseline的设计原则。

Method: 提出两个理想baseline应具备的性质：（i）有效移除输入信息；（ii）不生成过度out-of-distribution（OOD）图像；通过实证分析验证现有baseline在二者间存在权衡；进而利用特征可视化技术构建模型依赖的新型baseline。

Result: 实证表明所有常用baseline（如黑色、灰色、高斯噪声等）均无法同时满足去信息性与低OOD性；所提新baseline在两项指标上取得更好权衡，显著提升Fidelity评估的公平性与可靠性。

Conclusion: Fidelity类评估指标的可信度高度依赖baseline设计；仅关注单一指标（如删除性能）不足以反映归因方法本质优劣；应采用兼顾信息移除与分布合理性的模型相关baseline，推动XAI评估标准化。

Abstract: Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline

</details>


### [197] [Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes](https://arxiv.org/abs/2512.11463)
*Junghwan Lim,Sungmin Lee,Dongseok Kim,Taehyun Kim,Eunhwan Park,Jeesoo Lee,Jeongdoo Lee,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Minsu Ha,Jaeheui Her,Jaeyeon Huh,Hanbin Jung,Changjin Kang,Beomgyu Kim,Minjae Kim,Taewhan Kim,Youngrok Kim,Hyukjin Kweon,Haesol Lee,Kungyu Lee,Dongpin Oh,Yeongjae Park,Bokki Ryu,Dongjoo Weon*

Main category: cs.AI

TL;DR: 本文提出Motif-2-12.7B-Reasoning，一个12.7B参数的开源大语言模型，通过系统、数据与算法三方面优化，显著提升复杂推理与长上下文理解能力，性能媲美更大参数模型。


<details>
  <summary>Details</summary>
Motivation: 解决开源模型在复杂推理和长上下文理解上落后于闭源前沿模型的问题，以及推理适配中常见的模型崩溃和训练不稳定挑战。

Method: 提出一套可复现的训练方案：包括支持64K token上下文的内存高效基础设施（混合并行+内核优化）、两阶段监督微调（SFT）课程（利用经验证对齐的合成数据缓解分布偏移）、以及基于难度感知过滤与混合策略轨迹复用的强化学习微调（RLFT）流程。

Result: Motif-2-12.7B-Reasoning在数学、编程和智能体基准测试中达到与更大参数模型相当的性能，成为具备竞争力的开源模型，并提供可在现实算力约束下扩展推理能力的实用范式。

Conclusion: 该工作证明了通过系统性工程优化，中小规模开源模型可在复杂推理任务上逼近甚至媲美更大模型，为社区提供了高性能开放模型及可复现的推理能力扩展方法论。

Abstract: We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory-efficient infrastructure for 64K-token contexts using hybrid parallelism and kernel-level optimizations with a two-stage Supervised Fine-Tuning (SFT) curriculum that mitigates distribution mismatch through verified, aligned synthetic data. Furthermore, we detail a robust Reinforcement Learning Fine-Tuning (RLFT) pipeline that stabilizes training via difficulty-aware data filtering and mixed-policy trajectory reuse. Empirical results demonstrate that Motif-2-12.7B-Reasoning achieves performance comparable to models with significantly larger parameter counts across mathematics, coding, and agentic benchmarks, offering the community a competitive open model and a practical blueprint for scaling reasoning capabilities under realistic compute constraints.

</details>


### [198] [Three methods, one problem: Classical and AI approaches to no-three-in-line](https://arxiv.org/abs/2512.11469)
*Pranav Ramanathan,Thomas Prellberg,Matthew Lewis,Prathamesh Dinesh Joshi,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.AI

TL;DR: 本文首次系统比较了经典优化方法（如整数线性规划ILP）与AI方法（PatternBoost Transformer和PPO强化学习）在No-Three-In-Line问题上的性能：ILP可保证19×19以内最优解，PatternBoost在14×14内达到最优且测试损失降低96%，PPO仅在10×10内完美求解；结果表明经典方法仍为精确解必需，AI适合小规模，混合方法最具扩展潜力。


<details>
  <summary>Details</summary>
Motivation: No-Three-In-Line问题是组合几何中的经典难题，传统ILP方法存在指数级计算复杂度瓶颈，而新兴AI方法在模式识别与近似求解上展现出潜力，亟需系统评估二者性能边界与适用场景。

Method: 采用整数线性规划（ILP）、PatternBoost Transformer学习模型和近端策略优化（PPO）强化学习三种方法，在不同尺寸n×n网格上求解No-Three-In-Line问题，并进行跨方法性能对比分析。

Result: ILP在n≤19时获得可证明最优解；PatternBoost在n≤14时匹配最优解，测试损失降低96%；PPO仅在n=10时得到完美解，n=11时因约束违反无法生成有效配置。

Conclusion: 经典优化方法仍是获取精确解的可靠基础，AI方法在中小规模实例上具备竞争力，但泛化能力受限；未来应探索ILP与AI结合的混合范式以突破大规模问题求解瓶颈。

Abstract: The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.

</details>


### [199] [BAID: A Benchmark for Bias Assessment of AI Detectors](https://arxiv.org/abs/2512.11505)
*Priyam Basu,Yunfeng Zhang,Vipul Raheja*

Main category: cs.AI

TL;DR: 本文提出BAID框架，系统评估AI生成文本检测器在多种社会语言学因素（如人口统计、年龄、教育水平、方言等）下的偏见问题，发现现有检测器对少数群体文本的召回率普遍偏低。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器在教育和职业场景中被广泛应用，但缺乏对社会语言学因素（如英语学习者、方言、教育水平等）系统性偏见的评估。

Method: 构建BAID评估框架，包含20万+样本，覆盖7类社会语言学维度，并通过精心设计的提示生成保留原意但体现子群写作风格的合成文本；评估4个开源SOTA检测器的性能差异。

Result: 四个主流开源AI文本检测器在不同子群上表现不一致，尤其对弱势群体文本的召回率显著偏低，暴露出系统性偏见。

Conclusion: AI文本检测器需在部署前进行偏见感知的系统性审计，BAID提供了一种可扩展、透明的评估方法，强调公平性与责任性。

Abstract: AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.

</details>


### [200] [EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection](https://arxiv.org/abs/2512.11506)
*Georgios Kaoukis,Ioannis Aris Koufopoulos,Psaroudaki Eleni,Danae Pla Karidi,Evaggelia Pitoura,George Papastefanatos,Panayiotis Tsaparas*

Main category: cs.AI

TL;DR: EmeraldMind 是一个基于事实的绿色漂洗检测框架，结合领域知识图谱与检索增强生成技术，无需微调即可实现高准确率、广覆盖和高质量解释的自动化绿色漂洗识别。


<details>
  <summary>Details</summary>
Motivation: 绿色漂洗（即企业虚假或误导性可持续发展声明）严重阻碍环保进展，而现有通用大模型缺乏可靠、可验证的企业ESG证据支持，难以准确识别和解释绿色漂洗行为。

Method: 提出 EmeraldMind 框架，构建专用于企业ESG报告的领域知识图谱 EmeraldGraph，并结合检索增强生成（RAG）技术，实现对可持续性声明的事实核查与透明判据生成；采用 justification-centric 分类策略，支持可解释判决与审慎弃权。

Result: 在新构建的绿色漂洗声明数据集上，EmeraldMind 在准确率、覆盖范围和解释质量上均优于通用大语言模型，且无需任何微调或重训练。

Conclusion: EmeraldMind 证明了融合结构化领域知识与生成式AI可有效提升绿色漂洗检测的可靠性、透明性与实用性，为可持续AI系统提供了一种可推广的技术范式。

Abstract: As AI and web agents become pervasive in decision-making, it is critical to design intelligent systems that not only support sustainability efforts but also guard against misinformation. Greenwashing, i.e., misleading corporate sustainability claims, poses a major challenge to environmental progress. To address this challenge, we introduce EmeraldMind, a fact-centric framework integrating a domain-specific knowledge graph with retrieval-augmented generation to automate greenwashing detection. EmeraldMind builds the EmeraldGraph from diverse corporate ESG (environmental, social, and governance) reports, surfacing verifiable evidence, often missing in generic knowledge bases, and supporting large language models in claim assessment. The framework delivers justification-centric classifications, presenting transparent, evidence-backed verdicts and abstaining responsibly when claims cannot be verified. Experiments on a new greenwashing claims dataset demonstrate that EmeraldMind achieves competitive accuracy, greater coverage, and superior explanation quality compared to generic LLMs, without the need for fine-tuning or retraining.

</details>


### [201] [AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives](https://arxiv.org/abs/2512.11544)
*Yuan Shen,Xiaojun Wu,Linghua Yu*

Main category: cs.AI

TL;DR: 本研究首次提出'AI-MASLD'概念，发现大语言模型在处理含噪声的临床主诉时会出现类似代谢功能障碍的表现，存在安全隐患，需在医生监督下作为辅助工具使用。


<details>
  <summary>Details</summary>
Motivation: 模拟真实临床场景，系统评估大语言模型从含噪声、冗余的患者主诉中提取核心医学信息的能力，并验证其是否表现出类似MASLD的功能衰退。

Method: 采用基于标准化医学探针的横断面分析设计，选取GPT-4o、Gemini 2.5、DeepSeek 3.1和Qwen3-Max四款主流大语言模型；构建涵盖五个核心维度的二十个医学探针评估体系，由两位独立临床医生按双盲逆向评分标准进行评估。

Result: 所有模型均存在不同程度功能缺陷，Qwen3-Max整体表现最优，Gemini 2.5最差；极端噪声下多数模型出现功能崩溃；GPT-4o在深静脉血栓继发肺栓塞风险评估中出现严重误判。

Conclusion: 首次实证确认大语言模型在处理临床信息时表现出类似代谢功能障碍的特征，提出'AI-MASLD'新概念，警示当前大语言模型在医疗应用中仍需人类专家监督，理论知识与临床实践间存在显著差距。

Abstract: This study aims to simulate real-world clinical scenarios to systematically evaluate the ability of Large Language Models (LLMs) to extract core medical information from patient chief complaints laden with noise and redundancy, and to verify whether they exhibit a functional decline analogous to Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD). We employed a cross-sectional analysis design based on standardized medical probes, selecting four mainstream LLMs as research subjects: GPT-4o, Gemini 2.5, DeepSeek 3.1, and Qwen3-Max. An evaluation system comprising twenty medical probes across five core dimensions was used to simulate a genuine clinical communication environment. All probes had gold-standard answers defined by clinical experts and were assessed via a double-blind, inverse rating scale by two independent clinicians. The results show that all tested models exhibited functional defects to varying degrees, with Qwen3-Max demonstrating the best overall performance and Gemini 2.5 the worst. Under conditions of extreme noise, most models experienced a functional collapse. Notably, GPT-4o made a severe misjudgment in the risk assessment for pulmonary embolism (PE) secondary to deep vein thrombosis (DVT). This research is the first to empirically confirm that LLMs exhibit features resembling metabolic dysfunction when processing clinical information, proposing the innovative concept of "AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)". These findings offer a crucial safety warning for the application of Artificial Intelligence (AI) in healthcare, emphasizing that current LLMs must be used as auxiliary tools under human expert supervision, as there remains a significant gap between their theoretical knowledge and practical clinical application.

</details>


### [202] [AI Benchmark Democratization and Carpentry](https://arxiv.org/abs/2512.11588)
*Gregor von Laszewski,Wesley Brewer,Jeyan Thiyagalingam,Juri Papay,Armstrong Foundjem,Piotr Luszczek,Murali Emani,Shirley V. Moore,Vijay Janapa Reddi,Matthew D. Sinclair,Sebastian Lobentanzer,Sujata Goswami,Benjamin Hawks,Marco Colombo,Nhan Tran,Christine R. Kirkpatrick,Abdulkareem Alsudais,Gregg Barrett,Tianhao Li,Kirsten Morehouse,Shivaram Venkataraman,Rutwik Jain,Kartik Mathur,Victor Lu,Tejinder Singh,Khojasteh Z. Mirza,Kongtao Chen,Sasidhar Kunapuli,Gavin Farrell,Renato Umeton,Geoffrey C. Fox*

Main category: cs.AI

TL;DR: 本文提出'AI Benchmark Carpentry'概念，倡导构建动态、自适应、包容性的AI基准测试框架，以应对当前静态基准在大模型时代面临的过拟合、脱离实际应用和资源不平等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有AI基准测试过于静态，易被大语言模型记忆，导致评估结果与真实性能脱节；同时高资源门槛、硬件依赖和设计专业知识缺乏阻碍了基准测试的普及与有效应用。

Method: 基于MLCommons、美国能源部万亿参数联盟等实践经验，提出通过教育推广（AI Benchmark Carpentry）、技术革新（动态更新数据/模型/平台）与社区共建，推动基准测试民主化与动态化。

Result: 提出动态自适应基准测试框架的核心原则：实时演化、异构平台兼容、透明可复现、应用导向；并指出教育与社区协作是实现可持续基准能力的关键路径。

Conclusion: AI基准测试需从静态评测转向动态、包容、教育驱动的持续评估范式，以支撑负责任、可复现且可及的AI部署。

Abstract: Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance.
  Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This calls for skills and education in AI Benchmark Carpentry. From our experience with MLCommons, educational initiatives, and programs like the DOE's Trillion Parameter Consortium, key barriers include high resource demands, limited access to specialized hardware, lack of benchmark design expertise, and uncertainty in relating results to application domains. Current benchmarks often emphasize peak performance on top-tier hardware, offering limited guidance for diverse, real-world scenarios.
  Benchmarking must become dynamic, incorporating evolving models, updated data, and heterogeneous platforms while maintaining transparency, reproducibility, and interpretability. Democratization requires both technical innovation and systematic education across levels, building sustained expertise in benchmark design and use. Benchmarks should support application-relevant comparisons, enabling informed, context-sensitive decisions. Dynamic, inclusive benchmarking will ensure evaluation keeps pace with AI evolution and supports responsible, reproducible, and accessible AI deployment. Community efforts can provide a foundation for AI Benchmark Carpentry.

</details>


### [203] [Causal Inference in Energy Demand Prediction](https://arxiv.org/abs/2512.11653)
*Chutian Ma,Grigorii Pomazkin,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.AI

TL;DR: 本文提出了一种基于结构因果模型的能源需求预测方法，揭示了温度与能源需求之间的季节依赖性因果关系，并利用该因果洞察构建贝叶斯模型，在测试集上实现3.84% MAPE的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 能源需求受天气和日历等多因素影响，且这些因素存在因果依赖关系，传统相关性学习方法难以建模。

Method: 构建结构因果模型以刻画变量间因果关系，并基于因果发现结果设计贝叶斯预测模型，将因果知识作为先验。

Result: 在测试集上达到3.84% MAPE，两年交叉验证平均MAPE为3.88%，性能达当前最优且鲁棒性强。

Conclusion: 因果建模能有效提升能源预测精度与可解释性，揭示出温度敏感性随季节变化及冬季活动模式解耦等重要规律。

Abstract: Energy demand prediction is critical for grid operators, industrial energy
  consumers, and service providers. Energy demand is influenced by multiple
  factors, including weather conditions (e.g. temperature, humidity, wind
  speed, solar radiation), and calendar information (e.g. hour of day and
  month of year), which further affect daily work and life schedules. These
  factors are causally interdependent, making the problem more complex than
  simple correlation-based learning techniques satisfactorily allow for. We
  propose a structural causal model that explains the causal relationship
  between these variables. A full analysis is performed to validate our causal
  beliefs, also revealing important insights consistent with prior studies.
  For example, our causal model reveals that energy demand responds to
  temperature fluctuations with season-dependent sensitivity. Additionally, we
  find that energy demand exhibits lower variance in winter due to the
  decoupling effect between temperature changes and daily activity patterns.
  We then build a Bayesian model, which takes advantage of the causal insights
  we learned as prior knowledge. The model is trained and tested on unseen
  data and yields state-of-the-art performance in the form of a 3.84 percent MAPE on
  the test set. The model also demonstrates strong robustness, as the
  cross-validation across two years of data yields an average MAPE of 3.88 percent.

</details>


### [204] [MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition](https://arxiv.org/abs/2512.11682)
*Tim Cofala,Christian Kalfar,Jingge Xiao,Johanna Schrader,Michelle Tang,Wolfgang Nejdl*

Main category: cs.AI

TL;DR: 本文介绍了TxAgent，一种面向临床治疗决策的智能代理系统，通过迭代式检索增强生成（RAG）与统一生物医学工具集（ToolUniverse）协同，提升药物推荐、治疗规划与不良反应预测的准确性与安全性；强调推理链与工具调用序列的可验证性，并在CURE-Bench挑战中获开放科学卓越奖。


<details>
  <summary>Details</summary>
Motivation: 临床治疗决策具有高风险性，需兼顾患者特征、疾病机制与药理作用；通用RAG系统难以满足医疗场景对推理过程和工具调用准确性的严格安全要求。

Method: 提出TxAgent框架，基于微调的Llama-3.1-8B模型，动态生成并执行ToolUniverse中的函数调用（集成FDA Drug API、OpenTargets、Monarch等资源），采用以推理轨迹和工具使用为监督信号的评估协议。

Result: 验证了检索质量对工具调用准确性的关键影响，通过优化工具检索策略显著提升整体性能；在CURE-Bench NeurIPS 2025挑战中取得优异表现，获开放科学卓越奖。

Conclusion: 面向临床治疗的Agentic AI需深度融合高质量生物医学知识与可审计的多步推理机制；将推理过程与工具行为显式建模为监督信号，是提升医疗AI可靠性与安全性的有效路径。

Abstract: Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (RAG). TxAgent employs a fine-tuned Llama-3.1-8B model that dynamically generates and executes function calls to a unified biomedical tool suite (ToolUniverse), integrating FDA Drug API, OpenTargets, and Monarch resources to ensure access to current therapeutic information. In contrast to general-purpose RAG systems, medical applications impose stringent safety constraints, rendering the accuracy of both the reasoning trace and the sequence of tool invocations critical. These considerations motivate evaluation protocols treating token-level reasoning and tool-usage behaviors as explicit supervision signals. This work presents insights derived from our participation in the CURE-Bench NeurIPS 2025 Challenge, which benchmarks therapeutic-reasoning systems using metrics that assess correctness, tool utilization, and reasoning quality. We analyze how retrieval quality for function (tool) calls influences overall model performance and demonstrate performance gains achieved through improved tool-retrieval strategies. Our work was awarded the Excellence Award in Open Science. Complete information can be found at https://curebench.ai/.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [205] [WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control](https://arxiv.org/abs/2512.11047)
*Haoran Jiang,Jin Chen,Qingwen Bu,Li Chen,Modi Shi,Yanjie Zhang,Delong Li,Chuanzhe Suo,Chuang Wang,Zhihui Peng,Hongyang Li*

Main category: cs.RO

TL;DR: 本文提出WholeBodyVLA框架，通过统一潜在学习和专为locomanipulation设计的强化学习策略，解决人形机器人在大空间中进行精确运动与灵巧操作协同的难题。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏操作感知的运动能力，受限于人形遥操作数据稀缺及RL控制器精度与稳定性不足，难以实现大空间loco-manipulation。

Method: 提出统一潜在学习框架，使VLA系统能从低成本、无动作的自我中心视频中学习；构建高效人类数据采集流程以扩充数据集；设计面向loco-manipulation的LMO RL策略，提升前进、转向、下蹲等核心动作的执行精度与稳定性。

Result: WholeBodyVLA在AgiBot X2人形机器人上实验验证，性能较先前基线提升21.3%，具备强泛化性与高可扩展性。

Conclusion: WholeBodyVLA是首个支持大空间人形loco-manipulation的统一框架，有效弥合了运动与操作协同的鸿沟。

Abstract: Humanoid robots require precise locomotion and dexterous manipulation to perform challenging loco-manipulation tasks. Yet existing approaches, modular or end-to-end, are deficient in manipulation-aware locomotion. This confines the robot to a limited workspace, preventing it from performing large-space loco-manipulation. We attribute this to: (1) the challenge of acquiring loco-manipulation knowledge due to the scarcity of humanoid teleoperation data, and (2) the difficulty of faithfully and reliably executing locomotion commands, stemming from the limited precision and stability of existing RL controllers. To acquire richer loco-manipulation knowledge, we propose a unified latent learning framework that enables Vision-Language-Action (VLA) system to learn from low-cost action-free egocentric videos. Moreover, an efficient human data collection pipeline is devised to augment the dataset and scale the benefits. To more precisely execute the desired locomotion commands, we present a loco-manipulation-oriented (LMO) RL policy specifically tailored for accurate and stable core loco-manipulation movements, such as advancing, turning, and squatting. Building on these components, we introduce WholeBodyVLA, a unified framework for humanoid loco-manipulation. To the best of our knowledge, WholeBodyVLA is one of its kind enabling large-space humanoid loco-manipulation. It is verified via comprehensive experiments on the AgiBot X2 humanoid, outperforming prior baseline by 21.3%. It also demonstrates strong generalization and high extensibility across a broad range of tasks.

</details>


### [206] [Taxonomy and Modular Tool System for Versatile and Effective Non-Prehensile Manipulations](https://arxiv.org/abs/2512.11080)
*Cedric-Pascal Sommer,Robert J. Wood,Justin Werfel*

Main category: cs.RO

TL;DR: 本文提出了一种基于关键属性分类的非驱动末端执行器工具系统，扩展了标准两指夹爪在非抓取操作（如按压、摩擦、刮擦）中的能力，并在航空航天和家庭场景中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有通用机器人末端执行器（如平行夹爪）虽适用于抓取类操作，但未针对按压、摩擦、刮擦等非抓取操作进行优化；人类则根据任务需求选用不同刚度、摩擦特性的身体部位或工具，启发了对非抓取操作工具系统的系统化设计。

Method: 首先构建非驱动末端执行器的关键属性分类法（taxonomy），以此为基础设计模块化工具系统，使其可由标准两指夹爪快速装配与切换，支持多种非抓取及抓取操作。

Result: 实现了模块化工具系统，并在航空航天（如表面清洁、密封检测）和家庭（如擦拭、刮除）场景中成功演示了其对多类非抓取与抓取任务的有效支持。

Conclusion: 该基于属性分类的模块化工具系统显著提升了通用夹爪在多样化物理交互任务中的适应性与实用性，为非抓取操作提供了可扩展、可复用的硬件解决方案。

Abstract: General-purpose robotic end-effectors of limited complexity, like the parallel-jaw gripper, are appealing for their balance of simplicity and effectiveness in a wide range of manipulation tasks. However, while many such manipulators offer versatility in grasp-like interactions, they are not optimized for non-prehensile actions like pressing, rubbing, or scraping -- manipulations needed for many common tasks. To perform such tasks, humans use a range of different body parts or tools with different rigidity, friction, etc., according to the properties most effective for a given task. Here, we discuss a taxonomy for the key properties of a non-actuated end-effector, laying the groundwork for a systematic understanding of the affordances of non-prehensile manipulators. We then present a modular tool system, based on the taxonomy, that can be used by a standard two-fingered gripper to extend its versatility and effectiveness in performing such actions. We demonstrate the application of the tool system in aerospace and household scenarios that require a range of non-prehensile and prehensile manipulations.

</details>


### [207] [Design and Experimental Validation of Closed-Form CBF-Based Safe Control for Stewart Platform Under Multiple Constraints](https://arxiv.org/abs/2512.11125)
*Benedictus C. G. Cinun,Tua A. Tamba,Immanuel R. Santjoko,Xiaofeng Wang,Michael A. Gunarso,Bin Hu*

Main category: cs.RO

TL;DR: 本文提出了一种针对Stewart平台的控制屏障函数（CBF）框架的闭式解，能同时处理多个位置和速度约束，无需每步求解二次规划（QP），显著提升实时性；推导了保证解非奇异的充要条件，并通过仿真与实物实验验证了其安全性与计算效率优势。


<details>
  <summary>Details</summary>
Motivation: 解决传统CBF方法在Stewart平台等并联机器人中需实时求解QP导致计算负担重、难以满足实时安全控制需求的问题。

Method: 设计一种显式的闭式控制律，统一处理多位置与多速度安全约束，并推导其非奇异性的必要与充分条件以确保解的良定性。

Result: 在仿真与自研Stewart平台硬件上验证了该方法的安全性能与QP方法相当，但计算时间降低一个数量级以上。

Conclusion: 所提闭式CBF方法为并联机器人提供了可靠、轻量化的实时安全控制新框架。

Abstract: This letter presents a closed-form solution of Control Barrier Function (CBF) framework for enforcing safety constraints on a Stewart robotic platform. The proposed method simultaneously handles multiple position and velocity constraints through an explicit closed-form control law, eliminating the need to solve a Quadratic Program (QP) at every control step and enabling efficient real-time implementation. This letter derives necessary and sufficient conditions under which the closed-form expression remains non-singular, thereby ensuring well-posedness of the CBF solution to multi-constraint problem. The controller is validated in both simulation and hardware experiments on a custom-built Stewart platform prototype, demonstrating safetyguaranteed performance that is comparable to the QP-based formulation, while reducing computation time by more than an order of magnitude. The results confirm that the proposed approach provides a reliable and computationally lightweight framework for real-time safe control of parallel robotic systems. The experimental videos are available on the project website. (https://nail-uh.github.io/StewartPlatformSafeControl.github.io/)

</details>


### [208] [Learning Category-level Last-meter Navigation from RGB Demonstrations of a Single-instance](https://arxiv.org/abs/2512.11173)
*Tzu-Hsien Lee,Fidan Mahmudova,Karthik Desingh*

Main category: cs.RO

TL;DR: 本文提出了一种面向对象的模仿学习框架，用于四足移动机械臂的“最后一米”导航，仅依赖RGB图像即可实现高精度定位，无需深度、LiDAR或地图先验。


<details>
  <summary>Details</summary>
Motivation: 现有RGB导航系统精度仅为米级，难以满足移动操作中对基座精确定位的需求，导致操作策略在真实部署时频繁失败。

Method: 基于目标图像、多视角RGB观测和文本提示（指定目标物体）构建导航策略；引入语言驱动的分割模块与空间得分矩阵解码器，实现显式的物体定位与相对位姿推理。

Result: 在边缘对齐指标上成功率达73.47%，物体对齐指标达96.94%；系统能跨环境泛化至未见过的同类物体实例，适应复杂光照与背景。

Conclusion: 仅用RGB即可实现类别级最后一米精准导航，为统一的移动操作提供了可扩展路径。

Abstract: Achieving precise positioning of the mobile manipulator's base is essential for successful manipulation actions that follow. Most of the RGB-based navigation systems only guarantee coarse, meter-level accuracy, making them less suitable for the precise positioning phase of mobile manipulation. This gap prevents manipulation policies from operating within the distribution of their training demonstrations, resulting in frequent execution failures. We address this gap by introducing an object-centric imitation learning framework for last-meter navigation, enabling a quadruped mobile manipulator robot to achieve manipulation-ready positioning using only RGB observations from its onboard cameras. Our method conditions the navigation policy on three inputs: goal images, multi-view RGB observations from the onboard cameras, and a text prompt specifying the target object. A language-driven segmentation module and a spatial score-matrix decoder then supply explicit object grounding and relative pose reasoning. Using real-world data from a single object instance within a category, the system generalizes to unseen object instances across diverse environments with challenging lighting and background conditions. To comprehensively evaluate this, we introduce two metrics: an edge-alignment metric, which uses ground truth orientation, and an object-alignment metric, which evaluates how well the robot visually faces the target. Under these metrics, our policy achieves 73.47% success in edge-alignment and 96.94% success in object-alignment when positioning relative to unseen target objects. These results show that precise last-meter navigation can be achieved at a category-level without depth, LiDAR, or map priors, enabling a scalable pathway toward unified mobile manipulation. Project page: https://rpm-lab-umn.github.io/category-level-last-meter-nav/

</details>


### [209] [Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy](https://arxiv.org/abs/2512.11218)
*Kechun Xu,Zhenjie Zhu,Anzhe Chen,Shuqi Zhao,Qing Huang,Yifei Yang,Haojian Lu,Rong Xiong,Masayoshi Tomizuka,Yue Wang*

Main category: cs.RO

TL;DR: BayesVLA 提出一种贝叶斯分解方法，解耦视觉-动作先验与语言条件似然，缓解VLA模型中因模态不平衡导致的语言遗忘和视觉捷径问题，提升分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: VLA模型在微调时易因视觉-语言模态不平衡（语言多样性远低于视觉和动作）导致语言遗忘和依赖视觉捷径，现有共训练方法依赖外部数据且调参复杂。

Method: 提出BayesVLA：将策略贝叶斯分解为视觉-动作先验（seeing-to-act）和语言条件似然（prompt-to-specify），并引入接触前/后阶段以更好利用预训练基础模型；结合信息论分析验证其抑制捷径学习的有效性。

Result: 在未见指令、物体和环境上的分布外泛化性能显著优于现有方法。

Conclusion: 模态不平衡是VLA泛化瓶颈的内在原因；BayesVLA通过贝叶斯结构设计，在不依赖外部数据的前提下，兼顾视觉动作能力与语言指令遵循，有效提升泛化性。

Abstract: The pursuit of out-of-distribution generalization in Vision-Language-Action (VLA) models is often hindered by catastrophic forgetting of the Vision-Language Model (VLM) backbone during fine-tuning. While co-training with external reasoning data helps, it requires experienced tuning and data-related overhead. Beyond such external dependencies, we identify an intrinsic cause within VLA datasets: modality imbalance, where language diversity is much lower than visual and action diversity. This imbalance biases the model toward visual shortcuts and language forgetting. To address this, we introduce BayesVLA, a Bayesian factorization that decomposes the policy into a visual-action prior, supporting seeing-to-act, and a language-conditioned likelihood, enabling prompt-to-specify. This inherently preserves generalization and promotes instruction following. We further incorporate pre- and post-contact phases to better leverage pre-trained foundation models. Information-theoretic analysis formally validates our effectiveness in mitigating shortcut learning. Extensive experiments show superior generalization to unseen instructions, objects, and environments compared to existing methods. Project page is available at: https://xukechun.github.io/papers/BayesVLA.

</details>


### [210] [Elevation Aware 2D/3D Co-simulation Framework for Large-scale Traffic Flow and High-fidelity Vehicle Dynamics](https://arxiv.org/abs/2512.11249)
*Chandra Raskoti,Weizi Li*

Main category: cs.RO

TL;DR: 本文提出了一种自动化的、考虑高程信息的联合仿真框架，将SUMO与CARLA结合，利用OpenStreetMap和USGS高程数据构建物理一致的三维城市环境，以支持高保真自动驾驶系统测试。


<details>
  <summary>Details</summary>
Motivation: 现有仿真工具难以准确建模真实世界中的地形高程，尤其在复杂地形城市中限制了自动驾驶系统测试的可靠性。

Method: 构建一个自动化流水线，融合OpenStreetMap道路网络与USGS高程数据，生成平滑且几何准确的三维环境，并实现SUMO（2D交通流）与CARLA（3D感知仿真）的同步联合仿真。

Result: 在旧金山多个区域成功演示了该框架的可扩展性及对陡峭、不规则地形的高保真复现能力。

Conclusion: 该框架为在高程丰富的现实城市环境中开展高保真自动驾驶测试提供了实用基础。

Abstract: Reliable testing of autonomous driving systems requires simulation environments that combine large-scale traffic modeling with realistic 3D perception and terrain. Existing tools rarely capture real-world elevation, limiting their usefulness in cities with complex topography. This paper presents an automated, elevation-aware co-simulation framework that integrates SUMO with CARLA using a pipeline that fuses OpenStreetMap road networks and USGS elevation data into physically consistent 3D environments. The system generates smooth elevation profiles, validates geometric accuracy, and enables synchronized 2D-3D simulation across platforms. Demonstrations on multiple regions of San Francisco show the framework's scalability and ability to reproduce steep and irregular terrain. The result is a practical foundation for high-fidelity autonomous vehicle testing in realistic, elevation-rich urban settings.

</details>


### [211] [Optimal Control and Structurally-Informed Gradient Optimization of a Custom 4-DOF Rigid-Body Manipulator](https://arxiv.org/abs/2512.11250)
*Brock Marcinczyk,Logan E. Beaver*

Main category: cs.RO

TL;DR: 本文提出了一种面向控制的框架，结合简化Pontryagin最大值原理（PMP）控制器与物理信息驱动的梯度下降模块，为定制4自由度刚体机械臂生成动力学一致的轨迹与时间尺度。


<details>
  <summary>Details</summary>
Motivation: 为定制4-DOF刚体机械臂设计一种兼顾控制理论严谨性与物理建模准确性的高效运动规划方法，避免高维优化带来的计算负担。

Method: 耦合简化PMP控制器（提供关节加速度闭式最优控制律）与基于完整刚体动力学代价函数的梯度下降模块（优化时间尺度）；利用结构力学反力分析初始化可行关节速度（尤其是方位角分量）；最终将所得轨迹输入符号化Euler-Lagrange模型求解逆动力学。

Result: 生成了运动学轨迹与动力学一致的时间尺度，并输出闭式逆动力学控制输入，整个流程保持严格控制理论结构，同时嵌入物理约束与载荷行为。

Conclusion: 该框架在保证控制理论完整性的同时，以计算高效方式融合了高保真物理建模，适用于定制刚体机械臂的实时或准实时控制设计。

Abstract: This work develops a control-centric framework for a custom 4-DOF rigid-body manipulator by coupling a reduced-order Pontryagin's Maximum Principle (PMP) controller with a physics-informed Gradient Descent stage. The reduced PMP model provides a closed-form optimal control law for the joint accelerations, while the Gradient Descent module determines the corresponding time horizons by minimizing a cost functional built directly from the full Rigid-Body Dynamics. Structural-mechanics reaction analysis is used only to initialize feasible joint velocities-most critically the azimuthal component-ensuring that the optimizer begins in a physically admissible region. The resulting kinematic trajectories and dynamically consistent time horizons are then supplied to the symbolic Euler-Lagrange model to yield closed-form inverse-dynamics inputs. This pipeline preserves a strict control-theoretic structure while embedding the physical constraints and loading behavior of the manipulator in a computationally efficient way.

</details>


### [212] [Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing](https://arxiv.org/abs/2512.11275)
*Suchang Chen,Daqiang Guo*

Main category: cs.RO

TL;DR: 本文提出了一种面向机器人操作的对象中心化操作逻辑模式τ（八字段元组），以显式编码执行关键参数（如接口、轨迹、容差、力/阻抗等），弥补现有视觉语言模型在制造场景接触密集型任务中的不足，并在3D打印机线轴移除任务中验证了其在数据增强、检索增强提示及规划质量方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在机器人操作中侧重语义泛化，但忽略了制造业中接触密集型操作所必需的执行级参数（如力、轨迹容差、接口等），导致人-机协同可靠性不足。

Method: 提出对象中心化的八字段操作逻辑模式τ，涵盖对象、接口、轨迹、容差、力/阻抗等关键执行信息；构建小型知识库（KB）；在3D打印线轴移除任务中实现τ实例化；结合τ进行VLM条件化规划，并支持τ驱动的数据增强与逻辑感知的检索增强提示（RAG）。

Result: 验证了τ可提升VLM规划质量（基于适配的VLM/LLM规划评测指标）；实现了基于τ的标签化数据增强与逻辑-aware RAG；为智能制造企业提供可扩展的助理系统基础构件。

Conclusion: 将执行关键参数显式建模为结构化知识（τ）是连接人类意图、VLM助手与机器人控制器的有效桥梁，显著增强VLM在真实制造场景中的可部署性与可靠性。

Abstract: Existing pipelines for vision-language models (VLMs) in robotic manipulation prioritize broad semantic generalization from images and language, but typically omit execution-critical parameters required for contact-rich actions in manufacturing cells. We formalize an object-centric manipulation-logic schema, serialized as an eight-field tuple τ, which exposes object, interface, trajectory, tolerance, and force/impedance information as a first-class knowledge signal between human operators, VLM-based assistants, and robot controllers. We instantiate τ and a small knowledge base (KB) on a 3D-printer spool-removal task in a collaborative cell, and analyze τ-conditioned VLM planning using plan-quality metrics adapted from recent VLM/LLM planning benchmarks, while demonstrating how the same schema supports taxonomy-tagged data augmentation at training time and logic-aware retrieval-augmented prompting at test time as a building block for assistant systems in smart manufacturing enterprises.

</details>


### [213] [Incremental Validation of Automated Driving Functions using Generic Volumes in Micro- Operational Design Domains](https://arxiv.org/abs/2512.11351)
*Steffen Schäfer,Martin Cichon*

Main category: cs.RO

TL;DR: 本文提出了一种结构化方法，将运行设计域（ODD）细分为微ODD（mODD），并基于抽象障碍物表征生成测试用例，以系统评估感知系统在边缘场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于场景的测试中，从ODD分类法到具体测试用例的转化缺乏结构化方法，且完整性仅停留在理论层面，难以支撑高自动化驾驶系统的安全验证与授权。

Method: 提出微ODD（mODD）划分方法，将ODD分解为可管理的子域，并在其中构建窄化分类法；采用通用立方体抽象表征障碍物；在闭环协同仿真环境中（含真实感渲染及模拟LiDAR、GNSS、摄像头）开展测试。

Result: 成功系统探索了障碍物检测的边缘案例，通过‘碰撞’与‘安全停车’两类行为结果评估感知质量，并验证了该方法对感知性能评估和安全论证框架构建的有效性。

Conclusion: 该方法为自动化驾驶功能的标准化安全论证和实际验证授权提供了可行路径，推动了感知驱动型自动驾驶系统验证的结构化与可重复性发展。

Abstract: The validation of highly automated, perception-based driving systems must ensure that they function correctly under the full range of real-world conditions. Scenario-based testing is a prominent approach to addressing this challenge, as it involves the systematic simulation of objects and environments. Operational Design Domains (ODDs) are usually described using a taxonomy of qualitative designations for individual objects. However, the process of transitioning from taxonomy to concrete test cases remains unstructured, and completeness is theoretical. This paper introduces a structured method of subdividing the ODD into manageable sections, termed micro-ODDs (mODDs), and deriving test cases with abstract object representations. This concept is demonstrated using a one-dimensional, laterally guided manoeuvre involving a shunting locomotive within a constrained ODD. In this example, mODDs are defined and refined into narrow taxonomies that enable test case generation. Obstacles are represented as generic cubes of varying sizes, providing a simplified yet robust means of evaluating perception performance. A series of tests were conducted in a closed-loop, co-simulated virtual environment featuring photorealistic rendering and simulated LiDAR, GNSS and camera sensors. The results demonstrate how edge cases in obstacle detection can be systematically explored and how perception quality can be evaluated based on observed vehicle behaviour, using crash versus safe stop as the outcome metrics. These findings support the development of a standardised framework for safety argumentation and offer a practical step towards the validation and authorisation of automated driving functions.

</details>


### [214] [Agile Flight Emerges from Multi-Agent Competitive Racing](https://arxiv.org/abs/2512.11781)
*Vineet Pasumarti,Lorenzo Bianchi,Antonio Loquercio*

Main category: cs.RO

TL;DR: 本文通过多智能体竞争和稀疏的高层目标（赢得比赛），发现强化学习训练的智能体能够自主涌现出敏捷飞行（如高速运动逼近平台物理极限）和策略行为（如超车或阻挡）。该方法在仿真和现实世界中均优于传统单智能体、基于行为引导奖励（如赛道进度）的训练范式，尤其在环境复杂度增加时（如存在障碍物），且具备更优的仿真到现实迁移能力和对未见过对手的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统单智能体强化学习依赖密集、行为级奖励（如赛道进度），难以扩展到复杂物理环境；而多智能体竞争可能通过稀疏任务级奖励激发更鲁棒、可迁移的低层控制能力。

Method: 采用多智能体竞争框架，在仿真环境中训练多个无人机智能体以‘赢得比赛’为唯一稀疏奖励目标；使用相同仿真环境、随机化策略与硬件对比单智能体进度奖励基线；在仿真和真实无人机平台上验证性能与迁移性。

Result: 多智能体竞争策略在仿真和真实世界中均展现出更高水平的敏捷飞行与对抗策略；相比单智能体进度奖励方法，其sim-to-real迁移成功率显著提升，并能泛化至训练中未见过的对手。

Conclusion: 稀疏的任务级奖励（如获胜）结合多智能体竞争，足以驱动物理世界中高级低层控制能力的涌现，为具身智能体训练提供了更高效、鲁棒且可迁移的新范式。

Abstract: Through multi-agent competition and the sparse high-level objective of winning a race, we find that both agile flight (e.g., high-speed motion pushing the platform to its physical limits) and strategy (e.g., overtaking or blocking) emerge from agents trained with reinforcement learning. We provide evidence in both simulation and the real world that this approach outperforms the common paradigm of training agents in isolation with rewards that prescribe behavior, e.g., progress on the raceline, in particular when the complexity of the environment increases, e.g., in the presence of obstacles. Moreover, we find that multi-agent competition yields policies that transfer more reliably to the real world than policies trained with a single-agent progress-based reward, despite the two methods using the same simulation environment, randomization strategy, and hardware. In addition to improved sim-to-real transfer, the multi-agent policies also exhibit some degree of generalization to opponents unseen at training time. Overall, our work, following in the tradition of multi-agent competitive game-play in digital domains, shows that sparse task-level rewards are sufficient for training agents capable of advanced low-level control in the physical world.
  Code: https://github.com/Jirl-upenn/AgileFlight_MultiAgent

</details>


### [215] [An Anatomy of Vision-Language-Action Models: From Modules to Milestones and Challenges](https://arxiv.org/abs/2512.11362)
*Chao Xu,Suyu Zhang,Yang Liu,Baigui Sun,Weihong Chen,Bo Xu,Qi Liu,Juncheng Wang,Shujun Wang,Shan Luo,Jan Peters,Athanasios V. Vasilakos,Stefanos Zafeiriou,Jiankang Deng*

Main category: cs.RO

TL;DR: This survey provides a structured guide to Vision-Language-Action (VLA) models in robotics, organizing the field around five core challenges—Representation, Execution, Generalization, Safety, and Dataset & Evaluation—following a researcher’s learning path and agent development roadmap.


<details>
  <summary>Details</summary>
Motivation: The rapid growth of VLA models and datasets makes it difficult for researchers to keep pace; this survey aims to provide clarity, structure, and strategic direction for both newcomers and experts.

Method: The paper adopts a pedagogical and developmental structure: first introducing foundational modules, then tracing historical milestones, and finally analyzing five key research challenges with reviews of existing approaches and future opportunities.

Result: A comprehensive, living survey that categorizes and synthesizes the VLA field along five major challenges, serving as both an educational resource and a research roadmap.

Conclusion: The survey establishes a unified framework for understanding VLA progress and bottlenecks, emphasizing the need for integrated perception-action loops, scalable generalization, safe deployment, and robust data infrastructure—guiding next steps in embodied intelligence.

Abstract: Vision-Language-Action (VLA) models are driving a revolution in robotics, enabling machines to understand instructions and interact with the physical world. This field is exploding with new models and datasets, making it both exciting and challenging to keep pace with. This survey offers a clear and structured guide to the VLA landscape. We design it to follow the natural learning path of a researcher: we start with the basic Modules of any VLA model, trace the history through key Milestones, and then dive deep into the core Challenges that define recent research frontier. Our main contribution is a detailed breakdown of the five biggest challenges in: (1) Representation, (2) Execution, (3) Generalization, (4) Safety, and (5) Dataset and Evaluation. This structure mirrors the developmental roadmap of a generalist agent: establishing the fundamental perception-action loop, scaling capabilities across diverse embodiments and environments, and finally ensuring trustworthy deployment-all supported by the essential data infrastructure. For each of them, we review existing approaches and highlight future opportunities. We position this paper as both a foundational guide for newcomers and a strategic roadmap for experienced researchers, with the dual aim of accelerating learning and inspiring new ideas in embodied intelligence. A live version of this survey, with continuous updates, is maintained on our \href{https://suyuz1.github.io/Survery/}{project page}.

</details>


### [216] [CarlaNCAP: A Framework for Quantifying the Safety of Vulnerable Road Users in Infrastructure-Assisted Collective Perception Using EuroNCAP Scenarios](https://arxiv.org/abs/2512.11551)
*Jörg Gamerdinger,Sven Teufel,Simon Roller,Oliver Bringmann*

Main category: cs.RO

TL;DR: 本文提出了一种基于基础设施的集体感知（CP）框架，用于提升弱势道路使用者（VRUs）的安全性，并构建了包含11,000帧安全关键场景的CarlaNCAP数据集；仿真结果表明，该方法可将事故率大幅降低，最高实现100%避撞，远优于单车传感器方案的33%。


<details>
  <summary>Details</summary>
Motivation: 弱势道路使用者（VRUs）在城市环境中易因遮挡而发生事故，亟需更可靠的感知技术；基础设施辅助的集体感知（CP）有望缓解遮挡问题，但缺乏面向VRU安全提升的系统性评估与公开数据集。

Method: 提出一个面向VRU安全评估的基础设施辅助CP框架，并构建CarlaNCAP数据集（含EuroNCAP安全关键场景、11k帧），在CARLA仿真平台开展对比实验，评估事故避免率。

Result: 基础设施辅助CP在安全关键场景中事故避免率最高达100%，显著优于仅依赖车载传感器的33%；验证了其对VRU安全性的实质性提升。

Conclusion: 基础设施辅助CP是提升城市环境中VRU安全性的一项有效且可行的技术路径，CarlaNCAP数据集和评估框架为后续研究与政策制定提供了重要支撑。

Abstract: The growing number of road users has significantly increased the risk of accidents in recent years. Vulnerable Road Users (VRUs) are particularly at risk, especially in urban environments where they are often occluded by parked vehicles or buildings. Autonomous Driving (AD) and Collective Perception (CP) are promising solutions to mitigate these risks. In particular, infrastructure-assisted CP, where sensor units are mounted on infrastructure elements such as traffic lights or lamp posts, can help overcome perceptual limitations by providing enhanced points of view, which significantly reduces occlusions. To encourage decision makers to adopt this technology, comprehensive studies and datasets demonstrating safety improvements for VRUs are essential. In this paper, we propose a framework for evaluating the safety improvement by infrastructure-based CP specifically targeted at VRUs including a dataset with safety-critical EuroNCAP scenarios (CarlaNCAP) with 11k frames. Using this dataset, we conduct an in-depth simulation study and demonstrate that infrastructure-assisted CP can significantly reduce accident rates in safety-critical scenarios, achieving up to 100% accident avoidance compared to a vehicle equipped with sensors with only 33%. Code is available at https://github.com/ekut-es/carla_ncap

</details>


### [217] [Cross-Entropy Optimization of Physically Grounded Task and Motion Plans](https://arxiv.org/abs/2512.11571)
*Andreu Matoses Gimenez,Nils Wilde,Chris Pek,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: 本文提出了一种利用GPU并行物理仿真器结合交叉熵优化，直接在真实机器人控制器参数空间中搜索可行、低成本运动规划的TAMP方法，兼顾动力学与接触建模，实现端到端可执行计划。


<details>
  <summary>Details</summary>
Motivation: 传统TAMP算法为提升计算性能或保证完备性/最优性而过度简化模型，导致生成的计划忽略动力学和复杂接触，难以在真实机器人上可靠执行；且忽略底层控制器影响会导致计划不可行或次优。

Method: 采用GPU并行化物理仿真器对含运动控制器的高层计划进行真实感实现评估，通过交叉熵优化在控制器参数（或动作）空间中采样搜索低代价可行解。

Result: 在多个依赖环境几何进行物体操作的任务中成功验证了该方法，生成的计划可直接由真实机器人执行，显著提升了任务成功率与现实可行性。

Conclusion: 将高保真物理仿真与控制器级优化相结合的TAMP框架，能有效弥合理论规划与实际执行之间的鸿沟，为动态、接触密集型操作任务提供更鲁棒、可部署的解决方案。

Abstract: Autonomously performing tasks often requires robots to plan high-level discrete actions and continuous low-level motions to realize them. Previous TAMP algorithms have focused mainly on computational performance, completeness, or optimality by making the problem tractable through simplifications and abstractions. However, this comes at the cost of the resulting plans potentially failing to account for the dynamics or complex contacts necessary to reliably perform the task when object manipulation is required. Additionally, approaches that ignore effects of the low-level controllers may not obtain optimal or feasible plan realizations for the real system. We investigate the use of a GPU-parallelized physics simulator to compute realizations of plans with motion controllers, explicitly accounting for dynamics, and considering contacts with the environment. Using cross-entropy optimization, we sample the parameters of the controllers, or actions, to obtain low-cost solutions. Since our approach uses the same controllers as the real system, the robot can directly execute the computed plans. We demonstrate our approach for a set of tasks where the robot is able to exploit the environment's geometry to move an object. Website and code: https://andreumatoses.github.io/research/parallel-realization

</details>


### [218] [UniBYD: A Unified Framework for Learning Robotic Manipulation Across Embodiments Beyond Imitation of Human Demonstrations](https://arxiv.org/abs/2512.11609)
*Tingyu Yuan,Biaoliang Guan,Wen Ye,Ziyan Tian,Yi Yang,Weijie Zhou,Yan Huang,Peng Wang,Chaoyang Zhao,Jinqiao Wang*

Main category: cs.RO

TL;DR: 本文提出UniBYD框架，通过动态强化学习与统一形态表征（UMR），使机器人手在多样化形态下超越人类示范模仿、实现更优操作策略；引入混合马尔可夫阴影引擎提升早期模仿质量，并构建首个跨形态操作基准UniManip，实验显示成功率较SOTA提升67.90%。


<details>
  <summary>Details</summary>
Motivation: 机器人手与人手之间存在显著的具身差异（embodiment gap），导致从人类演示中学习操作策略效果受限；现有方法仅停留在模仿层面，难以适配不同机器人手的物理特性。

Method: 提出UniBYD统一框架：1）设计统一形态表征（UMR）以支持多形态建模；2）构建带退火奖励调度的动态PPO算法，实现从模仿到自主适应的过渡；3）开发混合马尔可夫式阴影引擎，提升早期细粒度模仿稳定性。同时构建跨形态基准UniManip用于评估。

Result: 在UniManip基准上，UniBYD相较当前最优方法成功率提升67.90%；验证了其在多种机器人手形态下的泛化性与鲁棒性。

Conclusion: UniBYD成功弥合了具身差异带来的学习瓶颈，不仅提升了操作性能，还推动了具身智能中面向多样化硬件的通用策略学习范式发展。

Abstract: In embodied intelligence, the embodiment gap between robotic and human hands brings significant challenges for learning from human demonstrations. Although some studies have attempted to bridge this gap using reinforcement learning, they remain confined to merely reproducing human manipulation, resulting in limited task performance. In this paper, we propose UniBYD, a unified framework that uses a dynamic reinforcement learning algorithm to discover manipulation policies aligned with the robot's physical characteristics. To enable consistent modeling across diverse robotic hand morphologies, UniBYD incorporates a unified morphological representation (UMR). Building on UMR, we design a dynamic PPO with an annealed reward schedule, enabling reinforcement learning to transition from imitation of human demonstrations to explore policies adapted to diverse robotic morphologies better, thereby going beyond mere imitation of human hands. To address the frequent failures of learning human priors in the early training stage, we design a hybrid Markov-based shadow engine that enables reinforcement learning to imitate human manipulations in a fine-grained manner. To evaluate UniBYD comprehensively, we propose UniManip, the first benchmark encompassing robotic manipulation tasks spanning multiple hand morphologies. Experiments demonstrate a 67.90% improvement in success rate over the current state-of-the-art. Upon acceptance of the paper, we will release our code and benchmark at https://github.com/zhanheng-creator/UniBYD.

</details>


### [219] [Architecting Large Action Models for Human-in-the-Loop Intelligent Robots](https://arxiv.org/abs/2512.11620)
*Kanisorn Sangchai,Methasit Boonpun,Withawin Kraipetchara,Paulo Garcia*

Main category: cs.RO

TL;DR: 本文提出了一种通过组合现成基础模型并加入符号化封装与输出验证，构建可控、可解释、可验证的大型动作模型（Large Action Models）的方法，用于智能机器人，避免了大规模端到端训练，提升了可靠性与安全性。


<details>
  <summary>Details</summary>
Motivation: 传统符号AI因计算与内存开销难以扩展；而纯神经方法（如大语言模型）虽能力强，但缺乏控制性、可解释性与可靠性；大型动作模型虽试图整合感知-推理-动作闭环，却仍面临训练成本高与可靠性不足的问题。

Method: 采用模块化设计，组合现成的多模态基础模型，并在其上嵌入符号化封装（如PDDL生成器）与形式化验证机制，实现神经-符号融合；通过人类在环（human-in-the-loop）对PDDL动作规划进行验证，抑制动作幻觉。

Result: 在多模态机器人实验中验证了该方法的有效性：无需海量端到端训练，即可实现可靠的动作执行；PDDL驱动的规划显著降低了动作幻觉；系统具备更高可控性、可解释性与可验证性。

Conclusion: 大型动作模型的智能不依赖于大规模端到端训练，而可通过高效感知模型与逻辑驱动核心的集成实现；神经-符号协同路径为安全、可信的机器人AI提供了可行范式。

Abstract: The realization of intelligent robots, operating autonomously and interacting with other intelligent agents, human or artificial, requires the integration of environment perception, reasoning, and action. Classic Artificial Intelligence techniques for this purpose, focusing on symbolic approaches, have long-ago hit the scalability wall on compute and memory costs. Advances in Large Language Models in the past decade (neural approaches) have resulted in unprecedented displays of capability, at the cost of control, explainability, and interpretability. Large Action Models aim at extending Large Language Models to encompass the full perception, reasoning, and action cycle; however, they typically require substantially more comprehensive training and suffer from the same deficiencies in reliability. Here, we show it is possible to build competent Large Action Models by composing off-the-shelf foundation models, and that their control, interpretability, and explainability can be effected by incorporating symbolic wrappers and associated verification on their outputs, achieving verifiable neuro-symbolic solutions for intelligent robots. Our experiments on a multi-modal robot demonstrate that Large Action Model intelligence does not require massive end-to-end training, but can be achieved by integrating efficient perception models with a logic-driven core. We find that driving action execution through the generation of Planning Domain Definition Language (PDDL) code enables a human-in-the-loop verification stage that effectively mitigates action hallucinations. These results can support practitioners in the design and development of robotic Large Action Models across novel industries, and shed light on the ongoing challenges that must be addressed to ensure safety in the field.

</details>


### [220] [Bench-Push: Benchmarking Pushing-based Navigation and Manipulation Tasks for Mobile Robots](https://arxiv.org/abs/2512.11736)
*Ninghan Zhong,Steven Caro,Megnath Ramesh,Rishi Bhatnagar,Avraiem Iskandar,Stephen L. Smith*

Main category: cs.RO

TL;DR: 本文提出了Bench-Push，首个面向基于推动物体的移动机器人导航与操作任务的统一基准，包含多样化仿真环境、新型评估指标，并开源了模块化Python库。


<details>
  <summary>Details</summary>
Motivation: 传统移动机器人方法禁止与可移动物体交互，难以应对杂乱环境；现有推动研究缺乏统一、可复现的评估标准。

Method: 设计并实现Bench-Push基准，涵盖多类典型推动任务仿真环境（如迷宫导航、冰面船舶导航、箱体递送、区域清理），提出衡量效率、交互努力和部分完成度的新评估指标，并对若干基线方法进行实证评估。

Result: 构建了首个开源、模块化的推动任务基准Bench-Push，支持跨方法公平比较，已发布代码、文档及预训练模型。

Conclusion: Bench-Push填补了推动式移动机器人领域标准化评估的空白，有望推动算法可复现性与性能提升。

Abstract: Mobile robots are increasingly deployed in cluttered environments with movable objects, posing challenges for traditional methods that prohibit interaction. In such settings, the mobile robot must go beyond traditional obstacle avoidance, leveraging pushing or nudging strategies to accomplish its goals. While research in pushing-based robotics is growing, evaluations rely on ad hoc setups, limiting reproducibility and cross-comparison. To address this, we present Bench-Push, the first unified benchmark for pushing-based mobile robot navigation and manipulation tasks. Bench-Push includes multiple components: 1) a comprehensive range of simulated environments that capture the fundamental challenges in pushing-based tasks, including navigating a maze with movable obstacles, autonomous ship navigation in ice-covered waters, box delivery, and area clearing, each with varying levels of complexity; 2) novel evaluation metrics to capture efficiency, interaction effort, and partial task completion; and 3) demonstrations using Bench-Push to evaluate example implementations of established baselines across environments. Bench-Push is open-sourced as a Python library with a modular design. The code, documentation, and trained models can be found at https://github.com/IvanIZ/BenchNPIN.

</details>


### [221] [The Influence of Human-like Appearance on Expected Robot Explanations](https://arxiv.org/abs/2512.11746)
*Hana Kopecka,Jose Such*

Main category: cs.RO

TL;DR: 本研究探讨了机器人外观（尤其是类人程度）如何影响用户对其解释的期望，发现类人外观会增强人类对机器人的拟人化归因，并导致用户更倾向于期待拟人化的解释。


<details>
  <summary>Details</summary>
Motivation: 机器人外观是影响用户心理模型和人机交互的重要因素，但其对用户预期机器人解释的影响尚未被系统研究。

Method: 采用被试间实验设计，向参与者展示三种外观类人程度不同的家用服务机器人图像，并要求他们描述自己期望从这些机器人处获得的相同行为的解释。

Result: 所有条件下，大多数解释均为拟人化；拟人化解释比例与机器人外观类人程度呈正相关；同时观察到非拟人化解释及机器人描述中的细微趋势。

Conclusion: 机器人外观显著影响用户对解释的预期，类人外观会增强拟人化归因，进而塑造用户对机器人‘心智能力’的解释期待。

Abstract: A robot's appearance is a known factor influencing user's mental model and human-robot interaction, that has not been studied in the context of its influence in expected robot explanations. In this study, we investigate whether and to what extent the human-like appearance of robots elicits anthropomorphism, which is conceptualised as an attribution of mental capacities, and how the level of anthropomorphism is revealed in explanations that people expect to receive. We designed a between-subject study comprising conditions with visual stimuli of three domestic service robots with varying human-like appearance, and we prompted respondents to provide explanations they would expect to receive from the robot for the same robot actions. We found that most explanations were anthropomorphic across all conditions. However, there is a positive correlation between the anthropomorphic explanations and human-like appearance. We also report on more nuanced trends observed in non-anthropomorphic explanations and trends in robot descriptions.

</details>


### [222] [BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models](https://arxiv.org/abs/2512.11769)
*Xiaoyu Ma,Zhengqing Yuan,Zheyuan Zhang,Kaiwen Shi,Lichao Sun,Yanfang Ye*

Main category: cs.RO

TL;DR: BLURR is a lightweight inference wrapper for Vision-Language-Action (VLA) models that accelerates control without retraining, using KV caching, mixed precision, and single-step rollout—enabling real-time web demos and efficient robot control on low-end hardware.


<details>
  <summary>Details</summary>
Motivation: Existing VLA models have heavy inference stacks, limiting their use in responsive web demos or high-frequency robot control on commodity GPUs.

Method: BLURR introduces an instruction prefix key-value cache, mixed precision execution, and a single-step rollout schedule—all integrated into existing VLA controllers like pi-zero without modifying checkpoints or observation interfaces.

Result: In SimplerEnv evaluation, BLURR maintains task success rates comparable to the original controller while significantly reducing effective FLOPs and wall-clock latency; it also powers a real-time interactive web demo.

Conclusion: BLURR provides a practical, plug-and-play solution for deploying modern VLA policies under tight compute budgets.

Abstract: Vision-language-action (VLA) models enable impressive zero shot manipulation, but their inference stacks are often too heavy for responsive web demos or high frequency robot control on commodity GPUs. We present BLURR, a lightweight inference wrapper that can be plugged into existing VLA controllers without retraining or changing model checkpoints. Instantiated on the pi-zero VLA controller, BLURR keeps the original observation interfaces and accelerates control by combining an instruction prefix key value cache, mixed precision execution, and a single step rollout schedule that reduces per step computation. In our SimplerEnv based evaluation, BLURR maintains task success rates comparable to the original controller while significantly lowering effective FLOPs and wall clock latency. We also build an interactive web demo that allows users to switch between controllers and toggle inference options in real time while watching manipulation episodes. This highlights BLURR as a practical approach for deploying modern VLA policies under tight compute budgets.

</details>


### [223] [ProbeMDE: Uncertainty-Guided Active Proprioception for Monocular Depth Estimation in Surgical Robotics](https://arxiv.org/abs/2512.11773)
*Britton Jordan,Jordan Thompson,Jesse F. d'Almeida,Hao Li,Nithesh Kumar,Susheela Sharma Stern,Ipek Oguz,Robert J. Webster,Daniel Brown,Alan Kuntz,James Ferguson*

Main category: cs.RO

TL;DR: 本文提出ProbeMDE，一种结合RGB图像与稀疏本体感知测量的代价感知主动感知框架，用于提升单目深度估计在挑战性手术场景中的准确性与不确定性建模能力。


<details>
  <summary>Details</summary>
Motivation: 单目深度估计（MDE）在手术等纹理缺失、镜面反射和遮挡严重的环境中预测不准且不确定性高，需引入可靠先验信息提升鲁棒性。

Method: 利用MDE模型集成预测深度图，以RGB图像和机器人已知位姿下触碰获得的稀疏深度测量为条件；通过集成方差量化不确定性，并计算其对候选触碰位置的梯度；采用Stein变分梯度下降（SVGD）在梯度图上进行采样，避免模式坍缩并选择信息量最大的触碰位置。

Result: 在中心气道阻塞手术仿真环境的仿真与实物实验中，ProbeMDE在标准深度估计指标上优于基线方法，在更少本体感知测量下实现更高精度。

Conclusion: ProbeMDE有效融合视觉与稀疏触觉反馈，实现了代价敏感、不确定性感知驱动的主动深度估计，在微创手术机器人感知中具有实用潜力。

Abstract: Monocular depth estimation (MDE) provides a useful tool for robotic perception, but its predictions are often uncertain and inaccurate in challenging environments such as surgical scenes where textureless surfaces, specular reflections, and occlusions are common. To address this, we propose ProbeMDE, a cost-aware active sensing framework that combines RGB images with sparse proprioceptive measurements for MDE. Our approach utilizes an ensemble of MDE models to predict dense depth maps conditioned on both RGB images and on a sparse set of known depth measurements obtained via proprioception, where the robot has touched the environment in a known configuration. We quantify predictive uncertainty via the ensemble's variance and measure the gradient of the uncertainty with respect to candidate measurement locations. To prevent mode collapse while selecting maximally informative locations to propriocept (touch), we leverage Stein Variational Gradient Descent (SVGD) over this gradient map. We validate our method in both simulated and physical experiments on central airway obstruction surgical phantoms. Our results demonstrate that our approach outperforms baseline methods across standard depth estimation metrics, achieving higher accuracy while minimizing the number of required proprioceptive measurements.

</details>


### [224] [AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis](https://arxiv.org/abs/2512.11797)
*Junjie Ye,Rong Xue,Basile Van Hoorick,Pavel Tokmakov,Muhammad Zubair Irshad,Yue Wang,Vitor Guizilini*

Main category: cs.RO

TL;DR: AnchorDream是一种面向机器人具身智能的世界模型，利用预训练视频扩散模型，通过将扩散过程锚定在机器人运动渲染上，生成高质量、多样化且符合机器人运动学的仿真数据，从而显著提升下游策略学习性能。


<details>
  <summary>Details</summary>
Motivation: 大规模、多样化的机器人演示数据收集困难，真实世界数据获取成本高，仿真器多样性与保真度有限且存在明显仿真到现实差距；现有生成模型要么只改变外观不生成新行为，要么因具身不一致导致动作不合理。

Method: 提出AnchorDream，一种具身感知的世界模型，复用预训练视频扩散模型进行机器人数据合成；通过以机器人运动渲染为条件来锚定扩散过程，防止幻觉，同时合成与机器人运动学一致的物体和环境；仅需少量人类遥操作演示即可扩展生成大规模、多样化、高质量数据集，无需显式环境建模。

Result: 生成的数据使下游策略学习性能显著提升：仿真基准测试中相对提升36.4%，真实世界实验中性能接近翻倍。

Conclusion: 将生成式世界模型扎根于机器人运动，为规模化模仿学习提供了一条实用路径。

Abstract: The collection of large-scale and diverse robot demonstrations remains a major bottleneck for imitation learning, as real-world data acquisition is costly and simulators offer limited diversity and fidelity with pronounced sim-to-real gaps. While generative models present an attractive solution, existing methods often alter only visual appearances without creating new behaviors, or suffer from embodiment inconsistencies that yield implausible motions. To address these limitations, we introduce AnchorDream, an embodiment-aware world model that repurposes pretrained video diffusion models for robot data synthesis. AnchorDream conditions the diffusion process on robot motion renderings, anchoring the embodiment to prevent hallucination while synthesizing objects and environments consistent with the robot's kinematics. Starting from only a handful of human teleoperation demonstrations, our method scales them into large, diverse, high-quality datasets without requiring explicit environment modeling. Experiments show that the generated data leads to consistent improvements in downstream policy learning, with relative gains of 36.4% in simulator benchmarks and nearly double performance in real-world studies. These results suggest that grounding generative world models in robot motion provides a practical path toward scaling imitation learning.

</details>
