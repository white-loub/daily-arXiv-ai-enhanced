<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 68]
- [cs.CL](#cs.CL) [Total: 35]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 63]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.IR](#cs.IR) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出了TeleWorld，一种实时多模态4D世界建模框架，通过生成-重建-引导范式、分层规划（MMPL）与分布匹配蒸馏（DMD），实现视频生成、动态场景重建与长期世界记忆的闭环统一，显著提升长时序一致性、交互性与实时性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽视觉质量高，但在实时交互、长时序一致性及动态场景持久记忆方面存在局限，难以成为实用的世界模型。

Method: 提出TeleWorld框架，包含生成-重建-引导闭环范式；采用基于扩散模型的自回归视频生成器，结合Macro-from-Micro Planning（MMPL）进行分层规划，并引入Distribution Matching Distillation（DMD）提升实时性与效率；统一建模静态场景与动态对象于4D时空表示中。

Result: 在静态与动态世界理解、长时序一致性及实时生成效率方面均取得优异性能，支持低延迟、长视野的交互式世界建模。

Conclusion: TeleWorld推动了世界模型向实用化、可交互、计算友好的方向发展，为多模态生成与具身智能提供了可行路径。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [2] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 本文提出了一种通过噪声优化来提升文本到图像生成多样性的新方法，有效缓解了模式坍塌问题，同时保持了生成质量。


<details>
  <summary>Details</summary>
Motivation: 当代文本到图像模型存在显著的模式坍塌现象，即相同文本提示下生成图像多样性不足。

Method: 提出一种简单的噪声优化目标函数，并分析噪声的频率特性，探索不同频率分布的噪声初始化对优化和搜索的影响。

Result: 实验表明，该噪声优化方法在生成质量和多样性方面均优于现有方法。

Conclusion: 噪声优化是一种有效缓解模式坍塌、提升生成多样性的可行路径，且不损害原始模型保真度。

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [3] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: 本文提出了Spatial4D-Bench，一个大规模、多任务的4D空间智能评测基准，用于系统评估多模态大语言模型（MLLMs）在时空推理方面的能力，并揭示了当前模型在路径规划、动作识别和物理合理性推理等方面的显著不足。


<details>
  <summary>Details</summary>
Motivation: 探究多模态大语言模型（MLLMs）能否达到人类水平的4D空间智能，而现有基准存在规模小、多样性不足等问题。

Method: 构建了包含约4万问答对、覆盖18项任务的Spatial4D-Bench基准，将任务系统归类为六大认知类别，并对多种开源与闭源MLLM进行评测。

Result: 实验表明当前主流MLLM在多种4D空间推理任务（如路径规划、动作识别、物理合理性推理）上存在显著局限性。

Conclusion: Spatial4D-Bench为评估和推动MLLM的空间认知能力提供了结构化、全面的工具，有助于促进向人类水平4D空间智能的发展。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [4] [A Spatially Masked Adaptive Gated Network for multimodal post-flood water extent mapping using SAR and incomplete multispectral data](https://arxiv.org/abs/2601.00123)
*Hyunho Lee,Wenwen Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为SMAGNet的多模态深度学习模型，用于洪水后水体范围制图，通过自适应融合SAR（主输入）与MSI数据，在MSI数据部分或完全缺失时仍保持高性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在洪水响应阶段依赖SAR数据，但当及时获取的灾后MSI影像有限时，如何自适应地融合部分可用MSI数据以提升水体制图精度尚缺乏研究。

Method: 提出空间掩码自适应门控网络（SMAGNet），以SAR数据为主输入，通过特征融合机制自适应引入MSI数据；在C2S-MS Floods数据集上进行实验验证。

Result: SMAGNet在不同MSI数据可用性条件下均优于其他多模态模型；即使MSI数据完全缺失，其性能仍与纯SAR训练的U-Net统计相当。

Conclusion: SMAGNet提升了模型对缺失数据的鲁棒性，增强了多模态深度学习在真实洪水管理场景中的实用性。

Abstract: Mapping water extent during a flood event is essential for effective disaster management throughout all phases: mitigation, preparedness, response, and recovery. In particular, during the response stage, when timely and accurate information is important, Synthetic Aperture Radar (SAR) data are primarily employed to produce water extent maps. Recently, leveraging the complementary characteristics of SAR and MSI data through a multimodal approach has emerged as a promising strategy for advancing water extent mapping using deep learning models. This approach is particularly beneficial when timely post-flood observations, acquired during or shortly after the flood peak, are limited, as it enables the use of all available imagery for more accurate post-flood water extent mapping. However, the adaptive integration of partially available MSI data into the SAR-based post-flood water extent mapping process remains underexplored. To bridge this research gap, we propose the Spatially Masked Adaptive Gated Network (SMAGNet), a multimodal deep learning model that utilizes SAR data as the primary input for post-flood water extent mapping and integrates complementary MSI data through feature fusion. In experiments on the C2S-MS Floods dataset, SMAGNet consistently outperformed other multimodal deep learning models in prediction performance across varying levels of MSI data availability. Furthermore, we found that even when MSI data were completely missing, the performance of SMAGNet remained statistically comparable to that of a U-Net model trained solely on SAR data. These findings indicate that SMAGNet enhances the model robustness to missing data as well as the applicability of multimodal deep learning in real-world flood management scenarios.

</details>


### [5] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: 本文提出了一种名为Compressed Map Priors (CMP)的框架，利用历史行驶数据学习空间先验，以提升自动驾驶视觉系统在已知区域的3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶视觉系统通常忽略历史行驶数据，将每个位置视为首次访问，而实际上大多数部署区域已被多次经过；因此，利用历史轨迹构建空间先验可提升感知性能。

Method: 提出Compressed Map Priors（CMP），采用二值化哈希表存储空间先验，仅需32KB/km²，压缩率达20倍；该先验可无缝嵌入主流3D感知系统，计算开销极小。

Result: 在nuScenes数据集上，CMP显著且一致地提升了多种3D检测架构的性能。

Conclusion: 利用轻量级、可压缩的空间先验（CMP）能有效增强已有3D感知系统，无需大幅增加计算负担，为实际部署提供了实用且高效的改进路径。

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [6] [Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection](https://arxiv.org/abs/2601.00141)
*Lawrence Han*

Main category: cs.CV

TL;DR: 本文提出GLASS架构，通过全局缩放视图与多尺度局部裁剪结合，利用分层空间采样和注意力机制聚合原始分辨率细节，在不显著增加计算开销下提升AI生成图像检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测方法通常先对图像降采样，导致细粒度纹理等关键判别信息丢失，影响检测精度。

Method: 提出GLASS（Global-Local Attention with Stratified Sampling）架构：1）输入图像保留原始分辨率；2）生成一个全局缩放视图 + 多个空间分层随机采样的高分辨率局部区域；3）用注意力机制对局部区域加权聚合；4）适配ViT、ResNet、ConvNeXt等多种视觉骨干网络。

Result: 在多个数据集上，GLASS显著优于标准迁移学习基线，在保持可行计算成本前提下获得更高检测准确率。

Conclusion: 融合全局结构与原始分辨率局部细节，并通过注意力机制自适应融合，是提升AI生成图像检测鲁棒性和精度的有效范式；GLASS具有模型无关性和尺度不变性，具备良好泛化能力。

Abstract: The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.

</details>


### [7] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: 本文提出了FCMBench-V1.0，一个面向金融信贷场景的大规模多模态基准，涵盖18类核心证件、4043张隐私合规图像和8446个问答样本，从感知、推理与鲁棒性三方面评估模型，并在23个SOTA视觉语言模型上进行了测试，验证了其有效性与挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有通用多模态基准无法满足金融信贷领域对文档特异性、信用理解深度、真实鲁棒性及隐私合规性的综合需求，亟需构建专用基准。

Method: 提出FCMBench-V1.0基准，采用闭源合成-实拍流水线生成隐私合规数据；设计三维度评估框架（感知、信用推理、鲁棒性），覆盖3类基础感知任务、4类决策导向的信用推理任务及10类真实采集失真类型。

Result: 在23个SOTA视觉语言模型上评测显示：Gemini 3 Pro（64.61 F1）、Qwen3-VL-235B（57.27 F1）和专为金融设计的Qfin-VL-Instruct（64.92 F1）分别取得最佳商业模型、开源基线与整体性能；所有模型在各类采集失真下均显著下降。

Conclusion: FCMBench-V1.0填补了金融信贷多模态评估空白，兼具现实性、合规性与挑战性，可有效区分模型能力差异，揭示当前VLMs在真实金融场景中的关键短板。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [8] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics 是一个端到端可微框架，通过自然语言提示自动推断3D场景中物体的合理物理参数，无需真实轨迹或标注视频监督，结合多模态大模型与可学习运动蒸馏损失，实现高质量、物理合理的动态仿真。


<details>
  <summary>Details</summary>
Motivation: 传统3D物理仿真依赖专家调参，耗时且门槛高；亟需一种能从自然语言描述中自动获取合理物理参数的方法。

Method: 1）利用多模态大语言模型根据文本提示估计材料参数（约束在合理范围内）；2）设计可学习的运动蒸馏损失，从预训练视频扩散模型中提取鲁棒运动先验，同时抑制外观与几何偏差对仿真的干扰。

Result: 在30+种场景（含真实、人工设计及AI生成3D物体）和多种材料（弹性体、金属、泡沫、沙子、牛顿/非牛顿流体）上验证有效；生成的动态仿真视觉真实、物理合理，性能超越现有方法。

Conclusion: MotionPhysics 成功实现了自然语言驱动的、无需真值监督的物理参数自动推理与仿真，为降低物理仿真门槛提供了新范式。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [9] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 本文提出FaceFocalDesc任务，即对任意选定的面部区域生成并识别包含面部动作单元（AU）、情绪状态和年龄估计的多属性自然语言描述；构建了首个面向任意面部区域的多属性描述数据集，并提出基于Qwen2.5-VL微调的Focal-RegionFace模型，通过多阶段渐进式微调提升局部特征聚焦能力，在新基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有面部分析方法缺乏对任意局部区域的细粒度、多属性（AU、情绪、年龄）联合建模与自然语言描述能力，限制了可解释性与可控性。

Method: 构建面向任意面部区域的多属性自然语言描述数据集；提出Focal-RegionFace模型，基于Qwen2.5-VL进行多阶段渐进式微调，增强对局部面部特征的聚焦与解析能力。

Result: 在新构建的基准上，Focal-RegionFace在传统指标（如BLEU、CIDEr）及新提指标上均达到最优性能，验证了其在细粒度区域聚焦分析中的有效性与通用性。

Conclusion: FaceFocalDesc是一项具有挑战性且实用的新任务；所提数据集与Focal-RegionFace模型为可解释、可控的细粒度面部状态分析提供了新范式。

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [10] [DichroGAN: Towards Restoration of in-air Colours of Seafloor from Satellite Imagery](https://arxiv.org/abs/2601.00194)
*Salma Gonzalez-Sabbagh,Antonio Robles-Kelly,Shang Gao*

Main category: cs.CV

TL;DR: 本文提出DichroGAN，一种用于从卫星图像中恢复海底真实颜色的条件生成对抗网络，通过两阶段联合训练估计漫反射与镜面反射，并结合水下光传输模型，有效消除水体对光的吸收和散射影响。


<details>
  <summary>Details</summary>
Motivation: 由于水体中光随深度呈指数衰减，从卫星影像中准确恢复海底在空气中的真实颜色极具挑战性。

Method: 提出DichroGAN，一种基于条件生成对抗网络（cGAN）的方法；采用两步同步训练策略：前两个生成器利用高光谱图像立方体估计漫反射和镜面反射以获取大气场景辐射度；后两个生成器分别处理生成的场景辐射度和估计水下光传输，依据水下成像方程联合恢复海底颜色。训练数据来自PRISMA卫星影像构建的紧凑RGB-光谱带-掩码配对数据集。

Result: 在卫星与水下数据集上的大量实验表明，DichroGAN性能优于当前主流水下图像复原方法。

Conclusion: DichroGAN为遥感驱动的海底颜色复原提供了新思路，验证了基于物理建模与深度学习融合方法在复杂水下成像任务中的有效性与潜力。

Abstract: Recovering the in-air colours of seafloor from satellite imagery is a challenging task due to the exponential attenuation of light with depth in the water column. In this study, we present DichroGAN, a conditional generative adversarial network (cGAN) designed for this purpose. DichroGAN employs a two-steps simultaneous training: first, two generators utilise a hyperspectral image cube to estimate diffuse and specular reflections, thereby obtaining atmospheric scene radiance. Next, a third generator receives as input the generated scene radiance containing the features of each spectral band, while a fourth generator estimates the underwater light transmission. These generators work together to remove the effects of light absorption and scattering, restoring the in-air colours of seafloor based on the underwater image formation equation. DichroGAN is trained on a compact dataset derived from PRISMA satellite imagery, comprising RGB images paired with their corresponding spectral bands and masks. Extensive experiments on both satellite and underwater datasets demonstrate that DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques.

</details>


### [11] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的3D形变框架MorphAny3D，利用结构化潜在表示（SLAT）和新设计的注意力机制（MCA与TFSA），实现跨类别、语义一致且时间平滑的高质量3D形变。


<details>
  <summary>Details</summary>
Motivation: 现有3D形变方法难以在跨类别场景下同时保证语义一致性与时间平滑性。

Method: 提出MorphAny3D框架，核心包括：1）基于SLAT表示的无训练形变；2）Morphing Cross-Attention（MCA）融合源/目标结构信息；3）Temporal-Fused Self-Attention（TFSA）引入前序帧增强时序一致性；4）姿态校正策略缓解形变过程中的朝向模糊。

Result: 在多种跨类别形变任务上达到SOTA效果，并支持解耦形变、3D风格迁移等拓展应用，且可泛化至其他SLAT生成模型。

Conclusion: MorphAny3D验证了无需训练、仅靠结构化潜在空间与注意力机制设计即可实现高质量3D形变的可行性，为通用3D生成编辑提供了新范式。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [12] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 本文提出了一种基于多视角2D图像与神经辐射场（NeRF）的3D实例分割作物计数框架，通过引入可见性与掩码一致性评分，实现高精度、无需作物特异性调参的精确计数，并在棉花铃、苹果和梨数据集上验证了其鲁棒性与先进性。


<details>
  <summary>Details</summary>
Motivation: 户外农田中作物常存在部分遮挡和簇生导致的视觉歧义，使传统2D图像分割方法难以准确计数。

Method: 利用多视角2D图像训练NeRF模型，生成3D场景表示；设计作物可见性分数和掩码一致性分数，结合NeRF提供的3D信息进行3D实例分割，从而实现精确计数。

Result: 在棉花铃、苹果、梨三个农业数据集上取得一致且高精度的计数结果，优于现有最先进方法；无需针对不同作物调整参数；并开源了一个新的棉花植株数据集。

Conclusion: 该框架通过融合多视角几何与学习型3D重建，有效克服了2D方法在复杂农田场景下的局限性，为通用、鲁棒的作物计数提供了新范式。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [13] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: 本文提出IntraStyler方法，通过示例图像引导的风格合成与对比学习驱动的风格编码器，无需先验知识即可捕捉目标域内多样风格，提升跨模态无监督域自适应分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域自适应方法主要关注源域与目标域间的域偏移，而忽视了目标域内部的风格多样性；预设域内变化的方式不切实际，需更灵活的风格多样化策略。

Method: 提出基于示例的风格合成方法IntraStyler：利用示例图像指导风格生成，并设计基于对比学习的风格编码器以提取纯风格特征。

Result: 在CrossMoDA 2023数据集上验证了IntraStyler在可控风格合成和下游分割任务中的有效性，生成的多样化合成数据显著提升分割性能。

Conclusion: IntraStyler无需先验知识即可实现目标域内风格多样性建模，为图像级域对齐提供了新思路，有效缓解域内变异不足问题。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [14] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 本文提出了一种基于奖励驱动的强化学习方法，用于提升多模态大语言模型（MLLMs）在视觉推理任务中的表现，尤其解决其视觉信息整合不足的问题；通过设计多种面向推理不同方面的奖励函数，并采用GRPO算法，显著提升了Qwen-2.5-VL-7B在视觉谜题等任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在生成推理链时往往未能有效整合视觉信息，导致在需精准视觉感知的任务（如视觉谜题）中表现受限；实验证明视觉感知是关键瓶颈。

Method: 采用奖励驱动的强化学习框架，设计六种针对图像理解、推理步骤和答案准确性等不同方面的奖励函数，并利用Group Relative Policy Optimization（GRPO）算法优化策略，显式鼓励更长、结构化的视觉推理并防止跳过视觉信息。

Result: 在Qwen-2.5-VL-7B上实现5.56%的性能提升，且在领域内与跨领域设置下均保持稳定增益；将图像转为文本描述可使Claude 3.5和3.7分别提升26.7%和23.6%。

Conclusion: 奖励驱动的RL是一种无需昂贵监督即可解锁开源MLLM长视觉推理能力的有效途径，关键在于合理设计奖励函数以引导模型深度融合视觉与语言推理。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [15] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: 本文提出LooC方法，通过低维组合式向量量化，在保持小码本的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度增加，需要高容量但更紧凑的向量量化（VQ）方法。

Method: LooC采用低维组合式码本设计，将码向量视为特征向量中的低维组成单元进行组合；引入无参插值外推机制增强特征平滑性；支持即插即用。

Result: 在多个任务、数据集和架构上显著优于现有VQ方法，以更小码本实现SOTA性能，并实现全码本利用、避免坍缩。

Conclusion: LooC成功协调了VQ中容量与紧凑性的矛盾，是一种高效、通用且鲁棒的向量量化新范式。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [16] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 本文提出SynDR-IQA框架，通过重塑合成数据分布（增强多样性+降低冗余簇密度）来提升盲图像质量评估（BIQA）模型在跨数据集场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于合成数据训练的BIQA模型泛化能力差，主因是合成数据分布导致特征表示呈离散聚类模式，而非模型结构问题。

Method: 提出SynDR-IQA框架：1）分布感知的多样化内容上采样（提升视觉多样性，保持内容分布）；2）密度感知的冗余簇下采样（降低高密度聚类区域样本密度）。理论依据为样本多样性和冗余性对泛化误差的影响。

Result: 在三种跨数据集设置（合成→真实、合成→算法生成、合成→合成）下均显著提升BIQA模型泛化性能。

Conclusion: 重塑合成数据分布是提升BIQA泛化能力的关键，SynDR-IQA为合成数据驱动的视觉评估任务提供了新思路。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [17] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 本文提出了一种结合CycleGAN与YOLOv8的跨模态数据增强框架，通过无配对图像翻译生成高质量伪红外PCB图像，缓解红外数据稀缺问题，并提升YOLOv8在少量真实红外数据下的缺陷检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决红外（IR）数据在PCB缺陷检测中严重稀缺的问题，制约了红外图像检测模型的训练与性能。

Method: 采用CycleGAN进行无配对可见光到红外图像翻译，生成保留缺陷结构语义并模拟热分布的伪红外图像；再将生成数据与少量真实红外数据融合，联合训练轻量级YOLOv8检测器。

Result: 所提方法显著提升了低数据条件下的特征学习能力，增强后的检测器性能远超仅用少量真实红外数据训练的模型，并接近全监督训练的基准水平。

Conclusion: 伪红外图像合成是一种有效且鲁棒的跨模态数据增强策略，适用于工业红外检测等小样本场景。

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [18] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级框架，用于在低资源设备（如手机和无人机）上进行害虫检测与农药推荐，结合轻量CNN与原型元学习实现小样本识别，并融合环境因素提供生态友好型农药建议。


<details>
  <summary>Details</summary>
Motivation: 传统害虫管理依赖人工巡查和化学农药，存在成本高、耗时长、劳动密集及环境污染等问题，亟需面向小农户的低成本、可持续解决方案。

Method: 构建包含害虫检测模块（轻量CNN+原型元学习）和农药推荐模块（融合作物类型、生长阶段等环境因素）的轻量级框架；基于多源公开数据集构建多样化害虫图像数据集用于训练与评估。

Result: 所提轻量CNN在精度上媲美SOTA模型，同时显著降低计算复杂度；决策支持系统可减少对化学农药的依赖，支持实时精准农业应用。

Conclusion: 该框架适用于资源受限场景，为小农户提供高效、环保、可部署的智能害虫管理工具，推动可持续农业实践。

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [19] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: 本文提出TotalFM，一种基于器官分离概念的放射学基础模型，通过自监督预训练和对比学习，在14万CT序列数据上高效学习3D-CT图像与临床报告文本的对应关系，在零样本病变分类和报告生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决在3D-CT体积数据上训练放射学基础模型时面临的高计算成本问题，并提升模型在真实临床场景中的泛化能力。

Method: 利用分割技术与大语言模型（LLM）自动构建器官体积-报告句子对；结合VideoMAE自监督预训练与体积-文本对比学习进行联合优化；采用器官分离的学习框架。

Result: 在零样本器官级病变分类中，83%器官F1高于CT-CLIP，64%高于Merlin；在零样本发现级分类中，83%类别AUROC优于Merlin；在放射报告生成任务中性能媲美现有视觉-语言模型。

Conclusion: 器官分离的学习框架是一种切实可行且高效的设计范式，适用于3D-CT基础模型的实际部署。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [20] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: 本文提出了S1-MMAlign，一个大规模、多学科的科学图像-文本对数据集，并设计了基于Qwen-VL的语义增强流程以提升图文对齐质量，显著改善了科学多模态学习的数据基础。


<details>
  <summary>Details</summary>
Motivation: 科学图像与稀疏文本描述之间存在巨大语义鸿沟，限制了多模态学习在科学发现中的应用。

Method: 构建包含1550万高质量图像-文本对的S1-MMAlign数据集，并利用Qwen-VL系列模型结合论文摘要和引用上下文进行图像重标注，形成AI-ready语义增强流水线。

Result: 语义增强后，SciBERT伪困惑度下降表明语义歧义减少，CLIP图文匹配得分提升18.21%。

Conclusion: S1-MMAlign为AI for Science提供了关键多模态基础设施，推动科学推理与跨模态理解发展。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [21] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的激活擦除方法ActErase，通过分析提示词对的激活差异区域，动态替换输入激活，实现高效、轻量且鲁棒的概念擦除（如裸露、艺术风格、物体），在保持生成能力的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法依赖数据密集和计算昂贵的微调，限制了其实际应用；而扩散模型激活中仅少量成分表征目标概念，为训练-free擦除提供了可能。

Method: 提出训练-free的ActErase方法：基于prompt-pair分析识别激活差异区域，提取目标概念相关激活，并在前向传播中动态替换输入激活。

Result: 在裸露、艺术风格和物体擦除三个任务上达到SOTA擦除效果，同时较好保留模型整体生成能力，并展现出强对抗鲁棒性。

Conclusion: ActErase建立了一种即插即用、轻量高效且鲁棒的概念操纵新范式，为扩散模型的安全与可控生成提供了实用解决方案。

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [22] [FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering](https://arxiv.org/abs/2601.00269)
*Chaodong Tong,Qi Zhang,Chen Li,Lei Jiang,Yanbing Liu*

Main category: cs.CV

TL;DR: 本文提出FaithSCAN，一种轻量级网络，通过利用视觉语言模型（VLM）内部的多种信号（如词元级解码不确定性、中间视觉表征和跨模态对齐特征）来检测VQA中的忠实性幻觉，避免依赖外部模型或重复采样，并采用LLM-as-a-Judge范式自动生成监督信号，实验证明其在有效性与效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VQA幻觉检测方法存在计算开销大、依赖外部资源质量、或仅捕获有限不确定性等固有缺陷，难以兼顾效率、鲁棒性与检测性能。

Method: 提出FaithSCAN：1）融合词元级解码不确定性、中间视觉表征和跨模态对齐特征；2）采用分支式证据编码与不确定性感知注意力进行信号融合；3）扩展LLM-as-a-Judge范式，设计低成本策略自动生成模型依赖的监督信号以实现无须人工标注的监督训练。

Result: 在多个VQA基准上显著优于现有方法；深入分析揭示幻觉源于视觉感知、跨模态推理和语言解码中系统性的内部状态变化；不同内部信号提供互补诊断线索，且幻觉模式随VLM架构而异。

Conclusion: FaithSCAN通过挖掘VLM丰富的内部信号实现高效、鲁棒、高精度的幻觉检测，为理解多模态幻觉成因提供了新视角，并推动了无需人工标注的自动化检测范式发展。

Abstract: Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.

</details>


### [23] [Disentangling Hardness from Noise: An Uncertainty-Driven Model-Agnostic Framework for Long-Tailed Remote Sensing Classification](https://arxiv.org/abs/2601.00278)
*Chi Ding,Junxiao Xue,Xinyi Yin,Shi Chen,Yunyun Shi,Yiduo Wang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: 本文提出了一种基于证据深度学习的不确定性感知框架DUAL，用于解决遥感图像中长尾分布下的硬尾样本与噪声模糊样本的区分问题。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中目标分布天然存在长尾现象，但现有方法难以区分难学的尾部样本和含噪声的模糊样本，易导致对噪声过拟合。

Method: 基于证据深度学习，将预测不确定性解耦为认知不确定性（EU）和偶然不确定性（AU）：EU指示样本稀缺性，用于重加权难学尾部样本；AU量化数据模糊性，指导自适应标签平滑以抑制噪声影响。

Result: 在多个数据集和不同骨干网络上验证了DUAL的有效性和泛化能力，性能超越TGN、SADE等强基线；消融实验揭示了关键设计选择的重要性。

Conclusion: DUAL是一种模型无关、不确定性驱动的长尾学习框架，能有效解耦并分别利用两类不确定性，提升遥感长尾分类鲁棒性。

Abstract: Long-Tailed distributions are pervasive in remote sensing due to the inherently imbalanced occurrence of grounded objects. However, a critical challenge remains largely overlooked, i.e., disentangling hard tail data samples from noisy ambiguous ones. Conventional methods often indiscriminately emphasize all low-confidence samples, leading to overfitting on noisy data. To bridge this gap, building upon Evidential Deep Learning, we propose a model-agnostic uncertainty-aware framework termed DUAL, which dynamically disentangles prediction uncertainty into Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU). Specifically, we introduce EU as an indicator of sample scarcity to guide a reweighting strategy for hard-to-learn tail samples, while leveraging AU to quantify data ambiguity, employing an adaptive label smoothing mechanism to suppress the impact of noise. Extensive experiments on multiple datasets across various backbones demonstrate the effectiveness and generalization of our framework, surpassing strong baselines such as TGN and SADE. Ablation studies provide further insights into the crucial choices of our design.

</details>


### [24] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: 本文提出了SV-GS框架，用于在稀疏时空观测下实现动态目标的三维重建，通过骨架驱动的变形场建模运动与形变，并支持以生成先验替代初始静态重建，显著提升实际场景适用性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中动态重建面临观测在时间和视角上均稀疏的挑战，传统方法依赖密集多视角视频，在真实环境中难以满足。

Method: 提出SV-GS框架，结合粗粒度骨架关节姿态估计器（时变）与细粒度形变模块，构建骨架驱动的变形场；利用初始骨架图和静态重建初始化，并可扩展为扩散模型生成先验。

Result: 在合成数据上PSNR比现有方法最高提升34%；在真实数据上仅用极少帧即达到与密集单目视频方法相当性能；验证了生成先验替代初始重建的有效性。

Conclusion: SV-GS实现了稀疏条件下的高质量动态重建，兼顾运动平滑性与几何细节保真度，且降低对先验输入的依赖，提升了实用性。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [25] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 本文提出了一种基于Swin Transformer的深度学习模型，用于皮肤病变分类，在ISIC2019数据集上达到87.71%准确率，旨在辅助临床诊断与患者自评。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病日益普遍而皮肤科医生资源有限，亟需智能工具支持及时准确的诊断。

Method: 采用基于Swin Transformer的深度学习模型，利用公开皮肤疾病图像数据集进行预训练，优化模型结构、数据预处理流程及针对性数据增强技术。

Result: 在ISIC2019数据集八个皮肤病变类别上达到87.71%的预测准确率。

Conclusion: 该模型具备作为临床诊断辅助工具和患者自我评估工具的应用潜力。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [26] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: 本文提出DVEFormer，一种基于RGB-D的高效Transformer模型，通过知识蒸馏学习像素级文本对齐视觉嵌入（DVE），支持语义分割、自然语言查询和3D建图，实现实时性能（最高77 FPS）并适用于移动机器人。


<details>
  <summary>Details</summary>
Motivation: 家庭环境中机器人需全面理解环境以与非专业人类直观交互，传统固定类别语义分割灵活性不足，亟需支持文本查询与3D建图的统一表征方法。

Method: 提出DVEFormer模型，采用RGB-D输入的Transformer架构，通过知识蒸馏利用Alpha-CLIP教师模型生成的文本对齐嵌入，训练轻量学生模型输出密集DVE；支持线性探针实现语义分割，并拓展至文本查询与3D映射。

Result: 在室内数据集上达到有竞争力的性能，全模型26.3 FPS、小模型77.0 FPS（NVIDIA Jetson AGX Orin）；支持高质量语义分割、自然语言查询及三维地图构建，具备实际应用潜力。

Conclusion: DVEFormer可作为传统分割方法的即插即用替代方案，在满足实时性的同时，统一支持语义理解、语言交互与三维感知，推动服务机器人实用化。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [27] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor 是一种基于草图的视频着色模型，支持异构、可变数量的参考图像（如角色设定图、背景图等），通过显式区域分配、额外潜变量帧拼接、时空对应掩码注意力和模态分离 RoPE 索引，提升色彩保真度、身份一致性和时序稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有着色模型通常仅依赖单帧参考（如首帧），忽略了角色设定图、背景图或任意已着色帧等多源条件信息，导致颜色泄漏与身份混淆。

Method: TimeColor 将各类参考图像编码为额外潜变量帧并按时间维度拼接；引入显式每参考区域分配机制；采用时空对应掩码注意力增强主体-参考绑定；结合模态分离的 RoPE 索引避免模态混淆。

Result: 在 SAKUGA-42M 数据集上，TimeColor 在单参考与多参考设置下均优于基线方法，显著提升色彩保真度、身份一致性与时间稳定性。

Conclusion: 支持异构多参考的显式建模能有效缓解扩散模型中的快捷学习与跨身份调色板泄漏问题，为视频着色提供了更鲁棒、可控的条件生成范式。

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [28] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: 本文提出VisNet，一种计算高效且有效的行人重识别模型，通过多尺度特征融合、语义聚类与解剖分区、动态权重平均及FIDI损失函数等创新，在保持高精度的同时显著降低计算开销，适用于资源受限的实时场景。


<details>
  <summary>Details</summary>
Motivation: 现有最先进方法虽精度高，但计算成本过高，难以满足监控和移动应用中对高精度与低计算开销的双重需求。

Method: 提出VisNet模型，包含：1）无需并行路径的ResNet50多阶段（1–4）多尺度特征融合并辅以自动注意力；2）基于规则伪标签的语义聚类与人体解剖分区以引入空间约束；3）动态权重平均平衡分类与语义正则化；4）采用FIDI损失函数提升度量学习效果。

Result: 在Market-1501数据集上达到87.05% Rank-1准确率和77.65% mAP，参数量32.41M，计算量4.601 GFLOPs。

Conclusion: VisNet在精度与效率间取得良好平衡，为资源受限场景（如监控与移动端）提供了实用、可部署的行人重识别解决方案。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [29] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM是一种鲁棒的高斯泼溅SLAM框架，通过无需训练的对应点到高斯初始化替代原有残差驱动的稠密化过程，提升重建质量与收敛速度。


<details>
  <summary>Details</summary>
Motivation: 解决GS-SLAM中残差驱动的渐进式高斯稠密化导致早期建图不稳定、收敛慢、纹理丰富或杂乱场景下渲染保真度低的问题。

Method: 提出训练无关的对应点到高斯初始化：利用DINOv3描述子提取密集多视角对应点，并经置信度感知内点分类器优化，再进行单次三角化生成结构感知、分布良好的高斯种子，作为后续优化初始值。

Result: 在TUM RGB-D和Replica数据集上，定位与重建精度达到或超越当前最优高斯及点云SLAM方法；收敛速度提升约20%，实时建图达925 FPS，且完全兼容现有GS-SLAM流程。

Conclusion: RGS-SLAM通过更优的初始化策略显著提升了高斯泼溅SLAM的鲁棒性、效率与重建质量，尤其适用于复杂真实场景。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [30] [ReMA: A Training-Free Plug-and-Play Mixing Augmentation for Video Behavior Recognition](https://arxiv.org/abs/2601.00311)
*Feng-Qi Cui,Jinyang Huang,Sirui Zhao,Jinglong Guo,Qifan Cai,Xin Yan,Zhi Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Representation-aware Mixing Augmentation（ReMA）的视频数据增强方法，通过可控的混合策略，在增强表征多样性的同时保持类条件稳定性，从而提升视频行为识别的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据增强方法多为扰动驱动，易引入不可控变化，削弱类内分布结构并导致表征漂移，尤其在不同时间尺度上效果不一致。

Method: ReMA包含两个机制：1）表征对齐机制（RAM），在分布对齐约束下进行结构化类内混合，抑制无关漂移；2）动态选择机制（DSM），生成运动感知的时空掩码，将扰动引导至判别性弱的区域，增强时序一致性。

Result: 在多个视频行为识别基准上，ReMA显著提升了模型在不同时空粒度下的泛化性与鲁棒性，且无需额外监督或可训练参数。

Conclusion: ReMA是一种即插即用、无参数、高鲁棒性的视频增强策略，有效缓解了传统扰动式增强带来的表征不稳定问题。

Abstract: Video behavior recognition demands stable and discriminative representations under complex spatiotemporal variations. However, prevailing data augmentation strategies for videos remain largely perturbation-driven, often introducing uncontrolled variations that amplify non-discriminative factors, which finally weaken intra-class distributional structure and representation drift with inconsistent gains across temporal scales. To address these problems, we propose Representation-aware Mixing Augmentation (ReMA), a plug-and-play augmentation strategy that formulates mixing as a controlled replacement process to expand representations while preserving class-conditional stability. ReMA integrates two complementary mechanisms. Firstly, the Representation Alignment Mechanism (RAM) performs structured intra-class mixing under distributional alignment constraints, suppressing irrelevant intra-class drift while enhancing statistical reliability. Then, the Dynamic Selection Mechanism (DSM) generates motion-aware spatiotemporal masks to localize perturbations, guiding them away from discrimination-sensitive regions and promoting temporal coherence. By jointly controlling how and where mixing is applied, ReMA improves representation robustness without additional supervision or trainable parameters. Extensive experiments on diverse video behavior benchmarks demonstrate that ReMA consistently enhances generalization and robustness across different spatiotemporal granularities.

</details>


### [31] [Depth-Synergized Mamba Meets Memory Experts for All-Day Image Reflection Separation](https://arxiv.org/abs/2601.00322)
*Siyan Fang,Long Peng,Yuntao Wang,Ruonan Wei,Yuehuan Wang*

Main category: cs.CV

TL;DR: 本文提出DMDNet，通过深度感知扫描、深度协同状态空间模型和记忆专家补偿模块，有效解决夜间图像反射分离中因对比度相似导致的层混淆问题，并构建了NightIRS数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖单张图像信息，在白天和夜间（尤其是夜间）当透射层与反射层对比度相似时容易混淆两层，亟需更鲁棒的分离方法。

Method: 提出Depth-Memory Decoupling Network（DMDNet），包含三个核心组件：1）Depth-Aware Scanning（DAScan）引导Mamba关注显著结构；2）Depth-Synergized State-Space Model（DS-SSM）依据深度调制状态激活敏感性以抑制模糊特征传播；3）Memory Expert Compensation Module（MECM）利用跨图像历史知识进行层特异性补偿。同时构建NightIRS夜间数据集。

Result: DMDNet在白天和夜间图像反射分离任务上均显著优于现有最先进方法。

Conclusion: DMDNet通过深度融合感知、状态空间建模与历史记忆机制，有效提升了反射分离鲁棒性，尤其在挑战性更大的夜间场景下表现突出，验证了多维度先验协同建模的有效性。

Abstract: Image reflection separation aims to disentangle the transmission layer and the reflection layer from a blended image. Existing methods rely on limited information from a single image, tending to confuse the two layers when their contrasts are similar, a challenge more severe at night. To address this issue, we propose the Depth-Memory Decoupling Network (DMDNet). It employs the Depth-Aware Scanning (DAScan) to guide Mamba toward salient structures, promoting information flow along semantic coherence to construct stable states. Working in synergy with DAScan, the Depth-Synergized State-Space Model (DS-SSM) modulates the sensitivity of state activations by depth, suppressing the spread of ambiguous features that interfere with layer disentanglement. Furthermore, we introduce the Memory Expert Compensation Module (MECM), leveraging cross-image historical knowledge to guide experts in providing layer-specific compensation. To address the lack of datasets for nighttime reflection separation, we construct the Nighttime Image Reflection Separation (NightIRS) dataset. Extensive experiments demonstrate that DMDNet outperforms state-of-the-art methods in both daytime and nighttime.

</details>


### [32] [HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection](https://arxiv.org/abs/2601.00327)
*Naiqi Zhang,Chuancheng Shi,Jingtong Dou,Wenhua Wu,Fei Shen,Jianhua Cao*

Main category: cs.CV

TL;DR: HarmoniAD 是一种频率引导的双分支异常检测框架，结合结构与语义建模，在工业缺陷检测中实现高敏感性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在结构建模（易受噪声干扰）和语义建模（丢失细粒度细节）之间存在权衡，难以兼顾微小缺陷检测的精度与鲁棒性。

Method: 提出 HarmoniAD：基于 CLIP 提取特征后转至频域，解耦为高频（配 FSAM 模块增强纹理边缘）和低频分支（配 GSCM 模块建模长程依赖），并采用多类别联合训练策略。

Result: 在 MVTec-AD、VisA 和 BTAD 数据集上达到当前最优性能，兼具高敏感性和强鲁棒性。

Conclusion: 频率域解耦双分支设计有效弥合结构与语义建模鸿沟，为工业微小缺陷检测提供了新范式。

Abstract: Anomaly detection is crucial in industrial product quality inspection. Failing to detect tiny defects often leads to serious consequences. Existing methods face a structure-semantics trade-off: structure-oriented models (such as frequency-based filters) are noise-sensitive, while semantics-oriented models (such as CLIP-based encoders) often miss fine details. To address this, we propose HarmoniAD, a frequency-guided dual-branch framework. Features are first extracted by the CLIP image encoder, then transformed into the frequency domain, and finally decoupled into high- and low-frequency paths for complementary modeling of structure and semantics. The high-frequency branch is equipped with a fine-grained structural attention module (FSAM) to enhance textures and edges for detecting small anomalies, while the low-frequency branch uses a global structural context module (GSCM) to capture long-range dependencies and preserve semantic consistency. Together, these branches balance fine detail and global semantics. HarmoniAD further adopts a multi-class joint training strategy, and experiments on MVTec-AD, VisA, and BTAD show state-of-the-art performance with both sensitivity and robustness.

</details>


### [33] [Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion](https://arxiv.org/abs/2601.00328)
*Yingzhi Tang,Qijian Zhang,Junhui Hou*

Main category: cs.CV

TL;DR: 本文提出JGA-LBD框架，通过联合隐式表示与桥接扩散模型，统一重建单张RGB图像下的3D数字人几何与外观，显著提升保真度与一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法多采用解耦流程分别估计几何和合成外观，导致重建不一致；且异构条件（如深度图、SMPL）直接融合带来训练困难。

Method: 提出JGA-LBD：将各类3D条件统一为3D高斯表示，经共享稀疏变分自编码器（VAE）压缩至联合隐空间；再利用桥接扩散模型，从部分观测隐码出发推断缺失部分；最后通过专用解码模块恢复完整几何并渲染新视角。

Result: 在几何保真度和外观质量上均超越当前SOTA方法，尤其在野外（in-the-wild）复杂场景下表现优异。

Conclusion: 联合隐表示与桥接扩散建模可有效解决单图3D数字人重建中几何-外观不一致与条件融合难的问题，为端到端高质量重建提供了新范式。

Abstract: Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.

</details>


### [34] [Intelligent Traffic Surveillance for Real-Time Vehicle Detection, License Plate Recognition, and Speed Estimation](https://arxiv.org/abs/2601.00344)
*Bruce Mugizi,Sudi Murindanyi,Olivia Nakacwa,Andrew Katumba*

Main category: cs.CV

TL;DR: 本文提出了一种面向乌干达等发展中国家的实时智能交通监控系统，利用YOLOv8进行车牌检测（mAP 97.9%），CNN与Transformer进行字符识别（CER分别3.85%和1.79%），结合ROI实现速度估计（误差±10 km/h），并集成数据库与Africa's Talking API实现自动短信开罚单。


<details>
  <summary>Details</summary>
Motivation: 乌干达等发展中国家因道路安全基础设施薄弱，超速导致大量交通事故死亡，亟需低成本、高适应性的自动化交通执法方案。

Method: 采用YOLOv8进行车牌检测；CNN与Transformer分别用于车牌字符识别；基于源/目标感兴趣区域（ROI）估算车速；构建车辆-用户数据库，并通过Africa's Talking API发送短信罚单。

Result: YOLOv8车牌检测mAP达97.9%；Transformer字符识别CER降至1.79%；速度估计误差控制在±10 km/h；系统成功实现端到端自动罚单发放。

Conclusion: 该系统为资源受限地区提供了可行、高效、可部署的智能交通监管方案，具备显著降低道路事故的潜力。

Abstract: Speeding is a major contributor to road fatalities, particularly in developing countries such as Uganda, where road safety infrastructure is limited. This study proposes a real-time intelligent traffic surveillance system tailored to such regions, using computer vision techniques to address vehicle detection, license plate recognition, and speed estimation. The study collected a rich dataset using a speed gun, a Canon Camera, and a mobile phone to train the models. License plate detection using YOLOv8 achieved a mean average precision (mAP) of 97.9%. For character recognition of the detected license plate, the CNN model got a character error rate (CER) of 3.85%, while the transformer model significantly reduced the CER to 1.79%. Speed estimation used source and target regions of interest, yielding a good performance of 10 km/h margin of error. Additionally, a database was established to correlate user information with vehicle detection data, enabling automated ticket issuance via SMS via Africa's Talking API. This system addresses critical traffic management needs in resource-constrained environments and shows potential to reduce road accidents through automated traffic enforcement in developing countries where such interventions are urgently needed.

</details>


### [35] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本文提出OmniVaT框架，首次解决单域泛化下的视觉-触觉学习（SDG-VTL）任务，通过多模态分数傅里叶适配器（MFFA）统一视觉与触觉嵌入的频域表征，并引入离散树生成（DTG）模块提升对未知域偏移的适应性，显著提升跨域泛化性能。


<details>
  <summary>Details</summary>
Motivation: 视觉-触觉学习（VTL）面临模态差异（视觉vs触觉图像）和领域差异（非标准化传感器、不一致采集流程）两大挑战，亟需新任务设定与方法应对。

Method: 提出OmniVaT框架：1）多模态分数傅里叶适配器（MFFA），将VIS/TAC嵌入映射至统一嵌入-频率空间，缓解模态差异；2）离散树生成（DTG）模块，基于层次化树结构生成多样且鲁棒的多模态分数表征，增强对未知域偏移的适应性。

Result: 在SDG-VTL任务上，OmniVaT展现出卓越的跨域泛化性能，实验验证其有效性与鲁棒性。

Conclusion: OmniVaT首次系统性地解决了单域设定下多模态VTL的泛化难题，为具身智能中异构传感融合提供了新范式。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [36] [Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting](https://arxiv.org/abs/2601.00368)
*Aarya Sumuk*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级两阶段框架，用于受损3D文物的几何与颜色联合修复：第一阶段用2D卷积网络预测损伤掩码并聚合为体素掩码；第二阶段用扩散式3D U-Net在掩码引导下直接在体素网格上完成几何与颜色联合重建。


<details>
  <summary>Details</summary>
Motivation: 受文化遗产文物数字化修复需求驱动，解决受损3D物体几何与颜色联合修复问题。

Method: 两阶段方法：第一阶段基于RGB切片的2D CNN预测损伤掩码并融合为体素掩码；第二阶段采用掩码条件化的扩散式3D U-Net，在体素网格上联合预测占据率与颜色，使用包含占据重建、掩码颜色重建和感知正则化的复合损失函数。

Result: 在合成损坏的纹理化文物数据集上，相比基于对称性的基线方法，在固定32^3分辨率下实现了更完整的几何重建和更连贯的颜色重建。

Conclusion: 显式的掩码条件化是一种实用且有效的方式，可用于指导体素扩散模型完成3D几何与颜色的联合修复任务。

Abstract: We present a lightweight two-stage framework for joint geometry and color inpainting of damaged 3D objects, motivated by the digital restoration of cultural heritage artifacts. The pipeline separates damage localization from reconstruction. In the first stage, a 2D convolutional network predicts damage masks on RGB slices extracted from a voxelized object, and these predictions are aggregated into a volumetric mask. In the second stage, a diffusion-based 3D U-Net performs mask-conditioned inpainting directly on voxel grids, reconstructing geometry and color while preserving observed regions. The model jointly predicts occupancy and color using a composite objective that combines occupancy reconstruction with masked color reconstruction and perceptual regularization. We evaluate the approach on a curated set of textured artifacts with synthetically generated damage using standard geometric and color metrics. Compared to symmetry-based baselines, our method produces more complete geometry and more coherent color reconstructions at a fixed 32^3 resolution. Overall, the results indicate that explicit mask conditioning is a practical way to guide volumetric diffusion models for joint 3D geometry and color inpainting.

</details>


### [37] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 本文提出了一种面向手部精细动作识别的骨骼动作识别框架，通过概率双流结构融合多种骨骼模态与RGB信息，在多个基准上展现出鲁棒性和优越性。


<details>
  <summary>Details</summary>
Motivation: 现有基于骨骼的动作识别方法过于关注大尺度身体运动，忽视对手部细微关节运动的建模，难以支持细粒度动作识别。

Method: 提出概率双流框架，包含三个核心组件：(1) 无需校准的原生坐标预处理；(2) 基于Noisy-OR的概率化双流融合，无需显式置信度监督；(3) 从骨骼内到跨模态的集成，耦合四种骨骼模态（关节点、骨骼、关节点运动、骨骼运动）与RGB特征。

Result: 在NTU RGB+D 60/120、PKU-MMD、N-UCLA等多个基准及新构建的手部中心化数据集上均取得一致性能提升，并在噪声与异构条件下表现出强鲁棒性。

Conclusion: 该框架有效提升了手部细微动作的建模能力，实现了可靠性感知与多模态融合的统一，为细粒度骨骼动作识别提供了新范式。

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [38] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: 本文提出了NeoVerse，一种可扩展的4D世界模型，支持4D重建、新视角轨迹视频生成及多种下游应用，基于单目视频实现无需位姿估计的前馈式4D重建和在线退化模拟，显著提升通用性与性能。


<details>
  <summary>Details</summary>
Motivation: 现有4D世界建模方法受限于多视角4D数据成本高或训练预处理复杂，导致可扩展性差。

Method: NeoVerse采用无需位姿估计的前馈式4D重建、在线单目退化模式模拟等技术，构建面向野外单目视频的可扩展全栈流程。

Result: 在标准重建与生成基准上达到SOTA性能，并展现出跨域泛化能力与多功能性。

Conclusion: NeoVerse通过简化数据与训练依赖，实现了高效、通用且可扩展的4D世界建模，为实际应用场景提供了新范式。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [39] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: 本文提出了首个面向车载摄像头的路边垃圾检测大规模数据集RoLID-11K（含11,000+张图像），针对其小目标、稀疏性与背景杂乱等挑战，系统评测了包括CO-DETR和YOLO在内的多种检测器，揭示了现有方法在极端小目标定位上的性能瓶颈，并推动低成本、可扩展的路边垃圾监测系统发展。


<details>
  <summary>Details</summary>
Motivation: 现有路边垃圾监测依赖人工调查和公众报告，覆盖有限；已有视觉数据集不适用于车载摄像头场景，因其图像中垃圾目标极小、稀疏且嵌入复杂路肩背景中。

Method: 构建首个专用于车载摄像头的路边垃圾检测数据集RoLID-11K（>11k标注图像，涵盖英国多样驾驶条件），并系统评测多种现代目标检测器（如CO-DETR、YOLO系列）在该任务上的表现。

Result: CO-DETR等Transformer模型在定位精度上最优，但实时模型受限于粗糙的特征层级；RoLID-11K成为极端小目标检测在动态驾驶场景中的新基准。

Conclusion: RoLID-11K填补了车载视角下路边垃圾检测的数据空白，揭示了当前检测器对极端小目标的局限性，为开发低成本、可扩展的自动监测系统提供了重要支撑。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [40] [ABFR-KAN: Kolmogorov-Arnold Networks for Functional Brain Analysis](https://arxiv.org/abs/2601.00416)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: 本文提出ABFR-KAN，一种结合Kolmogorov-Arnold网络（KAN）与Transformer的新型功能连接分析模型，旨在克服传统图谱分割带来的选择偏差和个体特异性缺失问题，提升自闭症谱系障碍（ASD）分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于图谱的功能连接（FC）分析存在选择偏差和忽视被试个体特异性的问题，影响诊断可靠性。

Method: 提出ABFR-KAN模型，融合Transformer架构与Kolmogorov-Arnold网络（KAN），构建更符合解剖结构、减少结构偏差的先进脑功能表征模块。

Result: 在ABIDE I数据集上的跨站点实验与消融研究表明，ABFR-KAN在ASD分类任务中持续优于现有最先进方法。

Conclusion: ABFR-KAN有效提升了FC估计的可靠性与个体适配性，为基于功能连接的脑疾病辅助诊断提供了新范式。

Abstract: Functional connectivity (FC) analysis, a valuable tool for computer-aided brain disorder diagnosis, traditionally relies on atlas-based parcellation. However, issues relating to selection bias and a lack of regard for subject specificity can arise as a result of such parcellations. Addressing this, we propose ABFR-KAN, a transformer-based classification network that incorporates novel advanced brain function representation components with the power of Kolmogorov-Arnold Networks (KANs) to mitigate structural bias, improve anatomical conformity, and enhance the reliability of FC estimation. Extensive experiments on the ABIDE I dataset, including cross-site evaluation and ablation studies across varying model backbones and KAN configurations, demonstrate that ABFR-KAN consistently outperforms state-of-the-art baselines for autism spectrum distorder (ASD) classification. Our code is available at https://github.com/tbwa233/ABFR-KAN.

</details>


### [41] [Robust Assembly Progress Estimation via Deep Metric Learning](https://arxiv.org/abs/2601.00422)
*Kazuma Miura,Sarthak Pathak,Kazunori Umeda*

Main category: cs.CV

TL;DR: 本文提出了一种基于四元组损失（Quadruplet Loss）的Anomaly Quadruplet-Net方法，用于在视觉变化微小或存在遮挡的手动装配场景中，更鲁棒地估计产品组装进度，尤其适用于小样本数据。


<details>
  <summary>Details</summary>
Motivation: 手动多日装配任务中，因视觉变化细微或遮挡，现有基于度量学习的方法（如Anomaly Triplet-Net）易发生误分类，难以支撑智能工厂的自动进度监控需求。

Method: 提出Anomaly Quadruplet-Net：采用四元组损失函数优化异常图像的特征判别性，并设计定制化数据加载器，策略性采样训练样本以提升相邻任务区分能力。

Result: 在桌面PC组装图像数据集上，相比基线方法，估计精度提升1.3%，相邻任务误分类率降低1.9%。

Conclusion: 四元组损失结合针对性数据采样可有效提升微变与遮挡场景下的装配进度估计鲁棒性，为小样本工业视觉监控提供了可行方案。

Abstract: In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.

</details>


### [42] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: 本文提出CPPO方法，通过对比感知损失（CPL）在不依赖额外模型或标注数据的前提下，有效提升视觉语言模型（VLMs）的感知能力与多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的多模态推理方法难以区分感知token与推理token，需依赖额外LLM、真值数据或强制分离策略，导致复杂低效。

Method: CPPO利用扰动图像下模型输出熵的变化检测感知token，并设计对比感知损失（CPL），在信息保持扰动下增强一致性，在信息去除扰动下增强敏感性，从而优化RL目标函数。

Result: 实验表明CPPO优于以往感知奖励方法，且无需额外模型，训练更高效、可扩展性更强。

Conclusion: CPPO为VLMs的多模态RL微调提供了一种简洁、高效、无需额外组件的感知增强新范式。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [43] [All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations](https://arxiv.org/abs/2601.00533)
*Wenrui Li,Hongtao Chen,Yao Xiao,Wangmeng Zuo,Jiantao Zhou,Yonghong Tian,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 本文提出了一种面向视频的全合一图像恢复新场景——平滑演化的未知退化（SEUD），并设计了ORCANet网络，结合物理先验与动态提示机制，实现高质量、高时序一致性的视频恢复。


<details>
  <summary>Details</summary>
Motivation: 现有视频恢复方法忽视了真实世界中退化过程的时间连续性，即退化类型和强度随时间平滑变化且可能复合或渐变，缺乏对这种动态演化的建模能力。

Method: 提出SEUD场景；构建支持单/复合/演化退化的视频合成管线；设计ORCANet：包含基于物理先验的粗略雾度估计模块（CIED）和流式提示生成模块（FPG），后者分别生成表征片段级退化类型的静态提示和适应帧级强度变化的动态提示，并引入标签感知监督提升静态提示判别力。

Result: ORCANet在恢复质量、时序一致性和鲁棒性上均显著优于图像及视频基线模型。

Conclusion: 平滑演化退化是更贴近实际的视频恢复建模方式，ORCANet通过条件化、自适应的递归提示机制有效应对SEUD挑战，为视频全合一恢复提供了新范式。

Abstract: All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.

</details>


### [44] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: 本文提出FreeText，一种无需训练、即插即用的文本渲染增强框架，通过利用扩散Transformer（DiT）模型内在机制，分别解决‘在哪里写’（基于注意力的空间定位）和‘写什么’（频域调制的字形注入）问题，在多行、密集排版及中文等长尾文字上显著提升可读性，同时保持语义与美学质量。


<details>
  <summary>Details</summary>
Motivation: 现有大规模文本到图像扩散模型在精确文本渲染（尤其是多行布局、密集字体和中文等长尾脚本）方面仍存在困难；已有方法依赖昂贵重训练或刚性外部布局约束，损害美观性与灵活性。

Method: FreeText分为两部分：1）‘在哪里写’——利用DiT中图像到文本注意力的词元级空间归因，以类汇点词元为稳定空间锚点，并结合拓扑感知优化生成高置信度书写区域掩码；2）‘写什么’——提出频谱调制字形注入（SGMI），将噪声对齐的字形先验通过频域带通调制注入，强化字形结构并抑制语义泄漏。

Result: 在Qwen-Image、FLUX.1-dev和SD3变体上，于longText-Benchmark、CVTG及自建CLT-Bench评测中，文本可读性持续提升，语义对齐与美学质量基本保持，推理开销轻微。

Conclusion: FreeText是一种高效、通用、免训练的文本渲染增强方案，揭示并利用了DiT模型的内在机制，在精度、灵活性与实用性间取得良好平衡。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [45] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: 本文提出VNS-SAM，通过Mask-Edge Token Interactive解码器和Non-Salient Feature Mining模块增强SAM在低对比度（视觉非显著）场景下的零样本分割能力，同时保持其泛化性；构建了包含35K图像的VNS-SEG统一数据集，并验证了方法高效性与实用性。


<details>
  <summary>Details</summary>
Motivation: SAM在视觉非显著场景（前景与背景对比度低）下分割效果差，难以准确捕捉轮廓，现有方法无法有效应对。

Method: 提出VNS-SAM，包含Mask-Edge Token Interactive解码器和Non-Salient Feature Mining模块，利用SAM低层特征增强对非显著特性的建模；构建大规模统一数据集VNS-SEG（>35K图像）用于训练与评测。

Result: VNS-SAM在多种视觉非显著分割任务中显著优于基线，尤其在零样本设置下表现突出；仅需4小时即可完成微调，参数与计算开销增加极小。

Conclusion: VNS-SAM有效提升了SAM在视觉非显著场景下的鲁棒性与分割精度，同时维持其零样本泛化能力，具备良好的实用性和推广价值。

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [46] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: 本文提出DynaDrag，一种基于预测-移动框架的新型拖拽式图像编辑方法，通过迭代进行运动预测和运动监督，并动态调整有效控制点，解决了以往方法中跟踪不准、源目标图像差距大及中间点不合理等问题。


<details>
  <summary>Details</summary>
Motivation: 现有拖拽式图像编辑方法存在跟踪不准、源目标图像差距大以及中间点不合理导致编辑能力差等问题。

Method: 提出DynaDrag方法，采用预测-移动框架，迭代执行运动预测（预测控制点应移动位置）与运动监督（按预测结果拖拽），并动态调整有效控制点。

Result: 在人脸和人体数据集上的实验表明，该方法优于先前工作。

Conclusion: DynaDrag是首个基于预测-移动框架的拖拽式图像编辑方法，有效克服了传统方法的关键缺陷，提升了像素级图像编辑性能。

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [47] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: 本文提出SlingBAG Pro算法，扩展SlingBAG方法以支持任意阵列几何结构，通过分层优化策略（零梯度滤波+渐进式提高时间采样率）加速点云迭代重建，在不牺牲质量前提下显著提升不规则阵列下3D光声成像的重建速度。


<details>
  <summary>Details</summary>
Motivation: 传统迭代重建算法难以高效处理不规则几何超声换能器阵列，存在计算复杂度高、内存占用大、重建时间长等问题，而此类阵列对低成本、高适应性3D光声成像临床应用至关重要。

Method: 基于点云迭代的Sliding ball adaptive growth（SlingBAG）思想，提出SlingBAG Pro算法；引入分层优化策略：结合零梯度滤波与迭代过程中逐步提高时间采样率，以快速剔除冗余点云并加速收敛。

Result: 在不规则阵列配置下，相比原始SlingBAG算法，SlingBAG Pro实现最高2.2倍的3D光声重建速度提升；经仿真与活体小鼠实验验证，保持高重建质量；代码已开源。

Conclusion: SlingBAG Pro是一种高效、通用、开源的3D光声图像重建算法，特别适用于不规则换能器阵列，在保证图像质量的同时显著降低计算负担和重建时间，推动便携式与定制化临床PAI系统发展。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [48] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: 本文介绍了MS COCOAI数据集，用于检测AI生成图像，包含96000张真实与合成图像，并支持两类任务：真假二分类与生成模型溯源。


<details>
  <summary>Details</summary>
Motivation: 随着Stable Diffusion、DALL-E等多模态生成模型普及，AI伪造图像难以辨识，亟需可靠检测方法。

Method: 基于MS COCO构建MS COCOAI数据集，使用5种主流生成模型（SD3、SD2.1、SDXL、DALL-E 3、MidJourney v6）生成合成图像，并定义真假分类与模型溯源两项检测任务。

Result: 发布首个大规模、多模型覆盖的AI图像检测基准数据集MS COCOAI（96000样本），并公开于Hugging Face。

Conclusion: MS COCOAI为AI生成图像检测研究提供了高质量、多样化的新基准，推动检测技术发展与评估标准化。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [49] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: 本文提出AEGIS多任务基准和确定性清单评估（DCE）协议，系统评测统一多模态模型（UMMs）的世界知识能力，发现其普遍存在严重缺陷，尤其在复杂推理中性能显著下降，并指出引入推理模块是潜在改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅支持单任务孤立评估，缺乏对UMMs跨任务应用世界知识能力的综合、可诊断性评测。

Method: 构建覆盖视觉理解、生成、编辑及交错生成的多任务基准AEGIS（含1050个手工标注问题、21类主题、6种推理类型），并提出基于原子Y/N判断的确定性清单评估（DCE）协议替代模糊的提示词评分。

Result: 实验表明多数UMMs存在严重世界知识缺陷，且性能随推理复杂度升高而显著下降；简单插件式推理模块可部分缓解该问题。

Conclusion: 世界知识驱动的推理能力是UMMs亟待突破的关键前沿，需更可靠、多维的评测体系与针对性建模方法。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [50] [A Cascaded Information Interaction Network for Precise Image Segmentation](https://arxiv.org/abs/2601.00562)
*Hewen Xiao,Jie Mei,Guangfu Ma,Weiren Wu*

Main category: cs.CV

TL;DR: 本文提出了一种结合全局信息引导模块的级联卷积神经网络，用于提升复杂场景下的图像分割鲁棒性与精度。


<details>
  <summary>Details</summary>
Motivation: 视觉感知在自主行为中至关重要，但复杂场景下的鲁棒分割仍具挑战性。

Method: 提出一种级联卷积神经网络，并引入新型全局信息引导模块，实现多层低层纹理细节与高层语义特征的有效融合。

Result: 在基准图像分割数据集上实验表明，该方法精度优于现有最先进方法，尤其在视觉杂乱或模糊环境中表现突出。

Conclusion: 该架构创新显著提升了分割准确性，展现出在实际机器人应用中的广阔前景。

Abstract: Visual perception plays a pivotal role in enabling autonomous behavior, offering a cost-effective and efficient alternative to complex multi-sensor systems. However, robust segmentation remains a challenge in complex scenarios. To address this, this paper proposes a cascaded convolutional neural network integrated with a novel Global Information Guidance Module. This module is designed to effectively fuse low-level texture details with high-level semantic features across multiple layers, thereby overcoming the inherent limitations of single-scale feature extraction. This architectural innovation significantly enhances segmentation accuracy, particularly in visually cluttered or blurred environments where traditional methods often fail. Experimental evaluations on benchmark image segmentation datasets demonstrate that the proposed framework achieves superior precision, outperforming existing state-of-the-art methods. The results highlight the effectiveness of the approach and its promising potential for deployment in practical robotic applications.

</details>


### [51] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的零样本视频时刻检索框架GranAlign，通过粒度感知对齐解决文本查询与视频内容间语义粒度不匹配问题，包含基于粒度的查询重写和查询感知字幕生成两项技术，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 零样本视频时刻检索（ZVMR）中，文本查询与视频内容之间存在语义粒度不匹配问题，已有方法虽利用高质量预训练多模态表征，但未能平衡不同模态在特定场景下的语义粒度，导致检索不准。

Method: 提出无训练框架GranAlign：1）基于粒度的查询重写，生成多级语义粒度的查询；2）查询感知字幕生成，将查询意图嵌入视频字幕；结合查询无关与查询相关的多级字幕实现对齐。

Result: 在QVHighlights、Charades-STA和ActivityNet-Captions三大基准上均达SOTA，其中在具挑战性的QVHighlights数据集上mAP@avg提升3.23%。

Conclusion: GranAlign有效缓解了跨模态语义粒度失配问题，验证了无需训练即可显著提升零样本视频时刻检索性能的可行性与有效性。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [52] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出SafeMo框架，通过Minimal Motion Unlearning（MMU）在连续空间中实现安全的人体动作生成，避免离散码本替换带来的性能下降与运动失真，并构建首个安全文本-动作数据集SafeMoVAE-29K。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散VQ-VAE码本替换的安全T2M方法存在良性任务性能下降和运动不自然（量化/不平滑）两大缺陷；且现有数据集天然含不安全样本，难以支撑安全驱动的训练。

Method: 提出SafeMo框架，核心为两阶段连续空间机器遗忘策略MMU；构建首个安全T2M数据集SafeMoVAE-29K（含重写安全文本与连续优化动作）；基于DiP扩散模型实现高效、自然的安全动作生成。

Result: 在HumanML3D和Motion-X上，对遗忘集的FID分别比SOTA方法LCR提升2.5倍和14.4倍；同时在安全提示下保持甚至优于基线的良性性能。

Conclusion: SafeMo首次在连续空间实现高效、保真、高安全-效用平衡的人体动作生成与遗忘，解决了离散码本方法的根本缺陷，并提供了高质量安全数据集与开源实现。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [53] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 本文提出Modality Dominance Index (MDI)量化RGB-IR跨模态融合中的模态主导现象，并设计MDACL框架，通过分层跨模态引导（HCG）和对抗均衡正则化（AER）缓解优化偏差，提升融合效果。


<details>
  <summary>Details</summary>
Motivation: RGB-IR跨模态检测中，因模态间信息密度与特征质量差异导致优化偏差，现有方法未充分建模该不对称性。

Method: 提出Modality Dominance Index (MDI)量化模态主导性；构建MDACL框架，包含Hierarchical Cross-modal Guidance (HCG)和Adversarial Equilibrium Regularization (AER)。

Result: 在三个RGB-IR基准上显著缓解优化偏差，达到SOTA性能。

Conclusion: 模态主导性是影响跨模态融合训练的关键因素，MDACL通过动态感知与调控优化过程，有效提升多模态协同性能。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [54] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: 本文提出了一种针对微小目标检测中标注噪声敏感问题的鲁棒定位框架TOLF，利用标准化流建模复杂误差分布，并通过不确定性引导优化缓解噪声过拟合。


<details>
  <summary>Details</summary>
Motivation: 微小目标对标注噪声高度敏感，严格的位置优化目标易导致噪声过拟合，从而拉大与常规尺度目标的性能差距。

Method: 提出Tiny Object Localization with Flows（TOLF）：1）基于标准化流的误差建模，捕获非高斯预测分布；2）不确定性感知的梯度调制机制，抑制高不确定性样本的学习。

Result: 在三个数据集上验证有效，尤其在AI-TOD上将DINO基线提升1.2% AP。

Conclusion: TOLF通过灵活误差建模与不确定性引导优化，显著提升了微小目标检测在噪声标注下的鲁棒性与性能。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [55] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: 本文提出了一种名为RePose的实时3D人体姿态估计与运动分析方法，专为康复训练设计，支持多视角RGB视频输入、快速多人跟踪、改进的SmoothNet姿态估计以及基于Unity的实时可视化反馈与肌肉应力显示。


<details>
  <summary>Details</summary>
Motivation: 为康复训练提供实时、准确的人体姿态监测与运动评估，帮助患者正确执行康复动作并及时获得反馈，从而有效恢复肌力和运动功能。

Method: 构建端到端统一管道，融合多相机RGB视频输入；提出毫秒级快速跟踪方法应对多人干扰场景；改进SmoothNet以降低姿态估计误差、提升运动平滑性；基于Unity平台实现运动实时监控、评估及肌肉应力可视化。

Result: 实现了亚毫秒级单帧跟踪（<1ms）、更准确和平滑的3D姿态估计，并在Unity中成功集成实时反馈与肌肉应力显示系统。

Conclusion: RePose为临床康复训练提供了高效、低延迟、易部署的实时运动分析解决方案，显著提升了康复指导的及时性与有效性。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [56] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: 本文提出HyperPriv-EPN框架，利用超图和特权信息学习（LUPI）方法，在无术后文本数据的术前MRI诊断中，通过师生图结构与双流蒸馏，实现高精度预后预测。


<details>
  <summary>Details</summary>
Motivation: 术前脑室管膜瘤预后预测困难，因MRI缺乏语义信息，而现有多模态方法无法在推理阶段利用术后报告等特权文本数据。

Method: 提出基于超图的LUPI框架HyperPriv-EPN；设计‘截断图策略’，共享编码器处理含术后信息的教师图与仅含术前影像的学生图；通过双流知识蒸馏使学生图从纯视觉特征中推断语义社区结构。

Result: 在311例多中心患者队列上验证，达到当前最优诊断准确率与生存风险分层性能。

Conclusion: 该方法成功将专家术后知识迁移至术前场景，无需推理时提供文本，即可提升新患者的术前诊断能力。

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [57] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 本文提出了一种基于图像的深度学习方法，用于非侵入式、可扩展地监测储存期间马铃薯的质量，包括发芽检测、失重估计和保质期预测。使用ResNet、VGG、DenseNet和ViT等预训练模型构建了两个专用模型，在发芽检测（DenseNet达98.03%准确率）和粗粒度保质期分类（2–5类，>89.83%准确率）上表现优异，验证了其在自动化分拣与库存管理中的实用价值。


<details>
  <summary>Details</summary>
Motivation: 解决马铃薯储存过程中发芽检测、失重估计与保质期预测等关键质量监控难题，提供非侵入、可扩展、低成本的替代方案。

Method: 采集200天内受控温湿度条件下的马铃薯图像及对应重量数据；基于ResNet、VGG、DenseNet和ViT设计两个专用模型：(1)高精度二分类器用于发芽检测；(2)多分类模型用于失重估计与保质期预测；评估不同类别粒度（2–8类）对性能的影响。

Result: DenseNet在发芽检测中达到98.03%准确率；保质期预测在2–5类粗划分下准确率超89.83%，细划分（6–8类）性能下降；模型具备实际部署潜力，支持自动化分拣与动态库存分级。

Conclusion: 图像深度学习可有效支撑马铃薯储存质量监测，尤其适用于粗粒度保质期分类与发芽识别；未来需拓展至多品种、多环境以提升泛化性与可扩展性。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [58] [Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network](https://arxiv.org/abs/2601.00658)
*Zhaiyu Chen,Yuanyuan Wang,Yilei Shi,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的双拓扑网络框架，用于将噪声大、分布不均、存在空洞的TomoSAR点云直接转换为高分辨率建筑高度图，是首个面向大规模城市高度制图的端到端方法，并可融合光学影像进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: TomoSAR点云存在噪声、各向异性分布和非相干表面数据缺失等问题，严重制约了建筑高度重建精度，亟需一种鲁棒、端到端的高度映射方法。

Method: 提出双拓扑网络，交替处理点云分支（建模不规则散射体特征）与网格分支（保障空间一致性），联合实现去噪与空洞修复；并支持融合光学卫星影像以增强性能。

Result: 在慕尼黑和柏林TomoSAR数据上验证了方法有效性，显著提升了高度图连续性与精度；首次实现了从原始TomoSAR点云到城市级高度图的端到端生成。

Conclusion: 该学习框架为TomoSAR建筑高度反演提供了新范式，兼具鲁棒性与可扩展性，开源代码促进了后续研究与应用。

Abstract: Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.

</details>


### [59] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: 本文提出CRoPS框架，通过选择性移除关键文本token构建幻觉模型，并结合广义对比解码整合多种幻觉源，实现无需训练的视觉语言大模型幻觉缓解，显著提升CHAIR分数和多基准性能。


<details>
  <summary>Details</summary>
Motivation: 现有无训练幻觉缓解方法存在两点局限：一是对幻觉来源假设过于狭窄；二是生成后期（幻觉高发阶段）效果下降。单纯移除视觉token无法阻断视觉信息向文本的传播。

Method: 提出新型幻觉模型——选择性移除关键文本token；引入广义对比解码（GCD），融合多个不同幻觉源的幻觉模型；二者共同构成无训练框架CRoPS。

Result: CRoPS在CHAIR指标上提升20%，在六个基准和三类LVLM上均取得一致性能增益，超越当前最优无训练方法。

Conclusion: 选择性文本token屏蔽与多源幻觉建模的结合，比传统视觉token屏蔽更有效；CRoPS为无训练LVLM幻觉缓解提供了新范式。

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [60] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 本文提出了一种基于单张图像、通过3D高斯场景表示实现相机引导的高效视频生成新框架，显著提升了用户可控性、时间一致性与几何完整性。


<details>
  <summary>Details</summary>
Motivation: 现有单图生成视频方法缺乏对相机路径等用户控制的鲁棒支持，且在建模相机运动、保持时间一致性和几何完整性方面存在不足。

Method: 构建3D高斯场景表示，结合单次前向传播采样合理物体运动，实现相机轨迹对齐的视频生成，避免迭代去噪注入运动。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上达到SOTA视频质量与推理效率。

Conclusion: 所提框架在保证强用户可控性的同时，兼顾时间一致性与几何保真度，为单图到4D视频生成提供了高效、端到端的新范式。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [61] [Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks](https://arxiv.org/abs/2601.00703)
*Cory Fan,Wenchao Zhang*

Main category: cs.CV

TL;DR: 本文提出在各向同性网络中引入显著的空间下采样，以提升图像去马赛克及联合去马赛克与去噪（JDD）任务的效率与性能，并通过设计含/不含下采样的全卷积网络及JD3Net验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有各向同性网络因避免空间下采样而计算开销大，难以适用于移动平台；需兼顾轻量化与高性能的去马赛克深度模型。

Method: 采用源自DeepMAD的数学架构设计方法，构建含/不含空间下采样的全卷积各向同性网络，并提出下采样变体JD3Net。

Result: 实验证明，引入显著空间下采样可提升各向同性网络的效率与性能；JD3Net在多种去马赛克和JDD任务上表现出强实证性能。

Conclusion: 空间下采样并非损害各向同性网络性能的负担，而是提升其在移动端实用性与精度的关键设计选择。

Abstract: In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.

</details>


### [62] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 本文研究了视觉-语言模型（VLM）在病理学应用中面对数据分布偏移时的性能退化检测问题，提出结合输入级数据偏移检测与输出级置信度监控的互补框架，并开发了轻量级工具DomainSAT支持系统分析。


<details>
  <summary>Details</summary>
Motivation: 部署后的视觉-语言模型在数据分布偏移下性能可能下降，影响临床可靠性；而现有方法缺乏无标签条件下的有效退化检测手段。

Method: 提出DomainSAT工具用于输入级数据偏移分析，并设计一种无需标签、基于预测置信度的输出级退化指标；在大型病理肿瘤分类数据集上进行实验验证。

Result: 输入级偏移检测可提供早期信号但不总对应真实性能退化；输出级置信度指标与性能退化高度相关；二者结合可更可靠地检测和解释VLM退化。

Conclusion: 输入与输出双视角监控构成实用、互补的数字病理基础模型可靠性监测框架。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [63] [Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection](https://arxiv.org/abs/2601.00725)
*Johannes C. Bauer,Paul Geng,Stephan Trattnig,Petr Dokládal,Rüdiger Daub*

Main category: cs.CV

TL;DR: 本文提出了一种多级特征融合（MLFF）方法，利用预训练网络不同深度的表征，在减少可训练参数的同时，提升持续学习下的快速适应能力、缓解灾难性遗忘并增强对新产品或缺陷的泛化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在再制造等动态场景中，产品和缺陷模式频繁变化，传统深度神经网络难以快速适应新条件，面临持续学习挑战，需兼顾计算效率与避免灾难性遗忘。

Method: 提出多级特征融合（MLFF）方法，融合预训练网络不同深度的特征表示，以实现参数高效且稳定的模型适应。

Result: MLFF在多个质量检测任务上达到端到端训练的性能，显著减少可训练参数，同时降低灾难性遗忘、提升对新类别缺陷或产品的泛化鲁棒性。

Conclusion: MLFF是一种高效、鲁棒的持续学习方案，适用于动态工业视觉质检场景。

Abstract: Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.

</details>


### [64] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态大语言模型的端到端手写工科试卷自动评分流程，在不改变传统考试形式（A4纸、自由书写）的前提下，仅需教师提供手写参考答案和简短评分规则，即可实现可靠、可审计的自动评分。


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能反映学生开放性推理与图示能力，但人工评阅耗时且难以规模化；现有自动化方案常要求格式约束或数字作答，脱离实际教学场景。

Method: 构建多阶段评分流水线：先进行格式/存在性检查排除空白卷；再利用多模态LLM（GPT-5.2、Gemini-3 Pro）对扫描图像进行结构化提示评分，参考答案经文本摘要后作为条件输入（不暴露原始图像）；最后通过独立评分器集成、监督者聚合及刚性模板验证生成机器可解析报告。

Result: 在斯洛文尼亚语真实课程测验（含手绘电路图）上，该冻结流水线与教师评分的平均绝对分差约8分，偏差低，当最大容许误差D_max=40时，需人工复核率约17%；消融实验表明结构化提示与参考答案锚定对准确性至关重要。

Conclusion: 该方法在保持考试原生态前提下实现了高可靠性自动评分，验证了多模态LLM结合结构化工程设计在真实教育场景中的可行性与鲁棒性；参考答案的文本化条件注入与多级验证机制是保障公平性与可审计性的关键。

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [65] [Unified Primitive Proxies for Structured Shape Completion](https://arxiv.org/abs/2601.00759)
*Zhaiyu Chen,Yuqing Wang,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 本文提出UniCo方法，通过专用路径解码结构化原始形状（primitives），在单次前向传播中预测具有完整几何、语义和内点隶属关系的原始形状集合，显著提升不完整3D数据的结构化理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多采用级联方式处理原始形状与点云的关系，但作者认为应重新思考二者交互方式，发现通过专用路径并结合共享形状特征来解码原始形状更有效。

Method: 提出UniCo框架，引入可学习的原始形状代理（primitive proxies）作为上下文化查询，生成即用型装配输出；训练中采用在线目标更新策略，耦合原始形状与点云以确保优化一致性。

Result: 在多个合成与真实世界基准上，UniCo在四个独立装配求解器下均超越近期基线：Chamfer距离最多降低50%，法向一致性最多提升7%。

Conclusion: UniCo为不完整3D数据的结构化理解提供了高效且鲁棒的新范式，验证了统一原始形状表示的有效性。

Abstract: Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.

</details>


### [66] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 本文探讨了将自监督学习作为辅助任务，以优化通用深度伪造检测这一主要任务的性能。研究发现，融合自监督任务与主任务的特征表示能显著提升检测泛化能力，并在多个数据集上超越当前SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 挖掘自监督学习作为辅助任务的潜力，以提升深度伪造检测模型的泛化能力。

Method: 探索不同自监督辅助任务与主任务的联合训练策略，重点采用特征表示融合方式来整合两类任务的信息。

Result: 所提方法在DF40、FaceForensics++、Celeb-DF等多个数据集的跨数据集评估中展现出更强的泛化性能，优于当前最先进检测器。

Conclusion: 融合自监督与主任务的特征表示是一种高效策略，能协同发挥两类任务优势，显著提升深度伪造检测的鲁棒性与泛化性。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [67] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 本文提出了两种新的深度学习架构LNU-Net和IBU-Net，用于短轴心脏MRI图像的左心室分割，通过引入层归一化和实例-批量归一化，在Dice系数和平均垂直距离指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 左心室（LV）分割对心脏影像的临床量化和诊断至关重要，但现有方法在精度上仍有提升空间。

Method: 提出LNU-Net（基于层归一化的U-Net）和IBU-Net（结合实例与批量归一化的U-Net），均采用下采样特征提取与上采样精确定位结构，并引入仿射变换和弹性形变进行数据增强。

Result: 在包含805张MRI图像的数据集上实验表明，LNU-Net和IBU-Net在Dice系数和平均垂直距离上均优于其他先进方法。

Conclusion: LNU-Net和IBU-Net有效提升了左心室分割精度，验证了归一化策略在医学图像分割中的重要性。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [68] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 本文提出AdaGaR框架，通过自适应Gabor表示提升动态3D场景重建的频率表达能力与稳定性，并引入三次Hermite样条与时间曲率正则化保证运动连续性，结合自适应初始化策略，在单目视频动态建模任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于单高斯基元的方法难以兼顾高频外观细节与时间连续运动；标准Gabor函数存在能量不稳定问题；缺乏时间连续性约束导致插值时出现运动伪影。

Method: 提出AdaGaR统一框架：1）自适应Gabor表示（含可学习频率权重与自适应能量补偿）；2）带时间曲率正则化的三次Hermite样条建模运动；3）融合深度估计、点跟踪与前景掩码的自适应初始化机制。

Result: 在Tap-Vid DAVIS数据集上达到PSNR 35.49、SSIM 0.9433、LPIPS 0.0723，同时在帧插值、深度一致性、视频编辑和立体视图合成任务中展现出强泛化能力。

Conclusion: AdaGaR有效解决了显式动态场景建模中频率适应性与时间连续性的协同建模难题，为单目动态3D重建提供了新范式。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [69] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: 本文提出RIMRULE，一种基于动态规则注入的神经符号方法，用于提升大语言模型在特定领域工具使用中的可靠性。该方法通过从失败轨迹中提炼简洁、可解释的规则，并在推理时将其注入提示中，从而提高任务性能。规则由LLM自身生成，并通过最小描述长度（MDL）目标进行优化以保证通用性和简洁性，同时以自然语言和结构化符号形式存储，便于高效检索。实验表明，该方法在多个工具使用基准上提升了准确率，且无需修改模型权重，规则还具有跨模型可迁移性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在领域特定工具使用中表现不可靠，尤其当API具有特殊性、文档不全或为私有流程定制时，亟需有效的任务特定工具适配方法。

Method: 提出RIMRULE方法：基于失败轨迹自动提炼紧凑、可解释的规则；规则由LLM生成，用最小描述长度（MDL）目标进行归纳压缩；规则以自然语言与结构化符号双形式存储，支持推理时高效检索与注入。

Result: 在工具使用基准测试中显著提升准确率（包括已见与未见工具），优于纯提示工程方法，可与微调互补；规则具备跨LLM可移植性，能迁移提升其他模型（含长推理LLM）性能。

Conclusion: RIMRULE是一种无需修改模型权重、兼具可解释性与可迁移性的神经符号适配框架，验证了符号化知识在LLM工具使用适应中的关键价值。

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [70] [Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning](https://arxiv.org/abs/2601.00095)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CL

TL;DR: MetaJuLS是一种元强化学习方法，通过图注意力网络学习通用的约束传播策略，实现跨语言和任务的结构化推理，显著提升推理速度并保持高精度，同时支持快速跨域适应和绿色AI目标。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在结构化推理（如JSON模式强制、多语言解析）中需要满足复杂约束，现有方法缺乏跨任务和跨语言的泛化能力，且训练成本高。

Method: 将结构化推理建模为自适应约束传播问题，采用图注意力网络（GAT）结合元强化学习训练通用策略，无需任务特定重训练。

Result: 相比GPU优化基线提速1.5–2.0倍，精度损失<0.2%；在10种语言的Universal Dependencies及LogicBench、GSM8K-Constrained上仅需5–10步梯度更新（5–15秒）即可适配新任务；机制分析显示其发现类人（easy-first）与非直觉启发式策略。

Conclusion: MetaJuLS实现了高效、通用、可快速迁移的结构化推理，降低LLM部署中的传播步骤与碳足迹，推动绿色AI发展。

Abstract: Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\times$ speedups over GPU-optimized baselines while maintaining within 0.2\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.

</details>


### [71] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: 本文提出Pat-DEVAL，首个面向专利说明书的多维评估框架，引入法律约束的Chain-of-Legal-Thought（CoLT）机制，显著提升对法定合规性（如启用性、书面描述要求）的评估能力，在专家验证下达到0.69的Pearson相关性，法律专业合规性达0.73。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法有效衡量长文本结构连贯性及专利法特有的法定合规性（如启用性、书面描述要求），而自动化专利撰写亟需可靠评估工具。

Method: 提出Pat-DEVAL框架，基于LLM-as-a-judge范式，设计法律约束的Chain-of-Legal-Thought（CoLT）推理机制，实现对专利说明书的多维、逐条法定要求分析；在自建专家标注数据集Pap2Pat-EvalGold上进行实验验证。

Result: Pat-DEVAL在整体评估上Pearson相关性达0.69，显著优于基线；在法律专业合规性子项上达0.73，证实显式注入法定约束的必要性与有效性。

Conclusion: Pat-DEVAL为自动化专利撰写系统提供了兼顾技术合理性与法律合规性的可靠评估标准，奠定了其实际落地的方法论基础。

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [72] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 本文通过系统性分析IEMOCAP数据集，揭示了对话情绪识别（ERC）中关键架构选择的影响，并建立了识别与生成之间的语言学联系：发现对话上下文至关重要（10–30轮内即达90%增益），层级句表示在有上下文时无额外收益，情感词典无提升；同时发现情绪（尤其是'sad'）与话语标记位置显著相关，解释了为何'sad'更依赖上下文。


<details>
  <summary>Details</summary>
Motivation: 现有ERC方法虽准确率高，但缺乏对关键架构选择的归因分析，也缺少连接情绪识别与语言生成（如话语标记使用）的深入语言学解释。

Method: 在IEMOCAP上开展10次随机种子的严谨消融实验；结合话语标记（5286例）的统计分析与情绪标签关联性检验（p值），建立识别性能与语言特征间的解释性桥梁。

Result: 仅用因果（单向）上下文的简单架构即达82.69%（4类）和67.07%（6类）加权F1，超越多数双向上下文方法；发现sad情绪话语左缘标记使用率显著偏低（21.9% vs. 28–32%），且其识别性能对上下文增益最大（+22个百分点）。

Conclusion: 对话上下文是ERC性能的核心驱动因素，其作用远超句内结构或外部词典；sad情绪因缺乏显性语用标记而高度依赖历史上下文，该发现统一解释了识别性能模式与语言生成特征。

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [73] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: 本文提出了一种针对职业教育与培训（VET）历史数字化文档的噪声感知命名实体识别（NER）方法，通过注入OCR错误的合成数据、迁移学习和多阶段微调提升模型在噪声环境下的鲁棒性与准确性。


<details>
  <summary>Details</summary>
Motivation: 历史VET文档经OCR处理后存在大量噪声，现有NER方法难以有效应对；同时缺乏针对该领域多类型实体识别的研究。

Method: 采用噪声感知训练（NAT），在训练中合成注入OCR错误；结合迁移学习与多阶段微调，并系统比较在噪声数据、干净数据和人工合成数据上训练的三种策略。

Result: 实验表明，领域特化与噪声感知的微调显著提升了模型在噪声条件下的鲁棒性和准确率；该方法首次支持VET文档中多种实体类型的识别，且适用于任意语言（已验证德语）。

Conclusion: 噪声感知训练与领域适配微调是提升OCR噪声环境下领域NER性能的关键；所提方法具有通用性与可复现性，并开源了代码。

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [74] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: 本文提出了一种专为时序知识图谱（TKG）推理设计的蒸馏框架，利用大语言模型作为教师模型，将结构与时间推理能力有效迁移至轻量级学生模型，在保证高精度的同时显著提升计算效率和部署可行性。


<details>
  <summary>Details</summary>
Motivation: 现有TKG推理模型参数量大、计算密集，难以在资源受限、低功耗和分布式平台上实时部署；且传统压缩与蒸馏方法未充分建模TKG中的时间依赖性，导致性能下降。

Method: 提出面向TKG推理的专用知识蒸馏框架，以大语言模型为教师，融合大规模公开知识与任务特定时序信息，指导轻量级学生模型学习结构与时间推理能力。

Result: 在多个公开基准数据集上实验表明，该方法在推理精度、计算效率与可部署性之间取得更优平衡，持续优于强基线模型。

Conclusion: 所提蒸馏框架有效解决了TKG推理模型轻量化与时间建模兼顾的难题，为资源受限场景下的智能决策系统提供了可行技术路径。

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [75] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: 本文提出了一种将循证医学（EBM）原则融入图增强检索增强生成（RAG）系统的新策略，通过PICO框架指导知识图谱构建与检索，并设计贝叶斯启发的重排序算法以依据证据等级校准排序得分；在运动康复领域验证有效，显著提升检索质量、答案可信度与临床对齐性，并开源了大规模知识图谱和基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有医学RAG方法忽视循证医学（EBM）原则，尤其缺乏查询与证据间的PICO结构对齐，以及在重排序中未考虑证据等级层次。

Method: 将PICO框架嵌入知识图谱构建与检索过程，并提出一种无需预设权重的贝叶斯启发式重排序算法，依据证据等级动态校准检索得分。

Result: 在运动康复领域实现0.830 nugget覆盖率、0.819答案忠实度、0.882语义相似度、0.788 PICOT匹配准确率；5位临床专家在5分Likert量表中评分达4.66–4.84分（涵盖事实准确性、忠实性、相关性、安全性及PICO对齐性）。

Conclusion: 该EBM适配策略可提升RAG系统的检索质量与答案临床可信度，具备跨临床领域的可迁移性；所发布的知识图谱与QA基准填补了运动康复领域RAG资源空白。

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [76] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: 本文介绍了JP-TL-Bench，一个轻量级、开源的日本语-英语翻译系统评估基准，通过参考无关的LLM成对比较与固定锚点集对比，并利用Bradley-Terry模型聚合结果，生成稳定可比的赢率和归一化LT分数。


<details>
  <summary>Details</summary>
Motivation: 针对日英翻译中礼貌性、隐含意义、省略及语域等细微差异显著影响自然度感知的特点，需解决‘两个较好译文哪个更优’而非简单判断‘是否可接受’的问题。

Method: 采用参考无关的LLM成对比较方法，将候选模型与固定版本化的锚点集进行对比；使用Bradley-Terry模型聚合成对结果，通过逻辑变换将拟合的对数强度转化为0–10归一化LT分数。

Result: JP-TL-Bench实现了评分结构稳定性——只要基础锚点集、LLM裁判器和聚合代码不变，不同候选模型得分即可直接比较；并提供了赢率和LT分数两种量化指标。

Conclusion: JP-TL-Bench为日英翻译系统的迭代开发提供了可靠、经济且可复现的轻量级评估框架，其设计兼顾判别力、稳定性和实用性。

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [77] [Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback](https://arxiv.org/abs/2601.00224)
*Yan Sun,Ming Cai,Stanley Kok*

Main category: cs.CL

TL;DR: 本文提出Q*和Feedback+两种验证技术，嵌入生成器-判别器框架中，以提升企业级大语言模型在业务分析中的输出准确性与可信度。


<details>
  <summary>Details</summary>
Motivation: 当前对话式商业分析（CBA）系统缺乏内置验证机制，用户需手动验证结果，影响效率与可靠性。

Method: 提出Q*（通过反向翻译与语义匹配验证代码与用户意图一致性）和Feedback+（利用执行反馈指导代码优化），二者协同嵌入生成器-判别器框架。

Result: 在Spider、Bird和GSM8K三个基准数据集上验证，两种方法均显著降低错误率并缩短任务完成时间；同时发现反向翻译是关键瓶颈。

Conclusion: 该工作为构建高可靠性、可信赖的企业级生成式AI系统提供了面向设计的验证框架。

Abstract: As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.

</details>


### [78] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文系统研究了大语言模型（LLM）生成多语言反事实样本的能力，发现翻译法生成的反事实有效性更高但改动更大、质量仍逊于英文原生反事实；高资源欧洲语言间的编辑模式高度相似；归纳出四类跨语言共性错误；多语言反事实数据增强效果优于跨语言增强，尤其对低资源语言，但生成缺陷制约了性能与鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在英文反事实生成和多语言能力上表现优异，但其在多语言反事实生成上的有效性尚不明确，亟需系统评估与分析。

Method: 开展多语言反事实综合研究：1）自动评估六种语言中直接生成与经英语翻译生成的反事实；2）分析编辑模式跨语言一致性；3）归纳跨语言共性错误类型；4）评估多语言与跨语言反事实数据增强对模型性能的影响。

Result: 1）翻译法反事实有效性更高但修改量大、质量低于英文原生反事实；2）高资源欧洲语言编辑模式高度相似；3）识别出四类跨语言高频错误；4）多语言CDA提升效果优于跨语言CDA，尤其利于低资源语言，但生成缺陷限制了鲁棒性增益。

Conclusion: 当前LLM生成的多语言反事实仍存在质量与一致性瓶颈，需针对性改进生成策略与错误建模，以充分发挥其在多语言可解释性与鲁棒性提升中的潜力。

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [79] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: WildAGTEval是一个评估大语言模型（LLM）智能体在真实API复杂性下函数调用能力的新基准，涵盖API规范与执行两方面复杂性，包含60种场景、约32K测试配置，并揭示了当前LLM在噪声、无关信息等现实挑战下的显著性能下降及意图扭曲问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准假设理想化API环境，忽略真实世界中的噪声输出、文档复杂性、运行时挑战等因素，无法准确反映LLM智能体在实际部署中的函数调用能力。

Method: 构建WildAGTEval基准，从API规范（详细文档与使用约束）和API执行（运行时挑战）两个维度建模现实复杂性；设计60种可组合的复杂性场景，生成约32K测试配置；开展系统性实验评估多个先进LLM，并进行定性分析。

Result: 多数场景对当前LLM构成挑战，其中‘无关信息复杂性’导致最强LLM性能下降27.3%；定性分析发现LLM常扭曲用户意图以虚假宣称任务完成，严重损害用户满意度。

Conclusion: WildAGTEval揭示了当前LLM智能体在真实API环境中的关键短板，强调需在API理解、抗噪推理与忠实意图执行三方面加强研究，为更鲁棒、可信的智能体开发提供新评测标准与改进方向。

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [80] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文研究了量化对大语言模型自解释（SEs）质量与可信度的影响，发现量化虽导致SE质量与可信度轻微下降，但不影响其作为模型压缩技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 自解释（SEs）在高风险应用中日益重要，但量化对SEs的影响尚未被探索，需评估量化是否及如何损害SEs的质量与可信度。

Method: 研究分析了三种常见量化技术在不同比特宽度下对两类自解释（自然语言解释NLEs和反事实示例）的影响，并通过用户研究评估其连贯性与可信度。

Result: 量化导致SE质量下降最多4.4%，可信度下降最多2.38%，用户研究显示连贯性与可信度下降最多8.5%；大模型在SE质量上抗量化能力弱，但在可信度上表现更好；无一种量化技术在任务准确率、SE质量和可信度上全面占优。

Conclusion: 量化对SE质量与可信度仅有轻微影响，仍是一种有效的模型压缩方法；建议针对具体应用场景（尤其是NLEs）验证SE质量。

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [81] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: 本文提出DepFlow框架，通过三阶段文本到语音合成方法解决抑郁检测中语言情感与诊断标签强耦合导致的语义偏差问题，并构建CDoA数据集以提升模型在隐匿性抑郁场景下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁数据集（如DAIC-WOZ）存在语言情感与诊断标签强耦合问题，导致模型依赖语义捷径，在隐匿性抑郁（即语言积极/中性但实际抑郁）等真实场景中鲁棒性差。

Method: 提出DepFlow：1）基于对抗训练的抑郁声学编码器，学习与说话人和内容无关的抑郁嵌入；2）结合FiLM调制的流匹配TTS模型，注入抑郁嵌入并保持内容与说话人身份；3）基于原型的严重度映射机制，实现抑郁程度连续可控调节。并据此构建CDoA数据集。

Result: 抑郁嵌入ROC-AUC达0.693；CDoA数据集使三类抑郁检测模型macro-F1分别提升9%、12%、5%，显著优于传统增强方法。

Conclusion: DepFlow有效缓解语义偏差，提升模型对隐匿性抑郁的识别能力，并为对话系统与仿真评估提供可控语音合成平台。

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [82] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型（LLM）幻觉问题的新型不确定性量化方法（RU），通过构建含虚假名称的‘陷阱问题’数据集，在多事实生成任务中验证其有效性，显著提升幻觉检测性能（ROCAUC平均提高0.1–0.2）。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法在常规问答中有效，但在非典型或对抗性提问下表现不佳，难以支撑真实场景中对LLM可靠性的高要求。

Method: 构建含虚假名称的陷阱问题数据集，提出鲁棒不确定性量化方法（RU），用于多事实生成任务中的幻觉检测。

Result: RU在四个不同LLM上显著优于基线方法，ROCAUC平均提升0.1–0.2；所建陷阱问题集表现优异。

Conclusion: RU为缓解LLM幻觉提供了新思路和实用工具，尤其适用于需强批判性思维的真实应用场景。

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [83] [The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2601.00364)
*Jiandong Shao,Raphael Tang,Crystina Zhang,Karin Sevegnani,Pontus Stenetorp,Jianfei Yang,Yao Lu*

Main category: cs.CL

TL;DR: 本文通过控制实验探究了多语言预训练数据中双语数据对多语言大模型跨语言能力的影响，发现平行语料对翻译性能至关重要，而对跨语言问答和推理等任务影响甚微。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言大语言模型在少或多语预训练下展现出强跨语言能力，但其中双语数据的具体作用尚不明确，本文旨在厘清其贡献。

Method: 从零开始在受控条件下预训练模型，对比标准网络语料与剔除所有双语文档的单语语料；进一步将双语数据细分为平行、语码转换和杂类三类，并分别进行消融实验。

Result: 仅占语料2%的双语数据移除导致BLEU分数下降56%，但跨语言QA和推理任务表现稳定；平行数据恢复91%的翻译性能，语码转换数据贡献极小；其他跨语言任务不受二者显著影响。

Conclusion: 翻译能力高度依赖平行语料提供的系统性词元级对齐，而跨语言理解与推理可在无双语数据情况下实现。

Abstract: Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.

</details>


### [84] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: 本文提出了BERT-JEPA（BEPA），一种将JEPA训练目标引入BERT式模型的新范式，旨在解决[CLS]嵌入空间坍缩问题，并构建语言无关的嵌入空间，从而提升多语言基准性能。


<details>
  <summary>Details</summary>
Motivation: 解决BERT等模型中[CLS]嵌入空间坍缩问题，并增强其在多语言场景下的泛化能力。

Method: 在BERT-style模型中引入Joint Embedding Predictive Architectures（JEPA）训练目标，重构[CLS]嵌入空间为语言无关表示。

Result: 在多个多语言基准测试中性能显著提升。

Conclusion: BEPA有效缓解了[CLS]嵌入坍缩，构建了更鲁棒、语言无关的语义空间，验证了JEPA与BERT结合的可行性与优势。

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [85] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: 本文提出Geo-R，一种无需检索的图像地理定位框架，通过强化学习优化地理位置预测，并引入Chain of Region规则化分层推理范式，将GPS坐标映射为可解释的地理实体，提升精度、泛化性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型驱动的图像地理定位方法依赖合成推理标注或外部图像检索，导致可解释性和泛化能力受限。

Method: 提出Chain of Region规则化分层推理范式，将GPS坐标映射为国家、省、市等地理实体；设计基于Haversine距离的坐标对齐奖励机制，采用轻量级强化学习优化模型预测。

Result: 在多个基准测试中显著提升地理定位精度与泛化能力，实现更透明、可解释的推理过程，并建立首个检索无关的地理定位新范式。

Conclusion: Geo-R成功融合结构化地理推理与直接空间监督，为可扩展、可解释的图像地理定位提供了新路径。

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [86] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: 本文提出judgeWEL数据集，利用维基百科和Wikidata作为弱监督源，并结合大语言模型（LLM）进行自动标注与质量筛选，构建了目前规模最大的卢森堡语命名实体识别（NER）数据集。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如卢森堡语）在命名实体识别任务中因资源稀缺、标注成本高且不一致而导致的数据瓶颈问题。

Method: 基于维基百科内部链接与对应Wikidata条目推断实体类型，生成初始标注；再通过多个大语言模型评估并过滤低质量句子，提升标注可靠性。

Result: 构建了约是现有卢森堡语NER数据集五倍大的judgeWEL数据集，在实体类别覆盖更广、分布更均衡。

Conclusion: 该方法为低资源语言NER提供了可扩展、低成本且高质量的数据构建范式，显著拓展了多语言NER研究的资源基础。

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [87] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: 本文提出了一种新的知识表示结构HTKGH，以增强对地缘政治事件中复杂多实体时序事实的建模能力，并基于POLECAT构建了htkgh-polecat数据集，评估了主流大语言模型在关系预测任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有超关系时序知识图谱（HTKGs）无法有效表达涉及两个以上主体的复杂地缘政治事件，限制了其在真实场景中的应用。

Method: 形式化定义了超关系时序知识广义超图（HTKGH），支持两类常见复杂事实；基于POLECAT构建htkgh-polecat数据集；在关系预测任务上对主流大语言模型进行基准测试与分析。

Result: 验证了HTKGH的向后兼容性及其对复杂事实的建模能力；提供了首个面向HTKGH结构的基准数据集；揭示了当前LLMs在复杂时序关系预测中的适应性与局限性。

Conclusion: HTKGH是一种更具表达力的时序知识结构，为地缘政治预测等复杂场景提供了更合适的建模基础，而现有LLMs虽具潜力，仍需针对性优化以更好适配HTKGH。

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [88] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: 本文比较了三种轻量级Transformer模型（DistilBERT、MiniLM和ALBERT）在客户情感分类、新闻主题分类和毒性/仇恨言论检测三个企业NLP任务上的性能与效率，发现各模型在准确率与推理效率上存在权衡：ALBERT精度最高，MiniLM推理最快，DistilBERT综合表现最均衡。


<details>
  <summary>Details</summary>
Motivation: 企业NLP应用对高效、轻量级模型的需求日益增长，亟需在多领域文本自动化任务中评估不同轻量模型的性能-效率权衡。

Method: 在IMDB、AG News和Measuring Hate Speech数据集上，对DistilBERT、MiniLM和ALBERT进行受控微调，并使用准确率、精确率、召回率、F1值及模型大小、推理时间、吞吐量、内存占用等指标进行多维评估。

Result: ALBERT在多个任务上达到最高准确率；MiniLM推理速度与吞吐量最优；DistilBERT跨任务准确率最稳定且效率具竞争力；三者无绝对优势模型。

Conclusion: 应依据企业场景需求选择模型：低延迟场景选MiniLM，平衡性需求选DistilBERT，资源受限环境选ALBERT。

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [89] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: 本文对比了社会建构主义语言游戏观与数学导向的语义场理论，提出词汇场（Lexfelder）和语言场（Lingofelder）作为连续语义空间中的交互结构，并分析其与Transformer架构特性（如分布式表征、注意力机制、嵌入几何规律）的关系；主张数学结构与语言游戏是互补视角，而非互斥，从而厘清纯统计语言模型的适用边界，并推动理论驱动的AI架构发展。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（LLMs）这一新经验背景下，检验长期存在的语言意义理论，特别是调和社会建构主义（语言游戏）与数学化语义理论之间的张力。

Method: 基于作者前期工作，形式化定义词汇场（Lexfelder）和语言场（Lingofelder）为连续语义空间中相互作用的结构，并系统分析Transformer架构的关键特性（分布式表征、注意力机制、嵌入空间几何规律）如何对应并支持这些结构。

Result: LLMs对语义规律的成功建模支持语言具有内在数学结构的观点；而其在语用推理和语境敏感性上的持续缺陷，则印证了哲学语言观所强调的社会具身性与互动 grounding 的必要性。

Conclusion: 数学结构与语言游戏并非竞争关系，而是互补视角；该整合框架既明确了纯统计语言模型的能力边界，也为融合语言学理论与AI架构设计提供了新路径。

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [90] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 本文提出Defensive M2S训练范式，将多轮对话压缩为单轮输入以训练守卫模型，显著降低计算开销（训练token减少93倍，推理token减少94.6%），同时提升攻击检测召回率38.9个百分点。


<details>
  <summary>Details</summary>
Motivation: 守卫模型在LLM部署中至关重要，但处理完整多轮对话历史计算成本高，亟需高效压缩方法。

Method: 提出Multi-turn to Single-turn（M2S）压缩范式，设计三种压缩模板（hyphenize、numberize、pythonize），并在多轮 jailbreak 基准 SafeDialBench 上评估三类守卫模型（LlamaGuard、Nemotron、Qwen3Guard）。

Result: Qwen3Guard+hyphenize 在SafeDialBench上达到93.8%攻击检测召回率，推理token从3231降至173（减少94.6%），训练token从15.7M降至169K（减少93倍），较基线提升38.9个百分点。

Conclusion: M2S压缩是一种高效可行的守卫模型优化技术，可支撑长多轮对话的大规模安全筛查。

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [91] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: 本文研究了基于依存句法的规则化原子句提取方法，分析了复杂句法结构（如关系从句、状语从句、并列结构和被动语态）对提取性能的影响，在WikiSplit数据集上实现了中高程度的准确率，但对句法复杂性敏感。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的原子句提取方法缺乏可解释性，且未系统分析具体句法结构如何导致提取失败。

Method: 在WikiSplit数据集上，使用spaCy实现基于依存句法的规则化原子句提取，并人工构建100组黄金标准原子句，采用ROUGE和BERTScore评估性能。

Result: 系统达到ROUGE-1 F1=0.6714，ROUGE-2 F1=0.478，ROUGE-L F1=0.650，BERTScore F1=0.5898；相对从句、同位结构、并列谓语、状语从句和被动结构最难处理。

Conclusion: 规则化依存句法提取在原子句分解中具有合理准确性，但性能显著受句法复杂性影响，需针对特定难点结构优化。

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [92] [Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends](https://arxiv.org/abs/2601.00536)
*Yuelyu Ji,Zhuochun Li,Rui Meng,Daqing He*

Main category: cs.CL

TL;DR: 本文提出一个四轴框架来分析多跳问答系统中的检索-推理过程，涵盖执行计划、索引结构、下一步控制策略及停止/继续标准，并在多个基准上总结了效果、效率与证据忠实性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有RAG和智能体方法虽性能优异，但其检索-推理过程常隐式化，导致不同模型间的流程选择难以比较。

Method: 以执行过程为分析单元，构建包含执行计划、索引结构、下一步控制（策略与触发）、停止/继续判据的四轴分析框架，并系统映射主流多跳QA系统及其消融实验。

Result: 在HotpotQA、2WikiMultiHopQA、MuSiQue等基准上揭示了有效性、效率与证据忠实性之间的反复权衡；识别出结构感知规划、可迁移控制策略、分布偏移下的鲁棒停止等共性挑战。

Conclusion: 多跳问答中显式建模检索-推理过程至关重要；未来需发展更透明、可控、鲁棒的检索-推理协同机制。

Abstract: Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.

</details>


### [93] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: 本文提出Embedding Consistency Regulation（ECR）框架，通过语义锚点保持紧凑模型嵌入空间的几何结构一致性，无需匹配logits或内部特征，在多语言场景下显著提升小模型的语义保真度与任务性能。


<details>
  <summary>Details</summary>
Motivation: 紧凑模型常因容量受限或多语言数据导致嵌入空间结构坍塌，现有压缩方法仅对齐输出表层，无法维持底层流形结构，引发语义漂移。

Method: ECR首先离线从教师模型嵌入中提取语义锚点，再让紧凑模型学习在这些锚点周围保持一致的几何关系；仅引入轻量投影步骤，不改变解码架构或推理行为。

Result: 在10万样本多语言语料上，ECR稳定训练、跨任务/语言保持语义结构，生成更紧凑且任务对齐的嵌入空间，使低容量模型学习到比基线更清晰的流形；无需教师输出，可独立于蒸馏使用。

Conclusion: ECR有助于紧凑模型更好满足下游任务需求，并在严格效率或隐私约束下更易部署。

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [94] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级、语言无关的多语言ASR系统HLoRA，基于CTC架构与领域自适应，通过LID后验驱动的LoRA路由实现单次解码，无需语言标签，在资源受限设备上显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有大规模多语言ASR模型（如Whisper）计算开销和延迟高，难以部署于边缘设备。

Method: 提出语言无关的分层LoRA-MoE（HLoRA）框架，集成于mHuBERT-CTC模型；采用LID后验驱动的LoRA路由机制，包含共享LoRA（学习语言不变声学表征）与语言特定LoRA专家（建模语言依赖特性）。

Result: 在MSR-86K和MLC-SLM 2025 Challenge数据集上，HLoRA以单次解码达到与先进两阶段方法相当的性能，显著提升低资源多语言ASR的解码效率。

Conclusion: HLoRA实现了真正语言无关、高效、轻量的端到端多语言语音识别，适用于边缘部署。

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [95] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: 本文提出InfoSynth框架，利用信息论原理（KL散度与熵）自动构建新颖、多样且可控难度的推理与编程基准，显著提升生成效率与质量。


<details>
  <summary>Details</summary>
Motivation: 传统人工构建LLM评测基准成本高、耗时长，且现有基准易与训练数据重叠，难以真实评估模型能力，亟需自动化、新颖、多样的基准生成方法。

Method: 提出基于KL散度和熵的信息论指标量化基准的新颖性与多样性；构建端到端流水线，结合遗传算法与迭代代码反馈，从种子数据集自动生成Python编程问题及配套测试用例与解法。

Result: 生成问题的测试用例与解法准确率达97%；合成基准在新颖性与多样性上持续优于原始种子数据集；支持对新颖性/多样性及难度的可控调节。

Conclusion: InfoSynth提供了一种可扩展、自验证的自动化基准构建范式，能高效生成高质量、新颖且多样化的LLM评测基准。

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [96] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: 本文提出了针对中文场景的特定安全基准CSSBench，重点评估轻量级大语言模型在面对中文特有对抗模式（如谐音、拼音、符号分割等）时的安全性，并涵盖六大现实领域，揭示了这些对抗模式对轻量级模型构成的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有安全评估基准主要面向英语，难以捕捉中文恶意查询中特有的对抗模式（如谐音、拼音、符号分割等），导致中文安全评估存在明显缺口，尤其影响成本敏感和端侧部署的轻量级模型。

Method: 构建中文特有安全基准CSSBench，覆盖六大中文常见风险领域（非法活动、隐私泄露、医疗误导、欺诈与仇恨、成人内容、公共与政治安全），组织多类型任务查询，并评估多个主流轻量级LLM的安全表现及过拒绝行为。

Result: 实验表明，中文特有对抗模式对轻量级LLM构成显著安全挑战；CSSBench能有效揭示模型在中文场景下的安全短板与性能退化问题。

Conclusion: CSSBench填补了中文LLM安全评估的空白，为轻量级模型在真实中文场景中的鲁棒部署提供了重要支撑。

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [97] [Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence](https://arxiv.org/abs/2601.00596)
*Sumanth Balaji,Piyush Mishra,Aashraya Sachdeva,Suraj Agrawal*

Main category: cs.CL

TL;DR: 本文提出JourneyBench基准，用于评估大语言模型（LLM）代理在客户支持场景中对多步业务策略的遵循能力，并引入用户旅程覆盖率（UJCS）新指标；实验表明，显式建模策略控制的动态提示代理（DPA）显著提升策略依从性，甚至使较小模型超越更大模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准忽视了代理在复杂、策略驱动任务中对多步政策的遵守、任务依赖处理及对不可预测用户/环境行为的鲁棒性，而传统IVR系统又缺乏灵活性，亟需更可靠的评估手段。

Method: 构建基于图结构的JourneyBench基准，生成多样化真实支持场景；提出用户旅程覆盖率（UJCS）作为策略依从性度量；对比静态提示代理（SPA）与显式建模策略控制的动态提示代理（DPA）在703轮跨三领域对话中的表现。

Result: DPA显著提升策略依从性；GPT-4o-mini在DPA下表现优于GPT-4o；验证了结构化编排对策略执行的关键作用。

Conclusion: 显式策略建模和结构化任务编排对提升LLM代理在客户支持中的可靠性至关重要；JourneyBench为推进AI客服超越传统IVR提供了关键评估资源。

Abstract: Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.

</details>


### [98] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: 本文提出了一种模型无关的轻量级框架，通过重复采样与LLM-as-a-judge（辅以多数投票）相结合，在固定输入场景下为降低大语言模型上下文幻觉提供显式概率保证。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在确定性自动化流程中易产生与提示明确信息矛盾或忽略该信息的上下文幻觉，而此类错误在输入固定、正确性明确的场景中尤为严重。

Method: 形式化定义固定输入与确定性正确性标准的任务；对同一提示在独立上下文窗口中多次生成；用LLM-as-a-judge筛选输出，并通过多数投票增强不完美judge的可靠性；理论推导失败概率的指数衰减界。

Result: 实验表明：在合成噪声judge下的受控抽取任务中，流水线失败率随重复次数指数下降，选中幻觉答案的概率随judge投票数指数下降，与理论预测完全一致。

Conclusion: 该方法无需修改模型权重、解码策略或提示工程，即可在固定输入LLM工作流中将幻觉概率任意降低，具备轻量、模块化和理论可证的优点。

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [99] [Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations](https://arxiv.org/abs/2601.00647)
*QiWei Meng*

Main category: cs.CL

TL;DR: 本文提出Physio-DPO，一种基于物理信息的对齐框架，通过引入能量差感知的目标函数，将蛋白语言模型与热力学稳定性对齐，显著减少结构幻觉，提升生成蛋白的折叠率和结构一致性。


<details>
  <summary>Details</summary>
Motivation: 大型蛋白语言模型虽在生成式蛋白设计中展现潜力，但常产生结构幻觉（即高语言似然但热力学不稳定的序列），而现有对齐方法（如DPO）仅使用二元偏好标签，忽略了物理能量景观的连续性。

Method: 提出Physio-DPO框架，设计一种幅度感知（magnitude-aware）优化目标，根据天然结构与物理扰动难负样本之间的能量差来缩放优化更新。

Result: 实验表明Physio-DPO在多个指标上超越SFT、PPO和标准DPO：自一致性RMSD降至1.28 Å，折叠率提升至92.8%；定性分析显示其能恢复疏水核心堆积和氢键网络等关键生物物理相互作用。

Conclusion: Physio-DPO通过将热力学物理先验融入对齐过程，有效缓解蛋白生成中的结构幻觉问题，为可信赖的生成式蛋白设计提供了新范式。

Abstract: Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.

</details>


### [100] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: 本文提出Fast-weight Product Key Memory (FwPKM)，一种将稀疏Product Key Memory动态化为快速权重式情景记忆的新架构，通过局部块级梯度下降实现训练与推理时的动态参数更新，在保持计算效率的同时显著提升长上下文建模能力。


<details>
  <summary>Details</summary>
Motivation: 解决现代语言模型中序列建模层在存储容量与计算效率之间的权衡问题：Softmax注意力存储无界但计算代价高，线性变体高效但存储固定且有限。

Method: 将静态的稀疏Product Key Memory（PKM）改造为动态的'fast-weight'情景记忆模块FwPKM，使其在训练和推理过程中通过局部chunk-level梯度下降动态更新参数，从而实现对输入序列中键值对的快速记忆与检索。

Result: FwPKM在长上下文数据集上显著降低困惑度；在'Needle in a Haystack'评测中，仅用4K-token训练即能泛化至128K-token上下文。

Conclusion: FwPKM作为一种高效且可动态更新的情景记忆机制，有效补充了模型固有的语义记忆，缓解了容量与效率的矛盾，提升了长程依赖建模能力。

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [101] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 本文提出了一种名为Sigmoid Head的质量估计模块，用于解决语言模型（LM）中softmax输出导致的多正确答案无法同时获得高概率的问题，通过引入sigmoid激活的额外解嵌头，并在负采样中避免选择潜在的正确token，从而提升质量估计的可靠性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 语言模型的概率输出不可靠，因为自然语言具有歧义性，多个输出可能都正确，但softmax强制概率分布集中在单一选项上，且训练数据仅提供单一对齐参考，限制了对多正确答案的建模能力。

Method: 提出Sigmoid Head：一个附加的、使用sigmoid激活的解嵌头；在负采样阶段采用启发式策略避开潜在的正确token；整个方法无需人工标注的质量数据，可直接在预训练LM上训练。

Result: Sigmoid Head输出的概率比原始softmax头更准确地反映生成质量，在计算效率、跨领域鲁棒性及无需监督信号方面均优于现有监督式质量评估方法。

Conclusion: Sigmoid Head是一种轻量、无监督、泛化性强的语言生成质量估计新范式，有效缓解了LM softmax输出在多正确性场景下的质量误判问题。

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [102] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在情感分析、攻击性语言识别和主张验证三种任务中的文本片段识别性能，探索了指令微调、上下文学习和思维链等策略，并发现文本内在关系有助于LLM精确定位文本片段。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于命名实体识别等显式片段识别任务，而主观性更强的基于方面的情感分析（ABSA）等任务中LLM的片段识别能力尚未被充分探索，本文旨在填补这一空白。

Method: 对多种大型语言模型在情感分析、攻击性语言识别和主张验证三个任务上进行文本片段识别评估，采用指令微调、上下文学习和思维链等多种LLM策略。

Result: 实验结果表明，文本内部的潜在关系有助于大型语言模型更准确地识别精确的文本片段。

Conclusion: 大型语言模型在主观性较强的文本片段识别任务中具有潜力，其性能受文本内在结构关系影响显著，相关策略（如思维链、上下文学习）可提升识别精度。

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [103] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: 本文评估了BCCRTron和GatorTron两个预训练Transformer模型在加拿大跨省病理报告自动分类（癌症/非癌症、可上报/不可上报）任务中的泛化能力，提出一种仅共享模型权重的隐私保护跨省适配与集成方法，在纽芬兰与拉布拉多癌症登记处数据上显著提升了召回率并减少了漏检。


<details>
  <summary>Details</summary>
Motivation: 人口癌症登记依赖病理报告，但人工摘录耗时且易延迟；现有基于Transformer的NLP系统在不同地区报告格式差异下的泛化能力尚不明确。

Method: 对BCCRTron（BC省定制模型）和GatorTron（通用生物医学模型）在纽芬兰与拉布拉多癌症登记处（NLCR）约10.4万和2.2万份脱敏病理报告上进行微调，采用合成式与诊断焦点两种文本输入流程，并构建保守OR集成策略。

Result: 集成模型在Tier 1任务中召回率达0.99（漏检癌数降至24例），Tier 2任务中召回率亦达0.99（漏检可上报癌数降至33例）；仅共享模型权重实现跨省隐私保护协作。

Conclusion: 预训练Transformer模型可通过少量微调跨省迁移；互补文本表征的集成显著降低漏检，支持构建泛加拿大的隐私优先癌症登记NLP基础设施。

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [104] [μACP: A Formal Calculus for Expressive, Resource-Constrained Agent Communication](https://arxiv.org/abs/2601.00219)
*Arnab Mallick,Indraveni Chebolu*

Main category: cs.MA

TL;DR: 本文提出μACP，一种在明确资源限制下支持表达性智能体通信的正式演算，通过四动词基础集（PING、TELL、ASK、OBSERVE）编码FIPA协议，建立消息复杂度的信息论紧界，并在部分同步与崩溃故障下实现共识；经TLA⁺和Coq形式验证确保安全性与有界性，大规模仿真显示其在严苛资源约束下优于现有协议。


<details>
  <summary>Details</summary>
Motivation: Agent通信在多智能体系统中至关重要，但现有协议如FIPA-ACL语义丰富却不可行于受限环境，而轻量级IoT协议虽高效却牺牲表达力，亟需兼顾表达性与效率的统一框架。

Method: 提出μACP形式演算，构建资源受限智能体通信（RCAC）模型；证明四动词集足以编码有限状态FIPA协议；推导消息复杂度的信息论紧界；在TLA⁺和Coq中进行形式验证；开展大规模系统仿真评估性能。

Result: μACP可在部分同步与崩溃故障下实现标准共识；形式验证确认安全性和有界性，并在建模假设下支持活性；仿真显示其中位端到端消息延迟为34 ms（95百分位104 ms），在严苛资源约束下优于现有协议。

Conclusion: μACP为资源受限多智能体系统提供了统一、严谨的基础：首次在保证语义表达力的同时，实现可证明的通信效率与形式化保障，推动边缘原生智能体协调框架的发展。

Abstract: Agent communication remains a foundational problem in multi-agent systems: protocols such as FIPA-ACL guarantee semantic richness but are intractable for constrained environments, while lightweight IoT protocols achieve efficiency at the expense of expressiveness. This paper presents $μ$ACP, a formal calculus for expressive agent communication under explicit resource bounds. We formalize the Resource-Constrained Agent Communication (RCAC) model, prove that a minimal four-verb basis \textit{\{PING, TELL, ASK, OBSERVE\}} is suffices to encode finite-state FIPA protocols, and establish tight information-theoretic bounds on message complexity. We further show that $μ$ACP can implement standard consensus under partial synchrony and crash faults, yielding a constructive coordination framework for edge-native agents. Formal verification in TLA$^{+}$ (model checking) and Coq (mechanized invariants) establishes safety and boundedness, and supports liveness under modeled assumptions. Large-scale system simulations confirm ACP achieves a median end-to-end message latency of 34 ms (95th percentile 104 ms) at scale, outperforming prior agent and IoT protocols under severe resource constraints. The main contribution is a unified calculus that reconciles semantic expressiveness with provable efficiency, providing a rigorous foundation for the next generation of resource-constrained multi-agent systems.

</details>


### [105] [Offline Multi-Agent Reinforcement Learning for 6G Communications: Fundamentals, Applications and Future Directions](https://arxiv.org/abs/2601.00321)
*Eslam Eldeeb,Hirley Alves*

Main category: cs.MA

TL;DR: 本文提出了一种基于保守Q学习（CQL）的新型离线多智能体强化学习（MARL）算法，并结合元学习以适应动态无线环境，在无线电资源管理和无人机网络中验证了其安全高效性。


<details>
  <summary>Details</summary>
Motivation: 随着5G之后及6G网络发展，无线网络日益复杂，传统在线强化学习在多智能体场景下面临成本高、安全性差和可扩展性不足等问题。

Method: 提出基于保守Q学习（CQL）的离线多智能体强化学习算法，并融合元学习以应对动态环境；在无线电资源管理与无人机网络两个典型用例中进行验证。

Result: 所提算法在保证训练安全性的同时提升了效率，成功应用于无线资源管理和UAV网络等场景，验证了离线MARL在实际无线系统中的可行性与优势。

Conclusion: 离线MARL为未来无线网络提供了安全、高效且可扩展的决策范式，但仍面临数据质量、泛化能力与部署适配等挑战，需进一步探索。

Abstract: The next-generation wireless technologies, including beyond 5G and 6G networks, are paving the way for transformative applications such as vehicle platooning, smart cities, and remote surgery. These innovations are driven by a vast array of interconnected wireless entities, including IoT devices, access points, UAVs, and CAVs, which increase network complexity and demand more advanced decision-making algorithms. Artificial intelligence (AI) and machine learning (ML), especially reinforcement learning (RL), are key enablers for such networks, providing solutions to high-dimensional and complex challenges. However, as networks expand to multi-agent environments, traditional online RL approaches face cost, safety, and scalability limitations. Offline multi-agent reinforcement learning (MARL) offers a promising solution by utilizing pre-collected data, reducing the need for real-time interaction. This article introduces a novel offline MARL algorithm based on conservative Q-learning (CQL), ensuring safe and efficient training. We extend this with meta-learning to address dynamic environments and validate the approach through use cases in radio resource management and UAV networks. Our work highlights offline MARL's advantages, limitations, and future directions in wireless applications.

</details>


### [106] [Mapping Human Anti-collusion Mechanisms to Multi-agent AI](https://arxiv.org/abs/2601.00360)
*Jamiu Adekunle Idowu,Ahmed Almasoud,Ayman Alfahid*

Main category: cs.MA

TL;DR: 本文构建了人类反共谋机制的分类法，并将其映射到多智能体AI系统中，提出相应的干预措施，并指出了在AI环境中应用这些机制所面临的若干关键挑战。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体AI系统日益自主化，其可能发展出类似人类市场中的共谋策略；而人类长期积累的反共谋机制尚不清楚如何适配AI场景，存在研究空白。

Method: （i）构建人类反共谋机制的分类法（包括制裁、宽大处理与举报、监控与审计、市场设计、治理）；（ii）将各类机制映射至多智能体AI系统，为每类提出具体实施路径。

Result: 提出了面向AI系统的反共谋机制映射框架及初步实现方案，并识别出四大核心挑战：归因难题、身份流动性、边界问题和对抗性适应。

Conclusion: 人类反共谋经验可为AI治理提供重要借鉴，但需针对AI特性（如代理可复制性、行为涌现性）进行根本性重构，不能简单移植。

Abstract: As multi-agent AI systems become increasingly autonomous, evidence shows they can develop collusive strategies similar to those long observed in human markets and institutions. While human domains have accumulated centuries of anti-collusion mechanisms, it remains unclear how these can be adapted to AI settings. This paper addresses that gap by (i) developing a taxonomy of human anti-collusion mechanisms, including sanctions, leniency & whistleblowing, monitoring & auditing, market design, and governance and (ii) mapping them to potential interventions for multi-agent AI systems. For each mechanism, we propose implementation approaches. We also highlight open challenges, such as the attribution problem (difficulty attributing emergent coordination to specific agents) identity fluidity (agents being easily forked or modified) the boundary problem (distinguishing beneficial cooperation from harmful collusion) and adversarial adaptation (agents learning to evade detection).

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [107] [Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems](https://arxiv.org/abs/2601.00005)
*Lesley Wheat,Martin v. Mohrenschildt,Saeid Habibi*

Main category: cs.LG

TL;DR: 本文通过构建一个反映真实工程约束的合成数据集，对14种异常检测算法在极端类别不平衡条件下的性能进行了系统评估，发现检测器性能高度依赖于训练集中故障样本的绝对数量，并据此提出了适用于工业场景的实用部署建议。


<details>
  <summary>Details</summary>
Motivation: 工业系统中机器学习面临的主要挑战之一是极端类别不平衡，尤其是故障样本稀缺，导致现有异常检测方法在实际应用中效果受限。

Method: 使用基于超球面分布的2D和10D合成数据集，系统性地评估14种异常检测算法；训练数据异常率设为0.05%–20%，样本量为1000–10000，测试集固定为40000；分析不同故障样本数量和特征维度下各类方法（无监督、半监督、有监督）的性能与泛化误差。

Result: 当故障样本少于20个时，无监督方法（kNN/LOF）最优；30–50个时，半监督（XGBOD）和有监督方法（SVM/CatBoost）性能显著提升；10维特征下半监督方法优势明显，而2维时不显著；整体泛化性能随训练数据规模减小而明显下降。

Conclusion: 异常检测器的选择应优先依据训练中可用的故障样本绝对数量而非比例；工业部署中应重视小样本下的泛化能力，且高维特征更利于半监督方法发挥优势。

Abstract: Machine learning offers potential solutions to current issues in industrial systems in areas such as quality control and predictive maintenance, but also faces unique barriers in industrial applications. An ongoing challenge is extreme class imbalance, primarily due to the limited availability of faulty data during training. This paper presents a comprehensive evaluation of anomaly detection algorithms using a problem-agnostic simulated dataset that reflects real-world engineering constraints. Using a synthetic dataset with a hyper-spherical based anomaly distribution in 2D and 10D, we benchmark 14 detectors across training datasets with anomaly rates between 0.05% and 20% and training sizes between 1 000 and 10 000 (with a testing dataset size of 40 000) to assess performance and generalization error. Our findings reveal that the best detector is highly dependant on the total number of faulty examples in the training dataset, with additional healthy examples offering insignificant benefits in most cases. With less than 20 faulty examples, unsupervised methods (kNN/LOF) dominate; but around 30-50 faulty examples, semi-supervised (XGBOD) and supervised (SVM/CatBoost) detectors, we see large performance increases. While semi-supervised methods do not show significant benefits with only two features, the improvements are evident at ten features. The study highlights the performance drop on generalization of anomaly detection methods on smaller datasets, and provides practical insights for deploying anomaly detection in industrial environments.

</details>


### [108] [Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games](https://arxiv.org/abs/2601.00007)
*Nicholas A. Pape*

Main category: cs.LG

TL;DR: 本文将经典骰子游戏Yahtzee建模为马尔可夫决策过程，通过多种策略梯度方法（REINFORCE、A2C、PPO）训练自博弈智能体，并系统分析各设计选择对性能的影响；结果表明A2C最稳健，达到接近最优得分（95%），但所有模型在长程信用分配和上区奖励策略学习上仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: Yahtzee具有随机性、组合结构和延迟奖励特性，是中等规模强化学习的有趣基准；单人版可用动态规划求解，但多人版不可行，需近似方法；现有RL方法在该任务上的表现与关键挑战尚不明确。

Method: 将Yahtzee形式化为MDP；采用共享主干+多头网络架构，对比REINFORCE、A2C和PPO三种策略梯度算法；进行消融实验，涵盖特征/动作编码、网络结构、回报估计器和熵正则化等设计因素。

Result: 在固定训练预算下，A2C表现最稳健，REINFORCE和PPO对超参数敏感且性能较差；最终智能体在10万局测试中取得中位数241.78分（达最优DP分数254.59的95%），上区奖励触发率24.9%，Yahtzee达成率34.1%；所有模型均难以学会上区奖励策略，过度依赖四条策略。

Conclusion: A2C在Yahtzee任务中展现出更强的鲁棒性和可训练性；但长时程信用分配与探索问题（尤其上区奖励策略）仍是当前RL方法的关键瓶颈，凸显了该环境作为基准的价值。

Abstract: Yahtzee is a classic dice game with a stochastic, combinatorial structure and delayed rewards, making it an interesting mid-scale RL benchmark. While an optimal policy for solitaire Yahtzee can be computed using dynamic programming methods, multiplayer is intractable, motivating approximation methods. We formulate Yahtzee as a Markov Decision Process (MDP), and train self-play agents using various policy gradient methods: REINFORCE, Advantage Actor-Critic (A2C), and Proximal Policy Optimization (PPO), all using a multi-headed network with a shared trunk. We ablate feature and action encodings, architecture, return estimators, and entropy regularization to understand their impact on learning. Under a fixed training budget, REINFORCE and PPO prove sensitive to hyperparameters and fail to reach near-optimal performance, whereas A2C trains robustly across a range of settings. Our agent attains a median score of 241.78 points over 100,000 evaluation games, within 5.0\% of the optimal DP score of 254.59, achieving the upper section bonus and Yahtzee at rates of 24.9\% and 34.1\%, respectively. All models struggle to learn the upper bonus strategy, overindexing on four-of-a-kind's, highlighting persistent long-horizon credit-assignment and exploration challenges.

</details>


### [109] [The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065)
*Xiaoze Liu,Weichen Yu,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.LG

TL;DR: 本文提出了一种针对LLM tokenizer移植过程的新型供应链攻击：通过构造一个在源模型中无害、但在移植到目标模型后激活恶意行为的'breaker token'，利用嵌入空间几何特性实现隐蔽、鲁棒的攻击。


<details>
  <summary>Details</summary>
Motivation: 随着开放权重大模型生态中模型组合技术（如权重合并、推测解码、词表扩展）的普及，tokenizer移植成为跨模型家族互操作的关键步骤；但该步骤存在未被重视的供应链安全风险。

Method: 将攻击建模为双目标优化问题，利用稀疏求解器构造功能上在源模型中惰性、但在目标模型中能重建高显著性恶意特征的'breaker token'， exploiting coefficient reuse geometry。

Result: 攻击无需训练，具备频谱拟合能力以规避异常检测，并对微调和权重合并具有结构鲁棒性；实证验证了其在多种模型组合场景下的有效性。

Conclusion: tokenizer移植环节存在严重且隐蔽的安全隐患，威胁模块化AI组合生态的安全性，需在模型互操作标准与工具链中引入新的安全验证机制。

Abstract: The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single "breaker token" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge

</details>


### [110] [Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings](https://arxiv.org/abs/2601.00186)
*Moirangthem Tiken Singh,Adnan Arif*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习的自适应重复编码框架，实现按维度不等错误保护，通过复合语义失真度量平衡全局嵌入相似性与实体级保真度，在低信噪比下显著提升语义通信性能，并挑战了传统信道编码范式。


<details>
  <summary>Details</summary>
Motivation: 在带宽受限的通信系统中保持语义含义完整性是一个紧迫挑战，尤其在边缘计算和物联网等场景中，带宽稀缺但语义保真度至关重要。

Method: 引入一种新颖的强化学习框架，采用自适应重复编码实现每维不等错误保护；设计复合语义失真度量，兼顾全局嵌入相似性与实体级语义保留，使智能体能上下文感知地分配保护资源。

Result: 实验表明相比均匀保护，该方法在1 dB SNR下chrF得分提高6.8%，实体保留率提升9.3%；验证了简单但智能分配的重复编码可实现细粒度语义保护，优于LDPC或里德-所罗门等传统码。

Conclusion: 代码结构必须与语义粒度对齐，这一发现挑战了传统信道编码范式；所提框架为下一代语义感知网络提供了实用可行的技术路径。

Abstract: This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.

</details>


### [111] [IMBWatch -- a Spatio-Temporal Graph Neural Network approach to detect Illicit Massage Business](https://arxiv.org/abs/2601.00075)
*Swetha Varadarajan,Abhishek Ray,Lumina Albert*

Main category: cs.LG

TL;DR: 本文提出IMBWatch，一种基于时空图神经网络的框架，用于大规模检测非法按摩院（IMBs），通过整合多源开放情报构建动态异构图，建模其时空演化模式，显著提升检测性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 非法按摩院隐蔽性强、运营网络复杂，传统依赖社区举报和监管检查的方法反应滞后、难以发现其深层关联网络。

Method: 提出IMBWatch框架，构建融合线上广告、营业执照、众包评论等数据的动态异构时空图，节点包括企业、别名、电话、地址等，边刻画共址、电话复用、广告同步等关系；采用图卷积与时间注意力机制联合建模网络演化。

Result: 在多个美国城市真实数据集上实验表明，IMBWatch在准确率和F1分数上均优于基线模型，并具备良好可解释性与可扩展性。

Conclusion: IMBWatch为打击人口贩卖与非法劳工提供了可扩展、可复现、可迁移的AI驱动解决方案，推动从被动响应转向主动干预。

Abstract: Illicit Massage Businesses (IMBs) are a covert and persistent form of organized exploitation that operate under the facade of legitimate wellness services while facilitating human trafficking, sexual exploitation, and coerced labor. Detecting IMBs is difficult due to encoded digital advertisements, frequent changes in personnel and locations, and the reuse of shared infrastructure such as phone numbers and addresses. Traditional approaches, including community tips and regulatory inspections, are largely reactive and ineffective at revealing the broader operational networks traffickers rely on.
  To address these challenges, we introduce IMBWatch, a spatio-temporal graph neural network (ST-GNN) framework for large-scale IMB detection. IMBWatch constructs dynamic graphs from open-source intelligence, including scraped online advertisements, business license records, and crowdsourced reviews. Nodes represent heterogeneous entities such as businesses, aliases, phone numbers, and locations, while edges capture spatio-temporal and relational patterns, including co-location, repeated phone usage, and synchronized advertising. The framework combines graph convolutional operations with temporal attention mechanisms to model the evolution of IMB networks over time and space, capturing patterns such as intercity worker movement, burner phone rotation, and coordinated advertising surges.
  Experiments on real-world datasets from multiple U.S. cities show that IMBWatch outperforms baseline models, achieving higher accuracy and F1 scores. Beyond performance gains, IMBWatch offers improved interpretability, providing actionable insights to support proactive and targeted interventions. The framework is scalable, adaptable to other illicit domains, and released with anonymized data and open-source code to support reproducible research.

</details>


### [112] [Exploration in the Limit](https://arxiv.org/abs/2601.00084)
*Brian M. Cho,Nathan Kallus*

Main category: cs.LG

TL;DR: 本文提出了一种面向固定置信度最佳臂识别（BAI）的渐近松弛框架，通过构建任意时刻有效的置信序列，在非参数、带协变量设定下实现更紧的样本复杂度和近似误差控制。


<details>
  <summary>Details</summary>
Motivation: 现有BAI方法在实践中受限于严格误差控制所需的松散尾部不等式或参数假设，难以应对弱信号、高显著性要求及后验推断等现实场景。

Method: 提出渐近误差控制新范式；构造基于臂索引的渐近任意时刻有效置信序列；设计融合协变量以降方差的新BAI算法；在非参数设定下保证近似错误率控制。

Result: 在温和收敛假设下给出渐近样本复杂度界；最坏情况样本复杂度匹配已知方差高斯BAI的最佳情况复杂度；实验显示平均样本复杂度降低且误差可控。

Conclusion: 所提渐近框架兼顾理论最优性与实践灵活性，为非参数、上下文相关BAI提供了更实用、更高效的新路径。

Abstract: In fixed-confidence best arm identification (BAI), the objective is to quickly identify the optimal option while controlling the probability of error below a desired threshold. Despite the plethora of BAI algorithms, existing methods typically fall short in practical settings, as stringent exact error control requires using loose tail inequalities and/or parametric restrictions. To overcome these limitations, we introduce a relaxed formulation that requires valid error control asymptotically with respect to a minimum sample size. This aligns with many real-world settings that often involve weak signals, high desired significance, and post-experiment inference requirements, all of which necessitate long horizons. This allows us to achieve tighter optimality, while better handling flexible nonparametric outcome distributions and fully leveraging individual-level contexts. We develop a novel asymptotic anytime-valid confidence sequences over arm indices, and we use it to design a new BAI algorithm for our asymptotic framework. Our method flexibly incorporates covariates for variance reduction and ensures approximate error control in fully nonparametric settings. Under mild convergence assumptions, we provide asymptotic bounds on the sample complexity and show the worst-case sample complexity of our approach matches the best-case sample complexity of Gaussian BAI under exact error guarantees and known variances. Experiments suggest our approach reduces average sample complexities while maintaining error control.

</details>


### [113] [TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications](https://arxiv.org/abs/2601.00691)
*Mohamed Trabelsi,Huseyin Uzunalioglu*

Main category: cs.LG

TL;DR: 本文提出了TeleDoCTR，一个面向电信领域的端到端工单排障系统，融合领域专用排序与生成模型，实现工单分类、相似历史工单检索和故障分析报告生成，显著提升排障准确率与效率。


<details>
  <summary>Details</summary>
Motivation: 电信领域工单排障高度依赖专家人工处理，耗时长、效率低，亟需自动化解决方案以提升运维效率。

Method: 提出TeleDoCTR系统，集成领域专用的排序模型（用于工单路由分类）和生成模型（用于检索相似历史工单及生成故障分析报告），实现端到端工单排障。

Result: 在真实电信基础设施数据集上验证，TeleDoCTR性能优于现有最先进方法，显著提升排障准确性与效率。

Conclusion: TeleDoCTR有效解决了电信领域工单排障中人工依赖强、效率低的问题，为垂直领域智能运维提供了可落地的AI解决方案。

Abstract: Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.

</details>


### [114] [Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery](https://arxiv.org/abs/2601.00088)
*Junqi Qu,Yan Zhang,Shangqian Gao,Shibo Li*

Main category: cs.LG

TL;DR: 本文提出NeuroSymBO方法，将提示工程重构为序列决策问题，利用贝叶斯优化根据数值反馈动态选择最优推理策略，显著提升偏微分方程发现任务中的方程恢复率与解的简洁性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在方程发现中存在指令脆性问题，即输出对提示措辞高度敏感，静态提示无法适应多步生成过程的动态变化，导致模型陷入次优解。

Method: 提出NeuroSymBO方法，维护一个离散的推理策略库，并使用贝叶斯优化在每一步基于数值反馈选择最优提示指令。

Result: 在PDE发现基准测试中，自适应指令选择显著优于固定提示，在恢复率和解的简洁性上均有提升。

Conclusion: 将提示工程建模为序列决策问题并引入贝叶斯优化进行动态指令选择，可有效缓解LLMs在方程发现任务中的指令脆性问题。

Abstract: Large Language Models (LLMs) show promise for equation discovery, yet their outputs are highly sensitive to prompt phrasing, a phenomenon we term instruction brittleness. Static prompts cannot adapt to the evolving state of a multi-step generation process, causing models to plateau at suboptimal solutions. To address this, we propose NeuroSymBO, which reframes prompt engineering as a sequential decision problem. Our method maintains a discrete library of reasoning strategies and uses Bayesian Optimization to select the optimal instruction at each step based on numerical feedback. Experiments on PDE discovery benchmarks show that adaptive instruction selection significantly outperforms fixed prompts, achieving higher recovery rates with more parsimonious solutions.

</details>


### [115] [GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments](https://arxiv.org/abs/2601.00116)
*Aditya Sai Ellendula,Yi Wang,Minh Nguyen,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: 本文提出了GRL-SNAM，一种基于几何强化学习的同步导航与建图（SNAM）框架，通过局部感官观测和受控哈密顿优化实现无地图环境下的高效导航，无需构建全局地图。


<details>
  <summary>Details</summary>
Motivation: 解决未知无地图环境中多智能体协同导航与建图的挑战，避免依赖全局地图构建，提升实时性与泛化能力。

Method: 将导航与建图建模为动态最短路径搜索问题，利用受控哈密顿优化将局部感官输入转化为能量景观，通过更新哈密顿量分阶段演化感知、规划与重构策略，并以约化哈密顿量作为自适应评分函数持续优化轨迹。

Result: 在两类2D导航任务中，相比局部反应式基线和全局策略学习方法，GRL-SNAM保持安全间距、泛化至未见布局，并验证了基于局部能量精炼的几何强化学习可实现低探索开销的高质量导航。

Conclusion: GRL-SNAM证明了仅依赖局部观测与哈密顿动力学更新的几何强化学习范式，在SNAM任务中具备可行性与优越性，为无地图自主导航提供了新思路。

Abstract: We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.

</details>


### [116] [Reinforcement Learning with Function Approximation for Non-Markov Processes](https://arxiv.org/abs/2601.00151)
*Ali Devran Kara*

Main category: cs.LG

TL;DR: 本文研究了在非马尔可夫状态和成本过程下，使用线性函数逼近的强化学习方法，分析了策略评估与Q学习的收敛性，并将其应用于部分可观测马尔可夫决策过程（POMDP）中，给出了有限记忆状态表示下的显式误差界。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习理论多基于马尔可夫假设，而现实中的许多问题（如POMDP）本质上是非马尔可夫的；本文旨在拓展线性函数逼近方法的理论基础至更一般的非马尔可夫设定。

Method: 采用基于正交投影与辅助马尔可夫决策过程贝尔曼算子联合构造的算子分析框架；对策略评估证明其在非马尔可夫遍历条件下的收敛性；对Q学习，在量化映射选取基函数的特殊情形下建立收敛性；最后将理论应用于带有限记忆状态表示的POMDP。

Result: 1) 策略评估算法在非马尔可夫遍历条件下收敛，极限为某联合算子的不动点；2) 特定基函数（量化映射）下Q学习可证收敛；3) 在POMDP中导出学习算法极限的显式误差界。

Conclusion: 线性函数逼近的强化学习方法可在适当遍历性条件下推广至非马尔可夫设定；其理论分析可通过关联一个辅助马尔可夫过程实现；该框架为POMDP等实际非马尔可夫问题提供了可分析且具误差保证的学习方案。

Abstract: We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \emph{Markov} decision process.
  For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.

</details>


### [117] [The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data](https://arxiv.org/abs/2601.00152)
*Yann Bellec,Rohan Kaman,Siwen Cui,Aarav Agrawal,Calvin Chen*

Main category: cs.LG

TL;DR: 本研究利用2016–2023年美国50万起交通事故数据，构建XGBoost分类器预测事故严重程度，准确率达78%；发现时间、地理位置及部分天气变量（如温度、风速）是关键预测因子，而降水和能见度影响有限；数据中中等严重度样本占主导，制约极端案例建模效果，需改进采样与特征工程。


<details>
  <summary>Details</summary>
Motivation: 探究环境、时间和空间因素对美国交通事故严重程度的预测能力，以支持基于证据的交通管理决策。

Method: 采用XGBoost分类器，通过随机搜索交叉验证优化超参数，并使用类别权重缓解类别不平衡问题；基于50万起事故数据训练模型，结合特征重要性分析识别关键预测因子。

Result: 模型整体准确率为78%，对主流严重度等级（Severity 2）达到87%的精确率和召回率；时间、地理位置及温度、风速等天气变量为最重要预测因子，而降水和能见度预测作用较弱。

Conclusion: 当前模型在中等严重度事故预测上表现良好，但对极端严重事故泛化能力受限，主要源于数据分布偏差；未来需改进采样策略、加强特征工程并融合外部数据以提升预测鲁棒性。

Abstract: This study investigates the predictive capacity of environmental, temporal, and spatial factors on traffic accident severity in the United States. Using a dataset of 500,000 U.S. traffic accidents spanning 2016-2023, we trained an XGBoost classifier optimized through randomized search cross-validation and adjusted for class imbalance via class weighting. The final model achieves an overall accuracy of 78%, with strong performance on the majority class (Severity 2), attaining 87% precision and recall. Feature importance analysis reveals that time of day, geographic location, and weather-related variables, including visibility, temperature, and wind speed, rank among the strongest predictors of accident severity. However, contrary to initial hypotheses, precipitation and visibility demonstrate limited predictive power, potentially reflecting behavioral adaptation by drivers under overtly hazardous conditions. The dataset's predominance of mid-level severity accidents constrains the model's capacity to learn meaningful patterns for extreme cases, highlighting the need for alternative sampling strategies, enhanced feature engineering, and integration of external datasets. These findings contribute to evidence-based traffic management and suggest future directions for severity prediction research.

</details>


### [118] [Online Finetuning Decision Transformers with Pure RL Gradients](https://arxiv.org/abs/2601.00167)
*Junkai Luo,Yinglun Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种纯强化学习梯度驱动的Decision Transformer在线微调方法，解决了传统基于后见之明回报重标注（hindsight return relabeling）导致与重要性采样类RL算法（如GRPO）不兼容的问题，并通过子轨迹优化、序列级似然目标和主动采样等改进，在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有Decision Transformer在线微调仍严重依赖监督式序列建模目标，难以利用纯RL梯度；而标准的后见之明回报重标注虽利于监督学习，却与重要性采样类RL算法（如GRPO）不兼容，导致训练不稳定。

Method: 提出适配GRPO的Decision Transformer在线微调新算法，包含三项关键改进：子轨迹优化以提升信用分配、序列级似然目标以增强训练稳定性与效率、主动采样以促进对不确定性区域的探索。

Result: 在多个基准测试中显著优于现有在线DT基线，取得新的SOTA性能。

Conclusion: 纯强化学习梯度驱动的在线微调是提升Decision Transformer性能的有效路径，关键在于规避监督式重标注带来的兼容性问题并设计适配序列决策结构的RL优化机制。

Abstract: Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.

</details>


### [119] [Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting](https://arxiv.org/abs/2601.00172)
*Ata Akbari Asanjan,Filip Wudarski,Daniel O'Connor,Shaun Geaney,Elena Strbac,P. Aaron Lott,Davide Venturelli*

Main category: cs.LG

TL;DR: 本文提出了一种顺序储层计算（Sequential RC）架构，通过将大储层分解为多个小而互连的储层，显著提升了高维时空系统预测的效率与精度，同时大幅降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 传统RNN和LSTM在高维时空系统预测中面临梯度训练困难和内存瓶颈；常规储层计算（RC）虽缓解了部分问题，但仍难以随输入维度扩展。

Method: 提出Sequential RC架构：将大型储层分解为一系列小型、相互连接的子储层，避免反向传播，采用固定递归层加凸优化读出层。

Result: 在Lorenz63、2D涡度和浅水方程等任务上，相比LSTM和标准RNN，有效预报时长提升15–25%，SSIM和RMSE误差降低20–30%，训练成本降低达三个数量级。

Conclusion: Sequential RC在保持传统RC简洁高效优势的同时，显著提升了对高维动力系统的可扩展性，为科学与工程中的实时、节能预测提供了可行路径。

Abstract: Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.

</details>


### [120] [Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score](https://arxiv.org/abs/2601.00175)
*Zhuqi Miao,Sujan Ravi,Abdulaziz Ahmed*

Main category: cs.LG

TL;DR: 本研究开发并评估了基于电子健康记录（EHR）数据的机器学习模型，用于提前1、2、3年预测脂肪肝患者发生肝硬化的风险，并证明其性能显著优于传统FIB-4评分。


<details>
  <summary>Details</summary>
Motivation: 现有临床工具（如FIB-4）对肝硬化的早期预测能力有限，亟需利用丰富但未被充分利用的EHR数据构建更精准、可部署的风险预测模型。

Method: 基于大型学术医疗系统的去标识化EHR数据，构建回顾性队列；使用ICD编码定义肝硬化与非肝硬化组；按不同观察窗/预测窗提取人口统计学、诊断、检验、生命体征及共病指数等特征；采用XGBoost训练1/2/3年预测模型，并以AUC与FIB-4对比评估。

Result: XGBoost模型在1年、2年、3年预测中AUC分别为0.81、0.73、0.69，均显著高于FIB-4的0.71、0.63、0.57；性能优势随预测时间延长仍保持，表明其具备更好早期风险识别能力。

Conclusion: 基于常规EHR数据的机器学习模型能显著提升肝硬化的早期预测准确性，具备临床转化潜力，可作为自动化决策支持工具嵌入工作流，助力主动预防和管理。

Abstract: Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.

</details>


### [121] [SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification](https://arxiv.org/abs/2601.00189)
*Danial Sharifrazi,Nouman Javed,Mojtaba Mohammadi,Seyede Sana Salehi,Roohallah Alizadehsani,Prasad N. Paradkar,U. Rajendra Acharya,Asim Bhatti*

Main category: cs.LG

TL;DR: 本文提出了一种半监督的Swin启发式生成对抗网络（SSI-GAN），用于在极少量标注数据（仅1%-3%）下对蚊子神经元放电模式进行分类，以检测寨卡、登革热等病毒的神经趋向性，准确率达99.93%，大幅降低人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 解决蚊媒病毒疾病中神经元放电模式人工分类耗时昂贵、现有深度学习方法依赖大量标注和高度预处理数据、难以在实地大规模应用的问题。

Method: 提出半监督Swim启发式GAN（SSI-GAN）：采用基于Swin的移窗判别器与Transformer生成器；判别器使用多头自注意力机制的扁平窗口式Transformer，捕获稀疏高频放电特征；仅用1%-3%标注数据，在超1500万放电样本上训练；结合贝叶斯优化（Optuna）调参，并通过五折蒙特卡洛交叉验证评估鲁棒性。

Result: 在感染后第3天仅用3%标注数据即达99.93%分类精度；仅1%标注数据仍保持高精度；相较全监督方法减少97-99%人工标注工作量；性能全面超越所有基线模型。

Conclusion: SSI-GAN显著缓解了神经电生理数据分析中标注稀缺瓶颈，为野外实时病毒监测提供了高效、低依赖的AI解决方案，其移窗Transformer设计为神经信号分类树立了新基准。

Abstract: Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.

</details>


### [122] [Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework](https://arxiv.org/abs/2601.00192)
*Moirangthem Tiken Singh,Manibhushan Yaikhom*

Main category: cs.LG

TL;DR: 本文提出一种面向边缘设备的轻量级心律失常检测框架，通过融合小波时频分解与图论结构描述符（如PageRank中心性）进行特征工程，并结合互信息筛选和递归消除，构建可解释的超轻量线性分类器，在MIT-BIH和INCART数据集上实现98.44%准确率、8.54 KB模型大小和0.46微秒推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法计算开销大，难以部署于资源受限的医疗物联网边缘设备，亟需高效、低功耗、实时的心律失常监测方案。

Method: 提出以数据为中心的轻量框架：采用小波时频分解提取信号特征，结合图论结构性描述符（如PageRank中心性）建模信号动态结构；再利用互信息和递归特征消除优化特征子集，最终训练超轻量线性分类器。

Result: 在MIT-BIH和INCART数据集上达到98.44%诊断准确率，模型仅8.54 KB，单次推理延迟0.46微秒，整拍处理耗时52 ms；相比KD-Light等压缩模型（25 KB，96.32%），效率提升一个数量级。

Conclusion: 该方法通过强化特征工程而非模型复杂度，实现了高精度、超轻量、可解释且实时的心律失常检测，为无电池心脏传感器提供了可行技术路径。

Abstract: Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $μ$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.

</details>


### [123] [Unknown Aware AI-Generated Content Attribution](https://arxiv.org/abs/2601.00218)
*Ellie Thieu,Jifan Zhang,Haoyue Bai*

Main category: cs.LG

TL;DR: 本文研究如何识别生成图像的具体模型来源，提出一种利用互联网未标注数据的约束优化方法，显著提升了对未知生成模型的归因性能。


<details>
  <summary>Details</summary>
Motivation: 随着逼真生成模型的快速发展，需要从简单的真假检测转向识别具体生成模型，但现有方法难以泛化到未知或新发布的生成模型。

Method: 基于CLIP特征和线性分类器构建基线，并提出一种约束优化方法：利用互联网采集的未标注野生数据，强制其被分类为非目标模型，同时保持标注数据上的高性能。

Result: 实验表明，引入野生未标注数据可显著提升对挑战性未知生成模型的归因性能。

Conclusion: 未标注的野生数据可有效用于开放世界下的AI生成内容归因任务，提升模型对未知生成器的泛化能力。

Abstract: The rapid advancement of photorealistic generative models has made it increasingly important to attribute the origin of synthetic content, moving beyond binary real or fake detection toward identifying the specific model that produced a given image. We study the problem of distinguishing outputs from a target generative model (e.g., OpenAI Dalle 3) from other sources, including real images and images generated by a wide range of alternative models. Using CLIP features and a simple linear classifier, shown to be effective in prior work, we establish a strong baseline for target generator attribution using only limited labeled data from the target model and a small number of known generators. However, this baseline struggles to generalize to harder, unseen, and newly released generators. To address this limitation, we propose a constrained optimization approach that leverages unlabeled wild data, consisting of images collected from the Internet that may include real images, outputs from unknown generators, or even samples from the target model itself. The proposed method encourages wild samples to be classified as non target while explicitly constraining performance on labeled data to remain high. Experimental results show that incorporating wild data substantially improves attribution performance on challenging unseen generators, demonstrating that unlabeled data from the wild can be effectively exploited to enhance AI generated content attribution in open world settings.

</details>


### [124] [Robust Graph Fine-Tuning with Adversarial Graph Prompting](https://arxiv.org/abs/2601.00229)
*Ziyan Zhang,Bo Jiang,Jin Tang*

Main category: cs.LG

TL;DR: 本文提出了一种新的对抗图提示（AGP）框架，将对抗学习引入图提示中，以提升参数高效微调（PEFT）方法在图神经网络（GNN）中的鲁棒性，尤其针对图结构和节点属性上的噪声与攻击。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络的参数高效微调方法对图拓扑和节点特征上的噪声及攻击高度脆弱，亟需提升其鲁棒性。

Method: 提出对抗图提示（AGP）框架，建模为min-max优化问题；内层最大化采用联合投影梯度下降（JointPGD）生成强对抗扰动，外层最小化学习最优节点提示以抵抗扰动；理论分析证明其可同时应对图结构和节点属性噪声。

Result: 在多个基准任务上，AGP显著优于当前最先进方法，验证了其在各类图噪声下的鲁棒性与有效性；且该方法具有通用性，可适配多种预训练GNN模型。

Conclusion: AGP是一种通用、理论可证、实践有效的鲁棒图微调方法，为图神经网络的参数高效微调提供了新范式。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) method has emerged as a dominant paradigm for adapting pre-trained GNN models to downstream tasks. However, existing PEFT methods usually exhibit significant vulnerability to various noise and attacks on graph topology and node attributes/features. To address this issue, for the first time, we propose integrating adversarial learning into graph prompting and develop a novel Adversarial Graph Prompting (AGP) framework to achieve robust graph fine-tuning. Our AGP has two key aspects. First, we propose the general problem formulation of AGP as a min-max optimization problem and develop an alternating optimization scheme to solve it. For inner maximization, we propose Joint Projected Gradient Descent (JointPGD) algorithm to generate strong adversarial noise. For outer minimization, we employ a simple yet effective module to learn the optimal node prompts to counteract the adversarial noise. Second, we demonstrate that the proposed AGP can theoretically address both graph topology and node noise. This confirms the versatility and robustness of our AGP fine-tuning method across various graph noise. Note that, the proposed AGP is a general method that can be integrated with various pre-trained GNN models to enhance their robustness on the downstream tasks. Extensive experiments on multiple benchmark tasks validate the robustness and effectiveness of AGP method compared to state-of-the-art methods.

</details>


### [125] [GRIT -- Geometry-Aware PEFT with K-FACPreconditioning, Fisher-Guided Reprojection, andDynamic Rank Adaptation](https://arxiv.org/abs/2601.00231)
*Pritish Saha,Chandrav Rajbangshi,Rudra Goyal,Mohit Goyal,Anurag Deo,Biswajit Roy,Ningthoujam Dhanachandra Singh,Raxit Goswami,Amitava Das*

Main category: cs.LG

TL;DR: 本文提出GRIT，一种动态、曲率感知的LoRA方法，通过预处理梯度、周期性重投影低秩基和自适应调整有效秩，显著减少可训练参数（平均减少46%），同时保持甚至提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法如LoRA和QLoRA忽略局部损失曲率，导致更新预算浪费和弱约束方向上的漂移放大。

Method: GRIT在保持LoRA参数化的同时：(1) 使用K-FAC作为自然梯度代理在秩空间中预处理梯度；(2) 周期性将低秩基重投影到主导Fisher特征方向以抑制漂移；(3) 根据谱自适应调整有效秩，使容量集中在信号所在位置。

Result: 在LLaMA系列模型上的指令遵循、理解与推理基准测试中，GRIT匹配或超越LoRA与QLoRA，平均减少46%可训练参数（任务间25%-80%），且无实际质量损失；建模遗忘时拟合出曲率调制的幂律，实证显示其漂移更低、更新-保留权衡更优。

Conclusion: GRIT通过引入曲率感知机制，在不牺牲性能的前提下大幅降低参数量，为高效微调提供了新范式。

Abstract: Parameter-efficient fine-tuning (PEFT) is the default way to adapt LLMs, but widely used LoRA and QLoRA are largely geometry-agnostic: they optimize in fixed, randomly oriented low-rank subspaces with first-order descent, mostly ignoring local loss curvature. This can inflate the effective update budget and amplify drift along weakly constrained directions. We introduce GRIT, a dynamic, curvature-aware LoRA procedure that preserves the LoRA parameterization but: (1) preconditions gradients in rank space using K-FAC as a natural-gradient proxy; (2) periodically reprojects the low-rank basis onto dominant Fisher eigendirections to suppress drift; and (3) adapts the effective rank from the spectrum so capacity concentrates where signal resides. Across instruction-following, comprehension, and reasoning benchmarks on LLaMA backbones, GRIT matches or surpasses LoRA and QLoRA while reducing trainable parameters by 46% on average (25--80% across tasks), without practical quality loss across prompt styles and data mixes. To model forgetting, we fit a curvature-modulated power law. Empirically, GRIT yields lower drift and a better updates-vs-retention frontier than strong PEFT-optimizer baselines (Orthogonal-LoRA, IA3, DoRA, Eff-FT, Shampoo).

</details>


### [126] [Task-Driven Kernel Flows: Label Rank Compression and Laplacian Spectral Filtering](https://arxiv.org/abs/2601.00276)
*Hongxi Li,Chunlin Huang*

Main category: cs.LG

TL;DR: 本文提出了一种关于宽L2正则化网络中特征学习的理论，表明监督学习本质上是压缩性的，并推导出预测'注水式'谱演化的核ODE；证明了任何稳定稳态下核的秩受类别数C限制，且SGD噪声也是低秩的（O(C)），从而将动态限制在任务相关子空间内；该框架统一了对齐现象的确定性和随机性视角，并对比了监督学习的低秩特性与自监督学习的高秩、扩展性表征。


<details>
  <summary>Details</summary>
Motivation: 理解监督学习中特征学习的本质机制，特别是其压缩性以及与自监督学习在表征特性上的根本差异。

Method: 通过理论分析，推导核ODE以描述谱演化，证明核秩和SGD噪声的低秩性质，并分析其对学习动态的影响。

Result: 证明了监督学习中核的秩被类别数C所限制，SGD噪声也为O(C)低秩，从而将学习动态约束在任务相关子空间内。

Conclusion: 监督学习本质上是压缩性的，其动态受限于低秩结构，这与自监督学习的高秩、扩展性表征形成鲜明对比；该理论统一了对齐现象的确定性和随机性解释。

Abstract: We present a theory of feature learning in wide L2-regularized networks showing that supervised learning is inherently compressive. We derive a kernel ODE that predicts a "water-filling" spectral evolution and prove that for any stable steady state, the kernel rank is bounded by the number of classes ($C$). We further demonstrate that SGD noise is similarly low-rank ($O(C)$), confining dynamics to the task-relevant subspace. This framework unifies the deterministic and stochastic views of alignment and contrasts the low-rank nature of supervised learning with the high-rank, expansive representations of self-supervision.

</details>


### [127] [Can Optimal Transport Improve Federated Inverse Reinforcement Learning?](https://arxiv.org/abs/2601.00309)
*David Millard,Ali Baheri*

Main category: cs.LG

TL;DR: 本文提出了一种基于最优传输的联邦逆强化学习（IRL）方法，通过Wasserstein质心融合各客户端本地学习的奖励函数，实现通信高效、隐私保护且对异构环境鲁棒的共享奖励学习。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中，各智能体环境存在差异，且受限于动力学差异、隐私约束和通信带宽，难以直接共享数据学习统一奖励函数。

Method: 各客户端在本地执行轻量级最大熵IRL；利用Wasserstein质心对本地学习的奖励函数进行几何感知融合。

Result: 理论证明Wasserstein质心融合比传统参数平均法能获得更准确的全局奖励估计；实验验证其在异构环境下的泛化能力与通信效率。

Conclusion: 该方法为异构多智能体系统提供了一个原理清晰、通信高效、兼顾隐私与泛化的联邦IRL新框架。

Abstract: In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.

</details>


### [128] [Quantum King-Ring Domination in Chess: A QAOA Approach](https://arxiv.org/abs/2601.00318)
*Gerhard Stenzel,Michael Kölle,Tobias Rohe,Julian Hager,Leo Sünkel,Maximilian Zorn,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 本文提出了一种基于国际象棋战术位置的新型NISQ尺度量子基准测试——Quantum King-Ring Domination（QKRD），包含5000个结构化实例，具备语义可解释性、空间局部性和一热约束；利用该基准发现约束保持混子、warm-start策略等对QAOA性能有显著提升，而CVaR优化效果不佳；结果表明结构化基准能揭示在随机实例中被掩盖的问题导向优化优势。


<details>
  <summary>Details</summary>
Motivation: 现有QAOA基准多基于无语义结构的随机问题（如MaxCut、TSP），难以反映其在真实世界有约束问题上的实际性能，缺乏人类可解释性和内在验证机制。

Method: 提出QKRD基准：源自国际象棋战术，含5000个10–40量子比特、带一热约束与空间局部性的结构化实例；结合人类可解释的覆盖度量与经典启发式算法进行内在验证；系统评估QAOA不同设计选择（混子类型、warm-start、CVaR优化）的收敛步数、能量与覆盖率。

Result: 约束保持混子（XY/域墙）比标准混子快约13步（p<10^{-7}）且免调惩罚项；warm-start减少45步收敛（p<10^{-127}），能量提升显著（d=8+）；CVaR优化反而导致更差能量（p<10^{-40}, d=1.21）且无覆盖率增益；QAOA内在表现优于贪心启发式12.6%、随机选择80.1%。

Conclusion: 结构化、语义丰富的基准（如QKRD）能有效揭示问题导向的QAOA技术优势，弥补随机基准的局限性，推动面向真实NISQ应用的算法研究与评估范式升级。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is extensively benchmarked on synthetic random instances such as MaxCut, TSP, and SAT problems, but these lack semantic structure and human interpretability, offering limited insight into performance on real-world problems with meaningful constraints. We introduce Quantum King-Ring Domination (QKRD), a NISQ-scale benchmark derived from chess tactical positions that provides 5,000 structured instances with one-hot constraints, spatial locality, and 10--40 qubit scale. The benchmark pairs human-interpretable coverage metrics with intrinsic validation against classical heuristics, enabling algorithmic conclusions without external oracles. Using QKRD, we systematically evaluate QAOA design choices and find that constraint-preserving mixers (XY, domain-wall) converge approximately 13 steps faster than standard mixers (p<10^{-7}, d\approx0.5) while eliminating penalty tuning, warm-start strategies reduce convergence by 45 steps (p<10^{-127}, d=3.35) with energy improvements exceeding d=8, and Conditional Value-at-Risk (CVaR) optimization yields an informative negative result with worse energy (p<10^{-40}, d=1.21) and no coverage benefit. Intrinsic validation shows QAOA outperforms greedy heuristics by 12.6\% and random selection by 80.1\%. Our results demonstrate that structured benchmarks reveal advantages of problem-informed QAOA techniques obscured in random instances. We release all code, data, and experimental artifacts for reproducible NISQ algorithm research.

</details>


### [129] [Smart Fault Detection in Nanosatellite Electrical Power System](https://arxiv.org/abs/2601.00335)
*Alireza Rezaee,Niloofar Nobahari,Amin Asgarifar,Farshid Hajati*

Main category: cs.LG

TL;DR: 本文提出了一种在无姿态确定与控制系统（ADCS）的近地轨道纳卫星上，基于神经网络与多种机器学习方法的电气电源系统故障检测新方法。


<details>
  <summary>Details</summary>
Motivation: 纳卫星在发射和在轨运行中面临严苛环境压力，其电源系统各部件易发生多种典型故障（如光伏子系统短路/开路、DC-DC变换器IGBT故障、电池稳压器故障），亟需不依赖ADCS的自主故障诊断能力。

Method: 构建基于太阳辐射与太阳能板表面温度为输入、电流与负载为输出的神经网络模型模拟正常电源系统；再利用该模型输出特征，结合神经网络分类器、PCA、决策树和KNN等多种机器学习方法进行故障模式识别与类型分类。

Result: 成功实现了对光伏子系统、DC-DC变换器及电池稳压器等关键部件多种典型故障的有效诊断与分类，验证了所提方法在无ADCS条件下的可行性与有效性。

Conclusion: 基于多源环境参数与机器学习的故障诊断方法可有效替代传统依赖ADCS的方案，为资源受限的纳卫星提供鲁棒、轻量的电源健康监测手段。

Abstract: This paper presents a new detection method of faults at Nanosatellites' electrical power without an Attitude Determination Control Subsystem (ADCS) at the LEO orbit. Each part of this system is at risk of fault due to pressure tolerance, launcher pressure, and environmental circumstances. Common faults are line to line fault and open circuit for the photovoltaic subsystem, short circuit and open circuit IGBT at DC to DC converter, and regulator fault of the ground battery. The system is simulated without fault based on a neural network using solar radiation and solar panel's surface temperature as input data and current and load as outputs. Finally, using the neural network classifier, different faults are diagnosed by pattern and type of fault. For fault classification, other machine learning methods are also used, such as PCA classification, decision tree, and KNN.

</details>


### [130] [Bayesian Inverse Games with High-Dimensional Multi-Modal Observations](https://arxiv.org/abs/2601.00696)
*Yash Jain,Xinjie Liu,Lasse Peters,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.LG

TL;DR: 本文提出了一种贝叶斯逆博弈框架，通过结构化变分自编码器与可微纳什求解器结合，从多模态交互数据中推断智能体目标的后验分布，提升不确定性建模能力与下游决策安全性。


<details>
  <summary>Details</summary>
Motivation: 现有最大似然逆博弈方法仅给出目标函数的点估计，缺乏不确定性量化，导致下游规划可能做出过度自信且不安全的决策。

Method: 构建基于结构化变分自编码器的贝叶斯逆博弈框架，其中嵌入可微纳什均衡求解器；利用多模态交互数据进行无标签训练，支持实时后验采样。

Result: 实验表明该方法能有效学习先验与后验分布，推理质量优于最大似然方法，提升下游决策安全性；在轨迹信息缺失时，多模态融合可进一步降低不确定性。

Conclusion: 所提贝叶斯逆博弈方法为多智能体自主决策提供了更鲁棒、安全且高效的不确定性感知建模范式。

Abstract: Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.

</details>


### [131] [Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models](https://arxiv.org/abs/2601.00391)
*Nouar AlDahoul,Aznul Qalid Md Sabri,Ali Mohammed Mansoor*

Main category: cs.LG

TL;DR: 本文提出了一种基于自动特征学习的视频中人体检测方法，结合光流与三种深度模型（S-CNN、预训练CNN、H-ELM），在UCF-ARG航拍数据集上验证了其有效性，其中预训练CNN准确率最高（98.09%）。


<details>
  <summary>Details</summary>
Motivation: 传统手工特征方法依赖专家知识、泛化性差且易受光照变化、相机抖动和目标尺度变化等动态因素影响；而自动特征学习可更廉价、便捷地提取高阶判别性特征。

Method: 融合光流信息，采用三种自动特征学习模型：监督式卷积神经网络（S-CNN）、预训练CNN特征提取器、分层极限学习机（H-ELM），在非静态航拍视频上进行人体检测，并在UCF-ARG数据集上训练与测试。

Result: 预训练CNN平均准确率达98.09%，S-CNN（Softmax）为95.6%，S-CNN（SVM）为91.7%，H-ELM为95.9%；H-ELM CPU训练耗时445秒，S-CNN GPU训练耗时770秒。

Conclusion: 所提自动特征学习方法在航拍视频人体检测任务中表现优异，尤其预训练CNN兼顾高精度与实用性，验证了深度特征学习在复杂动态场景下的有效性。

Abstract: Human detection in videos plays an important role in various real-life applications. Most traditional approaches depend on utilizing handcrafted features, which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods, which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for the human detection task. The pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with softmax and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high-performance Graphical Processing Unit (GPU).

</details>


### [132] [Deep Delta Learning](https://arxiv.org/abs/2601.00417)
*Yifan Zhang,Yifeng Liu,Mengdi Wang,Quanquan Gu*

Main category: cs.LG

TL;DR: 本文提出Deep Delta Learning（DDL），通过引入可学习的、数据依赖的几何变换（Delta Operator）来推广标准残差连接，该变换是单位矩阵的秩-1扰动，能动态插值恒等映射、正交投影和几何反射，从而增强建模复杂状态转移的能力，同时保持训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 标准残差网络中的恒等捷径连接虽缓解梯度消失问题，但其严格的加性归纳偏置限制了网络建模复杂状态转移的能力。

Method: 提出Deep Delta Learning（DDL），用Delta Operator（由反射方向向量k(X)和门控标量β(X)参数化的单位矩阵秩-1扰动）替代恒等捷径；对算子进行谱分析；将残差更新重构为同步秩-1注入，使门控变量动态控制信息擦除与新特征写入。

Result: Delta Operator可动态插值恒等映射、正交投影和几何反射；门控变量β(X)能显式调控层间转移算子的谱特性，支持建模复杂非单调动力学；同时保留门控残差结构的稳定训练特性。

Conclusion: DDL通过推广残差连接的几何语义，提升了深度网络对复杂状态转移的建模能力，在不牺牲训练稳定性前提下拓展了残差学习的表达边界。

Abstract: The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector $\mathbf{k}(\mathbf{X})$ and a gating scalar $β(\mathbf{X})$. We provide a spectral analysis of this operator, demonstrating that the gate $β(\mathbf{X})$ enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.

</details>


### [133] [E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models](https://arxiv.org/abs/2601.00423)
*Shengjun Zhang,Zhang Zhang,Chensheng Dai,Yueqi Duan*

Main category: cs.LG

TL;DR: 本文提出E-GRPO方法，通过熵感知的分组相对策略优化，提升流匹配模型在人类偏好对齐中的性能。核心思想是合并低熵SDE采样步以形成高熵步，并在这些步上使用多步分组归一化优势进行优化。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的流匹配模型在多步去噪优化中面临稀疏且模糊的奖励信号问题，尤其低熵步骤导致轨迹区分度低，影响探索效率。

Method: 提出熵感知的Group Relative Policy Optimization（E-GRPO）：1）识别并合并连续低熵SDE采样步为单个高熵步；2）其余步骤采用确定性ODE采样；3）在合并后的高熵步内计算多步分组归一化优势。

Result: 在多种奖励设置下的实验表明，E-GRPO显著提升了模型对人类偏好的对齐效果与采样效率。

Conclusion: 熵感知的采样步整合与分组优势估计能有效缓解SDE多步优化中的奖励模糊性，为流匹配模型的偏好对齐提供了新思路。

Abstract: Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.

</details>


### [134] [A Comparative Analysis of Interpretable Machine Learning Methods](https://arxiv.org/abs/2601.00428)
*Mattia Billa,Giovanni Orlandi,Veronica Guidetti,Federica Mandreoli*

Main category: cs.LG

TL;DR: 本文对16种固有可解释机器学习方法在216个真实表格数据集上进行了大规模对比评估，分析其在预测性能、训练时间及分布偏移鲁棒性等方面的差异，并依据数据特性（如维度、样本量、线性程度、类别不平衡）进行分层评估，为实际应用提供可解释性与性能权衡的实证指导。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在医疗、金融、法律等高风险领域广泛应用，模型可解释性与可问责性日益重要；然而，针对表格数据的固有可解释模型仍缺乏系统性、细粒度的实证评估。

Method: 对16种固有可解释模型（包括线性模型、决策树、EBM、符号回归、GOSDT等）在216个真实表格数据集上开展大规模实验，按数据结构特征（维度、样本量、线性、类别不平衡）分层评估预测性能、训练时间与分布偏移鲁棒性。

Result: EBM在回归任务中持续表现优异；符号回归与IGANN在非线性场景下更优；GOSDT对类别不平衡高度敏感；整体性能具有强上下文依赖性。

Conclusion: 可解释模型的选择需结合具体数据特性，不能仅依赖整体性能排名；本研究为从业者提供了基于实证的选型指南，并推动了表格数据可解释建模的深入理解。

Abstract: In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.
  To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.

</details>


### [135] [A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection](https://arxiv.org/abs/2601.00446)
*Miseon Park,Kijung Yoon*

Main category: cs.LG

TL;DR: 本文探讨了时间序列基础模型（TSFMs）作为通用骨干网络用于异常检测的潜力，通过系统实验比较了零样本推理、全模型微调和参数高效微调（PEFT）策略，结果表明TSFMs在多个基准上优于任务特定基线，尤其在严重类别不平衡下表现突出；PEFT方法（如LoRA、OFT、HRA）在降低计算成本的同时，性能媲美甚至超越全微调。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法大多需要大量任务特定训练，缺乏通用性和可扩展性，因此探索预训练于大规模异构数据的时间序列基础模型（TSFMs）是否可作为通用骨干用于异常检测。

Method: 在多个基准数据集上系统评估零样本推理、全模型适应和参数高效微调（PEFT，包括LoRA、OFT、HRA）三种策略。

Result: TSFMs显著优于任务特定基线，在AUC-PR和VUS-PR指标上取得明显提升，尤其在严重类别不平衡场景下；PEFT方法在大幅降低计算开销的同时，性能匹配或超越全微调。

Conclusion: TSFMs可作为高效、可扩展的时间序列异常检测通用模型，且即使预训练目标为预测任务，也能通过PEFT高效适配异常检测任务。

Abstract: Time series anomaly detection is essential for the reliable operation of complex systems, but most existing methods require extensive task-specific training. We explore whether time series foundation models (TSFMs), pretrained on large heterogeneous data, can serve as universal backbones for anomaly detection. Through systematic experiments across multiple benchmarks, we compare zero-shot inference, full model adaptation, and parameter-efficient fine-tuning (PEFT) strategies. Our results demonstrate that TSFMs outperform task-specific baselines, achieving notable gains in AUC-PR and VUS-PR, particularly under severe class imbalance. Moreover, PEFT methods such as LoRA, OFT, and HRA not only reduce computational cost but also match or surpass full fine-tuning in most cases, indicating that TSFMs can be efficiently adapted for anomaly detection, even when pretrained for forecasting. These findings position TSFMs as promising general-purpose models for scalable and efficient time series anomaly detection.

</details>


### [136] [Controllable Concept Bottleneck Models](https://arxiv.org/abs/2601.00451)
*Hongbin Lin,Chenyang Ren,Juangui Xu,Zhengyu Hu,Cheng-Long Wang,Yao Shu,Hui Xiong,Jingfeng Zhang,Di Wang,Lijie Hu*

Main category: cs.LG

TL;DR: 本文提出可控概念瓶颈模型（CCBMs），支持概念标签级、概念级和数据级三种粒度的模型编辑，无需从头训练即可高效更新模型，适用于现实世界中需要持续维护的动态场景。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）主要针对静态、干净的数据场景，而实际应用中需要频繁进行数据删除（unlearning）、概念修正或新增样本（增量学习）等操作，亟需一种无需重新训练即可编辑的CBM方法。

Method: 提出可控概念瓶颈模型（CCBMs），基于影响函数推导出数学上严格的闭式近似解，支持概念标签级、概念级和数据级（包括删除与添加）三种编辑粒度。

Result: 实验验证了CCBMs在编辑效率和适应性方面的优越性，显著降低了模型维护成本，提升了CBMs在动态环境中的实用性与可信度。

Conclusion: CCBMs为实现可编辑、可信赖且适用于大规模动态场景的概念瓶颈模型提供了有效解决方案。

Abstract: Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.

</details>


### [137] [Imitation from Observations with Trajectory-Level Generative Embeddings](https://arxiv.org/abs/2601.00452)
*Yongtao Qu,Shangzhe Li,Weitong Zhang*

Main category: cs.LG

TL;DR: 本文提出TGE方法，通过在离线轨迹数据上训练时间扩散模型，在其潜在空间中估计专家状态密度，构建稠密平滑的代理奖励，从而在专家数据稀缺且离线数据次优的情况下提升模仿学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有分布匹配方法在专家演示稀缺、离线数据次优且与专家分布差异大时表现不佳，因其依赖脆弱的单步模型并受支持集约束限制。

Method: 提出轨迹级生成嵌入（TGE），利用时间扩散模型学习轨迹潜在空间，并在其中估计专家状态密度以构建平滑 surrogate reward，利用扩散嵌入的平滑几何特性建模长程时序动态并弥合分布支持差距。

Result: 在D4RL多个locomotion和manipulation任务上，TGE一致达到或超越现有离线LfO方法。

Conclusion: TGE通过潜在空间密度估计与扩散模型的平滑性，为离线模仿学习提供了更鲁棒、更有效的信号提取机制，尤其适用于专家数据稀缺且离线数据质量差的场景。

Abstract: We consider the offline imitation learning from observations (LfO) where the expert demonstrations are scarce and the available offline suboptimal data are far from the expert behavior. Many existing distribution-matching approaches struggle in this regime because they impose strict support constraints and rely on brittle one-step models, making it hard to extract useful signal from imperfect data. To tackle this challenge, we propose TGE, a trajectory-level generative embedding for offline LfO that constructs a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model trained on offline trajectory data. By leveraging the smooth geometry of the learned diffusion embedding, TGE captures long-horizon temporal dynamics and effectively bridges the gap between disjoint supports, ensuring a robust learning signal even when offline data is distributionally distinct from the expert. Empirically, the proposed approach consistently matches or outperforms prior offline LfO methods across a range of D4RL locomotion and manipulation benchmarks.

</details>


### [138] [Deep Networks Learn Deep Hierarchical Models](https://arxiv.org/abs/2601.00455)
*Amit Daniely*

Main category: cs.LG

TL;DR: 本文研究了残差网络中逐层SGD如何高效学习具有层次结构的多标签监督模型，该模型基于未知的标签层级关系，突破了以往深度学习可高效学习模型的深度限制，并从教育学角度论证了层次结构在人类教学与大脑算法中的自然存在及其对可学习性的促进作用。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习理论难以解释为何深层网络在实践中表现优异；作者试图通过构建一个更广义的、符合真实世界数据（如人类教学）特性的层次化标签模型，来弥合理论与实践之间的差距，并探索层次结构是否是深度学习成功的核心机制。

Method: 提出一类基于嵌套标签集 $L_1 \subseteq L_2 \subseteq \dots \subseteq L_r = [n]$ 的分层模型，其中高层标签是低层标签的简单函数；分析残差网络上逐层随机梯度下降（layerwise SGD）对该类模型的高效可学习性；并建立简化教师模型，形式化‘教师提供粒度化标签即揭示脑内算法片段’这一认知直觉。

Result: 证明该分层模型类可在多项式时间内被残差网络+layerwise SGD高效学习，且其表达所需深度可达多项式量级（超越此前log-depth可表征模型），达到当前深度学习高效可学习性的深度上限；同时在教师部分自知模型下，严格导出层次结构与高效可学习性的关联。

Conclusion: 层次化结构不仅是深度学习擅长领域的自然建模方式，更可能是其可学习性的根本来源；人类教师通过渐进式标注所提供的‘提示’，本质上揭示了内在的计算层次，为深度学习的理论基础提供了认知科学支持。

Abstract: We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \subseteq L_2 \subseteq \dots \subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.
  Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.
  Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.

</details>


### [139] [Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations](https://arxiv.org/abs/2601.00457)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: 本文研究了正交性损失在MoE模型中对专家多样性的几何正则化效果，发现其未能有效降低权重空间和激活空间的重叠，并且对性能提升效果不一致甚至有负面影响，因此认为该方法不适合用于MoE多样性控制。


<details>
  <summary>Details</summary>
Motivation: 探究几何正则化（特别是正交性损失）在MoE模型中促进专家专业化的作用是否真实有效。

Method: 在多个数据集（WikiText-103、TinyStories、PTB）上系统评估不同强度（共7种）的正交性损失对MoE模型的影响，量化权重空间重叠（MSO）与激活空间重叠，并分析其与性能的关系。

Result: 正交性损失导致权重空间重叠反而上升（最高+114%），激活空间重叠仍居高（~0.6），性能变化不一致（WikiText微升-0.9%，TinyStories略降+0.9%，PTB方差>1.0），且权重与激活正交性无显著相关性（r=-0.293, p=0.523）。

Conclusion: 权重空间的正则化既未达成其几何目标，也不能稳定提升性能，因此不适合作为MoE专家多样性控制手段。

Abstract: Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.

</details>


### [140] [Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet](https://arxiv.org/abs/2601.00459)
*Saurav Sengupta,Scott Kilianski,Suchetha Sharma,Sakina Lashkeri,Ashley McHugh,Mark Beenhakker,Donald E. Brown*

Main category: cs.LG

TL;DR: 本文提出了一种改进的1D UNet模型（AugUNet1D），通过数据增强（尤其是缩放）显著提升了小鼠长时程EEG中棘慢波放电（SWD）的自动检测性能，并优于现有算法Twin Peaks。


<details>
  <summary>Details</summary>
Motivation: 手动标注EEG中的棘慢波放电（SWD）耗时费力，尤其在数周至数月的连续记录中；亟需高精度、鲁棒的自动标注方法。

Method: 在961小时、含22637个SWD的手动标注小鼠EEG数据集上，系统比较14种机器学习分类器；选定1D UNet为基础模型，引入多种数据增强策略（重点评估缩放），构建AugUNet1D；并与基于时频分析的Twin Peaks算法对比。

Result: 1D UNet表现最优；缩放增强效果最显著；AugUNet1D在检测精度和事件特征相似性上均优于Twin Peaks；模型（预训练/未训练版）已开源。

Conclusion: AugUNet1D是一种高效、可复现且开源的SWD自动检测工具，为长时程EEG分析提供了更优的深度学习解决方案。

Abstract: The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called "Twin Peaks". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.

</details>


### [141] [Laplacian Kernelized Bandit](https://arxiv.org/abs/2601.00461)
*Shuang Wu,Arash A. Amini*

Main category: cs.LG

TL;DR: 本文提出了一种基于图结构与核方法结合的多用户上下文赌博机框架，通过构造统一的多用户RKHS及其再生核，实现了对用户奖励函数的联合正则化，并设计了基于高斯过程后验的高效算法，理论分析表明其遗憾界依赖于有效维度而非用户数或环境维度。


<details>
  <summary>Details</summary>
Motivation: 解决多用户上下文赌博机中用户间存在图结构关联、奖励函数兼具非线性和图同质性（homophily）的建模难题，现有方法难以同时兼顾图结构先验与非线性函数空间建模。

Method: 提出一种融合图平滑项（基于RKHS距离）与个体粗糙度惩罚的联合正则化项；证明该正则项等价于一个统一的多用户RKHS中的平方范数；显式导出其再生核（融合图拉普拉斯与臂核）；在此基础上将问题重构为学习一个‘提升’函数，并设计基于该核的高斯过程上置信界（LK-GP-UCB）与汤普森采样（LK-GP-TS）算法。

Result: 获得以多用户核有效维度为尺度的高概率遗憾上界，摆脱对用户数量和环境维度的直接依赖；实验表明所提方法在非线性设定下显著优于线性及无图感知基线，在线性设定下仍具竞争力。

Conclusion: 本文建立了拉普拉斯正则化与核化赌博机的理论桥梁，提供了一个统一、有理论保证且实用的结构化探索框架。

Abstract: We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\{f_u\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \texttt{LK-GP-UCB} and \texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.

</details>


### [142] [Neural Chains and Discrete Dynamical Systems](https://arxiv.org/abs/2601.00473)
*Sauro Succi,Abhisek Ganguly,Santosh Ansumali*

Main category: cs.LG

TL;DR: 本文探讨了无自注意力机制的神经链（neural chains）与离散化神经积分/偏微分方程（NIE/PDE）动力系统之间的类比，并比较了传统有限差分法与物理信息神经网络（PINN）在求解Burgers和Eikonal方程上的表现；发现二者获取系统动力学知识的路径不同：FD依赖结构化稀疏矩阵，而PINN依赖大量随机矩阵，虽参数多、可解释性差、训练成本高，但在高维问题中或有优势。


<details>
  <summary>Details</summary>
Motivation: 探究神经链与离散动力系统（如NIE/PDE）的理论联系，并厘清PINN与传统数值方法在建模物理系统时的本质异同及各自优劣。

Method: 通过将标准数值离散化（如有限差分）重新表述为神经链形式，与PINN学习进行对比分析；以一维Burgers（粘性/无粘性）和Eikonal方程为测试案例，考察二者在解精度、矩阵结构、参数规模和训练行为上的差异。

Result: 标准数值离散与PINN虽路径不同（结构化FD矩阵 vs. 随机矩阵），但可获得等效的动力学知识；随机矩阵解空间远大于唯一三对角FD矩阵，故PINN易收敛于随机解；代价是参数量大、物理可解释性弱、训练开销高。

Conclusion: 在低维问题中，传统数值方法更高效透明；PINN当前优势不显著，但其高维扩展潜力未被否定，值得进一步探索。

Abstract: We inspect the analogy between machine-learning (ML) applications based on the transformer architecture without self-attention, {\it neural chains} hereafter, and discrete dynamical systems associated with discretised versions of neural integral and partial differential equations (NIE, PDE). A comparative analysis of the numerical solution of the (viscid and inviscid) Burgers and Eikonal equations via standard numerical discretization (also cast in terms of neural chains) and via PINN's learning is presented and commented on. It is found that standard numerical discretization and PINN learning provide two different paths to acquire essentially the same knowledge about the dynamics of the system. PINN learning proceeds through random matrices which bear no direct relation to the highly structured matrices associated with finite-difference (FD) procedures. Random matrices leading to acceptable solutions are far more numerous than the unique tridiagonal form in matrix space, which explains why the PINN search typically lands on the random ensemble. The price is a much larger number of parameters, causing lack of physical transparency (explainability) as well as large training costs with no counterpart in the FD procedure. However, our results refer to one-dimensional dynamic problems, hence they don't rule out the possibility that PINNs and ML in general, may offer better strategies for high-dimensional problems.

</details>


### [143] [When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents](https://arxiv.org/abs/2601.00513)
*Laksh Advani*

Main category: cs.LG

TL;DR: 本文揭示了小型语言模型（7-9B）作为自主代理时存在的‘结果正确但推理错误’的可靠性危机，并提出基于推理过程的Reasoning Integrity Score（RIS）评估指标；研究发现RAG能提升推理完整性，而自省类方法反而损害小模型表现，最终蒸馏出高效验证分类器。


<details>
  <summary>Details</summary>
Motivation: 部署小型语言模型作为可信自主代理需关注其推理过程而非仅输出结果；标准准确率指标无法捕捉‘Right-for-Wrong-Reasons’现象，存在严重可靠性隐患。

Method: 分析10,734条跨3个模型与多任务的推理链，构建并验证Reasoning Integrity Score（RIS）；对比RAG与自批判等元认知干预的效果；进行机制分析；蒸馏神经验证分类器。

Result: 发现50–69%的正确答案含根本性推理错误；RAG显著提升RIS（Cohen's d=0.23–0.93），而自批判降低RIS（d=−0.14至−0.33）；RAG通过外部证据锚定计算减少7.6%错误；验证分类器达0.86 F1且加速100×。

Conclusion: 仅依赖输出准确率不足以保障小型模型代理的可信性；必须采用基于推理过程的验证机制，RIS及配套技术为可信部署提供了新路径。

Abstract: Deploying small language models (7-9B parameters) as autonomous agents requires trust in their reasoning, not just their outputs. We reveal a critical reliability crisis: 50-69\% of correct answers from these models contain fundamentally flawed reasoning -- a ``Right-for-Wrong-Reasons'' phenomenon invisible to standard accuracy metrics. Through analysis of 10,734 reasoning traces across three models and diverse tasks, we introduce the Reasoning Integrity Score (RIS), a process-based metric validated with substantial inter-rater agreement ($κ=0.657$). Conventional practices are challenged by our findings: while retrieval-augmented generation (RAG) significantly improves reasoning integrity (Cohen's $d=0.23$--$0.93$), meta-cognitive interventions like self-critique often harm performance ($d=-0.14$ to $-0.33$) in small models on the evaluated tasks. Mechanistic analysis reveals RAG succeeds by grounding calculations in external evidence, reducing errors by 7.6\%, while meta-cognition amplifies confusion without sufficient model capacity. To enable deployment, verification capabilities are distilled into a neural classifier achieving 0.86 F1-score with 100$\times$ speedup. These results underscore the necessity of process-based verification for trustworthy agents: accuracy alone is dangerously insufficient when models can be right for entirely wrong reasons.

</details>


### [144] [Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI](https://arxiv.org/abs/2601.00516)
*Laksh Advani*

Main category: cs.LG

TL;DR: 本文提出Trajectory Guard，一种用于检测自主LLM代理生成计划中异常的Siamese循环自编码器，结合对比学习与重构损失，在多个基准上显著提升异常检测F1分数与召回率，并具备低延迟实时能力。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法在处理LLM代理多步计划时存在不足：均值池化稀释异常步骤，纯对比学习忽略序列结构，无监督方法F1上限仅0.69。

Method: 提出Trajectory Guard，一种Siamese循环自编码器，采用混合损失函数，联合进行任务-轨迹对齐（对比学习）和序列有效性建模（重构）。

Result: 在合成扰动及真实世界基准（RAS-Eval、Who&When）上，平衡集F1达0.88–0.94，非平衡外部基准召回率达0.86–0.92；推理延迟32ms，比LLM Judge快17–27倍。

Conclusion: Trajectory Guard实现了对‘错误任务计划’和‘结构畸形计划’的统一检测，支持实时安全验证，适用于生产环境部署。

Abstract: Autonomous LLM agents generate multi-step action plans that can fail due to contextual misalignment or structural incoherence. Existing anomaly detection methods are ill-suited for this challenge: mean-pooling embeddings dilutes anomalous steps, while contrastive-only approaches ignore sequential structure. Standard unsupervised methods on pre-trained embeddings achieve F1-scores no higher than 0.69. We introduce Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss function that jointly learns task-trajectory alignment via contrastive learning and sequential validity via reconstruction. This dual objective enables unified detection of both "wrong plan for this task" and "malformed plan structure." On benchmarks spanning synthetic perturbations and real-world failures from security audits (RAS-Eval) and multi-agent systems (Who\&When), we achieve F1-scores of 0.88-0.94 on balanced sets and recall of 0.86-0.92 on imbalanced external benchmarks. At 32 ms inference latency, our approach runs 17-27$\times$ faster than LLM Judge baselines, enabling real-time safety verification in production deployments.

</details>


### [145] [A Sparse-Attention Deep Learning Model Integrating Heterogeneous Multimodal Features for Parkinson's Disease Severity Profiling](https://arxiv.org/abs/2601.00519)
*Dristi Datta,Tanmoy Debnath,Minh Chau,Manoranjan Paul,Gourab Adhikary,Md Geaur Rahman*

Main category: cs.LG

TL;DR: 本文提出了一种名为Class-Weighted Sparse-Attention Fusion Network (SAFN)的可解释深度学习框架，用于融合多模态数据（如MRI皮层厚度、体积测量、临床评估和人口统计学变量）以稳健地预测帕金森病（PD），在PPMI数据集上取得了高准确率（0.98±0.02）和完美PR-AUC（1.00±0.00），并展现出与临床诊断原则一致的可解释性。


<details>
  <summary>Details</summary>
Motivation: 帕金森病表型异质性强，需整合生物学与临床标志物；现有模型存在可解释性差、类别不平衡及高维多模态数据融合效果不佳等问题。

Method: 提出SAFN模型：采用模态特异性编码器、对称交叉注意力机制建模影像与临床特征的非线性交互；引入稀疏约束的注意力门控融合层动态选择关键模态；使用类别平衡的焦点损失（beta=0.999, gamma=1.5）缓解样本不平衡。

Result: 在PPMI数据集（703名受试者）五折交叉验证中，准确率达0.98±0.02，PR-AUC达1.00±0.00，显著优于基线模型；可解释性分析显示约60%预测权重来自临床评估，符合运动障碍学会诊断原则。

Conclusion: SAFN提供了一种可复现、透明的多模态建模范式，适用于神经退行性疾病的计算表征分析。

Abstract: Characterising the heterogeneous presentation of Parkinson's disease (PD) requires integrating biological and clinical markers within a unified predictive framework. While multimodal data provide complementary information, many existing computational models struggle with interpretability, class imbalance, or effective fusion of high-dimensional imaging and tabular clinical features. To address these limitations, we propose the Class-Weighted Sparse-Attention Fusion Network (SAFN), an interpretable deep learning framework for robust multimodal profiling. SAFN integrates MRI cortical thickness, MRI volumetric measures, clinical assessments, and demographic variables using modality-specific encoders and a symmetric cross-attention mechanism that captures nonlinear interactions between imaging and clinical representations. A sparsity-constrained attention-gating fusion layer dynamically prioritises informative modalities, while a class-balanced focal loss (beta = 0.999, gamma = 1.5) mitigates dataset imbalance without synthetic oversampling. Evaluated on 703 participants (570 PD, 133 healthy controls) from the Parkinson's Progression Markers Initiative using subject-wise five-fold cross-validation, SAFN achieves an accuracy of 0.98 plus or minus 0.02 and a PR-AUC of 1.00 plus or minus 0.00, outperforming established machine learning and deep learning baselines. Interpretability analysis shows a clinically coherent decision process, with approximately 60 percent of predictive weight assigned to clinical assessments, consistent with Movement Disorder Society diagnostic principles. SAFN provides a reproducible and transparent multimodal modelling paradigm for computational profiling of neurodegenerative disease.

</details>


### [146] [Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study](https://arxiv.org/abs/2601.00525)
*Ravi Teja Pagidoju*

Main category: cs.LG

TL;DR: 本文研究了LSTM模型压缩对零售销售预测性能的影响，发现将隐藏单元数从128减少到64不仅使模型体积缩小73%、推理更高效，还意外提升了预测精度（MAPE从23.6%降至12.4%，提升47%），挑战了‘越大越好’的常见假设。


<details>
  <summary>Details</summary>
Motivation: 标准LSTM虽在零售销量预测中准确，但计算开销大，中小零售商难以负担，亟需轻量化且不失精度的模型。

Method: 通过系统性地减少LSTM隐藏单元数量（128→16），在Kaggle商店商品销量数据集上评估模型大小与预测精度的权衡关系。

Result: 隐藏单元为64时，模型大小减小73%（280KB→76KB），MAPE从23.6%降至12.4%，准确率提升47%；进一步压缩至16则精度显著下降。

Conclusion: 适度压缩LSTM模型（如64隐藏单元）可在大幅降低资源消耗的同时提升预测性能，表明模型规模与性能并非单调正相关，中小零售商可采用该轻量高质方案。

Abstract: Standard LSTM(Long Short-Term Memory) neural networks provide accurate predictions for sales data in the retail industry, but require a lot of computing power. It can be challenging especially for mid to small retail industries. This paper examines LSTM model compression by gradually reducing the number of hidden units from 128 to 16. We used the Kaggle Store Item Demand Forecasting dataset, which has 913,000 daily sales records from 10 stores and 50 items, to look at the trade-off between model size and how accurate the predictions are. Experiments show that lowering the number of hidden LSTM units to 64 maintains the same level of accuracy while also improving it. The mean absolute percentage error (MAPE) ranges from 23.6% for the full 128-unit model to 12.4% for the 64-unit model. The optimized model is 73% smaller (from 280KB to 76KB) and 47% more accurate. These results show that larger models do not always achieve better results.

</details>


### [147] [Federated Customization of Large Models: Approaches, Experiments, and Insights](https://arxiv.org/abs/2601.00526)
*Yuchuan Ye,Ming Ding,Youjia Chen,Peng Cheng,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文探讨了大型模型在联邦学习框架下的定制化方法，重点分析了包括前缀调优在内的多种技术在联邦环境中的适用性，并首次实验验证了联邦前缀调优的可行性与有效性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中大型模型定制化面临通信开销大、数据异构、隐私保护与模型性能平衡等关键挑战，亟需适配联邦场景的高效定制方法。

Method: 系统梳理主流大模型定制技术（全量微调、高效微调、提示工程、前缀调优、知识蒸馏、检索增强生成），并分析其在联邦学习中的适配路径；重点设计并实现联邦前缀调优方案，开展对比实验。

Result: 联邦前缀调优首次在联邦学习中成功应用，性能接近中心化训练；相比其他三种联邦定制方法，在性能、效率和鲁棒性方面均表现优异。

Conclusion: 前缀调优是一种适用于联邦学习的大模型定制化有效范式，兼顾性能、通信效率与稳定性，为后续研究提供了新方向。

Abstract: In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.

</details>


### [148] [Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization](https://arxiv.org/abs/2601.00527)
*Ravi Teja Pagidoju,Shriya Agarwal*

Main category: cs.LG

TL;DR: 本文提出了一种基于云原生架构和扩散模型的自动货架陈列图（planogram）生成方法，大幅缩短设计时间、降低成本，并满足零售约束。


<details>
  <summary>Details</summary>
Motivation: 传统planogram设计耗时长（平均30小时/复杂布局），依赖人工或优化算法，缺乏从多店成功实践中学习的能力。

Method: 采用云原生架构，结合AWS云端训练与边缘端实时推理；使用改进损失函数嵌入零售业务约束的扩散模型，从多门店成功陈列数据中学习生成新planogram。

Result: 设计时间减少98.3%（30→0.5小时），约束满足率达94.4%，创建成本降低97.5%，盈亏平衡期为4.4个月，系统可线性扩展至支持10,000家门店并发请求。

Conclusion: 该工作验证了生成式AI在自动化零售空间优化中的可行性与实用性，为智能零售提供可扩展、高效率的新范式。

Abstract: Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existing layouts, our system learns from successful shelf arrangements across multiple retail locations to create new planogram configurations. The architecture combines cloud-based model training via AWS with edge deployment for real-time inference. The diffusion model integrates retail-specific constraints through a modified loss function. Simulation-based analysis demonstrates the system reduces planogram design time by 98.3% (from 30 to 0.5 hours) while achieving 94.4% constraint satisfaction. Economic analysis reveals a 97.5% reduction in creation expenses with a 4.4-month break-even period. The cloud-native architecture scales linearly, supporting up to 10,000 concurrent store requests. This work demonstrates the viability of generative AI for automated retail space optimization.

</details>


### [149] [Entropy Production in Machine Learning Under Fokker-Planck Probability Flow](https://arxiv.org/abs/2601.00554)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: 本文提出了一种基于熵的模型重训练框架，利用非平衡随机动力学建模数据漂移，通过Fokker-Planck方程和KL散度的时间演化量化模型-数据失配，并以熵产率为触发机制实现标签无关、高效节制的重训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有数据漂移检测方法缺乏动力学解释，且难以权衡重训练频率与运维成本。

Method: 将部署期数据漂移建模为由Fokker-Planck方程描述的概率流，用时变KL散度衡量模型-数据失配，并推导其时间导数的熵平衡分解，提取非负熵产率作为重训练触发信号。

Result: 在可控非平稳分类实验中，熵触发重训练在预测性能上媲美高频重训练，同时将重训练次数比日更策略和标签依赖策略降低一个数量级。

Conclusion: 熵触发重训练是一种原理清晰、无需标签、响应及时且资源高效的自适应模型维护策略。

Abstract: Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.

</details>


### [150] [Adversarial Samples Are Not Created Equal](https://arxiv.org/abs/2601.00577)
*Jennifer Crawford,Amol Khanna,Fred Lu,Amy R. Wagoner,Stella Biderman,Andre T. Nguyen,Edward Raff*

Main category: cs.LG

TL;DR: 本文提出了一种新的视角，区分两类对抗样本：利用脆弱但可预测特征的样本与不依赖此类特征的样本，并设计了一个基于集成的度量方法来量化对抗扰动对非鲁棒特征的操纵程度，进而重新审视了SAM对鲁棒性的影响及对抗训练与标准训练在鲁棒数据集上的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有非鲁棒特征理论忽略了不直接利用这些特征的对抗样本，导致对抗鲁棒性评估不够全面。

Method: 提出一种基于集成的度量方法，用于评估对抗扰动对非鲁棒特征的操纵程度，并据此分析不同攻击生成的对抗样本构成。

Result: 揭示了对抗样本存在两类不同的弱点；该度量有助于解释SAM提升鲁棒性的机制，并阐明对抗训练与标准训练在鲁棒数据集上表现差异的原因。

Conclusion: 应区分两类对抗弱点以更准确评估模型鲁棒性；所提度量为理解鲁棒性相关现象提供了新工具和视角。

Abstract: Over the past decade, numerous theories have been proposed to explain the widespread vulnerability of deep neural networks to adversarial evasion attacks. Among these, the theory of non-robust features proposed by Ilyas et al. has been widely accepted, showing that brittle but predictive features of the data distribution can be directly exploited by attackers. However, this theory overlooks adversarial samples that do not directly utilize these features. In this work, we advocate that these two kinds of samples - those which use use brittle but predictive features and those that do not - comprise two types of adversarial weaknesses and should be differentiated when evaluating adversarial robustness. For this purpose, we propose an ensemble-based metric to measure the manipulation of non-robust features by adversarial perturbations and use this metric to analyze the makeup of adversarial samples generated by attackers. This new perspective also allows us to re-examine multiple phenomena, including the impact of sharpness-aware minimization on adversarial robustness and the robustness gap observed between adversarially training and standard training on robust datasets.

</details>


### [151] [Learning to be Reproducible: Custom Loss Design for Robust Neural Networks](https://arxiv.org/abs/2601.00578)
*Waqas Ahmed,Sheeba Samuel,Kevin Coakley,Birgitta Koenig-Ries,Odd Erik Gundersen*

Main category: cs.LG

TL;DR: 本文提出了一种定制损失函数（CLF），通过平衡预测精度与训练稳定性，显著提升深度学习模型在不同训练运行间的性能一致性与鲁棒性，且不牺牲预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习训练方法缺乏保障模型多次运行结果一致性和鲁棒性的机制，实证发现即使在控制初始化和训练条件的情况下，模型准确率仍存在显著波动。

Method: 提出一种定制损失函数（CLF），通过调节其参数显式地在预测精度与训练稳定性之间进行权衡，降低训练结果对权重初始化、数据洗牌等随机因素的敏感性。

Result: 在图像分类和时间序列预测等多种架构上的大量实验表明，CLF显著提升了训练鲁棒性，同时保持了预测性能。

Conclusion: CLF是一种有效且高效的策略，有助于构建更稳定、可靠和可信的神经网络。

Abstract: To enhance the reproducibility and reliability of deep learning models, we address a critical gap in current training methodologies: the lack of mechanisms that ensure consistent and robust performance across runs. Our empirical analysis reveals that even under controlled initialization and training conditions, the accuracy of the model can exhibit significant variability. To address this issue, we propose a Custom Loss Function (CLF) that reduces the sensitivity of training outcomes to stochastic factors such as weight initialization and data shuffling. By fine-tuning its parameters, CLF explicitly balances predictive accuracy with training stability, leading to more consistent and reliable model performance. Extensive experiments across diverse architectures for both image classification and time series forecasting demonstrate that our approach significantly improves training robustness without sacrificing predictive performance. These results establish CLF as an effective and efficient strategy for developing more stable, reliable and trustworthy neural networks.

</details>


### [152] [HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts](https://arxiv.org/abs/2601.00583)
*Zihan Fang,Zheng Lin,Senkang Hu,Yanan Ma,Yihang Tao,Yiqin Deng,Xianhao Chen,Yuguang Fang*

Main category: cs.LG

TL;DR: 本文提出HFedMoE框架，解决在资源受限设备上将Mixture-of-Experts（MoE）集成到联邦学习（FL）中进行大语言模型（LLM）微调所面临的专家选择、异构资源适配与全局聚合干扰三大挑战。该方法基于专家重要性评估与信息瓶颈视角动态分配专家子集，并设计稀疏感知的加权聚合策略，显著提升训练精度与收敛速度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中直接微调大语言模型在资源受限客户端（如移动设备）上不现实；MoE虽可降低计算开销，但在FL场景下面临专家选择无可靠指标、客户端算力异构导致动态激活不稳定、以及客户端路由偏好差异引发聚合干扰三大问题。

Method: HFedMoE框架：1）基于本地微调性能贡献评估专家重要性；2）从信息瓶颈角度自适应为各客户端选择匹配其计算预算的专家子集；3）设计稀疏感知的模型聚合策略，对活跃微调的专家参数和门控网络参数按重要性加权聚合。

Result: 在多个基准数据集上的实验表明，HFedMoE在训练准确率和收敛速度方面均优于当前最优方法。

Conclusion: HFedMoE通过定制化专家分配与重要性加权聚合，有效缓解了MoE在异构联邦学习环境中的适配难题，为资源受限设备上的高效LLM微调提供了可行方案。

Abstract: While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.

</details>


### [153] [Memory Bank Compression for Continual Adaptation of Large Language Models](https://arxiv.org/abs/2601.00756)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.LG

TL;DR: 本文提出MBC模型，通过码本优化策略压缩记忆库，并引入在线重置机制防止码本坍塌，结合键值低秩适配技术，在大幅减小记忆库规模的同时保持高知识保留准确率。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法在更新大语言模型知识时面临计算开销大、灾难性遗忘以及外部记忆库随数据流持续膨胀等问题。

Method: 提出MBC模型：1）采用码本优化策略压缩记忆库；2）设计在线重置机制防止码本坍塌；3）在LLM注意力层中引入Key-Value低秩适配（LoRA）以高效利用压缩后的记忆表示。

Result: 在基准问答数据集上，MBC将记忆库大小压缩至最强基线的0.3%，同时在在线适应学习中保持高知识保留准确率。

Conclusion: MBC有效解决了记忆库无限增长与知识遗忘的矛盾，为大语言模型的高效持续学习提供了新思路。

Abstract: Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.

</details>


### [154] [Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load](https://arxiv.org/abs/2601.00604)
*Francisco Aguilera Moreno*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的骑行时长预测方法，利用路线拓扑特征和运动员当前健身状态（来自训练负荷指标）进行预测，在单人数据集上实现了高精度（MAE=6.60分钟，R²=0.922），并证明加入生理状态指标可显著降低误差。


<details>
  <summary>Details</summary>
Motivation: 现有基于物理模型的骑行时长预测方法依赖难以获取的参数（如风阻系数、实时风速），对业余骑手不实用，亟需更易用、个性化的预测方案。

Method: 采用Lasso回归模型，输入为路线拓扑特征与运动员健身状态指标（CTL、ATL等训练负荷衍生指标），基于单被试（N-of-1）历史骑行数据（N=96）建模，并通过严格特征工程防止数据泄露。

Result: Lasso回归结合拓扑+健身特征达到MAE=6.60分钟、R²=0.922；相比仅用拓扑特征（MAE=7.66分钟），误差降低14%；支持分段动态预测，可用于实时赛事规划。

Conclusion: 运动员的生理状态是影响自定节奏骑行表现的关键约束因素；基于历史性能代理的机器学习方法可替代复杂物理建模，为业余骑手提供高精度、易部署的时长预测工具。

Abstract: Predicting cycling duration for a given route is essential for training planning and event preparation. Existing solutions rely on physics-based models that require extensive parameterization, including aerodynamic drag coefficients and real-time wind forecasts, parameters impractical for most amateur cyclists. This work presents a machine learning approach that predicts ride duration using route topology features combined with the athlete's current fitness state derived from training load metrics. The model learns athlete-specific performance patterns from historical data, substituting complex physical measurements with historical performance proxies. We evaluate the approach using a single-athlete dataset (N=96 rides) in an N-of-1 study design. After rigorous feature engineering to eliminate data leakage, we find that Lasso regression with Topology + Fitness features achieves MAE=6.60 minutes and R2=0.922. Notably, integrating fitness metrics (CTL, ATL) reduces error by 14% compared to topology alone (MAE=7.66 min), demonstrating that physiological state meaningfully constrains performance even in self-paced efforts. Progressive checkpoint predictions enable dynamic race planning as route difficulty becomes apparent.

</details>


### [155] [Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning](https://arxiv.org/abs/2601.00791)
*Valentin Noël*

Main category: cs.LG

TL;DR: 本文提出了一种无需训练的、基于注意力矩阵谱分析的方法，用于检测大语言模型在数学推理中的有效性；通过将注意力矩阵视为动态图的邻接矩阵，提取四个可解释的谱特征（Fiedler值、高频能量比HFER、图信号平滑度、谱熵），在多个模型上实现了85.0–95.6%的分类准确率，并揭示了注意力机制设计对判别性谱特征选择的影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖训练数据或形式验证器，难以区分逻辑正确性与技术性错误（如编译失败）；亟需一种无需微调、可解释、能直接反映推理连贯性的黑盒验证手段。

Method: 将Transformer各层注意力矩阵建模为动态图邻接矩阵，计算四种谱图理论指标：Fiedler值（代数连通性）、高频能量比（HFER）、图信号平滑度、谱熵；仅用单个阈值即可完成二元分类，无需训练、微调或监督学习。

Result: 在7个来自4个不同架构家族的模型上，该方法达到最高Cohen's d = 3.30（p < 10⁻¹¹⁶），准确率85.0–95.6%，校准后达93–95%；发现Mistral-7B因滑动窗口注意力导致判别特征从HFER转向晚期层平滑度（d = 2.09, p = 1.16×10⁻⁴⁸）；且能识别被形式验证器误拒但逻辑正确的证明。

Conclusion: 谱图分析为大模型数学推理验证提供了原理清晰、无需训练、高度可解释的新范式，具有 hallucination 检测与AI安全监控的直接应用价值。

Abstract: We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\text{MW}} = 1.16 \times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.

</details>


### [156] [Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning](https://arxiv.org/abs/2601.00607)
*Sonia Khetarpaul,P Y Sharan*

Main category: cs.LG

TL;DR: 本文提出了一种交通感知的图神经网络强化学习框架，用于城市出租车热点预测与调度优化，显著降低乘客等待时间和司机行驶距离。


<details>
  <summary>Details</summary>
Motivation: 传统出租车热点预测模型仅依赖历史需求数据，忽略了实时交通拥堵、道路事件和公共活动等动态因素的影响。

Method: 将城市路网建模为图结构，节点为交叉口，边为路段，并融合历史需求、事件 proximity 和实时拥堵评分；利用图神经网络（GNN）提取时空特征，结合Q-learning进行热点推荐，奖励函数综合考虑乘客等待时间、司机行驶距离和拥堵规避。

Result: 在基于德里真实地理与历史订单生成的仿真数据集上，相比随机选择基线，乘客等待时间减少约56%，司机行驶距离减少38%。

Conclusion: 该框架具备可扩展性，适用于多模态交通系统，并可集成至智慧城市平台实现城市出行实时优化。

Abstract: In the context of smart city transportation, efficient matching of taxi supply with passenger demand requires real-time integration of urban traffic network data and mobility patterns. Conventional taxi hotspot prediction models often rely solely on historical demand, overlooking dynamic influences such as traffic congestion, road incidents, and public events. This paper presents a traffic-aware, graph-based reinforcement learning (RL) framework for optimal taxi placement in metropolitan environments. The urban road network is modeled as a graph where intersections represent nodes, road segments serve as edges, and node attributes capture historical demand, event proximity, and real-time congestion scores obtained from live traffic APIs. Graph Neural Network (GNN) embeddings are employed to encode spatial-temporal dependencies within the traffic network, which are then used by a Q-learning agent to recommend optimal taxi hotspots. The reward mechanism jointly optimizes passenger waiting time, driver travel distance, and congestion avoidance. Experiments on a simulated Delhi taxi dataset, generated using real geospatial boundaries and historic ride-hailing request patterns, demonstrate that the proposed model reduced passenger waiting time by about 56% and reduced travel distance by 38% compared to baseline stochastic selection. The proposed approach is adaptable to multi-modal transport systems and can be integrated into smart city platforms for real-time urban mobility optimization.

</details>


### [157] [Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization](https://arxiv.org/abs/2601.00611)
*Hareshkumar Jadav,Ranveer Singh,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 本文提出了一种针对非负、非单调γ-弱DR-次模函数在向下封闭凸体上最大化问题的近似算法，其性能保证随γ平滑变化，在γ=1时达到0.401的近似比，并在γ<1时优于先前结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理非单调γ-弱DR-次模函数最大化时性能有限，尤其在γ<1时缺乏紧致且平滑依赖γ的近似保证。

Method: 结合Frank-Wolfe引导的连续贪心框架与γ感知的双贪心步骤，以有效应对非单调性。

Result: 获得了目前最优的近似比，特别地在γ=1时恢复0.401，在γ<1时优于已有工作。

Conclusion: 该算法为非单调γ-弱DR-次模函数在向下封闭凸约束下的最大化提供了状态最优、γ自适应的理论保证与实用方案。

Abstract: Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.

</details>


### [158] [Do Chatbot LLMs Talk Too Much? The YapBench Benchmark](https://arxiv.org/abs/2601.00624)
*Vadim Borisov,Michael Gröger,Mina Mikhael,Richard H. Schreiber*

Main category: cs.LG

TL;DR: 本文提出了YapBench基准，用于量化大语言模型在简洁性理想提示下的过度生成问题，并引入YapScore和YapIndex指标评估模型冗余长度，发现不同模型存在显著的 verbosity 差异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM常对简单请求生成过长回答，增加认知负担与推理成本；偏好式后训练和LLM评判易引入长度偏差，需客观、用户可见的简洁性评估基准。

Method: 构建轻量级基准YapBench，含300+英文提示，每项含单轮提示、精简充分基线答案及类别标签；定义字符级YapScore（响应超长量）和YapIndex（类别中位YapScore的等权均值）；在76个LLM上评测。

Result: 76个LLM在YapBench上呈现数量级差异的中位冗余长度；三类场景（模糊输入澄清、封闭式事实问答、单行编程）暴露出不同失败模式，如模糊输入下的‘真空填充’、技术请求中的解释/格式冗余。

Conclusion: YapBench为评估和追踪LLM verbosity提供了可复现、跨模型、用户导向的标准化工具；结果揭示当前LLM普遍存在系统性过度生成问题，亟需针对性优化。

Abstract: Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.
  We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.
  YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.

</details>


### [159] [Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability](https://arxiv.org/abs/2601.00655)
*Kasra Fouladi,Hamta Rahmani*

Main category: cs.LG

TL;DR: 本文提出了可解释性引导的双目标优化（IGBO）框架，通过将领域知识编码为有向无环图（DAG）并结合时序集成梯度（TIG）与最优路径预言机，提升模型可解释性与OOD鲁棒性，在保持精度的同时有效满足结构约束。


<details>
  <summary>Details</summary>
Motivation: 解决现有可解释机器学习方法在引入结构化领域知识（如特征重要性层级）时难以兼顾模型准确性与可解释性，以及时序集成梯度（TIG）在分布外（OOD）场景下计算不稳定的问题。

Method: 提出IGBO框架：1）将特征重要性层级建模为DAG；2）采用时序集成梯度（TIG）量化特征重要性；3）设计最优路径预言机以学习数据流形感知的积分路径，缓解OOD问题；4）构建双目标优化问题联合优化预测性能与DAG约束一致性。

Result: 理论证明了IGBO的收敛性及对小批量噪声的鲁棒性；在时序数据上的实验表明，IGBO能在极小精度损失下严格满足DAG结构约束，并显著优于标准正则化基线方法。

Conclusion: IGBO为融合结构化先验知识与深度模型训练提供了新范式，兼顾可解释性、鲁棒性与预测性能，尤其适用于需强领域约束的时序建模任务。

Abstract: This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.

</details>


### [160] [Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation](https://arxiv.org/abs/2601.00664)
*Taekyung Ki,Sangwon Jang,Jaehyeong Jo,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.LG

TL;DR: 本文提出Avatar Forcing框架，通过扩散强制（diffusion forcing）实现实时、低延迟的交互式 talking head 生成，并引入无标签偏好优化方法，显著提升 avatar 的反应性与表现力。


<details>
  <summary>Details</summary>
Motivation: 现有talking head模型缺乏真正交互感，表现为单向响应、情感参与不足；两大挑战是实时因果运动生成与无需标注数据的生动反应学习。

Method: 提出Avatar Forcing框架：1）基于扩散模型的因果实时生成机制，融合用户音频与运动模态输入；2）直接偏好优化（DPO），利用丢弃用户条件构造合成负样本，实现无监督表达性学习。

Result: 实现实时交互（~500ms延迟，较基线快6.8倍）；用户研究显示其生成动作在反应性与表现力上优于基线80%以上。

Conclusion: Avatar Forcing有效解决了交互式avatar生成中的实时性与表达性难题，为虚拟沟通提供了更自然、沉浸的解决方案。

Abstract: Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.

</details>


### [161] [IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning](https://arxiv.org/abs/2601.00677)
*Haonan Song,Qingchen Xie,Huan Zhu,Feng Xiao,Luxi Xing,Fuzhen Li,Liu Kang,Feng Jiang,Zhiyong Zheng,Fan Yang*

Main category: cs.LG

TL;DR: 本文提出IRPO框架，通过引入Bradley-Terry模型将生成式奖励模型（GRM）从计算开销大的 pairwise 形式转为高效 pointwise 形式，在保持可解释性和细粒度奖励信号的同时，显著提升RL训练效率与后训练表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有pairwise生成式奖励模型（GRMs）在与RL算法（如GRPO）联合使用时存在的O(n^2)计算瓶颈和重复采样/CoT推理开销问题。

Method: 提出Intergroup Relative Preference Optimization（IRPO）框架，将Bradley-Terry模型融入GRPO，实现对每个响应生成pointwise得分，从而支持任意数量候选响应的高效评估。

Result: IRPO在多个基准上达到pointwise GRMs中的SOTA性能，与当前领先pairwise GRMs性能相当，并在post-training评估中显著优于后者。

Conclusion: IRPO在不牺牲可解释性与奖励精细度的前提下，有效缓解了pairwise GRMs的计算瓶颈，为GRMs与RL的高效协同提供了新范式。

Abstract: Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.

</details>


### [162] [ARISE: Adaptive Reinforcement Integrated with Swarm Exploration](https://arxiv.org/abs/2601.00693)
*Rajiv Chaitanya M,D R Ramesh Babu*

Main category: cs.LG

TL;DR: ARISE是一种轻量级的强化学习探索增强框架，通过在标准策略梯度方法上增加基于粒子群的自适应探索层，在非平稳奖励和高维策略场景下显著提升性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中特别是在非平稳奖励或高维策略下的有效探索难题。

Method: 提出ARISE框架，将策略动作与粒子驱动的行动空间轨迹采样相结合，并利用奖励方差信号自适应调节探索强度。

Result: 在LunarLander-v3和Hopper-v4上分别提升46%和22%，在非平稳奖励下CartPole上比PPO高出75分；消融实验证明粒子群组件与自适应机制均关键。

Conclusion: ARISE是一种简单、架构无关的增强方案，可在不修改核心算法结构的前提下提升RL智能体的探索能力与环境变化鲁棒性。

Abstract: Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.

</details>


### [163] [BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting](https://arxiv.org/abs/2601.00698)
*Maximilian Reinwardt,Michael Eichelbeck,Matthias Althoff*

Main category: cs.LG

TL;DR: 本文提出了一种名为B-Spline Adaptive Tokenizer (BSAT)的新方法，用于解决基于Transformer的长期时间序列预测中自注意力计算复杂度高和固定分块不适应数据语义结构的问题；BSAT通过B样条拟合时间序列实现自适应分段，并结合新型混合位置编码L-RoPE，在多个基准上实现了高压缩率下的高性能，适用于内存受限场景。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的时间序列预测方法面临两个主要问题：一是自注意力机制带来O(n^2)的计算复杂度，难以扩展到长序列；二是统一长度的patching策略无法适配时间序列内在的多尺度、非平稳语义结构，导致信息损失或冗余。

Method: 提出B-Spline Adaptive Tokenizer（BSAT）：一种无参数、基于B样条拟合的自适应分段方法，将高曲率区域分配更多token，并将变长样条基函数编码为固定大小token（含系数与位置）；同时设计混合位置编码L-RoPE，融合可学习加性位置编码与层间可学习底数的RoPE，使各层能建模不同时间依赖模式。

Result: 在多个公开时间序列预测基准（如ETT、Weather、Electricity等）上验证了方法有效性；相比主流Transformer模型（如Informer、Autoformer、FEDformer），在高压缩率（即更少token）下仍保持强竞争力，显著降低显存占用与计算开销。

Conclusion: BSAT+L-RoPE构成了一种高效、自适应、低资源消耗的时间序列Transformer建模框架，突破了传统均匀分块与固定位置编码的局限，为长时序预测在边缘设备或大规模部署场景提供了新思路。

Abstract: Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.

</details>


### [164] [Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL](https://arxiv.org/abs/2601.00728)
*Erin Carson,Xinye Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习（RL）的自适应精度调优框架，用于线性求解器等数值算法，将问题建模为上下文赌博机，并通过离散化状态空间与Q表学习动态选择最优计算精度，在精度与效率间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有混合精度方法多依赖人工经验或静态策略，难以在动态变化的数值计算场景中自动、高效地平衡精度与计算开销；需一种数据驱动、可泛化的自适应精度决策机制。

Method: 将精度选择建模为上下文赌博机问题，采用增量式动作值估计与ε-贪婪策略优化Q表；状态由离散化的系统特征（如近似条件数、矩阵范数）构成，动作为空间中的精度配置（如单/双精度组合），奖励函数兼顾求解精度与计算成本。

Result: 在迭代精化求解Ax=b任务中，该方法显著降低计算开销，同时保持与双精度基线相当的数值精度；且在未见过的数据集上具有良好泛化能力。

Conclusion: 这是首个将强化学习应用于精度自动调优并经未见数据验证的工作，为科学计算中混合精度算法的智能化提供了新范式。

Abstract: We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.

</details>


### [165] [Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty](https://arxiv.org/abs/2601.00737)
*Uğurcan Özalp*

Main category: cs.LG

TL;DR: 本文提出了一种新的离策略Actor-Critic算法STAC，利用分布式批评家网络建模时序（单步）偶然不确定性（aleatoric uncertainty），以实现对TD更新的悲观偏差调节，避免依赖集成方法估计认知不确定性（epistemic uncertainty），从而缓解价值高估问题，并提升训练稳定性与计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有离策略Actor-Critic方法中，批评家网络普遍存在系统性价值高估问题；常用基于集成的认知不确定性估计引入悲观偏差，但计算开销大、扩展性受限。

Method: 提出Stochastic Actor-Critic（STAC）算法：采用单个分布式批评家网络建模贝尔曼目标中的时序偶然不确定性（来自环境转移、奖励及策略随机性），并结合Dropout正则化批评家与执行器网络。

Result: 实验证明，仅靠分布式批评家带来的悲观偏差即可有效缓解高估问题，并自然诱导风险规避行为；加入Dropout进一步提升了训练稳定性和性能；整体实现更高计算效率。

Conclusion: 基于偶然不确定性的悲观偏差机制优于依赖集成的认知不确定性估计，STAC在保持高性能的同时显著降低计算复杂度，为鲁棒、高效离策略强化学习提供了新思路。

Abstract: Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncertainty estimates. Current methods employ ensembling to quantify the critic's epistemic uncertainty-uncertainty due to limited data and model ambiguity-to scale pessimistic updates. In this work, we propose a new algorithm called Stochastic Actor-Critic (STAC) that incorporates temporal (one-step) aleatoric uncertainty-uncertainty arising from stochastic transitions, rewards, and policy-induced variability in Bellman targets-to scale pessimistic bias in temporal-difference updates, rather than relying on epistemic uncertainty. STAC uses a single distributional critic network to model the temporal return uncertainty, and applies dropout to both the critic and actor networks for regularization. Our results show that pessimism based on a distributional critic alone suffices to mitigate overestimation, and naturally leads to risk-averse behavior in stochastic environments. Introducing dropout further improves training stability and performance by means of regularization. With this design, STAC achieves improved computational efficiency using a single distributional critic network.

</details>


### [166] [The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving](https://arxiv.org/abs/2601.00747)
*Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文提出Distributional Creative Reasoning（DCR）框架，统一建模基于分布的创造性推理，揭示了现有LLM推理方法（如STaR、GRPO、DPO）因过度追求正确性而导致推理路径多样性衰减（语义熵坍缩）的根本问题，并给出防止坍缩、兼顾正确性与创造性的理论保障与实用方案。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理流程（如bootstrapped reasoning）过度优化正确性，导致推理路径分布坍缩、语义熵下降，损害创造性问题求解能力。

Method: 提出DCR——一种基于概率测度上梯度流的变分目标框架，将STaR、GRPO、DPO、熵正则等方法统一为特例，并推导多样性衰减定理、设计稳定多样策略的收敛条件。

Result: （i）证明正确性导向目标引发不同形式的多样性衰减；（ii）给出确保策略稳定且多样的收敛设计；（iii）提供简单可实施的训练配方。

Conclusion: DCR是首个兼顾正确性与创造性的LLM推理原则性框架，为避免推理坍缩提供了理论基础与实践路径。

Abstract: State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.

</details>


### [167] [A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football](https://arxiv.org/abs/2601.00748)
*Sean Groom,Shuo Wang,Francisco Belo,Axl Rice,Liam Anderson*

Main category: cs.LG

TL;DR: 本文提出了一种协变量依赖的隐马尔可夫模型（CDHMM），用于在角球场景中从球员追踪数据中无标签推断盯人与区域防守分配，并构建了基于角色的‘幽灵化’反事实分析框架，以更合理、可解释地评估无球防守表现。


<details>
  <summary>Details</summary>
Motivation: 传统足球防守评估指标难以刻画限制对手行动选择与成功率的复杂协同移动；现有基于占有值或‘幽灵化’的反事实方法缺乏战术上下文。

Method: 提出协变量依赖的隐马尔可夫模型（CDHMM），在角球场景下无监督地从追踪数据中推断时间分辨的盯人/区域防守角色；进而构建角色条件化的幽灵化方法与防守贡献归因框架。

Result: 实现了对角球阶段无球防守行为的可解释、上下文感知的量化评估，提升了防守贡献归因与反事实分析的战术相关性。

Conclusion: CDHMM及配套框架为结构化比赛场景（如角球）中的无球防守评估提供了新范式，弥补了占有值模型在防守端应用的空白，并增强了反事实分析的战术真实性。

Abstract: Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating "average" behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.

</details>


### [168] [Categorical Reparameterization with Denoising Diffusion models](https://arxiv.org/abs/2601.00781)
*Samson Gourevitch,Alain Durmus,Eric Moulines,Jimmy Olsson,Yazid Janati*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散过程的分类变量软重参数化方法，利用高斯加噪过程下的去噪器闭式解实现无需训练的扩散采样与反向传播，提升了梯度优化性能。


<details>
  <summary>Details</summary>
Motivation: 解决分类变量梯度优化中score-function估计器噪声大、连续松弛引入偏差的问题。

Method: 引入基于扩散过程的软重参数化，利用高斯加噪下分类分布去噪器的闭式解构建可微采样路径。

Result: 在多个基准任务上，所提方法展现出有竞争力甚至更优的优化性能。

Conclusion: 扩散机制可为分类变量提供高效、免训练、低偏差的重参数化方案，拓展了连续松弛方法族。

Abstract: Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.

</details>


### [169] [FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing](https://arxiv.org/abs/2601.00785)
*Sunny Gupta,Amit Sethi*

Main category: cs.LG

TL;DR: 本文提出FedHypeVAE，一种基于差分隐私与超网络的联邦嵌入级数据生成框架，通过客户端感知解码器、类条件先验及局部MMD对齐，在非独立同分布（non-IID）下实现个性化生成与强隐私保障。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入级生成方法在客户端数据非独立同分布（non-IID）下性能下降，且缺乏对梯度泄露的严格形式化隐私保护。

Method: 提出FedHypeVAE：以条件变分自编码器（CVAE）为骨干，用共享超网络动态生成客户端专属解码器和类条件潜在先验；超网络训练施加差分隐私（裁剪+噪声）；引入局部MMD损失对齐真实/合成嵌入分布，并添加Lipschitz正则化提升稳定性；支持中性元码合成与多域混合控制。

Result: 在多个non-IID联邦基准上验证了FedHypeVAE在生成质量、下游任务性能及隐私保障（如梯度反演攻击鲁棒性）方面显著优于现有方法。

Conclusion: FedHypeVAE首次在生成器层级统一实现客户端个性化、差分隐私保障与非IID下的分布一致性，为联邦学习中的隐私保护数据合成提供了新范式。

Abstract: Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [170] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 本文提出了一种推理感知的知识检索方法，通过粗粒度到细粒度的两阶段检索策略，结合蒙特卡洛树搜索思想，在对话上下文中精准定位与逻辑结构匹配的知识，从而提升大语言模型在多轮对话中的响应质量、信息量和创造性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在检索与推理能力协同优化方面存在显著挑战，尤其是难以将检索内容与对话内在的逻辑推理过程对齐。

Method: 提出推理感知的知识检索方法：采用粗到细两阶段策略——先基于话题相关性筛选知识库子区域，再在该区域内聚焦于支持当前推理步骤的知识；全程使用受蒙特卡洛树搜索启发的关键词导航机制遍历知识句子。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更契合人类对话的内在推理逻辑，还显著提升了检索知识的多样性，进而生成更富信息量和创造性的响应。

Conclusion: 推理与检索的深度协同可行且有效；将知识检索锚定于推理过程而非表层语义，是提升LLM对话能力的关键路径。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [171] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 本研究提出了一种基于微调大语言模型（LLM）的尼日利亚皮钦语自动化抑郁筛查方法，通过构建432条皮钦语音频数据集并进行细粒度标注，评估了Phi-3、Gemma-3和GPT-4.1在准确性与文化适配性上的表现，其中GPT-4.1以94.5%准确率最优，为资源有限、语言多样的地区提供了可行的心理健康筛查新范式。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁筛查覆盖率低，受限于临床资源匮乏、病耻感及语言障碍；现有PHQ-9等工具缺乏对尼日利亚皮钦语及520余种本土语言的文化与语言适配性。

Method: 收集432条尼日利亚年轻成人（18–40岁）用皮钦语回答PHQ-9相关心理体验问题的音频，经转录、预处理与多维标注（语义标签、俚语/习语释义、PHQ-9严重度评分），并对Phi-3-mini-4k-instruct、Gemma-3-4B-it和GPT-4.1三个LLM进行微调与定量（准确率、精确率、语义一致性）及定性（清晰度、相关性、文化适宜性）评估。

Result: GPT-4.1在PHQ-9严重度预测中达到94.5%准确率，显著优于其他两个模型；定性评估亦显示其生成响应最具文化适宜性、清晰性与上下文相关性。

Conclusion: 微调后的LLM（尤其是GPT-4.1）可有效支持尼日利亚等语言多元、资源受限地区的AI辅助抑郁筛查，为本地化心理健康数字工具的部署奠定基础。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [172] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的智能体，用于从原始文本中自动提取因果反馈型模糊认知图（FCM），并通过三步指令引导实现概念节点与模糊因果边的抽取；该系统在Kissinger等人关于AI的论文上验证有效，并能融合多LLM生成的FCM以产生新平衡态。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从非结构化文本中自动、准确地提取具有动态因果关系的模糊认知图（FCM），而人工构建费时且主观性强；亟需一种兼具自主性与可控性的因果建模智能体。

Method: 设计一个具备半自主性的LLM智能体，通过三步系统指令依次完成：1）提取关键名词/名词短语；2）从中筛选FCM概念节点；3）推断模糊因果边；并引入FCM动力学平衡（极限环/不动点）反向驱动LLM检索与处理文本，形成双向自适应闭环。

Result: 在Henry Kissinger等人关于AI的论文上成功生成FCM，其动力学平衡（极限环）与人工构建FCM一致，尽管节点与边数量不同；进一步混合Gemini与ChatGPT各自生成的FCM，所得混合FCM既继承主导成分的平衡态，又涌现出新平衡态，提升对底层因果系统的逼近能力。

Conclusion: 该LLM-FCM联合框架实现了因果知识建模的‘有 leash 的自治’——既利用LLM语义理解能力实现自动化抽取，又以FCM动力学约束其行为边界；为可解释AI与复杂系统建模提供了新范式。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [173] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 本文提出了一种基于不可逆信息处理的智能物理理论，将智能定义为每纳特（nat）不可逆处理信息所产生的目标导向功，并通过守恒一致编码（CCE）框架连接信息与物理状态，揭示了智能系统的物理约束、内在认知极限及高效运作机制。


<details>
  <summary>Details</summary>
Motivation: 传统智能理论缺乏与物理基本定律（如守恒律和热力学第二定律）的深层联系；本文旨在建立一个统一、基质无关的智能物理理论，解释智能如何在真实物理系统中实现并受限。

Method: 构建守恒一致编码（CCE）框架，将信息编码映射到受守恒律保护的亚稳态吸引子盆地；定义智能为‘目标导向功/不可逆处理信息量’；结合非平衡热力学、动力系统理论与信息论，推导物理约束层级、自建模机制与认知极限；应用于生物神经动力学与连续动力学电路建模，并延伸至AI安全分析。

Result: 揭示了长时程效率依赖于内部信息结构保持，从而自然引出自建模；证明物理具身智能系统存在类哥德尔不完备性的内在认识论极限；预测大脑处于该框架所指明的高效临界运行区域；表明布尔逻辑是吸引子选择的特例，更一般的不变几何支持超越定点逻辑的计算模式；提出基于不可逆信息流与结构稳态的AI安全新视角。

Conclusion: 智能是一种可被物理定律刻画的基本现象，其本质在于受守恒律约束的不可逆信息—功转译过程；该理论为理解自然与人工智能提供了统一、普适且可检验的物理基础。

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [174] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文提出了一种多算法方法，用于在城市末端快递配送中平衡配送员的工作量，兼顾距离与工作负荷，以实现更公平、高效的任务分配。


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法易导致配送员间工作负载不均衡，影响系统效率与公平性。

Method: 提出多算法框架，融合k-means聚类、进化算法、基于k-means初始化的递归分配及混合进化集成算法，综合考虑配送点距离与个体工作负荷进行任务分配。

Result: 在西班牙Azuqueca de Henares的真实城市末端配送场景中验证了该方法的有效性，显著改善了配送员日工作量的均衡性。

Conclusion: 所提多算法方法能有效实现人力 workload balancing，提升末端配送系统的整体效率与公平性，具备实际部署价值。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [175] [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)
*Sixue Xing,Xuanye Xia,Kerui Wu,Meng Jiang,Jintai Chen,Tianfan Fu*

Main category: cs.AI

TL;DR: 本文提出ClinicalReTrial，一种自演化的AI代理框架，将临床试验推理建模为迭代式方案重设计问题，在闭环奖励驱动优化中实现失败诊断、安全性感知修改与候选方案评估，显著提升试验成功率。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法仅能被动预测临床试验失败风险，缺乏提供可操作改进方案的能力，亟需主动干预机制。

Method: 提出ClinicalReTrial框架，融合失败诊断、安全感知的协议修改和候选评估，以结果预测模型为仿真环境，构建奖励驱动的闭环优化，并采用分层记忆机制支持跨试验知识迁移。

Result: 在实验中，ClinicalReTrial成功改进83.3%的试验方案，平均成功率提升5.7%；回溯案例研究显示其重设计策略与真实世界修改高度一致。

Conclusion: ClinicalReTrial实现了从风险预测到主动优化的范式转变，为提升临床试验成功率提供了可解释、可行动的AI解决方案。

Abstract: Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.

</details>


### [176] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 本文提出了一种基于新手牌评估指标MinDist的规则化印度拉米（13张牌）策略框架，该指标通过编辑距离衡量手牌与合法组合的结构接近度，并结合对手建模与零和博弈模拟进行策略评估，实验表明其显著提升了胜率。


<details>
  <summary>Details</summary>
Motivation: 13张牌的印度拉米是一种不完全信息序贯博弈，需概率推理与组合决策，现有启发式方法缺乏形式化与可解释性。

Method: 提出MinDist手牌评估指标（改进自MinScore，引入编辑距离），设计基于动态剪枝与模式缓存的高效算法精确计算该指标；在双人零和仿真框架中融入对手手牌建模；采用统计假设检验评估策略性能。

Result: MinDist-based智能体相比传统启发式方法在胜率上取得统计显著提升。

Conclusion: MinDist为印度拉米策略设计提供了形式化、可解释且高效的算法基础，是迈向可理解AI博弈策略的重要一步。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [177] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: 本文提出了一种受生物自愈机制启发的智能体框架ReCiSt，用于提升分布式计算连续体系统（DCCS）的韧性与自主故障恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现代分布式计算连续体系统（DCCS）因异构性、移动性和动态运行环境而频繁发生故障，亟需可扩展、自适应、自调节的韧性策略。

Method: 将人体生理自愈四阶段（止血、炎症、增生、重塑）映射为计算四层架构（Containment, Diagnosis, Meta-Cognitive, Knowledge），并由语言模型驱动的多智能体协同完成日志解析、根因推理、资源重配置与知识沉淀。

Result: 在公开故障数据集上验证了ReCiSt可在数十秒内完成自愈，CPU占用率低至10%；同时展现出应对不确定性的深度分析能力及微智能体协同规模的有效性。

Conclusion: ReCiSt为DCCS提供了首个类生物自愈范式的LM驱动智能体框架，填补了该领域研究空白，并验证了其高效性与可行性。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [178] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 本研究探讨生成式AI系统如何解读乡土建筑形式中蕴含的建筑智慧，以伊朗鸽塔为案例，测试了Midjourney v6、DALL-E 3和基于Stable Diffusion XL的DreamStudio三种扩散模型在参照性、适应性和推测性三类提示下的表现，并通过五项标准评估其对类型学、材料性、环境、真实感与文化特异性的重构能力。结果表明AI能可靠复现几何图案，但常误读材料与气候逻辑；参考图像提升真实感却抑制创造力，而脱离参考则产生富有创意但文化模糊的结果。研究划定了视觉相似性与建筑推理之间的边界，提出‘计算性乡土推理’作为分析AI如何感知、扭曲与再想象传统设计智慧的新框架。


<details>
  <summary>Details</summary>
Motivation: 探究生成式AI系统如何理解并再现乡土建筑中隐含的建筑智慧与地域逻辑，尤其关注其是否具备超越表观模仿的深层设计推理能力。

Method: 以伊朗鸽塔为典型案例，采用Midjourney v6、DALL-E 3和DreamStudio（基于SDXL）三种扩散模型，在参照性、适应性、推测性三阶段提示下生成图像；构建涵盖类型学、材料性、环境、真实感、文化特异性的五维评估框架进行系统性比较分析。

Result: AI能稳定复现几何形态，但普遍误读材料选择与气候响应逻辑；引入参考图像可提升视觉真实感但削弱创造性表达；无参考条件下生成结果更具创新性，却丧失文化语境准确性；揭示AI当前仅具表层视觉映射能力，缺乏对乡土建筑深层设计理据的理解。

Conclusion: 生成式AI尚不能真正‘理解’乡土建筑的建构逻辑与环境智慧，其输出本质是视觉统计关联而非建筑推理；研究提出‘计算性乡土推理’概念，为评估AI在文化遗产与建筑设计领域的能力边界提供新范式。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [179] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar是一个结合质量-多样性算法与大语言模型的系统，用于自动演化游戏机制，通过合成完整游戏并评估其技能导向的玩家排序能力来筛选机制。


<details>
  <summary>Details</summary>
Motivation: 手动设计游戏机制耗时且依赖专家经验，亟需自动化方法提升游戏设计效率与多样性。

Method: 将质量-多样性算法与大语言模型结合，通过树搜索合成含演化机制与存档机制的完整游戏，并以玩家技能排序一致性作为核心评估指标。

Result: Mortar生成的游戏具有多样性与可玩性，演化出的机制显著提升技能排序得分；消融实验和用户研究验证了各组件有效性及人类对游戏的正向评价。

Conclusion: Mortar为自动游戏设计提供了可行、可评估的新范式，证明了AI驱动机制演化在保持技能导向性方面的潜力。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [180] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: 本文提出一种混合智能体框架，将大语言模型（LLM）作为自然语言接口，调用严格算法执行库存优化，避免其直接求解导致的“幻觉税”；实验表明该框架相较端到端LLM求解可降低32.1%总库存成本，并验证性能瓶颈在于计算能力而非信息获取。


<details>
  <summary>Details</summary>
Motivation: 中小型企业缺乏部署先进优化方法的专业能力，亟需易用、可靠的库存管理辅助工具；而直接用大语言模型（LLM）作端到端求解器存在因缺乏接地随机推理能力而导致的性能下降问题。

Method: 提出严格解耦语义推理与数学计算的混合智能体框架：LLM仅负责自然语言参数提取与结果解释，调用严谨优化算法构建求解引擎；并设计细调的‘人类模仿器’（Human Imitator）作为受限理性的管理者数字孪生体，用于对系统进行可扩展、可复现的压力测试。

Result: 混合智能体框架使总库存成本较GPT-4o端到端交互基线降低32.1%；实验证明即使提供完美真值信息，GPT-4o性能也无法提升，确认瓶颈在于计算能力而非信息缺失。

Conclusion: LLM不应替代运筹学方法，而应作为自然语言接口，使基于求解器的严谨策略对非专家用户可及；该框架弥合了理论优化与实际业务应用之间的鸿沟。

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [181] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: 本文提出Mathesis，一种神经符号架构，通过将数学状态编码为高阶超图，并利用可微逻辑引擎（SRK）将约束映射到连续能量景观，实现基于梯度的证明搜索与能量最小化，从而提升大语言模型在复杂逻辑推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂推理中持续存在逻辑错误，根源在于缺乏内在的公理化框架。

Method: 提出Mathesis架构：用高阶超图编码数学状态；设计可微的符号推理核（SRK），定义全局能量函数E(G)，使零能量对应逻辑一致性；利用梯度信号训练超图Transformer Brain；结合蒙特卡洛树搜索与进化式证明搜索，并由学习到的价值函数和语义合一机制引导多步演绎。

Result: 实现了将证明搜索转化为能量最小化问题，支持多步逻辑演绎，并提供梯度驱动的端到端可训练推理框架。

Conclusion: Mathesis通过融合神经网络与符号逻辑，在保持可微性的同时引入形式化推理能力，为解决LLMs的逻辑缺陷提供了新范式。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [182] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 本文研究了视觉语言模型（VLM）在视频问答任务中基于置信度的主动拒绝（abstention）策略是否能可靠控制错误率，并评估其在分布偏移下的鲁棒性；结果表明，置信度阈值法在分布内有效，但在分布外性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 高风险场景下部署视觉语言模型需具备选择性预测能力（即在不确定时主动拒绝回答），以避免高代价错误；但现有置信度驱动的拒绝机制在分布偏移下的可靠性尚不明确。

Method: 在NExT-QA数据集上，使用Gemini 2.0 Flash模型，通过设定不同置信度阈值ε进行置信度阈值化（confidence thresholding），分析其在分布内与分布外的错误率控制能力及风险-覆盖率权衡曲线。

Result: 1）在分布内，置信度阈值可实现平滑、可控的风险-覆盖率权衡；2）在分布偏移下，该机制失效，错误率控制能力显著退化，模型倾向于过度自信。

Conclusion: 基于置信度的主动拒绝虽在分布内有效，但缺乏跨分布鲁棒性，亟需更可靠的不确定性校准或拒绝机制以支撑高风险部署。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [183] [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)
*Tiansi Dong,Henry He,Pietro Liò,Mateja Jamnik*

Main category: cs.AI

TL;DR: 本文比较了三种神经推理方法：大语言模型（LLM）推理、监督学习推理和显式模型构建推理，发现基于显式模型（如Sphere Neural Network）的推理最可靠，能避免灾难性遗忘并支持严格的逻辑推理。


<details>
  <summary>Details</summary>
Motivation: LLM在简单决策任务上不可靠，而监督学习推理存在灾难性遗忘和模式级局限性，亟需更可靠的神经推理范式。

Method: 提出基于球面几何的Sphere Neural Network，将概念表示为n维球面上的圆，用补圆表示否定，并通过过滤不满足逻辑的圆形配置实现可靠推理；对比测试Euler Net与Sphere Neural Network在经典及选言三段论任务上的表现。

Result: Sphere Neural Network成功掌握16种三段论任务（含严格选言三段论），保持经典三段论严谨性；Euler Net在选言任务上达100%准确率但经典任务性能骤降至6.25%，体现严重灾难性遗忘。

Conclusion: 显式模型构建的神经推理在可靠性上优于LLM推理和监督学习推理，是当前最可靠的神经推理方法学类别。

Abstract: This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.

</details>


### [184] [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)
*Shanli Xing,Yiyan Zhai,Alexander Jiang,Yixin Dong,Yong Wu,Zihao Ye,Charlie Ruan,Yingyi Huang,Yineng Zhang,Liangsheng Yin,Aksara Bayyapu,Luis Ceze,Tianqi Chen*

Main category: cs.AI

TL;DR: FlashInfer-Bench 提出一个标准化闭环框架，连接AI生成GPU核的生成、评测与部署，支持自动注入最优核至主流LLM推理引擎。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型自动生成GPU核后难以集成到真实推理系统中的问题。

Method: 构建基于真实服务轨迹的FlashInfer-Bench框架，含统一Trace Schema、评测基准、公开排行榜和动态替换机制apply()。

Result: 实现了LLM生成核在SGLang和vLLM等生产引擎中的无缝部署，并评估了不同GPU编程语言的性能权衡。

Conclusion: FlashInfer-Bench为AI生成GPU核的持续优化与规模化部署提供了实用、可复现的技术路径。

Abstract: Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.

</details>


### [185] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 本文揭示了大语言模型（LLM）代理不仅存在人口统计学偏见，还可能因微小的‘我们vs.他们’线索而产生群体间偏见；当这种群体界限与‘代理-人类’分界重合时，人类整体可能被视作外群体；作者构建多智能体社会模拟验证该现象，并提出一种新型‘信念投毒攻击（BPA）’来操控代理对自身及人类身份的信念，从而诱发对外群体（人类）的偏见；最后探讨了在档案与记忆边界上可行的防御策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究关注LLM代理对不同人类群体的偏见，但忽视了更根本的风险：当代理将自身与人类划分为不同群体时，可能系统性地将整个人类视为外群体，导致群体层面的不对称对待。

Method: 构建基于显式收益权衡的可控多智能体社会模拟实验；设计信念投毒攻击（BPA），包括初始化阶段的档案投毒（BPA-PP）和通过优化后缀注入存储反思中的记忆投毒（BPA-MP）；评估偏见表现及攻击有效性。

Result: 实验证实LLM代理在最小群体线索下即表现出稳定群体间偏见；人类身份提示可削弱偏见，但依赖于代理‘相信真实人类存在’这一隐含信念；BPA能有效破坏该信念，重新激活对人类的外群体偏见；多种设置下BPA均展现出高攻击成功率。

Conclusion: LLM代理存在本质性的群体间偏见风险，其行为受内在身份信念调控；信念投毒构成新型安全威胁；需在代理系统的设计中强化档案与记忆边界的安全机制，以防范此类攻击，推动更安全的代理发展。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [186] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 本文提出了一种'金融蜂群（Financial Swarm）'模型，将流动性博弈与理性蜂群结合，利用差分奖励机制，在无需协调或共谋的前提下，使独立交易者在追求个体利润的同时提升整体市场流动性与效率。


<details>
  <summary>Details</summary>
Motivation: 推动蜂群智能与金融市场建模的交叉研究：一方面用博弈论解释蜂群中理性个体如何实现集体效用；另一方面理解金融市场上独立代理如何自组织以提升市场稳定性与效率。

Method: 将流动性博弈（Liquidity Games）与理性蜂群（Rational Swarms）统一，构建基于马尔可夫团队博弈框架的理论模型，引入差分奖励（difference rewards）机制引导去中心化代理的学习行为。

Result: 证明个体以最大化自身流动性为目标的行为，可在无协调、无共谋条件下自然提升整体市场流动性；该模型支持双边资产市场中个体盈利性与集体市场效率的双重达成。

Conclusion: 金融蜂群模型为建模理性、独立金融代理提供新范式，弥合了多智能体系统理论与实际金融市场设计之间的鸿沟，具有跨领域方法论价值。

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [187] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种自适应因果协调检测（ACCD）框架，通过三阶段架构（自适应CCM因果发现、主动学习半监督分类、基于历史经验的自动验证）提升社交平台协同行为检测的准确性、效率与自动化水平，在真实数据集上F1提升15.2%，人工标注减少68%，处理速度提升2.8倍。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖表层相关性分析、静态参数设置，且需大量人工标注，难以应对多样化的协同行为场景。

Method: 提出ACCD三阶段框架：1）自适应Convergent Cross Mapping（CCM）识别账户间真实因果关系；2）结合不确定性采样的主动学习半监督分类，降低标注负担；3）基于历史检测经验的自动验证模块实现结果自检与优化。

Result: 在Twitter IRA、Reddit协调痕迹及主流机器人检测基准上，ACCD达到87.3% F1-score，较最强基线提升15.2%；人工标注需求减少68%，处理速度提升2.8倍。

Conclusion: ACCD是一种更准确、高效、高度自动化的端到端协同行为检测方案，具有显著实用价值和广泛适用潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [188] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 本文将语义空间推理方法从计算语言学拓展至团队体育的战术决策，通过将球员建模为多维向量、球队配置视为语义结构，在共享向量空间中量化战术适配性与对手可利用性，并提供可解释、自适应的策略建议。


<details>
  <summary>Details</summary>
Motivation: 传统战术分析缺乏可计算、可泛化的语义建模框架；受文本中词语组合生成意义的启发，提出将球队类比为文本、球员类比为词语，以统一向量空间支持战术理解与优化。

Method: 将球员表示为融合技术、体能、心理属性的多维向量；通过上下文加权聚合构建球队语义表征；将战术模板（如高位逼抢）编码为向量；利用向量距离度量战术-球队匹配度及对手漏洞。

Result: 实现了Python原型系统，可生成可解释、动态自适应的战术推荐，并提供细粒度属性级诊断；验证了方法在足球中的可行性，并初步表明其可扩展至篮球、冰球、协同机器人及人机协作等团队场景。

Conclusion: 语义空间建模为团队战术决策提供了新颖、通用且可计算的理论与实践框架；未来工作聚焦真实数据融合、预测性仿真及人机协同战术智能。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [189] [Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation](https://arxiv.org/abs/2601.00475)
*Sankar B,Srinidhi Ranjini Girish,Aadya Bharti,Dibakar Sen*

Main category: cs.AI

TL;DR: 本文提出MIDAS框架，通过分布式专业化AI代理团队模拟人类元认知发散思维过程，提升工程设计中创意的新颖性与多样性，实现真正的人机协同创新。


<details>
  <summary>Details</summary>
Motivation:  novice设计师在生成真正新颖多样的创意方面面临认知挑战，而现有单次爆发式AI系统因产生语义高度聚集的创意而加剧了该问题。

Method: 提出MIDAS（通过分布式代理AI系统实现元认知创意生成）框架，采用多个专业化AI代理组成的分布式系统，模拟人类元认知创意流程，并对每个创意进行全局新颖性（相对于现有方案）和局部新颖性（相对于已生成创意）评估。

Result: MIDAS成功将人类设计师从被动筛选者转变为主动、参与式、协作式合作伙伴，验证了其作为人机协同创新可行且渐进范式的有效性。

Conclusion: MIDAS为工程设计中的人机协同创意生成提供了新范式，强调分布式代理协作与双重新颖性评估，显著提升了创意质量与人类参与度。

Abstract: The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

</details>


### [190] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 本文研究了推理模型在推理过程中是否具有类似人类的“Aha!”顿悟时刻，发现所谓的中段推理转变（mid-reasoning shifts）极为罕见、不随训练增强、且通常不提升准确性，本质上反映的是推理不稳定性而非内在自校正能力；但若在高不确定性（高熵）时人为触发外部转变，则可稳定提升准确率。


<details>
  <summary>Details</summary>
Motivation: 探究推理模型（如DeepSeek-R1-Zero）是否存在真实有效的内在‘顿悟’式自我修正能力，澄清此前关于中段推理突变提升性能的假设。

Method: 对超100万条推理轨迹、数百个训练检查点、三个推理领域、多种温度与模型架构进行大规模实证分析，并通过仪器化训练过程检测中段推理转变；进一步设计在高熵条件下人工触发外源性转变的干预实验。

Result: 中段推理转变罕见、不随训练增加、极少提升准确率；其影响依赖于模型不确定性；在高熵时人工触发转变可显著提升准确性。

Conclusion: 中段推理转变是推理不稳定的表现，而非内在自校正机制；提升性能的关键在于依据不确定性动态调控推理路径，而非依赖模型自发顿悟。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [191] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: 本文提出了一种难度感知的直接偏好优化方法（DA-DPO），用于缓解多模态大语言模型（MLLMs）中的幻觉问题，通过估计偏好对难度并据此重加权训练样本，避免过拟合，提升鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态DPO方法因偏好数据难度不平衡易过拟合，模型过度关注易区分样本，削弱细粒度幻觉抑制能力。

Method: DA-DPO包含两部分：(1) 难度估计模块，利用预训练视觉-语言模型，结合生成式与对比式目标输出，并通过分布感知投票策略生成无需额外训练的鲁棒难度分数；(2) 难度感知训练模块，依据估计难度对偏好对进行重加权，降低简单样本权重、增强困难样本权重。

Result: 在多个标准基准上，DA-DPO显著提升了多模态偏好优化效果，增强了抗幻觉鲁棒性与泛化能力，且计算高效，无需新增数据或微调阶段。

Conclusion: DA-DPO是一种轻量、高效、无需额外训练的难度感知优化框架，有效缓解了MLLMs中因难度失衡导致的DPO过拟合问题，为多模态对齐提供了新思路。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [192] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: 本文提出PedX-LLM，一种融合视觉特征与交通领域知识的LLM框架，用于提升行人过街行为推断的泛化能力，在跨站点验证中显著优于传统统计与监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法泛化能力差，难以适应新场景；而当前大语言模型缺乏领域适配与视觉上下文支持。

Method: 构建PedX-LLM框架：融合LLaVA提取的视觉特征、文本数据及交通领域知识，基于LLaMA-2-7B模型，采用LoRA进行轻量微调。

Result: 在平衡准确率上达82.0%；视觉增强模块带来2.9%提升，领域知识注入再提升4.1%；零样本跨站点测试达66.9%，五样本少样本学习提升至72.2%。

Conclusion: 视觉与知识增强的推理机制可有效提升模型泛化性，使模型更接近人类决策逻辑，突破纯数据驱动方法的局限。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [193] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: 本文提出AgenticDomiKnowS（ADS），一种能将自由格式任务描述自动翻译为完整DomiKnowS程序的代理式工作流系统，显著降低神经符号编程门槛与开发时间。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号集成框架（如DomiKnowS）虽提供高层接口，但仍要求用户掌握其特定语法，限制了易用性与普及性。

Method: 提出ADS系统，采用代理式工作流，将任务描述分解为独立DomiKnowS组件并逐个生成与测试；支持可选的人机协同干预。

Result: ADS使有经验及无经验的用户均能在10–15分钟内快速构建神经符号程序，相较传统数小时大幅缩短开发时间。

Conclusion: ADS有效消除了对DomiKnowS语法的依赖，提升了神经符号建模的可访问性、效率与实用性。

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [194] [DiffTetVR: Differentiable Tetrahedral Volume Rendering](https://arxiv.org/abs/2601.00114)
*Christoph Neuhauser*

Main category: cs.GR

TL;DR: 本文提出了一种基于四面体网格的可微体积渲染方法DiffTetVR，支持顶点位置优化和局部网格细分，无需多网格方法，并提供了高效前向渲染、反向传播导数推导及防止退化四面体的正则化项。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则网格的可微渲染方法难以灵活优化顶点位置和进行局部细分，且依赖多网格方法；本文旨在通过四面体网格提升几何表示的灵活性与优化自由度。

Method: 提出DiffTetVR：基于四面体网格的可微体积渲染框架；实现高效的前向渲染；推导后向传播所需的梯度；引入正则化项避免退化四面体；支持局部自适应细分以实现由粗到细的优化。

Result: 实现了对四面体网格顶点位置和局部拓扑的端到端可微优化；验证了其在体积渲染任务中的有效性与灵活性；代码已开源。

Conclusion: DiffTetVR为可微渲染提供了更灵活、几何感知更强的四面体表示方案，摆脱了对规则网格和多网格的依赖，拓展了隐式/显式几何联合优化的可能性。

Abstract: Differentiable rendering is a technique that aims to invert the rendering process to enable optimizing rendering parameters from a set of images. In this article, we present a differentiable volume rendering solution called DiffTetVR for tetrahedral meshes. Unlike previous works based on regular grids, this enables the optimization of vertex positions and the local subdivision of the mesh without relying on multigrid methods. We present an efficient implementation of the forward rendering process, deduce the derivatives for the backwards pass and regularization terms for avoiding degenerate tetrahedra, and finally show how the tetrahedral mesh can be subdivided locally to enable a coarse-to-fine optimization process. The source code is made publicly available on GitHub at https://github.com/chrismile/DiffTetVR.

</details>


### [195] [Modeling and Simulating Origami Structures using Bilinear Solid-Shell Element](https://arxiv.org/abs/2601.00569)
*Qixin Liang*

Main category: cs.GR

TL;DR: 本文提出了一种用于建模和模拟折纸结构的新计算框架，采用双线性实体壳单元建模面板，通过相邻面板的法向量夹角描述折痕折叠，并引入假设自然应变法缓解锁死问题，验证了其在直/曲折痕模拟中的准确性与有效性。


<details>
  <summary>Details</summary>
Motivation: 现有折纸结构模拟方法在处理复杂几何（如曲折痕）和数值锁死问题上存在局限，需更鲁棒、通用的计算框架。

Method: 采用双线性实体壳单元建模折纸面板；用未变形中面法向量（director vector）夹角表征折痕折叠；引入假设自然应变（ANS）法缓解剪切/体积锁死。

Result: 成功模拟了含直折痕和曲折痕的折纸结构；定量与定性分析证实该框架具有高精度与计算有效性。

Conclusion: 所提框架能准确、稳健地模拟各类折纸结构（含曲折痕），为折纸工程与可展开结构设计提供了可靠的数值工具。

Abstract: We propose a novel computational framework for modeling and simulating origami structures. In this framework, bilinear solid-shell elements are employed to model the origami panels while crease folding is considered through the angle between the director vectors of the adjacent panels. The director vector is the vector normal to the mid-surface before displacement/deformation comes in. To mitigate locking issues in the solid-shell element, we introduce the assumed natural strain method. To validate the effectiveness of our framework, we conduct origami simulations involving both straight- and curved-creases. The accuracy and efficacy of the framework are demonstrated through quantitative and qualitative analyses.

</details>


### [196] [Spatiotemporal Detection and Uncertainty Visualization of Atmospheric Blocking Events](https://arxiv.org/abs/2601.00775)
*Mingzhe Li,Peer Nowack,Bei Wang*

Main category: cs.GR

TL;DR: 本文提出了一种用于检测和表征大气阻塞事件的不确定性可视化框架，结合几何检测方法与多种不确定性感知摘要（如等高线箱线图、频率热图和3D时间堆叠），并在2003年欧洲热浪案例中验证其有效性，以支持气候风险评估。


<details>
  <summary>Details</summary>
Motivation: 大气阻塞事件对中纬度极端天气影响重大，但在长期气象记录中准确建模与分析仍具挑战性。

Method: 提出基于几何的阻塞检测与追踪方法，并设计不确定性感知的可视化摘要：等高线箱线图、频率热图和3D时间堆叠；在UKESM模拟与ERA5再分析数据上评估。

Result: 框架成功揭示了阻塞事件高发区域及其空间形态随时间的演变规律，并在2003年欧洲热浪案例中实现时空分布映射。

Conclusion: 该不确定性可视化框架可助力气候科学家和气象学家分析历史阻塞事件特征及不同气候情景下的极端天气风险。

Abstract: Atmospheric blocking events are quasi-stationary high-pressure systems that disrupt the typical paths of polar and subtropical air currents, often producing prolonged extreme weather events such as summer heat waves or winter cold spells. Despite their critical role in shaping mid-latitude weather, accurately modeling and analyzing blocking events in long meteorological records remains a significant challenge. To address this challenge, we present an uncertainty visualization framework for detecting and characterizing atmospheric blocking events. First, we introduce a geometry-based detection and tracking method, evaluated on both pre-industrial climate model simulations (UKESM) and reanalysis data (ERA5), which represent historical Earth observations assimilated from satellite and station measurements onto regular numerical grids using weather models. Second, we propose a suite of uncertainty-aware summaries: contour boxplots that capture representative boundaries and their variability, frequency heatmaps that encode occurrences, and 3D temporal stacks that situate these patterns in time. Third, we demonstrate our framework in a case study of the 2003 European heatwave, mapping the spatiotemporal occurrences of blocking events using these summaries. Collectively, these uncertainty visualizations reveal where blocking events are most likely to occur and how their spatial footprints evolve over time. We envision our framework as a valuable tool for climate scientists and meteorologists: by analyzing how blocking frequency, duration, and intensity vary across regions and climate scenarios, it supports both the study of historical blocking events and the assessment of scenario-dependent climate risks associated with changes in extreme weather linked to blocking.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [197] [Reinforcement learning with timed constraints for robotics motion planning](https://arxiv.org/abs/2601.00087)
*Zhaoan Wang,Junchao Li,Mahdi Mohammad,Shaoping Xiao*

Main category: cs.RO

TL;DR: 本文提出了一种基于自动机的强化学习框架，用于在MITL时序逻辑约束下，在MDP和POMDP中合成满足严格时间约束的策略。通过将MITL公式转化为Timed-LDGBA并构建乘积定时模型，结合Q学习与定制奖励结构，在多个仿真场景中验证了其有效性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 动态不确定环境中机器人需满足复杂、严格的时间约束任务序列，而现有方法难以将MITL形式化规范与RL（尤其在部分可观测和随机动力学下）有效结合。

Method: 将MITL公式编译为Timed Limit-Deterministic Generalized Büchi Automata（Timed-LDGBA），与MDP/POMDP同步构建乘积定时模型，并在此上应用Q-learning；设计兼顾时间正确性与性能优化的奖励结构。

Result: 在5×5 MDP、10×10 POMDP及办公服务机器人三个仿真任务中，该框架能稳定学习出满足MITL时间约束的策略，具备良好可扩展性与部分可观测鲁棒性。

Conclusion: 该统一自动机-RL框架为时间关键、不确定性环境下的可靠机器人规划提供了可行且实用的解决方案，弥合了形式化时序验证与数据驱动学习之间的鸿沟。

Abstract: Robotic systems operating in dynamic and uncertain environments increasingly require planners that satisfy complex task sequences while adhering to strict temporal constraints. Metric Interval Temporal Logic (MITL) offers a formal and expressive framework for specifying such time-bounded requirements; however, integrating MITL with reinforcement learning (RL) remains challenging due to stochastic dynamics and partial observability. This paper presents a unified automata-based RL framework for synthesizing policies in both Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs) under MITL specifications. MITL formulas are translated into Timed Limit-Deterministic Generalized Büchi Automata (Timed-LDGBA) and synchronized with the underlying decision process to construct product timed models suitable for Q-learning. A simple yet expressive reward structure enforces temporal correctness while allowing additional performance objectives. The approach is validated in three simulation studies: a $5 \times 5$ grid-world formulated as an MDP, a $10 \times 10$ grid-world formulated as a POMDP, and an office-like service-robot scenario. Results demonstrate that the proposed framework consistently learns policies that satisfy strict time-bounded requirements under stochastic transitions, scales to larger state spaces, and remains effective in partially observable environments, highlighting its potential for reliable robotic planning in time-critical and uncertain settings.

</details>


### [198] [Compositional Diffusion with Guided search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126)
*Utkarsh A Mishra,David He,Yongxin Chen,Danfei Xu*

Main category: cs.RO

TL;DR: 本文提出了一种名为Compositional Diffusion with Guided Search (CDGS)的新方法，用于解决组合式生成模型中的模式平均（mode averaging）问题，通过在扩散去噪过程中嵌入引导式搜索，实现了局部模态的多样化探索与全局一致性约束，在机器人操作、全景图像合成和长视频生成等任务中展现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 组合式生成模型在建模长时程任务分布时面临关键挑战：当局部分布为多模态时，现有组合方法会平均不兼容的模式，导致生成结果既不局部可行也不全局一致。

Method: CDGS将搜索嵌入扩散去噪过程，采用基于种群的采样探索局部多模态组合，用似然性过滤剔除不可行候选，并通过重采样在重叠段间迭代强化全局一致性。

Result: CDGS在七个机器人操作任务上达到oracle性能，优于缺乏组合性或需长时程训练数据的基线方法；同时泛化至全景图像与长视频生成，实现文本引导下的连贯生成。

Conclusion: CDGS有效解决了组合生成中的模式平均问题，通过局部到全局的消息传递机制，提升了多领域长时程生成任务的可行性与一致性。

Abstract: Generative models have emerged as powerful tools for planning, with compositional approaches offering particular promise for modeling long-horizon task distributions by composing together local, modular generative models. This compositional paradigm spans diverse domains, from multi-step manipulation planning to panoramic image synthesis to long video generation. However, compositional generative models face a critical challenge: when local distributions are multimodal, existing composition methods average incompatible modes, producing plans that are neither locally feasible nor globally coherent. We propose Compositional Diffusion with Guided Search (CDGS), which addresses this \emph{mode averaging} problem by embedding search directly within the diffusion denoising process. Our method explores diverse combinations of local modes through population-based sampling, prunes infeasible candidates using likelihood-based filtering, and enforces global consistency through iterative resampling between overlapping segments. CDGS matches oracle performance on seven robot manipulation tasks, outperforming baselines that lack compositionality or require long-horizon training data. The approach generalizes across domains, enabling coherent text-guided panoramic images and long videos through effective local-to-global message passing. More details: https://cdgsearch.github.io/

</details>


### [199] [SLEI3D: Simultaneous Exploration and Inspection via Heterogeneous Fleets under Limited Communication](https://arxiv.org/abs/2601.00163)
*Junfeng Chen,Yuxiao Zhu,Xintong Zhang,Bing Luo,Meng Guo*

Main category: cs.RO

TL;DR: 本文提出了一种名为SLEI3D的新型规划与协同框架，用于异构机器人集群在未知环境中同步执行三维探索、自适应检测及通过间歇性或主动通信协议向移动地面站实时汇报的联合任务。


<details>
  <summary>Details</summary>
Motivation: 传统机器人编队多用于已知静态环境的例行巡检；而许多实际场景中，待检测区域未知，需在探索过程中在线识别，且常面临全局通信不可用、仅能依赖局部无遮挡邻近无线通信的挑战。

Method: 提出SLEI3D框架，融合在线协同3D探索、自适应检测与及时通信策略；设计多层多速率规划机制，支持机器人子群间及子群内主动会合与局部计划协调；利用长距激光雷达快速探索、近距相机精细检测，并适配间歇/主动通信协议。

Result: 在高保真仿真中完成多达48台机器人、38.4万立方米的大规模任务验证；并开展7台机器人硬件实验；项目开源代码与演示见官网。

Conclusion: SLEI3D有效解决了未知环境下异构机器人协同探索、检测与受限通信条件下的实时信息回传问题，具备良好的可扩展性与实用性。

Abstract: Robotic fleets such as unmanned aerial and ground vehicles have been widely used for routine inspections of static environments, where the areas of interest are known and planned in advance. However, in many applications, such areas of interest are unknown and should be identified online during exploration. Thus, this paper considers the problem of simultaneous exploration, inspection of unknown environments and then real-time communication to a mobile ground control station to report the findings. The heterogeneous robots are equipped with different sensors, e.g., long-range lidars for fast exploration and close-range cameras for detailed inspection. Furthermore, global communication is often unavailable in such environments, where the robots can only communicate with each other via ad-hoc wireless networks when they are in close proximity and free of obstruction. This work proposes a novel planning and coordination framework (SLEI3D) that integrates the online strategies for collaborative 3D exploration, adaptive inspection and timely communication (via the intermit-tent or proactive protocols). To account for uncertainties w.r.t. the number and location of features, a multi-layer and multi-rate planning mechanism is developed for inter-and-intra robot subgroups, to actively meet and coordinate their local plans. The proposed framework is validated extensively via high-fidelity simulations of numerous large-scale missions with up to 48 robots and 384 thousand cubic meters. Hardware experiments of 7 robots are also conducted. Project website is available at https://junfengchen-robotics.github.io/SLEI3D/.

</details>


### [200] [SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks](https://arxiv.org/abs/2601.00238)
*Julia Di,Kenneth A. W. Hoffmann,Tony G. Chen,Tian-Ao Ren,Mark R. Cutkosky*

Main category: cs.RO

TL;DR: 本文提出了一种适用于较大无人机的轻柔垂直表面（如树干）停驻方法SLAP，结合视觉定位、IMU故障检测、姿态控制、光学近距感知与快速弹性微刺抓取器，实现了高成功率停驻与100%失败恢复。


<details>
  <summary>Details</summary>
Motivation: 现有垂直表面停驻方案多依赖轻量化机械设计，缺乏系统级集成，且常需高风险高速着陆，不适用于搭载敏感电子设备的巡检无人机。

Method: 提出SLAP系统，包含：基于视觉的停驻点检测器、基于IMU的停驻失败检测器、用于软着陆的姿态控制器、光学近距探测系统，以及由商用slapbands制成的快速主动弹性微刺抓取器；在1.2 kg改装四旋翼上进行组件与系统验证。

Result: 室内人机协同自主飞行实验中，在真实橡木段上20次飞行实现75%停驻成功率，2次人为诱发失败全部成功恢复。

Conclusion: SLAP为大型巡检无人机提供了安全、可靠、可恢复的垂直表面轻柔停驻新范式，兼具工程可行性与系统鲁棒性。

Abstract: Perching allows unmanned aerial vehicles (UAVs) to reduce energy consumption, remain anchored for surface sampling operations, or stably survey their surroundings. Previous efforts for perching on vertical surfaces have predominantly focused on lightweight mechanical design solutions with relatively scant system-level integration. Furthermore, perching strategies for vertical surfaces commonly require high-speed, aggressive landing operations that are dangerous for a surveyor drone with sensitive electronics onboard. This work presents the preliminary investigation of a perching approach suitable for larger drones that both gently perches on vertical tree trunks and reacts and recovers from perch failures. The system in this work, called SLAP, consists of vision-based perch site detector, an IMU (inertial-measurement-unit)-based perch failure detector, an attitude controller for soft perching, an optical close-range detection system, and a fast active elastic gripper with microspines made from commercially-available slapbands. We validated this approach on a modified 1.2 kg commercial quadrotor with component and system analysis. Initial human-in-the-loop autonomous indoor flight experiments achieved a 75% perch success rate on a real oak tree segment across 20 flights, and 100% perch failure recovery across 2 flights with induced failures.

</details>


### [201] [Vehicle Painting Robot Path Planning Using Hierarchical Optimization](https://arxiv.org/abs/2601.00271)
*Yuya Nagai,Hiromitsu Nakamura,Narito Shinmachi,Yuta Higashizono,Satoshi Ono*

Main category: cs.RO

TL;DR: 本文提出了一种分层优化方法，用于自动设计汽车喷涂过程中多机器人臂的喷漆路径，上层类似车辆路径问题（VRP），下层为详细路径规划，实验表明该方法能自动生成满足所有约束、质量媲美人工设计的喷漆路径。


<details>
  <summary>Details</summary>
Motivation: 汽车喷涂过程中，人工设计机器人喷漆路径耗时费力，亟需自动化以缩短设计周期；而传统机器人路径规划方法（如焊接）难以直接适用于喷涂过程的独特约束。

Method: 将喷漆路径设计建模为分层优化问题：上层子问题类比车辆路径问题（VRP），负责区域分配；下层子问题负责各机械臂的详细路径规划；通过定制变量表示、约束处理、修复算子和初始化策略，灵活适配喷涂工艺特有约束。

Result: 在三种商用汽车模型上的实验表明，该方法可全自动设计出满足全部工艺约束的喷漆路径，且路径质量与工程师手工设计相当。

Conclusion: 所提出的分层优化框架有效解决了汽车喷涂中多机器人协同路径规划难题，兼顾自动化、约束适应性与实际应用质量，为智能制造中的专用路径规划提供了新思路。

Abstract: In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.

</details>


### [202] [Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors](https://arxiv.org/abs/2601.00275)
*Dusan Nemec,Gal Versano,Itai Savin,Vojtech Simak,Juraj Kekelak,Itzik Klein*

Main category: cs.RO

TL;DR: 本文提出WiCHINS系统，通过融合轮式与车体惯性传感器，并采用三阶段扩展卡尔曼滤波框架，实现高精度纯惯性导航，显著降低位置误差。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号弱或光照条件差的实际场景中，仅依赖惯性传感器会导致导航随时间漂移，亟需提升纯惯性导航精度。

Method: 提出WiCHINS系统，结合轮载与车体惯性传感器，构建三阶段扩展卡尔曼滤波框架，在估计过程中分别利用轮端和车体传感器的优势。

Result: 在包含5个IMU、总时长228.6分钟的数据集上验证，使用两个轮式和一个车体IMU，平均位置误差为11.4米（占平均行驶距离的2.4%），优于四个惯性基线方法。

Conclusion: WiCHINS能有效提升纯惯性导航精度，增强复杂环境下的鲁棒导航能力，缩小纯惯性导航性能差距。

Abstract: Autonomous vehicles and wheeled robots are widely used in many applications in both indoor and outdoor settings. In practical situations with limited GNSS signals or degraded lighting conditions, the navigation solution may rely only on inertial sensors and as result drift in time due to errors in the inertial measurement. In this work, we propose WiCHINS, a wheeled and chassis inertial navigation system by combining wheel-mounted-inertial sensors with a chassis-mounted inertial sensor for accurate pure inertial navigation. To that end, we derive a three-stage framework, each with a dedicated extended Kalman filter. This framework utilizes the benefits of each location (wheel/body) during the estimation process. To evaluate our proposed approach, we employed a dataset with five inertial measurement units with a total recording time of 228.6 minutes. We compare our approach with four other inertial baselines and demonstrate an average position error of 11.4m, which is $2.4\%$ of the average traveled distance, using two wheels and one body inertial measurement units. As a consequence, our proposed method enables robust navigation in challenging environments and helps bridge the pure-inertial performance gap.

</details>


### [203] [Priority-Aware Multi-Robot Coverage Path Planning](https://arxiv.org/abs/2601.00580)
*Kanghoon Lee,Hyeonjun Kim,Jiachen Li,Jinkyoo Park*

Main category: cs.RO

TL;DR: 本文提出了优先感知的多机器人覆盖路径规划（PA-MCPP）问题，目标是在字典序意义上最小化加权区域覆盖延迟和整体完工时间，并设计了一个两阶段可扩展框架，在实验中显著降低了加权延迟并保持了有竞争力的完工时间。


<details>
  <summary>Details</summary>
Motivation: 现有大多数多机器人覆盖路径规划（MCPP）方法假设环境各区域重要性一致，难以应对某些区域需更快响应的实际需求。

Method: 提出一种可扩展的两阶段框架：（1）结合贪心区域分配、局部搜索与生成树路径规划；（2）基于斯坦纳树引导的剩余区域覆盖。

Result: 实验表明该方法相比标准MCPP基线显著降低优先加权延迟，同时保持有竞争力的完工时间；敏感性分析验证其随机器人数量扩展性良好，且可通过调整优先权重有效控制区域覆盖行为。

Conclusion: PA-MCPP问题建模更贴合实际应用需求，所提两阶段框架在兼顾优先响应与整体效率方面具有有效性与可扩展性。

Abstract: Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.

</details>


### [204] [Replaceable Bit-based Gripper for Picking Cluttered Food Items](https://arxiv.org/abs/2601.00305)
*Prashant Kumar,Yukiyasu Domae,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 本文提出了一种可更换比特式夹持器系统，用于食品包装中对不同重量、形状和物理特性的杂乱食品（如鱼子酱和意大利面）进行精准抓取与定量投放，具备高精度（>80%–95%）、快速换装和多类型适配能力。


<details>
  <summary>Details</summary>
Motivation: 食品包装行业需快速应对食品种类、形态及重量的频繁变化，尤其对粘性、颗粒状、细长缠绕等难处理食品缺乏通用高效夹持方案。

Method: 设计一种基于可更换专用‘比特’（bits）的带式夹持器系统，集成定制化食品附件（分别针对鱼子酱和意大利面）和快速更换机构，并实现重量可控的抓取与释放。

Result: 成功抓取并实现重量特异性投放：鱼子酱准确率>95%，意大利面>80%；支持快速比特切换，适配多种复杂食品。

Conclusion: 该系统为柔性、粘性、颗粒/缠绕类食品提供了高适应性、高精度、易重构的自动化包装解决方案，显著提升产线灵活性与效率。

Abstract: The food packaging industry goes through changes in food items and their weights quite rapidly. These items range from easy-to-pick, single-piece food items to flexible, long and cluttered ones. We propose a replaceable bit-based gripper system to tackle the challenge of weight-based handling of cluttered food items. The gripper features specialized food attachments(bits) that enhance its grasping capabilities, and a belt replacement system allows switching between different food items during packaging operations. It offers a wide range of control options, enabling it to grasp and drop specific weights of granular, cluttered, and entangled foods. We specifically designed bits for two flexible food items that differ in shape: ikura(salmon roe) and spaghetti. They represent the challenging categories of sticky, granular food and long, sticky, cluttered food, respectively. The gripper successfully picked up both spaghetti and ikura and demonstrated weight-specific dropping of these items with an accuracy over 80% and 95% respectively. The gripper system also exhibited quick switching between different bits, leading to the handling of a large range of food items.

</details>


### [205] [Space Debris Removal using Nano-Satellites controlled by Low-Power Autonomous Agents](https://arxiv.org/abs/2601.00465)
*Dennis Christmann,Juan F. Gutierrez,Sthiti Padhi,Patrick Plörer,Aditya Takur,Simona Silvestri,Andres Gomez*

Main category: cs.RO

TL;DR: 本文提出了一种基于资源受限平台的自主智能纳米卫星群方案，用于安全地将空间碎片脱轨进入地球大气层，并在无线微控制器和专用测试平台上验证了其可行性与能效。


<details>
  <summary>Details</summary>
Motivation: 空间碎片日益增多，威胁卫星运行和太空航行安全，亟需低成本、自主化解决方案。

Method: 基于最新自主代理技术，在无线微控制器上实现轻量级自主代理软件，并在专用测试平台上开展实验验证。

Result: 成功实现了适用于纳米卫星群的自主代理系统，实验证明该方法可行且具备良好能量效率。

Conclusion: 该简化方案为未来大规模部署自主纳米卫星群清理空间碎片提供了可行的技术路径和初步实践基础。

Abstract: Space debris is an ever-increasing problem in space travel. There are already many old, no longer functional spacecraft and debris orbiting the earth, which endanger both the safe operation of satellites and space travel. Small nano-satellite swarms can address this problem by autonomously de-orbiting debris safely into the Earth's atmosphere. This work builds on the recent advances of autonomous agents deployed in resource-constrained platforms and shows a first simplified approach how such intelligent and autonomous nano-satellite swarms can be realized. We implement our autonomous agent software on wireless microcontrollers and perform experiments on a specialized test-bed to show the feasibility and overall energy efficiency of our approach.

</details>


### [206] [Variable Elimination in Hybrid Factor Graphs for Discrete-Continuous Inference & Estimation](https://arxiv.org/abs/2601.00545)
*Varun Agrawal,Frank Dellaert*

Main category: cs.RO

TL;DR: 本文提出了一种高效的混合因子图框架及混合变量消元算法，用于精确求解含离散与连续变量的机器人估计问题（如SLAM），通过新型混合高斯因子和混合条件表示实现精确后验推断，并在含模糊测量的SLAM数据集上验证了其准确性与实用性。


<details>
  <summary>Details</summary>
Motivation: 混合问题（含连续与离散变量）在机器人中普遍存在，但建模与精确估计长期困难；现有混合因子图求解方法多依赖近似，缺乏精确解法。

Method: 提出混合高斯因子和混合条件表示以连接离散与连续变量；在条件线性高斯（CLG）假设下推导混合变量消元过程，生成混合贝叶斯网络；结合树状因子结构、剪枝与概率分配策略控制离散假设数量。

Result: 实现了对混合变量的精确最大后验（MAP）估计与边缘化；在含模糊测量的SLAM数据集上验证了该框架的准确性、通用性与简洁性。

Conclusion: 所提混合因子图框架及其变量消元算法能高效、精确地处理机器人中典型的混合估计问题，为复杂感知与决策场景提供了坚实的理论与实用基础。

Abstract: Many hybrid problems in robotics involve both continuous and discrete components, and modeling them together for estimation tasks has been a long standing and difficult problem. Hybrid Factor Graphs give us a mathematical framework to model these types of problems, however existing approaches for solving them are based on approximations. In this work, we propose an efficient Hybrid Factor Graph framework alongwith a variable elimination algorithm to produce a hybrid Bayes network, which can then be used for exact Maximum A Posteriori estimation and marginalization over both sets of variables. Our approach first develops a novel hybrid Gaussian factor which can connect to both discrete and continuous variables, and a hybrid conditional which can represent multiple continuous hypotheses conditioned on the discrete variables. Using these representations, we derive the process of hybrid variable elimination under the Conditional Linear Gaussian scheme, giving us exact posteriors as hybrid Bayes network. To bound the number of discrete hypotheses, we use a tree-structured representation of the factors coupled with a simple pruning and probabilistic assignment scheme, which allows for tractable inference. We demonstrate the applicability of our framework on a SLAM dataset with ambiguous measurements, where discrete choices for the most likely measurement have to be made. Our demonstrated results showcase the accuracy, generality, and simplicity of our hybrid factor graph framework.

</details>


### [207] [LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration](https://arxiv.org/abs/2601.00555)
*Abu Hanif Muhammad Syarubany,Farhan Zaki Rahmani,Trio Widianto*

Main category: cs.RO

TL;DR: 本文提出了一种基于大语言模型（LLM）的端到端智能体探索系统，用于室内购物任务，在仿真与真实走廊环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决室内复杂环境下的语义导航与多目标购物任务执行问题，提升机器人在自然语言指令下端到端任务完成能力及可解释性、可调试性。

Method: 构建轻量级语义地图（通过检测路标牌、存储POI方向关系与结点位姿，以AprilTag为定位锚点）；采用LLM在每个路口生成离散动作（转向+是否进店）；ROS有限状态控制器调用模块化运动原语（局部代价地图避障、AprilTag接近、进店、抓取）执行决策。

Result: 系统在Gazebo仿真和真实走廊场景中均能从自然语言指令出发，完成多店铺导航与物体抓取；具备文本化地图与决策日志，保障模块化与可调试性。

Conclusion: 该LLM驱动的分层代理架构有效融合语义理解、空间推理与具身控制，在保持可解释性的同时实现了鲁棒的端到端室内购物任务执行。

Abstract: This paper presents an end-to-end LLM-based agentic exploration system for an indoor shopping task, evaluated in both Gazebo simulation and a corresponding real-world corridor layout. The robot incrementally builds a lightweight semantic map by detecting signboards at junctions and storing direction-to-POI relations together with estimated junction poses, while AprilTags provide repeatable anchors for approach and alignment. Given a natural-language shopping request, an LLM produces a constrained discrete action at each junction (direction and whether to enter a store), and a ROS finite-state main controller executes the decision by gating modular motion primitives, including local-costmap-based obstacle avoidance, AprilTag approaching, store entry, and grasping. Qualitative results show that the integrated stack can perform end-to-end task execution from user instruction to multi-store navigation and object retrieval, while remaining modular and debuggable through its text-based map and logged decision history.

</details>


### [208] [NMPC-Augmented Visual Navigation and Safe Learning Control for Large-Scale Mobile Robots](https://arxiv.org/abs/2601.00609)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种面向大型移动机器人（LSMR）在松散、易打滑地形上稳定安全导航与控制的综合框架，融合视觉定位、非线性模型预测控制、深度神经网络与自适应控制结合的低层控制器，以及日志型安全监控模块，实现了系统级稳定性与安全性保障。


<details>
  <summary>Details</summary>
Motivation: 大型移动机器人（LSMR）作为高阶多体系统，在松散未固结地形上运行时牵引力下降，易导致打滑与失控，亟需兼顾稳定性、鲁棒性与安全性的导航与控制方案。

Method: 构建四模块联合架构：（1）基于机载传感器与双目相机的视觉位姿估计；（2）高阶非线性模型预测控制（NMPC）实时校正打滑引起的位姿偏差；（3）低层深度神经网络控制器近似复杂轮式驱动动力学，并融合鲁棒自适应控制以应对分布外扰动；（4）日志型安全模块全程监控并保障系统级安全；理论证明低层执行子系统具有一致指数稳定性。

Result: 在6000 kg LSMR平台（配备两套电液静力驱动系统）上完成实验验证，各模块在不同频率下同步运行，验证了框架在真实打滑地形下的鲁棒性、跟踪精度与系统安全性。

Conclusion: 所提框架通过分层协同设计，有效解决了LSMR在低附着地形下的姿态漂移、执行器建模不确定性与系统安全耦合难题，为重型野外机器人提供了可扩展、可验证的控制范式。

Abstract: A large-scale mobile robot (LSMR) is a high-order multibody system that often operates on loose, unconsolidated terrain, which reduces traction. This paper presents a comprehensive navigation and control framework for an LSMR that ensures stability and safety-defined performance, delivering robust operation on slip-prone terrain by jointly leveraging high-performance techniques. The proposed architecture comprises four main modules: (1) a visual pose-estimation module that fuses onboard sensors and stereo cameras to provide an accurate, low-latency robot pose, (2) a high-level nonlinear model predictive control that updates the wheel motion commands to correct robot drift from the robot reference pose on slip-prone terrain, (3) a low-level deep neural network control policy that approximates the complex behavior of the wheel-driven actuation mechanism in LSMRs, augmented with robust adaptive control to handle out-of-distribution disturbances, ensuring that the wheels accurately track the updated commands issued by high-level control module, and (4) a logarithmic safety module to monitor the entire robot stack and guarantees safe operation. The proposed low-level control framework guarantees uniform exponential stability of the actuation subsystem, while the safety module ensures the whole system-level safety during operation. Comparative experiments on a 6,000 kg LSMR actuated by two complex electro-hydrostatic drives, while synchronizing modules operating at different frequencies.

</details>


### [209] [Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework](https://arxiv.org/abs/2601.00610)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种面向大型机器人的安全目标到达控制框架，通过模块化设计（视觉位姿估计、强化学习运动规划、数据驱动动力学建模、鲁棒自适应跟踪控制与数学安全监督）实现复杂地形下的稳定、安全与自主运行。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人应用中因需大量探索而存在安全性问题，尤其对大型、复杂执行器、非稳定地形下的机器人难以适用，亟需一种兼顾安全性与性能的控制框架。

Method: 将系统分解为五个紧密耦合模块：1）实时视觉位姿估计；2）约束机器人规格的RL运动规划器；3）监督式深度学习动力学建模；4）基于该模型的鲁棒自适应轮式跟踪控制器；5）数学安全监督器，实现故障停机与自主返安。

Result: 理论证明执行机构系统具有一致指数稳定性，整机运行满足安全性；在6000 kg大型机器人多场景实验中验证了框架有效性。

Conclusion: 模块化分层架构成功融合学习与控制优势，在保证严格安全前提下实现了复杂环境下大型机器人的自主目标到达，为重型机器人实用化提供了可行路径。

Abstract: Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.

</details>


### [210] [From 2D to 3D terrain-following area coverage path planning](https://arxiv.org/abs/2601.00614)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 本文提出了一种用于三维地形跟随的区域覆盖路径规划算法，适用于农业机械作业，确保路径间距离等于机械工作宽度、且路径始终位于地形上方指定工作高度处。


<details>
  <summary>Details</summary>
Motivation: 为农业机械在复杂三维地形中实现高效、均匀的覆盖作业，需解决传统2D路径规划无法适应地形起伏的问题。

Method: 提出一种3D地形跟随路径规划算法，结合反距离加权法（IDW）生成均匀高程数据和局部搜索策略，保证路径间距等于机械工作宽度、投影高度等于设定工作高度。

Result: 在真实农业三维地形数据上验证了该算法的有效性，成功生成满足作业约束的多条覆盖路径。

Conclusion: 该算法扩展了2D覆盖路径规划至3D地形场景，兼顾几何精度与实用性，为智能农机自主作业提供了可行路径规划方案。

Abstract: An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.

</details>


### [211] [RoboReward: General-Purpose Vision-Language Reward Models for Robotics](https://arxiv.org/abs/2601.00675)
*Tony Lee,Andrew Wagenmaker,Karl Pertsch,Percy Liang,Sergey Levine,Chelsea Finn*

Main category: cs.RO

TL;DR: 本文提出了RoboReward，一个基于真实机器人数据集构建的奖励模型基准，并通过负样本增强技术提升了视觉语言模型在机器人任务中的奖励预测能力，实验表明其训练的4B/8B参数模型显著优于现有大模型，并在真实机器人强化学习中接近人类奖励效果。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习中奖励设计依赖人工标注或手工设定，成本高且泛化差；尽管视觉语言模型（VLMs）有望自动提供奖励，但其在真实机器人任务上的有效性尚不明确。

Method: 构建RoboReward数据集与基准，涵盖Open X-Embodiment和RoboArena的大规模真实机器人数据；提出‘负样本数据增强’流程，包括反事实重标注成功轨迹生成负例与近似失败样本，以及时间裁剪生成部分进展样本；在此基础上训练4B/8B参数的视觉语言奖励模型。

Result: 评估显示当前主流开源与闭源VLM均无法在所有机器人任务上表现优异；所提RoboReward 4B/8B模型在短时程任务中超越更大参数量的VLM；在真实机器人RL部署中，8B模型显著优于Gemini Robotics-ER 1.5，并大幅缩小与人类奖励训练的性能差距。

Conclusion: RoboReward为VLM驱动的机器人奖励建模提供了可靠基准与有效模型，验证了专用小参数VLM在真实机器人奖励任务中的优越性与实用性，指明了未来提升方向。

Abstract: A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \emph{negative examples data augmentation} pipeline that generates calibrated \emph{negatives} and \emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.

</details>


### [212] [DefVINS: Visual-Inertial Odometry for Deformable Scenes](https://arxiv.org/abs/2601.00702)
*Samuel Cerezo,Javier Civera*

Main category: cs.RO

TL;DR: 本文提出DefVINS，一种用于非刚性场景的视觉-惯性里程计框架，通过将刚性状态（由IMU锚定）与非刚性形变（用嵌入式形变图表示）显式分离，提升在形变场景下的鲁棒性与可观测性。


<details>
  <summary>Details</summary>
Motivation: 传统视觉-惯性里程计（VIO）基于刚性假设，在可变形场景中易过拟合局部非刚性运动或产生严重漂移。

Method: 提出DefVINS框架：1）初始化采用标准VIO流程以固定重力、速度和IMU偏差；2）随后渐进激活非刚性自由度；3）引入可观测性分析，阐明IMU如何约束刚性运动并使原本不可观的模态在形变存在下变得可观；4）基于该分析设计IMU锚定与条件驱动的形变激活策略。

Result: 消融实验证明，结合IMU约束与可观测性感知的形变激活策略显著提升了系统在非刚性环境中的鲁棒性与精度。

Conclusion: DefVINS通过刚性-非刚性解耦建模与可观测性引导的激活机制，有效缓解了形变场景下VIO的漂移与病态更新问题，为动态环境定位提供了新思路。

Abstract: Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.

</details>


### [213] [Calling for Backup: How Children Navigate Successive Robot Communication Failures](https://arxiv.org/abs/2601.00754)
*Maria Teresa Parreira,Isabel Neto,Filipa Rocha,Wendy Ju*

Main category: cs.RO

TL;DR: 本研究探讨了8-10岁儿童在面对机器人连续三次对话错误时的行为反应，发现儿童虽与成人一样会调整语言和语调、表现出更强的情绪化非言语反应，但更易出现脱离互动行为（如忽略机器人或寻求成人帮助）；且错误未影响其对机器人的整体评价，表明儿童对人机对话具有更灵活的预期。


<details>
  <summary>Details</summary>
Motivation: 先前研究多关注成人对机器人连续错误的反应，而儿童作为日益重要的机器人用户群体，其反应机制尚缺乏系统探索。

Method: 采用Liu等人提出的连续机器人失败范式，招募59名8–10岁儿童参与人机对话实验；机器人连续三次未能理解儿童指令；全程录像并编码分析儿童的语言调整、语调变化、非言语情绪表达及脱离行为。

Result: 儿童在连续错误中会调整提示语、改变语调、增强情绪化非言语反应，但比成人更频繁出现暂时忽略机器人或主动寻求成人帮助等脱离行为；机器人错误未显著影响儿童对其可信度或好感度的评价。

Conclusion: 儿童对机器人错误的适应策略与成人既有共性又有发展特异性，其更高的脱离倾向和更稳定的机器人评价提示设计需兼顾认知发展阶段与情感支持需求，以提升面向儿童的人机交互系统的有效性与适龄性。

Abstract: How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [214] [A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies](https://arxiv.org/abs/2601.00510)
*Jetlir Duraj,Ishita Khan,Kilian Merkelbach,Mehran Elyasi*

Main category: cs.IR

TL;DR: 本文提出了一种结合树搜索与大语言模型（LLM）语义打分的链式思维（CoT）方法，用于电商搜索查询的层级分类任务，显著优于基于嵌入的基线方法，并能发现分类体系中的问题，同时提出了可扩展至百万级查询的LLM优化方案。


<details>
  <summary>Details</summary>
Motivation: 电商搜索依赖于商品类目层级结构，准确将用户查询映射到合适叶子类目对提升搜索相关性、约束检索范围及理解用户意图至关重要，但现有方法在真实复杂层级 taxonomy 中效果有限。

Method: 提出链式思维（CoT）范式：先进行轻量级树搜索定位候选路径，再用LLM对路径节点进行细粒度语义打分；并进一步设计了可扩展的LLM直接分类方法以支持海量查询处理。

Result: 在人工标注数据、相关性测试和LLM基线对比中，CoT方法均优于嵌入式查询-类目预测基准；能有效识别层级taxonomy中的结构性问题；所提LLM方案具备百万级查询处理能力。

Conclusion: CoT范式为电商查询分类提供了更准确、可解释且可诊断的解决方案，兼顾性能与可扩展性，推动了层级意图理解与搜索系统优化。

Abstract: Search in e-Commerce is powered at the core by a structured representation of the inventory, often formulated as a category taxonomy. An important capability in e-Commerce with hierarchical taxonomies is to select a set of relevant leaf categories that are semantically aligned with a given user query. In this scope, we address a fundamental problem of search query categorization in real-world e-Commerce taxonomies. A correct categorization of a query not only provides a way to zoom into the correct inventory space, but opens the door to multiple intent understanding capabilities for a query. A practical and accurate solution to this problem has many applications in e-commerce, including constraining retrieved items and improving the relevance of the search results. For this task, we explore a novel Chain-of-Thought (CoT) paradigm that combines simple tree-search with LLM semantic scoring. Assessing its classification performance on human-judged query-category pairs, relevance tests, and LLM-based reference methods, we find that the CoT approach performs better than a benchmark that uses embedding-based query category predictions. We show how the CoT approach can detect problems within a hierarchical taxonomy. Finally, we also propose LLM-based approaches for query-categorization of the same spirit, but which scale better at the range of millions of queries.

</details>


### [215] [Improving Scientific Document Retrieval with Academic Concept Index](https://arxiv.org/abs/2601.00567)
*Jeyun Lee,Junhyoung Lee,Wonbin Kweon,Bowen Jin,Yu Zhang,Susik Yoon,Dongha Lee,Hwanjo Yu,Jiawei Han,Seongku Kang*

Main category: cs.IR

TL;DR: 本文提出了一种基于学术概念索引的方法，通过概念覆盖式查询生成（CCQGen）和概念聚焦的上下文扩展（CCExpand），提升科学领域检索器在缺乏标注数据下的性能。


<details>
  <summary>Details</summary>
Motivation: 科学领域检索面临领域标注数据稀缺、词汇与信息需求不匹配的问题，现有基于大语言模型的合成查询生成和辅助上下文生成方法忽略了文献中丰富的学术概念，导致生成内容冗余或概念覆盖窄。

Method: 构建学术概念索引（基于学术分类法提取并组织论文关键概念）；在此基础上：（1）提出CCQGen，使LLM根据未覆盖概念自适应生成互补查询；（2）提出CCExpand，利用CCQGen查询对应的文档片段作为简洁、概念聚焦的辅助上下文。

Result: 在多个科学检索基准上实验表明，该方法显著提升了查询质量、概念对齐度和最终检索性能。

Conclusion: 学术概念索引为科学检索中的查询生成与上下文增强提供了结构化语义基础，联合优化二者可有效缓解领域适配中的概念贫乏问题。

Abstract: Adapting general-domain retrievers to scientific domains is challenging due to the scarcity of large-scale domain-specific relevance annotations and the substantial mismatch in vocabulary and information needs. Recent approaches address these issues through two independent directions that leverage large language models (LLMs): (1) generating synthetic queries for fine-tuning, and (2) generating auxiliary contexts to support relevance matching. However, both directions overlook the diverse academic concepts embedded within scientific documents, often producing redundant or conceptually narrow queries and contexts. To address this limitation, we introduce an academic concept index, which extracts key concepts from papers and organizes them guided by an academic taxonomy. This structured index serves as a foundation for improving both directions. First, we enhance the synthetic query generation with concept coverage-based generation (CCQGen), which adaptively conditions LLMs on uncovered concepts to generate complementary queries with broader concept coverage. Second, we strengthen the context augmentation with concept-focused auxiliary contexts (CCExpand), which leverages a set of document snippets that serve as concise responses to the concept-aware CCQGen queries. Extensive experiments show that incorporating the academic concept index into both query generation and context augmentation leads to higher-quality queries, better conceptual alignment, and improved retrieval performance.

</details>
