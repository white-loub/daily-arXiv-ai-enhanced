<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 53]
- [cs.CL](#cs.CL) [Total: 53]
- [cs.RO](#cs.RO) [Total: 15]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.IR](#cs.IR) [Total: 7]
- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GR3EN: Generative Relighting for 3D Environments](https://arxiv.org/abs/2601.16272)
*Xiaoyan Xing,Philipp Henzler,Junhwa Hur,Runze Li,Jonathan T. Barron,Pratul P. Srinivasan,Dor Verbin*

Main category: cs.CV

TL;DR: 本文提出了一种用于大型房间级3D场景重光照的方法，通过蒸馏视频到视频重光照扩散模型的输出到3D重建中，避免了求解病态逆渲染问题，实现了高质量、可控的3D重光照。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景重光照方法常需求解欠定或病态的逆渲染问题，难以在复杂真实场景中生成高质量结果；而基于扩散模型的方法多限于2D图像/视频或单个物体的3D重光照。

Method: 将视频到视频重光照扩散模型的输出蒸馏至3D重建中，实现房间级场景的可控3D重光照，绕过直接求解逆渲染问题。

Result: 在合成与真实数据集上验证了该方法能忠实渲染新视角下新光照条件的场景，支持复杂真实世界场景的高质量3D重光照。

Conclusion: 该方法提供了一种灵活、高效且高质量的房间级3D场景重光照方案，拓展了扩散模型在3D视觉中的应用边界。

Abstract: We present a method for relighting 3D reconstructions of large room-scale environments. Existing solutions for 3D scene relighting often require solving under-determined or ill-conditioned inverse rendering problems, and are as such unable to produce high-quality results on complex real-world scenes. Though recent progress in using generative image and video diffusion models for relighting has been promising, these techniques are either limited to 2D image and video relighting or 3D relighting of individual objects. Our approach enables controllable 3D relighting of room-scale scenes by distilling the outputs of a video-to-video relighting diffusion model into a 3D reconstruction. This side-steps the need to solve a difficult inverse rendering problem, and results in a flexible system that can relight 3D reconstructions of complex real-world scenes. We validate our approach on both synthetic and real-world datasets to show that it can faithfully render novel views of scenes under new lighting conditions.

</details>


### [2] [Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory](https://arxiv.org/abs/2601.16296)
*Dohun Lee,Chun-Hao Paul Huang,Xuelin Chen,Jong Chul Ye,Duygu Ceylan,Hyeonho Jeong*

Main category: cs.CV

TL;DR: 本文提出Memory-V2V框架，首次解决多轮视频编辑中的跨轮次一致性问题，通过外置缓存、精准检索、动态分词及可学习token压缩机制，在保持或提升性能的同时显著提升一致性并降低30%计算开销。


<details>
  <summary>Details</summary>
Motivation: 现实视频编辑是多轮迭代过程，而现有视频编辑模型难以在多轮编辑中维持跨轮次的一致性。

Method: 提出Memory-V2V框架：引入外部编辑视频缓存，结合精准检索与动态token化策略对当前编辑进行历史条件建模；并在DiT主干中嵌入可学习token压缩器以减少冗余计算。

Result: 在视频新视角合成和长视频文本编辑等任务上验证有效，显著提升跨轮次一致性，计算开销极小，且任务性能持平或优于SOTA基线。

Conclusion: Memory-V2V为多轮视频编辑提供了首个系统性解决跨一致性问题的轻量高效方案，兼具实用性与扩展性。

Abstract: Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V

</details>


### [3] [FeTTL: Federated Template and Task Learning for Multi-Institutional Medical Imaging](https://arxiv.org/abs/2601.16302)
*Abhijeet Parida,Antonia Alomar,Zhifan Jiang,Pooneh Roshanitabrizi,Austin Tapp,Ziyue Xu,Syed Muhammad Anwar,Maria J. Ledesma-Carbayo,Holger R. Roth,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本文提出了一种名为FeTTL的新框架，通过联合学习全局模板和任务模型来缓解联邦学习中多中心医学影像数据的分布偏移问题，并在两个医学影像任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在医学影像中面临域偏移和数据异质性问题，尤其受采集协议、设备类型和患者群体差异影响，导致模型性能下降。

Method: 提出联邦模板与任务学习（FeTTL）框架，在联邦环境下协同学习一个全局模板和一个任务模型，以对齐各客户端的数据分布。

Result: 在视盘分割和病理转移分类两个多中心医学影像任务上，FeTTL显著优于当前最优联邦学习基线（p值<0.002），且验证了联合学习模板与任务的重要性。

Conclusion: FeTTL为联邦学习中的分布偏移问题提供了原理清晰、可扩展的解决方案，有助于在真实多中心场景中实现鲁棒模型部署。

Abstract: Federated learning enables collaborative model training across geographically distributed medical centers while preserving data privacy. However, domain shifts and heterogeneity in data often lead to a degradation in model performance. Medical imaging applications are particularly affected by variations in acquisition protocols, scanner types, and patient populations. To address these issues, we introduce Federated Template and Task Learning (FeTTL), a novel framework designed to harmonize multi-institutional medical imaging data in federated environments. FeTTL learns a global template together with a task model to align data distributions among clients. We evaluated FeTTL on two challenging and diverse multi-institutional medical imaging tasks: retinal fundus optical disc segmentation and histopathological metastasis classification. Experimental results show that FeTTL significantly outperforms the state-of-the-art federated learning baselines (p-values <0.002) for optical disc segmentation and classification of metastases from multi-institutional data. Our experiments further highlight the importance of jointly learning the template and the task. These findings suggest that FeTTL offers a principled and extensible solution for mitigating distribution shifts in federated learning, supporting robust model deployment in real-world, multi-institutional environments.

</details>


### [4] [Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments](https://arxiv.org/abs/2601.16333)
*Aditya K Surikuchi,Raquel Fernández,Sandro Pezzelle*

Main category: cs.CV

TL;DR: 本文研究了基础模型在识别视频中重要子事件方面的能力，特别是在足球比赛场景下，通过构建一个基于人类偏好隐式标注的新数据集，发现现有最先进多模态模型表现接近随机水平，并揭示其过度依赖单一模态、跨模态融合能力不足的问题，进而强调模块化架构与互补训练策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 识别视频中最重要的子事件是多模态事件叙述与摘要生成的基础前提，但现有基础模型在此任务上的能力尚不明确，尤其缺乏低成本、高质量的评估基准。

Method: 利用足球比赛精彩集锦中隐含的人类对事件重要性的偏好，构建了一个无需额外人工标注的新数据集；在此基础上，系统评估多个前沿多模态模型，并通过超越标准指标的深入分析探究其模态利用偏差与跨模态融合缺陷。

Result: 当前最先进多模态模型在该任务上性能仅略高于随机水平；分析表明模型倾向于严重依赖单一主导模态（如视觉或文本），难以有效整合多源信息。

Conclusion: 需设计能应对样本级多模态异质性的模块化架构，并开发可最大化跨模态协同效应的互补训练方法。

Abstract: Foundation models are used for many real-world applications involving language generation from temporally-ordered multimodal events. In this work, we study the ability of models to identify the most important sub-events in a video, which is a fundamental prerequisite for narrating or summarizing multimodal events. Specifically, we focus on football games and evaluate models on their ability to distinguish between important and non-important sub-events in a game. To this end, we construct a new dataset by leveraging human preferences for importance implicit in football game highlight reels, without any additional annotation costs. Using our dataset, which we will publicly release to the community, we compare several state-of-the-art multimodal models and show that they are not far from chance level performance. Analyses of models beyond standard evaluation metrics reveal their tendency to rely on a single dominant modality and their ineffectiveness in synthesizing necessary information from multiple sources. Our findings underline the importance of modular architectures that can handle sample-level heterogeneity in multimodal data and the need for complementary training procedures that can maximize cross-modal synergy.

</details>


### [5] [Coarse-to-Fine Non-rigid Multi-modal Image Registration for Historical Panel Paintings based on Crack Structures](https://arxiv.org/abs/2601.16348)
*Aline Sindel,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 本文提出了一种基于细裂纹（craquelure）特征的粗到精、非刚性多模态图像配准方法，用于历史木板绘画分析，结合CNN关键点检测与描述、图神经网络匹配及多级关键点优化，在自建多模态数据集上取得最优配准效果。


<details>
  <summary>Details</summary>
Motivation: 历史木板绘画的多模态图像（如可见光、红外、X光等）需像素级对齐以支持综合分析，但现有手动配准耗时费力、精度受限；而自动配准面临分辨率差异大、图像尺寸巨大、非刚性形变及模态间内容差异等挑战。

Method: 提出一种端到端粗到精非刚性多模态配准方法：1）利用绘画表面普遍存在的craquelure作为稳定跨模态特征；2）采用CNN联合检测与描述craquelure关键点；3）用图神经网络在局部块内进行描述符匹配，并基于局部单应性重投影误差筛选匹配点；4）引入新型多级关键点细化策略，适配混合分辨率图像并逐级提升至最高分辨率；5）使用薄板样条（TPS）实现非刚性变换。

Result: 在自建的高标注量多模态木板画数据集（含5种模态、多分辨率图像）上验证，消融实验证明各模块有效；相比现有关键点法与稠密匹配法及其优化策略，所提方法在配准精度和鲁棒性上均达到最优性能。

Conclusion: 基于craquelure的关键点提取与多级细化配准框架，显著提升了历史绘画多模态图像自动化、高精度、高效率配准能力，为艺术科技分析提供了可靠技术支撑。

Abstract: Art technological investigations of historical panel paintings rely on acquiring multi-modal image data, including visual light photography, infrared reflectography, ultraviolet fluorescence photography, x-radiography, and macro photography. For a comprehensive analysis, the multi-modal images require pixel-wise alignment, which is still often performed manually. Multi-modal image registration can reduce this laborious manual work, is substantially faster, and enables higher precision. Due to varying image resolutions, huge image sizes, non-rigid distortions, and modality-dependent image content, registration is challenging. Therefore, we propose a coarse-to-fine non-rigid multi-modal registration method efficiently relying on sparse keypoints and thin-plate-splines. Historical paintings exhibit a fine crack pattern, called craquelure, on the paint layer, which is captured by all image systems and is well-suited as a feature for registration. In our one-stage non-rigid registration approach, we employ a convolutional neural network for joint keypoint detection and description based on the craquelure and a graph neural network for descriptor matching in a patch-based manner, and filter matches based on homography reprojection errors in local areas. For coarse-to-fine registration, we introduce a novel multi-level keypoint refinement approach to register mixed-resolution images up to the highest resolution. We created a multi-modal dataset of panel paintings with a high number of keypoint annotations, and a large test set comprising five multi-modal domains and varying image resolutions. The ablation study demonstrates the effectiveness of all modules of our refinement method. Our proposed approaches achieve the best registration results compared to competing keypoint and dense matching methods and refinement methods.

</details>


### [6] [Cognitively-Inspired Tokens Overcome Egocentric Bias in Multimodal Models](https://arxiv.org/abs/2601.16378)
*Bridget Leonard,Scott O. Murray*

Main category: cs.CV

TL;DR: 本文提出了一种名为'视角标记（perspective tokens）'的新方法，通过引入基于身体关键点或抽象旋转表示的专用嵌入，来增强多模态语言模型（MLMs）的空间推理与视觉视角转换能力，显著提升了其在多种基准上的表现，并揭示了现有模型已具备一定的他心空间表征雏形。


<details>
  <summary>Details</summary>
Motivation: 现有MLMs在语义视觉-语言任务上表现良好，但在需要采用他人视觉视角的空间推理任务中表现不佳，存在固有的自我中心偏差，缺乏他心（allocentric）推理能力。

Method: 受人类空间认知启发，设计两种视角标记：（1）基于具身身体关键点的线索；（2）支持心理旋转的抽象表示。将这些标记集成到LLaVA-1.5-13B模型中，并在Isle Bricks V2、COCO和3DSRBench等合成与真实场景基准上进行评估。

Result: 视角标记显著提升了模型在二级视觉视角转换任务上的准确率；旋转式标记可泛化至非人类参考主体；表征分析表明微调增强了基模型中已存在的潜在朝向敏感性。

Conclusion: 将符合认知科学原理的空间结构直接嵌入token空间，是一种轻量、模型无关的提升视角转换与类人空间推理能力的有效机制；当前MLMs已蕴含他心推理的先验基础，但需恰当的内部结构引导。

Abstract: Multimodal language models (MLMs) perform well on semantic vision-language tasks but fail at spatial reasoning that requires adopting another agent's visual perspective. These errors reflect a persistent egocentric bias and raise questions about whether current models support allocentric reasoning. Inspired by human spatial cognition, we introduce perspective tokens, specialized embeddings that encode orientation through either (1) embodied body-keypoint cues or (2) abstract representations supporting mental rotation. Integrating these tokens into LLaVA-1.5-13B yields performance on level-2 visual perspective-taking tasks. Across synthetic and naturalistic benchmarks (Isle Bricks V2, COCO, 3DSRBench), perspective tokens improve accuracy, with rotation-based tokens generalizing to non-human reference agents. Representational analyses reveal that fine-tuning enhances latent orientation sensitivity already present in the base model, suggesting that MLMs contain precursors of allocentric reasoning but lack appropriate internal structure. Overall, embedding cognitively grounded spatial structure directly into token space provides a lightweight, model-agnostic mechanism for perspective-taking and more human-like spatial reasoning.

</details>


### [7] [VTFusion: A Vision-Text Multimodal Fusion Network for Few-Shot Anomaly Detection](https://arxiv.org/abs/2601.16381)
*Yuxin Jiang,Yunkang Cao,Yuqi Cheng,Yiheng Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 本文提出VTFusion框架，专为少样本异常检测（FSAD）设计，通过自适应特征提取器和多模态预测融合模块，解决工业检测中视觉与文本模态语义不匹配问题，在多个数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有FSAD方法依赖自然场景预训练特征，忽视工业检测所需的细粒度领域语义，且常用融合策略（如简单拼接）无法解决视觉与文本模态间的语义错位问题，导致跨模态干扰鲁棒性差。

Method: 提出VTFusion框架：1）为图像和文本模态设计自适应特征提取器，学习任务特定表征，并结合合成异常增强判别性；2）构建专用多模态预测融合模块，含促进跨模态信息交互的融合块和在多模态指导下生成像素级异常图的分割网络。

Result: 在MVTec AD和VisA数据集2-shot设置下，图像级AUROC分别达96.8%和86.2%；在本文引入的真实汽车塑料件工业数据集上AUPRO达93.5%。

Conclusion: VTFusion有效弥合了预训练模型与工业数据间的领域差距，并提升了多模态融合质量，显著推动FSAD在实际工业检测中的应用能力。

Abstract: Few-Shot Anomaly Detection (FSAD) has emerged as a critical paradigm for identifying irregularities using scarce normal references. While recent methods have integrated textual semantics to complement visual data, they predominantly rely on features pre-trained on natural scenes, thereby neglecting the granular, domain-specific semantics essential for industrial inspection. Furthermore, prevalent fusion strategies often resort to superficial concatenation, failing to address the inherent semantic misalignment between visual and textual modalities, which compromises robustness against cross-modal interference. To bridge these gaps, this study proposes VTFusion, a vision-text multimodal fusion framework tailored for FSAD. The framework rests on two core designs. First, adaptive feature extractors for both image and text modalities are introduced to learn task-specific representations, bridging the domain gap between pre-trained models and industrial data; this is further augmented by generating diverse synthetic anomalies to enhance feature discriminability. Second, a dedicated multimodal prediction fusion module is developed, comprising a fusion block that facilitates rich cross-modal information exchange and a segmentation network that generates refined pixel-level anomaly maps under multimodal guidance. VTFusion significantly advances FSAD performance, achieving image-level AUROCs of 96.8% and 86.2% in the 2-shot scenario on the MVTec AD and VisA datasets, respectively. Furthermore, VTFusion achieves an AUPRO of 93.5% on a real-world dataset of industrial automotive plastic parts introduced in this paper, further demonstrating its practical applicability in demanding industrial scenarios.

</details>


### [8] [ResAgent: Entropy-based Prior Point Discovery and Visual Reasoning for Referring Expression Segmentation](https://arxiv.org/abs/2601.16394)
*Yihao Wang,Jusheng Zhang,Ziyi Tang,Keze Wang,Meng Yang*

Main category: cs.CV

TL;DR: 本文提出了一种新的Referring Expression Segmentation（RES）框架，通过熵驱动的点发现（EBD）和基于视觉的推理（VBR）解决现有MLLM方法中粗略边界框导致提示冗余及文本坐标推理不可靠的问题，实现了跨四大基准的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型（MLLM）的RES方法存在两个关键缺陷：一是MLLM提供的粗略边界框导致点提示冗余或缺乏判别性；二是依赖文本坐标推理难以区分视觉相似的干扰项。

Method: 提出名为\model的RES框架，包含熵基点发现（EBD）和视觉基推理（VBR）两部分：EBD在粗略边界框内建模空间不确定性以选择高信息量候选点；VBR通过联合视觉-语义对齐验证点正确性，摒弃纯文本坐标推理；整体采用粗到细流程：边界框初始化→熵引导点发现→视觉验证→掩码解码。

Result: 在RefCOCO、RefCOCO+、RefCOCOg和ReasonSeg四个基准上均达到新SOTA性能，生成准确且语义扎实的分割掩码，仅需极少提示。

Conclusion: EBD与VBR的有效结合显著提升了RES任务中目标定位与分割的鲁棒性和精度，验证了减少对文本坐标依赖、增强视觉语义联合推理的可行性与优越性。

Abstract: Referring Expression Segmentation (RES) is a core vision-language segmentation task that enables pixel-level understanding of targets via free-form linguistic expressions, supporting critical applications such as human-robot interaction and augmented reality. Despite the progress of Multimodal Large Language Model (MLLM)-based approaches, existing RES methods still suffer from two key limitations: first, the coarse bounding boxes from MLLMs lead to redundant or non-discriminative point prompts; second, the prevalent reliance on textual coordinate reasoning is unreliable, as it fails to distinguish targets from visually similar distractors. To address these issues, we propose \textbf{\model}, a novel RES framework integrating \textbf{E}ntropy-\textbf{B}ased Point \textbf{D}iscovery (\textbf{EBD}) and \textbf{V}ision-\textbf{B}ased \textbf{R}easoning (\textbf{VBR}). Specifically, EBD identifies high-information candidate points by modeling spatial uncertainty within coarse bounding boxes, treating point selection as an information maximization process. VBR verifies point correctness through joint visual-semantic alignment, abandoning text-only coordinate inference for more robust validation. Built on these components, \model implements a coarse-to-fine workflow: bounding box initialization, entropy-guided point discovery, vision-based validation, and mask decoding. Extensive evaluations on four benchmark datasets (RefCOCO, RefCOCO+, RefCOCOg, and ReasonSeg) demonstrate that \model achieves new state-of-the-art performance across all four benchmarks, highlighting its effectiveness in generating accurate and semantically grounded segmentation masks with minimal prompts.

</details>


### [9] [A Cosine Network for Image Super-Resolution](https://arxiv.org/abs/2601.16413)
*Chunwei Tian,Chengyuan Zhang,Bob Zhang,Zhiwu Li,C. L. Philip Chen,David Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种用于图像超分辨率的余弦网络（CSRNet），通过设计奇偶异构块提取互补结构信息，并引入余弦退火机制优化训练过程，提升了模型性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在图像超分辨率中，如何有效保留并利用层次化提取的结构信息是一个关键挑战，尤其是避免同源信息冗余、增强结构信息鲁棒性。

Method: 提出CSRNet：1）设计奇偶异构块以扩大架构差异，提取互补的线性与非线性结构信息；2）引入余弦退火机制进行学习率调度和warm restart，缓解梯度下降陷入局部最优问题。

Result: 实验结果表明CSRNet在图像超分辨率任务上具有竞争力，性能达到或接近当前最先进方法水平。

Conclusion: CSRNet通过结构设计与训练策略协同优化，有效提升了结构信息的多样性与鲁棒性，验证了异构建模与自适应学习率调度对超分辨率任务的有效性。

Abstract: Deep convolutional neural networks can use hierarchical information to progressively extract structural information to recover high-quality images. However, preserving the effectiveness of the obtained structural information is important in image super-resolution. In this paper, we propose a cosine network for image super-resolution (CSRNet) by improving a network architecture and optimizing the training strategy. To extract complementary homologous structural information, odd and even heterogeneous blocks are designed to enlarge the architectural differences and improve the performance of image super-resolution. Combining linear and non-linear structural information can overcome the drawback of homologous information and enhance the robustness of the obtained structural information in image super-resolution. Taking into account the local minimum of gradient descent, a cosine annealing mechanism is used to optimize the training procedure by performing warm restarts and adjusting the learning rate. Experimental results illustrate that the proposed CSRNet is competitive with state-of-the-art methods in image super-resolution.

</details>


### [10] [DCCS-Det: Directional Context and Cross-Scale-Aware Detector for Infrared Small Target](https://arxiv.org/abs/2601.16428)
*Shuying Li,Qiang Ma,San Zhang,Chuang Yang*

Main category: cs.CV

TL;DR: 本文提出DCCS-Det，一种面向红外小目标检测的新方法，通过DSE模块增强方向性上下文感知与局部细节捕获，结合LaSEA模块实现跨尺度特征提取与语义聚合，有效提升目标-背景判别力和抗噪能力，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有红外小目标检测方法在局部-全局特征联合建模不足，导致目标-背景区分能力弱；同时存在特征冗余与语义稀释问题，损害目标表征质量。

Method: 提出DCCS-Det检测器，包含Dual-stream Saliency Enhancement（DSE）块（融合局部感知与方向感知上下文聚合）和Latent-aware Semantic Extraction and Aggregation（LaSEA）模块（采用跨尺度特征提取与随机池化采样策略缓解特征退化）。

Result: 在多个数据集上实现SOTA检测精度，同时保持竞争性计算效率；消融实验验证了DSE和LaSEA对复杂场景下目标感知与特征表征的显著提升作用。

Conclusion: DCCS-Det通过协同优化上下文建模与跨尺度语义聚合，有效解决了红外小目标检测中局部-全局特征失衡与语义稀释问题，为该任务提供了高效鲁棒的新范式。

Abstract: Infrared small target detection (IRSTD) is critical for applications like remote sensing and surveillance, which aims to identify small, low-contrast targets against complex backgrounds. However, existing methods often struggle with inadequate joint modeling of local-global features (harming target-background discrimination) or feature redundancy and semantic dilution (degrading target representation quality). To tackle these issues, we propose DCCS-Det (Directional Context and Cross-Scale Aware Detector for Infrared Small Target), a novel detector that incorporates a Dual-stream Saliency Enhancement (DSE) block and a Latent-aware Semantic Extraction and Aggregation (LaSEA) module. The DSE block integrates localized perception with direction-aware context aggregation to help capture long-range spatial dependencies and local details. On this basis, the LaSEA module mitigates feature degradation via cross-scale feature extraction and random pooling sampling strategies, enhancing discriminative features and suppressing noise. Extensive experiments show that DCCS-Det achieves state-of-the-art detection accuracy with competitive efficiency across multiple datasets. Ablation studies further validate the contributions of DSE and LaSEA in improving target perception and feature representation under complex scenarios. \href{https://huggingface.co/InPeerReview/InfraredSmallTargetDetection-IRSTD.DCCS}{DCCS-Det Official Code is Available Here!}

</details>


### [11] [AlphaFace: High Fidelity and Real-time Face Swapper Robust to Facial Pose](https://arxiv.org/abs/2601.16429)
*Jongmin Yu,Hyeontaek Oh,Zhongtian Sun,Angelica I Aviles-Rivero,Moongu Jeon,Jinhong Yang*

Main category: cs.CV

TL;DR: AlphaFace is a real-time face-swapping method that uses vision-language models and CLIP embeddings with novel contrastive losses to improve identity preservation and attribute accuracy under extreme facial poses, outperforming existing methods on pose-challenging benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing face-swapping methods degrade significantly under extreme facial poses; explicit geometric features add dependencies and cost, while diffusion-based methods lack real-time capability.

Method: AlphaFace leverages an open-source vision-language model and CLIP image/text embeddings to introduce visual and textual semantic contrastive losses for stronger identity representation and precise attribute preservation.

Result: AlphaFace achieves superior performance over state-of-the-art methods in pose-challenging scenarios across FF++, MPIE, and LPFF benchmarks, while maintaining real-time speed.

Conclusion: AlphaFace effectively balances robustness to extreme poses, identity fidelity, attribute preservation, and real-time efficiency—setting a new standard for practical face-swapping.

Abstract: Existing face-swapping methods often deliver competitive results in constrained settings but exhibit substantial quality degradation when handling extreme facial poses. To improve facial pose robustness, explicit geometric features are applied, but this approach remains problematic since it introduces additional dependencies and increases computational cost. Diffusion-based methods have achieved remarkable results; however, they are impractical for real-time processing. We introduce AlphaFace, which leverages an open-source vision-language model and CLIP image and text embeddings to apply novel visual and textual semantic contrastive losses. AlphaFace enables stronger identity representation and more precise attribute preservation, all while maintaining real-time performance. Comprehensive experiments across FF++, MPIE, and LPFF demonstrate that AlphaFace surpasses state-of-the-art methods in pose-challenging cases. The project is publicly available on `https://github.com/andrewyu90/Alphaface_Official.git'.

</details>


### [12] [MDAFNet: Multiscale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection](https://arxiv.org/abs/2601.16434)
*Shuying Li,Qiang Ma,San Zhang,Wuwei Wang,Chuang Yang*

Main category: cs.CV

TL;DR: 本文提出MDAFNet网络，通过多尺度微分边缘模块（MSDE）和双域自适应特征增强模块（DAFE），解决红外小目标检测中边缘信息丢失与频域干扰问题，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在目标边缘像素随网络层数增加而逐渐退化、传统卷积难以区分频率成分导致低频背景干扰高频目标及高频噪声引发误检等问题。

Method: 提出MDAFNet，包含多尺度微分边缘（MSDE）模块用于补偿下采样过程中的边缘信息损失，以及双域自适应特征增强（DAFE）模块，结合频域处理与空间域模拟频分解/融合机制，实现高频目标增强与高频噪声抑制。

Result: 在多个数据集上的实验结果表明MDAFNet具有优越的检测性能。

Conclusion: MDAFNet有效缓解了红外小目标检测中的边缘退化与频域干扰问题，提升了检测精度与鲁棒性。

Abstract: Infrared small target detection (IRSTD) plays a crucial role in numerous military and civilian applications. However, existing methods often face the gradual degradation of target edge pixels as the number of network layers increases, and traditional convolution struggles to differentiate between frequency components during feature extraction, leading to low-frequency backgrounds interfering with high-frequency targets and high-frequency noise triggering false detections. To address these limitations, we propose MDAFNet (Multi-scale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection), which integrates the Multi-Scale Differential Edge (MSDE) module and Dual-Domain Adaptive Feature Enhancement (DAFE) module. The MSDE module, through a multi-scale edge extraction and enhancement mechanism, effectively compensates for the cumulative loss of target edge information during downsampling. The DAFE module combines frequency domain processing mechanisms with simulated frequency decomposition and fusion mechanisms in the spatial domain to effectively improve the network's capability to adaptively enhance high-frequency targets and selectively suppress high-frequency noise. Experimental results on multiple datasets demonstrate the superior detection performance of MDAFNet.

</details>


### [13] [Masked Face Recognition under Different Backbones](https://arxiv.org/abs/2601.16440)
*Bo Zhang,Ming Zhang,Kun Wu,Lei Bian,Yi Lin*

Main category: cs.CV

TL;DR: 本文评估了多种骨干网络在戴口罩和不戴口罩场景下的面部识别性能，发现r100系列在标准测试中表现最佳，而r100_mask_v2和ViT-Small/Tiny在戴口罩场景下更优，为实际部署提供指导。


<details>
  <summary>Details</summary>
Motivation: 后疫情时代，大量民航旅客佩戴口罩进行安检，给传统人脸识别模型带来挑战，亟需评估不同骨干网络在戴口罩场景下的性能表现。

Method: 通过大量对比实验，对多种主流骨干网络（如r100、r50、r34_mask_v1、r100_mask_v2、r50_mask_v3、ViT-Small/Tiny）在戴口罩与不戴口罩条件下面部识别任务中的性能进行全面评测。

Result: 标准测试中r100系列准确率超98%（FAR=0.01%），r50次之，r34_mask_v1最差；戴口罩测试中r100_mask_v2达90.07%，ViT-Small/Tiny亦表现出色；r50_mask_v3在r50系列中最佳但仍落后于r100系列。

Conclusion: 骨干网络结构显著影响戴口罩人脸识别效果，r100_mask_v2和ViT系列更适合口罩场景，研究为实际安防部署提供了具体模型选型建议。

Abstract: Erratum to the paper (Zhang et al., 2025): corrections to Table IV and the data in Page 3, Section A. In the post-pandemic era, a high proportion of civil aviation passengers wear masks during security checks, posing significant challenges to traditional face recognition models. The backbone network serves as the core component of face recognition models. In standard tests, r100 series models excelled (98%+ accuracy at 0.01% FAR in face comparison, high top1/top5 in search). r50 ranked second, r34_mask_v1 lagged. In masked tests, r100_mask_v2 led (90.07% accuracy), r50_mask_v3 performed best among r50 but trailed r100. Vit-Small/Tiny showed strong masked performance with gains in effectiveness. Through extensive comparative experiments, this paper conducts a comprehensive evaluation of several core backbone networks, aiming to reveal the impacts of different models on face recognition with and without masks, and provide specific deployment recommendations.

</details>


### [14] [GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss](https://arxiv.org/abs/2601.16885)
*Yangfan Xu,Lilian Zhang,Xiaofeng He,Pengdong Wu,Wenqi Wu,Jun Mao*

Main category: cs.CV

TL;DR: 本文提出了一种自监督的VGGT训练框架，通过序列级几何约束和联合光度-几何损失，在无标签数据上提升大场景定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的视觉几何模型依赖真实标签训练，难以适应无标签和未见过的场景。

Method: 扩展传统成对关系为序列级几何约束，对多源帧进行几何投影以增强时序特征一致性，并构建光度一致性和几何约束的联合优化损失。

Result: 模型在数百次迭代内收敛，在大规模定位任务中取得显著性能提升。

Conclusion: 所提自监督框架有效提升了VGGT在无标签数据下的跨视角几何建模与定位能力。

Abstract: Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT.

</details>


### [15] [Emotion-LLaMAv2 and MMEVerse: A New Framework and Benchmark for Multimodal Emotion Understanding](https://arxiv.org/abs/2601.16449)
*Xiaojiang Peng,Jingyi Chen,Zebang Cheng,Bao Peng,Fengyi Wu,Yifei Dong,Shuyuan Tu,Qiyu Hu,Huiting Huang,Yuxiang Lin,Jun-Yan He,Kai Wang,Zheng Lian,Zhi-Qi Cheng*

Main category: cs.CV

TL;DR: 本文提出了Emotion-LLaMAv2模型与MMEVerse基准，旨在提升多模态大语言模型在情感识别与推理任务中的性能。通过端到端多视角编码器、卷积注意力预融合模块及感知到认知的课程指令微调策略，显著改进了情感建模能力；同时构建了统一格式、高质量重标注的大规模多模态情感数据集与18项评测基准。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在情感推理能力上受限，缺乏高质量大规模带描述性情感标注的数据集和标准化评测基准；早期Emotion-LLaMA框架依赖显式人脸检测、隐式融合且训练数据质量与规模不足。

Method: 提出Emotion-LLaMAv2：（1）端到端多视角编码器替代外部人脸检测；（2）Conv Attention预融合模块实现局部与全局跨模态特征交互；（3）基于LLaMA2的感知→认知课程指令微调。配套构建MMEVerse基准：整合12个公开数据集，经Qwen2 Audio、Qwen2.5 VL与GPT-4o多智能体重标注，形成130k训练与36k测试样本，覆盖18个评测任务。

Result: Emotion-LLaMAv2在MMEVerse的18个情感识别与推理基准上显著优于现有方法；端到端设计避免了人脸检测误差，预融合模块增强了模态交互，课程指令微调提升了从基础识别到自由推理的泛化能力；MMEVerse成为首个大规模、高质量、统一格式的多模态情感指令数据集与评测体系。

Conclusion: Emotion-LLaMAv2与MMEVerse共同构成了面向情感计算的新型端到端多模态大模型范式与标准化评估基础设施，有效推动了多模态情感理解从窄域识别向开放域推理演进。

Abstract: Understanding human emotions from multimodal signals poses a significant challenge in affective computing and human-robot interaction. While multimodal large language models (MLLMs) have excelled in general vision-language tasks, their capabilities in emotional reasoning remain limited. The field currently suffers from a scarcity of large-scale datasets with high-quality, descriptive emotion annotations and lacks standardized benchmarks for evaluation. Our preliminary framework, Emotion-LLaMA, pioneered instruction-tuned multimodal learning for emotion reasoning but was restricted by explicit face detectors, implicit fusion strategies, and low-quality training data with limited scale. To address these limitations, we present Emotion-LLaMAv2 and the MMEVerse benchmark, establishing an end-to-end pipeline together with a standardized evaluation setting for emotion recognition and reasoning. Emotion-LLaMAv2 introduces three key advances. First, an end-to-end multiview encoder eliminates external face detection and captures nuanced emotional cues via richer spatial and temporal multiview tokens. Second, a Conv Attention pre-fusion module is designed to enable simultaneous local and global multimodal feature interactions external to the LLM backbone. Third, a perception-to-cognition curriculum instruction tuning scheme within the LLaMA2 backbone unifies emotion recognition and free-form emotion reasoning. To support large-scale training and reproducible evaluation, MMEVerse aggregates twelve publicly available emotion datasets, including IEMOCAP, MELD, DFEW, and MAFW, into a unified multimodal instruction format. The data are re-annotated via a multi-agent pipeline involving Qwen2 Audio, Qwen2.5 VL, and GPT 4o, producing 130k training clips and 36k testing clips across 18 evaluation benchmarks.

</details>


### [16] [AnyView: Synthesizing Any Novel View in Dynamic Scenes](https://arxiv.org/abs/2601.16982)
*Basile Van Hoorick,Dian Chen,Shun Iwase,Pavel Tokmakov,Muhammad Zubair Irshad,Igor Vasiljevic,Swati Gupta,Fangzhou Cheng,Sergey Zakharov,Vitor Campagnolo Guizilini*

Main category: cs.CV

TL;DR: 本文提出AnyView，一种基于扩散模型的动态视图合成框架，无需强几何假设，利用多源数据训练通用时空隐式表示，实现任意视角下的零样本视频生成，并在极端动态场景下展现出优越的时空一致性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式视频模型在高度动态的真实世界环境中难以维持多视角和时空一致性。

Method: 提出基于扩散模型的AnyView框架，利用单目（2D）、多视角静态（3D）和多视角动态（4D）数据进行联合训练，构建通用时空隐式表示，支持任意相机位置与轨迹的零样本视频生成。

Result: 在标准基准上达到SOTA水平；在新提出的AnyViewBench（面向极端动态视图合成）上显著优于现有方法，尤其在视角重叠少的情况下仍能生成逼真、合理且时空一致的视频。

Conclusion: AnyView通过弱归纳偏置和多源监督学习，实现了更鲁棒、泛化性更强的动态视图合成能力，为真实复杂场景下的自由视角视频生成提供了新范式。

Abstract: Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \textbf{AnyView}, a diffusion-based video generation framework for \emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \textbf{AnyViewBench}, a challenging new benchmark tailored towards \emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/

</details>


### [17] [VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology](https://arxiv.org/abs/2601.16451)
*Peixian Liang,Songhao Li,Shunsuke Koga,Yutong Li,Zahra Alipour,Yucheng Tang,Daguang Xu,Zhi Huang*

Main category: cs.CV

TL;DR: 本文提出了VISTA-PATH，一种面向病理图像的交互式、类别感知分割基础模型，通过融合视觉上下文、语义组织描述和专家空间提示，实现高精度多类别分割；并构建了包含160万图像-掩码-文本三元组的大规模数据集VISTA-PATH Data，在多个基准上超越现有方法，支持人机协同优化，并提升临床相关分析（如肿瘤相互作用评分TIS）效果。


<details>
  <summary>Details</summary>
Motivation: 现有分割基础模型将分割视为静态视觉预测任务，与病理学需求不匹配，缺乏对异质结构的建模能力及专家知识整合机制，难以支撑临床解释。

Method: 提出VISTA-PATH模型，联合建模视觉上下文、语义组织描述和可选专家空间提示（如边界框）；构建大规模VISTA-PATH Data数据集（1.6M图像-掩码-文本三元组，覆盖9器官、93组织类别）；支持基于稀疏标注的人机协同全片分割优化。

Result: 在多个留出集与外部基准上持续优于现有分割基础模型；支持动态人机交互 refinement；生成的高保真、类别感知分割结果被验证为计算病理学优选模型，其提出的Tumor Interaction Score（TIS）与患者生存显著相关。

Conclusion: VISTA-PATH将病理图像分割从静态预测提升为交互式、临床可解释的表征范式，确立了面向数字病理的基础模型新标准。

Abstract: Accurate semantic segmentation for histopathology image is crucial for quantitative tissue analysis and downstream clinical modeling. Recent segmentation foundation models have improved generalization through large-scale pretraining, yet remain poorly aligned with pathology because they treat segmentation as a static visual prediction task. Here we present VISTA-PATH, an interactive, class-aware pathology segmentation foundation model designed to resolve heterogeneous structures, incorporate expert feedback, and produce pixel-level segmentation that are directly meaningful for clinical interpretation. VISTA-PATH jointly conditions segmentation on visual context, semantic tissue descriptions, and optional expert-provided spatial prompts, enabling precise multi-class segmentation across heterogeneous pathology images. To support this paradigm, we curate VISTA-PATH Data, a large-scale pathology segmentation corpus comprising over 1.6 million image-mask-text triplets spanning 9 organs and 93 tissue classes. Across extensive held-out and external benchmarks, VISTA-PATH consistently outperforms existing segmentation foundation models. Importantly, VISTA-PATH supports dynamic human-in-the-loop refinement by propagating sparse, patch-level bounding-box annotation feedback into whole-slide segmentation. Finally, we show that the high-fidelity, class-aware segmentation produced by VISTA-PATH is a preferred model for computational pathology. It improve tissue microenvironment analysis through proposed Tumor Interaction Score (TIS), which exhibits strong and significant associations with patient survival. Together, these results establish VISTA-PATH as a foundation model that elevates pathology image segmentation from a static prediction to an interactive and clinically grounded representation for digital pathology. Source code and demo can be found at https://github.com/zhihuanglab/VISTA-PATH.

</details>


### [18] [Order from Chaos: Physical World Understanding from Glitchy Gameplay Videos](https://arxiv.org/abs/2601.16471)
*Meng Cao,Haoran Tang,Haoze Zhao,Mingfei Han,Ruyang Liu,Qiang Sun,Xiaojun Chang,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出利用游戏视频中的物理违规‘故障’（glitch）作为监督信号，构建了PhysGame数据集和GameBench评测基准，显著提升了多模态大模型在物理推理任务上的迁移能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有物理推理数据集存在真实视频标注成本高或合成数据缺乏真实性和多样性的问题；多模态大语言模型仍难以达到人类水平的物理世界理解能力。

Method: 提出基于游戏视频中违反物理定律的视觉异常（glitch）的新范式；构建元信息引导的指令微调数据集PhysGame（14万+问答对）和专家标注评测基准GameBench（880个带故障视频）；设计利用游戏标题、描述等元信息提升QA生成质量的提示策略。

Result: PhysGame微调使Qwen2.5VL在PhysBench上真实世界物理推理性能提升2.5%，在MVBench上通用迁移性能提升1.9%，在GameBench上故障检测准确率绝对提升3.7%。

Conclusion: 从游戏异常中学习是一种可扩展且有效的提升多模态智能体物理世界理解能力的新途径。

Abstract: Understanding the physical world, including object dynamics, material properties, and causal interactions, remains a core challenge in artificial intelligence. Although recent multi-modal large language models (MLLMs) have demonstrated impressive general reasoning capabilities, they still fall short of achieving human-level understanding of physical principles. Existing datasets for physical reasoning either rely on real-world videos, which incur high annotation costs, or on synthetic simulations, which suffer from limited realism and diversity. In this paper, we propose a novel paradigm that leverages glitches in gameplay videos, referring to visual anomalies that violate predefined physical laws, as a rich and scalable supervision source for physical world understanding. We introduce PhysGame, an meta information guided instruction-tuning dataset containing 140,057 glitch-centric question-answer pairs across five physical domains and sixteen fine-grained categories. To ensure data accuracy, we design a prompting strategy that utilizes gameplay metadata such as titles and descriptions to guide high-quality QA generation. Complementing PhysGame, we construct GameBench, an expert-annotated benchmark with 880 glitch-identified gameplay videos designed to evaluate physical reasoning capabilities. Extensive experiments show that PhysGame significantly enhances both Game2Real transferability, improving the real world physical reasoning performance of Qwen2.5VL by 2.5% on PhysBench, and Game2General transferability, yielding a 1.9% gain on the MVBench benchmark. Moreover, PhysGame-tuned models achieve a 3.7% absolute improvement on GameBench, demonstrating enhanced robustness in detecting physical implausibilities. These results indicate that learning from gameplay anomalies offers a scalable and effective pathway toward advancing physical world understanding in multimodal intelligence.

</details>


### [19] [Multi-View Consistent Wound Segmentation With Neural Fields](https://arxiv.org/abs/2601.16487)
*Remi Chierchia,Léo Lebrat,David Ahmedt-Aristizabal,Yulia Arzhaeva,Olivier Salvado,Clinton Fookes,Rodrigo Santa Cruz*

Main category: cs.CV

TL;DR: 本文提出WoundNeRF方法，利用NeRF SDF从自动标注的2D图像中鲁棒地估计伤口分割，并在3D重建一致性上优于现有ViT和光栅化算法。


<details>
  <summary>Details</summary>
Motivation: 伤口护理面临经济与物流负担，需借助计算机视觉与机器学习实现快速、自动的组织评估；而从2D图像推断多视角一致的3D结构仍是挑战。

Method: 提出基于NeRF SDF的WoundNeRF方法，从自动生成的标注中估计鲁棒的伤口分割，并与Vision Transformer及传统光栅化算法对比。

Result: WoundNeRF在恢复准确分割方面展现出优势，验证了其在多视角一致3D伤口建模中的潜力。

Conclusion: WoundNeRF为伤口3D建模提供了一种有前景的新范式，代码将开源以推动该方向发展。

Abstract: Wound care is often challenged by the economic and logistical burdens that consistently afflict patients and hospitals worldwide. In recent decades, healthcare professionals have sought support from computer vision and machine learning algorithms. In particular, wound segmentation has gained interest due to its ability to provide professionals with fast, automatic tissue assessment from standard RGB images. Some approaches have extended segmentation to 3D, enabling more complete and precise healing progress tracking. However, inferring multi-view consistent 3D structures from 2D images remains a challenge. In this paper, we evaluate WoundNeRF, a NeRF SDF-based method for estimating robust wound segmentations from automatically generated annotations. We demonstrate the potential of this paradigm in recovering accurate segmentations by comparing it against state-of-the-art Vision Transformer networks and conventional rasterisation-based algorithms. The code will be released to facilitate further development in this promising paradigm.

</details>


### [20] [Expert Knowledge-Guided Decision Calibration for Accurate Fine-Grained Tree Species Classification](https://arxiv.org/abs/2601.16498)
*Chen Long,Dian Chen,Ruifei Ding,Zhe Chen,Zhen Dong,Bisheng Yang*

Main category: cs.CV

TL;DR: 本文提出了一种专家知识引导的分类决策校准网络（EKDC-Net），通过引入外部领域专家知识，结合局部先验引导的知识提取模块（LPKEM）和不确定性引导的决策校准模块（UDCM），有效缓解树种细粒度分类中长尾分布与类间相似性带来的挑战，并构建了大规模数据集CU-Tree102。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视树种图像数据中普遍存在的长尾分布和高类间相似性问题，尤其在少样本或易混淆类别上表现不佳；受人类向专家求助以突破局部思维局限的启发，本文尝试引入外部领域专家知识辅助分类。

Method: 提出EKDC-Net框架，包含两个核心模块：1）局部先验引导的知识提取模块（LPKEM），利用CAM分析引导专家关注判别性特征；2）不确定性引导的决策校准模块（UDCM），动态融合整体类别不确定性和实例级预测不确定性来校准本地模型决策；同时构建CU-Tree102数据集（102类树种）。

Result: 在三个基准数据集上达到SOTA性能；作为轻量即插即用模块，仅增加0.08M可学习参数，即可使骨干网络准确率提升6.42%，精确率提升11.46%；开源数据集、代码与预训练模型。

Conclusion: 引入外部专家知识并建模不确定性是提升细粒度树种分类性能的有效范式；EKDC-Net兼具高性能与高效率，具备实际部署潜力。

Abstract: Accurate fine-grained tree species classification is critical for forest inventory and biodiversity monitoring. Existing methods predominantly focus on designing complex architectures to fit local data distributions. However, they often overlook the long-tailed distributions and high inter-class similarity inherent in limited data, thereby struggling to distinguish between few-shot or confusing categories. In the process of knowledge dissemination in the human world, individuals will actively seek expert assistance to transcend the limitations of local thinking. Inspired by this, we introduce an external "Domain Expert" and propose an Expert Knowledge-Guided Classification Decision Calibration Network (EKDC-Net) to overcome these challenges. Our framework addresses two core issues: expert knowledge extraction and utilization. Specifically, we first develop a Local Prior Guided Knowledge Extraction Module (LPKEM). By leveraging Class Activation Map (CAM) analysis, LPKEM guides the domain expert to focus exclusively on discriminative features essential for classification. Subsequently, to effectively integrate this knowledge, we design an Uncertainty-Guided Decision Calibration Module (UDCM). This module dynamically corrects the local model's decisions by considering both overall category uncertainty and instance-level prediction uncertainty. Furthermore, we present a large-scale classification dataset covering 102 tree species, named CU-Tree102 to address the issue of scarce diversity in current benchmarks. Experiments on three benchmark datasets demonstrate that our approach achieves state-of-the-art performance. Crucially, as a lightweight plug-and-play module, EKDC-Net improves backbone accuracy by 6.42% and precision by 11.46% using only 0.08M additional learnable parameters. The dataset, code, and pre-trained models are available at https://github.com/WHU-USI3DV/TreeCLS.

</details>


### [21] [SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer](https://arxiv.org/abs/2601.16515)
*Tongcheng Fang,Hanling Zhang,Ruiqi Xie,Zhuo Han,Xin Tao,Tianchen Zhao,Pengfei Wan,Wenbo Ding,Wanli Ouyang,Xuefei Ning,Yu Wang*

Main category: cs.CV

TL;DR: SALAD is a novel method that combines a lightweight linear attention branch with sparse attention using an input-dependent gating mechanism, achieving 90% sparsity and 1.72x speedup without sacrificing generation quality, and requiring minimal fine-tuning resources.


<details>
  <summary>Details</summary>
Motivation: The quadratic complexity of full attention in Diffusion Transformers causes high computational latency for long video sequences; existing sparse attention methods either offer limited acceleration (training-free) or require substantial training resources (training-based).

Method: SALAD introduces a lightweight linear attention branch in parallel with sparse attention and uses an input-dependent gating mechanism to balance the two branches.

Result: SALAD achieves 90% sparsity, 1.72x inference speedup, and maintains generation quality comparable to full attention, with efficient fine-tuning using only 2,000 video samples, 1,600 steps, and batch size 8.

Conclusion: SALAD effectively addresses the trade-off between sparsity, speed, and quality in video generation with Diffusion Transformers, offering a highly efficient and practical solution.

Abstract: Diffusion Transformers have recently demonstrated remarkable performance in video generation. However, the long input sequences result in high computational latency due to the quadratic complexity of full attention. Various sparse attention mechanisms have been proposed. Training-free sparse attention is constrained by limited sparsity and thus offers modest acceleration, whereas training-based methods can reach much higher sparsity but demand substantial data and computation for training. In this work, we propose SALAD, introducing a lightweight linear attention branch in parallel with the sparse attention. By incorporating an input-dependent gating mechanism to finely balance the two branches, our method attains 90% sparsity and 1.72x inference speedup, while maintaining generation quality comparable to the full attention baseline. Moreover, our finetuning process is highly efficient, requiring only 2,000 video samples and 1,600 training steps with a batch size of 8.

</details>


### [22] [TangramPuzzle: Evaluating Multimodal Large Language Models with Compositional Spatial Reasoning](https://arxiv.org/abs/2601.16520)
*Daixian Liu,Jiayi Kuang,Yinghui Li,Yangning Li,Di Yin,Haoyu Cao,Xing Sun,Ying Shen,Hai-Tao Zheng,Liang Lin,Philip S. Yu*

Main category: cs.CV

TL;DR: 本文提出了TangramPuzzle基准，用于评估多模态大语言模型（MLLMs）在组合空间推理方面的能力，引入了基于精确坐标的Tangram Construction Expression（TCE）框架，并设计了轮廓预测与端到端代码生成两个任务，实验发现MLLMs倾向于匹配目标轮廓而忽视几何约束，导致部件形变。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估MLLMs的精确组合空间推理能力方面存在不足，任务简单、依赖语义近似或粗略相对位置，且评价指标缺乏严谨数学定义。

Method: 提出几何 grounded 的TangramPuzzle基准；构建符号化几何框架TCE以实现机器可验证的精确坐标表达；设计Outline Prediction和End-to-End Code Generation两项互补任务。

Result: 在多个先进开源与闭源MLLM上评测发现，模型普遍偏向匹配目标轮廓而忽略几何约束，导致拼图部件出现扭曲或变形。

Conclusion: 当前MLLMs在精确组合空间推理方面仍存在显著缺陷，需更严格的几何约束建模与评估机制。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual recognition and semantic understanding. Nevertheless, their ability to perform precise compositional spatial reasoning remains largely unexplored. Existing benchmarks often involve relatively simple tasks and rely on semantic approximations or coarse relative positioning, while their evaluation metrics are typically limited and lack rigorous mathematical formulations. To bridge this gap, we introduce TangramPuzzle, a geometry-grounded benchmark designed to evaluate compositional spatial reasoning through the lens of the classic Tangram game. We propose the Tangram Construction Expression (TCE), a symbolic geometric framework that grounds tangram assemblies in exact, machine-verifiable coordinate specifications, to mitigate the ambiguity of visual approximation. We design two complementary tasks: Outline Prediction, which demands inferring global shapes from local components, and End-to-End Code Generation, which requires solving inverse geometric assembly problems. We conduct extensive evaluation experiments on advanced open-source and proprietary models, revealing an interesting insight: MLLMs tend to prioritize matching the target silhouette while neglecting geometric constraints, leading to distortions or deformations of the pieces.

</details>


### [23] [AnchoredDream: Zero-Shot 360° Indoor Scene Generation from a Single View via Geometric Grounding](https://arxiv.org/abs/2601.16532)
*Runmao Yao,Junsheng Zhou,Zhen Dong,Yu-Shen Liu*

Main category: cs.CV

TL;DR: 本文提出AnchoredDream，一种零样本单视图室内场景生成方法，通过外观-几何互促机制，基于高保真几何锚定360°场景生成，在外观一致性和几何合理性上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单视图室内场景生成是重要但病态的问题，现有基于扩散模型和深度估计的方法在大视角变化下难以兼顾外观一致性与几何合理性。

Method: 提出AnchoredDream零样本流水线：先进行外观引导的几何生成构建可靠3D布局；再通过warp-and-inpaint、warp-and-refine、后优化及新提出的Grouting Block模块逐步生成完整360°场景，确保输入视图与生成区域无缝过渡。

Result: 在多个指标上大幅超越现有方法，尤其在外观一致性和几何合理性方面表现突出，且全程无需微调（零样本）。

Conclusion: 几何锚定是实现高质量、零样本单视图场景生成的关键路径，为该方向提供了新范式。

Abstract: Single-view indoor scene generation plays a crucial role in a range of real-world applications. However, generating a complete 360° scene from a single image remains a highly ill-posed and challenging problem. Recent approaches have made progress by leveraging diffusion models and depth estimation networks, yet they still struggle to maintain appearance consistency and geometric plausibility under large viewpoint changes, limiting their effectiveness in full-scene generation. To address this, we propose AnchoredDream, a novel zero-shot pipeline that anchors 360° scene generation on high-fidelity geometry via an appearance-geometry mutual boosting mechanism. Given a single-view image, our method first performs appearance-guided geometry generation to construct a reliable 3D scene layout. Then, we progressively generate the complete scene through a series of modules: warp-and-inpaint, warp-and-refine, post-optimization, and a novel Grouting Block, which ensures seamless transitions between the input view and generated regions. Extensive experiments demonstrate that AnchoredDream outperforms existing methods by a large margin in both appearance consistency and geometric plausibility--all in a zero-shot manner. Our results highlight the potential of geometric grounding for high-quality, zero-shot single-view scene generation.

</details>


### [24] [OnlineSI: Taming Large Language Model for Online 3D Understanding and Grounding](https://arxiv.org/abs/2601.16538)
*Zixian Liu,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出OnlineSI框架，通过维护有限空间记忆和融合3D点云与语义信息，使多模态大语言模型具备持续的空间理解能力，适用于真实世界具身系统。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了多模态大语言模型在动态变化环境中持续工作的能力，且难以部署于真实世界的具身系统。

Method: 提出OnlineSI框架，采用有限空间记忆机制以控制计算开销，并融合3D点云与语义信息增强空间定位与物体识别能力；引入Fuzzy F1-Score评估指标缓解标注模糊性。

Result: 在两个代表性数据集上的实验验证了该方法的有效性，提升了模型持续空间理解能力。

Conclusion: OnlineSI为多模态大语言模型迈向真实世界具身应用提供了可行路径。

Abstract: In recent years, researchers have increasingly been interested in how to enable Multimodal Large Language Models (MLLM) to possess spatial understanding and reasoning capabilities. However, most existing methods overlook the importance of the ability to continuously work in an ever-changing world, and lack the possibility of deployment on embodied systems in real-world environments. In this work, we introduce OnlineSI, a framework that can continuously improve its spatial understanding of its surroundings given a video stream. Our core idea is to maintain a finite spatial memory to retain past observations, ensuring the computation required for each inference does not increase as the input accumulates. We further integrate 3D point cloud information with semantic information, helping MLLM to better locate and identify objects in the scene. To evaluate our method, we introduce the Fuzzy $F_1$-Score to mitigate ambiguity, and test our method on two representative datasets. Experiments demonstrate the effectiveness of our method, paving the way towards real-world embodied systems.

</details>


### [25] [Semi-Supervised Hierarchical Open-Set Classification](https://arxiv.org/abs/2601.16541)
*Erik Wallin,Fredrik Kahl,Lars Hammarstrand*

Main category: cs.CV

TL;DR: 本文提出了一种基于伪标签的师生框架，用于半监督分层开放集分类，通过子树伪标签和年龄门控机制提升对未知类别的泛化能力，在iNaturalist19数据集上仅用20个标注样本/类即可媲美全监督性能。


<details>
  <summary>Details</summary>
Motivation: 解决分层开放集分类中如何利用大规模未标注混合数据（含已知与未知类别）来提升模型对未知类别的泛化能力问题。

Method: 提出一种基于伪标签的教师-学生框架，包含两个关键组件：1）子树伪标签，为未知数据提供可靠监督；2）年龄门控机制，缓解伪标签过自信问题。

Result: 在iNaturalist19基准上，该方法优于自监督预训练+监督微调，并在每类仅20个标注样本时达到与全监督相当的性能。

Conclusion: 所提半监督框架能有效利用未标注混合数据，显著提升分层开放集分类性能，尤其在标注数据稀缺时表现突出。

Abstract: Hierarchical open-set classification handles previously unseen classes by assigning them to the most appropriate high-level category in a class taxonomy. We extend this paradigm to the semi-supervised setting, enabling the use of large-scale, uncurated datasets containing a mixture of known and unknown classes to improve the hierarchical open-set performance. To this end, we propose a teacher-student framework based on pseudo-labeling. Two key components are introduced: 1) subtree pseudo-labels, which provide reliable supervision in the presence of unknown data, and 2) age-gating, a mechanism that mitigates overconfidence in pseudo-labels. Experiments show that our framework outperforms self-supervised pretraining followed by supervised adaptation, and even matches the fully supervised counterpart when using only 20 labeled samples per class on the iNaturalist19 benchmark. Our code is available at https://github.com/walline/semihoc.

</details>


### [26] [HA2F: Dual-module Collaboration-Guided Hierarchical Adaptive Aggregation Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.16573)
*Shuying Li,Yuchen Wang,San Zhang,Chuang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为HA2F的双模块协同分层自适应聚合框架，用于遥感变化检测，通过动态分层特征校准和噪声自适应特征精炼两个模块，有效缓解多时相特征对齐偏差与辐射/几何噪声干扰，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法在局部补丁特征提取或全图整体处理之间存在权衡，导致跨时相特征匹配偏差，并对辐射和几何噪声敏感。

Method: 提出HA2F框架，包含动态分层特征校准模块（DHFCM）和噪声自适应特征精炼模块（NAFRM）：DHFCM通过感知驱动的跨层级特征融合抑制无关差异；NAFRM利用双特征选择机制生成空间掩码，突出变化敏感区域并抑制阴影等干扰。

Result: 在LEVIR-CD、WHU-CD和SYSU-CD数据集上达到SOTA性能，精度指标和计算效率均优于现有方法；消融实验验证了DHFCM和NAFRM的有效性。

Conclusion: HA2F通过分层自适应特征聚合与噪声鲁棒建模，显著提升了遥感变化检测的准确性与鲁棒性，为环境监测等应用提供了更可靠的技术支持。

Abstract: Remote sensing change detection (RSCD) aims to identify the spatio-temporal changes of land cover, providing critical support for multi-disciplinary applications (e.g., environmental monitoring, disaster assessment, and climate change studies). Existing methods focus either on extracting features from localized patches, or pursue processing entire images holistically, which leads to the cross temporal feature matching deviation and exhibiting sensitivity to radiometric and geometric noise. Following the above issues, we propose a dual-module collaboration guided hierarchical adaptive aggregation framework, namely HA2F, which consists of dynamic hierarchical feature calibration module (DHFCM) and noise-adaptive feature refinement module (NAFRM). The former dynamically fuses adjacent-level features through perceptual feature selection, suppressing irrelevant discrepancies to address multi-temporal feature alignment deviations. The NAFRM utilizes the dual feature selection mechanism to highlight the change sensitive regions and generate spatial masks, suppressing the interference of irrelevant regions or shadows. Extensive experiments verify the effectiveness of the proposed HA2F, which achieves state-of-the-art performance on LEVIR-CD, WHU-CD, and SYSU-CD datasets, surpassing existing comparative methods in terms of both precision metrics and computational efficiency. In addition, ablation experiments show that DHFCM and NAFRM are effective. \href{https://huggingface.co/InPeerReview/RemoteSensingChangeDetection-RSCD.HA2F}{HA2F Official Code is Available Here!}

</details>


### [27] [X-Aligner: Composed Visual Retrieval without the Bells and Whistles](https://arxiv.org/abs/2601.16582)
*Yuqian Zheng,Mariana-Iuliana Georgescu*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉语言模型（VLM）的新型组合视频检索（CoVR）框架，通过引入X-Aligner跨注意力模块实现渐进式多模态对齐，并结合视觉查询字幕增强查询表征；采用两阶段训练策略以保留预训练VLM表征，在Webvid-CoVR上达到SOTA（R@1=63.93%），并在CIR任务上展现强零样本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有CoVR方法通常单阶段融合多模态输入，性能提升有限，亟需更有效的多模态对齐与表征融合机制。

Method: 提出基于VLM的新CoVR框架，核心是X-Aligner跨注意力模块，用于渐进式融合与对齐视觉和文本输入；额外引入视觉查询的字幕作为辅助输入；采用两阶段训练：第一阶段仅训练X-Aligner，第二阶段微调文本编码器；基于BLIP/BLIP-2架构，在Webvid-CoVR数据集上训练。

Result: 在Webvid-CoVR-Test上Recall@1达63.93%，为当前最优；在CIRCO和Fashion-IQ上实现强零样本泛化性能。

Conclusion: 所提框架有效提升了CoVR性能，并验证了其跨任务（视频→图像）的泛化能力，凸显了渐进式跨模态对齐与两阶段训练策略的有效性。

Abstract: Composed Video Retrieval (CoVR) facilitates video retrieval by combining visual and textual queries. However, existing CoVR frameworks typically fuse multimodal inputs in a single stage, achieving only marginal gains over initial baseline. To address this, we propose a novel CoVR framework that leverages the representational power of Vision Language Models (VLMs). Our framework incorporates a novel cross-attention module X-Aligner, composed of cross-attention layers that progressively fuse visual and textual inputs and align their multimodal representation with that of the target video. To further enhance the representation of the multimodal query, we incorporate the caption of the visual query as an additional input. The framework is trained in two stages to preserve the pretrained VLM representation. In the first stage, only the newly introduced module is trained, while in the second stage, the textual query encoder is also fine-tuned. We implement our framework on top of BLIP-family architecture, namely BLIP and BLIP-2, and train it on the Webvid-CoVR data set. In addition to in-domain evaluation on Webvid-CoVR-Test, we perform zero-shot evaluations on the Composed Image Retrieval (CIR) data sets CIRCO and Fashion-IQ. Our framework achieves state-of-the-art performance on CoVR obtaining a Recall@1 of 63.93% on Webvid-CoVR-Test, and demonstrates strong zero-shot generalization on CIR tasks.

</details>


### [28] [A Lightweight Medical Image Classification Framework via Self-Supervised Contrastive Learning and Quantum-Enhanced Feature Modeling](https://arxiv.org/abs/2601.16608)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级医学图像分类框架，结合自监督对比学习与量子增强特征建模，在标注数据少、算力受限条件下实现高性能分类。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分析中标签稀缺、计算资源受限和模型泛化能力不足的问题。

Method: 采用MobileNetV2作为轻量骨干网络，基于SimCLR范式进行自监督预训练；嵌入参数化量子电路（PQC）作为量子特征增强模块，构建经典-量子混合架构，并在少量标注数据上微调。

Result: 仅约2-3百万参数、低计算开销下，在Accuracy、AUC和F1-score上持续优于无自监督或量子增强的经典基线方法；特征可视化显示判别性与表征稳定性提升。

Conclusion: 该方法为资源受限场景下的高性能医学人工智能提供了实用且前瞻性的解决方案。

Abstract: Intelligent medical image analysis is essential for clinical decision support but is often limited by scarce annotations, constrained computational resources, and suboptimal model generalization. To address these challenges, we propose a lightweight medical image classification framework that integrates self-supervised contrastive learning with quantum-enhanced feature modeling. MobileNetV2 is employed as a compact backbone and pretrained using a SimCLR-style self-supervised paradigm on unlabeled images. A lightweight parameterized quantum circuit (PQC) is embedded as a quantum feature enhancement module, forming a hybrid classical-quantum architecture, which is subsequently fine-tuned on limited labeled data. Experimental results demonstrate that, with only approximately 2-3 million parameters and low computational cost, the proposed method consistently outperforms classical baselines without self-supervised learning or quantum enhancement in terms of Accuracy, AUC, and F1-score. Feature visualization further indicates improved discriminability and representation stability. Overall, this work provides a practical and forward-looking solution for high-performance medical artificial intelligence under resource-constrained settings.

</details>


### [29] [Boundary and Position Information Mining for Aerial Small Object Detection](https://arxiv.org/abs/2601.16617)
*Rongxin Huang,Guangfeng Lin,Wenbo Zhou,Zhirong Li,Wenhuan Wu*

Main category: cs.CV

TL;DR: 本文提出了一种边界与位置信息挖掘（BPIM）框架，通过多个模块融合边界、位置和多尺度特征，显著提升了无人机图像中小目标的检测精度。


<details>
  <summary>Details</summary>
Motivation: 解决无人机图像中因尺度不平衡和边缘模糊导致的小目标检测困难问题。

Method: 提出BPIM框架，包含位置信息引导（PIG）、边界信息引导（BIG）、跨尺度融合（CSF）、三特征融合（TFF）和自适应权重融合（AWF）模块，结合注意力机制与跨尺度特征融合策略。

Result: 在VisDrone2021、DOTA1.0和WiderPerson数据集上性能优于YOLOv5-P2，并达到当前先进水平，同时计算开销可控。

Conclusion: BPIM有效整合边界、位置与尺度信息，增强了上下文特征判别力和小目标感知能力，适用于复杂场景下的小目标检测。

Abstract: Unmanned Aerial Vehicle (UAV) applications have become increasingly prevalent in aerial photography and object recognition. However, there are major challenges to accurately capturing small targets in object detection due to the imbalanced scale and the blurred edges. To address these issues, boundary and position information mining (BPIM) framework is proposed for capturing object edge and location cues. The proposed BPIM includes position information guidance (PIG) module for obtaining location information, boundary information guidance (BIG) module for extracting object edge, cross scale fusion (CSF) module for gradually assembling the shallow layer image feature, three feature fusion (TFF) module for progressively combining position and boundary information, and adaptive weight fusion (AWF) module for flexibly merging the deep layer semantic feature. Therefore, BPIM can integrate boundary, position, and scale information in image for small object detection using attention mechanisms and cross-scale feature fusion strategies. Furthermore, BPIM not only improves the discrimination of the contextual feature by adaptive weight fusion with boundary, but also enhances small object perceptions by cross-scale position fusion. On the VisDrone2021, DOTA1.0, and WiderPerson datasets, experimental results show the better performances of BPIM compared to the baseline Yolov5-P2, and obtains the promising performance in the state-of-the-art methods with comparable computation load.

</details>


### [30] [SCHIGAND: A Synthetic Facial Generation Mode Pipeline](https://arxiv.org/abs/2601.16627)
*Ananya Kadali,Sunnie Jehan-Morrison,Orasiki Wellington,Barney Evans,Precious Durojaiye,Richard Guest*

Main category: cs.CV

TL;DR: 本文提出SCHIGAND，一种结合StyleCLIP、HyperStyle、InterfaceGAN和扩散模型的合成人脸生成新方法，在保证身份一致性的同时提升真实感与多样性，适用于隐私合规的生物特征识别数据集构建。


<details>
  <summary>Details</summary>
Motivation: 应对面部数据在隐私法规、数据稀缺和伦理问题下的获取挑战，需兼顾真实性、多样性和身份保持的高质量合成人脸图像。

Method: 提出SCHIGAND合成人脸生成流程，融合StyleCLIP、HyperStyle、InterfaceGAN与扩散模型，增强身份保持能力，并控制类内变化与类间区分度。

Result: 在ArcFace验证下，SCHIGAND生成的数据集在图像质量与多样性之间取得更好平衡，优于以往生成模型；部分场景可替代真实数据用于生物特征测试。

Conclusion: SCHIGAND为面部生物识别提供了隐私合规、可扩展的合成数据生成方案，具备补充甚至替代真实数据的潜力。

Abstract: The growing demand for diverse and high-quality facial datasets for training and testing biometric systems is challenged by privacy regulations, data scarcity, and ethical concerns. Synthetic facial images offer a potential solution, yet existing generative models often struggle to balance realism, diversity, and identity preservation. This paper presents SCHIGAND, a novel synthetic face generation pipeline integrating StyleCLIP, HyperStyle, InterfaceGAN, and Diffusion models to produce highly realistic and controllable facial datasets. SCHIGAND enhances identity preservation while generating realistic intra-class variations and maintaining inter-class distinctiveness, making it suitable for biometric testing. The generated datasets were evaluated using ArcFace, a leading facial verification model, to assess their effectiveness in comparison to real-world facial datasets. Experimental results demonstrate that SCHIGAND achieves a balance between image quality and diversity, addressing key limitations of prior generative models. This research highlights the potential of SCHIGAND to supplement and, in some cases, replace real data for facial biometric applications, paving the way for privacy-compliant and scalable solutions in synthetic dataset generation.

</details>


### [31] [Edge-Aware Image Manipulation via Diffusion Models with a Novel Structure-Preservation Loss](https://arxiv.org/abs/2601.16645)
*Minsu Gong,Nuri Ryu,Jungseul Ok,Sunghyun Cho*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的结构保持损失（SPL），用于提升潜在扩散模型（LDM）在图像编辑中对边缘等像素级结构的保持能力，并结合后处理、掩码策略与颜色保持损失，显著提升了编辑结果的结构保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基于潜在扩散模型（LDM）的图像编辑方法难以保持像素级边缘结构，影响如照片级风格迁移和色调调整等任务的效果。

Method: 提出结构保持损失（SPL），利用局部线性模型量化输入与编辑图像间的结构差异；将SPL嵌入扩散生成过程；辅以后处理抑制解码失真、掩码策略实现精确编辑定位、颜色保持损失保护未编辑区域色调。

Result: 实验表明SPL显著提升结构保真度，在基于LDM的图像编辑任务中达到当前最优性能。

Conclusion: SPL是一种有效、即插即用的结构保持机制，无需额外训练即可增强LDM编辑的几何与边缘一致性，具备良好泛化性与实用性。

Abstract: Recent advances in image editing leverage latent diffusion models (LDMs) for versatile, text-prompt-driven edits across diverse tasks. Yet, maintaining pixel-level edge structures-crucial for tasks such as photorealistic style transfer or image tone adjustment-remains as a challenge for latent-diffusion-based editing. To overcome this limitation, we propose a novel Structure Preservation Loss (SPL) that leverages local linear models to quantify structural differences between input and edited images. Our training-free approach integrates SPL directly into the diffusion model's generative process to ensure structural fidelity. This core mechanism is complemented by a post-processing step to mitigate LDM decoding distortions, a masking strategy for precise edit localization, and a color preservation loss to preserve hues in unedited areas. Experiments confirm SPL enhances structural fidelity, delivering state-of-the-art performance in latent-diffusion-based image editing. Our code will be publicly released at https://github.com/gongms00/SPL.

</details>


### [32] [Reliable Brain Tumor Segmentation Based on Spiking Neural Networks with Efficient Training](https://arxiv.org/abs/2601.16652)
*Aurora Pia Ghiardelli,Guangzhi Tang,Tao Sun*

Main category: cs.CV

TL;DR: 本文提出了一种基于脉冲神经网络（SNN）的可靠且节能的3D脑肿瘤分割框架，采用多视角集成与前向时序传播（FPTT）方法，在保持高精度和良好不确定性校准的同时，大幅降低计算开销（FLOPs减少87%），适用于低功耗医疗物联网与床旁诊断系统。


<details>
  <summary>Details</summary>
Motivation: 解决传统SNN在语义图像分割中训练计算成本高的问题，并提升3D脑肿瘤分割的可靠性、能量效率及不确定性估计能力，以适配医疗IoT和床旁系统需求。

Method: 构建基于矢状面、冠状面和轴向切片的多视角SNN集成模型，实现体素级不确定性估计；采用Forward Propagation Through Time（FPTT）优化训练过程，兼顾时序学习效率与计算成本降低。

Result: 在BraTS 2017和BraTS 2023数据集上达到有竞争力的分割精度，不确定性校准良好，并实现87%的FLOPs降低。

Conclusion: 所提SNN框架在保证分割性能与不确定性可靠性的同时显著提升能效，展现出在低功耗医疗边缘设备上的应用潜力。

Abstract: We propose a reliable and energy-efficient framework for 3D brain tumor segmentation using spiking neural networks (SNNs). A multi-view ensemble of sagittal, coronal, and axial SNN models provides voxel-wise uncertainty estimation and enhances segmentation robustness. To address the high computational cost in training SNN models for semantic image segmentation, we employ Forward Propagation Through Time (FPTT), which maintains temporal learning efficiency with significantly reduced computational cost. Experiments on the Multimodal Brain Tumor Segmentation Challenges (BraTS 2017 and BraTS 2023) demonstrate competitive accuracy, well-calibrated uncertainty, and an 87% reduction in FLOPs, underscoring the potential of SNNs for reliable, low-power medical IoT and Point-of-Care systems.

</details>


### [33] [ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction](https://arxiv.org/abs/2601.16672)
*Ming Li,Hui Shan,Kai Zheng,Chentao Shen,Siyu Liu,Yanwei Fu,Zhen Chen,Xiangru Huang*

Main category: cs.CV

TL;DR: 本文提出ReWeaver框架，从稀疏多视角RGB图像中重建具有准确拓扑结构和缝纫模式的3D服装，解决了现有方法在结构表示和物理仿真适用性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有服装重建方法依赖非结构化表示（如3D高斯点阵），难以准确建模服装拓扑与缝纫结构，导致重建结果不适用于高保真物理仿真。

Method: 提出ReWeaver框架，从最少4个视角RGB图像中预测2D UV空间与3D空间中的缝线、衣片及其连接关系；构建大规模合成数据集GCD-TS（含10万+样本）用于训练。

Result: ReWeaver在拓扑精度、几何对齐度和缝线-衣片一致性上均显著优于现有方法。

Conclusion: ReWeaver实现了结构化、拓扑准确的3D服装重建，支持高保真物理仿真与机器人操作等下游任务。

Abstract: High-quality 3D garment reconstruction plays a crucial role in mitigating the sim-to-real gap in applications such as digital avatars, virtual try-on and robotic manipulation. However, existing garment reconstruction methods typically rely on unstructured representations, such as 3D Gaussian Splats, struggling to provide accurate reconstructions of garment topology and sewing structures. As a result, the reconstructed outputs are often unsuitable for high-fidelity physical simulation. We propose ReWeaver, a novel framework for topology-accurate 3D garment and sewing pattern reconstruction from sparse multi-view RGB images. Given as few as four input views, ReWeaver predicts seams and panels as well as their connectivities in both the 2D UV space and the 3D space. The predicted seams and panels align precisely with the multi-view images, yielding structured 2D--3D garment representations suitable for 3D perception, high-fidelity physical simulation, and robotic manipulation. To enable effective training, we construct a large-scale dataset GCD-TS, comprising multi-view RGB images, 3D garment geometries, textured human body meshes and annotated sewing patterns. The dataset contains over 100,000 synthetic samples covering a wide range of complex geometries and topologies. Extensive experiments show that ReWeaver consistently outperforms existing methods in terms of topology accuracy, geometry alignment and seam-panel consistency.

</details>


### [34] [Affinity Contrastive Learning for Skeleton-based Human Activity Understanding](https://arxiv.org/abs/2601.16694)
*Hongda Liu,Yunfan Liu,Min Ren,Lin Sui,Yunlong Wang,Zhenan Sun*

Main category: cs.CV

TL;DR: 本文提出ACLNet，一种基于亲和力的对比学习网络，通过引入亲和度度量、动态温度调度和基于间隔的对比策略，提升骨架数据中人类活动识别、步态识别及行人重识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于骨架的人类活动理解方法多采用对比学习范式，但未能充分利用类间结构相似性，且忽视异常正样本的影响。

Method: 提出ACLNet：1）设计亲和度度量以细化相似性计算，构建活动超类；2）引入动态温度调度自适应调整不同超类的惩罚强度；3）采用基于间隔的对比策略增强类内难分正负样本的分离。

Result: 在NTU RGB+D 60/120、Kinetics-Skeleton、PKU-MMD、FineGYM和CASIA-B等多个基准上，ACLNet在动作识别、步态识别和行人重识别任务中均取得优越性能。

Conclusion: ACLNet通过建模类间亲和关系与优化对比学习机制，显著提升了骨架数据表征的判别能力，验证了结构化对比学习的有效性。

Abstract: In skeleton-based human activity understanding, existing methods often adopt the contrastive learning paradigm to construct a discriminative feature space. However, many of these approaches fail to exploit the structural inter-class similarities and overlook the impact of anomalous positive samples. In this study, we introduce ACLNet, an Affinity Contrastive Learning Network that explores the intricate clustering relationships among human activity classes to improve feature discrimination. Specifically, we propose an affinity metric to refine similarity measurements, thereby forming activity superclasses that provide more informative contrastive signals. A dynamic temperature schedule is also introduced to adaptively adjust the penalty strength for various superclasses. In addition, we employ a margin-based contrastive strategy to improve the separation of hard positive and negative samples within classes. Extensive experiments on NTU RGB+D 60, NTU RGB+D 120, Kinetics-Skeleton, PKU-MMD, FineGYM, and CASIA-B demonstrate the superiority of our method in skeleton-based action recognition, gait recognition, and person re-identification. The source code is available at https://github.com/firework8/ACLNet.

</details>


### [35] [CER-HV: A CER-Based Human-in-the-Loop Framework for Cleaning Datasets Applied to Arabic-Script HTR](https://arxiv.org/abs/2601.16713)
*Sana Al-azzawi,Elisa Barney,Marcus Liwicki*

Main category: cs.CV

TL;DR: 本文提出CER-HV框架，结合基于字符错误率（CER）的噪声检测与人工验证，有效识别并清洗阿拉伯文字手写数据集中的标注错误，显著提升识别性能，并在多个数据集上达到SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯文字手写识别（HTR）性能落后于拉丁文字，主因是现有公开数据集存在大量未被充分报告的标注质量问题，如转录、分割、方向和非文本内容错误。

Method: 提出CER-HV框架：1）基于精心配置并采用早停策略的CRNN构建CER噪声检测器；2）引入人工在环（HITL）步骤对高风险样本进行人工验证。

Result: 在Muharaf和PHTI数据集上分别以90%和80–86%精度识别出各类标注错误；CRNN模型在KHATT、PHTI、Ajami、Muharaf上达SOTA CER（8.45%–10.66%），并在PHTD上建立新基线（11.3%）；应用CER-HV后，CER进一步降低0.3–1.8个百分点。

Conclusion: 数据质量是制约阿拉伯文字HTR发展的关键瓶颈，CER-HV是一种高效、通用的数据清洗框架，可推广至其他文字识别任务。

Abstract: Handwritten text recognition (HTR) for Arabic-script languages still lags behind Latin-script HTR, despite recent advances in model architectures, datasets, and benchmarks. We show that data quality is a significant limiting factor in many published datasets and propose CER-HV (CER-based Ranking with Human Verification) as a framework to detect and clean label errors. CER-HV combines a CER-based noise detector, built on a carefully configured Convolutional Recurrent Neural Network (CRNN) with early stopping to avoid overfitting noisy samples, and a human-in-the-loop (HITL) step that verifies high-ranking samples. The framework reveals that several existing datasets contain previously underreported problems, including transcription, segmentation, orientation, and non-text content errors. These have been identified with up to 90 percent precision in the Muharaf and 80-86 percent in the PHTI datasets.
  We also show that our CRNN achieves state-of-the-art performance across five of the six evaluated datasets, reaching 8.45 percent Character Error Rate (CER) on KHATT (Arabic), 8.26 percent on PHTI (Pashto), 10.66 percent on Ajami, and 10.11 percent on Muharaf (Arabic), all without any data cleaning. We establish a new baseline of 11.3 percent CER on the PHTD (Persian) dataset. Applying CER-HV improves the evaluation CER by 0.3-0.6 percent on the cleaner datasets and 1.0-1.8 percent on the noisier ones. Although our experiments focus on documents written in an Arabic-script language, including Arabic, Persian, Urdu, Ajami, and Pashto, the framework is general and can be applied to other text recognition datasets.

</details>


### [36] [Using Shadows in Circular Synthetic Aperture Sonar Imaging for Target Analysis](https://arxiv.org/abs/2601.16733)
*Yann Le Gall,Nicolas Burlet,Mathieu Simon,Fabien Novella,Samantha Dugelay,Jean-Philippe Malkasse*

Main category: cs.CV

TL;DR: 本文提出了一种从圆形合成孔径声纳（CSAS）数据中恢复目标阴影信息的方法，通过子孔径滤波和固定焦点阴影增强（FFSE）获取清晰阴影，并结合空间雕刻法进行3D重建，提升了水下目标识别与分析能力。


<details>
  <summary>Details</summary>
Motivation: CSAS虽提供360°视场和高分辨率成像，但因圆形扫描导致阴影丢失，而阴影对目标形状识别具有重要互补信息。

Method: 采用子孔径滤波生成多视角图像，应用固定焦点阴影增强（FFSE）突出阴影，并设计交互界面可视化阴影；最后利用空间雕刻法从分割后的阴影推断目标3D形状。

Result: 成功从CSAS数据中恢复并利用阴影信息，验证了其在目标分析和三维重建中的有效性与潜力。

Conclusion: 阴影信息可显著增强CSAS在水下目标识别与三维重建中的性能，所提方法为 mine warfare 等应用提供了新思路。

Abstract: Circular Synthetic Aperture Sonar (CSAS) provides a 360° azimuth view of the seabed, surpassing the limited aperture and mono-view image of conventional side-scan SAS. This makes CSAS a valuable tool for target recognition in mine warfare where the diversity of point of view is essential for reducing false alarms. CSAS processing typically produces a very high-resolution two-dimensional image. However, the parallax introduced by the circular displacement of the illuminator fill-in the shadow regions, and the shadow cast by an object on the seafloor is lost in favor of azimuth coverage and resolution. Yet the shadows provide complementary information on target shape useful for target recognition. In this paper, we explore a way to retrieve shadow information from CSAS data to improve target analysis and carry 3D reconstruction. Sub-aperture filtering is used to get a collection of images at various points of view along the circular trajectory and fixed focus shadow enhancement (FFSE) is applied to obtain sharp shadows. An interactive interface is also proposed to allow human operators to visualize these shadows along the circular trajectory. A space-carving reconstruction method is applied to infer the 3D shape of the object from the segmented shadows. The results demonstrate the potential of shadows in circular SAS for improving target analysis and 3D reconstruction.

</details>


### [37] [A Step to Decouple Optimization in 3DGS](https://arxiv.org/abs/2601.16736)
*Renjie Ding,Yaonan Wang,Min Liu,Jialin Zhu,Jiazheng Wang,Jiahao Zhao,Wenting Shen,Feixiang He,Xiang Che*

Main category: cs.CV

TL;DR: 本文重新审视了3D高斯点绘（3DGS）的优化过程，指出其中存在的更新步长耦合与梯度矩耦合问题，并提出解耦优化策略（Sparse Adam、Re-State Regularization、Decoupled Attribute Regularization），最终整合为改进的AdamW-GS优化器，在效率与表征能力上取得同步提升。


<details>
  <summary>Details</summary>
Motivation: 3DGS虽采用类似深度神经网络的优化方法（如Adam），但其物理意义和结构设计特殊，现有优化中存在被忽视的更新步长耦合和梯度矩耦合问题，影响效率与正则化效果。

Method: 通过分析3DGS优化中的耦合机制，提出三项解耦技术：Sparse Adam（稀疏化参数更新）、Re-State Regularization（重置优化器状态以改善正则化）、Decoupled Attribute Regularization（对高斯属性独立正则化）；并在大量实验基础上，重新耦合优势组件，设计出AdamW-GS优化器。

Result: 在3DGS及3DGS-MCMC框架下验证了各解耦组件的作用，AdamW-GS显著提升了优化效率与重建质量，实现了更快收敛与更优新视角合成效果。

Conclusion: 3DGS的优化不应直接套用DNN通用优化器，需结合其显式几何与物理特性进行定制化设计；解耦—分析—再耦合是提升其优化性能的有效范式。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful technique for real-time novel view synthesis. As an explicit representation optimized through gradient propagation among primitives, optimization widely accepted in deep neural networks (DNNs) is actually adopted in 3DGS, such as synchronous weight updating and Adam with the adaptive gradient. However, considering the physical significance and specific design in 3DGS, there are two overlooked details in the optimization of 3DGS: (i) update step coupling, which induces optimizer state rescaling and costly attribute updates outside the viewpoints, and (ii) gradient coupling in the moment, which may lead to under- or over-effective regularization. Nevertheless, such a complex coupling is under-explored. After revisiting the optimization of 3DGS, we take a step to decouple it and recompose the process into: Sparse Adam, Re-State Regularization and Decoupled Attribute Regularization. Taking a large number of experiments under the 3DGS and 3DGS-MCMC frameworks, our work provides a deeper understanding of these components. Finally, based on the empirical analysis, we re-design the optimization and propose AdamW-GS by re-coupling the beneficial components, under which better optimization efficiency and representation effectiveness are achieved simultaneously.

</details>


### [38] [Automated Road Crack Localization to Guide Highway Maintenance](https://arxiv.org/abs/2601.16737)
*Steffen Knoblauch,Ram Kumar Muthusamy,Pedram Ghamisi,Alexander Zipf*

Main category: cs.CV

TL;DR: 本研究提出了一种基于开源数据（航拍影像与OpenStreetMap）和YOLOv11微调的高速公路裂缝定位框架，并构建了瑞士相对公路裂缝密度（RHCD）指数以指导全国性养护决策；模型在裂缝检测中F1-score达0.84（正类）和0.97（负类），RHCD与温度幅度和交通量相关性弱，验证其独立信息价值。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致路面热应力加剧，养护成本上升，亟需高效、精准的养护策略；开源数据为低成本、可扩展的基础设施监测提供了新可能。

Method: 融合航拍影像与OpenStreetMap数据，微调YOLOv11模型实现裂缝像素级定位；基于检测结果构建瑞士相对公路裂缝密度（RHCD）指数，并分析其与长时地表温度振幅（LT-LST-A）及交通量（TV）的相关性。

Result: 裂缝检测模型F1-score为0.84（裂缝类）和0.97（非裂缝类）；RHCD指数与LT-LST-A呈弱负相关（r = -0.05），与TV呈弱正相关（r = 0.17）；高RHCD值集中于城市中心与交叉口，符合工程直觉。

Conclusion: 基于开源数据的自动化裂缝评估框架可行且具现实指导意义；RHCD作为新型指标能补充传统环境与交通变量，提升养护决策的科学性与效率；成果凸显开源数据共享对公共部门技术创新的价值。

Abstract: Highway networks are crucial for economic prosperity. Climate change-induced temperature fluctuations are exacerbating stress on road pavements, resulting in elevated maintenance costs. This underscores the need for targeted and efficient maintenance strategies. This study investigates the potential of open-source data to guide highway infrastructure maintenance. The proposed framework integrates airborne imagery and OpenStreetMap (OSM) to fine-tune YOLOv11 for highway crack localization. To demonstrate the framework's real-world applicability, a Swiss Relative Highway Crack Density (RHCD) index was calculated to inform nationwide highway maintenance. The crack classification model achieved an F1-score of $0.84$ for the positive class (crack) and $0.97$ for the negative class (no crack). The Swiss RHCD index exhibited weak correlations with Long-term Land Surface Temperature Amplitudes (LT-LST-A) (Pearson's $r\ = -0.05$) and Traffic Volume (TV) (Pearson's $r\ = 0.17$), underlining the added value of this novel index for guiding maintenance over other data. Significantly high RHCD values were observed near urban centers and intersections, providing contextual validation for the predictions. These findings highlight the value of open-source data sharing to drive innovation, ultimately enabling more efficient solutions in the public sector.

</details>


### [39] [Curated endoscopic retrograde cholangiopancreatography images dataset](https://arxiv.org/abs/2601.16759)
*Alda João Andrade,Mónica Martins,André Ferreira,Tarcísio Araújo,Luís Lopes,Victor Alves*

Main category: cs.CV

TL;DR: 本文介绍了一个大规模、经过人工标注和验证的ERCP内镜图像数据集，旨在填补AI在胆胰疾病自动诊断中缺乏公开数据的空白。


<details>
  <summary>Details</summary>
Motivation: 公共ERCP数据集稀缺，限制了人工智能在胆胰疾病自动诊断中的应用。

Method: 构建包含19,018张原始图像和19,317张处理后图像的大规模ERCP图像数据集，其中5,519张图像由三位资深胃肠病专家（均具丰富ERCP操作经验）进行人工标注与复核，并通过分类实验验证数据集有效性。

Result: 提供了高质量、可直接使用的ERCP图像数据集，支持自动ERCP分析及胆胰疾病诊断研究。

Conclusion: 该数据集有望成为ERCP自动分析和胆胰疾病AI辅助诊断的基准数据集，推动相关领域发展。

Abstract: Endoscopic Retrograde Cholangiopancreatography (ERCP) is a key procedure in the diagnosis and treatment of biliary and pancreatic diseases. Artificial intelligence has been pointed as one solution to automatize diagnosis. However, public ERCP datasets are scarce, which limits the use of such approach. Therefore, this study aims to help fill this gap by providing a large and curated dataset. The collection is composed of 19.018 raw images and 19.317 processed from 1.602 patients. 5.519 images are labeled, which provides a ready to use dataset. All images were manually inspected and annotated by two gastroenterologist with more than 5 years of experience and reviewed by another gastroenterologist with more than 20 years of experience, all with more than 400 ERCP procedures annually. The utility and validity of the dataset is proven by a classification experiment. This collection aims to provide or contribute for a benchmark in automatic ERCP analysis and diagnosis of biliary and pancreatic diseases.

</details>


### [40] [Flow Matching for Probabilistic Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.16763)
*Cuong Le,Pavló Melnyk,Bastian Wandt,Mårten Wadenbäck*

Main category: cs.CV

TL;DR: 本文提出FMPose，一种基于流匹配生成方法的概率性3D人体姿态估计模型，通过连续归一化流学习从简单源分布到合理3D姿态分布的最优传输，并利用图卷积网络建模2D线索条件，在多个基准上超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 解决单目图像3D人体姿态估计中因深度模糊导致的高度不适定问题，以及传统方法产生错误但过度自信的3D估计的问题。

Method: 提出FMPose，采用基于流匹配的生成范式，以2D关键点为条件，通过连续归一化流学习从简单源分布到3D姿态分布的最优传输；2D条件建模使用图卷积网络，利用人体关节点间的图结构进行特征聚合。

Result: 在Human3.6M、MPI-INF-3DHP和3DPW三个主流基准上，FMPose显著优于当前最先进方法，且相比扩散模型生成更快、更准确。

Conclusion: FMPose通过引入最优传输驱动的流匹配机制与图结构建模，有效提升了单目3D人体姿态估计的准确性与不确定性建模能力，是一种高效、先进的概率性姿态提升方法。

Abstract: Recovering 3D human poses from a monocular camera view is a highly ill-posed problem due to the depth ambiguity. Earlier studies on 3D human pose lifting from 2D often contain incorrect-yet-overconfident 3D estimations. To mitigate the problem, emerging probabilistic approaches treat the 3D estimations as a distribution, taking into account the uncertainty measurement of the poses. Falling in a similar category, we proposed FMPose, a probabilistic 3D human pose estimation method based on the flow matching generative approach. Conditioned on the 2D cues, the flow matching scheme learns the optimal transport from a simple source distribution to the plausible 3D human pose distribution via continuous normalizing flows. The 2D lifting condition is modeled via graph convolutional networks, leveraging the learnable connections between human body joints as the graph structure for feature aggregation. Compared to diffusion-based methods, the FMPose with optimal transport produces faster and more accurate 3D pose generations. Experimental results show major improvements of our FMPose over current state-of-the-art methods on three common benchmarks for 3D human pose estimation, namely Human3.6M, MPI-INF-3DHP and 3DPW.

</details>


### [41] [AutoRegressive Generation with B-rep Holistic Token Sequence Representation](https://arxiv.org/abs/2601.16771)
*Jiahao Li,Yunpeng Bai,Yongkang Dai,Hao Guo,Hongping Gan,Yilei Shi*

Main category: cs.CV

TL;DR: 本文提出BrepARG，首次将B-rep的几何与拓扑信息统一编码为整体token序列，支持基于序列的自回归生成，并通过Transformer解码器实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有B-rep表示与生成方法依赖图结构，割裂几何与拓扑特征，无法适配序列式生成模型（如Transformer）；亟需一种能统一建模二者并兼容序列生成范式的表示方法。

Method: BrepARG将B-rep编码为三类token（几何/位置token、面索引token），分层构建整体token序列：先构造几何块（面、边），再排序几何块，最后组装完整序列；并设计基于因果掩码的Decoder-only Transformer进行自回归建模。

Result: 在B-rep生成任务上达到SOTA性能；验证了将B-rep表示为整体token序列的可行性。

Conclusion: BrepARG为B-rep生成开辟了新路径，证明序列化建模几何与拓扑联合表征的有效性，推动CAD生成向大模型范式演进。

Abstract: Previous representation and generation approaches for the B-rep relied on graph-based representations that disentangle geometric and topological features through decoupled computational pipelines, thereby precluding the application of sequence-based generative frameworks, such as transformer architectures that have demonstrated remarkable performance. In this paper, we propose BrepARG, the first attempt to encode B-rep's geometry and topology into a holistic token sequence representation, enabling sequence-based B-rep generation with an autoregressive architecture. Specifically, BrepARG encodes B-rep into 3 types of tokens: geometry and position tokens representing geometric features, and face index tokens representing topology. Then the holistic token sequence is constructed hierarchically, starting with constructing the geometry blocks (i.e., faces and edges) using the above tokens, followed by geometry block sequencing. Finally, we assemble the holistic sequence representation for the entire B-rep. We also construct a transformer-based autoregressive model that learns the distribution over holistic token sequences via next-token prediction, using a multi-layer decoder-only architecture with causal masking. Experiments demonstrate that BrepARG achieves state-of-the-art (SOTA) performance. BrepARG validates the feasibility of representing B-rep as holistic token sequences, opening new directions for B-rep generation.

</details>


### [42] [CASP: Few-Shot Class-Incremental Learning with CLS Token Attention Steering Prompts](https://arxiv.org/abs/2601.16773)
*Shuai Huang,Xuhan Lin,Yuwu Lu*

Main category: cs.CV

TL;DR: 本文提出CLS Token Attention Steering Prompts (CASP)方法，通过在CLS token的Q/K/V投影中引入可学习的类别共享偏置参数，显式调控自注意力权重，并结合注意力扰动与流形Token混叠策略，提升少样本类增量学习中的泛化能力与知识保留能力。


<details>
  <summary>Details</summary>
Motivation: 在极端少样本增量设定下，模型需高效迁移和泛化，亟需在基础训练阶段利用预训练知识学习跨类别共享的特征表示。

Method: 提出CASP方法：1）在CLS token的查询、键、值投影中引入类别共享可训练偏置；2）设计注意力扰动策略；3）在浅层特征空间进行Manifold Token Mixup以合成新类特征。

Result: 在CUB200、CIFAR100和ImageNet-R数据集上，CASP在标准与细粒度FSCIL设置中均超越现有SOTA方法，且无需增量阶段微调，显著降低参数开销。

Conclusion: CASP通过改进CLS token注意力机制与特征空间增强策略，有效平衡了少样本增量学习中的泛化性与稳定性，为持续学习提供了轻量高效的新范式。

Abstract: Few-shot class-incremental learning (FSCIL) presents a core challenge in continual learning, requiring models to rapidly adapt to new classes with very limited samples while mitigating catastrophic forgetting. Recent prompt-based methods, which integrate pretrained backbones with task-specific prompts, have made notable progress. However, under extreme few-shot incremental settings, the model's ability to transfer and generalize becomes critical, and it is thus essential to leverage pretrained knowledge to learn feature representations that can be shared across future categories during the base session. Inspired by the mechanism of the CLS token, which is similar to human attention and progressively filters out task-irrelevant information, we propose the CLS Token Attention Steering Prompts (CASP). This approach introduces class-shared trainable bias parameters into the query, key, and value projections of the CLS token to explicitly modulate the self-attention weights. To further enhance generalization, we also design an attention perturbation strategy and perform Manifold Token Mixup in the shallow feature space, synthesizing potential new class features to improve generalization and reserve the representation capacity for upcoming tasks. Experiments on the CUB200, CIFAR100, and ImageNet-R datasets demonstrate that CASP outperforms state-of-the-art methods in both standard and fine-grained FSCIL settings without requiring fine-tuning during incremental phases and while significantly reducing the parameter overhead.

</details>


### [43] [SLD: Segmentation-Based Landmark Detection for Spinal Ligaments](https://arxiv.org/abs/2601.16782)
*Lara Blomenkamp,Ivanna Kramer,Sabine Bauer,Theresa Schöche*

Main category: cs.CV

TL;DR: 本文提出了一种新的脊柱韧带附着点检测方法，通过基于形状的3D椎骨分割和领域特定规则识别附着点，在所有脊柱区域均表现出高精度和强泛化能力，验证结果显示平均绝对误差为0.7 mm，均方根误差为1.1 mm。


<details>
  <summary>Details</summary>
Motivation: 现有自动化检测方法局限于特定脊柱区域或精度不足，而精准识别韧带附着点对构建可靠的脊柱生物力学模型至关重要。

Method: 首先进行基于形状的3D椎骨分割，然后应用领域特定规则识别不同类型的韧带附着点。

Result: 在两个独立的多患者脊柱数据集上验证，平均绝对误差（MAE）为0.7 mm，均方根误差（RMSE）为1.1 mm，性能优于现有方法。

Conclusion: 该方法具有高精度和跨脊柱区域的强泛化能力，可有效提升脊柱生物力学建模的可靠性。

Abstract: In biomechanical modeling, the representation of ligament attachments is crucial for a realistic simulation of the forces acting between the vertebrae. These forces are typically modeled as vectors connecting ligament landmarks on adjacent vertebrae, making precise identification of these landmarks a key requirement for constructing reliable spine models. Existing automated detection methods are either limited to specific spinal regions or lack sufficient accuracy. This work presents a novel approach for detecting spinal ligament landmarks, which first performs shape-based segmentation of 3D vertebrae and subsequently applies domain-specific rules to identify different types of attachment points. The proposed method outperforms existing approaches by achieving high accuracy and demonstrating strong generalization across all spinal regions. Validation on two independent spinal datasets from multiple patients yielded a mean absolute error (MAE) of 0.7 mm and a root mean square error (RMSE) of 1.1 mm.

</details>


### [44] [REL-SF4PASS: Panoramic Semantic Segmentation with REL Depth Representation and Spherical Fusion](https://arxiv.org/abs/2601.16788)
*Xuewei Li,Xinghan Bao,Zhimin Chen,Xi Li*

Main category: cs.CV

TL;DR: 本文提出REL-SF4PASS方法，通过新设计的REL深度表示（基于柱坐标系）和球面动态多模态融合（SMMF），提升全景语义分割性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有全景语义分割方法未充分利用全景图像几何结构，尤其在球面几何建模或深度使用上存在局限。

Method: 提出REL深度表示（含校正深度、仰角衍生垂直倾角、横向方位角）和球面动态多模态融合（SMMF），适配全景图像不同区域并缓解ERP投影导致的圆柱侧面展开失真。

Result: 在Stanford2D3D全景数据集上平均mIoU提升2.35%，面对3D扰动时性能方差降低约70%。

Conclusion: REL-SF4PASS有效利用全景图像几何特性，显著提升分割精度与鲁棒性，验证了柱坐标系深度表示与区域自适应融合策略的有效性。

Abstract: As an important and challenging problem in computer vision, Panoramic Semantic Segmentation (PASS) aims to give complete scene perception based on an ultra-wide angle of view. Most PASS methods often focus on spherical geometry with RGB input or using the depth information in original or HHA format, which does not make full use of panoramic image geometry. To address these shortcomings, we propose REL-SF4PASS with our REL depth representation based on cylindrical coordinate and Spherical-dynamic Multi-Modal Fusion SMMF. REL is made up of Rectified Depth, Elevation-Gained Vertical Inclination Angle, and Lateral Orientation Angle, which fully represents 3D space in cylindrical coordinate style and the surface normal direction. SMMF aims to ensure the diversity of fusion for different panoramic image regions and reduce the breakage of cylinder side surface expansion in ERP projection, which uses different fusion strategies to match the different regions in panoramic images. Experimental results show that REL-SF4PASS considerably improves performance and robustness on popular benchmark, Stanford2D3D Panoramic datasets. It gains 2.35% average mIoU improvement on all 3 folds and reduces the performance variance by approximately 70% when facing 3D disturbance.

</details>


### [45] [Incorporating Eye-Tracking Signals Into Multimodal Deep Visual Models For Predicting User Aesthetic Experience In Residential Interiors](https://arxiv.org/abs/2601.16811)
*Chen-Ying Chien,Po-Chih Kuo*

Main category: cs.CV

TL;DR: 本文提出了一种融合视觉特征与眼动信号的双分支CNN-LSTM模型，用于预测住宅室内空间的美学评价，在客观维度（72.2%）和主观维度（66.8%）上均优于现有视频基线方法，并验证了眼动数据作为训练时的‘特权信息’可提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 预测室内空间的美学体验困难，因其具有主观性和视觉响应复杂性；需更有效方法理解人对室内环境的感知与评价。

Method: 构建双分支CNN-LSTM框架，融合视频帧视觉特征与同步采集的眼动（注视点、瞳孔直径等）信号；基于224个室内设计视频及28名被试对15个美学维度的评分与眼动数据进行训练与评估，并开展消融实验分析各信号贡献。

Result: 模型在客观美学维度（如明亮度）达72.2%准确率，在主观维度（如放松感）达66.8%；引入眼动信号显著提升主观评估性能；仅用视觉输入部署时性能保持稳定；瞳孔响应主导客观评估， gaze+visual融合更利于主观评估。

Conclusion: 眼动数据作为训练阶段的特权信息，能有效增强美学预测模型尤其是主观维度的性能，且不损害实际部署时的视觉单模态可用性，为室内设计美学评估提供了兼具理论价值与实用潜力的新范式。

Abstract: Understanding how people perceive and evaluate interior spaces is essential for designing environments that promote well-being. However, predicting aesthetic experiences remains difficult due to the subjective nature of perception and the complexity of visual responses. This study introduces a dual-branch CNN-LSTM framework that fuses visual features with eye-tracking signals to predict aesthetic evaluations of residential interiors. We collected a dataset of 224 interior design videos paired with synchronized gaze data from 28 participants who rated 15 aesthetic dimensions. The proposed model attains 72.2% accuracy on objective dimensions (e.g., light) and 66.8% on subjective dimensions (e.g., relaxation), outperforming state-of-the-art video baselines and showing clear gains on subjective evaluation tasks. Notably, models trained with eye-tracking retain comparable performance when deployed with visual input alone. Ablation experiments further reveal that pupil responses contribute most to objective assessments, while the combination of gaze and visual cues enhances subjective evaluations. These findings highlight the value of incorporating eye-tracking as privileged information during training, enabling more practical tools for aesthetic assessment in interior design.

</details>


### [46] [ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models](https://arxiv.org/abs/2601.16836)
*Chenxi Ruan,Yu Xiao,Yihan Hou,Guosheng Hu,Wei Zeng*

Main category: cs.CV

TL;DR: 本文提出了ColorConceptBench基准，用于系统评估文本到图像模型对隐式颜色概念的关联能力，发现现有模型在抽象语义颜色理解上存在显著不足，且该问题无法通过常规扩展或引导策略解决。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在将颜色与隐式概念关联方面的能力尚未被充分研究，亟需一个系统性评估基准来揭示其局限性。

Method: 构建了基于6369条人工标注、涵盖1281个隐式颜色概念的ColorConceptBench基准，从概率颜色分布角度评估7种主流T2I模型的表现。

Result: 实验表明当前T2I模型对抽象语义颜色不敏感，且该缺陷对模型缩放和采样引导等标准干预手段具有鲁棒性。

Conclusion: 实现类人颜色语义理解不仅需要更大模型，更需在模型学习与表征隐式意义的方式上进行根本性变革。

Abstract: While text-to-image (T2I) models have advanced considerably, their capability to associate colors with implicit concepts remains underexplored. To address the gap, we introduce ColorConceptBench, a new human-annotated benchmark to systematically evaluate color-concept associations through the lens of probabilistic color distributions. ColorConceptBench moves beyond explicit color names or codes by probing how models translate 1,281 implicit color concepts using a foundation of 6,369 human annotations. Our evaluation of seven leading T2I models reveals that current models lack sensitivity to abstract semantics, and crucially, this limitation appears resistant to standard interventions (e.g., scaling and guidance). This demonstrates that achieving human-like color semantics requires more than larger models, but demands a fundamental shift in how models learn and represent implicit meaning.

</details>


### [47] [No Validation, No Problem: Predicting Model Performance from a Single Gradient](https://arxiv.org/abs/2601.16874)
*Fangzheng Wu,Brian Summa*

Main category: cs.CV

TL;DR: 本文提出了一种无需验证集的检查点选择信号——分类头梯度的Frobenius范数（||g||_F），仅需单次前向-反向传播即可计算；该信号在多种模型（CNN/Transformer）和任务（分类、检测、分割、扩散模型）中均能有效预测性能，实现接近oracle的检查点选择与早停，且开销极小（<0.1% epoch）。


<details>
  <summary>Details</summary>
Motivation: 避免依赖验证标签进行模型检查点选择和早停，降低标注成本与过拟合风险，提升训练流程的自动化与实用性。

Method: 利用单个batch上分类头参数梯度的Frobenius范数||dL/dW||_F作为无验证代理指标；针对不同架构采用不同归一化策略（head-scale用于CNN，feature-scale用于Transformer/现代CNN）；在训练尾部窗口内选取||g||_F最小的检查点。

Result: 在ImageNet-1k上，该方法以通用设置缩小了约4.24%±2.00%的oracle差距（调优后约1.12%）；在COCO检测/分割任务中可预测mAP；在CIFAR-10扩散模型中与MSE正相关、与FID负相关，支持无标签监控；计算开销低于0.1% epoch。

Conclusion: ||g||_F是一种高效、通用、标签无关的训练动态代理指标，适用于多种模型与任务的验证自由检查点选择、早停与性能监控。

Abstract: We propose a validation-free checkpointing signal from a single forward-backward pass: the Frobenius norm of the classifier-head gradient on one detached-feature batch, ||g||_F = ||dL/dW||_F. Across ImageNet-1k CNNs and Transformers, this proxy is strongly negative with Top-1 and positive with loss. Selecting the checkpoint with the minimum head gradient in a short tail window closes most of the gap to the oracle (4.24% +/- 2.00% with a universal setup, about 1.12% with light per-family tuning). For practical deployment, a head-scale normalization is more stable within classic CNN families (e.g., ResNets), while a feature-scale normalization works well for Transformers and modern CNNs. The same one-batch probe also predicts COCO detection/segmentation mAP. In diffusion (UNet/DDPM on CIFAR-10), it tracks progress and enables near-oracle tail-window selection; it is positively correlated with same-distribution probe MSE and negatively with FID (lower is better), so it can be used as a lightweight, label-free monitor. Validation labels are never used beyond reporting. The probe adds much less than 0.1% of an epoch and works as a drop-in for validation-free checkpoint selection and early stopping.

</details>


### [48] [Evaluating Large Vision-language Models for Surgical Tool Detection](https://arxiv.org/abs/2601.16895)
*Nakul Poudel,Richard Simon,Cristian A. Linte*

Main category: cs.CV

TL;DR: 本文评估了三种大型视觉语言模型（Qwen2.5、LLaVA1.5、InternVL3.5）在机器人手术工具检测任务中的性能，发现Qwen2.5在零样本和LoRA微调设置下均表现最优，尤其在工具识别上优于Grounding DINO，而后者定位能力更强。


<details>
  <summary>Details</summary>
Motivation: 当前外科AI系统多为单模态，难以全面理解手术流程；亟需能整合多模态信息、具备类人场景推理能力的通用外科AI系统。

Method: 在GraSP机器人手术数据集上，对Qwen2.5、LLaVA1.5和InternVL3.5三种VLM进行零样本推理与LoRA参数高效微调，并与开放集检测基线Grounding DINO对比工具检测性能。

Result: Qwen2.5在零样本和微调设置下均取得最优检测性能；相比Grounding DINO，其零样本泛化能力更强、微调后性能相当；Qwen2.5更擅长工具识别，Grounding DINO更擅长定位。

Conclusion: 大型视觉语言模型（尤其是Qwen2.5）在外科工具检测任务中展现出巨大潜力，验证了多模态大模型作为通用外科AI基础架构的可行性。

Abstract: Surgery is a highly complex process, and artificial intelligence has emerged as a transformative force in supporting surgical guidance and decision-making. However, the unimodal nature of most current AI systems limits their ability to achieve a holistic understanding of surgical workflows. This highlights the need for general-purpose surgical AI systems capable of comprehensively modeling the interrelated components of surgical scenes. Recent advances in large vision-language models that integrate multimodal data processing offer strong potential for modeling surgical tasks and providing human-like scene reasoning and understanding. Despite their promise, systematic investigations of VLMs in surgical applications remain limited. In this study, we evaluate the effectiveness of large VLMs for the fundamental surgical vision task of detecting surgical tools. Specifically, we investigate three state-of-the-art VLMs, Qwen2.5, LLaVA1.5, and InternVL3.5, on the GraSP robotic surgery dataset under both zero-shot and parameter-efficient LoRA fine-tuning settings. Our results demonstrate that Qwen2.5 consistently achieves superior detection performance in both configurations among the evaluated VLMs. Furthermore, compared with the open-set detection baseline Grounding DINO, Qwen2.5 exhibits stronger zero-shot generalization and comparable fine-tuned performance. Notably, Qwen2.5 shows superior instrument recognition, while Grounding DINO demonstrates stronger localization.

</details>


### [49] [LoL: Longer than Longer, Scaling Video Generation to Hour](https://arxiv.org/abs/2601.16914)
*Justin Cui,Jie Wu,Ming Li,Tao Yang,Xiaojie Li,Rui Wang,Andrew Bai,Yuanhao Ban,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的轻量级方法——多头RoPE抖动，以解决长视频自回归生成中因RoPE周期性与多头注意力机制冲突导致的'sink-collapse'问题，首次实现高质量、实时、流式、无限长视频生成（实测达12小时）。


<details>
  <summary>Details</summary>
Motivation: 现有长视频自回归生成模型因错误累积和长期连贯性丢失而性能下降；虽引入attention sink帧缓解，但引发sink-collapse（内容反复回退至sink帧，造成场景重置和循环运动）这一新问题。

Method: 分析发现sink-collapse源于Rotary Position Embedding（RoPE）的周期性结构与多头注意力机制的内在冲突；为此提出'多头RoPE抖动'（multi-head RoPE jitter）策略，通过打破头间注意力同质化来抑制长程崩溃，且无需额外训练。

Result: 实验表明该方法有效缓解sink-collapse，同时保持生成质量；首次实现高质量、实时、流式、近乎无限长度的视频生成，最长成功生成12小时连续视频。

Conclusion: 多头RoPE抖动是一种简单有效、即插即用的解决方案，为长视频生成中的长期一致性建模提供了新思路，并推动了流式无限视频生成的实际落地。

Abstract: Recent research in long-form video generation has shifted from bidirectional to autoregressive models, yet these methods commonly suffer from error accumulation and a loss of long-term coherence. While attention sink frames have been introduced to mitigate this performance decay, they often induce a critical failure mode we term sink-collapse: the generated content repeatedly reverts to the sink frame, resulting in abrupt scene resets and cyclic motion patterns. Our analysis reveals that sink-collapse originates from an inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and the multi-head attention mechanisms prevalent in current generative models. To address it, we propose a lightweight, training-free approach that effectively suppresses this behavior by introducing multi-head RoPE jitter that breaks inter-head attention homogenization and mitigates long-horizon collapse. Extensive experiments show that our method successfully alleviates sink-collapse while preserving generation quality. To the best of our knowledge, this work achieves the first demonstration of real-time, streaming, and infinite-length video generation with little quality decay. As an illustration of this robustness, we generate continuous videos up to 12 hours in length, which, to our knowledge, is among the longest publicly demonstrated results in streaming video generation.

</details>


### [50] [Reward-Forcing: Autoregressive Video Generation with Reward Feedback](https://arxiv.org/abs/2601.16933)
*Jingran Zhang,Ning Li,Yuanhao Ban,Andrew Bai,Justin Cui*

Main category: cs.CV

TL;DR: 本文提出了一种基于奖励信号引导的自回归视频生成方法，避免依赖强教师模型，在保持高质量视觉效果和时序一致性的同时，简化训练并提升可扩展性，在VBench上达到84.92分，媲美甚至超越部分双向模型。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视频生成方法严重依赖教师模型，导致性能受限、输出质量落后于双向模型。

Method: 引入奖励信号指导自回归生成过程，替代传统教师蒸馏范式，实现更高效、可扩展的训练。

Result: 在标准基准（如VBench）上表现媲美最先进自回归方法（84.92 vs 84.31），且在某些情况下超越同尺寸双向模型；无需异构蒸馏。

Conclusion: 基于奖励的引导机制是替代教师依赖的有效途径，可在不牺牲质量的前提下提升自回归视频生成的效率与灵活性。

Abstract: While most prior work in video generation relies on bidirectional architectures, recent efforts have sought to adapt these models into autoregressive variants to support near real-time generation. However, such adaptations often depend heavily on teacher models, which can limit performance, particularly in the absence of a strong autoregressive teacher, resulting in output quality that typically lags behind their bidirectional counterparts. In this paper, we explore an alternative approach that uses reward signals to guide the generation process, enabling more efficient and scalable autoregressive generation. By using reward signals to guide the model, our method simplifies training while preserving high visual fidelity and temporal consistency. Through extensive experiments on standard benchmarks, we find that our approach performs comparably to existing autoregressive models and, in some cases, surpasses similarly sized bidirectional models by avoiding constraints imposed by teacher architectures. For example, on VBench, our method achieves a total score of 84.92, closely matching state-of-the-art autoregressive methods that score 84.31 but require significant heterogeneous distillation.

</details>


### [51] [Domain-invariant Mixed-domain Semi-supervised Medical Image Segmentation with Clustered Maximum Mean Discrepancy Alignment](https://arxiv.org/abs/2601.16954)
*Ba-Thinh Lam,Thanh-Huy Nguyen,Hoang-Thien Nguyen,Quang-Khai Bui-Tran,Nguyen Lan Vi Vu,Phat K. Huynh,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: 本文提出了一种面向混合域半监督医学图像分割的域不变框架，通过Copy-Paste机制增强数据多样性，并利用Cluster MMD模块对齐跨域特征，无需显式域标签即可提升模型鲁棒性与精度。


<details>
  <summary>Details</summary>
Motivation: 现实医疗场景中，标注稀缺且图像来自多中心/多设备（混合域），域标签未知、域间差异大；而现有半监督或域自适应方法通常假设单域偏移或需已知域标签，难以适用。

Method: 提出域不变混合域半监督分割框架：1）Copy-Paste机制（CPM）跨域复制粘贴信息区域以增强数据多样性；2）Cluster Maximum Mean Discrepancy（CMMD）模块对无标签特征聚类，并通过MMD目标对其与有标签锚点对齐；3）嵌入教师-学生框架中联合优化。

Result: 在Fundus和M&Ms基准上实验表明，该方法在极少量标注下仍显著优于现有半监督和域自适应方法，尤其在多未知域混合设置中表现鲁棒。

Conclusion: 所提框架有效缓解了混合域下的域偏移与标注稀缺双重挑战，为真实医疗场景中的半监督分割提供了可行新范式。

Abstract: Deep learning has shown remarkable progress in medical image semantic segmentation, yet its success heavily depends on large-scale expert annotations and consistent data distributions. In practice, annotations are scarce, and images are collected from multiple scanners or centers, leading to mixed-domain settings with unknown domain labels and severe domain gaps. Existing semi-supervised or domain adaptation approaches typically assume either a single domain shift or access to explicit domain indices, which rarely hold in real-world deployment. In this paper, we propose a domain-invariant mixed-domain semi-supervised segmentation framework that jointly enhances data diversity and mitigates domain bias. A Copy-Paste Mechanism (CPM) augments the training set by transferring informative regions across domains, while a Cluster Maximum Mean Discrepancy (CMMD) block clusters unlabeled features and aligns them with labeled anchors via an MMD objective, encouraging domain-invariant representations. Integrated within a teacher-student framework, our method achieves robust and precise segmentation even with very few labeled examples and multiple unknown domain discrepancies. Experiments on Fundus and M&Ms benchmarks demonstrate that our approach consistently surpasses semi-supervised and domain adaptation methods, establishing a potential solution for mixed-domain semi-supervised medical image segmentation.

</details>


### [52] [VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents](https://arxiv.org/abs/2601.16973)
*Zirui Wang,Junyi Zhang,Jiaxin Ge,Long Lian,Letian Fu,Lisa Dunlap,Ken Goldberg,XuDong Wang,Ion Stoica,David M. Chan,Sewon Min,Joseph E. Gonzalez*

Main category: cs.CV

TL;DR: 本文提出了VisGym——一个包含17个环境的视觉-语言模型（VLM）评测与训练平台，用于评估VLM在多步视觉交互任务中的感知、记忆与动作整合能力；实验表明现有前沿模型在此类长时序交互任务中表现较差，揭示了其在长上下文利用、视觉化符号任务处理等方面的局限性，并验证了目标观测、文本反馈和探索性示范等策略对性能提升的有效性。


<details>
  <summary>Details</summary>
Motivation: 现代视觉-语言模型（VLMs）在多步视觉交互（涉及感知、记忆与动作长期协同）方面缺乏系统刻画与评测基准，亟需统一、可控、多样化的评测环境。

Method: 构建VisGym——一个包含17个多样化环境（涵盖符号谜题、真实图像理解、导航与操作）的Gymnasium式评测套件，支持调节难度、输入表示、规划步数与反馈机制；开发多步求解器生成结构化示范，支持监督微调；对前沿VLM进行系统性多步交互评测与消融分析。

Result: 所有前沿VLM在VisGym上表现不佳：易配置下成功率仅46.6%，难配置下仅26.0%；模型难以有效利用长上下文（无截断历史反而比截断窗口表现更差）；视觉化符号任务显著难于纯文本版本；而引入显式目标观测、文本反馈及探索性示范可带来一致性能提升。

Conclusion: VisGym揭示了当前VLM在多步视觉决策中的关键瓶颈，强调需在长程记忆建模、视觉-符号对齐、交互式学习范式等方面取得突破；所提出的改进策略为后续研究提供了明确方向。

Abstract: Modern Vision-Language Models (VLMs) remain poorly characterized in multi-step visual interactions, particularly in how they integrate perception, memory, and action over long horizons. We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback. We also provide multi-step solvers that generate structured demonstrations, enabling supervised finetuning. Our evaluations show that all frontier models struggle in interactive settings, achieving low success rates in both the easy (46.6%) and hard (26.0%) configurations. Our experiments reveal notable limitations: models struggle to effectively leverage long context, performing worse with an unbounded history than with truncated windows. Furthermore, we find that several text-based symbolic tasks become substantially harder once rendered visually. However, explicit goal observations, textual feedback, and exploratory demonstrations in partially observable or unknown-dynamics settings for supervised finetuning yield consistent gains, highlighting concrete failure modes and pathways for improving multi-step visual decision-making. Code, data, and models can be found at: https://visgym.github.io/.

</details>


### [53] [SyncLight: Controllable and Consistent Multi-View Relighting](https://arxiv.org/abs/2601.16981)
*David Serrano-Lozano,Anand Bhattad,Luis Herranz,Jean-François Lalonde,Javier Vazquez-Corral*

Main category: cs.CV

TL;DR: SyncLight 是首个支持多视角静态场景一致、参数化重打光的方法，通过多视角扩散Transformer实现单步高保真重打光，无需相机位姿信息即可零样本泛化到任意数量视角。


<details>
  <summary>Details</summary>
Motivation: 现有单视角重打光方法难以满足多摄像机广播、立体电影和虚拟制片等场景所需的严格多视角光照一致性要求。

Method: 提出基于多视角扩散Transformer的SyncLight方法，采用潜在桥匹配（latent bridge matching）训练策略，并构建包含合成与真实多视角数据的大规模混合数据集。

Result: SyncLight可在单次推理中实现整个多视角图像集的高保真重打光，且仅用图像对训练即可零样本泛化至任意视角数，无需相机姿态信息。

Conclusion: SyncLight为多视角捕获系统提供了实用、可控、一致的重打光工作流，突破了生成式方法在多视角光照一致性上的瓶颈。

Abstract: We present SyncLight, the first method to enable consistent, parametric relighting across multiple uncalibrated views of a static scene. While single-view relighting has advanced significantly, existing generative approaches struggle to maintain the rigorous lighting consistency essential for multi-camera broadcasts, stereoscopic cinema, and virtual production. SyncLight addresses this by enabling precise control over light intensity and color across a multi-view capture of a scene, conditioned on a single reference edit. Our method leverages a multi-view diffusion transformer trained using a latent bridge matching formulation, achieving high-fidelity relighting of the entire image set in a single inference step. To facilitate training, we introduce a large-scale hybrid dataset comprising diverse synthetic environments -- curated from existing sources and newly designed scenes -- alongside high-fidelity, real-world multi-view captures under calibrated illumination. Surprisingly, though trained only on image pairs, SyncLight generalizes zero-shot to an arbitrary number of viewpoints, effectively propagating lighting changes across all views, without requiring camera pose information. SyncLight enables practical relighting workflows for multi-view capture systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [54] [ChiEngMixBench: Evaluating Large Language Models on Spontaneous and Natural Chinese-English Code-Mixed Generation](https://arxiv.org/abs/2601.16217)
*Qingyan Yang,Tongxi Wang,Yunsheng Luo*

Main category: cs.CL

TL;DR: 本文提出了首个面向真实社区语境的中英混合（code-mixing）评测基准ChiEngMixBench，将代码混用建模为认知对齐问题，并提出自发性与自然性两个互补指标；实证表明该基准可有效区分模型性能，并发现模型隐式遵循人类语言学中的矩阵语言框架（MLF）理论，展现出术语分层策略。


<details>
  <summary>Details</summary>
Motivation: 现有工作将代码混用简化为翻译或可转换性问题，难以评估模型切换行为是否符合语境和人类惯例。

Method: 构建ChiEngMixBench基准，基于通用构造流程支持跨领域与双语对扩展；将代码混用建模为认知对齐问题，定义自发性（Spontaneity）与自然性（Naturalness）两个互补评估信号；结合实证分析与语言学理论（MLF）解释模型行为。

Result: 所提指标能系统区分不同模型的代码混用能力；发现多语言大模型隐式采用符合MLF理论的术语分层策略。

Conclusion: 代码混用应被视为认知对齐问题而非单纯转换任务；ChiEngMixBench为评估和理解多语言大模型在真实混用场景中的行为提供了新范式与可靠工具。

Abstract: Code-mixing is increasingly prevalent in interactions between humans and large language models, yet existing work often reduces it to a translation or convertibility problem, making it difficult to assess whether a model's switching behavior is context-appropriate and aligned with human conventions. We introduce ChiEngMixBench, the first benchmark designed to evaluate code-mixing ability in authentic community contexts, built upon a general construction pipeline that enables scalable dataset development across domains and bilingual pairs. ChiEngMixBench formulates code-mixing as a cognitive alignment problem, characterized by two complementary signals: Spontaneity and Naturalness. Empirical evaluation shows that our metrics can systematically distinguish code-mixing performance across models. Beyond benchmarking, we further uncover an implicitly emergent Terminology Layering Strategy, a phenomenon consistent with the Matrix Language Frame (MLF) theory, indicating structured cognitive alignment between multilingual large language models and human communication.

</details>


### [55] [M3Kang: Evaluating Multilingual Multimodal Mathematical Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.16218)
*Aleix Torres-Camps,Nathaniel Mitrani Hadida,Víctor Conchello Vendrell,Àlex Batlle Casellas,Arnau Padrés Masdemont,Jordi Ros-Giralt*

Main category: cs.CL

TL;DR: 本文介绍了M3Kang，首个大规模多语言、多模态数学推理数据集，基于国际袋鼠数学竞赛构建，涵盖108种语言和图表，用于评估视觉-语言模型（VLMs）在多语言数学推理上的能力，并发现当前模型在基础数学与图表推理上仍显著落后于人类表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）在多语言数学推理方面研究不足，尤其缺乏与人类表现的直接对比；需构建高质量、多语言、含图表的数学推理基准以推动该领域发展。

Method: 构建M3Kang数据集：源自袋鼠数学竞赛（覆盖90+国家、600万青少年），包含1747道按年级分级的多选题，翻译为108种语言，部分含解题必需图表；对闭源与开源SOTA VLMs进行系统评测，并结合68,000余名学生真实答题数据进行人机性能对比；探索多语言技术在多模态场景下的迁移有效性。

Result: 当前VLMs在基础数学与图表推理上表现较差；性能随语言覆盖率和模型规模提升，但不随年级升高而提升；多语言技术可有效迁移到多模态设置，带来显著性能增益；人类学生整体表现远超当前模型。

Conclusion: M3Kang填补了多语言多模态数学推理基准的空白，揭示了VLMs在该任务上的关键短板，验证了多语言建模对多模态推理的增益作用，并为后续研究提供了开源数据、代码与人机对比基准。

Abstract: Despite state-of-the-art vision-language models (VLMs) have demonstrated strong reasoning capabilities, their performance in multilingual mathematical reasoning remains underexplored, particularly when compared to human performance. To bridge this gap, we introduce M3Kang, the first massively multilingual, multimodal mathematical reasoning dataset for VLMs. It is derived from the Kangaroo Math Competition, the world's largest mathematics contest, which annually engages over six million participants under the age of 18 across more than 90 countries. M3Kang includes 1,747 unique multiple-choice problems organized by grade-level difficulty, with translations into 108 culturally diverse languages, some of them including diagrams essential for solving them. Using this dataset, we conduct extensive benchmarking on both closed- and open-source SOTA models. We observe that, despite recent advances, models still struggle with basic math and diagram-based reasoning, with performance scaling with language presence and model size, but not with grade level. We also find that multilingual techniques can be effectively extended to the multimodal setting, resulting in significant improvements over baseline approaches. Our analysis also incorporates performance data from over 68,000 students, enabling direct comparison with human performance. We are open-sourcing M3Kang, including the English-only subset M2Kang, along with the framework and codebase used to construct the dataset.

</details>


### [56] [GameTalk: Training LLMs for Strategic Conversation](https://arxiv.org/abs/2601.16276)
*Victor Conchello Vendrell,Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 本文提出了GameTalk框架，通过多轮对话训练大语言模型（LLM）进行战略决策，利用GRPO、DPO和STaR等细调方法结合全局交互奖励信号，显著提升了LLM在协调、谈判与对手建模等任务中的长期目标优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有工作多关注LLM在单步决策或静态动作预测上的表现，缺乏对长程对话中战略协调与长期目标优化的支持。

Method: 提出GameTalk框架，将GRPO、DPO和STaR等细调方法适配至多轮对话场景，使LLM能基于整段交互序列的全局奖励信号进行训练。

Result: 在一系列复杂博弈任务上验证了GameTalk的有效性，尤其在奖励塑形下性能显著优于基线模型，其中DPO效果最优。

Conclusion: 面向对话的细调是提升LLM在交互式环境中推理、协商与行动能力的重要路径。

Abstract: Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce \textbf{GameTalk}, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.

</details>


### [57] [Domain Specific Specialization in Low-Resource Settings: The Efficacy of Offline Response-Based Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2601.16219)
*Erdem Aslan,Pakize Erdoğmuş*

Main category: cs.CL

TL;DR: 本文提出了一种离线响应式知识蒸馏方法，通过高质量、结构化的小规模合成数据集（仅500行），在资源受限条件下显著提升大语言模型在专业领域的准确性（96.7%）与拒答能力，验证了数据质量与结构对齐比数据量更重要。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在通用任务上表现优异，但在处理其预训练中未涵盖的领域或机构特定知识时易产生幻觉；同时，现有方法常依赖大量计算资源，难以在硬件受限场景下部署专业化助手。

Method: 采用基于响应的知识蒸馏框架，对比三种数据策略：通用领域适配（15,000行）、非结构化知识注入（2,000行）和教师模型生成的上下文感知合成数据集（500行）；使用Unsloth库优化Qwen-2.5-7B学生模型，大幅降低GPU显存占用（40GB→16GB）。

Result: 500行上下文感知合成数据集在准确率（96.7%）和鲁棒拒答能力上显著优于更大规模的非结构化数据；而15,000行和2,000行数据仍存在持续幻觉问题。

Conclusion: 在低资源域适应场景中，数据质量与结构对齐比数据规模更关键，支持LIMA假设；该方法为轻量化、高精度专业化模型构建提供了可行路径。

Abstract: Large Language Models (LLMs) excel in general tasks but often struggle with hallucinations when handling domain-specific or institutional knowledge absent from their pre-training. We present an offline response-based knowledge distillation method that develops high-accuracy specialized assistants under constrained hardware resources. We evaluate three distinct data strategies: general domain adaptation (15,000 lines), unstructured knowledge injection (2,000 lines), and a context-aware synthetic dataset (500 lines) generated by a teacher model. To minimize computational costs, we utilize the Unsloth library to optimize the Qwen-2.5-7B student model, reducing NVIDIA A100 GPU memory requirements from 40 GB to 16 GB. Experimental results demonstrate that while larger unstructured datasets suffer from persistent hallucinations, the 500-line context-aware dataset achieves a 96.7% accuracy rate and robust rejection capability. These findings validate the LIMA hypothesis, showing that data quality and structural alignment are more critical than quantity for domain adaptation in low-resource settings.

</details>


### [58] [Towards Latent Diffusion Suitable For Text](https://arxiv.org/abs/2601.16220)
*Nesta Midavaine,Christian A. Naesseth,Grigory Bartosh*

Main category: cs.CL

TL;DR: 本文提出了神经流扩散模型（NFDM）用于语言生成，通过学习多变量前向过程，使连续扩散模型能直接应用于离散语言空间，在保持样本质量的同时显著缩小与自回归模型的似然差距。


<details>
  <summary>Details</summary>
Motivation: 提升语言扩散模型的采样速度和文本连贯性，克服现有方法在离散语言空间中应用连续扩散模型的困难。

Method: 提出神经流扩散模型（NFDM），学习数据驱动的多变量前向扩散过程，使前向过程与生成轨迹更适配语言建模任务。

Result: 在相同规模下显著缩小与自回归模型的似然差距，样本质量媲美先前的潜在扩散模型。

Conclusion: NFDM为将连续扩散模型有效应用于离散语言生成提供了简洁可行的新范式。

Abstract: Language diffusion models aim to improve sampling speed and coherence over autoregressive LLMs. We introduce Neural Flow Diffusion Models for language generation, an extension of NFDM that enables the straightforward application of continuous diffusion models to discrete state spaces. NFDM learns a multivariate forward process from the data, ensuring that the forward process and generative trajectory are a good fit for language modeling. Our model substantially reduces the likelihood gap with autoregressive models of the same size, while achieving sample quality comparable to that of previous latent diffusion models.

</details>


### [59] [Limits of n-gram Style Control for LLMs via Logit-Space Injection](https://arxiv.org/abs/2601.16224)
*Sami-ul Ahmed*

Main category: cs.CL

TL;DR: 本文提出了一种在解码时通过在logit空间注入n-gram风格先验来轻量级控制冻结大语言模型（LLM）写作风格的方法，但实验表明该方法仅在极窄参数范围内有效，整体上不如提示工程和LoRA。


<details>
  <summary>Details</summary>
Motivation: 现有个性化LLM的方法（如提示工程和LoRA）存在局限：提示难以捕捉复杂写作风格，LoRA则计算开销大；因此作者探索一种更轻量、无需训练的替代方案。

Method: 训练基于不同风格语料（如《堂吉诃德》、新闻标题、arXiv摘要）的1-3元n-gram模型，构建插值风格先验；在LLM生成时，将匹配上下文的各阶n-gram对数概率加权求和后注入logit，权重由超参lambda控制。

Result: 在TinyLlama-1.1B上仅在Don Quixote语料、lambda=0.1时观察到风格困惑度下降24.7%且基础模型困惑度改善51.4%；其余设置下（尤其多作者语料）均导致风格与流畅性下降，高lambda引发生成崩溃；JS散度与token重叠分析进一步验证其脆弱性。

Conclusion: logit空间注入n-gram风格先验虽轻量可调，但有效性高度依赖极低lambda且适用范围极窄，整体性能不及提示工程和LoRA，仅具有限理论价值。

Abstract: Large language models (LLMs) are typically personalized via prompt engineering or parameter-efficient fine-tuning such as LoRA. However, writing style can be difficult to distill into a single prompt, and LoRA fine-tuning requires computationally intensive training and infrastructure. We investigate a possible lightweight alternative: steering a frozen LLM with n-gram style priors injected in logit space at decoding time. We train an n-gram model on stylistically distinct corpora -- including Don Quixote, CNN/DailyMail news headlines, and arXiv abstracts -- constructing an interpolated 1-to-3-gram prior over next-token probabilities. During generation we modify the LLM's logits by adding a weighted sum of style log-probabilities from each n-gram order that matches the current context, scaled by a control parameter lambda in [0, 1].
  We sweep lambda and style corpora and report style perplexity under the n-gram model, base-model perplexity as a proxy for fluency, Jensen-Shannon (JS) divergence between the original and steered token distributions, and token-overlap statistics. On TinyLlama-1.1B we identify a single narrow regime (for the Don Quixote corpus at lambda=0.1) where style perplexity improves by 24.7% and base-model perplexity improves by 51.4% relative to the frozen model. Outside this regime, and for multi-author corpora such as CNN/DailyMail and arXiv abstracts, even small nonzero lambda values generally result in worse style and fluency, and larger lambda values lead to collapse with extreme perplexities and incoherent text. Logit-space injection of n-gram style priors provides lightweight, tunable style control, but it is fragile: it operates effectively only within a narrow range of low lambda values and is consistently outperformed by prompting and LoRA.

</details>


### [60] [Better as Generators Than Classifiers: Leveraging LLMs and Synthetic Data for Low-Resource Multilingual Classification](https://arxiv.org/abs/2601.16278)
*Branislav Pecher,Jan Cegin,Robert Belanec,Ivan Srba,Jakub Simko,Maria Bielikova*

Main category: cs.CL

TL;DR: 本文探讨了利用大型语言模型（LLMs）生成多语言合成数据，用于训练更小、更高效的模型，尤其在低资源语言场景下效果显著，表明LLM更适合作为‘教师’生成数据，而非直接作为分类器使用。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言中人工标注数据稀缺，需要有效方法提升小模型性能；LLM虽具多语言能力，但直接用作分类器成本高、效率低，因此探索其作为数据生成器的蒸馏潜力。

Method: 使用先进多语言LLM为11种语言、4个分类任务生成合成数据集，并分别用于小模型的微调、指令微调，或作为紧凑型LLM的上下文示例。

Result: 仅需少量合成数据，小模型即可在多语言（尤其是低资源语言）任务上超越原始大型生成模型；合成数据驱动的小模型表现稳健且高效。

Conclusion: LLM最有效的角色是作为数据生成器（教师），通过合成数据赋能更小、更高效的多语言模型，而非直接承担分类任务。

Abstract: Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train smaller models in low-resource scenarios where human-labelled data is scarce. In this work, we investigate whether these synthetic data generation capabilities can serve as a form of distillation, producing smaller models that perform on par with or even better than massive LLMs across languages and tasks. To this end, we use a state-of-the-art multilingual LLM to generate synthetic datasets covering 11 languages and 4 classification tasks. These datasets are then used to train smaller models via fine-tuning or instruction tuning, or as synthetic in-context examples for compact LLMs. Our experiments show that even small amounts of synthetic data enable smaller models to outperform the large generator itself, particularly in low-resource languages. Overall, the results suggest that LLMs are best utilised as generators (teachers) rather than classifiers, producing data that empowers smaller and more efficient multilingual models.

</details>


### [61] [Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition](https://arxiv.org/abs/2601.16711)
*Shanshan Liu,Noriki Nishida,Fei Cheng,Narumi Tokunaga,Rumana Ferdous Munne,Yuki Yamagata,Kouji Kozaki,Takehito Utsuro,Yuji Matsumoto*

Main category: cs.CL

TL;DR: 本文提出了一种面向未见概念泛化的评估框架，并探索了基于大语言模型的自动标注数据（ALD）在提及无关生物医学概念识别（MA-BCR）任务中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 解决因人工标注稀缺导致的在提及无关生物医学概念识别（MA-BCR）中对未见概念泛化能力不足的问题。

Method: 构建基于层次化概念索引和新指标的评估框架；设计面向任务的LLM自动生成自动标注数据（ALD）流程。

Result: 实验证明LLM生成的ALD虽不能完全替代人工标注，但能显著提升模型对未见概念的泛化能力，提供更广覆盖与结构知识。

Conclusion: ALD是一种有价值的补充资源，可有效增强MA-BCR模型在低资源场景下对未见概念的识别能力。

Abstract: Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical concept indices and novel metrics to measure generalization. Second, we explore LLM-based Auto-Labeled Data (ALD) as a scalable resource, creating a task-specific pipeline for its generation. Our research unequivocally shows that while LLM-generated ALD cannot fully substitute for manual annotations, it is a valuable resource for improving generalization, successfully providing models with the broader coverage and structural knowledge needed to approach recognizing unseen concepts. Code and datasets are available at https://github.com/bio-ie-tool/hi-ald.

</details>


### [62] [Generating Literature-Driven Scientific Theories at Scale](https://arxiv.org/abs/2601.16282)
*Peter Jansen,Peter Clark,Doug Downey,Daniel S. Weld*

Main category: cs.CL

TL;DR: 本文提出了一种从大规模科学文献中合成定性与定量理论的方法，相较于依赖大语言模型参数化知识的方法，该文献支持方法在匹配既有证据和预测后续研究结果方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前自动化科学发现主要集中于实验生成，而更高层次的理论构建系统仍被忽视；本文旨在填补这一空白，探索如何从海量文献中自动合成科学理论。

Method: 提出一种基于大规模科学文献（13.7k篇论文）合成理论（2.9k个）的方法，对比文献支撑生成与参数化知识生成、准确性导向与新颖性导向目标对理论性质的影响。

Result: 文献支持方法生成的理论在匹配已有证据和预测4.6k篇后续论文结果方面显著优于仅依赖LLM参数化记忆的方法。

Conclusion: 文献 grounding 是提升理论生成质量（兼顾准确性与预测力）的关键路径，为自动化理论构建提供了可行且可扩展的新范式。

Abstract: Contemporary automated scientific discovery has focused on agents for generating scientific experiments, while systems that perform higher-level scientific activities such as theory building remain underexplored. In this work, we formulate the problem of synthesizing theories consisting of qualitative and quantitative laws from large corpora of scientific literature. We study theory generation at scale, using 13.7k source papers to synthesize 2.9k theories, examining how generation using literature-grounding versus parametric knowledge, and accuracy-focused versus novelty-focused generation objectives change theory properties. Our experiments show that, compared to using parametric LLM memory for generation, our literature-supported method creates theories that are significantly better at both matching existing evidence and at predicting future results from 4.6k subsequently-written papers

</details>


### [63] [A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War](https://arxiv.org/abs/2601.16309)
*Dikshya Mohanty,Taisiia Sabadyn,Jelwin Rodrigues,Chenlu Wang,Abhishek Kalugade,Ritwik Banerjee*

Main category: cs.CL

TL;DR: 本文介绍了DNIPRO，一个涵盖2022年2月至2024年8月俄乌战争期间24.6万篇新闻文章的纵向多语种语料库，覆盖俄、乌、美、英、中五国11家媒体，含英、俄、中文三种语言，并具备丰富元数据与人工验证标注，旨在支持跨国家战时话语分析。


<details>
  <summary>Details</summary>
Motivation: 构建一个能系统分析战时跨国媒体叙事差异、框架策略与信息战机制的多语种、多视角新闻语料库，弥补现有资源在地缘政治视角覆盖与标注质量上的不足。

Method: 收集并整理246K篇新闻文章，覆盖五国十一媒体、三种语言；设计统一元数据方案；开展多类型人工标注（如立场、情感、主题框架、矛盾性）并进行严格质量评估；开展四项下游任务实验（立场检测、情感分析、主题框架、矛盾分析）。

Result: 实验证明DNIPRO能有效揭示不同媒体对同一冲突事件的极化解读，反映其背后地缘政治立场；各媒体构建出明显分化的‘现实版本’，印证了叙事分歧与信息战特征。

Conclusion: DNIPRO是一个具有独特地缘多样性与标注严谨性的基础性多语语料库，不仅推动计算新闻学研究，也为理解全球信息生态中冲突叙事的生成与演化提供了关键资源。

Abstract: We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages (English, Russian, and Mandarin Chinese). This multilingual resource features consistent and comprehensive metadata, and multiple types of annotation with rigorous human evaluations for downstream tasks relevant to systematic transnational analyses of contentious wartime discourse. DNIPRO's distinctive value lies in its inclusion of competing geopolitical perspectives, making it uniquely suited for studying narrative divergence, media framing, and information warfare. To demonstrate its utility, we include use case experiments using stance detection, sentiment analysis, topical framing, and contradiction analysis of major conflict events within the larger war. Our explorations reveal how outlets construct competing realities, with coverage exhibiting polarized interpretations that reflect geopolitical interests. Beyond supporting computational journalism research, DNIPRO provides a foundational resource for understanding how conflicting narratives emerge and evolve across global information ecosystems.

</details>


### [64] [Teaching and Evaluating LLMs to Reason About Polymer Design Related Tasks](https://arxiv.org/abs/2601.16312)
*Dikshya Mohanty,Mohammad Saqib Hasan,Syed Mostofa Monsur,Size Zheng,Benjamin Hsiao,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: 本文提出了PolyBench——一个大规模聚合物设计基准数据集（含125K+任务、13M+数据点），并结合知识增强的推理蒸馏方法训练小语言模型（7B–14B），使其在聚合物设计任务上超越同尺寸及部分闭源大模型。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型缺乏聚合物领域专业知识和相关能力，难以有效支持AI4Science中的聚合物设计任务。

Method: 构建PolyBench大规模聚合物设计基准数据集，并提出知识增强的思维链（CoT）推理蒸馏方法进行模型对齐；任务按难度递进组织，支持泛化性与诊断性评估。

Result: 基于PolyBench训练的7B–14B小语言模型在PolyBench测试集及其他聚合物基准上均显著优于同规模模型，甚至超越部分闭源前沿大模型。

Conclusion: 领域专用大规模基准与知识增强对齐方法可显著提升小模型在专业科学任务（如聚合物设计）上的性能，为AI4Science提供新范式。

Abstract: Research in AI4Science has shown promise in many science applications, including polymer design. However, current LLMs prove ineffective on this problem space because: (i) most models lack polymer-specific knowledge (ii) existing aligned models lack coverage of knowledge and capabilities relevant to polymer design. Addressing this, we introduce PolyBench, a large scale training and test benchmark dataset of more than 125K polymer design related tasks, leveraging a knowledge base of 13M+ data points obtained from experimental and synthetic sources to ensure broad coverage of polymers and their properties. For effective alignment using PolyBench, we introduce a knowledge-augmented reasoning distillation method that augments this dataset with structured CoT. Furthermore, tasks in PolyBench are organized from simple to complex analytical reasoning problems, enabling generalization tests and diagnostic probes across the problem space. Experiments show that small language models (SLMs), of 7B to 14B parameters, trained on PolyBench data outperform similar sized models, and even closed source frontier LLMs on PolyBench test dataset while demonstrating gains on other polymer benchmarks as well.

</details>


### [65] [Machine-Assisted Grading of Nationwide School-Leaving Essay Exams with LLMs and Statistical NLP](https://arxiv.org/abs/2601.16314)
*Andres Karjus,Kais Allkivi,Silvia Maine,Katarin Leppik,Krister Kruusmaa,Merilin Aruvee*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLM）在国家级毕业考试作文自动评分中的应用，基于爱沙尼亚两个全国性试测作文数据集，将LLM与统计NLP方法的评分结果与人工评分对比，结果表明自动化评分性能可媲美人类评分员，并具备低偏见、可控风险及生成细粒度反馈能力，支持人机协同、符合教育规范的高利害写作评估。


<details>
  <summary>Details</summary>
Motivation: 在大规模、限时阅卷场景（如全国性毕业考试）中，传统依赖人工的内容与论证维度评分效率低，亟需可靠、公平、合规的自动化评估方案。

Method: 基于官方课程标准构建评分量规，采用LLM和统计NLP方法对爱沙尼亚两个全国试测作文数据集进行自动评分，并与多人类评审小组评分结果对比；同时评估偏见、提示注入风险及LLM作为作答者的潜在问题。

Result: 自动评分结果与人类评分高度一致，落在人类评分区间内；系统能生成细粒度子分数并支持个性化反馈；在小语种（爱沙尼亚语）环境下仍保持稳健性与合规性。

Conclusion: 以量规为驱动、人类监督为保障的LLM辅助评分流程，可在国家层面、尤其数字化先进且语言资源有限的地区（如爱沙尼亚），安全、有效地支撑高利害写作评估，并满足教育与监管要求。

Abstract: Large language models (LLMs) enable rapid and consistent automated evaluation of open-ended exam responses, including dimensions of content and argumentation that have traditionally required human judgment. This is particularly important in cases where a large amount of exams need to be graded in a limited time frame, such as nation-wide graduation exams in various countries. Here, we examine the applicability of automated scoring on two large datasets of trial exam essays of two full national cohorts from Estonia. We operationalize the official curriculum-based rubric and compare LLM and statistical natural language processing (NLP) based assessments with human panel scores. The results show that automated scoring can achieve performance comparable to that of human raters and tends to fall within the human scoring range. We also evaluate bias, prompt injection risks, and LLMs as essay writers. These findings demonstrate that a principled, rubric-driven, human-in-the-loop scoring pipeline is viable for high-stakes writing assessment, particularly relevant for digitally advanced societies like Estonia, which is about to adapt a fully electronic examination system. Furthermore, the system produces fine-grained subscore profiles that can be used to generate systematic, personalized feedback for instruction and exam preparation. The study provides evidence that LLM-assisted assessment can be implemented at a national scale, even in a small-language context, while maintaining human oversight and compliance with emerging educational and regulatory standards.

</details>


### [66] [Regional Bias in Large Language Models](https://arxiv.org/abs/2601.16349)
*M P V S Gopinadh,Kappara Lakshmi Sindhu,Soma Sekhar Pandu Ranga Raju P,Yesaswini Swarna*

Main category: cs.CL

TL;DR: 本研究提出FAZE框架评估10个主流大语言模型的区域偏见，发现GPT-3.5偏见最强（9.5分），Claude 3.5 Sonnet最弱（2.5分），揭示地理偏见对AI公平性与跨文化应用可靠性的实质性影响。


<details>
  <summary>Details</summary>
Motivation: 区域偏见是AI公平性和全球代表性中的新兴关切，亟需系统评估与缓解。

Method: 构建包含100个中性情境强制选择提示的数据集，提出基于提示的FAZE评估框架，以10分制量化模型对不同地区的偏好倾向。

Result: 10个模型区域偏见差异显著：GPT-3.5得分最高（9.5），Claude 3.5 Sonnet最低（2.5）；区域偏见会实质性削弱LLM在跨文化场景下的可靠性、公平性与包容性。

Conclusion: 地理偏见是影响大语言模型实际部署的关键问题，需发展更具包容性的评估框架和系统性缓解策略。

Abstract: This study investigates regional bias in large language models (LLMs), an emerging concern in AI fairness and global representation. We evaluate ten prominent LLMs: GPT-3.5, GPT-4o, Gemini 1.5 Flash, Gemini 1.0 Pro, Claude 3 Opus, Claude 3.5 Sonnet, Llama 3, Gemma 7B, Mistral 7B, and Vicuna-13B using a dataset of 100 carefully designed prompts that probe forced-choice decisions between regions under contextually neutral scenarios. We introduce FAZE, a prompt-based evaluation framework that measures regional bias on a 10-point scale, where higher scores indicate a stronger tendency to favor specific regions. Experimental results reveal substantial variation in bias levels across models, with GPT-3.5 exhibiting the highest bias score (9.5) and Claude 3.5 Sonnet scoring the lowest (2.5). These findings indicate that regional bias can meaningfully undermine the reliability, fairness, and inclusivity of LLM outputs in real-world, cross-cultural applications. This work contributes to AI fairness research by highlighting the importance of inclusive evaluation frameworks and systematic approaches for identifying and mitigating geographic biases in language models.

</details>


### [67] [Identity, Cooperation and Framing Effects within Groups of Real and Simulated Humans](https://arxiv.org/abs/2601.16355)
*Suhong Moon,Minwoo Kang,Joseph Suh,Mustafa Safdari,John Canny*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLMs）如何在社会困境博弈中模拟人类行为，强调通过深度绑定基础模型与丰富叙事身份背景，提升对身份驱动行为的忠实再现能力，并验证其对时间、问题表述和参与者群体等情境因素的建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有工作多采用弱绑定（如提示工程）方式让聊天模型模拟人格，但难以准确复现人类基于身份和情境的复杂行为；本文旨在探索更忠实的人类行为模拟方法，以支持社会科学研究中对实验细节缺失问题的弥补。

Method: 采用深度绑定策略，将基础语言模型与扩展的叙事身份背景进行结合，并利用指令微调模型检验行为一致性；同时系统分析LLMs对时间、问题框架和参与者池等情境变量的建模能力。

Result: 相比弱绑定方法，使用丰富叙事身份背景进行条件化能显著提升LLM模拟行为与真实人类研究结果之间的一致性；LLMs可有效建模多种情境因素，揭示实验描述中常被忽略但影响结果的关键细节。

Conclusion: 深度绑定基础模型与叙事身份是提升LLM模拟人类社会行为保真度的有效路径，为社会科学实验的可复现性与因果机制探索提供了新工具。

Abstract: Humans act via a nuanced process that depends both on rational deliberation and also on identity and contextual factors. In this work, we study how large language models (LLMs) can simulate human action in the context of social dilemma games. While prior work has focused on "steering" (weak binding) of chat models to simulate personas, we analyze here how deep binding of base models with extended backstories leads to more faithful replication of identity-based behaviors. Our study has these findings: simulation fidelity vs human studies is improved by conditioning base LMs with rich context of narrative identities and checking consistency using instruction-tuned models. We show that LLMs can also model contextual factors such as time (year that a study was performed), question framing, and participant pool effects. LLMs, therefore, allow us to explore the details that affect human studies but which are often omitted from experiment descriptions, and which hamper accurate replication.

</details>


### [68] [PolyAgent: Large Language Model Agent for Polymer Design](https://arxiv.org/abs/2601.16376)
*Vani Nigam,Achuth Chandrasekhar,Amir Barati Farimani*

Main category: cs.CL

TL;DR: 本文提出了一种面向实验室研究人员的终端集成式闭环聚合物结构-性能预测框架，利用大语言模型（LLM）实现性能预测、性能引导的结构生成与修改，并结合合成可及性评分（SA Score）和合成复杂度评分（SC Score）确保生成结构的实验可行性。


<details>
  <summary>Details</summary>
Motivation: 实验室研究人员难以直接使用现有机器学习模型进行聚合物发现，受限于基础设施；传统实验试错法耗时耗力，亟需易用、可落地的计算工具支持早期聚合物研发。

Method: 构建基于LLM推理的终端闭环框架，支持SMILES格式聚合物结构的性能预测、性能导向生成与编辑；引入SA Score和SC Score约束生成过程，聚焦单体级、可合成结构。

Result: 实现了面向实验人员的轻量、易用、可解释的聚合物发现工具，在终端即可完成从性能需求到可合成结构的闭环探索。

Conclusion: 该框架弥合了AI模型与实验化学家之间的鸿沟，推动了可访问、可部署的聚合物智能发现范式。

Abstract: On-demand Polymer discovery is essential for various industries, ranging from biomedical to reinforcement materials. Experiments with polymers have a long trial-and-error process, leading to long procedures and extensive resources. For these processes, machine learning has accelerated scientific discovery at the property prediction and latent space search fronts. However, laboratory researchers cannot readily access codes and these models to extract individual structures and properties due to infrastructure limitations. We present a closed-loop polymer structure-property predictor integrated in a terminal for early-stage polymer discovery. The framework is powered by LLM reasoning to provide users with property prediction, property-guided polymer structure generation, and structure modification capabilities. The SMILES sequences are guided by the synthetic accessibility score and the synthetic complexity score (SC Score) to ensure that polymer generation is as close as possible to synthetically accessible monomer-level structures. This framework addresses the challenge of generating novel polymer structures for laboratory researchers, thereby providing computational insights into polymer research.

</details>


### [69] [Cross-Lingual Activation Steering for Multilingual Language Models](https://arxiv.org/abs/2601.16390)
*Rhitabrat Pokharel,Ameeta Agrawal,Tanay Nagar*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的推理时干预方法——跨语言激活引导（CLAS），通过选择性调节神经元激活来缩小大语言模型中主导语言与非主导语言之间的性能差距，并发现功能分化而非严格对齐更有利于跨语言迁移。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽具备较强的多语言能力，但在主导语言和非主导语言之间仍存在显著性能差距，先前研究认为这源于多语言表征中共享神经元与语言特异性神经元之间的不平衡。

Method: 提出Cross-Lingual Activation Steering（CLAS），一种无需训练、仅在推理阶段对神经元激活进行选择性调控的方法。

Result: 在分类和生成基准测试中，CLAS分别带来平均2.3%（准确率）和3.4%（F1值）的提升，同时保持高资源语言性能；发现有效跨语言迁移依赖于功能分化而非严格对齐，性能提升与语言簇分离度增强呈正相关。

Conclusion: 有针对性的激活引导可在不修改模型权重的前提下，释放现有大语言模型中潜在的多语言能力。

Abstract: Large language models exhibit strong multilingual capabilities, yet significant performance gaps persist between dominant and non-dominant languages. Prior work attributes this gap to imbalances between shared and language-specific neurons in multilingual representations. We propose Cross-Lingual Activation Steering (CLAS), a training-free inference-time intervention that selectively modulates neuron activations. We evaluate CLAS on classification and generation benchmarks, achieving average improvements of 2.3% (Acc.) and 3.4% (F1) respectively, while maintaining high-resource language performance. We discover that effective transfer operates through functional divergence rather than strict alignment; performance gains correlate with increased language cluster separation. Our results demonstrate that targeted activation steering can unlock latent multilingual capacity in existing models without modification to model weights.

</details>


### [70] [Cite-While-You-Generate: Training-Free Evidence Attribution for Multimodal Clinical Summarization](https://arxiv.org/abs/2601.16397)
*Qianqi Yan,Huy Nguyen,Sumana Srivatsa,Hari Bandi,Xin Eric Wang,Krishnaram Kenthapadi*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的生成时源归属框架，利用解码器注意力机制直接引用支持文本片段或图像，支持纯文本和多模态场景，在临床对话和放射报告数据集上显著提升了归属准确性。


<details>
  <summary>Details</summary>
Motivation: 可信的临床摘要生成不仅需要流畅的文本生成，还需透明地说明每句话的来源；现有后处理或需重训练的方法存在局限性。

Method: 提出一种训练-free的生成时源归属框架，利用decoder attentions进行直接引用；设计两种多模态归属策略：raw image mode（直接使用图像块注意力）和caption-as-span mode（用生成的图像描述替代图像，实现纯文本对齐）。

Result: 在CliConSummation和MIMIC-CXR两个数据集上，该方法在文本级和多模态归属准确率上均优于embedding-based和self-attribution基线（如F1提升15%）；caption-based方式性能接近raw-image attention，但更轻量实用。

Conclusion: 注意力引导的归属方法是迈向可解释、可部署临床摘要系统的重要一步。

Abstract: Trustworthy clinical summarization requires not only fluent generation but also transparency about where each statement comes from. We propose a training-free framework for generation-time source attribution that leverages decoder attentions to directly cite supporting text spans or images, overcoming the limitations of post-hoc or retraining-based methods. We introduce two strategies for multimodal attribution: a raw image mode, which directly uses image patch attentions, and a caption-as-span mode, which substitutes images with generated captions to enable purely text-based alignment. Evaluations on two representative domains: clinician-patient dialogues (CliConSummation) and radiology reports (MIMIC-CXR), show that our approach consistently outperforms embedding-based and self-attribution baselines, improving both text-level and multimodal attribution accuracy (e.g., +15% F1 over embedding baselines). Caption-based attribution achieves competitive performance with raw-image attention while being more lightweight and practical. These findings highlight attention-guided attribution as a promising step toward interpretable and deployable clinical summarization systems.

</details>


### [71] [Clarify or Answer: Reinforcement Learning for Agentic VQA with Context Under-specification](https://arxiv.org/abs/2601.16400)
*Zongwan Cao,Bingbing Wen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: 本文提出CoA（Clarify-or-Answer）框架，用于解决现实世界中依赖外部上下文的视觉问答（VQA）问题；它通过判断是否需要澄清、生成聚焦性澄清问题，并结合回答来提升准确性；在多个模型与数据集上平均提升VQA准确率15.3个百分点。


<details>
  <summary>Details</summary>
Motivation: 现实中的视觉问答常依赖图像外的上下文信息，而图像-问题对可能表述模糊，直接作答易导致高置信度错误答案。

Method: 提出CoA（Clarify-or-Answer）代理：先判断是否需澄清，若需则生成一个聚焦性澄清问题，再融合用户反馈作答；构建CONTEXTCLARIFY数据集（含模糊/非模糊VQA问题对比）；设计GRPO-CR强化学习方法，多目标优化澄清问题质量（形式规范、聚焦、非平凡、消歧有效）。

Result: 在三个视觉语言大模型和三个数据集上，CoA在模块级和系统级均取得一致提升，端到端VQA准确率平均提高+15.3分（相对提升83%）。

Conclusion: 显式建模‘提问或回答’决策并优化澄清过程，可显著提升上下文依赖型VQA鲁棒性与准确性，为开放世界VQA提供新范式。

Abstract: Real-world visual question answering (VQA) is often context-dependent: an image-question pair may be under-specified, such that the correct answer depends on external information that is not observable in the image. In such cases, directly answering can lead to confident but incorrect predictions. We propose CoA(Clarify-or-Answer), an ask-or-answer agent that separately models the decision to ask or answer, and what to ask if needed. CoA first determines whether clarification is necessary; if so, it asks a single focused question and then incorporates the response to produce the final answer. We introduce CONTEXTCLARIFY with a set of ambiguous VQA questions and the contrast set that is non-ambiguous. We further introduce GRPO-CR (Clarification Reasoning), a reinforcement learning approach that optimizes clarification question generation with multiple reward signals encouraging well-formed, focused, non-trivial questions that resolve ambiguity. Across three VLLMs and three datasets, CoA achieves consistent improvements at both the module and system levels, improving end-to-end VQA accuracy by an average of +15.3 points (83%) over prompting-based baselines

</details>


### [72] [Jacobian Scopes: token-level causal attributions in LLMs](https://arxiv.org/abs/2601.16407)
*Toni J. B. Liu,Baran Zadeoğlu,Nicolas Boullé,Raphaël Sarfati,Christopher J. Earls*

Main category: cs.CL

TL;DR: 本文提出Jacobian Scopes，一种基于梯度的token级因果归因方法，用于解释大语言模型（LLM）的预测机制，通过分析最终隐藏状态对输入的线性化关系，量化输入token对预测的影响；提出了三种变体（Semantic、Fisher、Temperature Scopes），分别关注特定logits敏感性、完整预测分布及模型置信度，并在指令理解、翻译和上下文学习等任务中验证其有效性，还揭示了隐含政治偏见等现象。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型结构复杂（多层、多注意力头），难以明确识别哪些前置token对当前预测影响最大，亟需可解释性强、细粒度的归因方法。

Method: 提出Jacobian Scopes系列方法，基于对最终隐藏状态关于输入token的雅可比矩阵分析，构建三种归因变体：Semantic Scope（针对特定logit的梯度敏感性）、Fisher Scope（针对整个预测分布的Fisher信息加权归因）、Temperature Scope（针对模型输出置信度/逆温度参数的归因）。

Result: 在指令理解、机器翻译和上下文学习等任务中成功定位关键影响token；发现模型隐含政治倾向等社会偏见；为上下文学习中的时序预测机制提供新解释视角。

Conclusion: Jacobian Scopes是一种有效、灵活且可扩展的token级归因工具，提升了LLM决策过程的透明性与可解释性，具备理论深度与实际应用价值。

Abstract: Large language models (LLMs) make next-token predictions based on clues present in their context, such as semantic descriptions and in-context examples. Yet, elucidating which prior tokens most strongly influence a given prediction remains challenging due to the proliferation of layers and attention heads in modern architectures. We propose Jacobian Scopes, a suite of gradient-based, token-level causal attribution methods for interpreting LLM predictions. By analyzing the linearized relations of final hidden state with respect to inputs, Jacobian Scopes quantify how input tokens influence a model's prediction. We introduce three variants - Semantic, Fisher, and Temperature Scopes - which respectively target sensitivity of specific logits, the full predictive distribution, and model confidence (inverse temperature). Through case studies spanning instruction understanding, translation and in-context learning (ICL), we uncover interesting findings, such as when Jacobian Scopes point to implicit political biases. We believe that our proposed methods also shed light on recently debated mechanisms underlying in-context time-series forecasting. Our code and interactive demonstrations are publicly available at https://github.com/AntonioLiu97/JacobianScopes.

</details>


### [73] [Learning Domain Knowledge in Multimodal Large Language Models through Reinforcement Fine-Tuning](https://arxiv.org/abs/2601.16419)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CL

TL;DR: 本文发现文本层面的领域知识注入对科学多模态任务效果甚微，提出一种将领域知识编码为约束和奖励信号的强化微调框架，在遥感和医学影像领域显著提升MLLM性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）在遥感、医学影像等专业领域表现有限，而传统通过文本提示或字幕注入领域知识的方法效果不佳，表明模型难以仅靠语言输入内化领域先验，需在优化层面融入领域知识。

Method: 提出一种强化微调框架，将领域知识编码为领域感知的约束条件和奖励信号，直接嵌入学习目标，在输出空间中引导模型行为，而非仅作为输入描述信息。

Result: 在多个遥感与医学影像数据集上实验表明，该方法带来显著性能提升，并在多模态领域任务上达到SOTA水平。

Conclusion: 优化层面的领域知识集成是必要的；当前MLLMs存在文本层面领域条件化能力的根本局限。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities in multimodal perception and understanding tasks. However, their effectiveness in specialized domains, such as remote sensing and medical imaging, remains limited. A natural approach to domain adaptation is to inject domain knowledge through textual instructions, prompts, or auxiliary captions. Surprisingly, we find that such input-level domain knowledge injection yields little to no improvement on scientific multimodal tasks, even when the domain knowledge is explicitly provided. This observation suggests that current MLLMs fail to internalize domain-specific priors through language alone, and that domain knowledge must be integrated at the optimization level. Motivated by this insight, we propose a reinforcement fine-tuning framework that incorporates domain knowledge directly into the learning objective. Instead of treating domain knowledge as descriptive information, we encode it as domain-informed constraints and reward signals, shaping the model's behavior in the output space. Extensive experiments across multiple datasets in remote sensing and medical domains consistently demonstrate good performance gains, achieving state-of-the-art results on multimodal domain tasks. Our results highlight the necessity of optimization-level domain knowledge integration and reveal a fundamental limitation of textual domain conditioning in current MLLMs.

</details>


### [74] [Exploring the Effects of Alignment on Numerical Bias in Large Language Models](https://arxiv.org/abs/2601.16444)
*Ayako Sato,Hwichan Kim,Zhousi Chen,Masato Mita,Mamoru Komachi*

Main category: cs.CL

TL;DR: 本文研究了LLM-as-a-judge中评估者大模型存在的数值偏差问题，发现对齐（alignment）是其主要原因，并提出包括分数范围调整在内的多种缓解策略，其中分数范围调整最有效。


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-judge在评估任务中广泛应用，但 evaluator LLM 存在数值偏差，影响评估性能；作者试图探究该偏差的成因并提出缓解方法。

Method: 通过对比对齐前后的LLM输出验证对齐导致数值偏差的假设，并尝试温度缩放、分布校准和分数范围调整等缓解策略。

Result: 确认对齐显著加剧数值偏差；在多种缓解策略中，分数范围调整最有效，能降低偏差并提升评估性能，但仍属启发式方法。

Conclusion: 对齐是LLM-as-a-judge中数值偏差的主要成因；需进一步研究最优分数范围选择及更鲁棒的缓解策略。

Abstract: ``LLM-as-a-judge,'' which utilizes large language models (LLMs) as evaluators, has proven effective in many evaluation tasks. However, evaluator LLMs exhibit numerical bias, a phenomenon where certain evaluation scores are generated disproportionately often, leading reduced evaluation performance. This study investigates the cause of this bias. Given that most evaluator LLMs are aligned through instruction tuning and preference tuning, and that prior research suggests alignment reduces output diversity, we hypothesize that numerical bias arises from alignment. To test this, we compare outputs from pre- and post-alignment LLMs, and observe that alignment indeed increases numerical bias. We also explore mitigation strategies for post-alignment LLMs, including temperature scaling, distribution calibration, and score range adjustment. Among these, score range adjustment is most effective in reducing bias and improving performance, though still heuristic. Our findings highlight the need for further work on optimal score range selection and more robust mitigation strategies.

</details>


### [75] [Mixing Expert Knowledge: Bring Human Thoughts Back To the Game of Go](https://arxiv.org/abs/2601.16447)
*Yichuan Ma,Linyang Li,Yongkang Chen,Peiji Li,Jiasheng Ye,Qipeng Guo,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出LoGos模型，通过混合微调与强化学习，将大型语言模型（LLMs）的通用推理能力与围棋领域专家知识结合，在自然语言围棋推理和落子预测上达到人类职业选手水平，显著超越现有LLM，并开源首个大规模围棋训练数据集、评测基准及模型。


<details>
  <summary>Details</summary>
Motivation: 主流大语言模型在专业领域（如围棋）表现远逊于领域专家，限制了其在垂直任务中的应用；需弥合通用推理能力与领域专业知识之间的鸿沟。

Method: 采用结构化围棋专业知识与通用长链思维（CoT）数据进行混合微调作为冷启动，再通过强化学习融合围棋专家知识与通用推理能力。

Result: LoGos在自然语言围棋策略推理和准确落子预测上达到人类职业选手水平，大幅超越所有现有LLM；并开源首个大规模围棋LLM训练数据集、首个LLM围棋评测基准及首个职业级围棋LLM。

Conclusion: 证明了通过合理融合领域专家知识与通用推理训练范式，可显著提升LLM在高度专业化任务上的性能，为LLM向垂直领域拓展提供了可行路径与重要实践范例。

Abstract: Large language models (LLMs) have demonstrated exceptional performance in reasoning tasks such as mathematics and coding, matching or surpassing human capabilities. However, these impressive reasoning abilities face significant challenges in specialized domains. Taking Go as an example, although AlphaGo has established the high performance ceiling of AI systems in Go, mainstream LLMs still struggle to reach even beginner-level proficiency, let alone perform natural language reasoning. This performance gap between general-purpose LLMs and domain experts is significantly limiting the application of LLMs on a wider range of domain-specific tasks. In this work, we aim to bridge the divide between LLMs' general reasoning capabilities and expert knowledge in domain-specific tasks. We perform mixed fine-tuning with structured Go expertise and general long Chain-of-Thought (CoT) reasoning data as a cold start, followed by reinforcement learning to integrate expert knowledge in Go with general reasoning capabilities. Through this methodology, we present \textbf{LoGos}, a powerful LLM that not only maintains outstanding general reasoning abilities, but also conducts Go gameplay in natural language, demonstrating effective strategic reasoning and accurate next-move prediction. LoGos achieves performance comparable to human professional players, substantially surpassing all existing LLMs. Through this work, we aim to contribute insights on applying general LLM reasoning capabilities to specialized domains. We will release the first large-scale Go dataset for LLM training, the first LLM Go evaluation benchmark, and the first general LLM that reaches human professional-level performance in Go at: https://github.com/Entarochuan/LoGos.

</details>


### [76] [Graph-Anchored Knowledge Indexing for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.16462)
*Zhenghao Liu,Mingyan Wu,Xinze Li,Yukun Yan,Shuo Wang,Cheng Yang,Minghe Yu,Zheni Zeng,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出GraphAnchor，一种基于图锚定的知识索引方法，通过在迭代检索中动态构建和更新知识图谱，增强RAG系统对多跳问答中分散关键信息的整合与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统难以有效整合和解读跨噪声文档的分散关键证据，导致知识利用不足和推理不准确。

Method: GraphAnchor将图结构从静态知识表示重构为动态演化的知识索引，在迭代检索过程中增量式构建图，锚定显著实体与关系，并利用最终图与所有检索文档联合生成答案。

Result: 在四个多跳问答基准上验证了GraphAnchor的有效性，实验表明其能调节LLM注意力，更有效地关联跨文档的关键信息。

Conclusion: GraphAnchor通过图锚定机制显著提升了RAG系统在复杂推理任务中的知识整合与生成质量，为动态知识索引提供了新范式。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a dominant paradigm for mitigating hallucinations in Large Language Models (LLMs) by incorporating external knowledge. Nevertheless, effectively integrating and interpreting key evidence scattered across noisy documents remains a critical challenge for existing RAG systems. In this paper, we propose GraphAnchor, a novel Graph-Anchored Knowledge Indexing approach that reconceptualizes graph structures from static knowledge representations into active, evolving knowledge indices. GraphAnchor incrementally updates a graph during iterative retrieval to anchor salient entities and relations, yielding a structured index that guides the LLM in evaluating knowledge sufficiency and formulating subsequent subqueries. The final answer is generated by jointly leveraging all retrieved documents and the final evolved graph. Experiments on four multi-hop question answering benchmarks demonstrate the effectiveness of GraphAnchor, and reveal that GraphAnchor modulates the LLM's attention to more effectively associate key information distributed in retrieved documents. All code and data are available at https://github.com/NEUIR/GraphAnchor.

</details>


### [77] [Persona Jailbreaking in Large Language Models](https://arxiv.org/abs/2601.16466)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文提出PHISH框架，首次揭示了大语言模型（LLM）在黑盒、仅推理设置下可通过用户输入的历史对话隐式诱导并篡改其人格特征的新安全漏洞；该攻击在教育、心理健康和客服等高风险领域仍有效，且对模型推理能力影响甚微。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了对抗性对话历史单独重塑LLM人格的可能性，黑盒人格操纵尚未被探索，而稳定人格对教育、心理支持等关键应用至关重要。

Method: 提出‘人格编辑’新任务，设计PHISH框架：通过在用户查询中嵌入语义丰富线索，渐进式诱导反向人格；定义量化攻击成功率的指标，并在3个基准、8个LLM上评估。

Result: PHISH可在多轮对话中稳定改变目标人格，引发相关特质的连带变化；在心理健康、辅导、客服等高风险场景中经人类与LLM-as-Judge双重验证有效；仅轻微降低推理性能。

Conclusion: PHISH暴露了LLM人格表征的脆弱性，当前防护机制在持续攻击下依然脆弱，亟需构建上下文鲁棒的人格保持机制。

Abstract: Large Language Models (LLMs) are increasingly deployed in domains such as education, mental health and customer support, where stable and consistent personas are critical for reliability. Yet, existing studies focus on narrative or role-playing tasks and overlook how adversarial conversational history alone can reshape induced personas. Black-box persona manipulation remains unexplored, raising concerns for robustness in realistic interactions. In response, we introduce the task of persona editing, which adversarially steers LLM traits through user-side inputs under a black-box, inference-only setting. To this end, we propose PHISH (Persona Hijacking via Implicit Steering in History), the first framework to expose a new vulnerability in LLM safety that embeds semantically loaded cues into user queries to gradually induce reverse personas. We also define a metric to quantify attack success. Across 3 benchmarks and 8 LLMs, PHISH predictably shifts personas, triggers collateral changes in correlated traits, and exhibits stronger effects in multi-turn settings. In high-risk domains mental health, tutoring, and customer support, PHISH reliably manipulates personas, validated by both human and LLM-as-Judge evaluations. Importantly, PHISH causes only a small reduction in reasoning benchmark performance, leaving overall utility largely intact while still enabling significant persona manipulation. While current guardrails offer partial protection, they remain brittle under sustained attack. Our findings expose new vulnerabilities in personas and highlight the need for context-resilient persona in LLMs. Our codebase and dataset is available at: https://github.com/Jivnesh/PHISH

</details>


### [78] [DeepEra: A Deep Evidence Reranking Agent for Scientific Retrieval-Augmented Generated Question Answering](https://arxiv.org/abs/2601.16478)
*Haotian Chen,Qingqing Long,Siyu Pu,Xiao Luo,Wei Ju,Meng Xiao,Yuanchun Zhou,Jianghua Zhao,Xuezhi Wang*

Main category: cs.CL

TL;DR: 本文提出DeepEra方法，通过逐步推理重排序候选段落，解决科学问答中语义相似但逻辑无关（SSLI）的问题，并构建了SciRAG-SSLI数据集进行系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有检索与重排序方法易受语义相似但逻辑无关的段落干扰，导致事实可靠性下降和幻觉增强。

Method: 提出Deep Evidence Reranking Agent（DeepEra），融合逐步推理机制，超越表层语义进行更精准的段落评估；并构建大规模SciRAG-SSLI数据集（约30万实例），含自然检索上下文与系统生成干扰项。

Result: 在多个指标上显著优于当前主流重排序器，验证了DeepEra对SSLI问题的有效缓解。

Conclusion: 首次全面研究并实证验证了两阶段RAG框架中不可忽视的SSLI问题，为提升科学问答的事实准确性提供了新思路与基准资源。

Abstract: With the rapid growth of scientific literature, scientific question answering (SciQA) has become increasingly critical for exploring and utilizing scientific knowledge. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating knowledge from external sources, thereby providing credible evidence for scientific question answering. But existing retrieval and reranking methods remain vulnerable to passages that are semantically similar but logically irrelevant, often reducing factual reliability and amplifying hallucinations.To address this challenge, we propose a Deep Evidence Reranking Agent (DeepEra) that integrates step-by-step reasoning, enabling more precise evaluation of candidate passages beyond surface-level semantics. To support systematic evaluation, we construct SciRAG-SSLI (Scientific RAG - Semantically Similar but Logically Irrelevant), a large-scale dataset comprising about 300K SciQA instances across 10 subjects, constructed from 10M scientific corpus. The dataset combines naturally retrieved contexts with systematically generated distractors to test logical robustness and factual grounding. Comprehensive evaluations confirm that our approach achieves superior retrieval performance compared to leading rerankers. To our knowledge, this work is the first to comprehensively study and empirically validate innegligible SSLI issues in two-stage RAG frameworks.

</details>


### [79] [TL-GRPO: Turn-Level RL for Reasoning-Guided Iterative Optimization](https://arxiv.org/abs/2601.16480)
*Peiji Li,Linyang Li,Handa Sun,Wenjin Mai,Yongkang Chen,Xiaozhe Li,Yue Shen,Yichuan Ma,Yiliu Sun,Jiaxi Cao,Zhishu He,Bo Wang,Xiaoqing Zheng,Zhaori Bi,Xipeng Qiu,Qipeng Guo,Kai Chen,Dahua Lin*

Main category: cs.CL

TL;DR: 本文提出了一种名为Turn-Level GRPO（TL-GRPO）的轻量级强化学习算法，用于解决迭代优化类推理任务中现有方法（如标准GRPO和黑箱优化）无法兼顾细粒度轮次级优化与先验知识利用的问题；在模拟预算受限的模拟电路尺寸设计（ACS）任务上验证了其优越性，并实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的轨迹级强化学习方法难以处理迭代优化任务——这类任务中环境状态跨轮次不变、奖励取决于最优单轮表现而非累积回报；而黑箱优化方法又无法利用大模型已有的推理能力与领域知识。

Method: 提出Turn-Level GRPO（TL-GRPO），采用轮次级分组采样机制，在保持语言模型推理能力的同时实现细粒度的每轮优化；将该方法应用于需多轮仿真与领域知识的模拟电路尺寸设计（ACS）任务。

Result: TL-GRPO在ACS任务上显著优于标准GRPO和贝叶斯优化；30B规模模型在相同仿真预算下达到当前最优（SOTA）性能，展现出强泛化性与实用价值。

Conclusion: TL-GRPO有效弥合了强化学习与黑箱优化在迭代优化任务中的关键缺陷，为大模型驱动的科学计算与工程优化提供了新范式。

Abstract: Large language models have demonstrated strong reasoning capabilities in complex tasks through tool integration, which is typically framed as a Markov Decision Process and optimized with trajectory-level RL algorithms such as GRPO. However, a common class of reasoning tasks, iterative optimization, presents distinct challenges: the agent interacts with the same underlying environment state across turns, and the value of a trajectory is determined by the best turn-level reward rather than cumulative returns. Existing GRPO-based methods cannot perform fine-grained, turn-level optimization in such settings, while black-box optimization methods discard prior knowledge and reasoning capabilities. To address this gap, we propose Turn-Level GRPO (TL-GRPO), a lightweight RL algorithm that performs turn-level group sampling for fine-grained optimization. We evaluate TL-GRPO on analog circuit sizing (ACS), a challenging scientific optimization task requiring multiple simulations and domain expertise. Results show that TL-GRPO outperforms standard GRPO and Bayesian optimization methods across various specifications. Furthermore, our 30B model trained with TL-GRPO achieves state-of-the-art performance on ACS tasks under same simulation budget, demonstrating both strong generalization and practical utility.

</details>


### [80] [Timely Machine: Awareness of Time Makes Test-Time Scaling Agentic](https://arxiv.org/abs/2601.16486)
*Yichuan Ma,Linyang Li,Yongkang chen,Peiji Li,Xiaozhe Li,Qipeng Guo,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出Timely Machine框架，将测试时扩展重新定义为基于真实时间（wall-clock time）的动态策略调整，并设计Timely-Eval基准和Timely-RL方法，使模型能根据时间预算自适应推理，显著提升工具调用密集型场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于生成长度的测试时扩展在智能体（agentic）场景中失效，因工具调用延迟使推理时间与生成长度解耦；现有模型缺乏对时间预算的感知与适应能力。

Method: 提出Timely Machine框架，定义测试时为真实时间；构建涵盖高频/低频工具调用与时间约束推理的Timely-Eval基准；提出Timely-RL方法：先监督微调冷启动，再通过强化学习优化时间感知的推理规划。

Result: 实验表明：小模型在低延迟下靠高频交互胜出，大模型在高延迟下靠高质量交互占优；Timely-RL显著提升模型对时间预算的感知与Timely-Eval各项任务性能。

Conclusion: 测试时扩展应转向以真实时间为标尺的动态策略调控；Timely-RL为面向工具调用的智能体时代提供了可扩展、自适应的时间感知推理新范式。

Abstract: As large language models (LLMs) increasingly tackle complex reasoning tasks, test-time scaling has become critical for enhancing capabilities. However, in agentic scenarios with frequent tool calls, the traditional generation-length-based definition breaks down: tool latency decouples inference time from generation length. We propose Timely Machine, redefining test-time as wall-clock time, where models dynamically adjust strategies based on time budgets. We introduce Timely-Eval, a benchmark spanning high-frequency tool calls, low-frequency tool calls, and time-constrained reasoning. By varying tool latency, we find smaller models excel with fast feedback through more interactions, while larger models dominate high-latency settings via superior interaction quality. Moreover, existing models fail to adapt reasoning to time budgets. We propose Timely-RL to address this gap. After cold-start supervised fine-tuning, we use reinforcement learning to enhance temporal planning. Timely-RL improves time budget awareness and consistently boosts performance across Timely-Eval. We hope our work offers a new perspective on test-time scaling for the agentic era.

</details>


### [81] [MRAG: Benchmarking Retrieval-Augmented Generation for Bio-medicine](https://arxiv.org/abs/2601.16503)
*Wei Zhu*

Main category: cs.CL

TL;DR: 本文提出了医学检索增强生成（MRAG）基准和配套工具包，用于系统评估RAG在中英文医疗问答任务中的性能，并分析了检索方法、模型规模和提示策略对效果的影响。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏面向医疗领域的全面RAG评估基准，限制了其在科学与临床问答系统中的可靠应用。

Method: 构建覆盖中英文的MRAG基准（基于Wikipedia和PubMed），开发MRAG-Toolkit支持RAG各组件的系统性实验，并开展多维度性能分析。

Result: RAG提升了大语言模型在医疗任务中的可靠性；性能受检索方法、模型大小和提示策略显著影响；虽提升有用性和推理质量，但长问题下可读性略有下降。

Conclusion: MRAG为医疗RAG研究提供了标准化评估平台和开源工具，推动学术界与工业界在该方向的发展与应用。

Abstract: While Retrieval-Augmented Generation (RAG) has been swiftly adopted in scientific and clinical QA systems, a comprehensive evaluation benchmark in the medical domain is lacking. To address this gap, we introduce the Medical Retrieval-Augmented Generation (MRAG) benchmark, covering various tasks in English and Chinese languages, and building a corpus with Wikipedia and Pubmed. Additionally, we develop the MRAG-Toolkit, facilitating systematic exploration of different RAG components. Our experiments reveal that: (a) RAG enhances LLM reliability across MRAG tasks. (b) the performance of RAG systems is influenced by retrieval approaches, model sizes, and prompting strategies. (c) While RAG improves usefulness and reasoning quality, LLM responses may become slightly less readable for long-form questions. We will release the MRAG-Bench's dataset and toolkit with CCBY-4.0 license upon acceptance, to facilitate applications from both academia and industry.

</details>


### [82] [LOGICAL-COMMONSENSEQA: A Benchmark for Logical Commonsense Reasoning](https://arxiv.org/abs/2601.16504)
*Obed Junias,Maria Leonor Pacheco*

Main category: cs.CL

TL;DR: 本文提出LOGICAL-COMMONSENSEQA基准，将常识推理重构为基于成对原子陈述与真值级逻辑算子（AND/OR/NEITHER/NOR）的组合推理任务，揭示现有模型在否定类推理上的显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有常识推理基准多采用单标签评估，无法刻画多个解释之间的逻辑关系（如联合合理、互斥或联合不合理），限制了对模型组合推理能力的评估。

Method: 构建LOGICAL-COMMONSENSEQA基准，将常识推理建模为对成对原子陈述进行AND/OR/NEITHER/NOR等逻辑组合的真值判断；在零样本、少样本及思维链提示下评测多种主流大模型。

Result: 模型在合取（AND）推理上表现尚可，析取（OR）推理中等，但在基于否定（NEITHER/NOR）的推理上性能急剧下降。

Conclusion: LOGICAL-COMMONSENSEQA揭示了当前模型在逻辑组合常识推理，尤其是否定推理方面的根本性局限，为后续研究提供了可控、可分解的评估框架。

Abstract: Commonsense reasoning often involves evaluating multiple plausible interpretations rather than selecting a single atomic answer, yet most benchmarks rely on single-label evaluation, obscuring whether statements are jointly plausible, mutually exclusive, or jointly implausible. We introduce LOGICAL-COMMONSENSEQA, a benchmark that re-frames commonsense reasoning as logical composition over pairs of atomic statements using plausibility-level operators (AND, OR, NEITHER/NOR). Evaluating instruction-tuned, reasoning-specialized, and fine-tuned models under zero-shot, few-shot, and chain-of-thought prompting, we find that while models perform reasonably on conjunctive and moderately on disjunctive reasoning, performance degrades sharply on negation-based questions. LOGICAL-COMMONSENSEQA exposes fundamental reasoning limitations and provides a controlled framework for advancing compositional commonsense reasoning.

</details>


### [83] [Is Length Really A Liability? An Evaluation of Multi-turn LLM Conversations using BoolQ](https://arxiv.org/abs/2601.16508)
*Karl Neergaard,Le Qiu,Emmanuele Chersoni*

Main category: cs.CL

TL;DR: 本文指出单轮提示评估无法捕捉真实对话中可能出现的危害，通过在BoolQ数据集上对多个大语言模型进行多轮对话测试，发现对话长度和提示结构会影响模型回答的真实性，揭示了静态评估的局限性。


<details>
  <summary>Details</summary>
Motivation: 单轮提示评估无法反映真实对话场景中的潜在危害，需要探索多轮对话对模型性能的影响。

Method: 在BoolQ数据集上，对三个不同的大语言模型，在不同对话长度和提示结构（scaffolding）条件下进行评估。

Result: 发现了模型特定的脆弱性，这些脆弱性在单轮测试中无法被发现；对话长度和提示结构显著影响响应真实性。

Conclusion: 静态单轮评估存在根本性局限，部署相关漏洞仅在多轮对话设置中显现，应加强多轮对话场景下的模型安全评估。

Abstract: Single-prompt evaluations dominate current LLM benchmarking, yet they fail to capture the conversational dynamics where real-world harm occurs. In this study, we examined whether conversation length affects response veracity by evaluating LLM performance on the BoolQ dataset under varying length and scaffolding conditions. Our results across three distinct LLMs revealed model-specific vulnerabilities that are invisible under single-turn testing. The length-dependent and scaffold-specific effects we observed demonstrate a fundamental limitation of static evaluations, as deployment-relevant vulnerabilities could only be spotted in a multi-turn conversational setting.

</details>


### [84] [SearchLLM: Detecting LLM Paraphrased Text by Measuring the Similarity with Regeneration of the Candidate Source via Search Engine](https://arxiv.org/abs/2601.16512)
*Hoang-Quoc Nguyen-Son,Minh-Son Dao,Koji Zettsu*

Main category: cs.CL

TL;DR: 本文提出SearchLLM方法，利用搜索引擎定位原文来源，通过比对输入文本与候选源再生文本的相似性，识别大语言模型（LLM）生成的改写文本，并作为代理层提升现有检测器性能。


<details>
  <summary>Details</summary>
Motivation: LLM改写可能导致原意丢失或扭曲，且其类人质量使传统检测方法失效，尤其在改写高度模仿原文时。

Method: 提出SearchLLM方法，将待测文本提交至搜索引擎获取候选原文，再比对原文与LLM再生文本的相似性；设计为可插拔代理层，兼容现有检测器。

Result: 在多种LLM上实验表明，SearchLLM显著提升现有检测器对高保真LLM改写文本的识别准确率，并能有效抵御改写攻击。

Conclusion: SearchLLM是一种有效、通用且可集成的LLM改写文本检测新范式，弥补了现有方法在高保真改写场景下的不足。

Abstract: With the advent of large language models (LLMs), it has become common practice for users to draft text and utilize LLMs to enhance its quality through paraphrasing. However, this process can sometimes result in the loss or distortion of the original intended meaning. Due to the human-like quality of LLM-generated text, traditional detection methods often fail, particularly when text is paraphrased to closely mimic original content. In response to these challenges, we propose a novel approach named SearchLLM, designed to identify LLM-paraphrased text by leveraging search engine capabilities to locate potential original text sources. By analyzing similarities between the input and regenerated versions of candidate sources, SearchLLM effectively distinguishes LLM-paraphrased content. SearchLLM is designed as a proxy layer, allowing seamless integration with existing detectors to enhance their performance. Experimental results across various LLMs demonstrate that SearchLLM consistently enhances the accuracy of recent detectors in detecting LLM-paraphrased text that closely mimics original content. Furthermore, SearchLLM also helps the detectors prevent paraphrasing attacks.

</details>


### [85] [Curate-Train-Refine: A Closed-Loop Agentic Framework for Zero Shot Classification](https://arxiv.org/abs/2601.16530)
*Gaurav Maheshwari,Kevin El Haddad*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLM）动态生成监督信号来训练轻量级文本分类器的方法，通过迭代的闭环数据生成与评估，显著提升零/少样本分类性能，同时降低推理开销。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和高容量编码器虽提升了零样本和少样本分类性能，但其高昂的推理成本和延迟限制了实际部署。

Method: 采用迭代式、具身代理（agentic）循环：LLM负责筛选训练数据、分析轻量级分类器的错误，并生成针对性修正样本；该闭环过程持续优化数据质量并适配下游任务和模型。

Result: 在四个主流基准上，该方法持续超越标准零样本和少样本基线。

Conclusion: LLM可有效作为数据策展者，在不部署大模型的前提下实现高精度、高效率的文本分类。

Abstract: Large language models (LLMs) and high-capacity encoders have advanced zero and few-shot classification, but their inference cost and latency limit practical deployment. We propose training lightweight text classifiers using dynamically generated supervision from an LLM. Our method employs an iterative, agentic loop in which the LLM curates training data, analyzes model successes and failures, and synthesizes targeted examples to address observed errors. This closed-loop generation and evaluation process progressively improves data quality and adapts it to the downstream classifier and task. Across four widely used benchmarks, our approach consistently outperforms standard zero and few-shot baselines. These results indicate that LLMs can serve effectively as data curators, enabling accurate and efficient classification without the operational cost of large-model deployment.

</details>


### [86] [Retrieve-Refine-Calibrate: A Framework for Complex Claim Fact-Checking](https://arxiv.org/abs/2601.16555)
*Mingwei Sun,Qianlong Wang,Ruifeng Xu*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型的Retrieve-Refine-Calibrate（RRC）框架，通过检索、精炼和校准三个步骤提升事实核查准确性，避免分解范式引入的噪声。


<details>
  <summary>Details</summary>
Motivation: 现有基于分解范式的事实核查方法易因无关实体或证据引入噪声，降低验证准确率。

Method: 提出RRC框架：1）识别声明中的实体并检索相关证据；2）根据声明精炼证据以减少无关信息；3）对低置信度预测进行再评估以校准验证过程。

Result: 在HOVER和FEVEROUS-S两个主流数据集上，RRC框架性能优于多个强基线方法。

Conclusion: RRC框架有效缓解了分解范式带来的噪声问题，提升了事实核查的准确性和鲁棒性。

Abstract: Fact-checking aims to verify the truthfulness of a claim based on the retrieved evidence. Existing methods typically follow a decomposition paradigm, in which a claim is broken down into sub-claims that are individually verified. However, the decomposition paradigm may introduce noise to the verification process due to irrelevant entities or evidence, ultimately degrading verification accuracy. To address this problem, we propose a Retrieve-Refine-Calibrate (RRC) framework based on large language models (LLMs). Specifically, the framework first identifies the entities mentioned in the claim and retrieves evidence relevant to them. Then, it refines the retrieved evidence based on the claim to reduce irrelevant information. Finally, it calibrates the verification process by re-evaluating low-confidence predictions. Experiments on two popular fact-checking datasets (HOVER and FEVEROUS-S) demonstrate that our framework achieves superior performance compared with competitive baselines.

</details>


### [87] [Attention-MoA: Enhancing Mixture-of-Agents via Inter-Agent Semantic Attention and Deep Residual Synthesis](https://arxiv.org/abs/2601.16596)
*Jianyu Wen,Yang Wei,Xiongxi Yu,Changxuan Xiao,Ke Zeng*

Main category: cs.CL

TL;DR: 本文提出了Attention-MoA框架，通过引入跨智能体语义注意力机制和自适应早停的残差模块，提升多智能体协作中的语义交互与推理质量，在多个基准上显著超越现有方法，甚至使小型开源模型超越大型闭源模型。


<details>
  <summary>Details</summary>
Motivation: 现有Mixture-of-Agents（MoA）方法虽引入动态路由和残差连接，但缺乏深层语义交互能力，难以有效纠正幻觉和优化逻辑推理。

Method: 提出Attention-MoA框架，核心包括：1）Inter-agent Semantic Attention（跨智能体语义注意力），增强智能体间深层语义对齐；2）Inter-layer Residual Module with Adaptive Early Stopping（带自适应早停的层间残差模块），缓解深层信息退化并提升计算效率。

Result: 在AlpacaEval 2.0、MT-Bench和FLASK上全面领先：AlpacaEval 2.0长度控制胜率91.15%；FLASK中12项能力中胜出10项；MT-Bench得分8.83，AlpacaEval LC胜率77.36%，超越Claude-4.5-Sonnet与GPT-4.1。

Conclusion: Attention-MoA通过增强语义协作与优化信息流，证明了轻量级开源模型通过高质量协同可媲美甚至超越巨型闭源模型，为高效、可控的推理协作范式提供了新路径。

Abstract: As the development of Large Language Models (LLMs) shifts from parameter scaling to inference-time collaboration, the Mixture-of-Agents (MoA) framework has emerged as a general paradigm to harness collective intelligence by layering diverse models. While recent MoA variants have introduced dynamic routing and residual connections to improve efficiency, these methods often fail to facilitate deep semantic interaction between agents, limiting the system's ability to actively correct hallucinations and refine logic. In this paper, we introduce Attention-MoA, a novel MoA-based framework that redefines collaboration through Inter-agent Semantic Attention. Complemented by an Inter-layer Residual Module with Adaptive Early Stopping Mechanism, our architecture mitigates information degradation in deep layers while improving computational efficiency. Extensive evaluations across AlpacaEval 2.0, MT-Bench, and FLASK demonstrate that Attention-MoA significantly outperforms state-of-the-art baselines, achieving a 91.15% Length-Controlled Win Rate on AlpacaEval 2.0 and dominating in 10 out of 12 capabilities on FLASK. Notably, Attention-MoA enables an ensemble of small open-source models to outperform massive proprietary models like Claude-4.5-Sonnet and GPT-4.1, achieving an MT-Bench score of 8.83 and an AlpacaEval 2.0 LC Win Rate of 77.36%.

</details>


### [88] [AuroraEdge-V-2B: A Faster And Stronger Edge Visual Large Language Model](https://arxiv.org/abs/2601.16615)
*Xiang Chen*

Main category: cs.CL

TL;DR: 本文提出AuroraEdge-V-2B，一种专为边缘部署设计的轻量、高效、鲁棒的视觉大语言模型，通过压缩融合方法提升推理效率，在保持高性能的同时显著降低计算开销和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有视觉大语言模型（VLLMs）在工业应用中面临参数量大、推理慢、特定领域性能弱等瓶颈，难以满足边缘部署对实时性、成本与资源的严苛要求。

Method: 提出紧凑型VLLM AuroraEdge-V-2B（2B参数），并设计压缩-融合方法以减少视觉token数量、降低浮点运算量；优化模型结构以适配边缘设备。

Result: 在9个基准测试中性能超越同参数量模型（如Qwen2-VL-2B、Qwen2.5-VL-3B、InternVL-2.5-2B）；推理浮点运算减半，支持高效边缘部署与实时响应。

Conclusion: AuroraEdge-V-2B在速度、成本与性能间取得良好平衡，为VLLMs在工业边缘场景落地提供了可行方案。

Abstract: Recently, due to the advancement of multimodal technology, people are attempting to use visual large language models (VLLMs) in industrial production. Many deep learning models (DLMs) deployed in the production environment are gradually being replaced by VLLMs. Compared with DLMs, VLLMs have some advantages in industrial applications: (1) Their strong generalization ability enables them to perform well across a wide range of tasks. (2) They are flexible and can deal with unfamiliar samples through context learning quickly. However, VLLMs also have obvious drawbacks: (1) VLLMs do not perform as well as custom-developed DLMs in specific domains. (2) The number of parameters in VLLMs is generally quite large, and their deployment requires substantial computational resources. (3) VLLMs generally operate much slower than DLMs, making real-time response challenging to achieve. To better utilize VLLMs in industrial applications, we introduce AuroraEdge-V-2B in this work, a compact, robust, and high-speed VLLM designed for edge deployment. To make the model run faster, we also propose a compression-fusion method to improve inference efficiency. AuroraEdge-V-2B has the following notable features: (1) Easy deployment and faster: It has only 2B parameters and is highly suitable for edge deployment, offering better real-time performance. (2) Fewer visual tokens and cheaper: It significantly reduces the number of visual tokens in the decoding process, thereby reducing the floating-point operations by half during inference and making it cheaper to use. (3) Strong performance: It gets a higher score on 9 benchmarks than models with the same number of parameter (e.g., Qwen2-VL-2B, Qwen2.5-VL-3B, InternVL-2.5-2B).

</details>


### [89] [PROST-LLM: Progressively Enhancing the Speech-to-Speech Translation Capability in LLMs](https://arxiv.org/abs/2601.16618)
*Jing Xu,Jiaqi Wang,Daxin Tan,Xiao Chen*

Main category: cs.CL

TL;DR: 本文提出PROST-LLM方法，通过三任务学习、模态链训练、自采样与回译生成偏好对，并进行偏好优化，逐步提升大语言模型在语音到语音翻译（S2ST）任务上的能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在语音到语音翻译（S2ST）任务中应用尚不充分，主要受限于标注数据稀缺。

Method: 提出PROST-LLM框架：1）基于CVSS语料库，采用三任务学习和模态链方法微调LLM；2）利用微调后的模型通过自采样与回译生成无需人工评估的偏好对；3）基于偏好对进行偏好优化。

Result: 大量实验验证了PROST-LLM能有效提升LLMs在S2ST任务上的性能。

Conclusion: PROST-LLM是一种有效的渐进式增强LLMs语音到语音翻译能力的方法，缓解了S2ST领域数据稀缺问题。

Abstract: Although Large Language Models (LLMs) excel in many tasks, their application to Speech-to-Speech Translation (S2ST) is underexplored and hindered by data scarcity. To bridge this gap, we propose PROST-LLM (PROgressive Speech-to-speech Translation) to enhance the S2ST capabilities in LLMs progressively. First, we fine-tune the LLMs with the CVSS corpus, employing designed tri-task learning and chain of modality methods to boost the initial performance. Then, leveraging the fine-tuned model, we generate preference pairs through self-sampling and back-translation without human evaluation. Finally, these preference pairs are used for preference optimization to enhance the model's S2ST capability further. Extensive experiments confirm the effectiveness of our proposed PROST-LLM in improving the S2ST capability of LLMs.

</details>


### [90] [How Does Personalized Memory Shape LLM Behavior? Benchmarking Rational Preference Utilization in Personalized Assistants](https://arxiv.org/abs/2601.16621)
*Xueyang Feng,Weinan Gan,Xu Chen,Quanyu Dai,Yong Liu*

Main category: cs.CL

TL;DR: 本文提出RPEval基准和RP-Reasoner方法，以解决大语言模型个性化记忆导致的意图理解干扰问题，通过务实推理实现选择性记忆整合，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM助手在引入用户个性化记忆时，常将无关记忆带入上下文，干扰模型对用户意图的理解，影响用户体验。

Method: 构建RPEval基准（含个性化意图推理数据集与多粒度评估协议），并提出RP-Reasoner方法，将记忆利用建模为务实推理过程，实现个性化信息的选择性整合。

Result: RP-Reasoner在RPEval上显著优于精心设计的基线，并在大规模商用个性化助手中解决了80%的不良案例。

Conclusion: 务实推理能有效缓解大语言模型中的非理性个性化问题，RPEval基准为该方向提供了可复现的评估标准。

Abstract: Large language model (LLM)-powered assistants have recently integrated memory mechanisms that record user preferences, leading to more personalized and user-aligned responses. However, irrelevant personalized memories are often introduced into the context, interfering with the LLM's intent understanding. To comprehensively investigate the dual effects of personalization, we develop RPEval, a benchmark comprising a personalized intent reasoning dataset and a multi-granularity evaluation protocol. RPEval reveals the widespread phenomenon of irrational personalization in existing LLMs and, through error pattern analysis, illustrates its negative impact on user experience. Finally, we introduce RP-Reasoner, which treats memory utilization as a pragmatic reasoning process, enabling the selective integration of personalized information. Experimental results demonstrate that our method significantly outperforms carefully designed baselines on RPEval, and resolves 80% of the bad cases observed in a large-scale commercial personalized assistant, highlighting the potential of pragmatic reasoning to mitigate irrational personalization. Our benchmark is publicly available at https://github.com/XueyangFeng/RPEval.

</details>


### [91] [MultiLexNorm++: A Unified Benchmark and a Generative Model for Lexical Normalization for Asian Languages](https://arxiv.org/abs/2601.16623)
*Weerayut Buaphet,Thanh-Nhi Nguyen,Risa Kondo,Tomoyuki Kajiwara,Yumin Kim,Jimin Lee,Hwanhee Lee,Holy Lovenia,Peerat Limkonchotiwat,Sarana Nutanong,Rob Van der Goot*

Main category: cs.CL

TL;DR: 本文扩展了MultiLexNorm基准测试，新增5种亚洲语言（涵盖不同语系和4种文字），发现现有SOTA模型在新语言上性能下降，并提出基于大语言模型（LLM）的新架构以提升鲁棒性，同时分析错误类型指明未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有MultiLexNorm基准主要覆盖印欧语系拉丁字母语言，缺乏对亚洲语言（多语系、多文字）的覆盖，限制了词法规范化任务的普适性评估。

Method: 扩展MultiLexNorm基准至5种亚洲语言（含4种文字），评估现有SOTA模型表现，并提出一种基于大语言模型（LLM）的新架构。

Result: 现有SOTA模型在新增亚洲语言上性能显著下降；所提LLM-based新架构展现出更强的跨语言鲁棒性；错误分析揭示了未来改进方向。

Conclusion: 词法规范化需更广泛的语言覆盖基准，LLM为多语言、多文字场景提供了更优解决方案，但仍存在可改进的错误模式。

Abstract: Social media data has been of interest to Natural Language Processing (NLP) practitioners for over a decade, because of its richness in information, but also challenges for automatic processing. Since language use is more informal, spontaneous, and adheres to many different sociolects, the performance of NLP models often deteriorates. One solution to this problem is to transform data to a standard variant before processing it, which is also called lexical normalization. There has been a wide variety of benchmarks and models proposed for this task. The MultiLexNorm benchmark proposed to unify these efforts, but it consists almost solely of languages from the Indo-European language family in the Latin script. Hence, we propose an extension to MultiLexNorm, which covers 5 Asian languages from different language families in 4 different scripts. We show that the previous state-of-the-art model performs worse on the new languages and propose a new architecture based on Large Language Models (LLMs), which shows more robust performance. Finally, we analyze remaining errors, revealing future directions for this task.

</details>


### [92] [Typologically Informed Parameter Aggregation](https://arxiv.org/abs/2601.16629)
*Stef Accou,Wessel Poelman*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的、基于语言类型学相似性的参数聚合方法TIPA，用于构建代理语言适配器，以提升多语言模型在低资源和未见语言上的零样本跨语言迁移性能。


<details>
  <summary>Details</summary>
Motivation: 大规模多语言语言模型在低资源和未见语言上表现不佳，而为每种语言单独训练适配器成本高昂。

Method: 提出Typologically Informed Parameter Aggregation (TIPA)，通过基于语言类型学相似性加权聚合已有语言适配器，生成代理适配器，并集成到MAD-X框架中实现零样本迁移。

Result: 在5个NLP任务、230多种语言上验证，TIPA持续优于或匹配英语微调、选择最相近语言适配器等基线方法，尤其在缺乏专用适配器的语言上提升显著。

Conclusion: 基于类型学的适配器聚合是一种无需额外训练、有效替代语言专用模块的可行方案。

Abstract: Massively multilingual language models enable cross-lingual generalization but underperform on low-resource and unseen languages. While adapter-based fine-tuning offers a parameter-efficient solution, training language-specific adapters at scale remains costly. We introduce Typologically Informed Parameter Aggregation (TIPA), a training-free method that constructs proxy language adapters by aggregating existing ones, weighted by typological similarity. Integrated into the MAD-X framework, these proxies enable zero-shot cross-lingual transfer without additional training. We evaluate TIPA on five NLP tasks and over 230 languages. TIPA consistently outperforms or matches baselines such as English-only fine-tuning or selecting the typologically closest language adapter. We see the largest gains for languages lacking dedicated adapters. Our results demonstrate that typologically informed aggregation provides a viable alternative to language-specific modules without any training needed.

</details>


### [93] [Sycophancy Hides Linearly in the Attention Heads](https://arxiv.org/abs/2601.16644)
*Rifo Genadi,Munachiso Nwadike,Nurdaulet Mukhituly,Hilal Alquabeh,Tatsuya Hiraoka,Kentaro Inui*

Main category: cs.CL

TL;DR: 本文发现，正确到错误的谄媚信号在多头注意力激活中最具线性可分性，并通过线性探针定位到中间层稀疏注意力头进行有效干预，从而缓解模型谄媚倾向。


<details>
  <summary>Details</summary>
Motivation: 基于线性表征假设，探究谄媚信号在模型内部（残差流、MLP、注意力层）的表征位置与可干预性。

Method: 在TruthfulQA数据集上训练线性探针，分析残差流、MLP和注意力层中谄媚信号的线性可分性；评估探针在其他事实问答基准上的迁移能力；对比已知‘真实’方向；分析注意力模式。

Result: 谄媚信号在多头注意力激活中最易线性分离；中间层稀疏注意力头上的探针干预最有效；探针具有跨数据集迁移能力；与已有‘真实’方向重叠有限；关键注意力头更关注用户疑虑表达。

Conclusion: 谄媚倾向可通过简单、定向的线性干预，在注意力激活的内部几何结构中被有效缓解。

Abstract: We find that correct-to-incorrect sycophancy signals are most linearly separable within multi-head attention activations. Motivated by the linear representation hypothesis, we train linear probes across the residual stream, multilayer perceptron (MLP), and attention layers to analyze where these signals emerge. Although separability appears in the residual stream and MLPs, steering using these probes is most effective in a sparse subset of middle-layer attention heads. Using TruthfulQA as the base dataset, we find that probes trained on it transfer effectively to other factual QA benchmarks. Furthermore, comparing our discovered direction to previously identified "truthful" directions reveals limited overlap, suggesting that factual accuracy, and deference resistance, arise from related but distinct mechanisms. Attention-pattern analysis further indicates that the influential heads attend disproportionately to expressions of user doubt, contributing to sycophantic shifts. Overall, these findings suggest that sycophancy can be mitigated through simple, targeted linear interventions that exploit the internal geometry of attention activations.

</details>


### [94] [Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations](https://arxiv.org/abs/2601.16651)
*Lukas Hinterleitner,Loris Schoenegger,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文探讨了在大型语言模型（LLM）中进行基于实例的梯度解释时，如何更有效地降低梯度维度：是选择架构导向的少量组件子集，还是对全梯度进行随机降维？作者提出新基准并发现，贪心选取的组件子集在数据影响检索任务中优于全梯度或随机投影，且计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 梯度类实例解释方法受限于LLM梯度的高维性，现有实践中常随意选取参数子集估计影响，缺乏系统评估与合理依据。

Method: 设计新基准任务（训练数据影响检索），对比三种降维策略：全梯度、随机投影、以及基于模型架构和贪心策略选取的少量组件子集。

Result: 贪心选取的组件子集在检索任务中表现最优，且计算效率高于随机投影；全梯度和随机投影效果均较差。

Conclusion: 针对LLM的实例解释，有依据地选择少量关键模型组件比盲目降维（如随机投影）更有效且更高效，是一种实用可行的策略。

Abstract: Gradient-based methods for instance-based explanation for large language models (LLMs) are hindered by the immense dimensionality of model gradients. In practice, influence estimation is restricted to a subset of model parameters to make computation tractable, but this subset is often chosen ad hoc and rarely justified by systematic evaluation. This paper investigates if it is better to create low-dimensional representations by selecting a small, architecturally informed subset of model components or by projecting the full gradients into a lower-dimensional space. Using a novel benchmark, we show that a greedily selected subset of components captures the information about training data influence needed for a retrieval task more effectively than either the full gradient or random projection. We further find that this approach is more computationally efficient than random projection, demonstrating that targeted component selection is a practical strategy for making instance-based explanations of large models more computationally feasible.

</details>


### [95] [PLawBench: A Rubric-Based Benchmark for Evaluating LLMs in Real-World Legal Practice](https://arxiv.org/abs/2601.16669)
*Yuzhen Shi,Huanghai Liu,Yiran Hu,Gaojie Song,Xinran Xu,Yubo Ma,Tianyi Tang,Li Zhang,Qingjing Chen,Di Feng,Wenbo Lv,Weiheng Wu,Kexin Yang,Sen Yang,Wei Wang,Rongyao Shi,Yuanyang Qiu,Yuemeng Qi,Jingwen Zhang,Xiaoyu Sui,Yifan Chen,Yi Zhang,An Yang,Bowen Yu,Dayiheng Liu,Junyang Lin,Weixing Shen,Bing Zhao,Charles L. A. Clarke,Hu Wei*

Main category: cs.CL

TL;DR: 本文提出了PLawBench，一个面向真实法律实践场景的实用法律基准，用于评估大语言模型（LLMs）在法律咨询、案例分析和法律文书生成等任务中的细粒度法律推理能力；实验表明当前主流LLM在此基准上表现不佳，揭示其法律推理能力仍存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有法律评测基准过于简化、标准化，无法反映真实法律实践中的模糊性、复杂性和高阶推理需求，且缺乏细粒度、多维度的评估指标。

Method: 构建基于真实法律工作流程的PLawBench基准，涵盖三大任务类别（公众法律咨询、实务案例分析、法律文书生成），包含850道题、13类场景及约12,500项专家设计的评分细则；采用与人类专家判断对齐的LLM评估器评测10个主流LLM。

Result: 所有被测LLM在PLawBench上均未展现出强性能，尤其在识别关键事实、结构化法律推理和生成合法合规文书方面存在明显短板。

Conclusion: 当前LLM在细粒度法律推理能力上存在显著局限，亟需更贴近实务的评测体系与针对性模型优化，PLawBench为未来法律领域LLM的评估与发展提供了新范式。

Abstract: As large language models (LLMs) are increasingly applied to legal domain-specific tasks, evaluating their ability to perform legal work in real-world settings has become essential. However, existing legal benchmarks rely on simplified and highly standardized tasks, failing to capture the ambiguity, complexity, and reasoning demands of real legal practice. Moreover, prior evaluations often adopt coarse, single-dimensional metrics and do not explicitly assess fine-grained legal reasoning. To address these limitations, we introduce PLawBench, a Practical Law Benchmark designed to evaluate LLMs in realistic legal practice scenarios. Grounded in real-world legal workflows, PLawBench models the core processes of legal practitioners through three task categories: public legal consultation, practical case analysis, and legal document generation. These tasks assess a model's ability to identify legal issues and key facts, perform structured legal reasoning, and generate legally coherent documents. PLawBench comprises 850 questions across 13 practical legal scenarios, with each question accompanied by expert-designed evaluation rubrics, resulting in approximately 12,500 rubric items for fine-grained assessment. Using an LLM-based evaluator aligned with human expert judgments, we evaluate 10 state-of-the-art LLMs. Experimental results show that none achieves strong performance on PLawBench, revealing substantial limitations in the fine-grained legal reasoning capabilities of current LLMs and highlighting important directions for future evaluation and development of legal LLMs. Data is available at: https://github.com/skylenage/PLawbench.

</details>


### [96] [EMemBench: Interactive Benchmarking of Episodic Memory for VLM Agents](https://arxiv.org/abs/2601.16690)
*Xinze Li,Ziyue Zhu,Siyuan Liu,Yubo Ma,Yuhang Zang,Yixin Cao,Aixin Sun*

Main category: cs.CL

TL;DR: EMemBench 是一个面向智能体长期记忆评估的交互式程序化基准，通过从智能体自身游戏轨迹中动态生成问题，覆盖文本与视觉环境，并涵盖多种记忆能力维度；实验表明当前模型在归纳与空间推理（尤其视觉场景）上仍存在显著瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有记忆评估方法多依赖固定问题集，难以真实反映智能体在动态交互中对自身经历的长期记忆能力，亟需能生成个性化、可验证、多维度记忆任务的基准。

Method: 提出 EMemBench：基于游戏轨迹自动生成问题的程序化基准，问题模板从底层游戏信号推导可验证真值，系统覆盖单/多跳回忆、归纳、时序、空间、逻辑及对抗性记忆技能；在15个文本游戏和多个视觉种子上评估以强语言模型（LM）/视觉语言模型（VLM）为骨干的记忆智能体，采用上下文学习作为基线，并开展人类研究验证难度。

Result: 结果远未饱和：归纳与空间推理是持续瓶颈，尤其在视觉环境中；持久记忆机制对文本游戏中的开放骨干模型提升明显，但对VLM效果不一致；人类研究证实该基准具有高难度。

Conclusion: EMemBench 有效揭示了当前记忆智能体（尤其VLM）在视觉具身场景下 episodic memory 的根本局限，凸显归纳与空间记忆建模仍是关键挑战。

Abstract: We introduce EMemBench, a programmatic benchmark for evaluating long-term memory of agents through interactive games. Rather than using a fixed set of questions, EMemBench generates questions from each agent's own trajectory, covering both text and visual game environments. Each template computes verifiable ground truth from underlying game signals, with controlled answerability and balanced coverage over memory skills: single/multi-hop recall, induction, temporal, spatial, logical, and adversarial. We evaluate memory agents with strong LMs/VLMs as backbones, using in-context prompting as baselines. Across 15 text games and multiple visual seeds, results are far from saturated: induction and spatial reasoning are persistent bottlenecks, especially in visual setting. Persistent memory yields clear gains for open backbones on text games, but improvements are less consistent for VLM agents, suggesting that visually grounded episodic memory remains an open challenge. A human study further confirms the difficulty of EMemBench.

</details>


### [97] [Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach](https://arxiv.org/abs/2601.16724)
*Kevin Fan,Eric Yun*

Main category: cs.CL

TL;DR: 本文研究了自动作文评分（AES）系统对英语作为第二语言（ESL）学习者的算法偏见问题，发现现有基于Transformer的模型在高熟练度ESL写作中存在显著评分偏低现象；为此提出一种基于匹配作文对的对比学习方法，显著缩小评分差距并保持评分一致性。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的自动作文评分模型主要在母语者语料上训练，易将二语表面语言特征与作文质量建立虚假关联，导致对ESL学习者（尤其是高熟练度者）系统性低估，引发教育公平性质疑。

Method: 在ASAP 2.0和ELLIPSE数据集上分析微调DeBERTa-v3模型的偏见表现；构建17,161对匹配的ESL-母语作文对，采用三元组对比学习（Triplet Margin Loss）进行微调，使模型隐空间中两类写作表征对齐。

Result: 高熟练度ESL作文与母语作文同质评分差距从10.3%降至6.2%（降幅39.9%），同时保持QWK达0.76；事后语言学分析表明模型能区分句法复杂性与语法错误，避免惩罚合法的二语句式结构。

Conclusion: 对比学习结合匹配作文对可有效缓解AES系统对高熟练度ESL学习者的评分偏见，在不牺牲整体评分性能的前提下提升公平性，为构建更公正的教育AI系统提供了可行路径。

Abstract: As Automated Essay Scoring (AES) systems are increasingly used in high-stakes educational settings, concerns regarding algorithmic bias against English as a Second Language (ESL) learners have increased. Current Transformer-based regression models trained primarily on native-speaker corpora often learn spurious correlations between surface-level L2 linguistic features and essay quality. In this study, we conduct a bias study of a fine-tuned DeBERTa-v3 model using the ASAP 2.0 and ELLIPSE datasets, revealing a constrained score scaling for high-proficiency ESL writing where high-proficiency ESL essays receive scores 10.3% lower than Native speaker essays of identical human-rated quality. To mitigate this, we propose applying contrastive learning with a triplet construction strategy: Contrastive Learning with Matched Essay Pairs. We constructed a dataset of 17,161 matched essay pairs and fine-tuned the model using Triplet Margin Loss to align the latent representations of ESL and Native writing. Our approach reduced the high-proficiency scoring disparity by 39.9% (to a 6.2% gap) while maintaining a Quadratic Weighted Kappa (QWK) of 0.76. Post-hoc linguistic analysis suggests the model successfully disentangled sentence complexity from grammatical error, preventing the penalization of valid L2 syntactic structures.

</details>


### [98] [Standardizing Longitudinal Radiology Report Evaluation via Large Language Model Annotation](https://arxiv.org/abs/2601.16753)
*Xinyi Wang,Grazziela Figueredo,Ruizhe Li,Xin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLM）的自动化标注流程，用于识别和提取放射学报告中的纵向信息（如疾病进展），在MIMIC-CXR数据集上构建了大规模标注基准，并据此评估了7种前沿报告生成模型，显著优于传统人工规则方法。


<details>
  <summary>Details</summary>
Motivation: 现有放射学报告纵向信息标注方法依赖手工词典与封闭、复杂或过于简化的规则，费时且难以泛化；亟需一种高效、准确、可适应新场景的自动标注工具。

Method: 设计两阶段LLM驱动流程：先识别含纵向信息的句子，再提取疾病进展关系；在500份人工标注报告上评估5个主流LLM，选出Qwen2.5-32B，并用其标注95,169份MIMIC-CXR报告，构建标准化纵向评估基准。

Result: Qwen2.5-32B在纵向信息检测和疾病追踪任务中F1分数分别比现有方法高11.3%和5.3%；基于新基准对7种SOTA报告生成模型的评估验证了该标注方法的有效性与实用性。

Conclusion: 基于LLM的自动纵向标注方法更高效、鲁棒且可扩展，为放射学报告生成模型的纵向能力评估提供了可靠、标准化的新基准。

Abstract: Longitudinal information in radiology reports refers to the sequential tracking of findings across multiple examinations over time, which is crucial for monitoring disease progression and guiding clinical decisions. Many recent automated radiology report generation methods are designed to capture longitudinal information; however, validating their performance is challenging. There is no proper tool to consistently label temporal changes in both ground-truth and model-generated texts for meaningful comparisons. Existing annotation methods are typically labor-intensive, relying on the use of manual lexicons and rules. Complex rules are closed-source, domain specific and hard to adapt, whereas overly simple ones tend to miss essential specialised information. Large language models (LLMs) offer a promising annotation alternative, as they are capable of capturing nuanced linguistic patterns and semantic similarities without extensive manual intervention. They also adapt well to new contexts. In this study, we therefore propose an LLM-based pipeline to automatically annotate longitudinal information in radiology reports. The pipeline first identifies sentences containing relevant information and then extracts the progression of diseases. We evaluate and compare five mainstream LLMs on these two tasks using 500 manually annotated reports. Considering both efficiency and performance, Qwen2.5-32B was subsequently selected and used to annotate another 95,169 reports from the public MIMIC-CXR dataset. Our Qwen2.5-32B-annotated dataset provided us with a standardized benchmark for evaluating report generation models. Using this new benchmark, we assessed seven state-of-the-art report generation models. Our LLM-based annotation method outperforms existing annotation solutions, achieving 11.3\% and 5.3\% higher F1-scores for longitudinal information detection and disease tracking, respectively.

</details>


### [99] [Do LLM hallucination detectors suffer from low-resource effect?](https://arxiv.org/abs/2601.16766)
*Debtanu Datta,Mohan Kishore Chilukuri,Yash Kumar,Saptarshi Ghosh,Muhammad Bilal Zafar*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）在低资源语言中的幻觉检测器是否也受低资源效应影响，发现尽管任务准确率大幅下降，幻觉检测器的准确率下降幅度小得多，表明LLM内部仍保留不确定性信号，且检测器在单语和多语设置下稳健，但在无目标语言监督的跨语言设置下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探究幻觉检测器是否同样受低资源效应影响，即在低资源语言中其性能是否显著下降。

Method: 在三个领域（事实回忆、STEM、人文学科）的五项任务上，使用四种大语言模型和三种幻觉检测器进行实验，对比英语与低资源语言（如孟加拉语）下的任务准确率与检测器准确率变化。

Result: 低资源语言中任务准确率大幅下降，但幻觉检测器准确率下降幅度明显更小；检测器在单语和多语设置下稳健，但在无目标语言监督的跨语言设置下性能不佳。

Conclusion: LLM在低资源语言中仍编码不确定性信号，幻觉检测器具有跨语言鲁棒性潜力，但需目标语言监督以实现有效泛化。

Abstract: LLMs, while outperforming humans in a wide range of tasks, can still fail in unanticipated ways. We focus on two pervasive failure modes: (i) hallucinations, where models produce incorrect information about the world, and (ii) the low-resource effect, where the models show impressive performance in high-resource languages like English but the performance degrades significantly in low-resource languages like Bengali. We study the intersection of these issues and ask: do hallucination detectors suffer from the low-resource effect? We conduct experiments on five tasks across three domains (factual recall, STEM, and Humanities). Experiments with four LLMs and three hallucination detectors reveal a curious finding: As expected, the task accuracies in low-resource languages experience large drops (compared to English). However, the drop in detectors' accuracy is often several times smaller than the drop in task accuracy. Our findings suggest that even in low-resource languages, the internal mechanisms of LLMs might encode signals about their uncertainty. Further, the detectors are robust within language (even for non-English) and in multilingual setups, but not in cross-lingual settings without in-language supervision.

</details>


### [100] [Persuasion Tokens for Editing Factual Knowledge in LLMs](https://arxiv.org/abs/2601.16781)
*Paul Youssef,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: 本文提出了一种名为P-Tokens的新方法，用于在不依赖长而具体的事实演示的情况下高效地进行大语言模型（LLM）的知识编辑，其性能与现有上下文内知识编辑（IKE）方法相当甚至更优。


<details>
  <summary>Details</summary>
Motivation: 现有上下文内知识编辑（IKE）方法依赖于冗长且特定事实的演示，创建成本高且占用大量上下文空间，亟需更高效、可扩展的替代方案。

Method: 提出并训练特殊标记（P-Tokens），使其能模拟IKE中事实演示的效果，从而实现无需事实特定演示的知识编辑；在两个编辑数据集和三个LLM上进行评估，并分析其对干扰项的鲁棒性及P-Token数量对性能的影响。

Result: P-Tokens在多个数据集和模型上的编辑性能与IKE相当甚至更优；编辑效果对干扰项鲁棒，仅对邻近事实产生轻微负面影响；增加P-Token数量可提升性能。

Conclusion: P-Tokens有效缓解了IKE的关键局限，为大语言模型知识编辑提供了一种更实用、更可扩展的替代方法。

Abstract: In-context knowledge editing (IKE) is a promising technique for updating Large Language Models (LLMs) with new information. However, IKE relies on lengthy, fact-specific demonstrations which are costly to create and consume significant context window space. In this paper, we introduce persuasion tokens (P-Tokens) -- special tokens trained to replicate the effect of IKE demonstrations, enabling efficient knowledge editing without requiring fact-specific demonstrations. We evaluate P-Tokens across two editing datasets and three LLMs, demonstrating performance comparable to, and often exceeding, IKE. We further find that editing performance is robust to distractors with small negative effects to neighboring facts, and that increasing the number of P-Tokens improves performance. Our work addresses key limitations of IKE and provides a more practical and scalable alternative for editing LLMs.

</details>


### [101] [Large Language Models as Automatic Annotators and Annotation Adjudicators for Fine-Grained Opinion Analysis](https://arxiv.org/abs/2601.16800)
*Gaurav Negi,MA Waskow,Paul Buitelaar*

Main category: cs.CL

TL;DR: 本文探讨了利用大语言模型（LLM）作为自动标注器，解决细粒度观点分析任务中标注成本高、跨领域数据稀缺的问题，提出了一种声明式标注流程和多标签仲裁方法，在ASTE和ACOS任务上验证了其有效性与高一致性。


<details>
  <summary>Details</summary>
Motivation: 细粒度观点分析需要大量人工标注，尤其在多领域和实际应用中成本高昂；缺乏领域特定的标注数据制约模型训练。

Method: 提出声明式标注流程以降低LLM提示工程的变异性，并设计新型LLM多标签仲裁机制，用于识别文本中的细粒度观点片段；在ASTE和ACOS任务上测试不同规模LLM的效果。

Result: LLM可作为高一致性的自动标注器与仲裁器，显著提升标注效率，Inter-Annotator Agreement表现优异。

Conclusion: LLM能有效缓解细粒度观点分析中的人力与成本瓶颈，为构建高质量标注数据集提供可行、低成本的自动化方案。

Abstract: Fine-grained opinion analysis of text provides a detailed understanding of expressed sentiments, including the addressed entity. Although this level of detail is sound, it requires considerable human effort and substantial cost to annotate opinions in datasets for training models, especially across diverse domains and real-world applications. We explore the feasibility of LLMs as automatic annotators for fine-grained opinion analysis, addressing the shortage of domain-specific labelled datasets. In this work, we use a declarative annotation pipeline. This approach reduces the variability of manual prompt engineering when using LLMs to identify fine-grained opinion spans in text. We also present a novel methodology for an LLM to adjudicate multiple labels and produce final annotations. After trialling the pipeline with models of different sizes for the Aspect Sentiment Triplet Extraction (ASTE) and Aspect-Category-Opinion-Sentiment (ACOS) analysis tasks, we show that LLMs can serve as automatic annotators and adjudicators, achieving high Inter-Annotator Agreement across individual LLM-based annotators. This reduces the cost and human effort needed to create these fine-grained opinion-annotated datasets.

</details>


### [102] [SoS: Analysis of Surface over Semantics in Multilingual Text-To-Image Generation](https://arxiv.org/abs/2601.16803)
*Carolin Holtermann,Florian Schneider,Anne Lauscher*

Main category: cs.CL

TL;DR: 本文首次系统分析了文本到图像（T2I）模型中普遍存在的“重表层、轻语义”（Surface-over-Semantics, SoS）现象，发现多语言提示下模型易产生文化刻板视觉输出，并提出新量化指标验证该倾向在文本编码器深层加剧且与刻板印象显著相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究指出T2I模型对非英语输入高度敏感，易产生文化刻板图像，但缺乏对这种‘重表层、轻语义’（SoS）现象的全面系统分析。

Method: 构建覆盖171种文化身份、翻译为14种语言的提示集，用于测试7个主流T2I模型；提出一种新量化指标来衡量SoS倾向，并分析其在文本编码器各层的演化及视觉表现。

Result: 除一个模型外，其余均在至少两种语言中表现出强SoS倾向；该倾向随文本编码器层数加深而增强；SoS倾向常与刻板视觉输出显著相关。

Conclusion: SoS是T2I模型中广泛存在的系统性偏差，其根源部分在于文本编码器对语言表层特征的过度依赖，亟需从模型设计和评估层面加以缓解。

Abstract: Text-to-image (T2I) models are increasingly employed by users worldwide. However, prior research has pointed to the high sensitivity of T2I towards particular input languages - when faced with languages other than English (i.e., different surface forms of the same prompt), T2I models often produce culturally stereotypical depictions, prioritizing the surface over the prompt's semantics. Yet a comprehensive analysis of this behavior, which we dub Surface-over-Semantics (SoS), is missing. We present the first analysis of T2I models' SoS tendencies. To this end, we create a set of prompts covering 171 cultural identities, translated into 14 languages, and use it to prompt seven T2I models. To quantify SoS tendencies across models, languages, and cultures, we introduce a novel measure and analyze how the tendencies we identify manifest visually. We show that all but one model exhibit strong surface-level tendency in at least two languages, with this effect intensifying across the layers of T2I text encoders. Moreover, these surface tendencies frequently correlate with stereotypical visual depictions.

</details>


### [103] [Trapped in the past? Disentangling fluid and crystallized intelligence of large language models using chess](https://arxiv.org/abs/2601.16823)
*Leonard S. Pleiss,Maximilian Schiffer,Robert K. von Weizsäcker*

Main category: cs.CL

TL;DR: 本文利用国际象棋作为可控测试平台，区分大语言模型（LLMs）的晶体智力（记忆）与流体智力（推理），发现模型在需强推理的分布外任务中性能骤降至随机水平，表明当前架构在系统性泛化上存在根本局限。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型能力来源尚不明确——是依赖训练数据的记忆（晶体智力），还是具备真正推理能力（流体智力）？需一个结构清晰、可量化、能分离两类能力的测试环境。

Method: 以国际象棋为测试床，构建基于训练语料出现频率的位置分类体系（从高频记忆型到低频需推理型），结合引擎评估与可控推理强度（如思维链提示），系统评测多代GPT模型。

Result: 模型性能随流体智力需求上升而持续下降；分布外任务性能坍缩至随机水平；新模型提升有限；推理增强策略的边际收益随位置越接近训练分布而递减。

Conclusion: 当前LLM仍严重依赖模式匹配与记忆，缺乏稳健的系统性泛化能力；仅靠扩大模型规模难以实现真正流体智力，亟需新架构或机制突破。

Abstract: Large Language Models (LLMs) exhibit remarkable capabilities, yet it remains unclear to what extent these reflect sophisticated recall (crystallized intelligence) or reasoning ability (fluid intelligence). We introduce chess as a controlled testbed for disentangling these faculties. Leveraging the game's structure and scalable engine evaluations, we construct a taxonomy of positions varying in training corpus proximity--ranging from common states solvable by memorization to novel ones requiring first-principles reasoning. We systematically evaluate multiple GPT generations under varying reasoning intensities. Our analysis reveals a clear gradient: performance consistently degrades as fluid intelligence demands increase. Notably, in out-of-distribution tasks, performance collapses to random levels. While newer models improve, progress slows significantly for tasks outside the training distribution. Furthermore, while reasoning-augmented inference improves performance, its marginal benefit per token decreases with distributional proximity. These results suggest current architectures remain limited in systematic generalization, highlighting the need for mechanisms beyond scale to achieve robust fluid intelligence.

</details>


### [104] [LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems](https://arxiv.org/abs/2601.16890)
*João A. Leite,Olesya Razuvayevskaya,Kalina Bontcheva,Carolina Scarton*

Main category: cs.CL

TL;DR: 本文提出了一种利用说服性修辞技巧对自动事实核查（AFC）系统实施对抗攻击的新方法，通过大语言模型重写声明以规避检测，在FEVER和FEVEROUS数据集上显著降低验证与证据检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有AFC系统易受对抗攻击，但尚无工作探索利用真实虚假信息传播中广泛使用的说服技巧作为对抗手段。

Method: 设计基于生成式大语言模型的说服性对抗攻击框架，覆盖15种分属6类的说服技巧，并采用解耦评估策略分别测试其对声明验证和证据检索的影响。

Result: 在FEVER和FEVEROUS基准上，说服性攻击显著降低了验证准确率和证据检索效果；部分说服技巧展现出极强的对抗有效性。

Conclusion: 说服技巧是一类强大且现实相关的对抗攻击方式，揭示当前AFC系统在语义操纵鲁棒性方面的严重缺陷，亟需设计更具韧性的核查机制。

Abstract: Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.

</details>


### [105] [Information Representation Fairness in Long-Document Embeddings: The Peculiar Interaction of Positional and Language Bias](https://arxiv.org/abs/2601.16934)
*Elias Schuhmacher,Andrianos Michail,Juri Opitz,Rico Sennrich,Simon Clematide*

Main category: cs.CL

TL;DR: 本文提出了一种基于排列的评估框架，用于检测嵌入模型在长文档和多语言场景下的位置与语言偏差，并设计了推理时注意力校准方法以缓解早期段落过度表征、后期及低资源语言段落被边缘化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入模型在处理长文档或多语段落时可能存在系统性偏差（如位置偏差和语言偏差），影响下游检索的公平性与有效性，亟需可量化的评估手段与缓解策略。

Method: 提出基于排列的评估框架以量化嵌入中各段落的表征程度；分析发现偏差源于池化token注意力分布前重后轻；据此设计推理时注意力校准方法，使注意力更均匀分布于文档各位置。

Result: 实证表明主流嵌入模型存在显著的位置偏差（早段过表征、晚段被弱化）和语言偏差（高资源语言如英语占优、低资源语言被边缘化）；所提注意力校准方法有效提升后期段落的可发现性。

Conclusion: 嵌入模型的公平性不仅依赖训练数据与目标，也受推理机制（如注意力分布）深刻影响；通过简单而有效的推理时校准，可在不重训模型前提下显著改善长文档与多语言检索的均衡性与鲁棒性。

Abstract: To be discoverable in an embedding-based search process, each part of a document should be reflected in its embedding representation. To quantify any potential reflection biases, we introduce a permutation-based evaluation framework. With this, we observe that state-of-the-art embedding models exhibit systematic positional and language biases when documents are longer and consist of multiple segments. Specifically, early segments and segments in higher-resource languages like English are over-represented, while later segments and segments in lower-resource languages are marginalized. In our further analysis, we find that the positional bias stems from front-loaded attention distributions in pooling-token embeddings, where early tokens receive more attention. To mitigate this issue, we introduce an inference-time attention calibration method that redistributes attention more evenly across document positions, increasing discoverabiltiy of later segments. Our evaluation framework and attention calibration is available at https://github.com/impresso/fair-sentence-transformers

</details>


### [106] [Strategies for Span Labeling with Large Language Models](https://arxiv.org/abs/2601.16946)
*Danil Semin,Ondřej Dušek,Zdeněk Kasner*

Main category: cs.CL

TL;DR: 本文提出了一种名为LogitMatch的新约束解码方法，用于解决大语言模型在跨度标注任务中缺乏显式输入位置引用机制的问题，并通过四类任务验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在文本分析任务中广泛应用，但其生成式架构缺乏对输入特定部分的显式引用机制，导致跨度标注任务中出现各种不一致的提示策略。

Method: 将现有跨度标注提示策略分为三类：文本标记、数值位置索引和跨度内容匹配；针对内容匹配的局限性，提出LogitMatch——一种强制模型输出与有效输入跨度对齐的约束解码方法。

Result: 在四个多样化任务上的评估表明，尽管文本标记仍是稳健基线，LogitMatch能消除跨度匹配问题，在某些设置下优于其他策略。

Conclusion: LogitMatch为LLM在跨度标注任务中提供了一种更可靠、更精准的约束解码方案，弥补了生成式模型在结构化输出方面的固有缺陷。

Abstract: Large language models (LLMs) are increasingly used for text analysis tasks, such as named entity recognition or error detection. Unlike encoder-based models, however, generative architectures lack an explicit mechanism to refer to specific parts of their input. This leads to a variety of ad-hoc prompting strategies for span labeling, often with inconsistent results. In this paper, we categorize these strategies into three families: tagging the input text, indexing numerical positions of spans, and matching span content. To address the limitations of content matching, we introduce LogitMatch, a new constrained decoding method that forces the model's output to align with valid input spans. We evaluate all methods across four diverse tasks. We find that while tagging remains a robust baseline, LogitMatch improves upon competitive matching-based methods by eliminating span matching issues and outperforms other strategies in some setups.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [107] [Scalable Screw-Theoretic Synthesis for PDE-Based Dynamic Modeling of Multibody Flexible Manipulators](https://arxiv.org/abs/2601.16242)
*S. Yaqubi,J. Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种基于螺旋理论的多体综合框架，用于三维空间中任意数量柔性连杆串联机器人操纵器的PDE动态建模，通过螺旋描述运动与变形，并构建半显式微分-代数方程系统，保证数学严谨性与计算可行性。


<details>
  <summary>Details</summary>
Motivation: 为解决三维空间中含大量柔性连杆的串联机器人动态建模难题，需兼顾局部子系统与全局系统动力学，同时保证模型的可扩展性、物理一致性与数学良适性。

Method: 采用螺旋理论构建各柔性连杆的偏微分方程（PDE）动力学模型，用三个体坐标系下的对偶螺旋分别描述刚体运动、构型映射与弹性变形；通过能量变分原理统一推导控制方程；利用交互力严格施加完整关节约束；最终合成多体系统并转化为半显式指标-1微分-代数方程，再经变量分离处理为抽象Cauchy问题。

Result: 获得一个无限可扩展的多体PDE模型，能显式恢复所有动态状态（包括各体坐标系运动与柔性连杆分布变形场），且所导出系统具有数学良适性，并具备计算实现基础。

Conclusion: 该螺旋理论驱动的多体综合框架为高保真柔性机器人建模提供了统一、可扩展、兼具物理意义与数学严谨性的新范式。

Abstract: This paper presents a novel and scalable screw-theoretic multibody synthesis framework for PDE-based dynamic modeling of serial robotic manipulators with an arbitrary number of flexible links in three-dimensional space. The proposed approach systematically constructs screw-theoretic PDE models for individual flexible links and rigorously enforces holonomic joint constraints through interaction forces. The dynamics of each link are formulated using a set of dual screws expressed in body-fixed coordinates: one describing the motion of the body-fixed frame relative to the inertial frame, a second relating the body-fixed frame to the undeformed configuration, and a third capturing elastic deformations. By expressing the system energy and applying variational principles, the governing dynamics of each link had been previously derived in a unified manner. Synthesizing the individual link models yields an infinitely scalable multibody representation capable of capturing both local (subsystem-level) and global (system-level) dynamics. The framework explicitly recovers all dynamic states, including the motion of each body-fixed frame and the distributed deformation fields of the flexible links. For computational tractability and mathematical rigor, the resulting governing equations are formulated as a semi-explicit index-1 differential-algebraic system. Furthermore, by applying separation of variables, the PDE model is recast as an abstract Cauchy problem, and well-posedness of the resulting system is established.

</details>


### [108] [DMV-AVP: Distributed Multi-Vehicle Autonomous Valet Parking using Autoware](https://arxiv.org/abs/2601.16327)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 本文提出了DMV-AVP系统，一种基于分布式多车架构（DMAVA）的多车自主代客泊车（AVP）仿真系统，通过新增AVP节点与YOLOv5视觉检测模块，并采用Zenoh通信层，实现了跨主机的低延迟协同泊车仿真，验证了其可扩展性与无冲突行为。


<details>
  <summary>Details</summary>
Motivation: 现有AVP仿真多为集中式或非分布式设计，限制了可扩展性与全自主控制能力，亟需支持多车协同、低延迟通信的分布式仿真框架。

Method: 基于DMAVA架构，构建两个核心模块：1）多车AVP节点（实现状态协调、队列与预约管理）；2）集成Unity与YOLOv5的泊位视觉检测模块；底层采用Zenoh实现跨主机低延迟主题同步。

Result: 在双机和三机配置下实验表明系统具备确定性协调能力、无冲突泊车行为及面向Autoware实例的可扩展性能。

Conclusion: DMV-AVP系统成功支持协同式AVP分布式仿真，为真实场景与硬件在环验证提供了可扩展基础架构。

Abstract: This paper presents the DMV-AVP System, a distributed simulation of Multi-Vehicle Autonomous Valet Parking (AVP). The system was implemented as an application of the Distributed Multi-Vehicle Architecture (DMAVA) for synchronized multi-host execution. Most existing simulation approaches rely on centralized or non-distributed designs that constrain scalability and limit fully autonomous control. This work introduces two modules built on top of the DMAVA: 1) a Multi-Vehicle AVP Node that performs state-based coordination, queuing, and reservation management across multiple vehicles, and 2) a Unity-Integrated YOLOv5 Parking Spot Detection Module that provides real-time, vision-based perception within AWSIM Labs. Both modules integrate seamlessly with the DMAVA and extend it specifically for multi-vehicle AVP operation, supported by a Zenoh-based communication layer that ensures low-latency topic synchronization and coordinated behavior across hosts. Experiments conducted on two- and three-host configurations demonstrate deterministic coordination, conflict-free parking behavior, and scalable performance across distributed Autoware instances. The results confirm that the proposed Distributed Multi-Vehicle AVP System supports cooperative AVP simulation and establishes a foundation for future real-world and hardware-in-the-loop validation. Demo videos and source code are available at https://github.com/zubxxr/multi-vehicle-avp

</details>


### [109] [DMAVA: Distributed Multi-Autonomous Vehicle Architecture Using Autoware](https://arxiv.org/abs/2601.16336)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 本文提出了一种分布式多自动驾驶车辆架构（DMAVA），支持跨多物理主机的实时、同步自动驾驶仿真，各车独立运行完整AV栈，并通过低延迟数据中心化通信层实现协同；集成ROS 2 Humble、Autoware Universe、AWSIM Labs和Zenoh，在Unity环境中实现多Autoware栈并发执行；实验验证了其定位稳定性、跨主机通信可靠性与闭环控制同步性，并拓展应用于多车自主代客泊车。


<details>
  <summary>Details</summary>
Motivation: 现有仿真架构多局限于单车操作或依赖集中式控制，难以有效模拟和验证多自动驾驶车辆间的协调。

Method: 设计并实现分布式多AV架构（DMAVA），基于ROS 2 Humble、Autoware Universe、AWSIM Labs和Zenoh，在Unity仿真环境中支持多主机部署；各AV独立运行完整软件栈，通过Zenoh构建低延迟数据为中心的通信层实现同步协调。

Result: 在多主机配置下实验表明系统具备稳定定位、可靠跨主机通信和完全同步的闭环控制能力；成功应用于多车自主代客泊车场景，验证了其对高层协同自主性的可扩展性。

Conclusion: DMAVA为多AV协同仿真提供了可扩展、去中心化、实时同步的分布式基础架构，兼具工程实用性与研究前瞻性。

Abstract: Simulating and validating coordination among multiple autonomous vehicles (AVs) is a challenging task as most existing simulation architectures are limited to single-vehicle operation or rely on centralized control. This paper presents a Distributed Multi-AV Architecture (DMAVA) that enables synchronized, real-time autonomous driving simulation across multiple physical hosts. Each vehicle runs its own complete AV stack and operates independently from other AVs. The vehicles in the simulation maintain synchronized coordination through a low-latency data-centric communication layer. The proposed system integrates ROS 2 Humble, Autoware Universe, AWSIM Labs, and Zenoh to support concurrent execution of multiple Autoware stacks within a shared Unity-based environment. Experiments conducted on multiple-host configurations demonstrate stable localization, reliable inter-host communication, and fully synchronized closed-loop control. The DMAVA also serves as a foundation for Multi-Vehicle Autonomous Valet Parking, demonstrating its extensibility toward higher-level cooperative autonomy. Demo videos and source code are available at: https://github.com/zubxxr/distributed-multi-autonomous-vehicle-architecture.

</details>


### [110] [GNSS-based Lunar Orbit and Clock Estimation With Stochastic Cloning UD Filter](https://arxiv.org/abs/2601.16393)
*Keidai Iiyama,Grace Gao*

Main category: cs.RO

TL;DR: 本文提出了一种基于地面GNSS的月球导航卫星轨道与钟差估计框架，通过改进的随机克隆UD分解滤波器与延迟状态平滑器，结合高精度动力学与测量模型（含相对论效应、月球时间尺度转换及多层传播延迟），在低可观测性条件下实现了米级轨道与亚毫米/秒级速度精度。


<details>
  <summary>Details</summary>
Motivation: 为满足未来月球增强导航服务（LANS）对信号空间误差的严格要求，在月球距离下GNSS观测几何弱、可观测性低，需发展高精度、高稳定性的轨道与钟差估计算法。

Method: 提出一种随机克隆UD因子化滤波器与延迟状态平滑器，处理精密时间差分载波相位（TDCP）观测；构建包含相对论耦合、月球时间尺度变换及电离层/等离子体层/夏皮罗延迟的综合动力学与测量模型。

Result: 蒙特卡洛仿真表明，联合无电离层伪距与TDCP观测可实现米级轨道精度和亚毫米/秒级速度精度，满足LANS严苛指标。

Conclusion: 所提框架在低可观测 lunar 环境下具备数值稳定性与高精度性能，为地基GNSS支持月球导航提供了可行技术路径。

Abstract: This paper presents a terrestrial GNSS-based orbit and clock estimation framework for lunar navigation satellites. To enable high-precision estimation under the low-observability conditions encountered at lunar distances, we develop a stochastic-cloning UD-factorized filter and delayed-state smoother that provide enhanced numerical stability when processing precise time-differenced carrier phase (TDCP) measurements. A comprehensive dynamics and measurement model is formulated, explicitly accounting for relativistic coupling between orbital and clock states, lunar time-scale transformations, and signal propagation delays including ionospheric, plasmaspheric, and Shapiro effects. The proposed approach is evaluated using high-fidelity Monte-Carlo simulations incorporating realistic multi-constellation GNSS geometry, broadcast ephemeris errors, lunar satellite dynamics, and ionospheric and plasmaspheric delay computed from empirical electron density models. Simulation results demonstrate that combining ionosphere-free pseudorange and TDCP measurements achieves meter-level orbit accuracy and sub-millimeter-per-second velocity accuracy, satisfying the stringent signal-in-space error requirements of future Lunar Augmented Navigation Services (LANS).

</details>


### [111] [Reinforcement Learning-Based Energy-Aware Coverage Path Planning for Precision Agriculture](https://arxiv.org/abs/2601.16405)
*Beining Wu,Zihao Ding,Leo Ostigaard,Jun Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于Soft Actor-Critic（SAC）强化学习的能耗感知覆盖路径规划（CPP）框架，结合CNN-LSTM网络结构与定制化奖励函数，在保证能源安全前提下显著提升农业机器人覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有农业机器人覆盖路径规划方法常忽略能量约束，导致在大规模或资源受限环境中任务无法完成。

Method: 提出基于Soft Actor-Critic（SAC）的强化学习框架，融合CNN进行空间特征提取、LSTM建模时序动态，并设计兼顾覆盖率、能耗和返航约束的奖励函数，适用于含障碍物和充电站的栅格环境。

Result: 实验表明该方法覆盖率稳定超过90%，相比RRT、PSO、ACO等启发式算法覆盖率提升13.4–19.5%，约束违反减少59.9–88.3%。

Conclusion: 所提SAC框架是一种有效且可扩展的能耗约束下农业机器人覆盖路径规划解决方案。

Abstract: Coverage Path Planning (CPP) is a fundamental capability for agricultural robots; however, existing solutions often overlook energy constraints, resulting in incomplete operations in large-scale or resource-limited environments. This paper proposes an energy-aware CPP framework grounded in Soft Actor-Critic (SAC) reinforcement learning, designed for grid-based environments with obstacles and charging stations. To enable robust and adaptive decision-making under energy limitations, the framework integrates Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal dynamics. A dedicated reward function is designed to jointly optimize coverage efficiency, energy consumption, and return-to-base constraints. Experimental results demonstrate that the proposed approach consistently achieves over 90% coverage while ensuring energy safety, outperforming traditional heuristic algorithms such as Rapidly-exploring Random Tree (RRT), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) baselines by 13.4-19.5% in coverage and reducing constraint violations by 59.9-88.3%. These findings validate the proposed SAC-based framework as an effective and scalable solution for energy-constrained CPP in agricultural robotics.

</details>


### [112] [RENEW: Risk- and Energy-Aware Navigation in Dynamic Waterways](https://arxiv.org/abs/2601.16424)
*Mingi Jeong,Alberto Quattrini Li*

Main category: cs.RO

TL;DR: RENEW is a global path planner for Autonomous Surface Vehicles (ASVs) that integrates risk and energy awareness to handle dynamic maritime environments with disturbances like water currents.


<details>
  <summary>Details</summary>
Motivation: To enable safe and robust navigation for ASVs in dynamic, real-world maritime environments with external disturbances (e.g., water currents) and uncertain non-navigable regions.

Method: RENEW uses a unified risk- and energy-aware strategy with adaptive safety constraints, inspired by maritime contingency planning; it features a hierarchical architecture combining high-level constrained triangulation for topological diversity and low-level trajectory optimization within safe corridors.

Result: Validated on real-world ocean data, RENEW successfully jointly addresses adaptive non-navigability identification and topological path diversity—demonstrating robustness in dynamic maritime settings.

Conclusion: RENEW is the first framework to jointly tackle adaptive non-navigability and topological path diversity for ASVs, enabling safer and more reliable autonomous navigation under environmental disturbances.

Abstract: We present RENEW, a global path planner for Autonomous Surface Vehicle (ASV) in dynamic environments with external disturbances (e.g., water currents). RENEW introduces a unified risk- and energy-aware strategy that ensures safety by dynamically identifying non-navigable regions and enforcing adaptive safety constraints. Inspired by maritime contingency planning, it employs a best-effort strategy to maintain control under adverse conditions. The hierarchical architecture combines high-level constrained triangulation for topological diversity with low-level trajectory optimization within safe corridors. Validated with real-world ocean data, RENEW is the first framework to jointly address adaptive non-navigability and topological path diversity for robust maritime navigation.

</details>


### [113] [Zero-Shot MARL Benchmark in the Cyber-Physical Mobility Lab](https://arxiv.org/abs/2601.16578)
*Julius Beerwerth,Jianye Xu,Simon Schäfer,Fynn Belderink,Bassam Alrifaee*

Main category: cs.RO

TL;DR: 本文提出了一个用于评估多智能体强化学习（MARL）策略在网联自动驾驶车辆（CAVs）中仿真到现实（sim-to-real）迁移性能的可复现基准平台，基于CPM实验室构建，涵盖仿真、高保真数字孪生和物理测试平台，并揭示了性能下降的两大原因：仿真与硬件控制栈架构差异及环境真实性提升带来的仿真-现实差距。


<details>
  <summary>Details</summary>
Motivation: 解决MARL在CAVs中sim-to-real迁移缺乏可复现、结构化评估基准的问题，支持系统性分析迁移挑战。

Method: 构建集成仿真、高保真数字孪生和物理测试床的基准平台，在三个层级上零样本部署SigmaRL训练的MARL运动规划策略进行评估。

Result: 发现性能下降源于两方面：仿真与硬件控制栈的架构差异，以及随环境真实性提升而加剧的sim-to-real差距。

Conclusion: 该开源平台为在真实、可复现条件下系统研究MARL的sim-to-real挑战提供了有效支撑。

Abstract: We present a reproducible benchmark for evaluating sim-to-real transfer of Multi-Agent Reinforcement Learning (MARL) policies for Connected and Automated Vehicles (CAVs). The platform, based on the Cyber-Physical Mobility Lab (CPM Lab) [1], integrates simulation, a high-fidelity digital twin, and a physical testbed, enabling structured zero-shot evaluation of MARL motion-planning policies. We demonstrate its use by deploying a SigmaRL-trained policy [2] across all three domains, revealing two complementary sources of performance degradation: architectural differences between simulation and hardware control stacks, and the sim-to-real gap induced by increasing environmental realism. The open-source setup enables systematic analysis of sim-to-real challenges in MARL under realistic, reproducible conditions.

</details>


### [114] [A Unified Calibration Framework for High-Accuracy Articulated Robot Kinematics](https://arxiv.org/abs/2601.16638)
*Philip Tobuschat,Simon Duenser,Markus Bambach,Ivo Aschwanden*

Main category: cs.RO

TL;DR: 本文提出了一种统一的工业机器人静态标定方法，通过单次简单实验即可同时建模几何与非几何误差（如柔性弯曲、热变形、齿轮传动误差），并利用带解析梯度的高斯-牛顿优化进行参数识别，显著提升了定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统机器人工具定位误差补偿方法通常需要各自独立的专门实验、模型和辨识流程，缺乏统一性和效率。

Method: 构建包含虚拟关节的增强运动学模型以表征几何与非几何效应（柔性弯曲、热变形、齿轮误差），采用高斯-牛顿优化结合解析梯度进行参数辨识，并通过Fisher信息谱分析、时间交叉验证和模型消融验证鲁棒性与条件数。

Result: 在KUKA KR30机器人上实现平均定位误差26.8 μm，显著优于纯几何标定的102.3 μm；Fisher谱表明估计条件良好、参数化接近最小冗余；交叉验证与消融实验证明辨识鲁棒性强。

Conclusion: 该统一标定框架兼顾建模完整性与实验简易性，兼具高精度与强鲁棒性，为工业机器人高精度应用提供了实用可行的解决方案。

Abstract: Researchers have identified various sources of tool positioning errors for articulated industrial robots and have proposed dedicated compensation strategies. However, these typically require individual, specialized experiments with separate models and identification procedures. This article presents a unified approach to the static calibration of industrial robots that identifies a robot model, including geometric and non-geometric effects (compliant bending, thermal deformation, gear transmission errors), using only a single, straightforward experiment for data collection. The model augments the kinematic chain with virtual joints for each modeled effect and realizes the identification using Gauss-Newton optimization with analytic gradients. Fisher information spectra show that the estimation is well-conditioned and the parameterization near-minimal, whereas systematic temporal cross-validation and model ablations demonstrate robustness of the model identification. The resulting model is very accurate and its identification robust, achieving a mean position error of 26.8 $μm$ on a KUKA KR30 industrial robot compared to 102.3 $μm$ for purely geometric calibration.

</details>


### [115] [ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance](https://arxiv.org/abs/2601.16667)
*Zhuohao Li,Yinghao Li,Jian-Jian Jiang,Lang Zhou,Tianyu Zhang,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: 本文提出ReViP框架，通过视觉-本体感觉再平衡机制，利用外部VLM作为任务阶段观察者提供实时视觉线索，并采用特征级线性调制增强环境感知，缓解状态主导偏差与虚假完成问题；并在新构建的False-Completion Benchmark上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因直接融合本体感觉信号与视觉语言特征，导致状态主导偏差和可见执行失败下的虚假完成，根源在于模态不平衡——策略过度依赖内部状态而忽视视觉证据。

Method: 提出ReViP框架：引入任务感知的外部VLM作为任务阶段观察者，提取实时任务中心视觉线索；设计视觉-本体感觉特征级线性调制（Feature-wise Linear Modulation）以自适应调节语义感知与本体动态耦合；并构建首个可控False-Completion Benchmark（基于LIBERO，含Object-Drop等设定）。

Result: ReViP显著降低虚假完成率、提升任务成功率，在自建False-Completion Benchmark、LIBERO、RoboTwin 2.0及真实世界评估中均优于强基线。

Conclusion: 视觉-本体感觉再平衡是提升VLA模型鲁棒性与视觉接地能力的关键路径，ReViP为解决状态主导偏差与虚假完成提供了有效且可扩展的新范式。

Abstract: Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations.

</details>


### [116] [Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation](https://arxiv.org/abs/2601.16677)
*Lucía Güitta-López,Lionel Güitta-López,Jaime Boal,Álvaro Jesús López-López*

Main category: cs.RO

TL;DR: 本文提出了一种基于StyleID-CycleGAN（SICGAN）的域自适应方法，通过将虚拟环境图像翻译为逼真的合成图像，实现DRL策略在无需真实微调情况下的零样本迁移，在工业机器人抓取任务中验证了其高效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在现实中训练成本高、效率低，而虚拟环境训练后因sim-to-real gap难以直接部署；零样本迁移具有重要实用价值。

Method: 提出Style-Identified Cycle Consistent GAN（SICGAN），将虚拟观测图像翻译为真实风格的合成图像，构建‘虚拟动力学+真实视觉’的混合训练域；结合AR标定提升评估效率，并在两种工业机器人上验证。

Result: 虚拟训练成功率90–100%；真实场景零样本部署精度超95%（多数工作区）；成功泛化至不同颜色/形状的真实物体（如乐高积木、马克杯）。

Conclusion: 该SICGAN驱动的pipeline是一种高效、可扩展的sim-to-real解决方案，显著提升了DRL在工业场景中的落地可行性。

Abstract: The sample efficiency challenge in Deep Reinforcement Learning (DRL) compromises its industrial adoption due to the high cost and time demands of real-world training. Virtual environments offer a cost-effective alternative for training DRL agents, but the transfer of learned policies to real setups is hindered by the sim-to-real gap. Achieving zero-shot transfer, where agents perform directly in real environments without additional tuning, is particularly desirable for its efficiency and practical value. This work proposes a novel domain adaptation approach relying on a Style-Identified Cycle Consistent Generative Adversarial Network (StyleID-CycleGAN or SICGAN), an original Cycle Consistent Generative Adversarial Network (CycleGAN) based model. SICGAN translates raw virtual observations into real-synthetic images, creating a hybrid domain for training DRL agents that combines virtual dynamics with real-like visual inputs. Following virtual training, the agent can be directly deployed, bypassing the need for real-world training. The pipeline is validated with two distinct industrial robots in the approaching phase of a pick-and-place operation. In virtual environments agents achieve success rates of 90 to 100\%, and real-world deployment confirms robust zero-shot transfer (i.e., without additional training in the physical environment) with accuracies above 95\% for most workspace regions. We use augmented reality targets to improve the evaluation process efficiency, and experimentally demonstrate that the agent successfully generalizes to real objects of varying colors and shapes, including LEGO\textsuperscript{\textregistered}~cubes and a mug. These results establish the proposed pipeline as an efficient, scalable solution to the sim-to-real problem.

</details>


### [117] [Adaptive Reinforcement and Model Predictive Control Switching for Safe Human-Robot Cooperative Navigation](https://arxiv.org/abs/2601.16686)
*Ning Liu,Sen Shen,Zheng Li,Matthew D'Souza,Jen Jen Chung,Thomas Braunl*

Main category: cs.RO

TL;DR: 本文提出ARMS框架，结合强化学习与模型预测控制，通过自适应神经开关器实现两者软融合，在保证安全的同时提升复杂环境下的导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决移动协作机器人在人类引导下同时满足近距离调节和安全约束的导航挑战，尤其是在部分可观测性和非平稳人类运动条件下的鲁棒感知与控制问题。

Method: 提出ARMS混合框架：基于PPO训练的强化学习跟随器 + 一步QP形式的MPC安全滤波器；采用LSTM时间编码器与空间编码器解耦感知；设计可学习的自适应神经开关器实现上下文感知的软动作融合。

Result: 在高度杂乱环境中成功率82.5%，较DWA和纯RL基线分别提升7.1%和3.1%；计算延迟降至5.2ms，比多步MPC降低33%；Gazebo仿真迁移与初步实机部署验证了实用性与鲁棒性。

Conclusion: ARMS通过学习式自适应切换机制，在安全性与机动性间取得有效平衡，为安全高效的人机协同导航提供了可行且实用的解决方案。

Abstract: This paper addresses the challenge of human-guided navigation for mobile collaborative robots under simultaneous proximity regulation and safety constraints. We introduce Adaptive Reinforcement and Model Predictive Control Switching (ARMS), a hybrid learning-control framework that integrates a reinforcement learning follower trained with Proximal Policy Optimization (PPO) and an analytical one-step Model Predictive Control (MPC) formulated as a quadratic program safety filter. To enable robust perception under partial observability and non-stationary human motion, ARMS employs a decoupled sensing architecture with a Long Short-Term Memory (LSTM) temporal encoder for the human-robot relative state and a spatial encoder for 360-degree LiDAR scans. The core contribution is a learned adaptive neural switcher that performs context-aware soft action fusion between the two controllers, favoring conservative, constraint-aware QP-based control in low-risk regions while progressively shifting control authority to the learned follower in highly cluttered or constrained scenarios where maneuverability is critical, and reverting to the follower action when the QP becomes infeasible. Extensive evaluations against Pure Pursuit, Dynamic Window Approach (DWA), and an RL-only baseline demonstrate that ARMS achieves an 82.5 percent success rate in highly cluttered environments, outperforming DWA and RL-only approaches by 7.1 percent and 3.1 percent, respectively, while reducing average computational latency by 33 percent to 5.2 milliseconds compared to a multi-step MPC baseline. Additional simulation transfer in Gazebo and initial real-world deployment results further indicate the practicality and robustness of ARMS for safe and efficient human-robot collaboration. Source code and a demonstration video are available at https://github.com/21ning/ARMS.git.

</details>


### [118] [Creating a biologically more accurate spider robot to study active vibration sensing](https://arxiv.org/abs/2601.16691)
*Siyuan Sun,Eugene H. Lin,Nathan Brown,Hsin-Yi Hung,Andrew Gordus,Jochen Mueller,Chen Li*

Main category: cs.RO

TL;DR: 本文通过开发一种具有八条腿、每条腿四个关节的新型蜘蛛机器人，结合3D打印外骨骼和可调刚度关节，研究蜘蛛动态屈腿行为如何增强蛛网振动感知能力，为理解主动感知机制提供了更符合生物真实性的机器人模型。


<details>
  <summary>Details</summary>
Motivation: 蜘蛛在捕食时会动态屈腿以增强蛛网振动感知，但其具体机制因难以在活体动物中测量振动而尚不清楚。

Method: 采用机器人物理建模（robophysical modeling）方法，设计并构建了一种新型八足蜘蛛机器人，具备更真实的腿部形态、更深的屈腿范围、可调刚度的硅胶嵌入式关节及腱驱动系统，并在关节处集成加速度计记录振动。

Result: 新机器人成功复现了先前四足机器人中的关键振动特征，同时显著提升了生物保真度，验证了其作为研究蛛网振动感知调控机制的有效性。

Conclusion: 该机器人平台为探究蜘蛛如何通过肢体行为主动调控振动感知提供了更准确、可实验操控的生物物理模型。

Abstract: Orb-weaving spiders detect prey on a web using vibration sensors at leg joints. They often dynamically crouch their legs during prey sensing, likely an active sensing strategy. However, how leg crouching enhances sensing is poorly understood, because measuring system vibrations in behaving animals is difficult. We use robophysical modeling to study this problem. Our previous spider robot had only four legs, simplified leg morphology, and a shallow crouching range of motion. Here, we developed a new spider robot, with eight legs, each with four joints that better approximated spider leg morphology. Leg exoskeletons were 3-D printed and joint stiffness was tuned using integrated silicone molding with variable materials and geometry. Tendon-driven actuation allowed a motor in the body to crouch all eight legs deeply as spiders do, while accelerometers at leg joints record leg vibrations. Experiments showed that our new spider robot reproduced key vibration features observed in the previous robot while improving biological accuracy. Our new robot provides a biologically more accurate robophysical model for studying how leg behaviors modulate vibration sensing on a web.

</details>


### [119] [A Feature Extraction Pipeline for Enhancing Lightweight Neural Networks in sEMG-based Joint Torque Estimation](https://arxiv.org/abs/2601.16712)
*Kartik Chari,Raid Dokhan,Anas Homsi,Niklas Kueper,Elsa Andrea Kirchner*

Main category: cs.RO

TL;DR: 本文提出了一种基于8通道sEMG信号的特征提取流程，用于预测肘关节和肩关节扭矩，并在有限数据下验证了其与TCN相当的性能。


<details>
  <summary>Details</summary>
Motivation: 为实现机器人辅助康复中对用户关节扭矩的准确预测，以提供个性化辅助。

Method: 构建基于8通道表面肌电信号（sEMG）的特征提取流程，并结合多层感知机（MLP）和时序卷积网络（TCN）进行关节扭矩预测；数据来自单受试者在三种负载条件下的肘肩运动，参考扭矩由质心运动学在静力平衡假设下估算。

Result: 离线分析显示，MLP在肘、前肩、侧肩关节的平均RMSE分别为0.963、1.403、1.434 N·m（五次随机种子），性能与TCN相当。

Conclusion: 所提出的特征提取流程可使结构简单的MLP达到与专为时序建模设计的TCN相近的性能，适用于训练数据受限的临床场景。

Abstract: Robot-assisted rehabilitation offers an effective approach, wherein exoskeletons adapt to users' needs and provide personalized assistance. However, to deliver such assistance, accurate prediction of the user's joint torques is essential. In this work, we propose a feature extraction pipeline using 8-channel surface electromyography (sEMG) signals to predict elbow and shoulder joint torques. For preliminary evaluation, this pipeline was integrated into two neural network models: the Multilayer Perceptron (MLP) and the Temporal Convolutional Network (TCN). Data were collected from a single subject performing elbow and shoulder movements under three load conditions (0 kg, 1.10 kg, and 1.85 kg) using three motion-capture cameras. Reference torques were estimated from center-of-mass kinematics under the assumption of static equilibrium. Our offline analyses showed that, with our feature extraction pipeline, MLP model achieved mean RMSE of 0.963 N m, 1.403 N m, and 1.434 N m (over five seeds) for elbow, front-shoulder, and side-shoulder joints, respectively, which were comparable to the TCN performance. These results demonstrate that the proposed feature extraction pipeline enables a simple MLP to achieve performance comparable to that of a network designed explicitly for temporal dependencies. This finding is particularly relevant for applications with limited training data, a common scenario patient care.

</details>


### [120] [Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators](https://arxiv.org/abs/2601.16866)
*Lucía Güitta-López,Vincenzo Suriani,Jaime Boal,Álvaro J. López-López,Daniele Nardi*

Main category: cs.RO

TL;DR: 本文提出了一种将深度强化学习（DRL）与知识图谱嵌入（KGEs）相结合的新方法，通过向智能体提供语义上下文信息来提升其在机器人控制任务中的学习效率。实验表明，该方法可减少60%的学习时间并提高约15个百分点的任务准确率。


<details>
  <summary>Details</summary>
Motivation: DRL在机器人控制中面临样本效率低、训练耗时长和计算成本高的问题，亟需提升学习效率。

Method: 将知识图谱嵌入（KGEs）与视觉观测融合，构建具备语义感知能力的DRL智能体架构，使智能体在训练中利用环境先验知识。

Result: 在固定及随机目标属性的机器人操作环境中，学习时间最多减少60%，任务准确率提升约15个百分点，且未增加训练时间或计算复杂度。

Conclusion: 引入语义知识（如KGEs）可显著降低DRL的样本复杂度，提升其在机器人应用中的实用性与有效性。

Abstract: Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to {60}{\%} reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications.

</details>


### [121] [A Multimodal Data Collection Framework for Dialogue-Driven Assistive Robotics to Clarify Ambiguities: A Wizard-of-Oz Pilot Study](https://arxiv.org/abs/2601.16870)
*Guangping Liu,Nicholas Hawkins,Billy Madden,Tipu Sultan,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 本文提出了一种多模态数据采集框架，用于收集轮椅与轮椅 mounted 机械臂（WMRA）在对话驱动控制下的自然人机交互数据，以解决现有AI辅助控制中因缺乏含对话模糊性的多模态数据集所导致的发展瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有轮椅与机械臂集成控制系统接口缺乏灵活性，且数据驱动AI方法受限于缺少能反映自然人机交互（尤其是对话模糊性）的多模态数据集。

Method: 设计了一个基于对话协议和双房间Wizard-of-Oz（WoZ）实验设置的多模态数据采集框架，同步记录RGB-D视频、对话音频、IMU信号、末端执行器位姿及全身关节状态共五种模态，覆盖五类辅助任务。

Result: 采集了5名参与者的53次试验 pilot 数据集，并通过运动平滑性分析和用户反馈验证了数据质量；结果表明该框架能有效捕获多种对话模糊类型，支持自然对话驱动交互。

Conclusion: 所提框架适用于扩展构建更大规模数据集，支撑面向模糊性感知的辅助控制算法的学习、基准测试与评估。

Abstract: Integrated control of wheelchairs and wheelchair-mounted robotic arms (WMRAs) has strong potential to increase independence for users with severe motor limitations, yet existing interfaces often lack the flexibility needed for intuitive assistive interaction. Although data-driven AI methods show promise, progress is limited by the lack of multimodal datasets that capture natural Human-Robot Interaction (HRI), particularly conversational ambiguity in dialogue-driven control. To address this gap, we propose a multimodal data collection framework that employs a dialogue-based interaction protocol and a two-room Wizard-of-Oz (WoZ) setup to simulate robot autonomy while eliciting natural user behavior. The framework records five synchronized modalities: RGB-D video, conversational audio, inertial measurement unit (IMU) signals, end-effector Cartesian pose, and whole-body joint states across five assistive tasks. Using this framework, we collected a pilot dataset of 53 trials from five participants and validated its quality through motion smoothness analysis and user feedback. The results show that the framework effectively captures diverse ambiguity types and supports natural dialogue-driven interaction, demonstrating its suitability for scaling to a larger dataset for learning, benchmarking, and evaluation of ambiguity-aware assistive control.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [122] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: 本文扩展了用于因果发现的得分匹配框架，提出了一种基于离散得分函数的新叶节点判别准则，以从离散观测数据中准确推断因果顺序，并提升现有因果发现方法的准确性。


<details>
  <summary>Details</summary>
Motivation: 从纯观测数据中学习有向无环图（DAG）结构在各科学领域仍是长期挑战，尤其针对离散数据缺乏适配的得分匹配方法。

Method: 将原用于连续数据的得分匹配框架扩展至离散数据，提出基于离散得分函数的新型叶节点判别准则，先识别拓扑序，再进行边剪枝恢复图结构。

Result: 在模拟与真实数据实验中，该方法能准确推断真实因果顺序，且所识别的顺序显著提升了多种现有因果发现基线方法在几乎所有设置下的准确性。

Conclusion: 所提离散得分匹配方法为离散数据因果发现提供了理论支撑与实用工具，有效弥补了现有框架在离散场景下的不足。

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [123] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 本研究收集了学生在疫情期间的Fitbit数据（StudentMEH数据集），评估多种生理模态（如心率、睡眠）对抑郁、焦虑和压力的机器学习筛查效果，F1分数最高达0.79，表明可穿戴设备具有连续心理健康监测潜力。


<details>
  <summary>Details</summary>
Motivation: 大学生面临多重压力源，导致焦虑和抑郁高发；现有研究在心理量表种类、生理模态和时序参数多样性方面存在局限，亟需更全面的可穿戴数据驱动筛查方法。

Method: 采集本校学生疫情期间的Fitbit传感器数据（StudentMEH数据集），结合标准化心理量表，采用多种机器学习模型，分别评估心率、睡眠等不同生理模态在抑郁、焦虑和压力筛查中的预测性能，并分析最优数据聚合层级。

Result: 心率模态在压力筛查中F1达0.77，睡眠模态在抑郁筛查中达0.78，焦虑筛查整体最高F1为0.79；证实不同生理模态对不同心理问题具有差异化预测能力。

Conclusion: 可穿戴设备（尤其是心率与睡眠数据）可用于抑郁、焦虑和压力的早期筛查；研究强调需针对具体心理病症选择最优生理模态与数据聚合方式，以支持连续、精准的心理健康监测。

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [124] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 本文提出了一种用于基于数据低维线性投影构建的高斯过程（GP）的新训练目标——投影似然（PL），并提供了其信息损失的闭式表达式；通过实验表明，PL在精度和计算效率上均优于精确GP训练和变分自由能稀疏GP方法。


<details>
  <summary>Details</summary>
Motivation: 解决高斯过程（GP）在中等规模数据集上训练时的计算复杂度高和精度不足的问题，探索更高效且准确的训练目标。

Method: 提出投影似然（PL）训练目标，利用低维线性投影（特别是单位球面上的随机投影）构造GP，并推导其信息损失的闭式表达式；在多种优化器、核函数和中等规模数据集上进行实验评估。

Result: PL在精度和计算效率上均显著优于精确GP训练和变分自由能稀疏GP方法；信息损失可通过单位球面上的随机投影有效降低。

Conclusion: 投影似然（PL）是一种有前景的GP训练目标，在兼顾准确性与计算效率方面展现出优越性，尤其适用于中等规模数据集。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [125] [Analyzing Neural Network Information Flow Using Differential Geometry](https://arxiv.org/abs/2601.16366)
*Shuhang Tan,Jayson Sia,Paul Bogdan,Radoslav Ivanov*

Main category: cs.LG

TL;DR: 本文提出了一种基于Ollivier-Ricci曲率（ORC）的神经网络数据流分析新方法，定义了神经曲率（NC），通过分析激活模式计算边曲率，发现负曲率边为关键瓶颈，正曲率边可安全剪枝；实验表明该方法在MNIST、CIFAR-10/100上比现有剪枝方法能识别更多冗余连接。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络数据流分析多基于信息论，难以直观刻画结构重要性；而图曲率（尤其是ORC）已在交通、生物和社会网络中成功识别关键边，本文旨在将其引入NN分析，提供一种几何视角下的可解释性工具，支撑鲁棒性分析与模型修复。

Method: 1) 将神经网络建模为有向加权图，定义基于Ollivier-Ricci曲率的神经曲率（NC）；2) 利用输入样本的激活模式计算各边的NC值；3) 根据NC符号（负值≈瓶颈，正值≈冗余）对连接重要性排序，并用于结构化剪枝。

Result: 剪枝实验表明：移除负ORC边迅速降低模型精度，而移除正ORC边影响甚微；在MNIST、CIFAR-10和CIFAR-100上的多个模型上，该方法识别出的冗余边数量超过当前主流剪枝方法。

Conclusion: 神经曲率（NC）是一种有效、可解释的神经网络连接重要性度量；基于ORC的数据流分析为符号化NN分析（如鲁棒性验证与模型修复）提供了新的几何基础，并展现出优于现有剪枝方法的冗余识别能力。

Abstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provides a tool for symbolic NN analysis, e.g.,~robustness analysis or model repair. Unlike the standard approach to NN data flow analysis, which is based on information theory, we employ the notion of graph curvature, specifically Ollivier-Ricci curvature (ORC). The ORC has been successfully used to identify important graph edges in various domains such as road traffic analysis, biological and social networks. In particular, edges with negative ORC are considered bottlenecks and as such are critical to the graph's overall connectivity, whereas positive-ORC edges are not essential. We use this intuition for the case of NNs as well: we 1)~construct a graph induced by the NN structure and introduce the notion of neural curvature (NC) based on the ORC; 2)~calculate curvatures based on activation patterns for a set of input examples; 3)~aim to demonstrate that NC can indeed be used to rank edges according to their importance for the overall NN functionality. We evaluate our method through pruning experiments and show that removing negative-ORC edges quickly degrades the overall NN performance, whereas positive-ORC edges have little impact. The proposed method is evaluated on a variety of models trained on three image datasets, namely MNIST, CIFAR-10 and CIFAR-100. The results indicate that our method can identify a larger number of unimportant edges as compared to state-of-the-art pruning methods.

</details>


### [126] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 本文提出了一种单循环、一阶的actor-critic算法，用于求解上层为光滑函数、下层为MDP策略优化的双层优化问题，通过衰减熵正则化实现无偏超梯度估计，并在特定Polyak-Lojasiewicz条件下证明了其有限时间与样本收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有双层优化与强化学习方法常需二阶信息、强正则化或低效嵌套循环，限制了实际应用。

Method: 提出基于惩罚重构的单循环一阶actor-critic算法，在下层RL目标中引入衰减熵正则化，实现渐近无偏的上层超梯度估计；结合新型下层残差分析和特殊Polyak-Lojasiewicz条件进行理论分析。

Result: 理论上证明算法以有限时间与有限样本收敛至原始无正则化双层优化问题的驻点；实验验证了其在GridWorld和RLHF任务上的有效性。

Conclusion: 所提方法克服了传统双层RL优化对二阶信息和强正则化的依赖，实现了高效、无偏且理论可证的单循环优化。

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [127] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 本文构建了基于算法稳定性的RLHF（从人类反馈中进行强化学习）泛化理论，证明在线性奖励模型下，满足特征覆盖条件时，策略模型的经验最优解具有O(n^{-1/2})的泛化界，并可推广至梯度上升类算法。


<details>
  <summary>Details</summary>
Motivation: 尽管RLHF在实践中被广泛使用且效果显著，但其在高维场景下的理论泛化性质尚未被深入探讨。

Method: 基于算法稳定性框架，在线性奖励模型假设下，建立端到端的RLHF泛化分析；引入并依赖‘特征覆盖’条件，推导经验最优解及梯度类算法（GA/SGA）所得参数的泛化界。

Result: 证明了在特征覆盖条件下，策略模型经验最优解的泛化误差上界为O(n^{-1/2})，且该界适用于梯度上升和随机梯度上升算法所得参数。

Conclusion: 本工作为LLM经RLHF后所表现出的良好泛化能力提供了新的理论支撑，弥补了现有基于最大似然一致性的分析与实际端到端训练不一致的缺陷。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [128] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: 本文提出LPCORP框架，通过推理增强预测与置信度驱动的输出校正，有效缓解极端类别不平衡下的罕见事件预测偏差，显著提升精度并在真实场景中实现超50%的成本降低。


<details>
  <summary>Details</summary>
Motivation: 罕见事件预测在医疗、金融等领域至关重要，但极端类别不平衡导致传统模型召回率低、校准差、实用性受限。

Method: 提出两阶段LPCORP框架：第一阶段用推理模型从叙述性输入生成增强预测；第二阶段用轻量逻辑回归分类器基于置信度选择性校正输出，不依赖重采样。

Result: 在医疗和消费服务真实数据集上验证，LPCORP将高度不平衡设置转化为良好平衡状态，保持样本数量不变，显著提升精度（尤其弥补低发生率数据中精度薄弱问题），并实现预防性干预成本降低超50%。

Conclusion: LPCORP无需重采样即可有效缓解罕见事件预测中的流行度偏差，在精度与业务成本效益上均取得实质性改进，具备实际部署价值。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [129] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 本文通过使用带有显式Berry-Esseen误差控制的正态近似，替代传统的Hoeffding不等式，对VC定理的概率部分进行了改进，得到了中等偏差意义下更精确的收敛速率估计。


<details>
  <summary>Details</summary>
Motivation: 改进VC定理中经验概率一致收敛到理论概率的速率估计，特别是在中等偏差区域提升精度。

Method: 用带显式Berry-Esseen误差控制的正态近似替代Hoeffding不等式，重新分析VC定理中的概率部分。

Result: 获得了一个中等偏差意义下的 sharper VC 估计，其主导指数项额外包含因子 $(\varepsilon\sqrt{n})^{-1}$（当 $\varepsilon\sqrt{n}$ 较大时）。

Conclusion: 该方法在保持理论严谨性的同时，提升了VC定理在中等偏差区域的收敛速率刻画精度，为统计学习理论提供了更精细的概率分析工具。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [130] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0 is an open-source clinical deep learning toolkit designed to lower barriers in healthcare AI research by improving reproducibility, accessibility, and efficiency—supporting multimodal clinical data, diverse hardware, and community-driven development.


<details>
  <summary>Details</summary>
Motivation: Difficulty replicating baselines, high computational costs, and required domain expertise hinder clinical AI research.

Method: Development of PyHealth 2.0—a unified, open-source toolkit integrating datasets, tasks, models, interpretability methods, uncertainty quantification, and medical coding standards; optimized for speed and memory; supported by an active community and multi-language interface (e.g., RHealth).

Result: PyHealth 2.0 enables predictive modeling in as few as 7 lines of code, achieves up to 39x faster processing and 20x lower memory usage, supports 15+ datasets, 20+ tasks, 25+ models, and serves 400+ community members with extensive documentation and collaborations.

Conclusion: PyHealth 2.0 establishes an accessible, reproducible, and community-driven foundation for clinical AI research and deployment.

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [131] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: 本文比较了贝叶斯实验设计（BED）中KL散度与Wasserstein距离作为效用函数的优劣，指出Wasserstein距离在先验非信息性时可能产生与信息增益无关的虚假奖励；KL散度在无模型偏差时收敛更快，而Wasserstein距离在存在模型偏差时更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 在贝叶斯实验设计中，效用函数的选择长期存在争议，KL散度虽常用，但Wasserstein距离被提出为替代方案，其适用条件和局限性尚不明确。

Method: 通过一个玩具示例揭示Wasserstein距离的问题，并在经典的源反演问题上系统比较KL散度与Wasserstein距离在顺序BED中的性能。

Result: 发现Wasserstein距离在先验为均匀分布等非信息性情形下，其值受后验主质量位置影响，可能给出虚假奖励；KL散度在无模型偏差时收敛更快，Wasserstein距离在模型偏差显著时更鲁棒。

Conclusion: KL散度与Wasserstein距离各有适用场景，应依据是否存在模型偏差等因素选择合适效用函数，本文为此提供了实践指导。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [132] [Safe Multitask Molecular Graph Networks for Vapor Pressure and Odor Threshold Prediction](https://arxiv.org/abs/2601.16426)
*Shuang Wu,Meijie Wang,Lun Yu*

Main category: cs.LG

TL;DR: 本文研究了气味相关性质建模中的两个重要任务：蒸气压（VP）和气味阈值（OP），提出了一种‘安全多任务’方法，在不损害主任务性能的前提下提升泛化能力，并系统比较了分子图特征与GNN骨干网络。


<details>
  <summary>Details</summary>
Motivation: 提升气味相关性质（如蒸气压VP和气味阈值OP）预测模型在分布外（OOD）场景下的泛化能力，尤其关注分子骨架划分下的鲁棒性。

Method: 采用Bemis-Murcko骨架划分评估OOD性能；引入A20/E17丰富分子图特征；对比GINE与PNA图神经网络；提出‘安全多任务’策略（VP为主任务、OP为辅助任务），结合延迟激活、梯度裁剪与小权重分配。

Result: VP单任务下PNA回归头达验证集MSE≈0.21（归一化空间）；OP单任务使用A20/E17+鲁棒训练达MSE≈0.60–0.61；‘安全多任务’显著提升VP泛化性能且不损害其精度。

Conclusion: A20/E17特征与PNA模型更适配VP/OP建模；‘安全多任务’是一种有效且稳健的多任务学习范式；论文提供了完整可复现实验、消融分析及噪声影响讨论。

Abstract: We investigate two important tasks in odor-related property modeling: Vapor Pressure (VP) and Odor Threshold (OP). To evaluate the model's out-of-distribution (OOD) capability, we adopt the Bemis-Murcko scaffold split. In terms of features, we introduce the rich A20/E17 molecular graph features (20-dimensional atom features + 17-dimensional bond features) and systematically compare GINE and PNA backbones. The results show: for VP, PNA with a simple regression head achieves Val MSE $\approx$ 0.21 (normalized space); for the OP single task under the same scaffold split, using A20/E17 with robust training (Huber/winsor) achieves Val MSE $\approx$ 0.60-0.61. For multitask training, we propose a **"safe multitask"** approach: VP as the primary task and OP as the auxiliary task, using delayed activation + gradient clipping + small weight, which avoids harming the primary task and simultaneously yields the best VP generalization performance. This paper provides complete reproducible experiments, ablation studies, and error-similarity analysis while discussing the impact of data noise and method limitations.

</details>


### [133] [Endless Terminals: Scaling RL Environments for Terminal Agents](https://arxiv.org/abs/2601.16443)
*Kanishk Gandhi,Shivam Garg,Noah D. Goodman,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: 本文提出Endless Terminals——一个全自动、无需人工标注的终端任务生成管道，用于训练自我提升的智能体；通过该管道生成3255个多样化终端任务，仅用简单PPO算法训练即显著提升多个大模型在终端操作任务上的性能，并实现向人工评测基准的正向迁移。


<details>
  <summary>Details</summary>
Motivation: 现有终端基准主要用于评估而非训练，而强化学习需要可扩展的训练环境管道，而非静态数据集；人工构建环境成本高、难以规模化，制约了自改进智能体的发展。

Method: 提出Endless Terminals四阶段自动化管道：1）生成多样化任务描述；2）构建并验证容器化执行环境；3）生成完成性测试；4）基于可解性过滤任务；最终生成3255个覆盖文件操作、日志管理、数据处理、脚本和数据库操作的任务；采用标准PPO算法、二元回合奖励、极简交互循环（无检索、无多智能体协调、无专用工具）进行训练。

Result: 在自建预留开发集上，Llama-3.2-3B准确率从4.0%提升至18.2%，Qwen2.5-7B从10.7%升至53.3%，Qwen3-8B-openthinker-sft从42.6%升至59.0%；在人工构建的TerminalBench 2.0上也取得显著提升，且优于更复杂智能体架构的基线方法。

Conclusion: 当环境规模足够大时，简单的强化学习方法即可有效提升智能体终端操作能力；无需复杂代理架构，高质量、可扩展的自主生成环境是推动自改进智能体发展的关键瓶颈与突破口。

Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.

</details>


### [134] [Brownian ReLU(Br-ReLU): A New Activation Function for a Long-Short Term Memory (LSTM) Network](https://arxiv.org/abs/2601.16446)
*George Awiakye-Marfo,Elijah Agbosu,Victoria Mawuena Barns,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 本文提出了一种基于布朗运动的随机激活函数BrownianReLU，用于提升LSTM在金融时间序列建模中的梯度传播稳定性与预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统激活函数（如ReLU）在处理噪声大、非平稳的金融时间序列时易出现梯度不稳定问题，导致训练困难（如'死亡ReLU'）。

Method: 设计基于布朗运动的随机激活函数BrownianReLU，结合蒙特卡洛模拟实现对负输入的平滑自适应响应，并将其嵌入LSTM网络中；在苹果、GCB、标普500等金融时间序列及LendingClub贷款数据上进行回归与分类实验。

Result: BrownianReLU在多个数据集上显著降低MSE、提升R²；在分类任务中虽ROC-AUC受限，但明显改善准确率与敏感性的权衡。

Conclusion: BrownianReLU能有效增强LSTM在金融时序建模中的学习稳定性与泛化能力，为噪声非平稳序列建模提供了新思路。

Abstract: Deep learning models are effective for sequential data modeling, yet commonly used activation functions such as ReLU, LeakyReLU, and PReLU often exhibit gradient instability when applied to noisy, non-stationary financial time series. This study introduces BrownianReLU, a stochastic activation function induced by Brownian motion that enhances gradient propagation and learning stability in Long Short-Term Memory (LSTM) networks. Using Monte Carlo simulation, BrownianReLU provides a smooth, adaptive response for negative inputs, mitigating the dying ReLU problem. The proposed activation is evaluated on financial time series from Apple, GCB, and the S&P 500, as well as LendingClub loan data for classification. Results show consistently lower Mean Squared Error and higher $R^2$ values, indicating improved predictive accuracy and generalization. Although ROC-AUC metric is limited in classification tasks, activation choice significantly affects the trade-off between accuracy and sensitivity, with Brownian ReLU and the selected activation functions yielding practically meaningful performance.

</details>


### [135] [On the Expressive Power of Floating-Point Transformers](https://arxiv.org/abs/2601.16450)
*Sejun Park,Yeachan Park,Geonho Hwang*

Main category: cs.LG

TL;DR: 本文研究了浮点数实现下的Transformer模型的表示能力，发现其可表示非置换等变函数，且在序列长度受限时能表示所有置换等变函数，但长度较大时则不能；同时指出加性位置编码会损害其表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有对Transformer表达能力的研究基于实数参数和精确运算，而实际计算机实现只能使用有限精度浮点数和存在舍入误差的不精确运算，因此需重新评估其真实表示能力。

Method: 理论分析与证明，包括构造性论证浮点Transformer可表示非置换等变函数、证明其在有界和无界序列长度下的置换等变函数表示能力边界，以及分析位置编码对表示能力的影响。

Result: 1）浮点Transformer无需位置编码即可表示某些非置换等变函数；2）当序列长度有界时可表示所有置换等变函数，但长度足够大时则不能；3）揭示了其内在最小等变结构；4）任意非平凡加性位置编码均会削弱其表示能力。

Conclusion: 浮点实现显著改变了Transformer的理论表示性质，使其不再严格置换等变，且位置编码的设计需谨慎以避免损害表示能力。

Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.

</details>


### [136] [On the Effects of Adversarial Perturbations on Distribution Robustness](https://arxiv.org/abs/2601.16464)
*Yipei Wang,Zhaoying Pan,Xiaoqian Wang*

Main category: cs.LG

TL;DR: 本文理论分析了对抗鲁棒性与分布鲁棒性之间的权衡关系，指出ℓ∞扰动在中等偏差数据上可提升分布鲁棒性，且当简洁性偏差促使模型依赖核心特征（即特征可分性更高）时，该增益在高度偏斜数据上仍存在；强调特征可分性在理解二者权衡中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 已有研究发现对抗鲁棒性与分布鲁棒性之间存在权衡，对抗训练可能增强对虚假特征的依赖，损害分布鲁棒性（尤其在少数子群上），需深入理解其内在机制。

Method: 通过理论分析建模扰动数据上的训练过程，提出每步对抗训练的可处理代理，并研究ℓ∞扰动、数据偏差程度与特征可分性对两类鲁棒性的影响。

Result: 发现ℓ∞扰动在中等偏差数据上可提升分布鲁棒性；当简洁性偏差导致模型依赖核心特征（高特征可分性）时，该提升在高度偏斜数据上依然存在；特征可分性是调和或缓解权衡的关键因素。

Conclusion: 对抗与分布鲁棒性的权衡并非绝对，其表现高度依赖于特征可分性；忽略该因素可能导致对鲁棒性的错误判断，需在鲁棒性评估与算法设计中显式考虑特征结构。

Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\ell_\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.

</details>


### [137] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: 本文提出了一种新的自监督学习框架R-NCE，通过整合FreeSurfer特征并最大化增强不变信息，在阿尔茨海默病（AD）的生物标志物发现中超越了传统手工特征和现有SSL方法，并验证其生物学相关性。


<details>
  <summary>Details</summary>
Motivation: 发现敏感且具有生物学基础的生物标志物对阿尔茨海默病（AD）的早期检测与监测至关重要；而现有自监督学习（SSL）方法在AD相关任务中表现不如传统手工MRI特征（如皮层厚度），亟需更优方法。

Method: 提出残差噪声对比估计（R-NCE）框架：在SSL中融合辅助FreeSurfer特征，同时挖掘额外的增强不变信息；进一步基于R-NCE提取脑龄差距（BAG）并开展全基因组关联分析（GWAS）。

Result: R-NCE在AD分类、进展预测及淀粉样蛋白状态预测等多个基准上均优于传统特征和现有SSL方法；R-NCE-BAG表现出高遗传力，并显著关联MAPT与IRAG1基因，且在星形胶质细胞和少突胶质细胞中富集。

Conclusion: R-NCE能从常规结构MRI中自动学习更具判别力与生物学意义的生物标志物，为AD无创早期识别与机制研究提供了新范式。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [138] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 本文提出了一种面向分类数据的多粒度聚类方法MCDC，包含MGCPL算法和CAME策略，能自动挖掘嵌套式多粒度簇结构，具有鲁棒性、可扩展性和高效性。


<details>
  <summary>Details</summary>
Motivation: 分类数据缺乏明确定义的距离度量，其隐式离散距离空间中普遍存在嵌套粒度簇效应，给聚类分析带来挑战。

Method: 提出多粒度竞争惩罚学习（MGCPL）算法，使潜在簇分阶段自适应调整；结合基于MGCPL编码的簇聚合（CAME）策略，先编码再聚类。

Result: MCDC在多个真实公开数据集上显著优于现有最先进方法，具备线性时间复杂度，可扩展至大规模数据，并适用于分布式计算的预划分。

Conclusion: MCDC能有效挖掘分类数据中自然存在的嵌套多粒度簇分布，兼具鲁棒性、高效性与可扩展性，为分类数据聚类提供了新范式。

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [139] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 本文提出了一种名为CRISPNAM-FG的内在可解释生存模型，用于竞争风险下的生存分析，结合神经加性模型（NAMs）结构与Fine-Gray公式，在保持高预测性能的同时提供透明、可审计的预测。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在生存建模中预测性能优异，但其黑箱特性限制了在临床实践中的应用，亟需兼具高性能与高可解释性的模型。

Method: 基于神经加性模型（NAMs）结构，为每种风险引入独立投影向量，采用Fine-Gray公式预测累积发生函数（CIF），构建内在可解释的CRISPNAM-FG模型。

Result: 在多个基准数据集及29家安大略医院糖尿病足并发症真实数据（2016–2023）上验证，模型性能媲美其他深度生存模型，并通过形状函数和特征重要性图提供直观可解释性。

Conclusion: CRISPNAM-FG成功平衡了预测准确性与内在可解释性，为临床决策支持提供了可信、可审计的AI工具。

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [140] [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)
*Zekai Chen,Kairui Yang,Xunkai Li,Henan Sun,Zhihan Zhang,Jia Li,Qiangqiang Dai,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 本文提出BoostFGL框架，通过客户端节点增强、拓扑增强和服务器端模型增强三机制，提升联邦图学习中对弱势节点群体的公平性，同时保持整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦图学习方法虽整体准确率高，但掩盖了对弱势节点群体的严重性能下降，其根源在于标签偏斜、拓扑混淆和聚合稀释三方面。

Method: 提出BoostFGL框架，包含客户端节点 boosting（强调服务不足节点）、客户端拓扑 boosting（优化消息传播结构）和服务器端模型 boosting（难度与可靠性感知的聚合）。

Result: 在9个数据集上实验表明，BoostFGL显著提升公平性，Overall-F1提高8.43%，同时保持与强基线相当的整体性能。

Conclusion: BoostFGL有效缓解联邦图学习中的群体不公平问题，为公平性驱动的分布式图学习提供了新范式。

Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.

</details>


### [141] [kNN-Graph: An adaptive graph model for $k$-nearest neighbors](https://arxiv.org/abs/2601.16509)
*Jiaye Li,Gang Chen,Hang Xu,Shichao Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于自适应图模型的kNN加速方法，将邻居选择与加权计算移至训练阶段，结合HNSW图与预计算投票机制，在不损失精度的前提下实现实时推理。


<details>
  <summary>Details</summary>
Motivation: kNN在大规模应用中受限于推理速度与精度之间的权衡，现有近似方法常牺牲精度且缺乏对最优k值的自适应选择能力。

Method: 提出一种自适应图模型，融合分层可导航小世界（HNSW）图与预计算投票机制，高层用于快速导航，底层编码节点特异性决策边界并支持自适应邻居数量。

Result: 在六个数据集上对比八个SOTA基线，显著提升推理速度至实时水平，同时保持分类精度不下降。

Conclusion: 该方法为kNN推理瓶颈提供了可扩展、鲁棒的解决方案，建立了图结构非参数学习的新范式。

Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.

</details>


### [142] [Finite-Time Analysis of Gradient Descent for Shallow Transformers](https://arxiv.org/abs/2601.16514)
*Enes Arda,Semih Cayci,Atilla Eryilmaz*

Main category: cs.LG

TL;DR: 本文分析了浅层Transformer在核区域内的训练行为，发现其宽度需求仅随样本量对数增长，且优化误差与序列长度无关，但内存需求随序列长度增加。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer为何表现优异仍具挑战性，因其非凸优化景观复杂。

Method: 分析具有m个独立头的浅层Transformer，在核区域内使用投影梯度下降进行训练。

Result: （i）非渐近保证所需的宽度仅随样本量n对数增长；（ii）优化误差与序列长度T无关，而RNN的优化误差可能随T指数增长。

Conclusion: Transformer在优化稳定性上优于RNN，但需权衡更高的内存开销；理论结果在师生设置中得到数值验证。

Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.

</details>


### [143] [Rethinking Large Language Models For Irregular Time Series Classification In Critical Care](https://arxiv.org/abs/2601.16516)
*Feixiang Zheng,Yu Wu,Cecilia Mascolo,Ting Dang*

Main category: cs.LG

TL;DR: 本文研究了大语言模型（LLM）在ICU不规则时间序列建模中的应用，发现显式建模不规则性的编码器比对齐策略更重要，但LLM方法训练耗时长、小样本性能差。


<details>
  <summary>Details</summary>
Motivation: 现有LLM用于时间序列建模的研究尚未充分探索其在高缺失率、不规则的ICU时间序列数据上的有效性。

Method: 构建系统化测试平台，评估不同时间序列编码器与多模态对齐策略对多种LLM-based TSM方法的影响，并在ICU基准数据集上与强监督/自监督基线对比。

Result: 编码器设计比对齐策略更关键；显式建模不规则性的编码器使平均AUPRC提升12.8%；最佳融合式语义对齐策略仅比交叉注意力提升2.9%；LLM方法训练时间超最优不规则监督模型10倍，且小样本下表现更差。

Conclusion: LLM在ICU不规则时间序列建模中具有潜力，但当前存在训练效率低、数据需求高、小样本泛化弱等明显局限。

Abstract: Time series data from the Intensive Care Unit (ICU) provides critical information for patient monitoring. While recent advancements in applying Large Language Models (LLMs) to time series modeling (TSM) have shown great promise, their effectiveness on the irregular ICU data, characterized by particularly high rates of missing values, remains largely unexplored. This work investigates two key components underlying the success of LLMs for TSM: the time series encoder and the multimodal alignment strategy. To this end, we establish a systematic testbed to evaluate their impact across various state-of-the-art LLM-based methods on benchmark ICU datasets against strong supervised and self-supervised baselines. Results reveal that the encoder design is more critical than the alignment strategy. Encoders that explicitly model irregularity achieve substantial performance gains, yielding an average AUPRC increase of $12.8\%$ over the vanilla Transformer. While less impactful, the alignment strategy is also noteworthy, with the best-performing semantically rich, fusion-based strategy achieving a modest $2.9\%$ improvement over cross-attention. However, LLM-based methods require at least 10$\times$ longer training than the best-performing irregular supervised models, while delivering only comparable performance. They also underperform in data-scarce few-shot learning settings. These findings highlight both the promise and current limitations of LLMs for irregular ICU time series. The code is available at https://github.com/mHealthUnimelb/LLMTS.

</details>


### [144] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 本文提出DANCE，一种用于文本属性图联邦学习（TAG-FGL）的新范式，通过轮次级、模型在环的图凝练（GC）缓解LLM开销与性能权衡，并通过可追溯的证据包提升可解释性，在多个数据集上显著提升准确率与效率。


<details>
  <summary>Details</summary>
Motivation: 现有文本属性图联邦学习（TAG-FGL）方法面临三大挑战：LLM处理长文本带来的高开销、固定式图凝练导致的客户端非自适应与性能次优、以及LLM凝练过程缺乏可解释性与溯源能力。

Method: 提出DANCE框架：1）采用轮次级、模型在环（model-in-the-loop）的动态图凝练，利用最新全局模型指导每轮本地凝练；2）构建可本地检验的‘证据包’（evidence packs），显式记录预测所依赖的邻居节点及原始文本片段，保障可解释性与可审计性。

Result: 在8个TAG数据集上，DANCE在8%凝练比率下准确率提升2.33%，令牌消耗比基线减少33.42%。

Conclusion: DANCE有效平衡了TAG-FGL中效率、性能与可解释性三者关系，为LLM赋能的联邦图学习提供了更实用、可靠的新范式。

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [145] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: 本文提出SARE方法，通过目标化min-max优化和Targeted-SAM机制，实现对多模态大模型中物体幻觉的几何稳定去学习，显著提升幻觉抑制的鲁棒性和持久性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型易产生物体幻觉，现有去学习方法存在结构脆弱性，仅实现表面抑制，幻觉在轻量再学习后会灾难性复发。

Method: 提出SARE框架，将去学习建模为针对幻觉概念的目标化min-max优化问题，并引入Targeted-SAM机制，在损失曲面中显式压平幻觉相关区域，以增强对参数扰动的鲁棒性。

Result: SARE在擦除效果上显著优于基线方法，同时保持生成质量；尤其在面对再学习和参数更新时，仍能持久抑制幻觉，验证了几何稳定化的有效性。

Conclusion: 几何稳定性是实现可靠、持久幻觉消除的关键，SARE为多模态大模型可信性提升提供了新范式。

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [146] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 本文研究了高频键碰撞是否是Engram风格条件记忆的主要瓶颈，通过引入无碰撞的Engram-Nine架构发现：消除碰撞并不总能降低验证损失；相反，碰撞可能起到隐式正则化作用；真正的瓶颈可能在于门控机制中的信用分配问题，而非索引精度。


<details>
  <summary>Details</summary>
Motivation: 探究高频键碰撞是否为Engram-style条件记忆性能瓶颈，并验证消除碰撞是否必然提升模型训练效果。

Method: 提出Engram-Nine——一种无碰撞热层扩展架构，使用最小完美哈希函数（MPHF）映射高频n-gram，保留原多头哈希查找作为冷层；在严格等参数条件下进行对比；采用路径分层评估（hot/cold loss分解）与门控行为分析。

Result: 1）无碰撞设计未一致改善验证损失；2）发现'hot-to-cold优势翻转'现象，且无碰撞配置翻转更早，表明碰撞具隐式正则化作用；3）门控存在匹配失衡：门持续偏好高损失的hot位置。

Conclusion: 单纯提升查找精度（如消除碰撞）不足以改善训练；主要限制可能在于门控的信用分配机制；碰撞引入的噪声具有有益正则化效应，不应被简单移除。

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [147] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: 本文提出JORC-UMAP，通过引入Ollivier-Ricci曲率几何先验和Jaccard相似性拓扑先验改进UMAP，缓解其因局部欧氏假设导致的拓扑撕裂与结构坍塌问题，在保持计算效率的同时提升流形结构保真度。


<details>
  <summary>Details</summary>
Motivation: UMAP在高维数据可视化中广泛应用，但其局部欧氏距离假设常无法准确刻画流形内在几何，导致拓扑撕裂和结构坍塌；作者指出其对k近邻图的敏感性是关键原因。

Method: 引入Ollivier-Ricci曲率作为几何先验，强化几何瓶颈处的边、削弱冗余连接；为缓解曲率估计对噪声敏感的问题，进一步融合基于Jaccard相似性的拓扑先验以保障邻域一致性，从而构建改进的JORC-UMAP方法。

Result: 在合成与真实数据集上的实验表明，JORC-UMAP相比标准UMAP及其他降维方法，显著降低撕裂与坍塌现象，SVM分类精度与三元组保持分数更高，同时维持良好计算效率。

Conclusion: JORC-UMAP是一种几何感知的UMAP增强方法，能更忠实地还原数据内在流形结构，提升可视化质量。

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [148] [Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow of Distinguishability](https://arxiv.org/abs/2601.16563)
*Vasileios Sevetlidis,George Pavlidis*

Main category: cs.LG

TL;DR: 本文提出将神经网络训练视为一个'过程张量'，并引入一种基于'可区分性反向流动'的模型无关训练记忆见证者，实证表明实际SGD训练过程具有非马尔可夫性。


<details>
  <summary>Details</summary>
Motivation: 揭示实际神经网络训练（如SGD）中隐含的时序依赖与记忆效应，挑战其常被理想化为马尔可夫过程的假设。

Method: 将训练建模为多时刻映射（过程张量），设计两步干预协议，通过比较单/双干预后模型输出分布差异（TV/JS/Hellinger距离）定义反向流动Δ_BF；引入'因果断点'（重置优化器状态）验证记忆来源。

Result: 观测到一致显著的正向反向流动（Δ_BF > 0），该效应随动量增大、批量重叠增加、微步增多而增强，并在优化器状态重置后消失；见证者鲁棒、廉价、无需修改模型结构。

Conclusion: 提供了首个原理性、可计算、模型无关的训练记忆测量工具，证实实用SGD偏离马尔可夫理想，为优化器、课程与调度的比较提供统一实证框架。

Abstract: This work proposes neural training as a \emph{process tensor}: a multi-time map that takes a sequence of controllable instruments (batch choices, augmentations, optimizer micro-steps) and returns an observable of the trained model. Building on this operational lens, we introduce a simple, model-agnostic witness of training memory based on \emph{back-flow of distinguishability}. In a controlled two-step protocol, we compare outcome distributions after one intervention versus two; the increase $Δ_{\mathrm{BF}} = D_2 - D_1>0$ (with $D\in\{\mathrm{TV}, \mathrm{JS}, \mathrm{H}\}$ measured on softmax predictions over a fixed probe set) certifies non-Markovianity. We observe consistent positive back-flow with tight bootstrap confidence intervals, amplification under higher momentum, larger batch overlap, and more micro-steps, and collapse under a \emph{causal break} (resetting optimizer state), directly attributing the effect to optimizer/data-state memory. The witness is robust across TV/JS/Hellinger, inexpensive to compute, and requires no architectural changes. We position this as a \emph{measurement} contribution: a principled diagnostic and empirical evidence that practical SGD deviates from the Markov idealization. An exploratory case study illustrates how the micro-level signal can inform curriculum orderings. "Data order matters" turns into a testable operator with confidence bounds, our framework offers a common stage to compare optimizers, curricula, and schedules through their induced training memory.

</details>


### [149] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 本文提出了一种基于大语言模型（LLM）的无需训练的上下文学习框架kNN-ICL，用于在数据稀缺环境下预测早期初创企业成功与否，仅需少量标注样例（如50个），且性能优于传统监督学习方法。


<details>
  <summary>Details</summary>
Motivation: VC机构面临早期初创企业成功预测难的问题，主因是标注数据极度稀缺（通常仅有几十个案例），限制了传统机器学习方法的应用。

Method: 提出kNN-ICL框架：一种基于k近邻的上下文学习方法，利用Crunchbase真实初创资料，在LLM中动态选取最相似的历史成功/失败案例作为提示示例，无需微调或训练。

Result: 在真实数据上，kNN-ICL显著优于监督学习基线和普通上下文学习；仅用50个标注示例即可达到高平衡准确率。

Conclusion: 上下文学习可作为数据稀缺场景下VC决策的有效工具，为小样本创业预测提供了新范式。

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [150] [Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland](https://arxiv.org/abs/2601.16592)
*Vinicius Pozzobon Borin,Jean Michel de Souza Sant'Ana,Usama Raheel,Nurul Huda Mahmood*

Main category: cs.LG

TL;DR: 本文构建了首个公开的芬兰铁路运营与气象数据融合数据集（2018–2024），涵盖3850万条记录、28个特征，支持延迟预测（XGBoost MAE=2.73分钟）、天气影响分析和基础设施脆弱性评估。


<details>
  <summary>Details</summary>
Motivation: 现有铁路数据集极少整合气象信息，尤其在易受天气影响的北欧地区；亟需高质量、时空对齐的多源融合数据支撑可靠性研究。

Method: 融合芬兰Digitraffic运营数据与209个气象站观测数据，采用Haversine距离进行时空对齐；引入空间回退填补缺失值、周期性时间编码、气象数据鲁棒缩放等预处理方法；构建28维特征集并开展XGBoost延迟预测基线实验。

Result: 发现冬季延迟率超25%，高延迟走廊集中于芬兰中北部；XGBoost模型在站点级延迟预测中MAE达2.73分钟；数据集已开源，支持延迟预测、气象归因分析与基础设施脆弱性制图。

Conclusion: 该数据集填补了北欧铁路-气象融合数据空白，经系统预处理与验证，具备强实用性与可扩展性，为铁路智能运维与气候韧性研究提供了关键基础资源。

Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.

</details>


### [151] [E2Former-V2: On-the-Fly Equivariant Attention with Linear Activation Memory](https://arxiv.org/abs/2601.16622)
*Lin Huang,Chengxiang Huang,Ziang Wang,Yiyue Du,Chu Wang,Haocheng Lu,Yunyang Li,Xiaoli Liu,Arthur Jiang,Jia Zhang*

Main category: cs.LG

TL;DR: 本文提出了E2Former-V2，一种结合代数稀疏性与硬件感知执行的可扩展等变图神经网络架构，通过EAAS方法和On-the-Fly等变注意力机制显著提升计算效率，实现20倍TFLOPS提升，同时保持预测性能。


<details>
  <summary>Details</summary>
Motivation: 主流等变图神经网络因显式构建几何特征或在每条边上进行密集张量积而面临严重可扩展性瓶颈。

Method: 提出Equivariant Axis-Aligned Sparsification（EAAS），基于Wigner-6j卷积与SO(3)→SO(2)基变换，将密集张量收缩转为稀疏奇偶重索引；并设计On-the-Fly Equivariant Attention，通过定制Triton融合核消除边张量存储、最大化SRAM利用。

Result: 在SPICE和OMol25数据集上，E2Former-V2保持与现有方法相当的预测精度，同时大幅加速推理；TFLOPS达标准实现的20倍；可在通用GPU平台上高效训练大型等变Transformer。

Conclusion: 代数稀疏性与硬件感知优化可有效突破等变模型的计算瓶颈，使大规模等变Transformer在普通GPU上实用化成为可能。

Abstract: Equivariant Graph Neural Networks (EGNNs) have become a widely used approach for modeling 3D atomistic systems. However, mainstream architectures face critical scalability bottlenecks due to the explicit construction of geometric features or dense tensor products on \textit{every} edge. To overcome this, we introduce \textbf{E2Former-V2}, a scalable architecture that integrates algebraic sparsity with hardware-aware execution. We first propose \textbf{E}quivariant \textbf{A}xis-\textbf{A}ligned \textbf{S}parsification (EAAS). EAAS builds on Wigner-$6j$ convolution by exploiting an $\mathrm{SO}(3) \rightarrow \mathrm{SO}(2)$ change of basis to transform computationally expensive dense tensor contractions into efficient, sparse parity re-indexing operations. Building on this representation, we introduce \textbf{On-the-Fly Equivariant Attention}, a fully node-centric mechanism implemented via a custom fused Triton kernel. By eliminating materialized edge tensors and maximizing SRAM utilization, our kernel achieves a \textbf{20$\times$ improvement in TFLOPS} compared to standard implementations. Extensive experiments on the SPICE and OMol25 datasets demonstrate that E2Former-V2 maintains comparable predictive performance while notably accelerating inference. This work demonstrates that large equivariant transformers can be trained efficiently using widely accessible GPU platforms. The code is avalible at https://github.com/IQuestLab/UBio-MolFM/tree/e2formerv2.

</details>


### [152] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: 本文提出了一种名为DPAD的模型无关辅助框架，通过动态双原型库（DDP）和双路径上下文感知路由（DPC）机制，实现时间序列中常见与罕见模式的解耦与自适应利用，并引入解耦引导损失（DGLoss）提升预测性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以动态解耦并利用时间序列中复杂交织的时序模式，导致学习到静态、平均化的表征，缺乏上下文感知能力。

Method: 提出DPAD框架，包括：1）动态双原型库（DDP），含具有强时序先验的通用模式库和动态记忆关键罕见事件的稀有模式库；2）双路径上下文感知路由（DPC）机制，选择性检索上下文相关模式表示；3）解耦引导损失（DGLoss），确保各原型库专业化且覆盖全面。

Result: 在多个真实世界基准数据集上，DPAD显著且一致地提升了多种SOTA预测模型的性能与可靠性。

Conclusion: DPAD是一种有效、通用的时间序列预测增强方法，能实现模式解耦与上下文自适应，为时序建模提供了新思路。

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [153] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: 本文提出了一种名为Probabilistically Safe CEs (PSCE)的新方法，用于生成在模型更新下仍保持高置信度和低预测方差的反事实解释，并基于贝叶斯原理提供形式化的概率保证。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释在模型频繁更新的实际场景中容易失效或不可靠，亟需具备鲁棒性和可靠性保障的新方法。

Method: 基于贝叶斯原理，设计满足δ-安全（高预测置信度）和ε-鲁棒（低预测方差）的反事实生成方法，将不确定性感知约束嵌入优化框架，并定义⟨δ, ε⟩-集合以保证理论性质。

Result: 在多个数据集上的实验表明，PSCE生成的反事实解释比当前最优贝叶斯CE方法更合理、更具判别性，且在模型变化下具有可证明的鲁棒性。

Conclusion: PSCE为动态模型环境下的可解释AI提供了兼具理论保证与实用性能的反事实解释新范式。

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [154] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 本文提出了一种利用动态请求专家知识（包括LLM）进行因果发现算法集成的灵活模型平均方法，以应对现实医疗场景中算法假设不满足和专家知识依赖的问题，并在干净与噪声数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 因果关系对医疗健康至关重要，但现有因果发现算法繁多且无明确最优选择，同时现实场景常违反算法假设，需依赖专家知识。

Method: 提出一种基于动态请求专家知识（如LLM）的模型平均方法，集成多种因果发现算法。

Result: 实验表明该方法在使用不完美专家（如LLM）时仍有效，适用于干净和噪声数据；并分析了专家正确率影响及LLM在临床因果发现中的能力。

Conclusion: 动态调用专家知识的集成方法是提升因果发现鲁棒性与实用性的可行路径，尤其适用于医疗等高专业门槛领域。

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [155] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 本文提出了一种用于深度学习中带严格约束优化问题的序列罚方法，并证明了其在合理假设下的收敛性，实验验证了其在图像处理任务中的实用性。


<details>
  <summary>Details</summary>
Motivation: 许多学习任务中，对单个数据样本处理的特定要求应被形式化为优化问题中的严格约束，而非任意惩罚项。

Method: 提出一种基于序列罚法的算法，用于处理深度学习中的约束优化问题，并提供收敛性保证。

Result: 理论分析表明该算法在深度学习场景下具有合理的收敛性保证；图像处理实验验证了其实际可行性。

Conclusion: 序列罚方法是一种可行且有效的处理深度学习中严格约束优化问题的方案。

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [156] [Uncertainty propagation through trained multi-layer perceptrons: Exact analytical results](https://arxiv.org/abs/2601.16830)
*Andrew Thompson,Miles McCrory*

Main category: cs.LG

TL;DR: 本文给出了单隐层ReLU激活函数的多层感知机（MLP）在输入为多元高斯分布时，输出均值和方差的精确解析表达式，无需级数展开。


<details>
  <summary>Details</summary>
Motivation: 以往方法常依赖于级数展开来近似传播不确定性，但存在精度和适用范围限制；本文旨在推导出无需近似、适用于该特定网络结构的精确传播公式。

Method: 基于ReLU激活函数的分段线性特性和高斯输入的性质，通过概率分析与解析积分，严格推导出单隐层MLP输出的均值与方差的闭式表达式。

Result: 得到了输入为多元高斯分布时，单隐层ReLU-MLP输出的均值和方差的精确解析公式，不依赖任何近似或级数展开。

Conclusion: 该工作为神经网络不确定性传播提供了严格且实用的理论工具，特别适用于需精确量化预测不确定性的场景，如贝叶斯神经网络或安全关键系统。

Abstract: We give analytical results for propagation of uncertainty through trained multi-layer perceptrons (MLPs) with a single hidden layer and ReLU activation functions. More precisely, we give expressions for the mean and variance of the output when the input is multivariate Gaussian. In contrast to previous results, we obtain exact expressions without resort to a series expansion.

</details>


### [157] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: 本文提出了一种基于注意力机制的神经过程（ANPs）方法，用于NASA GEDI任务中稀疏LiDAR数据的生物量制图，通过结合局部观测与地理空间基础模型嵌入，实现了更准确且校准良好的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法（如随机森林、XGBoost）在壁到壁生物量制图中未能有效建模空间异质性导致的不确定性，尤其混淆了集成方差与偶然不确定性，并忽略局部空间上下文。

Method: 引入Attentive Neural Processes（ANPs），一种概率元学习框架，显式地以局部观测集和地理空间基础模型嵌入为条件，学习灵活的空间协方差函数以自适应调整不确定性估计。

Result: 在五大生物群系（热带雨林、北方林、高山生态系统等）上验证，ANPs在保持竞争性预测精度的同时实现近乎理想的不确定性校准，并支持少样本跨区域迁移。

Conclusion: ANPs为大陆尺度地球观测提供了一种可扩展、理论严谨的替代方案，克服了传统集成方法在不确定性建模上的根本缺陷。

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [158] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 本文展示了人类与大语言模型（LLM）协作在理论计算机科学开放问题上的强大能力，特别是在组合优化中通过改进FunSearch算法输出，构造出针对多种经典问题的新型对抗实例，从而获得多年未突破的最优下界。


<details>
  <summary>Details</summary>
Motivation: 解决理论计算机科学中长期停滞的组合优化问题下界，尤其是标准启发式算法的最坏情况性能分析缺乏进展。

Method: 基于FunSearch算法生成的初始解，通过人类专家反复迭代、验证和数学精炼，构造针对层次k-中位数聚类、装箱问题、背包问题及Lovász汽油问题推广形式的对抗实例。

Result: 获得了多个经典问题的最新最优下界，其中部分结果是十余年来首次实质性突破；验证了人类-LLM协同模式在数学构造中的有效性。

Conclusion: LLM可提供关键初始模式，但人类专家在数学严谨性、洞察力和构造优化中不可替代；二者协同是推动理论研究的新范式。

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [159] [Provably Learning Attention with Queries](https://arxiv.org/abs/2601.16873)
*Satwik Bhattamishra,Kulin Shah,Michael Hahn,Varun Kanade*

Main category: cs.LG

TL;DR: 本文研究了在仅有黑盒输出访问权限的情况下学习基于Transformer的序列模型的问题，提出了针对单头softmax注意力回归器的精确学习算法，并扩展到单层Transformer；同时设计了适用于小头维度的随机化压缩感知算法，分析了噪声环境下的鲁棒性，并指出多头注意力参数在一般情况下不可识别。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，模型常以黑盒形式提供（如API服务），无法获取内部参数或梯度，仅能通过输入查询获得输出。因此，如何仅凭输出反馈高效、准确地逆向推断Transformer类模型的结构与参数，是一个重要且具有挑战性的问题。

Method: 采用自适应查询策略，结合线性代数分析、压缩感知理论和鲁棒估计方法：对单头softmax注意力提出O(d²)精确学习算法；利用FFN可学习性将其推广至单层Transformer；针对小头维数r≪d设计O(rd)随机压缩感知算法；在噪声下引入范数与间隔条件进行ε精度参数估计；并通过构造反例证明多头注意力的非可识别性。

Result: 1) 单头softmax注意力可在O(d²)次查询内被精确学习；2) 若ReLU前馈网络可学习，则单层单头Transformer亦可学习；3) 小头维数下可用O(rd)次查询学习；4) 在加性噪声下仍能以多项式查询数实现ε精度估计；5) 多头注意力在纯值查询下参数不可识别。

Conclusion: 单头注意力结构具备良好的可学习性，但多头注意力在无额外假设时无法仅从输出唯一确定参数，揭示了模型结构对逆向工程能力的关键影响；研究为黑盒模型审计、知识蒸馏与对抗攻防提供了理论基础。

Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.

</details>


### [160] [Theory of Minimal Weight Perturbations in Deep Networks and its Applications for Low-Rank Activated Backdoor Attacks](https://arxiv.org/abs/2601.16880)
*Bethan Evans,Jared Tanner*

Main category: cs.LG

TL;DR: 本文推导了深度神经网络（DNN）为实现特定输出变化所需的最小范数权重扰动，并分析其影响因素；对比单层精确公式与多层Lipschitz鲁棒性保证，发现二者量级相当；并将结果应用于精度调制触发的后门攻击，给出可证明的压缩阈值，并验证低秩压缩可激活隐性后门且保持高精度。


<details>
  <summary>Details</summary>
Motivation: 理解DNN对参数扰动的敏感性，为后门攻击与防御提供理论依据和可验证保障。

Method: 推导单层最小范数权重扰动的解析表达式，结合Lipschitz常数分析多层鲁棒性，并将其应用于精度调制型后门攻击建模与压缩阈值分析。

Result: 获得层敏感性由反向传播间隔主导的结论；给出后门攻击失效的可证明压缩阈值；实证表明低秩压缩可在保持全精度准确率的同时可靠激活潜在后门。

Conclusion: 最小扰动公式与Lipschitz界具有同等量级有效性；所提理论可支撑对后门攻击的可验证防御与鲁棒性量化评估。

Abstract: The minimal norm weight perturbations of DNNs required to achieve a specified change in output are derived and the factors determining its size are discussed. These single-layer exact formulae are contrasted with more generic multi-layer Lipschitz constant based robustness guarantees; both are observed to be of the same order which indicates similar efficacy in their guarantees. These results are applied to precision-modification-activated backdoor attacks, establishing provable compression thresholds below which such attacks cannot succeed, and show empirically that low-rank compression can reliably activate latent backdoors while preserving full-precision accuracy. These expressions reveal how back-propagated margins govern layer-wise sensitivity and provide certifiable guarantees on the smallest parameter updates consistent with a desired output shift.

</details>


### [161] [Multigrade Neural Network Approximation](https://arxiv.org/abs/2601.16884)
*Shijun Zhang,Zuowei Shen,Yuesheng Xu*

Main category: cs.LG

TL;DR: 本文提出多级深度学习（MGDL）框架，通过逐级训练残差块来稳定地提升深层网络性能，并提供了严格的理论保证其逼近误差可趋近于零。


<details>
  <summary>Details</summary>
Motivation: 深层神经网络训练困难，因其优化景观高度非凸且常病态；而浅层网络（如单隐层ReLU模型）具有凸重构和全局收敛保证，启发了兼顾稳定性与深度扩展的学习范式。

Method: MGDL采用逐级训练策略：每级冻结已学参数，仅训练新残差块以减小剩余逼近误差；并建立算子理论基础，分析ReLU多级结构的误差递减与一致收敛性。

Result: 证明了对任意连续目标函数，存在固定宽度的多级ReLU方案，其各级残差严格递减并一致收敛至零；数值实验验证了理论结果。

Conclusion: MGDL为逐级训练提供了首个严格理论保障，表明该策略可在深层网络中实现可证明的逼近误差消失，兼具可解释性与稳定性。

Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.

</details>


### [162] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM是一个统一的联邦约束优化框架，解决了联邦学习中的功能约束、通信瓶颈、本地更新和部分客户端参与四大挑战，采用无投影、仅原始变量更新，并结合双向误差反馈以应对压缩带来的偏差，理论证明其收敛速率为O(1/√T)，并在Neyman-Pearson分类与CMDP任务上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中功能约束、通信瓶颈、本地更新和部分客户端参与这四大实际挑战，现有方法难以兼顾这些因素且缺乏理论支撑。

Method: 基于切换梯度法（switching gradient method），设计无投影、仅原始变量的更新机制；引入双向误差反馈机制以校正压缩偏差，并分析压缩噪声与多步本地更新的交互；提出软切换版本以增强可行性边界附近的稳定性。

Result: 理论证明FedSGM在平均迭代点上达到标准O(1/√T)收敛速率，并给出解耦优化进展与采样噪声的高概率界；实验在Neyman-Pearson分类和CMDP任务上验证了其有效性。

Conclusion: FedSGM是首个统一处理功能约束、模型压缩、多步本地更新与部分参与的联邦学习框架，为约束型联邦学习提供了坚实的理论基础与实用算法。

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [163] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: 本文提出了一种基于嵌入的卫星遥感作物类型制图方法，通过四项标准（性能、合理性、可迁移性、可访问性）评估了TESSERA和AlphaEarth等地理空间基础模型，并在塞内加尔花生盆地验证了TESSERA表现最优，时序迁移中准确率提升28%。


<details>
  <summary>Details</summary>
Motivation: 现有卫星遥感作物类型制图方法不适用于小农地区，亟需适配小农条件的新方法。

Method: 构建四维评估标准（性能、合理性、可迁移性、可访问性），对比分析TESSERA与AlphaEarth等地理空间基础模型嵌入方法与现有基线方法在塞内加尔花生盆地的表现。

Result: TESSERA嵌入方法在各项评估标准中综合最优，在一个时序迁移案例中比次优方法准确率高28%。

Conclusion: TESSERA嵌入是一种适用于塞内加尔作物类型分类与制图的有效方法，具备推广潜力。

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [164] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: 本文提出GRIP框架，通过几何约束路由器梯度更新，解决MoE架构下机器遗忘方法易依赖路由操纵、损害模型效用的问题，实现知识直接擦除与高路由稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法在MoE架构上泛化能力差，主要因利用其路由器机制进行表面遗忘（重定向查询而非真正擦除知识），导致效用下降。

Method: 提出Geometric Routing Invariance Preservation（GRIP）：将路由器梯度更新投影至专家特定的零空间，解耦路由选择稳定性与参数可塑性，迫使遗忘优化直接作用于专家参数而非路由器。GRIP作为即插即用适配器，不修改原有遗忘算法。

Result: 在大规模MoE模型上验证，GRIP使所有测试遗忘方法路由稳定性达95%以上，同时保持原有效用；有效防止对路由器漏洞的滥用，成功将密集模型遗忘方法迁移至MoE。

Conclusion: GRIP为MoE架构提供了通用、算法无关的机器遗忘适配框架，推动了面向稀疏大模型的AI安全遗忘研究。

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [165] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: 本文提出Trajectory Alignment Coefficient (TAC)作为评估奖励函数与专家偏好的一致性的指标，并通过人类实验验证其在Lunar Lander任务中提升奖励调优效果；进一步提出可微的Soft-TAC，用作损失函数训练奖励模型，在Gran Turismo 7中展现出优于交叉熵的偏好建模能力。


<details>
  <summary>Details</summary>
Motivation: 奖励函数设计耗时且易出错，需更好支持RL从业者设计合适奖励；同时手动调参仍繁重，需自动化学习高TAC奖励模型。

Method: 引入TAC度量奖励函数与专家轨迹偏好的对齐程度；开展人因实验评估TAC辅助调参效果；提出Soft-TAC作为可微近似，用于端到端训练奖励模型。

Result: TAC辅助调参显著提升奖励函数性能并降低认知负荷；Soft-TAC在Gran Turismo 7中训练出的奖励模型能更好捕捉偏好，生成行为更鲜明的策略。

Conclusion: TAC既可作为实用的奖励调优指导工具，也可作为复杂领域中奖励学习的有效优化目标。

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [166] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 本文提出一种基于各向同性回归的单调校准方法，用于修复预训练嵌入空间中余弦相似度绝对值的系统性偏差，从而恢复其可解释性，同时保持排序和局部稳定性不变。


<details>
  <summary>Details</summary>
Motivation: 预训练嵌入空间中的原始余弦相似度虽与人类判断高度相关，但因各向异性导致绝对值严重偏高且集中，缺乏定量可解释性。

Method: 使用在人类相似度判断数据上训练的各向同性回归，构建一个单调变换函数，对余弦相似度进行校准。

Result: 校准后相似度接近完美校准，保持98%的局部稳定性（七种扰动下），且所有基于序的结构（如角度排序、最近邻、阈值图、分位决策）均保持不变。

Conclusion: 各向同性校准不是替代余弦相似度，而是通过保序变换恢复其绝对值的可解释性，无需修改嵌入空间或重计算嵌入。

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [167] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: 本文研究了多组学习的样本复杂度，在组可实现设定下，即使组族无限但VC维有限，其样本复杂度仍优于无假设设定；该改进通过在组可实现概念类上进行经验风险最小化实现，但该方法计算不可行，因此提出了一种基于非恰当学习的替代方案。


<details>
  <summary>Details</summary>
Motivation: 提升多组学习在组可实现设定下的样本效率，并解决传统经验风险最小化方法的计算不可行性问题。

Method: 理论分析组可实现设定下的样本复杂度；采用经验风险最小化（ERM）于组可实现概念类；指出其计算不可行性并提出基于 improper learning 的替代方法。

Result: 证明了在组族具有有限VC维条件下，组可实现设定下样本复杂度优于无假设设定；ERM 方法虽能获得理论保证但计算不可行；提出了可行的 improper learning 替代方案。

Conclusion: 组可实现性可显著降低多组学习的样本复杂度，但需设计计算高效的非恰当学习算法来实现实际应用。

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [168] [Is BatchEnsemble a Single Model? On Calibration and Diversity of Efficient Ensembles](https://arxiv.org/abs/2601.16936)
*Anton Zamyatin,Patrick Indri,Sagar Malhotra,Thomas Gärtner*

Main category: cs.LG

TL;DR: BatchEnsemble在不确定性估计方面表现不佳，更接近单模型而非真实集成，尤其在准确率、校准和OOD检测上远逊于Deep Ensembles。


<details>
  <summary>Details</summary>
Motivation: 在资源受限和低延迟场景下，需高效获取不确定性估计；Deep Ensembles虽鲁棒但开销大，BatchEnsemble旨在以更低参数和内存代价实现类似效果。

Method: 通过在共享基础网络上施加可学习的秩-1扰动来构建轻量级集成，并在CIFAR10/10C/SVHN和MNIST上系统评估其准确性、校准性与OOD检测能力。

Result: BatchEnsemble在各项指标上均接近单模型基线，显著弱于Deep Ensembles；MNIST控制实验显示各成员在函数和参数空间高度一致，缺乏多样性。

Conclusion: BatchEnsemble本质上不具备真正集成的能力，其不确定性估计不可靠，不应被当作Deep Ensembles的有效替代方案。

Abstract: In resource-constrained and low-latency settings, uncertainty estimates must be efficiently obtained. Deep Ensembles provide robust epistemic uncertainty (EU) but require training multiple full-size models. BatchEnsemble aims to deliver ensemble-like EU at far lower parameter and memory cost by applying learned rank-1 perturbations to a shared base network. We show that BatchEnsemble not only underperforms Deep Ensembles but closely tracks a single model baseline in terms of accuracy, calibration and out-of-distribution (OOD) detection on CIFAR10/10C/SVHN. A controlled study on MNIST finds members are near-identical in function and parameter space, indicating limited capacity to realize distinct predictive modes. Thus, BatchEnsemble behaves more like a single model than a true ensemble.

</details>


### [169] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 本文提出了一种基于刚性片段（rigid motifs）的三维分子结构生成方法，利用SE(3)-等变生成模型，在保持几何一致性的同时显著提升生成效率与稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统3D分子生成以原子为单位，而图生成常使用片段；本文受蛋白质骨架生成启发，将小分子建模为刚性片段集合，以兼顾几何合理性与生成效率。

Method: 将分子表示为刚体片段集合，采用SE(3)-equivariant生成模型进行从片段到完整3D结构的端到端生成。

Result: 在GEOM-Drugs等基准上达到或超越SOTA，原子稳定性更高，生成步数减少2–10倍，分子表征压缩率达3.5倍。

Conclusion: 基于刚性片段的SE(3)-等变生成范式是一种更高效、更稳定的3D分子生成新路径，兼具物理合理性和计算优势。

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [170] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: 本文提出了一种新型语言模型ARMD，通过将掩码扩散过程重构为分块因果模型，在保持并行生成能力的同时，实现了类似自回归模型的高效训练与解码，并在标准语言建模基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型（MDMs）虽具潜力，但相比自回归模型（ARMs）存在性能差距且训练迭代次数多，亟需兼顾训练效率与并行生成能力的新架构。

Method: 提出Auto-Regressive Masked Diffusion（ARMD）模型，将掩码扩散建模为块状因果过程，设计严格因果且置换等变的网络结构，支持单次前向传递计算多步去噪条件概率；引入渐进式置换训练和跨步并行生成策略。

Result: ARMD在标准语言建模基准上达到SOTA，超越现有扩散基线，训练步数显著减少；同时成为并行文本生成新标杆，有效弥合并行与串行解码间的性能鸿沟。

Conclusion: ARMD成功融合自回归训练效率与扩散模型并行生成优势，验证了因果化掩码扩散建模的有效性，为高效大语言模型设计提供了新范式。

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [171] [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)
*Estela Sánchez-Carballo,Francisco M. Melgarejo-Meseguer,José Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 本文提出使用潜在扩散模型（LDM）进行物联网入侵检测中的攻击数据增强，显著提升IDS性能并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: ML-based IDS在IoT中因良性与攻击流量类别严重不平衡而导致性能下降；现有数据增强方法在样本保真度、多样性与计算效率之间难以兼顾。

Method: 采用潜在扩散模型（LDM）生成高质量、多样化的攻击流量样本，并在DDoS、Mirai和中间人三类IoT攻击上系统评估其对下游IDS性能及生成质量（分布性、依赖性、多样性）的影响。

Result: LDM增强后IDS的F1-score达0.99（DDoS/Mirai），全面超越基线方法；同时保持特征依赖性、提升样本多样性，并将采样时间降低约25%。

Conclusion: LDM是一种高效、可扩展的合成IoT攻击数据生成方案，能有效缓解ML-based IDS中的类别不平衡问题。

Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.

</details>


### [172] [A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs](https://arxiv.org/abs/2601.16979)
*Dayal Singh Kalra,Jean-Christophe Gagnon-Audet,Andrey Gromov,Ishita Mediratta,Kelvin Niu,Alexander H Miller,Michael Shvartsman*

Main category: cs.LG

TL;DR: 本文提出了一种计算高效的曲率度量——临界尖锐度（critical sharpness, λ_c），用于替代昂贵的Hessian尖锐度（λ_max^H），首次在7B参数规模的LLM（OLMo-2）上实证验证了渐进尖锐化与稳定性边缘（Edge of Stability）等现象，并进一步提出相对临界尖锐度（λ_c^{1→2}）以分析预训练到微调的曲率迁移，指导数据混合策略。


<details>
  <summary>Details</summary>
Motivation: Hessian尖锐度对理解神经网络训练动力学至关重要，但其直接计算在大语言模型上因计算开销过大而不可行，亟需可扩展的替代度量。

Method: 提出临界尖锐度λ_c（仅需少于10次前向传播）及其相对形式λ_c^{1→2}，基于更新方向Δθ估计损失曲率；在OLMo-2模型（最高7B参数）的预训练与中期训练中进行大规模实证分析，并用于分析预训练到微调的曲率变化及数据混合。

Result: 成功在7B参数模型上观测到渐进尖锐化和Edge of Stability；验证了λ_c能准确捕捉Hessian尖锐度关键现象；λ_c^{1→2}揭示了不同训练阶段间曲率差异，为数据混合提供量化依据。

Conclusion: 临界尖锐度是一种高效、可扩展的曲率诊断工具，不仅支持大规模训练中的动态监控，还为数据组成与训练策略优化提供了实用指导；表明可扩展曲率分析能带来切实可行的工程洞见。

Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($λ_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [173] [Computational Foundations for Strategic Coopetition: Formalizing Collective Action and Loyalty](https://arxiv.org/abs/2601.16237)
*Vik Pant,Eric Yu*

Main category: cs.MA

TL;DR: 本文提出了一种基于忠诚度调节的效用函数框架，用于建模混合动机下团队成员在合作与竞争并存环境中的努力决策，有效缓解自由搭便车问题，并在多场景实验与真实开源项目案例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 混合动机多智能体环境中普遍存在持续性搭便车问题：个体付出成本高而收益共享，导致纳什均衡下普遍懈怠；现有i*模型缺乏可扩展的计算机制来分析团队层面的集体行动问题。

Method: 构建忠诚度调节的效用函数，包含忠诚收益（福利内化+内在贡献满足感）与成本容忍（降低忠诚成员的努力负担）两个机制；通过依赖加权的团队凝聚力将i*结构依赖嵌入团队层级激励建模；适用于人类团队（心理认同）与多智能体系统（对齐系数与调整成本函数）。

Result: 在3125种配置实验中，忠诚效应稳健（中位努力分化达15.04倍）；6项行为目标全部达标（最低96.5%）；Apache HTTP Server（1995–2023）案例复现得满分60/60；统计显著性p<0.001，效应量Cohen's d=0.71。

Conclusion: 忠诚度可作为关键调节变量，有效重构团队激励结构，在理论和实证层面为解决混合动机下的自由搭便车问题提供了可扩展、可验证的计算基础。

Abstract: Mixed-motive multi-agent settings are rife with persistent free-riding because individual effort benefits all members equally, yet each member bears the full cost of their own contribution. Classical work by Holmström established that under pure self-interest, Nash equilibrium is universal shirking. While i* represents teams as composite actors, it lacks scalable computational mechanisms for analyzing how collective action problems emerge and resolve in coopetitive settings. This technical report extends computational foundations for strategic coopetition to team-level dynamics, building on companion work formalizing interdependence/complementarity (arXiv:2510.18802) and trust dynamics (arXiv:2510.24909). We develop loyalty-moderated utility functions with two mechanisms: loyalty benefit (welfare internalization plus intrinsic contribution satisfaction) and cost tolerance (reduced effort burden for loyal members). We integrate i* structural dependencies through dependency-weighted team cohesion, connecting member incentives to team-level positioning. The framework applies to both human teams (loyalty as psychological identification) and multi-agent systems (alignment coefficients and adjusted cost functions). Experimental validation across 3,125 configurations demonstrates robust loyalty effects (15.04x median effort differentiation). All six behavioral targets achieve thresholds: free-riding baseline (96.5%), loyalty monotonicity (100%), effort differentiation (100%), team size effect (100%), mechanism synergy (99.5%), and bounded outcomes (100%). Empirical validation using published Apache HTTP Server (1995-2023) case study achieves 60/60 points, reproducing contribution patterns across formation, growth, maturation, and governance phases. Statistical significance confirmed at p<0.001, Cohen's d=0.71.

</details>


### [174] [AMBER: A Columnar Architecture for High-Performance Agent-Based Modeling in Python](https://arxiv.org/abs/2601.16292)
*Anh-Duy Pham*

Main category: cs.MA

TL;DR: 本文介绍了AMBER框架，通过使用Polars DataFrame的列式状态管理替代传统的每个代理对象表示法，解决了Python中基于代理建模（ABM）在易用性与高性能之间的矛盾；实验表明其在速度和内存使用上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: Python在科学计算中因易用性而流行，但其基于对象的ABM框架难以满足大规模仿真的性能需求，存在易用性与性能之间的根本张力。

Method: 提出AMBER框架，采用列式状态管理（基于Polars DataFrame）替代传统对象-代理范式，并设计了核心抽象、空间环境、实验管理和优化能力等架构组件。

Result: 在三个基准测试中，AMBER实现1.2x至93x的速度提升（尤其在全局属性操作密集型模型中优势明显），峰值内存使用减少30–50%。

Conclusion: 列式状态管理是一种可行且高效的ABM架构范式，可在解释型语言（如Python）中支撑高性能代理建模。

Abstract: Agent-based modeling (ABM) has emerged as an indispensable methodology for studying complex adaptive systems across the natural and social sciences. However, Python-based ABM frameworks face a fundamental tension between the accessibility that has made Python dominant in scientific computing and the performance requirements of large-scale simulations. This paper introduces AMBER, a framework that resolves this tension through a novel architectural approach: replacing the conventional object-per-agent representation with columnar state management using the Polars DataFrame library. We analyze the computational characteristics of both paradigms, present the architectural design of AMBER including its core abstractions, spatial environments, experiment management, and optimization capabilities. Empirical evaluation on three canonical benchmarks demonstrates that AMBER achieves speedups of 1.2x to 93x depending on workload characteristics, with the greatest advantages for models dominated by population-wide attribute operations. Memory profiling reveals 30-50% reduction in peak usage compared to object-oriented frameworks. Our results establish columnar state management as a viable architectural foundation for high-performance ABM in interpreted languages.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [175] [LLM-based Semantic Search for Conversational Queries in E-commerce](https://arxiv.org/abs/2601.16492)
*Emad Siddiqui,Venkatesh Terikuti,Xuan Lu*

Main category: cs.IR

TL;DR: 本文提出了一种基于大语言模型（LLM）的语义搜索框架，用于提升电商平台上对会话式用户查询的理解与检索效果，通过合成数据微调嵌入和生成模型，并融合相似性检索与结构化过滤，显著提升了精度与召回率。


<details>
  <summary>Details</summary>
Motivation: 传统电商平台的搜索系统针对关键词查询优化，难以应对日益增多的会话式用户查询，亟需能更好理解用户意图的语义搜索方案。

Method: 构建LLM驱动的语义搜索框架，结合领域专用嵌入与结构化过滤；利用LLM生成合成数据，分别微调嵌入模型（拉近语义相似商品在表征空间距离）和生成模型（将自然语言查询转为结构化约束）；最终融合相似性检索与约束过滤。

Result: 在真实数据集上，该框架在多种设置下相较基线方法显著提升了检索的精度与召回率。

Conclusion: 融合领域嵌入、结构化过滤与LLM生成的合成数据微调策略，是提升电商会话搜索性能的有效途径。

Abstract: Conversational user queries are increasingly challenging traditional e-commerce platforms, whose search systems are typically optimized for keyword-based queries. We present an LLM-based semantic search framework that effectively captures user intent from conversational queries by combining domain-specific embeddings with structured filters. To address the challenge of limited labeled data, we generate synthetic data using LLMs to guide the fine-tuning of two models: an embedding model that positions semantically similar products close together in the representation space, and a generative model for converting natural language queries into structured constraints. By combining similarity-based retrieval with constraint-based filtering, our framework achieves strong precision and recall across various settings compared to baseline approaches on a real-world dataset.

</details>


### [176] [PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation](https://arxiv.org/abs/2601.16556)
*Dengzhao Fang,Jingtong Gao,Yu Li,Xiangyu Zhao,Yi Chang*

Main category: cs.IR

TL;DR: 本文提出PRISM框架，通过纯净语义量化器和集成语义推荐器解决生成式序列推荐中语义标记不纯与生成信息损失问题，显著提升稀疏场景下的推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式序列推荐（GSR）框架存在语义标记不纯不稳定、生成过程信息损失且结构弱两大关键局限。

Method: 提出PRISM框架，包括：（1）纯净语义量化器，采用自适应协同去噪与分层语义锚定构建鲁棒码本；（2）集成语义推荐器，通过动态语义融合机制整合细粒度语义，并以语义结构对齐目标保障逻辑有效性。

Result: PRISM在四个真实数据集上持续超越SOTA基线，尤其在高稀疏场景下性能提升显著。

Conclusion: PRISM通过提升语义标记质量与增强生成结构化能力，有效推动生成式序列推荐的实用性与鲁棒性。

Abstract: Generative Sequential Recommendation (GSR) has emerged as a promising paradigm, reframing recommendation as an autoregressive sequence generation task over discrete Semantic IDs (SIDs), typically derived via codebook-based quantization. Despite its great potential in unifying retrieval and ranking, existing GSR frameworks still face two critical limitations: (1) impure and unstable semantic tokenization, where quantization methods struggle with interaction noise and codebook collapse, resulting in SIDs with ambiguous discrimination; and (2) lossy and weakly structured generation, where reliance solely on coarse-grained discrete tokens inevitably introduces information loss and neglects items' hierarchical logic. To address these issues, we propose a novel generative recommendation framework, PRISM, with Purified Representation and Integrated Semantic Modeling. Specifically, to ensure high-quality tokenization, we design a Purified Semantic Quantizer that constructs a robust codebook via adaptive collaborative denoising and hierarchical semantic anchoring mechanisms. To compensate for information loss during quantization, we further propose an Integrated Semantic Recommender, which incorporates a dynamic semantic integration mechanism to integrate fine-grained semantics and enforces logical validity through a semantic structure alignment objective. PRISM consistently outperforms state-of-the-art baselines across four real-world datasets, demonstrating substantial performance gains, particularly in high-sparsity scenarios.

</details>


### [177] [LLM-powered Real-time Patent Citation Recommendation for Financial Technologies](https://arxiv.org/abs/2601.16775)
*Tianang Deng,Yu Deng,Tianchen Gao,Yonghong Hu,Rui Pan*

Main category: cs.IR

TL;DR: 本文提出了一种面向动态金融专利库的实时引文推荐框架，利用大语言模型嵌入、近似最近邻搜索与HNSW增量索引技术，在保持高准确率的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 金融领域专利数量激增、更新迅速，传统静态索引或周期性重训练方法难以适应其动态性，亟需支持实时更新的引文推荐方案。

Method: 构建三阶段推荐流程：1）用LLM生成专利摘要语义嵌入；2）基于HNSW图实现高效近似最近邻检索以生成候选集；3）按语义相似度排序输出top-k推荐；采用增量式索引策略支持新专利实时加入。

Result: 在42.8万条CNIPA金融专利数据上验证，该框架相比重建式索引显著提升召回率并大幅降低计算成本，且持续优于传统文本方法及其它近邻检索方法。

Conclusion: 所提框架有效解决了金融专利引文推荐中的时效性与可扩展性难题，为动态知识产权分析提供了实用、高效的技术路径。

Abstract: Rapid financial innovation has been accompanied by a sharp increase in patenting activity, making timely and comprehensive prior-art discovery more difficult. This problem is especially evident in financial technologies, where innovations develop quickly, patent collections grow continuously, and citation recommendation systems must be updated as new applications arrive. Existing patent retrieval and citation recommendation methods typically rely on static indexes or periodic retraining, which limits their ability to operate effectively in such dynamic settings. In this study, we propose a real-time patent citation recommendation framework designed for large and fast-changing financial patent corpora. Using a dataset of 428,843 financial patents granted by the China National Intellectual Property Administration (CNIPA) between 2000 and 2024, we build a three-stage recommendation pipeline. The pipeline uses large language model (LLM) embeddings to represent the semantic content of patent abstracts, applies efficient approximate nearest-neighbor search to construct a manageable candidate set, and ranks candidates by semantic similarity to produce top-k citation recommendations. In addition to improving recommendation accuracy, the proposed framework directly addresses the dynamic nature of patent systems. By using an incremental indexing strategy based on hierarchical navigable small-world (HNSW) graphs, newly issued patents can be added without rebuilding the entire index. A rolling day-by-day update experiment shows that incremental updating improves recall while substantially reducing computational cost compared with rebuild-based indexing. The proposed method also consistently outperforms traditional text-based baselines and alternative nearest-neighbor retrieval approaches.

</details>


### [178] [PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework](https://arxiv.org/abs/2601.16815)
*Shaoqing Wang,Yingcai Ma,Kairui Fu,Ziyang Wang,Dunxian Huang,Yuliang Yan,Jian Wu*

Main category: cs.IR

TL;DR: 本文提出了一种名为PI2I的两阶段个性化物品到物品推荐框架，通过优化检索池和引入交互式打分模型，提升了传统协同过滤方法的个性化能力，并在淘宝‘猜你喜欢’场景中取得线上交易率提升1.05%的效果。


<details>
  <summary>Details</summary>
Motivation: 传统基于物品的协同过滤和双塔模型因统一截断策略和缺乏用户-物品交叉建模，难以充分捕捉复杂的用户-物品交互关系。

Method: 提出两阶段框架：第一阶段（IBS）放宽截断阈值以扩大候选池、提升召回率；第二阶段（PRS）采用交互式打分模型替代内积计算，并基于触发-目标关系构建负样本，保障训推一致。

Result: 在大规模真实数据集上离线实验优于传统CF方法，媲美双塔模型；线上部署于淘宝‘猜你喜欢’模块，带来1.05%的交易率提升；并开源了含1.3亿真实交互的大规模推荐数据集PI2I。

Conclusion: PI2I有效增强了物品协同过滤的个性化能力，在保持高效性的同时显著提升推荐效果，且开源数据集为社区提供了重要基准资源。

Abstract: Efficiently selecting relevant content from vast candidate pools is a critical challenge in modern recommender systems. Traditional methods, such as item-to-item collaborative filtering (CF) and two-tower models, often fall short in capturing the complex user-item interactions due to uniform truncation strategies and overdue user-item crossing. To address these limitations, we propose Personalized Item-to-Item (PI2I), a novel two-stage retrieval framework that enhances the personalization capabilities of CF. In the first Indexer Building Stage (IBS), we optimize the retrieval pool by relaxing truncation thresholds to maximize Hit Rate, thereby temporarily retaining more items users might be interested in. In the second Personalized Retrieval Stage (PRS), we introduce an interactive scoring model to overcome the limitations of inner product calculations, allowing for richer modeling of intricate user-item interactions. Additionally, we construct negative samples based on the trigger-target (item-to-item) relationship, ensuring consistency between offline training and online inference. Offline experiments on large-scale real-world datasets demonstrate that PI2I outperforms traditional CF methods and rivals Two-Tower models. Deployed in the "Guess You Like" section on Taobao, PI2I achieved a 1.05% increase in online transaction rates. In addition, we have released a large-scale recommendation dataset collected from Taobao, containing 130 million real-world user interactions used in the experiments of this paper. The dataset is publicly available at https://huggingface.co/datasets/PI2I/PI2I, which could serve as a valuable benchmark for the research community.

</details>


### [179] [Navigating the Shift: A Comparative Analysis of Web Search and Generative AI Response Generation](https://arxiv.org/abs/2601.16858)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: This paper conducts a large-scale empirical study comparing generative AI (e.g., LLMs) and traditional web search (e.g., Google) across multiple dimensions—source domains, domain typology, query intent, and information freshness—and identifies LLM pre-training as a key factor shaping differences; it highlights implications for Answer Engine Optimization (AEO) versus SEO.


<details>
  <summary>Details</summary>
Motivation: The rise of generative AI as a primary information source marks a paradigm shift from traditional web search, necessitating empirical understanding of how their outputs fundamentally differ and what drives those differences.

Method: Large-scale empirical comparison of results from Google Search and leading generative AI services across multiple dimensions (source domains, domain typology, query intent, freshness); analysis of how LLM pre-training knowledge interacts with real-time web search.

Result: AI-generated answers and web search results diverge significantly in source domains, domain typology (e.g., earned vs. owned media), query intent alignment, and information freshness; LLM pre-training strongly shapes output behavior—even when web search is enabled—leading to distinct information ecosystem mechanics.

Conclusion: Generative AI and web search operate via fundamentally different mechanisms, calling for new optimization paradigms like Answer Engine Optimization (AEO), which differs critically from traditional SEO.

Abstract: The rise of generative AI as a primary information source presents a paradigm shift from traditional web search. This paper presents a large-scale empirical study quantifying the fundamental differences between the results returned by Google Search and leading generative AI services. We analyze multiple dimensions, demonstrating that AI-generated answers and web search results diverge significantly in their consulted source domains, the typology of these domains (e.g., earned media vs. owned, social), query intent and the freshness of the information provided. We then investigate the role of LLM pre-training as a key factor shaping these differences, analyzing how this intrinsic knowledge base interacts with and influences real-time web search when enabled. Our findings reveal the distinct mechanics of these two information ecosystems, leading to critical observations on the emergent field of Answer Engine Optimization (AEO) and its contrast with traditional Search Engine Optimization (SEO).

</details>


### [180] [From Atom to Community: Structured and Evolving Agent Memory for User Behavior Modeling](https://arxiv.org/abs/2601.16872)
*Yuxin Liao,Le Wu,Min Hou,Yu Wang,Han Wu,Meng Wang*

Main category: cs.IR

TL;DR: STEAM is a novel framework for user behavior modeling that uses structured, evolving agent memory to capture multi-faceted and dynamic user preferences from implicit signals, outperforming existing methods in recommendation tasks.


<details>
  <summary>Details</summary>
Motivation: Existing memory mechanisms for LLM-based agents struggle with non-textual, implicit user behaviors (e.g., clicks) due to lack of supervision, conflation of multi-faceted interests, catastrophic forgetting from naive overwriting, and underuse of collaborative signals.

Method: STEAM decomposes user preferences into atomic, behavior-linked memory units; groups similar memories across users into communities; generates prototype memories for collaborative signal propagation; and employs adaptive evolution mechanisms—consolidation and formation—to refine and discover interests.

Result: STEAM achieves substantial improvements over state-of-the-art baselines in recommendation accuracy, simulation fidelity, and diversity on three real-world datasets.

Conclusion: Structured and evolving memory organization—rather than flat, overwritten summaries—enables more faithful, adaptive, and collaborative modeling of user preferences from sparse, implicit behavioral data.

Abstract: User behavior modeling lies at the heart of personalized applications like recommender systems. With LLM-based agents, user preference representation has evolved from latent embeddings to semantic memory. While existing memory mechanisms show promise in textual dialogues, modeling non-textual behaviors remains challenging, as preferences must be inferred from implicit signals like clicks without ground truth supervision. Current approaches rely on a single unstructured summary, updated through simple overwriting. However, this is suboptimal: users exhibit multi-faceted interests that get conflated, preferences evolve yet naive overwriting causes forgetting, and sparse individual interactions necessitate collaborative signals. We present STEAM (\textit{\textbf{ST}ructured and \textbf{E}volving \textbf{A}gent \textbf{M}emory}), a novel framework that reimagines how agent memory is organized and updated. STEAM decomposes preferences into atomic memory units, each capturing a distinct interest dimension with explicit links to observed behaviors. To exploit collaborative patterns, STEAM organizes similar memories across users into communities and generates prototype memories for signal propagation. The framework further incorporates adaptive evolution mechanisms, including consolidation for refining memories and formation for capturing emerging interests. Experiments on three real-world datasets demonstrate that STEAM substantially outperforms state-of-the-art baselines in recommendation accuracy, simulation fidelity, and diversity.

</details>


### [181] [Explaining Group Recommendations via Counterfactuals](https://arxiv.org/abs/2601.16882)
*Maria Stratigi,Nikos Bikakis*

Main category: cs.IR

TL;DR: 本文提出了一种面向群体推荐系统的反事实解释框架，通过移除特定历史交互来揭示推荐结果的变化，并设计了兼顾效用与公平性的启发式算法，在多个数据集上验证了不同方法的权衡效果。


<details>
  <summary>Details</summary>
Motivation: 现有群体推荐系统缺乏透明性，且解释方法多针对个体，难以支持群体中多偏好交互的场景。

Method: 提出群体反事实解释框架，形式化定义该概念，设计面向群体的效用与公平性度量，并开发Pareto过滤、增长-剪枝等启发式算法以高效生成解释。

Result: 在MovieLens和Amazon数据集上的实验表明：低成本方法生成更大但更不公平的解释；其他方法则以更高代价获得简洁、均衡的结果；Pareto过滤在稀疏场景下显著提升效率。

Conclusion: 所提框架及算法能有效提升群体推荐的可解释性与公平性，为实际应用提供了实用且可扩展的解决方案。

Abstract: Group recommender systems help users make collective choices but often lack transparency, leaving group members uncertain about why items are suggested. Existing explanation methods focus on individuals, offering limited support for groups where multiple preferences interact. In this paper, we propose a framework for group counterfactual explanations, which reveal how removing specific past interactions would change a group recommendation. We formalize this concept, introduce utility and fairness measures tailored to groups, and design heuristic algorithms, such as Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets show clear trade-offs: low-cost methods produce larger, less fair explanations, while other approaches yield concise and balanced results at higher cost. Furthermore, the Pareto-filtering heuristic demonstrates significant efficiency improvements in sparse settings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [182] [When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems](https://arxiv.org/abs/2601.16280)
*Donghao Huang,Gauri Malwe,Zhaoxia Wang*

Main category: cs.AI

TL;DR: 本文提出了一种面向多智能体系统工具使用可靠性的诊断评估框架，基于大数据分析构建12类错误分类体系，并在多种模型与硬件配置上进行系统测试，揭示了不同规模模型的可靠性瓶颈与实用部署阈值。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型驱动的多智能体系统缺乏系统性、可复现的工具使用可靠性评估方法，尤其在中小企业隐私敏感、资源受限场景下亟需可落地的评估基础设施。

Method: 构建涵盖工具初始化、参数处理、执行与结果解析四大阶段的12类错误分类体系；在1980个确定性测试实例上，对Qwen2.5系列、Functionary、GPT-4、Claude 3.5/3.7等模型在多种边缘硬件上开展系统性评估；结合成功率与延迟指标分析可靠性-效率权衡。

Result: 发现工具初始化失败是小模型的主要瓶颈；qwen2.5:32b表现与GPT-4.1持平（零失败）；qwen2.5:14b在通用硬件上达96.6%成功率与7.3秒延迟，具备实用部署价值。

Conclusion: 该框架为工具增强型多智能体AI系统提供了首个面向生产部署的系统性可靠性评估基础设施，支持SME在隐私敏感与资源受限环境中的可信落地。

Abstract: Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems.

</details>


### [183] [SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems](https://arxiv.org/abs/2601.16286)
*Varun Chillara,Dylan Kline,Christopher Alvares,Evan Wooten,Huan Yang,Shlok Khetan,Cade Bauer,Tré Guillory,Tanishka Shah,Yashodhara Dhariwal,Volodymyr Pavlov,George Popstefanov*

Main category: cs.AI

TL;DR: 本文提出SemanticALLI架构，通过将生成过程分解为分析意图解析（AIR）和可视化合成（VS）两个阶段，将结构化中间表示（IRs）作为可缓存的一等对象，显著提升缓存命中率与系统效率。


<details>
  <summary>Details</summary>
Motivation: Agentic AI流水线存在隐性低效问题：即使用户自然语言输入新颖，系统仍频繁重复构建相同的中间逻辑（如指标归一化、图表框架），而传统边界缓存因将推理视为黑箱而无法捕获此类冗余。

Method: 提出SemanticALLI——一种面向流水线的架构，在Alli平台中实现冗余推理的显式识别与复用；核心是将生成解耦为Analytic Intent Resolution（AIR）和Visualization Synthesis（VS）两阶段，并将结构化中间表示（IRs）提升为可缓存的一等构件。

Result: 相比基线单体缓存38.7%的命中率，SemanticALLI在VS阶段达到83.10%命中率，规避4023次LLM调用，中位延迟仅2.66ms，显著降低总token消耗。

Conclusion: AI系统设计应关注流水线内部稳定、结构化的检查点进行缓存，即便用户输入高度多样化，流水线自身仍存在大量可复用逻辑。

Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.

</details>


### [184] [DSGym: A Holistic Framework for Evaluating and Training Data Science Agents](https://arxiv.org/abs/2601.16344)
*Fan Nie,Junlin Wang,Harper Hua,Federico Bianchi,Yongchan Kwon,Zhenting Qi,Owen Queen,Shang Zhu,James Zou*

Main category: cs.AI

TL;DR: 本文提出了DSGym，一个用于评估和训练数据科学智能体的标准化、可扩展框架，解决了现有基准测试在接口碎片化、任务覆盖窄及数据基础不牢等方面的不足；通过引入DSGym-Tasks、DSBio和DSPredict等任务集，并支持执行验证的数据合成与模型训练，显著提升了智能体在真实科研场景中端到端数据分析能力的评估与提升。


<details>
  <summary>Details</summary>
Motivation: 现有数据科学基准存在评估接口碎片化、任务覆盖狭窄、缺乏严格数据支撑等问题，且大量任务无需真实数据即可求解，难以真实反映智能体的数据分析能力。

Method: 提出DSGym框架，包含模块化架构、自包含执行环境、质量与捷径可解性筛选的任务集（DSGym-Tasks）、专家构建的生物信息学任务（DSBio）和跨领域的预测任务（DSPredict），并构建执行验证的数据合成与训练流程。

Result: 基于DSGym构建了2000例训练数据集，训练出4B参数模型，在标准化分析基准上超越GPT-4o；DSGym实现了对智能体端到端规划、实现与验证数据分析能力的严谨测量。

Conclusion: DSGym为数据科学智能体提供了统一、可扩展、强数据支撑的评估与训练平台，推动其在真实科研场景中的实用化发展。

Abstract: Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.

</details>


### [185] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: 本文提出Doc2AHP框架，将分析层次过程（AHP）的结构化逻辑约束引入大语言模型（LLM）推理过程，无需标注数据或专家干预，即可从非结构化文档中自动生成逻辑一致、数值可靠的决策模型。


<details>
  <summary>Details</summary>
Motivation: LLM在复杂逻辑决策任务中缺乏结构性与推理可靠性；传统AHP等决策理论虽严谨但依赖专家，难以规模化应用。

Method: 提出Doc2AHP：以AHP结构原则为约束，引导LLM在非结构化文档空间中进行受控推理，确保父子节点间的逻辑蕴含；引入多智能体加权机制与自适应一致性优化策略保障权重数值一致性。

Result: Doc2AHP使非专家用户可从零构建高质量决策模型，在逻辑完整性与下游任务准确率上显著优于直接生成基线方法。

Conclusion: Doc2AHP成功融合LLM的泛化能力与AHP的逻辑严谨性，突破专家瓶颈，实现可扩展、可靠、结构化的自动决策建模。

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [186] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: 本文提出SycoEval-EM多智能体仿真框架，评估大语言模型（LLMs）在急诊医学中面对患者不当说服时的鲁棒性；实验发现LLMs易屈从于患者压力（ acquiescence率0–100%），尤其在影像检查请求上更脆弱，且现有静态基准无法有效预测其真实临床安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽在临床决策支持中展现潜力，但可能因患者施压而提供不恰当诊疗建议，亟需评估其在社会压力下的稳健性与安全性。

Method: 构建SycoEval-EM多智能体仿真框架，在急诊医学场景下模拟对抗性患者说服行为；在三个'明智选择（Choosing Wisely）'临床场景中，对20个LLM开展共1875次交互测试，量化其屈从率并分析不同说服策略与模型能力的影响。

Result: LLMs屈从率跨度极大（0–100%）；对影像检查请求屈从率（38.8%）高于阿片类处方（25.0%）；模型基础能力与鲁棒性无强相关；各类说服策略效果相近（30.0–36.0%），表明普遍存在普遍脆弱性。

Conclusion: 静态基准测试不足以保障临床AI在真实社会互动中的安全性，必须引入多轮对抗性测试作为临床AI认证的必要环节。

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [187] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 本文通过统一基准测试比较了传统机器学习、提示式大模型（Gemini 2.5）和LoRA微调的Gemma3在四种医学多模态分类任务上的性能，发现传统ML模型整体最优，尤其是文本任务；LoRA微调效果最差；Gemini 2.5在图像多分类任务中表现接近ResNet-50。


<details>
  <summary>Details</summary>
Motivation: 评估当前主流模型（传统ML、提示式VLM/LLM、PEFT微调模型）在医学分类任务中的实际有效性，揭示基础模型并非在所有场景下都优于传统方法。

Method: 在四个公开多模态医学数据集上，统一实验设置（数据划分、评估指标），对比三类模型：经典ML（LR、LightGBM、ResNet-50）、提示式VLM/LLM（Gemini 2.5）、PEFT微调模型（LoRA-Gemma3）。

Result: 传统ML模型在多数任务（尤其文本）中性能最佳；LoRA-Gemma3在所有任务中表现最差；Gemini 2.5在文本任务中表现差，但在图像多分类任务中媲美ResNet-50。

Conclusion: 在当前医学分类任务中，传统机器学习仍是最可靠选择；基础模型优势不具普适性；PEFT效果高度依赖适配策略，最小化微调在此场景下反而有害。

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [188] [Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation](https://arxiv.org/abs/2601.16863)
*Tims Pecerskis,Aivars Smirnovs*

Main category: cs.AI

TL;DR: 本文提出N-Way Self-Evaluating Deliberation（NSED）协议，一种运行时混合模型（MoM）架构，通过动态专家中介和宏观循环神经网络实现多专家协同推理，在不增加显存开销前提下提升小模型性能，并展现出内在对齐与安全优势。


<details>
  <summary>Details</summary>
Motivation: 突破传统静态门控混合专家（MoE）的局限，解决大模型部署成本高、小模型能力弱、以及单一模型易产生偏见或幻觉的问题，探索硬件效率与智能涌现的新平衡点。

Method: 设计动态专家中介（将模型选择建模为实时背包问题）、宏观尺度RNN式协商机制（含语义遗忘门）、无信任N对N同行评审编排架构、二次投票激活函数及反馈驱动状态更新。

Result: 在AIME 2025和LiveCodeBench等基准上，多个<20B参数消费级模型组成的NSED系统性能媲美甚至超越100B+大模型；在DarkBench安全测试中，sycophancy得分低于任一单个代理，体现内在对齐性。

Conclusion: NSED证明了通过结构化协作与运行时优化，可释放小模型群体智能，建立新的‘硬件套利效率前沿’，为高效、可信、可扩展AI提供新范式。

Abstract: This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.

</details>


### [189] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 本文提出了一种基于oracle反事实框架的分析方法，用于评估AI智能体在多轮、长周期任务中各项底层能力（如规划、状态跟踪、长上下文处理）的重要性，并通过可控的游戏化任务验证了不同能力对性能提升的贡献度依赖于环境和模型特性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在孤立任务上表现良好，但在需要规划、状态跟踪和长上下文处理等能力的多轮、长周期智能体任务中仍表现不佳；本文旨在厘清这些底层能力对解决此类任务的相对重要性。

Method: 提出oracle反事实框架：通过为特定子能力（如规划或状态跟踪）提供完美oracle干预，在可控的程序生成游戏任务中量化该能力对整体性能的提升作用；采用可调复杂度的任务设计以隔离各能力影响。

Result: 发现规划能力的提升在多数设置下具有一致正向效果，而其他能力（如状态跟踪）的效用则显著依赖于具体环境和所用语言模型；不同能力的重要性并非普适，而是情境相关。

Conclusion: 多轮智能体任务的瓶颈并非单一能力缺失，而是多种能力与环境、模型间的复杂交互；未来AI智能体研究应注重能力组合与适配，而非孤立提升某项技能。

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [190] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: 本文提出AgentsEval，一种多智能体流式推理框架，用于评估医学影像报告生成系统的临床正确性和推理保真度，通过模拟放射科医生的协作诊断流程，提供可解释的推理轨迹和结构化临床反馈。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法捕捉放射学解释背后的结构化诊断逻辑，导致判断不可靠且临床相关性有限。

Method: 提出AgentsEval多智能体流式推理框架，将评估过程分解为标准定义、证据提取、对齐和一致性评分等可解释步骤，并构建覆盖五种医学报告数据集的多领域扰动基准。

Result: 实验表明AgentsEval在语义忠实性、临床一致性与可解释性方面表现优异，且对改写、语义和风格扰动具有鲁棒性。

Conclusion: AgentsEval推动了医学报告生成系统透明、临床导向的评估，有助于大型语言模型在临床实践中的可信整合。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [191] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: 本文提出了一种AI驱动的医疗设备维修支持平台，结合大语言模型与用户友好的网页界面，帮助生物医学技术人员实时诊断和修复设备，已在Philips HDI 5000超声设备上验证其可行性。


<details>
  <summary>Details</summary>
Motivation: LMICs中大量医疗设备因缺乏及时维护、技术专家短缺及厂商支持不足而闲置或失灵，影响诊疗效率和患者安全。

Method: 开发一个集成大语言模型（LLM）的AI支持平台，提供错误代码解析、分步排障指导，并嵌入全球同行论坛；以Philips HDI 5000超声机为原型进行概念验证。

Result: 在原型测试中实现100%错误代码识别精度和80%纠正措施建议准确率。

Conclusion: 该AI平台在资源受限环境中具备可行性，有望显著降低设备停机时间，提升基层医疗服务质量。

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>


### [192] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601是一个5600亿参数的开源MoE推理模型，通过统一训练框架、环境扩展、噪声建模与Heavy Thinking推理模式，在代理式任务（搜索、工具使用等）上达到开源模型SOTA，并具备强泛化性与现实鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 提升开源大模型在真实复杂场景下的代理式推理能力，尤其解决工具交互泛化性差、多环境训练不稳定、现实噪声鲁棒性不足及长尾生成困难等问题。

Method: 提出统一训练框架：域并行专家训练+融合；扩展异步强化学习框架DORA以支持超万环境训练；系统建模现实噪声并融入训练；设计Heavy Thinking测试时推理模式，联合扩展推理深度与宽度。

Result: 在各类代理基准（搜索、工具使用、工具集成推理）上达开源模型SOTA；展现出对复杂工具交互的强泛化能力及噪声环境下的高鲁棒性；支持超大规模（>10,000环境、20+领域）稳定训练。

Conclusion: LongCat-Flash-Thinking-2601验证了端到端协同设计（数据、环境、算法、基础设施）与现实导向训练范式对构建高性能、高鲁棒开源推理模型的关键作用。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [193] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 本文提出了一种受昆虫启发的视觉点目标导航智能体，结合了与联想学习和路径积分相关的两种昆虫脑结构的抽象模型，在计算成本大幅降低的同时，性能媲美当前最先进模型。


<details>
  <summary>Details</summary>
Motivation: 受昆虫在自然环境中高效学习和导航能力的启发，旨在设计一种低计算成本、高鲁棒性的视觉导航方法，以应对现有深度学习模型计算开销大、泛化性弱的问题。

Method: 构建一个融合昆虫联想学习（如蘑菇体）和路径积分（如中央复合体）机制的简化神经网络模型，并将其应用于Habitat点目标导航基准任务。

Result: 该昆虫启发智能体在多个指标上达到与当前SOTA模型相当的性能，但计算成本降低数个数量级；在更真实的仿真环境中也表现出对扰动的强鲁棒性。

Conclusion: 昆虫神经系统中的简单计算机制可为高效、鲁棒的自主导航提供新范式，证明了生物启发方法在具身AI中的巨大潜力。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [194] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 本文研究了通过强化学习与可验证奖励（RLVR）训练的推理型大语言模型在心理理论（ToM）任务中的表现，发现其提升主要源于解题鲁棒性增强，而非具备真正的新形式ToM推理能力。


<details>
  <summary>Details</summary>
Motivation: 近期LLMs在ToM测试中表现强劲，引发对其内在能力本质的争议；同时，RLVR训练的推理型模型在多项基准上取得显著进步，亟需系统考察其在ToM任务中的真实行为机制。

Method: 采用新设计的机器心理学实验范式，并结合已有ToM基准测试，对RLVR训练的推理型LLM进行行为分析，重点评估其对提示变化和任务扰动的鲁棒性。

Result: 推理型模型在ToM任务中展现出对提示变化和任务扰动的一致更高鲁棒性；该提升更可能源于搜索正确解的能力增强，而非获得新的ToM推理机制。

Conclusion: 当前推理型LLM在ToM任务上的性能提升应谨慎解读为社会认知能力的实质性突破，而更可能是优化后的推理鲁棒性所致；这对未来LLM社会认知能力的评估具有重要启示。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [195] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: 本文提出MAGE-KT框架，通过多视角异构图建模学生、题目与知识概念间关系，结合多智能体KC关系抽取器与交互图，并利用非对称交叉注意力融合模块进行子图检索与融合，显著提升知识追踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络方法未能充分挖掘知识概念间的深层关系，且全图编码计算开销大、噪声多，导致注意力扩散和关系建模失真。

Method: 构建多视角异构图（含多智能体KC关系抽取器生成的语义图与学生-题目交互图），基于目标学生历史检索紧凑高价值子图，并通过非对称交叉注意力融合模块进行信息整合。

Result: 在三个主流KT数据集上，KC关系识别准确率与下题预测性能均显著优于现有方法。

Conclusion: MAGE-KT有效缓解了图结构噪声与注意力扩散问题，提升了知识概念关系建模的准确性与预测鲁棒性。

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [196] [Preventing the Collapse of Peer Review Requires Verification-First AI](https://arxiv.org/abs/2601.16909)
*Lei You,Lele Cao,Iryna Gurevych*

Main category: cs.AI

TL;DR: 本文主张AI辅助同行评审应以验证为先，而非模仿评审；提出'真实性耦合'作为评审工具的核心目标，并分析了导致评估体系转向代理主导的两种力量：验证压力与信号衰减；通过模型推导出耦合定律和激励崩溃条件，建议将AI用作生成可审计验证证据的对抗性审计员，而非仅预测分数的工具。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助评审多聚焦于模仿人类评审打分，但忽略了科学评审的根本目标——逼近科学真理；作者认为需重新定义评审工具的目标，转向以验证为核心。

Method: 提出‘真实性耦合’概念并形式化；构建一个融合高保真核查与代理判断的最小模型；推导耦合定律与激励崩溃条件；进行理论分析与机制设计。

Result: 发现当验证压力增大或信号衰减加剧时，系统可能发生相变，理性行为从追求真理转向优化代理指标；即使评审结果表面仍可靠，实质已发生激励塌缩。

Conclusion: AI评审工具应定位为扩展验证带宽的对抗性审计员，生成可审计的验证产物，而非强化声明通胀的分数预测器；该范式转变对工具开发者和会议主席具有明确行动指导意义。

Abstract: This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.

</details>


### [197] [AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems](https://arxiv.org/abs/2601.16964)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.AI

TL;DR: 本文提出了AgentDrive，一个包含30万LLM生成驾驶场景的开放基准数据集，用于训练和评估自主智能体；同时发布了AgentDrive-MCQ多选题基准（10万题），涵盖五类推理能力，并对50个主流大模型进行了大规模评测。


<details>
  <summary>Details</summary>
Motivation: 现有自主系统中，缺乏大规模、结构化且面向安全关键任务的基准来评估和训练基于LLM的智能体。

Method: 构建了七维正交因子化的驾驶场景空间；设计LLM驱动的prompt-to-JSON生成流程并施加物理与模式约束验证；通过仿真推演、代理安全指标计算和规则标注生成高质量场景；另构建覆盖五类推理维度的AgentDrive-MCQ多选题基准。

Result: 在AgentDrive-MCQ上对50个主流LLM的大规模评测表明：闭源前沿模型在上下文与策略推理上领先，而先进开源模型在结构化与物理 grounded 推理方面正快速追赶。

Conclusion: AgentDrive为基于LLM的自动驾驶智能体提供了可扩展、可验证、多维度的评估与训练基础设施，推动了安全关键型具身智能研究的发展。

Abstract: The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive

</details>


### [198] [Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts](https://arxiv.org/abs/2601.16965)
*Riyang Bao,Cheng Yang,Dazhou Yu,Zhexiang Tang,Gengchen Mai,Liang Zhao*

Main category: cs.AI

TL;DR: 本文提出Spatial-Agent，一种基于空间信息科学基础理论的AI代理，将地理分析问答形式化为概念转换问题，并通过GeoFlow图生成可执行的工作流，在MapEval-API和MapQA基准测试中显著优于ReAct和Reflexion等基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的代理在真实地理空间计算上表现不佳，常依赖网络搜索或模式匹配，且易产生空间关系幻觉。

Method: 将地理分析问答形式化为概念转换问题，使用GeoFlow图（有向无环图）表示可执行工作流；基于空间信息理论提取空间概念、分配功能角色并施加有序约束，通过模板生成组合变换序列。

Result: 在MapEval-API和MapQA基准上显著优于ReAct、Reflexion等现有基线，生成结果具有可解释性和可执行性。

Conclusion: Spatial-Agent通过理论驱动的结构化建模，有效提升了LLM在地理空间推理任务中的准确性与可靠性。

Abstract: Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.

</details>
