<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 105]
- [cs.CL](#cs.CL) [Total: 31]
- [cs.LG](#cs.LG) [Total: 75]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.AI](#cs.AI) [Total: 54]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Neuromorphic Eye Tracking for Low-Latency Pupil Detection](https://arxiv.org/abs/2512.09969)
*Paul Hueber,Luca Peres,Florian Pitters,Alejandro Gloriani,Oliver Rhodes*

Main category: cs.CV

TL;DR: 本文提出了一种基于脉冲神经网络（SNN）的高效事件驱动眼动追踪模型，通过用轻量级LIF层替代循环和注意力模块，并采用深度可分离卷积，显著降低模型复杂度与功耗，在保持接近顶尖性能（3.7–4.1px误差）的同时实现20倍模型压缩和850倍计算量下降，适用于低延迟、毫瓦级AR/VR可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 传统帧式眼动追踪在可穿戴系统中面临运动模糊、高计算开销和时间分辨率受限等问题，难以满足AR/VR对低延迟、低功耗和高响应性的实时交互需求；而现有SNN方案又存在泛化性差或精度不足的问题。

Method: 将高性能事件驱动眼动追踪ANN模型重构为SNN：用轻量级LIF神经元替代原有RNN和注意力模块，并引入深度可分离卷积以压缩模型；同时进行事件流输入适配与SNN训练优化。

Result: 所提SNN模型在眼动追踪任务上达到3.7–4.1像素平均误差，接近专用类视网膜系统Retina（3.24px）；模型尺寸减小20倍，理论计算量降低850倍；预计功耗仅3.9–4.9 mW，延迟3 ms（1 kHz），满足可穿戴实时部署要求。

Conclusion: 高性能事件驱动眼动追踪模型可成功转化为SNN架构，在几乎不损失精度的前提下获得巨大能效提升，验证了SNN在低功耗可穿戴感知系统中的实用潜力。

Abstract: Eye tracking for wearable systems demands low latency and milliwatt-level power, but conventional frame-based pipelines struggle with motion blur, high compute cost, and limited temporal resolution. Such capabilities are vital for enabling seamless and responsive interaction in emerging technologies like augmented reality (AR) and virtual reality (VR), where understanding user gaze is key to immersion and interface design. Neuromorphic sensors and spiking neural networks (SNNs) offer a promising alternative, yet existing SNN approaches are either too specialized or fall short of the performance of modern ANN architectures. This paper presents a neuromorphic version of top-performing event-based eye-tracking models, replacing their recurrent and attention modules with lightweight LIF layers and exploiting depth-wise separable convolutions to reduce model complexity. Our models obtain 3.7-4.1px mean error, approaching the accuracy of the application-specific neuromorphic system, Retina (3.24px), while reducing model size by 20x and theoretical compute by 850x, compared to the closest ANN variant of the proposed model. These efficient variants are projected to operate at an estimated 3.9-4.9 mW with 3 ms latency at 1 kHz. The present results indicate that high-performing event-based eye-tracking architectures can be redesigned as SNNs with substantial efficiency gains, while retaining accuracy suitable for real-time wearable deployment.

</details>


### [2] [ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects](https://arxiv.org/abs/2512.10031)
*Woojin Lee,Hyugjae Chang,Jaeho Moon,Jaehyup Lee,Munchurl Kim*

Main category: cs.CV

TL;DR: 本文提出ABBSPO框架，用于弱监督定向目标检测（WS-OOD），通过自适应边界框缩放（ABBS）和基于对称先验的角度损失（SPA）提升HBox监督下的RBox预测精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有HBox监督的OOD方法在将GT水平框与预测旋转框的最小外接矩形直接对比时，存在尺度估计不准、角度学习易崩溃等问题，亟需更鲁棒、精准的弱监督建模方法。

Method: 提出ABBSPO框架，包含两部分：(i) 自适应边界框缩放（ABBS），动态缩放GT HBox以匹配各预测RBox尺寸；(ii) 对称先验角度损失（SPA），利用航拍目标固有对称性，在原始、旋转、翻转三视图间构建自监督约束。

Result: 在多个标准数据集上取得SOTA性能，显著优于现有弱监督OOD方法。

Conclusion: ABBSPO有效缓解了HBox监督下尺度失配与角度学习崩溃问题，验证了自适应缩放与对称先验在弱监督定向检测中的有效性与泛化能力。

Abstract: Weakly supervised oriented object detection (WS-OOD) has gained attention as a cost-effective alternative to fully supervised methods, providing both efficiency and high accuracy. Among weakly supervised approaches, horizontal bounding box (HBox)-supervised OOD stands out for its ability to directly leverage existing HBox annotations while achieving the highest accuracy under weak supervision settings. This paper introduces adaptive bounding box scaling and symmetry-prior-based orientation prediction, called ABBSPO, a framework for WS-OOD. Our ABBSPO addresses limitations of previous HBox-supervised OOD methods, which compare ground truth (GT) HBoxes directly with the minimum circumscribed rectangles of predicted RBoxes, often leading to inaccurate scale estimation. To overcome this, we propose: (i) Adaptive Bounding Box Scaling (ABBS), which appropriately scales GT HBoxes to optimize for the size of each predicted RBox, ensuring more accurate scale prediction; and (ii) a Symmetric Prior Angle (SPA) loss that exploits inherent symmetry of aerial objects for self-supervised learning, resolving issues in previous methods where learning collapses when predictions for all three augmented views (original, rotated, and flipped) are consistently incorrect. Extensive experimental results demonstrate that ABBSPO achieves state-of-the-art performance, outperforming existing methods.

</details>


### [3] [What matters for Representation Alignment: Global Information or Spatial Structure?](https://arxiv.org/abs/2512.10794)
*Jaskirat Singh,Xingjian Leng,Zongze Wu,Liang Zheng,Richard Zhang,Eli Shechtman,Saining Xie*

Main category: cs.CV

TL;DR: 本文发现，在表示对齐（REPA）中，目标视觉编码器表征的空间结构（而非全局语义性能）更关键地影响生成质量；为此提出iREPA方法，仅用少量代码改进空间信息传递，显著提升多种REPA变体的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 探究在表示对齐（REPA）中，目标视觉编码器表征的哪一特性（全局语义能力 vs. 空间结构）真正决定生成性能，挑战‘更强语义即更好生成’的既有认知。

Method: 1）大规模实证分析27种视觉编码器；2）提出iREPA：将REPA中的MLP投影层替换为卷积层，并引入外部表征的空间归一化层。

Result: 证实空间结构（如patch token间余弦相似性）比ImageNet-1K准确率等全局语义指标更能预测生成性能；iREPA在多种编码器、模型规模及REPA变体（REPA、REPA-E、Meanflow、JiT等）上均加速收敛。

Conclusion: 表征对齐的有效性主要源于空间结构信息的迁移，而非语义判别能力；iREPA以极简设计验证该机制，并为生成模型训练提供新思路。

Abstract: Representation alignment (REPA) guides generative training by distilling representations from a strong, pretrained vision encoder to intermediate diffusion features. We investigate a fundamental question: what aspect of the target representation matters for generation, its \textit{global} \revision{semantic} information (e.g., measured by ImageNet-1K accuracy) or its spatial structure (i.e. pairwise cosine similarity between patch tokens)? Prevalent wisdom holds that stronger global semantic performance leads to better generation as a target representation. To study this, we first perform a large-scale empirical analysis across 27 different vision encoders and different model scales. The results are surprising; spatial structure, rather than global performance, drives the generation performance of a target representation. To further study this, we introduce two straightforward modifications, which specifically accentuate the transfer of \emph{spatial} information. We replace the standard MLP projection layer in REPA with a simple convolution layer and introduce a spatial normalization layer for the external representation. Surprisingly, our simple method (implemented in $<$4 lines of code), termed iREPA, consistently improves convergence speed of REPA, across a diverse set of vision encoders, model sizes, and training variants (such as REPA, REPA-E, Meanflow, JiT etc). %, etc. Our work motivates revisiting the fundamental working mechanism of representational alignment and how it can be leveraged for improved training of generative models. The code and project page are available at https://end2end-diffusion.github.io/irepa

</details>


### [4] [Diffusion Is Your Friend in Show, Suggest and Tell](https://arxiv.org/abs/2512.10038)
*Jia Cheng Hu,Roberto Cavicchioli,Alessandro Capotondi*

Main category: cs.CV

TL;DR: 本文提出了一种新范式，将扩散模型作为建议模块辅助自回归生成，而非直接替代；所提出的Show, Suggest and Tell (SST)方法在COCO数据集上达到SOTA性能（125.1 CIDEr-D），无需强化学习，并验证了建议模块对文本质量的正向影响。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在连续域表现优异，但在离散生成任务（如图像描述）中仍弱于自回归模型；作者旨在融合二者优势：扩散模型的双向建模与迭代优化能力，以及自回归模型对语言结构的强建模能力。

Method: 提出Show, Suggest and Tell (SST)框架，其中扩散模型生成多候选词或短语作为‘建议’，由自回归解码器整合并生成最终描述；建议模块可插拔、可训练，且不改变主干自回归架构。

Result: SST在COCO测试集上取得125.1 CIDEr-D得分，超越当时自回归和扩散类SOTA分别1.5和2.5分；消融与相关性分析证实建议质量与最终caption质量呈正相关。

Conclusion: 将扩散模型用作自回归生成的辅助建议器是有效且有潜力的新方向，为离散生成任务提供了兼顾结构严谨性与内容丰富性的新思路。

Abstract: Diffusion Denoising models demonstrated impressive results across generative Computer Vision tasks, but they still fail to outperform standard autoregressive solutions in the discrete domain, and only match them at best. In this work, we propose a different paradigm by adopting diffusion models to provide suggestions to the autoregressive generation rather than replacing them. By doing so, we combine the bidirectional and refining capabilities of the former with the strong linguistic structure provided by the latter. To showcase its effectiveness, we present Show, Suggest and Tell (SST), which achieves State-of-the-Art results on COCO, among models in a similar setting. In particular, SST achieves 125.1 CIDEr-D on the COCO dataset without Reinforcement Learning, outperforming both autoregressive and diffusion model State-of-the-Art results by 1.5 and 2.5 points. On top of the strong results, we performed extensive experiments to validate the proposal and analyze the impact of the suggestion module. Results demonstrate a positive correlation between suggestion and caption quality, overall indicating a currently underexplored but promising research direction. Code will be available at: https://github.com/jchenghu/show\_suggest\_tell.

</details>


### [5] [MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata](https://arxiv.org/abs/2512.10041)
*Yihao Liu,Chenyu Gao,Lianrui Zuo,Michael E. Kim,Brian D. Boyd,Lisa L. Barnes,Walter A. Kukull,Lori L. Beason-Held,Susan M. Resnick,Timothy J. Hohman,Warren D. Taylor,Bennett A. Landman*

Main category: cs.CV

TL;DR: MetaVoxel是一种生成式联合扩散建模框架，通过单个扩散过程建模医学影像与临床元数据的联合分布，从而统一多种医疗AI任务并支持零样本灵活推理。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法通常针对特定预测方向和输入变量建模条件分布，难以统一多任务且缺乏灵活性；本文旨在构建能建模影像与临床数据联合分布的通用框架。

Method: 提出MetaVoxel框架，采用单一扩散过程建模影像（如T1加权MRI）与临床元数据（如年龄、性别）的联合分布，实现跨模态生成与零样本推理。

Result: 在来自9个数据集的10,000+例MRI及配套临床数据上验证，单个MetaVoxel模型可同时完成图像生成、年龄估计与性别预测，性能媲美各任务专用基线模型，并展现出灵活推理能力。

Conclusion: 联合多模态扩散建模为统一医疗AI模型、提升临床适用性提供了新路径。

Abstract: Modern deep learning methods have achieved impressive results across tasks from disease classification, estimating continuous biomarkers, to generating realistic medical images. Most of these approaches are trained to model conditional distributions defined by a specific predictive direction with a specific set of input variables. We introduce MetaVoxel, a generative joint diffusion modeling framework that models the joint distribution over imaging data and clinical metadata by learning a single diffusion process spanning all variables. By capturing the joint distribution, MetaVoxel unifies tasks that traditionally require separate conditional models and supports flexible zero-shot inference using arbitrary subsets of inputs without task-specific retraining. Using more than 10,000 T1-weighted MRI scans paired with clinical metadata from nine datasets, we show that a single MetaVoxel model can perform image generation, age estimation, and sex prediction, achieving performance comparable to established task-specific baselines. Additional experiments highlight its capabilities for flexible inference.Together, these findings demonstrate that joint multimodal diffusion offers a promising direction for unifying medical AI models and enabling broader clinical applicability.

</details>


### [6] [Independent Density Estimation](https://arxiv.org/abs/2512.10067)
*Jiahao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为独立密度估计（IDE）的新方法，旨在提升大规模视觉-语言模型在未见组合上的泛化能力，通过建立单词与图像特征间的对应关系，并结合熵驱动的组合推理方法，在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有大规模视觉-语言模型在人类水平的组合泛化能力上仍存在不足。

Method: 提出独立密度估计（IDE）方法，构建两种模型：一种以完全解耦的视觉表征为输入，另一种利用变分自编码器从原始图像中提取部分解耦特征；并设计基于熵的组合推理方法来整合各词预测结果。

Result: 所提模型在多个数据集上对未见组合的泛化性能优于当前主流模型。

Conclusion: IDE方法有效提升了视觉-语言模型的 compositional generalization 能力，验证了解耦表征与熵驱动推理在该任务中的有效性。

Abstract: Large-scale Vision-Language models have achieved remarkable results in various domains, such as image captioning and conditioned image generation. Neverthe- less, these models still encounter difficulties in achieving human-like composi- tional generalization. In this study, we propose a new method called Independent Density Estimation (IDE) to tackle this challenge. IDE aims to learn the connec- tion between individual words in a sentence and the corresponding features in an image, enabling compositional generalization. We build two models based on the philosophy of IDE. The first one utilizes fully disentangled visual representations as input, and the second leverages a Variational Auto-Encoder to obtain partially disentangled features from raw images. Additionally, we propose an entropy- based compositional inference method to combine predictions of each word in the sentence. Our models exhibit superior generalization to unseen compositions compared to current models when evaluated on various datasets.

</details>


### [7] [TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing](https://arxiv.org/abs/2512.10095)
*Jiachen Tao,Junyi Wu,Haoxuan Wang,Zongxin Yang,Dawen Cai,Yan Yan*

Main category: cs.CV

TL;DR: TraceFlow 是一种用于高保真渲染动态镜面场景的新框架，通过残差材质增强的2D高斯点绘表示、动态环境高斯模型和混合渲染管线，实现了精确反射方向估计与物理准确的反射建模。


<details>
  <summary>Details</summary>
Motivation: 解决动态镜面场景中反射方向估计不精确和反射建模物理真实性不足两大挑战。

Method: 提出残差材质增强的2D高斯点绘表示以建模动态几何与材质；设计动态环境高斯与混合渲染管线（分解为漫反射与镜面反射分量，分别用光栅化与光线追踪合成）；采用由粗到细的训练策略提升优化稳定性与物理可解释性分解。

Result: 在动态场景基准测试中，TraceFlow 在定量与定性指标上均超越先前方法，生成更锐利、更真实的镜面反射效果。

Conclusion: TraceFlow 有效提升了动态镜面场景的高保真渲染质量，兼顾几何动态性、材质变化与物理合理性。

Abstract: We present TraceFlow, a novel framework for high-fidelity rendering of dynamic specular scenes by addressing two key challenges: precise reflection direction estimation and physically accurate reflection modeling. To achieve this, we propose a Residual Material-Augmented 2D Gaussian Splatting representation that models dynamic geometry and material properties, allowing accurate reflection ray computation. Furthermore, we introduce a Dynamic Environment Gaussian and a hybrid rendering pipeline that decomposes rendering into diffuse and specular components, enabling physically grounded specular synthesis via rasterization and ray tracing. Finally, we devise a coarse-to-fine training strategy to improve optimization stability and promote physically meaningful decomposition. Extensive experiments on dynamic scene benchmarks demonstrate that TraceFlow outperforms prior methods both quantitatively and qualitatively, producing sharper and more realistic specular reflections in complex dynamic environments.

</details>


### [8] [Hierarchical Instance Tracking to Balance Privacy Preservation with Accessible Information](https://arxiv.org/abs/2512.10102)
*Neelima Prasad,Jarek Reynolds,Neel Karsanbhai,Tanusree Sharma,Lotus Zhang,Abigale Stangl,Yang Wang,Leah Findlater,Danna Gurari*

Main category: cs.CV

TL;DR: 本文提出了分层实例跟踪的新任务，并构建了首个支持该任务的基准数据集，包含552个视频中2765个唯一实体，涵盖40个物体及部件类别。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪任务未充分考虑物体与其部件之间的层次关系，因此需要提出一种能同时跟踪物体及其部件并保持其层级结构的新任务。

Method: 设计了分层实例跟踪任务定义，构建了大规模标注数据集，并对四种模型的七种变体进行了评估。

Result: 实验表明该新数据集具有挑战性，为后续研究提供了重要基准。

Conclusion: 分层实例跟踪是一个有意义的新方向，所构建的数据集和评估结果将推动物体-部件联合理解与跟踪的发展。

Abstract: We propose a novel task, hierarchical instance tracking, which entails tracking all instances of predefined categories of objects and parts, while maintaining their hierarchical relationships. We introduce the first benchmark dataset supporting this task, consisting of 2,765 unique entities that are tracked in 552 videos and belong to 40 categories (across objects and parts). Evaluation of seven variants of four models tailored to our novel task reveals the new dataset is challenging. Our dataset is available at https://vizwiz.org/tasks-and-datasets/hierarchical-instance-tracking/

</details>


### [9] [Topological Conditioning for Mammography Models via a Stable Wavelet-Persistence Vectorization](https://arxiv.org/abs/2512.10151)
*Charles Fanning,Mehmet Emin Aktas*

Main category: cs.CV

TL;DR: 本文提出了一种基于小波持久同调的条件信号方法，以提升乳腺癌筛查模型在跨设备、跨人群场景下的泛化性能，并在多个国际数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌筛查中，现有模型在不同扫描仪、成像模态和患者群体间性能下降明显，存在高假阴性和假阳性问题，亟需提升模型的外部泛化能力。

Method: 利用拓扑数据分析（TDA）提取图像在多强度阈值下稳定的结构特征，通过小波变换进行向量化，生成对强度扰动鲁棒的空间多尺度图；将这些图作为额外通道与原始图像拼接，嵌入两阶段检测流程，并采用ConvNeXt Tiny架构进行训练。

Result: 在葡萄牙INbreast数据集上，使用有限训练预算时，加入小波持久性通道后患者级AUC从0.55显著提升至0.75；模型还在中国CMMD数据集上完成跨域评估。

Conclusion: 小波持久同调作为一种稳定、可解释的结构先验，能有效增强深度模型在异构医疗影像数据上的泛化能力，为鲁棒乳腺癌筛查提供了新思路。

Abstract: Breast cancer is the most commonly diagnosed cancer in women and a leading cause of cancer death worldwide. Screening mammography reduces mortality, yet interpretation still suffers from substantial false negatives and false positives, and model accuracy often degrades when deployed across scanners, modalities, and patient populations. We propose a simple conditioning signal aimed at improving external performance based on a wavelet based vectorization of persistent homology. Using topological data analysis, we summarize image structure that persists across intensity thresholds and convert this information into spatial, multi scale maps that are provably stable to small intensity perturbations. These maps are integrated into a two stage detection pipeline through input level channel concatenation. The model is trained and validated on the CBIS DDSM digitized film mammography cohort from the United States and evaluated on two independent full field digital mammography cohorts from Portugal (INbreast) and China (CMMD), with performance reported at the patient level. On INbreast, augmenting ConvNeXt Tiny with wavelet persistence channels increases patient level AUC from 0.55 to 0.75 under a limited training budget.

</details>


### [10] [Feature Coding for Scalable Machine Vision](https://arxiv.org/abs/2512.10209)
*Md Eimran Hossain Eimon,Juan Merlos,Ashan Perera,Hari Kalva,Velibor Adzic,Borko Furht*

Main category: cs.CV

TL;DR: This paper introduces the Feature Coding Test Model (FCTM) for compressing intermediate features in split DNN inference, achieving 85.14% average bitrate reduction without accuracy loss, supporting efficient, privacy-aware edge-cloud vision systems.


<details>
  <summary>Details</summary>
Motivation: To overcome bandwidth bottlenecks in edge-cloud split inference of DNNs for machine vision, especially under constraints of latency, bandwidth, and privacy.

Method: Design and evaluation of the Feature Coding Test Model (FCTM), aligned with the MPEG Feature Coding for Machines (FCM) standard, for compressing intermediate DNN features.

Result: FCTM achieves an average 85.14% bitrate reduction across multiple vision tasks while preserving model accuracy.

Conclusion: FCM and FCTM provide a scalable, interoperable, and efficient solution for deploying intelligent vision features in bandwidth-limited and privacy-sensitive edge applications.

Abstract: Deep neural networks (DNNs) drive modern machine vision but are challenging to deploy on edge devices due to high compute demands. Traditional approaches-running the full model on-device or offloading to the cloud face trade-offs in latency, bandwidth, and privacy. Splitting the inference workload between the edge and the cloud offers a balanced solution, but transmitting intermediate features to enable such splitting introduces new bandwidth challenges. To address this, the Moving Picture Experts Group (MPEG) initiated the Feature Coding for Machines (FCM) standard, establishing a bitstream syntax and codec pipeline tailored for compressing intermediate features. This paper presents the design and performance of the Feature Coding Test Model (FCTM), showing significant bitrate reductions-averaging 85.14%-across multiple vision tasks while preserving accuracy. FCM offers a scalable path for efficient and interoperable deployment of intelligent features in bandwidth-limited and privacy-sensitive consumer applications.

</details>


### [11] [Latent Chain-of-Thought World Modeling for End-to-End Driving](https://arxiv.org/abs/2512.10226)
*Shuhan Tan,Kashyap Chitta,Yuxiao Chen,Ran Tian,Yurong You,Yan Wang,Wenjie Luo,Yulong Cao,Philipp Krahenbuhl,Marco Pavone,Boris Ivanovic*

Main category: cs.CV

TL;DR: 本文提出Latent-CoT-Drive（LCDrive），一种在潜在空间中进行链式推理（CoT）的视觉-语言-动作模型，用于自动驾驶。它用动作对齐的潜在语言替代自然语言进行推理，融合动作提议与基于世界模型的未来状态预测，并通过真实轨迹监督冷启动和闭环强化学习优化，显著提升推理速度、轨迹质量与学习效果。


<details>
  <summary>Details</summary>
Motivation: 自然语言作为链式推理（CoT）的表示方式在自动驾驶中可能效率不高；需更紧凑、动作对齐、可微且能直接关联未来状态的推理表征。

Method: 提出LCDrive模型：（1）使用与输出动作共享词表的动作提议token；（2）引入基于学习到的潜在世界模型的世界模型token，表征各动作的未来结果；二者在统一潜在空间中交替生成；通过真实未来轨迹监督冷启动，再以闭环强化学习后训练增强推理能力。

Result: 在大规模端到端驾驶基准上，LCDrive相比无推理和文本推理基线：推理更快、轨迹质量更高、交互式强化学习带来的性能增益更大。

Conclusion: 在潜在空间中建模链式推理（Latent-CoT）比自然语言CoT更适配自动驾驶任务，实现了推理与决策的统一建模，提升了性能与训练效率。

Abstract: Recent Vision-Language-Action (VLA) models for autonomous driving explore inference-time reasoning as a way to improve driving performance and safety in challenging scenarios. Most prior work uses natural language to express chain-of-thought (CoT) reasoning before producing driving actions. However, text may not be the most efficient representation for reasoning. In this work, we present Latent-CoT-Drive (LCDrive): a model that expresses CoT in a latent language that captures possible outcomes of the driving actions being considered. Our approach unifies CoT reasoning and decision making by representing both in an action-aligned latent space. Instead of natural language, the model reasons by interleaving (1) action-proposal tokens, which use the same vocabulary as the model's output actions; and (2) world model tokens, which are grounded in a learned latent world model and express future outcomes of these actions. We cold start latent CoT by supervising the model's action proposals and world model tokens based on ground-truth future rollouts of the scene. We then post-train with closed-loop reinforcement learning to strengthen reasoning capabilities. On a large-scale end-to-end driving benchmark, LCDrive achieves faster inference, better trajectory quality, and larger improvements from interactive reinforcement learning compared to both non-reasoning and text-reasoning baselines.

</details>


### [12] [Emerging Standards for Machine-to-Machine Video Coding](https://arxiv.org/abs/2512.10230)
*Md Eimran Hossain Eimon,Velibor Adzic,Hari Kalva,Borko Furht*

Main category: cs.CV

TL;DR: 本文提出了一种面向机器视觉任务的新型视频编码框架（FCM），通过压缩神经网络中间特征而非原始像素，显著降低带宽、保护隐私并支持计算卸载；实验表明HEVC与VVC在多数任务中性能相近，而H.264性能较差，但在目标跟踪任务中现有硬件编解码器已足够高效。


<details>
  <summary>Details</summary>
Motivation: 现有机器视觉系统多采用面向人眼的视频编码（如H.264/HEVC/VVC）传输原始像素，导致带宽浪费、扩展性差及隐私泄露；亟需面向机器感知的、任务驱动的高效编码新范式。

Method: 提出Feature Coding for Machines（FCM）框架，直接压缩神经网络中间特征；将H.264、HEVC和VVC作为FCM内部的特征压缩编解码器进行对比评估，并在多种机器视觉任务（如分类、检测、跟踪）上测试其BD-Rate与精度权衡。

Result: FCM可在大幅降低比特率的同时保持接近边缘推理的精度；HEVC与VVC在多数任务中性能几乎一致（BD-Rate差异仅1.39%），而H.264比VVC差32.28%；但在跟踪任务中，HEVC略优于VVC（BD-Rate -1.81%），H.264仍可用（+8.79%）。

Conclusion: FCM是一种可行且高效的机器视觉通信新范式；现有HEVC硬件已能较好支撑多数机器任务，无需全面升级至VVC，有利于快速部署与兼容性。

Abstract: Machines are increasingly becoming the primary consumers of visual data, yet most deployments of machine-to-machine systems still rely on remote inference where pixel-based video is streamed using codecs optimized for human perception. Consequently, this paradigm is bandwidth intensive, scales poorly, and exposes raw images to third parties. Recent efforts in the Moving Picture Experts Group (MPEG) redesigned the pipeline for machine-to-machine communication: Video Coding for Machines (VCM) is designed to apply task-aware coding tools in the pixel domain, and Feature Coding for Machines (FCM) is designed to compress intermediate neural features to reduce bitrate, preserve privacy, and support compute offload. Experiments show that FCM is capable of maintaining accuracy close to edge inference while significantly reducing bitrate. Additional analysis of H.26X codecs used as inner codecs in FCM reveals that H.265/High Efficiency Video Coding (HEVC) and H.266/Versatile Video Coding (VVC) achieve almost identical machine task performance, with an average BD-Rate increase of 1.39% when VVC is replaced with HEVC. In contrast, H.264/Advanced Video Coding (AVC) yields an average BD-Rate increase of 32.28% compared to VVC. However, for the tracking task, the impact of codec choice is minimal, with HEVC outperforming VVC and achieving BD Rate of -1.81% and 8.79% for AVC, indicating that existing hardware for already deployed codecs can support machine-to-machine communication without degrading performance.

</details>


### [13] [Multi-dimensional Preference Alignment by Conditioning Reward Itself](https://arxiv.org/abs/2512.10237)
*Jiho Jang,Jinyoung Kim,Kyungjune Baek,Nojun Kwak*

Main category: cs.CV

TL;DR: 本文提出了一种多奖励条件DPO（MCDPO）方法，以解决标准DPO在扩散模型中因使用Bradley-Terry模型聚合多维人类反馈而引发的奖励冲突问题；通过解耦奖励建模、条件化偏好向量和维度奖励Dropout，实现单网络内各维度独立优化，并支持推理时无需额外训练的多轴动态控制。


<details>
  <summary>Details</summary>
Motivation: 标准DPO依赖Bradley-Terry模型将美学质量、语义对齐等多维评估轴聚合成单一标量奖励，导致奖励冲突——模型可能因全局偏好而遗忘某维度上的优良特征。

Method: 提出Multi Reward Conditional DPO（MCDPO）：1）引入解耦的Bradley-Terry目标；2）将偏好结果向量作为条件注入训练过程，使单网络能独立优化各奖励维度；3）加入维度奖励Dropout以平衡各维度优化。

Result: 在Stable Diffusion 1.5和SDXL上实验表明，MCDPO在多个基准上性能更优；其条件框架支持通过Classifier-Free Guidance在推理时动态增强特定奖励维度，无需额外训练或外部奖励模型。

Conclusion: MCDPO有效缓解了多维人类反馈中的奖励冲突问题，提升了扩散模型对齐的细粒度可控性与整体性能，为RLHF在生成模型中的应用提供了新范式。

Abstract: Reinforcement Learning from Human Feedback has emerged as a standard for aligning diffusion models. However, we identify a fundamental limitation in the standard DPO formulation because it relies on the Bradley-Terry model to aggregate diverse evaluation axes like aesthetic quality and semantic alignment into a single scalar reward. This aggregation creates a reward conflict where the model is forced to unlearn desirable features of a specific dimension if they appear in a globally non-preferred sample. To address this issue, we propose Multi Reward Conditional DPO (MCDPO). This method resolves reward conflicts by introducing a disentangled Bradley-Terry objective. MCDPO explicitly injects a preference outcome vector as a condition during training, which allows the model to learn the correct optimization direction for each reward axis independently within a single network. We further introduce dimensional reward dropout to ensure balanced optimization across dimensions. Extensive experiments on Stable Diffusion 1.5 and SDXL demonstrate that MCDPO achieves superior performance on benchmarks. Notably, our conditional framework enables dynamic and multiple-axis control at inference time using Classifier Free Guidance to amplify specific reward dimensions without additional training or external reward models.

</details>


### [14] [Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective](https://arxiv.org/abs/2512.10244)
*Tian Liu,Anwesha Basu,James Caverlee,Shu Kong*

Main category: cs.CV

TL;DR: 本文提出SWIFT方法，通过分类器初始化和温度调优解决VLM在半监督少样本学习中softmax分布过平导致的伪标签置信度低问题，显著提升未标注数据利用率和性能，在多个基准上超越现有方法约5个准确率点，接近全监督学习效果。


<details>
  <summary>Details</summary>
Motivation: 现实中的自动标注等任务需要半监督少样本学习（SSFSL），但现有SSFSL研究忽视了强大的开源视觉语言模型（VLM）及其预训练数据；而相关领域FSL已成功利用这些资源，因此SSFSL亟需有效融合VLM与开放资源。

Method: 发现VLM在SSFSL中因softmax分布过平导致伪标签无效，进而提出简单有效的分类器初始化与温度调优策略，并构建分阶段微调框架SWIFT，支持在少量标注、大量未标注及从VLM预训练集中检索出的相关但含噪数据上联合微调VLM。

Result: 在五个SSFSL基准上，SWIFT比近期FSL和SSL方法平均高出约5个准确率点，甚至可媲美使用真实标签标注全部未标注数据的全监督微调方法。

Conclusion: VLM在SSFSL中的潜力被低估，关键在于校准其输出置信度；SWIFT以极简设计释放VLM在半监督少样本场景下的能力，为自动标注等实际应用提供了高效可行的新范式。

Abstract: Semi-supervised few-shot learning (SSFSL) formulates real-world applications like ''auto-annotation'', as it aims to learn a model over a few labeled and abundant unlabeled examples to annotate the unlabeled ones. Despite the availability of powerful open-source Vision-Language Models (VLMs) and their pretraining data, the SSFSL literature largely neglects these open-source resources. In contrast, the related area few-shot learning (FSL) has already exploited them to boost performance. Arguably, to achieve auto-annotation in the real world, SSFSL should leverage such open-source resources. To this end, we start by applying established SSL methods to finetune a VLM. Counterintuitively, they significantly underperform FSL baselines. Our in-depth analysis reveals the root cause: VLMs produce rather ''flat'' distributions of softmax probabilities. This results in zero utilization of unlabeled data and weak supervision signals. We address this issue with embarrassingly simple techniques: classifier initialization and temperature tuning. They jointly increase the confidence scores of pseudo-labels, improving the utilization rate of unlabeled data, and strengthening supervision signals. Building on this, we propose: Stage-Wise Finetuning with Temperature Tuning (SWIFT), which enables existing SSL methods to effectively finetune a VLM on limited labeled data, abundant unlabeled data, and task-relevant but noisy data retrieved from the VLM's pretraining set. Extensive experiments on five SSFSL benchmarks show that SWIFT outperforms recent FSL and SSL methods by $\sim$5 accuracy points. SWIFT even rivals supervised learning, which finetunes VLMs with the unlabeled data being labeled with ground truth!

</details>


### [15] [RobustSora: De-Watermarked Benchmark for Robust AI-Generated Video Detection](https://arxiv.org/abs/2512.10248)
*Zhuo Wang,Xiliang Liu,Ligang Sun*

Main category: cs.CV

TL;DR: 本文提出RobustSora基准，系统评估AI生成视频检测器对数字水印的依赖性，发现多种模型存在2-8个百分点的性能波动，揭示其部分依赖水印，并呼吁水印感知的训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC视频检测基准忽视了生成模型嵌入数字水印这一关键因素，导致检测器可能依赖水印而非真实伪造特征，影响检测鲁棒性与泛化能力。

Method: 构建包含6500个视频的RobustSora基准数据集，涵盖四类视频（真实清洁、真实加伪水印、生成带水印、生成去水印），并设计两项任务：Task-I评估去水印AI视频检测性能，Task-II评估对加伪水印真实视频的误报率；在十种模型（专用检测器、Transformer、MLLM）上开展实验分析。

Result: 实验显示 watermark manipulation 导致模型性能下降2–8个百分点；Transformer模型表现出一致中度水印依赖（6–8pp），MLLM则呈现多样性（2–8pp）；证实当前检测器存在部分水印依赖。

Conclusion: AIGC视频检测器普遍存在对嵌入水印的非预期依赖，削弱其鲁棒性；需发展水印感知的训练范式与更鲁棒的检测方法；RobustSora为推动该方向研究提供了关键基准工具。

Abstract: The proliferation of AI-generated video technologies poses challenges to information integrity. While recent benchmarks advance AIGC video detection, they overlook a critical factor: many state-of-the-art generative models embed digital watermarks in outputs, and detectors may partially rely on these patterns. To evaluate this influence, we present RobustSora, the benchmark designed to assess watermark robustness in AIGC video detection. We systematically construct a dataset of 6,500 videos comprising four types: Authentic-Clean (A-C), Authentic-Spoofed with fake watermarks (A-S), Generated-Watermarked (G-W), and Generated-DeWatermarked (G-DeW). Our benchmark introduces two evaluation tasks: Task-I tests performance on watermark-removed AI videos, while Task-II assesses false alarm rates on authentic videos with fake watermarks. Experiments with ten models spanning specialized AIGC detectors, transformer architectures, and MLLM approaches reveal performance variations of 2-8pp under watermark manipulation. Transformer-based models show consistent moderate dependency (6-8pp), while MLLMs exhibit diverse patterns (2-8pp). These findings indicate partial watermark dependency and highlight the need for watermark-aware training strategies. RobustSora provides essential tools to advance robust AIGC detection research.

</details>


### [16] [THE-Pose: Topological Prior with Hybrid Graph Fusion for Estimating Category-Level 6D Object Pose](https://arxiv.org/abs/2512.10251)
*Eunho Lee,Chaehyeon Song,Seunghoon Jeong,Ayoung Kim*

Main category: cs.CV

TL;DR: 本文提出THE-Pose框架，通过引入拓扑先验与混合图融合（HGF），融合2D图像上下文与3D几何结构，显著提升类别级6D位姿估计鲁棒性与精度。


<details>
  <summary>Details</summary>
Motivation: 现有3D图卷积方法仅依赖局部几何和深度信息，难以应对类内变化、复杂物体及视觉歧义。

Method: 提出基于表面嵌入的拓扑先验建模，并设计混合图融合（HGF）模块，自适应融合图像域提取的拓扑特征与点云几何特征。

Result: 在REAL275数据集上相较3D-GC基线HS-Pose提升35.8%，全面超越此前SOTA 7.2%。

Conclusion: 拓扑先验与跨模态图融合可有效增强类别级位姿估计对遮挡、复杂形状和未见物体的泛化能力。

Abstract: Category-level object pose estimation requires both global context and local structure to ensure robustness against intra-class variations. However, 3D graph convolution (3D-GC) methods only focus on local geometry and depth information, making them vulnerable to complex objects and visual ambiguities. To address this, we present THE-Pose, a novel category-level 6D pose estimation framework that leverages a topological prior via surface embedding and hybrid graph fusion. Specifically, we extract consistent and invariant topological features from the image domain, effectively overcoming the limitations inherent in existing 3D-GC based methods. Our Hybrid Graph Fusion (HGF) module adaptively integrates the topological features with point-cloud features, seamlessly bridging 2D image context and 3D geometric structure. These fused features ensure stability for unseen or complicated objects, even under significant occlusions. Extensive experiments on the REAL275 dataset show that THE-Pose achieves a 35.8% improvement over the 3D-GC baseline (HS-Pose) and surpasses the previous state-of-the-art by 7.2% across all key metrics. The code is avaialbe on https://github.com/EHxxx/THE-Pose

</details>


### [17] [GDKVM: Echocardiography Video Segmentation via Spatiotemporal Key-Value Memory with Gated Delta Rule](https://arxiv.org/abs/2512.10252)
*Rui Wang,Yimu Sun,Jingxing Guo,Huisi Wu,Jing Qin*

Main category: cs.CV

TL;DR: 本文提出GDKVM模型，用于超声心动图视频的心脏腔室分割，通过LKVA、GDR和KPFF模块提升长程时空建模能力与鲁棒性，在CAMUS和EchoNet-Dynamic数据集上实现高精度、实时分割。


<details>
  <summary>Details</summary>
Motivation: 超声心动图视频中存在噪声、伪影及心脏形变运动，现有方法难以兼顾长程时空依赖建模与计算效率及细粒度特征表达。

Method: 提出GDKVM架构，包含Linear Key-Value Association（LKVA）建模帧间相关性、Gated Delta Rule（GDR）高效存储中间记忆状态、Key-Pixel Feature Fusion（KPFF）多尺度融合局部与全局特征。

Result: 在CAMUS和EchoNet-Dynamic数据集上，GDKVM在分割精度和鲁棒性上优于现有SOTA方法，同时保持实时性能。

Conclusion: GDKVM有效解决了超声视频分割中时空建模与效率的权衡问题，为临床定量分析提供更可靠、高效的工具。

Abstract: Accurate segmentation of cardiac chambers in echocardiography sequences is crucial for the quantitative analysis of cardiac function, aiding in clinical diagnosis and treatment. The imaging noise, artifacts, and the deformation and motion of the heart pose challenges to segmentation algorithms. While existing methods based on convolutional neural networks, Transformers, and space-time memory networks have improved segmentation accuracy, they often struggle with the trade-off between capturing long-range spatiotemporal dependencies and maintaining computational efficiency with fine-grained feature representation. In this paper, we introduce GDKVM, a novel architecture for echocardiography video segmentation. The model employs Linear Key-Value Association (LKVA) to effectively model inter-frame correlations, and introduces Gated Delta Rule (GDR) to efficiently store intermediate memory states. Key-Pixel Feature Fusion (KPFF) module is designed to integrate local and global features at multiple scales, enhancing robustness against boundary blurring and noise interference. We validated GDKVM on two mainstream echocardiography video datasets (CAMUS and EchoNet-Dynamic) and compared it with various state-of-the-art methods. Experimental results show that GDKVM outperforms existing approaches in terms of segmentation accuracy and robustness, while ensuring real-time performance. Code is available at https://github.com/wangrui2025/GDKVM.

</details>


### [18] [VLM-NCD:Novel Class Discovery with Vision-Based Large Language Models](https://arxiv.org/abs/2512.10262)
*Yuetong Su,Baoguo Wei,Xinyu Wang,Xu Li,Lixin Li*

Main category: cs.CV

TL;DR: 本文提出LLM-NCD，一种融合视觉-文本语义与原型引导聚类的多模态新型类别发现（NCD）框架，显著提升未知类别的分类准确率并首次在NCD中展现出对长尾分布的强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的NCD方法仅依赖视觉特征，存在特征判别力不足和数据长尾分布等问题。

Method: 提出LLM-NCD框架，通过联合优化已知类别的图像与文本特征建模聚类中心和语义原型，并设计双阶段发现机制，利用语义亲和度阈值与自适应聚类动态区分已知/新颖样本。

Result: 在CIFAR-100上，未知类别分类准确率较现有方法最高提升25.3%，且首次在NCD中展现出对长尾分布的强鲁棒性。

Conclusion: 融合视觉-文本语义与原型引导聚类可有效突破纯视觉NCD的瓶颈，提升未知类别发现性能与泛化能力。

Abstract: Novel Class Discovery aims to utilise prior knowledge of known classes to classify and discover unknown classes from unlabelled data. Existing NCD methods for images primarily rely on visual features, which suffer from limitations such as insufficient feature discriminability and the long-tail distribution of data. We propose LLM-NCD, a multimodal framework that breaks this bottleneck by fusing visual-textual semantics and prototype guided clustering. Our key innovation lies in modelling cluster centres and semantic prototypes of known classes by jointly optimising known class image and text features, and a dualphase discovery mechanism that dynamically separates known or novel samples via semantic affinity thresholds and adaptive clustering. Experiments on the CIFAR-100 dataset show that compared to the current methods, this method achieves up to 25.3% improvement in accuracy for unknown classes. Notably, our method shows unique resilience to long tail distributions, a first in NCD literature.

</details>


### [19] [Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction](https://arxiv.org/abs/2512.10267)
*Chen Ziwen,Hao Tan,Peng Wang,Zexiang Xu,Li Fuxin*

Main category: cs.CV

TL;DR: 本文提出Long-LRM++，一种结合半显式场景表示与轻量解码器的新方法，在保持LaCT级渲染质量的同时实现A100上14 FPS实时渲染，并支持64视图输入及更优深度预测。


<details>
  <summary>Details</summary>
Motivation: 现有通用高斯泼溅（GS）方法对参数预测敏感、易模糊；隐式表示方法（如LVSM、LaCT）虽保真度高，但逐帧解压导致无法实时渲染。作者旨在探索是否必须依赖深度顺序解压，以及能否兼顾隐式表示优势与实时性。

Method: 提出Long-LRM++：采用半显式场景表示（介于完全显式GS与全隐式之间），配合轻量级解码器，避免全Transformer/TTC逐帧解压；支持更多输入视图（达64），并在950×540分辨率下端到端训练。

Result: 在DL3DV上达到与LaCT相当的渲染质量，在A100 GPU上实现14 FPS实时渲染；在ScanNetv2上新型视角深度预测优于直接从高斯渲染的深度；可扩展至64输入视图，且消融实验证明各组件有效。

Conclusion: Long-LRM++成功弥合了显式与隐式3D重建方法之间的质量-速度鸿沟，证明轻量半显式设计可在不牺牲保真度的前提下实现高效、可扩展的实时新视角合成与深度估计。

Abstract: Recent advances in generalizable Gaussian splatting (GS) have enabled feed-forward reconstruction of scenes from tens of input views. Long-LRM notably scales this paradigm to 32 input images at $950\times540$ resolution, achieving 360° scene-level reconstruction in a single forward pass. However, directly predicting millions of Gaussian parameters at once remains highly error-sensitive: small inaccuracies in positions or other attributes lead to noticeable blurring, particularly in fine structures such as text. In parallel, implicit representation methods such as LVSM and LaCT have demonstrated significantly higher rendering fidelity by compressing scene information into model weights rather than explicit Gaussians, and decoding RGB frames using the full transformer or TTT backbone. However, this computationally intensive decompression process for every rendered frame makes real-time rendering infeasible. These observations raise key questions: Is the deep, sequential "decompression" process necessary? Can we retain the benefits of implicit representations while enabling real-time performance? We address these questions with Long-LRM++, a model that adopts a semi-explicit scene representation combined with a lightweight decoder. Long-LRM++ matches the rendering quality of LaCT on DL3DV while achieving real-time 14 FPS rendering on an A100 GPU, overcoming the speed limitations of prior implicit methods. Our design also scales to 64 input views at the $950\times540$ resolution, demonstrating strong generalization to increased input lengths. Additionally, Long-LRM++ delivers superior novel-view depth prediction on ScanNetv2 compared to direct depth rendering from Gaussians. Extensive ablation studies validate the effectiveness of each component in the proposed framework.

</details>


### [20] [Sample-wise Adaptive Weighting for Transfer Consistency in Adversarial Distillation](https://arxiv.org/abs/2512.10275)
*Hongsin Lee,Hye Won Chung*

Main category: cs.CV

TL;DR: 本文提出了一种基于样本级自适应对抗蒸馏（SAAD）的方法，通过衡量对抗样本在师生模型间的迁移性来重加权训练样本，从而提升学生模型的鲁棒性，且不增加计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有对抗蒸馏方法常忽略使用最先进的鲁棒教师模型，且更强的教师并不总能带来更鲁棒的学生（即鲁棒饱和现象），传统归因于容量差距的解释不充分。

Method: 提出样本级自适应对抗蒸馏（SAAD），以对抗迁移性（即学生生成的对抗样本对教师仍有效的比例）为关键指标，动态重加权训练样本。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上，SAAD在AutoAttack下持续优于先前方法。

Conclusion: 对抗迁移性是鲁棒性迁移的关键因素；SAAD无需额外计算即可有效缓解鲁棒饱和，提升学生模型鲁棒性。

Abstract: Adversarial distillation in the standard min-max adversarial training framework aims to transfer adversarial robustness from a large, robust teacher network to a compact student. However, existing work often neglects to incorporate state-of-the-art robust teachers. Through extensive analysis, we find that stronger teachers do not necessarily yield more robust students-a phenomenon known as robust saturation. While typically attributed to capacity gaps, we show that such explanations are incomplete. Instead, we identify adversarial transferability-the fraction of student-crafted adversarial examples that remain effective against the teacher-as a key factor in successful robustness transfer. Based on this insight, we propose Sample-wise Adaptive Adversarial Distillation (SAAD), which reweights training examples by their measured transferability without incurring additional computational cost. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that SAAD consistently improves AutoAttack robustness over prior methods. Our code is available at https://github.com/HongsinLee/saad.

</details>


### [21] [MotionEdit: Benchmarking and Learning Motion-Centric Image Editing](https://arxiv.org/abs/2512.10284)
*Yixin Wan,Lei Ke,Wenhao Yu,Kai-Wei Chang,Dong Yu*

Main category: cs.CV

TL;DR: 本文提出了MotionEdit数据集和MotionEdit-Bench基准，用于评估图像运动编辑任务，并提出MotionNFT方法提升扩散模型在该任务上的运动保真度。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑数据集聚焦于静态外观变化或仅提供稀疏、低质量的运动编辑，无法满足对高保真、物理合理动作变换的需求；同时缺乏专门针对运动编辑的评测基准与有效方法。

Method: 构建MotionEdit高保真运动编辑图像对数据集；设计包含生成性、判别性和偏好性指标的MotionEdit-Bench基准；提出MotionNFT框架，利用运动流对齐奖励进行负感知微调。

Result: MotionNFT在FLUX.1 Kontext和Qwen-Image-Edit上显著提升运动编辑质量与运动保真度，且不损害通用编辑能力；现有SOTA扩散编辑模型在MotionEdit-Bench上表现仍较差。

Conclusion: 运动中心图像编辑是一个重要且具挑战性的新任务；MotionEdit数据集、MotionEdit-Bench基准及MotionNFT方法共同推动了该方向的发展。

Abstract: We introduce MotionEdit, a novel dataset for motion-centric image editing-the task of modifying subject actions and interactions while preserving identity, structure, and physical plausibility. Unlike existing image editing datasets that focus on static appearance changes or contain only sparse, low-quality motion edits, MotionEdit provides high-fidelity image pairs depicting realistic motion transformations extracted and verified from continuous videos. This new task is not only scientifically challenging but also practically significant, powering downstream applications such as frame-controlled video synthesis and animation.
  To evaluate model performance on the novel task, we introduce MotionEdit-Bench, a benchmark that challenges models on motion-centric edits and measures model performance with generative, discriminative, and preference-based metrics. Benchmark results reveal that motion editing remains highly challenging for existing state-of-the-art diffusion-based editing models. To address this gap, we propose MotionNFT (Motion-guided Negative-aware Fine Tuning), a post-training framework that computes motion alignment rewards based on how well the motion flow between input and model-edited images matches the ground-truth motion, guiding models toward accurate motion transformations. Extensive experiments on FLUX.1 Kontext and Qwen-Image-Edit show that MotionNFT consistently improves editing quality and motion fidelity of both base models on the motion editing task without sacrificing general editing ability, demonstrating its effectiveness.

</details>


### [22] [ShotDirector: Directorially Controllable Multi-Shot Video Generation with Cinematographic Transitions](https://arxiv.org/abs/2512.10286)
*Xiaoxue Wu,Xinyuan Chen,Yaohui Wang,Yu Qiao*

Main category: cs.CV

TL;DR: 本文提出ShotDirector框架，通过参数级相机控制与分层剪辑模式感知提示，实现电影级可控多镜头视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注镜头间的低层视觉一致性，忽视了转场设计与电影语言对叙事连贯性的影响，导致缺乏专业剪辑逻辑的简单镜头拼接。

Method: 提出ShotDirector框架，包含6自由度相机控制模块和基于专业剪辑模式的分层提示掩码机制；构建ShotWeaver40K数据集及配套评估指标。

Result: 实现了参数级条件与高层语义引导的有效融合，生成具备电影感、可控性强的多镜头视频，在多项实验中验证了有效性。

Conclusion: ShotDirector为多镜头视频生成引入了导演级控制能力，推动了视频生成从视觉连续性向叙事可控性的发展。

Abstract: Shot transitions play a pivotal role in multi-shot video generation, as they determine the overall narrative expression and the directorial design of visual storytelling. However, recent progress has primarily focused on low-level visual consistency across shots, neglecting how transitions are designed and how cinematographic language contributes to coherent narrative expression. This often leads to mere sequential shot changes without intentional film-editing patterns. To address this limitation, we propose ShotDirector, an efficient framework that integrates parameter-level camera control and hierarchical editing-pattern-aware prompting. Specifically, we adopt a camera control module that incorporates 6-DoF poses and intrinsic settings to enable precise camera information injection. In addition, a shot-aware mask mechanism is employed to introduce hierarchical prompts aware of professional editing patterns, allowing fine-grained control over shot content. Through this design, our framework effectively combines parameter-level conditions with high-level semantic guidance, achieving film-like controllable shot transitions. To facilitate training and evaluation, we construct ShotWeaver40K, a dataset that captures the priors of film-like editing patterns, and develop a set of evaluation metrics for controllable multi-shot video generation. Extensive experiments demonstrate the effectiveness of our framework.

</details>


### [23] [Physically Aware 360$^\circ$ View Generation from a Single Image using Disentangled Scene Embeddings](https://arxiv.org/abs/2512.10293)
*Karthikeya KV,Narendra Bandaru*

Main category: cs.CV

TL;DR: Disentangled360 是一种新型 3D 感知技术，通过在高斯泼溅（Gaussian Splatting）框架中解耦各向同性与各向异性光散射，并采用双分支条件机制和姿态无关的混合锚定方法，实现单图驱动的高质量 360° 视角合成，适用于医学影像与自然场景，在多个数据集上取得 SSIM/LPIPS 最优性能，且无需场景微调或昂贵物理仿真。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么过度简化各向异性光行为，要么泛化能力差；医学与自然场景对方向敏感的体积渲染需求未被统一高效满足。

Method: 提出 Disentangled360 框架：1）在 Gaussian Splatting 主干中显式分离各向同性与各向异性体渲染分量；2）双分支条件机制——CT 强度驱动的散射建模分支 + 基于归一化相机嵌入的 RGB 场景分支；3）混合姿态无关锚定法，自适应采样深度与材质跃变点以稳定场景蒸馏。

Result: 在 Mip-NeRF 360、RealEstate10K 和 DeepDRR 数据集上 SSIM 和 LPIPS 指标均优于现有方法；运行时效率支持交互式应用；成功集成术前 X 光仿真与消费级 360° 渲染于单一流程。

Conclusion: Disentangled360 实现了方向解耦、跨域通用、免微调的单图 360° 合成，在混合现实医疗指导、机器人感知和沉浸式内容生成中具有实用价值。

Abstract: We introduce Disentangled360, an innovative 3D-aware technology that integrates the advantages of direction disentangled volume rendering with single-image 360° unique view synthesis for applications in medical imaging and natural scene reconstruction. In contrast to current techniques that either oversimplify anisotropic light behavior or lack generalizability across various contexts, our framework distinctly differentiates between isotropic and anisotropic contributions inside a Gaussian Splatting backbone. We implement a dual-branch conditioning framework, one optimized for CT intensity driven scattering in volumetric data and the other for real-world RGB scenes through normalized camera embeddings. To address scale ambiguity and maintain structural realism, we present a hybrid pose agnostic anchoring method that adaptively samples scene depth and material transitions, functioning as stable pivots during scene distillation. Our design integrates preoperative radiography simulation and consumer-grade 360° rendering into a singular inference pipeline, facilitating rapid, photorealistic view synthesis with inherent directionality. Evaluations on the Mip-NeRF 360, RealEstate10K, and DeepDRR datasets indicate superior SSIM and LPIPS performance, while runtime assessments confirm its viability for interactive applications. Disentangled360 facilitates mixed-reality medical supervision, robotic perception, and immersive content creation, eliminating the necessity for scene-specific finetuning or expensive photon simulations.

</details>


### [24] [Efficient-VLN: A Training-Efficient Vision-Language Navigation Model](https://arxiv.org/abs/2512.10310)
*Duo Zheng,Shijia Huang,Yanyang Li,Liwei Wang*

Main category: cs.CV

TL;DR: 本文提出Efficient-VLN，一种训练高效的视觉-语言导航（VLN）模型，通过设计两种高效记忆机制（渐进式记忆和可学习递归记忆）缓解长序列token处理的计算负担，并引入动态混合策略平衡探索效率权衡，显著降低训练开销的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在视觉-语言导航（VLN）中潜力巨大，但其实际开发受限于巨大的训练开销，主要源于长时序观测导致的二次方计算负担以及DAgger数据聚合中探索效率的权衡问题。

Method: 提出Efficient-VLN模型：1）渐进式记忆机制——动态为近期观测分配更多token；2）可学习递归记忆机制——利用可学习token的KV缓存作为记忆状态；3）动态混合策略——在训练中自适应平衡探索与效率。

Result: 在R2R-CE和RxR-CE基准上分别达到64.2%和67.0%的成功率（SR），且仅需282 H800 GPU小时训练时间，大幅低于现有SOTA方法。

Conclusion: Efficient-VLN有效解决了VLN中训练开销大的核心瓶颈，在保持甚至提升性能的同时显著提升训练效率，为MLLMs在具身智能任务中的实用化提供了新路径。

Abstract: Multimodal large language models (MLLMs) have shown promising potential in Vision-Language Navigation (VLN). However, their practical development is severely hindered by the substantial training overhead. We recognize two key issues that contribute to the overhead: (1) the quadratic computational burden from processing long-horizon historical observations as massive sequences of tokens, and (2) the exploration-efficiency trade-off in DAgger, i.e., a data aggregation process of collecting agent-explored trajectories. While more exploration yields effective error-recovery trajectories for handling test-time distribution shifts, it comes at the cost of longer trajectory lengths for both training and inference. To address these challenges, we propose Efficient-VLN, a training-efficient VLN model. Specifically, to mitigate the token processing burden, we design two efficient memory mechanisms: a progressive memory that dynamically allocates more tokens to recent observations, and a learnable recursive memory that utilizes the key-value cache of learnable tokens as the memory state. Moreover, we introduce a dynamic mixed policy to balance the exploration-efficiency trade-off. Extensive experiments show that Efficient-VLN achieves state-of-the-art performance on R2R-CE (64.2% SR) and RxR-CE (67.0% SR). Critically, our model consumes merely 282 H800 GPU hours, demonstrating a dramatic reduction in training overhead compared to state-of-the-art methods.

</details>


### [25] [DualProtoSeg: Simple and Efficient Design with Text- and Image-Guided Prototype Learning for Weakly Supervised Histopathology Image Segmentation](https://arxiv.org/abs/2512.10314)
*Anh M. Vu,Khang P. Le,Trang T. K. Vo,Ha Thach,Huy Hung Nguyen,David Yang,Han H. Huynh,Quynh Nguyen,Tuan M. Pham,Tuan-Anh Le,Minh H. N. Le,Thanh-Huy Nguyen,Akash Awasthi,Chandra Mohan,Zhu Han,Hien Van Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉-语言对齐的原型驱动框架，用于弱监督病理图像语义分割（WSSS），通过可学习文本提示和图像原型构建双模态原型库，并引入多尺度金字塔模块缓解ViT过平滑问题，显著提升了区域发现与定位精度。


<details>
  <summary>Details</summary>
Motivation: 解决病理图像弱监督语义分割中因类间同质性、类内异质性及CAM监督导致的区域收缩效应等关键限制。

Method: 结合CoOp风格的可学习提示调优生成文本原型，与可学习图像原型构成双模态原型库；引入多尺度金字塔模块以增强ViT特征的空间精度和定位质量。

Result: 在BCSS-WSSS基准上超越现有最先进方法；消融分析验证了文本描述多样性、上下文长度以及图文原型互补性的积极作用。

Conclusion: 联合利用文本语义与视觉原型学习能有效提升弱监督病理图像语义分割性能。

Abstract: Weakly supervised semantic segmentation (WSSS) in histopathology seeks to reduce annotation cost by learning from image-level labels, yet it remains limited by inter-class homogeneity, intra-class heterogeneity, and the region-shrinkage effect of CAM-based supervision. We propose a simple and effective prototype-driven framework that leverages vision-language alignment to improve region discovery under weak supervision. Our method integrates CoOp-style learnable prompt tuning to generate text-based prototypes and combines them with learnable image prototypes, forming a dual-modal prototype bank that captures both semantic and appearance cues. To address oversmoothing in ViT representations, we incorporate a multi-scale pyramid module that enhances spatial precision and improves localization quality. Experiments on the BCSS-WSSS benchmark show that our approach surpasses existing state-of-the-art methods, and detailed analyses demonstrate the benefits of text description diversity, context length, and the complementary behavior of text and image prototypes. These results highlight the effectiveness of jointly leveraging textual semantics and visual prototype learning for WSSS in digital pathology.

</details>


### [26] [ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation](https://arxiv.org/abs/2512.10316)
*Khang Le,Ha Thach,Anh M. Vu,Trang T. K. Vo,Han H. Huynh,David Yang,Minh H. N. Le,Thanh-Huy Nguyen,Akash Awasthi,Chandra Mohan,Zhu Han,Hien Van Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种面向组织病理学图像的弱监督语义分割（WSSS）原型学习框架，融合CONCH的形态感知表征、SegFormer的多尺度结构线索与文本引导的语义对齐，通过文本引导的原型初始化和结构蒸馏机制，在无像素级标注下生成高质量伪掩码，提升定位完整性与跨组织类型的语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有WSSS方法依赖分类主干，易仅定位最具判别性的区域，难以覆盖组织结构完整空间范围；视觉-语言模型（如CONCH）与现代分割主干（如SegFormer）虽具互补优势，但其融合在弱监督下仍具挑战。

Method: 提出原型学习框架：1）利用CONCH的形态感知表征、SegFormer的多尺度结构线索及文本引导语义对齐构建联合原型；2）文本引导原型初始化，结合病理描述生成更完整准确的伪掩码；3）结构蒸馏机制将SegFormer的空间知识迁移至原型学习过程，保持细粒度形态模式与局部组织边界。

Result: 在BCSS-WSSS数据集上显著优于现有WSSS方法；生成高质量伪掩码，提升定位完整性与跨组织类型语义一致性；通过冻结基础模型主干+轻量可训练适配器，保证计算高效性。

Conclusion: 所提框架有效融合多源异构信息，在弱监督下实现更完整、更一致的组织病理图像语义分割，为无密集标注的医学图像分析提供了新思路。

Abstract: Weakly supervised semantic segmentation (WSSS) in histopathology relies heavily on classification backbones, yet these models often localize only the most discriminative regions and struggle to capture the full spatial extent of tissue structures. Vision-language models such as CONCH offer rich semantic alignment and morphology-aware representations, while modern segmentation backbones like SegFormer preserve fine-grained spatial cues. However, combining these complementary strengths remains challenging, especially under weak supervision and without dense annotations. We propose a prototype learning framework for WSSS in histopathological images that integrates morphology-aware representations from CONCH, multi-scale structural cues from SegFormer, and text-guided semantic alignment to produce prototypes that are simultaneously semantically discriminative and spatially coherent. To effectively leverage these heterogeneous sources, we introduce text-guided prototype initialization that incorporates pathology descriptions to generate more complete and semantically accurate pseudo-masks. A structural distillation mechanism transfers spatial knowledge from SegFormer to preserve fine-grained morphological patterns and local tissue boundaries during prototype learning. Our approach produces high-quality pseudo masks without pixel-level annotations, improves localization completeness, and enhances semantic consistency across tissue types. Experiments on BCSS-WSSS datasets demonstrate that our prototype learning framework outperforms existing WSSS methods while remaining computationally efficient through frozen foundation model backbones and lightweight trainable adapters.

</details>


### [27] [Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset](https://arxiv.org/abs/2512.10321)
*Hyunsoo Lee,Daeum Jeon,Hyeokjae Oh*

Main category: cs.CV

TL;DR: 本文提出了一种基于点云序列的生成式3D人体姿态估计方法Point2Pose，结合时空点云编码与姿态特征编码，并设计了注意力机制的生成回归器；同时构建了大规模多模态室内数据集MVPose3D，实验表明该方法在多个数据集上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 3D人体姿态估计面临人体复杂几何结构、关节自遮挡以及缺乏大规模真实世界运动数据集等关键挑战。

Method: 提出Point2Pose框架，包含时空点云编码器、姿态特征编码器和基于注意力机制的生成回归器，以建模给定点云序列和历史姿态条件下的人体姿态分布；并构建了包含IMU数据、密集多视角点云和RGB图像的多模态数据集MVPose3D。

Result: 所提方法在多个数据集上均优于基线模型，验证了其有效性与泛化能力。

Conclusion: Point2Pose是一种有效的生成式3D姿态估计方法，结合新构建的大规模多模态数据集MVPose3D，为解决复杂场景下的人体姿态估计问题提供了新思路。

Abstract: We propose a novel generative approach for 3D human pose estimation. 3D human pose estimation poses several key challenges due to the complex geometry of the human body, self-occluding joints, and the requirement for large-scale real-world motion datasets. To address these challenges, we introduce Point2Pose, a framework that effectively models the distribution of human poses conditioned on sequential point cloud and pose history. Specifically, we employ a spatio-temporal point cloud encoder and a pose feature encoder to extract joint-wise features, followed by an attention-based generative regressor. Additionally, we present a large-scale indoor dataset MVPose3D, which contains multiple modalities, including IMU data of non-trivial human motions, dense multi-view point clouds, and RGB images. Experimental results show that the proposed method outperforms the baseline models, demonstrating its superior performance across various datasets.

</details>


### [28] [EchoingPixels: Cross-Modal Adaptive Token Reduction for Efficient Audio-Visual LLMs](https://arxiv.org/abs/2512.10324)
*Chao Gong,Depeng Wang,Zhipeng Wei,Ya Guo,Huijia Zhu,Jingjing Chen*

Main category: cs.CV

TL;DR: 本文提出EchoingPixels框架，通过跨模态语义筛（CS2）和同步增强RoPE（Sync-RoPE），在音频-视觉大模型中实现联合流的自适应令牌压缩，显著降低计算开销并保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有音视频大模型面临高昂计算开销；单模态令牌压缩方法无法利用音视频跨模态协同，且固定模态预算难以适配二者动态差异的信息密度。

Method: 提出EchoingPixels框架：1）跨模态语义筛（CS2）实现早期音视频交互，在联合音视频令牌池中自适应筛选关键令牌；2）同步增强RoPE（Sync-RoPE）维持稀疏采样后的时间建模能力。

Result: 实验表明，EchoingPixels仅用原令牌数5%-20%即达到与强基线相当性能，推理速度提升2-3倍，内存占用显著下降。

Conclusion: 联合音视频流的自适应令牌压缩是可行且高效的，CS2与Sync-RoPE协同解决了跨模态协同压缩与时间建模保留的关键挑战。

Abstract: Audio-Visual Large Language Models (AV-LLMs) face prohibitive computational overhead from massive audio and video tokens. Token reduction, while extensively explored for video-only LLMs, is insufficient for the audio-visual domain, as these unimodal methods cannot leverage audio-visual cross-modal synergies. Furthermore, the distinct and dynamic information densities of audio and video render static budgets per modality suboptimal. How to perform token reduction on a joint audio-visual stream thus remains an unaddressed bottleneck. To fill this gap, we introduce EchoingPixels, a framework inspired by the coexistence and interaction of visuals and sound in real-world scenes. The core of our framework is the Cross-Modal Semantic Sieve (CS2), a module enabling early audio-visual interaction. Instead of compressing modalities independently, CS2 co-attends to the joint multimodal stream and reduces tokens from an entire combined pool of audio-visual tokens rather than using fixed budgets per modality. This single-pool approach allows it to adaptively allocate the token budget across both modalities and dynamically identify salient tokens in concert. To ensure this aggressive reduction preserves the vital temporal modeling capability, we co-design a Synchronization-Augmented RoPE (Sync-RoPE) to maintain critical temporal relationships for the sparsely selected tokens. Extensive experiments demonstrate that EchoingPixels achieves performance comparable to strong baselines using only 5-20% of the original tokens, with a 2-3x speedup and memory reduction.

</details>


### [29] [StainNet: A Special Staining Self-Supervised Vision Transformer for Computational Pathology](https://arxiv.org/abs/2512.10326)
*Jiawen Li,Jiali Hu,Xitong Ling,Yongqiang Lv,Yuxuan Chen,Yizhi Wang,Tian Guan,Yifei Liu,Yonghong He*

Main category: cs.CV

TL;DR: 本文提出StainNet，一种专为特殊染色病理图像设计的视觉Transformer基础模型，采用自蒸馏自监督学习方法，在超140万张特殊染色图像块上预训练，显著提升在特殊染色图像上的下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有病理基础模型主要在H&E染色图像上预训练，难以有效泛化到免疫组化等特殊染色图像，限制其临床应用。

Method: 提出基于ViT架构的StainNet模型，采用自蒸馏式自监督学习（SSL），在HISTAI数据库中20,231张特殊染色全切片图像裁剪出的140余万图像块上进行预训练。

Result: 在肝恶性肿瘤滑片级分类及两个公开ROI级数据集上表现优异；在少样本学习和图像检索任务中优于近期更大规模的病理基础模型。

Conclusion: StainNet是首个面向特殊染色图像的专用基础模型，填补了该领域空白，提升了模型在真实临床多染色场景下的适用性与鲁棒性。

Abstract: Foundation models trained with self-supervised learning (SSL) on large-scale histological images have significantly accelerated the development of computational pathology. These models can serve as backbones for region-of-interest (ROI) image analysis or patch-level feature extractors in whole-slide images (WSIs) based on multiple instance learning (MIL). Existing pathology foundation models (PFMs) are typically pre-trained on Hematoxylin-Eosin (H&E) stained pathology images. However, images with special stains, such as immunohistochemistry, are also frequently used in clinical practice. PFMs pre-trained mainly on H\&E-stained images may be limited in clinical applications involving special stains. To address this issue, we propose StainNet, a specialized foundation model for special stains based on the vision transformer (ViT) architecture. StainNet adopts a self-distillation SSL approach and is trained on over 1.4 million patch images cropping from 20,231 publicly available special staining WSIs in the HISTAI database. To evaluate StainNet, we conduct experiments on an in-house slide-level liver malignancy classification task and two public ROI-level datasets to demonstrate its strong ability. We also perform few-ratio learning and retrieval evaluations, and compare StainNet with recently larger PFMs to further highlight its strengths. We have released the StainNet model weights at: https://huggingface.co/JWonderLand/StainNet.

</details>


### [30] [Simple Yet Effective Selective Imputation for Incomplete Multi-view Clustering](https://arxiv.org/abs/2512.10327)
*Cai Xu,Jinlong Liu,Yilin Zhang,Ziyu Guan,Wei Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种基于信息量选择性插补的多视图聚类方法（ISMVC），通过评估缺失位置的信息量，仅在有足够支持时进行插补，并结合带高斯混合先验的变分自编码器学习聚类友好的潜在表示，从而在不平衡缺失场景下实现更鲁棒、准确的聚类。


<details>
  <summary>Details</summary>
Motivation: 不完整多视图数据中缺失和不平衡观测给聚类带来挑战：现有插补法易引入噪声和偏差，而无插补法则在严重缺失时因缺乏跨视图互补性而失效。

Method: 提出ISMVC方法，基于视内相似性和跨视图一致性评估各缺失位置的插补相关信息量，选择性插补；并结合带高斯混合先验的变分自编码器，实现分布级插补与不确定性建模。

Result: 在多个基准数据集及更真实、更具挑战性的不平衡缺失场景下，ISMVC显著优于现有插补法和无插补法。

Conclusion: ISMVC是一种轻量、数据驱动、模型无关的插补策略，可作为即插即用模块提升现有不完整多视图聚类模型性能。

Abstract: Incomplete multi-view data, where different views suffer from missing and unbalanced observations, pose significant challenges for clustering. Existing imputation-based methods attempt to estimate missing views to restore data associations, but indiscriminate imputation often introduces noise and bias, especially when the available information is insufficient. Imputation-free methods avoid this risk by relying solely on observed data, but struggle under severe incompleteness due to the lack of cross-view complementarity. To address this issue, we propose Informativeness-based Selective imputation Multi-View Clustering (ISMVC). Our method evaluates the imputation-relevant informativeness of each missing position based on intra-view similarity and cross-view consistency, and selectively imputes only when sufficient support is available. Furthermore, we integrate this selection with a variational autoencoder equipped with a mixture-of-Gaussians prior to learn clustering-friendly latent representations. By performing distribution-level imputation, ISMVC not only stabilizes the aggregation of posterior distributions but also explicitly models imputation uncertainty, enabling robust fusion and preventing overconfident reconstructions. Compared with existing cautious imputation strategies that depend on training dynamics or model feedback, our method is lightweight, data-driven, and model-agnostic. It can be readily integrated into existing IMC models as a plug-in module. Extensive experiments on multiple benchmark datasets under a more realistic and challenging unbalanced missing scenario demonstrate that our method outperforms both imputation-based and imputation-free approaches.

</details>


### [31] [Any4D: Unified Feed-Forward Metric 4D Reconstruction](https://arxiv.org/abs/2512.10935)
*Jay Karhade,Nikhil Keetha,Yuchen Zhang,Tanisha Gupta,Akash Sharma,Sebastian Scherer,Deva Ramanan*

Main category: cs.CV

TL;DR: Any4D是一种可扩展的多视角Transformer模型，用于公制尺度、密集前馈式4D重建，支持多模态输入（如RGB-D、IMU、雷达），采用模块化4D场景表示，在精度和计算效率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常局限于双视图稠密场景流或稀疏3D点跟踪，且多数仅支持单目RGB视频；缺乏对多模态传感器数据的统一建模能力与高效、精确的4D重建框架。

Method: 提出Any4D：基于多视角Transformer的端到端4D重建框架；采用模块化4D表示——将每帧预测分解为以相机坐标系表示的本征因素（深度图、内参）和以世界坐标系表示的外在因素（外参、场景流）；支持RGB、RGB-D、IMU、雷达等多模态输入。

Result: 在多种设置下性能优越：误差降低2–3倍，计算速度快15倍。

Conclusion: Any4D实现了更通用、高效且精确的4D重建，为下游应用（如AR/VR、自动驾驶）提供了新基础。

Abstract: We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.

</details>


### [32] [A Conditional Generative Framework for Synthetic Data Augmentation in Segmenting Thin and Elongated Structures in Biological Images](https://arxiv.org/abs/2512.10334)
*Yi Liu,Yichi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于Pix2Pix的条件生成框架，用于从二值掩码生成逼真的显微镜图像中的丝状结构（如微管、肌动蛋白），并设计了丝状结构感知的结构损失函数以提升生成图像的结构相似性，从而缓解丝状结构分割任务中标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 获取高质量像素级丝状结构标注数据困难，因其密集分布和几何特性导致人工标注极其耗时费力，造成训练数据短缺。

Method: 提出基于Pix2Pix架构的条件生成框架，从二值掩码生成含真实丝状结构的显微镜图像；引入 filament-aware structural loss 以增强生成图像的结构保真度。

Result: 实验表明该方法生成的合成数据能有效提升分割模型性能，优于未使用合成数据训练的现有模型。

Conclusion: 所提生成框架及结构损失可缓解丝状结构图像分割中数据标注瓶颈，为相关生物图像分析提供可行的数据增强方案。

Abstract: Thin and elongated filamentous structures, such as microtubules and actin filaments, often play important roles in biological systems. Segmenting these filaments in biological images is a fundamental step for quantitative analysis. Recent advances in deep learning have significantly improved the performance of filament segmentation. However, there is a big challenge in acquiring high quality pixel-level annotated dataset for filamentous structures, as the dense distribution and geometric properties of filaments making manual annotation extremely laborious and time-consuming. To address the data shortage problem, we propose a conditional generative framework based on the Pix2Pix architecture to generate realistic filaments in microscopy images from binary masks. We also propose a filament-aware structural loss to improve the structure similarity when generating synthetic images. Our experiments have demonstrated the effectiveness of our approach and outperformed existing model trained without synthetic data.

</details>


### [33] [Zero-shot Adaptation of Stable Diffusion via Plug-in Hierarchical Degradation Representation for Real-World Super-Resolution](https://arxiv.org/abs/2512.10340)
*Yi-Cheng Liao,Shyang-En Weng,Yu-Syuan Xu,Chi-Wei Hsiao,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: 本文提出HD-CLIP，一种分层退化CLIP模型，用于真实世界图像超分辨率（Real-ISR），通过语义与有序退化嵌入联合指导扩散模型，提升细节保真度和感知真实性，且为即插即用模块，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有Real-ISR方法常假设退化程度已知，依赖CLIP文本编码器，无法刻画数值化的退化严重性，泛化能力受限。

Method: 提出HD-CLIP，将低质图像分解为语义嵌入和有序退化嵌入；结合分类器自由引导（CFG）与新提出的分类器自由投影引导（CFPG），嵌入到扩散模型中。

Result: HD-CLIP作为即插即用模块，在多种超分框架中无需训练即可显著提升细节保真度与感知真实性，在多个真实世界数据集上表现优异。

Conclusion: HD-CLIP通过解耦并协同建模语义与有序退化信息，有效增强扩散模型在Real-ISR任务中的指导能力，兼具通用性与实用性。

Abstract: Real-World Image Super-Resolution (Real-ISR) aims to recover high-quality images from low-quality inputs degraded by unknown and complex real-world factors. Real-world scenarios involve diverse and coupled degradations, making it necessary to provide diffusion models with richer and more informative guidance. However, existing methods often assume known degradation severity and rely on CLIP text encoders that cannot capture numerical severity, limiting their generalization ability. To address this, we propose \textbf{HD-CLIP} (\textbf{H}ierarchical \textbf{D}egradation CLIP), which decomposes a low-quality image into a semantic embedding and an ordinal degradation embedding that captures ordered relationships and allows interpolation across unseen levels. Furthermore, we integrated it into diffusion models via classifier-free guidance (CFG) and proposed classifier-free projection guidance (CFPG). HD-CLIP leverages semantic cues to guide generative restoration while using degradation cues to suppress undesired hallucinations and artifacts. As a \textbf{plug-and-play module}, HD-CLIP can be seamlessly integrated into various super-resolution frameworks without training, significantly improving detail fidelity and perceptual realism across diverse real-world datasets.

</details>


### [34] [CoSPlan: Corrective Sequential Planning via Scene Graph Incremental Updates](https://arxiv.org/abs/2512.10342)
*Shresth Grover,Priyank Pathak,Akash Kumar,Vibhav Vineet,Yogesh S Rawat*

Main category: cs.CV

TL;DR: 本文提出了CoSPlan基准，用于评估大规模视觉语言模型（VLMs）在含错误的视觉序列规划任务中的纠错能力，并提出无需训练的Scene Graph Incremental更新（SGI）方法，提升VLMs的序列推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有大规模VLMs虽具强复杂推理能力，但在视觉序列规划（尤其是含非最优/错误步骤的实际场景）中尚未被充分探索；需构建能评估其错误检测与纠正能力的新基准。

Method: 构建CoSPlan基准（涵盖迷宫导航、积木重排、图像重建、物体重组4领域），定义Error Detection与Step Completion两项能力；提出无需训练的SGI方法，在初始与目标状态间引入增量式场景图推理步骤。

Result: 当前SOTA VLMs（如Intern-VLM、Qwen2）在CoSPlan上表现不佳；SGI方法带来平均5.2%性能提升，并可泛化至Plan-Bench和VQA等传统任务。

Conclusion: 视觉序列规划中的纠错能力是VLMs的重要短板；SGI通过结构化中间推理显著增强其可靠性与泛化性，为实用化视觉规划提供新思路。

Abstract: Large-scale Vision-Language Models (VLMs) exhibit impressive complex reasoning capabilities but remain largely unexplored in visual sequential planning, i.e., executing multi-step actions towards a goal. Additionally, practical sequential planning often involves non-optimal (erroneous) steps, challenging VLMs to detect and correct such steps. We propose Corrective Sequential Planning Benchmark (CoSPlan) to evaluate VLMs in error-prone, vision-based sequential planning tasks across 4 domains: maze navigation, block rearrangement, image reconstruction,and object reorganization. CoSPlan assesses two key abilities: Error Detection (identifying non-optimal action) and Step Completion (correcting and completing action sequences to reach the goal). Despite using state-of-the-art reasoning techniques such as Chain-of-Thought and Scene Graphs, VLMs (e.g. Intern-VLM and Qwen2) struggle on CoSPlan, failing to leverage contextual cues to reach goals. Addressing this, we propose a novel training-free method, Scene Graph Incremental updates (SGI), which introduces intermediate reasoning steps between the initial and goal states. SGI helps VLMs reason about sequences, yielding an average performance gain of 5.2%. In addition to enhancing reliability in corrective sequential planning, SGI generalizes to traditional planning tasks such as Plan-Bench and VQA.

</details>


### [35] [Topology-Agnostic Animal Motion Generation from Text Prompt](https://arxiv.org/abs/2512.10352)
*Keyi Chen,Mingze Sun,Zhenyu Liu,Zhangquan Chen,Ruqi Huang*

Main category: cs.CV

TL;DR: 本文提出OmniZoo数据集和一种拓扑感知的自回归运动生成框架，支持任意骨骼结构和文本驱动的动物运动生成与跨物种风格迁移。


<details>
  <summary>Details</summary>
Motivation: 现有运动生成方法依赖固定骨骼模板，难以泛化到不同或扰动的骨骼拓扑；缺乏大规模异构动物运动数据及统一生成框架。

Method: 构建包含140个物种、32979段序列的OmniZoo动物运动数据集，并提出基于拓扑感知骨骼嵌入模块的广义自回归运动生成框架，实现骨骼结构与文本语义的联合建模。

Result: 模型能根据文本提示和目标骨骼生成时序连贯、物理合理、语义对齐的运动，并支持跨物种运动风格迁移。

Conclusion: OmniZoo和所提框架显著提升了运动生成方法对任意骨骼拓扑的泛化能力，推动了文本驱动动物运动生成的发展。

Abstract: Motion generation is fundamental to computer animation and widely used across entertainment, robotics, and virtual environments. While recent methods achieve impressive results, most rely on fixed skeletal templates, which prevent them from generalizing to skeletons with different or perturbed topologies. We address the core limitation of current motion generation methods - the combined lack of large-scale heterogeneous animal motion data and unified generative frameworks capable of jointly modeling arbitrary skeletal topologies and textual conditions. To this end, we introduce OmniZoo, a large-scale animal motion dataset spanning 140 species and 32,979 sequences, enriched with multimodal annotations. Building on OmniZoo, we propose a generalized autoregressive motion generation framework capable of producing text-driven motions for arbitrary skeletal topologies. Central to our model is a Topology-aware Skeleton Embedding Module that encodes geometric and structural properties of any skeleton into a shared token space, enabling seamless fusion with textual semantics. Given a text prompt and a target skeleton, our method generates temporally coherent, physically plausible, and semantically aligned motions, and further enables cross-species motion style transfer.

</details>


### [36] [Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation](https://arxiv.org/abs/2512.10353)
*Yiheng Lyu,Lian Xu,Mohammed Bennamoun,Farid Boussaid,Coen Arrow,Girish Dwivedi*

Main category: cs.CV

TL;DR: TranSamba 是一种结合 Transformer 与 Mamba 的混合架构，专为弱监督三维医学图像分割设计，通过跨平面 Mamba 模块高效建模体积上下文，在多个数据集上达到 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督语义分割方法多采用2D编码器，忽略了医学影像固有的三维结构特性，导致体积上下文建模不足。

Method: 提出 TranSamba 架构：在 Vision Transformer 主干中嵌入 Cross-Plane Mamba 模块，利用状态空间模型的线性复杂度实现相邻切片间高效信息交换，并增强片内自注意力以提升定位能力。

Result: 在三个医学影像数据集上显著超越现有方法，性能覆盖多种模态与病理类型；计算时间复杂度随体数据深度线性增长，批处理内存占用恒定。

Conclusion: TranSamba 成功融合 Transformer 的表征能力与 Mamba 的高效建模优势，为弱监督三维医学分割提供了更优、可扩展的解决方案。

Abstract: Weakly supervised semantic segmentation offers a label-efficient solution to train segmentation models for volumetric medical imaging. However, existing approaches often rely on 2D encoders that neglect the inherent volumetric nature of the data. We propose TranSamba, a hybrid Transformer-Mamba architecture designed to capture 3D context for weakly supervised volumetric medical segmentation. TranSamba augments a standard Vision Transformer backbone with Cross-Plane Mamba blocks, which leverage the linear complexity of state space models for efficient information exchange across neighboring slices. The information exchange enhances the pairwise self-attention within slices computed by the Transformer blocks, directly contributing to the attention maps for object localization. TranSamba achieves effective volumetric modeling with time complexity that scales linearly with the input volume depth and maintains constant memory usage for batch processing. Extensive experiments on three datasets demonstrate that TranSamba establishes new state-of-the-art performance, consistently outperforming existing methods across diverse modalities and pathologies. Our source code and trained models are openly accessible at: https://github.com/YihengLyu/TranSamba.

</details>


### [37] [mmCounter: Static People Counting in Dense Indoor Scenarios Using mmWave Radar](https://arxiv.org/abs/2512.10357)
*Tarik Reza Toha,Shao-Jung,Lu,Shahriar Nirjon*

Main category: cs.CV

TL;DR: mmCounter is a novel system that accurately counts static people in dense indoor spaces using ultra-low frequency signals from breathing and micro-movements, achieving high accuracy with a multi-stage signal processing pipeline.


<details>
  <summary>Details</summary>
Motivation: mmWave radars struggle to detect or count static individuals in dense groups due to limited spatial resolution and reliance on movement; existing breathing rate estimation methods assume known person count, which is insufficient for counting.

Method: mmCounter extracts ultra-low frequency (<1 Hz) signals from breathing and micro-movements, applies novel signal processing to separate these from noise and static objects, and uses a multi-stage pipeline to associate spatially resolved low-frequency sources with individual people.

Result: mmCounter achieves 87% average F1 score and 0.6 mean absolute error in familiar environments, and 60% F1 score and 1.1 MAE in unseen environments; it can count up to seven people in a 3 m² space with minimal spacing.

Conclusion: mmCounter overcomes key limitations of mmWave radar for static human counting in dense scenarios, enabling practical deployment in real-world indoor settings.

Abstract: mmWave radars struggle to detect or count individuals in dense, static (non-moving) groups due to limitations in spatial resolution and reliance on movement for detection. We present mmCounter, which accurately counts static people in dense indoor spaces (up to three people per square meter). mmCounter achieves this by extracting ultra-low frequency (< 1 Hz) signals, primarily from breathing and micro-scale body movements such as slight torso shifts, and applying novel signal processing techniques to differentiate these subtle signals from background noise and nearby static objects. Our problem differs significantly from existing studies on breathing rate estimation, which assume the number of people is known a priori. In contrast, mmCounter utilizes a novel multi-stage signal processing pipeline to extract relevant low-frequency sources along with their spatial information and map these sources to individual people, enabling accurate counting. Extensive evaluations in various environments demonstrate that mmCounter delivers an 87% average F1 score and 0.6 mean absolute error in familiar environments, and a 60% average F1 score and 1.1 mean absolute error in previously untested environments. It can count up to seven individuals in a three square meter space, such that there is no side-by-side spacing and only a one-meter front-to-back distance.

</details>


### [38] [Tool-Augmented Spatiotemporal Reasoning for Streamlining Video Question Answering Task](https://arxiv.org/abs/2512.10359)
*Sunqi Fan,Jiashuo Cui,Meng-Hao Guo,Shuojin Yang*

Main category: cs.CV

TL;DR: 本文提出了一种面向视频问答（VideoQA）任务的时空推理框架STAR和视频工具包，通过协同调度轻量级时空工具，显著提升多模态大模型（MLLM）在复杂视频理解与因果推理上的能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM难以同时建模视频帧内空间关系与时间演化中的因果动态，尤其在复杂、需深度推理的VideoQA任务上表现不足。

Method: 设计可扩展的视频工具包，并提出时空推理框架STAR，通过策略性调度时空工具，逐步定位视频关键区域；以轻量级工具增强GPT-4o。

Result: 在VideoMME上提升8.2%，在LongVideoBench上提升4.6%。

Conclusion: Video Toolkit与STAR框架为构建自主智能视频分析助手提供了重要进展。

Abstract: Video Question Answering (VideoQA) task serves as a critical playground for evaluating whether foundation models can effectively perceive, understand, and reason about dynamic real-world scenarios. However, existing Multimodal Large Language Models (MLLMs) struggle with simultaneously modeling spatial relationships within video frames and understanding the causal dynamics of temporal evolution on complex and reasoning-intensive VideoQA task. In this work, we equip MLLM with a comprehensive and extensible Video Toolkit, to enhance MLLM's spatiotemporal reasoning capabilities and ensure the harmony between the quantity and diversity of tools. To better control the tool invocation sequence and avoid toolchain shortcut issues, we propose a Spatiotemporal Reasoning Framework (STAR) that strategically schedules temporal and spatial tools, thereby progressively localizing the key area in the video. Our STAR framework enhances GPT-4o using lightweight tools, achieving an 8.2% gain on VideoMME and 4.6% on LongVideoBench. We believe that our proposed Video Toolkit and STAR framework make an important step towards building autonomous and intelligent video analysis assistants. The code is publicly available at https://github.com/fansunqi/VideoTool.

</details>


### [39] [Visual Funnel: Resolving Contextual Blindness in Multimodal Large Language Models](https://arxiv.org/abs/2512.10362)
*Woojun Jung,Jaehoon Go,Mingyu Jeon,Sunjae Yoon,Junyeong Kim*

Main category: cs.CV

TL;DR: 本文提出Visual Funnel方法，通过无训练的两步策略（上下文锚定与熵缩放组合）解决多模态大模型在细粒度视觉感知中的'上下文失明'问题，强调输入结构多样性而非信息数量。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs虽具强推理能力，但难以感知图像细粒度细节；裁剪显著区域的方法引入了'上下文失明'问题——即高保真局部细节与全局上下文之间存在结构性割裂。

Method: 提出无需训练的Visual Funnel：第一步Contextual Anchoring单次前向定位兴趣区域；第二步Entropy-Scaled Portfolio基于注意力熵动态确定裁剪尺寸与中心，构建包含焦点细节到周边环境的层次化图像组合。

Result: 在多项实验中显著优于单裁剪和非结构化多裁剪基线；验证增加无序裁剪反而效果有限甚至有害，证明层次化结构设计是关键。

Conclusion: 解决MLLM视觉感知瓶颈的关键在于提升输入的结构性多样性，而非单纯增加信息量；Visual Funnel为通用、轻量、有效的上下文感知增强提供了新范式。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate impressive reasoning capabilities, but often fail to perceive fine-grained visual details, limiting their applicability in precision-demanding tasks. While methods that crop salient regions of an image offer a partial solution, we identify a critical limitation they introduce: "Contextual Blindness". This failure occurs due to structural disconnect between high-fidelity details (from the crop) and the broader global context (from the original image), even when all necessary visual information is present. We argue that this limitation stems not from a lack of information 'Quantity', but from a lack of 'Structural Diversity' in the model's input. To resolve this, we propose Visual Funnel, a training-free, two-step approach. Visual Funnel first performs Contextual Anchoring to identify the region of interest in a single forward pass. It then constructs an Entropy-Scaled Portfolio that preserves the hierarchical context - ranging from focal detail to broader surroundings - by dynamically determining crop sizes based on attention entropy and refining crop centers. Through extensive experiments, we demonstrate that Visual Funnel significantly outperforms naive single-crop and unstructured multi-crop baselines. Our results further validate that simply adding more unstructured crops provides limited or even detrimental benefits, confirming that the hierarchical structure of our portfolio is key to resolving Contextual Blindness.

</details>


### [40] [Point to Span: Zero-Shot Moment Retrieval for Navigating Unseen Hour-Long Videos](https://arxiv.org/abs/2512.10363)
*Mingyu Jeon,Jisoo Yang,Sungjin Han,Jinkwon Hwang,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的零样本长视频时刻检索框架P2S，通过自适应跨度生成和查询分解，解决了搜索阶段候选爆炸和精炼阶段高计算成本的问题，在小时级视频上实现了优于监督式SOTA方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本长视频时刻检索（ZLVMR）方法在搜索阶段易导致候选爆炸，精炼阶段依赖高成本视觉语言模型（VLM）验证，计算开销大、语义不一致风险高；而监督方法泛化性差、可扩展性低。

Method: 提出Point-to-Span（P2S）无训练框架：1）自适应跨度生成器（Adaptive Span Generator）控制搜索阶段候选数量；2）查询分解（Query Decomposition）替代高成本VLM验证，实现高效精炼。

Result: P2S是首个支持小时级视频零样本时间定位的框架，在MAD数据集R5@0.1指标上超越监督式SOTA方法3.7%。

Conclusion: P2S有效克服了ZLVMR中‘搜索-精炼’范式的效率与成本瓶颈，为零样本长视频理解提供了可扩展、低开销的新路径。

Abstract: Zero-shot Long Video Moment Retrieval (ZLVMR) is the task of identifying temporal segments in hour-long videos using a natural language query without task-specific training. The core technical challenge of LVMR stems from the computational infeasibility of processing entire lengthy videos in a single pass. This limitation has established a 'Search-then-Refine' approach, where candidates are rapidly narrowed down, and only those portions are analyzed, as the dominant paradigm for LVMR. However, existing approaches to this paradigm face severe limitations. Conventional supervised learning suffers from limited scalability and poor generalization, despite substantial resource consumption. Yet, existing zero-shot methods also fail, facing a dual challenge: (1) their heuristic strategies cause a 'search' phase candidate explosion, and (2) the 'refine' phase, which is vulnerable to semantic discrepancy, requires high-cost VLMs for verification, incurring significant computational overhead. We propose \textbf{P}oint-\textbf{to}-\textbf{S}pan (P2S), a novel training-free framework to overcome this challenge of inefficient 'search' and costly 'refine' phases. P2S overcomes these challenges with two key innovations: an 'Adaptive Span Generator' to prevent the search phase candidate explosion, and 'Query Decomposition' to refine candidates without relying on high-cost VLM verification. To our knowledge, P2S is the first zero-shot framework capable of temporal grounding in hour-long videos, outperforming supervised state-of-the-art methods by a significant margin (e.g., +3.7\% on R5@0.1 on MAD).

</details>


### [41] [Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views](https://arxiv.org/abs/2512.10369)
*Zhankuo Xu,Chaoran Feng,Yingtao Li,Jianbin Zhao,Jiashu Yang,Wangbo Yu,Li Yuan,Yonghong Tian*

Main category: cs.CV

TL;DR: 本文提出CoherentGS框架，通过结合预训练的去模糊网络和扩散模型的双先验策略，解决稀疏且运动模糊图像下的高质量3D重建难题，在极少量输入视图（如3、6、9张）下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 3D高斯点绘（3DGS）依赖密集高质量图像，但在实际中常面临稀疏+运动模糊的双重退化，二者相互加剧导致重建失败。

Method: 提出CoherentGS框架：1）双先验策略——用专用去模糊网络提供光度引导，用扩散模型提供几何先验；2）一致性引导的相机探索模块；3）深度正则化损失保障几何合理性。

Result: 在合成与真实场景上定量与定性实验表明，仅用3/6/9张输入图像时，CoherentGS显著优于现有方法，达到该任务新SOTA。

Conclusion: 双先验协同建模稀疏性与模糊性是提升低质量输入下3D重建鲁棒性与保真度的有效范式。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a state-of-the-art method for novel view synthesis. However, its performance heavily relies on dense, high-quality input imagery, an assumption that is often violated in real-world applications, where data is typically sparse and motion-blurred. These two issues create a vicious cycle: sparse views ignore the multi-view constraints necessary to resolve motion blur, while motion blur erases high-frequency details crucial for aligning the limited views. Thus, reconstruction often fails catastrophically, with fragmented views and a low-frequency bias. To break this cycle, we introduce CoherentGS, a novel framework for high-fidelity 3D reconstruction from sparse and blurry images. Our key insight is to address these compound degradations using a dual-prior strategy. Specifically, we combine two pre-trained generative models: a specialized deblurring network for restoring sharp details and providing photometric guidance, and a diffusion model that offers geometric priors to fill in unobserved regions of the scene. This dual-prior strategy is supported by several key techniques, including a consistency-guided camera exploration module that adaptively guides the generative process, and a depth regularization loss that ensures geometric plausibility. We evaluate CoherentGS through both quantitative and qualitative experiments on synthetic and real-world scenes, using as few as 3, 6, and 9 input views. Our results demonstrate that CoherentGS significantly outperforms existing methods, setting a new state-of-the-art for this challenging task. The code and video demos are available at https://potatobigroom.github.io/CoherentGS/.

</details>


### [42] [RaLiFlow: Scene Flow Estimation with 4D Radar and LiDAR Point Clouds](https://arxiv.org/abs/2512.10376)
*Jingyun Fu,Zhiyu Xiang,Na Zhao*

Main category: cs.CV

TL;DR: 本文提出了首个用于4D毫米波雷达与LiDAR联合场景流估计的框架RaLiFlow，并构建了首个雷达-LiDAR场景流数据集，通过动态感知的双向跨模态融合模块（DBCF）和定制损失函数，显著提升了多模态融合性能。


<details>
  <summary>Details</summary>
Motivation: 现有场景流方法多聚焦于图像与LiDAR融合，而4D毫米波雷达（低成本、全天候鲁棒、可测速）与LiDAR的融合尚未探索；且缺乏专用雷达-LiDAR场景流数据集；雷达数据本身存在噪声大、分辨率低、稀疏等挑战。

Method: 构建首个Radar-LiDAR场景流数据集；提出雷达去噪与场景流标签生成的预处理策略；设计RaLiFlow框架，核心为Dynamic-aware Bidirectional Cross-modal Fusion（DBCF）模块，将雷达动态信息融入局部交叉注意力；引入针对性损失函数以抑制雷达噪声影响并增强实例级一致性。

Result: 在自建数据集上实验表明，RaLiFlow显著优于现有单模态（纯LiDAR或纯雷达）方法。

Conclusion: 雷达与LiDAR融合用于场景流估计是可行且有效的；DBCF模块和定制损失函数是提升融合性能的关键；该工作填补了雷达-LiDAR场景流研究的数据与方法空白。

Abstract: Recent multimodal fusion methods, integrating images with LiDAR point clouds, have shown promise in scene flow estimation. However, the fusion of 4D millimeter wave radar and LiDAR remains unexplored. Unlike LiDAR, radar is cheaper, more robust in various weather conditions and can detect point-wise velocity, making it a valuable complement to LiDAR. However, radar inputs pose challenges due to noise, low resolution, and sparsity. Moreover, there is currently no dataset that combines LiDAR and radar data specifically for scene flow estimation. To address this gap, we construct a Radar-LiDAR scene flow dataset based on a public real-world automotive dataset. We propose an effective preprocessing strategy for radar denoising and scene flow label generation, deriving more reliable flow ground truth for radar points out of the object boundaries. Additionally, we introduce RaLiFlow, the first joint scene flow learning framework for 4D radar and LiDAR, which achieves effective radar-LiDAR fusion through a novel Dynamic-aware Bidirectional Cross-modal Fusion (DBCF) module and a carefully designed set of loss functions. The DBCF module integrates dynamic cues from radar into the local cross-attention mechanism, enabling the propagation of contextual information across modalities. Meanwhile, the proposed loss functions mitigate the adverse effects of unreliable radar data during training and enhance the instance-level consistency in scene flow predictions from both modalities, particularly for dynamic foreground areas. Extensive experiments on the repurposed scene flow dataset demonstrate that our method outperforms existing LiDAR-based and radar-based single-modal methods by a significant margin.

</details>


### [43] [Self-Supervised Contrastive Embedding Adaptation for Endoscopic Image Matching](https://arxiv.org/abs/2512.10379)
*Alberto Rota,Elena De Momi*

Main category: cs.CV

TL;DR: 本文提出了一种面向内窥镜图像的自监督深度学习方法，通过新颖视图合成生成真值对应点，并结合对比学习优化DINOv2骨干网络，显著提升了像素级特征匹配精度与三维重建鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 内窥镜手术中缺乏深度传感器，仅依赖视觉输入，而传统计算机视觉方法在弱透视、非朗伯反射和组织形变等挑战下性能下降；现有深度学习特征不适用于手术图像的细粒度匹配，需针对性改进。

Method: 构建基于新颖视图合成的自监督训练框架，生成可靠内点对应关系；在此基础上设计三元组对比学习策略；对DINOv2骨干网络增加一个专用Transformer层，使其输出嵌入可直接通过余弦相似度阈值进行匹配。

Result: 在SCARED数据集上实验表明，该方法相比前沿方法具有更高的匹配精度和更低的极线误差。

Conclusion: 所提方法有效提升了内窥镜图像间的像素级对应能力，为术中3D重建、相机跟踪和场景理解等高级视觉任务提供了更准确的基础支撑。

Abstract: Accurate spatial understanding is essential for image-guided surgery, augmented reality integration and context awareness. In minimally invasive procedures, where visual input is the sole intraoperative modality, establishing precise pixel-level correspondences between endoscopic frames is critical for 3D reconstruction, camera tracking, and scene interpretation. However, the surgical domain presents distinct challenges: weak perspective cues, non-Lambertian tissue reflections, and complex, deformable anatomy degrade the performance of conventional computer vision techniques. While Deep Learning models have shown strong performance in natural scenes, their features are not inherently suited for fine-grained matching in surgical images and require targeted adaptation to meet the demands of this domain. This research presents a novel Deep Learning pipeline for establishing feature correspondences in endoscopic image pairs, alongside a self-supervised optimization framework for model training. The proposed methodology leverages a novel-view synthesis pipeline to generate ground-truth inlier correspondences, subsequently utilized for mining triplets within a contrastive learning paradigm. Through this self-supervised approach, we augment the DINOv2 backbone with an additional Transformer layer, specifically optimized to produce embeddings that facilitate direct matching through cosine similarity thresholding. Experimental evaluation demonstrates that our pipeline surpasses state-of-the-art methodologies on the SCARED datasets improved matching precision and lower epipolar error compared to the related work. The proposed framework constitutes a valuable contribution toward enabling more accurate high-level computer vision applications in surgical endoscopy.

</details>


### [44] [Towards Fine-Grained Recognition with Large Visual Language Models: Benchmark and Optimization Strategies](https://arxiv.org/abs/2512.10384)
*Cong Pang,Hongtao Yu,Zixuan Chen,Lewei Lu,Xin Lou*

Main category: cs.CV

TL;DR: 本文提出了FROW基准测试，用于评估大视觉语言模型（LVLMs）在细粒度识别任务上的性能，并从数据构建和训练过程两方面提出优化策略，显著提升了模型在类别识别与内容准确性上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注推理任务，忽视了对实际应用至关重要的细粒度识别能力，因此需构建专门评估该能力的新基准。

Method: 提出FROW基准，并设计包含马赛克数据（多短答案组合）和开放世界数据（基于GPT-4o生成的真实问答）的新型数据集；同时将细粒度数据融入预训练阶段以优化LVLMs。

Result: 马赛克数据使类别识别准确率提升1%；开放世界数据使FROW基准准确率提升10%-20%，内容准确率提升6%-12%；预训练中加入细粒度数据可使类别识别准确率最高提升10%。

Conclusion: FROW为LVLMs的细粒度识别能力提供了有效评估框架，所提数据构建与训练优化策略显著提升模型性能，具备实用价值和推广潜力。

Abstract: Large Vision Language Models (LVLMs) have made remarkable progress, enabling sophisticated vision-language interaction and dialogue applications. However, existing benchmarks primarily focus on reasoning tasks, often neglecting fine-grained recognition, which is crucial for practical application scenarios. To address this gap, we introduce the Fine-grained Recognition Open World (FROW) benchmark, designed for detailed evaluation of LVLMs with GPT-4o. On the basis of that, we propose a novel optimization strategy from two perspectives: \textit{data construction} and \textit{training process}, to improve the performance of LVLMs. Our dataset includes mosaic data, which combines multiple short-answer responses, and open-world data, generated from real-world questions and answers using GPT-4o, creating a comprehensive framework for evaluating fine-grained recognition in LVLMs. Experiments show that mosaic data improves category recognition accuracy by 1\% and open-world data boosts FROW benchmark accuracy by 10\%-20\% and content accuracy by 6\%-12\%. Meanwhile, incorporating fine-grained data into the pre-training phase can improve the model's category recognition accuracy by up to 10\%. The benchmark will be available at https://github.com/pc-inno/FROW.

</details>


### [45] [Adaptive Dual-Weighted Gravitational Point Cloud Denoising Method](https://arxiv.org/abs/2512.10386)
*Ge Zhang,Chunyang Wang,Bo Xiao,Xuelian Liu,Bin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种自适应双权重引力点云去噪方法，结合八叉树空间划分、自适应体素统计与kNN密度估计，以及融合密度与距离权重的引力评分函数，在保证高精度和强边缘保持能力的同时实现近实时处理。


<details>
  <summary>Details</summary>
Motivation: 现有点云去噪方法难以兼顾高精度、强边缘保持和实时性；LiDAR采集易受干扰导致噪声多，影响后续检测识别性能。

Method: 采用八叉树进行全局空间划分以支持并行加速；在叶节点内结合自适应体素占据统计与kNN密度估计快速剔除孤立低密度噪声；构建融合密度权重与自适应距离权重的引力评分函数精细区分噪声点与目标点。

Result: 在Stanford 3D、CADC及自研FMCW LiDAR数据集上，相比现有方法，F1、PSNR和Chamfer Distance指标均显著提升，单帧处理时间降低，验证了其高精度、鲁棒性与实时性。

Conclusion: 所提方法有效平衡了去噪精度、结构保真度与计算效率，适用于多类型噪声下的实际自动驾驶与三维重建场景。

Abstract: High-quality point cloud data is a critical foundation for tasks such as autonomous driving and 3D reconstruction. However, LiDAR-based point cloud acquisition is often affected by various disturbances, resulting in a large number of noise points that degrade the accuracy of subsequent point cloud object detection and recognition. Moreover, existing point cloud denoising methods typically sacrifice computational efficiency in pursuit of higher denoising accuracy, or, conversely, improve processing speed at the expense of preserving object boundaries and fine structural details, making it difficult to simultaneously achieve high denoising accuracy, strong edge preservation, and real-time performance. To address these limitations, this paper proposes an adaptive dual-weight gravitational-based point cloud denoising method. First, an octree is employed to perform spatial partitioning of the global point cloud, enabling parallel acceleration. Then, within each leaf node, adaptive voxel-based occupancy statistics and k-nearest neighbor (kNN) density estimation are applied to rapidly remove clearly isolated and low-density noise points, thereby reducing the effective candidate set. Finally, a gravitational scoring function that combines density weights with adaptive distance weights is constructed to finely distinguish noise points from object points. Experiments conducted on the Stanford 3D Scanning Repository, the Canadian Adverse Driving Conditions (CADC) dataset, and in-house FMCW LiDAR point clouds acquired in our laboratory demonstrate that, compared with existing methods, the proposed approach achieves consistent improvements in F1, PSNR, and Chamfer Distance (CD) across various noise conditions while reducing the single-frame processing time, thereby validating its high accuracy, robustness, and real-time performance in multi-noise scenarios.

</details>


### [46] [Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](https://arxiv.org/abs/2512.10949)
*Yiwen Tang,Zoey Guo,Kaixin Zhu,Ray Zhang,Qizhi Chen,Dongzhi Jiang,Junli Liu,Bohan Zeng,Haoming Song,Delin Qu,Tianyi Bai,Dan Xu,Wentao Zhang,Bin Zhao*

Main category: cs.CV

TL;DR: 本文首次系统研究了强化学习（RL）在文本到3D自回归生成中的应用，涵盖奖励设计、RL算法改进、新基准MME-3DR构建及提出分层优化方法Hi-GRPO，并据此开发出首个RL增强的文本到3D模型AR3D-R1。


<details>
  <summary>Details</summary>
Motivation: 3D生成因空间复杂度高、需全局几何一致性和局部纹理精细，对奖励设计和RL算法极为敏感，而此前RL在3D生成中尚未被系统探索。

Method: 从四方面展开：（1）评估多维奖励设计，强调人类偏好对齐与多模态模型信号有效性；（2）研究GRPO变体，突出token级优化与训练规模影响；（3）构建新基准MME-3DR以评测3D隐式推理能力；（4）提出分层RL方法Hi-GRPO，结合全局到局部生成与专用奖励集成。

Result: 提出了Hi-GRPO算法与MME-3DR基准，并实现了首个RL增强的文本到3D模型AR3D-R1，在从粗略形状到纹理细化的全流程中取得进展。

Conclusion: 本工作验证了RL在文本到3D生成中的可行性与潜力，为RL驱动的3D生成推理提供了系统性方法论与实践基础。

Abstract: Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.

</details>


### [47] [MultiHateLoc: Towards Temporal Localisation of Multimodal Hate Content in Online Videos](https://arxiv.org/abs/2512.10408)
*Qiyue Sun,Tailin Chen,Yinghui Zhang,Yuchen Zhang,Jiangbei Yue,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 本文提出MultiHateLoc，首个面向弱监督下的多模态仇恨内容时序定位框架，通过模态感知时序编码、动态跨模态融合与对比对齐、以及模态感知的多实例学习目标，在仅有视频级标签条件下实现帧级仇恨片段定位，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于视频级仇恨语音分类，缺乏对关键的时序定位（即识别仇恨内容发生时刻）的研究，尤其在仅提供视频级弱标签的现实场景下，传统静态融合或分类模型难以建模跨模态与时间动态性。

Method: 提出MultiHateLoc框架：(1) 模态感知时序编码器（含文本预处理增强模块）；(2) 动态跨模态融合机制与跨模态对比对齐策略；(3) 模态感知的多实例学习（MIL）目标，以视频级标签监督帧级定位。

Result: 在HateMM和MultiHateClip数据集上，MultiHateLoc在弱监督时序定位任务中达到SOTA性能，可输出细粒度、可解释的帧级预测。

Conclusion: MultiHateLoc有效解决了弱监督下多模态仇恨内容的时序定位难题，为真实短视频平台中的细粒度有害内容检测提供了可行且高效的新范式。

Abstract: The rapid growth of video content on platforms such as TikTok and YouTube has intensified the spread of multimodal hate speech, where harmful cues emerge subtly and asynchronously across visual, acoustic, and textual streams. Existing research primarily focuses on video-level classification, leaving the practically crucial task of temporal localisation, identifying when hateful segments occur, largely unaddressed. This challenge is even more noticeable under weak supervision, where only video-level labels are available, and static fusion or classification-based architectures struggle to capture cross-modal and temporal dynamics. To address these challenges, we propose MultiHateLoc, the first framework designed for weakly-supervised multimodal hate localisation. MultiHateLoc incorporates (1) modality-aware temporal encoders to model heterogeneous sequential patterns, including a tailored text-based preprocessing module for feature enhancement; (2) dynamic cross-modal fusion to adaptively emphasise the most informative modality at each moment and a cross-modal contrastive alignment strategy to enhance multimodal feature consistency; (3) a modality-aware MIL objective to identify discriminative segments under video-level supervision. Despite relying solely on coarse labels, MultiHateLoc produces fine-grained, interpretable frame-level predictions. Experiments on HateMM and MultiHateClip show that our method achieves state-of-the-art performance in the localisation task.

</details>


### [48] [Beyond Endpoints: Path-Centric Reasoning for Vectorized Off-Road Network Extraction](https://arxiv.org/abs/2512.10416)
*Wenfei Guan,Jilin Mei,Tong Shen,Xumin Wu,Shuo Wang,Cheng Min,Yu Hu*

Main category: cs.CV

TL;DR: 本文提出WildRoad数据集和MaGRoad方法，解决野外道路提取中因域差距导致的性能下降问题，通过路径中心范式提升拓扑鲁棒性并加速推理。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在野外道路提取中表现不佳，主要由于缺乏大规模向量化数据集及主流方法（如SAM-Road）采用节点中心范式，在遮挡和歧义路口下易产生拓扑错误。

Method: 1）构建全球野外道路网络数据集WildRoad，配备专用交互式标注工具；2）提出路径中心框架MaGRoad，沿候选路径聚合多尺度视觉证据以鲁棒推断连通性。

Result: MaGRoad在WildRoad基准上达到SOTA性能，且能良好泛化至城市数据集；推理速度提升约2.5倍。

Conclusion: WildRoad数据集与路径中心范式共同为野外道路制图提供了更坚实的基础。

Abstract: Deep learning has advanced vectorized road extraction in urban settings, yet off-road environments remain underexplored and challenging. A significant domain gap causes advanced models to fail in wild terrains due to two key issues: lack of large-scale vectorized datasets and structural weakness in prevailing methods. Models such as SAM-Road employ a node-centric paradigm that reasons at sparse endpoints, making them fragile to occlusions and ambiguous junctions in off-road scenes, leading to topological errors.This work addresses these limitations in two complementary ways. First, we release WildRoad, a gloabal off-road road network dataset constructed efficiently with a dedicated interactive annotation tool tailored for road-network labeling. Second, we introduce MaGRoad (Mask-aware Geodesic Road network extractor), a path-centric framework that aggregates multi-scale visual evidence along candidate paths to infer connectivity robustly.Extensive experiments show that MaGRoad achieves state-of-the-art performance on our challenging WildRoad benchmark while generalizing well to urban datasets. A streamlined pipeline also yields roughly 2.5x faster inference, improving practical applicability. Together, the dataset and path-centric paradigm provide a stronger foundation for mapping roads in the wild.

</details>


### [49] [TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning](https://arxiv.org/abs/2512.10419)
*Phu Pham,Damon Conover,Aniket Bera*

Main category: cs.CV

TL;DR: 本文提出了TransLocNet，一种用于空中-地面定位的跨模态注意力框架，通过融合激光雷达几何信息与空中语义上下文，显著提升了定位精度。


<details>
  <summary>Details</summary>
Motivation: 由于地面激光雷达与俯视图像之间存在较大的视角和模态差异，空中-地面定位十分困难。

Method: 提出TransLocNet框架，将激光雷达扫描投影为鸟瞰图表示，并通过双向注意力机制与空中特征对齐，再通过似然图解码器输出位置和朝向的空间概率分布；引入对比学习模块以增强跨模态对齐。

Result: 在CARLA和KITTI数据集上实验表明，TransLocNet相比现有最优方法将定位误差降低了最多63%，实现了亚米级、亚度级精度。

Conclusion: TransLocNet在合成与真实场景中均展现出鲁棒且可泛化的空中-地面定位能力。

Abstract: Aerial-ground localization is difficult due to large viewpoint and modality gaps between ground-level LiDAR and overhead imagery. We propose TransLocNet, a cross-modal attention framework that fuses LiDAR geometry with aerial semantic context. LiDAR scans are projected into a bird's-eye-view representation and aligned with aerial features through bidirectional attention, followed by a likelihood map decoder that outputs spatial probability distributions over position and orientation. A contrastive learning module enforces a shared embedding space to improve cross-modal alignment. Experiments on CARLA and KITTI show that TransLocNet outperforms state-of-the-art baselines, reducing localization error by up to 63% and achieving sub-meter, sub-degree accuracy. These results demonstrate that TransLocNet provides robust and generalizable aerial-ground localization in both synthetic and real-world settings.

</details>


### [50] [Neural Collapse in Test-Time Adaptation](https://arxiv.org/abs/2512.10421)
*Xiao Chen,Zhongjing Du,Jiazhen Huang,Xu Jiang,Li Lu,Jingyan Jiang,Zhi Wang*

Main category: cs.CV

TL;DR: 本文提出NCTTA方法，通过样本级特征-分类器对齐（NC3+）解决测试时自适应（TTA）中因样本级错位导致的性能下降问题，并在ImageNet-C等基准上显著优于现有方法如Tent。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应（TTA）方法缺乏对域偏移下性能下降根本原因的理论理解；神经坍缩（NC）为TTA提供了新视角，但需扩展至样本级以揭示更细粒度机制。

Method: 提出样本级对齐坍缩（NC3+）现象，指出性能下降源于样本级特征与分类器权重的错位；据此设计NCTTA方法，采用融合几何邻近性与预测置信度的混合目标，缓解伪标签不可靠问题。

Result: NCTTA在ImageNet-C上比Tent提升14.52%，在多个域偏移基准上显著提升模型鲁棒性。

Conclusion: 样本级特征-分类器对齐是TTA中提升鲁棒性的关键；NCTTA通过引入混合监督信号有效应对伪标签噪声，为TTA提供了新的理论支撑与实用框架。

Abstract: Test-Time Adaptation (TTA) enhances model robustness to out-of-distribution (OOD) data by updating the model online during inference, yet existing methods lack theoretical insights into the fundamental causes of performance degradation under domain shifts. Recently, Neural Collapse (NC) has been proposed as an emergent geometric property of deep neural networks (DNNs), providing valuable insights for TTA. In this work, we extend NC to the sample-wise level and discover a novel phenomenon termed Sample-wise Alignment Collapse (NC3+), demonstrating that a sample's feature embedding, obtained by a trained model, aligns closely with the corresponding classifier weight. Building on NC3+, we identify that the performance degradation stems from sample-wise misalignment in adaptation which exacerbates under larger distribution shifts. This indicates the necessity of realigning the feature embeddings with their corresponding classifier weights. However, the misalignment makes pseudo-labels unreliable under domain shifts. To address this challenge, we propose NCTTA, a novel feature-classifier alignment method with hybrid targets to mitigate the impact of unreliable pseudo-labels, which blends geometric proximity with predictive confidence. Extensive experiments demonstrate the effectiveness of NCTTA in enhancing robustness to domain shifts. For example, NCTTA outperforms Tent by 14.52% on ImageNet-C.

</details>


### [51] [An M-Health Algorithmic Approach to Identify and Assess Physiotherapy Exercises in Real Time](https://arxiv.org/abs/2512.10437)
*Stylianos Kandylakis,Christos Orfanopoulos,Georgios Siolas,Panayiotis Tsanakas*

Main category: cs.CV

TL;DR: 本文提出了一种基于移动设备的实时人体物理治疗运动识别、分类与评估算法框架，利用姿态估计神经网络提取关键点，转换为三角角度特征后用轻量级模型分类，并通过改进的Levenshtein距离动态规划匹配运动序列，全程端侧运行。


<details>
  <summary>Details</summary>
Motivation: 解决远程物理治疗中对运动动作实时、准确、隐私安全的自动监督需求。

Method: 将运动分解为静态姿态序列；用姿态估计网络获取关键点；转化为三角角度特征；轻量级监督模型进行帧级姿态分类与评分；采用改进Levenshtein距离的动态规划实现运动序列匹配与偏差定位；全客户端部署。

Result: 系统实现了实时、高精度的运动识别与偏差检测，实验验证了其在远程理疗和移动健康应用中的有效性与可扩展性。

Conclusion: 该端侧轻量框架兼顾实时性、鲁棒性与隐私性，为m-health和远程康复提供了可行的技术路径。

Abstract: This work presents an efficient algorithmic framework for real-time identification, classification, and evaluation of human physiotherapy exercises using mobile devices. The proposed method interprets a kinetic movement as a sequence of static poses, which are estimated from camera input using a pose-estimation neural network. Extracted body keypoints are transformed into trigonometric angle-based features and classified with lightweight supervised models to generate frame-level pose predictions and accuracy scores. To recognize full exercise movements and detect deviations from prescribed patterns, we employ a dynamic-programming scheme based on a modified Levenshtein distance algorithm, enabling robust sequence matching and localization of inaccuracies. The system operates entirely on the client side, ensuring scalability and real-time performance. Experimental evaluation demonstrates the effectiveness of the methodology and highlights its applicability to remote physiotherapy supervision and m-health applications.

</details>


### [52] [Error-Propagation-Free Learned Video Compression With Dual-Domain Progressive Temporal Alignment](https://arxiv.org/abs/2512.10450)
*Han Li,Shaohui Li,Wenrui Dai,Chenglin Li,Xinlong Pan,Haipeng Wang,Junni Zou,Hongkai Xiong*

Main category: cs.CV

TL;DR: 本文提出了一种新型统一变换框架，结合双域渐进式时序对齐与质量条件混合专家（QCMoE）模块，实现无误差传播、质量一致的流式学习视频压缩。


<details>
  <summary>Details</summary>
Motivation: 现有学习型视频压缩框架在运动估计与补偿（ME/MC）中面临时序对齐不准与误差传播之间的权衡：分离变换框架R-D性能好但误差传播严重；统一变换框架无误差传播但ME/MC性能差。

Method: 提出双域渐进式时序对齐（像素域粗对齐 + 潜在域精对齐，含Flow-Guided Deformable Transformer实现多帧长时运动细化）和质量条件混合专家（QCMoE）模块（按目标质量与内容动态分配专家以逐像素调整量化步长）。

Result: 实验表明该方法在保持无误差传播的同时，达到与当前最优方法具有竞争力的率失真（R-D）性能。

Conclusion: 所提统一变换框架通过双域对齐与QCMoE，有效兼顾高精度ME/MC与无误差传播，支持高质量、连续码率自适应的流式视频压缩。

Abstract: Existing frameworks for learned video compression suffer from a dilemma between inaccurate temporal alignment and error propagation for motion estimation and compensation (ME/MC). The separate-transform framework employs distinct transforms for intra-frame and inter-frame compression to yield impressive rate-distortion (R-D) performance but causes evident error propagation, while the unified-transform framework eliminates error propagation via shared transforms but is inferior in ME/MC in shared latent domains. To address this limitation, in this paper, we propose a novel unifiedtransform framework with dual-domain progressive temporal alignment and quality-conditioned mixture-of-expert (QCMoE) to enable quality-consistent and error-propagation-free streaming for learned video compression. Specifically, we propose dualdomain progressive temporal alignment for ME/MC that leverages coarse pixel-domain alignment and refined latent-domain alignment to significantly enhance temporal context modeling in a coarse-to-fine fashion. The coarse pixel-domain alignment efficiently handles simple motion patterns with optical flow estimated from a single reference frame, while the refined latent-domain alignment develops a Flow-Guided Deformable Transformer (FGDT) over latents from multiple reference frames to achieve long-term motion refinement (LTMR) for complex motion patterns. Furthermore, we design a QCMoE module for continuous bit-rate adaptation that dynamically assigns different experts to adjust quantization steps per pixel based on target quality and content rather than relies on a single quantization step. QCMoE allows continuous and consistent rate control with appealing R-D performance. Experimental results show that the proposed method achieves competitive R-D performance compared with the state-of-the-arts, while successfully eliminating error propagation.

</details>


### [53] [Robust Shape from Focus via Multiscale Directional Dilated Laplacian and Recurrent Network](https://arxiv.org/abs/2512.10498)
*Khurram Ashfaq,Muhammad Tariq Mahmood*

Main category: cs.CV

TL;DR: 本文提出了一种混合框架的Shape-from-Focus（SFF）方法，结合手工设计的多尺度方向膨胀拉普拉斯（DDL）核与轻量级多尺度GRU深度提取模块，并引入学习型凸上采样，以提升深度图精度、细节保持和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习SFF方法多为两阶段：先用重型编码器提取焦点体积，再通过简单聚合估计深度，易引入伪影和噪声。

Method: 采用手工设计的Directional Dilated Laplacian（DDL）核提取多尺度焦点体积；使用轻量级多尺度GRU模块迭代优化低分辨率初始深度估计；嵌入学习型凸上采样模块重建高分辨率深度图。

Result: 在合成与真实数据集上均超越当前最优深度学习与传统方法，具备更高精度与跨焦距条件的强泛化能力。

Conclusion: 所提混合框架兼顾效率与性能，在焦点体积建模、深度迭代优化与高分辨率重建三方面协同改进，显著提升了SFF的整体表现。

Abstract: Shape-from-Focus (SFF) is a passive depth estimation technique that infers scene depth by analyzing focus variations in a focal stack. Most recent deep learning-based SFF methods typically operate in two stages: first, they extract focus volumes (a per pixel representation of focus likelihood across the focal stack) using heavy feature encoders; then, they estimate depth via a simple one-step aggregation technique that often introduces artifacts and amplifies noise in the depth map. To address these issues, we propose a hybrid framework. Our method computes multi-scale focus volumes traditionally using handcrafted Directional Dilated Laplacian (DDL) kernels, which capture long-range and directional focus variations to form robust focus volumes. These focus volumes are then fed into a lightweight, multi-scale GRU-based depth extraction module that iteratively refines an initial depth estimate at a lower resolution for computational efficiency. Finally, a learned convex upsampling module within our recurrent network reconstructs high-resolution depth maps while preserving fine scene details and sharp boundaries. Extensive experiments on both synthetic and real-world datasets demonstrate that our approach outperforms state-of-the-art deep learning and traditional methods, achieving superior accuracy and generalization across diverse focal conditions.

</details>


### [54] [3D Blood Pulsation Maps](https://arxiv.org/abs/2512.10517)
*Maurice Rohr,Tobias Reinhardt,Tizian Dege,Justus Thies,Christoph Hoog Antink*

Main category: cs.CV

TL;DR: Pulse3DFace 是首个用于估计 3D 血液脉动图的数据集，支持动态面部血流建模、合成视频生成以提升远程光电容积脉搏波（PPG）测量，并推动多视角光照鲁棒性研究。


<details>
  <summary>Details</summary>
Motivation: 现有远程脉搏估计方法受限于缺乏真实、多视角、带生理参考的3D血流动态数据；同时光照变化严重影响血流信号分析，需新数据支撑多视角鲁棒算法研发。

Method: 采集15名受试者在23个视角下的30Hz RGB视频，同步获取真实血流参考信号与单目SfM生成的3D人脸模型；将血流信号映射至FLAME模型纹理空间，生成含信噪比、振幅、相位等信息的3D脉动图，并进行光照条件、地图一致性及生理特征有效性评估。

Result: 构建了首个带多视角视频、生理参考、3D头模对齐的3D血流脉动数据集 Pulse3DFace；验证了其在面部与颈部区域能稳定捕获符合生理规律的脉动特征，且具备良好跨视角一致性与可控光照多样性。

Conclusion: Pulse3DFace 为基于视觉的远程PPG研究提供了关键基础资源，推动高保真生理信号建模、合成数据驱动训练及光照不变脉动分析方法的发展。

Abstract: We present Pulse3DFace, the first dataset of its kind for estimating 3D blood pulsation maps. These maps can be used to develop models of dynamic facial blood pulsation, enabling the creation of synthetic video data to improve and validate remote pulse estimation methods via photoplethysmography imaging. Additionally, the dataset facilitates research into novel multi-view-based approaches for mitigating illumination effects in blood pulsation analysis. Pulse3DFace consists of raw videos from 15 subjects recorded at 30 Hz with an RGB camera from 23 viewpoints, blood pulse reference measurements, and facial 3D scans generated using monocular structure-from-motion techniques. It also includes processed 3D pulsation maps compatible with the texture space of the 3D head model FLAME. These maps provide signal-to-noise ratio, local pulse amplitude, phase information, and supplementary data. We offer a comprehensive evaluation of the dataset's illumination conditions, map consistency, and its ability to capture physiologically meaningful features in the facial and neck skin regions.

</details>


### [55] [Take a Peek: Efficient Encoder Adaptation for Few-Shot Semantic Segmentation via LoRA](https://arxiv.org/abs/2512.10521)
*Pasquale De Marinis,Gennaro Vessio,Giovanna Castellano*

Main category: cs.CV

TL;DR: 本文提出了一种名为Take a Peek (TaP)的轻量级方法，通过低秩自适应（LoRA）微调编码器，提升其在少样本语义分割（FSS）及跨域FSS中的泛化能力，显著提升性能且计算开销小。


<details>
  <summary>Details</summary>
Motivation: 现有FSS方法主要优化解码器，而编码器对未见类别的特征提取能力不足，成为关键瓶颈。

Method: 引入Take a Peek (TaP)，利用LoRA在支持集上对编码器进行快速、低开销微调，增强其对新类别的适应性并缓解灾难性遗忘；方法模型无关、易于集成。

Result: 在COCO 20^i、Pascal 5^i及跨域数据集（DeepGlobe、ISIC、Chest X-ray）上验证，TaP在多种模型和shot设置下均显著提升分割性能，尤其在多类别复杂场景中效果突出；低秩设置下仍保持高性能。

Conclusion: TaP有效解决了FSS中编码器泛化能力弱的关键问题，为构建更鲁棒、高效、通用的分割系统提供了新思路。

Abstract: Few-shot semantic segmentation (FSS) aims to segment novel classes in query images using only a small annotated support set. While prior research has mainly focused on improving decoders, the encoder's limited ability to extract meaningful features for unseen classes remains a key bottleneck. In this work, we introduce \textit{Take a Peek} (TaP), a simple yet effective method that enhances encoder adaptability for both FSS and cross-domain FSS (CD-FSS). TaP leverages Low-Rank Adaptation (LoRA) to fine-tune the encoder on the support set with minimal computational overhead, enabling fast adaptation to novel classes while mitigating catastrophic forgetting. Our method is model-agnostic and can be seamlessly integrated into existing FSS pipelines. Extensive experiments across multiple benchmarks--including COCO $20^i$, Pascal $5^i$, and cross-domain datasets such as DeepGlobe, ISIC, and Chest X-ray--demonstrate that TaP consistently improves segmentation performance across diverse models and shot settings. Notably, TaP delivers significant gains in complex multi-class scenarios, highlighting its practical effectiveness in realistic settings. A rank sensitivity analysis also shows that strong performance can be achieved even with low-rank adaptations, ensuring computational efficiency. By addressing a critical limitation in FSS--the encoder's generalization to novel classes--TaP paves the way toward more robust, efficient, and generalizable segmentation systems. The code is available at https://github.com/pasqualedem/TakeAPeek.

</details>


### [56] [Blink: Dynamic Visual Token Resolution for Enhanced Multimodal Understanding](https://arxiv.org/abs/2512.10548)
*Yuchen Feng,Zhenyu Zhang,Naibin Gu,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang*

Main category: cs.CV

TL;DR: 本文提出Blink框架，通过模拟人类‘眨眼式’视觉感知过程，在单次前向传播中动态调整视觉标记分辨率，提升多模态大语言模型（MLLMs）的视觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 受人类动态扫描和聚焦显著区域的视觉感知机制启发，探究MLLMs是否具备类似行为，并提升其有限的视觉感知能力。

Method: 提出Blink框架，包含显著性引导扫描和动态标记分辨率两个模块：基于注意力图估计各层视觉标记显著性，并通过即插即用的标记超分辨率（TokenSR）扩展重要标记；在后续层中丢弃失去关注的扩展标记。

Result: 大量实验验证了Blink在增强视觉感知与多模态理解方面的有效性。

Conclusion: Blink通过动态、自适应地平衡广域探索与细粒度聚焦，显著提升了MLLMs的视觉感知效率与性能。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress on various vision-language tasks, yet their visual perception remains limited. Humans, in comparison, perceive complex scenes efficiently by dynamically scanning and focusing on salient regions in a sequential "blink-like" process. Motivated by this strategy, we first investigate whether MLLMs exhibit similar behavior. Our pilot analysis reveals that MLLMs naturally attend to different visual regions across layers and that selectively allocating more computation to salient tokens can enhance visual perception. Building on this insight, we propose Blink, a dynamic visual token resolution framework that emulates the human-inspired process within a single forward pass. Specifically, Blink includes two modules: saliency-guided scanning and dynamic token resolution. It first estimates the saliency of visual tokens in each layer based on the attention map, and extends important tokens through a plug-and-play token super-resolution (TokenSR) module. In the next layer, it drops the extended tokens when they lose focus. This dynamic mechanism balances broad exploration and fine-grained focus, thereby enhancing visual perception adaptively and efficiently. Extensive experiments validate Blink, demonstrating its effectiveness in enhancing visual perception and multimodal understanding.

</details>


### [57] [Grounding Everything in Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2512.10554)
*Xiangxuan Ren,Zhongdao Wang,Liping Hou,Pin Tang,Guoqing Wang,Chao Ma*

Main category: cs.CV

TL;DR: 本文提出GETok方法，通过引入可学习的网格令牌和偏移令牌，增强多模态大语言模型（MLLMs）在2D图像空间中对物体的定位与推理能力，无需修改其自回归架构。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs依赖图像tokenization，难以准确在2D图像空间中定位物体，亟需改进语言token以更好支持空间接地。

Method: 提出GETok：使用网格令牌划分图像平面为结构化空间锚点，并用偏移令牌迭代精化定位预测，将空间关系直接嵌入token中。

Result: 在多种指代任务上，GETok在监督微调和强化学习设置下均显著优于当前最优方法。

Conclusion: GETok有效提升了MLLMs原生2D空间推理能力，且兼容标准自回归Transformer架构。

Abstract: Multimodal large language models (MLLMs) have made significant advancements in vision understanding and reasoning. However, the autoregressive Transformer architecture used by MLLMs requries tokenization on input images, which limits their ability to accurately ground objects within the 2D image space. This raises an important question: how can sequential language tokens be improved to better ground objects in 2D spatial space for MLLMs? To address this, we present a spatial representation method for grounding objects, namely GETok, that integrates a specialized vocabulary of learnable tokens into MLLMs. GETok first uses grid tokens to partition the image plane into structured spatial anchors, and then exploits offset tokens to enable precise and iterative refinement of localization predictions. By embedding spatial relationships directly into tokens, GETok significantly advances MLLMs in native 2D space reasoning without modifying the autoregressive architecture. Extensive experiments demonstrate that GETok achieves superior performance over the state-of-the-art methods across various referring tasks in both supervised fine-tuning and reinforcement learning settings.

</details>


### [58] [Data-Efficient American Sign Language Recognition via Few-Shot Prototypical Networks](https://arxiv.org/abs/2512.10562)
*Meher Md Saad*

Main category: cs.CV

TL;DR: 本文提出了一种基于骨架的少样本原型网络框架，结合ST-GCN与多尺度时间聚合模块，显著提升孤立手语识别在数据稀缺和长尾分布下的性能，并展现出良好的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 孤立手语识别面临数据稀缺和词汇长尾分布的挑战，传统分类方法易过拟合高频类、难以泛化至低频类。

Method: 提出基于骨架编码器的少样本原型网络框架，采用阶段性训练学习语义度量空间；结合ST-GCN与新提出的多尺度时间聚合（MSTA）模块，建模快速与流畅的动作动态。

Result: 在WLASL数据集上达到43.75% Top-1和77.10% Top-5准确率，较相同骨干网络的标准分类基线提升超13%；在未见过的SignASL数据集上实现近30%零样本准确率。

Conclusion: 原型网络范式在数据稀缺场景下显著优于标准分类，为大规模手语词汇识别提供了可扩展的解决方案。

Abstract: Isolated Sign Language Recognition (ISLR) is critical for bridging the communication gap between the Deaf and Hard-of-Hearing (DHH) community and the hearing world. However, robust ISLR is fundamentally constrained by data scarcity and the long-tail distribution of sign vocabulary, where gathering sufficient examples for thousands of unique signs is prohibitively expensive. Standard classification approaches struggle under these conditions, often overfitting to frequent classes while failing to generalize to rare ones. To address this bottleneck, we propose a Few-Shot Prototypical Network framework adapted for a skeleton based encoder. Unlike traditional classifiers that learn fixed decision boundaries, our approach utilizes episodic training to learn a semantic metric space where signs are classified based on their proximity to dynamic class prototypes. We integrate a Spatiotemporal Graph Convolutional Network (ST-GCN) with a novel Multi-Scale Temporal Aggregation (MSTA) module to capture both rapid and fluid motion dynamics. Experimental results on the WLASL dataset demonstrate the superiority of this metric learning paradigm: our model achieves 43.75% Top-1 and 77.10% Top-5 accuracy on the test set. Crucially, this outperforms a standard classification baseline sharing the identical backbone architecture by over 13%, proving that the prototypical training strategy effectively outperforms in a data scarce situation where standard classification fails. Furthermore, the model exhibits strong zero-shot generalization, achieving nearly 30% accuracy on the unseen SignASL dataset without fine-tuning, offering a scalable pathway for recognizing extensive sign vocabularies with limited data.

</details>


### [59] [Audio-sync Video Instance Editing with Granularity-Aware Mask Refiner](https://arxiv.org/abs/2512.10571)
*Haojie Zheng,Shuchen Weng,Jingqi Liu,Siqi Yang,Boxin Shi,Xinlong Wang*

Main category: cs.CV

TL;DR: 本文提出了AVI-Edit框架，用于音频同步的视频实例编辑，通过粒度感知掩码优化器和自反馈音频代理实现精细的空间与时间控制，并构建了大规模实例级标注数据集。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法忽视音视频同步，且缺乏对实例级编辑所需的精细时空可控性。

Method: 提出AVI-Edit框架，包括粒度感知掩码优化器（迭代优化粗略用户掩码）和自反馈音频代理（提供高质量、细粒度时序音频引导），并构建大规模实例中心对应数据集。

Result: 实验表明AVI-Edit在视觉质量、条件遵循性和音视频同步性方面均优于当前最先进方法。

Conclusion: AVI-Edit为音频同步的视频实例编辑提供了新范式，显著提升了编辑精度与同步效果。

Abstract: Recent advancements in video generation highlight that realistic audio-visual synchronization is crucial for engaging content creation. However, existing video editing methods largely overlook audio-visual synchronization and lack the fine-grained spatial and temporal controllability required for precise instance-level edits. In this paper, we propose AVI-Edit, a framework for audio-sync video instance editing. We propose a granularity-aware mask refiner that iteratively refines coarse user-provided masks into precise instance-level regions. We further design a self-feedback audio agent to curate high-quality audio guidance, providing fine-grained temporal control. To facilitate this task, we additionally construct a large-scale dataset with instance-centric correspondence and comprehensive annotations. Extensive experiments demonstrate that AVI-Edit outperforms state-of-the-art methods in visual quality, condition following, and audio-visual synchronization. Project page: https://hjzheng.net/projects/AVI-Edit/.

</details>


### [60] [Unleashing Degradation-Carrying Features in Symmetric U-Net: Simpler and Stronger Baselines for All-in-One Image Restoration](https://arxiv.org/abs/2512.10581)
*Wenlong Jiao,Heyang Lee,Ping Wang,Pengfei Zhu,Qinghua Hu,Dongwei Ren*

Main category: cs.CV

TL;DR: 本文提出了一种对称U-Net结构（SymUNet）用于一体化图像恢复，发现精心设计的特征提取本身已隐含退化信息，无需复杂架构；进一步引入CLIP语义增强变体SE-SymUNet，通过简单交叉注意力注入语义先验，在多个基准上实现更优性能且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 现有全合一图像恢复方法过度依赖复杂架构（如MoE、扩散模型）和精细的退化提示策略，缺乏对基础网络结构潜力的挖掘。

Method: 提出对称U-Net架构（SymUNet），强调编码器-解码器间特征尺度对齐与跨尺度传播简化；进一步设计SE-SymUNet，在跳连中通过冻结CLIP特征的交叉注意力直接注入语义先验以增强退化建模能力。

Result: SymUNet在多个基准数据集上超越现有方法且计算开销更低；SE-SymUNet进一步提升性能，验证了语义增强的有效性；两者均以更简结构达成SOTA效果。

Conclusion: 对称U-Net结构足以高效利用特征中的退化信息，无需复杂设计；语义先验可通过轻量方式有效融合；该工作为全合一图像恢复提供了更简洁、更强健的基础框架。

Abstract: All-in-one image restoration aims to handle diverse degradations (e.g., noise, blur, adverse weather) within a unified framework, yet existing methods increasingly rely on complex architectures (e.g., Mixture-of-Experts, diffusion models) and elaborate degradation prompt strategies. In this work, we reveal a critical insight: well-crafted feature extraction inherently encodes degradation-carrying information, and a symmetric U-Net architecture is sufficient to unleash these cues effectively. By aligning feature scales across encoder-decoder and enabling streamlined cross-scale propagation, our symmetric design preserves intrinsic degradation signals robustly, rendering simple additive fusion in skip connections sufficient for state-of-the-art performance. Our primary baseline, SymUNet, is built on this symmetric U-Net and achieves better results across benchmark datasets than existing approaches while reducing computational cost. We further propose a semantic enhanced variant, SE-SymUNet, which integrates direct semantic injection from frozen CLIP features via simple cross-attention to explicitly amplify degradation priors. Extensive experiments on several benchmarks validate the superiority of our methods. Both baselines SymUNet and SE-SymUNet establish simpler and stronger foundations for future advancements in all-in-one image restoration. The source code is available at https://github.com/WenlongJiao/SymUNet.

</details>


### [61] [Salient Object Detection in Complex Weather Conditions via Noise Indicators](https://arxiv.org/abs/2512.10592)
*Quan Chen,Xiaokai Yang,Tingyu Wang,Rongfeng Lu,Xichun Sheng,Yaoqi Sun,Chenggang Yan*

Main category: cs.CV

TL;DR: 本文提出了一种面向多变天气条件的显著目标检测（SOD）框架，通过引入噪声指示符（one-hot向量）和噪声指示融合模块（NIFM），在编码器中嵌入天气感知先验，提升复杂天气下的分割精度，同时保持与主流解码器的兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测方法大多假设低噪声视觉条件，忽视了真实场景中天气噪声对分割精度的严重影响。

Method: 提出一种包含专用编码器和可替换解码器的SOD框架；设计噪声指示符（one-hot向量）表征不同天气类型；构建噪声指示融合模块（NIFM），将语义特征与噪声指示符双输入融合，插入编码器各阶段间以实现自适应特征调制。

Result: 在WXSOD数据集上，不同训练规模（100%、50%、30%）及多种编码器/解码器组合下，所提框架（尤其是NIFM增强的专用编码器）在复杂天气条件下显著优于普通编码器。

Conclusion: NIFM能有效建模天气噪声并提升模型鲁棒性，所提框架兼顾性能与兼容性，为实际应用中的鲁棒SOD提供了新思路。

Abstract: Salient object detection (SOD), a foundational task in computer vision, has advanced from single-modal to multi-modal paradigms to enhance generalization. However, most existing SOD methods assume low-noise visual conditions, overlooking the degradation of segmentation accuracy caused by weather-induced noise in real-world scenarios. In this paper, we propose a SOD framework tailored for diverse weather conditions, encompassing a specific encoder and a replaceable decoder. To enable handling of varying weather noises, we introduce a one-hot vector as a noise indicator to represent different weather types and design a Noise Indicator Fusion Module (NIFM). The NIFM takes both semantic features and the noise indicator as dual inputs and is inserted between consecutive stages of the encoder to embed weather-aware priors via adaptive feature modulation. Critically, the proposed specific encoder retains compatibility with mainstream SOD decoders. Extensive experiments are conducted on the WXSOD dataset under varying training data scales (100%, 50%, 30% of the full training set), three encoder and seven decoder configurations. Results show that the proposed SOD framework (particularly the NIFM-enhanced specific encoder) improves segmentation accuracy under complex weather conditions compared to a vanilla encoder.

</details>


### [62] [Beyond Pixels: A Training-Free, Text-to-Text Framework for Remote Sensing Image Retrieval](https://arxiv.org/abs/2512.10596)
*J. Xiao,Y. Guo,X. Zi,K. Thiyagarajan,C. Moreira,M. Prasad*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的文本到文本遥感图像检索方法TRSLLaVA，并构建了多结构化标注的RSRT数据集，显著提升了零样本检索性能，验证了高质量文本描述在遥感图像语义检索中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有遥感图像语义检索方法受限于语义鸿沟，且依赖昂贵的领域特定训练；缺乏评估大视觉语言模型（VLM）生成文本在零样本检索中实用性的基准。

Method: 构建Remote Sensing Rich Text (RSRT)多结构化标注数据集；提出完全无训练、纯文本驱动的TRSLLaVA方法，将跨模态检索重构为文本到文本（T2T）匹配问题，在统一文本嵌入空间中匹配人工查询与VLM生成的图像描述。

Result: 在RSITMD和RSICD基准上，TRSLLaVA零样本检索平均召回率达42.62%，接近标准CLIP零样本基线（23.86%）的两倍，并超越多个监督模型。

Conclusion: 高质量结构化文本描述可有效弥合遥感图像的语义鸿沟，提供一种强大且低成本的检索新范式。

Abstract: Semantic retrieval of remote sensing (RS) images is a critical task fundamentally challenged by the \textquote{semantic gap}, the discrepancy between a model's low-level visual features and high-level human concepts. While large Vision-Language Models (VLMs) offer a promising path to bridge this gap, existing methods often rely on costly, domain-specific training, and there is a lack of benchmarks to evaluate the practical utility of VLM-generated text in a zero-shot retrieval context. To address this research gap, we introduce the Remote Sensing Rich Text (RSRT) dataset, a new benchmark featuring multiple structured captions per image. Based on this dataset, we propose a fully training-free, text-only retrieval reference called TRSLLaVA. Our methodology reformulates cross-modal retrieval as a text-to-text (T2T) matching problem, leveraging rich text descriptions as queries against a database of VLM-generated captions within a unified textual embedding space. This approach completely bypasses model training or fine-tuning. Experiments on the RSITMD and RSICD benchmarks show our training-free method is highly competitive with state-of-the-art supervised models. For instance, on RSITMD, our method achieves a mean Recall of 42.62\%, nearly doubling the 23.86\% of the standard zero-shot CLIP baseline and surpassing several top supervised models. This validates that high-quality semantic representation through structured text provides a powerful and cost-effective paradigm for remote sensing image retrieval.

</details>


### [63] [Track and Caption Any Motion: Query-Free Motion Discovery and Description in Videos](https://arxiv.org/abs/2512.10607)
*Bishoy Galoaa,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: TCAM是一种无需用户查询的视频理解框架，通过运动场注意力机制自动发现并描述视频中的多种运动模式，并在MeViS基准上展现出优异的跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法在遮挡、伪装或快速运动等挑战性条件下表现受限，而运动动力学往往比静态外观更能提供有效语义信息。

Method: 提出TCAM框架，结合对比式视觉-语言表征对齐运动模式，利用运动场注意力机制实现运动轨迹与自然语言描述的空间对齐，并通过全局视频-文本对齐与细粒度空间对应联合训练，借助多头交叉注意力实现无查询的多运动表达发现。

Result: 在MeViS基准上达到58.4%视频到文本检索准确率、64.9 JF空间定位分数，每视频平均发现4.8个相关表达且精度达84.7%。

Conclusion: 运动模式与对比式视觉-语言表征的对齐可作为强语义信号，TCAM验证了无查询、运动中心式视频理解的有效性与泛化性。

Abstract: We propose Track and Caption Any Motion (TCAM), a motion-centric framework for automatic video understanding that discovers and describes motion patterns without user queries. Understanding videos in challenging conditions like occlusion, camouflage, or rapid movement often depends more on motion dynamics than static appearance. TCAM autonomously observes a video, identifies multiple motion activities, and spatially grounds each natural language description to its corresponding trajectory through a motion-field attention mechanism. Our key insight is that motion patterns, when aligned with contrastive vision-language representations, provide powerful semantic signals for recognizing and describing actions. Through unified training that combines global video-text alignment with fine-grained spatial correspondence, TCAM enables query-free discovery of multiple motion expressions via multi-head cross-attention. On the MeViS benchmark, TCAM achieves 58.4% video-to-text retrieval, 64.9 JF for spatial grounding, and discovers 4.8 relevant expressions per video with 84.7% precision, demonstrating strong cross-task generalization.

</details>


### [64] [Robust Multi-Disease Retinal Classification via Xception-Based Transfer Learning and W-Net Vessel Segmentation](https://arxiv.org/abs/2512.10608)
*Mohammad Sadegh Gholizadeh,Amir Arsalan Rezapour*

Main category: cs.CV

TL;DR: 本文提出了一种结合深度特征提取与可解释图像处理模块的深度学习框架，以高保真视网膜血管分割为辅助任务，提升眼病自动诊断的准确性与临床可信度。


<details>
  <summary>Details</summary>
Motivation: 近年来致盲性眼病发病率大幅上升，亟需可扩展、高精度的筛查方案；同时标准CNN存在‘黑箱’问题，缺乏临床可解释性。

Method: 构建融合深度特征提取与可解释图像处理模块的pipeline，将高保真视网膜血管分割作为辅助任务，引导分类过程并增强模型对临床形态学特征的依赖。

Result: 模型预测更贴合临床专家判断，显著降低假阳性率，提升在真实临床场景中的部署可行性。

Conclusion: 将可解释性模块（如血管分割）嵌入诊断流程，可在不牺牲性能的前提下增强模型透明度与医学可信度，为AI辅助眼科筛查提供新范式。

Abstract: In recent years, the incidence of vision-threatening eye diseases has risen dramatically, necessitating scalable and accurate screening solutions. This paper presents a comprehensive study on deep learning architectures for the automated diagnosis of ocular conditions. To mitigate the "black-box" limitations of standard convolutional neural networks (CNNs), we implement a pipeline that combines deep feature extraction with interpretable image processing modules. Specifically, we focus on high-fidelity retinal vessel segmentation as an auxiliary task to guide the classification process. By grounding the model's predictions in clinically relevant morphological features, we aim to bridge the gap between algorithmic output and expert medical validation, thereby reducing false positives and improving deployment viability in clinical settings.

</details>


### [65] [Lang2Motion: Bridging Language and Motion through Joint Embedding Spaces](https://arxiv.org/abs/2512.10617)
*Bishoy Galoaa,Xiangyu Bai,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: Lang2Motion 是一种基于语言引导的点轨迹生成框架，通过将运动流形与联合嵌入空间对齐，实现对任意物体运动轨迹的生成；它利用真实视频中的点跟踪提取运动，结合 CLIP 冻结编码器进行文本和视觉双重监督训练，在文本到轨迹检索、运动精度及跨域动作识别等方面均取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有工作多集中于人体运动或视频合成，缺乏对任意物体显式轨迹生成的支持；本文旨在通过语言指导，从真实视频中提取通用物体运动并生成可编辑、可检索的轨迹表示。

Method: 提出基于 Transformer 的自编码器架构，利用 CLIP 的冻结文本和图像编码器，对文本描述与渲染轨迹可视化进行双路监督学习，实现运动流形与联合嵌入空间的对齐。

Result: 在文本到轨迹检索任务中 Recall@1 达 34.2%，较视频方法高 12.5 点；平均位移误差（ADE）降至 12.4，优于视频生成基线（18.3–25.3）；在仅用多样物体运动训练的情况下，人类动作识别 Top-1 准确率达 88.3%；支持风格迁移、语义插值与潜在空间编辑。

Conclusion: Lang2Motion 成功构建了语言与通用物体轨迹之间的语义桥梁，验证了跨物体类型与运动域的表征泛化能力，为具身智能与可控运动生成提供了新范式。

Abstract: We present Lang2Motion, a framework for language-guided point trajectory generation by aligning motion manifolds with joint embedding spaces. Unlike prior work focusing on human motion or video synthesis, we generate explicit trajectories for arbitrary objects using motion extracted from real-world videos via point tracking. Our transformer-based auto-encoder learns trajectory representations through dual supervision: textual motion descriptions and rendered trajectory visualizations, both mapped through CLIP's frozen encoders. Lang2Motion achieves 34.2% Recall@1 on text-to-trajectory retrieval, outperforming video-based methods by 12.5 points, and improves motion accuracy by 33-52% (12.4 ADE vs 18.3-25.3) compared to video generation baselines. We demonstrate 88.3% Top-1 accuracy on human action recognition despite training only on diverse object motions, showing effective transfer across motion domains. Lang2Motion supports style transfer, semantic interpolation, and latent-space editing through CLIP-aligned trajectory representations.

</details>


### [66] [DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM](https://arxiv.org/abs/2512.10619)
*Qintong Zhang,Junyuan Zhang,Zhifei Ren,Linke Ouyang,Zichen Wen,Junbo Niu,Yuan Qu,Bin Wang,Ka-Ho Chow,Conghui He,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文提出DOCR-Inspector，一种基于视觉语言模型（VLM）的细粒度文档解析质量评估方法，通过28类错误类型检测与Chain-of-Checklist推理范式，在真实场景数据集DOCRcaseBench上验证其优于Gemini 2.5 Pro等主流模型，并支持解析结果优化。


<details>
  <summary>Details</summary>
Motivation: 现有基准存在数据偏差、指标粗粒度、难以反映真实场景性能等问题，亟需更可靠、细粒度的文档解析质量评估方法。

Method: 提出DOCR-Inspector框架，结合VLM-as-a-Judge范式、28类细粒度错误定义、Chain-of-Checklist推理机制，并构建训练数据集DOCRcase-200K和评测基准DOCRcaseBench（882个真实案例）。

Result: DOCR-Inspector-7B在DOCRcaseBench上超越Gemini 2.5 Pro及主流开源模型；其评估结果可有效指导解析结果优化。

Conclusion: DOCR-Inspector实现了对文档解析质量的可靠、可解释、细粒度评估，兼具实用评测价值与系统优化驱动能力，推动文档解析技术在真实场景中的落地与演进。

Abstract: Document parsing aims to transform unstructured PDF images into semi-structured data, facilitating the digitization and utilization of information in diverse domains. While vision language models (VLMs) have significantly advanced this task, achieving reliable, high-quality parsing in real-world scenarios remains challenging. Common practice often selects the top-performing model on standard benchmarks. However, these benchmarks may carry dataset-specific biases, leading to inconsistent model rankings and limited correlation with real-world performance. Moreover, benchmark metrics typically provide only overall scores, which can obscure distinct error patterns in output. This raises a key challenge: how can we reliably and comprehensively assess document parsing quality in the wild? We address this problem with DOCR-Inspector, which formalizes document parsing assessment as fine-grained error detection and analysis. Leveraging VLM-as-a-Judge, DOCR-Inspector analyzes a document image and its parsed output, identifies all errors, assigns them to one of 28 predefined types, and produces a comprehensive quality assessment. To enable this capability, we construct DOCRcase-200K for training and propose the Chain-of-Checklist reasoning paradigm to enable the hierarchical structure of parsing quality assessment. For empirical validation, we introduce DOCRcaseBench, a set of 882 real-world document parsing cases with manual annotations. On this benchmark, DOCR-Inspector-7B outperforms commercial models like Gemini 2.5 Pro, as well as leading open-source models. Further experiments demonstrate that its quality assessments provide valuable guidance for parsing results refinement, making DOCR-Inspector both a practical evaluator and a driver for advancing document parsing systems at scale. Model and code are released at: https://github.com/ZZZZZQT/DOCR-Inspector.

</details>


### [67] [K-Track: Kalman-Enhanced Tracking for Accelerating Deep Point Trackers on Edge Devices](https://arxiv.org/abs/2512.10628)
*Bishoy Galoaa,Pau Closas,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: K-Track是一种混合加速框架，结合稀疏深度学习关键帧更新与轻量卡尔曼滤波，在保持85%以上精度的同时实现5–10倍加速，适用于边缘设备上的点跟踪部署。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的点跟踪器虽精度高，但依赖逐帧GPU推理，难以在计算、功耗和连接受限的边缘设备上部署。

Method: 提出K-Track框架：在关键帧运行完整深度学习跟踪器，中间帧采用基于贝叶斯不确定性传播的轻量卡尔曼滤波进行预测；该方法是tracker-agnostic的通用加速方案。

Result: 在多个SOTA点跟踪器上验证，实现5–10倍加速且精度保持超85%；在NVIDIA Jetson Nano和RTX Titan等边缘平台上达到实时性能。

Conclusion: K-Track有效弥合了高性能跟踪算法与实际边缘部署之间的鸿沟，为资源受限场景提供了实用、高质的点跟踪解决方案。

Abstract: Point tracking in video sequences is a foundational capability for real-world computer vision applications, including robotics, autonomous systems, augmented reality, and video analysis. While recent deep learning-based trackers achieve state-of-the-art accuracy on challenging benchmarks, their reliance on per-frame GPU inference poses a major barrier to deployment on resource-constrained edge devices, where compute, power, and connectivity are limited. We introduce K-Track (Kalman-enhanced Tracking), a general-purpose, tracker-agnostic acceleration framework designed to bridge this deployment gap. K-Track reduces inference cost by combining sparse deep learning keyframe updates with lightweight Kalman filtering for intermediate frame prediction, using principled Bayesian uncertainty propagation to maintain temporal coherence. This hybrid strategy enables 5-10X speedup while retaining over 85% of the original trackers' accuracy. We evaluate K-Track across multiple state-of-the-art point trackers and demonstrate real-time performance on edge platforms such as the NVIDIA Jetson Nano and RTX Titan. By preserving accuracy while dramatically lowering computational requirements, K-Track provides a practical path toward deploying high-quality point tracking in real-world, resource-limited settings, closing the gap between modern tracking algorithms and deployable vision systems.

</details>


### [68] [TriDF: Evaluating Perception, Detection, and Hallucination for Interpretable DeepFake Detection](https://arxiv.org/abs/2512.10652)
*Jian-Yu Jiang-Lin,Kang-Yang Huang,Ling Zou,Ling Lo,Sheng-Ping Yang,Yu-Wen Tseng,Kun-Hsiang Lin,Chia-Ling Chen,Yu-Ting Ta,Yan-Tsung Wang,Po-Ching Chen,Hongxia Xie,Hong-Han Shuai,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: 本文提出了TriDF基准，用于可解释的DeepFake检测，涵盖图像、视频和音频三种模态的16种伪造类型，评估感知能力、检测性能和幻觉程度三方面。


<details>
  <summary>Details</summary>
Motivation: 生成式建模的进步使得伪造逼真人像变得容易，对安全、通信和公众信任构成严重威胁；亟需不仅能区分真假媒体、还能提供清晰可靠推理的检测系统。

Method: 构建TriDF基准，包含高质量伪造样本，覆盖16种DeepFake类型及图像、视频、音频模态；从感知（人工标注证据识别）、检测（多类伪造分类性能）和幻觉（解释可靠性）三方面进行评估。

Result: 在前沿多模态大语言模型上的实验表明：准确的感知能力对可靠检测至关重要，但幻觉会严重干扰决策，三者存在强相互依赖关系。

Conclusion: TriDF为理解检测精度、证据识别与解释可靠性之间的交互提供了统一框架，为构建应对现实合成媒体威胁的可信系统奠定基础。

Abstract: Advances in generative modeling have made it increasingly easy to fabricate realistic portrayals of individuals, creating serious risks for security, communication, and public trust. Detecting such person-driven manipulations requires systems that not only distinguish altered content from authentic media but also provide clear and reliable reasoning. In this paper, we introduce TriDF, a comprehensive benchmark for interpretable DeepFake detection. TriDF contains high-quality forgeries from advanced synthesis models, covering 16 DeepFake types across image, video, and audio modalities. The benchmark evaluates three key aspects: Perception, which measures the ability of a model to identify fine-grained manipulation artifacts using human-annotated evidence; Detection, which assesses classification performance across diverse forgery families and generators; and Hallucination, which quantifies the reliability of model-generated explanations. Experiments on state-of-the-art multimodal large language models show that accurate perception is essential for reliable detection, but hallucination can severely disrupt decision-making, revealing the interdependence of these three aspects. TriDF provides a unified framework for understanding the interaction between detection accuracy, evidence identification, and explanation reliability, offering a foundation for building trustworthy systems that address real-world synthetic media threats.

</details>


### [69] [NaviHydra: Controllable Navigation-guided End-to-end Autonomous Driving with Hydra-distillation](https://arxiv.org/abs/2512.10660)
*Hanfeng Wu,Marlon Steiner,Michael Schmidt,Alvaro Marcos-Ramiro,Christoph Stiller*

Main category: cs.CV

TL;DR: 本文提出NaviHydra，一种基于规则仿真器蒸馏而来的可控导航引导端到端模型，能有效响应高层导航指令并生成安全轨迹，在NAVSIM基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的系统在动态环境中鲁棒性不足，而端到端方法难以严格遵循显式导航指令，亟需兼顾可控性与安全性。

Method: 提出NaviHydra模型，以高层导航指令为控制信号；采用鸟瞰图（BEV）轨迹采集增强特征提取；引入新型导航合规性度量评估路径遵循程度，并设计多指令响应测试验证可控性。

Result: 在NAVSIM基准上显著超越基线模型，达到当前最优性能；导航合规性度量和可控性测试验证了其对指令的高响应精度与安全性。

Conclusion: NaviHydra成功融合规则系统的可控性与端到端模型的感知-决策能力，为自动驾驶中高可靠性、可解释的导航控制提供了新范式。

Abstract: The complexity of autonomous driving scenarios requires robust models that can interpret high-level navigation commands and generate safe trajectories. While traditional rule-based systems can react to these commands, they often struggle in dynamic environments, and end-to-end methods face challenges in complying with explicit navigation commands. To address this, we present NaviHydra, a controllable navigation-guided end-to-end model distilled from an existing rule-based simulator. Our framework accepts high-level navigation commands as control signals, generating trajectories that align with specified intentions. We utilize a Bird's Eye View (BEV) based trajectory gathering method to enhance the trajectory feature extraction. Additionally, we introduce a novel navigation compliance metric to evaluate adherence to intended route, improving controllability and navigation safety. To comprehensively assess our model's controllability, we design a test that evaluates its response to various navigation commands. Our method significantly outperforms baseline models, achieving state-of-the-art results in the NAVSIM benchmark, demonstrating its effectiveness in advancing autonomous driving.

</details>


### [70] [XDen-1K: A Density Field Dataset of Real-World Objects](https://arxiv.org/abs/2512.10668)
*Jingxuan Zhang,Tianqi Yu,Yatu Zhang,Jinze Wu,Kaixin Yao,Jingyang Liu,Yuyao Zhang,Jiayuan Gu,Jingyi Yu*

Main category: cs.CV

TL;DR: 本文提出了XDen-1K数据集，首个面向真实世界物理属性（特别是体密度）估计的大规模多模态数据集，并基于该数据集构建了从稀疏X光图像恢复高保真体密度场的优化框架，在质心估计与机器人操作等下游任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型虽擅长建模物体表面几何与外观，但忽视其内部物理属性（如体密度），而这些属性对预测质心、稳定性及交互动力学至关重要；缺乏大规模真实世界数据是主要瓶颈。

Method: 构建XDen-1K数据集（含1000个真实物体的高分辨率3D模型、部件级标注及对应双平面X光扫描），并提出一种新优化框架，从稀疏X光视图中恢复物体体密度场；进一步将X光图像作为条件信号引入分割网络以实现体积分割，并在机器人操作等下游任务中验证效果。

Result: 实验表明，利用XDen-1K可显著提升质心估计精度和机器人操作成功率。

Conclusion: XDen-1K为物理驱动的视觉推理与具身AI提供了基础性资源与新基准，有望推动相关领域发展。

Abstract: A deep understanding of the physical world is a central goal for embodied AI and realistic simulation. While current models excel at capturing an object's surface geometry and appearance, they largely neglect its internal physical properties. This omission is critical, as properties like volumetric density are fundamental for predicting an object's center of mass, stability, and interaction dynamics in applications ranging from robotic manipulation to physical simulation. The primary bottleneck has been the absence of large-scale, real-world data. To bridge this gap, we introduce XDen-1K, the first large-scale, multi-modal dataset designed for real-world physical property estimation, with a particular focus on volumetric density. The core of this dataset consists of 1,000 real-world objects across 148 categories, for which we provide comprehensive multi-modal data, including a high-resolution 3D geometric model with part-level annotations and a corresponding set of real-world biplanar X-ray scans. Building upon this data, we introduce a novel optimization framework that recovers a high-fidelity volumetric density field of each object from its sparse X-ray views. To demonstrate its practical value, we add X-ray images as a conditioning signal to an existing segmentation network and perform volumetric segmentation. Furthermore, we conduct experiments on downstream robotics tasks. The results show that leveraging the dataset can effectively improve the accuracy of center-of-mass estimation and the success rate of robotic manipulation. We believe XDen-1K will serve as a foundational resource and a challenging new benchmark, catalyzing future research in physically grounded visual inference and embodied AI.

</details>


### [71] [Geo6DPose: Fast Zero-Shot 6D Object Pose Estimation via Geometry-Filtered Feature Matching](https://arxiv.org/abs/2512.10674)
*Javier Villena Toro,Mehdi Tarkian*

Main category: cs.CV

TL;DR: 本文提出Geo6DPose，一种轻量级、完全本地化且无需训练的零样本6D物体姿态估计方法，通过结合基础模型视觉特征与几何滤波策略，在单个消费级GPU上实现亚秒级推理，同时保持与更大零样本基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大规模模型和云端推理的零样本6D姿态估计方法存在高延迟、高能耗及部署风险（如连通性、成本和数据治理问题），难以满足实际机器人系统对低功耗、本地化推理的需求。

Method: Geo6DPose利用DINO等基础模型提取模板与场景图像的视觉特征，构建相似性图；通过将场景块中心投影到3D空间、模板描述符映射至物体坐标系建立互对应关系；采用对应驱动的RANSAC恢复姿态，并以兼顾重投影一致性和空间支持的加权几何对齐度量进行排序。

Result: 在单个消费级GPU上达到1.08 FPS（亚秒级）；平均召回率（AR）达53.7，与更大规模零样本基线相当；完全无需训练、微调或网络连接。

Conclusion: Geo6DPose通过以几何可靠性替代模型规模，在保证精度的同时显著提升部署实用性，推动了面向机器人应用的完全本地化6D感知发展。

Abstract: Recent progress in zero-shot 6D object pose estimation has been driven largely by large-scale models and cloud-based inference. However, these approaches often introduce high latency, elevated energy consumption, and deployment risks related to connectivity, cost, and data governance; factors that conflict with the practical constraints of real-world robotics, where compute is limited and on-device inference is frequently required. We introduce Geo6DPose, a lightweight, fully local, and training-free pipeline for zero-shot 6D pose estimation that trades model scale for geometric reliability. Our method combines foundation model visual features with a geometric filtering strategy: Similarity maps are computed between onboarded template DINO descriptors and scene patches, and mutual correspondences are established by projecting scene patch centers to 3D and template descriptors to the object model coordinate system. Final poses are recovered via correspondence-driven RANSAC and ranked using a weighted geometric alignment metric that jointly accounts for reprojection consistency and spatial support, improving robustness to noise, clutter, and partial visibility. Geo6DPose achieves sub-second inference on a single commodity GPU while matching the average recall of significantly larger zero-shot baselines (53.7 AR, 1.08 FPS). It requires no training, fine-tuning, or network access, and remains compatible with evolving foundation backbones, advancing practical, fully local 6D perception for robotic deployment.

</details>


### [72] [Optimal transport unlocks end-to-end learning for single-molecule localization](https://arxiv.org/abs/2512.10683)
*Romain Seailles,Jean-Baptiste Masson,Jean Ponce,Julien Mairal*

Main category: cs.CV

TL;DR: 本文提出了一种基于最优传输损失和迭代神经网络的新方法，用于单分子定位显微镜（SMLM），避免了传统非极大值抑制（NMS）带来的不可微分与漏检问题，显著提升了高密度荧光分子下的定位精度与端到端训练能力。


<details>
  <summary>Details</summary>
Motivation: 现有SMLM方法依赖非重叠荧光分子，导致成像时间长；深度学习方法虽能处理更高密度，但其使用的NMS层不可微分，易丢弃真实信号。

Method: 将SMLM建模为集合匹配问题，设计基于最优传输的可微损失函数，并构建融合显微镜光学先验的迭代神经网络架构。

Result: 在合成数据集和真实生物数据上，新损失函数与网络架构在中高密度下均超越当前最优方法。

Conclusion: 所提方法实现了无需NMS的端到端训练，提高了定位鲁棒性与精度，推动了活细胞超分辨成像的发展。

Abstract: Single-molecule localization microscopy (SMLM) allows reconstructing biology-relevant structures beyond the diffraction limit by detecting and localizing individual fluorophores -- fluorescent molecules stained onto the observed specimen -- over time to reconstruct super-resolved images. Currently, efficient SMLM requires non-overlapping emitting fluorophores, leading to long acquisition times that hinders live-cell imaging. Recent deep-learning approaches can handle denser emissions, but they rely on variants of non-maximum suppression (NMS) layers, which are unfortunately non-differentiable and may discard true positives with their local fusion strategy. In this presentation, we reformulate the SMLM training objective as a set-matching problem, deriving an optimal-transport loss that eliminates the need for NMS during inference and enables end-to-end training. Additionally, we propose an iterative neural network that integrates knowledge of the microscope's optical system inside our model. Experiments on synthetic benchmarks and real biological data show that both our new loss function and architecture surpass the state of the art at moderate and high emitter densities. Code is available at https://github.com/RSLLES/SHOT.

</details>


### [73] [Sharp Monocular View Synthesis in Less Than a Second](https://arxiv.org/abs/2512.10685)
*Lars Mescheder,Wei Dong,Shiwei Li,Xuyang Bai,Marcel Santos,Peiyun Hu,Bruno Lecouat,Mingmin Zhen,Amaël Delaunoy,Tian Fang,Yanghai Tsin,Stephan R. Richter,Vladlen Koltun*

Main category: cs.CV

TL;DR: SHARP is a fast, single-image photorealistic view synthesis method that regresses a metric 3D Gaussian scene representation in under a second, enabling real-time rendering and achieving state-of-the-art quality and speed.


<details>
  <summary>Details</summary>
Motivation: To enable fast, high-quality, metric-aware photorealistic view synthesis from a single image without requiring multi-view inputs or slow optimization.

Method: SHARP uses a neural network to regress parameters of a metric 3D Gaussian representation directly from a single input image via a single feedforward pass; the resulting representation is rendered in real time using differentiable rasterization.

Result: SHARP achieves state-of-the-art performance: 25–34% lower LPIPS and 21–43% lower DISTS than prior best methods, with ~1000× faster synthesis time; it generalizes zero-shot across datasets and supports absolute-scale camera motion.

Conclusion: SHARP demonstrates that high-fidelity, metric, real-time novel view synthesis is feasible from a single image, bridging efficiency and photorealism in a scalable, practical framework.

Abstract: We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. This is done in less than a second on a standard GPU via a single feedforward pass through a neural network. The 3D Gaussian representation produced by SHARP can then be rendered in real time, yielding high-resolution photorealistic images for nearby views. The representation is metric, with absolute scale, supporting metric camera movements. Experimental results demonstrate that SHARP delivers robust zero-shot generalization across datasets. It sets a new state of the art on multiple datasets, reducing LPIPS by 25-34% and DISTS by 21-43% versus the best prior model, while lowering the synthesis time by three orders of magnitude. Code and weights are provided at https://github.com/apple/ml-sharp

</details>


### [74] [CheXmask-U: Quantifying uncertainty in landmark-based anatomical segmentation for X-ray images](https://arxiv.org/abs/2512.10715)
*Matias Cosarinsky,Nicolas Gaggion,Rodrigo Echeveste,Enzo Ferrante*

Main category: cs.CV

TL;DR: 本文提出了一种针对胸部X光片解剖标志点分割的不确定性估计方法，利用混合神经网络架构（卷积编码器+图生成解码器）的变分潜在空间，推导出潜在不确定性和预测不确定性两种互补度量，并在CheXmask-U数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 不确定性估计对医学图像分割系统的临床安全部署至关重要，而基于标志点的分割虽具拓扑保证，但其不确定性研究仍不足。

Method: 基于结合卷积编码器与图生成解码器的混合神经网络架构，利用其变分潜在空间，推导出两种不确定性度量：(i) 从学习到的分布参数直接获取的潜在不确定性；(ii) 通过对潜在样本进行多次随机采样生成输出所得的预测不确定性。

Result: 实验表明两种不确定性均随图像扰动程度增加而上升，能有效识别不可靠预测、支持域外检测，并发布了含65.7万例带节点级不确定性标注的大规模CheXmask-U数据集。

Conclusion: 不确定性估计是提升胸部X光片标志点分割鲁棒性与临床安全部署潜力的重要方向。

Abstract: Uncertainty estimation is essential for the safe clinical deployment of medical image segmentation systems, enabling the identification of unreliable predictions and supporting human oversight. While prior work has largely focused on pixel-level uncertainty, landmark-based segmentation offers inherent topological guarantees yet remains underexplored from an uncertainty perspective. In this work, we study uncertainty estimation for anatomical landmark-based segmentation on chest X-rays. Inspired by hybrid neural network architectures that combine standard image convolutional encoders with graph-based generative decoders, and leveraging their variational latent space, we derive two complementary measures: (i) latent uncertainty, captured directly from the learned distribution parameters, and (ii) predictive uncertainty, obtained by generating multiple stochastic output predictions from latent samples. Through controlled corruption experiments we show that both uncertainty measures increase with perturbation severity, reflecting both global and local degradation. We demonstrate that these uncertainty signals can identify unreliable predictions by comparing with manual ground-truth, and support out-of-distribution detection on the CheXmask dataset. More importantly, we release CheXmask-U (huggingface.co/datasets/mcosarinsky/CheXmask-U), a large scale dataset of 657,566 chest X-ray landmark segmentations with per-node uncertainty estimates, enabling researchers to account for spatial variations in segmentation quality when using these anatomical masks. Our findings establish uncertainty estimation as a promising direction to enhance robustness and safe deployment of landmark-based anatomical segmentation methods in chest X-ray. A fully working interactive demo of the method is available at huggingface.co/spaces/matiasky/CheXmask-U and the source code at github.com/mcosarinsky/CheXmask-U.

</details>


### [75] [SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving](https://arxiv.org/abs/2512.10719)
*Peizheng Li,Zhenghao Zhang,David Holtz,Hang Yu,Yutong Yang,Yuzhi Lai,Rui Song,Andreas Geiger,Andreas Zell*

Main category: cs.CV

TL;DR: 本文提出SpaceDrive，一种空间感知的视觉语言模型（VLM）驱动框架，通过将3D空间信息显式编码为位置编码（PEs）而非数字文本标记，提升VLM对细粒度3D空间关系的理解能力，从而增强端到端自动驾驶的规划精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的端到端自动驾驶方法难以理解细粒度的3D空间关系，而这是与物理世界交互的基础需求。

Method: 提出SpaceDrive框架，引入通用位置编码器，将多视角深度估计、历史自车状态和文本提示中的3D坐标统一编码为3D位置编码（PEs）；这些PEs既用于增强2D视觉token，又作为任务无关的坐标表示，替代数字token作为VLM的输入和输出，实现语义与空间联合推理及轨迹坐标的直接回归。

Result: 在nuScenes数据集上达到开环性能SOTA，在Bench2Drive闭环基准中取得78.02的驾驶得分，位居VLM类方法第二。

Conclusion: 显式建模3D空间信息为位置编码可有效弥补VLM在空间理解上的不足，显著提升端到端自动驾驶系统的规划准确性与整体性能。

Abstract: End-to-end autonomous driving methods built on vision language models (VLMs) have undergone rapid development driven by their universal visual understanding and strong reasoning capabilities obtained from the large-scale pretraining. However, we find that current VLMs struggle to understand fine-grained 3D spatial relationships which is a fundamental requirement for systems interacting with the physical world. To address this issue, we propose SpaceDrive, a spatial-aware VLM-based driving framework that treats spatial information as explicit positional encodings (PEs) instead of textual digit tokens, enabling joint reasoning over semantic and spatial representations. SpaceDrive employs a universal positional encoder to all 3D coordinates derived from multi-view depth estimation, historical ego-states, and text prompts. These 3D PEs are first superimposed to augment the corresponding 2D visual tokens. Meanwhile, they serve as a task-agnostic coordinate representation, replacing the digit-wise numerical tokens as both inputs and outputs for the VLM. This mechanism enables the model to better index specific visual semantics in spatial reasoning and directly regress trajectory coordinates rather than generating digit-by-digit, thereby enhancing planning accuracy. Extensive experiments validate that SpaceDrive achieves state-of-the-art open-loop performance on the nuScenes dataset and the second-best Driving Score of 78.02 on the Bench2Drive closed-loop benchmark over existing VLM-based methods.

</details>


### [76] [Video Depth Propagation](https://arxiv.org/abs/2512.10725)
*Luigi Piccinelli,Thiemo Wandel,Christos Sakaridis,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: VeloDepth是一种高效、鲁棒的在线视频深度估计方法，通过引入基于光流的特征传播与残差校正模块，在保证高时间一致性和精度的同时实现快速推理。


<details>
  <summary>Details</summary>
Motivation: 现有视频深度估计方法要么仅逐帧处理导致时间不一致，要么依赖计算开销大的时序建模，难以兼顾实时性与性能。

Method: 提出VeloDepth框架，包含一个新颖的传播模块：利用光流进行深度特征扭曲，并结合学习到的残差修正；结构上强制时间一致性。

Result: 在多个基准上零样本评估显示，VeloDepth达到最先进的时序一致性、具有竞争力的精度，且推理速度显著快于现有视频深度估计算法。

Conclusion: VeloDepth为实时深度估计提供了实用、高效且准确的解决方案，适用于多样化的感知任务。

Abstract: Depth estimation in videos is essential for visual perception in real-world applications. However, existing methods either rely on simple frame-by-frame monocular models, leading to temporal inconsistencies and inaccuracies, or use computationally demanding temporal modeling, unsuitable for real-time applications. These limitations significantly restrict general applicability and performance in practical settings. To address this, we propose VeloDepth, an efficient and robust online video depth estimation pipeline that effectively leverages spatiotemporal priors from previous depth predictions and performs deep feature propagation. Our method introduces a novel Propagation Module that refines and propagates depth features and predictions using flow-based warping coupled with learned residual corrections. In addition, our design structurally enforces temporal consistency, resulting in stable depth predictions across consecutive frames with improved efficiency. Comprehensive zero-shot evaluation on multiple benchmarks demonstrates the state-of-the-art temporal consistency and competitive accuracy of VeloDepth, alongside its significantly faster inference compared to existing video-based depth estimators. VeloDepth thus provides a practical, efficient, and accurate solution for real-time depth estimation suitable for diverse perception tasks. Code and models are available at https://github.com/lpiccinelli-eth/velodepth

</details>


### [77] [IRG-MotionLLM: Interleaving Motion Generation, Assessment and Refinement for Text-to-Motion Generation](https://arxiv.org/abs/2512.10730)
*Yuan-Ming Li,Qize Yang,Nan Lei,Shenghao Fu,Ling-An Zeng,Jian-Fang Hu,Xihan Wei,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为IRMoGen的新范式，通过文本-动作对话迭代耦合动作生成、评估与精炼，构建首个支持该范式的模型IRG-MotionLLM，并设计三阶段训练策略和自动化数据引擎，在文本到动作生成任务中显著提升对齐性能与生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有动作感知大语言模型将理解与生成任务分离，无法利用二者间的交互反馈；作者发现动作评估与精炼可作为理解与生成之间的关键桥梁，从而激发双向知识流动。

Method: 提出IRMoGen范式，构建IRG-MotionLLM模型，采用三阶段渐进式训练策略，并开发自动化数据引擎，从现有文本-动作数据集中合成交错推理标注。

Result: 实验表明：（i）评估与精炼任务显著提升文本-动作对齐；（ii）交错执行生成、评估、精炼持续提升各训练阶段性能；（iii）IRG-MotionLLM在标准文本到动作生成基准上明显优于基线模型。

Conclusion: 动作生成、评估与精炼的交错推理是提升运动语言模型性能的有效路径，IRMoGen范式为统一运动理解与生成提供了新思路。

Abstract: Recent advances in motion-aware large language models have shown remarkable promise for unifying motion understanding and generation tasks. However, these models typically treat understanding and generation separately, limiting the mutual benefits that could arise from interactive feedback between tasks. In this work, we reveal that motion assessment and refinement tasks act as crucial bridges to enable bidirectional knowledge flow between understanding and generation. Leveraging this insight, we propose Interleaved Reasoning for Motion Generation (IRMoGen), a novel paradigm that tightly couples motion generation with assessment and refinement through iterative text-motion dialogue. To realize this, we introduce IRG-MotionLLM, the first model that seamlessly interleaves motion generation, assessment, and refinement to improve generation performance. IRG-MotionLLM is developed progressively with a novel three-stage training scheme, initializing and subsequently enhancing native IRMoGen capabilities. To facilitate this development, we construct an automated data engine to synthesize interleaved reasoning annotations from existing text-motion datasets. Extensive experiments demonstrate that: (i) Assessment and refinement tasks significantly improve text-motion alignment; (ii) Interleaving motion generation, assessment, and refinement steps yields consistent performance gains across training stages; and (iii) IRG-MotionLLM clearly outperforms the baseline model and achieves advanced performance on standard text-to-motion generation benchmarks. Cross-evaluator testing further validates its effectiveness. Code & Data: https://github.com/HumanMLLM/IRG-MotionLLM/tree/main.

</details>


### [78] [LDP: Parameter-Efficient Fine-Tuning of Multimodal LLM for Medical Report Generation](https://arxiv.org/abs/2512.10750)
*Tianyu Zhou,Junyi Tang,Zehui Li,Dahong Qian,Suncheng Xiang*

Main category: cs.CV

TL;DR: 本文提出LDP框架，利用多模态大语言模型（MLLMs）生成专业息肉诊断报告，通过构建MMEndo数据集并采用LoRA与DPO方法微调Qwen2-VL-7B模型，在自动指标和临床专家评估中均显著优于基线方法，且大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统自动化结肠镜息肉诊断报告存在不一致性和幻觉问题，主要源于高质量多模态医学数据稀缺。

Method: 构建专家标注的多模态结肠镜图像-文本数据集MMEndo；基于Qwen2-VL-7B模型，采用参数高效微调（LoRA）和直接偏好优化（DPO）对齐临床标准。

Result: LDP在自动评估指标和临床专家评分（医师评分为7.2/10）上均超越现有基线，训练计算成本比全量微调降低833倍，并在IU-XRay数据集上验证了泛化鲁棒性。

Conclusion: LDP为基层医疗提供了可扩展、临床可行的息肉诊断报告生成方案，推动多模态AI在消化内镜领域的实际落地。

Abstract: Colonoscopic polyp diagnosis is pivotal for early colorectal cancer detection, yet traditional automated reporting suffers from inconsistencies and hallucinations due to the scarcity of high-quality multimodal medical data. To bridge this gap, we propose LDP, a novel framework leveraging multimodal large language models (MLLMs) for professional polyp diagnosis report generation. Specifically, we curate MMEndo, a multimodal endoscopic dataset comprising expert-annotated colonoscopy image-text pairs. We fine-tune the Qwen2-VL-7B backbone using Parameter-Efficient Fine-Tuning (LoRA) and align it with clinical standards via Direct Preference Optimization (DPO). Extensive experiments show that our LDP outperforms existing baselines on both automated metrics and rigorous clinical expert evaluations (achieving a Physician Score of 7.2/10), significantly reducing training computational costs by 833x compared to full fine-tuning. The proposed solution offers a scalable, clinically viable path for primary healthcare, with additional validation on the IU-XRay dataset confirming its robustness.

</details>


### [79] [Blood Pressure Prediction for Coronary Artery Disease Diagnosis using Coronary Computed Tomography Angiography](https://arxiv.org/abs/2512.10765)
*Rene Lisasi,Michele Esposito,Chen Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的自动化流程，结合冠状动脉CT血管造影（CCTA）与扩散模型，绕过耗时的传统CFD仿真，直接预测冠状动脉血压分布，提升CAD无创诊断的可扩展性与临床适用性。


<details>
  <summary>Details</summary>
Motivation: 传统CFD仿真计算成本高、耗时长，难以融入大规模临床流程，导致标注血流动力学数据稀缺，限制AI模型训练和无创CAD评估的普及。

Method: 构建自动化管道：从CCTA中提取冠状动脉几何结构、生成仿真数据，并引入基于扩散的回归模型，直接从CCTA特征预测冠状动脉血压分布。

Result: 在模拟冠状动脉血流动力学数据集上，模型R²达64.42%，RMSE为0.0974，归一化RMSE为0.154，性能优于多个基线方法。

Conclusion: 该框架实现了快速、无创、可扩展的冠状动脉血压预测，有望推动生理学驱动的CAD临床诊断落地。

Abstract: Computational fluid dynamics (CFD) based simulation of coronary blood flow provides valuable hemodynamic markers, such as pressure gradients, for diagnosing coronary artery disease (CAD). However, CFD is computationally expensive, time-consuming, and difficult to integrate into large-scale clinical workflows. These limitations restrict the availability of labeled hemodynamic data for training AI models and hinder broad adoption of non-invasive, physiology based CAD assessment. To address these challenges, we develop an end to end pipeline that automates coronary geometry extraction from coronary computed tomography angiography (CCTA), streamlines simulation data generation, and enables efficient learning of coronary blood pressure distributions. The pipeline reduces the manual burden associated with traditional CFD workflows while producing consistent training data. We further introduce a diffusion-based regression model designed to predict coronary blood pressure directly from CCTA derived features, bypassing the need for slow CFD computation during inference. Evaluated on a dataset of simulated coronary hemodynamics, the proposed model achieves state of the art performance, with an R2 of 64.42%, a root mean squared error of 0.0974, and a normalized RMSE of 0.154, outperforming several baseline approaches. This work provides a scalable and accessible framework for rapid, non-invasive blood pressure prediction to support CAD diagnosis.

</details>


### [80] [Graph Laplacian Transformer with Progressive Sampling for Prostate Cancer Grading](https://arxiv.org/abs/2512.10808)
*Masum Shah Junayed,John Derek Van Vessem,Qian Wan,Gahie Nam,Sheida Nabavi*

Main category: cs.CV

TL;DR: 本文提出了一种结合图拉普拉斯注意力机制与迭代优化模块的Transformer模型（GLAT-IRM），用于前列腺癌全切片图像（WSI）分级，通过动态选择关键组织区域、建模空间关系并加权聚合，显著提升分级性能与空间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖随机或静态图像块选择，易引入冗余或无关区域，难以应对WSI尺度大、组织异质性强、关键区域难定位等挑战。

Method: 提出GLAT-IRM框架：1）迭代精炼模块（IRM）利用ResNet50提取局部特征、冻结基础模型打分，动态筛选高价值图像块；2）图拉普拉斯注意力Transformer（GLAT）将图像块建模为图节点，引入图拉普拉斯正则化保障空间一致性，并通过可学习滤波增强判别性组织结构；3）凸聚和机制动态加权聚合生成WSI级表示。

Result: 在五个公开及一个私有数据集上全面超越SOTA方法，在分级准确率与空间一致性方面均取得更优结果，同时保持计算高效性。

Conclusion: GLAT-IRM有效解决了WSI分级中关键区域选择偏差与空间上下文建模不足的问题，验证了图结构建模与迭代精炼协同对病理图像分析的重要性。

Abstract: Prostate cancer grading from whole-slide images (WSIs) remains a challenging task due to the large-scale nature of WSIs, the presence of heterogeneous tissue structures, and difficulty of selecting diagnostically relevant regions. Existing approaches often rely on random or static patch selection, leading to the inclusion of redundant or non-informative regions that degrade performance. To address this, we propose a Graph Laplacian Attention-Based Transformer (GLAT) integrated with an Iterative Refinement Module (IRM) to enhance both feature learning and spatial consistency. The IRM iteratively refines patch selection by leveraging a pretrained ResNet50 for local feature extraction and a foundation model in no-gradient mode for importance scoring, ensuring only the most relevant tissue regions are preserved. The GLAT models tissue-level connectivity by constructing a graph where patches serve as nodes, ensuring spatial consistency through graph Laplacian constraints and refining feature representations via a learnable filtering mechanism that enhances discriminative histological structures. Additionally, a convex aggregation mechanism dynamically adjusts patch importance to generate a robust WSI-level representation. Extensive experiments on five public and one private dataset demonstrate that our model outperforms state-of-the-art methods, achieving higher performance and spatial consistency while maintaining computational efficiency.

</details>


### [81] [Self-Ensemble Post Learning for Noisy Domain Generalization](https://arxiv.org/abs/2512.10818)
*Wang Lu,Jindong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Self-Ensemble Post Learning (SEPL) 的新方法，用于提升域泛化（DG）在标签噪声下的鲁棒性。SEPL通过特征探测训练和预测集成推理，利用模型中间层的多样化特征，并结合半监督学习与众包推理策略，显著提升了现有方法在噪声环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有域泛化方法在面对标签噪声时易放大虚假特征，导致性能下降；需探索如何使DG方法在噪声下仍保持稳健。

Method: 提出SEPL框架，包含两部分：1）基于中间层特征的多探针分类器训练（采用半监督算法应对噪声）；2）采用众包推理方式融合多个探针分类器的预测结果。

Result: 实验表明SEPL能有效提升现有DG方法在噪声标签下的鲁棒性，且具备高灵活性和实际应用潜力。

Conclusion: 利用模型内部判别性、多样化的中间特征并结合半监督与集成推理，是提升域泛化在噪声环境下性能的有效路径。

Abstract: While computer vision and machine learning have made great progress, their robustness is still challenged by two key issues: data distribution shift and label noise. When domain generalization (DG) encounters noise, noisy labels further exacerbate the emergence of spurious features in deep layers, i.e. spurious feature enlargement, leading to a degradation in the performance of existing algorithms. This paper, starting from domain generalization, explores how to make existing methods rework when meeting noise. We find that the latent features inside the model have certain discriminative capabilities, and different latent features focus on different parts of the image. Based on these observations, we propose the Self-Ensemble Post Learning approach (SEPL) to diversify features which can be leveraged. Specifically, SEPL consists of two parts: feature probing training and prediction ensemble inference. It leverages intermediate feature representations within the model architecture, training multiple probing classifiers to fully exploit the capabilities of pre-trained models, while the final predictions are obtained through the integration of outputs from these diverse classification heads. Considering the presence of noisy labels, we employ semi-supervised algorithms to train probing classifiers. Given that different probing classifiers focus on different areas, we integrate their predictions using a crowdsourcing inference approach. Extensive experimental evaluations demonstrate that the proposed method not only enhances the robustness of existing methods but also exhibits significant potential for real-world applications with high flexibility.

</details>


### [82] [PoseGAM: Robust Unseen Object Pose Estimation via Geometry-Aware Multi-View Reasoning](https://arxiv.org/abs/2512.10840)
*Jianqi Chen,Biao Zhang,Xiangjun Tang,Peter Wonka*

Main category: cs.CV

TL;DR: 本文提出PoseGAM，一种无需显式特征匹配的几何感知多视角框架，用于提升6D物体姿态估计在未见物体上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 6D物体姿态估计在未见物体上仍具挑战性，现有方法依赖显式构建查询图像与物体模型或模板图像之间的特征对应关系。

Method: PoseGAM基于多视角基础模型架构，融合显式的点云几何信息和几何表征网络学习到的特征；并构建了包含19万多个物体的大规模合成数据集以增强鲁棒性与泛化性。

Result: 在多个基准测试中达到SOTA性能，平均AR提升5.1%，单个数据集最高提升达17.6%。

Conclusion: PoseGAM有效提升了对未见物体的姿态估计泛化能力，验证了几何感知多视角建模的有效性。

Abstract: 6D object pose estimation, which predicts the transformation of an object relative to the camera, remains challenging for unseen objects. Existing approaches typically rely on explicitly constructing feature correspondences between the query image and either the object model or template images. In this work, we propose PoseGAM, a geometry-aware multi-view framework that directly predicts object pose from a query image and multiple template images, eliminating the need for explicit matching. Built upon recent multi-view-based foundation model architectures, the method integrates object geometry information through two complementary mechanisms: explicit point-based geometry and learned features from geometry representation networks. In addition, we construct a large-scale synthetic dataset containing more than 190k objects under diverse environmental conditions to enhance robustness and generalization. Extensive evaluations across multiple benchmarks demonstrate our state-of-the-art performance, yielding an average AR improvement of 5.1% over prior methods and achieving up to 17.6% gains on individual datasets, indicating strong generalization to unseen objects. Project page: https://windvchen.github.io/PoseGAM/ .

</details>


### [83] [SWiT-4D: Sliding-Window Transformer for Lossless and Parameter-Free Temporal 4D Generation](https://arxiv.org/abs/2512.10860)
*Kehong Gong,Zhengyu Wen,Mingxi Xu,Weixia He,Qi Wang,Ning Zhang,Zhengyu Li,Chenbin Li,Dongze Lian,Wei Zhao,Xiaoyu He,Mingyuan Zhang*

Main category: cs.CV

TL;DR: 本文提出SWiT-4D，一种无需额外参数、基于滑动窗口Transformer的视频到4D网格生成方法，可无缝集成任意DiT图像到3D生成器，在极少量（<10秒）4D监督下实现高质量、时序一致的4D网格重建。


<details>
  <summary>Details</summary>
Motivation: 单目视频转高质量显式4D网格仍具挑战性，且缺乏大规模真实4D网格数据集；而图像到3D生成已有强先验模型，亟需在减少4D监督依赖前提下有效利用该先验。

Method: 提出SWiT-4D——一种滑动窗口Transformer架构，实现无损、免参数的时序建模；无缝嵌入DiT图像到3D生成器，保持单图前向过程；引入优化驱动的轨迹模块恢复全局平移（适配静态相机单目视频）。

Result: 仅用单个短（<10秒）视频微调，即可实现高保真几何与稳定时序一致性；在域内zoo-test及跨域基准（C4D、Objaverse、野外视频）上，时序平滑性均显著优于现有方法。

Conclusion: SWiT-4D是一种高效、轻量、即插即用的视频到4D网格生成框架，在极低4D监督下展现出强泛化性与实用部署潜力。

Abstract: Despite significant progress in 4D content generation, the conversion of monocular videos into high-quality animated 3D assets with explicit 4D meshes remains considerably challenging. The scarcity of large-scale, naturally captured 4D mesh datasets further limits the ability to train generalizable video-to-4D models from scratch in a purely data-driven manner. Meanwhile, advances in image-to-3D generation, supported by extensive datasets, offer powerful prior models that can be leveraged. To better utilize these priors while minimizing reliance on 4D supervision, we introduce SWiT-4D, a Sliding-Window Transformer for lossless, parameter-free temporal 4D mesh generation. SWiT-4D integrates seamlessly with any Diffusion Transformer (DiT)-based image-to-3D generator, adding spatial-temporal modeling across video frames while preserving the original single-image forward process, enabling 4D mesh reconstruction from videos of arbitrary length. To recover global translation, we further introduce an optimization-based trajectory module tailored for static-camera monocular videos. SWiT-4D demonstrates strong data efficiency: with only a single short (<10s) video for fine-tuning, it achieves high-fidelity geometry and stable temporal consistency, indicating practical deployability under extremely limited 4D supervision. Comprehensive experiments on both in-domain zoo-test sets and challenging out-of-domain benchmarks (C4D, Objaverse, and in-the-wild videos) show that SWiT-4D consistently outperforms existing baselines in temporal smoothness. Project page: https://animotionlab.github.io/SWIT4D/

</details>


### [84] [MMSI-Video-Bench: A Holistic Benchmark for Video-Based Spatial Intelligence](https://arxiv.org/abs/2512.10863)
*Jingli Lin,Runsen Xu,Shaohao Zhu,Sihan Yang,Peizhou Cao,Yunlong Ran,Miao Hu,Chenming Zhu,Yiman Xie,Yilin Long,Wenbo Hu,Dahua Lin,Tai Wang,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 本文提出了MMSI-Video-Bench，一个面向多模态大语言模型（MLLMs）视频空间智能的全新、全人工标注基准，涵盖感知、规划、预测与跨视频推理四个层级，共1106个问题；评估25个主流MLLM发现显著人机差距，现有方法在几何推理、运动定位、长时序预测和跨视频对应等方面存在系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏全面评估MLLM在连续视觉输入中空间理解能力的综合基准，阻碍了其向物理环境通用助手的发展。

Method: 构建了MMSI-Video-Bench基准，包含四层空间智能框架（感知、规划、预测、跨视频推理），基于1278个视频片段（来自25个数据集及自采视频）设计1106道人工标注题目，并由3DV专家审核并提供解释性理由；同时定义三个领域子基准；对25个开源与闭源MLLM进行系统评测，并开展细粒度错误分析与消融实验（如帧采样、3D线索、思维链提示等）。

Result: 评估显示：多数模型表现接近随机水平，最优推理模型仍比人类低近60%；空间微调模型泛化能力差；典型帧采样策略效果不佳；引入3D空间线索或思维链提示均未带来实质性提升；系统性失败集中于几何推理、运动接地、长时序预测和跨视频对应。

Conclusion: MMSI-Video-Bench为视频空间智能提供了首个全面、严谨、可复现的评测平台，揭示了当前MLLM在空间理解上的根本局限，有望推动该方向的实质性进展。

Abstract: Spatial understanding over continuous visual input is crucial for MLLMs to evolve into general-purpose assistants in physical environments. Yet there is still no comprehensive benchmark that holistically assesses the progress toward this goal. In this work, we introduce MMSI-Video-Bench, a fully human-annotated benchmark for video-based spatial intelligence in MLLMs. It operationalizes a four-level framework, Perception, Planning, Prediction, and Cross-Video Reasoning, through 1,106 questions grounded in 1,278 clips from 25 datasets and in-house videos. Each item is carefully designed and reviewed by 3DV experts with explanatory rationales to ensure precise, unambiguous grounding. Leveraging its diverse data sources and holistic task coverage, MMSI-Video-Bench also supports three domain-oriented sub-benchmarks (Indoor Scene Perception Bench, Robot Bench and Grounding Bench) for targeted capability assessment. We evaluate 25 strong open-source and proprietary MLLMs, revealing a striking human--AI gap: many models perform near chance, and the best reasoning model lags humans by nearly 60%. We further find that spatially fine-tuned models still fail to generalize effectively on our benchmark. Fine-grained error analysis exposes systematic failures in geometric reasoning, motion grounding, long-horizon prediction, and cross-video correspondence. We also show that typical frame-sampling strategies transfer poorly to our reasoning-intensive benchmark, and that neither 3D spatial cues nor chain-of-thought prompting yields meaningful gains. We expect our benchmark to establish a solid testbed for advancing video-based spatial intelligence.

</details>


### [85] [From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models](https://arxiv.org/abs/2512.10867)
*Zongzhao Li,Xiangzhe Kong,Jiahui Su,Zongyang Ma,Mingze Li,Songyou Li,Yuelin Zhang,Yu Rong,Tingyang Xu,Deli Zhao,Wenbing Huang*

Main category: cs.CV

TL;DR: 本文提出了微观空间智能（MiSI）的概念，并构建了MiSI-Bench基准来评估视觉语言模型（VLMs）在该领域的能力，发现当前VLMs整体表现远低于人类水平，但经微调的小型模型在部分任务上可超越人类，强调需融合显式领域知识以推动科学AGI发展。


<details>
  <summary>Details</summary>
Motivation: 评估视觉语言模型在微观空间智能（MiSI）这一对科学发现至关重要的能力上的表现，并填补相关系统性基准的空白。

Method: 提出MiSI-Bench基准框架，包含16.3万问答对和58.7万图像，源自约4000个分子结构，涵盖九类互补任务；对多种VLM进行评测，并对一个7B模型进行微调分析。

Result: 当前SOTA VLM在MiSI-Bench上显著低于人类水平；微调后的7B模型在空间变换任务上超越人类，但在氢键识别等科学基础任务上表现较差。

Conclusion: 仅靠数据驱动的VLM难以胜任微观空间推理，需引入显式科学领域知识，方能向科学通用人工智能（scientific AGI）迈进。

Abstract: This paper introduces the concept of Microscopic Spatial Intelligence (MiSI), the capability to perceive and reason about the spatial relationships of invisible microscopic entities, which is fundamental to scientific discovery. To assess the potential of Vision-Language Models (VLMs) in this domain, we propose a systematic benchmark framework MiSI-Bench. This framework features over 163,000 question-answer pairs and 587,000 images derived from approximately 4,000 molecular structures, covering nine complementary tasks that evaluate abilities ranging from elementary spatial transformations to complex relational identifications. Experimental results reveal that current state-of-the-art VLMs perform significantly below human level on this benchmark. However, a fine-tuned 7B model demonstrates substantial potential, even surpassing humans in spatial transformation tasks, while its poor performance in scientifically-grounded tasks like hydrogen bond recognition underscores the necessity of integrating explicit domain knowledge for progress toward scientific AGI. The datasets are available at https://huggingface.co/datasets/zongzhao/MiSI-bench.

</details>


### [86] [MoCapAnything: Unified 3D Motion Capture for Arbitrary Skeletons from Monocular Videos](https://arxiv.org/abs/2512.10881)
*Kehong Gong,Zhengyu Wen,Weixia He,Mingxi Xu,Qi Wang,Ning Zhang,Zhengyu Li,Dongze Lian,Wei Zhao,Xiaoyu He,Mingyuan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种类别无关的运动捕捉方法CAMoCap，通过MoCapAnything框架实现任意 rigged 3D 资产在单目视频下的高质量、旋转驱动的动画重建。


<details>
  <summary>Details</summary>
Motivation: 现有运动捕捉流程大多局限于特定物种或模板，缺乏对任意3D资产的泛化能力，难以满足内容创作日益增长的灵活性需求。

Method: 提出MoCapAnything：一个参考引导、因子分解的框架，包含参考提示编码器、视频特征提取器和统一运动解码器三个可学习模块，结合轻量级约束感知逆向运动学（IK）阶段，先预测3D关节轨迹再恢复资产特异性旋转。

Result: 在域内基准与真实世界视频上均取得高质量骨骼动画；支持跨物种、异构绑定骨架的有效重定向；并发布包含1038段标准化三元组（骨架-网格-渲染图）的数据集Truebones Zoo。

Conclusion: MoCapAnything实现了真正类别无关、提示驱动的运动捕捉，为任意3D资产提供了可扩展、灵活且实用的单目运动重建方案。

Abstract: Motion capture now underpins content creation far beyond digital humans, yet most existing pipelines remain species- or template-specific. We formalize this gap as Category-Agnostic Motion Capture (CAMoCap): given a monocular video and an arbitrary rigged 3D asset as a prompt, the goal is to reconstruct a rotation-based animation such as BVH that directly drives the specific asset. We present MoCapAnything, a reference-guided, factorized framework that first predicts 3D joint trajectories and then recovers asset-specific rotations via constraint-aware inverse kinematics. The system contains three learnable modules and a lightweight IK stage: (1) a Reference Prompt Encoder that extracts per-joint queries from the asset's skeleton, mesh, and rendered images; (2) a Video Feature Extractor that computes dense visual descriptors and reconstructs a coarse 4D deforming mesh to bridge the gap between video and joint space; and (3) a Unified Motion Decoder that fuses these cues to produce temporally coherent trajectories. We also curate Truebones Zoo with 1038 motion clips, each providing a standardized skeleton-mesh-render triad. Experiments on both in-domain benchmarks and in-the-wild videos show that MoCapAnything delivers high-quality skeletal animations and exhibits meaningful cross-species retargeting across heterogeneous rigs, enabling scalable, prompt-driven 3D motion capture for arbitrary assets. Project page: https://animotionlab.github.io/MoCapAnything/

</details>


### [87] [PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction](https://arxiv.org/abs/2512.10888)
*Brandon Smock,Valerie Faucon-Morin,Max Sokolov,Libin Liang,Tayyibah Khanam,Maury Courtland*

Main category: cs.CV

TL;DR: 本文介绍了PubTables-v2数据集，用于多页表格结构识别，并提出了Page-Object Table Transformer (POTATR)模型以实现全面的页面级表格提取。


<details>
  <summary>Details</summary>
Motivation: 现有表格提取方法受限于缺乏大规模标注数据，尤其是多页表格结构识别任务缺乏基准数据集。

Method: 构建了大规模多页表格数据集PubTables-v2，并基于Table Transformer提出图像到图的扩展模型POTATR，用于页面级表格提取。

Result: PubTables-v2成为首个支持多页表格结构识别的大规模基准；POTATR在多个表格提取任务上验证了有效性。

Conclusion: PubTables-v2填补了多页表格识别数据集空白，POTATR为页面级表格提取提供了新思路，推动视觉文档理解发展。

Abstract: Table extraction (TE) is a key challenge in visual document understanding. Traditional approaches detect tables first, then recognize their structure. Recently, interest has surged in developing methods, such as vision-language models (VLMs), that can extract tables directly in their full page or document context. However, progress has been difficult to demonstrate due to a lack of annotated data. To address this, we create a new large-scale dataset, PubTables-v2. PubTables-v2 supports a number of current challenging table extraction tasks. Notably, it is the first large-scale benchmark for multi-page table structure recognition. We demonstrate its usefulness by evaluating domain-specialized VLMs on these tasks and highlighting current progress. Finally, we use PubTables-v2 to create the Page-Object Table Transformer (POTATR), an image-to-graph extension of the Table Transformer to comprehensive page-level TE. Data, code, and trained models will be released.

</details>


### [88] [DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance](https://arxiv.org/abs/2512.10894)
*Peiying Zhang,Nanxuan Zhao,Matthew Fisher,Yiran Xu,Jing Liao,Difan Liu*

Main category: cs.CV

TL;DR: DuetSVG 是一种统一的多模态模型，能端到端联合生成图像 token 和 SVG token，并在推理时利用视觉预测指导 SVG 解码，从而生成更忠实、语义对齐且语法规范的 SVG。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（VLM）的 SVG 生成方法仅生成文本，缺乏解码过程中的视觉信号，导致难以处理复杂语义，生成结果在视觉吸引力和几何一致性方面表现不佳。

Method: 提出 DuetSVG 模型，联合建模图像与 SVG token 的生成；使用图像和 SVG 数据集联合训练；引入测试时缩放策略，利用模型自身的视觉预测作为 SVG 解码的引导。

Result: 在多项实验中显著优于现有方法，生成的 SVG 在视觉保真度、语义对齐性和语法正确性方面均有提升。

Conclusion: 联合视觉与 SVG token 的端到端生成范式及测试时视觉引导策略，有效提升了 SVG 生成质量，为多模态矢量图形生成提供了新思路。

Abstract: Recent vision-language model (VLM)-based approaches have achieved impressive results on SVG generation. However, because they generate only text and lack visual signals during decoding, they often struggle with complex semantics and fail to produce visually appealing or geometrically coherent SVGs. We introduce DuetSVG, a unified multimodal model that jointly generates image tokens and corresponding SVG tokens in an end-to-end manner. DuetSVG is trained on both image and SVG datasets. At inference, we apply a novel test-time scaling strategy that leverages the model's native visual predictions as guidance to improve SVG decoding quality. Extensive experiments show that our method outperforms existing methods, producing visually faithful, semantically aligned, and syntactically clean SVGs across a wide range of applications.

</details>


### [89] [FoundationMotion: Auto-Labeling and Reasoning about Spatial Movement in Videos](https://arxiv.org/abs/2512.10927)
*Yulu Gan,Ligeng Zhu,Dandan Shan,Baifeng Shi,Hongxu Yin,Boris Ivanovic,Song Han,Trevor Darrell,Jitendra Malik,Marco Pavone,Boyi Li*

Main category: cs.CV

TL;DR: 本文提出FoundationMotion，一种全自动的数据整理流程，用于构建大规模、细粒度的运动数据集，通过结合视频中的物体轨迹检测与大语言模型生成高质量的运动描述和问答对，显著提升了现有开源模型在运动理解任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有运动理解模型在最新基准测试中表现不佳，主要原因是缺乏大规模、细粒度的运动数据集；而现有数据集多依赖高成本人工标注，难以扩展。

Method: 提出FoundationMotion自动化数据整理流程：首先在视频中检测并跟踪物体以提取轨迹，然后利用这些轨迹和视频帧，结合大语言模型（LLMs）生成细粒度运动描述及多样化的问答对；最后用生成的数据集微调开源视觉语言模型（如NVILA-Video-15B、Qwen2.5-7B）。

Result: 微调后的模型在多个运动理解基准上显著超越强闭源基线（如Gemini-2.5 Flash）和大型开源模型（如Qwen2.5-VL-72B），同时未损害其他任务性能。

Conclusion: FoundationMotion为构建可扩展、高质量运动数据集提供了有效方案，能广泛支持各类模型在运动理解和空间推理能力上的提升。

Abstract: Motion understanding is fundamental to physical reasoning, enabling models to infer dynamics and predict future states. However, state-of-the-art models still struggle on recent motion benchmarks, primarily due to the scarcity of large-scale, fine-grained motion datasets. Existing motion datasets are often constructed from costly manual annotation, severely limiting scalability. To address this challenge, we introduce FoundationMotion, a fully automated data curation pipeline that constructs large-scale motion datasets. Our approach first detects and tracks objects in videos to extract their trajectories, then leverages these trajectories and video frames with Large Language Models (LLMs) to generate fine-grained captions and diverse question-answer pairs about motion and spatial reasoning. Using datasets produced by this pipeline, we fine-tune open-source models including NVILA-Video-15B and Qwen2.5-7B, achieving substantial improvements in motion understanding without compromising performance on other tasks. Notably, our models outperform strong closed-source baselines like Gemini-2.5 Flash and large open-source models such as Qwen2.5-VL-72B across diverse motion understanding datasets and benchmarks. FoundationMotion thus provides a scalable solution for curating fine-grained motion datasets that enable effective fine-tuning of diverse models to enhance motion understanding and spatial reasoning capabilities.

</details>


### [90] [BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models](https://arxiv.org/abs/2512.10932)
*Shengao Wang,Wenqi Wang,Zecheng Wang,Max Whitton,Michael Wakeham,Arjun Chandra,Joey Huang,Pengyue Zhu,Helen Chen,David Li,Jeffrey Li,Shawn Li,Andrew Zagula,Amy Zhao,Andrew Zhu,Sayaka Nakamura,Yuki Yamamoto,Jerry Jun Yokono,Aaron Mueller,Bryan A. Plummer,Kate Saenko,Venkatesh Saligrama,Boqing Gong*

Main category: cs.CV

TL;DR: BabyVLM-V2 是一个受婴儿发展启发的视觉-语言建模框架，通过纵向多模态预训练数据集、灵活模型架构及专为婴幼儿认知能力设计的 DevCV Toolbox 评估工具箱，在多项任务上超越 GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 利用婴幼儿早期发展轨迹作为样本高效预训练视觉基础模型的自然目标，推动发展上合理（developmentally plausible）的AI建模。

Method: 构建纵向、多维度的婴儿中心音视频预训练集（含视频-语句、图像-语句、多轮对话数据），提出 BabyVLM-V2 模型，并开发 DevCV Toolbox——将 NIH Baby Toolbox 中视觉相关评测指标转化为涵盖空间推理、记忆与词汇理解的10项多模态认知任务基准。

Result: 从零预训练的小型模型在 DevCV Toolbox 上达到有竞争力的性能，部分任务超越 GPT-4o。

Conclusion: BabyVLM-V2 提供了一个原则性强、统一的发展导向框架，有望加速视觉基础模型的发展可解释性与样本高效预训练研究。

Abstract: Early children's developmental trajectories set up a natural goal for sample-efficient pretraining of vision foundation models. We introduce BabyVLM-V2, a developmentally grounded framework for infant-inspired vision-language modeling that extensively improves upon BabyVLM-V1 through a longitudinal, multifaceted pretraining set, a versatile model, and, most importantly, DevCV Toolbox for cognitive evaluation. The pretraining set maximizes coverage while minimizing curation of a longitudinal, infant-centric audiovisual corpus, yielding video-utterance, image-utterance, and multi-turn conversational data that mirror infant experiences. DevCV Toolbox adapts all vision-related measures of the recently released NIH Baby Toolbox into a benchmark suite of ten multimodal tasks, covering spatial reasoning, memory, and vocabulary understanding aligned with early children's capabilities. Experimental results show that a compact model pretrained from scratch can achieve competitive performance on DevCV Toolbox, outperforming GPT-4o on some tasks. We hope the principled, unified BabyVLM-V2 framework will accelerate research in developmentally plausible pretraining of vision foundation models.

</details>


### [91] [GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting](https://arxiv.org/abs/2512.10939)
*Madhav Agarwal,Mingtian Zhang,Laura Sevilla-Lara,Steven McDonagh*

Main category: cs.CV

TL;DR: 本文提出了一种结合3D可变形模型（3DMM）与高斯溅射（Gaussian Splatting）的语音驱动说话头生成方法，利用音频直接预测3DMM参数，并通过Transformer建模实现时序一致性，在保证实时性的同时提升视觉稳定性和保真度。


<details>
  <summary>Details</summary>
Motivation: 现有语音驱动说话头方法在高保真与实时性之间难以兼顾：扩散模型图像质量高但速度慢且难用于单样本生成；高斯溅射虽快，但因面部跟踪不准或高斯映射不一致导致视频不稳定和伪影。

Method: 将高斯溅射与3D可变形模型（3DMM）结合，构建人像专属说话头；采用Transformer网络直接从音频中预测3DMM形变参数，以驱动高斯渲染，确保时序一致性；输入为单目视频与独立语音，输出为实时、稳定的 talking head 视频。

Result: 在定量与定性评估中均达到具有竞争力的性能，生成视频兼具实时性、稳定性与高视觉保真度，显著减少抖动与伪影。

Conclusion: 该方法有效弥合了真实感与实时性之间的鸿沟，为交互式虚拟人应用提供了实用可行的技术路径。

Abstract: Speech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot settings. Gaussian Splatting approaches are real-time, yet inaccuracies in facial tracking, or inconsistent Gaussian mappings, lead to unstable outputs and video artifacts that are detrimental to realistic use cases. We address this problem by mapping Gaussian Splatting using 3D Morphable Models to generate person-specific avatars. We introduce transformer-based prediction of model parameters, directly from audio, to drive temporal consistency. From monocular video and independent audio speech inputs, our method enables generation of real-time talking head videos where we report competitive quantitative and qualitative performance.

</details>


### [92] [OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis](https://arxiv.org/abs/2512.10940)
*Xiang Fan,Sharath Girish,Vivek Ramanujan,Chaoyang Wang,Ashkan Mirzaei,Petr Sushko,Aliaksandr Siarohin,Sergey Tulyakov,Ranjay Krishna*

Main category: cs.CV

TL;DR: OmniView 是一个统一的扩散模型框架，旨在解决多种4D一致性任务（如新视角合成、文本/图像到视频生成等），通过分别建模空间、时间和视角条件实现灵活泛化，并在多个基准上超越专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅针对特定4D一致性子任务设计，训练数据割裂，缺乏统一建模能力。

Method: 提出OmniView框架，将空间、时间与视角条件解耦表示，支持多种输入组合（静态/动态/多视角、文本/图像提示等）下的4D一致生成。

Result: 在多个基准上性能领先：多视角NVS提升33%，动态NVS提升60%，静态相机控制提升20%，文本驱动视频相机轨迹误差降低4倍。

Conclusion: OmniView验证了单一大模型通用于多样化4D视频生成任务的可行性，推动通用4D视频模型的发展。

Abstract: Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D data. We introduce OmniView, a unified framework that generalizes across a wide range of 4D consistency tasks. Our method separately represents space, time, and view conditions, enabling flexible combinations of these inputs. For example, OmniView can synthesize novel views from static, dynamic, and multiview inputs, extrapolate trajectories forward and backward in time, and create videos from text or image prompts with full camera control. OmniView is competitive with task-specific models across diverse benchmarks and metrics, improving image quality scores among camera-conditioned diffusion models by up to 33\% in multiview NVS LLFF dataset, 60\% in dynamic NVS Neural 3D Video benchmark, 20\% in static camera control on RE-10K, and reducing camera trajectory errors by 4x in text-conditioned video generation. With strong generalizability in one model, OmniView demonstrates the feasibility of a generalist 4D video model. Project page is available at https://snap-research.github.io/OmniView/

</details>


### [93] [Mull-Tokens: Modality-Agnostic Latent Thinking](https://arxiv.org/abs/2512.10941)
*Arijit Ray,Ahmed Abdelkader,Chengzhi Mao,Bryan A. Plummer,Kate Saenko,Ranjay Krishna,Leonidas Guibas,Wen-Sheng Chu*

Main category: cs.CV

TL;DR: 本文提出Mull-Tokens，一种模态无关的潜在标记，用于在文本和图像模态间自由进行中间推理，无需依赖专用工具或人工标注数据，在空间推理任务上显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的多模态推理模型脆弱且难以扩展，依赖外部工具、高成本图像生成或手工构建的跨模态推理数据，无法有效支持真实世界中涉及空间、时间、功能等非语言要素的推理。

Method: 提出Mull-Tokens——预训练的模态无关潜在标记，先通过图文交错轨迹监督训练，再仅用最终答案进行无监督微调；不生成图像，也不调用外部工具，实现自由跨模态中间表示。

Result: 在四个空间推理基准（如解谜、视角转换）上，Mull-Tokens平均提升3%，在强推理型谜题子集上最高提升16%，显著优于纯文本及图文交错推理基线。

Conclusion: Mull-Tokens提供了一种简洁、可扩展的多模态抽象推理方案，缓解了文本与视觉推理的对齐与接地难题。

Abstract: Reasoning goes beyond language; the real world requires reasoning about space, time, affordances, and much more that words alone cannot convey. Existing multimodal models exploring the potential of reasoning with images are brittle and do not scale. They rely on calling specialist tools, costly generation of images, or handcrafted reasoning data to switch between text and image thoughts. Instead, we offer a simpler alternative -- Mull-Tokens -- modality-agnostic latent tokens pre-trained to hold intermediate information in either image or text modalities to let the model think free-form towards the correct answer. We investigate best practices to train Mull-Tokens inspired by latent reasoning frameworks. We first train Mull-Tokens using supervision from interleaved text-image traces, and then fine-tune without any supervision by only using the final answers. Across four challenging spatial reasoning benchmarks involving tasks such as solving puzzles and taking different perspectives, we demonstrate that Mull-Tokens improve upon several baselines utilizing text-only reasoning or interleaved image-text reasoning, achieving a +3% average improvement and up to +16% on a puzzle solving reasoning-heavy split compared to our strongest baseline. Adding to conversations around challenges in grounding textual and visual reasoning, Mull-Tokens offers a simple solution to abstractly think in multiple modalities.

</details>


### [94] [VL-JEPA: Joint Embedding Predictive Architecture for Vision-language](https://arxiv.org/abs/2512.10942)
*Delong Chen,Mustafa Shukor,Theo Moutakanni,Willy Chung,Jade Yu,Tejaswi Kasarla,Allen Bolourchi,Yann LeCun,Pascale Fung*

Main category: cs.CV

TL;DR: VL-JEPA是一种基于联合嵌入预测架构（JEPA）的视觉-语言模型，它预测目标文本的连续嵌入而非自回归生成token，在抽象表征空间中学习语义，性能更强、参数更少，并支持多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉-语言模型（VLMs）在token空间中自回归生成带来的表面语言变异性干扰问题，提升语义建模效率与泛化能力。

Method: 提出VL-JEPA模型，采用Joint Embedding Predictive Architecture，用视觉编码器提取图像特征，直接预测文本的连续嵌入；引入轻量级按需文本解码器，并支持选择性解码；整个框架无需修改即可适配分类、检索、VQA等判别式任务。

Result: 在8个视频分类和8个视频检索数据集上平均性能超越CLIP、SigLIP2和Perception Encoder；在4个VQA数据集（GQA、TallyQA、POPE、POPEv2）上媲美InstructBLIP、QwenVL等大模型，但参数仅1.6B；相比标准token-space VLM，性能更强且参数减少50%；选择性解码使解码操作减少2.85倍。

Conclusion: VL-JEPA验证了在嵌入空间而非token空间进行视觉-语言联合建模的有效性，兼具高效性、通用性和可扩展性，为下一代多模态基础模型提供了新范式。

Abstract: We introduce VL-JEPA, a vision-language model built on a Joint Embedding Predictive Architecture (JEPA). Instead of autoregressively generating tokens as in classical VLMs, VL-JEPA predicts continuous embeddings of the target texts. By learning in an abstract representation space, the model focuses on task-relevant semantics while abstracting away surface-level linguistic variability. In a strictly controlled comparison against standard token-space VLM training with the same vision encoder and training data, VL-JEPA achieves stronger performance while having 50% fewer trainable parameters. At inference time, a lightweight text decoder is invoked only when needed to translate VL-JEPA predicted embeddings into text. We show that VL-JEPA natively supports selective decoding that reduces the number of decoding operations by 2.85x while maintaining similar performance compared to non-adaptive uniform decoding. Beyond generation, the VL-JEPA's embedding space naturally supports open-vocabulary classification, text-to-video retrieval, and discriminative VQA without any architecture modification. On eight video classification and eight video retrieval datasets, the average performance VL-JEPA surpasses that of CLIP, SigLIP2, and Perception Encoder. At the same time, the model achieves comparable performance as classical VLMs (InstructBLIP, QwenVL) on four VQA datasets: GQA, TallyQA, POPE and POPEv2, despite only having 1.6B parameters.

</details>


### [95] [AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation](https://arxiv.org/abs/2512.10943)
*Sharath Girish,Viacheslav Ivanov,Tsai-Shien Chen,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov*

Main category: cs.CV

TL;DR: 本文提出了AlcheMinT框架，通过引入显式的时间戳条件和新颖的位置编码机制，实现了对主体驱动视频生成的精细时间控制，支持多主体在视频中的精确出现和消失。


<details>
  <summary>Details</summary>
Motivation: 现有主体驱动视频生成方法缺乏对主体外观和消失的细粒度时间控制，难以满足组合视频合成、故事板制作和可控动画等应用需求。

Method: 提出AlcheMinT统一框架，引入显式时间戳条件；设计新型位置编码机制以编码与主体身份相关的时间区间，并与预训练视频生成模型的位置嵌入无缝集成；加入主体描述性文本标记以增强视觉身份与视频字幕的绑定；采用逐标记拼接方式避免额外交叉注意力模块，参数开销极小。

Result: 建立了评估多主体身份保持、视频保真度和时间一致性基准；实验表明AlcheMinT在视觉质量上媲美当前最优视频个性化方法，首次实现对视频内多主体生成的精确时间控制。

Conclusion: AlcheMinT为视频生成提供了高效、轻量且具备精细时间控制能力的新范式，推动了主体驱动视频生成向更可控、更实用方向发展。

Abstract: Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applications such as compositional video synthesis, storyboarding, and controllable animation. We propose AlcheMinT, a unified framework that introduces explicit timestamps conditioning for subject-driven video generation. Our approach introduces a novel positional encoding mechanism that unlocks the encoding of temporal intervals, associated in our case with subject identities, while seamlessly integrating with the pretrained video generation model positional embeddings. Additionally, we incorporate subject-descriptive text tokens to strengthen binding between visual identity and video captions, mitigating ambiguity during generation. Through token-wise concatenation, AlcheMinT avoids any additional cross-attention modules and incurs negligible parameter overhead. We establish a benchmark evaluating multiple subject identity preservation, video fidelity, and temporal adherence. Experimental results demonstrate that AlcheMinT achieves visual quality matching state-of-the-art video personalization methods, while, for the first time, enabling precise temporal control over multi-subject generation within videos. Project page is at https://snap-research.github.io/Video-AlcheMinT

</details>


### [96] [MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation](https://arxiv.org/abs/2512.10945)
*Henghui Ding,Chang Liu,Shuting He,Kaining Ying,Xudong Jiang,Chen Change Loy,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文提出了MeViS数据集，一个大规模多模态数据集，用于基于运动描述的视频目标分割与跟踪，并评估了15种现有方法在4个相关任务上的性能，揭示其在运动表达引导的视频理解方面的不足；同时提出新方法LMPM++，在多个任务上达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有指代视频分割数据集多关注显著静态对象，语言描述富含静态属性，忽视了运动在视频和语言中的关键作用；本文旨在探索利用运动表达和运动推理线索进行像素级视频理解的可行性。

Method: 构建了包含33,072条人工标注的文本与音频运动表达、覆盖8,171个目标和2,006个复杂场景视频的MeViS数据集；在4类共15种现有方法上进行基准测试，并提出改进方法LMPM++用于RVOS/AVOS/RMOT任务。

Result: 基准测试揭示了现有方法在运动表达引导的视频理解任务中存在明显弱点；LMPM++在RVOS、AVOS和RMOT任务上均取得新的SOTA结果。

Conclusion: MeViS为运动表达驱动的复杂场景视频理解提供了重要基准与平台，推动了结合语言运动描述与视觉运动推理的算法发展。

Abstract: This paper proposes a large-scale multi-modal dataset for referring motion expression video segmentation, focusing on segmenting and tracking target objects in videos based on language description of objects' motions. Existing referring video segmentation datasets often focus on salient objects and use language expressions rich in static attributes, potentially allowing the target object to be identified in a single frame. Such datasets underemphasize the role of motion in both videos and languages. To explore the feasibility of using motion expressions and motion reasoning clues for pixel-level video understanding, we introduce MeViS, a dataset containing 33,072 human-annotated motion expressions in both text and audio, covering 8,171 objects in 2,006 videos of complex scenarios. We benchmark 15 existing methods across 4 tasks supported by MeViS, including 6 referring video object segmentation (RVOS) methods, 3 audio-guided video object segmentation (AVOS) methods, 2 referring multi-object tracking (RMOT) methods, and 4 video captioning methods for the newly introduced referring motion expression generation (RMEG) task. The results demonstrate weaknesses and limitations of existing methods in addressing motion expression-guided video understanding. We further analyze the challenges and propose an approach LMPM++ for RVOS/AVOS/RMOT that achieves new state-of-the-art results. Our dataset provides a platform that facilitates the development of motion expression-guided video understanding algorithms in complex video scenes. The proposed MeViS dataset and the method's source code are publicly available at https://henghuiding.com/MeViS/

</details>


### [97] [Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving](https://arxiv.org/abs/2512.10947)
*Jiawei Yang,Ziyu Chen,Yurong You,Yan Wang,Yiming Li,Yuxiao Chen,Boyi Li,Boris Ivanovic,Marco Pavone,Yue Wang*

Main category: cs.CV

TL;DR: Flex是一种高效的场景编码器，通过可学习的场景标记联合编码多摄像头和多时间步的图像信息，无需依赖显式的3D先验（如BEV或占据网格），在大幅提升推理吞吐量的同时显著提升驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 解决端到端自动驾驶中高容量多相机数据处理的计算瓶颈，并挑战3D先验在场景编码中必不可少的主流假设。

Method: 提出Flex，使用少量可学习的场景标记对所有相机和时间步的图像标记进行联合编码；采用几何无关设计，完全从数据中学习紧凑的场景表示，不依赖BEV、占据或三平面等显式3D归纳偏置。

Result: 在2万小时真实驾驶数据集上，Flex推理吞吐量提升2.2倍，驾驶性能大幅超越SOTA；且场景标记自发涌现出无监督的场景分解能力。

Conclusion: 数据驱动的联合编码策略比依赖3D先验的方法更高效、更可扩展，为未来自动驾驶系统提供了新路径。

Abstract: We present Flex, an efficient and effective scene encoder that addresses the computational bottleneck of processing high-volume multi-camera data in end-to-end autonomous driving. Flex employs a small set of learnable scene tokens to jointly encode information from all image tokens across different cameras and timesteps. By design, our approach is geometry-agnostic, learning a compact scene representation directly from data without relying on the explicit 3D inductive biases, such as Bird-Eye-View (BEV), occupancy or tri-plane representations, which are common in prior work. This holistic encoding strategy aggressively compresses the visual input for the downstream Large Language Model (LLM) based policy model. Evaluated on a large-scale proprietary dataset of 20,000 driving hours, our Flex achieves 2.2x greater inference throughput while improving driving performance by a large margin compared to state-of-the-art methods. Furthermore, we show that these compact scene tokens develop an emergent capability for scene decomposition without any explicit supervision. Our findings challenge the prevailing assumption that 3D priors are necessary, demonstrating that a data-driven, joint encoding strategy offers a more scalable, efficient and effective path for future autonomous driving systems.

</details>


### [98] [ClusIR: Towards Cluster-Guided All-in-One Image Restoration](https://arxiv.org/abs/2512.10948)
*Shengkai Hu,Jiaqi Ma,Jun Wan,Wenwen Min,Yongcheng Jing,Lefei Zhang,Dacheng Tao*

Main category: cs.CV

TL;DR: 本文提出ClusIR框架，通过可学习聚类显式建模退化语义，并在空域和频域传播聚类感知线索，实现对多种退化类型的自适应图像恢复。


<details>
  <summary>Details</summary>
Motivation: 现有全合一图像恢复方法难以显式建模退化类型，且对复杂或混合退化适应性差。

Method: 提出ClusIR框架，包含概率聚类引导路由机制（PCGRM）和退化感知频率调制模块（DAFMM），分别实现退化识别与专家路由解耦、以及基于聚类先验的自适应频域分解与调制。

Result: 在多个基准数据集上实验表明，ClusIR在多种退化场景下均达到具有竞争力的恢复性能。

Conclusion: ClusIR通过聚类引导的语义-频域协同机制，有效提升了全合一图像恢复的泛化性与精度。

Abstract: All-in-One Image Restoration (AiOIR) aims to recover high-quality images from diverse degradations within a unified framework. However, existing methods often fail to explicitly model degradation types and struggle to adapt their restoration behavior to complex or mixed degradations. To address these issues, we propose ClusIR, a Cluster-Guided Image Restoration framework that explicitly models degradation semantics through learnable clustering and propagates cluster-aware cues across spatial and frequency domains for adaptive restoration. Specifically, ClusIR comprises two key components: a Probabilistic Cluster-Guided Routing Mechanism (PCGRM) and a Degradation-Aware Frequency Modulation Module (DAFMM). The proposed PCGRM disentangles degradation recognition from expert activation, enabling discriminative degradation perception and stable expert routing. Meanwhile, DAFMM leverages the cluster-guided priors to perform adaptive frequency decomposition and targeted modulation, collaboratively refining structural and textural representations for higher restoration fidelity. The cluster-guided synergy seamlessly bridges semantic cues with frequency-domain modulation, empowering ClusIR to attain remarkable restoration results across a wide range of degradations. Extensive experiments on diverse benchmarks validate that ClusIR reaches competitive performance under several scenarios.

</details>


### [99] [E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training](https://arxiv.org/abs/2512.10950)
*Qitao Zhao,Hao Tan,Qianqian Wang,Sai Bi,Kai Zhang,Kalyan Sunkavalli,Shubham Tulsiani,Hanwen Jiang*

Main category: cs.CV

TL;DR: E-RayZer is a self-supervised large 3D vision model that learns 3D-aware representations directly from unlabeled multi-view images using explicit 3D geometry, outperforming prior methods like RayZer and even matching fully supervised models on 3D tasks.


<details>
  <summary>Details</summary>
Motivation: Self-supervised pre-training has been successful for 2D and video, but remains underexplored for learning 3D-aware representations from multi-view images; existing methods like RayZer infer 3D indirectly and suffer from shortcut solutions.

Method: E-RayZer performs self-supervised 3D reconstruction directly in 3D space using explicit geometry, and introduces a fine-grained unsupervised curriculum to organize training from easy to hard samples and harmonize heterogeneous data.

Result: E-RayZer significantly outperforms RayZer on pose estimation, matches or surpasses fully supervised models (e.g., VGGT) on reconstruction, and its representations surpass leading visual pre-training models (DINOv3, CroCo v2, VideoMAE V2, RayZer) on 3D downstream tasks.

Conclusion: E-RayZer establishes a new paradigm for 3D-aware visual pre-training by enabling geometrically grounded, truly 3D-aware representation learning from unlabeled multi-view images.

Abstract: Self-supervised pre-training has revolutionized foundation models for languages, individual 2D images and videos, but remains largely unexplored for learning 3D-aware representations from multi-view images. In this paper, we present E-RayZer, a self-supervised large 3D Vision model that learns truly 3D-aware representations directly from unlabeled images. Unlike prior self-supervised methods such as RayZer that infer 3D indirectly through latent-space view synthesis, E-RayZer operates directly in 3D space, performing self-supervised 3D reconstruction with Explicit geometry. This formulation eliminates shortcut solutions and yields representations that are geometrically grounded. To ensure convergence and scalability, we introduce a novel fine-grained learning curriculum that organizes training from easy to hard samples and harmonizes heterogeneous data sources in an entirely unsupervised manner. Experiments demonstrate that E-RayZer significantly outperforms RayZer on pose estimation, matches or sometimes surpasses fully supervised reconstruction models such as VGGT. Furthermore, its learned representations outperform leading visual pre-training models (e.g., DINOv3, CroCo v2, VideoMAE V2, and RayZer) when transferring to 3D downstream tasks, establishing E-RayZer as a new paradigm for 3D-aware visual pre-training.

</details>


### [100] [Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration](https://arxiv.org/abs/2512.10954)
*Sicheng Mo,Thao Nguyen,Richard Zhang,Nick Kolkin,Siddharth Srinivasan Iyer,Eli Shechtman,Krishna Kumar Singh,Yong Jae Lee,Bolei Zhou,Yuheng Li*

Main category: cs.CV

TL;DR: This paper introduces Group Diffusion, a novel method that enables collaborative image generation in diffusion models by sharing attention across multiple images during inference, leading to improved generation quality and up to 32.2% FID improvement on ImageNet-256x256.


<details>
  <summary>Details</summary>
Motivation: Previous diffusion model methods generate images independently; this work explores the untapped potential of collaborative, cross-sample generation during inference.

Method: Group Diffusion extends the attention mechanism in diffusion transformers to operate across multiple images (a group) rather than only within each image, enabling joint denoising and learning of intra- and inter-image correspondences.

Result: Larger group sizes enhance cross-sample attention and generation quality; a new qualitative measure correlates strongly with FID; GroupDiff achieves up to 32.2% FID improvement on ImageNet-256x256.

Conclusion: Cross-sample inference is an effective and previously unexplored mechanism for improving generative modeling performance in diffusion models.

Abstract: In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rather than limited to just the patches within an image. This enables images to be jointly denoised at inference time, learning both intra and inter-image correspondence. We observe a clear scaling effect - larger group sizes yield stronger cross-sample attention and better generation quality. Furthermore, we introduce a qualitative measure to capture this behavior and show that its strength closely correlates with FID. Built on standard diffusion transformers, our GroupDiff achieves up to 32.2% FID improvement on ImageNet-256x256. Our work reveals cross-sample inference as an effective, previously unexplored mechanism for generative modeling.

</details>


### [101] [Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization](https://arxiv.org/abs/2512.10955)
*Tsai-Shien Chen,Aliaksandr Siarohin,Guocheng Gordon Qian,Kuan-Chieh Jackson Wang,Egor Nemchinov,Moayed Haji-Ali,Riza Alp Guler,Willi Menapace,Ivan Skorokhodov,Anil Kag,Jun-Yan Zhu,Sergey Tulyakov*

Main category: cs.CV

TL;DR: 本文提出Omni-Attribute，首个开放词汇图像属性编码器，通过语义配对数据与双目标训练实现高保真、属性解耦的视觉表征，显著提升属性检索、个性化与组合生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖通用图像编码器的整体嵌入，导致多种视觉因素纠缠，难以分离单一属性，引发信息泄漏与合成不一致问题。

Method: 提出Omni-Attribute编码器：(i) 构建带正负属性标注的语义关联图像对用于显式监督；(ii) 采用兼顾生成保真度与对比解耦的双目标训练范式。

Result: 在多个基准上实现开放词汇属性检索、个性化及组合生成的最先进性能。

Conclusion: Omni-Attribute成功实现了细粒度、解耦、高保真的图像属性编码，为视觉概念个性化提供了新范式。

Abstract: Visual concept personalization aims to transfer only specific image attributes, such as identity, expression, lighting, and style, into unseen contexts. However, existing methods rely on holistic embeddings from general-purpose image encoders, which entangle multiple visual factors and make it difficult to isolate a single attribute. This often leads to information leakage and incoherent synthesis. To address this limitation, we introduce Omni-Attribute, the first open-vocabulary image attribute encoder designed to learn high-fidelity, attribute-specific representations. Our approach jointly designs the data and model: (i) we curate semantically linked image pairs annotated with positive and negative attributes to explicitly teach the encoder what to preserve or suppress; and (ii) we adopt a dual-objective training paradigm that balances generative fidelity with contrastive disentanglement. The resulting embeddings prove effective for open-vocabulary attribute retrieval, personalization, and compositional generation, achieving state-of-the-art performance across multiple benchmarks.

</details>


### [102] [Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision](https://arxiv.org/abs/2512.10956)
*Wentao Zhou,Xuweiyi Chen,Vignesh Rajagopal,Jeffrey Chen,Rohan Chandra,Zezhou Cheng*

Main category: cs.CV

TL;DR: 本文提出StereoWalker，一种结合立体视觉输入和显式中层视觉（如深度估计和密集像素跟踪）的端到端机器人导航基础模型，显著减少对大规模像素-动作标注数据的依赖，并在动态非结构化场景中提升导航性能。


<details>
  <summary>Details</summary>
Motivation: 单目视觉存在深度尺度模糊性，难以支持动态非结构化环境中的鲁棒导航；纯端到端NFM依赖大量难以获取的像素-动作监督信号，忽略中层视觉先验导致效率低下。

Method: 引入立体视觉输入以消除深度尺度歧义，并融合现代中层视觉模型（深度估计、密集像素跟踪）作为显式几何与运动结构先验；构建大规模带自动动作标注的互联网立体视频导航数据集。

Result: StereoWalker仅用1.5%训练数据即可达到SOTA性能，使用全部数据时性能超越SOTA；立体视觉输入比单目输入带来更高导航性能。

Conclusion: 在端到端导航基础模型中引入立体视觉与显式中层视觉先验是更高效、更鲁棒的设计范式，可大幅降低数据需求并提升实际部署能力。

Abstract: The success of foundation models in language and vision motivated research in fully end-to-end robot navigation foundation models (NFMs). NFMs directly map monocular visual input to control actions and ignore mid-level vision modules (tracking, depth estimation, etc) entirely. While the assumption that vision capabilities will emerge implicitly is compelling, it requires large amounts of pixel-to-action supervision that are difficult to obtain. The challenge is especially pronounced in dynamic and unstructured settings, where robust navigation requires precise geometric and dynamic understanding, while the depth-scale ambiguity in monocular views further limits accurate spatial reasoning. In this paper, we show that relying on monocular vision and ignoring mid-level vision priors is inefficient.
  We present StereoWalker, which augments NFMs with stereo inputs and explicit mid-level vision such as depth estimation and dense pixel tracking. Our intuition is straightforward: stereo inputs resolve the depth-scale ambiguity, and modern mid-level vision models provide reliable geometric and motion structure in dynamic scenes. We also curate a large stereo navigation dataset with automatic action annotation from Internet stereo videos to support training of StereoWalker and to facilitate future research. Through our experiments, we find that mid-level vision enables StereoWalker to achieve a comparable performance as the state-of-the-art using only 1.5% of the training data, and surpasses the state-of-the-art using the full data. We also observe that stereo vision yields higher navigation performance than monocular input.

</details>


### [103] [SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model](https://arxiv.org/abs/2512.10957)
*Yukai Shi,Weiyu Li,Zihao Wang,Hongyang Li,Xingyu Chen,Ping Tan,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一个解耦的3D场景生成框架SceneMaker，通过分离去遮挡模型与3D物体生成，并引入统一的姿态估计模型，显著提升了严重遮挡和开放集场景下的几何质量与姿态精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法因缺乏足够的开放集去遮挡和姿态估计先验，在严重遮挡和开放集设置下难以同时生成高质量几何结构和准确姿态。

Method: 1）将去遮挡模型从3D物体生成中解耦，并利用图像数据集和自建去遮挡数据集增强其泛化能力；2）提出融合全局与局部机制的统一姿态估计模型，改进自注意力与交叉注意力；3）构建开放集3D场景数据集以提升姿态估计模型泛化性。

Result: 在室内与开放集场景上均展现出优于现有方法的性能，代码与数据集已开源。

Conclusion: 解耦设计与多源数据协同训练有效提升了3D场景生成在复杂遮挡与开放集条件下的鲁棒性与准确性。

Abstract: We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.

</details>


### [104] [WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World](https://arxiv.org/abs/2512.10958)
*Ao Liang,Lingdong Kong,Tianyi Yan,Hongsi Liu,Wesley Yang,Ziqi Huang,Wei Yin,Jialong Zuo,Yixuan Hu,Dekai Zhu,Dongyue Lu,Youquan Liu,Guangfeng Jiang,Linfeng Li,Xiangtai Li,Long Zhuo,Lai Xing Ng,Benoit R. Cottereau,Changxin Gao,Liang Pan,Wei Tsang Ooi,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出了WorldLens，一个全面评估生成式世界模型的基准，涵盖生成、重建、动作跟随、下游任务和人类偏好五个方面，并构建了WorldLens-26K数据集和WorldLens-Agent评估模型，以统一衡量世界模型在视觉真实性、几何一致性、物理合理性和功能可靠性上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有生成式世界模型虽能生成视觉逼真的4D驾驶环境，但在物理合理性与行为可靠性上常失败，且缺乏统一的多维度评估标准。

Method: 提出WorldLens基准，涵盖生成、重建、动作跟随、下游任务和人类偏好五方面；构建含26K人类标注视频的WorldLens-26K数据集；训练可扩展、可解释的WorldLens-Agent评估模型。

Result: 发现当前模型在不同维度间存在权衡（如纹理强者常违物理，几何稳者缺行为保真）；WorldLens-Agent能对齐客观指标与人类判断，实现可扩展、可解释评分。

Conclusion: WorldLens及其配套数据集与评估模型构成统一生态系统，推动世界模型评估从‘看起来真实’转向‘行为上真实’，为未来研究提供标准化衡量框架。

Abstract: Generative world models are reshaping embodied AI, enabling agents to synthesize realistic 4D driving environments that look convincing but often fail physically or behaviorally. Despite rapid progress, the field still lacks a unified way to assess whether generated worlds preserve geometry, obey physics, or support reliable control. We introduce WorldLens, a full-spectrum benchmark evaluating how well a model builds, understands, and behaves within its generated world. It spans five aspects -- Generation, Reconstruction, Action-Following, Downstream Task, and Human Preference -- jointly covering visual realism, geometric consistency, physical plausibility, and functional reliability. Across these dimensions, no existing world model excels universally: those with strong textures often violate physics, while geometry-stable ones lack behavioral fidelity. To align objective metrics with human judgment, we further construct WorldLens-26K, a large-scale dataset of human-annotated videos with numerical scores and textual rationales, and develop WorldLens-Agent, an evaluation model distilled from these annotations to enable scalable, explainable scoring. Together, the benchmark, dataset, and agent form a unified ecosystem for measuring world fidelity -- standardizing how future models are judged not only by how real they look, but by how real they behave.

</details>


### [105] [StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space](https://arxiv.org/abs/2512.10959)
*Tjark Behrens,Anton Obukhov,Bingxin Ke,Fabio Tosi,Matteo Poggi,Konrad Schindler*

Main category: cs.CV

TL;DR: StereoSpace 是一种基于扩散模型的单目转双目合成框架，通过纯视角条件建模几何，无需显式深度估计或图像扭曲，端到端推断视差对应并修复遮挡区域；提出无泄漏的端到端评估协议，强调感知舒适度（iSQoE）与几何一致性（MEt3R），在各类复杂场景中性能领先。


<details>
  <summary>Details</summary>
Motivation: 现有单目转双目方法依赖显式深度估计或图像扭曲，易受误差传播和遮挡处理不佳影响，且评估常存在数据泄露；需一种更鲁棒、几何无关、端到端可优化的方案。

Method: 提出 StereoSpace 框架：构建规范化的校正空间，以视角变换参数为条件输入，驱动扩散模型直接生成目标视角图像；全程不引入深度图、视差图或显式扭曲操作，所有几何推理由扩散过程隐式完成。

Result: 在公平、无几何信息泄露的评估协议下，StereoSpace 在 iSQoE 和 MEt3R 指标上均超越 warp & inpaint、latent-warping 和 warped-conditioning 三类主流方法，尤其在多层结构与非朗伯体场景中保持高锐度视差与强鲁棒性。

Conclusion: 视角条件化扩散模型可作为可扩展、无需深度先验的立体生成新范式，为单目立体内容生成提供简洁而强大的替代路径。

Abstract: We introduce StereoSpace, a diffusion-based framework for monocular-to-stereo synthesis that models geometry purely through viewpoint conditioning, without explicit depth or warping. A canonical rectified space and the conditioning guide the generator to infer correspondences and fill disocclusions end-to-end. To ensure fair and leakage-free evaluation, we introduce an end-to-end protocol that excludes any ground truth or proxy geometry estimates at test time. The protocol emphasizes metrics reflecting downstream relevance: iSQoE for perceptual comfort and MEt3R for geometric consistency. StereoSpace surpasses other methods from the warp & inpaint, latent-warping, and warped-conditioning categories, achieving sharp parallax and strong robustness on layered and non-Lambertian scenes. This establishes viewpoint-conditioned diffusion as a scalable, depth-free solution for stereo generation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [106] [What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models](https://arxiv.org/abs/2512.10080)
*Luciano Floridi,Jessica Morley,Claudio Novelli,David Watson*

Main category: cs.CL

TL;DR: 本文探讨了当前基于token-completion机制的大语言模型（LLMs）的推理机制，指出其输出虽看似具有溯因推理（abductive reasoning）特征，实则仅依赖统计模式匹配，并无真实理解、语义基础或验证能力；其类溯因表现源于训练数据中人类文本的结构模仿，因此在应用中需谨慎评估其输出的真实性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 澄清当前LLMs是否真正具备溯因推理能力，揭示其表面推理性与内在随机性之间的本质差异，以正确认识其能力边界与应用风险。

Method: 概念分析与批判性论证，结合实例说明LLMs生成文本的统计本质及其与人类溯因推理的根本区别，并回应五类典型反对意见。

Result: 证实LLMs不具备真正的溯因推理能力——其输出是数据驱动的模式复现，缺乏真值判断、语义 grounding、逻辑验证和理解基础；其‘类溯因’表现仅为对人类文本结构的表层模仿。

Conclusion: LLMs可作为创意辅助与思维支持工具，但不能替代人类的推理与验证；对其输出必须保持批判性审视，评估标准应区分表面合理性与实质正确性。

Abstract: This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs create text based on learned patterns rather than performing actual abductive reasoning. When their output seems abductive, this is largely because they are trained on human-generated texts that include reasoning structures. Examples are used to show how LLMs can produce plausible ideas, mimic commonsense reasoning, and give explanatory answers without being grounded in truth, semantics, verification, or understanding, and without performing any real abductive reasoning. This dual nature, where the models have a stochastic base but appear abductive in use, has important consequences for how LLMs are evaluated and applied. They can assist with generating ideas and supporting human thinking, but their outputs must be critically assessed because they cannot identify truth or verify their explanations. The article concludes by addressing five objections to these points, noting some limitations in the analysis, and offering an overall evaluation.

</details>


### [107] [Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models](https://arxiv.org/abs/2512.10110)
*Yumou Wei,John Stamper,Paulo F. Carvalho*

Main category: cs.CL

TL;DR: 本文提出了一种利用小型语言模型（SLMs）进行自动问题生成的新流程，采用“先生成后验证”策略，结合文本生成与概率推理能力，经人工与大模型评估，证明SLM在合理流程引导下可生成高质量、目标对齐的问题。


<details>
  <summary>Details</summary>
Motivation: 弥补学习分析研究中过度依赖大语言模型（LLMs）的不足，探索小型语言模型（SLMs）在自动问题生成任务中的潜力与可行性。

Method: 提出一种新型问题生成流程，采用“生成-验证”两阶段策略：首先进行大规模候选问题生成，再基于新颖的概率推理机制进行选择性验证与筛选。

Result: 两项评估（7位人类专家与一个LLM）均表明，生成的问题大多具有明确答案，且与预设学习目标高度一致。

Conclusion: 小型语言模型（SLMs）在精心设计的流程引导下，能够有效生成高质量问题，无需依赖大模型，为资源受限场景提供了可行替代方案。

Abstract: We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a "generate-then-validate" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.

</details>


### [108] [Workflow is All You Need: Escaping the "Statistical Smoothing Trap" via High-Entropy Information Foraging and Adversarial Pacing](https://arxiv.org/abs/2512.10121)
*Zhongjie Jiang*

Main category: cs.CL

TL;DR: 本文提出DeepNews框架，通过双粒度检索、模式引导的战略规划和对抗性约束提示，解决金融长文本生成中的幻觉、逻辑连贯性与个性化表达的'不可能三角'问题，并在真实媒体测试中显著优于现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在垂直领域长文本生成中面临低幻觉、高逻辑连贯性与个性化表达难以兼顾的'不可能三元组'瓶颈，根源在于统计平滑陷阱忽视了专家写作所需的高熵信息获取与结构化认知过程。

Method: 提出DeepNews框架，包含：1）基于信息觅食理论的双粒度检索（10:1饱和输入比）；2）基于叙事模式与原子块的模式引导战略规划；3）含节奏中断与逻辑迷雾等策略的对抗性约束提示。

Result: 实验发现金融报道存在'知识断崖'：上下文低于15,000字符时真实性骤降；超30,000字符时幻觉自由率（HFR）稳定在85%以上；在中文头部科技媒体盲测中，基于DeepSeek-V3-0324的DeepNews提交接受率达25%，远超GPT-5零样本生成的0%。

Conclusion: 显式建模专家认知流程可突破统计平滑陷阱，DeepNews为垂直领域高质量长文本生成提供了可复现、可验证的新范式。

Abstract: Central to long-form text generation in vertical domains is the "impossible trinity" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).

</details>


### [109] [PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset](https://arxiv.org/abs/2512.10148)
*Moonsoo Park,Jeongseok Yun,Bohyung Kim*

Main category: cs.CL

TL;DR: 本文提出了一种两阶段提示框架，通过从简短的用户评论中推断显式和隐式用户画像，并将其融入响应生成提示中，以提升个性化回复质量，无需模型微调。


<details>
  <summary>Details</summary>
Motivation: 在用户信息有限的领域（如外卖平台），大语言模型常因缺乏上下文而生成泛化回复，降低用户参与度和效果。

Method: 设计两阶段提示框架：第一阶段从短评论中推断显式（如偏好）与隐式（如人口统计或风格线索）用户画像；第二阶段将这些画像属性融入响应生成提示，并通过调整解码温度提升生成多样性与保真度。

Result: 在韩国外卖App真实数据集上的实验表明，该方法显著提升了响应的精准性、多样性与语义一致性。

Conclusion: 基于画像增强的提示方法能有效提升自动化回复的相关性与个性化程度，且无需模型微调。

Abstract: Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.

</details>


### [110] [Unsupervised Acquisition of Discrete Grammatical Categories](https://arxiv.org/abs/2503.18702)
*David Ph. Shakouri,Crit Cremers,Niels O. Schiller*

Main category: cs.CL

TL;DR: 本文通过构建一个包含成人语言模型和女儿语言模型的多智能体系统，模拟语言习得过程，利用层次聚类分析从母亲模型生成的语言样本中提取统计规律，进而归纳出离散语法规则，使女儿模型获得抽象语法知识。


<details>
  <summary>Details</summary>
Motivation: 探索在缺乏内部知识访问权限的情况下，如何仅通过语言样例实现抽象语法知识的习得。

Method: 构建多智能体计算实验环境，采用层次凝聚聚类分析对母亲语言模型生成的连续话语进行统计模式分析，从中提取语法范畴并转化为语法规则，加入女儿语言模型的语法知识库。

Result: 成功从输入数据中归纳出类似语言学家为自然语言提出的语法范畴结构，验证了非平凡语法知识的获取；并通过独立测试集验证了参数配置的有效性。

Conclusion: 该方法证明了仅基于外部语言样例，可通过统计学习与聚类方法实现抽象语法知识的自主建构，为语言习得建模提供了可行计算路径。

Abstract: This article presents experiments performed using a computational laboratory environment for language acquisition experiments. It implements a multi-agent system consisting of two agents: an adult language model and a daughter language model that aims to learn the mother language. Crucially, the daughter agent does not have access to the internal knowledge of the mother language model but only to the language exemplars the mother agent generates. These experiments illustrate how this system can be used to acquire abstract grammatical knowledge. We demonstrate how statistical analyses of patterns in the input data corresponding to grammatical categories yield discrete grammatical rules. These rules are subsequently added to the grammatical knowledge of the daughter language model. To this end, hierarchical agglomerative cluster analysis was applied to the utterances consecutively generated by the mother language model. It is argued that this procedure can be used to acquire structures resembling grammatical categories proposed by linguists for natural languages. Thus, it is established that non-trivial grammatical knowledge has been acquired. Moreover, the parameter configuration of this computational laboratory environment determined using training data generated by the mother language model is validated in a second experiment with a test set similarly resulting in the acquisition of non-trivial categories.

</details>


### [111] [Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning](https://arxiv.org/abs/2512.10150)
*Lama Alssum,Hani Itani,Hasan Abed Al Kader Hammoud,Philip Torr,Adel Bibi,Bernard Ghanem*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）在任务适配过程中出现的安全性退化问题，将其建模为持续学习（CL）问题，并系统评估多种CL方法（如DER）在细调即服务场景下对安全性的保持效果，结果表明CL方法能显著降低攻击成功率且不损害任务性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及，其安全性对齐日益重要；而模型在针对新任务进行微调时常因灾难性遗忘导致安全性下降，尤其在用户上传数据进行定制化微调的服务模式下风险突出。

Method: 将安全性保持建模为持续学习问题，适配并评测多种CL方法（正则化类、记忆回放类、模型融合类），在良性与中毒两类用户数据设定下，于GSM8K、SST2、Code三个下游任务及LLaMA2-7B、Mistral-7B、Gemma-2B三类模型上开展系统实验。

Result: CL方法普遍优于标准微调，其中DER方法在攻击成功率和任务性能两方面均优于其他CL方法及现有安全性基线，效果具有跨任务和跨模型的泛化性。

Conclusion: 持续学习是解决LLM微调中安全性退化问题的一种实用且有效的方案，DER等CL方法可在保障任务效用的同时显著提升鲁棒安全性。

Abstract: The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user's selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.

</details>


### [112] [AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding](https://arxiv.org/abs/2512.10195)
*Gyutaek Oh,Sangjoon Park,Byung-Hoon Kim*

Main category: cs.CL

TL;DR: 本文提出AutoMedic，一个基于多智能体模拟的自动化评估框架，用于评估大语言模型在动态、交互式临床对话中的表现，并引入CARE指标进行多维度评估。


<details>
  <summary>Details</summary>
Motivation: 现有静态医疗问答基准无法充分评估大语言模型在动态、多轮临床对话中的实际表现，且缺乏超越简单准确率的多维评估策略。

Method: 构建AutoMedic多智能体模拟框架，将静态QA数据集转化为虚拟患者档案，生成真实、临床基础的多轮对话；设计CARE评估指标（临床准确性、效率/策略性、共情能力、鲁棒性）对临床对话代理进行综合评估。

Result: 通过专家验证，AutoMedic被证实为一种有效、可靠的自动化评估框架，能为医疗对话大模型的开发提供实践指导。

Conclusion: AutoMedic填补了动态临床对话评估的空白，推动了大语言模型在医疗对话应用中安全、可信的发展。

Abstract: Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.

</details>


### [113] [Multilingual VLM Training: Adapting an English-Trained VLM to French](https://arxiv.org/abs/2512.10336)
*Jules Lahmi,Alexis Roger*

Main category: cs.CL

TL;DR: 本文探讨了将英文训练的视觉-语言模型（VLM）适配到多语言场景的挑战，对比了翻译流水线、LoRA微调和两阶段微调三种方法，并发现数据集翻译质量是当前多语言VLM性能的主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLM）主要面向英语，限制了非英语使用者的可及性，亟需拓展至更广泛的语言。

Method: 比较了三种适配方法：基于翻译的流水线、LoRA微调、以及分离视觉与语言适配的两阶段微调；评估采用翻译后的多模态基准数据集与母语专家人工评估相结合的方式。

Result: 数据集翻译质量是多语言VLM性能的关键瓶颈，低质量翻译严重制约训练与评估效果。

Conclusion: 未来工作应聚焦于构建原生语言的高质量多模态数据集，并改进翻译策略。

Abstract: Artificial intelligence has made great progress in recent years, particularly in the development of Vision--Language Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non--English speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.

</details>


### [114] [Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale](https://arxiv.org/abs/2512.10398)
*Zhaodong Wang,Zhenting Qi,Sherman Wong,Nathan Hu,Samuel Lin,Jun Ge,Erwin Gao,Yining Yang,Ben Maurer,Wenlin Chen,David Recordon,Yilun Du,Minlan Yu,Ying Zhang*

Main category: cs.CL

TL;DR: 本文提出了Confucius Code Agent（CCA），一个开源的、可工业级部署的AI软件工程师，基于Confucius SDK构建，具备长上下文推理、跨会话持续学习和模块化工具链协调能力，并在SWE-Bench-Pro上达到54.3%的SOTA Resolve@1性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源编码智能体缺乏工业级可扩展性，而闭源方案又牺牲了可解释性与可控性；亟需兼顾透明性、性能与可扩展性的新范式。

Method: 提出Confucius SDK平台，融合Agent Experience（AX）、User Experience（UX）和Developer Experience（DX）三重视角；引入分层工作记忆、持久化笔记系统、模块化扩展机制及元智能体自动调优框架；在此基础上构建CCA智能体。

Result: 在SWE-Bench-Pro基准上达成54.3%的Resolve@1性能，显著超越先前开源编码智能体；验证了其在真实软件工程任务中的工业级实用性。

Conclusion: Confucius SDK与CCA共同构成透明、可扩展、可复现的AI智能体基础架构，弥合了研究原型与生产系统之间的鸿沟，支持工业规模的智能体开发与部署。

Abstract: Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.

</details>


### [115] [Sliding Window Attention Adaptation](https://arxiv.org/abs/2512.10411)
*Yijiong Yu,Jiale Liu,Qingyun Wu,Huazheng Wang,Ji Pei*

Main category: cs.CL

TL;DR: 本文提出Sliding Window Attention Adaptation (SWAA)，通过五种方法的组合（仅prefill阶段使用SWA、保留sink token、FA/SWA层交替、思维链提示、微调）来适配预训练为全注意力的LLM以支持滑动窗口注意力，从而在不重新预训练的前提下恢复长上下文性能。


<details>
  <summary>Details</summary>
Motivation: 滑动窗口注意力（SWA）虽能将自注意力复杂度从平方级降至线性级，但直接用于全注意力（FA）预训练模型会导致长上下文性能严重下降，因此需探索无需重新预训练的适配方法。

Method: 提出SWAA框架，整合五种适配策略：(1) 仅在prefill阶段启用SWA；(2) 保留sink tokens；(3) FA与SWA层交替堆叠；(4) 引入chain-of-thought提示；(5) 轻量微调。通过组合实验分析其协同效应。

Result: 实验证明单一方法效果有限，但特定组合可有效恢复原始长上下文性能；同时量化评估了不同SWAA配置的性能-效率权衡，并给出面向不同场景的推荐方案。

Conclusion: FA预训练LLM可通过SWAA有效适配SWA，无需重新预训练；适配成功依赖多种技术的协同，而非单一手段；该工作为高效长上下文推理提供了实用、即插即用的解决方案。

Abstract: The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving "sink" tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios. Our code is available at https://github.com/yuyijiong/sliding-window-attention-adaptation

</details>


### [116] [Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers](https://arxiv.org/abs/2512.10422)
*Youmin Ko,Sungjong Seo,Hyunjoon Kim*

Main category: cs.CL

TL;DR: 本文提出CoopRAG框架，通过检索器与大语言模型（LLM）协同工作、以及检索器内部不同层之间的协作，提升多跳和单跳问答任务中的检索准确性和答案生成质量，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在简单和多跳问答中仍易出现错误检索和幻觉问题，亟需更鲁棒的协同机制。

Method: CoopRAG框架包含四步：（i）将问题展开为带掩码不确定位置的子问题与推理链；（ii）基于子问题和推理链增强查询进行检索；（iii）利用检索器不同层间的对比进行文档重排序；（iv）由LLM填充掩码以重建完整推理链。

Result: 在三个多跳QA数据集和一个单跳QA数据集上，CoopRAG在检索性能和问答性能两方面均持续超越当前最优方法。

Conclusion: 检索器与LLM之间、以及检索器内部各层之间的协同建模，可有效缓解RAG中的错误检索与幻觉问题，提升端到端问答质量。

Abstract: Since large language models (LLMs) have a tendency to generate factually inaccurate output, retrieval-augmented generation (RAG) has gained significant attention as a key means to mitigate this downside of harnessing only LLMs. However, existing RAG methods for simple and multi-hop question answering (QA) are still prone to incorrect retrievals and hallucinations. To address these limitations, we propose CoopRAG, a novel RAG framework for the question answering task in which a retriever and an LLM work cooperatively with each other by exchanging informative knowledge, and the earlier and later layers of the retriever model work cooperatively with each other to accurately rank the retrieved documents relevant to a given query. In this framework, we (i) unroll a question into sub-questions and a reasoning chain in which uncertain positions are masked, (ii) retrieve the documents relevant to the question augmented with the sub-questions and the reasoning chain, (iii) rerank the documents by contrasting layers of the retriever, and (iv) reconstruct the reasoning chain by filling the masked positions via the LLM. Our experiments demonstrate that CoopRAG consistently outperforms state-of-the-art QA methods on three multi-hop QA datasets as well as a simple QA dataset in terms of both the retrieval and QA performances. Our code is available.\footnote{https://github.com/meaningful96/CoopRAG}

</details>


### [117] [T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground](https://arxiv.org/abs/2512.10430)
*Dmitrii Stoianov,Danil Taranets,Olga Tsymboi,Ramil Latypov,Almaz Dautov,Vladislav Kruglikov,Nikita Surkov,German Abramov,Pavel Gein,Dmitry Abulkhanov,Mikhail Gashkov,Viktor Zelenkovskiy,Artem Batalov,Aleksandr Medvedev,Anatolii Potapov*

Main category: cs.CL

TL;DR: T-pro 2.0 is an open-weight Russian LLM supporting hybrid reasoning and efficient inference via a Cyrillic-dense tokenizer and adapted EAGLE speculative decoding; the authors release model weights, instruction corpus (T-Wix 500k), reasoning benchmark (T-Math), and EAGLE weights to foster reproducible research and practical applications.


<details>
  <summary>Details</summary>
Motivation: To advance reproducible and extensible research on Russian-language LLMs, especially for hybrid reasoning and low-latency inference, while addressing the scarcity of open, efficient, and well-documented Russian models and evaluation resources.

Method: Developed T-pro 2.0 with a Cyrillic-dense tokenizer and integrated an adapted EAGLE speculative-decoding pipeline; constructed the T-Wix 500k instruction dataset and T-Math reasoning benchmark; released all components openly including model weights, data, and inference assets.

Result: Achieved efficient inference with reduced latency, demonstrated via public web demo showing speedups across domains; enabled direct answering and reasoning-trace generation; established a fully open ecosystem for Russian LLM development and evaluation.

Conclusion: T-pro 2.0 serves as an accessible, open, and practical foundation for building, studying, and deploying efficient Russian LLMs—bridging gaps in language support, reasoning capability, and inference efficiency.

Abstract: We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and extensible research, we release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face. These resources allow users to study Russian-language reasoning and to extend or adapt both the model and the inference pipeline. A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains. T-pro 2.0 thus serves as an accessible open system for building and evaluating efficient, practical Russian LLM applications.

</details>


### [118] [Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring "Tortured Phrases" in Scientific Literature](https://arxiv.org/abs/2512.10435)
*Agniva Maiti,Prajwal Panth,Suresh Chandra Satapathy*

Main category: cs.CL

TL;DR: 本文提出SRAP框架，通过领域特定语言模型与向量检索结合，检测并数学还原被自动化改写工具掩盖的学术剽窃文本，显著提升术语恢复准确率。


<details>
  <summary>Details</summary>
Motivation: 科学文献完整性正受自动化改写工具生成'扭曲短语'（如用'counterfeit consciousness'替代'artificial intelligence'）的严重威胁，现有检测方法依赖静态词表或通用语言模型，难以应对新型混淆且无法溯源。

Method: 采用两阶段架构：(1) 基于SciBERT的词元级伪困惑度进行统计异常检测；(2) 利用FAISS密集向量检索与SBERT句子级对齐实现源导向的语义重建。

Result: 在对抗性科学文本平行语料上，零样本基线恢复准确率为0%，而SRAP达到23.67%；验证了静态决策边界在专业术语密集文本中优于动态阈值。

Conclusion: SRAP不仅能检测扭曲表达，还能将其追溯并重建为最可能的原始术语和源文档，支持学术不端行为的法证分析。

Abstract: The integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate "tortured phrases", statistically improbable synonyms (e.g. "counterfeit consciousness" for "artificial intelligence"), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.

</details>


### [119] [Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT](https://arxiv.org/abs/2512.10440)
*Nour El Houda Ben Chaabene,Hamza Hammami*

Main category: cs.CL

TL;DR: This paper proposes integrating Knowledge Graphs (KGs) with large language models (LLMs) using KG-BERT to improve factual consistency and reasoning in knowledge-intensive NLP tasks.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) suffer from factual inconsistencies due to lack of structured knowledge.

Method: Integrating Knowledge Graphs (KGs) with LLMs via KG-BERT to enhance grounding and reasoning.

Result: Significant performance gains in knowledge-intensive tasks such as question answering and entity linking; improved factual reliability and context-awareness.

Conclusion: Integrating KGs with LLMs via KG-BERT effectively enhances factual consistency and reasoning capabilities, paving the way for more reliable next-generation LLMs.

Abstract: Large language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.

</details>


### [120] [Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis](https://arxiv.org/abs/2512.10441)
*Nour El Houda Ben Chaabene,Hamza Hammami,Laid Kahloul*

Main category: cs.CL

TL;DR: 本文提出了一种心理感知型对话代理，融合LLM、KG-BERT和带注意力机制的双向LSTM，利用文本、语音韵律与行为时序多模态数据实时识别学生认知与情感状态，在教育场景中同步提升学习效果与情绪健康。


<details>
  <summary>Details</summary>
Motivation: 现有教育聊天机器人通常仅聚焦于教学辅导或情感支持单一目标，缺乏对认知与情感状态协同建模的能力，难以实现真正以学生为中心的自适应干预。

Method: 结合大语言模型（LLM）、知识图谱增强的BERT（KG-BERT）与带注意力机制的双向LSTM，对文本语义、语音韵律特征及行为时序模式进行多模态融合与实时状态分类。

Result: 在大学生试点研究中，该系统显著提升了学习动机、降低了压力水平，并带来中等程度的学业成绩提升。

Conclusion: 语义推理、多模态融合与时序建模的协同整合，为构建自适应、心理感知的智能教育系统提供了可行路径与实证支持。

Abstract: This paper presents a psychologically-aware conversational agent designed to enhance both learning performance and emotional well-being in educational settings. The system combines Large Language Models (LLMs), a knowledge graph-enhanced BERT (KG-BERT), and a bidirectional Long Short-Term Memory (LSTM) with attention to classify students' cognitive and affective states in real time. Unlike prior chatbots limited to either tutoring or affective support, our approach leverages multimodal data-including textual semantics, prosodic speech features, and temporal behavioral trends-to infer engagement, stress, and conceptual understanding. A pilot study with university students demonstrated improved motivation, reduced stress, and moderate academic gains compared to baseline methods. These results underline the promise of integrating semantic reasoning, multimodal fusion, and temporal modeling to support adaptive, student-centered educational interventions.

</details>


### [121] [Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs](https://arxiv.org/abs/2512.10453)
*Lars G. B. Johnsen*

Main category: cs.CL

TL;DR: This paper investigates whether large language models (LLMs), trained only on surface forms, show sensitivity to syntactic structure by testing their performance on subject-auxiliary inversion and parasitic gap licensing—two classic diagnostics of hierarchical grammar. Results indicate LLMs reliably distinguish grammatical from ungrammatical variants, suggesting functional, emergent sensitivity to syntax without explicit structural encoding.


<details>
  <summary>Details</summary>
Motivation: To determine whether LLMs—trained solely on surface sequences—exhibit behavior consistent with implicit syntactic structure, challenging assumptions that such structure requires explicit grammatical knowledge or innate representations.

Method: Evaluated GPT-4 and LLaMA-3 using acceptability rating prompts on two syntactic diagnostics: subject-auxiliary inversion (to probe subject boundary awareness) and parasitic gap licensing (to probe abstract dependency structure).

Result: LLMs reliably distinguished grammatical from ungrammatical variants in both constructions, indicating sensitivity to hierarchical structure beyond linear order.

Conclusion: Structural generalizations can emerge from predictive training on surface forms alone, implying functional syntactic sensitivity without explicit internal grammar—challenging traditional generative assumptions about evidence for syntactic structure.

Abstract: What counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation.
  We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.

</details>


### [122] [XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs](https://arxiv.org/abs/2512.10545)
*Iñaki Lacunza,José Javier Saiz,Alexander Shvets,Aitor Gonzalez-Agirre,Marta Villegas*

Main category: cs.CL

TL;DR: 本文提出XDoGE算法优化多语言大模型训练中的语言分布，通过代理模型确定各语言权重，并在持续预训练中应用，显著提升中低资源语言性能，最终发布IberianLLM-7B-Instruct模型。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型过度依赖高资源语言（如英语），导致中低资源语言性能下降。

Method: 提出XDoGE算法——扩展DoGE至多语言场景，用小型代理模型优化语言分布；再基于所得语言权重，对全尺寸模型进行从头训练或持续预训练（CPT）。

Result: 在IberoBench框架下验证了方法有效性；发布了专为伊比利亚语言和英语优化的IberianLLM-7B-Instruct模型。

Conclusion: 合理调整训练数据的语言分布可显著提升中低资源语言的模型表现，XDoGE与CPT结合是一种高效可行的多语言预训练策略。

Abstract: Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.

</details>


### [123] [Causal Reasoning Favors Encoders: On The Limits of Decoder-Only Models](https://arxiv.org/abs/2512.10561)
*Amartya Roy,Elamparithy M,Kripabandhu Ghosh,Ponnurangam Kumaraguru,Adrian de Wynter*

Main category: cs.CL

TL;DR: 本文探讨了上下文学习（ICL）在因果推理任务中的有效性，发现ICL单独使用不足以实现可靠的因果推理，尤其decoder-only模型对分布偏移敏感；而经过微调的encoder和encoder-decoder模型在鲁棒性和泛化性上更优，尤其适用于成本敏感、短期 horizon的因果推理任务。


<details>
  <summary>Details</summary>
Motivation: 因果推理需要多跳组合与严格合取控制，而现有ICL方法易受输入中虚假词汇关系干扰，其在因果推理中的作用与性能尚不明确。

Method: 对比分析了微调后的encoder、encoder-decoder和decoder-only模型在零样本与少样本ICL设置下，于自然语言与非自然语言因果推理任务中的表现。

Result: ICL单独使用不可靠，decoder-only模型对分布偏移高度脆弱；微调后的encoder与encoder-decoder模型在各类测试（含非自然语言划分）中展现出更强的鲁棒泛化能力，仅在大参数规模下被decoder-only模型追平或超越。

Conclusion: 对于成本敏感、短期目标的鲁棒因果推理任务，推荐采用针对性微调的encoder或encoder-decoder架构。

Abstract: In context learning (ICL) underpins recent advances in large language models (LLMs), although its role and performance in causal reasoning remains unclear. Causal reasoning demands multihop composition and strict conjunctive control, and reliance on spurious lexical relations of the input could provide misleading results. We hypothesize that, due to their ability to project the input into a latent space, encoder and encoder decoder architectures are better suited for said multihop conjunctive reasoning versus decoder only models. To do this, we compare fine-tuned versions of all the aforementioned architectures with zero and few shot ICL in both natural language and non natural language scenarios. We find that ICL alone is insufficient for reliable causal reasoning, often overfocusing on irrelevant input features. In particular, decoder only models are noticeably brittle to distributional shifts, while finetuned encoder and encoder decoder models can generalize more robustly across our tests, including the non natural language split. Both architectures are only matched or surpassed by decoder only architectures at large scales. We conclude by noting that for cost effective, short horizon robust causal reasoning, encoder or encoder decoder architectures with targeted finetuning are preferable.

</details>


### [124] [RoleRMBench & RoleRM: Towards Reward Modeling for Profile-Based Role Play in Dialogue Systems](https://arxiv.org/abs/2512.10575)
*Hang Ding,Qiming Feng,Dongqi Liu,Qi Zhao,Tao Yao,Shuo Wang,Dongsheng Chen,Jian Li,Zhenye Gan,Jiangning Zhang,Chengjie Wang,Yabiao Wang*

Main category: cs.CL

TL;DR: 本文提出了RoleRMBench——首个面向角色扮演对话的奖励建模基准，并设计了基于连续隐式偏好（CIP）训练的奖励模型RoleRM，在叙事连贯性和风格保真度上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型在主观、开放的角色扮演等场景中表现严重退化，难以捕捉细致且角色 grounded 的人类判断。

Method: 构建首个角色扮演对话奖励建模基准RoleRMBench（含7项细粒度能力），并提出RoleRM模型，采用Continuous Implicit Preferences（CIP）方法，将主观评价重构为多策略下的连续一致成对监督信号。

Result: RoleRM在RoleRMBench上平均超越强基线（开源与闭源）奖励模型24%以上，尤其在叙事和风格维度提升显著；同时揭示了连续偏好表征与标注一致性的重要性。

Conclusion: 连续偏好建模与结构化标注策略对提升主观任务中奖励模型性能至关重要，为以人为中心的对话系统主观对齐奠定了基础。

Abstract: Reward modeling has become a cornerstone of aligning large language models (LLMs) with human preferences. Yet, when extended to subjective and open-ended domains such as role play, existing reward models exhibit severe degradation, struggling to capture nuanced and persona-grounded human judgments. To address this gap, we introduce RoleRMBench, the first systematic benchmark for reward modeling in role-playing dialogue, covering seven fine-grained capabilities from narrative management to role consistency and engagement. Evaluation on RoleRMBench reveals large and consistent gaps between general-purpose reward models and human judgment, particularly in narrative and stylistic dimensions. We further propose RoleRM, a reward model trained with Continuous Implicit Preferences (CIP), which reformulates subjective evaluation as continuous consistent pairwise supervision under multiple structuring strategies. Comprehensive experiments show that RoleRM surpasses strong open- and closed-source reward models by over 24% on average, demonstrating substantial gains in narrative coherence and stylistic fidelity. Our findings highlight the importance of continuous preference representation and annotation consistency, establishing a foundation for subjective alignment in human-centered dialogue systems.

</details>


### [125] [AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence](https://arxiv.org/abs/2512.10624)
*Bo Yang,Lanfei Feng,Yunkui Chen,Yu Zhang,Jianyu Zhang,Xiao Xu,Nueraili Aierken,Shijian Li*

Main category: cs.CL

TL;DR: AgriGPT-Omni is an agricultural omni-framework integrating speech, vision, and text, supported by a large multilingual speech dataset, a three-stage training paradigm, and the first tri-modal agricultural benchmark AgriBench-Omni-2K.


<details>
  <summary>Details</summary>
Motivation: Lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks in agricultural AI applications.

Method: 1) Building a scalable data synthesis pipeline to create the largest agricultural speech dataset (492K synthetic + 1.4K real samples across six languages); 2) Training the first agricultural omni-model via textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning; 3) Proposing AgriBench-Omni-2K, a tri-modal, multilingual agricultural benchmark with standardized protocols and tools.

Result: AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning and real-world speech understanding.

Conclusion: AgriGPT-Omni advances inclusive, reproducible, and sustainable agricultural AI—especially for low-resource regions—by unifying speech, vision, and text, and releasing all models, data, benchmarks, and code.

Abstract: Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.

</details>


### [126] [From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages](https://arxiv.org/abs/2512.10630)
*Smiljana Antonijevic Ubois*

Main category: cs.CL

TL;DR: 本研究以塞尔维亚语为案例，探讨低资源语言在AI时代语言技术发展中的结构性、历史性和社会技术性挑战，并提出基于CARE原则的'Data Care'框架，以文化敏感和可持续方式重构语料库设计与治理。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在低资源语言（如塞尔维亚语）中因依赖英语主导数据而导致的文化与语言偏见问题，揭示历史文本遗产损毁与当代工程化倾向加剧的语言技术失衡。

Method: 通过与10位语言学家、数字人文学者和AI开发者的半结构化访谈，结合对历史背景、数据偏见、转写简化及英语预训练模型依赖等问题的质性分析，提出'Data Care'框架。

Result: 识别出影响塞尔维亚语技术发展的多重挑战（如文本遗产破坏、数据缺乏文化特异性、工程优先范式），并构建以CARE原则（集体受益、控制权、责任、伦理）为核心的Data Care实践框架。

Conclusion: Data Care将偏见缓解从事后技术修补转变为语料建设与治理的内在组成部分，可作为在传统LLM开发易复制权力不平等背景下，构建包容、可持续、文化扎根型语言技术的可复用模型。

Abstract: Large language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.

</details>


### [127] [Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation](https://arxiv.org/abs/2512.10734)
*Rebekka Görge,Sujan Sai Gannamaneni,Tabea Naeven,Hammam Abdelwahab,Héctor Allende-Cid,Armin B. Cremers,Lennard Helmer,Michael Mock,Anna Schmitz,Songkai Xue,Elif Yildirir,Maximilian Poretschkin,Stefan Wrobel*

Main category: cs.CL

TL;DR: 本文提出了一套针对文本数据中表征偏差和显式刻板印象的检测与缓解流程，包含基于LLM生成词表的敏感群体识别、人口统计表征得分量化、社会语言学过滤去刻板印象、语法与上下文感知的反事实数据增强补偿表征偏差；实证表明该流程可有效降低数据偏差，但模型在偏差基准上的改进不一致，暴露出当前评估方法的缺陷。


<details>
  <summary>Details</summary>
Motivation: 法规（如欧盟AI法案）要求识别并缓解训练数据中对受保护群体的偏差，但缺乏实际可操作的指导方案。

Method: 提出四步数据偏差检测与缓解流程：1）利用LLM生成高质量敏感群体词表以识别相关标签；2）用人口统计表征得分（Demographic Representation Score）量化表征偏差；3）采用社会语言学启发的过滤方法检测并缓解显式刻板印象；4）通过语法与上下文感知的反事实数据增强补偿表征偏差。在性别、宗教、年龄三个敏感属性上开展双阶段评估。

Result: 各组件经人工验证和基线对比，能有效降低文本数据中的表征偏差和显式刻板印象；但在使用去偏数据微调0.6B–8B参数LLM后，模型在偏差基准上的表现未呈现一致改善。

Conclusion: 所提流程可有效实现数据层面的去偏，但数据去偏未必直接转化为模型输出偏差的下降，揭示了当前偏差评估方法的局限性，强调需更精准的数据操控策略来应对已显现的模型偏差。

Abstract: Textual data used to train large language models (LLMs) exhibits multifaceted bias manifestations encompassing harmful language and skewed demographic distributions. Regulations such as the European AI Act require identifying and mitigating biases against protected groups in data, with the ultimate goal of preventing unfair model outputs. However, practical guidance and operationalization are lacking. We propose a comprehensive data bias detection and mitigation pipeline comprising four components that address two data bias types, namely representation bias and (explicit) stereotypes for a configurable sensitive attribute. First, we leverage LLM-generated word lists created based on quality criteria to detect relevant group labels. Second, representation bias is quantified using the Demographic Representation Score. Third, we detect and mitigate stereotypes using sociolinguistically informed filtering. Finally, we compensate representation bias through Grammar- and Context-Aware Counterfactual Data Augmentation. We conduct a two-fold evaluation using the examples of gender, religion and age. First, the effectiveness of each individual component on data debiasing is evaluated through human validation and baseline comparison. The findings demonstrate that we successfully reduce representation bias and (explicit) stereotypes in a text dataset. Second, the effect of data debiasing on model bias reduction is evaluated by bias benchmarking of several models (0.6B-8B parameters), fine-tuned on the debiased text dataset. This evaluation reveals that LLMs fine-tuned on debiased data do not consistently show improved performance on bias benchmarks, exposing critical gaps in current evaluation methodologies and highlighting the need for targeted data manipulation to address manifested model bias.

</details>


### [128] [Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving](https://arxiv.org/abs/2512.10739)
*Songyang Gao,Yuzhe Gu,Zijian Wu,Lingkai Kong,Wenwei Zhang,Zhongrui Cai,Fan Zheng,Tianyou Ma,Junhao Shen,Haiteng Zhao,Duanyang Zhang,Huilun Zhang,Kuikun Liu,Chengqi Lyu,Yanhui Duan,Chiyu Chen,Ningsheng Ma,Jianfei Gao,Han Lyu,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出了一种新型验证器OPV（Outcome-based Process Verifier），结合结果导向与过程导向验证优势，通过迭代主动学习和拒绝微调（RFT）+ RLVR训练，在降低人工标注成本的同时提升长思维链（CoT）推理的验证准确率与效率，并在多个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于结果的验证器（OVs）无法检查长思维链中的不可靠中间步骤；而基于过程的验证器（PVs）受限于高质量人工标注稀缺，难以可靠检测复杂长CoT中的错误。

Method: 提出Outcome-based Process Verifier（OPV），对长CoT生成的摘要化结果进行过程验证；采用迭代主动学习框架，每轮选取当前OPV最不确定的样本由专家标注，并通过拒绝微调（RFT）和强化学习与可验证奖励（RLVR）更新模型。

Result: OPV在自建基准	extsc{\thisbench}上F1达83.1，超越Qwen3-Max-Preview（76.3）；能有效识别合成数据中的假阳性，与专家评估高度一致；与策略模型协同时显著提升性能，如在AIME2025上将DeepSeek-R1-Distill-Qwen-32B准确率从55.2%提升至73.3%。

Conclusion: OPV在保证验证准确性的同时大幅降低标注成本，兼具高效性与可扩展性，为大规模、高可靠性推理验证提供了新范式。

Abstract: Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the \textbf{O}utcome-based \textbf{P}rocess \textbf{V}erifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \textsc{\thisbench}, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2\% to 73.3\% on AIME2025 as the compute budget scales.

</details>


### [129] [TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage](https://arxiv.org/abs/2512.10741)
*Elroy Galbraith,Chadwick Sutherland,Donahue Morgan*

Main category: cs.CL

TL;DR: 本文提出TRIDENT系统，一种面向加勒比地区口音的三层调度员支持架构，通过口音适配ASR、本地实体抽取与生物声学压力检测，提升紧急语音识别在非标准英语变体上的鲁棒性，并将低ASR置信度转化为优先调度信号，确保加勒比人群公平获得国家分诊协议服务。


<details>
  <summary>Details</summary>
Motivation: 紧急语音识别系统在加勒比等非标准英语变体上性能显著下降，导致关键公共服务缺口；现有系统忽视低ASR置信度所蕴含的语用线索（如危机中语言转码），也缺乏对无明显声学压力但具临床意义的语义信息的捕捉。

Method: 提出TRIDENT三层次架构：1）加勒比口音微调的ASR；2）基于大语言模型的本地临床实体抽取；3）生物声学 distress 检测；融合三种信号（转录置信度、结构化临床实体、声学压力指标），并以心理语言学中压力诱发语码转换理论为支撑，支持离线部署。

Result: TRIDENT将低ASR置信度重新定义为有价值的队列优先级信号（尤其当叠加声学压力时），同时通过语义层补全无压力但高危的呼叫识别；构建了首个面向加勒比口音的、兼顾声学与语义线索的紧急AI分诊支持框架。

Conclusion: 该工作确立了‘口音弹性紧急AI’的设计范式，强调系统应适应语言多样性而非要求用户适应技术；为边缘化语言群体接入标准化医疗响应流程提供了可扩展、灾备就绪的技术路径。

Abstract: Emergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails.
  The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal -- particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss.
  We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.

</details>


### [130] [OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification](https://arxiv.org/abs/2512.10756)
*Zijian Wu,Lingkai Kong,Wenwei Zhang,Songyang Gao,Yuzhe Gu,Zhongrui Cai,Tianyou Ma,Yuhong Liu,Zhi Wang,Runyuan Ma,Guangyu Wang,Wei Li,Conghui He,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出了一种新型验证器OPV（Outcome-based Process Verifier），通过验证长思维链（CoT）的摘要结果来兼顾准确性与效率，并结合迭代主动学习与拒绝微调（RFT）/RLVR提升性能，显著优于现有验证器，在多个基准和任务中取得SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于结果的验证器（OVs）无法检查长思维链中的不可靠中间步骤；而基于过程的验证器（PVs）受限于高质量人工标注稀缺，难以可靠检测复杂长CoT中的错误。

Method: 提出Outcome-based Process Verifier（OPV），将长CoT总结为可验证的结果，并设计迭代主动学习框架：每轮选取OPV最不确定的样本由专家标注，再通过拒绝微调（RFT）和强化学习+可验证奖励（RLVR）训练新OPV。

Result: OPV在自建OPV-Bench上F1达83.1，超越Qwen3-Max-Preview（76.3）；能准确识别合成数据中的假阳性；与策略模型协同时，使DeepSeek-R1-Distill-Qwen-32B在AIME2025上的准确率从55.2%提升至73.3%。

Conclusion: OPV实现了对长推理链高效、准确且可扩展的验证，其迭代主动学习范式显著降低标注成本，为构建可靠推理系统提供了新路径。

Abstract: Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.

</details>


### [131] [Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation](https://arxiv.org/abs/2512.10772)
*Kevin Glocker,Kätriin Kukk,Romina Oji,Marcel Bollmann,Marco Kuhlmann,Jenny Kunz*

Main category: cs.CL

TL;DR: 本文探讨了通过扩大预训练模型规模来高效适配新目标语言的策略，发现大规模上采样模型在数据效率和保留原始语言能力方面优于标准持续预训练方法，并探索了语言特定模型融合构建多语言系统的可行性。


<details>
  <summary>Details</summary>
Motivation: 解决中低资源语言的高性能语言模型构建难题，尤其是大规模多语言模型在小规模时仍逊于单语适配模型的问题。

Method: 通过FLOP匹配的缩放消融实验，对比英语基线模型上采样与标准持续预训练在目标语言适应上的效果；评估缩放对英语能力保持（缓解灾难性遗忘）的影响；尝试多种模型融合方法构建多语言系统。

Result: 大规模上采样模型在足够目标语言数据下可达到甚至超越用更多数据持续预训练的小模型性能；缩放有助于保留英语能力；语言特定上采样模型融合效果优于小模型融合，但不及联合多语言训练；不同融合方法性能差异显著。

Conclusion: 模型缩放是一种高效、数据经济的语言适配策略，能兼顾目标语言性能与源语言能力保持；融合上采样语言模型是构建模块化多语言系统的可行路径，但需开发面向语言级集成的专用融合方法。

Abstract: Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model's capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.

</details>


### [132] [Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting](https://arxiv.org/abs/2512.10780)
*Manurag Khullar,Utkarsh Desai,Poorva Malviya,Aman Dalmia,Zheyuan Ryan Shi*

Main category: cs.CL

TL;DR: 本文研究了罗马化文本对大型语言模型（LLMs）在印度母婴健康分诊任务中可靠性的影响，发现罗马化输入导致F1分数下降5–12点，引发大量潜在误判，问题根源在于正字法噪声导致输出不稳定，而非语义理解失败。


<details>
  <summary>Details</summary>
Motivation: 印度临床场景中广泛使用罗马化印度语言文本，但现有研究极少基于真实数据评估该正字法变体对LLM可靠性的影响。

Method: 在涵盖五种印度语言及尼泊尔语的真实用户查询数据集上，评测主流LLMs在母幼健康分诊任务中的表现，并分析其语义理解与分类输出的分离现象。

Result: 罗马化文本显著降低LLM性能（F1下降5–12点），可能导致近200万额外分诊错误；模型常能正确推断罗马化查询的语义意图，但最终分类仍因正字法噪声而脆弱。

Conclusion: LLM在医疗系统中对罗马化输入的‘看似理解’不等于‘可靠行动’，暴露了当前基于LLM的健康系统中一个关键的安全盲区。

Abstract: Large Language Models (LLMs) are increasingly deployed in high-stakes clinical applications in India. In many such settings, speakers of Indian languages frequently communicate using romanized text rather than native scripts, yet existing research rarely evaluates this orthographic variation using real-world data. We investigate how romanization impacts the reliability of LLMs in a critical domain: maternal and newborn healthcare triage. We benchmark leading LLMs on a real-world dataset of user-generated queries spanning five Indian languages and Nepali. Our results reveal consistent degradation in performance for romanized messages, with F1 scores trailing those of native scripts by 5-12 points. At our partner maternal health organization in India, this gap could cause nearly 2 million excess errors in triage. Crucially, this performance gap by scripts is not due to a failure in clinical reasoning. We demonstrate that LLMs often correctly infer the semantic intent of romanized queries. Nevertheless, their final classification outputs remain brittle in the presence of orthographic noise in romanized inputs. Our findings highlight a critical safety blind spot in LLM-based health systems: models that appear to understand romanized input may still fail to act on it reliably.

</details>


### [133] [The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality](https://arxiv.org/abs/2512.10791)
*Aileen Cheng,Alon Jacovi,Amir Globerson,Ben Golan,Charles Kwong,Chris Alberti,Connie Tao,Eyal Ben-David,Gaurav Singh Tomar,Lukas Haas,Yonatan Bitton,Adam Bloniarz,Aijun Bai,Andrew Wang,Anfal Siddiqui,Arturo Bajuelos Castillo,Aviel Atias,Chang Liu,Corey Fry,Daniel Balle,Deepanway Ghosal,Doron Kukliansky,Dror Marcus,Elena Gribovskaya,Eran Ofek,Honglei Zhuang,Itay Laish,Jan Ackermann,Lily Wang,Meg Risdal,Megan Barnes,Michael Fink,Mohamed Amin,Moran Ambar,Natan Potikha,Nikita Gupta,Nitzan Katz,Noam Velan,Ofir Roval,Ori Ram,Polina Zablotskaia,Prathamesh Bang,Priyanka Agrawal,Rakesh Ghiya,Sanjay Ganapathy,Simon Baumgartner,Sofia Erell,Sushant Prakash,Thibault Sellam,Vikram Rao,Xuanhui Wang,Yaroslav Akulov,Yulong Yang,Zhen Yang,Zhixin Lai,Zhongru Wu,Anca Dragan,Avinatan Hassidim,Fernando Pereira,Slav Petrov,Srinivasan Venkatachary,Tulsee Doshi,Yossi Matias,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: 本文介绍了FACTS Leaderboard，一个用于全面评估语言模型生成事实准确文本能力的在线排行榜套件及配套基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法难以全面衡量语言模型在不同场景下的事实准确性，因此需要一个综合性、多维度的评估框架。

Method: 构建包含四个子排行榜（Multimodal、Parametric、Search、Grounding v2）的FACTS Leaderboard套件，各子榜采用自动化裁判模型评分，最终得分为四部分平均值；支持公私数据集划分以兼顾开放性与评估完整性。

Result: 推出了可公开访问并持续维护的FACTS Leaderboard在线评估平台（https://www.kaggle.com/benchmarks/google/facts），提供统一、鲁棒且平衡的事实性综合评估指标。

Conclusion: FACTS Leaderboard为语言模型的事实性评估提供了标准化、多场景、可扩展的基准框架，有助于推动更可信、更可靠的生成式AI发展。

Abstract: We introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a holistic measure of factuality by aggregating the performance of models on four distinct sub-leaderboards: (1) FACTS Multimodal, which measures the factuality of responses to image-based questions; (2) FACTS Parametric, which assesses models' world knowledge by answering closed-book factoid questions from internal parameters; (3) FACTS Search, which evaluates factuality in information-seeking scenarios, where the model must use a search API; and (4) FACTS Grounding (v2), which evaluates whether long-form responses are grounded in provided documents, featuring significantly improved judge models. Each sub-leaderboard employs automated judge models to score model responses, and the final suite score is an average of the four components, designed to provide a robust and balanced assessment of a model's overall factuality. The FACTS Leaderboard Suite will be actively maintained, containing both public and private splits to allow for external participation while guarding its integrity. It can be found at https://www.kaggle.com/benchmarks/google/facts .

</details>


### [134] [LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification](https://arxiv.org/abs/2512.10793)
*Michael Schlee,Christoph Weisser,Timo Kivimäki,Melchizedek Mashiku,Benjamin Saefken*

Main category: cs.CL

TL;DR: LabelFusion 是一种融合集成方法，将传统Transformer分类器（如RoBERTa）与大语言模型（如GPT、Gemini）结合，通过学习融合二者输出提升文本分类性能，并兼顾准确率、延迟与成本。


<details>
  <summary>Details</summary>
Motivation: 解决传统模型与LLM在文本分类中各自局限，实现优势互补，同时平衡精度、延迟和成本。

Method: 将Transformer模型的嵌入向量与经结构化提示工程获得的LLM类别得分拼接，输入轻量级多层感知机（FusionMLP）进行端到端联合训练。

Result: 在AG News和Reuters 21578数据集上分别达到92.4%和92.3%准确率，验证了其跨领域鲁棒性及实用权衡能力。

Conclusion: LabelFusion提供了一种可扩展、易用且高效的混合分类范式，为ML与LLM协同建模提供了新思路。

Abstract: LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML backbone's embeddings with the LLM-derived per-class scores -- obtained through structured prompt-engineering strategies -- and feeds this joint representation into a compact multi-layer perceptron (FusionMLP) that produces the final prediction. This learned fusion approach captures complementary strengths of LLM reasoning and traditional transformer-based classifiers, yielding robust performance across domains -- achieving 92.4% accuracy on AG News and 92.3% on 10-class Reuters 21578 topic classification -- while enabling practical trade-offs between accuracy, latency, and cost.

</details>


### [135] [Quantifying Emotional Tone in Tolkien's The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python](https://arxiv.org/abs/2512.10865)
*Lilin Qiu*

Main category: cs.CL

TL;DR: This paper uses computational text analysis to examine the emotional tone of dialogue in The Hobbit, revealing a generally positive, calm, and increasingly agentic emotional trajectory that reflects the novel's rhythmic balance between tension and comfort.


<details>
  <summary>Details</summary>
Motivation: To uncover subtle emotional structures in literature by combining computational tools with literary interpretation.

Method: Dialogue was extracted using regular expressions, preprocessed, and scored with the NRC-VAD lexicon to quantify valence, arousal, and dominance; visualizations like emotional trajectory graphs and word clouds were used.

Result: Dialogue shows high valence, low arousal, and increasing dominance over time, reflecting a rhythmic balance of danger, humor, camaraderie, and relief.

Conclusion: Computational methods can effectively reveal emotional rhythm and modulation in literary texts, enriching literary analysis.

Abstract: This study analyzes the emotional tone of dialogue in J. R. R. Tolkien's The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel's emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations -- including emotional trajectory graphs and word clouds -- highlight how Tolkien's language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.

</details>


### [136] [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882)
*Hauke Licht*

Main category: cs.CL

TL;DR: 本文评估了多模态大语言模型（mLLMs）在视频情绪唤醒度分析中的有效性，发现其在理想条件下表现可靠且无明显人口统计偏差，但在真实议会辩论视频中效果不佳，可能影响下游统计推断，强调需持续严谨评估AI方法在政治分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 缺乏关于多模态生成式AI在情绪分析中有效性的实证证据，而政治传播研究正越来越多地使用音视频材料并依赖新兴AI技术。

Method: 通过两个互补的人工标注视频数据集，评估当前多模态大语言模型（mLLMs）对视频中情绪唤醒度的识别能力，并检验其可靠性与潜在人口统计偏差。

Result: 在理想条件下，mLLMs的情绪唤醒度评分高度可靠、无显著人口统计偏差；但在真实议会辩论视频中，其评分表现不佳，可能误导下游统计推断。

Conclusion: 需对新兴生成式AI方法在政治分析中的应用开展持续、严格的评估，本文为此提供了可复现的评估框架。

Abstract: Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs' emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs' arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [137] [HGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding](https://arxiv.org/abs/2512.09947)
*Fuyan Ou,Siqi Ai,Yulin Hu*

Main category: cs.LG

TL;DR: 本文提出了HGC-Herd，一种无需训练的异质图压缩框架，通过轻量级特征传播和类级别herding机制，在保持语义与结构保真度的同时生成紧凑且信息丰富的异质图，显著降低计算与内存开销，同时在多个数据集上达到或超过全图训练精度。


<details>
  <summary>Details</summary>
Motivation: 现有异质图神经网络（HGNNs）面临大规模图上的可扩展性挑战，而主流图压缩方法（如GCond）主要面向同质图且依赖梯度匹配，带来高计算、内存和优化开销。

Method: 提出HGC-Herd：结合轻量级多跳特征传播以编码关系上下文，并采用类级别herding机制选取每类代表性节点，生成平衡且判别性强的子图。

Result: 在ACM、DBLP和Freebase数据集上实验表明，HGC-Herd在精度上媲美或优于全图训练，同时显著降低运行时间和内存消耗。

Conclusion: HGC-Herd是一种高效、可扩展的异质图表示学习压缩方案，具备实际部署价值。

Abstract: Heterogeneous graph neural networks (HGNNs) have demonstrated strong capability in modeling complex semantics across multi-type nodes and relations. However, their scalability to large-scale graphs remains challenging due to structural redundancy and high-dimensional node features. Existing graph condensation approaches, such as GCond, are primarily developed for homogeneous graphs and rely on gradient matching, resulting in considerable computational, memory, and optimization overhead. We propose HGC-Herd, a training-free condensation framework that generates compact yet informative heterogeneous graphs while maintaining both semantic and structural fidelity. HGC-Herd integrates lightweight feature propagation to encode multi-hop relational context and employs a class-wise herding mechanism to identify representative nodes per class, producing balanced and discriminative subsets for downstream learning tasks. Extensive experiments on ACM, DBLP, and Freebase validate that HGC-Herd attains comparable or superior accuracy to full-graph training while markedly reducing both runtime and memory consumption. These results underscore its practical value for efficient and scalable heterogeneous graph representation learning.

</details>


### [138] [BAMBO: Construct Ability and Efficiency LLM Pareto Set via Bayesian Adaptive Multi-objective Block-wise Optimization](https://arxiv.org/abs/2512.09972)
*Kesheng Chen,Wenjian Luo,Zhenqian Zhu,Yamin Hu,Yiya Xi*

Main category: cs.LG

TL;DR: 本文提出BAMBO框架，通过混合最优块划分与qEHVI驱动的进化优化，自动构建LLM能力-效率权衡的Pareto前沿，显著提升搜索效率与解集质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM模型合并方法在构建Pareto集时存在两难：粗粒度方法解稀疏且次优，细粒度方法因维度灾难导致计算不可行。

Method: 提出BAMBO框架，包含：1）将块划分建模为1D动态规划聚类问题，实现降维与关键粒度保留；2）基于q-Expected Hypervolume Improvement（qEHVI）的贝叶斯多目标进化优化循环。

Result: 实验表明BAMBO发现的Pareto前沿优于基线方法，解更优、更全面，支持面向多样化部署约束的敏捷模型选择。

Conclusion: BAMBO有效解决了LLM Pareto集构建中的精度-效率权衡难题，为高效、自动化多目标模型压缩与适配提供了新范式。

Abstract: Constructing a Pareto set is pivotal for navigating the capability-efficiency trade-offs in Large Language Models (LLMs); however, existing merging techniques remain inadequate for this task. Coarse-grained, model-level methods yield only a sparse set of suboptimal solutions, while fine-grained, layer-wise approaches suffer from the "curse of dimensionality," rendering the search space computationally intractable. To resolve this dichotomy, we propose BAMBO (Bayesian Adaptive Multi-objective Block-wise Optimization), a novel framework that automatically constructs the LLM Pareto set. BAMBO renders the search tractable by introducing a Hybrid Optimal Block Partitioning strategy. Formulated as a 1D clustering problem, this strategy leverages a dynamic programming approach to optimally balance intra-block homogeneity and inter-block information distribution, thereby dramatically reducing dimensionality without sacrificing critical granularity. The entire process is automated within an evolutionary loop driven by the q-Expected Hypervolume Improvement (qEHVI) acquisition function. Experiments demonstrate that BAMBO discovers a superior and more comprehensive Pareto frontier than baselines, enabling agile model selection tailored to diverse operational constraints. Code is available at: https://github.com/xin8coder/BAMBO.

</details>


### [139] [Latent Action World Models for Control with Unlabeled Trajectories](https://arxiv.org/abs/2512.10016)
*Marvin Alles,Xingyuan Zhang,Patrick van der Smagt,Philip Becker-Ehmck*

Main category: cs.LG

TL;DR: 本文提出了一种 latent-action world model，通过学习共享的潜在动作表征，联合利用带动作标签和无动作标签的数据，从而在动作标签稀缺时提升世界模型的学习效率，并在离线强化学习中实现高性能。


<details>
  <summary>Details</summary>
Motivation: 标准世界模型依赖动作标注轨迹，在动作标签稀缺时效果受限；而人类能结合直接交互与无动作的观察经验（如视频），因此作者希望构建能同时利用异构数据的世界模型。

Method: 提出 latent-action world model，学习一个将真实动作与被动观测中推断动作对齐的共享潜在动作空间，使单一动力学模型可同时在大规模无标签轨迹和少量动作标注数据上训练；并基于此进行离线强化学习以学习 latent-action 策略。

Result: 在 DeepMind Control Suite 上，该方法仅需约十分之一的动作标注样本，即可达到与纯动作标注基线相当甚至更优的性能。

Conclusion: latent action 表征有效桥接了动作标注数据与无动作数据，显著提升了世界模型在数据效率和泛化能力上的表现，也打通了离线 RL 与无动作训练之间的界限。

Abstract: Inspired by how humans combine direct interaction with action-free experience (e.g., videos), we study world models that learn from heterogeneous data. Standard world models typically rely on action-conditioned trajectories, which limits effectiveness when action labels are scarce. We introduce a family of latent-action world models that jointly use action-conditioned and action-free data by learning a shared latent action representation. This latent space aligns observed control signals with actions inferred from passive observations, enabling a single dynamics model to train on large-scale unlabeled trajectories while requiring only a small set of action-labeled ones. We use the latent-action world model to learn a latent-action policy through offline reinforcement learning (RL), thereby bridging two traditionally separate domains: offline RL, which typically relies on action-conditioned data, and action-free training, which is rarely used with subsequent RL. On the DeepMind Control Suite, our approach achieves strong performance while using about an order of magnitude fewer action-labeled samples than purely action-conditioned baselines. These results show that latent actions enable training on both passive and interactive data, which makes world models learn more efficiently.

</details>


### [140] [Cluster-Dags as Powerful Background Knowledge For Causal Discovery](https://arxiv.org/abs/2512.10032)
*Jan Marco Ruiz de Vargas,Kirtan Padh,Niki Kilbertus*

Main category: cs.LG

TL;DR: 本文提出利用Cluster-DAGs作为先验知识框架来提升因果发现效果，设计了两种改进的约束型算法Cluster-PC和Cluster-FCI，并在模拟数据上验证其优于无先验方法。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法在高维数据和复杂依赖下表现受限，引入系统先验知识可提升性能。

Method: 提出Cluster-DAGs作为更灵活的先验知识框架，并据此改进约束型算法，得到Cluster-PC（全观测）和Cluster-FCI（部分观测）两种新算法。

Result: 在模拟数据实验中，Cluster-PC和Cluster-FCI均优于各自无先验知识的基线方法。

Conclusion: Cluster-DAGs是一种有效且更具灵活性的先验知识表示方式，能显著提升因果发现算法在高维与复杂场景下的性能。

Abstract: Finding cause-effect relationships is of key importance in science. Causal discovery aims to recover a graph from data that succinctly describes these cause-effect relationships. However, current methods face several challenges, especially when dealing with high-dimensional data and complex dependencies. Incorporating prior knowledge about the system can aid causal discovery. In this work, we leverage Cluster-DAGs as a prior knowledge framework to warm-start causal discovery. We show that Cluster-DAGs offer greater flexibility than existing approaches based on tiered background knowledge and introduce two modified constraint-based algorithms, Cluster-PC and Cluster-FCI, for causal discovery in the fully and partially observed setting, respectively. Empirical evaluation on simulated data demonstrates that Cluster-PC and Cluster-FCI outperform their respective baselines without prior knowledge.

</details>


### [141] [Robust Gradient Descent via Heavy-Ball Momentum with Predictive Extrapolation](https://arxiv.org/abs/2512.10033)
*Sarwan Ali*

Main category: cs.LG

TL;DR: 本文提出了一种名为HB-SGE的新优化算法，结合重球动量与预测性梯度外推，在病态和非凸问题上比NAG等方法更稳定且收敛，同时保持较低内存开销和参数复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有加速梯度法（如NAG）在病态或非凸问题上因动量累积过激而易发散，亟需兼具加速性与鲁棒性的新方法。

Method: HB-SGE将重球动量与基于局部泰勒展开的合成梯度外推相结合，动态预测未来梯度方向，实现自适应加速并抑制发散。

Result: 理论证明其在强凸函数下收敛；实验显示在条件数κ=50的病态二次函数上收敛于119步（SGD与NAG发散），在Rosenbrock函数上收敛于2718步（经典动量10步内发散）。

Conclusion: HB-SGE是一种鲁棒、高效、低开销的一阶优化方法，在多种优化景观中显著优于SGD和NAG，尤其适用于病态与非凸场景。

Abstract: Accelerated gradient methods like Nesterov's Accelerated Gradient (NAG) achieve faster convergence on well-conditioned problems but often diverge on ill-conditioned or non-convex landscapes due to aggressive momentum accumulation. We propose Heavy-Ball Synthetic Gradient Extrapolation (HB-SGE), a robust first-order method that combines heavy-ball momentum with predictive gradient extrapolation. Unlike classical momentum methods that accumulate historical gradients, HB-SGE estimates future gradient directions using local Taylor approximations, providing adaptive acceleration while maintaining stability. We prove convergence guarantees for strongly convex functions and demonstrate empirically that HB-SGE prevents divergence on problems where NAG and standard momentum fail. On ill-conditioned quadratics (condition number $κ=50$), HB-SGE converges in 119 iterations while both SGD and NAG diverge. On the non-convex Rosenbrock function, HB-SGE achieves convergence in 2,718 iterations where classical momentum methods diverge within 10 steps. While NAG remains faster on well-conditioned problems, HB-SGE provides a robust alternative with speedup over SGD across diverse landscapes, requiring only $O(d)$ memory overhead and the same hyperparameters as standard momentum.

</details>


### [142] [Intelligently Weighting Multiple Reference Models for Direct Preference Optimization of LLMs](https://arxiv.org/abs/2512.10040)
*Skyler Wu,Aymen Echarghaoui*

Main category: cs.LG

TL;DR: 本文提出四种新的多参考偏好优化（MRPO）权重策略，包括两种离线方法、一种基于滑动窗口的在线方法和一种基于Thompson采样的在线带宽方法，实验表明这些策略在UltraFeedback和SafeRLHF数据集上均优于现有MRPO方法；但更引人深思的是，单参考DPO在多数情况下反而优于所有多参考方法，质疑了多参考方法的实际价值。


<details>
  <summary>Details</summary>
Motivation: 现有MRPO方法中参考模型权重设置是随意且统计上不可靠的，导致性能不稳定，亟需更科学、可验证的权重设定策略。

Method: 提出四种新参考权重策略：两种利用验证集信号的离线方法；一种使用滑动窗口估计器降低过拟合的在线方法；一种将参考权重学习建模为K臂老虎机并采用Thompson采样求解的在线方法。

Result: 在Qwen2.5-0.5B策略模型与7个来自Llama/Mistral/Qwen/Yi/Phi系列的参考模型（0.5B–14B）组合下，四种新策略在UltraFeedback和SafeRLHF上的偏好准确率均超越现有MRPO方法；但单参考DPO（任选7个中6个参考）始终优于所有多参考方法。

Conclusion: 尽管新权重策略提升了MRPO性能，但单参考DPO的持续优越性挑战了多参考方法的必要性与实用性，提示未来研究应重新审视多参考设计的收益与开销平衡。

Abstract: Fine-tuning is integral for aligning large language models (LLMs) with human preferences. Multiple-Reference Preference Optimization (MRPO) builds on Direct Preference Optimization (DPO) by fine-tuning LLMs on preference datasets while regularizing the policy towards a mixture of reference models to leverage their collective desirable properties. However, current methods for setting the reference weights are ad-hoc and statistically unsound, leading to unreliable performance. To address this, we introduce four new weighting strategies: two offline methods that leverage held-out validation signal; one online method that uses a sliding-window estimator to reduce overfitting; and an online method that treats reference weighting as a $K$-armed bandit via Thompson Sampling. Experiments using Qwen2.5-0.5B as the policy model and seven reference models from the Llama, Mistral, Qwen, Yi, and Phi families (0.5B-14B each) show that all 4 of our strategies outperform the current MRPO weighting methods on UltraFeedback and SafeRLHF in preference accuracy. More thought-provokingly, however, we find that single-reference DPO, using any of 6 out of 7 references, consistently outperforms all tested multiple-reference approaches -- calling into question the practical appeal of multiple-reference approaches.

</details>


### [143] [Better Prevent than Tackle: Valuing Defense in Soccer Based on Graph Neural Networks](https://arxiv.org/abs/2512.10355)
*Hyunsung Kim,Sangwoo Seo,Hoyoung Choi,Tom Boomstra,Jinsung Yoon,Chanyoung Park*

Main category: cs.LG

TL;DR: 本文提出DEFCON框架，利用图注意力网络评估足球防守球员在每次进攻中的隐性贡献，通过计算防守动作对对手期望持球价值（EPV）的影响来量化防守表现，并验证其与球员市场价值高度相关。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注有球防守动作（如抢断、拦截），难以衡量防守球员通过位置选择和压迫等无球行为预防危险进攻的隐性贡献，导致防守价值被系统性低估。

Method: 提出基于图注意力网络（GAT）的DEFCON框架，建模每次进攻中各攻击选项的成功概率与期望价值，并估计每位防守球员对该选项的防守责任；进而计算动作前后的期望持球价值（EPV）变化，并据此为防守球员分配正/负贡献分。

Result: 在2023-24赛季训练、2024-25赛季 Eredivisie 数据上验证，DEFCON 得分与球员市场估值呈显著正相关；并支持实时防守贡献时间线、区域化空间分析及攻防对位交互分析等应用。

Conclusion: DEFCON 能更全面、客观地量化足球中防守球员的隐性贡献，弥补传统指标缺陷，为战术分析、球员评估与转会决策提供新工具。

Abstract: Evaluating defensive performance in soccer remains challenging, as effective defending is often expressed not through visible on-ball actions such as interceptions and tackles, but through preventing dangerous opportunities before they arise. Existing approaches have largely focused on valuing on-ball actions, leaving much of defenders' true impact unmeasured. To address this gap, we propose DEFCON (DEFensive CONtribution evaluator), a comprehensive framework that quantifies player-level defensive contributions for every attacking situation in soccer. Leveraging Graph Attention Networks, DEFCON estimates the success probability and expected value of each attacking option, along with each defender's responsibility for stopping it. These components yield an Expected Possession Value (EPV) for the attacking team before and after each action, and DEFCON assigns positive or negative credits to defenders according to whether they reduced or increased the opponent's EPV. Trained on 2023-24 and evaluated on 2024-25 Eredivisie event and tracking data, DEFCON's aggregated player credits exhibit strong positive correlations with market valuations. Finally, we showcase several practical applications, including in-game timelines of defensive contributions, spatial analyses across pitch zones, and pairwise summaries of attacker-defender interactions.

</details>


### [144] [SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation](https://arxiv.org/abs/2512.10042)
*Jongmin Lee,Meiqi Sun,Pieter Abbeel*

Main category: cs.LG

TL;DR: 本文提出了SEMDICE，一种基于状态熵最大化（SEM）的无监督强化学习预训练算法，能够直接从任意离线数据集中优化策略，以最大化状态平稳分布的熵，并在下游任务适应性上表现最优。


<details>
  <summary>Details</summary>
Motivation: 解决无监督强化学习预训练中不依赖任务特定奖励函数来学习先验策略的问题，特别是通过最大化状态平稳分布的熵来提升下游任务的适应能力。

Method: 提出SEMDICE算法，一种原理清晰的离线策略算法，直接在平稳分布空间中优化策略，以实现状态熵最大化。

Result: 实验表明SEMDICE在状态熵最大化方面优于基线算法，并在SEM类无监督RL预训练方法中实现了最佳的下游任务适应效率。

Conclusion: SEMDICE是一种有效的无监督强化学习预训练方法，能够在不使用任务奖励的情况下，从离线数据中学习出高适应性的策略。

Abstract: In the unsupervised pre-training for reinforcement learning, the agent aims to learn a prior policy for downstream tasks without relying on task-specific reward functions. We focus on state entropy maximization (SEM), where the goal is to learn a policy that maximizes the entropy of the state stationary distribution. In this paper, we introduce SEMDICE, a principled off-policy algorithm that computes an SEM policy from an arbitrary off-policy dataset, which optimizes the policy directly within the space of stationary distributions. SEMDICE computes a single, stationary Markov state-entropy-maximizing policy from an arbitrary off-policy dataset. Experimental results demonstrate that SEMDICE outperforms baseline algorithms in maximizing state entropy while achieving the best adaptation efficiency for downstream tasks among SEM-based unsupervised RL pre-training methods.

</details>


### [145] [Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition](https://arxiv.org/abs/2512.10043)
*João Lucas Luz Lima Sarcinelli,Diego Furtado Silva*

Main category: cs.LG

TL;DR: 本文提出了一种用于葡萄牙语零样本命名实体识别（NER）的三步式本地大语言模型（LLM）集成方法，在多个数据集上超越单个LLM，且无需微调或大量标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在低资源语言（如葡萄牙语）的NER任务中表现不佳；虽有LLM集成研究，但主要集中在生成或分类任务，NER领域尚属空白。

Method: 提出一种三步零样本NER集成流程，利用启发式策略在少量标注数据下选择最优本地开源LLM组合，不依赖微调。

Result: 在五个葡萄牙语NER数据集中的四个上优于单个LLM；跨数据集配置下，基于不同源数据集选出的集成仍普遍优于单模型，表明可免于当前任务的标注数据。

Conclusion: 该方法推动了可扩展、低资源、零样本NER的发展，通过有效组合多个小型本地LLM实现高性能，无需微调。

Abstract: Large Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates all tasks, motivating ensemble approaches. However, existing LLM ensembles focus on text generation or classification, leaving NER under-explored. In this context, this work proposes a novel three-step ensemble pipeline for zero-shot NER using similarly capable, locally run LLMs. Our method outperforms individual LLMs in four out of five Portuguese NER datasets by leveraging a heuristic to select optimal model combinations with minimal annotated data. Moreover, we show that ensembles obtained on different source datasets generally outperform individual LLMs in cross-dataset configurations, potentially eliminating the need for annotated data for the current task. Our work advances scalable, low-resource, and zero-shot NER by effectively combining multiple small LLMs without fine-tuning. Code is available at https://github.com/Joao-Luz/local-llm-ner-ensemble.

</details>


### [146] [Detailed balance in large language model-driven agents](https://arxiv.org/abs/2512.10047)
*Zhuo-Yang Song,Qing-Hong Cao,Ming-xing Luo,Hua Xing Zhu*

Main category: cs.LG

TL;DR: 本文提出基于最小作用量原理的方法，估计嵌入智能体中的大语言模型（LLM）生成方向性；实验发现LLM状态转移存在细致平衡，表明其生成机制可能依赖隐式学习的通用势函数，而非显式规则；这是首个与模型细节无关的LLM宏观物理规律发现，旨在推动AI智能体研究从工程实践走向可预测、可量化科学。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的智能体在实践中表现出色，但缺乏统一理解其宏观动力学行为的理论框架。

Method: 基于最小作用量原理，通过实验测量LLM生成状态间的转移概率，统计分析其动态特性。

Result: 发现了LLM生成过程中的细致平衡现象，表明其生成机制可能隐式学习了一类与架构和提示模板无关的底层势函数。

Conclusion: 首次揭示了不依赖具体模型细节的LLM生成动力学宏观物理规律，为构建复杂AI系统的宏观动力学理论提供了基础。

Abstract: Large language model (LLM)-driven agents are emerging as a powerful new paradigm for solving complex problems. Despite the empirical success of these practices, a theoretical framework to understand and unify their macroscopic dynamics remains lacking. This Letter proposes a method based on the least action principle to estimate the underlying generative directionality of LLMs embedded within agents. By experimentally measuring the transition probabilities between LLM-generated states, we statistically discover a detailed balance in LLM-generated transitions, indicating that LLM generation may not be achieved by generally learning rule sets and strategies, but rather by implicitly learning a class of underlying potential functions that may transcend different LLM architectures and prompt templates. To our knowledge, this is the first discovery of a macroscopic physical law in LLM generative dynamics that does not depend on specific model details. This work is an attempt to establish a macroscopic dynamics theory of complex AI systems, aiming to elevate the study of AI agents from a collection of engineering practices to a science built on effective measurements that are predictable and quantifiable.

</details>


### [147] [DB2-TransF: All You Need Is Learnable Daubechies Wavelets for Time Series Forecasting](https://arxiv.org/abs/2512.10051)
*Moulik Gupta,Achyut Mani Tripathi*

Main category: cs.LG

TL;DR: DB2-TransF 是一种新型 Transformer 变体，用可学习的 Daubechies 小波系数层替代自注意力机制，以降低计算复杂度并提升多尺度时序建模能力，在13个基准上实现了与传统 Transformer 相当或更优的预测精度，同时显著节省内存。


<details>
  <summary>Details</summary>
Motivation: 传统 Transformer 在时间序列预测中因自注意力的二次计算复杂度而面临可扩展性与资源效率瓶颈。

Method: 提出 DB2-TransF 架构，将自注意力替换为可学习的 Daubechies 小波系数层，以高效捕获多尺度局部与全局时序模式，并增强多变量间相关性建模。

Result: 在13个标准预测基准上，DB2-TransF 达到与主流 Transformer 相当或更优的预测精度，同时大幅降低内存占用。

Conclusion: DB2-TransF 是一种兼具高预测性能、强可扩展性与资源效率的时间序列预测新框架。

Abstract: Time series forecasting requires models that can efficiently capture complex temporal dependencies, especially in large-scale and high-dimensional settings. While Transformer-based architectures excel at modeling long-range dependencies, their quadratic computational complexity poses limitations on scalability and adaptability. To overcome these challenges, we introduce DB2-TransF, a novel Transformer-inspired architecture that replaces the self-attention mechanism with a learnable Daubechies wavelet coefficient layer. This wavelet-based module efficiently captures multi-scale local and global patterns and enhances the modeling of correlations across multiple time series for the time series forecasting task. Extensive experiments on 13 standard forecasting benchmarks demonstrate that DB2-TransF achieves comparable or superior predictive accuracy to conventional Transformers, while substantially reducing memory usage for the time series forecasting task. The obtained experimental results position DB2-TransF as a scalable and resource-efficient framework for advanced time series forecasting. Our code is available at https://github.com/SteadySurfdom/DB2-TransF

</details>


### [148] [Mitigating Exposure Bias in Risk-Aware Time Series Forecasting with Soft Tokens](https://arxiv.org/abs/2512.10056)
*Alireza Namazi,Amirreza Dolatpour Fathkouhi,Heman Shakeri*

Main category: cs.LG

TL;DR: 本文提出Soft-Token Trajectory Forecasting (SoTra)方法，通过传播连续概率分布（软令牌）缓解自回归预测中的暴露偏差，并结合风险感知解码模块最小化临床危害，在血糖和血压预测中显著降低临床风险。


<details>
  <summary>Details</summary>
Motivation: 标准教师强制训练的自回归模型存在暴露偏差，导致多步预测不稳定，难以用于闭环临床控制；不同操作区域具有不同临床风险，需风险感知的不确定性建模。

Method: SoTra方法使用软令牌（连续概率分布）替代硬离散token进行轨迹预测，缓解暴露偏差；引入风险感知解码模块，以最小化期望临床危害为目标进行解码。

Result: 在血糖预测中平均区域风险降低18%；在血压预测中有效临床风险降低约15%。

Conclusion: SoTra提升了预测的校准性与不确定性感知能力，适用于糖尿病和血流动力学管理等安全关键型预测控制场景。

Abstract: Autoregressive forecasting is central to predictive control in diabetes and hemodynamic management, where different operating zones carry different clinical risks. Standard models trained with teacher forcing suffer from exposure bias, yielding unstable multi-step forecasts for closed-loop use. We introduce Soft-Token Trajectory Forecasting (SoTra), which propagates continuous probability distributions (``soft tokens'') to mitigate exposure bias and learn calibrated, uncertainty-aware trajectories. A risk-aware decoding module then minimizes expected clinical harm. In glucose forecasting, SoTra reduces average zone-based risk by 18\%; in blood-pressure forecasting, it lowers effective clinical risk by approximately 15\%. These improvements support its use in safety-critical predictive control.

</details>


### [149] [\textsc{Text2Graph}: Combining Lightweight LLMs and GNNs for Efficient Text Classification in Label-Scarce Scenarios](https://arxiv.org/abs/2512.10061)
*João Lucas Luz Lima Sarcinelli,Ricardo Marcondes Marcacini*

Main category: cs.LG

TL;DR: 本文提出了Text2Graph，一个开源Python包，结合LLM零样本标注与GNN标签传播，以降低大规模文本分类的能耗和环境成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽在零样本分类中有效，但其高计算开销和环境代价限制了其在高性能计算（HPC）环境中大规模标注的应用；亟需更可持续的替代方案。

Method: 提出Text2Graph框架，模块化实现文本到图的分类方法：利用LLM生成初始标注，再通过图神经网络（GNN）进行标签传播；支持灵活替换特征提取器、边构建方法和采样策略。

Result: 在五个零样本文本分类数据集（涵盖主题分类与情感分析）上验证，Text2Graph在性能上媲美其他零样本方法，同时显著降低能耗与碳排放。

Conclusion: Text2Graph为可持续AI提供了一种高效、低耗的文本分类新范式，兼顾性能与环保，适用于HPC等资源敏感场景。

Abstract: Large Language Models (LLMs) have become effective zero-shot classifiers, but their high computational requirements and environmental costs limit their practicality for large-scale annotation in high-performance computing (HPC) environments. To support more sustainable workflows, we present \textsc{Text2Graph}, an open-source Python package that provides a modular implementation of existing text-to-graph classification approaches. The framework enables users to combine LLM-based partial annotation with Graph Neural Network (GNN) label propagation in a flexible manner, making it straightforward to swap components such as feature extractors, edge construction methods, and sampling strategies. We benchmark \textsc{Text2Graph} on a zero-shot setting using five datasets spanning topic classification and sentiment analysis tasks, comparing multiple variants against other zero-shot approaches for text classification. In addition to reporting performance, we provide detailed estimates of energy consumption and carbon emissions, showing that graph-based propagation achieves competitive results at a fraction of the energy and environmental cost.

</details>


### [150] [MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis](https://arxiv.org/abs/2512.10098)
*Midhat Urooj,Ayan Banerjee,Farhat Shaikh,Kuntal Thakur,Sandeep Gupta*

Main category: cs.LG

TL;DR: MedXAI是一个融合专家知识与深度视觉模型的可解释医学影像分类框架，旨在提升泛化能力、缓解罕见病类别偏差，并提供临床可理解的诊断特征定位解释。


<details>
  <summary>Details</summary>
Motivation: 解决医学AI中图像诊断在域偏移和罕见病类别下的准确性与可解释性难题，克服深度学习模型分布鲁棒性差、罕见病偏差大、缺乏临床可信解释等问题。

Method: 提出MedXAI框架，将深度视觉模型与医生定义的专家知识（符号化组件）相结合，通过诊断特征定位而非后验技术（如显著图、LIME）生成解释，并在多中心、多模态数据上进行验证。

Result: 在10个跨中心数据集上实验表明，MedXAI提升跨域泛化性能3%，罕见类F1分数提升10%，且消融实验证明符号组件作为临床先验有效增强了分布偏移下的鲁棒性。

Conclusion: MedXAI在保持高诊断性能的同时，提供了临床对齐的可解释性，尤其适用于罕见病和多模态医学AI场景，为安全关键临床部署提供了新范式。

Abstract: Accurate and interpretable image-based diagnosis remains a fundamental challenge in medical AI, particularly un- der domain shifts and rare-class conditions. Deep learning mod- els often struggle with real-world distribution changes, exhibit bias against infrequent pathologies, and lack the transparency required for deployment in safety-critical clinical environments. We introduce MedXAI (An Explainable Framework for Med- ical Imaging Classification), a unified expert knowledge based framework that integrates deep vision models with clinician- derived expert knowledge to improve generalization, reduce rare- class bias, and provide human-understandable explanations by localizing the relevant diagnostic features rather than relying on technical post-hoc methods (e.g., Saliency Maps, LIME). We evaluate MedXAI across heterogeneous modalities on two challenging tasks: (i) Seizure Onset Zone localization from resting-state fMRI, and (ii) Diabetic Retinopathy grading. Ex periments on ten multicenter datasets show consistent gains, including a 3% improvement in cross-domain generalization and a 10% improvmnet in F1 score of rare class, substantially outperforming strong deep learning baselines. Ablations confirm that the symbolic components act as effective clinical priors and regularizers, improving robustness under distribution shift. MedXAI delivers clinically aligned explanations while achieving superior in-domain and cross-domain performance, particularly for rare diseases in multimodal medical AI.

</details>


### [151] [CHyLL: Learning Continuous Neural Representations of Hybrid Systems](https://arxiv.org/abs/2512.10117)
*Sangli Teng,Hang Liu,Jingyu Song,Koushil Sreenath*

Main category: cs.LG

TL;DR: 本文提出CHyLL方法，通过将混合系统状态空间建模为分段光滑商流形，在隐空间中学习连续神经表示，避免轨迹分割、事件函数和模式切换，从而更准确地预测混合系统流并识别其拓扑不变量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在学习具有连续与离散时间动态的混合系统流时，因模式切换和流不连续性而表现不佳。

Method: CHyLL利用重置映射将状态空间在守卫面处‘粘合’，构造分段光滑商流形，使流在空间上连续；结合微分拓扑嵌入定理，同步学习无奇点的高维神经嵌入及其中的连续流。

Result: CHyLL能更准确地预测混合系统流，并可识别其拓扑不变量；还成功应用于随机最优控制问题。

Conclusion: CHyLL提供了一种无需显式建模离散事件即可建模混合系统的统一连续框架，提升了建模精度与泛化能力，并拓展至控制任务。

Abstract: Learning the flows of hybrid systems that have both continuous and discrete time dynamics is challenging. The existing method learns the dynamics in each discrete mode, which suffers from the combination of mode switching and discontinuities in the flows. In this work, we propose CHyLL (Continuous Hybrid System Learning in Latent Space), which learns a continuous neural representation of a hybrid system without trajectory segmentation, event functions, or mode switching. The key insight of CHyLL is that the reset map glues the state space at the guard surface, reformulating the state space as a piecewise smooth quotient manifold where the flow becomes spatially continuous. Building upon these insights and the embedding theorems grounded in differential topology, CHyLL concurrently learns a singularity-free neural embedding in a higher-dimensional space and the continuous flow in it. We showcase that CHyLL can accurately predict the flow of hybrid systems with superior accuracy and identify the topological invariants of the hybrid systems. Finally, we apply CHyLL to the stochastic optimal control problem.

</details>


### [152] [Partitioning the Sample Space for a More Precise Shannon Entropy Estimation](https://arxiv.org/abs/2512.10133)
*Gabriel F. A. Bastos,Jugurta Montalvão*

Main category: cs.LG

TL;DR: 本文提出了一种新的离散熵估计器，利用可分解性、缺失质量估计和未见结果数量估计来校正小样本下的负偏差，在欠采样场景下性能优于部分经典估计器，并与一些前沿方法相当。


<details>
  <summary>Details</summary>
Motivation: 在小数据集（样本数可能少于可能结果数）下可靠地数据驱动估计Shannon熵是多个应用中的关键问题。

Method: 提出一种基于可分解性性质的离散熵估计器，结合缺失质量估计和未见结果数量估计，以补偿由此引起的负偏差。

Result: 实验表明该方法在欠采样情形下优于若干经典估计器，并与一些成熟的前沿估计器性能相当。

Conclusion: 所提估计器能有效缓解小样本下熵估计的负偏差问题，是一种有竞争力的熵估计新方法。

Abstract: Reliable data-driven estimation of Shannon entropy from small data sets, where the number of examples is potentially smaller than the number of possible outcomes, is a critical matter in several applications. In this paper, we introduce a discrete entropy estimator, where we use the decomposability property in combination with estimations of the missing mass and the number of unseen outcomes to compensate for the negative bias induced by them. Experimental results show that the proposed method outperforms some classical estimators in undersampled regimes, and performs comparably with some well-established state-of-the-art estimators.

</details>


### [153] [Sequence-to-Image Transformation for Sequence Classification Using Rips Complex Construction and Chaos Game Representation](https://arxiv.org/abs/2512.10141)
*Sarwan Ali,Taslim Murad,Imdadullah Khan*

Main category: cs.LG

TL;DR: 本文提出了一种结合混沌游戏表示（CGR）与Rips复形的拓扑方法，将分子序列转化为图像，以克服传统特征工程稀疏性和深度学习在生物表格数据上表现不佳的问题；该方法在抗癌肽数据集上取得了优异准确率，并具备理论保证。


<details>
  <summary>Details</summary>
Motivation: 传统分子序列分类的特征工程存在稀疏性和计算复杂性问题，而深度学习模型在生物表格数据上常表现欠佳。

Method: 将分子序列通过混沌游戏表示（CGR）映射为2D坐标，计算两两距离并构建Rips复形，从而捕获局部结构与全局拓扑特征；并提供表示唯一性、拓扑稳定性与信息保持性的形式化保证。

Result: 在乳腺癌和肺癌抗癌肽数据集上分别达到86.8%和94.5%的准确率，优于向量法、序列语言模型及现有图像方法。

Conclusion: 该拓扑图像表示能保留关键序列信息，并有效支持视觉深度学习架构用于分子序列分析。

Abstract: Traditional feature engineering approaches for molecular sequence classification suffer from sparsity issues and computational complexity, while deep learning models often underperform on tabular biological data. This paper introduces a novel topological approach that transforms molecular sequences into images by combining Chaos Game Representation (CGR) with Rips complex construction from algebraic topology. Our method maps sequence elements to 2D coordinates via CGR, computes pairwise distances, and constructs Rips complexes to capture both local structural and global topological features. We provide formal guarantees on representation uniqueness, topological stability, and information preservation. Extensive experiments on anticancer peptide datasets demonstrate superior performance over vector-based, sequence language models, and existing image-based methods, achieving 86.8\% and 94.5\% accuracy on breast and lung cancer datasets, respectively. The topological representation preserves critical sequence information while enabling effective utilization of vision-based deep learning architectures for molecular sequence analysis.

</details>


### [154] [Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences](https://arxiv.org/abs/2512.10147)
*Sarwan Ali,Taslim Murad*

Main category: cs.LG

TL;DR: 本文提出了一种基于哈希的可扩展嵌入方法，用于快速、高效地表征SARS-CoV-2刺突蛋白序列，并实现高精度（86.4%）和极低计算开销（嵌入生成时间减少99.81%）的谱系分类。


<details>
  <summary>Details</summary>
Motivation: 现有系统发育树方法计算开销大、难以扩展至百万级序列；嵌入方法则常依赖多序列比对或存在预测性能差、运行时间长等问题，亟需更高效可扩展的替代方案。

Method: 针对主流SARS-CoV-2谱系的刺突蛋白序列，设计基于哈希的轻量级嵌入方法，生成低维紧凑表示，并结合多种机器学习模型进行监督式谱系分类。

Result: 在多项指标上显著优于基线及前沿生物序列嵌入方法：分类准确率达86.4%，嵌入生成时间最多降低99.81%。

Conclusion: 该哈希嵌入方法是一种快速、有效且高度可扩展的工具，适用于大规模病毒基因组序列分析与实时监测。

Abstract: Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today's multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4\% classification accuracy while reducing embedding generation time by as much as 99.81\%. This highlights the method's potential as a fast, effective, and scalable solution for large-scale viral sequence analysis.

</details>


### [155] [Rethinking Causal Discovery Through the Lens of Exchangeability](https://arxiv.org/abs/2512.10152)
*Tiago Brogueira,Mário Figueiredo*

Main category: cs.LG

TL;DR: 本文提出将传统的独立同分布（i.i.d.）因果发现范式重新定义为更一般的可交换性（exchangeability）框架，并论证其理论合理性与实证必要性；基于此构建仅满足可交换性假设的新型合成数据集，且该数据集更贴近真实‘i.i.d.’基准（如Tübingen数据集）的统计结构；进一步设计仅在此数据上训练的神经网络因果发现方法，在真实基准上达到与当前SOTA i.i.d. 方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现方法在i.i.d.和时间序列两种割裂范式下发展，但现实中许多所谓‘i.i.d.’数据（如Tübingen数据集）实际仅满足更弱的可交换性；作者指出可交换性是实验因果推断的基础，也应成为因果发现的统一建模基础。

Method: 从概念与实证两方面论证可交换性优于i.i.d.作为因果发现的基本假设；构造首个显式仅满足可交换性、不强制i.i.d.的合成因果数据集；设计并训练一个仅基于该数据集的神经网络因果发现模型。

Result: 实证表明主流i.i.d.方法隐含依赖可交换性；Tübingen数据集主体为可交换而非严格i.i.d.；所提合成数据集比现有i.i.d.合成数据更贴近Tübingen数据的统计结构；新训练的神经网络模型在Tübingen基准上性能媲美SOTA i.i.d.方法。

Conclusion: 可交换性是比i.i.d.更自然、更普适、更具现实基础的因果发现建模前提；以可交换性为基石可推动因果发现方法的理论统一与实践提升。

Abstract: Causal discovery methods have traditionally been developed under two distinct regimes: independent and identically distributed (i.i.d.) and timeseries data, each governed by separate modelling assumptions. In this paper, we argue that the i.i.d. setting can and should be reframed in terms of exchangeability, a strictly more general symmetry principle. We present the implications of this reframing, alongside two core arguments: (1) a conceptual argument, based on extending the dependency of experimental causal inference on exchangeability to causal discovery; and (2) an empirical argument, showing that many existing i.i.d. causal-discovery methods are predicated on exchangeability assumptions, and that the sole extensive widely-used real-world "i.i.d." benchmark (the Tübingen dataset) consists mainly of exchangeable (and not i.i.d.) examples. Building on this insight, we introduce a novel synthetic dataset that enforces only the exchangeability assumption, without imposing the stronger i.i.d. assumption. We show that our exchangeable synthetic dataset mirrors the statistical structure of the real-world "i.i.d." dataset more closely than all other i.i.d. synthetic datasets. Furthermore, we demonstrate the predictive capability of this dataset by proposing a neural-network-based causal-discovery algorithm trained exclusively on our synthetic dataset, and which performs similarly to other state-of-the-art i.i.d. methods on the real-world benchmark.

</details>


### [156] [CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for Geometry-Aware and Domain-Aligned Data Augmentation](https://arxiv.org/abs/2512.10178)
*Keito Inoshita,Xiaokang Zhou,Akira Kawai,Katsutoshi Yada*

Main category: cs.LG

TL;DR: 本文提出CIEGAD框架，通过聚类条件生成、层次化几何-频率分配、插值与外推合成及几何约束过滤结合LLM判别机制，实现面向分布覆盖、领域对齐与质量可控的数据增强，显著提升长尾与多类分类任务的F1和召回率。


<details>
  <summary>Details</summary>
Motivation: 实际深度学习部署中数据稀缺与标签分布不均衡导致语义未覆盖区域，引发边界误分类与边缘区域不稳定；现有LLM数据增强缺乏方向控制、领域对齐与质量控制的统一框架。

Method: 提出Cluster-conditioned Interpolative and Extrapolative framework for Geometry-Aware and Domain-aligned data augmentation（CIEGAD）：1）聚类构建领域轮廓；2）融合类别频率与几何指标的分层频率-几何分配策略；3）插值与外推协同控制生成方向；4）几何约束过滤+LLM-as-a-Judge进行质量控制。

Result: 在多个分类任务实验中，CIEGAD有效扩展真实数据分布边缘，保持生成数据与真实数据的高度对齐及语义多样性；在长尾与多类任务中持续提升F1与召回率，验证了分布一致性、多样性与质量三者的协同优化。

Conclusion: CIEGAD是一种面向实际应用的数据增强框架，能系统性填补语义未覆盖区域，同时兼顾领域对齐与生成质量，为数据稀缺与不均衡场景提供可靠解决方案。

Abstract: In practical deep learning deployment, the scarcity of data and the imbalance of label distributions often lead to semantically uncovered regions within the real-world data distribution, hindering model training and causing misclassification near class boundaries as well as unstable behaviors in peripheral areas. Although recent large language models (LLMs) show promise for data augmentation, an integrated framework that simultaneously achieves directional control of generation, domain alignment, and quality control has not yet been fully established. To address these challenges, we propose a Cluster-conditioned Interpolative and Extrapolative framework for Geometry-Aware and Domain-aligned data augmentation (CIEGAD), which systematically complements both in-distribution and out-of-distribution semantically uncovered regions. CIEGAD constructs domain profiles through cluster conditioning, allocates generation with a hierarchical frequency-geometric allocation integrating class frequency and geometric indicators, and finely controls generation directions via the coexistence of interpolative and extrapolative synthesis. It further performs quality control through geometry-constrained filtering combined with an LLM-as-a-Judge mechanism. Experiments on multiple classification tasks demonstrate that CIEGAD effectively extends the periphery of real-world data distributions while maintaining high alignment between generated and real-world data as well as semantic diversity. In particular, for long-tailed and multi-class classification tasks, CIEGAD consistently improves F1 and recall, validating the triple harmony of distributional consistency, diversity, and quality. These results indicate that CIEGAD serves as a practically oriented data augmentation framework that complements underrepresented regions while preserving alignment with real-world data.

</details>


### [157] [Assessing Neuromorphic Computing for Fingertip Force Decoding from Electromyography](https://arxiv.org/abs/2512.10179)
*Abolfazl Shahrooei,Luke Arthur,Om Patel,Derek Kamper*

Main category: cs.LG

TL;DR: 本文比较了脉冲神经网络（SNN）与时间卷积网络（TCN）在基于高密度表面肌电（HD-sEMG）解码指尖力任务中的性能，结果显示TCN精度更高，但SNN作为类脑基线具备进一步优化潜力。


<details>
  <summary>Details</summary>
Motivation: 高密度表面肌电（HD-sEMG）虽为无创神经接口，但将神经活动映射到用户运动意图仍具挑战性，需探索更适配神经信号特性的解码模型。

Method: 采用FastICA分解获取运动单元（MU）放电序列，构建基于重叠滑动窗的因果卷积端到端训练框架，对比评估SNN与TCN在单被试10次试验上的指尖力解码性能。

Result: TCN在预留试验上达到4.44% MVC RMSE（r = 0.974），SNN为8.25% MVC（r = 0.922）；TCN精度显著优于SNN。

Conclusion: TCN当前性能更优，但SNN作为类脑架构具有硬件友好、能效潜力等优势，经适度结构与超参调整有望大幅缩小性能差距。

Abstract: High-density surface electromyography (HD-sEMG) provides a noninvasive neural interface for assistive and rehabilitation control, but mapping neural activity to user motor intent remains challenging. We assess a spiking neural network (SNN) as a neuromorphic architecture against a temporal convolutional network (TCN) for decoding fingertip force from motor-unit (MU) firing derived from HD-sEMG. Data were collected from a single participant (10 trials) with two forearm electrode arrays; MU activity was obtained via FastICA-based decomposition, and models were trained on overlapping windows with end-to-end causal convolutions. On held-out trials, the TCN achieved 4.44% MVC RMSE (Pearson r = 0.974) while the SNN achieved 8.25% MVC (r = 0.922). While the TCN was more accurate, we view the SNN as a realistic neuromorphic baseline that could close much of this gap with modest architectural and hyperparameter refinements.

</details>


### [158] [MiniF2F-Dafny: LLM-Guided Mathematical Theorem Proving via Auto-Active Verification](https://arxiv.org/abs/2512.10187)
*Mantas Baksys,Stefan Zetzsche,Olivier Bouissou*

Main category: cs.LG

TL;DR: 本文介绍了miniF2F-Dafny，即首个将miniF2F数学推理基准翻译为自动定理证明器Dafny的版本，并评估了Dafny自动化及大语言模型（LLM）在其中提供证明提示的能力。


<details>
  <summary>Details</summary>
Motivation: 将数学推理基准miniF2F扩展至自动定理证明器Dafny，填补此前仅支持交互式定理证明器（如Lean、Isabelle等）的空白，并探索LLM与自动化工具协同证明的潜力。

Method: 将miniF2F翻译为Dafny格式；测试Dafny在无手动证明步骤（empty proofs）下的自动验证率；对未能自动验证的问题，使用12种现成LLM生成证明提示，并采用迭代错误修正策略评估其pass@4成功率。

Result: Dafny空证明在测试集和验证集上分别验证成功99/244（40.6%）和109/244（44.7%）；最佳LLM在迭代纠错下达到55.7% pass@4成功率。

Conclusion: LLM适合提供高层证明指导，而自动化工具擅长处理底层细节，二者可形成有效分工；miniF2F-Dafny为评估和推动LLM与ATP协同推理提供了新基准。

Abstract: We present miniF2F-Dafny, the first translation of the mathematical reasoning benchmark miniF2F to an automated theorem prover: Dafny. Previously, the benchmark existed only in interactive theorem provers (Lean, Isabelle, HOL Light, Metamath). We find that Dafny's automation verifies 99/244 (40.6%) of the test set and 109/244 (44.7%) of the validation set with empty proofs--requiring no manual proof steps. For problems where empty proofs fail, we evaluate 12 off-the-shelf LLMs on providing proof hints. The best model we test achieves 55.7% pass@4 success rate employing iterative error correction. These preliminary results highlight an effective division of labor: LLMs provide high-level guidance while automation handles low-level details. Our benchmark can be found on GitHub at http://github.com/dafny-lang/miniF2F .

</details>


### [159] [Exact Recovery of Non-Random Missing Multidimensional Time Series via Temporal Isometric Delay-Embedding Transform](https://arxiv.org/abs/2512.10191)
*Hao Shu,Jicheng Li,Yu Jin,Ling Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种基于时间等距延迟嵌入变换（TIDT）的低秩张量补全方法（LRTC-TIDT），用于处理多维时间序列中非随机缺失数据的恢复问题，理论证明其在满足一定采样与非相干性条件下可实现精确恢复，并在多个真实任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 非随机缺失数据广泛存在且严重影响多维时间序列分析的可靠性；传统低秩张量补全方法无法有效应对，而现有Hankel结构方法缺乏对低秩性来源的清晰解释和针对非随机缺失的精确恢复理论。

Method: 提出时间等距延迟嵌入变换（TIDT），构造由时间序列平滑性与周期性自然诱导低秩性的Hankel张量，并在t-SVD框架下建立LRTC-TIDT模型。

Result: 在满足非随机采样条件和轻度非相干假设下，LRTC-TIDT可实现精确恢复；仿真和多个真实任务（网络流量重建、城市交通估计、温度场预测）验证了其优越性。

Conclusion: LRTC-TIDT为非随机缺失的多维时间序列提供了具有理论保证且实用性强的恢复方法，开源代码已发布。

Abstract: Non-random missing data is a ubiquitous yet undertreated flaw in multidimensional time series, fundamentally threatening the reliability of data-driven analysis and decision-making. Pure low-rank tensor completion, as a classical data recovery method, falls short in handling non-random missingness, both methodologically and theoretically. Hankel-structured tensor completion models provide a feasible approach for recovering multidimensional time series with non-random missing patterns. However, most Hankel-based multidimensional data recovery methods both suffer from unclear sources of Hankel tensor low-rankness and lack an exact recovery theory for non-random missing data. To address these issues, we propose the temporal isometric delay-embedding transform, which constructs a Hankel tensor whose low-rankness is naturally induced by the smoothness and periodicity of the underlying time series. Leveraging this property, we develop the \textit{Low-Rank Tensor Completion with Temporal Isometric Delay-embedding Transform} (LRTC-TIDT) model, which characterizes the low-rank structure under the \textit{Tensor Singular Value Decomposition} (t-SVD) framework. Once the prescribed non-random sampling conditions and mild incoherence assumptions are satisfied, the proposed LRTC-TIDT model achieves exact recovery, as confirmed by simulation experiments under various non-random missing patterns. Furthermore, LRTC-TIDT consistently outperforms existing tensor-based methods across multiple real-world tasks, including network flow reconstruction, urban traffic estimation, and temperature field prediction. Our implementation is publicly available at https://github.com/HaoShu2000/LRTC-TIDT.

</details>


### [160] [Federated Domain Generalization with Latent Space Inversion](https://arxiv.org/abs/2512.10224)
*Ragja Palakkadavath,Hung Le,Thanh Nguyen-Tang,Svetha Venkatesh,Sunil Gupta*

Main category: cs.LG

TL;DR: 本文提出了一种新的联邦域泛化（FedDG）方法，通过潜在空间逆变换增强本地模型的域不变性以保护隐私，并设计重要权重聚合策略来保留非独立同分布客户端的关键局部适应特征，在保证隐私的同时提升泛化性能与通信效率。


<details>
  <summary>Details</summary>
Motivation: 现有FedDG方法在提升全局模型泛化能力的同时，因共享客户端数据统计信息而损害隐私；且在客户端非独立同分布时，传统模型聚合会丢失局部适应性。

Method: 提出潜在空间逆变换（latent space inversion）增强本地训练的域不变性与隐私保护；设计重要权重（important weight）聚合策略，优先聚合对本地预测影响显著的参数。

Result: 在多个基准数据集上超越现有最先进方法，同时降低通信开销。

Conclusion: 所提方法在不牺牲隐私的前提下，有效提升了联邦域泛化性能，兼顾了泛化性、隐私性与通信效率。

Abstract: Federated domain generalization (FedDG) addresses distribution shifts among clients in a federated learning framework. FedDG methods aggregate the parameters of locally trained client models to form a global model that generalizes to unseen clients while preserving data privacy. While improving the generalization capability of the global model, many existing approaches in FedDG jeopardize privacy by sharing statistics of client data between themselves. Our solution addresses this problem by contributing new ways to perform local client training and model aggregation. To improve local client training, we enforce (domain) invariance across local models with the help of a novel technique, \textbf{latent space inversion}, which enables better client privacy. When clients are not \emph{i.i.d}, aggregating their local models may discard certain local adaptations. To overcome this, we propose an \textbf{important weight} aggregation strategy to prioritize parameters that significantly influence predictions of local models during aggregation. Our extensive experiments show that our approach achieves superior results over state-of-the-art methods with less communication overhead.

</details>


### [161] [Adaptive Information Routing for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.10229)
*Jun Seo,Hyeokjun Choe,Seohui Bae,Soyeon Park,Wonbin Ahn,Taeyoon Lim,Junhyuk Kang,Sangjun Han,Jaehoon Lee,Dongwan Kang,Minjae Kim,Sungdong Yoo,Soonyoung Lee*

Main category: cs.LG

TL;DR: 本文提出了一种名为自适应信息路由（AIR）的新型多模态时间序列预测框架，利用文本数据动态引导时间序列模型，提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法仅依赖历史时序数据，在实际场景中因信息有限而难以保证准确预测；因此需要引入文本等多模态数据来增强预测能力。

Method: 提出AIR框架，通过文本信息动态调控多变量时间序列特征的融合方式与程度；设计基于大语言模型的文本精炼流程，并构建配套多模态预测基准。

Result: 在原油价格、汇率等真实金融市场数据上的实验表明，AIR能有效利用文本输入调节时序模型行为，显著提升多种时间序列预测任务的准确性。

Conclusion: AIR为多模态时间序列预测提供了新范式，强调文本作为控制信号而非简单辅助特征的作用，验证了其在真实场景中的有效性与实用性。

Abstract: Time series forecasting is a critical task for artificial intelligence with numerous real-world applications. Traditional approaches primarily rely on historical time series data to predict the future values. However, in practical scenarios, this is often insufficient for accurate predictions due to the limited information available. To address this challenge, multimodal time series forecasting methods which incorporate additional data modalities, mainly text data, alongside time series data have been explored. In this work, we introduce the Adaptive Information Routing (AIR) framework, a novel approach for multimodal time series forecasting. Unlike existing methods that treat text data on par with time series data as interchangeable auxiliary features for forecasting, AIR leverages text information to dynamically guide the time series model by controlling how and to what extent multivariate time series information should be combined. We also present a text-refinement pipeline that employs a large language model to convert raw text data into a form suitable for multimodal forecasting, and we introduce a benchmark that facilitates multimodal forecasting experiments based on this pipeline. Experiment results with the real world market data such as crude oil price and exchange rates demonstrate that AIR effectively modulates the behavior of the time series model using textual inputs, significantly enhancing forecasting accuracy in various time series forecasting tasks.

</details>


### [162] [R^2-HGP: A Double-Regularized Gaussian Process for Heterogeneous Transfer Learning](https://arxiv.org/abs/2512.10258)
*Duo Wang,Xinming Wang,Chao Wang,Xiaowei Yue,Jianguo Wu*

Main category: cs.LG

TL;DR: 本文提出了一种双正则化异构高斯过程框架（R²-HGP），通过可学习的先验概率映射对齐异构输入空间，并结合物理信息正则化与稀疏转移系数约束，以提升多源迁移学习中高斯过程模型的鲁棒性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决多输出高斯过程在异构迁移学习中面临的三大挑战：输入空间异构导致知识迁移困难、忽略物理先验知识导致映射不稳定、以及不恰当的信息共享引发负迁移。

Method: 提出R²-HGP框架：1）设计可训练先验概率映射模型对齐异构输入域；2）将对齐后的输入作为隐变量，构建基于条件变分自编码器（CVAE）的多源迁移GP模型；3）引入物理知识作为正则项约束对齐过程；4）在迁移系数上施加稀疏惩罚以自适应选择有效源任务并抑制负迁移。

Result: 在大量仿真与真实工程案例中，R²-HGP在各类评估指标上均持续优于现有最先进方法。

Conclusion: R²-HGP通过联合建模输入对齐、物理引导正则化与稀疏迁移控制，为异构多源迁移学习中的高斯过程建模提供了统一、鲁棒且可解释的解决方案。

Abstract: Multi-output Gaussian process (MGP) models have attracted significant attention for their flexibility and uncertainty-quantification capabilities, and have been widely adopted in multi-source transfer learning scenarios due to their ability to capture inter-task correlations. However, they still face several challenges in transfer learning. First, the input spaces of the source and target domains are often heterogeneous, which makes direct knowledge transfer difficult. Second, potential prior knowledge and physical information are typically ignored during heterogeneous transfer, hampering the utilization of domain-specific insights and leading to unstable mappings. Third, inappropriate information sharing among target and sources can easily lead to negative transfer. Traditional models fail to address these issues in a unified way. To overcome these limitations, this paper proposes a Double-Regularized Heterogeneous Gaussian Process framework (R^2-HGP). Specifically, a trainable prior probability mapping model is first proposed to align the heterogeneous input domains. The resulting aligned inputs are treated as latent variables, upon which a multi-source transfer GP model is constructed and the entire structure is integrated into a novel conditional variational autoencoder (CVAE) based framework. Physical insights is further incorporated as a regularization term to ensure that the alignment results adhere to known physical knowledge. Next, within the multi-source transfer GP model, a sparsity penalty is imposed on the transfer coefficients, enabling the model to adaptively select the most informative source outputs and suppress negative transfer. Extensive simulations and real-world engineering case studies validate the effectiveness of our R^2-HGP, demonstrating consistent superiority over state-of-the-art benchmarks across diverse evaluation metrics.

</details>


### [163] [A Kernel-based Resource-efficient Neural Surrogate for Multi-fidelity Prediction of Aerodynamic Field](https://arxiv.org/abs/2512.10287)
*Apurba Sarker,Reza T. Batley,Darshan Sarojini,Sourav Saha*

Main category: cs.LG

TL;DR: 本文提出了一种基于核的神经代理模型KHRONOS，融合高/低保真度气动数据，在资源受限条件下以更少参数、更快训练和推理速度实现与主流模型相当的预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统代理模型在资源受限（如高保真数据稀缺）条件下效率低、参数多；需兼顾气动场预测的精度与计算效率。

Method: 基于变分原理、插值理论和张量分解构建KHRONOS模型；融合AirfRANS（高保真）与NeuralFoil（低保真）数据；在不同高保真数据比例（0%/10%/30%）和几何复杂度下，对比MLP、GNN、PINN。

Result: KHRONOS在资源受限时显著优于对比模型：参数量少数个数量级，训练与推理更快，且表面压力系数预测精度相当。

Conclusion: KHRONOS为多保真气动场建模提供了一种高性价比新范式，验证了数学驱动稀疏神经架构在工程代理建模中的潜力。

Abstract: Surrogate models provide fast alternatives to costly aerodynamic simulations and are extremely useful in design and optimization applications. This study proposes the use of a recent kernel-based neural surrogate, KHRONOS. In this work, we blend sparse high-fidelity (HF) data with low-fidelity (LF) information to predict aerodynamic fields under varying constraints in computational resources. Unlike traditional approaches, KHRONOS is built upon variational principles, interpolation theory, and tensor decomposition. These elements provide a mathematical basis for heavy pruning compared to dense neural networks. Using the AirfRANS dataset as a high-fidelity benchmark and NeuralFoil to generate low-fidelity counterparts, this work compares the performance of KHRONOS with three contemporary model architectures: a multilayer perceptron (MLP), a graph neural network (GNN), and a physics-informed neural network (PINN). We consider varying levels of high-fidelity data availability (0%, 10%, and 30%) and increasingly complex geometry parameterizations. These are used to predict the surface pressure coefficient distribution over the airfoil. Results indicate that, whilst all models eventually achieve comparable predictive accuracy, KHRONOS excels in resource-constrained conditions. In this domain, KHRONOS consistently requires orders of magnitude fewer trainable parameters and delivers much faster training and inference than contemporary dense neural networks at comparable accuracy. These findings highlight the potential of KHRONOS and similar architectures to balance accuracy and efficiency in multi-fidelity aerodynamic field prediction.

</details>


### [164] [An Interpretable AI Tool for SAVR vs TAVR in Low to Intermediate Risk Patients with Severe Aortic Stenosis](https://arxiv.org/abs/2512.10308)
*Vasiliki Stoumpou,Maciej Tysarowski,Talhat Azemi,Jawad Haider,Howard L. Haronian,Robert C. Hagberg,Dimitris Bertsimas*

Main category: cs.LG

TL;DR: 本文提出了一种可解释的处方框架，结合预后匹配、反事实结果建模和最优策略树（OPT），为严重主动脉瓣狭窄患者个体化推荐SAVR或TAVR，以最小化5年死亡率；在两家医院数据上验证显示可显著降低估计死亡率，且决策边界符合临床实际。


<details>
  <summary>Details</summary>
Motivation: 临床上对低至中危重度主动脉瓣狭窄患者选择SAVR或TAVR仍存在异质性和机构偏好差异，现有模型缺乏可解释、个体化、直接优化长期结局的治疗推荐工具。

Method: 构建融合预后匹配、反事实死亡率估计与最优策略树（OPT）的可解释处方框架；基于Hartford与St. Vincent's医院真实世界数据，通过预后匹配和加权模拟随机化，估计每位患者接受SAVR或TAVR下的5年反事实死亡率，并训练OPT划分临床亚组并推荐低风险术式。

Result: 应用OPT推荐方案可在Hartford医院降低20.3%、St. Vincent's医院降低13.8%的5年死亡率（相较真实临床决策）；模型在外部机构数据上表现出良好泛化性，且学习到的决策边界与真实结局及临床观察一致。

Conclusion: 该框架是首个在内部和外部队列中均能提升预估长期预后的、透明且临床可解释的TAVR/SAVR个体化推荐方法，推动结构性心脏病领域向精准医学系统化、循证化发展。

Abstract: Background. Treatment selection for low to intermediate risk patients with severe aortic stenosis between surgical (SAVR) and transcatheter (TAVR) aortic valve replacement remains variable in clinical practice, driven by patient heterogeneity and institutional preferences. While existing models predict postprocedural risk, there is a lack of interpretable, individualized treatment recommendations that directly optimize long-term outcomes.
  Methods. We introduce an interpretable prescriptive framework that integrates prognostic matching, counterfactual outcome modeling, and an Optimal Policy Tree (OPT) to recommend the treatment minimizing expected 5-year mortality. Using data from Hartford Hospital and St. Vincent's Hospital, we emulate randomization via prognostic matching and sample weighting and estimate counterfactual mortality under both SAVR and TAVR. The policy model, trained on these counterfactual predictions, partitions patients into clinically coherent subgroups and prescribes the treatment associated with lower estimated risk.
  Findings. If the OPT prescriptions are applied, counterfactual evaluation showed an estimated reduction in 5-year mortality of 20.3\% in Hartford and 13.8\% in St. Vincent's relative to real-life prescriptions, showing promising generalizability to unseen data from a different institution. The learned decision boundaries aligned with real-world outcomes and clinical observations.
  Interpretation. Our interpretable prescriptive framework is, to the best of our knowledge, the first to provide transparent, data-driven recommendations for TAVR versus SAVR that improve estimated long-term outcomes both in an internal and external cohort, while remaining clinically grounded and contributing toward a more systematic and evidence-based approach to precision medicine in structural heart disease.

</details>


### [165] [Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation](https://arxiv.org/abs/2512.10925)
*Zamirddine Mari,Mohamad Motasem Nawaf,Pierre Drap*

Main category: cs.LG

TL;DR: 本文提出了一种基于PPO算法的深度强化学习方法，用于BlueROV2水下机器人在复杂环境中的自主导航，并在仿真与真实平台（结合3D数字孪生）上验证其优于传统DWA规划器的性能和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 水下环境缺乏GPS、能见度低且存在障碍物，导致自主导航困难；现有确定性方法（如DWA）在高度杂乱环境中适应性不足。

Method: 采用Proximal Policy Optimization（PPO）算法，构建融合目标导向信息、虚拟占据栅格与边界射线投射的观测空间，在仿真中训练策略，并通过3D数字孪生监督的物理BlueROV2进行真实验证。

Result: PPO策略在高度杂乱环境中显著优于DWA，表现为更强的局部适应能力和更少碰撞；且策略具备良好的仿真到实物迁移能力。

Conclusion: 深度强化学习（特别是PPO）是提升水下机器人复杂环境自主导航能力的有效途径，结合数字孪生可安全高效地实现从仿真到现实的部署。

Abstract: Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.

</details>


### [166] [A Privacy-Preserving Cloud Architecture for Distributed Machine Learning at Scale](https://arxiv.org/abs/2512.10341)
*Vinoth Punniyamoorthy,Ashok Gadi Parthi,Mayilsamy Palanigounder,Ravi Kiran Kodali,Bikesh Kumar,Kabilan Kannan*

Main category: cs.LG

TL;DR: 本文提出了一种云原生隐私保护架构，融合联邦学习、差分隐私、零知识合规证明和基于强化学习的自适应治理，支持跨多云环境的安全模型训练与推理，并通过原型验证了其在降低成员推断风险、保障隐私预算和维持模型性能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 分布式机器学习系统亟需强隐私保证、可验证的合规性以及在异构和多云环境中的可扩展部署能力。

Method: 构建一个集成联邦学习、差分隐私、零知识合规证明和强化学习驱动的自适应治理机制的云原生隐私保护架构，并在混合Kubernetes集群上实现完整原型。

Result: 实验表明该架构能有效降低成员推断风险，严格遵守形式化隐私预算，保持稳定模型性能，同时维持高模型效用并引入最小开销，实现持续的风险感知治理。

Conclusion: 所提框架为大规模部署可信且合规的分布式机器学习系统提供了实用基础。

Abstract: Distributed machine learning systems require strong privacy guarantees, verifiable compliance, and scalable deploy- ment across heterogeneous and multi-cloud environments. This work introduces a cloud-native privacy-preserving architecture that integrates federated learning, differential privacy, zero- knowledge compliance proofs, and adaptive governance powered by reinforcement learning. The framework supports secure model training and inference without centralizing sensitive data, while enabling cryptographically verifiable policy enforcement across institutions and cloud platforms. A full prototype deployed across hybrid Kubernetes clusters demonstrates reduced membership- inference risk, consistent enforcement of formal privacy budgets, and stable model performance under differential privacy. Ex- perimental evaluation across multi-institution workloads shows that the architecture maintains utility with minimal overhead while providing continuous, risk-aware governance. The pro- posed framework establishes a practical foundation for deploying trustworthy and compliant distributed machine learning systems at scale.

</details>


### [167] [Decoupled Q-Chunking](https://arxiv.org/abs/2512.10926)
*Qiyang Li,Seohong Park,Sergey Levine*

Main category: cs.LG

TL;DR: 本文提出了一种解耦策略与评论家（critic）动作块长度的新算法，通过构建针对部分动作块的蒸馏评论家来优化策略，在保持多步值传播优势的同时，避免了开环策略次优性和长动作块建模困难的问题。


<details>
  <summary>Details</summary>
Motivation: TD方法存在自举偏差问题；chunked critics虽加速值备份，但其开环策略在需要反应性的环境中表现不佳且难以建模长动作块。

Method: 解耦策略与评论家的动作块长度，设计基于原始chunked critic乐观回溯构建的、针对部分动作块的蒸馏critic，用于策略优化。

Result: 在具有挑战性的长视野离线目标导向任务上，该方法稳定优于先前方法。

Conclusion: 解耦critic与policy的chunk长度并引入蒸馏partial-chunk critic，是兼顾多步价值传播效率与策略反应性的有效途径。

Abstract: Temporal-difference (TD) methods learn state and action values efficiently by bootstrapping from their own future value predictions, but such a self-bootstrapping mechanism is prone to bootstrapping bias, where the errors in the value targets accumulate across steps and result in biased value estimates. Recent work has proposed to use chunked critics, which estimate the value of short action sequences ("chunks") rather than individual actions, speeding up value backup. However, extracting policies from chunked critics is challenging: policies must output the entire action chunk open-loop, which can be sub-optimal for environments that require policy reactivity and also challenging to model especially when the chunk length grows. Our key insight is to decouple the chunk length of the critic from that of the policy, allowing the policy to operate over shorter action chunks. We propose a novel algorithm that achieves this by optimizing the policy against a distilled critic for partial action chunks, constructed by optimistically backing up from the original chunked critic to approximate the maximum value achievable when a partial action chunk is extended to a complete one. This design retains the benefits of multi-step value propagation while sidestepping both the open-loop sub-optimality and the difficulty of learning action chunking policies for long action chunks. We evaluate our method on challenging, long-horizon offline goal-conditioned tasks and show that it reliably outperforms prior methods. Code: github.com/ColinQiyangLi/dqc.

</details>


### [168] [Dynamics of Agentic Loops in Large Language Models: A Geometric Theory of Trajectories](https://arxiv.org/abs/2512.10350)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 本文提出了一种几何框架，用于分析基于大语言模型的智能体系统在语义嵌入空间中的迭代轨迹行为，区分了文本变换的‘产物空间’与几何分析的‘嵌入空间’；通过各向同性校准修正余弦相似度偏差，从而精确刻画收敛型（收缩）与发散型（探索）两类基本动力学模式，并揭示提示词设计可系统调控智能体循环的动力学行为。


<details>
  <summary>Details</summary>
Motivation: 现有研究对基于大语言模型的智能体系统中递归反馈环（即输出作为下一轮输入）的几何行为（如收敛、发散或复杂动态）缺乏深入理解。

Method: 构建几何分析框架，将智能体迭代视为离散动力系统；区分artifact space（语言变换发生处）与embedding space（几何度量处）；提出isotonic calibration方法消除嵌入各向异性导致的余弦相似度偏差；在受控实验中分析单一智能体循环的轨迹、聚类与吸引子特性。

Result: 发现两种基本动力学机制：contractive rewriting loop（收缩式重写循环）趋于稳定吸引子且分散度递减；exploratory summarize and negate loop（探索式摘要与否定循环）呈现无界发散、无聚类形成；二者具有显著不同的几何收缩/扩张特征；提示工程可直接决定智能体循环所属的动力学机制。

Conclusion: 提示词设计能系统性控制大语言模型迭代变换的动力学行为（收敛/发散/轨迹结构），该几何框架为理解和调控智能体系统提供了新范式。

Abstract: Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.

</details>


### [169] [GPG: Generalized Policy Gradient Theorem for Transformer-based Policies](https://arxiv.org/abs/2512.10365)
*Hangyu Mao,Guangting Dong,Zhicheng Dou*

Main category: cs.LG

TL;DR: 本文提出了适用于Transformer架构策略的广义策略梯度（GPG）定理，统一了标准策略梯度定理与GRPO，并探讨其在大语言模型训练中的应用。


<details>
  <summary>Details</summary>
Motivation: 为统一和扩展现有策略梯度方法，特别是适配Transformer架构的策略优化需求，提升大语言模型训练效率。

Method: 提出广义策略梯度（GPG）定理，通过理论推导证明其涵盖标准策略梯度定理与GRPO作为特例，并将其应用于LLM策略优化。

Result: 验证了GPG定理的理论一致性与泛化能力，并展示了其在LLM训练中提供更高效策略优化的新路径。

Conclusion: GPG定理为基于Transformer的策略学习提供了统一、灵活且实用的理论框架，推动强化学习与大模型训练的深度融合。

Abstract: We present the Generalized Policy Gradient (GPG) Theorem, specifically designed for Transformer-based policies. Notably, we demonstrate that both standard Policy Gradient Theorem and GRPO emerge as special cases within our GPG framework. Furthermore, we explore its practical applications in training Large Language Models (LLMs), offering new insights into efficient policy optimization.

</details>


### [170] [Fitting magnetization data using continued fraction of straight lines](https://arxiv.org/abs/2512.10390)
*Vijay Prakash S*

Main category: cs.LG

TL;DR: 本文提出了一种用直线连分式近似铁磁材料磁化非线性行为的方法，并用于解释磁畴生长与收缩过程中的非线性现象。


<details>
  <summary>Details</summary>
Motivation: 铁磁材料磁化响应具有非线性，源于磁畴在外部磁场下逐步对齐的微观机制，需更有效的数学模型描述该非线性。

Method: 采用直线连分式（continued fraction of straight lines）作为非线性函数的近似形式，并通过非线性回归估计模型参数。

Result: 所提连分式模型能有效拟合磁化曲线，成功解释磁畴在磁场增强和减弱过程中动态演化引起的非线性行为。

Conclusion: 直线连分式是一种灵活且可解析的代数工具，适用于建模和分析铁磁材料中磁畴演化驱动的非线性磁化特性。

Abstract: Magnetization of a ferromagnetic substance in response to an externally applied magnetic field increases with the strength of the field. This is because at the microscopic level, magnetic moments in certain regions or domains of the substance increasingly align with the applied field, while the amount of misaligned domains decreases. The alignment of such magnetic domains with an applied magnetic field forms the physical basis for the nonlinearity of magnetization. In this paper, the nonlinear function is approximated as a combination of continued fraction of straight lines. The resulting fit is used to interpret the nonlinear behavior in both growing and shrinking magnetic domains. The continued fraction of straight lines used here is an algebraic expression which can be used to estimate parameters using nonlinear regression.

</details>


### [171] [The Eminence in Shadow: Exploiting Feature Boundary Ambiguity for Robust Backdoor Attacks](https://arxiv.org/abs/2512.10402)
*Zhou Feng,Jiahao Chen,Chunyi Zhou,Yuwen Pu,Tianyu Du,Jinbao Li,Jianhai Chen,Shouling Ji*

Main category: cs.LG

TL;DR: 本文提出Eminence框架，通过理论分析揭示稀疏决策边界如何被少量后门样本操控，并设计出具有可解释性、鲁棒性和隐蔽性的黑盒后门攻击方法，仅需低于0.1%的投毒率即可实现高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击依赖启发式暴力搜索，缺乏理论支撑，限制了对其机制、可预测性与适应性的理解。

Method: 基于稀疏决策边界的理论分析，推导出模糊边界区域的闭式表达；利用影响函数量化边缘样本引起的参数偏移；据此设计通用、视觉隐晦的触发器，构建Eminence黑盒后门框架。

Result: Eminence在<0.1%极低投毒率下实现>90%攻击成功率，干净准确率损失可忽略，且具备跨模型、数据集和场景的高迁移性；实验证实边缘投毒与对抗边界操控呈指数关系。

Conclusion: 稀疏决策边界是后门攻击高效性的关键理论根源；Eminence首次为黑盒后门攻击提供了可证明的理论保证与内在隐蔽性。

Abstract: Deep neural networks (DNNs) underpin critical applications yet remain vulnerable to backdoor attacks, typically reliant on heuristic brute-force methods. Despite significant empirical advancements in backdoor research, the lack of rigorous theoretical analysis limits understanding of underlying mechanisms, constraining attack predictability and adaptability. Therefore, we provide a theoretical analysis targeting backdoor attacks, focusing on how sparse decision boundaries enable disproportionate model manipulation. Based on this finding, we derive a closed-form, ambiguous boundary region, wherein negligible relabeled samples induce substantial misclassification. Influence function analysis further quantifies significant parameter shifts caused by these margin samples, with minimal impact on clean accuracy, formally grounding why such low poison rates suffice for efficacious attacks. Leveraging these insights, we propose Eminence, an explainable and robust black-box backdoor framework with provable theoretical guarantees and inherent stealth properties. Eminence optimizes a universal, visually subtle trigger that strategically exploits vulnerable decision boundaries and effectively achieves robust misclassification with exceptionally low poison rates (< 0.1%, compared to SOTA methods typically requiring > 1%). Comprehensive experiments validate our theoretical discussions and demonstrate the effectiveness of Eminence, confirming an exponential relationship between margin poisoning and adversarial boundary manipulation. Eminence maintains > 90% attack success rate, exhibits negligible clean-accuracy loss, and demonstrates high transferability across diverse models, datasets and scenarios.

</details>


### [172] [The Operator Origins of Neural Scaling Laws: A Generalized Spectral Transport Dynamics of Deep Learning](https://arxiv.org/abs/2512.10427)
*Yizhou Zhang*

Main category: cs.LG

TL;DR: 本文从梯度下降出发，推导出神经网络训练动力学的统一算子理论描述，提出一个谱输运-耗散偏微分方程，揭示了特征漂移、正则性保持与标度律之间的深层联系，并统一解释NTK训练与表征学习。


<details>
  <summary>Details</summary>
Motivation: 现代深度网络处于粗糙、有限正则性区域，其Jacobian算子谱呈重尾分布且基底发生显著漂移，传统线性化分析（如NTK）难以刻画真实训练动力学，亟需更普适的算子理论框架。

Method: 基于函数空间中误差的精确演化方程，运用Kato扰动理论导出耦合模态常微分方程组；经粗粒化处理得到谱输运-耗散PDE；结合弱耦合假设与自相似解分析，推导标度律与有效训练时间形式；并通过极限分析关联NTK与特征学习。

Result: 证明训练过程保持函数正则性，导致漂移速度渐近呈幂律形式；在弱耦合下PDE存在具分辨率前沿与幂律耗散的自相似解；给出双下降几何、标度律指数及有效训练时间τ(t)=t^αL(t)的显式刻画；统一解释NTK（v≡0）与特征学习（v≠0）为同一PDE的两个极限。

Conclusion: 该工作建立了连接算子几何、优化动力学与深度网络普适标度行为的统一谱框架，为理解现代神经网络训练本质提供了新范式。

Abstract: Modern deep networks operate in a rough, finite-regularity regime where Jacobian-induced operators exhibit heavy-tailed spectra and strong basis drift. In this work, we derive a unified operator-theoretoretic description of neural training dynamics directly from gradient descent. Starting from the exact evolution $\dot e_t = -M(t)e_t$ in function space, we apply Kato perturbation theory to obtain a rigorous system of coupled mode ODEs and show that, after coarse-graining, these dynamics converge to a spectral transport--dissipation PDE \[ \partial_t g + \partial_λ(v g) = -λg + S, \] where $v$ captures eigenbasis drift and $S$ encodes nonlocal spectral coupling.
  We prove that neural training preserves functional regularity, forcing the drift to take an asymptotic power-law form $v(λ,t)\sim -c(t)λ^b$. In the weak-coupling regime -- naturally induced by spectral locality and SGD noise -- the PDE admits self-similar solutions with a resolution frontier, polynomial amplitude growth, and power-law dissipation. This structure yields explicit scaling-law exponents, explains the geometry of double descent, and shows that the effective training time satisfies $τ(t)=t^αL(t)$ for slowly varying $L$.
  Finally, we show that NTK training and feature learning arise as two limits of the same PDE: $v\equiv 0$ recovers lazy dynamics, while $v\neq 0$ produces representation drift. Our results provide a unified spectral framework connecting operator geometry, optimization dynamics, and the universal scaling behavior of modern deep networks.

</details>


### [173] [Metacognitive Sensitivity for Test-Time Dynamic Model Selection](https://arxiv.org/abs/2512.10451)
*Le Tuan Minh Trinh,Le Minh Vu Pham,Thi Minh Anh Pham,An Duc Nguyen*

Main category: cs.LG

TL;DR: 本文提出了一种基于人类认知科学的AI元认知评估框架，引入心理基础指标meta-d'来衡量模型置信度与准确率的一致性，并利用该指标指导测试时的模型选择，从而提升整体推理准确率。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型虽然能输出预测置信度，但常存在校准差的问题（即置信度不能真实反映其能力），因此需要一种更可靠的方式来评估模型是否‘知道自己知道什么’。

Method: 提出meta-d'作为元认知敏感性指标，并构建基于多臂赌博机（bandit）的仲裁器，在测试时依据meta-d'动态选择最优专家模型进行推理。

Result: 在多个数据集和多种深度学习模型组合（CNN、VLM等）上的实验表明，该元认知方法能显著提升联合推理准确率。

Conclusion: 将模型集成选择建模为同时考虑短期信号（置信度）与中期特征（元认知敏感性）的问题，为AI行为建模提供了新视角。

Abstract: A key aspect of human cognition is metacognition - the ability to assess one's own knowledge and judgment reliability. While deep learning models can express confidence in their predictions, they often suffer from poor calibration, a cognitive bias where expressed confidence does not reflect true competence. Do models truly know what they know? Drawing from human cognitive science, we propose a new framework for evaluating and leveraging AI metacognition. We introduce meta-d', a psychologically-grounded measure of metacognitive sensitivity, to characterise how reliably a model's confidence predicts its own accuracy. We then use this dynamic sensitivity score as context for a bandit-based arbiter that performs test-time model selection, learning which of several expert models to trust for a given task. Our experiments across multiple datasets and deep learning model combinations (including CNNs and VLMs) demonstrate that this metacognitive approach improves joint-inference accuracy over constituent models. This work provides a novel behavioural account of AI models, recasting ensemble selection as a problem of evaluating both short-term signals (confidence prediction scores) and medium-term traits (metacognitive sensitivity).

</details>


### [174] [Hybrid Physics-ML Model for Forward Osmosis Flux with Complete Uncertainty Quantification](https://arxiv.org/abs/2512.10457)
*Shiv Ratn,Shivang Rampriyan,Bahni Ray*

Main category: cs.LG

TL;DR: 本文提出了一种鲁棒的混合物理-机器学习框架，利用高斯过程回归（GPR）建模正向渗透（FO）过程中的水通量（Jw），通过拟合物理模型与实验数据之间的残差，并融合模型与输入不确定性量化，实现了高精度、可解释且具不确定性的预测。


<details>
  <summary>Details</summary>
Motivation: 传统机理模型参数依赖性强、泛化能力差；纯数据驱动模型缺乏物理解释性且难以进行严格不确定性量化（UQ）。

Method: 构建基于GPR的混合模型，以物理模型预测值与实测水通量的残差为训练目标；采用Delta法解析传播多变量相关输入的不确定性，结合GPR后验方差实现总预测方差（σ²_total）的分解（认知+偶然不确定性）。

Result: 仅用120个数据点训练，在独立测试集上达到MAPE=0.26%、R²=0.999的性能，显著优于现有方法。

Conclusion: 该鲁棒混合框架兼顾物理一致性与数据驱动精度，支持小样本下的高置信度预测，适用于FO工艺优化与数字孪生构建。

Abstract: Forward Osmosis (FO) is a promising low-energy membrane separation technology, but challenges in accurately modelling its water flux (Jw) persist due to complex internal mass transfer phenomena. Traditional mechanistic models struggle with empirical parameter variability, while purely data-driven models lack physical consistency and rigorous uncertainty quantification (UQ). This study introduces a novel Robust Hybrid Physics-ML framework employing Gaussian Process Regression (GPR) for highly accurate, uncertainty-aware Jw prediction. The core innovation lies in training the GPR on the residual error between the detailed, non-linear FO physical model prediction (Jw_physical) and the experimental water flux (Jw_actual). Crucially, we implement a full UQ methodology by decomposing the total predictive variance (sigma2_total) into model uncertainty (epistemic, from GPR's posterior variance) and input uncertainty (aleatoric, analytically propagated via the Delta method for multi-variate correlated inputs). Leveraging the inherent strength of GPR in low-data regimes, the model, trained on a meagre 120 data points, achieved a state-of-the-art Mean Absolute Percentage Error (MAPE) of 0.26% and an R2 of 0.999 on the independent test data, validating a truly robust and reliable surrogate model for advanced FO process optimization and digital twin development.

</details>


### [175] [T-SKM-Net: Trainable Neural Network Framework for Linear Constraint Satisfaction via Sampling Kaczmarz-Motzkin Method](https://arxiv.org/abs/2512.10461)
*Haoyu Zhu,Yao Zhang,Jiashen Ren,Qingchun Hou*

Main category: cs.LG

TL;DR: 本文提出了一种可训练的采样Kaczmarz-Motzkin网络（T-SKM-Net），首次将SKM类算法系统性地融入神经网络约束满足中，通过零空间变换和可微近似实现高效、可端到端训练的混合约束求解，在DCOPF任务上显著提速且零约束违反。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络约束满足方法在效率与适用性之间存在权衡，硬约束方法常面临高计算复杂度或对约束结构的强假设；而经典SKM算法虽收敛性好，但其argmax操作不可微，难以嵌入神经网络。

Method: 提出T-SKM-Net框架：1）用零空间变换将混合约束（等式+不等式）转为纯不等式系统；2）嵌入SKM迭代求解；3）映射回原约束空间；4）设计无偏梯度估计器保障端到端可训练性。

Result: 在DCOPF case118基准上，后处理模式达4.27ms/样本（GPU串行）、最大最优性间隙0.0025%；联合训练模式为5.25ms/样本、最大最优性间隙0.0008%；相较pandapower求解器提速超25倍，且约束违反率为零（给定容差内）。

Conclusion: T-SKM-Net成功弥合了随机迭代优化算法与深度学习之间的可微性鸿沟，为安全关键场景下的实时、可靠神经约束求解提供了新范式。

Abstract: Neural network constraint satisfaction is crucial for safety-critical applications such as power system optimization, robotic path planning, and autonomous driving. However, existing constraint satisfaction methods face efficiency-applicability trade-offs, with hard constraint methods suffering from either high computational complexity or restrictive assumptions on constraint structures. The Sampling Kaczmarz-Motzkin (SKM) method is a randomized iterative algorithm for solving large-scale linear inequality systems with favorable convergence properties, but its argmax operations introduce non-differentiability, posing challenges for neural network applications. This work proposes the Trainable Sampling Kaczmarz-Motzkin Network (T-SKM-Net) framework and, for the first time, systematically integrates SKM-type methods into neural network constraint satisfaction. The framework transforms mixed constraint problems into pure inequality problems through null space transformation, employs SKM for iterative solving, and maps solutions back to the original constraint space, efficiently handling both equality and inequality constraints. We provide theoretical proof of post-processing effectiveness in expectation and end-to-end trainability guarantees based on unbiased gradient estimators, demonstrating that despite non-differentiable operations, the framework supports standard backpropagation. On the DCOPF case118 benchmark, our method achieves 4.27ms/item GPU serial forward inference with 0.0025% max optimality gap with post-processing mode and 5.25ms/item with 0.0008% max optimality gap with joint training mode, delivering over 25$\times$ speedup compared to the pandapower solver while maintaining zero constraint violations under given tolerance.

</details>


### [176] [UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning](https://arxiv.org/abs/2512.10492)
*Jiaxi Wu,Tiantian Zhang,Yuxing Wang,Yongzhe Chang,Xueqian Wang*

Main category: cs.LG

TL;DR: 本文提出UACER方法，通过多样化评论家集成和时变衰减不确定性机制，提升对抗强化学习中策略的鲁棒性与训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗强化学习中，可训练对手导致环境非平稳，引发训练不稳定和收敛困难，尤其在高维复杂环境中。

Method: 提出UACER：1）多样化评论家集成，使用K个独立评论家网络并行估计Q值以降低方差、增强鲁棒性；2）基于认知不确定性驱动的时变衰减不确定性（TDU）机制，动态调节探索-利用权衡并稳定训练。

Result: 在多个MuJoCo控制任务上，UACER在整体性能、训练稳定性和效率方面均优于当前最优方法。

Conclusion: UACER通过引入不确定性感知的评论家集成架构，有效缓解了对抗训练中的非平稳性问题，为鲁棒强化学习提供了新思路。

Abstract: Robust adversarial reinforcement learning has emerged as an effective paradigm for training agents to handle uncertain disturbance in real environments, with critical applications in sequential decision-making domains such as autonomous driving and robotic control. Within this paradigm, agent training is typically formulated as a zero-sum Markov game between a protagonist and an adversary to enhance policy robustness. However, the trainable nature of the adversary inevitably induces non-stationarity in the learning dynamics, leading to exacerbated training instability and convergence difficulties, particularly in high-dimensional complex environments. In this paper, we propose a novel approach, Uncertainty-Aware Critic Ensemble for robust adversarial Reinforcement learning (UACER), which consists of two strategies: 1) Diversified critic ensemble: a diverse set of K critic networks is exploited in parallel to stabilize Q-value estimation rather than conventional single-critic architectures for both variance reduction and robustness enhancement. 2) Time-varying Decay Uncertainty (TDU) mechanism: advancing beyond simple linear combinations, we develop a variance-derived Q-value aggregation strategy that explicitly incorporates epistemic uncertainty to dynamically regulate the exploration-exploitation trade-off while simultaneously stabilizing the training process. Comprehensive experiments across several MuJoCo control problems validate the superior effectiveness of UACER, outperforming state-of-the-art methods in terms of overall performance, stability, and efficiency.

</details>


### [177] [Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning](https://arxiv.org/abs/2512.10510)
*Chihyeon Song,Jaewoo Lee,Jinkyoo Park*

Main category: cs.LG

TL;DR: 本文提出了一种自适应重放缓冲区（ARB），通过轻量级的'on-policyness'指标动态调整离线与在线数据采样比例，无需额外学习过程，提升O2O RL算法的早期稳定性和最终性能。


<details>
  <summary>Details</summary>
Motivation: 解决离线到在线强化学习中固定数据混合比例难以兼顾早期学习稳定性与渐近性能的问题。

Method: 设计一种学习无关、易于实现的自适应重放缓冲区（ARB），基于'on-policyness'度量评估轨迹与当前策略的一致性，并据此为每个转移分配采样权重。

Result: 在D4RL基准上广泛实验表明，ARB能持续缓解早期性能下降，并显著提升多种O2O RL算法的最终性能。

Conclusion: 行为感知且自适应的重放缓冲区设计对O2O RL至关重要，ARB提供了一种简洁有效的新范式。

Abstract: Offline-to-Online Reinforcement Learning (O2O RL) faces a critical dilemma in balancing the use of a fixed offline dataset with newly collected online experiences. Standard methods, often relying on a fixed data-mixing ratio, struggle to manage the trade-off between early learning stability and asymptotic performance. To overcome this, we introduce the Adaptive Replay Buffer (ARB), a novel approach that dynamically prioritizes data sampling based on a lightweight metric we call 'on-policyness'. Unlike prior methods that rely on complex learning procedures or fixed ratios, ARB is designed to be learning-free and simple to implement, seamlessly integrating into existing O2O RL algorithms. It assesses how closely collected trajectories align with the current policy's behavior and assigns a proportional sampling weight to each transition within that trajectory. This strategy effectively leverages offline data for initial stability while progressively focusing learning on the most relevant, high-rewarding online experiences. Our extensive experiments on D4RL benchmarks demonstrate that ARB consistently mitigates early performance degradation and significantly improves the final performance of various O2O RL algorithms, highlighting the importance of an adaptive, behavior-aware replay buffer design.

</details>


### [178] [Disentangled and Distilled Encoder for Out-of-Distribution Reasoning with Rademacher Guarantees](https://arxiv.org/abs/2512.10522)
*Zahra Rahiminasab,Michael Yuhas,Arvind Easwaran*

Main category: cs.LG

TL;DR: 本文提出了一种名为解耦蒸馏编码器（DDE）的框架，旨在压缩用于多标签OOD检测的变分自编码器（VAE）编码器，在保持解耦性的同时减小模型尺寸，适用于资源受限设备。


<details>
  <summary>Details</summary>
Motivation: 现有基于VAE解耦隐空间的多标签OOD推理方法模型较大，难以部署于资源受限设备，需在压缩模型的同时保持解耦性。

Method: 提出DDE框架，将学生-教师知识蒸馏建模为带解耦性约束的优化问题，并基于Rademacher复杂度提供解耦性保持的理论保证。

Result: 实现了模型压缩，同时在经验评估中验证了压缩后模型仍能有效进行OOD推理，并成功部署于NVIDIA设备。

Conclusion: DDE能在显著减小模型规模的同时维持解耦表示能力，为边缘端OOD检测提供了可行方案。

Abstract: Recently, the disentangled latent space of a variational autoencoder (VAE) has been used to reason about multi-label out-of-distribution (OOD) test samples that are derived from different distributions than training samples. Disentangled latent space means having one-to-many maps between latent dimensions and generative factors or important characteristics of an image. This paper proposes a disentangled distilled encoder (DDE) framework to decrease the OOD reasoner size for deployment on resource-constrained devices while preserving disentanglement. DDE formalizes student-teacher distillation for model compression as a constrained optimization problem while preserving disentanglement with disentanglement constraints. Theoretical guarantees for disentanglement during distillation based on Rademacher complexity are established. The approach is evaluated empirically by deploying the compressed model on an NVIDIA

</details>


### [179] [Mode-Seeking for Inverse Problems with Diffusion Models](https://arxiv.org/abs/2512.10524)
*Sai Bharath Chandra Gutha,Ricardo Vinuesa,Hossein Azizpour*

Main category: cs.LG

TL;DR: 本文提出了一种新的变分模式寻找损失（VML），用于指导无条件扩散模型在反问题求解中逼近最大后验估计（MAP），在多个图像恢复任务上验证了其性能和计算效率的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练扩散模型的反问题求解方法依赖建模近似，且计算开销大；本文旨在设计一种无需任务微调、理论严谨且高效实用的MAP导向优化目标。

Method: 提出变分模式寻找损失（VML），源于最小化扩散后验p(x₀|xₜ)与测量后验p(x₀|y)之间的KL散度；对线性反问题可解析推导VML；在此基础上设计VML-MAP算法，在每步反向扩散中最小化VML以逼近MAP解。

Result: 在多种图像恢复任务（如去噪、超分辨、压缩感知等）和多个数据集上，VML-MAP在重建质量与计算速度两方面均优于现有后验采样与MAP方法。

Conclusion: VML为扩散模型求解反问题提供了新的理论视角和实用工具，VML-MAP是一种无需微调、解析可行、高效鲁棒的通用反问题求解框架。

Abstract: A pre-trained unconditional diffusion model, combined with posterior sampling or maximum a posteriori (MAP) estimation techniques, can solve arbitrary inverse problems without task-specific training or fine-tuning. However, existing posterior sampling and MAP estimation methods often rely on modeling approximations and can be computationally demanding. In this work, we propose the variational mode-seeking loss (VML), which, when minimized during each reverse diffusion step, guides the generated sample towards the MAP estimate. VML arises from a novel perspective of minimizing the Kullback-Leibler (KL) divergence between the diffusion posterior $p(\mathbf{x}_0|\mathbf{x}_t)$ and the measurement posterior $p(\mathbf{x}_0|\mathbf{y})$, where $\mathbf{y}$ denotes the measurement. Importantly, for linear inverse problems, VML can be analytically derived and need not be approximated. Based on further theoretical insights, we propose VML-MAP, an empirically effective algorithm for solving inverse problems, and validate its efficacy over existing methods in both performance and computational time, through extensive experiments on diverse image-restoration tasks across multiple datasets.

</details>


### [180] [Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders](https://arxiv.org/abs/2512.10547)
*Qingsen Ma,Dianyun Wang,Jiaming Lyu,Yaoye Wang,Lechen Ning,Sujie Zhu,Zhenbo Xu,Liuyu Xiang,Huining Li,Huijia Wu,Zhaofeng He*

Main category: cs.LG

TL;DR: 本文提出STA-Attention框架，利用Top-K稀疏自编码器（SAE）将KV缓存分解为可解释的“语义原子”，揭示Key与Value向量间的根本不对称性，并设计双预算策略在保持模型性能的同时提升可解释性。


<details>
  <summary>Details</summary>
Motivation: KV缓存是长上下文大语言模型的主要内存瓶颈，但通常被视为不透明的数值张量，缺乏可解释性；现有L1正则化SAE存在收缩偏差，破坏注意力所需的点积几何结构。

Method: 提出STA-Attention框架，采用Top-K稀疏自编码器替代标准L1正则化SAE以消除收缩偏差；发现Key-Value不对称性（Key高度稀疏、Value更稠密），并据此设计双预算策略，选择性保留关键语义成分并滤除表征噪声。

Result: 在Yi-6B、Mistral-7B、Qwen2.5-32B等多个模型上实验表明，语义重建后的模型在困惑度和零样本任务性能上与原始模型相当。

Conclusion: KV缓存具有可分解的语义结构，Top-K SAE能兼顾几何保真与可解释性，Key-Value不对称性为高效压缩与分析提供了新范式，弥合了机制可解释性与忠实注意力建模之间的鸿沟。

Abstract: The Key-Value (KV) cache is the primary memory bottleneck in long-context Large Language Models, yet it is typically treated as an opaque numerical tensor. In this work, we propose \textbf{STA-Attention}, a framework that utilizes Top-K Sparse Autoencoders (SAEs) to decompose the KV cache into interpretable ``semantic atoms.'' Unlike standard $L_1$-regularized SAEs, our Top-K approach eliminates shrinkage bias, preserving the precise dot-product geometry required for attention. Our analysis uncovers a fundamental \textbf{Key-Value Asymmetry}: while Key vectors serve as highly sparse routers dominated by a ``Semantic Elbow,'' deep Value vectors carry dense content payloads requiring a larger budget. Based on this structure, we introduce a Dual-Budget Strategy that selectively preserves the most informative semantic components while filtering representational noise. Experiments on Yi-6B, Mistral-7B, Qwen2.5-32B, and others show that our semantic reconstructions maintain perplexity and zero-shot performance comparable to the original models, effectively bridging the gap between mechanistic interpretability and faithful attention modeling.

</details>


### [181] [Asynchronous Reasoning: Training-Free Interactive Thinking LLMs](https://arxiv.org/abs/2512.10931)
*George Yakushev,Nataliia Babina,Masoud Vahid Dastgerdi,Vyacheslav Zhdanovskiy,Alina Shutova,Denis Kuznedelev*

Main category: cs.LG

TL;DR: 本文提出一种无需额外训练即可增强大语言模型（LLM）实时交互能力的方法，使其能边‘听’边‘想’边‘答’，显著降低响应延迟。


<details>
  <summary>Details</summary>
Motivation: 现有具备推理能力的LLM采用串行交互模式（先思考再回答），难以满足语音助手、嵌入式设备等需实时响应与动态适应的实际场景；而人类可异步并行地听、想、说，本文旨在让LLM模拟这一能力。

Method: 利用旋转位置编码（rotary embeddings）的特性，对已具备推理能力的LLM进行推理-生成解耦改造，使其在接收输入的同时持续思考并渐进式生成答案，无需重新训练。

Result: 在数学、常识和安全推理任务上验证有效：首非思考token延迟从分钟级降至≤5秒，整体实时延迟降低6–11倍，且保持答案准确性。

Conclusion: 该方法为提升LLM实时交互性提供了轻量、通用、免训练的新范式，弥合了强推理能力与低延迟需求之间的关键鸿沟。

Abstract: Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to <= 5s. and the overall real-time delays by 6-11x.

</details>


### [182] [Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning](https://arxiv.org/abs/2512.10573)
*Yi Huang,Qingyun Sun,Yisen Gao,Haonan Yuan,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: 本文提出LaT-IB方法，通过引入Minimal-Sufficient-Clean（MSC）准则和噪声感知的潜在解耦机制，提升信息瓶颈（IB）在标签噪声下的鲁棒性，并设计三阶段训练框架，在实验中展现出优异的抗噪性能。


<details>
  <summary>Details</summary>
Motivation: 标准信息瓶颈（IB）方法严重依赖准确标签，在真实场景中广泛存在的标签噪声下易导致性能下降与过拟合，亟需提升其抗噪能力。

Method: 提出LaT-IB方法，包含Minimal-Sufficient-Clean（MSC）互信息正则化准则、噪声感知的潜在表示解耦（分离清洁标签空间与噪声空间），以及Warmup、Knowledge Injection、Robust Training三阶段训练框架；并理论推导各目标项的互信息上下界，证明其促使表示对输入噪声不变且分离清洁与噪声标签信息。

Result: LaT-IB在多种标签噪声设定下显著提升模型鲁棒性与效率，实验验证其优于现有方法，增强IB在现实含噪场景中的适用性。

Conclusion: LaT-IB通过MSC准则与解耦建模有效缓解IB对标签噪声的敏感性，理论分析与实证结果共同证实其在鲁棒表示学习中的有效性与实用性。

Abstract: The Information Bottleneck (IB) principle facilitates effective representation learning by preserving label-relevant information while compressing irrelevant information. However, its strong reliance on accurate labels makes it inherently vulnerable to label noise, prevalent in real-world scenarios, resulting in significant performance degradation and overfitting. To address this issue, we propose LaT-IB, a novel Label-Noise ResistanT Information Bottleneck method which introduces a "Minimal-Sufficient-Clean" (MSC) criterion. Instantiated as a mutual information regularizer to retain task-relevant information while discarding noise, MSC addresses standard IB's vulnerability to noisy label supervision. To achieve this, LaT-IB employs a noise-aware latent disentanglement that decomposes the latent representation into components aligned with to the clean label space and the noise space. Theoretically, we first derive mutual information bounds for each component of our objective including prediction, compression, and disentanglement, and moreover prove that optimizing it encourages representations invariant to input noise and separates clean and noisy label information. Furthermore, we design a three-phase training framework: Warmup, Knowledge Injection and Robust Training, to progressively guide the model toward noise-resistant representations. Extensive experiments demonstrate that LaT-IB achieves superior robustness and efficiency under label noise, significantly enhancing robustness and applicability in real-world scenarios with label noise.

</details>


### [183] [Stronger Normalization-Free Transformers](https://arxiv.org/abs/2512.10938)
*Mingzhi Chen,Taiming Lu,Jiachen Zhu,Mingjie Sun,Zhuang Liu*

Main category: cs.LG

TL;DR: 本文提出了一种新的逐点函数Derf(x) = erf(αx + s)，在多个领域（视觉、语音、DNA建模）中超越了LayerNorm、RMSNorm和DyT，且不依赖归一化层，性能提升主要源于更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索比Dynamic Tanh（DyT）更优的、无需归一化层的逐点激活函数设计，以挑战归一化层在深度学习中不可或缺的传统认知。

Method: 分析逐点函数内在属性对训练与性能的影响，并开展大规模搜索，最终提出基于误差函数erf的Derf(x) = erf(αx + s)。

Result: Derf在图像识别与生成、语音表征、DNA序列建模等多个任务上均优于LayerNorm、RMSNorm和DyT；其优势主要来自泛化能力提升而非更强拟合能力。

Conclusion: Derf是一种简单而高效、可替代归一化层的逐点函数，为构建归一化无关的Transformer架构提供了实用新选择。

Abstract: Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\mathrm{Derf}(x) = \mathrm{erf}(αx + s)$, where $\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.

</details>


### [184] [THeGAU: Type-Aware Heterogeneous Graph Autoencoder and Augmentation](https://arxiv.org/abs/2512.10589)
*Ming-Yi Hong,Miao-Chen Chiang,Youchen Teng,Yu-Hsiang Wang,Chih-Yu Wang,Che Lin*

Main category: cs.LG

TL;DR: THeGAU是一种模型无关的异构图神经网络框架，通过类型感知图自编码器与引导式图增强联合优化，缓解类型信息丢失与结构噪声问题，在节点分类任务中实现高效、鲁棒且准确的性能提升。


<details>
  <summary>Details</summary>
Motivation: 异构图神经网络（HGNNs）在建模异构信息网络（HINs）时易出现类型信息丢失和结构噪声，影响表征保真度与泛化能力。

Method: 提出THeGAU框架：1）设计类型感知图自编码器，以重建符合schema的有效边为辅助任务，保留节点类型语义；2）引入解码器驱动的图增强机制，选择性地修正噪声结构。

Result: 在IMDB、ACM、DBLP三个基准HIN数据集上，THeGAU在多种骨干网络上均超越现有HGNN方法，达到SOTA性能，同时显著降低计算开销。

Conclusion: THeGAU通过联合优化类型语义保持与结构噪声抑制，提升了HGNN的鲁棒性、准确性与效率，验证了其模型无关性和实用性。

Abstract: Heterogeneous Graph Neural Networks (HGNNs) are effective for modeling Heterogeneous Information Networks (HINs), which encode complex multi-typed entities and relations. However, HGNNs often suffer from type information loss and structural noise, limiting their representational fidelity and generalization. We propose THeGAU, a model-agnostic framework that combines a type-aware graph autoencoder with guided graph augmentation to improve node classification. THeGAU reconstructs schema-valid edges as an auxiliary task to preserve node-type semantics and introduces a decoder-driven augmentation mechanism to selectively refine noisy structures. This joint design enhances robustness, accuracy, and efficiency while significantly reducing computational overhead. Extensive experiments on three benchmark HIN datasets (IMDB, ACM, and DBLP) demonstrate that THeGAU consistently outperforms existing HGNN methods, achieving state-of-the-art performance across multiple backbones.

</details>


### [185] [Multi-Objective Reward and Preference Optimization: Theory and Algorithms](https://arxiv.org/abs/2512.10601)
*Akhil Agnihotri*

Main category: cs.LG

TL;DR: 本文提出了一系列理论框架和算法，推动了约束强化学习在控制、偏好学习和大语言模型对齐中的发展，涵盖平均成本约束MDP、有限时域CMDP、基于人类偏好的RL以及大规模模型对齐。


<details>
  <summary>Details</summary>
Motivation: 解决约束强化学习在不同场景（如平均成本、有限时域、人类偏好建模、大模型对齐）下的理论与实践挑战，提升安全性与对齐性。

Method: 提出ACPO（平均约束策略优化）、e-COP（首个面向阶段式CMDP的策略优化方法）、warmPref-PS（融合离线异构评分者偏好的后验采样策略）、PSPL（联合采样奖励模型与转移动态的偏好学习算法）和MOPO（多目标约束优化对齐算法）。

Result: ACPO和e-COP在约束MDP中实现理论保证与SOTA性能；warmPref-PS与PSPL显著降低遗憾并提升偏好学习效率；MOPO可扩展至数十亿参数语言模型并在多种对齐任务中保持鲁棒性。

Conclusion: 该论文统一了平均成本、阶段式与偏好驱动三类约束强化学习范式，提供了兼具理论深度与工程实用性的安全决策与模型对齐新工具。

Abstract: This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion through the Average-Constrained Policy Optimization (ACPO) algorithm. ACPO integrates sensitivity analysis with trust-region updates to ensure stable constraint handling, achieving state-of-the-art empirical performance with theoretical guarantees. Constrained RL is then extended to finite-horizon settings via e-COP, the first policy optimization method for episodic CMDPs. Built on an episodic policy difference lemma, e-COP offers provable performance, simplicity, and scalability in safety-critical environments. The thesis then investigates reinforcement learning from human preferences. warmPref-PS introduces a posterior sampling strategy for linear bandits that integrates offline preference data from heterogeneous raters into online learning. Explicit modeling of rater competence yields substantial regret reduction and more efficient data collection for RLHF. The PSPL algorithm further advances preference-based RL by jointly sampling reward models and transition dynamics from pairwise trajectory comparisons, providing Bayesian simple-regret guarantees and robust empirical identification of optimal policies. The final contribution applies these methods to large-scale model alignment. A multi-objective constrained optimization view yields MOPO, an iterative algorithm with closed-form updates that scales to multi-billion-parameter language models and remains robust across alignment settings. Collectively, the thesis unifies constrained RL across average-cost, episodic, and preference-driven paradigms, delivering theoretical advances and practical tools for safe and aligned decision-making.

</details>


### [186] [Uncertainty-Preserving QBNNs: Multi-Level Quantization of SVI-Based Bayesian Neural Networks for Image Classification](https://arxiv.org/abs/2512.10602)
*Hendrik Borras,Yong Wu,Bernhard Klein,Holger Fröning*

Main category: cs.LG

TL;DR: 本文提出了一种面向变分推断贝叶斯神经网络（BNNs）的多级量化框架，包含三种量化策略（VPQ、SPQ、JQ），支持低至4比特的量化，在保持分类精度与不确定性解耦能力的同时实现高达8倍内存压缩，推动BNN在边缘设备上的部署。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯神经网络（BNNs）虽能提供原则性不确定性估计，但计算与内存开销大；而现有量化技术在确定性模型中成功，却尚未系统应用于概率模型。

Method: 提出多级量化框架，区分变分参数量化（VPQ）、采样参数量化（SPQ）和联合量化（JQ）；采用方差参数的对数量化及专用激活函数以保持分布结构。

Result: 在Dirty-MNIST上验证：4比特量化下仍保持分类准确率与不确定性解耦能力；JQ方案实现最高8倍内存压缩，且认知/偶然不确定性估计仅轻微退化。

Conclusion: 该量化框架使BNN可在资源受限边缘设备部署，并为未来低精度模拟‘贝叶斯机器’提供设计指南。

Abstract: Bayesian Neural Networks (BNNs) provide principled uncertainty quantification but suffer from substantial computational and memory overhead compared to deterministic networks. While quantization techniques have successfully reduced resource requirements in standard deep learning models, their application to probabilistic models remains largely unexplored. We introduce a systematic multi-level quantization framework for Stochastic Variational Inference based BNNs that distinguishes between three quantization strategies: Variational Parameter Quantization (VPQ), Sampled Parameter Quantization (SPQ), and Joint Quantization (JQ). Our logarithmic quantization for variance parameters, and specialized activation functions to preserve the distributional structure are essential for calibrated uncertainty estimation. Through comprehensive experiments on Dirty-MNIST, we demonstrate that BNNs can be quantized down to 4-bit precision while maintaining both classification accuracy and uncertainty disentanglement. At 4 bits, Joint Quantization achieves up to 8x memory reduction compared to floating-point implementations with minimal degradation in epistemic and aleatoric uncertainty estimation. These results enable deployment of BNNs on resource-constrained edge devices and provide design guidelines for future analog "Bayesian Machines" operating at inherently low precision.

</details>


### [187] [Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach](https://arxiv.org/abs/2512.10633)
*C. Bosco,U. Minora,D. de Rigo,J. Pingsdorf,R. Cortinovis*

Main category: cs.LG

TL;DR: 本文提出了一种混合方法，结合机器学习与移民专家的定性判断，以提升欧洲五大移民路线非法越境人数一年期预测的准确性，并支持欧盟《移民与庇护公约》及AMMR法规下的政策制定。


<details>
  <summary>Details</summary>
Motivation: 应对移民模式突变和传统数据局限性带来的预测挑战，满足欧盟《移民与庇护公约》中对精准、政策相关预测的需求。

Method: 融合机器学习模型与移民专家评估的人类协变量的混合方法论。

Result: 在已知数据上验证了该方法的适用性与可靠性，可支撑战略决策、早期预警系统及成员国间团结机制。

Conclusion: 该方法将数据驱动建模与专家判断相结合，为欧盟移民治理提供了新颖且具操作性的预测工具。

Abstract: This paper presents a mixed-methodology to forecast illegal border crossings in Europe across five key migratory routes, with a one-year time horizon. The methodology integrates machine learning techniques with qualitative insights from migration experts. This approach aims at improving the predictive capacity of data-driven models through the inclusion of a human-assessed covariate, an innovation that addresses challenges posed by sudden shifts in migration patterns and limitations in traditional datasets. The proposed methodology responds directly to the forecasting needs outlined in the EU Pact on Migration and Asylum, supporting the Asylum and Migration Management Regulation (AMMR). It is designed to provide policy-relevant forecasts that inform strategic decisions, early warning systems, and solidarity mechanisms among EU Member States. By joining data-driven modeling with expert judgment, this work aligns with existing academic recommendations and introduces a novel operational tool tailored for EU migration governance. The methodology is tested and validated with known data to demonstrate its applicability and reliability in migration-related policy context.

</details>


### [188] [Token Sample Complexity of Attention](https://arxiv.org/abs/2512.10656)
*Léa Bohbot,Cyril Letrouit,Gabriel Peyré,François-Xavier Vialard*

Main category: cs.LG

TL;DR: 本文研究了大语言模型中注意力机制在超长序列下的收敛行为，提出了token-sample复杂度的概念，并从注意力图的逐点一致收敛和变换后token分布的矩收敛两个层面给出了有限样本下的收敛速率估计。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型上下文窗口不断扩大，亟需刻画注意力机制在极端序列长度下的行为特征。

Method: 提出token-sample复杂度概念，理论分析注意力图在紧支集（及次高斯）分布下的逐点一致收敛速率，以及变换后token分布各阶矩的收敛速率；同时分析softmax趋近hardmax时的对数收敛速率，并通过合成高斯数据与BERT模型在维基文本上的实验验证理论结果。

Result: 1）注意力图在半径R球内以C(R)/√n速率一致收敛，C(R)随R指数增长；2）变换后token分布的矩以C'(R)/n^β（β<1/2）速率收敛，C'(R)关于支撑集大小多项式增长；3）softmax趋近hardmax时获得对数收敛速率；实验验证了理论预测。

Conclusion: 本文建立了注意力机制在长序列下的收敛性理论框架，揭示了收敛速率与分布支撑、注意力几何结构及谱性质之间的定量关系，为理解超长上下文建模能力提供了理论基础。

Abstract: As context windows in large language models continue to expand, it is essential to characterize how attention behaves at extreme sequence lengths. We introduce token-sample complexity: the rate at which attention computed on $n$ tokens converges to its infinite-token limit. We estimate finite-$n$ convergence bounds at two levels: pointwise uniform convergence of the attention map, and convergence of moments for the transformed token distribution. For compactly supported (and more generally sub-Gaussian) distributions, our first result shows that the attention map converges uniformly on a ball of radius $R$ at rate $C(R)/\sqrt{n}$, where $C(R)$ grows exponentially with $R$. For large $R$, this estimate loses practical value, and our second result addresses this issue by establishing convergence rates for the moments of the transformed distribution (the token output of the attention layer). In this case, the rate is $C'(R)/n^β$ with $β<\tfrac{1}{2}$, and $C'(R)$ depends polynomially on the size of the support of the distribution. The exponent $β$ depends on the attention geometry and the spectral properties of the tokens distribution. We also examine the regime in which the attention parameter tends to infinity and the softmax approaches a hardmax, and in this setting, we establish a logarithmic rate of convergence. Experiments on synthetic Gaussian data and real BERT models on Wikipedia text confirm our predictions.

</details>


### [189] [DCFO Additional Material](https://arxiv.org/abs/2512.10659)
*Tommaso Amico,Pernille Matthews,Lena Krieger,Arthur Zimek,Ira Assent*

Main category: cs.LG

TL;DR: 本文提出DCFO方法，为Local Outlier Factor（LOF）提供基于密度的反事实解释，通过划分数据空间实现高效梯度优化，在50个OpenML数据集上验证了其在反事实邻近性与有效性上的优越性。


<details>
  <summary>Details</summary>
Motivation: LOF作为广泛使用的无监督异常检测方法缺乏可解释性，而现有反事实解释方法未针对LOF等经典算法设计，难以满足对异常点成因理解、验证及偏差识别的实际需求。

Method: 提出Density-based Counterfactuals for Outliers（DCFO），将数据空间划分为LOF行为平滑的区域，支持基于梯度的高效优化以生成最小改动的反事实样本。

Result: 在50个OpenML数据集上的实验表明，DCFO在反事实的邻近性（proximity）和有效性（validity）方面持续优于基准方法。

Conclusion: DCFO有效提升了LOF模型的可解释性，为异常检测提供了首个专用于密度比型算法的高效、可靠反事实解释框架。

Abstract: Outlier detection identifies data points that significantly deviate from the majority of the data distribution. Explaining outliers is crucial for understanding the underlying factors that contribute to their detection, validating their significance, and identifying potential biases or errors. Effective explanations provide actionable insights, facilitating preventive measures to avoid similar outliers in the future. Counterfactual explanations clarify why specific data points are classified as outliers by identifying minimal changes required to alter their prediction. Although valuable, most existing counterfactual explanation methods overlook the unique challenges posed by outlier detection, and fail to target classical, widely adopted outlier detection algorithms. Local Outlier Factor (LOF) is one the most popular unsupervised outlier detection methods, quantifying outlierness through relative local density. Despite LOF's widespread use across diverse applications, it lacks interpretability. To address this limitation, we introduce Density-based Counterfactuals for Outliers (DCFO), a novel method specifically designed to generate counterfactual explanations for LOF. DCFO partitions the data space into regions where LOF behaves smoothly, enabling efficient gradient-based optimisation. Extensive experimental validation on 50 OpenML datasets demonstrates that DCFO consistently outperforms benchmarked competitors, offering superior proximity and validity of generated counterfactuals.

</details>


### [190] [Learning by Analogy: A Causal Framework for Composition Generalization](https://arxiv.org/abs/2512.10669)
*Lingjing Kong,Shaoan Xie,Yang Jiao,Yetian Chen,Yanhui Guo,Simone Shao,Yan Gao,Guangyi Chen,Kun Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于因果模块化和最小变化原则的层次化数据生成模型，以形式化实现组合泛化能力，并证明其潜在层次结构可从文本-图像对等可观测数据中可识别；理论与实验均验证了该方法在复杂概念组合关系建模及泛化性能上的提升。


<details>
  <summary>Details</summary>
Motivation: 组合泛化能力虽重要但其背后的数据结构与原理尚不清晰，亟需从理论上刻画其机制。

Method: 基于因果模块化与最小变化原则，构建一个能自然编码多层级概念及其交互机制的层次化数据生成过程，并从理论上证明该结构的可识别性。

Result: 理论层面：支持复杂概念关系的组合泛化，超越以往仅假设加性效应的模型；并证明潜在层次结构可从文本-图像对等观测数据中被唯一恢复。实验层面：在基准数据集上取得显著性能提升。

Conclusion: 组合泛化本质上依赖于将高层概念分解为可跨情境重组的底层概念，而因果模块化与层次化生成结构为此提供了可建模、可学习、可验证的理论基础。

Abstract: Compositional generalization -- the ability to understand and generate novel combinations of learned concepts -- enables models to extend their capabilities beyond limited experiences. While effective, the data structures and principles that enable this crucial capability remain poorly understood. We propose that compositional generalization fundamentally requires decomposing high-level concepts into basic, low-level concepts that can be recombined across similar contexts, similar to how humans draw analogies between concepts. For example, someone who has never seen a peacock eating rice can envision this scene by relating it to their previous observations of a chicken eating rice.
  In this work, we formalize these intuitive processes using principles of causal modularity and minimal changes. We introduce a hierarchical data-generating process that naturally encodes different levels of concepts and their interaction mechanisms. Theoretically, we demonstrate that this approach enables compositional generalization supporting complex relations between composed concepts, advancing beyond prior work that assumes simpler interactions like additive effects. Critically, we also prove that this latent hierarchical structure is provably recoverable (identifiable) from observable data like text-image pairs, a necessary step for learning such a generative process. To validate our theory, we apply insights from our theoretical framework and achieve significant improvements on benchmark datasets.

</details>


### [191] [HybridVFL: Disentangled Feature Learning for Edge-Enabled Vertical Federated Multimodal Classification](https://arxiv.org/abs/2512.10701)
*Mostafa Anoosha,Zeinab Dehghani,Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker*

Main category: cs.LG

TL;DR: This paper proposes HybridVFL, a vertical federated learning framework for edge AI that enhances privacy-preserving multimodal learning via client-side feature disentanglement and server-side cross-modal transformer fusion, achieving superior performance on the HAM10000 dataset.


<details>
  <summary>Details</summary>
Motivation: Standard VFL systems face performance bottlenecks in Edge AI (e.g., mobile health) due to simplistic feature fusion, especially when handling sensitive, distributed, multimodal data on resource-constrained devices.

Method: HybridVFL employs client-side feature disentanglement to extract modality-specific representations and a server-side cross-modal transformer for context-aware, privacy-preserving fusion of features across modalities.

Result: HybridVFL significantly outperforms standard federated baselines on the multimodal HAM10000 skin lesion dataset, demonstrating improved accuracy and robustness.

Conclusion: Advanced, context-aware fusion mechanisms—such as those in HybridVFL—are critical for achieving high performance in privacy-preserving, multimodal VFL systems for edge AI applications.

Abstract: Vertical Federated Learning (VFL) offers a privacy-preserving paradigm for Edge AI scenarios like mobile health diagnostics, where sensitive multimodal data reside on distributed, resource-constrained devices. Yet, standard VFL systems often suffer performance limitations due to simplistic feature fusion. This paper introduces HybridVFL, a novel framework designed to overcome this bottleneck by employing client-side feature disentanglement paired with a server-side cross-modal transformer for context-aware fusion. Through systematic evaluation on the multimodal HAM10000 skin lesion dataset, we demonstrate that HybridVFL significantly outperforms standard federated baselines, validating the criticality of advanced fusion mechanisms in robust, privacy-preserving systems.

</details>


### [192] [Beyond the Black Box: Identifiable Interpretation and Control in Generative Models via Causal Minimality](https://arxiv.org/abs/2512.10720)
*Lingjing Kong,Shaoan Xie,Guangyi Chen,Yuewen Sun,Xiangchen Song,Eric P. Xing,Kun Zhang*

Main category: cs.LG

TL;DR: 本文提出基于因果最小性原则的可解释生成模型理论框架，通过稀疏性或压缩约束使潜在表征具备因果可解释性和组件级可控性，并在扩散模型和自回归语言模型上验证了其提取层级概念图与细粒度操控的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有深度生成模型多为黑箱，缺乏可解释性与可控性；尽管稀疏自编码器等方法经验上有效，但缺乏理论保障，导致理解主观。

Method: 引入因果最小性原则，构建层级选择模型理论框架，通过理论推导的最小性条件（如稀疏性、压缩约束）实现潜在表征的因果识别与层级结构建模。

Result: 证明在最小性条件下学习到的表征等价于真实数据生成过程的潜变量；实证上成功从主流生成模型中提取出内在层级概念图，并实现细粒度因果导向的模型操控。

Conclusion: 因果最小性为可解释生成模型提供了坚实理论基础，使潜空间具备清晰因果语义与鲁棒可操控性，推动透明、可信AI系统的发展。

Abstract: Deep generative models, while revolutionizing fields like image and text generation, largely operate as opaque black boxes, hindering human understanding, control, and alignment. While methods like sparse autoencoders (SAEs) show remarkable empirical success, they often lack theoretical guarantees, risking subjective insights. Our primary objective is to establish a principled foundation for interpretable generative models. We demonstrate that the principle of causal minimality -- favoring the simplest causal explanation -- can endow the latent representations of diffusion vision and autoregressive language models with clear causal interpretation and robust, component-wise identifiable control. We introduce a novel theoretical framework for hierarchical selection models, where higher-level concepts emerge from the constrained composition of lower-level variables, better capturing the complex dependencies in data generation. Under theoretically derived minimality conditions (manifesting as sparsity or compression constraints), we show that learned representations can be equivalent to the true latent variables of the data-generating process. Empirically, applying these constraints to leading generative models allows us to extract their innate hierarchical concept graphs, offering fresh insights into their internal knowledge organization. Furthermore, these causally grounded concepts serve as levers for fine-grained model steering, paving the way for transparent, reliable systems.

</details>


### [193] [Generalized Spherical Neural Operators: Green's Function Formulation](https://arxiv.org/abs/2512.10723)
*Hao Tang,Hao Chen,Chao Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于可设计球面格林函数及其谐波展开的球面神经算子框架（GSNO），结合新型谱学习方法和分层网络GSHNet，在扩散MRI、浅水动力学和全球天气预报等任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有球面神经算子在保持旋转一致性与适应现实世界复杂性之间存在矛盾，缺乏兼顾几何保真与建模灵活性的统一框架。

Method: 提出基于可设计球面格林函数及其球谐展开的算子理论框架；构建位置依赖（绝对与相对）的格林函数以平衡等变性与不变性；设计GSNO算子及配套谱学习方法；开发融合多尺度谱建模与球面上下采样的分层网络GSHNet。

Result: 在扩散MRI、浅水动力学和全球天气预报三个真实球面任务上，GSNO与GSHNet持续超越当前最优方法。

Conclusion: GSNO为球面算子学习提供了兼具严格理论基础与实际建模能力的通用框架，弥合理论严谨性与现实复杂性之间的鸿沟。

Abstract: Neural operators offer powerful approaches for solving parametric partial differential equations, but extending them to spherical domains remains challenging due to the need to preserve intrinsic geometry while avoiding distortions that break rotational consistency. Existing spherical operators rely on rotational equivariance but often lack the flexibility for real-world complexity. We propose a general operator-design framework based on the designable spherical Green's function and its harmonic expansion, establishing a solid operator-theoretic foundation for spherical learning. Based on this, we propose an absolute and relative position-dependent Green's function that enables flexible balance of equivariance and invariance for real-world modeling. The resulting operator, Green's-function Spherical Neural Operator (GSNO) with a novel spectral learning method, can adapt to anisotropic, constraint-rich systems while retaining spectral efficiency. To exploit GSNO, we develop GSHNet, a hierarchical architecture that combines multi-scale spectral modeling with spherical up-down sampling, enhancing global feature representation. Evaluations on diffusion MRI, shallow water dynamics, and global weather forecasting, GSNO and GSHNet consistently outperform state-of-the-art methods. Our results position GSNO as a principled and general framework for spherical operator learning, bridging rigorous theory with real-world complexity.

</details>


### [194] [LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation](https://arxiv.org/abs/2512.10735)
*Lin Du,Lu Bai,Jincheng Li,Lixin Cui,Hangyuan Du,Lichi Zhang,Yuting Chen,Zhao Li*

Main category: cs.LG

TL;DR: 本文提出了一种新型的线图聚合网络（LGAN），通过构建以每个节点为中心的诱导子图的线图来进行高阶聚合，从而在提升表达能力的同时降低计算复杂度，并增强模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于消息传递的GNN受限于1-WL测试的表达能力；k-WL类GNN虽能提升表达力但计算开销大，且难以支持细粒度归因（如Integrated Gradients），导致可解释性差。

Method: 提出Line Graph Aggregation Network（LGAN），利用节点中心诱导子图构造线图，在线图上进行高阶信息聚合；理论证明其表达力强于2-WL且时间复杂度更低。

Result: 在基准数据集上的实验表明，LGAN优于当前最先进的k-WL类GNN，同时具备更好的可解释性。

Conclusion: LGAN在保持较低计算成本的同时，显著提升了图神经网络的表达能力和可解释性，为高阶图学习提供了一种高效可行的新范式。

Abstract: Graph Neural Networks (GNNs) have emerged as a dominant paradigm for graph classification. Specifically, most existing GNNs mainly rely on the message passing strategy between neighbor nodes, where the expressivity is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Although a number of k-WL-based GNNs have been proposed to overcome this limitation, their computational cost increases rapidly with k, significantly restricting the practical applicability. Moreover, since the k-WL models mainly operate on node tuples, these k-WL-based GNNs cannot retain fine-grained node- or edge-level semantics required by attribution methods (e.g., Integrated Gradients), leading to the less interpretable problem. To overcome the above shortcomings, in this paper, we propose a novel Line Graph Aggregation Network (LGAN), that constructs a line graph from the induced subgraph centered at each node to perform the higher-order aggregation. We theoretically prove that the LGAN not only possesses the greater expressive power than the 2-WL under injective aggregation assumptions, but also has lower time complexity. Empirical evaluations on benchmarks demonstrate that the LGAN outperforms state-of-the-art k-WL-based GNNs, while offering better interpretability.

</details>


### [195] [Template-Free Retrosynthesis with Graph-Prior Augmented Transformers](https://arxiv.org/abs/2512.10770)
*Youjun Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种无需反应模板的、基于Transformer的无模板逆合成预测方法，通过将分子图信息融入注意力机制，并结合配对数据增强策略，在USPTO-50K数据集上达到模板自由方法中的最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有逆合成预测模型在准确性和鲁棒性上仍难以满足实际应用需求，且多依赖手工设计的反应模板或额外化学规则引擎。

Method: 提出一种模板自由的Transformer框架，将分子图信息注入注意力机制以联合利用SMILES序列和结构特征，并采用配对数据增强策略提升训练多样性与规模。

Result: 在USPTO-50K基准上，该方法在模板自由方法中达到最先进性能，并显著优于基础Transformer模型。

Conclusion: 融合图结构信息与数据增强的模板自由Transformer框架可有效提升逆合成预测的准确性与泛化能力，为实用化计算机辅助有机合成提供了新思路。

Abstract: Retrosynthesis reaction prediction seeks to infer plausible reactant molecules for a given product and is a central problem in computer-aided organic synthesis. Despite recent progress, many existing models still fall short of the accuracy and robustness required for practical deployment. This work studies a template-free, Transformer-based framework that eliminates reliance on handcrafted reaction templates or additional chemical rule engines. The model injects molecular graph information into the attention mechanism to jointly exploit \SMILES\ sequences and structural cues, and further applies a paired data augmentation strategy to enhance training diversity and scale. On the USPTO-50K benchmark, our proposed approach achieves state-of-the-art performance among template-free methods and substantially outperforming a vanilla Transformer baseline.

</details>


### [196] [UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting](https://arxiv.org/abs/2508.01426)
*Hang Ni,Weijia Zhang,Hao Liu*

Main category: cs.LG

TL;DR: 本文提出UniExtreme模型，通过自适应频率调制和事件先验增强模块，提升基础模型对多样化极端天气事件的预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有气象预报基础模型在预测极端天气事件方面能力有限，忽视了现实中多样化极端事件的大气模式特征。

Method: 提出UniExtreme模型，包含自适应频率调制（AFM）模块（利用可学习Beta分布滤波器与多粒度频谱聚合）和事件先验增强（EPA）模块（通过双层记忆融合网络引入区域特异性极端事件先验）。

Result: UniExtreme在极端天气与常规天气预报任务上均优于当前最优方法，展现出对多样化极端场景的强适应性。

Conclusion: UniExtreme通过建模极端事件的频谱差异与层级驱动机制，实现了通用极端天气预报能力的有效提升。

Abstract: Recent advancements in deep learning have led to the development of Foundation Models (FMs) for weather forecasting, yet their ability to predict extreme weather events remains limited. Existing approaches either focus on general weather conditions or specialize in specific-type extremes, neglecting the real-world atmospheric patterns of diversified extreme events. In this work, we identify two key characteristics of extreme events: (1) the spectral disparity against normal weather regimes, and (2) the hierarchical drivers and geographic blending of diverse extremes. Along this line, we propose UniExtreme, a universal extreme weather forecasting foundation model that integrates (1) an Adaptive Frequency Modulation (AFM) module that captures region-wise spectral differences between normal and extreme weather, through learnable Beta-distribution filters and multi-granularity spectral aggregation, and (2) an Event Prior Augmentation (EPA) module which incorporates region-specific extreme event priors to resolve hierarchical extreme diversity and composite extreme schema, via a dual-level memory fusion network. Extensive experiments demonstrate that UniExtreme outperforms state-of-the-art baselines in both extreme and general weather forecasting, showcasing superior adaptability across diverse extreme scenarios.

</details>


### [197] [Interpretable and Steerable Concept Bottleneck Sparse Autoencoders](https://arxiv.org/abs/2512.10805)
*Akshay Kulkarni,Tsui-Wei Weng,Vivek Narayanaswamy,Shusen Liu,Wesam A. Sakla,Kowshik Thopalli*

Main category: cs.LG

TL;DR: 本文提出Concept Bottleneck Sparse Autoencoders (CB-SAE)，通过剪枝低效神经元并引入用户定义概念瓶颈，显著提升稀疏自编码器在LVLMs和图像生成任务中的可解释性（+32.1%）与可操控性（+14.5%）。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器（SAEs）在LVLMs中虽有潜力，但多数学习到的特征缺乏可解释性或可操控性，且难以覆盖用户所需概念，限制了实际应用。

Method: 提出CB-SAE框架：1）设计两个轻量级指标评估可解释性与可操控性；2）系统分析LVLMs中SAE表现；3）剪枝低效神经元，并在潜空间中插入轻量级概念瓶颈以对齐用户定义概念集。

Result: CB-SAE在多个LVLMs和图像生成任务上实现可解释性提升32.1%、可操控性提升14.5%。

Conclusion: CB-SAE有效缓解了传统SAEs在可解释性、可操控性和概念覆盖方面的不足，为LLMs/LVLMs的机制可解释性与可控编辑提供了实用新路径。

Abstract: Sparse autoencoders (SAEs) promise a unified approach for mechanistic interpretability, concept discovery, and model steering in LLMs and LVLMs. However, realizing this potential requires that the learned features be both interpretable and steerable. To that end, we introduce two new computationally inexpensive interpretability and steerability metrics and conduct a systematic analysis on LVLMs. Our analysis uncovers two observations; (i) a majority of SAE neurons exhibit either low interpretability or low steerability or both, rendering them ineffective for downstream use; and (ii) due to the unsupervised nature of SAEs, user-desired concepts are often absent in the learned dictionary, thus limiting their practical utility. To address these limitations, we propose Concept Bottleneck Sparse Autoencoders (CB-SAE) - a novel post-hoc framework that prunes low-utility neurons and augments the latent space with a lightweight concept bottleneck aligned to a user-defined concept set. The resulting CB-SAE improves interpretability by +32.1% and steerability by +14.5% across LVLMs and image generation tasks. We will make our code and model weights available.

</details>


### [198] [Extrapolation of Periodic Functions Using Binary Encoding of Continuous Numerical Values](https://arxiv.org/abs/2512.10817)
*Brian P. Powell,Jordan A. Caraballo-Vega,Mark L. Carroll,Thomas Maxwell,Andrew Ptak,Greg Olmschenk,Jorge Martinez-Palomera*

Main category: cs.LG

TL;DR: 本文提出了一种名为归一化二进制编码（NB2E）的输入编码方法，使普通多层感知机（MLP）无需先验知识即可外推多种周期信号。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络难以在训练范围之外外推周期函数的问题。

Method: 提出归一化二进制编码（NB2E）方法对连续数值进行编码，并结合普通多层感知机（MLP）进行实验验证。

Result: 使用NB2E编码后，MLP能成功外推多种周期信号；内部激活分析显示其诱导出比特相位表征，使模型可独立于位置学习并外推信号结构。

Conclusion: 二进制编码为神经网络外推周期函数提供了新思路，NB2E是一种简单而有效的编码方案。

Abstract: We report the discovery that binary encoding allows neural networks to extrapolate periodic functions beyond their training bounds. We introduce Normalized Base-2 Encoding (NB2E) as a method for encoding continuous numerical values and demonstrate that, using this input encoding, vanilla multi-layer perceptrons (MLP) successfully extrapolate diverse periodic signals without prior knowledge of their functional form. Internal activation analysis reveals that NB2E induces bit-phase representations, enabling MLPs to learn and extrapolate signal structure independently of position.

</details>


### [199] [Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments](https://arxiv.org/abs/2512.10835)
*Atahan Cilan,Atay Özgövde*

Main category: cs.LG

TL;DR: 本文提出了一种无需人类游戏数据的强化学习框架，通过在N维连续行为空间中采样目标行为向量并以距离缩减为奖励，实现对玩家行为（如攻击性、机动性、合作性）的可控、多样化建模；单个PPO多智能体策略即可泛化至未见行为风格。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量人类轨迹、需为不同玩家类型单独训练模型，或缺乏可解释行为参数与策略的直接映射，导致可扩展性和可控性受限。

Method: 定义N维连续行为空间，均匀采样覆盖真实人类风格的目标行为向量；训练时每个智能体同时输入当前和目标行为向量，奖励基于二者距离的归一化减少量；采用PPO构建多智能体策略。

Result: 在自定义Unity多人游戏中，该方法显著提升行为多样性，能可靠匹配多种指定行为向量，且单策略无需微调即可生成新或未见风格。

Conclusion: 该框架为自动化游戏测试、平衡性调试、类人行为模拟及在线游戏断连玩家替代提供了可扩展、高可控性的解决方案。

Abstract: This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping between interpretable behavioral parameters and the learned policy, limiting their scalability and controllability. We define player behavior in an N-dimensional continuous space and uniformly sample target behavior vectors from a region that encompasses the subset representing real human styles. During training, each agent receives both its current and target behavior vectors as input, and the reward is based on the normalized reduction in distance between them. This allows the policy to learn how actions influence behavioral statistics, enabling smooth control over attributes such as aggressiveness, mobility, and cooperativeness. A single PPO-based multi-agent policy can reproduce new or unseen play styles without retraining. Experiments conducted in a custom multi-player Unity game show that the proposed framework produces significantly greater behavioral diversity than a win-only baseline and reliably matches specified behavior vectors across diverse targets. The method offers a scalable solution for automated playtesting, game balancing, human-like behavior simulation, and replacing disconnected players in online games.

</details>


### [200] [Bayesian Symbolic Regression via Posterior Sampling](https://arxiv.org/abs/2512.10849)
*Geoffrey F. Bomarito,Patrick E. Leser*

Main category: cs.LG

TL;DR: 本文提出了一种基于序贯蒙特卡洛（SMC）的贝叶斯符号回归框架，通过近似符号表达式的后验分布，提升噪声下的鲁棒性与不确定性量化能力，并在噪声基准数据集上优于传统遗传编程方法。


<details>
  <summary>Details</summary>
Motivation: 符号回归对噪声敏感，限制了其在实际科学与工程中的广泛应用。

Method: 提出基于序贯蒙特卡洛（SMC）的贝叶斯符号回归框架，融合概率选择、自适应退火和归一化边缘似然，在符号表达式空间中高效搜索。

Result: 在含噪基准数据集上表现优于标准遗传编程基线，过拟合倾向降低，能更准确、可解释地发现控制方程。

Conclusion: 该方法提升了符号回归在噪声环境下的鲁棒性与可解释性，为科学发现与工程设计提供了更可靠的工具。

Abstract: Symbolic regression is a powerful tool for discovering governing equations directly from data, but its sensitivity to noise hinders its broader application. This paper introduces a Sequential Monte Carlo (SMC) framework for Bayesian symbolic regression that approximates the posterior distribution over symbolic expressions, enhancing robustness and enabling uncertainty quantification for symbolic regression in the presence of noise. Differing from traditional genetic programming approaches, the SMC-based algorithm combines probabilistic selection, adaptive tempering, and the use of normalized marginal likelihood to efficiently explore the search space of symbolic expressions, yielding parsimonious expressions with improved generalization. When compared to standard genetic programming baselines, the proposed method better deals with challenging, noisy benchmark datasets. The reduced tendency to overfit and enhanced ability to discover accurate and interpretable equations paves the way for more robust symbolic regression in scientific discovery and engineering design applications.

</details>


### [201] [Generative Modeling from Black-box Corruptions via Self-Consistent Stochastic Interpolants](https://arxiv.org/abs/2512.10857)
*Chirag Modi,Jiequn Han,Eric Vanden-Eijnden,Joan Bruna*

Main category: cs.LG

TL;DR: 本文提出了一种名为自洽随机插值（SCSI）的新方法，用于在仅有被噪声和病态信道污染的观测数据时，构建原始干净数据的生成模型。该方法基于随机插值，通过迭代更新传输映射来反演污染信道，在仅访问污染数据和黑箱污染信道的前提下实现高效、灵活且具理论保障的逆问题求解。


<details>
  <summary>Details</summary>
Motivation: 在许多科学与工程领域，难以获得干净数据，而只能获取经噪声和病态信道污染的测量数据；因此需要在分布层面求解逆问题以构建干净数据的生成模型。

Method: 基于随机插值（Stochastic Interpolants），设计一种迭代更新传输映射的方法，仅需污染数据集和对污染信道的黑箱访问，最终收敛到能有效反演污染信道的自洽传输映射。

Result: SCSI方法计算效率高于变分方法，适用于任意非线性前向模型（仅需黑箱访问），具备理论收敛保证，并在自然图像处理和科学重建等逆问题上展现出优越性能。

Conclusion: SCSI为带噪声和病态观测条件下的生成建模提供了一种高效、灵活且理论上可保证的新范式，拓展了传输型生成模型在实际科学与工程逆问题中的适用性。

Abstract: Transport-based methods have emerged as a leading paradigm for building generative models from large, clean datasets. However, in many scientific and engineering domains, clean data are often unavailable: instead, we only observe measurements corrupted through a noisy, ill-conditioned channel. A generative model for the original data thus requires solving an inverse problem at the level of distributions. In this work, we introduce a novel approach to this task based on Stochastic Interpolants: we iteratively update a transport map between corrupted and clean data samples using only access to the corrupted dataset as well as black box access to the corruption channel. Under appropriate conditions, this iterative procedure converges towards a self-consistent transport map that effectively inverts the corruption channel, thus enabling a generative model for the clean data. We refer to the resulting method as the self-consistent stochastic interpolant (SCSI). It (i) is computationally efficient compared to variational alternatives, (ii) highly flexible, handling arbitrary nonlinear forward models with only black-box access, and (iii) enjoys theoretical guarantees. We demonstrate superior performance on inverse problems in natural image processing and scientific reconstruction, and establish convergence guarantees of the scheme under appropriate assumptions.

</details>


### [202] [Scaling Behavior of Discrete Diffusion Language Models](https://arxiv.org/abs/2512.10858)
*Dimitri von Rütte,Janis Fluri,Omead Pooladzandi,Bernhard Schölkopf,Thomas Hofmann,Antonio Orvieto*

Main category: cs.LG

TL;DR: 本文研究离散扩散语言模型（DLMs）在不同噪声类型下的缩放行为，发现均匀扩散比掩码扩散更适用于数据受限场景，并训练出目前最大的公开均匀扩散模型（10B参数、10^22 FLOPs）。


<details>
  <summary>Details</summary>
Motivation: 离散扩散语言模型（DLMs）作为自回归语言模型（ALMs）的替代方案，其缩放规律尚未被充分探索；已有研究表明DLMs需更多数据和算力才能达到ALMs性能，因此需系统研究其缩放行为。

Method: 通过在掩码扩散与均匀扩散之间平滑插值来研究不同噪声类型的DLMs缩放行为，并严格控制批大小、学习率等关键超参数。

Result: 发现DLMs缩放行为高度依赖噪声类型：在计算受限下所有噪声类型收敛至相似损失；但在数据受限下，均匀扩散所需参数更多、数据更少，更具计算效率；最终将均匀扩散模型扩展至10B参数、训练耗能10^22 FLOPs。

Conclusion: 均匀扩散是数据受限场景下更具潜力的DLM架构，其缩放规律显著区别于ALMs，且本文构建了迄今最大公开均匀扩散模型。

Abstract: Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However, their scaling behavior has not yet been fully explored, with prior work suggesting that they require more data and compute to match the performance of ALMs.
  We study the scaling behavior of DLMs on different noise types by smoothly interpolating between masked and uniform diffusion while paying close attention to crucial hyperparameters such as batch size and learning rate. Our experiments reveal that the scaling behavior of DLMs strongly depends on the noise type and is considerably different from ALMs. While all noise types converge to similar loss values in compute-bound scaling, we find that uniform diffusion requires more parameters and less data for compute-efficient training compared to masked diffusion, making them a promising candidate in data-bound settings. We scale our uniform diffusion model up to 10B parameters trained for $10^{22}$ FLOPs, confirming the predicted scaling behavior and making it the largest publicly known uniform diffusion model to date.

</details>


### [203] [UrbanAI 2025 Challenge: Linear vs Transformer Models for Long-Horizon Exogenous Temperature Forecasting](https://arxiv.org/abs/2512.10866)
*Ruslan Gokhman*

Main category: cs.LG

TL;DR: 本文研究了仅使用室内温度历史值进行长期温度预测的挑战性单变量设置，比较了线性模型（Linear、NLinear、DLinear）与Transformer系列模型（Transformer、Informer、Autoformer）的性能，结果表明精心设计的线性模型（尤其是DLinear）在所有测试中均优于更复杂的Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 探索在缺乏外部变量（exogenous-only）的长期温度预测任务中，简单线性模型与复杂Transformer模型的相对有效性，验证线性模型作为强基线的价值。

Method: 在标准化训练/验证/测试划分下，系统评估Linear、NLinear、DLinear、Transformer、Informer和Autoformer六种模型在长周期室内温度单变量预测任务上的表现。

Result: 线性模型（尤其是DLinear）在所有数据划分上持续优于Transformer系列模型，DLinear取得最佳整体精度。

Conclusion: 在具有挑战性的外生变量仅限于历史目标值的长期预测任务中，精心设计的线性模型仍是强大且可靠的基线，复杂模型未必带来性能增益。

Abstract: We study long-horizon exogenous-only temperature forecasting - a challenging univariate setting where only the past values of the indoor temperature are used for prediction - using linear and Transformer-family models. We evaluate Linear, NLinear, DLinear, Transformer, Informer, and Autoformer under standardized train, validation, and test splits. Results show that linear baselines (Linear, NLinear, DLinear) consistently outperform more complex Transformer-family architectures, with DLinear achieving the best overall accuracy across all splits. These findings highlight that carefully designed linear models remain strong baselines for time series forecasting in challenging exogenous-only settings.

</details>


### [204] [Guided Transfer Learning for Discrete Diffusion Models](https://arxiv.org/abs/2512.10877)
*Julian Kleutgens,Claudio Battiloro,Lingkai Kong,Benjamin Grewe,Francesca Dominici,Mauricio Tec*

Main category: cs.LG

TL;DR: 本文提出了一种名为GTL（Guided Transfer Learning）的迁移学习方法，用于离散扩散模型，无需微调预训练去噪器即可实现目标分布采样，并设计了高效的引导采样器以降低大规模词汇和长序列下的计算开销。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型虽性能强，但依赖大量训练数据，跨域适配时获取数据成本高或存在风险；现有迁移方法需微调大模型，计算昂贵且不实用。

Method: 基于连续扩散的比率式迁移学习思想，提出适用于离散扩散（含离散时间与连续时间分数扩散）的统一引导迁移学习框架GTL；并设计高效引导采样器，仅在规划位置和候选词上集中计算。

Result: 在合成马尔可夫链和语言建模任务上验证了GTL有效性；显著降低采样计算量，使大规模词汇和长序列上的引导语言建模变得可行。

Conclusion: GTL为离散扩散模型提供了一种免微调、高效、通用的迁移学习方案，拓展了其在数据稀缺场景下的实用性。

Abstract: Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.

</details>


### [205] [Classifier Reconstruction Through Counterfactual-Aware Wasserstein Prototypes](https://arxiv.org/abs/2512.10878)
*Xuan Zhao,Zhuo Cao,Arya Bangun,Hanno Scharr,Ira Assent*

Main category: cs.LG

TL;DR: 本文提出了一种利用反事实样本（counterfactuals）提升代理模型重建质量的新方法，通过Wasserstein重心融合原始数据与反事实样本以逼近类原型，缓解决策边界偏移问题。


<details>
  <summary>Details</summary>
Motivation: 在标签数据受限场景下，如何高效利用反事实解释提升代理模型对黑盒目标模型的拟合保真度。

Method: 将反事实样本与原始数据结合，利用Wasserstein barycenter估计各类的原型分布，从而构建更鲁棒、分布感知的代理模型训练集。

Result: 在多个数据集上验证了该方法显著提升了代理模型与目标模型之间的保真度（fidelity），优于将反事实简单作为普通训练样本的基线方法。

Conclusion: 反事实样本虽代表性弱但信息丰富，合理建模其分布特性（如通过Wasserstein重心）可有效增强模型重建性能，尤其适用于低数据访问条件。

Abstract: Counterfactual explanations provide actionable insights by identifying minimal input changes required to achieve a desired model prediction. Beyond their interpretability benefits, counterfactuals can also be leveraged for model reconstruction, where a surrogate model is trained to replicate the behavior of a target model. In this work, we demonstrate that model reconstruction can be significantly improved by recognizing that counterfactuals, which typically lie close to the decision boundary, can serve as informative though less representative samples for both classes. This is particularly beneficial in settings with limited access to labeled data. We propose a method that integrates original data samples with counterfactuals to approximate class prototypes using the Wasserstein barycenter, thereby preserving the underlying distributional structure of each class. This approach enhances the quality of the surrogate model and mitigates the issue of decision boundary shift, which commonly arises when counterfactuals are naively treated as ordinary training instances. Empirical results across multiple datasets show that our method improves fidelity between the surrogate and target models, validating its effectiveness.

</details>


### [206] [Physics-Informed Learning of Flow Distribution and Receiver Heat Losses in Parabolic Trough Solar Fields](https://arxiv.org/abs/2512.10886)
*Stefan Matthes,Markus Schramm*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息的学习框架，利用夜间无辐照循环时段的数据，从常规运行数据中推断槽式光热电站集热回路的质量流量比和接收器传热系数，从而实现对水力不平衡和接收器退化的诊断。


<details>
  <summary>Details</summary>
Motivation: 槽式光热电站的集热回路存在光学性能、热损失和压降的空间异质性，但回路级质量流量和接收器热损参数无法直接观测，导致难以用常规监测手段诊断水力失衡或接收器老化。

Method: 构建一个可微分的共轭传热模型，并在夜间均质化时段（无太阳辐照下循环导热油）分离水力与热损失效应；将该模型离散化并嵌入端到端学习流程，利用Andasol 3电站50MW历史运行数据进行优化训练。

Result: 模型能准确重构回路温度（RMSE <2°C），并给出物理意义明确的质量流量不平衡和接收器热损失估计；与无人机红外热成像（QScan）对比验证，能准确识别所有高损耗接收器区域。

Conclusion: 结合恰当的物理建模与可微分优化，即使在噪声较大的真实CSP运行数据中，也能有效反演关键隐含物理参数，为电站状态监测与故障诊断提供了新范式。

Abstract: Parabolic trough Concentrating Solar Power (CSP) plants operate large hydraulic networks of collector loops that must deliver a uniform outlet temperature despite spatially heterogeneous optical performance, heat losses, and pressure drops. While loop temperatures are measured, loop-level mass flows and receiver heat-loss parameters are unobserved, making it impossible to diagnose hydraulic imbalances or receiver degradation using standard monitoring tools.
  We present a physics-informed learning framework that infers (i) loop-level mass-flow ratios and (ii) time-varying receiver heat-transfer coefficients directly from routine operational data. The method exploits nocturnal homogenization periods -- when hot oil is circulated through a non-irradiated field -- to isolate hydraulic and thermal-loss effects. A differentiable conjugate heat-transfer model is discretized and embedded into an end-to-end learning pipeline optimized using historical plant data from the 50 MW Andasol 3 solar field.
  The model accurately reconstructs loop temperatures (RMSE $<2^\circ$C) and produces physically meaningful estimates of loop imbalances and receiver heat losses. Comparison against drone-based infrared thermography (QScan) shows strong correspondence, correctly identifying all areas with high-loss receivers. This demonstrates that noisy real-world CSP operational data contain enough information to recover latent physical parameters when combined with appropriate modeling and differentiable optimization.

</details>


### [207] [SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale](https://arxiv.org/abs/2512.10922)
*Max Zimmer,Christophe Roux,Moritz Wagner,Deborah Hendrych,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 本文提出了一种高效、可扩展的1-swap剪枝算法，通过行级等稀疏约束和Gram矩阵计算最优权重交换，在LLM上显著降低逐层剪枝误差（最高达60%），提升困惑度与零样本准确率，且几乎无需调参。


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法（如全局幅度剪枝）在Transformer架构上效果不佳；而基于整数规划精确求解层内掩码选择问题在大模型上计算不可行，现有方法依赖近似或启发式，亟需更高效、精确的剪枝策略。

Method: 提出一种基于行级等稀疏约束的1-swap剪枝算法：先对每行强制统一稀疏度以解耦优化；再利用校准数据的Gram矩阵高效计算最优单次权重交换（即一个保留权与一个剪除权互换）；算法可从任意初始掩码热启动，支持GPU高效并行执行。

Result: 在多个先进GPT架构上，相比Wanda（2023），该方法将逐层剪枝误差最高降低60%，并一致改善语言建模困惑度与零样本任务准确率。

Conclusion: 通过理论简化与高效实现，本文使层内掩码选择问题在LLM规模下变得切实可解，为大模型高效剪枝提供了新范式——兼顾最优性、可扩展性与易用性。

Abstract: The resource requirements of Neural Networks can be significantly reduced through pruning -- the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.

</details>


### [208] [Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks](https://arxiv.org/abs/2512.10936)
*Kristina Korotkova,Aleksandr Katrutsa*

Main category: cs.LG

TL;DR: 本文提出使用改进的Frank-Wolfe方法（一种投影自由优化算法）构建高效的白盒对抗攻击，以评估神经网络的对抗鲁棒性，并在MNIST、CIFAR-10数据集及多种模型上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 评估神经网络的对抗鲁棒性需要快速有效的对抗攻击构造方法；而现有方法多依赖投影操作或几何直觉，计算开销大或适用性受限。

Method: 从数值优化角度出发，采用改进的Frank-Wolfe（投影自由）方法构造白盒对抗攻击，并进行理论分析与数值实验。

Result: 所提方法在MNIST和CIFAR-10数据集上，对逻辑回归、CNN和ViT模型均展现出高效性和竞争力，优于或媲美基于投影的标准方法。

Conclusion: 改进的Frank-Wolfe类方法是一种有前景的对抗攻击构造框架，兼顾效率、通用性与理论可解释性，适用于多种模型和任务。

Abstract: The construction of adversarial attacks for neural networks appears to be a crucial challenge for their deployment in various services. To estimate the adversarial robustness of a neural network, a fast and efficient approach is needed to construct adversarial attacks. Since the formalization of adversarial attack construction involves solving a specific optimization problem, we consider the problem of constructing an efficient and effective adversarial attack from a numerical optimization perspective. Specifically, we suggest utilizing advanced projection-free methods, known as modified Frank-Wolfe methods, to construct white-box adversarial attacks on the given input data. We perform a theoretical and numerical evaluation of these methods and compare them with standard approaches based on projection operations or geometrical intuition. Numerical experiments are performed on the MNIST and CIFAR-10 datasets, utilizing a multiclass logistic regression model, the convolutional neural networks (CNNs), and the Vision Transformer (ViT).

</details>


### [209] [Hierarchical Dataset Selection for High-Quality Data Sharing](https://arxiv.org/abs/2512.10952)
*Xiaona Zhou,Yingyan Zeng,Ran Jin,Ismini Lourentzou*

Main category: cs.LG

TL;DR: 本文提出了一种名为DaSH的新型数据集选择方法，通过在数据集和组（如机构、数据集合）两个层次上建模效用，以在资源受限下从异构数据池中高效选择最有价值的数据集，显著提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法通常只针对单个样本，忽视了不同数据集及其来源在相关性、质量和实用性上的差异，而实际场景中数据天然按来源分组成离散数据集，亟需一种能跨数据集进行选择的方法。

Method: 提出Dataset Selection via Hierarchies (DaSH)，在数据集和更高层的组（如机构或数据集合）两个粒度上建模数据效用，利用少量观测实现泛化，支持高效、可扩展的多源数据集选择。

Result: 在Digit-Five和DomainNet两个公开基准上，DaSH相比SOTA数据选择基线最高提升26.2%准确率，且所需探索步骤显著减少；消融实验表明其在低资源和缺乏相关数据集场景下仍具鲁棒性。

Conclusion: DaSH为多源学习中的数据集级选择提供了可扩展、自适应且高效的解决方案，弥补了传统样本级选择方法在现实异构数据环境中的关键缺陷。

Abstract: The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.

</details>


### [210] [Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953)
*Yiyang Lu,Qiao Sun,Xianbang Wang,Zhicheng Jiang,Hanhong Zhao,Kaiming He*

Main category: cs.LG

TL;DR: 本文提出Bidirectional Normalizing Flow（BiFlow），通过学习近似逆映射替代传统Normalizing Flow中严格可逆的前向变换，从而摆脱因果解码瓶颈，在ImageNet上显著提升生成质量并加速采样达两个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统Normalizing Flow受限于显式可逆性约束，而TARFlow等新方法虽引入Transformer和自回归流，却遭遇因果解码瓶颈，亟需更灵活的逆过程建模方式。

Method: 提出BiFlow框架，放弃要求前向变换具有精确解析逆，转而训练一个独立的、可学习的反向模型来近似噪声到数据的映射，并支持更灵活的损失函数与网络架构。

Result: 在ImageNet上实验表明，BiFlow相较因果解码基线，生成质量更高、采样速度快两个数量级，达到NF类方法最优性能，并在单步评估（1-NFE）方法中具备竞争力。

Conclusion: BiFlow成功解耦正向与反向建模，拓展了Normalizing Flow的设计自由度，验证了放弃严格可逆性仍可取得优异生成性能，为该经典范式注入新活力。

Abstract: Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation ("1-NFE") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.

</details>


### [211] [CC-GRMAS: A Multi-Agent Graph Neural System for Spatiotemporal Landslide Risk Assessment in High Mountain Asia](https://arxiv.org/abs/2510.20875)
*Mihir Panchal,Ying-Jung Chen,Surya Parkash*

Main category: cs.LG

TL;DR: 本文提出CC-GRMAS框架，利用多源卫星与环境数据，通过预测、规划、执行三代理协同，实现实时滑坡预警与响应，提升高山亚洲地区气候韧性防灾能力。


<details>
  <summary>Details</summary>
Motivation: 滑坡作为日益加剧的气候诱发灾害，在高海拔亚洲地区造成严重环境与人道影响；尽管卫星与时间序列数据日益丰富，但实时监测与应急响应仍滞后且碎片化。

Method: 构建CC-GRMAS多智能体框架，包含预测（Prediction）、规划（Planning）和执行（Execution）三个相互关联的智能体，融合卫星观测与本地环境信号，实现协同式实时态势感知、响应规划与干预。

Result: 该框架提升了滑坡预报准确性，支持实时灾害响应，并具备在脆弱山地环境中规模化部署与主动式气候适应防灾的能力。

Conclusion: CC-GRMAS为高风险山地地区提供了一种可扩展、协同化、前瞻性的滑坡灾害应对新范式，推动气候韧性基础设施建设。

Abstract: Landslides are a growing climate induced hazard with severe environmental and human consequences, particularly in high mountain Asia. Despite increasing access to satellite and temporal datasets, timely detection and disaster response remain underdeveloped and fragmented. This work introduces CC-GRMAS, a framework leveraging a series of satellite observations and environmental signals to enhance the accuracy of landslide forecasting. The system is structured around three interlinked agents Prediction, Planning, and Execution, which collaboratively enable real time situational awareness, response planning, and intervention. By incorporating local environmental factors and operationalizing multi agent coordination, this approach offers a scalable and proactive solution for climate resilient disaster preparedness across vulnerable mountainous terrains.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [212] [STARS: Semantic Tokens with Augmented Representations for Recommendation at Scale](https://arxiv.org/abs/2512.10149)
*Han Chen,Steven Zhu,Yingrui Li*

Main category: cs.IR

TL;DR: STARS is a low-latency, transformer-based sequential recommendation framework for e-commerce, featuring dual-memory user embeddings, semantic item tokens, context-aware scoring, and a two-stage retrieval pipeline—achieving significant offline and online improvements over existing systems.


<details>
  <summary>Details</summary>
Motivation: Real-world e-commerce recommender systems face strict latency constraints (<10–20ms) while handling cold-start items, shifting user intent, and dynamic contextual signals (e.g., holidays, promotions).

Method: STARS uses: (1) dual-memory user embeddings (long-term vs. short-term session intent), (2) semantic item tokens combining pretrained text embeddings, learnable deltas, and LLM-derived attribute tags, (3) context-aware scoring with learned calendar/event offsets, and (4) a latency-conscious two-stage retrieval (offline embedding + online MIPS with filtering).

Result: Offline: >75% relative improvement in Hit@5 over LambdaMART. Online A/B test on 6M visits: Total Orders +0.8%, Add-to-Cart on Home +2.0%, Visits per User +0.5% — all statistically significant.

Conclusion: Integrating semantic enrichment, multi-intent modeling, and deployment-aware architecture enables state-of-the-art recommendation quality without compromising serving efficiency in production e-commerce systems.

Abstract: Real-world ecommerce recommender systems must deliver relevant items under strict tens-of-milliseconds latency constraints despite challenges such as cold-start products, rapidly shifting user intent, and dynamic context including seasonality, holidays, and promotions. We introduce STARS, a transformer-based sequential recommendation framework built for large-scale, low-latency ecommerce settings. STARS combines several innovations: dual-memory user embeddings that separate long-term preferences from short-term session intent; semantic item tokens that fuse pretrained text embeddings, learnable deltas, and LLM-derived attribute tags, strengthening content-based matching, long-tail coverage, and cold-start performance; context-aware scoring with learned calendar and event offsets; and a latency-conscious two-stage retrieval pipeline that performs offline embedding generation and online maximum inner-product search with filtering, enabling tens-of-milliseconds response times. In offline evaluations on production-scale data, STARS improves Hit@5 by more than 75 percent relative to our existing LambdaMART system. A large-scale A/B test on 6 million visits shows statistically significant lifts, including Total Orders +0.8%, Add-to-Cart on Home +2.0%, and Visits per User +0.5%. These results demonstrate that combining semantic enrichment, multi-intent modeling, and deployment-oriented design can yield state-of-the-art recommendation quality in real-world environments without sacrificing serving efficiency.

</details>


### [213] [The Best of the Two Worlds: Harmonizing Semantic and Hash IDs for Sequential Recommendation](https://arxiv.org/abs/2512.10388)
*Ziwei Liu,Yejing Wang,Qidong Liu,Zijian Zhang,Chong Chen,Wei Huang,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 本文提出H2Rec框架，通过双分支建模和双层级对齐策略，融合语义ID（SID）与哈希ID（HID），在保持头部物品唯一协同标识的同时，利用SID的多粒度语义建模能力缓解长尾问题，实现头尾物品推荐性能的均衡提升。


<details>
  <summary>Details</summary>
Motivation: 传统顺序推荐系统使用唯一哈希ID建模易受长尾问题影响；引入辅助信息的方法又面临共现噪声或语义同质化问题；现有语义ID方法则受限于量化导致的头部物品标识唯一性丧失，造成头尾性能此消彼长。

Method: 提出H2Rec框架：1）双分支建模架构，分别建模SID的多粒度语义与HID的独特协同信息；2）双层级对齐策略，实现SID与HID表征间的知识迁移与协同优化。

Result: 在三个真实数据集上实验表明，H2Rec显著优于现有基线，在头部与尾部物品推荐质量间取得更好平衡。

Conclusion: 融合SID与HID是解决顺序推荐中长尾与协同建模矛盾的有效路径，H2Rec通过结构化协同建模与对齐机制，为鲁棒偏好建模提供了新范式。

Abstract: Conventional Sequential Recommender Systems (SRS) typically assign unique Hash IDs (HID) to construct item embeddings. These HID embeddings effectively learn collaborative information from historical user-item interactions, making them vulnerable to situations where most items are rarely consumed (the long-tail problem). Recent methods that incorporate auxiliary information often suffer from noisy collaborative sharing caused by co-occurrence signals or semantic homogeneity caused by flat dense embeddings. Semantic IDs (SIDs), with their capability of code sharing and multi-granular semantic modeling, provide a promising alternative. However, the collaborative overwhelming phenomenon hinders the further development of SID-based methods. The quantization mechanisms commonly compromise the uniqueness of identifiers required for modeling head items, creating a performance seesaw between head and tail items. To address this dilemma, we propose \textbf{\name}, a novel framework that harmonizes the SID and HID. Specifically, we devise a dual-branch modeling architecture that enables the model to capture both the multi-granular semantics within SID while preserving the unique collaborative identity of HID. Furthermore, we introduce a dual-level alignment strategy that bridges the two representations, facilitating knowledge transfer and supporting robust preference modeling. Extensive experiments on three real-world datasets show that \name~ effectively balances recommendation quality for both head and tail items while surpassing the existing baselines. The implementation code can be found online\footnote{https://github.com/ziwliu8/H2Rec}.

</details>


### [214] [Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition](https://arxiv.org/abs/2512.10688)
*Lingfeng Liu,Yixin Song,Dazhong Shen,Bing Yin,Hao Li,Yanyong Zhang,Chao Wang*

Main category: cs.IR

TL;DR: 本文揭示了协同过滤中流行度偏差是贝叶斯成对排序（BPR）优化的内在几何现象，并提出方向分解与校正（DDC）框架，通过非对称方向更新修正嵌入几何结构，从而在源头解耦偏好与流行度，显著提升推荐质量与公平性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将流行度偏差视为外部混杂因素，但本文指出其本质是BPR优化过程中的内在几何缺陷，导致模型过度推荐热门物品而忽视用户对小众内容的真实偏好。

Method: 通过数学分析证明BPR使物品嵌入沿‘流行度方向’排列；提出DDC框架，采用不对称的方向更新策略：正样本沿个性化偏好方向优化，负样本避开全局流行度方向，从而从嵌入几何层面解耦偏好与流行度。

Result: 在多个基于BPR的架构上实验表明，DDC显著优于当前最优去偏方法，训练损失降至强调优基线的5%以下，同时提升推荐质量与公平性。

Conclusion: 流行度偏差是BPR的固有几何属性，而非外部干扰；DDC通过修正嵌入空间的方向结构，实现了更本质、更通用的去偏，为CF模型的公平性与个性化提供了新范式。

Abstract: Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users' genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant "popularity direction" where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [215] [Norm-Governed Multi-Agent Decision-Making in Simulator-Coupled Environments:The Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP)](https://arxiv.org/abs/2512.09939)
*Stella C. Dong*

Main category: cs.MA

TL;DR: 本文提出了一种面向再保险决策的约束型多智能体仿真过程（R-CMASP），通过耦合模拟器、角色化智能体与规范可行性层，提升了风险转移中的稳定性、一致性与合规性。


<details>
  <summary>Details</summary>
Motivation: 再保险决策具有分布式与非对称信息、部分可观测性、异构认知责任、模拟器驱动动态及严格审慎监管约束等特性，传统确定性工作流无法满足其认知灵活性、协作协调与规范敏感行为需求。

Method: 提出R-CMASP模型，扩展随机博弈与Dec-POMDP，引入三要素：(i)耦合灾害/资本/投资组合引擎的模拟器驱动状态转移；(ii)具备结构化观察能力、信念更新与类型化通信的角色专用智能体；(iii)将偿付能力、监管与组织规则编码为联合行动可容许性约束的规范可行性层；并采用具备工具调用能力与类型化消息协议的大语言模型智能体进行实验验证。

Result: 在领域校准的合成环境中，受规范约束的多智能体协同相比确定性自动化或单体大模型基线，显著降低了定价方差、提升了资本效率、增强了条款解释准确性，并提高了均衡稳定性。

Conclusion: 受监管、模拟器驱动的决策环境最自然地建模为规范治理、模拟器耦合的多智能体系统。

Abstract: Reinsurance decision-making exhibits the core structural properties that motivate multi-agent models: distributed and asymmetric information, partial observability, heterogeneous epistemic responsibilities, simulator-driven environment dynamics, and binding prudential and regulatory constraints. Deterministic workflow automation cannot meet these requirements, as it lacks the epistemic flexibility, cooperative coordination mechanisms, and norm-sensitive behaviour required for institutional risk-transfer.
  We propose the Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP), a formal model that extends stochastic games and Dec-POMDPs by adding three missing elements: (i) simulator-coupled transition dynamics grounded in catastrophe, capital, and portfolio engines; (ii) role-specialized agents with structured observability, belief updates, and typed communication; and (iii) a normative feasibility layer encoding solvency, regulatory, and organizational rules as admissibility constraints on joint actions.
  Using LLM-based agents with tool access and typed message protocols, we show in a domain-calibrated synthetic environment that governed multi-agent coordination yields more stable, coherent, and norm-adherent behaviour than deterministic automation or monolithic LLM baselines--reducing pricing variance, improving capital efficiency, and increasing clause-interpretation accuracy. Embedding prudential norms as admissibility constraints and structuring communication into typed acts measurably enhances equilibrium stability.
  Overall, the results suggest that regulated, simulator-driven decision environments are most naturally modelled as norm-governed, simulator-coupled multi-agent systems.

</details>


### [216] [Empirical Hardness in Multi-Agent Pathfinding: Research Challenges and Opportunities](https://arxiv.org/abs/2512.10078)
*Jingyao Ren,Eric Ewing,T. K. Satish Kumar,Sven Koenig,Nora Ayanian*

Main category: cs.MA

TL;DR: 本文探讨了多智能体路径规划（MAPF）问题的经验难度，提出了三个关键研究挑战：算法选择、影响经验难度的关键实例特征识别，以及如何利用经验难度知识生成难解实例或多样化基准数据集。


<details>
  <summary>Details</summary>
Motivation: 尽管MAPF在理论上是NP-hard问题，但实际求解难度差异显著，理论复杂度与实际难度之间存在差距，需深入理解其经验难度机制。

Method: 本文采用综述与问题建模方式，系统梳理并定义MAPF经验难度的三大核心研究挑战，并指出结构特性（如相变、骨干/后门）等关键特征的作用。

Result: 明确了算法选择、实例特征分析和难例生成三大研究方向，为MAPF经验硬度的后续实证研究奠定了基础。

Conclusion: MAPF经验难度是一个重要且尚未充分探索的研究方向，未来工作应聚焦于建立可解释的难度预测模型、设计更具代表性的基准集及开发自适应求解器。

Abstract: Multi-agent pathfinding (MAPF) is the problem of finding collision-free paths for a team of agents on a map. Although MAPF is NP-hard, the hardness of solving individual instances varies significantly, revealing a gap between theoretical complexity and actual hardness. This paper outlines three key research challenges in MAPF empirical hardness to understand such phenomena. The first challenge, known as algorithm selection, is determining the best-performing algorithms for a given instance. The second challenge is understanding the key instance features that affect MAPF empirical hardness, such as structural properties like phase transition and backbone/backdoor. The third challenge is how to leverage our knowledge of MAPF empirical hardness to effectively generate hard MAPF instances or diverse benchmark datasets. This work establishes a foundation for future empirical hardness research and encourages deeper investigation into these promising and underexplored areas.

</details>


### [217] [Emergent Collective Memory in Decentralized Multi-Agent AI Systems](https://arxiv.org/abs/2512.10166)
*Khushiyant*

Main category: cs.MA

TL;DR: 本文研究了去中心化多智能体系统中集体记忆的涌现机制，发现个体记忆与环境痕迹共同作用形成空间分布式的集体记忆；实验证明个体记忆独立提升性能，而环境痕迹需依赖认知基础才能发挥作用，并验证了理论预测的相变临界密度。


<details>
  <summary>Details</summary>
Motivation: 探索去中心化多智能体系统中集体记忆如何通过个体记忆与环境痕迹的交互自发涌现，弥补缺乏中央控制下协同记忆形成的理论与实证空白。

Method: 设计具有内部记忆状态并能留下持久环境痕迹的智能体，在多种网格规模、智能体数量和环境密度条件下进行大规模仿真实验（共50次/配置），结合统计检验与密度扫描分析相变行为。

Result: 个体记忆单独带来68.7%性能提升；无记忆时环境痕迹完全失效；在密度ρ > 0.20时，痕迹驱动的协同显著优于纯记忆方案（复合指标高36–41%）；实测临界密度ρ_c = 0.230，误差≤13%。

Conclusion: 集体记忆是记忆与痕迹协同的结果：记忆提供基础认知能力，痕迹实现空间化信息共享；系统存在由密度驱动的相变，验证了stigmergy在高密度下主导协同的理论预期。

Abstract: We demonstrate how collective memory emerges in decentralized multi-agent systems through the interplay between individual agent memory and environmental trace communication. Our agents maintain internal memory states while depositing persistent environmental traces, creating a spatially distributed collective memory without centralized control. Comprehensive validation across five environmental conditions (20x20 to 50x50 grids, 5-20 agents, 50 runs per configuration) reveals a critical asymmetry: individual memory alone provides 68.7% performance improvement over no-memory baselines (1563.87 vs 927.23, p < 0.001), while environmental traces without memory fail completely. This demonstrates that memory functions independently but traces require cognitive infrastructure for interpretation. Systematic density-sweep experiments (rho in [0.049, 0.300], up to 625 agents) validate our theoretical phase transition prediction. On realistic large grids (30x30, 50x50), stigmergic coordination dominates above rho ~ 0.20, with traces outperforming memory by 36-41% on composite metrics despite lower food efficiency. The experimental crossover confirms the predicted critical density rho_c = 0.230 within 13% error.

</details>


### [218] [Thinking While Driving: A Concurrent Framework for Real-Time, LLM-Based Adaptive Routing](https://arxiv.org/abs/2512.10610)
*Xiaopei Tan,Muyang Fan*

Main category: cs.MA

TL;DR: 本文提出了'驾驶中思考'框架，将大语言模型（LLM）集成到基于图的实时交通环境中，实现移动中的动态路径规划，显著降低交叉路口等待时间，并通过异步架构支持多智能体实时协同。


<details>
  <summary>Details</summary>
Motivation: 传统基于LLM的路由方法需智能体停驶后进行推理，导致高延迟，难以适应实时高密度交通场景；亟需一种能在运动中持续决策的低延迟、可扩展的智能路由机制。

Method: 提出并发式路由框架Thinking While Driving：采用加权无向图建模交通环境，融合实时拥堵指标；利用Unity协程与专用请求管理器构建非阻塞异步架构；LLM在智能体移动过程中持续接收环境更新并生成动态路径决策。

Result: 在高流量条件下，智能体平均决策延迟仅0.75秒；LLM驱动的智能体能实时感知拥堵、动态重路由，并展现出超越静态路径规划的自适应行为，同时保持端到端实时性能。

Conclusion: 该工作验证了LLM可在严格实时约束下有效支撑动态交通决策，提供了可复现的自适应路由与多智能体协同研究框架，为LLM赋能边缘智能交通系统开辟新路径。

Abstract: We present Thinking While Driving, a concurrent routing framework that integrates LLMs into a graph-based traffic environment. Unlike approaches that require agents to stop and deliberate, our system enables LLM-based route planning while agents are moving, significantly reducing intersection wait times. Under high traffic, agents average just 0.75 seconds of decision latency. To coordinate many agents in real-time, we implement a non-blocking asynchronous architecture using Unity coroutines and a dedicated request manager. The environment is a weighted undirected graph with live congestion metrics, updated continuously by the agents to enable shared perception. Our results show LLM-driven agents can dynamically adapt to traffic, reroute around congestion, and exhibit behaviors beyond static pathfinding, all while maintaining real-time performance. This work provides a reproducible framework for future research in adaptive routing and multi-agent cooperation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [219] [ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples](https://arxiv.org/abs/2512.09931)
*Akaash Chatterjee,Suman Kundu*

Main category: cs.AI

TL;DR: ExaCraft是一个基于Google Gemini和Flask API的AI系统，通过Chrome插件实现，能根据学习者的动态上下文（如地理位置、职业、学习行为等）实时生成个性化、文化适配的教学示例。


<details>
  <summary>Details</summary>
Motivation: 现有教育AI工具缺乏对学习者动态理解状态、困难点及技能成长的适应能力，难以提供真正个性化、情境相关的教学示例。

Method: 构建ExaCraft系统，整合用户画像（位置、职业、教育背景、复杂度偏好）与实时学习行为分析，利用Google Gemini模型生成示例，并依据五类学习上下文信号（挣扎指标、掌握模式、主题历史、会话边界、进展信号）动态调整输出。

Result: ExaCraft成功实现了随学习进程演进的示例生成，能响应主题重复、重生成请求及不同用例下的主题推进模式，提升示例的相关性与适应性。

Conclusion: 动态上下文感知是提升教育AI个性化效果的关键；ExaCraft验证了融合多维学习信号与大模型生成能力在自适应示例生成中的可行性与有效性。

Abstract: Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.

</details>


### [220] [Suzume-chan: Your Personal Navigator as an Embodied Information Hub](https://arxiv.org/abs/2512.09932)
*Maya Grace Torii,Takahito Murakami,Shuka Koseki,Yoichi Ochiai*

Main category: cs.AI

TL;DR: 本文提出了一种名为'具身信息中心'的新方法，通过物理与对话交互提升知识共享的临场感与人性化体验，其原型Suzume-chan是一个本地运行、支持语音交互与RAG的软性AI代理。


<details>
  <summary>Details</summary>
Motivation: 数字工具虽改善信息获取，但难以营造深度理解所需的连接感；需借助社交临场感理论弥合人机间心理距离。

Method: 基于社交临场理论，设计并实现一个具身化、本地化运行的软性AI代理Suzume-chan，集成语言模型与检索增强生成（RAG），支持语音输入与对话式响应。

Result: Suzume-chan能从口语讲解中学习并实时对话响应，有效降低心理距离，提升知识共享的温暖感与人际感。

Conclusion: 具身化、对话驱动的本地AI代理可显著增强知识传播中的社交临场感，为以人为本的人机交互提供新范式。

Abstract: Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of "being together" enhances communication. An "Embodied Information Hub" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.

</details>


### [221] [Exploring Health Misinformation Detection with Multi-Agent Debate](https://arxiv.org/abs/2512.09935)
*Chih-Han Chen,Chen-Han Tsai,Yu-Shao Peng*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段健康虚假信息检测框架：先通过大语言模型预测证据共识得分，若共识不足则启动多智能体辩论以生成有依据的判定结果。


<details>
  <summary>Details</summary>
Motivation: 随着健康相关错误信息在线上大量传播，有效验证需要高质量证据检索和严谨推理，而现有方法在处理证据冲突时表现不足。

Method: 提出两阶段框架：第一阶段用大语言模型独立评估检索到的文章并计算共识得分；第二阶段在共识不足时触发多智能体结构化辩论，综合冲突证据并生成带明确理由的判定。

Result: 实验表明该两阶段方法在健康虚假信息检测任务上性能优于基线方法。

Conclusion: 将自动化共识评分与协作式推理相结合，能显著提升复杂健康事实核查任务的准确性与可解释性。

Abstract: Fact-checking health-related claims has become increasingly critical as misinformation proliferates online. Effective verification requires both the retrieval of high-quality evidence and rigorous reasoning processes. In this paper, we propose a two-stage framework for health misinformation detection: Agreement Score Prediction followed by Multi-Agent Debate. In the first stage, we employ large language models (LLMs) to independently evaluate retrieved articles and compute an aggregated agreement score that reflects the overall evidence stance. When this score indicates insufficient consensus-falling below a predefined threshold-the system proceeds to a second stage. Multiple agents engage in structured debate to synthesize conflicting evidence and generate well-reasoned verdicts with explicit justifications. Experimental results demonstrate that our two-stage approach achieves superior performance compared to baseline methods, highlighting the value of combining automated scoring with collaborative reasoning for complex verification tasks.

</details>


### [222] [Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting](https://arxiv.org/abs/2512.09944)
*Moein Heidari,Mohammad Amin Roohi,Armin Khosravi,Ilker Hacihaliloglu*

Main category: cs.AI

TL;DR: 本文提出了Echo-CoPilot，一个基于大语言模型的多视图、多任务超声心动图分析代理，通过协调专用工具完成视图识别、结构分割、测量与疾病预测等任务，并生成符合临床指南的回答和报告，在MIMIC-EchoQA基准上达到50.8%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有超声心动图基础模型虽在单个感知子任务（如视图分类、分割、疾病预测）上表现良好，但彼此孤立，缺乏统一、临床连贯的综合评估能力。

Method: 构建Echo-CoPilot代理，采用ReAct式推理循环，利用大语言模型调度多个专业工具（视图识别、心脏结构分割、测量、疾病预测、报告生成），并整合输出为指南导向的答案和叙事摘要。

Result: 在公开MIMIC-EchoQA基准上准确率达50.8%，优于通用及生物医学视频-语言模型；定性分析显示其能结合定量测量与生理背景解决接近临床决策阈值的疑难病例（如临界左室肥厚、心包积液严重程度）。

Conclusion: Echo-CoPilot展示了以大语言模型为中枢协调多模态专业工具进行端到端超声心动图解读的可行性与临床潜力，推动了从孤立子任务模型向临床就绪型AI助手的演进。

Abstract: Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8\%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.

</details>


### [223] [Fuzzy Hierarchical Multiplex](https://arxiv.org/abs/2512.09976)
*Alexis Kafantaris*

Main category: cs.AI

TL;DR: 本文提出了一种扩展FCM因果关系的新型模糊优化框架，用于信息传输服务过程设计中的服务优化，并对FHM进行了逻辑清晰、简洁优雅的分析。


<details>
  <summary>Details</summary>
Motivation: 为了解决服务过程设计中信息传输的服务优化问题，需要一种能够映射数据动态特性并分析概念间逻辑蕴含与层次关系的新方法。

Method: 提出一种新的模糊优化框架，扩展FCM因果关系，利用动力学将数据映射到度量空间，并通过多层网络（multiplex）分析概念间的逻辑蕴含与层次结构。

Result: 构建了一个面向服务优化的理论框架，并对FHM（可能指某种模糊层次模型）进行了系统、简洁且严谨的逻辑与数学分析。

Conclusion: 该白理论论文成功建立了可支撑信息传输服务优化的模糊框架，其逻辑与数学基础坚实，具备理论推广价值。

Abstract: A new fuzzy optimization framework that extends FCM causality is proposed. This model utilizes the dynamics to map data into metrics and create a framework that examines logical implication and hierarchy of concepts using a multiplex. Moreover, this is a white-theoretical paper introducing the framework and analyzing the logic and math behind it. Upon this extension the main objectives and the orientation of this framework is expounded and exemplified; this framework is meant for service optimization of information transmission in service process design. Lastly, a thorough analysis of the FHM is included which is done following the logical steps in a simple and elegant manner.

</details>


### [224] [Exploring LLMs for Scientific Information Extraction Using The SciEx Framework](https://arxiv.org/abs/2512.10004)
*Sha Li,Ayush Sadekar,Nathan Self,Yiqi Su,Lars Andersland,Mira Chaplin,Annabel Zhang,Hyoju Yang,James B Henderson,Krista Wigginton,Linsey Marr,T. M. Murali,Naren Ramakrishnan*

Main category: cs.AI

TL;DR: 本文提出SciEx框架，旨在解决大型语言模型在科学信息抽取中面临的长文本、多模态内容及数据模式快速变化等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以应对科学文献中的长上下文、多模态内容以及跨多篇论文的细粒度信息标准化整合，且当数据模式频繁变更时，系统难以快速重构或微调。

Method: 提出模块化、可组合的SciEx框架，解耦PDF解析、多模态检索、信息抽取与聚合等关键组件，支持按需提取、灵活集成新模型与提示策略。

Result: 在涵盖三个科学主题的数据集上评估了SciEx，验证其在细粒度信息抽取上的准确性与一致性，并揭示了当前LLM管道的实际优势与局限。

Conclusion: SciEx为动态演化的科学信息抽取任务提供了更灵活、可扩展和实用的解决方案，推动LLM在科研自动化中的稳健应用。

Abstract: Large language models (LLMs) are increasingly touted as powerful tools for automating scientific information extraction. However, existing methods and tools often struggle with the realities of scientific literature: long-context documents, multi-modal content, and reconciling varied and inconsistent fine-grained information across multiple publications into standardized formats. These challenges are further compounded when the desired data schema or extraction ontology changes rapidly, making it difficult to re-architect or fine-tune existing systems. We present SciEx, a modular and composable framework that decouples key components including PDF parsing, multi-modal retrieval, extraction, and aggregation. This design streamlines on-demand data extraction while enabling extensibility and flexible integration of new models, prompting strategies, and reasoning mechanisms. We evaluate SciEx on datasets spanning three scientific topics for its ability to extract fine-grained information accurately and consistently. Our findings provide practical insights into both the strengths and limitations of current LLM-based pipelines.

</details>


### [225] [DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations](https://arxiv.org/abs/2512.10034)
*Salomé Guilbert,Cassandra Masschelein,Jeremy Goumaz,Bohdan Naida,Philippe Schwaller*

Main category: cs.AI

TL;DR: 本文提出了DynaMate，一个模块化的多智能体框架，用于自动设计和执行蛋白质及蛋白质-配体系统的完整分子动力学（MD）模拟工作流，并支持MM/PB(GB)SA自由能计算。


<details>
  <summary>Details</summary>
Motivation: MD模拟在药物发现和蛋白质工程中具有重要价值，但其设置过程（如参数化、输入准备和软件配置）技术复杂，限制了广泛应用；现有基于智能体的大型语言模型尚未成功应用于自动化蛋白-配体MD工作流。

Method: 构建了一个包含三个专用模块的多智能体框架DynaMate，集成动态工具调用、网络搜索、PaperQA和自纠错机制，分别负责实验规划、模拟执行和结果分析。

Result: 在12个不同复杂度的基准系统上评估显示，DynaMate能可靠完成全流程MD模拟，通过迭代推理修正运行时错误，并产出有意义的蛋白-配体相互作用分析结果。

Conclusion: DynaMate实现了MD工作流的自动化，为未来生物分子建模与药物设计提供了标准化、可扩展且高效的新范式。

Abstract: Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD setup, encompassing parameterization, input preparation, and software configuration, remains a major barrier for widespread and efficient usage. Agentic LLMs have demonstrated their capacity to autonomously execute multi-step scientific processes, and to date, they have not successfully been used to automate protein-ligand MD workflows. Here, we present DynaMate, a modular multi-agent framework that autonomously designs and executes complete MD workflows for both protein and protein-ligand systems, and offers free energy binding affinity calculations with the MM/PB(GB)SA method. The framework integrates dynamic tool use, web search, PaperQA, and a self-correcting behavior. DynaMate comprises three specialized modules, interacting to plan the experiment, perform the simulation, and analyze the results. We evaluated its performance across twelve benchmark systems of varying complexity, assessing success rate, efficiency, and adaptability. DynaMate reliably performed full MD simulations, corrected runtime errors through iterative reasoning, and produced meaningful analyses of protein-ligand interactions. This automated framework paves the way toward standardized, scalable, and time-efficient molecular modeling pipelines for future biomolecular and drug design applications.

</details>


### [226] [SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration](https://arxiv.org/abs/2512.10046)
*Yan Zhuang,Jiawei Ren,Xiaokang Ye,Jianzhi Shen,Ruixuan Zhang,Tianai Yue,Muhammad Faayez,Xuhong He,Ziqiao Ma,Lianhui Qin,Zhiting Hu,Tianmin Shu*

Main category: cs.AI

TL;DR: 本文提出了SimWorld-Robotics（SWR），一个基于Unreal Engine 5构建的大规模、照片级真实感城市环境仿真平台，支持动态行人与交通系统、多机器人控制与通信，并据此构建了两个具挑战性的新基准任务：多模态指令跟随导航与多智能体协同搜索，全面评估机器人在真实城市环境中的关键能力。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型驱动的通用机器人研究主要集中于室内家庭场景，缺乏面向大规模、复杂、真实城市环境的仿真平台与评测基准。

Method: 构建基于Unreal Engine 5的SimWorld-Robotics（SWR）仿真平台，支持程序化生成无限量高保真城市场景、动态行人与交通系统、多机器人控制与通信；并基于该平台设计两个新基准任务：多模态视觉-语言导航任务和双机器人协同搜索任务。

Result: 实验表明，当前最先进模型（包括VLMs）在SWR提出的两项任务上表现不佳，暴露出其在城市环境中鲁棒感知、空间推理与长程规划能力的严重不足。

Conclusion: SWR填补了城市级具身AI仿真与评测的空白，所提基准更全面地衡量机器人在开放、动态、真实场景下的综合能力，为推动通用机器人向复杂户外环境演进提供了关键基础设施与评估标准。

Abstract: Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly focused on indoor, household scenarios. In this work, we present SimWorld-Robotics~(SWR), a simulation platform for embodied AI in large-scale, photorealistic urban environments. Built on Unreal Engine 5, SWR procedurally generates unlimited photorealistic urban scenes populated with dynamic elements such as pedestrians and traffic systems, surpassing prior urban simulations in realism, complexity, and scalability. It also supports multi-robot control and communication. With these key features, we build two challenging robot benchmarks: (1) a multimodal instruction-following task, where a robot must follow vision-language navigation instructions to reach a destination in the presence of pedestrians and traffic; and (2) a multi-agent search task, where two robots must communicate to cooperatively locate and meet each other. Unlike existing benchmarks, these two new benchmarks comprehensively evaluate a wide range of critical robot capacities in realistic scenarios, including (1) multimodal instructions grounding, (2) 3D spatial reasoning in large environments, (3) safe, long-range navigation with people and traffic, (4) multi-robot collaboration, and (5) grounded communication. Our experimental results demonstrate that state-of-the-art models, including vision-language models (VLMs), struggle with our tasks, lacking robust perception, reasoning, and planning abilities necessary for urban environments.

</details>


### [227] [Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning](https://arxiv.org/abs/2512.10054)
*Logan Robbins*

Main category: cs.AI

TL;DR: 本文提出Parallel Decoder Transformer (PDT)，一种无需重训练、仅通过轻量级适配器（SNC）实现并行解码与流间协调的新架构，显著缓解大模型自回归生成的延迟瓶颈，并在保持主干权重冻结的前提下实现高精度语义一致性恢复。


<details>
  <summary>Details</summary>
Motivation: 自回归解码存在线性增长的延迟瓶颈；现有分解-填充类并行方法因缺乏跨流通信导致连贯性漂移（coherence drift）。

Method: 提出PDT架构，在冻结预训练大模型上注入轻量级Speculative Note Conditioning (SNC)适配器，构建共享动态潜在空间以支持并行流同步；将协调建模为speculative consensus问题，通过全局语义‘notes’广播与学习型验证头进行门控。

Result: 在50,000步课程学习和冻结20B参数主干模型上验证，PDT达到77.8%的覆盖预测精度，能近似恢复串行生成语义，且不修改主干权重。

Conclusion: PDT是一种可扩展、参数高效、无需全模型微调的结构化并行生成方案，为大模型低延迟推理提供了新范式。

Abstract: Autoregressive decoding in Large Language Models (LLMs) is inherently sequential, creating a latency bottleneck that scales linearly with output length. While ``Decomposition-and-Fill'' methods like Skeleton-of-Thought attempt to parallelize generation via external orchestration, they suffer from \textit{coherence drift} due to the lack of cross-stream communication. In this work, we introduce the \textbf{Parallel Decoder Transformer (PDT)}, a parameter-efficient architecture that embeds coordination primitives directly into the inference process of a frozen pre-trained model.
  Instead of retraining the base model, PDT injects lightweight \textit{Speculative Note Conditioning (SNC)} adapters that allow parallel decoding streams to synchronize via a shared, dynamic latent space. We formulate coordination as a \textit{speculative consensus} problem, where sibling streams broadcast semantic ``notes'' to a global bus, gated by a learned verification head. We validate our approach on a 50,000-step curriculum using a frozen 20B-parameter backbone. Our results demonstrate that PDT achieves effective self-correction, reaching \textbf{77.8\% precision} in coverage prediction and recovering approximate serial semantics without modifying the trunk weights. This establishes PDT as a scalable, efficient alternative to full model fine-tuning for structured parallel generation.

</details>


### [228] [Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research](https://arxiv.org/abs/2512.10058)
*Dani Roytburg,Beck Miller*

Main category: cs.AI

TL;DR: 本文通过大规模文献计量与合著网络分析，揭示了AI安全与AI伦理两大研究领域在机构层面的结构性割裂：80%以上合作局限于各自社区，跨领域连接高度依赖少数‘桥梁型’学者（仅5%论文贡献85%以上桥接链接），表明二者不仅概念分歧，更存在深层制度隔离；作者呼吁通过共享基准、跨机构平台与混合方法论促进技术安全与规范伦理的实质性融合。


<details>
  <summary>Details</summary>
Motivation: AI对齐（alignment）研究日益紧迫，但安全（关注规模化智能、欺骗行为、生存风险）与伦理（关注现实伤害、社会偏见、生产流程缺陷）两大路径长期平行发展、定义分歧、缺乏协作，亟需实证揭示其割裂现状并推动整合。

Method: 对2020–2025年12个主流ML/NLP会议共6442篇论文开展 bibliometric 分析与合著网络分析，量化安全与伦理社区内部/跨社区合作密度、桥接链接分布及关键节点移除效应。

Result: 超80%合作限于单一社区；跨领域连接极不均衡——约5%论文贡献超85%桥接链接；移除少量核心‘桥梁’作者即显著加剧社区隔离；证实割裂兼具概念性与制度性。

Conclusion: AI安全与AI伦理的割裂已固化为结构性问题，须通过共建基准、跨机构平台与混合方法论实现深度整合，方能构建既鲁棒又公正的AI系统。

Abstract: While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, "aligned" systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety--centered on scaled intelligence, deceptive or scheming behaviors, and existential risk--and ethics--focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.
  We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics--via shared benchmarks, cross-institutional venues, and mixed-method methodologies--is essential for building AI systems that are both robust and just.

</details>


### [229] [Linear socio-demographic representations emerge in Large Language Models from indirect cues](https://arxiv.org/abs/2512.10065)
*Paul Bouchaud,Pedro Ramaciotti*

Main category: cs.AI

TL;DR: 本文研究了大语言模型（LLMs）如何基于姓名、职业等间接线索推断用户社会人口学属性（如性别、种族），发现其在激活空间中形成可解释的线性表征，并证实这些隐式表征会影响下游任务（如职业推荐），即使模型通过偏见基准测试，仍可能隐含并利用偏见。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs在无显式提示下如何隐式推断用户社会人口学属性，及其对公平性和下游行为的影响。

Method: 在四个开源Transformer-based LLMs上，通过探针法分析残差流激活，分别使用显式人口信息和隐式线索（姓名、职业）触发表征；验证表征的线性性、可解释性及其与现实统计数据的相关性。

Result: LLMs在激活空间中形成线性、可解释的社会人口学表征；姓名和职业能可靠激活对应性别/种族及职业分布表征；这些隐式表征显著影响职业推荐等下游行为。

Conclusion: LLMs隐含编码并利用社会刻板印象，现有偏见评测不足以揭示其实际部署中的公平风险，需更深入的隐式偏见诊断与干预。

Abstract: We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.

</details>


### [230] [Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit](https://arxiv.org/abs/2512.10092)
*Nick Jiang,Xiaoqing Sun,Lisa Dunlap,Lewis Smith,Neel Nanda*

Main category: cs.AI

TL;DR: 本文提出使用稀疏自编码器（SAEs）生成可解释的稀疏嵌入（SAE embeddings），用于大规模文本语料分析，在成本、可控性和可靠性上优于现有LLM和稠密嵌入方法，并通过多个任务和案例研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大规模文本分析方法（如LLM标注或稠密嵌入）存在高成本、低可控性或缺乏可解释性等问题，亟需一种更高效、可解释且可控的分析工具。

Method: 提出基于稀疏自编码器（SAEs）构建SAE embeddings，利用其高维稀疏性实现概念级可解释性，并应用于数据集差异分析、概念相关性发现、按需聚类与属性检索等四类任务，辅以模型行为案例研究。

Result: SAE embeddings在识别数据集语义差异和模型偏差方面比LLM更可靠且成本低2–8倍；支持按概念过滤实现可控聚类与检索，性能优于稠密嵌入；成功应用于OpenAI模型演进分析和Tulu-3触发短语挖掘。

Conclusion: SAEs是一种高效、可控、可解释的大规模非结构化数据分析新范式，强调通过数据视角理解模型行为，具有广泛适用潜力。

Abstract: Analyzing large-scale text corpora is a core challenge in machine learning, crucial for tasks like identifying undesirable model behaviors or biases in training data. Current methods often rely on costly LLM-based techniques (e.g. annotating dataset differences) or dense embedding models (e.g. for clustering), which lack control over the properties of interest. We propose using sparse autoencoders (SAEs) to create SAE embeddings: representations whose dimensions map to interpretable concepts. Through four data analysis tasks, we show that SAE embeddings are more cost-effective and reliable than LLMs and more controllable than dense embeddings. Using the large hypothesis space of SAEs, we can uncover insights such as (1) semantic differences between datasets and (2) unexpected concept correlations in documents. For instance, by comparing model responses, we find that Grok-4 clarifies ambiguities more often than nine other frontier models. Relative to LLMs, SAE embeddings uncover bigger differences at 2-8x lower cost and identify biases more reliably. Additionally, SAE embeddings are controllable: by filtering concepts, we can (3) cluster documents along axes of interest and (4) outperform dense embeddings on property-based retrieval. Using SAE embeddings, we study model behavior with two case studies: investigating how OpenAI model behavior has changed over time and finding "trigger" phrases learned by Tulu-3 (Lambert et al., 2024) from its training data. These results position SAEs as a versatile tool for unstructured data analysis and highlight the neglected importance of interpreting models through their data.

</details>


### [231] [Robust AI Security and Alignment: A Sisyphean Endeavor?](https://arxiv.org/abs/2512.10100)
*Apostol Vassilev*

Main category: cs.AI

TL;DR: 本文通过将哥德尔不完备性定理扩展到人工智能领域，建立了AI安全与对齐的理论信息论限制，并探讨了其对AI认知推理能力的广泛影响。


<details>
  <summary>Details</summary>
Motivation: 揭示AI在安全与对齐方面的根本性理论局限，以支持AI技术的负责任应用。

Method: 将哥德尔不完备性定理推广至AI系统，结合信息论方法进行理论分析。

Result: 证明了AI安全与对齐存在信息论层面的根本限制，并推导出AI认知推理能力的固有局限。

Conclusion: 必须认识并应对这些理论限制，文中也提供了若干实用应对策略。

Abstract: This manuscript establishes information-theoretic limitations for robustness of AI security and alignment by extending Gödel's incompleteness theorem to AI. Knowing these limitations and preparing for the challenges they bring is critically important for the responsible adoption of the AI technology. Practical approaches to dealing with these challenges are provided as well. Broader implications for cognitive reasoning limitations of AI systems are also proven.

</details>


### [232] [Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups](https://arxiv.org/abs/2512.10105)
*Soorya Ram Shimgekar,Abhay Goyal,Lam Yin Cheung,Roy Ka-Wei Lee,Koustuv Saha,Pi Zonooz,Navin Kumar*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段计算框架（RoBERTa分类+Signed Belief Graph Neural Network），用于分析新加坡Telegram群组中的阴谋论话语，发现其广泛渗透于日常话题（如金融、法律）而非仅限于极端化回音室，并识别出七类叙事原型。


<details>
  <summary>Details</summary>
Motivation: 阴谋论话语日益嵌入数字通信生态，但其结构与传播机制难以研究；现有假设认为其局限于孤立回音室，需实证检验其在日常交流中的嵌入模式。

Method: 第一阶段：微调RoBERTa-large进行消息级阴谋论二分类（F1=0.866）；第二阶段：构建带符号信念图（节点为消息，边符号表信念对齐，权重为文本相似度），并提出SiBeGNN模型，引入符号解耦损失以分离意识形态对齐与风格特征；最后用层次聚类提取叙事原型。

Result: 在55万条消息中识别出7类叙事原型（法律、医疗、媒体、金融、权威矛盾、群组管理、日常聊天）；SiBeGNN聚类质量（cDBI=8.38）显著优于基线（13.60–67.27）；专家评估一致性达88%；证实阴谋论内容广泛分布于非怀疑类日常话题中。

Conclusion: 阴谋论话语并非仅存于激进或怀疑性子群体，而是深度融入普通社会互动；该框架推动了基于信念的 discourse 分析方法，可支撑立场检测、政治传播研究与内容治理政策。

Abstract: Conspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features.
  Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.

</details>


### [233] [AgriRegion: Region-Aware Retrieval for High-Fidelity Agricultural Advice](https://arxiv.org/abs/2512.10114)
*Mesafint Fanuel,Mahmoud Nabil Mahmoud,Crystal Cook Marshal,Vishal Lakhotia,Biswanath Dari,Kaushik Roy,Shaohu Zhang*

Main category: cs.AI

TL;DR: AgriRegion 是一种面向农业领域的检索增强生成（RAG）框架，通过引入地理空间元数据注入和区域优先重排序机制，提升LLM在区域农业咨询中的准确性与可信度，显著降低幻觉并提高本地适配性。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在农业领域易产生情境幻觉，其建议虽在某地科学合理，但在其他地区因土壤、气候和法规差异可能造成严重后果，亟需高保真、区域感知的农业咨询服务。

Method: 提出 AgriRegion 框架：1）构建基于权威地方农技推广服务的知识库；2）在检索阶段嵌入地理空间元数据并施加空间约束；3）设计区域优先的重排序机制；4）构建包含12个子领域的农业评测基准 AgriRegion-Eval（160题）。

Result: 相比现有最先进LLM系统，AgriRegion将幻觉率降低10–20%，并在综合评估中显著提升信任得分。

Conclusion: 地理上下文显式建模与区域受限检索是提升农业大模型可靠性与实用性的关键路径，AgriRegion为垂直领域RAG提供了可复用的区域感知范式。

Abstract: Large Language Models (LLMs) have demonstrated significant potential in democratizing access to information. However, in the domain of agriculture, general-purpose models frequently suffer from contextual hallucination, which provides non-factual advice or answers are scientifically sound in one region but disastrous in another due to variations in soil, climate, and local regulations. We introduce AgriRegion, a Retrieval-Augmented Generation (RAG) framework designed specifically for high-fidelity, region-aware agricultural advisory. Unlike standard RAG approaches that rely solely on semantic similarity, AgriRegion incorporates a geospatial metadata injection layer and a region-prioritized re-ranking mechanism. By restricting the knowledge base to verified local agricultural extension services and enforcing geo-spatial constraints during retrieval, AgriRegion ensures that the advice regarding planting schedules, pest control, and fertilization is locally accurate. We create a novel benchmark dataset, AgriRegion-Eval, which comprises 160 domain-specific questions across 12 agricultural subfields. Experiments demonstrate that AgriRegion reduces hallucinations by 10-20% compared to state-of-the-art LLMs systems and significantly improves trust scores according to a comprehensive evaluation.

</details>


### [234] [The 2025 Foundation Model Transparency Index](https://arxiv.org/abs/2512.10169)
*Alexander Wan,Kevin Klyman,Sayash Kapoor,Nestor Maslej,Shayne Longpre,Betty Xiong,Percy Liang,Rishi Bommasani*

Main category: cs.AI

TL;DR: 2025年基础模型透明度指数显示，基础模型开发者的整体透明度显著下降，平均分从2024年的58分降至40分；IBM表现突出（95分），而xAI和Midjourney最低（14分）；政策推动下亟需更强有力的干预以弥补关键信息缺口。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型开发者透明度实践的演变趋势，尤其在行业影响力日益增强的背景下，识别透明度现状、变化动因及政策应对需求。

Method: 通过构建并更新‘基础模型透明度指数（FMTI）’，引入数据获取、使用数据、监控等新指标，对包括阿里巴巴、DeepSeek、xAI等多家公司进行量化评分与比较分析。

Result: 2025年平均透明度得分大幅下滑至40分（2024年为58分）；训练数据、训练算力及部署后影响信息最不透明；IBM为显著例外（95分），xAI与Midjourney最低（14分）；前沿模型论坛成员居中，缺乏成为透明度领导者的激励。

Conclusion: 当前基础模型开发者透明度整体退步，自愿性举措效果有限；需依靠更严格的政策强制要求，尤其针对数据来源、算力使用与实际影响等关键盲区。

Abstract: Foundation model developers are among the world's most important companies. As these companies become increasingly consequential, how do their transparency practices evolve? The 2025 Foundation Model Transparency Index is the third edition of an annual effort to characterize and quantify the transparency of foundation model developers. The 2025 FMTI introduces new indicators related to data acquisition, usage data, and monitoring and evaluates companies like Alibaba, DeepSeek, and xAI for the first time. The 2024 FMTI reported that transparency was improving, but the 2025 FMTI finds this progress has deteriorated: the average score out of 100 fell from 58 in 2024 to 40 in 2025. Companies are most opaque about their training data and training compute as well as the post-deployment usage and impact of their flagship models. In spite of this general trend, IBM stands out as a positive outlier, scoring 95, in contrast to the lowest scorers, xAI and Midjourney, at just 14. The five members of the Frontier Model Forum we score end up in the middle of the Index: we posit that these companies avoid reputational harms from low scores but lack incentives to be transparency leaders. As policymakers around the world increasingly mandate certain types of transparency, this work reveals the current state of transparency for foundation model developers, how it may change given newly enacted policy, and where more aggressive policy interventions are necessary to address critical information deficits.

</details>


### [235] [CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment](https://arxiv.org/abs/2512.10206)
*Yakun Zhu,Zhongzhen Huang,Qianhan Feng,Linjie Mu,Yannian Gu,Shaoting Zhang,Qi Dou,Xiaofan Zhang*

Main category: cs.AI

TL;DR: 本文提出了CP-Env，一个可控的智能体医院环境，用于评估大语言模型在端到端临床路径中的表现，并设计了涵盖临床效能、流程能力与职业伦理的三层评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如静态考试或孤立对话）无法充分评估大语言模型在动态、多阶段、真实临床路径中的能力。

Method: 构建CP-Env模拟医院生态系统，含患者与医生智能体，支持分支式、长周期临床任务；提出三层次评估框架（临床效能、流程能力、职业伦理）。

Result: 多数模型在复杂路径中表现不佳，易产生幻觉、遗漏关键诊断信息；过多推理步骤反而有害；顶尖模型更依赖内部知识而非外部工具。

Conclusion: CP-Env为医疗AI智能体提供了首个面向端到端临床路径的综合评估基准，推动更可靠、可信赖的医疗大模型发展。

Abstract: Medical care follows complex clinical pathways that extend beyond isolated physician-patient encounters, emphasizing decision-making and transitions between different stages. Current benchmarks focusing on static exams or isolated dialogues inadequately evaluate large language models (LLMs) in dynamic clinical scenarios. We introduce CP-Env, a controllable agentic hospital environment designed to evaluate LLMs across end-to-end clinical pathways. CP-Env simulates a hospital ecosystem with patient and physician agents, constructing scenarios ranging from triage and specialist consultation to diagnostic testing and multidisciplinary team meetings for agent interaction. Following real hospital adaptive flow of healthcare, it enables branching, long-horizon task execution. We propose a three-tiered evaluation framework encompassing Clinical Efficacy, Process Competency, and Professional Ethics. Results reveal that most models struggle with pathway complexity, exhibiting hallucinations and losing critical diagnostic details. Interestingly, excessive reasoning steps can sometimes prove counterproductive, while top models tend to exhibit reduced tool dependency through internalized knowledge. CP-Env advances medical AI agents development through comprehensive end-to-end clinical evaluation. We provide the benchmark and evaluation tools for further research and development at https://github.com/SPIRAL-MED/CP-Env.

</details>


### [236] [An exploration for higher efficiency in multi objective optimisation with reinforcement learning](https://arxiv.org/abs/2512.10208)
*Mehmet Emin Aydin*

Main category: cs.AI

TL;DR: 本文提出了一种基于多目标强化学习的通用化方法，以优化多目标搜索过程中的算子序列选择，提升优化算法效率。


<details>
  <summary>Details</summary>
Motivation: 现有优化算法在多目标场景下缺乏对算子序列经验的泛化利用，而单目标已有较多研究，多目标领域仍待探索。

Method: 采用多目标强化学习框架，构建可泛化算子序列选择机制，分阶段实现并验证其有效性。

Result: 初步完成部分阶段，验证了该方法在提升多目标优化搜索效率方面的潜力。

Conclusion: 基于多目标强化学习的泛化方法为解决多目标优化中算子序列选择问题提供了可行且有前景的新思路。

Abstract: Efficiency in optimisation and search processes persists to be one of the challenges, which affects the performance and use of optimisation algorithms. Utilising a pool of operators instead of a single operator to handle move operations within a neighbourhood remains promising, but an optimum or near optimum sequence of operators necessitates further investigation. One of the promising ideas is to generalise experiences and seek how to utilise it. Although numerous works are done around this issue for single objective optimisation, multi-objective cases have not much been touched in this regard. A generalised approach based on multi-objective reinforcement learning approach seems to create remedy for this issue and offer good solutions. This paper overviews a generalisation approach proposed with certain stages completed and phases outstanding that is aimed to help demonstrate the efficiency of using multi-objective reinforcement learning.

</details>


### [237] [ID-PaS : Identity-Aware Predict-and-Search for General Mixed-Integer Linear Programs](https://arxiv.org/abs/2512.10211)
*Junyang Cai,El Mehdi Er Raqabi,Pascal Van Hentenryck,Bistra Dilkina*

Main category: cs.AI

TL;DR: This paper extends the Predict-and-Search framework to parametric MIPs and proposes ID-PaS, an identity-aware learning method that improves handling of heterogeneous variables, outperforming Gurobi and prior PaS on large-scale real-world problems.


<details>
  <summary>Details</summary>
Motivation: Existing Predict-and-Search methods are limited to binary problems and ignore fixed variables common in real-world MIPs.

Method: The authors extend Predict-and-Search to parametric MIPs and introduce ID-PaS, an identity-aware learning framework that enables ML models to better handle heterogeneous (e.g., integer, continuous, fixed) variables.

Result: ID-PaS achieves consistently superior performance over Gurobi and the original PaS on several real-world large-scale MIP problems.

Conclusion: ID-PaS successfully generalizes Predict-and-Search to practical parametric MIPs with heterogeneous variables, demonstrating significant empirical gains.

Abstract: Mixed-Integer Linear Programs (MIPs) are powerful and flexible tools for modeling a wide range of real-world combinatorial optimization problems. Predict-and-Search methods operate by using a predictive model to estimate promising variable assignments and then guiding a search procedure toward high-quality solutions. Recent research has demonstrated that incorporating machine learning (ML) into the Predict-and-Search framework significantly enhances its performance. Still, it is restricted to binary problems and overlooks the presence of fixed variables that commonly arise in practical settings. This work extends the Predict-and-Search (PaS) framework to parametric MIPs and introduces ID-PaS, an identity-aware learning framework that enables the ML model to handle heterogeneous variables more effectively. Experiments on several real-world large-scale problems demonstrate that ID-PaS consistently achieves superior performance compared to the state-of-the-art solver Gurobi and PaS.

</details>


### [238] [Reverse Thinking Enhances Missing Information Detection in Large Language Models](https://arxiv.org/abs/2512.10273)
*Yuxin Liu,Chaojie Gu,Yihang Zhang,Bin Qian,Shibo He*

Main category: cs.AI

TL;DR: 本文提出一种基于逆向思维的新框架，用于提升大语言模型（LLMs）在缺失信息检测任务中的表现，显著优于传统的前向推理方法（如CoT、ToT）。


<details>
  <summary>Details</summary>
Motivation: LLMs在涉及缺失信息的推理任务中常出现不完整回答、事实错误和幻觉；现有前向推理方法难以系统识别和补全遗漏信息。

Method: 受反向推理启发，设计一种引导LLM进行逆向思维的框架，通过推导必要条件来定位缺失要素，将缺失信息识别转化为可解的反向推理问题。

Result: 实验表明，该逆向思维方法在缺失信息检测任务上相比CoT、ToT等前向方法取得显著性能提升。

Conclusion: 逆向思维为增强LLMs的逻辑完备性和推理鲁棒性提供了新且有效的路径。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning tasks, yet they often struggle with problems involving missing information, exhibiting issues such as incomplete responses, factual errors, and hallucinations. While forward reasoning approaches like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) have shown success in structured problem-solving, they frequently fail to systematically identify and recover omitted information. In this paper, we explore the potential of reverse thinking methodologies to enhance LLMs' performance on missing information detection tasks. Drawing inspiration from recent work on backward reasoning, we propose a novel framework that guides LLMs through reverse thinking to identify necessary conditions and pinpoint missing elements. Our approach transforms the challenging task of missing information identification into a more manageable backward reasoning problem, significantly improving model accuracy. Experimental results demonstrate that our reverse thinking approach achieves substantial performance gains compared to traditional forward reasoning methods, providing a promising direction for enhancing LLMs' logical completeness and reasoning robustness.

</details>


### [239] [Neuronal Attention Circuit (NAC) for Representation Learning](https://arxiv.org/abs/2512.10282)
*Waleed Razzaq,Izis Kankaraway,Yun-Bo Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种生物启发的连续时间注意力机制Neuronal Attention Circuit（NAC），将注意力logits建模为带非线性门控的线性一阶ODE解，结合线虫神经回路策略（NCPs）实现稀疏、高效、可解释的CT建模，并在多个时序任务上验证了其有效性与理论保障。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制具有离散性，难以直接用于连续时间建模；现有CT模型缺乏生物可解释性和计算效率平衡。本文旨在设计一种既具生物合理性又支持灵活CT动态建模的注意力机制。

Method: 提出Neuronal Attention Circuit（NAC）：用线性一阶ODE建模attention logits，引入源自C. elegans NCPs的非线性互连门控结构；采用稀疏感官门替代全连接K/Q投影，设计双头稀疏骨干网络分别生成content-target门和可学习时间常数门；支持三种logits求解模式（显式欧拉、闭式解、稳态近似）；引入稀疏Top-K配对拼接以降低内存开销。

Result: NAC在不规则时间序列分类、自动驾驶车道保持、工业剩余寿命预测等任务上达到或超越主流基线精度；运行时间和内存效率介于若干CT基线之间；理论证明了状态稳定性、误差有界性与通用逼近能力。

Conclusion: NAC是一种新颖、生物合理、理论严谨且实用的连续时间注意力机制，弥合了注意力建模与神经动力学之间的鸿沟，为CT深度学习提供了新范式。

Abstract: Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-order ODE with nonlinear interlinked gates derived from repurposing \textit{C. elegans} Neuronal Circuit Policies (NCPs) wiring mechanism. NAC replaces dense projections with sparse sensory gates for key-query projections and a sparse backbone network with two heads for computing \textit{content-target} and \textit{learnable time-constant} gates, enabling efficient adaptive dynamics. NAC supports three attention logit computation modes: (i) explicit Euler integration, (ii) exact closed-form solution, and (iii) steady-state approximation. To improve memory intensity, we implemented a sparse Top-\emph{K} pairwise concatenation scheme that selectively curates key-query interactions. We provide rigorous theoretical guarantees, including state stability, bounded approximation errors, and universal approximation. Empirically, we implemented NAC in diverse domains, including irregular time-series classification, lane-keeping for autonomous vehicles, and industrial prognostics. We observed that NAC matches or outperforms competing baselines in accuracy and occupies an intermediate position in runtime and memory efficiency compared with several CT baselines.

</details>


### [240] [Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules](https://arxiv.org/abs/2512.10300)
*Yanbei Jiang,Xueqi Ma,Shu Liu,Sarah Monazam Erfani,Tongliang Liu,James Bailey,Jey Han Lau,Krista A. Ehinger*

Main category: cs.AI

TL;DR: 本文提出CogVision数据集和一种新的可解释性框架，用于系统分析视觉-语言模型（VLMs）中注意力头在多模态推理中的功能角色，发现存在稀疏分布、功能特异的‘功能头’，其干预显著影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在多模态基准上表现优异，但其内部机制仍不透明，亟需系统性可解释性分析。

Method: 构建CogVision数据集（含链式思维分解的多模态子问题），结合基于探针的分析方法识别并刻画执行特定感知或认知功能（如高层视觉接收、推理）的注意力头（即功能头）。

Result: 发现功能头具有普遍稀疏性、跨模型的功能数量与分布差异性，以及在多模态交互与层级组织中的中介作用；干预实验证明其对推理性能具有因果性影响（移除降效、增强提效）。

Conclusion: VLMs内部存在类人认知组织结构，功能头是其多模态推理的关键机制，该发现为构建更符合人类感知与推理规律的模型提供了新方向。

Abstract: Despite excelling on multimodal benchmarks, vision-language models (VLMs) largely remain a black box. In this paper, we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs, focusing on the functional roles of attention heads in multimodal reasoning. To this end, we introduce CogVision, a dataset that decomposes complex multimodal questions into step-by-step subquestions designed to simulate human reasoning through a chain-of-thought paradigm, with each subquestion associated with specific receptive or cognitive functions such as high-level visual reception and inference. Using a probing-based methodology, we identify attention heads that specialize in these functions and characterize them as functional heads. Our analysis across diverse VLM families reveals that these functional heads are universally sparse, vary in number and distribution across functions, and mediate interactions and hierarchical organization. Furthermore, intervention experiments demonstrate their critical role in multimodal reasoning: removing functional heads leads to performance degradation, while emphasizing them enhances accuracy. These findings provide new insights into the cognitive organization of VLMs and suggest promising directions for designing models with more human-aligned perceptual and reasoning abilities.

</details>


### [241] [Trustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance](https://arxiv.org/abs/2512.10304)
*Byeong Ho Kang,Wenli Yang,Muhammad Bilal Amin*

Main category: cs.AI

TL;DR: 本文提出了一个名为‘可信编排AI的十大标准’的综合保障框架，旨在将治理嵌入AI系统的执行架构中，以弥合技术能力与制度问责之间的差距。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统在关键决策中的角色日益重要，技术能力与制度问责之间出现了显著差距，仅靠伦理指导不足以应对这一挑战，亟需将治理机制嵌入AI生态系统的执行层面。

Method: 提出‘可信编排AI的十大标准’框架，构建融合人类输入、语义一致性、审计与溯源完整性的统一控制面板架构，并借鉴国际标准及澳大利亚国家AI保障框架。

Result: 该框架为整个AI组件、使用者及人类参与者提供全面治理覆盖，证明了可信性可通过工程化方式系统融入AI系统。

Conclusion: 通过该框架，AI系统的执行架构可实现可验证性、透明性、可复现性及有意义的人类控制，从而提升整体可信度与制度问责能力。

Abstract: As Artificial Intelligence (AI) systems increasingly assume consequential decision-making roles, a widening gap has emerged between technical capabilities and institutional accountability. Ethical guidance alone is insufficient to counter this challenge; it demands architectures that embed governance into the execution fabric of the ecosystem. This paper presents the Ten Criteria for Trustworthy Orchestration AI, a comprehensive assurance framework that integrates human input, semantic coherence, audit and provenance integrity into a unified Control-Panel architecture. Unlike conventional agentic AI initiatives that primarily focus on AI-to-AI coordination, the proposed framework provides an umbrella of governance to the entire AI components, their consumers and human participants. By taking aspiration from international standards and Australia's National Framework for AI Assurance initiative, this work demonstrates that trustworthiness can be systematically incorporated (by engineering) into AI systems, ensuring the execution fabric remains verifiable, transparent, reproducible and under meaningful human control.

</details>


### [242] [InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck](https://arxiv.org/abs/2512.10305)
*Quanmin Wei,Penglin Dai,Wei Li,Bingyi Liu,Xiao Wu*

Main category: cs.AI

TL;DR: 本文提出InfoCom框架，基于扩展的信息瓶颈原理，通过信息净化范式实现通信高效的协同感知，在大幅降低通信开销（达440倍）的同时保持近乎无损的感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有协同感知方法通信开销大（MB级），难以满足实际网络约束；需在通信效率与感知性能间取得更好平衡。

Method: 提出基于扩展信息瓶颈理论的信息感知框架InfoCom，包含：i) 信息感知编码（压缩特征并保留任务关键信息）；ii) 稀疏掩码生成（低成本识别空间线索）；iii) 多尺度解码（掩码引导下的渐进式感知信息恢复）。

Result: 在多个数据集上验证，InfoCom将通信开销从MB级降至KB级，相比Where2comm和ERMVP分别降低440倍和90倍，同时实现近无损感知性能。

Conclusion: InfoCom首次为通信高效协同感知建立了理论基础，其信息净化范式优于传统特征操作方法，显著提升了车载协同感知的实用性与可部署性。

Abstract: Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-efficient approaches typically assume MB-level data transmission per collaboration, which may fail due to practical network constraints. To address these issues, we propose InfoCom, an information-aware framework establishing the pioneering theoretical foundation for communication-efficient collaborative perception via extended Information Bottleneck principles. Departing from mainstream feature manipulation, InfoCom introduces a novel information purification paradigm that theoretically optimizes the extraction of minimal sufficient task-critical information under Information Bottleneck constraints. Its core innovations include: i) An Information-Aware Encoding condensing features into minimal messages while preserving perception-relevant information; ii) A Sparse Mask Generation identifying spatial cues with negligible communication cost; and iii) A Multi-Scale Decoding that progressively recovers perceptual information through mask-guided mechanisms rather than simple feature reconstruction. Comprehensive experiments across multiple datasets demonstrate that InfoCom achieves near-lossless perception while reducing communication overhead from megabyte to kilobyte-scale, representing 440-fold and 90-fold reductions per agent compared to Where2comm and ERMVP, respectively.

</details>


### [243] [EpiPlanAgent: Agentic Automated Epidemic Response Planning](https://arxiv.org/abs/2512.10313)
*Kangkun Mao,Fang Xu,Jinru Ding,Yidong Jiang,Yujun Yao,Yirong Chen,Junming Liu,Xiaoqin Wu,Qian Wu,Xiaoyan Huang,Jie Xu*

Main category: cs.AI

TL;DR: This paper introduces EpiPlanAgent, an LLM-based multi-agent system that automates epidemic response plan generation and validation, showing improved completeness, guideline alignment, and efficiency over manual methods.


<details>
  <summary>Details</summary>
Motivation: Epidemic response planning is essential but traditionally labor-intensive and manual, creating a need for automation to improve speed, consistency, and scalability.

Method: The authors designed EpiPlanAgent—a multi-agent framework integrating task decomposition, knowledge grounding, and simulation modules—using large language models to generate and validate digital emergency response plans. It was evaluated by public health professionals using real-world outbreak scenarios.

Result: EpiPlanAgent significantly improved plan completeness and alignment with guidelines, drastically reduced development time versus manual workflows, and showed high content consistency between AI-generated and human-authored plans, as confirmed by expert evaluation and user feedback.

Conclusion: EpiPlanAgent is an effective and scalable solution for intelligent epidemic response planning, demonstrating how agentic AI can enhance public health preparedness.

Abstract: Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.

</details>


### [244] [User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation](https://arxiv.org/abs/2512.10322)
*Yongqiang Yu,Xuhui Li,Hazza Mahmood,Jinxing Zhou,Haodong Hong,Longtao Jiang,Zhiqiang Xu,Qi Wu,Xiaojun Chang*

Main category: cs.AI

TL;DR: 本文提出了一种基于用户反馈的视觉-语言导航（VLN）持续适应框架，将人类反馈（如指令修正）转化为高质量训练数据，并结合记忆库热启动机制，显著提升了导航成功率与路径效率，尤其在环境动态更新时保持稳定性能。


<details>
  <summary>Details</summary>
Motivation: 现有GSA-VLN方法依赖无监督的环境重复暴露，忽略了用户反馈这一自然、高价值的监督信号，难以满足真实部署中对高质量、快速适应的需求。

Method: 构建用户反馈驱动的适应框架：将用户提供的导航指令和纠正信号转化为环境对齐的训练数据；引入记忆库热启动机制，复用历史环境知识以缓解冷启动问题。

Result: 在GSA-R2R基准上，该方法持续超越GR-DUET等强基线，提升导航成功率达显著水平，路径效率更高；记忆库热启动有效稳定早期导航表现，降低更新后的性能下降；在连续与混合适应设置下均表现出鲁棒性与泛化性。

Conclusion: 用户反馈是提升VLN持续适应能力的关键因素，所提框架通过结构化利用反馈与知识复用，更贴近真实世界部署需求，为GSA-VLN提供了实用且可扩展的新范式。

Abstract: Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.

</details>


### [245] [V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions](https://arxiv.org/abs/2512.10822)
*Mumuksh Tayal,Manan Tayal,Aditya Singh,Shishir Kolathaya,Ravi Prakash*

Main category: cs.AI

TL;DR: 本文提出V-OCBF框架，通过离线示范数据学习神经控制屏障函数（CBF），无需系统动力学模型或专家设计屏障，结合期望分位数目标与QP安全控制器，在多个案例中显著减少安全违规，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有安全离线强化学习方法仅满足软约束，无法保证前向不变性；而传统CBF依赖专家设计或精确动力学模型，限制其在实际中的应用。

Method: 提出Value-Guided Offline CBF（V-OCBF）：1）基于离线演示学习神经CBF；2）采用递归有限差分屏障更新实现模型无关学习；3）引入expectile-based目标避免OOD动作查询并限制更新于数据支持的动作集；4）将学习到的CBF嵌入QP实现实时安全控制。

Result: 在多个案例研究中，V-OCBF相比基线方法显著降低安全违规次数，同时维持强任务性能，验证了其在无在线交互、无手工设计屏障下的可扩展性。

Conclusion: V-OCBF为安全关键控制器的离线合成提供了新范式，兼顾理论安全性保障与数据驱动实用性。

Abstract: Ensuring safety in autonomous systems requires controllers that satisfy hard, state-wise constraints without relying on online interaction. While existing Safe Offline RL methods typically enforce soft expected-cost constraints, they do not guarantee forward invariance. Conversely, Control Barrier Functions (CBFs) provide rigorous safety guarantees but usually depend on expert-designed barrier functions or full knowledge of the system dynamics. We introduce Value-Guided Offline Control Barrier Functions (V-OCBF), a framework that learns a neural CBF entirely from offline demonstrations. Unlike prior approaches, V-OCBF does not assume access to the dynamics model; instead, it derives a recursive finite-difference barrier update, enabling model-free learning of a barrier that propagates safety information over time. Moreover, V-OCBF incorporates an expectile-based objective that avoids querying the barrier on out-of-distribution actions and restricts updates to the dataset-supported action set. The learned barrier is then used with a Quadratic Program (QP) formulation to synthesize real-time safe control. Across multiple case studies, V-OCBF yields substantially fewer safety violations than baseline methods while maintaining strong task performance, highlighting its scalability for offline synthesis of safety-critical controllers without online interaction or hand-engineered barriers.

</details>


### [246] [On the Collapse of Generative Paths: A Criterion and Correction for Diffusion Steering](https://arxiv.org/abs/2512.10339)
*Ziseok Lee,Minyeong Hwang,Sanghyun Jo,Wooyeol Lee,Jihyung Ko,Young Bin Park,Jae-Mun Choi,Eunho Yang,Kyungsu Kim*

Main category: cs.AI

TL;DR: 本文提出ACE方法解决扩散/流模型推理时steering中的边际路径坍缩问题，通过自适应指数修正确保概率路径有效性，并在分子设计等任务中显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于密度比的推理时steering方法在组合异构模型（如不同噪声调度或数据集训练的模型）时会出现边际路径坍缩（Marginal Path Collapse），导致中间密度不可归一化，限制其在分子设计等关键场景中的可靠应用。

Method: 首先推导出仅依赖噪声调度和指数的路径存在性判据；其次提出自适应路径修正与指数法（ACE），将Feynman-Kac steering扩展至时变指数，保证生成路径始终为有效概率路径。

Result: ACE在2D合成基准和柔性姿态支架修饰任务中彻底消除坍缩，支持高引导强度的组合生成，在分布匹配与对接指标上超越固定指数基线及专用模型。

Conclusion: ACE使基于异构专家模型的密度比steering从不稳定启发式方法转变为可控生成的可靠工具。

Abstract: Inference-time steering enables pretrained diffusion/flow models to be adapted to new tasks without retraining. A widely used approach is the ratio-of-densities method, which defines a time-indexed target path by reweighting probability-density trajectories from multiple models with positive, or in some cases, negative exponents. This construction, however, harbors a critical and previously unformalized failure mode: Marginal Path Collapse, where intermediate densities become non-normalizable even though endpoints remain valid. Collapse arises systematically when composing heterogeneous models trained on different noise schedules or datasets, including a common setting in molecular design where de-novo, conformer, and pocket-conditioned models must be combined for tasks such as flexible-pose scaffold decoration. We provide a novel and complete solution for the problem. First, we derive a simple path existence criterion that predicts exactly when collapse occurs from noise schedules and exponents alone. Second, we introduce Adaptive path Correction with Exponents (ACE), which extends Feynman-Kac steering to time-varying exponents and guarantees a valid probability path. On a synthetic 2D benchmark and on flexible-pose scaffold decoration, ACE eliminates collapse and enables high-guidance compositional generation, improving distributional and docking metrics over constant-exponent baselines and even specialized task-specific scaffold decoration models. Our work turns ratio-of-densities steering with heterogeneous experts from an unstable heuristic into a reliable tool for controllable generation.

</details>


### [247] [REMISVFU: Vertical Federated Unlearning via Representation Misdirection for Intermediate Output Feature](https://arxiv.org/abs/2512.10348)
*Wenhan Wu,Zhili He,Huanghuang Liang,Yili Gong,Jiawei Jiang,Chuang Hu,Dazhao Cheng*

Main category: cs.AI

TL;DR: 本文提出REMISVFU框架，用于垂直联邦学习（VFL）中的高效客户端级模型遗忘，通过锚点扰动与梯度正交优化，在保障剩余参与方模型效用的同时实现快速、可插拔的遗忘。


<details>
  <summary>Details</summary>
Motivation: GDPR等数据保护法规赋予参与者‘被遗忘权’，而现有联邦遗忘方法主要面向水平联邦学习（HFL），难以适用于特征划分的垂直联邦学习（VFL）场景。

Method: 提出REMISVFU：遗忘方将编码器输出坍缩至单位球上随机锚点以切断其特征与全局模型的统计关联；服务器联合优化保留损失与遗忘损失，并通过正交投影对齐梯度以避免干扰。

Result: 在公开基准测试中，REMISVFU将后门攻击成功率压制至自然类别先验水平，仅损失约2.5%干净准确率，性能优于当前最优基线。

Conclusion: REMISVFU为VFL系统提供了首个可插拔、高效且实用的客户端级遗忘方案，兼顾隐私合规性与模型效用。

Abstract: Data-protection regulations such as the GDPR grant every participant in a federated system a right to be forgotten. Federated unlearning has therefore emerged as a research frontier, aiming to remove a specific party's contribution from the learned model while preserving the utility of the remaining parties. However, most unlearning techniques focus on Horizontal Federated Learning (HFL), where data are partitioned by samples. In contrast, Vertical Federated Learning (VFL) allows organizations that possess complementary feature spaces to train a joint model without sharing raw data. The resulting feature-partitioned architecture renders HFL-oriented unlearning methods ineffective. In this paper, we propose REMISVFU, a plug-and-play representation misdirection framework that enables fast, client-level unlearning in splitVFL systems. When a deletion request arrives, the forgetting party collapses its encoder output to a randomly sampled anchor on the unit sphere, severing the statistical link between its features and the global model. To maintain utility for the remaining parties, the server jointly optimizes a retention loss and a forgetting loss, aligning their gradients via orthogonal projection to eliminate destructive interference. Evaluations on public benchmarks show that REMISVFU suppresses back-door attack success to the natural class-prior level and sacrifices only about 2.5% points of clean accuracy, outperforming state-of-the-art baselines.

</details>


### [248] [LLM-Empowered Representation Learning for Emerging Item Recommendation](https://arxiv.org/abs/2512.10370)
*Ziying Zhang,Quanming Yao,Yaqing Wang*

Main category: cs.AI

TL;DR: 本文提出EmerFlow框架，利用大语言模型（LLM）增强新兴物品的表征学习，通过特征增强、空间对齐和元学习微调，在仅有少量交互数据的情况下生成高质量嵌入，显著提升新兴物品推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法常假设新兴物品缺乏历史交互，忽略了其交互随时间动态积累的过程，导致无法兼顾新兴物品的独特性与与成熟物品的共性模式。

Method: 提出EmerFlow框架：1）利用LLM对新兴物品原始特征进行推理增强；2）将增强后的特征对齐到现有推荐模型的嵌入空间；3）通过元学习整合新增交互以微调嵌入。

Result: 在电影和药品等多个领域实验表明，EmerFlow在新兴物品推荐任务上持续优于现有方法。

Conclusion: EmerFlow能有效利用有限交互数据学习新兴物品的强表达力嵌入，为动态演化的推荐场景提供了新思路。

Abstract: In this work, we tackle the challenge of recommending emerging items, whose interactions gradually accumulate over time. Existing methods often overlook this dynamic process, typically assuming that emerging items have few or even no historical interactions. Such an assumption oversimplifies the problem, as a good model must preserve the uniqueness of emerging items while leveraging their shared patterns with established ones. To address this challenge, we propose EmerFlow, a novel LLM-empowered representation learning framework that generates distinctive embeddings for emerging items. It first enriches the raw features of emerging items through LLM reasoning, then aligns these representations with the embedding space of the existing recommendation model. Finally, new interactions are incorporated through meta-learning to refine the embeddings. This enables EmerFlow to learn expressive embeddings for emerging items from only limited interactions. Extensive experiments across diverse domains, including movies and pharmaceuticals, show that EmerFlow consistently outperforms existing methods.

</details>


### [249] [AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management](https://arxiv.org/abs/2512.10371)
*Shizuo Tian,Hao Wen,Yuxuan Chen,Jiacheng Liu,Shanhui Zhao,Guohong Liu,Ju Ren,Yunxin Liu,Yuanchun Li*

Main category: cs.AI

TL;DR: AgentProg 提出一种程序引导的上下文管理方法，将交互历史建模为带变量和控制流的程序，并引入全局信念状态机制以应对部分可观测性和环境变化，在长周期移动GUI任务中实现SOTA性能且保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有移动GUI智能体在长周期任务中受限于不断增长的交互历史带来的上下文开销，且传统压缩方法易丢失关键语义信息，导致性能下降。

Method: 提出AgentProg：1）将交互历史建模为结构化程序（含变量与控制流），据此有原则地筛选保留/丢弃信息；2）引入受Belief MDP启发的全局信念状态机制，以应对部分可观测性与环境突变。

Result: 在AndroidWorld及自建长周期任务套件上达到当前最优成功率；相比基线方法在长周期任务中性能不退化，展现出显著鲁棒性。

Conclusion: 程序化建模交互历史并结合信念状态机制，可有效缓解上下文膨胀问题，为长周期移动GUI自动化提供可扩展、鲁棒的新范式。

Abstract: The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.

</details>


### [250] [Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning](https://arxiv.org/abs/2412.20505)
*Hang Ni,Yuzhi Wang,Hao Liu*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的循环城市规划（CUP）新范式，通过规划、模拟居民生活和评估反馈三个环节构成多智能体闭环系统，实现对城市更新的动态、自适应规划。


<details>
  <summary>Details</summary>
Motivation: 城市更新在快速城市化背景下面临持续演化的挑战，亟需更灵活、自适应的规划方法。

Method: 构建基于多LLM智能体的循环框架，包含规划（Plan）、模拟生活（Living）和评估反馈（Judge）三个模块，形成闭环迭代流程。

Result: 在真实世界数据集上的实验验证了该框架作为连续、自适应规划过程的有效性。

Conclusion: CUP范式为城市再生提供了可扩展、可迭代、情境感知的新路径，展示了LLM在复杂城市系统建模与决策中的潜力。

Abstract: Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.

</details>


### [251] [Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention](https://arxiv.org/abs/2512.10414)
*Yang Yu,Zhuangzhuang Chen,Siqi Wang,Lanqing Li,Xiaomeng Li*

Main category: cs.AI

TL;DR: 本文提出了一种选择性对抗熵干预方法（SaEI），通过在强化学习采样阶段引入基于响应熵的视觉输入对抗扰动，提升视觉语言模型的策略探索能力与推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的VLM微调方法大多只在策略优化阶段干预熵，忽略了在RL采样阶段进行熵干预以提升响应多样性、从而增强GRPO性能的机会。

Method: 提出Selective-adversarial Entropy Intervention（SaEI），包含两部分：1）熵引导的对抗采样（EgAS），将采样响应的熵建模为对抗目标，利用其梯度攻击视觉输入生成对抗样本；2）词元选择性熵计算（TsEC），在不损害VLM事实知识的前提下提升对抗攻击有效性。

Result: 在域内和域外数据集上的大量实验表明，SaEI显著提升了策略探索能力，从而增强了VLM的推理能力。

Conclusion: 在RL采样阶段进行有针对性的熵干预（尤其是结合视觉对抗扰动与词元选择性熵计算）是提升VLM推理能力的有效新范式。

Abstract: Recently, reinforcement learning (RL) has become a common choice in enhancing the reasoning capabilities of vision-language models (VLMs). Considering existing RL- based finetuning methods, entropy intervention turns out to be an effective way to benefit exploratory ability, thereby improving policy performance. Notably, most existing stud- ies intervene in entropy by simply controlling the update of specific tokens during policy optimization of RL. They ig- nore the entropy intervention during the RL sampling that can boost the performance of GRPO by improving the di- versity of responses. In this paper, we propose Selective- adversarial Entropy Intervention, namely SaEI, which en- hances policy entropy by distorting the visual input with the token-selective adversarial objective coming from the en- tropy of sampled responses. Specifically, we first propose entropy-guided adversarial sampling (EgAS) that formu- lates the entropy of sampled responses as an adversarial ob- jective. Then, the corresponding adversarial gradient can be used to attack the visual input for producing adversarial samples, allowing the policy model to explore a larger an- swer space during RL sampling. Then, we propose token- selective entropy computation (TsEC) to maximize the ef- fectiveness of adversarial attack in EgAS without distorting factual knowledge within VLMs. Extensive experiments on both in-domain and out-of-domain datasets show that our proposed method can greatly improve policy exploration via entropy intervention, to boost reasoning capabilities. Code will be released once the paper is accepted.

</details>


### [252] [Representation of the structure of graphs by sequences of instructions](https://arxiv.org/abs/2512.10429)
*Ezequiel Lopez-Rubio*

Main category: cs.AI

TL;DR: 本文提出了一种将图的邻接矩阵转化为可被深度学习语言模型处理的字符串指令序列的新表示方法，该方法可逆、紧凑且保留图的局部结构模式，并通过初步实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有图表示方法（如邻接矩阵）难以被专为文本设计的深度学习语言模型直接处理，亟需一种兼容性强、结构保持好的新图表示形式。

Method: 将图的邻接矩阵编码为一系列构建该矩阵的简单字符串指令，该编码过程可逆，且能保持图的局部结构模式。

Result: 所提表示法紧凑、可逆、保结构，并在初步计算实验中展现出对深度学习模型处理图数据的提升潜力。

Conclusion: 该字符串化图表示法为桥接图计算与大语言模型提供了新思路，有望增强深度学习模型对图数据的理解与处理能力。

Abstract: The representation of graphs is commonly based on the adjacency matrix concept. This formulation is the foundation of most algebraic and computational approaches to graph processing. The advent of deep learning language models offers a wide range of powerful computational models that are specialized in the processing of text. However, current procedures to represent graphs are not amenable to processing by these models. In this work, a new method to represent graphs is proposed. It represents the adjacency matrix of a graph by a string of simple instructions. The instructions build the adjacency matrix step by step. The transformation is reversible, i.e. given a graph the string can be produced and vice versa. The proposed representation is compact and it maintains the local structural patterns of the graph. Therefore, it is envisaged that it could be useful to boost the processing of graphs by deep learning models. A tentative computational experiment is reported, with favorable results.

</details>


### [253] [Targeted Data Protection for Diffusion Model by Matching Training Trajectory](https://arxiv.org/abs/2512.10433)
*Hojun Lee,Mijin Koo,Yeji Song,Nojun Kwak*

Main category: cs.AI

TL;DR: 本文提出TAFAP方法，通过对抗扰动微调实现扩散模型的轨迹对齐，首次在细调过程中实现稳定、可验证的目标数据保护（TDP），同时保持高质量图像生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型个性化微调存在未经授权的数据使用和隐私侵犯风险；当前保护方法仅被动降低图像质量，缺乏稳定可控性；已有TDP方法因基于快照匹配而无法应对完整学习动态，导致可控性差。

Method: 提出TAFAP（Trajectory Alignment via Fine-tuning with Adversarial Perturbations），采用受数据集蒸馏启发的轨迹匹配机制，在整个微调过程中持续施加可验证的对抗扰动，替代传统快照匹配策略。

Result: 首次在扩散模型中成功实现兼顾身份与视觉模式的目标概念定向转换；显著优于现有TDP方法，在保证高图像质量的同时实现鲁棒的目标重定向；提供可验证的隐私保护机制及模型输出变更的可追溯框架。

Conclusion: TAFAP为扩散模型提供了首个有效、可控、可验证的目标数据保护方案，推动了模型微调中隐私保护从被动降质向主动轨迹控制的范式转变。

Abstract: Recent advancements in diffusion models have made fine-tuning text-to-image models for personalization increasingly accessible, but have also raised significant concerns regarding unauthorized data usage and privacy infringement. Current protection methods are limited to passively degrading image quality, failing to achieve stable control. While Targeted Data Protection (TDP) offers a promising paradigm for active redirection toward user-specified target concepts, existing TDP attempts suffer from poor controllability due to snapshot-matching approaches that fail to account for complete learning dynamics. We introduce TAFAP (Trajectory Alignment via Fine-tuning with Adversarial Perturbations), the first method to successfully achieve effective TDP by controlling the entire training trajectory. Unlike snapshot-based methods whose protective influence is easily diluted as training progresses, TAFAP employs trajectory-matching inspired by dataset distillation to enforce persistent, verifiable transformations throughout fine-tuning. We validate our method through extensive experiments, demonstrating the first successful targeted transformation in diffusion models with simultaneous control over both identity and visual patterns. TAFAP significantly outperforms existing TDP attempts, achieving robust redirection toward target concepts while maintaining high image quality. This work enables verifiable safeguards and provides a new framework for controlling and tracing alterations in diffusion model outputs.

</details>


### [254] [When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection](https://arxiv.org/abs/2512.10449)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Jahnvi Singh,Vinay Chamola,Yash Sinha,Murari Mandal,Dhruv Kumar*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型（LLM）作为审稿人（LLM-as-a-Judge）在科学同行评审中面对对抗性PDF篡改时的鲁棒性，提出新指标WAVS，并通过200篇论文和15种攻击策略验证多种主流模型易受干扰，尤其某些混淆策略可显著翻转拒稿决定。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被个人评审员自发使用及会议机构正式部署AI审稿系统，其安全性与鲁棒性面临挑战；本文聚焦于对抗性PDF操纵是否能将‘拒稿’决策翻转为‘接受’，以揭示潜在风险。

Method: 构建包含200篇科学论文的数据集，设计并适配15种领域特定的PDF对抗攻击策略，提出新评估指标WAVS（加权对抗脆弱性得分），在13个主流语言模型（含GPT-5、Claude Haiku、DeepSeek等）上进行系统性评测。

Result: 多种混淆类攻击（如‘Maximum Mark Magyk’）成功诱导模型评分异常，导致显著的决策翻转率，甚至在大模型上也表现脆弱；WAVS指标有效量化了不同模型与攻击组合的脆弱性。

Conclusion: 当前LLM-as-a-Judge系统对PDF层面的对抗性操纵高度脆弱，亟需加强防御机制与评估标准；作者将开源数据集与注入框架以推动后续研究。

Abstract: The landscape of scientific peer review is rapidly evolving with the integration of Large Language Models (LLMs). This shift is driven by two parallel trends: the widespread individual adoption of LLMs by reviewers to manage workload (the "Lazy Reviewer" hypothesis) and the formal institutional deployment of AI-powered assessment systems by conferences like AAAI and Stanford's Agents4Science. This study investigates the robustness of these "LLM-as-a-Judge" systems (both illicit and sanctioned) to adversarial PDF manipulation. Unlike general jailbreaks, we focus on a distinct incentive: flipping "Reject" decisions to "Accept," for which we develop a novel evaluation metric which we term as WAVS (Weighted Adversarial Vulnerability Score). We curated a dataset of 200 scientific papers and adapted 15 domain-specific attack strategies to this task, evaluating them across 13 Language Models, including GPT-5, Claude Haiku, and DeepSeek. Our results demonstrate that obfuscation strategies like "Maximum Mark Magyk" successfully manipulate scores, achieving alarming decision flip rates even in large-scale models. We will release our complete dataset and injection framework to facilitate more research on this topic.

</details>


### [255] [Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation](https://arxiv.org/abs/2512.10501)
*Lim Chien Her,Ming Yan,Yunshu Bai,Ruihao Li,Hao Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种无需训练的LLM双智能体架构（Actor-Critic），用于零样本配置程序化内容生成（PCG）工具的参数，显著提升了从自然语言指令生成3D地图的准确性与多样性。


<details>
  <summary>Details</summary>
Motivation: 现有PCG工具依赖难以理解的技术参数配置，而通用大模型难以弥合用户自然语言指令与严格参数规范之间的语义鸿沟。

Method: 设计无训练的双LLM智能体架构：Actor负责生成参数配置，Critic负责评估并反馈修正，通过多轮迭代推理实现对齐人类设计意图。

Result: 在3D地图生成任务上超越单智能体基线，生成多样且结构合法的环境；建立了PCG领域指令遵循的新基准。

Conclusion: 无需微调即可将现成大模型重构为通用PCG控制智能体，将学习负担从模型训练转向系统级推理架构，为操控复杂软件提供了可扩展新范式。

Abstract: Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.

</details>


### [256] [Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning](https://arxiv.org/abs/2512.10534)
*Haiteng Zhao,Junhao Shen,Yiming Zhang,Songyang Gao,Kuikun Liu,Tianyou Ma,Fan Zheng,Dahua Lin,Wenwei Zhang,Kai Chen*

Main category: cs.AI

TL;DR: 本文提出InternGeometry，首个达到IMO金牌水平的几何问题求解大语言模型代理，通过迭代提出命题与辅助构造、符号引擎验证及动态记忆机制，在仅用13K样本（AlphaGeometry 2的0.004%）下解决50道IMO几何题中的44道，并能生成人类解法中未见的新颖辅助构造。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在几何问题求解中受限于辅助构造启发式能力弱，而专家模型（如AlphaGeometry 2）依赖大规模数据合成与搜索；本文旨在探索LLM代理能否以极小数据实现专家级几何推理能力。

Method: 提出InternGeometry框架：1）迭代式提案—验证—反思循环，结合符号引擎进行严格验证；2）动态内存机制支持每题超200次引擎交互；3）引入复杂度递增的强化学习（CBRL）策略加速训练。

Result: 在2000–2024年共50道IMO几何题上解决44道，超越IMO金牌得主平均分（40.9分）；仅用13K训练样本；可生成人类解法中未出现的新颖辅助构造。

Conclusion: LLM代理可通过与符号系统的深度协同和高效学习策略，在极低数据成本下达到甚至超越人类专家水平，为AI几何求解开辟新路径。

Abstract: Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.

</details>


### [257] [NormCode: A Semi-Formal Language for Context-Isolated AI Planning](https://arxiv.org/abs/2512.10563)
*Xin Guan*

Main category: cs.AI

TL;DR: NormCode是一种半形式化语言，用于构建多步LLM推理流程，通过数据隔离、语义与句法操作分离、多格式支持（.ncds/.ncd/.ncn）来消除上下文污染，提升AI工作流的可靠性、可审计性与透明度。


<details>
  <summary>Details</summary>
Motivation: 多步LLM工作流存在上下文污染问题，导致幻觉、混淆中间输出及违反任务约束，亟需提升可靠性与可审计性，尤其在法律、医疗、金融等高风险领域。

Method: 提出NormCode半形式化语言：定义数据隔离的推理步骤；严格分离语义操作（LLM驱动、非确定性）与句法操作（确定性数据重构）；支持三种等价格式（.ncds人写、.ncd机执行、.ncn人审）；配套实现依赖调度、SQLite检查点与循环管理的运行时。

Result: 验证了两个案例：(1) 基数X加法算法对任意长度输入达100%准确率；(2) NormCode自托管编译器五阶段流水线成功运行；运行时支持可审计、可复现的AI工作流。

Conclusion: NormCode从语言设计层面根治上下文污染，为高可靠性、可验证、可审计的AI工作流提供了可行框架，推动LLM应用向关键领域落地。

Abstract: Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode's own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.

</details>


### [258] [Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs](https://arxiv.org/abs/2512.10611)
*Minghao LI,Ruihang Wang,Rui Tan,Yonggang Wen*

Main category: cs.AI

TL;DR: 本文提出Phythesis框架，结合大语言模型（LLM）与物理引导的进化优化，实现面向能效数据中心设计的仿真就绪（SimReady）三维场景自动生成。


<details>
  <summary>Details</summary>
Motivation: 传统数据中心设计方法难以应对系统复杂性增长；现有基于生成式AI的方法缺乏物理建模能力，无法满足数据中心对量化运行目标和严格物理约束的要求。

Method: 提出双层迭代优化架构：上层由LLM驱动，生成并自批评三维布局以优化拓扑结构；下层为物理信息优化，搜索最优设备参数与组合。整体框架融合LLM与物理仿真指导的进化算法。

Result: 在三个生成规模实验中，相比纯LLM方案，Phythesis将生成成功率提升57.3%，PUE降低11.5%。

Conclusion: Phythesis有效弥合了生成式AI与物理约束设计之间的鸿沟，为自动化、高保真、能效导向的数据中心基础设施设计提供了新范式。

Abstract: Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial intelligence to design plausible human-centric indoor layouts. However, they do not consider the underlying physics, making them unsuitable for the DC design that sets quantifiable operational objectives and strict physical constraints. To bridge the gap, we propose Phythesis, a novel framework that synergizes large language models (LLMs) and physics-guided evolutionary optimization to automate simulation-ready (SimReady) scene synthesis for energy-efficient DC design. Phythesis employs an iterative bi-level optimization architecture, where (i) the LLM-driven optimization level generates physically plausible three-dimensional layouts and self-criticizes them to refine the scene topology, and (ii) the physics-informed optimization level identifies the optimal asset parameters and selects the best asset combination. Experiments on three generation scales show that Phythesis achieves 57.3% generation success rate increase and 11.5% power usage effectiveness (PUE) improvement, compared with the vanilla LLM-based solution.

</details>


### [259] [Refinement Contrastive Learning of Cell-Gene Associations for Unsupervised Cell Type Identification](https://arxiv.org/abs/2512.10640)
*Liang Peng,Haopeng Liu,Yixuan Ye,Cheng Liu,Wenjun Shen,Si Wu,Hau-San Wong*

Main category: cs.AI

TL;DR: 本文提出scRCL框架，通过引入细胞-基因相互作用和对比分布对齐，提升单细胞数据中细胞类型识别的准确性与生物学可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有无监督细胞类型识别方法大多忽略细胞-基因关联，难以区分高度相似的细胞类型。

Method: 提出Refinement Contrastive Learning（scRCL）框架，包含两个对比分布对齐组件挖掘细胞结构关系，并设计一个精炼模块学习基因相关性结构以增强细胞嵌入表示。

Result: 在多个单细胞RNA-seq和空间转录组基准数据集上，scRCL在细胞类型识别准确率上持续优于现有最先进方法；下游分析显示其识别的细胞群体具有连贯的基因表达特征。

Conclusion: 显式建模细胞-基因关联可显著提升无监督细胞类型识别性能与生物学意义。

Abstract: Unsupervised cell type identification is crucial for uncovering and characterizing heterogeneous populations in single cell omics studies. Although a range of clustering methods have been developed, most focus exclusively on intrinsic cellular structure and ignore the pivotal role of cell-gene associations, which limits their ability to distinguish closely related cell types. To this end, we propose a Refinement Contrastive Learning framework (scRCL) that explicitly incorporates cell-gene interactions to derive more informative representations. Specifically, we introduce two contrastive distribution alignment components that reveal reliable intrinsic cellular structures by effectively exploiting cell-cell structural relationships. Additionally, we develop a refinement module that integrates gene-correlation structure learning to enhance cell embeddings by capturing underlying cell-gene associations. This module strengthens connections between cells and their associated genes, refining the representation learning to exploiting biologically meaningful relationships. Extensive experiments on several single-cell RNA-seq and spatial transcriptomics benchmark datasets demonstrate that our method consistently outperforms state-of-the-art baselines in cell-type identification accuracy. Moreover, downstream biological analyses confirm that the recovered cell populations exhibit coherent gene-expression signatures, further validating the biological relevance of our approach. The code is available at https://github.com/THPengL/scRCL.

</details>


### [260] [Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution](https://arxiv.org/abs/2512.10696)
*Zouying Cao,Jiaji Deng,Li Yu,Weikang Zhou,Zhaoyang Liu,Bolin Ding,Hai Zhao*

Main category: cs.AI

TL;DR: 本文提出ReMe框架，通过多维度蒸馏、上下文自适应复用和效用驱动精炼，实现LLM代理经验驱动的自我进化，显著提升记忆系统性能，并展现出内存扩展效应。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理记忆系统多采用被动累积范式，将记忆视为静态只读存档，难以支持动态推理与持续演化，亟需构建能主动提炼、适配与优化经验的记忆机制。

Method: 提出ReMe框架，包含三部分：1）多维度蒸馏（识别成功模式、分析失败原因、生成对比洞察）；2）上下文自适应复用（基于场景感知索引匹配历史经验）；3）效用驱动精炼（自动增删记忆以维持高质量、紧凑的经验池）。

Result: 在BFCL-V3和AppWorld上实验表明ReMe达到记忆系统新SOTA；Qwen3-8B+ReMe超越无记忆的Qwen3-14B，验证内存扩展效应；开源代码与reme.library数据集。

Conclusion: ReMe证明了经验驱动的主动记忆演化可替代单纯扩大模型规模，为LLM代理的终身学习提供更高效、可扩展的计算路径。

Abstract: Procedural memory enables large language model (LLM) agents to internalize "how-to" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a "passive accumulation" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\textbf{ReMe}$ ($\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\texttt{reme.library}$ dataset to facilitate further research.

</details>


### [261] [CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2512.10655)
*Tong Zhang,Carlos Hinojosa,Bernard Ghanem*

Main category: cs.AI

TL;DR: CAPTAIN是一种无需训练的扩散模型记忆缓解框架，通过在去噪过程中直接修改潜在特征（如频域噪声初始化、定位记忆区域、注入非记忆参考图像的语义对齐特征）来减少训练数据复现，同时保持提示对齐与图像质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型可能无意中复现训练样本，引发隐私和版权风险；现有推理阶段方法（如调整CFG或扰动提示嵌入）常难以兼顾降低记忆化与保持提示对齐。

Method: CAPTAIN为训练无关框架：1）采用基于频率的噪声初始化以抑制早期记忆模式复现；2）识别最优去噪时间步并定位潜在空间中的记忆化区域；3）向这些局部区域注入来自非记忆参考图像的语义对齐特征。

Result: 实验表明，CAPTAIN相比CFG基线显著降低了记忆化程度，同时维持了强提示对齐性和视觉质量。

Conclusion: CAPTAIN提供了一种高效、即插即用的推理时记忆缓解方案，在不牺牲生成质量与条件一致性前提下有效抑制训练数据复现。

Abstract: Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they often struggle to reduce memorization without compromising alignment with the conditioning prompt. We introduce CAPTAIN, a training-free framework that mitigates memorization by directly modifying latent features during denoising. CAPTAIN first applies frequency-based noise initialization to reduce the tendency to replicate memorized patterns early in the denoising process. It then identifies the optimal denoising timesteps for feature injection and localizes memorized regions. Finally, CAPTAIN injects semantically aligned features from non-memorized reference images into localized latent regions, suppressing memorization while preserving prompt fidelity and visual quality. Our experiments show that CAPTAIN achieves substantial reductions in memorization compared to CFG-based baselines while maintaining strong alignment with the intended prompt.

</details>


### [262] [Replace, Don't Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly](https://arxiv.org/abs/2512.10787)
*Moshe Lahmy,Roi Yozevitch*

Main category: cs.AI

TL;DR: 本文提出SEAL-RAG，一种无需训练的RAG控制器，通过‘替换而非扩展’策略，在固定检索深度k下缓解多跳查询中的上下文稀释问题；其采用搜索→抽取→评估→循环（SEAL）流程，结合实体锚定抽取、定向微查询和实体优先排序，显著提升答案正确率与证据精度。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理多跳查询时，若初始检索遗漏桥接事实，易失败；而现有纠错方法（如Self-RAG、CRAG、Adaptive-k）依赖扩充上下文，导致上下文稀释——无关信息挤占关键信息。

Method: 提出SEAL-RAG控制器，执行Search→Extract→Assess→Loop四步循环：1）实体锚定的实时抽取构建‘缺口规范’（缺失实体/关系）；2）触发定向微查询；3）采用实体优先排序机制，主动用填补缺口的证据替换原有干扰项；全程不增加k，仅替换top-k中的低质条目。

Result: 在HotpotQA（k=3）上，相比Self-RAG，答案正确率提升+3–13个百分点，证据精度提升+12–18个百分点；在2WikiMultiHopQA（k=5）上，相比Adaptive-k准确率+8.0pp，证据精度达96%（CRAG仅22%）；所有提升均统计显著（p<0.001）。

Conclusion: SEAL-RAG通过固定k下的精准替换策略，有效抑制上下文稀释，在保证计算成本可预测的同时，显著提升多跳问答的忠实性与准确性；代码与数据已开源。

Abstract: Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \textbf{context dilution}, where distractors crowd out relevant information. We propose \textbf{SEAL-RAG}, a training-free controller that adopts a \textbf{``replace, don't expand''} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\textbf{S}earch $\rightarrow$ \textbf{E}xtract $\rightarrow$ \textbf{A}ssess $\rightarrow$ \textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \textbf{HotpotQA} and \textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \textbf{+3--13 pp} and evidence precision by \textbf{+12--18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \textbf{+8.0 pp} in accuracy and maintains \textbf{96\%} evidence precision compared to 22\% for CRAG. These gains are statistically significant ($p<0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.

</details>


### [263] [On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity](https://arxiv.org/abs/2512.10665)
*Muhua Huang,Qinlin Zhao,Xiaoyuan Yi,Xing Xie*

Main category: cs.AI

TL;DR: 本文研究价值多样性如何影响基于大语言模型的多智能体系统的集体行为，发现适度的价值多样性可增强价值稳定性、促进涌现行为和创造性原则生成，但过度异质性会导致不稳定。


<details>
  <summary>Details</summary>
Motivation: 探究价值多样性如何塑造AI社区的集体行为，特别是集体智能等现象。

Method: 基于Schwartz基本人类价值观理论进行自然主义价值提取，构建具有不同数量智能体的多智能体模拟系统，开展开放式交互与宪章形成实验。

Result: 价值多样性提升了价值稳定性、激发了更多自发涌现行为和创造性原则；但极端异质性会引发不稳定性，呈现边际效应递减。

Conclusion: 价值多样性是未来AI能力的新维度，连接AI能力与制度涌现的社会学研究。

Abstract: As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz's Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.

</details>


### [264] [AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search](https://arxiv.org/abs/2512.10671)
*Oscar Robben,Saeed Khalilian,Nirvana Meratnia*

Main category: cs.AI

TL;DR: 本文提出了一种硬件感知的神经架构搜索（NAS）方法，用于优化早期退出网络（early-exit networks）中的退出分支结构（包括深度与层类型）并结合自适应阈值调优，从而在保持或降低计算量（MACs）的同时提升准确率。


<details>
  <summary>Details</summary>
Motivation: 设计高效且高性能的早期退出网络十分困难，尤其需权衡计算效率与模型精度；现有NAS方法未充分考虑退出分支的结构细节及硬件约束。

Method: 采用硬件感知的神经架构搜索（hardware-aware NAS），联合优化退出分支的位置、数量、深度和层类型，并引入自适应阈值调优机制。

Result: 在CIFAR-10、CIFAR-100和SVHN数据集上，所提方法在相同或更低平均MACs下实现了比当前最优方法更高的准确率。

Conclusion: 退出分支的细粒度结构设计（深度、层类型）与硬件感知优化对早期退出网络的能效与精度协同提升至关重要。

Abstract: Early-exit networks are effective solutions for reducing the overall energy consumption and latency of deep learning models by adjusting computation based on the complexity of input data. By incorporating intermediate exit branches into the architecture, they provide less computation for simpler samples, which is particularly beneficial for resource-constrained devices where energy consumption is crucial. However, designing early-exit networks is a challenging and time-consuming process due to the need to balance efficiency and performance. Recent works have utilized Neural Architecture Search (NAS) to design more efficient early-exit networks, aiming to reduce average latency while improving model accuracy by determining the best positions and number of exit branches in the architecture. Another important factor affecting the efficiency and accuracy of early-exit networks is the depth and types of layers in the exit branches. In this paper, we use hardware-aware NAS to strengthen exit branches, considering both accuracy and efficiency during optimization. Our performance evaluation on the CIFAR-10, CIFAR-100, and SVHN datasets demonstrates that our proposed framework, which considers varying depths and layers for exit branches along with adaptive threshold tuning, designs early-exit networks that achieve higher accuracy with the same or lower average number of MACs compared to the state-of-the-art approaches.

</details>


### [265] [Challenges of Evaluating LLM Safety for User Welfare](https://arxiv.org/abs/2512.10687)
*Manon Kempermann,Sai Suresh Macharla Vasu,Mahalakshmi Raveenthiran,Theo Farrell,Ingmar Weber*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLM）在金融与健康等高风险个人建议场景下的用户福祉安全评估问题，指出当前通用风险评估框架不足，强调需结合多样化用户背景进行上下文感知评估；实验发现仅靠用户主动提供上下文无法弥补评估偏差，尤其对脆弱用户群体，必须由评估者主动建模用户情境才能准确判断安全性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全评估聚焦于通用风险，忽视了用户个体差异（如脆弱性）带来的上下文依赖型危害，而现实中大量用户依赖LLM获取高风险领域个人建议，亟需发展面向用户福祉的安全评估方法。

Method: 开展探索性实证研究：1）对比上下文知情 vs 无知评估者对同一LLM输出（GPT-5、Claude Sonnet 4、Gemini 2.5 Pro）在金融/健康建议上的安全评分差异；2）测试用户自述愿披露的上下文是否足以改善评估效果。

Result: 上下文无知评估者显著高估安全性（如高脆弱用户评分从3/7升至5/7）；即使加入用户实际愿披露的上下文，安全评分无显著提升；证明仅靠提示工程无法替代评估者主动建模用户画像。

Conclusion: 用户福祉导向的安全评估不能沿用通用风险框架，必须系统性纳入多样化用户档案进行上下文感知评估；本研究提供了可复现的方法论基础与实证依据，并开源代码与数据集。

Abstract: Safety evaluations of large language models (LLMs) typically focus on universal risks like dangerous capabilities or undesirable propensities. However, millions use LLMs for personal advice on high-stakes topics like finance and health, where harms are context-dependent rather than universal. While frameworks like the OECD's AI classification recognize the need to assess individual risks, user-welfare safety evaluations remain underdeveloped. We argue that developing such evaluations is non-trivial due to fundamental questions about accounting for user context in evaluation design. In this exploratory study, we evaluated advice on finance and health from GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across user profiles of varying vulnerability. First, we demonstrate that evaluators must have access to rich user context: identical LLM responses were rated significantly safer by context-blind evaluators than by those aware of user circumstances, with safety scores for high-vulnerability users dropping from safe (5/7) to somewhat unsafe (3/7). One might assume this gap could be addressed by creating realistic user prompts containing key contextual information. However, our second study challenges this: we rerun the evaluation on prompts containing context users report they would disclose, finding no significant improvement. Our work establishes that effective user-welfare safety evaluation requires evaluators to assess responses against diverse user profiles, as realistic user context disclosure alone proves insufficient, particularly for vulnerable populations. By demonstrating a methodology for context-aware evaluation, this study provides both a starting point for such assessments and foundational evidence that evaluating individual welfare demands approaches distinct from existing universal-risk frameworks. We publish our code and dataset to aid future developments.

</details>


### [266] [Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning](https://arxiv.org/abs/2512.10691)
*Benjamin Gundersen,Nicolas Deperrois,Samuel Ruiperez-Campillo,Thomas M. Sutter,Julia E. Vogt,Michael Moor,Farhad Nooralahzadeh,Michael Krauthammer*

Main category: cs.AI

TL;DR: 本文探索了在胸部X光（CXR）视觉-语言模型（RadVLM）中引入强化学习（RL）和显式中间推理（'thinking'）的效果，发现RL能带来额外性能提升，而'thinking'未见明显增益；最终RL优化的RadVLM达到报告生成与视觉定位任务的SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉-语言模型多依赖监督微调（SFT），仅优化下一词预测，缺乏对答案质量的评估；而强化学习可引入任务特异性临床反馈，结合‘思考’机制已在其他领域验证有效，故探究其在CXR VLM中的适用性。

Method: 基于Qwen3-VL构建更新版RadVLM，先进行大规模CXR数据监督微调（SFT），再通过冷启动SFT赋予基础‘思考’能力；随后采用组相对策略优化（GRPO）施加临床导向的报告生成与视觉定位奖励，并在领域专用与通用Qwen3-VL变体上开展有无‘思考’的匹配RL实验。

Result: RL在报告生成和视觉定位两项任务上均带来额外性能提升；显式‘思考’未进一步改善结果；RL优化后的RadVLM在统一评估下超越基线，达到当前最优性能（SOTA）。

Conclusion: 临床对齐的强化学习是监督微调在医学视觉-语言模型中的有力补充，能有效提升任务性能，而显式中间推理在此类医疗任务中尚未展现显著优势。

Abstract: Recent advances in vision-language models (VLMs) have improved Chest X-ray (CXR) interpretation in multiple aspects. However, many medical VLMs rely solely on supervised fine-tuning (SFT), which optimizes next-token prediction without evaluating answer quality. In contrast, reinforcement learning (RL) can incorporate task-specific feedback, and its combination with explicit intermediate reasoning ("thinking") has demonstrated substantial gains on verifiable math and coding tasks. To investigate the effects of RL and thinking in a CXR VLM, we perform large-scale SFT on CXR data to build an updated RadVLM based on Qwen3-VL, followed by a cold-start SFT stage that equips the model with basic thinking ability. We then apply Group Relative Policy Optimization (GRPO) with clinically grounded, task-specific rewards for report generation and visual grounding, and run matched RL experiments on both domain-specific and general-domain Qwen3-VL variants, with and without thinking. Across these settings, we find that while strong SFT remains crucial for high base performance, RL provides additional gains on both tasks, whereas explicit thinking does not appear to further improve results. Under a unified evaluation pipeline, the RL-optimized RadVLM models outperform their baseline counterparts and reach state-of-the-art performance on both report generation and grounding, highlighting clinically aligned RL as a powerful complement to SFT for medical VLMs.

</details>


### [267] [COMPARE: Clinical Optimization with Modular Planning and Assessment via RAG-Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to ChatGPT-5 and Junior Operators](https://arxiv.org/abs/2512.10702)
*Wei Fang,Chiyao Wang,Wenshuai Ma,Hui Liu,Jianqiang Hu,Xiaona Niu,Yi Chu,Mingming Zhang,Jingxiao Yang,Dongwei Zhang,Zelin Li,Pengyun Liu,Jiawei Zheng,Pengke Zhang,Chaoshi Qin,Wangang Guo,Bin Wang,Yugang Xue,Wei Zhang,Zikuan Wang,Rui Zhu,Yihui Cao,Quanmao Lu,Rui Meng,Yan Li*

Main category: cs.AI

TL;DR: 本文提出并评估了一种专为光学相干断层扫描（OCT）指导的经皮冠状动脉介入治疗（PCI）设计的领域专用大模型CA-GPT。在96例患者中，CA-GPT在术前规划和术后评估中均显著优于通用大模型ChatGPT-5和初级医生，尤其在支架尺寸选择等关键指标上表现突出，展现出提升OCT解读标准化与可靠性的潜力。


<details>
  <summary>Details</summary>
Motivation: OCT图像解读存在操作者依赖性，通用AI缺乏心血管介入领域的可靠性，亟需高精度、可解释、临床可用的专用AI工具。

Method: 在单中心96例OCT引导PCI病例中，将CA-GPT、ChatGPT-5和初级医生生成的术前规划与术后评估决策，与专家制定的金标准记录进行对比，采用10项预设指标评估一致性。

Result: CA-GPT在术前规划中中位一致率（5分）显著高于ChatGPT-5（3分）和初级医生（4分）；在支架直径（90.3% vs. 72.2%）和长度选择（80.6% vs. 52.8%）上亦显著更优；术后评估中整体一致性（5分）同样最优，且在复杂病变亚组中优势稳定。

Conclusion: CA-GPT作为OCT专用大模型，在PCI全流程决策支持中展现出超越通用AI和初级医生的可靠性与鲁棒性，有望成为标准化、智能化血管内影像解读的关键工具。

Abstract: Background: While intravascular imaging, particularly optical coherence tomography (OCT), improves percutaneous coronary intervention (PCI) outcomes, its interpretation is operator-dependent. General-purpose artificial intelligence (AI) shows promise but lacks domain-specific reliability. We evaluated the performance of CA-GPT, a novel large model deployed on an AI-OCT system, against that of the general-purpose ChatGPT-5 and junior physicians for OCT-guided PCI planning and assessment.
  Methods: In this single-center analysis of 96 patients who underwent OCT-guided PCI, the procedural decisions generated by the CA-GPT, ChatGPT-5, and junior physicians were compared with an expert-derived procedural record. Agreement was assessed using ten pre-specified metrics across pre-PCI and post-PCI phases.
  Results: For pre-PCI planning, CA-GPT demonstrated significantly higher median agreement scores (5[IQR 3.75-5]) compared to both ChatGPT-5 (3[2-4], P<0.001) and junior physicians (4[3-4], P<0.001). CA-GPT significantly outperformed ChatGPT-5 across all individual pre-PCI metrics and showed superior performance to junior physicians in stent diameter (90.3% vs. 72.2%, P<0.05) and length selection (80.6% vs. 52.8%, P<0.01). In post-PCI assessment, CA-GPT maintained excellent overall agreement (5[4.75-5]), significantly higher than both ChatGPT-5 (4[4-5], P<0.001) and junior physicians (5[4-5], P<0.05). Subgroup analysis confirmed CA-GPT's robust performance advantage in complex scenarios.
  Conclusion: The CA-GPT-based AI-OCT system achieved superior decision-making agreement versus a general-purpose large language model and junior physicians across both PCI planning and assessment phases. This approach provides a standardized and reliable method for intravascular imaging interpretation, demonstrating significant potential to augment operator expertise and optimize OCT-guided PCI.

</details>


### [268] [HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition](https://arxiv.org/abs/2512.10807)
*Wang Lu,Yao Zhu,Jindong Wang*

Main category: cs.AI

TL;DR: 本文提出了HAROOD，一个面向传感器人体活动识别（HAR）的分布外泛化（OOD）综合基准，涵盖4种OOD场景、6个数据集、16种方法及两种模型选择协议，并通过大量实验揭示了当前OOD方法在HAR中尚无统一最优解。


<details>
  <summary>Details</summary>
Motivation: 现实场景中个体、设备、环境和时间差异导致显著分布偏移，现有OOD方法仅在特定偏移场景下被尝试，缺乏对OOD是否必要及哪种算法最优的系统性评估。

Method: 构建HAROOD基准，定义跨人、跨位置、跨数据集、跨时间四类OOD场景；整合6个数据集、16种CNN/Transformer基线方法；设计两种模型选择协议并开展大规模实验分析。

Result: 实验表明：没有单一OOD方法在所有场景下持续最优；不同场景下方法表现差异显著；现有方法仍有较大提升空间。

Conclusion: OOD对HAR至关重要但尚未被充分探索；HAROOD为后续研究提供了可扩展、模块化的开源平台，推动OOD-HAR方向的发展。

Abstract: Sensor-based human activity recognition (HAR) mines activity patterns from the time-series sensory data. In realistic scenarios, variations across individuals, devices, environments, and time introduce significant distributional shifts for the same activities. Recent efforts attempt to solve this challenge by applying or adapting existing out-of-distribution (OOD) algorithms, but only in certain distribution shift scenarios (e.g., cross-device or cross-position), lacking comprehensive insights on the effectiveness of these algorithms. For instance, is OOD necessary to HAR? Which OOD algorithm performs the best? In this paper, we fill this gap by proposing HAROOD, a comprehensive benchmark for HAR in OOD settings. We define 4 OOD scenarios: cross-person, cross-position, cross-dataset, and cross-time, and build a testbed covering 6 datasets, 16 comparative methods (implemented with CNN-based and Transformer-based architectures), and two model selection protocols. Then, we conduct extensive experiments and present several findings for future research, e.g., no single method consistently outperforms others, highlighting substantial opportunity for advancement. Our codebase is highly modular and easy to extend for new datasets, algorithms, comparisons, and analysis, with the hope to facilitate the research in OOD-based HAR. Our implementation is released and can be found at https://github.com/AIFrontierLab/HAROOD.

</details>


### [269] [Agile Deliberation: Concept Deliberation for Subjective Visual Classification](https://arxiv.org/abs/2512.10821)
*Leijie Wang,Otilia Stretcu,Wei Qiao,Thomas Denby,Krishnamurthy Viswanathan,Enming Luo,Chun-Ta Lu,Tushar Dogra,Ranjay Krishna,Ariel Fuxman*

Main category: cs.AI

TL;DR: 本文提出了一种名为'Agile Deliberation'的人机协同框架，支持用户在概念模糊、主观且动态演化的场景下（如内容审核）通过两阶段（概念界定与概念迭代）逐步厘清并训练视觉分类器，显著提升F1分数与用户认知体验。


<details>
  <summary>Details</summary>
Motivation: 现实中的用户（如内容审核员）往往从模糊概念出发，需通过反复交互式‘概念商议’来明确意图，而现有方法多假设用户已有清晰稳定的概念理解。

Method: 基于对审核专家的访谈提炼出概念商议策略，构建Agile Deliberation框架：第一阶段为概念界定（结构化分解初始概念），第二阶段为概念迭代（呈现语义边界样例供用户反馈以对齐模型）；采用18场每场1.5小时的用户实验进行评估，而非标准数据集基准测试。

Result: 相比自动分解基线F1提升7.5%，相比人工商议提升超3%；用户报告概念理解更清晰、认知负荷更低。

Conclusion: 支持主观、演化概念的人机协同框架是可行且有效的，Agile Deliberation为内容审核等真实场景提供了更贴合实际需求的视觉分类范式。

Abstract: From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through "concept deliberation", a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called "Agile Deliberation" that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user's evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.

</details>


### [270] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding,Janell Thomson,Jon Taylor,Changwoo Do*

Main category: cs.AI

TL;DR: 本文提出利用大语言模型（LLM）替代或辅助大型用户设施中提案评审的人工流程，通过基于偏好的两两比较方法提升评审的一致性与可扩展性，并在SNS三个束线的真实数据上验证了LLM排名与人类评审高度相关、成本显著更低且支持高级分析（如提案相似性量化）。


<details>
  <summary>Details</summary>
Motivation: 传统人工评审存在评审者偏差、不一致性和弱提案间相关性问题；而更优的两两偏好比较法因计算量呈二次增长而难以由人工实施。

Method: 采用大语言模型对Spallation Neutron Source（SNS）三个束线的高质量提案进行两两偏好判断，生成排序；同时利用嵌入模型进行提案相似性定量分析，并与人类评审结果（Spearman相关系数）及后续发表潜力进行对比评估。

Result: LLM排名与人类排名呈现较强相关性（Spearman ρ ≈ 0.2–0.8，剔除10%异常值后≥0.5）；识别高发表潜力提案的能力不逊于人类，但成本降低两个数量级以上；并成功实现提案相似性等人类难以完成的定量分析。

Conclusion: LLM可作为可扩展、一致且低成本的提案评审辅助工具，在保持甚至提升评审质量的同时，拓展评审维度与效率，具备在大型科学设施中实际部署的潜力。

Abstract: We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [271] [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903)
*Muhammad Umair Haider,Hammad Rizwan,Hassan Sajjad,A. B. Siddique*

Main category: cs.AI

TL;DR: 本文提出了一种节点级剪枝框架，用于大语言模型中行为相关子网络（circuit）的发现，支持从模块到单个神经元的多粒度可学习掩码与稀疏性约束，在单次微调中实现高效、细粒度、低内存开销的电路发现。


<details>
  <summary>Details</summary>
Motivation: 现有电路发现方法依赖迭代边剪枝，计算开销大，且仅支持粗粒度（如注意力头或MLP块），无法识别更细粒度结构（如单个神经元）。

Method: 提出多粒度可学习掩码（覆盖模块至单神经元）与粒度特异性稀疏惩罚项，嵌入统一优化目标，在单次微调中完成端到端电路压缩。

Result: 所发现电路节点数更少；验证了粗粒度方法认定的重要神经元中许多实际无关；内存占用降低5–10倍（无需缓存中间激活）。

Conclusion: 该节点级剪枝框架在保持任务性能的同时，显著提升了电路发现的效率、粒度和可扩展性。

Abstract: Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.

</details>


### [272] [On Decision-Making Agents and Higher-Order Causal Processes](https://arxiv.org/abs/2512.10937)
*Matt Wilson*

Main category: cs.AI

TL;DR: 本文建立了部分可观测马尔可夫决策过程（POMDP）中的决策智能体与一输入过程函数之间的精确对应关系，并将该框架推广至多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 探索人工智能中决策智能体与量子物理中高阶操作的理论联系，寻求统一建模部分可观测环境下的智能体行为。

Method: 将智能体的策略与记忆更新联合建模为一个过程函数w，通过link product与POMDP环境交互；并进一步将该框架扩展到多输入过程函数以建模去中心化POMDP。

Result: 确立了POMDP智能体与单输入过程函数的严格对应；提出了物理视角（过程函数为环境）与AI视角（过程函数为智能体）的双重解释；将多智能体系统自然对应于多输入过程函数。

Conclusion: 该工作架起了人工智能决策理论与高阶量子过程理论之间的桥梁，为跨学科建模提供了新范式。

Abstract: We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [273] [Neural Hamiltonian Deformation Fields for Dynamic Scene Rendering](https://arxiv.org/abs/2512.10424)
*Hai-Long Qin,Sixian Wang,Guo Lu,Jincheng Dai*

Main category: cs.GR

TL;DR: NeHaD 提出了一种基于哈密顿力学的神经变形场方法，用于动态高斯点绘（Gaussian Splatting），通过物理先验提升运动真实性与渲染质量，并支持自适应流式传输。


<details>
  <summary>Details</summary>
Motivation: 现有动态视图合成方法虽渲染质量高，但运动常违反物理规律；MLP预测的形变场存在固有偏差，导致不自然动态。

Method: 提出NeHaD：1）用哈密顿神经网络建模高斯形变，利用相空间结构保证能量守恒；2）引入玻尔兹曼平衡分解，按时空能量状态自适应分离动静态高斯；3）采用二阶辛积分与局部刚性正则化处理现实耗散；4）结合尺度感知mipmapping与渐进优化实现自适应流式渲染。

Result: 在多个动态场景上实现了物理合理、高质量、高效率的渲染，首次将哈密顿力学引入神经高斯形变建模，并支持流式传输。

Conclusion: 将物理先验（尤其是哈密顿力学）融入神经辐射场形变建模可显著提升动态场景的真实性与鲁棒性，为物理驱动的神经图形学提供了新范式。

Abstract: Representing and rendering dynamic scenes with complex motions remains challenging in computer vision and graphics. Recent dynamic view synthesis methods achieve high-quality rendering but often produce physically implausible motions. We introduce NeHaD, a neural deformation field for dynamic Gaussian Splatting governed by Hamiltonian mechanics. Our key observation is that existing methods using MLPs to predict deformation fields introduce inevitable biases, resulting in unnatural dynamics. By incorporating physics priors, we achieve robust and realistic dynamic scene rendering. Hamiltonian mechanics provides an ideal framework for modeling Gaussian deformation fields due to their shared phase-space structure, where primitives evolve along energy-conserving trajectories. We employ Hamiltonian neural networks to implicitly learn underlying physical laws governing deformation. Meanwhile, we introduce Boltzmann equilibrium decomposition, an energy-aware mechanism that adaptively separates static and dynamic Gaussians based on their spatial-temporal energy states for flexible rendering. To handle real-world dissipation, we employ second-order symplectic integration and local rigidity regularization as physics-informed constraints for robust dynamics modeling. Additionally, we extend NeHaD to adaptive streaming through scale-aware mipmapping and progressive optimization. Extensive experiments demonstrate that NeHaD achieves physically plausible results with a rendering quality-efficiency trade-off. To our knowledge, this is the first exploration leveraging Hamiltonian mechanics for neural Gaussian deformation, enabling physically realistic dynamic scene rendering with streaming capabilities.

</details>


### [274] [DeMapGS: Simultaneous Mesh Deformation and Surface Attribute Mapping via Gaussian Splatting](https://arxiv.org/abs/2512.10572)
*Shuyi Zhou,Shengze Zhong,Kenshi Takayama,Takafumi Taketomi,Takeshi Oishi*

Main category: cs.GR

TL;DR: DeMapGS is a novel Gaussian Splatting framework that jointly optimizes deformable surfaces and surface-attached 2D Gaussian splats, improving topology consistency, editing flexibility, and mesh reconstruction quality.


<details>
  <summary>Details</summary>
Motivation: Prior Gaussian Splatting methods treat points independently, leading to topological inconsistencies and limited editing flexibility. There's a need for a unified representation that supports high-fidelity mesh reconstruction and downstream editing tasks.

Method: DeMapGS anchors 2D Gaussian splats to a deformable template mesh, enabling joint optimization of surfaces and splats. It introduces gradient diffusion for robust optimization and an alternating 2D/3D rendering scheme to handle concave regions.

Result: DeMapGS achieves state-of-the-art mesh reconstruction quality and enables downstream applications such as editing and cross-object manipulation via a shared parametric surface.

Conclusion: By unifying deformable surfaces with Gaussian splats, DeMapGS overcomes key limitations of prior methods, offering improved topology, photorealistic rendering, and enhanced editing capabilities.

Abstract: We propose DeMapGS, a structured Gaussian Splatting framework that jointly optimizes deformable surfaces and surface-attached 2D Gaussian splats. By anchoring splats to a deformable template mesh, our method overcomes topological inconsistencies and enhances editing flexibility, addressing limitations of prior Gaussian Splatting methods that treat points independently. The unified representation in our method supports extraction of high-fidelity diffuse, normal, and displacement maps, enabling the reconstructed mesh to inherit the photorealistic rendering quality of Gaussian Splatting. To support robust optimization, we introduce a gradient diffusion strategy that propagates supervision across the surface, along with an alternating 2D/3D rendering scheme to handle concave regions. Experiments demonstrate that DeMapGS achieves state-of-the-art mesh reconstruction quality and enables downstream applications for Gaussian splats such as editing and cross-object manipulation through a shared parametric surface.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [275] [Openpi Comet: Competition Solution For 2025 BEHAVIOR Challenge](https://arxiv.org/abs/2512.10071)
*Junjie Bai,Yu-Wei Chao,Qizhi Chen,Jinwei Gu,Moo Jin Kim,Zhaoshuo Li,Xuan Li,Tsung-Yi Lin,Ming-Yu Liu,Nic Ma,Kaichun Mo,Delin Qu,Shangkun Sun,Hongchi Xia,Fangyin Wei,Xiaohui Zeng*

Main category: cs.RO

TL;DR: 本文介绍了在2025 BEHAVIOR挑战赛中获得亚军的解决方案，基于π₀.₅模型，通过系统性研究预训练与后训练策略及数据影响，显著提升长时程家庭任务性能，并为具身AI社区提供实用设计建议。


<details>
  <summary>Details</summary>
Motivation: 推动具身智能在真实、人类中心化场景（如日常家居任务）中的实际应用，弥合当前研究与现实复杂长时程移动操作任务之间的差距。

Method: 基于π₀.₅模型，系统开展训练技术与数据影响的消融实验，重点探索预训练与后训练阶段的缩放规律与优化策略。

Result: 在2025 BEHAVIOR Challenge中取得非常接近第1名的第2名成绩，大幅领先其余所有参赛方案。

Conclusion: 预训练与后训练阶段的协同缩放对具身智能任务性能至关重要；本文总结的实践教训与设计建议可为将大模型适配至复杂具身场景提供可操作指导。

Abstract: The 2025 BEHAVIOR Challenge is designed to rigorously track progress toward solving long-horizon tasks by physical agents in simulated environments. BEHAVIOR-1K focuses on everyday household tasks that people most want robots to assist with and these tasks introduce long-horizon mobile manipulation challenges in realistic settings, bridging the gap between current research and real-world, human-centric applications. This report presents our solution to the 2025 BEHAVIOR Challenge in a very close 2nd place and substantially outperforms the rest of the submissions. Building on $π_{0.5}$, we focus on systematically building our solution by studying the effects of training techniques and data. Through careful ablations, we show the scaling power in pre-training and post-training phases for competitive performance. We summarize our practical lessons and design recommendations that we hope will provide actionable insights for the broader embodied AI community when adapting powerful foundation models to complex embodied scenarios.

</details>


### [276] [Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation](https://arxiv.org/abs/2512.10099)
*Steven Caro,Stephen L. Smith*

Main category: cs.RO

TL;DR: 本文提出HeRD，一种分层强化学习-扩散策略，用于非抓取式操作（如推动物体），通过高层RL选择中间目标、低层扩散模型生成轨迹，提升了成功率、路径效率和泛化性。


<details>
  <summary>Details</summary>
Motivation: 非抓取式操作（如推动物体）因接触动力学复杂和长时序规划需求而具有挑战性。

Method: 提出分层架构HeRD：高层使用强化学习（RL）选择中间空间目标，低层使用目标条件扩散模型生成到达目标的可行高效轨迹。

Result: 在2D仿真环境中，HeRD在成功率、路径效率和跨多种环境配置的泛化性上均优于当前最优基线方法。

Conclusion: 分层控制结合生成式低层规划是实现可扩展、目标导向的非抓取式操作的有前景方向。

Abstract: Nonprehensile manipulation, such as pushing objects across cluttered environments, presents a challenging control problem due to complex contact dynamics and long-horizon planning requirements. In this work, we propose HeRD, a hierarchical reinforcement learning-diffusion policy that decomposes pushing tasks into two levels: high-level goal selection and low-level trajectory generation. We employ a high-level reinforcement learning (RL) agent to select intermediate spatial goals, and a low-level goal-conditioned diffusion model to generate feasible, efficient trajectories to reach them.
  This architecture combines the long-term reward maximizing behaviour of RL with the generative capabilities of diffusion models. We evaluate our method in a 2D simulation environment and show that it outperforms the state-of-the-art baseline in success rate, path efficiency, and generalization across multiple environment configurations. Our results suggest that hierarchical control with generative low-level planning is a promising direction for scalable, goal-directed nonprehensile manipulation. Code, documentation, and trained models are available: https://github.com/carosteven/HeRD.

</details>


### [277] [Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks](https://arxiv.org/abs/2512.10116)
*Andrew Razjigaev,Hans Lohr,Alejandro Vargas-Uscategui,Peter King,Tirthankar Bandyopadhyay*

Main category: cs.RO

TL;DR: 本文提出了一种利用任务空间分解、阻尼最小二乘法和Halley法求解六轴机械臂功能冗余逆运动学的新算法，以实现快速、鲁棒且关节运动更小的运动规划，并在冷喷涂涂层任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 六轴机械臂在焊接和增材制造等工业自动化任务中存在因工具轴对称导致的功能冗余（实为五轴任务），利用该冗余对工作空间扩展和刀具路径优化至关重要，但现有快速逆运动学方法未被充分利用。

Method: 提出一种结合任务空间分解、阻尼最小二乘法和Halley法的新型功能冗余逆运动学求解算法，以提升求解速度与鲁棒性并减少关节运动。

Result: 该算法在冷喷涂非平面表面涂层任务中实现了快速、低关节运动的刀具路径优化，显著扩展了复杂路径下的可行操作空间，并在ABB工业机械臂与冷喷涂枪平台上成功验证。

Conclusion: 所提算法为功能冗余机械臂提供了高效、实用的实时逆运动学解决方案，有助于推动在线优化与实际工业应用的结合。

Abstract: Industrial automation with six-axis robotic arms is critical for many manufacturing tasks, including welding and additive manufacturing applications; however, many of these operations are functionally redundant due to the symmetrical tool axis, which effectively makes the operation a five-axis task. Exploiting this redundancy is crucial for achieving the desired workspace and dexterity required for the feasibility and optimisation of toolpath planning. Inverse kinematics algorithms can solve this in a fast, reactive framework, but these techniques are underutilised over the more computationally expensive offline planning methods. We propose a novel algorithm to solve functionally redundant inverse kinematics for robotic manipulation utilising a task space decomposition approach, the damped least-squares method and Halley's method to achieve fast and robust solutions with reduced joint motion. We evaluate our methodology in the case of toolpath optimisation in a cold spray coating application on a non-planar surface. The functionally redundant inverse kinematics algorithm can quickly solve motion plans that minimise joint motion, expanding the feasible operating space of the complex toolpath. We validate our approach on an industrial ABB manipulator and cold-spray gun executing the computed toolpath.

</details>


### [278] [Inertial Magnetic SLAM Systems Using Low-Cost Sensors](https://arxiv.org/abs/2512.10128)
*Chuan Huang,Gustaf Hendeby,Isaac Skog*

Main category: cs.RO

TL;DR: 本文提出了一种基于惯性与磁力计的SLAM系统（IM-SLAM），分为松耦合与紧耦合两种架构，仅使用低成本IMU、磁力计阵列和气压计，在无视觉条件下实现鲁棒的3D定位与建图，误差约每百米几米，适用于矿井/火灾救援等低可见度场景。


<details>
  <summary>Details</summary>
Motivation: 现有磁SLAM系统依赖低漂移里程计（如视觉或轮式编码器），难以在未建图区域控制定位误差；且视觉系统在低能见度下失效，亟需纯非视觉、低成本的鲁棒SLAM方案。

Method: 设计松耦合与紧耦合两种IM-SLAM架构：均采用IMU、磁力计阵列和气压计；构建多尺度磁场模型（局部+全局）；松耦合将局部与全局模型分置于两个独立状态空间中，紧耦合则统一整合进单一状态空间；均基于状态估计框架实现定位与磁场建图联合优化。

Result: 实验表明紧耦合IM-SLAM在多数场景下定位误差低于松耦合，典型误差为每100米行程数米；验证了仅用低成本传感器实现全3D IM-SLAM的可行性。

Conclusion: 紧耦合IM-SLAM是一种可行、鲁棒且适用于低可见度应急场景（如矿难、火灾救援）的非视觉定位与建图方案，摆脱了对视觉或高精度里程计的依赖。

Abstract: Spatially inhomogeneous magnetic fields offer a valuable, non-visual information source for positioning. Among systems leveraging this, magnetic field-based simultaneous localization and mapping (SLAM) systems are particularly attractive because they can provide positioning information and build a magnetic field map on the fly. Moreover, they have bounded error within mapped regions. However, state-of-the-art methods typically require low-drift odometry data provided by visual odometry or a wheel encoder, etc. This is because these systems need to minimize/reduce positioning errors while exploring, which happens when they are in unmapped regions. To address these limitations, this work proposes a loosely coupled and a tightly coupled inertial magnetic SLAM (IM-SLAM) system. The proposed systems use commonly available low-cost sensors: an inertial measurement unit (IMU), a magnetometer array, and a barometer. The use of non-visual data provides a significant advantage over visual-based systems, making it robust to low-visibility conditions. Both systems employ state-space representations, and magnetic field models on different scales. The difference lies in how they use a local and global magnetic field model. The loosely coupled system uses these models separately in two state-space models, while the tightly coupled system integrates them into one state-space model. Experiment results show that the tightly coupled IM-SLAM system achieves lower positioning errors than the loosely coupled system in most scenarios, with typical errors on the order of meters per 100 meters traveled. These results demonstrate the feasiblity of developing a full 3D IM-SLAM systems using low-cost sensors and the potential of applying these systems in emergency response scenarios such as mine/fire rescue.

</details>


### [279] [Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine](https://arxiv.org/abs/2512.10235)
*Hui Li,Akhlak Uz Zaman,Fujian Yan,Hongsheng He*

Main category: cs.RO

TL;DR: 本文提出了一种结合上下文奖励机（Contextual Reward Machine）的强化学习框架，用于任务导向的抓取，通过分解任务、引入阶段上下文和过渡奖励，显著提升了学习效率与成功率，并在仿真和真实机器人上均取得优异效果。


<details>
  <summary>Details</summary>
Motivation: 提升任务导向抓取的学习效率与成功率，解决传统方法中状态-动作空间大、探索无序、收敛慢等问题。

Method: 构建基于上下文奖励机的强化学习框架，将抓取任务分解为多个子任务，每个子任务具有阶段特定的上下文（含奖励函数、动作空间和状态抽象函数），并引入过渡奖励以引导阶段间合理转移；结合PPO算法进行训练。

Result: 在1000个仿真抓取任务中成功率达95%，优于现有最先进方法；迁移至真实机器人后，在60个任务中达到83.3%成功率；展现出更高精度、数据效率与学习效率。

Conclusion: 上下文奖励机有效降低了任务复杂度与搜索空间，增强了策略可解释性与泛化能力，为仿真到真实的抓取任务迁移提供了高效可行的新范式。

Abstract: This paper presents a reinforcement learning framework that incorporates a Contextual Reward Machine for task-oriented grasping. The Contextual Reward Machine reduces task complexity by decomposing grasping tasks into manageable sub-tasks. Each sub-task is associated with a stage-specific context, including a reward function, an action space, and a state abstraction function. This contextual information enables efficient intra-stage guidance and improves learning efficiency by reducing the state-action space and guiding exploration within clearly defined boundaries. In addition, transition rewards are introduced to encourage or penalize transitions between stages which guides the model toward desirable stage sequences and further accelerates convergence. When integrated with the Proximal Policy Optimization algorithm, the proposed method achieved a 95% success rate across 1,000 simulated grasping tasks encompassing diverse objects, affordances, and grasp topologies. It outperformed the state-of-the-art methods in both learning speed and success rate. The approach was transferred to a real robot, where it achieved a success rate of 83.3% in 60 grasping tasks over six affordances. These experimental results demonstrate superior accuracy, data efficiency, and learning efficiency. They underscore the model's potential to advance task-oriented grasping in both simulated and real-world settings.

</details>


### [280] [Lies We Can Trust: Quantifying Action Uncertainty with Inaccurate Stochastic Dynamics through Conformalized Nonholonomic Lie Groups](https://arxiv.org/abs/2512.10294)
*Luís Marques,Maani Ghaffari,Dmitry Berenson*

Main category: cs.RO

TL;DR: 本文提出了一种名为CLAPS的对称性感知的共形预测算法，用于在机器人系统中构建具有概率保证的动作结果配置集，特别适用于SE(2)等李群配置空间。


<details>
  <summary>Details</summary>
Motivation: 传统不确定性量化方法依赖强假设或未校准的估计，难以满足安全控制需求；而现有共形预测方法忽略机器人配置空间的几何结构（如SE(2)），导致预测区域效率低、表达能力差。

Method: 基于李群理论设计对称性感知的非一致性分数，将共形预测框架从欧氏空间推广至SE(2)等李群配置空间，在不依赖动力学模型精确性与误差分布假设下提供非渐近、分布无关的概率保证。

Result: 在仿真JetBot和真实MBot平台上验证了CLAPS方法能生成体积更小、更能反映真实不确定性的预测集，优于现有共形预测方法。

Conclusion: 通过融合李群对称性与共形预测，CLAPS实现了对非欧配置空间中动作结果的严格、高效且模型无关的概率保证，提升了机器人安全控制中的不确定性量化能力。

Abstract: We propose Conformal Lie-group Action Prediction Sets (CLAPS), a symmetry-aware conformal prediction-based algorithm that constructs, for a given action, a set guaranteed to contain the resulting system configuration at a user-defined probability. Our assurance holds under both aleatoric and epistemic uncertainty, non-asymptotically, and does not require strong assumptions about the true system dynamics, the uncertainty sources, or the quality of the approximate dynamics model. Typically, uncertainty quantification is tackled by making strong assumptions about the error distribution or magnitude, or by relying on uncalibrated uncertainty estimates - i.e., with no link to frequentist probabilities - which are insufficient for safe control. Recently, conformal prediction has emerged as a statistical framework capable of providing distribution-free probabilistic guarantees on test-time prediction accuracy. While current conformal methods treat robots as Euclidean points, many systems have non-Euclidean configurations, e.g., some mobile robots have SE(2). In this work, we rigorously analyze configuration errors using Lie groups, extending previous Euclidean Space theoretical guarantees to SE(2). Our experiments on a simulated JetBot, and on a real MBot, suggest that by considering the configuration space's structure, our symmetry-informed nonconformity score leads to more volume-efficient prediction regions which represent the underlying uncertainty better than existing approaches.

</details>


### [281] [Design of a six wheel suspension and a three-axis linear actuation mechanism for a laser weeding robot](https://arxiv.org/abs/2512.10319)
*Muhammad Usama,Muhammad Ibrahim Khan,Ahmad Hasan,Muhammad Shaaf Nadeem,Khawaja Fahad Iqbal,Jawad Aslam,Mian Ashfaq Ali,Asad Nisar Awan*

Main category: cs.RO

TL;DR: 本文提出了一种基于低能量激光的自主除草机器人，采用六轮底盘与双四连杆悬架提升稳定性，结合3D线性执行机构精准引导激光，实现在农田复杂地形中高效、准确地识别与清除杂草。


<details>
  <summary>Details</summary>
Motivation: 传统机械除草效率低，化学除草剂破坏土壤生态，亟需一种可持续的精准农业替代方案。

Method: 设计六轮自主机器人，配备双四连杆悬架和三维线性激光导向机构；集成视觉识别与激光控制，在田间实地测试其导航、检测与除草性能。

Result: 机器人可越障15 cm；以42.5 cm/s速度运行时，杂草检测率达86.2%，作业耗时87秒/米；激光定位平均误差仅1.54 mm，命中率97%。

Conclusion: 该激光除草机器人在速度、精度与效率上表现优异，具备显著提升精准农业实践的潜力。

Abstract: Mobile robots are increasingly utilized in agriculture to automate labor-intensive tasks such as weeding, sowing, harvesting and soil analysis. Recently, agricultural robots have been developed to detect and remove weeds using mechanical tools or precise herbicide sprays. Mechanical weeding is inefficient over large fields, and herbicides harm the soil ecosystem. Laser weeding with mobile robots has emerged as a sustainable alternative in precision farming. In this paper, we present an autonomous weeding robot that uses controlled exposure to a low energy laser beam for weed removal. The proposed robot is six-wheeled with a novel double four-bar suspension for higher stability. The laser is guided towards the detected weeds by a three-dimensional linear actuation mechanism. Field tests have demonstrated the robot's capability to navigate agricultural terrains effectively by overcoming obstacles up to 15 cm in height. At an optimal speed of 42.5 cm/s, the robot achieves a weed detection rate of 86.2\% and operating time of 87 seconds per meter. The laser actuation mechanism maintains a minimal mean positional error of 1.54 mm, combined with a high hit rate of 97\%, ensuring effective and accurate weed removal. This combination of speed, accuracy, and efficiency highlights the robot's potential for significantly enhancing precision farming practices.

</details>


### [282] [Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing](https://arxiv.org/abs/2512.10349)
*Quan Yuan,Zhenting Du,Daqian Cao,Weibang Bai*

Main category: cs.RO

TL;DR: 本文提出了一种单驱动、同步绳索路由的欠驱动腱驱动机械手指（UTRF），通过固定角速度比机械耦合所有关节，在保证刚度与顺应性的同时显著减小体积与重量；建模考虑了绳索弹性，实验显示预测误差仅1.0 mm，集成五指手验证了其在多场景操作中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决腱驱动欠驱动机械手指在紧凑结构下难以兼顾高负载能力与自适应顺应性的挑战。

Method: 设计具有同步腱路由的欠驱动腱驱动手指（UTRF），所有关节以固定角速度比机械耦合，仅需单个执行器驱动；建立含腱弹性的运动学与静力学模型以预测结构刚度；制造单指原型并进行静态加载测试；最后集成至五指机械手（UTRF-RoboHand）验证操作性能。

Result: 单指原型在3 kg尖端载荷下测得刚度为1.2×10³ N/m，平均挠度预测误差为1.0 mm（占总长0.322%）；五指集成手在多种物体操作任务中表现出可预测刚度与可靠抓取性能。

Conclusion: 同步腱路由方案可在极简执行器配置下实现高刚度、良好顺应性与可靠操作性能，为轻量紧凑型多指机器人手提供了有效设计范式。

Abstract: Tendon-driven under-actuated robotic fingers provide advantages for dexterous manipulation through reduced actuator requirements and simplified mechanical design. However, achieving both high load capacity and adaptive compliance in a compact form remains challenging. This paper presents an under-actuated tendon-driven robotic finger (UTRF) featuring a synchronous tendon routing that mechanically couples all joints with fixed angular velocity ratios, enabling the entire finger to be actuated by a single actuator. This approach significantly reduces the number of actuators required in multi-finger hands, resulting in a lighter and more compact structure without sacrificing stiffness or compliance. The kinematic and static models of the finger are derived, incorporating tendon elasticity to predict structural stiffness. A single-finger prototype was fabricated and tested under static loading, showing an average deflection prediction error of 1.0 mm (0.322% of total finger length) and a measured stiffness of 1.2x10^3 N/m under a 3 kg tip load. Integration into a five-finger robotic hand (UTRF-RoboHand) demonstrates effective object manipulation across diverse scenarios, confirming that the proposed routing achieves predictable stiffness and reliable grasping performance with a minimal actuator count.

</details>


### [283] [CLASH: Collaborative Large-Small Hierarchical Framework for Continuous Vision-and-Language Navigation](https://arxiv.org/abs/2512.10360)
*Liuyi Wang,Zongtao He,Jinlong Li,Xiaoyan Qi,Mengxian Hu,Chenpeng Yao,Chengju Liu,Qijun Chen*

Main category: cs.RO

TL;DR: 本文提出CLASH框架，通过协同大模型与小模型（RSMP与RLMR）提升视觉-语言导航（VLN）性能，并引入不确定性感知协作机制（UCM）及可学习的避障策略，在仿真与真实场景中均达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言大模型在VLN任务中推理能力强但性能不如专用小模型，需融合二者优势以提升泛化性、可解释性与鲁棒性。

Method: 提出CLASH框架：1）RSMP小模型采用因果学习双分支架构；2）RLMR大模型结合全景视觉提示与思维链推理；3）UCM机制自适应融合两模型决策；4）仿真中用可学习点目标策略替代规则控制器，真实场景中结合LiDAR聚类与在线SLAM局部控制器。

Result: 在VLN-CE排行榜上取得SOTA（第1名），显著提升测试未见集的SR与SPL；真实世界实验验证其强鲁棒性。

Conclusion: CLASH成功实现大模型与小模型在VLN任务中的高效协同，兼顾性能、可解释性与部署实用性，为具身智能导航提供了新范式。

Abstract: Vision-and-Language Navigation (VLN) requires robots to follow natural language instructions and navigate complex environments without prior maps. While recent vision-language large models demonstrate strong reasoning abilities, they often underperform task-specific panoramic small models in VLN tasks. To address this, we propose CLASH (Collaborative Large-Small Hierarchy), a VLN-CE framework that integrates a reactive small-model planner (RSMP) with a reflective large-model reasoner (RLMR). RSMP adopts a causal-learning-based dual-branch architecture to enhance generalization, while RLMR leverages panoramic visual prompting with chain-of-thought reasoning to support interpretable spatial understanding and navigation. We further introduce an uncertainty-aware collaboration mechanism (UCM) that adaptively fuses decisions from both models. For obstacle avoidance, in simulation, we replace the rule-based controller with a fully learnable point-goal policy, and in real-world deployment, we design a LiDAR-based clustering module for generating navigable waypoints and pair it with an online SLAM-based local controller. CLASH achieves state-of-the-art (SoTA) results (ranking 1-st) on the VLN-CE leaderboard, significantly improving SR and SPL on the test-unseen set over the previous SoTA methods. Real-world experiments demonstrate CLASH's strong robustness, validating its effectiveness in both simulation and deployment scenarios.

</details>


### [284] [RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI](https://arxiv.org/abs/2512.10394)
*Weifan Guan,Huasen Xi,Chenxiao Zhang,Aosheng Li,Qinghao Hu,Jian Cheng*

Main category: cs.RO

TL;DR: RoboNeuron is a universal deployment framework that integrates LLMs and VLA models with ROS, using MCP as a semantic bridge to enable dynamic tool orchestration and modular, decoupled robotic system design.


<details>
  <summary>Details</summary>
Motivation: Current embodied AI systems suffer from poor cross-scenario adaptability, rigid inter-module coupling, and fragmented inference acceleration.

Method: Proposes RoboNeuron—a framework integrating LLMs/VLA models with ROS via Model Context Protocol (MCP) as a semantic bridge; introduces automated translation of ROS messages into callable MCP functions; enforces strict decoupling of sensing, reasoning, and control using ROS interfaces.

Result: Significantly improves cross-scenario adaptability and component flexibility; enables systematic horizontal performance benchmarking; provides streamlined development and a robust foundation for scalable real-world embodied applications.

Conclusion: RoboNeuron establishes a universal, modular, and scalable framework for embodied intelligence deployment by unifying cognitive models and robotic execution infrastructure.

Abstract: Current embodied AI systems face severe engineering impediments, primarily characterized by poor cross-scenario adaptability, rigid inter-module coupling, and fragmented inference acceleration. To overcome these limitations, we propose RoboNeuron, a universal deployment framework for embodied intelligence. RoboNeuron is the first framework to deeply integrate the cognitive capabilities of Large Language Models (LLMs) and Vision-Language-Action (VLA) models with the real-time execution backbone of the Robot Operating System (ROS). We utilize the Model Context Protocol (MCP) as a semantic bridge, enabling the LLM to dynamically orchestrate underlying robotic tools. The framework establishes a highly modular architecture that strictly decouples sensing, reasoning, and control by leveraging ROS's unified communication interfaces. Crucially, we introduce an automated tool to translate ROS messages into callable MCP functions, significantly streamlining development. RoboNeuron significantly enhances cross-scenario adaptability and component flexibility, while establishing a systematic platform for horizontal performance benchmarking, laying a robust foundation for scalable real-world embodied applications.

</details>


### [285] [Symphony: A Heuristic Normalized Calibrated Advantage Actor and Critic Algorithm in application for Humanoid Robots](https://arxiv.org/abs/2512.10477)
*Timur Ishuov,Michele Folgheraiter,Madi Nurmanov,Goncalo Gordo,Richárd Farkas,József Dombi*

Main category: cs.RO

TL;DR: 本文提出了一种名为Symphony的新型强化学习算法，结合Swaddling正则化、受限参数噪声、弱动作强度与Fading Replay Buffer等技术，旨在实现人形机器人从零开始的高效、安全、样本邻近的训练。


<details>
  <summary>Details</summary>
Motivation: 针对机器人从零学习时无法承受大量采样步数的问题，以及传统随机算法对硬件（如电机、齿轮箱）不安全的缺陷，本文旨在设计一种兼顾样本效率、动作安全性与训练稳定性的新方法。

Method: 提出Symphony算法，融合：1）Swaddling正则化（抑制动作幅值以提升稳定性）；2）受限参数噪声代替高斯噪声以保护硬件；3）弱动作强度机制，在低熵下安全提升探索；4）Fading Replay Buffer（基于tanh函数动态加权新旧经验），并引入Temporal Advantage实现Actor-Critic单步联合更新。

Result: 实验表明该方法显著提升了训练过程对机器人本体及环境的安全性，同时在样本效率和策略稳定性方面优于传统随机策略梯度方法。

Conclusion: 通过约束动作强度、调控噪声形式与重放机制，可有效平衡探索-利用、效率-安全之间的矛盾，为人形机器人从零训练提供了一条可行且鲁棒的新路径。

Abstract: In our work we not explicitly hint that it is a misconception to think that humans learn fast. Learning process takes time. Babies start learning to move in the restricted liquid area called placenta. Children often are limited by underdeveloped body. Even adults are not allowed to participate in complex competitions right away. However, with robots, when learning from scratch, we often don't have the privilege of waiting for dozen millions of steps. "Swaddling" regularization is responsible for restraining an agent in rapid but unstable development penalizing action strength in a specific way not affecting actions directly. The Symphony, Transitional-policy Deterministic Actor and Critic algorithm, is a concise combination of different ideas for possibility of training humanoid robots from scratch with Sample Efficiency, Sample Proximity and Safety of Actions in mind. It is no secret that continuous increase in Gaussian noise without appropriate smoothing is harmful for motors and gearboxes. Compared to Stochastic algorithms, we set a limited parametric noise and promote a reduced strength of actions, safely increasing entropy, since the actions are kind of immersed in weaker noise. When actions require more extreme values, actions rise above the weak noise. Training becomes empirically much safer for both the environment around and the robot's mechanisms. We use Fading Replay Buffer: using a fixed formula containing the hyperbolic tangent, we adjust the batch sampling probability: the memory contains a recent memory and a long-term memory trail. Fading Replay Buffer allows us to use Temporal Advantage when we improve the current Critic Network prediction compared to the exponential moving average. Temporal Advantage allows us to update Actor and Critic in one pass, as well as combine Actor and Critic in one Object and implement their Losses in one line.

</details>


### [286] [Seamless Outdoor-Indoor Pedestrian Positioning System with GNSS/UWB/IMU Fusion: A Comparison of EKF, FGO, and PF](https://arxiv.org/abs/2512.10480)
*Jiaqiang Zhang,Xianjia Yu,Sier Ha,Paola Torrico Moron,Sahar Salimpour,Farhad Kerama,Haizhou Zhang,Tomi Westerlund*

Main category: cs.RO

TL;DR: 本文提出了一种融合GNSS、UWB和IMU的统一框架，用于室内外无缝行人定位，并对比了三种概率后端（ESKF、滑动窗口因子图优化、粒子滤波），其中ESKF表现最优；引入基于OpenStreetMap的轻量地图可行性约束以提升过渡鲁棒性与抗城市GNSS干扰能力。


<details>
  <summary>Details</summary>
Motivation: GNSS、UWB和惯性PDR各自在信号遮挡、多径和漂移下表现脆弱，难以实现高精度连续的室内外行人定位。

Method: 构建基于胸挂IMU-PDR为运动主干、GNSS（室外）和UWB（室内）提供绝对观测的统一融合框架；引入源自OpenStreetMap建筑轮廓的轻量地图可行性约束；在ROS 2中实现实时运行，可视化使用Foxglove；对比ESKF、滑动窗口因子图优化和粒子滤波三种后端。

Result: ESKF在所有测试场景（纯室内、纯室外、室内外无缝切换）中展现出最一致的整体性能；地图约束有效提升了过渡鲁棒性并缓解了城市环境中GNSS退化问题。

Conclusion: 误差状态扩展卡尔曼滤波（ESKF）是该多源融合定位框架中最稳健、实用的后端选择；结合轻量地图先验可显著提升复杂环境下的定位连续性与可靠性。

Abstract: Accurate and continuous pedestrian positioning across outdoor-indoor environments remains challenging because GNSS, UWB, and inertial PDR are complementary yet individually fragile under signal blockage, multipath, and drift. This paper presents a unified GNSS/UWB/IMU fusion framework for seamless pedestrian localization and provides a controlled comparison of three probabilistic back-ends: an error-state extended Kalman filter, sliding-window factor graph optimization, and a particle filter. The system uses chest-mounted IMU-based PDR as the motion backbone and integrates absolute updates from GNSS outdoors and UWB indoors. To enhance transition robustness and mitigate urban GNSS degradation, we introduce a lightweight map-based feasibility constraint derived from OpenStreetMap building footprints, treating most building interiors as non-navigable while allowing motion inside a designated UWB-instrumented building. The framework is implemented in ROS 2 and runs in real time on a wearable platform, with visualization in Foxglove. We evaluate three scenarios: indoor (UWB+PDR), outdoor (GNSS+PDR), and seamless outdoor-indoor (GNSS+UWB+PDR). Results show that the ESKF provides the most consistent overall performance in our implementation.

</details>


### [287] [Contact SLAM: An Active Tactile Exploration Policy Based on Physical Reasoning Utilized in Robotic Fine Blind Manipulation Tasks](https://arxiv.org/abs/2512.10481)
*Gaozhao Wang,Xing Liu,Zhenduo Ye,Zhengxiong Liu,Panfeng Huang*

Main category: cs.RO

TL;DR: 本文提出了一种仅依赖触觉感知和场景先验知识的物理驱动接触认知方法Contact SLAM，用于解决视觉受限下的盲操作问题，并设计了主动探索策略以降低场景不确定性，在插座装配和推块等接触密集任务中验证了其有效性与精度。


<details>
  <summary>Details</summary>
Motivation: 接触密集型操作对机器人而言难度大，且在视觉被遮挡时（即“盲操作”）无法获取实时场景状态，亟需不依赖视觉的环境感知与操作方法。

Method: 提出名为Contact SLAM的物理驱动接触认知方法，仅利用触觉传感和场景先验知识估计环境状态并完成操作；同时设计主动探索策略以逐步降低操作场景中的不确定性。

Result: 在插座装配和方块推动等多个接触密集任务中，实验验证了该方法的有效性和高精度，尤其在困难且精细的插座装配任务中表现突出。

Conclusion: Contact SLAM为视觉受限下的机器人接触操作提供了可行、鲁棒且高效的解决方案，凸显了纯触觉驱动与主动探索结合的巨大潜力。

Abstract: Contact-rich manipulation is difficult for robots to execute and requires accurate perception of the environment. In some scenarios, vision is occluded. The robot can then no longer obtain real-time scene state information through visual feedback. This is called ``blind manipulation". In this manuscript, a novel physically-driven contact cognition method, called ``Contact SLAM", is proposed. It estimates the state of the environment and achieves manipulation using only tactile sensing and prior knowledge of the scene. To maximize exploration efficiency, this manuscript also designs an active exploration policy. The policy gradually reduces uncertainties in the manipulation scene. The experimental results demonstrated the effectiveness and accuracy of the proposed method in several contact-rich tasks, including the difficult and delicate socket assembly task and block-pushing task.

</details>


### [288] [Neural Ranging Inertial Odometry](https://arxiv.org/abs/2512.10531)
*Si Wang,Bingqi Shen,Fei Wang,Yanjun Cao,Rong Xiong,Yue Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于图注意力UWB网络与循环神经惯性网络的神经融合框架（IR-ULSG），用于无GPS环境下的高精度定位，尤其适用于多径干扰严重、锚点稀疏或非凸布置等挑战性场景。


<details>
  <summary>Details</summary>
Motivation: UWB在GPS拒止环境下具有轻量、无漂移优势，但其实际定位精度受限于传感器布置敏感性和由多径/多信号干扰引起的非高斯误差，尤其在长隧道等典型场景中表现不佳。

Method: 提出神经融合框架IR-ULSG：包含图注意力UWB网络（学习场景相关测距模式，支持任意锚点/标签数量，免标定）和循环神经惯性网络；融合最小二乘优化与名义坐标系提升性能与可扩展性。

Result: 在公共及自建数据集（室内、室外、隧道）上验证有效；显著优于现有方法，尤其在锚点位于目标凸包外、甚至仅单锚点可用等极端条件下仍保持鲁棒高精度。

Conclusion: IR-ULSG框架实现了对复杂非高斯干扰和灵活部署场景的强适应性，为UWB/IMU紧耦合定位提供了新范式，兼具精度、鲁棒性与工程实用性。

Abstract: Ultra-wideband (UWB) has shown promising potential in GPS-denied localization thanks to its lightweight and drift-free characteristics, while the accuracy is limited in real scenarios due to its sensitivity to sensor arrangement and non-Gaussian pattern induced by multi-path or multi-signal interference, which commonly occurs in many typical applications like long tunnels. We introduce a novel neural fusion framework for ranging inertial odometry which involves a graph attention UWB network and a recurrent neural inertial network. Our graph net learns scene-relevant ranging patterns and adapts to any number of anchors or tags, realizing accurate positioning without calibration. Additionally, the integration of least squares and the incorporation of nominal frame enhance overall performance and scalability. The effectiveness and robustness of our methods are validated through extensive experiments on both public and self-collected datasets, spanning indoor, outdoor, and tunnel environments. The results demonstrate the superiority of our proposed IR-ULSG in handling challenging conditions, including scenarios outside the convex envelope and cases where only a single anchor is available.

</details>


### [289] [Mr. Virgil: Learning Multi-robot Visual-range Relative Localization](https://arxiv.org/abs/2512.10540)
*Si Wang,Zhehan Li,Jiadong Lu,Rong Xiong,Yanjun Cao,Yue Wang*

Main category: cs.RO

TL;DR: 本文提出Mr. Virgil，一种端到端学习的多机器人视觉-超宽带（UWB）融合相对定位框架，通过图神经网络实现鲁棒数据关联，并结合可微姿态图优化（PGO）提升定位精度，支持去中心化部署，在多种仿真与真实场景下验证了其稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有UWB-视觉融合定位方法在机器人与视觉检测匹配上存在挑战，高度依赖身份编码硬件或精细调参算法，错误匹配可能导致系统不可逆损害。

Method: 提出端到端学习框架Mr. Virgil，包含基于图神经网络（GNN）的数据关联前端（处理UWB测距与视觉检测匹配）和可微分姿态图优化（PGO）后端；前端提供鲁棒匹配、初始位姿预测及不确定性估计，输入至PGO提升最终位姿估计精度；并实现去中心化系统设计。

Result: 在不同机器人数量、仿真与真实环境、遮挡与非遮挡条件下实验表明，该方法相比传统方法具有更高稳定性与定位精度。

Conclusion: Mr. Virgil有效缓解了UWB-视觉融合中匹配不可靠问题，通过端到端学习与可微优化联合建模，实现了鲁棒、精确、可部署的多机器人相对定位。

Abstract: Ultra-wideband (UWB)-vision fusion localization has achieved extensive applications in the domain of multi-agent relative localization. The challenging matching problem between robots and visual detection renders existing methods highly dependent on identity-encoded hardware or delicate tuning algorithms. Overconfident yet erroneous matches may bring about irreversible damage to the localization system. To address this issue, we introduce Mr. Virgil, an end-to-end learning multi-robot visual-range relative localization framework, consisting of a graph neural network for data association between UWB rangings and visual detections, and a differentiable pose graph optimization (PGO) back-end. The graph-based front-end supplies robust matching results, accurate initial position predictions, and credible uncertainty estimates, which are subsequently integrated into the PGO back-end to elevate the accuracy of the final pose estimation. Additionally, a decentralized system is implemented for real-world applications. Experiments spanning varying robot numbers, simulation and real-world, occlusion and non-occlusion conditions showcase the stability and exactitude under various scenes compared to conventional methods. Our code is available at: https://github.com/HiOnes/Mr-Virgil.

</details>


### [290] [Motion Planning for Safe Landing of a Human-Piloted Parafoil](https://arxiv.org/abs/2512.10595)
*Maximillian Fainkich,Kiril Solovey,Anna Clarke*

Main category: cs.RO

TL;DR: 本文研究了人控降落伞飞行的安全轨迹规划问题，提出了一种基于改进SST采样算法的轨迹生成方法，以减小滚转角（控制努力）为安全代理指标；与人类飞行员实际飞行数据对比显示，算法解在成本上比人类方案优20%-80%，且下降更平滑、着陆高度更精准；结果表明该方法可作为训练指南集成至未来模拟器中，提升跳伞训练安全性与效率。


<details>
  <summary>Details</summary>
Motivation: 跳伞事故多发生在伞翼操控与着陆阶段，主因是人为判断失误；现有训练周期长，缺乏实用易用的训练模拟器；适用于辅助人类训练的降落伞轨迹规划研究仍不足。

Method: 改进Li等人提出的Stable Sparse RRT（SST）采样式运动规划算法，适配降落伞动力学约束，并以最小化滚转角作为优化目标（代表控制努力与安全性）。

Result: 算法生成轨迹相比人类飞行员实际飞行，在成本（如控制努力）上提升20%-80%；人类倾向先水平接近再螺旋下降，而算法实现更平滑、渐进式下降，精确抵达着陆所需高度。

Conclusion: 计算机生成的安全轨迹可作为超越经验法则的新型训练指南，具备集成到未来跳伞模拟器中的潜力，从而提升训练安全性与经济性。

Abstract: Most skydiving accidents occur during the parafoil-piloting and landing stages and result from human lapses in judgment while piloting the parafoil. Training of novice pilots is protracted due to the lack of functional and easily accessible training simulators. Moreover, work on parafoil trajectory planning suitable for aiding human training remains limited. To bridge this gap, we study the problem of computing safe trajectories for human-piloted parafoil flight and examine how such trajectories fare against human-generated solutions. For the algorithmic part, we adapt the sampling-based motion planner Stable Sparse RRT (SST) by Li et al., to cope with the problem constraints while minimizing the bank angle (control effort) as a proxy for safety. We then compare the computer-generated solutions with data from human-generated parafoil flight, where the algorithm offers a relative cost improvement of 20\%-80\% over the performance of the human pilot. We observe that human pilots tend to, first, close the horizontal distance to the landing area, and then address the vertical gap by spiraling down to the suitable altitude for starting a landing maneuver. The algorithm considered here makes smoother and more gradual descents, arriving at the landing area at the precise altitude necessary for the final approach while maintaining safety constraints. Overall, the study demonstrates the potential of computer-generated guidelines, rather than traditional rules of thumb, which can be integrated into future simulators to train pilots for safer and more cost-effective flights.

</details>


### [291] [LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator](https://arxiv.org/abs/2512.10605)
*Lihuang Chen,Xiangyu Luo,Jun Meng*

Main category: cs.RO

TL;DR: LEO-RobotAgent是一个通用语言驱动的机器人智能体框架，支持大模型跨场景、跨平台自主完成复杂任务，具备强泛化性、鲁棒性与高效性，并支持人机协同交互。


<details>
  <summary>Details</summary>
Motivation: 现有机器人任务规划方法多局限于单任务、单机器人类型，结构复杂、泛化能力差，难以支持灵活、通用的人机协作。

Method: 提出轻量化、模块化的LEO-RobotAgent框架，集成可注册工具集与人机协同机制，使大模型能独立思考、规划与执行；支持多种主流机器人平台（如无人机、机械臂、轮式机器人）。

Result: 实验验证该框架可在不同机器人平台上高效执行多种复杂度任务，具备良好适应性与实用性。

Conclusion: LEO-RobotAgent为语言驱动的通用机器人智能体提供了可扩展、易部署、强交互的新范式，显著降低了人机交互门槛。

Abstract: We propose LEO-RobotAgent, a general-purpose language-driven intelligent agent framework for robots. Under this framework, LLMs can operate different types of robots to complete unpredictable complex tasks across various scenarios. This framework features strong generalization, robustness, and efficiency. The application-level system built around it can fully enhance bidirectional human-robot intent understanding and lower the threshold for human-robot interaction. Regarding robot task planning, the vast majority of existing studies focus on the application of large models in single-task scenarios and for single robot types. These algorithms often have complex structures and lack generalizability. Thus, the proposed LEO-RobotAgent framework is designed with a streamlined structure as much as possible, enabling large models to independently think, plan, and act within this clear framework. We provide a modular and easily registrable toolset, allowing large models to flexibly call various tools to meet different requirements. Meanwhile, the framework incorporates a human-robot interaction mechanism, enabling the algorithm to collaborate with humans like a partner. Experiments have verified that this framework can be easily adapted to mainstream robot platforms including unmanned aerial vehicles (UAVs), robotic arms, and wheeled robot, and efficiently execute a variety of carefully designed tasks with different complexity levels. Our code is available at https://github.com/LegendLeoChen/LEO-RobotAgent.

</details>


### [292] [Evaluating Gemini Robotics Policies in a Veo World Simulator](https://arxiv.org/abs/2512.10675)
*Gemini Robotics Team,Coline Devin,Yilun Du,Debidatta Dwibedi,Ruiqi Gao,Abhishek Jindal,Thomas Kipf,Sean Kirmani,Fangchen Liu,Anirudha Majumdar,Andrew Marmon,Carolina Parada,Yulia Rubanova,Dhruv Shah,Vikas Sindhwani,Jie Tan,Fei Xia,Ted Xiao,Sherry Yang,Wenhao Yu,Allan Zhou*

Main category: cs.RO

TL;DR: 本文提出了一种基于前沿视频基础模型（Veo）的生成式评估系统，用于全面评估机器人策略在名义性能、分布外（OOD）泛化及物理/语义安全性等方面的性能，通过图像编辑与多视角补全实现高保真场景合成，并在1600+真实世界实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视频模型在机器人领域仅限于分布内评估，缺乏对分布外泛化和安全性的系统性评估能力；亟需一种能支持全谱系策略评估（含OOD和安全性探测）的生成式世界模型。

Method: 构建基于Veo视频基础模型的生成式评估系统，支持机器人动作条件建模与多视角一致性；集成生成式图像编辑与多视角补全技术，以合成涵盖新交互物体、新背景、新干扰物等多维度变化的真实感场景。

Result: 该系统能高保真模拟编辑后的场景，准确预测不同策略在名义与OOD条件下的相对性能，量化各泛化维度对策略的影响，并可进行策略红队测试以暴露违反物理或语义安全的行为；经1600+次真实世界实验验证，覆盖8个Gemini Robotics策略检查点与5个双臂操作任务。

Conclusion: 前沿视频模型经针对性优化后，可作为强大、通用且可靠的生成式世界模型，支撑机器人策略的全谱系评估，尤其在OOD泛化与安全性分析方面展现出显著潜力。

Abstract: Generative world models hold significant potential for simulating interactions with visuomotor policies in varied environments. Frontier video models can enable generation of realistic observations and environment interactions in a scalable and general manner. However, the use of video models in robotics has been limited primarily to in-distribution evaluations, i.e., scenarios that are similar to ones used to train the policy or fine-tune the base video model. In this report, we demonstrate that video models can be used for the entire spectrum of policy evaluation use cases in robotics: from assessing nominal performance to out-of-distribution (OOD) generalization, and probing physical and semantic safety. We introduce a generative evaluation system built upon a frontier video foundation model (Veo). The system is optimized to support robot action conditioning and multi-view consistency, while integrating generative image-editing and multi-view completion to synthesize realistic variations of real-world scenes along multiple axes of generalization. We demonstrate that the system preserves the base capabilities of the video model to enable accurate simulation of scenes that have been edited to include novel interaction objects, novel visual backgrounds, and novel distractor objects. This fidelity enables accurately predicting the relative performance of different policies in both nominal and OOD conditions, determining the relative impact of different axes of generalization on policy performance, and performing red teaming of policies to expose behaviors that violate physical or semantic safety constraints. We validate these capabilities through 1600+ real-world evaluations of eight Gemini Robotics policy checkpoints and five tasks for a bimanual manipulator.

</details>


### [293] [How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning](https://arxiv.org/abs/2512.10698)
*Jianbo Wang,Galina Sidorenko,Johan Thunberg*

Main category: cs.RO

TL;DR: 本文提出了一种结合深度强化学习（DRL）与解析式最优恒定减速度选择方法的混合控制策略，用于多车跟驰场景下的紧急制动，以实现三车系统整体的碰撞避免与伤害最小化，兼顾安全性与性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于最坏情况的保守控制策略虽保障安全但牺牲灵活性和整体性能；需在多车紧急制动中兼顾个体与集体安全，尤其是不可避免碰撞时的伦理化伤害分配。

Method: 提出一种混合方法：将深度强化学习（DRL）与车辆间通信（V2V）结合，并嵌入已有的基于解析表达式的最优恒定减速度选择机制，以提升决策可靠性与全局优化能力。

Result: 相比纯DRL方法，该混合方法显著提高了可靠性，同时在整体伤害降低和碰撞避免方面表现更优。

Conclusion: DRL与解析方法的协同可有效平衡自动驾驶跟驰场景中的安全性、伦理性和系统性能，为多车协同紧急制动提供了可行且鲁棒的解决方案。

Abstract: Connected and automated vehicles (CAVs) have the potential to enhance driving safety, for example by enabling safe vehicle following and more efficient traffic scheduling. For such future deployments, safety requirements should be addressed, where the primary such are avoidance of vehicle collisions and substantial mitigating of harm when collisions are unavoidable. However, conservative worst-case-based control strategies come at the price of reduced flexibility and may compromise overall performance. In light of this, we investigate how Deep Reinforcement Learning (DRL) can be leveraged to improve safety in multi-vehicle-following scenarios involving emergency braking. Specifically, we investigate how DRL with vehicle-to-vehicle communication can be used to ethically select an emergency breaking profile in scenarios where overall, or collective, three-vehicle harm reduction or collision avoidance shall be obtained instead of single-vehicle such. As an algorithm, we provide a hybrid approach that combines DRL with a previously published method based on analytical expressions for selecting optimal constant deceleration. By combining DRL with the previous method, the proposed hybrid approach increases the reliability compared to standalone DRL, while achieving superior performance in terms of overall harm reduction and collision avoidance.

</details>


### [294] [On the Stabilization of Rigid Formations on Regular Curves](https://arxiv.org/abs/2512.10700)
*Mohamed Elobaid,Shinkyu Park,Eric Feron*

Main category: cs.RO

TL;DR: 本文提出了一种在平面上任意可微闭合曲线内稳定多智能体等边多边形构型的方法，通过随机多起点牛顿类算法求解内接正多边形，并设计连续反馈控制律保证收敛性与避碰。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在一般平面曲线上稳定刚性（如等边多边形）编队的问题，尤其在路径扫掠后实现构型精确部署并避免碰撞。

Method: 采用随机多起点牛顿类算法求解曲线内接正多边形中心与顶点；设计连续时间反馈控制律，兼顾曲线扫掠覆盖、构型收敛与智能体间避碰。

Result: 算法能保证存在最小化解；控制律确保系统收敛至目标构型且满足避碰约束；数值仿真验证了方法对多种曲线和刚性构型的有效性。

Conclusion: 所提方法为平面上曲线约束下的多智能体刚性构型稳定问题提供了可行、鲁棒且可验证的解决方案。

Abstract: This work deals with the problem of stabilizing a multi-agent rigid formation on a general class of planar curves. Namely, we seek to stabilize an equilateral polygonal formation on closed planar differentiable curves after a path sweep. The task of finding an inscribed regular polygon centered at the point of interest is solved via a randomized multi-start Newton-Like algorithm for which one is able to ascertain the existence of a minimizer. Then we design a continuous feedback law that guarantees convergence to, and sufficient sweeping of the curve, followed by convergence to the desired formation vertices while ensuring inter-agent avoidance. The proposed approach is validated through numerical simulations for different classes of curves and different rigid formations. Code: https://github.com/mebbaid/paper-elobaid-ifacwc-2026

</details>


### [295] [AERMANI-Diffusion: Regime-Conditioned Diffusion for Dynamics Learning in Aerial Manipulators](https://arxiv.org/abs/2512.10773)
*Samaksh Ujjawal,Shivansh Pratap Singh,Naveen Sudheer Nair,Rishabh Dev Yadav,Wei Pan,Spandan Roy*

Main category: cs.RO

TL;DR: 本文提出了一种基于条件扩散模型的残差动力学建模框架，用于提升空中机械臂在复杂动态环境下的控制精度。


<details>
  <summary>Details</summary>
Motivation: 空中机械臂在运动过程中惯性耦合力和气动力变化剧烈且依赖构型，导致传统解析模型失真、标准数据驱动方法难以泛化到多样化工况。

Method: 提出一种基于条件扩散过程与轻量级时序编码器的分段条件扩散框架，编码器提取近期运动与构型信息以支持跨工况（如突变或未知负载）的一致残差预测。

Result: 该框架结合自适应控制器，在真实实验中显著提升了轨迹跟踪精度，并实现了动力学不确定性补偿。

Conclusion: 所提方法有效建模了非线性、非平稳的动力学残差分布，为高动态空中操作提供了更鲁棒、可泛化的建模与控制方案。

Abstract: Aerial manipulators undergo rapid, configuration-dependent changes in inertial coupling forces and aerodynamic forces, making accurate dynamics modeling a core challenge for reliable control. Analytical models lose fidelity under these nonlinear and nonstationary effects, while standard data-driven methods such as deep neural networks and Gaussian processes cannot represent the diverse residual behaviors that arise across different operating conditions. We propose a regime-conditioned diffusion framework that models the full distribution of residual forces using a conditional diffusion process and a lightweight temporal encoder. The encoder extracts a compact summary of recent motion and configuration, enabling consistent residual predictions even through abrupt transitions or unseen payloads. When combined with an adaptive controller, the framework enables dynamics uncertainty compensation and yields markedly improved tracking accuracy in real-world tests.

</details>


### [296] [Iterative Compositional Data Generation for Robot Control](https://arxiv.org/abs/2512.10891)
*Anh-Quan Pham,Marcel Hussing,Shubhankar P. Patankar,Dani S. Bassett,Jorge Mendez-Mendez,Eric Eaton*

Main category: cs.RO

TL;DR: 本文提出了一种语义组合式扩散Transformer模型，通过分解机器人操作中的状态转移为机器人、物体、障碍物和目标等组件，并利用注意力机制学习其交互，从而在仅用少量任务数据训练后，实现对未见任务组合的零样本高质量数据生成与策略学习；进一步结合离线强化学习验证与迭代自提升，显著提升了零样本泛化能力，并展现出表征中自然涌现的组合性结构。


<details>
  <summary>Details</summary>
Motivation: 收集机器人操作数据成本高昂，难以覆盖多物体、多机器人、多环境下的组合爆炸式任务空间；现有生成模型缺乏对机器人领域组合结构的建模，泛化能力差。

Method: 提出语义组合式扩散Transformer，将状态转移分解为机器人、物体、障碍物、目标四类语义组件，通过注意力机制建模其交互；采用零样本生成+离线RL验证的迭代自改进流程。

Result: 在未见任务组合上实现高质量零样本过渡生成；控制策略可直接从中学习；迭代自提升后几乎解决所有预留任务；表征中涌现出有意义的组合结构。

Conclusion: 组合式表征与扩散生成相结合，配合离线RL驱动的迭代优化，能有效提升机器人操作数据生成的泛化性与实用性，为构建可扩展的机器人学习系统提供了新范式。

Abstract: Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, they do not exploit the compositional structure of robotic domains and struggle to generalize to unseen task combinations. We propose a semantic compositional diffusion transformer that factorizes transitions into robot-, object-, obstacle-, and objective-specific components and learns their interactions through attention. Once trained on a limited subset of tasks, we show that our model can zero-shot generate high-quality transitions from which we can learn control policies for unseen task combinations. Then, we introduce an iterative self-improvement procedure in which synthetic data is validated via offline reinforcement learning and incorporated into subsequent training rounds. Our approach substantially improves zero-shot performance over monolithic and hard-coded compositional baselines, ultimately solving nearly all held-out tasks and demonstrating the emergence of meaningful compositional structure in the learned representations.

</details>


### [297] [Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit](https://arxiv.org/abs/2512.10934)
*Zamirddine Mari,Jérôme Pasquet,Julien Seinturier*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习（PPO）的自主无人机导航方法，使其能在未知三维管状环境中仅依靠LiDAR和管中心视觉检测进行稳定飞行，无需先验几何信息；通过课程学习和转向协商机制应对部分可观测性挑战，性能超越依赖中心线先验的纯追踪基线。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在狭窄、封闭管状环境中因几何约束、壁面邻近及感知受限导致的自主导航难题，尤其面向工业、地下或医疗等弱感知窄通道场景。

Method: 采用PPO强化学习框架，输入为LiDAR局部观测与条件式管中心视觉检测；设计渐进式课程学习（从直管到高曲率管）；引入融合直接可见性、方向记忆与LiDAR对称性线索的转向协商机制以应对中心消失问题；以Pure Pursuit算法作为具备中心线先验的确定性基线进行对比。

Result: 训练出的PPO策略在仿真中展现出鲁棒性与泛化能力，持续优于Pure Pursuit基线；高保真3D环境验证表明策略可迁移至连续物理动力学系统。

Conclusion: 该方法构建了面向未知管状环境的端到端自主导航完整框架，证明RL可在严重信息受限下替代几何模型，为实际弱感知窄通道任务提供可行方案。

Abstract: Autonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate unknown three-dimensional tubes without any prior knowledge of their geometry, relying solely on local observations from LiDAR and a conditional visual detection of the tube center. In contrast, the Pure Pursuit algorithm, used as a deterministic baseline, benefits from explicit access to the centerline, creating an information asymmetry designed to assess the ability of RL to compensate for the absence of a geometric model. The agent is trained through a progressive Curriculum Learning strategy that gradually exposes it to increasingly curved geometries, where the tube center frequently disappears from the visual field. A turning-negotiation mechanism, based on the combination of direct visibility, directional memory, and LiDAR symmetry cues, proves essential for ensuring stable navigation under such partial observability conditions. Experiments show that the PPO policy acquires robust and generalizable behavior, consistently outperforming the deterministic controller despite its limited access to geometric information. Validation in a high-fidelity 3D environment further confirms the transferability of the learned behavior to a continuous physical dynamics.
  The proposed approach thus provides a complete framework for autonomous navigation in unknown tubular environments and opens perspectives for industrial, underground, or medical applications where progressing through narrow and weakly perceptive conduits represents a central challenge.

</details>


### [298] [ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning](https://arxiv.org/abs/2512.10946)
*Wendi Chen,Han Xue,Yi Wang,Fangyuan Zhou,Jun Lv,Yang Jin,Shirun Tang,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: 本文提出ImplicitRDP，一种统一的端到端视觉-力觉扩散策略，通过结构化慢-快学习机制和基于虚拟目标的表征正则化，有效融合视觉（全局慢速）与力觉（局部快速）信号，在接触密集操作任务中显著提升反应性与成功率。


<details>
  <summary>Details</summary>
Motivation: 人类级接触密集型操作需协同视觉（空间丰富但时序慢）与力觉（高频响应但局部），二者在频率与信息特性上差异大，传统方法难以有效融合。

Method: 提出ImplicitRDP：1）结构化慢-快学习机制，利用因果注意力异步处理视觉与力觉token；2）基于虚拟目标的表征正则化，将力反馈映射至动作空间以提供物理 grounded 的监督信号。

Result: 在多个接触密集任务上显著优于纯视觉及分层基线，具备更高反应性、成功率及更简化的训练流程。

Conclusion: ImplicitRDP实现了视觉规划与力觉反馈的真正端到端统一建模，为多模态机器人控制提供了新范式。

Abstract: Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at https://implicit-rdp.github.io.

</details>
