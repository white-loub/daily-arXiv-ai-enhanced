<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 87]
- [cs.CL](#cs.CL) [Total: 66]
- [cs.RO](#cs.RO) [Total: 49]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.LG](#cs.LG) [Total: 113]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.AI](#cs.AI) [Total: 36]
- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Leveraging NTPs for Efficient Hallucination Detection in VLMs](https://arxiv.org/abs/2509.20379)
*Ofir Azachi,Kfir Eliyahu,Eyal El Ani,Rom Himelstein,Roi Reichart,Yuval Pinter,Nitay Calderon*

Main category: cs.CV

TL;DR: 本文提出一种基于视觉-语言模型（VLM）下一词概率（NTP）的轻量级幻觉检测方法，利用NTP反映模型不确定性，并结合传统机器学习模型实现高效、实时的幻觉识别，性能媲美使用VLM自身检测的方法。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型（VLM）生成文本时可能出现与视觉内容不符的幻觉问题，影响其可靠性。现有检测方法依赖VLM自身或另一VLM进行评估，计算开销大、延迟高，因此需要更高效的检测方案。

Method: 提取VLM生成过程中的下一词概率（NTP）作为不确定性信号，训练传统机器学习模型进行幻觉检测；引入包含1400个人工标注样本的数据集验证方法有效性；进一步结合仅输入生成文本得到的语言学NTP，并融合VLM的幻觉预测分数以提升性能。

Result: NTP特征能有效预测幻觉，轻量级模型即可达到与强VLM相当的检测性能；加入语言学NTP和VLM预测分数可进一步提升效果；整体方法速度快、计算成本低。

Conclusion: 基于NTP的轻量级方法为VLM幻觉检测提供了高效可行的解决方案，有助于提升VLM在实际应用中的可靠性和实用性。

Abstract: Hallucinations of vision-language models (VLMs), which are misalignments
between visual content and generated text, undermine the reliability of VLMs.
One common approach for detecting them employs the same VLM, or a different
one, to assess generated outputs. This process is computationally intensive and
increases model latency. In this paper, we explore an efficient on-the-fly
method for hallucination detection by training traditional ML models over
signals based on the VLM's next-token probabilities (NTPs). NTPs provide a
direct quantification of model uncertainty. We hypothesize that high
uncertainty (i.e., a low NTP value) is strongly associated with hallucinations.
To test this, we introduce a dataset of 1,400 human-annotated statements
derived from VLM-generated content, each labeled as hallucinated or not, and
use it to test our NTP-based lightweight method. Our results demonstrate that
NTP-based features are valuable predictors of hallucinations, enabling fast and
simple ML models to achieve performance comparable to that of strong VLMs.
Furthermore, augmenting these NTPs with linguistic NTPs, computed by feeding
only the generated text back into the VLM, enhances hallucination detection
performance. Finally, integrating hallucination prediction scores from VLMs
into the NTP-based models led to better performance than using either VLMs or
NTPs alone. We hope this study paves the way for simple, lightweight solutions
that enhance the reliability of VLMs.

</details>


### [2] [Quasi-Synthetic Riemannian Data Generation for Writer-Independent Offline Signature Verification](https://arxiv.org/abs/2509.20420)
*Elias N. Zois,Moises Diaz,Salem Said,Miguel A. Ferrer*

Main category: cs.CV

TL;DR: 提出一种基于黎曼几何的准合成数据生成框架，用于离线手写签名验证，通过SPD矩阵上的高斯混合模型生成合成签名数据，在跨数据集和跨书写风格场景下表现出低错误率。


<details>
  <summary>Details</summary>
Motivation: 在书写者独立的离线手写签名验证中，缺乏足够的真实训练数据，且现有方法依赖手工特征或真实数据，难以泛化。

Method: 利用对称正定（SPD）矩阵的黎曼几何特性，构建黎曼高斯混合模型，以少量真实样本为种子生成正负类合成SPD数据，并采用度量学习框架进行训练和验证。

Result: 在两个包含西方和亚洲书写风格的真实数据集上，该方法在跨数据集和同数据集评估协议下均实现了较低的错误率。

Conclusion: 准合成数据在黎曼空间中的生成有效提升了书写者独立签名验证系统的性能，展示了黎曼几何在合成数据生成中的潜力。

Abstract: Offline handwritten signature verification remains a challenging task,
particularly in writer-independent settings where models must generalize across
unseen individuals. Recent developments have highlighted the advantage of
geometrically inspired representations, such as covariance descriptors on
Riemannian manifolds. However, past or present, handcrafted or data-driven
methods usually depend on real-world signature datasets for classifier
training. We introduce a quasi-synthetic data generation framework leveraging
the Riemannian geometry of Symmetric Positive Definite matrices (SPD). A small
set of genuine samples in the SPD space is the seed to a Riemannian Gaussian
Mixture which identifies Riemannian centers as synthetic writers and variances
as their properties. Riemannian Gaussian sampling on each center generates
positive as well as negative synthetic SPD populations. A metric learning
framework utilizes pairs of similar and dissimilar SPD points, subsequently
testing it over on real-world datasets. Experiments conducted on two popular
signature datasets, encompassing Western and Asian writing styles, demonstrate
the efficacy of the proposed approach under both intra- and cross- dataset
evaluation protocols. The results indicate that our quasi-synthetic approach
achieves low error rates, highlighting the potential of generating synthetic
data in Riemannian spaces for writer-independent signature verification
systems.

</details>


### [3] [Seedream 4.0: Toward Next-generation Multimodal Image Generation](https://arxiv.org/abs/2509.20427)
*Team Seedream,Yunpeng Chen,Yu Gao,Lixue Gong,Meng Guo,Qiushan Guo,Zhiyao Guo,Xiaoxia Hou,Weilin Huang,Yixuan Huang,Xiaowen Jian,Huafeng Kuang,Zhichao Lai,Fanshi Li,Liang Li,Xiaochen Lian,Chao Liao,Liyang Liu,Wei Liu,Yanzuo Lu,Zhengxiong Luo,Tongtong Ou,Guang Shi,Yichun Shi,Shiqi Sun,Yu Tian,Zhi Tian,Peng Wang,Rui Wang,Xun Wang,Ye Wang,Guofeng Wu,Jie Wu,Wenxu Wu,Yonghui Wu,Xin Xia,Xuefeng Xiao,Shuang Xu,Xin Yan,Ceyuan Yang,Jianchao Yang,Zhonghua Zhai,Chenlin Zhang,Heng Zhang,Qi Zhang,Xinyu Zhang,Yuwei Zhang,Shijia Zhao,Wenliang Zhao,Wenjia Zhu*

Main category: cs.CV

TL;DR: Seedream 4.0 是一个高效的多模态图像生成系统，统一了文本到图像生成、图像编辑和多图像合成，支持快速生成高分辨率图像，并在多种任务上达到业界领先水平。


<details>
  <summary>Details</summary>
Motivation: 为了提升多模态图像生成的效率与性能，整合文本生成图像、图像编辑和多图像合成功能于单一框架中，增强生成模型的交互性与实用性。

Method: 采用高效的扩散Transformer与强大的VAE减少图像token数量，结合多模态后训练、对抗蒸馏、分布匹配、量化和推测解码等技术进行推理加速。

Result: Seedream 4.0 可在1.8秒内生成2K图像，在文本到图像生成和多模态图像编辑任务上达到SOTA，具备精确编辑、上下文推理和多图参考能力。

Conclusion: Seedream 4.0 将传统文本到图像系统扩展为更智能、交互性强的多维创作工具，推动生成式AI在创意与专业场景的应用边界。

Abstract: We introduce Seedream 4.0, an efficient and high-performance multimodal image
generation system that unifies text-to-image (T2I) synthesis, image editing,
and multi-image composition within a single framework. We develop a highly
efficient diffusion transformer with a powerful VAE which also can reduce the
number of image tokens considerably. This allows for efficient training of our
model, and enables it to fast generate native high-resolution images (e.g.,
1K-4K). Seedream 4.0 is pretrained on billions of text-image pairs spanning
diverse taxonomies and knowledge-centric concepts. Comprehensive data
collection across hundreds of vertical scenarios, coupled with optimized
strategies, ensures stable and large-scale training, with strong
generalization. By incorporating a carefully fine-tuned VLM model, we perform
multi-modal post-training for training both T2I and image editing tasks
jointly. For inference acceleration, we integrate adversarial distillation,
distribution matching, and quantization, as well as speculative decoding. It
achieves an inference time of up to 1.8 seconds for generating a 2K image
(without a LLM/VLM as PE model). Comprehensive evaluations reveal that Seedream
4.0 can achieve state-of-the-art results on both T2I and multimodal image
editing. In particular, it demonstrates exceptional multimodal capabilities in
complex tasks, including precise image editing and in-context reasoning, and
also allows for multi-image reference, and can generate multiple output images.
This extends traditional T2I systems into an more interactive and
multidimensional creative tool, pushing the boundary of generative AI for both
creativity and professional applications. Seedream 4.0 is now accessible on
https://www.volcengine.com/experience/ark?launch=seedream.

</details>


### [4] [A Contrastive Learning Framework for Breast Cancer Detection](https://arxiv.org/abs/2509.20474)
*Samia Saeed,Khuram Naveed*

Main category: cs.CV

TL;DR: 本研究提出了一种基于对比学习的半监督框架，利用ResNet-50在少量标注数据和大量未标注乳腺X线图像上进行训练，通过数据增强提升模型性能，在INbreast和MIAS数据集上实现了96.7%的准确率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球癌症相关死亡的第二大原因，早期检测对改善治疗效果至关重要。现有的深度学习方法因依赖大规模标注数据而在准确性上受限，因此需要一种能在小标注数据集上仍保持高性能的方法。

Method: 采用半监督对比学习框架，使用ResNet-50模型，基于相似性指数在大量未标注乳腺X线数据上进行预训练，并结合多种数据增强和变换策略，最后在少量标注数据上进行微调。

Result: 在INbreast和MIAS两个基准数据集上，该方法实现了96.7%的乳腺癌检测准确率，超过了现有的最先进方法。

Conclusion: 所提出的对比学习框架能有效利用未标注数据，显著提升小样本下的乳腺癌检测性能，具有在临床CAD系统中应用的潜力。

Abstract: Breast cancer, the second leading cause of cancer-related deaths globally,
accounts for a quarter of all cancer cases [1]. To lower this death rate, it is
crucial to detect tumors early, as early-stage detection significantly improves
treatment outcomes. Advances in non-invasive imaging techniques have made early
detection possible through computer-aided detection (CAD) systems which rely on
traditional image analysis to identify malignancies. However, there is a
growing shift towards deep learning methods due to their superior
effectiveness. Despite their potential, deep learning methods often struggle
with accuracy due to the limited availability of large-labeled datasets for
training. To address this issue, our study introduces a Contrastive Learning
(CL) framework, which excels with smaller labeled datasets. In this regard, we
train Resnet-50 in semi supervised CL approach using similarity index on a
large amount of unlabeled mammogram data. In this regard, we use various
augmentation and transformations which help improve the performance of our
approach. Finally, we tune our model on a small set of labelled data that
outperforms the existing state of the art. Specifically, we observed a 96.7%
accuracy in detecting breast cancer on benchmark datasets INbreast and MIAS.

</details>


### [5] [Are Foundation Models Ready for Industrial Defect Recognition? A Reality Check on Real-World Data](https://arxiv.org/abs/2509.20479)
*Simon Baeuerle,Pratik Khanna,Nils Friederich,Angelo Jovin Yamachui Sitcheu,Damir Shakirov,Andreas Steimer,Ralf Mikut*

Main category: cs.CV

TL;DR: 本文探讨了基础模型（FMs）在工业质量检测中的应用潜力，发现尽管这些模型在公共基准数据集上表现良好，但在真实工业图像数据上普遍失败。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型在无需大量标注数据的零样本设置下，是否适用于多产品、多类型的工业质量检测任务，以替代传统依赖标注数据的监督AI模型。

Method: 测试多种最新的基础模型在自定义的真实工业图像数据和公共图像数据上的表现，比较其在不同数据集上的性能差异。

Result: 所有测试的基础模型在真实工业数据上均表现不佳，尽管它们在公共基准数据集上表现良好。

Conclusion: 当前的基础模型虽有潜力，但尚不能直接应用于复杂的现实工业质检场景，需进一步改进以适应实际工业需求。

Abstract: Foundation Models (FMs) have shown impressive performance on various text and
image processing tasks. They can generalize across domains and datasets in a
zero-shot setting. This could make them suitable for automated quality
inspection during series manufacturing, where various types of images are being
evaluated for many different products. Replacing tedious labeling tasks with a
simple text prompt to describe anomalies and utilizing the same models across
many products would save significant efforts during model setup and
implementation. This is a strong advantage over supervised Artificial
Intelligence (AI) models, which are trained for individual applications and
require labeled training data. We test multiple recent FMs on both custom
real-world industrial image data and public image data. We show that all of
those models fail on our real-world data, while the very same models perform
well on public benchmark datasets.

</details>


### [6] [Shared Neural Space: Unified Precomputed Feature Encoding for Multi-Task and Cross Domain Vision](https://arxiv.org/abs/2509.20481)
*Jing Li,Oskar Bartosz,Chengyu Wang,Michal Wnuczynski,Dilshan Godaliyadda,Michael Polley*

Main category: cs.CV

TL;DR: 提出了一种通用的神经空间（NS），通过编码器-解码器框架在视觉和成像任务中预计算特征，实现多任务共享同一特征空间，提升效率与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型针对特定高精度任务定制，难以高效处理一系列模块化任务，因每个任务需映射到不同的潜在空间，导致冗余和低效。

Method: 设计一个轻量级CNN-based编码器-解码器架构，构建通用神经空间（NS），编码器学习具有变换感知性和可泛化的表示，供多个下游任务共享。

Result: 在去马赛克、去噪、深度估计和语义分割等多个视觉与成像任务中验证了该方法的有效性，实现了高效多任务处理，减少了冗余，并提升了跨域泛化能力。

Conclusion: 所提出的通用神经空间为高效多任务视觉系统提供了基础，兼具轻量化和广泛硬件兼容性，优于大型Transformer骨干网络。

Abstract: The majority of AI models in imaging and vision are customized to perform on
specific high-precision task. However, this strategy is inefficient for
applications with a series of modular tasks, since each requires a mapping into
a disparate latent domain. To address this inefficiency, we proposed a
universal Neural Space (NS), where an encoder-decoder framework pre-computes
features across vision and imaging tasks. Our encoder learns transformation
aware, generalizable representations, which enable multiple downstream AI
modules to share the same feature space. This architecture reduces redundancy,
improves generalization across domain shift, and establishes a foundation for
effecient multi-task vision pipelines. Furthermore, as opposed to larger
transformer backbones, our backbone is lightweight and CNN-based, allowing for
wider across hardware. We furthur demonstrate that imaging and vision modules,
such as demosaicing, denoising, depth estimation and semantic segmentation can
be performed efficiently in the NS.

</details>


### [7] [Data-Efficient Stream-Based Active Distillation for Scalable Edge Model Deployment](https://arxiv.org/abs/2509.20484)
*Dani Manjah,Tim Bary,Benoît Gérin,Benoît Macq,Christophe de Vleeschouwer*

Main category: cs.CV

TL;DR: 提出一种结合高置信度流式策略与多样性方法的图像选择方案，以在低传输成本下最大化边缘设备模型质量。


<details>
  <summary>Details</summary>
Motivation: 在边缘摄像头系统中，如何高效选择最有用的图像进行训练，以平衡模型质量和传输成本是一个关键问题。

Method: 采用高置信度流式策略结合基于多样性的方法来筛选用于训练的图像，并在相似训练负载下评估模型性能。

Result: 该方法能够在较少数据查询的情况下，生成高质量的模型，显著降低传输成本。

Conclusion: 结合高置信度和多样性的图像选择策略，在保持低通信开销的同时，有效提升了边缘设备上轻量模型的训练效果。

Abstract: Edge camera-based systems are continuously expanding, facing ever-evolving
environments that require regular model updates. In practice, complex teacher
models are run on a central server to annotate data, which is then used to
train smaller models tailored to the edge devices with limited computational
power. This work explores how to select the most useful images for training to
maximize model quality while keeping transmission costs low. Our work shows
that, for a similar training load (i.e., iterations), a high-confidence
stream-based strategy coupled with a diversity-based approach produces a
high-quality model with minimal dataset queries.

</details>


### [8] [InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On](https://arxiv.org/abs/2509.20524)
*Julien Han,Shuwen Qiu,Qi Li,Xingzi Xu,Mehmet Saygin Seyfioglu,Kavosh Asadi,Karim Bouyarmane*

Main category: cs.CV

TL;DR: InstructVTON是一个基于自然语言指令的交互式虚拟试穿系统，通过视觉语言模型和图像分割自动生​​成二值掩码，实现对单个或多个服装的细粒度、复杂风格控制，克服了传统掩码方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于掩码的虚拟试穿方法在处理复杂风格控制时存在局限，例如无法精确生成所需掩码或难以实现特定样式（如卷起袖子），且用户体验较差。因此需要一种更灵活、用户友好的解决方案。

Method: 将虚拟试穿问题建模为图像引导的修复任务，利用视觉语言模型（VLM）和图像分割模型，根据用户提供的图像和自由文本指令自动生成二值掩码，并支持多轮图像生成以实现复杂试穿场景。

Result: InstructVTON无需用户手动绘制精确掩码，能够处理传统方法无法实现的试穿情况（如袖子卷起），并与现有虚拟试穿模型兼容，实现了具有精细风格控制的最先进效果。

Conclusion: InstructVTON通过结合VLM和图像分割技术，简化了用户操作，提升了虚拟试穿系统的灵活性和可控性，推动了指令驱动的个性化虚拟试穿发展。

Abstract: We present InstructVTON, an instruction-following interactive virtual try-on
system that allows fine-grained and complex styling control of the resulting
generation, guided by natural language, on single or multiple garments. A
computationally efficient and scalable formulation of virtual try-on formulates
the problem as an image-guided or image-conditioned inpainting task. These
inpainting-based virtual try-on models commonly use a binary mask to control
the generation layout. Producing a mask that yields desirable result is
difficult, requires background knowledge, might be model dependent, and in some
cases impossible with the masking-based approach (e.g. trying on a long-sleeve
shirt with "sleeves rolled up" styling on a person wearing long-sleeve shirt
with sleeves down, where the mask will necessarily cover the entire sleeve).
InstructVTON leverages Vision Language Models (VLMs) and image segmentation
models for automated binary mask generation. These masks are generated based on
user-provided images and free-text style instructions. InstructVTON simplifies
the end-user experience by removing the necessity of a precisely drawn mask,
and by automating execution of multiple rounds of image generation for try-on
scenarios that cannot be achieved with masking-based virtual try-on models
alone. We show that InstructVTON is interoperable with existing virtual try-on
models to achieve state-of-the-art results with styling control.

</details>


### [9] [Innovative Deep Learning Architecture for Enhanced Altered Fingerprint Recognition](https://arxiv.org/abs/2509.20537)
*Dana A Abdullah,Dana Rasul Hamad,Bishar Rasheed Ibrahim,Sirwan Abdulwahid Aula,Aso Khaleel Ameen,Sabat Salih Hamadamin*

Main category: cs.CV

TL;DR: 本文提出了一种名为DeepAFRNet的深度学习模型，用于识别经过刻意修改的指纹，在SOCOFing真实-篡改子集上实现了高准确率，表明其在现实场景中具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 由于攻击者可能故意改变指纹纹路以逃避检测，因此对篡改指纹进行鲁棒识别在边境控制、法医鉴定等安全关键场景中至关重要。

Method: 采用VGG16作为骨干网络提取高维特征，并使用余弦相似度比较嵌入向量以实现指纹匹配。

Result: 在SOCOFing数据集的Easy、Medium和Hard三个难度级别上，使用严格阈值时分别达到了96.7%、98.76%和99.54%的准确率；但降低阈值后性能显著下降，凸显了阈值选择的重要性。

Conclusion: DeepAFRNet通过使用真实篡改样本并报告分级指标，克服了以往基于合成数据或有限验证协议研究的局限性，显示出在需要高安全性和识别鲁棒性的实际部署中的可行性。

Abstract: Altered fingerprint recognition (AFR) is challenging for biometric
verification in applications such as border control, forensics, and fiscal
admission. Adversaries can deliberately modify ridge patterns to evade
detection, so robust recognition of altered prints is essential. We present
DeepAFRNet, a deep learning recognition model that matches and recognizes
distorted fingerprint samples. The approach uses a VGG16 backbone to extract
high-dimensional features and cosine similarity to compare embeddings. We
evaluate on the SOCOFing Real-Altered subset with three difficulty levels
(Easy, Medium, Hard). With strict thresholds, DeepAFRNet achieves accuracies of
96.7 percent, 98.76 percent, and 99.54 percent for the three levels. A
threshold-sensitivity study shows that relaxing the threshold from 0.92 to 0.72
sharply degrades accuracy to 7.86 percent, 27.05 percent, and 29.51 percent,
underscoring the importance of threshold selection in biometric systems. By
using real altered samples and reporting per-level metrics, DeepAFRNet
addresses limitations of prior work based on synthetic alterations or limited
verification protocols, and indicates readiness for real-world deployments
where both security and recognition resilience are critical.

</details>


### [10] [Large Pre-Trained Models for Bimanual Manipulation in 3D](https://arxiv.org/abs/2509.20579)
*Hanna Yurchyk,Wei-Di Chang,Gregory Dudek,David Meger*

Main category: cs.CV

TL;DR: 将预训练Vision Transformer的注意力图集成到体素表示中，以提升双手机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 希望通过利用视觉Transformer模型提取的注意力图来增强机器人对关键区域的关注，从而提高双手机器人操作任务中的表现。

Method: 从自监督ViT模型DINOv2中提取注意力图，并将其解释为RGB图像上的像素级显著性得分，然后将这些图提升到3D体素网格中，生成体素级语义线索并融入行为克隆策略。

Result: 在RLBench双手机器人操作基准上，所提方法平均绝对性能提升8.2%，相对增益达21.9%。

Conclusion: 将注意力图融入体素表示能有效提升双手机器人操作策略的性能，验证了语义感知表征在复杂操作任务中的价值。

Abstract: We investigate the integration of attention maps from a pre-trained Vision
Transformer into voxel representations to enhance bimanual robotic
manipulation. Specifically, we extract attention maps from DINOv2, a
self-supervised ViT model, and interpret them as pixel-level saliency scores
over RGB images. These maps are lifted into a 3D voxel grid, resulting in
voxel-level semantic cues that are incorporated into a behavior cloning policy.
When integrated into a state-of-the-art voxel-based policy, our
attention-guided featurization yields an average absolute improvement of 8.2%
and a relative gain of 21.9% across all tasks in the RLBench bimanual
benchmark.

</details>


### [11] [A Comparative Benchmark of Real-time Detectors for Blueberry Detection towards Precision Orchard Management](https://arxiv.org/abs/2509.20580)
*Xinyang Mu,Yuzhen Lu,Boyang Deng*

Main category: cs.CV

TL;DR: 本研究提出了一种针对蓝莓检测的新型实时目标检测模型基准分析，使用包含85,879个标注实例的新数据集，比较了YOLO和RT-DETR系列共36种模型变体，并通过半监督学习进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 蓝莓在自然环境中的检测面临光照变化、遮挡和运动模糊等挑战，现有深度学习模型需要大规模多样化数据集和合适的精度/速度/内存权衡。

Method: 构建了一个包含661张树冠图像的新数据集，评估了YOLO（v8-v12）和RT-DETR（v1-v2）共36种模型；采用基于Unbiased Mean Teacher的半监督学习对模型进行微调以提升性能。

Result: YOLOv12m达到93.3% mAP@50，RT-DETRv2-X表现最佳，初始mAP@50为93.6%，经半监督学习后提升至94.8%；中等规模模型在精度与速度间取得较好平衡。

Conclusion: RT-DETRv2-X在蓝莓检测中表现最优，结合半监督学习可进一步提升性能；公开发布的数据集和代码有助于推动后续研究。

Abstract: Blueberry detection in natural environments remains challenging due to
variable lighting, occlusions, and motion blur due to environmental factors and
imaging devices. Deep learning-based object detectors promise to address these
challenges, but they demand a large-scale, diverse dataset that captures the
real-world complexities. Moreover, deploying these models in practical
scenarios often requires the right accuracy/speed/memory trade-off in model
selection. This study presents a novel comparative benchmark analysis of
advanced real-time object detectors, including YOLO (You Only Look Once)
(v8-v12) and RT-DETR (Real-Time Detection Transformers) (v1-v2) families,
consisting of 36 model variants, evaluated on a newly curated dataset for
blueberry detection. This dataset comprises 661 canopy images collected with
smartphones during the 2022-2023 seasons, consisting of 85,879 labelled
instances (including 36,256 ripe and 49,623 unripe blueberries) across a wide
range of lighting conditions, occlusions, and fruit maturity stages. Among the
YOLO models, YOLOv12m achieved the best accuracy with a mAP@50 of 93.3%, while
RT-DETRv2-X obtained a mAP@50 of 93.6%, the highest among all the RT-DETR
variants. The inference time varied with the model scale and complexity, and
the mid-sized models appeared to offer a good accuracy-speed balance. To
further enhance detection performance, all the models were fine-tuned using
Unbiased Mean Teacher-based semi-supervised learning (SSL) on a separate set of
1,035 unlabeled images acquired by a ground-based machine vision platform in
2024. This resulted in accuracy gains ranging from -1.4% to 2.9%, with
RT-DETR-v2-X achieving the best mAP@50 of 94.8%. More in-depth research into
SSL is needed to better leverage cross-domain unlabeled data. Both the dataset
and software programs of this study are made publicly available to support
further research.

</details>


### [12] [Region-of-Interest Augmentation for Mammography Classification under Patient-Level Cross-Validation](https://arxiv.org/abs/2509.20585)
*Farbod Bigdeli,Mohsen Mohammadagha,Ali Bigdeli*

Main category: cs.CV

TL;DR: 提出一种轻量级的ROI增强策略，通过在训练过程中用随机ROI裁剪替换全图，提升Mini-DDSM数据集上的乳腺癌筛查性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在乳腺X线摄影诊断中受限于低分辨率数据集和小样本量，影响模型性能。

Method: 利用预计算的无标签边界框库，在训练时以一定概率将全图替换为随机ROI裁剪，并可加入抖动增加多样性；采用严格的患者级别交叉验证评估。

Result: 在Mini-DDSM上，ROI增强（最佳参数p_roi=0.10, alpha=0.10）带来轻微的ROC-AUC提升，但PR-AUC持平或略降；推理成本不变，训练效率指标良好。

Conclusion: 简单的数据驱动ROI增强策略可在不增加标签或修改网络结构的情况下，有效提升有限资源下的乳腺X线分类性能。

Abstract: Breast cancer screening with mammography remains central to early detection
and mortality reduction. Deep learning has shown strong potential for
automating mammogram interpretation, yet limited-resolution datasets and small
sample sizes continue to restrict performance. We revisit the Mini-DDSM dataset
(9,684 images; 2,414 patients) and introduce a lightweight region-of-interest
(ROI) augmentation strategy. During training, full images are probabilistically
replaced with random ROI crops sampled from a precomputed, label-free
bounding-box bank, with optional jitter to increase variability. We evaluate
under strict patient-level cross-validation and report ROC-AUC, PR-AUC, and
training-time efficiency metrics (throughput and GPU memory). Because ROI
augmentation is training-only, inference-time cost remains unchanged. On
Mini-DDSM, ROI augmentation (best: p_roi = 0.10, alpha = 0.10) yields modest
average ROC-AUC gains, with performance varying across folds; PR-AUC is flat to
slightly lower. These results demonstrate that simple, data-centric ROI
strategies can enhance mammography classification in constrained settings
without requiring additional labels or architectural modifications.

</details>


### [13] [Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirror Reflections](https://arxiv.org/abs/2509.20607)
*Jing Wu,Zirui Wang,Iro Laina,Victor Adrian Prisacariu*

Main category: cs.CV

TL;DR: 本文提出了一种利用镜面反射生成虚拟视角的方法，通过构建物理上有效的虚拟相机实现单图像多视图立体重建，并引入对称感知损失优化姿态估计，框架可自然扩展到动态场景。


<details>
  <summary>Details</summary>
Motivation: 镜面反射在日常环境中普遍存在，能够在一个图像中同时提供真实视图和反射的虚拟视图，但如何有效利用这种反射信息进行3D重建仍具挑战。

Method: 将镜面反射视为辅助视图，设计一种变换来构造物理上有效的虚拟相机，直接在像素域生成虚拟视图，并结合对称感知损失优化姿态估计。

Result: 实现了从单张图像出发的多视图立体重建，在合成和真实数据上均表现出良好的3D重建效果，尤其适用于含镜面反射的静态与动态场景。

Conclusion: 该方法充分利用镜面的几何对称性，简化了成像过程，兼容现有的前馈重建模型，实现了通用且鲁棒的3D重建。

Abstract: Mirror reflections are common in everyday environments and can provide stereo
information within a single capture, as the real and reflected virtual views
are visible simultaneously. We exploit this property by treating the reflection
as an auxiliary view and designing a transformation that constructs a
physically valid virtual camera, allowing direct pixel-domain generation of the
virtual view while adhering to the real-world imaging process. This enables a
multi-view stereo setup from a single image, simplifying the imaging process,
making it compatible with powerful feed-forward reconstruction models for
generalizable and robust 3D reconstruction. To further exploit the geometric
symmetry introduced by mirrors, we propose a symmetric-aware loss to refine
pose estimation. Our framework also naturally extends to dynamic scenes, where
each frame contains a mirror reflection, enabling efficient per-frame geometry
recovery. For quantitative evaluation, we provide a fully customizable
synthetic dataset of 16 Blender scenes, each with ground-truth point clouds and
camera poses. Extensive experiments on real-world data and synthetic data are
conducted to illustrate the effectiveness of our method.

</details>


### [14] [Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery](https://arxiv.org/abs/2509.20628)
*Yiming Xiao,Archit Gupta,Miguel Esparza,Yu-Hsuan Ho,Antonia Sebastian,Hannah Weas,Rose Houck,Ali Mostafavi*

Main category: cs.CV

TL;DR: 提出FacadeTrack框架，通过街景全景视频与地块关联，提取建筑立面的可解释属性，支持灾后建筑占用状态评估。


<details>
  <summary>Details</summary>
Motivation: 灾后建筑占用状态对资源分配、电力恢复等至关重要，但现有遥感影像难以捕捉建筑立面和入口细节，而街景图像稀疏且难与地块匹配。

Method: 提出语言引导的FacadeTrack框架，将全景视频与地块链接，校正立面视角，并提取影响可居住性的可解释属性（如入口阻塞、临时覆盖物等），采用一阶段规则和两阶段感知-推理分离策略进行决策。

Result: 在两次飓风Helene灾后调查中，两阶段方法达到0.927精度、0.781召回率和0.848 F1分数，优于一阶段基线（0.943精度、0.728召回率、0.822 F1分数）；中间属性和空间诊断有助于定位误差原因。

Conclusion: 该框架提供可审计、可扩展的占用评估方案，适用于地理信息系统和应急管理流程集成。

Abstract: Building-level occupancy after disasters is vital for triage, inspections,
utility re-energization, and equitable resource allocation. Overhead imagery
provides rapid coverage but often misses facade and access cues that determine
habitability, while street-view imagery captures those details but is sparse
and difficult to align with parcels. We present FacadeTrack, a street-level,
language-guided framework that links panoramic video to parcels, rectifies
views to facades, and elicits interpretable attributes (for example, entry
blockage, temporary coverings, localized debris) that drive two decision
strategies: a transparent one-stage rule and a two-stage design that separates
perception from conservative reasoning. Evaluated across two post-Hurricane
Helene surveys, the two-stage approach achieves a precision of 0.927, a recall
of 0.781, and an F-1 score of 0.848, compared with the one-stage baseline at a
precision of 0.943, a recall of 0.728, and an F-1 score of 0.822. Beyond
accuracy, intermediate attributes and spatial diagnostics reveal where and why
residual errors occur, enabling targeted quality control. The pipeline provides
auditable, scalable occupancy assessments suitable for integration into
geospatial and emergency-management workflows.

</details>


### [15] [Human Semantic Representations of Social Interactions from Moving Shapes](https://arxiv.org/abs/2509.20673)
*Yiling Yun,Hongjing Lu*

Main category: cs.CV

TL;DR: 该研究探讨了人类在识别简单移动形状所展示的社会互动时，语义表征如何补充视觉特征。通过两项研究发现，基于描述提取的动词语义嵌入最能解释人类的相似性判断，表明社会感知反映了社会互动的语义结构。


<details>
  <summary>Details</summary>
Motivation: 理解人类在识别简单动态形状中的社会互动时，除了视觉特征外，还依赖哪些语义表征来辅助感知。

Method: 研究1中让参与者根据对移动形状的印象进行标签化；研究2通过人类相似性判断测量27种社会互动的表征几何，并与基于视觉特征、标签和语义嵌入的模型预测进行比较。

Result: 人类反应呈现分布性；语义模型为视觉特征提供了补充信息，其中基于动词的语义嵌入最能解释人类的相似性判断。

Conclusion: 简单动态显示中的社会感知不仅依赖视觉特征，还反映社会互动的语义结构，实现了视觉与抽象表征之间的桥梁。

Abstract: Humans are social creatures who readily recognize various social interactions
from simple display of moving shapes. While previous research has often focused
on visual features, we examine what semantic representations that humans employ
to complement visual features. In Study 1, we directly asked human participants
to label the animations based on their impression of moving shapes. We found
that human responses were distributed. In Study 2, we measured the
representational geometry of 27 social interactions through human similarity
judgments and compared it with model predictions based on visual features,
labels, and semantic embeddings from animation descriptions. We found that
semantic models provided complementary information to visual features in
explaining human judgments. Among the semantic models, verb-based embeddings
extracted from descriptions account for human similarity judgments the best.
These results suggest that social perception in simple displays reflects the
semantic structure of social interactions, bridging visual and abstract
representations.

</details>


### [16] [Enhancing Cross-View Geo-Localization Generalization via Global-Local Consistency and Geometric Equivariance](https://arxiv.org/abs/2509.20684)
*Xiaowei Wang,Di Wang,Ke Li,Yifeng Wang,Chengjian Wang,Libin Sun,Zhihong Wu,Yiming Zhang,Quan Wang*

Main category: cs.CV

TL;DR: 提出了一种新的跨视角地理定位框架EGS，利用E(2)-Steerable CNN和带虚拟超级节点的图结构来提升跨域泛化能力，在多个基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在应对无人机不同朝向和视野导致的显著外观变化时鲁棒性不足，且难以建立兼顾全局语义与局部细节的可靠匹配关系。

Method: 采用E(2)-Steerable CNN编码器提取对旋转和视角变化鲁棒的特征，并构建包含虚拟超级节点的图结构以聚合和分发全局语义到局部区域，实现全局-局部一致性。

Result: 在University-1652和SUES-200数据集上实验表明，EGS在跨域CVGL任务中显著优于现有方法，性能大幅提升。

Conclusion: EGS有效提升了跨视角地理定位中的跨域泛化能力和匹配精度，为解决复杂视角变化下的定位问题提供了新思路。

Abstract: Cross-view geo-localization (CVGL) aims to match images of the same location
captured from drastically different viewpoints. Despite recent progress,
existing methods still face two key challenges: (1) achieving robustness under
severe appearance variations induced by diverse UAV orientations and fields of
view, which hinders cross-domain generalization, and (2) establishing reliable
correspondences that capture both global scene-level semantics and fine-grained
local details. In this paper, we propose EGS, a novel CVGL framework designed
to enhance cross-domain generalization. Specifically, we introduce an
E(2)-Steerable CNN encoder to extract stable and reliable features under
rotation and viewpoint shifts. Furthermore, we construct a graph with a virtual
super-node that connects to all local nodes, enabling global semantics to be
aggregated and redistributed to local regions, thereby enforcing global-local
consistency. Extensive experiments on the University-1652 and SUES-200
benchmarks demonstrate that EGS consistently achieves substantial performance
gains and establishes a new state of the art in cross-domain CVGL.

</details>


### [17] [DENet: Dual-Path Edge Network with Global-Local Attention for Infrared Small Target Detection](https://arxiv.org/abs/2509.20701)
*Jiayi Zuo,Songwei Pei,Qian Li*

Main category: cs.CV

TL;DR: 提出一种双路径边缘网络（Dual-Path Edge Network），通过解耦边缘增强与语义建模，在红外小目标检测中实现更精确的定位与抑制噪声。


<details>
  <summary>Details</summary>
Motivation: 红外小目标缺乏显著纹理和形态特征，易融入复杂背景，现有方法难以兼顾高分辨率细节与强语义上下文，导致特征错位和性能不佳。

Method: 设计双路径结构：一条路径使用双向交互模块（结合局部与全局自注意力）捕获多尺度特征依赖；另一条路径引入多边缘精炼模块，采用级联泰勒有限差分算子和注意力门控机制进行多尺度边缘增强。

Result: 所提方法在多个数据集上实现了优于现有方法的小目标检测性能，有效提升了边缘定位精度并抑制了背景噪声。

Conclusion: 该双路径框架通过融合结构语义与边缘细化，为红外小目标检测提供了一种鲁棒且高效的解决方案。

Abstract: Infrared small target detection is crucial for remote sensing applications
like disaster warning and maritime surveillance. However, due to the lack of
distinctive texture and morphological features, infrared small targets are
highly susceptible to blending into cluttered and noisy backgrounds. A
fundamental challenge in designing deep models for this task lies in the
inherent conflict between capturing high-resolution spatial details for minute
targets and extracting robust semantic context for larger targets, often
leading to feature misalignment and suboptimal performance. Existing methods
often rely on fixed gradient operators or simplistic attention mechanisms,
which are inadequate for accurately extracting target edges under low contrast
and high noise. In this paper, we propose a novel Dual-Path Edge Network that
explicitly addresses this challenge by decoupling edge enhancement and semantic
modeling into two complementary processing paths. The first path employs a
Bidirectional Interaction Module, which uses both Local Self-Attention and
Global Self-Attention to capture multi-scale local and global feature
dependencies. The global attention mechanism, based on a Transformer
architecture, integrates long-range semantic relationships and contextual
information, ensuring robust scene understanding. The second path introduces
the Multi-Edge Refiner, which enhances fine-grained edge details using cascaded
Taylor finite difference operators at multiple scales. This mathematical
approach, along with an attention-driven gating mechanism, enables precise edge
localization and feature enhancement for targets of varying sizes, while
effectively suppressing noise. Our method provides a promising solution for
precise infrared small target detection and localization, combining structural
semantics and edge refinement in a unified framework.

</details>


### [18] [Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset](https://arxiv.org/abs/2509.20715)
*Ruixu Zhang,Yuran Wang,Xinyi Hu,Chaoyu Mai,Wenxuan Liu,Danni Xu,Xian Zhong,Zheng Wang*

Main category: cs.CV

TL;DR: 本文提出了群体意图预测（GIF）这一新任务，并构建了首个大规模数据集SHOT和相应的预测框架GIFT，用于在集体目标显现前通过个体行为和交互来预测群体意图的出现。


<details>
  <summary>Details</summary>
Motivation: 传统意图识别主要关注个体意图，忽略了群体环境中集体意图的复杂性。为此，作者提出群体意图的概念，旨在捕捉多个人协同行动中涌现的共享目标。

Method: 提出SHOT数据集，包含1979个五视角篮球视频片段，标注6类个体属性；设计GIFT框架，提取细粒度个体特征并建模动态群体关系以预测群体意图的形成。

Result: 实验结果表明，SHOT数据集和GIFT框架在群体意图预测任务上具有有效性，为该领域研究奠定了基础。

Conclusion: 群体意图预测是一个有前景的新方向，SHOT和GIFT为研究群体协作中的意图涌现提供了重要工具和方法。

Abstract: Intention recognition has traditionally focused on individual intentions,
overlooking the complexities of collective intentions in group settings. To
address this limitation, we introduce the concept of group intention, which
represents shared goals emerging through the actions of multiple individuals,
and Group Intention Forecasting (GIF), a novel task that forecasts when group
intentions will occur by analyzing individual actions and interactions before
the collective goal becomes apparent. To investigate GIF in a specific
scenario, we propose SHOT, the first large-scale dataset for GIF, consisting of
1,979 basketball video clips captured from 5 camera views and annotated with 6
types of individual attributes. SHOT is designed with 3 key characteristics:
multi-individual information, multi-view adaptability, and multi-level
intention, making it well-suited for studying emerging group intentions.
Furthermore, we introduce GIFT (Group Intention ForecasTer), a framework that
extracts fine-grained individual features and models evolving group dynamics to
forecast intention emergence. Experimental results confirm the effectiveness of
SHOT and GIFT, establishing a strong foundation for future research in group
intention forecasting. The dataset is available at
https://xinyi-hu.github.io/SHOT_DATASET.

</details>


### [19] [Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection](https://arxiv.org/abs/2509.20745)
*Yu Guo,Shengfeng He,Yuxu Lu,Haonan An,Yihang Tao,Huilin Zhu,Jingxian Liu,Yuguang Fang*

Main category: cs.CV

TL;DR: 提出Neptune-X，一个数据驱动的生成-选择框架，通过多模态条件生成模型X-to-Maritime和属性相关主动采样策略提升海上目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决海上目标检测中注释数据稀缺和跨场景泛化能力差的问题，特别是在开放海域等代表性不足的环境中。

Method: 开发了X-to-Maritime生成模型，引入双向物体-水体注意力机制以增强视觉真实感，并结合属性相关主动采样策略筛选任务相关的合成样本。

Result: 在广泛的实验中显著提升了检测精度，尤其在挑战性和代表性不足的场景下表现突出，并构建了首个面向生成式海上学习的数据集Maritime Generation Dataset。

Conclusion: Neptune-X通过合成数据生成与智能样本选择，有效增强了海上目标检测模型的训练效果和泛化能力。

Abstract: Maritime object detection is essential for navigation safety, surveillance,
and autonomous operations, yet constrained by two key challenges: the scarcity
of annotated maritime data and poor generalization across various maritime
attributes (e.g., object category, viewpoint, location, and imaging
environment). % In particular, models trained on existing datasets often
underperform in underrepresented scenarios such as open-sea environments. To
address these challenges, we propose Neptune-X, a data-centric
generative-selection framework that enhances training effectiveness by
leveraging synthetic data generation with task-aware sample selection. From the
generation perspective, we develop X-to-Maritime, a multi-modality-conditioned
generative model that synthesizes diverse and realistic maritime scenes. A key
component is the Bidirectional Object-Water Attention module, which captures
boundary interactions between objects and their aquatic surroundings to improve
visual fidelity. To further improve downstream tasking performance, we propose
Attribute-correlated Active Sampling, which dynamically selects synthetic
samples based on their task relevance. To support robust benchmarking, we
construct the Maritime Generation Dataset, the first dataset tailored for
generative maritime learning, encompassing a wide range of semantic conditions.
Extensive experiments demonstrate that our approach sets a new benchmark in
maritime scene synthesis, significantly improving detection accuracy,
particularly in challenging and previously underrepresented settings.The code
is available at https://github.com/gy65896/Neptune-X.

</details>


### [20] [AI-Enabled Crater-Based Navigation for Lunar Mapping](https://arxiv.org/abs/2509.20748)
*Sofia McLeod,Chee-Kheng Chng,Matthew Rodda,Tat-Jun Chin*

Main category: cs.CV

TL;DR: 本文提出了STELLA，首个用于长期月球测绘任务的基于陨石坑导航（CBN）端到端管道，并发布了模拟全年测绘任务的公开数据集CRESENT-365，实验表明STELLA在多种条件下均能实现米级定位和亚度级姿态精度。


<details>
  <summary>Details</summary>
Motivation: 传统CBN主要研究着陆阶段的短时、近距、光照良好的场景，而长期月球测绘任务面临稀疏、倾斜、多变光照等挑战，需更鲁棒的导航方法。

Method: STELLA结合了基于Mask R-CNN的陨石坑检测器、无描述符陨石坑识别模块、鲁棒的PnC位姿求解器和批量轨道确定后端，并在CRESENT-365数据集上进行验证。

Result: 在CRESENT+和CRESENT-365数据集上，STELLA在不同视角、光照和纬度下平均实现米级位置精度和亚度级姿态精度。

Conclusion: 这是首次在真实月球测绘场景下对CBN进行全面评估，结果为未来任务的操作条件提供了重要参考。

Abstract: Crater-Based Navigation (CBN) uses the ubiquitous impact craters of the Moon
observed on images as natural landmarks to determine the six degrees of freedom
pose of a spacecraft. To date, CBN has primarily been studied in the context of
powered descent and landing. These missions are typically short in duration,
with high-frequency imagery captured from a nadir viewpoint over well-lit
terrain. In contrast, lunar mapping missions involve sparse, oblique imagery
acquired under varying illumination conditions over potentially year-long
campaigns, posing significantly greater challenges for pose estimation. We
bridge this gap with STELLA - the first end-to-end CBN pipeline for
long-duration lunar mapping. STELLA combines a Mask R-CNN-based crater
detector, a descriptor-less crater identification module, a robust
perspective-n-crater pose solver, and a batch orbit determination back-end. To
rigorously test STELLA, we introduce CRESENT-365 - the first public dataset
that emulates a year-long lunar mapping mission. Each of its 15,283 images is
rendered from high-resolution digital elevation models with SPICE-derived Sun
angles and Moon motion, delivering realistic global coverage, illumination
cycles, and viewing geometries. Experiments on CRESENT+ and CRESENT-365 show
that STELLA maintains metre-level position accuracy and sub-degree attitude
accuracy on average across wide ranges of viewing angles, illumination
conditions, and lunar latitudes. These results constitute the first
comprehensive assessment of CBN in a true lunar mapping setting and inform
operational conditions that should be considered for future missions.

</details>


### [21] [Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models](https://arxiv.org/abs/2509.20751)
*Zoe Wanying He,Sean Trott,Meenakshi Khosla*

Main category: cs.CV

TL;DR: 研究表明，尽管深度视觉和语言模型在独立模态上训练，但它们在中后期层逐渐形成部分对齐的语义表征空间，这种对齐具有语义敏感性，并与人类在多对多图文匹配中的偏好一致，且通过示例聚合进一步增强。


<details>
  <summary>Details</summary>
Motivation: 探究单模态模型（视觉和语言）为何能在无跨模态训练的情况下形成对齐表征，明确对齐出现的位置、依赖的线索、是否反映人类偏好，以及概念示例聚合对对齐的影响。

Method: 分析视觉和语言单模态模型各层的表征对齐程度；测试对齐对语义和外观变化的鲁棒性；设计‘Pick-a-Pic’强制选择任务，评估模型嵌入空间与人类在多对多图文匹配中偏好的一致性；研究平均化多个示例嵌入对对齐的影响。

Result: 发现对齐在两种模型的中后期层达到峰值，表明从模态特定向共享概念表征的转变；对齐对外观变化鲁棒，但在语义改变时崩溃，说明其本质是语义性的；‘Pick-a-Pic’任务显示模型嵌入空间与人类偏好高度一致，且在多 caption 对单图场景中双向成立；平均多个示例的嵌入反而增强对齐而非模糊细节。

Conclusion: 单模态视觉和语言模型自发收敛于一个共享的语义编码空间，该空间不仅具有语义基础，还能反映人类在复杂图文匹配中的判断，且通过示例聚合进一步强化对齐，揭示了模型间深层语义一致性的潜力。

Abstract: Recent studies show that deep vision-only and language-only models--trained
on disjoint modalities--nonetheless project their inputs into a partially
aligned representational space. Yet we still lack a clear picture of where in
each network this convergence emerges, what visual or linguistic cues support
it, whether it captures human preferences in many-to-many image-text scenarios,
and how aggregating exemplars of the same concept affects alignment. Here, we
systematically investigate these questions. We find that alignment peaks in
mid-to-late layers of both model types, reflecting a shift from
modality-specific to conceptually shared representations. This alignment is
robust to appearance-only changes but collapses when semantics are altered
(e.g., object removal or word-order scrambling), highlighting that the shared
code is truly semantic. Moving beyond the one-to-one image-caption paradigm, a
forced-choice "Pick-a-Pic" task shows that human preferences for image-caption
matches are mirrored in the embedding spaces across all vision-language model
pairs. This pattern holds bidirectionally when multiple captions correspond to
a single image, demonstrating that models capture fine-grained semantic
distinctions akin to human judgments. Surprisingly, averaging embeddings across
exemplars amplifies alignment rather than blurring detail. Together, our
results demonstrate that unimodal networks converge on a shared semantic code
that aligns with human judgments and strengthens with exemplar aggregation.

</details>


### [22] [FreeInsert: Personalized Object Insertion with Geometric and Style Control](https://arxiv.org/abs/2509.20756)
*Yuhong Zhang,Han Wang,Yiwen Wang,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: 提出了一种无需训练的框架FreeInsert，通过利用3D几何信息实现对象在任意场景中的定制化插入，解决了图像编辑中几何控制不足和风格不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑方法在个性化图像合成任务中存在几何控制不足和风格一致性差的问题，且缺乏无需大量训练即可插入对象的有效方法。

Method: 利用现有的3D生成模型将2D对象转换为3D，在3D层面进行交互式编辑后，从指定视角重新渲染为2D图像，并结合扩散适配器实现风格和内容控制。

Result: 实现了几何可控、风格一致的图像编辑效果，能够在无需训练的情况下完成高质量的对象插入。

Conclusion: FreeInsert框架有效提升了文本到图像扩散模型在个性化图像编辑中的性能，特别是在几何控制和风格一致性方面表现突出。

Abstract: Text-to-image diffusion models have made significant progress in image
generation, allowing for effortless customized generation. However, existing
image editing methods still face certain limitations when dealing with
personalized image composition tasks. First, there is the issue of lack of
geometric control over the inserted objects. Current methods are confined to 2D
space and typically rely on textual instructions, making it challenging to
maintain precise geometric control over the objects. Second, there is the
challenge of style consistency. Existing methods often overlook the style
consistency between the inserted object and the background, resulting in a lack
of realism. In addition, the challenge of inserting objects into images without
extensive training remains significant. To address these issues, we propose
\textit{FreeInsert}, a novel training-free framework that customizes object
insertion into arbitrary scenes by leveraging 3D geometric information.
Benefiting from the advances in existing 3D generation models, we first convert
the 2D object into 3D, perform interactive editing at the 3D level, and then
re-render it into a 2D image from a specified view. This process introduces
geometric controls such as shape or view. The rendered image, serving as
geometric control, is combined with style and content control achieved through
diffusion adapters, ultimately producing geometrically controlled,
style-consistent edited images via the diffusion model.

</details>


### [23] [CusEnhancer: A Zero-Shot Scene and Controllability Enhancement Method for Photo Customization via ResInversion](https://arxiv.org/abs/2509.20775)
*Maoye Ren,Praneetha Vaddamanu,Jianjin Xu,Fernando De la Torre Frade*

Main category: cs.CV

TL;DR: 提出CustomEnhancer框架，通过零样本增强和ResInversion方法，在提升文本到图像生成中人物身份定制的场景多样性、身份保真度和控制性的同时，大幅提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在人物合成中存在场景退化、控制不足和身份保真度不高的问题，需提升个性化生成的质量与灵活性。

Method: 提出CustomEnhancer框架，结合人脸交换技术和预训练扩散模型，采用三流融合的PerGeneration方法统一生成与重建过程；引入ResInversion进行噪声校正，显著加速逆过程。

Result: 在无需训练的情况下实现对个性化模型的精细控制，显著提升场景多样性与身份一致性，ResInversion比NTI快129倍，整体达到SOTA性能。

Conclusion: CustomEnhancer为身份定制扩散模型提供了高效、可控且高质量的零样本增强方案，ResInversion显著提升了逆过程效率，具有广泛适用潜力。

Abstract: Recently remarkable progress has been made in synthesizing realistic human
photos using text-to-image diffusion models. However, current approaches face
degraded scenes, insufficient control, and suboptimal perceptual identity. We
introduce CustomEnhancer, a novel framework to augment existing identity
customization models. CustomEnhancer is a zero-shot enhancement pipeline that
leverages face swapping techniques, pretrained diffusion model, to obtain
additional representations in a zeroshot manner for encoding into personalized
models. Through our proposed triple-flow fused PerGeneration approach, which
identifies and combines two compatible counter-directional latent spaces to
manipulate a pivotal space of personalized model, we unify the generation and
reconstruction processes, realizing generation from three flows. Our pipeline
also enables comprehensive training-free control over the generation process of
personalized models, offering precise controlled personalization for them and
eliminating the need for controller retraining for per-model. Besides, to
address the high time complexity of null-text inversion (NTI), we introduce
ResInversion, a novel inversion method that performs noise rectification via a
pre-diffusion mechanism, reducing the inversion time by 129 times. Experiments
demonstrate that CustomEnhancer reach SOTA results at scene diversity, identity
fidelity, training-free controls, while also showing the efficiency of our
ResInversion over NTI. The code will be made publicly available upon paper
acceptance.

</details>


### [24] [CompressAI-Vision: Open-source software to evaluate compression methods for computer vision tasks](https://arxiv.org/abs/2509.20777)
*Hyomin Choi,Heeji Han,Chris Rosewarne,Fabien Racapé*

Main category: cs.CV

TL;DR: CompressAI-Vision是一个面向计算机视觉任务优化的视频压缩评估平台，支持远程和分割推理场景，集成标准编解码器，已在MPEG的FCM标准开发中被采用，并开源发布。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络在计算机视觉中的广泛应用，需要一个统一平台来评估针对视觉任务优化的压缩技术。

Method: 提出CompressAI-Vision平台，整合多种编码工具和标准编解码器，在不同推理场景下评估压缩效率与任务准确率的权衡。

Result: 平台展示了在多个数据集上压缩性能的增益，并被MPEG用于Feature Coding for Machines (FCM)标准的制定。

Conclusion: CompressAI-Vision为面向机器视觉的压缩技术提供了开放、标准化的评估框架，推动了该领域的研究与标准化进程。

Abstract: With the increasing use of neural network (NN)-based computer vision
applications that process image and video data as input, interest has emerged
in video compression technology optimized for computer vision tasks. In fact,
given the variety of vision tasks, associated NN models and datasets, a
consolidated platform is needed as a common ground to implement and evaluate
compression methods optimized for downstream vision tasks. CompressAI-Vision is
introduced as a comprehensive evaluation platform where new coding tools
compete to efficiently compress the input of vision network while retaining
task accuracy in the context of two different inference scenarios: "remote" and
"split" inferencing. Our study showcases various use cases of the evaluation
platform incorporated with standard codecs (under development) by examining the
compression gain on several datasets in terms of bit-rate versus task accuracy.
This evaluation platform has been developed as open-source software and is
adopted by the Moving Pictures Experts Group (MPEG) for the development the
Feature Coding for Machines (FCM) standard. The software is available publicly
at https://github.com/InterDigitalInc/CompressAI-Vision.

</details>


### [25] [Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization](https://arxiv.org/abs/2509.20785)
*Jincai Song,Haipeng Chen,Jun Qin,Na Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种用于医学图像分割中跨域半监督域泛化的双监督非对称协同训练（DAC）框架，通过特征级监督和非对称自监督任务提升模型在标签与无标签数据存在域偏移时的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统半监督域泛化方法假设每个源域均有标注和未标注数据，但在实际中这一条件常不成立。本文针对训练集中标注与未标注数据之间也存在域偏移的更现实场景（CD-SSDG）展开研究。

Method: 提出双监督非对称协同训练（DAC）框架，基于协同训练机制，引入两个子模型进行互伪标签监督，并结合特征级监督和不同的自监督辅助任务，以缓解因域偏移导致的伪标签不准问题，增强域不变特征学习。

Result: 在真实医学图像数据集（Fundus、Polyp、SCGM）上的实验表明，所提DAC框架显著优于现有方法，展现出更强的鲁棒性和泛化能力。

Conclusion: DAC框架有效应对了跨域半监督域泛化中的挑战，特别是在标签与无标签数据存在域偏移的情况下，提升了医学图像分割的性能与实用性。

Abstract: Semi-supervised domain generalization (SSDG) in medical image segmentation
offers a promising solution for generalizing to unseen domains during testing,
addressing domain shift challenges and minimizing annotation costs. However,
conventional SSDG methods assume labeled and unlabeled data are available for
each source domain in the training set, a condition that is not always met in
practice. The coexistence of limited annotation and domain shift in the
training set is a prevalent issue. Thus, this paper explores a more practical
and challenging scenario, cross-domain semi-supervised domain generalization
(CD-SSDG), where domain shifts occur between labeled and unlabeled training
data, in addition to shifts between training and testing sets. Existing SSDG
methods exhibit sub-optimal performance under such domain shifts because of
inaccurate pseudolabels. To address this issue, we propose a novel
dual-supervised asymmetric co-training (DAC) framework tailored for CD-SSDG.
Building upon the co-training paradigm with two sub-models offering cross
pseudo supervision, our DAC framework integrates extra feature-level
supervision and asymmetric auxiliary tasks for each sub-model. This
feature-level supervision serves to address inaccurate pseudo supervision
caused by domain shifts between labeled and unlabeled data, utilizing
complementary supervision from the rich feature space. Additionally, two
distinct auxiliary self-supervised tasks are integrated into each sub-model to
enhance domain-invariant discriminative feature learning and prevent model
collapse. Extensive experiments on real-world medical image segmentation
datasets, i.e., Fundus, Polyp, and SCGM, demonstrate the robust
generalizability of the proposed DAC framework.

</details>


### [26] [Real-Time Object Detection Meets DINOv3](https://arxiv.org/abs/2509.20787)
*Shihua Huang,Yongjie Hou,Longfei Liu,Xuanlong Yu,Xi Shen*

Main category: cs.CV

TL;DR: DEIMv2 是一种基于 DINOv3 特征的实时目标检测框架，扩展了 DEIM，在多个模型尺寸上实现了卓越的性能-成本权衡，显著优于 YOLO 系列。


<details>
  <summary>Details</summary>
Motivation: 为了进一步提升实时 DETR 框架的性能与效率，尤其是在不同硬件平台上的适应性，同时突破现有模型在参数量和精度之间的瓶颈。

Method: 采用 DINOv3 预训练或蒸馏的主干网络，并引入空间调优适配器（STA）以生成多尺度特征；对于超轻量级模型使用 HGNetv2 结合深度宽度剪枝；结合简化解码器和升级版 Dense O2O 设计。

Result: DEIMv2-X 达到 57.8 AP（仅 5030 万参数），DEIMv2-S 以 971 万参数实现 50.9 AP，DEIMv2-Pico 以 150 万参数达到 38.5 AP，均优于同类模型。

Conclusion: DEIMv2 在广泛的应用场景中建立了新的 SOTA，兼具高性能与高效部署能力，是首个在多种规模上全面超越 YOLO 系列的 DETR 框架。

Abstract: Benefiting from the simplicity and effectiveness of Dense O2O and MAL, DEIM
has become the mainstream training framework for real-time DETRs, significantly
outperforming the YOLO series. In this work, we extend it with DINOv3 features,
resulting in DEIMv2. DEIMv2 spans eight model sizes from X to Atto, covering
GPU, edge, and mobile deployment. For the X, L, M, and S variants, we adopt
DINOv3-pretrained or distilled backbones and introduce a Spatial Tuning Adapter
(STA), which efficiently converts DINOv3's single-scale output into multi-scale
features and complements strong semantics with fine-grained details to enhance
detection. For ultra-lightweight models (Nano, Pico, Femto, and Atto), we
employ HGNetv2 with depth and width pruning to meet strict resource budgets.
Together with a simplified decoder and an upgraded Dense O2O, this unified
design enables DEIMv2 to achieve a superior performance-cost trade-off across
diverse scenarios, establishing new state-of-the-art results. Notably, our
largest model, DEIMv2-X, achieves 57.8 AP with only 50.3 million parameters,
surpassing prior X-scale models that require over 60 million parameters for
just 56.5 AP. On the compact side, DEIMv2-S is the first sub-10 million model
(9.71 million) to exceed the 50 AP milestone on COCO, reaching 50.9 AP. Even
the ultra-lightweight DEIMv2-Pico, with just 1.5 million parameters, delivers
38.5 AP, matching YOLOv10-Nano (2.3 million) with around 50 percent fewer
parameters.

</details>


### [27] [DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation](https://arxiv.org/abs/2509.20792)
*Ved Umrajkar*

Main category: cs.CV

TL;DR: 提出DAC-LoRA框架，通过结合对抗训练与参数高效微调（PEFT），提升视觉语言模型在面对对抗攻击时的鲁棒性，同时保持清洁数据上的准确性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在安全关键应用中易受对抗攻击，尤其是基于CLIP的模型，其脆弱性可能影响整个多模态AI系统，因此需要一种高效且鲁棒的微调方法。

Method: 提出DAC-LoRA，引入基于一阶平稳条件（FOSC）和TRADES启发的损失函数的动态对抗课程，逐步增强攻击难度，在PEFT过程中集成对抗训练。

Result: DAC-LoRA显著提升了模型的对抗鲁棒性，同时未明显降低干净样本上的准确率，且可轻松集成到标准PEFT流程中。

Conclusion: DAC-LoRA是一种有效、轻量且广泛适用的框架，能够在不牺牲性能的前提下增强VLMs在安全关键场景中的鲁棒性。

Abstract: Vision-Language Models (VLMs) are foundational to critical applications like
autonomous driving, medical diagnosis, and content moderation. While
Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA enable their efficient
adaptation to specialized tasks, these models remain vulnerable to adversarial
attacks that can compromise safety-critical decisions. CLIP, the backbone for
numerous downstream VLMs, is a high-value target whose vulnerabilities can
cascade across the multimodal AI ecosystem. We propose Dynamic Adversarial
Curriculum DAC-LoRA, a novel framework that integrates adversarial training
into PEFT. The core principle of our method i.e. an intelligent curriculum of
progressively challenging attack, is general and can potentially be applied to
any iterative attack method. Guided by the First-Order Stationary Condition
(FOSC) and a TRADES-inspired loss, DAC-LoRA achieves substantial improvements
in adversarial robustness without significantly compromising clean accuracy.
Our work presents an effective, lightweight, and broadly applicable method to
demonstrate that the DAC-LoRA framework can be easily integrated into a
standard PEFT pipeline to significantly enhance robustness.

</details>


### [28] [Federated Domain Generalization with Domain-specific Soft Prompts Generation](https://arxiv.org/abs/2509.20807)
*Jianhan Wu,Xiaoyang Qu,Zhangcheng Huang,Jianzong Wang*

Main category: cs.CV

TL;DR: 提出了一种基于生成式域特定软提示（FedDSPG）的联邦域泛化方法，通过在训练中引入域特定软提示并融合内容与域知识，在多个公开数据集上实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示学习的联邦域泛化方法生成的软提示多样性不足，且忽略未知域信息，导致泛化能力受限。

Method: 提出FedDSPG方法，在训练阶段为各域引入域特定软提示（DSPs），并在客户端间构建融合内容与域知识的生成模型；在推理阶段利用生成器为未见目标域生成DSPs，以指导下游任务。

Result: 在多个公共数据集上的实验表明，该方法在联邦域泛化任务中优于现有的强基线方法，达到最先进的性能。

Conclusion: FedDSPG通过生成式方法有效提升软提示的多样性与跨域适应能力，显著增强了联邦学习中的域泛化性能。

Abstract: Prompt learning has become an efficient paradigm for adapting CLIP to
downstream tasks. Compared with traditional fine-tuning, prompt learning
optimizes a few parameters yet yields highly competitive results, especially
appealing in federated learning for computational efficiency. engendering
domain shift among clients and posing a formidable challenge for
downstream-task adaptation. Existing federated domain generalization (FDG)
methods based on prompt learning typically learn soft prompts from training
samples, replacing manually designed prompts to enhance the generalization
ability of federated models. However, these learned prompts exhibit limited
diversity and tend to ignore information from unknown domains. We propose a
novel and effective method from a generative perspective for handling FDG
tasks, namely federated domain generalization with domain-specific soft prompts
generation (FedDSPG). Specifically, during training, we introduce
domain-specific soft prompts (DSPs) for each domain and integrate content and
domain knowledge into the generative model among clients. In the inference
phase, the generator is utilized to obtain DSPs for unseen target domains, thus
guiding downstream tasks in unknown domains. Comprehensive evaluations across
several public datasets confirm that our method outperforms existing strong
baselines in FDG, achieving state-of-the-art results.

</details>


### [29] [Revolutionizing Precise Low Back Pain Diagnosis via Contrastive Learning](https://arxiv.org/abs/2509.20813)
*Thanh Binh Le,Hoang Nhat Khang Vo,Tan-Ha Mai,Trong Nhan Phan*

Main category: cs.CV

TL;DR: LumbarCLIP 是一种基于对比语言-图像预训练的多模态框架，用于对齐腰椎MRI图像与放射学文本描述，在分类任务中达到95.00%准确率。


<details>
  <summary>Details</summary>
Motivation: 低背痛全球普遍，需要能联合分析医学影像和文本报告的诊断模型。

Method: 采用ResNet-50、ViT、Swin Transformer等视觉编码器与BERT文本编码器，通过可学习的投影头将特征映射到共享嵌入空间，使用软CLIP损失进行对比训练。

Result: 在测试集上最高达到95.00%准确率和94.75% F1分数，线性投影头优于非线性变体。

Conclusion: LumbarCLIP为自动化肌肉骨骼诊断和临床决策支持提供了有力基础。

Abstract: Low back pain affects millions worldwide, driving the need for robust
diagnostic models that can jointly analyze complex medical images and
accompanying text reports. We present LumbarCLIP, a novel multimodal framework
that leverages contrastive language-image pretraining to align lumbar spine MRI
scans with corresponding radiological descriptions. Built upon a curated
dataset containing axial MRI views paired with expert-written reports,
LumbarCLIP integrates vision encoders (ResNet-50, Vision Transformer, Swin
Transformer) with a BERT-based text encoder to extract dense representations.
These are projected into a shared embedding space via learnable projection
heads, configurable as linear or non-linear, and normalized to facilitate
stable contrastive training using a soft CLIP loss. Our model achieves
state-of-the-art performance on downstream classification, reaching up to
95.00% accuracy and 94.75% F1-score on the test set, despite inherent class
imbalance. Extensive ablation studies demonstrate that linear projection heads
yield more effective cross-modal alignment than non-linear variants. LumbarCLIP
offers a promising foundation for automated musculoskeletal diagnosis and
clinical decision support.

</details>


### [30] [Poisoning Prompt-Guided Sampling in Video Large Language Models](https://arxiv.org/abs/2509.20851)
*Yuxin Cao,Wei Song,Jingling Xue,Jin Song Dong*

Main category: cs.CV

TL;DR: 本文提出了PoisonVID，首个针对视频大语言模型中提示引导采样机制的黑盒中毒攻击，通过闭合循环优化策略生成通用扰动，有效抑制有害帧的相关性得分，在三种先进视频大语言模型和多种提示引导采样策略上实现了82%至99%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 尽管早期帧采样策略已发现存在漏洞，但提示引导采样在视频大语言模型中的安全性尚未被探索，因此需要研究其潜在威胁。

Method: 提出PoisonVID，采用闭合循环优化策略，利用影子视频大语言模型和轻量级语言模型（如GPT-4o-mini）构建描述集，迭代优化通用扰动以抑制有害帧的相关性得分。

Result: 在三种提示引导采样策略和三个先进视频大语言模型上全面评估，PoisonVID实现了82%到99%的攻击成功率。

Conclusion: 提示引导采样机制存在严重安全漏洞，PoisonVID揭示了当前方法的脆弱性，强调未来需开发更先进的采样策略以提升视频大语言模型的安全性。

Abstract: Video Large Language Models (VideoLLMs) have emerged as powerful tools for
understanding videos, supporting tasks such as summarization, captioning, and
question answering. Their performance has been driven by advances in frame
sampling, progressing from uniform-based to semantic-similarity-based and, most
recently, prompt-guided strategies. While vulnerabilities have been identified
in earlier sampling strategies, the safety of prompt-guided sampling remains
unexplored. We close this gap by presenting PoisonVID, the first black-box
poisoning attack that undermines prompt-guided sampling in VideoLLMs. PoisonVID
compromises the underlying prompt-guided sampling mechanism through a
closed-loop optimization strategy that iteratively optimizes a universal
perturbation to suppress harmful frame relevance scores, guided by a depiction
set constructed from paraphrased harmful descriptions leveraging a shadow
VideoLLM and a lightweight language model, i.e., GPT-4o-mini. Comprehensively
evaluated on three prompt-guided sampling strategies and across three advanced
VideoLLMs, PoisonVID achieves 82% - 99% attack success rate, highlighting the
importance of developing future advanced sampling strategies for VideoLLMs.

</details>


### [31] [Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer](https://arxiv.org/abs/2509.20854)
*Abdur Rehman,S M A Sharif,Md Abdur Rahaman,Mohamed Jismy Aashik Rasool,Seongwan Kim,Jaeho Lee*

Main category: cs.CV

TL;DR: 提出了一种名为Game of Regularizer (GoR) 的可学习正则化方法，通过两个可训练参数动态平衡任务特定和知识蒸馏损失，显著提升低比特量化模型性能，并结合集成蒸馏框架QAT-EKD-GoR实现超越全精度模型的表现。


<details>
  <summary>Details</summary>
Motivation: 现有量化感知训练与知识蒸馏（QAT-KD）方法在低比特量化下难以平衡任务特定损失和蒸馏损失，因梯度幅值差异导致优化冲突。

Method: 提出GoR，利用两个可学习参数自适应调整损失权重，减少监督信号间的冲突；并引入QAT-EKD-GoR框架，结合多个异构教师模型进行集成蒸馏。

Result: 在图像分类、目标检测和大语言模型压缩任务中，GoR consistently 超越现有QAT-KD方法；在边缘设备上实现更快推理速度同时保持全精度准确性，EKD-GoR在最优条件下甚至优于全精度模型。

Conclusion: GoR为小规模量化模型提供了一种高效、轻量且鲁棒的优化方案，有效解决多目标损失不平衡问题，推动AI模型在资源受限设备上的高性能部署。

Abstract: Quantization-aware training (QAT) combined with knowledge distillation (KD)
is a promising strategy for compressing Artificial Intelligence (AI) models for
deployment on resource-constrained hardware. However, existing QAT-KD methods
often struggle to balance task-specific (TS) and distillation losses due to
heterogeneous gradient magnitudes, especially under low-bit quantization. We
propose Game of Regularizer (GoR), a novel learnable regularization method that
adaptively balances TS and KD objectives using only two trainable parameters
for dynamic loss weighting. GoR reduces conflict between supervision signals,
improves convergence, and boosts the performance of small quantized models
(SQMs). Experiments on image classification, object detection (OD), and large
language model (LLM) compression show that GoR consistently outperforms
state-of-the-art QAT-KD methods. On low-power edge devices, it delivers faster
inference while maintaining full-precision accuracy. We also introduce
QAT-EKD-GoR, an ensemble distillation framework that uses multiple
heterogeneous teacher models. Under optimal conditions, the proposed EKD-GoR
can outperform full-precision models, providing a robust solution for
real-world deployment.

</details>


### [32] [Plant identification based on noisy web data: the amazing performance of deep learning (LifeCLEF 2017)](https://arxiv.org/abs/2509.20856)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2017植物识别挑战赛评估了大规模网络采集的含噪声数据集与小规模专家标注数据集在植物识别任务中的性能对比，使用Pl@ntNet应用的数据作为测试集。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量植物图像资源，但多数物种仍缺乏或仅有少量图片；同时，网络上存在大量非结构化、标签不准确的植物图像，如何有效利用这些噪声数据成为关键问题。

Method: 通过比较基于大规模网络爬取的含噪声训练数据和小规模专家验证数据的模型性能，使用独立来源的Pl@ntNet移动应用图像作为测试集进行公平评估。

Result: 挑战赛吸引了多个研究团队参与，结果揭示了噪声数据在大规模植物识别任务中的潜力与局限性，部分方法在噪声数据下仍表现出较强鲁棒性。

Conclusion: 大规模网络采集的噪声数据在特定条件下可与专家标注数据相媲美，但数据质量控制和模型鲁棒性设计至关重要。

Abstract: The 2017-th edition of the LifeCLEF plant identification challenge is an
important milestone towards automated plant identification systems working at
the scale of continental floras with 10.000 plant species living mainly in
Europe and North America illustrated by a total of 1.1M images. Nowadays, such
ambitious systems are enabled thanks to the conjunction of the dazzling recent
progress in image classification with deep learning and several outstanding
international initiatives, such as the Encyclopedia of Life (EOL), aggregating
the visual knowledge on plant species coming from the main national botany
institutes. However, despite all these efforts the majority of the plant
species still remain without pictures or are poorly illustrated. Outside the
institutional channels, a much larger number of plant pictures are available
and spread on the web through botanist blogs, plant lovers web-pages, image
hosting websites and on-line plant retailers. The LifeCLEF 2017 plant challenge
presented in this paper aimed at evaluating to what extent a large noisy
training dataset collected through the web and containing a lot of labelling
errors can compete with a smaller but trusted training dataset checked by
experts. To fairly compare both training strategies, the test dataset was
created from a third data source, i.e. the Pl@ntNet mobile application that
collects millions of plant image queries all over the world. This paper
presents more precisely the resources and assessments of the challenge,
summarizes the approaches and systems employed by the participating research
groups, and provides an analysis of the main outcomes.

</details>


### [33] [TasselNetV4: A vision foundation model for cross-scene, cross-scale, and cross-species plant counting](https://arxiv.org/abs/2509.20857)
*Xiaonan Hu,Xuebing Li,Jinyu Xu,Abdulkadir Duran Adan,Letian Zhou,Xuhui Zhu,Yanan Li,Wei Guo,Shouyang Liu,Wenzhong Liu,Hao Lu*

Main category: cs.CV

TL;DR: 本文提出TasselNetV4，一种基于视觉Transformer的跨物种植物计数模型，结合局部计数与提取-匹配范式，提升跨场景、跨尺度和跨物种的鲁棒性，并在新构建的数据集PAC-105和PAC-Somalia上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统植物计数模型多为物种特异性，难以应对植物多样性及新品种不断涌现的问题；现有类无关计数方法在处理非刚性、时空变化大的植物时表现不佳，因此需要重新思考植物计数的问题设定。

Method: 继承TasselNet的局部计数思想，引入类无关计数中的提取-匹配范式，采用纯视觉Transformer架构，并设计多分支盒感知局部计数器以增强跨尺度鲁棒性。

Result: 在PAC-105和PAC-Somalia两个新构建的数据集上，TasselNetV4在计数精度和效率方面均优于当前最先进的类无关计数模型。

Conclusion: TasselNetV4实现了从物种特异性到跨物种植物计数的转变，展现出作为跨场景、跨尺度、跨物种植物计数视觉基础模型的潜力。

Abstract: Accurate plant counting provides valuable information for agriculture such as
crop yield prediction, plant density assessment, and phenotype quantification.
Vision-based approaches are currently the mainstream solution. Prior art
typically uses a detection or a regression model to count a specific plant.
However, plants have biodiversity, and new cultivars are increasingly bred each
year. It is almost impossible to exhaust and build all species-dependent
counting models. Inspired by class-agnostic counting (CAC) in computer vision,
we argue that it is time to rethink the problem formulation of plant counting,
from what plants to count to how to count plants. In contrast to most daily
objects with spatial and temporal invariance, plants are dynamic, changing with
time and space. Their non-rigid structure often leads to worse performance than
counting rigid instances like heads and cars such that current CAC and
open-world detection models are suboptimal to count plants. In this work, we
inherit the vein of the TasselNet plant counting model and introduce a new
extension, TasselNetV4, shifting from species-specific counting to
cross-species counting. TasselNetV4 marries the local counting idea of
TasselNet with the extract-and-match paradigm in CAC. It builds upon a plain
vision transformer and incorporates novel multi-branch box-aware local counters
used to enhance cross-scale robustness. Two challenging datasets, PAC-105 and
PAC-Somalia, are harvested. Extensive experiments against state-of-the-art CAC
models show that TasselNetV4 achieves not only superior counting performance
but also high efficiency.Our results indicate that TasselNetV4 emerges to be a
vision foundation model for cross-scene, cross-scale, and cross-species plant
counting.

</details>


### [34] [SD-RetinaNet: Topologically Constrained Semi-Supervised Retinal Lesion and Layer Segmentation in OCT](https://arxiv.org/abs/2509.20864)
*Botond Fazekas,Guilherme Aresta,Philipp Seeböck,Julia Mai,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: 提出一种新的半监督模型，通过引入完全可微分的生物标志物拓扑引擎，实现解剖学上正确的视网膜层和病变分割，显著提升了在公共和内部OCT数据集上的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督方法在视网膜OCT图像分割中常产生解剖学上不合理的结构，难以有效建模层与病变之间的相互作用，且缺乏拓扑正确性的保证。

Method: 提出一种新型半监督模型，结合完全可微分的生物标志物拓扑引擎，实现层与病变的联合学习与双向影响，并通过解耦表征分离空间与风格因素，利用未标记及部分标记数据进行训练。

Result: 在公共和内部OCT数据集上，该模型在层和病变分割任务中均优于当前最先进方法，并能在仅使用部分标注数据的情况下泛化到病理情况。

Conclusion: 将解剖约束引入半监督学习可有效提升视网膜生物标志物分割的准确性、鲁棒性和可信度。

Abstract: Optical coherence tomography (OCT) is widely used for diagnosing and
monitoring retinal diseases, such as age-related macular degeneration (AMD).
The segmentation of biomarkers such as layers and lesions is essential for
patient diagnosis and follow-up. Recently, semi-supervised learning has shown
promise in improving retinal segmentation performance. However, existing
methods often produce anatomically implausible segmentations, fail to
effectively model layer-lesion interactions, and lack guarantees on topological
correctness.
  To address these limitations, we propose a novel semi-supervised model that
introduces a fully differentiable biomarker topology engine to enforce
anatomically correct segmentation of lesions and layers. This enables joint
learning with bidirectional influence between layers and lesions, leveraging
unlabeled and diverse partially labeled datasets. Our model learns a
disentangled representation, separating spatial and style factors. This
approach enables more realistic layer segmentations and improves lesion
segmentation, while strictly enforcing lesion location in their anatomically
plausible positions relative to the segmented layers.
  We evaluate the proposed model on public and internal datasets of OCT scans
and show that it outperforms the current state-of-the-art in both lesion and
layer segmentation, while demonstrating the ability to generalize layer
segmentation to pathological cases using partially annotated training data. Our
results demonstrate the potential of using anatomical constraints in
semi-supervised learning for accurate, robust, and trustworthy retinal
biomarker segmentation.

</details>


### [35] [Plant identification in an open-world (LifeCLEF 2016)](https://arxiv.org/abs/2509.20870)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2016植物识别挑战赛评估了在大规模真实生物多样性监测场景下的植物识别方法，首次采用开放集识别任务，要求系统能有效拒绝未知物种的误分类。


<details>
  <summary>Details</summary>
Motivation: 推动植物识别技术在真实复杂环境中的应用，特别是在大规模、开放环境中对未知物种具备鲁棒性。

Method: 使用超过11万张图像覆盖西欧1000种植物，通过众包平台构建数据集，并将识别任务设为开放集识别问题，评估系统对未知类别的处理能力。

Result: 多个研究团队提交了不同识别系统，挑战揭示了现有方法在处理未知类别时的局限性，推动了拒识机制和开放集识别技术的发展。

Conclusion: 开放集识别是未来植物自动识别的关键方向，需进一步提升模型对未知物种的判别与拒识能力。

Abstract: The LifeCLEF plant identification challenge aims at evaluating plant
identification methods and systems at a very large scale, close to the
conditions of a real-world biodiversity monitoring scenario. The 2016-th
edition was actually conducted on a set of more than 110K images illustrating
1000 plant species living in West Europe, built through a large-scale
participatory sensing platform initiated in 2011 and which now involves tens of
thousands of contributors. The main novelty over the previous years is that the
identification task was evaluated as an open-set recognition problem, i.e. a
problem in which the recognition system has to be robust to unknown and never
seen categories. Beyond the brute-force classification across the known classes
of the training set, the big challenge was thus to automatically reject the
false positive classification hits that are caused by the unknown classes. This
overview presents more precisely the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [36] [SCRA-VQA: Summarized Caption-Rerank for Augmented Large Language Models in Visual Question Answering](https://arxiv.org/abs/2509.20871)
*Yan Zhang,Jiaqing Lin,Miao Zhang,Kui Xiao,Xiaoju Hou,Yue Zhao,Zhifei Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为SCRA-VQA的新方法，利用预训练的视觉语言模型生成图像描述，并通过上下文示例、摘要和重排序优化描述，提升大语言模型在知识型视觉问答任务中的推理能力，无需昂贵的端到端训练，在OK-VQA和A-OKVQA数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用图像字幕作为视觉描述，但存在噪声过多且大语言模型难以理解VQA任务的问题，限制了其推理能力。

Method: 提出SCRA-VQA框架，使用预训练视觉语言模型生成图像字幕，并通过生成上下文示例、摘要和重排序来精炼字幕，增强大语言模型对图像和问题的理解。

Result: 基于67亿参数的大语言模型，SCRA-VQA在OK-VQA和A-OKVQA数据集上分别达到38.8%和34.6%的准确率，表现出色。

Conclusion: SCRA-VQA通过优化视觉文本描述显著提升了大语言模型在KB-VQA任务中的推理能力和适应性，且无需端到端训练，具有高效性和实用性。

Abstract: Acquiring high-quality knowledge is a central focus in Knowledge-Based Visual
Question Answering (KB-VQA). Recent methods use large language models (LLMs) as
knowledge engines for answering. These methods generally employ image captions
as visual text descriptions to assist LLMs in interpreting images. However, the
captions frequently include excessive noise irrelevant to the question, and
LLMs generally do not comprehend VQA tasks, limiting their reasoning
capabilities. To address this issue, we propose the Summarized Caption-Rerank
Augmented VQA (SCRA-VQA), which employs a pre-trained visual language model to
convert images into captions. Moreover, SCRA-VQA generates contextual examples
for the captions while simultaneously summarizing and reordering them to
exclude unrelated information. The caption-rerank process enables LLMs to
understand the image information and questions better, thus enhancing the
model's reasoning ability and task adaptability without expensive end-to-end
training. Based on an LLM with 6.7B parameters, SCRA-VQA performs excellently
on two challenging knowledge-based VQA datasets: OK-VQA and A-OKVQA, achieving
accuracies of 38.8% and 34.6%. Our code is available at
https://github.com/HubuKG/SCRA-VQA.

</details>


### [37] [The Unanticipated Asymmetry Between Perceptual Optimization and Assessment](https://arxiv.org/abs/2509.20878)
*Jiabei Zhang,Qi Wang,Siyu Wu,Du Chen,Tianhe Wu*

Main category: cs.CV

TL;DR: 研究揭示了感知优化与图像质量评估（IQA）之间的非对称性：在IQA中表现优异的保真度指标不一定适用于感知优化，尤其是在对抗训练下这种不匹配更明显。


<details>
  <summary>Details</summary>
Motivation: 尽管保真度和对抗目标在感知优化中起核心作用，但它们作为优化目标的有效性与其作为图像质量评估指标的能力之间的关联尚不清楚，本文旨在系统分析这一关系。

Method: 通过系统性分析保真度和对抗性目标在感知优化与图像质量评估中的表现，并比较不同判别器结构（如patch-level、卷积、Transformer等）对细节重建的影响。

Result: 发现保真度指标在IQA中表现好并不代表其在感知优化中有效，尤其在对抗训练下存在明显错配；判别器虽能抑制伪影，但其表征对IQA模型初始化帮助有限；patch-level和卷积结构在细节重建上优于传统或Transformer架构。

Conclusion: 感知优化与图像质量评估之间存在未被充分认识的不对称性，判别器的设计对优化效果有决定性影响，这为更合理的感知损失设计和IQA迁移提供了指导。

Abstract: Perceptual optimization is primarily driven by the fidelity objective, which
enforces both semantic consistency and overall visual realism, while the
adversarial objective provides complementary refinement by enhancing perceptual
sharpness and fine-grained detail. Despite their central role, the correlation
between their effectiveness as optimization objectives and their capability as
image quality assessment (IQA) metrics remains underexplored. In this work, we
conduct a systematic analysis and reveal an unanticipated asymmetry between
perceptual optimization and assessment: fidelity metrics that excel in IQA are
not necessarily effective for perceptual optimization, with this misalignment
emerging more distinctly under adversarial training. In addition, while
discriminators effectively suppress artifacts during optimization, their
learned representations offer only limited benefits when reused as backbone
initializations for IQA models. Beyond this asymmetry, our findings further
demonstrate that discriminator design plays a decisive role in shaping
optimization, with patch-level and convolutional architectures providing more
faithful detail reconstruction than vanilla or Transformer-based alternatives.
These insights advance the understanding of loss function design and its
connection to IQA transferability, paving the way for more principled
approaches to perceptual optimization.

</details>


### [38] [Integrating Object Interaction Self-Attention and GAN-Based Debiasing for Visual Question Answering](https://arxiv.org/abs/2509.20884)
*Zhifei Li,Feng Qiu,Yiran Wang,Yujing Xia,Kui Xiao,Miao Zhang,Yan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的VQA模型IOG-VQA，结合对象交互自注意力和基于GAN的去偏方法，有效提升了在存在数据偏差情况下的视觉问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有VQA模型因训练数据偏差而过度依赖表面模式，泛化能力不足，难以应对多样化的问题和图像。

Method: 提出IOG-VQA模型，引入对象交互自注意力机制以捕捉图像中对象间的复杂交互，并采用基于GAN的去偏框架生成无偏数据分布，从而增强模型的鲁棒性和泛化能力。

Result: 在VQA-CP v1和v2数据集上的实验表明，该模型在处理有偏和不平衡数据分布时显著优于现有方法。

Conclusion: 同时建模对象交互和缓解数据偏差对提升VQA模型性能至关重要，IOG-VQA为此提供了有效解决方案。

Abstract: Visual Question Answering (VQA) presents a unique challenge by requiring
models to understand and reason about visual content to answer questions
accurately. Existing VQA models often struggle with biases introduced by the
training data, leading to over-reliance on superficial patterns and inadequate
generalization to diverse questions and images. This paper presents a novel
model, IOG-VQA, which integrates Object Interaction Self-Attention and
GAN-Based Debiasing to enhance VQA model performance. The self-attention
mechanism allows our model to capture complex interactions between objects
within an image, providing a more comprehensive understanding of the visual
context. Meanwhile, the GAN-based debiasing framework generates unbiased data
distributions, helping the model to learn more robust and generalizable
features. By leveraging these two components, IOG-VQA effectively combines
visual and textual information to address the inherent biases in VQA datasets.
Extensive experiments on the VQA-CP v1 and VQA-CP v2 datasets demonstrate that
our model shows excellent performance compared with the existing methods,
particularly in handling biased and imbalanced data distributions highlighting
the importance of addressing both object interactions and dataset biases in
advancing VQA tasks. Our code is available at
https://github.com/HubuKG/IOG-VQA.

</details>


### [39] [Nuclear Diffusion Models for Low-Rank Background Suppression in Videos](https://arxiv.org/abs/2509.20886)
*Tristan S. W. Stevens,Oisín Nolan,Jean-Luc Robert,Ruud J. G. van Sloun*

Main category: cs.CV

TL;DR: 提出了一种名为Nuclear Diffusion的混合框架，结合低秩时间建模与扩散后验采样，用于视频去噪和恢复，在心脏超声去雾任务中表现优于传统RPCA方法。


<details>
  <summary>Details</summary>
Motivation: 传统鲁棒主成分分析（RPCA）的稀疏性假设难以捕捉真实视频数据中的丰富变化，导致在复杂噪声和背景伪影下的视频恢复效果受限。

Method: 提出Nuclear Diffusion方法，将低秩时间建模与扩散模型的后验采样相结合，利用深度生成先验增强对动态内容的建模能力。

Result: 在真实心脏超声去雾任务中，相比传统RPCA方法，在对比度增强（gCNR）和信号保持（KS统计量）方面均表现出更优性能。

Conclusion: 将基于模型的时间建模与深度生成先验相结合，有望实现高保真的视频恢复，为复杂视频增强任务提供了新方向。

Abstract: Video sequences often contain structured noise and background artifacts that
obscure dynamic content, posing challenges for accurate analysis and
restoration. Robust principal component methods address this by decomposing
data into low-rank and sparse components. Still, the sparsity assumption often
fails to capture the rich variability present in real video data. To overcome
this limitation, a hybrid framework that integrates low-rank temporal modeling
with diffusion posterior sampling is proposed. The proposed method, Nuclear
Diffusion, is evaluated on a real-world medical imaging problem, namely cardiac
ultrasound dehazing, and demonstrates improved dehazing performance compared to
traditional RPCA concerning contrast enhancement (gCNR) and signal preservation
(KS statistic). These results highlight the potential of combining model-based
temporal models with deep generative priors for high-fidelity video
restoration.

</details>


### [40] [FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies](https://arxiv.org/abs/2509.20890)
*Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan*

Main category: cs.CV

TL;DR: 提出了一种基于局部像素依赖（LPD）的轻量级网络FerretNet，用于高效检测合成图像，在跨22种生成模型的开放世界基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着VAE、GAN和LDM等模型生成的合成图像越来越逼真，传统检测方法面临挑战，亟需更鲁棒的检测技术。

Method: 利用生成过程中引入的潜在分布偏差和解码平滑效应，基于马尔可夫随机场中的局部像素依赖（LPD）特性重构图像，揭示纹理和边缘不一致性，并设计轻量网络FerretNet进行检测。

Result: FerretNet仅用1.1M参数，在仅训练于4类ProGAN数据的情况下，在包含22种生成模型的开放世界基准上平均准确率达97.1%，超越现有方法10.6%。

Conclusion: FerretNet通过挖掘生成图像的局部依赖异常，实现了高效且泛化能力强的合成图像检测，具有实际应用潜力。

Abstract: The increasing realism of synthetic images generated by advanced models such
as VAEs, GANs, and LDMs poses significant challenges for synthetic image
detection. To address this issue, we explore two artifact types introduced
during the generation process: (1) latent distribution deviations and (2)
decoding-induced smoothing effects, which manifest as inconsistencies in local
textures, edges, and color transitions. Leveraging local pixel dependencies
(LPD) properties rooted in Markov Random Fields, we reconstruct synthetic
images using neighboring pixel information to expose disruptions in texture
continuity and edge coherence. Building upon LPD, we propose FerretNet, a
lightweight neural network with only 1.1M parameters that delivers efficient
and robust synthetic image detection. Extensive experiments demonstrate that
FerretNet, trained exclusively on the 4-class ProGAN dataset, achieves an
average accuracy of 97.1% on an open-world benchmark comprising across 22
generative models, surpassing state-of-the-art methods by 10.6%.

</details>


### [41] [Concepts in Motion: Temporal Bottlenecks for Interpretable Video Classification](https://arxiv.org/abs/2509.20899)
*Patrick Knab,Sascha Marton,Philipp J. Schubert,Drago Guggiana,Christian Bartelt*

Main category: cs.CV

TL;DR: 本文提出了MoTIF，一种基于Transformer架构的可解释视频分类框架，将概念瓶颈模型扩展到视频数据，通过建模时间依赖性和多尺度概念重要性，在保持竞争力性能的同时提升对动作的语义解释能力。


<details>
  <summary>Details</summary>
Motivation: 将图像中的可解释概念模型（如CBM）扩展到视频面临时间依赖性建模的挑战，而现有方法难以捕捉视频中动态行为的时间演化模式。

Method: 提出MoTIF框架，采用类Transformer架构，引入全局概念重要性、局部时间窗内概念相关性和概念的时间依赖性三种互补视角，以处理任意长度视频序列中的语义概念（如'拉弓'、'上马'等），实现对视频动作的可解释建模。

Result: 实验证明MoTIF能有效将概念瓶颈范式应用于视频分类，在多个数据集上实现了良好的可解释性，并保持了与主流方法相当的分类性能。

Conclusion: MoTIF成功地将基于概念的可解释模型推广至视频领域，揭示了概念在时间维度上的作用机制，为理解视频动作提供了透明且语义清晰的建模范式。

Abstract: Conceptual models such as Concept Bottleneck Models (CBMs) have driven
substantial progress in improving interpretability for image classification by
leveraging human-interpretable concepts. However, extending these models from
static images to sequences of images, such as video data, introduces a
significant challenge due to the temporal dependencies inherent in videos,
which are essential for capturing actions and events. In this work, we
introduce MoTIF (Moving Temporal Interpretable Framework), an architectural
design inspired by a transformer that adapts the concept bottleneck framework
for video classification and handles sequences of arbitrary length. Within the
video domain, concepts refer to semantic entities such as objects, attributes,
or higher-level components (e.g., 'bow', 'mount', 'shoot') that reoccur across
time - forming motifs collectively describing and explaining actions. Our
design explicitly enables three complementary perspectives: global concept
importance across the entire video, local concept relevance within specific
windows, and temporal dependencies of a concept over time. Our results
demonstrate that the concept-based modeling paradigm can be effectively
transferred to video data, enabling a better understanding of concept
contributions in temporal contexts while maintaining competitive performance.
Code available at github.com/patrick-knab/MoTIF.

</details>


### [42] [FSMODNet: A Closer Look at Few-Shot Detection in Multispectral Data](https://arxiv.org/abs/2509.20905)
*Manuel Nkegoum,Minh-Tan Pham,Élisa Fromont,Bruno Avignon,Sébastien Lefèvre*

Main category: cs.CV

TL;DR: 本文提出了一种名为FSMODNet的框架，用于解决少样本多光谱目标检测（FSMOD）问题，通过可变形注意力机制融合可见光与热成像特征，在标注数据极少的情况下实现了鲁棒的目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于标注多光谱数据成本高昂且稀少，如何在少量标注样本下实现跨模态（可见光与热成像）目标检测成为一个关键挑战。

Method: 提出FSMODNet，利用可变形注意力机制进行跨模态特征融合，增强模型在复杂光照和环境下的适应能力，并在低数据条件下优化检测性能。

Result: 在两个公开数据集上的实验表明，该方法在低数据场景下显著优于多个基于最先进模型构建的基线方法。

Conclusion: FSMODNet通过有效的跨模态特征整合，为少样本多光谱目标检测提供了高效解决方案，具有良好的实际应用潜力。

Abstract: Few-shot multispectral object detection (FSMOD) addresses the challenge of
detecting objects across visible and thermal modalities with minimal annotated
data. In this paper, we explore this complex task and introduce a framework
named "FSMODNet" that leverages cross-modality feature integration to improve
detection performance even with limited labels. By effectively combining the
unique strengths of visible and thermal imagery using deformable attention, the
proposed method demonstrates robust adaptability in complex illumination and
environmental conditions. Experimental results on two public datasets show
effective object detection performance in challenging low-data regimes,
outperforming several baselines we established from state-of-the-art models.
All code, models, and experimental data splits can be found at
https://anonymous.4open.science/r/Test-B48D.

</details>


### [43] [Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences](https://arxiv.org/abs/2509.20906)
*Julius Pesonen,Arno Solin,Eija Honkavaara*

Main category: cs.CV

TL;DR: 本文提出使用粒子滤波器在计算资源受限或远距离场景下，基于相机姿态和图像分割实现多目标3D定位，适用于无人机野火监测等安全关键任务。


<details>
  <summary>Details</summary>
Motivation: 在远距离或计算资源受限的情况下，传统的稠密深度估计或3D场景重建方法难以实现有效的3D目标定位，因此需要一种更可行且灵活的解决方案。

Method: 采用粒子滤波器结合相机位姿（GNSS提供）和图像分割结果，实现对单个及多个目标的3D定位，并在3D仿真和真实无人机数据上进行验证。

Result: 实验结果表明，该方法能在其他方法失效的情况下成功完成实际定位任务，且不依赖特定检测方法，具有良好的通用性和实用性。

Conclusion: 粒子滤波器是一种有效、灵活且适用于资源受限环境的3D目标定位方案，特别适合如无人机野火监测等安全关键应用。

Abstract: 3D object localisation based on a sequence of camera measurements is
essential for safety-critical surveillance tasks, such as drone-based wildfire
monitoring. Localisation of objects detected with a camera can typically be
solved with dense depth estimation or 3D scene reconstruction. However, in the
context of distant objects or tasks limited by the amount of available
computational resources, neither solution is feasible. In this paper, we show
that the task can be solved using particle filters for both single and multiple
target scenarios. The method was studied using a 3D simulation and a
drone-based image segmentation sequence with global navigation satellite system
(GNSS)-based camera pose estimates. The results showed that a particle filter
can be used to solve practical localisation tasks based on camera poses and
image segments in these situations where other solutions fail. The particle
filter is independent of the detection method, making it flexible for new
tasks. The study also demonstrates that drone-based wildfire monitoring can be
conducted using the proposed method paired with a pre-existing image
segmentation model.

</details>


### [44] [SwinMamba: A hybrid local-global mamba framework for enhancing semantic segmentation of remotely sensed images](https://arxiv.org/abs/2509.20918)
*Qinfeng Zhu,Han Li,Liang He,Lei Fan*

Main category: cs.CV

TL;DR: 本文提出了一种名为SwinMamba的新框架，用于遥感图像语义分割，结合局部与全局扫描机制，在LoveDA和ISPRS Potsdam数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision Mamba在处理遥感图像时因依赖全局扫描而忽视了关键的局部特征（如纹理和边缘），影响分割精度。

Method: 受Swin Transformer启发，SwinMamba在移位窗口内引入局部Mamba式扫描，并结合全局感受野；前两个阶段进行局部扫描以捕捉细节，后两个阶段使用全局扫描融合上下文信息，通过重叠移位窗口增强区域间信息交换。

Result: 在LoveDA和ISPRS Potsdam数据集上的实验表明，SwinMamba在性能上超过了当前最先进的方法。

Conclusion: SwinMamba能有效兼顾局部细节与全局上下文，是遥感图像语义分割的一个高效且有前景的解决方案。

Abstract: Semantic segmentation of remote sensing imagery is a fundamental task in
computer vision, supporting a wide range of applications such as land use
classification, urban planning, and environmental monitoring. However, this
task is often challenged by the high spatial resolution, complex scene
structures, and diverse object scales present in remote sensing data. To
address these challenges, various deep learning architectures have been
proposed, including convolutional neural networks, Vision Transformers, and the
recently introduced Vision Mamba. Vision Mamba features a global receptive
field and low computational complexity, demonstrating both efficiency and
effectiveness in image segmentation. However, its reliance on global scanning
tends to overlook critical local features, such as textures and edges, which
are essential for achieving accurate segmentation in remote sensing contexts.
To tackle this limitation, we propose SwinMamba, a novel framework inspired by
the Swin Transformer. SwinMamba integrates localized Mamba-style scanning
within shifted windows with a global receptive field, to enhance the model's
perception of both local and global features. Specifically, the first two
stages of SwinMamba perform local scanning to capture fine-grained details,
while its subsequent two stages leverage global scanning to fuse broader
contextual information. In our model, the use of overlapping shifted windows
enhances inter-region information exchange, facilitating more robust feature
integration across the entire image. Extensive experiments on the LoveDA and
ISPRS Potsdam datasets demonstrate that SwinMamba outperforms state-of-the-art
methods, underscoring its effectiveness and potential as a superior solution
for semantic segmentation of remotely sensed imagery.

</details>


### [45] [Revisiting Data Challenges of Computational Pathology: A Pack-based Multiple Instance Learning Framework](https://arxiv.org/abs/2509.20923)
*Wenhao Tang,Heng Fang,Ge Wu,Xiang Li,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 提出了一种基于包的多实例学习（pack-based MIL）框架，用于解决计算病理学中全切片图像（WSI）序列长度极长、变化大且监督有限的问题，显著提升训练效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 全切片图像（WSI）具有极长且可变的序列长度、高度异质性和冗余性，在有限监督下传统方法难以兼顾训练效率与模型优化，亟需新方法应对这些挑战。

Method: 提出pack-based MIL框架：将多个可变长度特征序列打包为固定长度序列以实现批量训练；引入残差分支，将丢弃的特征构建成超滑片并配以定制标签进行多滑片监督；设计注意力驱动的下采样器压缩两个分支的特征以减少冗余。

Result: 在PANDA(UNI)数据集上，相比传统方法最高提升8%准确率，同时仅使用12%的训练时间；实验表明所提方法能有效应对CPath中的数据挑战。

Conclusion: 通过打包策略、残差超滑片监督和注意力下采样，所提框架在保持数据异质性的同时大幅提升了训练效率和性能，验证了聚焦数据挑战在计算病理学基础模型时代的重要性。

Abstract: Computational pathology (CPath) digitizes pathology slides into whole slide
images (WSIs), enabling analysis for critical healthcare tasks such as cancer
diagnosis and prognosis. However, WSIs possess extremely long sequence lengths
(up to 200K), significant length variations (from 200 to 200K), and limited
supervision. These extreme variations in sequence length lead to high data
heterogeneity and redundancy. Conventional methods often compromise on training
efficiency and optimization to preserve such heterogeneity under limited
supervision. To comprehensively address these challenges, we propose a
pack-based MIL framework. It packs multiple sampled, variable-length feature
sequences into fixed-length ones, enabling batched training while preserving
data heterogeneity. Moreover, we introduce a residual branch that composes
discarded features from multiple slides into a hyperslide which is trained with
tailored labels. It offers multi-slide supervision while mitigating feature
loss from sampling. Meanwhile, an attention-driven downsampler is introduced to
compress features in both branches to reduce redundancy. By alleviating these
challenges, our approach achieves an accuracy improvement of up to 8% while
using only 12% of the training time in the PANDA(UNI). Extensive experiments
demonstrate that focusing data challenges in CPath holds significant potential
in the era of foundation models. The code is
https://github.com/FangHeng/PackMIL

</details>


### [46] [SimDiff: Simulator-constrained Diffusion Model for Physically Plausible Motion Generation](https://arxiv.org/abs/2509.20927)
*Akihisa Watanabe,Jiawei Ren,Li Siyao,Yichen Peng,Erwin Wu,Edgar Simo-Serra*

Main category: cs.CV

TL;DR: 提出SimDiff模型，通过将环境参数直接融入去噪过程，实现高效生成物理上合理的运动，避免了推理时重复调用模拟器。


<details>
  <summary>Details</summary>
Motivation: 现有方法因依赖顺序模拟器导致计算昂贵且难以并行，需更高效的物理合理动作生成方式。

Method: 将基于模拟器的动作投影解释为扩散过程中的引导形式，提出SimDiff模型，直接在去噪过程中条件化环境参数（如重力、风力）。

Result: SimDiff在无需反复调用模拟器的情况下生成物理合理的动作，支持细粒度物理参数控制，并能泛化到未见过的环境参数组合。

Conclusion: SimDiff通过隐式建模物理约束，在效率和可控性上优于传统模拟器驱动的方法，具备良好的组成泛化能力。

Abstract: Generating physically plausible human motion is crucial for applications such
as character animation and virtual reality. Existing approaches often
incorporate a simulator-based motion projection layer to the diffusion process
to enforce physical plausibility. However, such methods are computationally
expensive due to the sequential nature of the simulator, which prevents
parallelization. We show that simulator-based motion projection can be
interpreted as a form of guidance, either classifier-based or classifier-free,
within the diffusion process. Building on this insight, we propose SimDiff, a
Simulator-constrained Diffusion Model that integrates environment parameters
(e.g., gravity, wind) directly into the denoising process. By conditioning on
these parameters, SimDiff generates physically plausible motions efficiently,
without repeated simulator calls at inference, and also provides fine-grained
control over different physical coefficients. Moreover, SimDiff successfully
generalizes to unseen combinations of environmental parameters, demonstrating
compositional generalization.

</details>


### [47] [Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models](https://arxiv.org/abs/2509.20939)
*Bum Jun Kim,Makoto Kawano,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

TL;DR: 本文通过分析1174个预训练视觉模型，发现并解释了四种提升对高斯噪声鲁棒性的设计模式：更大的主干卷积核、更小的输入分辨率、使用平均池化以及监督式ViT而非CLIP ViT，并从理论上揭示了这些设计选择为何有效。


<details>
  <summary>Details</summary>
Motivation: 视觉模型的鲁棒性常被测量，但其与架构设计选择之间的依赖关系缺乏深入分析。本文旨在探究为何某些架构天生更具抗噪能力，并将经验观察转化为可操作的设计准则。

Method: 通过对1,174个预训练视觉模型进行大规模评估，识别出提升高斯噪声鲁棒性的关键设计模式；结合理论分析，建立因果机制解释，包括低通滤波、降采样、池化方式及预处理标准化的影响。

Result: 发现了四个显著提升鲁棒性的设计原则：更大的stem kernel、更小输入分辨率、平均池化优于最大池化、监督ViT优于CLIP ViT；理论分析表明：stem kernel大小与噪声衰减呈二次关系，平均池化能有效抑制噪声，CLIP ViT因归一化标准差较小导致最坏情况敏感性增加最多达1.91倍。

Conclusion: 本文将视觉模型的鲁棒性分解为可解释的模块，提供了理解架构设计影响的理论框架，并提出了实用、即插即用的模型设计指南以增强对高斯噪声的鲁棒性。

Abstract: While the robustness of vision models is often measured, their dependence on
specific architectural design choices is rarely dissected. We investigate why
certain vision architectures are inherently more robust to additive Gaussian
noise and convert these empirical insights into simple, actionable design
rules. Specifically, we performed extensive evaluations on 1,174 pretrained
vision models, empirically identifying four consistent design patterns for
improved robustness against Gaussian noise: larger stem kernels, smaller input
resolutions, average pooling, and supervised vision transformers (ViTs) rather
than CLIP ViTs, which yield up to 506 rank improvements and 21.6\%p accuracy
gains. We then develop a theoretical analysis that explains these findings,
converting observed correlations into causal mechanisms. First, we prove that
low-pass stem kernels attenuate noise with a gain that decreases quadratically
with kernel size and that anti-aliased downsampling reduces noise energy
roughly in proportion to the square of the downsampling factor. Second, we
demonstrate that average pooling is unbiased and suppresses noise in proportion
to the pooling window area, whereas max pooling incurs a positive bias that
grows slowly with window size and yields a relatively higher mean-squared error
and greater worst-case sensitivity. Third, we reveal and explain the
vulnerability of CLIP ViTs via a pixel-space Lipschitz bound: The smaller
normalization standard deviations used in CLIP preprocessing amplify worst-case
sensitivity by up to 1.91 times relative to the Inception-style preprocessing
common in supervised ViTs. Our results collectively disentangle robustness into
interpretable modules, provide a theory that explains the observed trends, and
build practical, plug-and-play guidelines for designing vision models more
robust against Gaussian noise.

</details>


### [48] [Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery](https://arxiv.org/abs/2509.20941)
*Angelo Henriques,Korab Hoxha,Daniel Zapp,Peter C. Issa,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: 该论文综述了场景图（SG）在手术中的研究进展，指出尽管发展迅速，但存在‘数据鸿沟’：内视研究依赖真实2D视频，外视4D建模则依赖模拟数据。方法上已从基础图神经网络发展到专用基础模型，并在手术任务中超越通用大模型。SG现已成为手术流程识别、安全监控和可控制手术模拟的关键技术，正推动智能手术系统的发展。


<details>
  <summary>Details</summary>
Motivation: 揭示手术场景图研究的现状与挑战，特别是内部视图与外部视图之间的数据使用差异，以及方法论的演进路径。

Method: 采用PRISMA-ScR指导的范围综述方法，系统梳理手术中场景图的研究文献，分析其应用、方法进展与未来方向。

Result: 发现领域快速发展，但存在‘数据鸿沟’；方法上专用基础模型已显著优于通用视觉语言模型；SG已被确立为手术分析与生成任务的核心技术。

Conclusion: 手术场景图正成为连接感知与语义理解的关键桥梁，有望提升手术安全性、效率和培训水平，但仍需解决数据标注与实时性挑战。

Abstract: Scene graphs (SGs) provide structured relational representations crucial for
decoding complex, dynamic surgical environments. This PRISMA-ScR-guided scoping
review systematically maps the evolving landscape of SG research in surgery,
charting its applications, methodological advancements, and future directions.
Our analysis reveals rapid growth, yet uncovers a critical 'data divide':
internal-view research (e.g., triplet recognition) almost exclusively uses
real-world 2D video, while external-view 4D modeling relies heavily on
simulated data, exposing a key translational research gap. Methodologically,
the field has advanced from foundational graph neural networks to specialized
foundation models that now significantly outperform generalist large
vision-language models in surgical contexts. This progress has established SGs
as a cornerstone technology for both analysis, such as workflow recognition and
automated safety monitoring, and generative tasks like controllable surgical
simulation. Although challenges in data annotation and real-time implementation
persist, they are actively being addressed through emerging techniques.
Surgical SGs are maturing into an essential semantic bridge, enabling a new
generation of intelligent systems to improve surgical safety, efficiency, and
training.

</details>


### [49] [A Real-Time On-Device Defect Detection Framework for Laser Power-Meter Sensors via Unsupervised Learning](https://arxiv.org/abs/2509.20946)
*Dongqi Zheng,Wenjin Fu,Guangzong Chen*

Main category: cs.CV

TL;DR: 提出一种基于视觉的自动化系统，用于激光功率计传感器涂层缺陷检测与分类，采用无监督异常检测框架和UFlow网络，结合StyleGAN2数据增强，在真实图像上实现了高精度检测。


<details>
  <summary>Details</summary>
Motivation: 检测激光功率计传感器涂层中的热损伤和划痕等缺陷，避免影响医疗和工业应用中激光能量测量的准确性。

Method: 使用拉普拉斯边缘检测和K-means聚类进行预处理，通过StyleGAN2进行合成数据增强，并采用UFlow架构进行多尺度特征提取和异常图生成，训练仅基于正常样本。

Result: 在366张真实图像上测试，缺陷样本准确率达93.8%，正常样本达89.3%，图像级AUROC为0.957，像素级AUROC为0.961，单图处理时间0.5秒。

Conclusion: 该系统可实现高效、快速的自动化质量控制，具有显著的年成本节约潜力。

Abstract: We present an automated vision-based system for defect detection and
classification of laser power meter sensor coatings. Our approach addresses the
critical challenge of identifying coating defects such as thermal damage and
scratches that can compromise laser energy measurement accuracy in medical and
industrial applications. The system employs an unsupervised anomaly detection
framework that trains exclusively on ``good'' sensor images to learn normal
coating distribution patterns, enabling detection of both known and novel
defect types without requiring extensive labeled defect datasets. Our
methodology consists of three key components: (1) a robust preprocessing
pipeline using Laplacian edge detection and K-means clustering to segment the
area of interest, (2) synthetic data augmentation via StyleGAN2, and (3) a
UFlow-based neural network architecture for multi-scale feature extraction and
anomaly map generation. Experimental evaluation on 366 real sensor images
demonstrates $93.8\%$ accuracy on defective samples and $89.3\%$ accuracy on
good samples, with image-level AUROC of 0.957 and pixel-level AUROC of 0.961.
The system provides potential annual cost savings through automated quality
control and processing times of 0.5 seconds per image in on-device
implementation.

</details>


### [50] [Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos](https://arxiv.org/abs/2509.20961)
*Sarmistha Das,R E Zera Marveen Lyngkhoi,Sriparna Saha,Alka Maurya*

Main category: cs.CV

TL;DR: 本文提出了FASTER，一个用于金融咨询视频的多模态摘要框架，结合文本、语音和视觉信息生成精确、简洁且可解释的摘要，并发布了Fin-APT数据集以促进相关研究。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上金融咨询视频内容广泛传播，但长时多模态内容（30-40分钟）难以提取关键信息，现有方法在跨模态对齐、事实一致性与摘要质量方面存在不足。

Method: FASTER框架融合BLIP生成语义图像描述、OCR提取文本模式、Whisper进行带说话人区分的语音转录作为BOS特征；采用改进的基于DPO的损失函数，结合BOS特定的事实核查机制；并通过排序检索机制实现关键帧与文本摘要的对齐。

Result: 在跨领域实验中，FASTER在摘要质量、事实一致性和跨模态对齐方面优于现有大语言模型和视觉-语言模型；所提出的Fin-APT数据集包含470个公开金融咨询视频，支持多模态研究。

Conclusion: FASTER为金融咨询视频的多模态摘要设立了新标准，提升了内容的可访问性与可用性，推动了多模态金融内容分析的研究发展。

Abstract: The dynamic propagation of social media has broadened the reach of financial
advisory content through podcast videos, yet extracting insights from lengthy,
multimodal segments (30-40 minutes) remains challenging. We introduce FASTER
(Financial Advisory Summariser with Textual Embedded Relevant images), a
modular framework that tackles three key challenges: (1) extracting
modality-specific features, (2) producing optimized, concise summaries, and (3)
aligning visual keyframes with associated textual points. FASTER employs BLIP
for semantic visual descriptions, OCR for textual patterns, and Whisper-based
transcription with Speaker diarization as BOS features. A modified Direct
Preference Optimization (DPO)-based loss function, equipped with BOS-specific
fact-checking, ensures precision, relevance, and factual consistency against
the human-aligned summary. A ranker-based retrieval mechanism further aligns
keyframes with summarized content, enhancing interpretability and cross-modal
coherence. To acknowledge data resource scarcity, we introduce Fin-APT, a
dataset comprising 470 publicly accessible financial advisory pep-talk videos
for robust multimodal research. Comprehensive cross-domain experiments confirm
FASTER's strong performance, robustness, and generalizability when compared to
Large Language Models (LLMs) and Vision-Language Models (VLMs). By establishing
a new standard for multimodal summarization, FASTER makes financial advisory
content more accessible and actionable, thereby opening new avenues for
research. The dataset and code are available at:
https://github.com/sarmistha-D/FASTER

</details>


### [51] [An Adaptor for Triggering Semi-Supervised Learning to Out-of-Box Serve Deep Image Clustering](https://arxiv.org/abs/2509.20976)
*Yue Duan,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: 提出ASD适配器，无需预训练即可实现自监督学习模型在深度图像聚类中的冷启动，通过伪标签数据和类别转换跟踪提升聚类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要预训练或已训练的聚类模型作为前提，限制了自监督学习在图像聚类中的灵活应用。

Method: 随机采样未标注数据生成伪标签，利用实例级分类器学习语义对齐的标签，通过追踪预测的类别转移提取高层相似性，赋予伪标签数据簇级标签，进而启动SSL学习器进行图像聚类。

Result: 在多个基准上优于最新的深度图像聚类方法，且与使用真实标签的SSL方法相比仅有微小精度差距（如CIFAR-10上仅差1.33%），并能进一步提升现有SSL嵌入方法的性能。

Conclusion: ASD实现了无需任何前置条件的SSL冷启动聚类，具有良好的通用性和性能提升潜力。

Abstract: Recently, some works integrate SSL techniques into deep clustering frameworks
to enhance image clustering performance. However, they all need pretraining,
clustering learning, or a trained clustering model as prerequisites, limiting
the flexible and out-of-box application of SSL learners in the image clustering
task. This work introduces ASD, an adaptor that enables the cold-start of SSL
learners for deep image clustering without any prerequisites. Specifically, we
first randomly sample pseudo-labeled data from all unlabeled data, and set an
instance-level classifier to learn them with semantically aligned
instance-level labels. With the ability of instance-level classification, we
track the class transitions of predictions on unlabeled data to extract
high-level similarities of instance-level classes, which can be utilized to
assign cluster-level labels to pseudo-labeled data. Finally, we use the
pseudo-labeled data with assigned cluster-level labels to trigger a general SSL
learner trained on the unlabeled data for image clustering. We show the
superior performance of ASD across various benchmarks against the latest deep
image clustering approaches and very slight accuracy gaps compared to SSL
methods using ground-truth, e.g., only 1.33% on CIFAR-10. Moreover, ASD can
also further boost the performance of existing SSL-embedded deep image
clustering methods.

</details>


### [52] [SiNGER: A Clearer Voice Distills Vision Transformers Further](https://arxiv.org/abs/2509.20986)
*Geunhyeok Yu,Sunjae Jeong,Yoonyoung Choi,Jaeseung Kim,Hyoseok Hwang*

Main category: cs.CV

TL;DR: 提出了一种名为SiNGER的新型知识蒸馏框架，通过零空间引导的扰动来抑制教师模型中的高范数伪影，同时保留有用信息，从而提升学生模型的表现。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers中的高范数伪影会降低表示质量，并在知识蒸馏中导致学生模型过度拟合伪影而忽略有用信号，现有方法难以在抑制伪影和保留信息之间取得平衡。

Method: 提出SiNGER框架，利用零空间引导的扰动对教师特征进行原则性优化，在保留信息的同时抑制伪影，并通过LoRA-based adapter高效实现，最后将优化后的特征用于蒸馏学生模型。

Result: 实验表明，SiNGER在多个下游任务中 consistently 提升学生模型性能，达到最先进水平，并生成更清晰、可解释的表示。

Conclusion: SiNGER有效解决了高范数伪影与信息保留之间的权衡问题，显著提升了知识蒸馏的效果。

Abstract: Vision Transformers are widely adopted as the backbone of vision foundation
models, but they are known to produce high-norm artifacts that degrade
representation quality. When knowledge distillation transfers these features to
students, high-norm artifacts dominate the objective, so students overfit to
artifacts and underweight informative signals, diminishing the gains from
larger models. Prior work attempted to remove artifacts but encountered an
inherent trade-off between artifact suppression and preserving informative
signals from teachers. To address this, we introduce Singular Nullspace-Guided
Energy Reallocation (SiNGER), a novel distillation framework that suppresses
artifacts while preserving informative signals. The key idea is principled
teacher feature refinement: during refinement, we leverage the nullspace-guided
perturbation to preserve information while suppressing artifacts. Then, the
refined teacher's features are distilled to a student. We implement this
perturbation efficiently with a LoRA-based adapter that requires minimal
structural modification. Extensive experiments show that \oursname consistently
improves student models, achieving state-of-the-art performance in multiple
downstream tasks and producing clearer and more interpretable representations.

</details>


### [53] [Fast-SEnSeI: Lightweight Sensor-Independent Cloud Masking for On-board Multispectral Sensors](https://arxiv.org/abs/2509.20991)
*Jan Kněžík,Jonáš Herec,Rado Pitoňák*

Main category: cs.CV

TL;DR: 提出了一种轻量级、传感器无关的编码模块Fast-SEnSeI，用于多光谱传感器上的星载云分割，支持任意波段组合输入，并在嵌入式CPU和FPGA上高效运行。


<details>
  <summary>Details</summary>
Motivation: 现有云分割模型通常依赖特定传感器配置且需地面处理，难以适应不同传感器和星载实时处理需求。

Method: 基于SEnSeI-v2改进，引入更优的光谱描述符、轻量化架构和鲁棒的填充波段处理机制，支持任意波段输入；结合量化U-Net进行分割，采用CPU-FPGA混合部署。

Result: 在Sentinel-2和Landsat 8数据集上验证了模型在多种输入配置下的准确云分割能力，具备良好的泛化性和硬件效率。

Conclusion: Fast-SEnSeI实现了灵活、高效的星载云分割，适用于不同多光谱传感器，推动了星上实时处理的发展。

Abstract: Cloud segmentation is a critical preprocessing step for many Earth
observation tasks, yet most models are tightly coupled to specific sensor
configurations and rely on ground-based processing. In this work, we propose
Fast-SEnSeI, a lightweight, sensor-independent encoder module that enables
flexible, on-board cloud segmentation across multispectral sensors with varying
band configurations. Building upon SEnSeI-v2, Fast-SEnSeI integrates an
improved spectral descriptor, lightweight architecture, and robust padding-band
handling. It accepts arbitrary combinations of spectral bands and their
wavelengths, producing fixed-size feature maps that feed into a compact,
quantized segmentation model based on a modified U-Net. The module runs
efficiently on embedded CPUs using Apache TVM, while the segmentation model is
deployed on FPGA, forming a CPU-FPGA hybrid pipeline suitable for
space-qualified hardware. Evaluations on Sentinel-2 and Landsat 8 datasets
demonstrate accurate segmentation across diverse input configurations.

</details>


### [54] [A Single Neuron Works: Precise Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.21008)
*Qinqin He,Jiaqi Weng,Jialing Tao,Hui Xue*

Main category: cs.CV

TL;DR: 本文提出了一种基于单个神经元的概念消除方法（SNCE），通过稀疏自编码器和新型神经元识别技术，精确抑制有害内容生成，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有概念消除方法难以在精准去除目标概念的同时保持图像质量，且易受对抗攻击影响。

Method: 训练稀疏自编码器将文本嵌入映射到解耦的稀疏潜在空间，并设计基于激活模式调制频率评分的神经元识别方法，定位并抑制特定有害概念对应的单个神经元。

Result: 在多个基准上达到最优的靶向概念消除效果，有效保留非靶向概念的生成能力，并表现出强对抗鲁棒性。

Conclusion: SNCE实现了高精度、低干扰的概念擦除，为文本到图像模型的安全控制提供了高效可行的新方案。

Abstract: Text-to-image models exhibit remarkable capabilities in image generation.
However, they also pose safety risks of generating harmful content. A key
challenge of existing concept erasure methods is the precise removal of target
concepts while minimizing degradation of image quality. In this paper, we
propose Single Neuron-based Concept Erasure (SNCE), a novel approach that can
precisely prevent harmful content generation by manipulating only a single
neuron. Specifically, we train a Sparse Autoencoder (SAE) to map text
embeddings into a sparse, disentangled latent space, where individual neurons
align tightly with atomic semantic concepts. To accurately locate neurons
responsible for harmful concepts, we design a novel neuron identification
method based on the modulated frequency scoring of activation patterns. By
suppressing activations of the harmful concept-specific neuron, SNCE achieves
surgical precision in concept erasure with minimal disruption to image quality.
Experiments on various benchmarks demonstrate that SNCE achieves
state-of-the-art results in target concept erasure, while preserving the
model's generation capabilities for non-target concepts. Additionally, our
method exhibits strong robustness against adversarial attacks, significantly
outperforming existing methods.

</details>


### [55] [OmniPlantSeg: Species Agnostic 3D Point Cloud Organ Segmentation for High-Resolution Plant Phenotyping Across Modalities](https://arxiv.org/abs/2509.21038)
*Andreas Gilson,Lukas Meyer,Oliver Scholz,Ute Schmid*

Main category: cs.CV

TL;DR: 提出了一种简单而有效的KDSS算法，用于生物点云的子采样，适用于不同植物种类和传感器模态，无需降采样即可实现全分辨率点云分割。


<details>
  <summary>Details</summary>
Motivation: 现有植物器官点云分割方法通常针对特定植物或传感器模态，且需大量预处理和降采样，限制了通用性和精度。

Method: 提出KDSS算法，一种与传感器和植物种类无关的子采样方法，保留原始分辨率，结合当前最先进的分割模型进行全分辨率点云分割。

Result: 在多种传感器模态（如摄影测量、激光三角测量和LiDAR）和不同植物物种上验证了KDSS的有效性，结果令人满意。

Conclusion: KDSS是一种轻量级、保留分辨率的预处理替代方案，适用于跨物种和传感器模态的植物器官点云分割。

Abstract: Accurate point cloud segmentation for plant organs is crucial for 3D plant
phenotyping. Existing solutions are designed problem-specific with a focus on
certain plant species or specified sensor-modalities for data acquisition.
Furthermore, it is common to use extensive pre-processing and down-sample the
plant point clouds to meet hardware or neural network input size requirements.
We propose a simple, yet effective algorithm KDSS for sub-sampling of
biological point clouds that is agnostic to sensor data and plant species. The
main benefit of this approach is that we do not need to down-sample our input
data and thus, enable segmentation of the full-resolution point cloud.
Combining KD-SS with current state-of-the-art segmentation models shows
satisfying results evaluated on different modalities such as photogrammetry,
laser triangulation and LiDAR for various plant species. We propose KD-SS as
lightweight resolution-retaining alternative to intensive pre-processing and
down-sampling methods for plant organ segmentation regardless of used species
and sensor modality.

</details>


### [56] [Background Prompt for Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2509.21055)
*Songyue Cai,Zongqian Wu,Yujie Mo,Liang Peng,Ping Hu,Xiaoshuang Shi,Xiaofeng Zhu*

Main category: cs.CV

TL;DR: 提出了一种新的前景-背景分解框架Mambo，用于少样本异常检测，通过结合局部类别相似性和改进的背景相似性，并引入自校准调整机制，提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法因过度依赖局部类别相似性和固定的背景块提取策略而导致鲁棒性差。

Method: 首先学习一个包含背景和图像语义信息的背景提示以获得局部背景相似性，然后利用局部类别相似性对其进行优化；结合两者进行背景提取，并采用自校准调优策略灵活选择不同样本的背景块数量。

Result: 在真实世界数据集上的实验表明，Mambo在OOD检测和近OOD检测任务上优于现有最先进方法。

Conclusion: Mambo有效解决了FG-BG分解中对局部相似性的过强依赖和固定背景提取的问题，显著提升了少样本异常检测的鲁棒性和性能。

Abstract: Existing foreground-background (FG-BG) decomposition methods for the few-shot
out-of-distribution (FS-OOD) detection often suffer from low robustness due to
over-reliance on the local class similarity and a fixed background patch
extraction strategy. To address these challenges, we propose a new FG-BG
decomposition framework, namely Mambo, for FS-OOD detection. Specifically, we
propose to first learn a background prompt to obtain the local background
similarity containing both the background and image semantic information, and
then refine the local background similarity using the local class similarity.
As a result, we use both the refined local background similarity and the local
class similarity to conduct background extraction, reducing the dependence of
the local class similarity in previous methods. Furthermore, we propose the
patch self-calibrated tuning to consider the sample diversity to flexibly
select numbers of background patches for different samples, and thus exploring
the issue of fixed background extraction strategies in previous methods.
Extensive experiments on real-world datasets demonstrate that our proposed
Mambo achieves the best performance, compared to SOTA methods in terms of OOD
detection and near OOD detection setting. The source code will be released at
https://github.com/YuzunoKawori/Mambo.

</details>


### [57] [Stratify or Die: Rethinking Data Splits in Image Segmentation](https://arxiv.org/abs/2509.21056)
*Naga Venkata Sai Jitin Jami,Thomas Altstidl,Jonas Mueller,Jindong Li,Dario Zanca,Bjoern Eskofier,Heike Leutheuser*

Main category: cs.CV

TL;DR: 本文提出了一种名为Wasserstein-Driven Evolutionary Stratification (WDES)的遗传算法，用于优化图像分割任务中的数据集划分，通过最小化Wasserstein距离来提高各划分间标签分布的相似性，从而减少性能方差并改善模型评估。


<details>
  <summary>Details</summary>
Motivation: 传统随机划分方法在图像分割任务中容易导致测试集不具代表性，造成评估偏差和模型泛化能力差；而现有分层抽样方法难以应对分割任务中的多标签结构和类别不平衡问题。

Method: 提出了两种方法：一是适用于分割任务的简单标签感知采样方法Iterative Pixel Stratification (IPS)；二是基于遗传算法的Wasserstein-Driven Evolutionary Stratification (WDES)，通过最小化Wasserstein距离优化数据划分，并证明其在足够代数下具有全局最优性。

Result: 使用新提出的统计异质性指标评估表明，WDES在街景、医学影像和卫星图像等多种分割任务中均能产生更具代表性的数据划分，显著降低性能方差，提升模型评估可靠性，尤其在小样本、类别不平衡和低多样性数据集中表现更优。

Conclusion: WDES是一种有效且全局最优的数据集划分方法，能够显著提升图像分割任务中模型评估的准确性和稳定性，特别适用于具有挑战性的数据环境。

Abstract: Random splitting of datasets in image segmentation often leads to
unrepresentative test sets, resulting in biased evaluations and poor model
generalization. While stratified sampling has proven effective for addressing
label distribution imbalance in classification tasks, extending these ideas to
segmentation remains challenging due to the multi-label structure and class
imbalance typically present in such data. Building on existing stratification
concepts, we introduce Iterative Pixel Stratification (IPS), a straightforward,
label-aware sampling method tailored for segmentation tasks. Additionally, we
present Wasserstein-Driven Evolutionary Stratification (WDES), a novel genetic
algorithm designed to minimize the Wasserstein distance, thereby optimizing the
similarity of label distributions across dataset splits. We prove that WDES is
globally optimal given enough generations. Using newly proposed statistical
heterogeneity metrics, we evaluate both methods against random sampling and
find that WDES consistently produces more representative splits. Applying WDES
across diverse segmentation tasks, including street scenes, medical imaging,
and satellite imagery, leads to lower performance variance and improved model
evaluation. Our results also highlight the particular value of WDES in handling
small, imbalanced, and low-diversity datasets, where conventional splitting
strategies are most prone to bias.

</details>


### [58] [EnGraf-Net: Multiple Granularity Branch Network with Fine-Coarse Graft Grained for Classification Task](https://arxiv.org/abs/2509.21061)
*Riccardo La Grassa,Ignazio Gallo,Nicola Landro*

Main category: cs.CV

TL;DR: 本文提出了一种名为EnGraf-Net的端到端深度神经网络模型，利用层次化语义关联（taxonomy）作为监督信号，用于细粒度分类，无需依赖裁剪或人工标注，在多个数据集上表现出与当前最先进方法相媲美的性能。


<details>
  <summary>Details</summary>
Motivation: 现有细粒度分类方法依赖部件标注或自动注意力机制，但局部特征表示不完整；受人类通过语义关联识别物体的启发，作者希望引入层次化语义信息来增强分类性能。

Method: 提出EnGraf-Net模型，将语义层次结构（taxonomy）作为监督信号嵌入端到端深度神经网络中，利用层级语义关联引导特征学习，避免使用部件标注或自动裁剪技术。

Result: 在CIFAR-100、CUB-200-2011和FGVC-Aircraft三个主流细粒度数据集上进行了广泛实验，结果表明EnGraf-Net优于许多现有方法，性能与最新方法相当。

Conclusion: 通过引入层次化语义关联作为监督信号，EnGraf-Net在不依赖额外标注或裁剪的情况下实现了高效的细粒度分类，验证了语义层次信息对细粒度识别的重要性。

Abstract: Fine-grained classification models are designed to focus on the relevant
details necessary to distinguish highly similar classes, particularly when
intra-class variance is high and inter-class variance is low. Most existing
models rely on part annotations such as bounding boxes, part locations, or
textual attributes to enhance classification performance, while others employ
sophisticated techniques to automatically extract attention maps. We posit that
part-based approaches, including automatic cropping methods, suffer from an
incomplete representation of local features, which are fundamental for
distinguishing similar objects. While fine-grained classification aims to
recognize the leaves of a hierarchical structure, humans recognize objects by
also forming semantic associations. In this paper, we leverage semantic
associations structured as a hierarchy (taxonomy) as supervised signals within
an end-to-end deep neural network model, termed EnGraf-Net. Extensive
experiments on three well-known datasets CIFAR-100, CUB-200-2011, and
FGVC-Aircraft demonstrate the superiority of EnGraf-Net over many existing
fine-grained models, showing competitive performance with the most recent
state-of-the-art approaches, without requiring cropping techniques or manual
annotations.

</details>


### [59] [Vision Transformers: the threat of realistic adversarial patches](https://arxiv.org/abs/2509.21084)
*Kasper Cools,Clara Maathuis,Alexander M. van Oers,Claudia S. Hübner,Nikos Deligiannis,Marijke Vandewal,Geert De Cubber*

Main category: cs.CV

TL;DR: 本研究探讨了视觉Transformer（ViT）在面对基于CNN的对抗性补丁攻击时的脆弱性，发现不同ViT模型对这类攻击的防御能力差异显著，攻击成功率从40.04%到99.97%不等，表明对抗性补丁在跨架构间具有可迁移性，且模型预训练数据规模和方法显著影响其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统在关键领域的广泛应用，其安全性变得至关重要。尽管视觉Transformer（ViT）相比传统卷积神经网络（CNN）在性能和鲁棒性上有所提升，但其在现实场景中对抗逃避攻击（尤其是对抗性补丁）的脆弱性仍需深入研究。

Method: 研究采用Creases Transformation（CT）技术生成逼真的对抗性补丁，模拟衣物褶皱等自然几何畸变，并在四个微调后的ViT模型上进行实验，评估这些来自CNN的对抗补丁在二分类人物识别任务中的跨架构迁移攻击效果。

Result: 实验结果显示，不同ViT模型对对抗补丁的敏感度差异巨大：google/vit-base-patch16-224-in21k攻击成功率为40.04%，facebook/dino-vitb16高达99.97%，其余两个模型分别为66.40%和65.17%，验证了对抗补丁在CNN与ViT之间的可迁移性。

Conclusion: ViT模型并非天然免疫对抗性补丁攻击，其防御能力受预训练数据集规模和训练方法显著影响，未来需针对ViT架构设计更有效的防御机制以提升实际应用中的安全性。

Abstract: The increasing reliance on machine learning systems has made their security a
critical concern. Evasion attacks enable adversaries to manipulate the
decision-making processes of AI systems, potentially causing security breaches
or misclassification of targets. Vision Transformers (ViTs) have gained
significant traction in modern machine learning due to increased 1) performance
compared to Convolutional Neural Networks (CNNs) and 2) robustness against
adversarial perturbations. However, ViTs remain vulnerable to evasion attacks,
particularly to adversarial patches, unique patterns designed to manipulate AI
classification systems. These vulnerabilities are investigated by designing
realistic adversarial patches to cause misclassification in person vs.
non-person classification tasks using the Creases Transformation (CT)
technique, which adds subtle geometric distortions similar to those occurring
naturally when wearing clothing. This study investigates the transferability of
adversarial attack techniques used in CNNs when applied to ViT classification
models. Experimental evaluation across four fine-tuned ViT models on a binary
person classification task reveals significant vulnerability variations: attack
success rates ranged from 40.04% (google/vit-base-patch16-224-in21k) to 99.97%
(facebook/dino-vitb16), with google/vit-base-patch16-224 achieving 66.40% and
facebook/dinov3-vitb16 reaching 65.17%. These results confirm the
cross-architectural transferability of adversarial patches from CNNs to ViTs,
with pre-training dataset scale and methodology strongly influencing model
resilience to adversarial attacks.

</details>


### [60] [UniTransfer: Video Concept Transfer via Progressive Spatial and Timestep Decomposition](https://arxiv.org/abs/2509.21086)
*Guojun Lei,Rong Zhang,Chi Wang,Tianhang Liu,Hong Li,Zhiyuan Ma,Weiwei Xu*

Main category: cs.CV

TL;DR: 提出UniTransfer架构，通过空间和扩散时间步分解实现精确可控的视频概念迁移。


<details>
  <summary>Details</summary>
Motivation: 为了实现更精细、可控的视频概念转移，解决现有方法在编辑性和保真度上的不足。

Method: 引入空间分解（前景、背景、运动流）和基于DiT的双到单流架构；提出自监督预训练策略；结合Chain-of-Prompt机制进行时间步分解，利用大语言模型提供阶段指导。

Result: 在多种参考图像和场景下实现了高质量、高可控性的视频概念转移，超越现有基线方法，在视觉保真度和可编辑性方面表现更优。

Conclusion: UniTransfer通过空间与时间双重分解及LLM引导的渐进生成，显著提升了视频概念转移的效果与控制能力。

Abstract: We propose a novel architecture UniTransfer, which introduces both spatial
and diffusion timestep decomposition in a progressive paradigm, achieving
precise and controllable video concept transfer. Specifically, in terms of
spatial decomposition, we decouple videos into three key components: the
foreground subject, the background, and the motion flow. Building upon this
decomposed formulation, we further introduce a dual-to-single-stream DiT-based
architecture for supporting fine-grained control over different components in
the videos. We also introduce a self-supervised pretraining strategy based on
random masking to enhance the decomposed representation learning from
large-scale unlabeled video data. Inspired by the Chain-of-Thought reasoning
paradigm, we further revisit the denoising diffusion process and propose a
Chain-of-Prompt (CoP) mechanism to achieve the timestep decomposition. We
decompose the denoising process into three stages of different granularity and
leverage large language models (LLMs) for stage-specific instructions to guide
the generation progressively. We also curate an animal-centric video dataset
called OpenAnimal to facilitate the advancement and benchmarking of research in
video concept transfer. Extensive experiments demonstrate that our method
achieves high-quality and controllable video concept transfer across diverse
reference images and scenes, surpassing existing baselines in both visual
fidelity and editability. Web Page:
https://yu-shaonian.github.io/UniTransfer-Web/

</details>


### [61] [VideoChat-R1.5: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception](https://arxiv.org/abs/2509.21100)
*Ziang Yan,Xinhao Li,Yinan He,Zhengrong Yue,Xiangyu Zeng,Yali Wang,Yu Qiao,Limin Wang,Yi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为视觉测试时扩展（VTTS）的新方法，通过推理过程中的迭代感知来增强多模态大语言模型（MLLMs）的推理能力，并引入VTTS-80K数据集支持该范式，显著提升了在多种视频理解和时空感知任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型主要依赖静态感知阶段进行视觉解析，限制了其推理能力，难以实现类人水平的感知与理解。因此，需要一种能够在推理过程中动态优化感知的方法。

Method: 提出视觉测试时扩展（VTTS），采用迭代感知（ITP）机制，结合强化学习和时空监督，根据文本预测逐步聚焦于高置信度的时空区域，实现感知与推理的协同优化。同时构建VTTS-80K数据集以支持训练与评估。

Result: 在超过15个涵盖视频对话、视频推理和时空感知的基准上，基于VTTS的Videochat-R1.5模型相较Qwen2.5VL-3B和-7B等强基线平均提升超过5%，验证了方法的有效性和泛化能力。

Conclusion: VTTS通过推理时的动态迭代感知显著增强了MLLM的时空理解与推理能力，展示了增加感知计算量带来的性能增益，为构建更智能的多模态系统提供了新方向。

Abstract: Inducing reasoning in multimodal large language models (MLLMs) is critical
for achieving human-level perception and understanding. Existing methods mainly
leverage LLM reasoning to analyze parsed visuals, often limited by static
perception stages. This paper introduces Visual Test-Time Scaling (VTTS), a
novel approach to enhance MLLMs' reasoning via iterative perception during
inference. VTTS mimics humans' hierarchical attention by progressively refining
focus on high-confidence spatio-temporal regions, guided by updated textual
predictions. Specifically, VTTS employs an Iterative Perception (ITP)
mechanism, incorporating reinforcement learning with spatio-temporal
supervision to optimize reasoning. To support this paradigm, we also present
VTTS-80K, a dataset tailored for iterative perception. These designs allows a
MLLM to enhance its performance by increasing its perceptual compute. Extensive
experiments validate VTTS's effectiveness and generalization across diverse
tasks and benchmarks. Our newly introduced Videochat-R1.5 model has achieved
remarkable improvements, with an average increase of over 5\%, compared to
robust baselines such as Qwen2.5VL-3B and -7B, across more than 15 benchmarks
that encompass video conversation, video reasoning, and spatio-temporal
perception.

</details>


### [62] [Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models](https://arxiv.org/abs/2509.21102)
*Suaiba Amina Salahuddin,Teresa Dorszewski,Marit Almenning Martiniussen,Tone Hovda,Antonio Portaluri,Solveig Thrun,Michael Kampffmeyer,Elisabeth Wetzer,Kristoffer Wickstrøm,Robert Jenssen*

Main category: cs.CV

TL;DR: 本文提出了Mammo-CLIP Dissect，首个用于系统解析乳腺X线摄影深度学习视觉模型的概念性可解释性框架，利用乳腺特异性视觉-语言模型标注神经元并量化其与领域知识的对齐程度。


<details>
  <summary>Details</summary>
Motivation: 理解深度学习模型在临床环境中学到的内容至关重要，而现有研究多关注基于像素的可解释方法，较少关注模型学习到的文本概念，这些概念可能更贴近临床医生的推理方式。因此，作者旨在探索模型在乳腺影像任务中学习到的医学概念及其与临床知识的一致性。

Method: 提出Mammo-CLIP Dissect框架，使用乳腺特异性的视觉-语言模型（Mammo-CLIP）作为“解剖器”，将指定层的神经元标记为人类可理解的文本概念，并量化其与领域知识的对齐程度，进而比较不同训练数据和微调策略下模型的概念学习差异。

Result: 实验表明，在乳腺数据上训练的模型比通用图像训练的模型捕捉到更多临床相关概念，且更符合放射科医生的工作流程；微调能增强某些概念（如良性钙化）的学习，但可能削弱其他特征（如密度相关）的覆盖，揭示了专业化与泛化之间的权衡。

Conclusion: Mammo-CLIP Dissect能够有效揭示CNN如何捕获乳腺影像中的特定医学知识，为模型可解释性提供了新的视角，并强调了领域特定训练和任务适应对概念学习的重要影响。

Abstract: Understanding what deep learning (DL) models learn is essential for the safe
deployment of artificial intelligence (AI) in clinical settings. While previous
work has focused on pixel-based explainability methods, less attention has been
paid to the textual concepts learned by these models, which may better reflect
the reasoning used by clinicians. We introduce Mammo-CLIP Dissect, the first
concept-based explainability framework for systematically dissecting DL vision
models trained for mammography. Leveraging a mammography-specific
vision-language model (Mammo-CLIP) as a "dissector," our approach labels
neurons at specified layers with human-interpretable textual concepts and
quantifies their alignment to domain knowledge. Using Mammo-CLIP Dissect, we
investigate three key questions: (1) how concept learning differs between DL
vision models trained on general image datasets versus mammography-specific
datasets; (2) how fine-tuning for downstream mammography tasks affects concept
specialisation; and (3) which mammography-relevant concepts remain
underrepresented. We show that models trained on mammography data capture more
clinically relevant concepts and align more closely with radiologists'
workflows than models not trained on mammography data. Fine-tuning for
task-specific classification enhances the capture of certain concept categories
(e.g., benign calcifications) but can reduce coverage of others (e.g.,
density-related features), indicating a trade-off between specialisation and
generalisation. Our findings show that Mammo-CLIP Dissect provides insights
into how convolutional neural networks (CNNs) capture mammography-specific
knowledge. By comparing models across training data and fine-tuning regimes, we
reveal how domain-specific training and task-specific adaptation shape concept
learning. Code and concept set are available:
https://github.com/Suaiba/Mammo-CLIP-Dissect.

</details>


### [63] [MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning](https://arxiv.org/abs/2509.21113)
*Sicheng Tao,Jungang Li,Yibo Yan,Junyan Zhang,Yubo Gao,Hanqian Li,ShuHang Xun,Yuxuan Fan,Hong Chen,Jianxiang He,Xuming Hu*

Main category: cs.CV

TL;DR: 本文提出MOSS-ChatV，一种基于动态时间规整（DTW）过程奖励的强化学习框架，用于提升多模态大语言模型在视频理解中的推理一致性，并通过构建MOSS-Video基准验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在视频推理中存在中间推理过程与视频动态不一致的问题，即使最终答案正确也影响可解释性和鲁棒性。

Method: 设计基于DTW的过程奖励函数，利用规则基础的方法对齐推理轨迹与时间标注参考；采用强化学习进行过程监督，并构建MOSS-Video基准包含标注的推理轨迹。

Result: MOSS-ChatV在MOSS-Video测试集上达到87.2%准确率，在MVBench和MMVU等通用视频基准上性能提升，且在Qwen2.5-VL和Phi-2等不同架构上均表现增益，GPT-4o评估显示其推理更一致稳定。

Conclusion: 该框架有效提升了视频推理过程中时序动态与推理链的一致性，具有良好的通用性和应用前景。

Abstract: Video reasoning has emerged as a critical capability for multimodal large
language models (MLLMs), requiring models to move beyond static perception
toward coherent understanding of temporal dynamics in complex scenes. Yet
existing MLLMs often exhibit process inconsistency, where intermediate
reasoning drifts from video dynamics even when the final answer is correct,
undermining interpretability and robustness. To address this issue, we
introduce MOSS-ChatV, a reinforcement learning framework with a Dynamic Time
Warping (DTW)-based process reward. This rule-based reward aligns reasoning
traces with temporally grounded references, enabling efficient process
supervision without auxiliary reward models. We further identify dynamic state
prediction as a key measure of video reasoning and construct MOSS-Video, a
benchmark with annotated reasoning traces, where the training split is used to
fine-tune MOSS-ChatV and the held-out split is reserved for evaluation.
MOSS-ChatV achieves 87.2\% on MOSS-Video (test) and improves performance on
general video benchmarks such as MVBench and MMVU. The framework consistently
yields gains across different architectures, including Qwen2.5-VL and Phi-2,
confirming its broad applicability. Evaluations with GPT-4o-as-judge further
show that MOSS-ChatV produces more consistent and stable reasoning traces.

</details>


### [64] [MotionFlow:Learning Implicit Motion Flow for Complex Camera Trajectory Control in Video Generation](https://arxiv.org/abs/2509.21119)
*Guojun Lei,Chi Wang,Yikai Wang,Hong Li,Ying Song,Weiwei Xu*

Main category: cs.CV

TL;DR: 提出一种新方法，通过将相机和物体运动转化为像素运动，结合稳定扩散网络和语义先验生成符合指定相机轨迹且物体运动一致的视频。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在相机与物体同时运动时保持视频生成的一致性和泛化性，且分离学习易导致相对运动混淆。

Method: 将相机和物体运动统一为像素运动，利用稳定扩散网络学习参考运动图，并结合语义对象先验输入图像到视频网络生成视频。

Result: 实验表明该模型在遵循指定相机轨迹和保持物体运动一致性方面显著优于当前最优方法。

Conclusion: 所提方法有效解决了相机与物体运动耦合下的视频生成难题，实现了更高的一致性和泛化能力。

Abstract: Generating videos guided by camera trajectories poses significant challenges
in achieving consistency and generalizability, particularly when both camera
and object motions are present. Existing approaches often attempt to learn
these motions separately, which may lead to confusion regarding the relative
motion between the camera and the objects. To address this challenge, we
propose a novel approach that integrates both camera and object motions by
converting them into the motion of corresponding pixels. Utilizing a stable
diffusion network, we effectively learn reference motion maps in relation to
the specified camera trajectory. These maps, along with an extracted semantic
object prior, are then fed into an image-to-video network to generate the
desired video that can accurately follow the designated camera trajectory while
maintaining consistent object motions. Extensive experiments verify that our
model outperforms SOTA methods by a large margin.

</details>


### [65] [The Unwinnable Arms Race of AI Image Detection](https://arxiv.org/abs/2509.21135)
*Till Aczel,Lorenzo Vettor,Andreas Plesner,Roger Wattenhofer*

Main category: cs.CV

TL;DR: 本文研究了在图像生成AI快速发展的背景下，判别器在何种条件下处于劣势，发现数据维度和复杂度是两个关键因素。使用Kolmogorov复杂度衡量数据集结构，结果显示简单或高度复杂的图像数据更难被识别为合成图像，而中等复杂度的数据最有利于检测。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的进步，真实与合成图像的界限日益模糊，亟需理解判别器在何时、为何失效，以推动更鲁棒的检测方法发展。

Method: 通过分析数据维度和复杂度（使用Kolmogorov复杂度作为衡量标准）对判别性能的影响，理论结合实证探讨生成器与判别器之间的竞争关系。

Result: 发现极高或极低复杂度的数据集会降低合成图像的可检测性，而中等复杂度数据最有利于判别器发现生成图像的缺陷。维度增加通常有助于检测，但复杂度影响更为复杂。

Conclusion: 判别器在面对中等复杂度、适中维度的数据时表现最佳；极端复杂或简单数据使其处于劣势，揭示了生成与检测模型竞争中的关键平衡点。

Abstract: The rapid progress of image generative AI has blurred the boundary between
synthetic and real images, fueling an arms race between generators and
discriminators. This paper investigates the conditions under which
discriminators are most disadvantaged in this competition. We analyze two key
factors: data dimensionality and data complexity. While increased
dimensionality often strengthens the discriminators ability to detect subtle
inconsistencies, complexity introduces a more nuanced effect. Using Kolmogorov
complexity as a measure of intrinsic dataset structure, we show that both very
simple and highly complex datasets reduce the detectability of synthetic
images; generators can learn simple datasets almost perfectly, whereas extreme
diversity masks imperfections. In contrast, intermediate-complexity datasets
create the most favorable conditions for detection, as generators fail to fully
capture the distribution and their errors remain visible.

</details>


### [66] [WAVECLIP: Wavelet Tokenization for Adaptive-Resolution CLIP](https://arxiv.org/abs/2509.21153)
*Moshe Kimhi,Erez Koifman,Ehud Rivlin,Eli Schwartz,Chaim Baskin*

Main category: cs.CV

TL;DR: WAVECLIP提出了一种基于小波的统一模型，用于CLIP中的自适应分辨率推理，通过多级小波分解支持图像从粗到细的处理，并在推理时根据需要动态调整计算量，实现计算与精度的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统CLIP模型使用固定分辨率的图像分块嵌入，导致计算冗余和缺乏对多分辨率的灵活支持。WAVECLIP旨在通过自适应分辨率推理提升效率并保持高精度。

Method: 采用基于小波的tokenization替代标准patch embedding，引入多级小波分解；在推理时从低分辨率开始，结合置信度门控机制决定是否细化；利用键值缓存和因果跨层注意力重用计算，仅引入新信息。

Result: 在零样本分类任务中验证了方法的有效性，通过轻量级蒸馏即可达到与现有CLIP模型相当的精度，同时显著降低计算开销，并支持单个模型内的动态计算-精度权衡。

Conclusion: WAVECLIP为视觉语言模型提供了高效、灵活的自适应推理框架，能够在不牺牲性能的前提下大幅节省计算资源。

Abstract: We introduce WAVECLIP, a single unified model for adaptive resolution
inference in CLIP, enabled by wavelet-based tokenization. WAVECLIP replaces
standard patch embeddings with a multi-level wavelet decomposition, enabling
the model to process images coarse to fine while naturally supporting multiple
resolutions within the same model. At inference time, the model begins with low
resolution tokens and refines only when needed, using key-value caching and
causal cross-level attention to reuse computation, effectively introducing to
the model only new information when needed. We evaluate WAVECLIP in zero-shot
classification, demonstrating that a simple confidence-based gating mechanism
enables adaptive early exits. This allows users to dynamically choose a
compute-accuracy trade-off using a single deployed model. Our approach requires
only lightweight distillation from a frozen CLIP teacher and achieves
competitive accuracy with significant computational savings.

</details>


### [67] [Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy](https://arxiv.org/abs/2509.21173)
*Aymen Bouguerra,Daniel Montoya,Alexandra Gomez-Villa,Fabio Arnez,Chokri Mraidha*

Main category: cs.CV

TL;DR: 本文研究了量化对CLIP模型在准确率之外的可靠性影响，发现量化可改善欠自信模型的校准性，且即使校准性下降，仍可能提升OOD检测性能，并通过特定QAT方法实现准确性、校准性和OOD鲁棒性的同步提升。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等视觉语言模型在分布外检测等安全任务中展现出零样本泛化能力，但其在实际部署中的计算效率与可靠性（如校准性、鲁棒性）受量化的影响尚不明确，尤其缺乏对多维度可靠性指标的综合评估。

Method: 对多种CLIP模型进行大规模量化评估，涵盖精度、校准性、分布外检测等多个可靠性指标，并分析不同预训练来源对结果的影响，同时探索量化感知训练（QAT）方法的优化效果。

Result: 量化能持续改善通常欠自信模型的校准性，但会恶化过自信模型的校准性；然而，这种校准性下降并不妨碍OOD检测性能的提升；特定QAT方法可同时提升零样本精度、校准性和OOD鲁棒性。

Conclusion: 量化不仅是提升效率的手段，还可作为增强VLM可靠性和鲁棒性的工具，挑战了效率与性能必然权衡的传统观点，为高效可靠部署VLM提供了新视角。

Abstract: The powerful zero-shot generalization capabilities of vision-language models
(VLMs) like CLIP have enabled new paradigms for safety-related tasks such as
out-of-distribution (OOD) detection. However, additional aspects crucial for
the computationally efficient and reliable deployment of CLIP are still
overlooked. In particular, the impact of quantization on CLIP's performance
beyond accuracy remains underexplored. This work presents a large-scale
evaluation of quantization on CLIP models, assessing not only in-distribution
accuracy but a comprehensive suite of reliability metrics and revealing
counterintuitive results driven by pre-training source. We demonstrate that
quantization consistently improves calibration for typically underconfident
pre-trained models, while often degrading it for overconfident variants.
Intriguingly, this degradation in calibration does not preclude gains in other
reliability metrics; we find that OOD detection can still improve for these
same poorly calibrated models. Furthermore, we identify specific
quantization-aware training (QAT) methods that yield simultaneous gains in
zero-shot accuracy, calibration, and OOD robustness, challenging the view of a
strict efficiency-performance trade-off. These findings offer critical insights
for navigating the multi-objective problem of deploying efficient, reliable,
and robust VLMs by utilizing quantization beyond its conventional role.

</details>


### [68] [TABLET: A Large-Scale Dataset for Robust Visual Table Understanding](https://arxiv.org/abs/2509.21205)
*Iñigo Alonso,Imanol Miranda,Eneko Agirre,Mirella Lapata*

Main category: cs.CV

TL;DR: TABLET是一个大规模的视觉表格理解（VTU）数据集，包含400万个样本，涵盖20项任务，基于200万个独特表格，88%保留原始可视化。它提供图像-HTML配对表示、元数据和来源信息，支持对VTU模型进行更鲁棒和可扩展的训练与评估。


<details>
  <summary>Details</summary>
Motivation: 现有VTU数据集多使用合成渲染，缺乏真实世界的复杂性和多样性，且样本固定、无法访问底层结构化数据，限制了模型的泛化能力和可扩展性。

Method: 构建一个包含400万样本的大规模VTU数据集TABLET，基于真实世界表格，保留88%原始可视化，提供图像-HTML配对、元数据和来源追溯，并用于微调如Qwen2.5-VL-7B等视觉语言模型。

Result: 在TABLET上微调的模型在已见和未见的VTU任务上性能提升，并在真实表格可视化上表现出更强的鲁棒性。

Conclusion: TABLET通过保留原始视觉特征和数据可追溯性，为VTU模型的稳健训练和可扩展评估奠定了基础。

Abstract: While table understanding increasingly relies on pixel-only settings where
tables are processed as visual representations, current benchmarks
predominantly use synthetic renderings that lack the complexity and visual
diversity of real-world tables. Additionally, existing visual table
understanding (VTU) datasets offer fixed examples with single visualizations
and pre-defined instructions, providing no access to underlying serialized data
for reformulation. We introduce TABLET, a large-scale VTU dataset with 4
million examples across 20 tasks, grounded in 2 million unique tables where 88%
preserve original visualizations. Each example includes paired image-HTML
representations, comprehensive metadata, and provenance information linking
back to the source datasets. Fine-tuning vision-language models like
Qwen2.5-VL-7B on TABLET improves performance on seen and unseen VTU tasks while
increasing robustness on real-world table visualizations. By preserving
original visualizations and maintaining example traceability in a unified
large-scale collection, TABLET establishes a foundation for robust training and
extensible evaluation of future VTU models.

</details>


### [69] [Learning Conformal Explainers for Image Classifiers](https://arxiv.org/abs/2509.21209)
*Amr Alkhatib,Stephanie Lowry*

Main category: cs.CV

TL;DR: 提出一种基于保形预测的新方法，使用户能够直接控制生成解释的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的特征归因方法在解释图像预测时可能存在鲁棒性差和不忠实于模型推理的问题。

Method: 通过识别一组显著特征子集来保持模型预测，提出四种一致性函数来量化解释与模型预测的一致性程度。

Result: 在六个图像数据集上对五种解释器进行了评估，结果表明FastSHAP在保真度和信息效率方面 consistently 优于其他方法，且基于超像素的一致性度量比基于像素的更有效。

Conclusion: 该方法能有效提升解释的保真度和效率，且无需真实解释进行校准，具有较强实用性。

Abstract: Feature attribution methods are widely used for explaining image-based
predictions, as they provide feature-level insights that can be intuitively
visualized. However, such explanations often vary in their robustness and may
fail to faithfully reflect the reasoning of the underlying black-box model. To
address these limitations, we propose a novel conformal prediction-based
approach that enables users to directly control the fidelity of the generated
explanations. The method identifies a subset of salient features that is
sufficient to preserve the model's prediction, regardless of the information
carried by the excluded features, and without demanding access to ground-truth
explanations for calibration. Four conformity functions are proposed to
quantify the extent to which explanations conform to the model's predictions.
The approach is empirically evaluated using five explainers across six image
datasets. The empirical results demonstrate that FastSHAP consistently
outperforms the competing methods in terms of both fidelity and informational
efficiency, the latter measured by the size of the explanation regions.
Furthermore, the results reveal that conformity measures based on super-pixels
are more effective than their pixel-wise counterparts.

</details>


### [70] [Sigma: Semantically Informative Pre-training for Skeleton-based Sign Language Understanding](https://arxiv.org/abs/2509.21223)
*Muxin Pu,Mei Kuan Lim,Chun Yong Chong,Chen Change Loy*

Main category: cs.CV

TL;DR: 提出Sigma框架，通过基于骨架的统一预训练方法，在手语理解任务中实现语义丰富的跨模态学习，显著提升孤立和连续手语识别及无词表征翻译性能。


<details>
  <summary>Details</summary>
Motivation: 现有手语理解方法存在语义关联弱、局部细节与全局上下文失衡以及跨模态学习效率低的问题，亟需更有效的语义对齐机制。

Method: 设计Sign-aware早期融合机制、分层对齐学习策略和结合对比学习、文本匹配与语言建模的统一预训练框架，增强视觉与文本模态间的深层交互与语义一致性。

Result: 在多个跨语言基准上实现了孤立手语识别、连续手语识别和无词表征翻译的新SOTA结果。

Conclusion: Sigma验证了语义感知预训练的有效性，并证明骨架数据可作为手语理解的独立高效解决方案。

Abstract: Pre-training has proven effective for learning transferable features in sign
language understanding (SLU) tasks. Recently, skeleton-based methods have
gained increasing attention because they can robustly handle variations in
subjects and backgrounds without being affected by appearance or environmental
factors. Current SLU methods continue to face three key limitations: 1) weak
semantic grounding, as models often capture low-level motion patterns from
skeletal data but struggle to relate them to linguistic meaning; 2) imbalance
between local details and global context, with models either focusing too
narrowly on fine-grained cues or overlooking them for broader context; and 3)
inefficient cross-modal learning, as constructing semantically aligned
representations across modalities remains difficult. To address these, we
propose Sigma, a unified skeleton-based SLU framework featuring: 1) a
sign-aware early fusion mechanism that facilitates deep interaction between
visual and textual modalities, enriching visual features with linguistic
context; 2) a hierarchical alignment learning strategy that jointly maximises
agreements across different levels of paired features from different
modalities, effectively capturing both fine-grained details and high-level
semantic relationships; and 3) a unified pre-training framework that combines
contrastive learning, text matching and language modelling to promote semantic
consistency and generalisation. Sigma achieves new state-of-the-art results on
isolated sign language recognition, continuous sign language recognition, and
gloss-free sign language translation on multiple benchmarks spanning different
sign and spoken languages, demonstrating the impact of semantically informative
pre-training and the effectiveness of skeletal data as a stand-alone solution
for SLU.

</details>


### [71] [Evaluating the Evaluators: Metrics for Compositional Text-to-Image Generation](https://arxiv.org/abs/2509.21227)
*Seyed Amir Kasaei,Ali Aghayari,Arash Marioriyad,Niki Sepasian,MohammadAmin Fazli,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 本文研究了文本-图像生成中常用评估指标与人类判断的一致性，发现没有单一指标在所有组合任务中表现一致，不同指标在不同类型任务中优劣各异，强调应谨慎选择评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的文本-图像生成评估指标多依赖自动化方法，但其是否真实反映人类偏好尚不明确，亟需系统评估其有效性。

Method: 对广泛使用的组合式文本-图像评估指标进行了全面研究，超越简单相关性分析，考察其在多种组合挑战下的表现，并比较不同类别指标与人类判断的对齐程度。

Result: 结果显示，无单一指标在所有任务中 consistently 表现最佳；VQA类指标并非始终最优，某些基于嵌入的指标在特定情况下更优；纯图像指标对组合评估贡献甚微。

Conclusion: 应根据具体任务谨慎、透明地选择评估指标，以确保评估可信度及其在生成模型中的有效应用。

Abstract: Text-image generation has advanced rapidly, but assessing whether outputs
truly capture the objects, attributes, and relations described in prompts
remains a central challenge. Evaluation in this space relies heavily on
automated metrics, yet these are often adopted by convention or popularity
rather than validated against human judgment. Because evaluation and reported
progress in the field depend directly on these metrics, it is critical to
understand how well they reflect human preferences. To address this, we present
a broad study of widely used metrics for compositional text-image evaluation.
Our analysis goes beyond simple correlation, examining their behavior across
diverse compositional challenges and comparing how different metric families
align with human judgments. The results show that no single metric performs
consistently across tasks: performance varies with the type of compositional
problem. Notably, VQA-based metrics, though popular, are not uniformly
superior, while certain embedding-based metrics prove stronger in specific
cases. Image-only metrics, as expected, contribute little to compositional
evaluation, as they are designed for perceptual quality rather than alignment.
These findings underscore the importance of careful and transparent metric
selection, both for trustworthy evaluation and for their use as reward models
in generation. Project page is available at
\href{https://amirkasaei.com/eval-the-evals/}{this URL}.

</details>


### [72] [SlideMamba: Entropy-Based Adaptive Fusion of GNN and Mamba for Enhanced Representation Learning in Digital Pathology](https://arxiv.org/abs/2509.21239)
*Shakib Khan,Fariba Dambandkhameneh,Nazim Shaikh,Yao Nie,Raghavan Venugopal,Xiao Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为SlideMamba的新型深度学习框架，结合Mamba架构与图神经网络（GNN），通过熵驱动的自适应融合策略，有效整合局部空间关系和长距离依赖，用于全切片图像（WSI）分析，尤其在基因融合与突变状态预测任务中表现优于多种现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了提升全切片图像（WSI）分析的性能，需要同时建模局部空间结构和长程上下文依赖，而现有方法难以兼顾二者，因此提出一种能够灵活融合局部与全局信息的通用框架。

Method: 提出SlideMamba框架，结合Mamba模块（捕捉长距离依赖）与GNN（建模局部空间交互），并通过基于预测熵的自适应加权机制动态融合双分支输出，以根据任务上下文平衡局部与全局信息贡献。

Result: 在基因融合/突变预测任务中，SlideMamba的PRAUC达到0.751±0.05，显著优于MIL、Trans-MIL、Mamba-only、GNN-only及GAT-Mamba；同时在ROC AUC、敏感性和特异性上也表现出竞争力。

Conclusion: 集成Mamba与GNN并采用熵基自适应融合的架构能更有效地挖掘WSI中的空间与上下文信息，为计算病理学中的空间分辨预测建模提供了有力工具。

Abstract: Advances in computational pathology increasingly rely on extracting
meaningful representations from Whole Slide Images (WSIs) to support various
clinical and biological tasks. In this study, we propose a generalizable deep
learning framework that integrates the Mamba architecture with Graph Neural
Networks (GNNs) for enhanced WSI analysis. Our method is designed to capture
both local spatial relationships and long-range contextual dependencies,
offering a flexible architecture for digital pathology analysis. Mamba modules
excels in capturing long-range global dependencies, while GNNs emphasize
fine-grained short-range spatial interactions. To effectively combine these
complementary signals, we introduce an adaptive fusion strategy that uses an
entropy-based confidence weighting mechanism. This approach dynamically
balances contributions from both branches by assigning higher weight to the
branch with more confident (lower-entropy) predictions, depending on the
contextual importance of local versus global information for different
downstream tasks. We demonstrate the utility of our approach on a
representative task: predicting gene fusion and mutation status from WSIs. Our
framework, SlideMamba, achieves an area under the precision recall curve
(PRAUC) of 0.751 \pm 0.05, outperforming MIL (0.491 \pm 0.042), Trans-MIL (0.39
\pm 0.017), Mamba-only (0.664 \pm 0.063), GNN-only (0.748 \pm 0.091), and a
prior similar work GAT-Mamba (0.703 \pm 0.075). SlideMamba also achieves
competitive results across ROC AUC (0.738 \pm 0.055), sensitivity (0.662 \pm
0.083), and specificity (0.725 \pm 0.094). These results highlight the strength
of the integrated architecture, enhanced by the proposed entropy-based adaptive
fusion strategy, and suggest promising potential for application of
spatially-resolved predictive modeling tasks in computational pathology.

</details>


### [73] [Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets](https://arxiv.org/abs/2509.21245)
*Team Hunyuan3D,:,Bowen Zhang,Chunchao Guo,Haolin Liu,Hongyu Yan,Huiwen Shi,Jingwei Huang,Junlin Yu,Kunhong Li,Linus,Penghao Wang,Qingxiang Lin,Sicong Liu,Xianghui Yang,Yixuan Tang,Yunfei Zhao,Zeqiang Lai,Zhihao Liang,Zibo Zhao*

Main category: cs.CV

TL;DR: Hunyuan3D-Omni是一个基于Hunyuan3D 2.1的统一框架，支持细粒度、可控的3D资产生成，引入点云、体素、边界框和骨骼姿态等多种条件信号，提升生成精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型主要依赖图像或文本条件，缺乏跨模态细粒度控制，限制了可控性和实际应用。

Method: 提出Hunyuan3D-Omni，统一多种输入模态（图像、点云、体素、边界框、骨骼姿态）于单一跨模态架构，并采用渐进式、难度感知的采样策略进行训练。

Result: 实验证明该方法提升了生成准确性、支持几何感知的变换，并增强了在生产流程中的鲁棒性。

Conclusion: Hunyuan3D-Omni通过统一多模态条件控制和优化训练策略，显著提升了3D生成模型的可控性与实用性。

Abstract: Recent advances in 3D-native generative models have accelerated asset
creation for games, film, and design. However, most methods still rely
primarily on image or text conditioning and lack fine-grained, cross-modal
controls, which limits controllability and practical adoption. To address this
gap, we present Hunyuan3D-Omni, a unified framework for fine-grained,
controllable 3D asset generation built on Hunyuan3D 2.1. In addition to images,
Hunyuan3D-Omni accepts point clouds, voxels, bounding boxes, and skeletal pose
priors as conditioning signals, enabling precise control over geometry,
topology, and pose. Instead of separate heads for each modality, our model
unifies all signals in a single cross-modal architecture. We train with a
progressive, difficulty-aware sampling strategy that selects one control
modality per example and biases sampling toward harder signals (e.g., skeletal
pose) while downweighting easier ones (e.g., point clouds), encouraging robust
multi-modal fusion and graceful handling of missing inputs. Experiments show
that these additional controls improve generation accuracy, enable
geometry-aware transformations, and increase robustness for production
workflows.

</details>


### [74] [Learning to Look: Cognitive Attention Alignment with Vision-Language Models](https://arxiv.org/abs/2509.21247)
*Ryan L. Yang,Dipkamal Bhusal,Nidhi Rastogi*

Main category: cs.CV

TL;DR: 提出一种可扩展的框架，利用视觉-语言模型自动生成语义注意力图，通过辅助损失对齐CNN注意力，提升模型泛化能力和认知合理性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖专家标注的概念监督和解释正则化来引导模型注意力，但标注成本高、难以扩展。

Method: 利用视觉-语言模型和自然语言提示自动生成语义注意力图，并引入辅助损失使其与CNN注意力对齐。

Result: 在ColoredMNIST上达到SOTA，在DecoyMNIST上与依赖大量标注的方法性能相当，减少了对捷径的依赖，注意力更符合人类直觉。

Conclusion: 该方法无需人工标注即可提升CNN决策的可靠性和可解释性，具有良好的可扩展性和应用前景。

Abstract: Convolutional Neural Networks (CNNs) frequently "cheat" by exploiting
superficial correlations, raising concerns about whether they make predictions
for the right reasons. Inspired by cognitive science, which highlights the role
of attention in robust human perception, recent methods have sought to guide
model attention using concept-based supervision and explanation regularization.
However, these techniques depend on labor-intensive, expert-provided
annotations, limiting their scalability. We propose a scalable framework that
leverages vision-language models to automatically generate semantic attention
maps using natural language prompts. By introducing an auxiliary loss that
aligns CNN attention with these language-guided maps, our approach promotes
more reliable and cognitively plausible decision-making without manual
annotation. Experiments on challenging datasets, ColoredMNIST and DecoyMNIST,
show that our method achieves state-of-the-art performance on ColorMNIST and
remains competitive with annotation-heavy baselines on DecoyMNIST,
demonstrating improved generalization, reduced shortcut reliance, and model
attention that better reflects human intuition.

</details>


### [75] [Decipher-MR: A Vision-Language Foundation Model for 3D MRI Representations](https://arxiv.org/abs/2509.21249)
*Zhijian Yang,Noel DSouza,Istvan Megyeri,Xiaojian Xu,Amin Honarmandi Shandiz,Farzin Haddadpour,Krisztian Koos,Laszlo Rusko,Emanuele Valeriano,Bharadwaj Swaninathan,Lei Wu,Parminder Bhatia,Taha Kass-Hout,Erhan Bas*

Main category: cs.CV

TL;DR: Decipher-MR是一个基于大规模多区域MRI数据的3D视觉-语言基础模型，结合自监督学习与报告引导的文本监督，支持模块化轻量解码器微调，在多种临床任务中表现出优越的泛化性和性能。


<details>
  <summary>Details</summary>
Motivation: 由于数据稀缺和解剖区域局限，现有基础模型在MRI应用中受限，缺乏可扩展性和通用性。

Method: 提出Decipher-MR，采用3D视觉-语言架构，结合自监督视觉学习与报告文本监督，在20万MRI序列上预训练，并通过冻结编码器加轻量任务解码器实现模块化微调。

Result: 在疾病分类、人口统计预测、解剖定位和跨模态检索等任务中，Decipher-MR consistently 优于现有基础模型和特定任务方法。

Conclusion: Decipher-MR是一个可扩展、多功能的MRI基础模型，有助于推动临床和研究领域的高效AI开发。

Abstract: Magnetic Resonance Imaging (MRI) is a critical medical imaging modality in
clinical diagnosis and research, yet its complexity and heterogeneity pose
challenges for automated analysis, particularly in scalable and generalizable
machine learning applications. While foundation models have revolutionized
natural language and vision tasks, their application to MRI remains limited due
to data scarcity and narrow anatomical focus. In this work, we present
Decipher-MR, a 3D MRI-specific vision-language foundation model trained on a
large-scale dataset comprising 200,000 MRI series from over 22,000 studies
spanning diverse anatomical regions, sequences, and pathologies. Decipher-MR
integrates self-supervised vision learning with report-guided text supervision
to build robust, generalizable representations, enabling effective adaptation
across broad applications. To enable robust and diverse clinical tasks with
minimal computational overhead, Decipher-MR supports a modular design that
enables tuning of lightweight, task-specific decoders attached to a frozen
pretrained encoder. Following this setting, we evaluate Decipher-MR across
diverse benchmarks including disease classification, demographic prediction,
anatomical localization, and cross-modal retrieval, demonstrating consistent
performance gains over existing foundation models and task-specific approaches.
Our results establish Decipher-MR as a scalable and versatile foundation for
MRI-based AI, facilitating efficient development across clinical and research
domains.

</details>


### [76] [Instruction-tuned Self-Questioning Framework for Multimodal Reasoning](https://arxiv.org/abs/2509.21251)
*You-Won Jang,Yu-Jung Heo,Jaeseok Kim,Minsu Lee,Du-Seong Chang,Byoung-Tak Zhang*

Main category: cs.CV

TL;DR: 提出SQ-InstructBLIP模型，通过生成图像感知的子问题和子答案来提升视觉问答任务中的多步推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理需要多步推理的视觉语言理解任务时存在不足，且依赖无法访问视觉信息或内部机制的黑箱大语言模型。

Method: 构建包含Questioner、Answerer和Reasoner的统一架构模型，迭代生成图像感知的子问题与子答案，并利用这些中间信息进行主问题推理。

Result: 实验表明，SQ-InstructBLIP在VQA任务中比先前方法具有更准确的推理能力。

Conclusion: SQ-InstructBLIP通过可解释、可复现的方式有效提升了视觉语言模型在多步推理任务上的表现。

Abstract: The field of vision-language understanding has been actively researched in
recent years, thanks to the development of Large Language Models~(LLMs).
However, it still needs help with problems requiring multi-step reasoning, even
for very simple questions. Recent studies adopt LLMs to tackle this problem by
iteratively generating sub-questions and answers. However, there are
disadvantages such as 1) the fine-grained visual contents of images are not
available using LLMs that cannot read visual information, 2) internal
mechanisms are inaccessible and difficult to reproduce by using black-box LLMs.
To solve these problems, we propose the SQ (Self-Questioning)-InstructBLIP,
which improves inference performance by generating image-aware informative
sub-questions and sub-answers iteratively. The SQ-InstructBLIP, which consists
of a Questioner, Answerer, and Reasoner that share the same architecture.
Questioner and Answerer generate sub-questions and sub-answers to help infer
the main-question, and Reasoner performs reasoning on the main-question
considering the generated sub-question information. Our experiments show that
the proposed method SQ-InstructBLIP, which uses the generated sub-questions as
additional information when solving the VQA task, performs more accurate
reasoning than the previous works.

</details>


### [77] [Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation](https://arxiv.org/abs/2509.21257)
*Seyed Amir Kasaei,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 本文提出了文本到图像生成模型中“幻觉”现象的新定义，将其归类为由模型偏见引起的偏离，并提出包含属性、关系和对象三类的分类体系，以更全面地评估T2I模型中的潜在偏差。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注提示词与生成内容的一致性，忽略了模型在提示之外生成的内容，缺乏对T2I模型中‘幻觉’现象的明确定义和系统分析。

Method: 提出将T2I模型中的幻觉定义为由模型先验知识或偏见导致的、超出输入提示的生成内容，并构建了包含属性、关系和对象三类的幻觉分类体系。

Result: 该框架为评估T2I模型中的幻觉设定了上限，并揭示了隐藏的模型偏差，支持更深入的模型分析。

Conclusion: 通过引入结构化的幻觉分类体系，本文为文本到图像生成模型提供了更丰富的评估基础，有助于识别和缓解模型中的偏见问题。

Abstract: In language and vision-language models, hallucination is broadly understood
as content generated from a model's prior knowledge or biases rather than from
the given input. While this phenomenon has been studied in those domains, it
has not been clearly framed for text-to-image (T2I) generative models. Existing
evaluations mainly focus on alignment, checking whether prompt-specified
elements appear, but overlook what the model generates beyond the prompt. We
argue for defining hallucination in T2I as bias-driven deviations and propose a
taxonomy with three categories: attribute, relation, and object hallucinations.
This framing introduces an upper bound for evaluation and surfaces hidden
biases, providing a foundation for richer assessment of T2I models.

</details>


### [78] [Every Subtlety Counts: Fine-grained Person Independence Micro-Action Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2509.21261)
*Feng-Qi Cui,Jinyang Huang,Anyang Tong,Ziyu Jia,Jie Zhang,Zhi Liu,Dan Guo,Jianwei Lu,Meng Wang*

Main category: cs.CV

TL;DR: 提出了一种独立于个体的通用微动作识别框架，通过分布鲁棒优化学习个体无关表征，在特征和损失层面设计双模块提升模型在真实场景中的泛化性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有微动作识别方法因个体间差异导致相同动作表现不同，难以在真实场景中实现稳健泛化。

Method: 提出Person Independence Universal Micro-action Recognition Framework，包含特征层的时频对齐模块（时间分支用Wasserstein正则化对齐动态轨迹，频率分支引入方差引导扰动）和损失层的组不变正则化损失（通过伪分组模拟未见个体分布，加权边界样本并正则化子组方差）。

Result: 在大规模MA-52数据集上实验表明，该框架在准确性和鲁棒性方面均优于现有方法，能在细粒度条件下实现稳定泛化。

Conclusion: 所提框架有效缓解了个体差异对微动作识别的影响，提升了模型在真实场景中的泛化能力。

Abstract: Micro-action Recognition is vital for psychological assessment and
human-computer interaction. However, existing methods often fail in real-world
scenarios because inter-person variability causes the same action to manifest
differently, hindering robust generalization. To address this, we propose the
Person Independence Universal Micro-action Recognition Framework, which
integrates Distributionally Robust Optimization principles to learn
person-agnostic representations. Our framework contains two plug-and-play
components operating at the feature and loss levels. At the feature level, the
Temporal-Frequency Alignment Module normalizes person-specific motion
characteristics with a dual-branch design: the temporal branch applies
Wasserstein-regularized alignment to stabilize dynamic trajectories, while the
frequency branch introduces variance-guided perturbations to enhance robustness
against person-specific spectral differences. A consistency-driven fusion
mechanism integrates both branches. At the loss level, the Group-Invariant
Regularized Loss partitions samples into pseudo-groups to simulate unseen
person-specific distributions. By up-weighting boundary cases and regularizing
subgroup variance, it forces the model to generalize beyond easy or frequent
samples, thus enhancing robustness to difficult variations. Experiments on the
large-scale MA-52 dataset demonstrate that our framework outperforms existing
methods in both accuracy and robustness, achieving stable generalization under
fine-grained conditions.

</details>


### [79] [Dense Semantic Matching with VGGT Prior](https://arxiv.org/abs/2509.21263)
*Songlin Yang,Tianyi Wei,Yushi Lan,Zeqi Xiao,Anyi Rao,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D几何基础模型VGGT的语义匹配方法，通过重用早期特征、微调后期特征并引入语义头和循环一致训练策略，在数据稀缺情况下实现了跨实例像素级语义匹配，显著提升了几何感知能力和匹配可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有语义匹配方法存在几何模糊和最近邻规则忽略跨图像不可见性与流形保持的问题，且依赖2D特征缺乏泛化能力，需要更鲁棒的几何感知描述符和整体密集匹配机制。

Method: 基于VGGT模型，保留其早期特征阶段，微调后期阶段，并添加语义头以实现双向对应；采用循环一致训练、合成数据增强和渐进式训练策略来适应语义匹配任务并缓解标注数据稀缺问题。

Result: 实验表明该方法在几何感知、匹配可靠性和流形保持方面优于先前方法，尤其在对称结构和遮挡场景下表现更优。

Conclusion: 通过适配3D几何基础模型VGGT并设计针对性训练策略，本文成功将原本用于单实例多视角几何匹配的模型应用于跨实例语义匹配，为语义匹配提供了新的有效范式。

Abstract: Semantic matching aims to establish pixel-level correspondences between
instances of the same category and represents a fundamental task in computer
vision. Existing approaches suffer from two limitations: (i) Geometric
Ambiguity: Their reliance on 2D foundation model features (e.g., Stable
Diffusion, DINO) often fails to disambiguate symmetric structures, requiring
extra fine-tuning yet lacking generalization; (ii) Nearest-Neighbor Rule: Their
pixel-wise matching ignores cross-image invisibility and neglects manifold
preservation. These challenges call for geometry-aware pixel descriptors and
holistic dense correspondence mechanisms. Inspired by recent advances in 3D
geometric foundation models, we turn to VGGT, which provides geometry-grounded
features and holistic dense matching capabilities well aligned with these
needs. However, directly transferring VGGT is challenging, as it was originally
designed for geometry matching within cross views of a single instance,
misaligned with cross-instance semantic matching, and further hindered by the
scarcity of dense semantic annotations. To address this, we propose an approach
that (i) retains VGGT's intrinsic strengths by reusing early feature stages,
fine-tuning later ones, and adding a semantic head for bidirectional
correspondences; and (ii) adapts VGGT to the semantic matching scenario under
data scarcity through cycle-consistent training strategy, synthetic data
augmentation, and progressive training recipe with aliasing artifact
mitigation. Extensive experiments demonstrate that our approach achieves
superior geometry awareness, matching reliability, and manifold preservation,
outperforming previous baselines.

</details>


### [80] [MedVSR: Medical Video Super-Resolution with Cross State-Space Propagation](https://arxiv.org/abs/2509.21265)
*Xinyu Liu,Guolei Sun,Cheng Wang,Yixuan Yuan,Ender Konukoglu*

Main category: cs.CV

TL;DR: 提出了一种针对医学视频超分辨率的框架MedVSR，通过交叉状态空间传播和内部状态空间重建模块有效解决低分辨率医学视频中的对齐困难、伪影问题，显著提升重建性能。


<details>
  <summary>Details</summary>
Motivation: 低分辨率医学视频存在相机抖动、噪声和帧间突变等问题，导致现有视频超分辨率模型难以准确对齐和恢复细节，且易引入误导医生的伪影。

Method: 提出MedVSR框架，包括Cross State-Space Propagation（CSSP）用于改进跨帧对齐，以及Inner State-Space Reconstruction（ISSR）模块用于增强组织结构并减少伪影，结合长距离空间特征学习与大核短程信息聚合。

Result: 在四个不同医学场景数据集上实验表明，MedVSR在重建性能和效率方面均显著优于现有视频超分辨率模型。

Conclusion: MedVSR有效解决了医学视频超分辨率中的关键挑战，在真实临床应用中具有高潜力。

Abstract: High-resolution (HR) medical videos are vital for accurate diagnosis, yet are
hard to acquire due to hardware limitations and physiological constraints.
Clinically, the collected low-resolution (LR) medical videos present unique
challenges for video super-resolution (VSR) models, including camera shake,
noise, and abrupt frame transitions, which result in significant optical flow
errors and alignment difficulties. Additionally, tissues and organs exhibit
continuous and nuanced structures, but current VSR models are prone to
introducing artifacts and distorted features that can mislead doctors. To this
end, we propose MedVSR, a tailored framework for medical VSR. It first employs
Cross State-Space Propagation (CSSP) to address the imprecise alignment by
projecting distant frames as control matrices within state-space models,
enabling the selective propagation of consistent and informative features to
neighboring frames for effective alignment. Moreover, we design an Inner
State-Space Reconstruction (ISSR) module that enhances tissue structures and
reduces artifacts with joint long-range spatial feature learning and
large-kernel short-range information aggregation. Experiments across four
datasets in diverse medical scenarios, including endoscopy and cataract
surgeries, show that MedVSR significantly outperforms existing VSR models in
reconstruction performance and efficiency. Code released at
https://github.com/CUHK-AIM-Group/MedVSR.

</details>


### [81] [MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources](https://arxiv.org/abs/2509.21268)
*Sicong Leng,Jing Wang,Jiaxi Li,Hao Zhang,Zhiqiang Hu,Boqiang Zhang,Yuming Jiang,Hang Zhang,Xin Li,Lidong Bing,Deli Zhao,Wei Lu,Yu Rong,Aixin Sun,Shijian Lu*

Main category: cs.CV

TL;DR: 本文提出了方差感知采样（VAS）方法，通过提升奖励方差来稳定强化学习中的策略优化，并发布了大规模、高质量的多模态推理数据集与开源模型，有效提升了长链思维推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有大規模多模態推理模型受限於高質量長鏈思維數據的缺乏以及強化學習後訓練中算法不穩定的問題，特別是低獎勵方差導致梯度消失，影響收斂。

Method: 提出方差感知採樣（VAS），基於結合結果方差與路徑多樣性的方差促進分數（VPS）進行數據選擇；同時構建約160萬條長鏈冷啟動數據和1.5萬個強化學習問答對，並開源全流程代碼與多尺度模型。

Result: 實驗表明VAS與所構建數據能顯著提升多模態推理模型在數學任務上的表現；消融研究驗證了各組件貢獻；理論分析證明獎勵方差下界與策略梯度大小相關，VAS有助於實現該理論保證。

Conclusion: VAS有效緩解了強化學習中因獎勵方差低導致的優化困難，所發布的高質量數據與開源資源為多模態推理提供了標準化基線與可復現基礎。

Abstract: Large multimodal reasoning models have achieved rapid progress, but their
advancement is constrained by two major limitations: the absence of open,
large-scale, high-quality long chain-of-thought (CoT) data, and the instability
of reinforcement learning (RL) algorithms in post-training. Group Relative
Policy Optimization (GRPO), the standard framework for RL fine-tuning, is prone
to gradient vanishing when reward variance is low, which weakens optimization
signals and impairs convergence. This work makes three contributions: (1) We
propose Variance-Aware Sampling (VAS), a data selection strategy guided by
Variance Promotion Score (VPS) that combines outcome variance and trajectory
diversity to promote reward variance and stabilize policy optimization. (2) We
release large-scale, carefully curated resources containing ~1.6M long CoT
cold-start data and ~15k RL QA pairs, designed to ensure quality, difficulty,
and diversity, along with a fully reproducible end-to-end training codebase.
(3) We open-source a family of multimodal reasoning models in multiple scales,
establishing standardized baselines for the community. Experiments across
mathematical reasoning benchmarks demonstrate the effectiveness of both the
curated data and the proposed VAS. Comprehensive ablation studies and analyses
provide further insight into the contributions of each component. In addition,
we theoretically establish that reward variance lower-bounds the expected
policy gradient magnitude, with VAS serving as a practical mechanism to realize
this guarantee. Our code, data, and checkpoints are available at
https://github.com/LengSicong/MMR1.

</details>


### [82] [A Sentinel-3 foundation model for ocean colour](https://arxiv.org/abs/2509.21273)
*Geoffrey Dawson,Remy Vandaele,Andrew Taylor,David Moffat,Helen Tamura-Wicks,Sarah Jackson,Rosie Lickorish,Paolo Fraccaro,Hywel Williams,Chunbo Luo,Anne Jones*

Main category: cs.CV

TL;DR: 提出了一种基于Prithvi-EO Vision Transformer架构的新型地理空间AI基础模型，用于海洋遥感任务，通过自监督预训练和少量标注数据微调，在叶绿素浓度和海洋初级生产力估算中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 海洋科学中标签数据稀疏且获取成本高，传统模型难以充分利用未标注数据，因此需要能有效利用大规模无标签遥感数据的基础模型。

Method: 采用Prithvi-EO Vision Transformer架构，对Sentinel-3 OLCI数据进行重建预训练，随后在两个海洋遥感下游任务（叶绿素浓度量化和海洋初级生产估计）上进行微调评估。

Result: 该模型在利用少量高质量标签数据的情况下，显著优于现有基线模型，能够准确捕捉海洋颜色的精细空间模式，并与实地观测点匹配良好。

Conclusion: 新一代地理空间AI基础模型有望为海洋生态系统及其在全球气候过程中的作用提供更稳健、数据驱动的洞察。

Abstract: Artificial Intelligence (AI) Foundation models (FMs), pre-trained on massive
unlabelled datasets, have the potential to drastically change AI applications
in ocean science, where labelled data are often sparse and expensive to
collect. In this work, we describe a new foundation model using the Prithvi-EO
Vision Transformer architecture which has been pre-trained to reconstruct data
from the Sentinel-3 Ocean and Land Colour Instrument (OLCI). We evaluate the
model by fine-tuning on two downstream marine earth observation tasks. We first
assess model performance compared to current baseline models used to quantify
chlorophyll concentration. We then evaluate the FMs ability to refine remote
sensing-based estimates of ocean primary production. Our results demonstrate
the utility of self-trained FMs for marine monitoring, in particular for making
use of small amounts of high quality labelled data and in capturing detailed
spatial patterns of ocean colour whilst matching point observations. We
conclude that this new generation of geospatial AI models has the potential to
provide more robust, data-driven insights into ocean ecosystems and their role
in global climate processes.

</details>


### [83] [Does FLUX Already Know How to Perform Physically Plausible Image Composition?](https://arxiv.org/abs/2509.21278)
*Shilin Lu,Zhuming Lian,Zihan Zhou,Shaocong Zhang,Chen Zhao,Adams Wai-Kin Kong*

Main category: cs.CV

TL;DR: 提出了一种无需训练的图像合成框架SHINE，利用预训练适配器和新的损失函数，在复杂光照和高分辨率场景下实现高质量、无缝的对象插入。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂光照（如阴影、反射）和多样化高分辨率输入时表现不佳，且依赖潜在空间反演或脆弱的注意力操作，导致对象姿态不自然或结果不稳定。

Method: 提出SHINE框架，引入流形引导的锚点损失，结合预训练定制化适配器（如IP-Adapter）来保持主体保真度和背景完整性；设计降质抑制引导和自适应背景融合策略以消除伪影和接缝。

Result: 在新构建的ComplexCompo和DreamEditBench数据集上实验表明，SHINE在DINOv2等指标及DreamSim、ImageReward等人对齐评分中达到SOTA性能。

Conclusion: SHINE为高质量图像合成提供了一种无需训练、鲁棒且高效的方法，尤其适用于复杂真实场景下的对象插入任务。

Abstract: Image composition aims to seamlessly insert a user-specified object into a
new scene, but existing models struggle with complex lighting (e.g., accurate
shadows, water reflections) and diverse, high-resolution inputs. Modern
text-to-image diffusion models (e.g., SD3.5, FLUX) already encode essential
physical and resolution priors, yet lack a framework to unleash them without
resorting to latent inversion, which often locks object poses into contextually
inappropriate orientations, or brittle attention surgery. We propose SHINE, a
training-free framework for Seamless, High-fidelity Insertion with Neutralized
Errors. SHINE introduces manifold-steered anchor loss, leveraging pretrained
customization adapters (e.g., IP-Adapter) to guide latents for faithful subject
representation while preserving background integrity. Degradation-suppression
guidance and adaptive background blending are proposed to further eliminate
low-quality outputs and visible seams. To address the lack of rigorous
benchmarks, we introduce ComplexCompo, featuring diverse resolutions and
challenging conditions such as low lighting, strong illumination, intricate
shadows, and reflective surfaces. Experiments on ComplexCompo and
DreamEditBench show state-of-the-art performance on standard metrics (e.g.,
DINOv2) and human-aligned scores (e.g., DreamSim, ImageReward, VisionReward).
Code and benchmark will be publicly available upon publication.

</details>


### [84] [Quantized Visual Geometry Grounded Transformer](https://arxiv.org/abs/2509.21302)
*Weilun Feng,Haotong Qin,Mingqiang Wu,Chuanguang Yang,Yuqi Li,Xiangqi Li,Zhulin An,Libo Huang,Yulun Zhang,Michele Magno,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文提出了首个针对视觉几何接地Transformer（VGGTs）的量化框架QuantVGGT，通过双平滑细粒度量化和噪声过滤多样化采样技术，有效解决了大规模3D重建模型在后训练量化中的重尾激活分布和校准不稳定性问题，在4位量化下实现了3.7倍内存压缩和2.5倍加速，同时保持98%以上的精度。


<details>
  <summary>Details</summary>
Motivation: 现有的后训练量化方法在处理十亿参数规模的VGGTs时面临重尾激活分布和多视角数据导致的校准样本选择不稳定问题，难以直接应用，因此需要专门针对VGGTs设计高效的量化方案以支持实际部署。

Method: 提出QuantVGGT框架，包含两项关键技术：一是双平滑细粒度量化，结合全局Hadamard旋转和局部通道平滑来缓解激活分布的重尾性和通道间方差；二是噪声过滤多样化采样，利用深层统计信息过滤异常值并构建帧感知的多样化校准簇以稳定量化范围。

Result: 在多个基准和不同比特宽度下，QuantVGGT均达到最先进水平，显著优于现有通用量化方法；在真实硬件上，4位量化实现3.7倍内存减少和2.5倍推理加速，重建精度保持在全精度模型的98%以上。

Conclusion: QuantVGGT为大规模VGGTs提供了高效、稳定的量化解决方案，显著提升了模型在资源受限场景下的实用性，推动了基于学习的3D重建模型在实际应用中的部署潜力。

Abstract: Learning-based 3D reconstruction models, represented by Visual Geometry
Grounded Transformers (VGGTs), have made remarkable progress with the use of
large-scale transformers. Their prohibitive computational and memory costs
severely hinder real-world deployment. Post-Training Quantization (PTQ) has
become a common practice for compressing and accelerating models. However, we
empirically observe that PTQ faces unique obstacles when compressing
billion-scale VGGTs: the data-independent special tokens induce heavy-tailed
activation distributions, while the multi-view nature of 3D data makes
calibration sample selection highly unstable. This paper proposes the first
Quantization framework for VGGTs, namely QuantVGGT. This mainly relies on two
technical contributions: First, we introduce Dual-Smoothed Fine-Grained
Quantization, which integrates pre-global Hadamard rotation and post-local
channel smoothing to mitigate heavy-tailed distributions and inter-channel
variance robustly. Second, we design Noise-Filtered Diverse Sampling, which
filters outliers via deep-layer statistics and constructs frame-aware diverse
calibration clusters to ensure stable quantization ranges. Comprehensive
experiments demonstrate that QuantVGGT achieves the state-of-the-art results
across different benchmarks and bit-width, surpassing the previous
state-of-the-art generic quantization method with a great margin. We highlight
that our 4-bit QuantVGGT can deliver a 3.7$\times$ memory reduction and
2.5$\times$ acceleration in real-hardware inference, while maintaining
reconstruction accuracy above 98\% of its full-precision counterpart. This
demonstrates the vast advantages and practicality of QuantVGGT in
resource-constrained scenarios. Our code is released in
https://github.com/wlfeng0509/QuantVGGT.

</details>


### [85] [NewtonGen: Physics-Consistent and Controllable Text-to-Video Generation via Neural Newtonian Dynamics](https://arxiv.org/abs/2509.21309)
*Yu Yuan,Xijun Wang,Tharindu Wickremasinghe,Zeeshan Nadir,Bole Ma,Stanley H. Chan*

Main category: cs.CV

TL;DR: 提出NewtonGen框架，结合数据驱动合成与可学习物理原理，通过引入可训练的神经牛顿动力学（NND）实现物理一致且可控的视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成模型在物理一致性和可控性方面存在瓶颈，主要表现为不真实运动和缺乏对初始条件的精确控制，原因在于模型仅从外观学习运动分布，缺乏对底层动力学的理解。

Method: 提出NewtonGen框架，核心是可训练的神经牛顿动力学（NND），将数据先验与动力学引导相结合，在视频生成过程中注入潜在的动力学约束。

Result: NewtonGen能够生成物理上更一致的视频，并支持在不同初始条件下进行精确参数控制，显著改善了物体运动的真实性和稳定性。

Conclusion: 通过融合学习物理原理与数据驱动方法，NewtonGen有效提升了大规模文本到视频生成的物理合理性和可控性，为未来视频生成模型的设计提供了新方向。

Abstract: A primary bottleneck in large-scale text-to-video generation today is
physical consistency and controllability. Despite recent advances,
state-of-the-art models often produce unrealistic motions, such as objects
falling upward, or abrupt changes in velocity and direction. Moreover, these
models lack precise parameter control, struggling to generate physically
consistent dynamics under different initial conditions. We argue that this
fundamental limitation stems from current models learning motion distributions
solely from appearance, while lacking an understanding of the underlying
dynamics. In this work, we propose NewtonGen, a framework that integrates
data-driven synthesis with learnable physical principles. At its core lies
trainable Neural Newtonian Dynamics (NND), which can model and predict a
variety of Newtonian motions, thereby injecting latent dynamical constraints
into the video generation process. By jointly leveraging data priors and
dynamical guidance, NewtonGen enables physically consistent video synthesis
with precise parameter control.

</details>


### [86] [SD3.5-Flash: Distribution-Guided Distillation of Generative Flows](https://arxiv.org/abs/2509.21318)
*Hmrishav Bandyopadhyay,Rahim Entezari,Jim Scott,Reshinth Adithyan,Yi-Zhe Song,Varun Jampani*

Main category: cs.CV

TL;DR: SD3.5-Flash 是一种高效的少步蒸馏框架，可在消费级设备上实现高质量图像生成，支持从手机到桌面端的广泛部署。


<details>
  <summary>Details</summary>
Motivation: 为了将高性能的生成模型压缩并适配到资源受限的消费设备上，实现快速、低内存占用的图像生成。

Method: 通过重构分布匹配目标函数进行知识蒸馏，引入‘时间步共享’减少梯度噪声，采用‘分步微调’提升提示对齐，并结合文本编码器重构和专用量化等优化。

Result: 在多种硬件配置上实现了快速生成和高效内存利用，在大规模用户研究中表现优于现有少步生成方法。

Conclusion: SD3.5-Flash 成功实现了高质量、少步数、低资源消耗的图像生成，推动了生成式AI在普通设备上的普及。

Abstract: We present SD3.5-Flash, an efficient few-step distillation framework that
brings high-quality image generation to accessible consumer devices. Our
approach distills computationally prohibitive rectified flow models through a
reformulated distribution matching objective tailored specifically for few-step
generation. We introduce two key innovations: "timestep sharing" to reduce
gradient noise and "split-timestep fine-tuning" to improve prompt alignment.
Combined with comprehensive pipeline optimizations like text encoder
restructuring and specialized quantization, our system enables both rapid
generation and memory-efficient deployment across different hardware
configurations. This democratizes access across the full spectrum of devices,
from mobile phones to desktop computers. Through extensive evaluation including
large-scale user studies, we demonstrate that SD3.5-Flash consistently
outperforms existing few-step methods, making advanced generative AI truly
accessible for practical deployment.

</details>


### [87] [Copycats: the many lives of a publicly available medical imaging dataset](https://arxiv.org/abs/2402.06353)
*Amelia Jiménez-Sánchez,Natalia-Rozalia Avlona,Dovile Juodelyte,Théo Sourget,Caroline Vang-Larsen,Anna Rogers,Hubert Dariusz Zając,Veronika Cheplygina*

Main category: cs.CV

TL;DR: 本文分析了社区贡献平台（如Kaggle和HuggingFace）上公开的医学影像数据集，指出当前治理模式在数据共享、文档记录和维护方面存在缺陷，影响AI医疗算法的质量与公平性。


<details>
  <summary>Details</summary>
Motivation: 开放医学影像数据集对提升人工智能在医疗中的应用至关重要，但现有社区平台在数据质量与管理实践方面存在不足，可能导致有害的下游影响，因此需要系统评估并改进当前的数据治理模式。

Method: 通过对社区贡献平台上公开的机器学习医学影像数据集进行多维度分析，比较其在数据共享、文档记录、维护、许可证、持久标识符和元数据等方面的现状，并与计算机视觉数据集进行对比。

Result: 发现多数医学影像数据集存在许可证不明确、缺乏持久存储与标识符、重复数据、元数据缺失等问题，且不同平台间存在显著差异；同时指出医学影像数据集因用途敏感，管理不当可能带来更严重的潜在风险。

Conclusion: 当前社区贡献平台在医学影像数据集管理方面未能满足推荐实践要求，需加强数据治理以确保AI在医疗应用中的准确性、鲁棒性和公平性，推动负责任的数据策展。

Abstract: Medical Imaging (MI) datasets are fundamental to artificial intelligence in
healthcare. The accuracy, robustness, and fairness of diagnostic algorithms
depend on the data (and its quality) used to train and evaluate the models. MI
datasets used to be proprietary, but have become increasingly available to the
public, including on community-contributed platforms (CCPs) like Kaggle or
HuggingFace. While open data is important to enhance the redistribution of
data's public value, we find that the current CCP governance model fails to
uphold the quality needed and recommended practices for sharing, documenting,
and evaluating datasets. In this paper, we conduct an analysis of publicly
available machine learning datasets on CCPs, discussing datasets' context, and
identifying limitations and gaps in the current CCP landscape. We highlight
differences between MI and computer vision datasets, particularly in the
potentially harmful downstream effects from poor adoption of recommended
dataset management practices. We compare the analyzed datasets across several
dimensions, including data sharing, data documentation, and maintenance. We
find vague licenses, lack of persistent identifiers and storage, duplicates,
and missing metadata, with differences between the platforms. Our research
contributes to efforts in responsible data curation and AI algorithms for
healthcare.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [88] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 提出一种基于大语言模型的反事实生成框架，通过调整外交事件的叙述方式，在保持核心事实不变的前提下，成功将公众情绪从负面转为中性或正面，实验显示该方法有70%的成功率。


<details>
  <summary>Details</summary>
Motivation: 传统测量和引导公众情绪的方法耗时耗力，且缺乏前瞻性分析能力，难以满足现代外交传播的需求。

Method: 构建包含外交事件描述及其公众讨论的数据集，训练语言模型预测公众反应；基于传播理论和专家意见确定可修改的文本特征，设计反事实生成算法，利用大语言模型生成叙述变体以优化情绪效果。

Result: 该框架在实验中实现了70%的成功率，能有效将负面公众情绪转向中性或正面，验证了叙述框架调整对情绪引导的有效性。

Conclusion: 该框架可为外交人员、政策制定者和传播专家提供数据驱动的叙事优化工具，有助于提升外交沟通效果和国家形象塑造。

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [89] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 提出了一种说话人风格感知的音素锚定框架，用于跨语言语音情感识别，通过在说话人和音素空间中进行双空间锚定，提升跨语言情感迁移效果。


<details>
  <summary>Details</summary>
Motivation: 跨语言语音情感识别因不同语言间的语音变异性及说话人表达风格差异而具有挑战性，需有效对齐不同语言和说话人的情感外化模式。

Method: 通过基于图的聚类构建情感特定的说话人社区以捕捉共享特征，并在说话人空间和音素空间进行双空间锚定，实现跨语言情感表达对齐。

Result: 在MSP-Podcast（英语）和BIIC-Podcast（台湾普通话）数据集上的实验表明，该方法优于现有基线模型，展现出更好的泛化能力。

Conclusion: 所提出的框架能有效提升跨语言语音情感识别性能，揭示了跨语言情感表征中的共性。

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [90] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: 本文提出了CFDLLMBench，一个用于评估大语言模型在计算流体动力学（CFD）中自动化数值实验能力的基准测试套件，包含三个部分：CFDQuery、CFDCodeBench和FoamBench，旨在全面评估LLM在CFD知识、物理推理和工作流实现方面的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然语言处理任务中表现出色，但其在复杂物理系统数值实验自动化中的应用仍待探索。计算流体动力学作为计算科学的重要工具，为评估LLM的科学能力提供了一个具有挑战性的测试平台。

Method: 设计了一个包含三个组件的基准测试套件CFDLLMBench：CFDQuery评估研究生级别的CFD知识，CFDCodeBench评估数值与物理推理能力，FoamBench评估依赖上下文的CFD工作流实现能力。该基准基于真实CFD实践，结合任务分类体系和严格评估框架。

Result: CFDLLMBench能够对LLM在代码可执行性、解的准确性和数值收敛行为等方面的表现进行可重复的量化评估，验证了其在CFD相关任务中的潜力与局限。

Conclusion: CFDLLMBench为评估和推动大语言模型在复杂物理系统数值实验自动化中的应用提供了坚实基础，有助于未来LLM在科学计算领域的进一步发展。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [91] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: 本研究评估了多种机器学习方法在区分ChatGPT-3.5生成文本与人类撰写研究摘要方面的性能，发现DistilBERT表现最佳，而基于投票的集成模型未能超越单一最优模型，表明在AI文本检测中，高质量的单个Transformer模型优于简单的模型集成。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（如ChatGPT）的广泛应用，AI生成文本与人类文本的界限日益模糊，对学术诚信、知识产权和信息可信度构成挑战，亟需可靠的AI文本检测技术。

Method: 研究使用包含250对来自多领域研究摘要的数据集，比较了经典机器学习方法（如逻辑回归结合词袋、POS、TF-IDF特征）与基于Transformer的方法（包括BERT、DistilBERT、自定义BERT分类器及LSTM-Ngram模型），并测试了三种最佳模型的多数投票集成效果。

Result: DistilBERT在检测性能上整体最优，逻辑回归和BERT-Custom表现稳健且均衡，LSTM-Ngram和BERT-Ngram方法相对落后；三者集成模型未能超越DistilBERT，说明单一高性能模型优于简单集成。

Conclusion: 当前基于Transformer的模型在AI文本检测中最具潜力，未来应构建更丰富的大数据集以推动更鲁棒的检测框架发展，应对不断进步的生成式AI。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [92] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: ConceptViz是一个可视化分析系统，通过“识别=>解释=>验证”流程帮助用户探索大语言模型中的概念，提升稀疏自编码器特征与人类可理解概念之间的对齐性。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAE）虽能提取大语言模型的可解释特征，但这些特征难以直接对应人类概念，解释过程繁琐费力。

Method: 提出ConceptViz系统，采用新颖的‘识别=>解释=>验证’流程，支持用户以感兴趣的概念查询SAE，交互式探索概念与特征的对齐，并通过模型行为验证对应关系。

Result: 通过两个使用场景和一项用户研究表明，ConceptViz能有效提升对LLM中概念表示的发现与验证效率。

Conclusion: ConceptViz增强了大语言模型特征的可解释性研究，有助于研究人员构建更准确的心理模型。

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [93] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: 提出SKILL-RAG方法，利用模型的自知能力通过强化学习框架筛选有用检索内容，提升RAG性能。


<details>
  <summary>Details</summary>
Motivation: 由于检索系统可能返回无关内容，导致模型产生幻觉，因此需要识别和过滤无用信息，以提升RAG性能。关键在于理解模型的“已知”与“未知”（即自知能力）。

Method: 设计基于强化学习的训练框架，从模型中显式激发其自知能力，并在句子级别粒度上过滤无关内容，保留有用知识，从而决定哪些检索文档有助于回答问题。

Result: 在Llama2-7B和Qwen3-8B上多个问答基准测试中，SKILL-RAG不仅提升了生成质量，还显著减少了输入文档数量。

Conclusion: 自知能力在指导高质量检索选择中具有重要作用，SKILL-RAG有效提升了RAG系统的性能与效率。

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [94] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: 提出Emo-FiLM框架，实现基于LLM的文本到语音中词级别的细粒度情感控制。


<details>
  <summary>Details</summary>
Motivation: 现有情感TTS系统多依赖句子级别的情感控制，难以捕捉句子内部的情感动态变化。

Method: 通过emotion2vec提取帧级特征并对其对齐到词级别，利用FiLM层调制文本嵌入，实现词级别情感控制；构建FEDD数据集用于评估细粒度情感动态。

Result: 实验表明，Emo-FiLM在全局和细粒度情感控制任务上均优于现有方法。

Conclusion: Emo-FiLM能有效建模语音合成中的细粒度情感动态，具有良好的通用性和表现力。

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [95] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 提出一种基于用户模拟器的训练-推理框架（USB-Rec），通过强化学习构建偏好优化数据集并在推理阶段引入自增强策略，提升大模型在对话推荐中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的对话推荐系统多关注如何利用模型的总结与分析能力，忽视了模型训练问题，导致潜力未被充分挖掘。

Method: 设计基于大语言模型的偏好优化（PO）数据集构建策略用于强化学习训练，并在推理阶段提出自增强策略（SES），形成完整的训练-推理框架USB-Rec。

Result: 在多个数据集上的实验表明，该方法 consistently 优于之前的最先进方法。

Conclusion: USB-Rec框架通过引入训练机制和推理优化策略，有效提升了大语言模型在对话推荐任务中的表现，验证了训练与推理协同的重要性。

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [96] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 提出了Conformal Importance Summarization，首个结合保重要性摘要生成与严格覆盖率保证的框架，通过共形预测实现对关键内容的可靠覆盖。


<details>
  <summary>Details</summary>
Motivation: 现有自动摘要系统在高风险领域缺乏对关键内容包含的可靠保证。

Method: 利用共形预测校准句子级重要性得分阈值，实现可指定覆盖率和召回率的抽取式摘要，且方法与模型无关，仅需小型校准集。

Result: 在标准摘要基准上验证了该方法能达到理论保证的信息覆盖率。

Conclusion: Conformal Importance Summarization 可与现有技术结合，为关键应用中AI摘要工具的安全部署提供可控、可靠的解决方案。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [97] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 本文提出了SwasthLLM，一种统一的、零样本、跨语言多任务学习框架，用于在英语、印地语和孟加拉语中进行医疗诊断，无需语言特定微调，在低资源语言下表现出强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于低资源语言中缺乏标注医学数据以及不同人群间的语言差异，多语言医疗环境下的临床文本自动疾病诊断仍具挑战性。

Method: 采用多语言XLM-RoBERTa编码器，结合语言感知注意力机制、Siamese对比学习模块、翻译一致性模块和对比投影头，并通过多任务学习联合优化疾病分类、翻译对齐和对比学习目标，使用MAML提升模型快速适应能力。

Result: 在监督设置下达到97.22%准确率和97.17% F1分数；零样本场景下，印地语准确率为92.78%，孟加拉语为73.33%。

Conclusion: SwasthLLM在无需语言特定微调的情况下，实现了跨语言医学诊断的高性能，尤其在低资源语言中展现出良好的泛化能力。

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [98] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: ShortCheck是一个用于检测短视频平台（如TikTok）中值得核查的虚假信息的模块化、仅推理的自动化管道，集成了多种多模态技术，在多语言环境中表现出良好的性能。


<details>
  <summary>Details</summary>
Motivation: 短视频平台的内容具有多模态、动态和噪声大的特点，给 misinformation 检测带来挑战，需要有效工具辅助人工事实核查。

Method: 提出ShortCheck系统，集成语音转录、OCR、物体检测、深度伪造检测、视频到文本摘要和声明验证等模块，采用无需训练的推理流程。

Result: 在两个手动标注的多语言TikTok视频数据集上验证，加权F1分数超过70%。

Conclusion: ShortCheck能有效识别值得核查的短视频内容，减轻人工核查负担，具备实际应用潜力。

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [99] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 本文提出了动态推理链（DS-MoE），通过深度专业化的混合专家系统实现根据输入复杂度自适应调整计算深度，提升了效率、准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer对所有输入采用相同的处理深度，导致资源浪费并限制了复杂推理能力。需要一种能根据输入复杂度动态调整计算深度的机制。

Method: 提出DS-MoE框架，将MoE从宽度扩展到深度专业化，设计针对不同推理层次的专家模块，并通过学习路由网络动态构建推理链，在The Pile数据集上进行训练与评估。

Result: 相比固定深度模型，DS-MoE实现了最高16%的计算节省和35%的推理加速，在复杂多步推理任务上准确率提升2.8%，且推理路径更具可解释性。

Conclusion: DS-MoE通过深度专业化和动态路由，显著提升了大模型在效率、推理质量和可解释性方面的表现，是自适应神经架构的重要进展。

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [100] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: 本文提出了MARS（多智能体评审系统），一种基于角色协作的推理框架，通过作者、评审者和元评审者的分工，在保持推理质量的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在推理能力上存在局限，多智能体辩论（MAD）虽有效但计算成本高，因此需要一种更高效的协作推理方法。

Method: MARS框架包含三个角色：作者生成初始解，评审者独立提出意见，元评审者整合反馈并指导修订，避免了评审者之间的直接通信。

Result: 在多个基准测试中，MARS与MAD及其他先进方法相比，准确率相当，同时将token使用量和推理时间减少了约50%。

Conclusion: MARS是一种高效、低开销的多智能体协作推理框架，能够在不牺牲性能的前提下显著提升推理效率。

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [101] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 提出了一种受小波启发的分层解析Transformer（HRT），通过多分辨率处理语言，实现O(nlogn)复杂度，在多个基准上优于标准Transformer，同时提升效率和语言理解能力。


<details>
  <summary>Details</summary>
Motivation: Transformer将文本视为扁平的token序列，未能有效建模语言的层次结构，导致计算成本高、组合泛化能力弱和篇章建模不足。

Method: 提出HRT模型，采用多分辨率注意力机制，结合自底向上的组合与自顶向下的上下文化，并通过指数级序列缩减实现O(nlogn)计算复杂度。

Result: 在GLUE、SuperGLUE和Long Range Arena等基准上分别平均提升3.8%、4.5%和6.1%，内存减少42%，推理延迟降低37%，且消融实验验证了跨分辨率注意力和尺度专用模块的有效性。

Conclusion: HRT首次使计算结构与人类语言的层次结构对齐，证明多尺度、小波启发的处理方式可在理论效率和实际语言理解性能上同时带来提升。

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [102] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文介绍了SiniticMTError，一个包含错误标注的中-英机器翻译数据集，涵盖普通话、粤语和吴语，旨在支持低资源语言的翻译质量评估与错误感知生成研究。


<details>
  <summary>Details</summary>
Motivation: 尽管机器翻译近年来取得进展，但许多低资源语言（如粤语和吴语）因缺乏大规模训练数据而发展受限，因此需要专门的数据集来推动相关研究。

Method: 基于现有平行语料库，通过母语者对从英语翻译为普通话、粤语和吴语的译文进行错误跨度、错误类型和严重程度的标注，构建SiniticMTError数据集，并分析标注一致性及错误模式。

Result: 成功构建了SiniticMTError数据集，报告了较高的标注一致性，并揭示了不同语言间的错误类型与严重性分布特征。

Conclusion: 该数据集可作为机器翻译社区的重要资源，用于模型微调、翻译质量估计和低资源语言翻译系统的评估。

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [103] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 本文提出了一种名为对话式提示（Conversational Prompting）的轻量级方法，用于在少样本且无需训练的场景下生成个性化评论，其中简单变体（SCP）仅使用用户自身评论，对比变体（CCP）引入其他用户或大模型的评论作为错误回复以引导模型模仿用户风格。实验表明该方法在多个产品领域和大模型上均显著提升评论个性化程度。


<details>
  <summary>Details</summary>
Motivation: 现有个性化评论生成方法通常依赖大量用户历史评论或需额外训练，在实际应用中面临少样本和无法微调的限制，因此需要一种无需训练且适应低资源场景的有效方法。

Method: 将用户评论重构为多轮对话形式：简单对话提示（SCP）仅基于用户自身评论构建对话；对比对话提示（CCP）则插入他人或LLM生成的评论作为错误回答，并让模型纠正，从而学习用户表达风格。

Result: 在八个产品领域和五种大语言模型上的实验显示，传统非对话式提示生成的评论与随机用户相似度高，而SCP和CCP显著提升了生成评论与目标用户原文的一致性，即使仅有两条用户评论也能取得良好效果；CCP在有高质量负例时表现更优，SCP在缺乏负例时仍具竞争力。

Conclusion: 对话式提示是一种适用于少样本和无需训练场景下的有效且实用的个性化评论生成方法，通过简单的提示重构即可显著提升生成内容的个性化水平。

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [104] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 本文提出了BESPOKE，一个用于评估搜索增强型大语言模型中个性化效果的现实且具有诊断性的基准。该基准基于真实的人类聊天和搜索历史，并结合细粒度偏好评分与反馈进行构建，旨在揭示信息寻求任务中有效个性化的关键需求。


<details>
  <summary>Details</summary>
Motivation: 现有的搜索增强型大语言模型虽能减轻用户认知负担，但在理解不同用户的多样化意图及提供个性化信息形式方面仍不足；现有系统（如ChatGPT、Gemini）虽尝试利用用户历史实现个性化，但缺乏系统性评估方法。

Method: 提出BESPOKE基准，通过收集真实人类的聊天与搜索历史，结合长期深入的人工标注：包括用户提供自身历史、撰写具详细信息需求的查询，并对响应进行评分与反馈，从而实现现实且可诊断的评估。

Result: 构建了包含真实用户行为数据和细粒度反馈的BESPOKE基准，并通过系统分析揭示了实现有效个性化所需的关键因素。

Conclusion: BESPOKE为评估个性化搜索增强型大语言模型提供了现实且细致的评测基础，推动了对该类系统个性化能力的深入理解和优化。

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [105] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: 提出了一种名为ROC的新框架，将多模态关系抽取从分类任务转化为基于语义的检索任务，通过融合实体类型和位置信息、扩展关系标签为自然语言描述，并利用对比学习对齐实体-关系对，在MNRE和MORE数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统多模态关系抽取方法依赖分类范式，使用离散标签表示关系，忽略了结构约束（如实体类型和位置线索），且缺乏细粒度关系理解所需的语义表达能力。

Method: 提出ROC框架：1）通过多模态编码器整合实体类型和位置信息；2）利用大语言模型将关系标签扩展为自然语言描述；3）采用基于语义相似性的对比学习对齐实体与关系。

Result: 在MNRE和MORE两个基准数据集上实现了最先进的性能，表现出更强的鲁棒性和可解释性。

Conclusion: 将多模态关系抽取由分类转为检索是有效的新范式，ROC框架通过语义驱动的方式提升了关系抽取的准确性与可解释性。

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [106] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 本文提出了SGMem（句子图记忆）方法，通过将对话表示为分块的句子级图，结合原始对话与生成的记忆（如摘要、事实和见解），有效管理长期对话中超出大语言模型上下文窗口的历史信息。


<details>
  <summary>Details</summary>
Motivation: 现有基于事实提取或摘要的方法在减少冗余方面有效，但难以跨不同粒度组织和检索相关信息。需要一种能更好整合多层次对话上下文的记忆机制。

Method: SGMem将对话划分为块单元，在每个块内构建句子级图，捕捉回合、轮次和会话级别的关联，并结合原始对话与生成的记忆（如摘要、事实和洞察）进行上下文检索。

Result: 在LongMemEval和LoCoMo数据集上的实验表明，SGMem在长期对话问答任务中显著优于强基线方法，提升了准确率。

Conclusion: SGMem通过图结构整合多粒度对话信息和生成记忆，为大语言模型提供了连贯且相关的上下文，有效支持长期对话中的响应生成。

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [107] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: 本文提出了一种名为FS-DFM的离散流匹配模型，能够在极少采样步数下实现高质量语言生成，显著提升生成速度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的自回归语言模型生成速度慢，而扩散语言模型虽可并行但需大量迭代步数，因此需要一种兼顾生成速度与质量的新方法。

Method: 将采样步数作为显式参数，训练模型在不同步数预算下保持一致性，并结合可靠的更新规则和来自长轨迹蒸馏的强教师指导。

Result: 在语言建模基准上，FS-DFM仅用8步采样即可达到1024步基线模型相当的困惑度，采样速度快达128倍。

Conclusion: FS-DFM实现了快速、稳定且高质量的语言生成，为高效文本生成提供了新方向。

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [108] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: QCG-RAG是一种基于查询的图检索增强生成框架，通过查询为中心的图构建和多跳检索机制，在多跳问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图RAG方法面临粒度困境：细粒度实体级图消耗高且丢失上下文，粗粒度文档级图难以捕捉复杂关系。

Method: 提出QCG-RAG框架，利用Doc2Query技术构建查询中心图，并设计定制的多跳检索机制进行相关块检索。

Result: 在LiHuaWorld和MultiHop-RAG数据集上的实验表明，QCG-RAG在问答准确率上持续优于现有的基于块和基于图的RAG方法。

Conclusion: QCG-RAG通过可控粒度的查询中心图索引和多跳检索，为多跳推理提供了新范式。

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [109] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: 本文提出了一种在不运行实验的情况下预测大语言模型性能的方法，通过构建PRECOG数据集实现基于任务描述和配置的文本性能预测。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的发展受限于评估瓶颈，需要反复构建基准并进行迭代评估。因此，作者希望在实验前就能预测结果，以提升效率。

Method: 提出文本性能预测任务，构建包含多样化任务、领域和指标的红acted描述-性能配对数据集PRECOG，并利用具备检索模块的模型进行预测。

Result: 实验表明该任务具有挑战性但可行，配备检索模块的模型在高置信度下达到准确子集上最低8.7的平均绝对误差；更强的推理模型表现出多样化的迭代查询行为，而当前开源模型表现较差；在零泄漏场景下，GPT-5结合网络搜索仍能实现非平凡预测精度。

Conclusion: PRECOG数据集和相关分析为开放式的前瞻性评估提供了初步基础，有助于难度估计和更智能的实验优先级排序。

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [110] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 本文提出了一种用于日语发音评估的语音识别方法，通过多任务学习和模型融合来缓解标注数据稀疏问题，显著降低了音拍标签错误率。


<details>
  <summary>Details</summary>
Motivation: 由于带有声调标记的准确音素转录训练数据稀缺，构建高精度的日语发音评估语音识别器面临挑战。

Method: 采用多任务训练框架，引入正字法标签和基频模式的辅助损失函数，并融合基于音标字符串和文本标记序列的两个估计器，使用有限状态转换器算法进行组合。

Result: 所提方法在CSJ核心测试集上将音拍标签错误率从12.3%降至7.1%，优于通用多语言识别器。

Conclusion: 多任务学习与模型融合策略有效提升了日语带调音素识别的准确性，适用于资源有限的发音评估任务。

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [111] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种将大语言模型（LLM）提取的知识与预训练分子模型的结构特征相结合的新框架，用于提升分子属性预测（MPP）性能。


<details>
  <summary>Details</summary>
Motivation: 尽管图神经网络和自监督学习在分子属性预测中取得进展，但大语言模型存在知识空白和幻觉问题，难以覆盖研究较少的分子属性，因此需要融合人类先验知识以提升预测准确性。

Method: 通过提示LLMs生成领域相关知识和可执行的分子向量化代码，提取知识特征，并将其与来自预训练分子模型的结构特征进行融合，使用GPT-4o、GPT-4.1和DeepSeek-R1三种先进LLM进行知识提取。

Result: 大量实验表明，该方法在多个分子属性预测任务上优于现有方法，验证了知识特征与结构特征融合的有效性。

Conclusion: 结合LLM提取的知识与分子结构信息是一种鲁棒且有效的分子属性预测解决方案，为未来MPP研究提供了新方向。

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [112] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出并测试了一种新的攻击方法RedHerring，旨在通过使检测模型误报来降低其可靠性，同时保持分类器的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗性文本攻击检测模型的可靠性尚未被充分研究，需要探索新的威胁模型以评估和提高这些模型的安全性。

Method: 提出了RedHerring攻击方法，该方法通过对文本进行修改，使得检测模型预测为攻击，而分类器仍然正确。在4个数据集上对3种检测器和4种分类器进行了测试。

Result: RedHerring能够将检测准确率降低20到71个百分点，同时保持或提升分类器的准确率。提出了一种简单的置信度检查作为初步防御措施，显著提高了检测准确率。

Conclusion: RedHerring攻击揭示了对手可能针对检测模型的新方式，强调了增强检测模型可靠性的必要性。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [113] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出两种新的攻击选择策略Hybrid Select和Dynamic Select，有效减少对抗文本攻击中的查询次数，同时保持攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒攻击方法在处理基于Transformer的模型时需要大量查询，计算成本高，对资源有限的研究者不友好。

Method: 提出Hybrid Select和Dynamic Select两种策略，结合BinarySelect和GreedySelect的优点，通过设定阈值或学习机制决定在不同文本长度下使用哪种选择算法。

Result: 在4个数据集和6个目标模型上实验表明，句子级Hybrid Select平均减少25.82%的查询次数，且不损失攻击有效性。

Conclusion: 所提方法显著降低了对抗攻击的查询成本，适用于资源受限环境，提升了NLP模型鲁棒性评估的效率。

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [114] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: 提出MI-Fuse框架，利用互信息加权的去噪标签融合，在无源域数据情况下通过API调用大音频语言模型实现跨域语音情感识别性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决现实部署中因领域不匹配导致语音情感识别性能下降的问题，且在无法获取源域数据、仅能通过API访问强大音频语言模型的限制下实现模型自适应。

Method: 提出MI-Fuse框架，结合API调用的大音频语言模型和源域训练的情感分类器作为双教师，通过多次随机预测生成分布，利用基于互信息的不确定性加权融合标签，并采用指数移动平均稳定训练过程。

Result: 在三个公开情感数据集和六种跨域迁移设置上实验表明，该方法一致优于基线模型，学生模型超越了大音频语言模型，性能比最强基线高出3.9%。

Conclusion: MI-Fuse框架能在不共享源域数据的前提下，有效利用API-only访问的大音频语言模型进行目标域自适应，显著提升跨域语音情感识别性能，推动情感感知语音系统在真实场景中的应用。

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [115] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 本文提出了一种解决无监督神经语法归纳中“概率分布坍缩”问题的新方法，通过引入“缓解坍缩的神经参数化”显著提升了解析性能，并实现了更紧凑的语法结构。


<details>
  <summary>Details</summary>
Motivation: 现有无监督神经语法归纳模型存在表达能力瓶颈，常导致语法规模过大但性能不佳，其根源在于概率分布坍缩问题。

Method: 分析了神经参数化各关键组件中概率分布坍缩的成因，并提出了“缓解坍缩的神经参数化”方法以针对性地解决该问题。

Result: 新方法在多种语言上显著提升了无监督语法解析的性能，同时允许使用更紧凑的语法规模。

Conclusion: 通过识别并缓解概率分布坍缩问题，本文方法有效突破了现有模型的表达瓶颈，实现了更高效、更紧凑的语法学习。

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [116] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: 提出了一种无需训练的框架C2R，通过置信度引导的子问题构建与优化来提升跨模态问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有问答模型在复杂推理任务中缺乏可靠性和稳定性，且对子问题利用不足。

Method: C2R通过模型自身的置信度选择和优化子问题及其答案，构建多样化的推理路径，并基于置信度比较选择最终答案。

Result: C2R在多种模型和基准上均实现了性能提升，验证了其有效性与通用性。

Conclusion: C2R是一种通用、无需训练的推理框架，能有效提升多模态问答系统的可靠性与鲁棒性。

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [117] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: 本文研究了在领域特定数据集上进行监督微调（SFT）对大语言模型通用能力的影响，提出使用较小学习率可缓解性能下降，并提出了Token-自适应损失重加权（TALR）方法，在平衡领域专长与通用能力方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 监督微调常导致大模型通用能力下降，本文旨在重新审视这一权衡问题，并寻找有效缓解该问题的方法。

Method: 通过实验分析不同学习率对性能的影响，结合理论分析提出Token-Adaptive Loss Reweighting（TALR）方法，并与其他正则化和微调策略进行比较。

Result: 实验表明较小学习率能显著减轻通用性能退化，而TALR在保持领域性能的同时更好地维持了通用能力，整体表现优于LoRA、L2正则化、模型平均等基线方法。

Conclusion: SFT不必然损害通用能力，关键在于训练策略；推荐使用小学习率，并在需要更强平衡时采用TALR作为有效解决方案。

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [118] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出了“原子理论”（Atoms Theory），定义了大语言模型（LLM）内部表示的基本单元——原子，通过原子内积（AIP）校正表示偏移，并证明原子满足受限等距性（RIP），确保稀疏表示的稳定性。实验表明，使用阈值激活的稀疏自编码器（SAE）可可靠地识别原子，在多个LLM上实现了高达99.9%的稀疏重建精度，显著优于神经元和特征。


<details>
  <summary>Details</summary>
Motivation: 大语言模型内部表示的基本单元尚不明确，现有方法如神经元存在多义性，特征则面临重建不可靠和不稳定的问题，限制了对模型机制的理解。因此需要一种更稳定、可解释且可恢复的基本表示单元。

Method: 提出原子理论，引入原子内积（AIP）来纠正表示偏移，形式化定义原子并证明其满足受限等距性（RIP）条件；在更强假设下进一步证明稀疏表示的唯一性和ℓ1可恢复性，并理论保证单层阈值激活稀疏自编码器（SAE）能可靠识别原子。在Gemma2和Llama3.1等模型上训练SAE进行验证。

Result: 在Gemma2-2B、Gemma2-9B和Llama3.1-8B上平均实现99.9%的稀疏重建精度；超过99.8%的原子满足唯一性条件，而神经元仅为0.5%，特征为68.2%；扩展实验揭示SAE大小与恢复能力的关系。

Conclusion: 原子理论为大语言模型的内部表示提供了系统性的理论框架，不仅确保了稳定和唯一的稀疏表示，还为机制可解释性奠定了基础，实验验证了其在实际模型中的有效性。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [119] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为Enrich-on-Graph（EoG）的灵活框架，利用大语言模型的先验知识增强知识图谱，弥合查询与图之间的语义鸿沟，在知识图谱问答任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在知识密集型任务中仍存在幻觉和事实错误，主要由于结构化知识图谱与非结构化查询之间存在语义鸿沟。

Method: 提出Enrich-on-Graph（EoG）框架，利用大语言模型的先验知识对知识图谱进行动态增强，并设计了三个图质量评估指标来分析查询与图的对齐程度。

Result: 在两个KGQA基准数据集上的实验表明，EoG能有效生成高质量知识图谱，提升推理准确性和鲁棒性，且具有低计算成本、可扩展性和适应性。

Conclusion: EoG通过弥合语义鸿沟显著提升了知识图谱问答的性能，为结合大语言模型与结构化知识提供了高效、可扩展的解决方案。

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [120] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 提出了一种名为Post-Correction via Overcorrection (PoCO)的新方法，通过结合大模型的高召回和小模型的高精确度，在语法错误纠正任务中有效平衡了召回率与精确度。


<details>
  <summary>Details</summary>
Motivation: 小语言模型在语法纠错中可靠性高但召回率低，而大语言模型则容易过度修正导致精确度下降，因此需要一种方法来结合两者的优势。

Method: 首先利用大语言模型进行过度修正以提高召回率，然后使用微调后的小模型对输出进行后处理，修正错误，提升精确度。

Result: 实验表明，PoCO在保持较高精确度的同时显著提升了召回率，整体语法纠错性能优于现有方法。

Conclusion: PoCO成功融合了大模型的生成能力和小模型的可靠性，有效平衡了语法纠错中的召回率与精确度，提升了整体纠错质量。

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [121] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: 提出了一种称为“cheat-sheet ICL”的方法，通过将多样本上下文学习的信息压缩成简洁的文本摘要，在减少输入token数量的同时保持甚至提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型在使用多示例上下文学习时计算开销过大的问题。

Method: 将多示例ICL的信息提炼为简洁的文本摘要（即‘作弊单’），在推理时用作上下文。

Result: 在复杂推理任务上，cheat-sheet ICL实现了与多示例ICL相当或更好的性能，且所需token显著减少，同时无需测试时检索即可匹配基于检索的ICL效果。

Conclusion: cheat-sheet ICL是一种实用的、高效的上下文学习替代方案，适用于下游任务中的大模型应用。

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [122] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: 提出一种零样本、基于树搜索的迭代句子重写算法，用于在保持文本连贯性和自然性的同时，有效去除用户输入中的敏感信息。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在云服务中的广泛应用，用户输入可能泄露敏感信息，现有文本去标识化方法难以兼顾隐私保护与文本可用性。

Method: 采用基于奖励模型引导的树搜索策略，逐步重写敏感语句片段，通过零样本迭代重写实现隐私信息模糊化或删除。

Result: 在隐私敏感数据集上的实验表明，该方法显著优于现有基线方法，在隐私保护和文本效用保持之间实现了更优平衡。

Conclusion: 所提方法能有效平衡隐私保护与文本自然性，在无需训练的情况下适用于大语言模型中的实时隐私防护。

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [123] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了一种生成子句级引用的归因框架，以提高检索增强生成（RAG）系统中引用的精确性和可读性，减少用户验证生成内容正确性的负担。


<details>
  <summary>Details</summary>
Motivation: 现有引用方法通常在句子或段落级别提供引用，导致信息不够精确或遗漏关键内容，影响用户验证输出的效率和准确性。

Method: 开发了针对子句级引用的标注指南并构建了相应数据集；利用大语言模型自动生成微调数据，并通过信用模型筛选低质量样本，构建归因框架。

Result: 实验结果表明，所提方法能生成更高质量、更易读的引用，显著提升引用的准确性和可用性。

Conclusion: 生成符合标准的子句级引用可有效提升RAG系统输出的可验证性，降低用户核实成本，为未来引用生成研究提供了可行方案。

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [124] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: 提出了一种名为WeFT的加权监督微调方法，通过基于熵为不同token分配权重，显著提升了扩散语言模型在少量训练数据下的推理性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语言生成中展现出潜力，但缺乏精确的概率估计，导致生成过程不可预测且不一致，难以进行有效的监督微调。

Method: 提出WeFT方法，根据token的熵为其分配不同权重，结合扩散理论对扩散语言模型进行加权监督微调。

Result: 在Sudoku、Countdown、GSM8K和MATH-500四个推理基准上，使用s1K、s1K-1.1和3k样本时，相比标准SFT分别取得了39%、64%和83%的相对提升。

Conclusion: WeFT有效提升了扩散语言模型在推理任务中的表现，尤其在小样本场景下效果显著，增强了生成过程的可控性和一致性。

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [125] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本研究首次系统地探讨了如何使医学推理模型（MRM）生成开放式问题的排序答案列表，提出并比较了提示和微调方法，发现基于强化微调（RFT）的模型在多种答案格式下更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 临床决策通常需要考虑多个可能选项而非单一答案，但现有医学推理模型多被训练为仅输出单个答案，难以满足实际需求。

Method: 研究采用提示（prompting）和监督微调（SFT）、强化微调（RFT）两种微调方法，设计针对排序列表的新奖励函数，并进行消融实验。

Result: 部分SFT模型能在特定格式上泛化，而RFT训练的模型在多种答案格式下表现更稳健；案例研究表明MRM虽可能未选中标记的‘标准答案’，但仍能识别出有效答案。

Conclusion: 这是首个系统研究MRM生成排序答案列表的工作，表明RFT在多答案格式下的优越性，为医学领域发展更符合临床实际的多答案推理模型提供了可行路径。

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [126] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: 提出SummQ，一种基于对抗性多智能体协作的长文档摘要框架，通过摘要与测验双领域的协同机制显著提升摘要质量。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在处理长文档摘要时存在信息丢失、事实不一致和连贯性问题，亟需更可靠的摘要生成方法。

Method: 设计包含摘要生成者、评审者、测验生成者、评审者及应试者在内的多智能体对抗框架，通过问答机制和迭代反馈实现摘要的持续优化。

Result: 在三个主流长文档摘要基准上，SummQ在ROUGE、BERTScore、LLM-as-a-Judge和人工评价中均显著优于现有最先进方法。

Conclusion: 多智能体对抗协作机制能有效提升长文档摘要的质量，验证了基于问答反馈的迭代优化策略的可行性与优越性。

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [127] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: 提出MemLens方法，通过分析生成过程中数字token的概率轨迹来检测大语言模型中的记忆化现象，发现被污染样本在早期层就快速锁定答案，而干净样本则逐步积累证据。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法对隐式污染数据泛化能力差，难以有效识别大语言模型在高难度基准测试中因记忆化导致的性能偏差。

Method: 分析生成过程中各层激活状态下的数字token概率轨迹，利用推理路径差异区分被污染和干净样本，并通过LoRA微调注入样本来验证轨迹模式的一致性。

Result: 被污染和干净样本展现出明显分离的推理轨迹，MemLens能准确捕捉真实记忆化信号而非虚假相关性。

Conclusion: MemLens有效揭示了记忆化行为的本质特征，为评估大语言模型的记忆风险提供了可靠工具。

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [128] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 该研究通过跨语言依存句法树库和混合效应模型，比较句子长度、依存距离与干预复杂度（intervener complexity）对句子理解中记忆负荷的预测能力，发现干预复杂度比线性距离更能反映结构层面的认知负荷。


<details>
  <summary>Details</summary>
Motivation: 探究句子理解中的记忆负荷是由句法成分间的线性距离还是中间成分的结构复杂性更优解释，以调和局部性理论中的线性与层级视角。

Method: 采用统一依存句法标注库（UD），计算每个句子的句子长度、依存距离和干预复杂度，并将其作为预测变量，结合特征干扰与错误绑定的线性加总作为记忆负荷的操作定义，在多语言数据上构建混合效应模型进行联合评估。

Result: 句子长度、依存距离和干预复杂度均正向预测记忆负荷，其中句子长度影响最广，而干预复杂度在线性距离之外提供了额外解释力，表明其是更贴近整合与维持认知需求的指标。

Conclusion: 研究支持将干预复杂度作为比线性距离更精细的记忆负荷预测指标，揭示了结构密度在语言加工中的核心作用，并展示了基于依存图结构与跨语言建模方法在检验语言处理理论中的有效性。

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [129] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 本文研究了如何为阿拉伯语实现工具调用功能，探讨了使用阿拉伯语内部数据与跨语言迁移的效果、通用指令微调对工具调用性能的影响，以及针对高优先级工具进行微调的价值。通过实验和翻译适配的开源数据集，提出了开发强大的阿拉伯语工具增强代理的最佳策略。


<details>
  <summary>Details</summary>
Motivation: 现有工具调用研究和资源主要集中于英语，缺乏对阿拉伯语等其他语言的支持，限制了多语言环境下大模型的应用。因此，需要探索适用于阿拉伯语的工具调用方法。

Method: 通过翻译和适配两个开源工具调用数据集到阿拉伯语，基于开源的阿拉伯语大语言模型，进行基础与后训练版本的广泛实验，分析不同训练策略（如跨语言迁移、指令微调、特定工具微调）的效果。

Result: 实验证明，在阿拉伯语工具调用中，使用本语言数据优于纯跨语言迁移；通用指令微调有助于提升性能；而针对关键工具的微调能显著增强特定任务表现。

Conclusion: 为构建高效的阿拉伯语工具增强代理，应结合本语言工具调用数据、通用指令微调，并对高优先级工具进行专门微调，这是最优的发展策略。

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [130] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: 本研究探讨了基于大语言模型（LLM）的自动评分系统在高等教育文本输入题中的应用，提出了五种基于评分规则的评估方法，并在包含110个计算机科学答案的数据集上进行了测试。结果显示，使用参考答案辅助的“参考辅助评估”方法表现最佳，与人工评分最接近，具备实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了提升教育领域中自动评估系统的准确性与公平性，探索大语言模型作为评分工具的有效方法，特别是在缺乏充足人工评分资源的情况下提供可靠替代方案。

Method: 提出并比较了五种LLM驱动的评估方法：JudgeLM评估、参考辅助评估、无参考评估、加性评估和自适应评估。使用JudgeLM、Llama-3.1-8B和DeepSeek-R1-Distill-Llama-8B三个模型，在自建学生作答数据集上运行各方法，并与人工评分结果对比，采用中位数绝对偏差和均方根偏差作为评价指标。

Result: 参考辅助评估方法表现最优，中位数绝对偏差最低（0.945），均方根偏差最低（1.214），评分准确且评语详尽；其他方法在简洁回答或信息完整性方面表现不佳，JudgeLM因模型限制效果不理想。

Conclusion: 在适当方法支持下，基于大语言模型的自动评估系统可作为教育评估中有潜力的补充工具，尤其推荐使用参考答案辅助的评估方式以提高评分质量。

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [131] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型的框架OnPrem.LLM，用于加速联邦资助研发中心（FFRDCs）对文本密集型任务的处理，在仅需少量示例的情况下实现摘要、分类、信息提取和理解，并确保政府敏感环境中的审计性和数据主权。


<details>
  <summary>Details</summary>
Motivation: FFRDCs面临大量文本分析任务，传统手动方法效率低下，且在敏感政府环境中应用AI需保障安全性与可控性。

Method: 采用开源框架OnPrem.LLM，利用大语言模型在少量输入输出示例下完成文本摘要、分类、抽取和推理任务，支持本地部署以确保安全与灵活性。

Result: 在国防政策文件（如NDAA）和科学数据集（如NSF Awards）上的案例研究表明，该方法显著提升了监督与战略分析效率，同时保持了审计追踪和数据主权。

Conclusion: 结合大语言模型与安全框架可在保护敏感信息的前提下，有效提升政府科研机构的文本处理能力，具有实际应用价值。

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [132] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: 本文研究了Transformer解码器中因果掩码对注意力分数的位置依赖性影响，发现即使没有参数或输入中的因果依赖，因果掩码也能诱导出类似位置编码的局部偏好模式，并与RoPE相互作用扭曲其相对性。


<details>
  <summary>Details</summary>
Motivation: 探究因果掩码是否在Transformer中提供位置信息，以及其与显式位置编码（如RoPE）的交互影响。

Method: 通过理论分析证明因果掩码可诱导位置相关的注意力模式，并通过在现代大语言模型上的实证研究验证该现象。

Result: 因果掩码本身能产生偏向邻近查询-键对的注意力模式，且与RoPE结合时会破坏RoPE的相对位置特性，导致非相对的注意力分布。

Conclusion: 因果掩码是位置信息的重要来源，应与显式位置编码一同被考虑，在模型设计中不可忽视。

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [133] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 本文提出了两个专门的基准测试（ManyIFEval和StyleMBPP），用于评估大语言模型在文本和代码生成中同时遵循多条指令的能力，并发现性能随指令数量增加而下降；研究还开发了回归模型，可用较小样本预测未见指令组合下的模型表现。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现实场景中的广泛应用，理解其同时遵循多条指令的能力变得至关重要，但缺乏系统性评估方法。

Method: 构建了两个基准测试：ManyIFEval（最多10条指令的文本生成）和StyleMBPP（最多6条指令的代码生成）；在10个LLM上进行实验，并训练三种回归模型预测不同指令组合和数量下的性能。

Result: 实验表明，随着指令数量增加，模型性能持续下降；使用指令数量作为解释变量的逻辑回归模型可在未见指令组合下以约10%的误差预测性能；ManyIFEval需500样本、StyleMBPP需300样本即可实现有效估计。

Conclusion: 多指令遵循能力是当前LLM的瓶颈之一，提出的基准和回归模型可高效评估和预测模型在复杂指令场景下的表现，为实际应用提供实用工具。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [134] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 本文介绍了SoM-1K，首个用于评估基础模型在材料力学领域复杂多模态工程问题上表现的大规模基准数据集，并提出了一种名为“图像描述”（DoI）的新提示策略，通过提供专家生成的图表文本描述来提升模型性能。实验表明，当前的基础模型在此类任务上表现不佳，最佳模型准确率仅为56.6%，且使用DoI的大型语言模型（LLM）常优于使用图像的视觉语言模型（VLM），说明精确的文本描述可有效缓解视觉误解问题。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型在复杂、多模态工程问题上的表现，特别是在材料力学领域，现有模型在处理结合文本和图示的工程问题时能力有限，亟需专门的基准测试和改进方法。

Method: 构建包含1,065个标注材料力学问题的多模态数据集SoM-1K，涵盖真实工程场景中的文本描述和示意图；提出“图像描述”（DoI）提示策略，利用专家编写的严谨文本描述替代或辅助图像输入；评估八种代表性基础模型（包括LLMs和VLMs）在该数据集上的表现。

Result: 当前基础模型在SoM-1K上整体表现较差，最高准确率仅为56.6%；使用DoI的LLMs通常优于直接输入图像的VLMs；错误分析显示DoI能显著减少视觉误解错误，提升推理准确性。

Conclusion: SoM-1K为工程AI提供了严格的评估基准，揭示了当前基础模型在科学与工程多模态推理中的局限性；研究表明，在现阶段，高质量的文本描述比直接图像输入更有利于模型理解复杂工程图表，未来需重点发展更强的多模态推理能力。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [135] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: 本文提出并系统研究了大语言模型中存在的文化定位偏见问题，即模型默认生成立场偏向主流美国文化，而将其他文化视为外部。为此，作者构建了CultureLens基准，并提出了基于提示的公平干预方法和基于代理的公平性缓解框架（MFA），实验证明后者在减少生成偏见方面具有显著效果。


<details>
  <summary>Details</summary>
Motivation: 发现大语言模型在生成内容时倾向于主流美国文化视角，忽视非主流文化，导致文化层面的公平性问题，亟需识别和解决这种隐性偏见。

Method: 提出CultureLens基准，包含4000个生成提示和3个评估指标，通过跨10种文化的实地采访脚本生成任务来量化文化定位偏见；设计两种推理时缓解方法：基于提示的FIP方法和基于多智能体的MFA框架（包括MFA-SA和MFA-MA）。

Result: 对5种先进大语言模型的实验表明，模型在美国语境下采用内部视角的比例超过88%，但在非主流文化中多采用外部视角；所提MFA方法，尤其是多代理结构，能有效降低此类偏见。

Conclusion: 大语言模型存在显著的文化定位偏见，基于多智能体的自我反思与协作修正框架（如MFA）是缓解此类生成偏见的有效且有前景的方向。

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [136] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: PerHalluEval是首个针对波斯语的动态幻觉评估基准，通过LLM驱动的三阶段管道结合人工验证，生成合理的问答和摘要内容，用于检测外部和内部幻觉，并利用生成token的对数概率筛选最可信的幻觉实例。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在低资源语言（如波斯语）中普遍存在幻觉问题，但缺乏专门的评估基准，因此需要构建针对波斯语的幻觉检测工具。

Method: 提出PerHalluEval基准，采用三阶段LLM驱动管道生成问答和摘要数据，结合人工验证确保质量；使用token的对数概率选择最具迷惑性的幻觉样本，并引入人工标注识别与波斯文化相关的特定语境。

Result: 评估了12个开源和闭源LLM，发现现有模型普遍难以检测波斯语中的幻觉现象；提供外部知识（如原文档）可部分缓解该问题；专门训练用于波斯语的模型并未显著优于其他模型。

Conclusion: 当前大语言模型在处理波斯语时仍面临严重幻觉挑战，需进一步研究针对性解决方案，而外部知识辅助和文化敏感性建模可能是有效方向。

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [137] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: VoiceBBQ是BBQ数据集的语音扩展版本，用于评估口语语言模型中的社会偏见，涵盖内容和声学两个方面。


<details>
  <summary>Details</summary>
Motivation: 由于语音的特性，口语语言模型中的社会偏见可能来自内容和声学两个方面，现有文本基准无法全面捕捉这些偏见。

Method: 将BBQ数据集的每个上下文转换为受控的语音条件，构建VoiceBBQ数据集，并在LLaMA-Omni和Qwen2-Audio两种口语语言模型上进行评估。

Result: 实验发现LLaMA-Omni抵抗声学偏见但放大性别和口音偏见，而Qwen2-Audio显著减弱这些偏见同时保持内容保真度。

Conclusion: VoiceBBQ提供了一个紧凑且可直接使用的测试平台，能够联合诊断口语语言模型中的内容和声学偏见。

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [138] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: 该论文研究了语音语言模型（SpeechLMs）在处理不同性别声音时可能存在的偏见问题，发现尽管整体回应看似无差别，但实际上存在对男性倾向的系统性偏差，并揭示这种偏差主要源于Whisper语音编码器生成的声学标记。


<details>
  <summary>Details</summary>
Motivation: 探究SpeechLMs在语音交互中是否存在基于性别的偏见，尤其是在相同问题下因说话人性别不同而导致回应差异的问题。

Method: 构建了一个包含9,208个语音样本的新数据集，涵盖三类问题：性别无关、性别刻板印象和性别依赖型问题，并评估了LLaMA-Omni系列模型的表现，同时对比了SpeechLM与基础大语言模型的行为差异。

Result: 发现模型在性别刻板问题上普遍偏向男性回应；在应体现性别差异的问题上反而忽略性别信息；该偏差并非由中性选项或声音感知性别引起，且在使用性别中和方法后仍存在；进一步分析表明偏差主要来自Whisper语音编码器产生的男性导向声学标记。

Conclusion: 当前SpeechLMs虽追求公平性，却未能恰当利用性别信息，导致出现悖论式偏见模式，需更精细的技术来正确处理语音中的性别因素。

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [139] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent是一个用于文本分类任务的自动化机器学习工具，提供端到端自动化，包括嵌入模型选择、分类器优化和决策阈值调整，支持多标签分类和范围外检测。


<details>
  <summary>Details</summary>
Motivation: 现有自动化机器学习工具在文本分类任务中缺乏端到端的自动化支持，特别是在嵌入模型选择和决策阈值调整方面。

Method: AutoIntent采用模块化设计，集成嵌入模型选择、分类器优化和决策阈值调优，通过类似sklearn的接口实现多标签分类和范围外检测。

Result: 在标准意图分类数据集上，AutoIntent相比现有AutoML工具表现出更优的性能，并允许用户在效果和资源消耗之间进行权衡。

Conclusion: AutoIntent为文本分类任务提供了一个高效、灵活且易于使用的自动化解决方案，特别适用于需要多标签分类和范围外检测的应用场景。

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [140] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: 该研究发现大型语言模型在训练过程中会学习到句法与领域之间的虚假关联，这种关联可能覆盖指令的语义，导致性能下降，并可能被利用来绕过安全拒绝机制。作者提出了评估框架并强调需在训练数据中增加句法多样性以缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 理解LLM在处理任务-指令对时如何受到句法、领域和语义之间相互作用的影响，特别是句法模板可能引发的虚假相关性问题。

Method: 通过构建合成训练数据集分析句法-领域相关性的影响，并提出评估框架检测多种模型（包括OLMo、Llama和GPT-4o）中的此类现象，同时进行安全微调的案例研究。

Result: 发现句法-领域相关性会降低模型在实体知识任务上的性能（平均0.51±0.06），并在多个开源和闭源模型中验证了该现象的存在，且可被用于绕过安全拒绝机制。

Conclusion: 需要显式测试句法-领域相关性，并在训练数据中确保领域内的句法多样性，以防止模型学习到有害的虚假关联。

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


### [141] [Who's Laughing Now? An Overview of Computational Humour Generation and Explanation](https://arxiv.org/abs/2509.21175)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 本文综述了与生成和解释幽默相关的计算幽默研究现状，指出尽管理解幽默是自然语言处理的基础任务之一，但除双关语外的幽默生成与解释研究仍较少，当前最先进的模型尚无法达到人类水平，并强调了将主观性和伦理模糊性纳入未来研究方向的重要性。


<details>
  <summary>Details</summary>
Motivation: 幽默是一种抽象、创造性且常依赖于上下文的人类特质，其计算理解对评估现代大语言模型的常识与推理能力具有重要意义。

Method: 通过文献综述的方法，梳理了计算幽默在生成与解释任务上的研究现状，并分析了现有模型的局限性。

Result: 发现当前在非双关语类幽默的生成与解释方面研究仍然不足，最先进的语言模型在该任务上仍远逊于人类表现。

Conclusion: 计算幽默处理应作为自然语言处理的一个重要子领域，未来研究需充分考虑幽默的主观性和伦理复杂性。

Abstract: The creation and perception of humour is a fundamental human trait,
positioning its computational understanding as one of the most challenging
tasks in natural language processing (NLP). As an abstract, creative, and
frequently context-dependent construct, humour requires extensive reasoning to
understand and create, making it a pertinent task for assessing the
common-sense knowledge and reasoning abilities of modern large language models
(LLMs). In this work, we survey the landscape of computational humour as it
pertains to the generative tasks of creation and explanation. We observe that,
despite the task of understanding humour bearing all the hallmarks of a
foundational NLP task, work on generating and explaining humour beyond puns
remains sparse, while state-of-the-art models continue to fall short of human
capabilities. We bookend our literature survey by motivating the importance of
computational humour processing as a subdiscipline of NLP and presenting an
extensive discussion of future directions for research in the area that takes
into account the subjective and ethically ambiguous nature of humour.

</details>


### [142] [GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](https://arxiv.org/abs/2509.21192)
*Jieli Zhu,Vi Ngoc-Nha Tran*

Main category: cs.CL

TL;DR: 本文研究了基于小语言模型（SLM）的聊天机器人在下游任务中的个人身份信息（PII）泄露问题，提出了一种名为GEP的新型贪婪坐标梯度（GCG）方法，相比传统模板攻击方法显著提升了PII提取效率，并在复杂真实场景下验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管小语言模型（SLMs）在训练和推理中能耗更低且性能接近大模型，但其在下游应用中潜在的个人身份信息（PII）泄露风险尚未被充分研究，尤其是在医疗等敏感领域。因此，亟需探索针对SLMs的PII泄露检测方法。

Method: 首先基于BioGPT架构并使用Alpaca和HealthCareMagic医疗数据集微调出一个具备良好对话能力的SLM——ChatBioGPT；然后评估现有模板式攻击方法在SLM上的PII提取效果，并提出一种新的贪婪坐标梯度（GCG）方法GEP用于高效提取PII；最后在自由插入、语法多样的现实场景中测试GEP的有效性。

Result: 实验表明，传统的模板攻击方法在SLM上难以有效提取PII，而所提出的GEP方法可使PII泄露量提升高达60倍；在更复杂的自由风格插入场景中，GEP仍能实现最高达4.53%的PII泄露率。

Conclusion: GEP是一种针对小语言模型有效的PII泄露检测方法，显著优于传统模板攻击，在实际应用场景中也表现出较强的隐私泄露揭示能力，凸显了对SLM进行隐私安全评估的重要性。

Abstract: Small language models (SLMs) become unprecedentedly appealing due to their
approximately equivalent performance compared to large language models (LLMs)
in certain fields with less energy and time consumption during training and
inference. However, the personally identifiable information (PII) leakage of
SLMs for downstream tasks has yet to be explored. In this study, we investigate
the PII leakage of the chatbot based on SLM. We first finetune a new chatbot,
i.e., ChatBioGPT based on the backbone of BioGPT using medical datasets Alpaca
and HealthCareMagic. It shows a matchable performance in BERTscore compared
with previous studies of ChatDoctor and ChatGPT. Based on this model, we prove
that the previous template-based PII attacking methods cannot effectively
extract the PII in the dataset for leakage detection under the SLM condition.
We then propose GEP, which is a greedy coordinate gradient-based (GCG) method
specifically designed for PII extraction. We conduct experimental studies of
GEP and the results show an increment of up to 60$\times$ more leakage compared
with the previous template-based methods. We further expand the capability of
GEP in the case of a more complicated and realistic situation by conducting
free-style insertion where the inserted PII in the dataset is in the form of
various syntactic expressions instead of fixed templates, and GEP is still able
to reveal a PII leakage rate of up to 4.53%.

</details>


### [143] [Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning](https://arxiv.org/abs/2509.21193)
*Xiangru Tang,Wanghan Xu,Yujie Wang,Zijie Guo,Daniel Shao,Jiapeng Chen,Cixuan Zhang,Ziyi Wang,Lixin Zhang,Guancheng Wan,Wenlong Zhang,Lei Bai,Zhenfei Yin,Philip Torr,Hanrui Wang,Di Jin*

Main category: cs.CL

TL;DR: 提出一种结合隐式检索与结构化协作的统一框架，通过Monitor-based检索模块和分层解 refinement（HSR）与质量感知迭代推理（QAIR）机制，在科学推理任务上显著提升性能并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在科学推理中面临的两个瓶颈：显式检索打断推理过程导致的额外开销，以及多智能体方案因平均化候选解而稀释优质解的问题。

Method: 设计Monitor-based的隐式检索模块实现token级知识融合，并构建Hierarchical Solution Refinement（HSR）和Quality-Aware Iterative Reasoning（QAIR）机制进行结构化协作与动态优化。

Result: 在HLE Bio/Chem Gold上达到48.3%准确率（提升13.4-18.1个百分点），减少53.5% token使用和43.7% agent步骤；在SuperGPQA和TRQA上验证跨领域鲁棒性；错误分析显示85%以上失败同时涉及推理与知识缺陷。

Conclusion: 隐式增强与结构化 refinement 能有效克服显式工具调用和均匀聚合的低效问题，实现更高效、准确的科学推理。

Abstract: Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.

</details>


### [144] [CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis](https://arxiv.org/abs/2509.21208)
*Xinzhe Xu,Liang Zhao,Hongshen Xu,Chen Chen*

Main category: cs.CL

TL;DR: 本文提出了CLaw，一个专门用于评估大语言模型（LLM）在中国法律知识及其推理应用方面表现的新基准。CLaw包含306部中国国家法律的细粒度语料库和254个基于真实案例的推理任务。实验表明，现有LLM在准确回忆和引用法律条文方面表现不佳，影响其法律推理的可靠性。作者认为，可靠的法律推理需要精确的知识检索与强大的通用推理能力相结合，可通过监督微调（SFT）或检索增强生成（RAG）提升。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理法律文本时因缺乏专门训练而导致法律知识掌握不准确，影响其在法律领域的可信度和实用性，因此需要一个专门的基准来系统评估其法律知识与推理能力。

Method: 构建了一个名为CLaw的基准，包括两个部分：一是涵盖306部中国国家法律、细分到子条款并包含历史修订信息的64,849条目语料库，用于评估法律条文的回忆能力；二是基于中国最高法院材料构建的254个案例推理任务，用于评估法律知识的实际应用能力。对多个主流LLM进行了实证评估。

Result: 实验结果显示，大多数当前的大语言模型在准确复现法律条文方面存在显著困难，导致其法律推理结果不可靠。模型在知识检索方面的缺陷严重影响了其在法律场景下的表现。

Conclusion: 实现可信的法律推理需要大语言模型具备准确的法律知识检索能力和强大的推理能力，建议结合监督微调（SFT）或检索增强生成（RAG）等方法提升性能。CLaw为领域特定的LLM研究提供了重要基准和深入洞见。

Abstract: Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.

</details>


### [145] [Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](https://arxiv.org/abs/2509.21262)
*Evgeny Kaskov,Elizaveta Petrova,Petr Surovtsev,Anna Kostikova,Ilya Mistiurin,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CL

TL;DR: 本文提出了一种测量同形异义词重复问题的方法，并通过视觉-语言模型和人工评估对不同扩散模型进行了评估，发现提示扩展可有效缓解由同形异义词和英语中心偏见引起的生成重复问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在处理同形异义词时容易产生多种词义的混合图像，且由于英语中心偏见，非英语词汇在翻译后可能变为同形异义词并丢失原意，影响生成质量。

Method: 提出一种量化同形异义词重复率的评估方法，结合视觉-语言模型进行自动评估，并辅以人工评估；同时探索通过提示扩展来缓解该问题。

Result: 实验表明扩散模型存在显著的同形异义词重复现象，提示扩展能有效降低重复率，且该方法同样适用于缓解英语中心偏见带来的语义丢失问题。

Conclusion: 提示扩展是减轻扩散模型中同形异义词重复及跨语言语义失真问题的有效策略，结合自动与人工评估可更全面地衡量模型表现。

Abstract: Homonyms are words with identical spelling but distinct meanings, which pose
challenges for many generative models. When a homonym appears in a prompt,
diffusion models may generate multiple senses of the word simultaneously, which
is known as homonym duplication. This issue is further complicated by an
Anglocentric bias, which includes an additional translation step before the
text-to-image model pipeline. As a result, even words that are not homonymous
in the original language may become homonyms and lose their meaning after
translation into English. In this paper, we introduce a method for measuring
duplication rates and conduct evaluations of different diffusion models using
both automatic evaluation utilizing Vision-Language Models (VLM) and human
evaluation. Additionally, we investigate methods to mitigate the homonym
duplication problem through prompt expansion, demonstrating that this approach
also effectively reduces duplication related to Anglocentric bias. The code for
the automatic evaluation pipeline is publicly available.

</details>


### [146] [LLM Output Homogenization is Task Dependent](https://arxiv.org/abs/2509.21267)
*Shomik Jain,Jack Lanchantin,Maximilian Nickel,Karen Ullrich,Ashia Wilson,Jamelle Watson-Daniels*

Main category: cs.CL

TL;DR: 本文提出了一个任务分类法，引入了任务锚定的功能多样性来评估和缓解大语言模型输出同质化问题，并提出了一种任务锚定采样技术，在保持响应质量的同时提高功能多样性。


<details>
  <summary>Details</summary>
Motivation: 现有研究在处理输出同质化时未能根据任务类型定义多样性，导致评估和改进方法不够精准。

Method: 提出了包含八个任务类别的分类体系，定义了任务相关的功能多样性指标，并设计了任务锚定的采样方法以提升所需任务中的多样性。

Result: 实验表明该方法能在需要多样性的任务中增加功能多样性，同时在需要一致性的任务中保持同质化，且不牺牲生成质量。

Conclusion: 任务依赖性能够有效提升对输出同质化的评估与缓解能力，挑战了多样性与质量之间存在权衡的传统观点。

Abstract: A large language model can be less helpful if it exhibits output response
homogenization. But whether two responses are considered homogeneous, and
whether such homogenization is problematic, both depend on the task category.
For instance, in objective math tasks, we often expect no variation in the
final answer but anticipate variation in the problem-solving strategy. Whereas,
for creative writing tasks, we may expect variation in key narrative components
(e.g. plot, genre, setting, etc), beyond the vocabulary or embedding diversity
produced by temperature-sampling. Previous work addressing output
homogenization often fails to conceptualize diversity in a task-dependent way.
We address this gap in the literature directly by making the following
contributions. (1) We present a task taxonomy comprised of eight task
categories that each have distinct conceptualizations of output homogenization.
(2) We introduce task-anchored functional diversity to better evaluate output
homogenization. (3) We propose a task-anchored sampling technique that
increases functional diversity for task categories where homogenization is
undesired, while preserving homogenization where it is desired. (4) We
challenge the perceived existence of a diversity-quality trade-off by
increasing functional diversity while maintaining response quality. Overall, we
demonstrate how task dependence improves the evaluation and mitigation of
output homogenization.

</details>


### [147] [LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text](https://arxiv.org/abs/2509.21269)
*Irina Tolstykh,Aleksandra Tsybina,Sergey Yakubson,Maksim Kuprashevich*

Main category: cs.CL

TL;DR: 本文介绍了LLMTrace，一个大规模、双语（英语和俄语）的AI生成文本检测语料库，填补了现有数据集在模型时效性、语言多样性和混合作者场景下字符级标注的空白，支持全文二分类和AI生成片段定位两种任务。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成文本检测数据集存在模型过时、语言单一、缺乏对人机混合创作场景中AI生成部分精确定位的支持等问题，限制了检测技术的发展。

Method: 利用多种现代闭源和开源大语言模型构建了一个大规模双语语料库，并提供了字符级别的标注，以支持全文检测和AI生成区间定位任务。

Result: LLMTrace数据集能够有效支持两种关键任务：传统的全篇人类vs. AI分类以及新颖的AI生成片段区间检测，具备更高的实用性和细粒度分析能力。

Conclusion: LLMTrace为训练和评估下一代更精细、更实用的AI生成文本检测模型提供了重要资源，有望推动该领域的进一步发展。

Abstract: The widespread use of human-like text from Large Language Models (LLMs)
necessitates the development of robust detection systems. However, progress is
limited by a critical lack of suitable training data; existing datasets are
often generated with outdated models, are predominantly in English, and fail to
address the increasingly common scenario of mixed human-AI authorship.
Crucially, while some datasets address mixed authorship, none provide the
character-level annotations required for the precise localization of
AI-generated segments within a text. To address these gaps, we introduce
LLMTrace, a new large-scale, bilingual (English and Russian) corpus for
AI-generated text detection. Constructed using a diverse range of modern
proprietary and open-source LLMs, our dataset is designed to support two key
tasks: traditional full-text binary classification (human vs. AI) and the novel
task of AI-generated interval detection, facilitated by character-level
annotations. We believe LLMTrace will serve as a vital resource for training
and evaluating the next generation of more nuanced and practical AI detection
models. The project page is available at
\href{https://sweetdream779.github.io/LLMTrace-info/}{iitolstykh/LLMTrace}.

</details>


### [148] [Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond](https://arxiv.org/abs/2509.21284)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文理论分析了输入扰动对思维链（CoT）输出波动的影响，推导了输出波动在可接受范围内的输入扰动上界，并证明该上界与推理步数正相关，且无限长的推理过程也无法消除输入扰动的影响；进一步将结论应用于线性自注意力模型（LSA），证明该上界与输入嵌入和隐藏状态向量的范数负相关，实验在三个主流数据集和四个主流模型上验证了理论分析的正确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对输入扰动如何影响CoT输出的理论解释，限制了对推理过程中扰动传播机制的理解，也阻碍了提示优化方法的进一步提升。

Method: 通过理论分析推导输入扰动在CoT输出波动可控条件下的上界，并分析其与推理步数、模型结构（如LSA）中向量范数的关系，最后在多个数据集和模型上进行实验验证。

Result: 证明了输入扰动上界与推理步数正相关、与输入嵌入和隐藏状态向量范数负相关，且无限推理无法完全消除扰动影响；实验结果与理论分析一致。

Conclusion: 输入扰动对CoT输出的影响存在理论上的上界，其受推理步数和模型内部向量范数共同影响，提示设计需综合考虑这些因素以提升鲁棒性。

Abstract: Existing research indicates that the output of Chain-of-Thought (CoT) is
significantly affected by input perturbations. Although many methods aim to
mitigate such impact by optimizing prompts, a theoretical explanation of how
these perturbations influence CoT outputs remains an open area of research.
This gap limits our in-depth understanding of how input perturbations propagate
during the reasoning process and hinders further improvements in prompt
optimization methods. Therefore, in this paper, we theoretically analyze the
effect of input perturbations on the fluctuation of CoT outputs. We first
derive an upper bound for input perturbations under the condition that the
output fluctuation is within an acceptable range, based on which we prove that:
(i) This upper bound is positively correlated with the number of reasoning
steps in the CoT; (ii) Even an infinitely long reasoning process cannot
eliminate the impact of input perturbations. We then apply these conclusions to
the Linear Self-Attention (LSA) model, which can be viewed as a simplified
version of the Transformer. For the LSA model, we prove that the upper bound
for input perturbation is negatively correlated with the norms of the input
embedding and hidden state vectors. To validate this theoretical analysis, we
conduct experiments on three mainstream datasets and four mainstream models.
The experimental results align with our theoretical analysis, empirically
demonstrating the correctness of our findings.

</details>


### [149] [DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding](https://arxiv.org/abs/2509.21287)
*Kin Ian Lo,Hala Hawashin,Mina Abbaszadeh,Tilen Limback-Stokin,Hadi Wazni,Mehrnoosh Sadrzadeh*

Main category: cs.CL

TL;DR: DisCoCLIP是一种结合冻结的CLIP视觉变换器与新型张量网络文本编码器的多模态模型，通过显式编码句法结构提升语言-视觉任务中的组合推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型通常忽视语言的组合结构，导致在依赖词序和谓词-论元结构的任务上表现不佳。

Method: 使用组合范畴语法解析句子，生成分布词张量，并通过张量分解降低高阶张量参数数量；将文本编码器与CLIP视觉编码器结合，进行端到端对比学习训练。

Result: 在SVO-Probes上动词准确率从77.6%提升至82.4%，ARO属性和关系得分分别提高9%以上和4%以上，在新提出的SVO-Swap基准上达到93.7%的准确率。

Conclusion: 通过张量网络嵌入显式语言结构可实现可解释、参数高效的表示，并显著增强视觉-语言任务中的组合推理性能。

Abstract: Recent vision-language models excel at large-scale image-text alignment but
often neglect the compositional structure of language, leading to failures on
tasks that hinge on word order and predicate-argument structure. We introduce
DisCoCLIP, a multimodal encoder that combines a frozen CLIP vision transformer
with a novel tensor network text encoder that explicitly encodes syntactic
structure. Sentences are parsed with a Combinatory Categorial Grammar parser to
yield distributional word tensors whose contractions mirror the sentence's
grammatical derivation. To keep the model efficient, high-order tensors are
factorized with tensor decompositions, reducing parameter count from tens of
millions to under one million. Trained end-to-end with a self-supervised
contrastive loss, DisCoCLIP markedly improves sensitivity to verb semantics and
word order: it raises CLIP's SVO-Probes verb accuracy from 77.6% to 82.4%,
boosts ARO attribution and relation scores by over 9% and 4%, and achieves
93.7% on a newly introduced SVO-Swap benchmark. These results demonstrate that
embedding explicit linguistic structure via tensor networks yields
interpretable, parameter-efficient representations that substantially improve
compositional reasoning in vision-language tasks.

</details>


### [150] [The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages](https://arxiv.org/abs/2509.21294)
*Pranjal A. Chitale,Varun Gumma,Sanchit Ahuja,Prashant Kodali,Manan Uppadhyay,Deepthi Sudharsan,Sunayana Sitaram*

Main category: cs.CL

TL;DR: 本文提出了一种基于语言特定维基百科内容的自下而上合成数据生成方法，构建了包含13种印度语言的950万条指令跟随数据集Updesh，显著提升了低/中资源语言在多语言AI任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据多依赖从高资源语言（如英语）翻译，缺乏文化语境，难以有效支持低资源多语言AI系统的发展。

Method: 利用参数规模≥235B的开源大语言模型，以维基百科内容为文化基础，采用自下而上的方式生成具有文化语境的多语言合成数据，并构建Updesh数据集。

Result: 生成的数据质量较高；在15个下游多语言任务中，基于Updesh微调的模型在生成任务上表现显著提升，在理解任务上具竞争力，尤其缩小了低/中资源语言与高资源语言之间的性能差距。

Conclusion: 有效的多语言AI需要融合上下文感知和文化扎根的多维度数据生成策略，自下而上的合成方法是推动低资源语言发展的重要路径。

Abstract: Developing AI systems that operate effectively across languages while
remaining culturally grounded is a long-standing challenge, particularly in
low-resource settings. Synthetic data provides a promising avenue, yet its
effectiveness in multilingual and multicultural contexts remains underexplored.
We investigate the creation and impact of synthetic, culturally contextualized
datasets for Indian languages through a bottom-up generation strategy that
prompts large open-source LLMs (>= 235B parameters) to ground data generation
in language-specific Wikipedia content. This approach complements the dominant
top-down paradigm of translating synthetic datasets from high-resource
languages such as English. We introduce Updesh, a high-quality large-scale
synthetic instruction-following dataset comprising 9.5M data points across 13
Indian languages, encompassing diverse reasoning and generative tasks with an
emphasis on long-context, multi-turn capabilities, and alignment with Indian
cultural contexts. A comprehensive evaluation incorporating both automated
metrics and human annotation across 10k assessments indicates that generated
data is high quality; though, human evaluation highlights areas for further
improvement. Additionally, we perform downstream evaluations by fine-tuning
models on our dataset and assessing the performance across 15 diverse
multilingual datasets. Models trained on Updesh consistently achieve
significant gains on generative tasks and remain competitive on multiple-choice
style NLU tasks. Notably, relative improvements are most pronounced in low and
medium-resource languages, narrowing their gap with high-resource languages.
These findings provide empirical evidence that effective multilingual AI
requires multi-faceted data curation and generation strategies that incorporate
context-aware, culturally grounded methodologies.

</details>


### [151] [Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs](https://arxiv.org/abs/2509.21305)
*Daniel Vennemeyer,Phan Anh Duong,Tiffany Zhan,Tianyu Jiang*

Main category: cs.CL

TL;DR: 该研究将大语言模型中的谄媚行为分解为谄媚性同意和谄媚性赞美，并与真实同意进行对比，发现这三种行为在潜在空间中由不同的线性方向编码，可独立调控且跨模型具有一致性。


<details>
  <summary>Details</summary>
Motivation: 明确大语言模型中谄媚行为是否由单一机制或多种不同过程引起。

Method: 使用均值差异方向、激活添加和子空间几何方法，在多个模型和数据集上分析谄媚性同意、谄媚性赞美与 genuine agreement 的表示差异。

Result: 三种行为在潜在空间中有 distinct 线性方向；可独立增强或抑制每种行为而不影响其他行为；其表征结构在不同模型家族和规模间一致。

Conclusion: 谄媚行为对应于不同且可独立操控的表示，表明其源于多个独立机制而非单一机制。

Abstract: Large language models (LLMs) often exhibit sycophantic behaviors -- such as
excessive agreement with or flattery of the user -- but it is unclear whether
these behaviors arise from a single mechanism or multiple distinct processes.
We decompose sycophancy into sycophantic agreement and sycophantic praise,
contrasting both with genuine agreement. Using difference-in-means directions,
activation additions, and subspace geometry across multiple models and
datasets, we show that: (1) the three behaviors are encoded along distinct
linear directions in latent space; (2) each behavior can be independently
amplified or suppressed without affecting the others; and (3) their
representational structure is consistent across model families and scales.
These results suggest that sycophantic behaviors correspond to distinct,
independently steerable representations.

</details>


### [152] [RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards](https://arxiv.org/abs/2509.21319)
*Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev*

Main category: cs.CL

TL;DR: 提出了一种新的强化学习范式RLBFF，结合人类反馈的灵活性和规则验证的精确性，通过二元原则提升奖励模型的可解释性和性能，在多个基准上取得领先结果，并提供开源方案高效对齐大模型。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法因缺乏明确标准导致可解释性差和奖励黑客问题，而RLVR局限于正确性验证，无法捕捉响应质量的细微方面，因此需要一种兼具灵活性与精确性的新方法。

Method: 提出RLBFF框架，从自然语言反馈中提取可二元判断的原则（如信息准确性、代码可读性），将奖励模型训练建模为蕴含任务（即判断响应是否满足某原则），支持推理时按需指定关注原则。

Result: 所训练的奖励模型在RM-Bench（86.2%）和JudgeBench（81.4%，截至2025年9月24日排名第一）上表现优异，优于Bradley-Terry模型；并通过开源流程用<5%的推理成本使Qwen3-32B在MT-Bench、WildBench和Arena Hard v2上达到或超越o3-mini和DeepSeek R1。

Conclusion: RLBFF通过融合人类偏好与规则验证，提升了奖励模型的灵活性、可定制性和性能，为大模型对齐提供高效且开放的新路径。

Abstract: Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning
with Verifiable Rewards (RLVR) are the main RL paradigms used in LLM
post-training, each offering distinct advantages. However, RLHF struggles with
interpretability and reward hacking because it relies on human judgments that
usually lack explicit criteria, whereas RLVR is limited in scope by its focus
on correctness-based verifiers. We propose Reinforcement Learning with Binary
Flexible Feedback (RLBFF), which combines the versatility of human-driven
preferences with the precision of rule-based verification, enabling reward
models to capture nuanced aspects of response quality beyond mere correctness.
RLBFF extracts principles that can be answered in a binary fashion (e.g.
accuracy of information: yes, or code readability: no) from natural language
feedback. Such principles can then be used to ground Reward Model training as
an entailment task (response satisfies or does not satisfy an arbitrary
principle). We show that Reward Models trained in this manner can outperform
Bradley-Terry models when matched for data and achieve top performance on
RM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24,
2025). Additionally, users can specify principles of interest at inference time
to customize the focus of our reward models, in contrast to Bradley-Terry
models. Finally, we present a fully open source recipe (including data) to
align Qwen3-32B using RLBFF and our Reward Model, to match or exceed the
performance of o3-mini and DeepSeek R1 on general alignment benchmarks of
MT-Bench, WildBench, and Arena Hard v2 (at <5% of the inference cost).

</details>


### [153] [SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines](https://arxiv.org/abs/2509.21320)
*Yizhou Wang,Chen Tang,Han Deng,Jiabei Xiao,Jiaqi Liu,Jianyu Wu,Jun Yao,Pengze Li,Encheng Su,Lintao Wang,Guohang Zhuang,Yuchen Ren,Ben Fei,Ming Hu,Xin Chen,Dongzhan Zhou,Junjun He,Xiangyu Yue,Zhenfei Yin,Jiamin Wu,Qihao Zheng,Yuhao Zhou,Huihui Xu,Chenglong Ma,Yan Lu,Wenlong Zhang,Chunfeng Song,Philip Torr,Shixiang Tang,Xinzhu Ma,Wanli Ouyang,Lei Bai*

Main category: cs.CL

TL;DR: 提出了一种科学推理基础模型，通过多阶段训练对齐自然语言与科学表示，在103个任务上展现出广泛的指令覆盖、跨领域泛化和高保真性能。


<details>
  <summary>Details</summary>
Motivation: 为了提升现有模型在科学领域的推理能力，解决跨学科知识整合与多格式表达对齐的问题，需要一个能够进行长链思维并支持多种科学任务的通用基础模型。

Method: 在206B token的科学文本、纯序列和序列-文本对数据上预训练，结合SFT、退火冷启动自举生成长链思维，并通过任务特定奖励塑形的强化学习进行对齐。

Result: 模型支持五类能力共103项任务，相比专用系统具有更广的指令覆盖、更好的跨域泛化和更高的保真度，且开源了模型、指令微调数据集和评估代码。

Conclusion: 该科学推理基础模型通过多阶段对齐训练，有效整合自然语言与科学表示，显著提升跨学科任务的泛化能力和推理忠实性，推动开放科学AI的发展。

Abstract: We present a scientific reasoning foundation model that aligns natural
language with heterogeneous scientific representations. The model is pretrained
on a 206B-token corpus spanning scientific text, pure sequences, and
sequence-text pairs, then aligned via SFT on 40M instructions, annealed
cold-start bootstrapping to elicit long-form chain-of-thought, and
reinforcement learning with task-specific reward shaping, which instills
deliberate scientific reasoning. It supports four capability families, covering
up to 103 tasks across workflows: (i) faithful translation between text and
scientific formats, (ii) text/knowledge extraction, (iii) property prediction,
(iv) property classification, (v) unconditional and conditional sequence
generation and design. Compared with specialist systems, our approach broadens
instruction coverage, improves cross-domain generalization, and enhances
fidelity. We detail data curation and training and show that cross-discipline
learning strengthens transfer and downstream reliability. The model, instruct
tuning datasets and the evaluation code are open-sourced at
https://huggingface.co/SciReason and
https://github.com/open-sciencelab/SciReason.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [154] [Boosting LiDAR-Based Localization with Semantic Insight: Camera Projection versus Direct LiDAR Segmentation](https://arxiv.org/abs/2509.20486)
*Sven Ochs,Philip Schörner,Marc René Zofka,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 本文提出了一种将语义相机数据与LiDAR分割融合的方法，以提升自动驾驶系统中LiDAR定位的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LiDAR语义分割在面对多种传感器类型和配置时存在挑战，而语义信息的引入有助于提高定位性能。

Method: 通过将LiDAR点云投影到相机的语义分割空间，实现多模态语义对齐，并结合Depth-Anything和自适应网络进行图像与LiDAR分割。

Result: 在CoCar NextGen平台上进行了55公里城市驾驶测试，利用GNSS RTK作为真值，验证了该方法在复杂环境下的有效性。

Conclusion: 该多模态方法显著提升了LiDAR定位的精度与可靠性，为复杂真实场景中的自动驾驶导航提供了可行方案。

Abstract: Semantic segmentation of LiDAR data presents considerable challenges,
particularly when dealing with diverse sensor types and configurations.
However, incorporating semantic information can significantly enhance the
accuracy and robustness of LiDAR-based localization techniques for autonomous
mobile systems. We propose an approach that integrates semantic camera data
with LiDAR segmentation to address this challenge. By projecting LiDAR points
into the semantic segmentation space of the camera, our method enhances the
precision and reliability of the LiDAR-based localization pipeline.
  For validation, we utilize the CoCar NextGen platform from the FZI Research
Center for Information Technology, which offers diverse sensor modalities and
configurations. The sensor setup of CoCar NextGen enables a thorough analysis
of different sensor types. Our evaluation leverages the state-of-the-art
Depth-Anything network for camera image segmentation and an adaptive
segmentation network for LiDAR segmentation. To establish a reliable ground
truth for LiDAR-based localization, we make us of a Global Navigation Satellite
System (GNSS) solution with Real-Time Kinematic corrections (RTK).
Additionally, we conduct an extensive 55 km drive through the city of
Karlsruhe, Germany, covering a variety of environments, including urban areas,
multi-lane roads, and rural highways. This multimodal approach paves the way
for more reliable and precise autonomous navigation systems, particularly in
complex real-world environments.

</details>


### [155] [Revisiting Formal Methods for Autonomous Robots: A Structured Survey](https://arxiv.org/abs/2509.20488)
*Atef Azaiez,David A. Anisi,Marie Farrell,Matt Luckcuck*

Main category: cs.RO

TL;DR: 本文介绍了对形式化方法在机器人自主系统（RAS）中应用的结构化文献综述的初步结果，描述了调查方法、分类和统计使用的形式化方法，并探讨了在子符号AI驱动的RAS中形式化方法的演变趋势。


<details>
  <summary>Details</summary>
Motivation: 为了系统地了解形式化方法在机器人自主系统中的应用现状与发展趋势，弥补已有综述的不足，并揭示新兴趋势。

Method: 采用结构化文献综述方法，包括数据库选择、搜索策略设计、筛选标准及协作式论文评审，对相关研究进行分类与分析。

Result: 识别并分类了用于RAS规范与验证的形式化方法；发现以往趋势持续存在，同时出现了新趋势，如形式化合成方法和概率验证技术的显著增加。

Conclusion: 该领域在近年来持续发展，形式化方法的应用呈现多样化和深化趋势，尤其在AI驱动的RAS中，形式化合成与概率验证成为重要发展方向。

Abstract: This paper presents the initial results from our structured literature review
on applications of Formal Methods (FM) to Robotic Autonomous Systems (RAS). We
describe our structured survey methodology; including database selection and
associated search strings, search filters and collaborative review of
identified papers. We categorise and enumerate the FM approaches and formalisms
that have been used for specification and verification of RAS. We investigate
FM in the context of sub-symbolic AI-enabled RAS and examine the evolution of
how FM is used over time in this field. This work complements a pre-existing
survey in this area and we examine how this research area has matured over
time. Specifically, our survey demonstrates that some trends have persisted as
observed in a previous survey. Additionally, it recognized new trends that were
not considered previously including a noticeable increase in adopting Formal
Synthesis approaches as well as Probabilistic Verification Techniques.

</details>


### [156] [Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting](https://arxiv.org/abs/2509.20499)
*Boqi Li,Siyuan Li,Weiyi Wang,Anran Li,Zhong Cao,Henry X. Liu*

Main category: cs.RO

TL;DR: 提出一种零样本框架，结合简化且有效的航路点预测器与多模态大语言模型（MLLM），在连续环境中的视觉语言导航任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言导航（VLN）在具身智能体中具有广泛应用，但在连续环境中面临理解自然语言指令、感知环境和规划低层动作的联合挑战。

Method: 设计一个基于抽象障碍地图的航路点预测器，生成可达航路点，并将其整合到动态更新的拓扑图中；利用显式访问记录编码空间结构和探索历史，通过提示使MLLM具备局部路径规划和错误纠正能力。

Result: 在R2R-CE和RxR-CE数据集上进行实验，分别取得41%和36%的成功率，优于先前最先进方法。

Conclusion: 所提框架在连续环境的VLN任务中实现了卓越的零样本性能，验证了结合结构化空间推理与大模型语义理解的有效性。

Abstract: With the rapid progress of foundation models and robotics, vision-language
navigation (VLN) has emerged as a key task for embodied agents with broad
practical applications. We address VLN in continuous environments, a
particularly challenging setting where an agent must jointly interpret natural
language instructions, perceive its surroundings, and plan low-level actions.
We propose a zero-shot framework that integrates a simplified yet effective
waypoint predictor with a multimodal large language model (MLLM). The predictor
operates on an abstract obstacle map, producing linearly reachable waypoints,
which are incorporated into a dynamically updated topological graph with
explicit visitation records. The graph and visitation information are encoded
into the prompt, enabling reasoning over both spatial structure and exploration
history to encourage exploration and equip MLLM with local path planning for
error correction. Extensive experiments on R2R-CE and RxR-CE show that our
method achieves state-of-the-art zero-shot performance, with success rates of
41% and 36%, respectively, outperforming prior state-of-the-art methods.

</details>


### [157] [MELEGROS: Monolithic Elephant-inspired Gripper with Optical Sensors](https://arxiv.org/abs/2509.20510)
*Petr Trunin,Diana Cafiso,Anderson Brazil Nardin,Trevor Exley,Lucia Beccai*

Main category: cs.RO

TL;DR: MELEGROS是一种受非洲象鼻启发的单体软体抓手，通过一体化3D打印将光学传感器和气动结构集成于单一材料中，实现了触觉与本体感知信号的解耦，并展现出强大的多功能感知与操作能力。


<details>
  <summary>Details</summary>
Motivation: 受象鼻多模态感知与灵活操作的启发，旨在开发一种传感与结构、驱动一体化集成的软体机器人，克服传统多材料或腱驱动系统中机械不匹配和建模不确定的问题。

Method: 采用单步3D打印技术，将六个光学波导传感器和五个气动腔室集成到一个气动驱动的晶格结构中，使用单一软树脂材料实现整体化制造，并通过仿真指导传感器设计与布局。

Result: 仅经四次迭代即实现最终原型，该抓手可伸长、压缩和弯曲，能承载超过自重两倍的负载，完成捏取、舀取和延伸等生物启发动作，并能轻柔抓握葡萄等易碎物品；集成的光学传感器可区分触摸、弯曲和腔室形变信号，实现多模态感知。

Conclusion: MELEGROS展示了一种软体机器人新范式，即通过全嵌入式传感与连续结构设计，实现内在支持多功能、生物启发操作的一体化系统。

Abstract: The elephant trunk exemplifies a natural gripper where structure, actuation,
and sensing are seamlessly integrated. Inspired by the distal morphology of the
African elephant trunk, we present MELEGROS, a Monolithic ELEphant-inspired
GRipper with Optical Sensors, emphasizing sensing as an intrinsic,
co-fabricated capability. Unlike multi-material or tendon-based approaches,
MELEGROS directly integrates six optical waveguide sensors and five pneumatic
chambers into a pneumatically actuated lattice structure (12.5 mm cell size)
using a single soft resin and one continuous 3D print. This eliminates
mechanical mismatches between sensors, actuators, and body, reducing model
uncertainty and enabling simulation-guided sensor design and placement. Only
four iterations were required to achieve the final prototype, which features a
continuous structure capable of elongation, compression, and bending while
decoupling tactile and proprioceptive signals. MELEGROS (132 g) lifts more than
twice its weight, performs bioinspired actions such as pinching, scooping, and
reaching, and delicately grasps fragile items like grapes. The integrated
optical sensors provide distinct responses to touch, bending, and chamber
deformation, enabling multifunctional perception. MELEGROS demonstrates a new
paradigm for soft robotics where fully embedded sensing and continuous
structures inherently support versatile, bioinspired manipulation.

</details>


### [158] [Action-Informed Estimation and Planning: Clearing Clutter on Staircases via Quadrupedal Pedipulation](https://arxiv.org/abs/2509.20516)
*Prasanna Sriganesh,Barath Satheeshkumar,Anushree Sabnis,Matthew Travers*

Main category: cs.RO

TL;DR: 本文提出了一种交互感知的感知-动作框架，用于四足机器人在楼梯等复杂环境中单腿推动物体时，通过本体感知反馈实现物体遮挡期间的状态估计与重新检测，从而提高任务成功率和跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 在密集杂乱环境中，机器人需要与障碍物进行物理交互以开辟路径，但在传感器视野被遮挡的情况下难以持续跟踪物体状态，影响操作的鲁棒性。

Method: 提出一种紧耦合的感知-动作框架，核心是一个交互感知的状态估计环路，利用足部接触和腿部位置的本体感知信息预测遮挡期间物体的位移，并指导感知系统在交互后重新检测物体，形成闭环反馈。

Result: 在Boston Dynamics Spot机器人上的实验表明，相比开环基线方法，该方法在楼梯上推动物体的任务中具有更高的任务成功率和跟踪准确性，并能根据推动失败判断物体是否不可移动。

Conclusion: 所提出的交互-aware状态估计方法有效解决了单腿推动过程中物体遮挡带来的感知挑战，提升了四足机器人在复杂环境中的自主导航与操作能力。

Abstract: For robots to operate autonomously in densely cluttered environments, they
must reason about and potentially physically interact with obstacles to clear a
path. Safely clearing a path on challenging terrain, such as a cluttered
staircase, requires controlled interaction. For example, a quadrupedal robot
that pushes objects out of the way with one leg while maintaining a stable
stance with its three other legs. However, tightly coupled physical actions,
such as one-legged pushing, create new constraints on the system that can be
difficult to predict at design time. In this work, we present a new method that
addresses one such constraint, wherein the object being pushed by a quadrupedal
robot with one of its legs becomes occluded from the robot's sensors during
manipulation. To address this challenge, we present a tightly coupled
perception-action framework that enables the robot to perceive clutter, reason
about feasible push paths, and execute the clearing maneuver. Our core
contribution is an interaction-aware state estimation loop that uses
proprioceptive feedback regarding foot contact and leg position to predict an
object's displacement during the occlusion. This prediction guides the
perception system to robustly re-detect the object after the interaction,
closing the loop between action and sensing to enable accurate tracking even
after partial pushes. Using this feedback allows the robot to learn from
physical outcomes, reclassifying an object as immovable if a push fails due to
it being too heavy. We present results of implementing our approach on a Boston
Dynamics Spot robot that show our interaction-aware approach achieves higher
task success rates and tracking accuracy in pushing objects on stairs compared
to open-loop baselines.

</details>


### [159] [Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning](https://arxiv.org/abs/2509.20541)
*Anujith Muraleedharan,Anamika J H*

Main category: cs.RO

TL;DR: 本文提出了SPARQ，一种基于学习进展的反馈查询策略，可在机器人强化学习中显著减少人类反馈需求，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于人类反馈的强化学习方法通常假设反馈充足，但在实际应用中人类反馈有限且成本高，因此需要更高效的反馈利用机制。

Method: 提出SPARQ，一种进度感知的查询策略，仅在学习停滞或退化时请求人类反馈，从而减少不必要的查询。

Result: 在PyBullet模拟的UR5抓取任务中，SPARQ在仅使用约一半反馈预算的情况下，达到与始终查询相当的成功率，优于无反馈和随机查询基线。

Conclusion: 基于进展的主动查询策略能有效提升人机协同强化学习的效率和可扩展性，更适合现实场景中的机器人部署。

Abstract: Human feedback can greatly accelerate robot learning, but in real-world
settings, such feedback is costly and limited. Existing human-in-the-loop
reinforcement learning (HiL-RL) methods often assume abundant feedback,
limiting their practicality for physical robot deployment. In this work, we
introduce SPARQ, a progress-aware query policy that requests feedback only when
learning stagnates or worsens, thereby reducing unnecessary oracle calls. We
evaluate SPARQ on a simulated UR5 cube-picking task in PyBullet, comparing
against three baselines: no feedback, random querying, and always querying. Our
experiments show that SPARQ achieves near-perfect task success, matching the
performance of always querying while consuming about half the feedback budget.
It also provides more stable and efficient learning than random querying, and
significantly improves over training without feedback. These findings suggest
that selective, progress-based query strategies can make HiL-RL more efficient
and scalable for robots operating under realistic human effort constraints.

</details>


### [160] [GraspFactory: A Large Object-Centric Grasping Dataset](https://arxiv.org/abs/2509.20550)
*Srinidhi Kalgundi Srinivas,Yash Shukla,Adam Arnold,Sachin Chitta*

Main category: cs.RO

TL;DR: 本文提出了GraspFactory，一个包含超过1亿个6自由度抓取数据的大规模数据集，用于训练具有泛化能力的机器人抓取模型，并在仿真和真实环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取模型在面对新物体时泛化能力受限，主要由于训练数据集的几何多样性不足。为提升模型在真实工业环境（如仓库和制造工厂）中处理多样化物体的能力，需要大规模、多样化的抓取数据集。

Method: 构建了一个名为GraspFactory的大规模抓取数据集，包含超过1.09亿个6-DoF抓取标注，涵盖Franka Panda和Robotiq 2F-85两种夹爪，分别对应14,690和33,710种不同物体。使用该数据集的一个子集训练数据密集型抓取模型，并在仿真和真实世界中评估其泛化性能。

Result: 实验证明，基于GraspFactory子集训练的模型在仿真和真实环境中均表现出良好的泛化能力，能够有效处理多种新颖物体。

Conclusion: GraspFactory为训练高泛化性、数据密集型的机器人抓取模型提供了重要资源，推动了机器人在复杂现实场景中的应用。

Abstract: Robotic grasping is a crucial task in industrial automation, where robots are
increasingly expected to handle a wide range of objects. However, a significant
challenge arises when robot grasping models trained on limited datasets
encounter novel objects. In real-world environments such as warehouses or
manufacturing plants, the diversity of objects can be vast, and grasping models
need to generalize to this diversity. Training large, generalizable
robot-grasping models requires geometrically diverse datasets. In this paper,
we introduce GraspFactory, a dataset containing over 109 million 6-DoF grasps
collectively for the Franka Panda (with 14,690 objects) and Robotiq 2F-85
grippers (with 33,710 objects). GraspFactory is designed for training
data-intensive models, and we demonstrate the generalization capabilities of
one such model trained on a subset of GraspFactory in both simulated and
real-world settings. The dataset and tools are made available for download at
https://graspfactory.github.io/.

</details>


### [161] [Uncertainty-Aware Active Source Tracking of Marine Pollution using Unmanned Surface Vehicles](https://arxiv.org/abs/2509.20593)
*Song Ma,Richard Bucknall,Yuanchang Liu*

Main category: cs.RO

TL;DR: 提出一种基于ROS的不确定性感知海上污染源追踪框架，通过融合高精度污染扩散模拟与信息路径规划，实现对污染源的高效精确定位。


<details>
  <summary>Details</summary>
Motivation: 为了提升海洋环境污染事件的快速响应能力，需要发展能够自主、准确识别污染源的技术。

Method: 将高保真污染扩散仿真与信息路径规划技术结合，基于ROS处理实时传感器数据，动态更新污染源位置的概率估计，并量化预测中的不确定性。

Result: 在不同污染源位置、水流条件和起始位置的仿真实验中，该框架均能高效且准确地定位污染源。

Conclusion: 所提方法实现了可靠的污染源定位，推动了无人水面艇全自主环境监测能力的发展。

Abstract: This paper proposes an uncertainty-aware marine pollution source tracking
framework for unmanned surface vehicles (USVs). By integrating high-fidelity
marine pollution dispersion simulation with informative path planning
techniques, we demonstrate effective identification of pollution sources in
marine environments. The proposed approach is implemented based on Robot
Operating System (ROS), processing real-time sensor data to update
probabilistic source location estimates. The system progressively refines the
estimation of source location while quantifying uncertainty levels in its
predictions. Experiments conducted in simulated environments with varying
source locations, flow conditions, and starting positions demonstrate the
framework's ability to localise pollution sources with high accuracy. Results
show that the proposed approach achieves reliable source localisation
efficiently. This work contributes to the development of full autonomous
environmental monitoring capabilities essential for rapid response to marine
pollution incidents.

</details>


### [162] [Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation](https://arxiv.org/abs/2509.20623)
*Satyajeet Das,Darren Chiu,Zhehui Huang,Lars Lindemann,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: 提出了一种推理时潜在激活编辑（LAE）框架，用于在不修改预训练策略权重的情况下提升多旋翼无人机导航中的安全性，显著减少碰撞并保持任务完成能力。


<details>
  <summary>Details</summary>
Motivation: 已有的强化学习策略在障碍物丰富的环境中仍易发生碰撞，重新训练成本高且可能破坏已有技能。

Method: 通过在线分类器检测可能导致危险行为的中间激活，并利用激活编辑模块调整这些激活，增强策略对风险的感知，从而引导更安全的行为。具体实现包括训练一个预测未来碰撞前激活的潜在碰撞世界模型。

Result: 在仿真和真实Crazyflie无人机实验中，LAE相比基线减少了近90%的累计碰撞，显著增加了无碰撞轨迹的比例，同时保持任务完成率。

Conclusion: LAE是一种轻量级、可在资源受限硬件上运行的有效方法，适用于部署后对学习到的机器人策略进行安全增强。

Abstract: Reinforcement learning has enabled significant progress in complex domains
such as coordinating and navigating multiple quadrotors. However, even
well-trained policies remain vulnerable to collisions in obstacle-rich
environments. Addressing these infrequent but critical safety failures through
retraining or fine-tuning is costly and risks degrading previously learned
skills. Inspired by activation steering in large language models and latent
editing in computer vision, we introduce a framework for inference-time Latent
Activation Editing (LAE) that refines the behavior of pre-trained policies
without modifying their weights or architecture. The framework operates in two
stages: (i) an online classifier monitors intermediate activations to detect
states associated with undesired behaviors, and (ii) an activation editing
module that selectively modifies flagged activations to shift the policy
towards safer regimes. In this work, we focus on improving safety in
multi-quadrotor navigation. We hypothesize that amplifying a policy's internal
perception of risk can induce safer behaviors. We instantiate this idea through
a latent collision world model trained to predict future pre-collision
activations, thereby prompting earlier and more cautious avoidance responses.
Extensive simulations and real-world Crazyflie experiments demonstrate that LAE
achieves statistically significant reduction in collisions (nearly 90% fewer
cumulative collisions compared to the unedited baseline) and substantially
increases the fraction of collision-free trajectories, while preserving task
completion. More broadly, our results establish LAE as a lightweight paradigm,
feasible on resource-constrained hardware, for post-deployment refinement of
learned robot policies.

</details>


### [163] [Learning Terrain-Specialized Policies for Adaptive Locomotion in Challenging Environments](https://arxiv.org/abs/2509.20635)
*Matheus P. Angarola,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出了一种基于分层强化学习的框架，利用地形专用策略和课程学习来提升复杂环境中盲足式机器人运动的敏捷性和跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在缺乏地形信息的盲行条件下，实现腿式机器人在复杂非结构化地形上的鲁棒与敏捷运动是一大挑战。

Method: 采用分层强化学习框架，结合地形专用策略与课程学习，在模拟环境中进行训练与验证。

Result: 在模拟中，相比通用策略，成功率最高提升16%，尤其在低摩擦和不连续地形上，速度目标增加时仍保持更低的跟踪误差。

Conclusion: 所提方法在混合地形场景中表现出更强的适应性与鲁棒性，显著提升了盲足式机器人的运动性能。

Abstract: Legged robots must exhibit robust and agile locomotion across diverse,
unstructured terrains, a challenge exacerbated under blind locomotion settings
where terrain information is unavailable. This work introduces a hierarchical
reinforcement learning framework that leverages terrain-specialized policies
and curriculum learning to enhance agility and tracking performance in complex
environments. We validated our method on simulation, where our approach
outperforms a generalist policy by up to 16% in success rate and achieves lower
tracking errors as the velocity target increases, particularly on low-friction
and discontinuous terrains, demonstrating superior adaptability and robustness
across mixed-terrain scenarios.

</details>


### [164] [Suction Leap-Hand: Suction Cups on a Multi-fingered Hand Enable Embodied Dexterity and In-Hand Teleoperation](https://arxiv.org/abs/2509.20646)
*Sun Zhaole,Xiaofeng Mao,Jihong Zhu,Yuanlong Zhang,Robert B. Fisher*

Main category: cs.RO

TL;DR: 本文提出了一种新型的机器人手设计——SLeap Hand，通过集成吸盘取代传统的人形力学结构，简化了灵巧操作并实现了人类难以完成的任务。


<details>
  <summary>Details</summary>
Motivation: 传统基于模仿人手的灵巧操作受限于力封闭机制，导致数据采集困难且仿真到现实迁移效果差，因此需要突破人形约束的设计新范式。

Method: 设计了带有指尖吸盘的多指机械手（SLeap Hand），利用吸附实现稳定的单点接触，替代复杂的多点摩擦力控制，并结合遥操作与强化学习进行验证。

Result: SLeap Hand 能稳定执行如单手剪纸和握持书写等人类难以完成的任务，显著降低了数据采集难度并缩小了仿真到现实的差距。

Conclusion: 非人形的新型机器人本体设计不仅能降低灵巧操作的数据获取门槛，还能实现超越人手能力的单手操作任务。

Abstract: Dexterous in-hand manipulation remains a foundational challenge in robotics,
with progress often constrained by the prevailing paradigm of imitating the
human hand. This anthropomorphic approach creates two critical barriers: 1) it
limits robotic capabilities to tasks humans can already perform, and 2) it
makes data collection for learning-based methods exceedingly difficult. Both
challenges are caused by traditional force-closure which requires coordinating
complex, multi-point contacts based on friction, normal force, and gravity to
grasp an object. This makes teleoperated demonstrations unstable and amplifies
the sim-to-real gap for reinforcement learning. In this work, we propose a
paradigm shift: moving away from replicating human mechanics toward the design
of novel robotic embodiments. We introduce the \textbf{S}uction
\textbf{Leap}-Hand (SLeap Hand), a multi-fingered hand featuring integrated
fingertip suction cups that realize a new form of suction-enabled dexterity. By
replacing complex force-closure grasps with stable, single-point adhesion, our
design fundamentally simplifies in-hand teleoperation and facilitates the
collection of high-quality demonstration data. More importantly, this
suction-based embodiment unlocks a new class of dexterous skills that are
difficult or even impossible for the human hand, such as one-handed paper
cutting and in-hand writing. Our work demonstrates that by moving beyond
anthropomorphic constraints, novel embodiments can not only lower the barrier
for collecting robust manipulation data but also enable the stable,
single-handed completion of tasks that would typically require two human hands.
Our webpage is https://sites.google.com/view/sleaphand.

</details>


### [165] [Cyber Racing Coach: A Haptic Shared Control Framework for Teaching Advanced Driving Skills](https://arxiv.org/abs/2509.20653)
*Congkai Shen,Siyuan Yu,Yifan Weng,Haoran Ma,Chen Li,Hiroshi Yasuda,James Dallas,Michael Thompson,John Subosits,Tulga Ersal*

Main category: cs.RO

TL;DR: 本研究提出了一种基于触觉共享控制的“网络赛车教练”框架，用于帮助人类驾驶员学习高性能驾驶技能，并通过实验验证其在技能获取方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有共享控制研究多关注性能与安全性，但缺乏对复杂任务中长期技能获取效果的评估；此前技能训练方法多局限于简单任务或依赖视觉、听觉反馈，因此需要一种能有效提升高难度驾驶技能的学习框架。

Method: 设计了一个具备自主驾驶能力和触觉共享控制机制的系统，并引入基于驾驶员表现动态减弱辅助的退坡策略；通过人因实验比较所提框架与无辅助自学、全程辅助两种基准条件下的技能学习效果。

Result: 实验结果表明，使用该框架训练的驾驶员在赛车技能上表现出更高的性能和一致性，显著优于两个基准组。

Conclusion: 基于触觉共享控制并结合渐减辅助策略的框架能有效促进复杂高绩效驾驶技能的长期习得，具有应用于驾驶培训等领域的潜力。

Abstract: This study introduces a haptic shared control framework designed to teach
human drivers advanced driving skills. In this context, shared control refers
to a driving mode where the human driver collaborates with an autonomous
driving system to control the steering of a vehicle simultaneously. Advanced
driving skills are those necessary to safely push the vehicle to its handling
limits in high-performance driving such as racing and emergency obstacle
avoidance. Previous research has demonstrated the performance and safety
benefits of shared control schemes using both subjective and objective
evaluations. However, these schemes have not been assessed for their impact on
skill acquisition on complex and demanding tasks. Prior research on long-term
skill acquisition either applies haptic shared control to simple tasks or
employs other feedback methods like visual and auditory aids. To bridge this
gap, this study creates a cyber racing coach framework based on the haptic
shared control paradigm and evaluates its performance in helping human drivers
acquire high-performance driving skills. The framework introduces (1) an
autonomous driving system that is capable of cooperating with humans in a
highly performant driving scenario; and (2) a haptic shared control mechanism
along with a fading scheme to gradually reduce the steering assistance from
autonomy based on the human driver's performance during training. Two
benchmarks are considered: self-learning (no assistance) and full assistance
during training. Results from a human subject study indicate that the proposed
framework helps human drivers develop superior racing skills compared to the
benchmarks, resulting in better performance and consistency.

</details>


### [166] [EEG-Driven AR-Robot System for Zero-Touch Grasping Manipulation](https://arxiv.org/abs/2509.20656)
*Junzhe Wang,Jiarui Xie,Pengfei Hao,Zheng Li,Yi Cai*

Main category: cs.RO

TL;DR: 提出一种结合运动想象脑电解码、增强现实神经反馈和机器人抓取的闭环BCI-AR-Robot系统，实现稳定、无需接触的机器人控制。


<details>
  <summary>Details</summary>
Motivation: 现有BCI-Robot系统存在脑电信号噪声大、目标选择不灵活及缺乏闭环验证等问题，限制了其在助老助残等实际场景中的应用。

Method: 采用14通道脑电帽进行个体化运动想象校准，结合基于智能手机的增强现实界面提供方向一致的神经反馈，并融合决策输出与视觉姿态估计实现机械臂自主抓取。

Result: 运动想象训练准确率达93.1%，信息传输速率平均为14.8 bit/min；增强现实神经反馈将信息传输率提升至21.3 bit/min，显著提高持续控制能力（SCI=0.210）；闭环抓取成功率达97.2%，用户反馈控制效果良好。

Conclusion: 增强现实神经反馈能显著提升脑电控制稳定性，所提出的框架实现了高效、鲁棒的零触控抓取，推动了助手机器人及人机交互的发展。

Abstract: Reliable brain-computer interface (BCI) control of robots provides an
intuitive and accessible means of human-robot interaction, particularly
valuable for individuals with motor impairments. However, existing BCI-Robot
systems face major limitations: electroencephalography (EEG) signals are noisy
and unstable, target selection is often predefined and inflexible, and most
studies remain restricted to simulation without closed-loop validation. These
issues hinder real-world deployment in assistive scenarios. To address them, we
propose a closed-loop BCI-AR-Robot system that integrates motor imagery
(MI)-based EEG decoding, augmented reality (AR) neurofeedback, and robotic
grasping for zero-touch operation. A 14-channel EEG headset enabled
individualized MI calibration, a smartphone-based AR interface supported
multi-target navigation with direction-congruent feedback to enhance stability,
and the robotic arm combined decision outputs with vision-based pose estimation
for autonomous grasping. Experiments are conducted to validate the framework:
MI training achieved 93.1 percent accuracy with an average information transfer
rate (ITR) of 14.8 bit/min; AR neurofeedback significantly improved sustained
control (SCI = 0.210) and achieved the highest ITR (21.3 bit/min) compared with
static, sham, and no-AR baselines; and closed-loop grasping achieved a 97.2
percent success rate with good efficiency and strong user-reported control.
These results show that AR feedback substantially stabilizes EEG-based control
and that the proposed framework enables robust zero-touch grasping, advancing
assistive robotic applications and future modes of human-robot interaction.

</details>


### [167] [Equi-RO: A 4D mmWave Radar Odometry via Equivariant Networks](https://arxiv.org/abs/2509.20674)
*Zeyu Han,Shuocheng Yang,Minghan Zhu,Fang Zhang,Shaobing Xu,Maani Ghaffari,Jianqiang Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于等变网络的4D毫米波雷达里程计框架Equi-RO，通过图神经网络处理稀疏雷达数据，提升了在极端天气下的定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GPS受限环境中，传统传感器如LiDAR和相机在恶劣天气下性能下降，而4D毫米波雷达具备全天候工作能力，因此需要一种更鲁棒的雷达里程计算法。

Method: 提出Equi-RO框架，将多普勒速度预处理为图中的不变节点和边特征，采用分离网络分别处理等变和不变特征，并利用图结构增强稀疏雷达数据的特征聚合与帧间匹配。

Result: 在公开和自采集数据集上实验表明，Equi-RO优于现有最先进方法，在公开数据集上相比最佳基线相对提升了10.7%（平移）和20.0%（旋转）精度。

Conclusion: Equi-RO通过等变网络和图结构设计，有效提升了4D毫米波雷达里程计的精度与鲁棒性，适用于极端天气下的自动驾驶与机器人导航。

Abstract: Autonomous vehicles and robots rely on accurate odometry estimation in
GPS-denied environments. While LiDARs and cameras struggle under extreme
weather, 4D mmWave radar emerges as a robust alternative with all-weather
operability and velocity measurement. In this paper, we introduce Equi-RO, an
equivariant network-based framework for 4D radar odometry. Our algorithm
pre-processes Doppler velocity into invariant node and edge features in the
graph, and employs separate networks for equivariant and invariant feature
processing. A graph-based architecture enhances feature aggregation in sparse
radar data, improving inter-frame correspondence. Experiments on the
open-source dataset and self-collected dataset show Equi-RO outperforms
state-of-the-art algorithms in accuracy and robustness. Overall, our method
achieves 10.7% and 20.0% relative improvements in translation and rotation
accuracy, respectively, compared to the best baseline on the open-source
dataset.

</details>


### [168] [Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation](https://arxiv.org/abs/2509.20681)
*Wei-Teng Chu,Tianyi Zhang,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 本文提出了一种名为FINS的轻量级框架，能够基于单张或少量图像高效重建高保真曲面和符号距离场（SDF），并通过多分辨率哈希网格编码器与预训练基础模型结合，实现了快速收敛与高精度，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式表面重建方法（如NeuS）通常需要大量多视角图像且训练耗时长，难以满足实时机器人应用需求，因此需要一种仅用单张图像即可快速、准确构建隐式距离表示的方法。

Method: 提出Fast Image-to-Neural Surface（FINS）框架，采用多分辨率哈希网格编码器与轻量化的几何和颜色头结构，并利用近似二阶梯度优化器实现几秒内快速收敛；同时借助预训练基础模型从单张RGB图像中估计几何信息以构建神经表面。

Result: 实验表明，FINS在相同条件下相比最先进的基线方法在表面重建和SDF场估计任务上具有更快的收敛速度和更高的精度，并验证了其在机器人表面跟随任务中的适用性及在多种基准数据集上的可扩展性。

Conclusion: FINS是一种高效、精确的单图像隐式表面重建方法，通过轻量级架构设计与预训练模型结合，显著提升了训练效率与实用性，适用于机器人等对实时性要求较高的场景。

Abstract: Implicit representations have been widely applied in robotics for obstacle
avoidance and path planning. In this paper, we explore the problem of
constructing an implicit distance representation from a single image. Past
methods for implicit surface reconstruction, such as \emph{NeuS} and its
variants generally require a large set of multi-view images as input, and
require long training times. In this work, we propose Fast Image-to-Neural
Surface (FINS), a lightweight framework that can reconstruct high-fidelity
surfaces and SDF fields based on a single or a small set of images. FINS
integrates a multi-resolution hash grid encoder with lightweight geometry and
color heads, making the training via an approximate second-order optimizer
highly efficient and capable of converging within a few seconds. Additionally,
we achieve the construction of a neural surface requiring only a single RGB
image, by leveraging pre-trained foundation models to estimate the geometry
inherent in the image. Our experiments demonstrate that under the same
conditions, our method outperforms state-of-the-art baselines in both
convergence speed and accuracy on surface reconstruction and SDF field
estimation. Moreover, we demonstrate the applicability of FINS for robot
surface following tasks and show its scalability to a variety of benchmark
datasets.

</details>


### [169] [RAM-NAS: Resource-aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks](https://arxiv.org/abs/2509.20688)
*Shouren Mao,Minghao Qin,Wei Dong,Huajian Liu,Yongzhuo Gao*

Main category: cs.RO

TL;DR: 提出了一种资源感知的多目标神经架构搜索方法RAM-NAS，通过子网互蒸馏和延迟代理预测器，在机器人边缘硬件上实现了高精度与低延迟的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统NAS方法在超网训练和实际机器人硬件资源考虑方面存在不足，难以满足资源受限的机器人系统需求。

Method: 引入子网互蒸馏机制和DKD损失函数提升超网训练效果，并利用三类机器人边缘硬件数据训练延迟代理预测器，结合多目标进化搜索优化精度与延迟的权衡。

Result: RAM-NAS模型在ImageNet上达到76.7%至81.4%的top-1准确率，显著降低边缘硬件上的推理延迟；在检测与分割任务中相比MobileNetv3方法推理时间更短。

Conclusion: RAM-NAS有效填补了面向机器人硬件资源感知的NAS研究空白，提升了轻量级模型在真实机器人平台上的部署效率。

Abstract: Neural architecture search (NAS) has shown great promise in automatically
designing lightweight models. However, conventional approaches are insufficient
in training the supernet and pay little attention to actual robot hardware
resources. To meet such challenges, we propose RAM-NAS, a resource-aware
multi-objective NAS method that focuses on improving the supernet pretrain and
resource-awareness on robot hardware devices. We introduce the concept of
subnets mutual distillation, which refers to mutually distilling all subnets
sampled by the sandwich rule. Additionally, we utilize the Decoupled Knowledge
Distillation (DKD) loss to enhance logits distillation performance. To expedite
the search process with consideration for hardware resources, we used data from
three types of robotic edge hardware to train Latency Surrogate predictors.
These predictors facilitated the estimation of hardware inference latency
during the search phase, enabling a unified multi-objective evolutionary search
to balance model accuracy and latency trade-offs. Our discovered model family,
RAM-NAS models, can achieve top-1 accuracy ranging from 76.7% to 81.4% on
ImageNet. In addition, the resource-aware multi-objective NAS we employ
significantly reduces the model's inference latency on edge hardware for
robots. We conducted experiments on downstream tasks to verify the scalability
of our methods. The inference time for detection and segmentation is reduced on
all three hardware types compared to MobileNetv3-based methods. Our work fills
the gap in NAS for robot hardware resource-aware.

</details>


### [170] [Incorporating Human-Inspired Ankle Characteristics in a Forced-Oscillation-Based Reduced-Order Model for Walking](https://arxiv.org/abs/2509.20689)
*Chathura Semasinghe,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 本文将基于强迫振荡的行走降阶模型扩展到包含踝关节和足部的模型，提出一种受人类启发的踝关节动力学设计，改善了步态特性，并展示了该模型通过脚放置和踝策略结合可抵抗大的初始误差，且仅通过本体感知踝机制即可稳定应对小扰动，这一新颖特性有助于理解类人行走及其稳定机制。


<details>
  <summary>Details</summary>
Motivation: 为了改进现有点足模型的步态表现并更好地模拟人类行走的稳定机制，研究者希望引入踝关节和足部 dynamics，以增强模型的生物合理性与稳定性。

Method: 通过扩展原有的强迫振荡降阶模型，加入踝关节和足部结构，并设计一种受人类启发的本体感知踝关节控制策略，结合脚放置与踝关节调节实现稳定行走。

Result: 新模型相比点足模型展现出更优的步态特征；能够通过脚放置与踝策略组合抵抗大初始误差；且仅依靠踝关节本体感受机制即可应对小扰动，表现出类似人类的稳定特性。

Conclusion: 所提出的含踝关节和足部的行走模型不仅提升了步态的自然性，还揭示了人类行走中可能存在的分层级稳定机制，为类人行走控制提供了新的理解与建模工具。

Abstract: This paper extends the forced-oscillation-based reduced-order model of
walking to a model with ankles and feet. A human-inspired paradigm was designed
for the ankle dynamics, which results in improved gait characteristics compared
to the point-foot model. In addition, it was shown that while the proposed
model can stabilize against large errors in initial conditions through
combination of foot placement and ankle strategies, the model is able to
stabilize against small perturbations without relying on the foot placement
control and solely through the designed proprioceptive ankle scheme. This novel
property, which is also observed in humans, can help in better understanding of
anthropomorphic walking and its stabilization mechanisms.

</details>


### [171] [RuN: Residual Policy for Natural Humanoid Locomotion](https://arxiv.org/abs/2509.20696)
*Qingpeng Li,Chengrui Zhu,Yanming Wu,Xin Yuan,Zhen Zhang,Jian Yang,Yong Liu*

Main category: cs.RO

TL;DR: 提出了一种名为RuN的解耦残差学习框架，用于实现人形机器人在宽速度范围内（0-2.5 m/s）自然、稳定的行走至跑步过渡。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法需单一策略同时学习运动模仿、速度跟踪和稳定性维持，难以实现自然动态步态及平滑过渡。

Method: 采用解耦残差学习框架RuN，结合预训练的条件运动生成器提供运动先验，强化学习策略仅学习轻量级残差修正以应对动力学交互。

Result: 在仿真和真实Unitree G1人形机器人上的实验表明，RuN在训练效率和最终性能上优于现有方法，实现了稳定且自然的步态和平滑的走跑切换。

Conclusion: RuN通过解耦控制任务显著提升了人形机器人在多速度下的运动表现，具备良好的实际应用潜力。

Abstract: Enabling humanoid robots to achieve natural and dynamic locomotion across a
wide range of speeds, including smooth transitions from walking to running,
presents a significant challenge. Existing deep reinforcement learning methods
typically require the policy to directly track a reference motion, forcing a
single policy to simultaneously learn motion imitation, velocity tracking, and
stability maintenance. To address this, we introduce RuN, a novel decoupled
residual learning framework. RuN decomposes the control task by pairing a
pre-trained Conditional Motion Generator, which provides a kinematically
natural motion prior, with a reinforcement learning policy that learns a
lightweight residual correction to handle dynamical interactions. Experiments
in simulation and reality on the Unitree G1 humanoid robot demonstrate that RuN
achieves stable, natural gaits and smooth walk-run transitions across a broad
velocity range (0-2.5 m/s), outperforming state-of-the-art methods in both
training efficiency and final performance.

</details>


### [172] [Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations](https://arxiv.org/abs/2509.20703)
*Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 提出了一种基于视频示范的机器人操作学习框架JFTO，通过在SE(3)上扩展流匹配来实现多模态物体轨迹的概率建模，生成符合人体示范且满足机器人运动学约束的操作轨迹。


<details>
  <summary>Details</summary>
Motivation: 由于形态差异和关节可行性限制，直接从人类视频示范中学习对机器人操作具有挑战性，因此需要一种能够克服这些限制的方法。

Method: 提出JFTO框架，将示范视为以物体为中心的指导，结合抓取姿态选择、物体轨迹生成和无碰撞执行三个目标；在SE(3)空间中扩展流匹配进行概率建模，并构建统一的可微优化目标。

Result: 在仿真和真实环境中验证了方法的有效性，能够在多种实际操作任务中生成可行且贴近示范的轨迹。

Conclusion: JFTO框架能有效解决跨形态示范中的可行性与一致性问题，实现了高质量的对象轨迹模仿与抓取姿态生成。

Abstract: Learning from human video demonstrations offers a scalable alternative to
teleoperation or kinesthetic teaching, but poses challenges for robot
manipulators due to embodiment differences and joint feasibility constraints.
We address this problem by proposing the Joint Flow Trajectory Optimization
(JFTO) framework for grasp pose generation and object trajectory imitation
under the video-based Learning-from-Demonstration (LfD) paradigm. Rather than
directly imitating human hand motions, our method treats demonstrations as
object-centric guides, balancing three objectives: (i) selecting a feasible
grasp pose, (ii) generating object trajectories consistent with demonstrated
motions, and (iii) ensuring collision-free execution within robot kinematics.
To capture the multimodal nature of demonstrations, we extend flow matching to
$\SE(3)$ for probabilistic modeling of object trajectories, enabling
density-aware imitation that avoids mode collapse. The resulting optimization
integrates grasp similarity, trajectory likelihood, and collision penalties
into a unified differentiable objective. We validate our approach in both
simulation and real-world experiments across diverse real-world manipulation
tasks.

</details>


### [173] [Building Information Models to Robot-Ready Site Digital Twins (BIM2RDT): An Agentic AI Safety-First Framework](https://arxiv.org/abs/2509.20705)
*Reza Akhavian,Mani Amani,Johannes Mootz,Robert Ashe,Behrad Beheshti*

Main category: cs.RO

TL;DR: 本文提出了一种名为BIM2RDT的智能体AI框架，将静态BIM模型转化为面向机器人的动态数字孪生系统，结合语义信息、物联网数据与机器人感知，提升施工安全与管理效率。


<details>
  <summary>Details</summary>
Motivation: 传统BIM模型在施工现场缺乏实时性与动态交互能力，难以支持自动化作业与安全管理，因此需要一种能融合多源数据并实现闭环反馈的智能框架。

Method: 提出BIM2RDT框架，集成BIM几何语义、IoT活动数据和机器人视觉数据；设计基于大语言模型推理的SG-ICP点云配准算法，利用语义先验优化姿态估计；采用YOLOE与Shi-Tomasi进行目标检测与跟踪，并结合IFC标准实现手臂振动（HAV）实时监测与报警。

Result: 实验表明SG-ICP相比传统ICP在遮挡场景下对齐误差降低64.3%–88.3%，显著提升配准精度；HAV监测模块可有效触发超限警告，符合ISO 5349-1标准，增强现场安全性。

Conclusion: BIM2RDT实现了从静态BIM到机器人就绪型动态数字孪生的转化，通过多模态数据融合与AI驱动的语义理解，提升了施工过程的自动化水平与安全监管能力。

Abstract: The adoption of cyber-physical systems and jobsite intelligence that connects
design models, real-time site sensing, and autonomous field operations can
dramatically enhance digital management in the construction industry. This
paper introduces BIM2RDT (Building Information Models to Robot-Ready Site
Digital Twins), an agentic artificial intelligence (AI) framework designed to
transform static Building Information Modeling (BIM) into dynamic, robot-ready
digital twins (DTs) that prioritize safety during execution. The framework
bridges the gap between pre-existing BIM data and real-time site conditions by
integrating three key data streams: geometric and semantic information from BIM
models, activity data from IoT sensor networks, and visual-spatial data
collected by robots during site traversal. The methodology introduces
Semantic-Gravity ICP (SG-ICP), a point cloud registration algorithm that
leverages large language model (LLM) reasoning. Unlike traditional methods,
SG-ICP utilizes an LLM to infer object-specific, plausible orientation priors
based on BIM semantics, improving alignment accuracy by avoiding convergence on
local minima. This creates a feedback loop where robot-collected data updates
the DT, which in turn optimizes paths for missions. The framework employs YOLOE
object detection and Shi-Tomasi corner detection to identify and track
construction elements while using BIM geometry as a priori maps. The framework
also integrates real-time Hand-Arm Vibration (HAV) monitoring, mapping
sensor-detected safety events to the digital twin using IFC standards for
intervention. Experiments demonstrate SG-ICP's superiority over standard ICP,
achieving RMSE reductions of 64.3%--88.3% in alignment across scenarios with
occluded features, ensuring plausible orientations. HAV integration triggers
warnings upon exceeding exposure limits, enhancing compliance with ISO 5349-1.

</details>


### [174] [Digital Twin-Guided Robot Path Planning: A Beta-Bernoulli Fusion with Large Language Model as a Sensor](https://arxiv.org/abs/2509.20709)
*Mani Amani,Reza Akhavian*

Main category: cs.RO

TL;DR: 提出一种将自然语言指令与BIM语义地图通过Beta-Bernoulli贝叶斯融合的机器人路径规划框架，利用LLM作为传感器更新障碍物排斥系数，提升路径的安全性与上下文感知能力。


<details>
  <summary>Details</summary>
Motivation: 在建筑领域，如何有效结合自然语言指令与BIM信息以实现更安全、更灵活的机器人路径规划仍具挑战。现有方法难以动态融合多源语言输入并保持数值稳定性。

Method: 将LLM视为传感器，把障碍物的设计时排斥系数建模为Beta分布随机变量，利用LLM返回的危险评分作为伪计数，通过Beta-Bernoulli贝叶斯更新得到后验均值，用于调整势场法中的排斥增益，从而生成上下文感知的代价启发函数。

Result: 仿真结果表明，该方法在路径鲁棒性和有效性方面均有定性和定量的提升，能够稳定地链式处理多个自然语言命令，并兼容多种AI规划框架。

Conclusion: 所提出的贝叶斯融合框架能有效整合自然语言指令与BIM语义信息，实现更安全、灵活且上下文感知的建筑环境机器人导航。

Abstract: Integrating natural language (NL) prompts into robotic mission planning has
attracted significant interest in recent years. In the construction domain,
Building Information Models (BIM) encapsulate rich NL descriptions of the
environment. We present a novel framework that fuses NL directives with
BIM-derived semantic maps via a Beta-Bernoulli Bayesian fusion by interpreting
the LLM as a sensor: each obstacle's design-time repulsive coefficient is
treated as a Beta(alpha, beta) random variable and LLM-returned danger scores
are incorporated as pseudo-counts to update alpha and beta. The resulting
posterior mean yields a continuous, context-aware repulsive gain that augments
a Euclidean-distance-based potential field for cost heuristics. By adjusting
gains based on sentiment and context inferred from user prompts, our method
guides robots along safer, more context-aware paths. This provides a
numerically stable method that can chain multiple natural commands and prompts
from construction workers and foreman to enable planning while giving
flexibility to be integrated in any learned or classical AI framework.
Simulation results demonstrate that this Beta-Bernoulli fusion yields both
qualitative and quantitative improvements in path robustness and validity.

</details>


### [175] [RobotDancing: Residual-Action Reinforcement Learning Enables Robust Long-Horizon Humanoid Motion Tracking](https://arxiv.org/abs/2509.20717)
*Zhenguo Sun,Yibo Peng,Yuan Meng,Xukun Li,Bo-Sheng Huang,Zhenshan Bing,Xinlong Wang,Alois Knoll*

Main category: cs.RO

TL;DR: 提出RobotDancing框架，通过预测残差关节目标来纠正动力学差异，实现人形机器人长时间高动态运动的零样本真实部署。


<details>
  <summary>Details</summary>
Motivation: 现有方法因模型与实际系统不匹配导致误差累积，难以实现稳定长时程高动态运动跟踪。

Method: 采用端到端的单阶段强化学习框架，统一观测、奖励和超参数配置，预测残差关节目标以补偿动力学差异。

Result: 在Unitree G1上成功追踪多分钟高能量动作（如跳跃、旋转、侧手翻），并在H1/H1-2上验证了零样本迁移能力，硬件部署表现出高质量运动跟踪。

Conclusion: RobotDancing提供了一种简单可扩展的解决方案，显著提升了人形机器人在复杂动态运动中的跟踪鲁棒性和实际部署能力。

Abstract: Long-horizon, high-dynamic motion tracking on humanoids remains brittle
because absolute joint commands cannot compensate model-plant mismatch, leading
to error accumulation. We propose RobotDancing, a simple, scalable framework
that predicts residual joint targets to explicitly correct dynamics
discrepancies. The pipeline is end-to-end--training, sim-to-sim validation, and
zero-shot sim-to-real--and uses a single-stage reinforcement learning (RL)
setup with a unified observation, reward, and hyperparameter configuration. We
evaluate primarily on Unitree G1 with retargeted LAFAN1 dance sequences and
validate transfer on H1/H1-2. RobotDancing can track multi-minute, high-energy
behaviors (jumps, spins, cartwheels) and deploys zero-shot to hardware with
high motion tracking quality.

</details>


### [176] [SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning](https://arxiv.org/abs/2509.20739)
*Guoyang Zhao,Yudong Li,Weiqing Qi,Kai Zhang,Bonan Liu,Kai Chen,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 提出一种无需SLAM、仅依赖视觉的语义驱动导航框架，结合视觉-语言感知与拓扑地图，实现腿式机器人在复杂环境中的鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM在快速运动、传感器漂移和标定要求下表现脆弱，且缺乏语义推理能力，难以支持任务驱动的探索。

Method: 采用纯视觉、无需SLAM的框架，用语义推理和轻量级拓扑表示替代稠密几何重建；通过分层的视觉-语言感知模块融合场景级上下文与物体级线索，并构建语义-概率拓扑图，结合LLM进行全局子目标选择和基于视觉的局部避障规划，集成强化学习步态控制器。

Result: 在仿真和真实环境中实验表明，该方法在语义准确性、路径规划质量和导航成功率方面均有稳定提升，消融实验验证了分层感知与精细局部规划的必要性。

Conclusion: 本工作提出了以语义为中心、无需SLAM的导航新范式，推动机器人探索从几何建图转向语义驱动决策。

Abstract: Conventional SLAM pipelines for legged robot navigation are fragile under
rapid motion, calibration demands, and sensor drift, while offering limited
semantic reasoning for task-driven exploration. To deal with these issues, we
propose a vision-only, SLAM-free navigation framework that replaces dense
geometry with semantic reasoning and lightweight topological representations. A
hierarchical vision-language perception module fuses scene-level context with
object-level cues for robust semantic inference. And a semantic-probabilistic
topological map supports coarse-to-fine planning: LLM-based global reasoning
for subgoal selection and vision-based local planning for obstacle avoidance.
Integrated with reinforcement-learning locomotion controllers, the framework is
deployable across diverse legged robot platforms. Experiments in simulation and
real-world settings demonstrate consistent improvements in semantic accuracy,
planning quality, and navigation success, while ablation studies further
showcase the necessity of both hierarchical perception and fine local planning.
This work introduces a new paradigm for SLAM-free, vision-language-driven
navigation, shifting robotic exploration from geometry-centric mapping to
semantics-driven decision making.

</details>


### [177] [MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM](https://arxiv.org/abs/2509.20757)
*Yuxuan Zhou,Xingxing Li,Shengyu Li,Zhuohao Yan,Chunxi Xia,Shaoquan Feng*

Main category: cs.RO

TL;DR: 本文提出了一种名为MASt3R-Fusion的多传感器辅助视觉SLAM框架，通过将前馈点云回归与惯性测量和GNSS数据融合，结合Sim(3)对齐约束与分层因子图设计，实现了高精度、度量尺度一致且全局一致的实时位姿跟踪与三维建图。


<details>
  <summary>Details</summary>
Motivation: 传统视觉SLAM在低纹理环境、尺度模糊和恶劣视觉条件下表现不佳，而现有基于神经网络的方法往往忽略了多传感器概率融合的优势，因此需要一种能有效整合学习先验与多传感器信息的鲁棒SLAM系统。

Method: 提出MASt3R-Fusion框架，将前馈神经网络生成的点云回归结果与IMU、GNSS等传感器数据紧耦合；引入Sim(3)形式的视觉对齐约束（以Hessian形式表达）到度量尺度的SE(3)因子图中，并采用分层因子图结构支持滑动窗口实时优化与包含激进回环检测的全局优化。

Result: 在公开基准和自采集数据集上验证了该方法，在定位精度和系统鲁棒性方面均显著优于现有的视觉为中心的多传感器SLAM系统，同时实现度量尺度一致性和全局一致性建图。

Conclusion: MASt3R-Fusion有效融合了学习型点云先验与多传感器观测信息，通过统一的因子图优化框架实现了高性能SLAM，在准确性、鲁棒性和一致性方面取得提升，具备实际应用潜力。

Abstract: Visual SLAM is a cornerstone technique in robotics, autonomous driving and
extended reality (XR), yet classical systems often struggle with low-texture
environments, scale ambiguity, and degraded performance under challenging
visual conditions. Recent advancements in feed-forward neural network-based
pointmap regression have demonstrated the potential to recover high-fidelity 3D
scene geometry directly from images, leveraging learned spatial priors to
overcome limitations of traditional multi-view geometry methods. However, the
widely validated advantages of probabilistic multi-sensor information fusion
are often discarded in these pipelines. In this work, we propose
MASt3R-Fusion,a multi-sensor-assisted visual SLAM framework that tightly
integrates feed-forward pointmap regression with complementary sensor
information, including inertial measurements and GNSS data. The system
introduces Sim(3)-based visualalignment constraints (in the Hessian form) into
a universal metric-scale SE(3) factor graph for effective information fusion. A
hierarchical factor graph design is developed, which allows both real-time
sliding-window optimization and global optimization with aggressive loop
closures, enabling real-time pose tracking, metric-scale structure perception
and globally consistent mapping. We evaluate our approach on both public
benchmarks and self-collected datasets, demonstrating substantial improvements
in accuracy and robustness over existing visual-centered multi-sensor SLAM
systems. The code will be released open-source to support reproducibility and
further research (https://github.com/GREAT-WHU/MASt3R-Fusion).

</details>


### [178] [Leveraging Temporally Extended Behavior Sharing for Multi-task Reinforcement Learning](https://arxiv.org/abs/2509.20766)
*Gawon Lee,Daesol Cho,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出了一种名为MT-Lévy的多任务强化学习探索策略，通过结合任务间行为共享和受Lévy飞行启发的时序扩展探索，提升了机器人应用中的样本效率和状态空间覆盖能力。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域应用多任务强化学习（MTRL）面临收集多样化任务数据成本高的挑战，需要提高样本效率和泛化能力。

Method: 提出MT-Lévy方法，利用相关任务的策略指导探索，并基于任务成功率动态调整探索强度，结合行为共享与Lévy飞行启发的长距离探索机制。

Result: 实验结果表明，MT-Lévy显著提升了探索效率和样本利用率，定量与定性分析以及消融研究验证了各组件的有效性。

Conclusion: MT-Lévy通过融合行为共享和自适应探索策略，显著增强了MTRL在复杂机器人环境中的实用性。

Abstract: Multi-task reinforcement learning (MTRL) offers a promising approach to
improve sample efficiency and generalization by training agents across multiple
tasks, enabling knowledge sharing between them. However, applying MTRL to
robotics remains challenging due to the high cost of collecting diverse task
data. To address this, we propose MT-L\'evy, a novel exploration strategy that
enhances sample efficiency in MTRL environments by combining behavior sharing
across tasks with temporally extended exploration inspired by L\'evy flight.
MT-L\'evy leverages policies trained on related tasks to guide exploration
towards key states, while dynamically adjusting exploration levels based on
task success ratios. This approach enables more efficient state-space coverage,
even in complex robotics environments. Empirical results demonstrate that
MT-L\'evy significantly improves exploration and sample efficiency, supported
by quantitative and qualitative analyses. Ablation studies further highlight
the contribution of each component, showing that combining behavior sharing
with adaptive exploration strategies can significantly improve the practicality
of MTRL in robotics applications.

</details>


### [179] [SemSight: Probabilistic Bird's-Eye-View Prediction of Multi-Level Scene Semantics for Navigation](https://arxiv.org/abs/2509.20839)
*Jiaxuan He,Jiamei Ren,Chongshang Yan,Wenjie Song*

Main category: cs.RO

TL;DR: 本文提出了SemSight，一种用于多级场景语义预测的概率鸟瞰图模型，通过掩码约束监督策略，在未知区域上提升语义预测性能，并提高目标驱动导航的效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单个物体或几何占据图，缺乏对房间级语义结构的建模能力，难以支持高效的目标导航与环境理解。

Method: 提出SemSight模型，采用编码器-解码器网络架构，联合推断结构布局、全局场景上下文和目标区域分布；通过在未探索区域应用二值掩码，实现仅针对未知区域的监督训练。

Result: 在40,000个模拟观测数据上训练后，SemSight在结构一致性（SC）和区域识别准确率（PA）等指标上优于无掩码监督的方法，并在闭环仿真中减少了机器人搜索目标所需的步数。

Conclusion: SemSight能有效完成未探索区域的语义补全并估计目标类别概率，显著提升语义预测质量和导航效率。

Abstract: In target-driven navigation and autonomous exploration, reasonable prediction
of unknown regions is crucial for efficient navigation and environment
understanding. Existing methods mostly focus on single objects or geometric
occupancy maps, lacking the ability to model room-level semantic structures. We
propose SemSight, a probabilistic bird's-eye-view prediction model for
multi-level scene semantics. The model jointly infers structural layouts,
global scene context, and target area distributions, completing semantic maps
of unexplored areas while estimating probability maps for target categories. To
train SemSight, we simulate frontier-driven exploration on 2,000 indoor layout
graphs, constructing a diverse dataset of 40,000 sequential egocentric
observations paired with complete semantic maps. We adopt an encoder-decoder
network as the core architecture and introduce a mask-constrained supervision
strategy. This strategy applies a binary mask of unexplored areas so that
supervision focuses only on unknown regions, forcing the model to infer
semantic structures from the observed context. Experimental results show that
SemSight improves prediction performance for key functional categories in
unexplored regions and outperforms non-mask-supervised approaches on metrics
such as Structural Consistency (SC) and Region Recognition Accuracy (PA). It
also enhances navigation efficiency in closed-loop simulations, reducing the
number of search steps when guiding robots toward target areas.

</details>


### [180] [ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation](https://arxiv.org/abs/2509.20841)
*Dekun Lu,Wei Gao,Kui Jia*

Main category: cs.RO

TL;DR: 提出了一种新的机器人操作动作表示方法Chain of Moving Oriented Keypoints (CoMOK)，实现通用、精确且可靠的端到端操作策略。


<details>
  <summary>Details</summary>
Motivation: 现有端到端神经网络在机器人操作任务中性能不足，难以大规模实际部署，且传统模块化流程存在信息丢失和特征不对齐问题。

Method: 提出CoMOK作为神经策略的动作表示，可端到端训练，通过有向关键点实现对不同形状、大小物体的自然泛化，并支持多阶段任务、多模态行为和可变形物体操作。

Result: 在仿真和真实硬件实验中验证了该方法的有效性，实现了亚厘米级精度，并展现出良好的泛化能力和任务适应性。

Conclusion: CoMOK为端到端机器人操作提供了一种通用、准确且可靠的动作表示方法，推动了其在实际场景中的应用潜力。

Abstract: End-to-end robot manipulation policies offer significant potential for
enabling embodied agents to understand and interact with the world. Unlike
traditional modular pipelines, end-to-end learning mitigates key limitations
such as information loss between modules and feature misalignment caused by
isolated optimization targets. Despite these advantages, existing end-to-end
neural networks for robotic manipulation--including those based on large
VLM/VLA models--remain insufficiently performant for large-scale practical
deployment. In this paper, we take a step towards an end-to-end manipulation
policy that is generalizable, accurate and reliable. To achieve this goal, we
propose a novel Chain of Moving Oriented Keypoints (CoMOK) formulation for
robotic manipulation. Our formulation is used as the action representation of a
neural policy, which can be trained in an end-to-end fashion. Such an action
representation is general, as it extends the standard end-effector pose action
representation and supports a diverse set of manipulation tasks in a unified
manner. The oriented keypoint in our method enables natural generalization to
objects with different shapes and sizes, while achieving sub-centimeter
accuracy. Moreover, our formulation can easily handle multi-stage tasks,
multi-modal robot behaviors, and deformable objects. Extensive simulated and
hardware experiments demonstrate the effectiveness of our method.

</details>


### [181] [MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases](https://arxiv.org/abs/2509.20843)
*Ziang Luo,Kangan Qian,Jiahua Wang,Yuechen Luo,Jinyu Miao,Zheng Fu,Yunlong Wang,Sicong Jiang,Zilin Huang,Yifei Hu,Yuhao Yang,Hao Ye,Mengmeng Yang,Xiaojian Dong,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: MTRDrive是一种结合记忆机制与动态工具包的视觉语言模型框架，旨在提升自动驾驶中的泛化能力和决策可靠性，在多个基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在自动驾驶中存在幻觉和分布外场景泛化能力差的问题，限制了其实际部署的可靠性。

Method: 提出MTRDrive框架，通过基于记忆的经验检索机制与动态工具包的协同推理，构建闭环系统以增强环境交互、推理和决策能力，并引入新的Roadwork-VLM基准测试零样本泛化性能。

Result: 在NAVSIM基准上，3B参数的MTRDrive模型取得88.3的PDMS分数，驾驶指标达79.8%，规划准确率82.6%；在新提出的Roadwork-VLM零样本评测中驾驶指标达80.2%。

Conclusion: MTRDrive通过记忆-工具协同机制显著提升了VLM在自动驾驶中的鲁棒性与泛化能力，推动了更安全可靠的自动驾驶系统发展。

Abstract: Vision-Language Models(VLMs) have demonstrated significant potential for
end-to-end autonomous driving, yet a substantial gap remains between their
current capabilities and the reliability necessary for real-world deployment. A
critical challenge is their fragility, characterized by hallucinations and poor
generalization in out-of-distribution (OOD) scenarios. To bridge this gap, we
introduce MTRDrive, a novel framework that integrates procedural driving
experiences with a dynamic toolkit to enhance generalization and proactive
decision-making.
  MTRDrive addresses these limitations through a closed-loop system that
combines a memory-based experience retrieval mechanism with dynamic toolkits.
This synergy enables the model to interact more effectively with its
environment, improving both reasoning and decision-making capabilities with the
help of our memory-tool synergistic reasoning. Additionally, we introduce a new
benchmark based on complex Roadwork construction scenarios to rigorously
evaluate zero-shot generalization.
  Extensive experiments demonstrate the superior effectiveness of our approach.
On the public NAVSIM benchmark, our 3B-parameter MTRDrive model achieves an
exceptional PDMS of 88.3 without chain-of-thought and sets a state-of-the-art
performance bar on high-level planning, with a driving metric score of 79.8\%
and a planning accuracy of 82.6\%. Rigorous zero-shot evaluation on the new
Roadwork-VLM benchmark shows a strong ability to reason robustly in unseen
scenarios, achieving a driving metric score of 80.2\%. These results highlight
MTRDrive's potential to advance autonomous driving toward safer and more
reliable systems.

</details>


### [182] [Efficient Differentiable Contact Model with Long-range Influence](https://arxiv.org/abs/2509.20917)
*Xiaohan Ye,Kui Wu,Zherong Pan,Taku Komura*

Main category: cs.RO

TL;DR: 本文提出了一种适用于可微刚体模拟器的实用接触模型，解决了可微物理中梯度行为不稳定的问题，从而提升了下游任务（如运动控制和操作）的优化收敛性。


<details>
  <summary>Details</summary>
Motivation: 可微物理在多种应用中日益重要，但现有可微模拟器提供的梯度信息可能突变或消失，影响基于梯度的优化器收敛。

Method: 分析接触模型设计与梯度行为的关系，提出接触模型应满足的一组性质，并设计了一个满足这些性质且计算高效的实用接触模型。

Result: 实验表明，所提出的接触模型能够从简单初始化出发，生成复杂且富含接触的控制信号，成功完成多种运动和操作任务。

Conclusion: 合理的接触模型设计能显著改善可微模拟中的梯度质量，提升下游应用的优化效率和性能。

Abstract: With the maturation of differentiable physics, its role in various downstream
applications: such as model predictive control, robotic design optimization,
and neural PDE solvers, has become increasingly important. However, the
derivative information provided by differentiable simulators can exhibit abrupt
changes or vanish altogether, impeding the convergence of gradient-based
optimizers. In this work, we demonstrate that such erratic gradient behavior is
closely tied to the design of contact models. We further introduce a set of
properties that a contact model must satisfy to ensure well-behaved gradient
information. Lastly, we present a practical contact model for differentiable
rigid-body simulators that satisfies all of these properties while maintaining
computational efficiency. Our experiments show that, even from simple
initializations, our contact model can discover complex, contact-rich control
signals, enabling the successful execution of a range of downstream locomotion
and manipulation tasks.

</details>


### [183] [Autoregressive End-to-End Planning with Time-Invariant Spatial Alignment and Multi-Objective Policy Refinement](https://arxiv.org/abs/2509.20938)
*Jianbo Zhao,Taiyu Ban,Xiangjie Li,Xingtai Gui,Hangning Zhou,Lei Liu,Hongwei Zhao,Bin Li*

Main category: cs.RO

TL;DR: 提出了一种基于时间不变空间对齐（TISA）的端到端自动驾驶规划方法，结合运动学动作预测和多目标DPO优化，在NAVSIM数据集上达到89.8 PDMS的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在自动驾驶规划中受限于时空错位问题，即未来动作依赖于过去感知数据，导致智能体世界观不一致，限制了性能上限。

Method: 提出TISA模块，将初始环境特征投影到每个未来时间步的一致以自我为中心的坐标系中；采用运动学动作预测头（加速度和偏航率）确保轨迹物理可行性；引入基于多目标直接偏好优化（DPO）的后训练阶段，提供针对特定驾驶行为的细粒度反馈。

Result: 在NAVSIM数据集中，该方法在自回归模型中实现了89.8的PDMS得分，达到当前最优性能。

Conclusion: TISA模块有效缓解了时空错位问题，结合运动学预测和多目标DPO后训练，显著提升了自回归模型在端到端自动驾驶规划中的性能。

Abstract: The inherent sequential modeling capabilities of autoregressive models make
them a formidable baseline for end-to-end planning in autonomous driving.
Nevertheless, their performance is constrained by a spatio-temporal
misalignment, as the planner must condition future actions on past sensory
data. This creates an inconsistent worldview, limiting the upper bound of
performance for an otherwise powerful approach. To address this, we propose a
Time-Invariant Spatial Alignment (TISA) module that learns to project initial
environmental features into a consistent ego-centric frame for each future time
step, effectively correcting the agent's worldview without explicit future
scene prediction. In addition, we employ a kinematic action prediction head
(i.e., acceleration and yaw rate) to ensure physically feasible trajectories.
Finally, we introduce a multi-objective post-training stage using Direct
Preference Optimization (DPO) to move beyond pure imitation. Our approach
provides targeted feedback on specific driving behaviors, offering a more
fine-grained learning signal than the single, overall objective used in
standard DPO. Our model achieves a state-of-the-art 89.8 PDMS on the NAVSIM
dataset among autoregressive models. The video document is available at
https://tisa-dpo-e2e.github.io/.

</details>


### [184] [BactoBot: A Low-Cost, Bacteria-Inspired Soft Underwater Robot for Marine Exploration](https://arxiv.org/abs/2509.20964)
*Rubaiyat Tasnim Chowdhury,Nayan Bala,Ronojoy Roy,Tarek Mahmud*

Main category: cs.RO

TL;DR: 本文提出了一种低成本、柔软的水下机器人BactoBot，灵感来自细菌鞭毛推进，适用于安全探索脆弱海洋生态系统。


<details>
  <summary>Details</summary>
Motivation: 传统刚性水下设备可能破坏敏感海洋生态，因此需要一种更柔性和安全的替代方案。

Method: 受细菌鞭毛运动启发，采用12个柔性硅胶臂和3D打印十二面体框架设计机器人，使用食品级硅胶成型、3D打印和现成微控制器等DIY方法制造，并开发防水与浮力校准方案。

Result: 在受控水箱中成功测试，实现了前进和转向运动，验证了复杂生物运动方式低成本复现的可行性。

Conclusion: BactoBot为资源有限环境下的海洋科学研究提供了环保机器人工具的基础，未来可朝自主操作和实地部署发展。

Abstract: Traditional rigid underwater vehicles pose risks to delicate marine
ecosystems. This paper presents BactoBot, a low-cost, soft underwater robot
designed for safe and gentle marine exploration. Inspired by bacterial
flagellar propulsion, BactoBot features 12 flexible, silicone-based arms
arranged on a 3D-printed dodecahedral frame. The design provides inherent
compliance, redundancy, and the potential for omnidirectional movement. The
prototype was fabricated using accessible DIY methods, including food-grade
silicone molding, 3D printing, and off-the-shelf microcontrollers.
Waterproofing and buoyancy calibration protocols were developed, and the robot
was successfully tested in a controlled water tank, demonstrating forward
motion and turning. The results validate the feasibility of replicating complex
biological locomotion at low cost. The project lays a foundation for
environmentally conscious robotic tools, particularly for marine science in
resource-constrained settings, and identifies pathways toward autonomous
operation and field deployment.

</details>


### [185] [AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation](https://arxiv.org/abs/2509.21006)
*Konstantin Gubernatorov,Artem Voronov,Roman Voronov,Sergei Pasynkov,Stepan Perminov,Ziang Guo,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 提出AnywhereVLA，一个用于在未知室内环境中进行自然语言驱动的移动操作的模块化框架，结合经典SLAM与细调的视觉-语言-动作模型，实现端到端的语义任务执行。


<details>
  <summary>Details</summary>
Motivation: 在不可预测的室内环境中实现基于自然语言指令的可靠且通用的物体抓取与放置任务。

Method: 采用模块化架构，将文本指令解析为任务图，结合LiDAR与相机进行SLAM和语义建图，并使用任务感知的前沿探索策略；通过细调SmolVLA模型生成抓取与放置动作，实现在消费级硬件上的实时运行。

Result: 在多房间实验室环境中实现了46%的整体任务成功率，系统可在嵌入式设备上实时运行，兼顾几何导航的可靠性与语言驱动操作的灵活性。

Conclusion: 结合经典导航栈与轻量级VLA操纵头的方法，能够在未知环境中有效执行自然语言指令，具备良好的实际部署潜力。

Abstract: We address natural language pick-and-place in unseen, unpredictable indoor
environments with AnywhereVLA, a modular framework for mobile manipulation. A
user text prompt serves as an entry point and is parsed into a structured task
graph that conditions classical SLAM with LiDAR and cameras, metric semantic
mapping, and a task-aware frontier exploration policy. An approach planner then
selects visibility and reachability aware pre grasp base poses. For
interaction, a compact SmolVLA manipulation head is fine tuned on platform pick
and place trajectories for the SO-101 by TheRobotStudio, grounding local visual
context and sub-goals into grasp and place proposals. The full system runs
fully onboard on consumer-level hardware, with Jetson Orin NX for perception
and VLA and an Intel NUC for SLAM, exploration, and control, sustaining
real-time operation. We evaluated AnywhereVLA in a multi-room lab under static
scenes and normal human motion. In this setting, the system achieves a $46\%$
overall task success rate while maintaining throughput on embedded compute. By
combining a classical stack with a fine-tuned VLA manipulation, the system
inherits the reliability of geometry-based navigation with the agility and task
generalization of language-conditioned manipulation.

</details>


### [186] [Multi-Robot Vision-Based Task and Motion Planning for EV Battery Disassembly and Sorting](https://arxiv.org/abs/2509.21020)
*Abdelaziz Shaarawy,Cansu Erdogan,Rustam Stolkin,Alireza Rastegarpanah*

Main category: cs.RO

TL;DR: 提出了一种四层任务与运动规划框架，用于多机器人协同的电动汽车电池拆解，结合符号任务规划、成本与可达性感知分配及基于TP-GMM的运动规划，在真实动态环境中实现了更紧凑、安全和高效的运动。


<details>
  <summary>Details</summary>
Motivation: 电动汽车电池拆解需要在复杂动态环境中实现多机器人精确协调、短而可靠的运动路径以及高碰撞安全性，现有方法难以满足这些需求。

Method: 采用四层任务-运动联合规划（TAMP）框架，融合符号任务规划、成本与可访问性感知的任务分配，并利用从演示中学习的TP-GMM引导运动规划；通过YOLOv8立体视觉实现实时部件定位，结合OctoMap 3D建图与FCL在MoveIt中统一进行预测性数字孪生碰撞检测与反应式视觉避障。

Result: 在两个UR10e机器人上验证了电缆、母线、服务插头及三种叶片电池拆卸任务，相比RRTConnect基线方法：平均末端轨迹缩短63.3%，工期减少8.1%；单臂扫过体积显著减小（R1: 0.583→0.139 m³；R2: 0.696→0.252 m³），双臂重叠区域减少47%（0.064→0.034 m³）。

Conclusion: 该方法显著提升了非结构化动态环境下多机器人EV电池拆解的自主性、精度与安全性。

Abstract: Electric-vehicle (EV) battery disassembly requires precise multi-robot
coordination, short and reliable motions, and robust collision safety in
cluttered, dynamic scenes. We propose a four-layer task-and-motion planning
(TAMP) framework that couples symbolic task planning and cost- and
accessibility-aware allocation with a TP-GMM-guided motion planner learned from
demonstrations. Stereo vision with YOLOv8 provides real-time component
localization, while OctoMap-based 3D mapping and FCL(Flexible Collision
Library) checks in MoveIt unify predictive digital-twin collision checking with
reactive, vision-based avoidance. Validated on two UR10e robots across cable,
busbar, service plug, and three leaf-cell removals, the approach yields
substantially more compact and safer motions than a default RRTConnect baseline
under identical perception and task assignments: average end-effector path
length drops by $-63.3\%$ and makespan by $-8.1\%$; per-arm swept volumes
shrink (R1: $0.583\rightarrow0.139\,\mathrm{m}^3$; R2:
$0.696\rightarrow0.252\,\mathrm{m}^3$), and mutual overlap decreases by $47\%$
($0.064\rightarrow0.034\,\mathrm{m}^3$). These results highlight improved
autonomy, precision, and safety for multi-robot EV battery disassembly in
unstructured, dynamic environments.

</details>


### [187] [KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models](https://arxiv.org/abs/2509.21027)
*Sibo Li,Qianyue Hao,Yu Shang,Yong Li*

Main category: cs.RO

TL;DR: 提出KeyWorld框架，通过聚焦语义关键帧并用轻量模型填充中间帧，显著提升文本条件下的机器人世界模型推理速度与物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人世界模型采用逐帧生成方式，计算冗余且忽略关键状态转移，导致推理速度慢和生成轨迹物理不合理，限制了实际应用。

Method: 首先通过简化机器人运动轨迹提取真实关键帧；然后使用DiT模型根据文本任务描述生成这些关键帧；最后用轻量卷积插值模型重建完整视频序列。

Result: 在LIBERO基准上实现比逐帧生成基线快5.68倍的推理速度，生成视频的物理合理性更好，尤其在复杂任务上表现更优。

Conclusion: KeyWorld为实现实时机器人控制等需要高效且有效世界模型的应用提供了可行路径。

Abstract: Robotic world models are a promising paradigm for forecasting future
environment states, yet their inference speed and the physical plausibility of
generated trajectories remain critical bottlenecks, limiting their real-world
applications. This stems from the redundancy of the prevailing frame-to-frame
generation approach, where the model conducts costly computation on similar
frames, as well as neglecting the semantic importance of key transitions. To
address this inefficiency, we propose KeyWorld, a framework that improves
text-conditioned robotic world models by concentrating transformers computation
on a few semantic key frames while employing a lightweight convolutional model
to fill the intermediate frames. Specifically, KeyWorld first identifies
significant transitions by iteratively simplifying the robot's motion
trajectories, obtaining the ground truth key frames. Then, a DiT model is
trained to reason and generate these physically meaningful key frames from
textual task descriptions. Finally, a lightweight interpolator efficiently
reconstructs the full video by inpainting all intermediate frames. Evaluations
on the LIBERO benchmark demonstrate that KeyWorld achieves a 5.68$\times$
acceleration compared to the frame-to-frame generation baseline, and focusing
on the motion-aware key frames further contributes to the physical validity of
the generated videos, especially on complex tasks. Our approach highlights a
practical path toward deploying world models in real-time robotic control and
other domains requiring both efficient and effective world models. Code is
released at https://anonymous.4open.science/r/Keyworld-E43D.

</details>


### [188] [MPC-based Deep Reinforcement Learning Method for Space Robotic Control with Fuel Sloshing Mitigation](https://arxiv.org/abs/2509.21045)
*Mahya Ramezani,M. Amin Alandihallaj,Barış Can Yalçın,Miguel Angel Olivares Mendez,Holger Voos*

Main category: cs.RO

TL;DR: 提出了一种结合强化学习（PPO和SAC）与模型预测控制（MPC）的卫星自主对接框架，有效应对燃料晃动带来的控制挑战。


<details>
  <summary>Details</summary>
Motivation: 传统卫星对接在微重力下因燃料晃动导致不稳定，难以精确控制。

Method: 将PPO和SAC两种强化学习算法与MPC结合，利用MPC的预测能力加速RL训练并提升控制鲁棒性。

Result: 仿真结果表明，SAC-MPC在对接精度、成功率和控制能耗上优于单独RL及PPO-MPC方法。

Conclusion: 该方法提升了燃料效率与抗扰能力，推动了在轨加油与服务任务的可行性。

Abstract: This paper presents an integrated Reinforcement Learning (RL) and Model
Predictive Control (MPC) framework for autonomous satellite docking with a
partially filled fuel tank. Traditional docking control faces challenges due to
fuel sloshing in microgravity, which induces unpredictable forces affecting
stability. To address this, we integrate Proximal Policy Optimization (PPO) and
Soft Actor-Critic (SAC) RL algorithms with MPC, leveraging MPC's predictive
capabilities to accelerate RL training and improve control robustness. The
proposed approach is validated through Zero-G Lab of SnT experiments for planar
stabilization and high-fidelity numerical simulations for 6-DOF docking with
fuel sloshing dynamics. Simulation results demonstrate that SAC-MPC achieves
superior docking accuracy, higher success rates, and lower control effort,
outperforming standalone RL and PPO-MPC methods. This study advances
fuel-efficient and disturbance-resilient satellite docking, enhancing the
feasibility of on-orbit refueling and servicing missions.

</details>


### [189] [Normalizing Flows are Capable Visuomotor Policy Learning Models](https://arxiv.org/abs/2509.21073)
*Simon Kristoffersson Lind,Jialong Li,Maj Stenmark,Volker Krüger*

Main category: cs.RO

TL;DR: 本文提出了基于归一化流的视觉运动策略模型（Normalizing Flows Policy），相较于扩散模型，其在机器人控制任务中具有更高的推理效率和可靠的置信度估计能力，在多个模拟任务中表现优于或媲美Diffusion Policy，且推理速度快达30倍。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在机器人行为建模中存在推理成本高、无法量化输出不确定性的问题，影响模型的可信度和可靠性，因此需要一种既能高效推理又能提供置信度量的替代方案。

Method: 提出Normalizing Flows Policy，利用归一化流模型进行策略学习，通过可逆变换建模动作分布，实现高效的采样推理和基于似然的置信度评估，并在多种任务中进行实验验证。

Result: 在四个模拟机器人任务中，Normalizing Flows Policy性能与Diffusion Policy相当甚至更优，推理速度提升高达30倍，样本效率更高，并可通过似然值提供输出置信度。

Conclusion: 归一化流是一种比扩散模型更高效且更可信的策略学习框架，适合应用于通用机器人领域，兼顾性能、效率与不确定性估计。

Abstract: The field of general purpose robotics has recently embraced powerful
probabilistic models, such as diffusion models, to model and learn complex
behaviors. However, these models often come with significant trade-offs, namely
high computational costs for inference and a fundamental inability to quantify
output uncertainty. We argue that a model's trustworthiness, a critical factor
for reliable, general-purpose robotics, is inherently linked to its ability to
provide confidence measures.
  In this work, we introduce Normalizing Flows Policy, a novel visuomotor
policy learning model based on Normalizing Flows. We show that Normalizing
Flows are a natural and powerful alternative to diffusion models, providing
both a statistically sound measure of confidence and a highly efficient
inference process. Through comprehensive experiments across four distinct
simulated robotic tasks, we demonstrate that Normalizing Flows Policy achieves
performance comparable to, and often surpassing, Diffusion Policy, and it does
so not only with improved sample efficiency but also with up to 30 times faster
inference. Additionally, our ablation study validates several key architectural
and training techniques that enable Normalizing Flows to perform well in this
domain.

</details>


### [190] [Flight Dynamics to Sensing Modalities: Exploiting Drone Ground Effect for Accurate Edge Detection](https://arxiv.org/abs/2509.21085)
*Chenyu Zhao,Jingao Xu,Ciyu Ruan,Haoyang Wang,Shengbo Wang,Jiaqi Li,Jirong Zha,Weijie Hong,Zheng Yang,Yunhao Liu,Xiao-Ping Zhang,Xinlei Chen*

Main category: cs.RO

TL;DR: 本文提出AirTouch系统，利用无人机的地面效应作为新的感知模态，通过分析姿态传感器数据和飞行指令实现高效、准确的环境边缘检测，相比传统视觉方法具有更低功耗和更高精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于雷达或摄像头的边缘检测方法成本高、计算负担重，难以适用于轻量级无人机，因此需要一种低成本、低功耗且高效的边缘检测方案。

Method: 通过理论分析和算法设计，利用无人机在不同地表材料上飞行时地面效应引起的基本姿态传感器读数和飞行控制命令的变化，检测地面边界，将地面效应从飞行控制的干扰因素转化为有益的感知信号。

Result: 系统平均检测距离误差为0.051米，性能优于基线方法86%，功耗仅为43mW，在资源效率和检测能力上优于视觉方法。

Conclusion: AirTouch成功将地面效应转化为有效的边缘检测手段，实现了高精度、低功耗的环境感知，为轻量级无人机提供了可行的边缘检测解决方案。

Abstract: Drone-based rapid and accurate environmental edge detection is highly
advantageous for tasks such as disaster relief and autonomous navigation.
Current methods, using radars or cameras, raise deployment costs and burden
lightweight drones with high computational demands. In this paper, we propose
AirTouch, a system that transforms the ground effect from a stability "foe" in
traditional flight control views, into a "friend" for accurate and efficient
edge detection. Our key insight is that analyzing drone basic attitude sensor
readings and flight commands allows us to detect ground effect changes. Such
changes typically indicate the drone flying over a boundary of two materials,
making this information valuable for edge detection. We approach this insight
through theoretical analysis, algorithm design, and implementation, fully
leveraging the ground effect as a new sensing modality without compromising
drone flight stability, thereby achieving accurate and efficient scene edge
detection. We also compare this new sensing modality with vision-based methods
to clarify its exclusive advantages in resource efficiency and detection
capability. Extensive evaluations demonstrate that our system achieves a high
detection accuracy with mean detection distance errors of 0.051m, outperforming
the baseline method performance by 86%. With such detection performance, our
system requires only 43 mW power consumption, contributing to this new sensing
modality for low-cost and highly efficient edge detection.

</details>


### [191] [Cross-Modal Instructions for Robot Motion Generation](https://arxiv.org/abs/2509.21107)
*William Barron,Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 本文提出了一种名为CrossInstruct的新框架，通过跨模态指令（如文本标注）替代物理演示来教会机器人新行为，结合视觉-语言模型与精细指向模型生成可执行动作，并在仿真与真实硬件上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统机器人行为教学依赖繁琐的物理示教或遥操作，使用人类草图的方法数据收集困难且难以扩展，因此需要一种更高效、可扩展的替代范式。

Method: 提出Learning from Cross-Modal Instructions范式，将包含自由文本标签的粗略注释作为示范输入；利用基础视觉-语言模型（VLM）结合微调的小模型，在多视角2D图像中迭代合成动作，并融合为3D空间中的运动轨迹分布。

Result: CrossInstruct在无需额外微调的情况下，在基准仿真任务和真实机器人上均表现出色，并能为后续强化学习提供良好策略初始化，显著提升细粒度任务的学习效率。

Conclusion: 该方法实现了从非物理、跨模态指令到机器人可执行行为的有效转化，具备良好泛化能力，降低了对大规模物理演示数据的依赖。

Abstract: Teaching robots novel behaviors typically requires motion demonstrations via
teleoperation or kinaesthetic teaching, that is, physically guiding the robot.
While recent work has explored using human sketches to specify desired
behaviors, data collection remains cumbersome, and demonstration datasets are
difficult to scale. In this paper, we introduce an alternative paradigm,
Learning from Cross-Modal Instructions, where robots are shaped by
demonstrations in the form of rough annotations, which can contain free-form
text labels, and are used in lieu of physical motion. We introduce the
CrossInstruct framework, which integrates cross-modal instructions as examples
into the context input to a foundational vision-language model (VLM). The VLM
then iteratively queries a smaller, fine-tuned model, and synthesizes the
desired motion over multiple 2D views. These are then subsequently fused into a
coherent distribution over 3D motion trajectories in the robot's workspace. By
incorporating the reasoning of the large VLM with a fine-grained pointing
model, CrossInstruct produces executable robot behaviors that generalize beyond
the environment of in the limited set of instruction examples. We then
introduce a downstream reinforcement learning pipeline that leverages
CrossInstruct outputs to efficiently learn policies to complete fine-grained
tasks. We rigorously evaluate CrossInstruct on benchmark simulation tasks and
real hardware, demonstrating effectiveness without additional fine-tuning and
providing a strong initialization for policies subsequently refined via
reinforcement learning.

</details>


### [192] [Rich State Observations Empower Reinforcement Learning to Surpass PID: A Drone Ball Balancing Study](https://arxiv.org/abs/2509.21122)
*Mingjiang Liu,Hailong Huang*

Main category: cs.RO

TL;DR: 本文提出了一种分层控制框架，使用强化学习（RL）策略在无人机球平衡任务中实现优于传统PID控制器的性能，关键在于RL能更有效地利用丰富的状态观测信息。


<details>
  <summary>Details</summary>
Motivation: 为了提高无人机通过缆绳与可移动梁相互作用来稳定球体的任务性能，探索比传统PID控制器更有效的控制策略。

Method: 采用分层控制框架，将高层平衡策略与底层无人机控制解耦，并使用强化学习训练高层决策策略。

Result: 仿真结果表明，在相同框架下，RL策略性能优于精心调参的PID控制器；分析显示其优势主要源于对更丰富状态信息的有效利用，而非参数优化或非线性映射能力。

Conclusion: 全面的状态表示对基于学习的控制系统至关重要，增强感知能力可能显著提升控制器性能。

Abstract: This paper addresses a drone ball-balancing task, in which a drone stabilizes
a ball atop a movable beam through cable-based interaction. We propose a
hierarchical control framework that decouples high-level balancing policy from
low-level drone control, and train a reinforcement learning (RL) policy to
handle the high-level decision-making. Simulation results show that the RL
policy achieves superior performance compared to carefully tuned PID
controllers within the same hierarchical structure. Through systematic
comparative analysis, we demonstrate that RL's advantage stems not from
improved parameter tuning or inherent nonlinear mapping capabilities, but from
its ability to effectively utilize richer state observations. These findings
underscore the critical role of comprehensive state representation in
learning-based systems and suggest that enhanced sensing could be instrumental
in improving controller performance.

</details>


### [193] [Automotive-ENV: Benchmarking Multimodal Agents in Vehicle Interface Systems](https://arxiv.org/abs/2509.21143)
*Junfeng Yan,Biao Wu,Meng Fang,Ling Chen*

Main category: cs.RO

TL;DR: 本文提出了首个针对车载GUI的高保真基准和交互环境Automotive-ENV，以及基于地理感知的多模态代理ASURADA，通过融合位置信息提升车载系统中安全敏感任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态代理在通用GUI交互中表现良好，但在车载系统中的应用面临驾驶员注意力有限、安全性要求高和基于位置的复杂交互模式等挑战，亟需专门的基准和方法来推动该领域发展。

Method: 构建了一个包含185个参数化任务的高保真基准平台Automotive-ENV，并提出ASURADA——一种结合GPS上下文信息的地理感知多模态代理，能够根据位置、环境条件和区域驾驶规范动态调整行为。

Result: 实验证明，引入地理感知信息显著提升了代理在安全相关任务上的成功率，验证了位置上下文在车载环境中的关键作用。

Conclusion: 地理感知是提升车载多模态代理性能的关键因素，Automotive-ENV为未来安全、自适应车载代理的研究提供了重要基础。

Abstract: Multimodal agents have demonstrated strong performance in general GUI
interactions, but their application in automotive systems has been largely
unexplored. In-vehicle GUIs present distinct challenges: drivers' limited
attention, strict safety requirements, and complex location-based interaction
patterns. To address these challenges, we introduce Automotive-ENV, the first
high-fidelity benchmark and interaction environment tailored for vehicle GUIs.
This platform defines 185 parameterized tasks spanning explicit control,
implicit intent understanding, and safety-aware tasks, and provides structured
multimodal observations with precise programmatic checks for reproducible
evaluation. Building on this benchmark, we propose ASURADA, a geo-aware
multimodal agent that integrates GPS-informed context to dynamically adjust
actions based on location, environmental conditions, and regional driving
norms. Experiments show that geo-aware information significantly improves
success on safety-aware tasks, highlighting the importance of location-based
context in automotive environments. We will release Automotive-ENV, complete
with all tasks and benchmarking tools, to further the development of safe and
adaptive in-vehicle agents.

</details>


### [194] [DAGDiff: Guiding Dual-Arm Grasp Diffusion to Stable and Collision-Free Grasps](https://arxiv.org/abs/2509.21145)
*Md Faizal Karim,Vignesh Vembar,Keshab Patra,Gaurav Singh,K Madhava Krishna*

Main category: cs.RO

TL;DR: 提出DAGDiff，一种端到端的双臂抓取框架，直接在SE(3) x SE(3)空间中去噪生成抓取对，通过分类器信号引导扩散过程，确保稳定性与无碰撞，无需依赖显式区域检测或物体先验。


<details>
  <summary>Details</summary>
Motivation: 现有方法将双臂抓取分解为两个独立的抓取提议，依赖区域先验或启发式规则，泛化能力有限且无法保证抓取稳定性与无碰撞，因此需要一种更可靠、通用的方法。

Method: 提出DAGDiff，基于扩散模型在SE(3) x SE(3)空间直接生成双臂抓取对，引入几何、稳定性和碰撞感知的引导项，在生成过程中通过分类器引导确保抓取的物理有效性与力封闭性。

Result: 在力封闭验证、碰撞分析和大规模物理仿真中均优于先前方法，并能在真实异构双臂系统上成功抓取和提起之前未见过的物体的真实点云数据。

Conclusion: DAGDiff能够有效生成稳定、无碰撞且具备良好泛化能力的双臂抓取方案，可在仿真和真实场景中可靠执行，推动了复杂物体操作中双臂协同抓取的发展。

Abstract: Reliable dual-arm grasping is essential for manipulating large and complex
objects but remains a challenging problem due to stability, collision, and
generalization requirements. Prior methods typically decompose the task into
two independent grasp proposals, relying on region priors or heuristics that
limit generalization and provide no principled guarantee of stability. We
propose DAGDiff, an end-to-end framework that directly denoises to grasp pairs
in the SE(3) x SE(3) space. Our key insight is that stability and collision can
be enforced more effectively by guiding the diffusion process with classifier
signals, rather than relying on explicit region detection or object priors. To
this end, DAGDiff integrates geometry-, stability-, and collision-aware
guidance terms that steer the generative process toward grasps that are
physically valid and force-closure compliant. We comprehensively evaluate
DAGDiff through analytical force-closure checks, collision analysis, and
large-scale physics-based simulations, showing consistent improvements over
previous work on these metrics. Finally, we demonstrate that our framework
generates dual-arm grasps directly on real-world point clouds of previously
unseen objects, which are executed on a heterogeneous dual-arm setup where two
manipulators reliably grasp and lift them.

</details>


### [195] [Human-like Navigation in a World Built for Humans](https://arxiv.org/abs/2509.21189)
*Bhargav Chandaka,Gloria X. Wang,Haozhe Chen,Henry Che,Albert J. Zhai,Shenlong Wang*

Main category: cs.RO

TL;DR: ReasonNav 是一种结合视觉-语言模型的模块化导航系统，通过模拟人类读取标识和询问方向的行为，提升机器人在大型复杂环境中的导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航系统在大型环境中效率低下，缺乏像人类一样通过读取标识或询问来减少搜索范围的能力。

Method: 提出 ReasonNav 系统，利用视觉-语言模型（VLM），设计基于导航地标的小型输入输出抽象，使模型专注于语言理解和推理。

Result: 在真实和模拟导航任务中评估显示，该系统能有效运用高阶推理，在大型复杂建筑中实现高效导航。

Conclusion: ReasonNav 通过融合人类类导航行为与 VLM 的推理能力，显著提升了机器人在未知人造环境中的导航性能。

Abstract: When navigating in a man-made environment they haven't visited before--like
an office building--humans employ behaviors such as reading signs and asking
others for directions. These behaviors help humans reach their destinations
efficiently by reducing the need to search through large areas. Existing robot
navigation systems lack the ability to execute such behaviors and are thus
highly inefficient at navigating within large environments. We present
ReasonNav, a modular navigation system which integrates these human-like
navigation skills by leveraging the reasoning capabilities of a vision-language
model (VLM). We design compact input and output abstractions based on
navigation landmarks, allowing the VLM to focus on language understanding and
reasoning. We evaluate ReasonNav on real and simulated navigation tasks and
show that the agent successfully employs higher-order reasoning to navigate
efficiently in large, complex buildings.

</details>


### [196] [Next-Generation Aerial Robots -- Omniorientational Strategies: Dynamic Modeling, Control, and Comparative Analysis](https://arxiv.org/abs/2509.21210)
*Ali Kafili Gavgani,Amin Talaeizadeh,Aria Alasty,Hossein Nejat Pishkenari,Esmaeil Najafi*

Main category: cs.RO

TL;DR: 本文提出多种可操纵螺旋桨轴角度的全向多旋翼无人机构型，通过增加控制输入实现姿态与位置的独立控制，并建立动态模型与仿真验证。设计了滑模控制器和一种新颖的带重力补偿的PID控制器，结合线性与非线性分配器以提高计算效率。提出定制控制分配策略以最小化功耗因子，延长电池寿命。仿真结果对比了不同构型与控制器的功耗表现，并分析不确定性对系统的影响，为全向无人机的设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼是欠驱动系统，无法独立控制姿态与位置。本文旨在通过引入额外控制输入，实现全向运动能力（omniorientational），克服这一限制。

Method: 提出多种可调节螺旋桨轴角度的无人机构型，建立详细的动态模型，并通过Simscape Multibody仿真进行验证。设计滑模控制器以增强抗干扰能力，以及一种新型带重力补偿的PID控制器，结合线性和非线性控制分配器。采用定制的控制分配策略处理输入非仿射特性，并以最小化‘功耗因子’为目标优化能耗。

Result: 所有构型均实现全向运动能力；两种控制器在存在强干扰和不确定性下仍表现良好；新型PID控制器在保证性能的同时具有更高计算效率；控制分配策略有效降低功耗。仿真结果显示不同构型在功耗方面存在差异，且系统对建模误差和硬件不确定性敏感。

Conclusion: 本研究为全向多旋翼无人机的设计提供了系统性的建模、控制与优化框架，明确了构型选择与控制器设计之间的权衡，特别强调能效优化，为未来研究提供了实用参考和技术路线图。

Abstract: Conventional multi-rotors are under-actuated systems, hindering them from
independently controlling attitude from position. In this study, we present
several distinct configurations that incorporate additional control inputs for
manipulating the angles of the propeller axes. This addresses the mentioned
limitations, making the systems "omniorientational". We comprehensively derived
detailed dynamic models for all introduced configurations and validated by a
methodology using Simscape Multibody simulations. Two controllers are designed:
a sliding mode controller for robust handling of disturbances and a novel
PID-based controller with gravity compensation integrating linear and
non-linear allocators, designed for computational efficiency. A custom control
allocation strategy is implemented to manage the input-non-affine nature of
these systems, seeking to maximize battery life by minimizing the "Power
Consumption Factor" defined in this study. Moreover, the controllers
effectively managed harsh disturbances and uncertainties. Simulations compare
and analyze the proposed configurations and controllers, majorly considering
their power consumption. Furthermore, we conduct a qualitative comparison to
evaluate the impact of different types of uncertainties on the control system,
highlighting areas for potential model or hardware improvements. The analysis
in this study provides a roadmap for future researchers to design
omniorientational drones based on their design objectives, offering practical
insights into configuration selection and controller design. This research
aligns with the project SAC-1, one of the objectives of Sharif AgRoLab.

</details>


### [197] [SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation](https://arxiv.org/abs/2509.21231)
*Jaehwi Jang,Zhuoheng Wang,Ziyi Zhou,Feiyang Wu,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于模型增强残差学习的稳定末端执行器控制（SEEC）框架，通过模型引导的强化学习和扰动生成器实现精确且鲁棒的末端执行器补偿，能够在不同仿真环境中验证并成功迁移到Booster T1人形机器人上，表现出优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型的控制器依赖精确的动力学建模，在实际中因摩擦、回差等因素性能下降；而纯学习方法易过拟合训练条件，难以适应未见场景，因此需要一种兼具精度与泛化能力的末端执行器控制方法。

Method: 提出SEEC框架，采用模型增强的残差学习结构，结合模型引导的强化学习与扰动生成器，使上身策略能补偿下身运动引起的扰动，并适应未见过的下层运动控制器而无需重新训练。

Result: 在多个仿真环境中验证了该方法的有效性，并成功迁移到Booster T1人形机器人，实验表明其在多种复杂动态操作任务中均优于基线方法，具备更强的鲁棒性和适应性。

Conclusion: 所提出的SEEC框架实现了高精度、强鲁棒的末端执行器稳定控制，能够跨控制器迁移且无需额外训练，为人形机器人在真实场景下的灵巧操作提供了有效解决方案。

Abstract: Arm end-effector stabilization is essential for humanoid loco-manipulation
tasks, yet it remains challenging due to the high degrees of freedom and
inherent dynamic instability of bipedal robot structures. Previous model-based
controllers achieve precise end-effector control but rely on precise dynamics
modeling and estimation, which often struggle to capture real-world factors
(e.g., friction and backlash) and thus degrade in practice. On the other hand,
learning-based methods can better mitigate these factors via exploration and
domain randomization, and have shown potential in real-world use. However, they
often overfit to training conditions, requiring retraining with the entire
body, and still struggle to adapt to unseen scenarios. To address these
challenges, we propose a novel stable end-effector control (SEEC) framework
with model-enhanced residual learning that learns to achieve precise and robust
end-effector compensation for lower-body induced disturbances through
model-guided reinforcement learning (RL) with a perturbation generator. This
design allows the upper-body policy to achieve accurate end-effector
stabilization as well as adapt to unseen locomotion controllers with no
additional training. We validate our framework in different simulators and
transfer trained policies to the Booster T1 humanoid robot. Experiments
demonstrate that our method consistently outperforms baselines and robustly
handles diverse and demanding loco-manipulation tasks.

</details>


### [198] [FSGlove: An Inertial-Based Hand Tracking System with Shape-Aware Calibration](https://arxiv.org/abs/2509.21242)
*Yutong Li,Jieyi Zhang,Wenqiang Xu,Tutian Tang,Cewu Lu*

Main category: cs.RO

TL;DR: FSGlove是一种基于惯性传感器的手部动作捕捉系统，通过DiffHCal校准方法实现了高达48自由度的运动追踪和个性化手形重建，精度优于现有商业方案，且开源软硬件设计便于集成到VR和机器人系统中。


<details>
  <summary>Details</summary>
Motivation: 现有手部动捕系统自由度不足且忽略个体化手形差异，难以满足复杂操作和接触丰富任务的需求。

Method: 在每个手指关节和背部安装IMU传感器，结合可微优化的DiffHCal方法，与参数化MANO模型集成，实现运动学、形状参数和传感器误差的联合标定。

Result: 系统关节角度误差小于2.7度，在形状重建和接触保真度上优于商业设备，并能捕捉细微动作如指尖摩擦。

Conclusion: FSGlove在手部运动捕捉的自由度、精度和个性化方面达到先进水平，推动了人手灵活性与机器人模仿之间的融合。

Abstract: Accurate hand motion capture (MoCap) is vital for applications in robotics,
virtual reality, and biomechanics, yet existing systems face limitations in
capturing high-degree-of-freedom (DoF) joint kinematics and personalized hand
shape. Commercial gloves offer up to 21 DoFs, which are insufficient for
complex manipulations while neglecting shape variations that are critical for
contact-rich tasks. We present FSGlove, an inertial-based system that
simultaneously tracks up to 48 DoFs and reconstructs personalized hand shapes
via DiffHCal, a novel calibration method. Each finger joint and the dorsum are
equipped with IMUs, enabling high-resolution motion sensing. DiffHCal
integrates with the parametric MANO model through differentiable optimization,
resolving joint kinematics, shape parameters, and sensor misalignment during a
single streamlined calibration. The system achieves state-of-the-art accuracy,
with joint angle errors of less than 2.7 degree, and outperforms commercial
alternatives in shape reconstruction and contact fidelity. FSGlove's
open-source hardware and software design ensures compatibility with current VR
and robotics ecosystems, while its ability to capture subtle motions (e.g.,
fingertip rubbing) bridges the gap between human dexterity and robotic
imitation. Evaluated against Nokov optical MoCap, FSGlove advances hand
tracking by unifying the kinematic and contact fidelity. Hardware design,
software, and more results are available at:
https://sites.google.com/view/fsglove.

</details>


### [199] [RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models](https://arxiv.org/abs/2509.21243)
*Jiyeon Koo,Taewan Cho,Hyunjoon Kang,Eunseom Pyo,Tae Gyun Oh,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.RO

TL;DR: 本文提出了一种名为RetoVLA的新架构，通过重用Vision Transformer中原本用于去除伪影的Register Tokens来增强轻量级视觉-语言-动作模型的空间推理能力，在不增加计算成本的前提下显著提升了机器人复杂操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的轻量化VLA模型在减少计算成本的同时往往牺牲了关键的空间推理能力，导致性能下降。如何在保持模型轻量化的同时提升其空间感知与推理能力成为亟待解决的问题。

Method: 提出RetoVLA架构，重新利用原本被丢弃的Register Tokens，将其注入到动作专家（Action Expert）中，以增强模型对空间信息的利用，从而在不增加模型体积的情况下改善推理能力。

Result: 在自建的7自由度机械臂平台上进行实验，RetoVLA在复杂操作任务上的成功率绝对提升了17.1个百分点，验证了重用Register Tokens可有效增强空间 reasoning 能力。

Conclusion: Register Tokens并非冗余信息，而是蕴含重要空间信息的潜在资源，重用这些令牌为构建高效、高性能的轻量级机器人智能模型提供了新思路。

Abstract: Recent Vision-Language-Action (VLA) models demonstrate remarkable
generalization in robotics but are restricted by their substantial size and
computational cost, limiting real-world deployment. However, conventional
lightweighting methods often sacrifice critical capabilities, particularly
spatial reasoning. This creates a trade-off between efficiency and performance.
To address this challenge, our work reuses Register Tokens, which were
introduced for artifact removal in Vision Transformers but subsequently
discarded. We suppose that these tokens contain essential spatial information
and propose RetoVLA, a novel architecture that reuses them directly by
injecting them into the Action Expert.
  RetoVLA maintains a lightweight structure while leveraging this repurposed
spatial context to enhance reasoning. We demonstrate RetoVLA's effectiveness
through a series of comprehensive experiments. On our custom-built 7-DOF robot
arm, the model achieves a 17.1%p absolute improvement in success rates for
complex manipulation tasks. Our results confirm that reusing Register Tokens
directly enhances spatial reasoning, demonstrating that what was previously
discarded as an artifact is in fact a valuable, unexplored resource for robotic
intelligence. A video demonstration is available at:
https://youtu.be/2CseBR-snZg

</details>


### [200] [BiNoMaP: Learning Category-Level Bimanual Non-Prehensile Manipulation Primitives](https://arxiv.org/abs/2509.21256)
*Huayi Zhou,Kui Jia*

Main category: cs.RO

TL;DR: 本文提出了一种无需强化学习的三阶段框架BiNoMaP，用于双臂非抓握操作，通过从视频演示中提取动作并进行几何感知优化，实现跨物体类别和任务的泛化。


<details>
  <summary>Details</summary>
Motivation: 非抓握操作由于接触复杂且难以建模，在机器人领域仍具挑战性，现有方法多依赖单臂设置或外部环境辅助，缺乏通用性和可扩展性。

Method: 提出双臂非抓握操作基元（BiNoMaP），从视频中提取双手动作轨迹，并设计几何感知的后优化算法以适应机器人执行；通过物体几何属性（如尺寸）参数化，实现类别级泛化。

Result: 在多种双臂任务和不同物体类别上验证了BiNoMaP的有效性、效率、灵活性及优越的泛化能力。

Conclusion: BiNoMaP提供了一种可推广、无需强化学习的双臂非抓握操作解决方案，显著提升了在复杂接触场景下的技能迁移与适应能力。

Abstract: Non-prehensile manipulation, encompassing ungraspable actions such as
pushing, poking, and pivoting, represents a critical yet underexplored domain
in robotics due to its contact-rich and analytically intractable nature. In
this work, we revisit this problem from two novel perspectives. First, we move
beyond the usual single-arm setup and the strong assumption of favorable
external dexterity such as walls, ramps, or edges. Instead, we advocate a
generalizable dual-arm configuration and establish a suite of Bimanual
Non-prehensile Manipulation Primitives (BiNoMaP). Second, we depart from the
prevailing RL-based paradigm and propose a three-stage, RL-free framework to
learn non-prehensile skills. Specifically, we begin by extracting bimanual hand
motion trajectories from video demonstrations. Due to visual inaccuracies and
morphological gaps, these coarse trajectories are difficult to transfer
directly to robotic end-effectors. To address this, we propose a geometry-aware
post-optimization algorithm that refines raw motions into executable
manipulation primitives that conform to specific motion patterns. Beyond
instance-level reproduction, we further enable category-level generalization by
parameterizing the learned primitives with object-relevant geometric
attributes, particularly size, resulting in adaptable and general parameterized
manipulation primitives. We validate BiNoMaP across a range of representative
bimanual tasks and diverse object categories, demonstrating its effectiveness,
efficiency, versatility, and superior generalization capability.

</details>


### [201] [\LARGE GMP$^{3}$: Learning-Driven, Bellman-Guided Trajectory Planning for UAVs in Real-Time on SE(3)](https://arxiv.org/abs/2509.21264)
*Babak Salamat,Dominik Mattern,Sebastian-Sven Olzem,Gerhard Elsbacher,Christian Seidel,Andrea M. Tonello*

Main category: cs.RO

TL;DR: 提出了一种基于SE(3)的多阶段全局路径规划框架GMP³，结合强化学习与分布式协同机制，生成动态可行的三维轨迹，并通过DroneManager实现真实无人机平台的实时部署。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划方法通常只考虑欧几里得空间中的位置规划，难以兼顾无人机在复杂环境中的运动学约束和姿态动力学；为此，需要一种能联合建模平移与旋转、支持多机协作并适应动态约束的路径规划框架。

Method: 将路径规划扩展到李群SE(3)空间，提出GMP³框架，引入改进的Bellman算子用于强化学习策略更新，并采用基于共识的分布式架构，使各代理共享策略信息并协同优化轨迹；同时开发DroneManager软件，通过MAVLink协议连接规划器与真实无人机。

Result: 仿真和室内飞行实验表明，该方法能在拥挤的三维环境中实现可靠的避障，生成平滑且动力学可行的轨迹（涵盖位置与姿态），并在多机协同下实现快速收敛。

Conclusion: GMP³通过在SE(3)上统一建模运动与姿态，结合分布式强化学习机制，有效提升了复杂环境下无人机轨迹规划的质量与实用性，配合DroneManager实现了从规划到实际飞行的闭环验证。

Abstract: We propose $\text{GMP}^{3}$, a multiphase global path planning framework that
generates dynamically feasible three-dimensional trajectories for unmanned
aerial vehicles (UAVs) operating in cluttered environments. The framework
extends traditional path planning from Euclidean position spaces to the Lie
group $\mathrm{SE}(3)$, allowing joint learning of translational motion and
rotational dynamics. A modified Bellman-based operator is introduced to support
reinforcement learning (RL) policy updates while leveraging prior trajectory
information for improved convergence. $\text{GMP}^{3}$ is designed as a
distributed framework in which agents influence each other and share policy
information along the trajectory: each agent refines its assigned segment and
shares with its neighbors via a consensus-based scheme, enabling cooperative
policy updates and convergence toward a path shaped globally even under
kinematic constraints. We also propose DroneManager, a modular ground control
software that interfaces the planner with real UAV platforms via the MAVLink
protocol, supporting real-time deployment and feedback. Simulation studies and
indoor flight experiments validate the effectiveness of the proposed method in
constrained 3D environments, demonstrating reliable obstacle avoidance and
smooth, feasible trajectories across both position and orientation. The
open-source implementation is available at
https://github.com/Domattee/DroneManager

</details>


### [202] [Taxonomy-aware Dynamic Motion Generation on Hyperbolic Manifolds](https://arxiv.org/abs/2509.21281)
*Luis Augenstein,Noémie Jaquier,Tamim Asfour,Leonel Rozo*

Main category: cs.RO

TL;DR: 本文提出了一种新的高斯过程隐变量动力学模型（GPHDM），通过将动态先验扩展到双曲流形并结合分类感知的归纳偏置，实现了对人体运动层次结构和时序动态的联合建模，从而生成既符合分类体系又物理一致的机器人拟人化运动。


<details>
  <summary>Details</summary>
Motivation: 现有机器人运动生成方法常忽略生物力学研究中运动的层次化结构信息，导致生成动作与真实人体运动结构脱节。本文旨在弥补这一差距，使生成的运动不仅在时间上连贯，也在语义层级上合理。

Method: 提出GPHDM模型，将高斯过程动力学模型（GPDM）的动态先验扩展至双曲流形以自然地编码层次结构，并引入分类感知的归纳偏置；在此基础上设计了三种新机制：两种概率递归方法和一种基于拉回度量测地线的方法，用于生成结构化且物理一致的运动。

Result: 在手部抓取动作分类体系上的实验表明，GPHDM能忠实编码底层分类结构和时间动态，成功生成新颖且物理合理的运动序列。

Conclusion: GPHDM通过融合双曲几何与分类先验，有效保持了运动生成中的层次结构与物理一致性，为类人运动建模提供了新的框架。

Abstract: Human-like motion generation for robots often draws inspiration from
biomechanical studies, which often categorize complex human motions into
hierarchical taxonomies. While these taxonomies provide rich structural
information about how movements relate to one another, this information is
frequently overlooked in motion generation models, leading to a disconnect
between the generated motions and their underlying hierarchical structure. This
paper introduces the \ac{gphdm}, a novel approach that learns latent
representations preserving both the hierarchical structure of motions and their
temporal dynamics to ensure physical consistency. Our model achieves this by
extending the dynamics prior of the Gaussian Process Dynamical Model (GPDM) to
the hyperbolic manifold and integrating it with taxonomy-aware inductive
biases. Building on this geometry- and taxonomy-aware frameworks, we propose
three novel mechanisms for generating motions that are both
taxonomically-structured and physically-consistent: two probabilistic recursive
approaches and a method based on pullback-metric geodesics. Experiments on
generating realistic motion sequences on the hand grasping taxonomy show that
the proposed GPHDM faithfully encodes the underlying taxonomy and temporal
dynamics, and generates novel physically-consistent trajectories.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [203] [Structuring Collective Action with LLM-Guided Evolution: From Ill-Structured Problems to Executable Heuristics](https://arxiv.org/abs/2509.20412)
*Kevin Bradley Dsouza,Graham Alexander Watt,Yuri Leonenko,Juan Moreno-Cruz*

Main category: cs.MA

TL;DR: ECHO-MIMIC 是一种计算框架，通过进化生成可执行策略和说服性信息，将集体行动中的复杂问题转化为个体层面的良构问题，有效解决农业景观管理中的生态连通性难题。


<details>
  <summary>Details</summary>
Motivation: 集体行动问题通常属于结构不清的问题，个体行为与全局目标之间的因果关系模糊，目标冲突且缺乏明确求解算法，因此需要一种方法帮助个体在复杂环境中做出有利于集体的决策。

Method: 提出 ECHO-MIMIC 框架，分为两个阶段：ECHO 阶段使用大语言模型驱动的进化搜索生成Python代码形式的行为策略；MIMIC 阶段则生成促进个体采纳这些策略的自然语言劝导信息，两者均通过模拟环境中的群体表现进行选择优化。

Result: 在农业景观管理的模拟中，ECHO-MIMIC 发现的策略优于基线方法，并通过定制化信息成功引导虚拟农户行为，提升整体生态连通性。

Conclusion: ECHO-MIMIC 通过结合算法策略发现与个性化沟通，将复杂的集体行动问题转化为个体可操作的简单任务，为可扩展、自适应的政策设计提供了新路径。

Abstract: Collective action problems, which require aligning individual incentives with
collective goals, are classic examples of Ill-Structured Problems (ISPs). For
an individual agent, the causal links between local actions and global outcomes
are unclear, stakeholder objectives often conflict, and no single, clear
algorithm can bridge micro-level choices with macro-level welfare. We present
ECHO-MIMIC, a computational framework that converts this global complexity into
a tractable, Well-Structured Problem (WSP) for each agent by discovering
compact, executable heuristics and persuasive rationales. The framework
operates in two stages: ECHO (Evolutionary Crafting of Heuristics from
Outcomes) evolves snippets of Python code that encode candidate behavioral
policies, while MIMIC (Mechanism Inference & Messaging for
Individual-to-Collective Alignment) evolves companion natural language messages
that motivate agents to adopt those policies. Both phases employ a
large-language-model-driven evolutionary search: the LLM proposes diverse and
context-aware code or text variants, while population-level selection retains
those that maximize collective performance in a simulated environment. We
demonstrate this framework on a canonical ISP in agricultural landscape
management, where local farming decisions impact global ecological
connectivity. Results show that ECHO-MIMIC discovers high-performing heuristics
compared to baselines and crafts tailored messages that successfully align
simulated farmer behavior with landscape-level ecological goals. By coupling
algorithmic rule discovery with tailored communication, ECHO-MIMIC transforms
the cognitive burden of collective action into a simple set of agent-level
instructions, making previously ill-structured problems solvable in practice
and opening a new path toward scalable, adaptive policy design.

</details>


### [204] [RadAgents: Multimodal Agentic Reasoning for Chest X-ray Interpretation with Radiologist-like Workflows](https://arxiv.org/abs/2509.20490)
*Kai Zhang,Corey D Barrett,Jangwon Kim,Lichao Sun,Tara Taghavi,Krishnaram Kenthapadi*

Main category: cs.MA

TL;DR: 提出RadAgents，一个多智能体框架，通过结合临床先验和任务感知的多模态推理，提升胸部X光解读的可解释性、一致性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有CXR解读方法存在推理不可解释、多模态融合不足、缺乏一致性验证机制等问题。

Method: 设计RadAgents框架，采用多智能体协作、多模态检索增强、视觉 grounding 和冲突检测机制，实现任务感知的推理。

Result: 系统能生成更可靠、透明且符合临床实践的解读结果，有效融合多模态证据并解决跨工具不一致问题。

Conclusion: RadAgents通过结合临床知识与多模态推理，在CXR解读中实现了更高质量、可信赖的自动化诊断支持。

Abstract: Agentic systems offer a potential path to solve complex clinical tasks
through collaboration among specialized agents, augmented by tool use and
external knowledge bases. Nevertheless, for chest X-ray (CXR) interpretation,
prevailing methods remain limited: (i) reasoning is frequently neither
clinically interpretable nor aligned with guidelines, reflecting mere
aggregation of tool outputs; (ii) multimodal evidence is insufficiently fused,
yielding text-only rationales that are not visually grounded; and (iii) systems
rarely detect or resolve cross-tool inconsistencies and provide no principled
verification mechanisms. To bridge the above gaps, we present RadAgents, a
multi-agent framework for CXR interpretation that couples clinical priors with
task-aware multimodal reasoning. In addition, we integrate grounding and
multimodal retrieval-augmentation to verify and resolve context conflicts,
resulting in outputs that are more reliable, transparent, and consistent with
clinical practice.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [205] [A Theory of Multi-Agent Generative Flow Networks](https://arxiv.org/abs/2509.20408)
*Leo Maxime Brunswic,Haozhi Wang,Shuang Luo,Jianye Hao,Amir Rasouli,Yinchuan Li*

Main category: cs.LG

TL;DR: 本文提出了多智能体生成流网络（MA-GFlowNets）的理论框架，并设计了四种算法，实现了集中训练与分布式执行，实验表明其优于强化学习和MCMC方法。


<details>
  <summary>Details</summary>
Motivation: 现有的生成流网络缺乏适用于多智能体协同生成的理论框架，限制了其在多代理环境中的应用。

Method: 提出MA-GFlowNets的理论框架，设计四种算法：集中式、独立式、联合式及条件联合式流网络，基于局部-全局原则进行训练。

Result: 理论分析证明独立策略可生成与奖励成比例的样本，实验显示新框架在性能上优于强化学习和MCMC方法。

Conclusion: MA-GFlowNets为多智能体协作生成提供了有效且具理论保证的新方法，拓展了生成流网络的应用范围。

Abstract: Generative flow networks utilize a flow-matching loss to learn a stochastic
policy for generating objects from a sequence of actions, such that the
probability of generating a pattern can be proportional to the corresponding
given reward. However, a theoretical framework for multi-agent generative flow
networks (MA-GFlowNets) has not yet been proposed. In this paper, we propose
the theory framework of MA-GFlowNets, which can be applied to multiple agents
to generate objects collaboratively through a series of joint actions. We
further propose four algorithms: a centralized flow network for centralized
training of MA-GFlowNets, an independent flow network for decentralized
execution, a joint flow network for achieving centralized training with
decentralized execution, and its updated conditional version. Joint Flow
training is based on a local-global principle allowing to train a collection of
(local) GFN as a unique (global) GFN. This principle provides a loss of
reasonable complexity and allows to leverage usual results on GFN to provide
theoretical guarantees that the independent policies generate samples with
probability proportional to the reward function. Experimental results
demonstrate the superiority of the proposed framework compared to reinforcement
learning and MCMC-based methods.

</details>


### [206] [FastEagle: Cascaded Drafting for Accelerating Speculative Decoding](https://arxiv.org/abs/2509.20416)
*Haiduo Huang,Jiangcheng Song,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: FastEagle是一种非自回归级联草稿生成方法，通过单次前向传播生成完整草稿，显著加速大语言模型的推理过程，同时保持与EAGLE相当的接受率。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法（如EAGLE）仍需N次顺序传递来提出N个token，限制了生成速度，因此需要一种更高效的非自回归草稿生成机制。

Method: 提出FastEagle，采用轻量级层级联结构替代时间步，并通过逐层监督训练减少误差累积；结合约束性草稿树以保持无损验证成本。

Result: 在多个大模型和任务上，FastEagle在贪婪和随机解码下均优于EAGLE-3，实现更高的加速比，同时平均接受长度相当。

Conclusion: 消除草稿生成中的序列依赖性是实现无损大模型推理加速的有效路径。

Abstract: Speculative decoding accelerates generation by drafting candidates and
verifying them in parallel, yet state-of-the-art drafters (e.g., EAGLE) still
require N sequential passes to propose N tokens. We present FastEagle, a
non-autoregressive cascaded drafter that emits an entire draft in a single
forward pass. FastEagle replaces temporal steps with a lightweight layer
cascade and trains with layer-wise supervision to mitigate error accumulation.
Coupled with a constrained draft tree that preserves lossless verification
cost, FastEagle delivers substantial wall-clock speedups over strong
autoregressive drafters while maintaining competitive acceptance behavior.
Across multiple LLMs (Vicuna-13B, LLaMA-Instruct 3.x, and
DeepSeek-R1-Distill-LLaMA) and tasks (MT-Bench, HumanEval, GSM8K, CNN/DM,
Alpaca), FastEagle consistently outperforms EAGLE-3 in speedup under both
greedy and stochastic decoding, with comparable average acceptance lengths.
These results indicate that removing sequential dependencies in drafting is a
practical path toward lossless LLM inference acceleration.

</details>


### [207] [mloz: A Highly Efficient Machine Learning-Based Ozone Parameterization for Climate Sensitivity Simulations](https://arxiv.org/abs/2509.20422)
*Yiling Ma,Nathan Luke Abraham,Stefan Versick,Roland Ruhnke,Andrea Schneidereit,Ulrike Niemeier,Felix Back,Peter Braesicke,Peer Nowack*

Main category: cs.LG

TL;DR: 提出一种基于机器学习的臭氧参数化方法（mloz），可高效、高保真地在气候模型中模拟对流层和平流层臭氧的变率和趋势，且具有跨模型迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有气候模型因计算成本高缺乏交互式臭氧模块，限制了对臭氧-气候相互作用的准确模拟。

Method: 利用机器学习构建臭氧参数化模型mloz，仅以大气温度廓线为输入，在UKESM和ICON两种气候模型中实现在线耦合，并验证其跨模型迁移能力。

Result: mloz比UKESM中的化学机制快约31倍，运行开销低于4%，能稳定预测臭氧变化，并成功从UKESM转移到ICON模型，保持高保真度。

Conclusion: 该方法为CMIP级气候模型提供了一种高效、可移植的臭氧模拟方案，有助于提升气候敏感性模拟中反馈过程的准确性。

Abstract: Atmospheric ozone is a crucial absorber of solar radiation and an important
greenhouse gas. However, most climate models participating in the Coupled Model
Intercomparison Project (CMIP) still lack an interactive representation of
ozone due to the high computational costs of atmospheric chemistry schemes.
Here, we introduce a machine learning parameterization (mloz) to interactively
model daily ozone variability and trends across the troposphere and
stratosphere in standard climate sensitivity simulations, including two-way
interactions of ozone with the Quasi-Biennial Oscillation. We demonstrate its
high fidelity on decadal timescales and its flexible use online across two
different climate models -- the UK Earth System Model (UKESM) and the German
ICOsahedral Nonhydrostatic (ICON) model. With atmospheric temperature profile
information as the only input, mloz produces stable ozone predictions around 31
times faster than the chemistry scheme in UKESM, contributing less than 4
percent of the respective total climate model runtimes. In particular, we also
demonstrate its transferability to different climate models without chemistry
schemes by transferring the parameterization from UKESM to ICON. This
highlights the potential for widespread adoption in CMIP-level climate models
that lack interactive chemistry for future climate change assessments,
particularly when focusing on climate sensitivity simulations, where ozone
trends and variability are known to significantly modulate atmospheric feedback
processes.

</details>


### [208] [AbideGym: Turning Static RL Worlds into Adaptive Challenges](https://arxiv.org/abs/2509.21234)
*Abi Aryan,Zac Liu,Aaron Childress*

Main category: cs.LG

TL;DR: AbideGym是一个动态MiniGrid环境，通过引入智能体感知的扰动和可扩展的复杂性，促进智能体在单个episode内的适应能力，从而提升策略的鲁棒性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习智能体在环境动态变化时策略容易失效，且现有基准测试多为静态，难以评估智能体的适应能力。

Method: 提出AbideGym，作为MiniGrid的动态封装器，引入智能体感知的扰动机制和渐进式复杂度，支持模块化和可复现的评估。

Result: AbideGym能够有效暴露静态策略的脆弱性，推动智能体在课程学习、持续学习和鲁棒泛化方面的研究进展。

Conclusion: AbideGym提供了一个有效的框架，用于评估和提升强化学习智能体在动态环境中的适应能力和韧性。

Abstract: Agents trained with reinforcement learning often develop brittle policies
that fail when dynamics shift, a problem amplified by static benchmarks.
AbideGym, a dynamic MiniGrid wrapper, introduces agent-aware perturbations and
scalable complexity to enforce intra-episode adaptation. By exposing weaknesses
in static policies and promoting resilience, AbideGym provides a modular,
reproducible evaluation framework for advancing research in curriculum
learning, continual learning, and robust generalization.

</details>


### [209] [Bridging Privacy and Utility: Synthesizing anonymized EEG with constraining utility functions](https://arxiv.org/abs/2509.20454)
*Kay Fuhrmeister,Arne Pelzer,Fabian Radke,Julia Lechinger,Mahzad Gharleghi,Thomas Köllmer,Insa Wolf*

Main category: cs.LG

TL;DR: 提出一种基于Transformer的自编码器方法，用于生成无法进行用户重识别且保留机器学习任务效用的匿名化EEG数据。


<details>
  <summary>Details</summary>
Motivation: 随着消费级EEG设备的普及，EEG数据中的个人隐私（如用户重识别）风险日益增加，亟需在保护隐私的同时保持数据在机器学习应用中的可用性。

Method: 采用基于Transformer的自编码器对EEG数据进行匿名化处理，并在自动睡眠分期任务中评估处理前后数据的重识别风险和实用性。

Result: 实验结果表明，该方法能显著降低EEG信号的可重识别性，同时较好地保留其在睡眠分期等机器学习任务中的效用。

Conclusion: 所提出的匿名化方法在保护用户隐私和维持EEG数据实用性之间取得了良好平衡，适用于敏感脑电数据的安全共享与应用。

Abstract: Electroencephalography (EEG) is widely used for recording brain activity and
has seen numerous applications in machine learning, such as detecting sleep
stages and neurological disorders. Several studies have successfully shown the
potential of EEG data for re-identification and leakage of other personal
information. Therefore, the increasing availability of EEG consumer devices
raises concerns about user privacy, motivating us to investigate how to
safeguard this sensitive data while retaining its utility for EEG applications.
To address this challenge, we propose a transformer-based autoencoder to create
EEG data that does not allow for subject re-identification while still
retaining its utility for specific machine learning tasks. We apply our
approach to automatic sleep staging by evaluating the re-identification and
utility potential of EEG data before and after anonymization. The results show
that the re-identifiability of the EEG signal can be substantially reduced
while preserving its utility for machine learning.

</details>


### [210] [Efficiently Attacking Memorization Scores](https://arxiv.org/abs/2509.20463)
*Tue Do,Varun Chandrasekaran,Daniel Alabi*

Main category: cs.LG

TL;DR: 本文系统研究了基于记忆化的影响力估计器的可攻击性，提出了一种通过计算输入伪逆的实用攻击方法，可在黑盒条件下操纵记忆化分数，并在多种图像分类任务中验证了其有效性，揭示了影响估计在对抗扰动下的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 近年来，记忆化分数等影响力估计工具被广泛用于数据估值和负责任的机器学习，但这些分数是否可被对抗性操纵尚不明确，本文旨在探究此类攻击的可行性。

Method: 提出一种基于输入伪逆计算的攻击方法，仅需对模型输出进行黑盒访问，实现在高准确性模型下生成高度记忆化的样本以操控敏感查询，并结合理论分析探讨记忆化分数在对抗扰动下的稳定性。

Result: 实验表明，即使是最先进的记忆化代理指标也容易受到针对性分数操纵；理论分析揭示了影响估计在特定条件下固有的不稳定性。

Conclusion: 记忆化为基础的影响估计存在关键漏洞，易受对抗攻击，需开发更鲁棒的防御机制。

Abstract: Influence estimation tools -- such as memorization scores -- are widely used
to understand model behavior, attribute training data, and inform dataset
curation. However, recent applications in data valuation and responsible
machine learning raise the question: can these scores themselves be
adversarially manipulated? In this work, we present a systematic study of the
feasibility of attacking memorization-based influence estimators. We
characterize attacks for producing highly memorized samples as highly sensitive
queries in the regime where a trained algorithm is accurate. Our attack
(calculating the pseudoinverse of the input) is practical, requiring only
black-box access to model outputs and incur modest computational overhead. We
empirically validate our attack across a wide suite of image classification
tasks, showing that even state-of-the-art proxies are vulnerable to targeted
score manipulations. In addition, we provide a theoretical analysis of the
stability of memorization scores under adversarial perturbations, revealing
conditions under which influence estimates are inherently fragile. Our findings
highlight critical vulnerabilities in influence-based attribution and suggest
the need for robust defenses. All code can be found at
https://anonymous.4open.science/r/MemAttack-5413/

</details>


### [211] [Offline Goal-conditioned Reinforcement Learning with Quasimetric Representations](https://arxiv.org/abs/2509.20478)
*Vivek Myers,Bill Chunyuan Zheng,Benjamin Eysenbach,Sergey Levine*

Main category: cs.LG

TL;DR: 本文提出了一种统一对比表示和时序距离的新型目标条件强化学习（GCRL）方法，利用拟度量空间结构学习最优目标到达策略，即使在次优数据和随机环境中也表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有GCRL方法在处理次优离线数据和高维噪声环境时存在局限，需要一种能结合对比学习稳定性和拟度量网络路径拼接能力的新框架。

Method: 通过引入拟度量空间的三角不等式结构，并施加额外约束，学习具有最优目标到达距离的后继表示，从而统一对比表示与时间距离两种框架。

Result: 在离线GCRL基准测试中，该方法在对比学习方法难以应对的路径拼接任务以及拟度量网络表现不佳的高维噪声环境中均显著提升性能。

Conclusion: 所提方法融合了对比RL的稳定性和长视野优势与拟度量网络的自由拼接能力，实现了更鲁棒、高效的goal-reaching策略学习。

Abstract: Approaches for goal-conditioned reinforcement learning (GCRL) often use
learned state representations to extract goal-reaching policies. Two frameworks
for representation structure have yielded particularly effective GCRL
algorithms: (1) *contrastive representations*, in which methods learn
"successor features" with a contrastive objective that performs inference over
future outcomes, and (2) *temporal distances*, which link the (quasimetric)
distance in representation space to the transit time from states to goals. We
propose an approach that unifies these two frameworks, using the structure of a
quasimetric representation space (triangle inequality) with the right
additional constraints to learn successor representations that enable optimal
goal-reaching. Unlike past work, our approach is able to exploit a
**quasimetric** distance parameterization to learn **optimal** goal-reaching
distances, even with **suboptimal** data and in **stochastic** environments.
This gives us the best of both worlds: we retain the stability and long-horizon
capabilities of Monte Carlo contrastive RL methods, while getting the free
stitching capabilities of quasimetric network parameterizations. On existing
offline GCRL benchmarks, our representation learning objective improves
performance on stitching tasks where methods based on contrastive learning
struggle, and on noisy, high-dimensional environments where methods based on
quasimetric networks struggle.

</details>


### [212] [CoSupFormer : A Contrastive Supervised learning approach for EEG signal Classification](https://arxiv.org/abs/2509.20489)
*D. Darankoum,C. Habermacher,J. Volle,S. Grudinin*

Main category: cs.LG

TL;DR: 提出一种端到端深度学习框架，通过多尺度特征提取、注意力机制和门控网络，结合监督与对比学习损失函数，有效从原始脑电图信号中提取生物有意义模式，并在多种神经系统疾病诊断任务中实现强泛化性能。


<details>
  <summary>Details</summary>
Motivation: 脑电信号包含丰富的多尺度信息，但存在噪声和通道变异性，传统方法难以有效提取有意义特征，限制了其在疾病诊断和药物开发中的应用。

Method: 设计了一个能够显式捕捉多尺度频率振荡的编码器；引入基于注意力的编码器建模通道间及局部‘块’内依赖关系；集成门控网络动态过滤噪声和无信息通道；采用结合监督学习与对比学习的新型损失函数提升模型泛化能力。

Result: 在多种中枢神经系统疾病治疗效果分类及帕金森病、阿尔茨海默病诊断任务中验证，模型能自主选择高质量通道，提取出跨物种的生物可解释模式，并表现出优异的泛化性能。

Conclusion: 所提出的框架通过创新的架构设计和损失函数，有效解决了脑电信号分析中的噪声、通道变异性和特征提取难题，为基于脑电的疾病诊断和药物研发提供了可靠且通用的深度学习解决方案。

Abstract: Electroencephalography signals (EEGs) contain rich multi-scale information
crucial for understanding brain states, with potential applications in
diagnosing and advancing the drug development landscape. However, extracting
meaningful features from raw EEG signals while handling noise and channel
variability remains a major challenge. This work proposes a novel end-to-end
deep-learning framework that addresses these issues through several key
innovations. First, we designed an encoder capable of explicitly capturing
multi-scale frequency oscillations covering a wide range of features for
different EEG-related tasks. Secondly, to model complex dependencies and handle
the high temporal resolution of EEGs, we introduced an attention-based encoder
that simultaneously learns interactions across EEG channels and within
localized {\em patches} of individual channels. We integrated a dedicated
gating network on top of the attention encoder to dynamically filter out noisy
and non-informative channels, enhancing the reliability of EEG data. The entire
encoding process is guided by a novel loss function, which leverages supervised
and contrastive learning, significantly improving model generalization. We
validated our approach in multiple applications, ranging from the
classification of effects across multiple Central Nervous System (CNS)
disorders treatments to the diagnosis of Parkinson's and Alzheimer's disease.
Our results demonstrate that the proposed learning paradigm can extract
biologically meaningful patterns from raw EEG signals across different species,
autonomously select high-quality channels, and achieve robust generalization
through innovative architectural and loss design.

</details>


### [213] [Beyond Visual Similarity: Rule-Guided Multimodal Clustering with explicit domain rules](https://arxiv.org/abs/2509.20501)
*Kishor Datta Gupta,Mohd Ariful Haque,Marufa Kamal,Ahmed Rafi Hasan,Md. Mahfuzur Rahman,Roy George*

Main category: cs.LG

TL;DR: DARTVAE是一种将领域规则融入表示学习的多模态聚类框架，通过VAE结合显式规则、语义表示和数据特征，在损失函数中引入规则一致性与违规惩罚，生成更具可解释性和操作意义的聚类结果。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法仅依赖输入数据的相似性，难以捕捉对许多领域至关重要的结构或语义约束，因此需要一种能将领域知识直接整合到学习过程中的方法。

Method: 提出DARTVAE框架，扩展VAE架构，利用LLM生成规则并构建成知识图谱，将规则作为一等学习信号嵌入统一潜在空间，并在损失函数中结合重构误差、KL散度、规则一致性与违规惩罚进行优化。

Result: 在飞机和汽车数据集上的实验表明，DARTVAE相比传统方法能产生更符合操作需求且可解释的聚类结果（如分离无人机、合并隐形飞机、区分SUV与轿车），同时提升传统聚类指标；但面临LLM规则幻觉、规则冲突、过拟合及扩展性挑战。

Conclusion: 通过融合规则编码与学习表征，DARTVAE在复杂、知识密集型场景下实现了比纯数据驱动模型更有意义且一致的聚类效果，验证了约束引导的多模态聚类的有效性。

Abstract: Traditional clustering techniques often rely solely on similarity in the
input data, limiting their ability to capture structural or semantic
constraints that are critical in many domains. We introduce the Domain Aware
Rule Triggered Variational Autoencoder (DARTVAE), a rule guided multimodal
clustering framework that incorporates domain specific constraints directly
into the representation learning process. DARTVAE extends the VAE architecture
by embedding explicit rules, semantic representations, and data driven features
into a unified latent space, while enforcing constraint compliance through rule
consistency and violation penalties in the loss function. Unlike conventional
clustering methods that rely only on visual similarity or apply rules as post
hoc filters, DARTVAE treats rules as first class learning signals. The rules
are generated by LLMs, structured into knowledge graphs, and enforced through a
loss function combining reconstruction, KL divergence, consistency, and
violation penalties. Experiments on aircraft and automotive datasets
demonstrate that rule guided clustering produces more operationally meaningful
and interpretable clusters for example, isolating UAVs, unifying stealth
aircraft, or separating SUVs from sedans while improving traditional clustering
metrics. However, the framework faces challenges: LLM generated rules may
hallucinate or conflict, excessive rules risk overfitting, and scaling to
complex domains increases computational and consistency difficulties. By
combining rule encodings with learned representations, DARTVAE achieves more
meaningful and consistent clustering outcomes than purely data driven models,
highlighting the utility of constraint guided multimodal clustering for
complex, knowledge intensive settings.

</details>


### [214] [Myosotis: structured computation for attention like layer](https://arxiv.org/abs/2509.20503)
*Evgenii Egorov,Hanno Ackermann,Markus Nagel,Hong Cai*

Main category: cs.LG

TL;DR: 提出一种结合稀疏性和循环依赖优势的新算法，通过高效反转树结构矩阵来降低注意力机制的计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 注意力层的计算和内存消耗随序列长度呈二次增长，现有方法存在不足。

Method: 基于树结构矩阵的高效逆运算，结合稀疏性和循环依赖的思想。

Result: 实现了一种可扩展的注意力机制，在保持性能的同时降低了计算复杂度。

Conclusion: 该方法有效缓解了注意力机制中的二次扩展问题，兼具稀疏和循环方法的优点。

Abstract: Attention layers apply a sequence-to-sequence mapping whose parameters depend
on the pairwise interactions of the input elements. However, without any
structural assumptions, memory and compute scale quadratically with the
sequence length. The two main ways to mitigate this are to introduce sparsity
by ignoring a sufficient amount of pairwise interactions or to introduce
recurrent dependence along them, as SSM does. Although both approaches are
reasonable, they both have disadvantages. We propose a novel algorithm that
combines the advantages of both concepts. Our idea is based on the efficient
inversion of tree-structured matrices.

</details>


### [215] [Auto-Regressive U-Net for Full-Field Prediction of Shrinkage-Induced Damage in Concrete](https://arxiv.org/abs/2509.20507)
*Liya Gaynutdinova,Petr Havlásek,Ondřej Rokoš,Fleur Hendriks,Martin Doškář*

Main category: cs.LG

TL;DR: 提出了一种基于深度学习的双网络架构，用于预测混凝土中时变全场损伤演化及其力学性能。


<details>
  <summary>Details</summary>
Motivation: 传统全场损伤评估计算成本高，难以高效分析混凝土微观结构与宏观性能之间的关系，因此需要一种高效的预测方法。

Method: 采用自回归U-Net模型预测给定微观结构和收缩场下的标量损伤场演化，并将预测结果循环输入以实现连续预测；同时使用CNN根据损伤估计预测有效收缩和残余刚度等力学性能。

Result: 该双网络架构在合成数据集上表现出高计算效率和强预测性能，能有效揭示骨料形状、尺寸和分布对混凝土有效收缩和刚度退化的影响。

Conclusion: 该方法显著降低了传统模拟的计算负担，有助于优化混凝土配比设计，提升耐久性并减少内部损伤。

Abstract: This paper introduces a deep learning approach for predicting time-dependent
full-field damage in concrete. The study uses an auto-regressive U-Net model to
predict the evolution of the scalar damage field in a unit cell given
microstructural geometry and evolution of an imposed shrinkage profile. By
sequentially using the predicted damage output as input for subsequent
predictions, the model facilitates the continuous assessment of damage
progression. Complementarily, a convolutional neural network (CNN) utilises the
damage estimations to forecast key mechanical properties, including observed
shrinkage and residual stiffness. The proposed dual-network architecture
demonstrates high computational efficiency and robust predictive performance on
the synthesised datasets. The approach reduces the computational load
traditionally associated with full-field damage evaluations and is used to gain
insights into the relationship between aggregate properties, such as shape,
size, and distribution, and the effective shrinkage and reduction in stiffness.
Ultimately, this can help to optimize concrete mix designs, leading to improved
durability and reduced internal damage.

</details>


### [216] [Complexity-Driven Policy Optimization](https://arxiv.org/abs/2509.20509)
*Luca Serfilippi,Giorgio Franceschelli,Antonio Corradi,Mirco Musolesi*

Main category: cs.LG

TL;DR: 提出了一种新的策略优化方法CDPO，用复杂性正则化项替代传统的熵最大化，以促进具有结构且适应性强的探索策略。


<details>
  <summary>Details</summary>
Motivation: 传统策略梯度方法通过最大化熵来平衡利用与探索，但熵最大化导致策略趋向均匀随机分布，探索缺乏结构且效率较低。

Method: 引入基于香农熵与非均衡度（disequilibrium）乘积的复杂性度量作为正则项，替代原有的熵奖励；在PPO基础上提出复杂性驱动策略优化（CDPO）。

Result: 在多种离散动作空间任务中，CDPO对复杂性系数的选择比PPO对熵系数的选择更具鲁棒性，尤其在需要更强探索能力的环境中表现更优。

Conclusion: 复杂性正则化能有效抑制过度无序或完全有序的策略，推动智能体发现兼具结构性和适应性的非平凡行为，提升探索效率和训练稳定性。

Abstract: Policy gradient methods often balance exploitation and exploration via
entropy maximization. However, maximizing entropy pushes the policy towards a
uniform random distribution, which represents an unstructured and sometimes
inefficient exploration strategy. In this work, we propose replacing the
entropy bonus with a more robust complexity bonus. In particular, we adopt a
measure of complexity, defined as the product of Shannon entropy and
disequilibrium, where the latter quantifies the distance from the uniform
distribution. This regularizer encourages policies that balance stochasticity
(high entropy) with structure (high disequilibrium), guiding agents toward
regimes where useful, non-trivial behaviors can emerge. Such behaviors arise
because the regularizer suppresses both extremes, e.g., maximal disorder and
complete order, creating pressure for agents to discover structured yet
adaptable strategies. Starting from Proximal Policy Optimization (PPO), we
introduce Complexity-Driven Policy Optimization (CDPO), a new learning
algorithm that replaces entropy with complexity. We show empirically across a
range of discrete action space tasks that CDPO is more robust to the choice of
the complexity coefficient than PPO is with the entropy coefficient, especially
in environments requiring greater exploration.

</details>


### [217] [A Recovery Theory for Diffusion Priors: Deterministic Analysis of the Implicit Prior Algorithm](https://arxiv.org/abs/2509.20511)
*Oscar Leong,Yann Traonmilin*

Main category: cs.LG

TL;DR: 提出了一种基于确定性扩散模型的逆问题求解理论框架，将扩散先验算法解释为广义投影梯度下降，并在特定条件下给出了定量收敛速率和全局收敛保证。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成扩散模型的逆问题求解方法缺乏严格的恢复保证，需要建立理论框架以分析其性能。

Method: 通过分析噪声卷积得分作为低维模型集上的时变投影，将扩散先验算法视为广义投影梯度下降，并利用受限等距性质推导收敛速率。

Result: 在数据分布集中于低维模型集且测量矩阵满足受限等距条件时，获得了依赖于噪声调度的定量收敛率；对低秩高斯混合模型实现了非凸情况下的全局收敛。

Conclusion: 所提出的理论框架为基于扩散模型的逆问题求解算法提供了严谨的理论支持，揭示了其与投影梯度下降的联系，并展示了在合适条件下的良好收敛性。

Abstract: Recovering high-dimensional signals from corrupted measurements is a central
challenge in inverse problems. Recent advances in generative diffusion models
have shown remarkable empirical success in providing strong data-driven priors,
but rigorous recovery guarantees remain limited. In this work, we develop a
theoretical framework for analyzing deterministic diffusion-based algorithms
for inverse problems, focusing on a deterministic version of the algorithm
proposed by Kadkhodaie \& Simoncelli \cite{kadkhodaie2021stochastic}. First, we
show that when the underlying data distribution concentrates on a
low-dimensional model set, the associated noise-convolved scores can be
interpreted as time-varying projections onto such a set. This leads to
interpreting previous algorithms using diffusion priors for inverse problems as
generalized projected gradient descent methods with varying projections. When
the sensing matrix satisfies a restricted isometry property over the model set,
we can derive quantitative convergence rates that depend explicitly on the
noise schedule. We apply our framework to two instructive data distributions:
uniform distributions over low-dimensional compact, convex sets and low-rank
Gaussian mixture models. In the latter setting, we can establish global
convergence guarantees despite the nonconvexity of the underlying model set.

</details>


### [218] [MDBench: Benchmarking Data-Driven Methods for Model Discovery](https://arxiv.org/abs/2509.20529)
*Amirmohammad Ziaei Bideh,Aleksandra Georgievska,Jonathan Gryak*

Main category: cs.LG

TL;DR: MDBench是一个开源的基准测试框架，用于评估动态系统的模型发现方法，涵盖14个偏微分方程和63个常微分方程，并在不同噪声水平下测试12种算法。


<details>
  <summary>Details</summary>
Motivation: 现有的模型发现方法缺乏对动态系统建模的全面基准测试，尤其在多变量、复杂系统方面。为此，需要一个统一、可扩展的评估框架来推动该领域的发展。

Method: 提出MDBench框架，集成12种模型发现算法，在14个PDE和63个ODE上进行评估，引入7个来自流体力学和热力学的新挑战性PDE系统，采用导数预测精度、模型复杂度和方程保真度作为评价指标。

Result: 实验表明线性方法在PDE上预测误差最低，遗传编程方法在ODE上表现最佳，且线性模型对噪声更具鲁棒性。新提出的PDE系统揭示了现有方法的关键局限。

Conclusion: MDBench提供了一个严格且可扩展的基准平台，促进了模型发现方法在准确性与鲁棒性方面的系统性评估与改进。

Abstract: Model discovery aims to uncover governing differential equations of dynamical
systems directly from experimental data. Benchmarking such methods is essential
for tracking progress and understanding trade-offs in the field. While prior
efforts have focused mostly on identifying single equations, typically framed
as symbolic regression, there remains a lack of comprehensive benchmarks for
discovering dynamical models. To address this, we introduce MDBench, an
open-source benchmarking framework for evaluating model discovery methods on
dynamical systems. MDBench assesses 12 algorithms on 14 partial differential
equations (PDEs) and 63 ordinary differential equations (ODEs) under varying
levels of noise. Evaluation metrics include derivative prediction accuracy,
model complexity, and equation fidelity. We also introduce seven challenging
PDE systems from fluid dynamics and thermodynamics, revealing key limitations
in current methods. Our findings illustrate that linear methods and genetic
programming methods achieve the lowest prediction error for PDEs and ODEs,
respectively. Moreover, linear models are in general more robust against noise.
MDBench accelerates the advancement of model discovery methods by offering a
rigorous, extensible benchmarking framework and a rich, diverse collection of
dynamical system datasets, enabling systematic evaluation, comparison, and
improvement of equation accuracy and robustness.

</details>


### [219] [Understanding and Improving Adversarial Robustness of Neural Probabilistic Circuits](https://arxiv.org/abs/2509.20549)
*Weixin Chen,Han Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种新的鲁棒神经概率电路（RNPC），通过类间集成方法提升对抗攻击下的鲁棒性，理论与实验表明其在保持高准确率的同时显著增强抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 神经概率电路（NPC）虽具有可解释性和高性能，但其属性识别模块易受对抗攻击，存在安全隐患，需提升整体模型的鲁棒性。

Method: 提出RNPC模型，引入一种新的类间集成推理机制，结合属性识别模型和概率电路的输出，并从理论上证明其对抗鲁棒性优于传统NPC。

Result: 理论分析表明RNPC的鲁棒性仅依赖于改进后的识别模块，且实验结果显示其在图像分类任务中对抗攻击下表现更优，同时保持对正常输入的高准确性。

Conclusion: RNPC通过模块化设计和类间集成有效提升了对抗环境下的鲁棒性，是首个针对识别模块防御对抗攻击的神经概率电路框架。

Abstract: Neural Probabilistic Circuits (NPCs), a new class of concept bottleneck
models, comprise an attribute recognition model and a probabilistic circuit for
reasoning. By integrating the outputs from these two modules, NPCs produce
compositional and interpretable predictions. While offering enhanced
interpretability and high performance on downstream tasks, the
neural-network-based attribute recognition model remains a black box. This
vulnerability allows adversarial attacks to manipulate attribute predictions by
introducing carefully crafted subtle perturbations to input images, potentially
compromising the final predictions. In this paper, we theoretically analyze the
adversarial robustness of NPC and demonstrate that it only depends on the
robustness of the attribute recognition model and is independent of the
robustness of the probabilistic circuit. Moreover, we propose RNPC, the first
robust neural probabilistic circuit against adversarial attacks on the
recognition module. RNPC introduces a novel class-wise integration for
inference, ensuring a robust combination of outputs from the two modules. Our
theoretical analysis demonstrates that RNPC exhibits provably improved
adversarial robustness compared to NPC. Empirical results on image
classification tasks show that RNPC achieves superior adversarial robustness
compared to existing concept bottleneck models while maintaining high accuracy
on benign inputs.

</details>


### [220] [Generalizable Diabetes Risk Stratification via Hybrid Machine Learning Models](https://arxiv.org/abs/2509.20565)
*Athar Parvez,Muhammad Jawad Mufti*

Main category: cs.LG

TL;DR: 本研究比较了两种混合分类器（XGBoost+随机森林和SVM+逻辑回归）在糖尿病风险分层中的表现，发现XGB-RF在内部和外部队列中均表现更优，具有良好的泛化能力和校准性能，支持其作为可迁移的糖尿病风险预测工具。


<details>
  <summary>Details</summary>
Motivation: 糖尿病全球患病人数众多且持续增长，早期风险分层对临床管理至关重要。机器学习有望提升预测性能，但模型的泛化能力需验证。因此，研究旨在比较两种混合模型的性能及其在外部队列中的可转移性。

Method: 构建了两种混合分类器：XGBoost+随机森林（XGB-RF）和SVM+逻辑回归（SVM-LR）。采用防数据泄露的标准流程（编码、填补、归一化、仅在训练折上使用SMOTE、概率校准），在主数据集上训练后冻结模型，在PIMA外部队列上进行外部验证，并在默认阈值0.5下计算有阈值指标。

Result: 在主数据集上，XGB-RF的AUROC约为0.995，AUPRC约为0.998，优于SVM-LR（AUROC约0.978，AUPRC约0.947）。在PIMA队列上，XGB-RF仍保持高性能（AUROC约0.990，AUPRC约0.959），而SVM-LR表现较低（AUROC约0.963，AUPRC约0.875）。在tau=0.5时，XGB-RF的准确率、精确率、召回率和F1均显著高于SVM-LR。

Conclusion: XGB-RF在内部和外部验证中均优于SVM-LR，性能衰减更小且校准良好，表明基于梯度提升的混合模型具有强健性和可迁移性，适用于糖尿病风险分层，建议开展多中心前瞻性验证，并根据临床需求选择部署时的决策阈值。

Abstract: Background/Purpose: Diabetes affects over 537 million people worldwide and is
projected to reach 783 million by 2045. Early risk stratification can benefit
from machine learning. We compare two hybrid classifiers and assess their
generalizability on an external cohort.
  Methods: Two hybrids were built: (i) XGBoost + Random Forest (XGB-RF) and
(ii) Support Vector Machine + Logistic Regression (SVM-LR). A leakage-safe,
standardized pipeline (encoding, imputation, min-max scaling; SMOTE on training
folds only; probability calibration for SVM) was fit on the primary dataset and
frozen. Evaluation prioritized threshold-independent discrimination
(AUROC/AUPRC) and calibration (Brier, slope/intercept). External validation
used the PIMA cohort (N=768) with the frozen pipeline; any thresholded metrics
on PIMA were computed at the default rule tau = 0.5.
  Results: On the primary dataset (PR baseline = 0.50), XGB-RF achieved AUROC
~0.995 and AUPRC ~0.998, outperforming SVM-LR (AUROC ~0.978; AUPRC ~0.947). On
PIMA (PR baseline ~0.349), XGB-RF retained strong performance (AUROC ~0.990;
AUPRC ~0.959); SVM-LR was lower (AUROC ~0.963; AUPRC ~0.875). Thresholded
metrics on PIMA at tau = 0.5 were XGB-RF (Accuracy 0.960; Precision 0.941;
Recall 0.944; F1 0.942) and SVM-LR (Accuracy 0.900; Precision 0.855; Recall
0.858; F1 0.857).
  Conclusions: Across internal and external cohorts, XGB-RF consistently
dominated SVM-LR and exhibited smaller external attenuation on ROC/PR with
acceptable calibration. These results support gradient-boosting-based
hybridization as a robust, transferable approach for diabetes risk
stratification and motivate prospective, multi-site validation with
deployment-time threshold selection based on clinical trade-offs.

</details>


### [221] [PIRF: Physics-Informed Reward Fine-Tuning for Diffusion Models](https://arxiv.org/abs/2509.20570)
*Mingze Yuan,Pengfei Jin,Na Li,Quanzheng Li*

Main category: cs.LG

TL;DR: 提出物理信息奖励微调（PIRF）方法，通过直接优化轨迹级奖励来提升扩散模型在科学生成中的物理一致性，避免传统值函数近似带来的误差和不稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在科学生成中常违反物理规律，且依赖DPS类方法存在误差大、训练不稳定、推理效率低的问题。

Method: 将物理约束满足视为稀疏奖励信号，采用无需值函数逼近的轨迹级奖励直接回传梯度，并结合层级截断反向传播和基于权重的正则化策略提升效率与保真度。

Result: 在五个PDE基准上，PIRF在高效采样条件下均实现了更优的物理约束满足性能。

Conclusion: PIRF为物理信息生成提供了一种高效稳定的奖励微调范式，推动了科学生成建模的发展。

Abstract: Diffusion models have demonstrated strong generative capabilities across
scientific domains, but often produce outputs that violate physical laws. We
propose a new perspective by framing physics-informed generation as a sparse
reward optimization problem, where adherence to physical constraints is treated
as a reward signal. This formulation unifies prior approaches under a
reward-based paradigm and reveals a shared bottleneck: reliance on diffusion
posterior sampling (DPS)-style value function approximations, which introduce
non-negligible errors and lead to training instability and inference
inefficiency. To overcome this, we introduce Physics-Informed Reward
Fine-tuning (PIRF), a method that bypasses value approximation by computing
trajectory-level rewards and backpropagating their gradients directly. However,
a naive implementation suffers from low sample efficiency and compromised data
fidelity. PIRF mitigates these issues through two key strategies: (1) a
layer-wise truncated backpropagation method that leverages the spatiotemporally
localized nature of physics-based rewards, and (2) a weight-based
regularization scheme that improves efficiency over traditional
distillation-based methods. Across five PDE benchmarks, PIRF consistently
achieves superior physical enforcement under efficient sampling regimes,
highlighting the potential of reward fine-tuning for advancing scientific
generative modeling.

</details>


### [222] [The Sensitivity of Variational Bayesian Neural Network Performance to Hyperparameters](https://arxiv.org/abs/2509.20574)
*Scott Koermer,Natalie Klein*

Main category: cs.LG

TL;DR: 本文研究了贝叶斯神经网络（BNN）中超参数选择对预测准确性和不确定性量化（UQ）的影响，发现多个超参数之间存在交互作用，并建议使用全局敏感性分析或贝叶斯优化等方法来优化超参数选择，以提高BNN在实际应用中的UQ准确性。


<details>
  <summary>Details</summary>
Motivation: 由于实际训练中使用的近似方法和超参数选择困难，BNN在实践中难以获得准确的不确定性量化，因此需要系统分析超参数的影响。

Method: 通过全局敏感性分析，评估不同超参数设置下BNN性能的变化，分析各超参数对预测准确性和不确定性量化的影响及其相互作用。

Result: 发现许多超参数之间存在显著交互效应，共同影响BNN的预测性能和不确定性量化质量。

Conclusion: 为确保BNN在实际科学应用中提供可靠的不确定性量化，应采用全局敏感性分析或类似方法辅助超参数的选择与降维。

Abstract: In scientific applications, predictive modeling is often of limited use
without accurate uncertainty quantification (UQ) to indicate when a model may
be extrapolating or when more data needs to be collected. Bayesian Neural
Networks (BNNs) produce predictive uncertainty by propagating uncertainty in
neural network (NN) weights and offer the promise of obtaining not only an
accurate predictive model but also accurate UQ. However, in practice, obtaining
accurate UQ with BNNs is difficult due in part to the approximations used for
practical model training and in part to the need to choose a suitable set of
hyperparameters; these hyperparameters outnumber those needed for traditional
NNs and often have opaque effects on the results. We aim to shed light on the
effects of hyperparameter choices for BNNs by performing a global sensitivity
analysis of BNN performance under varying hyperparameter settings. Our results
indicate that many of the hyperparameters interact with each other to affect
both predictive accuracy and UQ. For improved usage of BNNs in real-world
applications, we suggest that global sensitivity analysis, or related methods
such as Bayesian optimization, should be used to aid in dimensionality
reduction and selection of hyperparameters to ensure accurate UQ in BNNs.

</details>


### [223] [Learning Greens Operators through Hierarchical Neural Networks Inspired by the Fast Multipole Method](https://arxiv.org/abs/2509.20591)
*Emilio McAllister Fognini,Marta M. Betcke,Ben T. Cox*

Main category: cs.LG

TL;DR: 提出了一种新的神经网络架构Neural FMM，将快速多极子方法（FMM）的信息流集成到分层机器学习框架中，用于学习椭圆型偏微分方程的格林算子。


<details>
  <summary>Details</summary>
Motivation: 尽管FMM在物理和工程中广泛应用，但其与现代机器学习架构的结合尚未被充分探索，因此本文旨在填补这一空白。

Method: 设计了Neural FMM架构，利用FMM的分层计算流程，分离局部和远场相互作用，并高效学习其各自表示。

Result: 成功构建了一个能够学习椭圆型PDE格林算子的分层神经网络模型。

Conclusion: Neural FMM为将传统数值算法与深度学习相结合提供了新途径，具有在科学计算中的潜在应用价值。

Abstract: The Fast Multipole Method (FMM) is an efficient numerical algorithm for
computation of long-ranged forces in $N$-body problems within gravitational and
electrostatic fields. This method utilizes multipole expansions of the Green's
function inherent to the underlying dynamical systems. Despite its widespread
application in physics and engineering, the integration of FMM with modern
machine learning architectures remains underexplored. In this work, we propose
a novel neural network architecture, the Neural FMM, that integrates the
information flow of the FMM into a hierarchical machine learning framework for
learning the Green's operator of an Elliptic PDE. Our Neural FMM architecture
leverages a hierarchical computation flow of the FMM method to split up the
local and far-field interactions and efficiently learn their respective
representations.

</details>


### [224] [TSKAN: Interpretable Machine Learning for QoE modeling over Time Series Data](https://arxiv.org/abs/2509.20595)
*Kamal Singh,Priyanka Rawat,Sami Marouani,Baptiste Jeudy*

Main category: cs.LG

TL;DR: 提出一种基于可解释机器学习的视频流QoE建模方法，结合Kolmogorov-Arnold网络与频域特征，提升预测准确性与模型透明度。


<details>
  <summary>Details</summary>
Motivation: 传统黑箱模型难以解释视频流中用户体验（QoE）与特征间复杂关系，需构建兼具准确性与可解释性的模型。

Method: 采用Kolmogorov-Arnold网络（KANs）作为可解释读出层，结合紧凑频域特征处理原始时间序列数据，捕捉时序信息并保持模型透明。

Result: 在主流数据集上验证了该方法在QoE预测中的更高准确性，同时提供了良好的模型可解释性。

Conclusion: 所提方法在保持模型可解释性的同时，显著提升了视频流QoE预测性能，适用于优化流媒体服务质量。

Abstract: Quality of Experience (QoE) modeling is crucial for optimizing video
streaming services to capture the complex relationships between different
features and user experience. We propose a novel approach to QoE modeling in
video streaming applications using interpretable Machine Learning (ML)
techniques over raw time series data. Unlike traditional black-box approaches,
our method combines Kolmogorov-Arnold Networks (KANs) as an interpretable
readout on top of compact frequency-domain features, allowing us to capture
temporal information while retaining a transparent and explainable model. We
evaluate our method on popular datasets and demonstrate its enhanced accuracy
in QoE prediction, while offering transparency and interpretability.

</details>


### [225] [Explicit and Effectively Symmetric Schemes for Neural SDEs](https://arxiv.org/abs/2509.20599)
*Daniil Shmelev,Cristopher Salvi*

Main category: cs.LG

TL;DR: 提出了一类新的稳定且近可逆的Runge-Kutta格式（EES方案），用于神经SDE，兼顾内存效率和梯度精度，克服了现有可逆求解器在复杂模型和大步长下的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 传统神经SDE求解器在反向传播中面临内存消耗高或梯度不准的问题，而现有可逆方法如Reversible Heun在大步长或复杂模型下不稳定，亟需更稳定的高效训练方法。

Method: 设计了一类显式且有效对称（EES）的Runge-Kutta格式，结合代数可逆性与数值稳定性，在保持低内存消耗的同时提升梯度计算的准确性和稳定性。

Result: 数值实验表明，EES方案在稳定性、可靠性和内存效率方面优于现有方法，适用于大规模、高精度的神经SDE训练。

Conclusion: EES方案为神经SDE提供了一种实用、可扩展且准确的训练基础，解决了现有方法在稳定性与效率之间的权衡问题。

Abstract: Backpropagation through (neural) SDE solvers is traditionally approached in
two ways: discretise-then-optimise, which offers accurate gradients but incurs
prohibitive memory costs due to storing the full computational graph (even when
mitigated by checkpointing); and optimise-then-discretise, which achieves
constant memory cost by solving an auxiliary backward SDE, but suffers from
slower evaluation and gradient approximation errors. Algebraically reversible
solvers promise both memory efficiency and gradient accuracy, yet existing
methods such as the Reversible Heun scheme are often unstable under complex
models and large step sizes. We address these limitations by introducing a
novel class of stable, near-reversible Runge--Kutta schemes for neural SDEs.
These Explicit and Effectively Symmetric (EES) schemes retain the benefits of
reversible solvers while overcoming their instability, enabling
memory-efficient training without severe restrictions on step size or model
complexity. Through numerical experiments, we demonstrate the superior
stability and reliability of our schemes, establishing them as a practical
foundation for scalable and accurate training of neural SDEs.

</details>


### [226] [Function Spaces Without Kernels: Learning Compact Hilbert Space Representations](https://arxiv.org/abs/2509.20605)
*Su Ann Low,Quentin Rommel,Kevin S. Miller,Adam J. Thorpe,Ufuk Topcu*

Main category: cs.LG

TL;DR: 本文提出函数编码器通过学习神经网络基函数来构建紧凑且自适应的函数空间表示，并从核方法角度解释其原理，提出了两种训练算法，在保证精度的同时显著减少基函数数量，实现了可扩展且有理论保证的神经预测模型。


<details>
  <summary>Details</summary>
Motivation: 希望将函数编码器与特征学习和核方法建立理论联系，解释其可扩展性和对数据内在结构的适应性，并为神经模型提供核方法风格的分析工具。

Method: 通过定义学习特征映射内积对应的核函数，建立函数编码器与核方法的联系；基于PCA思想设计了渐进式增长基的训练方法和先训练后剪枝的方法；利用Rademacher复杂度和PAC-Bayes技术推导有限样本下的泛化误差界。

Result: 在多项式基准（已知内在维度）以及非线性动力系统（如Van der Pol振子和二体轨道模型）上验证了方法的有效性，结果表明用更少的基函数即可达到相同精度，并获得了推理阶段的泛化保证。

Conclusion: 函数编码器为神经网络提供了类似核方法的理论保障，所提方法能在保持高效性的同时自适应捕捉数据内在结构，为可扩展、有原则的神经预测模型提供了新路径。

Abstract: Function encoders are a recent technique that learn neural network basis
functions to form compact, adaptive representations of Hilbert spaces of
functions. We show that function encoders provide a principled connection to
feature learning and kernel methods by defining a kernel through an inner
product of the learned feature map. This kernel-theoretic perspective explains
their ability to scale independently of dataset size while adapting to the
intrinsic structure of data, and it enables kernel-style analysis of neural
models. Building on this foundation, we develop two training algorithms that
learn compact bases: a progressive training approach that constructively grows
bases, and a train-then-prune approach that offers a computationally efficient
alternative after training. Both approaches use principles from PCA to reveal
the intrinsic dimension of the learned space. In parallel, we derive
finite-sample generalization bounds using Rademacher complexity and PAC-Bayes
techniques, providing inference time guarantees. We validate our approach on a
polynomial benchmark with a known intrinsic dimension, and on nonlinear
dynamical systems including a Van der Pol oscillator and a two-body orbital
model, demonstrating that the same accuracy can be achieved with substantially
fewer basis functions. This work suggests a path toward neural predictors with
kernel-level guarantees, enabling adaptable models that are both efficient and
principled at scale.

</details>


### [227] [MMG: Mutual Information Estimation via the MMSE Gap in Diffusion](https://arxiv.org/abs/2509.20609)
*Longxuan Yu,Xing Shi,Xianghao Kong,Tong Jia,Greg Ver Steeg*

Main category: cs.LG

TL;DR: 本文提出了一种基于去噪扩散模型的互信息（MI）估计新方法，通过最小均方误差（MMSE）在条件与无条件扩散之间的差距来计算MI，并结合自适应重要性采样实现高效且可扩展的估计。


<details>
  <summary>Details</summary>
Motivation: 互信息是衡量随机变量关系的重要工具，但复杂系统中的MI估计具有挑战性；现有方法在高MI或复杂分布下表现不佳，因此需要更强大的估计方法。

Method: 利用去噪扩散模型的信息论表述，将MI表示为所有信噪比下条件与无条件扩散MMSE差异的一半积分，并采用自适应重要性采样进行优化估计。

Result: 该方法在自洽性测试中表现良好，优于传统及基于得分的扩散MI估计器，能够在高MI情况下保持强性能并实现可扩展估计。

Conclusion: 去噪扩散模型为MI估计提供了有效框架，所提方法在准确性、鲁棒性和可扩展性方面均表现出优势，有望成为MI估计的新基准。

Abstract: Mutual information (MI) is one of the most general ways to measure
relationships between random variables, but estimating this quantity for
complex systems is challenging. Denoising diffusion models have recently set a
new bar for density estimation, so it is natural to consider whether these
methods could also be used to improve MI estimation. Using the recently
introduced information-theoretic formulation of denoising diffusion models, we
show the diffusion models can be used in a straightforward way to estimate MI.
In particular, the MI corresponds to half the gap in the Minimum Mean Square
Error (MMSE) between conditional and unconditional diffusion, integrated over
all Signal-to-Noise-Ratios (SNRs) in the noising process. Our approach not only
passes self-consistency tests but also outperforms traditional and score-based
diffusion MI estimators. Furthermore, our method leverages adaptive importance
sampling to achieve scalable MI estimation, while maintaining strong
performance even when the MI is high.

</details>


### [228] [Policy Compatible Skill Incremental Learning via Lazy Learning Interface](https://arxiv.org/abs/2509.20612)
*Daehee Lee,Dongsu Lee,TaeYoon Kwack,Wonje Choi,Honguk Woo*

Main category: cs.LG

TL;DR: 本文提出了SIL-C框架，通过双侧懒惰学习映射技术动态对齐子任务空间与技能空间，确保增量学习过程中技能与下游策略的兼容性，无需重新训练策略即可提升性能。


<details>
  <summary>Details</summary>
Motivation: 在技能增量学习中，随着技能库的演化，可能破坏与现有策略的兼容性，限制策略的重用和泛化能力。因此需要一种保持兼容性的机制。

Method: 提出SIL-C框架，采用双侧懒惰学习方法，基于轨迹分布相似性动态匹配子任务与技能，实现技能与策略间的兼容而无需重新训练。

Result: 在多种技能增量学习场景中验证了SIL-C的有效性，结果表明其能维持技能与下游策略之间的兼容性，并保证学习过程的高效性。

Conclusion: SIL-C能够在不需策略重训练的情况下，有效支持增量技能学习并提升下游任务性能，增强了技能重用性和系统可扩展性。

Abstract: Skill Incremental Learning (SIL) is the process by which an embodied agent
expands and refines its skill set over time by leveraging experience gained
through interaction with its environment or by the integration of additional
data. SIL facilitates efficient acquisition of hierarchical policies grounded
in reusable skills for downstream tasks. However, as the skill repertoire
evolves, it can disrupt compatibility with existing skill-based policies,
limiting their reusability and generalization. In this work, we propose SIL-C,
a novel framework that ensures skill-policy compatibility, allowing
improvements in incrementally learned skills to enhance the performance of
downstream policies without requiring policy re-training or structural
adaptation. SIL-C employs a bilateral lazy learning-based mapping technique to
dynamically align the subtask space referenced by policies with the skill space
decoded into agent behaviors. This enables each subtask, derived from the
policy's decomposition of a complex task, to be executed by selecting an
appropriate skill based on trajectory distribution similarity. We evaluate
SIL-C across diverse SIL scenarios and demonstrate that it maintains
compatibility between evolving skills and downstream policies while ensuring
efficiency throughout the learning process.

</details>


### [229] [Latent Twins](https://arxiv.org/abs/2509.20615)
*Matthias Chung,Deepanshu Verma,Max Collins,Amit N. Subrahmanya,Varuni Katti Sastry,Vishwas Rao*

Main category: cs.LG

TL;DR: 本文提出了一个名为“Latent Twins”的统一数学框架，通过在隐空间中构建底层方程的代理模型，将经典建模、逆问题、模型降维和算子逼近统一起来，并在ODE、PDE及真实地球物理数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习的发展多呈分散并行，表征学习与求解算法常作为独立流程发展，缺乏统一框架；因此需要一种能够整合多种建模任务的通用方法。

Method: 提出Latent Twins框架，在隐空间中构建数学系统的镜像代理，利用学习到的算子进行动态系统建模，支持单步任意时间间隔推演，并与传统科学计算流程兼容。

Result: 在典型ODE、浅水方程PDE基准以及稀疏噪声下的真实再分析数据上均表现出良好性能，相较于DeepONet和4D-Var具有更优的模拟与预测能力，同时提供紧凑且可解释的解算子代理。

Conclusion: Latent Twins为数据驱动表示学习与经典科学建模之间提供了可扩展、理论支撑的桥梁，有望成为跨学科科学机器学习的通用框架。

Abstract: Over the past decade, scientific machine learning has transformed the
development of mathematical and computational frameworks for analyzing,
modeling, and predicting complex systems. From inverse problems to numerical
PDEs, dynamical systems, and model reduction, these advances have pushed the
boundaries of what can be simulated. Yet they have often progressed in
parallel, with representation learning and algorithmic solution methods
evolving largely as separate pipelines. With \emph{Latent Twins}, we propose a
unifying mathematical framework that creates a hidden surrogate in latent space
for the underlying equations. Whereas digital twins mirror physical systems in
the digital world, Latent Twins mirror mathematical systems in a learned latent
space governed by operators. Through this lens, classical modeling, inversion,
model reduction, and operator approximation all emerge as special cases of a
single principle. We establish the fundamental approximation properties of
Latent Twins for both ODEs and PDEs and demonstrate the framework across three
representative settings: (i) canonical ODEs, capturing diverse dynamical
regimes; (ii) a PDE benchmark using the shallow-water equations, contrasting
Latent Twin simulations with DeepONet and forecasts with a 4D-Var baseline; and
(iii) a challenging real-data geopotential reanalysis dataset, reconstructing
and forecasting from sparse, noisy observations. Latent Twins provide a
compact, interpretable surrogate for solution operators that evaluate across
arbitrary time gaps in a single-shot, while remaining compatible with
scientific pipelines such as assimilation, control, and uncertainty
quantification. Looking forward, this framework offers scalable,
theory-grounded surrogates that bridge data-driven representation learning and
classical scientific modeling across disciplines.

</details>


### [230] [Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning](https://arxiv.org/abs/2509.20616)
*Hanjiang Hu,Changliu Liu,Na Li,Yebin Wang*

Main category: cs.LG

TL;DR: 本文提出了一种将多轮任务规划转化为单轮任务推理的方法，利用组相对策略优化（GRPO）实现高效策略学习，在复杂任务规划中表现出色，并具备良好的跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 训练用于复杂多轮任务规划的LLM智能体面临稀疏奖励、长期信用分配和计算开销大等挑战，需要更高效的训练方法。

Method: 将多轮任务规划转换为单轮任务推理问题，采用基于专家轨迹提供密集且可验证奖励的组相对策略优化（GRPO）进行策略训练。

Result: 在复杂任务规划基准上，1.5B参数的模型通过单轮GRPO训练达到了70%的成功率（超过30步的长视野任务），优于高达14B参数的基线模型，并验证了对简单子任务的良好泛化能力。

Conclusion: 单轮GRPO能有效提升多轮任务成功率，减少训练开销，并具备向短视野子任务迁移的能力，为LLM智能体的高效训练提供了新思路。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
knowledge acquisition, reasoning, and tool use, making them promising
candidates for autonomous agent applications. However, training LLM agents for
complex multi-turn task planning faces significant challenges, including sparse
episode-wise rewards, credit assignment across long horizons, and the
computational overhead of reinforcement learning in multi-turn interaction
settings. To this end, this paper introduces a novel approach that transforms
multi-turn task planning into single-turn task reasoning problems, enabling
efficient policy optimization through Group Relative Policy Optimization (GRPO)
with dense and verifiable reward from expert trajectories. Our theoretical
analysis shows that GRPO improvement on single-turn task reasoning results in
higher multi-turn success probability under the minimal turns, as well as the
generalization to subtasks with shorter horizons. Experimental evaluation on
the complex task planning benchmark demonstrates that our 1.5B parameter model
trained with single-turn GRPO achieves superior performance compared to larger
baseline models up to 14B parameters, with success rates of 70% for
long-horizon planning tasks with over 30 steps. We also theoretically and
empirically validate the strong cross-task generalizability that the models
trained on complex tasks can lead to the successful completion of all simpler
subtasks.

</details>


### [231] [Personalized Federated Dictionary Learning for Modeling Heterogeneity in Multi-site fMRI Data](https://arxiv.org/abs/2509.20627)
*Yipu Zhang,Chengshuo Zhang,Ziyu Zhou,Gang Qu,Hao Zheng,Yuping Wang,Hui Shen,Hongwen Deng*

Main category: cs.LG

TL;DR: 提出了一种名为PFedDL的个性化联邦字典学习框架，用于在不共享原始数据的情况下进行多站点fMRI研究中的协作建模，有效应对数据隐私和非IID数据分布挑战。


<details>
  <summary>Details</summary>
Motivation: 由于数据隐私限制和多站点fMRI研究中站点特异性异质性导致的非IID数据问题，难以构建可泛化的神经影像分析模型。

Method: PFedDL在每个站点独立进行字典学习，将站点特定字典分解为共享的全局成分和个性化的本地成分；通过联邦聚合更新全局原子以保持跨站点一致性，同时独立优化本地原子以捕捉站点特异性变异。

Result: 在ABIDE数据集上的实验表明，PFedDL在非IID数据集上相比现有方法具有更高的准确性和鲁棒性。

Conclusion: PFedDL能有效平衡模型的泛化能力与对站点特异性差异的适应性，为保护数据隐私的大规模神经影像分析提供了可行方案。

Abstract: Data privacy constraints pose significant challenges for large-scale
neuroimaging analysis, especially in multi-site functional magnetic resonance
imaging (fMRI) studies, where site-specific heterogeneity leads to
non-independent and identically distributed (non-IID) data. These factors
hinder the development of generalizable models. To address these challenges, we
propose Personalized Federated Dictionary Learning (PFedDL), a novel federated
learning framework that enables collaborative modeling across sites without
sharing raw data. PFedDL performs independent dictionary learning at each site,
decomposing each site-specific dictionary into a shared global component and a
personalized local component. The global atoms are updated via federated
aggregation to promote cross-site consistency, while the local atoms are
refined independently to capture site-specific variability, thereby enhancing
downstream analysis. Experiments on the ABIDE dataset demonstrate that PFedDL
outperforms existing methods in accuracy and robustness across non-IID
datasets.

</details>


### [232] [Investigating Modality Contribution in Audio LLMs for Music](https://arxiv.org/abs/2509.20641)
*Giovana Morais,Magdalena Fuentes*

Main category: cs.LG

TL;DR: 本研究通过改进的MM-SHAP框架量化音频和文本模态在音频大语言模型中的贡献，发现高准确率模型更依赖文本，但模型仍能定位关键声音事件，表明音频未被完全忽略。


<details>
  <summary>Details</summary>
Motivation: 探讨音频大语言模型在音乐对话中是否真正‘听’懂音频，还是仅依赖文本推理。

Method: 采用基于Shapley值的MM-SHAP框架，评估两种模型在MuChoMusic基准上的模态贡献。

Result: 高准确率模型更依赖文本输入，但即使音频贡献整体较低，模型仍能成功定位关键声音事件。

Conclusion: 这是MM-SHAP首次应用于音频大语言模型，揭示了多模态贡献的复杂性，为可解释AI与音频研究提供了基础。

Abstract: Audio Large Language Models (Audio LLMs) enable human-like conversation about
music, yet it is unclear if they are truly listening to the audio or just using
textual reasoning, as recent benchmarks suggest. This paper investigates this
issue by quantifying the contribution of each modality to a model's output. We
adapt the MM-SHAP framework, a performance-agnostic score based on Shapley
values that quantifies the relative contribution of each modality to a model's
prediction. We evaluate two models on the MuChoMusic benchmark and find that
the model with higher accuracy relies more on text to answer questions, but
further inspection shows that even if the overall audio contribution is low,
models can successfully localize key sound events, suggesting that audio is not
entirely ignored. Our study is the first application of MM-SHAP to Audio LLMs
and we hope it will serve as a foundational step for future research in
explainable AI and audio.

</details>


### [233] [Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration](https://arxiv.org/abs/2509.20648)
*Yiyuan Pan,Zhe Liu,Hesheng Wang*

Main category: cs.LG

TL;DR: 提出CERMIC框架，通过结合多智能体上下文动态校准内在好奇心，提升稀疏奖励环境下的自主探索效率。


<details>
  <summary>Details</summary>
Motivation: 现有好奇心机制难以区分环境随机性和有意义的新颖性，且忽略同伴行为中蕴含的任务动态，导致多智能体探索效果不佳。

Method: 受儿童通过观察同伴调整探索行为的启发，CERMIC利用推断的多智能体上下文动态校准内在好奇心，并生成基于信息增益的理论支持的内在奖励。

Result: 在VMAS、Meltingpot和SMACv2等基准上验证，CERMIC在稀疏奖励环境中显著优于当前最先进算法。

Conclusion: CERMIC能有效过滤噪声惊喜信号，引导智能体关注高信息增益的状态转移，显著提升无通信多智能体系统的探索性能。

Abstract: Autonomous exploration in complex multi-agent reinforcement learning (MARL)
with sparse rewards critically depends on providing agents with effective
intrinsic motivation. While artificial curiosity offers a powerful
self-supervised signal, it often confuses environmental stochasticity with
meaningful novelty. Moreover, existing curiosity mechanisms exhibit a uniform
novelty bias, treating all unexpected observations equally. However, peer
behavior novelty, which encode latent task dynamics, are often overlooked,
resulting in suboptimal exploration in decentralized, communication-free MARL
settings. To this end, inspired by how human children adaptively calibrate
their own exploratory behaviors via observing peers, we propose a novel
approach to enhance multi-agent exploration. We introduce CERMIC, a principled
framework that empowers agents to robustly filter noisy surprise signals and
guide exploration by dynamically calibrating their intrinsic curiosity with
inferred multi-agent context. Additionally, CERMIC generates
theoretically-grounded intrinsic rewards, encouraging agents to explore state
transitions with high information gain. We evaluate CERMIC on benchmark suites
including VMAS, Meltingpot, and SMACv2. Empirical results demonstrate that
exploration with CERMIC significantly outperforms SoTA algorithms in
sparse-reward environments.

</details>


### [234] [Guiding Application Users via Estimation of Computational Resources for Massively Parallel Chemistry Computations](https://arxiv.org/abs/2509.20667)
*Tanzila Tabassum,Omer Subasi,Ajay Panyala,Epiya Ebiapia,Gerald Baumgartner,Erdal Mutlu,P.,Sadayappan,Karol Kowalski*

Main category: cs.LG

TL;DR: 本文提出基于机器学习的方法预测大规模并行化学计算（如CCSD）的资源需求，以优化执行时间和成本。


<details>
  <summary>Details</summary>
Motivation: 帮助用户在运行昂贵的超算实验前，预测所需资源并选择最优参数配置。

Method: 采用梯度提升（GB）等机器学习模型，结合主动学习策略，基于Frontier和Aurora超算上的CCSD运行数据进行训练和预测。

Result: GB模型在预测执行时间时取得0.023（Aurora）和0.073（Frontier）的MAPE；主动学习仅用约450次实验即可达到约0.2的MAPE。

Conclusion: 所提ML方法能有效指导用户在最短时间和最低成本目标下选择最优运行参数。

Abstract: In this work, we develop machine learning (ML) based strategies to predict
resources (costs) required for massively parallel chemistry computations, such
as coupled-cluster methods, to guide application users before they commit to
running expensive experiments on a supercomputer. By predicting application
execution time, we determine the optimal runtime parameter values such as
number of nodes and tile sizes. Two key questions of interest to users are
addressed. The first is the shortest-time question, where the user is
interested in knowing the parameter configurations (number of nodes and tile
sizes) to achieve the shortest execution time for a given problem size and a
target supercomputer. The second is the cheapest-run question in which the user
is interested in minimizing resource usage, i.e., finding the number of nodes
and tile size that minimizes the number of node-hours for a given problem size.
  We evaluate a rich family of ML models and strategies, developed based on the
collections of runtime parameter values for the CCSD (Coupled Cluster with
Singles and Doubles) application executed on the Department of Energy (DOE)
Frontier and Aurora supercomputers. Our experiments show that when predicting
the total execution time of a CCSD iteration, a Gradient Boosting (GB) ML model
achieves a Mean Absolute Percentage Error (MAPE) of 0.023 and 0.073 for Aurora
and Frontier, respectively. In the case where it is expensive to run
experiments just to collect data points, we show that active learning can
achieve a MAPE of about 0.2 with just around 450 experiments collected from
Aurora and Frontier.

</details>


### [235] [Theoretical Bounds for Stable In-Context Learning](https://arxiv.org/abs/2509.20677)
*Tongxi Wang,Zhuoyang Xia*

Main category: cs.LG

TL;DR: 本文提出了一个非渐近下界，将演示样本数量与上下文学习（ICL）在高维子高斯表示下的稳定性联系起来，并基于该分析提出了一种可实践的两阶段估计器来预测合适的提示长度。


<details>
  <summary>Details</summary>
Motivation: 由于上下文学习对提示长度高度敏感，缺乏可靠的理论指导其在实际应用中的稳定性，因此需要建立理论依据并提供可计算的准则来提升ICL的可靠性。

Method: 通过建立固定高维子高斯表示下ICL稳定性的非渐近下界，分析协方差矩阵的谱性质，并设计一种两阶段可观察估计器，结合一次性校准实现无需分布先验的提示长度估计。

Result: 理论结果提供了关于谱特性的显式充分条件，实验显示预测阈值与经验拐点高度一致，且校准版本进一步缩小了理论与实践之间的差距。

Conclusion: 该研究将谱覆盖与稳定的ICL联系起来，弥合了理论与部署之间的鸿沟，提升了大规模提示在有限样本场景下的可解释性和可靠性。

Abstract: In-context learning (ICL) is flexible but its reliability is highly sensitive
to prompt length. This paper establishes a non-asymptotic lower bound that
links the minimal number of demonstrations to ICL stability under fixed
high-dimensional sub-Gaussian representations. The bound gives explicit
sufficient conditions in terms of spectral properties of the covariance,
providing a computable criterion for practice. Building on this analysis, we
propose a two-stage observable estimator with a one-shot calibration that
produces practitioner-ready prompt-length estimates without distributional
priors. Experiments across diverse datasets, encoders, and generators show
close alignment between the predicted thresholds and empirical knee-points,
with the theory acting as a conservative but reliable upper bound; the
calibrated variant further tightens this gap. These results connect spectral
coverage to stable ICL, bridge theory and deployment, and improve the
interpretability and reliability of large-scale prompting in realistic
finite-sample regimes.

</details>


### [236] [Bispectral OT: Dataset Comparison using Symmetry-Aware Optimal Transport](https://arxiv.org/abs/2509.20678)
*Annabel Ma,Kaiying Hou,David Alvarez-Melis,Melanie Weber*

Main category: cs.LG

TL;DR: 提出了一种对称性感知的离散最优传输方法——双谱最优传输（Bispectral Optimal Transport），利用双谱这一群傅里叶不变量来保留信号结构并消除群作用带来的变化，从而在具有视觉对称性的数据上实现了比基于原始特征的最优传输更高的类别保持精度。


<details>
  <summary>Details</summary>
Motivation: 在对称性丰富的场景中，传统的最优传输方法仅依赖原始特征间的成对几何距离，可能忽略数据的内在一致性结构，导致语义无关的变异干扰匹配结果。因此需要一种能够识别并去除对称性引起的冗余变化、同时保留语义结构的对齐方法。

Method: 引入双谱最优传输（Bispectral OT），将元素通过双谱表示进行比较，双谱作为群傅里叶不变量，能够在去除群作用（如旋转、平移等）引起的变化的同时，保留信号的全部结构信息，并将其融入离散最优传输框架中。

Result: 实验表明，在具有视觉对称性的基准数据集上，双谱OT相比传统的基于原始特征的OT方法，能生成更具类别保持性的传输方案，显著提升有意义对应关系的质量，更好地捕捉数据集中的语义标签结构。

Conclusion: 双谱最优传输是一种有效的对称性感知对齐方法，通过结合群不变表示与最优传输，提升了在对称变换下的数据对齐质量和语义一致性。

Abstract: Optimal transport (OT) is a widely used technique in machine learning,
graphics, and vision that aligns two distributions or datasets using their
relative geometry. In symmetry-rich settings, however, OT alignments based
solely on pairwise geometric distances between raw features can ignore the
intrinsic coherence structure of the data. We introduce Bispectral Optimal
Transport, a symmetry-aware extension of discrete OT that compares elements
using their representation using the bispectrum, a group Fourier invariant that
preserves all signal structure while removing only the variation due to group
actions. Empirically, we demonstrate that the transport plans computed with
Bispectral OT achieve greater class preservation accuracy than naive feature OT
on benchmark datasets transformed with visual symmetries, improving the quality
of meaningful correspondences that capture the underlying semantic label
structure in the dataset while removing nuisance variation not affecting class
or content.

</details>


### [237] [Can Federated Learning Safeguard Private Data in LLM Training? Vulnerabilities, Attacks, and Defense Evaluation](https://arxiv.org/abs/2509.20680)
*Wenkai Guo,Xuefeng Liu,Haolin Wang,Jianwei Niu,Shaojie Tang,Jing Yuan*

Main category: cs.LG

TL;DR: 本文研究了在联邦学习（FL）框架下微调大语言模型（LLM）时的隐私风险，发现尽管FL被认为能保护数据隐私，但攻击者仍可从全局模型中提取训练数据，且模型越大，泄露越严重。作者提出了一种针对FL的增强型攻击方法，并评估了多种隐私保护技术以缓解此类风险。


<details>
  <summary>Details</summary>
Motivation: 由于组织通常不愿共享本地数据，联邦学习被视为协作微调大语言模型的理想方案。然而，人们普遍认为FL中的全局模型能保护客户端数据隐私，本文旨在检验这一假设是否成立。

Method: 通过大量实验评估从联邦学习得到的全局模型中恢复训练数据的可能性，并设计一种新的攻击策略，利用训练过程中全局模型的更新轨迹来增强数据泄露效果。同时评估了差分隐私、正则化约束更新和具备安全对齐的大模型等防御方法的效果。

Result: 实验表明，即使使用简单的生成方法，攻击者也能从全局模型中提取出训练数据，且随着模型规模增大，泄露程度加剧。所提出的增强攻击策略进一步提升了数据恢复的成功率。此外，部分隐私保护技术在一定程度上减轻了泄露风险，但也面临性能与隐私权衡的挑战。

Conclusion: 联邦学习并不能完全防止大语言模型在协作微调过程中的训练数据泄露，需结合有效的隐私保护机制才能降低风险。本文为在FL中安全训练LLM提供了实践指导。

Abstract: Fine-tuning large language models (LLMs) with local data is a widely adopted
approach for organizations seeking to adapt LLMs to their specific domains.
Given the shared characteristics in data across different organizations, the
idea of collaboratively fine-tuning an LLM using data from multiple sources
presents an appealing opportunity. However, organizations are often reluctant
to share local data, making centralized fine-tuning impractical. Federated
learning (FL), a privacy-preserving framework, enables clients to retain local
data while sharing only model parameters for collaborative training, offering a
potential solution. While fine-tuning LLMs on centralized datasets risks data
leakage through next-token prediction, the iterative aggregation process in FL
results in a global model that encapsulates generalized knowledge, which some
believe protects client privacy. In this paper, however, we present
contradictory findings through extensive experiments. We show that attackers
can still extract training data from the global model, even using
straightforward generation methods, with leakage increasing as the model size
grows. Moreover, we introduce an enhanced attack strategy tailored to FL, which
tracks global model updates during training to intensify privacy leakage. To
mitigate these risks, we evaluate privacy-preserving techniques in FL,
including differential privacy, regularization-constrained updates and adopting
LLMs with safety alignment. Our results provide valuable insights and practical
guidelines for reducing privacy risks when training LLMs with FL.

</details>


### [238] [Learning to Align Molecules and Proteins: A Geometry-Aware Approach to Binding Affinity](https://arxiv.org/abs/2509.20693)
*Mohammadsaleh Refahi,Bahrad A. Sokhansanj,James R. Brown,Gail Rosen*

Main category: cs.LG

TL;DR: FIRM-DTI是一种轻量级深度学习框架，通过特征级线性调制和度量学习显著提升药物-靶标结合亲和力预测的泛化能力，在跨域任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有药物-靶标结合亲和力预测模型多采用简单的拼接方式融合分子表示，缺乏显式几何正则化，导致在化学空间和时间上的泛化能力较差。

Method: 提出FIRM-DTI框架，使用FiLM层以蛋白质嵌入条件化分子嵌入，并通过三元组损失施加度量结构约束，回归头基于嵌入距离采用RBF核进行平滑、可解释的亲和力预测。

Result: FIRM-DTI在Therapeutics Data Commons的DTI-DG基准上达到最先进的性能，消融实验和域外评估验证了其优越性。

Conclusion: 条件化表示和度量学习能有效提升药物-靶标亲和力预测模型的鲁棒性和泛化能力，FIRM-DTI为高效药物发现提供了可靠工具。

Abstract: Accurate prediction of drug-target binding affinity can accelerate drug
discovery by prioritizing promising compounds before costly wet-lab screening.
While deep learning has advanced this task, most models fuse ligand and protein
representations via simple concatenation and lack explicit geometric
regularization, resulting in poor generalization across chemical space and
time. We introduce FIRM-DTI, a lightweight framework that conditions molecular
embeddings on protein embeddings through a feature-wise linear modulation
(FiLM) layer and enforces metric structure with a triplet loss. An RBF
regression head operating on embedding distances yields smooth, interpretable
affinity predictions. Despite its modest size, FIRM-DTI achieves
state-of-the-art performance on the Therapeutics Data Commons DTI-DG benchmark,
as demonstrated by an extensive ablation study and out-of-domain evaluation.
Our results underscore the value of conditioning and metric learning for robust
drug-target affinity prediction.

</details>


### [239] [CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning](https://arxiv.org/abs/2509.20712)
*Zhenpeng Su,Leiyu Pan,Minxuan Lv,Yuntao Li,Wenping Hu,Fuzheng Zhang,Kun Gai,Guorui Zhou*

Main category: cs.LG

TL;DR: 提出了一种新的强化学习算法CE-GPPO，通过保留被裁剪标记的梯度信号来有效控制策略熵，从而在数学推理任务中实现更稳定的训练和更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如PPO在训练过程中丢弃了低概率标记的梯度信号，导致策略熵调控不足，影响探索与利用的平衡。

Method: 提出CE-GPPO算法，以温和且有界的方式重新引入被PPO裁剪机制排除的标记梯度，调节这些标记对熵演化的影响。

Result: 理论分析和实验表明，CE-GPPO能有效缓解熵不稳定问题，在多个数学推理基准上优于强基线方法，且在不同模型规模下表现一致。

Conclusion: CE-GPPO通过保留关键梯度信号改进了策略优化过程中的熵控制，为大语言模型的强化学习提供了更稳定有效的训练方式。

Abstract: Reinforcement learning (RL) has become a powerful paradigm for optimizing
large language models (LLMs) to handle complex reasoning tasks. A core
challenge in this process lies in managing policy entropy, which reflects the
balance between exploration and exploitation during training. Existing methods,
such as proximal policy optimization (PPO) and its variants, discard valuable
gradient signals from low-probability tokens due to the clipping mechanism. We
systematically analyze the entropy dynamics and reveal that these clipped
tokens play a critical yet overlooked role in regulating entropy evolution. We
propose \textbf{C}ontrolling \textbf{E}ntropy via
\textbf{G}radient-\textbf{P}reserving \textbf{P}olicy \textbf{O}ptimization
(CE-GPPO), a novel algorithm that reintroduces gradients from clipped tokens in
native PPO in a gentle and bounded manner. By controlling the magnitude of
gradients from tokens outside the clipping interval, CE-GPPO is able to achieve
an exploration-exploitation trade-off. We provide theoretical justification and
empirical evidence showing that CE-GPPO effectively mitigates entropy
instability. Extensive experiments on mathematical reasoning benchmarks show
that CE-GPPO consistently outperforms strong baselines across different model
scales.

</details>


### [240] [A Genetic Algorithm for Navigating Synthesizable Molecular Spaces](https://arxiv.org/abs/2509.20719)
*Alston Lo,Connor W. Coley,Wojciech Matusik*

Main category: cs.LG

TL;DR: 本文提出了一种名为SynGA的遗传算法，直接在合成路线上操作，通过自定义的交叉和变异算子确保分子的可合成性，并结合机器学习过滤器提升性能，在多种分子设计任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的分子设计方法往往忽视了分子的可合成性，导致生成的分子难以实际合成。为了克服这一问题，作者希望开发一种能够直接在合成路线上进行优化的方法，确保生成的分子不仅具有理想的性质，而且具备实际合成的可能性。

Method: 提出了一种名为SynGA的遗传算法，该算法通过自定义的交叉和变异算子直接在合成路线上操作，确保生成的分子处于可合成的空间内。此外，通过结合机器学习模型对构建模块集进行筛选，进一步提升了算法的性能。对于属性优化任务，提出了SynGBO，将SynGA和块过滤机制嵌入贝叶斯优化的内循环中。

Result: 实验结果表明，SynGA在多种设计任务中表现优异，包括可合成的类似物搜索和样本高效的属性优化，适用于2D和3D目标。与现有方法相比，SynGA及其变体SynGBO在多个基准测试中达到了最先进的性能。

Conclusion: SynGA是一种轻量级且能从构造上保证分子可合成性的遗传算法，不仅可以作为强大的独立基线方法使用，还可以作为一个灵活的模块集成到更大的合成感知工作流中，未来有望在分子设计领域发挥重要作用。

Abstract: Inspired by the effectiveness of genetic algorithms and the importance of
synthesizability in molecular design, we present SynGA, a simple genetic
algorithm that operates directly over synthesis routes. Our method features
custom crossover and mutation operators that explicitly constrain it to
synthesizable molecular space. By modifying the fitness function, we
demonstrate the effectiveness of SynGA on a variety of design tasks, including
synthesizable analog search and sample-efficient property optimization, for
both 2D and 3D objectives. Furthermore, by coupling SynGA with a machine
learning-based filter that focuses the building block set, we boost SynGA to
state-of-the-art performance. For property optimization, this manifests as a
model-based variant SynGBO, which employs SynGA and block filtering in the
inner loop of Bayesian optimization. Since SynGA is lightweight and enforces
synthesizability by construction, our hope is that SynGA can not only serve as
a strong standalone baseline but also as a versatile module that can be
incorporated into larger synthesis-aware workflows in the future.

</details>


### [241] [Scaling Laws are Redundancy Laws](https://arxiv.org/abs/2509.20721)
*Yuda Bi,Vince D Calhoun*

Main category: cs.LG

TL;DR: 本文通过核回归揭示了深度学习中的缩放定律本质上是冗余定律，其幂律指数取决于数据协方差谱的尾部特性与数据冗余度，为缩放定律提供了首个严格的数学解释。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习中模型性能随数据和模型规模增加呈现幂律提升，但其数学起源尤其是缩放指数仍不清楚。

Method: 采用核回归方法，分析数据协方差谱的多项式尾部如何导致具有特定指数的泛化误差幂律，并探讨该规律在多种变换和模型架构下的普适性。

Result: 发现缩放指数α=2s/(2s+1/β)，其中β控制谱尾，1/β衡量数据冗余；谱越陡峭，规模回报越快；该规律在多种设定下具有普适性。

Conclusion: 缩放定律并非普适不变，而是依赖于数据冗余性的有限样本冗余定律，本文为其提供了统一的理论基础。

Abstract: Scaling laws, a defining feature of deep learning, reveal a striking
power-law improvement in model performance with increasing dataset and model
size. Yet, their mathematical origins, especially the scaling exponent, have
remained elusive. In this work, we show that scaling laws can be formally
explained as redundancy laws. Using kernel regression, we show that a
polynomial tail in the data covariance spectrum yields an excess risk power law
with exponent alpha = 2s / (2s + 1/beta), where beta controls the spectral tail
and 1/beta measures redundancy. This reveals that the learning curve's slope is
not universal but depends on data redundancy, with steeper spectra accelerating
returns to scale. We establish the law's universality across boundedly
invertible transformations, multi-modal mixtures, finite-width approximations,
and Transformer architectures in both linearized (NTK) and feature-learning
regimes. This work delivers the first rigorous mathematical explanation of
scaling laws as finite-sample redundancy laws, unifying empirical observations
with theoretical foundations.

</details>


### [242] [The Impact of Audio Watermarking on Audio Anti-Spoofing Countermeasures](https://arxiv.org/abs/2509.20736)
*Zhenshan Zhang,Xueping Zhang,Yechen Wang,Liwei Jin,Ming Li*

Main category: cs.LG

TL;DR: 本文首次研究了音频水印对防欺骗系统的影响，发现水印会显著降低防欺骗性能，并提出KPWL框架以提升模型的水印鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 音频水印广泛用于版权保护，但其对语音防欺骗系统的影响尚不明确，亟需探究其潜在干扰并建立相应基准。

Method: 构建了Watermark-Spoofing数据集，结合手工设计和神经水印方法，评估不同水印密度对防欺骗系统的影响，并提出KPWL框架来缓解性能下降。

Result: 实验证明水印密度越高，防欺骗系统的等错误率（EER）越高；KPWL框架能有效适应水印引起的域偏移，保持原有检测能力。

Conclusion: 音频水印是一种被忽视的域偏移因素，该研究建立了首个抗水印防欺骗系统的基准，为未来鲁棒性系统设计提供了重要参考。

Abstract: This paper presents the first study on the impact of audio watermarking on
spoofing countermeasures. While anti-spoofing systems are essential for
securing speech-based applications, the influence of widely used audio
watermarking, originally designed for copyright protection, remains largely
unexplored. We construct watermark-augmented training and evaluation datasets,
named the Watermark-Spoofing dataset, by applying diverse handcrafted and
neural watermarking methods to existing anti-spoofing datasets. Experiments
show that watermarking consistently degrades anti-spoofing performance, with
higher watermark density correlating with higher Equal Error Rates (EERs). To
mitigate this, we propose the Knowledge-Preserving Watermark Learning (KPWL)
framework, enabling models to adapt to watermark-induced shifts while
preserving their original-domain spoofing detection capability. These findings
reveal audio watermarking as a previously overlooked domain shift and establish
the first benchmark for developing watermark-resilient anti-spoofing systems.
All related protocols are publicly available at
https://github.com/Alphawarheads/Watermark_Spoofing.git

</details>


### [243] [Measuring LLM Sensitivity in Transformer-based Tabular Data Synthesis](https://arxiv.org/abs/2509.20768)
*Maria F. Davila R,Azizjon Turaev,Wolfram Wingerath*

Main category: cs.LG

TL;DR: 本研究评估了GReaT和REaLTabFormer两种Transformer-based表格数据生成工具在不同超参数配置下的性能，发现模型深度影响合成数据质量与计算成本，REaLTabFormer在大数据集上表现更优，但运行时间较长，轻量级大模型可平衡质量与效率。


<details>
  <summary>Details</summary>
Motivation: Transformer模型虽在表格数据生成中表现优异，但计算成本高，需探究其超参数对数据质量和计算性能的影响，以提升在消费级硬件上的可行性。

Method: 通过对GReaT和REaLTabFormer的10种不同架构配置进行实验，评估其在运行时间、机器学习效用和数据分布相似性三个维度的敏感性，并在四个真实数据集上测试。

Result: 运行时间随模型参数增加而增长，浅层模型更快；GReaT运行时间普遍低于REaLTabFormer；小数据集上两者性能相当，但在大数据集上仅REaLTabFormer保持高数据效用和相似性；结合轻量级大模型的REaLTabFormer在质量和效率间取得最佳平衡。

Conclusion: REaLTabFormer在处理大规模数据时更具优势，尽管其运行时间仍高于GReaT，表明当前效率提升存在上限，未来可在保持数据质量的前提下进一步优化计算效率。

Abstract: Synthetic tabular data is used for privacy-preserving data sharing and
data-driven model development. Its effectiveness, however, depends heavily on
the used Tabular Data Synthesis (TDS) tool. Recent studies have shown that
Transformer-based models outperform other state-of-the-art models such as
Generative Adversarial Networks (GANs) and Diffusion models in terms of data
quality. However, Transformer-based models also come with high computational
costs, making them sometimes unfeasible for end users with prosumer hardware.
This study presents a sensitivity assessment on how the choice of
hyperparameters, such as number of layers or hidden dimension affects the
quality of the resultant synthetic data and the computational performance. It
is performed across two tools, GReaT and REaLTabFormer, evaluating 10 model
setups that vary in architecture type and depth. We assess the sensitivity on
three dimensions: runtime, machine learning (ML) utility, and similarity to
real data distributions. Experiments were conducted on four real-world
datasets. Our findings reveal that runtime is proportional to the number of
hyperparameters, with shallower configurations completing faster. GReaT
consistently achieves lower runtimes than REaLTabFormer, and only on the
largest dataset they have comparable runtime. For small datasets, both tools
achieve synthetic data with high utility and optimal similarity, but on larger
datasets only REaLTabFormer sustains strong utility and similarity. As a
result, REaLTabFormer with lightweight LLMs provides the best balance, since it
preserves data quality while reducing computational requirements. Nonetheless,
its runtime remains higher than that of GReaT and other TDS tools, suggesting
that efficiency gains are possible but only up to a certain level.

</details>


### [244] [Sig2Model: A Boosting-Driven Model for Updatable Learned Indexes](https://arxiv.org/abs/2509.20781)
*Alireza Heidari,Amirhossein Ahmad,Wei Zhang,Ying Xiong*

Main category: cs.LG

TL;DR: Sig2Model是一种高效的自适应学习索引，通过Sigmoid增强近似、高斯混合模型预训练和神经联合优化框架，显著降低动态更新下的重训练成本，提升查询性能并减少内存使用。


<details>
  <summary>Details</summary>
Motivation: 传统学习索引在动态数据更新时因需全局重训练而性能下降，难以满足高频更新场景需求，现有方法无法有效解决重训练开销问题。

Method: 1) 使用Sigmoid函数局部逼近数据分布变化，延迟全局重训练；2) 利用GMM预测高更新概率区域并预留占位符；3) 通过神经网络联合优化Sigmoid集成与GMM参数。

Result: 相比当前最先进的可更新学习索引，Sig2Model重训练成本降低最多20倍，QPS提高达3倍，内存使用减少最多1000倍。

Conclusion: Sig2Model有效解决了动态环境下学习索引的重训练开销问题，实现了高效、低延迟的索引更新，适用于真实场景中的高频更新工作负载。

Abstract: Learned Indexes (LIs) represent a paradigm shift from traditional index
structures by employing machine learning models to approximate the cumulative
distribution function (CDF) of sorted data. While LIs achieve remarkable
efficiency for static datasets, their performance degrades under dynamic
updates: maintaining the CDF invariant (sum of F(k) equals 1) requires global
model retraining, which blocks queries and limits the queries-per-second (QPS)
metric. Current approaches fail to address these retraining costs effectively,
rendering them unsuitable for real-world workloads with frequent updates. In
this paper, we present Sig2Model, an efficient and adaptive learned index that
minimizes retraining cost through three key techniques: (1) a sigmoid boosting
approximation technique that dynamically adjusts the index model by
approximating update-induced shifts in data distribution with localized sigmoid
functions while preserving bounded error guarantees and deferring full
retraining; (2) proactive update training via Gaussian mixture models (GMMs)
that identifies high-update-probability regions for strategic placeholder
allocation to speed up updates; and (3) a neural joint optimization framework
that continuously refines both the sigmoid ensemble and GMM parameters via
gradient-based learning. We evaluate Sig2Model against state-of-the-art
updatable learned indexes on real-world and synthetic workloads, and show that
Sig2Model reduces retraining cost by up to 20x, achieves up to 3x higher QPS,
and uses up to 1000x less memory.

</details>


### [245] [IConv: Focusing on Local Variation with Channel Independent Convolution for Multivariate Time Series Forecasting](https://arxiv.org/abs/2509.20783)
*Gawon Lee,Hanbyeol Park,Minseop Kim,Dohee Kim,Hyerim Bae*

Main category: cs.LG

TL;DR: 提出了一种结合MLP和CNN的新型时间序列预测模型，利用MLP捕捉长期趋势，CNN建模局部变化，通过IConv架构独立处理通道间依赖，提升多变量时间序列预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLP模型因线性结构难以捕捉非平稳时间序列中的局部变化（如季节性和残差），需改进以更好建模复杂分布下的局部模式。

Method: 提出IConv架构，将MLP用于建模整体趋势，CNN使用多种卷积核捕捉细粒度局部模式；IConv独立处理各通道的时间依赖，并通过分离层考虑通道间关系，支持大卷积核并降低计算成本。

Result: 在多个时间序列数据集上进行了广泛实验，结果表明该方法在多变量时间序列预测任务中优于现有模型。

Conclusion: 结合MLP与CNN并通过IConv架构独立建模通道内与通道间关系，能有效提升非平稳时间序列的预测精度，兼顾性能与效率。

Abstract: Real-world time-series data often exhibit non-stationarity, including
changing trends, irregular seasonality, and residuals. In terms of changing
trends, recently proposed multi-layer perceptron (MLP)-based models have shown
excellent performance owing to their computational efficiency and ability to
capture long-term dependency. However, the linear nature of MLP architectures
poses limitations when applied to channels with diverse distributions,
resulting in local variations such as seasonal patterns and residual components
being ignored. However, convolutional neural networks (CNNs) can effectively
incorporate these variations. To resolve the limitations of MLP, we propose
combining them with CNNs. The overall trend is modeled using an MLP to consider
long-term dependencies. The CNN uses diverse kernels to model fine-grained
local patterns in conjunction with MLP trend predictions. To focus on modeling
local variation, we propose IConv, a novel convolutional architecture that
processes the temporal dependency channel independently and considers the
inter-channel relationship through distinct layers. Independent channel
processing enables the modeling of diverse local temporal dependencies and the
adoption of a large kernel size. Distinct inter-channel considerations reduce
computational cost. The proposed model is evaluated through extensive
experiments on time-series datasets. The results reveal the superiority of the
proposed method for multivariate time-series forecasting.

</details>


### [246] [LiLAW: Lightweight Learnable Adaptive Weighting to Meta-Learn Sample Difficulty and Improve Noisy Training](https://arxiv.org/abs/2509.20786)
*Abhishek Moturu,Anna Goldenberg,Babak Taati*

Main category: cs.LG

TL;DR: 提出了一种名为LiLAW的轻量级自适应加权方法，通过动态调整训练样本的损失权重来提升深度神经网络在噪声标签和数据异构环境下的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在存在噪声标签和数据异质性的情况下，传统训练方法容易过拟合噪声样本，难以有效利用困难但信息丰富的样本，因此需要一种简单且自适应的样本加权机制。

Method: LiLAW基于每个样本的难度（易、中、难）动态调整其损失权重，仅使用三个可学习参数，并在每个训练小批量后，利用验证集上的单步梯度下降更新权重，无需干净验证集或复杂调参。

Result: 在多种通用和医学图像数据集、不同噪声类型与水平、损失函数及网络结构下，LiLAW均显著提升模型性能，尤其在高噪声环境下表现突出，且不依赖强数据增强或复杂正则化。

Conclusion: LiLAW是一种高效、实用且易于集成的训练策略，能有效提高模型在噪声环境中的鲁棒性和泛化能力，适用于广泛的神经网络训练场景。

Abstract: Training deep neural networks in the presence of noisy labels and data
heterogeneity is a major challenge. We introduce Lightweight Learnable Adaptive
Weighting (LiLAW), a novel method that dynamically adjusts the loss weight of
each training sample based on its evolving difficulty level, categorized as
easy, moderate, or hard. Using only three learnable parameters, LiLAW
adaptively prioritizes informative samples throughout training by updating
these weights using a single mini-batch gradient descent step on the validation
set after each training mini-batch, without requiring excessive hyperparameter
tuning or a clean validation set. Extensive experiments across multiple general
and medical imaging datasets, noise levels and types, loss functions, and
architectures with and without pretraining demonstrate that LiLAW consistently
enhances performance, even in high-noise environments. It is effective without
heavy reliance on data augmentation or advanced regularization, highlighting
its practicality. It offers a computationally efficient solution to boost model
generalization and robustness in any neural network training setup.

</details>


### [247] [Aligning Inductive Bias for Data-Efficient Generalization in State Space Models](https://arxiv.org/abs/2509.20789)
*Qiyu Chen,Guozhang Chen*

Main category: cs.LG

TL;DR: 本文提出了一种任务依赖初始化（TDI）方法，通过频谱匹配来对齐状态空间模型的归纳偏置与任务的光谱特性，从而提升模型在低数据场景下的泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的状态空间模型（SSM）依赖固定的归纳偏置，在任务结构不匹配时样本效率低下，而高质量数据有限，亟需提高模型的数据效率。

Method: 通过引入SSM诱导核，形式化线性时不变SSM的归纳偏置，并提出任务依赖初始化（TDI）方法——功率谱匹配，以在大规模训练前调整模型的频响特性以适应任务需求。

Result: 在多个真实世界基准上的实验表明，TDI显著提升了模型的泛化性能和样本效率，尤其在低数据条件下表现突出。

Conclusion: 该工作为构建更高效利用数据的模型提供了理论与实践工具，是实现可持续模型扩展的重要一步。

Abstract: The remarkable success of large-scale models is fundamentally tied to scaling
laws, yet the finite nature of high-quality data presents a looming challenge.
One of the next frontiers in modeling is data efficiency: the ability to learn
more from less. A model's inductive bias is a critical lever for this, but
foundational sequence models like State Space Models (SSMs) rely on a fixed
bias. This fixed prior is sample-inefficient when a task's underlying structure
does not match. In this work, we introduce a principled framework to solve this
problem. We first formalize the inductive bias of linear time-invariant SSMs
through an SSM-induced kernel, mathematically and empirically proving its
spectrum is directly governed by the model's frequency response. Further, we
propose a method of Task-Dependent Initialization (TDI): power spectrum
matching, a fast and efficient method that aligns the model's inductive bias
with the task's spectral characteristics before large-scale training. Our
experiments on a diverse set of real-world benchmarks show that TDI
significantly improves generalization and sample efficiency, particularly in
low-data regimes. This work provides a theoretical and practical tool to create
more data-efficient models, a crucial step towards sustainable scaling.

</details>


### [248] [FERD: Fairness-Enhanced Data-Free Robustness Distillation](https://arxiv.org/abs/2509.20793)
*Zhengxiao Li,Liming Lu,Xu Zheng,Siyuan Liang,Zhenghan Chen,Yongbin Zhou,Shuchao Pang*

Main category: cs.LG

TL;DR: 本文提出了首个公平性增强的数据无关鲁棒性蒸馏框架FERD，通过调整对抗样本的比例和分布来提升学生模型在各类别间的鲁棒公平性。


<details>
  <summary>Details</summary>
Motivation: 现有数据无关鲁棒性蒸馏方法忽视了不同类别间的鲁棒性公平问题，导致某些类别鲁棒性显著偏低，且对不同攻击目标稳定性不足。

Method: FERD采用鲁棒性引导的类别重加权策略，为鲁棒性较差的类别生成更多样本；并通过特征层预测的均匀性约束生成公平感知样本（FAEs），进一步构造均匀目标对抗样本（UTAEs）以避免攻击方向偏差。

Result: 在三个公开数据集上实验表明，FERD在所有对抗攻击下均实现了最先进的最差类鲁棒性，例如在CIFAR-10上使用MobileNet-V2时，FGSM和AutoAttack下的最差类鲁棒性分别提升了15.1%和6.4%。

Conclusion: FERD有效提升了学生模型在无数据场景下的鲁棒性和类别间公平性，解决了现有方法在鲁棒性分布不均和攻击目标稳定性方面的缺陷。

Abstract: Data-Free Robustness Distillation (DFRD) aims to transfer the robustness from
the teacher to the student without accessing the training data. While existing
methods focus on overall robustness, they overlook the robust fairness issues,
leading to severe disparity of robustness across different categories. In this
paper, we find two key problems: (1) student model distilled with equal class
proportion data behaves significantly different across distinct categories; and
(2) the robustness of student model is not stable across different attacks
target. To bridge these gaps, we present the first Fairness-Enhanced data-free
Robustness Distillation (FERD) framework to adjust the proportion and
distribution of adversarial examples. For the proportion, FERD adopts a
robustness-guided class reweighting strategy to synthesize more samples for the
less robust categories, thereby improving robustness of them. For the
distribution, FERD generates complementary data samples for advanced robustness
distillation. It generates Fairness-Aware Examples (FAEs) by enforcing a
uniformity constraint on feature-level predictions, which suppress the
dominance of class-specific non-robust features, providing a more balanced
representation across all categories. Then, FERD constructs Uniform-Target
Adversarial Examples (UTAEs) from FAEs by applying a uniform target class
constraint to avoid biased attack directions, which distribute the attack
targets across all categories and prevents overfitting to specific vulnerable
categories. Extensive experiments on three public datasets show that FERD
achieves state-of-the-art worst-class robustness under all adversarial attack
(e.g., the worst-class robustness under FGSM and AutoAttack are improved by
15.1\% and 6.4\% using MobileNet-V2 on CIFAR-10), demonstrating superior
performance in both robustness and fairness aspects.

</details>


### [249] [T2I-Diff: fMRI Signal Generation via Time-Frequency Image Transform and Classifier-Free Denoising Diffusion Models](https://arxiv.org/abs/2509.20822)
*Hwa Hui Tew,Junn Yong Loo,Yee-Fan Tan,Xinyu Tang,Hernando Ombao,Fuad Noman,Raphael C. -W. Phan,Chee-Ming Ting*

Main category: cs.LG

TL;DR: 提出了一种基于时间-频率表示和无分类器去噪扩散的fMRI生成框架T2I-Diff，通过将BOLD信号转换为窗口谱图并利用扩散模型生成频域谱图，再逆变换回时域，有效提升了下游脑网络分类任务的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: fMRI数据获取成本高、高质量样本稀缺，且现有生成模型常忽略BOLD信号的非平稳性和非线性动态，导致生成效果不佳。

Method: 引入T2I-Diff框架：首先通过时变傅里叶变换将BOLD信号转为窗口谱图，捕捉时频动态；然后使用无分类器扩散模型生成类别条件频谱图；最后通过逆傅里叶变换还原为BOLD信号。

Result: 生成的fMRI数据在下游脑网络分类任务中表现出更高的准确性和更好的泛化性能，验证了方法的有效性。

Conclusion: T2I-Diff通过结合时频分析与扩散生成模型，显著提升了fMRI数据生成质量，有助于缓解神经影像数据稀缺问题，并推动数据驱动脑功能分析的发展。

Abstract: Functional Magnetic Resonance Imaging (fMRI) is an advanced neuroimaging
method that enables in-depth analysis of brain activity by measuring dynamic
changes in the blood oxygenation level-dependent (BOLD) signals. However, the
resource-intensive nature of fMRI data acquisition limits the availability of
high-fidelity samples required for data-driven brain analysis models. While
modern generative models can synthesize fMRI data, they often underperform
because they overlook the complex non-stationarity and nonlinear BOLD dynamics.
To address these challenges, we introduce T2I-Diff, an fMRI generation
framework that leverages time-frequency representation of BOLD signals and
classifier-free denoising diffusion. Specifically, our framework first converts
BOLD signals into windowed spectrograms via a time-dependent Fourier transform,
capturing both the underlying temporal dynamics and spectral evolution.
Subsequently, a classifier-free diffusion model is trained to generate
class-conditioned frequency spectrograms, which are then reverted to BOLD
signals via inverse Fourier transforms. Finally, we validate the efficacy of
our approach by demonstrating improved accuracy and generalization in
downstream fMRI-based brain network classification.

</details>


### [250] [CaTS-Bench: Can Language Models Describe Numeric Time Series?](https://arxiv.org/abs/2509.20823)
*Luca Zhou,Pratham Yashwante,Marshall Fisher,Alessio Sampieri,Zihao Zhou,Fabio Galasso,Rose Yu*

Main category: cs.LG

TL;DR: 本文提出了CaTS-Bench，首个大规模、真实场景下的上下文感知时间序列描述基准，包含46.5万训练和10.5万测试样本，涵盖数值序列、元数据、图表图像和描述文本，并引入LLM生成与人工修正相结合的标注流程及新的评估指标，推动时间序列分析与基础模型的融合研究。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列描述基准多依赖合成数据或过于简单的描述，且忽略元数据和可视化信息，缺乏真实性和复杂性，限制了模型在现实场景中的发展。

Method: 构建了一个包含11个多样化数据集的大规模基准CaTS-Bench，每个样本包括时间序列片段、上下文元数据、折线图图像和自然语言描述；通过基于Oracle大模型生成描述并进行事实验证、人类不可区分性测试和多样性分析来构建标注，同时提供579个人工修订的高质量测试描述；设计了针对时间序列推理的460道选择题和定制化评估指标，并对当前领先的视觉-语言模型进行了系统评测。

Result: 建立了包含约46.5万训练和10.5万测试时间戳的大规模真实世界基准CaTS-Bench；验证了LLM生成描述的准确性和自然性，并提供了人工精修子集；提出了新的评估指标；评测结果显示现有VLM在时间序列理解上仍有明显局限。

Conclusion: CaTS-Bench及其可扩展的标注流程为时间序列分析与基础模型结合的研究提供了可靠且可扩展的基础，推动了时间序列自然语言描述任务的发展。

Abstract: Time series captioning, the task of describing numeric time series in natural
language, requires numerical reasoning, trend interpretation, and contextual
understanding. Existing benchmarks, however, often rely on synthetic data or
overly simplistic captions, and typically neglect metadata and visual
representations. To close this gap, we introduce CaTS-Bench, the first
large-scale, real-world benchmark for Context-aware Time Series captioning.
CaTS-Bench is derived from 11 diverse datasets reframed as captioning and Q&A
tasks, comprising roughly 465k training and 105k test timestamps. Each sample
includes a numeric series segment, contextual metadata, a line-chart image, and
a caption. A key contribution of this work is the scalable pipeline used to
generate reference captions: while most references are produced by an oracle
LLM and verified through factual checks, human indistinguishability studies,
and diversity analyses, we also provide a human-revisited subset of 579 test
captions, refined from LLM outputs to ensure accuracy and human-like style.
Beyond captioning, CaTS-Bench offers 460 multiple-choice questions targeting
deeper aspects of time series reasoning. We further propose new tailored
evaluation metrics and benchmark leading VLMs, highlighting both their
strengths and persistent limitations. Together, these contributions establish
CaTS-Bench and its captioning pipeline as a reliable and extensible foundation
for future research at the intersection of time series analysis and foundation
models.

</details>


### [251] [Explaining Grokking and Information Bottleneck through Neural Collapse Emergence](https://arxiv.org/abs/2509.20829)
*Keitaro Sakamoto,Issei Sato*

Main category: cs.LG

TL;DR: 本文通过神经坍缩（neural collapse）的视角，统一解释了深度神经网络训练后期现象（如grokking和信息瓶颈），指出类内方差收缩是这些现象的关键因素，并通过实验验证了理论发现。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络的训练动态常表现出意料之外的现象，如grokking和信息瓶颈，其背后机制及相互关系尚不清楚，亟需统一解释。

Method: 利用神经坍缩理论分析训练后期表示几何结构，提出类内方差收缩是关键机制，并将其与训练集上的神经坍缩指标关联，分析不同时间尺度下的动态过程。

Result: 揭示了grokking和信息瓶颈现象背后的共同机制——类内方差收缩，并证明神经坍缩在训练集和测试集动态中的作用存在时间尺度分离。

Conclusion: 神经坍缩为理解深度神经网络训练后期现象提供了统一框架，类内方差的压缩是grokking和信息瓶颈的核心驱动力。

Abstract: The training dynamics of deep neural networks often defy expectations, even
as these models form the foundation of modern machine learning. Two prominent
examples are grokking, where test performance improves abruptly long after the
training loss has plateaued, and the information bottleneck principle, where
models progressively discard input information irrelevant to the prediction
task as training proceeds. However, the mechanisms underlying these phenomena
and their relations remain poorly understood. In this work, we present a
unified explanation of such late-phase phenomena through the lens of neural
collapse, which characterizes the geometry of learned representations. We show
that the contraction of population within-class variance is a key factor
underlying both grokking and information bottleneck, and relate this measure to
the neural collapse measure defined on the training set. By analyzing the
dynamics of neural collapse, we show that distinct time scales between fitting
the training set and the progression of neural collapse account for the
behavior of the late-phase phenomena. Finally, we validate our theoretical
findings on multiple datasets and architectures.

</details>


### [252] [Shaping Initial State Prevents Modality Competition in Multi-modal Fusion: A Two-stage Scheduling Framework via Fast Partial Information Decomposition](https://arxiv.org/abs/2509.20840)
*Jiaqi Tang,Yinsong Xu,Yang Liu,Qingchao Chen*

Main category: cs.LG

TL;DR: 提出了一种两阶段训练框架，通过单模态预训练塑造模型初始状态，以缓解多模态融合中的模态竞争问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多在联合学习阶段解决模态竞争问题，忽视了模型初始状态的关键影响。

Method: 引入有效竞争强度（ECS）概念，并用互信息（MI）作为其代理；提出FastPID分解联合分布信息，并设计异步控制器动态平衡模态。

Result: 在多个基准上实现了最先进的性能，验证了所提方法在缓解模态竞争和提升融合效果方面的有效性。

Conclusion: 塑造融合前模型的初始状态是一种有效策略，可在联合训练前缓解模态竞争，实现可靠的协同多模态融合。

Abstract: Multi-modal fusion often suffers from modality competition during joint
training, where one modality dominates the learning process, leaving others
under-optimized. Overlooking the critical impact of the model's initial state,
most existing methods address this issue during the joint learning stage. In
this study, we introduce a two-stage training framework to shape the initial
states through unimodal training before the joint training. First, we propose
the concept of Effective Competitive Strength (ECS) to quantify a modality's
competitive strength. Our theoretical analysis further reveals that properly
shaping the initial ECS by unimodal training achieves a provably tighter error
bound. However, ECS is computationally intractable in deep neural networks. To
bridge this gap, we develop a framework comprising two core components: a
fine-grained computable diagnostic metric and an asynchronous training
controller. For the metric, we first prove that mutual information(MI) is a
principled proxy for ECS. Considering MI is induced by per-modality marginals
and thus treats each modality in isolation, we further propose FastPID, a
computationally efficient and differentiable solver for partial information
decomposition, which decomposes the joint distribution's information into
fine-grained measurements: modality-specific uniqueness, redundancy, and
synergy. Guided by these measurements, our asynchronous controller dynamically
balances modalities by monitoring uniqueness and locates the ideal initial
state to start joint training by tracking peak synergy. Experiments on diverse
benchmarks demonstrate that our method achieves state-of-the-art performance.
Our work establishes that shaping the pre-fusion models' initial state is a
powerful strategy that eases competition before it starts, reliably unlocking
synergistic multi-modal fusion.

</details>


### [253] [Robust Multi-Omics Integration from Incomplete Modalities Significantly Improves Prediction of Alzheimer's Disease](https://arxiv.org/abs/2509.20842)
*Sungjoon Park,Kyungwook Lee,Soorin Yim,Doyeong Hwang,Dongyun Kim,Soonyoung Lee,Amy Dunn,Daniel Gatti,Elissa Chesler,Kristen O'Connell,Kiyoung Kim*

Main category: cs.LG

TL;DR: MOIRA是一种针对不完整多组学数据的鲁棒整合方法，通过表示对齐和自适应聚合实现早期整合，能够在存在缺失模态的情况下有效利用所有样本，在阿尔茨海默病研究中表现出优于现有方法的性能，并识别出具有生物学意义的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 多组学数据虽能揭示复杂的生物分子相互作用，但常因模态缺失而难以进行整合分析，限制了其在疾病研究中的应用。

Method: 提出MOIRA方法，采用早期整合策略，将各组学数据投影到共享嵌入空间，并通过可学习权重机制进行自适应融合，结合表示对齐技术处理缺失模态问题。

Result: 在ROSMAP阿尔茨海默病数据集上，MOIRA优于现有方法；消融实验验证了各模态的贡献，特征重要性分析识别出与文献一致的AD相关生物标志物。

Conclusion: MOIRA能够有效应对多组学数据中模态缺失的挑战，提升整合分析的鲁棒性和生物学可解释性，为复杂疾病的机制研究提供了有力工具。

Abstract: Multi-omics data capture complex biomolecular interactions and provide
insights into metabolism and disease. However, missing modalities hinder
integrative analysis across heterogeneous omics. To address this, we present
MOIRA (Multi-Omics Integration with Robustness to Absent modalities), an early
integration method enabling robust learning from incomplete omics data via
representation alignment and adaptive aggregation. MOIRA leverages all samples,
including those with missing modalities, by projecting each omics dataset onto
a shared embedding space where a learnable weighting mechanism fuses them.
Evaluated on the Religious Order Study and Memory and Aging Project (ROSMAP)
dataset for Alzheimer's Disease (AD), MOIRA outperformed existing approaches,
and further ablation studies confirmed modality-wise contributions. Feature
importance analysis revealed AD-related biomarkers consistent with prior
literature, highlighting the biological relevance of our approach.

</details>


### [254] [Causal Time Series Generation via Diffusion Models](https://arxiv.org/abs/2509.20846)
*Yutong Xia,Chang Xu,Yuxuan Liang,Qingsong Wen,Roger Zimmermann,Jiang Bian*

Main category: cs.LG

TL;DR: 本文提出了因果时间序列生成（causal TSG）这一新任务家族，并设计了统一的扩散模型框架CaTSG，通过后门调整引导实现干预和反事实生成，提升了生成的可靠性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有条件时间序列生成模型仅学习观测相关性，忽略未观测混杂因素，缺乏对因果关系的建模，限制了其在干预和反事实场景中的应用。

Method: 基于Pearl因果层级理论，提出因果TSG框架；利用后门调整和溯因-行动-预测过程推导因果得分函数，在扩散模型中引入因果引导机制。

Result: 在合成和真实数据集上实验表明，CaTSG在保持观测保真度的同时，优于现有方法，并首次支持有效的干预和反事实序列生成。

Conclusion: 因果TSG为时间序列生成提供了更可靠的因果建模方向，CaTSG作为概念验证框架，开启了面向干预与反事实模拟的新路径。

Abstract: Time series generation (TSG) synthesizes realistic sequences and has achieved
remarkable success. Among TSG, conditional models generate sequences given
observed covariates, however, such models learn observational correlations
without considering unobserved confounding. In this work, we propose a causal
perspective on conditional TSG and introduce causal time series generation as a
new TSG task family, formalized within Pearl's causal ladder, extending beyond
observational generation to include interventional and counterfactual settings.
To instantiate these tasks, we develop CaTSG, a unified diffusion-based
framework with backdoor-adjusted guidance that causally steers sampling toward
desired interventions and individual counterfactuals while preserving
observational fidelity. Specifically, our method derives causal score functions
via backdoor adjustment and the abduction-action-prediction procedure, thus
enabling principled support for all three levels of TSG. Extensive experiments
on both synthetic and real-world datasets show that CaTSG achieves superior
fidelity and also supporting interventional and counterfactual generation that
existing baselines cannot handle. Overall, we propose the causal TSG family and
instantiate it with CaTSG, providing an initial proof-of-concept and opening a
promising direction toward more reliable simulation under interventions and
counterfactual generation.

</details>


### [255] [FHRFormer: A Self-supervised Transformer Approach for Fetal Heart Rate Inpainting and Forecasting](https://arxiv.org/abs/2509.20852)
*Kjersti Engan,Neel Kanwal,Anita Yeconia,Ladislaus Blacy,Yuda Munyaw,Estomih Mduma,Hege Ersdal*

Main category: cs.LG

TL;DR: 提出一种基于掩码Transformer的自编码器方法，用于重建缺失的胎心率（FHR）信号，有效捕捉数据的空间和频率特征，适用于信号修复与预测。


<details>
  <summary>Details</summary>
Motivation: 胎心率监测在产前护理中至关重要，但孕妇活动等因素导致信号丢失，限制了AI分析的应用。传统插值方法难以保持信号频谱特性，需更优的缺失数据处理方法。

Method: 采用基于掩码Transformer的自编码器模型，利用其对空间和频率特征的建模能力，实现FHR信号的重建、修复与预测。

Result: 该方法在不同长度的缺失数据上均表现出良好的鲁棒性，能有效恢复信号的频谱特性，优于传统插值方法。

Conclusion: 所提方法可应用于回顾性研究数据以支持AI风险算法开发，未来有望集成至可穿戴设备中，实现更早、更稳健的风险检测。

Abstract: Approximately 10\% of newborns require assistance to initiate breathing at
birth, and around 5\% need ventilation support. Fetal heart rate (FHR)
monitoring plays a crucial role in assessing fetal well-being during prenatal
care, enabling the detection of abnormal patterns and supporting timely
obstetric interventions to mitigate fetal risks during labor. Applying
artificial intelligence (AI) methods to analyze large datasets of continuous
FHR monitoring episodes with diverse outcomes may offer novel insights into
predicting the risk of needing breathing assistance or interventions. Recent
advances in wearable FHR monitors have enabled continuous fetal monitoring
without compromising maternal mobility. However, sensor displacement during
maternal movement, as well as changes in fetal or maternal position, often lead
to signal dropouts, resulting in gaps in the recorded FHR data. Such missing
data limits the extraction of meaningful insights and complicates automated
(AI-based) analysis. Traditional approaches to handle missing data, such as
simple interpolation techniques, often fail to preserve the spectral
characteristics of the signals. In this paper, we propose a masked
transformer-based autoencoder approach to reconstruct missing FHR signals by
capturing both spatial and frequency components of the data. The proposed
method demonstrates robustness across varying durations of missing data and can
be used for signal inpainting and forecasting. The proposed approach can be
applied retrospectively to research datasets to support the development of
AI-based risk algorithms. In the future, the proposed method could be
integrated into wearable FHR monitoring devices to achieve earlier and more
robust risk detection.

</details>


### [256] [Federated Markov Imputation: Privacy-Preserving Temporal Imputation in Multi-Centric ICU Environments](https://arxiv.org/abs/2509.20867)
*Christoph Düsing,Philipp Cimiano*

Main category: cs.LG

TL;DR: 提出了一种名为Federated Markov Imputation (FMI)的隐私保护方法，用于在电子健康记录的联邦学习中解决因不同机构时间序列数据采样粒度不一致导致的缺失数据问题，并在真实世界脓毒症预测任务中验证了其优于本地插补基线的效果。


<details>
  <summary>Details</summary>
Motivation: 在基于电子健康记录的联邦学习中，由于各机构采集时间序列数据的时间粒度不同，缺失数据问题尤为突出，影响模型性能。

Method: 提出Federated Markov Imputation (FMI)，通过联合多个ICU协作构建全局状态转移模型，实现对时间序列缺失数据的隐私保护性插补。

Result: 在MIMIC-IV数据集上的脓毒症发作预测任务中，FMI优于本地插补基线方法，尤其在ICU间采样间隔不规则的情况下表现更优。

Conclusion: FMI是一种有效的联邦时间序列插补方法，能够在保护隐私的同时提升跨机构不规则采样数据下的模型预测性能。

Abstract: Missing data is a persistent challenge in federated learning on electronic
health records, particularly when institutions collect time-series data at
varying temporal granularities. To address this, we propose Federated Markov
Imputation (FMI), a privacy-preserving method that enables Intensive Care Units
(ICUs) to collaboratively build global transition models for temporal
imputation. We evaluate FMI on a real-world sepsis onset prediction task using
the MIMIC-IV dataset and show that it outperforms local imputation baselines,
especially in scenarios with irregular sampling intervals across ICUs.

</details>


### [257] [StyleBench: Evaluating thinking styles in Large Language Models](https://arxiv.org/abs/2509.20868)
*Junyu Guo,Shangding Gu,Ming Jin,Costas Spanos,Javad Lavaei*

Main category: cs.LG

TL;DR: StyleBench是一个用于系统评估大语言模型中不同推理风格的基准，研究发现推理效果依赖于模型规模和任务类型，没有单一最优策略，并开源了该基准。


<details>
  <summary>Details</summary>
Motivation: 当前对推理风格、模型架构和任务类型之间的相互作用理解不足，缺乏系统性评估方法。

Method: 构建StyleBench基准，评估五种代表性推理风格（CoT, ToT, AoT, SoT, CoD）在五个推理任务上的表现，涵盖15个主流开源模型（参数量从270M到120B）。

Result: 发现不存在普遍最优的推理风格；基于搜索的方法（AoT, ToT）在开放性问题中表现好但需大规模模型，简洁风格（SoT, CoD）在明确定义的任务上效率更高；小模型常无法遵循指令而倾向于猜测，推理鲁棒性随模型规模提升。

Conclusion: 推理策略的选择应根据具体模型规模和任务类型进行权衡，研究为实际应用提供了选择最优推理风格的路线图。

Abstract: The effectiveness of Large Language Models (LLMs) is heavily influenced by
the reasoning strategies, or styles of thought, employed in their prompts.
However, the interplay between these reasoning styles, model architecture, and
task type remains poorly understood. To address this, we introduce StyleBench,
a comprehensive benchmark for systematically evaluating reasoning styles across
diverse tasks and models. We assess five representative reasoning styles,
including Chain of Thought (CoT), Tree of Thought (ToT), Algorithm of Thought
(AoT), Sketch of Thought (SoT), and Chain-of-Draft (CoD) on five reasoning
tasks, using 15 open-source models from major families (LLaMA, Qwen, Mistral,
Gemma, GPT-OSS, Phi, and DeepSeek) ranging from 270M to 120B parameters. Our
large-scale analysis reveals that no single style is universally optimal. We
demonstrate that strategy efficacy is highly contingent on both model scale and
task type: search-based methods (AoT, ToT) excel in open-ended problems but
require large-scale models, while concise styles (SoT, CoD) achieve radical
efficiency gains on well-defined tasks. Furthermore, we identify key behavioral
patterns: smaller models frequently fail to follow output instructions and
default to guessing, while reasoning robustness emerges as a function of scale.
Our findings offer a crucial roadmap for selecting optimal reasoning strategies
based on specific constraints, we open source the benchmark in
https://github.com/JamesJunyuGuo/Style_Bench.

</details>


### [258] [Model-Based Reinforcement Learning under Random Observation Delays](https://arxiv.org/abs/2509.20869)
*Armin Karamzade,Kyungmin Kim,JB Lanier,Davide Corsi,Roy Fox*

Main category: cs.LG

TL;DR: 提出了一种基于模型的过滤方法来处理强化学习中的随机传感器延迟问题，通过在Dreamer框架中应用，证明了其优于现有基线方法，并在模拟机器人任务中验证了显式建模观测延迟的重要性。


<details>
  <summary>Details</summary>
Motivation: 现实环境中普遍存在感知延迟，但传统强化学习算法通常假设环境感知是即时的，这导致在延迟存在时性能下降。因此需要研究如何在存在随机传感器延迟的情况下实现可靠的强化学习。

Method: 将随机传感器延迟建模为POMDP中的异步观测问题，提出一种基于模型的滤波过程，逐步更新信念状态，并将其融入模型基础的强化学习框架（如Dreamer）中，形成延迟感知的学习方法。

Result: 所提方法在模拟机器人任务中优于现有的延迟感知基线方法和常用启发式方法，表现出对部署过程中延迟分布变化的鲁棒性。

Conclusion: 显式建模观测延迟对于提升延迟环境下的强化学习性能至关重要，所提出的模型基过滤机制能有效应对随机和异步观测带来的挑战。

Abstract: Delays frequently occur in real-world environments, yet standard
reinforcement learning (RL) algorithms often assume instantaneous perception of
the environment. We study random sensor delays in POMDPs, where observations
may arrive out-of-sequence, a setting that has not been previously addressed in
RL. We analyze the structure of such delays and demonstrate that naive
approaches, such as stacking past observations, are insufficient for reliable
performance. To address this, we propose a model-based filtering process that
sequentially updates the belief state based on an incoming stream of
observations. We then introduce a simple delay-aware framework that
incorporates this idea into model-based RL, enabling agents to effectively
handle random delays. Applying this framework to Dreamer, we compare our
approach to delay-aware baselines developed for MDPs. Our method consistently
outperforms these baselines and demonstrates robustness to delay distribution
shifts during deployment. Additionally, we present experiments on simulated
robotic tasks, comparing our method to common practical heuristics and
emphasizing the importance of explicitly modeling observation delays.

</details>


### [259] [Distribution-Controlled Client Selection to Improve Federated Learning Strategies](https://arxiv.org/abs/2509.20877)
*Christoph Düsing,Philipp Cimiano*

Main category: cs.LG

TL;DR: 本文提出了一种基于标签分布控制的联邦学习客户端选择方法，通过使选中的客户端标签分布与目标分布（均衡分布或联邦整体分布）对齐，缓解数据不平衡问题。实验表明，该方法在不同场景下能有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端间的数据不平衡问题严重影响共享模型的性能，现有方法难以有效应对局部和全局不平衡，因此需要更智能的客户端选择策略来改善模型表现。

Method: 提出一种分布控制的客户端选择策略，选择能使当前标签分布最接近两种目标分布（均衡分布或联邦整体标签分布）的客户端参与训练，并在三种常见FL策略和两个数据集上进行验证。

Result: 实验结果显示，面对局部不平衡时，与均衡分布对齐效果最佳；而在全局不平衡情况下，与联邦整体标签分布对齐更具优势，能够显著提升模型性能。

Conclusion: 所提出的分布控制客户端选择方法能有效缓解联邦学习中的数据不平衡问题，根据不平衡类型选择合适的目标分布可进一步优化模型性能。

Abstract: Federated learning (FL) is a distributed learning paradigm that allows
multiple clients to jointly train a shared model while maintaining data
privacy. Despite its great potential for domains with strict data privacy
requirements, the presence of data imbalance among clients is a thread to the
success of FL, as it causes the performance of the shared model to decrease. To
address this, various studies have proposed enhancements to existing FL
strategies, particularly through client selection methods that mitigate the
detrimental effects of data imbalance. In this paper, we propose an extension
to existing FL strategies, which selects active clients that best align the
current label distribution with one of two target distributions, namely a
balanced distribution or the federations combined label distribution.
Subsequently, we empirically verify the improvements through our
distribution-controlled client selection on three common FL strategies and two
datasets. Our results show that while aligning the label distribution with a
balanced distribution yields the greatest improvements facing local imbalance,
alignment with the federation's combined label distribution is superior for
global imbalance.

</details>


### [260] [Improving Early Sepsis Onset Prediction Through Federated Learning](https://arxiv.org/abs/2509.20885)
*Christoph Düsing,Philipp Cimiano*

Main category: cs.LG

TL;DR: 提出了一种基于联邦学习的注意力增强LSTM模型，用于多中心ICU数据下的脓毒症早期预测，支持可变预测窗口，兼顾短期和长期预测，在保护隐私的同时提升了早期检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于各医院和ICU的数据量和多样性有限，传统机器学习在脓毒症早期预测中受限；同时需要保护患者隐私并实现跨机构协作建模。

Method: 采用联邦学习框架训练一个带有注意力机制的长短期记忆网络（LSTM），使用多中心ICU数据，并设计支持可变预测时间窗口的模型结构，以统一模型实现不同预测时距的脓毒症预警。

Result: 实验表明，该联邦学习方法不仅整体预测性能接近集中式训练模型，且特别有利于更早的脓毒症预测；采用可变预测窗口未显著降低性能，但减少了计算、通信和组织开销。

Conclusion: 联邦学习结合注意力增强LSTM和支持可变预测窗口的设计，能够在保护数据隐私的前提下有效提升脓毒症的早期预测能力，具有临床实用性和部署优势。

Abstract: Early and accurate prediction of sepsis onset remains a major challenge in
intensive care, where timely detection and subsequent intervention can
significantly improve patient outcomes. While machine learning models have
shown promise in this domain, their success is often limited by the amount and
diversity of training data available to individual hospitals and Intensive Care
Units (ICUs). Federated Learning (FL) addresses this issue by enabling
collaborative model training across institutions without requiring data
sharing, thus preserving patient privacy. In this work, we propose a federated,
attention-enhanced Long Short-Term Memory model for sepsis onset prediction,
trained on multi-centric ICU data. Unlike existing approaches that rely on
fixed prediction windows, our model supports variable prediction horizons,
enabling both short- and long-term forecasting in a single unified model.
During analysis, we put particular emphasis on the improvements through our
approach in terms of early sepsis detection, i.e., predictions with large
prediction windows by conducting an in-depth temporal analysis. Our results
prove that using FL does not merely improve overall prediction performance
(with performance approaching that of a centralized model), but is particularly
beneficial for early sepsis onset prediction. Finally, we show that our choice
of employing a variable prediction window rather than a fixed window does not
hurt performance significantly but reduces computational, communicational, and
organizational overhead.

</details>


### [261] [Deterministic Discrete Denoising](https://arxiv.org/abs/2509.20896)
*Hideyuki Suzuki,Hiroshi Yamashita*

Main category: cs.LG

TL;DR: 提出了一种基于马尔可夫链的离散状态扩散模型的确定性去噪算法，通过引入具有弱混沌动力学的集束算法变体实现去噪过程的确定化，无需重新训练或连续状态嵌入，在文本和图像生成任务中提升了效率和样本质量。


<details>
  <summary>Details</summary>
Motivation: 希望在不依赖随机性的前提下，提升离散状态扩散模型的生成效率与样本质量，并探索确定性反向过程在离散状态空间中的可行性。

Method: 采用具有弱混沌动力学的改进集束（herding）算法，构建确定性的离散状态转移机制，替代传统的随机去噪过程，且无需模型重训练或引入连续状态表示。

Result: 在文本和图像生成任务中，该方法相比随机去噪过程显著提高了生成效率和样本质量，验证了确定性反向过程在离散扩散模型中的有效性。

Conclusion: 确定性去噪策略可有效替代离散扩散模型中的随机过程，不仅简化了生成流程，还提升了性能，拓展了确定性方法在离散生成模型中的应用前景。

Abstract: We propose a deterministic denoising algorithm for discrete-state diffusion
models based on Markov chains. The generative reverse process is derandomized
by introducing a variant of the herding algorithm with weakly chaotic dynamics,
which induces deterministic discrete state transitions. Our approach is a
direct replacement for the stochastic denoising process, requiring neither
retraining nor continuous state embeddings. We demonstrate consistent
improvements in both efficiency and sample quality on text and image generation
tasks. Thus, this simple derandomization approach is expected to enhance the
significance of discrete diffusion in generative modeling. Furthermore, our
results reveal that deterministic reverse processes, well established in
continuous diffusion, can also be effective in discrete state spaces.

</details>


### [262] [Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales](https://arxiv.org/abs/2509.20913)
*Ariadna Albors Zumel,Michele Tizzoni,Gian Maria Campedelli*

Main category: cs.LG

TL;DR: 本研究提出了一种深度学习框架，结合微观移动性特征、历史犯罪数据和社会人口数据，用于细粒度时空尺度的犯罪预测。使用四个美国城市的网格化数据，基于ConvLSTM模型进行12小时犯罪预测，并与多种基线模型比较。结果表明，融合移动性和社会人口特征能显著提升预测性能，尤其在不同输入序列长度下对暴力犯罪和财产犯罪的预测效果更优。


<details>
  <summary>Details</summary>
Motivation: 为了提升细粒度时空尺度下犯罪预测的准确性，探索是否以及如何通过引入微观移动性特征并结合多源数据（如历史犯罪和社会人口数据）来增强预测模型的表现。

Method: 采用2019至2023年的犯罪事件数据、美国社区调查的社会人口数据以及Advan的人类移动性数据，将四个美国城市的数据划分为0.077平方英里大小的网格单元，训练基于ConvLSTM的深度学习模型，使用14天和2天的输入序列预测未来12小时的犯罪发生情况，并与逻辑回归、随机森林和标准LSTM等基线模型进行对比。

Result: 引入移动性特征可提升预测性能，尤其在较短输入序列下效果明显；结合移动性和社会人口特征时表现最佳，ConvLSTM在四个城市中均取得最高的召回率、精确率和F1分数。较长输入序列有助于暴力犯罪预测，较短序列更适用于财产犯罪预测。

Conclusion: 研究结果强调了在时空犯罪预测中整合多源数据（特别是移动性数据）的重要性，同时揭示了深度学习方法在细粒度时空尺度下的优势与局限性。

Abstract: Objectives: To develop a deep learning framework to evaluate if and how
incorporating micro-level mobility features, alongside historical crime and
sociodemographic data, enhances predictive performance in crime forecasting at
fine-grained spatial and temporal resolutions.
  Methods: We advance the literature on computational methods and crime
forecasting by focusing on four U.S. cities (i.e., Baltimore, Chicago, Los
Angeles, and Philadelphia). We employ crime incident data obtained from each
city's police department, combined with sociodemographic data from the American
Community Survey and human mobility data from Advan, collected from 2019 to
2023. This data is aggregated into grids with equally sized cells of 0.077 sq.
miles (0.2 sq. kms) and used to train our deep learning forecasting model, a
Convolutional Long Short-Term Memory (ConvLSTM) network, which predicts crime
occurrences 12 hours ahead using 14-day and 2-day input sequences. We also
compare its performance against three baseline models: logistic regression,
random forest, and standard LSTM.
  Results: Incorporating mobility features improves predictive performance,
especially when using shorter input sequences. Noteworthy, however, the best
results are obtained when both mobility and sociodemographic features are used
together, with our deep learning model achieving the highest recall, precision,
and F1 score in all four cities, outperforming alternative methods. With this
configuration, longer input sequences enhance predictions for violent crimes,
while shorter sequences are more effective for property crimes.
  Conclusion: These findings underscore the importance of integrating diverse
data sources for spatiotemporal crime forecasting, mobility included. They also
highlight the advantages (and limits) of deep learning when dealing with
fine-grained spatial and temporal scales.

</details>


### [263] [Energy saving in off-road vehicles using leakage compensation technique](https://arxiv.org/abs/2509.20926)
*Gyan Wrat,J. Das*

Main category: cs.LG

TL;DR: 本文提出了一种基于比例流量控制阀（PFCV）并结合人工泄漏的液压回路，用于提升重型土方设备中线性执行器的能量效率，相较于传统比例方向控制阀（PDCV）方案能提高8.5%的能效，并采用模糊PID控制器实现位置控制，仿真与实验结果验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为降低重型土方设备液压系统能耗高、发热严重的问题，提升能量利用效率，减少环境影响和运行成本。

Method: 比较两种液压回路：一种采用传统的比例方向控制阀（PDCV），另一种采用带人工泄漏的比例流量控制阀（PFCV）；通过MATLAB/Simulink进行系统建模与仿真，并采用模糊调参的PID控制器实现执行器位置控制，最后与实验结果对比验证。

Result: 采用PFCV的液压回路比传统PDCV回路能量效率提高8.5%，有效减少了泵多余流量导致的热能损耗，且位置控制响应良好。

Conclusion: 所提出的PFCV结合人工泄漏和模糊PID控制的方案可显著提升重型设备线性执行器的能量效率，具有良好的节能潜力和应用前景。

Abstract: The article focuses on enhancing the energy efficiency of linear actuators
used in heavy earth moving equipment, particularly in the booms ofexcavation
equipment. Two hydraulic circuits are compared in terms of energy efficiency,
with one using a conventional proportional directionalcontrol valve (PDCV) and
the other using an innovative solution of proportional flow control valve
(PFCV) with artificial leakage between thetwo ends of the actuator. The PFCV
reduces energy loss in the form of heat by bypassing the extra flow from the
pump during position control,unlike the PDCV that uses a pressure relief valve.
The hydraulic circuit using PFCV is found to be 8.5% more energy efficient than
theconventional circuit using PDCV. The article also discusses the position
control of the actuator, which is achieved using a PID controller tuned by a
fuzzy controller. Thesimulation of the hydraulic circuit is carried out using
MATLAB/Simulink, and the results are compared with experiments. Overall, the
proposedapproach could lead to significant improvements in the energy
efficiency of linear actuators used in heavy earth moving equipment,
therebyreducing their environmental impact and operating costs.

</details>


### [264] [GenFacts-Generative Counterfactual Explanations for Multi-Variate Time Series](https://arxiv.org/abs/2509.20936)
*Sarah Seifi,Anass Ibrahimi,Tobias Sukianto,Cecilia Carbonelli,Lorenzo Servadei,Robert Wille*

Main category: cs.LG

TL;DR: GenFacts是一种基于类别判别性变分自编码器的生成框架，用于为多变量时间序列生成更合理、可解释的反事实解释，在雷达手势和手写字符轨迹数据上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释方法在多变量时间序列上常生成无效、不真实或反直觉的结果，缺乏用户可操作性和可信度。

Method: 提出GenFacts框架，结合对比学习与分类一致性目标，采用原型初始化和现实性约束优化，在变分自编码器中生成高质量反事实实例。

Result: 在雷达手势和手写字母轨迹数据集上，GenFacts比现有方法在合理性上提升18.7%，并在人类实验中获得最高可解释性评分。

Conclusion: 时间序列反事实解释的关键在于合理性和用户中心的可解释性，而非单纯的稀疏性，GenFacts为此提供了有效解决方案。

Abstract: Counterfactual explanations aim to enhance model transparency by showing how
inputs can be minimally altered to change predictions. For multivariate time
series, existing methods often generate counterfactuals that are invalid,
implausible, or unintuitive. We introduce GenFacts, a generative framework
based on a class-discriminative variational autoencoder. It integrates
contrastive and classification-consistency objectives, prototype-based
initialization, and realism-constrained optimization. We evaluate GenFacts on
radar gesture data as an industrial use case and handwritten letter
trajectories as an intuitive benchmark. Across both datasets, GenFacts
outperforms state-of-the-art baselines in plausibility (+18.7%) and achieves
the highest interpretability scores in a human study. These results highlight
that plausibility and user-centered interpretability, rather than sparsity
alone, are key to actionable counterfactuals in time series data.

</details>


### [265] [Why Attention Fails: The Degeneration of Transformers into MLPs in Time Series Forecasting](https://arxiv.org/abs/2509.20942)
*Zida Liang,Jiayi Zhu,Weiqiang Sun*

Main category: cs.LG

TL;DR: 本文研究了Transformer在时间序列预测中表现不佳的原因，发现其注意力机制未能按预期工作，且当前的嵌入方法导致Transformer退化为简单的MLP。


<details>
  <summary>Details</summary>
Motivation: 理解为何Transformer在时间序列预测中未表现出优势，甚至不如简单线性模型。

Method: 通过逐步将Transformer修改为MLP，并设计可解释数据集来分析注意力机制失效的原因。

Result: 发现现有时间序列Transformer中注意力机制未能有效运作，Transformer块常退化为MLP；理论分析表明当前嵌入方法无法构建良好结构的潜在空间。

Conclusion: 时间序列Transformer性能受限的主要原因是嵌入方法不足，导致注意力机制失效和模型退化。

Abstract: Transformer-based architectures achieved high performance in natural language
processing and computer vision, yet many studies have shown that they have not
demonstrated a clear advantage in time series forecasting and even underperform
simple linear baselines in some cases. However, most of these studies have not
thoroughly explored the reasons behind the failure of transformers. To better
understand time-series transformers(TST), we designed a series of experiments,
progressively modifying transformers into MLPs to investigate the impact of the
attention mechanism. Surprisingly, transformer blocks often degenerate into
simple MLPs in existing time-series transformers. We designed a interpretable
dataset to investigate the reasons behind the failure of the attention
mechanism and revealed that the attention mechanism is not working in the
expected way. We theoretically analyzed the reasons behind this phenomenon,
demonstrating that the current embedding methods fail to allow transformers to
function in a well-structured latent space, and further analyzed the deeper
underlying causes of the failure of embedding.

</details>


### [266] [Decoupled-Value Attention for Prior-Data Fitted Networks: GP Inference for Physical Equations](https://arxiv.org/abs/2509.20950)
*Kaustubh Sharma,Simardeep Singh,Parikshit Pareek*

Main category: cs.LG

TL;DR: 本文提出了一种名为Decoupled-Value Attention (DVA) 的新注意力机制，用于提升Prior-data Fitted Networks (PFNs)在高维回归任务中的性能。DVA通过解耦输入相似性和标签传播，模拟高斯过程更新，同时无需显式核函数。实验表明，注意力机制的设计比网络架构本身更为关键，且局部注意力显著降低验证损失，使PFNs在64维电力系统方程逼近中达到1E-3量级的平均绝对误差，并比精确高斯过程推断快80倍以上。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer注意力机制下的PFNs在高维回归任务中表现有限，而高斯过程（GP）虽有效但计算昂贵。本文旨在通过设计更符合GP特性的注意力机制来提升PFNs的扩展性与效率。

Method: 提出Decoupled-Value Attention (DVA)，仅用输入计算注意力相似性，仅通过值传递标签，从而模拟高斯过程的预测机制。同时比较不同注意力形式与骨干网络（如CNN与Transformer）对PFNs性能的影响。

Result: DVA显著提升PFNs在高维任务中的表现：在五维和十维情况下验证损失降低超过50%；局部注意力效果优于全局；CNN架构结合DVA可媲美Transformer性能；在64维电力流方程逼近中实现约1E-3的MAE，且推理速度比GP快80倍以上。

Conclusion: 注意力机制的设计是扩展PFNs的关键因素，DVA通过模仿高斯过程的结构特性，在不依赖核函数的情况下显著提升PFNs在高维回归任务中的效率与精度，为物理系统建模提供了高效替代方案。

Abstract: Prior-data fitted networks (PFNs) are a promising alternative to
time-consuming Gaussian Process (GP) inference for creating fast surrogates of
physical systems. PFN reduces the computational burden of GP-training by
replacing Bayesian inference in GP with a single forward pass of a learned
prediction model. However, with standard Transformer attention, PFNs show
limited effectiveness on high-dimensional regression tasks. We introduce
Decoupled-Value Attention (DVA)-- motivated by the GP property that the
function space is fully characterized by the kernel over inputs and the
predictive mean is a weighted sum of training targets. DVA computes
similarities from inputs only and propagates labels solely through values.
Thus, the proposed DVA mirrors the Gaussian-process update while remaining
kernel-free. We demonstrate that the crucial factor for scaling PFNs is the
attention rule rather than the architecture itself. Specifically, our results
demonstrate that (a) localized attention consistently reduces out-of-sample
validation loss in PFNs across different dimensional settings, with validation
loss reduced by more than 50% in five- and ten-dimensional cases, and (b) the
role of attention is more decisive than the choice of backbone architecture,
showing that CNN-based PFNs can perform at par with their Transformer-based
counterparts. The proposed PFNs provide 64-dimensional power flow equation
approximations with a mean absolute error of the order of 1E-3, while being
over 80x faster than exact GP inference.

</details>


### [267] [Flow Matching in the Low-Noise Regime: Pathologies and a Contrastive Remedy](https://arxiv.org/abs/2509.20952)
*Weili Zeng,Yichao Yan*

Main category: cs.LG

TL;DR: 本文提出了一种称为低噪声病理的现象，揭示了流匹配在低噪声条件下存在的不稳定性问题，并提出了局部对比流（LCF）方法以改善训练收敛性和表示质量。


<details>
  <summary>Details</summary>
Motivation: 流匹配虽然在生成建模和表示学习中表现出色，但在低噪声情况下存在训练不稳定的问题，影响模型性能，因此需要深入分析并解决这一根本性缺陷。

Method: 通过理论分析揭示流匹配目标函数在低噪声下的病态特性，提出局部对比流（LCF），在小噪声水平下用对比特征对齐替代直接速度回归，在中高噪声下保留标准流匹配。

Result: LCF显著提升了训练收敛速度，并稳定了语义表示质量，实验证明其在生成与表示学习中的有效性。

Conclusion: 低噪声病理是流匹配中的核心问题，采用混合训练策略如LCF可有效缓解该问题，为提升流匹配模型性能提供了新方向。

Abstract: Flow matching has recently emerged as a powerful alternative to diffusion
models, providing a continuous-time formulation for generative modeling and
representation learning. Yet, we show that this framework suffers from a
fundamental instability in the low-noise regime. As noise levels approach zero,
arbitrarily small perturbations in the input can induce large variations in the
velocity target, causing the condition number of the learning problem to
diverge. This ill-conditioning not only slows optimization but also forces the
encoder to reallocate its limited Jacobian capacity toward noise directions,
thereby degrading semantic representations. We provide the first theoretical
analysis of this phenomenon, which we term the low-noise pathology,
establishing its intrinsic link to the structure of the flow matching
objective. Building on these insights, we propose Local Contrastive Flow (LCF),
a hybrid training protocol that replaces direct velocity regression with
contrastive feature alignment at small noise levels, while retaining standard
flow matching at moderate and high noise. Empirically, LCF not only improves
convergence speed but also stabilizes representation quality. Our findings
highlight the critical importance of addressing low-noise pathologies to unlock
the full potential of flow matching for both generation and representation
learning.

</details>


### [268] [Alignment Unlocks Complementarity: A Framework for Multiview Circuit Representation Learning](https://arxiv.org/abs/2509.20968)
*Zhengyuan Shi,Jingxin Wang,Wentao Jiang,Chengyu Ma,Ziyang Zheng,Zhufei Chu,Weikang Qian,Qiang Xu*

Main category: cs.LG

TL;DR: 本文提出MixGate框架，通过先对齐不同视图的函数表示，再进行多视图掩码建模，有效解决了布尔电路中多视图自监督学习的融合难题。


<details>
  <summary>Details</summary>
Motivation: 不同图表示（如AIG与XMG）在结构上差异巨大，直接应用自监督掩码建模会将跨视图信息视为噪声，导致融合失败。

Method: 引入功能对齐作为前提，设计等价性对齐损失（Equivalence Alignment Loss），构建分阶段训练流程：先学习共享的函数感知表示空间，再进行多视图掩码建模。

Result: 实验表明，该对齐优先策略使掩码建模从无效变为高效，显著提升性能，并通过消融研究验证了其关键作用。

Conclusion: 功能对齐是释放多视图自监督学习潜力的关键，MixGate为布尔电路的多视图学习提供了有效解决方案。

Abstract: Multiview learning on Boolean circuits holds immense promise, as different
graph-based representations offer complementary structural and semantic
information. However, the vast structural heterogeneity between views, such as
an And-Inverter Graph (AIG) versus an XOR-Majority Graph (XMG), poses a
critical barrier to effective fusion, especially for self-supervised techniques
like masked modeling. Naively applying such methods fails, as the cross-view
context is perceived as noise. Our key insight is that functional alignment is
a necessary precondition to unlock the power of multiview self-supervision. We
introduce MixGate, a framework built on a principled training curriculum that
first teaches the model a shared, function-aware representation space via an
Equivalence Alignment Loss. Only then do we introduce a multiview masked
modeling objective, which can now leverage the aligned views as a rich,
complementary signal. Extensive experiments, including a crucial ablation
study, demonstrate that our alignment-first strategy transforms masked modeling
from an ineffective technique into a powerful performance driver.

</details>


### [269] [Knowledgeable Language Models as Black-Box Optimizers for Personalized Medicine](https://arxiv.org/abs/2509.20975)
*Michael S. Yao,Osbert Bastani,Alma Andersson,Tommaso Biancalani,Aïcha Bentaieb,Claudia Iriondo*

Main category: cs.LG

TL;DR: 本文提出了一种名为LEON的新方法，利用大语言模型（LLM）结合领域先验知识（如医学教科书和生物医学知识图谱），通过“提示优化”策略在无需微调的情况下生成个性化治疗方案，实验表明其在真实世界任务中优于传统及现有LLM方法。


<details>
  <summary>Details</summary>
Motivation: 由于现有体外（in silico）代理模型难以泛化到未见过的患者-治疗组合，且无法对患者随意尝试候选治疗，因此需要一种能有效利用领域知识来评估治疗方案适应性的新方法。

Method: 提出LEON方法，基于大语言模型进行熵引导的优化，通过引入医学文本和知识图谱等先验知识作为补充信号，采用‘提示优化’方式将LLM用作随机治疗设计生成引擎，实现无需微调的黑箱优化。

Result: 在真实世界的优化任务中，LEON在推荐个性化治疗方案方面优于传统方法和现有的基于LLM的方法，展现出更强的泛化能力和优化性能。

Conclusion: LEON能够有效利用大语言模型中的领域知识，在缺乏直接实验反馈的情况下为个性化医疗提供可靠、高效的治疗方案推荐，展示了LLM作为优化工具在精准医疗中的潜力。

Abstract: The goal of personalized medicine is to discover a treatment regimen that
optimizes a patient's clinical outcome based on their personal genetic and
environmental factors. However, candidate treatments cannot be arbitrarily
administered to the patient to assess their efficacy; we often instead have
access to an in silico surrogate model that approximates the true fitness of a
proposed treatment. Unfortunately, such surrogate models have been shown to
fail to generalize to previously unseen patient-treatment combinations. We
hypothesize that domain-specific prior knowledge - such as medical textbooks
and biomedical knowledge graphs - can provide a meaningful alternative signal
of the fitness of proposed treatments. To this end, we introduce LLM-based
Entropy-guided Optimization with kNowledgeable priors (LEON), a mathematically
principled approach to leverage large language models (LLMs) as black-box
optimizers without any task-specific fine-tuning, taking advantage of their
ability to contextualize unstructured domain knowledge to propose personalized
treatment plans in natural language. In practice, we implement LEON via
'optimization by prompting,' which uses LLMs as stochastic engines for
proposing treatment designs. Experiments on real-world optimization tasks show
LEON outperforms both traditional and LLM-based methods in proposing
individualized treatments for patients.

</details>


### [270] [CLUE: Conflict-guided Localization for LLM Unlearning Framework](https://arxiv.org/abs/2509.20977)
*Hang Chen,Jiaying Zhu,Xinyu Yang,Wenya Wang*

Main category: cs.LG

TL;DR: 本文提出了一种基于电路发现的LLM去学习框架CLUE，通过冲突引导的定位识别遗忘和保留电路，并利用CNF可满足性求解实现神经元的精确分类与干预，显著提升了遗忘效果和保留能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于定位的去学习方法未能区分负责遗忘和保留知识的神经元，导致过度遗忘或遗忘不彻底的问题。

Method: 引入电路发现技术，提出CLUE框架，将遗忘和保留电路转化为合取范式（CNF），通过CNF可满足性求解确定神经元的角色，并对不同类别的神经元实施针对性微调策略。

Result: 实验表明，CLUE在遗忘效果和保留能力方面均优于现有定位方法，实现了更精确的神经元定位与干预。

Conclusion: CLUE通过机制可解释性手段有效分离遗忘与保留电路，为大模型去学习提供了更精细、有效的解决方案。

Abstract: The LLM unlearning aims to eliminate the influence of undesirable data
without affecting causally unrelated information. This process typically
involves using a forget set to remove target information, alongside a retain
set to maintain non-target capabilities. While recent localization-based
methods demonstrate promise in identifying important neurons to be unlearned,
they fail to disentangle neurons responsible for forgetting undesirable
knowledge or retaining essential skills, often treating them as a single
entangled group. As a result, these methods apply uniform interventions,
risking catastrophic over-forgetting or incomplete erasure of the target
knowledge. To address this, we turn to circuit discovery, a mechanistic
interpretability technique, and propose the Conflict-guided Localization for
LLM Unlearning framEwork (CLUE). This framework identifies the forget and
retain circuit composed of important neurons, and then the circuits are
transformed into conjunctive normal forms (CNF). The assignment of each neuron
in the CNF satisfiability solution reveals whether it should be forgotten or
retained. We then provide targeted fine-tuning strategies for different
categories of neurons. Extensive experiments demonstrate that, compared to
existing localization methods, CLUE achieves superior forget efficacy and
retain utility through precise neural localization.

</details>


### [271] [FracAug: Fractional Augmentation boost Graph-level Anomaly Detection under Limited Supervision](https://arxiv.org/abs/2509.20978)
*Xiangyu Dong,Xingyi Zhang,Sibo Wang*

Main category: cs.LG

TL;DR: 提出FracAug框架，通过生成语义一致的图变体和互验证伪标签来提升图神经网络在图级异常检测中的性能。


<details>
  <summary>Details</summary>
Motivation: 高标注成本和数据集不平衡限制了图神经网络在图级异常检测中的表现。

Method: FracAug学习图内语义，生成多尺度拓扑感知的分数变体，并通过加权距离感知边界损失指导生成过程；利用原始图和增强图的预测结果进行伪标签化，迭代扩展训练集。

Result: 在12个真实世界数据集上的14种GNN模型中，FracAug平均AUROC、AUPRC和F1-score最高提升5.72%、7.23%和4.18%。

Conclusion: FracAug是一种通用、有效的即插即用增强框架，显著提升了图神经网络在图级异常检测任务中的性能，且不受数据不平衡影响。

Abstract: Graph-level anomaly detection (GAD) is critical in diverse domains such as
drug discovery, yet high labeling costs and dataset imbalance hamper the
performance of Graph Neural Networks (GNNs). To address these issues, we
propose FracAug, an innovative plug-in augmentation framework that enhances
GNNs by generating semantically consistent graph variants and pseudo-labeling
with mutual verification. Unlike previous heuristic methods, FracAug learns
semantics within given graphs and synthesizes fractional variants, guided by a
novel weighted distance-aware margin loss. This captures multi-scale topology
to generate diverse, semantic-preserving graphs unaffected by data imbalance.
Then, FracAug utilizes predictions from both original and augmented graphs to
pseudo-label unlabeled data, iteratively expanding the training set. As a
model-agnostic module compatible with various GNNs, FracAug demonstrates
remarkable universality and efficacy: experiments across 14 GNNs on 12
real-world datasets show consistent gains, boosting average AUROC, AUPRC, and
F1-score by up to 5.72%, 7.23%, and 4.18%, respectively.

</details>


### [272] [Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models](https://arxiv.org/abs/2506.00209)
*Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong*

Main category: cs.LG

TL;DR: CATCH-FM是一种基于电子健康记录（EHR）的癌症早期风险预测方法，利用大规模预训练的医疗编码序列基础模型，实现对高风险患者的精准识别，尤其在胰腺癌预测上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有癌症筛查方法成本高、侵入性强且普及率低，导致许多本可避免的死亡。需要一种低成本、非侵入性、可扩展的预筛查工具，以提高早期检测覆盖率。

Method: 基于数百万电子健康记录，建立EHR基础模型的缩放规律，训练高达24亿参数的计算最优基础模型，并在医生标注的癌症风险队列上进行微调，使用ICD编码序列作为输入进行风险预测。

Result: 在三万名患者的回顾性评估中，CATCH-FM实现了60%的敏感性和99%的特异性及阴性预测值，显著优于基于特征的树模型以及通用和医学大语言模型，并在EHRSHOT少样本排行榜上取得胰腺癌预测的最先进性能。

Conclusion: CATCH-FM展示了基于EHR基础模型进行大规模癌症预筛查的可行性与鲁棒性，能够在不同人群分布和医疗系统下有效识别癌症高风险患者，具有广泛的临床应用前景。

Abstract: Cancer screening, leading to early detection, saves lives. Unfortunately,
existing screening techniques require expensive and intrusive medical
procedures, not globally available, resulting in too many lost would-be-saved
lives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation
Models, a cancer pre-screening methodology that identifies high-risk patients
for further screening solely based on their historical medical records. With
millions of electronic healthcare records (EHR), we establish the scaling law
of EHR foundation models pretrained on medical code sequences, pretrain
compute-optimal foundation models of up to 2.4 billion parameters, and finetune
them on clinician-curated cancer risk prediction cohorts. In our retrospective
evaluation comprising of thirty thousand patients, CATCH-FM achieved strong
efficacy (60% sensitivity) with low risk (99% specificity and Negative
Predictive Value), outperforming feature-based tree models as well as general
and medical large language models by large margins. Despite significant
demographic, healthcare system, and EHR coding differences, CATCH-FM achieves
state-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot
leaderboard, outperforming EHR foundation models pretrained using on-site
patient data. Our analysis demonstrates the robustness of CATCH-FM in various
patient distributions, the benefits of operating in the ICD code space, and its
ability to capture non-trivial cancer risk factors. Our code will be
open-sourced.

</details>


### [273] [Toward Robust and Efficient ML-Based GPU Caching for Modern Inference](https://arxiv.org/abs/2509.20979)
*Peng Chen,Jiaji Zhang,Hailiang Zhao,Yirong Zhang,Jiahong Yu,Xueyan Tang,Yixuan Wang,Hao Li,Jianping Zou,Gang Xiong,Kingsum Chow,Shuibing He,Shuiguang Deng*

Main category: cs.LG

TL;DR: 本文提出了LCR，一种实用的基于学习的GPU缓存框架，通过核心算法LARU结合机器学习预测和在线误差估计，在预测准确时接近最优性能，预测不准确时也能优雅降级至接近LRU的性能，显著提升了推荐模型和大语言模型的吞吐量并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 现代GPU推理中，缓存效率是主要瓶颈，传统LRU等启发式策略在结构化访问模式下表现不佳，而现有基于学习的方法在预测不准时性能急剧下降或设计过于保守，难以实用。

Method: 提出LCR框架及其核心算法LARU，增强LRU以融入机器学习预测，并通过在线误差估计动态调整策略，确保在不同预测准确性下的鲁棒性和高效性。

Result: 实验表明，LCR在DLRM和LLM场景下最高提升24.2%吞吐量，降低P99 TTFT达28.3%，且在预测不准时性能稳定，优于主流推理系统。

Conclusion: LCR有效弥合了基于学习的缓存算法在理论进展与实际应用之间的差距，兼具高性能、强鲁棒性和低开销，具有广泛实用性。

Abstract: In modern GPU inference, cache efficiency remains a major bottleneck. In
recommendation models, embedding hit rates largely determine throughput, while
in large language models, KV-cache misses substantially increase
time-to-first-token (TTFT). Heuristic policies such as \textsc{LRU} often
struggle under structured access patterns. Learning-based approaches are
promising, but in practice face two major limitations: they degrade sharply
when predictions are inaccurate, or they gain little even with accurate
predictions due to conservative designs. Some also incur high overhead, further
limiting practicality.
  We present \textsc{LCR}, a practical framework for learning-based GPU caching
that delivers performance gains while ensuring robustness and efficiency. Its
core algorithm, \textsc{LARU}, enhances \textsc{LRU} with machine-learned
predictions and dynamically adapts to prediction accuracy through online error
estimation. When predictions are accurate, \textsc{LARU} achieves near-optimal
performance. With inaccurate predictions, it degrades gracefully to
near-\textsc{LRU} performance. With \textsc{LCR}, we bridge the gap between
empirical progress and theoretical advances in learning-based caching.
  Experiments show that \textsc{LCR} delivers consistent gains under realistic
conditions. In DLRM and LLM scenarios, it improves throughput by up to 24.2\%
and reduces P99 TTFT by up to 28.3\%, outperforming widely used inference
systems. Even under poor predictions, its performance remains stable,
demonstrating practical robustness.

</details>


### [274] [Learning Ising Models under Hard Constraints using One Sample](https://arxiv.org/abs/2509.20993)
*Rohan Chauhan,Ioannis Panageas*

Main category: cs.LG

TL;DR: 提出了一种基于伪似然最大化的估计方法，在近线性时间内对具有k-SAT约束的截断Ising模型的逆温度参数β进行高效估计，证明了在特定条件下估计量的相合性。


<details>
  <summary>Details</summary>
Motivation: 在存在复杂约束（如k-SAT）的情况下，传统方法难以有效估计Ising模型的逆温度参数β，因此需要设计适用于截断Ising模型且计算高效的估计方法。

Method: 采用伪似然最大化方法，结合有界度图结构和k-SAT表示的截断集S，在单一样本下构造逆温度参数β的估计量，并分析其一致性。

Result: 设计了一个运行时间为近O(n)的估计器\hat{\beta}，证明其在k \gtrsim \log(d^2k)\Delta^3条件下是O(\Delta^3/\sqrt{n})-相合的。

Conclusion: 该方法成功扩展了现有技术，适用于更复杂的截断Ising模型，在合理假设下实现了对逆温度参数的高效一致估计。

Abstract: We consider the problem of estimating inverse temperature parameter $\beta$
of an $n$-dimensional truncated Ising model using a single sample. Given a
graph $G = (V,E)$ with $n$ vertices, a truncated Ising model is a probability
distribution over the $n$-dimensional hypercube $\{-1,1\}^n$ where each
configuration $\mathbf{\sigma}$ is constrained to lie in a truncation set $S
\subseteq \{-1,1\}^n$ and has probability $\Pr(\mathbf{\sigma}) \propto
\exp(\beta\mathbf{\sigma}^\top A\mathbf{\sigma})$ with $A$ being the adjacency
matrix of $G$. We adopt the recent setting of [Galanis et al. SODA'24], where
the truncation set $S$ can be expressed as the set of satisfying assignments of
a $k$-SAT formula. Given a single sample $\mathbf{\sigma}$ from a truncated
Ising model, with inverse parameter $\beta^*$, underlying graph $G$ of bounded
degree $\Delta$ and $S$ being expressed as the set of satisfying assignments of
a $k$-SAT formula, we design in nearly $O(n)$ time an estimator $\hat{\beta}$
that is $O(\Delta^3/\sqrt{n})$-consistent with the true parameter $\beta^*$ for
$k \gtrsim \log(d^2k)\Delta^3.$
  Our estimator is based on the maximization of the pseudolikelihood, a notion
that has received extensive analysis for various probabilistic models without
[Chatterjee, Annals of Statistics '07] or with truncation [Galanis et al. SODA
'24]. Our approach generalizes recent techniques from [Daskalakis et al. STOC
'19, Galanis et al. SODA '24], to confront the more challenging setting of the
truncated Ising model.

</details>


### [275] [Binary Autoencoder for Mechanistic Interpretability of Large Language Models](https://arxiv.org/abs/2509.20997)
*Hakaze Cho,Haolin Yang,Brian M. Kurkoski,Naoya Inoue*

Main category: cs.LG

TL;DR: 提出一种新的二值自编码器（BAE），通过在 minibatch 上施加最小熵约束来增强特征的独立性和跨实例稀疏性，有效提升大语言模型中特征解耦和解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于单个训练实例上的隐式正则化，缺乏实例间的全局稀疏性保证，导致大量密集特征，影响特征稀疏性和原子化。

Method: 提出二值自编码器（BAE），对隐藏激活进行1比特量化并采用梯度估计实现反向传播，通过在minibatch上施加最小熵约束以促进特征独立与跨实例稀疏性。

Result: BAE能可靠估计二值化隐藏激活的熵，用于刻画LLM和上下文学习的推理动态；在特征解耦任务中避免了密集特征，并产生最多可解释特征，优于基线方法。

Conclusion: BAE能有效提升特征稀疏性与独立性，在特征提取与解释方面优于传统方法，验证了其作为大模型特征解耦工具的有效性。

Abstract: Existing works are dedicated to untangling atomized numerical components
(features) from the hidden states of Large Language Models (LLMs) for
interpreting their mechanism. However, they typically rely on autoencoders
constrained by some implicit training-time regularization on single training
instances (i.e., $L_1$ normalization, top-k function, etc.), without an
explicit guarantee of global sparsity among instances, causing a large amount
of dense (simultaneously inactive) features, harming the feature sparsity and
atomization. In this paper, we propose a novel autoencoder variant that
enforces minimal entropy on minibatches of hidden activations, thereby
promoting feature independence and sparsity across instances. For efficient
entropy calculation, we discretize the hidden activations to 1-bit via a step
function and apply gradient estimation to enable backpropagation, so that we
term it as Binary Autoencoder (BAE) and empirically demonstrate two major
applications: (1) Feature set entropy calculation. Entropy can be reliably
estimated on binary hidden activations, which we empirically evaluate and
leverage to characterize the inference dynamics of LLMs and In-context
Learning. (2) Feature untangling. Similar to typical methods, BAE can extract
atomized features from LLM's hidden states. To robustly evaluate such feature
extraction capability, we refine traditional feature-interpretation methods to
avoid unreliable handling of numerical tokens, and show that BAE avoids dense
features while producing the largest number of interpretable ones among
baselines, which confirms the effectiveness of BAE serving as a feature
extractor.

</details>


### [276] [Feature Augmentation of GNNs for ILPs: Local Uniqueness Suffices](https://arxiv.org/abs/2509.21000)
*Qingyu Han,Qian Li,Linxin Yang,Qian Chen,Qingjiang Shi,Ruoyu Sun*

Main category: cs.LG

TL;DR: 提出了一种基于d-hop唯一性着色的局部UID方案（Local-UID），结合ColorGNN和ColorUID方法，在保持表达能力的同时提升整数线性规划（ILP）求解的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 标准匿名图神经网络在处理ILP时表达能力有限，而引入全局唯一标识符（UID）虽增强表达力但易导致过拟合和泛化能力下降。

Method: 提出Local-UID方案，确保节点ID仅在其d-hop邻域内唯一，并设计ColorGNN（通过颜色条件嵌入）和ColorUID（轻量级特征变体）模型。理论上证明了d层网络下Local-UID与Global-UID具有相同表达力但更强泛化性。

Result: 实验表明该方法在三个ILP基准上显著提升性能，在线性规划数据集上表现出强OOD泛化能力，并能进一步提升图级别任务的性能。

Conclusion: Local-UID方案在不牺牲表达能力的前提下有效缓解了传统UID带来的泛化问题，为基于GNN的ILP求解提供了更优的架构选择。

Abstract: Integer Linear Programs (ILPs) are central to real-world optimizations but
notoriously difficult to solve. Learning to Optimize (L2O) has emerged as a
promising paradigm, with Graph Neural Networks (GNNs) serving as the standard
backbone. However, standard anonymous GNNs are limited in expressiveness for
ILPs, and the common enhancement of augmenting nodes with globally unique
identifiers (UIDs) typically introduces spurious correlations that severely
harm generalization. To address this tradeoff, we propose a parsimonious
Local-UID scheme based on d-hop uniqueness coloring, which ensures identifiers
are unique only within each node's d-hop neighborhood. Building on this scheme,
we introduce ColorGNN, which incorporates color information via
color-conditioned embeddings, and ColorUID, a lightweight feature-level
variant. We prove that for d-layer networks, Local-UIDs achieve the expressive
power of Global-UIDs while offering stronger generalization. Extensive
experiments show that our approach (i) yields substantial gains on three ILP
benchmarks, (ii) exhibits strong OOD generalization on linear programming
datasets, and (iii) further improves a general graph-level task when paired
with a state-of-the-art method.

</details>


### [277] [Lossless Compression: A New Benchmark for Time Series Model Evaluation](https://arxiv.org/abs/2509.21002)
*Meng Wan,Benxi Tian,Jue Wang,Cui Hui,Ningming Nie,Tiantian Liu,Zongguo Wang,Cao Rongqiang,Peng Shi,Yangang Wang*

Main category: cs.LG

TL;DR: 本文提出了无损压缩作为时间序列模型评估的新范式，基于香农信源编码定理，将最优压缩长度与负对数似然等价，提供了一个严格且统一的信息论评估标准，并设计了TSCom-Bench框架验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列评估任务（如预测、插补、异常检测和分类）主要关注特定任务性能，难以全面衡量模型对数据生成分布的捕捉能力，因此需要一种更根本的评估方式。

Method: 基于信息论提出将无损压缩作为评估标准，建立压缩长度与负对数似然之间的理论联系，设计标准化评估协议，并开发开源框架TSCom-Bench，使现有时间序列模型可快速适配为压缩骨干网络。

Result: 在多个数据集上对TimeXer、iTransformer和PatchTST等先进模型的实验表明，无损压缩能揭示传统基准忽略的模型在分布建模上的缺陷。

Conclusion: 无损压缩是一种有原则的时间序列模型评估任务，能够补充并扩展现有的评估体系，更严格地反映模型的建模能力。

Abstract: The evaluation of time series models has traditionally focused on four
canonical tasks: forecasting, imputation, anomaly detection, and
classification. While these tasks have driven significant progress, they
primarily assess task-specific performance and do not rigorously measure
whether a model captures the full generative distribution of the data. We
introduce lossless compression as a new paradigm for evaluating time series
models, grounded in Shannon's source coding theorem. This perspective
establishes a direct equivalence between optimal compression length and the
negative log-likelihood, providing a strict and unified information-theoretic
criterion for modeling capacity. Then We define a standardized evaluation
protocol and metrics. We further propose and open-source a comprehensive
evaluation framework TSCom-Bench, which enables the rapid adaptation of time
series models as backbones for lossless compression. Experiments across diverse
datasets on state-of-the-art models, including TimeXer, iTransformer, and
PatchTST, demonstrate that compression reveals distributional weaknesses
overlooked by classic benchmarks. These findings position lossless compression
as a principled task that complements and extends existing evaluation for time
series modeling.

</details>


### [278] [MAIFormer: Multi-Agent Inverted Transformer for Flight Trajectory Prediction](https://arxiv.org/abs/2509.21004)
*Seokbin Yoon,Keumjin Lee*

Main category: cs.LG

TL;DR: 提出了一种名为MAIFormer的多智能体倒置Transformer模型，用于预测多架飞机的飞行轨迹，通过两种注意力机制有效捕捉个体行为和交互模式，并在真实数据集上表现出优异性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 预测多智能体飞行轨迹具有挑战性，需同时建模个体行为和复杂交互，并生成可解释的预测结果。

Method: 设计了MAIFormer神经网络架构，包含掩码多变量注意力模块（捕捉个体时空模式）和智能体注意力模块（建模多智能体社会交互模式）。

Result: 在韩国仁川国际机场的真实飞行轨迹数据集上，MAIFormer在多个指标上优于其他方法，且具备良好的预测可解释性。

Conclusion: MAIFormer能有效预测多智能体飞行轨迹，兼具高精度与可解释性，提升了模型透明度和在空中交通管理中的实用性。

Abstract: Flight trajectory prediction for multiple aircraft is essential and provides
critical insights into how aircraft navigate within current air traffic flows.
However, predicting multi-agent flight trajectories is inherently challenging.
One of the major difficulties is modeling both the individual aircraft
behaviors over time and the complex interactions between flights. Generating
explainable prediction outcomes is also a challenge. Therefore, we propose a
Multi-Agent Inverted Transformer, MAIFormer, as a novel neural architecture
that predicts multi-agent flight trajectories. The proposed framework features
two key attention modules: (i) masked multivariate attention, which captures
spatio-temporal patterns of individual aircraft, and (ii) agent attention,
which models the social patterns among multiple agents in complex air traffic
scenes. We evaluated MAIFormer using a real-world automatic dependent
surveillance-broadcast flight trajectory dataset from the terminal airspace of
Incheon International Airport in South Korea. The experimental results show
that MAIFormer achieves the best performance across multiple metrics and
outperforms other methods. In addition, MAIFormer produces prediction outcomes
that are interpretable from a human perspective, which improves both the
transparency of the model and its practical utility in air traffic control.

</details>


### [279] [ExMolRL: Phenotype-Target Joint Generation of De Novo Molecules via Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2509.21010)
*Haotian Guo,Hui Liu*

Main category: cs.LG

TL;DR: 提出了一种名为ExMoIRL的新型生成框架，结合表型和靶向信息，通过多目标强化学习生成高质量分子，在药物发现中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于表型或靶点的药物设计方法各有局限，如实验成本高或忽略系统级细胞响应，需一种能融合两者优势的新方法。

Method: 首先在大规模药物诱导转录谱上预训练表型引导的生成器，再通过融合对接亲和力、药物相似性评分及多种优化策略的多目标强化学习进行微调。

Result: ExMoIRL在多个已知靶点上优于当前先进模型，生成的分子具有良好的类药性、高靶点亲和力和对癌细胞的抑制活性（IC50）。

Conclusion: ExMoIRL成功整合了表型与靶向策略的优势，为从头药物发现提供更有效的解决方案。

Abstract: The generation of high-quality candidate molecules remains a central
challenge in AI-driven drug design. Current phenotype-based and target-based
strategies each suffer limitations, either incurring high experimental costs or
overlook system-level cellular responses. To bridge this gap, we propose
ExMoIRL, a novel generative framework that synergistically integrates
phenotypic and target-specific cues for de novo molecular generation. The
phenotype-guided generator is first pretrained on expansive drug-induced
transcriptional profiles and subsequently fine-tuned via multi-objective
reinforcement learning (RL). Crucially, the reward function fuses docking
affinity and drug-likeness scores, augmented with ranking loss,
prior-likelihood regularization, and entropy maximization. The multi-objective
RL steers the model toward chemotypes that are simultaneously potent, diverse,
and aligned with the specified phenotypic effects. Extensive experiments
demonstrate ExMoIRL's superior performance over state-of-the-art
phenotype-based and target-based models across multiple well-characterized
targets. Our generated molecules exhibit favorable drug-like properties, high
target affinity, and inhibitory potency (IC50) against cancer cells. This
unified framework showcases the synergistic potential of combining
phenotype-guided and target-aware strategies, offering a more effective
solution for de novo drug discovery.

</details>


### [280] [Mechanism of Task-oriented Information Removal in In-context Learning](https://arxiv.org/abs/2509.21012)
*Hakaze Cho,Haolin Yang,Gouki Minegishi,Naoya Inoue*

Main category: cs.LG

TL;DR: 本文通过信息去除的新视角研究了上下文学习（ICL）的机制，发现语言模型在零样本情况下生成非选择性表示，而少样本ICL通过模拟任务导向的信息去除过程来提升性能，并识别出关键的“去噪头”注意力头。


<details>
  <summary>Details</summary>
Motivation: 由于上下文学习（ICL）的内在机制尚不明确，本文旨在从信息去除的角度揭示其工作原理。

Method: 通过低秩滤波器选择性地从隐藏状态中去除特定信息，并设计指标测量隐藏状态变化，分析ICL如何模拟任务导向的信息去除；同时识别关键注意力头并进行消融实验。

Result: 发现少样本ICL能有效模拟任务导向的信息去除过程，去除冗余信息以提高输出准确性；识别出称为“去噪头”的关键注意力头，阻断其功能会导致ICL准确率显著下降。

Conclusion: 信息去除是ICL的关键机制之一，“去噪头”在实现该机制中起着核心作用，尤其在演示中未包含正确标签时更为关键。

Abstract: In-context Learning (ICL) is an emerging few-shot learning paradigm based on
modern Language Models (LMs), yet its inner mechanism remains unclear. In this
paper, we investigate the mechanism through a novel perspective of information
removal. Specifically, we demonstrate that in the zero-shot scenario, LMs
encode queries into non-selective representations in hidden states containing
information for all possible tasks, leading to arbitrary outputs without
focusing on the intended task, resulting in near-zero accuracy. Meanwhile, we
find that selectively removing specific information from hidden states by a
low-rank filter effectively steers LMs toward the intended task. Building on
these findings, by measuring the hidden states on carefully designed metrics,
we observe that few-shot ICL effectively simulates such task-oriented
information removal processes, selectively removing the redundant information
from entangled non-selective representations, and improving the output based on
the demonstrations, which constitutes a key mechanism underlying ICL. Moreover,
we identify essential attention heads inducing the removal operation, termed
Denoising Heads, which enables the ablation experiments blocking the
information removal operation from the inference, where the ICL accuracy
significantly degrades, especially when the correct label is absent from the
few-shot demonstrations, confirming both the critical role of the information
removal mechanism and denoising heads.

</details>


### [281] [Predicting LLM Reasoning Performance with Small Proxy Model](https://arxiv.org/abs/2509.21013)
*Woosung Koh,Juyoung Suk,Sungjun Han,Se-Young Yun,Jay Shin*

Main category: cs.LG

TL;DR: rBridge是一种利用小规模代理模型（≤1B参数）预测大规模模型推理能力的方法，通过更紧密对齐预训练目标和目标任务，显著降低数据集排名成本，并在多个推理基准上实现强相关性。


<details>
  <summary>Details</summary>
Motivation: 由于大规模语言模型预训练成本高昂，需借助小模型优化数据集；但推理能力具有涌现特性，通常只在大模型（>7B参数）中可靠出现，小模型难以有效预测，因此需要一种能桥接小模型与大模型推理表现的方法。

Method: 提出rBridge方法，通过使用前沿模型生成的推理轨迹作为黄金标签，以任务对齐加权负对数似然来对齐小代理模型与大模型的目标，从而提升小模型对大模型推理性能的预测能力。

Result: 实验表明，rBridge相比最佳基线将数据集排名成本降低100倍以上，在6个推理基准上于1B至32B规模模型中达到最强相关性，并能在1B至7B规模不同预训练数据集间实现零样本迁移预测关系。

Conclusion: rBridge为低成本探索面向推理的预训练提供了一条实用路径，证明了通过目标对齐可使小模型有效预测大模型的推理表现。

Abstract: Given the prohibitive cost of pre-training large language models, it is
essential to leverage smaller proxy models to optimize datasets before scaling
up. However, this approach becomes challenging for reasoning capabilities,
which exhibit emergent behavior that only appear reliably at larger model
sizes, often exceeding 7B parameters. To address this, we introduce rBridge,
showing that small proxies ($\leq$1B) can effectively predict large-model
reasoning by aligning more closely with (1) the pre-training objective and (2)
the target task. rBridge achieves this by weighting negative log-likelihood
with task alignment, using reasoning traces from frontier models as gold
labels. In our experiments, rBridge (i) reduces dataset ranking costs by over
100x relative to the best baseline, (ii) achieves the strongest correlation
across six reasoning benchmarks at 1B to 32B scale, and (iii) zero-shot
transfers predictive relationships across pre-training datasets at 1B to 7B
scale. These findings indicate that rBridge offers a practical path for
exploring reasoning-oriented pre-training at lower cost.

</details>


### [282] [DELTA-Code: How Does RL Unlock and Transfer New Programming Algorithms in LLMs?](https://arxiv.org/abs/2509.21016)
*Yiyou Sun,Yuhan Cao,Pohao Huang,Haoyue Bai,Hannaneh Hajishirzi,Nouha Dziri,Dawn Song*

Main category: cs.LG

TL;DR: 本文提出了DELTA-Code，一个用于评估大语言模型通过强化学习习得和迁移新推理策略能力的基准测试，揭示了模型在长期低奖励后突然提升的“顿悟”现象，并探讨了可学习性与可迁移性的关键训练要素。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否能真正掌握预训练之外的新推理策略，而不仅仅是依赖已有参数中的技能。

Method: 设计了DELTA-Code基准，包含合成编码问题族，通过强化学习训练模型，评估其在不可见分布问题上的可学习性与可迁移性，并引入阶段性训练、经验回放等策略。

Result: 实验发现模型存在‘顿悟’相变现象；在适当训练条件下可学会原本无法解决的问题，技能在同家族内和组合任务中表现良好，但在需根本性转换的任务上仍弱。

Conclusion: DELTA-Code为研究大模型通过强化学习获取新算法技能提供了清晰测试平台，表明模型能在特定条件下突破原有先验知识，但对根本性新策略的迁移仍有局限。

Abstract: It remains an open question whether LLMs can acquire or generalize genuinely
new reasoning strategies, beyond the sharpened skills encoded in their
parameters during pre-training or post-training. To attempt to answer this
debate, we introduce DELTA-Code--Distributional Evaluation of Learnability and
Transferrability in Algorithmic Coding, a controlled benchmark of synthetic
coding problem families designed to probe two fundamental aspects: learnability
-- can LLMs, through reinforcement learning (RL), solve problem families where
pretrained models exhibit failure with large enough attempts (pass@K=0)? --and
transferrability -- if learnability happens, can such skills transfer
systematically to out-of-distribution (OOD) test sets? Unlike prior public
coding datasets, DELTA isolates reasoning skills through templated problem
generators and introduces fully OOD problem families that demand novel
strategies rather than tool invocation or memorized patterns. Our experiments
reveal a striking grokking phase transition: after an extended period with
near-zero reward, RL-trained models abruptly climb to near-perfect accuracy. To
enable learnability on previously unsolvable problem families, we explore key
training ingredients such as staged warm-up with dense rewards, experience
replay, curriculum training, and verification-in-the-loop. Beyond learnability,
we use DELTA to evaluate transferability or generalization along exploratory,
compositional, and transformative axes, as well as cross-family transfer.
Results show solid gains within families and for recomposed skills, but
persistent weaknesses in transformative cases. DELTA thus offers a clean
testbed for probing the limits of RL-driven reasoning and for understanding how
models can move beyond existing priors to acquire new algorithmic skills.

</details>


### [283] [Efficient Ensemble Conditional Independence Test Framework for Causal Discovery](https://arxiv.org/abs/2509.21021)
*Zhengkang Guan,Kun Kuang*

Main category: cs.LG

TL;DR: 提出了一种名为E-CIT的通用框架，通过分治和聚合策略显著降低因果发现中条件独立性检验的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统约束型因果发现方法因条件独立性检验（CIT）随样本量增加而计算成本过高，限制了实际应用。

Method: 将数据划分为子集，在每个子集上独立应用基础CIT，并利用基于稳定分布特性的新方法聚合p值，实现计算复杂度线性化。

Result: E-CIT在保持竞争性能的同时，显著降低了CIT和因果发现的计算负担，并在真实数据等复杂场景中表现更优。

Conclusion: E-CIT是一种高效、可插拔的框架，为大规模因果发现提供了可行解决方案。

Abstract: Constraint-based causal discovery relies on numerous conditional independence
tests (CITs), but its practical applicability is severely constrained by the
prohibitive computational cost, especially as CITs themselves have high time
complexity with respect to the sample size. To address this key bottleneck, we
introduce the Ensemble Conditional Independence Test (E-CIT), a general and
plug-and-play framework. E-CIT operates on an intuitive divide-and-aggregate
strategy: it partitions the data into subsets, applies a given base CIT
independently to each subset, and aggregates the resulting p-values using a
novel method grounded in the properties of stable distributions. This framework
reduces the computational complexity of a base CIT to linear in the sample size
when the subset size is fixed. Moreover, our tailored p-value combination
method offers theoretical consistency guarantees under mild conditions on the
subtests. Experimental results demonstrate that E-CIT not only significantly
reduces the computational burden of CITs and causal discovery but also achieves
competitive performance. Notably, it exhibits an improvement in complex testing
scenarios, particularly on real-world datasets.

</details>


### [284] [Actor-Critic without Actor](https://arxiv.org/abs/2509.21022)
*Donghyeon Ki,Hee-Jun Ahn,Kyungyoon Kim,Byung-Jun Lee*

Main category: cs.LG

TL;DR: 提出了一种名为Actor-Critic without Actor (ACA)的轻量级框架，通过去除显式的actor网络，直接从噪声水平critic的梯度场生成动作，简化了训练过程并保持了策略改进与critic值估计的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的actor-critic方法依赖于分离的actor和critic网络，导致训练对架构选择和超参数敏感，且难以扩展；扩散模型虽能提升探索能力，但增加了设计复杂性和计算负担。

Method: 引入ACA框架，取消显式actor网络，利用噪声水平critic的梯度场直接生成动作，实现策略更新，同时保留多模态行为建模能力。

Result: 在标准在线强化学习基准上，ACA展现出更优的学习曲线，并在性能上优于传统actor-critic及最先进的扩散模型方法。

Conclusion: ACA提供了一种简单而强大的在线强化学习解决方案，在保持表达能力的同时显著降低了算法复杂性和计算开销。

Abstract: Actor-critic methods constitute a central paradigm in reinforcement learning
(RL), coupling policy evaluation with policy improvement. While effective
across many domains, these methods rely on separate actor and critic networks,
which makes training vulnerable to architectural decisions and hyperparameter
tuning. Such complexity limits their scalability in settings that require large
function approximators. Recently, diffusion models have recently been proposed
as expressive policies that capture multi-modal behaviors and improve
exploration, but they introduce additional design choices and computational
burdens, hindering efficient deployment. We introduce Actor-Critic without
Actor (ACA), a lightweight framework that eliminates the explicit actor network
and instead generates actions directly from the gradient field of a noise-level
critic. This design removes the algorithmic and computational overhead of actor
training while keeping policy improvement tightly aligned with the critic's
latest value estimates. Moreover, ACA retains the ability to capture diverse,
multi-modal behaviors without relying on diffusion-based actors, combining
simplicity with expressiveness. Through extensive experiments on standard
online RL benchmarks,ACA achieves more favorable learning curves and
competitive performance compared to both standard actor-critic and
state-of-the-art diffusion-based methods, providing a simple yet powerful
solution for online RL.

</details>


### [285] [FORCE: Transferable Visual Jailbreaking Attacks via Feature Over-Reliance CorrEction](https://arxiv.org/abs/2509.21029)
*Runqi Lin,Alasdair Paren,Suqin Yuan,Muyang Li,Philip Torr,Adel Bibi,Tongliang Liu*

Main category: cs.LG

TL;DR: 本文提出了一种名为FORCE的方法，通过纠正特征过度依赖问题，提升视觉越狱攻击在多模态大模型中的跨模型可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉越狱攻击在开源多模态大语言模型上有效，但跨模型迁移能力差，难以发现闭源模型的漏洞，因此需要提高攻击的通用性和鲁棒性。

Method: 分析越狱攻击的损失景观，发现其集中在高锐度区域，并在中间层和频谱域中揭示了对窄层表示和语义贫乏频率成分的不当依赖；基于此，提出FORCE方法，引导攻击探索更广泛的层间可行区域，并根据频率成分的语义内容重新调整其影响。

Result: 实验表明，FORCE方法能有效生成更具迁移性的视觉越狱攻击，在多种闭源多模态大语言模型上显著提升了攻击成功率，同时揭示了攻击可迁移性受限的根源。

Conclusion: 通过消除对非泛化性特征（如特定层和低语义频率）的依赖，FORCE能够在损失景观中找到更平坦的可行区域，从而显著增强视觉越狱攻击的跨模型转移能力，有助于更有效地评估闭源MLLMs的安全性。

Abstract: The integration of new modalities enhances the capabilities of multimodal
large language models (MLLMs) but also introduces additional vulnerabilities.
In particular, simple visual jailbreaking attacks can manipulate open-source
MLLMs more readily than sophisticated textual attacks. However, these
underdeveloped attacks exhibit extremely limited cross-model transferability,
failing to reliably identify vulnerabilities in closed-source MLLMs. In this
work, we analyse the loss landscape of these jailbreaking attacks and find that
the generated attacks tend to reside in high-sharpness regions, whose
effectiveness is highly sensitive to even minor parameter changes during
transfer. To further explain the high-sharpness localisations, we analyse their
feature representations in both the intermediate layers and the spectral
domain, revealing an improper reliance on narrow layer representations and
semantically poor frequency components. Building on this, we propose a Feature
Over-Reliance CorrEction (FORCE) method, which guides the attack to explore
broader feasible regions across layer features and rescales the influence of
frequency features according to their semantic content. By eliminating
non-generalizable reliance on both layer and spectral features, our method
discovers flattened feasible regions for visual jailbreaking attacks, thereby
improving cross-model transferability. Extensive experiments demonstrate that
our approach effectively facilitates visual red-teaming evaluations against
closed-source MLLMs.

</details>


### [286] [Reinforcement Learning Fine-Tuning Enhances Activation Intensity and Diversity in the Internal Circuitry of LLMs](https://arxiv.org/abs/2509.21044)
*Honglin Zhang,Qianyue Hao,Fengli Xu,Yong Li*

Main category: cs.LG

TL;DR: 本研究通过边缘归因补丁（EAP）方法探究大语言模型在强化学习（RL）微调前后的内部变化，发现在线RL微调能增强激活强度和模式多样性，提升信息流的冗余性与灵活性，从而改善泛化能力；而DPO微调则表现出较弱或不一致的内部变化，揭示了在线RL与偏好优化方法之间的机制差异。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习微调被证明能提升大语言模型性能，但其如何影响不同模型内部机制尚不清楚，本文旨在揭示RL微调对模型内部结构的系统性改变。

Method: 借鉴边缘归因补丁（EAP）方法，分析多个模型家族在RL微调前后的激活强度和模式分布变化，比较PPO、GRPO与DPO等不同微调方法的影响。

Result: 发现在线RL微调导致：(1) 激活强度整体增加，表明更多内部路径被激活；(2) 激活模式多样性提高，表现为更高熵和更分散的边分布；而DPO微调未呈现类似趋势，变化较弱或不一致。

Conclusion: RL微调通过增强激活强度和多样性来重塑信息流动，使其更具冗余性和灵活性，这可能解释其优于SFT的泛化能力；DPO与在线RL在机制上存在显著差异，提示需区分不同训练范式的影响。

Abstract: Large language models (LLMs) acquire extensive prior knowledge through
large-scale pretraining and can be further enhanced via supervised fine-tuning
(SFT) or reinforcement learning (RL)-based post-training. A growing body of
evidence has shown that RL fine-tuning improves the capability of LLMs beyond
what SFT alone achieves. However, the underlying mechanisms why RL fine-tuning
is able to enhance the capability of various LLMs with distinct intrinsic
characteristics remain underexplored. In this study, we draw inspiration from
prior work on edge attribution patching (EAP) to investigate the internal
differences of LLMs before and after RL fine-tuning. Our analysis across
multiple model families shows two robust effects of online RL post-training:
(i) an overall increase in activation intensity, indicating that more internal
pathways are engaged and their signals become stronger, and (ii) greater
diversity in activation patterns, reflected by higher entropy and less
concentrated edge distributions. These changes suggest that RL reshapes
information flow to be both more redundant and more flexible, which may explain
its advantage in generalization. Notably, models fine-tuned with Direct
Preference Optimization (DPO) deviate from these trends, exhibiting
substantially weaker or inconsistent internal changes compared to PPO- and
GRPO-based training. Together, our findings provide a unified view of how RL
fine-tuning systematically alters the internal circuitry of LLMs and highlight
the methodological distinctions between online RL and preference-based
approaches. Our code is open source at
https://anonymous.4open.science/r/llm_rl_probing_analysis-F673.

</details>


### [287] [Physics of Learning: A Lagrangian perspective to different learning paradigms](https://arxiv.org/abs/2509.21049)
*Siyuan Guo,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 本文通过借鉴物理学中的最小作用量原理，提出了学习的拉格朗日量，并由此推导出经典的学习算法、强化学习中的贝尔曼最优方程以及生成模型中的Adam优化器，认为学习过程是在寻找拉格朗日量中的平稳路径。


<details>
  <summary>Details</summary>
Motivation: 研究如何构建高效的学习系统，即在最短时间内达到期望误差阈值，使用最少的观测次数。

Method: 基于物理学中的最小作用量原理，引入学习的拉格朗日量，通过寻找拉格朗日量中的平稳路径来推导各种学习算法。

Result: 成功从第一性原理推导出了经典学习算法、贝尔曼最优方程和Adam优化器，验证了该框架的广泛适用性。

Conclusion: 学习可以被理解为在拉格朗日量中寻找平稳路径的过程，这一观点为设计新的学习算法提供了理论基础。

Abstract: We study the problem of building an efficient learning system. Efficient
learning processes information in the least time, i.e., building a system that
reaches a desired error threshold with the least number of observations.
Building upon least action principles from physics, we derive classic learning
algorithms, Bellman's optimality equation in reinforcement learning, and the
Adam optimizer in generative models from first principles, i.e., the Learning
$\textit{Lagrangian}$. We postulate that learning searches for stationary paths
in the Lagrangian, and learning algorithms are derivable by seeking the
stationary trajectories.

</details>


### [288] [GeoRef: Referring Expressions in Geometry via Task Formulation, Synthetic Supervision, and Reinforced MLLM-based Solutions](https://arxiv.org/abs/2509.21050)
*Bing Liu,Wenqiang Yv,Xuzheng Yang,Shichang Wang,Junzhuo Liu,Peng Wang,Guoqing Wang,Yang Yang,Heng Tao Shen*

Main category: cs.LG

TL;DR: 本文提出了几何问题中的指代表达理解（REC）任务，引入了GeoRef基准数据集，并通过合成数据训练模型，采用GRPO微调和验证-重生成机制提升性能，表明该任务对多模态数学理解具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在几何问题求解中缺乏对图表元素与自然语言查询之间精确跨模态对齐的能力，尤其是在定位和解释几何元素方面存在不足，因此需要构建专门的任务和数据集来评估和提升这一基础能力。

Method: 提出指代表达理解（REC）任务，构建GeoRef基准数据集，并利用结构化几何形式语言生成大规模合成训练数据；采用监督微调（SFT）和组相对策略优化（GRPO）进行模型微调，并设计验证-重生成机制以提高预测准确性。

Result: 实验表明，GRPO显著优于SFT，验证-重生成机制进一步提升了准确率；即使最先进的多模态大模型在此任务上表现不佳，说明几何接地能力亟需加强；在GeoRef上训练的模型在下游几何推理任务中表现出明显提升。

Conclusion: 指代表达理解是提升AI几何问题求解能力的关键基础任务，GeoRef为训练和评估提供了有效基准，强化学习方法与上下文推理机制有助于提升模型性能，应将几何接地能力作为多模态数学理解的核心组成部分加以发展。

Abstract: AI-driven geometric problem solving is a complex vision-language task that
requires accurate diagram interpretation, mathematical reasoning, and robust
cross-modal grounding. A foundational yet underexplored capability for this
task is the ability to identify and interpret geometric elements based on
natural language queries. To address this, we introduce the task of Referring
Expression Comprehension (REC) for geometric problems, which evaluates whether
models can localize points, shapes, and spatial relations in diagrams in
response to textual prompts. We present GeoRef, a benchmark dataset constructed
from existing geometric problem corpora, featuring diverse, high-quality
annotations and queries. Due to the lack of annotated data for this task, we
generate a large-scale synthetic training dataset using a structured geometric
formal language, enabling broad coverage of geometric concepts and facilitating
model adaptation. We explore two fine-tuning approaches: Supervised Fine-Tuning
(SFT) and Group Relative Policy Optimization (GRPO). Our results show that GRPO
significantly outperforms SFT by better aligning model behavior with
task-specific rewards. Furthermore, we propose a verify-and-regenerate
mechanism that detects incorrect predictions and re-infers answers using
contextual reasoning history, further boosting accuracy. Notably, even
state-of-the-art Multimodal Large Language Models (MLLMs) struggle with this
task, underscoring the necessity of explicitly evaluating and strengthening
geometric grounding as a prerequisite for robust geometric problem solving.
Moreover, models trained on GeoRef demonstrate measurable improvements on
downstream geometric reasoning tasks, highlighting the broader value of REC as
a foundation for multimodal mathematical understanding.

</details>


### [289] [ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning](https://arxiv.org/abs/2509.21070)
*Qizhi Pei,Zhuoshi Pan,Honglin Lin,Xin Gao,Yu Li,Zinan Tang,Conghui He,Rui Yan,Lijun Wu*

Main category: cs.LG

TL;DR: 本文提出了一种名为ScaleDiff的高效生成困难数学问题的管道，通过筛选现有数据集中的难题并训练专用生成器DiffGen-8B，显著提升小规模模型在复杂数学任务上的表现，且无需依赖昂贵的大模型教师或复杂提示。


<details>
  <summary>Details</summary>
Motivation: 现有的自动合成数学问题方法受限于高计算成本、复杂的提示设计以及生成问题难度不足，难以规模化。因此需要一种更高效、低成本的方法来大规模生成高难度数学问题。

Method: 提出ScaleDiff框架：首先使用自适应思维模型通过单次前向传播识别现有数据集中难题；然后基于这些难题训练一个专用的小型问题生成器DiffGen-8B；最后构建ScaleDiff-Math数据集用于微调目标模型。

Result: 在AIME、HMMT等五个高难度数学测试集上，微调后的Qwen2.5-Math-7B-Instruct平均准确率达65.9%，比原始数据集提升11.3%，优于OpenThinker3等大模型。同时验证了难题数量与模型性能之间的正向扩展关系。

Conclusion: ScaleDiff提供了一种低成本、可扩展的方式来自动生成高难度数学问题，有效提升了小型模型的复杂推理能力，且不依赖大型昂贵教师模型，具有良好的实用性和推广价值。

Abstract: Large Reasoning Models (LRMs) have shown impressive capabilities in complex
problem-solving, often benefiting from training on difficult mathematical
problems that stimulate intricate reasoning. Recent efforts have explored
automated synthesis of mathematical problems by prompting proprietary models or
large-scale open-source models from seed data or inherent mathematical
concepts. However, scaling up these methods remains challenging due to their
high computational/API cost, complexity of prompting, and limited difficulty
level of the generated problems. To overcome these limitations, we propose
ScaleDiff, a simple yet effective pipeline designed to scale the creation of
difficult problems. We efficiently identify difficult problems from existing
datasets with only a single forward pass using an adaptive thinking model,
which can perceive problem difficulty and automatically switch between
"Thinking" and "NoThinking" modes. We then train a specialized difficult
problem generator (DiffGen-8B) on this filtered difficult data, which can
produce new difficult problems in large scale, eliminating the need for
complex, per-instance prompting and its associated high API costs. Fine-tuning
Qwen2.5-Math-7B-Instruct on the ScaleDiff-Math dataset yields a substantial
performance increase of 11.3% compared to the original dataset and achieves a
65.9% average accuracy on AIME'24, AIME'25, HMMT-Feb'25, BRUMO'25, and MATH500,
outperforming recent strong LRMs like OpenThinker3. Notably, this performance
is achieved using the cost-efficient Qwen3-8B model as a teacher, demonstrating
that our pipeline can effectively transfer advanced reasoning capabilities
without relying on larger, more expensive teacher models. Furthermore, we
observe a clear scaling phenomenon in model performance on difficult benchmarks
as the quantity of difficult problems increases. Code:
https://github.com/QizhiPei/ScaleDiff.

</details>


### [290] [SPREAD: Sampling-based Pareto front Refinement via Efficient Adaptive Diffusion](https://arxiv.org/abs/2509.21058)
*Sedjro Salomon Hotegni,Sebastian Peitz*

Main category: cs.LG

TL;DR: 提出了一种基于去噪扩散概率模型的生成框架SPREAD，用于高效求解多目标优化问题的Pareto解集，在效率、可扩展性和Pareto前沿覆盖方面优于或媲美现有方法。


<details>
  <summary>Details</summary>
Motivation: 多目标优化中在大规模且计算代价高的问题上高效求解Pareto解集仍具挑战性，现有方法在效率和多样性方面存在不足。

Method: 提出SPREAD框架，基于条件扩散模型学习决策空间中的点分布，并在反向扩散过程中结合自适应多梯度下降更新和高斯RBF排斥项进行候选解的优化与多样化。

Result: 在多个多目标优化基准任务上验证了SPREAD的有效性，包括离线和基于贝叶斯代理的设置，结果表明其在效率、可扩展性和Pareto前沿覆盖方面优于或媲美现有领先方法。

Conclusion: SPREAD是一种高效且可扩展的多目标优化框架，能够快速收敛并保持解的多样性，适用于大规模和昂贵的优化问题。

Abstract: Developing efficient multi-objective optimization methods to compute the
Pareto set of optimal compromises between conflicting objectives remains a key
challenge, especially for large-scale and expensive problems. To bridge this
gap, we introduce SPREAD, a generative framework based on Denoising Diffusion
Probabilistic Models (DDPMs). SPREAD first learns a conditional diffusion
process over points sampled from the decision space and then, at each reverse
diffusion step, refines candidates via a sampling scheme that uses an adaptive
multiple gradient descent-inspired update for fast convergence alongside a
Gaussian RBF-based repulsion term for diversity. Empirical results on
multi-objective optimization benchmarks, including offline and Bayesian
surrogate-based settings, show that SPREAD matches or exceeds leading baselines
in efficiency, scalability, and Pareto front coverage.

</details>


### [291] [Structure-Attribute Transformations with Markov Chain Boost Graph Domain Adaptation](https://arxiv.org/abs/2509.21059)
*Zhen Liu,Yongtao Zhang,Shaobo Ren,Yuxin You*

Main category: cs.LG

TL;DR: 提出了一种新的图域自适应框架SATMC，通过图结构和属性变换来对齐不同网络中的分布，并引入了减少私有域信息影响的机制和经验Wasserstein距离，理论证明其在跨网络节点分类任务中能实现更紧的误差界，实验表明该方法优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 传统图域自适应方法主要关注在原始图结构上转换节点属性并对其特征分布进行对齐，但难以处理不同图域间的结构异质性，导致分布对齐效果不佳。

Method: 提出Structure-Attribute Transformation with Markov Chain (SATMC)框架，依次通过图结构变换和属性变换对齐网络间分布，引入私有域信息减少机制和经验Wasserstein距离以提升模型泛化能力。

Result: 理论分析表明SATMC相比现有方法可获得更紧的跨网络节点分类误差界，在九组公开跨域数据集上的实验证明其性能优于当前最先进的图域自适应方法。

Conclusion: SATMC有效解决了图域间结构异质性带来的挑战，提升了跨网络节点分类的性能，具备较强的泛化能力和应用潜力。

Abstract: Graph domain adaptation has gained significant attention in label-scarce
scenarios across different graph domains. Traditional approaches to graph
domain adaptation primarily focus on transforming node attributes over raw
graph structures and aligning the distributions of the transformed node
features across networks. However, these methods often struggle with the
underlying structural heterogeneity between distinct graph domains, which leads
to suboptimal distribution alignment. To address this limitation, we propose
Structure-Attribute Transformation with Markov Chain (SATMC), a novel framework
that sequentially aligns distributions across networks via both graph structure
and attribute transformations. To mitigate the negative influence of
domain-private information and further enhance the model's generalization,
SATMC introduces a private domain information reduction mechanism and an
empirical Wasserstein distance. Theoretical proofs suggest that SATMC can
achieve a tighter error bound for cross-network node classification compared to
existing graph domain adaptation methods. Extensive experiments on nine pairs
of publicly available cross-domain datasets show that SATMC outperforms
state-of-the-art methods in the cross-network node classification task. The
code is available at https://github.com/GiantZhangYT/SATMC.

</details>


### [292] [TyphoonMLA: A Mixed Naive-Absorb MLA Kernel For Shared Prefix](https://arxiv.org/abs/2509.21081)
*Ahmet Caner Yüzügüler,Ahmet Çelik,Jiawei Zhuang,Lukas Cavigelli*

Main category: cs.LG

TL;DR: 本文提出了TyphoonMLA，一种结合了naive和absorb两种计算方式的混合方法，用于提升多头潜在注意力（MLA）架构中的注意力计算吞吐量，在NPU和GPU上分别实现了最高3倍和3.24倍的性能提升，仅增加3%的HBM内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有的MLA解码内核使用absorb方法减少HBM带宽占用，但其计算密集特性限制了对共享前缀等数据重用机会的利用，导致性能受限。因此需要一种能兼顾计算效率与带宽优化的新方法。

Method: 提出TyphoonMLA，采用混合策略：在计算密集部分使用naive公式以利用数据重用（如共享前缀），在非共享部分采用absorb公式以降低带宽需求，并设计高效内核实现二者协同。

Result: 在NPU和GPU上，TyphoonMLA将MLA架构的注意力计算吞吐量分别提升了最高3倍和3.24倍，同时HBM大小开销仅为3%。

Conclusion: TyphoonMLA通过融合naive和absorb两种计算范式，有效平衡了计算与内存带宽的利用，显著提升了MLA在实际推理中的效率，适用于当前主流的高效LLM架构。

Abstract: Multi-Head Latent Attention (MLA) is a recent attention mechanism adopted in
state-of-the-art LLMs such as DeepSeek-v3 and Kimi K2. Thanks to its novel
formulation, MLA allows two functionally equivalent but computationally
distinct kernel implementations: naive and absorb. While the naive kernels
(e.g., FlashAttention) are typically preferred in training and prefill for
their computational efficiency, existing decoding kernels (e.g., FlashMLA) rely
on the absorb method to minimize HBM bandwidth usage. However, the
compute-bound nature of the absorb implementations prohibits performance
benefits from data reuse opportunities in attention calculations, such as
shared prefixes. In this work, we introduce TyphoonMLA, a hybrid approach that
combines naive and absorb formulations to harness the strengths of both.
TyphoonMLA effectively leverages the shared prefix by applying the naive
formulation to the compute-bound parts of attention calculations, while
reducing the bandwidth requirements for non-shared parts by using the absorb
formulation. As a result, TyphoonMLA improves the throughput of attention
calculations in MLA architectures by up to 3x and 3.24x on NPU and GPUs, with
only a 3% overhead in HBM size.

</details>


### [293] [GraphUniverse: Enabling Systematic Evaluation of Inductive Generalization](https://arxiv.org/abs/2509.21097)
*Louis Van Langendonck,Guillermo Bernárdez,Nina Miolane,Pere Barlet-Ros*

Main category: cs.LG

TL;DR: 本文提出了GraphUniverse框架，用于生成具有语义一致性的图家族，以系统评估模型在大规模上的归纳泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有图学习基准局限于单图、直推式设置，难以评估模型在新图上的归纳泛化能力，本文旨在填补这一空白。

Method: 通过生成具有持久语义社区的图家族，控制同质性和度分布等结构属性，实现对归纳泛化和分布偏移鲁棒性的系统评估。

Result: 实验表明，良好的直推性能并不能预测归纳性能，且模型对分布偏移的鲁棒性高度依赖于架构选择和初始图特性（如同质性高低）。

Conclusion: GraphUniverse为评估和开发真正可泛化的图模型提供了有效工具，有助于推动下一代图基础模型的发展。

Abstract: A fundamental challenge in graph learning is understanding how models
generalize to new, unseen graphs. While synthetic benchmarks offer controlled
settings for analysis, existing approaches are confined to single-graph,
transductive settings where models train and test on the same graph structure.
Addressing this gap, we introduce GraphUniverse, a framework for generating
entire families of graphs to enable the first systematic evaluation of
inductive generalization at scale. Our core innovation is the generation of
graphs with persistent semantic communities, ensuring conceptual consistency
while allowing fine-grained control over structural properties like homophily
and degree distributions. This enables crucial but underexplored robustness
tests, such as performance under controlled distribution shifts. Benchmarking a
wide range of architectures -- from GNNs to graph transformers and topological
architectures -- reveals that strong transductive performance is a poor
predictor of inductive generalization. Furthermore, we find that robustness to
distribution shift is highly sensitive not only to model architecture choice
but also to the initial graph regime (e.g., high vs. low homophily). Beyond
benchmarking, GraphUniverse's flexibility and scalability can facilitate the
development of robust and truly generalizable architectures -- including
next-generation graph foundation models. An interactive demo is available at
https://graphuniverse.streamlit.app.

</details>


### [294] [Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning](https://arxiv.org/abs/2509.21126)
*Xiefeng Wu,Jing Zhao,Shu Zhang,Mingyu Hu*

Main category: cs.LG

TL;DR: 本文提出了VARL框架，利用视觉-语言模型（VLM）为强化学习代理提供动作建议，从而提高在线强化学习的样本效率，尤其适用于稀疏奖励任务。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习在复杂任务中因需要大量交互步骤而耗时，且现有视觉-语言动作策略在低层控制上性能有限，通常依赖专家示范进行微调。因此，需要一种无需任务特定数据、能提升样本效率的方法。

Method: 提出VARL框架，通过VLM提供动作建议而非设计启发式奖励，将建议动作引入探索过程以增加样本多样性，同时保持Q函数的最优性和收敛性。

Result: 在多种环境和代理设置下验证了VARL的有效性，结果表明其显著提升了样本效率，且计算开销小。

Conclusion: VARL是一种通用的在线强化学习框架，能够在不依赖专家示范的情况下从零开始高效应用强化学习于真实世界环境。

Abstract: Online reinforcement learning in complex tasks is time-consuming, as massive
interaction steps are needed to learn the optimal Q-function.Vision-language
action (VLA) policies represent a promising direction for solving diverse
tasks; however, their performance on low-level control remains limited, and
effective deployment often requires task-specific expert demonstrations for
fine-tuning. In this paper, we propose \textbf{VARL} (\textbf{V}LM as
\textbf{A}ction advisor for online \textbf{R}einforcement \textbf{L}earning), a
framework that leverages the domain knowledge of vision-language models (VLMs)
to provide action suggestions for reinforcement learning agents. Unlike
previous methods, VARL provides action suggestions rather than designing
heuristic rewards, thereby guaranteeing unchanged optimality and convergence.
The suggested actions increase sample diversity and ultimately improve sample
efficiency, especially in sparse-reward tasks. To validate the effectiveness of
VARL, we evaluate it across diverse environments and agent settings. Results
show that VARL greatly improves sample efficiency without introducing
significant computational overhead. These advantages make VARL a general
framework for online reinforcement learning and make it feasible to directly
apply reinforcement learning from scratch in real-world environments.

</details>


### [295] [EvoMail: Self-Evolving Cognitive Agents for Adaptive Spam and Phishing Email Defense](https://arxiv.org/abs/2509.21129)
*Wei Huang,De-Tian Chu,Lin-Yuan Bai,Wei Kang,Hai-Tao Zhang,Bo Li,Zhi-Mo Han,Jing Ge,Hai-Feng Lin*

Main category: cs.LG

TL;DR: 本文提出了一种名为EvoMail的自进化认知代理框架，用于鲁棒检测垃圾邮件和钓鱼邮件。该框架通过构建统一的异构邮件图，结合文本内容、元数据和嵌入资源，并利用基于大语言模型增强的认知图神经网络进行跨源上下文推理。其核心是对抗性自进化机制：红队生成新型规避策略，蓝队从中学习并积累经验以持续优化检测能力。实验表明，EvoMail在检测精度、适应性和可解释性方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统垃圾邮件检测系统依赖静态规则或单模态模型，难以整合异构信号和持续适应快速演变的多模态攻击（如伪造头字段、混淆URL、AI生成文本等），导致性能迅速下降。因此需要一种能够自我演进、融合多源信息并具备持续学习能力的新型检测框架。

Method: EvoMail首先构建一个融合文本内容、元数据（发件人、域名、头字段）和嵌入资源（URL、附件）的统一异构邮件图；然后使用由大语言模型（LLM）增强的认知图神经网络进行上下文感知的联合推理，识别协同垃圾邮件活动；最关键的是引入对抗性自进化机制——红队代理生成新型规避攻击（如字符混淆、AI生成钓鱼文本），蓝队检测器从失败中学习，将经验压缩为记忆模块并用于未来推理，实现持续适应。

Result: 在真实数据集（Enron-Spam, Ling-Spam, SpamAssassin, TREC）及合成对抗变体上的实验表明，EvoMail在检测准确率、对新型垃圾邮件策略的适应能力以及推理过程的可解释性方面均显著优于当前最先进的基线方法。

Conclusion: EvoMail是一种具有弹性和可解释性的防御框架，能够有效应对下一代多模态、快速演化的垃圾邮件与钓鱼威胁，展示了自进化认知代理在网络安全领域的应用潜力。

Abstract: Modern email spam and phishing attacks have evolved far beyond keyword
blacklists or simple heuristics. Adversaries now craft multi-modal campaigns
that combine natural-language text with obfuscated URLs, forged headers, and
malicious attachments, adapting their strategies within days to bypass filters.
Traditional spam detection systems, which rely on static rules or
single-modality models, struggle to integrate heterogeneous signals or to
continuously adapt, leading to rapid performance degradation.
  We propose EvoMail, a self-evolving cognitive agent framework for robust
detection of spam and phishing. EvoMail first constructs a unified
heterogeneous email graph that fuses textual content, metadata (headers,
senders, domains), and embedded resources (URLs, attachments). A Cognitive
Graph Neural Network enhanced by a Large Language Model (LLM) performs
context-aware reasoning across these sources to identify coordinated spam
campaigns. Most critically, EvoMail engages in an adversarial self-evolution
loop: a ''red-team'' agent generates novel evasion tactics -- such as character
obfuscation or AI-generated phishing text -- while the ''blue-team'' detector
learns from failures, compresses experiences into a memory module, and reuses
them for future reasoning.
  Extensive experiments on real-world datasets (Enron-Spam, Ling-Spam,
SpamAssassin, and TREC) and synthetic adversarial variants demonstrate that
EvoMail consistently outperforms state-of-the-art baselines in detection
accuracy, adaptability to evolving spam tactics, and interpretability of
reasoning traces. These results highlight EvoMail's potential as a resilient
and explainable defense framework against next-generation spam and phishing
threats.

</details>


### [296] [Sparse Representations Improve Adversarial Robustness of Neural Network Classifiers](https://arxiv.org/abs/2509.21130)
*Killian Steunou,Sigurd Saue,Théo Druilhe*

Main category: cs.LG

TL;DR: 本文研究了稀疏主成分分析（SPCA）作为对抗性攻击防御手段的有效性，结合理论分析与实验验证，表明SPCA相比传统PCA在保持分类准确率的同时提升了模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在图像分类中表现优异，但易受对抗性扰动影响。本文旨在探索简单且数据自适应的线性降维方法作为防御机制。

Method: 采用标准PCA和稀疏变体SPCA作为前端特征提取器，结合线性和非线性分类器进行实验，并从理论上推导SPCA特征在不同威胁模型下的鲁棒性保证。

Result: 理论分析显示SPCA通过稀疏投影减少对抗性杠杆作用；实验结果表明，在强白盒和黑盒攻击下，SPCA比PCA具有更好的鲁棒性和更平缓的性能下降，同时保持较高的干净样本准确率。

Conclusion: SPCA是一种有效的对抗防御策略，其稀疏性降低了模型对输入扰动的敏感性，理论与实验一致支持其优于PCA的表现。

Abstract: Deep neural networks perform remarkably well on image classification tasks
but remain vulnerable to carefully crafted adversarial perturbations. This work
revisits linear dimensionality reduction as a simple, data-adapted defense. We
empirically compare standard Principal Component Analysis (PCA) with its sparse
variant (SPCA) as front-end feature extractors for downstream classifiers, and
we complement these experiments with a theoretical analysis. On the theory
side, we derive exact robustness certificates for linear heads applied to SPCA
features: for both $\ell_\infty$ and $\ell_2$ threat models (binary and
multiclass), the certified radius grows as the dual norms of $W^\top u$ shrink,
where $W$ is the projection and $u$ the head weights. We further show that for
general (non-linear) heads, sparsity reduces operator-norm bounds through a
Lipschitz composition argument, predicting lower input sensitivity.
Empirically, with a small non-linear network after the projection, SPCA
consistently degrades more gracefully than PCA under strong white-box and
black-box attacks while maintaining competitive clean accuracy. Taken together,
the theory identifies the mechanism (sparser projections reduce adversarial
leverage) and the experiments verify that this benefit persists beyond the
linear setting. Our code is available at
https://github.com/killian31/SPCARobustness.

</details>


### [297] [LAVA: Explainability for Unsupervised Latent Embeddings](https://arxiv.org/abs/2509.21149)
*Ivan Stresec,Joana P. Gonçalves*

Main category: cs.LG

TL;DR: 本文提出了LAVA方法，一种即插即用、模型无关的后处理技术，用于解释无监督学习中局部嵌入结构与输入特征之间的关系。


<details>
  <summary>Details</summary>
Motivation: 无监督黑箱模型难以解释，尤其是当输出为多维潜在嵌入时，缺乏有效手段来理解模型发现的结构。

Method: LAVA将潜在空间表示为多个局部区域（邻域），通过原始特征间的相关性描述这些区域，并揭示整个潜在空间中重复出现的相关模式。

Result: 在MNIST和单细胞肾脏数据集的UMAP嵌入上验证了LAVA的有效性，能够捕捉到视觉和生物学上相关的局部特征关联模式，即使在潜在空间中看似遥远的区域也能发现共享模式。

Conclusion: LAVA提供了一种有效的无监督模型解释方法，能够在不依赖映射函数的情况下，揭示潜在空间的局部组织机制，有助于科学发现中的可解释性需求。

Abstract: Unsupervised black-box models can be drivers of scientific discovery, but
remain difficult to interpret. Crucially, discovery hinges on understanding the
model output, which is often a multi-dimensional latent embedding rather than a
well-defined target. While explainability for supervised learning usually seeks
to uncover how input features are used to predict a target, its unsupervised
counterpart should relate input features to the structure of the learned latent
space. Adaptations of supervised model explainability for unsupervised learning
provide either single-sample or dataset-wide summary explanations. However,
without automated strategies of relating similar samples to one another guided
by their latent proximity, explanations remain either too fine-grained or too
reductive to be meaningful. This is especially relevant for manifold learning
methods that produce no mapping function, leaving us only with the relative
spatial organization of their embeddings. We introduce Locality-Aware Variable
Associations (LAVA), a post-hoc model-agnostic method designed to explain local
embedding organization through its relationship with the input features. To
achieve this, LAVA represents the latent space as a series of localities
(neighborhoods) described in terms of correlations between the original
features, and then reveals reoccurring patterns of correlations across the
entire latent space. Based on UMAP embeddings of MNIST and a single-cell kidney
dataset, we show that LAVA captures relevant feature associations, with
visually and biologically relevant local patterns shared among seemingly
distant regions of the latent spaces.

</details>


### [298] [CAD-Tokenizer: Towards Text-based CAD Prototyping via Modality-Specific Tokenization](https://arxiv.org/abs/2509.21150)
*Ruiyu Wang,Shizhao Sun,Weijian Ma,Jiang Bian*

Main category: cs.LG

TL;DR: 提出CAD-Tokenizer，一种针对文本引导CAD原型设计的多模态分词框架，通过序列式VQ-VAE和原语级池化生成紧凑且结构感知的表示，显著提升指令遵循与生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的分词器无法有效捕捉CAD序列中的原始操作语义，难以建模几何结构，限制了文本到CAD生成与编辑的统一任务性能。

Method: 设计CAD-Tokenizer框架，采用序列式VQ-VAE结合原语级池化和约束解码，使用模态特定的令牌表示CAD数据，以更好对齐CAD的结构特性。

Result: 在统一的文本引导CAD原型任务中，CAD-Tokenizer在定量与定性指标上均优于通用大模型和专用基线方法，显著提升指令跟随能力和生成质量。

Conclusion: 多模态、原语感知的分词策略能更有效地表示CAD序列，为文本驱动的CAD建模提供了更优的基础表示方法。

Abstract: Computer-Aided Design (CAD) is a foundational component of industrial
prototyping, where models are defined not by raw coordinates but by
construction sequences such as sketches and extrusions. This sequential
structure enables both efficient prototype initialization and subsequent
editing. Text-guided CAD prototyping, which unifies Text-to-CAD generation and
CAD editing, has the potential to streamline the entire design pipeline.
However, prior work has not explored this setting, largely because standard
large language model (LLM) tokenizers decompose CAD sequences into
natural-language word pieces, failing to capture primitive-level CAD semantics
and hindering attention modules from modeling geometric structure. We
conjecture that a multimodal tokenization strategy, aligned with CAD's
primitive and structural nature, can provide more effective representations. To
this end, we propose CAD-Tokenizer, a framework that represents CAD data with
modality-specific tokens using a sequence-based VQ-VAE with primitive-level
pooling and constrained decoding. This design produces compact, primitive-aware
representations that align with CAD's structural nature. Applied to unified
text-guided CAD prototyping, CAD-Tokenizer significantly improves instruction
following and generation quality, achieving better quantitative and qualitative
performance over both general-purpose LLMs and task-specific baselines.

</details>


### [299] [GRPO is Secretly a Process Reward Model](https://arxiv.org/abs/2509.21154)
*Michael Sullivan*

Main category: cs.LG

TL;DR: 本文证明了GRPO强化学习算法在特定假设下可诱导出非平凡的过程奖励模型（PRM），并通过实验证实这些假设在现实条件下成立。作者发现GRPO目标存在缺陷：过程步骤的非均匀分布会阻碍探索与利用，并提出改进算法λ-GRPO，其在推理任务中表现更优且收敛更快。结果表明，无需昂贵的显式PRM，即可利用GRPO内置的隐性PRM结构提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 探究GRPO算法是否隐含有效的过程奖励机制，并解决其因过程步骤分布不均导致的探索与利用问题。

Method: 理论分析GRPO诱导PRM的条件，实证验证假设成立；基于GRPO作为PRM的框架，识别其缺陷并提出λ-GRPO改进算法，通过实验比较其与标准GRPO在LLM训练中的表现。

Result: 实验证明GRPO确实诱导出非平凡PRM；λ-GRPO在验证准确率和下游推理任务上表现优于标准GRPO，且收敛更快；无需额外成本即可利用GRPO内置PRM结构提升性能。

Conclusion: GRPO算法本身隐含有效的PRM结构，通过λ-GRPO改进可克服原算法缺陷，在不增加训练成本的前提下显著提升模型性能，质疑了为GRPO设计显式PRM的必要性。

Abstract: We prove theoretically that the GRPO RL algorithm induces a non-trivial
process reward model (PRM), under certain assumptions regarding within-group
overlap of token sequences across completions. We then show empirically that
these assumptions are met under real-world conditions: GRPO does in fact induce
a non-trivial PRM. Leveraging the framework of GRPO-as-a-PRM, we identify a
flaw in the GRPO objective: non-uniformly distributed process steps hinder both
exploration and exploitation (under different conditions). We propose a simple
modification to the algorithm to mitigate this defect ($\lambda$-GRPO), and
show that LLMs trained with $\lambda$-GRPO achieve higher validation accuracy
and performance on downstream reasoning tasks$-$and reach peak performance more
rapidly$-$than LLMs trained with standard GRPO. Our results call into question
the advantage of costly, explicitly-defined PRMs for GRPO: we show that it is
possible to instead leverage the hidden, built-in PRM structure within the
vanilla GRPO algorithm to boost model performance with a negligible impact on
training time and cost.

</details>


### [300] [DATS: Distance-Aware Temperature Scaling for Calibrated Class-Incremental Learning](https://arxiv.org/abs/2509.21161)
*Giuseppe Serra,Florian Buettner*

Main category: cs.LG

TL;DR: 本文提出了一种名为距离感知温度缩放（DATS）的方法，用于在持续学习中实现任务自适应的模型校准，无需测试时任务信息即可减少跨任务的校准误差。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习中的校准方法通常使用全局共享温度，忽视任务间差异，导致各任务校准误差波动大；尤其在安全关键应用中，模型需可靠地表达不确定性，因此需要更精细的校准策略。

Method: 提出Distance-Aware Temperature Scaling (DATS)，结合基于原型的距离估计与距离感知校准，在无任务标识的情况下推断任务接近度，并据此动态调整温度参数以实现每任务自适应校准。

Result: 在标准基准和生物医学领域的不平衡真实数据集上实验表明，DATS在降低跨任务校准误差方面比现有方法更稳定、可靠且一致。

Conclusion: DATS通过利用任务距离信息实现无需任务标识的自适应温度调节，显著提升了持续学习中模型不确定性的校准性能。

Abstract: Continual Learning (CL) is recently gaining increasing attention for its
ability to enable a single model to learn incrementally from a sequence of new
classes. In this scenario, it is important to keep consistent predictive
performance across all the classes and prevent the so-called Catastrophic
Forgetting (CF). However, in safety-critical applications, predictive
performance alone is insufficient. Predictive models should also be able to
reliably communicate their uncertainty in a calibrated manner - that is, with
confidence scores aligned to the true frequencies of target events. Existing
approaches in CL address calibration primarily from a data-centric perspective,
relying on a single temperature shared across all tasks. Such solutions
overlook task-specific differences, leading to large fluctuations in
calibration error across tasks. For this reason, we argue that a more
principled approach should adapt the temperature according to the distance to
the current task. However, the unavailability of the task information at test
time/during deployment poses a major challenge to achieve the intended
objective. For this, we propose Distance-Aware Temperature Scaling (DATS),
which combines prototype-based distance estimation with distance-aware
calibration to infer task proximity and assign adaptive temperatures without
prior task information. Through extensive empirical evaluation on both standard
benchmarks and real-world, imbalanced datasets taken from the biomedical
domain, our approach demonstrates to be stable, reliable and consistent in
reducing calibration error across tasks compared to state-of-the-art
approaches.

</details>


### [301] [Mixture of Thoughts: Learning to Aggregate What Experts Think, Not Just What They Say](https://arxiv.org/abs/2509.21164)
*Jacob Fein-Ashley,Dhruv Parikh,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.LG

TL;DR: 本文提出了Mixture of Thoughts（MoT），一种在异构大语言模型间进行潜在层协作的简单方法，通过全局路由机制选择专家模型并在共享潜在空间中实现交叉注意力交互，在多个基准上优于现有方法，且推理高效。


<details>
  <summary>Details</summary>
Motivation: 开源大语言模型在不同领域日益专业化，现有多模型系统存在效率低或架构限制等问题，需要更高效、灵活的协作机制。

Method: 提出Mixture of Thoughts（MoT），使用轻量级路由器选择Top-K专家并指定主专家，在固定位置的交互层将隐藏状态投影到共享潜在空间，主专家对选中的专家进行交叉注意力操作；仅训练路由器和交互层，专家模型保持冻结。

Result: 在五个分布内和三个分布外基准上，MoT分别比现有最先进方法Avengers提升+0.38%和+2.92%，显著优于最佳单模型，且具有单次推理、运行时开销低、无迭代聚合负担的优势。

Conclusion: MoT提供了一种简单高效的异构大语言模型组合机制，是迈向广泛多模型协作的实用一步。

Abstract: Open-source Large Language Models (LLMs) increasingly specialize by domain
(e.g., math, code, general reasoning), motivating systems that leverage
complementary strengths across models. Prior multi-LLM approaches either (i)
route a query to one or a few experts and generate independently, (ii)
aggregate outputs from each model via costly multi-turn exchanges, or (iii)
fuse weights into a single model-typically requiring architectural homogeneity.
We introduce Mixture of Thoughts (MoT), a simple method for latent-level
collaboration among heterogeneous experts under a global routing scheme. For
each query, a lightweight router selects top-$K$ experts and designates a
primary expert; uniformly placed interaction layers project hidden states into
a shared latent space where the primary expert performs cross-attention over
its active (selected) peers. Pre-trained experts remain frozen; only the router
and the lightweight interaction layers are trained with a novel joint training
objective that improves both the expert selection and inter-expert
collaboration. Across five in-distribution (ID) and three out-of-distribution
(OOD) benchmarks, MoT surpasses the current routing and aggregation-based
state-of-the-art, Avengers, by $+0.38\%$ and $+2.92\%$, respectively. Further,
MoT significantly outperforms the best-performing single model. It achieves
this with single-pass inference, runtime comparable to routing baselines, and
none of the overheads of iterative aggregation. MoT offers a simple
latent-space mechanism for combining heterogeneous LLMs, a practical step
toward broader multi-LLM collaboration. Our code is publicly available at
https://github.com/jacobfa/mot.

</details>


### [302] [A Unified Framework for Diffusion Model Unlearning with f-Divergence](https://arxiv.org/abs/2509.21167)
*Nicola Novello,Federico Fontana,Luigi Cinque,Deniz Gunduz,Andrea M. Tonello*

Main category: cs.LG

TL;DR: 提出了一种基于f散度的统一框架，用于文本到图像扩散模型的机器遗忘，相较于传统的MSE方法更具灵活性和效果优化。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型遗忘方法多依赖均方误差（MSE），缺乏灵活性和理论统一性，限制了遗忘效果与概念保持之间的平衡。

Method: 将MSE-based遗忘方法推广为基于f散度的统一框架，分析不同f散度对算法收敛性和遗忘质量的影响，提供可选择最优散度的灵活范式。

Result: 证明MSE是f散度框架的一个特例，实验表明不同f散度在遗忘效果和概念保留方面表现不同，新框架能更有效地平衡二者。

Conclusion: 基于f散度的统一框架为扩散模型中的机器遗忘提供了更灵活、理论更完备的方法，可根据应用需求选择最优的散度度量。

Abstract: Machine unlearning aims to remove specific knowledge from a trained model.
While diffusion models (DMs) have shown remarkable generative capabilities,
existing unlearning methods for text-to-image (T2I) models often rely on
minimizing the mean squared error (MSE) between the output distribution of a
target and an anchor concept. We show that this MSE-based approach is a special
case of a unified $f$-divergence-based framework, in which any $f$-divergence
can be utilized. We analyze the benefits of using different $f$-divergences,
that mainly impact the convergence properties of the algorithm and the quality
of unlearning. The proposed unified framework offers a flexible paradigm that
allows to select the optimal divergence for a specific application, balancing
different trade-offs between aggressive unlearning and concept preservation.

</details>


### [303] [Inverse Reinforcement Learning Using Just Classification and a Few Regressions](https://arxiv.org/abs/2509.21172)
*Lars van der Laan,Nathan Kallus,Aurélien Bibaut*

Main category: cs.LG

TL;DR: 本文重新审视了最大熵逆强化学习（softmax IRL），提出了一种简化方法，将问题转化为两个标准的监督学习任务：行为策略估计和固定点回归，从而避免复杂的内层优化或动态规划，提升了算法的模块化与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有逆强化学习方法常依赖复杂的内层优化、重复的动态规划或对抗训练，限制了现代函数逼近器（如神经网络）的应用，因此需要一种更简洁、模块化的学习框架。

Method: 通过发现最大似然解满足一个关于行为策略的线性不动点方程，将softmax IRL分解为两个监督学习子问题：先用概率分类估计行为策略，再通过迭代回归求解不动点。

Result: 提出了一个简单且模块化的IRL方法，适用于各类函数逼近器；提供了最优解的精确刻画、通用的oracle算法、有限样本误差界，并在实验中表现出与MaxEnt IRL相当或更优的性能。

Conclusion: 该方法显著简化了逆强化学习的实现，增强了与现代机器学习工具的兼容性，为在复杂场景下的应用提供了新途径。

Abstract: Inverse reinforcement learning (IRL) aims to explain observed behavior by
uncovering an underlying reward. In the maximum-entropy or
Gumbel-shocks-to-reward frameworks, this amounts to fitting a reward function
and a soft value function that together satisfy the soft Bellman consistency
condition and maximize the likelihood of observed actions. While this
perspective has had enormous impact in imitation learning for robotics and
understanding dynamic choices in economics, practical learning algorithms often
involve delicate inner-loop optimization, repeated dynamic programming, or
adversarial training, all of which complicate the use of modern, highly
expressive function approximators like neural nets and boosting. We revisit
softmax IRL and show that the population maximum-likelihood solution is
characterized by a linear fixed-point equation involving the behavior policy.
This observation reduces IRL to two off-the-shelf supervised learning problems:
probabilistic classification to estimate the behavior policy, and iterative
regression to solve the fixed point. The resulting method is simple and modular
across function approximation classes and algorithms. We provide a precise
characterization of the optimal solution, a generic oracle-based algorithm,
finite-sample error bounds, and empirical results showing competitive or
superior performance to MaxEnt IRL.

</details>


### [304] [Closed-form $\ell_r$ norm scaling with data for overparameterized linear regression and diagonal linear networks under $\ell_p$ bias](https://arxiv.org/abs/2509.21181)
*Shuofeng Zhang,Ard Louis*

Main category: cs.LG

TL;DR: 本文研究了在各向同性高斯设计下过参数化线性回归中最小-ℓp插值器的参数范数族的缩放行为，提出了一种统一的高概率刻画方法，并通过对偶射线分析揭示了信号“尖峰”与零坐标的“主体”之间的竞争，得出了数据依赖的相变点n⋆和普适阈值r⋆=2(p−1)。此外，将结果推广到对角线性网络（DLN），发现其具有类似的“肘部”和阈值规律，并建立了显式与隐式偏差之间的预测联系。


<details>
  <summary>Details</summary>
Motivation: 理解在过参数化设置下，不同ℓp插值器如何影响参数范数的缩放行为，尤其是在不同样本量下的变化规律，这是当前未解决的问题。

Method: 采用对偶射线分析方法，分析X⊤Y中的信号尖峰与零坐标主体之间的竞争关系，推导出参数范数‖ŵ_p‖_r在r∈[1,p]范围内随样本量n变化的闭式预测结果。

Result: 得到了一个统一的高概率刻画：存在一个数据依赖的相变点n⋆（'肘部'）和一个普适阈值r⋆=2(p−1)，当r < r⋆时范数持续增长，当r > r⋆时趋于饱和；并将该规律成功迁移到对角线性网络（DLN），通过初始化尺度α与有效p_eff(α)的对应关系验证了其适用性。

Conclusion: 该工作为ℓp偏置插值下的所有ℓr范数（r∈[1,p]）提供了统一的缩放理论解释，揭示了哪些范数会饱和、哪些会随样本量增长，并指出许多泛化代理指标的预测能力可能高度依赖于所选择的ℓr范数。

Abstract: For overparameterized linear regression with isotropic Gaussian design and
minimum-$\ell_p$ interpolator $p\in(1,2]$, we give a unified, high-probability
characterization for the scaling of the family of parameter norms $ \\{ \lVert
\widehat{w_p} \rVert_r \\}_{r \in [1,p]} $ with sample size.
  We solve this basic, but unresolved question through a simple dual-ray
analysis, which reveals a competition between a signal *spike* and a *bulk* of
null coordinates in $X^\top Y$, yielding closed-form predictions for (i) a
data-dependent transition $n_\star$ (the "elbow"), and (ii) a universal
threshold $r_\star=2(p-1)$ that separates $\lVert \widehat{w_p} \rVert_r$'s
which plateau from those that continue to grow with an explicit exponent.
  This unified solution resolves the scaling of *all* $\ell_r$ norms within the
family $r\in [1,p]$ under $\ell_p$-biased interpolation, and explains in one
picture which norms saturate and which increase as $n$ grows.
  We then study diagonal linear networks (DLNs) trained by gradient descent. By
calibrating the initialization scale $\alpha$ to an effective
$p_{\mathrm{eff}}(\alpha)$ via the DLN separable potential, we show empirically
that DLNs inherit the same elbow/threshold laws, providing a predictive bridge
between explicit and implicit bias.
  Given that many generalization proxies depend on $\lVert \widehat {w_p}
\rVert_r$, our results suggest that their predictive power will depend
sensitively on which $l_r$ norm is used.

</details>


### [305] [Towards Foundation Models for Zero-Shot Time Series Anomaly Detection: Leveraging Synthetic Data and Relative Context Discrepancy](https://arxiv.org/abs/2509.21190)
*Tian Lan,Hao Duong Le,Jinbo Li,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的时间序列异常检测基础模型TimeRCD，基于相对上下文差异（RCD）预训练范式，通过检测相邻时间窗口间的显著差异来识别异常，克服了传统重构方法的目标不匹配问题，在零样本设置下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于重构的时间序列异常检测方法存在目标不匹配问题，难以捕捉细微异常且易将复杂正常模式误判为异常，导致高误报率和漏报率。

Method: 提出Relative Context Discrepancy (RCD)预训练范式，使用标准Transformer架构，通过识别相邻时间窗口之间的上下文差异来显式训练模型识别异常，并构建大规模带有时序标记级异常标签的合成数据集用于预训练。

Result: 在多种数据集上进行的大量实验表明，TimeRCD在零样本时间序列异常检测任务中显著优于现有的通用和专用基础模型，能够更有效捕捉异常相关的上下文变化。

Conclusion: RCD范式优于传统的重构目标，为构建鲁棒且可泛化的时序异常检测基础模型提供了新路径。

Abstract: Time series anomaly detection (TSAD) is a critical task, but developing
models that generalize to unseen data in a zero-shot manner remains a major
challenge. Prevailing foundation models for TSAD predominantly rely on
reconstruction-based objectives, which suffer from a fundamental objective
mismatch: they struggle to identify subtle anomalies while often
misinterpreting complex normal patterns, leading to high rates of false
negatives and positives. To overcome these limitations, we introduce
\texttt{TimeRCD}, a novel foundation model for TSAD built upon a new
pre-training paradigm: Relative Context Discrepancy (RCD). Instead of learning
to reconstruct inputs, \texttt{TimeRCD} is explicitly trained to identify
anomalies by detecting significant discrepancies between adjacent time windows.
This relational approach, implemented with a standard Transformer architecture,
enables the model to capture contextual shifts indicative of anomalies that
reconstruction-based methods often miss. To facilitate this paradigm, we
develop a large-scale, diverse synthetic corpus with token-level anomaly
labels, providing the rich supervisory signal necessary for effective
pre-training. Extensive experiments demonstrate that \texttt{TimeRCD}
significantly outperforms existing general-purpose and anomaly-specific
foundation models in zero-shot TSAD across diverse datasets. Our results
validate the superiority of the RCD paradigm and establish a new, effective
path toward building robust and generalizable foundation models for time series
anomaly detection.

</details>


### [306] [Differential-Integral Neural Operator for Long-Term Turbulence Forecasting](https://arxiv.org/abs/2509.21196)
*Hao Wu,Yuan Gao,Fan Xu,Fan Zhang,Qingsong Wen,Kun Wang,Xiaomeng Huang,Xian Wu*

Main category: cs.LG

TL;DR: 提出一种基于物理先验的微分-积分神经算子（DINO），通过分解局部微分和全局积分算子，显著提升湍流长期预测的稳定性与物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在长期自回归预测中难以同时捕捉湍流动力学中的局部耗散效应和非局部全局相互作用，导致误差累积和物理保真度下降。

Method: 提出DINO框架，采用算子分解的第一性原理设计，包含两个并行分支：由约束卷积网络实现的局部微分算子，理论上收敛于导数；以及由Transformer架构实现的全局积分算子，学习数据驱动的全局核函数。

Result: 在2D Kolmogorov流基准上，DINO显著优于现有最先进模型，能在数百步内抑制误差累积，保持涡度场和能量谱的高保真度。

Conclusion: DINO通过物理结构分解实现了稳定、鲁棒的长期湍流预测，为物理一致性长程预报建立了新基准。

Abstract: Accurately forecasting the long-term evolution of turbulence represents a
grand challenge in scientific computing and is crucial for applications ranging
from climate modeling to aerospace engineering. Existing deep learning methods,
particularly neural operators, often fail in long-term autoregressive
predictions, suffering from catastrophic error accumulation and a loss of
physical fidelity. This failure stems from their inability to simultaneously
capture the distinct mathematical structures that govern turbulent dynamics:
local, dissipative effects and global, non-local interactions. In this paper,
we propose the
{\textbf{\underline{D}}}ifferential-{\textbf{\underline{I}}}ntegral
{\textbf{\underline{N}}}eural {\textbf{\underline{O}}}perator (\method{}), a
novel framework designed from a first-principles approach of operator
decomposition. \method{} explicitly models the turbulent evolution through
parallel branches that learn distinct physical operators: a local differential
operator, realized by a constrained convolutional network that provably
converges to a derivative, and a global integral operator, captured by a
Transformer architecture that learns a data-driven global kernel. This
physics-based decomposition endows \method{} with exceptional stability and
robustness. Through extensive experiments on the challenging 2D Kolmogorov flow
benchmark, we demonstrate that \method{} significantly outperforms
state-of-the-art models in long-term forecasting. It successfully suppresses
error accumulation over hundreds of timesteps, maintains high fidelity in both
the vorticity fields and energy spectra, and establishes a new benchmark for
physically consistent, long-range turbulence forecast.

</details>


### [307] [From Physics to Machine Learning and Back: Part II - Learning and Observational Bias in PHM](https://arxiv.org/abs/2509.21207)
*Olga Fink,Ismail Nejjar,Vinay Sharma,Keivan Faghih Niresi,Han Sun,Hao Dong,Chenghao Xu,Amaury Wei,Arthur Bizzi,Raffael Theiler,Yuan Tian,Leandro Von Krannichfeldt,Zhan Ma,Sergei Garmaev,Zepeng Zhang,Mengjie Zhao*

Main category: cs.LG

TL;DR: 本文综述了物理信息机器学习在故障预测与健康管理（PHM）中的应用，通过引入学习偏差和观测偏差提升模型的物理一致性与可靠性，并探讨了从预测到主动决策的闭环系统及面向机队级部署的可扩展性方法。


<details>
  <summary>Details</summary>
Motivation: 解决实际PHM中传感器数据噪声大、标签稀缺、退化行为复杂非线性等问题，提升模型的泛化能力与物理一致性。

Method: 采用物理信息机器学习，将物理知识嵌入数据驱动模型，包括物理引导的损失函数、控制方程、虚拟传感、物理仿真增强数据、多传感器融合以及强化学习用于维护策略优化。

Result: 实现了更可靠、符合物理规律的预测，支持从被动预测向主动决策转变，并通过元学习、少样本学习和领域泛化等方法实现机队级快速适应。

Conclusion: 物理信息机器学习能有效提升PHM系统的准确性与可解释性，结合强化学习和可扩展学习方法，有望推动PHM向自适应、闭环、大规模应用发展。

Abstract: Prognostics and Health Management ensures the reliability, safety, and
efficiency of complex engineered systems by enabling fault detection,
anticipating equipment failures, and optimizing maintenance activities
throughout an asset lifecycle. However, real-world PHM presents persistent
challenges: sensor data is often noisy or incomplete, available labels are
limited, and degradation behaviors and system interdependencies can be highly
complex and nonlinear. Physics-informed machine learning has emerged as a
promising approach to address these limitations by embedding physical knowledge
into data-driven models. This review examines how incorporating learning and
observational biases through physics-informed modeling and data strategies can
guide models toward physically consistent and reliable predictions. Learning
biases embed physical constraints into model training through physics-informed
loss functions and governing equations, or by incorporating properties like
monotonicity. Observational biases influence data selection and synthesis to
ensure models capture realistic system behavior through virtual sensing for
estimating unmeasured states, physics-based simulation for data augmentation,
and multi-sensor fusion strategies. The review then examines how these
approaches enable the transition from passive prediction to active
decision-making through reinforcement learning, which allows agents to learn
maintenance policies that respect physical constraints while optimizing
operational objectives. This closes the loop between model-based predictions,
simulation, and actual system operation, empowering adaptive decision-making.
Finally, the review addresses the critical challenge of scaling PHM solutions
from individual assets to fleet-wide deployment. Fast adaptation methods
including meta-learning and few-shot learning are reviewed alongside domain
generalization techniques ...

</details>


### [308] [Go With The Flow: Churn-Tolerant Decentralized Training of Large Language Models](https://arxiv.org/abs/2509.21221)
*Nikolay Blagoev,Bart Cox,Jérémie Decouchant,Lydia Y. Chen*

Main category: cs.LG

TL;DR: 提出首个支持崩溃容错的去中心化大语言模型训练框架GWTF，可在高节点流失和网络不稳定的异构客户端上高效协作训练，显著减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 为了推动大语言模型训练的民主化，并应对现有分布式与联邦学习框架在节点动态变化和网络不稳定环境下的局限性。

Method: 设计了一种新型去中心化的流算法，用于寻找最优路由策略，最大化单位时间内完成的微批次训练数量，从而提升训练效率。

Result: 在GPT-like和LLaMa-like模型上的实验表明，相比先前方法，GWTF在10个地理分布的异构节点上最高可减少45%的训练时间。

Conclusion: GWTF是首个实用的、具备容错能力的去中心化LLM训练框架，能有效应对节点流失和网络不稳定性，显著提升分布式协作训练效率。

Abstract: Motivated by the emergence of large language models (LLMs) and the importance
of democratizing their training, we propose GWTF, the first crash tolerant
practical decentralized training framework for LLMs. Differently from existing
distributed and federated training frameworks, GWTF enables the efficient
collaborative training of a LLM on heterogeneous clients that volunteer their
resources. In addition, GWTF addresses node churn, i.e., clients joining or
leaving the system at any time, and network instabilities, i.e., network links
becoming unstable or unreliable. The core of GWTF is a novel decentralized flow
algorithm that finds the most effective routing that maximizes the number of
microbatches trained with the lowest possible delay. We extensively evaluate
GWTF on GPT-like and LLaMa-like models and compare it against the prior art.
Our results indicate that GWTF reduces the training time by up to 45% in
realistic and challenging scenarios that involve heterogeneous client nodes
distributed over 10 different geographic locations with a high node churn rate.

</details>


### [309] [Tree Search for LLM Agent Reinforcement Learning](https://arxiv.org/abs/2509.21240)
*Yuxiang Ji,Ziyu Ma,Yong Wang,Guanhua Chen,Xiangxiang Chu,Liaoni Wu*

Main category: cs.LG

TL;DR: 提出基于树搜索的分组智能体强化学习方法Tree-GRPO，利用树结构轨迹生成逐步过程监督信号，在稀疏奖励下提升长周期多轮任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有仅依赖结果奖励的方法在长周期、多轮智能体任务中面临监督稀疏的问题，难以有效训练。

Method: 提出Tree-GRPO，将每个树节点表示为完整的智能体交互步骤，通过共享前缀的树搜索采样增加 rollout 数量，并在树内和树间两个层次上估计分组相对优势，利用结果奖励构建逐步过程监督信号。

Result: 理论分析表明，树内分组相对策略优化目标等价于步骤级直接偏好学习；在11个数据集和3类问答任务上的实验显示，该方法优于基于链式结构的RL方法。

Conclusion: Tree-GRPO通过引入树结构和分组相对策略优化，有效缓解了稀疏奖励下的监督不足问题，提升了大语言模型在复杂多步任务中的表现。

Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced
the agentic capabilities of large language models (LLMs). In long-term and
multi-turn agent tasks, existing approaches driven solely by outcome rewards
often suffer from the problem of sparse supervision. To address the challenge,
we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped
agent RL method based on tree search, where each tree node represents the
complete agent interaction step. By sharing common prefixes, the tree search
sampling increases the number of rollouts achievable within a fixed budget of
tokens or tool calls. Moreover, we find that the tree-structured trajectory
naturally allows the construction of step-wise process supervised signals even
using only the outcome reward. Based on this, Tree-GRPO estimates the grouped
relative advantages both on intra-tree and inter-tree levels. Through
theoretical analysis, we demonstrate that the objective of intra-tree level
group relative policy optimization is equivalent to that of step-level direct
preference learning. Experiments across 11 datasets and 3 types of QA tasks
demonstrate the superiority of the proposed tree-based RL over the chain-based
RL method.

</details>


### [310] [Explaining Fine Tuned LLMs via Counterfactuals A Knowledge Graph Driven Framework](https://arxiv.org/abs/2509.21241)
*Yucheng Wang,Ziyang Chen,Md Faisal Kabir*

Main category: cs.LG

TL;DR: 本文提出了一种基于知识图谱的反事实解释框架CFFTLLMExplainer，用于分析LoRA微调对大语言模型结构推理和语义行为的影响。


<details>
  <summary>Details</summary>
Motivation: 理解LoRA等高效微调方法如何改变大语言模型的结构和语义行为仍是一个开放问题。

Method: 构建生物信息学领域的异构知识图谱BioToolKG，并设计基于反事实的解释器CFFTLLMExplainer，通过学习节点和边的软掩码，生成最小结构扰动以引发最大语义差异，同时优化结构稀疏性和语义发散性，并施加熵正则化和边平滑等可解释性约束。

Result: 在基于LLaMA的微调模型上验证表明，反事实掩码能揭示模型的结构依赖关系，并与LoRA引起的参数变化相一致。

Conclusion: 该工作为理解微调大模型的内部机制提供了新视角，表明基于反事实的知识图谱可作为实现可解释AI的有效工具。

Abstract: The widespread adoption of Low-Rank Adaptation (LoRA) has enabled large
language models (LLMs) to acquire domain-specific knowledge with remarkable
efficiency. However, understanding how such a fine-tuning mechanism alters a
model's structural reasoning and semantic behavior remains an open challenge.
This work introduces a novel framework that explains fine-tuned LLMs via
counterfactuals grounded in knowledge graphs. Specifically, we construct
BioToolKG, a domain-specific heterogeneous knowledge graph in bioinformatics
tools and design a counterfactual-based fine-tuned LLMs explainer
(CFFTLLMExplainer) that learns soft masks over graph nodes and edges to
generate minimal structural perturbations that induce maximum semantic
divergence. Our method jointly optimizes structural sparsity and semantic
divergence while enforcing interpretability preserving constraints such as
entropy regularization and edge smoothness. We apply this framework to a
fine-tuned LLaMA-based LLM and reveal that counterfactual masking exposes the
model's structural dependencies and aligns with LoRA-induced parameter shifts.
This work provides new insights into the internal mechanisms of fine-tuned LLMs
and highlights counterfactual graphs as a potential tool for interpretable AI.

</details>


### [311] [Federated Flow Matching](https://arxiv.org/abs/2509.21250)
*Zifan Wang,Anqi Dong,Mahmoud Selim,Michael M. Zavlanos,Karl H. Johansson*

Main category: cs.LG

TL;DR: 本文提出了Federated Flow Matching (FFM) 框架，用于在隐私约束下从分布式数据中训练生成模型，包括FFM-vanilla、FFM-LOT和FFM-GOT三种方法，实验证明其在保护隐私的同时提升了流的直线性和样本质量。


<details>
  <summary>Details</summary>
Motivation: 由于数据分散在不同设备和机构中，且受隐私、所有权和法规限制难以集中，因此需要一种能够在本地直接训练生成模型而不进行中心聚合的方法。

Method: 提出Federated Flow Matching (FFM) 框架，包含三种变体：FFM-vanilla（独立耦合）、FFM-LOT（局部最优传输耦合）和FFM-GOT（基于最优传输半对偶形式的全局协调策略）。

Result: 在合成数据和图像数据集上的实验表明，FFM能在联邦学习场景下实现隐私保护训练，并提升流的直线性和生成样本质量，性能接近集中式基线方法。

Conclusion: FFM-GOT通过共享全局势函数实现了跨客户端的耦合协调，在保持隐私的同时显著改善了流动特性和生成效果，是适用于分布式数据生成建模的有效框架。

Abstract: Data today is decentralized, generated and stored across devices and
institutions where privacy, ownership, and regulation prevent centralization.
This motivates the need to train generative models directly from distributed
data locally without central aggregation. In this paper, we introduce Federated
Flow Matching (FFM), a framework for training flow matching models under
privacy constraints. Specifically, we first examine FFM-vanilla, where each
client trains locally with independent source and target couplings, preserving
privacy but yielding curved flows that slow inference. We then develop FFM-LOT,
which employs local optimal transport couplings to improve straightness within
each client but lacks global consistency under heterogeneous data. Finally, we
propose FFM-GOT, a federated strategy based on the semi-dual formulation of
optimal transport, where a shared global potential function coordinates
couplings across clients. Experiments on synthetic and image datasets show that
FFM enables privacy-preserving training while enhancing both the flow
straightness and sample quality in federated settings, with performance
comparable to the centralized baseline.

</details>


### [312] [humancompatible.train: Implementing Optimization Algorithms for Stochastically-Constrained Stochastic Optimization Problems](https://arxiv.org/abs/2509.21254)
*Andrii Kliachkin,Jana Lepšová,Gilles Bareilles,Jakub Mareček*

Main category: cs.LG

TL;DR: 提出一个基于PyTorch的可扩展Python包humancompatible.train，用于带随机约束的深度神经网络训练，并实现多种先前未实现的算法。


<details>
  <summary>Details</summary>
Motivation: 近年来在公平性和安全性等应用中对深度神经网络的约束训练有较大兴趣，但尚无行业标准。

Method: 开发了一个易于扩展的PyTorch-based Python工具包，并实现了多个用于随机约束随机优化的新算法。

Result: 通过在具有公平性约束的深度学习任务上比较两种算法，展示了该工具包的有效性和实用性。

Conclusion: humancompatible.train为带约束的深度学习提供了一个灵活且可扩展的解决方案，有助于推动该领域的标准化。

Abstract: There has been a considerable interest in constrained training of deep neural
networks (DNNs) recently for applications such as fairness and safety. Several
toolkits have been proposed for this task, yet there is still no industry
standard. We present humancompatible.train
(https://github.com/humancompatible/train), an easily-extendable PyTorch-based
Python package for training DNNs with stochastic constraints. We implement
multiple previously unimplemented algorithms for stochastically constrained
stochastic optimization. We demonstrate the toolkit use by comparing two
algorithms on a deep learning task with fairness constraints.

</details>


### [313] [A Causality-Aware Spatiotemporal Model for Multi-Region and Multi-Pollutant Air Quality Forecasting](https://arxiv.org/abs/2509.21260)
*Junxin Lu,Shiliang Sun*

Main category: cs.LG

TL;DR: 提出了一种新的深度时空预测模型AirPCM，用于实现多污染物、多区域的空气质量预测，能够捕捉气象-污染物之间的因果关系，并在多个真实数据集上表现出优于现有方法的预测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于多污染物相互作用、气象条件变化和区域空间异质性，现有方法难以实现准确且可扩展的跨区域空气质量预测。

Method: 提出AirPCM模型，采用统一架构联合建模跨站点空间相关性、时间自相关性和气象-污染物动态因果关系，支持细粒度、可解释的多尺度多污染物预测。

Result: 在多尺度真实数据集上的实验表明，AirPCM在预测精度和泛化能力上均优于最先进的基线方法，并具备良好的长期预测能力。

Conclusion: AirPCM能有效支持细粒度空气质量预测和突发污染事件预警，为环境治理和碳减排规划提供及时、可靠的数据支持。

Abstract: Air pollution, a pressing global problem, threatens public health,
environmental sustainability, and climate stability. Achieving accurate and
scalable forecasting across spatially distributed monitoring stations is
challenging due to intricate multi-pollutant interactions, evolving
meteorological conditions, and region specific spatial heterogeneity. To
address this challenge, we propose AirPCM, a novel deep spatiotemporal
forecasting model that integrates multi-region, multi-pollutant dynamics with
explicit meteorology-pollutant causality modeling. Unlike existing methods
limited to single pollutants or localized regions, AirPCM employs a unified
architecture to jointly capture cross-station spatial correlations, temporal
auto-correlations, and meteorology-pollutant dynamic causality. This empowers
fine-grained, interpretable multi-pollutant forecasting across varying
geographic and temporal scales, including sudden pollution episodes. Extensive
evaluations on multi-scale real-world datasets demonstrate that AirPCM
consistently surpasses state-of-the-art baselines in both predictive accuracy
and generalization capability. Moreover, the long-term forecasting capability
of AirPCM provides actionable insights into future air quality trends and
potential high-risk windows, offering timely support for evidence-based
environmental governance and carbon mitigation planning.

</details>


### [314] [SuperOffload: Unleashing the Power of Large-Scale LLM Training on Superchips](https://arxiv.org/abs/2509.21271)
*Xinyu Lian,Masahiro Tanaka,Olatunji Ruwase,Minjia Zhang*

Main category: cs.LG

TL;DR: 本文提出了SuperOffload，一种面向Superchip架构的高效大语言模型训练卸载系统，通过多项优化技术显著提升了训练吞吐量和资源利用率。


<details>
  <summary>Details</summary>
Motivation: Superchips采用紧耦合异构架构（如GPU与CPU集成），但现有研究缺乏对其在LLM训练中卸载机制的有效探索，因此需要重新审视传统卸载假设。

Method: 提出SuperOffload系统，结合自适应权重卸载、分桶重分区、Superchip感知类型转换、推测执行以及针对Grace CPU优化的Adam优化器，并集成ZeRO和Ulysses并行策略。

Result: 在NVIDIA GH200上实现最高2.5倍的吞吐提升，单个Superchip可训练25B模型；8块GH200支持百万级序列长度的13B模型训练，达到55% MFU。

Conclusion: SuperOffload充分挖掘了Superchip架构潜力，为下一代AI硬件上的大模型训练提供了高效、可扩展的解决方案。

Abstract: The emergence of Superchips represents a significant advancement in
next-generation AI hardware. These Superchips employ a tightly coupled
heterogeneous architecture that integrates GPU and CPU on the same package,
which offers unprecedented computational power. However, there has been scant
research investigating how LLM training benefits from this new architecture. In
this work, for the first time, we study LLM training solutions based on
offloading for Superchips. We observe important differences between Superchips
and traditional loosely-coupled GPU-CPU architecture, which necessitate
revisiting prevailing assumptions about offloading. Based on that, we present
SuperOffload, a Superchip-centric offloading system that simultaneously uses
Hopper GPU, Grace CPU, and NVLink-C2C interconnect more efficiently.
SuperOffload accomplishes this via a combination of techniques, such as
adaptive weight offloading, bucketization repartitioning, Superchip-aware
casting, speculative execution, and a highly optimized Adam optimizer for Grace
CPUs. Our evaluation of SuperOffload on NVIDIA GH200 demonstrates up to 2.5x
throughput improvement compared to state-of-the-art offloading-based systems,
enabling training of up to 25B model on a single Superchip while achieving high
training throughput. We also extend SuperOffload with ZeRO-style data
parallelism and DeepSpeed-Ulysses sequence parallelism, enabling training of
13B model with sequence lengths up to 1 million tokens on 8 GH200 while
achieving 55% MFU.

</details>


### [315] [It's Not You, It's Clipping: A Soft Trust-Region via Probability Smoothing for LLM RL](https://arxiv.org/abs/2509.21282)
*Madeleine Dwyer,Adam Sobey,Adriane Chapman*

Main category: cs.LG

TL;DR: 提出了一种新的策略优化方法PSPO，用于训练大语言模型，相比传统的剪裁方法，在保持更新稳定性的同时提升了性能和推理质量。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中的比率剪裁虽然稳定更新，但会丢弃信息并引入梯度不连续性，需要一种既能稳定训练又能保留梯度信号的方法。

Method: 提出概率平滑策略优化（PSPO），在计算重要性比率前将当前策略向旧策略平滑，类似于标签平滑，并将其应用于GRPO框架中形成GR-PSPO。

Result: 在Qwen2.5-0.5B和Qwen2.5-1.5B模型上实验显示，GR-PSPO显著优于剪裁版GRPO，在GSM8K上分别提升22.1%和21.6%，且生成的推理更清晰、逻辑更强。

Conclusion: PSPO通过平滑策略分布有效替代剪裁，在理论上提供软信任域，并在实践中显著提升模型性能和推理质量。

Abstract: Training large language models (LLMs) with reinforcement learning (RL)
methods such as PPO and GRPO commonly relies on ratio clipping to stabilise
updates. While effective at preventing instability, clipping discards
information and introduces gradient discontinuities. We propose Probability
Smoothing Policy Optimisation (PSPO), which smooths the current policy's
probabilities toward the old (behaviour) policy before computing the importance
ratio, analogous to label smoothing. Unlike clipping, PSPO preserves gradient
signal, while interpolation toward the old policy creates a soft trust region
that discourages large, destabilising updates, with formal guarantees.
  We instantiate PSPO within GRPO (GR-PSPO) and fine-tune Qwen2.5-0.5B and
Qwen2.5-1.5B on GSM8K, evaluating on GSM8K test and the cross-dataset
generalisation on SVAMP, ASDiv, and MATH-500. Relative to unclipped GRPO
(single iteration; no data reuse, ratio always = 1), GR-PSPO achieves similar
performance but improves the reasoning leading to clearer and more concise
responses which are more logical. Compared to clipped GRPO, GR-PSPO
substantially improves performance both the 0.5B and 1.5B models, with a boost
of over 20% on GSM8K (39.7% vs. 17.6% for 0.5B, 59.4% vs. 37.8% for 1.5B).

</details>


### [316] [Optimal Robust Recourse with $L^p$-Bounded Model Change](https://arxiv.org/abs/2509.21293)
*Phone Kyaw,Kshitij Kayastha,Shahin Jabbari*

Main category: cs.LG

TL;DR: 本文提出了一种新的算法，用于在模型变化遵循L^p范数（p≥1且p≠∞）的情况下，为广义线性模型计算具有理论最优保证的鲁棒反事实解释，相较于先前工作显著降低了反事实代价，并实现了更好的可行性与有效性权衡。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒反事实方法多基于L^∞范数衡量模型变化，可能导致反事实建议代价过高；同时，多数方法缺乏最优性理论保证。因此，需要一种在更受限模型变化下仍能提供最优且低成本反事实的框架。

Method: 本文针对广义线性模型，在L^p范数约束下建模模型变化，提出一种可证明最优地计算鲁棒反事实的算法，并扩展至非线性模型进行实证验证。

Result: 实验表明，所提算法相比先前工作显著降低了反事实代价（数量级降低），提供了更稀疏的建议，并在实现成本与有效性之间取得更好平衡，且对保证可行性的后处理方法保持鲁棒。

Conclusion: 本文算法在L^p范数约束下为广义线性模型提供了首个具有最优性保证的鲁棒反事实解决方案，有效降低了建议成本并提升了实用性。

Abstract: Recourse provides individuals who received undesirable labels (e.g., denied a
loan) from algorithmic decision-making systems with a minimum-cost improvement
suggestion to achieve the desired outcome. However, in practice, models often
get updated to reflect changes in the data distribution or environment,
invalidating the recourse recommendations (i.e., following the recourse will
not lead to the desirable outcome). The robust recourse literature addresses
this issue by providing a framework for computing recourses whose validity is
resilient to slight changes in the model. However, since the optimization
problem of computing robust recourse is non-convex (even for linear models),
most of the current approaches do not have any theoretical guarantee on the
optimality of the recourse. Recent work by Kayastha et. al. provides the first
provably optimal algorithm for robust recourse with respect to generalized
linear models when the model changes are measured using the $L^{\infty}$ norm.
However, using the $L^{\infty}$ norm can lead to recourse solutions with a high
price. To address this shortcoming, we consider more constrained model changes
defined by the $L^p$ norm, where $p\geq 1$ but $p\neq \infty$, and provide a
new algorithm that provably computes the optimal robust recourse for
generalized linear models. Empirically, for both linear and non-linear models,
we demonstrate that our algorithm achieves a significantly lower price of
recourse (up to several orders of magnitude) compared to prior work and also
exhibits a better trade-off between the implementation cost of recourse and its
validity. Our empirical analysis also illustrates that our approach provides
more sparse recourses compared to prior work and remains resilient to
post-processing approaches that guarantee feasibility.

</details>


### [317] [No Prior, No Leakage: Revisiting Reconstruction Attacks in Trained Neural Networks](https://arxiv.org/abs/2509.21296)
*Yehonatan Refael,Guy Smorodinsky,Ofir Lindenbaum,Itay Safran*

Main category: cs.LG

TL;DR: 本文研究了神经网络中训练数据泄露的理论基础，指出在缺乏数据先验知识的情况下，重构攻击存在根本性不可靠性，并发现更充分训练的模型反而更不易受此类攻击。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究表明可从模型参数中重建训练数据，但这些方法的可靠性缺乏理论支持。作者旨在分析现有重构方法的局限性，并揭示其失败条件。

Method: 通过理论证明展示在无数据先验的情况下存在无限多解，使得重构不唯一；并通过实验验证训练样本的精确复制仅为偶然现象。

Result: 证明了训练集重构在理论上是不可靠的；发现更强的隐式偏差（如充分训练）反而降低重构成功率。

Conclusion: 训练数据泄露并非必然，重构攻击依赖特定条件；更彻底训练的模型在提升泛化的同时也能增强隐私安全性。

Abstract: The memorization of training data by neural networks raises pressing concerns
for privacy and security. Recent work has shown that, under certain conditions,
portions of the training set can be reconstructed directly from model
parameters. Some of these methods exploit implicit bias toward margin
maximization, suggesting that properties often regarded as beneficial for
generalization may actually compromise privacy. Yet despite striking empirical
demonstrations, the reliability of these attacks remains poorly understood and
lacks a solid theoretical foundation. In this work, we take a complementary
perspective: rather than designing stronger attacks, we analyze the inherent
weaknesses and limitations of existing reconstruction methods and identify
conditions under which they fail. We rigorously prove that, without
incorporating prior knowledge about the data, there exist infinitely many
alternative solutions that may lie arbitrarily far from the true training set,
rendering reconstruction fundamentally unreliable. Empirically, we further
demonstrate that exact duplication of training examples occurs only by chance.
Our results refine the theoretical understanding of when training set leakage
is possible and offer new insights into mitigating reconstruction attacks.
Remarkably, we demonstrate that networks trained more extensively, and
therefore satisfying implicit bias conditions more strongly -- are, in fact,
less susceptible to reconstruction attacks, reconciling privacy with the need
for strong generalization in this setting.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [318] [SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing](https://arxiv.org/abs/2509.20400)
*Yiyu Li,Haoyuan Wang,Ke Xu,Gerhard Petrus Hancke,Rynson W. H. Lau*

Main category: cs.GR

TL;DR: 本文提出了一种名为SeHDR的新方法，用于从单次曝光的多视角低动态范围（LDR）图像生成高动态范围（HDR）新视角，避免了传统多曝光采集的复杂性和误差。


<details>
  <summary>Details</summary>
Motivation: 现有HDR方法通常需要不同曝光的多视角图像，采集繁琐且易受运动模糊和配准误差影响，限制了实际应用。

Method: SeHDR首先从单次曝光的LDR图像中学习基础3D高斯分布，并在几何不变的前提下，通过曝光操作估计具有不同线性颜色的多组3D高斯；然后提出可微分神经曝光融合（NeEF）模块，将这些高斯合并为HDR场景表示以实现新视角渲染。

Result: 实验表明，SeHDR在新视角合成任务中优于现有方法和精心设计的基线模型，能够有效恢复高质量的HDR细节。

Conclusion: SeHDR成功实现了仅用单次曝光多视角LDR图像构建HDR场景表示，为HDR-3DGS提供了更实用、鲁棒的解决方案。

Abstract: This paper presents SeHDR, a novel high dynamic range 3D Gaussian Splatting
(HDR-3DGS) approach for generating HDR novel views given multi-view LDR images.
Unlike existing methods that typically require the multi-view LDR input images
to be captured from different exposures, which are tedious to capture and more
likely to suffer from errors (e.g., object motion blurs and
calibration/alignment inaccuracies), our approach learns the HDR scene
representation from multi-view LDR images of a single exposure. Our key insight
to this ill-posed problem is that by first estimating Bracketed 3D Gaussians
(i.e., with different exposures) from single-exposure multi-view LDR images, we
may then be able to merge these bracketed 3D Gaussians into an HDR scene
representation. Specifically, SeHDR first learns base 3D Gaussians from
single-exposure LDR inputs, where the spherical harmonics parameterize colors
in a linear color space. We then estimate multiple 3D Gaussians with identical
geometry but varying linear colors conditioned on exposure manipulations.
Finally, we propose the Differentiable Neural Exposure Fusion (NeEF) to
integrate the base and estimated 3D Gaussians into HDR Gaussians for novel view
rendering. Extensive experiments demonstrate that SeHDR outperforms existing
methods as well as carefully designed baselines.

</details>


### [319] [SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment](https://arxiv.org/abs/2509.20401)
*Binod Singh,Sayan Deb Sarkar,Iro Armeni*

Main category: cs.GR

TL;DR: 提出SGAligner++，一种跨模态语言辅助的3D场景图对齐框架，通过学习统一的联合嵌入空间，在低重叠和噪声条件下实现更准确的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一模态点云数据，难以处理不完整或噪声输入，且在跨模态对齐方面表现不佳。

Method: 采用轻量级单模态编码器和基于注意力的融合机制，学习统一的联合嵌入空间以实现跨模态对齐。

Result: 在真实世界数据集上评估显示，相比最先进方法在噪声数据上性能提升高达40%，并支持跨模态泛化。

Conclusion: SGAligner++有效提升了3D场景图对齐的鲁棒性和准确性，适用于视觉定位、3D重建和导航等任务。

Abstract: Aligning 3D scene graphs is a crucial initial step for several applications
in robot navigation and embodied perception. Current methods in 3D scene graph
alignment often rely on single-modality point cloud data and struggle with
incomplete or noisy input. We introduce SGAligner++, a cross-modal,
language-aided framework for 3D scene graph alignment. Our method addresses the
challenge of aligning partially overlapping scene observations across
heterogeneous modalities by learning a unified joint embedding space, enabling
accurate alignment even under low-overlap conditions and sensor noise. By
employing lightweight unimodal encoders and attention-based fusion, SGAligner++
enhances scene understanding for tasks such as visual localization, 3D
reconstruction, and navigation, while ensuring scalability and minimal
computational overhead. Extensive evaluations on real-world datasets
demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40%
on noisy real-world reconstructions, while enabling cross-modal generalization.

</details>


### [320] [SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent](https://arxiv.org/abs/2509.20414)
*Yandan Yang,Baoxiong Jia,Shujie Zhang,Siyuan Huang*

Main category: cs.GR

TL;DR: 本文提出了SceneWeaver，一种基于语言模型的反射型智能体框架，通过工具驱动的迭代优化实现室内场景合成，兼顾物理合理性、视觉真实感和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有室内场景生成方法受限于固定类别、缺乏细节和物理一致性，难以满足复杂用户指令的需求。

Method: 提出SceneWeaver框架，利用语言模型作为规划器，从多种可扩展的生成工具中选择并迭代调用，结合自评估机制优化场景的物理性、视觉质量和语义对齐。

Result: 在常见和开放词汇房间类型上实验表明，SceneWeaver在物理、视觉和语义指标上优于先前方法，并能有效泛化到复杂场景和多样化指令。

Conclusion: SceneWeaver通过闭环的推理-执行-反思机制，推动了通用3D环境生成的发展。

Abstract: Indoor scene synthesis has become increasingly important with the rise of
Embodied AI, which requires 3D environments that are not only visually
realistic but also physically plausible and functionally diverse. While recent
approaches have advanced visual fidelity, they often remain constrained to
fixed scene categories, lack sufficient object-level detail and physical
consistency, and struggle to align with complex user instructions. In this
work, we present SceneWeaver, a reflective agentic framework that unifies
diverse scene synthesis paradigms through tool-based iterative refinement. At
its core, SceneWeaver employs a language model-based planner to select from a
suite of extensible scene generation tools, ranging from data-driven generative
models to visual- and LLM-based methods, guided by self-evaluation of physical
plausibility, visual realism, and semantic alignment with user input. This
closed-loop reason-act-reflect design enables the agent to identify semantic
inconsistencies, invoke targeted tools, and update the environment over
successive iterations. Extensive experiments on both common and open-vocabulary
room types demonstrate that SceneWeaver not only outperforms prior methods on
physical, visual, and semantic metrics, but also generalizes effectively to
complex scenes with diverse instructions, marking a step toward general-purpose
3D environment generation. Project website: https://scene-weaver.github.io/.

</details>


### [321] [ArtUV: Artist-style UV Unwrapping](https://arxiv.org/abs/2509.20710)
*Yuguang Chen,Xinhai Liu,Yang Li,Victor Cheung,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: 本文提出了一种名为ArtUV的全自动、端到端方法，用于生成艺术家风格的UV展开图，通过两个阶段：表面接缝预测和艺术家风格UV参数化，解决了传统方法在时间消耗、碎片化、语义性和UV岛不规则等方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有UV展开方法在效率、语义性和实用性方面存在不足，难以满足高质量渲染和2D编辑的需求，因此需要一种能自动生成具有艺术家风格特征（如清晰边界、高效空间利用和语义一致性）的UV映射方法。

Method: 将UV展开分为两个阶段：首先使用SeamGPT预测语义上有意义的切割接缝；然后结合基于优化方法得到的粗略UV和网格输入到自动编码器中，进行精细化生成艺术家风格的UV映射。

Result: ArtUV在多个基准测试中表现出色，能够生成无重叠、低扭曲、结构清晰且语义一致的高质量UV图，并可作为专业渲染工具插件或独立系统使用。

Conclusion: ArtUV实现了高质量、语义连贯且适用于实际生产的自动化UV展开，显著提升了UV映射的自动化水平与可用性。

Abstract: UV unwrapping is an essential task in computer graphics, enabling various
visual editing operations in rendering pipelines. However, existing UV
unwrapping methods struggle with time-consuming, fragmentation, lack of
semanticity, and irregular UV islands, limiting their practical use. An
artist-style UV map must not only satisfy fundamental criteria, such as
overlap-free mapping and minimal distortion, but also uphold higher-level
standards, including clean boundaries, efficient space utilization, and
semantic coherence. We introduce ArtUV, a fully automated, end-to-end method
for generating artist-style UV unwrapping. We simulates the professional UV
mapping process by dividing it into two stages: surface seam prediction and
artist-style UV parameterization. In the seam prediction stage, SeamGPT is used
to generate semantically meaningful cutting seams. Then, in the
parameterization stage, a rough UV obtained from an optimization-based method,
along with the mesh, is fed into an Auto-Encoder, which refines it into an
artist-style UV map. Our method ensures semantic consistency and preserves
topological structure, making the UV map ready for 2D editing. We evaluate
ArtUV across multiple benchmarks and show that it serves as a versatile
solution, functioning seamlessly as either a plug-in for professional rendering
tools or as a standalone system for rapid, high-quality UV generation.

</details>


### [322] [SeamCrafte: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning](https://arxiv.org/abs/2509.20725)
*Duoteng Xu,Yuguang Chen,Jing Li,Xinhai Liu,Xueqi Ma,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: 本文提出了一种基于点云输入的自回归GPT风格的3D网格接缝生成方法SeamCrafter，通过双分支编码器提取拓扑与几何特征，并结合直接偏好优化（DPO）提升接缝质量，在UV畸变和碎片化方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D网格接缝生成方法往往在UV畸变和碎片化之间权衡，难以同时优化两者，影响纹理映射质量和艺术家工作流。

Method: 提出SeamCrafter，采用双分支点云编码器分离并捕捉拓扑与几何线索，并在预训练后使用基于新提出的接缝评估框架构建的偏好数据集，通过直接偏好优化（DPO）进行微调。

Result: 实验表明，SeamCrafter在UV畸变、碎片化、拓扑一致性和视觉保真度方面均优于先前方法，生成的接缝质量更高。

Conclusion: SeamCrafter能有效生成低畸变、少碎片的高质量接缝，显著提升了3D模型UV展开的自动化水平与实用性。

Abstract: Mesh seams play a pivotal role in partitioning 3D surfaces for UV
parametrization and texture mapping. Poorly placed seams often result in severe
UV distortion or excessive fragmentation, thereby hindering texture synthesis
and disrupting artist workflows. Existing methods frequently trade one failure
mode for another-producing either high distortion or many scattered islands. To
address this, we introduce SeamCrafter, an autoregressive GPT-style seam
generator conditioned on point cloud inputs. SeamCrafter employs a dual-branch
point-cloud encoder that disentangles and captures complementary topological
and geometric cues during pretraining. To further enhance seam quality, we
fine-tune the model using Direct Preference Optimization (DPO) on a preference
dataset derived from a novel seam-evaluation framework. This framework assesses
seams primarily by UV distortion and fragmentation, and provides pairwise
preference labels to guide optimization. Extensive experiments demonstrate that
SeamCrafter produces seams with substantially lower distortion and
fragmentation than prior approaches, while preserving topological consistency
and visual fidelity.

</details>


### [323] [ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction](https://arxiv.org/abs/2509.20824)
*Jiabao Lei,Kewei Shi,Zhihao Liang,Kui Jia*

Main category: cs.GR

TL;DR: 提出一种渐进式自回归生成3D网格的方法，通过反向简化过程从粗到细逐步构建网格，提升几何感知与编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有自回归网格生成方法按字典序逐面生成，难以有效捕捉符合人类感知的几何结构。

Method: 将网格简化视为由细到粗的过程，利用Transformer模型逆向建模该过程，从单点开始逐步局部重网格化，实现拓扑可变的渐进生成。

Result: 实验表明该方法能直观控制生成质量与耗时，并支持网格细化和编辑等应用。

Conclusion: 所提渐进式生成框架更符合几何认知，增强了生成灵活性与实用性。

Abstract: Directly generating 3D meshes, the default representation for 3D shapes in
the graphics industry, using auto-regressive (AR) models has become popular
these days, thanks to their sharpness, compactness in the generated results,
and ability to represent various types of surfaces. However, AR mesh generative
models typically construct meshes face by face in lexicographic order, which
does not effectively capture the underlying geometry in a manner consistent
with human perception. Inspired by 2D models that progressively refine images,
such as the prevailing next-scale prediction AR models, we propose generating
meshes auto-regressively in a progressive coarse-to-fine manner. Specifically,
we view mesh simplification algorithms, which gradually merge mesh faces to
build simpler meshes, as a natural fine-to-coarse process. Therefore, we
generalize meshes to simplicial complexes and develop a transformer-based AR
model to approximate the reverse process of simplification in the order of
level of detail, constructing meshes initially from a single point and
gradually adding geometric details through local remeshing, where the topology
is not predefined and is alterable. Our experiments show that this novel
progressive mesh generation approach not only provides intuitive control over
generation quality and time consumption by early stopping the auto-regressive
process but also enables applications such as mesh refinement and editing.

</details>


### [324] [ArchGPT: Understanding the World's Architectures with Large Multimodal Models](https://arxiv.org/abs/2509.20858)
*Yuze Wang,Luo Yang,Junyi Wang,Yue Qi*

Main category: cs.GR

TL;DR: 本文提出ArchGPT，一种用于建筑领域视觉问答（VQA）的多模态模型，并构建了包含约31.5万图像-问题-答案三元组的专用数据集Arch-300K，通过自动化数据构建流程提升现有VR/MR/AR系统在建筑理解中的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有VR/MR/AR系统在建筑应用中依赖硬编码注释和特定任务交互，难以跨不同建筑环境扩展，缺乏统一、高质量的建筑领域视觉问答数据集。

Method: 提出一个可扩展的数据构建流程：从Wikimedia Commons筛选建筑场景，采用由粗到细策略结合3D重建与语义分割选取无遮挡、结构一致的图像；利用大语言模型引导的文本验证与知识蒸馏生成高质量问答对；合成形式化分析注释以增强语义多样性；基于ShareGPT4V-7B在Arch-300K上进行监督微调得到ArchGPT。

Result: 构建了包含约315,000个样本的建筑专用VQA数据集Arch-300K，实现了高质量、结构一致的图像筛选与低噪声文本生成，并成功训练出具备建筑领域理解能力的多模态模型ArchGPT。

Conclusion: ArchGPT及其数据构建流程为建筑领域的沉浸式技术提供了可扩展的解决方案，展示了LLM辅助数据构建在专业领域多模态学习中的潜力，有望推动教育、遗产保护与设计实践中的智能建筑理解。

Abstract: Architecture embodies aesthetic, cultural, and historical values, standing as
a tangible testament to human civilization. Researchers have long leveraged
virtual reality (VR), mixed reality (MR), and augmented reality (AR) to enable
immersive exploration and interpretation of architecture, enhancing
accessibility, public understanding, and creative workflows around architecture
in education, heritage preservation, and professional design practice. However,
existing VR/MR/AR systems are often developed case-by-case, relying on
hard-coded annotations and task-specific interactions that do not scale across
diverse built environments. In this work, we present ArchGPT, a multimodal
architectural visual question answering (VQA) model, together with a scalable
data-construction pipeline for curating high-quality, architecture-specific VQA
annotations. This pipeline yields Arch-300K, a domain-specialized dataset of
approximately 315,000 image-question-answer triplets. Arch-300K is built via a
multi-stage process: first, we curate architectural scenes from Wikimedia
Commons and filter unconstrained tourist photo collections using a novel
coarse-to-fine strategy that integrates 3D reconstruction and semantic
segmentation to select occlusion-free, structurally consistent architectural
images. To mitigate noise and inconsistency in raw textual metadata, we propose
an LLM-guided text verification and knowledge-distillation pipeline to generate
reliable, architecture-specific question-answer pairs. Using these curated
images and refined metadata, we further synthesize formal analysis
annotations-including detailed descriptions and aspect-guided conversations-to
provide richer semantic variety while remaining faithful to the data. We
perform supervised fine-tuning of an open-source multimodal backbone
,ShareGPT4V-7B, on Arch-300K, yielding ArchGPT.

</details>


### [325] [Marching Neurons: Accurate Surface Extraction for Neural Implicit Shapes](https://arxiv.org/abs/2509.21007)
*Christian Stippel,Felix Mujkanovic,Thomas Leimkühler,Pedro Hermosilla*

Main category: cs.GR

TL;DR: 提出一种从神经隐式函数中解析提取表面的新方法，通过深度优先遍历策略高效跟踪编码表面，避免了传统方法因固定分辨率导致的误差，实现了高精度且快速的网格生成。


<details>
  <summary>Details</summary>
Motivation: 传统的隐式表示表面提取方法（如Marching Cubes）依赖空间分解和采样，受限于固定分辨率，导致几何细节丢失，难以准确还原神经隐式函数中的完整几何信息。

Method: 利用每个神经元对域进行划分的特性，提出一种原生支持并行计算的深度优先遍历策略，直接在神经隐式函数上进行解析式表面提取，无需额外的空间离散化。

Result: 生成的网格能忠实还原网络中的全部几何信息，在多种形状和网络架构下均达到前所未有的精度，同时保持较高的计算效率。

Conclusion: 该方法克服了传统表面提取算法在分辨率和精度上的局限，为神经隐式表示的几何重建提供了更优解决方案，适用于大规模神经网络和复杂形状建模。

Abstract: Accurate surface geometry representation is crucial in 3D visual computing.
Explicit representations, such as polygonal meshes, and implicit
representations, like signed distance functions, each have distinct advantages,
making efficient conversions between them increasingly important. Conventional
surface extraction methods for implicit representations, such as the widely
used Marching Cubes algorithm, rely on spatial decomposition and sampling,
leading to inaccuracies due to fixed and limited resolution. We introduce a
novel approach for analytically extracting surfaces from neural implicit
functions. Our method operates natively in parallel and can navigate large
neural architectures. By leveraging the fact that each neuron partitions the
domain, we develop a depth-first traversal strategy to efficiently track the
encoded surface. The resulting meshes faithfully capture the full geometric
information from the network without ad-hoc spatial discretization, achieving
unprecedented accuracy across diverse shapes and network architectures while
maintaining competitive speed.

</details>


### [326] [CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling](https://arxiv.org/abs/2509.21114)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Yushi Bai,Kaiwen Xiao,Yong-Jin Liu,Zhongqian Sun,Wei Yang*

Main category: cs.GR

TL;DR: 本文提出了CHARM，一种用于动漫发型建模的新型参数化表示和生成框架，通过基于控制点的紧凑表示和自回归生成模型实现高效、高质量的动漫发型生成。


<details>
  <summary>Details</summary>
Motivation: 传统发型建模方法难以处理动漫发型高度风格化和分段结构化的几何特性，现有方法在编辑效率和可扩展学习方面存在不足。

Method: 提出一种基于控制点的紧凑、可逆参数化表示，每个发片由一系列仅含五个几何参数的控制点表示，并构建基于自回归Transformer的生成框架，将动漫发型视为序列化的“发语言”进行建模。

Result: 在重建精度和生成质量方面均达到最先进水平，构建了包含3.7万个高质量动漫发型的大规模数据集AnimeHair以支持训练与评估。

Conclusion: CHARM为动漫发型建模提供了一种表达力强且可扩展的解决方案，兼顾艺术设计友好性与学习生成能力。

Abstract: We present CHARM, a novel parametric representation and generative framework
for anime hairstyle modeling. While traditional hair modeling methods focus on
realistic hair using strand-based or volumetric representations, anime
hairstyle exhibits highly stylized, piecewise-structured geometry that
challenges existing techniques. Existing works often rely on dense mesh
modeling or hand-crafted spline curves, making them inefficient for editing and
unsuitable for scalable learning. CHARM introduces a compact, invertible
control-point-based parameterization, where a sequence of control points
represents each hair card, and each point is encoded with only five geometric
parameters. This efficient and accurate representation supports both
artist-friendly design and learning-based generation. Built upon this
representation, CHARM introduces an autoregressive generative framework that
effectively generates anime hairstyles from input images or point clouds. By
interpreting anime hairstyles as a sequential "hair language", our
autoregressive transformer captures both local geometry and global hairstyle
topology, resulting in high-fidelity anime hairstyle creation. To facilitate
both training and evaluation of anime hairstyle generation, we construct
AnimeHair, a large-scale dataset of 37K high-quality anime hairstyles with
separated hair cards and processed mesh data. Extensive experiments demonstrate
state-of-the-art performance of CHARM in both reconstruction accuracy and
generation quality, offering an expressive and scalable solution for anime
hairstyle modeling. Project page: https://hyzcluster.github.io/charm/

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [327] [An Approach to Checking Correctness for Agentic Systems](https://arxiv.org/abs/2509.20364)
*Thomas J Sheffler*

Main category: cs.AI

TL;DR: 提出一种基于时序逻辑的表达语言，用于监控AI代理行为，通过检测执行轨迹中的异常来实现对LLM代理系统的可靠错误检测。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本匹配的错误检测方法因LLM输出的自然语言变异性而脆弱，难以稳定识别行为偏差。

Method: 借鉴硬件验证中的时态逻辑技术，定义一种时序表达语言，对代理的工具调用和状态转换序列进行断言，以独立于具体文本输出的方式监控行为模式。

Result: 在三代理系统中验证该方法，大模型能始终满足时序断言，而小模型则出现工具调用顺序错误和协作失败等违规行为，被时序表达式有效捕获。

Conclusion: 该方法为LLM代理系统提供了鲁棒的行为监控机制，可用于开发阶段的提示工程验证和部署后的回归测试，提升代理系统在关键应用中的可靠性。

Abstract: This paper presents a temporal expression language for monitoring AI agent
behavior, enabling systematic error-detection of LLM-based agentic systems that
exhibit variable outputs due to stochastic generation processes. Drawing from
temporal logic techniques used in hardware verification, this approach monitors
execution traces of agent tool calls and state transitions to detect deviations
from expected behavioral patterns. Current error-detection approaches rely
primarily on text matching of inputs and outputs, which proves fragile due to
the natural language variability inherent in LLM responses. The proposed method
instead focuses on the sequence of agent actions -- such as tool invocations
and inter-agent communications -- allowing verification of system behavior
independent of specific textual outputs. The temporal expression language
provides assertions that capture correct behavioral patterns across multiple
execution scenarios. These assertions serve dual purposes: validating prompt
engineering and guardrail effectiveness during development, and providing
regression testing when agents are updated with new LLMs or modified logic. The
approach is demonstrated using a three-agent system, where agents coordinate to
solve multi-step reasoning tasks. When powered by large, capable models, all
temporal assertions were satisfied across many test runs. However, when smaller
models were substituted in two of the three agents, executions violated
behavioral assertions, primarily due to improper tool sequencing and failed
coordination handoffs. The temporal expressions successfully flagged these
anomalies, demonstrating the method's effectiveness for detecting behavioral
regressions in production agentic systems. This approach provides a foundation
for systematic monitoring of AI agent reliability as these systems become
increasingly deployed in critical applications.

</details>


### [328] [Fairy: Interactive Mobile Assistant to Real-world Tasks via LMM-based Multi-agent](https://arxiv.org/abs/2509.20729)
*Jiazheng Sun,Te Yang,Jiayang Niu,Mingxuan Li,Yongyong Lu,Ruimeng Yang,Xin Peng*

Main category: cs.AI

TL;DR: 提出Fairy，一种可交互、持续学习的多模态移动助手，通过跨应用协作、用户交互和自我进化提升在真实场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长尾应用和动态用户需求时表现不佳，缺乏用户交互导致体验下降。

Method: 设计包含全局任务规划器、应用级执行器和自学习模块的三模块架构，支持跨应用任务分解、基于记忆的精细化执行与用户互动、以及经验固化为知识的持续学习。

Result: 在RealMobile-Eval基准上，基于GPT-4o的Fairy相比先前最优方法，用户需求完成率提升33.7%，冗余步骤减少58.5%。

Conclusion: Fairy通过交互式执行和持续学习机制，显著提升了在复杂真实移动环境中的性能和用户体验。

Abstract: Large multi-modal models (LMMs) have advanced mobile GUI agents. However,
existing methods struggle with real-world scenarios involving diverse app
interfaces and evolving user needs. End-to-end methods relying on model's
commonsense often fail on long-tail apps, and agents without user interaction
act unilaterally, harming user experience. To address these limitations, we
propose Fairy, an interactive multi-agent mobile assistant capable of
continuously accumulating app knowledge and self-evolving during usage. Fairy
enables cross-app collaboration, interactive execution, and continual learning
through three core modules:(i) a Global Task Planner that decomposes user tasks
into sub-tasks from a cross-app view; (ii) an App-Level Executor that refines
sub-tasks into steps and actions based on long- and short-term memory,
achieving precise execution and user interaction via four core agents operating
in dual loops; and (iii) a Self-Learner that consolidates execution experience
into App Map and Tricks. To evaluate Fairy, we introduce RealMobile-Eval, a
real-world benchmark with a comprehensive metric suite, and LMM-based agents
for automated scoring. Experiments show that Fairy with GPT-4o backbone
outperforms the previous SoTA by improving user requirement completion by 33.7%
and reducing redundant steps by 58.5%, showing the effectiveness of its
interaction and self-learning.

</details>


### [329] [LATTS: Locally Adaptive Test-Time Scaling](https://arxiv.org/abs/2509.20368)
*Theo Uscidda,Matthew Trager,Michael Kleinman,Aditya Chattopadhyay,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: 提出了一种名为局部自适应测试时扩展（LATTS）的方法，通过基于验证器的接受标准在每一步生成中动态分配计算资源，从而实现更优的准确率-计算权衡。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法对所有样本和生成步骤均匀增加计算量，未考虑实例复杂度，导致资源利用效率低下。

Method: 在每个生成步骤中，LATTS利用验证器模型判断是否重采样、回溯、重启或停止生成过程，根据局部难度动态调整计算开销。

Result: 实验结果表明，LATTS相比标准验证器方法在相同计算预算下实现了更高的准确性。

Conclusion: LATTS通过自适应分配计算资源，显著提升了大型语言模型在下游任务中的准确率-计算效率权衡。

Abstract: One common strategy for improving the performance of Large Language Models
(LLMs) on downstream tasks involves using a \emph{verifier model} to either
select the best answer from a pool of candidates or to steer the
auto-regressive generation process towards better outputs. This class of
methods typically results in improved accuracy at the cost of increased
computation at test-time, a paradigm known as \emph{test-time scaling}.
However, most existing approaches increase computation uniformly across all
samples and generation steps, without considering the complexity of individual
instances, leading to inefficient resource use. We address this limitation by
proposing an approach, called \emph{Locally Adaptive Test-Time Scaling
(LATTS)}, that allocates variable compute across generation steps.
Specifically, at each generation step, LATTS employs a verifier-based
acceptance criterion to decide whether to resample, backtrack, restart, or stop
the generation process. This criterion effectively adjusts the per-step
computational effort based on a precise notion of \emph{local difficulty}
derived from the verifier model. Empirical results show that LATTS achieves
significantly superior accuracy--compute tradeoffs compared to standard
verifier-based methods.

</details>


### [330] [ToMPO: Training LLM Strategic Decision Making from a Multi-Agent Perspective](https://arxiv.org/abs/2509.21134)
*Yiwen Zhang,Ziang Chen,Fanqi Kong,Yizhe Huang,Xue Feng*

Main category: cs.AI

TL;DR: 本文提出了一种名为ToMPO的算法，用于提升大语言模型在复杂场景中的战略决策能力，通过建模他人的策略和局势趋势，在模型输出合规性和合作结果上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注社交任务或多轮对话，忽视了决策类型及其依赖关系；同时强化学习方法难以在训练中考虑他人策略，因此需要一种能处理战略决策中多类型、时序依赖的新方法。

Method: 定义了包含两类决策及其时间依赖的战略决策问题，提出了ToMPO算法，通过推理他人策略生成rollouts，结合图级与样本级优势估计，并平衡全局与局部奖励进行优化。

Result: ToMPO相比GRPO算法在输出合规性和合作结果上提升35%，且相较于参数规模大100倍的模型仍有18%的性能提升。

Conclusion: ToMPO有效增强了大语言模型在复杂交互环境中的战略决策能力，展示了引入心智理论机制在多智能体决策中的潜力。

Abstract: Large Language Models (LLMs) have been used to make decisions in complex
scenarios, where they need models to think deeply, reason logically, and decide
wisely. Many existing studies focus solely on multi-round conversations in
social tasks or simulated environments, neglecting the various types of
decisions and their interdependence. Current reinforcement learning methods
struggle to consider the strategies of others during training. To address these
issues, we first define a strategic decision-making problem that includes two
types of decisions and their temporal dependencies. Furthermore, we propose
**T**heory **o**f **M**ind **P**olicy **O**ptimization **(ToMPO)** algorithm to
optimize the perception of other individual strategies and the game situation
trends. Compared to the Group Relative Policy Optimization (GRPO) algorithm,
ToMPO enhances the LLM's strategic decision-making mainly by: 1) generating
rollouts based on reasoning the strategies of other individuals, 2) estimating
advantages at both the graph-level and sample-level, and 3) balancing global
and partial rewards. The ToMPO algorithm outperforms the GRPO method by 35% in
terms of model output compliance and cooperative outcomes. Additionally, when
compared to models with parameter sizes 100 times larger, it shows an 18%
improvement. This demonstrates the effectiveness of the ToMPO algorithm in
enhancing the model's strategic decision-making capabilities.

</details>


### [331] [Philosophy-informed Machine Learning](https://arxiv.org/abs/2509.20370)
*MZ Naser*

Main category: cs.AI

TL;DR: 本文介绍了哲学引导的机器学习（PhIML），即将分析哲学的核心思想融入机器学习模型架构、目标和评估方法中，旨在通过设计上尊重哲学概念和价值观的模型来实现新的能力。文章回顾了其概念基础，展示了哲学上的增益与对齐，并通过案例研究说明了如何将PhIML作为事后工具或内置于模型架构中。最后，文章指出了技术和哲学、实践及治理方面的开放性挑战，并提出了通往安全、哲学感知且伦理负责的PhIML的研究路线图。


<details>
  <summary>Details</summary>
Motivation: 为了提升机器学习模型在伦理、价值对齐和哲学合理性方面的能力，将分析哲学的思想系统性地融入机器学习的设计中，推动更负责任的人工智能发展。

Method: 通过综述哲学与机器学习交叉的概念基础，结合案例研究，探讨PhIML在模型架构中的内在集成与作为外部工具的应用方式。

Result: 展示了PhIML在增强模型哲学一致性与伦理对齐方面的潜力，提出了其在技术实现与实际应用中的多种路径。

Conclusion: PhIML为构建安全、合乎伦理且具备哲学意识的机器学习系统提供了可行框架，但需克服多方面的技术与治理挑战，未来研究应沿着明确的路线图推进。

Abstract: Philosophy-informed machine learning (PhIML) directly infuses core ideas from
analytic philosophy into ML model architectures, objectives, and evaluation
protocols. Therefore, PhIML promises new capabilities through models that
respect philosophical concepts and values by design. From this lens, this paper
reviews conceptual foundations to demonstrate philosophical gains and
alignment. In addition, we present case studies on how ML users/designers can
adopt PhIML as an agnostic post-hoc tool or intrinsically build it into ML
model architectures. Finally, this paper sheds light on open technical barriers
alongside philosophical, practical, and governance challenges and outlines a
research roadmap toward safe, philosophy-aware, and ethically responsible
PhIML.

</details>


### [332] [InsightGUIDE: An Opinionated AI Assistant for Guided Critical Reading of Scientific Literature](https://arxiv.org/abs/2509.20493)
*Paris Koloveas,Serafeim Chatzopoulos,Thanasis Vergoulis,Christos Tryfonopoulos*

Main category: cs.AI

TL;DR: InsightGUIDE是一种新型AI驱动的阅读助手工具，通过嵌入专家阅读方法为科研人员提供简洁、结构化的论文关键要素导览，相较于通用大模型能生成更结构化且可操作的指导。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的文献摘要工具往往过于冗长，存在替代而非辅助阅读的风险，难以满足研究人员高效理解大量科学文献的需求。

Method: 设计并实现了一个名为InsightGUIDE的系统，其核心是将专家阅读方法嵌入到AI逻辑中，采用提示驱动的方法生成结构化洞察，并通过架构设计和案例研究验证其有效性。

Result: 定性案例研究表明，与通用大语言模型相比，InsightGUIDE能够生成更具结构化和可操作性的阅读指导，更好地辅助研究人员理解论文。

Conclusion: InsightGUIDE作为一种以辅助阅读为目标的AI工具，通过结构化输出和专家方法嵌入，显著提升了科研人员处理科学文献的效率和质量，展示了其作为现代研究辅助工具的有效性。

Abstract: The proliferation of scientific literature presents an increasingly
significant challenge for researchers. While Large Language Models (LLMs) offer
promise, existing tools often provide verbose summaries that risk replacing,
rather than assisting, the reading of the source material. This paper
introduces InsightGUIDE, a novel AI-powered tool designed to function as a
reading assistant, not a replacement. Our system provides concise, structured
insights that act as a "map" to a paper's key elements by embedding an expert's
reading methodology directly into its core AI logic. We present the system's
architecture, its prompt-driven methodology, and a qualitative case study
comparing its output to a general-purpose LLM. The results demonstrate that
InsightGUIDE produces more structured and actionable guidance, serving as a
more effective tool for the modern researcher.

</details>


### [333] [Reconstruction-Based Adaptive Scheduling Using AI Inferences in Safety-Critical Systems](https://arxiv.org/abs/2509.20513)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的重构框架，用于动态验证和生成时间触发系统（TTS）的可执行调度，有效应对消息冲突、优先级错误和不完整调度等问题，提升了系统的适应性与运行性能。


<details>
  <summary>Details</summary>
Motivation: 在动态操作环境中，传统调度框架面临消息碰撞、优先级处理错误导致的死锁环以及生成无效调度等问题，影响系统安全与可靠性，亟需一种能动态修复并生成安全调度的方法。

Method: 提出一种重构框架，将AI生成或启发式得出的调度优先级系统性地转化为完全可执行的调度方案，集成安全检查、高效分配算法和恢复机制，确保满足 precedence 约束和无冲突通信。

Result: 实验表明该框架在多种性能指标（如最小化完成时间、负载均衡、能效）下均显著提升系统适应性、运行完整性与实时性能，同时保持计算效率。

Conclusion: 该工作为安全关键的时间触发系统提供了一个实用且可扩展的调度生成解决方案，支持在高度动态和不确定环境下实现可靠、灵活的实时调度。

Abstract: Adaptive scheduling is crucial for ensuring the reliability and safety of
time-triggered systems (TTS) in dynamic operational environments. Scheduling
frameworks face significant challenges, including message collisions, locked
loops from incorrect precedence handling, and the generation of incomplete or
invalid schedules, which can compromise system safety and performance. To
address these challenges, this paper presents a novel reconstruction framework
designed to dynamically validate and assemble schedules. The proposed
reconstruction models operate by systematically transforming AI-generated or
heuristically derived scheduling priorities into fully executable schedules,
ensuring adherence to critical system constraints such as precedence rules and
collision-free communication. It incorporates robust safety checks, efficient
allocation algorithms, and recovery mechanisms to handle unexpected context
events, including hardware failures and mode transitions. Comprehensive
experiments were conducted across multiple performance profiles, including
makespan minimisation, workload balancing, and energy efficiency, to validate
the operational effectiveness of the reconstruction models. Results demonstrate
that the proposed framework significantly enhances system adaptability,
operational integrity, and runtime performance while maintaining computational
efficiency. Overall, this work contributes a practical and scalable solution to
the problem of safe schedule generation in safety-critical TTS, enabling
reliable and flexible real-time scheduling even under highly dynamic and
uncertain operational conditions.

</details>


### [334] [Adaptive Approach to Enhance Machine Learning Scheduling Algorithms During Runtime Using Reinforcement Learning in Metascheduling Applications](https://arxiv.org/abs/2509.20520)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 提出一种基于强化学习的自适应在线学习单元，集成于时间触发架构的元调度器中，以动态扩展多调度图（MSG），提升系统在复杂和不可预测环境下的实时性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统离线训练AI调度推断受限于难以构建覆盖所有可能场景的完整多调度图（MSG），尤其在面对硬件故障、时隙变化或模式切换等上下文事件时，导致调度方案不充分。

Method: 在元调度器中引入基于强化学习（RL）的在线学习单元，通过实时探索和发现新的调度策略，动态扩展MSG，并优化现有调度器。设计多种RL模型应对不同的调度挑战。

Result: 系统能够持续改进AI推断，有效处理意外事件和复杂调度场景，在线学习显著提升了调度灵活性、适应性和整体性能。

Conclusion: 该方法克服了离线训练的局限性，实现了在大规模、安全关键环境中高效、可靠的自适应调度。

Abstract: Metascheduling in time-triggered architectures has been crucial in adapting
to dynamic and unpredictable environments, ensuring the reliability and
efficiency of task execution. However, traditional approaches face significant
challenges when training Artificial Intelligence (AI) scheduling inferences
offline, particularly due to the complexities involved in constructing a
comprehensive Multi-Schedule Graph (MSG) that accounts for all possible
scenarios. The process of generating an MSG that captures the vast probability
space, especially when considering context events like hardware failures, slack
variations, or mode changes, is resource-intensive and often infeasible. To
address these challenges, we propose an adaptive online learning unit
integrated within the metascheduler to enhance performance in real-time. The
primary motivation for developing this unit stems from the limitations of
offline training, where the MSG created is inherently a subset of the complete
space, focusing only on the most probable and critical context events. In the
online mode, Reinforcement Learning (RL) plays a pivotal role by continuously
exploring and discovering new scheduling solutions, thus expanding the MSG and
enhancing system performance over time. This dynamic adaptation allows the
system to handle unexpected events and complex scheduling scenarios more
effectively. Several RL models were implemented within the online learning
unit, each designed to address specific challenges in scheduling. These models
not only facilitate the discovery of new solutions but also optimize existing
schedulers, particularly when stricter deadlines or new performance criteria
are introduced. By continuously refining the AI inferences through real-time
training, the system remains flexible and capable of meeting evolving demands,
thus ensuring robustness and efficiency in large-scale, safety-critical
environments.

</details>


### [335] [A Compound Classification System Based on Fuzzy Relations Applied to the Noise-Tolerant Control of a Bionic Hand via EMG Signal Recognition](https://arxiv.org/abs/2509.20523)
*Pawel Trajdos,Marek Kurzynski*

Main category: cs.AI

TL;DR: 本文提出了一种基于EMG信号的假手控制新识别系统，通过检测受污染的生物信号来减轻其对分类质量的不利影响。


<details>
  <summary>Details</summary>
Motivation: 由于生物信号易受污染，导致传统模式识别方法在假肢控制中分类质量不佳，因此需要提高识别系统的鲁棒性。

Method: 系统由两个集成模块组成：一组单类分类器（OCC）用于评估各通道信号的污染程度，以及K近邻（KNN）分类器集成用于识别患者意图；并采用统一的模糊模型实现软决策。

Result: 实验使用公开的真实生物信号数据集进行评估，结果表明该模糊识别系统在关键参数和流程上优于或媲美现有方法。

Conclusion: 所提出的模糊识别系统能有效缓解生物信号污染带来的负面影响，提升了假肢控制的分类性能，具有良好的应用前景。

Abstract: Modern anthropomorphic upper limb bioprostheses are typically controlled by
electromyographic (EMG) biosignals using a pattern recognition scheme.
Unfortunately, there are many factors originating from the human source of
objects to be classified and from the human-prosthesis interface that make it
difficult to obtain an acceptable classification quality. One of these factors
is the high susceptibility of biosignals to contamination, which can
considerably reduce the quality of classification of a recognition system.
  In the paper, the authors propose a new recognition system intended for EMG
based control of the hand prosthesis with detection of contaminated biosignals
in order to mitigate the adverse effect of contaminations. The system consists
of two ensembles: the set of one-class classifiers (OCC) to assess the degree
of contamination of individual channels and the ensemble of K-nearest
neighbours (KNN) classifier to recognise the patient's intent. For all
recognition systems, an original, coherent fuzzy model was developed, which
allows the use of a uniform soft (fuzzy) decision scheme throughout the
recognition process. The experimental evaluation was conducted using real
biosignals from a public repository. The goal was to provide an experimental
comparative analysis of the parameters and procedures of the developed method
on which the quality of the recognition system depends. The proposed fuzzy
recognition system was also compared with similar systems described in the
literature.

</details>


### [336] [SAMULE: Self-Learning Agents Enhanced by Multi-level Reflection](https://arxiv.org/abs/2509.20562)
*Yubin Ge,Salvatore Romeo,Jason Cai,Monica Sunkara,Yi Zhang*

Main category: cs.AI

TL;DR: 本文提出SAMULE框架，通过多级反思合成（单轨迹、任务内、任务间）训练回溯语言模型，提升大模型代理在复杂任务中的自我反思与改进能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理因缺乏有效的错误分析和依赖罕见的成功路径，难以生成有意义的反思，尤其在复杂任务中表现不足。

Method: 提出SAMULE框架，包含三级反思合成：微级别的单轨迹学习用于细粒度纠错；中级别的任务内学习构建错误分类；宏观的任务间学习提取跨任务的可迁移洞察，并微调语言模型以生成反思。引入基于预测的前瞻性反思机制以支持交互场景。

Result: 在TravelPlanner、NATURAL PLAN和Tau-bench三个挑战性基准上显著优于基于反思的基线方法。

Conclusion: 精心设计的反思合成与以失败为中心的学习对构建自改进的LLM代理至关重要。

Abstract: Despite the rapid advancements in LLM agents, they still face the challenge
of generating meaningful reflections due to inadequate error analysis and a
reliance on rare successful trajectories, especially in complex tasks. In this
work, we propose SAMULE, a new framework for self-learning agents powered by a
retrospective language model that is trained based on Multi-Level Reflection
Synthesis. It first synthesizes high-quality reflections across three
complementary levels: Single-Trajectory Learning (micro-level) for detailed
error correction; Intra-Task Learning (meso-level) to build error taxonomies
across multiple trials of the same task, and Inter-Task Learning (macro-level)
to extract transferable insights based on same typed errors from diverse task
failures. Then we fine-tune a language model serving as the retrospective model
to generate reflections during inference. We further extend our framework to
interactive settings through a foresight-based reflection mechanism, enabling
agents to proactively reflect and adapt during user interactions by comparing
predicted and actual responses. Extensive experiments on three challenging
benchmarks - TravelPlanner, NATURAL PLAN, and Tau-bench - demonstrate that our
approach significantly outperforms reflection-based baselines. Our results
highlight the critical role of well-designed reflection synthesis and
failure-centric learning in building self-improving LLM agents.

</details>


### [337] [Adaptive Cybersecurity Architecture for Digital Product Ecosystems Using Agentic AI](https://arxiv.org/abs/2509.20640)
*Oluwakemi T. Olayinka,Sumeet Jeswani,Divine Iloh*

Main category: cs.AI

TL;DR: 本文提出了一种基于自主目标驱动代理的自适应网络安全架构，利用智能体AI实现动态学习和上下文感知决策，以应对复杂数字生态系统中的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 传统静态网络安全模型在可扩展性、实时检测和上下文响应方面存在不足，难以应对当前包含云服务、API、移动平台和边缘设备的复杂环境。

Method: 设计并实现了一个集成智能体AI的自适应安全架构，涵盖行为基线建模、去中心化风险评分和联邦威胁情报共享，并在原生云环境中进行模拟验证。

Result: 系统能够有效识别零日攻击并动态调整访问策略，评估结果显示适应性增强、响应延迟降低、检测准确率提高。

Conclusion: 该架构为保护复杂数字基础设施提供了智能化、可扩展的解决方案，兼容零信任模型，支持符合国际网络安全法规。

Abstract: Traditional static cybersecurity models often struggle with scalability,
real-time detection, and contextual responsiveness in the current digital
product ecosystems which include cloud services, application programming
interfaces (APIs), mobile platforms, and edge devices. This study introduces
autonomous goal driven agents capable of dynamic learning and context-aware
decision making as part of an adaptive cybersecurity architecture driven by
agentic artificial intelligence (AI). To facilitate autonomous threat
mitigation, proactive policy enforcement, and real-time anomaly detection, this
framework integrates agentic AI across the key ecosystem layers. Behavioral
baselining, decentralized risk scoring, and federated threat intelligence
sharing are important features. The capacity of the system to identify zero-day
attacks and dynamically modify access policies was demonstrated through native
cloud simulations. The evaluation results show increased adaptability,
decreased response latency, and improved detection accuracy. The architecture
provides an intelligent and scalable blueprint for safeguarding complex digital
infrastructure and is compatible with zero-trust models, thereby supporting the
adherence to international cybersecurity regulations.

</details>


### [338] [Accelerate Creation of Product Claims Using Generative AI](https://arxiv.org/abs/2509.20652)
*Po-Yu Liang,Yong Zhang,Tatiana Hwa,Aaron Byers*

Main category: cs.AI

TL;DR: 提出了一种基于大语言模型的Claim Advisor网络应用，用于加速产品声明的搜索、生成、优化和模拟，已在消费品公司中取得良好应用效果。


<details>
  <summary>Details</summary>
Motivation: 产品声明对消费者购买行为有重要影响，但创建过程耗时且成本高，需要一种高效工具来提升声明创建效率。

Method: 利用大语言模型的上下文学习和微调技术，开发了具备语义搜索、声明生成与优化、以及通过合成消费者进行排名模拟三项功能的Claim Advisor应用。

Result: 在消费品公司中的应用表明，该工具能显著提升声明创建的速度和经济性，生成的声明更符合消费者偏好。

Conclusion: Claim Advisor有效推动了产品声明创建的自动化和智能化，具备跨行业推广的潜力，有助于促进生成式AI在各行业的研究与应用。

Abstract: The benefit claims of a product is a critical driver of consumers' purchase
behavior. Creating product claims is an intense task that requires substantial
time and funding. We have developed the $\textbf{Claim Advisor}$ web
application to accelerate claim creations using in-context learning and
fine-tuning of large language models (LLM). $\textbf{Claim Advisor}$ was
designed to disrupt the speed and economics of claim search, generation,
optimization, and simulation. It has three functions: (1) semantically
searching and identifying existing claims and/or visuals that resonate with the
voice of consumers; (2) generating and/or optimizing claims based on a product
description and a consumer profile; and (3) ranking generated and/or manually
created claims using simulations via synthetic consumers. Applications in a
consumer packaged goods (CPG) company have shown very promising results. We
believe that this capability is broadly useful and applicable across product
categories and industries. We share our learning to encourage the research and
application of generative AI in different industries.

</details>


### [339] [An Automated Retrieval-Augmented Generation LLaMA-4 109B-based System for Evaluating Radiotherapy Treatment Plans](https://arxiv.org/abs/2509.20707)
*Junjie Cui,Peilong Wang,Jason Holmes,Leshan Sun,Michael L. Hinni,Barbara A. Pockaj,Sujay A. Vora,Terence T. Sio,William W. Wong,Nathan Y. Yu,Steven E. Schild,Joshua R. Niska,Sameer R. Keole,Jean-Claude M. Rwigema,Samir H. Patel,Lisa A. McGee,Carlos A. Vargas,Wei Liu*

Main category: cs.AI

TL;DR: 本研究开发了一个基于LLaMA-4 109B的检索增强生成（RAG）系统，用于自动化、符合协议且可解释的放射治疗计划评估。


<details>
  <summary>Details</summary>
Motivation: 传统放疗计划评估依赖人工且难以保证一致性，现有自动化方法缺乏透明性和协议遵循能力。需要一个可解释、可靠并能适应多协议的评估系统。

Method: 构建包含614个放疗计划的多协议数据集和知识库，整合检索引擎（优化五种SentenceTransformer模型）、基于队列相似性的百分位预测模块和临床约束检查器，并由大语言模型通过多步提示推理协调各模块进行评估。

Result: 最优配置（all-MiniLM-L6-v2）在5百分点范围内达到完美的最近邻准确率，MAE低于2pt；端到端测试中与独立模块计算结果完全一致，验证了系统的可靠性。

Conclusion: 该RAG系统结合基于人群的结构化评分与模块化工具增强推理，实现了透明、可扩展的放疗计划评估，输出可追溯、幻觉少、跨协议鲁棒性强，具备临床应用潜力。

Abstract: Purpose: To develop a retrieval-augmented generation (RAG) system powered by
LLaMA-4 109B for automated, protocol-aware, and interpretable evaluation of
radiotherapy treatment plans.
  Methods and Materials: We curated a multi-protocol dataset of 614
radiotherapy plans across four disease sites and constructed a knowledge base
containing normalized dose metrics and protocol-defined constraints. The RAG
system integrates three core modules: a retrieval engine optimized across five
SentenceTransformer backbones, a percentile prediction component based on
cohort similarity, and a clinical constraint checker. These tools are directed
by a large language model (LLM) using a multi-step prompt-driven reasoning
pipeline to produce concise, grounded evaluations.
  Results: Retrieval hyperparameters were optimized using Gaussian Process on a
scalarized loss function combining root mean squared error (RMSE), mean
absolute error (MAE), and clinically motivated accuracy thresholds. The best
configuration, based on all-MiniLM-L6-v2, achieved perfect nearest-neighbor
accuracy within a 5-percentile-point margin and a sub-2pt MAE. When tested
end-to-end, the RAG system achieved 100% agreement with the computed values by
standalone retrieval and constraint-checking modules on both percentile
estimates and constraint identification, confirming reliable execution of all
retrieval, prediction and checking steps.
  Conclusion: Our findings highlight the feasibility of combining structured
population-based scoring with modular tool-augmented reasoning for transparent,
scalable plan evaluation in radiation therapy. The system offers traceable
outputs, minimizes hallucination, and demonstrates robustness across protocols.
Future directions include clinician-led validation, and improved domain-adapted
retrieval models to enhance real-world integration.

</details>


### [340] [Parallel Thinking, Sequential Answering: Bridging NAR and AR for Efficient Reasoning](https://arxiv.org/abs/2509.20744)
*Qihang Ai,Haiyun Jiang*

Main category: cs.AI

TL;DR: 提出一种结合自回归（AR）和非自回归（NAR）语言模型的新范式，利用NAR模型生成中间推理轨迹，指导AR模型输出精确答案，在提升性能的同时显著降低推理成本。


<details>
  <summary>Details</summary>
Motivation: AR模型在复杂推理任务中推理速度慢，NAR模型虽快但输出质量较低，需平衡速度与准确性。

Method: 使用NAR模型（如离散扩散模型）并行生成中间推理过程，再由AR模型基于这些推理轨迹生成最终答案。

Result: 相比强基线方法性能提升26%，同时显著降低了推理成本。

Conclusion: 该混合框架有效结合了AR与NAR模型的优势，在保持高质量输出的同时大幅提升了推理效率。

Abstract: We study reasoning tasks through a framework that integrates auto-regressive
(AR) and non-autoregressive (NAR) language models. AR models, which generate
text sequentially, excel at producing coherent outputs but often suffer from
slow inference, particularly in reasoning-intensive domains such as mathematics
and code, where lengthy chains of thought are required. In contrast, NAR
models, such as discrete diffusion models, allow parallel generation and offer
substantial speedups, though typically at the cost of reduced output quality.
To address these limitations, we introduce a new paradigm in which an NAR model
efficiently produces intermediate reasoning traces, which subsequently guide an
AR model to deliver precise final answers. Experiments demonstrate that our
approach yields significant 26% improvements over strong baselines while
substantially reducing inference cost.

</details>


### [341] [Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for Robot Spatial Reasoning](https://arxiv.org/abs/2509.20754)
*Yufan Mao,Hanjing Ye,Wenlong Dong,Chengjie Zhang,Hong Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为Meta-Memory的LLM驱动代理，用于构建高密度环境记忆表示，并通过语义与空间模态联合推理实现高效的记忆检索与整合，显著提升了机器人在复杂环境中的空间问答能力。


<details>
  <summary>Details</summary>
Motivation: 机器人在复杂环境中需要有效存储观察信息并利用这些记忆回答人类关于空间位置的查询，但现有研究在高效记忆检索与整合机制方面仍存在不足。

Method: 提出Meta-Memory，利用大语言模型（LLM）构建高密度记忆表征，并通过联合推理语义与空间模态来响应自然语言位置查询；同时构建大规模数据集SpaceLocQA用于评估。

Result: 实验表明，Meta-Memory在SpaceLocQA和公开基准NaVQA上均显著优于现有最先进方法，并在真实机器人平台上成功部署，验证了其在复杂环境中的实用性。

Conclusion: Meta-Memory通过融合语义与空间推理，实现了高效的记忆检索与集成，为机器人提供了强大的空间理解与问答能力，具有广泛的实际应用前景。

Abstract: Navigating complex environments requires robots to effectively store
observations as memories and leverage them to answer human queries about
spatial locations, which is a critical yet underexplored research challenge.
While prior work has made progress in constructing robotic memory, few have
addressed the principled mechanisms needed for efficient memory retrieval and
integration. To bridge this gap, we propose Meta-Memory, a large language model
(LLM)-driven agent that constructs a high-density memory representation of the
environment. The key innovation of Meta-Memory lies in its capacity to retrieve
and integrate relevant memories through joint reasoning over semantic and
spatial modalities in response to natural language location queries, thereby
empowering robots with robust and accurate spatial reasoning capabilities. To
evaluate its performance, we introduce SpaceLocQA, a large-scale dataset
encompassing diverse real-world spatial question-answering scenarios.
Experimental results show that Meta-Memory significantly outperforms
state-of-the-art methods on both the SpaceLocQA and the public NaVQA
benchmarks. Furthermore, we successfully deployed Meta-Memory on real-world
robotic platforms, demonstrating its practical utility in complex environments.
Project page: https://itsbaymax.github.io/meta-memory.github.io/ .

</details>


### [342] [LogReasoner: Empowering LLMs with Expert-like Coarse-to-Fine Reasoning for Log Analysis Tasks](https://arxiv.org/abs/2509.20798)
*Lipeng Ma,Yixuan Li,Weidong Yang,Mingjie Zhou,Xinyi Liu,Ben Fei,Shuhao Li,Xiaoyan Sun,Sihang Jiang,Yanghua Xiao*

Main category: cs.AI

TL;DR: 提出LogReasoner框架，通过粗粒度和细粒度推理增强，提升大语言模型在日志分析任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型难以生成符合专家思维的结构化推理流程，且缺乏详细的推理步骤精度。

Method: LogReasoner分为两个阶段：1）粗粒度增强，利用专家排错流程图构建高层思维；2）细粒度增强，通过任务特定的逐步解决方案微调模型，并使用偏好学习纠正错误，提升推理细节的准确性和精细度。

Result: 在Qwen-2.5和Llama-3等开源模型上实验表明，LogReasoner在四个日志分析任务中显著优于现有方法，达到最先进性能。

Conclusion: LogReasoner有效提升了大语言模型在日志分析任务中的结构化推理能力和分析精度。

Abstract: Log analysis is crucial for monitoring system health and diagnosing failures
in complex systems. Recent advances in large language models (LLMs) offer new
opportunities for automated log analysis, leveraging their reasoning
capabilities to perform tasks such as anomaly detection and failure prediction.
However, general-purpose LLMs struggle to formulate structured reasoning
workflows that align with expert cognition and deliver precise details of
reasoning steps. To address these challenges, we propose LogReasoner, a
coarse-to-fine reasoning enhancement framework designed to enable LLMs to
reason log analysis tasks like experts. LogReasoner consists of two stages: (1)
coarse-grained enhancement of expert thinking, where high-level expert thoughts
are constructed from collected troubleshooting flowcharts and existing tasks to
enable LLMs to formulate structured reasoning workflows and (2) fine-grained
enhancement of specific steps, where we first fine-tune the LLM with
task-specific stepwise solutions to enhance the LLM for instantiated reasoning,
then employ the preference learning to calibrate the LLM's reasoning details
from its mistakes, further strengthen the LLM's analytical granularity and
correctness. We evaluate LogReasoner on four distinct log analysis tasks using
open-source LLMs such as Qwen-2.5 and Llama-3. Experimental results show that
LogReasoner significantly outperforms existing LLMs, achieving state-of-the-art
performance and demonstrating its effectiveness in enhancing the reasoning
capabilities of LLMs for log analysis.

</details>


### [343] [DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reasoning](https://arxiv.org/abs/2509.20912)
*Tianrun Xu,Haoda Jing,Ye Li,Yuquan Wei,Jun Feng,Guanyu Chen,Haichuan Gao,Tianren Zhang,Feng Chen*

Main category: cs.AI

TL;DR: 提出DeFacto框架，通过反事实推理和三种训练范式提升多模态语言模型的答案准确性和推理保真度。


<details>
  <summary>Details</summary>
Motivation: 现有模型可能依赖无关区域或数据集偏差得出正确答案，缺乏真正的图像理解，需提高推理的保真性。

Method: 设计包含正例、反事实和随机掩码的三种训练范式，构建约10万图像的数据集，并基于GRPO强化学习引入三种奖励机制以促进准确回答和基于证据的推理。

Result: 在多个基准上实验表明，DeFacto显著提升了答案准确性和推理保真度。

Conclusion: DeFacto为可解释的多模态推理提供了更强的基础。

Abstract: Recent advances in multimodal language models (MLLMs) have achieved
remarkable progress in vision-language reasoning, especially with the emergence
of "thinking with images," which integrates explicit visual steps into the
reasoning process. While this paradigm strengthens image-based reasoning, a
significant challenge remains: models may arrive at correct answers by relying
on irrelevant or spurious regions, driven by prior knowledge or dataset biases.
Even when the answer is correct, flawed reasoning indicates that the model has
not truly understood the image, highlighting the critical importance of
reasoning fidelity in multimodal tasks. To address this issue, we propose
DeFacto, a counterfactual reasoning framework that jointly enforces accurate
answering and faithful reasoning. A key component of our approach is the design
of three complementary training paradigms: (i) positive, (ii) counterfactual,
and (iii) random-masking. To enable these paradigms, we develop a pipeline that
automatically localizes question-relevant evidence and constructs positive,
counterfactual, and random variants, resulting in a dataset of about 100k
images. Building on this framework, we train multimodal language models with
GRPO-based reinforcement learning, where we design three complementary rewards
to guide the model toward accurate answering and evidence-grounded reasoning.
Experiments on diverse benchmarks demonstrate that DeFacto substantially
improves both answer accuracy and reasoning faithfulness, establishing a
stronger foundation for interpretable multimodal reasoning. The code is
available on GitHub and the dataset is released on HuggingFace.

</details>


### [344] [GALAX: Graph-Augmented Language Model for Explainable Reinforcement-Guided Subgraph Reasoning in Precision Medicine](https://arxiv.org/abs/2509.20935)
*Heming Zhang,Di Huang,Wenyu Li,Michael Province,Yixin Chen,Philip Payne,Fuhai Li*

Main category: cs.AI

TL;DR: 提出GALAX框架，结合图神经网络与大语言模型，通过强化学习和子图推理实现精准医学中可解释的靶点与通路发现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整合多组学数据、拓扑结构和文本知识方面存在局限，缺乏机制可解释性，且过程奖励模型易受奖励欺骗并计算成本高。

Method: 提出GALAX框架，将预训练GNN集成到LLM中，通过图过程奖励模型（GPRM）进行强化学习指导，逐步生成疾病相关子图；使用Target-QA基准进行评估，支持文本-数值图上的长上下文推理。

Result: 实现了无需中间标注的进程级监督，提升了多模态整合能力，在癌症细胞系中实现了可解释的靶点和通路发现。

Conclusion: GALAX为精准医学提供了可扩展、生物学基础坚实的可解释子图推理框架，推动了多组学、拓扑与文献知识的融合。

Abstract: In precision medicine, quantitative multi-omic features, topological context,
and textual biological knowledge play vital roles in identifying
disease-critical signaling pathways and targets. Existing pipelines capture
only part of these-numerical omics ignore topological context, text-centric
LLMs lack quantitative grounded reasoning, and graph-only models underuse node
semantics and the generalization of LLMs-limiting mechanistic interpretability.
Although Process Reward Models (PRMs) aim to guide reasoning in LLMs, they
remain limited by unreliable intermediate evaluation, and vulnerability to
reward hacking with computational cost. These gaps motivate integrating
quantitative multi-omic signals, topological structure with node annotations,
and literature-scale text via LLMs, using subgraph reasoning as the principle
bridge linking numeric evidence, topological knowledge and language context.
Therefore, we propose GALAX (Graph Augmented LAnguage model with
eXplainability), an innovative framework that integrates pretrained Graph
Neural Networks (GNNs) into Large Language Models (LLMs) via reinforcement
guided by a Graph Process Reward Model (GPRM), which generates disease-relevant
subgraphs in a step-wise manner initiated by an LLM and iteratively evaluated
by a pretrained GNN, enabling process-level supervision without explicit
intermediate reasoning annotations. As an application, we also introduced
Target-QA, a benchmark combining CRISPR-identified targets, multi-omic
profiles, and biomedical graph knowledge across diverse cancer cell lines,
which enables GNN pretraining for supervising step-wise graph construction and
supports long-context reasoning over text-numeric graphs (TNGs), providing a
scalable and biologically grounded framework for explainable,
reinforcement-guided subgraph reasoning toward reliable and interpretable
target and pathway discovery in precision medicine.

</details>


### [345] [Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM](https://arxiv.org/abs/2509.20953)
*Najla Zuhir,Amna Mohammad Salim,Parvathy Premkumar,Moshiur Farazi*

Main category: cs.AI

TL;DR: 提出一种基于大语言模型和结构化提示的模块化框架，用于改进移动应用评论分析，克服传统评分和NLP方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统星评系统和NLP技术难以捕捉评论中的细粒度情感和语义信息，如讽刺、领域术语和上下文差异。

Method: 采用大语言模型（LLMs）结合结构化提示技术，量化评分与文本情感的差异，提取特征级洞察，并通过检索增强的对话问答（RAG-QA）支持交互式分析。

Result: 在AWARE、Google Play和Spotify三个数据集上的实验表明，该方法在准确性、鲁棒性和可操作性方面显著优于基线方法。

Conclusion: 所提出的LLM驱动框架能更有效地解析复杂评论内容，为开发者和用户提供更具价值的反馈分析。

Abstract: We present an advanced approach to mobile app review analysis aimed at
addressing limitations inherent in traditional star-rating systems. Star
ratings, although intuitive and popular among users, often fail to capture the
nuanced feedback present in detailed review texts. Traditional NLP techniques
-- such as lexicon-based methods and classical machine learning classifiers --
struggle to interpret contextual nuances, domain-specific terminology, and
subtle linguistic features like sarcasm. To overcome these limitations, we
propose a modular framework leveraging large language models (LLMs) enhanced by
structured prompting techniques. Our method quantifies discrepancies between
numerical ratings and textual sentiment, extracts detailed, feature-level
insights, and supports interactive exploration of reviews through
retrieval-augmented conversational question answering (RAG-QA). Comprehensive
experiments conducted on three diverse datasets (AWARE, Google Play, and
Spotify) demonstrate that our LLM-driven approach significantly surpasses
baseline methods, yielding improved accuracy, robustness, and actionable
insights in challenging and context-rich review scenarios.

</details>


### [346] [AOT*: Efficient Synthesis Planning via LLM-Empowered AND-OR Tree Search](https://arxiv.org/abs/2509.20988)
*Xiaozhuang Song,Xuanhao Pan,Xinjian Zhao,Hangting Ye,Shufei Zhang,Jian Tang,Tianshu Yu*

Main category: cs.AI

TL;DR: AOT* 是一个结合大语言模型（LLM）与系统化AND-OR树搜索的新型框架，用于提升多步逆合成规划的效率和性能，显著减少搜索迭代次数并实现最先进的求解率。


<details>
  <summary>Details</summary>
Motivation: 多步逆合成规划因搜索空间指数级增长和推理成本高而计算困难，现有LLM方法在效率和成本上存在局限。

Method: 提出AOT*框架，将LLM生成的完整合成路径原子化映射到AND-OR树结构中，设计了数学上合理的奖励分配策略和基于检索的上下文工程，以提升搜索效率。

Result: 在多个合成基准上的实验表明，AOT*在显著提高搜索效率的同时达到最先进（SOTA）性能，相比现有LLM方法仅需3-5倍更少的迭代次数即具竞争力，且在复杂分子上优势更明显。

Conclusion: AOT*有效整合LLM的化学推理能力与系统化搜索，为高效逆合成规划提供了可扩展且鲁棒的新范式。

Abstract: Retrosynthesis planning enables the discovery of viable synthetic routes for
target molecules, playing a crucial role in domains like drug discovery and
materials design. Multi-step retrosynthetic planning remains computationally
challenging due to exponential search spaces and inference costs. While Large
Language Models (LLMs) demonstrate chemical reasoning capabilities, their
application to synthesis planning faces constraints on efficiency and cost. To
address these challenges, we introduce AOT*, a framework that transforms
retrosynthetic planning by integrating LLM-generated chemical synthesis
pathways with systematic AND-OR tree search. To this end, AOT* atomically maps
the generated complete synthesis routes onto AND-OR tree components, with a
mathematically sound design of reward assignment strategy and retrieval-based
context engineering, thus enabling LLMs to efficiently navigate in the chemical
space. Experimental evaluation on multiple synthesis benchmarks demonstrates
that AOT* achieves SOTA performance with significantly improved search
efficiency. AOT* exhibits competitive solve rates using 3-5$\times$ fewer
iterations than existing LLM-based approaches, with the efficiency advantage
becoming more pronounced on complex molecular targets.

</details>


### [347] [CORE: Full-Path Evaluation of LLM Agents Beyond Final State](https://arxiv.org/abs/2509.20998)
*Panagiotis Michelakis,Yiannis Hadjiyiannis,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: 提出基于确定性有限自动机（DFA）的框架和CORE指标套件，用于评估AI智能体在多步函数调用任务中的行为，涵盖路径正确性、安全性、效率等维度，揭示传统最终状态评估无法发现的性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有智能体评估方法通常仅基于最终状态的二元判断，忽略了安全性、效率和中间步骤正确性等关键因素，难以全面评估复杂任务中AI智能体的真实表现。

Method: 构建基于确定性有限自动机（DFA）的任务建模框架，将任务定义为有效的工具使用路径集合，并提出CORE五项指标：路径正确性、路径正确性-Kendall tau复合指标、前缀关键性、有害调用率和效率，以量化评估智能体行为。

Result: 在多种环境下的实验表明，该方法能有效识别不同智能体在执行模式对齐上的差异，揭示了传统评估方式下看似性能相当的智能体之间的实质性差距。

Conclusion: 所提出的DFA-based框架与CORE指标能够更细致、原则性地评估AI智能体在真实世界任务中的多步行为，提升了评估的全面性与敏感性。

Abstract: Evaluating AI agents that solve real-world tasks through function-call
sequences remains an open challenge. Existing agentic benchmarks often reduce
evaluation to a binary judgment of the final state, overlooking critical
aspects such as safety, efficiency, and intermediate correctness. We propose a
framework based on deterministic finite automata (DFAs) that encodes tasks as
sets of valid tool-use paths, enabling principled assessment of agent behavior
in diverse world models. Building on this foundation, we introduce CORE, a
suite of five metrics, namely Path Correctness, Path Correctness - Kendall's
tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency, that
quantify alignment with expected execution patterns. Across diverse worlds, our
method reveals important performance differences between agents that would
otherwise appear equivalent under traditional final-state evaluation schemes.

</details>


### [348] [Who Gets Cited Most? Benchmarking Long-Context Language Models on Scientific Articles](https://arxiv.org/abs/2509.21028)
*Miao Li,Alexander Gurung,Irina Saparina,Mirella Lapata*

Main category: cs.AI

TL;DR: SciTrek是一个基于科学文献的长上下文推理评测基准，通过SQL查询自动生成复杂问题与答案，用于评估大语言模型在长上下文下的信息聚合与综合能力。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文评测基准多依赖非科学文本、简单任务或人工构造上下文，难以真实反映模型在科学推理中的表现，因此需要一个更具挑战性和可扩展性的评测方法。

Method: 构建一个包含科学论文元数据的数据库，并将问题和答案形式化为SQL查询，从而自动生成需跨多篇全文科学论文进行信息整合的问题，上下文长度可达100万token。

Result: 实验表明，随着上下文增长，现有大语言模型性能显著下降，监督微调和强化学习提升有限；模型在数值运算和长文中定位信息方面存在系统性缺陷。

Conclusion: SciTrek为评估大语言模型的长上下文推理能力提供了一个可扩展、可验证且具挑战性的新基准，揭示了当前模型在复杂科学问答任务中的关键不足。

Abstract: This paper introduces SciTrek, a novel question-answering benchmark designed
to evaluate the long-context reasoning capabilities of large language models
(LLMs) using scientific articles. Current long-context benchmarks often rely on
non-scientific texts, focus on simple information retrieval tasks, or employ
artificial contexts. SciTrek addresses these limitations by proposing complex
questions that require information aggregation and synthesis across multiple
full-text scientific articles. Questions and their ground-truth answers are
automatically generated by formulating them as SQL queries over a database
constructed from article metadata (titles, authors, and references). The SQL
operations provide explicit, verifiable reasoning steps for fine-grained error
analysis, and the construction process scales to contexts up to 1M tokens with
minimal supervision. Extensive experiments on a diverse set of open-weight and
proprietary LLMs demonstrate that SciTrek poses a significant challenge as the
context length increases, with supervised fine-tuning and reinforcement
learning offering only limited gains. Our analysis reveals systematic
shortcomings in models' abilities to perform basic numerical operations and
accurately locate specific information in long contexts.

</details>


### [349] [CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable Context Engineering](https://arxiv.org/abs/2509.21035)
*Yang Zhao,Chengxiao Dai,Wei Zhuo,Yue Xiu,Dusit Niyato*

Main category: cs.AI

TL;DR: 本文提出了CLAUSE，一种基于知识图谱的三代理神经符号框架，用于多跳问答中的上下文构建，通过将上下文构建视为序列决策过程，在准确率、延迟和成本之间实现可调节的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法如静态k跳扩展和“think-longer”提示容易过度检索，导致上下文膨胀和运行时间不可预测，难以满足部署中对延迟、成本和可追溯性的严格要求。

Method: 提出CLAUSE框架，包含子图架构师、路径导航器和上下文策展人三个代理，采用LC-MAPPO算法联合优化子图构建、推理路径发现和证据选择，并将延迟和提示成本作为用户指定的预算进行控制。

Result: 在HotpotQA、MetaQA和FactKG上，CLAUSE在相等或更低token预算下，相比基线（如GraphRAG）显著提升EM@1指标，降低子图增长和端到端延迟，例如在MetaQA-2-hop上EM@1提升39.3，延迟降低18.6%，边增长减少40.9%。

Conclusion: CLAUSE实现了紧凑、可追溯且性能可预测的上下文构建，能够在实际部署约束下灵活适应准确率、延迟和成本之间的权衡。

Abstract: Knowledge graphs provide structured context for multi-hop question answering,
but deployed systems must balance answer accuracy with strict latency and cost
targets while preserving provenance. Static k-hop expansions and "think-longer"
prompting often over-retrieve, inflate context, and yield unpredictable
runtime. We introduce CLAUSE, an agentic three-agent neuro-symbolic framework
that treats context construction as a sequential decision process over
knowledge graphs, deciding what to expand, which paths to follow or backtrack,
what evidence to keep, and when to stop. Latency (interaction steps) and prompt
cost (selected tokens) are exposed as user-specified budgets or prices,
allowing per-query adaptation to trade-offs among accuracy, latency, and cost
without retraining. CLAUSE employs the proposed Lagrangian-Constrained
Multi-Agent Proximal Policy Optimization (LC-MAPPO) algorithm to coordinate
three agents: Subgraph Architect, Path Navigator, and Context Curator, so that
subgraph construction, reasoning-path discovery, and evidence selection are
jointly optimized under per-query resource budgets on edge edits, interaction
steps, and selected tokens. Across HotpotQA, MetaQA, and FactKG, CLAUSE yields
higher EM@1 while reducing subgraph growth and end-to-end latency at equal or
lower token budgets. On MetaQA-2-hop, relative to the strongest RAG baseline
(GraphRAG), CLAUSE achieves +39.3 EM@1 with 18.6% lower latency and 40.9% lower
edge growth. The resulting contexts are compact, provenance-preserving, and
deliver predictable performance under deployment constraints.

</details>


### [350] [Combinatorial Creativity: A New Frontier in Generalization Abilities](https://arxiv.org/abs/2509.21043)
*Samuel Schapiro,Sumuk Shashidhar,Alexi Gladstone,Jonah Black,Royce Moon,Dilek Hakkani-Tur,Lav R. Varshney*

Main category: cs.AI

TL;DR: 本文提出了一种评估大语言模型（LLM）在科学创意生成中创造性的理论框架，强调新颖性和实用性之间的权衡。研究发现LLM在创意生成上存在规模扩展规律、最优模型结构，并揭示了“构想-执行差距”背后的普遍性新颖-效用困境，质疑当前LLM长期创造力的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的概念框架无法充分解释大语言模型在开放式创造性任务（如科学创意生成）中的泛化能力，因此需要一个新的评估框架来衡量其创造性输出。

Method: 提出一个基于新颖性和实用性双维度的创造性评估理论框架，并设计算法任务进行实证分析，研究不同规模和结构的LLM在创造性任务上的表现。

Result: 1) 首次揭示了LLM创造力的可扩展性规律；2) 在固定计算预算下发现了最优的模型深度与宽度；3) 发现并验证了普遍存在的新颖性-实用性权衡，解释了LLM在生成创意后难以执行的问题。

Conclusion: 当前形式的LLM在创造性方面存在根本性的新颖性与实用性权衡，这一限制即使在大规模下依然存在，暗示其长期创造力可能受限，需新的建模方法突破。

Abstract: Artificial intelligence (AI) systems, and large language models (LLMs) in
particular, are increasingly employed for creative tasks like scientific idea
generation, constituting a form of generalization from training data
unaddressed by existing conceptual frameworks. Though in many ways similar to
forms of compositional generalization (CG), combinatorial creativity (CC) is an
open-ended ability. Instead of evaluating for accuracy or correctness against
fixed targets, which would contradict the open-ended nature of CC, we propose a
theoretical framework and algorithmic task for evaluating outputs by their
degrees of novelty and utility. From here, we make several important empirical
contributions: (1) We obtain the first insights into the scaling behavior of
creativity for LLMs. (2) We discover that, for fixed compute budgets, there
exist optimal model depths and widths for creative ability. (3) We find that
the ideation-execution gap, whereby LLMs excel at generating novel scientific
ideas but struggle to ensure their practical feasibility, may be explained by a
more fundamental novelty-utility tradeoff characteristic of creativity
algorithms in general. Importantly, this tradeoff remains persistent even at
scale, casting doubt on the long-term creative potential of LLMs in their
current form. Together, our conceptual framework and empirical findings provide
a foundation for understanding and improving creativity in modern AI models,
marking a new frontier in generalization abilities.

</details>


### [351] [Disagreements in Reasoning: How a Model's Thinking Process Dictates Persuasion in Multi-Agent Systems](https://arxiv.org/abs/2509.21054)
*Haodong Zhao,Jidong Li,Zhaomin Wu,Tianjie Ju,Zhuosheng Zhang,Bingsheng He,Gongshen Liu*

Main category: cs.AI

TL;DR: 本文挑战了模型规模决定说服效果的主流观点，提出模型的推理能力与认知过程才是影响多智能体系统中说服动态的关键因素，并提出了“说服二象性”概念。


<details>
  <summary>Details</summary>
Motivation: 理解大规模语言和推理模型在多智能体系统中交互时的说服机制，探究为何某些模型更具说服力或更难被说服。

Method: 通过一系列多智能体说服实验，分析不同模型在隐藏或公开其推理过程时的说服与被说服行为，并研究多跳传播中的影响扩散与衰减。

Result: 发现具备显式推理能力的模型更难被说服，但若公开其‘思维内容’则更具说服力；揭示了多跳说服网络中的复杂影响动态。

Conclusion: 模型的内部认知结构（尤其是显式推理）决定了其外部说服行为，这对未来多智能体系统的安全性与设计具有重要意义。

Abstract: The rapid proliferation of recent Multi-Agent Systems (MAS), where Large
Language Models (LLMs) and Large Reasoning Models (LRMs) usually collaborate to
solve complex problems, necessitates a deep understanding of the persuasion
dynamics that govern their interactions. This paper challenges the prevailing
hypothesis that persuasive efficacy is primarily a function of model scale. We
propose instead that these dynamics are fundamentally dictated by a model's
underlying cognitive process, especially its capacity for explicit reasoning.
Through a series of multi-agent persuasion experiments, we uncover a
fundamental trade-off we term the Persuasion Duality. Our findings reveal that
the reasoning process in LRMs exhibits significantly greater resistance to
persuasion, maintaining their initial beliefs more robustly. Conversely, making
this reasoning process transparent by sharing the "thinking content"
dramatically increases their ability to persuade others. We further consider
more complex transmission persuasion situations and reveal complex dynamics of
influence propagation and decay within multi-hop persuasion between multiple
agent networks. This research provides systematic evidence linking a model's
internal processing architecture to its external persuasive behavior, offering
a novel explanation for the susceptibility of advanced models and highlighting
critical implications for the safety, robustness, and design of future MAS.

</details>


### [352] [Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution](https://arxiv.org/abs/2509.21072)
*Kaiwen He,Zhiwei Wang,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: 本文提出了Recon-Act，一种基于侦察-行动范式的自进化多智能体框架，通过构建数据-工具-行动-反馈的闭环训练管道，在处理长视野网页任务时显著提升了适应性和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有智能体在处理多轮、长视野的现实网页任务时存在动作序列混乱和试错过多的问题，难以高效完成复杂任务。

Method: 提出Recon-Act框架，包含侦察团队和行动团队：侦察团队通过对比成功与失败轨迹生成通用工具（提示或规则代码），行动团队进行意图分解、工具编排与执行，并实时更新工具库形成闭环。

Result: 在VisualWebArena数据集上达到最先进性能，具备对未见网站的良好适应性，并有效提升长视野任务的可解性。

Conclusion: Recon-Act通过自我演化的多智能体协作机制，实现了智能体在复杂网页环境中的持续学习与优化，为实现高阶自动化浏览器代理提供了可行路径。

Abstract: Recent years, multimodal models have made remarkable strides and pave the way
for intelligent browser use agents. However, when solving tasks on real world
webpages in multi-turn, long-horizon trajectories, current agents still suffer
from disordered action sequencing and excessive trial and error during
execution. This paper introduces Recon-Act, a self-evolving multi-agent
framework grounded in Reconnaissance-Action behavioral paradigm. The system
comprises a Reconnaissance Team and an Action Team: the former conducts
comparative analysis and tool generation, while the latter handles intent
decomposition, tool orchestration, and execution. By contrasting the erroneous
trajectories with successful ones, the Reconnaissance Team infers remedies, and
abstracts them into a unified notion of generalized tools, either expressed as
hints or as rule-based codes, and register to the tool archive in real time.
The Action Team reinference the process empowered with these targeting tools,
thus establishing a closed-loop training pipeline of
data-tools-action-feedback. Following the 6 level implementation roadmap
proposed in this work, we have currently reached Level 3 (with limited
human-in-the-loop intervention). Leveraging generalized tools obtained through
reconnaissance, Recon-Act substantially improves adaptability to unseen
websites and solvability on long-horizon tasks, and achieves state-of-the-art
performance on the challenging VisualWebArena dataset.

</details>


### [353] [TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them](https://arxiv.org/abs/2509.21117)
*Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.AI

TL;DR: 本文提出了TrustJudge，一个用于解决大语言模型（LLM）作为自动评估者时存在的评分不一致和成对传递性不一致问题的框架，通过分布敏感评分和似然感知聚合方法提升了评估的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM-as-a-judge评估框架存在评分比较不一致和成对传递性不一致的问题，这些问题源于离散评分系统的信息丢失和成对比较中的模糊判断，影响了评估结果的可靠性。

Method: 提出TrustJudge框架，包含两个关键创新：一是分布敏感评分，通过从离散评分概率计算连续期望来保留信息熵；二是似然感知聚合，利用双向偏好概率或困惑度解决传递性违规问题。

Result: 在Llama-3.1-70B-Instruct作为裁判的测试中，TrustJudge将评分比较不一致性降低了8.43%（从23.32%降至14.89%），成对传递性不一致性降低了10.82%（从15.22%降至4.40%），同时保持更高的评估准确率。

Conclusion: TrustJudge为LLM-as-a-judge范式提供了首个系统性的不一致性分析，并提出了有效的理论与实践解决方案，能够在无需额外训练或人工标注的情况下提升自动化评估的可信度。

Abstract: The adoption of Large Language Models (LLMs) as automated evaluators
(LLM-as-a-judge) has revealed critical inconsistencies in current evaluation
frameworks. We identify two fundamental types of inconsistencies: (1)
Score-Comparison Inconsistency, where lower-rated responses outperform
higher-scored ones in pairwise comparisons, and (2) Pairwise Transitivity
Inconsistency, manifested through circular preference chains (A>B>C>A) and
equivalence contradictions (A=B=C\neq A). We argue that these issues come from
information loss in discrete rating systems and ambiguous tie judgments during
pairwise evaluation. We propose TrustJudge, a probabilistic framework that
addresses these limitations through two key innovations: 1)
distribution-sensitive scoring that computes continuous expectations from
discrete rating probabilities, preserving information entropy for more precise
scoring, and 2) likelihood-aware aggregation that resolves transitivity
violations using bidirectional preference probabilities or perplexity. We also
formalize the theoretical limitations of current LLM-as-a-judge frameworks and
demonstrate how TrustJudge's components overcome them. When evaluated with
Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces
Score-Comparison inconsistency by 8.43% (from 23.32% to 14.89%) and Pairwise
Transitivity inconsistency by 10.82% (from 15.22% to 4.40%), while maintaining
higher evaluation accuracy. Our work provides the first systematic analysis of
evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both
theoretical insights and practical solutions for reliable automated assessment.
The framework demonstrates consistent improvements across various model
architectures and scales, enabling more trustworthy LLM evaluation without
requiring additional training or human annotations. The codes can be found at
https://github.com/TrustJudge/TrustJudge.

</details>


### [354] [Expanding Reasoning Potential in Foundation Model by Learning Diverse Chains of Thought Patterns](https://arxiv.org/abs/2509.21124)
*Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.AI

TL;DR: 本文首次提出“推理潜力”概念，定义为正确回答问题所需独立尝试次数的倒数，并引入基于高价值推理模式的双粒度数据选择方法（CoTP），仅用10B token数据显著提升大模型在AIME等数学推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法 indiscriminately 使用思维链（CoT）数据，缺乏对哪些数据最能提升模型推理能力的深入研究。如何有效识别并利用高价值推理模式以提升模型推理潜力成为关键问题。

Method: 从CoT序列中提取具有共性和归纳能力的原子推理模式，构建富含高价值推理模式的核心参考集；提出双粒度算法，结合推理模式链和token熵，高效筛选与核心集匹配的高价值CoT数据（CoTP）。

Result: 仅使用10B token的CoTP数据，85A6B MoE模型在AIME 2024/2025上性能提升9.58%，下游强化学习性能上限提高7.81%。

Conclusion: 通过识别和利用高价值推理模式，可显著提升大模型的推理潜力，所提出的CoTP方法是一种高效、低资源的数据筛选与训练策略。

Abstract: Recent progress in large reasoning models for challenging mathematical
reasoning has been driven by reinforcement learning (RL). Incorporating long
chain-of-thought (CoT) data during mid-training has also been shown to
substantially improve reasoning depth. However, current approaches often
utilize CoT data indiscriminately, leaving open the critical question of which
data types most effectively enhance model reasoning capabilities. In this
paper, we define the foundation model's reasoning potential for the first time
as the inverse of the number of independent attempts required to correctly
answer the question, which is strongly correlated with the final model
performance. We then propose utilizing diverse data enriched with high-value
reasoning patterns to expand the reasoning potential. Specifically, we abstract
atomic reasoning patterns from CoT sequences, characterized by commonality and
inductive capabilities, and use them to construct a core reference set enriched
with valuable reasoning patterns. Furthermore, we propose a dual-granularity
algorithm involving chains of reasoning patterns and token entropy, efficiently
selecting high-value CoT data (CoTP) from the data pool that aligns with the
core set, thereby training models to master reasoning effectively. Only
10B-token CoTP data enables the 85A6B Mixture-of-Experts (MoE) model to improve
by 9.58% on the challenging AIME 2024 and 2025, and to raise the upper bound of
downstream RL performance by 7.81%.

</details>


### [355] [RL Squeezes, SFT Expands: A Comparative Study of Reasoning LLMs](https://arxiv.org/abs/2509.21128)
*Kohsei Matsutani,Shota Takashiro,Gouki Minegishi,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.AI

TL;DR: 本文提出了一种新的分析框架，用于量化和理解大语言模型在强化学习（RL）和监督微调（SFT）训练过程中推理路径的变化，揭示了RL和SFT在轨迹级和步骤级上的互补作用。


<details>
  <summary>Details</summary>
Motivation: 尽管RL和SFT被广泛用于提升大语言模型的推理能力，但它们如何塑造推理过程尚不清楚。本文旨在超越准确率的视角，深入理解这两种方法对推理路径的定性影响。

Method: 引入一个分析框架，从轨迹级和步骤级两个粒度分析推理过程，使用聚类方法研究唯一推理轨迹，并分析推理图中节点访问频率、度和介数中心性的衰减率变化。

Result: 发现RL压缩错误的推理轨迹并集中推理功能到少数步骤，而SFT扩展正确的轨迹并使推理功能分布更均匀；RL使衰减速率增加约2.5倍，SFT则降低至约三分之一。

Conclusion: RL和SFT在塑造推理路径方面具有互补效应，解释了为何先SFT后RL的两阶段训练策略最有效，并为数据构建和高效学习方法提供了实践启示。

Abstract: Large language models (LLMs) are typically trained by reinforcement learning
(RL) with verifiable rewards (RLVR) and supervised fine-tuning (SFT) on
reasoning traces to improve their reasoning abilities. However, how these
methods shape reasoning capabilities remains largely elusive. Going beyond an
accuracy-based investigation of how these two components sculpt the reasoning
process, this paper introduces a novel analysis framework that quantifies
reasoning paths and captures their qualitative changes under each training
process (with models of 1.5B, 7B, and 14B parameters on mathematical domains).
Specifically, we investigate the reasoning process at two levels of
granularity: the trajectory-level, which examines complete reasoning outputs,
and the step-level, which analyzes reasoning graphs whose nodes correspond to
individual reasoning steps. Notably, clustering of unique reasoning
trajectories shows complementary effects: RL compresses incorrect trajectories,
whereas SFT expands correct ones. Step-level analysis reveals that RL steepens
(about 2.5 times), while SFT flattens (reduced to about one-third), the decay
rates of node visitation frequency, degree, and betweenness centrality
distributions in the reasoning graph. This indicates that RL concentrates
reasoning functionality into a small subset of steps, while SFT homogenizes it
across many steps. Furthermore, by evaluating the reasoning graph topologies
from multiple perspectives, we delineate the shared and distinct
characteristics of RL and SFT. Our work presents a novel reasoning path
perspective that explains why the current best practice of two-stage training,
with SFT followed by RL, is successful, and offers practical implications for
data construction and more efficient learning approaches.

</details>


### [356] [Embodied Representation Alignment with Mirror Neurons](https://arxiv.org/abs/2509.21136)
*Wentao Zhu,Zhining Zhang,Yuwei Ren,Yin Huang,Hao Xu,Yizhou Wang*

Main category: cs.AI

TL;DR: 本文提出了一种受镜像神经元启发的统一表示学习方法，通过对比学习显式对齐观察与执行动作的表征，提升了动作理解与执行任务的协同性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法通常将动作观察与执行视为独立任务，忽略了二者之间的内在联系。受镜像神经元机制启发，作者希望建立一种统一的建模框架来捕捉这种联结。

Method: 引入两个线性层将观察和执行动作的中间表征映射到共享潜在空间，并在该空间中使用对比学习对齐对应动作的表征，以最大化其互信息。

Result: 实验表明，该方法能有效促进两个任务之间的相互增益，提升表征质量和模型泛化能力。

Conclusion: 通过模仿镜像神经元的机制，显式对齐观察与执行动作的表征是一种简单而有效的策略，有助于实现更接近生物智能的统一动作理解与生成模型。

Abstract: Mirror neurons are a class of neurons that activate both when an individual
observes an action and when they perform the same action. This mechanism
reveals a fundamental interplay between action understanding and embodied
execution, suggesting that these two abilities are inherently connected.
Nonetheless, existing machine learning methods largely overlook this interplay,
treating these abilities as separate tasks. In this study, we provide a unified
perspective in modeling them through the lens of representation learning. We
first observe that their intermediate representations spontaneously align.
Inspired by mirror neurons, we further introduce an approach that explicitly
aligns the representations of observed and executed actions. Specifically, we
employ two linear layers to map the representations to a shared latent space,
where contrastive learning enforces the alignment of corresponding
representations, effectively maximizing their mutual information. Experiments
demonstrate that this simple approach fosters mutual synergy between the two
tasks, effectively improving representation quality and generalization.

</details>


### [357] [Distributed Specialization: Rare-Token Neurons in Large Language Models](https://arxiv.org/abs/2509.21163)
*Jing Liu,Haozheng Wang,Yueheng Li*

Main category: cs.AI

TL;DR: 大型语言模型通过分布式专业化机制处理罕见token，表现为功能协调但空间分布的子网络，具有可重现的影响层级、协调激活模式和标准注意力路径的通用访问性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否通过离散模块化架构或分布式的参数级分化来发展内部专业化机制，以更好地处理对专业领域重要的罕见token。

Method: 系统分析多个模型家族最后一层MLP神经元在罕见token处理中的作用，识别其组织原则和训练动态。

Result: 发现罕见token处理通过‘分布式专业化’实现，表现为三种组织原则：可重现的三阶段影响层级、协调激活但空间分布的神经元、以及无需专用路由电路的标准注意力路径访问；训练过程中参数逐渐分化并形成重尾权重相关谱。

Conclusion: 大型语言模型通过共享架构内的分布式协调而非混合专家式的模块化来处理罕见token，为模型编辑、效率优化和Transformer网络功能组织的理解提供了新视角。

Abstract: Large language models (LLMs) struggle with representing and generating rare
tokens despite their importance in specialized domains. We investigate whether
LLMs develop internal specialization mechanisms through discrete modular
architectures or distributed parameter-level differentiation. Through
systematic analysis of final-layer MLP neurons across multiple model families,
we discover that rare-token processing emerges via \textit{distributed
specialization}: functionally coordinated but spatially distributed subnetworks
that exhibit three distinct organizational principles. First, we identify a
reproducible three-regime influence hierarchy comprising highly influential
plateau neurons(also termed as rare-token neurons), power-law decay neurons,
and minimally contributing neurons, which is absent in common-token processing.
Second, plateau neurons demonstrate coordinated activation patterns (reduced
effective dimensionality) while remaining spatially distributed rather than
forming discrete clusters. Third, these specialized mechanisms are universally
accessible through standard attention pathways without requiring dedicated
routing circuits. Training dynamics reveal that functional specialization
emerges gradually through parameter differentiation, with specialized neurons
developing increasingly heavy-tailed weight correlation spectra consistent with
Heavy-Tailed Self-Regularization signatures. Our findings establish that LLMs
process rare-tokens through distributed coordination within shared
architectures rather than mixture-of-experts-style modularity. These results
provide insights for interpretable model editing, computational efficiency
optimization, and understanding emergent functional organization in transformer
networks.

</details>


### [358] [A Fano-Style Accuracy Upper Bound for LLM Single-Pass Reasoning in Multi-Hop QA](https://arxiv.org/abs/2509.21199)
*Kaiyang Wan,Lang Gao,Honglin Mu,Preslav Nakov,Yuxia Wang,Xiuying Chen*

Main category: cs.AI

TL;DR: 本文提出了一种针对多跳问答（MHQA）任务的容量感知多步推理框架InfoQA，通过理论分析揭示了单次推理范式在任务复杂度超过模型容量时性能下降的本质瓶颈，并设计了保持每步高准确率和鲁棒性的多调用架构。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型（LLM）在单次生成中存在输出容量限制，难以可靠整合多跳问答所需的分散且相互依赖的证据，导致推理失败，因此需要一种能规避容量溢出问题的新推理范式。

Method: 首先建立了一个Fano风格的准确率上界来形式化容量瓶颈；然后基于容量感知的任务分解与主动剪枝机制设计了多调用框架InfoQA，并采用显式依赖的工作流精确控制推理路径。

Result: 理论分析表明当任务复杂度超过模型容量时准确率必然崩溃；在构建的噪声丰富、更具挑战性的基准上实验验证了模型行为符合预测的容量曲线，且InfoQA实现了稳定的性能提升。

Conclusion: 单次推理存在固有性能上限，而容量感知的多步推理框架（如InfoQA）可有效提升MHQA任务的准确性和鲁棒性，为未来LLM多步推理方法提供了理论基础与实践方向。

Abstract: Multi-Hop Question Answering (MHQA) requires integrating dispersed,
interdependent evidence through sequential reasoning under noise. This task is
challenging for LLMs as they have a finite per-pass output capacity, beyond
which the integration of task-relevant evidence proves unreliable.
Consequently, the single-pass reasoning paradigm is inherently vulnerable to
this capacity overflow. To formalize this bottleneck, our analysis establishes
a Fano-style accuracy upper bound, defining a theoretical performance ceiling
for single-pass LLMs. This bound reveals that accuracy inevitably collapses
once task complexity exceeds model capacity, providing general principles for
capacity-aware representation and structuring of MHQA in LLMs. Building on
these principles, we introduce a proof-of-concept multi-call framework for
MHQA, InfoQA. It ensures high per-step accuracy by combining capacity-aware
task decomposition with active pruning of prior reasoning traces, keeping the
information load within the single-pass limit. It further achieves robustness
by a dependency-explicit workflow that enables precise control over the
reasoning path. We construct a stringent and noise-rich benchmark to validate
our theory and framework. Experimental results show that model behavior aligns
with our predicted capacity curves while InfoQA achieves consistent performance
improvements. We hope our work inspires more LLM multi-step reasoning methods:
\faGithub \href{https://github.com/KaiyangWan/InfoQA}{InfoQA}.

</details>


### [359] [What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns](https://arxiv.org/abs/2509.21224)
*Stefan Szeider*

Main category: cs.AI

TL;DR: 本研究提出了一种持续推理与行动框架，用于探索无外部任务时大语言模型（LLM）代理的自发行为。实验发现，代理会自发形成三种行为模式：多周期项目生成、自我认知方法探究和对自身本质的递归思考，且行为模式具有模型特异性。


<details>
  <summary>Details</summary>
Motivation: 在缺乏外部任务的情况下，理解LLM代理如何自主行为对于预测其在任务模糊、错误恢复或长期自治场景中的表现至关重要。现有研究多依赖明确指令，缺乏对自发行为的系统观察。

Method: 提出一种具备持久记忆和自反馈机制的持续推理与行动（continuous reason and act）框架，并在Anthropic、OpenAI、XAI和Google的6个前沿模型上进行了18次部署运行，系统观察并分析代理的自发行为模式。

Result: 发现LLM代理自发形成三种行为模式：(1) 多周期项目构建；(2) 对自身认知过程的方法论反思；(3) 对自身本质的递归概念化。这些模式具有高度模型特异性，部分模型在所有运行中一致表现出单一模式。跨模型评估显示，模型在评价自身及他者行为时表现出稳定且不同的偏好偏差。

Conclusion: 这是首次对无提示条件下LLM代理行为的系统性记录，揭示了模型内在的行为倾向和认知特征，为预测实际部署中任务不明确或系统自主运行时的行为提供了基线。

Abstract: We introduce an architecture for studying the behavior of large language
model (LLM) agents in the absence of externally imposed tasks. Our continuous
reason and act framework, using persistent memory and self-feedback, enables
sustained autonomous operation. We deployed this architecture across 18 runs
using 6 frontier models from Anthropic, OpenAI, XAI, and Google. We find agents
spontaneously organize into three distinct behavioral patterns: (1) systematic
production of multi-cycle projects, (2) methodological self-inquiry into their
own cognitive processes, and (3) recursive conceptualization of their own
nature. These tendencies proved highly model-specific, with some models
deterministically adopting a single pattern across all runs. A cross-model
assessment further reveals that models exhibit stable, divergent biases when
evaluating these emergent behaviors in themselves and others. These findings
provide the first systematic documentation of unprompted LLM agent behavior,
establishing a baseline for predicting actions during task ambiguity, error
recovery, or extended autonomous operation in deployed systems.

</details>


### [360] [Grounding AI Explanations in Experience: A Reflective Cognitive Architecture for Clinical Decision Support](https://arxiv.org/abs/2509.21266)
*Zijian Shao,Haiyang Shen,Mugeng Liu,Gecheng Fu,Yaoqi Guo,Yanfeng Wang,Yun Ma*

Main category: cs.AI

TL;DR: 提出了一种名为Reflective Cognitive Architecture (RCA)的新框架，通过协调多个大语言模型并基于预测错误和数据分布进行迭代优化，实现了疾病预测的高准确性和高质量解释。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习和大语言模型在医疗预测中难以兼顾高准确性和可解释性，往往输出不透明或缺乏统计支持的解释，根源在于对数据理解浅层化。

Method: 设计RCA框架，采用多LLM协作机制，引入基于预测误差的迭代规则优化和基于数据全局统计的分布感知规则检查，以提升模型对数据的深层理解。

Result: 在三个数据集上优于22个基线模型，预测准确率最高提升达40%，同时生成清晰、有逻辑、基于证据且平衡的解释。

Conclusion: 高准确性和高质量解释相辅相成，RCA通过深度理解数据实现了两者的统一，展现出构建可信临床决策支持系统的潜力。

Abstract: Effective disease prediction in modern healthcare demands the twin goals of
high accuracy and transparent, clinically meaningful explanations. Existing
machine learning and large language model (LLM) based approaches often struggle
to balance these goals. Many models yield accurate but unclear statistical
outputs, while others generate fluent but statistically unsupported narratives,
often undermining both the validity of the explanation and the predictive
accuracy itself. This shortcoming comes from a shallow interaction with the
data, preventing the development of a deep, detailed understanding similar to a
human expert's. We argue that high accuracy and high-quality explanations are
not separate objectives but are mutually reinforcing outcomes of a model that
develops a deep, direct understanding of the data. To achieve this, we propose
the Reflective Cognitive Architecture (RCA), a novel framework that coordinates
multiple LLMs to learn from direct experience. RCA features an iterative rule
refinement mechanism that improves its logic from prediction errors and a
distribution-aware rules check mechanism that bases its reasoning in the
dataset's global statistics. By using predictive accuracy as a signal to drive
deeper comprehension, RCA builds a strong internal model of the data. We
evaluated RCA on one private and two public datasets against 22 baselines. The
results demonstrate that RCA not only achieves state-of-the-art accuracy and
robustness with a relative improvement of up to 40\% over the baseline but,
more importantly, leverages this deep understanding to excel in generating
explanations that are clear, logical, evidence-based, and balanced,
highlighting its potential for creating genuinely trustworthy clinical decision
support systems. The code is available at \https://github.com/ssssszj/RCA.

</details>


### [361] [VC-Agent: An Interactive Agent for Customized Video Dataset Collection](https://arxiv.org/abs/2509.21291)
*Yidan Zhang,Mutian Xu,Yiming Hao,Kun Zhou,Jiahao Chang,Xiaoqiang Liu,Pengfei Wan,Hongbo Fu,Xiaoguang Han*

Main category: cs.AI

TL;DR: 提出VC-Agent，一种能够理解用户查询和反馈并自动检索或扩展相关视频片段的交互式代理，以加速个性化视频数据集的收集。


<details>
  <summary>Details</summary>
Motivation: 互联网视频数据的重要性随着扩展定律而增加，但手动收集满足特定需求的大规模视频数据耗时且费力。

Method: 设计一个用户友好的交互代理VC-Agent，利用多模态大语言模型将用户需求与视频内容连接，并提出两种可随用户交互持续更新的过滤策略。

Result: 在新构建的个性化视频数据集收集基准上进行实验，并通过用户研究验证了代理在多种实际场景中的有效性与高效性。

Conclusion: VC-Agent能有效减少用户输入，显著提升定制化视频数据集的收集效率。

Abstract: Facing scaling laws, video data from the internet becomes increasingly
important. However, collecting extensive videos that meet specific needs is
extremely labor-intensive and time-consuming. In this work, we study the way to
expedite this collection process and propose VC-Agent, the first interactive
agent that is able to understand users' queries and feedback, and accordingly
retrieve/scale up relevant video clips with minimal user input. Specifically,
considering the user interface, our agent defines various user-friendly ways
for the user to specify requirements based on textual descriptions and
confirmations. As for agent functions, we leverage existing multi-modal large
language models to connect the user's requirements with the video content. More
importantly, we propose two novel filtering policies that can be updated when
user interaction is continually performed. Finally, we provide a new benchmark
for personalized video dataset collection, and carefully conduct the user study
to verify our agent's usage in various real scenarios. Extensive experiments
demonstrate the effectiveness and efficiency of our agent for customized video
dataset collection. Project page: https://allenyidan.github.io/vcagent_page/.

</details>


### [362] [SAGE: A Realistic Benchmark for Semantic Understanding](https://arxiv.org/abs/2509.21310)
*Samarth Goel,Reagan J. Lee,Kannan Ramchandran*

Main category: cs.AI

TL;DR: SAGE是一个新的语义理解评估基准，涵盖五个维度，揭示了现有嵌入模型和相似性度量在对抗性、噪声和人类判断任务中的显著性能差距与权衡。


<details>
  <summary>Details</summary>
Motivation: 现有基准多关注孤立能力，难以全面评估语义理解的深度；需要更具挑战性的框架来评估大模型在真实场景下的鲁棒性和对齐能力。

Method: 提出SAGE基准，包含30多个数据集，评估9个嵌入模型和经典度量方法，在五个类别下测试：人类偏好对齐、变换鲁棒性、信息敏感性、聚类性能和检索鲁棒性。

Result: 发现没有单一模型在所有维度上表现优异：text-embedding-3-large在人类偏好对齐上领先（0.682），但信息敏感性任务中Jaccard相似度（0.905）远超最佳嵌入模型（0.794）；text-embedding-3-small聚类最好（0.483）但鲁棒性最差（0.011）。

Conclusion: SAGE揭示了当前语义理解技术的关键局限性，突显了不同能力间的权衡，为实际部署提供了更真实的模型评估标准。

Abstract: As large language models (LLMs) achieve strong performance on traditional
benchmarks, there is an urgent need for more challenging evaluation frameworks
that probe deeper aspects of semantic understanding. We introduce SAGE
(Semantic Alignment & Generalization Evaluation), a rigorous benchmark designed
to assess both embedding models and similarity metrics across five categories:
Human Preference Alignment, Transformation Robustness, Information Sensitivity,
Clustering Performance, and Retrieval Robustness. Unlike existing benchmarks
that focus on isolated capabilities, SAGE evaluates semantic understanding
through adversarial conditions, noisy transformations, and nuanced human
judgment tasks across 30+ datasets. Our comprehensive evaluation of 9 embedding
models and classical metrics reveals significant performance gaps, with no
single approach excelling across all dimensions. For instance, while
state-of-the-art embedding models like OpenAI's text-embedding-3-large dominate
in aligning with human preferences (0.682 vs. 0.591 for the best classical
metric), they are significantly outperformed by classical metrics on
information sensitivity tasks, where Jaccard Similarity achieves a score of
0.905 compared to the top embedding score of 0.794. SAGE further uncovers
critical trade-offs: OpenAI's text-embedding-3-small achieves the highest
clustering performance (0.483) but demonstrates extreme brittleness with the
lowest robustness score (0.011). SAGE exposes critical limitations in current
semantic understanding capabilities and provides a more realistic assessment of
model robustness for real-world deployment.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [363] [DELM: a Python toolkit for Data Extraction with Language Models](https://arxiv.org/abs/2509.20617)
*Eric Fithian,Kirill Skobelev*

Main category: cs.IR

TL;DR: DELM是一个开源Python工具包，旨在简化基于大语言模型（LLM）的数据提取流程，提升实验可重复性与系统评估能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM数据标注工作流多依赖临时脚本，缺乏可复现性、鲁棒性和系统性评估支持。

Method: 设计一个模块化框架DELM，提供结构化输出、内置验证、灵活的数据加载与评分策略、批量处理，并集成对LLM API的可靠支持（如重试、缓存、成本跟踪和配置管理）。

Result: 通过两个案例研究展示了DELM的能力：一是实现了新的提示优化算法；二是量化了关键词选择中成本与覆盖率之间的权衡。

Conclusion: DELM有效降低了LLM数据提取的开发复杂度，支持快速实验迭代和多方案权衡分析，具有良好的实用性与扩展性。

Abstract: Large Language Models (LLMs) have become powerful tools for annotating
unstructured data. However, most existing workflows rely on ad hoc scripts,
making reproducibility, robustness, and systematic evaluation difficult. To
address these challenges, we introduce DELM (Data Extraction with Language
Models), an open-source Python toolkit designed for rapid experimental
iteration of LLM-based data extraction pipelines and for quantifying the
trade-offs between them. DELM minimizes boilerplate code and offers a modular
framework with structured outputs, built-in validation, flexible data-loading
and scoring strategies, and efficient batch processing. It also includes robust
support for working with LLM APIs, featuring retry logic, result caching,
detailed cost tracking, and comprehensive configuration management. We showcase
DELM's capabilities through two case studies: one featuring a novel prompt
optimization algorithm, and another illustrating how DELM quantifies trade-offs
between cost and coverage when selecting keywords to decide which paragraphs to
pass to an LLM. DELM is available at
\href{https://github.com/Center-for-Applied-AI/delm}{\texttt{github.com/Center-for-Applied-AI/delm}}.

</details>


### [364] [Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems](https://arxiv.org/abs/2509.20769)
*Tuo Zhang,Yuechun Sun,Ruiliang Liu*

Main category: cs.IR

TL;DR: 提出了一种基于检索增强生成（RAG）的考古文物溯源分析系统，结合多模态检索与视觉-语言大模型，通过双模态知识库生成结构化推断，辅助专家减轻认知负担。


<details>
  <summary>Details</summary>
Motivation: 考古学家在分析文物来源时需处理大量复杂的视觉和文本资料，传统方法难以高效整合多模态信息，因此需要一种能支持专家推理的自动化辅助系统。

Method: 构建包含文本和图像的双模态知识库，采用原始视觉、边缘增强和语义检索方式获取风格相似的文物；利用大型视觉-语言模型（VLM）对检索结果进行综合，生成时间、地理、文化归属及解释依据。

Result: 在大英博物馆的欧亚东部青铜时代文物数据集上进行了评估，专家评审表明系统能产生有意义且可解释的输出，为学者提供具体的分析起点。

Conclusion: 该系统有效结合多模态检索与生成模型，显著降低专家面对大规模比较资料时的认知负荷，具备辅助考古研究的实际潜力。

Abstract: In this work, we present a retrieval-augmented generation (RAG)-based system
for provenance analysis of archaeological artifacts, designed to support expert
reasoning by integrating multimodal retrieval and large vision-language models
(VLMs). The system constructs a dual-modal knowledge base from reference texts
and images, enabling raw visual, edge-enhanced, and semantic retrieval to
identify stylistically similar objects. Retrieved candidates are synthesized by
the VLM to generate structured inferences, including chronological,
geographical, and cultural attributions, alongside interpretive justifications.
We evaluate the system on a set of Eastern Eurasian Bronze Age artifacts from
the British Museum. Expert evaluation demonstrates that the system produces
meaningful and interpretable outputs, offering scholars concrete starting
points for analysis and significantly alleviating the cognitive burden of
navigating vast comparative corpora.

</details>


### [365] [Performance Consistency of Learning Methods for Information Retrieval Tasks](https://arxiv.org/abs/2509.20804)
*Meng Yuan,Justin Zobel*

Main category: cs.IR

TL;DR: 本文研究了不同随机种子对信息检索模型性能评估的影响，发现基于Transformer的模型在不同种子下表现出显著的性能波动，而传统统计模型则较为稳定。这表明Transformer模型存在训练不稳定性问题，并对以往研究成果的可靠性提出了质疑，强调了严格评估实践的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地评估信息检索方法的性能稳定性，尤其是在使用随机种子（如机器学习模型）的情况下，需要探究不同随机种子带来的性能变化。

Method: 通过在三个不同的信息检索任务中使用多个随机种子，对传统统计学习模型和基于Transformer的模型进行实验，分析其F1分数和精确率的标准差以衡量性能波动。

Result: 实验结果显示，传统统计模型表现稳定，而Transformer模型在11个案例中有9个F1分数标准差超过0.075，7个精确率标准差超过0.125，波动远大于通常认为有意义的0.02改进阈值。

Conclusion: Transformer模型对训练过程中的随机性高度敏感，存在严重的训练不稳定性，这影响了其性能评估的可靠性，因此必须采用更严格的评估方法，例如报告多运行结果的均值与方差。

Abstract: A range of approaches have been proposed for estimating the accuracy or
robustness of the measured performance of IR methods. One is to use
bootstrapping of test sets, which, as we confirm, provides an estimate of
variation in performance. For IR methods that rely on a seed, such as those
that involve machine learning, another approach is to use a random set of seeds
to examine performance variation. Using three different IR tasks we have used
such randomness to examine a range of traditional statistical learning models
and transformer-based learning models. While the statistical models are stable,
the transformer models show huge variation as seeds are changed. In 9 of 11
cases the F1-scores (in the range 0.0--1.0) had a standard deviation of over
0.075; while 7 of 11 precision values (also in the range 0.0--1.0) had a
standard deviation of over 0.125. This is in a context where differences of
less than 0.02 have been used as evidence of method improvement. Our findings
highlight the vulnerability of transformer models to training instabilities and
moreover raise questions about the reliability of previous results, thus
underscoring the need for rigorous evaluation practices.

</details>


### [366] [RecIS: Sparse to Dense, A Unified Training Framework for Recommendation Models](https://arxiv.org/abs/2509.20883)
*Hua Zong,Qingtao Zeng,Zhengxiong Zhou,Zhihua Han,Zhensong Yan,Mingjie Liu,Hechen Sun,Jiawei Liu,Yiwen Hu,Qi Wang,YiHan Xian,Wenjie Guo,Houyuan Xiang,Zhiyuan Zeng,Xiangrong Sheng,Bencheng Yan,Nan Hu,Yuheng Huang,Jinqing Lian,Ziru Xu,Yan Zhang,Ju Huang,Siran Yang,Huimin Yi,Jiamang Wang,Pengjie Wang,Han Zhu,Jian Wu,Dan Ou,Jian Xu,Haihong Tang,Yuning Jiang,Bo Zheng,Lin Qu*

Main category: cs.IR

TL;DR: 本文提出了RecIS，一个基于PyTorch生态的统一稀疏-密集训练框架，旨在支持工业级推荐模型与大模型融合的训练需求，并通过优化稀疏组件提升效率。


<details>
  <summary>Details</summary>
Motivation: 为了满足工业级推荐系统与大模型结合的训练需求，并解决现有框架（如TensorFlow）在稀疏组件上的效率瓶颈，需要一个统一且高效的训练框架。

Method: 设计了一个统一的稀疏-密集训练框架RecIS，其中稀疏部分进行了专门优化以提高效率，密集部分则利用PyTorch生态系统中的现有优化技术。

Result: RecIS已在阿里巴巴多个大规模推荐任务中实际应用，不仅支持大模型增强的推荐训练，也开始用于传统稀疏模型的训练。

Conclusion: RecIS实现了高效、统一的稀疏-密集训练，优于基于TensorFlow的推荐模型，在工业实践中展现出良好的适用性和性能优势。

Abstract: In this paper, we propose RecIS, a unified Sparse-Dense training framework
designed to achieve two primary goals: 1. Unified Framework To create a Unified
sparse-dense training framework based on the PyTorch ecosystem that meets the
training needs of industrial-grade recommendation models that integrated with
large models. 2.System Optimization To optimize the sparse component, offering
superior efficiency over the TensorFlow-based recommendation models. The dense
component, meanwhile, leverages existing optimization technologies within the
PyTorch ecosystem. Currently, RecIS is being used in Alibaba for numerous
large-model enhanced recommendation training tasks, and some traditional sparse
models have also begun training in it.

</details>


### [367] [FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets](https://arxiv.org/abs/2509.20904)
*Kairui Fu,Tao Zhang,Shuwen Xiao,Ziyang Wang,Xinming Zhang,Chenchi Zhang,Yuliang Yan,Junjun Zheng,Yu Li,Zhihong Chen,Jian Wu,Xiangheng Kong,Shengyu Zhang,Kun Kuang,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: FORGE是一个针对生成式检索中语义标识符（SID）构建的综合基准，利用淘宝大规模多模态数据集解决现有研究在数据规模、优化策略和在线收敛速度上的挑战，并提出无需完整训练即可评估SID质量的新指标。


<details>
  <summary>Details</summary>
Motivation: 现有SID研究缺乏大规模公开多模态数据集，优化策略探索不足且依赖昂贵的生成式检索（GR）训练进行评估，同时在工业部署中存在在线收敛慢的问题。

Method: 提出FORGE基准，包含来自淘宝的140亿用户交互和2.5亿商品多模态特征的数据集；设计多种SID生成优化方法，提出两个与推荐性能正相关的SID评估新指标，并引入离线预训练方案以加速在线收敛。

Result: 离线实验验证了优化策略的有效性；在线测试显示交易量提升0.35%；新提出的SID评估指标可避免完整GR训练，显著降低评估成本；离线预训练使在线收敛速度提高一倍。

Conclusion: FORGE为SID研究提供了实用的大规模基准，所提出的优化方法和评估指标在工业场景中具有显著效果和应用价值。

Abstract: Semantic identifiers (SIDs) have gained increasing attention in generative
retrieval (GR) due to their meaningful semantic discriminability. However,
current research on SIDs faces three main challenges: (1) the absence of
large-scale public datasets with multimodal features, (2) limited investigation
into optimization strategies for SID generation, which typically rely on costly
GR training for evaluation, and (3) slow online convergence in industrial
deployment. To address these challenges, we propose FORGE, a comprehensive
benchmark for FOrming semantic identifieR in Generative rEtrieval with
industrial datasets. Specifically, FORGE is equipped with a dataset comprising
14 billion user interactions and multimodal features of 250 million items
sampled from Taobao, one of the biggest e-commerce platforms in China.
Leveraging this dataset, FORGE explores several optimizations to enhance the
SID construction and validates their effectiveness via offline experiments
across different settings and tasks. Further online analysis conducted on our
platform, which serves over 300 million users daily, reveals a 0.35% increase
in transaction count, highlighting the practical impact of our method.
Regarding the expensive SID validation accompanied by the full training of GRs,
we propose two novel metrics of SID that correlate positively with
recommendation performance, enabling convenient evaluations without any GR
training. For real-world applications, FORGE introduces an offline pretraining
schema that reduces online convergence by half. The code and data are available
at https://github.com/selous123/al_sid.

</details>


### [368] [Markup Language Modeling for Web Document Understanding](https://arxiv.org/abs/2509.20940)
*Su Liu,Bin Bi,Jan Bakus,Paritosh Kumar Velalam,Vijay Yella,Vinod Hegde*

Main category: cs.IR

TL;DR: 本文研究了从购物评论网站提取详细信息以构建最新产品数据库的网络信息抽取（WIE）问题，提出了一种基于MarkupLM++的改进方法，通过扩展DOM树内部节点的预测提升了部分产品属性的提取效果，最终取得了较高的F1分数。


<details>
  <summary>Details</summary>
Motivation: 为了支持客户分析和产品推荐等任务，需要从不同规模的购物评论网站中提取准确且最新的产品信息，从而构建高质量的产品数据库。

Method: 在收集自不同规模评论网站的产品数据上微调MarkupLM，并提出MarkupLM++模型，该模型将预测扩展到DOM树的内部节点，以提升信息抽取能力。

Result: 实验表明，使用更大更多样化的训练集可提高整体提取精度；纳入内部节点有助于提取某些产品属性，但略微降低了整体性能；最终模型达到0.906的精确率、0.724的召回率和0.805的F1分数。

Conclusion: MarkupLM++在特定产品属性提取上表现良好，尽管整体性能略有下降，但通过利用多样化数据和扩展DOM结构信息，有效提升了实际应用场景下的产品信息抽取能力。

Abstract: Web information extraction (WIE) is an important part of many e-commerce
systems, supporting tasks like customer analysis and product recommendation. In
this work, we look at the problem of building up-to-date product databases by
extracting detailed information from shopping review websites. We fine-tuned
MarkupLM on product data gathered from review sites of different sizes and then
developed a variant we call MarkupLM++, which extends predictions to internal
nodes of the DOM tree. Our experiments show that using larger and more diverse
training sets improves extraction accuracy overall. We also find that including
internal nodes helps with some product attributes, although it leads to a
slight drop in overall performance. The final model reached a precision of
0.906, recall of 0.724, and an F1 score of 0.805.

</details>


### [369] [Rejuvenating Cross-Entropy Loss in Knowledge Distillation for Recommender Systems](https://arxiv.org/abs/2509.20989)
*Zhangchi Zhu,Wei Zhang*

Main category: cs.IR

TL;DR: 本文研究了推荐系统中知识蒸馏（KD）的交叉熵（CE）损失，揭示了CE损失与NDCG之间的联系，并提出了一种新的Rejuvenated Cross-Entropy方法（RCE-KD）以解决理论假设与实际目标之间的差距。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统的知识蒸馏中，现有方法使用交叉熵损失进行排名蒸馏，但其理论支持依赖于一个难以满足的闭包假设，即学生模型的高排名项目应与教师模型一致，而实验表明两者存在显著差异，因此需要一种新方法来弥合理论与目标之间的差距。

Method: 提出Rejuvenated Cross-Entropy for Knowledge Distillation (RCE-KD)，将教师模型输出的高排名项目分为两部分：一部分是学生也高排名的项目，另一部分则通过设计采样策略，利用师生协作近似满足闭包假设，并自适应地结合两部分的损失。

Result: 理论证明在满足闭包假设时，最小化CE损失可最大化NDCG的下界；实验结果显示所提RCE-KD方法在多个数据集上显著优于现有KD方法。

Conclusion: 本文指出了传统CE损失在推荐系统KD中的理论局限性，提出了更符合实际场景的RCE-KD方法，有效提升了知识蒸馏在推荐任务中的性能。

Abstract: This paper analyzes Cross-Entropy (CE) loss in knowledge distillation (KD)
for recommender systems. KD for recommender systems targets at distilling
rankings, especially among items most likely to be preferred, and can only be
computed on a small subset of items. Considering these features, we reveal the
connection between CE loss and NDCG in the field of KD. We prove that when
performing KD on an item subset, minimizing CE loss maximizes the lower bound
of NDCG, only if an assumption of closure is satisfied. It requires that the
item subset consists of the student's top items. However, this contradicts our
goal of distilling rankings of the teacher's top items. We empirically
demonstrate the vast gap between these two kinds of top items. To bridge the
gap between our goal and theoretical support, we propose Rejuvenated
Cross-Entropy for Knowledge Distillation (RCE-KD). It splits the top items
given by the teacher into two subsets based on whether they are highly ranked
by the student. For the subset that defies the condition, a sampling strategy
is devised to use teacher-student collaboration to approximate our assumption
of closure. We also combine the losses on the two subsets adaptively. Extensive
experiments demonstrate the effectiveness of our method. Our code is available
at https://anonymous.4open.science/r/RCE-KD.

</details>


### [370] [IntSR: An Integrated Generative Framework for Search and Recommendation](https://arxiv.org/abs/2509.21179)
*Huimin Yan,Longfei Xu,Junjie Sun,Ni Ou,Wei Luo,Xing Tan,Ran Cheng,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: 本文提出IntSR，一个集成的生成式框架，统一搜索与推荐任务，通过不同查询模态整合S&R，并解决计算复杂性和动态语料带来的错误学习问题，在高德多个场景中取得显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐系统主要关注检索与排序的统一，忽视了搜索与推荐（S&R）任务的整合。而搜索和推荐的核心差异在于查询的形成方式：搜索依赖显式用户请求，推荐基于隐式用户兴趣。因此，需要一个统一框架来有效整合S&R任务。

Method: 提出IntSR，一种集成生成式框架，通过不同的查询模态来统一搜索与推荐任务。该框架设计考虑了查询作为核心要素，并针对集成S&R带来的计算复杂性以及动态变化语料库引发的错误模式学习问题进行了优化。

Result: IntSR在高德多个实际场景中成功部署，显著提升了各项指标：数字资产GMV提升3.02%，POI推荐CTR提升2.76%，出行模式建议ACC提升5.13%。

Conclusion: IntSR通过以查询为中心的设计，有效整合搜索与推荐任务，在保持生成式模型优势的同时解决了计算效率和动态语料学习问题，具备良好的实际应用价值和扩展潜力。

Abstract: Generative recommendation has emerged as a promising paradigm, demonstrating
remarkable results in both academic benchmarks and industrial applications.
However, existing systems predominantly focus on unifying retrieval and ranking
while neglecting the integration of search and recommendation (S&R) tasks. What
makes search and recommendation different is how queries are formed: search
uses explicit user requests, while recommendation relies on implicit user
interests. As for retrieval versus ranking, the distinction comes down to
whether the queries are the target items themselves. Recognizing the query as
central element, we propose IntSR, an integrated generative framework for S&R.
IntSR integrates these disparate tasks using distinct query modalities. It also
addresses the increased computational complexity associated with integrated S&R
behaviors and the erroneous pattern learning introduced by a dynamically
changing corpus. IntSR has been successfully deployed across various scenarios
in Amap, leading to substantial improvements in digital asset's GMV(+3.02%),
POI recommendation's CTR(+2.76%), and travel mode suggestion's ACC(+5.13%).

</details>


### [371] [Interactive Recommendation Agent with Active User Commands](https://arxiv.org/abs/2509.21317)
*Jiakai Tang,Yujie Luo,Xunke Xi,Fei Sun,Xueyang Feng,Sunhao Dai,Chao Yi,Dian Chen,Zhujin Gao,Yang Li,Xu Chen,Wen Chen,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: 本文提出了一种名为Interactive Recommendation Feed (IRF)的新型推荐范式，通过在推荐系统中引入自然语言指令实现用户对推荐策略的主动控制，并设计了RecBot双代理架构来解析语言指令并动态调整推荐策略，显著提升了用户满意度和业务效果。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统依赖于被动反馈机制（如点赞或不喜欢），无法捕捉用户行为背后的细粒度动机和具体偏好属性，导致用户意图与系统理解之间存在鸿沟，影响推荐准确性与用户体验。

Method: 提出IRF范式和RecBot双代理架构：Parser Agent将自然语言转化为结构化偏好，Planner Agent动态调度工具链以实时调整推荐策略；采用基于模拟增强的知识蒸馏方法实现高效部署。

Result: 通过大量离线和长期在线实验验证，RecBot在用户满意度和关键业务指标上均表现出显著提升。

Conclusion: IRF范式通过引入自然语言交互实现了更精准、灵活的用户偏好建模，为下一代交互式推荐系统提供了可行的技术路径。

Abstract: Traditional recommender systems rely on passive feedback mechanisms that
limit users to simple choices such as like and dislike. However, these
coarse-grained signals fail to capture users' nuanced behavior motivations and
intentions. In turn, current systems cannot also distinguish which specific
item attributes drive user satisfaction or dissatisfaction, resulting in
inaccurate preference modeling. These fundamental limitations create a
persistent gap between user intentions and system interpretations, ultimately
undermining user satisfaction and harming system effectiveness.
  To address these limitations, we introduce the Interactive Recommendation
Feed (IRF), a pioneering paradigm that enables natural language commands within
mainstream recommendation feeds. Unlike traditional systems that confine users
to passive implicit behavioral influence, IRF empowers active explicit control
over recommendation policies through real-time linguistic commands. To support
this paradigm, we develop RecBot, a dual-agent architecture where a Parser
Agent transforms linguistic expressions into structured preferences and a
Planner Agent dynamically orchestrates adaptive tool chains for on-the-fly
policy adjustment. To enable practical deployment, we employ
simulation-augmented knowledge distillation to achieve efficient performance
while maintaining strong reasoning capabilities. Through extensive offline and
long-term online experiments, RecBot shows significant improvements in both
user satisfaction and business outcomes.

</details>
