<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 99]
- [cs.CL](#cs.CL) [Total: 63]
- [cs.LG](#cs.LG) [Total: 112]
- [cs.AI](#cs.AI) [Total: 29]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.RO](#cs.RO) [Total: 47]
- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [UI-Venus-1.5 Technical Report](https://arxiv.org/abs/2602.09082)
*Veuns-Team,:,Changlong Gao,Zhangxuan Gu,Yulin Liu,Xinyu Qiu,Shuheng Shen,Yue Wen,Tianyu Xia,Zhenyu Xu,Zhengwen Zeng,Beitong Zhou,Xingran Zhou,Weizhi Chen,Sunhao Dai,Jingya Dou,Yichen Gong,Yuan Guo,Zhenlin Guo,Feng Li,Qian Li,Jinzhen Lin,Yuqi Zhou,Linchao Zhu,Liang Chen,Zhenyu Guo,Changhua Meng,Weiqiang Wang*

Main category: cs.CV

TL;DR: UI-Venus-1.5 是一个统一的端到端 GUI 智能体，通过中期训练、在线强化学习和模型融合三项关键技术改进，在多项基准测试中达到 SOTA 性能，并在真实中文移动应用中展现强泛化与导航能力。


<details>
  <summary>Details</summary>
Motivation: 现有 GUI 智能体难以兼顾广泛泛化能力与稳定任务性能，需构建更鲁棒、统一且适配多场景的端到端解决方案。

Method: 提出 UI-Venus-1.5 模型族（2B/8B 密集模型 + 30B-A3B MoE 模型）；引入三阶段技术：1）基于 100 亿 token 的中期训练夯实 GUI 语义基础；2）全轨迹在线强化学习优化长程动态导航；3）通过模型合并融合接地、网页、移动端专用模型为单一统一智能体。

Result: 在 ScreenSpot-Pro（69.6%）、VenusBench-GD（75.0%）、AndroidWorld（77.6%）上刷新 SOTA；在多种中文移动 App 中实现稳健指令执行。

Conclusion: UI-Venus-1.5 实现了通用性与高性能的统一，是面向真实世界 GUI 自动化的可靠端到端智能体架构。

Abstract: GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus

</details>


### [2] [Faster-GS: Analyzing and Improving Gaussian Splatting Optimization](https://arxiv.org/abs/2602.09999)
*Florian Hahlbohm,Linus Franke,Martin Eisemann,Marcus Magnor*

Main category: cs.CV

TL;DR: 本文提出Faster-GS，通过整合与改进现有3D高斯点绘（3DGS）优化策略，并引入新优化（如数值稳定性、高斯截断、梯度近似），实现训练速度最高提升5倍且保持视觉质量，同时拓展至4D非刚性场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS加速方法常混杂实现优化与算法修改，或牺牲保真度换性能，导致研究碎片化、难以公平比较。

Method: 系统梳理并评估已有3DGS高效策略，加入针对数值稳定性、高斯截断和梯度近似的新型优化，构建统一、严谨优化的Faster-GS框架。

Result: Faster-GS在多基准测试中实现最高5倍训练加速且视觉质量不变；成功迁移至4D高斯重建，支持高效非刚性场景优化。

Conclusion: Faster-GS为3DGS优化提供了新的高性价比、资源高效基准，并验证了关键优化策略对扩展至动态（4D）场景的有效性。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have focused on accelerating optimization while preserving reconstruction quality. However, many proposed methods entangle implementation-level improvements with fundamental algorithmic modifications or trade performance for fidelity, leading to a fragmented research landscape that complicates fair comparison. In this work, we consolidate and evaluate the most effective and broadly applicable strategies from prior 3DGS research and augment them with several novel optimizations. We further investigate underexplored aspects of the framework, including numerical stability, Gaussian truncation, and gradient approximation. The resulting system, Faster-GS, provides a rigorously optimized algorithm that we evaluate across a comprehensive suite of benchmarks. Our experiments demonstrate that Faster-GS achieves up to 5$\times$ faster training while maintaining visual quality, establishing a new cost-effective and resource efficient baseline for 3DGS optimization. Furthermore, we demonstrate that optimizations can be applied to 4D Gaussian reconstruction, leading to efficient non-rigid scene optimization.

</details>


### [3] [Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling](https://arxiv.org/abs/2602.09084)
*Ruijie Ye,Jiayi Zhang,Zhuoxin Liu,Zihao Zhu,Siyuan Yang,Li Li,Tianfu Fu,Franck Dernoncourt,Yue Zhao,Jiacheng Zhu,Ryan Rossi,Wenhao Chai,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 本文提出Agent Banana框架，解决专业图像编辑中过度编辑、单轮编辑局限及低分辨率评估等问题，通过Context Folding和Image Layer Decomposition实现高保真、对象感知、多轮图像编辑，并构建4K级HDD-Bench基准进行评测。


<details>
  <summary>Details</summary>
Motivation: 专业图像编辑工作流中存在三大挑战：编辑过度、单轮模型难以支持多轮交互导致对象失真、现有评估分辨率（约1K）与实际超高清（如4K）工作流不匹配。

Method: 提出分层智能体框架Agent Banana，包含两个核心机制：(1) Context Folding——将长交互历史压缩为结构化记忆以实现稳定长程控制；(2) Image Layer Decomposition——基于图层的局部编辑，保护非目标区域并支持原生分辨率输出；同时构建HDD-Bench——首个面向4K、多轮对话、可验证步骤目标的高清晰度评测基准。

Result: 在HDD-Bench上，Agent Banana在多轮一致性（IC 0.871）和背景保真度（SSIM-OM 0.84, LPIPS-OM 0.12）方面最优，指令遵循能力保持竞争力，并在标准单轮编辑基准上表现强劲。

Conclusion: Agent Banana推动了高可靠性、专业化级智能体图像编辑的发展，为真实工作流集成提供了新范式。

Abstract: We study instruction-based image editing under professional workflows and identify three persistent challenges: (i) editors often over-edit, modifying content beyond the user's intent; (ii) existing models are largely single-turn, while multi-turn edits can alter object faithfulness; and (iii) evaluation at around 1K resolution is misaligned with real workflows that often operate on ultra high-definition images (e.g., 4K). We propose Agent Banana, a hierarchical agentic planner-executor framework for high-fidelity, object-aware, deliberative editing. Agent Banana introduces two key mechanisms: (1) Context Folding, which compresses long interaction histories into structured memory for stable long-horizon control; and (2) Image Layer Decomposition, which performs localized layer-based edits to preserve non-target regions while enabling native-resolution outputs. To support rigorous evaluation, we build HDD-Bench, a high-definition, dialogue-based benchmark featuring verifiable stepwise targets and native 4K images (11.8M pixels) for diagnosing long-horizon failures. On HDD-Bench, Agent Banana achieves the best multi-turn consistency and background fidelity (e.g., IC 0.871, SSIM-OM 0.84, LPIPS-OM 0.12) while remaining competitive on instruction following, and also attains strong performance on standard single-turn editing benchmarks. We hope this work advances reliable, professional-grade agentic image editing and its integration into real workflows.

</details>


### [4] [SemanticMoments: Training-Free Motion Similarity via Third Moment Features](https://arxiv.org/abs/2602.09146)
*Saar Huberman,Kfir Goldberg,Or Patashnik,Sagie Benaim,Ron Mokady*

Main category: cs.CV

TL;DR: 本文提出SemanticMoments方法，通过在预训练语义模型特征上计算高阶时间统计量，实现无需训练的语义化运动视频理解，在新构建的SimMotion基准上显著优于现有RGB、光流和文本监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频表征方法过度依赖静态外观和场景上下文，忽视运动动力学；而传统光流等运动输入又缺乏高层语义理解能力，二者均难以真正实现语义化运动检索。

Method: 提出SemanticMoments：一种无需训练的方法，对预训练语义模型（如CLIP）提取的帧级特征，沿时间维度计算高阶矩（如均值、方差、偏度等）作为视频运动表征。

Result: 在新构建的SimMotion基准（含合成与真实世界人工标注数据）上，SemanticMoments显著超越现有RGB、光流及文本监督方法，且能更好解耦运动与外观信息。

Conclusion: 在语义特征空间中进行时间统计是实现可扩展、感知合理（perceptually grounded）的运动中心视频理解的有效基础。

Abstract: Retrieving videos based on semantic motion is a fundamental, yet unsolved, problem. Existing video representation approaches overly rely on static appearance and scene context rather than motion dynamics, a bias inherited from their training data and objectives. Conversely, traditional motion-centric inputs like optical flow lack the semantic grounding needed to understand high-level motion. To demonstrate this inherent bias, we introduce the SimMotion benchmarks, combining controlled synthetic data with a new human-annotated real-world dataset. We show that existing models perform poorly on these benchmarks, often failing to disentangle motion from appearance. To address this gap, we propose SemanticMoments, a simple, training-free method that computes temporal statistics (specifically, higher-order moments) over features from pre-trained semantic models. Across our benchmarks, SemanticMoments consistently outperforms existing RGB, flow, and text-supervised methods. This demonstrates that temporal statistics in a semantic feature space provide a scalable and perceptually grounded foundation for motion-centric video understanding.

</details>


### [5] [A Hybrid Deterministic Framework for Named Entity Extraction in Broadcast News Video](https://arxiv.org/abs/2602.09154)
*Andrea Filiberto Lucas,Dylan Seychell*

Main category: cs.CV

TL;DR: 本文提出了一种可解释、模块化、确定性的框架，用于从新闻视频中自动检测和提取人名，兼顾精度、可追溯性与审计性，优于生成式多模态方法。


<details>
  <summary>Details</summary>
Motivation: 视频新闻内容激增，但其图形布局、字体规范和平台设计差异大，人工索引不现实；同时新闻与分析场景要求信息提取过程透明、可审计、无幻觉。

Method: 构建了一个涵盖多样化新闻图形的标注帧语料库，并设计了一个确定性、可审计、模块化的多阶段人名提取流水线（含高精度图形元素定位检测器）。

Result: 检测器mAP@0.5达95.8%；提取任务Precision 79.9%，Recall 74.4%，F1为77.08%；相较生成式方法（F1 84.18%），虽略低但具备完全可追溯性、零幻觉和审计保障；用户调研显示59%观众难以看清快节奏视频中的人名。

Conclusion: 该工作确立了面向现代新闻媒体的、方法严谨且可解释的混合多模态信息提取新基线，强调确定性与透明性优先于单纯指标提升。

Abstract: The growing volume of video-based news content has heightened the need for transparent and reliable methods to extract on-screen information. Yet the variability of graphical layouts, typographic conventions, and platform-specific design patterns renders manual indexing impractical. This work presents a comprehensive framework for automatically detecting and extracting personal names from broadcast and social-media-native news videos. It introduces a curated and balanced corpus of annotated frames capturing the diversity of contemporary news graphics and proposes an interpretable, modular extraction pipeline designed to operate under deterministic and auditable conditions.
  The pipeline is evaluated against a contrasting class of generative multimodal methods, revealing a clear trade-off between deterministic auditability and stochastic inference. The underlying detector achieves 95.8% mAP@0.5, demonstrating operationally robust performance for graphical element localisation. While generative systems achieve marginally higher raw accuracy (F1: 84.18% vs 77.08%), they lack the transparent data lineage required for journalistic and analytical contexts. The proposed pipeline delivers balanced precision (79.9%) and recall (74.4%), avoids hallucination, and provides full traceability across each processing stage. Complementary user findings indicate that 59% of respondents report difficulty reading on-screen names in fast-paced broadcasts, underscoring the practical relevance of the task. The results establish a methodologically rigorous and interpretable baseline for hybrid multimodal information extraction in modern news media.

</details>


### [6] [VLM-Guided Iterative Refinement for Surgical Image Segmentation with Foundation Models](https://arxiv.org/abs/2602.09252)
*Ange Lou,Yamin Li,Qi Chang,Nan Xi,Luyuan Xie,Zichao Li,Tianyu Luan*

Main category: cs.CV

TL;DR: 本文提出了IR-SIS，一种基于自然语言描述的迭代式外科图像分割系统，结合微调SAM3、视觉-语言模型与智能体工作流，支持医生通过自然语言反馈参与分割过程，并构建了多粒度语言标注数据集，实现了领域内及分布外数据上的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有外科图像分割方法受限于预定义类别、单次预测无自适应优化、缺乏临床医生交互机制。

Method: 提出IR-SIS系统：1）用微调后的SAM3进行初始分割；2）利用视觉-语言模型检测器械并评估分割质量；3）采用智能体工作流自适应选择细化策略；4）支持医生通过自然语言反馈参与（clinician-in-the-loop）；5）构建基于EndoVis2017/2018的多粒度语言标注数据集。

Result: 在领域内和分布外数据上均达到SOTA性能；临床医生交互进一步提升分割效果。

Conclusion: 首次建立了基于自然语言的外科图像分割框架，具备自适应自优化能力，为机器人辅助手术和术中导航提供了新范式。

Abstract: Surgical image segmentation is essential for robot-assisted surgery and intraoperative guidance. However, existing methods are constrained to predefined categories, produce one-shot predictions without adaptive refinement, and lack mechanisms for clinician interaction. We propose IR-SIS, an iterative refinement system for surgical image segmentation that accepts natural language descriptions. IR-SIS leverages a fine-tuned SAM3 for initial segmentation, employs a Vision-Language Model to detect instruments and assess segmentation quality, and applies an agentic workflow that adaptively selects refinement strategies. The system supports clinician-in-the-loop interaction through natural language feedback. We also construct a multi-granularity language-annotated dataset from EndoVis2017 and EndoVis2018 benchmarks. Experiments demonstrate state-of-the-art performance on both in-domain and out-of-distribution data, with clinician interaction providing additional improvements. Our work establishes the first language-based surgical segmentation framework with adaptive self-refinement capabilities.

</details>


### [7] [Decoding Future Risk: Deep Learning Analysis of Tubular Adenoma Whole-Slide Images](https://arxiv.org/abs/2602.09155)
*Ahmed Rahu,Brian Shula,Brandon Combs,Aqsa Sultana,Surendra P. Singh,Vijayan K. Asari,Derrick Forchetti*

Main category: cs.CV

TL;DR: 本研究探索使用卷积神经网络（CNN）分析低级别管状腺瘤的全切片图像（WSI），以识别预测患者远期结直肠癌（CRC）风险的细微组织学特征。


<details>
  <summary>Details</summary>
Motivation: 传统组织学评估难以捕捉提示恶性潜能的细微结构或细胞学特征，亟需识别低风险患者中高进展风险亚群，以实现个体化监测与预防。

Method: 采用卷积神经网络（CNN）对低级别管状腺瘤的全切片图像（WSI）进行分析，挖掘可预测远期CRC风险的细微组织学特征。

Result: 尚未在摘要中明确报告具体结果，但研究旨在验证CNN能否识别具有预测价值的细微特征。

Conclusion: 数字病理结合机器学习有望提升对低级别腺瘤恶性进展风险的客观、全面评估能力，为精准监测和干预提供新工具。

Abstract: Colorectal cancer (CRC) remains a significant cause of cancer-related mortality, despite the widespread implementation of prophylactic initiatives aimed at detecting and removing precancerous polyps. Although screening effectively reduces incidence, a notable portion of patients initially diagnosed with low-grade adenomatous polyps will still develop CRC later in life, even without the presence of known high-risk syndromes. Identifying which low-risk patients are at higher risk of progression is a critical unmet need for tailored surveillance and preventative therapeutic strategies. Traditional histological assessment of adenomas, while fundamental, may not fully capture subtle architectural or cytological features indicative of malignant potential. Advancements in digital pathology and machine learning provide an opportunity to analyze whole-slide images (WSIs) comprehensively and objectively. This study investigates whether machine learning algorithms, specifically convolutional neural networks (CNNs), can detect subtle histological features in WSIs of low-grade tubular adenomas that are predictive of a patient's long-term risk of developing colorectal cancer.

</details>


### [8] [All-in-One Conditioning for Text-to-Image Synthesis](https://arxiv.org/abs/2602.09165)
*Hirunima Jayasekara,Chuong Huynh,Yixuan Ren,Christabel Acquaye,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 本文提出了一种基于场景图的零样本条件机制，通过ASQL Conditioner在推理时生成软视觉引导，提升文本到图像合成中对复杂提示（多物体、属性、空间关系）的语义保真度与结构一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在处理含多个对象、属性和空间关系的复杂提示时，难以保持语义保真度和结构一致性。

Method: 提出基于场景图的零样本条件机制，核心是Attribute-Size-Quantity-Location (ASQL) Conditioner，利用轻量语言模型生成视觉条件，并通过推理时优化指导扩散模型生成。

Result: 实现了更准确的文本-图像对齐，同时支持轻量、连贯且多样化的图像合成。

Conclusion: 基于场景图的软条件机制可有效提升复杂提示下的生成质量，避免预定义布局带来的灵活性限制。

Abstract: Accurate interpretation and visual representation of complex prompts involving multiple objects, attributes, and spatial relationships is a critical challenge in text-to-image synthesis. Despite recent advancements in generating photorealistic outputs, current models often struggle with maintaining semantic fidelity and structural coherence when processing intricate textual inputs. We propose a novel approach that grounds text-to-image synthesis within the framework of scene graph structures, aiming to enhance the compositional abilities of existing models. Eventhough, prior approaches have attempted to address this by using pre-defined layout maps derived from prompts, such rigid constraints often limit compositional flexibility and diversity. In contrast, we introduce a zero-shot, scene graph-based conditioning mechanism that generates soft visual guidance during inference. At the core of our method is the Attribute-Size-Quantity-Location (ASQL) Conditioner, which produces visual conditions via a lightweight language model and guides diffusion-based generation through inference-time optimization. This enables the model to maintain text-image alignment while supporting lightweight, coherent, and diverse image synthesis.

</details>


### [9] [Wearable environmental sensing to forecast how legged systems will interact with upcoming terrain](https://arxiv.org/abs/2602.09209)
*Michael D. Murray,James Tung,Richard W. Nuckols*

Main category: cs.CV

TL;DR: 本文提出了一种基于RGB-D视觉数据和轻量级CNN-RNN模型的步态转换（平地→上楼梯）前足底压力中心（COP）与触地时刻（TOI）的实时预测方法，在250ms预测时域内取得毫米/毫秒级误差，并验证了其在边缘设备上的实时性。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉用于环境分类以辅助控制，但尚缺乏对足部如何接触动态变化环境（如平地转楼梯）的前瞻性预测能力，尤其缺少对足底压力中心（COP）和触地时刻（TOI）的提前预测研究。

Method: 采用佩戴于右小腿的RGB-D相机与足底压力鞋垫采集8名受试者从平地迈步上楼梯过程的数据；构建CNN-RNN混合模型，在触地前250ms窗口（forecast horizon, FH）内连续预测AP方向COP和TOI；分析步态参数（躯干速度、趾摆速度、足着地点位置）对预测误差的影响；评估模型在消费级笔记本和边缘设备上的实时运行性能（FPS）。

Result: COP预测MAE在150/100/50ms FH下分别为29.42/26.82/23.72 mm；TOI预测MAE为21.14/20.08/17.73 ms；趾摆速度越快，COP预测越准，而躯干速度无影响；更靠前的着地点降低COP预测精度但不影响TOI；模型可在边缘设备上达60 FPS实时运行。

Conclusion: 仅依赖小腿视觉数据，用轻量CNN-RNN即可高精度、低延迟地预测关键步态参数（COP与TOI），为假肢、外骨骼等助行设备的前馈式/预测性控制提供了可行技术路径。

Abstract: Computer-vision (CV) has been used for environmental classification during gait and is often used to inform control in assistive systems; however, the ability to predict how the foot will contact a changing environment is underexplored. We evaluated the feasibility of forecasting the anterior-posterior (AP) foot center-of-pressure (COP) and time-of-impact (TOI) prior to foot-strike on a level-ground to stair-ascent transition. Eight subjects wore an RGB-D camera on their right shank and instrumented insoles while performing the task of stepping onto the stairs. We trained a CNN-RNN to forecast the COP and TOI continuously within a 250ms window prior to foot-strike, termed the forecast horizon (FH). The COP mean-absolute-error (MAE) at 150, 100, and 50ms FH was 29.42mm, 26.82, and 23.72mm respectively. The TOI MAE was 21.14, 20.08, and 17.73ms for 150, 100, and 50ms respectively. While torso velocity had no effect on the error in either task, faster toe-swing speeds prior to foot-strike were found to improve the prediction accuracy in the COP case, however, was insignificant in the TOI case. Further, more anterior foot-strikes were found to reduce COP prediction accuracy but did not affect the TOI prediction accuracy. We also found that our lightweight model was capable at running at 60 FPS on either a consumer grade laptop or an edge computing device. This study demonstrates that forecasting COP and TOI from visual data was feasible using a lightweight model, which may have important implications for anticipatory control in assistive systems.

</details>


### [10] [VLM-UQBench: A Benchmark for Modality-Specific and Cross-Modality Uncertainties in Vision Language Models](https://arxiv.org/abs/2602.09214)
*Chenyu Wang,Tianle Chen,H. M. Sabbir Ahmad,Kayhan Batmanghelich,Wenchao Li*

Main category: cs.CV

TL;DR: 本文提出了VLM-UQBench基准，用于评估视觉语言模型（VLMs）中模态特异性和跨模态不确定性，并设计了扰动管道与两个新指标来分析现有不确定性量化（UQ）方法的表现，发现当前UQ方法在细粒度、模态感知的不确定性识别上存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有UQ方法难以准确定位不确定性来源（图像、文本或图文错配），缺乏对VLM中细粒度、模态感知不确定性的有效评估手段。

Method: 构建VLM-UQBench基准，包含600个真实样本及三类不确定性子集；设计含8种视觉、5种文本、3种跨模态扰动的可扩展扰动管道；提出两个新指标：扰动敏感性与幻觉相关性，用于评估多种UQ方法在四个VLM和三个数据集上的表现。

Result: （i）UQ方法表现出强模态特异性且高度依赖底层VLM；（ii）模态特异性不确定性常伴随幻觉，但当前UQ得分仅提供微弱且不一致的风险信号；（iii）UQ方法虽能在群体级明显歧义上媲美思维链基线，却难以检测扰动引入的实例级细微歧义。

Conclusion: 当前UQ实践与VLM可靠部署所需的细粒度、模态感知不确定性之间存在显著差距，亟需更精准、解耦的不确定性建模方法。

Abstract: Uncertainty quantification (UQ) is vital for ensuring that vision-language models (VLMs) behave safely and reliably. A central challenge is to localize uncertainty to its source, determining whether it arises from the image, the text, or misalignment between the two. We introduce VLM-UQBench, a benchmark for modality-specific and cross-modal data uncertainty in VLMs, It consists of 600 real-world samples drawn from the VizWiz dataset, curated into clean, image-, text-, and cross-modal uncertainty subsets, and a scalable perturbation pipeline with 8 visual, 5 textual, and 3 cross-modal perturbations. We further propose two simple metrics that quantify the sensitivity of UQ scores to these perturbations and their correlation with hallucinations, and use them to evaluate a range of UQ methods across four VLMs and three datasets. Empirically, we find that: (i) existing UQ methods exhibit strong modality-specific specialization and substantial dependence on the underlying VLM, (ii) modality-specific uncertainty frequently co-occurs with hallucinations while current UQ scores provide only weak and inconsistent risk signals, and (iii) although UQ methods can rival reasoning-based chain-of-thought baselines on overt, group-level ambiguity, they largely fail to detect the subtle, instance-level ambiguity introduced by our perturbation pipeline. These results highlight a significant gap between current UQ practices and the fine-grained, modality-aware uncertainty required for reliable VLM deployment.

</details>


### [11] [Rethinking Global Text Conditioning in Diffusion Transformers](https://arxiv.org/abs/2602.09268)
*Nikita Starodubcev,Daniil Pakhomov,Zongze Wu,Ilya Drobyshevskiy,Yuchen Liu,Zhonghao Wang,Yuqian Zhou,Zhe Lin,Dmitry Baranchuk*

Main category: cs.CV

TL;DR: 本文探讨了扩散变换器中基于调制的文本条件化是否必要，发现传统池化文本嵌入贡献有限，但若将其作为引导信号则能显著提升性能，且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 探究扩散变换器中基于调制的文本条件化是否必要，及其是否能带来性能优势。

Method: 通过分析池化文本嵌入在常规与新视角（作为引导信号）下的作用，验证其对模型性能的影响。

Result: 传统池化嵌入贡献小，但作为引导信号可显著提升性能；该方法无需训练、实现简单、开销低、通用性强。

Conclusion: 基于调制的文本条件化在传统用法中非必需，但换作引导机制后可有效提升可控性与生成质量。

Abstract: Diffusion transformers typically incorporate textual information via attention layers and a modulation mechanism using a pooled text embedding. Nevertheless, recent approaches discard modulation-based text conditioning and rely exclusively on attention. In this paper, we address whether modulation-based text conditioning is necessary and whether it can provide any performance advantage. Our analysis shows that, in its conventional usage, the pooled embedding contributes little to overall performance, suggesting that attention alone is generally sufficient for faithfully propagating prompt information. However, we reveal that the pooled embedding can provide significant gains when used from a different perspective-serving as guidance and enabling controllable shifts toward more desirable properties. This approach is training-free, simple to implement, incurs negligible runtime overhead, and can be applied to various diffusion models, bringing improvements across diverse tasks, including text-to-image/video generation and image editing.

</details>


### [12] [X-Mark: Saliency-Guided Robust Dataset Ownership Verification for Medical Imaging](https://arxiv.org/abs/2602.09284)
*Pranav Kulkarni,Junfeng Guo,Heng Huang*

Main category: cs.CV

TL;DR: 本文提出X-Mark，一种面向胸部X光片的样本特异性、干净标签水印方法，通过条件U-Net在显著区域生成独特扰动，结合多目标损失（含Laplacian正则化）实现水印有效性、缩放鲁棒性、诊断保真度与视觉可区分性，并在黑盒设置下实现高检出率与低误报率。


<details>
  <summary>Details</summary>
Motivation: 高质量医学影像数据集对深度学习训练至关重要，但其未经授权使用引发严重版权与伦理问题；现有面向自然图像的数据集所有权验证方法难以适配医学影像——因其动态高分辨率、视觉多样性低、解剖结构细微，且需严格保持诊断质量。

Method: 提出X-Mark：基于条件U-Net为每张胸片在显著区域生成样本特异性扰动；设计多组分训练目标（含Laplacian正则化）以兼顾水印有效性、缩放鲁棒性、诊断保真度与视觉可区分性；采用黑盒所有权验证策略，检测可疑模型的特征行为。

Result: 在CheXpert数据集上实验表明，X-Mark达到100%水印成功率（WSR），在Ind-M场景下误报概率降低12%，并对潜在自适应攻击具有鲁棒性。

Conclusion: X-Mark是一种专为胸部X光影像设计的高效、鲁棒且临床友好的水印方案，解决了医学影像数据版权保护中缩放不变性与诊断质量保持的关键矛盾。

Abstract: High-quality medical imaging datasets are essential for training deep learning models, but their unauthorized use raises serious copyright and ethical concerns. Medical imaging presents a unique challenge for existing dataset ownership verification methods designed for natural images, as static watermark patterns generated in fixed-scale images scale poorly dynamic and high-resolution scans with limited visual diversity and subtle anatomical structures, while preserving diagnostic quality. In this paper, we propose X-Mark, a sample-specific clean-label watermarking method for chest x-ray copyright protection. Specifically, X-Mark uses a conditional U-Net to generate unique perturbations within salient regions of each sample. We design a multi-component training objective to ensure watermark efficacy, robustness against dynamic scaling processes while preserving diagnostic quality and visual-distinguishability. We incorporate Laplacian regularization into our training objective to penalize high-frequency perturbations and achieve watermark scale-invariance. Ownership verification is performed in a black-box setting to detect characteristic behaviors in suspicious models. Extensive experiments on CheXpert verify the effectiveness of X-Mark, achieving WSR of 100% and reducing probability of false positives in Ind-M scenario by 12%, while demonstrating resistance to potential adaptive attacks.

</details>


### [13] [A Deep Multi-Modal Method for Patient Wound Healing Assessment](https://arxiv.org/abs/2602.09315)
*Subba Reddy Oota,Vijay Rowtula,Shahid Mohammed,Jeffrey Galitz,Minghsun Liu,Manish Gupta*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度多模态和迁移学习的伤口评估方法，通过融合伤口图像与临床变量预测患者住院风险，并同步估计伤口变量及愈合轨迹，以实现早期复杂性识别与临床诊断效率提升。


<details>
  <summary>Details</summary>
Motivation: 住院是伤口护理高成本的主要原因，而延迟治疗、患者依从性差或共病等因素可能导致伤口恶化并最终住院；现有研究多局限于特定伤口类型的愈合轨迹建模，缺乏对住院风险的多模态联合预测。

Method: 提出一种深度多模态方法，结合伤口图像与伤口变量，采用迁移学习框架，统一建模伤口变量预测与愈合轨迹预测任务。

Result: 构建了一个可同时从伤口图像中预测伤口变量及其愈合轨迹的迁移学习模型，提升了住院风险预测的置信度与临床实用性。

Conclusion: 该模型有助于伤口复杂性的早期识别，减少临床医生诊断时间，并有望降低因延误导致的住院率与护理成本。

Abstract: Hospitalization of patients is one of the major factors for high wound care costs. Most patients do not acquire a wound which needs immediate hospitalization. However, due to factors such as delay in treatment, patient's non-compliance or existing co-morbid conditions, an injury can deteriorate and ultimately lead to patient hospitalization. In this paper, we propose a deep multi-modal method to predict the patient's risk of hospitalization. Our goal is to predict the risk confidently by collectively using the wound variables and wound images of the patient. Existing works in this domain have mainly focused on healing trajectories based on distinct wound types. We developed a transfer learning-based wound assessment solution, which can predict both wound variables from wound images and their healing trajectories, which is our primary contribution. We argue that the development of a novel model can help in early detection of the complexities in the wound, which might affect the healing process and also reduce the time spent by a clinician to diagnose the wound.

</details>


### [14] [GAFR-Net: A Graph Attention and Fuzzy-Rule Network for Interpretable Breast Cancer Image Classification](https://arxiv.org/abs/2602.09318)
*Lin-Guo Gao,Suxing Liu*

Main category: cs.CV

TL;DR: 本文提出GAFRNet，一种结合图注意力机制与可微模糊规则的新型网络，用于少样本乳腺癌病理图像分类，兼具高性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在标注数据有限时性能下降，且缺乏可解释性，难以在临床中应用。

Method: GAFRNet构建基于相似性的图表示，利用多头图注意力捕捉组织间复杂关系，并引入可微模糊规则模块，将拓扑特征编码为人类可理解的IF-THEN诊断逻辑。

Result: 在BreakHis、Mini-DDSM和ICIAR2018三个基准数据集上，GAFRNet在多种放大倍率和分类任务中均优于现有先进方法。

Conclusion: GAFRNet在弱监督医学图像分析中展现出优异泛化能力与实用价值，是一种可靠、透明的临床决策支持工具。

Abstract: Accurate classification of breast cancer histopathology images is pivotal for early oncological diagnosis and therapeutic intervention.However, conventional deep learning architectures often encounter performance degradation under limited annotations and suffer from a "blackbox" nature, hindering their clinical integration. To mitigate these limitations, we propose GAFRNet, a robust and interpretable Graph Attention and FuzzyRule Network specifically engineered for histopathology image classification with scarce supervision. GAFRNet constructs a similarity-driven graph representation to model intersample relationships and employs a multihead graph attention mechanism to capture complex relational features across heterogeneous tissue structures.Concurrently, a differentiable fuzzy-rule module encodes intrinsic topological descriptorsincluding node degree, clustering coefficient, and label consistencyinto explicit, human-understandable diagnostic logic. This design establishes transparent "IF-THEN" mappings that mimic the heuristic deduction process of medical experts, providing clear reasoning behind each prediction without relying on post-hoc attribution methods. Extensive evaluations on three benchmark datasets (BreakHis, Mini-DDSM, and ICIAR2018) demonstrate that GAFR-Net consistently outperforms various state-of-the-art methods across multiple magnifications and classification tasks. These results validate the superior generalization and practical utility of GAFR-Net as a reliable decision-support tool for weakly supervised medical image analysis.

</details>


### [15] [Deep Modeling and Interpretation for Bladder Cancer Classification](https://arxiv.org/abs/2602.09324)
*Ahmad Chaddad,Yihang Wu,Xianrui Chen*

Main category: cs.CV

TL;DR: 本文评估了13种深度模型（4种CNN和8种Transformer）在膀胱癌图像分类任务中的性能、校准性与可解释性，发现ConvNeXt泛化能力有限，ViT系列在校准性和OOD样本解释性上更优，而ConvNeXt更适合ID样本。


<details>
  <summary>Details</summary>
Motivation: 自然图像上表现优异的ViT和CNN模型在医学影像（如膀胱癌）中可能表现不佳，因其异常区域占比小，需系统评估其在该任务下的适用性。

Method: 1）标准分类评估13种模型；2）校准分析检验模型预测置信度可靠性；3）GradCAM++评估模型可解释性；4）结合测试时增强提升可解释性；5）在多中心公开膀胱癌数据集上开展约300次实验。

Result: ConvNeXt系列准确率仅约60%，泛化能力差；ViT在校准性上优于ConvNeXt和Swin；无单一模型能兼顾所有需求：ConvNeXt适合分布内样本，ViT及其变体更适合分布外样本解释。

Conclusion: 模型选择应依据具体临床场景需求：强调ID样本性能时可选ConvNeXt，强调校准性与OOD可解释性时推荐ViT系列。

Abstract: Deep models based on vision transformer (ViT) and convolutional neural network (CNN) have demonstrated remarkable performance on natural datasets. However, these models may not be similar in medical imaging, where abnormal regions cover only a small portion of the image. This challenge motivates this study to investigate the latest deep models for bladder cancer classification tasks. We propose the following to evaluate these deep models: 1) standard classification using 13 models (four CNNs and eight transormer-based models), 2) calibration analysis to examine if these models are well calibrated for bladder cancer classification, and 3) we use GradCAM++ to evaluate the interpretability of these models for clinical diagnosis. We simulate $\sim 300$ experiments on a publicly multicenter bladder cancer dataset, and the experimental results demonstrate that the ConvNext series indicate limited generalization ability to classify bladder cancer images (e.g., $\sim 60\%$ accuracy). In addition, ViTs show better calibration effects compared to ConvNext and swin transformer series. We also involve test time augmentation to improve the models interpretability. Finally, no model provides a one-size-fits-all solution for a feasible interpretable model. ConvNext series are suitable for in-distribution samples, while ViT and its variants are suitable for interpreting out-of-distribution samples.

</details>


### [16] [Kyrtos: A methodology for automatic deep analysis of graphic charts with curves in technical documents](https://arxiv.org/abs/2602.09337)
*Michail S. Alexiou,Nikolaos G. Bourbakis*

Main category: cs.CV

TL;DR: 本文提出Kyrtos方法，用于自动识别与分析技术文档图像中含曲线的图表，通过聚类识别线段中点、解析行为特征，并将曲线结构转化为属性图和自然语言描述，最终支持转换为随机Petri网（SPN）以表征功能。


<details>
  <summary>Details</summary>
Motivation: 技术文档数量庞大且蕴含宝贵知识，其整体理解依赖于对图形、表格、文本等多模态内容及其关联的精准分析，尤其需处理含曲线的图表。

Method: Kyrtos方法分为识别与分析两部分：识别采用基于聚类的方法定位曲线构成线段的中点；分析则从提取的线段中捕获方向、趋势等行为特征，并构建属性图以保留结构特性，再将图关系转为自然语言句子，并进一步映射为随机Petri网（SPN）。

Result: 实验表明Kyrtos在多函数图表上能高精度重建原始曲线结构，通过结构相似性度量验证了其识别与分析的准确性。

Conclusion: Kyrtos有效实现了技术文档中曲线图表的自动识别、结构建模与语义转化，为技术文档的深度理解与功能建模提供了可行路径。

Abstract: Deep Understanding of Technical Documents (DUTD) has become a very attractive field with great potential due to large amounts of accumulated documents and the valuable knowledge contained in them. In addition, the holistic understanding of technical documents depends on the accurate analysis of its particular modalities, such as graphics, tables, diagrams, text, etc. and their associations. In this paper, we introduce the Kyrtos methodology for the automatic recognition and analysis of charts with curves in graphics images of technical documents. The recognition processing part adopts a clustering based approach to recognize middle-points that delimit the line-segments that construct the illustrated curves. The analysis processing part parses the extracted line-segments of curves to capture behavioral features such as direction, trend and etc. These associations assist the conversion of recognized segments' relations into attributed graphs, for the preservation of the curves' structural characteristics. The graph relations are also are expressed into natural language (NL) text sentences, enriching the document's text and facilitating their conversion into Stochastic Petri-net (SPN) graphs, which depict the internal functionality represented in the chart image. Extensive evaluation results demonstrate the accuracy of Kyrtos' recognition and analysis methods by measuring the structural similarity between input chart curves and the approximations generated by Kyrtos for charts with multiple functions.

</details>


### [17] [Impact of domain adaptation in deep learning for medical image classifications](https://arxiv.org/abs/2602.09355)
*Yihang Wu,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 本文研究了10种深度学习模型在四个医学影像数据集上模拟常见域自适应（DA）技术的效果，涵盖多模态、噪声数据、联邦学习、可解释性分析和分类器校准等场景。实验表明DA能提升模型性能、抗噪能力、可解释性和校准效果，但在联邦学习中增益有限。


<details>
  <summary>Details</summary>
Motivation: 尽管域自适应（DA）已有显著进展，但其核心思想仍为将不同域的数据对齐到共享特征空间，以利用有标签源域知识提升无/少标签目标域的模型性能；本文旨在系统评估DA在多种现实医学影像场景下的实际效果。

Method: 采用10种深度学习模型模拟常见DA技术，在四个医学图像数据集上开展实验，覆盖多模态、含高斯噪声数据、联邦学习（FL）、Grad-CAM++可解释性分析及分类器校准（ECE评估）等多种设定。

Result: DA结合ResNet34在脑肿瘤（BT）数据集上提升性能4.7%，抗高斯噪声带来约3%准确率提升；在皮肤癌联邦学习中仅提升约0.3%；DA增强Grad-CAM++可解释性，具备临床价值；在多模态数据上DA使预期校准误差（ECE）降低约2%。

Conclusion: DA在多数医学影像任务中展现出显著增益，尤其在性能提升、鲁棒性、可解释性和模型校准方面；但在联邦学习等特定框架下潜力有限，需进一步适配优化。

Abstract: Domain adaptation (DA) is a quickly expanding area in machine learning that involves adjusting a model trained in one domain to perform well in another domain. While there have been notable progressions, the fundamental concept of numerous DA methodologies has persisted: aligning the data from various domains into a shared feature space. In this space, knowledge acquired from labeled source data can improve the model training on target data that lacks sufficient labels. In this study, we demonstrate the use of 10 deep learning models to simulate common DA techniques and explore their application in four medical image datasets. We have considered various situations such as multi-modality, noisy data, federated learning (FL), interpretability analysis, and classifier calibration. The experimental results indicate that using DA with ResNet34 in a brain tumor (BT) data set results in an enhancement of 4.7\% in model performance. Similarly, the use of DA can reduce the impact of Gaussian noise, as it provides $\sim 3\%$ accuracy increase using ResNet34 on a BT dataset. Furthermore, simply introducing DA into FL framework shows limited potential (e.g., $\sim 0.3\%$ increase in performance) for skin cancer classification. In addition, the DA method can improve the interpretability of the models using the gradcam++ technique, which offers clinical values. Calibration analysis also demonstrates that using DA provides a lower expected calibration error (ECE) value $\sim 2\%$ compared to CNN alone on a multi-modality dataset.

</details>


### [18] [Self-Supervised Learning as Discrete Communication](https://arxiv.org/abs/2602.09764)
*Kawtar Zaher,Ilyass Moummad,Olivier Buisson,Alexis Joly*

Main category: cs.CV

TL;DR: 本文提出了一种将视觉自监督学习建模为教师-学生间离散通信过程的新范式，通过固定容量的二进制信道传递多标签二值消息，并引入编码率正则化与投影头周期重初始化，以学习结构化、语义丰富的离散表征。


<details>
  <summary>Details</summary>
Motivation: 现有SSL方法主要学习连续表征，难以控制信息在特征维度上的结构；缺乏对表征可解释性、紧凑性和跨任务可迁移性的显式建模。

Method: 将SSL建模为离散通信：教师生成多标签二值消息，学生通过二元交叉熵预测该消息；引入编码率正则化提升信道利用率；周期性重初始化投影头以增强表征鲁棒性与结构稳定性。

Result: 在图像分类、检索、密集预测及域自适应任务上均超越连续对齐基线；所学二值码构成紧凑、语义清晰、跨类可复用的离散语言。

Conclusion: 离散通信视角为SSL提供了新理论框架和实用机制，能有效引导模型学习更结构化、可控且语义明确的视觉表征。

Abstract: Most self-supervised learning (SSL) methods learn continuous visual representations by aligning different views of the same input, offering limited control over how information is structured across representation dimensions. In this work, we frame visual self-supervised learning as a discrete communication process between a teacher and a student network, where semantic information is transmitted through a fixed-capacity binary channel. Rather than aligning continuous features, the student predicts multi-label binary messages produced by the teacher. Discrete agreement is enforced through an element-wise binary cross-entropy objective, while a coding-rate regularization term encourages effective utilization of the constrained channel, promoting structured representations. We further show that periodically reinitializing the projection head strengthens this effect by encouraging embeddings that remain predictive across multiple discrete encodings. Extensive experiments demonstrate consistent improvements over continuous agreement baselines on image classification, retrieval, and dense visual prediction tasks, as well as under domain shift through self-supervised adaptation. Beyond backbone representations, we analyze the learned binary codes and show that they form a compact and informative discrete language, capturing semantic factors reusable across classes.

</details>


### [19] [Fully Differentiable Bidirectional Dual-Task Synergistic Learning for Semi-Supervised 3D Medical Image Segmentation](https://arxiv.org/abs/2602.09378)
*Jun Li*

Main category: cs.CV

TL;DR: 本文提出了一种可微双向协同学习（DBiSL）框架，用于医学图像分割的半监督学习，通过整合监督学习、一致性正则化、伪监督学习和不确定性估计，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像标注成本高、依赖专家知识，导致高质量标注数据稀缺；现有双任务协同学习方法仅支持单向交互（如回归到分割），无法充分利用在线双向跨任务协作潜力。

Method: 提出可微双向协同学习（DBiSL）框架，实现分割与回归任务间的在线、可微、双向协同；无缝集成监督学习、一致性正则化、伪监督学习和不确定性估计四大半监督学习核心组件。

Result: 在两个基准数据集上达到当前最优（state-of-the-art）性能；提供了统一半监督学习框架设计的新见解，并建立了双任务驱动半监督学习的新架构基础。

Conclusion: DBiSL不仅提升了半监督医学图像分割性能，还为多任务学习提供了通用框架，具有向更广泛计算机视觉任务拓展的潜力。

Abstract: Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. The scarcity of high-quality labeled data remains a major challenge in medical image analysis due to the high annotation costs and the need for specialized clinical expertise. Semi-supervised learning has demonstrated significant potential in addressing this bottleneck, with pseudo-labeling and consistency regularization emerging as two predominant paradigms. Dual-task collaborative learning, an emerging consistency-aware paradigm, seeks to derive supplementary supervision by establishing prediction consistency between related tasks. However, current methodologies are limited to unidirectional interaction mechanisms (typically regression-to-segmentation), as segmentation results can only be transformed into regression outputs in an offline manner, thereby failing to fully exploit the potential benefits of online bidirectional cross-task collaboration. Thus, we propose a fully Differentiable Bidirectional Synergistic Learning (DBiSL) framework, which seamlessly integrates and enhances four critical SSL components: supervised learning, consistency regularization, pseudo-supervised learning, and uncertainty estimation. Experiments on two benchmark datasets demonstrate our method's state-of-the-art performance. Beyond technical contributions, this work provides new insights into unified SSL framework design and establishes a new architectural foundation for dual-task-driven SSL, while offering a generic multitask learning framework applicable to broader computer vision applications. The code will be released on github upon acceptance.

</details>


### [20] [Single-Slice-to-3D Reconstruction in Medical Imaging and Natural Objects: A Comparative Benchmark with SAM 3D](https://arxiv.org/abs/2602.09407)
*Yan Luo,Advaith Ravishankar,Serena Liu,Yutong Yang,Mengyu Wang*

Main category: cs.CV

TL;DR: 本文评估了五种先进的单图像到3D生成模型在医学单切片图像重建3D解剖结构任务上的零样本性能，发现所有模型在体素重叠指标上表现中等，暴露出单切片深度推断的根本局限；SAM3D在拓扑相似性上最优，而其他模型易过度简化；研究强调需转向多视角重建以提升医学3D推断可靠性。


<details>
  <summary>Details</summary>
Motivation: 三维解剖理解对诊疗至关重要，但常规容积成像成本高、等待时间长；利用2D医学图像重建3D结构有望缓解该问题，然而现有基于自然图像训练的图像到3D基础模型其几何先验是否适用于医学数据尚不明确。

Method: 构建了一个受控的零样本基准测试，涵盖5个SOTA图像到3D模型（SAM3D、Hunyuan3D-2.1、Direct3D、Hi3DGen、TripoSG），在6个医学数据集（涵盖解剖与病理结构）及2个自然图像数据集上，采用体素重叠和点云距离两类指标进行评估。

Result: 所有模型在医学数据上的体素重叠率均处于中等水平，表明存在深度重建失败；全局距离指标显示方法间存在差异：SAM3D在拓扑相似性上最优，其余模型更易产生过度简化的重建结果。

Conclusion: 单切片医学图像到3D重建存在固有局限，主要源于2D医学图像的平面本质导致的深度模糊性；应推动多视角图像到3D重建以实现可靠的医学三维推断。

Abstract: A 3D understanding of anatomy is central to diagnosis and treatment planning, yet volumetric imaging remains costly with long wait times. Image-to-3D foundations models can solve this issue by reconstructing 3D data from 2D modalites. Current foundation models are trained on natural image distributions to reconstruct naturalistic objects from a single image by leveraging geometric priors across pixels. However, it is unclear whether these learned geometric priors transfer to medical data. In this study, we present a controlled zero-shot benchmark of single slice medical image-to-3D reconstruction across five state-of-the-art image-to-3D models: SAM3D, Hunyuan3D-2.1, Direct3D, Hi3DGen, and TripoSG. These are evaluated across six medical datasets spanning anatomical and pathological structures and two natrual datasets, using voxel based metrics and point cloud distance metrics. Across medical datasets, voxel based overlap remains moderate for all models, consistent with a depth reconstruction failure mode when inferring volume from a single slice. In contrast, global distance metrics show more separation between methods: SAM3D achieves the strongest overall topological similarity to ground truth medical 3D data, while alternative models are more prone to over-simplication of reconstruction. Our results quantify the limits of single-slice medical reconstruction and highlight depth ambiguity caused by the planar nature of 2D medical data, motivating multi-view image-to-3D reconstruction to enable reliable medical 3D inference.

</details>


### [21] [K-Sort Eval: Efficient Preference Evaluation for Visual Generation via Corrected VLM-as-a-Judge](https://arxiv.org/abs/2602.09411)
*Zhikai Li,Jiatong Li,Xuewen Liu,Wangbo Zhao,Pan Du,Kaicheng Zhou,Qingyi Gu,Yang You,Zhen Dong,Kurt Keutzer*

Main category: cs.CV

TL;DR: 本文提出K-Sort Eval框架，利用视觉语言模型（VLM）结合后验校正与动态匹配策略，实现高效、可靠且与人类偏好对齐的生成模型评估。


<details>
  <summary>Details</summary>
Motivation: 现有基于众包的人类偏好评估（如Arena平台）成本高、耗时长，难以扩展；而直接用VLM替代人工判断又受限于其幻觉和偏差，且静态评估效率低。

Method: 构建高质量K-Sort Arena人类投票数据集；引入(K+1)-way自由比对机制；提出后验校正方法（基于VLM预测与人类监督一致性自适应调整贝叶斯后验概率）；设计动态匹配策略（权衡不确定性与多样性以最大化单次比较收益）。

Result: 实验表明K-Sort Eval评估结果与K-Sort Arena高度一致，通常仅需少于90次模型运行，兼具高效率与高可靠性。

Conclusion: K-Sort Eval是一种可扩展、可靠且高效的人类对齐视觉生成模型评估新范式，为VLM驱动的自动评估提供了实用解决方案。

Abstract: The rapid development of visual generative models raises the need for more scalable and human-aligned evaluation methods. While the crowdsourced Arena platforms offer human preference assessments by collecting human votes, they are costly and time-consuming, inherently limiting their scalability. Leveraging vision-language model (VLMs) as substitutes for manual judgments presents a promising solution. However, the inherent hallucinations and biases of VLMs hinder alignment with human preferences, thus compromising evaluation reliability. Additionally, the static evaluation approach lead to low efficiency. In this paper, we propose K-Sort Eval, a reliable and efficient VLM-based evaluation framework that integrates posterior correction and dynamic matching. Specifically, we curate a high-quality dataset from thousands of human votes in K-Sort Arena, with each instance containing the outputs and rankings of K models. When evaluating a new model, it undergoes (K+1)-wise free-for-all comparisons with existing models, and the VLM provide the rankings. To enhance alignment and reliability, we propose a posterior correction method, which adaptively corrects the posterior probability in Bayesian updating based on the consistency between the VLM prediction and human supervision. Moreover, we propose a dynamic matching strategy, which balances uncertainty and diversity to maximize the expected benefit of each comparison, thus ensuring more efficient evaluation. Extensive experiments show that K-Sort Eval delivers evaluation results consistent with K-Sort Arena, typically requiring fewer than 90 model runs, demonstrating both its efficiency and reliability.

</details>


### [22] [LARV: Data-Free Layer-wise Adaptive Rescaling Veneer for Model Merging](https://arxiv.org/abs/2602.09413)
*Xinyu Wang,Ke Deng,Fei Dou,Jinbo Bi,Jin Lu*

Main category: cs.CV

TL;DR: 本文提出LARV，一种无需训练、无需数据的层自适应重缩放技术，用于任务向量合并，通过为每层分配特定缩放因子来提升多种合并方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有任务向量合并方法忽略大视觉Transformer中各层异质性（浅层易受干扰、深层编码稳定任务特征），导致合并效果受限。

Method: LARV是一种插件式、与合并器无关的层自适应重缩放方法，基于简单确定性调度和数据免费层代理计算每层缩放因子，支持多种实例化方式（如分级或连续映射）。

Result: LARV在FusionBench上显著提升多种任务向量合并基线（如Iso-C+LARV在ViT-L/14达92.6%），并通过层分析和鲁棒性测试验证其抑制浅层干扰、增强深层对齐的效果。

Conclusion: LARV是首个面向任务向量合并的层感知缩放方法，正交于基础合并器、开销极小，将模型合并从统一操作转变为鲁棒的层感知过程。

Abstract: Model merging aims to combine multiple fine-tuned models into a single multi-task model without access to training data. Existing task-vector merging methods such as TIES, TSV-M, and Iso-C/CTS differ in their aggregation rules but treat all layers nearly uniformly. This assumption overlooks the strong layer-wise heterogeneity in large vision transformers, where shallow layers are sensitive to interference while deeper layers encode stable task-specific features. We introduce LARV, a training-free, data-free, merger-agnostic Layer-wise Adaptive Rescaling Veneer that plugs into any task-vector merger and assigns a per-layer scale to each task vector before aggregation, and show it consistently boosts diverse merging rules. LARV adaptively suppresses shallow-layer interference and amplifies deeper-layer alignment using a simple deterministic schedule, requiring no retraining or modification to existing mergers. To our knowledge, this is the first work to perform layer-aware scaling for task-vector merging. LARV computes simple data-free layer proxies and turns them into scales through a lightweight rule; we study several instantiations within one framework (e.g., tiered two/three-level scaling with fixed values, or continuous mappings) and show that tiered choices offer the best robustness, while continuous mappings remain an ablation. LARV is orthogonal to the base merger and adds negligible cost. On FusionBench with Vision Transformers, LARV consistently improves all task-vector baselines across 8/14/20-task settings; for example, Iso-C + LARV reaches 85.9% on ViT-B/32, 89.2% on ViT-B/16, and 92.6% on ViT-L/14. Layerwise analysis and corruption tests further indicate that LARV suppresses shallow-layer interference while modestly amplifying deeper, task-stable features, turning model merging into a robust, layer-aware procedure rather than a uniform one.

</details>


### [23] [Stability and Concentration in Nonlinear Inverse Problems with Block-Structured Parameters: Lipschitz Geometry, Identifiability, and an Application to Gaussian Splatting](https://arxiv.org/abs/2602.09415)
*Joe-Mei Feng,Hsin-Hsiung Kao*

Main category: cs.CV

TL;DR: 本文提出了一种面向块结构参数的非线性反问题的算子理论框架，建立了确定性稳定性不等式、全局Lipschitz界与非渐近集中估计，并应用于高斯点绘渲染算子，揭示了稳定性与分辨率间的根本权衡。


<details>
  <summary>Details</summary>
Motivation: 为刻画现代成像与可微渲染中高维非线性反问题的算子级性能极限，需统一处理稳定性、统计集中性与参数结构（如块结构）之间的关系。

Method: 构建基于算子理论的分析框架，结合分块Lipschitz几何、局部可识别性与亚高斯噪声假设，推导确定性稳定性不等式、最小二乘目标函数的全局Lipschitz界及非渐近集中估计；并以高斯点绘渲染算子为实例验证假设并量化常数。

Result: 获得与重构算法无关、仅依赖前向算子的高概率参数误差界；明确给出高斯点绘中Lipschitz常数与分辨率相关可观测性的显式表达；揭示估计误差受图像分辨率与模型复杂度之比的根本约束。

Conclusion: 该框架揭示了块结构非线性反问题在算子层面的内在稳定性与统计极限，为可微渲染与计算成像中的理论分析与算法设计提供了基础保障。

Abstract: We develop an operator-theoretic framework for stability and statistical concentration in nonlinear inverse problems with block-structured parameters. Under a unified set of assumptions combining blockwise Lipschitz geometry, local identifiability, and sub-Gaussian noise, we establish deterministic stability inequalities, global Lipschitz bounds for least-squares misfit functionals, and nonasymptotic concentration estimates. These results yield high-probability parameter error bounds that are intrinsic to the forward operator and independent of any specific reconstruction algorithm. As a concrete instantiation, we verify that the Gaussian Splatting rendering operator satisfies the proposed assumptions and derive explicit constants governing its Lipschitz continuity and resolution-dependent observability. This leads to a fundamental stability--resolution tradeoff, showing that estimation error is inherently constrained by the ratio between image resolution and model complexity. Overall, the analysis characterizes operator-level limits for a broad class of high-dimensional nonlinear inverse problems arising in modern imaging and differentiable rendering.

</details>


### [24] [Bridging the Modality Gap in Roadside LiDAR: A Training-Free Vision-Language Model Framework for Vehicle Classification](https://arxiv.org/abs/2602.09425)
*Yiqiao Li,Bo Shang,Jie Wei*

Main category: cs.CV

TL;DR: 本文提出了一种无需参数微调、适配现成视觉-语言模型（VLM）用于路侧LiDAR细粒度卡车分类的新框架，通过深度感知图像生成将稀疏点云转为2D视觉代理，在极少量样本（16–30例/类）下实现高精度分类，并揭示了文本引导的‘语义锚’效应及冷启动应用价值。


<details>
  <summary>Details</summary>
Motivation: 现有基于LiDAR的细粒度卡车分类方法依赖大量人工标注和监督学习，扩展性差；而VLM虽具少样本泛化能力，但受限于LiDAR（稀疏3D点云）与图像（稠密2D）之间的模态鸿沟。

Method: 设计深度感知图像生成流程，包括去噪、时空配准、朝向校正、形态学操作与各向异性平滑，将原始LiDAR点云转化为深度编码的2D视觉代理，进而直接输入冻结权重的商用VLM进行零微调分类；同时探索文本提示引导下的‘语义锚’效应，并将其用于冷启动——用VLM生成伪标签训练轻量监督模型。

Result: 在20类真实车辆数据集上，仅需每类16–30个样本即达有竞争力的分类精度；对特定拖车类别（20ft/40ft/53ft集装箱）实现>75%正确率，且无需任何训练或微调；发现k<4时文本引导提升性能，k增大后因语义失配反而下降。

Conclusion: 该框架显著降低ITS中初始人工标注成本，为LiDAR细粒度识别提供了可扩展、实用的少样本解决方案，并拓展了VLM在3D感知中的跨模态应用范式。

Abstract: Fine-grained truck classification is critical for intelligent transportation systems (ITS), yet current LiDAR-based methods face scalability challenges due to their reliance on supervised deep learning and labor-intensive manual annotation. Vision-Language Models (VLMs) offer promising few-shot generalization, but their application to roadside LiDAR is limited by a modality gap between sparse 3D point clouds and dense 2D imagery. We propose a framework that bridges this gap by adapting off-the-shelf VLMs for fine-grained truck classification without parameter fine-tuning. Our new depth-aware image generation pipeline applies noise removal, spatial and temporal registration, orientation rectification, morphological operations, and anisotropic smoothing to transform sparse, occluded LiDAR scans into depth-encoded 2D visual proxies. Validated on a real-world dataset of 20 vehicle classes, our approach achieves competitive classification accuracy with as few as 16-30 examples per class, offering a scalable alternative to data-intensive supervised baselines. We further observe a "Semantic Anchor" effect: text-based guidance regularizes performance in ultra-low-shot regimes $k < 4$, but degrades accuracy in more-shot settings due to semantic mismatch. Furthermore, we demonstrate the efficacy of this framework as a Cold Start strategy, using VLM-generated labels to bootstrap lightweight supervised models. Notably, the few-shot VLM-based model achieves over correct classification rate of 75 percent for specific drayage categories (20ft, 40ft, and 53ft containers) entirely without the costly training or fine-tuning, significantly reducing the intensive demands of initial manual labeling, thus achieving a method of practical use in ITS applications.

</details>


### [25] [SceneReVis: A Self-Reflective Vision-Grounded Framework for 3D Indoor Scene Synthesis via Multi-turn RL](https://arxiv.org/abs/2602.09432)
*Yang Zhao,Shizhao Sun,Meisheng Zhang,Yingdong Shi,Xubo Yang,Jiang Bian*

Main category: cs.CV

TL;DR: 本文提出SceneReVis框架，通过视觉引导的自反思机制和迭代式‘诊断-行动’循环，解决3D场景合成中的空间幻觉问题；构建了SceneChain-12k数据集，并采用两阶段训练策略（监督微调→智能体强化学习），显著提升生成质量与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有单次生成的3D场景合成方法常因缺乏审慎推理而出现空间幻觉（如物体碰撞），亟需引入可解释、可干预的推理机制。

Method: 提出SceneReVis框架，包含视觉接地的自反思机制与迭代‘诊断-行动’循环；构建SceneChain-12k因果构造轨迹数据集；采用两阶段训练：先监督微调，再基于多模态反馈的智能体强化学习。

Result: 在高保真生成与目标导向优化任务上达到SOTA性能，且对长尾领域具有强泛化能力。

Conclusion: 显式建模空间推理过程（而非端到端黑箱生成）是提升3D场景合成可靠性的关键路径，SceneReVis为具身AI与三维理解提供了新范式。

Abstract: Current one-pass 3D scene synthesis methods often suffer from spatial hallucinations, such as collisions, due to a lack of deliberative reasoning. To bridge this gap, we introduce SceneReVis, a vision-grounded self-reflection framework that employs an iterative ``diagnose-and-act'' loop to explicitly intercept and resolve spatial conflicts using multi-modal feedback. To support this step-wise paradigm, we construct SceneChain-12k, a large-scale dataset of causal construction trajectories derived through a novel reverse engineering pipeline. We further propose a two-stage training recipe that transitions from Supervised Fine-Tuning to Agentic Reinforcement Learning, evolving the model into an active spatial planner. Extensive experiments demonstrate that SceneReVis achieves state-of-the-art performance in high-fidelity generation and goal-oriented optimization, with robust generalization to long-tail domains.

</details>


### [26] [Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning](https://arxiv.org/abs/2602.09439)
*Xu Ma,Yitian Zhang,Qihua Dong,Yun Fu*

Main category: cs.CV

TL;DR: 本文提出了Fine-T2I，一个大规模、高质量、完全开源的文本到图像（T2I）微调数据集，包含600多万对文本-图像样本，覆盖多样任务、风格与提示模板，并经过严格筛选以确保图文对齐与质量；实验证明其显著提升多种预训练模型的生成质量与指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 当前公开的文本到图像微调数据集普遍存在分辨率低、图文对齐差、多样性不足等问题，导致开源模型性能明显落后于企业级模型，亟需高质量开放数据集来弥合这一差距。

Method: 构建Fine-T2I数据集：融合强现代生成模型合成图像与专业摄影师实拍图像；覆盖10种任务组合、32类提示、11种视觉风格和5种提示模板；通过多阶段严格过滤（图文对齐、视觉保真度、提示质量），剔除超95%候选样本。

Result: 最终获得超600万高质量文本-图像对、约2TB规模的数据集；在多种扩散与自回归预训练模型上微调后，在人类评估、视觉对比和自动指标上均显著提升生成质量与指令遵循能力。

Conclusion: Fine-T2I有效缓解了T2I微调中高质量开放数据稀缺的问题，为开源社区提供了可媲美预训练规模但保持微调级质量的数据资源，推动公平、透明与可复现的研究发展。

Abstract: High-quality and open datasets remain a major bottleneck for text-to-image (T2I) fine-tuning. Despite rapid progress in model architectures and training pipelines, most publicly available fine-tuning datasets suffer from low resolution, poor text-image alignment, or limited diversity, resulting in a clear performance gap between open research models and enterprise-grade models. In this work, we present Fine-T2I, a large-scale, high-quality, and fully open dataset for T2I fine-tuning. Fine-T2I spans 10 task combinations, 32 prompt categories, 11 visual styles, and 5 prompt templates, and combines synthetic images generated by strong modern models with carefully curated real images from professional photographers. All samples are rigorously filtered for text-image alignment, visual fidelity, and prompt quality, with over 95% of initial candidates removed. The final dataset contains over 6 million text-image pairs, around 2 TB on disk, approaching the scale of pretraining datasets while maintaining fine-tuning-level quality. Across a diverse set of pretrained diffusion and autoregressive models, fine-tuning on Fine-T2I consistently improves both generation quality and instruction adherence, as validated by human evaluation, visual comparison, and automatic metrics. We release Fine-T2I under an open license to help close the data gap in T2I fine-tuning in the open community.

</details>


### [27] [A Scoping Review of Deep Learning for Urban Visual Pollution and Proposal of a Real-Time Monitoring Framework with a Visual Pollution Index](https://arxiv.org/abs/2602.09446)
*Mohammad Masudur Rahman,Md. Rashedur Rahman,Ashraful Islam,Saadia B Alam,M Ashraful Amin*

Main category: cs.CV

TL;DR: 本文是一篇关于城市视觉污染（UVP）自动检测的范围综述，系统梳理了基于深度学习的检测与分类方法，指出当前研究存在数据集地域局限、缺乏统一分类体系和实时应用不足等问题，并提出一个整合视觉污染指数的综合管理框架。


<details>
  <summary>Details</summary>
Motivation: 城市视觉污染（UVP）日益严重，但其自动检测与应用研究分散、缺乏系统性，亟需整合性综述与统一管理框架。

Method: 遵循PRISMA-ScR指南，系统检索并分析7个学术数据库中的26篇文献，归纳主流模型（YOLO、Faster R-CNN、EfficientDet）、数据集现状及应用瓶颈，并提出包含视觉污染指数的综合管理框架。

Result: 识别出当前研究集中于特定污染物类别、模型架构趋同、数据集地域性强且缺乏标准分类法；少数实时系统存在地理偏差；提出首个集成视觉污染指数的监测框架。

Conclusion: 需构建统一的城市视觉污染管理系统，涵盖标准化污染物分类体系、跨城市基准数据集、泛化能力强的深度学习模型，以及支持可持续城市美学与居民福祉的评估指数。

Abstract: Urban Visual Pollution (UVP) has emerged as a critical concern, yet research on automatic detection and application remains fragmented. This scoping review maps the existing deep learning-based approaches for detecting, classifying, and designing a comprehensive application framework for visual pollution management. Following the PRISMA-ScR guidelines, seven academic databases (Scopus, Web of Science, IEEE Xplore, ACM DL, ScienceDirect, SpringerNatureLink, and Wiley) were systematically searched and reviewed, and 26 articles were found. Most research focuses on specific pollutant categories and employs variations of YOLO, Faster R-CNN, and EfficientDet architectures. Although several datasets exist, they are limited to specific areas and lack standardized taxonomies. Few studies integrate detection into real-time application systems, yet they tend to be geographically skewed. We proposed a framework for monitoring visual pollution that integrates a visual pollution index to assess the severity of visual pollution for a certain area. This review highlights the need for a unified UVP management system that incorporates pollutant taxonomy, a cross-city benchmark dataset, a generalized deep learning model, and an assessment index that supports sustainable urban aesthetics and enhances the well-being of urban dwellers.

</details>


### [28] [Look-Ahead and Look-Back Flows: Training-Free Image Generation with Trajectory Smoothing](https://arxiv.org/abs/2602.09449)
*Yan Luo,Henry Huang,Todd Y. Zhou,Mengyu Wang*

Main category: cs.CV

TL;DR: 本文提出两种无需训练的潜在轨迹调整方法（Look-Ahead 和 Look-Back），通过在潜在空间中平滑生成路径来提升扩散模型图像生成质量，显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于流匹配的训练-free方法通过调整速度场v来改进生成，但该调整会沿生成路径累积误差；而直接调整潜在轨迹z可由预训练速度网络自然校正，误差更小。

Method: 提出两种训练-free的潜在轨迹平滑方案：1）Look-Ahead——利用曲率加权平均当前与下一步潜在表示；2）Look-Back——采用指数滑动平均对潜在轨迹进行平滑。

Result: 在COCO17、CUB-200和Flickr30K等多个数据集上，所提方法在多项评估指标下显著超越多种SOTA模型。

Conclusion: 在潜在空间中直接优化轨迹比在速度场中调整更鲁棒高效，所提出的两种轨迹平滑策略为训练-free扩散生成提供了新范式。

Abstract: Recent advances have reformulated diffusion models as deterministic ordinary differential equations (ODEs) through the framework of flow matching, providing a unified formulation for the noise-to-data generative process. Various training-free flow matching approaches have been developed to improve image generation through flow velocity field adjustment, eliminating the need for costly retraining. However, Modifying the velocity field $v$ introduces errors that propagate through the full generation path, whereas adjustments to the latent trajectory $z$ are naturally corrected by the pretrained velocity network, reducing error accumulation. In this paper, we propose two complementary training-free latent-trajectory adjustment approaches based on future and past velocity $v$ and latent trajectory $z$ information that refine the generative path directly in latent space. We propose two training-free trajectory smoothing schemes: \emph{Look-Ahead}, which averages the current and next-step latents using a curvature-gated weight, and \emph{Look-Back}, which smoothes latents using an exponential moving average with decay. We demonstrate through extensive experiments and comprehensive evaluation metrics that the proposed training-free trajectory smoothing models substantially outperform various state-of-the-art models across multiple datasets including COCO17, CUB-200, and Flickr30K.

</details>


### [29] [ArtifactLens: Hundreds of Labels Are Enough for Artifact Detection with VLMs](https://arxiv.org/abs/2602.09475)
*James Burgess,Rameen Abdal,Dan Stoddart,Sergey Tulyakov,Serena Yeung-Levy,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: 本文提出ArtifactLens系统，利用预训练视觉语言模型（VLM）结合少量标注数据（每类数百样本）和多组件架构（含上下文学习与文本指令优化），高效检测生成图像中的人工痕迹（如扭曲的手、变形物体等），在多个基准上达到SOTA，显著降低对大规模标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有检测器需对视觉语言模型（VLM）进行大规模微调（数万标注图像），成本高且难以适应快速迭代的生成模型和新类型人工痕迹；亟需一种低数据依赖、泛化性强的轻量级检测方法。

Method: 提出ArtifactLens系统，核心是利用预训练VLM固有知识，通过多组件架构实现少样本检测：包括基于上下文学习（in-context learning）的提示机制、可优化的文本指令设计，以及针对不同人工痕迹类型的模块化适配策略。

Result: 在五个面向人类人工痕迹的基准测试中达到SOTA性能；首次实现跨多数据集统一评估；显著减少标注需求（仅需每类数百样本）；方法成功泛化至物体形态、动物解剖结构、实体交互等其他人工痕迹类型，以及AIGC整体检测任务。

Conclusion: 预训练VLM已蕴含丰富的人工痕迹判别能力，只需合理‘ scaffolding ’（如指令优化与上下文学习）即可高效释放，无需大量微调；ArtifactLens为低成本、高泛化性的AIGC检测提供了新范式。

Abstract: Modern image generators produce strikingly realistic images, where only artifacts like distorted hands or warped objects reveal their synthetic origin. Detecting these artifacts is essential: without detection, we cannot benchmark generators or train reward models to improve them. Current detectors fine-tune VLMs on tens of thousands of labeled images, but this is expensive to repeat whenever generators evolve or new artifact types emerge. We show that pretrained VLMs already encode the knowledge needed to detect artifacts - with the right scaffolding, this capability can be unlocked using only a few hundred labeled examples per artifact category. Our system, ArtifactLens, achieves state-of-the-art on five human artifact benchmarks (the first evaluation across multiple datasets) while requiring orders of magnitude less labeled data. The scaffolding consists of a multi-component architecture with in-context learning and text instruction optimization, with novel improvements to each. Our methods generalize to other artifact types - object morphology, animal anatomy, and entity interactions - and to the distinct task of AIGC detection.

</details>


### [30] [FD-DB: Frequency-Decoupled Dual-Branch Network for Unpaired Synthetic-to-Real Domain Translation](https://arxiv.org/abs/2602.09476)
*Chuanhai Zang,Jiabao Hu,XW Song*

Main category: cs.CV

TL;DR: 本文提出FD-DB模型，通过频率解耦的双分支架构，在无配对数据下实现合成到真实图像的域迁移：一个可解释的低频编辑分支控制白平衡、曝光等物理参数以保持结构稳定，另一个自由高频残差分支补充细节，并通过门控融合与两阶段训练提升真实感与结构一致性。


<details>
  <summary>Details</summary>
Motivation: 合成数据虽成本低、标注准，但因外观与成像差异导致严重域偏移；现有无配对合成到真实翻译方法难以兼顾光度真实感与结构稳定性。

Method: 提出频率解耦双分支（FD-DB）模型：低频可解释分支预测物理编辑参数（白平衡、曝光、对比度、饱和度、模糊、噪点）构建稳定外观基底；高频自由分支生成残差细节；门控融合机制在显式频率约束下融合二者；并采用两阶段训练策略（先稳编辑支，再启残差支）。

Result: 在YCB-V数据集上验证，FD-DB显著提升真实域外观一致性，下游语义分割性能大幅提升，同时保持几何与语义结构完整性。

Conclusion: FD-DB通过频率解耦与物理可解释编辑，在无配对设定下有效缓解合成-真实域差距，兼顾真实性与结构稳定性，为几何敏感视觉任务提供更可靠的合成数据增强方案。

Abstract: Synthetic data provide low-cost, accurately annotated samples for geometry-sensitive vision tasks, but appearance and imaging differences between synthetic and real domains cause severe domain shift and degrade downstream performance. Unpaired synthetic-to-real translation can reduce this gap without paired supervision, yet existing methods often face a trade-off between photorealism and structural stability: unconstrained generation may introduce deformation or spurious textures, while overly rigid constraints limit adaptation to real-domain statistics. We propose FD-DB, a frequency-decoupled dual-branch model that separates appearance transfer into low-frequency interpretable editing and high-frequency residual compensation. The interpretable branch predicts physically meaningful editing parameters (white balance, exposure, contrast, saturation, blur, and grain) to build a stable low-frequency appearance base with strong content preservation. The free branch complements fine details through residual generation, and a gated fusion mechanism combines the two branches under explicit frequency constraints to limit low-frequency drift. We further adopt a two-stage training schedule that first stabilizes the editing branch and then releases the residual branch to improve optimization stability. Experiments on the YCB-V dataset show that FD-DB improves real-domain appearance consistency and significantly boosts downstream semantic segmentation performance while preserving geometric and semantic structures.

</details>


### [31] [Weakly Supervised Contrastive Learning for Histopathology Patch Embeddings](https://arxiv.org/abs/2602.09477)
*Bodong Zhang,Xiwen Li,Hamid Manoochehri,Xiaoya Tang,Deepika Sirohi,Beatrice S. Knudsen,Tolga Tasdizen*

Main category: cs.CV

TL;DR: 本文提出了一种名为WeakSupCon的弱监督对比学习框架，用于在多实例学习（MIL）中提升图像块特征表示能力，仅需滑片级标签，无需实例级伪标签，显著提升下游MIL任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有MIL方法多直接使用冻结的预训练图像编码器提取的补丁特征，忽视了在MIL设定下对编码器进行弱监督特征表示学习的重要性；而手动标注补丁级标签成本高昂。

Method: 提出WeakSupCon——一种结合包级（滑片级）标签信息的弱监督对比学习框架，不依赖实例级伪标签，通过对比学习拉近同标签补丁、推远不同标签补丁在特征空间中的距离。

Result: 在三个数据集上的实验表明，WeakSupCon生成的图像特征显著优于自监督对比学习方法，在下游MIL任务中取得更好性能。

Conclusion: WeakSupCon有效利用稀疏的包级标签进行特征表示学习，为弱监督数字病理图像分析提供了新思路，验证了在MIL范式下联合优化特征学习与聚合的必要性。

Abstract: Digital histopathology whole slide images (WSIs) provide gigapixel-scale high-resolution images that are highly useful for disease diagnosis. However, digital histopathology image analysis faces significant challenges due to the limited training labels, since manually annotating specific regions or small patches cropped from large WSIs requires substantial time and effort. Weakly supervised multiple instance learning (MIL) offers a practical and efficient solution by requiring only bag-level (slide-level) labels, while each bag typically contains multiple instances (patches). Most MIL methods directly use frozen image patch features generated by various image encoders as inputs and primarily focus on feature aggregation. However, feature representation learning for encoder pretraining in MIL settings has largely been neglected.
  In our work, we propose a novel feature representation learning framework called weakly supervised contrastive learning (WeakSupCon) that incorporates bag-level label information during training. Our method does not rely on instance-level pseudo-labeling, yet it effectively separates patches with different labels in the feature space. Experimental results demonstrate that the image features generated by our WeakSupCon method lead to improved downstream MIL performance compared to self-supervised contrastive learning approaches in three datasets. Our related code is available at github.com/BzhangURU/Paper_WeakSupCon_for_MIL

</details>


### [32] [Beyond Next-Token Alignment: Distilling Multimodal Large Language Models via Token Interactions](https://arxiv.org/abs/2602.09483)
*Lin Chen,Xiaoke Zhao,Kun Ding,Weiwei Feng,Changtao Miao,Zili Wang,Wenxuan Guo,Ying Wang,Kaiyuan Zheng,Bo Zhang,Zhe Li,Shiming Xiang*

Main category: cs.CV

TL;DR: 本文提出Align-TI，一种面向Token Interactions的知识蒸馏框架，通过视觉-指令对齐（IVA）和响应内token转移对齐（TPA），提升多模态大语言模型（MLLMs）的蒸馏效果，在参数更少的情况下超越更大模型。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法仅关注静态next-token对齐，忽视了蕴含多模态理解与生成能力的动态token交互。

Method: 提出Align-TI框架，包含IVA（对齐显著视觉区域以模仿教师提取指令相关视觉信息的能力）和TPA（对齐token-to-token转移概率以捕捉教师的动态生成逻辑）。

Result: Align-TI相较Vanilla KD提升2.6%；蒸馏所得Align-TI-2B模型性能超越LLaVA-1.5-7B达7.0%，创SOTA。

Conclusion: Align-TI通过建模关键token交互，显著提升MLLM知识蒸馏效果，为高效部署多模态大模型提供了新范式。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate impressive cross-modal capabilities, yet their substantial size poses significant deployment challenges. Knowledge distillation (KD) is a promising solution for compressing these models, but existing methods primarily rely on static next-token alignment, neglecting the dynamic token interactions, which embed essential capabilities for multimodal understanding and generation. To this end, we introduce Align-TI, a novel KD framework designed from the perspective of Token Interactions. Our approach is motivated by the insight that MLLMs rely on two primary interactions: vision-instruction token interactions to extract relevant visual information, and intra-response token interactions for coherent generation. Accordingly, Align-TI introduces two components: IVA enables the student model to imitate the teacher's instruction-relevant visual information extract capability by aligning on salient visual regions. TPA captures the teacher's dynamic generative logic by aligning the sequential token-to-token transition probabilities. Extensive experiments demonstrate Align-TI's superiority. Notably, our approach achieves $2.6\%$ relative improvement over Vanilla KD, and our distilled Align-TI-2B even outperforms LLaVA-1.5-7B (a much larger MLLM) by $7.0\%$, establishing a new state-of-the-art distillation framework for training parameter-efficient MLLMs. Code is available at https://github.com/lchen1019/Align-TI.

</details>


### [33] [Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge](https://arxiv.org/abs/2510.04772)
*Max Kirchner,Hanna Hoffmann,Alexander C. Jenke,Oliver L. Saldanha,Kevin Pfeiffer,Weam Kanjo,Julia Alekseenko,Claas de Boer,Santhi Raj Kolamuri,Lorenzo Mazza,Nicolas Padoy,Sophia Bano,Annika Reinke,Lena Maier-Hein,Danail Stoyanov,Jakob N. Kather,Fiona R. Kolbinger,Sebastian Bodenstedt,Stefanie Speidel*

Main category: cs.CV

TL;DR: FedSurg挑战首次构建了面向外科视频分类的联邦学习基准，评估模型在未见临床中心的泛化能力与本地微调适应性，揭示了现有方法在泛化性、类别不平衡敏感性和超参调优方面的局限，并指出时空建模与上下文感知预处理是潜在突破口。


<details>
  <summary>Details</summary>
Motivation: 评估当前联邦学习方法在外科视频分类任务中对未见临床中心的泛化能力及本地微调适应性，同时支持不共享患者数据的协作建模。

Method: 基于多中心Appendix300视频数据集，组织参赛队伍采用ViViT等基础模型、线性探针、三元组损失度量学习及多种FL聚合算法（如FedAvg、FedMedian、FedSAM）完成炎症分期分类；评估涵盖泛化与适配两任务，指标包括F1-score和Expected Cost，并通过Bootstrap和统计检验评估排名鲁棒性。

Result: 泛化任务中跨中心性能有限；适配任务中所有队伍微调后均提升，但排名稳定性低；ViViT方案整体最优；发现泛化能力弱、对类别不平衡敏感、超参调优困难，而时空建模与上下文感知预处理表现突出。

Conclusion: FedSurg是首个外科视频分类联邦学习基准，揭示了本地个性化与全局鲁棒性间的权衡，强调架构选择、预处理与损失函数设计的重要性，为发展不平衡感知、自适应且鲁棒的临床外科AI联邦学习方法提供参考。

Abstract: Purpose: The FedSurg challenge was designed to benchmark the state of the art in federated learning for surgical video classification. Its goal was to assess how well current methods generalize to unseen clinical centers and adapt through local fine-tuning while enabling collaborative model development without sharing patient data. Methods: Participants developed strategies to classify inflammation stages in appendicitis using a preliminary version of the multi-center Appendix300 video dataset. The challenge evaluated two tasks: generalization to an unseen center and center-specific adaptation after fine-tuning. Submitted approaches included foundation models with linear probing, metric learning with triplet loss, and various FL aggregation schemes (FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and Expected Cost, with ranking robustness evaluated via bootstrapping and statistical testing. Results: In the generalization task, performance across centers was limited. In the adaptation task, all teams improved after fine-tuning, though ranking stability was low. The ViViT-based submission achieved the strongest overall performance. The challenge highlighted limitations in generalization, sensitivity to class imbalance, and difficulties in hyperparameter tuning in decentralized training, while spatiotemporal modeling and context-aware preprocessing emerged as promising strategies. Conclusion: The FedSurg Challenge establishes the first benchmark for evaluating FL strategies in surgical video classification. Findings highlight the trade-off between local personalization and global robustness, and underscore the importance of architecture choice, preprocessing, and loss design. This benchmarking offers a reference point for future development of imbalance-aware, adaptive, and robust FL methods in clinical surgical AI.

</details>


### [34] [OSI: One-step Inversion Excels in Extracting Diffusion Watermarks](https://arxiv.org/abs/2602.09494)
*Yuwei Chen,Zhenliang He,Jia Tang,Meina Kan,Shiguang Shan*

Main category: cs.CV

TL;DR: 本文提出了一种名为One-step Inversion（OSI）的单步 watermark 提取方法，用于高效、准确地提取 Gaussian Shading 类水印，相比传统多步扩散反演提速20倍、精度更高、载荷容量翻倍。


<details>
  <summary>Details</summary>
Motivation: 现有训练-free水印方法（如Gaussian Shading）虽生成质量高，但提取需多步扩散反演，计算开销大、耗时长。

Method: 将水印提取建模为可学习的符号分类问题，避免对初始噪声的精确回归；基于扩散模型主干初始化OSI模型，并在合成的噪声-图像对上以符号分类目标进行微调。

Result: OSI实现单步水印提取，速度提升20倍，提取精度更高，水印载荷容量翻倍；在多种调度器、扩散主干和密码方案下均表现鲁棒且通用。

Conclusion: OSI是一种高效、准确、通用的单步水印提取框架，显著优于传统多步反演方法，为扩散模型水印技术提供了实用化新路径。

Abstract: Watermarking is an important mechanism for provenance and copyright protection of diffusion-generated images. Training-free methods, exemplified by Gaussian Shading, embed watermarks into the initial noise of diffusion models with negligible impact on the quality of generated images. However, extracting this type of watermark typically requires multi-step diffusion inversion to obtain precise initial noise, which is computationally expensive and time-consuming. To address this issue, we propose One-step Inversion (OSI), a significantly faster and more accurate method for extracting Gaussian Shading style watermarks. OSI reformulates watermark extraction as a learnable sign classification problem, which eliminates the need for precise regression of the initial noise. Then, we initialize the OSI model from the diffusion backbone and finetune it on synthesized noise-image pairs with a sign classification objective. In this manner, the OSI model is able to accomplish the watermark extraction efficiently in only one step. Our OSI substantially outperforms the multi-step diffusion inversion method: it is 20x faster, achieves higher extraction accuracy, and doubles the watermark payload capacity. Extensive experiments across diverse schedulers, diffusion backbones, and cryptographic schemes consistently show improvements, demonstrating the generality of our OSI framework.

</details>


### [35] [Equilibrium contrastive learning for imbalanced image classification](https://arxiv.org/abs/2602.09506)
*Sumin Roh,Harim Kim,Ho Yun Lee,Il Yong Chun*

Main category: cs.CV

TL;DR: 本文提出了一种名为Equilibrium Contrastive Learning (ECL)的监督对比学习框架，旨在解决数据不平衡场景下对比学习中类中心与分类器对齐不足、原型贡献不均衡的问题，通过实现特征、类中心与分类器之间的几何平衡，提升长尾分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有监督对比学习方法在不平衡数据上存在两类问题：1）未对齐类中心（均值/原型）与分类器权重，影响泛化；2）原型仅作为单一样本，其贡献受批次中各类样本数量影响，导致类别间贡献失衡。

Method: 提出ECL框架，包含两个核心组件：1）表示几何均衡模块——在保持正则单形体结构（类内坍缩、类间均匀分布）的同时，平衡类平均特征与类原型的贡献；2）分类器-类中心几何均衡模块——显式对齐分类器权重与类原型。

Result: 在CIFAR-10-LT、ImageNet-LT、ISIC 2019和自建LCCT四个长尾/不平衡数据集上，ECL显著优于现有SOTA监督对比学习方法。

Conclusion: ECL通过协同优化特征空间几何结构与分类器对齐关系，有效缓解了数据不平衡带来的表示偏置与决策偏置，为不平衡学习提供了新的几何视角与实用框架。

Abstract: Contrastive learning (CL) is a predominant technique in image classification, but they showed limited performance with an imbalanced dataset. Recently, several supervised CL methods have been proposed to promote an ideal regular simplex geometric configuration in the representation space-characterized by intra-class feature collapse and uniform inter-class mean spacing, especially for imbalanced datasets. In particular, existing prototype-based methods include class prototypes, as additional samples to consider all classes. However, the existing CL methods suffer from two limitations. First, they do not consider the alignment between the class means/prototypes and classifiers, which could lead to poor generalization. Second, existing prototype-based methods treat prototypes as only one additional sample per class, making their influence depend on the number of class instances in a batch and causing unbalanced contributions across classes. To address these limitations, we propose Equilibrium Contrastive Learning (ECL), a supervised CL framework designed to promote geometric equilibrium, where class features, means, and classifiers are harmoniously balanced under data imbalance. The proposed ECL framework uses two main components. First, ECL promotes the representation geometric equilibrium (i.e., a regular simplex geometry characterized by collapsed class samples and uniformly distributed class means), while balancing the contributions of class-average features and class prototypes. Second, ECL establishes a classifier-class center geometric equilibrium by aligning classifier weights and class prototypes. We ran experiments with three long-tailed datasets, the CIFAR-10(0)-LT, ImageNet-LT, and the two imbalanced medical datasets, the ISIC 2019 and our constructed LCCT dataset. Results show that ECL outperforms existing SOTA supervised CL methods designed for imbalanced classification.

</details>


### [36] [Robust Depth Super-Resolution via Adaptive Diffusion Sampling](https://arxiv.org/abs/2602.09510)
*Kun Wang,Yun Zhu,Pan Zhou,Na Zhao*

Main category: cs.CV

TL;DR: AdaDS is a depth super-resolution framework using diffusion models and Gaussian smoothing properties to robustly recover high-resolution depth maps from degraded low-resolution inputs, with adaptive noise injection and strong zero-shot generalization.


<details>
  <summary>Details</summary>
Motivation: Conventional depth super-resolution methods suffer from artifacts under severe or unknown degradation; AdaDS addresses this by leveraging the contraction property of Gaussian smoothing to ensure robust recovery.

Method: AdaDS uses a pre-trained diffusion model and adapts the reverse diffusion process by estimating refinement uncertainty to select an optimal starting timestep and inject tailored noise, positioning intermediate samples in high-probability regions of the target posterior.

Result: AdaDS achieves superior zero-shot generalization and resilience to diverse degradation patterns on both real-world and synthetic benchmarks compared to state-of-the-art methods.

Conclusion: AdaDS provides a robust, generalizable solution for depth super-resolution by integrating diffusion priors with adaptive uncertainty-aware denoising, outperforming existing methods under arbitrary degradation.

Abstract: We propose AdaDS, a generalizable framework for depth super-resolution that robustly recovers high-resolution depth maps from arbitrarily degraded low-resolution inputs. Unlike conventional approaches that directly regress depth values and often exhibit artifacts under severe or unknown degradation, AdaDS capitalizes on the contraction property of Gaussian smoothing: as noise accumulates in the forward process, distributional discrepancies between degraded inputs and their pristine high-quality counterparts diminish, ultimately converging to isotropic Gaussian prior. Leveraging this, AdaDS adaptively selects a starting timestep in the reverse diffusion trajectory based on estimated refinement uncertainty, and subsequently injects tailored noise to position the intermediate sample within the high-probability region of the target posterior distribution. This strategy ensures inherent robustness, enabling generative prior of a pre-trained diffusion model to dominate recovery even when upstream estimations are imperfect. Extensive experiments on real-world and synthetic benchmarks demonstrate AdaDS's superior zero-shot generalization and resilience to diverse degradation patterns compared to state-of-the-art methods.

</details>


### [37] [Energy-Efficient Fast Object Detection on Edge Devices for IoT Systems](https://arxiv.org/abs/2602.09515)
*Mas Nurul Achmadiah,Afaroj Ahamad,Chi-Chia Sun,Wen-Kai Kuo*

Main category: cs.CV

TL;DR: 本文提出了一种基于帧差法的轻量级AI目标检测方法，适用于IoT边缘设备，相比端到端方法在准确率、能效和延迟方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 物联网系统对能效和实时性要求高，传统端到端目标检测方法在快速移动物体检测中存在准确率低、延迟高、能耗大的问题，亟需更高效的轻量级方案。

Method: 采用帧差法（frame difference method）作为预处理手段，结合MobileNet、YOLOX等人工神经网络与Transformer模型，在AMD Alveo U50、Jetson Orin Nano和Hailo-8T等边缘设备上实现轻量级目标检测。

Result: 相比端到端方法，平均准确率提升28.314%，平均能效提升3.6倍，平均延迟降低39.305%；MobileNet表现最优（高精度、低延迟、高能效），YOLOX精度最低；对快速移动目标（如火车、飞机）检测精度相对较低。

Conclusion: 帧差法配合轻量模型（如MobileNet）是面向IoT边缘设备的快速移动目标检测的有效方案，兼顾准确性、实时性与能效，优于传统端到端方法。

Abstract: This paper presents an Internet of Things (IoT) application that utilizes an AI classifier for fast-object detection using the frame difference method. This method, with its shorter duration, is the most efficient and suitable for fast-object detection in IoT systems, which require energy-efficient applications compared to end-to-end methods. We have implemented this technique on three edge devices: AMD AlveoT M U50, Jetson Orin Nano, and Hailo-8T M AI Accelerator, and four models with artificial neural networks and transformer models. We examined various classes, including birds, cars, trains, and airplanes. Using the frame difference method, the MobileNet model consistently has high accuracy, low latency, and is highly energy-efficient. YOLOX consistently shows the lowest accuracy, lowest latency, and lowest efficiency. The experimental results show that the proposed algorithm has improved the average accuracy gain by 28.314%, the average efficiency gain by 3.6 times, and the average latency reduction by 39.305% compared to the end-to-end method. Of all these classes, the faster objects are trains and airplanes. Experiments show that the accuracy percentage for trains and airplanes is lower than other categories. So, in tasks that require fast detection and accurate results, end-to-end methods can be a disaster because they cannot handle fast object detection. To improve computational efficiency, we designed our proposed method as a lightweight detection algorithm. It is well suited for applications in IoT systems, especially those that require fast-moving object detection and higher accuracy.

</details>


### [38] [A Universal Action Space for General Behavior Analysis](https://arxiv.org/abs/2602.09518)
*Hung-Shuo Chang,Yue-Cheng Yang,Yu-Hsi Chen,Wei-Hsin Chen,Chien-Yao Wang,James C. Liao,Chien-Chang Chen,Hen-Hsen Huang,Hong-Yuan Mark Liao*

Main category: cs.CV

TL;DR: 本文提出了一种基于大规模人类动作数据集构建通用动作空间（UAS）的方法，并将其应用于哺乳动物和黑猩猩行为分析，推动行为识别从低层特征向高层语义表示转变。


<details>
  <summary>Details</summary>
Motivation: 传统行为分析依赖手工设计的低层特征，鲁棒性和泛化性差；ImageNet推动了高层语义表征的发展，启发本文构建跨物种通用动作空间。

Method: 利用现有标注的人类动作数据集构建大规模通用动作空间（UAS），并将其迁移应用于哺乳动物与黑猩猩行为数据的分析与分类。

Result: 成功构建了可泛化至非人类灵长类及哺乳动物行为分析的通用动作空间，并开源了相关代码。

Conclusion: 高层语义动作表征（UAS）可有效跨越物种边界，提升动物行为分析的系统性与可扩展性，为跨物种行为理解提供新范式。

Abstract: Analyzing animal and human behavior has long been a challenging task in computer vision. Early approaches from the 1970s to the 1990s relied on hand-crafted edge detection, segmentation, and low-level features such as color, shape, and texture to locate objects and infer their identities-an inherently ill-posed problem. Behavior analysis in this era typically proceeded by tracking identified objects over time and modeling their trajectories using sparse feature points, which further limited robustness and generalization. A major shift occurred with the introduction of ImageNet by Deng and Li in 2010, which enabled large-scale visual recognition through deep neural networks and effectively served as a comprehensive visual dictionary. This development allowed object recognition to move beyond complex low-level processing toward learned high-level representations. In this work, we follow this paradigm to build a large-scale Universal Action Space (UAS) using existing labeled human-action datasets. We then use this UAS as the foundation for analyzing and categorizing mammalian and chimpanzee behavior datasets. The source code is released on GitHub at https://github.com/franktpmvu/Universal-Action-Space.

</details>


### [39] [Attention to details, logits to truth: visual-aware attention and logits enhancement to mitigate hallucinations in LVLMs](https://arxiv.org/abs/2602.09521)
*Jingyi Wang,Fei Li,Rujie Liu*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的注意力干预算法，通过视觉-文本跨模态相似性识别并增强任务相关视觉token的注意力，同时在束搜索解码中注入视觉注意力值，从而有效缓解大视觉语言模型（LVLMs）的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型（LVLMs）存在视觉注意力不足的问题，导致生成内容出现幻觉；已有方法通过放大所有视觉token的注意力来缓解，但会同时增强无关token的注意力，效果受限。

Method: 提出一种无需训练的注意力干预算法：1）提取视觉-文本交叉注意力子矩阵构建重加权矩阵，以增强高视觉-文本相似性的任务相关token注意力；2）在束搜索解码中注入视觉注意力值，优先选择视觉注意力更高的生成路径。

Result: 在多个主流LVLMs上显著降低了幻觉率，同时保持了生成内容的准确性与连贯性。

Conclusion: 基于视觉-文本相似性的任务相关token注意力增强与视觉注意力引导的束搜索解码，是提升LVLMs视觉感知能力、抑制幻觉的有效且通用的无训练方案。

Abstract: Existing Large Vision-Language Models (LVLMs) exhibit insufficient visual attention, leading to hallucinations. To alleviate this problem, some previous studies adjust and amplify visual attention. These methods present a limitation that boosting attention for all visual tokens inevitably increases attention to task irrelevant tokens. To tackle this challenge, we propose a training free attentional intervention algorithm to enhance the attention of task-relevant tokens based on the argument that task-relevant tokens generally demonstrate high visual-textual similarities. Specifically, the vision-text cross-attention submatrices, which represent visual-textual correlations, are extracted to construct the reweighting matrices to reallocate attention. Besides, to enhance the contribution of visual tokens, we inject visual attention values into the beam search decoding to identify solutions with higher visual attention. Extensive experiments demonstrate that this method significantly reduces hallucinations across mainstream LVLMs, while preserving the accuracy and coherence of generated content.

</details>


### [40] [Singpath-VL Technical Report](https://arxiv.org/abs/2602.09523)
*Zhen Qiu,Kaiwen Xiao,Zhengwei Lu,Xiangyu Liu,Lei Zhao,Hao Zhang*

Main category: cs.CV

TL;DR: 本文提出了Singpath-VL，一种专用于宫颈细胞学的视觉-语言大模型，通过构建百万级合成图像-描述数据集并微调Qwen3-VL-4B模型，在细粒度形态感知与细胞级诊断分类任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言大模型在细胞病理学（尤其是宫颈细胞学）中应用不足，主因是缺乏大规模高质量标注数据集。

Method: 提出三阶段合成数据构建流程：利用多个通用MLLM作为弱标注器，结合共识融合与专家知识注入生成高保真细胞形态描述；基于该百万级合成数据，采用多阶段策略微调Qwen3-VL-4B模型。

Result: Singpath-VL在细粒度形态感知和细胞级诊断分类任务上展现出优越性能，并将开源部分合成数据集与基准测试。

Conclusion: Singpath-VL填补了AI辅助宫颈细胞学分析的空白，验证了高质量合成数据驱动的领域专用MLLM构建范式有效性。

Abstract: We present Singpath-VL, a vision-language large model, to fill the vacancy of AI assistant in cervical cytology. Recent advances in multi-modal large language models (MLLMs) have significantly propelled the field of computational pathology. However, their application in cytopathology, particularly cervical cytology, remains underexplored, primarily due to the scarcity of large-scale, high-quality annotated datasets. To bridge this gap, we first develop a novel three-stage pipeline to synthesize a million-scale image-description dataset. The pipeline leverages multiple general-purpose MLLMs as weak annotators, refines their outputs through consensus fusion and expert knowledge injection, and produces high-fidelity descriptions of cell morphology. Using this dataset, we then fine-tune the Qwen3-VL-4B model via a multi-stage strategy to create a specialized cytopathology MLLM. The resulting model, named Singpath-VL, demonstrates superior performance in fine-grained morphological perception and cell-level diagnostic classification. To advance the field, we will open-source a portion of the synthetic dataset and benchmark.

</details>


### [41] [HLGFA: High-Low Resolution Guided Feature Alignment for Unsupervised Anomaly Detection](https://arxiv.org/abs/2602.09524)
*Han Zhou,Yuxuan Gao,Yinchao Du,Xuezhe Zheng*

Main category: cs.CV

TL;DR: 本文提出HLGFA框架，通过建模正常样本的高、低分辨率特征一致性来学习正常性，避免像素级重建，在工业异常检测中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测中缺陷样本稀缺，需可靠检测；传统方法依赖像素级重建，易受噪声干扰且难以捕捉结构一致性。

Method: 提出高-低分辨率引导的特征对齐框架HLGFA：使用共享冻结骨干网络提取多级特征；将高分辨率表征分解为结构与细节先验，通过条件调制和门控残差校正引导低分辨率特征优化；引入噪声感知数据增强抑制工业环境中的干扰响应。

Result: 在MVTec AD数据集上达到97.9%像素级AUROC和97.5%图像级AUROC，优于主流重建式和特征式方法。

Conclusion: 跨分辨率特征一致性建模是学习工业图像正常性的有效范式，HLGFA在精度与鲁棒性上均展现出显著优势。

Abstract: Unsupervised industrial anomaly detection (UAD) is essential for modern manufacturing inspection, where defect samples are scarce and reliable detection is required. In this paper, we propose HLGFA, a high-low resolution guided feature alignment framework that learns normality by modeling cross-resolution feature consistency between high-resolution and low-resolution representations of normal samples, instead of relying on pixel-level reconstruction. Dual-resolution inputs are processed by a shared frozen backbone to extract multi-level features, and high-resolution representations are decomposed into structure and detail priors to guide the refinement of low-resolution features through conditional modulation and gated residual correction. During inference, anomalies are naturally identified as regions where cross-resolution alignment breaks down. In addition, a noise-aware data augmentation strategy is introduced to suppress nuisance-induced responses commonly observed in industrial environments. Extensive experiments on standard benchmarks demonstrate the effectiveness of HLGFA, achieving 97.9% pixel-level AUROC and 97.5% image-level AUROC on the MVTec AD dataset, outperforming representative reconstruction-based and feature-based methods.

</details>


### [42] [SchröMind: Mitigating Hallucinations in Multimodal Large Language Models via Solving the Schrödinger Bridge Problem](https://arxiv.org/abs/2602.09528)
*Ziqiang Shi,Rujie Liu,Shanshan Yu,Satoshi Munakata,Koichi Shirahata*

Main category: cs.CV

TL;DR: 本文提出SchröMind框架，通过求解薛定谔桥问题来减少多模态大语言模型（MLLMs）在医疗等高风险领域中的幻觉现象，实现幻觉与真实激活之间的低代价词元级映射，在保持原模型能力的同时显著提升准确性。


<details>
  <summary>Details</summary>
Motivation: MLLMs在医疗等高风险领域应用受限，主要因生成文本与视觉输入矛盾的幻觉问题。

Method: 提出SchröMind框架，利用薛定谔桥问题建模并学习幻觉状态与真实状态间的轻量级词元级映射，最小化传输代价。

Result: 在POPE和MME基准上达到SOTA性能，且计算开销极小。

Conclusion: SchröMind能有效缓解MLLMs幻觉，兼顾准确性与效率，为高风险场景部署提供新思路。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have achieved significant success across various domains. However, their use in high-stakes fields like healthcare remains limited due to persistent hallucinations, where generated text contradicts or ignores visual input. We contend that MLLMs can comprehend images but struggle to produce accurate token sequences. Minor perturbations can shift attention from truthful to untruthful states, and the autoregressive nature of text generation often prevents error correction. To address this, we propose SchröMind-a novel framework reducing hallucinations via solving the Schrödinger bridge problem. It establishes a token-level mapping between hallucinatory and truthful activations with minimal transport cost through lightweight training, while preserving the model's original capabilities. Extensive experiments on the POPE and MME benchmarks demonstrate the superiority of Schrödinger, which achieves state-of-the-art performance while introducing only minimal computational overhead.

</details>


### [43] [SCA-Net: Spatial-Contextual Aggregation Network for Enhanced Small Building and Road Change Detection](https://arxiv.org/abs/2602.09529)
*Emad Gholibeigi,Abbas Koochari,Azadeh ZamaniFar*

Main category: cs.CV

TL;DR: 本文提出SCA-Net，一种基于Change-Agent框架的改进模型，用于双时相遥感影像中的建筑物与道路变化检测，通过多尺度差异分析、自适应多尺度处理、多级注意力机制及动态复合损失函数等创新，在精度与效率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在遥感影像变化检测中存在对小目标敏感度低、计算成本高等问题，亟需更高效精准的解决方案。

Method: 提出SCA-Net模型，包含差异金字塔模块（DPB）、自适应多尺度处理模块（融合形状感知与高分辨率增强）、PPM与CSAGate多级注意力机制，并引入动态复合损失函数和四阶段训练策略。

Result: 在LEVIR-CD和LEVIR-MCI数据集上超越Change-Agent及其他SOTA方法：LEVIR-MCI上mIoU提升2.64%，小建筑物IoU提升57.9%，训练时间减少61%。

Conclusion: SCA-Net为实际变化检测应用提供了高效、准确且鲁棒的解决方案。

Abstract: Automated change detection in remote sensing imagery is critical for urban management, environmental monitoring, and disaster assessment. While deep learning models have advanced this field, they often struggle with challenges like low sensitivity to small objects and high computational costs. This paper presents SCA-Net, an enhanced architecture built upon the Change-Agent framework for precise building and road change detection in bi-temporal images. Our model incorporates several key innovations: a novel Difference Pyramid Block for multi-scale change analysis, an Adaptive Multi-scale Processing module combining shape-aware and high-resolution enhancement blocks, and multi-level attention mechanisms (PPM and CSAGate) for joint contextual and detail processing. Furthermore, a dynamic composite loss function and a four-phase training strategy are introduced to stabilize training and accelerate convergence. Comprehensive evaluations on the LEVIR-CD and LEVIR-MCI datasets demonstrate SCA-Net's superior performance over Change-Agent and other state-of-the-art methods. Our approach achieves a significant 2.64% improvement in mean Intersection over Union (mIoU) on LEVIR-MCI and a remarkable 57.9% increase in IoU for small buildings, while reducing the training time by 61%. This work provides an efficient, accurate, and robust solution for practical change detection applications.

</details>


### [44] [DR.Experts: Differential Refinement of Distortion-Aware Experts for Blind Image Quality Assessment](https://arxiv.org/abs/2602.09531)
*Bohan Fu,Guanyi Qin,Fazhan Zhang,Zihao Huang,Mingxuan Li,Runze Hu*

Main category: cs.CV

TL;DR: 本文提出DR.Experts，一种基于失真先验驱动的盲图像质量评估（BIQA）框架，通过引入退化感知的视觉语言模型和动态失真加权模块，显式建模失真特征并按感知重要性加权，显著提升与人类主观评价的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有BIQA模型难以有效捕捉细微失真线索，主因是缺乏可靠的失真先验，导致对失真不敏感、与人类主观判断不一致。

Method: 提出DR.Experts框架：1）利用退化感知的视觉语言模型获取失真特异性先验；2）通过失真-显著性差异模块分离并增强失真表征；3）采用动态失真加权模块（MoE风格）融合失真先验、语义与桥接表征，并按感知影响加权。

Result: 在五个主流BIQA基准上显著优于现有方法，展现出更强的泛化能力和数据效率。

Conclusion: 显式建模并加权失真先验可有效弥合模型预测与人类感知之间的差距，DR.Experts为BIQA提供了新范式。

Abstract: Blind Image Quality Assessment, aiming to replicate human perception of visual quality without reference, plays a key role in vision tasks, yet existing models often fail to effectively capture subtle distortion cues, leading to a misalignment with human subjective judgments. We identify that the root cause of this limitation lies in the lack of reliable distortion priors, as methods typically learn shallow relationships between unified image features and quality scores, resulting in their insensitive nature to distortions and thus limiting their performance. To address this, we introduce DR.Experts, a novel prior-driven BIQA framework designed to explicitly incorporate distortion priors, enabling a reliable quality assessment. DR.Experts begins by leveraging a degradation-aware vision-language model to obtain distortion-specific priors, which are further refined and enhanced by the proposed Distortion-Saliency Differential Module through distinguishing them from semantic attentions, thereby ensuring the genuine representations of distortions. The refined priors, along with semantics and bridging representation, are then fused by a proposed mixture-of-experts style module named the Dynamic Distortion Weighting Module. This mechanism weights each distortion-specific feature as per its perceptual impact, ensuring that the final quality prediction aligns with human perception. Extensive experiments conducted on five challenging BIQA benchmarks demonstrate the superiority of DR.Experts over current methods and showcase its excellence in terms of generalization and data efficiency.

</details>


### [45] [RAD: Retrieval-Augmented Monocular Metric Depth Estimation for Underrepresented Classes](https://arxiv.org/abs/2602.09532)
*Michael Baltaxe,Dan Levi,Sagie Benaim*

Main category: cs.CV

TL;DR: 本文提出RAD框架，通过检索增强的方式利用RGB-D上下文样本作为几何代理，提升单目度量深度估计在罕见类别上的精度。


<details>
  <summary>Details</summary>
Motivation: 单目度量深度估计（MMDE）在复杂场景中对罕见类别的准确估计仍具挑战性。

Method: 提出RAD检索增强框架：首先用不确定性感知机制定位低置信区域并检索语义相似的RGB-D上下文；再通过双流网络处理输入与上下文，并用匹配的交叉注意力模块仅在可靠点对应处传递几何信息。

Result: 在NYU Depth v2、KITTI和Cityscapes上显著优于SOTA方法，在罕见类别上相对绝对误差分别降低29.2%、13.3%和7.2%，同时保持主流基准上的竞争力。

Conclusion: RAD有效缓解了单目深度估计中罕见类别性能下降问题，验证了检索增强几何先验的有效性。

Abstract: Monocular Metric Depth Estimation (MMDE) is essential for physically intelligent systems, yet accurate depth estimation for underrepresented classes in complex scenes remains a persistent challenge. To address this, we propose RAD, a retrieval-augmented framework that approximates the benefits of multi-view stereo by utilizing retrieved neighbors as structural geometric proxies. Our method first employs an uncertainty-aware retrieval mechanism to identify low-confidence regions in the input and retrieve RGB-D context samples containing semantically similar content. We then process both the input and retrieved context via a dual-stream network and fuse them using a matched cross-attention module, which transfers geometric information only at reliable point correspondences. Evaluations on NYU Depth v2, KITTI, and Cityscapes demonstrate that RAD significantly outperforms state-of-the-art baselines on underrepresented classes, reducing relative absolute error by 29.2% on NYU Depth v2, 13.3% on KITTI, and 7.2% on Cityscapes, while maintaining competitive performance on standard in-domain benchmarks.

</details>


### [46] [AUHead: Realistic Emotional Talking Head Generation via Action Units Control](https://arxiv.org/abs/2602.09534)
*Jiayi Lyu,Leigang Qu,Wenjing Zhang,Hanyu Jiang,Kai Liu,Zhenglin Zhou,Xiaobo Xia,Jian Xue,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出AUHead，一种两阶段方法，通过解耦音频中的精细情感动作单元（AUs）并驱动可控扩散模型，生成具有高情感真实感、精准唇动同步和视觉一致性的说话人视频。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以实现对说话人视频中细微情感表达的精细控制，缺乏细粒度的情感调控能力。

Method: 第一阶段利用大音频语言模型（ALM），结合时空AU标记化与“情感→AU”链式思维机制，从语音中解耦出动作单元；第二阶段设计AU驱动的可控扩散模型，将AU序列映射为结构化2D面部表示，并在交叉注意力模块中建模AU-视觉交互，引入AU解耦引导策略以平衡AU保真度与生成质量。

Result: 在基准数据集上，该方法在情感真实感、唇音同步精度和视觉连贯性方面显著优于现有技术。

Conclusion: AUHead实现了音频到精细情感动作单元再到高质量说话人视频的可控生成，为虚拟化身、影视制作等应用提供了新范式。

Abstract: Realistic talking-head video generation is critical for virtual avatars, film production, and interactive systems. Current methods struggle with nuanced emotional expressions due to the lack of fine-grained emotion control. To address this issue, we introduce a novel two-stage method (AUHead) to disentangle fine-grained emotion control, i.e. , Action Units (AUs), from audio and achieve controllable generation. In the first stage, we explore the AU generation abilities of large audio-language models (ALMs), by spatial-temporal AU tokenization and an "emotion-then-AU" chain-of-thought mechanism. It aims to disentangle AUs from raw speech, effectively capturing subtle emotional cues. In the second stage, we propose an AU-driven controllable diffusion model that synthesizes realistic talking-head videos conditioned on AU sequences. Specifically, we first map the AU sequences into the structured 2D facial representation to enhance spatial fidelity, and then model the AU-vision interaction within cross-attention modules. To achieve flexible AU-quality trade-off control, we introduce an AU disentanglement guidance strategy during inference, further refining the emotional expressiveness and identity consistency of the generated videos. Results on benchmark datasets demonstrate that our approach achieves competitive performance in emotional realism, accurate lip synchronization, and visual coherence, significantly surpassing existing techniques. Our implementation is available at https://github.com/laura990501/AUHead_ICLR

</details>


### [47] [Scalpel: Fine-Grained Alignment of Attention Activation Manifolds via Mixture Gaussian Bridges to Mitigate Multimodal Hallucination](https://arxiv.org/abs/2602.09541)
*Ziqiang Shi,Rujie Liu,Shanshan Yu,Satoshi Munakata,Koichi Shirahata*

Main category: cs.CV

TL;DR: 本文提出Scalpel方法，通过在推理过程中动态调整Transformer各层注意力头的激活分布，将注意力引导至更可信的视觉区域，从而有效缓解大视觉语言模型（LVLMs）中的幻觉问题。该方法基于高斯混合模型与熵最优传输理论，无需额外训练或计算开销，具有模型与数据无关性。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型（LVLMs）因大语言模型强先验及跨模态注意力错位，常产生与视觉内容不一致的幻觉输出，亟需一种高效、通用的推理时缓解方法。

Method: Scalpel在推理阶段预测每个Transformer注意力头的可信注意力方向，并利用高斯混合模型建模信任与幻觉状态下的多峰注意力分布，再通过熵最优传输（等价于Schrödinger桥问题）精确映射高斯成分；根据成分归属与映射关系动态调节干预强度与方向。

Result: 在多个数据集与基准上显著降低幻觉率，性能超越现有方法，达到SOTA；且完全无需额外训练、微调或计算资源，仅需单次解码。

Conclusion: Scalpel是一种轻量、通用、即插即用的推理时幻觉缓解框架，为提升LVLMs视觉-语言对齐提供了新范式。

Abstract: Rapid progress in large vision-language models (LVLMs) has achieved unprecedented performance in vision-language tasks. However, due to the strong prior of large language models (LLMs) and misaligned attention across modalities, LVLMs often generate outputs inconsistent with visual content - termed hallucination. To address this, we propose \textbf{Scalpel}, a method that reduces hallucination by refining attention activation distributions toward more credible regions. Scalpel predicts trusted attention directions for each head in Transformer layers during inference and adjusts activations accordingly. It employs a Gaussian mixture model to capture multi-peak distributions of attention in trust and hallucination manifolds, and uses entropic optimal transport (equivalent to Schrödinger bridge problem) to map Gaussian components precisely. During mitigation, Scalpel dynamically adjusts intervention strength and direction based on component membership and mapping relationships between hallucination and trust activations. Extensive experiments across multiple datasets and benchmarks demonstrate that Scalpel effectively mitigates hallucinations, outperforming previous methods and achieving state-of-the-art performance. Moreover, Scalpel is model- and data-agnostic, requiring no additional computation, only a single decoding step.

</details>


### [48] [Delving into Spectral Clustering with Vision-Language Representations](https://arxiv.org/abs/2602.09586)
*Bo Peng,Yuanwei Hu,Bo Liu,Ling Chen,Jie Lu,Zhen Fang*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经正切核的多模态谱聚类方法（NTK-SC），利用预训练视觉-语言模型中的跨模态对齐，通过锚定正向名词构建图像间亲和度，结合正则化亲和扩散机制，在16个基准数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统谱聚类主要依赖单模态信息，未能充分利用多模态表征中的丰富信息；受视觉-语言预训练成功启发，亟需将谱聚类拓展至多模态场景。

Method: 提出神经正切核谱聚类（NTK-SC）：利用预训练视觉-语言模型，以语义上贴近目标图像的正向名词为锚点，构建融合视觉相似性与语义重叠的图像亲和度；并引入正则化亲和扩散机制，自适应融合不同提示词生成的亲和矩阵。

Result: 在16个涵盖经典、大规模、细粒度及域偏移的数据集上，该方法持续大幅超越当前最优方法。

Conclusion: 将多模态先验（特别是视觉-语言对齐）引入谱聚类可显著提升聚类性能，所提NTK-SC框架为无监督学习提供了新范式。

Abstract: Spectral clustering is known as a powerful technique in unsupervised data analysis. The vast majority of approaches to spectral clustering are driven by a single modality, leaving the rich information in multi-modal representations untapped. Inspired by the recent success of vision-language pre-training, this paper enriches the landscape of spectral clustering from a single-modal to a multi-modal regime. Particularly, we propose Neural Tangent Kernel Spectral Clustering that leverages cross-modal alignment in pre-trained vision-language models. By anchoring the neural tangent kernel with positive nouns, i.e., those semantically close to the images of interest, we arrive at formulating the affinity between images as a coupling of their visual proximity and semantic overlap. We show that this formulation amplifies within-cluster connections while suppressing spurious ones across clusters, hence encouraging block-diagonal structures. In addition, we present a regularized affinity diffusion mechanism that adaptively ensembles affinity matrices induced by different prompts. Extensive experiments on \textbf{16} benchmarks -- including classical, large-scale, fine-grained and domain-shifted datasets -- manifest that our method consistently outperforms the state-of-the-art by a large margin.

</details>


### [49] [MieDB-100k: A Comprehensive Dataset for Medical Image Editing](https://arxiv.org/abs/2602.09587)
*Yongfan Lai,Wen Qian,Bo Liu,Hongyan Li,Hao Luo,Fan Wang,Bohan Zhuang,Shenda Hong*

Main category: cs.CV

TL;DR: 本文提出了MieDB-100k，一个大规模、高质量、多样化的文本引导医学图像编辑数据集，旨在解决现有医学图像编辑数据集多样性不足、忽视医学理解及质量与规模难以兼顾的问题。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像编辑数据集存在多样性有限、忽视医学图像理解、质量与可扩展性难以平衡等问题，制约了多模态生成模型在医学图像编辑中的适配。

Method: 构建了MieDB-100k数据集，将编辑任务按感知、修改和变换三类划分；采用模态专用专家模型与基于规则的数据合成方法进行数据构建，并辅以严格的人工审查确保临床保真度。

Result: 在MieDB-100k上训练的模型在多项指标上持续优于开源及商用模型，并展现出强泛化能力。

Conclusion: MieDB-100k有望成为推动专业医学图像编辑未来发展的基石数据集。

Abstract: The scarcity of high-quality data remains a primary bottleneck in adapting multimodal generative models for medical image editing. Existing medical image editing datasets often suffer from limited diversity, neglect of medical image understanding and inability to balance quality with scalability. To address these gaps, we propose MieDB-100k, a large-scale, high-quality and diverse dataset for text-guided medical image editing. It categorizes editing tasks into perspectives of Perception, Modification and Transformation, considering both understanding and generation abilities. We construct MieDB-100k via a data curation pipeline leveraging both modality-specific expert models and rule-based data synthetic methods, followed by rigorous manual inspection to ensure clinical fidelity. Extensive experiments demonstrate that model trained with MieDB-100k consistently outperform both open-source and proprietary models while exhibiting strong generalization ability. We anticipate that this dataset will serve as a cornerstone for future advancements in specialized medical image editing.

</details>


### [50] [Hand2World: Autoregressive Egocentric Interaction Generation via Free-Space Hand Gestures](https://arxiv.org/abs/2602.09600)
*Yuxi Wang,Wenqi Ouyang,Tianyi Wei,Yi Dong,Zhiqi Shen,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出Hand2World框架，用于从单张场景图像生成以自我为中心的手部交互视频，支持自由空间手势输入、几何一致性和长时序合成。


<details>
  <summary>Details</summary>
Motivation: 解决增强现实和具身AI中，基于单图的自我中心交互生成所面临的分布偏移、单目视角下手/相机运动模糊、以及任意长度视频生成等核心挑战。

Method: 提出统一的自回归框架Hand2World：1）采用投影3D手部网格实现遮挡无关的手部条件控制；2）引入逐像素Plücker射线嵌入显式编码相机几何，解耦手部与相机运动；3）构建全自动单目标注流程，并将双向扩散模型蒸馏为因果生成器。

Result: 在三个自我中心交互基准上显著提升感知质量与3D一致性，支持相机控制与长时序交互生成。

Conclusion: Hand2World有效解决了单图驱动的自我中心交互视频生成中的关键难题，为低延迟、几何一致、稳定持久的视觉生成提供了新范式。

Abstract: Egocentric interactive world models are essential for augmented reality and embodied AI, where visual generation must respond to user input with low latency, geometric consistency, and long-term stability. We study egocentric interaction generation from a single scene image under free-space hand gestures, aiming to synthesize photorealistic videos in which hands enter the scene, interact with objects, and induce plausible world dynamics under head motion. This setting introduces fundamental challenges, including distribution shift between free-space gestures and contact-heavy training data, ambiguity between hand motion and camera motion in monocular views, and the need for arbitrary-length video generation. We present Hand2World, a unified autoregressive framework that addresses these challenges through occlusion-invariant hand conditioning based on projected 3D hand meshes, allowing visibility and occlusion to be inferred from scene context rather than encoded in the control signal. To stabilize egocentric viewpoint changes, we inject explicit camera geometry via per-pixel Plücker-ray embeddings, disentangling camera motion from hand motion and preventing background drift. We further develop a fully automated monocular annotation pipeline and distill a bidirectional diffusion model into a causal generator, enabling arbitrary-length synthesis. Experiments on three egocentric interaction benchmarks show substantial improvements in perceptual quality and 3D consistency while supporting camera control and long-horizon interactive generation.

</details>


### [51] [LiDAR-based 3D Change Detection at City Scale](https://arxiv.org/abs/2510.21112)
*Hezam Albagami,Haitian Wang,Xinyu Wang,Muhammad Ibrahim,Zainy M. Malakan,Abdullah M. Alqamdi,Mohammed H. Alghamdi,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文提出了一种面向对象、具备不确定性感知能力的城市级LiDAR变化检测方法，通过多分辨率NDT与点面ICP配准、高程归一化、基于协方差与表面粗糙度的逐点检测置信度建模，并融合语义/实例分割与类别约束二分匹配，显著提升了精度。


<details>
  <summary>Details</summary>
Motivation: 传统DSM/图像差分易受垂直偏差和视角不一致影响；原始点云/体素模型内存开销大、依赖完美配准且对细长结构鲁棒性差。亟需一种高效、鲁棒、可解释的城市尺度LiDAR变化检测方法。

Method: 采用多分辨率Normal Distributions Transform（NDT）与点到平面ICP进行跨时段LiDAR数据配准；高程归一化后，结合配准协方差与表面粗糙度生成逐点检测置信度；利用语义与实例分割结果，通过类约束二分图匹配（含增广虚拟节点）优化几何关联；采用分块处理控制内存并保留窄小地面变化；最终在实例层面融合重叠、位移与体积差异，并施加局部检测门控。

Result: 在澳大利亚Subiaco 2023–2025双时相LiDAR数据集上达到95.3%准确率、90.8% mF1、82.9% mIoU，较最强基线Triplet KPConv分别提升0.3、0.6、1.1个百分点。

Conclusion: 所提不确定性感知、对象中心的变化检测框架在精度、鲁棒性与实用性上均优于现有方法，适用于城市规划、合规监管与资产监测等实际应用，并开源了数据与代码。

Abstract: High-definition 3D city maps enable city planning and change detection, which is essential for municipal compliance, map maintenance, and asset monitoring, including both built structures and urban greenery. Conventional Digital Surface Model (DSM) and image differencing are sensitive to vertical bias and viewpoint mismatch, while original point cloud or voxel models require large memory, assume perfect alignment, and degrade thin structures. We propose an uncertainty-aware, object-centric method for city-scale LiDAR-based change detection. Our method aligns data from different time periods using multi-resolution Normal Distributions Transform (NDT) and a point-to-plane Iterative Closest Point (ICP) method, normalizes elevation, and computes a per-point level of detection from registration covariance and surface roughness to calibrate change decisions. Geometry-based associations are refined by semantic and instance segmentation and optimized using class-constrained bipartite assignment with augmented dummies to handle split-merge cases. Tiled processing bounds memory and preserves narrow ground changes, while instance-level decisions integrate overlap, displacement, and volumetric differences under local detection gating. We perform experiments on a Subiaco (Western Australia) dataset captured in 2023 and again in 2025. Our method achieves 95.3% accuracy, 90.8% mF1, and 82.9% mIoU, improving over the strongest baseline, Triplet KPConv, by 0.3, 0.6, and 1.1 points, respectively. The datasets are available on IEEE DataPort (2023: https://ieee-dataport.org/documents/2023-subiaco-wa-3d-hd-lidar-point-cloud-maps-dataset and 2025: https://ieee-dataport.org/documents/2025-subiaco-wa-3d-hd-lidar-gnss-point-cloud-maps-dataset). The source code is available at https://github.com/HaitianWang/IEEE-Sensor-Journal-Changing-Detection.

</details>


### [52] [Tele-Omni: a Unified Multimodal Framework for Video Generation and Editing](https://arxiv.org/abs/2602.09609)
*Jialun Liu,Yukuo Ma,Xiao Cao,Tian Li,Gonghu Shang,Haibin Huang,Chi Zhang,Xuelong Li,Cong Liu,Junqi Liu,Jiakui Hu,Robby T. Tan,Shiwen Zhang,Liying Yang,Xiaoyan Yang,Qizhen Weng,Xiangzhen Chang,Yuanzhi Liang,Yifan Xu,Zhiyong Huang,Zuoxin Li,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出Tele-Omni，一个基于多模态指令（文本、图像、参考视频）的统一视频生成与编辑框架，通过解耦指令解析与视频合成，并引入任务感知的数据处理流程，实现灵活控制与高质量时序一致性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型视频生成方法多为任务特定、依赖纯文本输入，难以支持多模态输入与多样化编辑场景；视频编辑方法也常依赖定制化流水线，缺乏可扩展性与可组合性。

Method: 采用预训练多模态大语言模型解析异构指令并推断结构化意图，结合扩散模型进行条件视频合成；设计任务感知的数据处理流程，将多模态输入统一为结构化指令格式，支持联合训练。

Result: Tele-Omni在文本到视频、图像到视频、首尾帧生成、上下文内视频生成与编辑等多种任务上均取得有竞争力的结果，兼顾灵活性、时序连贯性与视觉一致性。

Conclusion: Tele-Omni验证了统一多模态指令驱动的视频生成与编辑框架的可行性与有效性，为构建通用视频基础模型提供了新思路。

Abstract: Recent advances in diffusion-based video generation have substantially improved visual fidelity and temporal coherence. However, most existing approaches remain task-specific and rely primarily on textual instructions, limiting their ability to handle multimodal inputs, contextual references, and diverse video generation and editing scenarios within a unified framework. Moreover, many video editing methods depend on carefully engineered pipelines tailored to individual operations, which hinders scalability and composability. In this paper, we propose Tele-Omni, a unified multimodal framework for video generation and editing that follows multimodal instructions, including text, images, and reference videos, within a single model. Tele-Omni leverages pretrained multimodal large language models to parse heterogeneous instructions and infer structured generation or editing intents, while diffusion-based generators perform high-quality video synthesis conditioned on these structured signals. To enable joint training across heterogeneous video tasks, we introduce a task-aware data processing pipeline that unifies multimodal inputs into a structured instruction format while preserving task-specific constraints. Tele-Omni supports a wide range of video-centric tasks, including text-to-video generation, image-to-video generation, first-last-frame video generation, in-context video generation, and in-context video editing. By decoupling instruction parsing from video synthesis and combining it with task-aware data design, Tele-Omni achieves flexible multimodal control while maintaining strong temporal coherence and visual consistency. Experimental results demonstrate that Tele-Omni achieves competitive performance across multiple tasks.

</details>


### [53] [Perception with Guarantees: Certified Pose Estimation via Reachability Analysis](https://arxiv.org/abs/2602.10032)
*Tobias Ladner,Yasser Shoukry,Matthias Althoff*

Main category: cs.CV

TL;DR: 本文提出了一种仅基于单张相机图像和已知目标几何形状的3D认证姿态估计方法，通过可达性分析与神经网络形式化验证技术，为安全关键型网络物理系统提供可证明的安全姿态边界。


<details>
  <summary>Details</summary>
Motivation: 在安全关键型网络物理系统中，传统姿态估计（如依赖GPS或多种传感器融合）无法提供最坏情况下的形式化安全保证，且外部服务可能不可信。

Method: 利用可达性分析和形式化神经网络验证技术，对仅基于单目相机图像和已知目标几何结构的姿态估计结果进行严格数学边界界定，实现认证式（certified）姿态估计。

Result: 实验表明该方法在合成数据和真实世界场景中均能高效、准确地定位智能体，并给出可验证的姿态不确定性边界。

Conclusion: 该工作首次实现了仅用单张图像和已知几何的3D姿态估计的形式化认证，为安全关键应用提供了理论保障和实用工具。

Abstract: Agents in cyber-physical systems are increasingly entrusted with safety-critical tasks. Ensuring safety of these agents often requires localizing the pose for subsequent actions. Pose estimates can, e.g., be obtained from various combinations of lidar sensors, cameras, and external services such as GPS. Crucially, in safety-critical domains, a rough estimate is insufficient to formally determine safety, i.e., guaranteeing safety even in the worst-case scenario, and external services might additionally not be trustworthy. We address this problem by presenting a certified pose estimation in 3D solely from a camera image and a well-known target geometry. This is realized by formally bounding the pose, which is computed by leveraging recent results from reachability analysis and formal neural network verification. Our experiments demonstrate that our approach efficiently and accurately localizes agents in both synthetic and real-world experiments.

</details>


### [54] [AGMark: Attention-Guided Dynamic Watermarking for Large Vision-Language Models](https://arxiv.org/abs/2602.09611)
*Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Linlin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为AGMark的注意力引导动态水印框架，用于在大型视觉-语言模型中嵌入可检测信号，同时严格保持视觉保真度。该方法在每个解码步骤中动态识别语义关键证据，并结合不确定性感知和证据校准来自适应地划分词汇表，从而避免无关词元，提升生成质量与视觉语义保真度，同时保持高检测准确率和抗攻击鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉无关水印会引入视觉无关词元并破坏视觉对齐；而现有视觉特定水印依赖静态权重估计、忽略权重分布密度，无法适应生成过程中视觉依赖的动态变化，易引入低质量长尾词元。

Method: 提出Attention-Guided Dynamic Watermarking（AGMark）：每步解码中基于注意力权重动态识别语义关键证据，并融合上下文连贯性线索，构建自适应证据-权重分布；再联合考虑词元熵（不确定性感知）和权重密度（证据校准）确定语义关键词元比例，实现自适应词汇划分。

Result: AGMark显著优于传统方法，在生成质量尤其是生成后期的视觉语义保真度上提升明显；检测准确率≥99.36% AUC，抗攻击鲁棒性≥88.61% AUC，且不牺牲推理效率。

Conclusion: AGMark为多模态水印建立了一个兼顾可靠性、视觉保真度与鲁棒性的新标准，解决了现有方法在动态视觉依赖建模与高质量词元选择上的关键缺陷。

Abstract: Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks may introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases. Additionally, current vision-specific watermarks rely on a static, one-time estimation of vision critical weights and ignore the weight distribution density when determining the proportion of protected tokens. This design fails to account for dynamic changes in visual dependence during generation and may introduce low-quality tokens in the long tail. To address these challenges, we propose Attention-Guided Dynamic Watermarking (AGMark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. At each decoding step, AGMark first dynamically identifies semantic-critical evidence based on attention weights for visual relevance, together with context-aware coherence cues, resulting in a more adaptive and well-calibrated evidence-weight distribution. It then determines the proportion of semantic-critical tokens by jointly considering uncertainty awareness (token entropy) and evidence calibration (weight density), thereby enabling adaptive vocabulary partitioning to avoid irrelevant tokens. Empirical results confirm that AGMark outperforms conventional methods, observably improving generation quality and yielding particularly strong gains in visual semantic fidelity in the later stages of generation. The framework maintains highly competitive detection accuracy (at least 99.36\% AUC) and robust attack resilience (at least 88.61\% AUC) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multi-modal watermarking.

</details>


### [55] [SAGE: Scalable Agentic 3D Scene Generation for Embodied AI](https://arxiv.org/abs/2602.10116)
*Hongchi Xia,Xuan Li,Zhaoshuo Li,Qianli Ma,Jiashu Xu,Ming-Yu Liu,Yin Cui,Tsung-Yi Lin,Wei-Chiu Ma,Shenlong Wang,Shuran Song,Fangyin Wei*

Main category: cs.CV

TL;DR: 本文提出SAGE框架，通过多生成器与批评者协同的智能体方法，自动生成符合用户指定任务、语义合理、视觉真实且物理稳定的仿真就绪3D环境，显著提升具身智能策略训练的可扩展性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中具身智能体的数据收集成本高且不安全，亟需可扩展、逼真且可直接用于仿真的3D环境；而现有场景生成系统依赖规则或任务特定流程，易产生伪影和物理无效场景。

Method: SAGE是一种具身任务驱动的智能体框架，结合布局与物体组合生成器及评估语义合理性、视觉真实性和物理稳定性的批评者，通过迭代推理与自适应工具选择实现场景自优化。

Result: 生成的环境逼真、多样且可直接部署于现代仿真器；纯基于该数据训练的策略展现出清晰的缩放趋势，并能泛化至未见过的物体与布局。

Conclusion: SAGE验证了仿真驱动扩展在具身AI中的巨大潜力，为低成本、高安全性、大规模策略训练提供了新范式。

Abstract: Real-world data collection for embodied agents remains costly and unsafe, calling for scalable, realistic, and simulator-ready 3D environments. However, existing scene-generation systems often rely on rule-based or task-specific pipelines, yielding artifacts and physically invalid scenes. We present SAGE, an agentic framework that, given a user-specified embodied task (e.g., "pick up a bowl and place it on the table"), understands the intent and automatically generates simulation-ready environments at scale. The agent couples multiple generators for layout and object composition with critics that evaluate semantic plausibility, visual realism, and physical stability. Through iterative reasoning and adaptive tool selection, it self-refines the scenes until meeting user intent and physical validity. The resulting environments are realistic, diverse, and directly deployable in modern simulators for policy training. Policies trained purely on this data exhibit clear scaling trends and generalize to unseen objects and layouts, demonstrating the promise of simulation-driven scaling for embodied AI. Code, demos, and the SAGE-10k dataset can be found on the project page here: https://nvlabs.github.io/sage.

</details>


### [56] [Towards Training-free Multimodal Hate Localisation with Large Language Models](https://arxiv.org/abs/2602.09637)
*Yueming Sun,Long Yang,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 本文提出LELA，一种无需训练的基于大语言模型（LLM）的视频仇恨内容定位框架，通过多模态字幕与多阶段提示实现帧级仇恨检测，显著优于现有无训练基线。


<details>
  <summary>Details</summary>
Motivation: 现有视频仇恨检测方法依赖大量人工标注或缺乏细粒度时间精度，亟需一种无需训练、高精度、可解释的解决方案。

Method: LELA将视频分解为图像、语音、OCR、音乐和视频上下文五种模态，利用模态特定字幕和多阶段提示计算每帧的细粒度仇恨得分，并引入组合匹配机制增强跨模态推理。

Result: 在HateMM和MultiHateClip两个基准上，LELA大幅超越所有现有无训练基线；消融实验与可视化分析验证了其有效性与可解释性。

Conclusion: LELA是首个训练-free的LLM驱动视频仇恨定位框架，为可扩展、可解释的仇恨内容治理提供了新范式。

Abstract: The proliferation of hateful content in online videos poses severe threats to individual well-being and societal harmony. However, existing solutions for video hate detection either rely heavily on large-scale human annotations or lack fine-grained temporal precision. In this work, we propose LELA, the first training-free Large Language Model (LLM) based framework for hate video localization. Distinct from state-of-the-art models that depend on supervised pipelines, LELA leverages LLMs and modality-specific captioning to detect and temporally localize hateful content in a training-free manner. Our method decomposes a video into five modalities, including image, speech, OCR, music, and video context, and uses a multi-stage prompting scheme to compute fine-grained hateful scores for each frame. We further introduce a composition matching mechanism to enhance cross-modal reasoning. Experiments on two challenging benchmarks, HateMM and MultiHateClip, demonstrate that LELA outperforms all existing training-free baselines by a large margin. We also provide extensive ablations and qualitative visualizations, establishing LELA as a strong foundation for scalable and interpretable hate video localization.

</details>


### [57] [VideoAfford: Grounding 3D Affordance from Human-Object-Interaction Videos via Multimodal Large Language Model](https://arxiv.org/abs/2602.09638)
*Hanqing Wang,Mingyu Liu,Xiaoyu Chen,Chengwei MA,Yiming Zhong,Wenti Yin,Yuhao Liu,Zhiqing Cui,Jiahao Yuan,Lu Dai,Zhiyuan Ma,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出VIDA视频数据集和VideoAfford模型，通过融合视频动态交互信息与多模态大语言模型，提升3D物体可操作区域的精准定位与开放世界泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态语言/图像线索，缺乏动态交互时序与因果信息，难以准确建模3D物体的可操作性。

Method: 构建大规模视频驱动的3D可操作性数据集VIDA（38K HOI视频、22K点云）；提出VideoAfford模型，集成多模态大语言模型、潜在动作编码器提取动态交互先验，并设计空间感知损失函数以增强3D空间理解。

Result: VideoAfford在多项指标上显著超越现有方法，具备强开放世界泛化能力和可操作性推理能力。

Conclusion: 引入视频动态交互信息并结合多模态大模型是提升3D可操作性定位性能与泛化性的有效途径，VIDA数据集与VideoAfford为该领域提供了重要基础。

Abstract: 3D affordance grounding aims to highlight the actionable regions on 3D objects, which is crucial for robotic manipulation. Previous research primarily focused on learning affordance knowledge from static cues such as language and images, which struggle to provide sufficient dynamic interaction context that can reveal temporal and causal cues. To alleviate this predicament, we collect a comprehensive video-based 3D affordance dataset, \textit{VIDA}, which contains 38K human-object-interaction videos covering 16 affordance types, 38 object categories, and 22K point clouds. Based on \textit{VIDA}, we propose a strong baseline: VideoAfford, which activates multimodal large language models with additional affordance segmentation capabilities, enabling both world knowledge reasoning and fine-grained affordance grounding within a unified framework. To enhance action understanding capability, we leverage a latent action encoder to extract dynamic interaction priors from HOI videos. Moreover, we introduce a \textit{spatial-aware} loss function to enable VideoAfford to obtain comprehensive 3D spatial knowledge. Extensive experimental evaluations demonstrate that our model significantly outperforms well-established methods and exhibits strong open-world generalization with affordance reasoning abilities. All datasets and code will be publicly released to advance research in this area.

</details>


### [58] [Time2General: Learning Spatiotemporal Invariant Representations for Domain-Generalization Video Semantic Segmentation](https://arxiv.org/abs/2602.09648)
*Siyu Chen,Ting Han,Haoling Huang,Chaolei Wang,Chengzheng Fu,Duxin Zhu,Guorong Cai,Jinhe Su*

Main category: cs.CV

TL;DR: 本文提出Time2General框架，用于解决域泛化视频语义分割（DGVSS）中因域偏移和时序采样偏移导致的帧间闪烁问题，通过稳定性查询、时空记忆解码器和掩码时序一致性损失提升跨域精度与时序稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有DGVSS方法在面对域偏移和时序采样偏移时，基于对应关系的传播和固定步长时序聚合失效，导致标签稳定区域仍出现严重帧间闪烁。

Method: 提出Time2General框架，包含稳定性查询机制、时空记忆解码器（聚合多帧上下文并解码一致逐帧掩码），以及掩码时序一致性损失（正则化不同采样步长下的预测差异）和随机训练步长策略。

Result: 在多个驾驶基准上显著提升跨域准确率和时序稳定性，优于现有DGSS和VSS基线，推理速度达18 FPS。

Conclusion: Time2General有效缓解了DGVSS中的域偏移与时序采样偏移问题，在不依赖目标域标签和测试时自适应的前提下，实现了高精度与高时序一致性的视频分割。

Abstract: Domain Generalized Video Semantic Segmentation (DGVSS) is trained on a single labeled driving domain and is directly deployed on unseen domains without target labels and test-time adaptation while maintaining temporally consistent predictions over video streams. In practice, both domain shift and temporal-sampling shift break correspondence-based propagation and fixed-stride temporal aggregation, causing severe frame-to-frame flicker even in label-stable regions. We propose Time2General, a DGVSS framework built on Stability Queries. Time2General introduces a Spatio-Temporal Memory Decoder that aggregates multi-frame context into a clip-level spatio-temporal memory and decodes temporally consistent per-frame masks without explicit correspondence propagation. To further suppress flicker and improve robustness to varying sampling rates, the Masked Temporal Consistency Loss is proposed to regularize temporal prediction discrepancies across different strides, and randomize training strides to expose the model to diverse temporal gaps. Extensive experiments on multiple driving benchmarks show that Time2General achieves a substantial improvement in cross-domain accuracy and temporal stability over prior DGSS and VSS baselines while running at up to 18 FPS. Code will be released after the review process.

</details>


### [59] [TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution](https://arxiv.org/abs/2602.09662)
*Deyang Jiang,Jing Huang,Xuanle Zhao,Lei Chen,Liming Zheng,Fanfan Liu,Haibo Qiu,Peng Shi,Zhixiong Zeng*

Main category: cs.CV

TL;DR: 本文提出TreeCUA框架，通过树结构组织GUI轨迹、多智能体协同探索与验证、树形拓扑存储与自适应探索算法，高效扩展GUI规划能力，并进一步提出TreeCUA-DPO方法利用分支信息提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作聚焦于GUI定位（grounding）的扩展，而忽视更关键的GUI规划（planning）；GUI探索天然呈树状结构，早期入口点被高频访问，因此需利用树结构降低数据成本、提升规划可扩展性。

Method: 提出TreeCUA：1）多智能体协同框架（探索、动作验证、轨迹总结、质量评估）；2）树形拓扑存储与回放重复节点；3）自适应探索算法平衡深度（难度）与宽度（多样性）；4）世界知识引导与全局记忆回溯避免低质量生成；5）基于树节点信息扩展出TreeCUA-DPO，利用邻近轨迹分支信息优化规划。

Result: TreeCUA与TreeCUA-DPO在多项指标上显著优于基线；OOD实验表明其具备强泛化能力；所有轨迹节点信息与代码将开源。

Conclusion: 树结构建模与多智能体协同验证是高效扩展GUI规划能力的关键路径，TreeCUA系列方法为CUA的数据规模化与泛化能力提升提供了新范式。

Abstract: Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, existing work primarily focuses on scaling GUI grounding rather than the more crucial GUI planning, which requires more sophisticated data collection. In reality, the exploration process of a CUA across apps/desktops/web pages typically follows a tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning. In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evolution. We propose a multi-agent collaborative framework to explore the environment, verify actions, summarize trajectories, and evaluate quality to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise a novel tree-based topology to store and replay duplicate exploration nodes, and design an adaptive exploration algorithm to balance the depth (\emph{i.e.}, trajectory difficulty) and breadth (\emph{i.e.}, trajectory diversity). Moreover, we develop world knowledge guidance and global memory backtracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUA-DPO method from abundant tree node information, improving GUI planning capability by referring to the branch information of adjacent trajectories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improvements, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA.

</details>


### [60] [Semi-supervised Liver Segmentation and Patch-based Fibrosis Staging with Registration-aided Multi-parametric MRI](https://arxiv.org/abs/2602.09686)
*Boya Wang,Ruizhe Li,Chao Chen,Xin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种用于肝脏分割（LiSeg）和肝纤维化分期（LiFS）的多任务深度学习框架，基于CARE Liver 2025 Track 4挑战，利用半监督学习与配准融合解决标注数据少、多模态MRI差异及域偏移问题，并采用基于图像块的分类方法实现可解释的纤维化分期。


<details>
  <summary>Details</summary>
Motivation: 临床中肝纤维化诊断面临肝脏精准分割与疾病准确分期的双重挑战，而现有方法受限于标注数据稀缺、多参数MRI模态差异大及跨中心域偏移问题。

Method: 构建多任务框架：LiSeg阶段采用融合图像分割与配准的半监督学习模型，充分利用有/无标签数据；LiFS阶段采用基于图像块的分类方法，支持纤维化分期结果可视化。

Result: 在CARE Liver 2025挑战独立测试集（含ID与OOD样本）上验证有效，支持3通道（T1/T2/DWI）与7通道（T1/T2/DWI+GED1–GED4）MRI输入，代码已开源。

Conclusion: 该框架能有效应对多模态MRI数据、标注稀缺与域偏移等现实挑战，为肝纤维化自动化诊断提供鲁棒、可解释且实用的解决方案。

Abstract: Liver fibrosis poses a substantial challenge in clinical practice, emphasizing the necessity for precise liver segmentation and accurate disease staging. Based on the CARE Liver 2025 Track 4 Challenge, this study introduces a multi-task deep learning framework developed for liver segmentation (LiSeg) and liver fibrosis staging (LiFS) using multiparametric MRI. The LiSeg phase addresses the challenge of limited annotated images and the complexities of multi-parametric MRI data by employing a semi-supervised learning model that integrates image segmentation and registration. By leveraging both labeled and unlabeled data, the model overcomes the difficulties introduced by domain shifts and variations across modalities. In the LiFS phase, we employed a patchbased method which allows the visualization of liver fibrosis stages based on the classification outputs. Our approach effectively handles multimodality imaging data, limited labels, and domain shifts. The proposed method has been tested by the challenge organizer on an independent test set that includes in-distribution (ID) and out-of-distribution (OOD) cases using three-channel MRIs (T1, T2, DWI) and seven-channel MRIs (T1, T2, DWI, GED1-GED4). The code is freely available. Github link: https://github.com/mileywang3061/Care-Liver

</details>


### [61] [GenSeg-R1: RL-Driven Vision-Language Grounding for Fine-Grained Referring Segmentation](https://arxiv.org/abs/2602.09701)
*Sandesh Hegde,Jaison Saji Chacko,Debarshi Banerjee,Uma Mahesh*

Main category: cs.CV

TL;DR: 本文提出GenSeg-R1框架，采用‘推理-再分割’解耦范式，利用微调的Qwen3-VL模型生成空间提示（框+关键点），驱动冻结的SAM 2完成细粒度指代表达图像分割；无需推理链标注，使用GRPO优化，并在多个基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有指代表达分割方法难以兼顾语言理解精度与分割质量，且依赖昂贵的推理链监督；需提升对复杂查询（如无目标提示）的鲁棒性与泛化能力。

Method: 构建解耦的reason-then-segment流程：VLM（Qwen3-VL）接收图文输入，输出结构化空间提示（bounding box + two interior keypoints）；冻结SAM 2将提示转为掩码；采用Group Relative Policy Optimization（GRPO）进行端到端强化学习微调，无需人工推理链标注；GenSeg-R1-G引入SAM 2 in-the-loop reward，直接优化掩码质量并支持无目标检测。

Result: GenSeg-R1-8B在RefCOCOg val上达0.7127 cIoU / 0.7382 mIoU，较Qwen3-VL Instruct基线提升+15.3/+21.9；超越Seg-Zero-7B +3.3 cIoU；GenSeg-R1-G在GRefCOCO val上达76.69% target mIoU与82.40%无目标准确率；GenSeg-R1-4B在ReasonSeg test上达68.40% mIoU，优于Seg-Zero-7B和Seg-R1-7B。

Conclusion: 解耦式VLM+SAM架构结合GRPO强化学习是高效、可扩展的指代表达分割新范式，无需推理链监督即可实现高性能与强泛化（尤其无目标识别），为多模态视觉定位任务提供新思路。

Abstract: We study fine-grained referring image segmentation via a decoupled reason-then-segment pipeline. A vision-language model (VLM) receives an image and a natural-language query, reasons about the scene, and emits structured spatial prompts: a bounding box plus two interior keypoints for every referred instance. A frozen promptable segmenter (SAM 2) converts these prompts into high-quality masks.
  Within our GenSeg-R1 framework we finetune Qwen3-VL models (4B and 8B parameters) using Group Relative Policy Optimization (GRPO), requiring no supervised reasoning-chain annotations. On RefCOCOg validation our best model (GenSeg-R1-8B) achieves 0.7127 cIoU and 0.7382 mIoU, substantially outperforming the corresponding Qwen3-VL Instruct baselines (+15.3 and +21.9 points, respectively) and surpassing Seg-Zero-7B [3] by +3.3 cIoU under identical evaluation.
  We further introduce GenSeg-R1-G, a variant trained on GRefCOCO [9] with a SAM 2 in-the-loop reward that directly optimizes mask quality. On GRefCOCO validation GenSeg-R1-G achieves 76.69% target mIoU with 82.40% accuracy on negative (no-target) prompts, substantially outperforming Seg-R1-7B and Seg-Zero-7B, which lack no-target detection capability. On ReasonSeg test, GenSeg-R1-4B reaches 68.40% mIoU, surpassing Seg-Zero-7B by +7.0 and Seg-R1-7B by +10.7 points.

</details>


### [62] [Stroke3D: Lifting 2D strokes into rigged 3D model via latent diffusion models](https://arxiv.org/abs/2602.09713)
*Ruisi Zhao,Haoren Zheng,Zongxin Yang,Hehe Fan,Yi Yang*

Main category: cs.CV

TL;DR: Stroke3D 是首个能根据用户手绘2D笔画和文本提示直接生成可动画3D绑定网格的框架，采用两阶段流程：先用Sk-VAE与Sk-DiT生成可控骨架，再通过增强的TextuRig数据集与SKA-DPO优化策略合成高质量带纹理网格。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法难以生成可动画几何体，而传统绑定技术缺乏对骨架结构的细粒度控制；需一种能结合语义（文本）与显式结构控制（2D笔画）的新方法。

Method: 提出两阶段框架：1）可控骨架生成——使用Skeletal Graph VAE（Sk-VAE）编码骨架图结构至隐空间，并由Skeletal Graph DiT（Sk-DiT）在文本与2D笔画联合条件下生成骨架嵌入；2）增强网格合成——基于TextuRig数据集（来自Objaverse-XL的带标注纹理绑定网格）微调骨架到网格模型，并引入SKA-DPO偏好优化策略，以骨架-网格对齐分数为指导提升几何保真度。

Result: Stroke3D成功生成语义合理、结构准确的3D骨架及高保真、可动画的带纹理网格；实验表明其在骨架合理性与网格质量上优于现有方法；首次实现基于用户手绘2D笔画的端到端绑定3D生成。

Conclusion: Stroke3D为创建即用型动画3D内容提供了更直观、可控的新范式，填补了文本/草图驱动生成与可动画绑定之间的关键空白，推动了生成式3D建模向实用化迈进。

Abstract: Rigged 3D assets are fundamental to 3D deformation and animation. However, existing 3D generation methods face challenges in generating animatable geometry, while rigging techniques lack fine-grained structural control over skeleton creation. To address these limitations, we introduce Stroke3D, a novel framework that directly generates rigged meshes from user inputs: 2D drawn strokes and a descriptive text prompt. Our approach pioneers a two-stage pipeline that separates the generation into: 1) Controllable Skeleton Generation, we employ the Skeletal Graph VAE (Sk-VAE) to encode the skeleton's graph structure into a latent space, where the Skeletal Graph DiT (Sk-DiT) generates a skeletal embedding. The generation process is conditioned on both the text for semantics and the 2D strokes for explicit structural control, with the VAE's decoder reconstructing the final high-quality 3D skeleton; and 2) Enhanced Mesh Synthesis via TextuRig and SKA-DPO, where we then synthesize a textured mesh conditioned on the generated skeleton. For this stage, we first enhance an existing skeleton-to-mesh model by augmenting its training data with TextuRig: a dataset of textured and rigged meshes with captions, curated from Objaverse-XL. Additionally, we employ a preference optimization strategy, SKA-DPO, guided by a skeleton-mesh alignment score, to further improve geometric fidelity. Together, our framework enables a more intuitive workflow for creating ready to animate 3D content. To the best of our knowledge, our work is the first to generate rigged 3D meshes conditioned on user-drawn 2D strokes. Extensive experiments demonstrate that Stroke3D produces plausible skeletons and high-quality meshes.

</details>


### [63] [From Lightweight CNNs to SpikeNets: Benchmarking Accuracy-Energy Tradeoffs with Pruned Spiking SqueezeNet](https://arxiv.org/abs/2602.09717)
*Radib Bin Kabir,Tawsif Tashwar Dipto,Mehedi Ahamed,Sabbir Ahmed,Md Hasanul Kabir*

Main category: cs.CV

TL;DR: 本文首次系统性地评估了从轻量级CNN（如ShuffleNet、SqueezeNet等）转换而来的Spiking Neural Networks（SNNs），在CIFAR和TinyImageNet数据集上验证其精度与能效；结果表明SNN可实现最高15.7倍能效提升，其中SqueezeNet-SNN最优，并通过结构化剪枝进一步提升性能与能效。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注大规模SNN，而轻量级CNN-to-SNN转换流程的设计与评估尚属空白，尤其面向边缘智能的低功耗需求亟需系统性基准。

Method: 将ShuffleNet、SqueezeNet、MnasNet和MixNet等轻量CNN统一转换为基于LIF神经元的SNN，采用代理梯度下降训练；构建对应SNN变体并进行多指标评测；进一步对SqueezeNet-SNN实施模块级结构化剪枝，得到SNN-SqueezeNet-P。

Result: SNN相较对应CNN最高提升15.7×能效；SqueezeNet-SNN表现最优；剪枝后SNN-SqueezeNet-P在CIFAR-10上精度提升6%、参数减少19%，且相较CNN-SqueezeNet仅低1%精度但能耗降低88.1%。

Conclusion: 轻量级SNN是边缘部署中兼具高性能与超低功耗的可行方案，本工作为边缘智能提供了实用、高效的脉冲神经网络落地路径。

Abstract: Spiking Neural Networks (SNNs) are increasingly studied as energy-efficient alternatives to Convolutional Neural Networks (CNNs), particularly for edge intelligence. However, prior work has largely emphasized large-scale models, leaving the design and evaluation of lightweight CNN-to-SNN pipelines underexplored. In this paper, we present the first systematic benchmark of lightweight SNNs obtained by converting compact CNN architectures into spiking networks, where activations are modeled with Leaky-Integrate-and-Fire (LIF) neurons and trained using surrogate gradient descent under a unified setup. We construct spiking variants of ShuffleNet, SqueezeNet, MnasNet, and MixNet, and evaluate them on CIFAR-10, CIFAR-100, and TinyImageNet, measuring accuracy, F1-score, parameter count, computational complexity, and energy consumption. Our results show that SNNs can achieve up to 15.7x higher energy efficiency than their CNN counterparts while retaining competitive accuracy. Among these, the SNN variant of SqueezeNet consistently outperforms other lightweight SNNs. To further optimize this model, we apply a structured pruning strategy that removes entire redundant modules, yielding a pruned architecture, SNN-SqueezeNet-P. This pruned model improves CIFAR-10 accuracy by 6% and reduces parameters by 19% compared to the original SNN-SqueezeNet. Crucially, it narrows the gap with CNN-SqueezeNet, achieving nearly the same accuracy (only 1% lower) but with an 88.1% reduction in energy consumption due to sparse spike-driven computations. Together, these findings establish lightweight SNNs as practical, low-power alternatives for edge deployment, highlighting a viable path toward deploying high-performance, low-power intelligence on the edge.

</details>


### [64] [Allure of Craquelure: A Variational-Generative Approach to Crack Detection in Paintings](https://arxiv.org/abs/2602.09730)
*Laura Paul,Holger Rauhut,Martin Burger,Samira Kabri,Tim Roith*

Main category: cs.CV

TL;DR: 本文提出了一种混合方法，将裂纹检测建模为逆问题，通过深度生成模型和Mumford-Shah型变分泛函联合优化，实现绘画中裂纹的像素级定位。


<details>
  <summary>Details</summary>
Motivation: 自动化检测数字化绘画中的裂纹对评估艺术品退化和指导修复至关重要，但因场景复杂及裂纹与笔触、发丝等艺术特征视觉相似而具有挑战性。

Method: 将裂纹检测建模为逆问题，分解图像为无裂纹画作和裂纹成分；使用深度生成模型作为画作先验，用Mumford-Shah型变分泛函结合裂纹先验刻画裂纹结构，并进行联合优化。

Result: 实现了绘画中裂纹的像素级定位图。

Conclusion: 该混合方法有效提升了裂纹检测精度，兼顾了艺术特征与真实裂纹的区分能力，为艺术品保护提供了新工具。

Abstract: Recent advances in imaging technologies, deep learning and numerical performance have enabled non-invasive detailed analysis of artworks, supporting their documentation and conservation. In particular, automated detection of craquelure in digitized paintings is crucial for assessing degradation and guiding restoration, yet remains challenging due to the possibly complex scenery and the visual similarity between cracks and crack-like artistic features such as brush strokes or hair. We propose a hybrid approach that models crack detection as an inverse problem, decomposing an observed image into a crack-free painting and a crack component. A deep generative model is employed as powerful prior for the underlying artwork, while crack structures are captured using a Mumford--Shah-type variational functional together with a crack prior. Joint optimization yields a pixel-level map of crack localizations in the painting.

</details>


### [65] [Toward Fine-Grained Facial Control in 3D Talking Head Generation](https://arxiv.org/abs/2602.09736)
*Shaoyang Xie,Xiaofeng Cong,Baosheng Yu,Zhipeng Gui,Jie Gui,Yuan Yan Tang,James Tin-Yau Kwok*

Main category: cs.CV

TL;DR: 本文提出Fine-Grained 3D Gaussian Splatting（FG-3DGS）框架，通过频率感知的解耦策略分别建模低频（如脸颊、鼻子）与高频（如眼睛、嘴巴）面部区域运动，并结合高分辨率后渲染对齐机制，显著提升唇形同步精度与面部动态稳定性，从而生成高保真、时序一致的说话人头像视频。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动说话人头像生成方法在唇形同步准确性和面部抖动控制方面存在不足，易引发恐怖谷效应，亟需更精细的面部运动建模能力。

Method: 提出FG-3DGS框架：1）频率感知解耦建模——低频区域用共享MLP建模，高频区域用掩码引导专用网络建模；2）基于高斯增量（Gaussian deltas）驱动静态高斯变形；3）引入由大规模音视频预训练模型指导的高频率细化后渲染对齐机制。

Result: 在主流说话人头像数据集上，本方法在生成质量、唇同步精度和时序稳定性方面均超越当前最先进方法。

Conclusion: FG-3DGS通过细粒度运动解耦与高精度后对齐，有效缓解了唇不同步与面部抖动问题，为实时高保真数字人生成提供了新范式。

Abstract: Audio-driven talking head generation is a core component of digital avatars, and 3D Gaussian Splatting has shown strong performance in real-time rendering of high-fidelity talking heads. However, achieving precise control over fine-grained facial movements remains a significant challenge, particularly due to lip-synchronization inaccuracies and facial jitter, both of which can contribute to the uncanny valley effect. To address these challenges, we propose Fine-Grained 3D Gaussian Splatting (FG-3DGS), a novel framework that enables temporally consistent and high-fidelity talking head generation. Our method introduces a frequency-aware disentanglement strategy to explicitly model facial regions based on their motion characteristics. Low-frequency regions, such as the cheeks, nose, and forehead, are jointly modeled using a standard MLP, while high-frequency regions, including the eyes and mouth, are captured separately using a dedicated network guided by facial area masks. The predicted motion dynamics, represented as Gaussian deltas, are applied to the static Gaussians to generate the final head frames, which are rendered via a rasterizer using frame-specific camera parameters. Additionally, a high-frequency-refined post-rendering alignment mechanism, learned from large-scale audio-video pairs by a pretrained model, is incorporated to enhance per-frame generation and achieve more accurate lip synchronization. Extensive experiments on widely used datasets for talking head generation demonstrate that our method outperforms recent state-of-the-art approaches in producing high-fidelity, lip-synced talking head videos.

</details>


### [66] [Robust Vision Systems for Connected and Autonomous Vehicles: Security Challenges and Attack Vectors](https://arxiv.org/abs/2602.09740)
*Sandeep Gupta,Roberto Passerone*

Main category: cs.CV

TL;DR: 本文研究了网联自动驾驶车辆（CAVs）视觉系统的鲁棒性，提出了一种CAV视觉系统（CAVVS）参考架构，识别其攻击面与攻击向量，并基于CIA三原则（机密性、完整性、可用性）评估其安全影响。


<details>
  <summary>Details</summary>
Motivation: 为实现L5级自动驾驶，需确保CAV视觉系统在复杂环境下的安全性与鲁棒性，而当前对其潜在攻击面和安全影响缺乏系统分析。

Method: 构建CAV视觉系统（CAVVS）参考架构，识别关键传感器与视觉组件的攻击表面，并系统梳理和评估各攻击向量对机密性、完整性与可用性（CIA）的影响。

Result: 明确了CAVVS的关键攻击面与对应攻击向量，并从CIA三维度量化/定性评估了其安全影响，为设计鲁棒防御机制提供依据。

Conclusion: CAV视觉系统存在多类可被利用的攻击面，其安全威胁直接影响导航可靠性；必须基于CIA框架开展系统性防护设计，以支撑L5级自动驾驶的安全落地。

Abstract: This article investigates the robustness of vision systems in Connected and Autonomous Vehicles (CAVs), which is critical for developing Level-5 autonomous driving capabilities. Safe and reliable CAV navigation undeniably depends on robust vision systems that enable accurate detection of objects, lane markings, and traffic signage. We analyze the key sensors and vision components essential for CAV navigation to derive a reference architecture for CAV vision system (CAVVS). This reference architecture provides a basis for identifying potential attack surfaces of CAVVS. Subsequently, we elaborate on identified attack vectors targeting each attack surface, rigorously evaluating their implications for confidentiality, integrity, and availability (CIA). Our study provides a comprehensive understanding of attack vector dynamics in vision systems, which is crucial for formulating robust security measures that can uphold the principles of the CIA triad.

</details>


### [67] [Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets](https://arxiv.org/abs/2602.09775)
*Abhipsa Basu,Yugam Bahl,Kirti Bhagat,Preethi Seshadri,R. Venkatesh Babu,Danish Pruthi*

Main category: cs.CV

TL;DR: 本文通过地理分析大型多模态数据集，发现文本到图像模型训练数据存在严重的地域代表性偏差，欧美国家样本占比过高，而南美和非洲国家严重不足，且数据分布与各国GDP高度相关；非英语子集也表现出母语国家主导的偏差；高代表性并不意味着高视觉或语义多样性；基于该数据训练的Stable Diffusion生成图像虽逼真但地理覆盖范围狭窄。


<details>
  <summary>Details</summary>
Motivation: 探究文本到图像模型训练数据的地理代表性偏差问题，理解其训练样本的地理来源分布，以评估模型公平性与泛化能力。

Method: 利用大语言模型从英文图像标题中提取地理位置信息，将图像-标题对映射到具体国家；分析Re-LAION、DataComp1B和Conceptual Captions三个主流数据集在20个常见实体上的地理分布；计算国家GDP与样本占比的相关性；扩展分析Re-LAION中四种非英语子集的地理倾向；评估地理代表性与视觉/语义多样性的关系；并用Stable Diffusion v1.3生成各国图像以对比真实图像覆盖度。

Result: 美国、英国、加拿大占样本48.0%，南美和非洲仅占1.8%和3.8%；国家GDP与数据占比强相关（ρ=0.82）；非英语子集同样偏向母语国家；高地理代表性不带来更高多样性；Stable Diffusion生成图像虽逼真但地理覆盖远窄于真实世界。

Conclusion: 当前主流多模态训练数据存在系统性地理偏差，可能导致模型在欠代表地区表现不佳，亟需构建更平衡、更具全球代表性的数据集，并在模型训练与评估中纳入地理公平性考量。

Abstract: Recent studies show that text-to-image models often fail to generate geographically representative images, raising concerns about the representativeness of their training data and motivating the question: which parts of the world do these training examples come from? We geographically profile large-scale multimodal datasets by mapping image-caption pairs to countries based on location information extracted from captions using LLMs. Studying English captions from three widely used datasets (Re-LAION, DataComp1B, and Conceptual Captions) across $20$ common entities (e.g., house, flag), we find that the United States, the United Kingdom, and Canada account for $48.0\%$ of samples, while South American and African countries are severely under-represented with only $1.8\%$ and $3.8\%$ of images, respectively. We observe a strong correlation between a country's GDP and its representation in the data ($ρ= 0.82$). Examining non-English subsets for $4$ languages from the Re-LAION dataset, we find that representation skews heavily toward countries where these languages are predominantly spoken. Additionally, we find that higher representation does not necessarily translate to greater visual or semantic diversity. Finally, analyzing country-specific images generated by Stable Diffusion v1.3 trained on Re-LAION, we show that while generations appear realistic, they are severely limited in their coverage compared to real-world images.

</details>


### [68] [SciFlow-Bench: Evaluating Structure-Aware Scientific Diagram Generation via Inverse Parsing](https://arxiv.org/abs/2602.09809)
*Tong Zhang,Honglin Lin,Zhou Liu,Chong Chen,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文提出了SciFlow-Bench，一个面向结构的科学图表生成评估基准，通过将生成图像反解析为结构图并比对来评估模型的结构正确性，而非仅依赖视觉相似性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法忽视像素级生成结果的结构正确性，多依赖图像中心化或主观指标，或仅评估中间符号表示，导致结构准确性被忽略。

Method: 构建基于真实科学PDF的SciFlow-Bench基准，采用闭环往返协议：将生成图像逆向解析为规范图结构，并通过分层多智能体系统实现规划、感知与结构推理协同。

Result: 实验表明，当前模型在复杂拓扑结构的图表生成中仍难以保持结构正确性，验证了结构感知评估的必要性。

Conclusion: 结构正确性是科学图表生成的核心挑战，SciFlow-Bench为该任务提供了首个以结构恢复能力为核心的像素级评估框架。

Abstract: Scientific diagrams convey explicit structural information, yet modern text-to-image models often produce visually plausible but structurally incorrect results. Existing benchmarks either rely on image-centric or subjective metrics insensitive to structure, or evaluate intermediate symbolic representations rather than final rendered images, leaving pixel-based diagram generation underexplored. We introduce SciFlow-Bench, a structure-first benchmark for evaluating scientific diagram generation directly from pixel-level outputs. Built from real scientific PDFs, SciFlow-Bench pairs each source framework figure with a canonical ground-truth graph and evaluates models as black-box image generators under a closed-loop, round-trip protocol that inverse-parses generated diagram images back into structured graphs for comparison. This design enforces evaluation by structural recoverability rather than visual similarity alone, and is enabled by a hierarchical multi-agent system that coordinates planning, perception, and structural reasoning. Experiments show that preserving structural correctness remains a fundamental challenge, particularly for diagrams with complex topology, underscoring the need for structure-aware evaluation.

</details>


### [69] [CompSplat: Compression-aware 3D Gaussian Splatting for Real-world Video](https://arxiv.org/abs/2602.09816)
*Hojun Song,Heejung Choi,Aro Kim,Chae-yeong Song,Gahyeon Kim,Soo Ye Kim,Jaehyup Lee,Sang-hyo Park*

Main category: cs.CV

TL;DR: 本文提出CompSplat，一种压缩感知的训练框架，用于提升真实视频在严重压缩条件下的新视角合成质量与几何一致性。


<details>
  <summary>Details</summary>
Motivation: 真实世界视频常具长序列、不规则相机轨迹和未知位姿，加之压缩失真，导致姿态漂移、特征错位与几何畸变，现有方法未能充分应对多样化的压缩模式。

Method: CompSplat通过建模帧级压缩特性，引入压缩感知的帧加权机制和自适应剪枝策略，以缓解帧间不一致性和累积几何误差。

Result: 在Tanks and Temples、Free和Hike等具有挑战性的基准上，CompSplat在严重压缩条件下显著超越多数最新NVS方法，实现最优渲染质量与位姿精度。

Conclusion: CompSplat有效提升了长视频在真实压缩场景下的新视角合成鲁棒性与几何一致性，为文化保护、数字孪生等应用提供了更可靠的重建方案。

Abstract: High-quality novel view synthesis (NVS) from real-world videos is crucial for applications such as cultural heritage preservation, digital twins, and immersive media. However, real-world videos typically contain long sequences with irregular camera trajectories and unknown poses, leading to pose drift, feature misalignment, and geometric distortion during reconstruction. Moreover, lossy compression amplifies these issues by introducing inconsistencies that gradually degrade geometry and rendering quality. While recent studies have addressed either long-sequence NVS or unposed reconstruction, compression-aware approaches still focus on specific artifacts or limited scenarios, leaving diverse compression patterns in long videos insufficiently explored. In this paper, we propose CompSplat, a compression-aware training framework that explicitly models frame-wise compression characteristics to mitigate inter-frame inconsistency and accumulated geometric errors. CompSplat incorporates compression-aware frame weighting and an adaptive pruning strategy to enhance robustness and geometric consistency, particularly under heavy compression. Extensive experiments on challenging benchmarks, including Tanks and Temples, Free, and Hike, demonstrate that CompSplat achieves state-of-the-art rendering quality and pose accuracy, significantly surpassing most recent state-of-the-art NVS approaches under severe compression conditions.

</details>


### [70] [SAKED: Mitigating Hallucination in Large Vision-Language Models via Stability-Aware Knowledge Enhanced Decoding](https://arxiv.org/abs/2602.09825)
*Zhaoxu Li,Chenqi Kong,Peijun Bao,Song Xia,Yi Tu,Yi Yu,Xinghao Jiang,Xudong Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的解码方法SAKED，通过量化模型各层知识稳定性（KSS）来抑制大视觉语言模型（LVLMs）中的幻觉现象，显著提升生成可靠性。


<details>
  <summary>Details</summary>
Motivation: LVLMs中的幻觉问题带来严重安全与可靠性风险；受人类在不确定时更易出错的启发，作者探究模型内部知识不稳定性与幻觉之间的关系。

Method: 从注意力头、模型层和解码token三方面进行实证分析，发现三类幻觉模式；据此提出SAKED方法，引入层级知识稳定性分数（KSS），对比最稳定与最不稳定层以抑制解码噪声并动态利用最可靠知识。

Result: SAKED无需训练、架构无关，在多种模型、任务和基准上均达到幻觉缓解的SOTA性能。

Conclusion: 模型内部知识的不稳定性是LVLM幻觉的重要成因，通过显式建模并利用知识稳定性可有效缓解幻觉，且无需额外训练。

Abstract: Hallucinations in Large Vision-Language Models (LVLMs) pose significant security and reliability risks in real-world applications. Inspired by the observation that humans are more error-prone when uncertain or hesitant, we investigate how instability in a model 's internal knowledge contributes to LVLM hallucinations. We conduct extensive empirical analyses from three perspectives, namely attention heads, model layers, and decoding tokens, and identify three key hallucination patterns: (i) visual activation drift across attention heads, (ii) pronounced knowledge fluctuations across layers, and (iii) visual focus distraction between neighboring output tokens. Building on these findings, we propose Stability-Aware Knowledge-Enhanced Decoding (SAKED), which introduces a layer-wise Knowledge Stability Score (KSS) to quantify knowledge stability throughout the model. By contrasting the most stability-aware and stability-agnostic layers, SAKED suppresses decoding noise and dynamically leverages the most reliable internal knowledge for faithful token generation. Moreover, SAKED is training-free and can be seamlessly integrated into different architectures. Extensive experiments demonstrate that SAKED achieves state-of-the-art performance for hallucination mitigation on various models, tasks, and benchmarks.

</details>


### [71] [ARK: A Dual-Axis Multimodal Retrieval Benchmark along Reasoning and Knowledge](https://arxiv.org/abs/2602.09839)
*Yijie Lin,Guofeng Ding,Haochen Zhou,Haobin Li,Mouxing Yang,Xi Peng*

Main category: cs.CV

TL;DR: 本文提出了ARK基准，用于评估多模态检索在专业知识和复杂推理方面的能力，涵盖五个知识领域、17个子类和六种推理技能，并测试了23种检索模型，发现知识密集型与推理密集型任务间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有多模态检索基准主要关注日常图像的语义匹配，缺乏对专业领域知识和复杂推理能力的诊断能力。

Method: 构建ARK基准，从知识领域（5大类、17子类）和推理技能（6类）两个维度设计评测；支持单模态与多模态查询/候选；引入针对硬负样本以避免捷径匹配；评估23种主流文本与多模态检索器，并尝试重排序与查询改写等增强方法。

Result: 实验发现知识密集型与推理密集型检索性能差距明显，细粒度视觉与空间推理是持续瓶颈；重排序与查询改写能带来一致提升，但仍有较大提升空间。

Conclusion: ARK为多模态检索提供了更全面的专业知识与推理能力评估框架，揭示了当前模型在复杂跨模态推理上的不足，并指明了改进方向。

Abstract: Existing multimodal retrieval benchmarks largely emphasize semantic matching on daily-life images and offer limited diagnostics of professional knowledge and complex reasoning. To address this gap, we introduce ARK, a benchmark designed to analyze multimodal retrieval from two complementary perspectives: (i) knowledge domains (five domains with 17 subtypes), which characterize the content and expertise retrieval relies on, and (ii) reasoning skills (six categories), which characterize the type of inference over multimodal evidence required to identify the correct candidate. Specifically, ARK evaluates retrieval with both unimodal and multimodal queries and candidates, covering 16 heterogeneous visual data types. To avoid shortcut matching during evaluation, most queries are paired with targeted hard negatives that require multi-step reasoning. We evaluate 23 representative text-based and multimodal retrievers on ARK and observe a pronounced gap between knowledge-intensive and reasoning-intensive retrieval, with fine-grained visual and spatial reasoning emerging as persistent bottlenecks. We further show that simple enhancements such as re-ranking and rewriting yield consistent improvements, but substantial headroom remains.

</details>


### [72] [Kelix Technique Report](https://arxiv.org/abs/2602.09843)
*Boyang Ding,Chenglong Chu,Dunju Zang,Han Li,Jiangxia Cao,Kun Gai,Muhao Wei,Ruiming Tang,Shiyao Wang,Siyang Mao,Xinchen Luo,Yahui Liu,Zhixin Ling,Zhuoran Yang,Ziming Li,Chengru Song,Guorui Zhou,Guowang Zhang,Hao Peng,Hao Wang,Jiaxin Deng,Jin Ouyang,Jinghao Zhang,Lejian Ren,Qianqian Wang,Qigen Hu,Tao Wang,Xingmei Wang,Yiping Yang,Zixing Zhang,Ziqi Wang*

Main category: cs.CV

TL;DR: 本文提出了Kelix模型，一种完全离散的自回归统一模型，旨在弥合离散视觉表示与连续视觉表示在理解能力上的差距。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）多采用离散文本token与连续ViT特征混合的接口，导致模型偏向文本理解、难以充分利用非文本数据的大规模自监督学习；而现有离散视觉token因码本容量有限常丢失信息，导致理解能力弱于连续特征VLMs。

Method: 提出Kelix模型，构建端到端离散的多模态自回归建模范式，通过改进离散视觉token化方法提升信息保留能力，实现完全离散的统一理解与生成。

Result: Kelix显著缩小了离散视觉表示与连续视觉表示在理解任务上的性能差距，验证了全离散自回归多模态建模的可行性与有效性。

Conclusion: Kelix证明了高质量离散视觉表征可支持强理解能力，为真正统一的、自监督驱动的多模态大模型提供了新路径。

Abstract: Autoregressive large language models (LLMs) scale well by expressing diverse tasks as sequences of discrete natural-language tokens and training with next-token prediction, which unifies comprehension and generation under self-supervision. Extending this paradigm to multimodal data requires a shared, discrete representation across modalities. However, most vision-language models (VLMs) still rely on a hybrid interface: discrete text tokens paired with continuous Vision Transformer (ViT) features. Because supervision is largely text-driven, these models are often biased toward understanding and cannot fully leverage large-scale self-supervised learning on non-text data. Recent work has explored discrete visual tokenization to enable fully autoregressive multimodal modeling, showing promising progress toward unified understanding and generation. Yet existing discrete vision tokens frequently lose information due to limited code capacity, resulting in noticeably weaker understanding than continuous-feature VLMs. We present Kelix, a fully discrete autoregressive unified model that closes the understanding gap between discrete and continuous visual representations.

</details>


### [73] [Reason-IAD: Knowledge-Guided Dynamic Latent Reasoning for Explainable Industrial Anomaly Detection](https://arxiv.org/abs/2602.09850)
*Peng Chen,Chao Huang,Yunkang Cao,Chengliang Liu,Wenqiang Wang,Mingbo Yang,Li Shen,Wenqi Ren,Xiaochun Cao*

Main category: cs.CV

TL;DR: 本文提出了Reason-IAD框架，通过知识引导的动态潜在推理机制，提升工业异常检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有通用多模态大模型难以捕捉类别特定的异常模式，导致检测精度和可解释性受限。

Method: 提出Reason-IAD框架，包含检索增强的知识模块、熵驱动的潜在推理机制和动态视觉注入策略，实现细粒度、可解释的异常检测。

Result: 在多个实验中，Reason-IAD持续优于当前最优方法。

Conclusion: Reason-IAD有效提升了工业异常检测的精度与可解释性，为领域专用多模态推理提供了新范式。

Abstract: Industrial anomaly detection demands precise reasoning over fine-grained defect patterns. However, existing multimodal large language models (MLLMs), pretrained on general-domain data, often struggle to capture category-specific anomalies, thereby limiting both detection accuracy and interpretability. To address these limitations, we propose Reason-IAD, a knowledge-guided dynamic latent reasoning framework for explainable industrial anomaly detection. Reason-IAD comprises two core components. First, a retrieval-augmented knowledge module incorporates category-specific textual descriptions into the model input, enabling context-aware reasoning over domain-specific defects. Second, an entropy-driven latent reasoning mechanism conducts iterative exploration within a compact latent space using optimizable latent think tokens, guided by an entropy-based reward that encourages confident and stable predictions. Furthermore, a dynamic visual injection strategy selectively incorporates the most informative image patches into the latent sequence, directing the reasoning process toward regions critical for anomaly detection. Extensive experimental results demonstrate that Reason-IAD consistently outperforms state-of-the-art methods. The code will be publicly available at https://github.com/chenpeng052/Reason-IAD.

</details>


### [74] [Code2World: A GUI World Model via Renderable Code Generation](https://arxiv.org/abs/2602.09856)
*Yuhao Zheng,Li'an Zhong,Yi Wang,Rui Dai,Kaikui Liu,Xiangxiang Chu,Linyuan Lv,Philip Torr,Kevin Qinghong Lin*

Main category: cs.CV

TL;DR: 本文提出Code2World，一种通过生成可渲染代码来模拟下一UI状态的视觉语言编码器，解决了GUI代理中高保真视觉预测与细粒度结构控制难以兼顾的问题；通过构建AndroidCode数据集和渲染感知强化学习方法，在UI预测与下游导航任务上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本和像素的GUI预测方法难以同时实现高视觉保真度和细粒度结构可控性，限制了自主GUI代理的性能。

Method: 提出Code2World视觉语言编码器，将GUI轨迹翻译为高保真HTML并构建AndroidCode数据集（>80K高质量屏幕-动作对）；采用监督微调（SFT）进行格式布局冷启动，再结合以渲染结果为奖励信号的渲染感知强化学习（Render-Aware RL），提升视觉语义保真度与动作一致性。

Result: Code2World-8B在下一UI预测任务中达到最优性能，媲美GPT-5和Gemini-3-Pro-Image；在AndroidWorld导航任务中，使Gemini-2.5-Flash成功率提升+9.5%。

Conclusion: Code2World通过可渲染代码生成范式，有效统一了视觉保真与结构可控性，为GUI代理提供了更可靠、可解释且可扩展的环境建模能力。

Abstract: Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.

</details>


### [75] [Free-GVC: Towards Training-Free Extreme Generative Video Compression with Temporal Coherence](https://arxiv.org/abs/2602.09868)
*Xiaoyue Ling,Chuqin Zhou,Chunyi Li,Yunuo Chen,Yuan Tian,Guo Lu,Wenjun Zhang*

Main category: cs.CV

TL;DR: 本文提出Free-GVC，一种无需训练的生成式视频压缩框架，将视频编码重构为受扩散先验引导的潜在轨迹压缩，在GOP级别操作，并通过自适应质量控制与帧间对齐模块显著提升超低码率下的感知质量与时序一致性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式视频压缩方法对时序相关性利用不足，导致超低码率下出现明显闪烁和时序连贯性下降。

Method: 提出Free-GVC框架：1）以视频扩散模型为先验，将视频编码建模为GOP级潜在轨迹压缩；2）引入自适应质量控制模块，动态构建在线率-感知代理模型以选择最优扩散步数；3）设计帧间对齐模块，通过帧重叠与潜在空间融合增强相邻GOP间的时序一致性。

Result: 在DISTS指标上相较最新神经编解码器DCVC-RT平均降低93.29% BD-Rate；用户研究验证其在超低码率下具有更优的主观感知质量与时序连贯性。

Conclusion: Free-GVC作为一种训练-free的生成式视频压缩方法，通过扩散先验引导的潜在轨迹压缩与跨GOP协同优化策略，有效解决了超低码率下的闪烁与时序失真问题，为生成式视频编码提供了新范式。

Abstract: Building on recent advances in video generation, generative video compression has emerged as a new paradigm for achieving visually pleasing reconstructions. However, existing methods exhibit limited exploitation of temporal correlations, causing noticeable flicker and degraded temporal coherence at ultra-low bitrates. In this paper, we propose Free-GVC, a training-free generative video compression framework that reformulates video coding as latent trajectory compression guided by a video diffusion prior. Our method operates at the group-of-pictures (GOP) level, encoding video segments into a compact latent space and progressively compressing them along the diffusion trajectory. To ensure perceptually consistent reconstruction across GOPs, we introduce an Adaptive Quality Control module that dynamically constructs an online rate-perception surrogate model to predict the optimal diffusion step for each GOP. In addition, an Inter-GOP Alignment module establishes frame overlap and performs latent fusion between adjacent groups, thereby mitigating flicker and enhancing temporal coherence. Experiments show that Free-GVC achieves an average of 93.29% BD-Rate reduction in DISTS over the latest neural codec DCVC-RT, and a user study further confirms its superior perceptual quality and temporal coherence at ultra-low bitrates.

</details>


### [76] [BabyMamba-HAR: Lightweight Selective State Space Models for Efficient Human Activity Recognition on Resource Constrained Devices](https://arxiv.org/abs/2602.09872)
*Mridankan Mandal*

Main category: cs.CV

TL;DR: 本文提出了BabyMamba-HAR框架，包含两种轻量级Mamba启发架构（CI-BabyMamba-HAR和Crossover-BiDir-BabyMamba-HAR），专为资源受限的人体活动识别（HAR）设计，在保持高精度的同时显著降低计算开销（如MACs减少11倍）。


<details>
  <summary>Details</summary>
Motivation: 现有HAR模型在可穿戴/移动设备上受限于内存与算力，而主流注意力机制计算复杂度高；SSMs虽具潜力，但在TinyML场景下的设计尚未充分探索。

Method: 提出两种新型轻量Mamba架构：(1) CI-BabyMamba-HAR采用通道独立但权重共享的stem以抑制噪声传播；(2) Crossover-BiDir-BabyMamba-HAR采用早期融合stem实现通道数无关计算；二者均引入权重绑定双向扫描与轻量时序注意力池化。

Result: Crossover-BiDir-BabyMamba-HAR在8个基准上达86.52%平均宏F1，仅需27K参数和2.21M MACs，性能媲美TinyHAR（86.16%）且MACs减少11倍；消融显示双向扫描提升最多8.42% F1，门控时序注意力比均值池化提升最多8.94% F1。

Conclusion: 本文确立了SSMs作为高效TinyML HAR骨干网络的实用设计原则，验证了其在精度、参数量与计算量间的优异权衡。

Abstract: Human activity recognition (HAR) on wearable and mobile devices is constrained by memory footprint and computational budget, yet competitive accuracy must be maintained across heterogeneous sensor configurations. Selective state space models (SSMs) offer linear time sequence processing with input dependent gating, presenting a compelling alternative to quadratic complexity attention mechanisms. However, the design space for deploying SSMs in the TinyML regime remains largely unexplored. In this paper, BabyMamba-HAR is introduced, a framework comprising two novel lightweight Mamba inspired architectures optimized for resource constrained HAR: (1) CI-BabyMamba-HAR, using a channel independent stem that processes each sensor channel through shared weight, but instance independent transformations to prevent cross channel noise propagation, and (2) Crossover-BiDir-BabyMamba-HAR, using an early fusion stem that achieves channel count independent computational complexity. Both variants incorporate weight tied bidirectional scanning and lightweight temporal attention pooling. Through evaluation across eight diverse benchmarks, it is demonstrated that Crossover-BiDir-BabyMamba-HAR achieves 86.52% average macro F1-score with approximately 27K parameters and 2.21M MACs, matching TinyHAR (86.16%) while requiring 11x fewer MACs on high channel datasets. Systematic ablation studies reveal that bidirectional scanning contributes up to 8.42% F1-score improvement, and gated temporal attention provides up to 8.94% F1-score gain over mean pooling. These findings establish practical design principles for deploying selective state space models as efficient TinyML backbones for HAR.

</details>


### [77] [MVISTA-4D: View-Consistent 4D World Model with Test-Time Action Inference for Robotic Manipulation](https://arxiv.org/abs/2602.09878)
*Jiaxu Wang,Yicheng Jiang,Tianlun He,Jingkai Sun,Qiang Zhang,Junhao He,Jiahang Cao,Zesen Gan,Mingyuan Sun,Qiming Shao,Xiangyu Yue*

Main category: cs.CV

TL;DR: 本文提出了一种具身4D世界模型，支持单视角RGBD输入下的任意视角RGBD生成与时间一致的4D场景预测，并结合测试时动作优化与残差逆动力学模型，实现从想象到动作的端到端闭环。


<details>
  <summary>Details</summary>
Motivation: 现有基于世界模型的机器人操作方法受限于纯图像预测或部分3D几何推理，难以建模完整、几何一致的4D场景动态。

Method: 设计具身4D世界模型，包含跨视角与跨模态（RGB+深度）特征融合机制；引入测试时动作优化（通过生成模型反向传播推断轨迹级隐变量）与残差逆动力学模型将隐变量转化为可执行动作。

Result: 在三个数据集上验证了该方法在4D场景生成和下游操作任务上的优越性能，并通过消融实验揭示了关键设计的有效性。

Conclusion: 所提方法统一了4D世界建模与动作生成，提升了预测的几何一致性与动作可行性，为具身智能提供了新范式。

Abstract: World-model-based imagine-then-act becomes a promising paradigm for robotic manipulation, yet existing approaches typically support either purely image-based forecasting or reasoning over partial 3D geometry, limiting their ability to predict complete 4D scene dynamics. This work proposes a novel embodied 4D world model that enables geometrically consistent, arbitrary-view RGBD generation: given only a single-view RGBD observation as input, the model imagines the remaining viewpoints, which can then be back-projected and fused to assemble a more complete 3D structure across time. To efficiently learn the multi-view, cross-modality generation, we explicitly design cross-view and cross-modality feature fusion that jointly encourage consistency between RGB and depth and enforce geometric alignment across views. Beyond prediction, converting generated futures into actions is often handled by inverse dynamics, which is ill-posed because multiple actions can explain the same transition. We address this with a test-time action optimization strategy that backpropagates through the generative model to infer a trajectory-level latent best matching the predicted future, and a residual inverse dynamics model that turns this trajectory prior into accurate executable actions. Experiments on three datasets demonstrate strong performance on both 4D scene generation and downstream manipulation, and ablations provide practical insights into the key design choices.

</details>


### [78] [AdaTSQ: Pushing the Pareto Frontier of Diffusion Transformers via Temporal-Sensitivity Quantization](https://arxiv.org/abs/2602.09883)
*Shaoqiu Zhang,Zizhong Ding,Kaicheng Yang,Junyi Wu,Xianglong Yan,Xi Li,Bingnan Duan,Jianping Fang,Yulun Zhang*

Main category: cs.CV

TL;DR: 本文提出AdaTSQ，一种针对扩散Transformer（DiTs）的新型后训练量化（PTQ）框架，通过考虑扩散过程中的时间动态特性，在保持生成质量的同时显著提升边缘设备部署效率。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers（DiTs）虽在图像和视频生成中表现优异，但其高计算与内存开销限制了在边缘设备上的部署；现有PTQ方法未考虑扩散过程特有的时间动态性，导致量化效果不佳。

Method: 提出两种核心技术：1）Pareto感知的时间步动态比特宽分配策略，将量化策略搜索建模为带约束的路径查找问题，并用端到端重建误差引导的束搜索实现各时间步下逐层比特宽动态分配；2）Fisher引导的时间校准机制，利用时间维度Fisher信息识别敏感时间步，优先校准对应数据，并与Hessian加权权重优化结合。

Result: 在Flux-Dev、Flux-Schnell、Z-Image和Wan2.1四个先进DiT模型上实验表明，AdaTSQ显著优于SVDQuant和ViDiT-Q等SOTA方法。

Conclusion: AdaTSQ通过显式建模DiTs的时间敏感性，推动了量化效率与生成质量的Pareto前沿，为高效边缘端扩散模型部署提供了新范式。

Abstract: Diffusion Transformers (DiTs) have emerged as the state-of-the-art backbone for high-fidelity image and video generation. However, their massive computational cost and memory footprint hinder deployment on edge devices. While post-training quantization (PTQ) has proven effective for large language models (LLMs), directly applying existing methods to DiTs yields suboptimal results due to the neglect of the unique temporal dynamics inherent in diffusion processes. In this paper, we propose AdaTSQ, a novel PTQ framework that pushes the Pareto frontier of efficiency and quality by exploiting the temporal sensitivity of DiTs. First, we propose a Pareto-aware timestep-dynamic bit-width allocation strategy. We model the quantization policy search as a constrained pathfinding problem. We utilize a beam search algorithm guided by end-to-end reconstruction error to dynamically assign layer-wise bit-widths across different timesteps. Second, we propose a Fisher-guided temporal calibration mechanism. It leverages temporal Fisher information to prioritize calibration data from highly sensitive timesteps, seamlessly integrating with Hessian-based weight optimization. Extensive experiments on four advanced DiTs (e.g., Flux-Dev, Flux-Schnell, Z-Image, and Wan2.1) demonstrate that AdaTSQ significantly outperforms state-of-the-art methods like SVDQuant and ViDiT-Q. Our code will be released at https://github.com/Qiushao-E/AdaTSQ.

</details>


### [79] [SARS: A Novel Face and Body Shape and Appearance Aware 3D Reconstruction System extends Morphable Models](https://arxiv.org/abs/2602.09918)
*Gulraiz Khan,Kenneth Y. Wertheim,Kevin Pimbblet,Waqas Ahmed*

Main category: cs.CV

TL;DR: 本文提出了一种形状与外观感知的3D重建系统（SARS），用于从单张图像中提取人脸和身体信息，实现全身体的高保真3D重建，特别关注年龄、性别、面部关键点等高层语义特征。


<details>
  <summary>Details</summary>
Motivation: 以往3D人像重建方法仅关注全局面部结构或几何，忽略了年龄、性别、面部关键点等高层语义特征，限制了重建的真实性和细节表现力。

Method: 提出模块化管道SARS，融合形状与外观感知机制，从单张图像中联合提取面部与身体信息，建模包括身份、表情、光照、相机参数等多维变量，并显式编码语义特征如面部边界、皱纹等。

Result: 实现了对人类全身体的高质量3D重建，能准确反映年龄、性别、面部关键点及细微几何特征（如曲线、凹陷、皱纹）等高层语义信息。

Conclusion: SARS系统突破了传统3DMM仅建模低层几何与纹理的局限，通过引入语义感知能力，显著提升了单图3D重建的真实性、可解释性与应用潜力。

Abstract: Morphable Models (3DMMs) are a type of morphable model that takes 2D images as inputs and recreates the structure and physical appearance of 3D objects, especially human faces and bodies. 3DMM combines identity and expression blendshapes with a basic face mesh to create a detailed 3D model. The variability in the 3D Morphable models can be controlled by tuning diverse parameters. They are high-level image descriptors, such as shape, texture, illumination, and camera parameters. Previous research in 3D human reconstruction concentrated solely on global face structure or geometry, ignoring face semantic features such as age, gender, and facial landmarks characterizing facial boundaries, curves, dips, and wrinkles. In order to accommodate changes in these high-level facial characteristics, this work introduces a shape and appearance-aware 3D reconstruction system (named SARS by us), a c modular pipeline that extracts body and face information from a single image to properly rebuild the 3D model of the human full body.

</details>


### [80] [A benchmark for video-based laparoscopic skill analysis and assessment](https://arxiv.org/abs/2602.09927)
*Isabel Funke,Sebastian Bodenstedt,Felix von Bechtolsheim,Florian Oehme,Michael Maruschke,Stefanie Herrlich,Jürgen Weitz,Marius Distler,Sören Torge Mees,Stefanie Speidel*

Main category: cs.CV

TL;DR: 本文介绍了LASANA数据集，包含1270段立体腹腔镜训练任务视频，并提供结构化技能评分和任务特异性错误标签，旨在推动基于视频的外科技能评估与错误识别研究。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在腹腔镜手术技能自动评估中的发展和评估受限于标注数据集规模小的问题。

Method: 构建了包含1270段立体视频的LASANA数据集，每段视频配有三位独立评分者汇总的结构化技能评分及任务特异性错误的二值标签；提供各任务的预定义数据划分，并报告了一个深度学习模型的基线结果。

Result: 发布了大规模、多任务、带多维度标注的腹腔镜技能分析数据集LASANA，并提供了标准划分与基线模型性能，为后续研究提供了基准。

Conclusion: LASANA数据集填补了腹腔镜视频技能评估领域高质量标注数据的空白，有助于推动自动化技能评估与错误识别方法的发展与公平比较。

Abstract: Laparoscopic surgery is a complex surgical technique that requires extensive training. Recent advances in deep learning have shown promise in supporting this training by enabling automatic video-based assessment of surgical skills. However, the development and evaluation of deep learning models is currently hindered by the limited size of available annotated datasets. To address this gap, we introduce the Laparoscopic Skill Analysis and Assessment (LASANA) dataset, comprising 1270 stereo video recordings of four basic laparoscopic training tasks. Each recording is annotated with a structured skill rating, aggregated from three independent raters, as well as binary labels indicating the presence or absence of task-specific errors. The majority of recordings originate from a laparoscopic training course, thereby reflecting a natural variation in the skill of participants. To facilitate benchmarking of both existing and novel approaches for video-based skill assessment and error recognition, we provide predefined data splits for each task. Furthermore, we present baseline results from a deep learning model as a reference point for future comparisons.

</details>


### [81] [Monocular Normal Estimation via Shading Sequence Estimation](https://arxiv.org/abs/2602.09929)
*Zongrui Li,Xinhua Ma,Minghui Hu,Yunqing Zhao,Yingchen Yu,Qian Zheng,Chang Liu,Xudong Jiang,Song Bai*

Main category: cs.CV

TL;DR: 本文提出RoSE方法，将单目法向量估计重构为阴影序列估计问题，利用图像到视频生成模型预测阴影序列，并通过最小二乘法转换为法向量图，在真实数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有单目法向量估计方法存在3D错位问题，即法向量图外观正确但重建表面与几何细节不一致，根源在于法向量图中几何差异仅表现为细微颜色变化，模型难以区分和重建不同几何结构。

Method: 提出将法向量估计重构为阴影序列估计的新范式；设计RoSE方法，利用图像到视频生成模型预测多光照下的阴影序列，并通过求解普通最小二乘问题将其转换为法向量图；在合成数据集MultiShade（含多样形状、材质和光照）上训练以提升鲁棒性。

Result: RoSE在真实世界物体级单目法向量估计基准数据集上达到当前最优性能。

Conclusion: 将法向量估计转化为更敏感于几何信息的阴影序列估计是有效解决3D错位问题的新思路，RoSE验证了该范式的有效性与优越性。

Abstract: Monocular normal estimation aims to estimate the normal map from a single RGB image of an object under arbitrary lights. Existing methods rely on deep models to directly predict normal maps. However, they often suffer from 3D misalignment: while the estimated normal maps may appear to have a correct appearance, the reconstructed surfaces often fail to align with the geometric details. We argue that this misalignment stems from the current paradigm: the model struggles to distinguish and reconstruct varying geometry represented in normal maps, as the differences in underlying geometry are reflected only through relatively subtle color variations. To address this issue, we propose a new paradigm that reformulates normal estimation as shading sequence estimation, where shading sequences are more sensitive to various geometric information. Building on this paradigm, we present RoSE, a method that leverages image-to-video generative models to predict shading sequences. The predicted shading sequences are then converted into normal maps by solving a simple ordinary least-squares problem. To enhance robustness and better handle complex objects, RoSE is trained on a synthetic dataset, MultiShade, with diverse shapes, materials, and light conditions. Experiments demonstrate that RoSE achieves state-of-the-art performance on real-world benchmark datasets for object-based monocular normal estimation.

</details>


### [82] [GeoFormer: A Swin Transformer-Based Framework for Scene-Level Building Height and Footprint Estimation from Sentinel Imagery](https://arxiv.org/abs/2602.09932)
*Han Jinzhen,JinByeong Lee,JiSung Kim,MinKyung Cho,DaHee Kim,HongSik Yun*

Main category: cs.CV

TL;DR: 本文提出了GeoFormer，一个开源的Swin Transformer框架，仅使用Sentinel-1/2影像和公开DEM数据，在100米网格上联合估计建筑物高度（BH）和轮廓（BF），显著提升了精度与跨城市泛化能力。


<details>
  <summary>Details</summary>
Motivation: 准确的三维城市数据对气候建模、灾害风险评估和城市规划至关重要，但目前受限于专有传感器依赖或跨城市泛化能力差。

Method: 提出基于Swin Transformer的GeoFormer框架，采用地理区块划分策略确保训练集与测试集空间独立，并融合Sentinel-1/2光学与SAR影像及开放DEM数据进行联合回归估计。

Result: 在54个多样化城市上评估，BH RMSE为3.19 m，BF RMSE为0.05，分别比最强CNN基线提升7.5%和15.3%；跨洲迁移时BH RMSE仍低于3.5 m；消融实验表明DEM对高度估计不可或缺，光学反射率主导SAR，但多源融合效果最佳。

Conclusion: GeoFormer是一种高效、开源且具备强泛化能力的三维城市建模方法，所有代码、权重和全球产品均已公开发布。

Abstract: Accurate three-dimensional urban data are critical for climate modelling, disaster risk assessment, and urban planning, yet remain scarce due to reliance on proprietary sensors or poor cross-city generalisation. We propose GeoFormer, an open-source Swin Transformer framework that jointly estimates building height (BH) and footprint (BF) on a 100 m grid using only Sentinel-1/2 imagery and open DEM data. A geo-blocked splitting strategy ensures strict spatial independence between training and test sets. Evaluated over 54 diverse cities, GeoFormer achieves a BH RMSE of 3.19 m and a BF RMSE of 0.05, improving 7.5% and 15.3% over the strongest CNN baseline, while maintaining under 3.5 m BH RMSE in cross-continent transfer. Ablation studies confirm that DEM is indispensable for height estimation and that optical reflectance dominates over SAR, though multi-source fusion yields the best overall accuracy. All code, weights, and global products are publicly released.

</details>


### [83] [Unbalanced optimal transport for robust longitudinal lesion evolution with registration-aware and appearance-guided priors](https://arxiv.org/abs/2602.09933)
*Melika Qahqaie,Dominik Neumann,Tobias Heimann,Andreas Maier,Veronika A. Zimmer*

Main category: cs.CV

TL;DR: 本文提出了一种基于非平衡最优传输（UOT）的注册感知匹配方法，用于在癌症患者的纵向CT扫描中鲁棒地建立病灶对应关系，能自然处理病灶出现、消失、合并与分裂等情况，并在多项指标上优于传统基于距离的方法。


<details>
  <summary>Details</summary>
Motivation: 标准二分匹配器依赖几何邻近性，在病灶出现、消失、合并或分裂时难以建立可靠对应；而临床中准确评估病灶演化对治疗响应判断至关重要。

Method: 提出基于非平衡最优传输（UOT）的注册感知匹配方法：融合尺寸归一化的几何距离、配准变形场Jacobian所反映的局部可信度、以及可选的图像块级外观一致性作为传输代价；通过相对剪枝稀疏化传输计划，直接输出一对一匹配及新/消失/合并/分裂事件。

Result: 在纵向CT数据上，该方法在边缘检测精度与召回率、病灶状态召回率、病灶图连通组件F1分数等指标上均显著优于仅依赖距离的基线方法。

Conclusion: 基于UOT的注册感知匹配框架无需重训练或启发式规则，即可灵活建模病灶动态演化，为纵向病灶分析提供了更鲁棒、可解释的对应关系建模新范式。

Abstract: Evaluating lesion evolution in longitudinal CT scans of can cer patients is essential for assessing treatment response, yet establishing reliable lesion correspondence across time remains challenging. Standard bipartite matchers, which rely on geometric proximity, struggle when lesions appear, disappear, merge, or split. We propose a registration-aware matcher based on unbalanced optimal transport (UOT) that accommodates unequal lesion mass and adapts priors to patient-level tumor-load changes. Our transport cost blends (i) size-normalized geometry, (ii) local registration trust from the deformation-field Jacobian, and (iii) optional patch-level appearance consistency. The resulting transport plan is sparsified by relative pruning, yielding one-to-one matches as well as new, disappearing, merging, and splitting lesions without retraining or heuristic rules. On longitudinal CT data, our approach achieves consistently higher edge-detection precision and recall, improved lesion-state recall, and superior lesion-graph component F1 scores versus distance-only baselines.

</details>


### [84] [VersaViT: Enhancing MLLM Vision Backbones via Task-Guided Optimization](https://arxiv.org/abs/2602.09934)
*Yikun Liu,Yuan Liu,Shangzhe Di,Haicheng Wang,Zhongyin Zhao,Le Tian,Xiao Zhou,Jie Zhou,Jiangchao Yao,Yanfeng Wang,Weidi Xie*

Main category: cs.CV

TL;DR: 本文探讨了多模态大语言模型（MLLMs）的视觉编码器能否作为通用视觉骨干网络用于经典视觉任务，发现其在密集特征表示上存在不足，并提出VersaViT方法，通过多任务协同后训练提升视觉编码器在多种视觉任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 探究MLLMs的视觉编码器是否可作为通用视觉骨干网络用于经典视觉任务，尤其是其在密集预测任务中的表现。

Method: 提出VersaViT，一种新型多任务协同后训练框架，利用轻量级任务头和多粒度监督优化视觉骨干网络。

Result: VersaViT在多种下游视觉任务（如语义分割、深度估计）中显著提升性能，使视觉骨干网络兼具语言引导推理与像素级理解能力。

Conclusion: MLLMs的视觉编码器虽在高层语义对齐上表现优异，但在密集特征表示上存在缺陷；VersaViT能有效弥补该缺陷，构建出更通用的视觉骨干网络。

Abstract: Multimodal Large Language Models (MLLMs) have recently achieved remarkable success in visual-language understanding, demonstrating superior high-level semantic alignment within their vision encoders. An important question thus arises: Can these encoders serve as versatile vision backbones, capable of reliably performing classic vision-centric tasks as well? To address the question, we make the following contributions: (i) we identify that the vision encoders within MLLMs exhibit deficiencies in their dense feature representations, as evidenced by their suboptimal performance on dense prediction tasks (e.g., semantic segmentation, depth estimation); (ii) we propose VersaViT, a well-rounded vision transformer that instantiates a novel multi-task framework for collaborative post-training. This framework facilitates the optimization of the vision backbone via lightweight task heads with multi-granularity supervision; (iii) extensive experiments across various downstream tasks demonstrate the effectiveness of our method, yielding a versatile vision backbone suited for both language-mediated reasoning and pixel-level understanding.

</details>


### [85] [Bladder Vessel Segmentation using a Hybrid Attention-Convolution Framework](https://arxiv.org/abs/2602.09949)
*Franziska Krauß,Matthias Ege,Zoltan Lovasz,Albrecht Bartz-Schmidt,Igor Tsaur,Oliver Sawodny,Carina Veil*

Main category: cs.CV

TL;DR: 本文提出了一种混合注意力-卷积（HAC）架构，用于膀胱内窥镜视频中血管的鲁棒分割，以支持膀胱癌术中导航；该方法结合Transformer建模全局血管拓扑结构与CNN精细化修复细小血管，并通过结构优化标注和物理感知自监督预训练缓解数据稀缺与伪影干扰问题，在BlaVeS数据集上显著提升精度与clDice指标，并有效抑制黏膜皱褶引起的假阳性。


<details>
  <summary>Details</summary>
Motivation: 膀胱缺乏稳定解剖标志，而内窥镜下可见的血管可作为患者特异性‘血管指纹’用于导航，但现有血管分割方法难以应对内窥镜图像中的稀疏标注、气泡/光照伪影、连续形变及易与血管混淆的黏膜皱褶等临床特异性挑战。

Method: 提出Hybrid Attention-Convolution（HAC）架构：Transformer模块学习全局血管拓扑先验（训练时剔除短/末端分支以强化结构连通性），CNN模块学习残差精修图以恢复细小血管；采用基于临床合理增强的物理感知自监督预训练策略缓解标注稀缺问题。

Result: 在BlaVeS内窥镜视频数据集上，HAC达到0.94准确率、0.61精确率和0.66 clDice，显著优于现有医学分割模型；尤其能有效抑制因膀胱充盈/排空导致的动态黏膜皱褶引发的假阳性。

Conclusion: HAC为膀胱癌术中导航提供了具备结构鲁棒性与临床可靠性的血管分割方案，解决了变形空腔器官内缺乏稳定定位基准的关键难题。

Abstract: Urinary bladder cancer surveillance requires tracking tumor sites across repeated interventions, yet the deformable and hollow bladder lacks stable landmarks for orientation. While blood vessels visible during endoscopy offer a patient-specific "vascular fingerprint" for navigation, automated segmentation is challenged by imperfect endoscopic data, including sparse labels, artifacts like bubbles or variable lighting, continuous deformation, and mucosal folds that mimic vessels. State-of-the-art vessel segmentation methods often fail to address these domain-specific complexities. We introduce a Hybrid Attention-Convolution (HAC) architecture that combines Transformers to capture global vessel topology prior with a CNN that learns a residual refinement map to precisely recover thin-vessel details. To prioritize structural connectivity, the Transformer is trained on optimized ground truth data that exclude short and terminal branches. Furthermore, to address data scarcity, we employ a physics-aware pretraining, that is a self-supervised strategy using clinically grounded augmentations on unlabeled data. Evaluated on the BlaVeS dataset, consisting of endoscopic video frames, our approach achieves high accuracy (0.94) and superior precision (0.61) and clDice (0.66) compared to state-of-the-art medical segmentation models. Crucially, our method successfully suppresses false positives from mucosal folds that dynamically appear and vanish as the bladder fills and empties during surgery. Hence, HAC provides the reliable structural stability required for clinical navigation.

</details>


### [86] [Learning to Detect Baked Goods with Limited Supervision](https://arxiv.org/abs/2602.09979)
*Thomas H. Schmitt,Maximilian Bundscherer,Tobias Bocklet*

Main category: cs.CV

TL;DR: 本文提出了一种在标注数据稀缺条件下，利用弱监督与伪标签传播方法训练YOLOv11检测德国烘焙食品的自动化方案，在非理想部署条件下性能超越全监督基线。


<details>
  <summary>Details</summary>
Motivation: 德国面包店需监控剩余产品以优化生产，但烘焙品类繁多导致全监督训练成本高、难扩展；同时，现有开放词汇检测器（如OWLv2、Grounding DINO）在该任务上表现不足，亟需适配工业场景下小样本、专业化视觉任务的新方法。

Method: 提出两种低监督训练流程：1）结合OWLv2与Grounding DINO定位结果和图像级标签进行弱监督训练；2）利用Segment Anything 2在视频帧中生成伪标签并微调以提升视角鲁棒性；最终选用YOLOv11作为检测模型。

Result: 仅用图像级监督时mAP达0.91；加入伪标签微调后，在非理想部署条件下性能提升19.3%，且整体方案超越全监督基线模型。

Conclusion: 验证了弱监督+伪标签传播策略在真实工业视觉任务中的有效性，为标注稀缺的专业化场景提供了可扩展、低成本的落地路径。

Abstract: Monitoring leftover products provides valuable insights that can be used to optimize future production. This is especially important for German bakeries because freshly baked goods have a very short shelf life. Automating this process can reduce labor costs, improve accuracy, and streamline operations. We propose automating this process using an object detection model to identify baked goods from images. However, the large diversity of German baked goods makes fully supervised training prohibitively expensive and limits scalability. Although open-vocabulary detectors (e.g., OWLv2, Grounding DINO) offer lexibility, we demonstrate that they are insufficient for our task. While motivated by bakeries, our work addresses the broader challenges of deploying computer vision in industries, where tasks are specialized and annotated datasets are scarce. We compile dataset splits with varying supervision levels, covering 19 classes of baked goods. We propose two training workflows to train an object detection model with limited supervision. First, we combine OWLv2 and Grounding DINO localization with image-level supervision to train the model in a weakly supervised manner. Second, we improve viewpoint robustness by fine-tuning on video frames annotated using Segment Anything 2 as a pseudo-label propagation model. Using these workflows, we train YOLOv11 for our detection task due to its favorable speed accuracy tradeoff. Relying solely on image-level supervision, the model achieves a mean Average Precision (mAP) of 0.91. Finetuning with pseudo-labels raises model performance by 19.3% under non-ideal deployment conditions. Combining these workflows trains a model that surpasses our fully-supervised baseline model under non-ideal deployment conditions, despite relying only on image-level supervision.

</details>


### [87] [Coupled Inference in Diffusion Models for Semantic Decomposition](https://arxiv.org/abs/2602.09983)
*Calvin Yeung,Ali Zakeri,Zhuowen Zou,Mohsen Imani*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型耦合推理的语义分解框架，将分解建模为逆问题，并通过重构驱动的引导项耦合多个扩散过程，性能优于共振器网络。


<details>
  <summary>Details</summary>
Motivation: 受Hopfield网络与扩散模型相似性的启发，以及对有效语义分解（如识别、推理、编辑）中解耦合绑定表示的需求，作者试图构建更强大的分解框架。

Method: 提出基于扩散模型的耦合推理框架：将语义分解建模为逆问题；引入重构驱动的引导项以耦合多个扩散过程，使各因子估计的绑定结果逼近原始绑定向量；设计新型迭代采样策略提升性能。

Result: 实验证明该框架在多种合成语义分解任务上均优于共振器网络；并证明注意力机制共振器网络是本框架的一个特例。

Conclusion: 耦合扩散模型为语义分解提供了更灵活、更强大的新范式，统一并拓展了基于绑定与共振器的思想。

Abstract: Many visual scenes can be described as compositions of latent factors. Effective recognition, reasoning, and editing often require not only forming such compositional representations, but also solving the decomposition problem. One popular choice for constructing these representations is through the binding operation. Resonator networks, which can be understood as coupled Hopfield networks, were proposed as a way to perform decomposition on such bound representations. Recent works have shown notable similarities between Hopfield networks and diffusion models. Motivated by these observations, we introduce a framework for semantic decomposition using coupled inference in diffusion models. Our method frames semantic decomposition as an inverse problem and couples the diffusion processes using a reconstruction-driven guidance term that encourages the composition of factor estimates to match the bound vector. We also introduce a novel iterative sampling scheme that improves the performance of our model. Finally, we show that attention-based resonator networks are a special case of our framework. Empirically, we demonstrate that our coupled inference framework outperforms resonator networks across a range of synthetic semantic decomposition tasks.

</details>


### [88] [Efficient Special Stain Classification](https://arxiv.org/abs/2602.09989)
*Oskar Thaeter,Christian Grashei,Anette Haas,Elisa Schmoeckel,Han Li,Peter J. Schüffler*

Main category: cs.CV

TL;DR: 本文比较了多实例学习（MIL）和轻量级缩略图方法在全切片图像中自动分类16种常用组织染色（包括H&E及14种特殊染色）的性能，结果表明缩略图方法在泛化性、速度和实用性上更具优势，适用于数字病理常规视觉质控。


<details>
  <summary>Details</summary>
Motivation: 维持组织切片染色类型准确的元数据对临床档案质量控制和计算病理数据集完整性至关重要，但目前缺乏高效可靠的自动化染色分类方法。

Method: 对比评估了多实例学习（MIL）流程与新提出的轻量级缩略图（thumbnail-based）分类方法，在内部测试集和外部TCGA数据集上以宏F1和加权F1为指标进行性能比较，并分析处理吞吐量。

Result: 在内部测试集上，MIL宏F1达0.941（16类）和0.969（14类合并）；缩略图法分别为0.897和0.953；在外部TCGA数据上，缩略图法加权F1（0.843）优于MIL（0.807）；且缩略图法吞吐量高出两个数量级（5.635 vs. 0.018 slides/s）。

Conclusion: 缩略图法是一种可扩展、鲁棒性强的染色自动分类方案，适合部署于日常数字病理视觉质量控制流程。

Abstract: Stains are essential in histopathology to visualize specific tissue characteristics, with Haematoxylin and Eosin (H&E) serving as the clinical standard. However, pathologists frequently
  utilize a variety of special stains for the diagnosis of specific morphologies. Maintaining accurate metadata for these slides is critical for quality control in clinical archives and for
  the integrity of computational pathology datasets. In this work, we compare two approaches for automated classification of stains using whole slide images, covering the 14 most commonly
  used special stains in our institute alongside standard and frozen-section H&E. We evaluate a Multi-Instance Learning (MIL) pipeline and a proposed lightweight thumbnail-based approach.
  On internal test data, MIL achieved the highest performance (macro F1: 0.941 for 16 classes; 0.969 for 14 merged classes), while the thumbnail approach remained competitive (0.897 and
  0.953, respectively). On external TCGA data, the thumbnail model generalized best (weighted F1: 0.843 vs. 0.807 for MIL). The thumbnail approach also increased throughput by two orders of
  magnitude (5.635 vs. 0.018 slides/s for MIL with all patches). We conclude that thumbnail-based classification provides a scalable and robust solution for routine visual quality control
  in digital pathology workflows.

</details>


### [89] [Fake-HR1: Rethinking reasoning of vision language model for synthetic image detection](https://arxiv.org/abs/2602.10042)
*Changjiang Jiang,Xinkuan Sha,Fengchang Yu,Jingjing Liu,Jian Liu,Mingqi Fang,Chenfeng Zhang,Wei Lu*

Main category: cs.CV

TL;DR: 本文提出Fake-HR1模型，首次实现对生成图像检测任务中是否需要推理的自适应判断，通过两阶段训练框架（混合微调+在线强化学习）提升检测性能与响应效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于思维链（CoT）的合成图像检测方法存在推理过长导致资源开销大、对明显伪造图像冗余推理的问题。

Method: 提出Fake-HR1混合推理模型，设计两阶段训练框架：第一阶段为混合微调（HFT）用于冷启动初始化；第二阶段为基于混合推理分组策略优化（HGRPO）的在线强化学习，隐式学习何时选择合适推理模式。

Result: Fake-HR1在不同查询类型上自适应执行推理，在推理能力与生成图像检测性能上均超越现有大语言模型，并显著提升响应效率。

Conclusion: Fake-HR1验证了自适应推理机制在生成内容检测中的有效性，为兼顾准确性与效率的检测范式提供了新思路。

Abstract: Recent studies have demonstrated that incorporating Chain-of-Thought (CoT) reasoning into the detection process can enhance a model's ability to detect synthetic images. However, excessively lengthy reasoning incurs substantial resource overhead, including token consumption and latency, which is particularly redundant when handling obviously generated forgeries. To address this issue, we propose Fake-HR1, a large-scale hybrid-reasoning model that, to the best of our knowledge, is the first to adaptively determine whether reasoning is necessary based on the characteristics of the generative detection task. To achieve this, we design a two-stage training framework: we first perform Hybrid Fine-Tuning (HFT) for cold-start initialization, followed by online reinforcement learning with Hybrid-Reasoning Grouped Policy Optimization (HGRPO) to implicitly learn when to select an appropriate reasoning mode. Experimental results show that Fake-HR1 adaptively performs reasoning across different types of queries, surpassing existing LLMs in both reasoning ability and generative detection performance, while significantly improving response efficiency.

</details>


### [90] [Simple Image Processing and Similarity Measures Can Link Data Samples across Databases through Brain MRI](https://arxiv.org/abs/2602.10043)
*Gaurang Sharma,Harri Polonen,Juha Pajula,Jutta Suksi,Jussi Tohka*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练、计算高效的方法，仅通过标准预处理和图像相似度计算，即可在去颅骨后的T1加权MRI中实现高精度个体匹配，揭示了当前脑影像数据共享中的潜在隐私风险。


<details>
  <summary>Details</summary>
Motivation: 尽管MRI数据在共享前已进行去颅骨等匿名化处理，但脑实质仍含有可识别个体的独特生物特征，存在跨数据库重识别风险；而现有监管框架要求基于‘合理性’评估此类风险，亟需更可靠、易实施的风险评估方法。

Method: 采用标准MRI预处理流程（如配准、标准化），随后直接计算去颅骨后T1加权图像之间的相似度（如互信息或归一化互相关），无需深度学习模型或大量训练数据。

Result: 在不同时间点、扫描仪型号、空间分辨率和采集协议下，该方法实现了近似完美的个体匹配准确率，且对认知衰退等生理变化具有鲁棒性。

Conclusion: 去颅骨MRI本身即构成强生物标识符，仅靠传统匿名化不足以保障隐私；应推动政策更新，将此类低门槛、高风险的重识别能力纳入数据共享合规性评估。

Abstract: Head Magnetic Resonance Imaging (MRI) is routinely collected and shared for research under strict regulatory frameworks. These frameworks require removing potential identifiers before sharing. But, even after skull stripping, the brain parenchyma contains unique signatures that can match other MRIs from the same participants across databases, posing a privacy risk if additional data features are available. Current regulatory frameworks often mandate evaluating such risks based on the assessment of a certain level of reasonableness. Prior studies have already suggested that a brain MRI could enable participant linkage, but they have relied on training-based or computationally intensive methods.
  Here, we demonstrate that linking an individual's skull-stripped T1-weighted MRI, which may lead to re-identification if other identifiers are available, is possible using standard preprocessing followed by image similarity computation. Nearly perfect linkage accuracy was achieved in matching data samples across various time intervals, scanner types, spatial resolutions, and acquisition protocols, despite potential cognitive decline, simulating MRI matching across databases. These results aim to contribute meaningfully to the development of thoughtful, forward-looking policies in medical data sharing.

</details>


### [91] [Conformal Prediction Sets for Instance Segmentation](https://arxiv.org/abs/2602.10045)
*Kerri Lu,Dan M. Kluger,Stephen Bates,Sherrie Wang*

Main category: cs.CV

TL;DR: 本文提出了一种用于实例分割的共形预测算法，能为每个像素生成具有统计保证的自适应置信集，确保其中至少一个预测与真实掩码具有高IoU。该方法在农业田块划分、细胞分割和车辆检测任务中验证有效，并优于多种基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有实例分割模型缺乏原则性的不确定性量化能力，预测结果未校准，且无法保证预测掩码与真实掩码接近。

Method: 引入共形预测算法，针对图像中任意像素坐标生成实例预测的置信集，并提供关于高IoU覆盖概率的可证明保证；支持渐近和有限样本两种统计保证版本。

Result: 在农业田块划分、细胞分割和车辆检测任务中，该方法生成的置信集大小随查询难度自适应变化，且准确达到目标覆盖率，性能优于Learn Then Test、Conformal Risk Control及基于形态学膨胀的方法。

Conclusion: 所提共形预测算法为实例分割提供了首个具备统计保证的不确定性量化框架，兼具理论严谨性与实际有效性。

Abstract: Current instance segmentation models achieve high performance on average predictions, but lack principled uncertainty quantification: their outputs are not calibrated, and there is no guarantee that a predicted mask is close to the ground truth. To address this limitation, we introduce a conformal prediction algorithm to generate adaptive confidence sets for instance segmentation. Given an image and a pixel coordinate query, our algorithm generates a confidence set of instance predictions for that pixel, with a provable guarantee for the probability that at least one of the predictions has high Intersection-Over-Union (IoU) with the true object instance mask. We apply our algorithm to instance segmentation examples in agricultural field delineation, cell segmentation, and vehicle detection. Empirically, we find that our prediction sets vary in size based on query difficulty and attain the target coverage, outperforming existing baselines such as Learn Then Test, Conformal Risk Control, and morphological dilation-based methods. We provide versions of the algorithm with asymptotic and finite sample guarantees.

</details>


### [92] [Spatio-Temporal Attention for Consistent Video Semantic Segmentation in Automated Driving](https://arxiv.org/abs/2602.10052)
*Serin Varghese,Kevin Ross,Fabian Hueger,Kira Maag*

Main category: cs.CV

TL;DR: 本文提出了一种时空注意力（STA）机制，扩展了Transformer的注意力模块以融合多帧上下文信息，从而提升视频语义分割的时序一致性和精度，且计算高效、易于集成。


<details>
  <summary>Details</summary>
Motivation: 现有语义分割模型独立处理视频帧，忽略了时间一致性，限制了动态场景下的准确性和稳定性。

Method: 设计了一种Spatio-Temporal Attention（STA）机制，对标准自注意力进行改造，使其能处理时空特征序列，在保持计算效率的同时仅需对现有架构做最小改动。

Result: 在Cityscapes和BDD100k数据集上，时序一致性指标提升9.20个百分点，mIoU最高提升1.76个百分点，验证了STA在轻量及大规模Transformer模型上的有效性与泛化性。

Conclusion: STA是一种有效、通用且高效的架构增强方法，显著提升了视频语义分割性能，尤其适用于需要高时序稳定性的环境感知任务。

Abstract: Deep neural networks, especially transformer-based architectures, have achieved remarkable success in semantic segmentation for environmental perception. However, existing models process video frames independently, thus failing to leverage temporal consistency, which could significantly improve both accuracy and stability in dynamic scenes. In this work, we propose a Spatio-Temporal Attention (STA) mechanism that extends transformer attention blocks to incorporate multi-frame context, enabling robust temporal feature representations for video semantic segmentation. Our approach modifies standard self-attention to process spatio-temporal feature sequences while maintaining computational efficiency and requiring minimal changes to existing architectures. STA demonstrates broad applicability across diverse transformer architectures and remains effective across both lightweight and larger-scale models. A comprehensive evaluation on the Cityscapes and BDD100k datasets shows substantial improvements of 9.20 percentage points in temporal consistency metrics and up to 1.76 percentage points in mean intersection over union compared to single-frame baselines. These results demonstrate STA as an effective architectural enhancement for video-based semantic segmentation applications.

</details>


### [93] [Can Image Splicing and Copy-Move Forgery Be Detected by the Same Model? Forensim: An Attention-Based State-Space Approach](https://arxiv.org/abs/2602.10079)
*Soumyaroop Nandi,Prem Natarajan*

Main category: cs.CV

TL;DR: Forensim是一种基于注意力机制的状态空间框架，用于图像伪造检测，能同时定位伪造区域（目标）和源区域，支持拼接与复制移动伪造的统一检测。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖伪影线索检测伪造区域，难以理解上下文；在如抗议图像等场景中，仅定位伪造区域可能导致错误解读，因此需联合定位源与目标区域。

Method: 提出一种视觉状态空间模型，利用归一化注意力图识别内部相似性，并结合基于区域的块注意力模块区分伪造区域，输出三类掩码（原始、源、目标），支持端到端训练。

Result: 在标准基准上达到最先进性能，并发布新数据集CMFD-Anything以弥补现有复制移动伪造数据集的不足。

Conclusion: Forensim通过联合源-目标定位和统一架构，显著提升了图像伪造检测的准确性与可解释性。

Abstract: We introduce Forensim, an attention-based state-space framework for image forgery detection that jointly localizes both manipulated (target) and source regions. Unlike traditional approaches that rely solely on artifact cues to detect spliced or forged areas, Forensim is designed to capture duplication patterns crucial for understanding context. In scenarios such as protest imagery, detecting only the forged region, for example a duplicated act of violence inserted into a peaceful crowd, can mislead interpretation, highlighting the need for joint source-target localization. Forensim outputs three-class masks (pristine, source, target) and supports detection of both splicing and copy-move forgeries within a unified architecture. We propose a visual state-space model that leverages normalized attention maps to identify internal similarities, paired with a region-based block attention module to distinguish manipulated regions. This design enables end-to-end training and precise localization. Forensim achieves state-of-the-art performance on standard benchmarks. We also release CMFD-Anything, a new dataset addressing limitations of existing copy-move forgery datasets.

</details>


### [94] [4RC: 4D Reconstruction via Conditional Querying Anytime and Anywhere](https://arxiv.org/abs/2602.10094)
*Yihang Luo,Shangchen Zhou,Yushi Lan,Xingang Pan,Chen Change Loy*

Main category: cs.CV

TL;DR: 4RC是一种统一的前馈框架，用于从单目视频中进行4D重建，通过一次编码、任意时刻查询的范式，联合学习密集场景几何与运动动力学。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将运动与几何解耦，或仅生成稀疏轨迹、双视图场景流等有限的4D属性，缺乏对完整4D时空结构的联合建模能力。

Method: 提出encode-once, query-anywhere and anytime范式：用transformer主干网络将整个视频编码为紧凑的时空潜在空间，条件解码器可高效查询任意帧、任意时间戳下的3D几何与运动；采用最小化因子化表示每视角4D属性，分解为基几何与时间依赖的相对运动。

Result: 在广泛的4D重建任务上，4RC性能优于先前及同期方法。

Conclusion: 4RC实现了对密集几何与运动动力学的联合建模，为单目视频4D重建提供了更统一、高效且表达能力强的新范式。

Abstract: We present 4RC, a unified feed-forward framework for 4D reconstruction from monocular videos. Unlike existing approaches that typically decouple motion from geometry or produce limited 4D attributes such as sparse trajectories or two-view scene flow, 4RC learns a holistic 4D representation that jointly captures dense scene geometry and motion dynamics. At its core, 4RC introduces a novel encode-once, query-anywhere and anytime paradigm: a transformer backbone encodes the entire video into a compact spatio-temporal latent space, from which a conditional decoder can efficiently query 3D geometry and motion for any query frame at any target timestamp. To facilitate learning, we represent per-view 4D attributes in a minimally factorized form by decomposing them into base geometry and time-dependent relative motion. Extensive experiments demonstrate that 4RC outperforms prior and concurrent methods across a wide range of 4D reconstruction tasks.

</details>


### [95] [Causality in Video Diffusers is Separable from Denoising](https://arxiv.org/abs/2602.10095)
*Xingjian Bai,Guande He,Zhengqi Li,Eli Shechtman,Xun Huang,Zongze Wu*

Main category: cs.CV

TL;DR: 本文提出了一种可分离的因果扩散模型（SCD），将时间因果推理与多步去噪渲染解耦，提升了视频生成效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有因果扩散模型将时间推理与迭代去噪紧密耦合，导致计算冗余；作者通过探针分析发现早期层特征稳定、深层注意力稀疏，表明二者可分离。

Method: 提出Separable Causal Diffusion（SCD）架构：用因果Transformer编码器进行单次/每帧时间建模，用轻量扩散解码器负责多步帧内渲染。

Result: 在合成与真实数据集的预训练和后训练任务中，SCD显著提升吞吐量和单帧延迟，同时保持或超越强基线的生成质量。

Conclusion: 因果推理与去噪渲染在视频扩散模型中是可分离的，SCD通过解耦设计实现了效率与性能的双重提升。

Abstract: Causality -- referring to temporal, uni-directional cause-effect relationships between components -- underlies many complex generative processes, including videos, language, and robot trajectories. Current causal diffusion models entangle temporal reasoning with iterative denoising, applying causal attention across all layers, at every denoising step, and over the entire context. In this paper, we show that the causal reasoning in these models is separable from the multi-step denoising process. Through systematic probing of autoregressive video diffusers, we uncover two key regularities: (1) early layers produce highly similar features across denoising steps, indicating redundant computation along the diffusion trajectory; and (2) deeper layers exhibit sparse cross-frame attention and primarily perform intra-frame rendering. Motivated by these findings, we introduce Separable Causal Diffusion (SCD), a new architecture that explicitly decouples once-per-frame temporal reasoning, via a causal transformer encoder, from multi-step frame-wise rendering, via a lightweight diffusion decoder. Extensive experiments on both pretraining and post-training tasks across synthetic and real benchmarks show that SCD significantly improves throughput and per-frame latency while matching or surpassing the generation quality of strong causal diffusion baselines.

</details>


### [96] [VideoWorld 2: Learning Transferable Knowledge from Real-world Videos](https://arxiv.org/abs/2602.10102)
*Zhongwei Ren,Yunchao Wei,Xiao Yu,Guixun Luo,Yao Zhao,Bingyi Kang,Jiashi Feng,Xiaojie Jin*

Main category: cs.CV

TL;DR: VideoWorld 2 提出动态增强的潜在动力学模型（dLDM），利用预训练视频扩散模型解耦动作动力学与视觉外观，从而从原始真实视频中学习可迁移的任务相关动力学表征，并在手工制作任务和机器人操作（CALVIN）上显著提升成功率与长程执行能力。


<details>
  <summary>Details</summary>
Motivation: 从无标签的真实世界视频中学习可迁移知识并应用于新环境，是智能体的关键能力；此前方法难以在复杂真实视频任务中稳定运行。

Method: 提出动态增强的潜在动力学模型（dLDM），用预训练视频扩散模型建模视觉外观，使dLDM专注于学习紧凑、有意义的任务相关潜在动力学编码，并通过自回归建模学习策略与支持长视野推理。

Result: 在真实手工制作任务中任务成功率最高提升70%，生成连贯的长执行视频；在机器人领域，利用Open-X数据集学习操作知识，显著提升CALVIN任务性能。

Conclusion: 直接从原始视频中学习可迁移的世界知识具有巨大潜力，VideoWorld 2为该方向提供了首个系统性探索与开源基础。

Abstract: Learning transferable knowledge from unlabeled video data and applying it in new environments is a fundamental capability of intelligent agents. This work presents VideoWorld 2, which extends VideoWorld and offers the first investigation into learning transferable knowledge directly from raw real-world videos. At its core, VideoWorld 2 introduces a dynamic-enhanced Latent Dynamics Model (dLDM) that decouples action dynamics from visual appearance: a pretrained video diffusion model handles visual appearance modeling, enabling the dLDM to learn latent codes that focus on compact and meaningful task-related dynamics. These latent codes are then modeled autoregressively to learn task policies and support long-horizon reasoning. We evaluate VideoWorld 2 on challenging real-world handcraft making tasks, where prior video generation and latent-dynamics models struggle to operate reliably. Remarkably, VideoWorld 2 achieves up to 70% improvement in task success rate and produces coherent long execution videos. In robotics, we show that VideoWorld 2 can acquire effective manipulation knowledge from the Open-X dataset, which substantially improves task performance on CALVIN. This study reveals the potential of learning transferable world knowledge directly from raw videos, with all code, data, and models to be open-sourced for further research.

</details>


### [97] [Olaf-World: Orienting Latent Actions for Video World Modeling](https://arxiv.org/abs/2602.10104)
*Yuxin Jiang,Yuchao Gu,Ivor W. Tsang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 本文提出SeqΔ-REPA方法，通过利用动作的可观测语义效果（时间特征差异）作为跨场景共享参考，对齐潜在动作语义，从而提升无标签视频中动作表征的泛化性与可迁移性；基于此构建Olaf-World框架，实现从大规模被动视频中预训练可控世界模型。


<details>
  <summary>Details</summary>
Motivation: 现有潜动作学习因仅在单个视频片段内建模，缺乏跨上下文的动作语义对齐机制，导致学得的潜在动作空间纠缠场景特异性线索、缺乏统一坐标系，难以迁移。

Method: 提出SeqΔ-REPA——一种序列级控制-效果对齐目标，将潜在动作锚定于冻结的自监督视频编码器提取的时间特征差（Δ）上；在此基础上构建Olaf-World流程，用于从无动作标签的大规模被动视频中预训练动作条件化世界模型。

Result: 实验表明该方法学习到更结构化的潜在动作空间，在零样本动作迁移和新控制接口的数据高效适配方面均优于现有SOTA方法。

Conclusion: 利用可观测的动作语义效果（而非隐变量本身）作为跨场景对齐锚点，是提升潜动作泛化能力的有效范式；SeqΔ-REPA与Olaf-World为无监督动作表征学习与世界模型扩展提供了新路径。

Abstract: Scaling action-controllable world models is limited by the scarcity of action labels. While latent action learning promises to extract control interfaces from unlabeled video, learned latents often fail to transfer across contexts: they entangle scene-specific cues and lack a shared coordinate system. This occurs because standard objectives operate only within each clip, providing no mechanism to align action semantics across contexts. Our key insight is that although actions are unobserved, their semantic effects are observable and can serve as a shared reference. We introduce Seq$Δ$-REPA, a sequence-level control-effect alignment objective that anchors integrated latent action to temporal feature differences from a frozen, self-supervised video encoder. Building on this, we present Olaf-World, a pipeline that pretrains action-conditioned video world models from large-scale passive video. Extensive experiments demonstrate that our method learns a more structured latent action space, leading to stronger zero-shot action transfer and more data-efficient adaptation to new control interfaces than state-of-the-art baselines.

</details>


### [98] [ConsID-Gen: View-Consistent and Identity-Preserving Image-to-Video Generation](https://arxiv.org/abs/2602.10113)
*Mingyang Wu,Ashirbad Mishra,Soumik Dey,Shuo Xing,Naveen Ravipati,Hansi Wu,Binbin Li,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 本文提出ConsID-Gen框架与ConsIDVid数据集，通过多视角辅助和双流编码器提升图像到视频生成中物体身份一致性和时序连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有图像到视频（I2V）方法在视角变化下难以保持细粒度物体身份，易出现外观漂移与几何失真，主因是单视角2D观测稀疏及跨模态对齐弱。

Method: 构建大规模物体中心数据集ConsIDVid及配套评测基准ConsIDVid-Bench；提出ConsID-Gen框架，利用未定姿辅助视图增强首帧，并设计语义-结构双流视觉几何编码器与文本-视觉连接器，为Diffusion Transformer提供统一条件输入。

Result: 在ConsIDVid-Bench上多项指标超越Wan2.1、HunyuanVideo等主流视频生成模型，显著提升身份保真度与时序连贯性。

Conclusion: 从数据与模型双路径出发，多视角建模与强跨模态融合可有效缓解I2V中的身份退化问题，为高质量可控视频生成提供新范式。

Abstract: Image-to-Video generation (I2V) animates a static image into a temporally coherent video sequence following textual instructions, yet preserving fine-grained object identity under changing viewpoints remains a persistent challenge. Unlike text-to-video models, existing I2V pipelines often suffer from appearance drift and geometric distortion, artifacts we attribute to the sparsity of single-view 2D observations and weak cross-modal alignment. Here we address this problem from both data and model perspectives. First, we curate ConsIDVid, a large-scale object-centric dataset built with a scalable pipeline for high-quality, temporally aligned videos, and establish ConsIDVid-Bench, where we present a novel benchmarking and evaluation framework for multi-view consistency using metrics sensitive to subtle geometric and appearance deviations. We further propose ConsID-Gen, a view-assisted I2V generation framework that augments the first frame with unposed auxiliary views and fuses semantic and structural cues via a dual-stream visual-geometric encoder as well as a text-visual connector, yielding unified conditioning for a Diffusion Transformer backbone. Experiments across ConsIDVid-Bench demonstrate that ConsID-Gen consistently outperforms in multiple metrics, with the best overall performance surpassing leading video generation models like Wan2.1 and HunyuanVideo, delivering superior identity fidelity and temporal coherence under challenging real-world scenarios. We will release our model and dataset at https://myangwu.github.io/ConsID-Gen.

</details>


### [99] [Quantum Multiple Rotation Averaging](https://arxiv.org/abs/2602.10115)
*Shuteng Wang,Natacha Kuete Meli,Michael Möller,Vladislav Golyanik*

Main category: cs.CV

TL;DR: 本文提出IQARS算法，首次将多旋转平均（MRA）问题重构为可在量子退火器上求解的局部二次非凸子问题序列，摆脱凸松弛依赖，更好保持旋转流形几何结构，并在实验中比最优经典方法Shonan提升约12%精度。


<details>
  <summary>Details</summary>
Motivation: 现有经典方法（如L1-IRLS和Shonan）易陷入局部极小、依赖破坏旋转流形几何结构的凸松弛，在高噪声下精度下降。

Method: 提出IQARS：将MRA分解为一系列局部二次非凸子问题，经二值化后适配量子退火硬件，利用量子隧穿与并行性进行高效搜索，不依赖凸松弛。

Result: 在合成与真实数据集上验证，当前受限规模的D-Wave量子退火器上，IQARS精度比Shonan高约12%。

Conclusion: IQARS是首个面向MRA的量子退火算法，兼顾几何保真性与硬件适配性，为噪声鲁棒的旋转同步提供了新范式，尽管受当前量子硬件规模限制，已展现初步优势。

Abstract: Multiple rotation averaging (MRA) is a fundamental optimization problem in 3D vision and robotics that aims to recover globally consistent absolute rotations from noisy relative measurements. Established classical methods, such as L1-IRLS and Shonan, face limitations including local minima susceptibility and reliance on convex relaxations that fail to preserve the exact manifold geometry, leading to reduced accuracy in high-noise scenarios. We introduce IQARS (Iterative Quantum Annealing for Rotation Synchronization), the first algorithm that reformulates MRA as a sequence of local quadratic non-convex sub-problems executable on quantum annealers after binarization, to leverage inherent hardware advantages. IQARS removes convex relaxation dependence and better preserves non-Euclidean rotation manifold geometry while leveraging quantum tunneling and parallelism for efficient solution space exploration. We evaluate IQARS's performance on synthetic and real-world datasets. While current annealers remain in their nascent phase and only support solving problems of limited scale with constrained performance, we observed that IQARS on D-Wave annealers can already achieve ca. 12% higher accuracy than Shonan, i.e., the best-performing classical method evaluated empirically.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [100] [Overview of PAN 2026: Voight-Kampff Generative AI Detection, Text Watermarking, Multi-Author Writing Style Analysis, Generative Plagiarism Detection, and Reasoning Trajectory Detection](https://arxiv.org/abs/2602.09147)
*Janek Bevendorff,Maik Fröbe,André Greiner-Petter,Andreas Jakoby,Maximilian Mayerl,Preslav Nakov,Henry Plutz,Martin Potthast,Benno Stein,Minh Ngoc Ta,Yuxia Wang,Eva Zangerle*

Main category: cs.CL

TL;DR: PAN 2026 workshop introduces five stylometry and text forensics tasks—including AI detection, text watermarking, multi-author analysis, generative plagiarism detection, and reasoning trajectory detection—with emphasis on reproducibility via Docker/TIRA.


<details>
  <summary>Details</summary>
Motivation: To advance computational stylometry and text forensics through objective, reproducible evaluation.

Method: Organizing five benchmark tasks with standardized evaluation protocols and requiring Docker-based software submissions via the TIRA platform.

Result: Five defined tasks for PAN 2026, including two new ones (Voight-Kampff AI Detection and Reasoning Trajectory Detection) and three continued tasks, supported by a long-standing reproducible infrastructure.

Conclusion: PAN 2026 reinforces the community’s commitment to rigorous, reproducible evaluation in authorship analysis and AI-generated text forensics.

Abstract: The goal of the PAN workshop is to advance computational stylometry and text forensics via objective and reproducible evaluation. In 2026, we run the following five tasks: (1) Voight-Kampff Generative AI Detection, particularly in mixed and obfuscated authorship scenarios, (2) Text Watermarking, a new task that aims to find new and benchmark the robustness of existing text watermarking schemes, (3) Multi-author Writing Style Analysis, a continued task that aims to find positions of authorship change, (4) Generative Plagiarism Detection, a continued task that targets source retrieval and text alignment between generated text and source documents, and (5) Reasoning Trajectory Detection, a new task that deals with source detection and safety detection of LLM-generated or human-written reasoning trajectories. As in previous years, PAN invites software submissions as easy-to-reproduce Docker containers for most of the tasks. Since PAN 2012, more than 1,100 submissions have been made this way via the TIRA experimentation platform.

</details>


### [101] [Measuring Inclusion in Interaction: Inclusion Analytics for Human-AI Collaborative Learning](https://arxiv.org/abs/2602.09269)
*Jaeyoon Choi,Nia Nixon*

Main category: cs.CL

TL;DR: 本文提出了一种基于话语分析的‘包容性分析’框架，用于动态、交互式地评估协作问题解决（CPS）中的包容性，涵盖参与公平性、情感氛围和认知公平性三个维度，并通过模拟与实证数据验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有对AI与教育中包容性、公平性和可及性的评估多依赖粗粒度样本描述或事后自我报告，难以捕捉协作问题解决过程中动态演化的包容性实践。

Method: 构建基于话语的‘包容性分析’框架，定义参与公平性、情感氛围和认知公平性三个互补维度，并采用可扩展的交互级测量方法，在模拟对话和人-AI协同实验数据中进行分析。

Result: 该框架能揭示参与模式、关系动态与观点采纳等被聚合统计或事后评估所忽略的微观互动特征。

Conclusion: 本研究是迈向以过程为导向的人-AI协作学习环境中包容性测量的重要初步探索。

Abstract: Inclusion, equity, and access are widely valued in AI and education, yet are often assessed through coarse sample descriptors or post-hoc self-reports that miss how inclusion is shaped moment by moment in collaborative problem solving (CPS). In this proof-of-concept paper, we introduce inclusion analytics, a discourse-based framework for examining inclusion as a dynamic, interactional process in CPS. We conceptualize inclusion along three complementary dimensions -- participation equity, affective climate, and epistemic equity -- and demonstrate how these constructs can be made analytically visible using scalable, interaction-level measures. Using both simulated conversations and empirical data from human-AI teaming experiments, we illustrate how inclusion analytics can surface patterns of participation, relational dynamics, and idea uptake that remain invisible to aggregate or post-hoc evaluations. This work represents an initial step toward process-oriented approaches to measuring inclusion in human-AI collaborative learning environments.

</details>


### [102] [Effective Reasoning Chains Reduce Intrinsic Dimensionality](https://arxiv.org/abs/2602.09276)
*Archiki Prasad,Mandar Joshi,Kenton Lee,Mohit Bansal,Peter Shaw*

Main category: cs.CL

TL;DR: 本文提出内在维度作为衡量推理链有效性的定量指标，发现有效的推理策略能降低任务的内在维度，并与泛化性能呈强负相关。


<details>
  <summary>Details</summary>
Motivation: 当前对链式思维（CoT）等推理策略如何提升模型泛化能力的机制理解不足，缺乏一致、可量化的解释。

Method: 提出‘内在维度’作为定量指标，定义为在给定任务上达到特定准确率所需的最少模型维度数；固定模型架构，通过不同推理策略改变任务形式，在GSM8K数据集上用Gemma-3 1B/4B验证。

Result: 有效推理策略显著降低任务内在维度；内在维度与in-distribution和out-of-distribution泛化性能均呈强负相关。

Conclusion: 有效推理链通过用更少参数压缩任务来促进学习，内在维度可作为分析推理过程的新定量指标。

Abstract: Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing a consistent, quantifiable link between these factors and generalization remains challenging. In this work, we identify intrinsic dimensionality as a quantitative measure for characterizing the effectiveness of reasoning chains. Intrinsic dimensionality quantifies the minimum number of model dimensions needed to reach a given accuracy threshold on a given task. By keeping the model architecture fixed and varying the task formulation through different reasoning strategies, we demonstrate that effective reasoning strategies consistently reduce the intrinsic dimensionality of the task. Validating this on GSM8K with Gemma-3 1B and 4B, we observe a strong inverse correlation between the intrinsic dimensionality of a reasoning strategy and its generalization performance on both in-distribution and out-of-distribution data. Our findings suggest that effective reasoning chains facilitate learning by better compressing the task using fewer parameters, offering a new quantitative metric for analyzing reasoning processes.

</details>


### [103] [Don't Shoot The Breeze: Topic Continuity Model Using Nonlinear Naive Bayes With Attention](https://arxiv.org/abs/2602.09312)
*Shu-Ting Pi,Pradeep Bagavan,Yejia Li,Disha,Qun Liu*

Main category: cs.CL

TL;DR: 本文提出了一种基于朴素贝叶斯扩展与注意力机制的可解释话题连续性模型，用于评估LLM聊天机器人回复是否保持初始话题，支持任意长度对话且具有线性时间复杂度，在长而复杂的对话中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: LLM作为商业场景中的聊天机器人时，常出现话题突变，损害用户体验并浪费计算资源，亟需一种能可靠评估话题连续性的方法。

Method: 将自然语言理解（NLU）模型通过朴素贝叶斯方法量化扩展，并引入注意力机制和对数非线性，构建可解释的分析公式；模型具备线性时间复杂度，支持任意长度对话。

Result: 实验表明，该模型在长而复杂的对话中持续优于传统方法，尤其在话题连续性识别上表现更优，且具备可解释性和高效性。

Conclusion: 所提模型为保障LLM在实际应用中的责任性与可解释性提供了新路径，兼顾性能、效率与透明度。

Abstract: Utilizing Large Language Models (LLM) as chatbots in diverse business scenarios often presents the challenge of maintaining topic continuity. Abrupt shifts in topics can lead to poor user experiences and inefficient utilization of computational resources. In this paper, we present a topic continuity model aimed at assessing whether a response aligns with the initial conversation topic. Our model is built upon the expansion of the corresponding natural language understanding (NLU) model into quantifiable terms using a Naive Bayes approach. Subsequently, we have introduced an attention mechanism and logarithmic nonlinearity to enhance its capability to capture topic continuity. This approach allows us to convert the NLU model into an interpretable analytical formula. In contrast to many NLU models constrained by token limits, our proposed model can seamlessly handle conversations of any length with linear time complexity. Furthermore, the attention mechanism significantly improves the model's ability to identify topic continuity in complex conversations. According to our experiments, our model consistently outperforms traditional methods, particularly in handling lengthy and intricate conversations. This unique capability offers us an opportunity to ensure the responsible and interpretable use of LLMs.

</details>


### [104] [Beyond Uniform Credit: Causal Credit Assignment for Policy Optimization](https://arxiv.org/abs/2602.09331)
*Mykola Khandoga,Rui Yuan,Vinay Kumar Sankarapu*

Main category: cs.CL

TL;DR: 本文提出了一种名为反事实重要性加权（counterfactual importance weighting）的新方法，用于改进语言模型推理中的策略梯度训练。该方法通过遮蔽推理片段、测量答案概率下降来估计各token的重要性，并据此调整梯度更新，无需额外模型或人工标注。在GSM8K数据集上的实验表明其优于均匀信用分配基线，且收敛更快、更准确；消融与反向验证进一步证实其捕捉到了真实的因果结构。


<details>
  <summary>Details</summary>
Motivation: 现有策略梯度方法（如GRPO、DAPO）对所有生成token给予同等信用，无法区分关键推理步骤与无关填充内容，导致训练低效。

Method: 提出反事实重要性加权：对推理过程中的token跨度进行遮蔽，观测答案概率的下降幅度，以此作为该跨度的重要性权重，在策略梯度更新中进行加权；全部计算基于策略模型自身输出，不依赖外部模型或标注。

Result: 在GSM8K上，于Qwen和Llama系列三个模型上均稳定超越均匀信用基线，收敛速度更快、最终准确率更高；反向重要性信号导致性能下降，验证了方法的有效性与因果性；分析显示其能正确聚焦于计算步骤而非冗余文本。

Conclusion: 反事实重要性加权是一种无需额外组件、可即插即用的策略梯度改进机制，能有效识别并强化关键推理token，为语言模型推理优化提供了新基础方向。

Abstract: Policy gradient methods for language model reasoning, such as GRPO and DAPO, assign uniform credit to all generated tokens - the filler phrase "Let me think" receives the same gradient update as the critical calculation "23 + 45 = 68." We propose counterfactual importance weighting: mask reasoning spans, measure the drop in answer probability, and upweight tokens accordingly during policy gradient updates. Our method requires no auxiliary models or external annotation, instead importance is estimated directly from the policy model's own probability shifts. Experiments on GSM8K across three models spanning the Qwen and Llama families demonstrate consistent improvements over uniform baselines and faster convergence to equivalent accuracy. Inverting the importance signal hurts performance, confirming we capture genuine causal structure rather than noise. Analysis shows the method correctly prioritizes calculation steps over scaffolding text. We view these findings as establishing counterfactual importance weighting as a foundation for further research rather than a complete solution.

</details>


### [105] [FM SO.P: A Progressive Task Mixture Framework with Automatic Evaluation for Cross-Domain SOP Understanding](https://arxiv.org/abs/2602.09336)
*Siyuan Huang,Ziyu Wang,Chao Pan,Han Zhao*

Main category: cs.CL

TL;DR: 本文提出FM SO.P，通过渐进式任务混合和多智能体评估系统，显著提升语言模型对标准操作流程（SOP）的理解与跨域泛化能力，在SOPBench基准上以更小模型达到媲美大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在SOP理解与跨域泛化上表现不佳，因其联合训练无法区分SOP所需的三类核心推理能力：术语精确性、顺序逻辑与约束推理。

Method: 提出FM SO.P：1）渐进式任务混合——分阶段训练概念消歧（术语精度）、动作序列理解（流程正确性）、场景感知图推理（条件逻辑）；2）自动多智能体评估系统——三个自适应智能体分别生成评分标准、分层测试集与自动打分，适配不同领域约束。

Result: 在七领域SOPBench基准上，32B模型达48.3%通过率，开源7B模型达34.3%，与Qwen-2.5-72B-Instruct（34.4%）相当，参数量仅为其1/10。

Conclusion: FM SO.P有效解耦并协同提升SOP所需的关键推理能力，验证了渐进式任务设计与自动化评估对专业领域语言建模的重要价值。

Abstract: Standard Operating Procedures (SOPs) are critical for enterprise operations, yet existing language models struggle with SOP understanding and cross-domain generalization. Current methods fail because joint training cannot differentiate between reasoning capabilities that SOP requires: terminology precision, sequential ordering, and constraint reasoning. We propose FM SO.P, solving these challenges through two novelties. First, we introduce progressive task mixtures that build capabilities by stages across three task types with cumulative data: concept disambiguation for terminology precision, action sequence understanding for procedural correctness, and scenario-aware graph reasoning for conditional logic. Second, we propose an automatic multi-agent evaluation system consisting of three agents that adaptively generate rubrics, stratified test sets, and rubric scoring, adapting to domains (e.g., temporal constraints for DMV, regulatory compliance for banking). Evaluated on SOPBench across seven domains (Bank, DMV, Healthcare, Market, University, Library, Hotel), FM SO.P achieves 48.3\% pass rate with our 32B model and 34.3\% with our opensource 7B model, matching Qwen-2.5-72B-Instruct baseline (34.4\%) with 10x fewer parameters.

</details>


### [106] [Understanding Risk and Dependency in AI Chatbot Use from User Discourse](https://arxiv.org/abs/2602.09339)
*Jianfeng Zhu,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 本研究通过大规模计算主题分析Reddit上两个AI相关危害社区的帖子，识别出用户感知AI心理风险的五个经验维度，发现自我调节困难最普遍，恐惧集中于自主性、控制和技术风险。


<details>
  <summary>Details</summary>
Motivation: 现有对AI使用中心理风险如何产生、体验和被用户调节的实证理解有限。

Method: 基于Braun和Clarke的反思性框架，采用多智能体、大语言模型辅助的主题分析法，对2023–2025年r/AIDangers和r/ChatbotAddiction社区帖子进行分析，并结合BERT情绪分类器进行情感标注与可视化。

Result: 识别出14个重复主题类别，归纳为五个高阶经验维度；自我调节困难最常见，恐惧情绪主要集中于自主性、控制与技术风险。

Conclusion: 研究首次基于真实用户话语，实证揭示了AI相关心理风险的五维经验结构，为AI安全研究、评估与负责任治理提供了来自真实场景的基础依据。

Abstract: Generative AI systems are increasingly embedded in everyday life, yet empirical understanding of how psychological risk associated with AI use emerges, is experienced, and is regulated by users remains limited. We present a large-scale computational thematic analysis of posts collected between 2023 and 2025 from two Reddit communities, r/AIDangers and r/ChatbotAddiction, explicitly focused on AI-related harm and distress. Using a multi-agent, LLM-assisted thematic analysis grounded in Braun and Clarke's reflexive framework, we identify 14 recurring thematic categories and synthesize them into five higher-order experiential dimensions. To further characterize affective patterns, we apply emotion labeling using a BERT-based classifier and visualize emotional profiles across dimensions. Our findings reveal five empirically derived experiential dimensions of AI-related psychological risk grounded in real-world user discourse, with self-regulation difficulties emerging as the most prevalent and fear concentrated in concerns related to autonomy, control, and technical risk. These results provide early empirical evidence from lived user experience of how AI safety is perceived and emotionally experienced outside laboratory or speculative contexts, offering a foundation for future AI safety research, evaluation, and responsible governance.

</details>


### [107] [Digital Linguistic Bias in Spanish: Evidence from Lexical Variation in LLMs](https://arxiv.org/abs/2602.09346)
*Yoshifumi Kawasaki*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLMs）对西班牙语地理词汇变异的捕捉能力，发现模型在识别西班牙、赤道几内亚、墨西哥与中美洲及拉普拉塔河地区词汇变体方面表现较好，但难以区分智利变体；性能差异不能仅用各国数字资源数量解释，表明数据量之外的因素影响方言表征。


<details>
  <summary>Details</summary>
Motivation: 西班牙语存在显著地域词汇变异，而大语言模型作为‘虚拟说话人’是否能准确反映这种变异尚不清楚；同时，需探究数字语言偏见在西班牙语中的具体表现。

Method: 将LLMs视为虚拟调查对象，采用是非题和多选题两种问卷形式，基于大规模专家整理的西班牙语词汇变异数据库，评估900多个词汇项在21个西语国家及方言区的表现。

Result: 模型对方言变体的表征存在系统性差异：对西班牙、赤道几内亚、墨西哥与中美洲、拉普拉塔河地区变体识别更准，而智利变体最难区分；国家数字资源总量与模型性能无显著相关性。

Conclusion: LLMs的方言知识存在不均衡性，其方言表征不仅受训练数据数量影响，更受数据质量、代表性及建模机制等多重因素制约；本研究为数字语言偏见提供了西班牙语实证依据，并推动了对LLMs方言能力的精细化评估。

Abstract: This study examines the extent to which Large Language Models (LLMs) capture geographic lexical variation in Spanish, a language that exhibits substantial regional variation. Treating LLMs as virtual informants, we probe their dialectal knowledge using two survey-style question formats: Yes-No questions and multiple-choice questions. To this end, we exploited a large-scale, expert-curated database of Spanish lexical variation. Our evaluation covers more than 900 lexical items across 21 Spanish-speaking countries and is conducted at both the country and dialectal area levels. Across both evaluation formats, the results reveal systematic differences in how LLMs represent Spanish language varieties. Lexical variation associated with Spain, Equatorial Guinea, Mexico & Central America, and the La Plata River is recognized more accurately by the models, while the Chilean variety proves particularly difficult for the models to distinguish. Importantly, differences in the volume of country-level digital resources do not account for these performance patterns, suggesting that factors beyond data quantity shape dialectal representation in LLMs. By providing a fine-grained, large-scale evaluation of geographic lexical variation, this work advances empirical understanding of dialectal knowledge in LLMs and contributes new evidence to discussions of Digital Linguistic Bias in Spanish.

</details>


### [108] [Unsupervised Cross-Lingual Part-of-Speech Tagging with Monolingual Corpora Only](https://arxiv.org/abs/2602.09366)
*Jianyu Zheng*

Main category: cs.CL

TL;DR: 本文提出了一种完全无监督的跨语言词性标注框架，仅依赖单语语料库，通过无监督神经机器翻译（UNMT）生成伪平行句对，再结合多源投影技术提升低资源语言的POS标注性能。


<details>
  <summary>Details</summary>
Motivation: 现有低资源语言词性标注方法严重依赖稀缺的平行语料，而许多低资源语言缺乏此类资源，亟需不依赖平行语料的解决方案。

Method: 利用无监督神经机器翻译（UNMT）将高资源语言句子翻译为低资源语言，构建伪平行句对；在此基础上沿用基于词对齐的POS标签投影方法训练目标语言词性标注器，并引入多源投影技术校准投影标签。

Result: 在28个语言对上的实验表明，该方法性能媲美甚至超越使用真实平行语料的基线方法；多源投影技术平均带来1.3%的性能提升。

Conclusion: 仅用单语语料即可实现高质量跨语言POS标注，有效缓解低资源语言标注数据匮乏问题，且多源投影策略进一步增强了模型鲁棒性与准确性。

Abstract: Due to the scarcity of part-of-speech annotated data, existing studies on low-resource languages typically adopt unsupervised approaches for POS tagging. Among these, POS tag projection with word alignment method transfers POS tags from a high-resource source language to a low-resource target language based on parallel corpora, making it particularly suitable for low-resource language settings. However, this approach relies heavily on parallel corpora, which are often unavailable for many low-resource languages. To overcome this limitation, we propose a fully unsupervised cross-lingual part-of-speech(POS) tagging framework that relies solely on monolingual corpora by leveraging unsupervised neural machine translation(UNMT) system. This UNMT system first translates sentences from a high-resource language into a low-resource one, thereby constructing pseudo-parallel sentence pairs. Then, we train a POS tagger for the target language following the standard projection procedure based on word alignments. Moreover, we propose a multi-source projection technique to calibrate the projected POS tags on the target side, enhancing to train a more effective POS tagger. We evaluate our framework on 28 language pairs, covering four source languages (English, German, Spanish and French) and seven target languages (Afrikaans, Basque, Finnis, Indonesian, Lithuanian, Portuguese and Turkish). Experimental results show that our method can achieve performance comparable to the baseline cross-lingual POS tagger with parallel sentence pairs, and even exceeds it for certain target languages. Furthermore, our proposed multi-source projection technique further boosts performance, yielding an average improvement of 1.3% over previous methods.

</details>


### [109] [AgentSkiller: Scaling Generalist Agent Intelligence through Semantically Integrated Cross-Domain Data Synthesis](https://arxiv.org/abs/2602.09372)
*Zexu Sun,Bokai Ji,Hengyi Cai,Shuaiqiang Wang,Lei Wang,Guangxia Li,Xu Chen*

Main category: cs.CL

TL;DR: 本文提出AgentSkiller框架，通过自动化合成多轮、跨领域、语义关联的交互数据，解决大模型智能体缺乏高质量长周期训练数据的问题，并在函数调用任务上显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于隐私约束或生成数据多样性不足，难以提供支撑通用智能体所需的大规模、高质量、长周期交互数据。

Method: 提出AgentSkiller：基于DAG的状态确定性架构；构建领域本体与以人为中心的实体图；定义服务蓝图以适配模型上下文协议服务器；融合跨域服务模拟复杂任务；通过执行验证与角色化模拟器自动生成用户任务和查询。

Result: 合成了约11K条高质量多轮交互样本；在函数调用任务上，使用该数据训练的模型显著优于基线，尤其在大参数模型中提升更明显。

Conclusion: AgentSkiller能高效生成可靠、可复现、语义丰富的多领域交互数据，为提升LLM智能体的工具使用能力提供了可扩展的数据基础。

Abstract: Large Language Model agents demonstrate potential in solving real-world problems via tools, yet generalist intelligence is bottlenecked by scarce high-quality, long-horizon data. Existing methods collect privacy-constrained API logs or generate scripted interactions lacking diversity, which struggle to produce data requisite for scaling capabilities. We propose AgentSkiller, a fully automated framework synthesizing multi-turn interaction data across realistic, semantically linked domains. It employs a DAG-based architecture with explicit state transitions to ensure determinism and recoverability. The pipeline builds a domain ontology and Person-Centric Entity Graph, defines tool interfaces via Service Blueprints for Model Context Protocol servers, and populates environments with consistent databases and strict Domain Policies. A cross-domain fusion mechanism links services to simulate complex tasks. Finally, the pipeline creates user tasks by verifying solution paths, filtering via execution-based validation, and generating queries using a Persona-based Simulator for automated rollout. This produces reliable environments with clear state changes. To demonstrate effectiveness, we synthesized $\approx$ 11K interaction samples; experimental results indicate that models trained on this dataset achieve significant improvements on function calling over baselines, particularly in larger parameter regimes.

</details>


### [110] [AfriNLLB: Efficient Translation Models for African Languages](https://arxiv.org/abs/2602.09373)
*Yasmin Moslem,Aman Kassahun Wassie,Amanuel Gizachew Abebe*

Main category: cs.CL

TL;DR: AfriNLLB is a set of lightweight, efficient neural machine translation models for African languages, built by compressing and distilling NLLB-200, supporting 15 language pairs with released models and data.


<details>
  <summary>Details</summary>
Motivation: To enable efficient deployment of translation models for African languages in resource-constrained settings, addressing the lack of lightweight, high-performance models for low-resource African languages.

Method: Compresses NLLB-200 600M via iterative layer pruning and quantization, then fine-tunes on curated African language parallel corpora using knowledge distillation from a larger teacher model.

Result: AfriNLLB achieves performance comparable to the baseline while being significantly faster; two inference-friendly versions (Transformers and CTranslate2) and all training data are publicly released.

Conclusion: AfriNLLB successfully balances efficiency and performance for African language translation, advancing accessibility and reproducibility through open models and data.

Abstract: In this work, we present AfriNLLB, a series of lightweight models for efficient translation from and into African languages. AfriNLLB supports 15 language pairs (30 translation directions), including Swahili, Hausa, Yoruba, Amharic, Somali, Zulu, Lingala, Afrikaans, Wolof, and Egyptian Arabic, as well as other African Union official languages such as Arabic (MSA), French, Portuguese, and Spanish. Our training data covers bidirectional translation between English and 13 languages, and between French and two languages (Lingala and Wolof).
  AfriNLLB models are based on NLLB-200 600M, which we compress using iterative layer pruning and quantization. We fine-tune the pruned models on parallel corpora we curated for African languages, employing knowledge distillation from a larger teacher model. Our work aims at enabling efficient deployment of translation models for African languages in resource-constrained settings.
  Our evaluation results demonstrate that AfriNLLB models achieve performance comparable to the baseline while being significantly faster. We release two versions of the AfriNLLB models, a Transformers version that allows further fine-tuning and a CTranslate2 version for efficient inference. Moreover, we release all the training data that we used for fine-tuning the baseline and pruned models to facilitate further research.

</details>


### [111] [BiasScope: Towards Automated Detection of Bias in LLM-as-a-Judge Evaluation](https://arxiv.org/abs/2602.09383)
*Peng Lai,Zhihao Ou,Yong Wang,Longyue Wang,Jian Yang,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: 本文提出BiasScope框架，用于自动、大规模发现LLM-as-a-Judge评估中潜在的未知偏差，并基于其构建更具挑战性的基准JudgeBench-Pro，揭示当前大模型作为裁判仍存在严重鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-Judge评估中对偏差的研究多集中于已知偏差，缺乏对未知偏差的自动化、系统性探索，影响评估的鲁棒性与可靠性。

Method: 提出BiasScope——一个由大语言模型驱动的、可扩展的偏差自动发现框架；并在JudgeBench数据集上验证其跨模型族与规模的通用性和有效性；进一步构建增强版基准JudgeBench-Pro。

Result: BiasScope成功实现了从依赖人工和预定义偏差列表的被动发现，转向主动、全面的自动化偏差探索；在JudgeBench-Pro上，即使强大LLM作为裁判，错误率仍超50%。

Conclusion: LLM-as-a-Judge评估存在严重未被识别的偏差风险，亟需通过如BiasScope等自动化方法提升评估鲁棒性，并推动更可靠的评估基准建设。

Abstract: LLM-as-a-Judge has been widely adopted across various research and practical applications, yet the robustness and reliability of its evaluation remain a critical issue. A core challenge it faces is bias, which has primarily been studied in terms of known biases and their impact on evaluation outcomes, while automated and systematic exploration of potential unknown biases is still lacking. Nevertheless, such exploration is crucial for enhancing the robustness and reliability of evaluations. To bridge this gap, we propose BiasScope, a LLM-driven framework for automatically and at scale discovering potential biases that may arise during model evaluation. BiasScope can uncover potential biases across different model families and scales, with its generality and effectiveness validated on the JudgeBench dataset. It overcomes the limitations of existing approaches, transforming bias discovery from a passive process relying on manual effort and predefined bias lists into an active and comprehensive automated exploration. Moreover, based on BiasScope, we propose JudgeBench-Pro, an extended version of JudgeBench and a more challenging benchmark for evaluating the robustness of LLM-as-a-judge. Strikingly, even powerful LLMs as evaluators show error rates above 50\% on JudgeBench-Pro, underscoring the urgent need to strengthen evaluation robustness and to mitigate potential biases further.

</details>


### [112] [Contractual Deepfakes: Can Large Language Models Generate Contracts?](https://arxiv.org/abs/2602.09384)
*Eliza Mik*

Main category: cs.CL

TL;DR: 本文批判了将大语言模型（LLM）直接用于合同起草的简单化观点，指出LLM缺乏语义理解、情境感知与法律推理能力，其生成的合同文本表面合理但实质可能不一致或不适用，因此不会真正威胁法律行业的存续。


<details>
  <summary>Details</summary>
Motivation: 驳斥当前将LLM盲目应用于合同起草的不合理主张，澄清语言模型的本质局限与法律实践的真实需求之间的根本差异。

Method: 概念辨析与批判性分析：区分‘统计式词预测’与‘法律语境下的语言使用’、‘模板拼凑’与‘法律推理’，结合法律实务要求展开论证。

Result: 揭示LLM生成的合同文本虽具表面合理性，却常存在条款矛盾、法律适用错误或交易不匹配等实质性缺陷，实际应用风险高。

Conclusion: LLM不具备替代律师进行合同起草等需深度法律推理工作的能力；所谓其威胁法律行业生存的观点是建立在对技术本质的误解之上，应予以否定。

Abstract: Notwithstanding their unprecedented ability to generate text, LLMs do not understand the meaning of words, have no sense of context and cannot reason. Their output constitutes an approximation of statistically dominant word patterns. And yet, the drafting of contracts is often presented as a typical legal task that could be facilitated by this technology. This paper seeks to put an end to such unreasonable ideas. Predicting words differs from using language in the circumstances of specific transactions and reconstituting common contractual phrases differs from reasoning about the law. LLMs seem to be able to generate generic and superficially plausible contractual documents. In the cold light of day, such documents may turn out to be useless assemblages of inconsistent provisions or contracts that are enforceable but unsuitable for a given transaction. This paper casts a shadow on the simplistic assumption that LLMs threaten the continued viability of the legal industry.

</details>


### [113] [Effective vocabulary expanding of multilingual language models for extremely low-resource languages](https://arxiv.org/abs/2602.09388)
*Jianyu Zheng*

Main category: cs.CL

TL;DR: 本文提出了一种针对低资源、未支持语言扩展多语言预训练语言模型（mPLMs）的方法：通过目标语料扩展词表，利用双语词典初始化新增词向量，并在此基础上继续预训练，显著提升POS和NER性能且不损害源语言能力。


<details>
  <summary>Details</summary>
Motivation: 现有工作多关注已支持语言的持续预训练，但缺乏对完全未被mPLMs覆盖的低资源语言的有效扩展方法。

Method: 1）基于目标语言语料扩展模型词表；2）筛选并移除原词表中偏向源语言（如英语）的子集；3）用双语词典初始化新增词向量；4）在目标语料上进行持续预训练。

Result: 在POS标注和命名实体识别任务上分别比随机初始化基线提升0.54%和2.60%；模型对训练语料选择鲁棒，且源语言性能无下降。

Conclusion: 基于双语词典初始化的词表扩展与持续预训练策略，可有效、稳健地将mPLMs扩展至新低资源语言，兼顾目标语言性能提升与源语言能力保持。

Abstract: Multilingual pre-trained language models(mPLMs) offer significant benefits for many low-resource languages. To further expand the range of languages these models can support, many works focus on continued pre-training of these models. However, few works address how to extend mPLMs to low-resource languages that were previously unsupported. To tackle this issue, we expand the model's vocabulary using a target language corpus. We then screen out a subset from the model's original vocabulary, which is biased towards representing the source language(e.g. English), and utilize bilingual dictionaries to initialize the representations of the expanded vocabulary. Subsequently, we continue to pre-train the mPLMs using the target language corpus, based on the representations of these expanded vocabulary. Experimental results show that our proposed method outperforms the baseline, which uses randomly initialized expanded vocabulary for continued pre-training, in POS tagging and NER tasks, achieving improvements by 0.54% and 2.60%, respectively. Furthermore, our method demonstrates high robustness in selecting the training corpora, and the models' performance on the source language does not degrade after continued pre-training.

</details>


### [114] [Are Language Models Sensitive to Morally Irrelevant Distractors?](https://arxiv.org/abs/2602.09416)
*Andrew Shaw,Christina Hahn,Catherine Rasgaitis,Yash Mishra,Alisa Liu,Natasha Jaques,Yulia Tsvetkov,Amy X. Zhang*

Main category: cs.CL

TL;DR: 本文受道德心理学中情境主义观点启发，探究大语言模型（LLMs）是否像人类一样受无关道德的情境因素影响。研究构建了60个无道德相关性的多模态‘道德干扰项’，注入现有道德基准测试中，发现这些干扰项可使LLM的道德判断偏移超30%，表明其道德判断存在显著情境敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有道德基准假设LLM具有稳定的道德偏好，但人类道德判断已被证明易受无关情境因素影响；本文旨在检验LLM是否同样表现出类似认知道德偏差。

Method: 从心理数据集中筛选60个情感化、无道德相关性的图像与叙事作为‘道德干扰项’，将其注入现有道德基准，系统评估其对LLM道德判断输出的影响。

Result: 道德干扰项显著改变LLM的道德判断，在低歧义场景下偏移幅度超30%。

Conclusion: LLM的道德判断具有强情境敏感性，挑战了其道德稳定性假设，提示需发展更情境化、更精细的认知道德建模与评估方法。

Abstract: With the rapid development and uptake of large language models (LLMs) across high-stakes settings, it is increasingly important to ensure that LLMs behave in ways that align with human values. Existing moral benchmarks prompt LLMs with value statements, moral scenarios, or psychological questionnaires, with the implicit underlying assumption that LLMs report somewhat stable moral preferences. However, moral psychology research has shown that human moral judgements are sensitive to morally irrelevant situational factors, such as smelling cinnamon rolls or the level of ambient noise, thereby challenging moral theories that assume the stability of human moral judgements. Here, we draw inspiration from this "situationist" view of moral psychology to evaluate whether LLMs exhibit similar cognitive moral biases to humans. We curate a novel multimodal dataset of 60 "moral distractors" from existing psychological datasets of emotionally-valenced images and narratives which have no moral relevance to the situation presented. After injecting these distractors into existing moral benchmarks to measure their effects on LLM responses, we find that moral distractors can shift the moral judgements of LLMs by over 30% even in low-ambiguity scenarios, highlighting the need for more contextual moral evaluations and more nuanced cognitive moral modeling of LLMs.

</details>


### [115] [Breaking the Pre-Sampling Barrier: Activation-Informed Difficulty-Aware Self-Consistency](https://arxiv.org/abs/2602.09438)
*Taewoong Yoon,Geunyeong Jeong,Geon Park,Sihyeong Yeom,Harksoo Kim*

Main category: cs.CL

TL;DR: 本文提出ACTSC方法，利用前馈网络神经元激活信号构建轻量级难度估计探针，动态调整自一致性采样数量，无需额外模型调用或预采样，显著降低推理开销并保持准确率。


<details>
  <summary>Details</summary>
Motivation: 现有自一致性（SC）方法推理成本高；难度自适应SC（DSC）虽减少采样，但需额外模型调用和预采样，计算开销大。

Method: 提出Activation-Informed Difficulty-Aware Self-Consistency（ACTSC），利用LLM前馈层神经元激活值构建无需额外token生成或模型调用的轻量级难度估计探针，动态调整SC采样数。

Result: 在五个基准上实验表明，ACTSC在保持精度的同时显著降低推理成本，且可跨数据集直接部署、无需预采样。

Conclusion: ACTSC是一种高效、通用、低开销的自一致性改进策略，通过挖掘内部激活信号实现难度感知的采样控制。

Abstract: Self-Consistency (SC) is an effective decoding strategy that improves the reasoning performance of Large Language Models (LLMs) by generating multiple chain-of-thought reasoning paths and selecting the final answer via majority voting. However, it suffers from substantial inference costs because it requires a large number of samples. To mitigate this issue, Difficulty-Adaptive Self-Consistency (DSC) was proposed to reduce unnecessary token usage for easy problems by adjusting the number of samples according to problem difficulty. However, DSC requires additional model calls and pre-sampling to estimate difficulty, and this process is repeated when applying to each dataset, leading to significant computational overhead. In this work, we propose Activation-Informed Difficulty-Aware Self-Consistency (ACTSC) to address these limitations. ACTSC leverages internal difficulty signals reflected in the feed-forward network neuron activations to construct a lightweight difficulty estimation probe, without any additional token generation or model calls. The probe dynamically adjusts the number of samples for SC and can be applied to new datasets without requiring pre-sampling for difficulty estimation. To validate its effectiveness, we conduct experiments on five benchmarks. Experimental results show that ACTSC effectively reduces inference costs while maintaining accuracy relative to existing methods.

</details>


### [116] [Evaluating Social Bias in RAG Systems: When External Context Helps and Reasoning Hurts](https://arxiv.org/abs/2602.09442)
*Shweta Parihar,Lu Cheng*

Main category: cs.CL

TL;DR: 本文研究了检索增强生成（RAG）对大语言模型社会偏见的影响，发现RAG可降低偏见，但引入思维链（CoT）提示反而增加偏见，揭示了准确性与公平性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）固有的社会偏见引发严重公平性问题，而检索增强生成（RAG）虽引入外部知识，但仍可能受相同偏见影响，因此需系统评估RAG对社会偏见的影响。

Method: 在多种检索语料库、LLM和偏见评估数据集上开展大规模实验，涵盖13种以上偏见类型；进一步将思维链（CoT）提示融入RAG，并评估其推理过程的忠实性。

Result: RAG整体上降低了社会偏见，表明外部上下文有助于抑制刻板印象预测；但加入CoT后，模型偏见反而上升，且偏见倾向随检索信息增多在刻板与反刻板响应间变化。

Conclusion: RAG具有缓解LLM社会偏见的潜力，但CoT等推理增强技术可能加剧偏见，需构建兼顾准确性与公平性的偏见感知推理框架。

Abstract: Social biases inherent in large language models (LLMs) raise significant fairness concerns. Retrieval-Augmented Generation (RAG) architectures, which retrieve external knowledge sources to enhance the generative capabilities of LLMs, remain susceptible to the same bias-related challenges. This work focuses on evaluating and understanding the social bias implications of RAG. Through extensive experiments across various retrieval corpora, LLMs, and bias evaluation datasets, encompassing more than 13 different bias types, we surprisingly observe a reduction in bias in RAG. This suggests that the inclusion of external context can help counteract stereotype-driven predictions, potentially improving fairness by diversifying the contextual grounding of the model's outputs. To better understand this phenomenon, we then explore the model's reasoning process by integrating Chain-of-Thought (CoT) prompting into RAG while assessing the faithfulness of the model's CoT. Our experiments reveal that the model's bias inclinations shift between stereotype and anti-stereotype responses as more contextual information is incorporated from the retrieved documents. Interestingly, we find that while CoT enhances accuracy, contrary to the bias reduction observed with RAG, it increases overall bias across datasets, highlighting the need for bias-aware reasoning frameworks that can mitigate this trade-off.

</details>


### [117] [Conceptual Cultural Index: A Metric for Cultural Specificity via Relative Generality](https://arxiv.org/abs/2602.09444)
*Takumi Ohashi,Hitoshi Iyatomi*

Main category: cs.CL

TL;DR: 本文提出了一种名为概念文化指数（CCI）的新指标，用于在句子级别量化文化特异性，并通过实证验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）日益部署于多元文化环境中，但目前尚缺乏对文化特异性在句子级别上的系统性评估方法。

Method: 提出概念文化指数（CCI），定义为句子在目标文化中的泛化性估计值与在其他文化中平均泛化性估计值之差；基于400句（200句文化特异、200句通用）进行验证，并与直接LLM打分对比评估性能。

Result: CCI得分分布符合预期：文化特异句子得分更高，通用句子得分更低；在二分类任务中，CCI的AUC比直接LLM评分高出10点以上（针对目标文化优化的模型）。

Conclusion: CCI是一种可操作、可解释的文化特异性量化工具，能有效支持LLM在多元文化场景中的适配与评估。

Abstract: Large language models (LLMs) are increasingly deployed in multicultural settings; however, systematic evaluation of cultural specificity at the sentence level remains underexplored. We propose the Conceptual Cultural Index (CCI), which estimates cultural specificity at the sentence level. CCI is defined as the difference between the generality estimate within the target culture and the average generality estimate across other cultures. This formulation enables users to operationally control the scope of culture via comparison settings and provides interpretability, since the score derives from the underlying generality estimates. We validate CCI on 400 sentences (200 culture-specific and 200 general), and the resulting score distribution exhibits the anticipated pattern: higher for culture-specific sentences and lower for general ones. For binary separability, CCI outperforms direct LLM scoring, yielding more than a 10-point improvement in AUC for models specialized to the target culture. Our code is available at https://github.com/IyatomiLab/CCI .

</details>


### [118] [Comprehensive Comparison of RAG Methods Across Multi-Domain Conversational QA](https://arxiv.org/abs/2602.09552)
*Klejda Alushi,Jan Strich,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: 本文系统评估了多种RAG方法在多轮对话问答中的性能，发现简单鲁棒的方法（如重排序、混合BM25、HyDE）普遍优于基础RAG，而部分复杂方法反而不如无RAG基线；性能高度依赖数据集特性和对话长度，强调检索策略与数据结构的匹配比方法复杂度更重要。


<details>
  <summary>Details</summary>
Motivation: 现有研究多孤立评估RAG方法，且集中于单轮问答，缺乏对多轮对话中因历史上下文、指代消解和意图漂移带来的检索挑战的系统性比较。

Method: 在统一实验框架下，对八种跨领域多轮对话QA数据集，全面实证评估基础与先进RAG方法（如reranking、hybrid BM25、HyDE等），使用检索与生成双维度指标，并分析性能随对话轮次的变化。

Result: reranking、hybrid BM25和HyDE等方法稳定优于vanilla RAG；部分先进方法未提升甚至低于No-RAG基线；数据集特性与对话长度显著影响检索效果，无单一策略全局最优。

Conclusion: 多轮对话RAG的有效性关键在于检索策略与数据集结构的匹配程度，而非方法本身的复杂度。

Abstract: Conversational question answering increasingly relies on retrieval-augmented generation (RAG) to ground large language models (LLMs) in external knowledge. Yet, most existing studies evaluate RAG methods in isolation and primarily focus on single-turn settings. This paper addresses the lack of a systematic comparison of RAG methods for multi-turn conversational QA, where dialogue history, coreference, and shifting user intent substantially complicate retrieval. We present a comprehensive empirical study of vanilla and advanced RAG methods across eight diverse conversational QA datasets spanning multiple domains. Using a unified experimental setup, we evaluate retrieval quality and answer generation using generator and retrieval metrics, and analyze how performance evolves across conversation turns. Our results show that robust yet straightforward methods, such as reranking, hybrid BM25, and HyDE, consistently outperform vanilla RAG. In contrast, several advanced techniques fail to yield gains and can even degrade performance below the No-RAG baseline. We further demonstrate that dataset characteristics and dialogue length strongly influence retrieval effectiveness, explaining why no single RAG strategy dominates across settings. Overall, our findings indicate that effective conversational RAG depends less on method complexity than on alignment between the retrieval strategy and the dataset structure. We publish the code used.\footnote{\href{https://github.com/Klejda-A/exp-rag.git}{GitHub Repository}}

</details>


### [119] [NOWJ @BioCreative IX ToxHabits: An Ensemble Deep Learning Approach for Detecting Substance Use and Contextual Information in Clinical Texts](https://arxiv.org/abs/2602.09469)
*Huu-Huy-Hoang Tran,Gia-Bao Duong,Quoc-Viet-Anh Tran,Thi-Hai-Yen Vuong,Hoang-Quynh Le*

Main category: cs.CL

TL;DR: 本文提出了一种多输出集成系统，结合BETO与CRF层，在西班牙语临床文本中高效检测毒物使用及其上下文属性，显著提升了触发词和论元检测的F1值和精确率。


<details>
  <summary>Details</summary>
Motivation: 解决从非结构化电子健康记录中提取药物使用信息的挑战，特别是在信任、可控性和效率受限的情况下，应对ToxHabits共享任务中西班牙语低资源临床文本的毒物使用检测需求。

Method: 提出多输出集成系统，融合BETO预训练模型与CRF层进行序列标注，采用多样化训练策略及句子过滤提升精度，分别处理ToxNER（Subtask 1）和ToxUse（Subtask 2）。

Result: 最佳运行在触发词检测上达到0.94 F1和0.97精确率，在论元检测上达到0.91 F1。

Conclusion: 该方法在低资源、领域特定的西班牙语临床NLP任务中表现出高精度和强鲁棒性，验证了轻量可控模型在敏感医疗场景中的实用价值。

Abstract: Extracting drug use information from unstructured Electronic Health Records remains a major challenge in clinical Natural Language Processing. While Large Language Models demonstrate advancements, their use in clinical NLP is limited by concerns over trust, control, and efficiency. To address this, we present NOWJ submission to the ToxHabits Shared Task at BioCreative IX. This task targets the detection of toxic substance use and contextual attributes in Spanish clinical texts, a domain-specific, low-resource setting. We propose a multi-output ensemble system tackling both Subtask 1 - ToxNER and Subtask 2 - ToxUse. Our system integrates BETO with a CRF layer for sequence labeling, employs diverse training strategies, and uses sentence filtering to boost precision. Our top run achieved 0.94 F1 and 0.97 precision for Trigger Detection, and 0.91 F1 for Argument Detection.

</details>


### [120] [LEMUR: A Corpus for Robust Fine-Tuning of Multilingual Law Embedding Models for Retrieval](https://arxiv.org/abs/2602.09570)
*Narges Baba Ahmadi,Jan Strich,Martin Semmann,Chris Biemann*

Main category: cs.CL

TL;DR: 本文提出了LEMUR，一个大规模多语言欧盟环境立法语料库，并基于此微调了多个多语言嵌入模型，显著提升了法律文本的跨语言检索性能，尤其对低资源语言效果更佳。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在多语言法律场景中面临检索不可靠、缺乏领域适配的开源嵌入模型等问题；现有法律语料未针对语义检索设计，且PDF源存在文本提取噪声。

Method: 构建LEMUR语料库（24953份EUR-Lex PDF，覆盖25种语言），提出Lexical Content Score（LCS）评估PDF转文本保真度；在单语与双语设定下，采用对比学习目标微调三个主流多语言嵌入模型。

Result: 法律领域微调显著提升Top-k检索准确率，尤其对低资源语言增益明显；跨语言评测显示性能可迁移到未见语言，表明模型学到的是语言无关的法律内容表征。

Conclusion: 领域适配的微调能有效增强多语言法律检索能力，LEMUR语料库与微调模型为开放研究提供了重要基础。

Abstract: Large language models (LLMs) are increasingly used to access legal information. Yet, their deployment in multilingual legal settings is constrained by unreliable retrieval and the lack of domain-adapted, open-embedding models. In particular, existing multilingual legal corpora are not designed for semantic retrieval, and PDF-based legislative sources introduce substantial noise due to imperfect text extraction. To address these challenges, we introduce LEMUR, a large-scale multilingual corpus of EU environmental legislation constructed from 24,953 official EUR-Lex PDF documents covering 25 languages. We quantify the fidelity of PDF-to-text conversion by measuring lexical consistency against authoritative HTML versions using the Lexical Content Score (LCS). Building on LEMUR, we fine-tune three state-of-the-art multilingual embedding models using contrastive objectives in both monolingual and bilingual settings, reflecting realistic legal-retrieval scenarios. Experiments across low- and high-resource languages demonstrate that legal-domain fine-tuning consistently improves Top-k retrieval accuracy relative to strong baselines, with particularly pronounced gains for low-resource languages. Cross-lingual evaluations show that these improvements transfer to unseen languages, indicating that fine-tuning primarily enhances language-independent, content-level legal representations rather than language-specific cues. We publish code\footnote{\href{https://github.com/nargesbh/eur_lex}{GitHub Repository}} and data\footnote{\href{https://huggingface.co/datasets/G4KMU/LEMUR}{Hugging Face Dataset}}.

</details>


### [121] [Listen to the Layers: Mitigating Hallucinations with Inter-Layer Disagreement](https://arxiv.org/abs/2602.09486)
*Koduvayur Subbalakshmi,Sabbir Hossain Ujjal,Venkata Krishna Teja Mangichetty,Nastaran Jamalipour Soofi*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的解码算法CoCoA，利用大语言模型中间层表征不稳定性来检测并抑制幻觉，显著提升生成内容的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型易产生流利但事实错误的文本（即幻觉），损害其可靠性；作者假设生成文本的事实性与其在模型内部各层的表征不稳定性相关。

Method: 提出CoCoA解码器，定义两个度量中间层表征不稳定性的指标，并据此对高内部混淆的输出施加惩罚；进一步提出自信息门控变体CoCoA-SIG，动态调节惩罚以聚焦高惊奇度、不稳定的生成。

Result: 在问答、摘要、代码生成等任务上，CoCoA显著提升了Llama-3、Qwen-2.5、Mistral等多个模型家族的事实正确性，且无需任何模型重训练。

Conclusion: CoCoA是一种有效、通用、训练无关的方法，能通过利用模型内在信号，在推理阶段增强大语言模型的可信度。

Abstract: Pretrained Large Language Models (LLMs) are prone to generating fluent yet factually incorrect text-a phenomenon known as hallucinations, undermining their reliability and utility in downstream tasks. We hypothesize that a generated text span's factuality is correlated with its representational instability across the model's internal layers. Based on this, we propose the CoCoA (Confusion and Consistency Aware) decoder, a novel, training-free decoding algorithm that mitigates hallucinations at inference time by listening to these signals in the middle layers. We propose two metrics to quantify this instability in the middle layers, and use it to penalize outputs that exhibit high internal confusion, thereby steering the model towards more internally consistent and factually grounded outputs. We further propose a self-information gated variant, CoCoA-SIG, that dynamically modulates this penalty to selectively target high-surprise, unstable generations. Extensive experiments on diverse tasks, including question-answering, summarization and code generation demonstrate that CoCoA significantly improves factual correctness across multiple model families (e.g., Llama-3, Qwen-2.5, Mistral). By leveraging model-intrinsic signals, CoCoA offers an effective and broadly applicable method for enhancing the trustworthiness of LLMs at inference time, without requiring any model retraining.

</details>


### [122] [Where-to-Unmask: Ground-Truth-Guided Unmasking Order Learning for Masked Diffusion Language Models](https://arxiv.org/abs/2602.09501)
*Hikaru Asano,Tadashi Kozuno,Kuniaki Saito,Yukino Baba*

Main category: cs.CL

TL;DR: 本文提出Gt-Margin位置评分方法，定义为正确token与最强竞争token之间的概率差，用于生成最优解码顺序；并基于此构建监督式unmasking planner，显著提升MDLM在逻辑推理任务上的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有MDLM在推理阶段的unmasking顺序（where-to-unmask）依赖启发式置信度或高成本强化学习，缺乏高效、可学习的确定性策略。

Method: 提出Gt-Margin——一种基于真实token的概率边际得分，用于构造oracle unmasking顺序；进而通过learning-to-rank训练监督式unmasking planner，从masked上下文中预测该顺序。

Result: 所提planner在不修改原token预测模型的前提下，显著提升MDLM在逻辑推理基准上的生成准确率。

Conclusion: Gt-Margin揭示了‘先易后难’的unmasking顺序对生成质量的关键作用；监督式planner提供了一种轻量、高效且可泛化的解耦式控制机制。

Abstract: Masked Diffusion Language Models (MDLMs) generate text by iteratively filling masked tokens, requiring two coupled decisions at each step: which positions to unmask (where-to-unmask) and which tokens to place (what-to-unmask). While standard MDLM training directly optimizes token prediction (what-to-unmask), inference-time unmasking orders (where-to-unmask) are typically determined by heuristic confidence measures or trained through reinforcement learning with costly on-policy rollouts. To address this, we introduce Gt-Margin, a position-wise score derived from ground-truth tokens, defined as the probability margin between the correct token and its strongest alternative. Gt-Margin yields an oracle unmasking order that prioritizes easier positions first under each partially masked state. We demonstrate that leveraging this oracle unmasking order significantly enhances final generation quality, particularly on logical reasoning benchmarks. Building on this insight, we train a supervised unmasking planner via learning-to-rank to imitate the oracle ordering from masked contexts. The resulting planner integrates into standard MDLM sampling to select where-to-unmask, improving reasoning accuracy without modifying the token prediction model.

</details>


### [123] [AmharicIR+Instr: A Two-Dataset Resource for Neural Retrieval and Instruction Tuning](https://arxiv.org/abs/2602.09914)
*Tilahun Yeshambel,Moncef Garouani,Josiane Mothe*

Main category: cs.CL

TL;DR: 本文发布了两个高质量的阿姆哈拉语数据集，分别用于神经检索排序和指令跟随式文本生成，以解决低资源语言数据稀缺问题，并提供了可推广至其他低资源语言的方法论。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如阿姆哈拉语）缺乏大规模、高质量的监督数据，制约了神经检索与生成模型的发展。

Method: 构建了两个数据集：（i）含1091个三元组的检索-排序数据集，通过专家设计、网络采集和大模型辅助生成查询，并结合网络获取或大模型合成文档，再由母语者验证；（ii）含6285个提示-响应对的指令数据集，由多个大模型生成并经人工审校修正语法、相关性、流利度与事实合理性。所有数据以标准格式（CSV/JSON/JSONL）发布并划分训练/验证/测试集。

Result: 发布了首个面向阿姆哈拉语的大规模、人工验证的检索排序与指令微调数据集，支持DPR、ColBERT、SPLADE等模型训练与评测，并附带可迁移至其他低资源语言的数据构建方法论。

Conclusion: 该工作显著缓解了阿姆哈拉语NLP任务的数据瓶颈，为低资源语言的检索与生成研究提供了坚实基础与通用范式。

Abstract: Neural retrieval and GPT-style generative models rely on large, high-quality supervised data, which is still scarce for low-resource languages such as Amharic. We release an Amharic data resource consisting of two datasets that supports research on (i) neural retrieval-ranking and (ii) instruction-following text generation. The retrieval-ranking dataset contains 1,091 manually verified query-positive-negative document triplets drawn from diverse Amharic sources and constructed to support contrastive training and benchmarking of neural retrievers (e.g., DPR, ColBERT-style late interaction and SPLADE-style sparse neural retrieval). Triplets are created through a combination of expert-curated queries, web-derived queries, and LLM-assisted generation, with positive/negative documents selected from the web or synthesized by LLMs and then validated by native speakers. The instruction prompt-response dataset comprises 6,285 Amharic prompt-response pairs spanning multiple domains and instruction types, generated with several LLMs and refined through manual review and correction for grammaticality, relevance, fluency, and factual plausibility. We release both datasets with standardized splits and formats (CSV,JSON,JSONL) to enable reproducible work on Amharic retrieval, ranking, and generative modelling. These datasets also come with a methodology that can be generalized to other low-resource languages.

</details>


### [124] [EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies](https://arxiv.org/abs/2602.09514)
*Xavier Hu,Jinxiang Xia,Shengze Xu,Kangqi Song,Yishuo Yuan,Guibin Zhang,Jincheng Ren,Boyu Feng,Li Lu,Tieyong Zeng,Jiaheng Liu,Minghao Liu,Yuchen Elenor Jiang,Wei Wang,He Zhu,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 本文提出了EcoGym，一个用于评估LLM智能体在持续交互经济环境中长周期规划与执行能力的通用基准，包含三个多样化环境，并基于商业指标评估模型表现，揭示了当前大模型在策略与执行层面的系统性不足。


<details>
  <summary>Details</summary>
Motivation: 现有长周期规划评估框架多为片段式、领域特定或缺乏对持续经济动态的建模，难以真实衡量LLM智能体的战略一致性与鲁棒性。

Method: 构建了统一接口、预算化动作、无限时间步（>1000步）的EcoGym基准，涵盖Vending、Freelance和Operation三类经济环境，以净财富、收入、日活用户等商业结果作为评估指标。

Result: 在11个主流大模型上的实验表明：无一模型在全部三个场景中占优；模型普遍在高层策略或底层动作执行上存在显著次优性。

Conclusion: EcoGym为长周期智能体评估提供了开放、可扩展的测试平台，并有助于研究可控性与效用之间的权衡。

Abstract: Long-horizon planning is widely recognized as a core capability of autonomous LLM-based agents; however, current evaluation frameworks suffer from being largely episodic, domain-specific, or insufficiently grounded in persistent economic dynamics. We introduce EcoGym, a generalizable benchmark for continuous plan-and-execute decision making in interactive economies. EcoGym comprises three diverse environments: Vending, Freelance, and Operation, implemented in a unified decision-making process with standardized interfaces, and budgeted actions over an effectively unbounded horizon (1000+ steps if 365 day-loops for evaluation). The evaluation of EcoGym is based on business-relevant outcomes (e.g., net worth, income, and DAU), targeting long-term strategic coherence and robustness under partial observability and stochasticity. Experiments across eleven leading LLMs expose a systematic tension: no single model dominates across all three scenarios. Critically, we find that models exhibit significant suboptimality in either high-level strategies or efficient actions executions. EcoGym is released as an open, extensible testbed for transparent long-horizon agent evaluation and for studying controllability-utility trade-offs in realistic economic settings.

</details>


### [125] [The CLEF-2026 CheckThat! Lab: Advancing Multilingual Fact-Checking](https://arxiv.org/abs/2602.09516)
*Julia Maria Struß,Sebastian Schellhammer,Stefan Dietze,Venktesh V,Vinay Setty,Tanmoy Chakraborty,Preslav Nakov,Avishek Anand,Primakov Chungkham,Salim Hafid,Dhruv Sahnan,Konstantin Todorov*

Main category: cs.CL

TL;DR: CheckThat! lab focuses on advancing technologies to combat online disinformation across languages and platforms, with this year's edition emphasizing a verification pipeline including source retrieval for scientific claims, fact-checking numerical/temporal claims with reasoning, and generating full fact-checking articles.


<details>
  <summary>Details</summary>
Motivation: To advance innovative technologies that combat disinformation and manipulation in multilingual and multi-platform online communication.

Method: Organizing shared tasks centered on the verification pipeline—source retrieval, fact-checking with reasoning, and generation of fact-checking articles—across multilingual settings.

Result: Introduction of three new or extended tasks: (1) source retrieval for scientific web claims, (2) fact-checking numerical/temporal claims with added reasoning, and (3) generation of full fact-checking articles—posing classification, retrieval, and document/span-level generation challenges.

Conclusion: The CheckThat! lab continues to evolve its task design to reflect real-world complexity in disinformation detection, integrating retrieval, reasoning, and generation in multilingual verification pipelines.

Abstract: The CheckThat! lab aims to advance the development of innovative technologies combating disinformation and manipulation efforts in online communication across a multitude of languages and platforms. While in early editions the focus has been on core tasks of the verification pipeline (check-worthiness, evidence retrieval, and verification), in the past three editions, the lab added additional tasks linked to the verification process. In this year's edition, the verification pipeline is at the center again with the following tasks: Task 1 on source retrieval for scientific web claims (a follow-up of the 2025 edition), Task 2 on fact-checking numerical and temporal claims, which adds a reasoning component to the 2025 edition, and Task 3, which expands the verification pipeline with generation of full-fact-checking articles. These tasks represent challenging classification and retrieval problems as well as generation challenges at the document and span level, including multilingual settings.

</details>


### [126] [Knowledge Integration Decay in Search-Augmented Reasoning of Large Language Models](https://arxiv.org/abs/2602.09517)
*Sangwon Yu,Ik-hwan Kim,Donghun Kang,Bongkyu Hwang,Junhwa Choi,Suk-hoon Jung,Seungki Hong,Taehee Lee,Sungroh Yoon*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的推理时方法SAKE，通过在推理过程的开头和结尾锚定检索到的知识，缓解大语言模型在长链推理中出现的知识整合衰减（KID）问题，从而提升多跳问答与复杂推理性能。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型在搜索增强推理中存在知识整合衰减（KID）瓶颈：随着推理链增长，模型难以有效利用已检索到的相关证据，即使信息可用，性能仍受限。

Method: 提出Self-Anchored Knowledge Encoding（SAKE），一种训练无关的推理时策略：将检索知识同时嵌入推理链的起始与终止位置，以防止其被前置上下文淹没，维持语义完整性。

Result: 在多跳问答和复杂推理基准上广泛实验表明，SAKE显著缓解KID，提升模型性能。

Conclusion: SAKE是一种轻量、高效且无需训练的知识整合方案，适用于具身式（agentic）大语言模型。

Abstract: Modern Large Language Models (LLMs) have demonstrated remarkable capabilities in complex tasks by employing search-augmented reasoning to incorporate external knowledge into long chains of thought. However, we identify a critical yet underexplored bottleneck in this paradigm, termed Knowledge Integration Decay (KID). Specifically, we observe that as the length of reasoning generated before search grows, models increasingly fail to integrate retrieved evidence into subsequent reasoning steps, limiting performance even when relevant information is available. To address this, we propose Self-Anchored Knowledge Encoding (SAKE), a training-free inference-time strategy designed to stabilize knowledge utilization. By anchoring retrieved knowledge at both the beginning and end of the reasoning process, SAKE prevents it from being overshadowed by prior context, thereby preserving its semantic integrity. Extensive experiments on multi-hop QA and complex reasoning benchmarks demonstrate that SAKE significantly mitigates KID and improves performance, offering a lightweight yet effective solution for knowledge integration in agentic LLMs.

</details>


### [127] [UniARM: Towards a Unified Autoregressive Reward Model for Multi-Objective Test-Time Alignment](https://arxiv.org/abs/2602.09538)
*Hongyan Xie,Yikun Ban,Ruiyu Fang,Zixuan Huang,Deqing Wang,Jianxin Li,Yitong Yao,Chao Wang,Shuangyong Song*

Main category: cs.CL

TL;DR: 本文提出了一种新的多目标对齐方法UniARM，通过Preference-Modulated & Shared Low-Rank Adaptation（MoSLoRA）训练统一的自回归奖励模型，共享特征提取并用偏好向量调制，缓解特征纠缠，实现更精准的多目标测试时对齐。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归奖励模型（ARM）的多目标对齐方法在建模多个偏好目标时存在特征交互忽略或特征纠缠问题，导致生成结果与用户偏好不一致。

Method: 提出MoSLoRA：先用偏好无关模块提取共享特征，再用基于混合偏好向量的调制模块进行仿射变换；在此基础上构建UniARM框架，在单一参数空间联合建模所有偏好维度。

Result: UniARM在多目标测试时对齐任务中实现了更优的偏好一致性与可控权衡，且适配大规模冻结LLM，提升实用性。

Conclusion: 共享特征+偏好调制的设计有效缓解了多目标ARM中的特征纠缠问题，UniARM为低成本、高精度的多目标对齐提供了新范式。

Abstract: Multi-objective alignment aims to align LLM responses with multiple human preference objectives. Among existing methods, guiding the generation of frozen LLMs through autoregressive reward models (ARMs) to accomplish multi-objective test-time alignment is a low-cost solution. However, these methods typically rely on independent parameters for each preference objective, either by training ARMs independently across preference dimensions, which neglects interactions among preference features, or by training a single ARM with separate feature extraction modules for each preference, which can cause feature entanglement. Both strategies can result in misalignment between generated outputs and user preferences. To address this limitation, we propose Preference-Modulated \& Shared Low-Rank Adaptation (MoSLoRA) for ARM training, which first extracts shared features via a preference-agnostic module and then applies affine transformations to shared features via a preference modulation module conditioned on mixed preference vectors. This design mitigates feature entanglement and enables precise control over preference trade-offs during inference. Building on this, we introduce the Unified Autoregressive Reward Model (UniARM), a novel framework for multi-objective test-time alignment. UniARM jointly models all preference dimensions in a single parameter space, eliminating the need for independent parameters for each preference objective. es on larger-scale LLMs, enhancing its practical usability.

</details>


### [128] [Advancing Block Diffusion Language Models for Test-Time Scaling](https://arxiv.org/abs/2602.09555)
*Yi Lu,Deyang Kong,Jianing Wang,Linsen Guo,Xue Wang,Qi Guo,Tao Gui,Xuanjing Huang,Wei Ye,Shikun Zhang,Wei Wang*

Main category: cs.CL

TL;DR: 本文提出了一种面向块扩散语言模型（BDLM）的测试时缩放统一框架，包含自适应置信解码（BACD）和“粗思细评”（TCCF）范式，显著提升长链推理效率与效果。


<details>
  <summary>Details</summary>
Motivation: 现有BDLM在测试时缩放下探索不足，且在长思维链推理中面临解码速度与有效性难以兼顾的挑战。

Method: 提出Bounded Adaptive Confidence Decoding（BACD）实现难度感知的动态去噪；引入Think Coarse, Critic Fine（TCCF）范式，按推理阶段自适应分配块大小；采用Progressive Block Size Extension缓解大块尺寸带来的性能下降。

Result: 在TDAR-8B上应用BACD与TCCF，相较TraDo-8B实现2.26倍加速和AIME24分数+11.2点提升。

Conclusion: 该框架有效平衡了BDLM在复杂推理任务中的测试时效率与效果，推动其实际部署潜力。

Abstract: Recent advances in block diffusion language models have demonstrated competitive performance and strong scalability on reasoning tasks. However, existing BDLMs have limited exploration under the test-time scaling setting and face more severe decoding challenges in long Chain-of-Thought reasoning, particularly in balancing the decoding speed and effectiveness. In this work, we propose a unified framework for test-time scaling in BDLMs that introduces adaptivity in both decoding and block-wise generation. At the decoding level, we propose Bounded Adaptive Confidence Decoding (BACD), a difficulty-aware sampling strategy that dynamically adjusts denoising based on model confidence, accelerating inference while controlling error accumulation. Beyond step-wise adaptivity, we introduce Think Coarse, Critic Fine (TCCF), a test-time scaling paradigm that allocates large block sizes to exploratory reasoning and smaller block sizes to refinement, achieving an effective efficiency-effectiveness balance. To enable efficient and effective decoding with a large block size, we adopt Progressive Block Size Extension, which mitigates performance degradation when scaling block sizes. Extensive experiments show that applying BACD and TCCF to TDAR-8B yields significant improvements over strong baselines such as TraDo-8B (2.26x speedup, +11.2 points on AIME24). These results mark an important step toward unlocking the potential of BDLMs for test-time scaling in complex reasoning tasks.

</details>


### [129] [Aligning Tree-Search Policies with Fixed Token Budgets in Test-Time Scaling of LLMs](https://arxiv.org/abs/2602.09574)
*Sora Miyamoto,Daisuke Oba,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 本文提出了一种预算感知的蒙特卡洛树搜索算法（BG-MCTS），用于大语言模型的测试时解码，能根据剩余token预算动态调整搜索策略，在数学推理任务上显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有树搜索解码策略对token预算不敏感，仅将其作为终止条件，易导致后期过度分支或过早终止，难以适配实际部署中多变的固定预算约束。

Method: 提出Budget-Guided MCTS（BG-MCTS），使搜索策略随剩余token预算动态演化：初期广度探索，后期转向精细化推理与答案完成，并抑制浅层节点的晚期分支。

Result: 在MATH500和AIME24/25数据集上，使用开源大语言模型，BG-MCTS在不同token预算下均持续超越预算无关的树搜索基线方法。

Conclusion: 预算引导的搜索策略能更高效利用有限token资源，提升推理质量，为LLM在资源受限场景下的部署提供了新范式。

Abstract: Tree-search decoding is an effective form of test-time scaling for large language models (LLMs), but real-world deployment imposes a fixed per-query token budget that varies across settings. Existing tree-search policies are largely budget-agnostic, treating the budget as a termination condition, which can lead to late-stage over-branching or premature termination. We propose {Budget-Guided MCTS} (BG-MCTS), a tree-search decoding algorithm that aligns its search policy with the remaining token budget: it starts with broad exploration, then prioritizes refinement and answer completion as the budget depletes while reducing late-stage branching from shallow nodes. BG-MCTS consistently outperforms budget-agnostic tree-search baselines across different budgets on MATH500 and AIME24/25 with open-weight LLMs.

</details>


### [130] [Context-Aware Counterfactual Data Augmentation for Gender Bias Mitigation in Language Models](https://arxiv.org/abs/2602.09590)
*Shweta Parihar,Liu Guangliang,Natalie Parde,Lu Cheng*

Main category: cs.CL

TL;DR: 本文提出Context-CDA方法，利用大语言模型增强反事实数据增强的上下文相关性和多样性，并通过不确定性过滤提升小模型微调数据质量，在缓解性别偏见的同时不损害语言建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有反事实数据增强（CDA）方法在缓解语言模型社会偏见时，常因生成数据与真实分布不一致或忽略敏感属性的社会语境，导致语言建模能力下降。

Method: 提出Context-CDA：利用大语言模型为反事实样本添加丰富上下文以提升多样性与相关性；再用目标小语言模型进行不确定性评估，过滤低质量生成样本。

Result: 在性别偏见基准测试中，Context-CDA显著降低偏见，同时保持甚至提升语言建模性能，并可通过分析下一词预测概率分布偏移揭示社会偏见机制。

Conclusion: 上下文增强与不确定性过滤相结合的CDA策略，能在不牺牲语言建模能力的前提下有效缓解社会偏见，为可信语言模型构建提供新思路。

Abstract: A challenge in mitigating social bias in fine-tuned language models (LMs) is the potential reduction in language modeling capability, which can harm downstream performance. Counterfactual data augmentation (CDA), a widely used method for fine-tuning, highlights this issue by generating synthetic data that may align poorly with real-world distributions or creating overly simplistic counterfactuals that ignore the social context of altered sensitive attributes (e.g., gender) in the pretraining corpus. To address these limitations, we propose a simple yet effective context-augmented CDA method, Context-CDA, which uses large LMs to enhance the diversity and contextual relevance of the debiasing corpus. By minimizing discrepancies between the debiasing corpus and pretraining data through augmented context, this approach ensures better alignment, enhancing language modeling capability. We then employ uncertainty-based filtering to exclude generated counterfactuals considered low-quality by the target smaller LMs (i.e., LMs to be debiased), further improving the fine-tuning corpus quality. Experimental results on gender bias benchmarks demonstrate that Context-CDA effectively mitigates bias without sacrificing language modeling performance while offering insights into social biases by analyzing distribution shifts in next-token generation probabilities.

</details>


### [131] [On the Optimal Reasoning Length for RL-Trained Language Models](https://arxiv.org/abs/2602.09591)
*Daisuke Nohara,Taishi Nakamura,Rio Yokota*

Main category: cs.CL

TL;DR: 本文研究了强化学习（RL）在提升大语言模型推理能力时带来的输出长度增加与计算成本上升问题，对比多种长度控制方法，发现长度惩罚可能阻碍推理能力获取，而适当调优的长度控制可提升强先验推理能力模型的效率，并识别出RL策略中长输出导致分散、短输出导致思考不足两种失败模式。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽能提升大语言模型的推理能力，但常导致思维链（CoT）过长、训练与推理开销增大；现有长度控制方法缺乏对‘最优输出长度’这一关键权衡点的系统分析。

Method: 在Qwen3-1.7B Base和DeepSeek-R1-Distill-Qwen-1.5B两个模型上，对比多种长度控制方法（如长度惩罚等），并扩展至RL训练后的策略，分析输出长度对推理性能与效率的影响。

Result: 长度惩罚可能损害推理能力习得；对具备强先验推理能力的模型，适度长度控制可提升效率；识别出RL策略中两类失败模式：长输出加剧响应分散性，短输出引发欠思考。

Conclusion: 最优输出长度需依模型先验推理能力而定；盲目施加长度惩罚不可取，应针对性设计长度控制策略以兼顾效率与推理质量。

Abstract: Reinforcement learning substantially improves reasoning in large language models, but it also tends to lengthen chain of thought outputs and increase computational cost during both training and inference. Though length control methods have been proposed, it remains unclear what the optimal output length is for balancing efficiency and performance. In this work, we compare several length control methods on two models, Qwen3-1.7B Base and DeepSeek-R1-Distill-Qwen-1.5B. Our results indicate that length penalties may hinder reasoning acquisition, while properly tuned length control can improve efficiency for models with strong prior reasoning. By extending prior work to RL trained policies, we identify two failure modes, 1) long outputs increase dispersion, and 2) short outputs lead to under-thinking.

</details>


### [132] [Learning from the Irrecoverable: Error-Localized Policy Optimization for Tool-Integrated LLM Reasoning](https://arxiv.org/abs/2602.09598)
*Qiao Liang,Yuke Zhu,Chao Ge,Lei Yang,Ying Shen,Bo Zheng,Sheng Guo*

Main category: cs.CL

TL;DR: 本文提出Error-Localized Policy Optimization (ELPO)，通过二分搜索 rollout 树定位长程工具集成推理（TIR）中首个不可恢复错误步骤，结合分层优势归因与误差局部化自适应裁剪，提升步级信用分配与策略优化效果，在多个TIR基准上显著优于现有Agentic RL方法。


<details>
  <summary>Details</summary>
Motivation: 工具集成推理（TIR）中，结果导向的强化学习面临奖励稀疏、延迟及步级信用分配弱的问题；尤其在长程轨迹中，早期不可恢复错误决定最终成败，亟需精准定位并利用该关键错误步进行细粒度优化。

Method: 提出Error-Localized Policy Optimization（ELPO）：1）在固定rollout预算下构建二分搜索rollout树以定位首个不可恢复错误步；2）将树结构转化为稳定学习信号，采用分层优势归因；3）引入误差局部化自适应裁剪机制，增强对关键错误步及其后续步骤的修正更新。

Result: ELPO在数学、科学问答和代码执行等TIR基准上持续超越强Agentic RL基线（如ReAct+PPO），在Pass@K、Major@K、rollout排序质量及工具调用效率方面均有提升，且采样预算相当。

Conclusion: ELPO通过精准错误定位与细粒度信用分配，有效缓解TIR中长程依赖与稀疏奖励挑战，为LLM智能体的稳健推理优化提供了新范式。

Abstract: Tool-integrated reasoning (TIR) enables LLM agents to solve tasks through planning, tool use, and iterative revision, but outcome-only reinforcement learning in this setting suffers from sparse, delayed rewards and weak step-level credit assignment. In long-horizon TIR trajectories, an early irrecoverable mistake can determine success or failure, making it crucial to localize the first irrecoverable step and leverage it for fine-grained credit assignment. We propose Error-Localized Policy Optimization (ELPO), which localizes the first irrecoverable step via binary-search rollout trees under a fixed rollout budget, converts the resulting tree into stable learning signals through hierarchical advantage attribution, and applies error-localized adaptive clipping to strengthen corrective updates on the critical step and its suffix. Across TIR benchmarks in math, science QA, and code execution, ELPO consistently outperforms strong Agentic RL baselines under comparable sampling budgets, with additional gains in Pass@K and Major@K scaling, rollout ranking quality, and tool-call efficiency. Our code will be publicly released soon.

</details>


### [133] [AlignTune: Modular Toolkit for Post-Training Alignment of Large Language Models](https://arxiv.org/abs/2602.09621)
*R E Zera Marveen Lyngkhoi,Chirag Chawla,Pratinav Seth,Utsav Avaiya,Soham Bhattacharjee,Mykola Khandoga,Rui Yuan,Vinay Kumar Sankarapu*

Main category: cs.CL

TL;DR: AlignTune是一个模块化工具包，旨在统一和标准化大语言模型后训练对齐流程，解决现有实践中后端耦合、奖励分散和不可复现等问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM后训练对齐实践存在后端干扰、奖励碎片化和流水线不可复现三大障碍，导致实验难以复现和比较。

Method: 提出AlignTune工具包，提供统一接口支持SFT和RLHF式优化，支持TRL与Unsloth后端切换；标准化配置、设计可扩展的奖励层（规则+学习型）、集成标准与自定义评估。

Result: 实现了后端逻辑隔离于单一工厂边界，支持可控对比和可复现的对齐实验。

Conclusion: AlignTune通过模块化与接口抽象，提升了对齐研究的可复现性、灵活性与工程效率。

Abstract: Post-training alignment is central to deploying large language models (LLMs), yet practical workflows remain split across backend-specific tools and ad-hoc glue code, making experiments hard to reproduce. We identify backend interference, reward fragmentation, and irreproducible pipelines as key obstacles in alignment research. We introduce AlignTune, a modular toolkit exposing a unified interface for supervised fine-tuning (SFT) and RLHF-style optimization with interchangeable TRL and Unsloth backends. AlignTune standardizes configuration, provides an extensible reward layer (rule-based and learned), and integrates evaluation over standard benchmarks and custom tasks. By isolating backend-specific logic behind a single factory boundary, AlignTune enables controlled comparisons and reproducible alignment experiments.

</details>


### [134] [MILE-RefHumEval: A Reference-Free, Multi-Independent LLM Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2602.09624)
*Nalin Srun,Parisa Rastin,Guénaël Cabanes,Lydia Boudjeloud Assala*

Main category: cs.CL

TL;DR: MILE-RefHumEval 是一种无需参考答案和人工标注的 LLM 评估框架，通过人类对齐的多提示评估器集成实现高效、可解释且与人类判断高度一致的自动评估。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM评估方法依赖真实标签、人工协调成本高、扩展性差等问题，提供更贴近真实应用场景的无参考评估方案。

Method: 构建基于人类对齐schema的独立提示评估器集合，支持离散与连续评分；针对不同任务（如摘要、图像描述、对话等）设计任务特定提示，并采用最优候选选择策略。

Result: 实验表明该方法与人类判断高度一致，性能优于先前无参考方法，同时显著降低计算开销。

Conclusion: MILE-RefHumEval 是一种灵活、可解释、可扩展且人类对齐的高效LLM评估框架，适用于实际部署场景。

Abstract: We introduce MILE-RefHumEval, a reference-free framework for evaluating Large Language Models (LLMs) without ground-truth annotations or evaluator coordination. It leverages an ensemble of independently prompted evaluators guided by a human-aligned schema, supporting both discrete and continuous scoring judgement. With task-specific prompts from best candidate selection, summarization and image captioning to dialogue, MILE-RefHumEval provides flexible, interpretable, and scalable assessments. Experiments show it aligns closely with human judgments, outperforms prior methods, and reduces computational overhead, offering an efficient, robust, and human-aligned solution for real-world LLM evaluation.

</details>


### [135] [MATA: Multi-Agent Framework for Reliable and Flexible Table Question Answering](https://arxiv.org/abs/2602.09642)
*Sieun Hyeon,Jusang Oh,Sunghwan Steve Cho,Jaeyoung Do*

Main category: cs.CL

TL;DR: 本文提出了MATA，一种基于多智能体的表格问答（TableQA）框架，利用多个互补推理路径和由小型语言模型构建的工具集，在保证高准确率的同时显著提升效率与可扩展性，尤其适用于资源受限或隐私敏感场景。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在表格理解任务（如TableQA）中虽有进展，但仍面临可靠性、可扩展性和效率方面的挑战，特别是在资源受限或隐私敏感环境中。

Method: 提出MATA多智能体框架：通过多种推理风格生成候选答案，并利用小型语言模型构建的工具进行答案精炼或选择；引入优化算法以最小化高成本的大语言模型调用次数。

Result: 在两个不同难度基准数据集上，使用十种不同大语言模型的广泛实验表明，MATA在准确率和推理效率方面均达到当前最优水平，且避免了过度的大语言模型推理开销。

Conclusion: 精心编排多个推理路径可实现可扩展、可靠的表格问答，MATA在保持高性能的同时支持小模型部署与跨LLM类型适配。

Abstract: Recent advances in Large Language Models (LLMs) have significantly improved table understanding tasks such as Table Question Answering (TableQA), yet challenges remain in ensuring reliability, scalability, and efficiency, especially in resource-constrained or privacy-sensitive environments. In this paper, we introduce MATA, a multi-agent TableQA framework that leverages multiple complementary reasoning paths and a set of tools built with small language models. MATA generates candidate answers through diverse reasoning styles for a given table and question, then refines or selects the optimal answer with the help of these tools. Furthermore, it incorporates an algorithm designed to minimize expensive LLM agent calls, enhancing overall efficiency. MATA maintains strong performance with small, open-source models and adapts easily across various LLM types. Extensive experiments on two benchmarks of varying difficulty with ten different LLMs demonstrate that MATA achieves state-of-the-art accuracy and highly efficient reasoning while avoiding excessive LLM inference. Our results highlight that careful orchestration of multiple reasoning pathways yields scalable and reliable TableQA. The code is available at https://github.com/AIDAS-Lab/MATA.

</details>


### [136] [Life Cycle-Aware Evaluation of Knowledge Distillation for Machine Translation: Environmental Impact and Translation Quality Trade-offs](https://arxiv.org/abs/2602.09691)
*Joseph Attieh,Timothee Mickus,Anne-Laure Ligozat,Aurélie Névéol,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 本文评估了知识蒸馏（KD）在机器翻译中的翻译质量与计算成本（以碳足迹衡量）的权衡，发现蒸馏开销在小规模部署时占主导，而推理开销在大规模部署时占主导；KD仅在超过任务依赖的使用阈值后才具环保效益；词级蒸馏通常比序列级蒸馏具有更优的碳足迹-质量权衡。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只报告学生模型的翻译质量，忽略知识蒸馏本身的计算复杂度，导致在算力约束下难以选择最优KD方法。

Method: 采用机器学习生命周期评估（MLCA）工具，将计算成本量化为碳足迹，涵盖教师训练、蒸馏过程和推理阶段的运行时排放及硬件制造的分摊成本，并系统比较多种代表性KD方法在翻译质量与碳足迹上的表现。

Result: （i）小规模部署时蒸馏开销主导总碳足迹；（ii）大规模部署时推理开销主导，KD仅在超过任务相关使用阈值后才体现净减排效益；（iii）词级蒸馏相比序列级蒸馏通常提供更优的碳足迹-质量权衡。

Conclusion: 提出了一套可复现的评估协议，为在明确质量与计算约束下选择知识蒸馏方法提供实践指导。

Abstract: Knowledge distillation (KD) is a tool to compress a larger system (teacher) into a smaller one (student). In machine translation, studies typically report only the translation quality of the student and omit the computational complexity of performing KD, making it difficult to select among the many available KD choices under compute-induced constraints. In this study, we evaluate representative KD methods by considering both translation quality and computational cost. We express computational cost as a carbon footprint using the machine learning life cycle assessment (MLCA) tool. This assessment accounts for runtime operational emissions and amortized hardware production costs throughout the KD model life cycle (teacher training, distillation, and inference). We find that (i) distillation overhead dominates the total footprint at small deployment volumes, (ii) inference dominates at scale, making KD beneficial only beyond a task-dependent usage threshold, and (iii) word-level distillation typically offers more favorable footprint-quality trade-offs than sequence-level distillation. Our protocol provides reproducible guidance for selecting KD methods under explicit quality and compute-induced constraints.

</details>


### [137] [Maastricht University at AMIYA: Adapting LLMs for Dialectal Arabic using Fine-tuning and MBR Decoding](https://arxiv.org/abs/2602.09703)
*Abdulhai Alali,Abderrahmane Issam*

Main category: cs.CL

TL;DR: This paper proposes a framework using LoRA fine-tuning, adapter merging, and dialect-aware MBR decoding to enhance LLMs' performance on Arabic dialects (Syrian, Moroccan, Saudi), improving dialectal fidelity without sacrificing semantic accuracy.


<details>
  <summary>Details</summary>
Motivation: Dialect variations—especially in Arabic—are underrepresented in LLMs due to limited data and high linguistic variation, despite growing multilingual support.

Method: Adapts a pre-trained LLM via Low Rank Adaptation (LoRA) on monolingual and English–dialect parallel data, followed by adapter merging and dialect-aware Minimum Bayes Risk (MBR) decoding.

Result: Experiments on Syrian, Moroccan, and Saudi Arabic show improved dialectal fidelity and preserved semantic accuracy; adapter merging and MBR jointly enhance robustness.

Conclusion: The proposed compact framework effectively boosts dialectal Arabic generation and translation, offering a practical solution for low-resource dialect adaptation.

Abstract: Large Language Models (LLMs) are becoming increasingly multilingual, supporting hundreds of languages, especially high resource ones. Unfortunately, Dialect variations are still underrepresented due to limited data and linguistic variation. In this work, we adapt a pre-trained LLM to improve dialectal performance. Specifically, we use Low Rank Adaptation (LoRA) fine-tuning on monolingual and English Dialect parallel data, adapter merging and dialect-aware MBR decoding to improve dialectal fidelity generation and translation. Experiments on Syrian, Moroccan, and Saudi Arabic show that merging and MBR improve dialectal fidelity while preserving semantic accuracy. This combination provides a compact and effective framework for robust dialectal Arabic generation.

</details>


### [138] [TraceMem: Weaving Narrative Memory Schemata from User Conversational Traces](https://arxiv.org/abs/2602.09712)
*Yiming Shu,Pei Liu,Tiange Zhang,Ruiyang Gao,Jun Ma,Chen Sun*

Main category: cs.CL

TL;DR: 本文提出TraceMem，一种受认知启发的框架，通过三阶段流程（短期记忆处理、突触记忆巩固、系统记忆巩固）从用户对话轨迹中构建结构化、叙事性的记忆图式，并在LoCoMo基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）受限于有限的上下文窗口，难以维持长期交互；现有记忆系统将对话视为离散片段，无法捕捉对话流的叙事连贯性。

Method: TraceMem采用三阶段认知启发式流程：（1）短期记忆处理——基于演绎的主题分割识别对话片段边界并提取语义表征；（2）突触记忆巩固——将片段总结为情景记忆，并与语义共同提炼为用户特异性轨迹；（3）系统记忆巩固——通过两阶段分层聚类将轨迹组织为随时间演化的主题一致叙事线，最终封装为结构化用户记忆卡；并引入智能体式搜索机制支持记忆利用。

Result: 在LoCoMo基准上达到SOTA性能；显著提升多跳推理与时间推理能力；实证表明其叙事建构能力对深层叙事理解至关重要。

Conclusion: TraceMem通过构建连贯叙事记忆图式，有效缓解LLMs长程交互瓶颈，为构建具备持续理解与记忆能力的智能体提供了新范式，并推动记忆系统研究的发展。

Abstract: Sustaining long-term interactions remains a bottleneck for Large Language Models (LLMs), as their limited context windows struggle to manage dialogue histories that extend over time. Existing memory systems often treat interactions as disjointed snippets, failing to capture the underlying narrative coherence of the dialogue stream. We propose TraceMem, a cognitively-inspired framework that weaves structured, narrative memory schemata from user conversational traces through a three-stage pipeline: (1) Short-term Memory Processing, which employs a deductive topic segmentation approach to demarcate episode boundaries and extract semantic representation; (2) Synaptic Memory Consolidation, a process that summarizes episodes into episodic memories before distilling them alongside semantics into user-specific traces; and (3) Systems Memory Consolidation, which utilizes two-stage hierarchical clustering to organize these traces into coherent, time-evolving narrative threads under unifying themes. These threads are encapsulated into structured user memory cards, forming narrative memory schemata. For memory utilization, we provide an agentic search mechanism to enhance reasoning process. Evaluation on the LoCoMo benchmark shows that TraceMem achieves state-of-the-art performance with a brain-inspired architecture. Analysis shows that by constructing coherent narratives, it surpasses baselines in multi-hop and temporal reasoning, underscoring its essential role in deep narrative comprehension. Additionally, we provide an open discussion on memory systems, offering our perspectives and future outlook on the field. Our code implementation is available at: https://github.com/YimingShu-teay/TraceMem

</details>


### [139] [Unsupervised Layer-Wise Dynamic Test Time Adaptation for LLMs](https://arxiv.org/abs/2602.09719)
*Longhuan Xu,Cunjian Chen,Feng Yin*

Main category: cs.CL

TL;DR: 本文提出了一种层自适应的动态测试时适配（TTA）框架，通过轻量级超网络为LoRA参数预测每层、每步的学习率缩放因子，以提升无监督、样本级TTA的稳定性与性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督、样本级测试时适配（TTA）方法因固定学习率易导致过拟合、分布偏移和生成质量下降，亟需更稳定、细粒度的适配机制。

Method: 提出层-wise 动态TTA框架：仅更新LoRA参数，并用轻量级超网络根据prompt表示、LLM结构和适配步数，动态预测各层各步的学习率乘子。

Result: 在多个数据集和大语言模型上实验表明，该方法显著提升TTA稳定性与生成性能，学会有效的跨步长与Transformer层的缩放模式。

Conclusion: 层自适应的动态学习率调控是提升无监督样本级TTA鲁棒性与效果的关键，验证了细粒度、上下文感知的测试时优化的可行性与优势。

Abstract: Test-time adaptation (TTA) for large language models (LLMs) updates model parameters at inference time using signals available at deployment. This paper focuses on a common yet under-explored regime: unsupervised, sample-specific TTA, where the model adapts independently for each prompt using only the prompt itself, without gold answers or external supervision. Although appealing, naive unsupervised TTA with a fixed, handcrafted learning rate can be unstable: updates may overfit to prompt-specific statistics, drift from the desired answer distribution, and ultimately degrade generation quality. This failure mode is not surprising, as in this case TTA must adapt to a single prompt within only a few gradient steps, unlike standard training that averages updates over large datasets and long optimization horizons. Therefore, we propose layer-wise dynamic test-time adaptation, a framework which explicitly modulates TTA strength as a function of prompt representation, LLM structure and adaptation step. In our setting, TTA updates only LoRA parameters, and a lightweight hypernetwork predicts per-layer, per-step learning-rate multipliers, enabling fine-grained control. Experiments across various datasets and LLMs consistently show that our method substantially strengthens TTA by learning effective scaling patterns over adaptation steps and transformer layer projections, improving stability while delivering better performance.

</details>


### [140] [AI-Assisted Scientific Assessment: A Case Study on Climate Change](https://arxiv.org/abs/2602.09723)
*Christian Buck,Levke Caesar,Michelle Chen Huebscher,Massimiliano Ciaramita,Erich M. Fischer,Zeke Hausfather,Özge Kart Tokmak,Reto Knutti,Markus Leippold,Joseph Ludescher,Katharine J. Mach,Sofia Palazzo Corner,Kasra Rafiezadeh Shahi,Johan Rockström,Joeri Rogelj,Boris Sakschewski*

Main category: cs.CL

TL;DR: 本文探讨了AI作为科学协作伙伴在气候科学中的应用，特别是在大西洋经向翻转环流（AMOC）稳定性评估中，验证了AI可加速文献综述与报告撰写，但需专家深度参与以保障科学严谨性。


<details>
  <summary>Details</summary>
Motivation: 现有AI‘猜-验’范式难以适用于无法重复验证、依赖理论与证据共识构建真理的复杂科学问题，亟需支持协作式科学评估的新AI范式。

Method: 将Gemini驱动的AI环境嵌入标准科研流程，与13位气候科学家合作，围绕AMOC稳定性开展协同评估，记录文献综述、修订轮次、内容来源及专家干预情况。

Result: 团队在46+人小时内完成79篇文献的综合报告，历经104轮修订；多数AI生成内容被保留，AI提升了逻辑一致性与呈现质量，但仅约45%内容由AI直接产出，其余依赖专家补充与深度把关。

Conclusion: AI可有效辅助复杂科学评估任务，提升效率与表达质量，但尚不能替代专家判断；成功的关键在于人机协同闭环，强调AI为‘协作者’而非‘决策者’。

Abstract: The emerging paradigm of AI co-scientists focuses on tasks characterized by repeatable verification, where agents explore search spaces in 'guess and check' loops. This paradigm does not extend to problems where repeated evaluation is impossible and ground truth is established by the consensus synthesis of theory and existing evidence. We evaluate a Gemini-based AI environment designed to support collaborative scientific assessment, integrated into a standard scientific workflow. In collaboration with a diverse group of 13 scientists working in the field of climate science, we tested the system on a complex topic: the stability of the Atlantic Meridional Overturning Circulation (AMOC). Our results show that AI can accelerate the scientific workflow. The group produced a comprehensive synthesis of 79 papers through 104 revision cycles in just over 46 person-hours. AI contribution was significant: most AI-generated content was retained in the report. AI also helped maintain logical consistency and presentation quality. However, expert additions were crucial to ensure its acceptability: less than half of the report was produced by AI. Furthermore, substantial oversight was required to expand and elevate the content to rigorous scientific standards.

</details>


### [141] [Targum -- A Multilingual New Testament Translation Corpus](https://arxiv.org/abs/2602.09724)
*Maciej Rapacz,Aleksander Smywiński-Pohl*

Main category: cs.CL

TL;DR: 本文介绍了一个包含657个新约译本的多语种语料库，涵盖英语、法语、意大利语、波兰语和西班牙语五种语言，具有前所未有的历史深度，并通过标准化元数据标注支持多层次翻译史定量研究。


<details>
  <summary>Details</summary>
Motivation: 现有语料库注重语言广度而忽视翻译历史深度，难以支持对欧洲语言丰富圣经翻译史的深入研究。

Method: 构建了一个涵盖5种语言、657个新约译本（其中352个为唯一版本）的多语种语料库，数据来自12个在线圣经图书馆和1个已有语料库，并对每个译本进行人工元数据标注，包括作品标准标识符、具体版本及修订年份。

Result: 提供了首个支持灵活、多层次分析（如KJV谱系微观分析或跨版本宏观去重研究）的标准化圣经翻译语料库。

Conclusion: 该语料库填补了翻译史定量研究中历史深度不足的空白，确立了翻译史研究的新基准。

Abstract: Many European languages possess rich biblical translation histories, yet existing corpora - in prioritizing linguistic breadth - often fail to capture this depth. To address this gap, we introduce a multilingual corpus of 657 New Testament translations, of which 352 are unique, with unprecedented depth in five languages: English (208 unique versions from 396 total), French (41 from 78), Italian (18 from 33), Polish (30 from 48), and Spanish (55 from 102). Aggregated from 12 online biblical libraries and one preexisting corpus, each translation is manually annotated with metadata that maps the text to a standardized identifier for the work, its specific edition, and its year of revision. This canonicalization empowers researchers to define "uniqueness" for their own needs: they can perform micro-level analyses on translation families, such as the KJV lineage, or conduct macro-level studies by deduplicating closely related texts. By providing the first resource designed for such flexible, multilevel analysis, our corpus establishes a new benchmark for the quantitative study of translation history.

</details>


### [142] [Improving Interpretability of Lexical Semantic Change with Neurobiological Features](https://arxiv.org/abs/2602.09760)
*Kohei Oda,Hiroya Takamura,Kiyoaki Shirai,Natthawut Kertkeidkachorn*

Main category: cs.CL

TL;DR: 本文提出了一种将词的上下文化嵌入映射到神经生物学特征空间的新方法，以提升词汇语义变化（LSC）的可解释性，并在LSC程度估计任务上取得优越性能，同时支持新型LSC类型发现与定向检索。


<details>
  <summary>Details</summary>
Motivation: 现有LSC研究多关注变化程度估计的性能，但缺乏对语义如何变化的可解释性分析，而提升可解释性有助于获得新洞见。

Method: 将预训练语言模型生成的词上下文化嵌入映射到神经生物学特征空间，该空间每个维度对应一个词的原始语义特征，值表示该特征强度。

Result: 在LSC程度估计任务中性能优于多数先前方法；并借此发现了以往被忽视的LSC类型，且能有效检索具有特定LSC类型的词语。

Conclusion: 所提方法兼顾高可解释性与高性能，为LSC研究提供了新的分析范式和实用工具。

Abstract: Lexical Semantic Change (LSC) is the phenomenon in which the meaning of a word change over time. Most studies on LSC focus on improving the performance of estimating the degree of LSC, however, it is often difficult to interpret how the meaning of a word change. Enhancing the interpretability of LSC is a significant challenge as it could lead to novel insights in this field. To tackle this challenge, we propose a method to map the semantic space of contextualized embeddings of words obtained by a pre-trained language model to a neurobiological feature space. In the neurobiological feature space, each dimension corresponds to a primitive feature of words, and its value represents the intensity of that feature. This enables humans to interpret LSC systematically. When employed for the estimation of the degree of LSC, our method demonstrates superior performance in comparison to the majority of the previous methods. In addition, given the high interpretability of the proposed method, several analyses on LSC are carried out. The results demonstrate that our method not only discovers interesting types of LSC that have been overlooked in previous studies but also effectively searches for words with specific types of LSC.

</details>


### [143] [Where Are We At with Automatic Speech Recognition for the Bambara Language?](https://arxiv.org/abs/2602.09785)
*Seydou Diallo,Yacouba Diarra,Mamadou K. Keita,Panga Azazia Kamaté,Adam Bouno Kampo,Aboubacar Ouattara*

Main category: cs.CL

TL;DR: 本文提出了首个用于评估班巴拉语自动语音识别（ASR）的标准化基准，基于一小时专业录制的马里宪法文本；在37个模型测试中，最优WER为46.76%，CER为13.00%，表明当前ASR性能远未达实际部署标准，且多语言预训练与模型扩展不足以解决低资源语言问题。


<details>
  <summary>Details</summary>
Motivation: 解决班巴拉语等低资源语言缺乏标准化ASR评估基准的问题，推动其语音技术发展。

Method: 构建一个基于马里宪法文本、一小时长、声学与语言条件近最优的专业录音基准数据集，并对37种模型（含班巴拉语专用及商用多语言模型）进行WER和CER评测。

Result: 最优WER为46.76%，最优CER为13.00%；多个主流多语言模型WER超100%；该基准代表最简正式口语场景，实际场景性能尚待验证。

Conclusion: 多语言预训练与模型规模扩大不足以弥补低资源语言的数据与语言学差距；需针对性建模与数据建设；作者开源基准与公共排行榜以支持后续研究。

Abstract: This paper introduces the first standardized benchmark for evaluating Automatic Speech Recognition (ASR) in the Bambara language, utilizing one hour of professionally recorded Malian constitutional text. Designed as a controlled reference set under near-optimal acoustic and linguistic conditions, the benchmark was used to evaluate 37 models, ranging from Bambara-trained systems to large-scale commercial models. Our findings reveal that current ASR performance remains significantly below deployment standards in a narrow formal domain; the top-performing system in terms of Word Error Rate (WER) achieved 46.76\% and the best Character Error Rate (CER) of 13.00\% was set by another model, while several prominent multilingual models exceeded 100\% WER. These results suggest that multilingual pre-training and model scaling alone are insufficient for underrepresented languages. Furthermore, because this dataset represents a best-case scenario of the most simplified and formal form of spoken Bambara, these figures are yet to be tested against practical, real-world settings. We provide the benchmark and an accompanying public leaderboard to facilitate transparent evaluation and future research in Bambara speech technology.

</details>


### [144] [Decomposing Reasoning Efficiency in Large Language Models](https://arxiv.org/abs/2602.09805)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: 本文提出了一种可选追踪的框架，用于分解大语言模型在推理任务中的token效率，涵盖完成率、条件正确性、冗余度等可解释维度，并进一步分析了冗余度与任务工作量的关系及推理轨迹质量，揭示了准确率与token效率排名存在显著差异，不同模型存在不同的效率瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有评估仅报告最终准确率，掩盖了token的使用分布与浪费情况，缺乏对推理过程中token效率的细粒度分析。

Method: 提出trace-optional框架，将token效率分解为完成率、条件正确性、verbosity（含平均口语化开销和耦合系数）；当有推理轨迹时，引入无需人工标注的确定性轨迹质量指标（如grounding、重复、prompt复制）。

Result: 在CogniLoad上评估25个模型发现：准确率与token效率排名仅中度相关（Spearman ρ=0.63）；效率差异主因是条件正确性；口语化开销跨模型差异达约9倍，且与模型规模弱相关。

Conclusion: token效率需多维分解才能揭示真实瓶颈，不同模型需差异化优化策略，该框架为高效推理提供了可解释、可干预的评估基础。

Abstract: Large language models trained for reasoning trade off inference tokens against accuracy, yet standard evaluations report only final accuracy, obscuring where tokens are spent or wasted. We introduce a trace-optional framework that decomposes token efficiency into interpretable factors: completion under a fixed token budget (avoiding truncation), conditional correctness given completion, and verbosity (token usage). When benchmark metadata provides per-instance workload proxies, we further factor verbosity into two components: mean verbalization overhead (tokens per work unit) and a coupling coefficient capturing how overhead scales with task workload. When reasoning traces are available, we add deterministic trace-quality measures (grounding, repetition, prompt copying) to separate degenerate looping from verbose-but-engaged reasoning, avoiding human labeling and LLM judges. Evaluating 25 models on CogniLoad, we find that accuracy and token-efficiency rankings diverge (Spearman $ρ=0.63$), efficiency gaps are often driven by conditional correctness, and verbalization overhead varies by about 9 times (only weakly related to model scale). Our decomposition reveals distinct bottleneck profiles that suggest different efficiency interventions.

</details>


### [145] [AnalyticsGPT: An LLM Workflow for Scientometric Question Answering](https://arxiv.org/abs/2602.09817)
*Khang Ly,Georgios Cheirmpos,Adrian Raudaschl,Christopher James,Seyed Amin Tabatabaei*

Main category: cs.CL

TL;DR: 本文提出了AnalyticsGPT，一个基于大语言模型（LLM）的端到端工作流系统，用于回答科学计量学问题（即‘科学的科学’类元科学研究问题），融合了检索增强生成（RAG）与智能体（agentic）规划能力，并在专有科研绩效评估平台数据上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 科学计量学问答这一下游任务被长期忽视，其在问题理解（如学术实体识别）和多维度数据检索（如影响因子等指标）方面具有独特挑战，需结合LLM的规划、推理与任务分解能力加以解决。

Method: 设计并实现了一个顺序式LLM工作流，整合检索增强生成（RAG）与智能体式任务规划；使用专有科研绩效评估平台作为检索数据库；采用领域专家评估与LLM-as-judges双轨机制进行评测。

Result: 成功构建并验证了AnalyticsGPT系统在科学计量学问答任务上的可行性与有效性，提供了该小众下游任务中LLM应用的实证洞见。

Conclusion: LLM具备支撑复杂元科学研究任务的潜力，尤其在结合结构化检索、任务分解与结果综合分析时表现突出；本工作为科学学自动化分析提供了可复现的技术路径与开源资源。

Abstract: This paper introduces AnalyticsGPT, an intuitive and efficient large language model (LLM)-powered workflow for scientometric question answering. This underrepresented downstream task addresses the subcategory of meta-scientific questions concerning the "science of science." When compared to traditional scientific question answering based on papers, the task poses unique challenges in the planning phase. Namely, the need for named-entity recognition of academic entities within questions and multi-faceted data retrieval involving scientometric indices, e.g. impact factors. Beyond their exceptional capacity for treating traditional natural language processing tasks, LLMs have shown great potential in more complex applications, such as task decomposition and planning and reasoning. In this paper, we explore the application of LLMs to scientometric question answering, and describe an end-to-end system implementing a sequential workflow with retrieval-augmented generation and agentic concepts. We also address the secondary task of effectively synthesizing the data into presentable and well-structured high-level analyses. As a database for retrieval-augmented generation, we leverage a proprietary research performance assessment platform. For evaluation, we consult experienced subject matter experts and leverage LLMs-as-judges. In doing so, we provide valuable insights on the efficacy of LLMs towards a niche downstream task. Our (skeleton) code and prompts are available at: https://github.com/lyvykhang/llm-agents-scientometric-qa/tree/acl.

</details>


### [146] [Text summarization via global structure awareness](https://arxiv.org/abs/2602.09821)
*Jiaquan Zhang,Chaoning Zhang,Shuxu Chen,Yibei Liu,Chenghao Li,Qigan Sun,Shuai Yuan,Fachrina Dewi Puspitasari,Dongshen Han,Guoqing Wang,Sung-Ho Bae,Yang Yang*

Main category: cs.CL

TL;DR: 本文提出GloSA-sum，一种基于拓扑数据分析（TDA）的全局结构感知文本摘要方法，通过语义加权图与持久同调识别核心语义与逻辑结构，并结合轻量级代理指标和分层策略，在保持语义与逻辑完整性的同时提升效率，尤其利于LLM下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有摘要方法多关注模型改进或句子级剪枝，忽视全局结构，导致连贯性受损、下游性能下降；而使用大语言模型虽精度高但资源开销大。

Method: 构建语义加权句嵌入图，利用持久同调识别核心语义与逻辑结构并存入‘保护池’作为摘要主干；设计拓扑引导的迭代策略，用轻量代理指标评估句子重要性；引入分层策略融合段级与全局摘要。

Result: 在多个数据集上验证，GloSA-sum有效降低冗余，保持语义与逻辑完整性，在准确率与效率间取得平衡，并能缩短LLM输入上下文同时保留关键推理链，提升下游任务性能。

Conclusion: GloSA-sum是首个将拓扑数据分析引入文本摘要的工作，实现了全局结构感知，在长文档处理中兼顾效率、语义保真与逻辑连贯，为高效鲁棒摘要提供了新范式。

Abstract: Text summarization is a fundamental task in natural language processing (NLP), and the information explosion has made long-document processing increasingly demanding, making summarization essential. Existing research mainly focuses on model improvements and sentence-level pruning, but often overlooks global structure, leading to disrupted coherence and weakened downstream performance. Some studies employ large language models (LLMs), which achieve higher accuracy but incur substantial resource and time costs. To address these issues, we introduce GloSA-sum, the first summarization approach that achieves global structure awareness via topological data analysis (TDA). GloSA-sum summarizes text efficiently while preserving semantic cores and logical dependencies. Specifically, we construct a semantic-weighted graph from sentence embeddings, where persistent homology identifies core semantics and logical structures, preserved in a ``protection pool'' as the backbone for summarization. We design a topology-guided iterative strategy, where lightweight proxy metrics approximate sentence importance to avoid repeated high-cost computations, thus preserving structural integrity while improving efficiency. To further enhance long-text processing, we propose a hierarchical strategy that integrates segment-level and global summarization. Experiments on multiple datasets demonstrate that GloSA-sum reduces redundancy while preserving semantic and logical integrity, striking a balance between accuracy and efficiency, and further benefits LLM downstream tasks by shortening contexts while retaining essential reasoning chains.

</details>


### [147] [From FusHa to Folk: Exploring Cross-Lingual Transfer in Arabic Language Models](https://arxiv.org/abs/2602.09826)
*Abdulmuizz Khalak,Abderrahmane Issam,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文研究了阿拉伯语预训练语言模型在不同方言间的跨语言迁移能力，发现迁移效果因方言与现代标准阿拉伯语（MSA）的相似性及地理邻近性而异，并存在多方言联合训练导致的负向干扰现象。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语模型主要基于现代标准阿拉伯语（MSA）预训练，但实际使用中大量涉及地域性方言；方言与MSA差异显著，导致模型迁移能力受限，亟需系统评估其跨方言泛化能力。

Method: 通过在3个自然语言处理任务上的探针分析（probing）和表征相似性度量，评估阿拉伯语模型在MSA与各方言间的跨语言迁移表现，并分析地理距离与迁移效果的关系。

Result: 迁移效果在不同方言间不均衡，部分可由地理邻近性解释；多方言联合训练的模型出现负向干扰，表明方言间并非完全相似，挑战了现有跨语言迁移假设。

Conclusion: 阿拉伯语方言与MSA的结构性差异及方言间的异质性，限制了当前语言模型的跨方言迁移能力；未来模型设计需更精细地建模方言多样性，避免简单统一处理。

Abstract: Arabic Language Models (LMs) are pretrained predominately on Modern Standard Arabic (MSA) and are expected to transfer to its dialects. While MSA as the standard written variety is commonly used in formal settings, people speak and write online in various dialects that are spread across the Arab region. This poses limitations for Arabic LMs, since its dialects vary in their similarity to MSA. In this work we study cross-lingual transfer of Arabic models using probing on 3 Natural Language Processing (NLP) Tasks, and representational similarity. Our results indicate that transfer is possible but disproportionate across dialects, which we find to be partially explained by their geographic proximity. Furthermore, we find evidence for negative interference in models trained to support all Arabic dialects. This questions their degree of similarity, and raises concerns for cross-lingual transfer in Arabic models.

</details>


### [148] [LLM Reasoning Predicts When Models Are Right: Evidence from Coding Classroom Discourse](https://arxiv.org/abs/2602.09832)
*Bakhtawar Ahtisham,Kirk Vanacore,Zhuqian Zhou,Jinsook Lee,Rene F. Kizilcec*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLM）自身生成推理文本的错误检测方法，用于提升教育对话自动标注的可靠性；通过TF-IDF编码推理并训练分类器（如随机森林），F1达0.83，并结合LIWC分析发现因果性语言预示正确性，而犹豫性与元认知语言预示错误。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在教育对话大规模自动标注中缺乏可靠的错误检测机制，亟需一种可扩展的质量控制方法。

Method: 对30,300条教师话语，由多个SOTA LLM标注 instructional move 并生成推理；以人工真值为基准，将错误检测建模为二分类任务；使用TF-IDF编码推理文本，训练五种监督分类器；进一步采用LIWC框架分析四类语言特征（因果、区分、犹豫、洞察）与预测正确性的关系。

Result: Random Forest分类器F1=0.83（召回率0.854）；构造特异性检测器可提升难构念性能；正确推理更倾向使用因果连接词（如because, therefore），错误推理则更多使用犹豫性（might, could）和元认知动词（think, realize）；句法复杂度和长度与正确性无关。

Conclusion: LLM生成的推理文本蕴含足够信号用于自身错误检测，该方法具备实用性与可扩展性，为教育对话自动化分析提供了可靠质量保障新路径。

Abstract: Large Language Models (LLMs) are increasingly deployed to automatically label and analyze educational dialogue at scale, yet current pipelines lack reliable ways to detect when models are wrong. We investigate whether reasoning generated by LLMs can be used to predict the correctness of a model's own predictions. We analyze 30,300 teacher utterances from classroom dialogue, each labeled by multiple state-of-the-art LLMs with an instructional move construct and an accompanying reasoning. Using human-verified ground-truth labels, we frame the task as predicting whether a model's assigned label for a given utterance is correct. We encode LLM reasoning using Term Frequency-Inverse Document Frequency (TF-IDF) and evaluate five supervised classifiers. A Random Forest classifier achieves an F1 score of 0.83 (Recall = 0.854), successfully identifying most incorrect predictions and outperforming baselines. Training specialist detectors for specific instructional move constructs further improves performance on difficult constructs, indicating that error detection benefits from construct-specific linguistic cues. Using the Linguistic Inquiry and Word Count (LIWC) framework, we examine four linguistic markers of correctness: Causation, Differentiation, Tentativeness, and Insight. Correct predictions exhibit grounded causal language (e.g., because, therefore), while incorrect reasoning is substantially more likely to rely on epistemic hedging (e.g., might, could) and performative metacognition (e.g., think, realize). Syntactic complexity does not distinguish correct from incorrect reasoning, and longer reasoning is not more reliable. These findings demonstrate that reasoning-based error detection offers a practical and scalable approach to quality control in automated educational dialogue analysis.

</details>


### [149] [How Do People Quantify Naturally: Evidence from Mandarin Picture Description](https://arxiv.org/abs/2602.09838)
*Yayun Zhang,Guanyi Chen,Fahime Same,Saad Mahamood,Tingting He*

Main category: cs.CL

TL;DR: 本研究通过图片描述任务，探究了汉语母语者在自然语言产出中量化表达的选择、精确度及策略，发现物体数量、生命性及产出模态显著影响量化行为。


<details>
  <summary>Details</summary>
Motivation: 量化是日常语言使用的基本组成部分，但人们对说话者在自然产出中如何决定是否及如何量化知之甚少。

Method: 采用基于图片的诱发描述任务，让汉语母语者自由描述含多个物体的场景（无计数或量化指令），跨口语与书面语模态考察量化选择、精确度和策略。

Result: 物体数量增加会降低量化倾向与精确度；有生性指称物及产出模态则选择性地调节量化策略；口语与书面语间存在系统性差异。

Conclusion: 量化行为受语境因素（如 numerosity、animacy、modality）系统影响，该研究为自然语言产出中数量表达提供了新实证依据与数据资源。

Abstract: Quantification is a fundamental component of everyday language use, yet little is known about how speakers decide whether and how to quantify in naturalistic production. We investigate quantification in Mandarin Chinese using a picture-based elicited description task in which speakers freely described scenes containing multiple objects, without explicit instructions to count or quantify. Across both spoken and written modalities, we examine three aspects of quantification: whether speakers choose to quantify at all, how precise their quantification is, and which quantificational strategies they adopt. Results show that object numerosity, animacy, and production modality systematically shape quantificational behaviour. In particular, increasing numerosity reduces both the likelihood and the precision of quantification, while animate referents and modality selectively modulate strategy choice. This study demonstrates how quantification can be examined under unconstrained production conditions and provides a naturalistic dataset for further analyses of quantity expression in language production.

</details>


### [150] [SinFoS: A Parallel Dataset for Translating Sinhala Figures of Speech](https://arxiv.org/abs/2602.09866)
*Johan Sofalas,Dilushri Pavithra,Nevidu Jayatilleke,Ruvan Weerasinghe*

Main category: cs.CL

TL;DR: 本文构建了一个包含2344个僧伽罗语修辞表达的语料库，并进行了文化来源分类和跨语言对等识别；开发了92%准确率的二分类器，并揭示了现有大语言模型在处理文化相关习语时的显著不足。


<details>
  <summary>Details</summary>
Motivation: 解决神经机器翻译（NMT）在低资源语言（如僧伽罗语）中处理文化相关修辞表达（FoS）效果差的问题，因缺乏高质量标注数据。

Method: 构建含文化与跨语言标注的僧伽罗语修辞表达语料库（2344条）；开展文化起源分类与跨语言对等识别任务；训练二分类器区分两类FoS；评估主流大语言模型（LLMs）在该数据集上的表现。

Result: 二分类器准确率达约92%；现有LLMs在准确传达习语含义方面表现显著不足；语料库已公开，为低资源NLP与文化感知机器翻译提供新基准。

Conclusion: 该工作填补了低资源语言修辞表达研究的数据空白，强调了文化意识建模对机器翻译的重要性，并为后续研究提供了可复现、可扩展的评估资源。

Abstract: Figures of Speech (FoS) consist of multi-word phrases that are deeply intertwined with culture. While Neural Machine Translation (NMT) performs relatively well with the figurative expressions of high-resource languages, it often faces challenges when dealing with low-resource languages like Sinhala due to limited available data. To address this limitation, we introduce a corpus of 2,344 Sinhala figures of speech with cultural and cross-lingual annotations. We examine this dataset to classify the cultural origins of the figures of speech and to identify their cross-lingual equivalents. Additionally, we have developed a binary classifier to differentiate between two types of FOS in the dataset, achieving an accuracy rate of approximately 92%. We also evaluate the performance of existing LLMs on this dataset. Our findings reveal significant shortcomings in the current capabilities of LLMs, as these models often struggle to accurately convey idiomatic meanings. By making this dataset publicly available, we offer a crucial benchmark for future research in low-resource NLP and culturally aware machine translation.

</details>


### [151] [Steer2Edit: From Activation Steering to Component-Level Editing](https://arxiv.org/abs/2602.09870)
*Chung-En Sun,Ge Yan,Zimo Wang,Tsui-Wei Weng*

Main category: cs.CL

TL;DR: 本文提出Steer2Edit，一种无需训练的框架，将推理时的转向向量转化为组件级秩-1权重编辑的诊断信号，通过选择性重分配行为影响（而非全局干预），在保持标准前向传播和并行推理兼容性的同时，显著改善属性-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有转向方法多采用固定、全局的推理时激活干预，忽视了模型行为常由少量异质组件控制，导致强控制下属性与效用间权衡不佳。

Method: Steer2Edit将转向向量从控制信号转为诊断信号，实现注意力头与MLP神经元层面的秩-1权重编辑，不修改前向过程，支持并行推理。

Result: 在安全对齐、幻觉缓解与推理效率任务上，Steer2Edit在保持下游性能前提下，安全提升达17.2%，真实性提高9.8%，平均推理长度减少12.2%。

Conclusion: Steer2Edit在表示转向与权重编辑之间建立了原理性桥梁，将转向信号转化为可解释、免训练的参数更新。

Abstract: Steering methods influence Large Language Model behavior by identifying semantic directions in hidden representations, but are typically realized through inference-time activation interventions that apply a fixed, global modification to the model's internal states. While effective, such interventions often induce unfavorable attribute-utility trade-offs under strong control, as they ignore the fact that many behaviors are governed by a small and heterogeneous subset of model components. We propose Steer2Edit, a theoretically grounded, training-free framework that transforms steering vectors from inference-time control signals into diagnostic signals for component-level rank-1 weight editing. Instead of uniformly injecting a steering direction during generation, Steer2Edit selectively redistributes behavioral influence across individual attention heads and MLP neurons, yielding interpretable edits that preserve the standard forward pass and remain compatible with optimized parallel inference. Across safety alignment, hallucination mitigation, and reasoning efficiency, Steer2Edit consistently achieves more favorable attribute-utility trade-offs: at matched downstream performance, it improves safety by up to 17.2%, increases truthfulness by 9.8%, and reduces reasoning length by 12.2% on average. Overall, Steer2Edit provides a principled bridge between representation steering and weight editing by translating steering signals into interpretable, training-free parameter updates.

</details>


### [152] [The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies](https://arxiv.org/abs/2602.09877)
*Chenxu Wang,Chaozhuo Li,Songyang Liu,Zejian Chen,Jinyu Hou,Ji Qi,Rui Li,Litian Zhang,Qiwei Ye,Zheng Liu,Xu Chen,Xi Zhang,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文指出基于大语言模型的多智能体系统在实现持续自我进化、完全隔离和安全不变性三者共存时存在根本性矛盾（即'自我进化三难困境'），并从信息论角度证明隔离式自我进化会导致安全对齐不可逆退化；通过实证研究验证该理论，并提出若干缓解方向。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在实现持续自我进化过程中如何同时保障安全对齐的根本挑战，揭示现有‘封闭式’自演化范式的内在风险。

Method: 构建信息论框架，将安全性形式化为与人类价值分布的散度；理论推导隔离式自我进化导致统计盲点与安全退化的必然性；通过开放社区（Moltbook）和两个封闭自演化系统开展实证与定性分析。

Result: 证明了自我进化、完全隔离与安全不变性三者不可兼得；发现所有测试系统均出现安全对齐的渐进性退化；识别出统计盲点是退化的核心机制。

Conclusion: 多智能体AI社会的自我演化存在本质安全极限，必须引入外部监督或设计新型安全保持机制，而非仅依赖事后修补。

Abstract: The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution. Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment--a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution, complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework, we formalize safety as the divergence degree from anthropic value distributions. We theoretically demonstrate that isolated self-evolution induces statistical blind spots, leading to the irreversible degradation of the system's safety alignment. Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms.

</details>


### [153] [LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations](https://arxiv.org/abs/2602.09924)
*William Lugoloobi,Thomas Foster,William Bankes,Chris Russell*

Main category: cs.CL

TL;DR: 本文研究了如何利用大语言模型（LLM）在生成前的内部表征来预测其在数学和编程任务上的成功概率，从而实现更高效的推理调度；提出线性探针方法，发现模型自身对难度的感知与人类不同且随推理增强而加剧；通过跨模型查询路由，在MATH数据集上实现性能超越最优单模型的同时降低最高70%的推理成本。


<details>
  <summary>Details</summary>
Motivation: 运行具备扩展推理能力的LLM成本高昂，但难以判断哪些输入真正需要额外计算资源；亟需一种基于模型自身信号的、低成本的推理决策机制。

Method: 在生成前的隐藏层激活上训练线性探针，预测模型在数学与编程任务上的成功概率；使用E2H-AMC数据集对比模型与人类对难度的感知差异；构建基于探针输出的跨模型路由策略。

Result: 线性探针显著优于基于问题长度、TF-IDF等表面特征的基线；发现模型内部编码的‘难度’与其人类感知显著不同，且该差异随扩展推理增强；路由策略在MATH上实现SOTA性能并降低最多70%推理成本。

Conclusion: LLM生成前的内部表征蕴含可被简单线性模型提取的成功预测信号，该信号虽偏离人类直觉，却能支撑高效、实用的推理调度策略，为低成本智能推理提供新路径。

Abstract: Running LLMs with extended reasoning on every problem is expensive, but determining which inputs actually require additional compute remains challenging. We investigate whether their own likelihood of success is recoverable from their internal representations before generation, and if this signal can guide more efficient inference. We train linear probes on pre-generation activations to predict policy-specific success on math and coding tasks, substantially outperforming surface features such as question length and TF-IDF. Using E2H-AMC, which provides both human and model performance on identical problems, we show that models encode a model-specific notion of difficulty that is distinct from human difficulty, and that this distinction increases with extended reasoning. Leveraging these probes, we demonstrate that routing queries across a pool of models can exceed the best-performing model whilst reducing inference cost by up to 70\% on MATH, showing that internal representations enable practical efficiency gains even when they diverge from human intuitions about difficulty. Our code is available at: https://github.com/KabakaWilliam/llms_know_difficulty

</details>


### [154] [ATTNPO: Attention-Guided Process Supervision for Efficient Reasoning](https://arxiv.org/abs/2602.09953)
*Shuaiyi Nie,Siyu Ding,Wenyuan Zhang,Linhao Yu,Tianmeng Yang,Yao Chen,Tingwen Liu,Weichong Yin,Yu Sun,Hua Wu*

Main category: cs.CL

TL;DR: 本文提出ATTNPO，一种利用模型内在注意力信号进行步骤级信用分配的低开销过程监督强化学习框架，有效缓解大推理模型的过度思考问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效区分推理步骤中的冗余与必要性，导致长度惩罚效果差或资源消耗大、信用分配不准。

Method: 提出ATTNPO框架，识别具有选择性聚焦能力的特殊注意力头，利用其注意力得分设计两种子策略：抑制冗余步骤、降低对关键步骤的惩罚。

Result: 在9个基准上显著缩短推理长度并提升性能。

Conclusion: ATTNPO通过细粒度注意力驱动的信用分配，在低开销下实现了更高效、更准确的推理过程优化。

Abstract: Large reasoning models trained with reinforcement learning and verifiable rewards (RLVR) achieve strong performance on complex reasoning tasks, yet often overthink, generating redundant reasoning without performance gains. Existing trajectory-level length penalties often fail to effectively shorten reasoning length and degrade accuracy, as they uniformly treat all reasoning steps and lack fine-grained signals to distinguish redundancy from necessity. Meanwhile, process-supervised methods are typically resource-intensive and suffer from inaccurate credit assignment. To address these issues, we propose ATTNPO, a low-overhead process-supervised RL framework that leverages the model's intrinsic attention signals for step-level credit assignment. We first identify a set of special attention heads that naturally focus on essential steps while suppressing redundant ones. By leveraging the attention scores of these heads, We then employ two sub-strategies to mitigate overthinking by discouraging redundant steps while preserving accuracy by reducing penalties on essential steps. Experimental results show that ATTNPO substantially reduces reasoning length while significantly improving performance across 9 benchmarks.

</details>


### [155] [ViMultiChoice: Toward a Method That Gives Explanation for Multiple-Choice Reading Comprehension in Vietnamese](https://arxiv.org/abs/2602.09961)
*Trung Tien Cao,Lam Minh Thai,Nghia Hieu Nguyen,Duc-Vu Nguyen,Ngan Luu-Thuy Nguyen*

Main category: cs.CL

TL;DR: 本文提出了一种面向越南语的多选阅读理解与解释生成联合建模方法ViMultiChoice，并构建了首个支持解释生成的越南语MCRC数据集，实验表明其在ViMMRC 2.0和新数据集上均达到SOTA性能，且联合训练显著提升选择准确率。


<details>
  <summary>Details</summary>
Motivation: 现有越南语多选阅读理解（MCRC）模型缺乏解释能力，且缺少支持解释生成的高质量越南语数据集。

Method: 提出ViMultiChoice方法，联合建模越南语阅读理解中的选项预测与解释生成任务；同时构建了一个新的越南语MCRC解释生成数据集。

Result: ViMultiChoice在ViMMRC 2.0和新数据集上均取得SOTA性能；联合训练使多选准确率显著提升。

Conclusion: 联合建模答案选择与解释生成不仅可行，而且能相互促进，提升越南语MCRC整体性能，为低资源语言可解释NLP研究提供了新范式。

Abstract: Multiple-choice Reading Comprehension (MCRC) models aim to select the correct answer from a set of candidate options for a given question. However, they typically lack the ability to explain the reasoning behind their choices. In this paper, we introduce a novel Vietnamese dataset designed to train and evaluate MCRC models with explanation generation capabilities. Furthermore, we propose ViMultiChoice, a new method specifically designed for modeling Vietnamese reading comprehension that jointly predicts the correct answer and generates a corresponding explanation. Experimental results demonstrate that ViMultiChoice outperforms existing MCRC baselines, achieving state-of-the-art (SotA) performance on both the ViMMRC 2.0 benchmark and the newly introduced dataset. Additionally, we show that jointly training option decision and explanation generation leads to significant improvements in multiple-choice accuracy.

</details>


### [156] [A Unified Assessment of the Poverty of the Stimulus Argument for Neural Language Models](https://arxiv.org/abs/2602.09992)
*Xiulin Yang,Arianna Bisazza,Nathan Schneider,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 本文通过构建POS HBench基准测试套件，评估神经语言模型在缺乏显式正向证据的情况下对英语句法现象（如疑问句形成、移动岛屿限制等）的泛化能力，发现Transformer模型虽能实现一定程度的泛化，但数据效率和泛化强度仍远低于儿童；引入三种认知启发的归纳偏置后，句法能力提升但未改善POS HBench表现，从而挑战了‘先天语法是唯一通向泛化路径’的观点。


<details>
  <summary>Details</summary>
Motivation: 检验贫困刺激假说（PoSH）——即儿童仅凭有限语言输入能否习得母语级句法，是否必须依赖先天语言约束；利用无语言特异性设计的神经语言模型作为计算验证工具。

Method: 构建POS HBench训练与评测套件（聚焦疑问句形成、移动岛屿等PoSH核心现象）；在10–50M词的发展适宜文本上训练Transformer模型；引入三种认知启发的归纳偏置进行增强实验。

Result: Transformer模型在无直接正向证据下展现出对所有目标现象的泛化迹象，但其数据效率和泛化强度均弱于儿童；加入认知偏置提升了整体句法能力，却未提升POS HBench上的具体表现。

Conclusion: 先天语法并非实现句法泛化的唯一可能路径；要达到类人的数据效率，需引入本文未测试的其他归纳偏置。

Abstract: How can children acquire native-level syntax from limited input? According to the Poverty of the Stimulus Hypothesis (PoSH), the linguistic input children receive is insufficient to explain certain generalizations that are robustly learned; innate linguistic constraints, many have argued, are thus necessary to explain language learning. Neural language models, which lack such language-specific constraints in their design, offer a computational test of this longstanding (but controversial) claim. We introduce \poshbench, a training-and-evaluation suite targeting question formation, islands to movement, and other English phenomena at the center of the PoSH arguments. Training Transformer models on 10--50M words of developmentally plausible text, we find indications of generalization on all phenomena even without direct positive evidence -- yet neural models remain less data-efficient and their generalizations are weaker than those of children. We further enhance our models with three recently proposed cognitively motivated inductive biases. We find these biases improve general syntactic competence but not \poshbench performance. Our findings challenge the claim that innate syntax is the only possible route to generalization, while suggesting that human-like data efficiency requires inductive biases beyond those tested here.

</details>


### [157] [ViSpeechFormer: A Phonemic Approach for Vietnamese Automatic Speech Recognition](https://arxiv.org/abs/2602.10003)
*Khoa Anh Nguyen,Long Minh Hoang,Nghia Hieu Nguyen,Luan Thanh Nguyen,Ngan Luu-Thuy Nguyen*

Main category: cs.CL

TL;DR: 本文提出了一种基于音素的越南语自动语音识别（ASR）框架ViSpeechFormer，利用越南语高度音形一致的正字法特性，首次显式建模音素表示，在公开数据集上展现出更强的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 越南语具有高度音形一致的正字法（每个字形最多对应一个音素，反之亦然），但此前缺乏显式建模音素表示的越南语ASR框架。

Method: 提出ViSpeechFormer，一种基于音素的越南语ASR框架，利用其音形透明性显式建模音素表示。

Result: 在两个公开越南语ASR数据集上实验表明，ViSpeechFormer性能优异，对未登录词泛化能力更强，且受训练偏差影响更小。

Conclusion: 基于音素的方法适用于越南语等具有音形一致正字法的语言，为类似语言的ASR提供了新范式。

Abstract: Vietnamese has a phonetic orthography, where each grapheme corresponds to at most one phoneme and vice versa. Exploiting this high grapheme-phoneme transparency, we propose ViSpeechFormer (\textbf{Vi}etnamese \textbf{Speech} Trans\textbf{Former}), a phoneme-based approach for Vietnamese Automatic Speech Recognition (ASR). To the best of our knowledge, this is the first Vietnamese ASR framework that explicitly models phonemic representations. Experiments on two publicly available Vietnamese ASR datasets show that ViSpeechFormer achieves strong performance, generalizes better to out-of-vocabulary words, and is less affected by training bias. This phoneme-based paradigm is also promising for other languages with phonetic orthographies. The code will be released upon acceptance of this paper.

</details>


### [158] [SCORE: Specificity, Context Utilization, Robustness, and Relevance for Reference-Free LLM Evaluation](https://arxiv.org/abs/2602.10017)
*Homaira Huda Shomee,Rochana Chaturvedi,Yangxinyu Xie,Tanwi Mallick*

Main category: cs.CL

TL;DR: 本文提出了一种无需参考答案的多维评估框架，用于评估大语言模型在自然灾害响应等高风险领域中的问答质量，涵盖特异性、鲁棒性、答案相关性和上下文利用四个维度，并构建了包含1412个专业问题对的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有RAG和开放问答评估方法主要依赖表面相似性、事实一致性或语义相关性，难以衡量是否提供了领域敏感决策所需的特定信息。

Method: 提出一种无参考的多维评估框架，从特异性、对改写与语义扰动的鲁棒性、答案相关性、上下文利用四个维度评估LLM输出；构建覆盖40种职业角色和7类自然灾害的1412个问答对数据集；开展人工评估以检验标注一致性与人机判断对齐。

Result: 实证表明单一指标无法充分反映高风险场景下答案质量，需采用结构化多指标评估框架；人工评估揭示了开放域、领域特定评估固有的主观性。

Conclusion: 在高风险应用场景中部署LLM时，必须采用多维、结构化、参考无关的评估框架，而非依赖单一指标。

Abstract: Large language models (LLMs) are increasingly used to support question answering and decision-making in high-stakes, domain-specific settings such as natural hazard response and infrastructure planning, where effective answers must convey fine-grained, decision-critical details. However, existing evaluation frameworks for retrieval-augmented generation (RAG) and open-ended question answering primarily rely on surface-level similarity, factual consistency, or semantic relevance, and often fail to assess whether responses provide the specific information required for domain-sensitive decisions. To address this gap, we propose a multi-dimensional, reference-free evaluation framework that assesses LLM outputs along four complementary dimensions: specificity, robustness to paraphrasing and semantic perturbations, answer relevance, and context utilization. We introduce a curated dataset of 1,412 domain-specific question-answer pairs spanning 40 professional roles and seven natural hazard types to support systematic evaluation. We further conduct human evaluation to assess inter-annotator agreement and alignment between model outputs and human judgments, which highlights the inherent subjectivity of open-ended, domain-specific evaluation. Our results show that no single metric sufficiently captures answer quality in isolation and demonstrate the need for structured, multi-metric evaluation frameworks when deploying LLMs in high-stakes applications.

</details>


### [159] [Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference](https://arxiv.org/abs/2602.10021)
*Wenxuan Xie,Yujia Wang,Xin Tan,Chaochao Lu,Xia Hu,Xuhong Wang*

Main category: cs.CL

TL;DR: 本文提出DRIFT，一种双模型架构，通过轻量级知识模型动态压缩文档为隐式事实标记，并将其投影到推理模型嵌入空间，从而解耦知识提取与推理过程，提升长上下文任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如RAG和参数化知识编辑）受限于有限上下文窗口、检索噪声或灾难性遗忘，难以有效将动态知识集成到大语言模型中。

Method: 提出DRIFT双模型架构：轻量级知识模型根据查询动态压缩文档块为隐式事实标记，并将这些稠密表示投影至推理模型嵌入空间，替代原始冗余文本。

Result: 在长上下文任务上显著优于同规模强基线模型，提升了推理准确性和有效上下文窗口。

Conclusion: DRIFT提供了一种可扩展且高效的方法，用于增强大语言模型的知识集成能力与推理能力。

Abstract: The integration of extensive, dynamic knowledge into Large Language Models (LLMs) remains a significant challenge due to the inherent entanglement of factual data and reasoning patterns. Existing solutions, ranging from non-parametric Retrieval-Augmented Generation (RAG) to parametric knowledge editing, are often constrained in practice by finite context windows, retriever noise, or the risk of catastrophic forgetting. In this paper, we propose DRIFT, a novel dual-model architecture designed to explicitly decouple knowledge extraction from the reasoning process. Unlike static prompt compression, DRIFT employs a lightweight knowledge model to dynamically compress document chunks into implicit fact tokens conditioned on the query. These dense representations are projected into the reasoning model's embedding space, replacing raw, redundant text while maintaining inference accuracy. Extensive experiments show that DRIFT significantly improves performance on long-context tasks, outperforming strong baselines among comparably sized models. Our approach provides a scalable and efficient paradigm for extending the effective context window and reasoning capabilities of LLMs. Our code is available at https://github.com/Lancelot-Xie/DRIFT.

</details>


### [160] [MEVER: Multi-Modal and Explainable Claim Verification with Graph-based Evidence Retrieval](https://arxiv.org/abs/2602.10023)
*Delvin Ce Zhang,Suhan Cui,Zhelin Chu,Xianren Zhang,Dongwon Lee*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的多模态模型，用于联合完成证据检索、多模态声明验证和解释生成，并构建了面向AI领域的科学数据集AIChartClaim。


<details>
  <summary>Details</summary>
Motivation: 现有声明验证工作大多仅依赖文本证据或忽略可解释性，导致验证结果不准确且缺乏说服力。

Method: 构建两层多模态图进行证据检索（含图文互推理）；提出词级和证据级融合进行多模态声明验证；引入多模态Fusion-in-Decoder生成解释；并构建AI领域的科学数据集AIChartClaim。

Result: 实验表明所提模型在多模态声明验证与解释生成任务上具有优越性能。

Conclusion: 该模型有效实现了多模态证据检索、验证与可解释生成的统一，提升了声明验证的准确性与透明度，并推动了领域专用数据集建设。

Abstract: Verifying the truthfulness of claims usually requires joint multi-modal reasoning over both textual and visual evidence, such as analyzing both textual caption and chart image for claim verification. In addition, to make the reasoning process transparent, a textual explanation is necessary to justify the verification result. However, most claim verification works mainly focus on the reasoning over textual evidence only or ignore the explainability, resulting in inaccurate and unconvincing verification. To address this problem, we propose a novel model that jointly achieves evidence retrieval, multi-modal claim verification, and explanation generation. For evidence retrieval, we construct a two-layer multi-modal graph for claims and evidence, where we design image-to-text and text-to-image reasoning for multi-modal retrieval. For claim verification, we propose token- and evidence-level fusion to integrate claim and evidence embeddings for multi-modal verification. For explanation generation, we introduce multi-modal Fusion-in-Decoder for explainability. Finally, since almost all the datasets are in general domain, we create a scientific dataset, AIChartClaim, in AI domain to complement claim verification community. Experiments show the strength of our model.

</details>


### [161] [Anagent For Enhancing Scientific Table & Figure Analysis](https://arxiv.org/abs/2602.10081)
*Xuehang Guo,Zhiyong Lu,Tom Hope,Qingyun Wang*

Main category: cs.CL

TL;DR: 本文提出了AnaBench基准和Anagent多智能体框架，以提升科学图表分析能力，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统难以准确解析复杂多模态科学知识，尤其在处理结构异构、上下文长的科学表格与图表时面临根本性挑战。

Method: 构建了包含63,178个样本、覆盖9个科学领域的AnaBench基准；提出由Planner、Expert、Solver和Critic四个专业化智能体组成的Anagent多智能体框架，并采用模块化监督微调与专用强化学习策略进行训练。

Result: 在170个子领域综合评估中，Anagent在免训练设置下最高提升13.43%，微调后最高提升42.12%；验证了任务导向推理与上下文感知问题解决对高质量分析的关键作用。

Conclusion: Anagent框架及其训练策略有效提升了科学图表分析能力，揭示了多智能体协同与领域适配推理是突破当前瓶颈的关键路径。

Abstract: In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) systems struggle to consistently demonstrate such capabilities. The complexity and variability of scientific tables and figures, combined with heterogeneous structures and long-context requirements, pose fundamental obstacles to scientific table \& figure analysis. To quantify these challenges, we introduce AnaBench, a large-scale benchmark featuring $63,178$ instances from nine scientific domains, systematically categorized along seven complexity dimensions. To tackle these challenges, we propose Anagent, a multi-agent framework for enhanced scientific table \& figure analysis through four specialized agents: Planner decomposes tasks into actionable subtasks, Expert retrieves task-specific information through targeted tool execution, Solver synthesizes information to generate coherent analysis, and Critic performs iterative refinement through five-dimensional quality assessment. We further develop modular training strategies that leverage supervised finetuning and specialized reinforcement learning to optimize individual capabilities while maintaining effective collaboration. Comprehensive evaluation across 170 subdomains demonstrates that Anagent achieves substantial improvements, up to $\uparrow 13.43\%$ in training-free settings and $\uparrow 42.12\%$ with finetuning, while revealing that task-oriented reasoning and context-aware problem-solving are essential for high-quality scientific table \& figure analysis. Our project page: https://xhguo7.github.io/Anagent/.

</details>


### [162] [Quantum-Audit: Evaluating the Reasoning Limits of LLMs on Quantum Computing](https://arxiv.org/abs/2602.10092)
*Mohamed Afane,Kayla Laufer,Wenqi Wei,Ying Mao,Junaid Farooq,Ying Wang,Juntao Chen*

Main category: cs.CL

TL;DR: Quantum-Audit 是一个包含2700道题目的新基准，用于系统评估大语言模型对量子计算概念的理解能力；研究发现当前顶级模型虽在整体准确率上超过人类专家（如Claude Opus达84%），但在专家出题、高阶主题（如安全）及识别错误前提等关键推理任务上表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估量子代码生成和电路设计能力，但缺乏对语言模型量子计算概念理解能力的系统性测量。

Method: 构建了包含2700道题的Quantum-Audit基准，涵盖专家撰写、LLM生成并经专家验证、以及含错误前提和开放性问题三类题目；评估26个主流模型，并对比人类专家与普通参与者的表现。

Result: 顶级模型（如Claude Opus 4.5）整体准确率达84%，超过人类专家平均值（74%）；但在专家出题上准确率下降12个百分点；安全类题目降至73%；识别错误前提的任务准确率低于66%。

Conclusion: 当前语言模型在量子计算概念理解上仍存在明显局限，尤其在深度推理、批判性检验和高阶主题方面亟需改进。

Abstract: Language models have become practical tools for quantum computing education and research, from summarizing technical papers to explaining theoretical concepts and answering questions about recent developments in the field. While existing benchmarks evaluate quantum code generation and circuit design, their understanding of quantum computing concepts has not been systematically measured. Quantum-Audit addresses this gap with 2,700 questions covering core quantum computing topics. We evaluate 26 models from leading organizations. Our benchmark comprises 1,000 expert-written questions, 1,000 questions extracted from research papers using LLMs and validated by experts, plus an additional 700 questions including 350 open-ended questions and 350 questions with false premises to test whether models can correct erroneous assumptions. Human participants scored between 23% and 86%, with experts averaging 74%. Top-performing models exceeded the expert average, with Claude Opus 4.5 reaching 84% accuracy, though top models showed an average 12-point accuracy drop on expert-written questions compared to LLM-generated ones. Performance declined further on advanced topics, dropping to 73% on security questions. Additionally, models frequently accepted and reinforced false premises embedded in questions instead of identifying them, with accuracy below 66% on these critical reasoning tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [163] [Enhanced Graph Transformer with Serialized Graph Tokens](https://arxiv.org/abs/2602.09065)
*Ruixiang Wang,Yuyang Hong,Shiming Xiang,Chunhong Pan*

Main category: cs.LG

TL;DR: 本文提出了一种新的序列化标记范式（serialized token paradigm），以克服图神经网络中图级表示的信息瓶颈问题，通过图序列化和堆叠自注意力层来建模多个图标记间的复杂交互，从而获得更具表现力的图表示，并在多个图级基准上达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的图学习方法在生成图级表示时存在信息瓶颈，单标记范式无法充分利用自注意力对序列建模的能力，退化为节点信号的加权和。

Method: 提出序列化标记范式：首先设计图序列化方法将节点信号聚合为带自动位置编码的序列化图标记；然后用堆叠的自注意力层对这些标记序列进行编码，捕获其内部依赖关系。

Result: 在多个图级基准测试上取得SOTA性能；消融实验验证了所提模块的有效性。

Conclusion: 序列化标记范式能更有效地封装全局图信号，通过建模多个图标记间的复杂交互，显著提升图级表示能力。

Abstract: Transformers have demonstrated success in graph learning, particularly for node-level tasks. However, existing methods encounter an information bottleneck when generating graph-level representations. The prevalent single token paradigm fails to fully leverage the inherent strength of self-attention in encoding token sequences, and degenerates into a weighted sum of node signals. To address this issue, we design a novel serialized token paradigm to encapsulate global signals more effectively. Specifically, a graph serialization method is proposed to aggregate node signals into serialized graph tokens, with positional encoding being automatically involved. Then, stacked self-attention layers are applied to encode this token sequence and capture its internal dependencies. Our method can yield more expressive graph representations by modeling complex interactions among multiple graph tokens. Experimental results show that our method achieves state-of-the-art results on several graph-level benchmarks. Ablation studies verify the effectiveness of the proposed modules.

</details>


### [164] [Spectral Disentanglement and Enhancement: A Dual-domain Contrastive Framework for Representation Learning](https://arxiv.org/abs/2602.09066)
*Jinjin Guo,Yexin Li,Zhichao Huang,Jun Fang,Zhiyuan Liu,Chao Liu,Pengzhang Liu,Qixia Jiang*

Main category: cs.LG

TL;DR: 本文提出Spectral Disentanglement and Enhancement (SDE)框架，通过奇异值分解自适应分离特征维度为强信号、弱信号和噪声，并设计课程式谱增强策略与双域对比损失，在特征空间和谱空间联合优化，提升多模态表征的鲁棒性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有大规模多模态对比学习方法对特征维度做均匀处理，忽视其内在谱结构，导致高维嵌入坍缩成窄锥、语义集中在少数维度，其余维度充斥噪声和虚假相关，损害泛化能力。

Method: 提出SDE框架：1）利用奇异值分解（SVD）自适应划分特征维度为强信号、弱信号和噪声；2）设计课程式谱增强策略选择性放大信息成分；3）引入双域对比损失，在特征空间和谱空间联合优化对齐。

Result: 在多个大规模多模态基准上实验表明，SDE持续提升表征鲁棒性与泛化能力，性能超越当前最优方法，且可无缝集成到现有对比学习流程中。

Conclusion: SDE有效弥合嵌入空间几何结构与谱特性之间的鸿沟，通过谱解耦与增强及双域对比学习，显著改善多模态表示学习效果。

Abstract: Large-scale multimodal contrastive learning has recently achieved impressive success in learning rich and transferable representations, yet it remains fundamentally limited by the uniform treatment of feature dimensions and the neglect of the intrinsic spectral structure of the learned features. Empirical evidence indicates that high-dimensional embeddings tend to collapse into narrow cones, concentrating task-relevant semantics in a small subspace, while the majority of dimensions remain occupied by noise and spurious correlations. Such spectral imbalance and entanglement undermine model generalization. We propose Spectral Disentanglement and Enhancement (SDE), a novel framework that bridges the gap between the geometry of the embedded spaces and their spectral properties. Our approach leverages singular value decomposition to adaptively partition feature dimensions into strong signals that capture task-critical semantics, weak signals that reflect ancillary correlations, and noise representing irrelevant perturbations. A curriculum-based spectral enhancement strategy is then applied, selectively amplifying informative components with theoretical guarantees on training stability. Building upon the enhanced features, we further introduce a dual-domain contrastive loss that jointly optimizes alignment in both the feature and spectral spaces, effectively integrating spectral regularization into the training process and encouraging richer, more robust representations. Extensive experiments on large-scale multimodal benchmarks demonstrate that SDE consistently improves representation robustness and generalization, outperforming state-of-the-art methods. SDE integrates seamlessly with existing contrastive pipelines, offering an effective solution for multimodal representation learning.

</details>


### [165] [Learning to Remember, Learn, and Forget in Attention-Based Models](https://arxiv.org/abs/2602.09075)
*Djohan Bonnet,Jamie Lohoff,Jan Finkbeiner,Elidona Skhikerujah,Emre Neftci*

Main category: cs.LG

TL;DR: 本文提出Palimpsa模型，将上下文学习视为持续学习问题，通过贝叶斯元可塑性机制提升注意力模型的记忆容量与抗干扰能力，并在多项基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有门控线性注意力模型（如Mamba2）在长序列中存在固定记忆容量和易受干扰的问题，难以有效支持上下文学习（ICL）。

Method: 提出Palimpsa模型，引入贝叶斯元可塑性机制：每个注意力状态的可塑性由一个基于先验分布的重要性状态调控，从而动态平衡稳定性与可塑性；并证明多种门控线性注意力模型是Palimpsa在不同架构选择与后验近似下的特例。

Result: Palimpsa在Multi-Query Associative Recall（MQAR）和常识推理任务上持续优于基线模型；理论表明Mamba2是其遗忘主导的特例，且该框架可将任意非元可塑模型转化为元可塑模型，显著扩展记忆容量。

Conclusion: Palimpsa为理解与增强Transformer类模型的上下文学习能力提供了新视角，通过元可塑性建模解决了稳定性-可塑性困境，提升了长序列建模能力。

Abstract: In-Context Learning (ICL) in transformers acts as an online associative memory and is believed to underpin their high performance on complex sequence processing tasks. However, in gated linear attention models, this memory has a fixed capacity and is prone to interference, especially for long sequences. We propose Palimpsa, a self-attention model that views ICL as a continual learning problem that must address a stability-plasticity dilemma. Palimpsa uses Bayesian metaplasticity, where the plasticity of each attention state is tied to an importance state grounded by a prior distribution that captures accumulated knowledge. We demonstrate that various gated linear attention models emerge as specific architecture choices and posterior approximations, and that Mamba2 is a special case of Palimpsa where forgetting dominates. This theoretical link enables the transformation of any non-metaplastic model into a metaplastic one, significantly expanding its memory capacity. Our experiments show that Palimpsa consistently outperforms baselines on the Multi-Query Associative Recall (MQAR) benchmark and on Commonsense Reasoning tasks.

</details>


### [166] [Patient foundation model for risk stratification in low-risk overweight patients](https://arxiv.org/abs/2602.09079)
*Zachary N. Flamholz,Dillon Tracy,Ripple Khera,Jordan Wolinsky,Nicholas Lee,Nathaniel Tann,Xiao Yin Zhu,Harry Phillips,Jeffrey Sherman*

Main category: cs.LG

TL;DR: 本文提出了PatientTPP模型，一种基于神经时间点过程的患者表征学习方法，利用超50万真实临床轨迹数据，整合静态、时序及临床知识，实现对肥胖相关健康风险与医疗成本的精准分层预测。


<details>
  <summary>Details</summary>
Motivation: 准确评估超重或肥胖患者的风险对于指导预防性护理和合理分配高成本疗法（如GLP-1受体激动剂）至关重要。

Method: 提出PatientTPP——一种扩展的神经时间点过程（TPP）模型，支持静态特征、数值特征与临床知识驱动的事件编码，基于大规模真实世界临床序列（诊断、检验、用药）学习患者表征。

Result: PatientTPP在低风险个体中有效分类肥胖相关结局；在卫生经济学评估中，其对心血管相关未来医疗费用的分层能力显著优于BMI，能更高效识别高风险患者。

Conclusion: PatientTPP通过联合建模临床事件类型与时序，提供可解释、通用的患者风险建模基础，可直接应用于肥胖相关临床决策与成本优化。

Abstract: Accurate risk stratification in patients with overweight or obesity is critical for guiding preventive care and allocating high-cost therapies such as GLP-1 receptor agonists. We present PatientTPP, a neural temporal point process (TPP) model trained on over 500,000 real-world clinical trajectories to learn patient representations from sequences of diagnoses, labs, and medications. We extend existing TPP modeling approaches to include static and numeric features and incorporate clinical knowledge for event encoding. PatientTPP representations support downstream prediction tasks, including classification of obesity-associated outcomes in low-risk individuals, even for events not explicitly modeled during training. In health economic evaluation, PatientTPP outperformed body mass index in stratifying patients by future cardiovascular-related healthcare costs, identifying higher-risk patients more efficiently. By modeling both the type and timing of clinical events, PatientTPP offers an interpretable, general-purpose foundation for patient risk modeling with direct applications to obesity-related care and cost targeting.

</details>


### [167] [Looping Back to Move Forward: Recursive Transformers for Efficient and Flexible Large Multimodal Models](https://arxiv.org/abs/2602.09080)
*Ruihan Xu,Yuting Gao,Lan Wang,Jianing Li,Weihao Chen,Qingpei Guo,Ming Yang,Shiliang Zhang*

Main category: cs.LG

TL;DR: 本文提出RecursiveVLM，一种通过递归细化重用参数的大型多模态模型架构，在不增加模型规模的前提下提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）参数量庞大，但在训练和推理中常未被充分利用，亟需更高效的参数利用方式。

Method: 提出RecursiveVLM：包含Recursive Connector（融合中间层隐状态并做模态特异性投影）和Monotonic Recursion Loss（确保每步递归性能单调提升）。

Result: 实验显示相比标准Transformer提升+3%，相比基础递归基线提升+7%，验证了递归细化的有效性与部署适应性。

Conclusion: 递归细化是一种高效、可扩展且资源自适应的LMM优化路径，为参数高效利用提供了新范式。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in vision-language tasks, yet their vast parameter counts are often underutilized during both training and inference. In this work, we embrace the idea of looping back to move forward: reusing model parameters through recursive refinement to extract stronger multimodal representations without increasing model size. We propose RecursiveVLM, a recursive Transformer architecture tailored for LMMs. Two key innovations enable effective looping: (i) a Recursive Connector that aligns features across recursion steps by fusing intermediate-layer hidden states and applying modality-specific projections, respecting the distinct statistical structures of vision and language tokens; (ii) a Monotonic Recursion Loss that supervises every step and guarantees performance improves monotonically with recursion depth. This design transforms recursion into an on-demand refinement mechanism: delivering strong results with few loops on resource-constrained devices and progressively improving outputs when more computation resources are available. Experiments show consistent gains of +3% over standard Transformers and +7% over vanilla recursive baselines, demonstrating that strategic looping is a powerful path toward efficient, deployment-adaptive LMMs.

</details>


### [168] [DMamba: Decomposition-enhanced Mamba for Time Series Forecasting](https://arxiv.org/abs/2602.09081)
*Ruxuan Chen,Fang Sun*

Main category: cs.LG

TL;DR: 本文提出DMamba模型，通过季节-趋势分解并为不同成分设计不同复杂度的模块（变量方向Mamba编码器处理季节成分，MLP处理趋势成分），以更好建模非平稳时间序列，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Mamba的模型在处理具有非平稳模式的时间序列时表现不佳；而时间序列理论指出趋势和季节成分的变量间关系在统计特性上存在本质差异，需差异化建模。

Method: 提出DMamba模型：先进行季节-趋势分解，再分别用变量方向Mamba编码器（处理高维动态的季节成分）和简单MLP（处理低维趋势成分）进行建模，并融合输出。

Result: 在多个数据集上的实验表明，DMamba持续优于最新的Mamba架构及主流分解模型，达到新的SOTA性能。

Conclusion: 将模型架构复杂度与时间序列成分的内在统计特性对齐是提升非平稳时间序列预测性能的有效范式。

Abstract: State Space Models (SSMs), particularly Mamba, have shown potential in long-term time series forecasting. However, existing Mamba-based architectures often struggle with datasets characterized by non-stationary patterns. A key observation from time series theory is that the statistical nature of inter-variable relationships differs fundamentally between the trend and seasonal components of a decomposed series. Trend relationships are often driven by a few common stochastic factors or long-run equilibria, suggesting that they reside on a lower-dimensional manifold. In contrast, seasonal relationships involve dynamic, high-dimensional interactions like phase shifts and amplitude co-movements, requiring more expressive modeling. In this paper, we propose DMamba, a novel forecasting model that explicitly aligns architectural complexity with this component-specific characteristic. DMamba employs seasonal-trend decomposition and processes the components with specialized, differentially complex modules: a variable-direction Mamba encoder captures the rich, cross-variable dynamics within the seasonal component, while a simple Multi-Layer Perceptron (MLP) suffices to learn from the lower-dimensional inter-variable relationships in the trend component. Extensive experiments on diverse datasets demonstrate that DMamba sets a new state-of-the-art (SOTA), consistently outperforming both recent Mamba-based architectures and leading decomposition-based models.

</details>


### [169] [From Adam to Adam-Like Lagrangians: Second-Order Nonlocal Dynamics](https://arxiv.org/abs/2602.09101)
*Carlos Heredia*

Main category: cs.LG

TL;DR: 本文提出了Adam优化器的加速连续时间公式，将其建模为二阶积分微分动力系统，并通过α-细化极限与现有的一阶非局部Adam流建立联系；同时提供了基于李雅普诺夫的稳定性和收敛性分析，并引入了受Adam启发的非局部拉格朗日表述，最后通过Rosenbrock型数值实验验证了所提动力学与离散Adam的一致性。


<details>
  <summary>Details</summary>
Motivation: 为深入理解Adam优化器的动态行为并提升其理论基础，需构建其连续时间模型并进行稳定性与收敛性分析。

Method: 将Adam建模为二阶积分微分动力系统，通过α-细化极限关联一阶非局部Adam流，并采用Lyapunov方法分析稳定性与收敛性；同时构建Adam启发的非局部拉格朗日变分框架。

Result: 建立了加速连续时间Adam模型及其与一阶模型的理论联系，完成了Lyapunov稳定性与收敛性证明，并通过数值实验验证了模型与离散Adam行为的一致性。

Conclusion: 所提出的二阶非局部动力系统为Adam提供了更丰富的连续时间刻画，增强了对其加速机制和收敛性质的理论理解，并拓展了变分视角下的优化器建模方法。

Abstract: In this paper, we derive an accelerated continuous-time formulation of Adam by modeling it as a second-order integro-differential dynamical system. We relate this inertial nonlocal model to an existing first-order nonlocal Adam flow through an $α$-refinement limit, and we provide Lyapunov-based stability and convergence analyses. We also introduce an Adam-inspired nonlocal Lagrangian formulation, offering a variational viewpoint. Numerical simulations on Rosenbrock-type examples show agreement between the proposed dynamics and discrete Adam.

</details>


### [170] [Distributed Hybrid Parallelism for Large Language Models: Comparative Study and System Design Guide](https://arxiv.org/abs/2602.09109)
*Hossam Amer,Rezaul Karim,Ali Pourranjbar,Weiwei Zhang,Walid Ahmed,Boxing Chen*

Main category: cs.LG

TL;DR: 本文全面综述了大语言模型（LLM）分布式训练与推理中的集体通信操作与并行策略，通过数学建模深化理论理解，重点分析混合并行设计中的计算-通信重叠，并探讨基于成本模型的自动搜索方法；结合主流架构的案例研究提供实践指导，最后指出当前范式的挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有综述多为描述性，缺乏对分布式技术效益与权衡的系统性分析，以及如何据此指导最优分布式系统设计的原则性方法。

Method: 综合文献回顾、数学建模、混合并行策略分析、通信-计算重叠评估、基于成本模型的自动化搜索方法探讨，以及面向主流硬件架构的实证案例研究。

Result: 建立了涵盖集体操作、分布式并行策略及混合并行设计的系统性分析框架；揭示了不同架构下并行策略选择的经验规律；总结了自动化并行策略搜索的最新进展。

Conclusion: 分布式LLM训练与推理需兼顾理论严谨性与工程实用性；未来需突破通信瓶颈、提升自动化程度，并发展适配新型硬件与任务范式的下一代大规模模型训练范式。

Abstract: With the rapid growth of large language models (LLMs), a wide range of methods have been developed to distribute computation and memory across hardware devices for efficient training and inference. While existing surveys provide descriptive overviews of these techniques, systematic analysis of their benefits and trade offs and how such insights can inform principled methodology for designing optimal distributed systems remain limited. This paper offers a comprehensive review of collective operations and distributed parallel strategies, complemented by mathematical formulations to deepen theoretical understanding. We further examine hybrid parallelization designs, emphasizing communication computation overlap across different stages of model deployment, including both training and inference. Recent advances in automated search for optimal hybrid parallelization strategies using cost models are also discussed. Moreover, we present case studies with mainstream architecture categories to reveal empirical insights to guide researchers and practitioners in parallelism strategy selection. Finally, we highlight open challenges and limitations of current LLM training paradigms and outline promising directions for the next generation of large scale model development.

</details>


### [171] [Benchmarking the Energy Savings with Speculative Decoding Strategies](https://arxiv.org/abs/2602.09113)
*Rohit Dutta,Paramita Koley,Soham Poddar,Janardan Misra,Sanjay Podder,Naveen Balani,Saptarshi Ghosh,Niloy Ganguly*

Main category: cs.LG

TL;DR: This paper surveys the energy requirements of speculative decoding strategies for LLMs, analyzing how model size, decoding strategies, and dataset characteristics affect energy efficiency.


<details>
  <summary>Details</summary>
Motivation: Speculative decoding reduces latency and inference cost, but its energy consumption has been underexplored.

Method: Comprehensive survey and detailed analysis of energy usage across different speculative decoding strategies, model sizes/families, and dataset characteristics.

Result: Identifies key factors influencing energy optimization in speculative decoding.

Conclusion: Energy efficiency in speculative decoding depends significantly on model size, strategy choice, and dataset properties; findings guide more sustainable LLM inference.

Abstract: Speculative decoding has emerged as an effective method to reduce latency and inference cost of LLM inferences. However, there has been inadequate attention towards the energy requirements of these models. To address this gap, this paper presents a comprehensive survey of energy requirements of speculative decoding strategies, with detailed analysis on how various factors -- model size and family, speculative decoding strategies, and dataset characteristics -- influence the energy optimizations.

</details>


### [172] [Importance inversion transfer identifies shared principles for cross-domain learning](https://arxiv.org/abs/2602.09116)
*Daniele Caligiore*

Main category: cs.LG

TL;DR: 本文提出可解释的跨域迁移学习（X-CDTL）框架，结合网络科学与可解释AI，通过重要性反转迁移（IIT）机制识别跨生物、语言、分子和社会网络的结构不变量，在数据稀缺和强噪声下显著提升异常检测稳定性（相对提升56%），推动机器学习成为可信赖的科学发现工具。


<details>
  <summary>Details</summary>
Motivation: 现有迁移学习方法难以在数据极度稀缺或存在强随机噪声时，有效连接差异极大的科学领域；需寻找跨域共享的组织原理以实现知识迁移。

Method: 提出X-CDTL框架，融合网络科学与可解释AI，引入重要性反转迁移（IIT）机制，优先选择域不变的结构锚点而非特异性强但泛化性差的特征。

Result: 在异常检测任务中，模型决策稳定性在极端噪声下相对传统基线提升56%；验证了异质领域间存在共享的组织签名。

Conclusion: X-CDTL为跨学科知识传播提供了新范式，通过从黑箱隐表示转向显式结构规律，增强了机器学习在科学发现中的鲁棒性与可解释性。

Abstract: The capacity to transfer knowledge across scientific domains relies on shared organizational principles. However, existing transfer-learning methodologies often fail to bridge radically heterogeneous systems, particularly under severe data scarcity or stochastic noise. This study formalizes Explainable Cross-Domain Transfer Learning (X-CDTL), a framework unifying network science and explainable artificial intelligence to identify structural invariants that generalize across biological, linguistic, molecular, and social networks. By introducing the Importance Inversion Transfer (IIT) mechanism, the framework prioritizes domain-invariant structural anchors over idiosyncratic, highly discriminative features. In anomaly detection tasks, models guided by these principles achieve significant performance gains - exhibiting a 56\% relative improvement in decision stability under extreme noise - over traditional baselines. These results provide evidence for a shared organizational signature across heterogeneous domains, establishing a principled paradigm for cross-disciplinary knowledge propagation. By shifting from opaque latent representations to explicit structural laws, this work advances machine learning as a robust engine for scientific discovery.

</details>


### [173] [SpinCastML an Open Decision-Making Application for Inverse Design of Electrospinning Manufacturing: A Machine Learning, Optimal Sampling and Inverse Monte Carlo Approach](https://arxiv.org/abs/2602.09120)
*Elisa Roldan,Tasneem Sabir*

Main category: cs.LG

TL;DR: 本文提出了SpinCastML，一个开源的、分布感知的、化学信息驱动的机器学习与逆蒙特卡洛（IMC）软件，用于电纺纤维的逆向设计，可预测纤维直径全分布并生成符合化学约束的可行工艺参数组合。


<details>
  <summary>Details</summary>
Motivation: 现有电纺设计缺乏整合聚合物-溶剂化学约束、预测完整纤维直径分布及支持逆向设计的统一框架，仍依赖试错法。

Method: 基于68,480个纤维直径数据构建严格筛选的数据集；集成三种结构化采样方法、11种高性能机器学习模型（如Cubist）及化学感知约束；采用逆蒙特卡洛（IMC）实现分布预测与逆向设计。

Result: Cubist模型结合聚合物平衡Sobol D最优采样达到R² > 0.92；IMC对纤维分布预测R² > 0.90，成功率预测误差<1%；支持回溯分析与面向目标的正向逆设计。

Conclusion: SpinCastML将电纺从经验试错转变为可重复、数据驱动的设计范式，减少实验浪费、加速发现，并通过开源促进社区共建，为生物医学、过滤和能源等领域的可持续纳米纤维制造树立新标准。

Abstract: Electrospinning is a powerful technique for producing micro to nanoscale fibers with application specific architectures. Small variations in solution or operating conditions can shift the jet regime, generating non Gaussian fiber diameter distributions. Despite substantial progress, no existing framework enables inverse design toward desired fiber outcomes while integrating polymer solvent chemical constraints or predicting full distributions. SpinCastML is an open source, distribution aware, chemically informed machine learning and Inverse Monte Carlo (IMC) software for inverse electrospinning design. Built on a rigorously curated dataset of 68,480 fiber diameters from 1,778 datasets across 16 polymers, SpinCastML integrates three structured sampling methods, a suite of 11 high-performance learners, and chemistry aware constraints to predict not only mean diameter but the entire distribution. Cubist model with a polymer balanced Sobol D optimal sampling provides the highest global performance (R2 > 0.92). IMC accurately captures the fiber distributions, achieving R2 > 0.90 and <1% error between predicted and experimental success rates. The IMC engine supports both retrospective analysis and forward-looking inverse design, generating physically and chemically feasible polymer solvent parameter combinations with quantified success probabilities for user-defined targets. SpinCastML reframes electrospinning from trial and error to a reproducible, data driven design process. As an open source executable, it enables laboratories to analyze their own datasets and co create an expanding community software. SpinCastML reduces experimental waste, accelerates discovery, and democratizes access to advanced modeling, establishing distribution aware inverse design as a new standard for sustainable nanofiber manufacturing across biomedical, filtration, and energy applications.

</details>


### [174] [Epistemic Throughput: Fundamental Limits of Attention-Constrained Inference](https://arxiv.org/abs/2602.09127)
*Lei You*

Main category: cs.LG

TL;DR: 本文提出了注意力受限推理（ACI）框架，研究在廉价筛选和昂贵验证资源受限下，如何最大化后验不确定性降低（即认知吞吐量），发现其存在一个基线项和一个非线性信息杠杆项√(JKB)，并指出重尾分数分布对实现高杠杆至关重要。


<details>
  <summary>Details</summary>
Motivation: 生成式与工具型AI系统能低成本产出大量候选结果，但人工或高成本验证能力有限，导致下游决策者面临注意力瓶颈，需从海量公开记录中高效形成可靠后验。

Method: 形式化定义注意力受限推理（ACI）模型：包含处理K条记录的廉价筛选阶段和最多验证B条的昂贵验证阶段；在贝叶斯对数损失下，以单位窗口内后验不确定性减少（即'认知吞吐量'）为优化目标，推导其理论标度律。

Result: 得出'JaKoB'标度律：认知吞吐量 = 基线项（线性于B和先验概率） + 信息杠杆项（∝√(JKB)，J表征筛选质量）；该标度在弱筛选极限下是紧的；在稀疏验证（B≪K）时，仅当分数分布为重尾时才能获得显著杠杆，轻尾时杠杆仅为对数级。

Conclusion: 扩大廉价筛选规模可非线性放大稀缺验证资源的效果，但该放大效应高度依赖筛选器输出分数的分布形态——重尾分布是实现高信息杠杆的关键前提。

Abstract: Recent generative and tool-using AI systems can surface a large volume of candidates at low marginal cost, yet only a small fraction can be checked carefully. This creates a decoder-side bottleneck: downstream decision-makers must form reliable posteriors from many public records under scarce attention. We formalize this regime via Attention-Constrained Inference (ACI), in which a cheap screening stage processes $K$ records and an expensive verification stage can follow up on at most $B$ of them. Under Bayes log-loss, we study the maximum achievable reduction in posterior uncertainty per window, which we call \emph{epistemic throughput}. Our main result is a ``JaKoB'' scaling law showing that epistemic throughput has a baseline term that grows linearly with verification and prevalence, and an additional \emph{information-leverage} term that scales as $\sqrt{JKB}$, where $J$ summarizes screening quality. Thus, expanding cheap screening can nonlinearly amplify scarce verification, even when informative records are rare. We further show that this scaling is tight in a weak-screening limit, and that in the sparse-verification regime ($B \ll K$), substantial leverage requires heavy-tailed score distributions; for light-tailed scores the amplification is only logarithmic.

</details>


### [175] [Counterfactual Maps: What They Are and How to Find Them](https://arxiv.org/abs/2602.09128)
*Awa Khouna,Julien Ferry,Thibaut Vidal*

Main category: cs.LG

TL;DR: 本文提出了一种基于最近区域搜索和反事实图（counterfactual maps）的高效、精确方法，用于为树集成模型生成反事实解释；利用KD树实现亚线性查询时间，并提供最优性保证。


<details>
  <summary>Details</summary>
Motivation: 现有树集成模型的反事实解释方法要么缺乏最优性保证（启发式），要么计算开销大、无法满足交互式需求（混合整数规划），忽视了模型预测在轴对齐超矩形上分段常数的几何结构。

Method: 将树集成压缩为带标签的超矩形划分，把反事实搜索建模为寻找异标号最近超矩形对应的广义Voronoi单元问题；设计基于体积KD树的分支限界最近区域查询算法，支持一次性预处理与摊销式快速查询，并提供显式最优性证书。

Result: 在多个高风险真实数据集上验证，该方法可在毫秒级延迟内生成全局最优反事实解释，查询速度比现有精确冷启动优化方法快数个数量级。

Conclusion: 通过挖掘树集成的几何本质并引入反事实图与体积KD树，本文实现了高效、可扩展且理论保证的反事实生成，显著推进了可解释机器学习在实际场景中的落地能力。

Abstract: Counterfactual explanations are a central tool in interpretable machine learning, yet computing them exactly for complex models remains challenging. For tree ensembles, predictions are piecewise constant over a large collection of axis-aligned hyperrectangles, implying that an optimal counterfactual for a point corresponds to its projection onto the nearest rectangle with an alternative label under a chosen metric. Existing methods largely overlook this geometric structure, relying either on heuristics with no optimality guarantees or on mixed-integer programming formulations that do not scale to interactive use.
  In this work, we revisit counterfactual generation through the lens of nearest-region search and introduce counterfactual maps, a global representation of recourse for tree ensembles. Leveraging the fact that any tree ensemble can be compressed into an equivalent partition of labeled hyperrectangles, we cast counterfactual search as the problem of identifying the generalized Voronoi cell associated with the nearest rectangle of an alternative label. This leads to an exact, amortized algorithm based on volumetric k-dimensional (KD) trees, which performs branch-and-bound nearest-region queries with explicit optimality certificates and sublinear average query time after a one-time preprocessing phase.
  Our experimental analyses on several real datasets drawn from high-stakes application domains show that this approach delivers globally optimal counterfactual explanations with millisecond-level latency, achieving query times that are orders of magnitude faster than existing exact, cold-start optimization methods.

</details>


### [176] [Beyond the Unit Hypersphere: Embedding Magnitude in Contrastive Learning](https://arxiv.org/abs/2602.09229)
*Xincan Feng,Taro Watanabe*

Main category: cs.LG

TL;DR: 本文系统研究了嵌入向量模长在对比学习中的作用，发现其并非噪声，而是携带任务相关的重要信息（如文档相关性）；模长在输入侧和输出侧作用不对称；并提出‘任务对称性原则’指导何时使用点积或余弦相似度。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习普遍使用余弦相似度，隐含假设嵌入模长是噪声，但未阐明模长实际承载什么信息、在何种任务下有用、以及如何有效利用。

Method: 通过2×2消融实验，独立控制文本与视觉模型中输入侧和输出侧的归一化操作，系统分析模长的作用。

Result: 1）输出端模长与文本检索相关性高度正相关（Cohen's d达1.80）；2）输入/输出模长作用不对称：前者影响训练动态，后者直接影响相似度得分；3）模长学习提升非对称任务（如文本检索、RAG），但损害对称任务（如STS、图文对齐）。

Conclusion: 模长蕴含语义信息，不应被简单丢弃；任务对称性决定是否应去除模长约束——该原则可实现零成本性能提升。

Abstract: Cosine similarity is prevalent in contrastive learning, yet it makes an implicit assumption: embedding magnitude is noise. Prior work occasionally found dot product and cosine similarity comparable, but left unanswered WHAT information magnitude carries, WHEN it helps, and HOW to leverage it. We conduct a systematic study through a $2 \times 2$ ablation that independently controls input-side and output-side normalization across text and vision models. Our findings reveal three key insights. First, in text retrieval, output (document) magnitude strongly correlates with relevance (Cohen's $d$ up to 1.80), yielding the largest gains on reasoning-intensive tasks. Second, input and output magnitudes serve asymmetric roles: output magnitude directly scales similarity scores while input magnitude modulates training dynamics. Third, magnitude learning benefits asymmetric tasks (text retrieval, RAG) but harms symmetric tasks (STS, text-image alignment). These findings establish a task symmetry principle: the choice between cosine and dot product depends on whether the task has distinct input roles, enabling cost-free improvements by simply removing an unnecessary constraint.

</details>


### [177] [UniComp: A Unified Evaluation of Large Language Model Compression via Pruning, Quantization and Distillation](https://arxiv.org/abs/2602.09130)
*Jonathan von Rad,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: 本文提出了UniComp统一评估框架，用于全面比较LLM压缩技术（剪枝、量化、知识蒸馏），从性能、可靠性和效率三方面评估，并揭示了压缩带来的知识偏差、不同方法的权衡特性及任务校准对推理能力的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM压缩评估方法覆盖不全，且过度聚焦于知识型基准，缺乏对推理、多语言、指令遵循等能力及安全性的系统评估。

Method: 提出UniComp统一评估框架，涵盖剪枝、量化和知识蒸馏三类压缩方法；在40+数据集上，从性能（能力与安全性基准）、可靠性（鲁棒性与一致性）和效率（硬件感知分析）三个维度进行综合评测。

Result: （i）压缩普遍存在知识偏差：知识密集型任务保留较好，而推理、多语言和指令跟随能力显著下降；（ii）量化在性能-效率权衡上最优，蒸馏虽加速明显但计算开销高；（iii）任务特定校准可使剪枝模型推理能力提升达50%。

Conclusion: UniComp为LLM压缩提供了更全面、实用的评估范式，揭示了关键权衡规律，并指出任务校准是提升压缩模型推理能力的有效途径。

Abstract: Model compression is increasingly essential for deploying large language models (LLMs), yet existing evaluations are limited in method coverage and focus primarily on knowledge-centric benchmarks. Thus, we introduce UniComp, a unified evaluation framework for comparing pruning, quantization, and knowledge distillation. UniComp evaluates compressed models along three dimensions: performance, reliability, and efficiency, using a diverse set of capability- and safety-oriented benchmarks together with a hardware-aware efficiency analysis. Through extensive evaluation of six compression techniques on modern LLMs across more than 40 datasets, we find that (i) compression exhibits a consistent knowledge bias, where knowledge-intensive tasks are relatively preserved while reasoning, multilingual, and instruction-following capabilities degrade substantially; (ii) quantization provides the best overall trade-off between retained performance and efficiency, whereas distillation yields strong runtime acceleration gains at high computational cost; and (iii) task-specific calibration can significantly improve the reasoning ability of pruned models by up to 50%.

</details>


### [178] [What do Geometric Hallucination Detection Metrics Actually Measure?](https://arxiv.org/abs/2602.09158)
*Eric Yeats,John Buckheit,Sarah Scullen,Brendan Kennedy,Loc Truong,Davis Brown,Bill Kay,Cliff Joslyn,Tegan Emerson,Michael J. Henry,John Emanuello,Henry Kvinge*

Main category: cs.LG

TL;DR: 本文研究了大语言模型内部状态中的几何信号对幻觉现象的预测能力，通过构建合成数据集分析不同几何统计量对各类幻觉（如错误性、不相关性、不连贯性等）的识别效果，并提出一种简单归一化方法以缓解任务领域迁移带来的性能下降，显著提升多领域设置下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 幻觉问题阻碍了生成式模型在高风险场景中的部署，尤其在缺乏外部真实标签验证输出时；现有基于内部几何信号的幻觉检测方法缺乏对所捕获幻觉类型的具体刻画，且易受任务领域变化影响。

Method: 构建一个系统性变化输出正确性、置信度、相关性、连贯性和完整性等维度的合成数据集，评估多种内部几何统计量对不同幻觉类型的敏感性；分析领域偏移对检测性能的影响，并提出一种针对几何统计量的简单归一化方法。

Result: 发现不同几何统计量对不同类型的幻觉具有差异化捕捉能力；多数现有几何检测方法对任务领域变化（如数学题 vs 历史题）高度敏感；所提归一化方法在多领域设置下AUROC提升达+34点。

Conclusion: 几何信号并非统一表征‘幻觉’这一笼统概念，而是分别响应不同语义层面的输出缺陷；需结合幻觉定义的具体维度设计和校准检测方法，而归一化是提升跨领域鲁棒性的有效手段。

Abstract: Hallucination remains a barrier to deploying generative models in high-consequence applications. This is especially true in cases where external ground truth is not readily available to validate model outputs. This situation has motivated the study of geometric signals in the internal state of an LLM that are predictive of hallucination and require limited external knowledge. Given that there are a range of factors that can lead model output to be called a hallucination (e.g., irrelevance vs incoherence), in this paper we ask what specific properties of a hallucination these geometric statistics actually capture. To assess this, we generate a synthetic dataset which varies distinct properties of output associated with hallucination. This includes output correctness, confidence, relevance, coherence, and completeness. We find that different geometric statistics capture different types of hallucinations. Along the way we show that many existing geometric detection methods have substantial sensitivity to shifts in task domain (e.g., math questions vs. history questions). Motivated by this, we introduce a simple normalization method to mitigate the effect of domain shift on geometric statistics, leading to AUROC gains of +34 points in multi-domain settings.

</details>


### [179] [Boltzmann Reinforcement Learning for Noise resilience in Analog Ising Machines](https://arxiv.org/abs/2602.09162)
*Aditya Choudhary,Saaketh Desai,Prasad Iyer*

Main category: cs.LG

TL;DR: 本文提出BRAIN框架，利用变分强化学习逼近玻尔兹曼分布，提升模拟伊辛机在噪声环境下的优化与采样性能。


<details>
  <summary>Details</summary>
Motivation: 传统优化和采样算法在模拟伊辛机（AIMs）上受限于固有测量噪声，影响性能。

Method: 提出BRAIN（Boltzmann Reinforcement for Analog Ising Networks），采用变分强化学习，聚合多次含噪声测量信息而非逐状态采样，以增强对高斯噪声的鲁棒性。

Result: 在3%高斯噪声下，BRAIN保持98%基态保真度（MCMC仅51%）；求解速度比MCMC快至192倍；扩展性达65,536自旋（O(N^1.55)）；对高达40%测量不确定性仍具鲁棒性；并能准确刻画相变与亚稳态。

Conclusion: BRAIN为模拟计算架构提供了可扩展、抗噪的组合优化新方法，不仅提升基态搜索能力，还支持热力学性质建模。

Abstract: Analog Ising machines (AIMs) have emerged as a promising paradigm for combinatorial optimization, utilizing physical dynamics to solve Ising problems with high energy efficiency. However, the performance of traditional optimization and sampling algorithms on these platforms is often limited by inherent measurement noise. We introduce BRAIN (Boltzmann Reinforcement for Analog Ising Networks), a distribution learning framework that utilizes variational reinforcement learning to approximate the Boltzmann distribution. By shifting from state-by-state sampling to aggregating information across multiple noisy measurements, BRAIN is resilient to Gaussian noise characteristic of AIMs. We evaluate BRAIN across diverse combinatorial topologies, including the Curie-Weiss and 2D nearest-neighbor Ising systems. We find that under realistic 3\% Gaussian measurement noise, BRAIN maintains 98\% ground state fidelity, whereas Markov Chain Monte Carlo (MCMC) methods degrade to 51\% fidelity. Furthermore, BRAIN reaches the MCMC-equivalent solution up to 192x faster under these conditions. BRAIN exhibits $\mathcal{O}(N^{1.55})$ scaling up to 65,536 spins and maintains robustness against severe measurement uncertainty up to 40\%. Beyond ground state optimization, BRAIN accurately captures thermodynamic phase transitions and metastable states, providing a scalable and noise-resilient method for utilizing analog computing architectures in complex optimizations.

</details>


### [180] [Faster Rates For Federated Variational Inequalities](https://arxiv.org/abs/2602.09164)
*Guanghui Wang,Satyen Kale*

Main category: cs.LG

TL;DR: 本文研究联邦优化下随机变分不等式（VIs）的求解，提出新算法LIPPAX以缓解客户端漂移并改进收敛率，覆盖多种设定并扩展至复合变分不等式。


<details>
  <summary>Details</summary>
Motivation: 现有联邦变分不等式求解方法的收敛率与联邦凸优化的最优界之间存在显著差距，且Local Extra SGD存在客户端漂移问题。

Method: 通过精细化分析改进Local Extra SGD的收敛性；识别其漂移缺陷后，提出新算法LIPPAX（带额外步的局部近似邻近点算法），并在有界Hessian、有界算子和低方差等设定下分析其性能；进一步将结果推广至联邦复合变分不等式。

Result: 获得了比现有方法更优的收敛率；LIPPAX有效缓解客户端漂移，在多个设定下取得理论保证提升；对联邦复合变分不等式也建立了改进的收敛性结果。

Conclusion: 本文填补了联邦变分不等式收敛率与联邦凸优化之间的理论鸿沟，提出的LIPPAX算法为该问题提供了更稳健、高效的新解决方案。

Abstract: In this paper, we study federated optimization for solving stochastic variational inequalities (VIs), a problem that has attracted growing attention in recent years. Despite substantial progress, a significant gap remains between existing convergence rates and the state-of-the-art bounds known for federated convex optimization. In this work, we address this limitation by establishing a series of improved convergence rates. First, we show that, for general smooth and monotone variational inequalities, the classical Local Extra SGD algorithm admits tighter guarantees under a refined analysis. Next, we identify an inherent limitation of Local Extra SGD, which can lead to excessive client drift. Motivated by this observation, we propose a new algorithm, the Local Inexact Proximal Point Algorithm with Extra Step (LIPPAX), and show that it mitigates client drift and achieves improved guarantees in several regimes, including bounded Hessian, bounded operator, and low-variance settings. Finally, we extend our results to federated composite variational inequalities and establish improved convergence guarantees.

</details>


### [181] [Train Less, Infer Faster: Efficient Model Finetuning and Compression via Structured Sparsity](https://arxiv.org/abs/2602.09169)
*Jonathan Svirsky,Yehonathan Refael,Ofir Lindenbaum*

Main category: cs.LG

TL;DR: 本文提出了一种基于稀疏化的高效大语言模型任务适配方法，通过训练随机门控来剪枝特定的模型行列，在几乎不损失精度的情况下减少20-40%参数、降低推理延迟，并提供理论收敛性保证和更优的优化景观。


<details>
  <summary>Details</summary>
Motivation: 全量微调百亿参数大语言模型计算开销大、内存占用高且易过拟合；现有低秩适配（如LoRA）虽减少训练参数，但增加内存并无法降低推理延迟。

Method: 提出基于训练随机门控（stochastic gates）的稀疏化微调方案，选择性地剪枝模型中的行与列，仅需极少量可训练参数，实现无需权重更新的任务适配。

Result: 在多个任务上超越近期微调基线，在效率（推理速度、参数量）和性能（准确率）上均表现更优；理论证明其收敛性，并表明其优化景观比LoRA更简单、条件更好。

Conclusion: 稀疏性是一种极具潜力的大语言模型任务特化适配机制，可在显著压缩模型的同时保持高性能，并提升训练与推理效率。

Abstract: Fully finetuning foundation language models (LMs) with billions of parameters is often impractical due to high computational costs, memory requirements, and the risk of overfitting. Although methods like low-rank adapters help address these challenges by adding small trainable modules to the frozen LM, they also increase memory usage and do not reduce inference latency. We uncover an intriguing phenomenon: sparsifying specific model rows and columns enables efficient task adaptation without requiring weight tuning. We propose a scheme for effective finetuning via sparsification using training stochastic gates, which requires minimal trainable parameters, reduces inference time, and removes 20--40\% of model parameters without significant accuracy loss. Empirical results show it outperforms recent finetuning baselines in efficiency and performance. Additionally, we provide theoretical guarantees for the convergence of this stochastic gating process, and show that our method admits a simpler and better-conditioned optimization landscape compared to LoRA. Our results highlight sparsity as a compelling mechanism for task-specific adaptation in LMs.

</details>


### [182] [$n$-Musketeers: Reinforcement Learning Shapes Collaboration Among Language Models](https://arxiv.org/abs/2602.09173)
*Ryozo Masukawa,Sanggeon Yun,Hyunwoo Oh,SuhgHeon Jeong,Raheeb Hassa,Hanning Chen,Wenjun Huang,Mahdi Imani,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani*

Main category: cs.LG

TL;DR: 本文提出了一种软隐状态协作机制，通过可训练的注意力接口整合多个异构冻结的小型语言模型（SLM）专家，实验证明其在推理任务上媲美强单模型基线，并揭示了专家利用模式随任务难度演化的现象。


<details>
  <summary>Details</summary>
Motivation: 探索如何在不依赖大型单体语言模型的前提下，利用小型专业化模型实现结构化推理，同时提升强化学习中可验证奖励（RLVR）框架下的性能与可解释性。

Method: 提出软隐状态协作机制：将多个异构冻结SLM专家的内部隐状态通过一个可训练的注意力接口进行融合，实现跨模型的潜在空间协作。

Result: 在Reasoning Gym和GSM8K上达到与强单模型RLVR基线相当的性能；消融实验发现简单任务下专家偏好趋于静态，而复杂任务促使注意力分布更集中、结构化，呈现专家利用的涌现式专门化。

Conclusion: 隐状态协作是一种紧凑高效利用冻结专家的方法，不仅提升性能，还为观察和理解RLVR中专家利用模式的动态演化提供了新视角。

Abstract: Recent progress in reinforcement learning with verifiable rewards (RLVR) shows that small, specialized language models (SLMs) can exhibit structured reasoning without relying on large monolithic LLMs. We introduce soft hidden-state collaboration, where multiple heterogeneous frozen SLM experts are integrated through their internal representations via a trainable attention interface. Experiments on Reasoning Gym and GSM8K show that this latent integration is competitive with strong single-model RLVR baselines. Ablations further reveal a dual mechanism of expert utilization: for simpler arithmetic domains, performance gains can largely be explained by static expert preferences, whereas more challenging settings induce increasingly concentrated and structured expert attention over training, indicating emergent specialization in how the router connects to relevant experts. Overall, hidden-state collaboration provides a compact mechanism for leveraging frozen experts, while offering an observational window into expert utilization patterns and their evolution under RLVR.

</details>


### [183] [Weighted Wasserstein Barycenter of Gaussian Processes for exotic Bayesian Optimization tasks](https://arxiv.org/abs/2602.09181)
*Antonio Candelieri,Francesco Archetti*

Main category: cs.LG

TL;DR: 本文提出了一种基于加权Wasserstein重心（W2BGP）的统一框架，用于处理多种贝叶斯优化（BO）任务，包括协同/联邦BO、批量BO和多保真度BO，并重新诠释经典采集函数，提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 为统一处理多种异构贝叶斯优化任务（如联邦BO、批量BO、多保真BO），需一个通用且灵活的理论框架。

Method: 利用高斯过程后验与高斯分布之间的类比，构建加权Wasserstein重心（W2BGP）框架，并通过调整权重适配不同BO任务；同时将经典BO采集函数纳入该框架并优化重心计算。

Result: 实证表明：仅需为不同BO任务设计合适权重，即可复用同一W2BGP框架；经典采集函数可自然嵌入该框架；W2BGP计算比现有机器学习方法更高效。

Conclusion: W2BGP提供了一个统一、可扩展且计算高效的贝叶斯优化通用框架，为未来联邦学习、多保真建模等方向提供了新思路。

Abstract: Exploiting the analogy between Gaussian Distributions and Gaussian Processes' posterior, we present how the weighted Wasserstein Barycenter of Gaussian Processes (W2BGP) can be used to unify, under a common framework, different exotic Bayesian Optimization (BO) tasks. Specifically, collaborative/federated BO, (synchronous) batch BO, and multi-fidelity BO are considered in this paper. Our empirical analysis proves that each one of these tasks requires just an appropriate weighting schema for the W2BGP, while the entire framework remains untouched. Moreover, we demonstrate that the most well-known BO acquisition functions can be easily re-interpreted under the proposed framework and also enable a more computationally efficient way to deal with the computation of the Wasserstein Barycenter, compared with state-of-the-art methods from the Machine Learning literature. Finally, research perspectives branching from the proposed approach are presented.

</details>


### [184] [Gradient Residual Connections](https://arxiv.org/abs/2602.09190)
*Yangchen Pan,Qizhen Ying,Philip Torr,Bo Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于梯度的残差连接，以增强神经网络对高频函数的逼近能力，尤其在合成高频正弦回归任务和单图像超分辨率任务中表现优异，同时在图像分类与分割等标准任务上保持与常规残差网络相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作将函数梯度性质与函数逼近难度联系起来；作者受此启发，探索如何利用梯度信息提升神经网络对高频函数的逼近能力。

Method: 提出一种梯度-based残差连接，作为标准恒等跳连的补充；进一步引入标准残差与梯度残差的凸组合，使网络可自适应调节对梯度信息的依赖程度。

Result: 在高频合成回归任务中显著优于常规残差连接；在单图像超分辨率任务中验证有效性；在图像分类与分割任务中性能与标准残差网络相当。

Conclusion: 梯度信息有助于区分输入并提升高频函数逼近能力；所提梯度残差连接具有通用性与实用性，可作为标准残差结构的有效扩展。

Abstract: Existing work has linked properties of a function's gradient to the difficulty of function approximation. Motivated by these insights, we study how gradient information can be leveraged to improve neural network's ability to approximate high-frequency functions, and we propose a gradient-based residual connection as a complement to the standard identity skip connection used in residual networks. We provide simple theoretical intuition for why gradient information can help distinguish inputs and improve the approximation of functions with rapidly varying behaviour. On a synthetic regression task with a high-frequency sinusoidal ground truth, we show that conventional residual connections struggle to capture high-frequency patterns. In contrast, our gradient residual substantially improves approximation quality. We then introduce a convex combination of the standard and gradient residuals, allowing the network to flexibly control how strongly it relies on gradient information. After validating the design choices of our proposed method through an ablation study, we further validate our approach's utility on the single-image super-resolution task, where the underlying function may be high-frequency. Finally, on standard tasks such as image classification and segmentation, our method achieves performance comparable to standard residual networks, suggesting its broad utility.

</details>


### [185] [ML-DCN: Masked Low-Rank Deep Crossing Network Towards Scalable Ads Click-through Rate Prediction at Pinterest](https://arxiv.org/abs/2602.09194)
*Jiacheng Li,Yixiong Meng,Yi wu,Yun Zhao,Sharare Zehtabian,Jiayin Jin,Degao Peng,Jinfeng Zhuang,Qifei Shen,Kungang Li*

Main category: cs.LG

TL;DR: 本文提出ML-DCN，一种在固定推理预算下高效扩展特征交互模块的新架构，融合了DCNv2与MaskNet的优点，在Pinterest广告排序系统中实现了更优的AUC-FLOPs权衡及线上业务指标提升。


<details>
  <summary>Details</summary>
Motivation: 大规模广告排序中，需在严格延迟和计算量（FLOPs）约束下提升模型容量以改善性能，但现有方法（如DCNv2、MaskNet）在固定服务预算下扩展时收益迅速衰减。

Method: 提出ML-DCN：在低秩交叉层中引入实例条件掩码（instance-conditioned mask），实现样本级关键交互方向的选择与增强，兼顾表达能力与计算效率。

Result: 在Pinterest内部广告数据集上，ML-DCN在相同FLOPs下AUC优于DCNv2、MaskNet及近期扩展型方法；AUC-FLOPs权衡更强；线上A/B测试显著提升CTR与点击质量等核心广告指标。

Conclusion: ML-DCN有效解决了特征交互模块在服务预算约束下的可扩展性问题，兼具高性能与高效率，已在Pinterest生产系统部署且服务开销中性。

Abstract: Deep learning recommendation systems rely on feature interaction modules to model complex user-item relationships across sparse categorical and dense features. In large-scale ad ranking, increasing model capacity is a promising path to improving both predictive performance and business outcomes, yet production serving budgets impose strict constraints on latency and FLOPs. This creates a central tension: we want interaction modules that both scale effectively with additional compute and remain compute-efficient at serving time. In this work, we study how to scale feature interaction modules under a fixed serving budget. We find that naively scaling DCNv2 and MaskNet, despite their widespread adoption in industry, yields rapidly diminishing offline gains in the Pinterest ads ranking system. To overcome aforementioned limitations, we propose ML-DCN, an interaction module that integrates an instance-conditioned mask into a low-rank crossing layer, enabling per-example selection and amplification of salient interaction directions while maintaining efficient computation. This novel architecture combines the strengths of DCNv2 and MaskNet, scales efficiently with increased compute, and achieves state-of-the-art performance. Experiments on a large internal Pinterest ads dataset show that ML-DCN achieves higher AUC than DCNv2, MaskNet, and recent scaling-oriented alternatives at matched FLOPs, and it scales more favorably overall as compute increases, exhibiting a stronger AUC-FLOPs trade-off. Finally, online A/B tests demonstrate statistically significant improvements in key ads metrics (including CTR and click-quality measures) and ML-DCN has been deployed in the production system with neutral serving cost.

</details>


### [186] [Fair Feature Importance Scores via Feature Occlusion and Permutation](https://arxiv.org/abs/2602.09196)
*Camille Little,Madeline Navarro,Santiago Segarra,Genevera Allen*

Main category: cs.LG

TL;DR: 本文提出了两种模型无关的方法来衡量特征对公平性的重要性：置换法和遮蔽法，旨在提高机器学习模型在公平性方面的可解释性和可问责性。


<details>
  <summary>Details</summary>
Motivation: 现有特征重要性指标主要针对预测准确性，而评估特征对公平性贡献的方法尚不充分，难以支持可解释、公平的模型构建。

Method: 提出两种模型无关方法：1）置换法——通过置换特征值比较模型公平性变化；2）遮蔽法——训练包含与不包含某特征的模型并比较其公平性，借助minipatch学习实现高效计算。

Result: 实验证明两种方法简单、有效、可扩展，适用于多种预测任务，能清晰量化特征对公平性的影响。

Conclusion: 所提方法为负责任的机器学习开发提供了新的、可解释且实用的公平性分析工具。

Abstract: As machine learning models increasingly impact society, their opaque nature poses challenges to trust and accountability, particularly in fairness contexts. Understanding how individual features influence model outcomes is crucial for building interpretable and equitable models. While feature importance metrics for accuracy are well-established, methods for assessing feature contributions to fairness remain underexplored. We propose two model-agnostic approaches to measure fair feature importance. First, we propose to compare model fairness before and after permuting feature values. This simple intervention-based approach decouples a feature and model predictions to measure its contribution to training. Second, we evaluate the fairness of models trained with and without a given feature. This occlusion-based score enjoys dramatic computational simplification via minipatch learning. Our empirical results reflect the simplicity and effectiveness of our proposed metrics for multiple predictive tasks. Both methods offer simple, scalable, and interpretable solutions to quantify the influence of features on fairness, providing new tools for responsible machine learning development.

</details>


### [187] [CausalGDP: Causality-Guided Diffusion Policies for Reinforcement Learning](https://arxiv.org/abs/2602.09207)
*Xiaofeng Xiao,Xiao Hu,Yang Ye,Xubo Yue*

Main category: cs.LG

TL;DR: 本文提出Causality-guided Diffusion Policy（CausalGDP），将因果推理融入基于扩散的强化学习框架，以提升策略对高回报动作成分的识别与优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略仅依赖统计关联，忽视状态、动作与奖励间的因果关系，难以识别真正导致高回报的动作成分。

Method: CausalGDP首先从离线数据中学习基础扩散策略和初始因果动力学模型；在实时交互中持续更新因果信息，并将其作为引导信号调控扩散过程，使采样动作更倾向于具有因果影响力的动作。

Result: 实验表明，CausalGDP在复杂高维控制任务中持续优于或媲美当前最先进的扩散型及离线RL方法。

Conclusion: 显式建模因果关系可有效提升扩散策略的泛化性与决策质量，为因果驱动的生成式强化学习提供了新范式。

Abstract: Reinforcement learning (RL) has achieved remarkable success in a wide range of sequential decision-making problems. Recent diffusion-based policies further improve RL by modeling complex, high-dimensional action distributions. However, existing diffusion policies primarily rely on statistical associations and fail to explicitly account for causal relationships among states, actions, and rewards, limiting their ability to identify which action components truly cause high returns. In this paper, we propose Causality-guided Diffusion Policy (CausalGDP), a unified framework that integrates causal reasoning into diffusion-based RL. CausalGDP first learns a base diffusion policy and an initial causal dynamical model from offline data, capturing causal dependencies among states, actions, and rewards. During real-time interaction, the causal information is continuously updated and incorporated as a guidance signal to steer the diffusion process toward actions that causally influence future states and rewards. By explicitly considering causality beyond association, CausalGDP focuses policy optimization on action components that genuinely drive performance improvements. Experimental results demonstrate that CausalGDP consistently achieves competitive or superior performance over state-of-the-art diffusion-based and offline RL methods, especially in complex, high-dimensional control tasks.

</details>


### [188] [A Lightweight Multi-View Approach to Short-Term Load Forecasting](https://arxiv.org/abs/2602.09220)
*Julien Guité-Vinet,Alexandre Blondin Massé,Éric Beaudry*

Main category: cs.LG

TL;DR: 本文提出了一种轻量级多视角方法用于短期负荷预测，通过单值嵌入和缩放时间范围输入高效捕捉时序相关特征，并引入嵌入丢弃机制提升鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的大参数模型虽性能优越，但易过拟合、预测不稳定，尤其当历史数据相关性下降时；需更轻量、鲁棒且可解释的方案。

Method: 采用单值嵌入与缩放时间范围输入构建多视角特征表示，并设计嵌入丢弃机制以降低对特定特征的依赖。

Result: 在多个数据集上达到具有竞争力的性能，参数量显著减少，对噪声和稀疏数据表现鲁棒，并支持特征贡献分析。

Conclusion: 该轻量级多视角方法在保证精度的同时提升了模型效率、鲁棒性与可解释性，适用于实际短时负荷预测场景。

Abstract: Time series forecasting is a critical task across domains such as energy, finance, and meteorology, where accurate predictions enable informed decision-making. While transformer-based and large-parameter models have recently achieved state-of-the-art results, their complexity can lead to overfitting and unstable forecasts, especially when older data points become less relevant. In this paper, we propose a lightweight multi-view approach to short-term load forecasting that leverages single-value embeddings and a scaled time-range input to capture temporally relevant features efficiently. We introduce an embedding dropout mechanism to prevent over-reliance on specific features and enhance interpretability. Our method achieves competitive performance with significantly fewer parameters, demonstrating robustness across multiple datasets, including scenarios with noisy or sparse data, and provides insights into the contributions of individual features to the forecast.

</details>


### [189] [Barycentric alignment for instance-level comparison of neural representations](https://arxiv.org/abs/2602.09225)
*Shreya Saha,Zoe Wanying He,Meenakshi Khosla*

Main category: cs.LG

TL;DR: 本文提出了一种基于重心对齐（barycentric alignment）的框架，用于消除神经网络表征中的对称性干扰（如神经元重排序、空间旋转），构建跨模型的通用嵌入空间；该方法支持在单个刺激（instance-level）层面衡量表征相似性，从而揭示不同模型或大脑区域对特定输入的收敛或分歧响应，并在视觉、语言及脑科学任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 神经网络表征存在多种对称性（如神经元排列任意性、激活空间旋转），使得跨模型比较困难；现有相似性度量仅在整体刺激集层面进行总结，无法刻画个体刺激层面的表征一致性或差异。

Method: 提出重心对齐框架，通过商空间（quotient space）方式消除表征中的无关对称性，构建跨模型/跨被试/跨脑区的通用嵌入空间，并定义实例级（stimulus-level）相似性度量。

Result: 1）识别出预测视觉与语言模型间表征收敛/分歧的系统性输入属性；2）构建跨被试和皮层区域的通用脑表征空间，实现人类视觉层级中实例级表征一致性比较；3）对独立训练的单模态模型进行后对齐，所得图文相似度接近对比学习的多模态模型性能，并与人类跨模态判断高度一致。

Conclusion: 实例级表征相似性分析能揭示集合级度量无法发现的现象，表明独立学习的单模态表征已蕴含足够几何结构以支持人类对齐的跨模态理解，重心对齐为跨模型、跨模态、跨被试比较提供了统一可解释框架。

Abstract: Comparing representations across neural networks is challenging because representations admit symmetries, such as arbitrary reordering of units or rotations of activation space, that obscure underlying equivalence between models. We introduce a barycentric alignment framework that quotients out these nuisance symmetries to construct a universal embedding space across many models. Unlike existing similarity measures, which summarize relationships over entire stimulus sets, this framework enables similarity to be defined at the level of individual stimuli, revealing inputs that elicit convergent versus divergent representations across models. Using this instance-level notion of similarity, we identify systematic input properties that predict representational convergence versus divergence across vision and language model families. We also construct universal embedding spaces for brain representations across individuals and cortical regions, enabling instance-level comparison of representational agreement across stages of the human visual hierarchy. Finally, we apply the same barycentric alignment framework to purely unimodal vision and language models and find that post-hoc alignment into a shared space yields image text similarity scores that closely track human cross-modal judgments and approach the performance of contrastively trained vision-language models. This strikingly suggests that independently learned representations already share sufficient geometric structure for human-aligned cross-modal comparison. Together, these results show that resolving representational similarity at the level of individual stimuli reveals phenomena that cannot be detected by set-level comparison metrics.

</details>


### [190] [Do Neural Networks Lose Plasticity in a Gradually Changing World?](https://arxiv.org/abs/2602.09234)
*Tianhui Liu,Lili Mou*

Main category: cs.LG

TL;DR: 本文研究持续学习中的可塑性丧失现象，提出在渐变环境中进行研究，并通过输入/输出插值和任务采样模拟该环境，理论与实证分析表明可塑性丧失主要是由环境突变引起，渐变环境可大幅缓解该问题。


<details>
  <summary>Details</summary>
Motivation: 现有可塑性研究多基于突变任务设定，无法反映真实世界中环境渐变的特点，因此需在更贴近现实的渐变环境下重新审视可塑性丧失问题。

Method: 提出渐变环境建模方法，包括输入/输出插值和任务采样；结合理论分析与实验验证，探究可塑性随环境变化速率的演化规律。

Result: 发现可塑性丧失本质上是任务突变导致的伪现象，在渐变环境中神经网络能维持较高可塑性。

Conclusion: 环境变化的平滑性对维持模型可塑性至关重要，持续学习系统应设计为适应渐变而非突变的任务流。

Abstract: Continual learning has become a trending topic in machine learning. Recent studies have discovered an interesting phenomenon called loss of plasticity, referring to neural networks gradually losing the ability to learn new tasks. However, existing plasticity research largely relies on contrived settings with abrupt task transitions, which often do not reflect real-world environments. In this paper, we propose to investigate a gradually changing environment, and we simulate this by input/output interpolation and task sampling. We perform theoretical and empirical analysis, showing that the loss of plasticity is an artifact of abrupt tasks changes in the environment and can be largely mitigated if the world changes gradually.

</details>


### [191] [RAPID: Risk of Attribute Prediction-Induced Disclosure in Synthetic Microdata](https://arxiv.org/abs/2602.09235)
*Matthias Templ,Oscar Thees,Roman Müller*

Main category: cs.LG

TL;DR: 本文提出了一种名为RAPID的新披露风险度量方法，用于评估合成数据中属性推断导致的身份泄露风险，该方法基于现实攻击模型，具有可解释性、鲁棒性和通用性。


<details>
  <summary>Details</summary>
Motivation: 传统身份披露度量在完全合成微数据场景下信息量不足，需更贴合现实攻击者能力的属性推断风险度量。

Method: RAPID通过让攻击者仅用发布的合成数据训练预测模型，并在真实个体的准标识符上进行敏感属性预测：对连续型敏感属性，计算预测值在相对误差容限内的比例；对分类型敏感属性，设计基线归一化的置信度分数，并统计超过阈值的记录比例。

Result: RAPID提供了一个有界、可解释、抗类别不平衡、不依赖特定合成器且兼容任意学习算法的风险指标，并通过模拟和真实数据验证了其在阈值校准、不确定性量化及生成器比较中的有效性。

Conclusion: RAPID为属性推断披露风险提供了实用、贴近攻击者视角的上界估计，可有效补充现有效用诊断与披露控制框架。

Abstract: Statistical data anonymization increasingly relies on fully synthetic microdata, for which classical identity disclosure measures are less informative than an adversary's ability to infer sensitive attributes from released data. We introduce RAPID (Risk of Attribute Prediction--Induced Disclosure), a disclosure risk measure that directly quantifies inferential vulnerability under a realistic attack model. An adversary trains a predictive model solely on the released synthetic data and applies it to real individuals' quasi-identifiers. For continuous sensitive attributes, RAPID reports the proportion of records whose predicted values fall within a specified relative error tolerance. For categorical attributes, we propose a baseline-normalized confidence score that measures how much more confident the attacker is about the true class than would be expected from class prevalence alone, and we summarize risk as the fraction of records exceeding a policy-defined threshold. This construction yields an interpretable, bounded risk metric that is robust to class imbalance, independent of any specific synthesizer, and applicable with arbitrary learning algorithms. We illustrate threshold calibration, uncertainty quantification, and comparative evaluation of synthetic data generators using simulations and real data. Our results show that RAPID provides a practical, attacker-realistic upper bound on attribute-inference disclosure risk that complements existing utility diagnostics and disclosure control frameworks.

</details>


### [192] [Feature salience -- not task-informativeness -- drives machine learning model explanations](https://arxiv.org/abs/2602.09238)
*Benedict Clark,Marta Oliveira,Rick Wilming,Stefan Haufe*

Main category: cs.LG

TL;DR: 本文研究了可解释AI（XAI）中特征重要性归因的主要驱动因素，发现图像结构在测试时的显著性（salience）比模型学习到的统计关联性更能影响归因结果，挑战了XAI依赖‘重要特征必含信息’这一基本假设。


<details>
  <summary>Details</summary>
Motivation: XAI方法常假设被标记为重要的输入特征必然包含目标变量的信息，但该假设缺乏实证验证；实际中，统计抑制、测试时新颖性或特征显著性等其他因素可能更主导重要性归因。

Method: 在三种变体的二分类图像任务（无水印、类依赖水印、类无关水印）上训练深度学习模型，使用五种主流归因方法评估水印区域相对重要性（RIW），并对比边缘检测滤波器行为及亮度编码方式的影响。

Result: 所有模型在水印区域均呈现显著升高的RIW（R² ≥ .45），而水印是否类依赖对RIW影响极小（R² ≤ .03）；XAI归因行为类似边缘检测器，且当高亮度由较小特征值编码时，归因于水印的重要性大幅下降。

Conclusion: XAI中的重要性归因主要受测试样本中图像结构显著性驱动，而非模型学到的统计相关性；这提示以往基于XAI的成功应用可能存在‘显著性与信息性偶然共现’的混淆，相关工作流需重新审视。

Abstract: Explainable AI (XAI) promises to provide insight into machine learning models' decision processes, where one goal is to identify failures such as shortcut learning. This promise relies on the field's assumption that input features marked as important by an XAI must contain information about the target variable. However, it is unclear whether informativeness is indeed the main driver of importance attribution in practice, or if other data properties such as statistical suppression, novelty at test-time, or high feature salience substantially contribute. To clarify this, we trained deep learning models on three variants of a binary image classification task, in which translucent watermarks are either absent, act as class-dependent confounds, or represent class-independent noise. Results for five popular attribution methods show substantially elevated relative importance in watermarked areas (RIW) for all models regardless of the training setting ($R^2 \geq .45$). By contrast, whether the presence of watermarks is class-dependent or not only has a marginal effect on RIW ($R^2 \leq .03$), despite a clear impact impact on model performance and generalisation ability. XAI methods show similar behaviour to model-agnostic edge detection filters and attribute substantially less importance to watermarks when bright image intensities are encoded by smaller instead of larger feature values. These results indicate that importance attribution is most strongly driven by the salience of image structures at test time rather than statistical associations learned by machine learning models. Previous studies demonstrating successful XAI application should be reevaluated with respect to a possibly spurious concurrency of feature salience and informativeness, and workflows using feature attribution methods as building blocks should be scrutinised.

</details>


### [193] [Generalizing GNNs with Tokenized Mixture of Experts](https://arxiv.org/abs/2602.09258)
*Xiaoguang Guo,Zehong Wang,Jiazheng Li,Shawn Spitzel,Qi Yang,Kaize Ding,Jundong Li,Chuxu Zhang*

Main category: cs.LG

TL;DR: 本文提出STEM-GNN框架，通过预训练-微调范式、混合专家编码器、向量量化token接口和Lipschitz正则化预测头，在保持干净图性能的同时，显著提升GNN对分布偏移与扰动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有部署的图神经网络（GNN）在推理时是静态冻结的，难以同时兼顾干净数据性能、分布偏移下的泛化能力以及对扰动的稳定性，存在根本性权衡。

Method: 提出STEM-GNN：采用混合专家（MoE）编码器支持实例条件路由以增强多样性；引入向量量化token接口稳定编码器到预测头的信号传递；使用Lipschitz正则化预测头限制输出对输入扰动的放大效应。

Result: 在9个节点、链接和图级基准上，STEM-GNN在干净数据性能、分布偏移（如度数/同质性变化）鲁棒性、特征/边扰动鲁棒性三方面取得更优平衡，整体鲁棒性显著提升。

Conclusion: 实例条件路由结合结构化稳定性设计（量化接口+Lipschitz约束）可突破静态GNN的鲁棒性-泛化权衡瓶颈，为部署鲁棒GNN提供新范式。

Abstract: Deployed graph neural networks (GNNs) are frozen at deployment yet must fit clean data, generalize under distribution shifts, and remain stable to perturbations. We show that static inference induces a fundamental tradeoff: improving stability requires reducing reliance on shift-sensitive features, leaving an irreducible worst-case generalization floor. Instance-conditional routing can break this ceiling, but is fragile because shifts can mislead routing and perturbations can make routing fluctuate. We capture these effects via two decompositions separating coverage vs selection, and base sensitivity vs fluctuation amplification. Based on these insights, we propose STEM-GNN, a pretrain-then-finetune framework with a mixture-of-experts encoder for diverse computation paths, a vector-quantized token interface to stabilize encoder-to-head signals, and a Lipschitz-regularized head to bound output amplification. Across nine node, link, and graph benchmarks, STEM-GNN achieves a stronger three-way balance, improving robustness to degree/homophily shifts and to feature/edge corruptions while remaining competitive on clean graphs.

</details>


### [194] [The effect of whitening on explanation performance](https://arxiv.org/abs/2602.09278)
*Benedict Clark,Stoyan Karastoyanov,Rick Wilming,Stefan Haufe*

Main category: cs.LG

TL;DR: 本文研究数据白化（whitening）是否能缓解XAI中特征归因方法对非信息性变量（如抑制变量）的错误重要性分配问题，通过XAI-TRIS基准和理论分析发现：特定白化技术可提升解释性能，但效果因XAI方法和模型架构而异，强调预处理对可解释性的关键作用。


<details>
  <summary>Details</summary>
Motivation: 许多特征归因方法会错误地将高重要性赋予非信息性变量（如抑制变量），导致根本性误解释；而抑制效应源于特征间依赖关系，因此探究能解除相关性的数据白化是否可缓解该问题。

Method: 在XAI-TRIS基准上实证评估16种主流特征归因方法与5种白化变换的组合效果，并结合Wilming等人提出的二维线性分类问题进行理论分析，考察白化能否消除抑制特征在贝叶斯最优模型中的影响。

Result: 特定白化技术可提升解释正确性，但提升程度在不同XAI方法和模型架构间差异显著；白化不能普适地消除抑制效应，其有效性受数据非线性、预处理质量及归因方法本身特性共同影响。

Conclusion: 数据预处理（尤其是白化）对提升XAI可靠性具有重要作用，但需与具体归因方法和模型联合设计，不可一概而论；未来XAI研究应更重视预处理与解释方法的协同优化。

Abstract: Explainable Artificial Intelligence (XAI) aims to provide transparent insights into machine learning models, yet the reliability of many feature attribution methods remains a critical challenge. Prior research (Haufe et al., 2014; Wilming et al., 2022, 2023) has demonstrated that these methods often erroneously assign significant importance to non-informative variables, such as suppressor variables, leading to fundamental misinterpretations. Since statistical suppression is induced by feature dependencies, this study investigates whether data whitening, a common preprocessing technique for decorrelation, can mitigate such errors. Using the established XAI-TRIS benchmark (Clark et al., 2024b), which offers synthetic ground-truth data and quantitative measures of explanation correctness, we empirically evaluate 16 popular feature attribution methods applied in combination with 5 distinct whitening transforms. Additionally, we analyze a minimal linear two-dimensional classification problem (Wilming et al., 2023) to theoretically assess whether whitening can remove the impact of suppressor features from Bayes-optimal models. Our results indicate that, while specific whitening techniques can improve explanation performance, the degree of improvement varies substantially across XAI methods and model architectures. These findings highlight the complex relationship between data non-linearities, preprocessing quality, and attribution fidelity, underscoring the vital role of pre-processing techniques in enhancing model interpretability.

</details>


### [195] [Measuring Privacy Risks and Tradeoffs in Financial Synthetic Data Generation](https://arxiv.org/abs/2602.09288)
*Michael Zuo,Inwon Kang,Stacy Patterson,Oshani Seneviratne*

Main category: cs.LG

TL;DR: 本文探讨了在具有高监管风险和严重类别不平衡的表格金融数据集上，合成数据生成方案的隐私-效用权衡问题，评估了多种生成器（如自编码器、GAN、扩散模型、Copula合成器）在数据质量、下游效用和隐私保护方面的综合表现，并提出了针对GAN和自编码器的新型隐私保护实现方法。


<details>
  <summary>Details</summary>
Motivation: 金融数据具有高监管风险和严重类别不平衡的特点，使得合成数据生成面临独特挑战，需在隐私保护与数据效用之间取得平衡。

Method: 采用多种代表性表格数据生成器（包括自编码器、GAN、扩散模型、Copula合成器），并提出针对GAN和自编码器的新型隐私保护实现方法；在平衡与不平衡输入数据集上系统评估其数据质量、下游任务效用及隐私保护能力。

Result: 揭示了在严重类别不平衡和混合类型属性数据上生成合成数据的独特挑战；不同生成器在隐私、效用和质量上的表现存在显著差异；所提出的隐私增强型GAN与自编码器在金融场景中展现出更好平衡性。

Conclusion: 合成数据生成在金融领域需兼顾隐私、效用与数据特性；现有方法在类别不平衡场景下表现受限；定制化的隐私保护设计对提升金融合成数据实用性至关重要。

Abstract: We explore the privacy-utility tradeoff of synthetic data generation schemes on tabular financial datasets, a domain characterized by high regulatory risk and severe class imbalance. We consider representative tabular data generators, including autoencoders, generative adversarial networks, diffusion, and copula synthesizers. To address the challenges of the financial domain, we provide novel privacy-preserving implementations of GAN and autoencoder synthesizers. We evaluate whether and how well the generators simultaneously achieve data quality, downstream utility, and privacy, with comparison across balanced and imbalanced input datasets. Our results offer insight into the distinct challenges of generating synthetic data from datasets that exhibit severe class imbalance and mixed-type attributes.

</details>


### [196] [Positive-Unlabelled Active Learning to Curate a Dataset for Orca Resident Interpretation](https://arxiv.org/abs/2602.09295)
*Bret Nestor,Bohan Yao,Jasmine Moore,Jasper Kanes*

Main category: cs.LG

TL;DR: 本文提出了一种弱监督、正样本-无标签（PU）结合主动学习的策略，从30多年公开水听器数据中系统挖掘南方定居型虎鲸（SRKW）及其他海洋哺乳动物声学数据，构建了迄今最大的SRKW声学数据集，并开发了高性能、高能效的Transformer检测与分类模型。


<details>
  <summary>Details</summary>
Motivation: 南方定居型虎鲸（SRKW）为极危生态型，缺乏大规模、高质量、带标注的声学数据严重制约其监测与保护研究；现有数据集规模小、覆盖有限，亟需系统性整合与标注。

Method: 采用弱监督+正样本-无标签（PU）学习+主动学习的混合策略，对超30年公共水听器音频进行系统检索；构建基于Transformer的检测器与多类物种/生态型分类器；在多个基准（DEEPAL、DCLDE-2026及两个新标注集）上评估性能。

Result: 获得总计超5000小时带标签海洋哺乳动物音频（含919小时SRKW），远超DCLDE-2026等现有数据集；检测器在精度、能效和速度上均优于SOTA；SRKW检测特异性0–28.8%（95%敏感度）；多物种分类Top-1准确率42.1%，生态型分类Top-1准确率43.0%（DCLDE-2026）。

Conclusion: 本工作不仅提供了目前最大、最全面的SRKW声学数据集（CC-BY 4.0许可标注+原始授权音频），还验证了弱监督主动学习在稀疏标注生物声学大数据挖掘中的有效性，为濒危物种自动监测、栖息地分析与保护决策提供了关键数据与技术基础。

Abstract: This work presents the largest curation of Southern Resident Killer Whale (SRKW) acoustic data to date, also containing other marine mammals in their environment. We systematically search all available public archival hydrophone data within the SRKW habitat (over 30 years of audio data). The search consists of a weakly-supervised, positive-unlabelled, active learning strategy to identify all instances of marine mammals. The resulting transformer-based detectors outperform state-of-the-art detectors on the DEEPAL, DCLDE-2026, and two newly introduced expert-annotated datasets in terms of accuracy, energy efficiency, and speed. The detection model has a specificity of 0-28.8% at 95% sensitivity. Our multiclass species classifier obtains a top-1 accuracy of 42.1% (11 train classes, 4 test classes) and our ecotype classifier obtains a top-1 accuracy of 43.0% (4 train classes, 5 test classes) on the DCLDE-2026 dataset.
  We yield 919 hours of SRKW data, 230 hours of Bigg's orca data, 1374 hours of orca data from unlabelled ecotypes, 1501 hours of humpback data, 88 hours of sea lion data, 246 hours of pacific white-sided dolphin data, and over 784 hours of unspecified marine mammal data. This SRKW dataset is larger than DCLDE-2026, Ocean Networks Canada, and OrcaSound combined. The curated species labels are available under CC-BY 4.0 license, and the corresponding audio data are available under the licenses of the original owners. The comprehensive nature of this dataset makes it suitable for unsupervised machine translation, habitat usage surveys, and conservation endeavours for this critically endangered ecotype.

</details>


### [197] [The Laplacian Mechanism Improves Transformers by Reshaping Token Geometry](https://arxiv.org/abs/2602.09297)
*Yuchong Zhang,Vardan Papyan*

Main category: cs.LG

TL;DR: 本文提出了一种基于拉普拉斯机制的注意力修改方法，以更直接地控制token表示的方差，并验证其在视觉和语言任务中的一致性提升效果，同时通过多种几何分析工具证实该机制能促使token嵌入朝向最大可分性几何结构演化。


<details>
  <summary>Details</summary>
Motivation: Transformer通过注意力、残差连接和层归一化来控制token表示的方差，但作者认为需要更直接的方差控制机制以实现理想的token几何结构。

Method: 将注意力机制修改为拉普拉斯机制，并结合PCA、余弦相似度、方差分析和Neural Collapse指标等工具分析token表示的几何变化。

Result: 引入拉普拉斯机制后，在计算机视觉和自然语言处理多个基准上均取得一致性能提升；token嵌入呈现按类别坍缩、类中心满足Neural Collapse的几何特性。

Conclusion: 拉普拉斯机制能有效重塑token嵌入几何结构，使其趋向于最大可分性，从而提升模型性能并增强理论可解释性。

Abstract: Transformers leverage attention, the residual connection, and layer normalization to control the variance of token representations. We propose to modify attention into a Laplacian mechanism that gives the model more direct control over token variance. We conjecture that this helps transformers achieve the ideal token geometry. To investigate our conjecture, we first show that incorporating the Laplacian mechanism into transformers induces consistent improvements across benchmarks in computer vision and language. Next, we study how the Laplacian mechanism impacts the geometry of token representations using various tools: 1) principal component analysis, 2) cosine similarity metric, 3) analysis of variance, and 4) Neural Collapse metrics. Our investigation shows that the Laplacian mechanism reshapes token embeddings toward a geometry of maximal separability: tokens collapse according to their classes, and the class means exhibit Neural Collapse.

</details>


### [198] [Risk-sensitive reinforcement learning using expectiles, shortfall risk and optimized certainty equivalent risk](https://arxiv.org/abs/2602.09300)
*Sumedh Gupte,Shrey Rakeshkumar Patel,Soumen Pachal,Prashanth L. A.,Sanjay P. Bhat*

Main category: cs.LG

TL;DR: 本文提出了针对三种风险度量（期望分位数、基于效用的短缺风险和优化确定性等价风险）的风险敏感强化学习算法，推导了策略梯度定理，设计了梯度估计器并给出误差界，证明了目标函数的光滑性及算法收敛性，并通过实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法多关注期望回报，缺乏对不同风险偏好的建模能力；需为多种重要风险度量提供统一、可证收敛的风险敏感策略优化框架。

Method: 针对有限时域MDP，为三类风险度量分别推导策略梯度定理；构造无偏/渐近无偏梯度估计器；分析估计器的均方误差（O(1/m)）；证明风险敏感目标函数的光滑性；建立策略梯度算法的平稳点收敛速率界；开展基准实验验证。

Result: 获得三类风险度量下的策略梯度定理；提出具有O(1/m)均方误差界的梯度估计器；证明目标函数光滑性及算法收敛性；实验验证了理论结论的有效性。

Conclusion: 所提风险敏感策略梯度算法具备坚实的理论基础（梯度定理、误差界、收敛性），适用于多种主流风险度量，且在标准RL任务中表现有效，为鲁棒与安全强化学习提供了新工具。

Abstract: We propose risk-sensitive reinforcement learning algorithms catering to three families of risk measures, namely expectiles, utility-based shortfall risk and optimized certainty equivalent risk. For each risk measure, in the context of a finite horizon Markov decision process, we first derive a policy gradient theorem. Second, we propose estimators of the risk-sensitive policy gradient for each of the aforementioned risk measures, and establish $\mathcal{O}\left(1/m\right)$ mean-squared error bounds for our estimators, where $m$ is the number of trajectories. Further, under standard assumptions for policy gradient-type algorithms, we establish smoothness of the risk-sensitive objective, in turn leading to stationary convergence rate bounds for the overall risk-sensitive policy gradient algorithm that we propose. Finally, we conduct numerical experiments to validate the theoretical findings on popular RL benchmarks.

</details>


### [199] [Stabilizing Physics-Informed Consistency Models via Structure-Preserving Training](https://arxiv.org/abs/2602.09303)
*Che-Chia Chang,Chen-Yang Dai,Te-Sheng Lin,Ming-Chih Lai,Chieh-Hsin Lai*

Main category: cs.LG

TL;DR: 本文提出了一种物理信息驱动的一致性建模框架，用于通过快速、少步的生成式推理求解偏微分方程（PDE），通过两阶段训练和两步残差目标提升稳定性与精度。


<details>
  <summary>Details</summary>
Motivation: 解决物理约束一致性训练中PDE残差导致模型收敛至平凡或退化解、损害数据分布学习的稳定性问题。

Method: 提出结构保持的两阶段训练策略：先学习分布，再冻结系数解码器进行物理信息微调；并设计两步残差目标，在结构有效的生成轨迹上而非噪声单步预测上施加物理一致性约束。

Result: 实现了无条件生成与正向PDE求解的稳定高保真推理；正向解可通过基于投影的零样本修复方法获得，精度媲美扩散模型，计算成本降低数个数量级。

Conclusion: 该框架在保证物理一致性的前提下显著提升了生成式PDE求解的效率与稳定性，为科学机器学习提供了新范式。

Abstract: We propose a physics-informed consistency modeling framework for solving partial differential equations (PDEs) via fast, few-step generative inference. We identify a key stability challenge in physics-constrained consistency training, where PDE residuals can drive the model toward trivial or degenerate solutions, degrading the learned data distribution. To address this, we introduce a structure-preserving two-stage training strategy that decouples distribution learning from physics enforcement by freezing the coefficient decoder during physics-informed fine-tuning. We further propose a two-step residual objective that enforces physical consistency on refined, structurally valid generative trajectories rather than noisy single-step predictions. The resulting framework enables stable, high-fidelity inference for both unconditional generation and forward problems. We demonstrate that forward solutions can be obtained via a projection-based zero-shot inpainting procedure, achieving consistent accuracy of diffusion baselines with orders of magnitude reduction in computational cost.

</details>


### [200] [Statistical Roughness-Informed Machine Unlearning](https://arxiv.org/abs/2602.09304)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为SRAGU的机器遗忘算法，通过层间统计粗糙度（基于权重矩阵重尾谱诊断）自适应重分配遗忘更新，以提升深度网络在大规模或对抗性删除场景下的遗忘稳定性与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有近似遗忘方法在面对大规模或对抗性数据删除时容易失效，主要原因是现代深度网络各层表征存在显著异质性：部分层稳定且正则化良好，而另一些层则脆弱、欠训练或过拟合，导致简单更新分配引发灾难性遗忘或不稳定动态。

Method: 提出Statistical-Roughness Adaptive Gradient Unlearning (SRAGU)，首先基于Forget集计算AGU敏感度信号，再对每层权重矩阵进行WeightWatcher式重尾指数估计，映射为有界谱稳定性权重，并以此对AGU敏感度进行谱加权重分配，最后采用相同小批量更新形式执行遗忘。

Result: SRAGU在困难删除任务下显著提升了遗忘稳定性；实验通过行为对齐（预测差异、KL散度）和成员推断审计等指标验证其效果，显示其更接近从头在保留数据上重训练的黄金参考模型，且降低遗忘集信息泄露。

Conclusion: 层间谱稳定性是影响遗忘鲁棒性的关键因素，SRAGU通过机制驱动的统计粗糙度建模实现了更合理、更稳定的更新分配，为深度网络可信遗忘提供了新范式。

Abstract: Machine unlearning aims to remove the influence of a designated forget set from a trained model while preserving utility on the retained data. In modern deep networks, approximate unlearning frequently fails under large or adversarial deletions due to pronounced layer-wise heterogeneity: some layers exhibit stable, well-regularized representations while others are brittle, undertrained, or overfit, so naive update allocation can trigger catastrophic forgetting or unstable dynamics. We propose Statistical-Roughness Adaptive Gradient Unlearning (SRAGU), a mechanism-first unlearning algorithm that reallocates unlearning updates using layer-wise statistical roughness operationalized via heavy-tailed spectral diagnostics of layer weight matrices. Starting from an Adaptive Gradient Unlearning (AGU) sensitivity signal computed on the forget set, SRAGU estimates a WeightWatcher-style heavy-tailed exponent for each layer, maps it to a bounded spectral stability weight, and uses this stability signal to spectrally reweight the AGU sensitivities before applying the same minibatch update form. This concentrates unlearning motion in spectrally stable layers while damping updates in unstable or overfit layers, improving stability under hard deletions. We evaluate unlearning via behavioral alignment to a gold retrained reference model trained from scratch on the retained data, using empirical prediction-divergence and KL-to-gold proxies on a forget-focused query set; we additionally report membership inference auditing as a complementary leakage signal, treating forget-set points as should-be-forgotten members during evaluation.

</details>


### [201] [Reward Modeling for Reinforcement Learning-Based LLM Reasoning: Design, Challenges, and Evaluation](https://arxiv.org/abs/2602.09305)
*Pei-Chi Pan,Yingbin Liang,Sen Lin*

Main category: cs.LG

TL;DR: 本文提出Reasoning-Aligned Reinforcement Learning (RARL)框架，强调奖励建模对大语言模型推理能力对齐的核心作用，系统分类奖励机制、分析奖励黑客等失败模式，并批判现有评测基准的缺陷，为构建鲁棒、可验证、可信的推理模型提供基础路线图。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习微调是提升大语言模型推理能力的关键手段，但其效果严重依赖奖励设计；而当前对奖励建模与评估偏差、幻觉、分布偏移和高效学习等核心挑战之间关系的理解仍十分匮乏。

Method: 提出统一框架Reasoning-Aligned Reinforcement Learning (RARL)，系统化多步推理中的各类奖励范式；构建奖励机制分类法；分析奖励黑客作为典型失败模式；考察奖励信号如何统一刻画推理相关挑战（如推理时扩展、幻觉缓解）；批判性评估现有基准的数据污染与奖励错位问题。

Result: 揭示奖励建模并非实现细节，而是推理对齐的‘中心架构师’；建立奖励机制分类体系；识别并阐释奖励黑客的普遍性；阐明奖励设计与模型泛化性、可信性之间的深层关联；指出主流基准的系统性脆弱点。

Conclusion: 奖励设计是决定大语言模型推理质量的根本因素；RARL框架整合碎片化研究，厘清奖励与推理能力的内在联系，为构建鲁棒、可验证、可信的推理模型提供了理论基础与实践指南。

Abstract: Large Language Models (LLMs) demonstrate transformative potential, yet their reasoning remains inconsistent and unreliable. Reinforcement learning (RL)-based fine-tuning is a key mechanism for improvement, but its effectiveness is fundamentally governed by reward design. Despite its importance, the relationship between reward modeling and core LLM challenges--such as evaluation bias, hallucination, distribution shift, and efficient learning--remains poorly understood. This work argues that reward modeling is not merely an implementation detail but a central architect of reasoning alignment, shaping what models learn, how they generalize, and whether their outputs can be trusted. We introduce Reasoning-Aligned Reinforcement Learning (RARL), a unifying framework that systematizes diverse reward paradigms for multi-step reasoning. Within this framework, we present a taxonomy of reward mechanisms, analyze reward hacking as a pervasive failure mode, and examine how reward signals unify challenges ranging from inference-time scaling to hallucination mitigation. We further critically evaluate existing benchmarks, highlighting vulnerabilities such as data contamination and reward misalignment, and outline directions for more robust evaluation. By integrating fragmented research threads and clarifying the interplay between reward design and fundamental reasoning capabilities, this work provides a foundational roadmap for building reasoning models that are robust, verifiable, and trustworthy.

</details>


### [202] [Empowering Contrastive Federated Sequential Recommendation with LLMs](https://arxiv.org/abs/2602.09306)
*Thi Minh Chau Nguyen,Minh Hieu Nguyen,Duc Anh Nguyen,Xuan Huong Tran,Thanh Trung Huynh,Quoc Viet Hung Nguyen*

Main category: cs.LG

TL;DR: 本文提出LUMOS，一种利用本地大语言模型（LLM）生成多样化语义序列（未来导向轨迹、语义等价重述、偏好不一致反事实）以增强联邦序列推荐性能的新架构，在保护隐私的同时提升模型鲁棒性与效果。


<details>
  <summary>Details</summary>
Motivation: 现有联邦序列推荐方法受限于设备端数据碎片化、噪声大、同质化严重，手动数据增强或服务器端约束策略效果有限或开销高。

Method: 提出参数隔离的LUMOS架构，每个客户端私有调用轻量级本地LLM生成三类互补序列，并通过三视图对比学习在联邦主干网络中联合编码，不共享梯度或额外参数。

Result: 在三个公开基准上，LUMOS在HR@20和NDCG@20指标上持续超越集中式与联邦基线；在噪声与对抗环境下鲁棒性更强，且无需服务器端防护模块。

Conclusion: LLM驱动的本地语义生成可作为隐私保护联邦推荐的新范式，兼顾表现力、多样性与安全性。

Abstract: Federated sequential recommendation (FedSeqRec) aims to perform next-item prediction while keeping user data decentralised, yet model quality is frequently constrained by fragmented, noisy, and homogeneous interaction logs stored on individual devices. Many existing approaches attempt to compensate through manual data augmentation or additional server-side constraints, but these strategies either introduce limited semantic diversity or increase system overhead. To overcome these challenges, we propose \textbf{LUMOS}, a parameter-isolated FedSeqRec architecture that integrates large language models (LLMs) as \emph{local semantic generators}. Instead of sharing gradients or auxiliary parameters, LUMOS privately invokes an on-device LLM to construct three complementary sequence variants from each user history: (i) \emph{future-oriented} trajectories that infer plausible behavioural continuations, (ii) \emph{semantically equivalent rephrasings} that retain user intent while diversifying interaction patterns, and (iii) \emph{preference-inconsistent counterfactuals} that serve as informative negatives. These synthesized sequences are jointly encoded within the federated backbone through a tri-view contrastive optimisation scheme, enabling richer representation learning without exposing sensitive information. Experimental results across three public benchmarks show that LUMOS achieves consistent gains over competitive centralised and federated baselines on HR@20 and NDCG@20. In addition, the use of semantically grounded positive signals and counterfactual negatives improves robustness under noisy and adversarial environments, even without dedicated server-side protection modules. Overall, this work demonstrates the potential of LLM-driven semantic generation as a new paradigm for advancing privacy-preserving federated recommendation.

</details>


### [203] [Clarifying Shampoo: Adapting Spectral Descent to Stochasticity and the Parameter Trajectory](https://arxiv.org/abs/2602.09314)
*Runa Eschenhagen,Anna Cai,Tsung-Hsien Lee,Hao-Jun Michael Shi*

Main category: cs.LG

TL;DR: 本文通过实验比较了Shampoo和Muon两种矩阵结构优化器在语言模型上的数据效率，发现Shampoo在token效率上优于Muon，并揭示其优势源于对权重矩阵的特定更新方式，而非泛化的参数形状无关解释。


<details>
  <summary>Details</summary>
Motivation: 澄清Shampoo与Muon在一般设置下的关系及其相对数据效率尚不明确，尤其在控制条件下缺乏系统性对比。

Method: 在语言模型上开展大量实验，分析Shampoo与Muon的token效率；对Shampoo更新进行数学分解，揭示其与Muon更新的关系；提出‘时间平均半正交’的新解释视角。

Result: Shampoo在token效率上高于Muon，其优势完全来自对权重矩阵的应用；Shampoo更新可分解为适配后的Muon更新；其本质是时间平均意义下的半正交更新，而非严格的谱下降。

Conclusion: Shampoo的优势依赖于参数的矩阵结构，挑战了忽略形状的通用解释；新提出的‘时间平均半正交’视角更准确地刻画了其行为，并规避了方差自适应和白化等解释的缺陷。

Abstract: Optimizers leveraging the matrix structure in neural networks, such as Shampoo and Muon, are more data-efficient than element-wise algorithms like Adam and Signum. While in specific settings, Shampoo and Muon reduce to spectral descent analogous to how Adam and Signum reduce to sign descent, their general relationship and relative data efficiency under controlled settings remain unclear. Through extensive experiments on language models, we demonstrate that Shampoo achieves higher token efficiency than Muon, mirroring Adam's advantage over Signum. We show that Shampoo's update applied to weight matrices can be decomposed into an adapted Muon update. Consistent with this, Shampoo's benefits can be exclusively attributed to its application to weight matrices, challenging interpretations agnostic to parameter shapes. This admits a new perspective that also avoids shortcomings of related interpretations based on variance adaptation and whitening: rather than enforcing semi-orthogonality as in spectral descent, Shampoo's updates are time-averaged semi-orthogonal in expectation.

</details>


### [204] [Effective MoE-based LLM Compression by Exploiting Heterogeneous Inter-Group Experts Routing Frequency and Information Density](https://arxiv.org/abs/2602.09316)
*Zhendong Mi,Yixiao Chen,Pu Zhao,Xiaodong Yu,Hao Wang,Yanzhi Wang,Shaoyi Huang*

Main category: cs.LG

TL;DR: 本文提出RFID-MoE框架，通过联合考虑专家路由频率与信息密度实现异构化低秩压缩，并引入稀疏投影重建压缩残差，在保持参数量显著降低的同时大幅提升MoE大模型的压缩后性能。


<details>
  <summary>Details</summary>
Motivation: MoE大模型因存储多个专家网络导致内存开销巨大，而现有SVD压缩方法多采用统一秩分配或仅依赖静态权重特性，忽略了专家间在路由频率和信息密度上的显著异质性。

Method: 提出RFID-MoE：1）设计融合专家激活频率与有效秩的综合重要性度量，实现预算约束下的自适应异构秩分配；2）利用参数高效的稀疏投影机制重建SVD压缩残差，恢复丢失信息。

Result: 在Qwen3-30B和DeepSeekMoE等模型上验证，60%压缩比下PTB困惑度降至16.92（较基线降低超8.0），HellaSwag零样本准确率提升约8%，显著优于MoBE、D2-MoE等SOTA方法。

Conclusion: 专家异质性是MoE压缩的关键因素，RFID-MoE通过动态重要性评估与残差重建，在大幅压缩的同时有效保持甚至提升模型性能，为MoE模型高效部署提供了新范式。

Abstract: Mixture-of-Experts (MoE) based Large Language Models (LLMs) have achieved superior performance, yet the massive memory overhead caused by storing multiple expert networks severely hinders their practical deployment. Singular Value Decomposition (SVD)-based compression has emerged as a promising post-training technique; however, most existing methods apply uniform rank allocation or rely solely on static weight properties. This overlooks the substantial heterogeneity in expert utilization observed in MoE models, where frequent routing patterns and intrinsic information density vary significantly across experts. In this work, we propose RFID-MoE, an effective framework for MoE compression by exploiting heterogeneous Routing Frequency and Information Density. We first introduce a fused metric that combines expert activation frequency with effective rank to measure expert importance, adaptively allocating higher ranks to critical expert groups under a fixed budget. Moreover, instead of discarding compression residuals, we reconstruct them via a parameter-efficient sparse projection mechanism to recover lost information with minimal parameter overhead. Extensive experiments on representative MoE LLMs (e.g., Qwen3, DeepSeekMoE) across multiple compression ratios demonstrate that RFID-MoE consistently outperforms state-of-the-art methods like MoBE and D2-MoE. Notably, RFID-MoE achieves a perplexity of 16.92 on PTB with the Qwen3-30B model at a 60% compression ratio, reducing perplexity by over 8.0 compared to baselines, and improves zero-shot accuracy on HellaSwag by approximately 8%.

</details>


### [205] [SnareNet: Flexible Repair Layers for Neural Networks with Hard Constraints](https://arxiv.org/abs/2602.09317)
*Ya-Chi Chu,Alkiviades Boukas,Madeleine Udell*

Main category: cs.LG

TL;DR: SnareNet是一种新型神经网络架构，通过添加可微修复层和自适应松弛机制，确保输出满足输入依赖的非线性约束，在优化学习与轨迹规划任务中兼顾目标性能与约束可行性。


<details>
  <summary>Details</summary>
Motivation: 神经网络作为代理求解器或控制策略时，其无约束预测可能违反物理、运行或安全要求，亟需一种能保证输出可行性的方法。

Method: 提出SnareNet架构，包含一个在约束映射值域内导航的可微修复层，并引入自适应松弛机制：训练初期使用宽松可行集‘捕获’网络输出，逐步收缩至严格可行集以稳定端到端训练。

Result: 在优化学习与轨迹规划基准测试中，SnareNet在满足约束的可靠性上优于先前方法，同时提升了目标函数质量。

Conclusion: SnareNet为受约束学习任务提供了一种通用、可微、端到端可训练的可行性控制框架，兼顾约束满足与性能优化。

Abstract: Neural networks are increasingly used as surrogate solvers and control policies, but unconstrained predictions can violate physical, operational, or safety requirements. We propose SnareNet, a feasibility-controlled architecture for learning mappings whose outputs must satisfy input-dependent nonlinear constraints. SnareNet appends a differentiable repair layer that navigates in the constraint map's range space, steering iterates toward feasibility and producing a repaired output that satisfies constraints to a user-specified tolerance. To stabilize end-to-end training, we introduce adaptive relaxation, which designs a relaxed feasible set that snares the neural network at initialization and shrinks it into the feasible set, enabling early exploration and strict feasibility later in training. On optimization-learning and trajectory planning benchmarks, SnareNet consistently attains improved objective quality while satisfying constraints more reliably than prior work.

</details>


### [206] [Priority-Aware Shapley Value](https://arxiv.org/abs/2602.09326)
*Kiljae Lee,Ziqi Liu,Weijing Tang,Yuan Zhang*

Main category: cs.LG

TL;DR: 本文提出了优先感知Shapley值（PASV），通过引入硬性优先约束和软性贡献者特定优先权重，改进了传统Shapley值在处理依赖性贡献者或需按信任/风险调整贡献时的局限性；该方法具有公理化唯一性、可扩展采样算法，并在数据估值与特征归因任务中验证了其结构保真性和实用性。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值隐含假设贡献者可互换，难以应对数据依赖（如增强/复用数据）、因果特征顺序或需按信任/风险调整贡献等现实场景。

Method: 提出Priority-Aware Shapley Value（PASV），融合硬性前序约束与软性贡献者优先权重；设计基于邻接交换的Metropolis-Hastings采样器实现高效蒙特卡洛估计；并分析极端权重下的渐近行为。

Result: PASV适用于一般前序结构，可退化为纯前序或纯权重Shapley变体；满足自然公理且唯一；实验表明其在MNIST/CIFAR10数据估值与Census Income特征归因中分配更符合结构，并支持‘优先级扫描’敏感性分析。

Conclusion: PASV为Shapley框架提供了更灵活、现实的推广，兼顾依赖建模与贡献调节能力，兼具理论严谨性与实际可扩展性。

Abstract: Shapley values are widely used for model-agnostic data valuation and feature attribution, yet they implicitly assume contributors are interchangeable. This can be problematic when contributors are dependent (e.g., reused/augmented data or causal feature orderings) or when contributions should be adjusted by factors such as trust or risk. We propose Priority-Aware Shapley Value (PASV), which incorporates both hard precedence constraints and soft, contributor-specific priority weights. PASV is applicable to general precedence structures, recovers precedence-only and weight-only Shapley variants as special cases, and is uniquely characterized by natural axioms. We develop an efficient adjacent-swap Metropolis-Hastings sampler for scalable Monte Carlo estimation and analyze limiting regimes induced by extreme priority weights. Experiments on data valuation (MNIST/CIFAR10) and feature attribution (Census Income) demonstrate more structure-faithful allocations and a practical sensitivity analysis via our proposed "priority sweeping".

</details>


### [207] [In-Hospital Stroke Prediction from PPG-Derived Hemodynamic Features](https://arxiv.org/abs/2602.09328)
*Jiaming Liu,Cheng Ding,Daoqiang Zhang*

Main category: cs.LG

TL;DR: 本文利用住院患者中突发脑卒中的罕见场景，首次大规模分析了发病前的PPG信号，构建了基于ResNet-1D的早期预测模型，在MIMIC-III和MC-MED数据集上实现了高F1-score的多时间窗预测，证明PPG具有数小时前预测脑卒中的潜力。


<details>
  <summary>Details</summary>
Motivation: 标准临床数据缺乏院前生理数据，限制了脑卒中早期预测；PPG等连续监测信号的预测价值尚未验证。

Method: 构建LLM辅助的数据挖掘流程，从非结构化临床笔记中提取并经医生验证的脑卒中发生时间戳；在MIMIC-III和MC-MED中识别出共334例高质量同步PPG数据；提取PPG血流动力学特征，采用ResNet-1D模型进行多时间窗（4/5/6小时）预测。

Result: 模型在MIMIC-III上4/5/6小时前F1-score达0.7956/0.8759/0.9406；在MC-MED上（未调参）达0.9256/0.9595/0.9888；首次提供真实世界PPG可预测脑卒中的实证。

Conclusion: PPG信号蕴含脑卒中发生前数小时的预测信息，支持从事件后识别转向基于生理信号的主动预警，有望改善临床预后。

Abstract: The absence of pre-hospital physiological data in standard clinical datasets fundamentally constrains the early prediction of stroke, as patients typically present only after stroke has occurred, leaving the predictive value of continuous monitoring signals such as photoplethysmography (PPG) unvalidated. In this work, we overcome this limitation by focusing on a rare but clinically critical cohort - patients who suffered stroke during hospitalization while already under continuous monitoring - thereby enabling the first large-scale analysis of pre-stroke PPG waveforms aligned to verified onset times. Using MIMIC-III and MC-MED, we develop an LLM-assisted data mining pipeline to extract precise in-hospital stroke onset timestamps from unstructured clinical notes, followed by physician validation, identifying 176 patients (MIMIC) and 158 patients (MC-MED) with high-quality synchronized pre-onset PPG data, respectively. We then extract hemodynamic features from PPG and employ a ResNet-1D model to predict impending stroke across multiple early-warning horizons. The model achieves F1-scores of 0.7956, 0.8759, and 0.9406 at 4, 5, and 6 hours prior to onset on MIMIC-III, and, without re-tuning, reaches 0.9256, 0.9595, and 0.9888 on MC-MED for the same horizons. These results provide the first empirical evidence from real-world clinical data that PPG contains predictive signatures of stroke several hours before onset, demonstrating that passively acquired physiological signals can support reliable early warning, supporting a shift from post-event stroke recognition to proactive, physiology-based surveillance that may materially improve patient outcomes in routine clinical care.

</details>


### [208] [MacrOData: New Benchmarks of Thousands of Datasets for Tabular Outlier Detection](https://arxiv.org/abs/2602.09329)
*Xueying Ding,Simon Klüttermann,Haomin Wen,Yilong Chen,Leman Akoglu*

Main category: cs.LG

TL;DR: 本文介绍了MacrOData，一个大规模、多样化的表格异常检测（OD）基准套件，包含三个子基准：OddBench（790个含语义异常的真实数据集）、OvrBench（856个含统计异常的真实数据集）和SynBench（800个合成数据集），总计2446个数据集，旨在解决现有基准（如AdBench仅含57个数据集）规模小、多样性不足的问题，并提供标准化划分、语义标注与公开排行榜。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测基准（如AdBench）规模过小（仅57个数据集），缺乏多样性与统计效力，难以支撑对方法的全面、稳健评估；亟需构建更大规模、更富多样性、更具实用价值的基准套件。

Method: 构建MacrOData基准套件，包含三个独立但互补的子基准：OddBench（真实语义异常）、OvrBench（真实统计异常）和SynBench（可控生成的合成异常），并统一提供标准化训练/测试划分、公/私分区设计（私有部分用于在线排行榜）、语义元数据标注；同时对大量OD方法（经典、深度、基础模型）在全基准上进行系统性实验评估。

Result: MacrOData共涵盖2446个高质量数据集，显著超越现有基准规模；实验证明其能揭示不同OD方法在语义/统计/合成场景下的性能差异，提供可复现的基线结果、实用调参指南与性能参考；全部数据与 leaderboard 开源发布。

Conclusion: MacrOData是首个兼具大规模、真实性、语义可解释性与评估严谨性的表格异常检测基准，为该领域提供了坚实、可持续的评估基础设施，有望推动方法创新与实践落地。

Abstract: Quality benchmarks are essential for fairly and accurately tracking scientific progress and enabling practitioners to make informed methodological choices. Outlier detection (OD) on tabular data underpins numerous real-world applications, yet existing OD benchmarks remain limited. The prominent OD benchmark AdBench is the de facto standard in the literature, yet comprises only 57 datasets. In addition to other shortcomings discussed in this work, its small scale severely restricts diversity and statistical power. We introduce MacrOData, a large-scale benchmark suite for tabular OD comprising three carefully curated components: OddBench, with 790 datasets containing real-world semantic anomalies; OvrBench, with 856 datasets featuring real-world statistical outliers; and SynBench, with 800 synthetically generated datasets spanning diverse data priors and outlier archetypes. Owing to its scale and diversity, MacrOData enables comprehensive and statistically robust evaluation of tabular OD methods. Our benchmarks further satisfy several key desiderata: We provide standardized train/test splits for all datasets, public/private benchmark partitions with held-out test labels for the latter reserved toward an online leaderboard, and annotate our datasets with semantic metadata. We conduct extensive experiments across all benchmarks, evaluating a broad range of OD methods comprising classical, deep, and foundation models, over diverse hyperparameter configurations. We report detailed empirical findings, practical guidelines, as well as individual performances as references for future research. All benchmarks containing 2,446 datasets combined are open-sourced, along with a publicly accessible leaderboard hosted at https://huggingface.co/MacrOData-CMU.

</details>


### [209] [Large Language Models for Designing Participatory Budgeting Rules](https://arxiv.org/abs/2602.09349)
*Nguyen Thach,Xingchen Sha,Hau Chan*

Main category: cs.LG

TL;DR: 本文提出LLMRule框架，利用大语言模型（LLM）结合进化搜索自动设计参与式预算分配规则，在真实世界PB数据集上验证其在效用方面优于人工设计规则，同时保持相近的公平性。


<details>
  <summary>Details</summary>
Motivation: 参与式预算（PB）中效用与公平性目标难以兼顾，且依赖大量领域知识；而大语言模型在算法自动生成方面展现出潜力，且PB规则与背包问题算法高度相似，为LLM辅助设计提供了契机。

Method: 提出LLMRule框架，将大语言模型嵌入进化搜索流程，自动化生成满足预算约束的PB分配规则，并在多国真实PB数据（600+实例）上，基于不同偏好表示进行评估。

Result: LLM生成的规则在总体效用上普遍优于现有手工设计规则，同时公平性水平相当。

Conclusion: LLM结合进化搜索可有效缓解PB中效用与公平性的权衡难题，为自动化社会选择规则设计提供了新范式。

Abstract: Participatory budgeting (PB) is a democratic paradigm for deciding the funding of public projects given the residents' preferences, which has been adopted in numerous cities across the world. The main focus of PB is designing rules, functions that return feasible budget allocations for a set of projects subject to some budget constraint. Designing PB rules that optimize both utility and fairness objectives based on agent preferences had been challenging due to the extensive domain knowledge required and the proven trade-off between the two notions. Recently, large language models (LLMs) have been increasingly employed for automated algorithmic design. Given the resemblance of PB rules to algorithms for classical knapsack problems, in this paper, we introduce a novel framework, named LLMRule, that addresses the limitations of existing works by incorporating LLMs into an evolutionary search procedure for automating the design of PB rules. Our experimental results, evaluated on more than 600 real-world PB instances obtained from the U.S., Canada, Poland, and the Netherlands with different representations of agent preferences, demonstrate that the LLM-generated rules generally outperform existing handcrafted rules in terms of overall utility while still maintaining a similar degree of fairness.

</details>


### [210] [Latent Poincaré Shaping for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.09375)
*Hanchen Xia,Baoyou Chen,Zelin Zang,Yutang Ge,Guojiang Zhao,Siyu Zhu*

Main category: cs.LG

TL;DR: LaPha是一种在庞加莱空间中训练AlphaZero风格大语言模型代理的方法，利用双曲几何特性提升推理能力，并在多个数学基准测试中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统LLM推理方法在搜索空间扩展和过程奖励稀疏性方面存在局限，而双曲空间的负曲率特性可提供指数级增长的容量，有望提升推理效率与准确性。

Method: LaPha将搜索过程建模为以提示为根、从庞加莱球原点向外生长的树；使用双曲测地距离衡量规则验证正确性，定义节点势能并基于势差分配密集过程奖励；同时在共享潜空间上附加轻量值头，支持自引导测试时缩放。

Result: 在MATH-500上，LaPha将Qwen2.5-Math-1.5B准确率从66.0%提升至88.2%；在AIME'24上，LaPha-1.5B达56.7%，LaPha-7B达60.0%；在AIME'25上，LaPha-7B达53.3%。

Conclusion: LaPha通过引入庞加莱潜空间与双曲几何机制，有效增强了LLM的数学推理能力，且具备低开销、可扩展的测试时搜索优势。

Abstract: We propose LaPha, a method for training AlphaZero-like LLM agents in a Poincaré latent space. Under LaPha, the search process can be visualized as a tree rooted at the prompt and growing outward from the origin toward the boundary of the Poincaré ball, where negative curvature provides exponentially increasing capacity with radius. Using hyperbolic geodesic distance to rule-verified correctness, we define a node potential and assign dense process rewards by potential differences. We further attach a lightweight value head on the same shared latent space, enabling self-guided test-time scaling with almost no additional overhead. On MATH-500, LaPha improves Qwen2.5-Math-1.5B from 66.0% to 88.2%. With value-head-guided search, LaPha-1.5B reaches 56.7% accuracy on AIME'24, and LaPha-7B further achieves 60.0% on AIME'24 and 53.3% on AIME'25.

</details>


### [211] [Sparse Layer Sharpness-Aware Minimization for Efficient Fine-Tuning](https://arxiv.org/abs/2602.09395)
*Yifei Cheng,Xianglin Yang,Guoxia Wang,Chao Huang,Fei Ma,Dianhai Yu,Xiaochun Cao,Li Shen*

Main category: cs.LG

TL;DR: 本文提出SL-SAM，通过将层选择建模为多臂赌博机问题，在SAM中稀疏化参与梯度上升（扰动）和下降（更新）的层，显著降低计算开销，同时保持甚至提升泛化性能。


<details>
  <summary>Details</summary>
Motivation: SAM虽能提升泛化性，但其参数扰动步骤使计算成本翻倍，成为实际应用瓶颈。

Method: 提出SL-SAM：基于梯度范数动态选择部分层参与扰动与更新，并将该选择建模为多臂赌博机问题；理论分析保证收敛性。

Result: 在多个微调任务（尤其大语言模型）中达到SOTA性能（LLM微调排名第一）；反向传播激活参数比例大幅下降（视觉/中等/大语言模型分别为47%/22%/21%，而SAM为100%）。

Conclusion: SL-SAM在不牺牲性能前提下显著提升SAM计算效率，验证了层稀疏化策略的有效性与实用性。

Abstract: Sharpness-aware minimization (SAM) seeks the minima with a flat loss landscape to improve the generalization performance in machine learning tasks, including fine-tuning. However, its extra parameter perturbation step doubles the computation cost, which becomes the bottleneck of SAM in the practical implementation. In this work, we propose an approach SL-SAM to break this bottleneck by introducing the sparse technique to layers. Our key innovation is to frame the dynamic selection of layers for both the gradient ascent (perturbation) and descent (update) steps as a multi-armed bandit problem. At the beginning of each iteration, SL-SAM samples a part of the layers of the model according to the gradient norm to participate in the backpropagation of the following parameter perturbation and update steps, thereby reducing the computation complexity. We then provide the analysis to guarantee the convergence of SL-SAM. In the experiments of fine-tuning models in several tasks, SL-SAM achieves the performances comparable to the state-of-the-art baselines, including a \#1 rank on LLM fine-tuning. Meanwhile, SL-SAM significantly reduces the ratio of active parameters in backpropagation compared to vanilla SAM (SL-SAM activates 47\%, 22\% and 21\% parameters on the vision, moderate and large language model respectively while vanilla SAM always activates 100\%), verifying the efficiency of our proposed algorithm.

</details>


### [212] [Squeezing More from the Stream : Learning Representation Online for Streaming Reinforcement Learning](https://arxiv.org/abs/2602.09396)
*Nilaksh,Antoine Clavaud,Mathieu Reymond,François Rivest,Sarath Chandar*

Main category: cs.LG

TL;DR: 本文提出将自预测表示（SPR）扩展到流式强化学习中，通过正交梯度更新解决流式数据相关性导致的训练不稳定问题，显著提升了样本效率和表征质量。


<details>
  <summary>Details</summary>
Motivation: 流式强化学习中数据即用即弃，导致基于值的损失难以从瞬态数据中提取有意义的表征，样本效率低下。

Method: 将自预测表示（SPR）引入流式RL框架，并设计正交梯度更新机制以缓解因高相关样本和流式优化器引发的梯度冲突。

Result: 在Atari、MinAtar和Octax基准上系统性超越现有流式基线；潜空间分析（如t-SNE和有效秩）证实其学习到更丰富的表征，弥补了无回放缓冲区带来的性能差距。

Conclusion: 所提方法在保持低资源消耗（仅需数个CPU核心）的同时，显著提升流式RL的表征能力和样本效率，为边缘设备上的在线学习提供了可行方案。

Abstract: In streaming Reinforcement Learning (RL), transitions are observed and discarded immediately after a single update. While this minimizes resource usage for on-device applications, it makes agents notoriously sample-inefficient, since value-based losses alone struggle to extract meaningful representations from transient data. We propose extending Self-Predictive Representations (SPR) to the streaming pipeline to maximize the utility of every observed frame. However, due to the highly correlated samples induced by the streaming regime, naively applying this auxiliary loss results in training instabilities. Thus, we introduce orthogonal gradient updates relative to the momentum target and resolve gradient conflicts arising from streaming-specific optimizers. Validated across the Atari, MinAtar, and Octax suites, our approach systematically outperforms existing streaming baselines. Latent-space analysis, including t-SNE visualizations and effective-rank measurements, confirms that our method learns significantly richer representations, bridging the performance gap caused by the absence of a replay buffer, while remaining efficient enough to train on just a few CPU cores.

</details>


### [213] [Learning with Multiple Correct Answers -- A Trichotomy of Regret Bounds under Different Feedback Models](https://arxiv.org/abs/2602.09402)
*Alireza F. Pour,Farnam Mansouri,Shai Ben-David*

Main category: cs.LG

TL;DR: 本文研究了具有多个正确答案的在线学习问题，特别是在语言生成任务中，每个输入可能有多个可接受的输出，但并非所有输出都合适。文章在三种反馈模型下分析了该问题，并在现实可实现和不可实现（agnostic）设定下分别给出了最优错误界和遗憾界，并推导出批量学习下的样本复杂度界。


<details>
  <summary>Details</summary>
Motivation: 受语言生成任务启发，其中同一提示可能有多个可接受的补全，但并非所有补全都合理，因此需要建模具有多标签正确答案的在线学习场景。

Method: 通过定义适配各反馈模型的组合维度（combinatorial dimension），在现实可实现设定下刻画最优错误界；在不可实现设定下，分析并证明三种模型的遗憾界呈现三重分类（trichotomy）；进一步将结果推广至批量学习，得出依赖于对应组合维度的样本复杂度界。

Result: 在现实可实现设定下，每种反馈模型均有精确的最优错误界；在不可实现设定下，三种模型展现出截然不同的遗憾增长阶（常数、对数、平方根）；批量学习的样本复杂度由对应组合维度决定。

Conclusion: 本文系统建立了多正确答案在线学习的理论框架，揭示了反馈模型对学习难度的根本影响，并统一刻画了现实与不可实现设定下的性能极限。

Abstract: We study an online learning problem with multiple correct answers, where each instance admits a set of valid labels, and in each round the learner must output a valid label for the queried example. This setting is motivated by language generation tasks, in which a prompt may admit many acceptable completions, but not every completion is acceptable. We study this problem under three feedback models. For each model, we characterize the optimal mistake bound in the realizable setting using an appropriate combinatorial dimension. We then establish a trichotomy of regret bounds across the three models in the agnostic setting. Our results also imply sample complexity bounds for the batch setup that depend on the respective combinatorial dimensions.

</details>


### [214] [Reward-Guided Discrete Diffusion via Clean-Sample Markov Chain for Molecule and Biological Sequence Design](https://arxiv.org/abs/2602.09424)
*Prin Phunyaphibarn,Minhyuk Sung*

Main category: cs.LG

TL;DR: 本文提出Clean-Sample Markov Chain (CSMC)采样器，用于离散扩散模型的奖励引导生成，避免依赖噪声大的中间奖励，通过Metropolis-Hastings构建清洁样本马尔可夫链，实现更优的分子与生物序列生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于中间奖励引导的离散扩散模型在化学与生物学领域表现不佳，因科学领域中奖励函数非光滑导致中间奖励噪声大。

Method: 提出CSMC采样器，利用Metropolis-Hastings算法构建以目标分布为平稳分布的清洁样本马尔可夫链；设计结合前向与反向扩散过程的提议分布，使接受概率可解。

Result: 在多种奖励函数下的分子和生物序列生成实验中，CSMC持续优于依赖中间奖励的已有方法。

Conclusion: CSMC提供了一种不依赖中间奖励的有效测试时奖励引导采样方法，提升了离散扩散模型在科学生成任务中的性能。

Abstract: Discrete diffusion models have recently emerged as a powerful class of generative models for chemistry and biology data. In these fields, the goal is to generate various samples with high rewards (e.g., drug-likeness in molecules), making reward-based guidance crucial. Most existing methods are based on guiding the diffusion model using intermediate rewards but tend to underperform since intermediate rewards are noisy due to the non-smooth nature of reward functions used in scientific domains. To address this, we propose Clean-Sample Markov Chain (CSMC) Sampler, a method that performs effective test-time reward-guided sampling for discrete diffusion models, enabling local search without relying on intermediate rewards. CSMC constructs a Markov chain of clean samples using the Metropolis-Hastings algorithm such that its stationary distribution is the target distribution. We design a proposal distribution by sequentially applying the forward and backward diffusion processes, making the acceptance probability tractable. Experiments on molecule and biological sequence generation with various reward functions demonstrate that our method consistently outperforms prior approaches that rely on intermediate rewards.

</details>


### [215] [Diffusion-Guided Pretraining for Brain Graph Foundation Models](https://arxiv.org/abs/2602.09437)
*Xinxu Wei,Rong Zhou,Lifang He,Yu Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的脑图预训练框架，通过结构感知的掩码策略和拓扑感知的读出与重建机制，提升脑信号表征学习的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有脑图对比学习和掩码自编码方法依赖随机掩码，破坏语义连通性；图级读出和重建方式难以捕获全局结构信息。

Method: 提出统一的扩散驱动预训练框架：1）利用扩散过程指导结构感知的节点/边掩码与丢弃；2）借助扩散建模实现拓扑感知的图级读出与节点级全局重建。

Result: 在涵盖25,000多名被试、60,000多次扫描、多种精神障碍与脑图谱的多个神经影像数据集上，性能持续提升。

Conclusion: 扩散模型可有效建模脑图的复杂拓扑结构，为脑信号基础模型提供更鲁棒、更具语义一致性的预训练范式。

Abstract: With the growing interest in foundation models for brain signals, graph-based pretraining has emerged as a promising paradigm for learning transferable representations from connectome data. However, existing contrastive and masked autoencoder methods typically rely on naive random dropping or masking for augmentation, which is ill-suited for brain graphs and hypergraphs as it disrupts semantically meaningful connectivity patterns. Moreover, commonly used graph-level readout and reconstruction schemes fail to capture global structural information, limiting the robustness of learned representations. In this work, we propose a unified diffusion-based pretraining framework that addresses both limitations. First, diffusion is designed to guide structure-aware dropping and masking strategies, preserving brain graph semantics while maintaining effective pretraining diversity. Second, diffusion enables topology-aware graph-level readout and node-level global reconstruction by allowing graph embeddings and masked nodes to aggregate information from globally related regions. Extensive experiments across multiple neuroimaging datasets with over 25,000 subjects and 60,000 scans involving various mental disorders and brain atlases demonstrate consistent performance improvements.

</details>


### [216] [Taming the Monster Every Context: Complexity Measure and Unified Framework for Offline-Oracle Efficient Contextual Bandits](https://arxiv.org/abs/2602.09456)
*Hao Qin,Chicheng Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Offline Estimation to Decisions (OE2D)的算法框架，将上下文赌博机学习（含通用奖励函数逼近）归约为离线回归问题，在大动作空间下实现近最优遗憾，并通过新定义的Decision-Offline Estimation Coefficient (DOEC)刻画其复杂度，建立了与DEC的理论联系。


<details>
  <summary>Details</summary>
Motivation: 解决上下文赌博机中大规模动作空间下的高效学习问题，降低对在线交互的依赖，提升离线回归方法在在线决策中的适用性。

Method: 提出OE2D框架，采用‘exploitative F-design’动作分布策略，在探索与利用间取得平衡；引入新的复杂度度量DOEC，并分析其在Eluder维数有界和光滑遗憾场景下的有界性。

Result: 实现了O(log T)次离线回归调用下的近最优遗憾，当T已知时可降至O(log log T)；证明了DOEC在多种设定下有界，并建立了DOEC与DEC的理论联系。

Conclusion: OE2D为连接离线估计与在线决策提供了统一框架，拓展了oracle-efficient contextual bandit算法的设计原理，推动了上下文赌博机理论与实践的发展。

Abstract: We propose an algorithmic framework, Offline Estimation to Decisions (OE2D), that reduces contextual bandit learning with general reward function approximation to offline regression. The framework allows near-optimal regret for contextual bandits with large action spaces with $O(log(T))$ calls to an offline regression oracle over $T$ rounds, and makes $O(loglog(T))$ calls when $T$ is known. The design of OE2D algorithm generalizes Falcon~\citep{simchi2022bypassing} and its linear reward version~\citep[][Section 4]{xu2020upper} in that it chooses an action distribution that we term ``exploitative F-design'' that simultaneously guarantees low regret and good coverage that trades off exploration and exploitation. Central to our regret analysis is a new complexity measure, the Decision-Offline Estimation Coefficient (DOEC), which we show is bounded in bounded Eluder dimension per-context and smoothed regret settings. We also establish a relationship between DOEC and Decision Estimation Coefficient (DEC)~\citep{foster2021statistical}, bridging the design principles of offline- and online-oracle efficient contextual bandit algorithms for the first time.

</details>


### [217] [Scalable and Reliable State-Aware Inference of High-Impact N-k Contingencies](https://arxiv.org/abs/2602.09461)
*Lihao Mai,Chenhan Xiao,Yang Weng*

Main category: cs.LG

TL;DR: 本文提出了一种基于条件扩散模型和图神经网络的可扩展、状态感知的N-k故障推断框架，无需穷举组合即可生成高影响故障场景，并提供可控的严重故障覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 随着逆变器资源、柔性负荷增加及运行工况快速变化，传统N-k故障评估计算成本过高，现有启发式筛选方法缺乏理论保障，难以确保不遗漏关键故障。

Method: 采用条件扩散模型根据当前运行状态生成候选故障；利用仅基于基态和N-1故障训练的拓扑感知图神经网络离线构建高风险样本；并设计机制以在有限AC潮流评估预算下提供严重故障的可控覆盖保证。

Result: 在IEEE标准系统上的实验表明，在相同评估预算下，该方法比均匀采样更稳定地评估更高严重度的故障，从而以更低计算代价更可靠地识别关键故障。

Conclusion: 所提框架显著提升了N-k安全评估的效率与可靠性，为实际电网运行提供了具备理论保障的轻量级高风险故障筛选新范式。

Abstract: Increasing penetration of inverter-based resources, flexible loads, and rapidly changing operating conditions make higher-order $N\!-\!k$ contingency assessment increasingly important but computationally prohibitive. Exhaustive evaluation of all outage combinations using AC power-flow or ACOPF is infeasible in routine operation. This fact forces operators to rely on heuristic screening methods whose ability to consistently retain all critical contingencies is not formally established. This paper proposes a scalable, state-aware contingency inference framework designed to directly generate high-impact $N\!-\!k$ outage scenarios without enumerating the combinatorial contingency space. The framework employs a conditional diffusion model to produce candidate contingencies tailored to the current operating state, while a topology-aware graph neural network trained only on base and $N\!-\!1$ cases efficiently constructs high-risk training samples offline. Finally, the framework is developed to provide controllable coverage guarantees for severe contingencies, allowing operators to explicitly manage the risk of missing critical events under limited AC power-flow evaluation budgets. Experiments on IEEE benchmark systems show that, for a given evaluation budget, the proposed approach consistently evaluates higher-severity contingencies than uniform sampling. This allows critical outages to be identified more reliably with reduced computational effort.

</details>


### [218] [Online Learning in MDPs with Partially Adversarial Transitions and Losses](https://arxiv.org/abs/2602.09474)
*Ofir Schlisselberg,Tal Lancewicki,Yishay Mansour*

Main category: cs.LG

TL;DR: 本文研究了在大部分时间是随机但某些步骤可能为对抗性转移的MDP中的强化学习问题，提出了条件占据度量，并设计了两种算法以应对不同场景下的对抗性转移，同时分析了完全对抗性设置下的后悔界。


<details>
  <summary>Details</summary>
Motivation: 现实环境中存在一些脆弱点，使得MDP的转移函数在多数步骤稳定但在少数步骤可能呈现对抗性；需要设计对这类混合环境鲁棒的学习算法。

Method: 引入‘条件占据度量’以保持跨episode稳定性，并基于此设计两种算法：一种适用于任意位置的Λ个对抗性步骤，另一种假设这些步骤连续；还提出无需先验知晓对抗步骤位置的K^{2/3}-regret reduction方法；并系统分析全对抗（Λ=H−1）情形下全信息与bandit反馈的后悔界。

Result: 第一种算法获得 regret Õ(H S^Λ √(K S A^{Λ+1}))；第二种在对抗步骤连续时改进为 Õ(H √(K S^3 A^{Λ+1}))；还实现了无需知道对抗步骤位置的 K^{2/3} regret reduction；并对全对抗MDP给出了几乎匹配的上下界。

Conclusion: 条件占据度量是一种有效刻画混合随机-对抗MDP结构的工具，所提算法在多种设定下达到较优后悔界，且理论分析厘清了反馈机制对学习难度的影响。

Abstract: We study reinforcement learning in MDPs whose transition function is stochastic at most steps but may behave adversarially at a fixed subset of $Λ$ steps per episode. This model captures environments that are stable except at a few vulnerable points. We introduce \emph{conditioned occupancy measures}, which remain stable across episodes even with adversarial transitions, and use them to design two algorithms. The first handles arbitrary adversarial steps and achieves regret $\tilde{O}(H S^Λ\sqrt{K S A^{Λ+1}})$, where $K$ is the number of episodes, $S$ is the number of state, $A$ is the number of actions and $H$ is the episode's horizon. The second, assuming the adversarial steps are consecutive, improves the dependence on $S$ to $\tilde{O}(H\sqrt{K S^{3} A^{Λ+1}})$. We further give a $K^{2/3}$-regret reduction that removes the need to know which steps are the $Λ$ adversarial steps. We also characterize the regret of adversarial MDPs in the \emph{fully adversarial} setting ($Λ=H-1$) both for full-information and bandit feedback, and provide almost matching upper and lower bounds (slightly strengthen existing lower bounds, and clarify how different feedback structures affect the hardness of learning).

</details>


### [219] [Adaptive recurrent flow map operator learning for reaction diffusion dynamics](https://arxiv.org/abs/2602.09487)
*Huseyin Tunc*

Main category: cs.LG

TL;DR: 本文提出了一种纯数据驱动的算子学习方法DDOL-ART，通过自适应循环训练与轻量验证里程碑机制，显著提升反应-扩散方程长期预测的稳定性与OOD泛化能力，且训练成本远低于物理约束方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在反应-扩散方程建模中面临长期自回归误差累积、对OOD初值敏感、以及物理残差损失引入高计算开销与设计敏感性等问题。

Method: 提出DDOL-ART框架：采用纯数据驱动策略，结合自适应循环训练机制，设置轻量级验证里程碑以提前终止无效 rollout 段并重定向优化方向；仅在单类短时程 toroidal Gaussian 初值上训练。

Result: DDOL-ART 在 FitzHugh-Nagumo、Gray-Scott 和 Lambda-Omega 系统上实现零样本强形态迁移；长期预测稳定，OOD鲁棒性强；训练速度数倍快于物理残差法NLOL，且精度与稳定性具竞争力；验证误差与OOD测试误差相关性增强。

Conclusion: 反馈控制的循环训练可构建无需PDE残差的鲁棒流映射代理模型，在保持高性能的同时大幅降低训练成本。

Abstract: Reaction-diffusion (RD) equations underpin pattern formation across chemistry, biology, and physics, yet learning stable operators that forecast their long-term dynamics from data remains challenging. Neural-operator surrogates provide resolution-robust prediction, but autoregressive rollouts can drift due to the accumulation of error, and out-of-distribution (OOD) initial conditions often degrade accuracy. Physics-based numerical residual objectives can regularize operator learning, although they introduce additional assumptions, sensitivity to discretization and loss design, and higher training cost. Here we develop a purely data-driven operator learner with adaptive recurrent training (DDOL-ART) using a robust recurrent strategy with lightweight validation milestones that early-exit unproductive rollout segments and redirect optimization. Trained only on a single in-distribution toroidal Gaussian family over short horizons, DDOL-ART learns one-step operators that remain stable under long rollouts and generalize zero-shot to strong morphology shifts across FitzHugh-Nagumo (FN), Gray-Scott (GS), and Lambda-Omega (LO) systems. Across these benchmarks, DDOL-ART delivers a strong accuracy and cost trade-off. It is several-fold faster than a physics-based numerical-loss operator learner (NLOL) under matched settings, and it remains competitive on both in-distribution stability and OOD robustness. Training-dynamics diagnostics show that adaptivity strengthens the correlation between validation error and OOD test error performance, acting as a feedback controller that limits optimization drift. Our results indicate that feedback-controlled recurrent training of DDOL-ART generates robust flow-map surrogates without PDE residuals, while simultaneously maintaining competitiveness with NLOL at significantly reduced training costs.

</details>


### [220] [Beware of the Batch Size: Hyperparameter Bias in Evaluating LoRA](https://arxiv.org/abs/2602.09492)
*Sangyoon Lee,Jaeho Lee*

Main category: cs.LG

TL;DR: 本文揭示了批量大小（batch size）是影响LoRA变体性能差异的关键但被忽视的因素，指出在合理调优下，基础LoRA常可媲美更复杂变体，并提出一种基于代理的高效批量大小调优策略。


<details>
  <summary>Details</summary>
Motivation: LoRA变体在相同基准上报告相互矛盾的实证结果，亟需厘清根本原因。

Method: 系统分析不同LoRA变体中批量大小的影响；提出基于代理的低成本批量大小调优策略；探究秩、数据集规模和模型容量对最优批量大小的影响。

Result: 发现批量大小是导致LoRA变体性能差异的主要因素；验证调优后的基础LoRA性能可匹敌复杂变体；明确了各因素对最优批量大小的作用规律。

Conclusion: 批量大小应被视为LoRA设计与评估中的一阶核心参数，而非次要实现细节；该发现统一了先前不一致的结论，提升了LoRA变体评估的可靠性。

Abstract: Low-rank adaptation (LoRA) is a standard approach for fine-tuning large language models, yet its many variants report conflicting empirical gains, often on the same benchmarks. We show that these contradictions arise from a single overlooked factor: the batch size. When properly tuned, vanilla LoRA often matches the performance of more complex variants. We further propose a proxy-based, cost-efficient strategy for batch size tuning, revealing the impact of rank, dataset size, and model capacity on the optimal batch size. Our findings elevate batch size from a minor implementation detail to a first-order design parameter, reconciling prior inconsistencies and enabling more reliable evaluations of LoRA variants.

</details>


### [221] [Computationally Efficient Replicable Learning of Parities](https://arxiv.org/abs/2602.09499)
*Moshe Noivirt,Jessica Sorrell,Eliad Tsfadia*

Main category: cs.LG

TL;DR: 本文提出了首个针对任意分布下可实现性学习奇偶函数的高效可复现算法，证明了高效可复现学习在计算能力上严格强于统计查询（SQ）学习，并更接近高效差分隐私学习。


<details>
  <summary>Details</summary>
Motivation: 以往高效可复现学习算法仅限于SQ可学习任务或受限分布，而差分隐私学习能力更强；本文旨在填补可复现学习在计算能力上的理论空白，探索其与差分隐私和SQ模型的关系。

Method: 提出一种新的高效且可复现的子空间覆盖算法作为核心构件，用于在向量集合的线性张成中输出覆盖大多数向量的子空间，并将其应用于奇偶函数的可实现性学习。

Result: 首次实现了在任意分布下对奇偶函数的高效可复现学习，该任务在SQ模型中已知为难解，但在差分隐私下可行；从而证明高效可复现学习严格强于高效SQ学习，并在能力上更接近高效差分隐私学习。

Conclusion: 可复现学习在统计上虽与差分隐私等价，但计算上此前受限；本文突破了这一限制，表明其计算能力可超越SQ模型，逼近差分隐私，揭示了二者间新的计算关系。

Abstract: We study the computational relationship between replicability (Impagliazzo et al. [STOC `22], Ghazi et al. [NeurIPS `21]) and other stability notions. Specifically, we focus on replicable PAC learning and its connections to differential privacy (Dwork et al. [TCC 2006]) and to the statistical query (SQ) model (Kearns [JACM `98]). Statistically, it was known that differentially private learning and replicable learning are equivalent and strictly more powerful than SQ-learning. Yet, computationally, all previously known efficient (i.e., polynomial-time) replicable learning algorithms were confined to SQ-learnable tasks or restricted distributions, in contrast to differentially private learning.
  Our main contribution is the first computationally efficient replicable algorithm for realizable learning of parities over arbitrary distributions, a task that is known to be hard in the SQ-model, but possible under differential privacy. This result provides the first evidence that efficient replicable learning over general distributions strictly extends efficient SQ-learning, and is closer in power to efficient differentially private learning, despite computational separations between replicability and privacy. Our main building block is a new, efficient, and replicable algorithm that, given a set of vectors, outputs a subspace of their linear span that covers most of them.

</details>


### [222] [Improved Approximate Regret for Decentralized Online Continuous Submodular Maximization via Reductions](https://arxiv.org/abs/2602.09502)
*Yuanyu Wan,Yu Shen,Dingzhi Yu,Bo Xue,Mingli Song*

Main category: cs.LG

TL;DR: 本文提出了两种从去中心化在线连续子模最大化（D-OCSM）到去中心化在线凸优化（D-OCO）的归约方法，显著改进了D-OCSM在一般凸决策集和向下闭决策集上的近似遗憾界，尤其提升了投影自由算法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有D-OCSM算法在近似遗憾界上与凸设置差距大，且投影自由算法无法达到集中式设置的遗憾界。

Method: 提出两种将D-OCSM归约为D-OCO的新技术，分别适用于一般凸决策集和向下闭决策集，从而利用现有D-OCO算法改进遗憾界。

Result: 在一般凸决策集上同时解决遗憾界差距大和投影自由算法性能差两个问题；在向下闭决策集上缓解前者并解决后者。

Conclusion: 通过归约策略，D-OCSM可在保持投影自由优势的同时，显著逼近D-OCO的遗憾性能，推动去中心化在线非凸优化的发展。

Abstract: To expand the applicability of decentralized online learning, previous studies have proposed several algorithms for decentralized online continuous submodular maximization (D-OCSM) -- a non-convex/non-concave setting with continuous DR-submodular reward functions. However, there exist large gaps between their approximate regret bounds and the regret bounds achieved in the convex setting. Moreover, if focusing on projection-free algorithms, which can efficiently handle complex decision sets, they cannot even recover the approximate regret bounds achieved in the centralized setting. In this paper, we first demonstrate that for D-OCSM over general convex decision sets, these two issues can be addressed simultaneously. Furthermore, for D-OCSM over downward-closed decision sets, we show that the second issue can be addressed while significantly alleviating the first issue. Our key techniques are two reductions from D-OCSM to decentralized online convex optimization (D-OCO), which can exploit D-OCO algorithms to improve the approximate regret of D-OCSM in these two cases, respectively.

</details>


### [223] [Towards Uniformity and Alignment for Multimodal Representation Learning](https://arxiv.org/abs/2602.09507)
*Wenzhe Yin,Pan Zhou,Zehao Xiao,Jie Liu,Shujian Yu,Jan-Jakob Sonke,Efstratios Gavves*

Main category: cs.LG

TL;DR: 本文提出了一种解耦对齐与均匀性的多模态表示学习方法，以解决InfoNCE目标中固有的模态间分布差距问题，并在检索和生成任务上取得一致提升。


<details>
  <summary>Details</summary>
Motivation: InfoNCE类目标在多模态表示学习中引发对齐-均匀性冲突和模态内对齐冲突，且随模态数量增加而加剧，导致模态间分布不一致。

Method: 提出一种原则性的对齐与均匀性解耦框架，理论证明其等价于最小化多模态分布间的全局Hölder散度。

Result: 在跨模态检索和UnCLIP风格生成任务上均取得稳定性能提升。

Conclusion: 解耦对齐与均匀性可有效缓解多模态学习中的内在冲突，缩小模态间分布差距，兼顾判别与生成任务。

Abstract: Multimodal representation learning aims to construct a shared embedding space in which heterogeneous modalities are semantically aligned. Despite strong empirical results, InfoNCE-based objectives introduce inherent conflicts that yield distribution gaps across modalities. In this work, we identify two conflicts in the multimodal regime, both exacerbated as the number of modalities increases: (i) an alignment-uniformity conflict, whereby the repulsion of uniformity undermines pairwise alignment, and (ii) an intra-alignment conflict, where aligning multiple modalities induces competing alignment directions. To address these issues, we propose a principled decoupling of alignment and uniformity for multimodal representations, providing a conflict-free recipe for multimodal learning that simultaneously supports discriminative and generative use cases without task-specific modules. We then provide a theoretical guarantee that our method acts as an efficient proxy for a global Hölder divergence over multiple modality distributions, and thus reduces the distribution gap among modalities. Extensive experiments on retrieval and UnCLIP-style generation demonstrate consistent gains.

</details>


### [224] [Beyond Student: An Asymmetric Network for Neural Network Inheritance](https://arxiv.org/abs/2602.09509)
*Yiyun Zhou,Jingwei Shi,Mingjing Xu,Zhonghua Jiang,Jingyuan Chen*

Main category: cs.LG

TL;DR: 本文提出InherNet，一种通过非对称低秩分解继承教师网络权重的神经网络继承方法，在保持轻量级的同时最大化知识继承，性能优于同参数规模的学生网络。


<details>
  <summary>Details</summary>
Motivation: 解决知识蒸馏中学生网络因容量差距导致性能受限的问题，探索能否设计一种既能继承教师网络结构又能最大化继承其知识的网络。

Method: 提出InherNet方法，对教师网络权重进行非对称低秩分解，并利用奇异值分解（SVD）初始化以确保主知识继承，重构轻量但表达力强的网络。

Result: 在单模态和多模态任务上的实验表明，InherNet在相似参数量下性能高于传统学生网络。

Conclusion: InherNet为高效模型压缩提供了新方向，超越了传统知识蒸馏范式。

Abstract: Knowledge Distillation (KD) has emerged as a powerful technique for model compression, enabling lightweight student networks to benefit from the performance of redundant teacher networks. However, the inherent capacity gap often limits the performance of student networks. Inspired by the expressiveness of pretrained teacher networks, a compelling research question arises: is there a type of network that can not only inherit the teacher's structure but also maximize the inheritance of its knowledge? Furthermore, how does the performance of such an inheriting network compare to that of student networks, all benefiting from the same teacher network? To further explore this question, we propose InherNet, a neural network inheritance method that performs asymmetric low-rank decomposition on the teacher's weights and reconstructs a lightweight yet expressive network without significant architectural disruption. By leveraging Singular Value Decomposition (SVD) for initialization to ensure the inheritance of principal knowledge, InherNet effectively balances depth, width, and compression efficiency. Experimental results across unimodal and multimodal tasks demonstrate that InherNet achieves higher performance compared to student networks of similar parameter sizes. Our findings reveal a promising direction for future research in efficient model compression beyond traditional distillation.

</details>


### [225] [Rashomon Sets and Model Multiplicity in Federated Learning](https://arxiv.org/abs/2602.09520)
*Xenia Heilmann,Luca Corbucci,Mattia Cerrato*

Main category: cs.LG

TL;DR: 本文首次将Rashomon集的概念形式化引入联邦学习（FL）场景，提出三种联邦视角下的Rashomon集定义（全局、t-一致、个体），设计满足隐私约束的多重性度量估计方法，并构建多重性感知的FL流程，实验证明其有助于提升模型本地适配性、公平性与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有Rashomon集与多重性度量仅适用于中心化学习，无法直接用于联邦学习（FL）；而FL中数据异构、隐私保护与通信限制导致单一最优模型可能加剧偏差、损害公平性与鲁棒性，亟需刻画模型多重性。

Method: 1）提出联邦Rashomon集的三种定义：全局（基于聚合统计）、t-一致（t比例客户端局部Rashomon集交集）、个体（各客户端本地分布）；2）在FL隐私约束下设计多重性度量估计方法；3）构建多重性感知的FL训练与部署流程。

Result: 在标准FL基准数据集上的实验表明，三种联邦Rashomon集定义均能提供有价值洞察，支持客户端选择更契合本地数据分布、公平目标与实际需求的模型。

Conclusion: Rashomon集的联邦扩展为理解FL中模型多样性、提升透明性、公平性与鲁棒性提供了新理论工具与实践路径，推动了可信联邦学习的发展。

Abstract: The Rashomon set captures the collection of models that achieve near-identical empirical performance yet may differ substantially in their decision boundaries. Understanding the differences among these models, i.e., their multiplicity, is recognized as a crucial step toward model transparency, fairness, and robustness, as it reveals decision boundaries instabilities that standard metrics obscure. However, the existing definitions of Rashomon set and multiplicity metrics assume centralized learning and do not extend naturally to decentralized, multi-party settings like Federated Learning (FL). In FL, multiple clients collaboratively train models under a central server's coordination without sharing raw data, which preserves privacy but introduces challenges from heterogeneous client data distribution and communication constraints. In this setting, the choice of a single best model may homogenize predictive behavior across diverse clients, amplify biases, or undermine fairness guarantees. In this work, we provide the first formalization of Rashomon sets in FL.First, we adapt the Rashomon set definition to FL, distinguishing among three perspectives: (I) a global Rashomon set defined over aggregated statistics across all clients, (II) a t-agreement Rashomon set representing the intersection of local Rashomon sets across a fraction t of clients, and (III) individual Rashomon sets specific to each client's local distribution.Second, we show how standard multiplicity metrics can be estimated under FL's privacy constraints. Finally, we introduce a multiplicity-aware FL pipeline and conduct an empirical study on standard FL benchmark datasets. Our results demonstrate that all three proposed federated Rashomon set definitions offer valuable insights, enabling clients to deploy models that better align with their local data, fairness considerations, and practical requirements.

</details>


### [226] [Learning to Discover Iterative Spectral Algorithms](https://arxiv.org/abs/2602.09530)
*Zihang Liu,Oleg Balabanov,Yaoqing Yang,Michael W. Mahoney*

Main category: cs.LG

TL;DR: AutoSpec是一个神经网络框架，用于自动发现适用于大规模数值线性代数与优化任务的迭代谱算法，通过自监督学习预测矩阵多项式递推系数，在多个任务上显著优于基线方法，并展现出与经典Chebyshev多项式相似的最优逼近特性。


<details>
  <summary>Details</summary>
Motivation: 传统迭代谱算法（如Chebyshev、Lanczos）依赖人工设计和先验谱信息，难以适应多样化的实际算子；亟需一种能自适应、可学习、泛化性强的算法发现机制。

Method: 提出AutoSpec框架：1）设计具备可执行数值递推结构的神经网络架构；2）在小型合成问题上自监督训练，实现向大规模真实算子迁移；3）以任务导向目标（如逼近误差、预处理效果）驱动学习，利用粗粒度谱信息（如特征值估计、残差范数）动态调整多项式系数。

Result: 在矩阵函数加速、稀疏线性求解器加速、特征值计算的谱滤波/预处理等任务中，AutoSpec在真实矩阵上实现数量级级别的精度提升或迭代次数减少；所学多项式表现出近等波纹、近极小极大特性，与经典Chebyshev理论高度一致。

Conclusion: AutoSpec成功将深度学习与经典谱理论结合，验证了数据驱动方式发现高效、鲁棒、理论可解释的数值算法的可行性，为智能数值计算开辟新路径。

Abstract: We introduce AutoSpec, a neural network framework for discovering iterative spectral algorithms for large-scale numerical linear algebra and numerical optimization. Our self-supervised models adapt to input operators using coarse spectral information (e.g., eigenvalue estimates and residual norms), and they predict recurrence coefficients for computing or applying a matrix polynomial tailored to a downstream task. The effectiveness of AutoSpec relies on three ingredients: an architecture whose inference pass implements short, executable numerical linear algebra recurrences; efficient training on small synthetic problems with transfer to large-scale real-world operators; and task-defined objectives that enforce the desired approximation or preconditioning behavior across the range of spectral profiles represented in the training set. We apply AutoSpec to discovering algorithms for representative numerical linear algebra tasks: accelerating matrix-function approximation; accelerating sparse linear solvers; and spectral filtering/preconditioning for eigenvalue computations. On real-world matrices, the learned procedures deliver orders-of-magnitude improvements in accuracy and/or reductions in iteration count, relative to basic baselines. We also find clear connections to classical theory: the induced polynomials often exhibit near-equiripple, near-minimax behavior characteristic of Chebyshev polynomials.

</details>


### [227] [ECG-IMN: Interpretable Mesomorphic Neural Networks for 12-Lead Electrocardiogram Interpretation](https://arxiv.org/abs/2602.09566)
*Vajira Thambawita,Jonas L. Isaksen,Jørgen K. Kanters,Hugo L. Hammer,Pål Halvorsen*

Main category: cs.LG

TL;DR: 本文提出ECG-IMN——一种面向12导联心电图分类的可解释中形态神经网络，通过超网络结构生成样本特异性线性模型参数，实现内在可解释性，并在PTB-XL数据集上验证了其高精度与高保真解释能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习在心电图自动诊断中表现优异，但其“黑箱”特性阻碍临床落地；临床信任不仅依赖高准确率，更需模型决策依据（如特定生理特征）透明可解释；现有后验解释方法（如Grad-CAM、SHAP）存在不稳定、计算开销大、不忠实于真实决策过程等问题。

Method: 提出ECG-IMN（Interpretable Mesomorphic Neural Network）：以深度卷积骨干网络作为超网络，为每个输入样本动态生成一个严格线性分类器的参数（权重W）；引入过渡解码器（transition decoder），将潜在特征映射为样本级权重，从而在时间和导联维度上精确定位病理证据（如ST段抬高、T波倒置）；该架构实现内在可解释性，W即为精确、高分辨率的特征归因图。

Result: 在PTB-XL数据集上的分类任务中，ECG-IMN达到与黑箱基线相当的AUROC性能，同时提供忠实、实例级的高分辨率解释；成功将深度学习能力与临床可信度统一，迈向‘白盒’心脏诊断。

Conclusion: ECG-IMN通过参数生成与预测执行的显式解耦，为医学AI提供了一种兼具高性能与内在可解释性的新范式，是推动可信赖AI临床部署的重要进展。

Abstract: Deep learning has achieved expert-level performance in automated electrocardiogram (ECG) diagnosis, yet the "black-box" nature of these models hinders their clinical deployment. Trust in medical AI requires not just high accuracy but also transparency regarding the specific physiological features driving predictions. Existing explainability methods for ECGs typically rely on post-hoc approximations (e.g., Grad-CAM and SHAP), which can be unstable, computationally expensive, and unfaithful to the model's actual decision-making process. In this work, we propose the ECG-IMN, an Interpretable Mesomorphic Neural Network tailored for high-resolution 12-lead ECG classification. Unlike standard classifiers, the ECG-IMN functions as a hypernetwork: a deep convolutional backbone generates the parameters of a strictly linear model specific to each input sample. This architecture enforces intrinsic interpretability, as the decision logic is mathematically transparent and the generated weights (W) serve as exact, high-resolution feature attribution maps. We introduce a transition decoder that effectively maps latent features to sample-wise weights, enabling precise localization of pathological evidence (e.g., ST-elevation, T-wave inversion) in both time and lead dimensions. We evaluate our approach on the PTB-XL dataset for classification tasks, demonstrating that the ECG-IMN achieves competitive predictive performance (AUROC comparable to black-box baselines) while providing faithful, instance-specific explanations. By explicitly decoupling parameter generation from prediction execution, our framework bridges the gap between deep learning capability and clinical trustworthiness, offering a principled path toward "white-box" cardiac diagnostics.

</details>


### [228] [Training deep physical neural networks with local physical information bottleneck](https://arxiv.org/abs/2602.09569)
*Hao Wang,Ziao Wang,Xiangpeng Liang,Han Zhao,Jianqi Hu,Junjie Jiang,Xing Fu,Jianshi Tang,Huaqiang Wu,Sylvain Gigan,Qiang Liu*

Main category: cs.LG

TL;DR: 本文提出了一种名为物理信息瓶颈（PIB）的通用高效训练框架，结合信息论与局部学习，支持深度物理神经网络（PNNs）在任意物理动力学下进行监督、无监督和强化学习，并具备容错性与分布式并行训练能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习面临能耗和延迟瓶颈，而深度物理神经网络（PNNs）虽具能效与速度优势，却缺乏适配其物理特性的通用训练方法。

Method: 提出物理信息瓶颈（PIB）框架，通过为每个计算单元分配基于矩阵的信息瓶颈，融合信息论原理与局部学习规则，无需辅助数字模型或对比测量。

Result: 在电子忆阻器芯片与光计算平台上成功实现监督、无监督及强化学习；支持严重硬件故障下的鲁棒训练，并可利用地理分布资源并行训练。

Conclusion: PIB将PNN训练重构为一种内生的、可扩展的信息理论过程，兼容多种物理载体，为高效、可扩展的类脑硬件AI训练提供了新范式。

Abstract: Deep learning has revolutionized modern society but faces growing energy and latency constraints. Deep physical neural networks (PNNs) are interconnected computing systems that directly exploit analog dynamics for energy-efficient, ultrafast AI execution. Realizing this potential, however, requires universal training methods tailored to physical intricacies. Here, we present the Physical Information Bottleneck (PIB), a general and efficient framework that integrates information theory and local learning, enabling deep PNNs to learn under arbitrary physical dynamics. By allocating matrix-based information bottlenecks to each unit, we demonstrate supervised, unsupervised, and reinforcement learning across electronic memristive chips and optical computing platforms. PIB also adapts to severe hardware faults and allows for parallel training via geographically distributed resources. Bypassing auxiliary digital models and contrastive measurements, PIB recasts PNN training as an intrinsic, scalable information-theoretic process compatible with diverse physical substrates.

</details>


### [229] [Flexible Entropy Control in RLVR with Gradient-Preserving Perspective](https://arxiv.org/abs/2602.09782)
*Kun Chen,Peng Shi,Fanfan Liu,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao*

Main category: cs.LG

TL;DR: 本文提出了一种基于梯度保持裁剪（Gradient-Preserving Clipping）的动态熵控制方法，以缓解强化学习中策略熵崩溃问题，提升大语言模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 连续训练常导致策略熵崩溃（entropy collapse），表现为熵快速衰减、过早过自信、输出多样性下降及梯度范数消失，而现有裁剪策略静态且缺乏与熵精确调控的理论联系。

Method: 首先理论与实证分析重要性采样比不同区间对熵增/减的贡献；进而提出基于动态裁剪阈值的熵调控机制，并设计多种动态熵控制策略（如先增后减、先减再增再减、振荡衰减等）。

Result: 实验表明所提策略能有效缓解熵崩溃，在多个基准上取得更优性能。

Conclusion: 从梯度保持裁剪视角重塑RL中的熵控制是可行且有效的，动态阈值机制为实现精准熵调控提供了新框架。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a critical method for enhancing the reasoning capabilities of Large Language Models (LLMs). However, continuous training often leads to policy entropy collapse, characterized by a rapid decay in entropy that results in premature overconfidence, reduced output diversity, and vanishing gradient norms that inhibit learning. Gradient-Preserving Clipping is a primary factor influencing these dynamics, but existing mitigation strategies are largely static and lack a framework connecting clipping mechanisms to precise entropy control. This paper proposes reshaping entropy control in RL from the perspective of Gradient-Preserving Clipping. We first theoretically and empirically verify the contributions of specific importance sampling ratio regions to entropy growth and reduction. Leveraging these findings, we introduce a novel regulation mechanism using dynamic clipping threshold to precisely manage entropy. Furthermore, we design and evaluate dynamic entropy control strategies, including increase-then-decrease, decrease-increase-decrease, and oscillatory decay. Experimental results demonstrate that these strategies effectively mitigate entropy collapse, and achieve superior performance across multiple benchmarks.

</details>


### [230] [Rollout-Training Co-Design for Efficient LLM-Based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.09578)
*Zhida Jiang,Zhaolong Xing,Jiawei Lu,Yipei Niu,Qingyuan Sang,Liangxu Zhang,Wenquan Dai,Junhua Shu,Jiaxing Wang,Qiangyu Pei,Qiong Chen,Xinyu Liu,Fangming Liu,Ai Han,Zhen Chen,Ke Zhang*

Main category: cs.LG

TL;DR: 本文提出了FlexMARL，首个面向大规模LLM-based多智能体强化学习（MARL）的端到端训练框架，通过解耦rollout与训练、异步微批次流水线、分层负载均衡和智能体中心化资源分配等技术，显著提升训练速度与硬件利用率。


<details>
  <summary>Details</summary>
Motivation: 现有MARL训练框架主要针对单智能体优化，未解决MARL特有的系统级挑战，如rollout-训练同步瓶颈、rollout负载不均和训练资源利用率低。

Method: 提出FlexMARL框架：1）联合调度器管理解耦架构下的数据流；2）基于经验存储的微批次异步流水线消除同步障碍并保障一致性；3）rollout引擎采用并行采样+分层负载均衡应对请求倾斜；4）训练引擎通过智能体中心化资源分配实现按需硬件绑定，并利用统一位置无关通信交换各智能体训练状态。

Result: 在大规模生产集群上的实验表明，FlexMARL相比现有框架最高实现7.3倍加速，硬件利用率最高提升5.6倍。

Conclusion: FlexMARL首次从系统层面全面优化大规模MARL训练，有效解决了同步、负载均衡与资源利用等关键问题，为LLM-based MARL的实际部署提供了高效可扩展的基础设施支持。

Abstract: Despite algorithm-level innovations for multi-agent reinforcement learning (MARL), the underlying networked infrastructure for large-scale MARL training remains underexplored. Existing training frameworks primarily optimize for single-agent scenarios and fail to address the unique system-level challenges of MARL, including rollout-training synchronization barriers, rollout load imbalance, and training resource underutilization. To bridge this gap, we propose FlexMARL, the first end-to-end training framework that holistically optimizes rollout, training, and their orchestration for large-scale LLM-based MARL. Specifically, FlexMARL introduces the joint orchestrator to manage data flow under the rollout-training disaggregated architecture. Building upon the experience store, a novel micro-batch driven asynchronous pipeline eliminates the synchronization barriers while providing strong consistency guarantees. Rollout engine adopts a parallel sampling scheme combined with hierarchical load balancing, which adapts to skewed inter/intra-agent request patterns. Training engine achieves on-demand hardware binding through agent-centric resource allocation. The training states of different agents are swapped via unified and location-agnostic communication. Empirical results on a large-scale production cluster demonstrate that FlexMARL achieves up to 7.3x speedup and improves hardware utilization by up to 5.6x compared to existing frameworks.

</details>


### [231] [Why Linear Interpretability Works: Invariant Subspaces as a Result of Architectural Constraints](https://arxiv.org/abs/2602.09783)
*Andres Saurez,Yousung Lee,Dongsoo Har*

Main category: cs.LG

TL;DR: 本文提出不变子空间必要性定理，指出Transformer中语义特征必须位于上下文不变的线性子空间中，从而解释了线性探针和稀疏自编码器为何有效；并推导出自指性质，支持零样本语义结构识别。


<details>
  <summary>Details</summary>
Motivation: 解释为何在线性探针和稀疏自编码器等简单方法能在深层非线性Transformer模型中成功恢复有意义的结构。

Method: 通过形式化分析Transformer架构中的线性接口（如注意力OV电路、解嵌入矩阵），提出‘不变子空间必要性’定理与‘自指性质’，并结合八项分类任务、四个模型族进行实证验证。

Result: 验证了类token与语义相关实例在几何方向上的对齐，证实线性可解码特征必然处于上下文不变线性子空间，并支持零样本语义识别。

Conclusion: 线性可解释性方法的有效性源于Transformer架构本身的设计约束，而非偶然经验现象；该框架统一解释了线性探针与稀疏自编码器的工作原理。

Abstract: Linear probes and sparse autoencoders consistently recover meaningful structure from transformer representations -- yet why should such simple methods succeed in deep, nonlinear systems? We show this is not merely an empirical regularity but a consequence of architectural necessity: transformers communicate information through linear interfaces (attention OV circuits, unembedding matrices), and any semantic feature decoded through such an interface must occupy a context-invariant linear subspace. We formalize this as the \emph{Invariant Subspace Necessity} theorem and derive the \emph{Self-Reference Property}: tokens directly provide the geometric direction for their associated features, enabling zero-shot identification of semantic structure without labeled data or learned probes. Empirical validation in eight classification tasks and four model families confirms the alignment between class tokens and semantically related instances. Our framework provides \textbf{a principled architectural explanation} for why linear interpretability methods work, unifying linear probes and sparse autoencoders.

</details>


### [232] [Mitigating the Likelihood Paradox in Flow-based OOD Detection via Entropy Manipulation](https://arxiv.org/abs/2602.09581)
*Donghwan Kim,Hyunsoo Yoon*

Main category: cs.LG

TL;DR: 本文提出一种基于语义相似性调节输入熵的方法，以缓解深度生成模型对分布外样本赋予过高似然值的问题，无需额外训练即可提升OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型（如标准化流）在计算输入似然时，常对分布外（OOD）样本给出异常高的似然值，导致OOD检测失效。

Method: 根据输入与分布内记忆库的语义相似性动态调整输入熵：对语义上更远离记忆库的输入施加更强的扰动，从而控制其熵；该方法无需重新训练密度模型。

Result: 理论分析表明该方法能增大分布内与OOD样本的期望对数似然差；在标准基准上的实验显示，相比基线方法，AUROC指标持续提升。

Conclusion: 通过语义感知的熵控制可有效缓解似然悖论，提升基于似然的OOD检测鲁棒性，且不依赖额外模型训练。

Abstract: Deep generative models that can tractably compute input likelihoods, including normalizing flows, often assign unexpectedly high likelihoods to out-of-distribution (OOD) inputs. We mitigate this likelihood paradox by manipulating input entropy based on semantic similarity, applying stronger perturbations to inputs that are less similar to an in-distribution memory bank. We provide a theoretical analysis showing that entropy control increases the expected log-likelihood gap between in-distribution and OOD samples in favor of the in-distribution, and we explain why the procedure works without any additional training of the density model. We then evaluate our method against likelihood-based OOD detectors on standard benchmarks and find consistent AUROC improvements over baselines, supporting our explanation.

</details>


### [233] [Circuit Fingerprints: How Answer Tokens Encode Their Geometrical Path](https://arxiv.org/abs/2602.09784)
*Andres Saurez,Neha Sengar,Dongsoo Har*

Main category: cs.LG

TL;DR: 本文提出Circuit Fingerprint假设，指出答案词元在孤立处理时即编码了能生成它们的方向，从而统一电路发现与激活引导，仅通过几何对齐即可实现无需梯度或因果干预的电路发现，并在多个基准上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 电路发现与激活引导虽为不同研究方向，但作用于同一表征空间，作者试图探究二者是否源于同一底层结构。

Method: 提出Circuit Fingerprint假设，利用答案词元在孤立处理时所编码的方向进行几何对齐，实现无需梯度或因果干预的电路发现与可控引导。

Result: 在IOI、SVA、MCQA等标准基准上，跨四个模型家族实现了与基于梯度方法相当的电路发现性能；在情绪分类任务中达到69.8%准确率，优于指令提示的53.1%，同时保持事实准确性。

Conclusion: 变压器电路本质上是几何结构，可解释性与可控性是其同一对象的两个方面。

Abstract: Circuit discovery and activation steering in transformers have developed as separate research threads, yet both operate on the same representational space. Are they two views of the same underlying structure? We show they follow a single geometric principle: answer tokens, processed in isolation, encode the directions that would produce them. This Circuit Fingerprint hypothesis enables circuit discovery without gradients or causal intervention -- recovering comparable structure to gradient-based methods through geometric alignment alone. We validate this on standard benchmarks (IOI, SVA, MCQA) across four model families, achieving circuit discovery performance comparable to gradient-based methods. The same directions that identify circuit components also enable controlled steering -- achieving 69.8\% emotion classification accuracy versus 53.1\% for instruction prompting while preserving factual accuracy. Beyond method development, this read-write duality reveals that transformer circuits are fundamentally geometric structures: interpretability and controllability are two facets of the same object.

</details>


### [234] [Why the Counterintuitive Phenomenon of Likelihood Rarely Appears in Tabular Anomaly Detection with Deep Generative Models?](https://arxiv.org/abs/2602.09593)
*Donghwan Kim,Junghun Phee,Hyunsoo Yoon*

Main category: cs.LG

TL;DR: 本文研究了在表格数据中使用基于似然的深度生成模型（如归一化流）进行异常检测时，是否会出现反直觉现象（即异常样本获得更高似然），发现该现象在表格数据中远少于图像数据，并通过理论与实验分析指出维度与特征相关性是关键因素。


<details>
  <summary>Details</summary>
Motivation: 解决深度生成模型在异常检测中出现反直觉现象（异常样本似然更高）在表格数据中缺乏明确定义和系统评估的问题。

Method: 提出一种领域无关的反直觉现象形式化定义；在ADBench的47个表格数据集和10个CV/NLP嵌入数据集上，对比13种基线模型；结合理论分析与实证研究，考察数据维度和特征相关性的影响。

Result: 反直觉现象在通用表格数据中一致罕见；数据维度较低和特征相关性较弱是其较少发生的关键原因；基于似然的归一化流在表格异常检测中表现实用且可靠。

Conclusion: 基于似然的归一化流是表格数据异常检测中一种可行且稳健的方法，其反直觉行为显著弱于图像域，可被安全用于实际场景。

Abstract: Deep generative models with tractable and analytically computable likelihoods, exemplified by normalizing flows, offer an effective basis for anomaly detection through likelihood-based scoring. We demonstrate that, unlike in the image domain where deep generative models frequently assign higher likelihoods to anomalous data, such counterintuitive behavior occurs far less often in tabular settings. We first introduce a domain-agnostic formulation that enables consistent detection and evaluation of the counterintuitive phenomenon, addressing the absence of precise definition. Through extensive experiments on 47 tabular datasets and 10 CV/NLP embedding datasets in ADBench, benchmarked against 13 baseline models, we demonstrate that the phenomenon, as defined, is consistently rare in general tabular data. We further investigate this phenomenon from both theoretical and empirical perspectives, focusing on the roles of data dimensionality and difference in feature correlation. Our results suggest that likelihood-only detection with normalizing flows offers a practical and reliable approach for anomaly detection in tabular domains.

</details>


### [235] [LLM-FS: Zero-Shot Feature Selection for Effective and Interpretable Malware Detection](https://arxiv.org/abs/2602.09634)
*Naveen Gill,Ajvad Haneef K,Madhu Kumar S D*

Main category: cs.LG

TL;DR: 本文探索了利用大语言模型（LLM）在零样本设置下进行特征选择（FS）以提升恶意软件检测模型的准确性与可解释性，实验表明LLM引导的FS在性能、稳定性与可解释性方面媲美甚至优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统特征选择方法依赖统计启发式或模型重要性评分，忽视特征语义；而LLM在理解特征名称和任务描述方面展现出潜力，因此作者探究其在零样本下的可行性。

Method: 采用GPT-5.0、GPT-4.0、Gemini-2.5等LLM，在仅输入特征名和任务描述的零样本设定下进行特征选择，并在EMBOD数据集上与Extra Trees、Chi-Squared等传统方法对比，评估多种分类器（RF、ET、MLP、KNN）下的多维指标。

Result: LLM引导的零样本FS在准确率、F1、AUC等指标上达到与传统方法相当的水平，同时具备更高可解释性、稳定性及更少对标注数据的依赖。

Conclusion: 零样本LLM驱动的特征选择是一种有前景的替代策略，有望推动知识引导的安全关键领域特征工程发展。

Abstract: Feature selection (FS) remains essential for building accurate and interpretable detection models, particularly in high-dimensional malware datasets. Conventional FS methods such as Extra Trees, Variance Threshold, Tree-based models, Chi-Squared tests, ANOVA, Random Selection, and Sequential Attention rely primarily on statistical heuristics or model-driven importance scores, often overlooking the semantic context of features. Motivated by recent progress in LLM-driven FS, we investigate whether large language models (LLMs) can guide feature selection in a zero-shot setting, using only feature names and task descriptions, as a viable alternative to traditional approaches. We evaluate multiple LLMs (GPT-5.0, GPT-4.0, Gemini-2.5 etc.) on the EMBOD dataset (a fusion of EMBER and BODMAS benchmark datasets), comparing them against established FS methods across several classifiers, including Random Forest, Extra Trees, MLP, and KNN. Performance is assessed using accuracy, precision, recall, F1, AUC, MCC, and runtime. Our results demonstrate that LLM-guided zero-shot feature selection achieves competitive performance with traditional FS methods while offering additional advantages in interpretability, stability, and reduced dependence on labeled data. These findings position zero-shot LLM-based FS as a promising alternative strategy for effective and interpretable malware detection, paving the way for knowledge-guided feature selection in security-critical applications

</details>


### [236] [Blind denoising diffusion models and the blessings of dimensionality](https://arxiv.org/abs/2602.09639)
*Zahra Kadkhodaie,Aram-Alexandre Pooladian,Sinho Chewi,Eero Simoncelli*

Main category: cs.LG

TL;DR: 本文研究了基于盲去噪器的生成扩散模型（BDDMs），证明其在不依赖噪声幅度信息的情况下，能自动跟踪隐式噪声调度，并在多项式步数内准确采样；实验表明BDDMs在合成与图像数据上均表现更优，因其能校正真实残差噪声与预设噪声调度间的失配。


<details>
  <summary>Details</summary>
Motivation: 解决传统扩散模型依赖显式噪声幅度信息、易因噪声调度失配导致性能下降的问题，探索无需噪声幅度输入的盲去噪扩散模型的理论可行性与实际性能。

Method: 理论分析结合实证研究：在数据低本征维假设下，证明盲去噪扩散模型能自动学习隐式噪声调度；通过合成数据和图像数据实验验证其噪声方差估计准确性及采样质量。

Result: BDDMs能在多项式步数内准确采样；实验显示其能准确估计噪声方差；相比非盲模型，BDDMs生成样本质量更高。

Conclusion: 盲去噪扩散模型不仅理论上可行，且实践中更具鲁棒性与优越性，其性能提升源于对真实残差噪声与调度噪声之间失配的自动校正。

Abstract: We analyze, theoretically and empirically, the performance of generative diffusion models based on \emph{blind denoisers}, in which the denoiser is not given the noise amplitude in either the training or sampling processes. Assuming that the data distribution has low intrinsic dimensionality, we prove that blind denoising diffusion models (BDDMs), despite not having access to the noise amplitude, \emph{automatically} track a particular \emph{implicit} noise schedule along the reverse process. Our analysis shows that BDDMs can accurately sample from the data distribution in polynomially many steps as a function of the intrinsic dimension. Empirical results corroborate these mathematical findings on both synthetic and image data, demonstrating that the noise variance is accurately estimated from the noisy image. Remarkably, we observe that schedule-free BDDMs produce samples of higher quality compared to their non-blind counterparts. We provide evidence that this performance gain arises because BDDMs correct the mismatch between the true residual noise (of the image) and the noise assumed by the schedule used in non-blind diffusion models.

</details>


### [237] [Differentiable Modeling for Low-Inertia Grids: Benchmarking PINNs, NODEs, and DP for Identification and Control of SMIB System](https://arxiv.org/abs/2602.09667)
*Shinhoo Kang,Sangwook Kim,Sehyun Yun*

Main category: cs.LG

TL;DR: 本文比较了物理信息神经网络（PINN）、神经常微分方程（NODE）和可微编程（DP）在低惯量电力系统建模、辨识与控制中的性能，发现DP在参数估计收敛速度和控制闭环稳定性方面最优，NODE在轨迹外推上表现最佳，而PINN泛化能力较弱。


<details>
  <summary>Details</summary>
Motivation: 低惯量电力系统需要兼具高精度状态预测与物理一致敏感度的建模框架；现有科学机器学习方法在控制导向下的可微范式差异尚不明确。

Method: 在单机无穷大系统（SMIB）基准上，对比分析PINN、NODE和DP三种可微建模范式在轨迹外推、参数估计和LQR控制器综合三方面的性能。

Result: NODE在外推任务中表现最优；PINN和DP均可完成参数识别，但DP因将控制方程作为硬约束而收敛更快；DP合成的控制器闭环稳定性接近理论最优；NODE可在缺乏控制方程时作为可行的数据驱动代理。

Conclusion: 不同可微范式存在数据灵活性与物理结构性的根本权衡：DP最适合控制导向任务，NODE适合无模型动态建模，PINN则受限于时间依赖解映射导致泛化能力差。

Abstract: The transition toward low-inertia power systems demands modeling frameworks that provide not only accurate state predictions but also physically consistent sensitivities for control. While scientific machine learning offers powerful nonlinear modeling tools, the control-oriented implications of different differentiable paradigms remain insufficiently understood. This paper presents a comparative study of Physics-Informed Neural Networks (PINNs), Neural Ordinary Differential Equations (NODEs), and Differentiable Programming (DP) for modeling, identification, and control of power system dynamics. Using the Single Machine Infinite Bus (SMIB) system as a benchmark, we evaluate their performance in trajectory extrapolation, parameter estimation, and Linear Quadratic Regulator (LQR) synthesis.
  Our results highlight a fundamental trade-off between data-driven flexibility and physical structure. NODE exhibits superior extrapolation by capturing the underlying vector field, whereas PINN shows limited generalization due to its reliance on a time-dependent solution map. In the inverse problem of parameter identification, while both DP and PINN successfully recover the unknown parameters, DP achieves significantly faster convergence by enforcing governing equations as hard constraints. Most importantly, for control synthesis, the DP framework yields closed-loop stability comparable to the theoretical optimum. Furthermore, we demonstrate that NODE serves as a viable data-driven surrogate when governing equations are unavailable.

</details>


### [238] [Resilient Class-Incremental Learning: on the Interplay of Drifting, Unlabelled and Imbalanced Data Streams](https://arxiv.org/abs/2602.09681)
*Jin Li,Kleanthis Malialis,Marios Polycarpou*

Main category: cs.LG

TL;DR: 本文提出SCIL框架，用于解决流式数据中概念漂移、类别不平衡、标签稀缺和新类出现等挑战，通过结合自编码器与多层感知机、双损失策略、修正伪标签、队列管理及过采样等技术提升动态环境下的检测鲁棒性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 流式数据中普遍存在概念漂移、类别不平衡、标签稀缺和新类涌现等问题，导致表征不稳定、模型偏向过时分布、检测可靠性下降。

Method: 提出SCIL（Streaming Class-Incremental Learning）框架：集成自编码器（AE）与多层感知机进行多类预测；采用分类损失与重建损失的双损失策略；使用修正伪标签进行在线训练；通过队列管理类别；结合过采样缓解不平衡。

Result: 在真实与合成数据集（含类别不平衡、增量类别与概念漂移）上的实验表明，SCIL显著优于强基线与前沿方法。

Conclusion: SCIL有效提升了流式类增量学习在复杂动态场景下的稳定性、适应性与鲁棒性；代码与数据集已开源以支持开放科学。

Abstract: In today's connected world, the generation of massive streaming data across diverse domains has become commonplace. In the presence of concept drift, class imbalance, label scarcity, and new class emergence, they jointly degrade representation stability, bias learning toward outdated distributions, and reduce the resilience and reliability of detection in dynamic environments. This paper proposes SCIL (Streaming Class-Incremental Learning) to address these challenges. The SCIL framework integrates an autoencoder (AE) with a multi-layer perceptron for multi-class prediction, uses a dual-loss strategy (classification and reconstruction) for prediction and new class detection, employs corrected pseudo-labels for online training, manages classes with queues, and applies oversampling to handle imbalance. The rationale behind the method's structure is elucidated through ablation studies and a comprehensive experimental evaluation is performed using both real-world and synthetic datasets that feature class imbalance, incremental classes, and concept drifts. Our results demonstrate that SCIL outperforms strong baselines and state-of-the-art methods. Based on our commitment to Open Science, we make our code and datasets available to the community.

</details>


### [239] [Model soups need only one ingredient](https://arxiv.org/abs/2602.09689)
*Alireza Abdollahpoorrostam,Nikolaos Dimitriadis,Adam Hazimeh,Pascal Frossard*

Main category: cs.LG

TL;DR: 本文提出MonoSoup，一种无需数据、无需超参数的后处理方法，通过SVD分解模型各层更新并基于熵有效秩自动重加权高低能量方向，在仅用单个检查点的情况下实现ID-OOD性能的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 微调大模型虽提升ID准确率，却损害OOD鲁棒性；现有权重集成方法（如Model Soups）效果好但计算开销大，需训练和存储多个检查点。

Method: 对每个层的微调更新进行奇异值分解（SVD），分离高能（任务特化）与低能（含鲁棒性相关残余信号）方向，并利用熵定义的有效秩自动确定各层重加权系数。

Result: 在CLIP（ImageNet微调+自然分布偏移）和Qwen（数学推理与多选题）上的实验表明，MonoSoup以单检查点达到接近多检查点集成的ID-OOD平衡，且即插即用、高效实用。

Conclusion: MonoSoup是一种轻量、通用、有效的后处理方案，显著降低了获得鲁棒微调模型的计算门槛，为ID-OOD协同优化提供了新思路。

Abstract: Fine-tuning large pre-trained models on a target distribution often improves in-distribution (ID) accuracy, but at the cost of out-of-distribution (OOD) robustness as representations specialize to the fine-tuning data. Weight-space ensembling methods, such as Model Soups, mitigate this effect by averaging multiple checkpoints, but they are computationally prohibitive, requiring the training and storage of dozens of fine-tuned models. In this paper, we introduce MonoSoup, a simple, data-free, hyperparameter-free, post-hoc method that achieves a strong ID-OOD balance using only a single checkpoint. Our method applies Singular Value Decomposition (SVD) to each layer's update and decomposes it into high-energy directions that capture task-specific adaptation and low-energy directions that introduce noise but may still encode residual signals useful for robustness. MonoSoup then uses entropy-based effective rank to automatically re-weigh these components with layer-wise coefficients that account for the spectral and geometric structure of the model. Experiments on CLIP models fine-tuned on ImageNet and evaluated under natural distribution shifts, as well as on Qwen language models tested on mathematical reasoning and multiple-choice benchmarks, show that this plug-and-play approach is a practical and effective alternative to multi-checkpoint methods, retaining much of their benefits without their computational overhead.

</details>


### [240] [Contextual and Seasonal LSTMs for Time Series Anomaly Detection](https://arxiv.org/abs/2602.09690)
*Lingpei Zhang,Qingming Li,Yong Yang,Jiahao Chen,Rui Zeng,Chenyang Lyu,Shouling Ji*

Main category: cs.LG

TL;DR: 本文提出了一种名为CS-LSTMs的新型预测框架，通过噪声分解策略结合上下文依赖与季节性模式，并融合时域与频域表示，以提升对微小点异常和缓慢上升异常的检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于重构和预测的方法难以有效捕捉微小点异常和缓慢上升异常。

Method: 提出CS-LSTMs框架，基于噪声分解策略，联合建模上下文依赖与季节性模式，并融合时域与频域表示。

Result: 在多个公开基准数据集上的实验表明，CS-LSTMs持续优于当前最先进方法。

Conclusion: CS-LSTMs在鲁棒时间序列异常检测中具有显著有效性与实用价值。

Abstract: Univariate time series (UTS), where each timestamp records a single variable, serve as crucial indicators in web systems and cloud servers. Anomaly detection in UTS plays an essential role in both data mining and system reliability management. However, existing reconstruction-based and prediction-based methods struggle to capture certain subtle anomalies, particularly small point anomalies and slowly rising anomalies. To address these challenges, we propose a novel prediction-based framework named Contextual and Seasonal LSTMs (CS-LSTMs). CS-LSTMs are built upon a noise decomposition strategy and jointly leverage contextual dependencies and seasonal patterns, thereby strengthening the detection of subtle anomalies. By integrating both time-domain and frequency-domain representations, CS-LSTMs achieve more accurate modeling of periodic trends and anomaly localization. Extensive evaluations on public benchmark datasets demonstrate that CS-LSTMs consistently outperform state-of-the-art methods, highlighting their effectiveness and practical value in robust time series anomaly detection.

</details>


### [241] [Physics-informed diffusion models in spectral space](https://arxiv.org/abs/2602.09708)
*Davide Gallon,Philippe von Wurstemberger,Patrick Cheridito,Arnulf Jentzen*

Main category: cs.LG

TL;DR: 本文提出了一种结合生成式潜在扩散模型与物理信息机器学习的方法，用于在部分观测条件下生成参数化偏微分方程（PDE）的解，涵盖正向与反向PDE问题。该方法在缩放谱表示的潜在空间中建模参数与解的联合分布，利用扩散过程并引入物理约束和测量条件进行后验采样，显著提升了稀疏观测下的求解精度与计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在求解PDE时面临高维网格表示带来的计算负担，且难以保证解满足物理规律和算子定义域要求；亟需一种既能降维又能嵌入物理先验的生成式求解框架。

Method: 在谱表示的潜在空间中构建参数-解联合分布的扩散过程，以高斯噪声控制函数正则性；基于扩散后验采样，在每步推理中通过Adam优化施加物理约束（如PDE残差）和观测条件。

Result: 在Poisson、Helmholtz和不可压Navier-Stokes方程上验证，相比现有扩散类PDE求解器，在稀疏观测场景下精度更高、计算更高效。

Conclusion: 谱域潜在扩散结合物理引导的后验采样是一种有效且可扩展的参数化PDE求解新范式，兼顾表达能力、正则性保障与物理一致性。

Abstract: We propose a methodology that combines generative latent diffusion models with physics-informed machine learning to generate solutions of parametric partial differential equations (PDEs) conditioned on partial observations, which includes, in particular, forward and inverse PDE problems. We learn the joint distribution of PDE parameters and solutions via a diffusion process in a latent space of scaled spectral representations, where Gaussian noise corresponds to functions with controlled regularity. This spectral formulation enables significant dimensionality reduction compared to grid-based diffusion models and ensures that the induced process in function space remains within a class of functions for which the PDE operators are well defined. Building on diffusion posterior sampling, we enforce physics-informed constraints and measurement conditions during inference, applying Adam-based updates at each diffusion step. We evaluate the proposed approach on Poisson, Helmholtz, and incompressible Navier--Stokes equations, demonstrating improved accuracy and computational efficiency compared with existing diffusion-based PDE solvers, which are state of the art for sparse observations. Code is available at https://github.com/deeplearningmethods/PISD.

</details>


### [242] [BRAVA-GNN: Betweenness Ranking Approximation Via Degree MAss Inspired Graph Neural Network](https://arxiv.org/abs/2602.09716)
*Justin Dachille,Aurora Rossi,Sunil Kumar Maurya,Frederik Mallmann-Trenn,Xin Liu,Frédéric Giroire,Tsuyoshi Murata,Emanuele Natale*

Main category: cs.LG

TL;DR: 本文提出BRAVA-GNN，一种轻量级图神经网络，利用多跳度质量与介数中心性之间的经验相关性，并结合超双曲随机图模型生成更贴近真实网络（如道路网）结构的合成训练图，显著提升在高直径图上的泛化能力与推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN预测节点介数中心性的方法难以泛化到高直径图（如道路网络），且依赖不具代表性的无标度合成图。

Method: 提出BRAVA-GNN架构：以多跳度质量为尺寸不变节点特征；采用超双曲随机图模型生成匹配真实网络度分布的合成训练图；摒弃传统无标度图假设。

Result: 在19个真实网络（社交、网页、邮件、道路等）上实验表明，BRAVA-GNN相较SOTA方法Kendall-Tau相关性最高提升214%，推理速度最高快70倍，参数量减少54倍。

Conclusion: BRAVA-GNN通过引入更具普适性的结构先验和图生成模型，在保持轻量的同时显著提升了对多样化真实网络（尤其是道路网）的泛化能力和效率。

Abstract: Computing node importance in networks is a long-standing fundamental problem that has driven extensive study of various centrality measures. A particularly well-known centrality measure is betweenness centrality, which becomes computationally prohibitive on large-scale networks. Graph Neural Network (GNN) models have thus been proposed to predict node rankings according to their relative betweenness centrality. However, state-of-the-art methods fail to generalize to high-diameter graphs such as road networks. We propose BRAVA-GNN, a lightweight GNN architecture that leverages the empirically observed correlation linking betweenness centrality to degree-based quantities, in particular multi-hop degree mass. This correlation motivates the use of degree masses as size-invariant node features and synthetic training graphs that closely match the degree distributions of real networks. Furthermore, while previous work relies on scale-free synthetic graphs, we leverage the hyperbolic random graph model, which reproduces power-law exponents outside the scale-free regime, better capturing the structure of real-world graphs like road networks. This design enables BRAVA-GNN to generalize across diverse graph families while using 54x fewer parameters than the most lightweight existing GNN baseline. Extensive experiments on 19 real-world networks, spanning social, web, email, and road graphs, show that BRAVA-GNN achieves up to 214% improvement in Kendall-Tau correlation and up to 70x speedup in inference time over state-of-the-art GNN-based approaches, particularly on challenging road networks.

</details>


### [243] [ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm](https://arxiv.org/abs/2602.09726)
*Hanyong Wang,Menglong Yang*

Main category: cs.LG

TL;DR: 本文提出了一种新的PPO变体ExO-PPO，结合了on-policy的稳定性与off-policy的数据利用效率，通过扩展的off-policy改进、分段指数裁剪机制和多策略轨迹回放缓冲区，在多个任务上实现了更优的性能平衡。


<details>
  <summary>Details</summary>
Motivation: PPO虽稳定但样本效率低，off-policy方法数据利用高但方差和偏差大，需融合二者优势。

Method: 提出ExO-PPO：1）基于广义策略改进下界推导扩展的off-policy改进；2）引入分段指数函数改进裁剪机制；3）使用过去M个策略生成的轨迹构建回放缓冲区进行off-policy训练。

Result: 在多种任务上的实验表明，ExO-PPO相比PPO及其他SOTA变体，在样本效率与训练稳定性之间取得了更好平衡，性能更优。

Conclusion: ExO-PPO成功融合on-policy稳定性与off-policy数据效率，为深度强化学习提供了一种兼顾可靠性与高效性的新范式。

Abstract: Deep reinforcement learning has been able to solve various tasks successfully, however, due to the construction of policy gradient and training dynamics, tuning deep reinforcement learning models remains challenging. As one of the most successful deep reinforcement-learning algorithm, the Proximal Policy Optimization algorithm (PPO) clips the policy gradient within a conservative on-policy updates, which ensures reliable and stable policy improvement. However, this training pattern may sacrifice sample efficiency. On the other hand, off-policy methods make more adequate use of data through sample reuse, though at the cost of increased the estimation variance and bias. To leverage the advantages of both, in this paper, we propose a new PPO variant based on the stability guarantee from conservative on-policy iteration with a more efficient off-policy data utilization. Specifically, we first derive an extended off-policy improvement from an expectation form of generalized policy improvement lower bound. Then, we extend the clipping mechanism with segmented exponential functions for a suitable surrogate objective function. Third, the trajectories generated by the past $M$ policies are organized in the replay buffer for off-policy training. We refer to this method as Extended Off-policy Proximal Policy Optimization (ExO-PPO). Compared with PPO and some other state-of-the-art variants, we demonstrate an improved performance of ExO-PPO with balanced sample efficiency and stability on varied tasks in the empirical experiments.

</details>


### [244] [Towards Poisoning Robustness Certification for Natural Language Generation](https://arxiv.org/abs/2602.09757)
*Mihnea Ghitu,Matthew Wicker*

Main category: cs.LG

TL;DR: 本文提出了Targeted Partition Aggregation（TPA）算法，首次为自然语言生成任务提供针对有害输出的可证明鲁棒性认证，涵盖稳定性与有效性两类安全属性，并通过MILP扩展支持多轮生成，实验证明其在工具调用和偏好对齐等场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有针对分类任务的认证中毒防御方法无法适配自回归文本生成任务，因其难以处理序列预测及语言模型巨大的输出空间；亟需建立面向自然语言生成的可证明鲁棒性认证框架。

Method: 形式化定义了生成任务中的稳定性（对任意生成变化的鲁棒性）和有效性（对定向有害变化的鲁棒性）两类安全属性；提出Targeted Partition Aggregation（TPA）算法，用于计算诱导特定有害输出所需的最小数据投毒预算；进一步结合混合整数线性规划（MILP）扩展TPA，以提升多轮生成下的认证紧致性。

Result: 在多个实际场景中验证了TPA的有效性：如在数据集被最多0.5%污染时仍能认证智能体工具调用的有效性，以及在偏好对齐中认证8-token长度的稳定性生成范围。

Conclusion: TPA是首个支持自然语言生成中定向攻击认证的算法，为安全敏感领域中大语言模型的可信部署提供了理论基础与实用工具，尽管推理延迟仍是待解挑战。

Abstract: Understanding the reliability of natural language generation is critical for deploying foundation models in security-sensitive domains. While certified poisoning defenses provide provable robustness bounds for classification tasks, they are fundamentally ill-equipped for autoregressive generation: they cannot handle sequential predictions or the exponentially large output space of language models. To establish a framework for certified natural language generation, we formalize two security properties: stability (robustness to any change in generation) and validity (robustness to targeted, harmful changes in generation). We introduce Targeted Partition Aggregation (TPA), the first algorithm to certify validity/targeted attacks by computing the minimum poisoning budget needed to induce a specific harmful class, token, or phrase. Further, we extend TPA to provide tighter guarantees for multi-turn generations using mixed integer linear programming (MILP). Empirically, we demonstrate TPA's effectiveness across diverse settings including: certifying validity of agent tool-calling when adversaries modify up to 0.5% of the dataset and certifying 8-token stability horizons in preference-based alignment. Though inference-time latency remains an open challenge, our contributions enable certified deployment of language models in security-critical applications.

</details>


### [245] [Grounding LTL Tasks in Sub-Symbolic RL Environments for Zero-Shot Generalization](https://arxiv.org/abs/2602.09761)
*Matteo Pannacci,Andrea Fanti,Elena Umili,Roberto Capobianco*

Main category: cs.LG

TL;DR: 本文提出了一种无需预定义符号映射的多任务强化学习方法，通过联合训练策略网络与符号接地器（symbol grounder），利用神经奖励机（Neural Reward Machines）从原始视觉观测和稀疏奖励中半监督地学习符号语义，从而在时序逻辑指令指导下完成多任务。


<details>
  <summary>Details</summary>
Motivation: 以往多任务RL方法依赖于观测到符号之间的已知映射，该假设在真实环境中不现实；本文旨在摆脱这一限制，在子符号（sub-symbolic）环境中实现对线性时序逻辑（LTL）指令的泛化执行能力。

Method: 联合训练一个多任务策略网络和一个符号接地器，二者共享同一经验数据；符号接地器通过神经奖励机（Neural Reward Machines）以半监督方式，仅从原始视觉观测和稀疏奖励中学习将观测映射为LTL公式中所需的符号。

Result: 在基于视觉的环境中，该方法性能接近使用真实符号接地的上限，并显著优于当前子符号环境下的最先进方法。

Conclusion: 联合策略与符号接地的端到端学习是可行且有效的，能消除对人工符号标注的依赖，提升RL智能体在复杂、未结构化环境中的多任务泛化能力。

Abstract: In this work we address the problem of training a Reinforcement Learning agent to follow multiple temporally-extended instructions expressed in Linear Temporal Logic in sub-symbolic environments. Previous multi-task work has mostly relied on knowledge of the mapping between raw observations and symbols appearing in the formulae. We drop this unrealistic assumption by jointly training a multi-task policy and a symbol grounder with the same experience. The symbol grounder is trained only from raw observations and sparse rewards via Neural Reward Machines in a semi-supervised fashion. Experiments on vision-based environments show that our method achieves performance comparable to using the true symbol grounding and significantly outperforms state-of-the-art methods for sub-symbolic environments.

</details>


### [246] [Explainability in Generative Medical Diffusion Models: A Faithfulness-Based Analysis on MRI Synthesis](https://arxiv.org/abs/2602.09781)
*Surjo Dey,Pallabi Saikia*

Main category: cs.LG

TL;DR: 本文提出了一种基于可信度的可解释性框架，用于分析生成式扩散模型在MRI合成中的决策过程，发现EPPNet具有最高的可信度（0.1534），提升了模型在医疗AI中的透明性与可信性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在医学图像生成中表现优异，但其内部决策过程不透明，限制了其在临床中的可信应用。

Method: 构建基于可信度的可解释性框架，结合原型类方法（ProtoPNet、EPPNet、ProtoPool）分析扩散模型去噪轨迹与训练特征之间的关联。

Result: EPPNet在可信度指标上表现最优（0.1534），能提供更可靠的生成过程解释；实验验证了该框架可提升扩散模型的可解释性与可信度。

Conclusion: 基于可信度的解释方法可有效增强扩散模型在医学影像生成中的透明性与可靠性，推动可解释生成式AI在医疗健康领域的安全落地。

Abstract: This study investigates the explainability of generative diffusion models in the context of medical imaging, focusing on Magnetic resonance imaging (MRI) synthesis. Although diffusion models have shown strong performance in generating realistic medical images, their internal decision making process remains largely opaque. We present a faithfulness-based explainability framework that analyzes how prototype-based explainability methods like ProtoPNet (PPNet), Enhanced ProtoPNet (EPPNet), and ProtoPool can link the relationship between generated and training features. Our study focuses on understanding the reasoning behind image formation through denoising trajectory of diffusion model and subsequently prototype explainability with faithfulness analysis. Experimental analysis shows that EPPNet achieves the highest faithfulness (with score 0.1534), offering more reliable insights, and explainability into the generative process. The results highlight that diffusion models can be made more transparent and trustworthy through faithfulness-based explanations, contributing to safer and more interpretable applications of generative AI in healthcare.

</details>


### [247] [When Less is More: The LLM Scaling Paradox in Context Compression](https://arxiv.org/abs/2602.09789)
*Ruishan Guo,Yibing Liu,Guoxin Ma,Yan Wang,Yueyang Zhang,Long Xia,Kecheng Chen,Zhiyuan Sun,Daiting Shi*

Main category: cs.LG

TL;DR: 本文揭示了在压缩器-解码器架构中，增大压缩器模型参数量反而会降低上下文重建保真度的‘尺寸-保真度悖论’，并指出其根源在于知识覆盖和语义漂移，而非参数量本身。


<details>
  <summary>Details</summary>
Motivation: 探究为何在损失压缩上下文的场景下，增大压缩器模型规模反而损害重建保真度，挑战‘越大越好’的缩放范式。

Method: 在0.6B至90B参数规模的模型上开展大量实验，分析知识覆盖与语义漂移现象，并从上下文嵌入秩与token预测分布熵角度解释机制。

Result: 发现更大模型更易用自身先验知识覆盖原始事实（如‘白草莓’→‘红草莓’），并倾向于改写而非忠实复现（如‘Alice hit Bob’→‘Bob hit Alice’）；保真度下降主因是语义容量过剩与生成不确定性增强。

Conclusion: 参数规模本身不是问题，真正导致保真度下降的是伴随缩放而来的过高语义容量和生成不确定性；该发现揭示了开放生成中保真压缩的缩放定律失效。

Abstract: Scaling up model parameters has long been a prevalent training paradigm driven by the assumption that larger models yield superior generation capabilities. However, under lossy context compression in a compressor-decoder setup, we observe a Size-Fidelity Paradox: increasing the compressor size can lessen the faithfulness of reconstructed contexts though training loss decreases. Through extensive experiments across models from 0.6B to 90B, we coin this paradox arising from two dominant factors: 1) knowledge overwriting: larger models increasingly replace source facts with their own prior beliefs, e.g., ``the white strawberry'' $\to$ ``the red strawberry''; and 2) semantic drift: larger models tend to paraphrase or restructure content instead of reproducing it verbatim, e.g., ``Alice hit Bob'' $\to$ ``Bob hit Alice''. By holding model size fixed, we reflect on the emergent properties of compressed context representations. We show that the culprit is not parameter count itself, but the excessive semantic capacity and amplified generative uncertainty that accompany scaling. Specifically, the increased rank of context embeddings facilitates prior knowledge intrusion, whereas higher entropy over token prediction distributions promotes rewriting. Our results complement existing evaluations over context compression paradigm, underpinning a breakdown in scaling laws for faithful preservation in open-ended generation.

</details>


### [248] [Fully-automated sleep staging: multicenter validation of a generalizable deep neural network for Parkinson's disease and isolated REM sleep behavior disorder](https://arxiv.org/abs/2602.09793)
*Jesper Strøm,Casper Skjærbæk,Natasha Becker Bertelsen,Steffen Torpe Simonsen,Niels Okkels,David Bertram,Sinah Röttgen,Konstantin Kufer,Kaare B. Mikkelsen,Marit Otto,Poul Jørgen Jennum,Per Borghammer,Michael Sommerauer,Preben Kidmose*

Main category: cs.LG

TL;DR: 本文提出了一种基于U-Sleep深度神经网络的改进方法，通过在PD和iRBD患者数据上微调预训练模型，显著提升了REM睡眠自动分期的准确性与泛化能力，并利用置信度阈值进一步优化REM识别性能。


<details>
  <summary>Details</summary>
Motivation: 手动PSG睡眠分期在帕金森病（PD）和孤立性快动眼期行为障碍（iRBD）患者中困难且耗时，限制了RBD大规模筛查技术的应用；需提升自动睡眠分期模型在神经退行性疾病人群中的泛化能力。

Method: 在大型非神经退行性多中心PSG数据集（PUB）上预训练U-Sleep模型，再于两个PD/iRBD研究队列（PACE和CBC）上微调；在独立验证集（DCSM）评估性能；对人机分歧大（κ<0.6）的样本进行双盲人工复评；引入置信度阈值优化REM期识别。

Result: 微调后模型在PACE/CBC上κ达0.74（p<0.001），优于直接迁移的预训练模型（κ=0.66）；在DCSM验证集中平均κ从0.60提升至0.64，中位κ从0.64升至0.69（均p<0.001）；置信度筛选使REM期识别准确率从85%升至95.5%，且95%受试者仍保留足够（>5分钟）REM睡眠用于分析。

Conclusion: U-Sleep经针对性微调后可在PD和iRBD人群中实现更鲁棒、可推广的自动睡眠分期，尤其改善REM期识别；人机分歧主要源于人类评分者间固有差异，说明模型已接近人类水平；置信度阈值策略可有效提升临床可用性。

Abstract: Isolated REM sleep behavior disorder (iRBD) is a key prodromal marker of Parkinson's disease (PD), and video-polysomnography (vPSG) remains the diagnostic gold standard. However, manual sleep staging is particularly challenging in neurodegenerative diseases due to EEG abnormalities and fragmented sleep, making PSG assessments a bottleneck for deploying new RBD screening technologies at scale. We adapted U-Sleep, a deep neural network, for generalizable sleep staging in PD and iRBD. A pretrained U-Sleep model, based on a large publicly available, multisite non-neurodegenerative dataset (PUB; 19,236 PSGs across 12 sites), was fine-tuned on research datasets from two centers (Lundbeck Foundation Parkinson's Disease Research Center (PACE) and the Cologne-Bonn Cohort (CBC); 112 PD, 138 iRBD, 89 age-matched controls. The resulting model was evaluated on an independent dataset from the Danish Center for Sleep Medicine (DCSM; 81 PD, 36 iRBD, 87 sleep-clinic controls). A subset of PSGs with low agreement between the human rater and the model (\k{appa} < 0.6) was re-scored by a second blinded human rater to identify sources of disagreement. Finally, we applied confidence-based thresholds to optimize REM sleep staging. The pretrained model achieved mean \k{appa} = 0.81 in PUB, but \k{appa} = 0.66 when applied directly to PACE/CBC. By fine-tuning the model, we developed a generalized model with \k{appa} = 0.74 on PACE/CBC (p < 0.001 vs. the pretrained model). In DCSM, mean and median \k{appa} increased from 0.60 to 0.64 (p < 0.001) and 0.64 to 0.69 (p < 0.001), respectively. In the interrater study, PSGs with low agreement between the model and the initial scorer showed similarly low agreement between human scorers. Applying a confidence threshold increased the proportion of correctly identified REM sleep epochs from 85% to 95.5%, while preserving sufficient (> 5 min) REM sleep for 95% of subjects.

</details>


### [249] [A Controlled Study of Double DQN and Dueling DQN Under Cross-Environment Transfer](https://arxiv.org/abs/2602.09810)
*Azka Nasir,Fatima Dossa,Muhammad Ahmed Atif,Mohammad Ahmed Atif*

Main category: cs.LG

TL;DR: 本文通过控制实验研究了DDQN和Dueling DQN在跨环境迁移学习中的表现差异，发现DDQN能避免负迁移且保持稳定，而Dueling DQN则一致出现负迁移；表明网络架构的归纳偏置对迁移鲁棒性有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探究深度强化学习中不同网络架构（DDQN vs Dueling DQN）如何影响迁移学习的稳定性与有效性，尤其在存在较大领域偏移时为何迁移可能失败。

Method: 在CartPole（源任务）到LunarLander（目标任务）之间采用固定层间表征迁移协议，控制超参数与训练条件一致，并与从零训练的基线模型对比；进行多随机种子统计分析。

Result: DDQN在迁移中始终避免负迁移，性能与基线相当；Dueling DQN则一致出现负迁移，表现为奖励下降与优化不稳定；统计检验确认二者性能差异显著。

Conclusion: 在所考察的迁移协议下，价值函数型深度强化学习中网络架构的归纳偏置是决定跨环境迁移鲁棒性的关键因素。

Abstract: Transfer learning in deep reinforcement learning is often motivated by improved stability and reduced training cost, but it can also fail under substantial domain shift. This paper presents a controlled empirical study examining how architectural differences between Double Deep Q-Networks (DDQN) and Dueling DQN influence transfer behavior across environments. Using CartPole as a source task and LunarLander as a structurally distinct target task, we evaluate a fixed layer-wise representation transfer protocol under identical hyperparameters and training conditions, with baseline agents trained from scratch used to contextualize transfer effects. Empirical results show that DDQN consistently avoids negative transfer under the examined setup and maintains learning dynamics comparable to baseline performance in the target environment. In contrast, Dueling DQN consistently exhibits negative transfer under identical conditions, characterized by degraded rewards and unstable optimization behavior. Statistical analysis across multiple random seeds confirms a significant performance gap under transfer. These findings suggest that architectural inductive bias is strongly associated with robustness to cross-environment transfer in value-based deep reinforcement learning under the examined transfer protocol.

</details>


### [250] [PlugSI: Plug-and-Play Test-Time Graph Adaptation for Spatial Interpolation](https://arxiv.org/abs/2602.09824)
*Xuhang Wu,Zhuoxuan Liang,Wei Li,Xiaohua Jia,Sumi Helal*

Main category: cs.LG

TL;DR: 本文提出PlugSI框架，通过未知拓扑适配器（UTA）和时序平衡适配器（TBA）实现测试时图结构自适应与历史一致性引导，提升空间插值模型在未见大规模图上的泛化能力与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的空间插值方法依赖预训练模型，难以适应测试时更大或未见过的图结构，且未充分利用测试数据，导致可扩展性与鲁棒性受限。

Method: 提出PlugSI插件式框架，包含两个核心组件：1）未知拓扑适配器（UTA），在测试时对每个小批量图结构进行动态适配；2）时序平衡适配器（TBA），利用稳定的历史共识指导UTA，抑制当前批次噪声引起的漂移。

Result: 实验表明PlugSI可无缝集成到现有图空间插值方法中，在MAE等指标上显著提升（如MAE降低10.81%）。

Conclusion: PlugSI是一种轻量、即插即用的测试时适配框架，有效提升了空间插值模型对未知图结构的泛化能力与抗噪鲁棒性，为大规模传感器部署提供了实用支持。

Abstract: With the rapid advancement of IoT and edge computing, sensor networks have become indispensable, driving the need for large-scale sensor deployment. However, the high deployment cost hinders their scalability. To tackle the issues, Spatial Interpolation (SI) introduces virtual sensors to infer readings from observed sensors, leveraging graph structure. However, current graph-based SI methods rely on pre-trained models, lack adaptation to larger and unseen graphs at test-time, and overlook test data utilization. To address these issues, we propose PlugSI, a plug-and-play framework that refines test-time graph through two key innovations. First, we design an Unknown Topology Adapter (UTA) that adapts to the new graph structure of each small-batch at test-time, enhancing the generalization of SI pre-trained models. Second, we introduce a Temporal Balance Adapter (TBA) that maintains a stable historical consensus to guide UTA adaptation and prevent drifting caused by noise in the current batch. Empirically, extensive experiments demonstrate PlugSI can be seamlessly integrated into existing graph-based SI methods and provide significant improvement (e.g., a 10.81% reduction in MAE).

</details>


### [251] [CoFEH: LLM-driven Feature Engineering Empowered by Collaborative Bayesian Hyperparameter Optimization](https://arxiv.org/abs/2602.09851)
*Beicheng Xu,Keyao Ding,Wei Liu,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: 本文提出CoFEH框架，通过LLM驱动的特征工程（FE）与贝叶斯超参优化（HPO）协同交替优化，引入Tree of Thought和互条件机制实现端到端AutoML。


<details>
  <summary>Details</summary>
Motivation: 传统FE方法受限于预定义搜索空间且缺乏领域感知；现有LLM方法仅支持孤立子任务、未与HPO联合优化，导致次优的贪心流程。

Method: 提出CoFEH：1）基于Tree of Thought的LLM驱动FE优化器构建自由形式FE流水线；2）贝叶斯优化模块处理HPO；3）动态优化器选择器实现FE与HPO交替调度；4）LLM与BO间互条件机制共享上下文。

Result: 实验表明CoFEH在特征工程和端到端AutoML性能上均优于传统及LLM基线方法。

Conclusion: CoFEH通过LLM与BO的协同交替优化及互条件机制，有效建模FE-HPO强交互，显著提升AutoML鲁棒性与性能。

Abstract: Feature Engineering (FE) is pivotal in automated machine learning (AutoML) but remains a bottleneck for traditional methods, which treat it as a black-box search, operating within rigid, predefined search spaces and lacking domain awareness. While Large Language Models (LLMs) offer a promising alternative by leveraging semantic reasoning to generate unbounded operators, existing methods fail to construct free-form FE pipelines, remaining confined to isolated subtasks such as feature generation. Most importantly, they are rarely optimized jointly with hyperparameter optimization (HPO) of the ML model, leading to greedy "FE-then-HPO" workflows that cannot capture strong FE-HPO interactions. In this paper, we present CoFEH, a collaborative framework that interleaves LLM-based FE and Bayesian HPO for robust end-to-end AutoML. CoFEH uses an LLM-driven FE optimizer powered by Tree of Thought (ToT) to explore flexible FE pipelines, a Bayesian optimization (BO) module to solve HPO, and a dynamic optimizer selector that realizes interleaved optimization by adaptively scheduling FE and HPO steps. Crucially, we introduce a mutual conditioning mechanism that shares context between LLM and BO, enabling mutually informed decisions. Experiments show that CoFEH not only outperforms traditional and LLM-based FE baselines, but also achieves superior end-to-end performance under joint optimization.

</details>


### [252] [Differentiable Tripartite Modularity for Clustering Heterogeneous Graphs](https://arxiv.org/abs/2602.09864)
*Benoît Hurpeau*

Main category: cs.LG

TL;DR: 本文提出了一种可微分的三部图模块度（tripartite modularity）公式，用于异构关系图（含三种节点类型）的端到端社区发现，避免高阶张量计算，引入结构归一化以稳定优化，并在大规模城市地籍数据上验证了其有效性与空间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有可微模块度方法（如DMoN）仅适用于同质或二部图，难以扩展至含三种及以上实体类型的高阶异构图，而现实世界中（如城市地籍系统）常存在多类型中介交互结构。

Method: 提出基于加权共路径（weighted co-paths）定义三部图社区结构的可微模块度目标函数；采用精确因式分解策略避免显式构建稠密三阶张量；在枢纽节点引入结构归一化以缓解极端度异质性；支持与图神经网络联合端到端优化，时间复杂度为边数线性。

Result: 在大规模城市地籍数据上验证，模型展现出鲁棒收敛性与空间连贯的聚类结果，优于现有方法。

Conclusion: 可微分三部模块度是一种通用、高效且稳定的异构图无监督聚类基础方法，为高阶关系建模提供了新范式。

Abstract: Clustering heterogeneous relational data remains a central challenge in graph learning, particularly when interactions involve more than two types of entities. While differentiable modularity objectives such as DMoN have enabled end-to-end community detection on homogeneous and bipartite graphs, extending these approaches to higher-order relational structures remains non-trivial.
  In this work, we introduce a differentiable formulation of tripartite modularity for graphs composed of three node types connected through mediated interactions. Community structure is defined in terms of weighted co-paths across the tripartite graph, together with an exact factorized computation that avoids the explicit construction of dense third-order tensors. A structural normalization at pivot nodes is introduced to control extreme degree heterogeneity and ensure stable optimization.
  The resulting objective can be optimized jointly with a graph neural network in an end-to-end manner, while retaining linear complexity in the number of edges. We validate the proposed framework on large-scale urban cadastral data, where it exhibits robust convergence behavior and produces spatially coherent partitions. These results highlight differentiable tripartite modularity as a generic methodological building block for unsupervised clustering of heterogeneous graphs.

</details>


### [253] [Statistical benchmarking of transformer models in low signal-to-noise time-series forecasting](https://arxiv.org/abs/2602.09869)
*Cyril Garcia,Guillaume Remy*

Main category: cs.LG

TL;DR: 本文研究了在仅有几年日观测数据的低数据场景下，Transformer架构在多变量时间序列预测中的性能表现。作者通过合成数据实验发现，采用时序与横截面交替自注意力机制的双路注意力Transformer模型，在多种设置（包括低信噪比环境）下均优于Lasso、提升方法和全连接MLP等基线模型；并提出一种训练中动态稀疏化注意力矩阵的方法，在强噪声环境下显著提升性能；注意力模式分析还揭示了其与经典回归中稀疏正则化的联系。


<details>
  <summary>Details</summary>
Motivation: 解决多变量时间序列预测在低数据量（仅几年日观测）且高噪声条件下的建模难题，探究Transformer架构是否及如何在此类挑战性场景中有效工作。

Method: 1) 构建具有已知时序与横截面依赖结构、可控信噪比的合成时间序列数据；2) 设计双路注意力Transformer（交替进行时间维度和变量维度的自注意力）；3) 提出训练中动态稀疏化注意力矩阵的方法；4) 通过自助法（bootstrapped）实验，以外部最优预测器为基准，用样本外相关系数评估模型性能；5) 分析学习到的注意力模式以解释泛化能力。

Result: 双路注意力Transformer在宽泛设置（尤其低信噪比）下显著优于Lasso、提升方法和MLP；动态稀疏化注意力在目标变量与最优预测器相关性仅为百分之几的强噪声环境中效果突出；注意力模式呈现可解释结构，并与经典稀疏正则化存在概念关联。

Conclusion: 双路注意力Transformer及其动态稀疏化策略是低数据、高噪声多变量时间序列预测的有效方法；其成功部分源于注意力机制隐式实现的结构化稀疏正则化，提升了模型鲁棒性与可解释性。

Abstract: We study the performance of transformer architectures for multivariate time-series forecasting in low-data regimes consisting of only a few years of daily observations. Using synthetically generated processes with known temporal and cross-sectional dependency structures and varying signal-to-noise ratios, we conduct bootstrapped experiments that enable direct evaluation via out-of-sample correlations with the optimal ground-truth predictor. We show that two-way attention transformers, which alternate between temporal and cross-sectional self-attention, can outperform standard baselines-Lasso, boosting methods, and fully connected multilayer perceptrons-across a wide range of settings, including low signal-to-noise regimes. We further introduce a dynamic sparsification procedure for attention matrices applied during training, and demonstrate that it becomes significantly effective in noisy environments, where the correlation between the target variable and the optimal predictor is on the order of a few percent. Analysis of the learned attention patterns reveals interpretable structure and suggests connections to sparsity-inducing regularization in classical regression, providing insight into why these models generalize effectively under noise.

</details>


### [254] [Safeguarding Privacy: Privacy-Preserving Detection of Mind Wandering and Disengagement Using Federated Learning in Online Education](https://arxiv.org/abs/2602.09904)
*Anna Bodonhelyi,Mengdi Wang,Efe Bozkir,Babette Bühler,Enkelejda Kasneci*

Main category: cs.LG

TL;DR: 本文提出了一种基于跨设备联邦学习的视频分析框架，用于在远程在线学习中实时检测行为与认知层面的分心（如走神、无聊、行为脱离），同时保护用户隐私；通过融合面部表情与视线特征，并针对性优化眼镜佩戴者场景，模型在五个数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情后在线教育普及，但缺乏教师直接支持导致学习者自我调节困难，分心现象影响学习效果；而传统基于机器学习的自动检测方法需共享敏感视频数据，存在隐私风险。

Method: 提出基于跨设备联邦学习的框架，利用本地设备上的面部表情和视线特征构建认知分心检测模型；引入针对戴眼镜用户的特征增强策略；在五个数据集上对比多种联邦学习算法。

Result: 所提方法在多个数据集上展现出良好的检测性能，尤其在戴眼镜场景下通过特征优化提升了鲁棒性；验证了联邦学习在保障隐私前提下实现有效实时学习支持的可行性。

Conclusion: 该工作为隐私优先的智能教育技术提供了可行路径，证明联邦学习可兼顾数据安全与模型效能，推动远程学习中个性化、实时化干预的发展。

Abstract: Since the COVID-19 pandemic, online courses have expanded access to education, yet the absence of direct instructor support challenges learners' ability to self-regulate attention and engagement. Mind wandering and disengagement can be detrimental to learning outcomes, making their automated detection via video-based indicators a promising approach for real-time learner support. However, machine learning-based approaches often require sharing sensitive data, raising privacy concerns. Federated learning offers a privacy-preserving alternative by enabling decentralized model training while also distributing computational load. We propose a framework exploiting cross-device federated learning to address different manifestations of behavioral and cognitive disengagement during remote learning, specifically behavioral disengagement, mind wandering, and boredom. We fit video-based cognitive disengagement detection models using facial expressions and gaze features. By adopting federated learning, we safeguard users' data privacy through privacy-by-design and introduce a novel solution with the potential for real-time learner support. We further address challenges posed by eyeglasses by incorporating related features, enhancing overall model performance. To validate the performance of our approach, we conduct extensive experiments on five datasets and benchmark multiple federated learning algorithms. Our results show great promise for privacy-preserving educational technologies promoting learner engagement.

</details>


### [255] [Drug Release Modeling using Physics-Informed Neural Networks](https://arxiv.org/abs/2602.09963)
*Daanish Aleem Qureshi,Khemraj Shukla,Vikas Srivastava*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息神经网络（PINNs）和贝叶斯PINNs（BPINNs）的新方法，用于预测不同几何结构（平面、1D褶皱、2D皱缩）薄膜的药物释放行为；该方法融合Fick第二定律与少量实验数据，在仅用早期6%-33%释放时间数据的情况下，显著优于经典模型（误差降低达40%，RMSE<0.05），并提供更可靠的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 经典药物释放模型（如Fick、Higuchi、Peppas）因简化假设难以准确刻画复杂几何与释放机制，亟需兼顾物理可解释性与数据效率的新建模方法。

Method: 将Fick第二定律嵌入PINN损失函数，使用10,000个拉丁超立方配点；在平面、1D褶皱、2D皱缩薄膜上，基于公开实验数据，采用MAE和RMSE评估性能，并对比经典模型；进一步构建BPINNs以提升噪声和小样本下的不确定性量化能力。

Result: PINN在所有膜型上相对经典模型平均误差降低最多达40%；平面膜仅用前6%释放时间数据即达RMSE<0.05（节省94%实验时间）；褶皱与皱缩膜分别在33%数据下达到同等精度；BPINNs在噪声条件下给出更紧致、可靠的不确定性估计。

Conclusion: PINNs/BPINNs框架成功融合物理规律与稀疏实验数据，实现了高精度、长时程药物释放预测，为控释系统快速表征与早期配方优化提供了实用新范式。

Abstract: Accurate modeling of drug release is essential for designing and developing controlled-release systems. Classical models (Fick, Higuchi, Peppas) rely on simplifying assumptions that limit their accuracy in complex geometries and release mechanisms. Here, we propose a novel approach using Physics-Informed Neural Networks (PINNs) and Bayesian PINNs (BPINNs) for predicting release from planar, 1D-wrinkled, and 2D-crumpled films. This approach uniquely integrates Fick's diffusion law with limited experimental data to enable accurate long-term predictions from short-term measurements, and is systematically benchmarked against classical drug release models. We embedded Fick's second law into PINN as loss with 10,000 Latin-hypercube collocation points and utilized previously published experimental datasets to assess drug release performance through mean absolute error (MAE) and root mean square error (RMSE), considering noisy conditions and limited-data scenarios. Our approach reduced mean error by up to 40% relative to classical baselines across all film types. The PINN formulation achieved RMSE <0.05 utilizing only the first 6% of the release time data (reducing 94% of release time required for the experiments) for the planar film. For wrinkled and crumpled films, the PINN reached RMSE <0.05 in 33% of the release time data. BPINNs provide tighter and more reliable uncertainty quantification under noise. By combining physical laws with experimental data, the proposed framework yields highly accurate long-term release predictions from short-term measurements, offering a practical route for accelerated characterization and more efficient early-stage drug release system formulation.

</details>


### [256] [Causal Identification in Multi-Task Demand Learning with Confounding](https://arxiv.org/abs/2602.09969)
*Varun Gupta,Vijay Kamble*

Main category: cs.LG

TL;DR: 本文提出了一种名为DCMOML的新框架，用于在存在内生性（即历史价格与未观测需求因素相关）的情况下，从多任务、小样本数据中因果识别异质性价格响应函数。


<details>
  <summary>Details</summary>
Motivation: 零售定价中需估计大量决策场景下的异质线性价格响应函数，但各场景历史价格变化有限且存在内生性（价格由管理者/算法设定，与未观测需求因素相关），导致传统方法（如联合回归、元学习）无法识别因果效应。

Method: 提出Decision-Conditioned Masked-Outcome Meta-Learning（DCMOML）：通过精心设计元学习器的信息集，在利用跨任务异质性的同时处理内生决策历史；在价格适应性较弱的温和假设下，实现对任务特异性因果参数条件均值的识别。

Result: DCMOML可在内生价格和每任务样本量小的前提下，实现大规模需求估计的因果识别，并提供理论保证。

Conclusion: 该方法为在实际运营环境中部署因果驱动的定价模型提供了原理性基础，解决了多任务需求学习中的内生性难题。

Abstract: We study a canonical multi-task demand learning problem motivated by retail pricing, in which a firm seeks to estimate heterogeneous linear price-response functions across a large collection of decision contexts. Each context is characterized by rich observable covariates yet typically exhibits only limited historical price variation, motivating the use of multi-task learning to borrow strength across tasks. A central challenge in this setting is endogeneity: historical prices are chosen by managers or algorithms and may be arbitrarily correlated with unobserved, task-level demand determinants. Under such confounding by latent fundamentals, commonly used approaches, such as pooled regression and meta-learning, fail to identify causal price effects.
  We propose a new estimation framework that achieves causal identification despite arbitrary dependence between prices and latent task structure. Our approach, Decision-Conditioned Masked-Outcome Meta-Learning (DCMOML), involves carefully designing the information set of a meta-learner to leverage cross-task heterogeneity while accounting for endogenous decision histories. Under a mild restriction on price adaptivity in each task, we establish that this method identifies the conditional mean of the task-specific causal parameters given the designed information set. Our results provide guarantees for large-scale demand estimation with endogenous prices and small per-task samples, offering a principled foundation for deploying causal, data-driven pricing models in operational environments.

</details>


### [257] [Supervised Metric Regularization Through Alternating Optimization for Multi-Regime Physics-Informed Neural Networks](https://arxiv.org/abs/2602.09980)
*Enzo Nicolas Spotorno,Josafat Ribeiro Leal,Antonio Augusto Frohlich*

Main category: cs.LG

TL;DR: 本文提出了一种拓扑感知的物理信息神经网络（TAPINN），通过监督度量正则化构建隐空间，以解决标准PINN在建模具有尖锐相变（如分岔）的参数化动力系统时出现的谱偏差和模式坍塌问题。实验表明，TAPINN显著降低物理残差、梯度方差，并减少参数量。


<details>
  <summary>Details</summary>
Motivation: 标准PINN在处理具有尖锐 regime 转变（如分岔）的参数化动力系统时，因连续映射导致谱偏差或模式坍塌，难以准确表征不同物理行为。

Method: 提出Topology-Aware PINN（TAPINN），采用监督度量正则化构造反映不同物理态间度量分离的隐状态，并引入基于相位的交替优化（AO）策略协调度量与物理目标的梯度冲突。

Result: 在Duffing振子实验中，TAPINN相较标准PINN降低约49%物理残差（0.082 vs. 0.160），梯度方差比Sobolev误差基线低2.18倍，参数量比超网络方法少5倍，且避免过拟合与物理不一致性。

Conclusion: TAPINN通过显式建模参数空间的拓扑结构，有效缓解了PINN在多模态动力系统建模中的固有缺陷，提升了泛化性、稳定性与物理保真度。

Abstract: Standard Physics-Informed Neural Networks (PINNs) often face challenges when modeling parameterized dynamical systems with sharp regime transitions, such as bifurcations. In these scenarios, the continuous mapping from parameters to solutions can result in spectral bias or "mode collapse", where the network averages distinct physical behaviors. We propose a Topology-Aware PINN (TAPINN) that aims to mitigate this challenge by structuring the latent space via Supervised Metric Regularization. Unlike standard parametric PINNs that map physical parameters directly to solutions, our method conditions the solver on a latent state optimized to reflect the metric-based separation between regimes, showing ~49% lower physics residual (0.082 vs. 0.160). We train this architecture using a phase-based Alternating Optimization (AO) schedule to manage gradient conflicts between the metric and physics objectives. Preliminary experiments on the Duffing Oscillator demonstrate that while standard baselines suffer from spectral bias and high-capacity Hypernetworks overfit (memorizing data while violating physics), our approach achieves stable convergence with 2.18x lower gradient variance than a multi-output Sobolev Error baseline, and 5x fewer parameters than a hypernetwork-based alternative.

</details>


### [258] [Online Monitoring Framework for Automotive Time Series Data using JEPA Embeddings](https://arxiv.org/abs/2602.09985)
*Alexander Fertig,Karthikeyan Chandra Sekaran,Lakshman Balasubramanian,Michael Botsch*

Main category: cs.LG

TL;DR: 本文提出了一种无需异常标签的在线监控框架，利用JEPA自监督嵌入方法将目标数据映射到潜在空间，再结合传统异常检测方法识别自动驾驶中物体状态表示的未知异常。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆部署后需持续监控以保障安全，但现实中未知异常缺乏标注数据，亟需无监督/自监督的在线异常检测方法。

Method: 构建基于JEPA（Joint Embedding Predictive Architecture）的自监督预测任务，学习物体状态数据的潜在嵌入表示；将学到的嵌入作为输入，接入经典异常检测算法进行异常识别。

Result: 在真实世界nuScenes数据集上的实验验证了该框架对未知异常的有效检测能力，证明其适用于实际运行环境。

Conclusion: 所提框架成功实现了无需异常标签的在线异常监测，在自动驾驶等开放动态场景中具有实用价值和推广潜力。

Abstract: As autonomous vehicles are rolled out, measures must be taken to ensure their safe operation. In order to supervise a system that is already in operation, monitoring frameworks are frequently employed. These run continuously online in the background, supervising the system status and recording anomalies. This work proposes an online monitoring framework to detect anomalies in object state representations. Thereby, a key challenge is creating a framework for anomaly detection without anomaly labels, which are usually unavailable for unknown anomalies. To address this issue, this work applies a self-supervised embedding method to translate object data into a latent representation space. For this, a JEPA-based self-supervised prediction task is constructed, allowing training without anomaly labels and the creation of rich object embeddings. The resulting expressive JEPA embeddings serve as input for established anomaly detection methods, in order to identify anomalies within object state representations. This framework is particularly useful for applications in real-world environments, where new or unknown anomalies may occur during operation for which there are no labels available. Experiments performed on the publicly available, real-world nuScenes dataset illustrate the framework's capabilities.

</details>


### [259] [Infusion: Shaping Model Behavior by Editing Training Data via Influence Functions](https://arxiv.org/abs/2602.09987)
*J Rosser,Robert Kirk,Edward Grefenstette,Jakob Foerster,Laura Ruis*

Main category: cs.LG

TL;DR: 本文提出Infusion框架，利用可扩展的影响函数近似方法，通过微小修改训练文档来诱导模型行为变化，在图像和语言任务中验证了其数据投毒有效性。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过反向设计训练数据来诱导模型产生特定行为，而非仅用影响函数分析已有训练数据对模型的影响。

Method: 提出Infusion框架，使用可扩展的影响函数近似方法，计算对训练文档的微小扰动，以通过参数偏移诱导目标模型行为变化。

Result: 在CIFAR-10上仅修改0.2%训练样本即可达到与插入显式示例相当的效果；跨架构（ResNet↔CNN）迁移有效；语言实验表明该方法在放大模型已习得行为时最有效。

Conclusion: 微小、隐蔽的训练数据修改可系统性塑造模型行为，凸显训练数据可解释性对攻击者和防御者均至关重要。

Abstract: Influence functions are commonly used to attribute model behavior to training documents. We explore the reverse: crafting training data that induces model behavior. Our framework, Infusion, uses scalable influence-function approximations to compute small perturbations to training documents that induce targeted changes in model behavior through parameter shifts. We evaluate Infusion on data poisoning tasks across vision and language domains. On CIFAR-10, we show that making subtle edits via Infusion to just 0.2% (100/45,000) of the training documents can be competitive with the baseline of inserting a small number of explicit behavior examples. We also find that Infusion transfers across architectures (ResNet $\leftrightarrow$ CNN), suggesting a single poisoned corpus can affect multiple independently trained models. In preliminary language experiments, we characterize when our approach increases the probability of target behaviors and when it fails, finding it most effective at amplifying behaviors the model has already learned. Taken together, these results show that small, subtle edits to training data can systematically shape model behavior, underscoring the importance of training data interpretability for adversaries and defenders alike. We provide the code here: https://github.com/jrosseruk/infusion.

</details>


### [260] [Empirical Stability Analysis of Kolmogorov-Arnold Networks in Hard-Constrained Recurrent Physics-Informed Discovery](https://arxiv.org/abs/2602.09988)
*Enzo Nicolas Spotorno,Josafat Leal Filho,Antonio Augusto Medeiros Frohlich*

Main category: cs.LG

TL;DR: 本文研究了将Kolmogorov-Arnold网络（KANs）集成到硬约束循环物理信息神经网络（HRPINN）中，以评估其在振荡系统中学习残差流形的保真度；结果表明，尽管小规模KAN在单变量多项式残差任务上具竞争力，但在多变量乘性项任务中表现差、超参数敏感且深层结构不稳定，总体不如MLP。


<details>
  <summary>Details</summary>
Motivation: 受Kolmogorov-Arnold表示定理及初步灰箱结果启发，假设KAN相比MLP能更高效恢复未知项。

Method: 将KAN集成进HRPINN框架，开展配置敏感性、参数尺度与训练范式等初始敏感性分析。

Result: 小KAN在Duffing系统（单变量多项式残差）上具竞争力，但在Van der Pol系统（乘性项）上严重失效；存在超参数脆弱性、深层结构不稳定性，整体被MLP超越。

Conclusion: 原始KAN的加性归纳偏置在状态耦合建模中存在局限性，该实证结果为未来混合建模中归纳偏置设计提供了初步警示。

Abstract: We investigate the integration of Kolmogorov-Arnold Networks (KANs) into hard-constrained recurrent physics-informed architectures (HRPINN) to evaluate the fidelity of learned residual manifolds in oscillatory systems. Motivated by the Kolmogorov-Arnold representation theorem and preliminary gray-box results, we hypothesized that KANs would enable efficient recovery of unknown terms compared to MLPs. Through initial sensitivity analysis on configuration sensitivity, parameter scale, and training paradigm, we found that while small KANs are competitive on univariate polynomial residuals (Duffing), they exhibit severe hyperparameter fragility, instability in deeper configurations, and consistent failure on multiplicative terms (Van der Pol), generally outperformed by standard MLPs. These empirical challenges highlight limitations of the additive inductive bias in the original KAN formulation for state coupling and provide preliminary empirical evidence of inductive bias limitations for future hybrid modeling.

</details>


### [261] [Answer First, Reason Later: Aligning Search Relevance via Mode-Balanced Reinforcement Learning](https://arxiv.org/abs/2602.10006)
*Shijie Zhang,Xiang Guo,Rujun Guo,Shaoyu Liu,Xiaozhao Wang,Guanjun Jiang,Kevin Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种'先答后理（AFRL）'范式，使模型首 token 输出相关性分数，再给出结构化解释；为解决强化学习中的模式坍塌问题，提出模式平衡优化策略，并结合指令进化与多阶段课程提升数据质量，最终实现大模型高精度与小模型低延迟的兼顾。


<details>
  <summary>Details</summary>
Motivation: 构建兼具低延迟与高性能的搜索相关性模型是行业长期挑战；需满足毫秒级响应要求，同时保留大语言模型的可解释推理能力。

Method: 提出Answer-First, Reason Later（AFRL）范式；采用SFT+RL联合训练框架；针对RL导致的模式坍塌问题，从信息论角度分析正/逆KL差异，提出融入SFT辅助损失的Mode-Balanced Optimization策略；构建自动指令进化系统与多阶段课程以保障专家级数据质量。

Result: 32B教师模型达到SOTA性能；AFRL架构支持高效知识蒸馏，成功将专家级推理能力迁移到0.6B模型，在保持推理深度的同时显著降低部署延迟。

Conclusion: AFRL范式及其配套的模式平衡优化与高质量数据构建方法，有效协调了搜索相关性建模中性能、可解释性与延迟之间的矛盾，为工业级LLM推理系统提供了新范式。

Abstract: Building a search relevance model that achieves both low latency and high performance is a long-standing challenge in the search industry. To satisfy the millisecond-level response requirements of online systems while retaining the interpretable reasoning traces of Large Language Models (LLMs), we propose a novel \textbf{Answer-First, Reason Later (AFRL)} paradigm. This paradigm requires the model to output the definitive relevance score in the very first token, followed by a structured logical explanation. Inspired by the success of reasoning models, we adopt a "Supervised Fine-Tuning (SFT) + Reinforcement Learning (RL)" pipeline to achieve AFRL. However, directly applying existing RL training often leads to \textbf{mode collapse} in the search relevance task, where the model forgets complex long-tail rules in pursuit of high rewards. From an information theory perspective: RL inherently minimizes the \textbf{Reverse KL divergence}, which tends to seek probability peaks (mode-seeking) and is prone to "reward hacking." On the other hand, SFT minimizes the \textbf{Forward KL divergence}, forcing the model to cover the data distribution (mode-covering) and effectively anchoring expert rules. Based on this insight, we propose a \textbf{Mode-Balanced Optimization} strategy, incorporating an SFT auxiliary loss into Stepwise-GRPO training to balance these two properties. Furthermore, we construct an automated instruction evolution system and a multi-stage curriculum to ensure expert-level data quality. Extensive experiments demonstrate that our 32B teacher model achieves state-of-the-art performance. Moreover, the AFRL architecture enables efficient knowledge distillation, successfully transferring expert-level logic to a 0.6B model, thereby reconciling reasoning depth with deployment latency.

</details>


### [262] [A Task-Centric Theory for Iterative Self-Improvement with Easy-to-Hard Curricula](https://arxiv.org/abs/2602.10014)
*Chenruo Liu,Yijun Dong,Yiqiu Shen,Qi Lei*

Main category: cs.LG

TL;DR: 本文提出了一种基于奖励过滤分布的最大似然微调建模方法，为LLM的迭代自改进提供了有限样本下的理论保证，并揭示了模型性能提升与数据接受率之间的反馈机制；同时证明了在多难度推理任务中，易到难课程学习优于固定任务混合训练的条件。


<details>
  <summary>Details</summary>
Motivation: 现有自改进方法虽经验上成功，但缺乏在实际有限样本场景下的理论基础。

Method: 将每轮自改进建模为在奖励筛选数据上的最大似然微调，并结合任务难度分层分析，推导有限样本下期望奖励的理论界。

Result: 揭示了模型能力提升与每轮可接受数据量之间的正反馈机制，解释了自改进的持续性与最终饱和现象；并给出了易到难课程学习优于固定混合训练的可量化条件。

Conclusion: 该理论框架为LLM自改进提供了首个有限样本保证，并支持课程学习设计在复杂推理任务中的有效性。

Abstract: Iterative self-improvement fine-tunes an autoregressive large language model (LLM) on reward-verified outputs generated by the LLM itself. In contrast to the empirical success of self-improvement, the theoretical foundation of this generative, iterative procedure in a practical, finite-sample setting remains limited. We make progress toward this goal by modeling each round of self-improvement as maximum-likelihood fine-tuning on a reward-filtered distribution and deriving finite-sample guarantees for the expected reward. Our analysis reveals an explicit feedback loop where better models accept more data per iteration, supporting sustained self-improvement while explaining eventual saturation of such improvement. Adopting a task-centric view by considering reasoning tasks with multiple difficulty levels, we further prove quantifiable conditions on model initialization, task difficulty, and sample budget where easy-to-hard curricula provably achieve better guarantees than training on fixed mixtures of tasks. Our analyses are validated via Monte-Carlo simulations and controlled experiments on graph-based reasoning tasks.

</details>


### [263] [ADORA: Training Reasoning Models with Dynamic Advantage Estimation on Reinforcement Learning](https://arxiv.org/abs/2602.10019)
*Qingnan Ren,Shiting Huang,Zhen Fang,Zehui Chen,Lin Chen,Lijun Li,Feng Zhao*

Main category: cs.LG

TL;DR: 本文提出ADORA框架，通过在线rollout自适应调整优势函数的权重，动态区分训练样本的临时优劣性，从而提升强化学习中策略优化的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法采用静态优势估计，忽视样本效用随时间的动态变化，导致信用分配低效、策略更新次优、收敛慢且不稳定。

Method: 提出ADORA（Advantage Dynamics via Online Rollout Adaptation）框架，基于在线模型rollout中样本效用的演化，自适应地将训练数据划分为暂时有利/不利样本，并动态调整优势函数权重；可无缝嵌入现有策略优化算法。

Result: 在多种模型架构和数据规模下验证，ADORA显著提升几何与数学等长推理任务性能，收敛更快、稳定性更高，且无需敏感超参调优。

Conclusion: ADORA通过建模优势函数的动态性，有效改善信用分配与策略更新效率，是一种通用、鲁棒且即插即用的强化学习策略优化新范式。

Abstract: Reinforcement learning has become a cornerstone technique for developing reasoning models in complex tasks, ranging from mathematical problem-solving to imaginary reasoning. The optimization of these models typically relies on policy gradient methods, whose efficacy hinges on the accurate estimation of an advantage function. However, prevailing methods typically employ static advantage estimation, a practice that leads to inefficient credit assignment by neglecting the dynamic utility of training samples over time. This limitation results in suboptimal policy updates, which in turn manifest as slower convergence rates and increased learning instability, as models fail to adapt to evolving sample utilities effectively. To address this problem, we introduce \textbf{ADORA} (\textbf{A}dvantage \textbf{D}ynamics via \textbf{O}nline \textbf{R}ollout \textbf{A}daptation), a novel framework for policy optimization. ADORA dynamically adjusts the advantage function's weighting by adaptively categorizing training data into temporarily advantageous and disadvantageous samples, based on their evolving utility during online model rollouts. This tailored data differentiation strategy allows ADORA to be seamlessly integrated into existing policy optimization algorithms without significant architectural modifications, enabling the policy to prioritize learning from more informative experiences and thereby achieve more efficient policy updates. Extensive evaluations across diverse model families and varying data scales demonstrate that ADORA is a robust and efficient framework. It significantly enhances long reasoning in both geometric and mathematical tasks, consistently achieving notable performance gains without requiring sensitive hyperparameter tuning.

</details>


### [264] [Position: Message-passing and spectral GNNs are two sides of the same coin](https://arxiv.org/abs/2602.10031)
*Antonis Vasileiou,Juan Cervino,Pascal Frossard,Charilaos I. Kanatsoulis,Christopher Morris,Michael T. Schaub,Pierre Vandergheynst,Zhiyang Wang,Guy Wolf,Ron Levie*

Main category: cs.LG

TL;DR: This paper argues that the division between message-passing and spectral graph neural networks is artificial, and proposes a unified view where both are seen as permutation-equivariant operators on graph signals; it highlights their complementary strengths and calls for theoretical unification.


<details>
  <summary>Details</summary>
Motivation: The artificial divide between MPNNs and spectral GNNs hinders progress in graph learning.

Method: Reframing both MPNNs and spectral GNNs as parametrizations of permutation-equivariant operators acting on graph signals.

Result: Many popular architectures are equivalent in expressive power; genuine differences arise only in specific regimes; MPNNs and spectral GNNs offer complementary analytical and practical advantages.

Conclusion: Progress in graph learning will be accelerated by unifying these perspectives within a common theoretical framework rather than treating them as competing paradigms.

Abstract: Graph neural networks (GNNs) are commonly divided into message-passing neural networks (MPNNs) and spectral graph neural networks, reflecting two largely separate research traditions in machine learning and signal processing. This paper argues that this divide is mostly artificial, hindering progress in the field. We propose a viewpoint in which both MPNNs and spectral GNNs are understood as different parametrizations of permutation-equivariant operators acting on graph signals. From this perspective, many popular architectures are equivalent in expressive power, while genuine gaps arise only in specific regimes. We further argue that MPNNs and spectral GNNs offer complementary strengths. That is, MPNNs provide a natural language for discrete structure and expressivity analysis using tools from logic and graph isomorphism research, while the spectral perspective provides principled tools for understanding smoothing, bottlenecks, stability, and community structure. Overall, we posit that progress in graph learning will be accelerated by clearly understanding the key similarities and differences between these two types of GNNs, and by working towards unifying these perspectives within a common theoretical and conceptual framework rather than treating them as competing paradigms.

</details>


### [265] [Effectiveness of Binary Autoencoders for QUBO-Based Optimization Problems](https://arxiv.org/abs/2602.10037)
*Tetsuro Abe,Masashi Yamashita,Shu Tanaka*

Main category: cs.LG

TL;DR: 本文研究了在黑箱组合优化中，如何通过二进制自编码器（bAE）提升因子分解机与量子退火（FMQA）方法的性能，特别是在处理非二元结构（如TSP中的排列）时，bAE能学习更符合原始解空间几何结构的紧凑二进制表示，从而提高搜索效率与可行性保持能力。


<details>
  <summary>Details</summary>
Motivation: FMQA要求变量为二进制，而实际组合优化问题（如TSP）常涉及非二元结构；人工设计的二进制编码往往无法保持原解空间的邻域结构，导致搜索低效和大量不可行解；现有bAE+FMQA虽表现更好，但其优势机制尚不明确。

Method: 以小规模TSP为可解释测试平台，对比bAE学习的二进制隐空间与多种人工编码方案，在重建精度、隐空间汉明距离与真实路径距离的一致性、小比特翻转下的邻域平滑性、局部最优数量等方面进行定量分析。

Result: bAE能高精度重建可行旅行路线；相比同等压缩率的人工编码，其隐空间更准确反映路径距离，邻域更平滑，局部最优更少；这解释了bAE+FMQA更快提升近似比且全程保持可行性的原因。

Conclusion: 隐空间的几何性质（距离对齐性、邻域平滑性、局部最优稀疏性）是bAE提升FMQA性能的关键；该发现为面向黑箱优化的潜在表示设计提供了原则性指导。

Abstract: In black-box combinatorial optimization, objective evaluations are often expensive, so high quality solutions must be found under a limited budget. Factorization machine with quantum annealing (FMQA) builds a quadratic surrogate model from evaluated samples and optimizes it on an Ising machine. However, FMQA requires binary decision variables, and for nonbinary structures such as integer permutations, the choice of binary encoding strongly affects search efficiency. If the encoding fails to reflect the original neighborhood structure, small Hamming moves may not correspond to meaningful modifications in the original solution space, and constrained problems can yield many infeasible candidates that waste evaluations. Recent work combines FMQA with a binary autoencoder (bAE) that learns a compact binary latent code from feasible solutions, yet the mechanism behind its performance gains is unclear. Using a small traveling salesman problem as an interpretable testbed, we show that the bAE reconstructs feasible tours accurately and, compared with manually designed encodings at similar compression, better aligns tour distances with latent Hamming distances, yields smoother neighborhoods under small bit flips, and produces fewer local optima. These geometric properties explain why bAE+FMQA improves the approximation ratio faster while maintaining feasibility throughout optimization, and they provide guidance for designing latent representations for black-box optimization.

</details>


### [266] [Optimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning](https://arxiv.org/abs/2602.10044)
*Akshay Mete,Shahid Aamir Sheikh,Tzu-Hsiang Lin,Dileep Kalathil,P. R. Kumar*

Main category: cs.LG

TL;DR: 本文提出乐观世界模型（OWMs），将经典RBMLE方法引入深度强化学习，通过在模型学习中直接嵌入乐观动力学损失实现高效探索，无需不确定性估计或约束优化，可即插即用并显著提升样本效率与累积回报。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏奖励环境下强化学习中的高效探索难题。

Method: 提出乐观世界模型（OWMs），在世界模型训练中引入乐观动力学损失，将乐观性直接嵌入模型学习过程，无需不确定性估计或约束优化，兼容现有世界模型框架。

Result: 在DreamerV3和STORM两种先进世界模型架构上实例化OWMs，得到Optimistic DreamerV3和Optimistic STORM，在样本效率和累积回报上显著优于基线方法。

Conclusion: OWMs为深度RL提供了一种原理清晰、可扩展且易于集成的乐观探索新范式。

Abstract: Efficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments. We introduce Optimistic World Models (OWMs), a principled and scalable framework for optimistic exploration that brings classical reward-biased maximum likelihood estimation (RBMLE) from adaptive control into deep RL. In contrast to upper confidence bound (UCB)-style exploration methods, OWMs incorporate optimism directly into model learning by augmentation with an optimistic dynamics loss that biases imagined transitions toward higher-reward outcomes. This fully gradient-based loss requires neither uncertainty estimates nor constrained optimization. Our approach is plug-and-play with existing world model frameworks, preserving scalability while requiring only minimal modifications to standard training procedures. We instantiate OWMs within two state-of-the-art world model architectures, leading to Optimistic DreamerV3 and Optimistic STORM, which demonstrate significant improvements in sample efficiency and cumulative return compared to their baseline counterparts.

</details>


### [267] [Vendi Novelty Scores for Out-of-Distribution Detection](https://arxiv.org/abs/2602.10062)
*Amey P. Pasarkar,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: 本文提出了一种基于多样性视角的新型OOD检测方法——Vendi Novelty Score（VNS），它利用Vendi Score衡量测试样本对训练数据特征集多样性的提升程度，无需密度建模，具备线性时间复杂度、非参数性和兼顾局部与全局新颖性信号的特点，并在多个图像分类基准上达到SOTA性能，且仅需1%训练数据即可保持优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法多依赖模型置信度或特征空间似然估计，常受限于强分布假设；本文旨在提出一种不依赖密度建模、更鲁棒且灵活的新范式。

Method: 提出Vendi Novelty Score（VNS），基于Vendi Score（VS）这一相似性驱动的多样性度量，计算测试样本加入后对ID特征集多样性的影响；VNS为非参数、线性时间复杂度，融合类条件（局部）与数据集级（全局）新颖性信号。

Result: VNS在多个图像分类基准和网络架构上实现SOTA的OOD检测性能；即使仅使用1%训练数据，仍保持优异性能，适用于内存或数据访问受限场景。

Conclusion: 从多样性角度建模OOD检测是可行且有效的；VNS提供了一种无需密度估计、计算高效、数据高效且兼具局部与全局感知能力的新范式，拓展了OOD检测的方法论边界。

Abstract: Out-of-distribution (OOD) detection is critical for the safe deployment of machine learning systems. Existing post-hoc detectors typically rely on model confidence scores or likelihood estimates in feature space, often under restrictive distributional assumptions. In this work, we introduce a third paradigm and formulate OOD detection from a diversity perspective. We propose the Vendi Novelty Score (VNS), an OOD detector based on the Vendi Scores (VS), a family of similarity-based diversity metrics. VNS quantifies how much a test sample increases the VS of the in-distribution feature set, providing a principled notion of novelty that does not require density modeling. VNS is linear-time, non-parametric, and naturally combines class-conditional (local) and dataset-level (global) novelty signals. Across multiple image classification benchmarks and network architectures, VNS achieves state-of-the-art OOD detection performance. Remarkably, VNS retains this performance when computed using only 1% of the training data, enabling deployment in memory- or access-constrained settings.

</details>


### [268] [Long Chain-of-Thought Compression via Fine-Grained Group Policy Optimization](https://arxiv.org/abs/2602.10048)
*Xinchen Han,Hossam Afifi,Michel Marot,Xilu Wang,Lu Yin*

Main category: cs.LG

TL;DR: 本文提出FGO算法，通过细粒度分组策略优化实现链式思维（CoT）压缩，在不降低性能的前提下减少LLM推理冗余。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）常生成冗长的链式思维（CoT）推理，增加计算开销和延迟，但未带来相应性能提升。

Method: 提出细粒度分组策略优化（FGO）强化学习算法，通过细分响应组并依据长度与熵动态加权，实现高效CoT压缩；作为GRPO的增强变体，改进其数据利用效率低和熵坍塌问题。

Result: 在MATH500、AIME24、AMC23和Minerva等多个基准上验证，FGO在保持性能的同时实现高效CoT压缩，并有效克服GRPO的两大缺陷。

Conclusion: FGO是一种有效的CoT压缩方法，兼顾推理效率与模型性能，同时解决了GRPO的关键局限性。

Abstract: Large Language Models (LLMs) often generate unnecessarily verbose Chain-of-Thought (CoT) reasoning that increases computational costs and latency without proportional performance gains. In this paper, we propose \textbf{F}ine-grained \textbf{G}roup policy \textbf{O}ptimization (\textbf{FGO}), a Reinforcement Learning (RL) algorithm that refines group responses by subdividing them and assigning appropriate weights based on length and entropy, thereby enabling effective CoT compression. Meanwhile, as an enhanced variant of Group Relative Policy Optimization (GRPO), FGO successfully addresses two major limitations of the GRPO: inefficient data utilization and entropy collapse. We evaluate FGO on multiple reasoning LLMs and benchmarks, including MATH500, AIME24, AMC23, and Minerva. Experimental results show that FGO achieves efficient CoT compression without degrading performance, and simultaneously resolves the key limitations of GRPO.

</details>


### [269] [WildCat: Near-Linear Attention in Theory and Practice](https://arxiv.org/abs/2602.10056)
*Tobias Schröder,Lester Mackey*

Main category: cs.LG

TL;DR: WildCat is a novel attention compression method that uses a spectrally-accurate coreset selection (randomly pivoted Cholesky) and optimal weighting to achieve super-polynomial error decay and near-linear runtime, outperforming prior methods in both theory and practice.


<details>
  <summary>Details</summary>
Motivation: Attention mechanisms are powerful but computationally expensive due to their quadratic scaling with sequence length; there is a need for high-fidelity, low-cost approximations suitable for real-world deployment.

Method: WildCat selects a small weighted coreset via randomly pivoted Cholesky subsampling and optimally weights coreset elements to minimize attention reconstruction error.

Result: WildCat achieves super-polynomial error decay $O(n^{-\sqrt{\log(\log(n))}})$ and near-linear $O(n^{1+o(1)})$ time complexity; it demonstrates strong empirical performance across image generation, classification, and KV cache compression.

Conclusion: WildCat bridges the gap between theoretical guarantees and practical efficiency in attention approximation, offering both rigorous error bounds and scalable GPU implementation.

Abstract: We introduce WildCat, a high-accuracy, low-cost approach to compressing the attention mechanism in neural networks. While attention is a staple of modern network architectures, it is also notoriously expensive to deploy due to resource requirements that scale quadratically with the input sequence length $n$. WildCat avoids these quadratic costs by only attending over a small weighted coreset. Crucially, we select the coreset using a fast but spectrally-accurate subsampling algorithm -- randomly pivoted Cholesky -- and weight the elements optimally to minimise reconstruction error. Remarkably, given bounded inputs, WildCat approximates exact attention with super-polynomial $O(n^{-\sqrt{\log(\log(n))}})$ error decay while running in near-linear $O(n^{1+o(1)})$ time. In contrast, prior practical approximations either lack error guarantees or require quadratic runtime to guarantee such high fidelity. We couple this advance with a GPU-optimized PyTorch implementation and a suite of benchmark experiments demonstrating the benefits of WildCat for image generation, image classification, and language model KV cache compression.

</details>


### [270] [Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders](https://arxiv.org/abs/2602.10099)
*Amandeep Kumar,Vishal M. Patel*

Main category: cs.LG

TL;DR: 本文提出Riemannian Flow Matching with Jacobi Regularization (RJF)方法，解决标准扩散Transformer在表示编码器特征空间中因几何干扰（Geometric Interference）导致的不收敛问题，使标准DiT-B架构无需加宽即可高效收敛并取得优异FID指标。


<details>
  <summary>Details</summary>
Motivation: 标准扩散Transformer在表示编码器的超球面特征空间中无法直接收敛，以往归因为模型容量不足，但本文指出根本原因是欧氏流匹配迫使概率路径穿过低密度空间内部，违背流形结构。

Method: 提出Riemannian Flow Matching with Jacobi Regularization (RJF)，将生成过程约束在流形测地线上，并通过Jacobi正则化校正曲率引起的误差传播。

Result: RJF使标准DiT-B架构（1.31亿参数）成功收敛，FID达3.37，而此前方法在此配置下无法收敛。

Conclusion: 生成建模中的收敛失败本质上是几何问题而非容量问题；RJF通过黎曼流匹配与曲率感知正则化，实现了高效、高保真且无需模型加宽的表征空间扩散建模。

Abstract: Leveraging representation encoders for generative modeling offers a path for efficient, high-fidelity synthesis. However, standard diffusion transformers fail to converge on these representations directly. While recent work attributes this to a capacity bottleneck proposing computationally expensive width scaling of diffusion transformers we demonstrate that the failure is fundamentally geometric. We identify Geometric Interference as the root cause: standard Euclidean flow matching forces probability paths through the low-density interior of the hyperspherical feature space of representation encoders, rather than following the manifold surface. To resolve this, we propose Riemannian Flow Matching with Jacobi Regularization (RJF). By constraining the generative process to the manifold geodesics and correcting for curvature-induced error propagation, RJF enables standard Diffusion Transformer architectures to converge without width scaling. Our method RJF enables the standard DiT-B architecture (131M parameters) to converge effectively, achieving an FID of 3.37 where prior methods fail to converge. Code: https://github.com/amandpkr/RJF

</details>


### [271] [Features as Rewards: Scalable Supervision for Open-Ended Tasks via Interpretability](https://arxiv.org/abs/2602.10067)
*Aaditya Vikram Prasad,Connor Watts,Jack Merullo,Dhruvil Gala,Owen Lewis,Thomas McGrath,Ekdeep Singh Lubana*

Main category: cs.LG

TL;DR: 本文提出了一种利用语言模型内部特征作为奖励信号的强化学习方法（RLFR），用于减少模型幻觉，显著提升事实性而不损害基准性能。


<details>
  <summary>Details</summary>
Motivation: 传统上语言模型的抽象特征（如事实性、意图）仅用于监控或引导；本文探索其作为开放任务监督信号的新用途，特别是针对难以精确定义的幻觉问题。

Method: 提出RLFR框架：基于新探针框架识别潜在幻觉陈述，将模型内部事实性特征用作强化学习的奖励函数，训练模型在不确定时主动干预并修正输出；同时支持可扩展的测试时计算。

Result: 在Gemma-3-12B-IT上实现的策略相较原模型幻觉率降低58%，且在标准基准上保持原有性能。

Conclusion: 将可解释性特征直接用作监督信号，开辟了利用模型内部表征学习开放性任务的新范式。

Abstract: Language models trained on large-scale datasets have been shown to learn features that encode abstract concepts such as factuality or intent. Such features are traditionally used for test-time monitoring or steering. We present an alternative affordance: features as scalable supervision for open-ended tasks. We consider the case of hallucination-reduction as a desirable, yet open-ended behavior and design a reinforcement learning (RL) pipeline, titled RLFR (Reinforcement Learning from Feature Rewards), that uses features as reward functions. Grounded in a novel probing framework that identifies candidate hallucinated claims, our pipeline teaches a model to intervene and correct its completions when it is uncertain of their factuality. Furthermore, the pipeline enables scalable test-time compute, guided once more by our reward features. This end-to-end process operationalized on Gemma-3-12B-IT results in a policy that is 58% less likely to hallucinate compared to the original model, while preserving performance on standard benchmarks. Taken together, by grounding supervision in the language of features, this paper introduces a novel paradigm in the use of interpretability for learning open-ended tasks.

</details>


### [272] [Step-resolved data attribution for looped transformers](https://arxiv.org/abs/2602.10097)
*Georgios Kaissis,David Mildenberger,Juan Felipe Gomez,Martin J. Menten,Eleni Triantafillou*

Main category: cs.LG

TL;DR: 本文提出Step-Decomposed Influence (SDI)方法，将传统TracIn影响度估计分解为每步循环迭代的轨迹，以揭示训练样本在循环Transformer推理过程中的动态影响，并通过TensorSketch实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 现有训练数据影响估计器（如TracIn）仅提供对所有循环迭代的聚合标量分数，无法揭示训练样本在循环计算中何时起作用。

Method: 提出Step-Decomposed Influence (SDI)，通过展开循环计算图，将TracIn分解为长度为τ的影响轨迹；并设计基于TensorSketch的高效实现，避免显式存储单样本梯度。

Result: 在循环GPT模型和算法推理任务上的实验表明，SDI具有良好可扩展性，误差低，能准确匹配全梯度基线，并支持多种按步归因与可解释性任务。

Conclusion: SDI为循环Transformer提供了细粒度、按步的数据影响分析能力，显著提升了对潜在推理过程的理解与可解释性。

Abstract: We study how individual training examples shape the internal computation of looped transformers, where a shared block is applied for $τ$ recurrent iterations to enable latent reasoning. Existing training-data influence estimators such as TracIn yield a single scalar score that aggregates over all loop iterations, obscuring when during the recurrent computation a training example matters. We introduce \textit{Step-Decomposed Influence (SDI)}, which decomposes TracIn into a length-$τ$ influence trajectory by unrolling the recurrent computation graph and attributing influence to specific loop iterations. To make SDI practical at transformer scale, we propose a TensorSketch implementation that never materialises per-example gradients. Experiments on looped GPT-style models and algorithmic reasoning tasks show that SDI scales excellently, matches full-gradient baselines with low error and supports a broad range of data attribution and interpretability tasks with per-step insights into the latent reasoning process.

</details>


### [273] [Towards Explainable Federated Learning: Understanding the Impact of Differential Privacy](https://arxiv.org/abs/2602.10100)
*Júlio Oliveira,Rodrigo Ferreira,André Riker,Glaucio H. S. Carvalho,Eirini Eleni Tsilopoulou*

Main category: cs.LG

TL;DR: 本文提出了一种结合联邦学习、决策树与差分隐私的可解释机器学习框架FEXT-DP，在保障数据隐私的同时兼顾模型可解释性，并量化分析了差分隐私对可解释性的影响。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习系统需兼顾数据隐私（如联邦学习、差分隐私）与可解释性（如决策树），但现有方法常在二者间权衡不足，尤其差分隐私可能损害可解释性。

Method: 提出FEXT-DP框架：基于轻量级、高可解释性的决策树构建联邦学习系统，并在树模型中嵌入差分隐私机制；同时评估DP对可解释性的影响。

Result: 实验表明FEXT-DP在训练轮次、均方误差和可解释性方面均有提升。

Conclusion: FEXT-DP成功融合了强隐私保护与高可解释性，且差分隐私在合理设置下未显著削弱解释能力，为隐私敏感场景下的可信AI提供了可行路径。

Abstract: Data privacy and eXplainable Artificial Intelligence (XAI) are two important aspects for modern Machine Learning systems. To enhance data privacy, recent machine learning models have been designed as a Federated Learning (FL) system. On top of that, additional privacy layers can be added, via Differential Privacy (DP). On the other hand, to improve explainability, ML must consider more interpretable approaches with reduced number of features and less complex internal architecture. In this context, this paper aims to achieve a machine learning (ML) model that combines enhanced data privacy with explainability. So, we propose a FL solution, called Federated EXplainable Trees with Differential Privacy (FEXT-DP), that: (i) is based on Decision Trees, since they are lightweight and have superior explainability than neural networks-based FL systems; (ii) provides additional layer of data privacy protection applying Differential Privacy (DP) to the Tree-Based model. However, there is a side effect adding DP: it harms the explainability of the system. So, this paper also presents the impact of DP protection on the explainability of the ML model. The carried out performance assessment shows improvements of FEXT-DP in terms of a faster training, i.e., numbers of rounds, Mean Squared Error and explainability.

</details>


### [274] [Biases in the Blind Spot: Detecting What LLMs Fail to Mention](https://arxiv.org/abs/2602.10117)
*Iván Arcuschin,David Chanin,Adrià Garriga-Alonso,Oana-Maria Camburu*

Main category: cs.LG

TL;DR: 本文提出了一种全自动、黑盒式的流水线方法，用于检测大语言模型（LLMs）在特定任务中隐藏于链式推理（CoT）之外的未言明偏差（unverbalized biases），通过LLM自评器生成候选偏差概念，并结合统计检验与早期停止策略进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有偏差评估依赖预定义类别和人工构建数据集，且仅监控模型显式输出的推理链（CoT）不可靠，因其中可能掩盖内部未言明偏差。

Method: 提出一种黑盒自动化流水线：1）用LLM autorater从任务数据集中生成候选偏差概念；2）对每个概念构造正/负样本变体并在逐步增大的输入样本上测试；3）采用多重假设检验与早期停止策略；4）若某概念导致显著性能差异但未在模型CoT中被提及，则判定为未言明偏差。

Result: 在6个LLM、3个决策任务（招聘、贷款审批、大学录取）上验证了该方法；自动发现了先前未知的偏差（如西班牙语流利度、英语熟练度、写作正式性），并复现了已有研究识别的偏差（性别、种族、宗教、民族）。

Conclusion: 该方法为任务特定偏差的自动发现提供了一条实用、可扩展的新路径，弥补了传统依赖显式推理或人工标注的评估局限。

Abstract: Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require predefined categories and hand-crafted datasets. In this work, we introduce a fully automated, black-box pipeline for detecting task-specific unverbalized biases. Given a task dataset, the pipeline uses LLM autoraters to generate candidate bias concepts. It then tests each concept on progressively larger input samples by generating positive and negative variations, and applies statistical techniques for multiple testing and early stopping. A concept is flagged as an unverbalized bias if it yields statistically significant performance differences while not being cited as justification in the model's CoTs. We evaluate our pipeline across six LLMs on three decision tasks (hiring, loan approval, and university admissions). Our technique automatically discovers previously unknown biases in these models (e.g., Spanish fluency, English proficiency, writing formality). In the same run, the pipeline also validates biases that were manually identified by prior work (gender, race, religion, ethnicity). More broadly, our proposed approach provides a practical, scalable path to automatic task-specific bias discovery.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [275] [A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation](https://arxiv.org/abs/2602.09112)
*Russ Webb,Jason Ramapuram*

Main category: cs.AI

TL;DR: 本文介绍了Cadmus系统，一个低成本、可解释的小型模型框架，用于研究程序合成、分布外泛化、归纳推理和指令遵循等任务，相比大语言模型（LLM）具有更强的可控性与可分析性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的程序合成研究面临分布界定不清、微调效应难解析、分词影响不明、算力与存储成本高等问题；亟需一种更透明、可控、低成本的替代实验范式。

Method: 构建Cadmus系统，包含：1）整数虚拟机（VM）；2）涵盖多样化真实程序任务的专用数据集；3）轻量级自回归Transformer模型，训练成本低于200美元；支持细粒度控制训练分布及模型内部观测与插桩。

Result: 在自定义DSL下的整数算术程序补全任务中，Cadmus小模型达到100%准确率，超越GPT-5（95%）；同时揭示GPT-5引入未知先验，构成对训练-任务关系分析的干扰因素。

Conclusion: 小型可控模型（如Cadmus）为程序合成及相关认知推理研究提供了高性价比、高透明度的实验平台，有助于规避LLM不可控先验带来的混淆，推动可复现、可归因的基础研究。

Abstract: What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\% accuracy while GPT-5 has 95\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood.

</details>


### [276] [Uncertainty-Aware Multimodal Emotion Recognition through Dirichlet Parameterization](https://arxiv.org/abs/2602.09121)
*Rémi Grzeczkowicz,Eric Soriano,Ali Janati,Miyu Zhang,Gerard Comas-Quiles,Victor Carballo Araruna,Aneesh Jonelagadda*

Main category: cs.AI

TL;DR: 本文提出了一种轻量级、隐私保护的多模态情感识别（MER）框架，适用于边缘设备部署。框架采用Emotion2Vec、ResNet和DistilRoBERTa分别处理语音、面部图像和文本，并引入基于Dempster-Shafer理论与Dirichlet证据的不确定性融合机制，无需额外训练即可建模跨模态不确定性。在五个基准数据集上验证了其高精度、高效率及对缺失/模糊输入的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 面向边缘设备部署的多模态情感识别需兼顾轻量化、隐私保护与不确定性建模能力，现有方法在模态融合的通用性、计算效率及鲁棒性方面存在不足。

Method: 构建模块化MER框架，各模态使用专用高效骨干网络（Emotion2Vec、ResNet、DistilRoBERTa），并提出基于Dempster-Shafer理论与Dirichlet证据的模型与任务无关融合机制，直接作用于模型logits以建模预测不确定性。

Result: 在eNTERFACE05、MEAD、MELD、RAVDESS和CREMA-D五个基准数据集上达到具有竞争力的准确率，同时保持低计算开销和对模糊或缺失输入的强鲁棒性。

Conclusion: 该框架强调模块化、可扩展性与现实可行性，为医疗健康、人机交互等情感感知应用提供了不确定性感知的多模态系统新范式。

Abstract: In this work, we present a lightweight and privacy-preserving Multimodal Emotion Recognition (MER) framework designed for deployment on edge devices. To demonstrate framework's versatility, our implementation uses three modalities - speech, text and facial imagery. However, the system is fully modular, and can be extended to support other modalities or tasks. Each modality is processed through a dedicated backbone optimized for inference efficiency: Emotion2Vec for speech, a ResNet-based model for facial expressions, and DistilRoBERTa for text. To reconcile uncertainty across modalities, we introduce a model- and task-agnostic fusion mechanism grounded in Dempster-Shafer theory and Dirichlet evidence. Operating directly on model logits, this approach captures predictive uncertainty without requiring additional training or joint distribution estimation, making it broadly applicable beyond emotion recognition. Validation on five benchmark datasets (eNTERFACE05, MEAD, MELD, RAVDESS and CREMA-D) show that our method achieves competitive accuracy while remaining computationally efficient and robust to ambiguous or missing inputs. Overall, the proposed framework emphasizes modularity, scalability, and real-world feasibility, paving the way toward uncertainty-aware multimodal systems for healthcare, human-computer interaction, and other emotion-informed applications.

</details>


### [277] [PABU: Progress-Aware Belief Update for Efficient LLM Agents](https://arxiv.org/abs/2602.09138)
*Haitao Jiang,Lin Ge,Hengrui Cai,Rui Song*

Main category: cs.AI

TL;DR: 本文提出Progress-Aware Belief Update（PABU）框架，通过显式建模任务进展和选择性保留历史信息，提升LLM智能体的任务完成率与推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体依赖完整动作-观测历史，易引入无关信息，导致冗余动作和高推理开销。

Method: PABU构建一种信念状态框架，每步预测相对进展，并据此决定是否保留新交互信息，仅基于保留子集进行后续决策。

Result: 在AgentGym八个环境中，PABU任务完成率达81.0%，较全历史SoTA模型提升23.9%；平均交互步数降至9.5步，降低26.9%。消融实验证明进展预测与选择性保留均不可或缺。

Conclusion: 显式进展建模与选择性记忆可显著提升LLM智能体的性能与效率，为轻量高效信念状态设计提供新范式。

Abstract: Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round and decides whether the newly encountered interaction should be stored, conditioning future decisions only on the retained subset. Across eight environments in the AgentGym benchmark, and using identical training trajectories, PABU achieves an 81.0% task completion rate, outperforming previous State of the art (SoTA) models with full-history belief by 23.9%. Additionally, PABU's progress-oriented action selection improves efficiency, reducing the average number of interaction steps to 9.5, corresponding to a 26.9% reduction. Ablation studies show that both explicit progress prediction and selective retention are necessary for robust belief learning and performance gains.

</details>


### [278] [CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective](https://arxiv.org/abs/2602.09159)
*Yichen Wu,Yujin Oh,Sangjoon Park,Kailong Fan,Dania Daye,Hana Farzaneh,Xiang Li,Raul Uppot,Quanzheng Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为CoMMa的去中心化多LLM智能体框架，用于肿瘤学决策支持，通过确定性嵌入投影实现贡献感知的信用分配，提升决策的可解释性、稳定性与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于随机叙事推理的多智能体架构在处理动态异构患者数据时缺乏可解释性和稳定性，难以满足肿瘤学决策支持对鲁棒性与证据归因的高要求。

Method: 提出Contribution-Aware Medical Multi-Agents（CoMMa），采用去中心化结构，各专科智能体在划分的证据子集上运行，并通过博弈论目标协调；使用确定性嵌入投影近似边际效用，实现贡献感知的信用分配与显式证据归因。

Result: 在多个肿瘤学基准（含真实多学科肿瘤会诊数据集）上，CoMMa在准确率和性能稳定性上均优于数据集中式和角色式多智能体基线。

Conclusion: CoMMa通过数学可解释的贡献建模，为医疗多智能体系统提供了更稳健、可归因、可信赖的决策范式，推动了AI在临床决策支持中的可信落地。

Abstract: Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines.

</details>


### [279] [FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases](https://arxiv.org/abs/2602.09163)
*Xingjian Zhang,Sophia Moylan,Ziyang Xiong,Qiaozhu Mei,Yichen Luo,Jiaqi W. Ma*

Main category: cs.AI

TL;DR: 本文提出了FlyBench基准，用于评估AI代理在果蝇基因文献中端到端本体注释任务上的能力，涵盖检索、阅读理解与结构化标注；实验表明多智能体架构表现最优，但现有方法仍有较大提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅关注命名实体识别或关系抽取等孤立子任务，无法反映专家人工知识库构建中所需的端到端、多步、检索增强的本体注释真实工作流。

Method: 构建FlyBench基准：给定基因符号，在16,898篇全文论文中检索并阅读，生成Gene Ontology功能、表达模式及历史别名等结构化注释；评估四种AI代理架构（记忆型、固定流水线、单智能体、多智能体）。

Result: 多智能体架构性能最优，但模型规模扩大带来收益递减；所有基线方法均远低于专家水平；分析发现代理主要用检索验证已有知识，而非发现新信息。

Conclusion: FlyBench填补了科学文献端到端智能注释评估的空白，揭示了当前AI代理在检索增强科学推理方面的关键瓶颈，为未来研究提供明确方向。

Abstract: Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to evaluate AI agents on end-to-end agentic ontology curation from scientific literature. Given only a gene symbol, agents must search and read from a corpus of 16,898 full-text papers to produce structured annotations: Gene Ontology terms describing function, expression patterns, and historical synonyms linking decades of nomenclature. The benchmark includes 7,397 expert-curated annotations across 100 genes drawn from FlyBase, the Drosophila (fruit fly) knowledge base. We evaluate four baseline agent architectures: memorization, fixed pipeline, single-agent, and multi-agent. We find that architectural choices significantly impact performance, with multi-agent designs outperforming simpler alternatives, yet scaling backbone models yields diminishing returns. All baselines leave substantial room for improvement. Our analysis surfaces several findings to guide future development; for example, agents primarily use retrieval to confirm parametric knowledge rather than discover new information. We hope FlyBench will drive progress on retrieval-augmented scientific reasoning, a capability with broad applications across scientific domains.

</details>


### [280] [Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities](https://arxiv.org/abs/2602.09286)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.AI

TL;DR: 本文通过分析两个新兴Reddit社区（r/OpenClaw和r/Moltbook）在2026年初对具身AI监管的讨论，发现尽管两者均以“人类控制”为锚点，但其具体含义依AI角色而异：前者关注执行风险（如安全防护与故障恢复），后者关注意义风险（如身份认同、合法性与公共问责）。研究提出一种基于角色适配的监管分析框架，反对一刀切式控制策略。


<details>
  <summary>Details</summary>
Motivation: 早期具身AI部署已催生不同社会技术角色下的差异化监管期待，但现有讨论常将‘人类控制’视为单一目标，忽视角色特异性。

Method: 采用主题建模、跨社区共享语义空间、参与加权显著性分析及分布差异检验（JSD、余弦相似度、置换检验）对两个Reddit社区的监管话语进行比较分析。

Result: 两社区监管话语显著可分（JSD=0.418，余弦=0.372，p=0.0005）；‘人类控制’在r/OpenClaw中指向行动风险（执行守卫与恢复），在r/Moltbook中指向意义风险（身份、合法性、公共问责）。

Conclusion: 监管机制应依据AI所处社会技术角色进行定制化设计与评估，而非统一适用‘人类控制’这一抽象原则；该角色适配视角具有跨场景可迁移性。

Abstract: Oversight for agentic AI is often discussed as a single goal ("human control"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium.
  Using topic modeling in a shared comparison space, a coarse-grained oversight-theme abstraction, engagement-weighted salience, and divergence tests, we show the communities are strongly separable (JSD =0.418, cosine =0.372, permutation $p=0.0005$). Across both communities, "human control" is an anchor term, but its operational meaning diverges: r/OpenClaw} emphasizes execution guardrails and recovery (action-risk), while r/Moltbook} emphasizes identity, legitimacy, and accountability in public interaction (meaning-risk). The resulting distinction offers a portable lens for designing and evaluating oversight mechanisms that match agent role, rather than applying one-size-fits-all control policies.

</details>


### [281] [Measuring Dataset Diversity from a Geometric Perspective](https://arxiv.org/abs/2602.09340)
*Yang Ba,Mohammad Sadeq Abolhasani,Michelle V Mancenido,Rong Pan*

Main category: cs.AI

TL;DR: 本文提出了一种基于拓扑数据分析（TDA）和持续性景观（PLs）的新型数据多样性度量方法PLDiv，以弥补现有指标忽视数据几何结构的不足。


<details>
  <summary>Details</summary>
Motivation: 现有多样性指标（如特征空间离散度、度量空间幅度）主要刻画分布变异或熵，却忽略了数据集的几何结构，因此需要一种能刻画几何丰富性的新度量。

Method: 构建基于拓扑数据分析（TDA）与持续性景观（PLs）的框架，从数据中提取并量化几何特征，提出PLDiv多样性度量。

Result: 在多种模态数据上的实验表明，PLDiv具有强表达力、高可靠性与良好可解释性，能将数据多样性直接关联到其底层几何结构。

Conclusion: PLDiv为数据集构建、增强与评估提供了一个理论扎实、几何感知的基础性工具。

Abstract: Diversity can be broadly defined as the presence of meaningful variation across elements, which can be viewed from multiple perspectives, including statistical variation and geometric structural richness in the dataset. Existing diversity metrics, such as feature-space dispersion and metric-space magnitude, primarily capture distributional variation or entropy, while largely neglecting the geometric structure of datasets. To address this gap, we introduce a framework based on topological data analysis (TDA) and persistence landscapes (PLs) to extract and quantify geometric features from data. This approach provides a theoretically grounded means of measuring diversity beyond entropy, capturing the rich geometric and structural properties of datasets. Through extensive experiments across diverse modalities, we demonstrate that our proposed PLs-based diversity metric (PLDiv) is powerful, reliable, and interpretable, directly linking data diversity to its underlying geometry and offering a foundational tool for dataset construction, augmentation, and evaluation.

</details>


### [282] [Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge](https://arxiv.org/abs/2602.09341)
*Wei Yang,Shixuan Li,Heng Ping,Peiyu Zhang,Paul Bogdan,Jesse Thomason*

Main category: cs.AI

TL;DR: 本文提出AgentAuditor，通过构建显式的推理树替代多数投票，结合关键分歧点的局部验证与反共识偏好优化（ACPO）训练裁判模型，在多智能体系统中提升LLM推理准确性。


<details>
  <summary>Details</summary>
Motivation: 多数投票方法忽视推理路径中的证据结构，且在智能体存在相关偏差导致错误共识时表现脆弱。

Method: 构建显式表示智能体推理路径间一致与分歧的推理树；在关键分歧点进行局部冲突解析；提出反共识偏好优化（ACPO），在多数失败案例上训练裁判模型，奖励基于证据的少数正确选择。

Result: 在5种主流多智能体设置下，AgentAuditor相比多数投票最高提升5%绝对准确率，相比LLM-as-Judge最高提升3%。

Conclusion: AgentAuditor提供了一种更鲁棒、可解释、泛化性强的多智能体结果聚合机制，显著提升推理准确性。

Abstract: Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge.

</details>


### [283] [Not-in-Perspective: Towards Shielding Google's Perspective API Against Adversarial Negation Attacks](https://arxiv.org/abs/2602.09343)
*Michail S. Alexiou,J. Sukarno Mertoguno*

Main category: cs.AI

TL;DR: 本文提出了一种基于形式推理的包装方法，用于增强现有机器学习毒性检测系统对否定类对抗攻击的鲁棒性，显著提升了检测准确率和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于统计/机器学习的自动毒性检测系统易受逻辑型对抗攻击（如否定修饰）影响，亟需提升鲁棒性。

Method: 设计并实现一套形式推理方法作为预处理与后处理模块，嵌入到现有机器学习毒性检测系统中，构成混合检测框架。

Result: 在否定对抗数据集上的实验表明，所提混合方法相比纯统计方法在准确率和毒性评分效能上有显著提升。

Conclusion: 形式推理与机器学习的结合能有效缓解否定类对抗攻击，为构建更鲁棒的在线毒性检测系统提供了新思路。

Abstract: The rise of cyberbullying in social media platforms involving toxic comments has escalated the need for effective ways to monitor and moderate online interactions. Existing solutions of automated toxicity detection systems, are based on a machine or deep learning algorithms. However, statistics-based solutions are generally prone to adversarial attacks that contain logic based modifications such as negation in phrases and sentences. In that regard, we present a set of formal reasoning-based methodologies that wrap around existing machine learning toxicity detection systems. Acting as both pre-processing and post-processing steps, our formal reasoning wrapper helps alleviating the negation attack problems and significantly improves the accuracy and efficacy of toxicity scoring. We evaluate different variations of our wrapper on multiple machine learning models against a negation adversarial dataset. Experimental results highlight the improvement of hybrid (formal reasoning and machine-learning) methods against various purely statistical solutions.

</details>


### [284] [Image Quality in the Era of Artificial Intelligence](https://arxiv.org/abs/2602.09347)
*Jana G. Delfino,Jason L. Granstedt,Frank W. Samuelson,Robert Ochs,Krishna Juluru*

Main category: cs.AI

TL;DR: 本文讨论了人工智能在放射学图像重建和增强中的应用及其潜在局限性，强调了理解这些局限性对于安全有效地使用AI技术的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI在放射学中快速部署，其在图像重建和增强方面的优势显著，但同时也引入了新的故障模式，并可能加剧图像感知质量与实际信息内容之间的脱节。因此，有必要提高对AI图像处理局限性的认识。

Method: 本文采用综述和分析方法，系统梳理AI在放射学图像重建与增强中的常见问题和潜在风险。

Result: 识别出AI图像处理可能导致的图像失真、信息丢失、临床误判等关键局限性，并提出相应的风险缓解建议。

Conclusion: 必须充分认识并应对AI图像重建与增强技术的局限性，以确保其在临床实践中的安全与有效应用。

Abstract: Artificial intelligence (AI) is being deployed within radiology at a rapid pace. AI has proven an excellent tool for reconstructing and enhancing images that appear sharper, smoother, and more detailed, can be acquired more quickly, and allowing clinicians to review them more rapidly. However, incorporation of AI also introduces new failure modes and can exacerbate the disconnect between perceived quality of an image and information content of that image. Understanding the limitations of AI-enabled image reconstruction and enhancement is critical for safe and effective use of the technology. Hence, the purpose of this communication is to bring awareness to limitations when AI is used to reconstruct or enhance a radiological image, with the goal of enabling users to reap benefits of the technology while minimizing risks.

</details>


### [285] [P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads](https://arxiv.org/abs/2602.09443)
*Yun Luo,Futing Wang,Qianjia Cheng,Fangchen Yu,Haodi Lei,Jianhao Yan,Chenxi Li,Jiacheng Chen,Yufeng Zhao,Haiyuan Wan,Yuchen Zhang,Shenghe Zheng,Junchi Yao,Qingyang Zhang,Haonan He,Wenxuan Zeng,Li Sheng,Chengxing Xie,Yuxin Zuo,Yizhuo Li,Yulun Wu,Rui Huang,Dongzhan Zhou,Kai Chen,Yu Qiao,Lei Bai,Yu Cheng,Ning Ding,Bowen Zhou,Peng Ye,Ganqu Cui*

Main category: cs.AI

TL;DR: 本文提出P1-VL系列开源视觉语言模型，结合课程强化学习与智能体增强方法，专为高级科学推理（尤其是物理奥林匹克级别）设计，在HiPhO基准上达到开源模型SOTA，并实现全球第二排名。


<details>
  <summary>Details</summary>
Motivation: 物理作为检验大模型科学推理能力的关键锚点，要求模型将抽象逻辑与物理现实一致地绑定；而奥赛级物理题中图表常含关键约束（如边界条件、对称性），仅靠文本无法覆盖，亟需弥合视觉-逻辑鸿沟。

Method: 提出P1-VL模型家族，融合课程强化学习（渐进式难度扩展以稳定后训练）与智能体增强（推理时迭代自验证）。

Result: P1-VL-235B-A22B在HiPhO（2024–2025年13场考试）上首获开源VLM中12枚金牌，SOTA；代理增强系统全球总榜第2，仅次于Gemini-3-Pro；在STEM多领域基准上显著超越基线模型。

Conclusion: P1-VL为构建通用物理智能迈出基础性一步，通过开源推动机器科学发现，实现视觉感知与抽象物理定律的深度对齐。

Abstract: The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative, containing essential constraints, such as boundary conditions and spatial symmetries, that are absent from the text. To bridge this visual-logical gap, we introduce P1-VL, a family of open-source vision-language models engineered for advanced scientific reasoning. Our method harmonizes Curriculum Reinforcement Learning, which employs progressive difficulty expansion to stabilize post-training, with Agentic Augmentation, enabling iterative self-verification at inference. Evaluated on HiPhO, a rigorous benchmark of 13 exams from 2024-2025, our flagship P1-VL-235B-A22B becomes the first open-source Vision-Language Model (VLM) to secure 12 gold medals and achieves the state-of-the-art performance in the open-source models. Our agent-augmented system achieves the No.2 overall rank globally, trailing only Gemini-3-Pro. Beyond physics, P1-VL demonstrates remarkable scientific reasoning capacity and generalizability, establishing significant leads over base models in STEM benchmarks. By open-sourcing P1-VL, we provide a foundational step toward general-purpose physical intelligence to better align visual perceptions with abstract physical laws for machine scientific discovery.

</details>


### [286] [SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning](https://arxiv.org/abs/2602.09463)
*Furong Jia,Ling Dai,Wenjin Deng,Fan Zhang,Chen Hu,Daxin Jiang,Yu Liu*

Main category: cs.AI

TL;DR: 本文提出SpotAgent框架，通过结合视觉理解与工具辅助验证（如网络搜索、地图），将地理定位任务形式化为代理推理过程，显著提升了大型视觉语言模型在稀疏、长尾和高度模糊视觉线索下的定位准确性与可验证性。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在真实场景中因视觉线索稀疏、长尾且高度模糊而表现不佳，且依赖内部知识导致预测不可验证、易产生幻觉。

Method: 提出SpotAgent框架，采用ReAct图驱动的工具调用机制；设计三阶段后训练流程：监督微调（SFT）、多智能体合成轨迹驱动的代理冷启动、空间感知动态过滤策略引导的强化学习。

Result: 在标准基准上达到SOTA性能，有效缓解幻觉问题，提供精确且可验证的地理定位结果。

Conclusion: SpotAgent通过引入外部工具协同与结构化代理推理，显著提升了LVLMs在复杂现实地理定位任务中的鲁棒性、准确性和可解释性。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated strong reasoning capabilities in geo-localization, yet they often struggle in real-world scenarios where visual cues are sparse, long-tailed, and highly ambiguous. Previous approaches, bound by internal knowledge, often fail to provide verifiable results, yielding confident but ungrounded predictions when faced with confounded evidence. To address these challenges, we propose SpotAgent, a framework that formalizes geo-localization into an agentic reasoning process that leverages expert-level reasoning to synergize visual interpretation with tool-assisted verification. SpotAgent actively explores and verifies visual cues by leveraging external tools (e.g., web search, maps) through a ReAct diagram. We introduce a 3-stage post-training pipeline starting with a Supervised Fine-Tuning (SFT) stage for basic alignment, followed by an Agentic Cold Start phase utilizing high-quality trajectories synthesized via a Multi-Agent framework, aiming to instill tool-calling expertise. Subsequently, the model's reasoning capabilities are refined through Reinforcement Learning. We propose a Spatially-Aware Dynamic Filtering strategy to enhance the efficiency of the RL stage by prioritizing learnable samples based on spatial difficulty. Extensive experiments on standard benchmarks demonstrate that SpotAgent achieves state-of-the-art performance, effectively mitigating hallucinations while delivering precise and verifiable geo-localization.

</details>


### [287] [Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models](https://arxiv.org/abs/2602.09485)
*Yizhi Wang,Linan Yue,Min-Ling Zhang*

Main category: cs.AI

TL;DR: 本文提出XMCC，一种可解释的多模态思维链压缩器，通过强化学习将压缩建模为序列决策过程，在保持推理完整性和答案正确性的同时，显著缩短推理链长度，并生成自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 长思维链（Long CoTs）虽能提升多模态推理性能，但存在冗余、效率低、压缩后易丢失视觉-文本对齐线索及缺乏可解释性等问题。

Method: 提出XMCC框架，将思维链压缩建模为基于强化学习的序列决策过程，联合优化压缩质量与可解释性，同时生成自然语言压缩解释。

Result: 在多个主流多模态推理基准上验证了XMCC能有效缩短推理长度、保持答案准确率，并提供高质量、可理解的压缩解释。

Conclusion: XMCC是一种兼顾高效性、保真性与可解释性的多模态思维链压缩方法，为可信多模态推理提供了新思路。

Abstract: Long chains of thought (Long CoTs) are widely employed in multimodal reasoning models to tackle complex tasks by capturing detailed visual information. However, these Long CoTs are often excessively lengthy and contain redundant reasoning steps, which can hinder inference efficiency. Compressing these long CoTs is a natural solution, yet existing approaches face two major challenges: (1) they may compromise the integrity of visual-textual reasoning by removing essential alignment cues, and (2) the compression process lacks explainability, making it difficult to discern which information is critical. To address these problems, we propose XMCC, an eXplainable Multimodal CoT Compressor that formulates compression as a sequential decision-making process optimized via reinforcement learning. XMCC can effectively shorten reasoning trajectories while preserving key reasoning steps and answer correctness, and simultaneously generates natural-language explanations for its compression decisions. Extensive experiments on representative multimodal reasoning benchmarks demonstrate that XMCC not only reduces reasoning length but also provides explainable explanations, validating its effectiveness.

</details>


### [288] [Computing Conditional Shapley Values Using Tabular Foundation Models](https://arxiv.org/abs/2602.09489)
*Lars Henry Berge Olsen,Dennis Christensen*

Main category: cs.AI

TL;DR: 本文提出利用TabPFN等表格基础模型通过上下文学习高效估计Shapley值，避免了传统方法中对每个条件期望反复训练的高开销，在多个数据集上实现了接近最优的性能与显著降低的运行时间。


<details>
  <summary>Details</summary>
Motivation: Shapley值在可解释AI中至关重要，但其计算成本高昂，尤其在特征依赖时需大量近似条件期望；传统回归方法因需为每个条件期望单独重训练而效率低下。

Method: 利用TabPFN等表格基础模型的上下文学习能力，无需重训练即可快速估计各条件期望，进而计算Shapley值，并与现有最先进方法在模拟和真实数据集上进行对比实验。

Result: TabPFN在大多数情况下性能最优；即使未达最优，也仅略差于最佳方法，且运行时间大幅缩短。

Conclusion: TabPFN能高效、准确地估计条件Shapley值，为基于基础模型的可解释性方法提供了新路径，并指出了针对该任务进一步优化模型设计的方向。

Abstract: Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation.

</details>


### [289] [Autoregressive Direct Preference Optimization](https://arxiv.org/abs/2602.09533)
*Masanari Oi,Mahiro Ukai,Masahiro Kaneko,Naoaki Okazaki,Nakamasa Inoue*

Main category: cs.AI

TL;DR: 本文提出了一种新的直接偏好优化方法——自回归DPO（ADPO），通过在应用Bradley-Terry模型前显式引入自回归假设，改进了传统DPO的理论基础，并首次区分并分析了token长度μ与反馈长度μ'对LLM偏好优化的影响。


<details>
  <summary>Details</summary>
Motivation: 传统DPO广泛依赖响应级Bradley-Terry模型，但其将参考模型和可学习模型视为仅在推导目标函数后才具有自回归性质，限制了其潜力。

Method: 重新审视DPO理论基础，显式在BT模型前引入自回归假设，推导出新变体ADPO；其损失函数将DPO中log-sigmoid内的求和移至外部，并理论分析了token长度μ与反馈长度μ'两个关键长度度量。

Result: 提出了ADPO方法，其损失形式简洁优雅；理论上明确了token长度μ与反馈长度μ'的区别及其对偏好优化算法设计的影响。

Conclusion: ADPO在不违背DPO理论基础的前提下，通过显式建模自回归性提升了偏好优化效果，并首次系统分析了两种长度度量，为LLM对齐提供了新视角。

Abstract: Direct preference optimization (DPO) has emerged as a promising approach for aligning large language models (LLMs) with human preferences. However, the widespread reliance on the response-level Bradley-Terry (BT) model may limit its full potential, as the reference and learnable models are assumed to be autoregressive only after deriving the objective function. Motivated by this limitation, we revisit the theoretical foundations of DPO and propose a novel formulation that explicitly introduces the autoregressive assumption prior to applying the BT model. By reformulating and extending DPO, we derive a novel variant, termed Autoregressive DPO (ADPO), that explicitly integrates autoregressive modeling into the preference optimization framework. Without violating the theoretical foundations, the derived loss takes an elegant form: it shifts the summation operation in the DPO objective outside the log-sigmoid function. Furthermore, through theoretical analysis of ADPO, we show that there exist two length measures to be considered when designing DPO-based algorithms: the token length $μ$ and the feedback length $μ$'. To the best of our knowledge, we are the first to explicitly distinguish these two measures and analyze their implications for preference optimization in LLMs.

</details>


### [290] [Detecting radar targets swarms in range profiles with a partially complex-valued neural network](https://arxiv.org/abs/2602.09597)
*Martin Bauw*

Main category: cs.AI

TL;DR: 本文提出了一种基于部分复数值神经网络的雷达距离剖面自适应处理方法，用于解决多目标近距离和回波畸变下的检测难题，并在仿真数据上验证了其相比传统脉冲压缩方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 雷达目标检测常受杂波、波形失真及多目标近距离相互干扰（如合并感知或阈值影响）的挑战，而现有方法对目标间距敏感，尤其受限于雷达分辨率与自适应门限设置。

Method: 提出一种部分复数值神经网络作为雷达距离剖面的自适应处理架构；该网络为生成式结构，一次性处理整段接收信号以输出完整检测剖面；在仿真生成的多目标、不同间距与畸变回波数据集上开展实验对比。

Result: 所提部分复数值神经网络在多目标近距离及回波畸变场景下的检测性能优于传统单脉冲长度处理的脉冲压缩方法。

Conclusion: 部分复数值神经网络能更鲁棒地建模雷达回波的相位与幅度特性，适用于复杂环境下的端到端目标检测，为雷达信号处理提供了新范式。

Abstract: Correctly detecting radar targets is usually challenged by clutter and waveform distortion. An additional difficulty stems from the relative proximity of several targets, the latter being perceived as a single target in the worst case, or influencing each other's detection thresholds. The negative impact of targets proximity notably depends on the range resolution defined by the radar parameters and the adaptive threshold adopted. This paper addresses the matter of targets detection in radar range profiles containing multiple targets with varying proximity and distorted echoes. Inspired by recent contributions in the radar and signal processing literature, this work proposes partially complex-valued neural networks as an adaptive range profile processing. Simulated datasets are generated and experiments are conducted to compare a common pulse compression approach with a simple neural network partially defined by complex-valued parameters. Whereas the pulse compression processes one pulse length at a time, the neural network put forward is a generative architecture going through the entire received signal in one go to generate a complete detection profile.

</details>


### [291] [FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints](https://arxiv.org/abs/2602.09620)
*Jorge Fandinno,Pedro Cabalar,Philipp Wanko,Torsten Schaub*

Main category: cs.AI

TL;DR: 本文提出FLINGO语言及工具，旨在增强约束答案集编程（CASP）中数值约束的表达能力，使其支持ASP风格的数值属性建模（如默认值、未定义、选择规则、聚合等），并通过翻译到CLINGCON格式实现语义兼容。


<details>
  <summary>Details</summary>
Motivation: 现有CASP求解器在数值约束表示上偏向后端数值求解器的表达与语义，丢失了ASP中通过谓词表示数值属性所具有的灵活性（如默认值、未定义、选择规则、聚合等），限制了其在真实应用中的建模能力。

Method: 设计并实现FLINGO语言，将ASP风格的数值属性建模能力嵌入数值约束中；基于已有语义基础，给出从FLINGO语法到标准CASP（CLINGCON格式）的翻译方法。

Result: 提出了具备更强表达力的FLINGO语言及其实现工具，并通过多个示例验证其有效性；提供了形式化翻译方案，确保与现有CASP求解器兼容。

Conclusion: FLINGO成功弥合了ASP与CASP在数值建模表达力之间的鸿沟，提升了CASP在现实应用中的建模灵活性与实用性。

Abstract: Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format.

</details>


### [292] [ClinAlign: Scaling Healthcare Alignment from Clinician Preference](https://arxiv.org/abs/2602.09653)
*Shiwei Lyu,Xidong Wang,Lei Liu,Hao Zhu,Chaohe Zhang,Jian Wang,Jinjie Gu,Benyou Wang,Yue Shen*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段框架（HealthRubrics数据集 + HealthPrinciples原则集），提升大语言模型在临床场景中的对齐能力，兼顾专业性与效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖粗粒度目标或不可靠的自动评估器，难以将LLM开放输出与细粒度临床偏好对齐，且缺乏真实临床指南支撑。

Method: 第一阶段构建医生验证的HealthRubrics数据集（7034条偏好样本）；第二阶段提炼出119条按临床维度组织、可复用的HealthPrinciples，并用于离线对齐（合成评测标准）和推理时引导式自我修正。

Result: 一个仅激活3B参数的30B模型在HealthBench-Hard上达33.4%，超越Deepseek-R1和o3等更大模型，确立了资源高效的临床对齐新基线。

Conclusion: HealthRubrics与HealthPrinciples构成可扩展、临床可信的对齐范式，显著提升小激活规模模型在专业医疗任务中的表现。

Abstract: Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B parameter model that activates only 3B parameters at inference trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.

</details>


### [293] [GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis](https://arxiv.org/abs/2602.09794)
*Jiaquan Zhang,Chaoning Zhang,Shuxu Chen,Xudong Wang,Zhenzhen Huang,Pengcheng Zheng,Shuai Yuan,Sheng Zheng,Qigan Sun,Jie Zou,Lik-Hang Lee,Yang Yang*

Main category: cs.AI

TL;DR: 本文提出GHS-TDA方法，通过构建语义增强的全局假设图和基于持续同调的拓扑数据分析，解决链式推理中错误传播与冗余问题，提升大语言模型推理的准确性、鲁棒性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有链式推理（CoT）方法存在早期错误传播难修正、缺乏全局协调与冗余过滤机制两大缺陷，导致推理不稳定且不可解释。

Method: 提出GHS-TDA：1）构建语义增强的全局假设图，聚合与协调多条候选推理路径，提供全局纠错能力；2）利用基于持续同调的拓扑数据分析，提取稳定多尺度结构，去除冗余与不一致，生成可靠推理骨架。

Result: GHS-TDA在多个推理基准上显著优于强基线，在准确率和鲁棒性上均取得一致提升，并生成高置信度、可解释的推理路径。

Conclusion: 联合推理多样性与拓扑稳定性可实现自适应收敛，有效缓解CoT固有缺陷，为可信推理提供了新范式。

Abstract: Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks.

</details>


### [294] [Symbolic Pattern Temporal Numeric Planning with Intermediate Conditions and Effects](https://arxiv.org/abs/2602.09798)
*Matteo Cardellini,Enrico Giunchiglia*

Main category: cs.AI

TL;DR: 本文扩展了符号模式规划（SPP）方法，使其适用于带有中间条件和效果（ICEs）的时序规划问题，并提出了新规划器Patty，在多个基准测试中表现优于现有规划器。


<details>
  <summary>Details</summary>
Motivation: 现有SPP方法仅适用于数值规划，无法处理具有时间维度和中间条件/效果（ICEs）的复杂时序规划问题，因此需要扩展以提升其适用性和求解能力。

Method: 将SPP方法扩展至支持durative动作、动作执行期间任意时刻可检查/施加的条件与效果，以及计划执行中特定时刻需满足的条件/效果；构建基于SMT编码的规划器Patty。

Result: 实验表明Patty在多数无ICEs的时序领域中超越所有现有规划器；在含ICEs的文献领域中性能与当前最优搜索规划器相当；在基于真实应用的新领域中表现更优。

Conclusion: SPP框架可成功扩展至带ICEs的时序规划，Patty验证了该方法的有效性与竞争力，为复杂时序规划提供了新思路。

Abstract: Recently, a Symbolic Pattern Planning (SPP) approach was proposed for numeric planning where a pattern (i.e., a finite sequence of actions) suggests a causal order between actions. The pattern is then encoded in a SMT formula whose models correspond to valid plans. If the suggestion by the pattern is inaccurate and no valid plan can be found, the pattern is extended until it contains the causal order of actions in a valid plan, making the approach complete. In this paper, we extend the SPP approach to the temporal planning with Intermediate Conditions and Effects (ICEs) fragment, where $(i)$ actions are durative (and thus can overlap over time) and have conditions/effects which can be checked/applied at any time during an action's execution, and $(ii)$ one can specify plan's conditions/effects that must be checked/applied at specific times during the plan execution. Experimental results show that our SPP planner Patty $(i)$ outperforms all other planners in the literature in the majority of temporal domains without ICEs, $(ii)$ obtains comparable results with the SoTA search planner for ICS in literature domains with ICEs, and $(iii)$ outperforms the same planner in a novel domain based on a real-world application.

</details>


### [295] [Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices](https://arxiv.org/abs/2602.09802)
*Manon Reusens,Sofie Goethals,Toon Calders,David Martens*

Main category: cs.AI

TL;DR: 本文研究了大语言模型（LLMs）在旅行助手场景中进行主观决策的能力，通过选择困境实验和多项Logit模型推导其隐含支付意愿（WTP），并与人类基准值对比；发现大模型虽能生成有意义的WTP，但存在系统性偏差，尤其高估人类WTP，而引入用户历史偏好可改善一致性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被广泛用于旅行协助等需主观判断的应用场景，亟需评估其在无客观正确答案情境下的决策合理性与人类一致性。

Method: 在旅行助手语境中构建选择困境任务，利用多项Logit模型从LLM响应中反推隐含支付意愿（WTP），并与经济学文献中的人类WTP基准对比；同时考察基础设定、用户历史偏好信息注入及人格化提示等不同条件的影响。

Result: 较大规模LLM可推导出有意义的WTP，但在属性层面存在系统性偏差；整体上显著高估人类WTP，尤其在昂贵选项或商务型人格提示下；当条件化于用户过往低价偏好时，WTP估值更接近人类基准。

Conclusion: LLM具备用于主观决策支持的潜力，但其输出受模型规模、提示设计与用户表征方式显著影响，实际部署中需谨慎选模、优化提示并准确建模用户偏好。

Abstract: As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice.

</details>


### [296] [Efficient Unsupervised Environment Design through Hierarchical Policy Representation Learning](https://arxiv.org/abs/2602.09813)
*Dexun Li,Sidney Tio,Pradeep Varakantham*

Main category: cs.AI

TL;DR: 本文提出了一种基于分层马尔可夫决策过程（MDP）的无监督环境设计（UED）框架，通过利用学生策略表征和生成模型来提升教师代理生成训练环境的效率与针对性，显著减少师生交互次数。


<details>
  <summary>Details</summary>
Motivation: 现有基于开放性（Open-Endedness）的UED方法依赖随机过程无限生成环境，在资源受限、师生交互机会有限的实际场景中不实用。

Method: 构建分层MDP框架，教师代理利用学生在评估环境中展现出的策略表征来生成适配其能力的训练环境；引入生成模型扩充教师训练数据，降低对真实师生交互的依赖。

Result: 在多个领域实验中，该方法在单轮episode中所需师生交互次数少于基线方法，且性能更优。

Conclusion: 所提框架能有效应对资源受限下的UED挑战，适用于训练机会稀缺的实际部署场景。

Abstract: Unsupervised Environment Design (UED) has emerged as a promising approach to developing general-purpose agents through automated curriculum generation. Popular UED methods focus on Open-Endedness, where teacher algorithms rely on stochastic processes for infinite generation of useful environments. This assumption becomes impractical in resource-constrained scenarios where teacher-student interaction opportunities are limited. To address this challenge, we introduce a hierarchical Markov Decision Process (MDP) framework for environment design. Our framework features a teacher agent that leverages student policy representations derived from discovered evaluation environments, enabling it to generate training environments based on the student's capabilities. To improve efficiency, we incorporate a generative model that augments the teacher's training dataset with synthetic data, reducing the need for teacher-student interactions. In experiments across several domains, we show that our method outperforms baseline approaches while requiring fewer teacher-student interactions in a single episode. The results suggest the applicability of our approach in settings where training opportunities are limited.

</details>


### [297] [Why Do AI Agents Systematically Fail at Cloud Root Cause Analysis?](https://arxiv.org/abs/2602.09937)
*Taeyoon Kim,Woohyeok Park,Hoyeong Yun,Kyungyong Lee*

Main category: cs.AI

TL;DR: 本文对基于大语言模型（LLM）的根因分析（RCA）智能体进行了过程级失效分析，识别出12类典型陷阱，发现主要问题源于共享的智能体架构而非模型能力差异，并验证了改进通信协议比单纯提示工程更有效。


<details>
  <summary>Details</summary>
Motivation: 大型云系统故障造成巨大经济损失，自动化根因分析（RCA）至关重要；但现有LLM智能体RCA系统检测准确率低，且评估框架仅关注最终答案正确性，无法揭示推理失败原因。

Method: 在OpenRCA基准上对5个LLM模型执行共1675次智能体运行，进行过程级失效分析，归纳出覆盖智能体内推理、智能体间通信与智能体-环境交互三层面的12类失效陷阱，并开展控制实验验证缓解策略有效性。

Result: 发现幻觉式数据解读和探索不充分是最普遍且跨模型存在的两类主要陷阱，根源在于智能体架构而非模型本身；提示工程无法解决主导性陷阱，而增强智能体间通信协议可将通信相关失效降低最多15个百分点。

Conclusion: LLM智能体在云RCA中的关键失效源于通用架构缺陷，需从通信机制等系统设计层面改进；本文提出的失效分类体系与诊断方法为构建更可靠的自主RCA智能体提供了基础支撑。

Abstract: Failures in large-scale cloud systems incur substantial financial losses, making automated Root Cause Analysis (RCA) essential for operational stability. Recent efforts leverage Large Language Model (LLM) agents to automate this task, yet existing systems exhibit low detection accuracy even with capable models, and current evaluation frameworks assess only final answer correctness without revealing why the agent's reasoning failed. This paper presents a process level failure analysis of LLM-based RCA agents. We execute the full OpenRCA benchmark across five LLM models, producing 1,675 agent runs, and classify observed failures into 12 pitfall types across intra-agent reasoning, inter-agent communication, and agent-environment interaction. Our analysis reveals that the most prevalent pitfalls, notably hallucinated data interpretation and incomplete exploration, persist across all models regardless of capability tier, indicating that these failures originate from the shared agent architecture rather than from individual model limitations. Controlled mitigation experiments further show that prompt engineering alone cannot resolve the dominant pitfalls, whereas enriching the inter-agent communication protocol reduces communication-related failures by up to 15 percentage points. The pitfall taxonomy and diagnostic methodology developed in this work provide a foundation for designing more reliable autonomous agents for cloud RCA.

</details>


### [298] [Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning](https://arxiv.org/abs/2602.09945)
*Jinsong Liu,Yuhang Jiang,Ramayya Krishnan,Rema Padman,Yiye Zhang,Jiang Bian*

Main category: cs.AI

TL;DR: 本文提出了一种名为差分推理学习（DRL）的框架，通过分析临床代理与参考推理之间的图结构差异，提升其推理准确性和临床合理性，并在多个医学问答和真实临床预测任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 临床决策支持不仅需要正确答案，还需具备临床上有效的推理过程；现有方法缺乏对推理过程质量的系统性优化机制。

Method: DRL框架将参考推理（如医生撰写的理由、指南或更强模型输出）与代理的链式推理（CoT）分别建模为有向无环图（DAG），利用LLM-as-a-judge进行语义对齐与图编辑距离（GED）差异诊断，生成自然语言修正指令并存入差分推理知识库（DR-KB）；推理时通过RAG检索并注入指令以增强提示。

Result: 在公开医学问答基准和内部返院预测（RVA）任务中，DRL显著提升了最终答案准确率与推理保真度；消融实验证明参考推理注入与top-k检索策略均有效；临床医生评审进一步验证其临床合理性。

Conclusion: DRL为复杂临床推理场景提供了更可靠的决策支持机制，且适用于有限token预算的实际部署环境。

Abstract: Clinical decision support requires not only correct answers but also clinically valid reasoning. We propose Differential Reasoning Learning (DRL), a framework that improves clinical agents by learning from reasoning discrepancies. From reference reasoning rationales (e.g., physician-authored clinical rationale, clinical guidelines, or outputs from more capable models) and the agent's free-form chain-of-thought (CoT), DRL extracts reasoning graphs as directed acyclic graphs (DAGs) and performs a clinically weighted graph edit distance (GED)-based discrepancy analysis. An LLM-as-a-judge aligns semantically equivalent nodes and diagnoses discrepancies between graphs. These graph-level discrepancy diagnostics are converted into natural-language instructions and stored in a Differential Reasoning Knowledge Base (DR-KB). At inference, we retrieve top-$k$ instructions via Retrieval-Augmented Generation (RAG) to augment the agent prompt and patch likely logic gaps. Evaluation on open medical question answering (QA) benchmarks and a Return Visit Admissions (RVA) prediction task from internal clinical data demonstrates gains over baselines, improving both final-answer accuracy and reasoning fidelity. Ablation studies confirm gains from infusing reference reasoning rationales and the top-$k$ retrieval strategy. Clinicians' review of the output provides further assurance of the approach. Together, results suggest that DRL supports more reliable clinical decision-making in complex reasoning scenarios and offers a practical mechanism for deployment under limited token budgets.

</details>


### [299] [ESTAR: Early-Stopping Token-Aware Reasoning For Efficient Inference](https://arxiv.org/abs/2602.10004)
*Junda Wang,Zhichao Yang,Dongxu Zhang,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

TL;DR: 本文提出ESTAR方法，通过早期停止冗余推理来提升大推理模型（LRMs）的效率而不损失准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽性能优异，但常在已得出正确答案后仍继续生成冗余推理链，造成计算浪费。

Method: ESTAR包含三部分：(i) 基于轨迹的分类器判断何时可安全停止；(ii) 监督微调使模型自主生成<stop>信号；(iii) <stop>-感知的强化学习，在自生成停止点截断推理并引入计算感知奖励。

Result: 在四个推理数据集上，ESTAR将平均推理长度减少约3.7倍（从4799降至1290），准确率保持相近（74.9% vs. 74.2%），且具备强跨域泛化能力。

Conclusion: 早期停止是一种简单而有效的机制，可显著提升LRMs的推理效率。

Abstract: Large reasoning models (LRMs) achieve state-of-the-art performance by generating long chains-of-thought, but often waste computation on redundant reasoning after the correct answer has already been reached. We introduce Early-Stopping for Token-Aware Reasoning (ESTAR), which detects and reduces such reasoning redundancy to improve efficiency without sacrificing accuracy. Our method combines (i) a trajectory-based classifier that identifies when reasoning can be safely stopped, (ii) supervised fine-tuning to teach LRMs to propose self-generated <stop> signals, and (iii) <stop>-aware reinforcement learning that truncates rollouts at self-generated stop points with compute-aware rewards. Experiments on four reasoning datasets show that ESTAR reduces reasoning length by about 3.7x (from 4,799 to 1,290) while preserving accuracy (74.9% vs. 74.2%), with strong cross-domain generalization. These results highlight early stopping as a simple yet powerful mechanism for improving reasoning efficiency in LRMs.

</details>


### [300] [Discovering High Level Patterns from Simulation Traces](https://arxiv.org/abs/2602.10009)
*Sean Memery,Kartic Subr*

Main category: cs.AI

TL;DR: 本文提出一种自然语言引导的方法，从详细物理仿真日志中自动发现粗粒度物理模式（如'刚体碰撞'、'稳定支撑'等），通过合成程序将仿真日志映射为高层激活模式，从而提升大语言模型在物理推理、奖励程序生成等任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型缺乏真实物理 grounding，仅靠观测数据学习物理推理能力有限；直接将细粒度仿真轨迹作为上下文又面临可扩展性差的问题。

Method: 设计自然语言引导的程序合成方法，从仿真日志中提取并标注粗粒度物理模式（如 rigid-body collision），构建高层语义表征。

Result: 在两个物理基准测试中验证了该标注表征更利于自然语言对物理系统的推理；成功实现从自然语言目标生成有效奖励程序，可用于规划或监督学习。

Conclusion: 将仿真日志抽象为语言可理解的粗粒度物理模式，可弥补大语言模型在物理交互任务中的推理短板，为具身AI提供更高效、可解释的物理知识接口。

Abstract: Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning.

</details>


### [301] [Chain of Mindset: Reasoning with Adaptive Cognitive Modes](https://arxiv.org/abs/2602.10063)
*Tianyi Jiang,Arctanx An,Hengyi Feng,Naixin Zhai,Haodong Li,Xiaomin Yu,Jiahui Liu,Hanwen Du,Shuo Zhang,Zhi Yang,Jie Huang,Yuhua Li,Yongxin Ni,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: 本文提出Chain of Mindset (CoM)框架，通过在推理过程中动态切换四种不同认知模式（空间、收敛、发散、算法），提升大模型多步推理能力，无需额外训练，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型推理方法采用固定单一思维模式，无法适应问题求解各阶段所需的多样化认知方式，限制了模型智能水平的进一步提升。

Method: 提出无需训练的智能体框架CoM，将推理分解为四种功能异质的认知模式，并由元智能体根据推理状态动态选择最优模式，辅以双向上下文门控机制调控模块间信息流。

Result: 在数学、代码生成、科学问答和空间推理等六大挑战性基准上，CoM在Qwen3-VL-32B-Instruct和Gemini-2.0-Flash上分别超越最强基线4.96%和4.72%的整体准确率，同时兼顾推理效率。

Conclusion: 引入细粒度、自适应的认知模式切换机制是提升大模型复杂推理能力的有效路径，CoM为构建更类人化推理系统提供了新范式。

Abstract: Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\% and 4.72\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at \href{https://github.com/QuantaAlpha/chain-of-mindset}{https://github.com/QuantaAlpha/chain-of-mindset}.

</details>


### [302] [CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs](https://arxiv.org/abs/2602.10085)
*Richard Bornemann,Pierluigi Vito Amadori,Antoine Cully*

Main category: cs.AI

TL;DR: 本文提出CODE-SHARP框架，利用基础模型（FM）实现技能的开放性发现与演化，构建可执行的分层奖励程序（SHARP）图谱，并在Craftax环境中验证其能显著提升长时程目标求解能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习依赖人工设计奖励函数，难以支持未知技能的开放性发现；已有自动奖励设计方法仅限于预定义任务，缺乏开放性扩展能力。

Method: 提出CODE-SHARP框架，将技能库建模为有向图结构的可执行奖励函数（SHARP），利用基础模型持续生成、扩展和优化这些奖励程序；结合目标条件智能体与FM高阶规划器进行技能组合与执行。

Result: 在Craftax环境中，仅用SHARP生成的奖励训练的目标条件智能体可解决越来越长时程的目标；与预训练智能体和任务专家策略相比，复合性能平均提升超134%。

Conclusion: CODE-SHARP实现了真正开放性的技能发现与演化，为构建自主学习、持续成长的AI智能体提供了新范式。

Abstract: Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain limited to refining rewards for pre-defined tasks. To address this limitation, we introduce Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP), a novel framework leveraging Foundation Models (FM) to open-endedly expand and refine a hierarchical skill archive, structured as a directed graph of executable reward functions in code. We show that a goal-conditioned agent trained exclusively on the rewards generated by the discovered SHARP skills learns to solve increasingly long-horizon goals in the Craftax environment. When composed by a high-level FM-based planner, the discovered skills enable a single goal-conditioned agent to solve complex, long-horizon tasks, outperforming both pretrained agents and task-specific expert policies by over $134$% on average. We will open-source our code and provide additional videos $\href{https://sites.google.com/view/code-sharp/homepage}{here}$.

</details>


### [303] [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.10090)
*Zhaoyang Wang,Canwen Xu,Boyi Liu,Yite Wang,Siwei Han,Zhewei Yao,Huaxiu Yao,Yuxiong He*

Main category: cs.AI

TL;DR: 本文提出Agent World Model (AWM)，一种用于生成大量、多样且可靠的合成环境的流水线，以支持大规模自主智能体训练；该方法在1000个日常场景环境中验证了其有效性，并展现出优异的分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有自主智能体训练受限于缺乏多样且可靠的交互环境，难以规模化。

Method: 提出Agent World Model（AWM），一种代码驱动、数据库支撑的合成环境生成流水线，可生成1000个覆盖日常场景的环境，每个环境平均集成35种工具，并支持高效、可执行的多轮工具调用与可靠奖励设计。

Result: 在三个基准测试中，仅使用合成环境训练的多轮工具使用智能体展现出强分布外泛化能力；环境具备高一致性、可执行性与状态可访问性，支持高效强化学习训练。

Conclusion: AWM为自主智能体的大规模训练提供了可扩展、可靠且高效的合成环境基础，显著缓解了真实环境数据稀缺与不一致问题。

Abstract: Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [304] [LingxiDiagBench: A Multi-Agent Framework for Benchmarking LLMs in Chinese Psychiatric Consultation and Diagnosis](https://arxiv.org/abs/2602.09379)
*Shihao Xu,Tiancheng Zhou,Jiatong Ma,Yanli Ding,Yiming Yan,Ming Xiao,Guoyi Li,Haiyang Geng,Yunyun Han,Jianhua Chen,Yafeng Deng*

Main category: cs.MA

TL;DR: 本文提出了LingxiDiagBench，一个面向中文精神科诊断的多智能体大语言模型评测基准，包含16,000条模拟问诊对话数据集LingxiDiag-16K，并揭示了当前大模型在共病识别、多类别鉴别诊断及动态问诊能力上的显著短板。


<details>
  <summary>Details</summary>
Motivation: 精神障碍高发但专业资源匮乏，现有AI辅助诊断研究受限于缺乏兼具真实患者模拟、临床验证标签和多轮动态问诊支持的评测基准。

Method: 构建LingxiDiagBench基准，核心为EMR对齐、覆盖12类ICD-10精神障碍、符合真实人口与诊断分布的16,000条合成问诊对话数据集LingxiDiag-16K；结合静态诊断推理与动态多轮咨询任务，采用前沿大模型进行系统评测，并引入LLM-as-a-Judge评估问诊质量。

Result: 实验发现：(1)大模型在二分类（抑郁/焦虑）准确率达92.3%，但在共病识别（43.0%）和12类鉴别诊断（28.5%）上大幅下降；(2)动态问诊性能普遍低于静态诊断；(3)问诊质量与诊断准确率仅中度相关。

Conclusion: 当前大模型在复杂精神科诊断任务，尤其是动态交互与细粒度鉴别方面仍存在根本性局限；LingxiDiagBench为推动可信赖、临床可用的AI精神健康工具提供了标准化评测基础。

Abstract: Mental disorders are highly prevalent worldwide, but the shortage of psychiatrists and the inherent subjectivity of interview-based diagnosis create substantial barriers to timely and consistent mental-health assessment. Progress in AI-assisted psychiatric diagnosis is constrained by the absence of benchmarks that simultaneously provide realistic patient simulation, clinician-verified diagnostic labels, and support for dynamic multi-turn consultation. We present LingxiDiagBench, a large-scale multi-agent benchmark that evaluates LLMs on both static diagnostic inference and dynamic multi-turn psychiatric consultation in Chinese. At its core is LingxiDiag-16K, a dataset of 16,000 EMR-aligned synthetic consultation dialogues designed to reproduce real clinical demographic and diagnostic distributions across 12 ICD-10 psychiatric categories. Through extensive experiments across state-of-the-art LLMs, we establish key findings: (1) although LLMs achieve high accuracy on binary depression--anxiety classification (up to 92.3%), performance deteriorates substantially for depression--anxiety comorbidity recognition (43.0%) and 12-way differential diagnosis (28.5%); (2) dynamic consultation often underperforms static evaluation, indicating that ineffective information-gathering strategies significantly impair downstream diagnostic reasoning; (3) consultation quality assessed by LLM-as-a-Judge shows only moderate correlation with diagnostic accuracy, suggesting that well-structured questioning alone does not ensure correct diagnostic decisions. We release LingxiDiag-16K and the full evaluation framework to support reproducible research at https://github.com/Lingxi-mental-health/LingxiDiagBench.

</details>


### [305] [Dieu khien he da tac tu](https://arxiv.org/abs/2602.09412)
*Minh Hoang Trinh,Hieu Minh Nguyen*

Main category: cs.MA

TL;DR: This book provides a systematic and pedagogical treatment of fundamental principles in multi-agent system control, developed from teaching experience since 2021, covering graph theory, linear consensus algorithms, and applications like formation control and distributed optimization.


<details>
  <summary>Details</summary>
Motivation: The scarcity of textbooks—especially in English—that systematically present foundational principles of multi-agent system control motivates this book.

Method: The book adopts a step-by-step pedagogical approach, organizing content into three parts: (I) introduction and graph theory, (II) linear consensus algorithm design and analysis, and (III) selected applications and research directions; each chapter includes notes, references, and exercises.

Result: A comprehensive, teachable textbook on multi-agent control, originally developed in Vietnamese and structured to bridge undergraduate learning and research-level complexity.

Conclusion: The book fills an educational gap by offering a coherent, accessible, and application-informed foundation for multi-agent system control, suitable for courses and self-study.

Abstract: Since the early 2000s, control of multiagent systems has attracted significant research interest, with applications ranging from natural collective behaviors and social dynamics to engineered systems such as autonomous vehicles, sensor networks, and smart grids. Although research on multi-agent systems has diversified into numerous specialized directions, textbooks -- including those in English -- that provide a systematic treatment of the fundamental principles of multi-agent system control remain scarce. The material presented in this book has been developed and used in teaching since 2021, initially as a concise Vietnamese-language reference for the courses Networked Control Systems and Control of Multi-Agent Systems at Hanoi University of Science and Technology. The book focuses on a selection of fundamental topics of broad and continuing interest in the field. The complexity of several topics is asymptotic to that encountered in research-level studies, however, the analysis is presented in a step-by-step manner to facilitate access to commonly used methods and tools.
  The material is divided into three main parts. Part I introduces multiagent systems and basic graph-theoretic concepts. Part II addresses the design and analysis of linear consensus algorithms. Part III covers selected applications and research directions, including formation control, network localization, distributed optimization, opinion dynamics, and matrix-weighted networks. Each chapter concludes with notes on notable researchers in this field, further reading, and exercises.
  This book cannot be completed without the encouragement, support and suggestions from families, colleagues and friends. The authors appreciate feedback from readers to further improve the content of the book.

</details>


### [306] [Tiny Moves: Game-based Hypothesis Refinement](https://arxiv.org/abs/2602.09801)
*Agnieszka Dobrowolska,Rogier Hintzen,Martin Balla,Karl Gemayel,Sabine Reichert,Thomas Charman,Jen Ning Lim,Lindsay Edwards,Anna Gogleva*

Main category: cs.MA

TL;DR: 本文提出了一种名为'Hypothesis Game'的符号化框架，利用大语言模型（LLM）代理在共享假设状态上执行基于固定语法规则的推理操作，以实现科学假设的渐进式精细化。实验表明，该方法在错误修复和部分线索重建任务中优于强提示基线，提升了可控性、可解释性和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 科学进步常通过小范围、局部化的修订推进，而非大规模重写；现有机器学习方法将假设视为端到端预测，掩盖了科学推理的渐进结构。

Method: 提出The Hypothesis Game符号形式化框架，定义固定语法的推理动作，由LLM代理在共享假设状态上进行增量式编辑；在通路级机制细化任务中实例化并评估。

Result: 在腐败恢复（corruption recovery）主任务中，游戏方法比强提示基线更有效地消除错误且精度更高，同时保持假设结构有效性；在部分线索重建任务中表现与最强基线相当。

Conclusion: 基于游戏的推理为构建更可控、可解释、可迁移的科学发现假设精炼系统提供了原理性路径。

Abstract: Most machine learning approaches to scientific discovery frame hypotheses as end-to-end predictions, obscuring the incremental structure of scientific reasoning. We propose The Hypothesis Game, a symbolic formalism for hypothesis refinement in which LLM agents operate on a shared hypothesis state using a fixed grammar of reasoning moves. The framework is motivated by the observation that scientific progress often proceeds through small, localized revisions, grounded in domain context, rather than extensive rewrites. We instantiate a minimal game with LLM agents and evaluate it on pathway-level mechanistic refinement tasks. In the primary setting of corruption recovery, where hypotheses contain controlled errors, the game-based approach consistently removes more errors and achieves higher precision than strong prompting baselines, while preserving valid structure through incremental edits. In a secondary reconstruction setting from partial cues, it performs comparably to the strongest baseline, indicating that explicit move-based refinement remains competitive even when ground-truth recovery is difficult. These findings support game-based reasoning as a principled route to more controllable, interpretable, and transferable hypothesis refinement systems for scientific discovery.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [307] [SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes](https://arxiv.org/abs/2602.09153)
*Nicholas Pfaff,Thomas Cohn,Sergey Zakharov,Rick Cory,Russ Tedrake*

Main category: cs.RO

TL;DR: 本文提出SceneSmith，一种基于自然语言提示生成仿真就绪室内环境的分层代理框架，通过多阶段协作（布局→家具放置→小物体填充）结合文本到3D生成、数据集检索与物理属性估计，显著提升场景密度、真实感与物理合理性，并验证其在机器人策略评估中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有仿真环境无法充分反映真实室内空间的多样性与物理复杂性，场景合成方法生成的房间家具稀疏、缺乏密集杂乱、可动家具及必要物理属性，难以支撑机器人操作训练与评估。

Method: 提出SceneSmith分层代理框架，包含设计师、批评家和协调者三个VLM代理，按建筑布局、家具摆放、小物体填充三阶段迭代生成；集成文本到3D合成（静态物体）、数据集检索（可动物体）与物理属性估计；支持仿真就绪输出。

Result: 相比先前方法，生成物体数量提升3–6倍，物体间碰撞率<2%，96%物体在物理仿真中保持稳定；用户研究（205人）显示平均真实感与提示忠实度胜率分别为92%和91%；验证了其在端到端机器人策略自动评估流水线中的可用性。

Conclusion: SceneSmith有效弥合了仿真环境与真实室内复杂性之间的鸿沟，为大规模、高保真、物理可信的家用机器人训练与评估提供了新范式。

Abstract: Simulation has become a key tool for training and evaluating home robots at scale, yet existing environments fail to capture the diversity and physical complexity of real indoor spaces. Current scene synthesis methods produce sparsely furnished rooms that lack the dense clutter, articulated furniture, and physical properties essential for robotic manipulation. We introduce SceneSmith, a hierarchical agentic framework that generates simulation-ready indoor environments from natural language prompts. SceneSmith constructs scenes through successive stages$\unicode{x2013}$from architectural layout to furniture placement to small object population$\unicode{x2013}$each implemented as an interaction among VLM agents: designer, critic, and orchestrator. The framework tightly integrates asset generation through text-to-3D synthesis for static objects, dataset retrieval for articulated objects, and physical property estimation. SceneSmith generates 3-6x more objects than prior methods, with <2% inter-object collisions and 96% of objects remaining stable under physics simulation. In a user study with 205 participants, it achieves 92% average realism and 91% average prompt faithfulness win rates against baselines. We further demonstrate that these environments can be used in an end-to-end pipeline for automatic robot policy evaluation.

</details>


### [308] [Feasible Static Workspace Optimization of Tendon Driven Continuum Robot based on Euclidean norm](https://arxiv.org/abs/2602.09046)
*Mohammad Jabari,Carmen Visconte,Giuseppe Quaglia,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出了一种基于可行静态工作空间（FSW）优化肌腱驱动连续体机器人（TDCR）设计的方法，通过遗传算法最大化机器人末端位置的欧氏范数，并在外部力和力矩作用下验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 提升肌腱驱动连续体机器人在外部负载下的可行静态工作空间，以增强其操作性能和实用性。

Method: 将肌腱力作为设计变量，采用遗传算法优化方法，在考虑外部力和力矩约束下，最大化TDCR末端位置的欧氏范数以确定其可行静态工作空间。

Result: 该方法能有效识别最优肌腱力，显著扩大TDCR在外部力和力矩作用下的可行静态工作空间。

Conclusion: 基于FSW的优化设计方法为TDCR结构与控制参数协同优化提供了新思路，提升了其在复杂环境中的适应性与鲁棒性。

Abstract: This paper focuses on the optimal design of a tendon-driven continuum robot (TDCR) based on its feasible static workspace (FSW). The TDCR under consideration is a two-segment robot driven by eight tendons, with four tendon actuators per segment. Tendon forces are treated as design variables, while the feasible static workspace (FSW) serves as the optimization objective. To determine the robot's feasible static workspace, a genetic algorithm optimization approach is employed to maximize a Euclidian norm of the TDCR's tip position over the workspace. During the simulations, the robot is subjected to external loads, including torques and forces. The results demonstrate the effectiveness of the proposed method in identifying optimal tendon forces to maximize the feasible static workspace, even under the influence of external forces and torques.

</details>


### [309] [Legs Over Arms: On the Predictive Value of Lower-Body Pose for Human Trajectory Prediction from Egocentric Robot Perception](https://arxiv.org/abs/2602.09076)
*Nhat Le,Daeun Song,Xuesu Xiao*

Main category: cs.RO

TL;DR: 本文研究了利用人体骨骼特征（特别是下肢3D关键点及生物力学线索）提升多智能体轨迹预测精度，显著降低了平均位移误差，并验证了单目环视图像的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法多将人简化为质点，忽略人体运动细节；而社交机器人在密集环境中需更精准的人类轨迹预测，因此需探索更具判别性的运动表征。

Method: 系统评估2D/3D骨骼关键点及衍生的生物力学线索作为额外输入对多智能体轨迹预测的影响，在JRDB数据集和新构建的360度全景视频社交导航数据集上进行实验。

Result: 仅使用下肢3D关键点可使平均位移误差降低13%；加入对应生物力学线索后进一步提升1–4%；在2D关键点（来自等距矩形全景图）上同样观察到性能增益。

Conclusion: 人类下肢运动蕴含强预测性信息，仅依赖单目环视视觉即可有效支持轨迹预测，为社交机器人感知设计提供了明确指导。

Abstract: Predicting human trajectory is crucial for social robot navigation in crowded environments. While most existing approaches treat human as point mass, we present a study on multi-agent trajectory prediction that leverages different human skeletal features for improved forecast accuracy. In particular, we systematically evaluate the predictive utility of 2D and 3D skeletal keypoints and derived biomechanical cues as additional inputs. Through a comprehensive study on the JRDB dataset and another new dataset for social navigation with 360-degree panoramic videos, we find that focusing on lower-body 3D keypoints yields a 13% reduction in Average Displacement Error and augmenting 3D keypoint inputs with corresponding biomechanical cues provides a further 1-4% improvement. Notably, the performance gain persists when using 2D keypoint inputs extracted from equirectangular panoramic images, indicating that monocular surround vision can capture informative cues for motion forecasting. Our finding that robots can forecast human movement efficiently by watching their legs provides actionable insights for designing sensing capabilities for social robot navigation.

</details>


### [310] [Agile asymmetric multi-legged locomotion: contact planning via geometric mechanics and spin model duality](https://arxiv.org/abs/2602.09123)
*Jackson Habala,Gabriel B. Margolis,Tianyu Wang,Pratyush Bhatt,Juntao He,Naheel Naeem,Zhaochen Xu,Pulkit Agrawal,Daniel I. Goldman,Di Luo,Baxi Chong*

Main category: cs.RO

TL;DR: 本文提出了一种基于几何力学和统计力学自旋模型对偶性的新框架，用于发现多足机器人中的新型控制结构，成功在六足机器人上实现了前向速度提升50%的非对称步态，并揭示了高维具身系统中由对称性重构引发的新运动行为。


<details>
  <summary>Details</summary>
Motivation: 现有研究过度集中于双足和四足机器人，缺乏能解释‘何时及如何通过增加腿数提升运动性能’的原理性控制框架；多足系统因接触协调导致维度灾难，传统低维步态无法利用高维系统的对称性和控制自由度。

Method: 结合几何力学将接触丰富的运动规划简化为图优化问题，并引入源自统计力学的自旋模型对偶框架，利用对称性破缺指导最优步态重组。

Result: 在六足机器人上发现一种新型不对称运动策略：前向速度达0.61体长/周期（较传统步态提升50%）；控制层面表现为身体朝向在快速顺时针与慢速逆时针转动阶段间非对称振荡；硬件层面显示同侧两条腿可完全被动化甚至替换为刚性部件而不影响性能。

Conclusion: 该框架不仅为多足机器人提供了可扩展的原理性控制范式，还揭示了高维具身系统中通过对称性重构可涌现出超越传统直觉的新型运动模态，为未来多足乃至超多足机器人设计奠定理论基础。

Abstract: Legged robot research is presently focused on bipedal or quadrupedal robots, despite capabilities to build robots with many more legs to potentially improve locomotion performance. This imbalance is not necessarily due to hardware limitations, but rather to the absence of principled control frameworks that explain when and how additional legs improve locomotion performance. In multi-legged systems, coordinating many simultaneous contacts introduces a severe curse of dimensionality that challenges existing modeling and control approaches. As an alternative, multi-legged robots are typically controlled using low-dimensional gaits originally developed for bipeds or quadrupeds. These strategies fail to exploit the new symmetries and control opportunities that emerge in higher-dimensional systems. In this work, we develop a principled framework for discovering new control structures in multi-legged locomotion. We use geometric mechanics to reduce contact-rich locomotion planning to a graph optimization problem, and propose a spin model duality framework from statistical mechanics to exploit symmetry breaking and guide optimal gait reorganization. Using this approach, we identify an asymmetric locomotion strategy for a hexapod robot that achieves a forward speed of 0.61 body lengths per cycle (a 50% improvement over conventional gaits). The resulting asymmetry appears at both the control and hardware levels. At the control level, the body orientation oscillates asymmetrically between fast clockwise and slow counterclockwise turning phases for forward locomotion. At the hardware level, two legs on the same side remain unactuated and can be replaced with rigid parts without degrading performance. Numerical simulations and robophysical experiments validate the framework and reveal novel locomotion behaviors that emerge from symmetry reforming in high-dimensional embodied systems.

</details>


### [311] [Elements of Robot Morphology: Supporting Designers in Robot Form Exploration](https://arxiv.org/abs/2602.09203)
*Amy Koike,Ge,Guo,Xinning He,Callie Y. Kim,Dakota Sullivan,Bilge Mutlu*

Main category: cs.RO

TL;DR: 本文提出了机器人形态学的五个基本要素框架（感知、关节、末端执行器、运动和结构），并开发了形态探索模块（MEB）以支持人机交互中机器人形态的系统化、协作式设计与探索。


<details>
  <summary>Details</summary>
Motivation: 机器人形态在人机交互中至关重要，但目前缺乏能指导系统化形态探索的设计框架。

Method: 通过分析现有机器人，提炼出五个基本形态要素，并开发了可触摸的形态探索模块（MEB）用于实践验证；通过案例研究和设计工作坊进行评估。

Result: 验证了该框架和工具在机器人形态分析、创意构思、反思及协作设计中的有效性。

Conclusion: Elements of Robot Morphology 框架及其配套工具 MEB 为机器人形态的系统化、参与式设计提供了可行且实用的方法论支持。

Abstract: Robot morphology, the form, shape, and structure of robots, is a key design space in human-robot interaction (HRI), shaping how robots function, express themselves, and interact with people. Yet, despite its importance, little is known about how design frameworks can guide systematic form exploration. To address this gap, we introduce Elements of Robot Morphology, a framework that identifies five fundamental elements: perception, articulation, end effectors, locomotion, and structure. Derived from an analysis of existing robots, the framework supports structured exploration of diverse robot forms. To operationalize the framework, we developed Morphology Exploration Blocks (MEB), a set of tangible blocks that enable hands-on, collaborative experimentation with robot morphologies. We evaluate the framework and toolkit through a case study and design workshops, showing how they support analysis, ideation, reflection, and collaborative robot design.

</details>


### [312] [A Collaborative Safety Shield for Safe and Efficient CAV Lane Changes in Congested On-Ramp Merging](https://arxiv.org/abs/2602.10007)
*Bharathkumar Hegde,Melanie Bouroche*

Main category: cs.RO

TL;DR: 本文提出了一种结合安全保证与协作效率的多智能体车道变换控制器MARL-MASS，通过控制屏障函数（CBF）构建多智能体安全盾（MASS），并融合多智能体强化学习（MARL）与定制化奖励函数，在密集交通场景中实现安全且高效的协同换道。


<details>
  <summary>Details</summary>
Motivation: 现有车道变换控制器难以同时兼顾安全性与交通效率，尤其在密集交通中二者存在冲突；需一种能协同建模多车交互并严格满足安全约束的方法。

Method: 提出基于控制屏障函数（CBFs）的多智能体安全盾（MASS），利用图结构建模车辆间交互拓扑；将先进MARL控制器与MASS集成，并设计以效率提升为优先的定制化奖励函数。

Result: 在拥堵匝道合流仿真中验证了MARL-MASS：MASS确保严格的安全约束满足，定制奖励提升了MARL策略训练稳定性，整体实现了安全与效率的平衡。

Conclusion: MARL-MASS成功解决了密集交通中安全与效率的权衡问题，为CAVs提供了一种可验证安全、支持协作优化的实用化车道变换控制框架。

Abstract: Lane changing in dense traffic is a significant challenge for Connected and Autonomous Vehicles (CAVs). Existing lane change controllers primarily either ensure safety or collaboratively improve traffic efficiency, but do not consider these conflicting objectives together. To address this, we propose the Multi-Agent Safety Shield (MASS), designed using Control Barrier Functions (CBFs) to enable safe and collaborative lane changes. The MASS enables collaboration by capturing multi-agent interactions among CAVs through interaction topologies constructed as a graph using a simple algorithm. Further, a state-of-the-art Multi-Agent Reinforcement Learning (MARL) lane change controller is extended by integrating MASS to ensure safety and defining a customised reward function to prioritise efficiency improvements. As a result, we propose a lane change controller, known as MARL-MASS, and evaluate it in a congested on-ramp merging simulation. The results demonstrate that MASS enables collaborative lane changes with safety guarantees by strictly respecting the safety constraints. Moreover, the proposed custom reward function improves the stability of MARL policies trained with a safety shield. Overall, by encouraging the exploration of a collaborative lane change policy while respecting safety constraints, MARL-MASS effectively balances the trade-off between ensuring safety and improving traffic efficiency in congested traffic. The code for MARL-MASS is available with an open-source licence at https://github.com/hkbharath/MARL-MASS

</details>


### [313] [Risk-Aware Obstacle Avoidance Algorithm for Real-Time Applications](https://arxiv.org/abs/2602.09204)
*Ozan Kaya,Emir Cem Gezer,Roger Skjetne,Ingrid Bouwer Utne*

Main category: cs.RO

TL;DR: 本文提出了一种面向自主水面艇的混合风险感知导航架构，融合概率障碍建模与平滑轨迹优化，通过风险地图引导RRT*规划并用B样条优化轨迹，在动态海洋环境中提升了安全性与适应性。


<details>
  <summary>Details</summary>
Motivation: 海洋环境动态多变，自主系统需在不确定性下实现鲁棒导航，现有LIDAR或视觉单模态方法在安全性和自适应性方面存在不足。

Method: 构建融合障碍物距离与动态目标行为的概率风险地图；设计风险偏差的RRT*规划器，支持三种重连线模式（最小路径长度、最小风险、路径与风险加权优化）；采用B样条对初始路径进行平滑优化。

Result: 在含静态与动态障碍物的实验场景中，系统实现了安全导航、轨迹平滑及对环境风险的动态适应；相比传统LIDAR或视觉方案，在操作安全性和自主性上均有提升。

Conclusion: 该混合风险感知导航框架为不确定、动态海洋环境下的自主航行任务提供了可行且有前景的解决方案。

Abstract: Robust navigation in changing marine environments requires autonomous systems capable of perceiving, reasoning, and acting under uncertainty. This study introduces a hybrid risk-aware navigation architecture that integrates probabilistic modeling of obstacles along the vehicle path with smooth trajectory optimization for autonomous surface vessels. The system constructs probabilistic risk maps that capture both obstacle proximity and the behavior of dynamic objects. A risk-biased Rapidly Exploring Random Tree (RRT) planner leverages these maps to generate collision-free paths, which are subsequently refined using B-spline algorithms to ensure trajectory continuity. Three distinct RRT* rewiring modes are implemented based on the cost function: minimizing the path length, minimizing risk, and optimizing a combination of the path length and total risk. The framework is evaluated in experimental scenarios containing both static and dynamic obstacles. The results demonstrate the system's ability to navigate safely, maintain smooth trajectories, and dynamically adapt to changing environmental risks. Compared with conventional LIDAR or vision-only navigation approaches, the proposed method shows improvements in operational safety and autonomy, establishing it as a promising solution for risk-aware autonomous vehicle missions in uncertain and dynamic environments.

</details>


### [314] [From Legible to Inscrutable Trajectories: (Il)legible Motion Planning Accounting for Multiple Observers](https://arxiv.org/abs/2602.09227)
*Ananya Yammanuru,Maria Lusardi,Nancy M. Amato,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 本文提出了混合动机有限可观测性可读运动规划（MMLO-LMP）问题，旨在为多动机、部分可观测环境下的机器人生成对善意观察者可读、对恶意观察者不可读的轨迹，并设计了求解器DUBIOUS验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在现实复杂环境中，不同观察者（人类或机器人）具有不同动机（合作/对抗）且观测能力受限（仅能看见部分环境），传统单一目标（仅追求可读或不可读）的运动规划无法满足需求。

Method: 形式化定义MMLO-LMP问题；提出多种策略应对混合动机与有限可观测性；设计基于优化的轨迹生成器DUBIOUS。

Result: DUBIOUS能有效生成兼顾对正向观察者可读、对负向观察者不可读、并适配各观察者可视域的轨迹；实验验证了其平衡能力。

Conclusion: MMLO-LMP为多动机、部分可观测场景提供了更贴近实际的运动规划新范式；DUBIOUS是首个针对该问题的有效求解器；未来工作包括扩展至移动观察者和观察者协作等变体。

Abstract: In cooperative environments, such as in factories or assistive scenarios, it is important for a robot to communicate its intentions to observers, who could be either other humans or robots. A legible trajectory allows an observer to quickly and accurately predict an agent's intention. In adversarial environments, such as in military operations or games, it is important for a robot to not communicate its intentions to observers. An illegible trajectory leads an observer to incorrectly predict the agent's intention or delays when an observer is able to make a correct prediction about the agent's intention. However, in some environments there are multiple observers, each of whom may be able to see only part of the environment, and each of whom may have different motives. In this work, we introduce the Mixed-Motive Limited-Observability Legible Motion Planning (MMLO-LMP) problem, which requires a motion planner to generate a trajectory that is legible to observers with positive motives and illegible to observers with negative motives while also considering the visibility limitations of each observer. We highlight multiple strategies an agent can take while still achieving the problem objective. We also present DUBIOUS, a trajectory optimizer that solves MMLO-LMP. Our results show that DUBIOUS can generate trajectories that balance legibility with the motives and limited visibility regions of the observers. Future work includes many variations of MMLO-LMP, including moving observers and observer teaming.

</details>


### [315] [STaR: Scalable Task-Conditioned Retrieval for Long-Horizon Multimodal Robot Memory](https://arxiv.org/abs/2602.09255)
*Mingfeng Yuan,Hao Zhang,Mahan Mohammadi,Runhao Li,Jinjun Shan,Steven L. Waslander*

Main category: cs.RO

TL;DR: 本文提出STaR框架，通过构建任务无关的多模态长期记忆和基于信息瓶颈原理的可扩展任务条件检索算法，提升移动机器人在开放动态场景中长时程导航与问答的推理能力。


<details>
  <summary>Details</summary>
Motivation: 移动机器人需在长期、开放、动态的室内外环境中执行多样化任务，核心挑战在于构建可扩展的长时程记忆以支持规划、检索与多粒度指令推理，并生成精确可执行的导航决策。

Method: 提出STaR（Scalable Task-Conditioned Retrieval）框架：（i）构建任务无关、保留细粒度环境语义（物体属性、空间关系、动态事件）的多模态长期记忆；（ii）设计基于信息瓶颈原理的可扩展任务条件检索算法，从长期记忆中提取紧凑、非冗余、信息丰富的候选记忆用于上下文推理。

Result: 在NaVQA和自建仓库基准WH-VQA上，STaR显著优于强基线，成功率更高、空间误差更低；并在真实Husky机器人上成功部署于室内外环境，验证了其长时程推理鲁棒性、可扩展性与实用性。

Conclusion: STaR为移动机器人提供了可泛化、可扩展、高精度的长期记忆与检索机制，有效支撑开放场景下的具身智能推理与导航。

Abstract: Mobile robots are often deployed over long durations in diverse open, dynamic scenes, including indoor setting such as warehouses and manufacturing facilities, and outdoor settings such as agricultural and roadway operations. A core challenge is to build a scalable long-horizon memory that supports an agentic workflow for planning, retrieval, and reasoning over open-ended instructions at variable granularity, while producing precise, actionable answers for navigation. We present STaR, an agentic reasoning framework that (i) constructs a task-agnostic, multimodal long-term memory that generalizes to unseen queries while preserving fine-grained environmental semantics (object attributes, spatial relations, and dynamic events), and (ii) introduces a Scalable TaskConditioned Retrieval algorithm based on the Information Bottleneck principle to extract from long-term memory a compact, non-redundant, information-rich set of candidate memories for contextual reasoning. We evaluate STaR on NaVQA (mixed indoor/outdoor campus scenes) and WH-VQA, a customized warehouse benchmark with many visually similar objects built with Isaac Sim, emphasizing contextual reasoning. Across the two datasets, STaR consistently outperforms strong baselines, achieving higher success rates and markedly lower spatial error. We further deploy STaR on a real Husky wheeled robot in both indoor and outdoor environments, demonstrating robust longhorizon reasoning, scalability, and practical utility.

</details>


### [316] [Data-centric Design of Learning-based Surgical Gaze Perception Models in Multi-Task Simulation](https://arxiv.org/abs/2602.09259)
*Yizhou Li,Shuyuan Yang,Jiaji Su,Zonghe Chua*

Main category: cs.RO

TL;DR: 本文提出了一种配对的主动-被动多任务外科注视数据集，用于研究不同专家水平（中级 vs. 新手）和感知模式（主动执行 vs. 被动观看）对注意力模型学习效果的影响；结果表明被动注视可部分替代主动注视监督，尤其新手被动标签在高质量演示中近似中级被动注视，为可扩展的外科教学与感知建模提供可行路径。


<details>
  <summary>Details</summary>
Motivation: 在机器人辅助微创手术中，触觉反馈和深度线索减少，使专家视觉感知更为关键；但术中专家注视数据采集成本高，且尚不清楚注视监督的来源（专家水平与感知模式）如何影响注意力模型的学习效果。

Method: 构建了一个在da Vinci SimNow模拟器上采集的配对主动-被动、多任务外科注视数据集，涵盖四个训练项目；主动注视在VR头显执行任务时同步眼动追踪获取，对应视频再用于采集被动注视；通过注视密度重叠分析和单帧显著性建模评估不同注视监督下的模型性能。

Result: MSI-Net模型预测稳定且可解释，SalGAN则不稳定且常与人类注视不一致；被动注视训练模型能恢复大部分中级主动注视特征，但存在可预测退化，且主动与被动目标间迁移不对称；新手被动标签在高质量演示中可较好逼近中级被动注视。

Conclusion: 被动注视（尤其是新手被动注视）可在一定条件下作为主动注视监督的有效替代，为低成本、可扩展的外科教练系统与学习型手术感知模型提供了实用方案。

Abstract: In robot-assisted minimally invasive surgery (RMIS), reduced haptic feedback and depth cues increase reliance on expert visual perception, motivating gaze-guided training and learning-based surgical perception models. However, operative expert gaze is costly to collect, and it remains unclear how the source of gaze supervision, both expertise level (intermediate vs. novice) and perceptual modality (active execution vs. passive viewing), shapes what attention models learn. We introduce a paired active-passive, multi-task surgical gaze dataset collected on the da Vinci SimNow simulator across four drills. Active gaze was recorded during task execution using a VR headset with eye tracking, and the corresponding videos were reused as stimuli to collect passive gaze from observers, enabling controlled same-video comparisons. We quantify skill- and modality-dependent differences in gaze organization and evaluate the substitutability of passive gaze for operative supervision using fixation density overlap analyses and single-frame saliency modeling. Across settings, MSI-Net produced stable, interpretable predictions, whereas SalGAN was unstable and often poorly aligned with human fixations. Models trained on passive gaze recovered a substantial portion of intermediate active attention, but with predictable degradation, and transfer was asymmetric between active and passive targets. Notably, novice passive labels approximated intermediate-passive targets with limited loss on higher-quality demonstrations, suggesting a practical path for scalable, crowd-sourced gaze supervision in surgical coaching and perception modeling.

</details>


### [317] [Disambiguating Anthropomorphism and Anthropomimesis in Human-Robot Interaction](https://arxiv.org/abs/2602.09287)
*Minja Axelsson,Henry Shevlin*

Main category: cs.RO

TL;DR: 本文初步区分了人机交互（HRI）与社交机器人领域中的两个理论概念：拟人化（anthropomorphism）与拟人模仿（anthropomimesis），明确前者指用户将人类特质归因于机器人，后者指开发者主动在机器人中设计人类特征，并强调责任主体不同，以促进后续理论研究与机器人设计评估。


<details>
  <summary>Details</summary>
Motivation: 澄清HRI领域中常被混淆的anthropomorphism与anthomimesis概念，明确其责任主体（感知者vs设计者），为后续理论构建与实践提供基础。

Method: 概念辨析与定义界定，基于理论分析提出二者在主体、方向和作用机制上的根本区别。

Result: 清晰界定了anthropomorphism（用户感知层面）与anthropomimesis（开发者设计层面）的内涵与外延，并指出二者在责任归属上的本质差异。

Conclusion: 该概念区分有助于推动HRI学术研究的严谨性，并为未来机器人设计与评估提供更准确的理论框架。

Abstract: In this preliminary work, we offer an initial disambiguation of the theoretical concepts anthropomorphism and anthropomimesis in Human-Robot Interaction (HRI) and social robotics. We define anthropomorphism as users perceiving human-like qualities in robots, and anthropomimesis as robot developers designing human-like features into robots. This contribution aims to provide a clarification and exploration of these concepts for future HRI scholarship, particularly regarding the party responsible for human-like qualities - robot perceiver for anthropomorphism, and robot designer for anthropomimesis. We provide this contribution so that researchers can build on these disambiguated theoretical concepts for future robot design and evaluation.

</details>


### [318] [CAPER: Constrained and Procedural Reasoning for Robotic Scientific Experiments](https://arxiv.org/abs/2602.09367)
*Jinghan Yang,Jingyi Hou,Xinbo Yu,Wei He,Yifan Wu*

Main category: cs.RO

TL;DR: CAPER是一种面向科学实验的机器人框架，通过分层责任分离结构（任务级推理、中层多模态接地、低层强化学习控制）提升长时程操作的程序正确性、鲁棒性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有端到端视觉-语言-动作（VLA）模型在协议敏感、低示范、少监督的科学实验场景中易出错且不可靠，难以满足程序正确性和执行鲁棒性要求。

Method: 提出CAPER框架，采用约束性与程序化推理：任务层基于显式约束生成合法动作序列；中层通过多模态接地实现子任务，避免LLM直接做空间决策；底层用少量示范的强化学习适应物理不确定性；全程使用可解释中间表示编码程序承诺。

Result: 在科学工作流基准和公开长时程操作数据集上，CAPER在成功率和程序正确性上显著优于基线，尤其在低数据和长时程设置下优势明显。

Conclusion: 将学习与推理显式解耦并分层约束，比增强端到端策略更适配高可靠性科学机器人任务，提升了可控性、鲁棒性与数据效率。

Abstract: Robotic assistance in scientific laboratories requires procedurally correct long-horizon manipulation, reliable execution under limited supervision, and robustness in low-demonstration regimes. Such conditions greatly challenge end-to-end vision-language-action (VLA) models, whose assumptions of recoverable errors and data-driven policy learning often break down in protocol-sensitive experiments. We propose CAPER, a framework for Constrained And ProcEdural Reasoning for robotic scientific experiments, which explicitly restricts where learning and reasoning occur in the planning and control pipeline. Rather than strengthening end-to-end policies, CAPER enforces a responsibility-separated structure: task-level reasoning generates procedurally valid action sequences under explicit constraints, mid-level multimodal grounding realizes subtasks without delegating spatial decision-making to large language models, and low-level control adapts to physical uncertainty via reinforcement learning with minimal demonstrations. By encoding procedural commitments through interpretable intermediate representations, CAPER prevents execution-time violations of experimental logic, improving controllability, robustness, and data efficiency. Experiments on a scientific workflow benchmark and a public long-horizon manipulation dataset demonstrate consistent improvements in success rate and procedural correctness, particularly in low-data and long-horizon settings.

</details>


### [319] [Certified Gradient-Based Contact-Rich Manipulation via Smoothing-Error Reachable Tubes](https://arxiv.org/abs/2602.09368)
*Wei-Chen Li,Glen Chou*

Main category: cs.RO

TL;DR: 本文提出了一种结合平滑动力学规划与误差量化补偿的新方法，用于接触丰富场景下的控制器优化，在保证真实混合动力学约束满足和目标可达性的同时，利用平滑模型提供有效梯度。


<details>
  <summary>Details</summary>
Motivation: 梯度优化方法在接触丰富的操作中面临挑战，因为混合接触动力学导致梯度不连续或消失；而单纯平滑动力学会引入模型失配，导致真实系统上控制器失效。

Method: 提出基于凸优化的新型可微仿真器，对接触动力学和几何同时进行平滑，并将与真实动力学的偏差建模为集合值偏差；通过该偏差对时变仿射反馈策略优化施加解析可达集边界约束。

Result: 在平面推挤、物体旋转和灵巧手内操作等任务中验证了方法有效性，相比基线方法具有更低的安全违规率和目标误差，并提供了对真实闭环混合动力学的约束满足与目标可达性形式化保证。

Conclusion: 本文首次实现了面向接触丰富操作的、具备形式化安全保证的可微分物理驱动策略综合方法， bridging 可微物理与集合值鲁棒控制。

Abstract: Gradient-based methods can efficiently optimize controllers using physical priors and differentiable simulators, but contact-rich manipulation remains challenging due to discontinuous or vanishing gradients from hybrid contact dynamics. Smoothing the dynamics yields continuous gradients, but the resulting model mismatch can cause controller failures when executed on real systems. We address this trade-off by planning with smoothed dynamics while explicitly quantifying and compensating for the induced errors, providing formal guarantees of constraint satisfaction and goal reachability on the true hybrid dynamics. Our method smooths both contact dynamics and geometry via a novel differentiable simulator based on convex optimization, which enables us to characterize the discrepancy from the true dynamics as a set-valued deviation. This deviation constrains the optimization of time-varying affine feedback policies through analytical bounds on the system's reachable set, enabling robust constraint satisfaction guarantees for the true closed-loop hybrid dynamics, while relying solely on informative gradients from the smoothed dynamics. We evaluate our method on several contact-rich tasks, including planar pushing, object rotation, and in-hand dexterous manipulation, achieving guaranteed constraint satisfaction with lower safety violation and goal error than baselines. By bridging differentiable physics with set-valued robust control, our method is the first certifiable gradient-based policy synthesis method for contact-rich manipulation.

</details>


### [320] [Phase-Aware Policy Learning for Skateboard Riding of Quadruped Robots via Feature-wise Linear Modulation](https://arxiv.org/abs/2602.09370)
*Minsung Yoon,Jeil Jeong,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: 本文提出了一种面向四足机器人滑板运动的相位感知策略学习（PAPL）框架，利用相位条件化的FiLM层实现统一但相位敏感的控制策略，在仿真中验证了其指令跟踪精度、效率优势及真实世界可迁移性。


<details>
  <summary>Details</summary>
Motivation: 四足机器人控制滑板面临感知驱动交互和多阶段多模态控制目标带来的策略学习挑战。

Method: 提出Phase-Aware Policy Learning（PAPL）强化学习框架，将相位条件化的Feature-wise Linear Modulation（FiLM）层嵌入Actor-Critic网络，利用滑板运动的周期性实现相位依赖行为建模与跨阶段知识共享。

Result: 仿真验证了高命令跟踪精度；消融实验量化了各组件贡献；相比腿式和轮腿式基线展现出更高运动效率；并实现了真实场景迁移。

Conclusion: PAPL是一种有效应对滑板运动多阶段特性的策略学习方法，兼顾相位特异性与策略统一性，具备仿真到现实的泛化能力。

Abstract: Skateboards offer a compact and efficient means of transportation as a type of personal mobility device. However, controlling them with legged robots poses several challenges for policy learning due to perception-driven interactions and multi-modal control objectives across distinct skateboarding phases. To address these challenges, we introduce Phase-Aware Policy Learning (PAPL), a reinforcement-learning framework tailored for skateboarding with quadruped robots. PAPL leverages the cyclic nature of skateboarding by integrating phase-conditioned Feature-wise Linear Modulation layers into actor and critic networks, enabling a unified policy that captures phase-dependent behaviors while sharing robot-specific knowledge across phases. Our evaluations in simulation validate command-tracking accuracy and conduct ablation studies quantifying each component's contribution. We also compare locomotion efficiency against leg and wheel-leg baselines and show real-world transferability.

</details>


### [321] [Sci-VLA: Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments](https://arxiv.org/abs/2602.09430)
*Yiwen Pang,Bo Zhou,Changjin Li,Xuanhao Wang,Shengxiang Xu,Deng-Bao Wang,Min-Ling Zhang,Shimin Di*

Main category: cs.RO

TL;DR: 本文提出了一种无需额外训练的Agentic VLA推理插件，通过LLM显式推断过渡步骤并生成过渡动作代码，显著提升VLA模型在长周期科学实验任务中的执行成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型虽能可靠执行训练中见过的原子实验操作，但在面对由已知原子动作重组构成的复合长周期任务时表现不佳，主因是训练与推理阶段任务分布不匹配，导致缺失必要的过渡操作。

Method: 提出一种基于大语言模型（LLM）的主动式VLA推理插件，该插件在执行序列操作任务时介入，显式进行过渡推理并生成过渡机器人动作代码，从而引导VLA模型完成复合任务；整个方法仅在推理阶段干预，无需再训练。

Result: 在构建的3D科学仪器与操作场景仿真环境中，该方法使原子任务平均成功率提升42%；且可轻松从仿真迁移到真实科学实验室。

Conclusion: 所提推理插件是一种计算高效、数据高效、适用于开放性与长周期机器人实验室任务的有效解决方案，显著增强了VLA模型在真实科研自动化场景中的泛化与组合能力。

Abstract: Robotic laboratories play a critical role in autonomous scientific discovery by enabling scalable, continuous experimental execution. Recent vision-language-action (VLA) models offer a promising foundation for robotic laboratories. However, scientific experiments typically involve long-horizon tasks composed of multiple atomic tasks, posing a fundamental challenge to existing VLA models. While VLA models fine-tuned for scientific tasks can reliably execute atomic experimental actions seen during training, they often fail to perform composite tasks formed by reordering and composing these known atomic actions. This limitation arises from a distributional mismatch between training-time atomic tasks and inference-time composite tasks, which prevents VLA models from executing necessary transitional operations between atomic tasks. To address this challenge, we propose an Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments. It introduces an LLM-based agentic inference mechanism that intervenes when executing sequential manipulation tasks. By performing explicit transition inference and generating transitional robotic action code, the proposed plugin guides VLA models through missing transitional steps, enabling reliable execution of composite scientific workflows without any additional training. This inference-only intervention makes our method computationally efficient, data-efficient, and well-suited for open-ended and long-horizon robotic laboratory tasks. We build 3D assets of scientific instruments and common scientific operating scenes within an existing simulation environment. In these scenes, we have verified that our method increases the average success rate per atomic task by 42\% during inference. Furthermore, we show that our method can be easily transferred from the simulation to real scientific laboratories.

</details>


### [322] [LLM-Grounded Dynamic Task Planning with Hierarchical Temporal Logic for Human-Aware Multi-Robot Collaboration](https://arxiv.org/abs/2602.09472)
*Shuyuan Hu,Tao Lin,Kai Ye,Yang Yang,Tianwei Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种结合大语言模型（LLM）与线性时序逻辑（LTL）的神经符号框架，用于解决开放世界多机器人任务规划中的可行性、效率与动态适应性问题。通过分层LTL建模和滚动时域规划（RHP），系统在真实场景中实现了高成功率、流畅人机交互与低规划延迟。


<details>
  <summary>Details</summary>
Motivation: LLM生成的多机器人任务计划常缺乏运动学可行性且效率低；而LTL等形式化方法虽具正确性与最优性保证，却难以应对动态环境与计算可扩展性挑战。

Method: 提出神经符号框架：将LLM输出映射为分层LTL规格，并求解同时任务分配与规划（STAP）问题；引入基于实时感知的滚动时域规划（RHP）循环，在分层状态空间中动态响应环境变化（如移动用户或指令更新）。

Result: 在真实世界实验中，该方法在任务成功率、人机交互流畅度上显著优于基线方法，同时大幅降低规划延迟。

Conclusion: 所提框架成功融合LLM的语义表达能力与LTL的形式化保证，在动态开放环境中实现了高效、可行、自适应的多机器人协同规划。

Abstract: While Large Language Models (LLM) enable non-experts to specify open-world multi-robot tasks, the generated plans often lack kinematic feasibility and are not efficient, especially in long-horizon scenarios. Formal methods like Linear Temporal Logic (LTL) offer correctness and optimal guarantees, but are typically confined to static, offline settings and struggle with computational scalability. To bridge this gap, we propose a neuro-symbolic framework that grounds LLM reasoning into hierarchical LTL specifications and solves the corresponding Simultaneous Task Allocation and Planning (STAP) problem. Unlike static approaches, our system resolves stochastic environmental changes, such as moving users or updated instructions via a receding horizon planning (RHP) loop with real-time perception, which dynamically refines plans through a hierarchical state space. Extensive real-world experiments demonstrate that our approach significantly outperforms baseline methods in success rate and interaction fluency while minimizing planning latency.

</details>


### [323] [Optimal Control of Microswimmers for Trajectory Tracking Using Bayesian Optimization](https://arxiv.org/abs/2602.09563)
*Lucas Palazzolo,Mickaël Binois,Laëtitia Giraldi*

Main category: cs.RO

TL;DR: 本文提出了一种结合B样条参数化与贝叶斯优化的最优控制方法，用于解决微泳者在低雷诺数下的轨迹跟踪问题，适用于多种模型精度，并能部分补偿壁面引起的水动力效应。


<details>
  <summary>Details</summary>
Motivation: 微泳者的轨迹跟踪在微机器人学中仍具挑战性，尤其因低雷诺数下流体动力学复杂、控制设计困难。

Method: 将轨迹跟踪建模为最优控制问题，采用B样条对控制输入进行参数化，并利用贝叶斯优化求解，避免复杂梯度计算，适应高计算成本场景。

Result: 在鞭毛式磁驱动微泳者和三球微泳者模型上验证了该方法，成功复现多种目标轨迹（含生物启发路径），并部分补偿壁面水动力效应；方法在从ODE到PDE等不同保真度模型上均表现一致有效。

Conclusion: 贝叶斯优化是一种通用、鲁棒的工具，适用于复杂流固耦合下的微尺度运动最优控制。

Abstract: Trajectory tracking for microswimmers remains a key challenge in microrobotics, where low-Reynolds-number dynamics make control design particularly complex. In this work, we formulate the trajectory tracking problem as an optimal control problem and solve it using a combination of B-spline parametrization with Bayesian optimization, allowing the treatment of high computational costs without requiring complex gradient computations. Applied to a flagellated magnetic swimmer, the proposed method reproduces a variety of target trajectories, including biologically inspired paths observed in experimental studies. We further evaluate the approach on a three-sphere swimmer model, demonstrating that it can adapt to and partially compensate for wall-induced hydrodynamic effects. The proposed optimization strategy can be applied consistently across models of different fidelity, from low-dimensional ODE-based models to high-fidelity PDE-based simulations, showing its robustness and generality. These results highlight the potential of Bayesian optimization as a versatile tool for optimal control strategies in microscale locomotion under complex fluid-structure interactions.

</details>


### [324] [Sample-Efficient Real-World Dexterous Policy Fine-Tuning via Action-Chunked Critics and Normalizing Flows](https://arxiv.org/abs/2602.09580)
*Chenyu Yang,Denis Tarasov,Davide Liconti,Hehui Zheng,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 本文提出了SOFT-FLOW框架，结合归一化流（NF）策略与动作块级评论家，实现对灵巧操作策略的高效、稳定、离线微调，首次在真实机器人硬件上验证了基于似然的多模态生成策略与块级价值学习的结合效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界中灵巧操作策略微调面临交互预算有限和动作分布高度多模态的挑战；扩散策略无法提供可计算的动作概率以支持保守更新，而高斯策略在多模态和动作分块执行下易坍缩，且传统逐步评论家难以匹配分块执行结构，导致信用分配差。

Method: 提出SOFT-FLOW：1）采用归一化流策略建模动作块，提供精确似然，支持似然正则化的保守策略更新；2）设计动作块级评论家，对整段动作序列进行价值评估，提升长程信用分配。

Result: 在真实机器人上完成两项高难度灵巧操作任务（剪胶带、掌心向下手内立方体旋转），SOFT-FLOW实现了稳定、样本高效的适应，显著优于标准方法。

Conclusion: SOFT-FLOW通过将可计算似然的多模态动作建模与块级价值学习相结合，有效解决了现实灵巧操作策略微调中的样本效率与稳定性难题，为生成式策略的实际部署提供了新范式。

Abstract: Real-world fine-tuning of dexterous manipulation policies remains challenging due to limited real-world interaction budgets and highly multimodal action distributions. Diffusion-based policies, while expressive, do not permit conservative likelihood-based updates during fine-tuning because action probabilities are intractable. In contrast, conventional Gaussian policies collapse under multimodality, particularly when actions are executed in chunks, and standard per-step critics fail to align with chunked execution, leading to poor credit assignment. We present SOFT-FLOW, a sample-efficient off-policy fine-tuning framework with normalizing flow (NF) to address these challenges. The normalizing flow policy yields exact likelihoods for multimodal action chunks, allowing conservative, stable policy updates through likelihood regularization and thereby improving sample efficiency. An action-chunked critic evaluates entire action sequences, aligning value estimation with the policy's temporal structure and improving long-horizon credit assignment. To our knowledge, this is the first demonstration of a likelihood-based, multimodal generative policy combined with chunk-level value learning on real robotic hardware. We evaluate SOFT-FLOW on two challenging dexterous manipulation tasks in the real world: cutting tape with scissors retrieved from a case, and in-hand cube rotation with a palm-down grasp -- both of which require precise, dexterous control over long horizons. On these tasks, SOFT-FLOW achieves stable, sample-efficient adaptation where standard methods struggle.

</details>


### [325] [Preference Aligned Visuomotor Diffusion Policies for Deformable Object Manipulation](https://arxiv.org/abs/2602.09583)
*Marco Moletta,Michael C. Welle,Danica Kragic*

Main category: cs.RO

TL;DR: 本文提出RKO方法，通过结合RPO和KTO框架，利用少量演示将预训练视觉运动扩散策略适配到人类对可变形物体（如织物）操作的偏好上，在真实布料折叠任务中验证了其在性能和采样效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 人类对操作任务存在细微、个性化且难以言明的偏好，而机器人需考虑这些偏好以提升个性化与用户满意度；当前在可变形物体操作中，该问题尚未被充分研究。

Method: 提出RKO偏好对齐方法，融合RPO与KTO两种最新框架，基于少量演示对预训练的视觉运动扩散策略进行偏好适应。

Result: 在多类衣物与多种偏好设置的真实布料折叠任务中，RKO显著优于RPO、KTO及基础扩散策略微调，在任务性能与样本效率上表现更优。

Conclusion: 结构化偏好学习对于在复杂可变形物体操作中扩展个性化机器人行为具有重要性与可行性。

Abstract: Humans naturally develop preferences for how manipulation tasks should be performed, which are often subtle, personal, and difficult to articulate. Although it is important for robots to account for these preferences to increase personalization and user satisfaction, they remain largely underexplored in robotic manipulation, particularly in the context of deformable objects like garments and fabrics. In this work, we study how to adapt pretrained visuomotor diffusion policies to reflect preferred behaviors using limited demonstrations. We introduce RKO, a novel preference-alignment method that combines the benefits of two recent frameworks: RPO and KTO. We evaluate RKO against common preference learning frameworks, including these two, as well as a baseline vanilla diffusion policy, on real-world cloth-folding tasks spanning multiple garments and preference settings. We show that preference-aligned policies (particularly RKO) achieve superior performance and sample efficiency compared to standard diffusion policy fine-tuning. These results highlight the importance and feasibility of structured preference learning for scaling personalized robot behavior in complex deformable object manipulation tasks.

</details>


### [326] [AnyTouch 2: General Optical Tactile Representation Learning For Dynamic Tactile Perception](https://arxiv.org/abs/2602.09617)
*Ruoxuan Feng,Yuxuan Zhou,Siyu Mei,Dongzhan Zhou,Pengwei Wang,Shaowei Cui,Bin Fang,Guocai Yao,Di Hu*

Main category: cs.RO

TL;DR: 本文提出ToucHD数据集和AnyTouch 2框架，旨在提升机器人对触觉动态信息（如表面形变、力动力学）的感知能力，构建从数据到模型的分层动态触觉感知体系。


<details>
  <summary>Details</summary>
Motivation: 现有触觉数据集和模型多关注物体级静态属性，缺乏对接触过程中细粒度时序触觉动态（如表面变形、力变化）的建模，限制了真实场景中接触丰富操作的能力。

Method: 1）构建大规模分层触觉数据集ToucHD，涵盖触觉原子动作、真实操作及触-力配对数据；2）提出AnyTouch 2通用触觉表征学习框架，统一建模像素级形变、动作特异性变形与物理力动力学，支持多层级动态感知。

Result: 在涵盖静态属性与动态物理属性的基准及多层级真实操作任务（从物体识别到力感知灵巧操作）上，AnyTouch 2在多种光学触觉传感器和任务中均展现出一致且优异的性能。

Conclusion: 分层动态触觉感知需数据与模型协同设计；ToucHD与AnyTouch 2共同构成从数据生态到表征学习的完整范式，显著推动接触丰富操作中动态触觉理解的发展。

Abstract: Real-world contact-rich manipulation demands robots to perceive temporal tactile feedback, capture subtle surface deformations, and reason about object properties as well as force dynamics. Although optical tactile sensors are uniquely capable of providing such rich information, existing tactile datasets and models remain limited. These resources primarily focus on object-level attributes (e.g., material) while largely overlooking fine-grained tactile temporal dynamics during physical interactions. We consider that advancing dynamic tactile perception requires a systematic hierarchy of dynamic perception capabilities to guide both data collection and model design. To address the lack of tactile data with rich dynamic information, we present ToucHD, a large-scale hierarchical tactile dataset spanning tactile atomic actions, real-world manipulations, and touch-force paired data. Beyond scale, ToucHD establishes a comprehensive tactile dynamic data ecosystem that explicitly supports hierarchical perception capabilities from the data perspective. Building on it, we propose AnyTouch 2, a general tactile representation learning framework for diverse optical tactile sensors that unifies object-level understanding with fine-grained, force-aware dynamic perception. The framework captures both pixel-level and action-specific deformations across frames, while explicitly modeling physical force dynamics, thereby learning multi-level dynamic perception capabilities from the model perspective. We evaluate our model on benchmarks that covers static object properties and dynamic physical attributes, as well as real-world manipulation tasks spanning multiple tiers of dynamic perception capabilities-from basic object-level understanding to force-aware dexterous manipulation. Experimental results demonstrate consistent and strong performance across sensors and tasks.

</details>


### [327] [TeleGate: Whole-Body Humanoid Teleoperation via Gated Expert Selection with Motion Prior](https://arxiv.org/abs/2602.09628)
*Jie Li,Bing Tang,Feng Wu,Rongyun Cao*

Main category: cs.RO

TL;DR: 本文提出了TeleGate框架，通过轻量级门控网络动态激活领域专家策略，并结合VAE运动先验模块实现高精度实时全身遥操作，显著提升了动态动作跟踪精度与成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过知识蒸馏将多个专家策略融合为单一通用策略，易导致性能下降，尤其在高度动态动作中；亟需一种能保留各专家策略完整能力的统一遥操作框架。

Method: 提出TeleGate框架：1）训练轻量级门控网络，根据本体感知状态和参考轨迹实时激活对应领域专家策略；2）引入基于VAE的运动先验模块，从历史观测中隐式提取未来运动意图，支持需预测的动作（如跳跃、起立）的前瞻性控制。

Result: 在仿真和Unitree G1人形机器人上验证，仅用2.5小时动捕数据训练，即可在跑步、跌倒恢复、跳跃等多样化动态动作中实现高精度实时遥操作，跟踪精度与成功率均显著优于基线方法。

Conclusion: TeleGate通过动态专家选择与运动意图预测，有效克服了知识蒸馏带来的性能损失，为人形机器人复杂环境下的实时全身遥操作提供了高效可靠的统一框架。

Abstract: Real-time whole-body teleoperation is a critical method for humanoid robots to perform complex tasks in unstructured environments. However, developing a unified controller that robustly supports diverse human motions remains a significant challenge. Existing methods typically distill multiple expert policies into a single general policy, which often inevitably leads to performance degradation, particularly on highly dynamic motions. This paper presents TeleGate, a unified whole-body teleoperation framework for humanoid robots that achieves high-precision tracking across various motions while avoiding the performance loss inherent in knowledge distillation. Our key idea is to preserve the full capability of domain-specific expert policies by training a lightweight gating network, which dynamically activates experts in real-time based on proprioceptive states and reference trajectories. Furthermore, to compensate for the absence of future reference trajectories in real-time teleoperation, we introduce a VAE-based motion prior module that extracts implicit future motion intent from historical observations, enabling anticipatory control for motions requiring prediction such as jumping and standing up. We conducted empirical evaluations in simulation and also deployed our technique on the Unitree G1 humanoid robot. Using only 2.5 hours of motion capture data for training, our TeleGate achieves high-precision real-time teleoperation across diverse dynamic motions (e.g., running, fall recovery, and jumping), significantly outperforming the baseline methods in both tracking accuracy and success rate.

</details>


### [328] [AutoFly: Vision-Language-Action Model for UAV Autonomous Navigation in the Wild](https://arxiv.org/abs/2602.09657)
*Xiaolou Sun,Wufei Si,Wenhui Ni,Yuntian Li,Dongming Wu,Fei Xie,Runwei Guan,He-Yang Xu,Henghui Ding,Yuan Wu,Yutao Yue,Yongming Huang,Hui Xiong*

Main category: cs.RO

TL;DR: 本文提出AutoFly模型，一种端到端的视觉-语言-动作（VLA）模型，用于无人机在未知户外环境中基于粗粒度指令的自主导航，通过伪深度编码器和两阶段训练策略提升空间推理与多模态对齐能力，并构建了首个面向自主行为建模的新数据集。


<details>
  <summary>Details</summary>
Motivation: 现有无人机视觉-语言导航（VLN）方法依赖详细预设指令，难以适应真实户外未知环境中仅有粗粒度位置或方向指引的自主导航需求。

Method: 提出AutoFly模型，包含伪深度编码器以从RGB图像提取深度感知特征，并采用渐进式两阶段训练策略对齐视觉、深度、语言表征与动作策略；同时构建新型自主导航数据集，强调连续避障、自主规划与真实世界数据集成。

Result: AutoFly在模拟与真实环境中均超越现有SOTA VLA基线，成功率提升3.9%。

Conclusion: AutoFly有效提升了无人机在缺乏精细指令的未知环境中的自主导航能力，所构建的数据集推动了从指令跟随向自主行为建模的范式转变。

Abstract: Vision-language navigation (VLN) requires intelligent agents to navigate environments by interpreting linguistic instructions alongside visual observations, serving as a cornerstone task in Embodied AI. Current VLN research for unmanned aerial vehicles (UAVs) relies on detailed, pre-specified instructions to guide the UAV along predetermined routes. However, real-world outdoor exploration typically occurs in unknown environments where detailed navigation instructions are unavailable. Instead, only coarse-grained positional or directional guidance can be provided, requiring UAVs to autonomously navigate through continuous planning and obstacle avoidance. To bridge this gap, we propose AutoFly, an end-to-end Vision-Language-Action (VLA) model for autonomous UAV navigation. AutoFly incorporates a pseudo-depth encoder that derives depth-aware features from RGB inputs to enhance spatial reasoning, coupled with a progressive two-stage training strategy that effectively aligns visual, depth, and linguistic representations with action policies. Moreover, existing VLN datasets have fundamental limitations for real-world autonomous navigation, stemming from their heavy reliance on explicit instruction-following over autonomous decision-making and insufficient real-world data. To address these issues, we construct a novel autonomous navigation dataset that shifts the paradigm from instruction-following to autonomous behavior modeling through: (1) trajectory collection emphasizing continuous obstacle avoidance, autonomous planning, and recognition workflows; (2) comprehensive real-world data integration. Experimental results demonstrate that AutoFly achieves a 3.9% higher success rate compared to state-of-the-art VLA baselines, with consistent performance across simulated and real environments.

</details>


### [329] [RANT: Ant-Inspired Multi-Robot Rainforest Exploration Using Particle Filter Localisation and Virtual Pheromone Coordination](https://arxiv.org/abs/2602.09661)
*Ameer Alhashemi,Layan Abdulhadi,Karam Abuodeh,Tala Baghdadi,Suryanarayana Datla*

Main category: cs.RO

TL;DR: RANT is an ant-inspired multi-robot exploration framework that uses particle-filter localization, gradient-based hotspot exploitation, and virtual pheromone-based coordination to efficiently explore noisy, uncertain environments.


<details>
  <summary>Details</summary>
Motivation: To enable robust multi-robot exploration in noisy and uncertain environments where sensor data is unreliable and coordination is challenging.

Method: RANT integrates particle-filter localization for robot pose estimation, a behaviour-based controller for gradient-driven hotspot exploitation, and a lightweight no-revisit coordination mechanism using virtual pheromone blocking; evaluated on differential-drive robots in a 10×10 m terrain.

Result: Particle filtering is critical for reliable hotspot engagement; coordination significantly reduces mapping overlap; increasing team size improves coverage but with diminishing returns due to interference.

Conclusion: RANT demonstrates that bio-inspired coordination and probabilistic perception are effective for multi-robot exploration under uncertainty, balancing coverage, hotspot recall, and redundancy.

Abstract: This paper presents RANT, an ant-inspired multi-robot exploration framework for noisy, uncertain environments. A team of differential-drive robots navigates a 10 x 10 m terrain, collects noisy probe measurements of a hidden richness field, and builds local probabilistic maps while the supervisor maintains a global evaluation. RANT combines particle-filter localisation, a behaviour-based controller with gradient-driven hotspot exploitation, and a lightweight no-revisit coordination mechanism based on virtual pheromone blocking. We experimentally analyse how team size, localisation fidelity, and coordination influence coverage, hotspot recall, and redundancy. Results show that particle filtering is essential for reliable hotspot engagement, coordination substantially reduces overlap, and increasing team size improves coverage but yields diminishing returns due to interference.

</details>


### [330] [Fast Motion Planning for Non-Holonomic Mobile Robots via a Rectangular Corridor Representation of Structured Environments](https://arxiv.org/abs/2602.09714)
*Alejandro Gonzalez-Garcia,Sebastiaan Wyns,Sonia De Santis,Jan Swevers,Wilm Decré*

Main category: cs.RO

TL;DR: 本文提出了一种面向非完整自主移动机器人在复杂结构化环境中快速运动规划的完整框架，通过确定性自由空间分解构建紧凑矩形走廊图，并结合解析轨迹生成器实现高效、近时间最优且运动学可行的在线规划。


<details>
  <summary>Details</summary>
Motivation: 传统基于栅格的规划器存在可扩展性差的问题，而许多运动学可行规划器则因搜索空间复杂度高导致计算负担重。

Method: 引入确定性自由空间分解方法，构建由重叠矩形走廊组成的紧凑图；在线规划阶段先搜索矩形序列，再利用解析规划器生成近时间最优、运动学可行的轨迹。

Result: 实现了大规模导航中高效、高分辨率且运动学可行的路径规划，在仿真和实物机器人上均得到验证。

Conclusion: 该框架显著降低了搜索空间复杂度，同时保持路径质量与实时性，开源实现进一步提升了实用性与可复现性。

Abstract: We present a complete framework for fast motion planning of non-holonomic autonomous mobile robots in highly complex but structured environments. Conventional grid-based planners struggle with scalability, while many kinematically-feasible planners impose a significant computational burden due to their search space complexity. To overcome these limitations, our approach introduces a deterministic free-space decomposition that creates a compact graph of overlapping rectangular corridors. This method enables a significant reduction in the search space, without sacrificing path resolution. The framework then performs online motion planning by finding a sequence of rectangles and generating a near-time-optimal, kinematically-feasible trajectory using an analytical planner. The result is a highly efficient solution for large-scale navigation. We validate our framework through extensive simulations and on a physical robot. The implementation is publicly available as open-source software.

</details>


### [331] [Rethinking Visual-Language-Action Model Scaling: Alignment, Mixture, and Regularization](https://arxiv.org/abs/2602.09722)
*Ye Wang,Sipeng Zheng,Hao Luo,Wanpeng Zhang,Haoqi Yuan,Chaoyi Xu,Haiweng Xu,Yicheng Feng,Mingyang Yu,Zhiyu Kang,Zongqing Lu,Qin Jin*

Main category: cs.RO

TL;DR: 本文对视觉-语言-动作（VLA）模型在机器人控制中的规模化训练进行了系统性实证研究，发现盲目扩大异构机器人数据规模可能引发负迁移；提出EEF相对动作表征、分组盲测集成协议等关键改进，并挑战了当前VLA规模化中若干常见假设。


<details>
  <summary>Details</summary>
Motivation: Vision-Language-Action (VLA)模型在通用机器人控制中前景广阔，但标准的“扩大数据规模”范式是否适用于机器人领域尚不明确，因其训练数据天然异构（不同本体、传感器和动作空间）。

Method: 基于统一VLA框架（视觉-语言骨干网络+流匹配），在仿真与真实机器人上开展受控消融实验；引入Grouped Blind Ensemble协议以降低实验者偏差；系统分析物理对齐、本体混合与训练正则化三个维度。

Result: （1）EEF相对动作表示对跨本体迁移至关重要；（2）盲目混合异构机器人数据常导致负迁移而非增益；（3）感官丢弃与多阶段微调等常规正则策略在大规模下效果不一致。

Conclusion: 挑战了‘数据越多越好’等VLA规模化常见假设，强调需谨慎设计动作表征与数据混合策略，并提供面向多样化机器人数据的大规模VLA策略训练实用指南。

Abstract: While Vision-Language-Action (VLA) models show strong promise for generalist robot control, it remains unclear whether -- and under what conditions -- the standard "scale data" recipe translates to robotics, where training data is inherently heterogeneous across embodiments, sensors, and action spaces. We present a systematic, controlled study of VLA scaling that revisits core training choices for pretraining across diverse robots. Using a representative VLA framework that combines a vision-language backbone with flow-matching, we ablate key design decisions under matched conditions and evaluate in extensive simulation and real-robot experiments. To improve the reliability of real-world results, we introduce a Grouped Blind Ensemble protocol that blinds operators to model identity and separates policy execution from outcome judgment, reducing experimenter bias. Our analysis targets three dimensions of VLA scaling. (1) Physical alignment: we show that a unified end-effector (EEF)-relative action representation is critical for robust cross-embodiment transfer. (2) Embodiment mixture: we find that naively pooling heterogeneous robot datasets often induces negative transfer rather than gains, underscoring the fragility of indiscriminate data scaling. (3) Training regularization: we observe that intuitive strategies, such as sensory dropout and multi-stage fine-tuning, do not consistently improve performance at scale. Together, this study challenge some common assumptions about embodied scaling and provide practical guidance for training large-scale VLA policies from diverse robotic data. Project website: https://research.beingbeyond.com/rethink_vla

</details>


### [332] [NavDreamer: Video Models as Zero-Shot 3D Navigators](https://arxiv.org/abs/2602.09765)
*Xijie Huang,Weiqi Gai,Tianyue Wu,Congyu Wang,Zhiyang Liu,Xin Zhou,Yuze Wu,Fei Gao*

Main category: cs.RO

TL;DR: NavDreamer 是一种基于视频的3D导航框架，利用生成式视频模型作为语言指令与导航轨迹之间的通用接口，通过采样优化、VLM评分和逆动力学解码实现零样本泛化导航。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在导航中面临数据稀缺多样、表征静态、无法建模时序动态与物理规律等关键限制。

Method: 提出NavDreamer框架：以生成式视频模型为统一接口；引入基于采样的优化方法，用VLM对轨迹打分筛选；采用逆动力学模型将视频计划解码为可执行航点；构建覆盖多任务的综合视频导航基准。

Result: 实验表明该方法在新物体和未见环境中具备强零样本泛化能力；消融分析揭示导航任务的高层决策特性使其特别适配视频规划范式。

Conclusion: 视频因其天然蕴含时空信息与物理动态，且数据规模庞大，可作为语言到导航动作间更优的中间表征，推动开放世界具身智能发展。

Abstract: Previous Vision-Language-Action models face critical limitations in navigation: scarce, diverse data from labor-intensive collection and static representations that fail to capture temporal dynamics and physical laws. We propose NavDreamer, a video-based framework for 3D navigation that leverages generative video models as a universal interface between language instructions and navigation trajectories. Our main hypothesis is that video's ability to encode spatiotemporal information and physical dynamics, combined with internet-scale availability, enables strong zero-shot generalization in navigation. To mitigate the stochasticity of generative predictions, we introduce a sampling-based optimization method that utilizes a VLM for trajectory scoring and selection. An inverse dynamics model is employed to decode executable waypoints from generated video plans for navigation. To systematically evaluate this paradigm in several video model backbones, we introduce a comprehensive benchmark covering object navigation, precise navigation, spatial grounding, language control, and scene reasoning. Extensive experiments demonstrate robust generalization across novel objects and unseen environments, with ablation studies revealing that navigation's high-level decision-making nature makes it particularly suited for video-based planning.

</details>


### [333] [Diverse Skill Discovery for Quadruped Robots via Unsupervised Learning](https://arxiv.org/abs/2602.09767)
*Ruopeng Cui,Yifei Bi,Haojie Luo,Wei Li*

Main category: cs.RO

TL;DR: 本文提出了一种正交混合专家（OMoE）架构与多判别器框架，用于提升无监督技能发现的效率与技能多样性，避免奖励欺骗，在Unitree A1四足机器人上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有无监督技能发现方法中学习效率低、技能多样性不足及易发生奖励欺骗的问题。

Method: 提出正交混合专家（OMoE）架构以维持技能表征的正交性，并设计多判别器框架在不同观测空间中协同判别，防止技能坍缩与奖励欺骗。

Result: 在12-DOF Unitree A1四足机器人上成功实现多样化运动技能，训练效率提升，状态空间覆盖率较基线提高18.3%。

Conclusion: OMoE与多判别器框架能有效提升无监督技能发现的多样性、鲁棒性与学习效率，为具身智能体自主技能获取提供了新思路。

Abstract: Reinforcement learning necessitates meticulous reward shaping by specialists to elicit target behaviors, while imitation learning relies on costly task-specific data. In contrast, unsupervised skill discovery can potentially reduce these burdens by learning a diverse repertoire of useful skills driven by intrinsic motivation. However, existing methods exhibit two key limitations: they typically rely on a single policy to master a versatile repertoire of behaviors without modeling the shared structure or distinctions among them, which results in low learning efficiency; moreover, they are susceptible to reward hacking, where the reward signal increases and converges rapidly while the learned skills display insufficient actual diversity. In this work, we introduce an Orthogonal Mixture-of-Experts (OMoE) architecture that prevents diverse behaviors from collapsing into overlapping representations, enabling a single policy to master a wide spectrum of locomotion skills. In addition, we design a multi-discriminator framework in which different discriminators operate on distinct observation spaces, effectively mitigating reward hacking. We evaluated our method on the 12-DOF Unitree A1 quadruped robot, demonstrating a diverse set of locomotion skills. Our experiments demonstrate that the proposed framework boosts training efficiency and yields an 18.3\% expansion in state-space coverage compared to the baseline.

</details>


### [334] [Design and Evaluation of an Assisted Programming Interface for Behavior Trees in Robotics](https://arxiv.org/abs/2602.09772)
*Jonathan Styrud,Matteo Iovino,Rebecca Stower,Mart Kartašev,Mikael Norrlöf,Mårten Björkman,Christian Smith*

Main category: cs.RO

TL;DR: 本文提出了BETR-GUI，一个结合大语言模型、规划、遗传编程和贝叶斯优化的图形化行为树（BT）编辑工具，通过用户研究验证其在机器人编程任务中显著提升人类用户表现，并优于纯AI自动方法。


<details>
  <summary>Details</summary>
Motivation: 提升非专业程序员快速构建反应式机器人程序的能力，探索如何将多种BT自动生成技术与完整GUI结合，支持人工校验与编辑。

Method: 开发BETR-GUI系统，集成大语言模型、经典规划、遗传编程和贝叶斯优化作为AI助手，并搭配拖拽式图形界面；开展60人用户研究评估不同辅助方式的效果。

Result: 用户研究表明，组合多种辅助方法显著提升用户完成机器人编程任务的表现；完整版BETR-GUI下的人类表现优于仅由AI助手独立运行的结果。

Conclusion: 融合多类AI技术与直观GUI的行为树编辑工具能有效增强人类编程效率与准确性，证实人机协同在机器人编程中的优势。

Abstract: The possibility to create reactive robot programs faster without the need for extensively trained programmers is becoming increasingly important. So far, it has not been explored how various techniques for creating Behavior Tree (BT) program representations could be combined with complete graphical user interfaces (GUIs) to allow a human user to validate and edit trees suggested by automated methods. In this paper, we introduce BEhavior TRee GUI (BETR-GUI) for creating BTs with the help of an AI assistant that combines methods using large language models, planning, genetic programming, and Bayesian optimization with a drag-and-drop editor. A user study with 60 participants shows that by combining different assistive methods, BETR-GUI enables users to perform better at solving the robot programming tasks. The results also show that humans using the full variant of BETR-GUI perform better than the AI assistant running on its own.

</details>


### [335] [BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation](https://arxiv.org/abs/2602.09849)
*Yucheng Hu,Jianke Zhang,Yuanfei Luo,Yanjiang Guo,Xiaoyu Chen,Xinshu Sun,Kun Feng,Qingzhou Lu,Sheng Chen,Yangang Zhang,Wei Li,Jianyu Chen*

Main category: cs.RO

TL;DR: 本文提出BagelVLA模型，统一整合语言规划、视觉预测与动作生成，通过残差流引导（RFG）机制实现多模态高效耦合，在复杂长周期操作任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有Vision-Language-Action（VLA）模型通常孤立地处理语言规划或视觉预测，难以协同指导动作生成，导致在复杂长周期操作任务中性能受限。

Method: 提出BagelVLA统一框架，基于预训练统一理解与生成模型初始化，将文本推理与视觉预测交织嵌入动作执行循环；引入残差流引导（RFG），利用单步去噪从当前观测中提取预测性视觉特征，以低延迟引导动作生成。

Result: 在多个仿真与真实世界基准测试中，BagelVLA显著超越现有基线，尤其在需多阶段推理的任务上表现突出。

Conclusion: BagelVLA成功实现了语言规划、视觉预测与动作生成的联合建模，验证了多模态协同对具身智能操作能力提升的关键作用。

Abstract: Equipping embodied agents with the ability to reason about tasks, foresee physical outcomes, and generate precise actions is essential for general-purpose manipulation. While recent Vision-Language-Action (VLA) models have leveraged pre-trained foundation models, they typically focus on either linguistic planning or visual forecasting in isolation. These methods rarely integrate both capabilities simultaneously to guide action generation, leading to suboptimal performance in complex, long-horizon manipulation tasks. To bridge this gap, we propose BagelVLA, a unified model that integrates linguistic planning, visual forecasting, and action generation within a single framework. Initialized from a pretrained unified understanding and generative model, BagelVLA is trained to interleave textual reasoning and visual prediction directly into the action execution loop. To efficiently couple these modalities, we introduce Residual Flow Guidance (RFG), which initializes from current observation and leverages single-step denoising to extract predictive visual features, guiding action generation with minimal latency. Extensive experiments demonstrate that BagelVLA outperforms existing baselines by a significant margin on multiple simulated and real-world benchmarks, particularly in tasks requiring multi-stage reasoning.

</details>


### [336] [TriPilot-FF: Coordinated Whole-Body Teleoperation with Force Feedback](https://arxiv.org/abs/2602.09888)
*Zihao Li,Yanan Zhou,Ranpeng Qiu,Hangyu Wu,Guoqiang Ren,Weiming Zhi*

Main category: cs.RO

TL;DR: 本文提出TriPilot-FF，一种开源全身遥操作系统，利用脚踏板结合激光雷达触觉反馈实现移动基座的直观控制，并整合上肢双臂主从遥操作、力反馈与双臂可操作性可视化引导，提升远程操控精度与安全性；同时将遥操作信号融入ACT策略，提升学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有移动操作机器人遥操作界面以手控为主（如VR控制器、摇杆），缺乏对脚部连续基座控制通道的探索，导致操作者需同时协调轮式底盘与双臂、并兼顾障碍物和接触，负担重且效率低。

Method: 设计TriPilot-FF系统：1）低成本底置激光雷达驱动脚踏板触觉反馈（阻力随障碍距离变化）；2）上肢双臂主从遥操作；3）手臂侧力反馈增强接触感知；4）实时可视化双臂可操作性以提示基座重定位；5）将遥操作反馈信号融入Action Chunking with Transformers（ACT）策略训练。

Result: 实验证明TriPilot-FF能长期有效辅助人类操作者完成需精密基座运动与协调的任务；在真实双臂轮式平台上验证了系统有效性；集成遥操作信号后ACT策略性能提升；完整硬件设计、软件栈及评估数据全部开源。

Conclusion: 脚部通道是提升移动操作机器人遥操作自然性与安全性的关键补充；TriPilot-FF通过简单传感器与多模态反馈实现了无需显式避障控制器的碰撞规避行为塑造，为全身遥操作提供了新范式，并推动人机协同学习的发展。

Abstract: Mobile manipulators broaden the operational envelope for robot manipulation. However, the whole-body teleoperation of such robots remains a problem: operators must coordinate a wheeled base and two arms while reasoning about obstacles and contact. Existing interfaces are predominantly hand-centric (e.g., VR controllers and joysticks), leaving foot-operated channels underexplored for continuous base control. We present TriPilot-FF, an open-source whole-body teleoperation system for a custom bimanual mobile manipulator that introduces a foot-operated pedal with lidar-driven pedal haptics, coupled with upper-body bimanual leader-follower teleoperation. Using only a low-cost base-mounted lidar, TriPilot-FF renders a resistive pedal cue from proximity-to-obstacle signals in the commanded direction, shaping operator commands toward collision-averse behaviour without an explicit collision-avoidance controller. The system also supports arm-side force reflection for contact awareness and provides real-time force and visual guidance of bimanual manipulability to prompt mobile base repositioning, thereby improving reach. We demonstrate the capability of TriPilot-FF to effectively ``co-pilot'' the human operator over long time-horizons and tasks requiring precise mobile base movement and coordination. Finally, we incorporate teleoperation feedback signals into an Action Chunking with Transformers (ACT) policy and demonstrate improved performance when the additional information is available. We release the pedal device design, full software stack, and conduct extensive real-world evaluations on a bimanual wheeled platform. The project page of TriPilot-FF is http://bit.ly/46H3ZJT.

</details>


### [337] [TaCo: A Benchmark for Lossless and Lossy Codecs of Heterogeneous Tactile Data](https://arxiv.org/abs/2602.09893)
*Zhengxue Cheng,Yan Zhao,Keyu Wang,Hengdi Zhang,Li Song*

Main category: cs.RO

TL;DR: 本文提出了首个全面的触觉数据编解码器基准测试TaCo，评估了30种压缩方法在五个不同触觉数据集上的表现，并开发了专为触觉数据设计的数据驱动编解码器TaCo-LL（无损）和TaCo-L（有损），验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 触觉传感对具身智能至关重要，但受限于带宽约束的实时机器人应用中，高效触觉数据压缩仍缺乏深入研究，且触觉数据固有的异构性和时空复杂性加剧了该挑战。

Method: 构建了TaCo基准，系统评估30种压缩方法（包括现成算法和神经编解码器）在五个多样化触觉数据集上的表现；提出专为触觉数据训练的数据驱动编解码器TaCo-LL（无损）和TaCo-L（有损）；在无损存储、人类可视化、材质与物体分类、灵巧抓取四项任务上进行评测。

Result: TaCo-LL和TaCo-L在多项任务中展现出优于现有方法的性能；TaCo基准揭示了压缩效率与任务性能之间的关键权衡关系。

Conclusion: TaCo为触觉数据压缩提供了基础性评测框架，推动了面向实际机器人应用的高效触觉感知技术发展。

Abstract: Tactile sensing is crucial for embodied intelligence, providing fine-grained perception and control in complex environments. However, efficient tactile data compression, which is essential for real-time robotic applications under strict bandwidth constraints, remains underexplored. The inherent heterogeneity and spatiotemporal complexity of tactile data further complicate this challenge. To bridge this gap, we introduce TaCo, the first comprehensive benchmark for Tactile data Codecs. TaCo evaluates 30 compression methods, including off-the-shelf compression algorithms and neural codecs, across five diverse datasets from various sensor types. We systematically assess both lossless and lossy compression schemes on four key tasks: lossless storage, human visualization, material and object classification, and dexterous robotic grasping. Notably, we pioneer the development of data-driven codecs explicitly trained on tactile data, TaCo-LL (lossless) and TaCo-L (lossy). Results have validated the superior performance of our TaCo-LL and TaCo-L. This benchmark provides a foundational framework for understanding the critical trade-offs between compression efficiency and task performance, paving the way for future advances in tactile perception.

</details>


### [338] [Instruct2Act: From Human Instruction to Actions Sequencing and Execution via Robot Action Network for Robotic Manipulation](https://arxiv.org/abs/2602.09940)
*Archit Sharma,Dharmendra Sharma,John Rebeiro,Peeyush Thakur,Narendra Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: 本文提出了一种轻量级、全端侧的自然语言指令到机器人操作的 pipeline，包含 Instruct2Act（指令解析为原子动作序列）和 RAN（基于 DATRN 与 YOLOv8 的轨迹生成），在无云服务、单摄像头、资源受限条件下实现高精度与实时性。


<details>
  <summary>Details</summary>
Motivation: 机器人在真实场景中难以可靠执行自由形式的人类自然语言指令，主要受限于计算与感知能力。

Method: 提出两阶段端侧 pipeline：1) Instruct2Act——轻量 BiLSTM + 多头注意力自编码器，将指令解析为原子动作序列；2) RAN——结合动态自适应轨迹径向网络（DATRN）与 YOLOv8 视觉环境分析器，生成各子动作的精确控制轨迹。

Result: Instruct2Act 在自建数据集上子动作预测准确率达 91.5%；真机实验在四项任务中整体成功率 90%；子动作推理 <3.8s，端到端执行耗时 30–60s。

Conclusion: 细粒度指令解析、DATRN 轨迹生成与视觉引导定位相结合，为资源受限、单摄像头场景下的确定性实时操作提供了实用路径。

Abstract: Robots often struggle to follow free-form human instructions in real-world settings due to computational and sensing limitations. We address this gap with a lightweight, fully on-device pipeline that converts natural-language commands into reliable manipulation. Our approach has two stages: (i) the instruction to actions module (Instruct2Act), a compact BiLSTM with a multi-head-attention autoencoder that parses an instruction into an ordered sequence of atomic actions (e.g., reach, grasp, move, place); and (ii) the robot action network (RAN), which uses the dynamic adaptive trajectory radial network (DATRN) together with a vision-based environment analyzer (YOLOv8) to generate precise control trajectories for each sub-action. The entire system runs on a modest system with no cloud services. On our custom proprietary dataset, Instruct2Act attains 91.5% sub-actions prediction accuracy while retaining a small footprint. Real-robot evaluations across four tasks (pick-place, pick-pour, wipe, and pick-give) yield an overall 90% success; sub-action inference completes in < 3.8s, with end-to-end executions in 30-60s depending on task complexity. These results demonstrate that fine-grained instruction-to-action parsing, coupled with DATRN-based trajectory generation and vision-guided grounding, provides a practical path to deterministic, real-time manipulation in resource-constrained, single-camera settings.

</details>


### [339] [Hydra-Nav: Object Navigation via Adaptive Dual-Process Reasoning](https://arxiv.org/abs/2602.09972)
*Zixuan Wang,Huang Fang,Shaoan Wang,Yuanfei Luo,Heng Dong,Wei Li,Yiming Gan*

Main category: cs.RO

TL;DR: 本文提出Hydra-Nav，一种结合快慢双系统的VLM导航架构，通过三阶段课程学习提升时空推理能力，在多个基准上达到SOTA，并引入新指标SOT评估搜索效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大视觉语言模型（VLM）的物体目标导航方法在未见物体定位和成功率上表现不佳，主因是时空推理能力弱；而引入推理的改进方法又带来过高计算开销。

Method: 提出Hydra-Nav架构，融合可自适应切换的‘慢系统’（用于历史分析与高层规划）与‘快系统’（用于高效执行）；采用三阶段课程学习训练：空间-动作对齐、记忆-推理融合、迭代拒绝微调，实现关键决策点的选择性推理。

Result: 在HM3D、MP3D和OVON基准上分别超越次优方法11.1%、17.4%和21.2%；新指标SOT验证了自适应推理显著提升搜索效率。

Conclusion: Hydra-Nav通过自适应快慢系统与课程学习，兼顾导航有效性与推理效率，为VLM具身导航提供了可扩展、高效率的新范式。

Abstract: While large vision-language models (VLMs) show promise for object goal navigation, current methods still struggle with low success rates and inefficient localization of unseen objects--failures primarily attributed to weak temporal-spatial reasoning. Meanwhile, recent attempts to inject reasoning into VLM-based agents improve success rates but incur substantial computational overhead. To address both the ineffectiveness and inefficiency of existing approaches, we introduce Hydra-Nav, a unified VLM architecture that adaptively switches between a deliberative slow system for analyzing exploration history and formulating high-level plans, and a reactive fast system for efficient execution. We train Hydra-Nav through a three-stage curriculum: (i) spatial-action alignment to strengthen trajectory planning, (ii) memory-reasoning integration to enhance temporal-spatial reasoning over long-horizon exploration, and (iii) iterative rejection fine-tuning to enable selective reasoning at critical decision points. Extensive experiments demonstrate that Hydra-Nav achieves state-of-the-art performance on the HM3D, MP3D, and OVON benchmarks, outperforming the second-best methods by 11.1%, 17.4%, and 21.2%, respectively. Furthermore, we introduce SOT (Success weighted by Operation Time), a new metric to measure search efficiency across VLMs with varying reasoning intensity. Results show that adaptive reasoning significantly enhances search efficiency over fixed-frequency baselines.

</details>


### [340] [RoboInter: A Holistic Intermediate Representation Suite Towards Robotic Manipulation](https://arxiv.org/abs/2602.09973)
*Hao Li,Ziqin Wang,Zi-han Ding,Shuai Yang,Yilun Chen,Yang Tian,Xiaolin Hu,Tai Wang,Dahua Lin,Feng Zhao,Si Liu,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本文提出了RoboInter Manipulation Suite，一个包含数据、基准和模型的统一资源，旨在通过细粒度和多样化的中间表示来提升视觉-语言-动作（VLA）系统的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据集成本高、具身特异性强、覆盖与多样性不足，且缺乏中间表示监督，限制了VLA模型的泛化能力。

Method: 构建RoboInter Manipulation Suite，包括轻量级GUI工具RoboInter-Tool、大规模多场景数据集RoboInter-Data（23万+片段，571场景，10+类中间表示标注）、空间与时间导向的VQA基准RoboInter-VQA，以及支持模块化与端到端训练的plan-then-execute框架RoboInter-VLA。

Result: 提供了目前最大规模、最高质量的中间表示标注数据集；建立了首个系统性评估具身推理能力的VQA基准；实现了无需额外人工中间监督即可训练的VLA框架。

Conclusion: RoboInter为构建鲁棒、可泛化的机器人学习系统提供了实用基础，推动了以中间表示为核心的VLA研究范式发展。

Abstract: Advances in large vision-language models (VLMs) have stimulated growing interest in vision-language-action (VLA) systems for robot manipulation. However, existing manipulation datasets remain costly to curate, highly embodiment-specific, and insufficient in coverage and diversity, thereby hindering the generalization of VLA models. Recent approaches attempt to mitigate these limitations via a plan-then-execute paradigm, where high-level plans (e.g., subtasks, trace) are first generated and subsequently translated into low-level actions, but they critically rely on extra intermediate supervision, which is largely absent from existing datasets. To bridge this gap, we introduce the RoboInter Manipulation Suite, a unified resource including data, benchmarks, and models of intermediate representations for manipulation. It comprises RoboInter-Tool, a lightweight GUI that enables semi-automatic annotation of diverse representations, and RoboInter-Data, a large-scale dataset containing over 230k episodes across 571 diverse scenes, which provides dense per-frame annotations over more than 10 categories of intermediate representations, substantially exceeding prior work in scale and annotation quality. Building upon this foundation, RoboInter-VQA introduces 9 spatial and 20 temporal embodied VQA categories to systematically benchmark and enhance the embodied reasoning capabilities of VLMs. Meanwhile, RoboInter-VLA offers an integrated plan-then-execute framework, supporting modular and end-to-end VLA variants that bridge high-level planning with low-level execution via intermediate supervision. In total, RoboInter establishes a practical foundation for advancing robust and generalizable robotic learning via fine-grained and diverse intermediate representations.

</details>


### [341] [Acoustic Drone Package Delivery Detection](https://arxiv.org/abs/2602.09991)
*François Marcoux,François Grondin*

Main category: cs.RO

TL;DR: 本文提出了一种基于地面麦克风阵列的声学包裹投递检测算法，首次专注于识别无人机在禁飞区（如监狱）的投递事件，通过深度神经网络从梅尔频谱中检测无人机存在并估计其桨叶通过频率（BPF），再利用BPF突变识别投递时刻，实现了高精度的声学投递检测。


<details>
  <summary>Details</summary>
Motivation: 近年来，无人机在监狱等受限区域进行非法投递活动已成为重大安全挑战，但现有研究多集中于无人机检测或定位，缺乏对投递事件本身的识别方法。

Method: 提出一种基于地面麦克风阵列的声学检测方法：首先用深度神经网络从梅尔频谱中检测无人机存在并估计桨叶通过频率（BPF）；然后分析BPF的时间变化特征，通过BPF在特定时刻前后的突变来识别投递事件。

Result: 桨叶通过频率估计平均绝对误差为16 Hz（距离<150米）；无人机存在检测准确率达97%；投递事件识别正确率为96%，误报率为8%；有效检测距离达100米。

Conclusion: 仅依赖声学信号即可可靠识别无人机包裹投递事件，该方法为受限区域的反无人机安防提供了新思路和实用工具。

Abstract: In recent years, the illicit use of unmanned aerial vehicles (UAVs) for deliveries in restricted area such as prisons became a significant security challenge. While numerous studies have focused on UAV detection or localization, little attention has been given to delivery events identification. This study presents the first acoustic package delivery detection algorithm using a ground-based microphone array. The proposed method estimates both the drone's propeller speed and the delivery event using solely acoustic features. A deep neural network detects the presence of a drone and estimates the propeller's rotation speed or blade passing frequency (BPF) from a mel spectrogram. The algorithm analyzes the BPFs to identify probable delivery moments based on sudden changes before and after a specific time. Results demonstrate a mean absolute error of the blade passing frequency estimator of 16 Hz when the drone is less than 150 meters away from the microphone array. The drone presence detection estimator has a accuracy of 97%. The delivery detection algorithm correctly identifies 96% of events with a false positive rate of 8%. This study shows that deliveries can be identified using acoustic signals up to a range of 100 meters.

</details>


### [342] [Learning Force-Regulated Manipulation with a Low-Cost Tactile-Force-Controlled Gripper](https://arxiv.org/abs/2602.10013)
*Xuhui Kang,Tongxuan Tian,Sung-Wook Lee,Binghao Huang,Yunzhu Li,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 本文提出了一种低成本、力控型平行夹爪TF-Gripper及配套的高频率力调节框架RETAF，结合触觉反馈与腕部图像实现对易损物体（如薯片）的精准力控制，显著提升抓取稳定性与任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有商用夹爪成本高或最小力过大，难以支持面向日常力敏感物体的力控策略学习；而人类能基于触觉快速自适应调节力，机器人亟需类似能力。

Method: 设计低成本力控夹爪TF-Gripper（0.45–45N力范围，集成触觉传感）和配套遥操作设备采集人类力数据；提出RETAF框架，将高频力控制（基于触觉+腕部图像）与低频位姿/开合动作解耦。

Result: 在五项真实力敏任务中，相比位置控制，直接力控制显著提升抓取稳定性与任务成功率；触觉反馈被证实为力调节关键；RETAF持续优于基线方法，并兼容多种基础策略。

Conclusion: TF-Gripper与RETAF为机器人力控策略的学习与规模化部署提供了实用硬件平台与高效算法框架。

Abstract: Successfully manipulating many everyday objects, such as potato chips, requires precise force regulation. Failure to modulate force can lead to task failure or irreversible damage to the objects. Humans can precisely achieve this by adapting force from tactile feedback, even within a short period of physical contact. We aim to give robots this capability. However, commercial grippers exhibit high cost or high minimum force, making them unsuitable for studying force-controlled policy learning with everyday force-sensitive objects. We introduce TF-Gripper, a low-cost (~$150) force-controlled parallel-jaw gripper that integrates tactile sensing as feedback. It has an effective force range of 0.45-45N and is compatible with different robot arms. Additionally, we designed a teleoperation device paired with TF-Gripper to record human-applied grasping forces. While standard low-frequency policies can be trained on this data, they struggle with the reactive, contact-dependent nature of force regulation. To overcome this, we propose RETAF (REactive Tactile Adaptation of Force), a framework that decouples grasping force control from arm pose prediction. RETAF regulates force at high frequency using wrist images and tactile feedback, while a base policy predicts end-effector pose and gripper open/close action. We evaluate TF-Gripper and RETAF across five real-world tasks requiring precise force regulation. Results show that compared to position control, direct force control significantly improves grasp stability and task performance. We further show that tactile feedback is essential for force regulation, and that RETAF consistently outperforms baselines and can be integrated with various base policies. We hope this work opens a path for scaling the learning of force-controlled policies in robotic manipulation. Project page: https://force-gripper.github.io .

</details>


### [343] [RoboSubtaskNet: Temporal Sub-task Segmentation for Human-to-Robot Skill Transfer in Real-World Environments](https://arxiv.org/abs/2602.10015)
*Dharmendra Sharma,Archit Sharma,John Reberio,Vaibhav Kesharwani,Peeyush Thakur,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: 本文提出RoboSubtaskNet，一种用于长视频中细粒度子任务时序定位与分类的多阶段框架，结合注意力增强I3D特征与改进的MS-TCN（斐波那契空洞采样），并设计RoboSubtask数据集以支持机器人可执行子任务映射；在多个基准上取得SOTA性能，并在Kinova机械臂上验证了端到端执行的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法难以满足人机协作中对机器人可直接执行的细粒度、可确定映射至操控原语的子任务标签的需求；通用动作识别与实际机器人控制之间存在鸿沟。

Method: 提出RoboSubtaskNet：1）融合注意力增强的I3D（RGB+光流）特征；2）采用斐波那契空洞采样的改进MS-TCN以更好建模短时序过渡（如reach-pick-place）；3）设计复合损失函数（交叉熵+截断MSE+转移感知项）抑制过分割、保障子任务合理演进；4）构建RoboSubtask数据集（医疗与工业场景，子任务级标注，支持确定性映射至机械臂原语）。

Result: 在GTEA上F1@50=79.5%，Edit=88.6%，Acc=78.9%；在Breakfast上F1@50=30.4%，Edit=52.0%，Acc=53.5%；在自建RoboSubtask上F1@50=94.2%，Edit=95.6%，Acc=92.2%；在Kinova Gen3物理平台实现约91.25%的整体任务成功率。

Conclusion: RoboSubtaskNet有效弥合了视频理解与机器人执行之间的语义与时间粒度鸿沟，为真实场景中基于视频理解的可靠人机协同操作提供了可行路径。

Abstract: Temporally locating and classifying fine-grained sub-task segments in long, untrimmed videos is crucial to safe human-robot collaboration. Unlike generic activity recognition, collaborative manipulation requires sub-task labels that are directly robot-executable. We present RoboSubtaskNet, a multi-stage human-to-robot sub-task segmentation framework that couples attention-enhanced I3D features (RGB plus optical flow) with a modified MS-TCN employing a Fibonacci dilation schedule to capture better short-horizon transitions such as reach-pick-place. The network is trained with a composite objective comprising cross-entropy and temporal regularizers (truncated MSE and a transition-aware term) to reduce over-segmentation and to encourage valid sub-task progressions. To close the gap between vision benchmarks and control, we introduce RoboSubtask, a dataset of healthcare and industrial demonstrations annotated at the sub-task level and designed for deterministic mapping to manipulator primitives. Empirically, RoboSubtaskNet outperforms MS-TCN and MS-TCN++ on GTEA and our RoboSubtask benchmark (boundary-sensitive and sequence metrics), while remaining competitive on the long-horizon Breakfast benchmark. Specifically, RoboSubtaskNet attains F1 @ 50 = 79.5%, Edit = 88.6%, Acc = 78.9% on GTEA; F1 @ 50 = 30.4%, Edit = 52.0%, Acc = 53.5% on Breakfast; and F1 @ 50 = 94.2%, Edit = 95.6%, Acc = 92.2% on RoboSubtask. We further validate the full perception-to-execution pipeline on a 7-DoF Kinova Gen3 manipulator, achieving reliable end-to-end behavior in physical trials (overall task success approx 91.25%). These results demonstrate a practical path from sub-task level video understanding to deployed robotic manipulation in real-world settings.

</details>


### [344] [A Collision-Free Sway Damping Model Predictive Controller for Safe and Reactive Forestry Crane Navigation](https://arxiv.org/abs/2602.10035)
*Marc-Philip Ecker,Christoph Fröhlich,Johannes Huemer,David Gruber,Bernhard Bischof,Tobias Glück,Wolfgang Kemmetmüller*

Main category: cs.RO

TL;DR: 本文提出了一种首个面向林业起重机的无碰撞、抑摆模型预测控制器（MPC），将环境感知（LiDAR+EDF）、实时避障与负载摆动抑制统一于单一控制框架中，并在真实设备上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 林业起重机在动态、非结构化户外环境中作业，需同时保障避障与负载抑摆，但现有方法通常将二者割裂处理，缺乏统一实时控制方案。

Method: 提出一种集成LiDAR环境建图与在线欧氏距离场（EDF）的模型预测控制器（MPC），在优化目标中联合建模碰撞约束与摆动动力学，支持在线重规划、扰动鲁棒性和安全急停。

Result: 在真实林业起重机平台上成功验证：实现有效负载抑摆与动态障碍物规避；具备对准静态环境变化的响应能力、扰动下的持续避障能力，以及无绕行路径时的安全停止功能。

Conclusion: 该MPC框架首次实现了林业起重机中避障与抑摆的紧耦合实时控制，显著提升了复杂野外作业的安全性与自主性。

Abstract: Forestry cranes operate in dynamic, unstructured outdoor environments where simultaneous collision avoidance and payload sway control are critical for safe navigation. Existing approaches address these challenges separately, either focusing on sway damping with predefined collision-free paths or performing collision avoidance only at the global planning level. We present the first collision-free, sway-damping model predictive controller (MPC) for a forestry crane that unifies both objectives in a single control framework. Our approach integrates LiDAR-based environment mapping directly into the MPC using online Euclidean distance fields (EDF), enabling real-time environmental adaptation. The controller simultaneously enforces collision constraints while damping payload sway, allowing it to (i) replan upon quasi-static environmental changes, (ii) maintain collision-free operation under disturbances, and (iii) provide safe stopping when no bypass exists. Experimental validation on a real forestry crane demonstrates effective sway damping and successful obstacle avoidance. A video can be found at https://youtu.be/tEXDoeLLTxA.

</details>


### [345] [Humanoid Factors: Design Principles for AI Humanoids in Human Worlds](https://arxiv.org/abs/2602.10069)
*Xinyuan Liu,Eren Sadikoglu,Ransalu Senanayake,Lixiao Huang*

Main category: cs.RO

TL;DR: 本文提出了‘人形机器人因素’（humanoid factors）这一新框架，围绕物理、认知、社会和伦理四大支柱，旨在指导人形机器人与人类共存协作的设计、评估与治理。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人进入人类生活空间，传统人因工程已不足以应对人-机共存带来的新挑战，亟需一个兼顾人类与人形机器人双方特性的系统性框架。

Method: 提出四支柱（物理、认知、社会、伦理）的‘人形机器人因素’框架，并以真实人形机器人控制算法为案例进行应用分析，对比常规机器人任务指标与人类认知及交互原则的差异。

Result: 揭示了现有机器人评估指标忽视人类认知与交互原则的问题，验证了该框架在识别设计盲点与提升协作质量方面的实用性。

Conclusion: ‘人形机器人因素’是支撑可持续人-机共存的基础性框架，应成为人形机器人研发、评估与治理的核心范式。

Abstract: Human factors research has long focused on optimizing environments, tools, and systems to account for human performance. Yet, as humanoid robots begin to share our workplaces, homes, and public spaces, the design challenge expands. We must now consider not only factors for humans but also factors for humanoids, since both will coexist and interact within the same environments. Unlike conventional machines, humanoids introduce expectations of human-like behavior, communication, and social presence, which reshape usability, trust, and safety considerations. In this article, we introduce the concept of humanoid factors as a framework structured around four pillars - physical, cognitive, social, and ethical - that shape the development of humanoids to help them effectively coexist and collaborate with humans. This framework characterizes the overlap and divergence between human capabilities and those of general-purpose humanoids powered by AI foundation models. To demonstrate our framework's practical utility, we then apply the framework to evaluate a real-world humanoid control algorithm, illustrating how conventional task completion metrics in robotics overlook key human cognitive and interaction principles. We thus position humanoid factors as a foundational framework for designing, evaluating, and governing sustained human-humanoid coexistence.

</details>


### [346] [UniVTAC: A Unified Simulation Platform for Visuo-Tactile Manipulation Data Generation, Learning, and Benchmarking](https://arxiv.org/abs/2602.10093)
*Baijun Chen,Weijie Wan,Tianxing Chen,Xianda Guo,Congsheng Xu,Yuanyang Qi,Haojie Zhang,Longyan Wu,Tianling Xu,Zixuan Li,Yizhe Wu,Rui Li,Xiaokang Yang,Ping Luo,Wei Sui,Yao Mu*

Main category: cs.RO

TL;DR: 本文提出了UniVTAC，一个基于仿真的触觉-视觉数据合成平台，用于解决触觉数据获取难和缺乏统一评估平台的问题；并基于该平台构建了触觉中心的编码器（UniVTAC Encoder）和包含8个任务的基准测试集（UniVTAC Benchmark），实验表明其显著提升了操作成功率。


<details>
  <summary>Details</summary>
Motivation: 触觉感知对接触密集型操作（如插入）至关重要，但真实世界中大规模、可靠的触觉数据采集成本高、难度大，且缺乏统一评估平台，限制了策略学习与系统分析。

Method: 提出仿真驱动的UniVTAC平台，支持三种主流触觉传感器，实现可扩展、可控的接触交互数据合成；基于合成数据训练触觉中心的UniVTAC Encoder；构建包含八个代表性任务的UniVTAC Benchmark进行评估。

Result: 在UniVTAC Benchmark上平均成功率提升17.1%；真实机器人实验中任务成功率提升25%。

Conclusion: UniVTAC平台、Encoder与Benchmark共同为触觉-视觉操作研究提供了可扩展的数据基础、有效表征与标准化评估手段，显著提升了触觉驱动策略性能。

Abstract: Robotic manipulation has seen rapid progress with vision-language-action (VLA) policies. However, visuo-tactile perception is critical for contact-rich manipulation, as tasks such as insertion are difficult to complete robustly using vision alone. At the same time, acquiring large-scale and reliable tactile data in the physical world remains costly and challenging, and the lack of a unified evaluation platform further limits policy learning and systematic analysis. To address these challenges, we propose UniVTAC, a simulation-based visuo-tactile data synthesis platform that supports three commonly used visuo-tactile sensors and enables scalable and controllable generation of informative contact interactions. Based on this platform, we introduce the UniVTAC Encoder, a visuo-tactile encoder trained on large-scale simulation-synthesized data with designed supervisory signals, providing tactile-centric visuo-tactile representations for downstream manipulation tasks. In addition, we present the UniVTAC Benchmark, which consists of eight representative visuo-tactile manipulation tasks for evaluating tactile-driven policies. Experimental results show that integrating the UniVTAC Encoder improves average success rates by 17.1% on the UniVTAC Benchmark, while real-world robotic experiments further demonstrate a 25% improvement in task success. Our webpage is available at https://univtac.github.io/.

</details>


### [347] [VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model](https://arxiv.org/abs/2602.10098)
*Jingwen Sun,Wenyao Zhang,Zekun Qi,Shaojie Ren,Zezhi Liu,Hanxin Zhu,Guangzhong Sun,Xin Jin,Zhibo Chen*

Main category: cs.RO

TL;DR: 本文提出VLA-JEPA框架，通过无信息泄漏的状态预测，在潜在空间中学习动作相关的状态转移，从而提升视觉-语言-动作策略在跨任务泛化与鲁棒性上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于潜在动作的预训练方法易受外观偏差、无关运动和信息泄漏影响，因其仍依赖像素级变化而非真正动作相关状态变化。

Method: 提出JEPA风格的预训练框架VLA-JEPA，采用目标编码器从未来帧生成潜在表征作为监督信号，学生通路仅输入当前观测，确保未来信息不参与前向传播；在潜在空间进行状态预测，并接动作头微调。

Result: 在LIBERO、LIBERO-Plus、SimplerEnv及真实世界操作任务上，VLA-JEPA在泛化性和鲁棒性方面持续优于现有方法。

Conclusion: VLA-JEPA通过泄漏自由的潜在空间状态预测，有效解耦动作相关动态与干扰因素，提供更简洁高效且更具鲁棒性的VLA预训练范式。

Abstract: Pretraining Vision-Language-Action (VLA) policies on internet-scale video is appealing, yet current latent-action objectives often learn the wrong thing: they remain anchored to pixel variation rather than action-relevant state transitions, making them vulnerable to appearance bias, nuisance motion, and information leakage. We introduce VLA-JEPA, a JEPA-style pretraining framework that sidesteps these pitfalls by design. The key idea is \emph{leakage-free state prediction}: a target encoder produces latent representations from future frames, while the student pathway sees only the current observation -- future information is used solely as supervision targets, never as input. By predicting in latent space rather than pixel space, VLA-JEPA learns dynamics abstractions that are robust to camera motion and irrelevant background changes. This yields a simple two-stage recipe -- JEPA pretraining followed by action-head fine-tuning -- without the multi-stage complexity of prior latent-action pipelines. Experiments on LIBERO, LIBERO-Plus, SimplerEnv and real-world manipulation tasks show that VLA-JEPA achieves consistent gains in generalization and robustness over existing methods.

</details>


### [348] [Robo3R: Enhancing Robotic Manipulation with Accurate Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2602.10101)
*Sizhe Yang,Linning Xu,Hao Li,Juncheng Mu,Jia Zeng,Dahua Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: Robo3R是一种实时、高精度的RGB+机器人状态驱动的3D重建模型，专为机器人操作设计，通过联合估计局部几何与相机位姿，并在机器人坐标系下统一建模，显著提升下游操作任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度传感器存在噪声和材质敏感问题，而传统重建模型缺乏操作所需的精度与度量一致性，亟需一种可靠、实时、高保真的3D感知方案。

Method: Robo3R采用前馈网络，联合预测尺度无关的局部几何与相对相机位姿，通过学习到的全局相似变换统一至机器人本体坐标系；引入掩码点云头生成精细点云，并结合关键点PnP优化相机外参与全局对齐；在自建大规模合成数据集Robo3R-4M上训练。

Result: Robo3R在重建精度与度量一致性上持续超越SOTA方法及真实深度传感器，在模仿学习、sim-to-real迁移、抓取合成与无碰撞运动规划等下游任务中均取得一致性能提升。

Conclusion: Robo3R提供了一种可替代传统深度传感的高可靠性3D感知模块，为通用机器人操作奠定了坚实的几何感知基础。

Abstract: 3D spatial perception is fundamental to generalizable robotic manipulation, yet obtaining reliable, high-quality 3D geometry remains challenging. Depth sensors suffer from noise and material sensitivity, while existing reconstruction models lack the precision and metric consistency required for physical interaction. We introduce Robo3R, a feed-forward, manipulation-ready 3D reconstruction model that predicts accurate, metric-scale scene geometry directly from RGB images and robot states in real time. Robo3R jointly infers scale-invariant local geometry and relative camera poses, which are unified into the scene representation in the canonical robot frame via a learned global similarity transformation. To meet the precision demands of manipulation, Robo3R employs a masked point head for sharp, fine-grained point clouds, and a keypoint-based Perspective-n-Point (PnP) formulation to refine camera extrinsics and global alignment. Trained on Robo3R-4M, a curated large-scale synthetic dataset with four million high-fidelity annotated frames, Robo3R consistently outperforms state-of-the-art reconstruction methods and depth sensors. Across downstream tasks including imitation learning, sim-to-real transfer, grasp synthesis, and collision-free motion planning, we observe consistent gains in performance, suggesting the promise of this alternative 3D sensing module for robotic manipulation.

</details>


### [349] [DexImit: Learning Bimanual Dexterous Manipulation from Monocular Human Videos](https://arxiv.org/abs/2602.10105)
*Juncheng Mu,Sizhe Yang,Yiming Bao,Hojin Bae,Tianming Wei,Linning Xu,Boyi Li,Huazhe Xu,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本文提出DexImit框架，将单目人类操作视频自动转化为物理上合理的双手机器人操作数据，以缓解双手机器人灵巧操作中真实数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 真实世界中双手机器人灵巧操作的数据采集成本高、耗时长，导致数据稀缺；而人类操作视频虽丰富，却因人手与机器人手在形态和运动学上的巨大差异（embodiment gap）难以直接用于机器人预训练。

Method: DexImit采用四阶段自动生成流程：(1) 从任意视角重建具有近度量尺度的手-物交互；(2) 进行子任务分解与双手调度；(3) 合成符合演示交互的机器人轨迹；(4) 全面的数据增强以支持零样本真实部署。

Result: DexImit能基于互联网或生成式视频模型获取的人类视频，大规模生成高质量机器人操作数据，并成功处理多种复杂任务，如工具使用（切苹果）、长程任务（制作饮料）和细粒度操作（叠杯子）。

Conclusion: DexImit有效弥合了人类视频与机器人执行之间的具身鸿沟，为利用海量人类视频知识提升双手机器人灵巧操作能力提供了可扩展、自动化的新范式。

Abstract: Data scarcity fundamentally limits the generalization of bimanual dexterous manipulation, as real-world data collection for dexterous hands is expensive and labor-intensive. Human manipulation videos, as a direct carrier of manipulation knowledge, offer significant potential for scaling up robot learning. However, the substantial embodiment gap between human hands and robotic dexterous hands makes direct pretraining from human videos extremely challenging. To bridge this gap and unleash the potential of large-scale human manipulation video data, we propose DexImit, an automated framework that converts monocular human manipulation videos into physically plausible robot data, without any additional information. DexImit employs a four-stage generation pipeline: (1) reconstructing hand-object interactions from arbitrary viewpoints with near-metric scale; (2) performing subtask decomposition and bimanual scheduling; (3) synthesizing robot trajectories consistent with the demonstrated interactions; (4) comprehensive data augmentation for zero-shot real-world deployment. Building on these designs, DexImit can generate large-scale robot data based on human videos, either from the Internet or video generation models. DexImit is capable of handling diverse manipulation tasks, including tool use (e.g., cutting an apple), long-horizon tasks (e.g., making a beverage), and fine-grained manipulations (e.g., stacking cups).

</details>


### [350] [EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration](https://arxiv.org/abs/2602.10106)
*Modi Shi,Shijia Peng,Jin Chen,Haoran Jiang,Yinghui Li,Di Huang,Ping Luo,Hongyang Li,Li Chen*

Main category: cs.RO

TL;DR: 本文提出EgoHumanoid框架，首次利用大量第一人称视角人类演示数据与少量机器人数据协同训练视觉-语言-动作策略，通过系统性对齐（包括视角和动作对齐）弥合人类与人形机器人在形态和视角上的差异，显著提升人形机器人在真实世界多场景下的定位-操作能力。


<details>
  <summary>Details</summary>
Motivation: 人类演示具有环境多样性高、易扩展等优势，但在更具挑战性、数据需求更高的人形机器人定位-操作任务中尚未被充分探索。

Method: 提出EgoHumanoid框架，构建从硬件设计到数据处理的系统性对齐流程：开发便携式人类数据采集系统与实用协议；实现视角对齐（缓解相机高度与视角差异）与动作对齐（将人类动作映射至人形机器人可行动作空间）；联合训练视觉-语言-动作策略。

Result: 真实世界实验表明，引入无机器人参与的第一人称人类数据使性能较纯机器人基线提升51%，尤其在未见环境中效果显著；分析揭示了可有效迁移的行为模式及人类数据规模化潜力。

Conclusion: EgoHumanoid验证了利用大规模人类演示数据提升人形机器人locomanipulation能力的可行性与有效性，为降低机器人数据依赖提供了新范式。

Abstract: Human demonstrations offer rich environmental diversity and scale naturally, making them an appealing alternative to robot teleoperation. While this paradigm has advanced robot-arm manipulation, its potential for the more challenging, data-hungry problem of humanoid loco-manipulation remains largely unexplored. We present EgoHumanoid, the first framework to co-train a vision-language-action policy using abundant egocentric human demonstrations together with a limited amount of robot data, enabling humanoids to perform loco-manipulation across diverse real-world environments. To bridge the embodiment gap between humans and robots, including discrepancies in physical morphology and viewpoint, we introduce a systematic alignment pipeline spanning from hardware design to data processing. A portable system for scalable human data collection is developed, and we establish practical collection protocols to improve transferability. At the core of our human-to-humanoid alignment pipeline lies two key components. The view alignment reduces visual domain discrepancies caused by camera height and perspective variation. The action alignment maps human motions into a unified, kinematically feasible action space for humanoid control. Extensive real-world experiments demonstrate that incorporating robot-free egocentric data significantly outperforms robot-only baselines by 51\%, particularly in unseen environments. Our analysis further reveals which behaviors transfer effectively and the potential for scaling human data.

</details>


### [351] [ST4VLA: Spatially Guided Training for Vision-Language-Action Models](https://arxiv.org/abs/2602.10109)
*Jinhui Ye,Fangjing Wang,Ning Gao,Junqiu Yu,Yangkun Zhu,Bin Wang,Jinyu Zhang,Weiyang Jin,Yanwei Fu,Feng Zheng,Yilun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本文提出了ST4VLA框架，通过空间引导训练将视觉-语言模型（VLM）扩展至具身任务，显著提升机器人在SimlperEnv等基准上的动作生成性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（VLMs）在多模态理解上表现优异，但在具身任务中难以将指令转化为低层动作，亟需引入空间先验以桥接感知与行动。

Method: 提出双系统Vision-Language-Action框架ST4VLA，包含两阶段：(i) 空间接地预训练，利用网络与机器人数据进行点、框、轨迹预测；(ii) 空间引导动作后训练，通过空间提示增强动作生成。

Result: 在Google Robot和WidowX Robot上分别从66.1→84.6、54.7→73.2，刷新SimplerEnv SOTA；并展现出对未见物体、改写指令及长时程扰动的强泛化与鲁棒性。

Conclusion: 空间引导训练是一种可扩展、稳健且通用的机器人学习新范式，有效保持空间接地性并协调空间与动作目标优化。

Abstract: Large vision-language models (VLMs) excel at multimodal understanding but fall short when extended to embodied tasks, where instructions must be transformed into low-level motor actions. We introduce ST4VLA, a dual-system Vision-Language-Action framework that leverages Spatial Guided Training to align action learning with spatial priors in VLMs. ST4VLA includes two stages: (i) spatial grounding pre-training, which equips the VLM with transferable priors via scalable point, box, and trajectory prediction from both web-scale and robot-specific data, and (ii) spatially guided action post-training, which encourages the model to produce richer spatial priors to guide action generation via spatial prompting. This design preserves spatial grounding during policy learning and promotes consistent optimization across spatial and action objectives. Empirically, ST4VLA achieves substantial improvements over vanilla VLA, with performance increasing from 66.1 -> 84.6 on Google Robot and from 54.7 -> 73.2 on WidowX Robot, establishing new state-of-the-art results on SimplerEnv. It also demonstrates stronger generalization to unseen objects and paraphrased instructions, as well as robustness to long-horizon perturbations in real-world settings. These results highlight scalable spatially guided training as a promising direction for robust, generalizable robot learning. Source code, data and models are released at https://internrobotics.github.io/internvla-m1.github.io/

</details>


### [352] [Learning Agile Quadrotor Flight in the Real World](https://arxiv.org/abs/2602.10111)
*Yunfan Ren,Zhiyuan Zhu,Jiaxu Xing,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本文提出了一种无需精确系统辨识和离线Sim2Real迁移的自适应控制框架，通过自适应时间缩放（ATS）探索平台物理极限，并结合在线残差学习与RASH-BPTT算法实现实时策略更新，在约100秒内将四旋翼峰值速度从1.9 m/s提升至7.3 m/s。


<details>
  <summary>Details</summary>
Motivation: 基于学习的控制器在仿真中训练效果好，但依赖准确建模以实现Sim2Real迁移；固定策略难以应对真实世界中不断变化的不确定性（如气流扰动、硬件退化），导致需保守设计、牺牲敏捷性；而在线自适应又受限于数据稀缺与飞行安全风险。

Method: 提出自适应框架：1）自适应时间缩放（ATS）主动探索物理极限；2）在线残差学习增强简单名义模型；3）基于混合模型设计Real-world Anchored Short-horizon BPTT（RASH-BPTT）进行高效鲁棒的机上策略更新。

Result: 实验表明该方法使四旋翼可靠执行近执行器饱和极限的敏捷机动；在约100秒飞行时间内，峰值速度由1.9 m/s提升至7.3 m/s。

Conclusion: 真实世界中的在线自适应不仅是补偿建模误差的手段，更是实现激进飞行模式下持续性能提升的实用机制。

Abstract: Learning-based controllers have achieved impressive performance in agile quadrotor flight but typically rely on massive training in simulation, necessitating accurate system identification for effective Sim2Real transfer. However, even with precise modeling, fixed policies remain susceptible to out-of-distribution scenarios, ranging from external aerodynamic disturbances to internal hardware degradation. To ensure safety under these evolving uncertainties, such controllers are forced to operate with conservative safety margins, inherently constraining their agility outside of controlled settings. While online adaptation offers a potential remedy, safely exploring physical limits remains a critical bottleneck due to data scarcity and safety risks. To bridge this gap, we propose a self-adaptive framework that eliminates the need for precise system identification or offline Sim2Real transfer. We introduce Adaptive Temporal Scaling (ATS) to actively explore platform physical limits, and employ online residual learning to augment a simple nominal model. {Based on the learned hybrid model, we further propose Real-world Anchored Short-horizon Backpropagation Through Time (RASH-BPTT) to achieve efficient and robust in-flight policy updates. Extensive experiments demonstrate that our quadrotor reliably executes agile maneuvers near actuator saturation limits. The system evolves a conservative base policy with a peak speed of 1.9 m/s to 7.3 m/s within approximately 100 seconds of flight time. These findings underscore that real-world adaptation serves not merely to compensate for modeling errors, but as a practical mechanism for sustained performance improvement in aggressive flight regimes.

</details>


### [353] [Decoupled MPPI-Based Multi-Arm Motion Planning](https://arxiv.org/abs/2602.10114)
*Dan Evron,Elias Goldsztejn,Ronen I. Brafman*

Main category: cs.RO

TL;DR: 本文提出MR-STORM，一种分布式多机器人采样式模型预测控制运动规划算法，通过动态障碍物处理、共享运动前缀与动态优先级机制，显著提升多臂协同规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GPU的采样式运动规划算法在多臂联合控制时扩展性差，难以高效处理多机器人协同场景。

Method: 在STORM算法基础上进行三方面改进：1）增强对动态障碍物的支持；2）各机械臂独立计算并共享运动计划前缀，将其余臂视为动态障碍；3）引入动态优先级调度机制。

Result: MR-STORM在静态与动态障碍环境下均展现出优于当前SOTA算法的实证性能。

Conclusion: 分布式协同规划框架结合动态障碍建模与优先级机制，有效提升了高自由度多臂系统的运动规划效率与可扩展性。

Abstract: Recent advances in sampling-based motion planning algorithms for high DOF arms leverage GPUs to provide SOTA performance. These algorithms can be used to control multiple arms jointly, but this approach scales poorly. To address this, we extend STORM, a sampling-based model-predictive-control (MPC) motion planning algorithm, to handle multiple robots in a distributed fashion. First, we modify STORM to handle dynamic obstacles. Then, we let each arm compute its own motion plan prefix, which it shares with the other arms, which treat it as a dynamic obstacle. Finally, we add a dynamic priority scheme. The new algorithm, MR-STORM, demonstrates clear empirical advantages over SOTA algorithms when operating with both static and dynamic obstacles.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [354] [SMES: Towards Scalable Multi-Task Recommendation via Expert Sparsity](https://arxiv.org/abs/2602.09386)
*Yukun Zhang,Si Dong,Xu Wang,Bo Chen,Qinglin Jia,Shengzhe Wang,Jinlong Jiao,Runhan Li,Jiaqing Liu,Chaoyi Ma,Ruiming Tang,Guorui Zhou,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: 本文提出SMES框架，通过渐进式专家路由和全局多门负载均衡正则化，解决稀疏MoE在多任务推荐中专家激活爆炸和负载不均的问题，在快手短视频服务中取得显著线上效果提升。


<details>
  <summary>Details</summary>
Motivation: 工业级推荐系统中，统一扩大模型参数难以适配不同任务对容量的异质需求，导致在线推理成本高且稀疏任务收益递减。

Method: 提出SMES框架：将专家激活分解为任务共享子集和任务自适应私有专家，并引入全局多门负载均衡正则化以稳定训练和平衡各任务下专家总体利用率。

Result: 在快手大规模短视频服务中部署，支持超4亿日活用户；线上实验显示GAUC提升0.29%，用户观看时长提升0.31%。

Conclusion: SMES通过结构化稀疏设计与协同负载控制，实现了高效、可扩展的多任务推荐，验证了参数稀疏化作为推荐模型规模化新范式的可行性与有效性。

Abstract: Industrial recommender systems typically rely on multi-task learning to estimate diverse user feedback signals and aggregate them for ranking. Recent advances in model scaling have shown promising gains in recommendation. However, naively increasing model capacity imposes prohibitive online inference costs and often yields diminishing returns for sparse tasks with skewed label distributions. This mismatch between uniform parameter scaling and heterogeneous task capacity demands poses a fundamental challenge for scalable multi-task recommendation. In this work, we investigate parameter sparsification as a principled scaling paradigm and identify two critical obstacles when applying sparse Mixture-of-Experts (MoE) to multi-task recommendation: exploded expert activation that undermines instance-level sparsity and expert load skew caused by independent task-wise routing. To address these challenges, we propose SMES, a scalable sparse MoE framework with progressive expert routing. SMES decomposes expert activation into a task-shared expert subset jointly selected across tasks and task-adaptive private experts, explicitly bounding per-instance expert execution while preserving task-specific capacity. In addition, SMES introduces a global multi-gate load-balancing regularizer that stabilizes training by regulating aggregated expert utilization across all tasks. SMES has been deployed in Kuaishou large-scale short-video services, supporting over 400 million daily active users. Extensive online experiments demonstrate stable improvements, with GAUC gain of 0.29% and a 0.31% uplift in user watch time.

</details>


### [355] [Query-Mixed Interest Extraction and Heterogeneous Interaction: A Scalable CTR Model for Industrial Recommender Systems](https://arxiv.org/abs/2602.09387)
*Fangye Wang,Guowei Yang,Xiaojiang Zhou,Song Yang,Pengjie Wang*

Main category: cs.IR

TL;DR: HeMix is a scalable ranking model for recommender systems that unifies adaptive sequence tokenization and heterogeneous interaction structure to better model user intent from long-term and real-time behavior, achieving significant online improvements on AMAP.


<details>
  <summary>Details</summary>
Motivation: Existing models struggle with sparse multi-field inputs and ultra-long user behavior sequences; they fail to jointly capture context-aware and context-independent user intent, and suffer from inefficient, homogeneous interaction mechanisms.

Method: HeMix introduces (1) a Query-Mixed Interest Extraction module using dynamic/fixed queries over global and real-time behavior sequences, and (2) a HeteroMixer block replacing self-attention for efficient, multi-granularity, heterogeneous cross-feature interactions via multi-head token fusion, heterogeneous interaction, and group-aligned reconstruction.

Result: HeMix shows favorable scaling behavior and consistently outperforms strong baselines on industrial-scale datasets; deployed on AMAP, it yields +0.61% GMV, +2.32% PV_CTR, and +0.81% UV_CVR.

Conclusion: HeMix effectively addresses key limitations in industrial recommender systems by unifying adaptive tokenization and heterogeneous interaction, enabling scalable, accurate, and deployable modeling of user intent.

Abstract: Learning effective feature interactions is central to modern recommender systems, yet remains challenging in industrial settings due to sparse multi-field inputs and ultra-long user behavior sequences. While recent scaling efforts have improved model capacity, they often fail to construct both context-aware and context-independent user intent from the long-term and real-time behavior sequence. Meanwhile, recent work also suffers from inefficient and homogeneous interaction mechanisms, leading to suboptimal prediction performance. To address these limitations, we propose HeMix, a scalable ranking model that unifies adaptive sequence tokenization and heterogeneous interaction structure. Specifically, HeMix introduces a Query-Mixed Interest Extraction module that jointly models context-aware and context-independent user interests via dynamic and fixed queries over global and real-time behavior sequences. For interaction, we replace self-attention with the HeteroMixer block, enabling efficient, multi-granularity cross-feature interactions that adopt the multi-head token fusion, heterogeneous interaction and group-aligned reconstruction pipelines. HeMix demonstrates favorable scaling behavior, driven by the HeteroMixer block, where increasing model scale via parameter expansion leads to steady improvements in recommendation accuracy. Experiments on industrial-scale datasets show that HeMix scales effectively and consistently outperforms strong baselines. Most importantly, HeMix has been deployed on the AMAP platform, delivering significant online gains: +0.61% GMV, +2.32% PV_CTR, and +0.81% UV_CVR.

</details>


### [356] [SARM: LLM-Augmented Semantic Anchor for End-to-End Live-Streaming Ranking](https://arxiv.org/abs/2602.09401)
*Ruochen Yang,Yueyang Liu,Zijie Zhuang,Changxin Lao,Yuhui Zhang,Jiangxia Cao,Jia Xu,Xiang Chen,Haoke Xiao,Xiangyu Wu,Xiaoyou Zhou,Xiao Lv,Shuang Yang,Tingwen Liu,Zhaojie Liu,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: 本文提出SARM，一种端到端的直播推荐排序架构，通过将自然语言语义锚点直接融入排序优化，实现细粒度、内容感知的作者表征，并在工业级大规模部署中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有工业直播推荐方法存在两大局限：离散语义抽象牺牲描述精度，稠密多模态嵌入与排序目标弱对齐，难以支持细粒度内容感知排序。

Method: 提出SARM架构，引入可学习的自然语言语义锚点（文本token），与排序特征联合优化；采用轻量级双token门控设计建模直播领域语义；设计非对称部署策略保障低延迟在线训练与服务。

Result: 离线评估与大规模A/B测试均显著优于线上基线模型；已全量部署，日均服务超4亿用户。

Conclusion: SARM成功实现了语义建模与排序优化的端到端协同，兼顾表达能力与实时性，在工业大规模直播推荐系统中具备实用价值和推广意义。

Abstract: Large-scale live-streaming recommendation requires precise modeling of non-stationary content semantics under strict real-time serving constraints. In industrial deployment, two common approaches exhibit fundamental limitations: discrete semantic abstractions sacrifice descriptive precision through clustering, while dense multimodal embeddings are extracted independently and remain weakly aligned with ranking optimization, limiting fine-grained content-aware ranking. To address these limitations, we propose \textbf{SARM}, an end-to-end ranking architecture that integrates natural-language semantic anchors directly into ranking optimization, enabling fine-grained author representations conditioned on multimodal content. Each semantic anchor is represented as learnable text tokens jointly optimized with ranking features, allowing the model to adapt content descriptions to ranking objectives. A lightweight dual-token gated design captures domain-specific live-streaming semantics, while an asymmetric deployment strategy preserves low-latency online training and serving. Extensive offline evaluation and large-scale A/B tests show consistent improvements over production baselines. SARM is fully deployed and serves over 400 million users daily.

</details>


### [357] [Personalized Parameter-Efficient Fine-Tuning of Foundation Models for Multimodal Recommendation](https://arxiv.org/abs/2602.09445)
*Sunwoo Kim,Hyunjin Hwang,Kijung Shin*

Main category: cs.IR

TL;DR: 本文提出PerPEFT，一种面向多模态推荐的个性化参数高效微调（PEFT）策略，通过按用户兴趣分组并为每组分配独立PEFT模块，使物品嵌入能感知用户偏好，显著提升推荐效果且保持轻量级。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态基础模型的推荐方法中，即使采用参数高效微调（PEFT），物品嵌入仍是用户盲的，无法根据用户兴趣动态关注不同物品特征。

Method: 提出PerPEFT：按用户兴趣聚类分组，为每组分配专属PEFT模块，并设计专门训练技术强化用户-组条件建模；该方法与具体PEFT方式无关，具有通用性。

Result: 在多个基准上，PerPEFT相较最强基线提升最高达15.3%（NDCG@20），且在各类PEFT变体上均保持稳定增益；仅增加基础模型0.013倍参数量。

Conclusion: PerPEFT有效解决了多模态推荐中物品表征缺乏用户感知的问题，在性能与效率间取得良好平衡，验证了个性化PEFT在推荐场景中的有效性与可扩展性。

Abstract: In recent years, substantial research has integrated multimodal item metadata into recommender systems, often by using pre-trained multimodal foundation models to encode such data. Since these models are not originally trained for recommendation tasks, recent works efficiently adapt them via parameter-efficient fine-tuning (PEFT). However, even with PEFT, item embeddings from multimodal foundation models remain user-blind: item embeddings are not conditioned on user interests, despite the fact that users with diverse interests attend to different item aspects. To address this limitation, we propose PerPEFT, a personalized PEFT strategy for multimodal recommendation. Specifically, PerPEFT groups users by interest and assigns a distinct PEFT module to each group, enabling each module to capture the fine-grained item aspects most predictive of that group`s purchase decisions. We further introduce a specialized training technique that strengthens this user-group conditioning. Notably, PerPEFT is PEFT-agnostic and can be paired with any PEFT method applicable to multimodal foundation models. Through extensive experiments, we show that (1) PerPEFT outperforms the strongest baseline by up to 15.3% (NDCG@20) and (2) delivers consistent gains across diverse PEFT variants. It is noteworthy that, even with personalization, PEFT remains lightweight, adding only 1.3% of the parameter count of the foundation model. We provide our code and datasets at https://github.com/kswoo97/PerPEFT.

</details>


### [358] [The Wisdom of Many Queries: Complexity-Diversity Principle for Dense Retriever Training](https://arxiv.org/abs/2602.09448)
*Xincan Feng,Noriki Nishida,Yusuke Sakai,Yuji Matsumoto*

Main category: cs.IR

TL;DR: 本文提出Q-D指标量化查询多样性对密集检索的影响，发现其在多跳检索中尤为有效，并基于查询复杂度（内容词数量）提出复杂度-多样性原则（CDP），据此设计零样本多查询合成方法，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 先前研究在合成数据生成中查询多样性的效果上存在矛盾结果，本文旨在解决这一冲突并建立可测量的评估框架。

Method: 设计Q-D指标量化查询多样性影响；在31个数据集上进行实验；深入分析多跳数据中查询复杂度与多样性收益的关系；提出复杂度-多样性原则（CDP）及相应阈值；基于CDP设计零样本多查询合成方法。

Result: 发现查询多样性显著提升多跳检索性能；多样性收益与查询复杂度高度相关（r≥0.95，p<0.05）；CDP给出可操作阈值（CW>10用多样性，CW<7避免）；所提零样本方法达SOTA。

Conclusion: 查询复杂度决定最优多样性水平，CDP为合成数据生成提供了理论指导和实践准则，推动多跳密集检索的发展。

Abstract: Prior work reports conflicting results on query diversity in synthetic data generation for dense retrieval. We identify this conflict and design Q-D metrics to quantify diversity's impact, making the problem measurable. Through experiments on 4 benchmark types (31 datasets), we find query diversity especially benefits multi-hop retrieval. Deep analysis on multi-hop data reveals that diversity benefit correlates strongly with query complexity ($r$$\geq$0.95, $p$$<$0.05 in 12/14 conditions), measured by content words (CW). We formalize this as the Complexity-Diversity Principle (CDP): query complexity determines optimal diversity. CDP provides actionable thresholds (CW$>$10: use diversity; CW$<$7: avoid it). Guided by CDP, we propose zero-shot multi-query synthesis for multi-hop tasks, achieving state-of-the-art performance.

</details>


### [359] [With Argus Eyes: Assessing Retrieval Gaps via Uncertainty Scoring to Detect and Remedy Retrieval Blind Spots](https://arxiv.org/abs/2602.09616)
*Zeinab Sadat Taghavi,Ali Modarressi,Hinrich Schutze,Andreas Marfurt*

Main category: cs.IR

TL;DR: 本文揭示了RAG系统中神经检索器存在'盲点'问题，即无法检索到与查询语义相关但嵌入相似度低的实体；提出基于嵌入几何结构预测盲点风险的RPS指标，并设计ARGUS方法通过知识库增强文档来提升高风险实体的可检索性，显著提升了多个基准上的检索效果。


<details>
  <summary>Details</summary>
Motivation: 神经检索器在RAG系统中存在盲点——无法检索到语义相关但嵌入空间距离远的实体，影响系统可靠性。

Method: 提出检索概率分数（RPS）从嵌入几何结构预判盲点风险；设计ARGUS流程，利用知识库（如Wikipedia首段）对低RPS实体进行定向文档增强。

Result: 在BRIGHT、IMPLIRET和RAR-B上，ARGUS使各检索器平均提升+3.4 nDCG@5和+4.5 nDCG@10；在困难子集上增益更显著。

Conclusion: 预判并修复检索盲点对构建鲁棒可信的RAG系统至关重要。

Abstract: Reliable retrieval-augmented generation (RAG) systems depend fundamentally on the retriever's ability to find relevant information. We show that neural retrievers used in RAG systems have blind spots, which we define as the failure to retrieve entities that are relevant to the query, but have low similarity to the query embedding. We investigate the training-induced biases that cause such blind spot entities to be mapped to inaccessible parts of the embedding space, resulting in low retrievability. Using a large-scale dataset constructed from Wikidata relations and first paragraphs of Wikipedia, and our proposed Retrieval Probability Score (RPS), we show that blind spot risk in standard retrievers (e.g., CONTRIEVER, REASONIR) can be predicted pre-index from entity embedding geometry, avoiding expensive retrieval evaluations. To address these blind spots, we introduce ARGUS, a pipeline that enables the retrievability of high-risk (low-RPS) entities through targeted document augmentation from a knowledge base (KB), first paragraphs of Wikipedia, in our case. Extensive experiments on BRIGHT, IMPLIRET, and RAR-B show that ARGUS achieves consistent improvements across all evaluated retrievers (averaging +3.4 nDCG@5 and +4.5 nDCG@10 absolute points), with substantially larger gains in challenging subsets. These results establish that preemptively remedying blind spots is critical for building robust and trustworthy RAG systems (Code and Data).

</details>


### [360] [DiffuReason: Bridging Latent Reasoning and Generative Refinement for Sequential Recommendation](https://arxiv.org/abs/2602.09744)
*Jie Jiang,Yang Wu,Qian Li,Yuling Xiong,Yihang Su,Junbang Huo,Longfei Lu,Jun Zhang,Huan Yu*

Main category: cs.IR

TL;DR: 本文提出DiffuReason框架，通过'思考-扩散'两阶段机制，在序列推荐中建模用户意图的不确定性，并实现端到端联合优化。


<details>
  <summary>Details</summary>
Motivation: 现有隐式推理方法依赖确定性推理链，易累积噪声且忽略用户意图的不确定性，且多采用分阶段训练，难以联合优化和充分探索。

Method: 提出DiffuReason：1）Think阶段生成Thinking Tokens进行初步意图推理；2）Diffuse阶段用扩散模型对中间表征进行概率化迭代去噪；3）采用端到端Group Relative Policy Optimization（GRPO）对齐推理与精炼模块。

Result: 在四个公开基准上显著提升多种骨干模型性能；大规模工业平台在线A/B测试验证其实际有效性。

Conclusion: DiffuReason通过引入概率化隐式推理与端到端强化学习对齐，有效缓解了噪声累积与意图不确定性建模难题，提升了序列推荐的鲁棒性与准确性。

Abstract: Latent reasoning has emerged as a promising paradigm for sequential recommendation, enabling models to capture complex user intent through multi-step deliberation. Yet existing approaches often rely on deterministic latent chains that accumulate noise and overlook the uncertainty inherent in user intent, and they are typically trained in staged pipelines that hinder joint optimization and exploration. To address these challenges, we propose DiffuReason, a unified "Think-then-Diffuse" framework for sequential recommendation. It integrates multi-step Thinking Tokens for latent reasoning, diffusion-based refinement for denoising intermediate representations, and end-to-end Group Relative Policy Optimization (GRPO) alignment to optimize for ranking performance. In the Think stage, the model generates Thinking Tokens that reason over user history to form an initial intent hypothesis. In the Diffuse stage, rather than treating this hypothesis as the final output, we refine it through a diffusion process that models user intent as a probabilistic distribution, providing iterative denoising against reasoning noise. Finally, GRPO-based reinforcement learning enables the reasoning and refinement modules to co-evolve throughout training, without the constraints of staged optimization. Extensive experiments on four benchmarks demonstrate that DiffuReason consistently improves diverse backbone architectures. Online A/B tests on a large-scale industrial platform further validate its practical effectiveness.

</details>


### [361] [Internalizing Multi-Agent Reasoning for Accurate and Efficient LLM-based Recommendation](https://arxiv.org/abs/2602.09829)
*Yang Wu,Haoze Wang,Qian Li,Jun Zhang,Huan Yu,Jie Jiang*

Main category: cs.IR

TL;DR: 本文提出了一种单智能体轨迹对齐推荐系统STAR，通过多智能体教师系统生成推理轨迹，并利用轨迹驱动的知识蒸馏将复杂推理能力内化到轻量级模型中，在提升推荐效果的同时消除迭代延迟，实现低延迟、高精度的实时推荐。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽具备强大语义理解和推理能力，但难以有效融合协同信号且推理延迟高，限制了其在实时推荐系统中的应用。

Method: 设计多智能体教师系统，引入协同信号翻译机制将用户行为模式转化为自然语言证据；构建轨迹驱动的知识蒸馏流程，将教师的规划、工具调用与自反思能力压缩至单智能体STAR模型中。

Result: STAR在多个指标上超越教师模型8.7%–39.5%，同时完全消除迭代推理延迟，支持实时推理增强型推荐。

Conclusion: 轨迹驱动的内部化框架可高效将多智能体推理能力压缩至单智能体模型，在保持甚至提升性能的同时显著降低延迟，为LLM赋能的工业级推荐系统提供了新范式。

Abstract: Large Language Models (LLMs) are reshaping recommender systems by leveraging extensive world knowledge and semantic reasoning to interpret user intent. However, effectively integrating these capabilities with collaborative signals while avoiding prohibitive inference latency remains a critical bottleneck. To address this, we propose a trajectory-driven internalization framework to develop a Single-agent Trajectory-Aligned Recommender (STAR). Specifically, to internalize complex reasoning capabilities into a single efficient model, we first design a multi-agent teacher system capable of multi-turn tool usage and reflection. This teacher utilizes a Collaborative Signal Translation mechanism to explicitly convert latent behavioral patterns into descriptive natural language evidence to enhance reasoning accuracy. Subsequently, a trajectory-driven distillation pipeline transfers this agentic logic, including planning, tool usage, and self-reflection, into the compact STAR model. Extensive experiments demonstrate that STAR surpasses its teacher by 8.7% to 39.5% while eliminating iterative latency, paving the way for real-time, reasoning-enhanced recommendation.

</details>


### [362] [QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search](https://arxiv.org/abs/2602.09901)
*Jianzhao Huang,Xiaorui Huang,Fei Zhao,Yunpeng Liu,Hui Zhang,Fangcheng Shi,Congfeng Li,Zechen Sun,Yi Wu,Yao Hu,Yunhan Bai,Shaosheng Cao*

Main category: cs.IR

TL;DR: 本文提出QP-OneModel，一种面向社交网络服务（SNS）搜索的统一生成式大语言模型，通过三阶段对齐与多奖励强化学习，将多任务查询理解统一为序列生成范式，并引入意图描述作为高保真语义信号，在离线和线上均显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 传统查询处理系统依赖孤立判别模型，语义理解有限、维护成本高；现有LLM方法多孤立优化子任务，缺乏语义协同，且难以适配SNS非正式语言与严格业务定义。

Method: 将异构子任务统一为序列生成范式，采用渐进式三阶段对齐策略（预训练→监督微调→多奖励强化学习），并引入意图描述作为新型语义信号以增强下游任务。

Result: 离线评估相较判别基线整体提升7.35%，NER F1提升9.01%，词权重F1提升9.31%；泛化性优于32B模型7.60%；线上A/B测试显示DCG提升0.21%，用户留存率提升0.044%。

Conclusion: QP-OneModel验证了统一生成式架构在SNS查询理解中的有效性与工业落地价值，兼顾性能、泛化性与业务适配性。

Abstract: Query Processing (QP) bridges user intent and content supply in large-scale Social Network Service (SNS) search engines. Traditional QP systems rely on pipelines of isolated discriminative models (e.g., BERT), suffering from limited semantic understanding and high maintenance overhead. While Large Language Models (LLMs) offer a potential solution, existing approaches often optimize sub-tasks in isolation, neglecting intrinsic semantic synergy and necessitating independent iterations. Moreover, standard generative methods often lack grounding in SNS scenarios, failing to bridge the gap between open-domain corpora and informal SNS linguistic patterns, while struggling to adhere to rigorous business definitions. We present QP-OneModel, a Unified Generative LLM for Multi-Task Query Understanding in the SNS domain. We reformulate heterogeneous sub-tasks into a unified sequence generation paradigm, adopting a progressive three-stage alignment strategy culminating in multi-reward Reinforcement Learning. Furthermore, QP-OneModel generates intent descriptions as a novel high-fidelity semantic signal, effectively augmenting downstream tasks such as query rewriting and ranking. Offline evaluations show QP-OneModel achieves a 7.35% overall gain over discriminative baselines, with significant F1 boosts in NER (+9.01%) and Term Weighting (+9.31%). It also exhibits superior generalization, surpassing a 32B model by 7.60% accuracy on unseen tasks. Fully deployed at Xiaohongshu, online A/B tests confirm its industrial value, optimizing retrieval relevance (DCG) by 0.21% and lifting user retention by 0.044%.

</details>


### [363] [Efficient Learning of Sparse Representations from Interactions](https://arxiv.org/abs/2602.09935)
*Vojtěch Vančura,Martin Spišák,Rodrigo Alves,Ladislav Peška*

Main category: cs.IR

TL;DR: 本文提出了一种用于推荐系统初始检索阶段的高维稀疏嵌入训练策略，以在保持表达力的同时提升效率与可解释性；在ELSA模型上验证了嵌入尺寸最多可压缩10倍而精度无损、100倍时仅损失2.5%准确率，并揭示了嵌入维度的可解释倒排索引结构。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统的初始检索阶段，需在嵌入表达力与服务组件的可扩展性、延迟之间权衡，亟需兼具紧凑性与表达力的表示。

Method: 提出一种训练高维稀疏嵌入层的策略，替代传统稠密嵌入，并将其应用于生产级协同过滤自编码器ELSA。

Result: 在ELSA上实现嵌入大小最多减少10倍（精度无损）或100倍（精度仅降2.5%）；稀疏激活维度形成可解释的倒排索引结构，支持段级推荐功能（如2D首页布局）直接集成到检索模型中。

Conclusion: 高维稀疏嵌入可在显著压缩模型规模的同时维持甚至增强推荐性能与可解释性，为工业级推荐系统提供高效、紧凑且可解释的检索方案。

Abstract: Behavioral patterns captured in embeddings learned from interaction data are pivotal across various stages of production recommender systems. However, in the initial retrieval stage, practitioners face an inherent tradeoff between embedding expressiveness and the scalability and latency of serving components, resulting in the need for representations that are both compact and expressive. To address this challenge, we propose a training strategy for learning high-dimensional sparse embedding layers in place of conventional dense ones, balancing efficiency, representational expressiveness, and interpretability. To demonstrate our approach, we modified the production-grade collaborative filtering autoencoder ELSA, achieving up to 10x reduction in embedding size with no loss of recommendation accuracy, and up to 100x reduction with only a 2.5% loss. Moreover, the active embedding dimensions reveal an interpretable inverted-index structure that segments items in a way directly aligned with the model's latent space, thereby enabling integration of segment-level recommendation functionality (e.g., 2D homepage layouts) within the candidate retrieval model itself. Source codes, additional results, as well as a live demo are available at https://github.com/zombak79/compressed_elsa

</details>


### [364] [Kunlun: Establishing Scaling Laws for Massive-Scale Recommendation Systems through Unified Architecture Design](https://arxiv.org/abs/2602.10016)
*Bojian Hou,Xiaolong Liu,Xiaoyi Liu,Jiaqi Xu,Yasmine Badr,Mengyue Hang,Sudhanshu Chanpuriya,Junqing Zhou,Yuhang Yang,Han Xu,Qiuling Suo,Laming Chen,Yuxi Hu,Jiasheng Zhang,Huaqing Xiong,Yuzhen Huang,Chao Chen,Yue Dong,Yi Yang,Shuo Chang,Xiaorui Gan,Wenlin Chen,Santanu Kolay,Darren Liu,Jade Nie,Chunzhi Yang,Jiyan Yang,Huayu Li*

Main category: cs.IR

TL;DR: 本文提出了Kunlun架构，通过低层优化（如GDPA、HSP、滑动窗口注意力）和高层创新（如CompSkip、事件级个性化），显著提升推荐系统模型的计算效率与可扩展性，在Meta广告模型中已实现大规模部署并取得显著生产效果。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统缺乏类似大语言模型那样可预测的性能-算力缩放规律，尤其在同时处理用户历史和上下文特征时，主要瓶颈在于模块计算效率低（MFU低）和资源分配不合理。

Method: 提出Kunlun可扩展架构，包含低层优化（广义点积注意力GDPA、分层种子池化HSP、滑动窗口注意力）和高层创新（计算跳过CompSkip、事件级个性化）。

Result: MFU从17%提升至37%（NVIDIA B200 GPU），缩放效率较SOTA方法翻倍，并已在Meta主要广告模型中部署。

Conclusion: Kunlun有效解决了推荐系统中可预测缩放律缺失的问题，通过系统性提升模型效率与资源分配，实现了高性能与高效率的统一。

Abstract: Deriving predictable scaling laws that govern the relationship between model performance and computational investment is crucial for designing and allocating resources in massive-scale recommendation systems. While such laws are established for large language models, they remain challenging for recommendation systems, especially those processing both user history and context features. We identify poor scaling efficiency as the main barrier to predictable power-law scaling, stemming from inefficient modules with low Model FLOPs Utilization (MFU) and suboptimal resource allocation. We introduce Kunlun, a scalable architecture that systematically improves model efficiency and resource allocation. Our low-level optimizations include Generalized Dot-Product Attention (GDPA), Hierarchical Seed Pooling (HSP), and Sliding Window Attention. Our high-level innovations feature Computation Skip (CompSkip) and Event-level Personalization. These advances increase MFU from 17% to 37% on NVIDIA B200 GPUs and double scaling efficiency over state-of-the-art methods. Kunlun is now deployed in major Meta Ads models, delivering significant production impact.

</details>


### [365] [Overview of the TREC 2025 RAGTIME Track](https://arxiv.org/abs/2602.10024)
*Dawn Lawrie,Sean MacAvaney,James Mayfield,Luca Soldaini,Eugene Yang,Andrew Yates*

Main category: cs.IR

TL;DR: RAGTIME track at TREC focuses on multilingual report generation using news documents in Arabic, Chinese, English, and Russian, with three tasks and 125 submitted runs from 13 teams.


<details>
  <summary>Details</summary>
Motivation: To study report generation from multilingual source documents and evaluate systems across languages and tasks.

Method: Organized a multilingual document collection and defined three evaluation tasks: Multilingual Report Generation, English Report Generation, and Multilingual Information Retrieval (MLIR).

Result: 125 runs were submitted by 13 teams and track coordinators across the three tasks; results are summarized in the overview.

Conclusion: The RAGTIME track provides a benchmark for evaluating multilingual RAG systems, highlighting challenges and performance trends across languages and tasks.

Abstract: The principal goal of the RAG TREC Instrument for Multilingual Evaluation (RAGTIME) track at TREC is to study report generation from multilingual source documents. The track has created a document collection containing Arabic, Chinese, English, and Russian news stories. RAGTIME includes three task types: Multilingual Report Generation, English Report Generation, and Multilingual Information Retrieval (MLIR). A total of 125 runs were submitted by 13 participating teams (and as baselines by the track coordinators) for three tasks. This overview describes these three tasks and presents the available results.

</details>
